{"cell_type":{"d1f6a07d":"code","11f281be":"code","ae4c1f57":"code","c3d1d1da":"code","1b25f625":"code","17fa7099":"code","9b660e00":"code","7155fb75":"code","caa190c1":"code","5a3edce5":"code","93cf57f3":"code","99a9b05e":"code","f6f55a5f":"code","392a8e89":"code","e9404c1e":"code","a4948dfb":"code","37308ae7":"code","1c05087a":"code","36a86785":"code","279f1a61":"code","06fc230c":"code","99f95c07":"code","0cb5755b":"code","523f39d5":"code","1a113716":"code","c96dc5f7":"code","8458f231":"code","0080c6bb":"code","e993ae20":"code","57572ae4":"code","f5743be7":"code","e8d1c158":"code","e680fd6f":"code","39bb17fa":"code","4696007c":"code","4c60ed07":"code","a5f24130":"code","6811ba5b":"code","ab873fcb":"code","9407432b":"code","1f11942a":"code","871b6811":"code","9a3a8cbb":"code","c30ecda1":"code","583a510f":"code","453b7c9d":"code","07ce0666":"code","baa8fc23":"code","456c39d5":"code","04b37f88":"code","152bec73":"code","c769dca7":"code","a7065067":"code","74680a7f":"code","38006303":"code","55a991d0":"code","d404c19f":"code","686fe7dc":"code","67e8f330":"code","68613250":"code","87fdb338":"code","1e305066":"code","168cc767":"code","046ca3c8":"code","eaa02557":"code","9e722f00":"code","caf2cbe3":"code","87c3546c":"code","8cf7a02b":"code","e39cadc8":"code","b46cb02c":"code","004c0f39":"markdown","3ea037cb":"markdown","1f9d5ad3":"markdown","3892947e":"markdown","e18d37e4":"markdown","0a537720":"markdown","b53ddb6a":"markdown","5247c026":"markdown","b0cd4024":"markdown","439f509a":"markdown","acb86773":"markdown","f15c710c":"markdown","403a6886":"markdown","05df0dfe":"markdown","d525acf3":"markdown","4996b226":"markdown","5dc99235":"markdown","e4f4c809":"markdown","ea5212cb":"markdown","2b4fb6ff":"markdown","3c10b0a8":"markdown","0389aba0":"markdown","96a9745e":"markdown","e69fd242":"markdown","c64f8357":"markdown","98f06dd1":"markdown","3fd627ad":"markdown","c6bfe7d4":"markdown","79b86303":"markdown","adc10c34":"markdown","93bd841e":"markdown","a2d06398":"markdown","8551c070":"markdown","6b9024cc":"markdown","2337e9b2":"markdown"},"source":{"d1f6a07d":"# Main packages\n\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd","11f281be":"# Packages for graph\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nplt.style.use('fivethirtyeight')","ae4c1f57":"def create_graph_multiple(data, list_units, title_graph, foot_note, adjust_factor, figV=16, figH=10, minDate = \"2020-04-01\", type_agg=\"mean\"):\n    '''\n    :param data: dataFrame with the following columns: text\/unit named \"unit\", date and numeric values.\n    :param list_units: List with the name of the unique units.\n    :param title_graph: Graph title.\n    :param foot_note: Text to show in footer.\n    :param adjust_factor: usually something around -1. Useful to make the foot note in the right position.\n    :param figV: Figure size vertical\n    :param figH: Figure size horizontal\n    :param minDate: Starting date of the analysis. Format: \"2020-04-30\"\n    :param type_agg: Type of aggregation when grouping unit values by date.\n    '''\n    \n    # Start the figure that will receive the graphs\n    fig = plt.figure(figsize=(figV, figH))\n    # The figure will have as many rows as the numbers of states\n    grid = plt.GridSpec(len(list_units), 20, hspace=0.5, wspace=0.5)\n    # Counter to fill the graph\n    row = 0\n    \n    # Now create data for the specific State and create the graph\n    for unit in list_units:\n        # 1- Preparing the data\n        # Selecting an specific state\n        data_unit = data.loc[(data['unit'] == unit)].copy()\n        # Drop if date is less than.\n        data_unit = data_unit.loc[ (data_unit['date'] >= pd.to_datetime(minDate)) ]\n\n        #### Type of aggregation. When data has several groups, one must set the type of agreggation. Mean or Sum\n        if(type_agg == \"mean\"):\n            # Group by day\n            data_unit = data_unit.groupby(['date']).mean()\n        else:\n            data_unit = data_unit.groupby(['date']).sum()\n        \n        # 2- Creating the graph\n        ax = fig.add_subplot(grid[row, 1:])\n        ax.xaxis.set_major_locator(mdates.WeekdayLocator())\n        # set major ticks format\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n        # Set title\n        ax.set_title(f\"{title_graph} - {unit}\")\n\n        # Plot data\n        ax.plot(data_unit)\n        # Label\n        labels = list(data_unit.columns)\n        ax.legend(labels, loc='upper left', shadow=True, fontsize='x-large')    \n        # Go to next graph row\n        row+=1\n        \n    # Add footer at x = min X, y = min Y - 1.5.\n    plt.text(ax.get_xlim()[0], ax.get_ylim()[0] + adjust_factor, foot_note)\n\n    return None","c3d1d1da":"def create_graph_single(data, list_units, list_label, title_graph, title_legend, foot_note, adjust_factor, figV=16, figH=10, minDate = \"2020-04-01\", type_graph=\"none\", type_agg=\"mean\"):\n    '''\n    :param data: dataFrame with the following columns: text\/unit named \"unit\", date and numeric values.\n    :param list_units: List with the name of the unique units.\n    :param list_label: Dict that receives the label for each unit.\n    :param title_graph: Graph title.\n    :param title_legend: The title in the legend. Upper left.\n    :param foot_note: Text to show in footer.\n    :param adjust_factor: usually something around -1. Useful to make the foot note in the right position.\n    :param figV: Figure size vertical\n    :param figH: Figure size horizontal\n    :param minDate: Starting date of the analysis. Format: \"2020-04-30\"\n    :param type_graph: Type \"pct\" to dysplay as percentage.\n    :param type_agg: Type of aggregation when grouping unit values by date.\n    '''\n    \n    # Start the figure that will receive the graphs\n    fig, ax = plt.subplots(1, figsize=(figV, figH))\n    fig.suptitle(title_graph, fontsize=15)\n    \n    row = 0\n    # Now create data for the specific State and create the graph\n    for unit in list_units:\n        \n        # 1- Preparing the data\n        # Selecting an specific unit (state, country, continent)\n        data_each_unit = data.loc[(data['unit'] == unit)].copy()\n        # Drop if date is less than minimum.\n        data_each_unit = data_each_unit.loc[ (data_each_unit['date'] >= pd.to_datetime(minDate)) ]\n        \n        #### Type of aggregation. When data has several groups, one must set the type of agreggation. Mean or Sum\n        if(type_agg == \"mean\"):\n            # Group by day\n            data_each_unit = data_each_unit.groupby(['date']).mean()\n        else:\n            data_each_unit = data_each_unit.groupby(['date']).sum()\n\n        # 2- Creating the graph\n        ax.xaxis.set_major_locator(mdates.WeekdayLocator())\n        # set major ticks format\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n        if(type_graph == \"pct\"):\n            ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n        else:\n            pass\n        # Plot data with legend\n        ax.plot(data_each_unit, label=list_label[unit])\n        # Go to next graph row\n        row+=1\n\n    # Add footer at x = min X, y = min Y - 1.5.\n    plt.text(ax.get_xlim()[0], ax.get_ylim()[0] + adjust_factor, foot_note)\n    \n    # Legend title\n    plt.legend(loc=\"upper left\", title=title_legend, frameon=True)\n\n    plt.show()\n    \n    return None","1b25f625":"# Caminho para os dados\npath = \"..\/input\/HIST_PAINEL_COVIDBR_10jun2020.csv\"\n\n# L\u00ea os dados do CSV.\ndata = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False, dtype={'codmun': float} )\n\n# Renaming according to previous analysis\ndata.rename(columns={\"data\": \"date\", \"estado\": \"state\", \"municipio\": \"city\", \"regiao\": \"region\",\n                              \"casosAcumulado\": \"totalConfirmed\", \"casosNovos\": \"newConfirmed\", \n                             \"obitosAcumulado\": \"totalDeaths\", \"obitosNovos\": \"newDeaths\",\n                              \"emAcompanhamentoNovos\": \"newFollowing\", \"Recuperadosnovos\": \"totalRecoveredBrazil\"},  inplace=True)\n\n# Assign correct row to Brazil total\ndata[\"state\"] = data[\"state\"].replace(np.NaN, \"Brazil\")\n\n# Assign date\ndata['date'] = pd.to_datetime(data['date'], infer_datetime_format=True)","17fa7099":"# 1- Filter only data after 22\/march\/2020, since this is the first day with all states having data\ndata = data.loc[data['date'] >= pd.to_datetime(\"2020-03-22\")]\n\n# 2- Selecting only cities from the state of SP\ndata = data[data['codmun'].notna()]\ndata = data[data['state'] == \"SP\"]\n\n# 3- Reset index: drop = False\ndata.reset_index(inplace = True, drop = True)\n\n# 4- Drop munic with code = 350000. This is not recognized city.\ndata = data[data['codmun'] != 350000]\ndata.reset_index(inplace = True, drop = True)\n\n# 5- Convert pop data to int\ndata[\"populacaoTCU2019\"] = data[\"populacaoTCU2019\"].astype(int)","9b660e00":"# Caminho para os dados\npath = \"..\/input\/de_para_drs_sp.csv\"\n\n# L\u00ea os dados do CSV.\nde_para_sp_regions = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False,  dtype={'codmun': float})","7155fb75":"# 1) Copy main data\ndata_munic_sp_init = data.copy()","caa190c1":"# 2) Get useful columns\ndata_munic_sp = data_munic_sp_init[[\"date\", \"codmun\", \"newDeaths\", \"totalDeaths\", \"newConfirmed\", \"totalConfirmed\", \"populacaoTCU2019\"]].copy()","5a3edce5":"# 3) Now Merge with population data\ndata_munic_sp = data_munic_sp.merge(de_para_sp_regions, on=\"codmun\")\n\n# Rearrange columns\ndata_munic_sp.insert(1, \"regional\", data_munic_sp.pop(\"regional\"))","93cf57f3":"data_munic_sp","99a9b05e":"# 4) Now get deaths and confirmed cases per 1MM per city\n\n# Deaths\ndata_munic_sp[\"newDeaths_1MM\"] = (data_munic_sp[\"newDeaths\"] \/ data_munic_sp[\"populacaoTCU2019\"])*1000000\ndata_munic_sp[\"totalDeaths_1MM\"] = (data_munic_sp[\"totalDeaths\"] \/ data_munic_sp[\"populacaoTCU2019\"])*1000000\n\n# Confirmed Cases\ndata_munic_sp[\"newConfirmed_1MM\"] = (data_munic_sp[\"newConfirmed\"] \/ data_munic_sp[\"populacaoTCU2019\"])*1000000\ndata_munic_sp[\"totalConfirmed_1MM\"] = (data_munic_sp[\"totalConfirmed\"] \/ data_munic_sp[\"populacaoTCU2019\"])*1000000","f6f55a5f":"data_munic_sp","392a8e89":"# 5) Here we aggregate per region, bringing the sum of new deaths and confirmed cases in that region per day. We also get the new deaths and confirmed rates per 1MM, but considering the\n# average rate within the cities in such region, which provides an approximation of the real number.\n\n# Group columns\ndata_region_sp = data_munic_sp.groupby(['regional', 'date']).agg({'newDeaths': 'sum', 'newConfirmed': 'sum', 'newDeaths_1MM': 'mean', 'newConfirmed_1MM': 'mean'})\n# Name aggregations\ndata_region_sp.columns = ['newDeaths', 'newConfirmed', 'newDeaths_1MM_average', 'newConfirmed_1MM_average']\n# Reset index\ndata_region_sp = data_region_sp.reset_index()","e9404c1e":"data_region_sp","a4948dfb":"data_region_deaths = data_region_sp[['regional', 'date', \"newDeaths\", \"newDeaths_1MM_average\"]].copy()","37308ae7":"# Creating SMA on new deaths\n\n# First, send date to index. That way we can use 'date' as reference, instead of observations. So, if we have a missing that, it will be considered.\ndata_region_deaths.set_index([\"date\"], inplace = True, append = False, drop = True)\n\n# SMA 7 days\ndata_region_deaths.loc[:,'newDeaths_1MM_sma7'] = data_region_deaths.groupby('regional')['newDeaths_1MM_average'].rolling('7D',min_periods=7).mean().reset_index(0,drop=True)\n\n# SMA 15 days\ndata_region_deaths.loc[:,'newDeaths_1MM_sma15'] = data_region_deaths.groupby('regional')['newDeaths_1MM_average'].rolling('15D',min_periods=15).mean().reset_index(0,drop=True)\n\n# SMA 30 days\ndata_region_deaths.loc[:,'newDeaths_1MM_sma30'] = data_region_deaths.groupby('regional')['newDeaths_1MM_average'].rolling('30D',min_periods=30).mean().reset_index(0,drop=True)","1c05087a":"data_region_deaths","36a86785":"# Graph: newDeaths_1MM_average per region \n\ngraph = data_region_deaths[['regional', \"newDeaths_1MM_sma7\"]].copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph.rename(columns={\"regional\": \"unit\"}, inplace=True)\n\nlist_labels = { \"DRS - Munic. de S\u00e3o Paulo - Fase laranja\": \"S\u00e3o Paulo - Stage 2\", \"Fase laranja\": \"Other cities - Stage 2\", \"DRS XI - Presidente Prudente - Fase Vermelha\": \"Presidente Prudente - Stage 1\", \n               \"DRS XIII - Ribeir\u00e3o Preto - Fase Vermelha\": \"Ribeir\u00e3o Preto - Stage 1\", \"DRS V - Barretos - Fase Vermelha\": \"Barretos - Stage 1\"}\n\ncreate_graph_single(graph, [\"DRS - Munic. de S\u00e3o Paulo - Fase laranja\", \"Fase laranja\", \"DRS V - Barretos - Fase Vermelha\", \n                                             \"DRS XI - Presidente Prudente - Fase Vermelha\", \"DRS XIII - Ribeir\u00e3o Preto - Fase Vermelha\"], list_labels,\n                                            \"New deaths of COVID-19 per 1MM pop. SMA 7 days.\", \n                                            \"Stage from 08\/jun to 15\/jun\", \"Source: Ministry of Health of Brazil\", -1.5, 20, 6, \"2020-03-24\", \"normal\", \"mean\")","279f1a61":"data_region_confirmed = data_region_sp[['regional', 'date', \"newConfirmed\", \"newConfirmed_1MM_average\"]].copy()","06fc230c":"# Creating SMA on new deaths\n\n# First, send date to index. That way we can use 'date' as reference, instead of observations. So, if we have a missing that, it will be considered.\ndata_region_confirmed.set_index([\"date\"], inplace = True, append = False, drop = True)\n\n# SMA 7 days\ndata_region_confirmed.loc[:,'newConfirmed_1MM_sma7'] = data_region_confirmed.groupby('regional')['newConfirmed_1MM_average'].rolling('7D',min_periods=7).mean().reset_index(0,drop=True)\n\n# SMA 15 days\ndata_region_confirmed.loc[:,'newConfirmed_1MM_sma15'] = data_region_confirmed.groupby('regional')['newConfirmed_1MM_average'].rolling('15D',min_periods=15).mean().reset_index(0,drop=True)\n\n# SMA 30 days\ndata_region_confirmed.loc[:,'newConfirmed_1MM_sma30'] = data_region_confirmed.groupby('regional')['newConfirmed_1MM_average'].rolling('30D',min_periods=30).mean().reset_index(0,drop=True)","99f95c07":"data_region_confirmed","0cb5755b":"# Graph: newDeaths_1MM_average per region \n\ngraph = data_region_confirmed[['regional', \"newConfirmed_1MM_sma7\"]].copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph.rename(columns={\"regional\": \"unit\"}, inplace=True)\n\nlist_labels = { \"DRS - Munic. de S\u00e3o Paulo - Fase laranja\": \"S\u00e3o Paulo - Stage 2\", \"Fase laranja\": \"Other cities - Stage 2\", \"DRS XI - Presidente Prudente - Fase Vermelha\": \"Presidente Prudente - Stage 1\", \n               \"DRS XIII - Ribeir\u00e3o Preto - Fase Vermelha\": \"Ribeir\u00e3o Preto - Stage 1\", \"DRS V - Barretos - Fase Vermelha\": \"Barretos - Stage 1\"}\n\ncreate_graph_single(graph, [\"DRS - Munic. de S\u00e3o Paulo - Fase laranja\", \"Fase laranja\", \"DRS V - Barretos - Fase Vermelha\", \n                                             \"DRS XI - Presidente Prudente - Fase Vermelha\", \"DRS XIII - Ribeir\u00e3o Preto - Fase Vermelha\"], list_labels,\n                                            \"New confirmed cases of COVID-19 per 1MM pop. SMA 7 days.\", \n                                            \"Stage from 08\/jun to 15\/jun\", \"Source: Ministry of Health of Brazil\", -1.5, 20, 6, \"2020-03-24\", \"normal\", \"mean\")","523f39d5":"# Caminho para os dados\npath = \"..\/input\/brazil_pop_2019.csv\"\n\n# L\u00ea os dados do CSV.\ndata_additional = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False)","1a113716":"# Caminho para os dados\npath = \"..\/input\/HIST_PAINEL_COVIDBR_10jun2020.csv\"\n\n# L\u00ea os dados do CSV.\ndata = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False)\n\n# Renaming according to previous analysis\ndata.rename(columns={\"data\": \"date\", \"estado\": \"state\", \"municipio\": \"city\", \"regiao\": \"region\",\n                              \"casosAcumulado\": \"totalConfirmed\", \"casosNovos\": \"newConfirmed\", \n                             \"obitosAcumulado\": \"totalDeaths\", \"obitosNovos\": \"newDeaths\",\n                              \"emAcompanhamentoNovos\": \"newFollowing\", \"Recuperadosnovos\": \"totalRecoveredBrazil\"}, inplace=True)\n\n# Assign correct row to Brazil total\ndata[\"state\"] = data[\"state\"].replace(np.NaN, \"Brazil\")\n\n# Assign date\ndata['date'] = pd.to_datetime(data['date'], infer_datetime_format=True)","c96dc5f7":"# For each country\/date, create column for new recovered\n\n# Sort by country and date\ndata = data.sort_values([\"state\", \"date\"], ascending = (True, True))\ndata.reset_index(inplace = True, drop = True)\n\n# A column to receive new recovered cases for each day\ndata[\"newRecoveredBrazil\"] = 0\n\n# This function will assign to each country\/day the number of new cases, based on the difference among accumulated cases of the actual and last day.\n#country_before = data.iloc[0,0]\n\nfor row in range(1, data.shape[0], 1):\n    #country_actual = data.iloc[row,0]\n    if(data.iloc[row,1] == \"Brazil\"):\n        data.iloc[row,16] = data.iloc[row,14] - data.iloc[row-1,14]\n    else:\n        pass\n","8458f231":"# Getting only total data for states. Ignore total for cities.\n\n# 1- Filter only data after 22\/march\/2020, since this is the first day with all states having data\ndata = data.loc[data['date'] >= pd.to_datetime(\"2020-03-22\")]\n\n# 2- Drop row referring to cities. (codmun not NaN) We will be using only the number for states.\ndata = data[data['codmun'].isna()]\n\n# Reset index: drop = False\ndata.reset_index(inplace = True, drop = True)","0080c6bb":"# 1) Copy main data\ndata_state_br_init = data.copy()","e993ae20":"# 2) Get useful columns\ndata_state_br = data_state_br_init[[\"date\", \"state\", \"newDeaths\", \"totalDeaths\", \"newConfirmed\", \"totalConfirmed\", \"newRecoveredBrazil\", \"totalRecoveredBrazil\"]]","57572ae4":"# 3) Now Merge with population data\ndata_state_br = data_state_br.merge(data_additional, on=\"state\")\ndel data_state_br[\"gov_name\"]\ndel data_state_br[\"gov_image\"]","f5743be7":"data_state_br","e8d1c158":"# 4) Now Create a column for total deaths by 1MM habitants from each state. \n# Important that this command can only be used AFTER grouping by states.\n\n# Deaths\ndata_state_br[\"newDeaths_1MM\"] = (data_state_br[\"newDeaths\"] \/ data_state_br[\"pop_2019\"])*1000000\ndata_state_br[\"totalDeaths_1MM\"] = (data_state_br[\"totalDeaths\"] \/ data_state_br[\"pop_2019\"])*1000000\n\n# Cases\ndata_state_br[\"newConfirmed_1MM\"] = (data_state_br[\"newConfirmed\"] \/ data_state_br[\"pop_2019\"])*1000000\ndata_state_br[\"totalConfirmed_1MM\"] = (data_state_br[\"totalConfirmed\"] \/ data_state_br[\"pop_2019\"])*1000000\n\n# Recovered\ndata_state_br[\"newRecovered_Brazil_1MM\"] = (data_state_br[\"newRecoveredBrazil\"] \/ data_state_br[\"pop_2019\"])*1000000\ndata_state_br[\"totalRecovered_Brazil_1MM\"] = (data_state_br[\"totalRecoveredBrazil\"] \/ data_state_br[\"pop_2019\"])*1000000","e680fd6f":"data_state_br","39bb17fa":"# Checking to see if every state has the same ammount of available records.\ndata_state_br.groupby(['date', 'state']).size().unstack(fill_value=0).describe().T.sort_values([\"count\"], ascending =True)","4696007c":"# 1) Selecting data\ndata_state_br_deaths = data_state_br.copy()\ndata_state_br_deaths = data_state_br_deaths[[\"date\", \"state\", \"newDeaths_1MM\"]]","4c60ed07":"data_state_br_deaths","a5f24130":"# 2) Creating SMA on new deaths\n\n# First, send date to index. That way we can use 'date' as reference, instead of observations. So, if we have a missing that, it will be considered.\ndata_state_br_deaths.set_index([\"date\"], inplace = True, append = False, drop = True)\n\n# SMA 7 days\ndata_state_br_deaths.loc[:,'newDeaths_1MM_sma7'] = data_state_br_deaths.groupby('state')['newDeaths_1MM'].rolling('7D',min_periods=7).mean().reset_index(0,drop=True)\n\n# SMA 15 days\ndata_state_br_deaths.loc[:,'newDeaths_1MM_sma15'] = data_state_br_deaths.groupby('state')['newDeaths_1MM'].rolling('15D',min_periods=15).mean().reset_index(0,drop=True)\n\n# SMA 30 days\ndata_state_br_deaths.loc[:,'newDeaths_1MM_sma30'] = data_state_br_deaths.groupby('state')['newDeaths_1MM'].rolling('30D',min_periods=30).mean().reset_index(0,drop=True)","6811ba5b":"###### Graph\n\ngraph = data_state_br_deaths[['state', \"newDeaths_1MM_sma7\"]].copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph.rename(columns={\"state\": \"unit\"}, inplace=True)\n\nlist_labels = {\"Brazil\": \"Brazil\", \"RJ\": \"RJ\", \"CE\": \"CE\", \"PA\": \"PA\", \"PE\": \"PE\", \"AM\": \"AM\"}\n\ncreate_graph_single(graph, [\"Brazil\", \"RJ\", \"CE\", \"PA\", \"PE\", \"AM\"],\n                    list_labels,\n                    \"New deaths of COVID-19 per 1MM pop. SMA 7 days.\", \n                    \"State\", \"Source: Ministry of Health of Brazil\", \n                    -3.5, 20, 6, \"2020-04-01\", \"normal\", \"mean\")","ab873fcb":"# 1) Selecting data\ndata_state_br_confirmed = data_state_br.copy()\ndata_state_br_confirmed = data_state_br_confirmed[[\"date\", \"state\", \"newConfirmed_1MM\"]]","9407432b":"data_state_br_confirmed","1f11942a":"# 2) Creating SMA on new deaths\n\n# First, send date to index. That way we can use 'date' as reference, instead of observations. So, if we have a missing that, it will be considered.\ndata_state_br_confirmed.set_index([\"date\"], inplace = True, append = False, drop = True)\n\n# SMA 7 days\ndata_state_br_confirmed.loc[:,'newConfirmed_1MM_sma7'] = data_state_br_confirmed.groupby('state')['newConfirmed_1MM'].rolling('7D',min_periods=7).mean().reset_index(0,drop=True)\n\n# SMA 15 days\ndata_state_br_confirmed.loc[:,'newConfirmed_1MM_sma15'] = data_state_br_confirmed.groupby('state')['newConfirmed_1MM'].rolling('15D',min_periods=15).mean().reset_index(0,drop=True)\n\n# SMA 30 days\ndata_state_br_confirmed.loc[:,'newConfirmed_1MM_sma30'] = data_state_br_confirmed.groupby('state')['newConfirmed_1MM'].rolling('30D',min_periods=30).mean().reset_index(0,drop=True)","871b6811":"###### Graph\n\ngraph = data_state_br_confirmed[['state', \"newConfirmed_1MM_sma7\"]].copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph.rename(columns={\"state\": \"unit\"}, inplace=True)\n\nlist_labels = {\"Brazil\": \"Brazil\", \"RJ\": \"RJ\", \"CE\": \"CE\", \"PA\": \"PA\", \"PE\": \"PE\", \"AM\": \"AM\"}\n\ncreate_graph_single(graph, [\"Brazil\", \"RJ\", \"CE\", \"PA\", \"PE\", \"AM\"],\n                    list_labels,\n                    \"New confirmed cases of COVID-19 per 1MM pop. SMA 7 days.\", \n                    \"State\", \"Source: Ministry of Health of Brazil\", \n                    -60, 20, 6, \"2020-04-01\", \"normal\", \"mean\")","9a3a8cbb":"# 1) Selecting data\ndata_br_recovered = data_state_br.copy()\ndata_br_recovered = data_br_recovered[[\"date\", \"state\", \"newRecovered_Brazil_1MM\"]]\n\n# Selecting data only for the consolidate, which mean, for Brazil\ndata_br_recovered = data_br_recovered.loc[(data_br_recovered['state'] == \"Brazil\")]\ndata_br_recovered.reset_index(inplace = True, drop = True)","c30ecda1":"data_br_recovered","583a510f":"# 2) Creating SMA on new deaths\n\n# First, send date to index. That way we can use 'date' as reference, instead of observations. So, if we have a missing that, it will be considered.\ndata_br_recovered.set_index([\"date\"], inplace = True, append = False, drop = True)\n\n# SMA 7 days\ndata_br_recovered.loc[:,'newRecovered_Brazil_1MM_sma7'] = data_br_recovered.groupby('state')['newRecovered_Brazil_1MM'].rolling('7D',min_periods=7).mean().reset_index(0,drop=True)\n\n# SMA 15 days\ndata_br_recovered.loc[:,'newRecovered_Brazil_1MM_sma15'] = data_br_recovered.groupby('state')['newRecovered_Brazil_1MM'].rolling('15D',min_periods=15).mean().reset_index(0,drop=True)\n\n# SMA 30 days\ndata_br_recovered.loc[:,'newRecovered_Brazil_1MM_sma30'] = data_br_recovered.groupby('state')['newRecovered_Brazil_1MM'].rolling('30D',min_periods=30).mean().reset_index(0,drop=True)","453b7c9d":"graph = data_br_recovered[['state', \"newRecovered_Brazil_1MM\", \"newRecovered_Brazil_1MM_sma7\", \"newRecovered_Brazil_1MM_sma15\", \"newRecovered_Brazil_1MM_sma30\"]].copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph.rename(columns={\"state\": \"unit\"}, inplace=True)\n\nlist_labels = {\"Brazil\": \"Brazil\"}\n\ncreate_graph_multiple(graph, [\"Brazil\"], \"New recovered cases of COVID-19 per 1MM pop. SMA 7 days\",\n                          \"Source: Ministry of Health of Brazil\", \n                          -15, 20, 6, \"2020-04-01\", \"mean\" )","07ce0666":"data_br_recovered","baa8fc23":"# 1) Getting data from Brazil\n# deaths\nbr_deaths = data_state_br_deaths.loc[(data_state_br_deaths['state'] == \"Brazil\")].copy()\ndel br_deaths[\"newDeaths_1MM_sma15\"]\ndel br_deaths[\"state\"]\n    \n# confirmed\nbr_confirmed = data_state_br_confirmed.loc[(data_state_br_confirmed['state'] == \"Brazil\")].copy()\ndel br_confirmed[\"newConfirmed_1MM_sma15\"]\ndel br_confirmed[\"state\"]\n\n# recovered\nbr_recovered = data_br_recovered.loc[(data_br_recovered['state'] == \"Brazil\")].copy()\ndel br_recovered[\"newRecovered_Brazil_1MM_sma15\"]\ndel br_recovered[\"state\"]","456c39d5":"br_mod1 = br_deaths.merge(br_confirmed, on=\"date\")","04b37f88":"br_mod2 = br_mod1.merge(br_recovered, on=\"date\")","152bec73":"##### Graph\n\ngraph = br_mod2.copy()\n\ngraph.reset_index(inplace = True, drop = False)\n\ngraph[\"unit\"]=\"Brazil\"\n\n# Rename columns\ngraph.rename(columns={\"newConfirmed_1MM\": \"New Confirmed\", \"newConfirmed_1MM_sma7\": \"New Confirmed SMA7\", \"newConfirmed_1MM_sma15\": \"New Confirmed SMA15\", \"newConfirmed_1MM_sma30\": \"New Confirmed SMA30\",\n                    \"newRecovered_Brazil_1MM\": \"New Recovered\", \"newRecovered_Brazil_1MM_sma7\": \"New Recovered SMA7\", \"newRecovered_Brazil_1MM_sma15\": \"New Recovered SMA 15\", \"newRecovered_Brazil_1MM_sma30\": \"New Recovered SMA30\",\n                    \"newDeaths_1MM\": \"New Deaths\", \"newDeaths_1MM_sma7\": \"New Deaths SMA7\", \"newDeaths_1MM_sma15\": \"New Deaths SMA15\", \"newDeaths_1MM_sma30\": \"New Deaths SMA30\"}, inplace=True)\n\ndel graph[\"New Confirmed SMA7\"]\ndel graph[\"New Recovered SMA7\"]\ndel graph[\"New Deaths SMA7\"]\n\ncreate_graph_multiple(graph, [\"Brazil\"], \"New deaths, recovered and confirmed cases of COVID-19 per 1MM pop. \\n New and Simple Moving Average for 30 days\",\n                          \"Source: Ministry of Health of Brazil\", \n                          -25, 20, 6, \"2020-04-01\", \"mean\" )","c769dca7":"# Caminho para os dados\npath = \"..\/input\/data_pop_2020.csv\"\n\n# L\u00ea os dados do CSV.\ndata_pop_2020 = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False, dtype={\"country_pop_2020\": float})","a7065067":"# Caminho para os dados\npath = \"..\/input\/flourish_flags.csv\"\n\n# L\u00ea os dados do CSV.\nflourish_flags = pd.read_csv(path, encoding='UTF-8', delimiter=';' , low_memory=False)","74680a7f":"path = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv\"\ndata = pd.read_csv(path, encoding='ISO-8859-1', delimiter=',' , low_memory=False)\ndata_deaths = data.copy()\n\n# Remove lat & long values\ndel data_deaths[\"Lat\"]\ndel data_deaths[\"Long\"]\ndel data_deaths[\"Province\/State\"]","38006303":"path = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv\"\ndata = pd.read_csv(path, encoding='ISO-8859-1', delimiter=',' , low_memory=False)\ndata_confirmed = data.copy()\n\ndel data\n\n# Remove lat & long values\ndel data_confirmed[\"Lat\"]\ndel data_confirmed[\"Long\"]","55a991d0":"path = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv\"\ndata = pd.read_csv(path, encoding='ISO-8859-1', delimiter=',' , low_memory=False)\ndata_recovered = data.copy()\n\ndel data\n\n# Remove lat & long values\ndel data_recovered[\"Lat\"]\ndel data_recovered[\"Long\"]","d404c19f":"# This function receives dataset from Johns Hopkins and returns treated data per 1MM for confirmed, recovered and deaths.\ndef get_sma_per1MM(data_inicial, name):\n    '''\n    :param data: Dataset from Johns hopkins for confirmed, recovered or deaths.\n    :param name: The type of data analysed. Confirmed, Recovered or Deaths by COVID-19.\n    '''\n    data = data_inicial.copy()\n    # 1) Group by country\n    data = data.groupby(['Country\/Region']).sum()\n    data.reset_index(inplace = True, drop = False)\n    \n    # 2) Make data in rows\n    data = data.melt(id_vars=[\"Country\/Region\"], var_name=\"date\", value_name=f\"total{name}\")\n    \n    # 3) For each country\/date, create column for new deaths\n    # Assign date type\n    data['date'] = pd.to_datetime(data['date']).dt.date\n    # Sort by country and date\n    data = data.sort_values([\"Country\/Region\", \"date\"], ascending = (True, True))\n    data.reset_index(inplace = True, drop = True)\n    # A column to receive new cases for each day\n    data[f\"new{name}\"] = 0\n    # This function will assign to each country\/day the number of new cases, based on the difference among accumulated cases of the actual and last day.\n    country_before = data.iloc[0,0]\n    for row in range(1, data.shape[0], 1):\n        country_actual = data.iloc[row,0]\n        if(country_actual == country_before):\n            data.iloc[row,3] = data.iloc[row,2] - data.iloc[row-1,2]\n        else:\n            data.iloc[row,3] = data.iloc[row,2]\n        country_before = country_actual\n    # Reset index: drop = False\n    data.reset_index(inplace = True, drop = True)\n    \n    # 4) Add population data\n    data = data.merge(data_pop_2020, on=\"Country\/Region\")\n    \n    # 5) Now Create a column for total deaths by 1MM habitants from each country. \n    # Important that this command can only be used AFTER grouping by contries.\n    data[f\"new{name}_1MM\"] = 0\n    data[f\"new{name}_1MM\"] = (data[f\"new{name}\"] \/ data[\"country_pop_2020\"])*1000000\n    data[f\"total{name}_1MM\"] = 0\n    data[f\"total{name}_1MM\"] = (data[f\"total{name}\"] \/ data[\"country_pop_2020\"])*1000000\n    # remove pop column\n    del data[\"country_pop_2020\"]\n    \n    ##### Getting SMA for new cases and total cases (7,15,30)\n    \n    # 1) Creating SMA per country - New cases per 1MM\n    # SMA 7 days\n    data.loc[:,f'new{name}_1MM_sma7'] = data.groupby('Country\/Region')[f'new{name}_1MM'].rolling(window=7).mean().reset_index(0,drop=True)\n    # SMA 15 days\n    data.loc[:,f'new{name}_1MM_sma15'] = data.groupby('Country\/Region')[f'new{name}_1MM'].rolling(window=15).mean().reset_index(0,drop=True)\n    # SMA 30 days\n    data.loc[:,f'new{name}_1MM_sma30'] = data.groupby('Country\/Region')[f'new{name}_1MM'].rolling(window=30).mean().reset_index(0,drop=True)\n    \n    # 2) Creating SMA per country - Total cases per 1MM\n    # SMA 7 days\n    data.loc[:,f'total{name}_1MM_sma7'] = data.groupby('Country\/Region')[f'total{name}_1MM'].rolling(window=7).mean().reset_index(0,drop=True)\n    # SMA 15 days\n    data.loc[:,f'total{name}_1MM_sma15'] = data.groupby('Country\/Region')[f'total{name}_1MM'].rolling(window=15).mean().reset_index(0,drop=True)\n    # SMA 30 days\n    data.loc[:,f'total{name}_1MM_sma30'] = data.groupby('Country\/Region')[f'total{name}_1MM'].rolling(window=30).mean().reset_index(0,drop=True)\n        \n    return data\n","686fe7dc":"data_deaths_world = get_sma_per1MM(data_deaths, \"Deaths\")","67e8f330":"#graph\n\ngraph = data_deaths_world[[\"date\", \"Country\/Region\", \"newDeaths_1MM_sma7\"]].copy()\n\ngraph.rename(columns={\"Country\/Region\": \"unit\"}, inplace=True)\n\nlist_labels = {\"US\": \"US\", \"Brazil\": \"Brazil\",  \"Belgium\": \"Belgium\", \"United Kingdom\": \"United Kingdom\",\n               \"Spain\": \"Spain\",  \"Sweden\": \"Sweden\", \"Mexico\": \"Mexico\"}\n\ncreate_graph_single(graph, [\"US\", \"Brazil\",  \"Spain\", \"Sweden\", \"United Kingdom\", \"Belgium\", \"Mexico\"],\n                    list_labels,\n                    \"Brazil compared to other countries - New deaths of COVID-19 per 1MM pop. \\n Simple Moving Average - 7 days\", \n                    \"Country\", \"Source: Johns Hopkins\", \n                    -5, 20, 6, \"2020-03-15\", \"normal\", \"mean\")","68613250":"# Countries with high rates of new deaths on average\ngraph.groupby(\"unit\").mean().sort_values([\"newDeaths_1MM_sma7\"], ascending = False).head(15)","87fdb338":"################################################\n# Prepare data for visual\n################################################\ndata_deaths_world_visual = data_deaths_world.pivot(index='Country\/Region', columns='date', values='newDeaths_1MM_sma7')\ndata_deaths_world_visual.reset_index(inplace = True, drop = False)","1e305066":"# Adding flags and Regions\ndata_deaths_world_visual.rename(columns={\"Country\/Region\": \"Country\"}, inplace=True)\ndata_deaths_world_visual = data_deaths_world_visual.merge(flourish_flags, on=\"Country\")\n# Rearrange columns\ndata_deaths_world_visual.insert(1, \"region\", data_deaths_world_visual.pop(\"region\"))\ndata_deaths_world_visual.insert(2, \"Image URL\", data_deaths_world_visual.pop(\"Image URL\"))","168cc767":"# Remove Djibouti\ndata_deaths_world_visual.drop(data_deaths_world_visual[data_deaths_world_visual[\"Country\"] == \"Djibouti\"].index, inplace=True)\ndata_deaths_world_visual.drop(data_deaths_world_visual[data_deaths_world_visual[\"Country\"] == \"San Marino\"].index, inplace=True)\ndata_deaths_world_visual.drop(data_deaths_world_visual[data_deaths_world_visual[\"Country\"] == \"Andorra\"].index, inplace=True)","046ca3c8":"data_deaths_world_visual","eaa02557":"# Export data\n#data_deaths_world_visual.to_excel(\"output\/data_deaths_world_visual.xlsx\")","9e722f00":"data_confirmed_world = get_sma_per1MM(data_confirmed, \"Confirmed\")","caf2cbe3":"#graph\n\ngraph = data_confirmed_world[[\"date\", \"Country\/Region\", \"newConfirmed_1MM_sma7\"]].copy()\n\ngraph.rename(columns={\"Country\/Region\": \"unit\"}, inplace=True)\n\nlist_labels = {\"US\": \"US\", \"Brazil\": \"Brazil\",  \"Belgium\": \"Belgium\", \"Peru\": \"Peru\",\n               \"Spain\": \"Spain\",  \"Sweden\": \"Sweden\", \"Chile\": \"Chile\"}\n\ncreate_graph_single(graph, [\"US\", \"Brazil\",  \"Spain\", \"Sweden\", \"Peru\", \"Belgium\", \"Chile\"],\n                    list_labels,\n                    \"Brazil compared to other countries - New confirmed cases of COVID-19 per 1MM pop. \\n Simple Moving Average - 7 days\", \n                    \"Country\", \"Source: Johns Hopkins\", \n                    -5, 20, 6, \"2020-03-15\", \"normal\", \"mean\")","87c3546c":"# States with high rates of new deaths on average\ngraph.groupby(\"unit\").mean().sort_values([\"newConfirmed_1MM_sma7\"], ascending = False).head(15)","8cf7a02b":"data_recovered_world = get_sma_per1MM(data_recovered, \"Recovered\")","e39cadc8":"#graph\n\ngraph = data_recovered_world[[\"date\", \"Country\/Region\", \"newRecovered_1MM_sma7\"]].copy()\n\ngraph.rename(columns={\"Country\/Region\": \"unit\"}, inplace=True)\n\nlist_labels = {\"US\": \"US\", \"Brazil\": \"Brazil\",  \"Belgium\": \"Belgium\", \"Italy\": \"Italy\",\n               \"Spain\": \"Spain\",  \"Peru\": \"Peru\"}\n\ncreate_graph_single(graph, [\"US\", \"Brazil\",  \"Spain\", \"Italy\", \"Peru\", \"Belgium\"],\n                    list_labels,\n                    \"Brazil compared to other countries - New recovered cases of COVID-19 per 1MM pop. \\n Simple Moving Average - 7 days\", \n                    \"Country\", \"Source: Johns Hopkins\", \n                    -5, 20, 6, \"2020-03-15\", \"normal\", \"mean\")","b46cb02c":"# States with high rates of new deaths on average\ngraph.groupby(\"unit\").mean().sort_values([\"newRecovered_1MM_sma7\"], ascending = False).head(15)","004c0f39":"## 1.2 Loading SP regions","3ea037cb":"# 4 New confirmed cases per state","1f9d5ad3":"# [Graph Function]","3892947e":"## 1.5 COVID-19 Recovered","e18d37e4":"# [Brazilian States] Analysis using SMA for COVID-19. Per 1MM pop.","0a537720":"# [World] Comparison on Deaths, Recovered and Confirmed cases","b53ddb6a":"# Analysis of COVID-19 in Brazil\n#### Author: [Rafael Klanfer Nunes](https:\/\/www.linkedin.com\/in\/rafaelknunes\/)\n#### **Date**: 10\/jun\/2020\n#### **Data Source Brazil**: [Ministry of Health](https:\/\/covid.saude.gov.br)\n#### **Data Source International**: [Data Repository by Johns Hopkins CSSE](https:\/\/github.com\/CSSEGISandData\/COVID-19\/tree\/master\/csse_covid_19_data\/csse_covid_19_time_series)\n\n#### **Disclaimer**: This code is available at [Kaggle](https:\/\/www.kaggle.com\/rafaelknunes\/analysis-of-covid-19-in-brazil-states-countries)","5247c026":"# ------------------------------------------------------------------------------------------","b0cd4024":"# 2. Function to get SMA cases per 1MM","439f509a":"# 6. Brazil analysis for confirmed, recovered and deaths","acb86773":"# 1. Loading data","f15c710c":"# 4. Analysis of New confirmed cases per region","403a6886":"## 1.1 COVID-19 Min. Health by city","05df0dfe":"https:\/\/public.flourish.studio\/visualisation\/2784419\/","d525acf3":"# ------------------------------------------------------------------------------------------","4996b226":"# 1. Loading data\n\n* COVID-19: Source: [Data Repository by Johns Hopkins CSSE](https:\/\/github.com\/CSSEGISandData\/COVID-19\/tree\/master\/csse_covid_19_data\/csse_covid_19_time_series). This data regards deaths by COVID-19 per country, per day. Accumulated up to date.\n\n* Population data: Source: Worldometer (www.Worldometers.info)\nElaboration of data by United Nations, Department of Economic and Social Affairs, Population Division. World Population Prospects: The 2019 Revision. (Medium-fertility variant).","5dc99235":"## 1.3 COVID-19 Deaths","e4f4c809":"# 3. Analysis of New Deaths per region","ea5212cb":"### Visual Animation on Flourish","2b4fb6ff":"# 5. New recovered cases (Available data only for Brazil)","3c10b0a8":"# [Plano SP] Analysis for state of S\u00e3o Paulo\n\nThe numbers displayed by 1MM of hab. refer to the average rate of different municipalities in a region. This is a good indicator if the rate is homogeneous among the cities in that region. Otherwise, it is another indication that the heterogeneity of cities within these regions requires a municipal strategy instead of the regional one.","0389aba0":"## 1.1 Additional data (pop per state, names, HDI)","96a9745e":"# 3. New deaths of COVID-19. Per 1MM pop.","e69fd242":"## 1.2 Country's Flags","c64f8357":"# 1. Loading data","98f06dd1":"# ------------------------------------------------------------------------------------------","3fd627ad":"# 3. New deaths per state","c6bfe7d4":"# 2. Preparing data","79b86303":"## 1.2 Population data per country","adc10c34":"# ------------------------------------------------------------------------------------------","93bd841e":"# 4. New confirmed cases of COVID-19. Per 1MM pop.","a2d06398":"## 1.2 Brazil's COVID-19 data. Min. of Health\n\nStarting at 22\/mar\/2020 since this is the first day that all states have at least one case.","8551c070":"## 1.4 COVID-19 Confirmed","6b9024cc":"# 5. New recovered cases of COVID-19. Per 1MM pop.","2337e9b2":"# 2 Preparing data grouped per region of SP"}}