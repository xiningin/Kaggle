{"cell_type":{"33369b9f":"code","c49f88e2":"code","d75b62d5":"code","c133d460":"code","e65c19ef":"code","c04c1714":"code","7c1dbcb5":"code","8d9b96f5":"code","a7e1ed43":"code","c014ce4a":"code","de38493f":"code","690e1f0a":"code","e1fce19d":"code","517fbbe1":"code","9354e996":"code","3555df2d":"code","d31042f4":"code","fd2c0daa":"code","2b8fac01":"code","44c02909":"code","e7eecd10":"code","01591291":"code","b272a73c":"code","cb5691e1":"code","50dadcc6":"code","ce56024f":"code","7059f364":"code","029523be":"markdown","c8875d98":"markdown","a9429121":"markdown","b683e873":"markdown","32efc574":"markdown","4b456d1b":"markdown","91af55da":"markdown","dddef9da":"markdown","4f53644d":"markdown","d871fb5a":"markdown","9c72639b":"markdown","e046d848":"markdown","e3be1ce8":"markdown","bda896d0":"markdown","da752bd0":"markdown","f223f545":"markdown","6e1cc704":"markdown","016de85d":"markdown","bca23fa7":"markdown","35e1de5f":"markdown","ce0d56ec":"markdown","973ca19a":"markdown","7f882c61":"markdown","1a5609f9":"markdown","7dd8265c":"markdown","a08e1c0f":"markdown","d544676d":"markdown","d1c42c58":"markdown","b4d0271c":"markdown","0df4e2f8":"markdown","b6b9e561":"markdown"},"source":{"33369b9f":"# Importing libraries:\n\n# Importing numpy, pandas, matplotlib and seaborn:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Imports for plotly:\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n\n# To keep graph within the nobebook:\n%matplotlib inline\n\n# To hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","c49f88e2":"# Read data from saved csv file:\ndf = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","d75b62d5":"# Display first five rows of dataframe:\nheader = ff.create_table(df.head())\n\nheader.show()","c133d460":"# Function to describe variables\ndef desc(df):\n    d = pd.DataFrame(df.dtypes,columns=['Data_Types'])\n    d = d.reset_index()\n    d['Columns'] = d['index']\n    d = d[['Columns','Data_Types']]\n    d['Missing'] = df.isnull().sum().values    \n    d['Uniques'] = df.nunique().values\n    return d\n\n\ndescr = ff.create_table(desc(df))\n\ndescr.show()","e65c19ef":"# Explore dataframe's statistics (numerical values only):\ndesc = ff.create_table(df.describe())\n\ndesc.show()","c04c1714":"age_df = pd.DataFrame(df.groupby(['Gender'])['Gender'].count())\n#age_df.head()","7c1dbcb5":"#Gender distribution of shoppers:\n\n\ndata=go.Bar(x = age_df.index\n           , y = age_df.Gender\n           ,  marker=dict( color=['#FF0000', '#0000FF'])\n           )\n\n\n\nlayout = go.Layout(title = 'Number of Customers split by Gender'\n                   , xaxis = dict(title = 'Gender')\n                   , yaxis = dict(title = 'Volume')\n                  )\n\nfig = go.Figure(data,layout)\nfig.show()","8d9b96f5":"# Box plot for Annual Income by Gender:\n\nfig = px.box(df\n             , x='Gender'\n             , y='Annual Income (k$)'\n             , points='all'\n             , color='Gender'\n             , title='Box plot of Annual Income by Gender'\n             #, width = 950\n            )\n\nfig.show()","a7e1ed43":"# Box Plot for Spending Score split by Gender:\n\nfig = px.box(df\n             , x='Gender'\n             , y='Spending Score (1-100)'\n             , points=\"all\"\n             , color='Gender'\n             , title='Box plot of Spending Score by Gender'\n            )\n\nfig.show()","c014ce4a":"# Scatters for Age vs. Spending Score split by Gender:\n\nfig = px.scatter(df\n                 , x='Age'\n                 , y='Spending Score (1-100)'\n                 , color = 'Gender'\n                 , facet_col='Gender'\n                 , color_continuous_scale= ['#FF0000','#0000FF']   #px.colors.sequential.Viridis\n                 , render_mode=\"webgl\"\n                # , width = 950\n                )\n\nfig.show()","de38493f":"# Scatter for Annual income vs. Speniding Score split by Gender:\n\nfig = px.scatter(df\n                 , x='Annual Income (k$)'\n                 , y='Spending Score (1-100)'\n                 , color = 'Gender'\n                 , facet_col='Gender'\n                 , color_continuous_scale= ['#FF0000','#0000FF']   #px.colors.sequential.Viridis\n                 , render_mode=\"webgl\"\n                )\n\nfig.show()","690e1f0a":"# Histograms, Distribution of Annual Income, Age and Spending Score:\n\nfig = make_subplots(rows=1\n                    , cols=3\n                    ,subplot_titles=('Annual Income', 'Age', 'Spending Score'))\n\n\ntrace0 = go.Histogram(x=df['Annual Income (k$)']\n                      , xbins=dict(start=15\n                                   , end=140\n                                   , size= 5)\n                      , autobinx=False\n                      , opacity=0.7\n                     )\ntrace1 = go.Histogram(x=df['Age']\n                      , xbins=dict(start=18\n                                   , end=98\n                                   , size= 5)\n                      , autobinx=False\n                      , opacity=0.7\n                     )\ntrace2 = go.Histogram(x=df['Spending Score (1-100)']\n                      , xbins=dict(start=1\n                                   , end=100\n                                   , size= 2)\n                      , autobinx=False\n                      , opacity=0.7\n                     )\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 1, 3)\n\n# Update xaxis properties\nfig.update_xaxes(title_text='Annual Income (k$)', row=1, col=1)\nfig.update_xaxes(title_text='Age', row=1, col=2)\nfig.update_xaxes(title_text='Spending Score (1-100)',  row=1, col=3)\n\n\n# Update yaxis properties\nfig.update_yaxes(title_text='count', row=1, col=1)\n\n# Update title and height\nfig.update_layout(title_text='Distributions of ', height=600)\n\n\nfig.show()","e1fce19d":"# Scatter graph for Annual Income vs Spending Score by Gender:\n\nfig = px.scatter(df\n                 , x='Annual Income (k$)'\n                 , y='Spending Score (1-100)'\n                 , color= 'Gender'\n                 , marginal_y='rug'\n                 , marginal_x='histogram'\n                )\nfig.show()","517fbbe1":"# Scatter graph for Annual Income vs. Spending Score by Age:\n\nfig = px.scatter(df\n                 , x='Annual Income (k$)'\n                 , y='Spending Score (1-100)'\n                 , color= 'Age'\n                 , marginal_y='box'\n                 , marginal_x='histogram'\n                )\nfig.show()","9354e996":"# Scatter graph for Age vs. Spending Score by Annual Income:\n\nfig = px.scatter(df\n                 , x='Age'\n                 , y= 'Spending Score (1-100)'\n                 , color= 'Annual Income (k$)'\n                 , marginal_y='box'\n                 , marginal_x='histogram'\n                )\nfig.show()","3555df2d":"# 3D Scatter graph for Annual Income, Spending Score and Age:\n\nfig = px.scatter_3d(df\n                    , x='Annual Income (k$)'\n                    , y='Spending Score (1-100)'\n                    , z='Age'\n                    , color='Annual Income (k$)'\n                    , size='Spending Score (1-100)'\n                   )\n\nfig.show()","d31042f4":"# Correlation matrix for Mall dataset features:\n\ncorr = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].corr()\n\nfig = go.Figure(data=go.Heatmap(\n                   z=corr\n                 , x=['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n                 , y=['Spending Score (1-100)','Annual Income (k$)', 'Age' ]\n                 , hoverongaps = False))\n\nfig.update_layout(title='Correlation for Features of Mall data')\n\n\nfig.show()","fd2c0daa":"# Calculate inertia for k-clusters:\n\nfrom sklearn.cluster import KMeans\n\nX = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n\nl = []\nfor i in range(2, 11):\n    kmeans = KMeans(n_clusters = i, random_state = 123)\n    kmeans.fit(X)\n    l.append(kmeans.inertia_)\n\ndf_1= pd.DataFrame(l, columns=['Inertia'])\ndf_1['k'] = df_1.index+2","2b8fac01":"# Line graph for Inertia vs. k-Clusters\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df_1.k\n                         , y=df_1.Inertia\n                         , mode='lines'\n                         , name='inertia lines'\n                        )\n             )\n\nfig.add_trace(go.Scatter(x=df_1.k, y=df_1.Inertia,\n                    mode='markers', name='inertia point'))\n\nfig.update_layout(title='The Total Sum of Squares Method'\n                  , xaxis_title='k-clusters'\n                  , yaxis_title='Internia'\n                 )\n\nfig.show()","44c02909":"# Calculate silhouette score for k-clusters:\n\nfrom sklearn.metrics import silhouette_score\nfrom sklearn import metrics\n\nm = []\n\nfor i in range(2,11):\n    kmeans = KMeans(n_clusters = i, random_state = 123)\n    k_means = kmeans.fit(X)  \n    labels = k_means.labels_\n    sil_coeff = metrics.silhouette_score(X, labels,metric='euclidean')\n    m.append(sil_coeff)\n\n\ndf_2= pd.DataFrame(m, columns=['Score'])\ndf_2['k'] = df_2.index+2\n#print(df_2)\n","e7eecd10":"# Line graph for silhouette score vs. k-clusters\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df_2.k\n                         , y=df_2.Score\n                         , mode='lines'\n                         , name=' score lines'\n                        )\n             )\n\nfig.add_trace(go.Scatter(x=df_2.k\n                         , y=df_2.Score\n                         , mode='markers'\n                         , name='score point'))\n\nfig.update_layout(title='The Silhouette Score Method'\n                  , xaxis_title='k-clusters'\n                  , yaxis_title='Score'\n                 )\n\nfig.show()","01591291":"# Fit data to KMeans clustering with 5 clusters, assign labels and cetroids: \n\nkmeans= KMeans(n_clusters = 5)\nkmeans.fit(X)\n\nlabels = kmeans.labels_\ncentroids = kmeans.cluster_centers_\n","b272a73c":"print('Cluster membership: \\n{}'.format(labels))","cb5691e1":"print('Centroids: \\n{}'.format(centroids))","50dadcc6":"clusters = labels.tolist()\nX['clusters'] = clusters\nX['Id'] = df['CustomerID']","ce56024f":"# Display first 5 rows of dataset X:\n\nhead = ff.create_table(X.head())\nhead.show()","7059f364":"# Scatter graph of clusters, centroids are displayed as black markers:\n\nX['clusters'] = X['clusters'].astype(str)\n\nfig = px.scatter(X\n                 , x='Annual Income (k$)'\n                 , y='Spending Score (1-100)'\n                 , color='clusters'\n                 , title='Customer Segmentation (k=5)'\n                )\n\nfig.add_trace(go.Scatter(x=centroids[:,1], y=centroids[:,2],\n                    mode='markers',\n                    name='centroids',\n                        marker=dict(\n            color='black')))\n              \n              \nfig.show()","029523be":"Silhouette score is considered to be a more precise approach than internia's 'elbow'. It is the mean silhouette coefficient over all the instances. An instance's silhouette coefficient is equal to:\n\n$$\\frac{(b-a)}{max(a,b)}$$\n\nwhere a is the mean distance to the other instances in the same cluster and b is the miean nearest cluster distance.","c8875d98":"#### Acknowledgements","a9429121":"## Importing Libraries ","b683e873":"The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion:\n\n\n$$\\sum\\limits_{i=0}^{n}\\min_{\\mu_{j}\\in C}(\\lVert x_i - \\mu_j \\rVert^2)$$\n \n","32efc574":"In our Dataset we have 112 female and 88 male samples, so female represantation is higher.","4b456d1b":"#### Targets","91af55da":"Data for customer segmentation was obtained through membership cards of supermaket mall. We have some basic data about customers such as Customer ID, age, gender, annual income and spending score.\n\nSpending Score is something we assign to the customer based on our defined parameters like customer behavior and purchasing data.\n\nIn this project we would like to identify the potential customer base for selling a new product. To do so we will be using Unsupervised Learning technique called KMeans Clustering. ","dddef9da":"### **Please upvote my kernel, if you like my work. It not only motivates me, but also makes me happy :)**","4f53644d":"From the description customers' ages are from 18 to 70, with average of 38 years. We have 200 samples in our dataset and 0 missing values.","d871fb5a":"In terms of Spending Score, both genders have a median of 50. Lower quartile for males is 23, 12 lower than q1 for females. It seems that females' spending score is slightly higer. \n\nObserving the scatter points for both genders we can see some gaps. We could devide customers into 3 groups into low (0-40), medium (40-60) and high Spending Score (>60).","9c72639b":"#### Clustering ","e046d848":"Default number of clusters in sklearn is set to 8. It is not an easy task to decide on optimal number of custers k and result can be quite bad if it's set to wrong number. ","e3be1ce8":"The source of data for this project is from Kaggle's [Mall Customer Segmentation Data]('https:\/\/www.kaggle.com\/vjchoudhary7\/customer-segmentation-tutorial-in-python\/kernels') dataset.\n\nLiterature:\n - A. Geron: Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow. O'Reilly, 2019, ISBN: 978-1-492-03264-9.\n - A.C Muller & S.Guido: Introduction to machine Learning with Python. O'Reilly, 2017, ISBN: 978-1-449-36941-5.","bda896d0":"KMeans clustering is one of the simplest and most commonly used clustering algorithms. It tries to find cluster centers that are representative of certain regions of the data. \n\nThe algorithm alternates between two steps:\n1. assigning each data point to the closest custer center,\n2. setting each cluster center as the mean of the data ponts that are assigned to it.\n\nThe algorithm is finished when the assignment of instances to clusters no longer changes.","da752bd0":"### Loading the Data","f223f545":"## KMeans Clustering ","6e1cc704":"As we can see this visualisation is much richer than the elbow method. It just confirms that 6 is a good choice for a number of clusters. It also underlines that k=5 is quite a good choice too and much better than k=4 or k=7.\n\nWe will choose k = 5 (in case we can see that we would benefit from higher or lower number of clusters, k can be replaced by 6 or 4)","016de85d":"# Customer Segmentation (K-Means Clustering)","bca23fa7":"#### Introduction ","35e1de5f":"Now, when we have decided on potential number of clusters let's jump into actual KMeans clustering.","ce0d56ec":"#### Selecting the number of clusters using internia","973ca19a":"Introducing a new product, we would like to target (send marketing materials) customers in clusters 1 and 3.\n\nCluster 3 has annual income similar to cluster 4 (between 15k - 40k). However, cluster 3 has high Spening Score.\nCluster 3 has high annual income similar to cluster 0, but again much higher Spending Score than 0.","7f882c61":"The inertia is not a good performance metric when trying to choose k because it keeps getting lower as we increase k. \nAs we can see, the inertia drops very quickly as we increase k up to 5, but then it decreases much more slowly as we keep increasing k. This curve has roughly the shape of an arm and we can consider point at k=5 to be an 'elbow'. It's not actually 100% clear what point the 'elbow' is. It can also be 4 or 6.\n\nSo 4,5 or 6 would be a good choice for number of clusters. Lower values would be dramatic and going for higher values would not be much help, as we might be splitting perfectly good clusters in half for no good reason.","1a5609f9":"Perhaps it's not a surprise that males have on average higher annual income than females. Just for a comparison the highest male annual income reaches 137k whilst highest female annual income is 126k whitch is 11k lower. ","7dd8265c":"Clustering is the task of partitioning the dataset into groups, called clusters. The goal is to split the data in such a way that points within a single cluster are very similar and points in different clusters are different. Clustering algorithms assign a number to each data point, indicating which cluster a particular point belongs to. ","a08e1c0f":"The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares. **This algorithm requires the number of clusters to be specified.** It scales well to large number of samples and has been used across a large range of application areas in many different fields.\n\nThe k-means algorithm divides a set of samples into disjoint clusters, each described by the mean of the samples in the cluster. The means are commonly called the cluster \u201ccentroids\u201d; note that they are not, in general, points from, although they live in the same space.\n","d544676d":"## Exploratory Data Analysis  ","d1c42c58":"#### Selecting the number of clusters using silhouette score","b4d0271c":"By the end of this project, we will:\n -  Know how to achieve customer segmentation using machine learning algorithm (KMeans Clustering) in Python in simplest way.\n -  Identify who are our target customers with whom we can start marketing strategy easy to converse","0df4e2f8":"### Clustering ","b6b9e561":"### What is the optimal number of clusters? "}}