{"cell_type":{"09045d2b":"code","36e91b5a":"code","edb3f0dd":"code","715dec30":"code","c6a0dbe2":"code","e7934d26":"code","8dbc806f":"code","fd6383f0":"code","032a147b":"code","33ebf2fc":"code","503436c3":"code","11e21324":"code","e326c9f5":"code","d87fbdb9":"code","0664b3da":"code","9920154d":"code","cb6f491e":"code","5cd25928":"code","3975650e":"code","3e9de1c2":"code","7d3865ea":"code","9b667ce9":"code","981b3653":"code","c342829f":"markdown","35ee6917":"markdown"},"source":{"09045d2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36e91b5a":"data = pd.read_csv(\"\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\ndata","edb3f0dd":"data['Gender'] = data['Gender'].map({'Female':1,'Male':0}).astype(int)","715dec30":"data.isnull().sum()\ndata.fillna(0)","c6a0dbe2":"x= data.drop(columns='CustomerID')\nx","e7934d26":"import seaborn as sns\nsns.heatmap(data.isnull())","8dbc806f":"x.dtypes","fd6383f0":"nom_col = [0]\nord_col = []","032a147b":"from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\nimport numpy as np\ntrans  = make_column_transformer((OneHotEncoder(sparse = False),nom_col),\n                                  (OrdinalEncoder(),ord_col),\n                                 remainder = 'passthrough')\nset_config(display = 'diagram')\ntrans","33ebf2fc":"from sklearn.cluster import KMeans\nkm = KMeans(n_clusters=2)\nkm","503436c3":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(trans,km)\npipe","11e21324":"pipe.fit(data)","e326c9f5":"#for k in K:\n   # km=KMeans(n_clusters=k).fit(data)\n    #km.fit(data)","d87fbdb9":"km.labels_","0664b3da":"km.cluster_centers_","9920154d":"km.n_iter_","cb6f491e":"from sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom scipy.spatial.distance import cdist\nimport numpy as np\nimport matplotlib.pyplot as plt","5cd25928":"distortions = []\ninertias = []\nmapping1 = {}\nmapping2 = {}\nK = range(1, 10)\n \nfor k in K:\n    # Building and fitting the model\n    kmeanModel = KMeans(n_clusters=k).fit(x)\n    kmeanModel.fit(x)\n \n    distortions.append(sum(np.min(cdist(x, kmeanModel.cluster_centers_,\n                                        'euclidean'), axis=1)) \/ x.shape[0])\n    inertias.append(kmeanModel.inertia_)\n \n    mapping1[k] = sum(np.min(cdist(x, kmeanModel.cluster_centers_,\n                                   'euclidean'), axis=1)) \/ x.shape[0]\n    mapping2[k] = kmeanModel.inertia_","3975650e":"for key, val in mapping1.items():\n    print(f'{key} : {val}')","3e9de1c2":"plt.plot(K, distortions, 'bx-')\nplt.xlabel('Values of K')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method using Distortion')\nplt.show()","7d3865ea":"for key, val in mapping2.items():\n    print(f'{key} : {val}')","9b667ce9":"plt.plot(K, inertias, 'bx-')\nplt.xlabel('Values of K')\nplt.ylabel('Inertia')\nplt.title('The Elbow Method using Inertia')\nplt.show()","981b3653":"import matplotlib.pyplot as plt\nplt.plot(x)","c342829f":"# DISTROTION","35ee6917":"# INERTIA"}}