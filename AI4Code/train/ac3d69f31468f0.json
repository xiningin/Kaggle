{"cell_type":{"230f961b":"code","26c700a0":"code","87d8105d":"code","646902f0":"code","411b6712":"code","eeda7e72":"code","ca82bfe3":"code","121a8030":"code","54bfe13c":"code","8333d648":"code","d5684b9d":"code","dcaaf415":"code","820ace74":"code","dcb56a95":"code","b86d8cb3":"code","651d6689":"code","4ed17de4":"code","693c3199":"code","0f5fad16":"code","59205ebb":"code","66676b9c":"code","1a197a16":"code","7c2fd1af":"code","9112666e":"markdown","e18f81a3":"markdown","8bd57221":"markdown","35afe4bd":"markdown","3c04b3a0":"markdown","4d44add1":"markdown","c2322f10":"markdown","7015304a":"markdown","d725aa22":"markdown"},"source":{"230f961b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport glob\nimport cv2\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import *\n\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom plotly.offline import iplot\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26c700a0":"train_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntrain_df.shape","87d8105d":"train_df.head()","646902f0":"train_df['target'].value_counts()","411b6712":"##checking for missing vals\ntrain_df.isnull().sum()","eeda7e72":"train_df.dropna(axis=0, subset=['sex'], inplace=True)\ntrain_df.dropna(axis = 0,subset=['age_approx'], inplace=True)\ntrain_df.dropna(axis=0, subset=['anatom_site_general_challenge'], inplace=True)\n\ntrain_df.isnull().sum()","ca82bfe3":"train_df.head()","121a8030":"plt.figure(figsize = (10,10))\ndata = train_df.benign_malignant.value_counts()\ndata.iplot(kind = 'bar', color='blue', title = 'Data Imbalance')","54bfe13c":"img = cv2.imread('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0015719.jpg')\nprint(img.shape)","8333d648":"##creating labels from target columns with corressponding images \ntrain_dir = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir = '..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\nlabels = []\ndata = []\nfor i in range(train_df.shape[0]):\n    data.append(train_dir + train_df['image_name'].iloc[i] + '.jpg')\n    labels.append(train_df['target'].iloc[i])\n\ndf = pd.DataFrame(data)\ndf.columns = ['images']\ndf['target'] = labels","d5684b9d":"test_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\ntest_data=[]\nfor i in range(test_df.shape[0]):\n    test_data.append(test_dir + test_df['image_name'].iloc[i]+'.jpg')\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']","dcaaf415":"groups_by_patient_id_list = train_df['patient_id'].copy().tolist()","820ace74":"skf = model_selection.StratifiedKFold(n_splits=10)\nylabels = train_df.target.values\nresult = []   \nfor train_idx, val_idx in skf.split(train_df, ylabels, groups = groups_by_patient_id_list):\n    train_fold = train_df.iloc[train_idx]\n    val_fold = train_df.iloc[val_idx]\n    result.append((train_fold, val_fold))","dcb56a95":"train_fold_1, val_fold_1 = result[0][0],result[0][1]\ntrain_fold_2, val_fold_2 = result[1][0],result[1][1]\ntrain_fold_3, val_fold_3 = result[2][0],result[2][1]\ntrain_fold_4, val_fold_4 = result[3][0],result[3][1]\ntrain_fold_5, val_fold_5 = result[4][0],result[4][1]\n\ntrain_fold_6, val_fold_6 = result[6][0],result[6][1]\ntrain_fold_7, val_fold_7 = result[7][0],result[7][1]\ntrain_fold_8, val_fold_8 = result[8][0],result[8][1]\ntrain_fold_9, val_fold_9 = result[9][0],result[9][1]","b86d8cb3":"## sanity checks\nsample = train_fold_1.groupby(\"patient_id\")\nsample.get_group(\"IP_0147446\")\nsample.get_group(\"IP_0147446\").count()","651d6689":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","4ed17de4":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n\n# Configuration\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nimage_size = 224\nEPOCHS = 3","693c3199":"def train_image_paths(img_name):\n    return GCS_PATH + '\/jpeg\/train\/' + img_name + '.jpg'\n\ndef test_image_paths(image_name):\n    return GCS_PATH + '\/jpeg\/test\/' + img_name + '.jpg'\n\n##applying this to folds data which we created\ntrain_path_fold_1 = train_fold_1.image_name.apply(train_image_paths).values\nval_path_fold_1 = val_fold_1.image_name.apply(train_image_paths).values\n\ntrain_path_fold_2 = train_fold_2.image_name.apply(train_image_paths).values\nval_path_fold_2 = val_fold_2.image_name.apply(train_image_paths).values\n\ntrain_path_fold_3 = train_fold_3.image_name.apply(train_image_paths).values\nval_path_fold_3 = val_fold_3.image_name.apply(train_image_paths).values\n\ntrain_path_fold_4 = train_fold_4.image_name.apply(train_image_paths).values\nval_path_fold_4 = val_fold_4.image_name.apply(train_image_paths).values\n\ntrain_path_fold_5 = train_fold_5.image_name.apply(train_image_paths).values\nval_path_fold_5 = val_fold_5.image_name.apply(train_image_paths).values\n\n\ntrain_labels_fold_1 = train_fold_1.target.values\nval_labels_fold_1 = val_fold_1.target.values","0f5fad16":"def decode_image(filename, label=None, image_size=(image_size,image_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, size = image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\n##augmenting the data\ndef augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n#     image = tf.image.random_saturation(image, lower = 1, upper = 3)\n#     image = tf.image.adjust_brightness(image, delta = 0.3)\n    image = tf.image.random_contrast(image, lower = 1, upper = 2)\n    if label is None:\n        return image\n    else:\n        return image, label","59205ebb":"train_fold_1","66676b9c":"sample_filename = 'gs:\/\/kds-5dd48bdf94d283b2157eff515b17b1a840a9133121124719ad41d5c4\/jpeg\/train\/ISIC_1102075.jpg' \nsample_label = 0\nimage_size = 224\n\n# 1. tf.io_read_file takes in a Tensor of type string and outputs a ensor of type string. \n#    Reads and outputs the entire contents of the input filename. \nbits = tf.io.read_file(sample_filename)\n\n# 2. Decode a JPEG-encoded image to a uint8 tensor. You can also use tf.io.decode_jpeg but according to \n#    tensorflow's website, it might be cleaner to use tf.image.decode_jpeg\nimage = tf.image.decode_jpeg(bits, channels=3)\n\nimage.shape  # outputs TensorShape([4000, 6000, 3])\n\n# 3. image = tf.cast(image, tf.float32) \/ 255.0 is easy to understand, it takes in \n#    an image, and cast the image into the data type you want. Here we also normalized by dividing by 255.\n\nimage = tf.cast(image, tf.float32) \/ 255.0\n\n\n# 4. image = tf.image.resize(image, image_size) is also easy to understand. We merely resize this image to the image_size we wish for.\n#    take note in our function defined above, the argument image_size is a tuple already. So we must pass in a tuple of our desired image_size.\nimage = tf.image.resize(image, size = (image_size, image_size))\n\nimage.shape","1a197a16":"# train_labels_fold_1 = train_fold_1.target.values\nsample_data = tf.data.Dataset.from_tensor_slices((train_path_fold_1, train_labels_fold_1))\nfor data in sample_data:\n    print(len(data))\n    print(data[0])\n    print(data[1])   \n    break","7c2fd1af":"dataset = tf.data.Dataset.from_tensor_slices((train_path_fold_1, train_labels_fold_1)).map(decode_image, num_parallel_calls=AUTO)\nfor data in dataset:\n    print(len(data))\n    print(data[0])\n    print(data[1])\n    break","9112666e":"## TPU\/GPU Initialization","e18f81a3":"**Let's check it out**","8bd57221":"## Stratified KFolds","35afe4bd":"## Preparing Dataset","3c04b3a0":"## Exploring Image ","4d44add1":"Next Step, I will be using [tf.data.Dataset](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/data\/Dataset)\n\nAccording to the tensorflow website: *The tf.data.Dataset* API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n\nCreate a source dataset from your input data.\nApply dataset transformations to preprocess the data.\nIterate over the dataset and process the elements.\nIteration happens in a streaming fashion, so the full dataset does not need to fit into memory.","c2322f10":"## Loading and Exploring Dataset","7015304a":"## Preparing Dataset\n- **Using decode_image function from tensorflow, we will generate labels, with the corresponding paths provided, it also will resize the image**","d725aa22":"**Creating functions that will take in an image name and return image path, this we will apply to the training and validation folds, that we have created**\n**Implementation courtesy of this awesome [kernel](https:\/\/www.kaggle.com\/reighns\/groupkfold-and-stratified-groupkfold-efficientnet\/comments)**"}}