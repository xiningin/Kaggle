{"cell_type":{"52e5508d":"code","2b4f46e3":"code","b9988637":"code","b2d971cf":"code","6feadd91":"code","b4201ce0":"code","cb3fa7d5":"code","37c6d94c":"code","689c018a":"code","f92a34b5":"code","9fffa402":"code","eae01925":"code","7707bc49":"code","4d4c5e03":"code","85f5de98":"code","e2e43dc7":"code","6ad67501":"code","34210bef":"code","e16dfab9":"code","fe2b90ad":"code","5dcc8dea":"code","624a1932":"code","7aa99982":"code","33a10e27":"code","a1119a6d":"code","abf1dd3c":"code","d3ff95ba":"code","4d3bc61d":"code","cc05cf03":"code","788beeb2":"code","1d305b6d":"code","c0d953b1":"code","d8833a9f":"code","10b9149e":"code","4da8b828":"code","8f11592e":"code","f8f94d44":"code","9edb95c9":"code","964532b6":"code","1a3252f2":"code","9f182f5f":"markdown","9a8f46fd":"markdown","7ca33736":"markdown","8de750c2":"markdown","9298cbec":"markdown","a0894c0b":"markdown","f992fe7b":"markdown","eac10f3d":"markdown","43c138c5":"markdown","098054fa":"markdown","a1c5db35":"markdown","40456d07":"markdown"},"source":{"52e5508d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport requests\nimport shapely\nimport matplotlib.pyplot as plot\n%matplotlib inline\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2b4f46e3":"travel_times = pd.read_csv('\/kaggle\/input\/uber-movement-data\/Travel_Times.csv')\ntravel_times_daily = pd.read_csv('\/kaggle\/input\/uber-movement-data\/Travel_Times_Daily.csv')\ntravel_times_day = pd.read_csv('\/kaggle\/input\/uber-movement-data\/Travel_Times_time_of_day.csv')\ntravel_times_week = pd.read_csv('\/kaggle\/input\/uber-movement-data\/Travel_Times_day_of_week.csv')\nbnglr_wards_hourly = pd.read_csv('\/kaggle\/input\/uber-movement-data\/bangalore-wards-2020-1-All-HourlyAggregate.csv')\nbnglr_wards_weekly = pd.read_csv('\/kaggle\/input\/uber-movement-data\/bangalore-wards-2020-1-WeeklyAggregate.csv')\nbnglr_wards_monthly = pd.read_csv('\/kaggle\/input\/uber-movement-data\/bangalore-wards-2020-1-All-MonthlyAggregate.csv')","b9988637":"bnglr_wards_hourly.head(2)","b2d971cf":"mean_travel_time_by_hour_of_day = bnglr_wards_hourly.groupby('hod')['mean_travel_time'].mean()\/60\nplt = mean_travel_time_by_hour_of_day.plot(kind=\"bar\", figsize=(16,7))\nplt.set_title('Mean travel times around Bangalore',fontsize=20)\nplt.set_xlabel('Hour of day', fontsize=16)\n_ = plt.set_ylabel('Mean travel time in mins', fontsize=16)","6feadd91":"std_dev_time_by_hour_of_day = bnglr_wards_hourly.groupby('hod')['standard_deviation_travel_time'].mean()\/60\nplt = std_dev_time_by_hour_of_day.plot(kind=\"bar\", figsize=(16,7))\nplt.set_title('Std Dev of travel times around Bangalore',fontsize=20)\nplt.set_xlabel('Hour of day', fontsize=16)\n_ = plt.set_ylabel('Std Dev of travel time in mins', fontsize=16)","b4201ce0":"bglr=gpd.read_file('\/kaggle\/input\/uber-movement-data\/bangalore_wards.json')\nbglr.plot()","cb3fa7d5":"bglr.head()","37c6d94c":"bglr = bglr.drop(columns=['WARD_NO', 'MOVEMENT_ID'])\nbglr_c = bglr.copy()\nbglr_c.geometry = bglr_c['geometry'].centroid\nfig, ax = plot.subplots(figsize=(9,9))\nbglr.plot(color='grey',ax=ax)\nbglr_c.plot(color='red',ax=ax)","689c018a":"id_to_dest = travel_times[['Destination Movement ID', 'Destination Display Name']]\nid_to_dest.columns = ['id', 'name']\nid_to_dest.head()\n","f92a34b5":"from shapely.geometry import Point\nimport random\n\n# The number of rows with random points to be created corresponding to each row in source df\nnumber = 3\n\ndef random_points_in_polygon(number, polygon):\n    points = []\n    min_x, min_y, max_x, max_y = polygon.bounds\n    i= 0\n    while i < number:\n        point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n        if polygon.contains(point):\n            points.append(point)\n            i += 1\n    return points\n\ndef diversify_geo_data(df):\n    new_df = gpd.GeoDataFrame()\n    common_columns = df.columns\n    common_columns.tolist().remove('geometry')\n    for row in df.itertuples():\n        points = random_points_in_polygon(number, row.geometry)\n        for point in points:\n            tmp = gpd.GeoDataFrame(columns=df.columns, data=[list(row[1:3]) + [point]])\n            new_df = new_df.append(tmp, ignore_index=True)\n    return new_df\n            \n\ndiversified_points = diversify_geo_data(bglr)\ndiversified_points.sample(5)","9fffa402":"diversified_points.shape","eae01925":"fig, ax = plot.subplots(figsize=(9,9))\nbglr.plot(color='grey',ax=ax)\ndiversified_points.plot(color='red',ax=ax)","7707bc49":"time_df = pd.merge(bnglr_wards_hourly, id_to_dest, left_on=['sourceid'], right_on=['id'], how='inner')\ntime_df = time_df.drop(columns=['id', 'geometric_mean_travel_time', 'geometric_standard_deviation_travel_time'])\ntime_df = time_df.rename(columns={'name': 'Source Name'})\ntime_df = pd.merge(time_df, id_to_dest, left_on=['dstid'], right_on=['id'], how='inner')\ntime_df = time_df.drop(columns=['id'])\ntime_df = time_df.rename(columns={'name': 'Destination Name'})\ntime_df = time_df.sort_values(by=['sourceid', 'dstid', 'hod'])\ntime_df.tail(5)","4d4c5e03":"bglr_c.shape","85f5de98":"diversified_points.shape","e2e43dc7":"full_bglr = bglr_c.append(diversified_points, ignore_index=True)\nfull_bglr.shape","6ad67501":"time_df2 = pd.merge(time_df, full_bglr, left_on=['Source Name'], right_on=['DISPLAY_NAME'], how='inner')\ntime_df2 = time_df2.drop(columns=['DISPLAY_NAME'])\ntime_df2 = time_df2.rename(columns = {'WARD_NAME': 'Source Ward Name', 'geometry': 'Source Geometry'})\ntime_df2 = pd.merge(time_df2, full_bglr, left_on=['Destination Name'], right_on=['DISPLAY_NAME'], how='inner')\ntime_df2 = time_df2.drop(columns=['DISPLAY_NAME'])\ntime_df2 = time_df2.rename(columns = {'WARD_NAME': 'Destination Ward Name', 'geometry': 'Destination Geometry'})\ntime_df2.sample(3)","34210bef":"time_df2.shape","e16dfab9":"import pickle\ndef save_object(obj, filename):\n    with open(filename, 'wb') as output:  # Overwrites any existing file.\n        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n\nimport os.path\ndef file_exists(filename):\n    return os.path.exists(filename)\n\ninput_path = '..\/input\/uber-travel-time-prediction\/'","fe2b90ad":"import geopy.distance\n\ndef calc_distance(x):\n    src_point = (x['Source Geometry'].y, x['Source Geometry'].x)\n    dest_point = (x['Destination Geometry'].y, x['Destination Geometry'].x)\n    return geopy.distance.geodesic(src_point, dest_point).kilometers\n\nfilename = 'Df_for_modelling.bin'\npath = input_path + filename\nif file_exists(path):\n    # skip to next section since the results here are already precalculated\n    pass\nelse:\n    print('Creating distance file')\n    time_df2['Geodesic Distance'] = time_df2.apply(func = calc_distance, axis=1)\n    df = time_df2\n","5dcc8dea":"filename = 'Df_for_modelling.bin'\npath = input_path + filename\nif file_exists(path):\n    with open(path, 'rb') as file:\n        final_df = pickle.load(file)\nelse:\n    print('Creating final df file')\n    final_df = df.copy()\n    final_df['Source lat'] = final_df['Source Geometry'].apply(lambda pt: float(pt.y))\n    final_df['Source long'] = final_df['Source Geometry'].apply(lambda pt: float(pt.x))\n    final_df['Dest lat'] = final_df['Destination Geometry'].apply(lambda pt: float(pt.y))\n    final_df['Dest long'] = final_df['Destination Geometry'].apply(lambda pt: float(pt.x))\n\n    \nfeatures = ['Source lat', 'Source long', 'Dest lat', 'Dest long', 'hod', 'Geodesic Distance']\noutcome = ['mean_travel_time']\nfinal_df = final_df[features + outcome]\n\ntry:\n    save_object(final_df, filename)\nexcept:\n    pass","624a1932":"\nX = final_df[features]\ny = final_df[outcome]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n","7aa99982":"\nimport xgboost as xgb\n\nfilename = 'XGB_model_5.bin'\npath = input_path + filename\nif file_exists(path):\n    with open(path, 'rb') as file:\n        my_model = pickle.load(file)\nelse:\n    my_model = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4, objective='reg:squarederror')\n    my_model.fit(X_train, y_train,verbose=False)\n    \ntry:    \n    save_object(X_train, 'train_set_x.bin')\n    save_object(y_train, 'train_set_y.bin')\n    save_object(X_test, 'test_set_x.bin')\n    save_object(y_test, 'test_set_y.bin')\n    save_object(my_model, filename)\nexcept:\n    pass","33a10e27":"xgb.plot_importance(my_model)","a1119a6d":"predictions = my_model.predict(X_test)\n\nfrom sklearn import metrics\n\nr2 = metrics.r2_score(y_test, predictions)\nprint('R2: {}\\n'.format(r2))\n\nmse = metrics.mean_squared_error(y_test, predictions)\nprint('MSE: {}\\n'.format(mse))\n\nprint('RMSE: {}\\n'.format(np.sqrt(mse)))\n\nmae = metrics.mean_absolute_error(y_test, predictions)\nprint('MAE: {}\\n'.format(mae))\n","abf1dd3c":"x_ax = range(len(y_test))\nplot.plot(x_ax, y_test, label=\"original\")\nplot.plot(x_ax, predictions, label=\"predicted\")\n\nplot.title(\"Mean travel times actual and predicted data\")\n\nplot.legend()\nplot.show()","d3ff95ba":"fig, ax = plot.subplots()\nax.scatter(y_test, predictions)\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\nax.set_xlabel('Measured Time')\nax.set_ylabel('Predicted Time')\nplot.show()","4d3bc61d":"from sklearn.model_selection import cross_val_score, KFold\n\nscore = my_model.score(X_train, y_train)  \nprint(\"Training score: \", score)\n\n# These take more than 9 hours to complete so skipped\n\n# scores = cross_val_score(my_model, X_train, y_train, cv=10)\n# print(\"Mean cross-validation score: %.2f\" % scores.mean())\n\n# kfold = KFold(n_splits=10, shuffle=True)\n# kf_cv_scores = cross_val_score(my_model, X_train, y_train, cv=kfold )\n# print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())","cc05cf03":"features = ['Source lat', 'Source long', 'Dest lat', 'Dest long', 'hod', 'Geodesic Distance']\noutcome = ['mean_travel_time']\n\ndef get_distance(lat1, long1, lat2, long2):\n    src_point = (lat1, long1)\n    dest_point = (lat2, long2)\n    return geopy.distance.geodesic(src_point, dest_point).kilometers\n\ndef prepare_df(lat1, long1, lat2, long2, hod):\n    distance = get_distance(lat1, long1, lat2, long2)\n    return pd.DataFrame(columns = ['Source lat', 'Source long', 'Dest lat', 'Dest long', 'hod', 'Geodesic Distance'],\n                 data = [[lat1, long1, lat2, long2, hod, distance]])\n    \ndef predict(df):\n    return my_model.predict(df[features])","788beeb2":"def compare(actual, predicted):\n#     actual = [act[0] for act in actual[outcome].values.tolist()]\n#     predicted = predicted.tolist()\n    return pd.DataFrame(data = {'actual': actual, 'prediction': predicted})\n","1d305b6d":"# entire bangalore geojson from https:\/\/github.com\/datameet\/PincodeBoundary\/tree\/master\/Bangalore\n\n# bangalore_polygon = gpd.read_file('..\/input\/external-geodata\/bangalore boundary.geojson')\n# bangalore_polygon.plot()","c0d953b1":"def get_random_points_in_bangalore(number):\n    points = []\n    min_x, min_y, max_x, max_y = 12.85, 77.45, 13.0, 77.75  \n    i= 0\n    while i < number:\n        point = (random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n        i += 1\n        points.append(point)\n    return points\n\n# ORS_API_KEY = '5b3ce3597851110001cf6248f4d0d79bab0a4f5a8b95a4403ba8b839'\n\n# def get_ORS_data(source, dest):\n#     parameters = {\n#         'locations' : [['{},{}'.format(source[1], source[0])],['{},{}'.format(dest[1], dest[0])]]\n#     }\n#     headers = {'Authorization ': ORS_API_KEY}\n#     response = requests.post(\n#         'https:\/\/api.openrouteservice.org\/v2\/matrix\/driving-car', data=parameters, headers=headers)\n\n#     if response.status_code == 200:\n#         print('Request successful.')\n#         data = response.json()\n#         summary = data['features'][0]['properties']['summary']\n#         print(summary)\n# #         distance = summary['distance']\/1000\n#         return duration\n#     else:\n#         print('Request failed.')\n#         print(response.text)","d8833a9f":"# get_ORS_data((12.928781971722811, 77.6121303701099), (12.854079170010449, 77.55145104575789))","10b9149e":"# points1 = get_random_points_in_bangalore(10)\n# points2 = get_random_points_in_bangalore(10)\n\n# travel_times_ORS = []\n# for point1, point2 in zip(points1, points2):\n#     travel_times_ORS.append(get_ORS_data(point1, point2))\n    \n# travel_times_model = []\n# for point1, point2 in zip(points1, points2):\n#     lat1, long1, lat2, long2 = point1[0], point1[1], point2[0], point2[1]\n#     hod = random.uniform(0, 23)\n#     p = predict(prepare_df(lat1, long1, lat2, long2, hod))\n#     p = p.tolist()[0]\n#     travel_times_model.append(p)\n    \n# print({points: time for points, time in zip(zip(points1, points2), travel_times_model)})\n# compare(travel_times_ORS, travel_times_model)","4da8b828":"points = [((12.999289603200602, 77.72750046509455),\n  (12.900586869608652, 77.57751972070913)),\n ((12.935917259525278, 77.61353555551875),\n  (12.856440148061886, 77.48546536718554)),\n ((12.897459477917653, 77.7095308106631),\n  (12.996842230621631, 77.64938231715406)),\n ((12.936661694778596, 77.71873838420447),\n  (12.907286088453898, 77.4772158363428)),\n ((12.88453533783865, 77.70914845848147),\n  (12.893719016027402, 77.71748845762684)),\n ((12.90661849980788, 77.6359030720415),\n  (12.986913454190185, 77.6667791482254)),\n ((12.89600641097292, 77.70444731327966),\n  (12.98987526206819, 77.60524558740501)),\n ((12.897523292566822, 77.56067149766076),\n  (12.894608188894253, 77.66337661025209)),\n ((12.86194623889842, 77.56338966329798),\n  (12.944443289052925, 77.4887976744094)),\n ((12.858621405573748, 77.46556646993612),\n  (12.90990445061544, 77.58937083560666))]\n\nhours_of_day = [18, 7, 18, 2, 16, 23, 10, 8, 4, 16]","8f11592e":"# taking average of thetime bounds given by manual google maps travel times for same coordinates and departure time\ntravel_times_gmaps_in_mins = [75, 55, 43, 63, 7, 45, 60, 50, 40, 50]\ntravel_times_gmaps = [t*60 for t in travel_times_gmaps_in_mins]","f8f94d44":"travel_times_model = []\npoints1 = [p[0] for p in points]\npoints2 = [p[1] for p in points]\nfor point1, point2, hod in zip(points1, points2, hours_of_day):\n    lat1, long1, lat2, long2 = point1[0], point1[1], point2[0], point2[1]\n    p = predict(prepare_df(lat1, long1, lat2, long2, hod))\n    p = p.tolist()[0]\n    travel_times_model.append(p)\n[t\/60 for t in travel_times_model]","9edb95c9":"compare(travel_times_gmaps, travel_times_model)","964532b6":"x_ax = range(len(travel_times_model))\nplot.plot(x_ax, travel_times_gmaps, label=\"original\")\nplot.plot(x_ax, travel_times_model, label=\"predicted\")\n\nplot.title(\"Mean travel times actual and predicted data\")\n\nplot.legend()\nplot.show()","1a3252f2":"lat1 = 13.002385\nlong1 = 77.568491\nlat2 = 13.061071\nlong2 = 77.597371\nhod = 10\n\ndf = prepare_df(lat1, long1, lat2, long2, hod)\npredict(df)","9f182f5f":"# Cleaning up data for analysis\n\nGot source and destination data and removed unneeded columns like geometric_mean_travel_time and geometric_standard_deviation_travel_time.","9a8f46fd":"Note: the travel time is in seconds, so as we see below, the error is pretty low.","7ca33736":"Model without eval set\n","8de750c2":"# Get some random points from each ward to diversify representation","9298cbec":"# Live testing","a0894c0b":"# The ward data","f992fe7b":"# Testing with some random points","eac10f3d":"# Picking centroids to represent an area","43c138c5":"# Modelling","098054fa":"We'll consider the hourly travel time average for modelling.","a1c5db35":"# Reading Inputs\n\nHere, we consider Bangalore travel time data for January 2020 to March 2020.","40456d07":"# Calculating distances to use as a feature"}}