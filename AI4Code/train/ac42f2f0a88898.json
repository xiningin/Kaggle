{"cell_type":{"87dd9439":"code","f0ea7c77":"code","defceb89":"code","dca9eab4":"code","62ce082e":"code","cc7291b4":"code","a2631e02":"code","5e1c0fc5":"code","69b7798d":"code","82c176f6":"code","844a548e":"code","f55a14ba":"code","877435de":"code","30eb590d":"code","b471a17f":"code","6ec6e042":"markdown","60eaa8c0":"markdown","5fd1ab7b":"markdown","941a8127":"markdown","371fe2af":"markdown","6a9e32d4":"markdown","735c4a1d":"markdown","5e10230b":"markdown","82cb31e6":"markdown"},"source":{"87dd9439":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f0ea7c77":"dataset = pd.read_csv(\"..\/input\/cleveland-heart-disease-data-csv\/Cleveland Heart Disease Data.csv\")\ndataset.head()","defceb89":"dataset.describe()","dca9eab4":"y = dataset['num']\nX = dataset.drop('num', axis = 1)\nX.shape","62ce082e":"y.shape","cc7291b4":"from sklearn.model_selection import train_test_split\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n#Checking if it worked\nprint(X_train_full.shape)\nprint(X_test.shape)\nprint(y_train_full.shape)\nprint(y_test.shape)","a2631e02":"# Creating some valid sets\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 0)\n\nprint(X_train.shape)\nprint(X_valid.shape)\nprint(y_train.shape)\nprint(y_valid.shape)","5e1c0fc5":"X_train.dtypes","69b7798d":"numerical_columns = ['Age', 'trestbps','chol', 'thalach','oldpeak'] \ncategorical_columns = ['Sex','CP','fbs','restecg','exang','slope','ca','thal']\n\ncols_with_missing_train = [col for col in X_train.columns if X_train[col].isnull().any()]\nprint(cols_with_missing_train)\ncols_with_missing_valid = [col for col in X_valid.columns if X_valid[col].isnull().any()]\nprint(cols_with_missing_valid)","82c176f6":"for column in categorical_columns:\n    print(X_train[column].value_counts())","844a548e":"X_train.ca.replace(\"?\", np.NaN).value_counts()","f55a14ba":"X_train.thal.replace(\"?\", np.NaN).value_counts()","877435de":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n#pipelines!\n#creating a transformers for categories\nnumerical_transformer = SimpleImputer(strategy='constant')\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),\n        ('cat', categorical_transformer, categorical_columns)\n    ])","30eb590d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\ndef get_score(n_estimators):\n    my_pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', RandomForestRegressor(n_estimators, random_state=0))\n        ])\n    my_pipeline.fit(X_train, y_train)\n    preds_valid = my_pipeline.predict(X_valid)\n    scores = mean_absolute_error(y_valid, preds_valid)\n    return scores\n\nMAE = {}\n\nfor num_leaves in range(100,151):\n    MAE[num_leaves] = get_score(num_leaves)\n    \nMAE\n","b471a17f":"my_pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', RandomForestRegressor(131, random_state=0))\n        ])\nmy_pipeline.fit(X_train, y_train)\n\n#Applying that to the test model. I actually have a y-value for test too.\npreds_test = my_pipeline.predict(X_test)\nscore_test = mean_absolute_error(y_test, preds_test)\nprint(\"MAE:\", score_test)\n\n# Save test predictions to file\noutput = pd.DataFrame({'num': preds_test})\noutput.to_csv('submission.csv', index=False)","6ec6e042":"It looks like pandas looks at most of the the variables as int64 or float64. So I'm going to have to manually tell it which features are categorical and which ones are numerical. As I understand it, my differentiation should be like thus:\n\nCategorical:\n* Sex\n* CP\n* fbs\n* restecg\n* exang\n* slope\n* ca\n* thal\n\nNumerical:\n* Age\n* trestbps\n* chol\n* thalach\n* oldpeak","60eaa8c0":"It appears that the ideal number of leaves is 131, based on MAE.","5fd1ab7b":"Training on the Random Forest Regressor","941a8127":"I'm going to replace the ?s with NaNs. And then use simple imputing to fill missing values.","371fe2af":"Next, it's time to split the dataset using the test train split. And then, turn the train data into valid data as well.","6a9e32d4":"The documentation on the website seems to make it pretty apparent which variables are numerical and which ones are categorical. I assume that because the file was already processed, there are no missing values and generally pretty good. Nonetheless, a cursory glance at the uniques will do well. \n\nSo, first, I'm going to remove \"num\" from the dataset, since that's the y variable.","735c4a1d":"Lots of people on Kaggle have worked with this heart disease dataset it seems. Here are the links.\n\nhttps:\/\/www.kaggle.com\/ronitf\/heart-disease-uci\nhttp:\/\/archive.ics.uci.edu\/ml\/datasets\/Heart+Disease","5e10230b":"It looks like there are no missing values. But that's not exactly true.","82cb31e6":"So far so good. Here's the documentation on all the variables. Might be useful in trying to understand what's going on, over here.\n\nVariables:\n* age: Age in years\n* sex: sex (1 = male; 0 = female)\n* cp: chest pain type\n    - Value 1: typical angina\n    - Value 2: atypical angina\n    - Value 3: non-anginal pain\n    - Value 4: asymptomatic\n* trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n* chol: serum cholestoral in mg\/dl\n* fbs: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* restecg: resting electrocardiographic results\n    - Value 0: normal\n    - Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach: maximum heart rate achieved\n* exang: exercise induced angina (1 = yes; 0 = no)\n* oldpeak = ST depression induced by exercise relative to rest\n* slope: the slope of the peak exercise ST segment\n    - Value 1: upsloping\n    - Value 2: flat\n    - Value 3: downsloping\n* ca: number of major vessels (0-3) colored by flourosopy\n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n* num: diagnosis of heart disease (angiographic disease status) (the predicted attribute)\n    - Value 0: < 50% diameter narrowing\n    - Value 1: > 50% diameter narrowing"}}