{"cell_type":{"c22f8d29":"code","9963e9a4":"code","0c5c21e7":"code","e24d2d68":"code","91348f38":"code","9ebc6fd2":"code","40f570bb":"code","bdf01715":"code","9a64ed6c":"code","7a5995d3":"code","4438899b":"code","922bd3c4":"code","43e59330":"code","c90c3c83":"code","391b5597":"code","1a9c7019":"code","65ba9ef4":"code","a925e654":"code","f802d2ca":"code","7af32e8c":"code","597360ce":"code","d309e69f":"code","d2aecc34":"code","62ae771b":"code","161ddf63":"code","da09eb9b":"code","6d5e9cc0":"code","69aec68e":"code","35a73d9f":"code","c4d3a6e5":"code","e29766e7":"code","048ce990":"code","13fd6ea8":"code","d18825be":"code","18afad77":"code","40e1efc7":"code","57741928":"code","ed4ff778":"code","a5b2c698":"code","c8b9f604":"code","12cc145a":"code","50f539f3":"code","4e0b9f18":"code","1a1110ac":"code","acc80096":"code","7968ffab":"code","9fac63e0":"code","67760f0a":"code","960e47f2":"code","bbc83b88":"code","c9a9a61e":"code","04d700ee":"markdown","a5bfeb67":"markdown","f4d2e4a9":"markdown","32e70525":"markdown","cb14ecd2":"markdown"},"source":{"c22f8d29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport umap\nfrom PIL import Image\nfrom scipy import misc\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nfrom scipy import misc\nfrom random import shuffle\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.utils.np_utils import to_categorical\n","9963e9a4":"os.chdir('..\/input\/utkface_aligned_cropped')","0c5c21e7":"#os.listdir()\n#os.chdir('input')\nos.listdir()","e24d2d68":"os.chdir('crop_part1')\nos.listdir()[:5]","91348f38":"im =Image.open('27_0_1_20170102233552626.jpg.chip.jpg').resize((128,128))\nim","9ebc6fd2":"onlyfiles = os.listdir()","40f570bb":"len(onlyfiles)\n\n#Enable Asian only\nasian = []\nfor name in onlyfiles:\n    race = name.split('_')[2]\n    if race == '2':\n        asian.append(name)\nonlyfiles = asian","bdf01715":"shuffle(onlyfiles)\nage = [i.split('_')[0] for i in onlyfiles]","9a64ed6c":"class_label = ['17-','18-24','25-34','35-44','45-60','60+']\n\n\n# classes = []\n# for i in age:\n#     i = int(i)\n#     if i <= 17:\n#         classes.append(0)\n#     if (i>17) and (i<=24):\n#         classes.append(1)\n#     if (i>25) and (i<34):\n#         classes.append(2)\n#     if (i>=45) and (i<60):\n#         classes.append(3)\n#     if i>=60:\n#         classes.append(4)\n\n\nclasses = []\nY_age = []\nfor i in age:\n    i = int(i)\n    if i <= 17:\n        classes.append(0)\n    elif (i>17) and (i<=24):\n        classes.append(1)\n    elif (i>24) and (i<=34):\n        classes.append(2)\n    elif (i>34) and (i<=44):\n        classes.append(3)\n    elif (i>44) and (i<=60):\n        classes.append(4)\n    elif i>60:\n        classes.append(5)\n    Y_age.append(i)","7a5995d3":"# X_data =[]\n# for file in onlyfiles:\n#     face = misc.imread(file)\n#     face =cv2.resize(face, (32, 32) )\n#     X_data.append(face)\n\n# This way is faster than the original one\ndef convertImage(filename):\n    face = misc.imread(filename)\n    face = cv2.resize(face, (32, 32))\n    return face \nX_data = list(map(convertImage, onlyfiles))\n","4438899b":"X = np.squeeze(X_data)\n","922bd3c4":"X.shape","43e59330":"# normalize data\nX = X.astype('float32')\nX \/= 255\n","c90c3c83":"classes[:10]\n","391b5597":"categorical_labels = to_categorical(classes, num_classes=6)\n","1a9c7019":"categorical_labels","65ba9ef4":"categorical_labels[:10]\n","a925e654":"len(X)","f802d2ca":"(x_train, y_train, y_train_age), (x_test, y_test, y_test_age) = (X[:1100],categorical_labels[:1100], Y_age[:1100]) , (X[1100:] , categorical_labels[1100:], Y_age[1100:])\n#(x_valid , y_valid) = (x_test[1000:], y_test[1000:])\n#(x_test, y_test) = (x_test[:1000], y_test[:1000])\n","7af32e8c":"len(x_train)+len(x_test)  == len(X)\n","597360ce":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, classification_report","d309e69f":"\ncv2.cvtColor(x_train[0], cv2.COLOR_BGR2GRAY).shape","d2aecc34":"x_train_temp = np.array([cv2.cvtColor(x_t, cv2.COLOR_BGR2GRAY).flatten() for x_t in x_train]) \nx_train_temp.shape","62ae771b":"x_train_df = pd.DataFrame(x_train_temp)\nx_train_df","161ddf63":"def plot_faces(pixels):\n    fig, axes = plt.subplots(5, 5, figsize=(6, 6))\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(np.array(pixels)[i].reshape(32, 32), cmap='gray')\n    plt.show()\n# for x_t in x_train_temp:\n#     plot_faces(x_t)\n#     break\nplot_faces(x_train_df)","da09eb9b":"pca = PCA().fit(x_train_df)\nplt.figure(figsize=(18, 7))\nplt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)","6d5e9cc0":"representPercesntage = 0.999 # This significantly affects accuracy\n#representPercesntage = 0.8\nnp.where(pca.explained_variance_ratio_.cumsum() > representPercesntage)[0][0:10]","69aec68e":"n_com = np.where(pca.explained_variance_ratio_.cumsum() > representPercesntage)[0][0]","35a73d9f":"pca = PCA(n_components=n_com).fit(x_train_df)","c4d3a6e5":"x_train_pca = pca.transform(x_train_df)","e29766e7":"x_train_pca.shape","048ce990":"y_train_sklearn = np.array([np.where(yt == 1)[0][0] for yt in y_train])","13fd6ea8":"y_train_sklearn","d18825be":"classifier = SVC().fit(x_train_pca,y_train_sklearn)","18afad77":"predictions = classifier.predict(x_train_pca)\ntarget_names = [str(l) for l in range(6)]\nprint(classification_report(y_train_sklearn, predictions, target_names=target_names))","40e1efc7":"TruePrediction = 0\nfor i in range(len(predictions)):\n    if predictions[i] == y_train_sklearn[i]:\n        TruePrediction += 1\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")","57741928":"# Preprocessing pipeline\nx_test_temp = np.array([cv2.cvtColor(x_t, cv2.COLOR_BGR2GRAY).flatten() for x_t in x_test]) \nx_test_df = pd.DataFrame(x_test_temp)\nx_test_pca = pca.transform(x_test_df)\n\npredictions = classifier.predict(x_test_pca)\n\ny_test_sklearn = np.array([np.where(yt == 1)[0][0] for yt in y_test])\n\nprint(classification_report(y_test_sklearn, predictions))","ed4ff778":"TruePrediction = 0\nloss = 0\nN = len(predictions)\nfor i in range(len(predictions)):\n    if predictions[i] == y_test_sklearn[i]:\n        TruePrediction += 1\n    else:\n        loss += (y_test_sklearn[i] - predictions[i])**2\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")\nprint(f\"Loss: {(loss\/N)**0.5}\")","a5b2c698":"labels = class_label\n\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","c8b9f604":"#SVC linear\n\nclassifier = SVC(kernel = 'linear').fit(x_train_pca,y_train_sklearn)\n# Preprocessing pipeline\nx_test_temp = np.array([cv2.cvtColor(x_t, cv2.COLOR_BGR2GRAY).flatten() for x_t in x_test]) \nx_test_df = pd.DataFrame(x_test_temp)\nx_test_pca = pca.transform(x_test_df)\n\npredictions = classifier.predict(x_test_pca)\n\ny_test_sklearn = np.array([np.where(yt == 1)[0][0] for yt in y_test])\n\nprint(classification_report(y_test_sklearn, predictions))\n\nTruePrediction = 0\nloss = 0\nN = len(predictions)\nfor i in range(N):\n    if predictions[i] == y_test_sklearn[i]:\n        TruePrediction += 1\n    else:\n        loss += (y_test_sklearn[i] - predictions[i])**2\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")\nprint(f\"Loss: {(loss\/N)**0.5}\")\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","12cc145a":"#SVC poly\n\nclassifier = SVC(kernel = 'poly', gamma='auto', class_weight='balanced').fit(x_train_pca,y_train_sklearn)\n# Preprocessing pipeline\nx_test_temp = np.array([cv2.cvtColor(x_t, cv2.COLOR_BGR2GRAY).flatten() for x_t in x_test]) \nx_test_df = pd.DataFrame(x_test_temp)\nx_test_pca = pca.transform(x_test_df)\n\npredictions = classifier.predict(x_test_pca)\n\ny_test_sklearn = np.array([np.where(yt == 1)[0][0] for yt in y_test])\n\nprint(classification_report(y_test_sklearn, predictions))\n\nTruePrediction = 0\nloss = 0\nN = len(predictions)\nfor i in range(N):\n    if predictions[i] == y_test_sklearn[i]:\n        TruePrediction += 1\n    else:\n        loss += (y_test_sklearn[i] - predictions[i])**2\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")\nprint(f\"Loss: {(loss\/N)**0.5}\")\n\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","50f539f3":"from sklearn.cluster import KMeans\nimport numpy as np\n\nkmeans = KMeans(n_clusters=6, random_state=2).fit(x_train_pca)\nkmeans.labels_\n","4e0b9f18":"results = {\n    i:[] for i in range(6)\n}\n\ncolors = ['r','g','b','y','m','c']\nfor i in range(len(x_train_pca)):\n    pc1, pc2 = x_train_pca[i][0:2]\n    label = kmeans.labels_[i]\n    results[label].append(y_train_sklearn[i])\n    plt.scatter(pc1, pc2, c= colors[label],\n            s=50, cmap='viridis');\n    ","1a1110ac":"from collections import Counter\nsumCounter = Counter()\nfor k,v in results.items():\n    print(f\"Label {k}\")\n    print(Counter(v))\n    sumCounter += Counter(v)","acc80096":"sumCounter","7968ffab":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(x_train_pca, y_train_age)\nreg.score(x_train_pca, y_train_age)\n\npredictions = reg.predict(x_train_pca)\n\naccuracy = 0\nfor i in range(len(predictions)):\n    print(f\"Prediction: {predictions[i]}\")\n    print(f\"Real: {y_train_age[i]}\")\n    \n    if predictions[i] <= 17:\n        Class = 0\n    elif (predictions[i]>17) and (predictions[i]<=24):\n        Class = 1\n    elif (predictions[i]>24) and (predictions[i]<=34):\n        Class = 2\n    elif (predictions[i]>34) and (predictions[i]<=44):\n        Class = 3\n    elif (predictions[i]>44) and (predictions[i]<=60):\n        Class = 4\n    elif predictions[i]>60:\n        Class = 5\n    if Class == y_train_sklearn[i]:\n        accuracy += 1\naccuracy \/= len(predictions)\nprint(f\"Train accuracy {accuracy}\")\n\npredictions = reg.predict(x_test_pca)\npredictions_class = []\naccuracy = 0\nfor i in range(len(predictions)):\n    print(f\"Prediction: {predictions[i]}\")\n    print(f\"Real: {y_test_age[i]}\")\n    \n    if predictions[i] <= 17:\n        Class = 0\n    elif (predictions[i]>17) and (predictions[i]<=24):\n        Class = 1\n    elif (predictions[i]>24) and (predictions[i]<=34):\n        Class = 2\n    elif (predictions[i]>34) and (predictions[i]<=44):\n        Class = 3\n    elif (predictions[i]>44) and (predictions[i]<=60):\n        Class = 4\n    elif predictions[i]>60:\n        Class = 5\n    if Class == y_test_sklearn[i]:\n        accuracy += 1\n    predictions_class.append(Class)\naccuracy \/= len(predictions)\nprint(f\"Test accuracy {accuracy}\")","9fac63e0":"# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions_class[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","67760f0a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification","960e47f2":"clf = RandomForestClassifier(max_depth=100, random_state=100)\nclf.fit(x_train_pca, y_train_sklearn)","bbc83b88":"predictions = clf.predict(x_train_pca)\nprint(classification_report(y_train_sklearn, predictions))\n\nTruePrediction = 0\nloss = 0\nN = len(predictions)\nfor i in range(N):\n    if predictions[i] == y_train_sklearn[i]:\n        TruePrediction += 1\n    else:\n        loss += (y_train_sklearn[i] - predictions[i])**2\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")\nprint(f\"Loss: {(loss\/N)**0.5}\")\n\npredictions = clf.predict(x_test_pca)\nprint(classification_report(y_test_sklearn, predictions))\n\n\nTruePrediction = 0\nloss = 0\nN = len(predictions)\nfor i in range(N):\n    if predictions[i] == y_test_sklearn[i]:\n        TruePrediction += 1\n    else:\n        loss += (y_test_sklearn[i] - predictions[i])**2\nprint(f\"Accuracy: {TruePrediction\/len(predictions)}\")\nprint(f\"Loss: {(loss\/N)**0.5}\")\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","c9a9a61e":"# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = predictions[index]\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()","04d700ee":"## Linear Regression","a5bfeb67":"## Test Data","f4d2e4a9":"**CONVERT IMAGES TO VECTORS**","32e70525":"## Eigenface encoder\n\nidea from https:\/\/towardsdatascience.com\/eigenfaces-face-classification-in-python-7b8d2af3d3ea","cb14ecd2":"We can split the data into Classes\n* Children (1-14) CLASS 0\n* Youth (14-25) CLASS 1\n*  ADULTS (25-40) CLASS 2\n*  Middle age (40-60) CLASS 3\n*  Very Old (>60) CLASS 4"}}