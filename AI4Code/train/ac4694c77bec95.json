{"cell_type":{"df662a79":"code","9ab47402":"code","7a300260":"code","0f538150":"code","382308a8":"code","61c09af2":"code","b8929f13":"code","0a3a11e8":"code","8251117b":"code","28b6178e":"code","f42768e0":"code","09cfcc40":"code","45c05969":"code","bf91fa16":"markdown","ed887f4e":"markdown","8203ad5d":"markdown","901afcd3":"markdown","14423024":"markdown"},"source":{"df662a79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ab47402":"#let's see the artists\nartists = pd.read_csv('..\/input\/best-artworks-of-all-time\/artists.csv')\nartists.head()","7a300260":"#Processing Data\nartists = artists.sort_values(by=['paintings'], ascending=False)\n#consider only painter with at least 200 paintings\nartists_top = artists[artists['paintings'] >= 200]\nartists_top = artists_top[['name', 'paintings']]\n\nprint(artists_top)\n\n#Correct error Durer\nupdated_name = \"Albrecht_Du\u0308rer\".replace(\"_\", \" \")\nartists_top.iloc[4, 0] = updated_name","0f538150":"#print some paintings\nimages_dir = '..\/input\/best-artworks-of-all-time\/images\/images'\nartists_dirs = os.listdir(images_dir)\nartists_top_name = artists_top['name'].str.replace(' ', '_').values\nn= 10\nfig, axes = plt.subplots(1, n, figsize=(20,20))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top['name'].str.replace(' ', '_').values)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n    image = plt.imread(random_image_file)\n    axes[i].imshow(image)\n    axes[i].set_title(\"Artist: \" + random_artist.replace('_', ' '))\n    axes[i].axis('off')\n\nplt.show()","382308a8":"#to train the classificator tried to use ResNet50, an already trained neaural network\n## https:\/\/www.kaggle.com\/suniliitb96\/tutorial-keras-transfer-learning-with-resnet50\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_input_shape = (224, 224, 3)","61c09af2":"\n#this has to be low so less memory is used\n## The kaggle kernel memory was filling and the training stopped everytime, reduced batch size to 5\nbatch_size = 8\ngener = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1.\/255.,\n                                   rotation_range=30,\n                                   shear_range=5,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                  )\n\n#this creates random images to check the training accuracy\ntrain_generator = gener.flow_from_directory(directory=images_dir,class_mode='categorical',target_size=(224,224),\n                                                    batch_size=batch_size,subset=\"training\",shuffle=True,classes=artists_top_name.tolist()\n                                                   )\n\n#this creates random images to check the validation accuracy \nvalid_generator = gener.flow_from_directory(directory=images_dir, class_mode='categorical', target_size=(224,224), batch_size=batch_size,\n                                                    subset=\"validation\", shuffle=True, classes=artists_top_name.tolist()\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\n\nimage_dir = \"\/kaggle\/input\/best-artworks-of-all-time\/images\/images\/Peter_Paul_Rubens\/Peter_Paul_Rubens_141.jpg\"\nimage = plt.imread(image_dir)\nimage_transf = gener.random_transform(image)\nfig, axes = plt.subplots(1, 2, figsize=(15,5))\naxes[0].imshow(image)\naxes[1].imshow(image_transf)\nplt.show()","b8929f13":"# Prediction\nfrom keras.preprocessing import *\n\n#function to view the results of some random painting recognition\ndef testPaintings(model, numberofimg):\n    fig, axes = plt.subplots(1, numberofimg, figsize=(20,20))\n\n    for i in range(numberofimg):\n        random_artist = random.choice(artists_top_name)\n        random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n        random_image_file = os.path.join(images_dir, random_artist, random_image)\n\n        # Original image\n\n        test_image = image.load_img(random_image_file, target_size=(train_input_shape))\n\n        # Predict artist\n        test_image = image.img_to_array(test_image)\n        test_image = test_image\/\/255\n        test_image = np.expand_dims(test_image, axis=0)\n\n        prediction = model.predict(test_image)\n        prediction_probability = np.amax(prediction)\n        prediction_idx = np.argmax(prediction)\n\n        labels = train_generator.class_indices\n        labels = dict((v,k) for k,v in labels.items())\n\n        title = \"Actual artist = \" + str(random_artist) + \"\\nPredicted artist = \" + str(labels[prediction_idx]) + \"\\nPrediction probability = \" +  str(prediction_probability*100)\n\n        # Print image\n        axes[i].imshow(plt.imread(random_image_file))\n        axes[i].set_title(title)\n        axes[i].axis('off')\n\n        plt.show()\n    \n        labels = train_generator.class_indices\n        labels = dict((v,k) for k,v in labels.items())\n\n        title = \"Actual artist = \" + str(random_artist) + \"\\nPredicted artist = \" + str(labels[prediction_idx]) + \"\\nPrediction probability = \" +  str(prediction_probability*100)\n\n        # Print image\n        axes[i].imshow(plt.imread(random_image_file))\n    return\n","0a3a11e8":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n#base_model.summary()","8251117b":"# Add layers at the end\nX = base_model.output\nX = Flatten()(X)\n\nX = Dense(512, kernel_initializer='he_uniform')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dense(16, kernel_initializer='he_uniform')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\nn_classes = artists_top.shape[0]\n\noutput = Dense(n_classes, activation='softmax')(X)\n\nmodel = Model(inputs=base_model.input, outputs=output)\n\nmodel.summary()","28b6178e":"for layer in model.layers:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n","f42768e0":"#number of training epochs\nn_epoch = 10\n\n\n# Train the model - all layers\n# https:\/\/keras.io\/models\/sequential\/\n# fit_generator trains the model on data generated by a Python generator that runs in parallel\nresults= model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,epochs=n_epoch,shuffle=True,verbose=1,use_multiprocessing=True,workers=1,)\n\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n\n#TO LOAD THE MODEL\n#json_file = open('model.json', 'r')\n#loaded_model_json = json_file.read()\n#json_file.close()\n#loaded_model = model_from_json(loaded_model_json)\n# load weights into new model\n#loaded_model.load_weights(\"model.h5\")\n#print(\"Loaded model from disk\")\n","09cfcc40":"#see accuracy changes\n\nacc = results.history['accuracy']\nval_acc = results.history['val_accuracy']\nloss = results.history['loss']\nval_loss = results.history['val_loss']\nepoche = range(len(acc))\n\nfig, axes = plt.subplots(1, 2, figsize=(15,5))\n\naxes[0].plot(epoche, acc, 'r-', label='Training Accuracy')\naxes[0].plot(epoche, val_acc, 'b--', label='Validation Accuracy')\naxes[0].set_title('Training and Validation Accuracy')\naxes[0].legend(loc='best')\n\naxes[1].plot(epoche, loss, 'r-', label='Training Loss')\naxes[1].plot(epoche, val_loss, 'b--', label='Validation Loss')\naxes[1].set_title('Training and Validation Loss')\naxes[1].legend(loc='best')\n\nplt.show()","45c05969":"#check the accuracy on some paintings (of dataset)\ntestPaintings(model, 5)","bf91fa16":"## Load pre-trained model of ResNet50 and add some layers","ed887f4e":"## Function for image visualization and classification\n","8203ad5d":"## Data visualization","901afcd3":"## Image Generator for Dataset Augmentation\n","14423024":"## Train Model of ResNet"}}