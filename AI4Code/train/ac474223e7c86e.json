{"cell_type":{"76588695":"code","6a22b83f":"code","42101745":"code","fd5fb1a3":"code","2b8fd512":"code","c8f0afa3":"code","7a3fcd35":"code","8418d545":"code","ef977800":"code","0196715b":"code","a52379e1":"code","df31944b":"code","e533d467":"code","5f379c85":"code","0dd13fa4":"code","8409b613":"code","82a42e0d":"code","517b6c9c":"code","8869845b":"code","91e0dbe5":"code","4ed3677c":"code","b6c2610a":"code","0d1a3284":"code","699afc4a":"code","646cf777":"code","1e5a226b":"code","574fda2d":"code","69d6fa4a":"code","c6914388":"code","195801a2":"code","61be8fab":"code","47758443":"code","8c40e887":"code","06b801a2":"code","aed91576":"code","f1b4f3e9":"code","e0815c85":"code","f4c5f533":"code","89746473":"code","e52fec6a":"code","802b3831":"code","3a301e09":"code","df66def3":"code","eafea232":"code","dccefc6f":"code","8278be3b":"code","e021a420":"code","f7593273":"code","e873a86d":"code","99cab57a":"code","c831c870":"code","be1a16e1":"code","49955399":"code","601e4692":"code","ff20f63d":"code","9bc0ce37":"code","909e9599":"markdown","a286885f":"markdown","f148e58f":"markdown","0a0d2c67":"markdown","2f696522":"markdown","0291fabf":"markdown","0ff3edcf":"markdown","86f337ba":"markdown","ac128dc5":"markdown","b62eeca8":"markdown","49a5787c":"markdown"},"source":{"76588695":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a22b83f":"# %matplotlib inline will lead to static images of your plot embedded in the notebook\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","42101745":"# Training Data\ndf_train=pd.read_csv('..\/input\/bigmart-sales-data\/Train.csv')\ndf_train.sample(5)","fd5fb1a3":"# Testing Data \ndf_test=pd.read_csv('..\/input\/bigmart-sales-data\/Test.csv')\ndf_test.sample(5)","2b8fd512":"df_train.info()","c8f0afa3":"df_train.shape","7a3fcd35":"df_train.isna().sum()","8418d545":"df_train.duplicated().sum()","ef977800":"df_test.info()","0196715b":"df_test.shape","a52379e1":"df_test.isna().sum()","df31944b":"df_test.duplicated().sum()","e533d467":"df_train.groupby('Item_Type')['Item_Weight'].mean()","5f379c85":"Category_mean = df_train.groupby('Item_Type')['Item_Weight'].mean()\nfor i in range(len(Category_mean)):\n#     print(s.index[i], Category_mean[i])\n    c1 = (df_train['Item_Type']==Category_mean.index[i])&(df_train['Item_Weight'].isna()==True)\n    df_train['Item_Weight'] = np.select([c1], [Category_mean[i]], df_train['Item_Weight'])","0dd13fa4":"from statistics import mode\ndf_train['Outlet_Size'].fillna(mode(df_train['Outlet_Size']),inplace=True)","8409b613":"df_train.isna().sum()","82a42e0d":"df_test.groupby('Item_Type')['Item_Weight'].mean()","517b6c9c":"Category_mean = df_test.groupby('Item_Type')['Item_Weight'].mean()\nfor i in range(len(Category_mean)):\n#     print(s.index[i], Category_mean[i])\n    c1 = (df_test['Item_Type']==Category_mean.index[i])&(df_test['Item_Weight'].isna()==True)\n    df_test['Item_Weight'] = np.select([c1], [Category_mean[i]], df_test['Item_Weight'])","8869845b":"df_test['Outlet_Size'].fillna(mode(df_test['Outlet_Size']),inplace=True)","91e0dbe5":"df_test.isna().sum()","4ed3677c":"df_train['Item_Fat_Content'].value_counts()","b6c2610a":"print('Values before Imputing numeric values:',df_train['Item_Fat_Content'].unique())\ndf_train['Item_Fat_Content']=df_train['Item_Fat_Content'].apply(lambda x: x.lower())\ndf_train['Item_Fat_Content']=df_train['Item_Fat_Content'].apply(lambda x:'lf' if x=='low fat' else x )\ndf_train['Item_Fat_Content']=df_train['Item_Fat_Content'].apply(lambda x:'reg' if x=='regular' else x )\ndf_train['Item_Fat_Content']=df_train['Item_Fat_Content'].map({\n    'lf':0,\n    'reg':1\n})\nprint('Values after Imputing numeric values:',df_train['Item_Fat_Content'].unique())","0d1a3284":"df_train['Item_Fat_Content'].value_counts()","699afc4a":"df_train['Outlet_Size'].value_counts()","646cf777":"print('Values before Imputing numeric values:', df_train['Outlet_Size'].unique())\ndf_train['Outlet_Size']=df_train['Outlet_Size'].map({ 'Medium':1,                            \n                                'High':2,\n                                'Small':3\n})\nprint('Values after Imputing numeric values:' ,df_train['Outlet_Size'].unique())","1e5a226b":"df_train['Outlet_Size'].value_counts()","574fda2d":"df_train=pd.get_dummies(df_train, columns= ['Item_Type','Outlet_Location_Type','Outlet_Type'],drop_first=True)","69d6fa4a":"df_test['Item_Fat_Content'].value_counts()","c6914388":"print('Values before Imputing numeric values:',df_test['Item_Fat_Content'].unique())\ndf_test['Item_Fat_Content']=df_test['Item_Fat_Content'].apply(lambda x: x.lower())\ndf_test['Item_Fat_Content']=df_test['Item_Fat_Content'].apply(lambda x:'lf' if x=='low fat' else x )\ndf_test['Item_Fat_Content']=df_test['Item_Fat_Content'].apply(lambda x:'reg' if x=='regular' else x )\ndf_test['Item_Fat_Content']=df_test['Item_Fat_Content'].map({\n    'lf':0,\n    'reg':1\n})\nprint('Values after Imputing numeric values:',df_test['Item_Fat_Content'].unique())","195801a2":"df_test['Item_Fat_Content'].value_counts()","61be8fab":"df_test['Outlet_Size'].value_counts()","47758443":"print('Values before Imputing numeric values:', df_test['Outlet_Size'].unique())\ndf_test['Outlet_Size']=df_test['Outlet_Size'].map({ 'Medium':1,                            \n                                'High':2,\n                                'Small':3\n})\nprint('Values after Imputing numeric values:' ,df_test['Outlet_Size'].unique())","8c40e887":"df_test['Outlet_Size'].value_counts()","06b801a2":"df_test=pd.get_dummies(df_test, columns= ['Item_Type','Outlet_Location_Type','Outlet_Type'],drop_first=True)","aed91576":"l=[1,3,4,6]\nfor col in df_train.iloc[:,l].columns:\n  #  if type(col) !='str':\n    print(col)\n    sns.boxplot(x=df_train[col],data=df_train)\n    plt.show()","f1b4f3e9":"l=[3]\ndef Outlier(data):\n    for column in data.iloc[:,l].columns:\n        if data[column].dtype!='str':\n            Q1=np.percentile(data[column],25)\n            Q3=np.percentile(data[column],75)\n            IQR= Q3-Q1\n            lower=Q1-(1.5* IQR)\n            upper=Q3+(1.5* IQR)\n            data.loc[:,column] =np.where(data[column].values>upper,upper,data[column].values)\n            data.loc[:,column] =np.where(data[column].values<lower,lower,data[column].values)\n    return data\n \ndf_train2=Outlier(df_train)\ndf_train2.columns\ndf_train2.sample()","e0815c85":"l=[1,3,4,6]\nfor col in df_train2.iloc[:,l].columns:\n  #  if type(col) !='str':\n    print(col)\n    sns.boxplot(x=df_train2[col],data=df_train2)\n    plt.show()","f4c5f533":"l=[1,3,4,6]\nfor col in df_test.iloc[:,l].columns:\n  #  if type(col) !='str':\n    print(col)\n    sns.boxplot(x=df_test[col],data=df_test)\n    plt.show()","89746473":"l=[3]\ndef Outlier(data):\n    for column in data.iloc[:,l].columns:\n        if data[column].dtype!='str':\n            Q1=np.percentile(data[column],25)\n            Q3=np.percentile(data[column],75)\n            IQR= Q3-Q1\n            lower=Q1-(1.5* IQR)\n            upper=Q3+(1.5* IQR)\n            data.loc[:,column] =np.where(data[column].values>upper,upper,data[column].values)\n            data.loc[:,column] =np.where(data[column].values<lower,lower,data[column].values)\n    return data\n \ndf_test2=Outlier(df_test)\ndf_test2.columns\ndf_test2.sample()","e52fec6a":"l=[1,3,4,6]\nfor col in df_test2.iloc[:,l].columns:\n  #  if type(col) !='str':\n    print(col)\n    sns.boxplot(x=df_test2[col],data=df_test2)\n    plt.show()","802b3831":"plt.figure(figsize=(12,7))\nplt.xlabel(\"Item_Visibility\")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Item_Visibility and Item_Outlet_Sales Analysis\")\nplt.plot(df_train.Item_Visibility, df_train[\"Item_Outlet_Sales\"],'.', alpha = 0.3)","3a301e09":"plt.figure(figsize=(12,7))\nplt.xlabel(\"Item_MRP\")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Item_MRP and Item_Outlet_Sales Analysis\")\nplt.plot(df_train.Item_MRP, df_train[\"Item_Outlet_Sales\"],'.', alpha = 0.3)","df66def3":"Outlet_Establishment_Year_pivot = \\\ndf_train.pivot_table(index='Outlet_Establishment_Year', values=\"Item_Outlet_Sales\", aggfunc=np.median)\n\nOutlet_Establishment_Year_pivot.plot(kind='bar', color='blue',figsize=(12,7))\nplt.xlabel(\"Outlet_Establishment_Year\")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Impact of Outlet_Establishment_Year on Item_Outlet_Sales\")\nplt.xticks(rotation=0)\nplt.show()","eafea232":"X=df_train2.drop(['Outlet_Identifier','Item_Identifier','Item_Outlet_Sales'],axis=1)\ny=df_train2['Item_Outlet_Sales']","dccefc6f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)","8278be3b":"#Scaling the data\n\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train_transformed=sc.fit_transform(X_train)\nX_test_transformed=sc.transform(X_test)","e021a420":"from sklearn.linear_model import LinearRegression\nlm=LinearRegression()","f7593273":"lm.fit(X_train_transformed,y_train)","e873a86d":"pred=lm.predict(X_test_transformed)\npred","99cab57a":"train_pred=lm.predict(X_train_transformed)\ntrain_pred","c831c870":"from sklearn.metrics import mean_squared_error\n\nprint('MSE:',mean_squared_error(y_test,pred))\nprint('MSE:',mean_squared_error(y_train,train_pred))","be1a16e1":"print('RMSE:',np.sqrt(mean_squared_error(y_test,pred)))\nprint('RMSE:',np.sqrt(mean_squared_error(y_train,train_pred)))","49955399":"import pickle","601e4692":"pickle_out=open('model.pickle','wb')\npickle.dump(lm,pickle_out)\npickle_out.close()","ff20f63d":"pickle_in=open('model.pickle','rb')\nexample_dict=pickle.load(pickle_in)","9bc0ce37":"example_dict.predict('')","909e9599":"**Treating Categorical Columns**","a286885f":"**Data Visualisation**","f148e58f":"**Evaluating Data**","0a0d2c67":"**Treating Null Values**","2f696522":"**Splitting Data**","0291fabf":"**Loading The Pickle File**","0ff3edcf":"**Creating A Pickle File**","86f337ba":"**Building A Model**","ac128dc5":"**Treating Outliers**","b62eeca8":"**Reading Data**","49a5787c":"**Importing Libraries**"}}