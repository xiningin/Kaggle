{"cell_type":{"e6212231":"code","96747445":"code","90bb20eb":"code","79ee5473":"code","56fbe867":"code","ef128568":"code","e9c14340":"code","9557aeee":"code","a8fc4ed0":"code","c45c9c7d":"code","c0c26708":"code","c83d401d":"markdown","090663f8":"markdown","5353387b":"markdown","0519fc63":"markdown","eb7e1e35":"markdown","f304a334":"markdown","0d36b6fd":"markdown","ca0f7df7":"markdown","47b6dbe2":"markdown","53a50fa1":"markdown","b3248686":"markdown"},"source":{"e6212231":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython import display\nfrom tqdm.auto import trange\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow_addons.layers import InstanceNormalization\n\nfrom functools import partial","96747445":"def plot_results(images, n_cols=None, title=None):\n    \n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    \n    fig = plt.figure(figsize=(n_cols, n_rows))\n    \n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")\n        \n    plt.suptitle(title)","90bb20eb":"def log2(x):\n    return int(np.log2(x))\n\nbatch_sizes = {2: 1024, 3: 512, 4: 512, 5: 512}\ntrain_step_ratio = {k: batch_sizes[2] \/ v for k, v in batch_sizes.items()}\n\ndef resize_image(res, image):\n    # only donwsampling, so use nearest neighbor that is faster to run\n    image = tf.image.resize(\n        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n    )\n    image = tf.cast(image, tf.float32) \/ 127.5 - 1.0\n    return image\n\n\ndef create_dataloader(res, label):\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n    x_all = np.concatenate([x_train, x_test])\n    y_all = np.concatenate([y_train, y_test])\n    x_train = x_all[np.where(y_all == label)]\n    x_train = np.pad(x_train, [(0, 0), (2, 2), (2, 2)], mode='constant')\n    x_train = tf.image.grayscale_to_rgb(tf.expand_dims(x_train, axis=3), name=None)\n    x_train = tf.data.Dataset.from_tensor_slices(x_train)\n    \n    batch_size = batch_sizes[log2(res)]\n    dl = x_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE)\n    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n    return dl\n\ndef prepare_images(label):\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n    X_all = np.concatenate([X_train, X_test])\n    y_all = np.concatenate([y_train, y_test])\n    \n    X_all = X_all.astype(np.float32) \/ 255\n    X_all = X_all.reshape(-1, 28, 28, 1) * 2. - 1.\n    X_train = X_all[np.where(y_all == label)]\n    \n    return X_train","79ee5473":"def fade_in(alpha, a, b):\n    return alpha * a + (1.0 - alpha) * b\n\n\ndef wasserstein_loss(y_true, y_pred):\n    return -tf.reduce_mean(y_true * y_pred)\n\n\ndef pixel_norm(x, epsilon=1e-8):\n    return x \/ tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n\n\ndef minibatch_std(input_tensor, epsilon=1e-8):\n    n, h, w, c = tf.shape(input_tensor)\n    group_size = tf.minimum(4, n)\n    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n    group_std = tf.sqrt(group_var + epsilon)\n    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n    x = tf.tile(avg_std, [group_size, h, w, 1])\n    return tf.concat([input_tensor, x], axis=-1)\n\n\nclass EqualizedConv(layers.Layer):\n    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n        super(EqualizedConv, self).__init__(**kwargs)\n        self.kernel = kernel\n        self.out_channels = out_channels\n        self.gain = gain\n        self.pad = kernel != 1\n\n    def build(self, input_shape):\n        self.in_channels = input_shape[-1]\n        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n        self.w = self.add_weight(\n            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n            initializer=initializer,\n            trainable=True,\n            name=\"kernel\",\n        )\n        self.b = self.add_weight(\n            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n        )\n        fan_in = self.kernel * self.kernel * self.in_channels\n        self.scale = tf.sqrt(self.gain \/ fan_in)\n\n    def call(self, inputs):\n        if self.pad:\n            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n        else:\n            x = inputs\n        output = (\n            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n        )\n        return output\n\n\nclass EqualizedDense(layers.Layer):\n    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n        super(EqualizedDense, self).__init__(**kwargs)\n        self.units = units\n        self.gain = gain\n        self.learning_rate_multiplier = learning_rate_multiplier\n\n    def build(self, input_shape):\n        self.in_channels = input_shape[-1]\n        initializer = keras.initializers.RandomNormal(\n            mean=0.0, stddev=1.0 \/ self.learning_rate_multiplier\n        )\n        self.w = self.add_weight(\n            shape=[self.in_channels, self.units],\n            initializer=initializer,\n            trainable=True,\n            name=\"kernel\",\n        )\n        self.b = self.add_weight(\n            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n        )\n        fan_in = self.in_channels\n        self.scale = tf.sqrt(self.gain \/ fan_in)\n\n    def call(self, inputs):\n        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n        return output * self.learning_rate_multiplier\n\n\nclass AddNoise(layers.Layer):\n    def build(self, input_shape):\n        n, h, w, c = input_shape[0]\n        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n        self.b = self.add_weight(\n            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n        )\n\n    def call(self, inputs):\n        x, noise = inputs\n        output = x + self.b * noise\n        return output\n\n\nclass AdaIN(layers.Layer):\n    def __init__(self, gain=1, **kwargs):\n        super(AdaIN, self).__init__(**kwargs)\n        self.gain = gain\n\n    def build(self, input_shapes):\n        x_shape = input_shapes[0]\n        w_shape = input_shapes[1]\n\n        self.w_channels = w_shape[-1]\n        self.x_channels = x_shape[-1]\n\n        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n\n    def call(self, inputs):\n        x, w = inputs\n        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n        return ys * x + yb","56fbe867":"def Mapping(num_stages, input_shape=512):\n    z = layers.Input(shape=(input_shape))\n    w = pixel_norm(z)\n    for i in range(8):\n        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n        w = layers.LeakyReLU(0.2)(w)\n    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n    return keras.Model(z, w, name=\"mapping\")","ef128568":"class Generator:\n    def __init__(self, start_res_log2, target_res_log2, filter_nums=None):\n        self.start_res_log2 = start_res_log2\n        self.target_res_log2 = target_res_log2\n        self.num_stages = target_res_log2 - start_res_log2 + 1\n        self.g_blocks = []\n        self.to_rgb = []\n        self.noise_inputs = []\n        self.filter_nums = filter_nums\n\n        start_res = 2 ** start_res_log2\n        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n\n        for i in range(start_res_log2, target_res_log2 + 1):\n            filter_num = self.filter_nums[i]\n            res = 2 ** i\n            self.noise_inputs.append(\n                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n            )\n            to_rgb = Sequential(\n                [\n                    layers.InputLayer(input_shape=(res, res, filter_num)),\n                    EqualizedConv(3, 1, gain=1),\n                ],\n                name=f\"to_rgb_{res}x{res}\",\n            )\n            self.to_rgb.append(to_rgb)\n            is_base = i == self.start_res_log2\n            if is_base:\n                input_shape = (res, res, self.filter_nums[i - 1])\n            else:\n                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n            g_block = self.build_block(\n                filter_num, res=res, input_shape=input_shape, is_base=is_base\n            )\n            self.g_blocks.append(g_block)\n\n    def build_block(self, filter_num, res, input_shape, is_base):\n        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n        w = layers.Input(shape=512)\n        x = input_tensor\n\n        if not is_base:\n            x = layers.UpSampling2D((2, 2))(x)\n            x = EqualizedConv(filter_num, 3)(x)\n\n        x = AddNoise()([x, noise])\n        x = layers.LeakyReLU(0.2)(x)\n        x = InstanceNormalization()(x)\n        x = AdaIN()([x, w])\n\n        x = EqualizedConv(filter_num, 3)(x)\n        x = AddNoise()([x, noise])\n        x = layers.LeakyReLU(0.2)(x)\n        x = InstanceNormalization()(x)\n        x = AdaIN()([x, w])\n        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n\n    def grow(self, res_log2):\n        res = 2 ** res_log2\n\n        num_stages = res_log2 - self.start_res_log2 + 1\n        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n\n        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n\n        if num_stages == 1:\n            rgb = self.to_rgb[0](x)\n        else:\n            for i in range(1, num_stages - 1):\n\n                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n\n            old_rgb = self.to_rgb[num_stages - 2](x)\n            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n\n            i = num_stages - 1\n            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n\n            new_rgb = self.to_rgb[i](x)\n\n            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n\n        return keras.Model(\n            [self.g_input, w, self.noise_inputs, alpha],\n            rgb,\n            name=f\"generator_{res}_x_{res}\",\n        )","e9c14340":"class Discriminator:\n    def __init__(self, start_res_log2, target_res_log2, filter_nums):\n        self.start_res_log2 = start_res_log2\n        self.target_res_log2 = target_res_log2\n        self.num_stages = target_res_log2 - start_res_log2 + 1\n        self.filter_nums = filter_nums\n        # list of discriminator blocks at increasing resolution\n        self.d_blocks = []\n        # list of layers to convert RGB into activation for d_blocks inputs\n        self.from_rgb = []\n\n        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n            res = 2 ** res_log2\n            filter_num = self.filter_nums[res_log2]\n            from_rgb = Sequential(\n                [\n                    layers.InputLayer(\n                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n                    ),\n                    EqualizedConv(filter_num, 1),\n                    layers.LeakyReLU(0.2),\n                ],\n                name=f\"from_rgb_{res}\",\n            )\n\n            self.from_rgb.append(from_rgb)\n\n            input_shape = (res, res, filter_num)\n            if len(self.d_blocks) == 0:\n                d_block = self.build_base(filter_num, res)\n            else:\n                d_block = self.build_block(\n                    filter_num, self.filter_nums[res_log2 - 1], res\n                )\n\n            self.d_blocks.append(d_block)\n\n    def build_base(self, filter_num, res):\n        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n        x = minibatch_std(input_tensor)\n        x = EqualizedConv(filter_num, 3)(x)\n        x = layers.LeakyReLU(0.2)(x)\n        x = layers.Flatten()(x)\n        x = EqualizedDense(filter_num)(x)\n        x = layers.LeakyReLU(0.2)(x)\n        x = EqualizedDense(1)(x)\n        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n\n    def build_block(self, filter_num_1, filter_num_2, res):\n        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n        x = layers.LeakyReLU(0.2)(x)\n        x = EqualizedConv(filter_num_2)(x)\n        x = layers.LeakyReLU(0.2)(x)\n        x = layers.AveragePooling2D((2, 2))(x)\n        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n\n    def grow(self, res_log2):\n        res = 2 ** res_log2\n        idx = res_log2 - self.start_res_log2\n        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n        x = self.from_rgb[idx](input_image)\n        x = self.d_blocks[idx](x)\n        if idx > 0:\n            idx -= 1\n            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n            y = self.from_rgb[idx](downsized_image)\n            x = fade_in(alpha[0], x, y)\n\n            for i in range(idx, -1, -1):\n                x = self.d_blocks[i](x)\n        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")","9557aeee":"class StyleGAN(tf.keras.Model):\n    def __init__(self, z_dim=512, target_res=64, start_res=4, filter_nums=None):\n        super().__init__()\n        self.z_dim = z_dim\n\n        self.target_res_log2 = log2(target_res)\n        self.start_res_log2 = log2(start_res)\n        self.current_res_log2 = self.target_res_log2\n        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n\n        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n\n        if filter_nums is None:\n            self.filter_nums = {\n                0: 32,\n                1: 32,\n                2: 32,  # 4x4\n                3: 32,  # 8x8\n                4: 32,  # 16x16\n                5: 32,  # 32x32\n            }\n        else:\n            self.filter_nums = filter_nums\n        \n        self.mapping = Mapping(num_stages=self.num_stages)\n        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2, self.filter_nums)\n        self.g_builder = Generator(self.start_res_log2, self.target_res_log2, self.filter_nums)\n        self.g_input_shape = self.g_builder.input_shape\n\n        self.phase = None\n        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n\n        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n\n    def grow_model(self, res):\n        tf.keras.backend.clear_session()\n        res_log2 = log2(res)\n        self.generator = self.g_builder.grow(res_log2)\n        self.discriminator = self.d_builder.grow(res_log2)\n        self.current_res_log2 = res_log2\n        print(f\"\\nModel resolution:{res}x{res}\")\n\n    def compile(\n        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n    ):\n        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n        self.steps_per_epoch = steps_per_epoch\n        if res != 2 ** self.current_res_log2:\n            self.grow_model(res)\n            self.d_optimizer = d_optimizer\n            self.g_optimizer = g_optimizer\n\n        self.train_step_counter.assign(0)\n        self.phase = phase\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n        super(StyleGAN, self).compile(*args, **kwargs)\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def generate_noise(self, batch_size):\n        noise = [\n            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n        ]\n        return noise\n\n    def gradient_loss(self, grad):\n        loss = tf.square(grad)\n        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n        loss = tf.sqrt(loss)\n        loss = tf.reduce_mean(tf.square(loss - 1))\n        return loss\n\n    def train_step(self, real_images):\n        self.train_step_counter.assign_add(1)\n\n        if self.phase == \"TRANSITION\":\n            self.alpha.assign(\n                tf.cast(self.train_step_counter \/ self.steps_per_epoch, tf.float32)\n            )\n        elif self.phase == \"STABLE\":\n            self.alpha.assign(1.0)\n        else:\n            raise NotImplementedError\n        alpha = tf.expand_dims(self.alpha, 0)\n        batch_size = tf.shape(real_images)[0]\n        real_labels = tf.ones(batch_size)\n        fake_labels = -tf.ones(batch_size)\n\n        z = tf.random.normal((batch_size, self.z_dim))\n        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n        noise = self.generate_noise(batch_size)\n\n        # generator\n        with tf.GradientTape() as g_tape:\n            w = self.mapping(z)\n            fake_images = self.generator([const_input, w, noise, alpha])\n            pred_fake = self.discriminator([fake_images, alpha])\n            g_loss = wasserstein_loss(real_labels, pred_fake)\n\n            trainable_weights = (\n                self.mapping.trainable_weights + self.generator.trainable_weights\n            )\n            gradients = g_tape.gradient(g_loss, trainable_weights)\n            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n\n        # discriminator\n        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n            # forward pass\n            pred_fake = self.discriminator([fake_images, alpha])\n            pred_real = self.discriminator([real_images, alpha])\n\n            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n            gradient_tape.watch(interpolates)\n            pred_fake_grad = self.discriminator([interpolates, alpha])\n\n            # calculate losses\n            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n            loss_real = wasserstein_loss(real_labels, pred_real)\n            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n\n            # gradient penalty\n            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n            gradient_penalty = self.loss_weights[\n                \"gradient_penalty\"\n            ] * self.gradient_loss(gradients_fake)\n\n            # drift loss\n            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n\n            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n\n            gradients = total_tape.gradient(\n                d_loss, self.discriminator.trainable_weights\n            )\n            self.d_optimizer.apply_gradients(\n                zip(gradients, self.discriminator.trainable_weights)\n            )\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }\n\n    def call(self, inputs: dict()):\n        style_code = inputs.get(\"style_code\", None)\n        z = inputs.get(\"z\", None)\n        noise = inputs.get(\"noise\", None)\n        batch_size = inputs.get(\"batch_size\", 1)\n        alpha = inputs.get(\"alpha\", 1.0)\n        alpha = tf.expand_dims(alpha, 0)\n        if style_code is None:\n            if z is None:\n                z = tf.random.normal((batch_size, self.z_dim))\n            style_code = self.mapping(z)\n\n        if noise is None:\n            noise = self.generate_noise(batch_size)\n\n        # self.alpha.assign(alpha)\n\n        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n        images = self.generator([const_input, style_code, noise, alpha])\n        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n\n        return images","a8fc4ed0":"START_RES = 4\nTARGET_RES = 32\n\ndef train(label, start_res, target_res, steps_per_epoch):\n    style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)\n    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n\n    val_batch_size = 16\n    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n    val_noise = style_gan.generate_noise(val_batch_size)\n\n    start_res_log2 = int(np.log2(start_res))\n    target_res_log2 = int(np.log2(target_res))\n\n    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n        res = 2 ** res_log2\n        for phase in [\"TRANSITION\", \"STABLE\"]:\n            if res == start_res and phase == \"TRANSITION\":\n                continue\n\n            train_dl = create_dataloader(res, label)\n\n            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n\n            style_gan.compile(\n                d_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n                g_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n                steps_per_epoch=steps,\n                res=res,\n                phase=phase,\n                run_eagerly=False,\n            )\n\n\n            ckpt_cb = keras.callbacks.ModelCheckpoint(\n                f\"checkpoints_{label}\/stylegan_{res}x{res}.ckpt\",\n                save_weights_only=True,\n                verbose=0,\n            )\n            print(phase)\n            style_gan.fit(\n                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n            )\n            \nfor i in range(10):\n    print(f'\\n\\nTraining for Digit {i}')\n    train(start_res=START_RES, target_res=TARGET_RES, steps_per_epoch=10, label=i)            ","c45c9c7d":"from scipy.linalg import sqrtm\n\ndef frechet_distance(act1, act2):\n    mu1, sigma1 = np.mean(act1, axis=0), np.cov(act1, rowvar=False)\n    mu2, sigma2 = np.mean(act2, axis=0), np.cov(act2, rowvar=False)\n    ssdiff = np.sum((mu1 - mu2)**2.0)\n    covmean = sqrtm(sigma1.dot(sigma2))\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid\n\nevaluator = keras.models.Sequential(keras.models.load_model('..\/input\/mnist-net\/mnist_net.h5').layers[:-1])\nscores = []\n\n\nfor label in range(10):\n    res = TARGET_RES\n    style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)\n    style_gan.grow_model(res)\n    style_gan.load_weights(f\"..\/input\/mnist-style-gans\/checkpoints_{label}\/stylegan_{res}x{res}.ckpt\")\n    batch_size = 128\n    z = tf.random.normal((batch_size, style_gan.z_dim))\n    w = style_gan.mapping(z)\n    noise = style_gan.generate_noise(batch_size=batch_size)\n    images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n    embeddings_real = evaluator(prepare_images(i))\n    embeddings_fake = evaluator(tf.image.rgb_to_grayscale(images[:, 2:-2, 2:-2, :], name=None))\n    scores.append(frechet_distance(embeddings_real, embeddings_fake))              \n    plot_results(images, 16, f'Images Generated for class {label}')\n    plt.show()","c0c26708":"pd.Series(scores, name=\"Frechet Distance\")","c83d401d":"**Generator**","090663f8":"# Evaluation","5353387b":"# Build the Model\n\nThe key idea of StyleGAN is to progressively increase the resolution of the generated images and to incorporate style features in the generative process.\n\n**Custom Layers**","0519fc63":"**Style GAN**","eb7e1e35":"## Utilities","f304a334":"# Style GAN-MNIST Augmentation","0d36b6fd":"# Prepare the Dataset","ca0f7df7":"**Discriminator**","47b6dbe2":"# Style GAN in Action\nTraining for 10 steps per epoch for demonstration","53a50fa1":"# Generated Images\nUsing GANs trained on 5000 steps per epoch","b3248686":"**A model mapping to map the random noise into style code**"}}