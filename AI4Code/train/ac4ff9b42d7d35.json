{"cell_type":{"207ac0c6":"code","fcddd7f4":"code","5cb44129":"code","b899705b":"code","4acf4426":"code","234401a8":"code","32a9ecab":"code","77ec0c7b":"code","0d376272":"code","6828efdd":"code","c83585a2":"code","ab789363":"code","8136ae1b":"code","4a254d00":"code","988334d0":"code","f08201bb":"code","a95cc25c":"code","81c09b1a":"code","26ce8788":"code","990be8e5":"code","8ffcb1a4":"markdown","740ba18a":"markdown","199fe117":"markdown","52453f2d":"markdown","c6bc502a":"markdown","b2d76885":"markdown","61e6bb1d":"markdown","6a54727c":"markdown","b06d421e":"markdown","ddf19f45":"markdown","0c8a85df":"markdown","c26ec205":"markdown","5b33242b":"markdown","11a29784":"markdown","82afd353":"markdown","976b82c3":"markdown","3658198a":"markdown","e6ee5c08":"markdown","61863fef":"markdown"},"source":{"207ac0c6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom pandas.io.json import json_normalize\n%matplotlib inline\n","fcddd7f4":"df=pd.read_csv(\"..\/input\/KNN_Project_Data.csv\")","5cb44129":"sns.pairplot(df,hue='TARGET CLASS',palette='coolwarm')","b899705b":"from sklearn.preprocessing import StandardScaler ","4acf4426":"scaler=StandardScaler()","234401a8":"scaler.fit(df.drop(('TARGET CLASS'),axis=1))","32a9ecab":"scaler_feature=scaler.transform(df.drop(('TARGET CLASS'),axis=1))","77ec0c7b":"df_f=pd.DataFrame(scaler_feature,columns=df.columns[:-1])\ndf_f.head()","0d376272":"from sklearn.model_selection import train_test_split","6828efdd":"X=scaler_feature\ny=df['TARGET CLASS']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","c83585a2":"from sklearn.neighbors import KNeighborsClassifier","ab789363":"knn=KNeighborsClassifier(n_neighbors=1\n                        )","8136ae1b":"knn.fit(X_train,y_train)","4a254d00":"pred=knn.predict(X_test)","988334d0":"from sklearn.metrics import confusion_matrix,classification_report","f08201bb":"confusion_matrix(y_test,pred)","a95cc25c":"print(classification_report(y_test,pred))","81c09b1a":"error_rate=[]\nfor i in range(1,40):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i=knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","26ce8788":"plt.figure(figsize=(10,6))\nplt.style.use('ggplot')\nplt.plot(range(1,40),error_rate,color='blue',linestyle='--',marker='o',markerfacecolor='red',markersize=10)\nplt.title(\"Error rate Vs K Value\")\nplt.ylabel('Error Rate')\nplt.xlabel('K')","990be8e5":"knn=KNeighborsClassifier(n_neighbors=22)\nknn.fit(X_train,y_train)\npred_i=knn.predict(X_test)\n\nprint('WITH K=22')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","8ffcb1a4":"# Standardize the Variables\n\nTime to standardize the variables.\n\n** Import StandardScaler from Scikit learn.**","740ba18a":"** Create a confusion matrix and classification report.**","199fe117":"** Create a StandardScaler() object called scaler.**","52453f2d":"**Check the head of the dataframe.**","c6bc502a":"# Using KNN\n\n**Import KNeighborsClassifier from scikit learn.**","b2d76885":"**Fit this KNN model to the training data.**","61e6bb1d":"# Train Test Split\n\n**Use train_test_split to split your data into a training set and a testing set.**","6a54727c":"## Get the Data\n** Read the 'KNN_Project_Data csv file into a dataframe **","b06d421e":"**Use the .transform() method to transform the features to a scaled version.**","ddf19f45":"# Predictions and Evaluations\nLet's evaluate our KNN model!","0c8a85df":"**Use the predict method to predict values using your KNN model and X_test.**","c26ec205":"**Create a KNN model instance with n_neighbors=1**","5b33242b":"# Choosing a K Value\nLet's go ahead and use the elbow method to pick a good K Value!\n\n** Create a for loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list. Refer to the lecture if you are confused on this step.**","11a29784":"**Convert the scaled features to a dataframe and check the head of this dataframe to make sure the scaling worked.**","82afd353":"**Now create the following plot using the information from your for loop.**","976b82c3":"## Retrain with new K Value\n\n**Retrain your model with the best K value (up to you to decide what you want) and re-do the classification report and the confusion matrix.**","3658198a":"** Fit scaler to the features.**","e6ee5c08":"# K Nearest Neighbors Project \n\nWelcome to the KNN Project! This will be a simple project very similar to the lecture, except you'll be given another data set. Go ahead and just follow the directions below.\n## Import Libraries\n**Import pandas,seaborn, and the usual libraries.**","61863fef":"# EDA\n\nSince this data is artificial, we'll just do a large pairplot with seaborn.\n\n**Use seaborn on the dataframe to create a pairplot with the hue indicated by the TARGET CLASS column.**"}}