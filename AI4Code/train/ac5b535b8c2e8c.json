{"cell_type":{"00a21ae0":"code","69dadbe8":"code","f5f3b996":"code","56f9001d":"code","76300cc1":"code","7eddd181":"code","01af4d10":"code","e12a915a":"code","b71e6d85":"code","aa02e5d8":"code","bba886e1":"code","b032b342":"code","7ae06f62":"markdown","b8909eca":"markdown","e22ae939":"markdown","7ab5e579":"markdown","15814d2c":"markdown","0ac8851a":"markdown","3ba552d1":"markdown","43aff709":"markdown","59aa6dfb":"markdown","87c9174f":"markdown","67e2878d":"markdown","cad8ce71":"markdown","f7b35e89":"markdown","4629f9b0":"markdown","cb5873b4":"markdown"},"source":{"00a21ae0":"import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","69dadbe8":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nall_data = [train,test]","f5f3b996":"train.head()","56f9001d":"train.info()","76300cc1":"train = train[train['Embarked'].notna()]\nclean_data=train.drop(['PassengerId','Name','Survived','Ticket'], axis=1)\nclean_data.head()","7eddd181":"test_clean_data = test.drop(['PassengerId','Name','Ticket'], axis=1)\ntest_clean_data.head()","01af4d10":"s = (clean_data.dtypes == 'object')\ncategorical_cols = list(s[s].index)\n\nt = (clean_data.dtypes != 'object')\nnumerical_cols = list(t[t].index)","e12a915a":"numerical = Pipeline(steps=[\n    ('imputer',SimpleImputer(strategy='most_frequent')),\n    ('scaler', StandardScaler(with_mean=False))\n])\n\ncategorical = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n    ('scaler', StandardScaler(with_mean=False))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical, numerical_cols),\n        ('cat', categorical, categorical_cols)\n    ])","b71e6d85":"x = clean_data\ny = train[\"Survived\"]\nx_test = test_clean_data\nx.columns = clean_data.columns\nx_test.columns = test_clean_data.columns\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, train_size=0.7,test_size=0.3, random_state=1)\n\n\ndemo_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\ntrial_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', demo_model)\n                             ])\n\ntrial_pipeline.fit(train_x, train_y)\n\npredictions = trial_pipeline.predict(val_x)\n\nprint(classification_report(val_y, predictions)) ","aa02e5d8":"model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\npipeline.fit(train_x, train_y)\n","bba886e1":"prediction_results = pipeline.predict(x_test)","b032b342":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': prediction_results})\noutput.to_csv('submission.csv', index=False)\nprint(\"Submission Saved\")\noutput","7ae06f62":"# Final Model","b8909eca":"**Importing Datasets**","e22ae939":"We have null values in **Age**,**Cabin** and **Embarked**.","7ab5e579":"Lets now save them to a file called **submission.csv**","15814d2c":"I will validate the data using parameters by trial and testing to find the best parameters.","0ac8851a":"We will now create a pipeline.","3ba552d1":"Now that we have made the model, let us predict!","43aff709":"We will separate the Categorical and Numerical Columns.","59aa6dfb":"# Creating a Pipeline","87c9174f":"We can see we have Alphanumeric and Numeric mixed data types in **Ticket** and categorical data in **Sex** and **Embarked**.","67e2878d":"This Notebook is written in Python and uses the Titanic dataset to predict the survuval rate of passengers on the Titanic.","cad8ce71":"# Validating Data","f7b35e89":"# Final Predictions","4629f9b0":"Since only 2 values are there which have NULL values, we will drop them since they wont make a lot of difference to our dataset.We will also drop useless columns which won't help in prediction, such as **Ticket**.","cb5873b4":"# Introduction"}}