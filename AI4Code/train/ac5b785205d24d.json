{"cell_type":{"269be593":"code","237eab38":"code","db1b4874":"code","b6fa3fee":"code","c47df2a5":"code","82a8c5e3":"code","42c1424f":"code","58a0a130":"code","d298cc1e":"code","8dd91cbc":"code","4e9eefff":"code","8fca678f":"code","64506dcb":"code","bd366287":"code","17ffe148":"code","7534eb18":"code","3bb6feaa":"code","d1d7f816":"code","a23467c3":"code","b4fa527b":"code","0f627f11":"code","e97027ff":"code","886efdac":"code","5ceb39c5":"code","e5d562c8":"code","d00af78a":"code","aaa2dbc3":"code","5bd55768":"code","cb2a2fd8":"code","d96ddd04":"code","8cf6dc58":"code","3b56bec0":"code","a5f83c61":"code","8e76b8ea":"code","90e820b2":"code","a8ae3168":"code","0fdf30be":"code","27f30600":"code","3a3dfe3d":"code","7deb6f5b":"code","a7432974":"markdown","c41ab664":"markdown","6ba049c7":"markdown","1b6ba783":"markdown","dd06b150":"markdown","58478a29":"markdown","fdfe5064":"markdown","7c8d6968":"markdown","06ca35fb":"markdown","66c096ce":"markdown","819b1101":"markdown","41d90b65":"markdown","a4742b3f":"markdown","d33e7c62":"markdown","8111f26b":"markdown","fdbc3e87":"markdown","86a64b18":"markdown","7bb47484":"markdown","3419dac4":"markdown","26242f34":"markdown"},"source":{"269be593":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","237eab38":"from keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","db1b4874":"import cv2\nimport os\nimport glob\nimport gc\n\ndef lire_images(img_dir, xdim, ydim, nmax=5000) :\n    \"\"\" \n    Lit les images dans les sous r\u00e9pertoires de img_dir\n    nmax images lues dans chaque r\u00e9pertoire au maximum\n    Renvoie :\n    X : liste des images lues, matrices xdim*ydim\n    y : liste des labels num\u00e9riques\n    label : nombre de labels\n    label_names : liste des noms des r\u00e9pertoires lus\n    \"\"\"\n    label = 0\n    label_names = []\n    X = []\n    y=[]\n    for dirname in os.listdir(img_dir):\n        print(dirname)\n        label_names.append(dirname)\n        data_path = os.path.join(img_dir + \"\/\" + dirname,'*g')\n        files = glob.glob(data_path)\n        n=0\n        for f1 in files:\n            if n>nmax : break\n            img = cv2.imread(f1)\n            img = cv2.resize(img, (xdim,ydim))\n            X.append(np.array(img))\n            y.append(label)\n            n=n+1\n        print(n,' images lues')\n        label = label+1\n    X = np.array(X)\n    y = np.array(y)\n    gc.collect() # R\u00e9cup\u00e9ration de m\u00e9moire\n    return X,y, label, label_names","b6fa3fee":"X,y,nlabels,names = lire_images('..\/input\/chest-xray-pneumonia\/chest_xray\/test', 224, 224, 2000)","c47df2a5":"names","82a8c5e3":"import random\nplt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    j = random.randint(0,len(X))\n    plt.axis('off')\n    plt.imshow(X[j])\n    plt.title(names[y[j]])","42c1424f":"y = to_categorical(y)","58a0a130":"X.shape","d298cc1e":"# Normalisation entre 0 et 1\nX = X \/ 255\nprint(X[0][0])","8dd91cbc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","4e9eefff":"del X,y","8fca678f":"# R\u00e9seau convolutionnel simple\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(224, 224, 3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\n#model.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","64506dcb":"model.summary()","bd366287":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","17ffe148":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","7534eb18":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","3bb6feaa":"plot_scores(train)","d1d7f816":"# Prediction\ny_cnn = model.predict_classes(X_test)","a23467c3":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (names[y_cnn[j]], names[y_test[j].argmax(axis=-1)]))\n        i+=1","b4fa527b":"# Mod\u00e8le CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","0f627f11":"model.summary()","e97027ff":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200, verbose=1)\n\n# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","886efdac":"plot_scores(train)","5ceb39c5":"model.save('mnist_cnn2.h5')","e5d562c8":"new_model = load_model('mnist_cnn2.h5')\nnew_model.summary()","d00af78a":"scores = new_model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","aaa2dbc3":"from keras.applications import VGG16","5bd55768":"vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\nvgg16.trainable = False","cb2a2fd8":"vgg16.summary()","d96ddd04":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(49, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","8cf6dc58":"model.summary()","3b56bec0":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","a5f83c61":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","8e76b8ea":"for i in range (len(vgg16.layers)):\n    print (i,vgg16.layers[i])","90e820b2":"for layer in vgg16.layers[15:]:\n    layer.trainable=True\nfor layer in vgg16.layers[0:15]:\n    layer.trainable=False","a8ae3168":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(49, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","0fdf30be":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","27f30600":"plot_scores(train)","3a3dfe3d":"y_cnn = model.predict_classes(X_test)","7deb6f5b":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (names[y_cnn[j]], names[y_test[j].argmax(axis=-1)]))\n        i+=1","a7432974":"On d\u00e9gele les derni\u00e8res couches","c41ab664":"On utilise une couche convolutionnelle pour l'extraction des caract\u00e9ristiques, et une couche dense pour la classification ","6ba049c7":"On binarise la cible ","1b6ba783":"## Une couche convolutionnelle","dd06b150":"On affiche la structure du mod\u00e8le","58478a29":"On teste un mod\u00e8le avec deux couches convolutionnelles","fdfe5064":"On peut ensuite utiliser le mod\u00e8le sans recommencer l'entra\u00eenement","7c8d6968":"On affiche des images al\u00e9atoirement ","06ca35fb":"On utilise un mod\u00e8le pr\u00e9d\u00e9fini dans Keras (VGG16)","66c096ce":"On ajoute des couches pour entra\u00eener le mod\u00e8le \u00e0 partir du dataset, sans modifier les poids existants du VGG16","819b1101":"On affiche les images o\u00f9 l'algorithme s'est tromp\u00e9","41d90b65":"On d\u00e9compose en ensemble d'apprentissage et de validation","a4742b3f":"## Mod\u00e8le CNN plus profond","d33e7c62":"Le mod\u00e8le entrain\u00e9 peut \u00eatre sauvegard\u00e9","8111f26b":"On utilise les poids pr\u00e9-entra\u00een\u00e9s sur ImageNet (un million d'images) On \"fige\" le r\u00e9seau VGG16, de mani\u00e8re \u00e0 ne pas refaire l'entra\u00eenement sur le dataset particulier","fdbc3e87":"## Transfer learning","86a64b18":"On d\u00e9finit une fonction pour afficher un graphique des scores","7bb47484":"Fonction permettant de lire des images dans des sous-r\u00e9pertoires ","3419dac4":"## Initialisations","26242f34":"## Lecture des images"}}