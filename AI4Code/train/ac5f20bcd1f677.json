{"cell_type":{"f6f0326d":"code","53dbea1b":"code","f9e5bfd9":"code","75323429":"code","8a46b670":"code","71f9750e":"code","a4f18067":"code","ccb987ef":"code","ec09c1be":"code","05dc2b32":"code","97846b9c":"code","4353eaba":"code","50fcdf46":"code","09dae7f8":"code","bba8d2b8":"code","a425c0ec":"code","7b87ed99":"code","a19c2162":"code","594646f6":"code","11702597":"code","73a86cbb":"code","cfaadf94":"code","1e755e83":"code","bb3ce8d3":"code","0d7c6d9b":"code","8ac095a1":"code","a9a5f16c":"code","c2105e52":"code","4457eb04":"code","361897ca":"code","6cdae18e":"code","3fcaea3b":"code","607c8ed1":"code","f0e350d0":"code","9cbc76a0":"code","7f1736b4":"code","f6e94187":"code","06021e15":"code","da855159":"code","92bb52bf":"code","e196b258":"code","d7170c12":"code","d670f148":"code","0c50f1ca":"code","3f754d64":"code","514c45c7":"code","02693233":"code","eda1d652":"code","0a12ed23":"code","37774780":"code","c4ff84bd":"code","53f6c5d3":"code","e701ae68":"code","476e486d":"code","80bcc80b":"code","c7d1c2ad":"code","a7b59d86":"code","ea5fe428":"code","6355193a":"code","697c6bf5":"code","dbc8531d":"code","e1591e71":"code","81e8d3e5":"code","4f6171db":"code","113ce75e":"code","987a7db7":"code","c4aa4063":"code","ce17b348":"code","3027813a":"code","cac2afd7":"code","520ec2ec":"code","45e42c08":"code","04d07f9e":"code","c0fd3b06":"code","8ad3e06d":"code","6c024ac3":"code","6226dd06":"code","3e8642d3":"code","8a946cdc":"code","6d565814":"code","41a0b2d2":"code","43ac4c9b":"code","2b44014e":"code","ef37c3bb":"code","605f81a0":"markdown","913f7801":"markdown","26dad605":"markdown","753803e8":"markdown","225a976a":"markdown","a6ff4be7":"markdown","d09121d1":"markdown"},"source":{"f6f0326d":"#!pip install keras==2.1.6","53dbea1b":"!pip install git+https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp","f9e5bfd9":"rs = 10005","75323429":"import datetime\nnow = datetime.datetime.now()\nprint(now)","8a46b670":"%matplotlib inline\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot","71f9750e":"import os\nprint(os.listdir(\"..\/input\"))","a4f18067":"import os.path\nimport itertools\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n    Conv1D, Conv2D, Conv3D, \\\n    Conv2DTranspose, \\\n    AveragePooling1D, AveragePooling2D, \\\n    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n    GlobalAveragePooling1D, GlobalAveragePooling2D, \\\n    GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalMaxPooling3D, \\\n    LocallyConnected1D, LocallyConnected2D, \\\n    concatenate, Flatten, Average, Activation, \\\n    RepeatVector, Permute, Reshape, Dot, \\\n    multiply, dot, add, \\\n    PReLU, \\\n    Bidirectional, TimeDistributed, \\\n    SpatialDropout1D, \\\n    BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras import losses\nfrom keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.metrics import categorical_accuracy\nfrom keras.constraints import maxnorm, non_neg\nfrom keras.optimizers import RMSprop\nfrom keras.utils import to_categorical, plot_model\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras","ccb987ef":"from PIL import Image\nfrom zipfile import ZipFile\nimport h5py\nimport cv2\nfrom tqdm import tqdm","ec09c1be":"from keras_ex.gkernel import GaussianKernel, GaussianKernel2, GaussianKernel3","05dc2b32":"src_dir = '..\/input\/cifar10-object-recognition-in-images-zip-file'\ntrain_zip = os.path.join(src_dir, 'train_test\/train.zip')\ntest_zip = os.path.join(src_dir, 'train_test\/test.zip')","97846b9c":"train_labels = pd.read_csv(os.path.join(src_dir, \"trainLabels.csv\"))\nprint(train_labels.shape)\ntrain_labels.head(10)","4353eaba":"id_key = dict([ee for ee in enumerate(np.unique(train_labels.label.values))])\nid_key","50fcdf46":"key_id = dict([(ee[1], ee[0]) for ee in enumerate(np.unique(train_labels.label.values))])\nkey_id","09dae7f8":"y_train0 = np.array([key_id[ee] for ee in train_labels.label.values])\ny_train0","bba8d2b8":"test_labels = pd.read_csv(os.path.join(src_dir, \"sampleSubmission.csv\"))\nprint(test_labels.shape)\ntest_labels.head()","a425c0ec":"from zipfile import ZipFile","7b87ed99":"trainImg_list = []\nwith ZipFile(train_zip, 'r') as myzip:\n    for ii in train_labels.id.values:\n        with myzip.open('train\/'+str(ii)+'.png') as tgt:\n            img = Image.open(tgt)\n            img_array = np.asarray(img)\n            trainImg_list.append(img_array)","a19c2162":"x_train0 = np.stack(trainImg_list).astype('float32') \/ 255.0\nx_train0.shape","594646f6":"testImg_list = []\nwith ZipFile(test_zip, 'r') as myzip:\n    for ii in test_labels.id.values:\n        with myzip.open('test\/'+str(ii)+'.png') as tgt:\n            img = Image.open(tgt)\n            img_array = np.asarray(img)\n            testImg_list.append(img_array)","11702597":"x_test = np.stack(testImg_list).astype('float32') \/ 255.0\nx_test.shape","73a86cbb":"plt.imshow(x_train0[0])","cfaadf94":"plt.imshow(x_test[0])","1e755e83":"y_cat_train0 = to_categorical(y_train0)\nprint(y_cat_train0.shape)","bb3ce8d3":"nrows=10\nncols=10\nfig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 10))\n\nfor ii in range(nrows):\n    for jj in range(ncols):\n        iplt = subs[ii, jj]\n        img_array = x_train0[ii*ncols + jj]\n        iplt.imshow(img_array)","0d7c6d9b":"nrows=10\nncols=12\nfig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 10))\n\nfor ii in range(nrows):\n    idx = (y_train0 == ii)\n    target_img = x_train0[idx][:ncols]\n    for jj in range(ncols):\n        iplt = subs[ii, jj]\n        img_array = target_img[jj]\n        iplt.imshow(img_array)","8ac095a1":"x_train = x_train0\ny_train = y_train0\ny_cat_train = y_cat_train0","a9a5f16c":"def make_trainable_false(model, trainable=False):\n    layers = model.layers\n    for ilayer in layers:\n        ilayer.trainable = trainable\n    return\n\nclass TrainableCtrl(object):\n    \n    def __init__(self, model_dic):\n        self.model_dic = model_dic\n        self.trainable_dic = {}\n        self.get_trainable()\n        \n    def get_trainable(self):\n        for k in self.model_dic:\n            model = self.model_dic[k]\n            res = []\n            for ilayer in model.layers:\n                res.append(ilayer.trainable)\n            self.trainable_dic[k] = res\n    \n    def set_trainable_false(self, model_key):\n        model = self.model_dic[model_key]\n        make_trainable_false(model)\n    \n    def set_trainable_true(self, model_key):\n        model = self.model_dic[model_key]\n        for ii, ilayer in enumerate(model.layers):\n            ilayer.trainable = self.trainable_dic[model_key][ii]","c2105e52":"img_shape = x_train.shape[1:]\nimg_dim = np.array(img_shape).prod()\nprint(img_dim)\n\nnn = 256*2 # output dim of img_cnvt\n\nnum_cnvt_lm = 2\nnum_cls = 10","4457eb04":"n = 3\ndepth = n * 9 + 2","361897ca":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","6cdae18e":"def _resnet_v2(input_shape, depth, num_classes=10):\n    \"\"\"ResNet Version 2 Model builder [b]\n    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n    bottleneck layer\n    First shortcut connection per layer is 1 x 1 Conv2D.\n    Second and onwards shortcut connection is identity.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filter maps is\n    doubled. Within each stage, the layers have the same number filters and the\n    same filter map sizes.\n    Features maps sizes:\n    conv1  : 32x32,  16\n    stage 0: 32x32,  64\n    stage 1: 16x16, 128\n    stage 2:  8x8,  256\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n    # Returns\n        model (Model): Keras model instance\n    \"\"\"\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) \/ 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = add([x, y])\n\n        num_filters_in = num_filters_out\n\n    # Add classifier on top.\n    x1 = GlobalMaxPooling2D()(x)\n    x2 = GlobalAveragePooling2D()(x)\n    x = concatenate([x1, x2])\n    # v2 has BN-ReLU before Pooling\n#     x = BatchNormalization()(x)\n    x = Activation('sigmoid')(x)\n#     x = AveragePooling2D(pool_size=8)(x)\n    \n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=x, name='model_img_converter')\n    return model","3fcaea3b":"model_img_cnvt = _resnet_v2(input_shape=img_shape, depth=depth)\nmodel_img_cnvt.summary()","607c8ed1":"# SVG(model_to_dot(model_img_cnvt).create(prog='dot', format='svg'))","f0e350d0":"def make_model_gkernel(nn=nn, num_lm=num_cnvt_lm, random_state=0, scale=1):\n    inp = Input(shape=(nn,), name='inp')\n    oup = inp\n    \n    np.random.seed(random_state)\n    #init_wgt = (np.random.random_sample((num_lm, nn))-0.5) * scale\n    init_wgt = np.random.random_sample((num_lm, nn))\n    \n    weights2 = [init_wgt, np.log(np.array([1\/(2*nn*0.1*scale)]))]\n    oup = GaussianKernel3(num_landmark=num_lm, num_feature=nn, weights=weights2, name='gkernel')(oup)\n#     weights2 = [np.log(np.array([1\/(2*nn*0.1*scale)]))]\n#     oup = GaussianKernel2(init_wgt, weights=weights2, name='gkernel')(oup)\n    model = Model(inp, oup, name='model_gkernel')\n    return init_wgt, model\n\nlm_gkernel, model_gkernel = make_model_gkernel(random_state=rs)\nmodel_gkernel.summary()","9cbc76a0":"print(lm_gkernel.shape)\n\ndf = pd.DataFrame(lm_gkernel[:,:5])\ndf.head()\nfig = sns.pairplot(df, markers=['o'], height=2.2, diag_kind='hist')","7f1736b4":"# def get_circle(nn=10, rs=None):\n#     np.random.seed(rs)\n#     idx = np.pi*2*np.arange(nn-1)\/(nn-1)\n#     idx += 2*np.pi*np.random.random(1)\n#     init_wgt = np.c_[np.cos(idx), np.sin(idx)]\n#     init_wgt = np.vstack([init_wgt, np.array([0,0])])\n#     return np.random.permutation(init_wgt)\n#     return init_wgt\ndef get_circle(nn=10, rs=None):\n    np.random.seed(rs)\n    idx = np.pi*2*np.arange(nn)\/nn\n    idx += 2*np.pi*np.random.random(1)\n    idx = np.random.permutation(idx)\n    #return idx\n    init_wgt = np.c_[np.cos(idx), np.sin(idx)]\n    return init_wgt","f6e94187":"init_circle = get_circle(nn=num_cls, rs=rs)\ninit_circle = init_circle*0.8\/2 + 0.5\nprint(init_circle)\n\ndf = pd.DataFrame(init_circle)\ndf['cls'] = ['c'+str(ee) for ee in range(num_cls)]\ndf.head()\nfig = sns.pairplot(df, markers='o', size=2.2, diag_kind='hist', hue='cls')\naxes = fig.axes\naxes[0,0].set_xlim(0, 1)\naxes[0,0].set_ylim(0, 1)\naxes[1,1].set_xlim(0, 1)\naxes[1,1].set_ylim(0, 1)","06021e15":"def make_models_out(init_heart, nn=num_cnvt_lm, num_cls=num_cls):\n    inp = Input(shape=(nn,), name='inp')\n    # oup = Dense(num_cls, activation='sigmoid')(inp)\n#     init_wgt = np.random.random_sample((num_cls, nn))\n#     weights = [init_wgt, np.log(np.array([1\/(2*nn*0.1)]))]\n#     oup = GaussianKernel3(num_landmark=num_cls, num_feature=nn, weights=weights, name='gkernel3')(inp)\n    weights = [np.log(np.array([1\/(2*nn*0.1)]))]\n    oup = GaussianKernel2(init_heart, weights=weights, name='gkernel_out')(inp)\n    model = Model(inp, oup, name='model_out')\n    return model\n\nmodel_out = make_models_out(init_circle)\nmodel_out.summary()","da855159":"# model_dic = {\n#     'model_img_cnvt': model_img_cnvt,\n#     'model_gkernel2': model_gkernel,\n#     'model_out': model_out\n# }\n# train_ctrl = TrainableCtrl(model_dic)","92bb52bf":"def make_modelz(img_shape, model_img_cnvt, model_gkernel2, model_out):\n    inp = Input(shape=img_shape, name='inp')\n    oup = model_img_cnvt(inp)\n    oup = model_gkernel2(oup)\n    oup1 = model_out(oup)\n    pre_model = Model(inp, oup1)\n    pre_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return {\n        'pre_model': pre_model,\n        'model_img_cnvt': model_img_cnvt,\n        'model_gkernel2': model_gkernel2,\n        'model_out': model_out,\n    }\n\nmodels = make_modelz(img_shape, model_img_cnvt, model_gkernel, model_out)\nmodels['pre_model'].summary()","e196b258":"THRESHOLD = 0.5\n\n# credits: https:\/\/www.kaggle.com\/guglielmocamporese\/macro-f1-score-keras\n\nK_epsilon = K.epsilon()\ndef f1(y_true, y_pred):\n    #y_pred = K.round(y_pred)\n    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K_epsilon)\n    r = tp \/ (tp + fn + K_epsilon)\n\n    f1 = 2*p*r \/ (p+r+K_epsilon)\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef f1_loss(y_true, y_pred):\n    \n    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp \/ (tp + fp + K_epsilon)\n    r = tp \/ (tp + fn + K_epsilon)\n\n    f1 = 2*p*r \/ (p+r+K_epsilon)\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1-K.mean(f1)","d7170c12":"'''\nThanks Iafoss.\npretrained ResNet34 with RGBY\nhttps:\/\/www.kaggle.com\/iafoss\/pretrained-resnet34-with-rgby-0-460-public-lb\n'''\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","d670f148":"# train_ctrl.set_trainable_true('model_img_cnvt')\n# train_ctrl.set_trainable_false('model_gkernel2')\n# train_ctrl.set_trainable_false('model_out')\n\nmodels['pre_model'].compile(loss=focal_loss,\n                            optimizer='adam',\n                            metrics=['categorical_accuracy', 'binary_accuracy', f1])\nmodels['pre_model'].summary()","0c50f1ca":"def lr_schedule(epoch):\n    lr0 = 0.001\n    epoch1 = 64\n    epoch2 = 64\n    epoch3 = 64\n    epoch4 = 64\n    \n    if epoch<epoch1:\n        lr = lr0\n    elif epoch<epoch1+epoch2:\n        lr = lr0\/2\n    elif epoch<epoch1+epoch2+epoch3:\n        lr = lr0\/4\n    elif epoch<epoch1+epoch2+epoch3+epoch4:\n        lr = lr0\/8\n    else:\n        lr = lr0\/16\n    \n    if divmod(epoch,4)[1] == 3:\n        lr *= (1\/8)\n    elif divmod(epoch,4)[1] == 2:\n        lr *= (1\/4)\n    elif divmod(epoch,4)[1] == 1:\n        lr *= (1\/2)\n    elif divmod(epoch,4)[1] == 0:\n        pass\n    print('Learning rate: ', lr)\n    return lr\n\n# filepath = 'cifar10_model.{epoch:03d}.h5'\n# filepath2 = 'cifar10_model.best.h5'\n\n# checkpoint = ModelCheckpoint(filepath=filepath,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n# checkpoint2 = ModelCheckpoint(filepath=filepath2,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\n#callbacks = [checkpoint, lr_scheduler, checkpoint2]\ncallbacks = [lr_scheduler]","3f754d64":"datagen = ImageDataGenerator(\n    # set input mean to 0 over the dataset\n    featurewise_center=False,\n    # set each sample mean to 0\n    samplewise_center=False,\n    # divide inputs by std of dataset\n    featurewise_std_normalization=False,\n    # divide each input by its std\n    samplewise_std_normalization=False,\n    # apply ZCA whitening\n    zca_whitening=False,\n    # epsilon for ZCA whitening\n    zca_epsilon=1e-06,\n    # randomly rotate images in the range (deg 0 to 180)\n    rotation_range=10,\n    # randomly shift images horizontally\n    width_shift_range=0.1,\n    # randomly shift images vertically\n    height_shift_range=0.1,\n    # set range for random shear\n    shear_range=0.,\n    # set range for random zoom\n    zoom_range=0.,\n    # set range for random channel shifts\n    channel_shift_range=0.,\n    # set mode for filling points outside the input boundaries\n    fill_mode='nearest',\n    # value used for fill_mode = \"constant\"\n    cval=0.,\n    # randomly flip images\n    horizontal_flip=True,\n    # randomly flip images\n    vertical_flip=False,\n    # set rescaling factor (applied before any other transformation)\n    rescale=None,\n    # set function that will be applied on each input\n    preprocessing_function=None,\n    # image data format, either \"channels_first\" or \"channels_last\"\n    data_format=None,\n    # fraction of images reserved for validation (strictly between 0 and 1)\n    validation_split=0.0)\n\n# Compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied).\ndatagen.fit(x_train)","514c45c7":"# hst = models['pre_model'].fit(x_train, y_cat_train,\n#                               epochs=10, batch_size=32, verbose=2)\nit = datagen.flow(x_train, y_cat_train, batch_size=128)\nhst = models['pre_model'].fit_generator(it, steps_per_epoch=len(it),\n                                        #validation_data=(x_val, y_cat_val),\n                                        epochs=128, verbose=2,\n                                        #epochs=4, verbose=2,\n                                        callbacks=callbacks)","02693233":"hst_history = hst.history","eda1d652":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"loss\"], label=\"Train loss\")\nax[1].set_title('acc')\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"binary_accuracy\"], label=\"binary_accuracy\")\nax[2].set_title('f1_score')\nax[2].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"f1\"], label=\"f1 score\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","0a12ed23":"# fig, ax = plt.subplots(1, 2, figsize=(20,5))\n# ax[0].set_title('acc')\n# ax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\n# ax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"val_categorical_accuracy\"], label=\"val_categorical_accuracy\")\n# ax[1].set_title('f1')\n# ax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"f1\"], label=\"f1 score\")\n# ax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"val_f1\"], label=\"val_f1 score\")\n# ax[0].legend()\n# ax[1].legend()","37774780":"models['pre_model'].save_weights('cifar10_model.h5')","c4ff84bd":"init_circle2 = get_circle(nn=num_cls, rs=rs)\ninit_circle2 = init_circle2*0.6\/2 + 0.5\nprint(init_circle2)\n\ndf = pd.DataFrame(init_circle2)\ndf['cls'] = ['c'+str(ee) for ee in range(num_cls)]\ndf.head()\nfig = sns.pairplot(df, markers='o', size=2.2, diag_kind='hist', hue='cls')\naxes = fig.axes\naxes[0,0].set_xlim(0, 1)\naxes[0,0].set_ylim(0, 1)\naxes[1,1].set_xlim(0, 1)\naxes[1,1].set_ylim(0, 1)","53f6c5d3":"model_out = make_models_out(init_circle2)\nmodel_out.summary()","e701ae68":"models = make_modelz(img_shape, model_img_cnvt, model_gkernel, model_out)\nmodels['pre_model'].summary()","476e486d":"'''load saved weights'''\nmodels['pre_model'].load_weights('cifar10_model.h5', by_name=False)","80bcc80b":"models['pre_model'].compile(loss=focal_loss,\n                            optimizer='adam',\n                            metrics=['categorical_accuracy', 'binary_accuracy', f1])\nmodels['pre_model'].summary()","c7d1c2ad":"def lr_schedule(epoch):\n    epoch +=128\n    lr0 = 0.001\n    epoch1 = 64\n    epoch2 = 64\n    epoch3 = 64\n    epoch4 = 64\n    \n    if epoch<epoch1:\n        lr = lr0\n    elif epoch<epoch1+epoch2:\n        lr = lr0\/2\n    elif epoch<epoch1+epoch2+epoch3:\n        lr = lr0\/4\n    elif epoch<epoch1+epoch2+epoch3+epoch4:\n        lr = lr0\/8\n    else:\n        lr = lr0\/16\n    \n    if divmod(epoch,4)[1] == 3:\n        lr *= (1\/8)\n    elif divmod(epoch,4)[1] == 2:\n        lr *= (1\/4)\n    elif divmod(epoch,4)[1] == 1:\n        lr *= (1\/2)\n    elif divmod(epoch,4)[1] == 0:\n        pass\n    print('Learning rate: ', lr)\n    return lr\n\n# filepath = 'cifar10_model.{epoch:03d}.h5'\n# filepath2 = 'cifar10_model.best.h5'\n\n# checkpoint = ModelCheckpoint(filepath=filepath,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n# checkpoint2 = ModelCheckpoint(filepath=filepath2,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\n# callbacks = [checkpoint, lr_scheduler, checkpoint2]\ncallbacks = [lr_scheduler]","a7b59d86":"# hst = models['pre_model'].fit(x_train, y_cat_train,\n#                               epochs=10, batch_size=32, verbose=2)\nit = datagen.flow(x_train, y_cat_train, batch_size=128)\nhst = models['pre_model'].fit_generator(it, steps_per_epoch=len(it),\n                                        #validation_data=(x_val, y_cat_val),\n                                        epochs=64, verbose=2,\n                                        #epochs=4, verbose=2,\n                                        callbacks=callbacks)","ea5fe428":"'''merge hst_history'''\nfor k in hst.history:\n    hst_history[k].extend(hst.history[k])","6355193a":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"loss\"], label=\"Train loss\")\nax[1].set_title('acc')\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"binary_accuracy\"], label=\"binary_accuracy\")\nax[2].set_title('f1_score')\nax[2].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"f1\"], label=\"f1 score\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","697c6bf5":"models['pre_model'].save_weights('cifar10_model.h5')","dbc8531d":"init_circle3 = get_circle(nn=num_cls, rs=rs)\ninit_circle3 = init_circle3*0.4\/2 + 0.5\nprint(init_circle3)\n\ndf = pd.DataFrame(init_circle3)\ndf['cls'] = ['c'+str(ee) for ee in range(num_cls)]\ndf.head()\nfig = sns.pairplot(df, markers='o', size=2.2, diag_kind='hist', hue='cls')\naxes = fig.axes\naxes[0,0].set_xlim(0, 1)\naxes[0,0].set_ylim(0, 1)\naxes[1,1].set_xlim(0, 1)\naxes[1,1].set_ylim(0, 1)","e1591e71":"model_out = make_models_out(init_circle3)\nmodel_out.summary()","81e8d3e5":"models = make_modelz(img_shape, model_img_cnvt, model_gkernel, model_out)\nmodels['pre_model'].summary()","4f6171db":"'''load saved weights'''\nmodels['pre_model'].load_weights('cifar10_model.h5', by_name=False)","113ce75e":"models['pre_model'].compile(loss=focal_loss,\n                            optimizer='adam',\n                            metrics=['categorical_accuracy', 'binary_accuracy', f1])\nmodels['pre_model'].summary()","987a7db7":"def lr_schedule(epoch):\n    epoch += 128+64\n    lr0 = 0.001\n    epoch1 = 64\n    epoch2 = 64\n    epoch3 = 64\n    epoch4 = 64\n    \n    if epoch<epoch1:\n        lr = lr0\n    elif epoch<epoch1+epoch2:\n        lr = lr0\/2\n    elif epoch<epoch1+epoch2+epoch3:\n        lr = lr0\/4\n    elif epoch<epoch1+epoch2+epoch3+epoch4:\n        lr = lr0\/8\n    else:\n        lr = lr0\/16\n    \n    if divmod(epoch,4)[1] == 3:\n        lr *= (1\/8)\n    elif divmod(epoch,4)[1] == 2:\n        lr *= (1\/4)\n    elif divmod(epoch,4)[1] == 1:\n        lr *= (1\/2)\n    elif divmod(epoch,4)[1] == 0:\n        pass\n    print('Learning rate: ', lr)\n    return lr\n\n# filepath = 'cifar10_model.{epoch:03d}.h5'\n# filepath2 = 'cifar10_model.best.h5'\n\n# checkpoint = ModelCheckpoint(filepath=filepath,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n# checkpoint2 = ModelCheckpoint(filepath=filepath2,\n#                              monitor='val_categorical_accuracy',\n#                              verbose=1,\n#                              save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\n# callbacks = [checkpoint, lr_scheduler, checkpoint2]\ncallbacks = [lr_scheduler]","c4aa4063":"# hst = models['pre_model'].fit(x_train, y_cat_train,\n#                               epochs=10, batch_size=32, verbose=2)\nit = datagen.flow(x_train, y_cat_train, batch_size=128)\nhst = models['pre_model'].fit_generator(it, steps_per_epoch=len(it),\n                                        #validation_data=(x_val, y_cat_val),\n                                        epochs=128, verbose=2,\n                                        #epochs=4, verbose=2,\n                                        callbacks=callbacks)","ce17b348":"'''merge hst_history'''\nfor k in hst.history:\n    hst_history[k].extend(hst.history[k])","3027813a":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"loss\"], label=\"Train loss\")\nax[1].set_title('acc')\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"binary_accuracy\"], label=\"binary_accuracy\")\nax[2].set_title('f1_score')\nax[2].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"f1\"], label=\"f1 score\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","cac2afd7":"models['pre_model'].save_weights('cifar10_model.h5')","520ec2ec":"# '''load saved weights'''\n# models['pre_model'].load_weights(filepath2, by_name=False)","45e42c08":"pred_img_cnvt = model_img_cnvt.predict(x_train0, batch_size=128, verbose=1)\nprint(pred_img_cnvt.shape)\npred_img_cnvt","04d07f9e":"df = pd.DataFrame(pred_img_cnvt[:,:5])\ndf['cls'] = ['c'+str(ee) for ee in y_train0]\ndf.head()\nfig = sns.pairplot(df, markers='o', hue='cls', height=2.2, diag_kind='hist')","c0fd3b06":"df = pd.DataFrame(np.vstack([pred_img_cnvt, lm_gkernel])[:,:5])\ndf['cls'] = ['c'+str(ee) for ee in y_train0] + ['LM']*lm_gkernel.shape[0]\ndf.head()\nfig = sns.pairplot(df, markers=['.']*num_cls + ['s'], hue='cls', height=2.2, diag_kind='hist')","8ad3e06d":"y_pred0 = models['pre_model'].predict(x_train0, batch_size=128, verbose=1)\ny_pred0.shape","6c024ac3":"print(f1_score(y_train0, np.argmax(y_pred0, axis=1), average='macro'))\nprint(classification_report(y_train0, np.argmax(y_pred0, axis=1)))\nconfusion_matrix(y_train0, np.argmax(y_pred0, axis=1))","6226dd06":"y_pred_test = models['pre_model'].predict(x_test, batch_size=128, verbose=0)\ny_pred_test.shape","3e8642d3":"# print(f1_score(y_test, np.argmax(y_pred_test, axis=1), average='macro'))\n# print(classification_report(y_test, np.argmax(y_pred_test, axis=1)))\n# confusion_matrix(y_test, np.argmax(y_pred_test, axis=1))","8a946cdc":"pred_gkernel = model_gkernel.predict(pred_img_cnvt, batch_size=128, verbose=1)\nprint(pred_gkernel.shape)","6d565814":"df = pd.DataFrame(pred_gkernel)\ndf.columns = [\"comp_1\", \"comp_2\"]\ndf['cls'] = ['c'+str(ee) for ee in y_train0]\nprint(df.head())\nmatplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\nsns.lmplot(\"comp_1\", \"comp_2\", hue=\"cls\", data=df, fit_reg=False, markers='.')\n# fig = sns.pairplot(df, markers='.', hue='cls', height=2.2, diag_kind='hist')","41a0b2d2":"df = pd.DataFrame(np.vstack([pred_gkernel, init_circle3]))\ndf.columns = [\"comp_1\", \"comp_2\"]\ndf['cls'] = ['c'+str(int(ee)) for ee in y_train0] + ['LM']*(init_circle3.shape[0])\nprint(df.head())\n\nmatplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\nsns.lmplot(\"comp_1\", \"comp_2\", hue=\"cls\", data=df, fit_reg=False, markers=['.']*10 + ['s'])\n# fig = sns.pairplot(df, markers=['.']*num_cls+['s'], hue='cls', height=2.2, diag_kind='hist')","43ac4c9b":"df_pred1 = pd.DataFrame({'label': y_train0})\ndf_pred1 = pd.concat([df_pred1, pd.DataFrame(y_pred0)], axis=1)\nprint(df_pred1.shape)\ndf_pred1.to_csv('proba.csv', index=False)\ndf_pred1.head()","2b44014e":"#df_pred1_test = pd.DataFrame({'label': y_test})\ndf_pred1_test = pd.DataFrame(y_pred_test)\nprint(df_pred1_test.shape)\ndf_pred1_test.to_csv('proba_test.csv', index=False)\ndf_pred1_test.head()","ef37c3bb":"submit_csv = test_labels.copy()\nsubmit_csv.label = [id_key[ee] for ee in np.argmax(y_pred_test, axis=1)]\n\nsubmit_csv.to_csv('submit.csv', index=False)\nsubmit_csv.head()","605f81a0":"## Create model","913f7801":"## Train","26dad605":"### image_converter","753803e8":"### gkernel2","225a976a":"## Load data","a6ff4be7":"### output layer","d09121d1":"corresponding to keras 2.2"}}