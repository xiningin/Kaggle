{"cell_type":{"02136fa4":"code","60a15276":"code","1b300664":"code","45e38c37":"code","d80cd8b4":"code","dca26876":"code","b03b1b80":"code","4691170c":"code","5d5c5865":"code","c6b8a7b4":"code","145d118a":"code","f024a640":"code","41354873":"code","1fb01c73":"code","59d8f175":"code","d68562a0":"code","87a6aaa0":"code","b347eae0":"code","73942bb9":"code","8fa4080f":"code","f497bfbd":"code","24dead55":"code","4aef4ae1":"markdown","877d3c10":"markdown","5c2131ed":"markdown","3399f703":"markdown","7c95fb55":"markdown","9e059dbb":"markdown","0654947e":"markdown","ef622ea5":"markdown","cdf72fe7":"markdown","a66ecdcc":"markdown","f5a2d5d6":"markdown","75962941":"markdown"},"source":{"02136fa4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom collections import Counter\nimport category_encoders as ce\n\nfrom sklearn import preprocessing\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#about file\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","60a15276":"result_example = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/submission.csv\")\nresult_example.head(),result_example.shape","1b300664":"test = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntrain.head(3)","45e38c37":"test.head(3)","d80cd8b4":"train.shape","dca26876":"train_new = train.groupby([\"Country_Region\",\"Date\"],as_index= False).sum().drop('Id',axis = 1)\ntrain_new.shape","b03b1b80":"train[\"Date\"] = pd.to_datetime(train[\"Date\"]).dt.strftime(\"%m%d\").astype(int) \ntrain['Date'] -= 122 #because first_date = 122\ntest[\"Date\"] = pd.to_datetime(test[\"Date\"]).dt.strftime(\"%m%d\").astype(int) \ntest['Date'] -= 122","4691170c":"train['Province_State'].fillna(train['Country_Region'],inplace = True)\ntest['Province_State'].fillna(test['Country_Region'],inplace = True)","5d5c5865":"train.Country_Region","c6b8a7b4":"le = preprocessing.LabelEncoder()\n\ntrain.Country_Region = le.fit_transform(train.Country_Region)\ntrain.Province_State = le.fit_transform(train.Province_State)\ntest.Country_Region = le.fit_transform(test.Country_Region)\ntest.Province_State = le.fit_transform(test.Province_State)\n\n#scaling did not improve score\n\n#train.Country_Region = preprocessing.scale(train.Country_Region)\n#train.Province_State = preprocessing.scale(train.Province_State)\n#test.Country_Region = preprocessing.scale(test.Country_Region)\n#test.Province_State = preprocessing.scale(test.Province_State)","145d118a":"train.tail(3), test.head(3)","f024a640":"#open_period only_use data 1\/22~3\/19\nval = train[train[\"Date\"] > 196].reset_index(drop = True)\ntrain = train[train[\"Date\"] <= 196].reset_index(drop = True)\n\n#scaling Date gave bad socre!\n\n#val.Date= preprocessing.scale(val.Date)\n#train.Date= preprocessing.scale(train.Date)\n#test.Date= preprocessing.scale(test.Date)","41354873":"x_train = train.drop(['Id', 'ConfirmedCases','Fatalities'], axis = 1)\ny_train_1 = train[\"ConfirmedCases\"]\ny_train_2 = train[\"Fatalities\"]\nx_val = val.drop(['Id', 'ConfirmedCases','Fatalities'], axis = 1)\ny_val_1 = val[\"ConfirmedCases\"]\ny_val_2 = val[\"Fatalities\"]\ntrain.shape , val.shape","1fb01c73":"val.tail()","59d8f175":"import lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor","d68562a0":"def evaluate(predict,actual):\n    #eval = 0\n    #for i in range(n):\n        #eval += float(np.square( np.log(predict[i]+1) - np.log(actual[i]+1) ) )                                                \n    return np.sqrt(np.mean(np.square(np.log(predict+1) - np.log(actual+1))))","87a6aaa0":"lgbm_params = {\n   'objective': 'regression',\n    'metric': 'rmse',\n}\nlgb_train_1 = lgb.Dataset(x_train, y_train_1)\nlgb_eval_1 = lgb.Dataset(x_val, y_val_1, reference=lgb_train_1)\n\nlgb_model_1 = lgb.train(lgbm_params,lgb_train_1, valid_sets=lgb_eval_1,num_boost_round=10000)\ny_pred_1 = lgb_model_1.predict(x_val, num_iteration = lgb_model_1.best_iteration)\n\nlgb_train_2 = lgb.Dataset(x_train, y_train_2)\nlgb_eval_2 = lgb.Dataset(x_val, y_val_2, reference=lgb_train_2)\n\nlgb_model_2 = lgb.train(lgbm_params,lgb_train_2, valid_sets=lgb_eval_2,num_boost_round=5000)\ny_pred_2 = lgb_model_1.predict(x_val, num_iteration = lgb_model_2.best_iteration)\n\nevaluate(y_pred_1,y_val_1), evaluate(y_pred_2,y_val_2),evaluate(y_pred_1,y_val_1)+evaluate(y_pred_2,y_val_2)\n","b347eae0":"lgb_model_3= lgb.LGBMRegressor(n_estimators=3000)\nlgb_model_3.fit(x_train,y_train_1)\ny_pred_1 = lgb_model_3.predict(x_val)\nlgb_model_4= lgb.LGBMRegressor(n_estimators=3000)\nlgb_model_4.fit(x_train,y_train_2)\ny_pred_2 = lgb_model_4.predict(x_val)\n\nevaluate(y_pred_1,y_val_1), evaluate(y_pred_2,y_val_2),evaluate(y_pred_1,y_val_1)+evaluate(y_pred_2,y_val_2)","73942bb9":"xgb_model_1= XGBRegressor(n_estimators = 4000)\nxgb_model_1.fit(x_train,y_train_1)\ny_pred_1 = xgb_model_1.predict(x_val)\nxgb_model_2= XGBRegressor(n_estimators = 4000)\nxgb_model_2.fit(x_train,y_train_2)\ny_pred_2 = xgb_model_2.predict(x_val)\n\nevaluate(y_pred_1,y_val_1), evaluate(y_pred_2,y_val_2),evaluate(y_pred_1,y_val_1) + evaluate(y_pred_2,y_val_2)","8fa4080f":"random_forest_1=RandomForestRegressor(bootstrap=True, \n            max_depth=25, max_features='auto', max_leaf_nodes=None,\n            min_samples_leaf=1, min_samples_split=15,\n            min_weight_fraction_leaf=0.0, n_estimators=150, \n            random_state=0, verbose=0, warm_start=False)\nrandom_forest_1.fit(x_train,y_train_1)\nrandom_forest_1 = xgb_model_1.predict(x_val)\n\nrandom_forest_2=RandomForestRegressor(bootstrap=True, \n            max_depth=25, max_features='auto', max_leaf_nodes=None,\n            min_samples_leaf=1, min_samples_split=15,\n            min_weight_fraction_leaf=0.0, n_estimators=150, \n            random_state=0, verbose=0, warm_start=False)\nrandom_forest_2.fit(x_train,y_train_2)\ny_pred_2 = random_forest_2.predict(x_val)\nevaluate(y_pred_1,y_val_1), evaluate(y_pred_2,y_val_2),evaluate(y_pred_1,y_val_1)+evaluate(y_pred_2,y_val_2)","f497bfbd":"x_test = test.drop(['ForecastId'],axis = 1)\nans_1 =xgb_model_1.predict(x_test)\nans_2 = xgb_model_2.predict(x_test)","24dead55":"test[\"ConfirmedCases\"] = ans_1.astype(int)\ntest[\"Fatalities\"] = ans_2.astype(int)\ntest.drop([\"Date\",\"Country_Region\",\"Province_State\"],axis = 1,inplace = True)\ntest.to_csv(\"submission.csv\",index = False)","4aef4ae1":"## Data_cleaning","877d3c10":"# Predict & Submit","5c2131ed":"### XGB","3399f703":"### Random_forest","7c95fb55":"## evaluation","9e059dbb":"# Data","0654947e":"## library for data","ef622ea5":"### lgb_model","cdf72fe7":"## library for machine_learning","a66ecdcc":"### train_new.shape < train.shape\nso, 'train_new' is not meaningful in this competition.","f5a2d5d6":"# Machine_learning","75962941":"## read_dataset and easy_looking"}}