{"cell_type":{"9eb6fe99":"code","1ef118d2":"code","2094823e":"code","e31b445a":"code","e2abaa30":"code","a70f8d28":"code","241bce02":"code","253b144f":"code","0af351a4":"code","d496fb4c":"code","4f0e43f5":"code","ed53d662":"code","0ef97531":"code","e967bfa9":"code","0b6c30ef":"code","3dae7684":"code","b7b5cf35":"code","008aeb20":"code","197bd3b5":"code","9b8675a4":"markdown","9765a232":"markdown","5a7aa32d":"markdown"},"source":{"9eb6fe99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ef118d2":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)","2094823e":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","e31b445a":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","e2abaa30":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","a70f8d28":"# Look at page 2\npdf = os.path.join(outputFolder,'DSInterview1.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/DSInterview1.jpg') # intro page to preview later","241bce02":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/DSInterview1.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","253b144f":"# Plot WordCloud of page 2\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 2 of DSInterview1\")","0af351a4":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/DSInterview1.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","d496fb4c":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 2 to 5 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p2\npdf = os.path.join(outputFolder,'DSInterview1.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/DSInterview1.jpg')\npdfimage2 = Image.open('\/kaggle\/working\/DSInterview1.jpg')","4f0e43f5":"# PDF to JPG for p4\npdf = os.path.join(outputFolder,'DSInterview1.pdf[4]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/DSInterview1.jpg')\npdfimage4 = Image.open('\/kaggle\/working\/DSInterview1.jpg')\n\n# PDF to JPG for p5\npdf = os.path.join(outputFolder,'DSInterview1.pdf[5]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/DSInterview1.jpg')\npdfimage5 = Image.open('\/kaggle\/working\/DSInterview1.jpg')","ed53d662":"# Parse a PDF file and convert it to CSV using PyTesseract (p2)\ntext = pytesseract.image_to_string(pdfimage2)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","0ef97531":"# Parse a PDF file and convert it to CSV using Tika-Python (p2-5)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/DSInterview1.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/DSInterview1.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 2-5","e967bfa9":"#Explore page 5 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage5.size # crop image\npdfimage5.crop((0, 1240, w, h-1300)) # display exerpt of PDF","0b6c30ef":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 2 to 5 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p2\npdf = os.path.join(outputFolder,'DSInterview1.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/DSInterview1.jpg')\npdfimage2 = Image.open('\/kaggle\/working\/DSInterview1.jpg')","3dae7684":"#Explore page 2 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 54 pages \nw, h = pdfimage2.size # crop image\npdfimage2.crop((0, 1240, w, h-1300)) # display exerpt of PDF","b7b5cf35":"# Pages 2, 4 and 5\ndfcombined.head() # preview csv of 2-5","008aeb20":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","197bd3b5":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here' )","9b8675a4":"#PDF to CSV\n\nConvert Page 2 of PDF to CSV (Method 1 of 2: PyTesseract)","9765a232":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRiSo0-KoRFWgAQD8YZrwK1neOqu4cv5PJYtQ&usqp=CAU)datasciencebee.com","5a7aa32d":"#Codes by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook"}}