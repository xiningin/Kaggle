{"cell_type":{"0c7d0530":"code","2181b958":"code","1fb833c9":"code","8b5481f5":"code","f8104494":"code","77af90f5":"code","6cd9a5fd":"code","cf92d532":"code","0d1657b3":"code","ca9bc541":"code","8c23331c":"code","5fdb13cd":"code","c43c2b83":"markdown","c4ad4b77":"markdown","7175342e":"markdown","8efb013f":"markdown"},"source":{"0c7d0530":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm import notebook\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport copy\nfrom sklearn.ensemble import RandomForestClassifier\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","2181b958":"#loading dataframe\ndf = pd.read_csv(dirname + \"\/train.csv\")\ndf.head()\n","1fb833c9":"def get_data(data):\n    # take only this specific column\n    data = data[['Age', 'Sex', 'Fare', 'Pclass', 'SibSp', 'Parch']]\n    \n    # replace male by 1, female by 0\n    data.replace({ 'male' : 1, 'female' : 0 }, inplace=True)\n    \n    # replace null\/nan data by the mean (age and fare columns)\n    data['Fare'].fillna(int(data['Fare'].mean()), inplace=True)\n    data['Age'].fillna(int(data['Age'].mean()), inplace=True)\n    \n    \n    # transform into a numpy array\n    data = data.to_numpy()\n    \n    # normalize (make sure the data is between -1 and 1)\n    for i in range(data.shape[1]):\n        data[:,i] = (data[:,i] - data[:,i].mean()) \/ data[:,i].std()\n    \n    return data","8b5481f5":"# lets take out first the label\ny=df['Survived'].values\n#print(y.shape)-->(891,)\n#y_binarized is used just stratifying the data in train_test_split\n#df['Survived'].value_counts(normalize=True)#ensures all 0,1's are in equal ratio\n#y_binarized=df['Survived'].values\n#print(y_binarized)\n\n#loading data into x\nx= get_data(df)\n#print(x.shape)--->(891,6)\n\n#splitting data for evaluation and training  x_train,y_train --->training purpose y_test,x_test--->valuation purpose\n#x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,stratify=y_binarized)\n#print(x_train.shape)-->(668,6)\n#print(x_test.shape)-->(223,6)\n#print(y_train.shape)-->(668,)\n#print(y_test.shape)-->(223,)\n\n#converting numpy arrays into tensors using pytorch\nx_torch_train=torch.from_numpy(x)\ny_torch_trian=torch.from_numpy(y)\n#x_torch_test=torch.from_numpy(x_test)\n#y_torch_test=torch.from_numpy(y_test)","f8104494":"#This class is used to to create above network\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        torch.manual_seed(0)\n        self.net=nn.Sequential(\n                                nn.Linear(6,512),\n                                nn.Sigmoid(),\n                                nn.Linear(512,256),\n                                nn.Sigmoid(),\n                                nn.Linear(256,1),\n                                nn.Sigmoid()\n                                )\n    def forward(self,X):\n        return self.net(X)[:,0]\n    #Fit function is used to iterate over train data and update parameters    \n    def fit(self,X,Y,optimizer=0,loss_fn=nn.BCELoss(),epochs=1000):\n        loss_arr=[]\n        min_loss=8\n        if optimizer == 0:\n            optimizer=optim.Adam(self.net.parameters(),lr=0.00125)\n        for i in notebook.tqdm(range(epochs),total=epochs,unit='epoch'):\n            loss=loss_fn(self(X),Y)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            loss_arr.append(loss.item())\n            if min_loss > loss.item():\n                min_loss = loss.item()\n                best_model = copy.deepcopy(self.state_dict())\n        print('========================')\n        print('     Min loss %0.2f' % min_loss)\n        print('========================')\n        self.load_state_dict(best_model)\n        return loss_arr\n    #calaculate accuracy after training the data\n    def accuracy(self,X,Y):\n        correct=0\n        total=0\n        bin_train=self(X)\n        bin_train=(bin_train>0.5).int()\n        Y=Y.int()\n        for i,j in zip(bin_train,Y):\n            total+=1\n            if i==j:\n                correct+=1\n        accuracy=100*(correct\/total)\n        print('total =',total)\n        print('correct predictions =',correct)\n        print('accuracy =',round(accuracy,2))","77af90f5":"#intializing model and moving all data to gpu\nmodel=Network()\ndevice=torch.device(\"cuda\")\nprint(device)\nx_torch_train=x_torch_train.to(device)\ny_torch_trian=y_torch_trian.to(device)\n#x_torch_test=x_torch_test.to(device)\n#y_torch_test=y_torch_test.to(device)\nmodel.to(device)","6cd9a5fd":"#loss_fn=nn.BCELoss()\noptimizer=optim.SGD(model.parameters(),lr=1)#---->#specifiy learning rate if you prefer using lr=learning_rate_value\nlosslist=model.fit(x_torch_train.float(),y_torch_trian.float(),epochs=10000)\nprint('----------Train Accuracy---------- ')\nmodel.accuracy(x_torch_train.float(),y_torch_trian.float())\nprint('----------Test  Accuracy---------- ')\nmodel.accuracy(x_torch_test.float(),y_torch_test.float())\nplt.plot(losslist)\nplt.show()","cf92d532":"test_df = pd.read_csv(dirname + \"\/test.csv\")\ntest_x = get_data(test_df)\ntorch_test_x=torch.from_numpy(test_x)\ntorch_test_x=torch_test_x.to(device)","0d1657b3":"# Get test data predictions\ntest_preds =model(torch_test_x.float())\ntest_preds=(test_preds>0.5).int()\ntest_preds=test_preds.tolist()\n","ca9bc541":"# Add passengers ids to the test predictions\npassenger_ids = test_df['PassengerId'].to_numpy()","8c23331c":"# combine passenger ids with the predictions\nfinal_result = np.array(list(map(list, zip(passenger_ids,test_preds))))","5fdb13cd":"# arraay final_result to dataframe\ndf_final = pd.DataFrame(data=final_result, columns=[\"PassengerId\", \"Survived\"])\n# save the result\n#df_final.tail()\ndf_final.to_csv('submission_final13.csv', index=False)","c43c2b83":"# Make predictions on test DATA","c4ad4b77":"# Neural Network\n### Network consists of 10 layers: \n        1)Linear(in_features=6, out_features=512, bias=True)\n        2)ELU(alpha=1.0)\n        3)Linear(in_features=512, out_features=128, bias=True)\n        4)ELU(alpha=1.0)\n        5)Linear(in_features=128, out_features=18, bias=True)\n        6)ELU(alpha=1.0)\n        7)Linear(in_features=18, out_features=6, bias=True)\n        8)ELU(alpha=1.0)\n        9)Linear(in_features=6, out_features=1, bias=True)\n        10)Sigmoid()\n***Loss Function*** is ***Binary CrossEntropyLoss(BCELoss)***<br>\n***Optimization Function*** is ***Adam() with learning rate=0.00125***(given manually)","7175342e":"### Training The model","8efb013f":"### Analyze Data"}}