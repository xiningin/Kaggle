{"cell_type":{"026445dd":"code","1257438b":"code","0d986946":"code","f4f7260c":"code","0eb51d06":"code","548f2293":"code","f6e56189":"code","c25bbb68":"code","aa464f49":"code","7cab1cb1":"code","975c193a":"code","b2ec4d86":"code","13255f04":"code","dccf28c2":"code","f35e051f":"code","a1b850eb":"code","d7a078aa":"code","8516f7bd":"code","4f5c6c16":"code","4121e2bf":"code","13ad4217":"code","2d3f3265":"code","a3dfab76":"code","a57ac49f":"code","079c3781":"code","a4e118f4":"code","cec24d65":"code","a8b530ea":"code","9d072df3":"code","c33501e2":"code","7028d0c2":"code","f17a0817":"code","9bf321d7":"code","b38e5373":"code","65d3361a":"code","a5f80775":"code","91cd8e1f":"code","328388b9":"code","78e6fb78":"code","4ab89025":"code","c47a7785":"code","6898a595":"code","bc21d2e0":"code","beaa5a31":"code","60e65449":"code","7c12e955":"code","b728d72a":"code","ec745bb5":"code","b20f58fe":"code","5f1c30fb":"markdown","0ecc5998":"markdown","f6245a02":"markdown","58ae5034":"markdown","e2201325":"markdown","fd5dcd20":"markdown","93853c26":"markdown","60890853":"markdown","2d4fb2f8":"markdown","7bd256c1":"markdown","2fde036e":"markdown","ddf78a72":"markdown","4198f815":"markdown","0cddb481":"markdown","99666b26":"markdown","91754fa6":"markdown","7e14e088":"markdown","077e0cad":"markdown","1b0d2229":"markdown","ac7ba00c":"markdown","231a2ac4":"markdown","bc78f243":"markdown","6d71b493":"markdown","0a62ce0d":"markdown","03f07e21":"markdown","3262f433":"markdown"},"source":{"026445dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1257438b":"import numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns","0d986946":"import pandas as pd\nimport io\nimport requests \nimport datetime","f4f7260c":"df = pd.read_csv('..\/input\/new-tata-dataset\/NSE-TATAGLOBAL.csv')\ndf.head()","0eb51d06":"df1 = pd.read_csv('..\/input\/new-tata-dataset\/NSE-TATAGLOBAL.csv')\ndf1.head()","548f2293":"df.shape","f6e56189":"df.info()","c25bbb68":"df.describe()","aa464f49":"df.dtypes","7cab1cb1":"missing_values_count = df.isnull().sum()\n\ntotal_cells = np.product(df.shape)\n\ntotal_missing = missing_values_count.sum()\n\npercentage_missing = (total_missing\/total_cells)*100\n\nprint(percentage_missing)","975c193a":"NAN = [(c, df[c].isnull().mean()*100) for c in df]\nNAN = pd.DataFrame(NAN, columns=['column_name', 'percentage'])\nNAN","b2ec4d86":"sns.set(rc = {'figure.figsize': (20, 5)})\ndf['Open'].plot(linewidth = 1,color='blue')","13255f04":"df.columns","dccf28c2":"cols_plot = ['Open','High','Low','Last','Close']\naxes = df[cols_plot].plot(alpha = 1, figsize=(20, 30), subplots = True)\n\nfor ax in axes:\n    ax.set_ylabel('Variation')","f35e051f":"df[\"Date\"]=pd.to_datetime(df.Date,format=\"%Y-%m-%d\")\ndf.index=df['Date']\ndf","a1b850eb":"del df[\"Date\"]","d7a078aa":"df.dtypes","8516f7bd":"df.rolling(7).mean().head(10)","4f5c6c16":"df['Open'].plot(figsize=(20,8),alpha = 1)\ndf.rolling(window=30).mean()['Close'].plot(alpha = 1)","4121e2bf":"df['Close: 30 Day Mean'] = df['Close'].rolling(window=30).mean()\ndf[['Close','Close: 30 Day Mean']].plot(figsize=(20,8),alpha = 1)","13ad4217":"df['Close'].expanding(min_periods=1).mean().plot(figsize=(20,8),alpha = 1)","2d3f3265":"df2=df1.reset_index()['Open']\ndf2","a3dfab76":"plt.plot(df2)","a57ac49f":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\ndf2=scaler.fit_transform(np.array(df2).reshape(-1,1))\nprint(df2)","079c3781":"train_size=int(len(df2)*0.75)\ntest_size=len(df2)-train_size\ntrain_data,test_data=df2[0:train_size,:],df2[train_size:len(df2),:1]","a4e118f4":"train_size,test_size","cec24d65":"train_data,test_data","a8b530ea":"def create_dataset(dataset, time_step=1):\n    train_X, train_Y = [], []\n    for i in range(len(dataset)-time_step-1):\n        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n        train_X.append(a)\n        train_Y.append(dataset[i + time_step, 0])\n    return numpy.array(train_X), numpy.array(train_Y)","9d072df3":"import numpy\ntime_step = 100\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, ytest = create_dataset(test_data, time_step)","c33501e2":"print(X_train.shape), print(y_train.shape)","7028d0c2":"X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","f17a0817":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","9bf321d7":"model=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')","b38e5373":"model.summary()","65d3361a":"model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)","a5f80775":"import tensorflow as tf","91cd8e1f":"train_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","328388b9":"train_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)","78e6fb78":"import math\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train,train_predict))","4ab89025":"math.sqrt(mean_squared_error(ytest,test_predict))","c47a7785":"look_back=100\ntrainPredictPlot = numpy.empty_like(df1)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict","6898a595":"testPredictPlot = numpy.empty_like(df1)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict","bc21d2e0":"pred  = scaler.inverse_transform(df2)\nplt.plot(pred,color='blue')\nplt.show()","beaa5a31":"plt.plot(trainPredictPlot,color='red')\nplt.show()\nplt.plot(testPredictPlot,color='green')\nplt.show()","60e65449":"plt.plot(trainPredictPlot,color='red')\nplt.plot(testPredictPlot,color='green')\nplt.show()","7c12e955":"plt.plot(pred,color='blue')\nplt.plot(trainPredictPlot,color='red')\nplt.plot(testPredictPlot,color='green')\nplt.show()","b728d72a":"len(test_data)","ec745bb5":"x_input=test_data[341:].reshape(1,-1)\nx_input.shape","b20f58fe":"model.save(\"saved_model.h5\")","5f1c30fb":"## Import Datasets","0ecc5998":"## splitting dataset into train and test split","f6245a02":"## Lets Do the prediction and check performance metrics","58ae5034":"# NSE-TATAGLOBAL DATASETS","e2201325":"## Calculate RMSE performance metrics","fd5dcd20":"### Total percentage of data is missing","93853c26":"## Save the Model","60890853":"## Create the Stacked LSTM model","2d4fb2f8":"### To build the stock price prediction model, we will use the NSE TATA GLOBAL dataset. This is a dataset of Tata Beverages from Tata Global Beverages Limited, National Stock Exchange of India: Tata Global Dataset","7bd256c1":"## LSTM are sensitive to the scale of the data. so we apply MinMax scaler","2fde036e":"## reshape input to be [samples, time steps, features] which is required for LSTM","ddf78a72":"## shift test predictions for plotting","4198f815":"## Data Cleaning","0cddb481":"## Sort the dataset on date time and filter \u201cDate\u201d and \u201cOpen\u201d columns","99666b26":"# Stock Market Prediction And Forecasting Using Stacked LSTM\n","91754fa6":"## Shape of data","7e14e088":"# Data Visualisation","077e0cad":"## 7 day rolling mean","1b0d2229":"## Optional specify a minimum numbe2of periods","ac7ba00c":"## convert an array of values into a dataset matrix","231a2ac4":"## shift train predictions for plotting","bc78f243":"## Gathering information about the data","6d71b493":"## plot baseline and predictions","0a62ce0d":"## reshape into X=t,t+1,t+2,t+3 and Y=t+4","03f07e21":"## Test Data RMSE","3262f433":"## Import Libraries"}}