{"cell_type":{"79f5dfb2":"code","c651a572":"code","f9b9bd25":"code","9e434741":"code","3b48d495":"code","2611ef5f":"code","7cfcef52":"code","c31bc64a":"code","68cd6ad0":"code","8da8829f":"code","7e0b683a":"code","be14477c":"code","8c47329c":"code","a0d1ddf1":"code","b15227bb":"code","013a0541":"code","7ba84f97":"code","8d3c1aae":"code","a5b917c1":"code","95ce1fe5":"code","b989fe24":"code","2765e64a":"code","5fa1bf35":"code","a9a4cc4f":"code","e82d039b":"code","e8134f87":"code","414f943f":"code","9dc63410":"code","00985c3e":"code","7422b6aa":"code","facbdbd8":"code","06780709":"code","c2f40124":"code","42348b36":"code","28935901":"code","affdb7e3":"code","f00a9ecc":"code","f722d864":"code","3714ed18":"code","6b2df3b1":"code","243ce291":"code","8766737b":"code","55798ac1":"code","e83a8a77":"code","28564003":"code","67f13d8b":"code","319df476":"code","7281b221":"code","62244284":"markdown","9d22c404":"markdown","ab533bd8":"markdown","d3c86865":"markdown","dd114854":"markdown","a748e2ef":"markdown","722a9416":"markdown","6b09f71b":"markdown","c261c3d8":"markdown","227ebdb3":"markdown","c1864609":"markdown","f5a866e7":"markdown","5a6f6c2e":"markdown","6b3ef37d":"markdown","3e066a1b":"markdown"},"source":{"79f5dfb2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport string\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n\n","c651a572":"data=pd.read_csv(\"..\/input\/fake-news-classifier-data\/test.csv\")\n","f9b9bd25":"data","9e434741":"data.head()","3b48d495":"data.info()","2611ef5f":"data.describe()","7cfcef52":"data.value_counts","c31bc64a":"data.dtypes","68cd6ad0":"data.shape","8da8829f":"data.columns","7e0b683a":"data.isnull().sum()","be14477c":"data.isnull().any()","8c47329c":"###Drop Nan Values\ndata=data.dropna()\n","a0d1ddf1":"data.isnull().sum()","b15227bb":"## Get the Independent Features\n\nX=data.drop('id',axis=1)\n","013a0541":"y=data['id']\n","7ba84f97":"y.value_counts()\n","8d3c1aae":"X.shape","a5b917c1":"y.shape","95ce1fe5":"plt.style.use(\"default\")\nsns.barplot(x=\"id\", y=\"title\",data=data[180:190])\nplt.title(\"ID vs TITLE\",fontsize=15)\nplt.xlabel(\"ID\")\nplt.ylabel(\"TITLE\")\nplt.show()\n\n\n","b989fe24":"data.columns","2765e64a":"sns.set_palette(\"Paired\")\nsns.pairplot(data,hue='text',height=5,palette='colorblind')\nplt.show()\n","5fa1bf35":"plt.figure(figsize=(14,10))\nsns.set_style(style='whitegrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='id',data=data)\n\n","a9a4cc4f":"sns.pairplot(data=data)","e82d039b":"import tensorflow as tf\n","e8134f87":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\n\n","414f943f":"### Vocabulary size\nvoc_size=5000\n","9dc63410":"messages=X.copy()\n","00985c3e":"messages.reset_index(inplace=True)\n\n","7422b6aa":"import nltk\nimport re\nfrom nltk.corpus import stopwords","facbdbd8":"nltk.download('stopwords')\n","06780709":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n","c2f40124":"corpus","42348b36":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","28935901":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)\n","affdb7e3":"embedded_docs[0]\n","f00a9ecc":"## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='mae',optimizer='adam',metrics=['accuracy'])\n\n","f722d864":"model.summary()","3714ed18":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)\n","6b2df3b1":"X_final.shape,y_final.shape","243ce291":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=42)\n","8766737b":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=256)\n","55798ac1":"from tensorflow.keras.layers import Dropout\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='mae',optimizer='adam',metrics=['accuracy'])","e83a8a77":"y_pred=model.predict(X_test)\n","28564003":"y_pred","67f13d8b":"print((y_pred > 0.5))\n","319df476":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes = True)\n","7281b221":"model.summary()","62244284":"**LSTM**","9d22c404":"# IMPORTING THE LIBRARIES","ab533bd8":"***So now we can see all the null values have been dropped .***","d3c86865":"# FAKE NEWS CLASSIFIER ","dd114854":"***So we have to drop the null values .***","a748e2ef":"**With Dense we can also use Dropout and Batch Normalization**","722a9416":"**NLTK**","6b09f71b":"# LOADING THE DATASET","c261c3d8":"**Types of Loss Functions:**\n\n**1) Mean Squared Error**\n\n**2) Regression Loss Function**\n\n**3) Mean Absolute Error Loss**\n\n**4) Binary Classification Loss Function**\n\n**5) Binary Cross Entropy Loss**\n","227ebdb3":"# **Exploratory Data Analysis**","c1864609":"# **Checking Null Values**","f5a866e7":"**Types of Activation Functions:**\n\n**1) Relu**\n\n**2) Sigmoid**\n\n**3) Threshold**\n\n**4) Hyperbolic Tangent**","5a6f6c2e":"**Types of Optimizers:**\n\n**1) Gradient Descent (GD)**\n\n**2) Stochastic Gradient Descent**\n\n**3) Mini-Batch Gradient Descent**\n\n**4) Adagrad**\n\n**5) RMSProp**\n\n\n\n","6b3ef37d":"**Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.**","3e066a1b":"**MODEL CREATION**"}}