{"cell_type":{"853d5e54":"code","9423f3c8":"code","2ed52cfb":"code","7206221e":"code","176b202d":"code","1e02174a":"code","a0c25c71":"code","949ad723":"code","4e5f7bb0":"code","3342b5b9":"code","c6e0b7a6":"code","badd1076":"code","0796a7b4":"code","10db31c3":"code","5cc28b04":"code","de607ad1":"code","0e2b1de0":"code","c075e8d9":"code","ac6f01d1":"code","38ddf8b4":"code","20391f59":"code","b515e05a":"markdown","0313e07d":"markdown","d86139e4":"markdown","ffb511e0":"markdown","2749ac5c":"markdown","7f057b88":"markdown","a7f6fa24":"markdown","3c2aff1d":"markdown"},"source":{"853d5e54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9423f3c8":"df=pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head().T","2ed52cfb":"df.shape","7206221e":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport math","176b202d":"plt.figure()\ndf.hist(rwidth=0.9)\nplt.tight_layout()","1e02174a":"sns.countplot(x=df['quality'])","a0c25c71":"df['quality'] = [1 if i > 6 else 0 for i in df['quality']]\nsns.countplot(x=df['quality'])","949ad723":"from pandas.plotting import scatter_matrix\nattr=list(df.columns)","4e5f7bb0":"scatter_matrix(df[attr],figsize=(200,150))\nplt.tight_layout()","3342b5b9":"df.corr()","c6e0b7a6":"#df=df.drop(['residual sugar','free sulfur dioxide','pH'],axis=1)","badd1076":"df.isnull().sum()","0796a7b4":"matrix = np.triu(df.corr())\nsns.heatmap(df.corr(), annot = True, fmt='.1g',vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',mask=matrix)","10db31c3":"from sklearn.model_selection import train_test_split\nX = df.drop(['quality'], axis=1)\ny = df['quality']\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=.20, random_state=42)","5cc28b04":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(X_train)\n\n# transform training data\nX_train = norm.transform(X_train)\n\n# transform testing dataabs\nX_test = norm.transform(X_test)","de607ad1":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier()\n","0e2b1de0":"# For Hyper-parameter Tuning the model\nfrom sklearn.model_selection import GridSearchCV\n\n# For checking Model Performance\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import learning_curve\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\")\n\nfrom sklearn.model_selection import StratifiedKFold","c075e8d9":"\ncv_method = StratifiedKFold(n_splits=3)\nparam={'n_neighbors':(1,3,5,7),'weights': ('uniform','distance'),'metric':('euclidean','manhattan','chebyshev','minkowski','wminkowski','seuclidean','mahalanobis'),'p' :(1,2)}\nclf = GridSearchCV(neigh, param,cv=cv_method,scoring=\"accuracy\")\nclf.fit(X_train,Y_train)","ac6f01d1":"clf.best_params_","38ddf8b4":"knn = KNeighborsClassifier(n_neighbors= 5, p= 1, weights='distance',metric= 'euclidean')\nknn.fit(X_train,Y_train)\nknn.score(X_test,Y_test)","20391f59":"pred = knn.predict(X_test)\nprint(\"Classification Report\")\nprint(classification_report(Y_test, pred))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(Y_test, pred), annot=True, ax = ax);\n\n# labels, title and ticks\nax.set_xlabel(\"Predicted labels\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion Matrix\")\nax.xaxis.set_ticklabels([\"bad\", \"good\"])","b515e05a":"# input data","0313e07d":"# feature scaling\n\nFeature scaling is a method used to normalize the range of independent variables or features of data.","d86139e4":"# setting threshold for quality\n\ngood= >6\nbad= <6","ffb511e0":"# Explore dataset","2749ac5c":"# cheking performance measures","7f057b88":"# splitting dataset","a7f6fa24":"# KNN classifier","3c2aff1d":"# Hyper parameter tuning"}}