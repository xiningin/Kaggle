{"cell_type":{"418a04da":"code","7a63bb8b":"code","1a636f46":"code","79353e1a":"code","a8804b64":"code","9dfe5881":"code","328dbdd9":"code","c244d57c":"code","748ba2ac":"code","5723e687":"code","9422074c":"code","5b7d6311":"code","ce1bd8cf":"code","5b204656":"code","b9a95eb0":"code","072fd3aa":"code","567fc430":"markdown","3a70b29b":"markdown","e093fcb1":"markdown","3512ba68":"markdown","b48fe667":"markdown","b7bd3bcb":"markdown","c54c4a8f":"markdown","70e48d64":"markdown"},"source":{"418a04da":"import numpy as np\nimport pandas as pd\nimport os\nimport holidays\n\nimport optuna\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (12, 6)","7a63bb8b":"DATA_PATH = '..\/input\/tabular-playground-series-jan-2022\/'\nTRAIN_PATH = DATA_PATH + 'train.csv'\nTEST_PATH = DATA_PATH + 'test.csv'\nPURCHASING_POWER_PATH = '..\/input\/purchasing-power-of-norway-sweden-finland\/purchasing_power.csv' # purchasing power index\nCOST_OF_LIVING_PATH = '..\/input\/cost-of-living-index-norway-sweden-finland\/cost_of_living.csv' # cost of living index\nQUALITY_OF_LIFE_PATH = '..\/input\/quality-of-life-norway-sweden-finland\/quality_of_life.csv' # quality of life index\nGDP_PATH = '..\/input\/gdp-20152019-finland-sweden-norway\/gdp.csv'\n\nTARGET_COLUMN = 'num_sold'","1a636f46":"def SMAPE(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.mean(np.abs(y_true - y_pred) \/ (y_true + np.abs(y_pred))) * 200","79353e1a":"purchasing_power = pd.read_csv(PURCHASING_POWER_PATH)\ncost_of_living = pd.read_csv(COST_OF_LIVING_PATH)\nquality_of_life = pd.read_csv(QUALITY_OF_LIFE_PATH)\ngdp = pd.read_csv(GDP_PATH)","a8804b64":"def preprocess_dataset(dataset):\n    dataset['date'] = pd.to_datetime(dataset['date'])\n    \n    dataset['day'] = dataset['date'].dt.day\n    dataset['month'] = dataset['date'].dt.month\n    dataset['weekday'] = dataset['date'].dt.weekday\n    dataset['year'] = dataset['date'].dt.year\n    \n    dataset = pd.merge(dataset, purchasing_power, on=['year', 'country'], how='left')\n    dataset = pd.merge(dataset, quality_of_life, on=['year', 'country'], how='left')\n    dataset = pd.merge(dataset, cost_of_living, on=['year', 'country'], how='left')\n    dataset = pd.merge(dataset, gdp, on=['year', 'country'], how='left')\n    \n    return dataset","9dfe5881":"train_data = pd.read_csv(TRAIN_PATH)\ntest_data = pd.read_csv(TEST_PATH)\n\ntrain_data = train_data.drop(['row_id'], axis=1)\n\ntrain_data = preprocess_dataset(train_data)\ntest_data = preprocess_dataset(test_data)","328dbdd9":"train_data.head()","c244d57c":"finland_holidays = holidays.Finland()['2015-01-01': '2019-12-31']\nfinland_holidays_df = pd.DataFrame({'date': pd.to_datetime(finland_holidays), 'country': 'Finland',\n                                    'holiday': 1})\n\nnorway_holidays = holidays.Norway()['2015-01-01': '2019-12-31']\nnorway_holidays_df = pd.DataFrame({'date': pd.to_datetime(norway_holidays), 'country': 'Norway',\n                                    'holiday': 1})\n\nsweden_holidays = holidays.Sweden()['2015-01-01': '2019-12-31']\nsweden_holidays_df = pd.DataFrame({'date': pd.to_datetime(sweden_holidays), 'country': 'Sweden',\n                                    'holiday': 1})\n\nholidays_df = holidays_df = pd.concat([finland_holidays_df, norway_holidays_df, sweden_holidays_df])","748ba2ac":"holidays_df.head()","5723e687":"X_public = train_data.drop([TARGET_COLUMN], axis=1)\ny_public = train_data[TARGET_COLUMN]\n\nX_public = pd.merge(X_public, holidays_df, on=['date', 'country'], how='outer')\n\nX_public = X_public.drop(['date'], axis=1)\nX_public = pd.get_dummies(X_public)\nX_public = X_public[X_public.day.notna()].fillna(0)\n\nprint(X_public.shape)\nX_public.tail()","9422074c":"def objective(trial):\n    kfold = KFold(n_splits=5)\n    \n    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n    max_depth = trial.suggest_int('max_depth', 3, 10)\n    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n    subsample = trial.suggest_float('subsample', 0.5, 1)\n    reg_lambda = trial.suggest_float('reg_lambda', 0, 2)\n    reg_alpha = trial.suggest_float('reg_alpha', 0, 2)\n    \n    loss_history = []\n    for train_index, test_index in kfold.split(X_public):\n        X_train, y_train = X_public.iloc[train_index], np.log(y_public.iloc[train_index])\n        X_test, y_test = X_public.iloc[test_index], np.log(y_public.iloc[test_index])\n        \n        xgb_regressor = XGBRegressor(learning_rate=learning_rate,\n                                max_depth=max_depth,\n                                min_child_weight=min_child_weight,\n                                subsample=subsample,\n                                reg_lambda=reg_lambda,\n                                reg_alpha=reg_alpha,\n                                objective='reg:squarederror')\n        \n        xgb_regressor.fit(X_train, y_train)\n        loss_history.append(SMAPE(xgb_regressor.predict(X_test), y_test))\n        \n    return np.mean(loss_history)","5b7d6311":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=100)","ce1bd8cf":"X_train, X_test, y_train, y_test = train_test_split(X_public, y_public, random_state=42, test_size=0.2)\n\nxgb_regressor = XGBRegressor(**study.best_params)\nxgb_regressor.fit(X_train, np.log(y_train))","5b204656":"SMAPE(np.exp(xgb_regressor.predict(X_test)), y_test)","b9a95eb0":"X_private = test_data.drop(['row_id'], axis=1)\nids = test_data['row_id']\n\nX_private = pd.merge(X_private, holidays_df, on=['date', 'country'], how='outer')\n\nX_private = X_private.drop(['date'], axis=1)\nX_private = pd.get_dummies(X_private)\nX_private = X_private[X_private.day.notna()].fillna(0)\n\nprint(X_private.shape)\nX_private.sample(5)","072fd3aa":"boosting_prediction = np.round(np.exp(xgb_regressor.predict(X_private)))\n\npredictions = boosting_prediction\npd.DataFrame({'row_id': ids, 'num_sold': predictions}).set_index('row_id').to_csv('predictions.csv')","567fc430":"## Training the model with the best hyperparameters","3a70b29b":"## Inference","e093fcb1":"## Adding extra features","3512ba68":"## Defining DataFrame with holidays","b48fe667":"## Imports","b7bd3bcb":"## Optuna objective function for XGBoost hyperparameters optimization","c54c4a8f":"## Constants for data paths","70e48d64":"## SMAPE loss function"}}