{"cell_type":{"c5f86603":"code","06ec6756":"code","1565d6e2":"code","f0dc6c18":"code","9a5e27ba":"code","8b43f2cc":"code","5b6d486f":"code","9e1451c0":"code","db4c2c01":"code","d4f2b72c":"code","a2005c58":"code","14d38900":"code","536cf297":"code","cecb66f3":"code","364c5780":"code","5f83c5d8":"code","7fb8beae":"code","34916df9":"code","95e7175b":"markdown","b1fc9ae2":"markdown","862f8661":"markdown"},"source":{"c5f86603":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06ec6756":"df = pd.read_csv('\/kaggle\/input\/population-time-series-data\/POP.csv')\ndf.head()","1565d6e2":"df['realtime_start'] = pd.to_datetime(df['realtime_start'])\ndf['realtime_end'] = pd.to_datetime(df['realtime_end'])\ndf['date'] = pd.to_datetime(df['date'])\ndf[['realtime_start', 'date', 'realtime_end']].describe(datetime_is_numeric=True)","f0dc6c18":"ts = df.drop(['realtime_start', 'realtime_end'], axis=1).set_index('date')\nts.head()","9a5e27ba":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nts.plot(title='Population Timeseries', figsize=(8, 6))\nplt.show()","8b43f2cc":"x_train = ts.values[:700]\nx_valid = ts.values[700:]","5b6d486f":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nx_train_prep = scaler.fit_transform(x_train)\nx_valid_prep = scaler.transform(x_valid)\nx_train_prep[:20]","9e1451c0":"import tensorflow as tf\ntf.keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 15\nbatch_size = 16\nn_steps = 10\n\ndef windowed_datasets(series, window_size, batch_size, n_steps, shuffle_buffer=None):\n    dataset = tf.data.Dataset.from_tensor_slices(series.ravel())\n    dataset = dataset.window(window_size + n_steps, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + n_steps))\n    \n    if shuffle_buffer:\n        dataset = dataset.shuffle(shuffle_buffer)\n    \n    dataset = dataset.map(lambda window: (window[:-n_steps], window[-n_steps:]))\n    dataset = dataset.map(lambda x, y: (tf.expand_dims(x, axis=-1), y))\n    return dataset.batch(batch_size).prefetch(1)\n\ntrain_set = windowed_datasets(x_train_prep, window_size=window_size, batch_size=batch_size, n_steps=n_steps, shuffle_buffer=1000)\nvalid_set = windowed_datasets(x_valid_prep, window_size=window_size, batch_size=batch_size, n_steps=n_steps)\n\nfor x, y in train_set.take(1):\n    print(x[0], y[0])","db4c2c01":"def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True):\n    plt.plot(series, \".-\")\n    if y is not None:\n        plt.plot(n_steps, y, \"bo\", label=\"Target\")\n    if y_pred is not None:\n        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")\n    plt.grid(True)\n    if x_label:\n        plt.xlabel(x_label, fontsize=16)\n    if y_label:\n        plt.ylabel(y_label, fontsize=16, rotation=0)\n    if legend and (y or y_pred):\n        plt.legend(fontsize=14, loc=\"upper left\")\n\ndef plot_multiple_forecasts(X, Y, Y_pred):\n    n_steps = X.shape[1]\n    ahead = Y.shape[1]\n    plot_series(X[0, :, 0])\n    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :], \"bo-\", label=\"Actual\")\n    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :], \"rx-\", label=\"Forecast\", markersize=10)\n    plt.legend(fontsize=14)","d4f2b72c":"x_valid = np.array(list(valid_set.map(lambda x, y: x).unbatch().as_numpy_iterator()))\ny_valid = np.array(list(valid_set.map(lambda x, y: y).unbatch().as_numpy_iterator()))\ny_valid_naive = np.array(list(valid_set.unbatch().map(lambda x, y: tf.tile(x[-1], tf.constant([10], tf.int32))).as_numpy_iterator()))\n\nprint(x_valid.shape)\nprint(y_valid.shape)\nprint(y_valid_naive.shape)","a2005c58":"np.mean(tf.keras.metrics.mean_squared_error(y_valid, y_valid_naive))","14d38900":"plot_multiple_forecasts(x_valid, y_valid, y_valid_naive)\nplt.show()","536cf297":"np.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=[window_size, 1]),\n    tf.keras.layers.Dense(n_steps)\n])\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n\nmodel.compile(loss=\"mse\", optimizer=\"adam\")\nhistory = model.fit(train_set, epochs=100, validation_data=valid_set, callbacks=[early_stopping_cb], verbose=0)","cecb66f3":"model.evaluate(valid_set)","364c5780":"y_valid_dnn = model.predict(x_valid)\nprint(y_valid_dnn.shape)\nplot_multiple_forecasts(x_valid, y_valid, y_valid_dnn)\nplt.show()","5f83c5d8":"np.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.SimpleRNN(10, input_shape=[None, 1]),\n    tf.keras.layers.Dense(n_steps)\n])\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"rnn.h5\", save_best_only=True)\n\nmodel.compile(loss=\"mse\", optimizer=\"adam\")\nhistory = model.fit(train_set, epochs=100, validation_data=valid_set, callbacks=[early_stopping_cb, checkpoint_cb])","7fb8beae":"model = tf.keras.models.load_model(\"rnn.h5\") # rollback to best model\nmodel.evaluate(valid_set)","34916df9":"y_valid_rnn = model.predict(x_valid)\nprint(y_valid_rnn.shape)\nplot_multiple_forecasts(x_valid, y_valid, y_valid_rnn)\nplt.show()","95e7175b":"# Prepare the Dataset","b1fc9ae2":"# Explore the Dataset","862f8661":"# Create multisteps ahead timeseries forecast model\n\nLet's create some baselines: naive prediction and a simple linear model:"}}