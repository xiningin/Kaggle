{"cell_type":{"fe0a6a65":"code","92ba076c":"code","0d7fa71b":"code","e08349f7":"code","063f0150":"code","50acc607":"code","b25562bc":"code","2a6905b4":"code","196f3e5d":"code","4fac8086":"code","f25ed58f":"code","87c48e13":"code","d64f2d3f":"code","fedb0214":"code","530b25ab":"code","b6288789":"code","ae625a9c":"code","cc1bf59c":"code","b8c0c20e":"code","48256081":"code","a353a550":"code","c65a5997":"code","983730f0":"code","b44799f8":"code","6023868f":"code","8924d723":"code","773512a1":"code","d87ac9d6":"code","e6d673f4":"code","7ccb0c6f":"code","83dbd7f1":"markdown","235f693f":"markdown","97756f9a":"markdown","f6a9f38a":"markdown","d2c4cb14":"markdown","3953350d":"markdown","d33e9b0a":"markdown","1e43f75b":"markdown","9a9f2833":"markdown","d8aa71e3":"markdown","38129edb":"markdown","0c1dcf01":"markdown","027fef18":"markdown","7b414a5f":"markdown"},"source":{"fe0a6a65":"import pandas as pd\nimport numpy as np \nimport seaborn as sns \nimport scipy \nimport sklearn as sk\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n","92ba076c":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/akhil14shukla\/Housing-Price-Prediction\/master\/train.csv', index_col='Id')\ndf_test = pd.read_csv('https:\/\/raw.githubusercontent.com\/akhil14shukla\/Housing-Price-Prediction\/master\/test.csv',  index_col='Id')","0d7fa71b":"# sns.catplot(x='GarageYrBlt',y='SalePrice',data=df,aspect=10)\n# df.GarageYrBlt.describe() \n#making bins for Garage Year Built\n# sns.catplot(x='YearBuilt',y='SalePrice',data=df,aspect=2)\nsns.catplot(x='YearRemodAdd',y='SalePrice',data=df,aspect=2)","e08349f7":"df.value_counts()\n# df.LotShape.fillna(df.LotConfig.mode(),inplace=True)\n# plt.bar(df.LotConfig,df.SalePrice)","063f0150":"sns.catplot(x='GarageCars',y='SalePrice',data=df)\nsns.lineplot(x='GarageCars',y='SalePrice',data=df)\nsns.lineplot(x='GarageCars',y='GarageArea',data=df)\n#dropping Garage Area and will use Garage Cars for the same, as both represent the same thing","50acc607":"from sklearn.linear_model import LinearRegression\nsub = df[['OpenPorchSF', '3SsnPorch','ScreenPorch','EnclosedPorch']]\nm1 = LinearRegression().fit(sub,df.SalePrice)\nm1.score(sub,df.SalePrice)\ncoef = m1.coef_\ninter = m1.intercept_","b25562bc":"# sns.catplot(x='YearBuilt',y='SalePrice',data=df)\nsns.lineplot(x='YearBuilt',y='SalePrice',data=df)\n# sns.lineplot(x='YearBuilt',y='GarageArea',data=df)\/\ndf['HouseYear'] = pd.cut(x=df['YearBuilt'], bins=[1872, 1910, 1950, 1980, 1990, 2002, 2010], labels=[0, 1, 2, 3, 4, 5])","2a6905b4":"# df.corr().OverallCond # we can consider dropping this,, less correlation with Sale Price","196f3e5d":"sns.catplot(x='BsmtExposure',y='SalePrice',data=df) # we can drop this\ndf.BsmtExposure.value_counts()","4fac8086":"# df['BsmtFinSF'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'])\/2\n# df.drop(['BsmtFinSF1', 'BsmtFinSF2'],axis=1,inplace=True)","f25ed58f":"sns.catplot(x='HeatingQC',y='Heating',data=df)\nsns.catplot(x='HeatingQC',y='SalePrice',data=df)\nsns.catplot(x='Heating',y='SalePrice',data=df)","87c48e13":"# from sklearn.ensemble import RandomForestRegressor\n# regr = RandomForestRegressor(max_depth=2, random_state=0)\n# df = prep(df)\n# y = df['SalePrice']\n# df.drop(['SalePrice'],axis=1,inplace=True)\n# regr.fit(df, y)\n# df.info()","d64f2d3f":"# df1[\"LandSlope\"] = (pd.DataFrame(label_encoder.fit_transform(df[\"LandSlope\"])).value_counts())\ndef ordinal_ch(df1):\n    print(df.LandSlope.value_counts())\n    LS_map = {'Gtl': 0, 'Mod': 1, 'Sev':2}\n    df1['LandSlope'] = df1['LandSlope'].map(LS_map)\n\n    LS_map = {'Unf': 1, 'RFn': 2, 'Fin':3, 'NA':0}\n    df1['GarageFinish'] = df1['GarageFinish'].map(LS_map)\n\n    LS_map = {'MnPrv': 2, 'GdPrv': 3, 'GdWo':2, 'MnWw':1, 'NA':0}\n    df1['Fence'] = df1['Fence'].map(LS_map)\n\n    LS_map = {'1Fam': 0, 'TwnhsE': 4, 'Duplex':3, 'Twnhs':5, '2fmCon':2}\n    df1['BldgType'] = df1['BldgType'].map(LS_map)\n\n    LS_map = {'SBrkr': 4, 'FuseA': 3, 'FuseF':2, 'FuseP':1, 'Mix':0}\n    df1['Electrical'] = df1['Electrical'].map(LS_map)\n\n    LS_map = {'Unf': 0, 'GLQ': 5, 'ALQ':4, 'BLQ':2, 'Rec':3, 'LwQ': 1, 'NA':0}\n    df1['BsmtFinType1'] = df1['BsmtFinType1'].map(LS_map)\n\n    LS_map = {'1Story': 0, '2Story': 3, '1.5Fin':2, 'SLvl':6, 'SFoyer':6, '1.5Unf': 1, '2.5Unf':4 , '2.5Fin':5}\n    df1['HouseStyle'] = df1['HouseStyle'].map(LS_map)\n\n    LS_map = {'Fa': 0, 'Gd': 2, 'TA':1, 'Ex':3}\n    for x in [\"ExterQual\" , \"KitchenQual\"] :\n        df1[x] = df1[x].map(LS_map)     # \"BsmtQual\" , \"KitchenQual\"\n\n    LS_map = {'Fa': 1, 'Gd': 3, 'TA':2, 'Ex':4 , 'Po': 0}\n    for x in [\"HeatingQC\" , \"ExterCond\"]:\n        df1[x] = df1[x].map(LS_map)     # \"HeatingQC\" , \"FireplaceQu\" , \"GarageQual\"\n\n    LS_map = {'Fa': 2, 'Gd': 4, 'TA':3, 'Ex':5 , 'Po': 1, 'NA':0}\n    df1['FireplaceQu'] = df1['FireplaceQu'].map(LS_map)\n\n    LS_map = {'Fa': 2, 'Gd': 4, 'TA':3,  'Po': 1, 'NA':0}\n    df1['BsmtCond'] = df1['BsmtCond'].map(LS_map)\n\n    LS_map = {'Mn': 2, 'No': 1, 'Av':3, 'Gd': 4, 'NA':0}\n    df1['BsmtExposure'] = df1['BsmtExposure'].map(LS_map)\n\n    LS_map = {'Y': 1, 'N': 0}\n    df1['CentralAir'] = df1['CentralAir'].map(LS_map)\n\n    LS_map = {'Fa': 1, 'Gd': 3, 'TA':2, 'Ex':4, 'NA':0}\n    df1[\"BsmtQual\"] = df1[\"BsmtQual\"].map(LS_map)","fedb0214":"def fill_na(df, feature):       # filling null values based on current distribution\n    s = df[feature].value_counts(normalize=True)\n    missing = df[feature].isnull()\n    df.loc[missing,feature] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\ndef remod(df):\n    if df['YearBuilt'] == df['YearRemodAdd']:\n        res=0\n    else:\n        res=1\n    return res","530b25ab":"def prep(df):\n    # Alley - many are null values, won't be useful\n    # PoolArea - 1453\/1460 are 0's\n    filling_NA = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"Fence\", \"MiscFeature\"]\n    for x in filling_NA:\n        df[x].fillna('NA', inplace=True)  # special care, NA represents no fence, not value absent\n    for i in df.columns:\n        fill_na(df,i)\n    # df['YearRemodAdd']=df.apply(remod,axis=1) #useless, remodelling is not of that much use most probably\n    df['Bath'] = df['FullBath'] + df['HalfBath'] + df['BsmtFullBath'] + df['BsmtHalfBath']\n    df['Porch'] = df['OpenPorchSF'] + df['3SsnPorch']  + df['ScreenPorch'] + df['EnclosedPorch'] + df['WoodDeckSF']\n    df['GarageYear'] = pd.cut(x=df['GarageYrBlt'], bins=[1900, 1933, 1946, 1969, 1981,1990, 1993, 2002, 2010], labels=[0, 1, 2, 3, 4, 5, 6, 7])\n    df['HouseYear'] = pd.cut(x=df['YearBuilt'], bins=[1872, 1915, 1931,1941, 1956,1972, 1980, 1991, 2002, 2010], labels=[0, 1, 2, 3, 4, 5,6,7,8])\n    # df['BsmtFinSF'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'])\/2\n    dropin = [\"MiscFeature\",'FullBath', 'HalfBath','BsmtFullBath','BsmtHalfBath', 'GarageYrBlt', 'Heating','GarageArea', 'YearBuilt', 'Alley', 'PoolArea',\"PoolQC\", \"Functional\", \"GarageCond\", \"GarageQual\", \"PavedDrive\", \"SaleType\", \"Utilities\",'BsmtFinSF2', 'BsmtFinSF1', 'OpenPorchSF','3SsnPorch','ScreenPorch', 'BsmtFinType2', 'WoodDeckSF', 'EnclosedPorch']\n    df.drop(dropin,axis=1,inplace=True)\n    \n    return df","b6288789":"labels = [\"MSZoning\", \"Street\", \"LotShape\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\"Condition1\", \"Condition2\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"GarageType\", \"SaleCondition\"]\n# labels = labels.append([\"MiscFeature\", 'Heating','GarageArea', 'PoolArea',\"PoolQC\", \"Functional\", \"GarageCond\", \"GarageQual\", \"PavedDrive\", \"SaleType\", \"Utilities\"])\n\nordinals = [\"LandSlope\", \"BldgType\", \"HouseStyle\", \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"HeatingQC\", \"Heating\", \"CentralAir\", \"Electrical\", \"KitchenQual\", \"FireplaceQu\", \"GarageFinish\",\"Fence\"]","ae625a9c":"def prep2(df):    \n    enc_df = pd.DataFrame(me.transform(df[labels]).toarray())\n    df1 = df.join(enc_df)\n    df1.drop(labels, axis=1,inplace=True)\n    df1.fillna(0, inplace=True) # not sure abbout this\n    ordinal_ch(df1)\n    return df1","cc1bf59c":"# for x in ordinals:\n#     print(df[x].value_counts())\ny = df['SalePrice']\ndf.drop(['SalePrice'], axis=1, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=42)","b8c0c20e":"label_encoder = preprocessing.LabelEncoder()\nenc = OneHotEncoder(handle_unknown='ignore')\nme = (enc.fit(X_train[labels]))\n# end_df = me.transform(df[labels]).toarray()","48256081":"X_train = prep(X_train)\nX_test = prep(X_test)\nX_train = prep2(X_train)\nX_test = prep2(X_test)","a353a550":"#Scaling data\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(20.0, 85.0), unit_variance=True)\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)","c65a5997":"X_test = scaler.transform(X_test)","983730f0":"regr = RandomForestRegressor(n_estimators=100, max_depth=40, max_leaf_nodes=100, min_samples_leaf=1, min_samples_split=0.00001, random_state=4200)\nm1 = regr.fit(X_train,y_train)\nm1.score(X_train,y_train)","b44799f8":"y_pred = np.log(m1.predict(X_test))","6023868f":"from sklearn.metrics import mean_squared_error\n\nrms = mean_squared_error(np.log(y_test), y_pred, squared=False)\nprint(rms)","8924d723":"ind=df_test.index\ndf = prep(df)\ndf_test = prep(df_test)\ndf = prep2(df)\ndf_test = prep2(df_test)\nscaler.fit(df)\ndf = scaler.transform(df)\ndf_test = scaler.transform(df_test)\nm1.fit(df,y);","773512a1":"Y_pred = m1.predict(df_test)\nsubmission = pd.DataFrame({\n        \"Id\": ind,\n        \"SalePrice\": Y_pred\n    })","d87ac9d6":"submission.to_csv('submission.csv', index=False)","e6d673f4":"# df['YearRemodAdd']","7ccb0c6f":"# df","83dbd7f1":"## Testing and Finalising\n\nFirst on validation and then on final test dataset, which is to be submitted ","235f693f":"Using Random Forest as first model","97756f9a":"Now we will change the object type to numerical or float\/int type. For this I will use label encoding and ordinal encoding, depending on the data description.\nHeating --- doubt\n\ncan drop \"Functional\", \"GarageCond\", \"GarageQual\", \"PavedDrive\", \"MiscFeature\", \"SaleType\", \"Utilities\"","f6a9f38a":"On Test dataset","d2c4cb14":"## Data Cleaning and Feature Engineering\nData Visualisation and understanding is done above the feature engineering, for ease of maintaining this notebook","3953350d":"Custom function for filling null values, based on  the the distribution of non null values","d33e9b0a":"Function below changes object type rows to integer type. This function only considers ordinal type variables. ","1e43f75b":"## Reading CSV file (Test and Train)","9a9f2833":"## Data Visualisastion and Understanding\nObservations of this section led to the code in the above section","d8aa71e3":"ordinal  encoding on features that require that treatment, and on rest label encoding , using for loop.","38129edb":"Experimental code below, it is not included in the data processing","0c1dcf01":"Important thing to remember: do not fit the scaler again on test data. But fitted scaler on train data should tranform both training and test datasets.","027fef18":"### Function below is the main pipeline\nIt calls the functions declared above and drops the features which are unimportant (if more than 90% have same value or non-null value) ","7b414a5f":"Scaling the data, it improves accuracy in most models and is recommended"}}