{"cell_type":{"3ebdd16a":"code","5f056605":"code","ea520685":"code","96c2be3a":"code","045d3af4":"code","d13f3097":"code","027a35c9":"code","2cbcd7fd":"code","bdf25077":"code","01c1428c":"code","72cb6745":"code","16acc68f":"code","50708997":"code","0768645f":"code","1833f72e":"code","9ae55359":"code","2f6e0ae3":"code","a88d64ae":"code","7c4b6b77":"code","0b065cd7":"code","1db6d2de":"code","8245b4e8":"code","052c44b5":"markdown","693291a4":"markdown","1763274b":"markdown","f326cb00":"markdown","23149fe5":"markdown","0866a267":"markdown","6eeeaaa2":"markdown","720dab60":"markdown","f2e58886":"markdown","b229fb3f":"markdown","f70badc5":"markdown","624ec986":"markdown","ac32a881":"markdown","a475e986":"markdown","54ff7f17":"markdown","7494ac55":"markdown","f8eecc88":"markdown","c51f4735":"markdown","b4dda34e":"markdown","badcf683":"markdown","8bec1d52":"markdown","6bb881fc":"markdown","331c2bdc":"markdown","746a0be1":"markdown","c86292ab":"markdown","0f9b7a85":"markdown","dc2df6bb":"markdown","4b541bfe":"markdown","d7cbe18e":"markdown"},"source":{"3ebdd16a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler","5f056605":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","ea520685":"# Outcome column is the dependent variable (basically telling us if the person has diabetes or not). I'll rename it to 'result'.\ndf = df.rename(columns={'Outcome':'Result'})\ndf.head()","96c2be3a":"df.info()","045d3af4":"# We can use a heatmap to check correlation between the variables.\ncorr = df.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,cmap='Reds')","d13f3097":"# Checking how many samples we have for non-diabetics and for diabetics\ndf['Result'].value_counts()","027a35c9":"plt.figure(figsize=(10,10))\nsns.countplot(x=\"Result\", data=df)","2cbcd7fd":"# Age vs Insulin\nx = []\nfor age in df.Age:\n    x.append(age)\ny = df.Insulin\nplt.figure(figsize=(20,10))\nplt.bar(x,y)\n#for index, value in enumerate(y):\n #   plt.text(index, value, str(value),color='blue',size=10,fontweight='bold')\nplt.xlabel(\"Age\",size=10)\nplt.ylabel(\"Insulin\")\nplt.xticks(x)\nplt.title(\"Relationship between Age and Insulin levels\")\nplt.show()\nplt.show()","bdf25077":"# Age vs Glucose\nx = []\nfor age in df.Age:\n    x.append(age)\ny = df.Glucose\nplt.figure(figsize=(20,10))\nplt.bar(x,y)\nplt.xlabel(\"Age\",size=10)\nplt.ylabel(\"Glucose\")\nplt.xticks(x)\nplt.grid()\nplt.title(\"Relationship between Age and Glucose levels\")\nplt.show()","01c1428c":"# We'll check mean values of the dependent variables for diabetics and non-diabetics\ndf.groupby('Result').mean()","72cb6745":"# We need to split the data\nX = df.drop(['Result'],axis=1) # We need all the variables (columns) as independent variables so we're just dropping the target column to make things easier.\ny = df['Result'] # Target.","16acc68f":"Scaler = StandardScaler()\nStandardizedData = Scaler.fit_transform(X)\nprint(StandardizedData)","50708997":"X = StandardizedData","0768645f":"# Then we split the data into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 2) # 80% data will be used for training the model and rest 20% for testing.","1833f72e":"X.shape","9ae55359":"X_train.shape","2f6e0ae3":"model = svm.SVC(kernel='linear')","a88d64ae":"# Now we need to train the model\nmodel.fit(X_train,y_train) # fitting means training","7c4b6b77":"train_pred = model.predict(X_train)\ntrain_pred","0b065cd7":"# Now let's check accuracy score on training data\nTraining_score = accuracy_score(train_pred,y_train) #(Basically comparing the original y_train and predictions and seeing difference\/error)\nprint(\"Accuracy Score:\",Training_score)","1db6d2de":"test_pred = model.predict(X_test)\ntest_pred","8245b4e8":"# Accuracy Score\nTest_score = accuracy_score(test_pred,y_test) \nprint(\"Accuracy Score:\",Test_score)","052c44b5":"# Supervised vs Unsupervised Machine Learning","693291a4":"**We can make observations such as, as glucose increases, the likelihood of having diabetes increases.**","1763274b":"**We're going to use Support Vector Machine for our classifier. It uses a technique called the kernel trick to transform the data and then based on these transformations it finds an optimal boundary between the possible outputs.**","f326cb00":"# Conclusion","23149fe5":"# Classification","0866a267":"**This notebook is a guide for beginners into machine learning, classification to be more specific. There will be comments every step of the way so there is a clear understanding. We will be building a system that predicts whether a woman has  diabetes or not given a set of information about that woman.**","6eeeaaa2":"**Our model was 76.6% accurate with test data so we can say this is a pretty accurate model.**","720dab60":"# Prediction and Evaluation of the Model","f2e58886":"# Data Standardization","b229fb3f":"**To get better accuracy, try different models or use more training data.**","f70badc5":"**Now all our columns are in same range**","624ec986":"# Missing Values","ac32a881":"# Splitting Data","a475e986":"**As we can see, 614 rows are used for testing out of 768 which is about 79.9% of the data.**","54ff7f17":"# Exploratory Data Analysis","7494ac55":"**Machine learning is divided into supervised and unsupervised learning. We train our model with data that we have previously acquired in supervised learning. In unsupervised learning, we have no data that we can train our model with.**\n\n**Supervised machine learning is divided into classification and regression. In classification, we predict discrete values, e.g. Yes\/No, Customer will purchase\/Won't purchase. But in regression, we predict continuous values, such as age, price, etc.**","f8eecc88":"**All our columns have variable ranges. This could cause some problems for our ML model to make prediction. So, we should standardize the data, bring all of it to a similar range so it's easy for our model to understand the data.**","c51f4735":"So basically the workflow is like this: Import libraries and dataset -> check for missing values -> perform necessary imputation -> Exploratory Data Analysis -> split data -> Data Standardization -> train model -> check its accuracy -> improve model or try other ones.","b4dda34e":"# Importing Libraries and dataset","badcf683":"**This means our model is 77% accurate which is good enough.**","8bec1d52":"**We can see that 59 year olds have highest insulin levels but there is no real trend visible. Insulin levels keep varying, but maybe if we had more samples, a trend could be more obvious**","6bb881fc":"**We have more non-diabetic samples than diabetics. Also, we only have 786 samples total which is very less. Predictions would be more reliable if we had more data.**","331c2bdc":"**From here, we can make deductions such as:**\n* Women with more pregnancies tend to be more diabetic. \n* Non-diabetics tend to have lower glucose levels.\n* Non-diabetics tend to have lower blood pressure.\n* Diabetics have higher insulin levels.\n* Diabetics weigh more than non-diabetics.\n* Diabetics are older than non-diabetics on an average.","746a0be1":"**Again, no real trend found. But, interestingly 22 year olds have the highest glucose in their blood and 68 year olds have the least.**","c86292ab":"**Good thing we have no missing values in this dataset so no imputation (replacing missing values with other appropriate ones) necessary.**","0f9b7a85":"# Introduction","dc2df6bb":"**First, we need to use the model to predict diabetes\/not from the training data. Then, we check our model's accuracy using accuracy score (for classification).**","4b541bfe":"**But keep in mind that we used training data to check accuracy. We need to check using test data for a better understanding.**","d7cbe18e":"**All patients here are females at least 21 years old.**"}}