{"cell_type":{"a45da9c1":"code","0d13110d":"code","0bcce3d6":"code","818cbbe9":"code","78300ac7":"code","44314031":"code","7c11c27f":"code","3f071be2":"code","bdf6f6aa":"code","51dcfda8":"code","3916bf73":"code","1da5b9f0":"code","b2255993":"code","e8435cc8":"code","7f95ac0d":"code","726a1a72":"code","bcdb706b":"code","6cd8ca39":"code","7c89c258":"code","06096c22":"code","29c2b47f":"code","953531b4":"code","e2e146b0":"code","37f3724f":"code","8eda4b1b":"code","d896e182":"code","1e9f4f85":"code","f13d4b55":"code","fea4bd0e":"code","c2f0d05a":"code","9b645af8":"code","09f527b7":"code","b47e8bf7":"code","657fb6c4":"code","f0d6d6d4":"code","1998ba13":"code","9f364502":"code","db0b9c0a":"code","36dd9634":"code","2d63876d":"code","b27599bc":"code","cfe8c09c":"code","a1bcdb1a":"code","fa39d4ee":"code","a40edc91":"code","6a07aff3":"code","9eb4915d":"code","30fc8e8c":"code","3e7f5fca":"code","c317a41e":"code","d77e45df":"code","4a0a5e34":"code","07a5dd3f":"code","501bfda6":"code","c3a0d734":"code","670689df":"code","c337acc2":"code","9cfbbce2":"code","b21a1e57":"code","230bf7a0":"code","d9ed2247":"code","8c7c2f06":"code","103f8e6f":"code","a8ee4c49":"code","7ea2b4da":"markdown","2147be1c":"markdown","85fd4b13":"markdown","28ec6a3d":"markdown","c24bcde1":"markdown","256f5758":"markdown","64ef41cf":"markdown","5cf2874f":"markdown","c1ca3536":"markdown","1182bb93":"markdown","749def9a":"markdown","1418a7bf":"markdown","713ac7fb":"markdown","b3dc89d5":"markdown"},"source":{"a45da9c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0d13110d":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords","0bcce3d6":"train = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv\")","818cbbe9":"print(train.shape)\nprint(test.shape)","78300ac7":"# Collecting the info about the train data\ntrain.info()","44314031":"train.isnull().sum()","7c11c27f":"# We have null value for text and selected_text only\ntrain.dropna(inplace = True)","3f071be2":"train.isnull().sum()","bdf6f6aa":"# Collecting info for the test data\ntest.info()","51dcfda8":"train.head()","3916bf73":"train.describe()","1da5b9f0":"temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by = 'text', ascending = False)\ntemp.style.background_gradient(cmap = 'Purples')","b2255993":"# Plotting the sentiments count\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (12,6))\nsns.countplot(x = 'sentiment', data = train)","e8435cc8":"fig = go.Figure(go.Funnelarea(\ntext = temp.sentiment,\nvalues = temp.text,\ntitle = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n))\nfig.show()\n","7f95ac0d":"def jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c))\/(len(a) + len(b) -len(c))","726a1a72":"results_jaccard = []\n\nfor ind, row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n    \n    jaccard_score = jaccard(sentence1, sentence2)\n    results_jaccard.append([sentence1, sentence2,jaccard_score])","bcdb706b":"train.iterrows()","6cd8ca39":"jaccard = pd.DataFrame(results_jaccard, columns = [\"text\", \"selected_text\", \"jaccard_score\"])\ntrain = train.merge(jaccard, how = 'outer')","7c89c258":"jaccard.head()","06096c22":"train['Num_words_ST'] = train['selected_text'].apply(lambda x: len(str(x).split())) # Number of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x: len(str(x).split())) # Number of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] # Difference in number of words text and selected text","29c2b47f":"train.head()","953531b4":"hist_data = [train['Num_words_ST'], train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, show_curve = False)\nfig.update_layout(title_text = 'Distribtion of Number of words')\nfig.update_layout(\nautosize = False,\nwidth = 900,\nheight = 700,\npaper_bgcolor = 'LightSteelBlue'\n)\nfig.show()","e2e146b0":"hist_data = [train['Num_words_ST'], train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, show_curve = True)\nfig.update_layout(title_text = 'Distribtion of Number of words')\nfig.update_layout(\nautosize = False,\nwidth = 900,\nheight = 700,\npaper_bgcolor = 'LightSteelBlue'\n)\nfig.show()","37f3724f":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train['Num_words_ST'], shade = True, color = \"r\").set_title('Kernel Distribution of Number of words')\np1 = sns.kdeplot(train['Num_word_text'], shade = True, color = 'b')","8eda4b1b":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade = True, color = \"b\").set_title('Kernel Distribution of Difference in Number of Words')\np2 = sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade = True, color = 'r')","d896e182":"plt.figure(figsize = (12,6))\nsns.distplot(train[train['sentiment']=='neutral']['difference_in_words'], kde = False)","1e9f4f85":"k = train[train['sentiment']=='neutral']['difference_in_words']\nk","f13d4b55":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade = True, color = 'b').set_title(\"KDE of Jaccard Scores across different Sentiments\")\np2 = sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade = True, color = 'r')\nplt.legend(labels = ['positive', 'negative'])","fea4bd0e":"plt.figure(figsize = (12,6))\nsns.distplot(train[train['sentiment']=='neutral']['jaccard_score'], kde = False)","c2f0d05a":"k = train[train['Num_word_text']<=2]","9b645af8":"k.groupby('sentiment').mean()['jaccard_score']","09f527b7":"train['Num_words_ST'].unique()","b47e8bf7":"len(k)","657fb6c4":"len(k[k['sentiment']=='positive'])","f0d6d6d4":"k[k['sentiment']=='positive']","1998ba13":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets, remove links, remove punctuation and remove words containing numbers'''\n    text = str(text).lower()\n    text = re.sub('\\[*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\W*\\d\\w*', '', text)\n    return text","9f364502":"train['text'] = train['text'].apply(lambda x: clean_text(x))\ntrain['selected_text'] = train['text'].apply(lambda x: clean_text(x))","db0b9c0a":"train.head()","36dd9634":"train['temp_list'] = train['selected_text'].apply(lambda x: str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Blues')","2d63876d":"fig = px.bar(temp, x = 'count', y = 'Common_words', title = 'Common Words Text', orientation = 'h',\n            width = 700, height = 700, color = 'Common_words')\nfig.show()","b27599bc":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x: remove_stopword(x))","cfe8c09c":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Purples')","a1bcdb1a":"fig = px.treemap(temp, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Words')\nfig.show()","fa39d4ee":"train['temp_list1'] = train['text'].apply(lambda x: str(x).split()) # List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x: remove_stopword(x)) # Removing Stopwords","a40edc91":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:, :]\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Blues')","6a07aff3":"fig = px.bar(temp, x = 'count', y = \"Common_words\", title = \"Common Words in Text\",\n            orientation = 'h', width = 700, height = 700, color = 'Common_words')\nfig.show()","9eb4915d":"Positive_sent = train[train['sentiment'] == 'positive']\nNegative_sent = train[train['sentiment'] == 'negative']\nNeutral_sent = train[train['sentiment'] == 'neutral']","30fc8e8c":"# MOst Common Positive Words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap = 'Greens')","3e7f5fca":"# Most Common Negative Words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words', 'count']\ntemp_negative.style.background_gradient(cmap = 'Reds')","c317a41e":"fig = px.treemap(temp_negative, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Negative Words')\nfig.show()","d77e45df":"# Most Common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.iloc[1:,:]\ntemp_neutral.columns = ['Common_words', 'count']\ntemp_neutral.style.background_gradient(cmap = 'Reds')","4a0a5e34":"fig = px.bar(temp_neutral, x = 'count', y = 'Common_words', title = 'Most Common Neutral Words',\n            orientation = 'h', width = 700, height = 700, color = 'Common_words')\nfig.show()","07a5dd3f":"fig = px.treemap(temp_neutral, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Neutral Words')\nfig.show()","501bfda6":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","c3a0d734":"raw_text","670689df":"def words_unique(sentiment, numwords, raw_words):\n    '''\n    Input:\n        segment - Segment Category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result;\n        raw_word = list for item in train_data[train_data.segments == segments]['temp_list1']:\n    \n    Output:\n    dataframe giving information about the name of the specific ingredient and how many times it\n    occurs in the chosen cuisine (in descending order based on their counts)...\n    '''\n    \n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother.append(word)\n    allother = list(set(allother))\n        \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    \n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n            \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words', 'count'])\n    \n    return Unique_words","c337acc2":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","9cfbbce2":"fig = px.treemap(Unique_Positive, path = ['words'], values = 'count', title = 'Tree Of Unique Positive Words')\nfig.show()","b21a1e57":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.pie(Unique_Positive['count'], labels = Unique_Positive.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Positive Words')\nplt.show()","230bf7a0":"Unique_Negative = words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap = 'Reds')","d9ed2247":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels = Unique_Negative.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Negative Words')\nplt.show()","8c7c2f06":"Unique_Neutral = words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap = 'Oranges')","103f8e6f":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.pie(Unique_Neutral['count'], labels = Unique_Neutral.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Neutral Words')\nplt.show()","a8ee4c49":"def plot_wordcloud(text, mask = None, max_words = 200, max_font_size = 100,)","7ea2b4da":"**Most Common Words Sentiments Wise**","2147be1c":"for the same reason mentioned above I am unable to plot the kde plot for the jaccard_score of neutral tweets","85fd4b13":"**It's Time For WordClouds**","28ec6a3d":"**Most Common Words in Text**","c24bcde1":"Selected_text is subset of text","256f5758":"**Let's Look at Unique Words in each Segment**","64ef41cf":"Let's look at the distribution of Meta-Features","5cf2874f":"The number of words plot is really interesting, the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed.","c1ca3536":"  Removing the stop words","1182bb93":"lets look at the distribution of tweets in the train set","749def9a":"Cleaning the Corpus","1418a7bf":"Jackard Similarity","713ac7fb":"**EDA**","b3dc89d5":"since most of the value obtained in difference in numbers of word is zero so we can.t plot kde plot for sentiment analysis hence we have taken kde = False in the above case"}}