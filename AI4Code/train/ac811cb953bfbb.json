{"cell_type":{"afcba58e":"code","983b54af":"code","f1ff1f7f":"code","ed21ef9f":"code","991e0a54":"code","780ac8e8":"code","34de8397":"code","2798a90e":"code","fbbb974b":"code","397a5305":"code","849ae584":"code","32199dc0":"code","9fb837f4":"code","070e5267":"code","1b101206":"code","37b88baf":"code","8031fc76":"code","3b212968":"code","55d192d4":"code","ace64669":"markdown","017b9ce9":"markdown","27c1b152":"markdown"},"source":{"afcba58e":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier","983b54af":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')","f1ff1f7f":"train.shape,test.shape","ed21ef9f":"train.head()","991e0a54":"train.isna().sum().sort_values(ascending=False)","780ac8e8":"fig = plt.subplots(figsize = (10,5))\nsns.countplot(x='target',data=train)","34de8397":"col = []\nfor cols in train.columns[1:-1]:\n    col.append(cols)","2798a90e":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'],color='#606ff2').background_gradient(subset=['std'],cmap='PuBu').background_gradient(subset=['50%'],cmap='PuBu')","fbbb974b":"le = LabelEncoder()\nencoded = le.fit_transform(train.target)\ntrain = train.assign(target = encoded)\nfor i,c in enumerate(le.classes_):\n    print(i,c)","397a5305":"scaler = StandardScaler()\ntrain[col] = scaler.fit_transform(train[col])\ntest[col] = scaler.transform(test[col])","849ae584":"print(train.head())\nprint(test.head())","32199dc0":"X = train.drop(['id','target'],axis=1)\ny = train['target']\nX.shape,y.shape,test[col].shape","9fb837f4":"cat_params ={\n    'iterations': 10143, \n    'od_wait': 1115, \n    'learning_rate': 0.02248589308956038, \n    'reg_lambda': 86.12583478104304, \n    'subsample': 0.08594672381075155, \n    'random_strength': 29.926327447041192, \n    'depth': 6, 'min_data_in_leaf': 30, \n    'leaf_estimation_iterations': 3,\n    'loss_function' : 'MultiClass',\n    'eval_metric' : 'MultiClass',\n    'bootstrap_type' : 'Bernoulli',\n    'leaf_estimation_method' : 'Newton',\n    'random_state' : 42,\n    'task_type' : 'GPU',\n    }","070e5267":"preds = None\nskf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\nl=[]\nn=0\nfor tr_idx, test_idx in skf.split(X.values,y.values):\n    \n    X_tr, X_val = X.values[tr_idx], X.values[test_idx]\n    y_tr, y_val = y.values[tr_idx], y.values[test_idx]\n    \n    model = CatBoostClassifier(**cat_params)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    if preds is None:\n        preds = model.predict_proba(test[col].values)\n    else:\n        preds += model.predict_proba(test[col].values)\n    preds = preds\/skf.n_splits\n    l.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,l[n])\n    n+=1","1b101206":"df_kfold_cat = pd.DataFrame(preds,columns=['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'])\ndf_kfold_cat['id']  = test['id']\ndf_kfold_cat = df_kfold_cat[['id','Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']]\noutput = df_kfold_cat.to_csv('submit_1.csv',index=False)","37b88baf":"params_lgbm = {'learning_rate': 0.03193398814609538, \n                    'max_depth': 100, \n                    'min_child_samples': 263, \n                    'min_child_weight': 0.00038121415013974824,\n                    'objective':'multiclass',\n                    'random_state': 42,\n                    'n_estimators': 10000,\n                    'metric': 'multi_logloss',\n                   }","8031fc76":"preds2 = None\nskf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn = 0\nfor tr_idx, test_idx in skf.split(X.values,y.values):\n    X_tr, X_val = X.values[tr_idx], X.values[test_idx]\n    y_tr, y_val = y.values[tr_idx], y.values[test_idx] \n    \n    model = LGBMClassifier(**params_lgbm)\n    \n    model.fit(X_tr,y_tr,eval_set = [(X_val,y_val)],early_stopping_rounds = 200,verbose = False)\n    \n    if preds2 is None:\n        preds2 = model.predict_proba(test[col].values)\n    else:\n        preds2 += model.predict_proba(test[col].values)\n    preds2 \/= skf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n += 1","3b212968":"np.mean(ll)","55d192d4":"df_kfold_lgb = pd.DataFrame(preds2,columns=['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'])\ndf_kfold_lgb['id']  = test['id']\ndf_kfold_lgb = df_kfold_lgb[['id','Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']]","ace64669":"****Label Encoding and Scaling****","017b9ce9":"****LGBM Classifier****","27c1b152":"****Catboost Classifier****"}}