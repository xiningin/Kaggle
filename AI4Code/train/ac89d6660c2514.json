{"cell_type":{"8df49f43":"code","d5620f7f":"code","505edff7":"code","59fe9db3":"code","fb63bd72":"code","ed032cd5":"code","58c989d0":"code","59b324ea":"code","23fa1e61":"code","a32fe213":"code","bbe2a934":"code","1b83f6fb":"code","77ec8813":"code","a9be5ed0":"code","465f8777":"markdown","93868369":"markdown","053a4300":"markdown","dcb86ac1":"markdown","c4c58aec":"markdown","3794d6bb":"markdown","2e72b846":"markdown","072aaf87":"markdown","a036cd05":"markdown","a3b6ec23":"markdown","190427ea":"markdown","f167ad0d":"markdown"},"source":{"8df49f43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d5620f7f":"%matplotlib inline\n# launch tensorboard to track model performance\n%load_ext tensorboard\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\ntf.__version__","505edff7":"MODEL_OUT_DIR = '\/model' # model will be saved here\n!rm -rf .\/models\/ # remove previous model and summaries\n%tensorboard --logdir .\/models\/ # tensorbaord loads data from here","59fe9db3":"data = pd.read_csv('..\/input\/avocado-prices\/avocado.csv')\ndata.head()","fb63bd72":"# fix column names with spaces, to avoid issues in training. names in dataframe will be updated with corresponding names in columns list\ncolumns = [\"Unnamed\",\"Date\" ,\"AveragePrice\",\"Total_Volume\",\"4046\",\"4225\",\"4770\",\"Total_Bags\",\"Small_Bags\",\"Large_Bags\",\"XLarge_Bags\",\"type\",\"year\",\"region\"]\ndata.columns = columns","ed032cd5":"def get_random_split(data):\n    msk = np.random.rand(len(data)) < 0.8\n    return data[msk], data[~msk]\ntrain_df, eval_df = get_random_split(data)","58c989d0":"train_df.groupby('year').mean().plot(y='AveragePrice', kind='bar')","59b324ea":"train_df.groupby('type').mean().plot(y='AveragePrice', kind='bar')","23fa1e61":"train_df.groupby('region').mean().plot(y='AveragePrice', kind='bar')","a32fe213":"train_df.plot.scatter(x='Total_Volume', y='AveragePrice')","bbe2a934":"DENSE_COLUMNS = [\n    'Total_Volume',\n    '4046',\n    '4225',\n    '4770',\n    'Total_Bags',\n    'Small_Bags',\n    'Large_Bags',\n    'XLarge_Bags'\n]\n\nSPARSE_COLUMNS = ['type', 'year', 'region']\n\nfeature_columns = []\nfor feature in DENSE_COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(feature))\nfor feature in SPARSE_COLUMNS:\n    vocab = data[feature].unique()\n    categorical_feature = tf.feature_column.categorical_column_with_vocabulary_list(feature, vocab)\n    feature_columns.append(tf.feature_column.indicator_column(categorical_feature))","1b83f6fb":"def make_input_fn(df, epochs=500, shuffle=True, batch_size=32):\n    df = df.copy()\n    labels = df.pop('AveragePrice')\n    def input_function():\n        # create dataset from inmemory pandas dataframe        \n        dataset = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=len(df))\n        \n        dataset = dataset.batch(batch_size).repeat(epochs)\n        return dataset\n    return input_function\n\ntrain_input_fn = make_input_fn(train_df)\neval_input_fn = make_input_fn(eval_df, epochs=1, shuffle=False)","77ec8813":"linear_regressor = tf.estimator.LinearRegressor(\n    feature_columns=feature_columns,\n    model_dir='.\/models'\n)\nlinear_regressor.train(train_input_fn)","a9be5ed0":"linear_regressor.evaluate(eval_input_fn)","465f8777":"### Create dataset\nEstimator will use input_function to parse dataset. This is also the place to play any transformation required on dataset","93868369":"### Import libraries","053a4300":"#### Average prices per Region","dcb86ac1":"#### average prices of different types","c4c58aec":"#### Price vs volume sold","3794d6bb":"### Finally build an Estimator","2e72b846":"### Create Feature Columns","072aaf87":"### Train-Evaluation split","a036cd05":"### Find out how various columns relate to AveragePrice","a3b6ec23":"### Try it on Evaluation Set","190427ea":"#### average prices of different types","f167ad0d":"### Load data using pandas"}}