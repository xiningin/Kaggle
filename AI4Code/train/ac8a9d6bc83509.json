{"cell_type":{"1c399bef":"code","7b6b36fc":"code","d369c589":"code","d75490f9":"code","f4a7b0ef":"code","1c81fee0":"code","5fbe61b7":"code","2fff7f43":"code","1fa237b5":"code","be0a5e53":"code","448b78fb":"code","c37fcb5e":"code","b2714a20":"code","42501ca2":"code","0eb3eb77":"code","efcef02a":"code","ce10023b":"code","c9add460":"code","013537a5":"code","80f41f8f":"code","00c5c76d":"code","e37a0d84":"code","e92982fc":"code","734dd1df":"code","f9a4a71f":"code","af895032":"markdown","4f33c2be":"markdown","18557145":"markdown","83f8388b":"markdown","9661ed10":"markdown","6b85e60e":"markdown","611e6fe2":"markdown","f3307590":"markdown","7aa411ad":"markdown","12c2da64":"markdown","d6fb9b2a":"markdown","56d820a6":"markdown","d313b2f6":"markdown","c95be687":"markdown","9f8f0081":"markdown","1778d516":"markdown","e853c7a6":"markdown","117899af":"markdown","cfb9a14b":"markdown","1cf52bdb":"markdown","8a918fd8":"markdown","eca83cf8":"markdown","ce9e4b06":"markdown","10449aca":"markdown"},"source":{"1c399bef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b6b36fc":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBClassifier\nfrom sklearn.impute import KNNImputer","d369c589":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head(10)","d75490f9":"train_data.info()","f4a7b0ef":"train_data.isnull().sum()","1c81fee0":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","5fbe61b7":"test_data.info()","2fff7f43":"y_train = train_data.Survived\nX_train = train_data.drop('Survived', axis=1)\nX_test = test_data\ny_train","1fa237b5":"num_cols_train = [col for col in X_train.columns if X_train[col].dtype != 'object']\n\n\nnum_cols_train.remove('Age')\nnum_cols_train.remove(\"PassengerId\")\nnum_cols_train","be0a5e53":"sns.barplot(x=X_train.SibSp, y=y_train)","448b78fb":"low_cardinality_cols = [col for col in X_train.columns if X_train[col].nunique() < 10 and X_train[col].dtype=='object']\n\nlow_cardinality_cols","c37fcb5e":"sns.barplot(x=X_train.Sex, y=y_train)","b2714a20":"sns.barplot(x=X_train.Embarked, y=y_train)","42501ca2":"all_cols = num_cols_train + low_cardinality_cols \n\npreprocessed_X_train = X_train[all_cols].copy()\n\n\npreprocessed_X_train\n","0eb3eb77":"\ntrain_X, val_X, train_y, val_y = train_test_split(preprocessed_X_train, y_train,\n                                                  train_size=0.8,\n                                                  test_size=0.2,\n                                                  random_state=0)\n\n# Preprocessing for numerical data\nnumerical_transformer = KNNImputer() #SimpleImputer(strategy='mean')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols_train),\n        ('cat', categorical_transformer, low_cardinality_cols)\n    ])\n","efcef02a":"preprocessed_train_X = pd.DataFrame(preprocessor.fit_transform(train_X))\npreprocessed_val_X = pd.DataFrame(preprocessor.transform(val_X))\npreprocessed_train_X","ce10023b":"#Decision Tree\n\nfor leaf in range(25,400,25):\n    iowa_model = DecisionTreeClassifier(max_leaf_nodes=leaf, random_state=1)\n    iowa_model.fit(preprocessed_train_X, train_y)\n    val_predictions = iowa_model.predict(preprocessed_val_X)\n    \n    print('Leaf:',leaf, \"; MAE:\",mean_absolute_error(val_predictions, val_y))\n    \n#Random Forest\n\nrf_model = RandomForestClassifier(random_state=1)\nrf_model.fit(preprocessed_train_X, train_y)\nrf_val_predictions = rf_model.predict(preprocessed_val_X)\nprint('Random Forest MAE:',mean_absolute_error(rf_val_predictions, val_y))\n\nrf_estimators_model = RandomForestClassifier(random_state=1, n_estimators=50)\nrf_estimators_model.fit(preprocessed_train_X, train_y)\nrf_n_estimators_val_predictions = rf_estimators_model.predict(preprocessed_val_X)\nprint('Random Forest MAE with n_estimators defined:',\n      mean_absolute_error(rf_n_estimators_val_predictions, val_y))\n\n#XGBoost\n\nxgb_model_1 = XGBClassifier(random_state=0, eval_metric='logloss')\nxgb_model_1.fit(preprocessed_train_X, train_y,\n                early_stopping_rounds=5, \n                eval_set=[(preprocessed_val_X, val_y)], \n                verbose=False)\nxgb_predictions_1 = xgb_model_1.predict(preprocessed_val_X)\nprint('XGBoost (model 1) MAE:',mean_absolute_error(rf_val_predictions, val_y))\n\nxgb_model_2 = XGBClassifier(random_state=0, n_estimators=1000, learning_rate=0.01,\n                            eval_metric='logloss')\nxgb_model_2.fit(preprocessed_train_X, train_y,\n                early_stopping_rounds=5, \n                eval_set=[(preprocessed_val_X, val_y)], \n                verbose=False)\nxgb_predictions_2 = xgb_model_2.predict(preprocessed_val_X)\nprint('XGBoost (model 2) MAE:',mean_absolute_error(rf_val_predictions, val_y))","c9add460":"X_train_copy = X_train[all_cols].copy()\n\n#RFC MAE scores (with n_estimators)\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(n_estimators=50,\n                                                              random_state=1,\n                                                              max_depth=3))\n                             ])\nscores = -1 * cross_val_score(my_pipeline, X_train_copy, y_train,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\nprint(\"RFC MAE scores (with n_estimators):\\n\", scores.mean())\n\n#-------------------------------------------------------------\n#RFC MAE scores(without n_estimators)\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=1))\n                             ])\nscores = -1 * cross_val_score(my_pipeline, X_train_copy, y_train,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\nprint(\"RFC MAE scores(without n_estimators):\\n\", scores.mean())\n\n#-------------------------------------------------------------- \n#XGB MAE scores \n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', XGBClassifier(random_state=1,\n                                                      n_estimators=1000,\n                                                      learning_rate=0.01,\n                                                      early_stopping_rounds=5,\n                                                      eval_metric='logloss',\n                                                      subsample=0.8,\n                                                      max_depth=5)\n                              )])\nscores = -1 * cross_val_score(my_pipeline, X_train_copy, y_train,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\nprint(\"XGB MAE scores:\\n\", scores.mean())\n\n#0.18964283472475046","013537a5":"full_X = pd.concat([preprocessed_train_X, preprocessed_val_X], axis=0)\nfull_y = pd.concat([train_y, val_y], axis=0)\nfull_X\n","80f41f8f":"\nrf_model = RandomForestClassifier(n_estimators=50,\n                                  random_state=1,\n                                  max_depth=3)\nrf_model.fit(full_X, full_y)\npreprocessed_X_test = X_test[all_cols].copy()\npreprocessed_X_test = pd.DataFrame(preprocessor.transform(preprocessed_X_test))\n\n'''\nxgb_model = XGBClassifier(random_state=1,\n              n_estimators=1000,\n              learning_rate=0.01,\n              early_stopping_rounds=5,\n              eval_metric='logloss',\n              subsample=0.8,\n              max_depth=5)\nxgb_model.fit(full_X, full_y)\npreprocessed_X_test = X_test[all_cols].copy()\npreprocessed_X_test = pd.DataFrame(preprocessor.transform(preprocessed_X_test))\n'''\n\npreprocessed_X_test","00c5c76d":"preprocessed_X_test[0] = preprocessed_X_test.astype(int)\nprint(preprocessed_X_test)","e37a0d84":"predictions = rf_model.predict(preprocessed_X_test)\n\noutput = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e92982fc":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","734dd1df":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","f9a4a71f":"'''\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n'''","af895032":"![image.png](attachment:d3ad962b-ca42-4f9a-aa0b-18bdf74a453f.png)","4f33c2be":"**Verifying the importance of those columns in the survivance**\n","18557145":"I will use RF Model for not overfitting the model, and use n_estimators=50","83f8388b":"Embarked","9661ed10":"Because Cross-Validation has a better measure of the real MAE,that proofs that a model with n_estimators=50 is better","6b85e60e":"# **Separating in X and Y**","611e6fe2":"# **Variable Notes**","f3307590":"# **Testing Data**","7aa411ad":"# **Importing**","12c2da64":"Sex","d6fb9b2a":"# **Selecting the best model**","56d820a6":"# **Training Data**\n","d313b2f6":"That shows that 'Embarked' and 'Sex' have some importance in the survivance","c95be687":"# **Verifying with Cross-Validation**","9f8f0081":"# **Data Dictionary**","1778d516":"# **Material from the First Version**","e853c7a6":"# **Predictions and Submition**","117899af":"pclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\n\n\n\nParent = mother, father\n\nChild = daughter, son, stepdaughter, stepson\n\nSome children travelled only with a nanny, therefore parch=0 for them","cfb9a14b":"# **Modeling with all data**","1cf52bdb":"# **Numerical Columns**","8a918fd8":"**Verifying 'SibSp'**","eca83cf8":"# **Concatenate both columns**","ce9e4b06":"# **Spliting and Preprocessing**","10449aca":"# **Categorical Columns**"}}