{"cell_type":{"4e910955":"code","2588adde":"code","21ed08c1":"code","5993879d":"code","6fd9cc8c":"code","e4321f2f":"code","affab542":"code","2a881232":"code","76c44b88":"code","bfd27bd9":"code","bdd5f634":"code","06fa5257":"code","b0f013d9":"code","49e75e2c":"code","03cc8bb6":"code","7682cd01":"code","562a9e2c":"code","1988f51a":"code","0a837b40":"code","e6473f59":"code","e3bdd058":"code","82cf4a4c":"code","9499004f":"code","f44d3db3":"code","6b7e01ed":"code","08dcd9fd":"code","95ec465a":"code","36b663d3":"code","cae87751":"code","b3c03e0b":"code","5304dfbf":"code","62aa932a":"code","18daeef0":"code","c5b28acb":"code","dd310a07":"code","540f2249":"markdown","b8b71cd2":"markdown","b01261f9":"markdown","58c49a56":"markdown","2a3350f4":"markdown","71e0c811":"markdown","409d781e":"markdown","c8607a58":"markdown","79da553f":"markdown"},"source":{"4e910955":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","2588adde":"# 1. User's Dataset\nu_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\nusers = pd.read_csv('..\/input\/ml-100k\/u.user', sep='|', names=u_cols,\n                    encoding='latin-1', parse_dates=True) \n# 2. Rating dataset\nr_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings = pd.read_csv('..\/input\/ml-100k\/u.data', sep='\\t', names=r_cols,\n                      encoding='latin-1')\n\n# 3.Movies Dataset\nm_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url','unknown', 'Action', 'Adventure',\n'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy','Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\nmovies = pd.read_csv('..\/input\/ml-100k\/u.item', sep='|', names=m_cols,\n                     encoding='latin-1')","21ed08c1":"#users\nprint(users.shape)\nusers.head(4)","5993879d":"#ratings\nprint(ratings.shape)\nratings.head(4)","6fd9cc8c":"#items\nprint(movies.shape)\nmovies.head(4)","e4321f2f":"r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings_train = pd.read_csv('..\/input\/ml-100k\/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\nratings_test = pd.read_csv('..\/input\/ml-100k\/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\nratings_train.shape, ratings_test.shape","affab542":"ratings_train.head(4),ratings_test.head(4)","2a881232":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x=ratings_train.rating,data=ratings_train)","76c44b88":"ratings_train.groupby(by='movie_id')['rating'].mean().sort_values(ascending=False).head(20)","bfd27bd9":"no_of_rated_movies_per_user = ratings_train.groupby(by='user_id')['rating'].count().sort_values(ascending=False)\nno_of_rated_movies_per_user.head()","bdd5f634":"ax1 = plt.subplot(121)\nsns.kdeplot(no_of_rated_movies_per_user, shade=True, ax=ax1)\nplt.xlabel('No of ratings by user')\nplt.title(\"PDF\")\n\nax2 = plt.subplot(122)\nsns.kdeplot(no_of_rated_movies_per_user, shade=True, cumulative=True,ax=ax2)\nplt.xlabel('No of ratings by user')\nplt.title('CDF')\n\nplt.show()","06fa5257":"no_of_rated_movies_per_user.describe()","b0f013d9":"quantiles = no_of_rated_movies_per_user.quantile(np.arange(0,1.01,0.01), interpolation='higher')\nquantiles","49e75e2c":"plt.title(\"Quantiles and their Values\")\nquantiles.plot()\n# quantiles with 0.05 difference\nplt.scatter(x=quantiles.index[::5], y=quantiles.values[::5], c='orange', label=\"quantiles with 0.05 intervals\")\n# quantiles with 0.25 difference\nplt.scatter(x=quantiles.index[::25], y=quantiles.values[::25], c='m', label = \"quantiles with 0.25 intervals\")\nplt.ylabel('No of ratings by user')\nplt.xlabel('Value at the quantile')\nplt.legend(loc='best')\n\n# annotate the 25th, 50th, 75th and 100th percentile values....\nfor x,y in zip(quantiles.index[::25], quantiles[::25]):\n    plt.annotate(s=\"({} , {})\".format(x,y), xy=(x,y), xytext=(x-0.05, y+500)\n                ,fontweight='bold')\n\nplt.show()","03cc8bb6":"quantiles[::5]","7682cd01":"print('\\n No of ratings at last 5 percentile : {}\\n'.format(sum(no_of_rated_movies_per_user>= 301)) )","562a9e2c":"no_of_ratings_per_movie = ratings_train.groupby(by='movie_id')['rating'].count().sort_values(ascending=False)\n\nfig = plt.figure(figsize=plt.figaspect(.5))\nax = plt.gca()\nplt.plot(no_of_ratings_per_movie.values)\nplt.title('# RATINGS per Movie')\nplt.xlabel('Movie')\nplt.ylabel('No of Users who rated a movie')\nax.set_xticklabels([])\n\nplt.show()","1988f51a":"n_users = ratings.user_id.unique().shape[0]\nn_items = ratings.movie_id.unique().shape[0]","0a837b40":"data_matrix = np.zeros((n_users, n_items))\nfor line in ratings.itertuples():\n    data_matrix[line[1]-1, line[2]-1] = line[3]\n    \ntest_data_matrix = np.zeros((n_users, n_items))\nfor line in ratings_test.itertuples():\n    test_data_matrix[line[1]-1, line[2]-1] = line[3]","e6473f59":"from sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.metrics.pairwise import cosine_similarity \n\n#user_similarity = pairwise_distances(data_matrix, metric='cosine')\n#item_similarity = pairwise_distances(data_matrix.T, metric='cosine')\n#print (user_similarity[0][1])\n\n# NOTE: why use pairwise_distances? why not cosine_similarity? cosine_distance = 1-cosine_similarity. i believe cosine_similarity is right for here.\n# let's change it to consine_similarity\n\nuser_similarity = cosine_similarity(data_matrix)\nitem_similarity = cosine_similarity(data_matrix.T)\nprint (user_similarity[0][1])\n","e3bdd058":"user_similarity.shape","82cf4a4c":"def predict(ratings, similarity, type='user'):\n    if type == 'user':\n        mean_user_rating = ratings.mean(axis=1)\n        print (mean_user_rating.shape)\n        print (mean_user_rating[:, np.newaxis].shape)\n        #We use np.newaxis so that mean_user_rating has same format as ratings\n        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n\n        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) \/ np.array([np.abs(similarity).sum(axis=1)]).T\n        print (np.array([np.abs(similarity).sum(axis=1)]).shape, pred.shape)\n    elif type == 'item':\n        pred = ratings.dot(similarity) \/ np.array([np.abs(similarity).sum(axis=1)])\n    return pred","9499004f":"user_prediction = predict(data_matrix, user_similarity, type='user')\nitem_prediction = predict(data_matrix, item_similarity, type='item')\nprint (data_matrix[0])\nprint (user_prediction[0])","f44d3db3":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\ndef rmse(prediction, ground_truth):\n    prediction = prediction[ground_truth.nonzero()].flatten() \n    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n    #print (prediction.shape, ground_truth.shape)\n    return sqrt(mean_squared_error(prediction, ground_truth))","6b7e01ed":"print ('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\nprint ('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))","08dcd9fd":"import turicreate\n\ntrain_data = turicreate.SFrame(ratings_train)\ntest_data = turicreate.SFrame(ratings_test)","95ec465a":"popularity_model = turicreate.popularity_recommender.create(train_data, user_id='user_id', item_id='movie_id', target='rating')","36b663d3":"#Get recommendations for first 5 users and print them\n#users = range(1,6) specifies user ID of first 5 users\n#k=5 specifies top 5 recommendations to be given\npopularity_recomm = popularity_model.recommend(users=list(range(1,6)),k=5)\npopularity_recomm.print_rows(num_rows=25)\n","cae87751":"#Train Model\n#item_sim_model = turicreate.item_similarity_recommender.create(train_data, user_id='user_id', item_id='movie_id', target='rating', similarity_type='pearson')\nitem_sim_model = turicreate.item_similarity_recommender.create(train_data, user_id='user_id', item_id='movie_id', target='rating', similarity_type='cosine')\n\n#Make Recommendations:\nitem_sim_recomm = item_sim_model.recommend(users=list(range(1,6)),k=5)\nitem_sim_recomm.print_rows(num_rows=25)","b3c03e0b":"popularity_model.evaluate(test_data)\nitem_sim_model.evaluate(test_data)","5304dfbf":"#model_performance = turicreate.compare(test_data, [popularity_model, item_sim_model])\n#turicreate.show_comparison(model_performance,[popularity_model, item_sim_model])\nmodel_performance = turicreate.recommender.util.compare_models = (test_data, [popularity_model, item_sim_model])\nprint (model_performance)\n","62aa932a":"print (len(ratings_train), float(n_users*n_items))\nsparsity=round(1.0-len(ratings_train)\/float(n_users*n_items),3)\nprint ('The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%')","18daeef0":"import scipy.sparse as sp\nfrom scipy.sparse.linalg import svds\n\ndef SVD(rating_matrix):\n    #get SVD components from train matrix. Choose k.\n    u, s, vt = svds(rating_matrix, k = 20)\n    s_diag_matrix=np.diag(s)\n    X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n    return X_pred\n\nprint ('User-based CF MSE: ' + str(rmse(SVD(data_matrix), test_data_matrix)))","c5b28acb":"factorization_model = turicreate.factorization_recommender.create(train_data, user_id='user_id', item_id='movie_id', target='rating')\nfactorization_recomm = factorization_model.recommend(users=list(range(1,6)),k=5)\nfactorization_recomm.print_rows(num_rows=25)","dd310a07":"factorization_model.evaluate(test_data)","540f2249":"Looking PDF and CDF of number of rated movies per user\n\n**CDF**: cummulative denisty function. It is the total probability of anything below it. Its range is 0-1. Also known as density function. Represented as F(x).\n\n**PDF** : Probability denisty function. It is probability at one point. also know as probability mass function(PMF). Represented as f(x).\n![1](https:\/\/qph.ec.quoracdn.net\/main-qimg-e50787cd6024e1945ef5632192b70a69)\n[2](http:\/\/work.thaslwanter.at\/Stats\/html\/statsDistributions.html)\nSo both F(x) and f(x) as inter related to each other.\nif we do the derivative of F(x) we get the f(x) and vice versa if we integrate f(x) we get the F(x).\n\n**In detail Explaination:**\nGenerally Random variables are two types \n\n1.** Continuos**: Which is solved by integral.\n![image.png](attachment:image.png)  \n2.** Discrete** : Which is solved by summation.\n\nSo we can say the *PDF* is the continuous function.\n\n[For more Explanation please refer this vedio](http:\/\/youtu.be\/DIsZFAV9Hy0)","b8b71cd2":"use following formula to calculate prediction:\n![image.png](attachment:image.png)\n\nrefer to http:\/\/cis.csuohio.edu\/~sschung\/CIS660\/CollaborativeFilteringSuhua.pdf","b01261f9":"### Building a simple popularity and collaborative filtering model using Turicreate","58c49a56":"in turicreate:","2a3350f4":"### Building collaborative filtering model from scratch","71e0c811":"### Model-based Collaborative Filtering\n\nLet\u2019s calculate the sparsity level of MovieLens dataset:\n","409d781e":"This kernel forked from https:\/\/www.kaggle.com\/srisudheera\/introduction-to-recommendation and got many many insights from following links. \n1. https:\/\/www.analyticsvidhya.com\/blog\/2018\/06\/comprehensive-guide-recommendation-engine-python\/\n1. https:\/\/www.tuicool.com\/articles\/biYvArn\n1. http:\/\/cis.csuohio.edu\/~sschung\/CIS660\/CollaborativeFilteringSuhua.pdf\n\nThe original kernel use GraphLabs which have been bought by Apple and now it becomes open source project call Turicreate, so i use Turicreate here.\n\nPlease add some credits to this kernel if you like it. Thanks!\n","c8607a58":"in python:","79da553f":"First let's load the data and do some data exploring analysis."}}