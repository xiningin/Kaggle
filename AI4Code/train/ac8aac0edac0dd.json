{"cell_type":{"a9ca6191":"code","cf166dd7":"code","1ba47402":"code","ce121d94":"code","38577c11":"code","5ba51137":"code","f7ee14b0":"code","15c8a427":"code","8011abf8":"code","b1ca4cf6":"code","ad5f4547":"markdown","97165c1b":"markdown","878a50d0":"markdown"},"source":{"a9ca6191":"import numpy as np\n\nfrom keras.datasets import cifar10\nfrom keras.utils.np_utils import to_categorical ","cf166dd7":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","1ba47402":"print(\"Shape of training data:\")\nprint(X_train.shape)\nprint(y_train.shape)\nprint(\"Shape of test data:\")\nprint(X_test.shape)\nprint(y_test.shape)","ce121d94":"import matplotlib.pyplot as plt\n\ncifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\nprint('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) \nprint('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\n\nf, axarr = plt.subplots(1, 5)\nf.set_size_inches(16, 6)\n\nfor i in range(5):\n    img = X_train[i]\n    axarr[i].imshow(img)\nplt.show()","38577c11":"# Transform label indices to one-hot encoded vectors\n\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\n# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n\nX_train = np.reshape(X_train,(50000,3072))\nX_test = np.reshape(X_test,(10000,3072))\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# Normalization of pixel values (to [0-1] range)\n\nX_train \/= 255\nX_test \/= 255","5ba51137":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom tensorflow.keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(256, activation='relu', input_dim=3072))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\nmodel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])","f7ee14b0":"# Training the MLP\n\nhistory = model.fit(X_train,y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)","15c8a427":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","8011abf8":"# Evaluating the MLP\nscore = model.evaluate(X_test, y_test, batch_size=128, verbose=0)","b1ca4cf6":"print(model.metrics_names)\nprint(score)","ad5f4547":"- 2. MLP classifier","97165c1b":"## Import Library","878a50d0":"## Classify CIFAR-10 data set using MLP classifier. Perform the following"}}