{"cell_type":{"02f299a0":"code","478f5cef":"code","65cd83b9":"code","c19f0a79":"code","6abbc7fc":"code","a9f127fd":"code","2d3317d3":"code","db2d6ae8":"code","c8629f38":"code","91ad060b":"code","6809a78f":"code","0342aa53":"code","2e6f34a8":"code","55c41e90":"code","e8f33663":"code","9e67310d":"code","87762c77":"code","0939eea0":"code","952be138":"code","28850f55":"code","cba0e273":"code","3c3ea458":"code","21d5ee3f":"code","ae5ccf8e":"code","9bb542e6":"code","e02b96fe":"code","06bb4101":"code","03b8e56a":"code","f728a6cf":"code","57ebaada":"code","a073811c":"markdown","36105ba1":"markdown","fa3d6bbb":"markdown","8e3ce071":"markdown","c300e06e":"markdown","3e9c138d":"markdown","ca540021":"markdown","43a842b3":"markdown","e38b5225":"markdown","25216471":"markdown","abcc56d4":"markdown","0ba721f5":"markdown"},"source":{"02f299a0":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(palette=\"Set2\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (accuracy_score, f1_score,average_precision_score, confusion_matrix,\n                             average_precision_score, precision_score, recall_score, roc_auc_score, )\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n\n\nfrom xgboost import XGBClassifier, plot_importance\nfrom imblearn.over_sampling import SMOTE","478f5cef":"# read dataset\ndataset = pd.read_csv(\"..\/input\/Churn_Modelling.csv\")","65cd83b9":"# first five row of the dataset\ndataset.head()","c19f0a79":"dataset.describe()","6abbc7fc":"# checking datatypes and null values\ndataset.info()","a9f127fd":"dataset.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis=1, inplace=True)","2d3317d3":"_, ax = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)\nsns.countplot(x = \"NumOfProducts\", hue=\"Exited\", data = dataset, ax= ax[0])\nsns.countplot(x = \"HasCrCard\", hue=\"Exited\", data = dataset, ax = ax[1])\nsns.countplot(x = \"IsActiveMember\", hue=\"Exited\", data = dataset, ax = ax[2])","db2d6ae8":"_, ax = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)\nsns.swarmplot(x = \"NumOfProducts\", y = \"Age\", hue=\"Exited\", data = dataset, ax= ax[0])\nsns.swarmplot(x = \"HasCrCard\", y = \"Age\", data = dataset, hue=\"Exited\", ax = ax[1])\nsns.swarmplot(x = \"IsActiveMember\", y = \"Age\", hue=\"Exited\", data = dataset, ax = ax[2])","c8629f38":"encoder = LabelEncoder()\ndataset[\"Geography\"] = encoder.fit_transform(dataset[\"Geography\"])\ndataset[\"Gender\"] = encoder.fit_transform(dataset[\"Gender\"])","91ad060b":"dataset[\"Age\"].value_counts().plot.bar(figsize=(20,6))","6809a78f":"facet = sns.FacetGrid(dataset, hue=\"Exited\",aspect=3)\nfacet.map(sns.kdeplot,\"Age\",shade= True)\nfacet.set(xlim=(0, dataset[\"Age\"].max()))\nfacet.add_legend()\n\nplt.show()","0342aa53":"_, ax =  plt.subplots(1, 2, figsize=(15, 7))\ncmap = sns.cubehelix_palette(light=1, as_cmap=True)\nsns.scatterplot(x = \"Age\", y = \"Balance\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = dataset, ax=ax[0])\nsns.scatterplot(x = \"Age\", y = \"CreditScore\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = dataset, ax=ax[1])","2e6f34a8":"plt.figure(figsize=(8, 8))\nsns.swarmplot(x = \"HasCrCard\", y = \"Age\", data = dataset, hue=\"Exited\")","55c41e90":"facet = sns.FacetGrid(dataset, hue=\"Exited\",aspect=3)\nfacet.map(sns.kdeplot,\"Balance\",shade= True)\nfacet.set(xlim=(0, dataset[\"Balance\"].max()))\nfacet.add_legend()\n\nplt.show()","e8f33663":"_, ax = plt.subplots(1, 2, figsize=(15, 6))\nsns.scatterplot(x = \"Balance\", y = \"Age\", data = dataset, hue=\"Exited\", ax = ax[0])\nsns.scatterplot(x = \"Balance\", y = \"CreditScore\", data = dataset, hue=\"Exited\", ax = ax[1])","9e67310d":"facet = sns.FacetGrid(dataset, hue=\"Exited\",aspect=3)\nfacet.map(sns.kdeplot,\"CreditScore\",shade= True)\nfacet.set(xlim=(0, dataset[\"CreditScore\"].max()))\nfacet.add_legend()\n\nplt.show()","87762c77":"plt.figure(figsize=(12,6))\nbplot = dataset.boxplot(patch_artist=True)\nplt.xticks(rotation=90)       \nplt.show()","0939eea0":"plt.subplots(figsize=(11,8))\nsns.heatmap(dataset.corr(), annot=True, cmap=\"RdYlBu\")\nplt.show()","952be138":"X = dataset.drop(\"Exited\", axis=1)\ny = dataset[\"Exited\"]","28850f55":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","cba0e273":"clf = GaussianNB()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","3c3ea458":"clf = LogisticRegression()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","21d5ee3f":"clf = tree.DecisionTreeClassifier()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","ae5ccf8e":"clf = RandomForestClassifier(n_estimators = 200, random_state=200)\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","9bb542e6":"clf  = XGBClassifier(max_depth = 10,random_state = 10, n_estimators=220, eval_metric = 'auc', min_child_weight = 3,\n                    colsample_bytree = 0.75, subsample= 0.9)\n\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","e02b96fe":"scaler = MinMaxScaler() \n\nbumpy_features = [\"CreditScore\", \"Age\", \"Balance\",'EstimatedSalary']\n\ndf_scaled = pd.DataFrame(data = X)\ndf_scaled[bumpy_features] = scaler.fit_transform(X[bumpy_features])","06bb4101":"df_scaled.head()","03b8e56a":"X = df_scaled\nsm  = SMOTE(random_state=42)\nX_res, y_res = sm.fit_sample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size= 0.2, random_state=7)","f728a6cf":"clf = XGBClassifier(max_depth = 12,random_state=7, n_estimators=100, eval_metric = 'auc', min_child_weight = 3,\n                    colsample_bytree = 0.75, subsample= 0.8)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1:\", f1_score(y_test, y_pred))\nprint(\"Area under precision (AUC) Recall:\", average_precision_score(y_test, y_pred))","57ebaada":"# Confusion Matrix\nconfusion_matrix(y_test, y_pred)","a073811c":"## Prediction with ML models:","36105ba1":"__Customer with 3 or 4 products are higher chances to Churn__","fa3d6bbb":"# Bank Customer Churn Prediction\nIn this kernel I am going to make an __Exploratory Data Analysis (EDA)__ on [this](https:\/\/www.kaggle.com\/filippoo\/deep-learning-az-ann) dataset. Also I am going to make different predictive models and find out the best one with highest prediction accuracy. \n\n### Kernel Outlines:\n* __Importing Necessary Packages__\n* __Statistical Summary of the Dataset__\n* __Dropping Irrelevant Features__\n* __One Hot Encoding__\n* __Data Visualization__\n* __Detecting Outliers using Tukey Boxplot__\n* __Hand written function for detecting and removing outliers__\n* __Checking Correlation with Heatmap__\n* __Different ML predictive models__\n    * Gaussian Naive Bayes\n    * Logistic Regression\n    * Decision Tree\n    * Random Forest\n    * Extra Gradient Boosting Tree (XGBoost)\n* __Improve the Predictive Model__\n    * Feature Scaling\n    * Over Sampling","8e3ce071":"### Dropping Irrelevant Feature\n`RowNumber`, `CustomerId` and `Surname` are irrelivant, so we drop those features.","c300e06e":"### __The statistical summary of the dataset__","3e9c138d":"> __That's  it for this kernel.__ If you like this kernel then give a upvote! \ud83d\ude1c","ca540021":"> * __40 to 70 years old customers are higher chances to churn__\n* __Customer with `CreditScore` less then `400` are higher chances to churn__","43a842b3":"### __Detecting Outliers using Tukey Boxplot__","e38b5225":"### __Checking Correlation__","25216471":"## Data Visualization ","abcc56d4":"### Over Sampling","0ba721f5":"### Importing Necessary Packages"}}