{"cell_type":{"0be42e25":"code","1f48d4d5":"code","d7b4e6fd":"code","8c4d1837":"code","6399c66f":"code","29fe9a1c":"code","fa7a7c97":"code","247f6224":"code","769620e8":"code","bf5c8917":"code","695d5033":"code","56ac42db":"code","b61630c4":"code","00566b42":"code","bf48c900":"code","21ac41d6":"code","b3780741":"code","c47efa64":"code","b963b1b8":"code","2035618f":"code","8ff28617":"code","0cc4d997":"code","f283c16b":"code","ebdc5642":"code","0bfa5564":"code","a027ebd9":"code","f3721058":"code","af80a2fd":"code","7d3cede7":"code","e4966799":"markdown","255feef4":"markdown","5a26598c":"markdown","5d32568f":"markdown","be1c3159":"markdown","29717ef0":"markdown","7d8ecf04":"markdown","2ec220e7":"markdown","063edaa7":"markdown","07270020":"markdown","eba0de36":"markdown","ae5fe376":"markdown","e85f1c8f":"markdown","9e43bdea":"markdown","9eec8e32":"markdown"},"source":{"0be42e25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # fancy plotting\nfrom sklearn.manifold import TSNE # visualize high dimensional data \nfrom sklearn.decomposition import PCA # principal component analysis\nfrom sklearn.linear_model import LogisticRegression # Logistic Regression\nfrom sklearn.svm import SVC # SVM\nfrom sklearn.tree import DecisionTreeClassifier # Decision Tree \nfrom sklearn.ensemble import RandomForestClassifier # Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier # Nearest Neighbors\nfrom sklearn.model_selection import StratifiedKFold # For stratified random sampling\nfrom sklearn.model_selection import GridSearchCV # Hyperparameter tuning\nfrom sklearn.model_selection import cross_val_predict # Error analysis\nfrom sklearn.metrics import confusion_matrix # Error analysis\nfrom sklearn.metrics import accuracy_score # Find accuracy\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f48d4d5":"# Set pandas to display all output\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","d7b4e6fd":"train = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/eval.csv')","8c4d1837":"train.info()","6399c66f":"train.describe()","29fe9a1c":"test.info()","fa7a7c97":"test.describe()","247f6224":"# this just bothers me\ntrain.rename(columns={'strong_janguage': 'strong_language'}, inplace=True)\ntest.rename(columns={'strong_janguage': 'strong_language'}, inplace=True)","769620e8":"sns.set_style('darkgrid')","bf5c8917":"# list of relevant columns\/values for searching\n\nratings = ['E', 'ET', 'T', 'M']\n\ncols = ['no_descriptors', 'console',\n        'alcohol_reference', 'drug_reference', 'use_of_alcohol', 'use_of_drugs_and_alcohol', \n        'animated_blood', 'mild_blood', 'blood', 'blood_and_gore',\n        'mild_cartoon_violence', 'cartoon_violence', 'mild_fantasy_violence', 'fantasy_violence', 'mild_violence', 'violence', 'intense_violence',\n        'crude_humor', 'mature_humor',\n        'mild_language', 'language', 'strong_language', 'mild_lyrics', 'lyrics',\n        'partial_nudity', 'nudity',\n        'simulated_gambling', \n        'mild_suggestive_themes', 'suggestive_themes', 'sexual_themes', 'sexual_content', 'strong_sexual_content',\n        'esrb_rating']","695d5033":"# separate relevant features for visualization\nfeatures = train.loc[:, cols]\n\n# encode ratings numerically\n# the way the ratings appear in the train dataset, they will be encoded in order [E, ET, T, M]\n# low correlation values correspond to more likely to be E and high correlation values correspond to more likely to be M\nfeatures['esrb_encoded'] = train['esrb_rating'].apply(lambda rating: train['esrb_rating'].unique().tolist().index(rating))","56ac42db":"# Correlation matrix for ratings\n\ncorr = features.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nfig = plt.figure(figsize=(12, 9))\nsns.heatmap(features.corr(), mask=mask, center=0, linewidths=1, cmap='icefire', square=True)","b61630c4":"# Correlation matrix for *individual* ratings\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 16), constrained_layout=True) # ik it's huge but I'm trying not to make it look cramped\n\nfor index, rating in enumerate(ratings):\n    r_df = features[features['esrb_rating'] == rating].iloc[:, :-1]\n    corr = r_df.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    g = sns.heatmap(r_df.corr(), mask=mask, center=0, vmax=0.5, vmin=-0.5, linewidths=1, cmap='icefire', square=True, ax=axes[index\/\/2][index%2])\n    g.set_title('Rating: ' + rating)","00566b42":"# See if we can drop some columns to help differentiate between ratings\n\nsums = pd.DataFrame(pd.Series(cols), columns=['categories'])\n\nfor r in ratings:\n    sums[r] = train[train['esrb_rating'] == r][cols].sum().tolist()\nsums['totals'] = train[cols].sum().tolist()\nsums.drop(index=32, inplace=True)\nsums\n\n# drop candidates: cartoon_violence, mild_violence, mild_suggestive_themes, animated_blood, crude_humor","bf48c900":"# downsample\n\n# sample = train[train['esrb_rating'] == 'T'].sample(n=200, random_state=69)\n# train.drop(index=sample.index, inplace=True)","21ac41d6":"X = train.drop(['id', 'title', 'esrb_rating'], axis=1)\ny = train['esrb_rating']\nZ = test.drop(['id'], axis=1)","b3780741":"# PCA \n\n# pca = PCA(n_components=4)\n# X = pca.fit_transform(X)\n#Z = pca.transform(Z)\n# pca.explained_variance_ratio_","c47efa64":"# drop columns\n\n# X.drop(['cartoon_violence', 'mild_violence', 'mild_suggestive_themes', 'animated_blood', 'crude_humor'], axis=1, inplace=True)\n# Z.drop(['cartoon_violence', 'mild_violence', 'mild_suggestive_themes', 'animated_blood', 'crude_humor'], axis=1, inplace=True)","b963b1b8":"# Ensure the splits are consistent across all models \n\nskcv = StratifiedKFold(n_splits=10, shuffle=True, random_state=69)","2035618f":"lreg_params = {'C': [1, 10, 100, 500, 1000]} # hyperparameter grid  \n\nlreg = GridSearchCV(LogisticRegression(max_iter=10000),\n                  lreg_params,\n                  scoring='accuracy',             \n                  n_jobs=-1,\n                  cv=skcv)\n\nlreg.fit(X, y)\nlreg.best_params_","8ff28617":"svc_params = {'C': [0.1, 1, 2, 10, 100, 500],\n              'kernel': ['poly', 'rbf'],\n              'degree': [2, 3, 4, 5],\n              'gamma': ['scale', 'auto'],\n              'decision_function_shape': ['ovo', 'ovr']}\n\nsvc = GridSearchCV(SVC(),\n                  svc_params,\n                  scoring='accuracy',             \n                  n_jobs=-1,\n                  cv=skcv)\n\nsvc.fit(X, y)\nsvc.best_params_","0cc4d997":"dt_params = {'criterion': ['entropy'],\n             'splitter': ['best', 'random'],\n             'min_samples_split': [2, 3, 4],\n             'max_depth': [20, 50, 100, 500, 1000]}\n\ndt = GridSearchCV(DecisionTreeClassifier(class_weight='balanced', random_state=69), \n                  dt_params,\n                  scoring='accuracy',             \n                  n_jobs=-1,\n                  cv=skcv)\n\ndt.fit(X, y)\ndt.best_params_","f283c16b":"rndm_params = {'n_estimators': [100, 200, 500], \n               'criterion': ['entropy'],\n               'min_samples_split': [2, 3, 4],\n               'max_depth': [10, 20, 50],\n               'bootstrap': [True, False]}\n\nrndm = GridSearchCV(RandomForestClassifier(n_jobs=-1, random_state=69), \n                  rndm_params,\n                  scoring='accuracy',\n                  n_jobs=-1,\n                  cv=skcv)\n\nrndm.fit(X, y)\nrndm.best_params_","ebdc5642":"knn_params = {'n_neighbors': [2, 5, 8, 10, 20],\n              'weights': ['uniform', 'distance'],\n              'p': [1, 2]}\n\nknn = GridSearchCV(KNeighborsClassifier(n_jobs=-1),\n                  knn_params,\n                  scoring='accuracy',             \n                  n_jobs=-1,\n                  cv=skcv)\n\nknn.fit(X, y)\nknn.best_params_","0bfa5564":"# For model evaluation\n\ncv_splits = ['split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score']\nmodels = [lreg, svc, dt, rndm, knn]\ntitles = ['Logistic Regression', 'Support Vector Machine', 'Decision Tree', 'Random Forest', 'K Nearest Neighbors']\n\ncv_results = {split: [] for split in cv_splits}\n\nfor model in models:\n    for split in cv_splits:\n        cv_results[split].append(model.cv_results_[split][model.best_index_])\n        \ncv_results = pd.DataFrame.from_dict(cv_results, orient='index', columns=titles)\ncv_results.describe()","a027ebd9":"# Plot distribution of validation scores\n\nfig, axes = plt.subplots(nrows=1, ncols=5, sharex=True, sharey=True, figsize=(20, 5), constrained_layout=True)\nfor index, column in enumerate(cv_results.columns):\n    g = sns.histplot(data=cv_results, x=column, ax=axes[index], bins=5, stat='count', kde=True)","f3721058":"# Plot confusion matrices\n\nfig, axes = plt.subplots(nrows=1, ncols=5, sharex=True, sharey=True, figsize=(20, 5), constrained_layout=True)\n\nfor index, model in enumerate(models):\n    y_pred = cross_val_predict(model.best_estimator_, X, y, cv=skcv)\n    conf = confusion_matrix(y, y_pred, labels=['E', 'ET', 'T', 'M'])\n    np.fill_diagonal(conf, 0)\n    g = sns.heatmap(conf,\n                    vmax=80,\n                    xticklabels=['E', 'ET', 'T', 'M'],\n                    yticklabels=['E', 'ET', 'T', 'M'],\n                    annot=True,\n                    linewidths=1,\n                    square=True,\n                    cmap='rocket_r',\n                    ax=axes[index],\n                    cbar=(index==4))\n    g.tick_params(labelbottom = False, bottom=False, top = False, labeltop=True)\n    g.set_xlabel('Predicted')\n    g.xaxis.set_label_position('top')\n    g.set_ylabel('True')\n    g.set_title(titles[index])","af80a2fd":"# accuracy scores\n\n# accuracy = []\n# for model in models:\n#     y_pred = model.best_estimator_.predict(X)\n#     accuracy.append(accuracy_score(y, y_pred))\n    \n# print(accuracy)","7d3cede7":"# Support Vector Machine seems to have performed the best\n\ny_pred = svc.best_estimator_.predict(Z)\noutput = pd.DataFrame({'id': test.id, 'esrb_rating': y_pred})\noutput.to_csv('submission.csv', index=False)\noutput","e4966799":"## SVM","255feef4":"## Logistic Regression","5a26598c":"## Take a look at train dataset","5d32568f":"## Prepare submission","be1c3159":"## Visualizing the data","29717ef0":"## Observations\nAll columns seem to be binary categories, except for `'esrb_rating'` (text categories) and `'title'`\n### Missing values\nThere are **no missing values**\n### Outliers in the data\nBecause every column represents a binary category, there are **no outliers** in the data","7d8ecf04":"# Load the data","2ec220e7":"## Take a look at test dataset","063edaa7":"## Decision Tree","07270020":"## Nearest Neighbors","eba0de36":"# Build models","ae5fe376":"# Exploratory data analysis","e85f1c8f":"## Random Forest","9e43bdea":"## Notes on games with same values but different ratings\n* There are 12 games that can be E, ET, or T\n    * All of them only have `'mild_violence'` column set to 1 and the rest to 0\n        * 4 E, 4 ET, 4 T\n* There are only 37 games that can be E or ET\n    * All of them only have `'mild_blood'` column set to 1 and the rest to 0\n        * 35 E, 2 ET\n* There are 231 games that can be ET or T\n    * 7 of them only have `'suggestive_themes'` set to 1 and the rest to 0\n        * 6 ET, 1 T\n    * 92 of them only have `'fantasy_violence'` set to 1 and the rest to 0\n        * 72 ET, 20 T\n    * 43 of them only have `'console'` and `'fantasy_violence'` set to 1 and the rest to 0\n        * 33 ET, 10 T\n    * 181 ET, 49 T\n* There are 106 games that can be T or M\n    * Most of them have at least one of `alcohol_reference'`, `'animated_blood'`, `'blood'`, `'blood_and_gore'`, or `'cartoon_violence'` set to 1\n        * 73 T, 33 M\n* 386 total games in this category\n    * 39 E\n    * 187 ET\n    * 126 T\n    * 33 M","9eec8e32":"## Prepare the data\nNo data transformation or feature engineering was done as it didn't affect model performance. Downsampling and PCA were attempted but didn't drastically improve performance on evaluation dataset"}}