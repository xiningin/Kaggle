{"cell_type":{"41fe615d":"code","eec0fbb6":"code","dfc7e46d":"code","c4782802":"code","7cd8aa3c":"code","f2ac1bac":"code","5d4a6f7c":"code","108246e3":"code","08dbf195":"code","b065a431":"code","362b92e9":"code","6de7afb3":"code","a8a8a049":"code","32069cf5":"code","5ec5af56":"code","95d31311":"code","db7f7f71":"code","7b2502fe":"code","85d1ae6d":"markdown","f53bbf50":"markdown","fd0602fa":"markdown","a1bff65e":"markdown","e311ae03":"markdown","208ed0da":"markdown","9f228770":"markdown","175ee422":"markdown","7a356eff":"markdown","fd598db2":"markdown"},"source":{"41fe615d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# SKLearn libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import fetch_california_housing\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nnp.random.seed(0)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","eec0fbb6":"house_data = pd.read_csv(\"\/kaggle\/input\/california-housing-prices\/housing.csv\")\n\nprint(house_data.columns)\n\n# Drop text variable\nhouse_data = house_data.drop('ocean_proximity', axis=1)","dfc7e46d":"feature_cols = ['median_income', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'latitude', 'longitude']\n\ntarget_col = 'median_house_value'\n","c4782802":"# Getting feature and target data\nX = house_data[feature_cols]\ny = house_data[target_col]\n\n","7cd8aa3c":"house_data.describe().T","f2ac1bac":"# Apply divide the amount by 100K\nhouse_data['median_house_value'] = house_data['median_house_value'].apply(lambda n: n\/100000)","5d4a6f7c":"# Spliting data into Train, Holdout and Test\nX_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Split the train data for holdout set\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)","108246e3":"def standardize(X_train, X_valid, X_test):\n    \"\"\"\n    :param X_train, X_test: training set and test set\n    \"\"\"\n    # scaler object\n    scaler = StandardScaler()\n    \n    scaler.fit(X_train)\n    \n    X_train_scaled = scaler.transform(X_train)\n    X_valid_scaled = scaler.transform(X_valid)\n    X_test_scaled = scaler.transform(X_test) # test or valid data\n    \n    return X_train_scaled,X_valid_scaled, X_test_scaled\n    \n\n# Standardize the data\nX_train_scaled, X_valid_scaled, X_test_scaled = standardize(X_train, X_valid, X_test)\n    ","08dbf195":"X_train_scaled.shape[1]","b065a431":"# Model based on sequential API\ndef build_sequential(n_units=30):\n    model = keras.models.Sequential()\n\n    model.add(keras.layers.Dense(n_units, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n    model.add(keras.layers.Dense(1))\n    \n    return model\n","362b92e9":"model = build_sequential()\n\nmodel.summary()","6de7afb3":"# Compile the model\nmodel.compile(loss='mean_squared_error',\n             optimizer='sgd',\n             metrics=['mae'])\n\n# fit the model with data\nhistory = model.fit(X_train_scaled, y_train,\n                   epochs=20,\n                   validation_data=(X_valid_scaled, y_valid),\n                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n                   verbose=1)\n\n","a8a8a049":"def functional_model():\n    \n    input_layer = keras.layers.Input(shape=(X_train_scaled.shape[1],))\n    \n    hidden_1 = keras.layers.Dense(30, activation='relu')(input_layer) # Passing layer as parameter\n    hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n    \n    concat = keras.layers.Concatenate()([input_layer, hidden_2]) # concatinates input and output of second layer\n    output_layer = keras.layers.Dense(1)(concat)\n    \n    model = keras.Model(inputs=[input_layer], outputs=[output_layer])\n    \n    return model\n    \n# build model\nmodel_b = functional_model()\n\nmodel_b.summary()\n    ","32069cf5":"# Compile the model\nmodel_b.compile(loss='mean_squared_error',\n             optimizer='sgd',\n             metrics=['mae'])\n\n# fit the model with data\nhistory = model_b.fit(X_train_scaled, y_train,\n                   epochs=20,\n                   validation_data=(X_valid_scaled, y_valid),\n                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n                   verbose=1)","5ec5af56":" X_train_scaled[:, 1:]","95d31311":"# Splite \nX_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 1:]\nX_valid_A, X_valid_B = X_valid_scaled[:, :5], X_valid_scaled[:, 1:]\n\nX_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 1:]","db7f7f71":"input_A = keras.layers.Input(shape=(5,), name='wide_input')\ninput_B = keras.layers.Input(shape=(6,), name='deep_input')\n\nhidden_1 = keras.layers.Dense(30, activation='relu')(input_B)\nhidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n\nconcat = keras.layers.Concatenate()([input_A, hidden_2])\n\noutput = keras.layers.Dense(1, name='output')(concat)\n\nmulti_model = keras.Model(inputs=[input_A, input_B], outputs=[output])\n\nmulti_model.summary()","7b2502fe":"# Compile the model\nmulti_model.compile(loss='mse',\n             optimizer=keras.optimizers.SGD(lr=1e-3),\n                   metrics=['mae'])\n\nhistory = multi_model.fit((X_train_A, X_train_B), \n                    y_train,\n                   validation_data=((X_valid_A, X_valid_B), y_valid),\n                   epochs=20,\n                   verbose=1)\n\nresult = multi_model.evaluate((X_test_A, X_test_B), y_test)\n\nprint(result)","85d1ae6d":"## Split the data","f53bbf50":"## Load Dataset","fd0602fa":"## Building Functional API\n\n\n![image.png](attachment:image.png)","a1bff65e":"# Model building","e311ae03":"## Import Required Libraries","208ed0da":"## Functional Model handline multiple input\n\n\nThis approach allows to send a subset of features through the wide path and a different subset through deep path.\n\n","9f228770":"### Transform the \"Price\" to lower value\n\nThe price of the house is in thousands. The **max amount** is **500K** and the min value is **14.9K**. We will make it a smaller number by divide them by 100K.","175ee422":"## Exploratory Analysis\n","7a356eff":"# \ud83c\udfe1House Price Prediction Model(Neural Network)\n\n## Overview\n\nThe dataset is about california house features and prices. The data object has different properties about the house such as number of rooms, bedrooms, size, age of the house, longitude and lattitude. We need to predict the `Price` of the house by considering the attributes of the house. \n","fd598db2":"The network of the model as 1 input\/hidden layer and 1 output layer. \n\n![image.png](attachment:image.png)"}}