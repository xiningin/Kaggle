{"cell_type":{"20919ba3":"code","21de509d":"code","b18bbab3":"code","0765d66d":"code","abf466e1":"code","e50e3ada":"code","87799a05":"code","9be4b380":"code","de94d6b7":"code","ab14ab10":"code","366b69f1":"code","4b0be0d9":"code","104901aa":"code","cc253e03":"code","7f169254":"code","d132e073":"code","139bfaf0":"code","2b30321f":"code","81f80dc1":"code","5d3cbaa7":"code","29d3f114":"code","57e50ece":"code","99422a89":"code","cedc73f3":"markdown","0ca0e203":"markdown","9f5d5a20":"markdown","8bbb47a9":"markdown","078fe3f9":"markdown","f8497acf":"markdown","54df6770":"markdown","0f3fdd1a":"markdown"},"source":{"20919ba3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21de509d":"!mkdir -p \/kaggle\/temp\/\n!unzip \/kaggle\/input\/dogs-vs-cats\/test1.zip -d \/kaggle\/temp\/\n!unzip \/kaggle\/input\/dogs-vs-cats\/train.zip -d \/kaggle\/temp\/","b18bbab3":"train_data_path = \"\/kaggle\/temp\/train\/\"\ntest_data_path = \"\/kaggle\/temp\/test1\/\"\nsample_submission_path = \"\/kaggle\/input\/dogs-vs-cats\/sampleSubmission.csv\"","0765d66d":"sample_submission = pd.read_csv(sample_submission_path)\nsample_submission.head()","abf466e1":"import torch\nimport cv2\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.transforms as T\nfrom typing import Dict, Callable, Optional, Any, Tuple\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport multiprocessing","e50e3ada":"class ResizeImage(object):\n    def __init__(self, image:Image, ratio:float, pad:Tuple[float, float]):\n        self.image = image\n        self.ratio = ratio\n        self.pad = pad","87799a05":"def load_image(path:str, new_shape: Tuple[int, int]) -> Tuple[Any, ResizeImage]:\n    # new_shape tuple [Height, Width]\n    img = Image.open(path)\n    w0, h0 = img.size # Pillow give us [Width, Height]\n    \n    # Scale ratio (new \/ old) -> min(h_new\/h_old, w_new\/w_old)\n    # This secure to resize the large dimension first\n    r = min(new_shape[0]\/h0, new_shape[1]\/w0)\n    \n    # new un_pad dimensions keeping aspec ratio\n    new_unpad = int(round(h0 * r)), int(round(w0 * r))\n    # Compute padding\n    dw, dh = new_shape[1] - new_unpad[1], new_shape[0] - new_unpad[0]\n    dw \/= 2; dh \/= 2;\n    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n    \n    # First Stage Preprocessing Transforms\n    inteli_resize = T.Compose([\n        T.Resize(new_unpad),\n        T.Pad((left, top, right, bottom), fill=(0,0,0))\n    ])\n    \n    return (img, ResizeImage(inteli_resize(img), r, (dw, dh)))           ","9be4b380":"class CatsVsDogs(Dataset):\n    def __init__(self, path: str, train: bool,\n                transforms: Optional[Callable] = None,\n                new_shape: Optional[Tuple[int, int]] = (224, 224)) -> None:\n        \n        self.img_paths = os.listdir(path)\n        self.name_classes = {'cat': 0,\n                                'dog': 1}\n        self.new_shape = new_shape\n        self.transforms = transforms\n        \n        if train:\n            self.classes = [self.name_classes[img_path.split(\".\")[0]] for img_path in self.img_paths]\n        else:\n            # In this case classes will contains images ids\n            self.classes = [int(img_path.split(\".\")[0]) for img_path in self.img_paths]\n        \n        self.img_paths = [os.path.join(path, img_path) for img_path in self.img_paths]\n            \n    \n    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        _, resize_image = load_image(self.img_paths[index], self.new_shape)\n        if self.transforms is not None:\n            tensor_img = self.transforms(resize_image.image)\n        else:\n            transforms = T.Compose([\n                T.ToTensor(),\n                T.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n            ])\n            tensor_img = transforms(resize_image.image)\n        return tensor_img, torch.tensor(self.classes[index], dtype=torch.float32)\n        \n    def __len__(self) -> int:\n        return len(self.img_paths)","de94d6b7":"class CatsVsDogsDataModule(pl.LightningDataModule):\n    def __init__(self, train_dir: str, test_dir: str):\n        super().__init__()\n        self.train_dir = train_dir\n        self.test_dir = test_dir\n        self.transform = T.Compose([\n            T.ToTensor(),\n            T.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225])\n        ])\n        # self.dims is returned when you call dm.size()\n        # Setting default dims here because we know them.\n        # Could optionally be assigned dynamically in dm.setup()\n        self.dims = (3, 224, 224)\n\n    def prepare_data(self):\n        # download\n        pass\n\n    def setup(self, stage=None):\n        # Assign train\/val datasets for use in dataloaders\n        if stage == 'fit' or stage is None:\n            dataset_full = CatsVsDogs(self.train_dir, train=True,\n                                    transforms=self.transform, new_shape=self.dims[1:])\n            self.train_dataset, self.val_dataset = random_split(dataset_full, [int(len(dataset_full)*0.8),\n                                                                               len(dataset_full) - int(len(dataset_full)*0.8)])\n\n        # Assign test dataset for use in dataloader(s)\n        if stage == 'test' or stage is None:\n            self.test_dataset = CatsVsDogs(self.test_dir, train=False,\n                                           transforms=self.transform, new_shape=self.dims[1:])\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=16, shuffle=True,\n                         num_workers = multiprocessing.cpu_count())\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=16, shuffle=False,\n                         num_workers = multiprocessing.cpu_count())\n\n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=16, shuffle=False,\n                         num_workers = multiprocessing.cpu_count())","ab14ab10":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import models","366b69f1":"class VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16, self).__init__()\n        self.vgg16 = models.vgg16(pretrained=True)\n        self.vgg16.classifier[-1] = nn.Linear(in_features = 4096, out_features = 1)\n        \n    def forward(self, x):\n        x = self.vgg16(x)\n        return x.view(-1)","4b0be0d9":"from pytorch_lightning.callbacks import LearningRateMonitor\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\nclass CatVsDogLitModel(pl.LightningModule):\n    def __init__(self, model: nn.Module, lr:int):\n        super(CatVsDogLitModel, self).__init__()\n        self.model = model\n        self.lr = lr\n        \n    def forward(self, x):\n        y = self.model(x)\n        return y\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        bs, _, _, _ = x.size()\n        y_hat = self(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        bs, _, _, _ = x.size()\n        y_hat = self(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n        self.log('val_loss', loss, prog_bar=True)\n    \n    \n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True)\n        return {\n           'optimizer': optimizer,\n           'lr_scheduler': scheduler, # Changed scheduler to lr_scheduler\n           'monitor': 'val_loss'\n       }","104901aa":"data = CatsVsDogsDataModule(train_dir=train_data_path, test_dir=test_data_path)\n\nae_model = CatVsDogLitModel(VGG16(), 1e-3)\nlr_monitor = LearningRateMonitor(logging_interval='step')\n\ntrainer = pl.Trainer(gpus=1, max_epochs=25, amp_level='O2', precision=16, callbacks=[lr_monitor,\n                                                                                     EarlyStopping(monitor='val_loss')])\n\nlr_finder = trainer.tuner.lr_find(ae_model, data)\nlr_finder.results\n\nfig = lr_finder.plot(suggest=True)\nnew_lr = lr_finder.suggestion()\nae_model.lr = new_lr","cc253e03":"trainer.fit(ae_model, data)","7f169254":"from tqdm.notebook import tqdm\n\npbar = tqdm(total=len(data.val_dataset),\n           desc=\"Metric\")\n\nae_model.eval()\nae_model.cuda()\n \nreal_ = []\npred_ = []\nfor x, y in data.val_dataset:\n    with torch.no_grad():\n        y_hat = ae_model(x.unsqueeze(0).cuda()).sigmoid()\n        pred = (y_hat > 0.5).to(dtype=torch.float32)\n    \n    real_.append(y.item())\n    pred_.append(pred.item())\n    \n    pbar.update(1)\n    \nreal_ = np.array(real_)\npred_ = np.array(pred_)\n\naccuracy = sum(real_ == pred_)\/len(real_) * 100\naccuracy","d132e073":"import random\nindexes = np.where(real_ != pred_)[0]\nchoices = random.choices(range(len(indexes)), k=10)\n\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nunormalize = T.Normalize(mean=-mean\/std,\n            std=1.0\/std)\n\nprint(choices)\ndata.setup(stage=\"test\")\nplt.figure(figsize=(45, 45), tight_layout=True)\nfor j, i in enumerate(choices):\n    plt.subplot(1, len(choices), j + 1)\n    x, y = data.val_dataset[indexes[i]]\n    plt.title(f\"class {list(data.test_dataset.name_classes.keys())[int(y.item())]},\" + \\\n             f\" pred {list(data.test_dataset.name_classes.keys())[int(pred_[indexes[i]])]}\")\n    plt.imshow(np.transpose(unormalize(x), (1, 2, 0)))\nplt.show()","139bfaf0":"pbar = tqdm(total=len(data.test_dataset),\n           desc=\"Test Set Predict\")\n\nae_model.eval()\nae_model.cuda()\n \npred_ = []\nidx_ = []\nfor x, y in data.test_dataset:\n    with torch.no_grad():\n        y_hat = ae_model(x.unsqueeze(0).cuda()).sigmoid()\n        pred = (y_hat > 0.5).to(dtype=torch.float32)\n    \n    idx_.append(y.item())\n    pred_.append(pred.item())\n    \n    pbar.update(1)\n    \npred_ = np.array(pred_)\nidx_ = np.array(idx_)","2b30321f":"ae_model.eval()\nae_model.cpu()\nae_model.to_torchscript(\"\/kaggle\/working\/model.torch.pt\", example_inputs=torch.randn(1, 3, 224, 224))","81f80dc1":"pred_ = pred_.astype(np.int64); idx_ = idx_.astype(np.int64)","5d3cbaa7":"submission = sample_submission.copy()\nsubmission.head()","29d3f114":"submission.set_index(\"id\", inplace=True, drop=True)\nsubmission.loc[idx_, \"label\"] = pred_","57e50ece":"submission.reset_index(inplace=True)\nsubmission.head()","99422a89":"submission.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","cedc73f3":"## Creating Dataset","0ca0e203":"# Save submissions","9f5d5a20":"# Loading Data","8bbb47a9":"# Get Metrics results with validation dataset","078fe3f9":"# Define Model","f8497acf":"# Save model","54df6770":"# Unzipping Data","0f3fdd1a":"# Get results\n"}}