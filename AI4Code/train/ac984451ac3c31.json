{"cell_type":{"45e86e9a":"code","63e075cd":"code","a09e2a23":"code","08a096c7":"code","17acd97b":"code","1b230ad1":"code","19b7babc":"code","c6cf1bd7":"code","cbca1fc7":"code","13472900":"code","4fdc1c49":"code","988b1122":"code","f0c3f0e1":"code","ddb4376e":"code","34dcd56b":"code","726fb32e":"code","d28a049b":"code","edfd0da3":"code","c48a67bd":"code","18bfb029":"code","b4a8529b":"code","3bf29a63":"code","eba2b7dc":"markdown","230fae72":"markdown","6878c015":"markdown","612cd17c":"markdown","77064447":"markdown","61fac945":"markdown","50b97eec":"markdown","2f030832":"markdown","d76f5d76":"markdown","f9f1d213":"markdown","f1fc0c32":"markdown","d32a5ab2":"markdown","82bbd55a":"markdown","c8dee554":"markdown","3ac96529":"markdown","09c8ff84":"markdown","85a496ba":"markdown","fa089ba7":"markdown","c543bb49":"markdown","63919238":"markdown","d6eccf44":"markdown","b6bf018f":"markdown","585a53f4":"markdown","e6cbc2f3":"markdown","7fa310c3":"markdown","eb5fa965":"markdown","154f5dca":"markdown","efed8642":"markdown","f5c73c58":"markdown","a45a3815":"markdown","1e3186b7":"markdown","d9cb1c5e":"markdown","9b66b480":"markdown","898f18ff":"markdown","3b02aef1":"markdown","d8bb0eed":"markdown"},"source":{"45e86e9a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom itertools import combinations\nfrom time import sleep, time\nfrom IPython.display import clear_output\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_blobs\nfrom K_Means.K_Means_Vanilla import Kmeans\nfrom K_Means.K_Means_Boost import KmeansBoost","63e075cd":"def perfomance_2d(num_clusters):\n    for it in range(2, num_clusters + 1):\n        df = np.zeros((0,2))\n        for i in range(it):\n            df = np.vstack((df, np.random.uniform(i, i + 1, size=(500,2))))\n\n        model = Kmeans(num_clusters = it, similiarity=\"euclidian\", max_iter=20)\n        model.fit(df)\n        df = pd.DataFrame(df)\n        df = df.rename(columns={ 0: \"x\", 1: \"y\"})\n        for i in range(len(model.centroids_stack)):\n            plt.figure(figsize= (8, 8))\n            sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=model.labels_stack[i] )\n            sns.scatterplot(x=model.centroids_stack[i][:, 0], y=model.centroids_stack[i][:, 1], marker=\"*\", s=300)\n            plt.show()\n            sleep(0.2)\n            clear_output(wait=True)\n        sleep(2)\n       \n","a09e2a23":"perfomance_2d(5)","08a096c7":"def perfomance_blobs(num_clusters):\n    for it in range(2, num_clusters + 1):\n        df, _ = make_blobs(n_features=2, n_samples=it * 200, centers=it)\n        model = Kmeans(num_clusters = it, similiarity=\"euclidian\", max_iter=20)\n        model.fit(df)\n        df = pd.DataFrame(df)\n        df = df.rename(columns={ 0: \"x\", 1: \"y\"})\n        for i in range(len(model.centroids_stack)):\n            plt.figure(figsize= (8, 8))\n            sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=model.labels_stack[i] )\n            sns.scatterplot(x=model.centroids_stack[i][:, 0], y=model.centroids_stack[i][:, 1], marker=\"*\", s=300)\n            plt.show()\n            sleep(0.2)\n            clear_output(wait=True)\n        sleep(2)\n       ","17acd97b":"perfomance_blobs(7)","1b230ad1":"def perfomance_3d(num_clusters):\n    for it in range(2, num_clusters + 1):\n        df = np.zeros((0,3))\n        for i in range(it):\n            df = np.vstack((df, np.random.uniform(i, i + 1, size=(500,3))))\n\n        model = Kmeans(num_clusters = it, similiarity=\"euclidian\", max_iter=30)\n        model.fit(df)\n        \n        sns.set_style(\"whitegrid\")\n        for i in range(len(model.centroids_stack)):\n        \n            fig = plt.figure(figsize=(10,10))\n            ax = Axes3D(fig)\n\n            sc_1 = ax.scatter(model.centroids_stack[i][:, 0], model.centroids_stack[i][:, 1], zs=model.centroids_stack[i][:, 2], \n                                                                                              zdir=\"z\", \n                                                                                              marker=\"$CENTER$\",\n                                                                                              s=1500,\n                                                                                              alpha=1,\n                                                                                              c=\"brown\")\n            sc = ax.scatter(df[:, 0], df[:, 1], zs=df[:, 2], zdir='z', c=model.labels_stack[i], \n                                                                   marker='o',\n                                                                   alpha=0.7)\n            ax.set_xlabel('X')\n            ax.set_ylabel('Y')\n            ax.set_zlabel('Z')\n            plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.5, 1.2), loc=0)\n            plt.show()\n            sleep(0.2)\n            clear_output(wait=True)\n        sleep(2)","19b7babc":"perfomance_3d(5)","c6cf1bd7":"df = np.zeros((0, 2))\nnum_clusters = 3\nfor i in range(2, num_clusters):\n    df = np.vstack((df, np.random.uniform(1, 2, size=(100,2))))\n\nmodel = Kmeans(similiarity=\"euclidian\", max_iter=15, auto_clusters=True)\nmodel.fit(df)\nmetric_df =  pd.DataFrame(model.metric, columns={\"F_metric\"}).reset_index().rename(columns={\"index\": \"Number_of_clusters\"})\nmetric_df[\"Number_of_clusters\"] += 2\nplt.figure(figsize=(8, 8))\nsns.barplot(data = metric_df, y=\"F_metric\", x=\"Number_of_clusters\")","cbca1fc7":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0,2))\n    for i in range(30):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,2))))\n    model = Kmeans(num_clusters = 3, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of clusters = 3: {} ms\".format((time_end - time_start) * 10, '.2f'))","13472900":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0,2))\n    for i in range(30):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,2))))\n    model = Kmeans(num_clusters = 30, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of clusters = 30: {} ms\".format((time_end - time_start) * 10, '.2f'))","4fdc1c49":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0,2))\n    for i in range(10):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,2))))\n    model = Kmeans(num_clusters = 2, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of rows = 3000: {} ms\".format((time_end - time_start) * 10, '.2f'))","988b1122":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0,2))\n    for i in range(1000):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,2))))\n    model = Kmeans(num_clusters = 2, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of rows = 300000: {} ms\".format((time_end - time_start) * 10, '.2f'))","f0c3f0e1":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0, 5))\n    for i in range(10):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300, 5))))\n    model = Kmeans(num_clusters = 2, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of columns = 5: {} ms\".format((time_end - time_start) * 10, '.2f'))","ddb4376e":"time_start = time()\nfor i in range(100):\n    df = np.zeros((0, 50))\n    for i in range(10):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300, 50))))\n    model = Kmeans(num_clusters = 2, similiarity=\"euclidian\")\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of columns = 50: {} ms\".format((time_end - time_start) * 10, '.2f'))","34dcd56b":"time_start = time()\nfor i in range(50):\n    df = np.zeros((0,10))\n    for i in range(100):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,10))))\n    model = Kmeans(num_clusters = 10, similiarity=\"euclidian\", max_iter=20)\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of rows = 30000: {} ms\".format((time_end - time_start) * 5, '.2f'))","726fb32e":"time_start = time()\nfor i in range(50):\n    df = np.zeros((0,10))\n    for i in range(100):\n        df = np.vstack((df, np.random.uniform(i, i + 1, size=(300,10))))\n    model = KmeansBoost(num_clusters = 10, similiarity=\"euclidian\", max_iter=20)\n    model.fit(df)\ntime_end = time()\nprint(\"Mean time of one fit() for model with num of rows = 30000: {} ms\".format((time_end - time_start) * 5, '.2f'))","d28a049b":"def comparasion_perfomance_2d(num_clusters):\n    for it in range(2, num_clusters + 1):\n        df = np.zeros((0,2))\n        for i in range(it):\n            df = np.vstack((df, np.random.uniform(i, i + 1, size=(500,2))))\n\n        modelboost = KmeansBoost(num_clusters = it, similiarity=\"euclidian\", max_iter=20)\n        modelboost.fit(df)\n        model = Kmeans(num_clusters = it, similiarity=\"euclidian\", max_iter=20)\n        model.fit(df)\n        df = pd.DataFrame(df)\n        df = df.rename(columns={ 0: \"x\", 1: \"y\"})\n        for i in range(max(len(model.centroids_stack), len(modelboost.centroids_stack))):\n            fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16, 10))\n            if i <  len(model.centroids_stack):\n                sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=model.labels_stack[i], ax=ax1)\n                sns.scatterplot(x=model.centroids_stack[i][:, 0], \n                                        y=model.centroids_stack[i][:, 1], marker=\"*\", s=300, ax=ax1)\n                ax1.set_xlabel(\"Vanila\")\n            if i >=  len(model.centroids_stack):\n                j = len(model.centroids_stack) -1 \n                sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=model.labels_stack[j], ax=ax1 )\n                sns.scatterplot(x=model.centroids_stack[j][:, 0], \n                                        y=model.centroids_stack[j][:, 1], marker=\"*\", s=300, ax=ax1)\n                ax1.set_xlabel(\"Vanila\")\n                \n            if i < len(modelboost.centroids_stack):\n                sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=modelboost.labels_stack[i], ax=ax2)\n                sns.scatterplot(x=modelboost.centroids_stack[i][:, 0], \n                                        y=modelboost.centroids_stack[i][:, 1], marker=\"*\", s=300, ax=ax2)\n                ax2.set_xlabel(\"Boost\")\n                \n            if i >= len(modelboost.centroids_stack):\n                j = len(modelboost.centroids_stack) - 1 \n                sns.scatterplot(data = df, x=\"x\", y=\"y\", hue=modelboost.labels_stack[j], ax=ax2)\n                sns.scatterplot(x=modelboost.centroids_stack[j][:, 0], \n                                        y=modelboost.centroids_stack[j][:, 1], marker=\"*\", s=300, ax=ax2)\n                ax2.set_xlabel(\"Boost\")\n            fig.show()\n            plt.show()\n            sleep(0.2)\n            clear_output(wait=True)\n        sleep(2)","edfd0da3":"comparasion_perfomance_2d(7)","c48a67bd":"x_1 = np.linspace(0 , np.pi, num=200).reshape(-1, 1)\nx_2 = np.linspace(np.pi,  2 * np.pi, num=200).reshape(-1, 1)\ny_1 = np.sin(x_1) - .1\ny_2 = np.sin(x_2) + .1\npoint = np.vstack((np.hstack((x_1, y_1)), np.hstack((x_2 - np.pi \/ 2 , y_2))))","18bfb029":"modelboost = KmeansBoost(num_clusters = 2, similiarity=\"euclidian\", max_iter=20)\nmodelboost.fit(point)\nplt.figure(figsize=(8, 6))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(x=point[:, 0], y=point[:, 1], hue=modelboost.labels, style=modelboost.labels, s=80)","b4a8529b":"dbscan = DBSCAN()\ndbscan.fit(point)\n\nplt.figure(figsize=(8, 6))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(x=point[:, 0], y=point[:, 1], hue=dbscan.labels_, style=dbscan.labels_, s=80)","3bf29a63":"for i in range(2, 8):\n    df, _ = make_blobs(n_features=2, n_samples=i * 15, centers=i, cluster_std=np.random.randint(3))\n    model = KmeansBoost(num_clusters=i, max_iter=20)\n    model.fit(df)\n    labels = model.labels\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 9))\n    distance = np.zeros((df.shape[0], df.shape[0]))\n    for row in range(df.shape[0]):\n        distance[row, :] = np.sqrt(np.sum(np.square(df - df[row, :]), axis=1)).reshape(1, -1)\n    sns.heatmap(distance, cmap=\"magma\",  xticklabels=False, yticklabels=False, ax=ax1)\n    values = np.flip(np.unique(labels))\n    \n    new_df = np.zeros((0, df.shape[1]))\n    for label in values:\n        new_df = np.vstack((new_df, df[labels==label, :]))\n    fix_distances =  np.zeros((df.shape[0], df.shape[0]))\n    for row in range(new_df.shape[0]):\n        fix_distances[row, :] = np.sqrt(np.sum(np.square(new_df - new_df[row, :]), axis=1)).reshape(1, -1)\n    sns.heatmap(fix_distances, cmap=\"magma\",  xticklabels=False, yticklabels=False, ax=ax2)  \n    fig.show()\n    plt.show() \n    sleep(3)\n    clear_output(wait=True)\n   ","eba2b7dc":"**Such algorithms expect that the data represent some structure which could be divided on independent peaces.\nSo if we give the data with complex and intricate structure our model won't understand how study correctly and we will get ridiculous clusters. Below is the classical example of behaviour.**","230fae72":"*Our have the next physical meaning: the lower value of F_metric the better clusterisation. So if you want to find out which one number of clusters is more suitable for your problem you can stand on values of this metric.*","6878c015":"# <h1>The third test - we sample arrays with different number of columns. The number of clusters is equal to 2 again.","612cd17c":"**For such or more complex task exist clustering algorithm such DBSCAN. Below is its work on the previous example.**","77064447":"# A little bit about disadvantages of Kmeans and its analogs","61fac945":"# The next test - we sample arrays with different number of rows. The number of clusters is equal 2 for both models.\n","50b97eec":"# Documents","2f030832":"<h3>The practise shows that KmeansBoost is more reliable converge to correct centroids centers<h3>","d76f5d76":"# More examples -  perfomance on sklearn dataset blobs","f9f1d213":"* **New initialization funtion: for each cluster centr we sample  radndom num_clusters points from dataset and take such that:** \n    * *A weighted sum of the sum of distances from existed centroids and minimal distance from each existed centroids is maximal* \n* **Momentum method. We save information about previous steps and use its for more rapid convergence**","f1fc0c32":"# Implementation of classic k-means algorithm","d32a5ab2":"# Let's see perform of our model on 2D data","82bbd55a":"# <h1>Noooow it's time to boost our model and add some powerfull features","c8dee554":"# New attributes","3ac96529":"**We can't see dramatically difference between model with 3 and 30 clusters. In average an execution time difference in 20 times. It means that the execution time is in proportion with number of clusters with a some constant greater than 1.** ","09c8ff84":"As usually you are free to play with parameters in the cell above.","85a496ba":"*Now let's considere next example to figure out with function. Just run the next cells.*","fa089ba7":"<h1>Here we will test our model on several datasets with different numbers of rows and columns<h1>","c543bb49":"<h4>Here we go again! Welcome to 3D visualisation\n<h4>I think you know what you can do: play with parameters or runs cells and enjoy!<h4>","63919238":"# Let's see how to work with auto_clusters() function","d6eccf44":"**The watchings show that the execution time depends on the number of columns linearly with some constant about 0.3.**","b6bf018f":"# Despite on the new functions KmeansBoost shows almost the same execution time and usually  loose less than 30% percent of time other one.","585a53f4":"<h1>Extra part: distance matrix visualization","e6cbc2f3":"<h1> One more comparasion with the previous model","7fa310c3":"* **self.alpha** - The parametr is responsible for the speed of forgetting previous steps\n* **self.lr** - The parametr is responsible for correction of centroids shift","eb5fa965":"Look at the plot. We can see that in out example the lowest values match to numbers of clusters: 2, 3 and maybe 4.<\/p>\nSo when you want to predict the number of clusters in your dataset as a benchmark you can use these values.","154f5dca":"**Let's get dataset sklearn.dataset.make_blobs visualize distance matrixes**<\/p>\n**We just will rank labels by their frequencies in the labels set by the model.**\n","efed8642":"# Let's see perfomance on 3D data","f5c73c58":"# What's new?","a45a3815":"**Here you can play with distribution (any from np.random module, just don't forget to set correct parameters) and similiarity function, one of the next:** \n* \"euclidian\"\n* \"cosine-distance\"\n* \"manhattan\"<h5>\n**P.S. if you don't want to change something just run the next cells and enjoy!**","1e3186b7":"**Here we see about 500 times increasing of the execution time in condition of increasing the row number in 100 times.**<\/p>\n**It's seems like the execution time depends on the rows number linearly with some constant about 5.  What's next?**","d9cb1c5e":"# The first test - we sample arrays with identically shape but set the number of clusters with a difference of 10 times.\n**Just runs cells and watch an output.**","9b66b480":"# And now let's look at convergence","898f18ff":"# **Methods**\n* **\\__init__** (num_clusters, max_iter, auto_clusters, init) - Construct k-means model \n* **fit(X)** - Defines centroids and label for each object\n* **get_params** - Returns dictionary with parameters of model\n* **clustering(X)** - The function used to shape pipeline\n* **set_centroids(labels)** - Sets centroid's coordinates for each label\n* **euclidian_distance(X, dists)** - Computes distances for each object from each centroid using the \"euclidian\" distance\n* **cosine_distance(X, dists)** - Computes distances for each object from each centroid using the \"cosine\" distance\n* **manhattan_distance(X, dists)** - Computes distances for each object from each centroid using the \"manhattan\" distance\n* **predict(X)** - Predicts label for each object\n* **init_centroids(X)** - Initializes centroids centers\n* **set_auto_clusters(X)** - Tries to find optimal number of clusters using F-metric and gives list of scores for each number of clusters\n\n**P.S.** Here and later I will name the F-metric next ratio:<h4>$$\\frac{\\Phi_0}{\\Phi_1} $$<h4>\nwhere $$\\Phi_0 = \\sum_{a \\in Y}^{}{\\frac{1}{|X_a|}}\\sum_{i: a_i = a}{\\rho(x_i, \\mu_a) }$$ \n$$X_a = {\\{x_i \\in X^l | a_i = a\\}} - cluster \\:a \\:and \\:\\mu_a - \\:a\\;'s \\:mass \\:centr$$ <br>\n$$\\Phi_1 = \\frac{\\sum_{a, \\:b \\:\\in \\:Y}{\\rho(\\mu_a, \\mu_b)}}{ \\frac{|Y| * (|Y| - 1 )}{2}}$$","3b02aef1":"# **Attributes**\n* **self.num_clusters** - The number of cluster\n* **self.metric** - The list of F-metric score for number of classes in range: [2 , 15]\n* **self.centroids** - The numpy-array of centroids coordinates\n* **self.labels** - The numpy-array of labels for train set\n* **self.last_fit_dists** - The numpy-array of distances from the class-centroids for last test set\n* **self.similiarity** - The function which computes distances by chosen the function of similiarity\n* **self.labels_stack and self.centroids_stack** - Two stacks of history for labels and cetroids coordinates ","d8bb0eed":"<h2>$$That's \\;all! \\;Thanks \\;for \\;your \\;attention!$$<h2>\n$$I \\;hope \\;you \\;have \\;spent \\;time \\;with \\;enjoy. \\;Follow \\;me \\;and \\;check \\;other \\;repositories.$$ <h2>\n $$See you.  \\;Bye$$"}}