{"cell_type":{"01719a58":"code","9ff64419":"code","c9a3d8a5":"code","f1f8f19a":"code","e51ab2f9":"code","c91d3499":"code","ac9b6715":"code","46a9075b":"code","6ed66323":"code","f31a1878":"code","38226577":"code","a899f136":"code","7cfbfcb5":"code","5562ea23":"code","280e4f4c":"code","47caca6e":"code","386bb4fc":"code","f7715284":"code","5b261575":"code","b7a86db3":"code","f1e528c5":"code","f5c4d1d7":"code","948281d2":"code","d1426dce":"code","e08c926a":"code","d4d52a08":"code","9f683697":"code","45671d8e":"code","801621d9":"code","c61910b1":"code","33fd9202":"code","b326fb74":"code","d36017cf":"code","a7929e95":"code","b8ec5c95":"code","f55fb88e":"code","96a23f2a":"code","c1a4dba7":"code","e062d909":"code","ff0fb1e1":"code","5c43ca46":"code","80a5e76d":"code","2ed4993a":"code","77d8179f":"code","d33993d4":"code","dbce777a":"code","347f3d6a":"code","37dd8c06":"markdown","74bf30a6":"markdown","40bd757f":"markdown","689fbfc7":"markdown","6c1c390a":"markdown","abe3c722":"markdown","fbfa50da":"markdown","1b779a07":"markdown","29ac5967":"markdown","7e5c08da":"markdown","096ba44d":"markdown","b9445d4b":"markdown","6cf1fe4f":"markdown","d452339c":"markdown","72ec1d17":"markdown","0c84e6bb":"markdown","763f3d3a":"markdown","0f721fa4":"markdown","28bdd87f":"markdown","adfbb024":"markdown","37f9d7d8":"markdown","81701874":"markdown","cb965526":"markdown","631e941b":"markdown","6a1402c0":"markdown","fe5b0162":"markdown","e5a85fdb":"markdown","1ddaef7e":"markdown","3789a11b":"markdown","3e2e01d4":"markdown","2e80c3ef":"markdown","ff816a6a":"markdown","b35a86c8":"markdown","486e5d51":"markdown","740a7f13":"markdown","c37210ed":"markdown","7c006108":"markdown","e48a2fd6":"markdown","49fa78fa":"markdown","f8803d35":"markdown","be2bb0a5":"markdown","d1938f76":"markdown","4c1263a5":"markdown","9ef0117f":"markdown","24364a76":"markdown"},"source":{"01719a58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt     # for visualization\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import linear_model","9ff64419":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c9a3d8a5":"print(\"Train data shape:\", train.shape)\nprint(\"Test data shape:\", test.shape)","f1f8f19a":"print(train.head())","e51ab2f9":"plt.style.use(style='ggplot')\nplt.rcParams['figure.figsize'] = (10, 6)","c91d3499":"print (train.SalePrice.describe())","ac9b6715":"print (\"Skew is:\", train.SalePrice.skew())\nplt.hist(train.SalePrice, color='blue')\nplt.show()","46a9075b":"target = np.log(train.SalePrice)\nprint (\"\\n Skew is:\", target.skew())\nplt.hist(target, color='blue')\nplt.show()","6ed66323":"numeric_features = train.select_dtypes(include=[np.number])\nprint(numeric_features.dtypes)","f31a1878":"corr = numeric_features.corr()","38226577":"print (corr['SalePrice'].sort_values(ascending=False)[:5], '\\n')\nprint (corr['SalePrice'].sort_values(ascending=False)[-5:])","a899f136":"print(train.OverallQual.unique())","7cfbfcb5":"quality_pivot = train.pivot_table(index='OverallQual', values='SalePrice', aggfunc=np.median)\nprint(quality_pivot)","5562ea23":"quality_pivot.plot(kind='bar', color='blue')\nplt.xlabel('Overall Quality')\nplt.ylabel('Median Sale Price')\nplt.xticks(rotation=0)\nplt.show()","280e4f4c":"plt.scatter(x=train['GrLivArea'], y=target)\nplt.ylabel('Sale Price')\nplt.xlabel('Above grade (ground) living area square feet')\nplt.show()","47caca6e":"plt.scatter(x=train['GarageArea'], y=target)\nplt.ylabel('Sale Price')\nplt.xlabel('Garage Area')\nplt.show()","386bb4fc":"train = train[train['GarageArea'] < 1200]","f7715284":"plt.scatter(x=train['GarageArea'], y=np.log(train.SalePrice))\nplt.xlim(-200,1600)     # This forces the same scale as before\nplt.ylabel('Sale Price')\nplt.xlabel('Garage Area')\nplt.show()","5b261575":"nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])\nnulls.columns = ['Null Count']\nnulls.index.name = 'Feature'\nprint(nulls)","b7a86db3":"print (\"Unique values are:\", train.MiscFeature.unique())","f1e528c5":"categoricals = train.select_dtypes(exclude=[np.number])\nprint(categoricals.describe())","f5c4d1d7":"print (\"Original: \\n\")\nprint (train.Street.value_counts(), \"\\n\")","948281d2":"train['enc_street'] = pd.get_dummies(train.Street, drop_first=True)\ntest['enc_street'] = pd.get_dummies(test.Street, drop_first=True)","d1426dce":"print ('Encoded: \\n')\nprint (train.enc_street.value_counts())","e08c926a":"condition_pivot = train.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\ncondition_pivot.plot(kind='bar', color='blue')\nplt.xlabel('Sale Condition')\nplt.ylabel('Median Sale Price')\nplt.xticks(rotation=0)\nplt.show()","d4d52a08":"def encode(x): return 1 if x == 'Partial' else 0\ntrain['enc_condition'] = train.SaleCondition.apply(encode)\ntest['enc_condition'] = test.SaleCondition.apply(encode)","9f683697":"condition_pivot = train.pivot_table(index='enc_condition', values='SalePrice', aggfunc=np.median)\ncondition_pivot.plot(kind='bar', color='blue')\nplt.xlabel('Encoded Sale Condition')\nplt.ylabel('Median Sale Price')\nplt.xticks(rotation=0)\nplt.show()","45671d8e":"data = train.select_dtypes(include=[np.number]).interpolate().dropna()","801621d9":"print(sum(data.isnull().sum() != 0))","c61910b1":"y = np.log(train.SalePrice)\nX = data.drop(['SalePrice', 'Id'], axis=1)","33fd9202":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)","b326fb74":"lr = linear_model.LinearRegression()","d36017cf":"model = lr.fit(X_train, y_train)","a7929e95":"print(\"R^2 is: \\n\", model.score(X_test, y_test))","b8ec5c95":"predictions = model.predict(X_test)","f55fb88e":"print('RMSE is: \\n', mean_squared_error(y_test, predictions))","96a23f2a":"actual_values = y_test\nplt.scatter(predictions, actual_values, alpha=.75,\n            color='b') \nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')\nplt.title('Linear Regression Model')\nplt.show()","c1a4dba7":"for i in range (-2, 3):\n    alpha = 10**i\n    rm = linear_model.Ridge(alpha=alpha)\n    ridge_model = rm.fit(X_train, y_train)\n    preds_ridge = ridge_model.predict(X_test)\n\n    plt.scatter(preds_ridge, actual_values, alpha=.75, color='b')\n    plt.xlabel('Predicted Price')\n    plt.ylabel('Actual Price')\n    plt.title('Ridge Regularization with alpha = {}'.format(alpha))\n    overlay = 'R^2 is: {}\\nRMSE is: {}'.format(\n                    ridge_model.score(X_test, y_test),\n                    mean_squared_error(y_test, preds_ridge))\n    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n    plt.show()","e062d909":"print(\"R^2 is: \\n\", model.score(X_test, y_test))","ff0fb1e1":"submission = pd.DataFrame()","5c43ca46":"submission['Id'] = test.Id","80a5e76d":"feats = test.select_dtypes(\n    include=[np.number]).drop(['Id'], axis=1).interpolate()","2ed4993a":"predictions = model.predict(feats)","77d8179f":"final_predictions = np.exp(predictions)","d33993d4":"print(\"Original predictions are: \\n\", predictions[:10], \"\\n\")\nprint(\"Final predictions are: \\n\", final_predictions[:10])","dbce777a":"submission['SalePrice'] = final_predictions\nprint(submission.head())","347f3d6a":"submission.to_csv('submission1.csv', index=False)","37dd8c06":"try using Ridge Regularization to decrease the influence of less important features ","74bf30a6":"to plot a histogram of SalePrice","40bd757f":"explore this newly modified feature as a plot.","689fbfc7":"The first column must the contain the ID from the test data.","6c1c390a":"transform the predictions to the correct form. apply np.exp() to our predictions becasuse we have taken the logarithm(np.log()) previously.","abe3c722":"to do some plotting","fbfa50da":"generate predictions","1b779a07":"lr.fit() method will fit the linear regression on the features and target variable that we pass.","29ac5967":"to get the unique values that a particular column has.","7e5c08da":"to generate some scatter plots and visualize the relationship between the Ground Living Area(GrLivArea) and SalePrice","096ba44d":"to return a list of the unique values","b9445d4b":"to get more information like count, mean, std, min, max etc","6cf1fe4f":"our model needs numerical data, so we will use one-hot encoding to transform the data into a Boolean column. Create a new column called enc_street. The pd.get_dummies() method will handle this for us","d452339c":"separate the features and the target variable for modeling. We will assign the features to X and the target variable(Sales Price)to y.","72ec1d17":"do the same for GarageArea.","0c84e6bb":"Evaluate the performance and visualize results","763f3d3a":"display the previous graph again without outliers","0f721fa4":"displays the correlation between the columns and examine the correlations between the features and the target.","28bdd87f":"When transforming features, it's important to remember that any transformations that you've applied to the training data before fitting the model must be applied to the test data.","adfbb024":" create a csv that contains the predicted SalePrice for each observation in the test.csv dataset.","37f9d7d8":"create a new dataframe with some outliers removed","81701874":"check the difference","cb965526":"use np.log() to transform train.SalePric and calculate the skewness a second time, as well as re-plot the data","631e941b":"In this example, about 33% of the data is devoted to the hold-out set.","6a1402c0":"return a subset of columns matching the specified data types","fe5b0162":"use the model we have built to make predictions on the test data set.","e5a85fdb":"encode this SaleCondition as a new feature by using a similar method that we used for Street above","1ddaef7e":"assign these predictions and check","3789a11b":"The first five features are the most positively correlated with SalePrice, while the next five are the most negatively correlated.","3e2e01d4":"use Pandas to read in csv files. The pd.read_csv() method creates a DataFrame from a csv file","2e80c3ef":"investigate the relationship between OverallQual and SalePrice.\nWe set index='OverallQual' and values='SalePrice'. We chose to look at the median here.","ff816a6a":"export to a .csv file as Kaggle expects.","b35a86c8":"view this relationship between predictions and actual_values graphically with a scatter plot.","486e5d51":"look at a few rows using the DataFrame.head() method","740a7f13":"Check if the all of the columns have 0 null values.","c37210ed":"Dealing with missing values. We'll fill the missing values with an average value and then assign the results to data. This is a method of interpolation  ","7c006108":"consider the non-numeric features and display details of columns","e48a2fd6":"calculates the rmse","49fa78fa":" # Linear Regression Model ","f8803d35":"select the features from the test data for the model as we did above.","be2bb0a5":"visualize this pivot table more easily, we can create a bar plot. Notice that the median sales price strictly increases as Overall Quality increases.","d1938f76":"look at SaleCondition by constructing and plotting a pivot table, as we did above for OverallQual","4c1263a5":"create a DataFrame to view the top null columns and return the counts of the null values in each column","9ef0117f":"check out the size of the data","24364a76":"Pave and Grvl values converted into 1 and 0"}}