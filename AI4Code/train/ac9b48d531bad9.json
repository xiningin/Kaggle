{"cell_type":{"ff835a0b":"code","54c34431":"code","f091ed1f":"code","1bafb764":"code","23a2caf7":"code","beca0904":"code","8dad4b9b":"code","0aa7e802":"code","988673b7":"code","e42593e5":"code","f221eb61":"code","c1dbaaea":"code","6cb4a126":"code","74cda6fd":"code","cfc83984":"code","392a4376":"code","73ebfb90":"code","7a9589af":"code","8d7c9132":"code","2af71083":"code","4c0766b3":"code","540f874c":"code","a28714d6":"code","430ab59a":"code","d409eda2":"markdown","e6fac757":"markdown","00d58db3":"markdown","a22a042f":"markdown","5c584ba6":"markdown","63baceb9":"markdown","0c8914a3":"markdown","58ec6df8":"markdown","99bdddcc":"markdown","7b221ab9":"markdown","7cfc4ca6":"markdown","7f971723":"markdown","1084a886":"markdown"},"source":{"ff835a0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import datasets\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix\nfrom xgboost import XGBClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","54c34431":"#Read data from CSV\ndf_raw = pd.read_csv('..\/input\/weatherAUS.csv')","f091ed1f":"df_raw.head(5)","1bafb764":"df_raw.count().sort_values()","23a2caf7":"df = df_raw.drop(columns=['Sunshine','Evaporation','Cloud3pm','Cloud9am', 'RISK_MM', 'Date', 'Location'],axis=1)\ndf.shape","beca0904":"df.dropna(how='any', inplace=True)","8dad4b9b":"df.shape","0aa7e802":"fig, ax = plt.subplots(figsize=[15,15])\nsns.heatmap(df.corr(), ax=ax, cmap='Blues', annot=True);\nax.set_title(\"Pearson correlation coefficients\", size=20);","988673b7":"\nparams=['MinTemp','MaxTemp','Rainfall','WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\npd.plotting.scatter_matrix(df[params], alpha=0.2, figsize=(20, 20))\nplt.show()","e42593e5":"df['RainToday'] = df['RainToday'].map({'Yes': 1, 'No':0})\ndf['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No':0})\ndf = pd.get_dummies(data=df, columns=['WindGustDir', 'WindDir3pm', 'WindDir9am']) ","f221eb61":"X = df.loc[:, df.columns != 'RainTomorrow']\nY = df.loc[:,'RainTomorrow']\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=56)","c1dbaaea":"X_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)","6cb4a126":"classifier_models = {\n    'CART': DecisionTreeClassifier(),\n    'XGB': XGBClassifier(n_jobs=-1),\n    'GNB': GaussianNB(),\n    'LDA': LinearDiscriminantAnalysis(),\n    'LR': LogisticRegression(),\n    'KNN': KNeighborsClassifier()\n}","74cda6fd":"def accuracy_report(models, X, y):\n    results = []\n    for name in models.keys():\n        model = models[name]\n        scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n        print(\"Accuracy: %.3f (+\/- %.3f) [%s]-[%s]\" %(scores.mean(), scores.std(), models[name], name))","cfc83984":"accuracy_report(classifier_models, X_train, y_train)","392a4376":"from sklearn.metrics import confusion_matrix #for model evaluation\ndef confusion_martix_report(models, X_train, y_train, X_test, y_test):\n    results = []\n    for name in models.keys():\n        model = models[name]\n        model.fit(X_train, y_train)\n        y_predict = model.predict(X_test)\n        cm = confusion_matrix(y_test, y_predict)\n        plt.figure(figsize = (4,4))\n        sns.heatmap(cm,fmt=\"d\",annot=True)\n        plt.title(\"Confusion Matrix\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actuals\")\n        plt.show()","73ebfb90":"confusion_martix_report(classifier_models, X_train, y_train, X_test, y_test)","7a9589af":"rf_classifier = RandomForestClassifier()\nparam_grid = {\n    'n_estimators': [200,300,400,500,600],\n    'random_state': [30,40,50,60,70]\n}\ngscv_rfc = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv= 5)\ngscv_rfc.fit(X_train,y_train)","8d7c9132":"print(\"best parameters \",gscv_rfc.best_params_)\nprint(\"accuracy :\",gscv_rfc.best_params_)","2af71083":"rfc_modified = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n            oob_score=False, random_state=60, verbose=0,\n            warm_start=False)\nscores = cross_val_score(rfc_modified, X_train, y_train, scoring='accuracy')\nprint(\"Accuracy: %.3f (+\/- %.3f)\" %(scores.mean(), scores.std()))","4c0766b3":"import eli5 #for purmutation importance\nfrom eli5.sklearn import PermutationImportance\nimport shap #for SHAP values","540f874c":"rfc_modified.fit(X_train, y_train)\nperm = PermutationImportance(rfc_modified, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","a28714d6":"rfc_explainer = shap.TreeExplainer(rfc_modified)\nrfc_shap_values = rfc_explainer.shap_values(X_test)\n\nshap.summary_plot(rfc_shap_values[1], X_test, plot_type=\"bar\")","430ab59a":"shap.summary_plot(rfc_shap_values[1], X_test)","d409eda2":"# Preprocessing of Data\n\nDropping columns: 'Sunshine','Evaporation','Cloud3pm','Cloud9am', 'RISK_MM', 'Date', 'Location'","e6fac757":"# Hyperparameter Tuning Using Grid Search","00d58db3":"# MODEL COMPARISON","a22a042f":"**APPLING BEST PARAMETERS FOR RANDOM FOREST CLASSIFIERS**","5c584ba6":"**COMPARING CONFUSION MATRIX FOR 5 DIFFERENT CLASSIFICATION MODEL**","63baceb9":"**Understanding the effect of each feature in Random Classifier Model using SHAP**","0c8914a3":"Creating dummy variables for categorical data","58ec6df8":"**Understanding the Random Classifier Model using Permutation importance method**","99bdddcc":"# Explanation of the Model","7b221ab9":"Spliting Dataset into Training and Testing","7cfc4ca6":"Changing Yes and No values into 0 & 1","7f971723":"# COMPARING MODEL PERFORMANCES","1084a886":"**FINDING BEST ESTIMATOR FOR RANDOM FOREST CLASSIFIER USING GRID SEARCH CV**"}}