{"cell_type":{"a809149b":"code","547e6076":"code","62627cf4":"code","b522b2e5":"code","d4c9c1a5":"code","3b54d015":"code","8510d825":"code","6b6dbab4":"code","4fb4023c":"code","f987b5f1":"code","0f6d4845":"code","c26643dd":"code","454f1199":"markdown","cf8ec126":"markdown","758bc022":"markdown","e51b31b6":"markdown","d2d8a4e9":"markdown","4417f150":"markdown","ff7a7d6e":"markdown","d5814621":"markdown","34eb2f19":"markdown","ee4de409":"markdown","d604e431":"markdown"},"source":{"a809149b":"# Data Handling\nimport pandas as pd\nimport numpy as np\nimport os\nfrom ast import literal_eval\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Data Visualization\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","547e6076":"# Length to standardize data to.\n# Average is 19.708 samples, \n# max is 51, min is 10\ndata_truncate_pad_length = 26\n\n# Number of epochs per train iteration.\nepochs = 15\n\n# Number of iterations to simulate over.\nnum_iterations = 5\n\n# Number of gestures in the dataset.\nnum_gestures = 20\n\n# Number of total users in the training file.\nnum_train_users = 7\n\n# Create an array of the zero-based gesture IDs.\nclasses = np.arange( num_gestures )","62627cf4":"# Layer parameters.\ndropout_rate = 0.0\nlstm_units = 16\n\n\n# Optimizer parameters.\nlr = 0.001\nmodel_optimizer = Adam( learning_rate=lr, decay=1e-6 )\n\n\n# Callback parameters.\nmonitor = 'loss'\nmin_delta = 0.001\npatience = 20\nearlystop_callback = EarlyStopping( monitor=monitor, min_delta=min_delta,\n                                    verbose=1, patience=patience,\n                                    restore_best_weights=True )\n# lstm_callbacks = [earlystop_callback]\nlstm_callbacks = None\n\n\n# Create tuples for model creation later.\nmodel_params = ( dropout_rate, lstm_units, data_truncate_pad_length, model_optimizer )\nfit_params = ( epochs, lstm_callbacks )","b522b2e5":"def get_gesture_data( path, data_column_headers=None ):\n    \"\"\"\n    Load the gesture data from a csv located at 'path'.\n\n    :param path: Location of the gesture data csv file.\n\n    :param data_column_headers: List of data column header names that\n    need literal_eval to parse (i.e., the headers for data arrays). If None,\n    default to [ 'x', 'y', 'z' ]\n\n    :return: The pandas dataframe holding the gesture data.\n    \"\"\"\n\n    if data_column_headers is None:\n        data_column_headers = [ 'x', 'y', 'z' ]\n\n    # Create converter dictionary to literal_eval selected columns.\n    converters = {\n        header: literal_eval for header in data_column_headers\n    }\n\n    return pd.read_csv( path, converters=converters )\n\ndef truncate_data( data, length ):\n    \"\"\"\n    Truncates x, y, and z data to specified length. If data is less than length,\n    it is zero-padded at the end.\n\n    :param data: Pandas dataframe with at least x, y, z columns. Modified\n    in place.\n\n    :param length: Length of data to truncate (or pad) to.\n\n    :return: Pandas dataframe with truncated data.\n    \"\"\"\n    for idx, row in data.iterrows():\n        # If data length is greater than length, truncate.\n        # If data length is less than length, zero-pad at end.\n        if len( row[ 'x' ] ) > length:\n            data.at[ idx, 'x' ] = row[ 'x' ][ :length ]\n            data.at[ idx, 'y' ] = row[ 'y' ][ :length ]\n            data.at[ idx, 'z' ] = row[ 'z' ][ :length ]\n        elif len( row[ 'x' ] ) < length:\n            pad_length = length - len( row[ 'x' ] )\n\n            data.at[ idx, 'x' ] = row[ 'x' ][ : ] + ( [ 0 ] * pad_length )\n            data.at[ idx, 'y' ] = row[ 'y' ][ : ] + ( [ 0 ] * pad_length )\n            data.at[ idx, 'z' ] = row[ 'z' ][ : ] + ( [ 0 ] * pad_length )\n\n    return data","d4c9c1a5":"# Load in the pre-processed data.\ntrain = get_gesture_data( '\/kaggle\/input\/csce-5280-accelerometer-gesture-classification\/train.csv' )\ntest = get_gesture_data( '\/kaggle\/input\/csce-5280-accelerometer-gesture-classification\/test.csv' )\n\n# Truncate the data to desired length.\n# If data is longer than data_length, truncate\n# otherwise zero-pad to end.\ntrain = truncate_data( train, length=data_truncate_pad_length )\ntest = truncate_data( test, length=data_truncate_pad_length )\n\n# Test data doesn't have labels, so let's go ahead\n# and pull out the data now.\nX_test = np.array( [ np.array( test[ col ].tolist() ).T for col in [ 'x', 'y', 'z' ] ] ).T","3b54d015":"# These arrays will hold the ground truth\n# and predicted labels for the testing\n# data split from the provided training data\n# so that we can create a confustion matrix\n# after training for num_iterations.\ncf_matrix_true = np.array( [] )\ncf_matrix_pred = np.array( [] )\n\n# Holds the test scores (loss, accuracy)\nscores = []\n\n# Holds tuples for train, validation, and\n# test user sets that we randomly select at\n# each iteration.\nuser_selections = []","8510d825":"def create_lstm_model( num_classes=20,\n                       dropout=0.8, units=128,\n                       data_length=19,\n                       optimizer=Adam( learning_rate=0.001 )\n                     ):\n    \"\"\"\n    Create a simple bidirectional LSTM model for classification. Creates a\n    bidirectional LSTM layer, dropout, and two dense layers.\n\n    :param num_classes: Number of classes.\n\n    :param dropout: Dropout rate\n\n    :param units: Number of units in LSTM layer.\n\n    :param data_length: Length of time data for LSTM layer input.\n\n    :param optimizer: Optimizer to use for model compilation.\n\n    :return: The compiled model with LSTM, dropout, and two dense layers.\n    \"\"\"\n\n    # Create the model object.\n    model = tf.keras.models.Sequential()\n\n    # Add an LSTM layer.\n    # Input size is (data_length,3):\n    #   data_length time samples from data.\n    #   3 dimensions (x, y, z accelerometer data).\n    model.add(\n        tf.keras.layers.Bidirectional(\n            tf.keras.layers.LSTM( units=units, input_shape=[data_length, 3] )\n        )\n    )\n\n    # Add dropout layer to reduce overfitting.\n    model.add( tf.keras.layers.Dropout( rate=dropout ) )\n\n    # Add final dense layers.\n    model.add( tf.keras.layers.Dense( units=16, activation='relu' ) )\n    model.add( tf.keras.layers.Dense( units=num_classes,\n                                      activation='softmax' ) )\n\n    model.compile( loss='sparse_categorical_crossentropy', optimizer=optimizer,\n                   metrics=['accuracy'] )\n\n    return model","6b6dbab4":"def train_model( idx, data, model, fit_params,\n                 classes=None, num_subjects=7, verbose=1 ):\n    \"\"\"\n    Wrapper for training and testing model. Returns the testing loss and\n    accuracy and the test and predicted labels for the current iteration.\n\n    :param idx: Current iteration index.\n\n    :param data: Pandas dataframe of gesture data.\n\n    :param model: tf.keras model object to train on.\n\n    :param fit_params: Tupled collection of fit\/train parameters.\n    Contains: epochs, lstm_callbacks.\n\n    :param classes: List of gesture classes to be used for training. These\n    classes are used for mapping labels to range [0,num_classes).\n\n    :param num_subjects: Number of users in the dataset.\n\n    :param verbose: Verbosity of output.\n    0 -- no output. 1 -- Only current iteration output. 2 -- Full.\n\n    :return: Returns tuple of test loss\/accuracy, test labels, and predicted\n    labels.\n\n    \"\"\"\n\n    # Unpack model fit parameters.\n    epochs, callbacks = fit_params\n\n    # Select the training, test, and validation subjects.\n    # Get random ordering of subjects.\n    subject_list = np.random.permutation( num_subjects )\n\n    # Select the second from last as validation and last user as test.\n    train_subjects = subject_list[ :-2 ].tolist()\n    test_subjects = subject_list[ -2:-1 ].tolist()\n    val_subjects = [ subject_list[ -1 ] ]\n\n\n    if verbose > 0:\n        print( f\"============================================================\\n\"\n               f\"Iteration {idx+1}:\\n\"\n               f\"    Train Subjects:      {train_subjects}\\n\"\n               f\"    Validation Subjects: {val_subjects}\\n\"\n               f\"    Test Subjects:       {test_subjects}\\n\" )\n\n\n    # Split the data into training, testing, and validation data and labels.\n    X_train, y_train, \\\n    X_test, y_test,\\\n    X_val, y_val = train_test_split( data,\n                                     train_subjects=train_subjects,\n                                     test_subjects=test_subjects,\n                                     val_subjects=val_subjects )\n\n    # If selecting validation data, create tuple of data and labels.\n    validation_data = (X_val, y_val) if X_val is not None else None\n\n\n    # Train the model on the training data.\n    fit_verbose = 0 if verbose <= 1 else 2 if verbose == 2 else 1\n    model.fit( X_train, y_train, epochs=epochs, callbacks=callbacks,\n               verbose=verbose, validation_data=validation_data )\n\n\n    # Test the model to see how well we did.\n    score = model.evaluate( X_test, y_test )\n\n\n    # Return the test scores, test labels, test predictions, and a tuple\n    # containing the subjects selected for the train, validation, and testing\n    # sets.\n    return score, y_test, \\\n           np.argmax( model.predict( X_test ), axis=1 ), \\\n           ( train_subjects, val_subjects, test_subjects )","4fb4023c":"def train_test_split( data, train_subjects=None,\n                      test_subjects=None,\n                      val_subjects=None ):\n    \"\"\"\n    Split the given dataframe into test and train data and labels. Data is\n    of shape (length, 3) where length is the number of samples in a gesture\n    reading (can be arbitrary).\n\n    :param data: Dataframe with at least x, y, z accelerometer data and gesture\n    index number.\n\n    :param test_subjects: List of user indexes over [0, 7] to select for test\n    data. If None, use test_gestures to split.\n\n    :return: Training data, training labels, testing data, testing labels,\n    validation data, validation labels.\n    \"\"\"\n\n    if train_subjects is None or test_subjects is None:\n        raise ValueError( \"Must provide train and test subjects list.\" )\n\n\n    # Define the column we're selecting by.\n    # Not useful now, maybe in future updates for more dynamic splitting.\n    sel_column = 'user'\n\n    val_subjects = [] if val_subjects is None else val_subjects\n\n\n    # Split into train and test rows by selecting rows where slected column data\n    # is in the provided splitting list (user or gesture).\n    test = data[ data[ sel_column ].isin( test_subjects ) ]\n    train = data[ data[ sel_column ].isin( train_subjects ) ]\n\n\n    # Transpose the data so that the shape is\n    # (num_samples, sample_length, num_features).\n    # For user 6, 7 test, training data is (2450, 19, 3) assuming we\n    # truncate length to 19. Test would be (851, 19, 3).\n    X_train = np.array( [ np.array( train[ col ].tolist() ).T for col in [ 'x', 'y', 'z' ] ] ).T\n    y_train = np.array( train[ 'gesture' ].tolist() )\n\n    X_test = np.array( [ np.array( test[ col ].tolist() ).T for col in [ 'x', 'y', 'z' ] ] ).T\n    y_test = np.array( test[ 'gesture' ].tolist() )\n\n    # Shuffle the data.\n    train_perm = np.random.permutation( X_train.shape[ 0 ] )\n    X_train = X_train[ train_perm ]\n    y_train = y_train[ train_perm ]\n\n    test_perm = np.random.permutation( X_test.shape[ 0 ] )\n    X_test = X_test[ test_perm ]\n    y_test = y_test[ test_perm ]\n\n    if val_subjects is not None:\n        val = data[ data[ sel_column ].isin( val_subjects ) ]\n        X_val = np.array( [ np.array( val[ col ].tolist() ).T for col in [ 'x', 'y', 'z' ] ] ).T\n        y_val = np.array( val[ 'gesture' ].tolist() )\n\n        val_perm = np.random.permutation( X_val.shape[ 0 ] )\n        X_val = X_val[ val_perm ]\n        y_val = y_val[ val_perm ]\n    else:\n        X_val = None\n        y_val = None\n\n    return X_train, y_train, X_test, y_test, X_val, y_val","f987b5f1":"for i in range( num_iterations ):\n    model = create_lstm_model( num_classes=num_gestures,\n                               dropout=dropout_rate,\n                               units=lstm_units,\n                               data_length=data_truncate_pad_length,\n                               optimizer=model_optimizer )\n\n    score, y_test, y_pred,\\\n    train_val_test_split = train_model( i, train, model,\n                                        fit_params, classes=classes,\n                                        num_subjects=num_train_users,\n                                        verbose=1 )\n\n    # Save the train, validation, and test users and the test scores\n    # for this iteration.\n    user_selections.append( train_val_test_split )\n    scores.append( score )\n\n    # Predict on the test dataset and save the\n    # submission file for this iteration.\n    submission = test.assign( gesture=np.argmax( model.predict( X_test ), axis=1 ) )\n    submission.to_csv( f\".\/submission{i}.csv\", index=False,\n                       columns=[ 'id', 'gesture' ] )\n\n    # Generate data for confusion matrix.\n    cf_matrix_true = np.hstack( ( cf_matrix_true, y_test ) )\n    cf_matrix_pred = np.hstack( ( cf_matrix_pred, y_pred ) )\n\n    # Logging output for current iteration.\n    print( \"test loss, test acc: \", score )","0f6d4845":"def print_results_table( scores, data_sels, cf_matrix ):\n    \"\"\"\n    Print the results for a number of simulation iterations in a tabular format.\n\n    :param scores: List of tuples from model.evaluate containing test loss and\n    test accuracy.\n\n    :param data_sels: List of data set splits at each iteration containing\n    training, validation, and test set selections. Each row should be a tuple or\n    list of the format (train set, validation set, test set)\n\n    :param cf_matrix: Confusion matrix object from\n    sklearn.metrics.confusion_matrix. Used to calculate overall accuracy over\n    multiple iterations from the simulation.\n\n    :return: None.\n    \"\"\"\n\n    # Calculate maximum lengths for each of the three data selection sets so \n    # that we can properly set the widths of the train, validation, and test set\n    # columns. Creates a three-tuple by finding the max length of the string\n    # representation of the lists for train, validation, and test sets at each\n    # iteration of the simulation (row of the scores list). If the max length\n    # value for a specific column is less than the length of the column header,\n    # use the length of the column header instead.\n    # First index is train, second is validation, third is test.\n    col_headers = [ 'Train Set', 'Validation Set', 'Test Set' ]\n    max_lengths = tuple( \n            max( list( map( lambda x: len( str( x[ i ] ) ), data_sels ) ) )\n        for i in range( 3 ) )\n    max_lengths = [ length if len( col_headers[ i ] ) < length\n                    else len( col_headers[ i ] ) \n                    for i, length in enumerate( max_lengths ) ]\n\n    # Pre calculate the strings for the horizontal dividers for the train,\n    # validation, and test sets so we're not calculating them at each iteration.\n    set_bars = [ '\u2500' * length for length in max_lengths ]\n\n\n    # Set up widths for the index, accuracy, and loss sections.\n    # Does not include single spaces on left and right between vertical pipes.\n    index_width = 5\n    index_bars = '\u2500' * index_width\n\n    accuracy_width = 8\n    accuracy_bars = '\u2500' * accuracy_width\n\n    loss_width = 6\n    loss_bars = '\u2500' * loss_width\n\n\n    # Calculate table width (minus two spaces on either end for spacing)\n    table_width = index_width + 3 + accuracy_width + 3 + loss_width + 3 + \\\n                  max_lengths[ 0 ] + 3 + max_lengths[ 1 ] + 3 + max_lengths[ 2 ]\n\n\n    # Define outer box to go around the table. Makes it nice and clear.\n    # Value is equal to top\/bottom spacing. Horizontal spacing is double\n    # (monospace is more or less 2:1, width:height).\n    spacing = 2\n    side_spacing = ' ' * 2 * spacing\n\n\n    # Calculate overall table width including inner table, two inner padding\n    # spaces, inner table borders (2), and padding on both sides.\n    total_table_width = table_width + 2 + 2 + ( 2 * 2 * spacing )\n\n\n    # Print top-side outer box.\n    for _ in range( spacing ):\n        print()\n    print( f\"{side_spacing}\u2554{'\u2550' * total_table_width}\u2557\" )\n    for _ in range( spacing ):\n        print( f\"{side_spacing}\u2551{' ' * total_table_width}\u2551\" )\n\n\n    # Define the inner divider lines that go above each output row.\n    inner_divider = f\"\\n{side_spacing}\u2551{side_spacing}\u255f\u2500{index_bars}\u2500\u253c\u2500{accuracy_bars}\u2500\" + \\\n                    f\"\u253c\u2500{loss_bars}\u2500\u253c\u2500{set_bars[ 0 ]}\u2500\u253c\u2500{set_bars[ 1 ]}\u2500\" + \\\n                    f\"\u253c\u2500{set_bars[ 2 ]}\u2500\u2562{side_spacing}\u2551\\n\"\n\n\n    # Print the divider and header information\n    print( f\"{side_spacing}\u2551{side_spacing}\u2554\u2550{index_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2564\u2550{accuracy_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2564\u2550{loss_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2564\u2550{set_bars[ 0 ].replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2564\u2550{set_bars[ 1 ].replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2564\u2550{set_bars[ 2 ].replace( '\u2500', '\u2550' )}\u2550\u2557{side_spacing}\u2551\\n\"\n           f\"{side_spacing}\u2551{side_spacing}\u2551 {'Index':>{index_width}} \"\n           f\"\u2502 {'Accuracy':>{accuracy_width}} \"\n           f\"\u2502 {'Loss':>{loss_width}} \"\n           f\"\u2502 {col_headers[ 0 ]:^{max_lengths[ 0 ]}} \"\n           f\"\u2502 {col_headers[ 1 ]:^{max_lengths[ 1 ]}} \"\n           f\"\u2502 {col_headers[ 2 ]:^{max_lengths[ 2 ]}} \u2551{side_spacing}\u2551\", end='' )\n\n    # Iterate through each simulation result and print the data in the row.\n    for idx, score in enumerate( scores ):\n        # train_str = \n\n        print( f\"{inner_divider}\"\n               f\"{side_spacing}\u2551{side_spacing}\u2551 {idx + 1:>{index_width}d} \"\n               f\"\u2502 {score[ 1 ]:>{accuracy_width}.3f} \"\n               f\"\u2502 {score[ 0 ]:>{loss_width}.3f} \"\n               f\"\u2502 {str(data_sels[ idx ][ 0 ]):^{max_lengths[ 0 ]}} \"\n               f\"\u2502 {str(data_sels[ idx ][ 1 ]):^{max_lengths[ 1 ]}} \"\n               f\"\u2502 {str(data_sels[ idx ][ 2 ]):^{max_lengths[ 2 ]}} \u2551\"\n               f\"{side_spacing}\u2551\", \n               end='' )\n\n\n    # Prin the border for the bottom of the regular data.\n    print( f\"\\n{side_spacing}\u2551{side_spacing}\u2560\u2550{index_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2567\u2550{accuracy_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2567\u2550{loss_bars.replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2567\u2550{set_bars[ 0 ].replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2567\u2550{set_bars[ 1 ].replace( '\u2500', '\u2550' )}\u2550\"\n           f\"\u2567\u2550{set_bars[ 2 ].replace( '\u2500', '\u2550' )}\u2550\u2563{side_spacing}\u2551\" )\n\n\n    # Calculate the overall accuracy and total width of the table and print\n    # in its own row at the bottom of the table.\n    overall_accuracy = 100 * np.trace( cf_matrix ) \/ float( np.sum( cf_matrix ) )\n    print( f\"{side_spacing}\u2551{side_spacing}\u2551 {' ' * table_width} \u2551{side_spacing}\u2551\\n\"\n           f\"{side_spacing}\u2551{side_spacing}\u2551 {f'Total Accuracy: {overall_accuracy:{accuracy_width-1}.2f}%':^{table_width}} \"\n           f\"\u2551{side_spacing}\u2551\\n\"\n           f\"{side_spacing}\u2551{side_spacing}\u2551 {' ' * table_width} \u2551{side_spacing}\u2551\" )\n\n\n    # Print the bottom table outline.\n    print( f\"{side_spacing}\u2551{side_spacing}\u255a\u2550{'\u2550' * table_width}\u2550\u255d{side_spacing}\u2551\" )\n\n\n    # Print bottom-side outer box.\n    for _ in range( spacing ):\n        print( f\"{side_spacing}\u2551{' ' * total_table_width}\u2551\" )\n    print( f\"{side_spacing}\u255a{'\u2550' * total_table_width}\u255d\" )\n    for _ in range( spacing ):\n        print()\n        \n        \n        \ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n\n    Provided by: https:\/\/raw.githubusercontent.com\/DTrimarchi10\/confusion_matrix\/master\/cf_matrix.py\n\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n\n    normalize:     If True, show the proportions for each category. Default is True.\n\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n\n    xyticks:       If True, show x and y ticks. Default is True.\n\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n\n    title:         Title for the heatmap. Default is None.\n\n    '''\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names) == cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() \/ np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        # Accuracy is sum of diagonal divided by total observations\n        accuracy = np.trace(cf) \/ float(np.sum(cf))\n\n        # if it is a binary confusion matrix, show some more stats\n        if len(cf) == 2:\n            # Metrics for Binary Confusion Matrices\n            precision = cf[1, 1] \/ sum(cf[:, 1])\n            recall = cf[1, 1] \/ sum(cf[1, :])\n            f1_score = 2 * precision * recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy, precision, recall, f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize == None:\n        # Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks == False:\n        # Do not show categories if xyticks is False\n        categories = False\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n\n    if title:\n        plt.title(title)\n\n    plt.show()","c26643dd":"# Generate the confusion matrix.\ncf_matrix = confusion_matrix( cf_matrix_true, cf_matrix_pred )\n\n\n# Print the results for each simulation run in a tabular format.\nprint_results_table( scores, user_selections, cf_matrix )\n\n\n# Plot the confusion matrix.\nmake_confusion_matrix( cf_matrix, categories=classes,\n                       figsize=[8,8])","454f1199":"---\n# Define Helper Functions for Result Output and Confusion Matrix","cf8ec126":"---\n# Define a Function to Create the Model","758bc022":"---\n# Load and Standardize the Data","e51b31b6":"---\n# Define a Function for Train\/Val\/Test Splits","d2d8a4e9":"---\n# Define Simulation Parameters","4417f150":"---\n# Print out the Results from the Simulations and Show Confusion Matrix","ff7a7d6e":"---\n# Define a Function for Training the Model","d5814621":"---\n# Train the Model for the Selected Number of Iterations","34eb2f19":"---\n# Deifne Some Functions to Load and Standardize the Data","ee4de409":"---\n# Create Data Structures to Capture Training Information","d604e431":"---\n# Define Model Parameters"}}