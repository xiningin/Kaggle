{"cell_type":{"5437800e":"code","c886f2d1":"code","4558ff43":"code","bd8c17c7":"code","10b8a118":"code","397d0128":"code","848a1c3b":"code","59dc61ee":"code","27ed3084":"code","b3c96240":"code","b75635aa":"code","5a0c7a67":"code","a7416d4b":"code","8be74583":"code","d537bd92":"code","87a13542":"code","d2a959fe":"code","915661ca":"code","d6aceb4c":"code","63df64ed":"code","aa33b59d":"code","6422c151":"code","abaf89f8":"code","7a8e2f9d":"code","9ccdae07":"code","50255a25":"code","4a777623":"code","238a914c":"code","1c4f0406":"code","e6478d46":"code","660fa7d1":"code","2c165d0c":"code","3e6c7004":"code","9e3022ab":"code","639d09ef":"code","283bc8a2":"code","ddc87d8f":"code","a665adba":"code","283edccb":"code","9ad51935":"code","c070d737":"code","1d8d8bc6":"code","94d1b75e":"code","9a4e37db":"markdown","db6bbbf8":"markdown","d52a8301":"markdown","5a462573":"markdown","0f071950":"markdown","2448000e":"markdown","d0c5d7dd":"markdown","f990c14e":"markdown","85eb976e":"markdown","5af7a274":"markdown","cc6c2e06":"markdown","edfd4f50":"markdown","97f34d6e":"markdown","e9cbbfcd":"markdown","bf6602b3":"markdown","426fadfa":"markdown","17799eea":"markdown","2bdd726c":"markdown","1bd49d8e":"markdown","4838a5ab":"markdown"},"source":{"5437800e":"# Importing header files\nimport os\nimport pandas as pd\nimport numpy as np","c886f2d1":"# Setting path\ntrain_data_path = \"..\/input\/digit-recognizer\/train.csv\"\ntest_data_path = \"..\/input\/digit-recognizer\/test.csv\"","4558ff43":"# Load data frames\ntrain_df = pd.read_csv(train_data_path)\ntest_df = pd.read_csv(test_data_path)","bd8c17c7":"train_df","10b8a118":"test_df","397d0128":"train_df.info(verbose = True)","848a1c3b":"test_df.info(verbose = True)","59dc61ee":"print(\"Max value in train_df :\", max(train_df.max()))\nprint(\"Min value in train_df :\", min(train_df.min()))","27ed3084":"print(\"Max value in test_df :\", max(test_df.max()))\nprint(\"Min value in test_df :\", min(test_df.min()))","b3c96240":"train_X = train_df.loc[:, 'pixel0':].to_numpy()\ntrain_y = train_df.loc[:, 'label'].to_numpy().reshape(-1,1).ravel()\ntest_X = test_df.to_numpy()","b75635aa":"train_X = np.divide(train_X, 255)\ntest_X = np.divide(test_X, 255)","5a0c7a67":"print(train_X.shape)\nprint(train_y.shape)\nprint(test_X.shape)","a7416d4b":"# Function to get submission_file\ndef get_submission_file(model, filename):\n    predictions = model.predict(test_X)\n    df_submission = pd.DataFrame({'ImageId' : test_df.index + 1, 'Label' : predictions})\n    # submission file\n    submission_data_path = os.path.join(os.path.pardir, 'Data', 'Predictions')\n    submission_file_path = os.path.join(submission_data_path, filename)\n    # write to the file\n    df_submission.to_csv(submission_file_path, index = False)","8be74583":"# Function to test model\nfrom sklearn.model_selection import train_test_split\n\ndef test_model(model, trials):\n    total_score = 0\n    for trial in range(trials):\n        X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size = 0.2)\n        model.fit(X_train,  y_train)\n        total_score += model.score(X_test, y_test)\n    print(f\"Average Accuracy of the model : {round(total_score \/ trials, 3)}\") ","d537bd92":"from sklearn.dummy import DummyClassifier\n\ndummy_model = DummyClassifier(strategy = \"most_frequent\")\n\ntest_model(dummy_model, 10)","87a13542":"from sklearn.linear_model import LogisticRegression\n\nlr_model_1 = LogisticRegression(max_iter = 1000)\n\ntest_model(lr_model_1, 1)","d2a959fe":"from sklearn.neighbors import KNeighborsClassifier\n\nKCN_1 = KNeighborsClassifier()\n\ntest_model(KCN_1, 1)","915661ca":"from sklearn.ensemble import RandomForestClassifier\n\nRFC_1 = RandomForestClassifier()\n\ntest_model(RFC_1, 1)","d6aceb4c":"from sklearn.naive_bayes import GaussianNB\n\nGNB = GaussianNB();\n\ntest_model(GNB, 10)","63df64ed":"from sklearn.neural_network import MLPClassifier\n\nclf_1 = MLPClassifier()\n\ntest_model(clf_1, 1)","aa33b59d":"from sklearn.neural_network import MLPClassifier\n\nclf_2 = MLPClassifier(hidden_layer_sizes = (100, 100))\n\ntest_model(clf_2, 1)","6422c151":"from sklearn.neural_network import MLPClassifier\n\nclf_3 = MLPClassifier(hidden_layer_sizes = (62, 62))\n\ntest_model(clf_3, 1)","abaf89f8":"from sklearn.tree import DecisionTreeClassifier\n\nDTC = DecisionTreeClassifier()\n\ntest_model(DTC, 10)","7a8e2f9d":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier()\n\ntest_model(RFC, 1)","9ccdae07":"import tensorflow as tf\nimport matplotlib.pyplot as plt","50255a25":"X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size = 0.2)\nX_train = X_train.reshape(-1, 28, 28)\nX_test = X_test.reshape(-1, 28, 28)\nX = test_X.reshape(-1, 28, 28)","4a777623":"# Function to get submission_file\ndef get_submission_file_TF(model, filename):\n    y = model.predict(X)\n    predictions = []\n    for prediction in y:\n        predictions.append(np.argmax(prediction))\n    df_submission = pd.DataFrame({'ImageId' : test_df.index + 1, 'Label' : predictions})\n    # submission file\n    submission_data_path = os.path.join(os.path.pardir, 'Data', 'Predictions')\n    submission_file_path = os.path.join(submission_data_path, filename)\n    # write to the file\n    df_submission.to_csv(submission_file_path, index = False)","238a914c":"def get_submission_file_TF_cnn(model, filename):\n    y = model.predict(X.reshape(-1, 28, 28, 1))\n    predictions = []\n    for prediction in y:\n        predictions.append(np.argmax(prediction))\n    df_submission = pd.DataFrame({'ImageId' : test_df.index + 1, 'Label' : predictions})\n    # submission file\n    submission_data_path = os.path.join(os.path.pardir, 'Data', 'Predictions')\n    submission_file_path = os.path.join(submission_data_path, filename)\n    # write to the file\n    df_submission.to_csv(submission_file_path, index = False)","1c4f0406":"def get_predictions(model, X):\n    y = model.predict(X)\n    predictions = []\n    for prediction in y:\n        predictions.append(np.argmax(prediction))\n    return predictions","e6478d46":"def evaluate_model(model, X, y):\n    val_loss, val_acc = model.evaluate(X, y)\n    print(val_loss, val_acc)","660fa7d1":"def print_image(image):\n    plt.imshow(image, cmap = 'gray')\n    plt.show()","2c165d0c":"print_image(X_train[0])","3e6c7004":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = tf.nn.sigmoid))\nmodel.add(Dense(128, activation = tf.nn.sigmoid))\nmodel.add(Dense(10, activation = tf.nn.softmax))\n\nmodel.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, epochs = 20)","9e3022ab":"evaluate_model(model, X_test, y_test)","639d09ef":"predictions = get_predictions(model, X_test)","283bc8a2":"def get_wrong_predictions(predictons):\n    wrong_predictions = []\n    for i in range(len(predictions)):\n        if(y_test[i] != predictions[i]):\n             wrong_predictions.append(i)\n    return wrong_predictions","ddc87d8f":"wrong_predictions = get_wrong_predictions(predictions)","a665adba":"import random\ndef get_a_wrong_prediction(wrong_predictions):\n    n = random.randint(0, len(wrong_predictions))\n    n = wrong_predictions[n]\n    print_image(X_test[n])\n    print(\"Prediction :\", predictions[n])\n    print(\"Expected :\", y_test[n])","283edccb":"get_a_wrong_prediction(wrong_predictions)","9ad51935":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n# Layer 1\nmodel.add(Conv2D(128, (3, 3), input_shape = (28, 28, 1)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Layer 2\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n       \n# Layer 3\nmodel.add(Flatten())\nmodel.add(Dense(128))\n          \n# Output Layer\nmodel.add(Dense(10))\nmodel.add(Activation('sigmoid'))\n          \nmodel.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n          \nmodel.fit(X_train.reshape(-1, 28, 28, 1), y_train, batch_size = 32, epochs = 10)","c070d737":"evaluate_model(model, X_test.reshape(-1, 28, 28, 1), y_test)","1d8d8bc6":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2)\n\ndatagen.fit(X_train.reshape(-1, 28, 28, 1))\n\nmodel.fit(datagen.flow(X_train.reshape(-1, 28, 28, 1), y_train, batch_size = 32), batch_size = 32, steps_per_epoch = (len(X_train) \/ 32), epochs = 10)","94d1b75e":"evaluate_model(model, X_test.reshape(-1, 28, 28, 1), y_test)","9a4e37db":"## Dummy Model","db6bbbf8":"## Random Forest Classifier ","d52a8301":"## Decision Tree Classifier","5a462573":"### We expect similar accuracy scores.","0f071950":"## Logistic Regression Model","2448000e":"## Neural Network Classifier","d0c5d7dd":"### My best score so far is 98.87% (rank 1427).","f990c14e":"# This is the work of Anirudh Achal.","85eb976e":"# Making Predictive Models","5af7a274":"# TensforFlow","cc6c2e06":"# Import Data","edfd4f50":"## Data Augmentation","97f34d6e":"#### This is not improving my accuracy.","e9cbbfcd":"### We expect a similar validation score.","bf6602b3":"## Kth Nearest Neighbour","426fadfa":"## Random Forest Classifier","17799eea":"## Convolutional Neural Network","2bdd726c":"## Dense Layer Neural Network","1bd49d8e":"### The given data is complete and there are no missing values.","4838a5ab":"## Naive Bayes Classifier"}}