{"cell_type":{"0781b1f1":"code","7f42e550":"code","dfda047d":"code","e809e302":"code","53fc4f71":"code","5b5393e8":"code","b9cfd391":"code","832fd983":"code","706a2fd1":"code","23656549":"code","94e441d4":"code","483836cf":"code","e27369f8":"code","b4c913f4":"code","ca2ea211":"code","8b79bdc7":"code","b3b25b22":"code","e03cb221":"code","09cd0780":"code","6ca81f7c":"code","78767f77":"code","b2b6a733":"code","d14b0843":"code","80b35618":"code","3adaa138":"code","661b15aa":"code","19b75733":"code","0fc431dc":"code","fd391e50":"code","99a1f17a":"code","3d1a28d9":"code","6a447c66":"code","e3984e4b":"code","936340c1":"code","75f9819d":"code","37e0539e":"code","c4382802":"code","5afaf17d":"code","9e322c84":"code","7e55a05f":"code","0f035cdf":"code","b834376b":"code","43654c84":"code","5c92f1dd":"code","be1fc242":"code","c1e1b512":"code","ab6ca967":"code","be3f84d0":"code","f2aea782":"code","ce832c08":"code","11f49cca":"code","e3cb2ba6":"code","893586b2":"code","a1aa6429":"code","50e2aab1":"code","f19a28a0":"code","9a46b841":"code","8c3a2678":"code","fcc75204":"code","a025ecc0":"code","92a4f318":"code","2e7febf1":"code","cc66e05d":"code","2da4b40d":"code","624d35ec":"code","8904905b":"code","666215af":"code","b0c4925c":"code","56c0f2b7":"code","8553fbca":"code","0886a065":"code","1186e59d":"code","0ef7c29c":"code","94b52416":"code","c9e5a1ea":"code","1495f337":"code","b7a51444":"code","3953f39b":"markdown","7fcc4c48":"markdown","a5b69866":"markdown","c2d80bed":"markdown","580eaa51":"markdown","23a2f1da":"markdown","77d2b67d":"markdown","2bdf8576":"markdown","5fa6cc69":"markdown","35e29f83":"markdown","52b2394f":"markdown","18712575":"markdown","a1f5394a":"markdown","48bf001a":"markdown","1a93c460":"markdown","2e0c7bbd":"markdown","7e4e913c":"markdown","fac1407a":"markdown","6c2d7a7b":"markdown","cd03cfde":"markdown","0031854b":"markdown","584a6cb2":"markdown","09ff23f1":"markdown","2a7f6727":"markdown","b0d5b240":"markdown","2de4ca10":"markdown","4485126d":"markdown","8bb111f3":"markdown","8d0f3dc7":"markdown","e6f38edf":"markdown","707e1ca1":"markdown","f0e9c06b":"markdown"},"source":{"0781b1f1":"import time\nnotebookstart = time.time()\nnotebookstart","7f42e550":"import warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter(action='ignore', category=DeprecationWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)","dfda047d":"import platform\nimport sys\nimport importlib\nimport multiprocessing\nimport random","e809e302":"import numpy as np\nimport pandas as pd\n\nrandom.seed(321)\nnp.random.seed(321)\n\npd.options.display.max_columns = 9999","53fc4f71":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport matplotlib.colors as mcolors\n\n%matplotlib inline\n\nmpl.rc('figure', figsize=(15, 12))\nplt.figure(figsize=(15, 12))\nplt.rcParams['figure.facecolor'] = 'azure'\nmpl.style.use('seaborn')\nplt.style.use('seaborn')\n\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')","5b5393e8":"import seaborn as sns\n\nsns.set(rc={'figure.figsize': (15, 12)})\nsns.set(context='notebook', style='darkgrid', font='sans-serif',\n        font_scale=1.1, rc={'figure.facecolor': 'azure',\n        'axes.facecolor': 'azure', 'grid.color': 'steelblue'})\nsns.color_palette(mcolors.TABLEAU_COLORS);","b9cfd391":"import missingno as msno","832fd983":"import scikitplot as skplt","706a2fd1":"import sklearn\n\nfrom sklearn.model_selection import train_test_split, \\\n    cross_val_predict, cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit, \\\n    StratifiedKFold, GridSearchCV\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, \\\n    RobustScaler, MaxAbsScaler, Normalizer\nfrom sklearn.preprocessing import LabelBinarizer, label_binarize\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, \\\n    classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.metrics import average_precision_score, \\\n    precision_recall_fscore_support\n\nfrom sklearn.utils import shuffle, resample\nfrom sklearn.base import BaseEstimator, ClassifierMixin","23656549":"from sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier","94e441d4":"import xgboost as xgb\nfrom xgboost import XGBClassifier","483836cf":"import lightgbm as lgbm\nfrom lightgbm import LGBMClassifier","e27369f8":"import catboost\nfrom catboost import CatBoostClassifier","b4c913f4":"import skopt\nfrom skopt import BayesSearchCV","ca2ea211":"import imblearn\nfrom imblearn.over_sampling import SMOTE, SMOTENC","8b79bdc7":"print('Operating system version........', platform.platform())\nprint('Python version is............... %s.%s.%s' % sys.version_info[:3])\nprint('scikit-learn version is.........', sklearn.__version__)\nprint('pandas version is...............', pd.__version__)\nprint('numpy version is................', np.__version__)\nprint('matplotlib version is...........', mpl.__version__)\nprint('seaborn version is..............', sns.__version__)\nprint('scikit-plot version is..........', skplt.__version__)\nprint('missingno version is............', msno.__version__)\nprint('xgboost version is..............', xgb.__version__)\nprint('catboost version is.............', catboost.__version__)\nprint('lightgbm version is.............', lgbm.__version__)\nprint('scikit-optimize version is......', skopt.__version__)\nprint('imblearn version is.............', imblearn.__version__)","b3b25b22":"def getDatasetInformation(csv_filepath, is_corr_required=True):\n    \"\"\"\n    Read CSV (comma-separated) file into DataFrame\n    \n    Returns,\n    - DataFrame\n    - DataFrame's shape\n    - DataFrame's data types\n    - DataFrame's describe\n    - DataFrame's sorted unique value count\n    - DataFrame's missing or NULL value count\n    - DataFrame's correlation between numerical columns\n    \"\"\"\n\n    dataset_tmp = pd.read_csv(csv_filepath)\n\n    dataset_tmp_shape = pd.DataFrame(list(dataset_tmp.shape),\n            index=['No of Rows', 'No of Columns'], columns=['Total'])\n    dataset_tmp_shape = dataset_tmp_shape.reset_index()\n\n    dataset_tmp_dtypes = dataset_tmp.dtypes.reset_index()\n    dataset_tmp_dtypes.columns = ['Column Names', 'Column Data Types']\n\n    dataset_tmp_desc = pd.DataFrame(dataset_tmp.describe())\n    dataset_tmp_desc = dataset_tmp_desc.transpose()\n\n    dataset_tmp_unique = dataset_tmp.nunique().reset_index()\n    dataset_tmp_unique.columns = ['Column Name', 'Unique Value(s) Count'\n                                  ]\n\n    dataset_tmp_missing = dataset_tmp.isnull().sum(axis=0).reset_index()\n    dataset_tmp_missing.columns = ['Column Names',\n                                   'NULL value count per Column']\n    dataset_tmp_missing = \\\n        dataset_tmp_missing.sort_values(by='NULL value count per Column'\n            , ascending=False)\n\n    if is_corr_required:\n        dataset_tmp_corr = dataset_tmp.corr(method='spearman')\n    else:\n        dataset_tmp_corr = pd.DataFrame()\n\n    return [\n        dataset_tmp,\n        dataset_tmp_shape,\n        dataset_tmp_dtypes,\n        dataset_tmp_desc,\n        dataset_tmp_unique,\n        dataset_tmp_missing,\n        dataset_tmp_corr,\n        ]","e03cb221":"def getHighlyCorrelatedColumns(dataset, NoOfCols=6):\n    df_corr = dataset.corr()\n\n    # set the correlations on the diagonal or lower triangle to zero,\n    # so they will not be reported as the highest ones\n\n    df_corr *= np.tri(k=-1, *df_corr.values.shape).T\n    df_corr = df_corr.stack()\n    df_corr = \\\n        df_corr.reindex(df_corr.abs().sort_values(ascending=False).index).reset_index()\n    return df_corr.head(NoOfCols)","09cd0780":"def createFeatureEngineeredColumns(dataset):\n    dataset_tmp = pd.DataFrame()\n\n    dataset_tmp['CountOfZeroValues'] = (dataset == 0).sum(axis=1)\n    dataset_tmp['CountOfNonZeroValues'] = (dataset != 0).sum(axis=1)\n\n    weight = ((dataset != 0).sum() \/ len(dataset)).values\n    dataset_tmp['WeightedCount'] = (dataset * weight).sum(axis=1)\n\n    dataset_tmp['SumOfValues'] = dataset.sum(axis=1)\n\n    dataset_tmp['VarianceOfValues'] = dataset.var(axis=1)\n    dataset_tmp['MedianOfValues'] = dataset.median(axis=1)\n    dataset_tmp['MeanOfValues'] = dataset.mean(axis=1)\n    dataset_tmp['StandardDeviationOfValues'] = dataset.std(axis=1)\n    #dataset_tmp['ModeOfValues'] = dataset.mode(axis=1)\n    dataset_tmp['SkewOfValues'] = dataset.skew(axis=1)\n    dataset_tmp['KurtosisOfValues'] = dataset.kurtosis(axis=1)\n\n    dataset_tmp['MaxOfValues'] = dataset.max(axis=1)\n    dataset_tmp['MinOfValues'] = dataset.min(axis=1)\n    dataset_tmp['DiffOfMinMaxOfValues'] = \\\n        np.subtract(dataset_tmp['MaxOfValues'],\n                    dataset_tmp['MinOfValues'])\n\n    dataset_tmp['QuantilePointFiveOfValues'] = dataset[dataset\n            > 0].quantile(0.5, axis=1)\n\n    dataset = pd.concat([dataset, dataset_tmp], axis=1)\n\n    return dataset","6ca81f7c":"def getZeroStdColumns(dataset):\n    columnsWithZeroStd = dataset.columns[dataset.std() == 0].tolist()\n    return columnsWithZeroStd","78767f77":"def getUniqueValueColumns(dataset, valueToCheck=0):\n    columnsWithUniqueValue = dataset.columns[dataset.nunique()\n            == valueToCheck].tolist()\n    return columnsWithUniqueValue","b2b6a733":"def plotCategoricalVariableDistributionGraph(target_value, title='', xticksrotation=0):\n    tmp_count = target_value.value_counts()\n    \n    fig=plt.figure()\n    fig.suptitle(title, fontsize=18)\n    \n    ax1=fig.add_subplot(221)\n    sns.pointplot(x=tmp_count.index, y=tmp_count, ax=ax1)\n    ax1.set_title('Distribution Graph')\n    plt.xticks(rotation=xticksrotation)\n    \n    ax2=fig.add_subplot(222)\n    sns.barplot(x=tmp_count.index, y=tmp_count, ax=ax2)\n    ax2.set_title('Distribution Graph - Bar')\n    plt.xticks(rotation=xticksrotation)\n    \n    ax3=fig.add_subplot(212)\n    ax3.pie(tmp_count, labels=tmp_count.index, autopct=\"%1.1f%%\", shadow=True, startangle=195)\n    ax3.axis('equal')\n    ax3.set_title('Distribution Graph - Pie')\n    \n    fig.tight_layout()\n    fig.subplots_adjust(top=0.90)\n    plt.show()","d14b0843":"def plot_distplot(dataset):\n    colors = mcolors.TABLEAU_COLORS\n\n    dataset_fordist = dataset.select_dtypes([np.int, np.float])\n    number_of_subplots = len(dataset_fordist.columns)\n    number_of_columns = 3\n\n    number_of_rows = number_of_subplots \/\/ number_of_columns\n    number_of_rows += number_of_subplots % number_of_columns\n\n    postion = range(1, number_of_subplots + 1)\n\n    fig = plt.figure(1)\n    for k in range(number_of_subplots):\n        ax = fig.add_subplot(number_of_rows, number_of_columns,\n                             postion[k])\n        sns.distplot(dataset_fordist.iloc[:, k],\n                     color=random.choice(list(colors.keys())), ax=ax)\n    fig.tight_layout()\n    plt.show()","80b35618":"def convertIntFloatToInt(dictObj):\n    for (k, v) in dictObj.items():\n        if float('Inf') == v:\n            pass\n        elif int(v) == v and isinstance(v, float):\n            dictObj[k] = int(v)\n    return dictObj","3adaa138":"(\n    dataset_sctp_train,\n    df_train_shape,\n    df_train_dtypes,\n    df_train_describe,\n    df_train_unique,\n    df_train_missing,\n    df_train_corr,\n    ) = getDatasetInformation('..\/input\/train.csv', False)\n\n(\n    dataset_sctp_test,\n    df_test_shape,\n    df_test_dtypes,\n    df_test_describe,\n    df_test_unique,\n    df_test_missing,\n    df_test_corr,\n    ) = getDatasetInformation('..\/input\/test.csv', False)","661b15aa":"dataset_sctp_train.head()","19b75733":"df_train_shape","0fc431dc":"df_train_dtypes","fd391e50":"df_train_describe","99a1f17a":"df_train_unique","3d1a28d9":"df_train_missing","6a447c66":"msno.matrix(dataset_sctp_train, color=(33 \/ 255, 102 \/ 255, 172 \/ 255));","e3984e4b":"dataset_sctp_test.head()","936340c1":"df_test_shape","75f9819d":"df_test_dtypes","37e0539e":"df_test_describe","c4382802":"df_test_unique","5afaf17d":"df_test_missing","9e322c84":"msno.matrix(dataset_sctp_test, color=(33 \/ 255, 102 \/ 255, 172 \/ 255));","7e55a05f":"del(df_train_shape, df_train_dtypes, df_train_describe, df_train_unique, df_train_missing, df_train_corr)\ndel(df_test_shape, df_test_dtypes, df_test_describe, df_test_unique, df_test_missing, df_test_corr)","0f035cdf":"plot_distplot(dataset_sctp_train.iloc[:, 2:29])","b834376b":"plot_distplot(dataset_sctp_train.iloc[:, 29:56])","43654c84":"plot_distplot(dataset_sctp_train.iloc[:, 56:83])","5c92f1dd":"plot_distplot(dataset_sctp_train.iloc[:, 83:110])","be1fc242":"plot_distplot(dataset_sctp_train.iloc[:, 110:137])","c1e1b512":"plot_distplot(dataset_sctp_train.iloc[:, 137:164])","ab6ca967":"plot_distplot(dataset_sctp_train.iloc[:, 164:191])","be3f84d0":"plot_distplot(dataset_sctp_train.iloc[:, 191:204])","f2aea782":"dataset_sctp_train.target.unique()","ce832c08":"dataset_sctp_train.target.value_counts()","11f49cca":"plotCategoricalVariableDistributionGraph(dataset_sctp_train.target, 'Target (feature) - Distribution', xticksrotation=90)","e3cb2ba6":"dataset_sctp_train_majority = dataset_sctp_train[dataset_sctp_train.target==0]\ndataset_sctp_train_minority = dataset_sctp_train[dataset_sctp_train.target==1]\n\ndataset_sctp_train_minority_upsampled = resample(dataset_sctp_train_minority, replace=True, n_samples=100000,)\n\ndataset_sctp_train_upsampled = pd.concat([dataset_sctp_train_majority, dataset_sctp_train_minority_upsampled])\ndataset_sctp_train_upsampled.target.value_counts()","893586b2":"plotCategoricalVariableDistributionGraph(dataset_sctp_train_upsampled.target, 'Target (feature) - Distribution', xticksrotation=90)","a1aa6429":"#y=dataset_sctp_train['target']\n#X=dataset_sctp_train.drop(['ID_code', 'target'], axis=1)\n\ny=dataset_sctp_train_upsampled['target']\nX=dataset_sctp_train_upsampled.drop(['ID_code', 'target'], axis=1)\n\ndataset_sctp_test_ID_code = dataset_sctp_test['ID_code']\ndataset_sctp_test.drop(['ID_code'], axis=1, inplace=True)\n\n(X.shape, y.shape, dataset_sctp_test.shape)","50e2aab1":"getHighlyCorrelatedColumns(X, 20)","f19a28a0":"X=createFeatureEngineeredColumns(X)","9a46b841":"dataset_sctp_test=createFeatureEngineeredColumns(dataset_sctp_test)","8c3a2678":"(X.shape, dataset_sctp_test.shape)","fcc75204":"columnsWithZeroStdToRemove = getZeroStdColumns(X)\nprint(f'Columns with Zero STD to drop from Train and Test dataset(s) are {columnsWithZeroStdToRemove}.')\n\nX.drop(columnsWithZeroStdToRemove, axis=1, inplace=True)\ndataset_sctp_test.drop(columnsWithZeroStdToRemove, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","a025ecc0":"X_columns_one_unique_value = getUniqueValueColumns(X, 1)\nprint(f'Columns with only 1 as value to drop from Train and Test datasets are {X_columns_one_unique_value}.')\n\nX.drop(X_columns_one_unique_value, axis=1, inplace=True)\ndataset_sctp_test.drop(X_columns_one_unique_value, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","92a4f318":"X_columns_zero_unique_value = getUniqueValueColumns(X, 0)\nprint(f'Columns with only 0 as value to drop from Train and Test datasets are {X_columns_zero_unique_value}.')\n\nX.drop(X_columns_zero_unique_value, axis=1, inplace=True)\ndataset_sctp_test.drop(X_columns_zero_unique_value, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","2e7febf1":"n_cpus_avaliable = multiprocessing.cpu_count()\n\nprint(f'We\\'ve got {n_cpus_avaliable} cpus to work with.')","cc66e05d":"model_scores = pd.DataFrame(columns=['Classification_Type', 'Model_Name',\n                            'Accuracy_Score'])","2da4b40d":"(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n        test_size=0.20)","624d35ec":"dataset_sctp_train_lgbm = lgbm.Dataset(data=X, label=y)\ndataset_sctp_test_lgbm = lgbm.Dataset(data=X_test, label=y_test)\nwatchlist = [dataset_sctp_train_lgbm, dataset_sctp_test_lgbm]\n\nevaluation_results = {}\n\nlgbmparams = {\n    'boosting_type': 'gbdt',\n    'class_weight': 'balanced',\n    'colsample_bytree': 0.8220008732467731,\n    'importance_type': 'split',\n    'learning_rate': 0.6161285857013439,\n    'max_depth': 33,\n    'metric': 'binary_logloss',\n    'min_child_samples': 9,\n    'min_child_weight': 0.7823020109077508,\n    'min_split_gain': 0.7211200712627109,\n    'n_estimators': 295,\n    'n_jobs': n_cpus_avaliable,\n    'num_leaves': 41,\n    'objective': 'binary',\n    'reg_alpha': 0.0,\n    'reg_lambda': 0.002053077897015527,\n    'silent': False,\n    'subsample': 0.6820394902275151,\n    'subsample_for_bin': 200000,\n    'subsample_freq': 8,\n    }\n\nlgbm_twoclass_model = lgbm.train(\n    lgbmparams,\n    train_set=dataset_sctp_train_lgbm,\n    num_boost_round=5000,\n    valid_sets=watchlist,\n    early_stopping_rounds=120,\n    evals_result=evaluation_results,\n    verbose_eval=100,\n    )","8904905b":"y_pred_proba = lgbm_twoclass_model.predict(X_test)\ny_pred = [round(value) for value in y_pred_proba]\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the LightGBM (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': lgbm_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (LightGBM Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );","666215af":"ax = lgbm.plot_metric(evaluation_results)\nplt.show()","b0c4925c":"ax = lgbm.plot_importance(lgbm_twoclass_model, max_num_features=30, color=mcolors.TABLEAU_COLORS)\nplt.show()","56c0f2b7":"dtrain = xgb.DMatrix(X, label=y)\ndtest = xgb.DMatrix(X_test, label=y_test)\n\nwatchlist = [(dtrain, 'train'), (dtest, 'valid')]\n\nxgbparams = {\n    'base_score': 0.5,\n    'booster': 'gbtree',\n    'colsample_bylevel': 0.48973134715974026,\n    'colsample_bytree': 0.46131821596707184,\n    'device': 'cpu',\n    'eval_metric': 'auc',\n    'gamma': 8.0762512124703e-06,\n    'learning_rate': 0.054722068464825926,\n    'max_delta_step': 3,\n    'max_depth': 29,\n    'min_child_weight': 14,\n    'missing': 'None',\n    'n_estimators': 274,\n    'n_jobs': n_cpus_avaliable,\n    'objective': 'binary:logistic',\n    'reg_alpha': 0,\n    'reg_lambda': 2.1021696940800796,\n    'scale_pos_weight': 43.8858626195784,\n    'silent': True,\n    'subsample': 0.8113392946402368,\n    'tree_method': 'approx',\n    }\nxgb_twoclass_model = xgb.train(\n    xgbparams,\n    dtrain,\n    5000,\n    watchlist,\n    verbose_eval=200,\n    early_stopping_rounds=100,\n    )","8553fbca":"y_pred_proba = xgb_twoclass_model.predict(dtest)\ny_pred = [round(value) for value in y_pred_proba]\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the XGBoost (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': xgb_twoclass_model.__class__.__name__ + ' - CV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (XGBoost Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );","0886a065":"model_scores.Accuracy_Score = model_scores.Accuracy_Score.astype('float32')\nmodel_scores","1186e59d":"sns.barplot(x='Model_Name', y='Accuracy_Score', data=model_scores);\nplt.xticks(rotation=90)\nplt.show()","0ef7c29c":"sctp_predictions_lgbm = lgbm_twoclass_model.predict(dataset_sctp_test)\nsctp_predictions_lgbm = [round(value) for value in sctp_predictions_lgbm]\nsctp_predictions_lgbm = list(map(int, sctp_predictions_lgbm))\nsctp_predictions_lgbm[:20]","94b52416":"dataset_submission = pd.DataFrame()\ndataset_submission['ID_code'] = dataset_sctp_test_ID_code\ndataset_submission['target'] = sctp_predictions_lgbm\ndataset_submission.to_csv('lgbm_twoclass_model_submission.csv', index=False)","c9e5a1ea":"dataset_sctp_test_xgb = xgb.DMatrix(dataset_sctp_test)\nsctp_predictions_xgb = xgb_twoclass_model.predict(dataset_sctp_test_xgb)\nsctp_predictions_xgb = [round(value) for value in sctp_predictions_xgb]\nsctp_predictions_xgb = list(map(int, sctp_predictions_xgb))\nsctp_predictions_xgb[:20]","1495f337":"dataset_submission = pd.DataFrame()\ndataset_submission['ID_code'] = dataset_sctp_test_ID_code\ndataset_submission['target'] = sctp_predictions_xgb\ndataset_submission.to_csv('xgb_twoclass_model_submission.csv', index=False)","b7a51444":"print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)\/60))","3953f39b":"## SEPERATE DATA AND TARGET FEATURES","7fcc4c48":"feature_importance = pd.DataFrame({'imp': xgb_twoclass_model.feature_importances_, 'col': X_train.columns})\nfeature_importance = feature_importance.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nfeature_importance.plot(kind='barh', x='col', y='imp', color=mcolors.TABLEAU_COLORS);\nplt.title('Binomial Classification (XGBoost - Feature Importance(s))', fontsize=18)\nplt.show()","a5b69866":"## INTRODUCTION\n\nIn this challenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data they have available to solve this problem.\n\nThe data is anonimyzed, each row containing 200 numerical values identified just with a number.","c2d80bed":"upper = df_train_corr.where(np.triu(np.ones(df_train_corr.shape), k=1).astype(np.bool))\n\nto_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n\nprint(f'Columns to drop from Train and Test datasets are {to_drop}.')\n\nX.drop(columns=to_drop, axis=1, inplace=True)\ndataset_sctp_test.drop(columns=to_drop, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","580eaa51":"df_train_corr = X.corr(method='spearman')\ndf_train_corr","23a2f1da":"## UP-SAMPLE MINORITY CLASS (TARGET) TO BALANCE DATA","77d2b67d":"## BINOMIAL CLASSIFICATION: Using **XGBClassifier** with BayesSearchCV","2bdf8576":"# SANTANDER CUSTOMER TRANSACTION PREDICTION\n\n**BHAVESHKUMAR THAKER**","5fa6cc69":"y_pred = xgb_twoclass_model.predict(X_test)\ny_pred_proba = xgb_twoclass_model.predict_proba(X_test)\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the XGBoost (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': xgb_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (XGBoost Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_precision_recall(y_test, y_pred_proba,\n                                    title='Binomial Classification (XGBoost Precision-Recall Curve)',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_roc(y_test, y_pred_proba,\n                       title='Binomial Classification (XGBoost ROC Curves)',\n                      );","35e29f83":"## ANALYSE TRAIN DATA","52b2394f":"## BINOMIAL CLASSIFICATION: Using **LGBMClassifier** with BayesSearchCV","18712575":"def lgbm_status_print_twoclass(optimal_result):\n    all_models = pd.DataFrame(lgbm_bayes_cv_tuner_twoclass.cv_results_)\n    best_params = pd.Series(lgbm_bayes_cv_tuner_twoclass.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(len(all_models),\n            np.round(lgbm_bayes_cv_tuner_twoclass.best_score_, 4),\n            lgbm_bayes_cv_tuner_twoclass.best_params_)\n         )\n\n\nlgbm_bayes_cv_tuner_twoclass = BayesSearchCV(\n    estimator=lgbm.LGBMClassifier(n_jobs=n_cpus_avaliable,\n                                  objective='binary',\n                                  metric='binary_logloss',\n                                  #is_unbalance=True,\n                                  class_weight='balanced',\n                                  silent=True),\n    search_spaces={\n        #'boosting_type': ['gbdt', 'dart', 'rf'],\n        'num_leaves': (1, 50),\n        'max_depth': (1, 40),\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'n_estimators': (100, 300),\n        'min_split_gain': (0.01, 1.0, 'uniform'),\n        'min_child_weight': (0.01, 1.0, 'uniform'),\n        'min_child_samples': (1, 10),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'subsample_freq': (1, 50),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        #'bagging_fraction': (0.01, 1.0, 'uniform'),     # OR subsample\n        #'feature_fraction': (0.01, 1.0, 'uniform'),     # OR colsample_bytree\n        },\n    scoring='roc_auc',\n    cv=StratifiedKFold(n_splits=13, shuffle=True),\n    n_jobs=n_cpus_avaliable,\n    n_iter=9,\n    refit=True,\n    verbose=0,\n    )\n\n\nlgbm_result_twoclass = lgbm_bayes_cv_tuner_twoclass.fit(X, y, \n        callback=lgbm_status_print_twoclass)\n\nlgbm_twoclass_model = lgbm_result_twoclass.best_estimator_\n\nprint(lgbm_twoclass_model)","a1f5394a":"### PERFORM CLASSIFICATION","48bf001a":"def status_print_twoclass(optimal_result):\n    all_models = pd.DataFrame(bayes_cv_tuner_twoclass.cv_results_)\n    best_params = pd.Series(bayes_cv_tuner_twoclass.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(len(all_models), \n            np.round(bayes_cv_tuner_twoclass.best_score_, 4), \n            bayes_cv_tuner_twoclass.best_params_)\n         )\n\n\nbayes_cv_tuner_twoclass = BayesSearchCV(\n    estimator=xgb.XGBClassifier(\n        n_jobs=n_cpus_avaliable,\n        objective='binary:logistic',\n        eval_metric='auc',\n        silent=1,\n        tree_method='approx',\n        device='cpu',\n        ),\n    search_spaces={\n        #'booster': ['gbtree', 'dart'],\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'max_delta_step': (0, 20),\n        'max_depth': (0, 40),\n        'min_child_weight': (0, 20),\n        'n_estimators': (200, 300),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        'gamma': (1e-9, 0.5, 'log-uniform'),\n        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n        },\n    scoring='roc_auc',\n    cv=StratifiedKFold(n_splits=13, shuffle=True),\n    n_jobs=n_cpus_avaliable,\n    n_iter=9,\n    refit=True,\n    verbose=0,\n    )\n\nresult_twoclass = bayes_cv_tuner_twoclass.fit(X, y,\n        callback=status_print_twoclass)\n\nxgb_twoclass_model = result_twoclass.best_estimator_\n\nprint(xgb_twoclass_model)","1a93c460":"# DEFINE GENERIC COMMON METHODS","2e0c7bbd":"# PERFORM EXPLORATORY DATA ANALYSIS (EDA)","7e4e913c":"#mask = np.zeros_like(df_train_corr, dtype=np.bool)\n#mask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(\n    df_train_corr,\n    cmap='rainbow',\n    annot=False,\n    fmt='.2f',\n    center=0,\n    square=False,\n    linewidths=.75,\n    #mask=mask,\n    );\nplt.title('Correlation Matrix', fontsize=18)\nplt.show()","fac1407a":"# COMPARE MODELS","6c2d7a7b":"## UNDERSTANDING TARGET VARIABLE","cd03cfde":"## UNDERSTANDING DISTRIBUTION OF FEATURE(S)","0031854b":"### PERFORM CLASSIFICATION","584a6cb2":"# LOAD PACKAGES","09ff23f1":"y_pred = lgbm_twoclass_model.predict(X_test)\ny_pred_proba = lgbm_twoclass_model.predict_proba(X_test)\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the LightGBM (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': lgbm_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (LightGBM Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_precision_recall(y_test, y_pred_proba,\n                                    title='Binomial Classification (LightGBM Precision-Recall Curve)',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_roc(y_test, y_pred_proba,\n                       title='Binomial Classification (LightGBM ROC Curves)',\n                      );","2a7f6727":"# LOAD DATA AND PERFORM ANALYSIS","b0d5b240":"# MODELING","2de4ca10":"## CORRELATION MATRIX","4485126d":"del(df_train_corr)","8bb111f3":"# PREDICTIONS OF TEST DATA","8d0f3dc7":"## ANALYSE TEST DATA","e6f38edf":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#SANTANDER-CUSTOMER-TRANSACTION-PREDICTION\" data-toc-modified-id=\"SANTANDER-CUSTOMER-TRANSACTION-PREDICTION-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>SANTANDER CUSTOMER TRANSACTION PREDICTION<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#INTRODUCTION\" data-toc-modified-id=\"INTRODUCTION-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>INTRODUCTION<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#LOAD-PACKAGES\" data-toc-modified-id=\"LOAD-PACKAGES-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>LOAD PACKAGES<\/a><\/span><\/li><li><span><a href=\"#DEFINE-GENERIC-COMMON-METHODS\" data-toc-modified-id=\"DEFINE-GENERIC-COMMON-METHODS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>DEFINE GENERIC COMMON METHODS<\/a><\/span><\/li><li><span><a href=\"#LOAD-DATA-AND-PERFORM-ANALYSIS\" data-toc-modified-id=\"LOAD-DATA-AND-PERFORM-ANALYSIS-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>LOAD DATA AND PERFORM ANALYSIS<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#ANALYSE-TRAIN-DATA\" data-toc-modified-id=\"ANALYSE-TRAIN-DATA-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>ANALYSE TRAIN DATA<\/a><\/span><\/li><li><span><a href=\"#ANALYSE-TEST-DATA\" data-toc-modified-id=\"ANALYSE-TEST-DATA-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>ANALYSE TEST DATA<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#PERFORM-EXPLORATORY-DATA-ANALYSIS-(EDA)\" data-toc-modified-id=\"PERFORM-EXPLORATORY-DATA-ANALYSIS-(EDA)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>PERFORM EXPLORATORY DATA ANALYSIS (EDA)<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#UNDERSTANDING-DISTRIBUTION-OF-FEATURE(S)\" data-toc-modified-id=\"UNDERSTANDING-DISTRIBUTION-OF-FEATURE(S)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>UNDERSTANDING DISTRIBUTION OF FEATURE(S)<\/a><\/span><\/li><li><span><a href=\"#UNDERSTANDING-TARGET-VARIABLE\" data-toc-modified-id=\"UNDERSTANDING-TARGET-VARIABLE-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>UNDERSTANDING TARGET VARIABLE<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#FEATURE-ENGINEERING\" data-toc-modified-id=\"FEATURE-ENGINEERING-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>FEATURE ENGINEERING<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#UP-SAMPLE-MINORITY-CLASS-(TARGET)-TO-BALANCE-DATA\" data-toc-modified-id=\"UP-SAMPLE-MINORITY-CLASS-(TARGET)-TO-BALANCE-DATA-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>UP-SAMPLE MINORITY CLASS (TARGET) TO BALANCE DATA<\/a><\/span><\/li><li><span><a href=\"#SEPERATE-DATA-AND-TARGET-FEATURES\" data-toc-modified-id=\"SEPERATE-DATA-AND-TARGET-FEATURES-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>SEPERATE DATA AND TARGET FEATURES<\/a><\/span><\/li><li><span><a href=\"#CORRELATION-MATRIX\" data-toc-modified-id=\"CORRELATION-MATRIX-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>CORRELATION MATRIX<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#MODELING\" data-toc-modified-id=\"MODELING-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>MODELING<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#BINOMIAL-CLASSIFICATION:-Using-LGBMClassifier-with-BayesSearchCV\" data-toc-modified-id=\"BINOMIAL-CLASSIFICATION:-Using-LGBMClassifier-with-BayesSearchCV-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;<\/span>BINOMIAL CLASSIFICATION: Using <strong>LGBMClassifier<\/strong> with BayesSearchCV<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#PERFORM-CLASSIFICATION\" data-toc-modified-id=\"PERFORM-CLASSIFICATION-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;<\/span>PERFORM CLASSIFICATION<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#BINOMIAL-CLASSIFICATION:-Using-XGBClassifier-with-BayesSearchCV\" data-toc-modified-id=\"BINOMIAL-CLASSIFICATION:-Using-XGBClassifier-with-BayesSearchCV-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;<\/span>BINOMIAL CLASSIFICATION: Using <strong>XGBClassifier<\/strong> with BayesSearchCV<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#PERFORM-CLASSIFICATION\" data-toc-modified-id=\"PERFORM-CLASSIFICATION-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;<\/span>PERFORM CLASSIFICATION<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#COMPARE-MODELS\" data-toc-modified-id=\"COMPARE-MODELS-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>COMPARE MODELS<\/a><\/span><\/li><li><span><a href=\"#PREDICTIONS-OF-TEST-DATA\" data-toc-modified-id=\"PREDICTIONS-OF-TEST-DATA-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;<\/span>PREDICTIONS OF TEST DATA<\/a><\/span><\/li><\/ul><\/div>","707e1ca1":"# FEATURE ENGINEERING","f0e9c06b":"feature_importance = pd.DataFrame({'imp': lgbm_twoclass_model.feature_importances_, 'col': X_train.columns})\nfeature_importance = feature_importance.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nfeature_importance.plot(kind='barh', x='col', y='imp', color=mcolors.TABLEAU_COLORS);\nplt.title('Binomial Classification (LightGBM - Feature Importance(s))', fontsize=18)\nplt.show()"}}