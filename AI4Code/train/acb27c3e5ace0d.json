{"cell_type":{"c5e68939":"code","5ec28283":"code","83229c93":"code","597544db":"code","ea34cb6f":"code","3daf175f":"code","586f7444":"code","f1280086":"code","9d40c9cc":"code","fa4e7fce":"code","95deef19":"code","374b80c8":"code","f5ce371c":"code","a29c7379":"markdown","e1514ed5":"markdown","124d065e":"markdown"},"source":{"c5e68939":"!pip install SimpleITK\n\nimport numpy as np\nimport os\nimport time\nimport pandas as pd\nimport fnmatch\nimport cv2\nimport matplotlib.pyplot as plt\nimport SimpleITK as sitk\nfrom skimage.exposure import equalize_adapthist, equalize_hist\n\n!pip install albumentations > \/dev\/null\n!pip install -U segmentation-models\n#!pip install -U efficientnet==0.0.4\nimport numpy as np\nimport pandas as pd\nimport gc\nimport keras\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\n\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.losses import binary_crossentropy\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import  ModelCheckpoint\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, Concatenate, MaxPooling2D\nfrom keras.layers import UpSampling2D, Dropout, BatchNormalization\nfrom tqdm import tqdm_notebook\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.utils import conv_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.engine import InputSpec\nfrom keras import backend as K\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.losses import binary_crossentropy\nimport keras.callbacks as callbacks\nfrom keras.callbacks import Callback\nfrom keras.applications.xception import Xception\nfrom keras.layers import multiply\n\n\nfrom keras import optimizers\nfrom keras.legacy import interfaces\nfrom keras.utils.generic_utils import get_custom_objects\n\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.regularizers import l2\nfrom keras.layers.core import Dense, Lambda\nfrom keras.layers.merge import concatenate, add\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport glob\nimport shutil\nimport os\nimport random\nfrom PIL import Image\nimport cv2\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\n#tf.set_random_seed(seed)\n    \n%matplotlib inline\nfrom keras.models import Model\nfrom keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\nfrom keras.layers import  merge, UpSampling2D, Dropout, Cropping2D, BatchNormalization\nfrom keras import backend as K\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom functools import partial\nfrom keras.initializers import RandomNormal, VarianceScaling\nimport numpy as np\n\n","5ec28283":"print(tf.__version__)","83229c93":"def load_data():\n  return np.load('..\/input\/clahe-001real\/X_train(Clahe_0.01).npy'), np.load('..\/input\/clahe-001real\/y_train(Clahe_0.01).npy')","597544db":"X_data, y_data = load_data()","ea34cb6f":"from sklearn.model_selection import train_test_split\n#from wandb import magic","3daf175f":"# Evalaution Metrics\ndef dice_coef(y_true, y_pred, smooth=1.0):\n\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (\n        K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score","586f7444":"def elastic_transform(image, x=None, y=None, alpha=256*3, sigma=256*0.07):\n    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n       Convolutional Neural Networks applied to Visual Document Analysis\", in\n       Proc. of the International Conference on Document Analysis and\n       Recognition, 2003.\n    \"\"\"\n\n    shape = image.shape\n    blur_size = int(4*sigma) | 1\n    dx = cv2.GaussianBlur((np.random.rand(shape[0],shape[1]) * 2 - 1), ksize=(blur_size, blur_size), sigmaX=sigma)* alpha\n    dy = cv2.GaussianBlur((np.random.rand(shape[0],shape[1]) * 2 - 1), ksize=(blur_size, blur_size), sigmaX=sigma)* alpha\n\n    if (x is None) or (y is None):\n        x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n\n    map_x =  (x+dx).astype('float32')\n    map_y =  (y+dy).astype('float32')\n\n    return cv2.remap(image.astype('float32'), map_y,  map_x, interpolation=cv2.INTER_NEAREST).reshape(shape)","f1280086":"class SnapshotCallbackBuilder:\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.001):\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n\n        callback_list = [\n            callbacks.ModelCheckpoint(\"best_xception_model.h5\",monitor='val_dice_coef', \n                                   mode = 'max', save_best_only=True, verbose=1),\n            swa,\n            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n        ]\n\n        return callback_list\n\n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T \/\/ self.M))  # t - 1 is used when t has 1-based indexing.\n        cos_inner \/= self.T \/\/ self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero \/ 2 * cos_out)","9d40c9cc":"class SWA(keras.callbacks.Callback):\n    \n    def __init__(self, filepath, swa_epoch):\n        super(SWA, self).__init__()\n        self.filepath = filepath\n        self.swa_epoch = swa_epoch \n    \n    def on_train_begin(self, logs=None):\n        self.nb_epoch = self.params['epochs']\n        print('Stochastic weight averaging selected for last {} epochs.'\n              .format(self.nb_epoch - self.swa_epoch))\n        \n    def on_epoch_end(self, epoch, logs=None):\n        \n        if epoch == self.swa_epoch:\n            self.swa_weights = self.model.get_weights()\n            \n        elif epoch > self.swa_epoch:    \n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * \n                    (epoch - self.swa_epoch) + self.model.get_weights()[i])\/((epoch - self.swa_epoch)  + 1)  \n\n        else:\n            pass\n        \n    def on_train_end(self, logs=None):\n        self.model.set_weights(self.swa_weights)\n        print('Final model parameters set to stochastic weight average.')\n        self.model.save_weights(self.filepath)\n        print('Final stochastic averaged weights saved to file.')","fa4e7fce":"def keras_fit_generator(img_rows=256, img_cols=256, n_imgs=15 * 10 ** 4, batch_size=32, epochs = 50, regenerate=True):\n\n    # Data-split\n    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=0.1)\n\n    # img_rows = X_train.shape[1]\n    # img_cols =  X_train.shape[2]\n\n    # Provide the same seed and keyword arguments to the fit and flow methods\n\n    x, y = np.meshgrid(np.arange(img_rows), np.arange(img_cols), indexing='ij')\n    elastic = partial(elastic_transform, x=x, y=y, alpha=img_rows*1.5, sigma=img_rows*0.07 )\n    # we create two instances with the same arguments\n    data_gen_args = dict(\n        featurewise_center=False,\n        featurewise_std_normalization=False,\n        rotation_range=10.,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        zoom_range=[1, 1.2],\n        fill_mode='constant',\n        preprocessing_function=elastic)\n\n    image_datagen = ImageDataGenerator(**data_gen_args)\n    mask_datagen = ImageDataGenerator(**data_gen_args)\n\n    seed = 2\n    image_datagen.fit(X_train, seed=seed)\n    mask_datagen.fit(y_train, seed=seed)\n    image_generator = image_datagen.flow(X_train, batch_size=batch_size, seed=seed)\n    mask_generator = mask_datagen.flow(y_train, batch_size=batch_size, seed=seed)\n    train_generator = zip(image_generator, mask_generator)\n\n    model = UXception(input_shape=(img_rows, img_cols, 1))\n    model.load_weights('..\/input\/xception-weights\/best_xception_model_weights.h5')\n\n   # model.summary()\n    \n    # model_checkpoint = ModelCheckpoint(\n    #     'model_weights_5.h5', monitor='val_loss', save_best_only=True)\n\n    # c_backs = [model_checkpoint,swa]\n    # c_backs.append( EarlyStopping(monitor='loss', min_delta=0.001, patience=5) )\n\n    model.compile(  optimizer=Adam(lr=1e-3), loss=dice_loss, metrics=[dice_coef])\n\n    history = model.fit_generator(\n                        train_generator,\n                        steps_per_epoch=n_imgs\/\/batch_size,\n                        epochs=epochs,\n                        shuffle=True,\n                        validation_data=(X_test, y_test),\n                        callbacks=snapshot.get_callbacks())\n    \n    plt.figure(figsize=(16,4))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['dice_coef'][1:])\n    plt.plot(history.history['val_dice_coef'][1:])\n    plt.ylabel('dice coefficient')\n    plt.xlabel('epoch')\n    plt.legend(['train','Validation'], loc='upper left')\n\n    plt.title('model Dice Coefficient')\n    plt.savefig('xception_dice.png')\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'][1:])\n    plt.plot(history.history['val_loss'][1:])\n    plt.ylabel('loss value')\n    plt.xlabel('number of epochs')\n    plt.legend(['train','Validation'], loc='upper left')\n    plt.title('model loss')\n    plt.savefig('xception_loss.png')\n    \n    pd.DataFrame(history.history).to_hdf(\"xception_hist.h5\",key=\"history\")","95deef19":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = LeakyReLU(alpha=0.1)(blockInput)\n    x = BatchNormalization()(x)\n    blockInput = BatchNormalization()(blockInput)\n    x = convolution_block(x, num_filters, (3,3))\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    return x","374b80c8":"def UXception(input_shape=(None, None, 3),dropout_rate=0.5):\n\n    backbone = Xception(input_shape=input_shape,weights=None,include_top=False)\n    input = backbone.input\n    start_neurons = 16\n\n    conv4 = backbone.layers[121].output\n    conv4 = LeakyReLU(alpha=0.1)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(dropout_rate)(pool4)\n    \n     # Middle\n    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = LeakyReLU(alpha=0.1)(convm)\n    \n    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(dropout_rate)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n    \n    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    conv3 = backbone.layers[31].output\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(dropout_rate)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    conv2 = backbone.layers[21].output\n    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(0.1)(uconv2)\n    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n    \n    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[11].output\n    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(0.1)(uconv1)\n    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n    \n    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = Dropout(dropout_rate)(uconv0)\n    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = Dropout(dropout_rate\/2)(uconv0)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = Model(input, output_layer)\n    model.name = 'u-xception'\n\n    return model","f5ce371c":"import time\nepochs = 3\nswa = SWA('best_xception_model_weights.h5',epochs - 1)\nsnapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-4)\nstart = time.time()\nkeras_fit_generator(img_rows=256, img_cols=256, regenerate=True,\n                     batch_size=16,epochs = epochs)\n\nend = time.time()","a29c7379":"## Training","e1514ed5":"## Data Augmentation","124d065e":"## Model"}}