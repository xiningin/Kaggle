{"cell_type":{"8542194b":"code","6badf166":"code","9e687df7":"code","7146e236":"code","3d63c569":"code","bbae3009":"code","cc2a14f6":"code","76863d88":"code","582fba5e":"code","0f6fd807":"code","3ca4800c":"code","431ab499":"code","c638cf88":"code","97057ce0":"code","4fe9625d":"code","f34b0066":"code","f2a17d7f":"code","fc709e23":"code","1278b110":"code","b9b6462c":"code","9ee68528":"code","7e12bb76":"code","c83e182f":"code","770fe762":"markdown","202378d9":"markdown","c63a1280":"markdown","7e8ce496":"markdown","303c9ad7":"markdown","ea76bdf5":"markdown","381a73fd":"markdown","1cdaa87b":"markdown","085f4ebe":"markdown","b24e9245":"markdown","e6adfef9":"markdown","4348d837":"markdown","b431691a":"markdown","2907132e":"markdown","62e0187b":"markdown","8a517534":"markdown","4c715c78":"markdown","efb85a42":"markdown","363ce303":"markdown","72d1e390":"markdown","a780cbbf":"markdown"},"source":{"8542194b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6badf166":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport cv2\n\nimport glob","9e687df7":"train_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n","7146e236":"pneumonia_train_images = glob.glob(train_dir+\"\/PNEUMONIA\/*.jpeg\")\nnormal_train_images = glob.glob(train_dir+\"\/NORMAL\/*.jpeg\")","3d63c569":"plt.figure(figsize=(15, 10))\nplt.pie(x=np.array([len(pneumonia_train_images), len(normal_train_images)]), autopct=\"%.1f%%\", explode=[0.2,0], labels=[\"pneumonia\", \"normal\"], pctdistance=0.5)\nplt.title(\"Type of images and their share in train folder\", fontsize=14);","bbae3009":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\n    \nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (220,220))\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()    \nplt.show()","cc2a14f6":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.Canny(img, 80, 100)\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.Canny(img, 80, 100)\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()    \nplt.show()","76863d88":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   zoom_range = 0.2)\nval_datagen = ImageDataGenerator(rescale = 1.\/255.,)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255.,)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, batch_size=20, class_mode='binary', target_size = (220, 220))\nvalidation_generator = val_datagen.flow_from_directory(test_dir, batch_size=20, class_mode = 'binary', target_size=(220, 220))\ntest_generator = test_datagen.flow_from_directory(val_dir,shuffle=False, batch_size=20, class_mode = 'binary', target_size=(220, 220))","582fba5e":"input_shape = (220, 220, 3)","0f6fd807":"# define the model\nbase_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape=input_shape, include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n    \nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n        ","3ca4800c":"model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)\n\nhistory = model.fit(train_generator, validation_data=validation_generator, steps_per_epoch = 100, epochs=20, callbacks=callback)","431ab499":"model.save(\"model1\")","c638cf88":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","97057ce0":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.ylim(0.8, 1)\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.ylim(0, 0.5)\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","4fe9625d":"pred = model.predict(test_generator)","f34b0066":"pred","f2a17d7f":"y_pred = []\nfor prob in pred:\n    if prob >= 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","fc709e23":"y_pred","1278b110":"y_true = test_generator.classes","b9b6462c":"y_true","9ee68528":"cm = confusion_matrix(y_true, y_pred)","7e12bb76":"sn.heatmap(cm, annot=True,cmap=\"Blues\", annot_kws={\"size\": 16})","c83e182f":"print(classification_report(y_true, y_pred))","770fe762":"# Canny edge detection","202378d9":"## Visualize training and validation accuracy and loss\n","c63a1280":"# Import the necessary libraries","7e8ce496":"# Model creation\n## Transfer Learning\n\n- ResNet50 model is used here as base model for transfer learning\n- We have made the layers of the base model non-trainable\n    - This would fix the weights of the layers of the base model\n    - Only the additional layers that we will add on top of the base layer will be trained","303c9ad7":"# Define the paths for training, testing and validation directories","ea76bdf5":"# Create imgae data generators\n- We have rescaled the images by dividing the pixel values by 255\n- To maintain uniform size of the image, we have also configured the images to shape (220, 220)","381a73fd":"**We can see that it is difficult to detect edges in the x-rays with pneumonia whereas the normal images are clear with prominent edges**","1cdaa87b":"**We see that we have an imbalanced dataset. Hence, we will be using image augmentation techniques to compensate for this.**","085f4ebe":"### If you have any suggestions please feel free to comment and if you found this notebook helpful please feel free to upvote","b24e9245":"# Model metrics","e6adfef9":"- Precision is 1 for class 0\n    - This means that for all the images that were predicted to belong to class 0 were predicted correctly\n- Precision 0.89 for class 1\n    - This means that of all the images that the model predicted to belong to class 1, 11% were misclassified as 1, that is False Positive\n","4348d837":"# Predictions","b431691a":"# Our model achieved an accuracy of 94% which is pretty good","2907132e":"**We can see that our model misclassified only one image. The image was supposed to be non-pneumonia(0) but our model predicted it to be pneumonic(1)**","62e0187b":"# Confusion matrix","8a517534":"## Save the model","4c715c78":"# Classification report","efb85a42":"## Train the model","363ce303":"## Define the input shape of the images to be fed into the neural network","72d1e390":"**Since the predictions are in form of probabilities, we convert the probabilities with less than 0.5 to 0 and probabilities more than equal to 0.5 to 1. This would help us in calculation of metrics of the model.**","a780cbbf":"# Visualize the data"}}