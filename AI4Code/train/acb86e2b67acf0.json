{"cell_type":{"03f522dd":"code","b26b62f9":"code","a381bac7":"code","520d93e5":"code","5ce83e08":"code","25f08ee9":"code","4ee75b73":"code","4c4006c5":"code","06f97250":"code","a473a1b2":"code","77f26870":"code","656c5d50":"code","7177db20":"code","4c672f19":"code","a53f69ac":"code","76fc453b":"code","1d38a18b":"code","1d39e407":"code","eb64f9e7":"code","cd6c049c":"code","a37b2cdd":"code","783f4aaf":"code","db12a013":"code","b6ffdbf6":"code","5d7c3ae6":"code","6ca7952f":"code","efbebb23":"code","b2ad3be1":"code","2cac6edc":"code","7574ad0b":"code","71585f50":"code","9cb1b099":"markdown","3d37c950":"markdown","acc4600f":"markdown","7fe0b4ad":"markdown","71e5978b":"markdown","7844ad57":"markdown","4cd3d50e":"markdown","24a8b529":"markdown","268aa9c2":"markdown","202fb090":"markdown","cec367f8":"markdown","0e4c7020":"markdown","a9bf0ced":"markdown","efccd07a":"markdown","7449153c":"markdown","c1794f86":"markdown","989239c1":"markdown","57268ccd":"markdown","b981fcf2":"markdown","0fee6a75":"markdown","f3fa3720":"markdown","72256b01":"markdown","3cab5098":"markdown","8627e3a1":"markdown","777974aa":"markdown","f6da72ad":"markdown","4f91f9bd":"markdown","5b4cc386":"markdown","2e566c21":"markdown","ca0a32db":"markdown","8a1da90c":"markdown"},"source":{"03f522dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#Basic Packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Data Visualization\nimport seaborn as sns # Advance Data Visualization\n%matplotlib inline\n\n#OS packages\nimport os\n\n#Encoding Packages\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n#Scaling Packages\nfrom sklearn import preprocessing\nmm_scaler = preprocessing.MinMaxScaler()\n\n#Multicolinearity VIF\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n#Data Modelling Packages\nfrom sklearn.model_selection import train_test_split\n\nfrom imblearn.over_sampling import RandomOverSampler\nsm = RandomOverSampler(random_state=294,sampling_strategy='not majority')\n\n#Model Packages\nimport lightgbm as lgb\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b26b62f9":"df_Train = pd.read_csv('..\/input\/av-janatahack-healthcare-hackathon-ii\/Data\/train.csv')\ndf_Test = pd.read_csv('..\/input\/av-janatahack-healthcare-hackathon-ii\/Data\/test.csv')","a381bac7":"#To find the head of the Data\ndf_Train.head()","520d93e5":"#Information of the Dataset Datatype\ndf_Train.info()","5ce83e08":"#Information of the Dataset Continuous Values\ndf_Train.describe()","25f08ee9":"#Columns List\ndf_Train.columns","4ee75b73":"#Shape of the Train and Test Data\nprint('Shape of Train Data: ', df_Train.shape)\nprint('Shape of Test Data: ', df_Test.shape)","4c4006c5":"#Null values in the Train Dataset\nprint('Null values in Train Data: \\n', df_Train.isnull().sum())","06f97250":"#Null Values in the Test Dataset\nprint('Null Values in Test Data: \\n', df_Test.isnull().sum())","a473a1b2":"print('Total Count of the Prediction Output Column Stay Variable: \\n', df_Train['Stay'].value_counts())","77f26870":"df_Train.drop_duplicates(keep='first', inplace=True)","656c5d50":"# We will concat both train and test data set\ndf_Train['is_train'] = 1\ndf_Test['is_train'] = 0\n\n#df_Frames = [df_Train,df_Test]\ndf_Total = pd.concat([df_Train, df_Test])","7177db20":"#Null values in the Total Dataset\nprint('Null values in Total Data: \\n', df_Total.isnull().sum())","4c672f19":"#using Forward Fill to fill missing Values\ndf_Total['Bed Grade']=df_Total['Bed Grade'].fillna(method=\"ffill\",axis=0)\ndf_Total['City_Code_Patient']=df_Total['City_Code_Patient'].fillna(method=\"ffill\",axis=0)","a53f69ac":"df_Total['Bill_per_patient'] = df_Total.groupby('patientid')['Admission_Deposit'].transform('sum')","76fc453b":"df_Total.head()","1d38a18b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf_Total['Hospital_code'] = le.fit_transform(df_Total['Hospital_code'])\ndf_Total['Hospital_type_code'] = le.fit_transform(df_Total['Hospital_type_code'])\ndf_Total['City_Code_Hospital'] = le.fit_transform(df_Total['City_Code_Hospital'])\ndf_Total['Hospital_region_code'] = le.fit_transform(df_Total['Hospital_region_code'])\ndf_Total['Available Extra Rooms in Hospital'] = le.fit_transform(df_Total['Available Extra Rooms in Hospital'])\ndf_Total['Department'] = le.fit_transform(df_Total['Department'])\ndf_Total['Ward_Type'] = le.fit_transform(df_Total['Ward_Type'])\ndf_Total['Ward_Facility_Code'] = le.fit_transform(df_Total['Ward_Facility_Code'])\ndf_Total['Bed Grade'] = le.fit_transform(df_Total['Bed Grade'])\n#df_Total['patientid'] = le.fit_transform(df_Total['patientid'])\ndf_Total['City_Code_Patient'] = le.fit_transform(df_Total['City_Code_Patient'])\ndf_Total['Type of Admission'] = le.fit_transform(df_Total['Type of Admission'])\ndf_Total['Severity of Illness'] = le.fit_transform(df_Total['Severity of Illness'])\ndf_Total['Visitors with Patient'] = le.fit_transform(df_Total['Visitors with Patient'])\ndf_Total['Age'] = le.fit_transform(df_Total['Age'])","1d39e407":"df_Total['Admission_Deposit']","eb64f9e7":"df_Total['Admission_Deposit'].describe()","cd6c049c":"from sklearn import preprocessing\nmm_scaler = preprocessing.MinMaxScaler()\n#df_Total[['Admission_Deposit']] = mm_scaler.fit_transform(df_Total[['Admission_Deposit']])","a37b2cdd":"df_Total['Admission_Deposit'].describe()","783f4aaf":"#Un-Merge code\ndf_Train_final = df_Total[df_Total['is_train'] == 1]\ndf_Test_final = df_Total[df_Total['is_train'] == 0]","db12a013":"df_Train_final","b6ffdbf6":"df_Test_final","5d7c3ae6":"df_Train_final.columns","6ca7952f":"x = df_Train_final\nx = x.drop(['case_id'], axis=1)\n#x = x.drop(['patientid'], axis=1)\nx = x.drop(['is_train'], axis=1)\nx = x.drop(['Stay'], axis=1)\ny = df_Train['Stay']\nx_pred = df_Test_final\nx_pred = x_pred.drop(['case_id'], axis=1)\n#x_pred = x_pred.drop(['patientid'], axis=1)\nx_pred = x_pred.drop(['is_train'], axis=1)\nx_pred = x_pred.drop(['Stay'], axis=1)","efbebb23":"import lightgbm as lgb\nlgb_cl = lgb.LGBMClassifier(boosting_type='gbdt', learning_rate=0.1, n_estimators=500, importance_type='gain', objective='multiclass', num_boost_round=100,\n                            num_leaves=300, max_depth=5, \n                            max_bin=60, bagging_faction=0.9, feature_fraction=0.9, subsample_freq=2, scale_pos_weight=2.5, \n                            random_state=1994, n_jobs=-1, silent=False)","b2ad3be1":"#lgb_cl.fit(x_train, y_train, eval_set=[x_test,y_test], verbose=50, eval_metric='auc', early_stopping_rounds=100)\nlgb_cl.fit(x, np.ravel(y))","2cac6edc":"y_pred = lgb_cl.predict(x_pred)","7574ad0b":"y_pred","71585f50":"submission_df = pd.DataFrame({'case_id':df_Test['case_id'], 'Stay':y_pred})\nsubmission_df.to_csv('Sample Submission LGB v01.csv', index=False)","9cb1b099":"# Data Modelling","3d37c950":"## Boosting Algorithm","acc4600f":"# Basic Feature Engineering","7fe0b4ad":"Missing Values in \"Bed Grade\" and \"City_Code_Patient\" columns.","71e5978b":"### LightGBM Model","7844ad57":"## [Janatahack: Healthcare Analytics II](https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-healthcare-analytics-ii)","4cd3d50e":"## Feature Engineering","24a8b529":"Recent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, patient length of stay is one critical parameter to observe and predict if one wants to improve the efficiency of the healthcare management in a hospital. \n\nThis parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff\/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.\n\nSuppose you have been hired as Data Scientist of HealthMan \u2013 a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.\nThe task is to accurately predict the Length of Stay for each patient on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days.","268aa9c2":"Do share your comments on how to improvise the model","202fb090":"## Assumptions of the Predictor Variables","cec367f8":"Column - Description\n\ncase_id - Case_ID registered in Hospital\n\nHospital_code - Unique code for the Hospital\n\nHospital_type_code - Unique code for the type of Hospital\n\nCity_Code_Hospital - City Code of the Hospital\n\nHospital_region_code - Region Code of the Hospital\n\nAvailable Extra Rooms in Hospital - Number of Extra rooms available in the Hospital\n\nDepartment - Department overlooking the case\n\nWard_Type -\tCode for the Ward type\n\nWard_Facility_Code - Code for the Ward Facility\n\nBed Grade -\tCondition of Bed in the Ward\n\npatientid -\tUnique Patient Id\n\nCity_Code_Patient -\tCity Code for the patient\n\nType of Admission -\tAdmission Type registered by the Hospital\n\nSeverity of Illness - Severity of the illness recorded at the time of admission\n\nVisitors with Patient -\tNumber of Visitors with the patient\n\nAge - Age of the patient\n\nAdmission_Deposit -\tDeposit at the Admission Time\n\nStay - Stay Days by the patient","0e4c7020":"## Problem Statement","a9bf0ced":"NO Duplicate ROWS","efccd07a":"### For Tree Based Algorithm use Label Encoding","7449153c":"## Data","c1794f86":"# Exploratory Data Analysis","989239c1":"## For Scaling the Columns","57268ccd":"## Joining the Train and Test Data for Encoding and Filling the Missing Values","b981fcf2":"## Split the Data to x and y variable","0fee6a75":"## Un Merge the Train and Test Data after Feature Engineering","f3fa3720":"# Janatahack: Healthcare Analytics II","72256b01":"## Remove Duplicate Rows","3cab5098":"Target Variable\n\nStay - Highly Imbalanced. Need to use SMOTE to balance it\n\n\nPredictor Variable\n\nHospital Code - Highly Imbalanced and Might affect the model\n\nHospital Type Code - Imbalanced\n\nCity Code Hospital - Imbalanced\n\nAvailable Extra Rooms - Need to Balance the Available Extra Rooms as its Skewed Positive\n\nDepartment - Highly Imbalanced\n\nWard Type Count - highly imbalanced\n\nPatient ID - lot of Unique Values - Might need to drop it\n\nCity Code Patient - highly imbalance\n\nSeverity of Illness Variable - imbalanced\n\nVisitors with Patient - imbalanced\n\nAge - Imbalanced can be binned even more\n\nAdmission Deposit - Continous Need to remove the outliers or Scale the Values","8627e3a1":"The healthcare sector has long been an early adopter of and benefited greatly from technological advances. These days, machine learning plays a key role in many health-related realms, including the development of new medical procedures, the handling of patient data, staff management & more.\n\nThis weekend we invite you to participate in another Janatahack with the theme of healthcare analytics. Stay tuned for the problem statement and datasets this Friday and get a chance to work on a real healthcare case study along with 250 AV points at stake.","777974aa":"## Loading from Kaggle Input Data","f6da72ad":"## Fill missing Values","4f91f9bd":"# Load the Packages","5b4cc386":"## Encoding of the Columns","2e566c21":"Public Score of 42.35","ca0a32db":"Evaluation Metric\n\nThe evaluation metric for this hackathon is 100*Accuracy Score.","8a1da90c":"# Load the Datasets"}}