{"cell_type":{"e2b4b126":"code","1e63e419":"code","34fa5bbc":"code","24818d41":"code","698153d6":"code","71f7bf2f":"code","00be6b24":"code","f8a523ed":"code","0affed39":"code","6a58e492":"code","1ce50857":"code","7a8ae48a":"code","b7fba5a2":"code","c694bdd8":"code","35b47b0b":"code","bf80f37c":"code","26f924fa":"code","fdebbd41":"code","2f8e7d12":"code","b2e2c11b":"code","4371856e":"code","3f183071":"code","8724e0d4":"code","f7157ba3":"code","989effd8":"code","40b474ec":"code","52fd4b03":"code","5c13c74f":"code","d789a983":"code","1a713a44":"markdown","cf39ff17":"markdown","68fcc5bd":"markdown","a0dab09f":"markdown","a49b2f87":"markdown","6b16c78f":"markdown","4a104e80":"markdown"},"source":{"e2b4b126":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e63e419":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","34fa5bbc":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","24818d41":"print(train_data.shape)\nprint(test_data.shape)","698153d6":"train_data.head(10)","71f7bf2f":"X = train_data.drop([\"label\"],axis = 1).values\nY = train_data[\"label\"].values","00be6b24":"plt.figure(figsize = (12,6))\nsns.countplot(Y)","f8a523ed":"plt.imshow(X[0].reshape([28,28]))","0affed39":"plt.imshow(X[14].reshape([28,28]))","6a58e492":"X = X.reshape([42000,28,28,1])\nY = Y.reshape([42000,1])","1ce50857":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY = to_categorical(Y, num_classes = 10)","7a8ae48a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 14)","b7fba5a2":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","c694bdd8":"x_train = x_train\/255\nx_test = x_test\/255","35b47b0b":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(128, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(128, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","bf80f37c":"model.summary()","26f924fa":"from keras.optimizers import Adam\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer,\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","fdebbd41":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.6, \n                                            min_lr=0.00001)","2f8e7d12":"batch_size = 64\nepochs = 30","b2e2c11b":"train_datagen = ImageDataGenerator( \n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,\n        shear_range = 0.1,\n        horizontal_flip=False,  \n        vertical_flip=False\n        )\ntrain_datagen.fit(x_train)","4371856e":"history = model.fit(\n            train_datagen.flow(x_train,y_train,batch_size = batch_size),\n            validation_data = (x_test,y_test),\n            batch_size = batch_size,\n            steps_per_epoch = x_train.shape[0]\/\/batch_size,\n            epochs = epochs,\n            verbose = 1,\n            callbacks=[learning_rate_reduction]\n            )","3f183071":"model.evaluate(x_test,y_test)","8724e0d4":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure()\nplt.plot(acc,color = 'green',label = 'Training Acuracy')\nplt.plot(val_acc,color = 'red',label = 'Validation Accuracy')\nplt.legend()","f7157ba3":"plt.figure()\nplt.plot(loss,color = 'green',label = 'Training Loss')\nplt.plot(val_loss,color = 'red',label = 'Validation Loss')\nplt.legend()","989effd8":"data = test_data.values\ndata = data.reshape([28000,28,28,1])\nprint(data.shape)\ndata = data\/255","40b474ec":"test_pred = model.predict(data)\ntest_pred = np.argmax(test_pred,axis=1)\nprint(test_pred.shape)","52fd4b03":"sample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsample_submission","5c13c74f":"index = sample_submission.ImageId\ndata = {'ImageId' : index,'Label': test_pred}\ndf = pd.DataFrame(data)\ndf.head","d789a983":"df.to_csv('submission2.csv', index=False)","1a713a44":"# Data Augmentation","cf39ff17":"# Compiling the model (Optimizer=Adam)","68fcc5bd":"# Defining the CNN architecture","a0dab09f":"# Learning Rate Reduction","a49b2f87":"# Evaluation and Accuracy,Loss plots","6b16c78f":"# Fitting the model","4a104e80":"# Reading and preparing data"}}