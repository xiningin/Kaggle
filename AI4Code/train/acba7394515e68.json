{"cell_type":{"907cdb99":"code","0c064eba":"code","36eca16e":"code","0040b820":"code","69170b20":"code","2bf38d79":"code","278aab34":"code","cbcb58dd":"code","9b6f42a8":"code","1d1df94c":"code","22209655":"code","af8a71de":"code","117ff85e":"code","b8a80cb5":"code","e1fa0d02":"code","67dd117a":"code","4993691a":"code","4468bb26":"code","e0a5e106":"code","cea011ce":"code","37192b9e":"code","e50e258e":"code","e68e7fc1":"code","4f38b78b":"code","57a210b5":"code","f9e9216e":"code","5b0c63a6":"code","62aa726a":"markdown","b53b4785":"markdown","eb465fa2":"markdown","82f04516":"markdown","3d05312d":"markdown","52f3353b":"markdown","b654b2eb":"markdown","129a48d6":"markdown","a2ebb1a3":"markdown","fcd73799":"markdown","054251db":"markdown","7dac48d0":"markdown","ce90b4d0":"markdown"},"source":{"907cdb99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0c064eba":"train= pd.read_csv(\"..\/input\/titanic\/train.csv\")#, index_col= 'PassengerId')\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")#, index_col= 'PassengerId')\nprint(train.info())\nprint(train.head(5))\nprint(train.tail())\nprint(test.head())\n\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['Survived'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))\n\nall_data.head()\nntrain = len(train)","36eca16e":"train.hist(bins=50, figsize=(30,20))\n\ntest.hist(bins=50, figsize=(30,20))","0040b820":"train.head()\n\n#traindata[traindata.Age <=3]\ncolormap = np.array(['r', 'g'])\nplt.scatter(x = train.SibSp, y = train.Age, c=colormap[train.Survived])","69170b20":"#Survival by sex\nprint('**********Survival by Sex**************')\nprint(train.groupby('Sex')['Survived'].agg(['count', 'sum']).rename(columns={'Passengers':'Survived'})) \nprint(train.groupby('Sex')['Survived'].sum()*100\/ train.groupby('Sex')['Survived'].count()) # % of each sex survived\n\n#Survival by class\nprint('**********Survival by Class**************')\nprint(train.groupby('Pclass')['Survived'].agg(['count', 'sum']).rename(columns={'Passengers':'Survived'})) \nprint(train.groupby('Pclass')['Survived'].sum()*100\/train.groupby('Pclass')['Survived'].count()) # % of each sex survived\n\n#Survival by parch\nprint('**********Survival by Parch**************')\nprint(train.groupby('Parch')['Survived'].agg(['count', 'sum']))\nprint(train.groupby('Parch')['Survived'].sum()*100\/train.groupby('Parch')['Survived'].count()) # % of each sex survived\n\n#avg fare\nprint('**********Avg Fare by sex, class**************')\nprint(train.groupby(['Pclass'])['Fare'].agg(['mean', 'median']))\n\n#Unique values in Embarked column\nprint('**********Embarked column**************')\nprint(train['Embarked'].unique())\n","2bf38d79":"#Survival by class and gender\nprint(train.groupby(['Pclass', 'Sex'])['Survived'].agg(['count', 'sum']).rename(columns={'Passengers':'Survived'})) \ntrain.groupby(['Pclass', 'Sex'])['Survived'].sum()*100\/train.groupby(['Pclass', 'Sex'])['Survived'].count() # % of each sex survived\n#Survival varies by Gender and Class of passenger","278aab34":"print('******Train data missings*****')\nprint('There are',train.isnull().any().sum(), 'columns with missing values')\nprint('The columns are',train.columns[train.isnull().any()].values)\nprint('Number of missing values in each column are', (train.isnull().sum()\/len(train)).sort_values(ascending = False).head(3))\n# print(traindata[traindata.isnull().any(axis=1)].head())\n\nprint('******Test data missings*****')\nprint('There are',test.isnull().any().sum(), 'columns with missing values')\nprint('The columns are',test.columns[test.isnull().any()].values)\nprint('Number of missing values in each column are', (test.isnull().sum()\/len(train)).sort_values(ascending = False).head(3))","cbcb58dd":"#cabin column in traindata has ~78% missing values. Drop the cable column from train and test data\ntrain.drop('Cabin', axis=1, inplace=True)\ntest.drop('Cabin', axis=1, inplace=True)\nall_data.drop('Cabin', axis=1, inplace=True)\n\n#Imputing age column\nprint(all_data.groupby(['Sex', 'Pclass'])['Age'].agg(['mean', 'min', 'max', 'median']))\nage_impute = all_data.groupby(['Sex', 'Pclass'])['Age'].median().reset_index()\nprint(age_impute)\nall_data['Age']= all_data.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n\n#Imputing Embarked column\nall_data.loc[all_data['Embarked'].isnull(),'Embarked'] = all_data['Embarked'].value_counts().index[0]\n\nall_data.loc[all_data.isnull().any(axis=1), 'Fare'] = 8\nall_data.head()\nall_data.isnull().any().sum()","9b6f42a8":"all_data['Family_size']= all_data['SibSp']+all_data['Parch']+1\nall_data['Fare_pp']= all_data['Fare']\/all_data['Family_size']\nall_data['Title'] = all_data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\nprint(all_data.groupby('Title').Age.count())\nfare = all_data.groupby(['Pclass','Parch','SibSp']).Fare.median()[3][0][0]\n\nfor i in range(0, len(all_data)):\n    if all_data.Title[i] in ('Mlle', 'Mme', 'Dona', 'Ms', 'Lady', 'the Countess'): \n        all_data.Title[i] = 'Miss'\n    elif all_data.Title[i] in ('Jonkheer', 'Don', 'Sir', 'Don', 'Rev'): \n        all_data.Title[i] = 'Mr'","1d1df94c":"#label encoder\nfrom sklearn.preprocessing import LabelEncoder\nlbl= LabelEncoder()\nlbl.fit(list(all_data['Title'].values)) \nall_data['Title'] = lbl.transform(list(all_data['Title'].values))\n\nlbl.fit(list(all_data['Embarked'].values)) \nall_data['Embarked'] = lbl.transform(list(all_data['Embarked'].values))\n\nlbl.fit(list(all_data['Sex'].values)) \nall_data['Sex'] = lbl.transform(list(all_data['Sex'].values))\n\nprint(all_data.head())","22209655":"# encoding using get_dummies\n# finaldata['Sex'] = pd.get_dummies(finaldata['Sex'], drop_first = True)\n# finaldata[['Embarked_C', 'Embarked_Q', 'Embarked_S']] = pd.get_dummies(finaldata['Embarked'], columns=\"Embarked\", prefix=\"Embarked\")\n# finaldata.drop(['Ticket', 'Survived', 'Name', 'Embarked'], axis=1, inplace=True)\n# finaldata.head()\n    #repeating same on test data\n# testdata['Sex'] = pd.get_dummies(testdata['Sex'], drop_first = True)\n# testdata[['Embarked_C', 'Embarked_Q', 'Embarked_S']] = pd.get_dummies(testdata['Embarked'], columns=\"Embarked\", prefix=\"Embarked\")\n# testdata.drop(['Ticket','Name', 'Embarked'], axis=1, inplace=True)\n# testdata.head()","af8a71de":"from sklearn.preprocessing import StandardScaler\n# from sklearn.preprocessing import MinMaxScaler\nscaler = StandardScaler()\n\nall_data[['Age', 'Fare_pp']] = pd.DataFrame(data=scaler.fit_transform(all_data[['Age', 'Fare']]), columns=['Age', 'Fare'])","117ff85e":"#convert Pclass to categorical object\nall_data['Pclass'] = pd.Categorical(all_data.Pclass, ordered=True)\nall_data.info()\n\nall_data['Sex'] = pd.Categorical(all_data.Sex, ordered=True)\nall_data.info()\n\nall_data['Title'] = pd.Categorical(all_data.Title, ordered=True)\nall_data.info()","b8a80cb5":"#seperating data\nall_data.drop(['Ticket','Name', 'Embarked','Fare'], axis=1, inplace=True)\n#seperating data\n# all_data.drop(['SibSp','Parch'], axis=1, inplace=True)\ntraindata = all_data[:ntrain]\ntestdata = all_data[ntrain:]\ntraindata.set_index('PassengerId', inplace=True)\n\ntarget = train.set_index('PassengerId')['Survived']\nfinaldata=traindata[:]\ntraindata['Survival'] = target\ntestdata.set_index('PassengerId', inplace=True)\n\nall_data.info()\nfinaldata.info()","e1fa0d02":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import model_selection\n\n# implementing train-test-split\nX_train, X_test, y_train, y_test = train_test_split(finaldata, target, test_size=0.30, random_state=0)\n\n#Stratified Split\n# split = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n# for train_idex, test_index in split.split(traindata, traindata(['Survival', 'Sex', 'Pclass'])):\n#     train_set = traindata.loc[train_idex]\n#     test_set = traindata.loc[test_idex]\n\n\ntrain_check = X_train[:]\ntrain_check['survived'] = y_train\ntrain_check.head()\n\n#checking the distribution of the survival class in train data and x_train are distributed in the same proportion\n#check = ['Sex', 'Pclass']\n# for i in check:\n#     print(traindata.groupby([i, 'Survived'])['Age'].count())\n#     print(traindata.groupby([i, 'Survived'])['Age'].count()\/traindata.groupby(i)['Age'].count())\n#     print(train_check.groupby([i, 'survived'])['Age'].count())\n#     print(train_check.groupby([i, 'survived'])['Age'].count()\/train_check.groupby(i)['Age'].count())","67dd117a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\n\nlg = LogisticRegression()\nclf = LogisticRegression().fit(X_train, y_train)\nprint(clf.score(X_train, y_train))\nprint(clf.predict(X_test))\n\nimportance = clf.coef_[0]\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\nprint(np.round(clf.coef_, decimals=2) >0)\n\n    \nclf.predict_proba(X_test)[:, 1]\nclf.score(X_test, y_test)\n\n# Accuracy \naccuracy_lg = accuracy_score(y_test, clf.predict(X_test))\nprint('accuracy of logistic regression',accuracy_lg)\nlg_probs = clf.predict_proba(X_test)[:, 1]\n\nlg_auc = roc_auc_score(y_test, lg_probs)\n# summarize scores\nprint('Random Forest: ROC AUC=%.3f' % (lg_auc))\n# calculate roc curves\nlg_fpr, lg_tpr, _ = roc_curve(y_test, lg_probs)\n# plot the roc curve for the model\nplt.plot(lg_fpr, lg_tpr, marker='.', label='logistic regression')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","4993691a":"# creating the data set to check the errors\nerror_check = X_test[:]\nerror_check['y_test'] = y_test\nerror_check['predicted'] = clf.predict(X_test)\nerror_check['proba'] = clf.predict_proba(X_test)[:, 1]\nerror_check.head()\n\nerror_check.query('y_test != predicted')\nerror_check.query('y_test == predicted')\n\nprint(error_check.groupby(['Sex','y_test', 'predicted'])['Age'].count())\nprint(error_check.groupby(['Pclass', 'y_test', 'predicted'])['Age'].count())\n\nprint(error_check.groupby(['Pclass', 'Sex', 'y_test', 'predicted'])['Age'].count())\nprint(error_check.groupby('Sex')['Age'].count())\n\n# Wrong prediction groups\n# sex=0(male) and predicted = 1 and actual = 0\n# sex=1(female)  and predicted = 0 and actual = 1\n# class = 3 predicted = 0 and actual = 1                                                     \n#error_check.query('Pclass == 3 and predicted == 0 and y_test != predicted')","4468bb26":"from sklearn.model_selection import cross_val_score\n\n# scores = cross_val_score(lg, X_train, y_train, cv=5)\nscores = cross_val_score(lg, finaldata, target, cv=10)\nprint('Cross-Validation Accuracy Scores', scores)\nprint(scores.mean())\n\n\nfrom sklearn.model_selection import cross_val_predict\n# y_pred = cross_val_predict(lg, X_train, y_train, cv=5)\ny_pred = cross_val_predict(lg, finaldata, target, cv=5)\ncrossval_proba = cross_val_predict(lg, finaldata, target, cv=5, method='predict_proba')[:,1] \n\n# Accuracy \naccuracy_cv = accuracy_score(target, y_pred)\nprint('accuracy of cross validation for logistic regression',accuracy_cv)\n\ncv_auc = roc_auc_score(target, crossval_proba)\n# summarize scores\nprint('Random Forest: ROC AUC=%.3f' % (cv_auc))\n# calculate roc curves\ncv_fpr, cv_tpr, _ = roc_curve(target, crossval_proba)\n# plot the roc curve for the model\nplt.plot(cv_fpr, cv_tpr, marker='.', label='logistic cv regression')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","e0a5e106":"from sklearn.ensemble import RandomForestClassifier\nrf_class = RandomForestClassifier(oob_score=True, random_state=0,  n_estimators=8, max_depth=5,\n                                  max_leaf_nodes=10, min_samples_leaf=4, min_samples_split=4)\nrf_class.fit(X_train, y_train)\nprint('Oob score of random forest classifier is:', rf_class.oob_score_)\n\naccuracy_rf = accuracy_score(y_test, rf_class.predict(X_test))\nprint('accuracy of random forest', accuracy_rf)\n\nrf_probs = rf_class.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nrf_probs = rf_probs[:, 1]\n# calculate scores\nrf_auc = roc_auc_score(y_test, rf_probs)\n# summarize scores\nprint('Random Forest: ROC AUC=%.3f' % (rf_auc))\n# calculate roc curves\nrf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n# plot the roc curve for the model\nplt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n","cea011ce":"# implementing Grid search\nparam_grid = [{'n_estimators': np.arange(4,20,2), 'max_features': [3,4,5,6,7,8,9]}]\ngs_class = RandomForestClassifier(oob_score=True, random_state=20)\ngrid_search = model_selection.GridSearchCV(gs_class, param_grid, cv=5, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)\n\ngrid_search.best_params_\ngs_bestmodel = grid_search.best_estimator_\ngs_predict = gs_bestmodel.predict(X_test)\n\nprint('Oob score of random forest classifier with grid search is:', gs_bestmodel.oob_score_)\n\ncvres=grid_search.cv_results_\nprint(cvres[\"mean_test_score\"])","37192b9e":"accuracy_gs = accuracy_score(y_test, gs_predict)\nprint('accuracy of grid search random forest', accuracy_gs)\n\ngs_probs = gs_bestmodel.predict_proba(X_test)\n# keep probabilities for the positive outcome only\ngs_probs = gs_probs[:, 1]\n# calculate scores\ngs_auc = roc_auc_score(y_test, gs_probs)\n# summarize scores\nprint('Random Forest: ROC AUC=%.3f' % (gs_auc))\n# calculate roc curves\ngs_fpr, gs_tpr, _ = roc_curve(y_test, gs_probs)\n# plot the roc curve for the model\nplt.plot(gs_fpr, gs_tpr, marker='.', label='Random Forest')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","e50e258e":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb_class = RandomForestClassifier(random_state=42,  n_estimators=12, max_depth=4)\ngb_class.fit(X_train, y_train)\nprint('Oob score of Gradient Boosting classifier is:', rf_class.oob_score_)\n\naccuracy_gb = accuracy_score(y_test, gb_class.predict(X_test))\nprint('accuracy of Gradient Boosting', accuracy_rf)\n\n# keep probabilities for the positive outcome only\ngb_probs = gb_class.predict_proba(X_test)[:,1]\n# calculate scores\ngb_auc = roc_auc_score(y_test, gb_probs)\n# summarize scores\nprint('Gradient Boosting: ROC AUC=%.3f' % (gb_auc))\n# calculate roc curves\ngb_fpr, gb_tpr, _ = roc_curve(y_test, gb_probs)\n# plot the roc curve for the model\nplt.plot(gb_fpr, gb_tpr, marker='.', label='Gradient Boosting')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n","e68e7fc1":"#from sklearn.ensemble import VotingClassifer\n#Logistic regression\nlg = LogisticRegression()\nclf_p = clf.predict(X_test)    \nclf_proba = clf.predict_proba(X_test)[:, 1]\n\n#random forest classifier\nrf_class.fit(X_train, y_train)\nprint('Oob score of voting classifier is:', rf_class.oob_score_)\naccuracy_rf = accuracy_score(y_test, rf_class.predict(X_test))\nprint('accuracy of random forest', accuracy_rf)\nrf_probs = rf_class.predict_proba(X_test)[:,1]\nrf_p = rf_class.predict(X_test)\n\n# Random forst with grid search\ngs_probs = gs_bestmodel.predict_proba(X_test)[:, 1]\ngs_p = gs_bestmodel.predict(X_test)\n\n# Gradient Boosting \ngb_probs = gb_class.predict_proba(X_test)[:,1]\ngb_p = gb_class.predict(X_test)\n\n# Combining 3 probabilities into a single dataframe\nprob_val = pd.DataFrame(data=[clf_proba, rf_probs, gs_probs, gb_probs, clf_p,rf_p,gs_p, gb_p]).T\nprob_val.columns=['clf_proba', 'rf_probs', 'gs_probs', 'gb_probs', 'clf_p','rf_p','gs_p', 'gb_p']\nprint(prob_val)","4f38b78b":"# Implementing soft voting and hard voting manually\ndef voting_clf(df):\n    hard_voting=[]\n    soft_voting=[]\n    hard_voting_proba=[]\n    soft_voting_proba=[]\n    probtest2 = pd.DataFrame(columns=['SoftVoting', 'HardVoting', 'hard_voting_proba', 'soft_voting_proba'])\n    print(probtest2)\n    i=0\n    for i in range(0, len(df)):\n        hard_voting_proba.append((df.clf_proba[i]+df.rf_probs[i]+df.gs_probs[i]+df.gb_probs[i])\/4)\n        soft_voting_proba.append((df.clf_p[i]+df.rf_p[i]+df.gs_p[i]+df.gb_p[i])\/4)\n        \n        hard_voting.append(round((df.clf_proba[i]+df.rf_probs[i]+df.gs_probs[i]+df.gb_probs[i])\/4))\n        soft_voting.append(round((df.clf_p[i]+df.rf_p[i]+df.gs_p[i]+df.gb_p[i])\/4))\n\n    probtest2['HardVoting'] = pd.Series(hard_voting)\n    probtest2['SoftVoting'] = pd.Series(soft_voting)\n    probtest2['hard_voting_proba'] = pd.Series(hard_voting_proba)\n    probtest2['soft_voting_proba'] = pd.Series(soft_voting_proba)\n    \n    return probtest2\n\n\nprobval2 = voting_clf(prob_val)\n\nprobval2.query('SoftVoting != HardVoting')","57a210b5":"accuracy_HV= accuracy_score(y_test, probval2['HardVoting'])\nprint('accuracy of HardVoting', accuracy_HV)\n\naccuracy_SV= accuracy_score(y_test, probval2['SoftVoting'])\nprint('accuracy of SoftVoting', accuracy_SV)\n\nAUC_HV = roc_auc_score(y_test, probval2['hard_voting_proba'])\nprint('Hard voting AUC: ROC AUC=%.3f' % (AUC_HV))\n\nAUC_SV = roc_auc_score(y_test, probval2['soft_voting_proba'])\nprint('Soft voting AUC: ROC AUC=%.3f' % (AUC_SV))\n\n# calculate roc curves for soft voting\nsv_fpr, sv_tpr, _ = roc_curve(y_test, probval2['SoftVoting'])\n# plot the roc curve for the model\nplt.plot(sv_fpr, sv_tpr, marker='.', label='SoftVoting')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n\n\n# calculate roc curves for hard voting\nhv_fpr, hv_tpr, _ = roc_curve(y_test, probval2['HardVoting'])\n# plot the roc curve for the model\nplt.plot(hv_fpr, hv_tpr, marker='.', label='HardVoting')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","f9e9216e":"testdata.head()\n# testdata.set_index('PassengerId', inplace=True)\n# testdata.head()\n\n#predicting using logistic regression model\ntclf_p = clf.predict(testdata)    \ntclf_proba = clf.predict_proba(testdata)[:, 1]\n\n#predicting using random forest model\ntrf_probs = rf_class.predict_proba(testdata)[:,1]\ntrf_p = rf_class.predict(testdata)\n\n#predicting using the best model in grid search\ntgs_probs = gs_bestmodel.predict_proba(testdata)[:,1]\ntgs_p = gs_bestmodel.predict(testdata)\n\n\n#predicting using gradient Boosting\ntgb_probs = gb_class.predict_proba(testdata)[:,1]\ntgb_p = gb_class.predict(testdata)\n\n\nprob_test = pd.DataFrame(data=[tclf_proba, trf_probs, tgs_probs, tgb_probs, tclf_p, trf_p, tgs_p, tgb_p]).T\nprob_test.columns=['clf_proba', 'rf_probs', 'gs_probs', 'gb_probs', 'clf_p','rf_p','gs_p','gb_p']\nprint(prob_test)\n\nprob_test2 = voting_clf(prob_test)\n\nprob_test2.head(25)\n\nprob_test2.info()","5b0c63a6":"  \nsubmission_hv = pd.DataFrame(columns = ['PassengerId', 'Survived'])\nsubmission_hv['Survived'] = prob_test2['HardVoting']\nsubmission_hv['Survived'] = submission_hv['Survived'].astype('int64')\nsubmission_hv['PassengerId'] = testdata.index\nprint(submission_hv.head())\nsubmission_hv.to_csv('submission_HardVoting.csv', index=False)\n\n\nsubmission_sv = pd.DataFrame(columns = ['PassengerId', 'Survived'])\nsubmission_sv['Survived'] = prob_test2['SoftVoting']\nsubmission_sv['Survived'] = submission_sv['Survived'].astype('int64')\nsubmission_sv['PassengerId'] = testdata.index\nprint(submission_sv.head())\nsubmission_sv.to_csv('submission_SoftVoting.csv', index=False)","62aa726a":"**Survival varies by gender**","b53b4785":"**Logistic Regression**","eb465fa2":"error checking","82f04516":"**Charts**","3d05312d":"**Imputing Missing values**","52f3353b":"Encoding using get_dummies","b654b2eb":"**Missing values**","129a48d6":"Implementing Grid search","a2ebb1a3":"Cross Validation for Logistic Regression","fcd73799":"Random Forest","054251db":"Voting classifier","7dac48d0":"XGBoost classifier","ce90b4d0":"Adding new features"}}