{"cell_type":{"051fa29b":"code","eee30153":"code","6818d772":"code","ccc8ed57":"code","26587ebd":"code","134dc12c":"code","d993ddce":"code","13bb747a":"code","008492f9":"code","2054e9e8":"code","cf954ac5":"code","01659a58":"code","68fc094b":"code","4758b446":"code","adf7aa7a":"code","37f1e5d2":"code","cb8dedef":"code","51e7a596":"code","efafd1ce":"code","e76a09c4":"code","755f1914":"code","19361a25":"code","f65f1695":"code","0e7e54e9":"code","36887b79":"code","090b54a0":"code","be4eb829":"code","59a53863":"code","68b3ad97":"markdown","6882e90a":"markdown","b760a611":"markdown","7c0123ad":"markdown","aef10f3b":"markdown","0486d5f3":"markdown","74241faf":"markdown","dd43822e":"markdown","83cbcbaa":"markdown","d4ab51d6":"markdown"},"source":{"051fa29b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport pandas_profiling as pp\nfrom scipy.stats import norm\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\npd.set_option('display.max_columns', None)\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eee30153":"folder_loc = '\/kaggle\/input\/sqa-dataset\/dataset\/' #changes \nquality_data_loc = 'quality_attributes' #changes\n#files = glob.glob(folder_loc+'*.csv')\nfiles = []\n#fixed_folders = ['\/kaggle\/input\/sqa-dataset\/quality_attributes\/1 spring-framework', '\/kaggle\/input\/sqa-dataset\/quality_attributes\/2 junit-5' ]\nfor dirname, _, filenames in os.walk(folder_loc+quality_data_loc):\n    #print(dirname)\n    #if dirname in fixed_folders:\n    #print (str(len(files))  + dirname)\n    for filename in filenames:\n            #if(filename == '2020-7.csv'):#latest version\n        files.append(os.path.join(dirname, filename))\n\n#files.pop(0)\n#files = files[3:] # remove first 3 elments \nfiles\nlen(files)","6818d772":"data = pd.concat([pd.read_csv(fp).assign(filename=os.path.basename(fp).split('.')[0], projectname=os.path.dirname(fp).split('\/')[-1]    ) for fp in files])\n\ndata","ccc8ed57":"professional_repo = ['1 spring-framework', '2 junit-5', '3 kafka-trunk', '4 lucene-solr-master', '8 selenium-trunk']\nopen_source_repo = ['5 dropwizard-master', '6 checkstyle-master', '7 hadoop-trunk', '9 skywalking-master', '10 Signal-Android-master']\n\nlow_size_repo = [ '2 junit-5', '3 kafka-trunk', '5 dropwizard-master', '6 checkstyle-master', '8 selenium-trunk']\nhigh_size_repo = ['1 spring-framework',  '4 lucene-solr-master',  '7 hadoop-trunk', '9 skywalking-master', '10 Signal-Android-master']\n\nlow_age_repo = [ '2 junit-5', '3 kafka-trunk' , '5 dropwizard-master',  '9 skywalking-master', '10 Signal-Android-master' ]\nhigh_age_repo = ['1 spring-framework', '4 lucene-solr-master', '6 checkstyle-master', '7 hadoop-trunk', '8 selenium-trunk']\n\n# create a list of our conditions\ncondition_type1 = [\n    (data['projectname'].isin(professional_repo)),\n    (data['projectname'].isin(open_source_repo))\n    ]\n\ncondition_type2 = [\n    (data['projectname'].isin(low_size_repo)),\n    (data['projectname'].isin(high_size_repo))\n    ]\n\ncondition_type3 = [\n    (data['projectname'].isin(low_age_repo)),\n    (data['projectname'].isin(high_age_repo))\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues_type_1 = ['Professional', 'Open-source']\nvalues_type_2 = ['Low Volume Repository', 'High Volume Repository']\nvalues_type_3 = ['Age < 10 Years', 'Age > 10 Years']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndata['Type 1'] = np.select(condition_type1, values_type_1)\ndata['Type 2'] = np.select(condition_type2, values_type_2)\ndata['Type 3'] = np.select(condition_type3, values_type_3)\n\n# display updated DataFrame\ndata.head(5)","26587ebd":"dataset_detail = pd.read_csv(folder_loc+'attribute-details.csv')\ndataset_detail.head(50)","134dc12c":"def codes_detail(codes, desc_show=False):\n    idxs = dataset_detail.index[ dataset_detail['Code'].isin(codes) ]\n    print ('---------------------------------------')\n    i=1\n    for idx in idxs:\n        print (str(i) + '. '+ dataset_detail.at[idx,'Code']+ '\\t: '+ dataset_detail.at[idx,'Full name'])\n        if desc_show:\n            print(' - '+ dataset_detail.at[idx,'Description'])\n        i = i + 1\n    print ('---------------------------------------')\ndef code_detail(code):\n    idx = dataset_detail.index[ dataset_detail['Code'] == code ]\n    print ('---------------------------------------')\n    print ('Code: '+ dataset_detail.at[idx[0],'Code'])\n    print ('---------------------------------------')\n    print ('Category: '+ dataset_detail.at[idx[0],'Category'])\n    print ('Short Name: '+ dataset_detail.at[idx[0],'Short name'])\n    print ('Full Name: '+ dataset_detail.at[idx[0],'Full name'])\n    print ('Description: '+ dataset_detail.at[idx[0],'Description'])\n    print ('---------------------------------------')\n    \ncode_detail('CBO')\ncodes_detail(['LOC.2', 'LOC'])","d993ddce":"class_attributes = dataset_detail[ dataset_detail['Category'].str.contains ('Class')==True ]\nclass_attributes.head(100)","13bb747a":"data_classes = data[~data['QualifiedName'].str.contains(\"<Package>|<Method>|<Field>\")]\nprint(class_attributes['Code'].tolist())\ndata_classes = data_classes[['QualifiedName', 'Name', 'Type 1', 'Type 2','Type 3', 'Coupling', 'Lack of Cohesion', 'Complexity', 'Size', 'LOC', 'WMC', 'DIT', 'NOC', 'CBO', 'RFC', 'SRFC', 'LCOM', 'LCAM', 'NOF', 'NOM', 'NOSF', 'NOSM', 'SI', 'CMLOC', 'NORM', 'LTCC', 'ATFD', 'filename', 'projectname'  ]]\n#classes_row = classes_row[class_attributes['Code'].tolist()]\ndata_classes = data_classes.dropna()\ndata_classes","008492f9":"# change_values(df, 'Complexity', 'low', 'lw')\ndef change_values(df, column_name, from_str, to_str):\n    row = (df[column_name].str.contains(from_str))\n    df.loc[row, column_name] = to_str\n    return df\n\ndata_classes = change_values(data_classes, 'Complexity', 'low', 'low')    \ndata_classes = change_values(data_classes, 'Complexity', 'high', 'high') \n\ndata_classes = change_values(data_classes, 'Coupling', 'low', 'low')    \ndata_classes = change_values(data_classes, 'Coupling', 'high', 'high') \n\ndata_classes = change_values(data_classes, 'Size', 'low', 'low')    \ndata_classes = change_values(data_classes, 'Size', 'high', 'high') \n\ndata_classes = change_values(data_classes, 'Lack of Cohesion', 'low', 'low')    \ndata_classes = change_values(data_classes, 'Lack of Cohesion', 'high', 'high') \n\ndata_classes","2054e9e8":"data_classes.describe()","cf954ac5":"prof_data = data.loc[ data['projectname'].isin(professional_repo) ]\nprof_data","01659a58":"prof_classes_row  = data_classes[data_classes['Type 1']== \"Professional\"]\nprof_classes_row","68fc094b":"open_classes_row  = data_classes[data_classes['Type 1'] == 'Open-source']\nopen_classes_row ","4758b446":"year_order = ['2016-1', '2017-1', '2018-1', '2019-1', '2020-1', '2021-1']","adf7aa7a":"sns_plot = sns.countplot(x=\"filename\", hue=\"Type 1\", data=data_classes, order=year_order)\nplt.title(\"Number of Classes in Years (2016-2021)\")\nplt.xlabel(\"Development Years\")\nplt.ylabel(\"Class Count\")\nsns_plot.figure.savefig(\"number_classes_per_year.png\")","37f1e5d2":"sns.kdeplot(data=data_classes, x=\"DIT\", hue=\"Type 1\", multiple=\"stack\")\n#sns.kdeplot(data=data_classes, x=\"LCOM\", hue=\"Type 1\", multiple=\"stack\")\n#sns.kdeplot(data=data_classes, x=\"LCAM\", hue=\"Type 1\", multiple=\"stack\")","cb8dedef":"sns.displot(data_classes, x=\"NOM\", hue=\"Type 1\", bins=50, multiple=\"dodge\")","51e7a596":"sns.relplot(x=\"LOC\", y=\"WMC\", hue=\"Type 1\", style=\"filename\", data=data_classes);","efafd1ce":"#only categorical value\nvn = 'Size'\n\nsns_plot = sns.catplot(x=\"filename\", hue=vn, col=\"Type 1\", data=data_classes, kind=\"count\", order=year_order);\nsns_plot.set_axis_labels(\"Development Years\", \"Class Count\")\nsns_plot.set_titles(vn+\" classes in Professional Repo.\", vn+\" classes in Open-Source Repo.\")\nsns_plot.savefig(\"number_\"+vn+\"_classes_per_year.png\")","e76a09c4":"g = sns.FacetGrid(data_classes, col=\"Type 1\")\ng.map(sns.histplot, \"filename\")","755f1914":"from scipy import stats\ndef quantile_plot(x, **kwargs):\n    quantiles, xr = stats.probplot(x, fit=False)\n    plt.scatter(xr, quantiles, **kwargs)\n\ng = sns.FacetGrid(data_classes, col=\"Type 1\", height=4)\ng.map(quantile_plot, \"ATFD\")","19361a25":"def qqplot(x, y, **kwargs):\n    _, xr = stats.probplot(x, fit=False)\n    _, yr = stats.probplot(y, fit=False)\n    plt.scatter(xr, yr, **kwargs)\n","f65f1695":"g = sns.FacetGrid(data_classes, hue=\"Type 1\", col=\"filename\", height=4, col_order=year_order)\n#g.map(qqplot, \"LOC\", \"ATFD\")\ng.map(qqplot, \"LOC\", \"RFC\")\ng.add_legend()","0e7e54e9":"g = sns.FacetGrid(data_classes, col=\"Complexity\", hue=\"Type 1\")\ng.map(sns.scatterplot, \"NOSF\", \"NOSM\", alpha=.7)\ng.add_legend()","36887b79":"g = sns.lmplot(x=\"LOC\", y=\"WMC\", hue=\"Type 1\", data=data_classes, col=\"filename\", col_order=year_order)","090b54a0":"vn = 'LOC' # LOC(best), WMC(good), NOF(taking time), {DIT, NOM, ATFD(same as class com), } \nsns_plot = sns.barplot(x=\"filename\", y=vn, hue=\"Type 1\", data=data_classes, order = year_order)\nplt.title(vn+\" evolution in Years (2016-2021)\")\nplt.xlabel(\"Development Years\")\nplt.ylabel(vn+\" Value\")\nsns_plot.figure.savefig(vn+\"_per_year.png\")","be4eb829":"vn = 'Complexity' #Complexity ok\nsns_plot = open_classes_row[vn].value_counts().plot.pie(autopct='%1.1f%%')\nplt.title(\"Low vs High \"+vn+\" comparison in Open Source Repositories\")\nsns_plot.figure.savefig(vn+\"_pie_open.png\")","59a53863":"sns_plot = prof_classes_row['Complexity'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.title(\"Low vs High Complexity comparison in Professional Repositories\")\nsns_plot.figure.savefig(\"complexity_pie_prof.png\")","68b3ad97":"# 4 rel plot","6882e90a":"# 5 Cat Plot","b760a611":"# 7 lm plot","7c0123ad":"Countplot","aef10f3b":"# 9 PIE PLOT","0486d5f3":"# 6 FacetGrid","74241faf":"# 3 DIST PLOT","dd43822e":"# 1 COUNT PLOT","83cbcbaa":"# 8 Barplot","d4ab51d6":"# KDE PLOT"}}