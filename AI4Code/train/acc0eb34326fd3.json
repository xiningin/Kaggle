{"cell_type":{"63d20fdb":"code","b3616296":"code","f83b83fd":"code","22a2fe39":"code","454cde0c":"code","a10f8348":"code","2a99eef4":"code","5fbbd91a":"code","dafa2dcb":"code","93cdf1ca":"code","279cc32a":"code","6c691e06":"code","0b4e5cd0":"code","be894143":"code","c8d56ee4":"code","391c7a0a":"code","108ae0b8":"code","6c3738f3":"code","c8a49e46":"code","06aeda07":"code","df7d9900":"code","ab92adf6":"code","03446fcf":"code","90eda67f":"code","56063819":"code","dcbb5c27":"code","d534ba52":"code","6481eac9":"code","6b6d2391":"code","84736bb4":"code","72f9cd83":"code","4cb60249":"code","f0ca578d":"markdown","bfc3fced":"markdown","12ed95a8":"markdown","e65a982d":"markdown"},"source":{"63d20fdb":"!pip install \/kaggle\/input\/iterative-stratification\/iterative-stratification-master\/","b3616296":"import pandas as pd\nimport numpy as np\nfrom fastai.vision.all import *\nimport pickle\nimport os","f83b83fd":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'\n# !cp '..\/input\/resnet34\/resnet34.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet34-333f7ec4.pth'","22a2fe39":"path = Path('..\/input\/hpa-cell-tiles-sample-balanced-dataset')","454cde0c":"df = pd.read_csv(path\/'cell_df.csv')","a10f8348":"df.head()","2a99eef4":"len(df)","5fbbd91a":"labels = [str(i) for i in range(19)]\nfor x in labels: df[x] = df['image_labels'].apply(lambda r: int(x in r.split('|')))","dafa2dcb":"dfs = df.sample(frac=1, random_state=42)\ndfs = dfs.reset_index(drop=True)\nlen(dfs)","93cdf1ca":"unique_counts = {}\nfor lbl in labels:\n    unique_counts[lbl] = len(dfs[dfs.image_labels == lbl])\n\nfull_counts = {}\nfor lbl in labels:\n    count = 0\n    for row_label in dfs['image_labels']:\n        if lbl in row_label.split('|'): count += 1\n    full_counts[lbl] = count\n    \ncounts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\ncounts = np.array(sorted(counts, key=lambda x:-x[1]))\ncounts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\ncounts.set_index('label').T\n","279cc32a":"len(dfs)","6c691e06":"nfold = 5\nseed = 42\n\ny = dfs[labels].values\nX = dfs[['image_id', 'cell_id']].values\n\ndfs['fold'] = np.nan\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    dfs.iloc[test_index, -1] = i\n    \ndfs['fold'] = dfs['fold'].astype('int')","0b4e5cd0":"dfs['is_valid'] = False\ndfs['is_valid'][dfs['fold'] == 0] = True","be894143":"dfs.is_valid.value_counts()","c8d56ee4":"def get_x(r): return path\/'cells'\/(r['image_id']+'_'+str(r['cell_id'])+'.jpg')\nimg = get_x(dfs.loc[12])\nimg = PILImage.create(img)\nimg.show();","391c7a0a":"def get_y(r): return r['image_labels'].split('|')\nget_y(dfs.loc[12])","108ae0b8":"sample_stats = ([0.07237246, 0.04476176, 0.07661699], [0.17179589, 0.10284516, 0.14199627])","6c3738f3":"item_tfms = RandomResizedCrop(224, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(flip_vert=True, size=128,max_warp=0.2,max_lighting = 0.5,max_rotate =60), Normalize.from_stats(*sample_stats)]\nbs=256","c8a49e46":"def get_y_bce(r): \n    \n    categories = r['image_labels'].split('|')\n    n_categories = len(categories)\n    arr = np.zeros(len(labels))\n    for l in categories:\n        \n        arr[int(l)]= 1 #+ np.log(1\/n_categories)\/5\n    \n    \n    return arr\n\nget_y_bce(dfs.loc[12])","06aeda07":"dblock = DataBlock(blocks=(ImageBlock,RegressionBlock(n_out=len(labels))),\n                splitter=ColSplitter(col='is_valid'),\n                get_x=get_x,\n                get_y=get_y_bce,\n                item_tfms=item_tfms,\n                batch_tfms=batch_tfms\n                )\ndls = dblock.dataloaders(dfs, bs=bs)","df7d9900":"# dblock.summary(dfs)","ab92adf6":"dls.show_batch(nrows=9, ncols=1)","03446fcf":"cutmix = CutMix(0.1)","90eda67f":"learn = cnn_learner(dls, resnet50, metrics=[SpearmanCorrCoef()]).to_fp16()","56063819":"lr=3e-2","dcbb5c27":"learn.fine_tune(1,base_lr=lr,cbs=cutmix)","d534ba52":"learn.recorder.plot_loss()","6481eac9":"class CutMix(MixHandler):\n    \"Implementation of `https:\/\/arxiv.org\/abs\/1905.04899`\"\n    def __init__(self, alpha=1.): super().__init__(alpha)\n    def before_batch(self):\n        bs, _, H, W = self.x.size()\n        self.lam = self.distrib.sample((1,)).to(self.x.device)\n        shuffle = torch.randperm(bs).to(self.x.device)\n        xb1,self.yb1 = self.x[shuffle], tuple((self.y[shuffle],))\n        x1, y1, x2, y2 = self.rand_bbox(W, H, self.lam)\n        self.learn.xb[0][..., y1:y2, x1:x2] = xb1[..., y1:y2, x1:x2]\n        self.lam = (1 - ((x2-x1)*(y2-y1))\/float(W*H))\n        if not self.stack_y:\n            ny_dims = len(self.y.size())\n            self.learn.yb = tuple(L(self.yb1,self.yb).map_zip(torch.lerp,weight=unsqueeze(self.lam, n=ny_dims-1)))\n\n    def rand_bbox(self, W, H, lam):\n        cut_rat = torch.sqrt(1. - lam).to(self.x.device)\n        cut_w = torch.round(W * cut_rat).type(torch.long).to(self.x.device)\n        cut_h = torch.round(H * cut_rat).type(torch.long).to(self.x.device)\n        # uniform\n        cx = torch.randint(0, W, (1,)).to(self.x.device)\n        cy = torch.randint(0, H, (1,)).to(self.x.device)\n        x1 = torch.clamp(cx - cut_w \/\/ 2, 0, W)\n        y1 = torch.clamp(cy - cut_h \/\/ 2, 0, H)\n        x2 = torch.clamp(cx + cut_w \/\/ 2, 0, W)\n        y2 = torch.clamp(cy + cut_h \/\/ 2, 0, H)\n        return x1, y1, x2, y2","6b6d2391":"cutmix = CutMix(0.5)","84736bb4":"learn = cnn_learner(dls, resnet50,loss_func=torch.nn.BCEWithLogitsLoss(), metrics=[SpearmanCorrCoef()]).to_fp16()","72f9cd83":"learn.fine_tune(1,base_lr=lr,cbs=cutmix)","4cb60249":"learn.recorder.plot_loss()","f0ca578d":"# fastai training loop with the data-block API\nfastai is a great tool to create a strong baseline quickly. I use pretty much out of the box approach for multilabel classification, with resnet50 backbone, one cycle training, lr finder etc. The data block API is a great way to prepare the data, and comes with a default set of augmentations that I use as well.\n\nthis is based on \nSolution overview: https:\/\/www.kaggle.com\/c\/hpa-single-cell-image-classification\/discussion\/221550\n\nand forked to illustrate an issue with cutmix","bfc3fced":" learn.lr_find()\n# SuggestedLRs(lr_min=0.03630780577659607, lr_steep=0.02754228748381138)","12ed95a8":"# calback error","e65a982d":"# Workaround"}}