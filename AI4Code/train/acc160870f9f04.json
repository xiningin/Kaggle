{"cell_type":{"f28c3f4e":"code","d258f982":"code","154b0498":"code","fb553617":"code","8da71117":"code","2d610c4a":"code","50c91fd3":"code","ac7c08c8":"code","7eabaaa4":"code","8ea830aa":"code","f5e5da29":"code","3573c77a":"code","ebdafb2d":"code","bfa0a2b6":"code","7794841a":"code","b5d5d810":"code","944efbab":"code","f3592172":"code","e8daf746":"code","96b3f595":"code","3a208f7b":"code","0d885aab":"code","311b3b2b":"code","542df917":"code","398d4dfc":"code","691e5972":"code","769c0bc6":"markdown","7a41f92d":"markdown","610c98a0":"markdown","ce6e37bf":"markdown","67b3fc72":"markdown","1f108220":"markdown","eb682f3b":"markdown","3964c95b":"markdown"},"source":{"f28c3f4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d258f982":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, trange\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","154b0498":"train_pth = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_pth = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\ntrain = pd.read_csv(train_pth)\ntest = pd.read_csv(test_pth)\nprint('train: {}'.format(len(train)))\nprint('test: {}'.format(len(test)))","fb553617":"# have a look\ntrain.head()","8da71117":"test.head()","2d610c4a":"y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \ndel train \nsns.countplot(y_train)","50c91fd3":"y_train.value_counts()","ac7c08c8":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\n\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","7eabaaa4":"X_train.shape","8ea830aa":"test.shape","f5e5da29":"fig=plt.figure(figsize=(10,10))\nfig.subplots_adjust(wspace=0.5, hspace=0.5)\ncolumns = 5\nrows = 5\nfor i in range(1, 25+1):\n    fig.add_subplot(rows, columns, i)\n    img = X_train[i][:,:,0]\n    plt.imshow(img)\n    plt.title(y_train[i])\nplt.show()","3573c77a":"class MNIST(Dataset):\n    def __init__(self, df, phase, transform=None):\n        self.phase = phase\n        self.df = df\n        self.transform = transform\n        self.phase = phase\n    \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if self.phase in ['train', 'val']:\n            X = self.df.iloc[idx,1:].values.reshape((28,28,-1)).astype(np.uint8)\n            y = np.array(self.df.iloc[idx,0])\n            return self.transform(X), torch.from_numpy(y)\n        else:\n            X = self.df.iloc[idx].values.reshape((28,28,-1)).astype(np.uint8)\n            return self.transform(X)","ebdafb2d":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    # transforms.RandomHorizontalFlip(p=0.5)\n])","bfa0a2b6":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(         \n            nn.Conv2d(\n                in_channels=1,              \n                out_channels=16,            \n                kernel_size=5,              \n                stride=1,                   \n                padding=2,                  \n            ),                             \n            nn.ReLU(),                     \n            nn.MaxPool2d(kernel_size=2),   \n        )\n        self.conv2 = nn.Sequential(      \n            nn.Conv2d(16, 32, 5, 1, 2),  \n            nn.ReLU(),                    \n            nn.MaxPool2d(2),              \n        )\n        self.out = nn.Linear(32 * 7 * 7, 10) \n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x.view(x.size(0), -1) \n        output = self.out(x)\n        return output","7794841a":"model = CNN();model","b5d5d810":"EPOCH = 30               \nBATCH_SIZE = 64\nLR = 0.001 ","944efbab":"optimizer = torch.optim.Adam(model.parameters(), lr=LR) \ncriterion = nn.CrossEntropyLoss()  \nlr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[9, 15, 21], gamma=0.1)","f3592172":"# reload\ntrain = pd.read_csv(train_pth)\ntest = pd.read_csv(test_pth)\n\ntrain, val = train_test_split(train, test_size = 0.2)\n\ntrain_data = MNIST(train, 'train', transform)\ntest_data = MNIST(val, 'val', transform)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, num_workers=20, pin_memory=True, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)","e8daf746":"valid_loss_min = np.Inf\ntrain_losses, valid_losses = [], []\nhistory_accuracy = []\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\n\nfor epoch in range(1, EPOCH+1):\n    running_loss = 0\n    model.train()\n    with tqdm(train_loader, desc='Epoch [{}\/{}]'.format(epoch, EPOCH)) as pbar1:\n        for x, y in pbar1: \n            x, y = x.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            output = model(x)\n            loss = criterion(output, y)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            pbar1.set_postfix(loss=loss.item(), refresh=True)\n        train_losses.append(running_loss \/ len(train_loader))\n        lr_scheduler.step()\n        \n    with torch.no_grad():\n        with tqdm(test_loader, desc='Testing') as pbar2:\n            model.eval()\n            accuracy = 0\n            valid_loss = 0\n            for x, y in pbar2:\n                x, y = x.to(device), y.to(device)\n                test_output = model(x)\n                batch_loss = criterion(test_output, y)\n                valid_loss += batch_loss\n                pred_y = torch.max(test_output, 1)[1].data.squeeze()\n                batch_correct = pred_y.eq(y.data.view_as(pred_y)).cpu().sum()\n\n                batch_acc = batch_correct.item() \/ y.size(0)\n                pbar2.set_postfix(loss=batch_loss.item(),acc=batch_acc, refresh=True)\n                accuracy += batch_acc\n            valid_losses.append(valid_loss \/ len(test_loader))    \n            history_accuracy.append(accuracy \/ len(test_loader))\n            \n            # save the best model\n            if valid_losses[-1] < valid_loss_min:\n                torch.save(model.state_dict(), \".\/model.pth\")\n","96b3f595":"import matplotlib.pyplot as plt\n\nplt.plot(train_losses, label='Training Loss')\nplt.plot(valid_losses, label='Validation Loss')\nplt.legend(frameon=False)","3a208f7b":"plt.plot(history_accuracy, label='Validation Accuracy')\nplt.legend(frameon=False)","0d885aab":"# load model\nmodel = CNN()\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()","311b3b2b":"dataset = MNIST(test, 'test', transform)\n\ndataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=28000, num_workers=20)\n\nmodel.to(device)\nfor i, data in enumerate(tqdm(dataloader)):\n    data = data.to(device)\n    output = model(data)\n    pred_y = torch.max(output, 1)[1].cpu().data.numpy().squeeze()","542df917":"submission = pd.DataFrame(np.c_[np.arange(1, len(dataset)+1)[:,None], pred_y], \n                      columns=['ImageId', 'Label'])","398d4dfc":"submission.head()","691e5972":"submission.to_csv('submission.csv', index=False)","769c0bc6":"# Prediction","7a41f92d":"# Model","610c98a0":"The test file does not exist the label colum.","ce6e37bf":"# Category statistics","67b3fc72":"# Load the data","1f108220":"# Train","eb682f3b":"# Reshape data and visualize","3964c95b":"# DataLoader"}}