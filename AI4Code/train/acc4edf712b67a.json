{"cell_type":{"5f74284b":"code","e3201cd6":"code","52ac2782":"code","5c33271c":"code","229739e5":"code","5a668efb":"code","9c7f298d":"code","1c3f43f7":"code","01912853":"code","d1d1aa8c":"code","d5fe8096":"code","dc9db347":"code","9df4d637":"code","57f4d66d":"code","9e2dce5d":"code","0200df2a":"code","5793318c":"code","146f9112":"code","5bccfd4c":"code","22bcd480":"code","c365f586":"code","595acf27":"code","953bd7d4":"code","df7ec6cf":"code","5e3bc24a":"code","f6e09f50":"code","7178bce4":"code","f7e43927":"code","14a1737c":"code","c8c9a3b9":"code","9c444a3a":"code","06c97a16":"code","811c032b":"code","b92e41b1":"code","21ad4c59":"code","e812385e":"code","2839dfe7":"code","df23140c":"code","f5d9a0e0":"code","dfd42020":"code","902cc9d5":"code","c5c3c485":"code","2191f7ce":"code","699c7a19":"code","b66c5a9b":"code","52cce744":"code","ed0c5c32":"code","dff23f23":"code","ea239110":"code","ad97c3e4":"code","a8dd6167":"code","a617cbf8":"code","da924343":"code","02f202a0":"code","577d7dd6":"code","e098d381":"code","55be47e2":"code","3814ae1e":"markdown","f17af108":"markdown","a248ddef":"markdown","af445f26":"markdown","d309f681":"markdown","669d1703":"markdown","fe8a4204":"markdown","524705a9":"markdown","f5d0ace9":"markdown","1a389239":"markdown","83d52bdc":"markdown","ec3e8b77":"markdown","caec396e":"markdown","31d08d6e":"markdown","601d87a3":"markdown","aaeec104":"markdown","87f6f6fc":"markdown","cb1f197f":"markdown","b10fa40a":"markdown","8c448e8b":"markdown","e87e67ec":"markdown","8e16f338":"markdown","ce16e930":"markdown","2fc2eecf":"markdown","c25a54e2":"markdown","b6c91445":"markdown","606a82d9":"markdown","061ec477":"markdown","94057fa1":"markdown","a2fa1bde":"markdown","6f1b347d":"markdown","ebf5a3b7":"markdown","a0bf2b10":"markdown","b42bdfac":"markdown","6d1d8c54":"markdown","6e251bd7":"markdown","7b7fa4a5":"markdown","1b483d73":"markdown","55ae961e":"markdown","beafa0c7":"markdown","2fd50b2f":"markdown"},"source":{"5f74284b":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport matplotlib.pyplot as plt","e3201cd6":"import pydicom as dicom\nimport cv2","52ac2782":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer","5c33271c":"from keras.utils import to_categorical, Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import VGG19, VGG16, ResNet50","229739e5":"import tensorflow as tf","5a668efb":"import warnings\nwarnings.filterwarnings(\"ignore\")","9c7f298d":"path_in = \"..\/input\/rsna-intracranial-hemorrhage-detection\/rsna-intracranial-hemorrhage-detection\/\"\nos.listdir(path_in)","1c3f43f7":"path_train_img = path_in + 'stage_2_train'\npath_test_img = path_in + 'stage_2_test'","01912853":"path_models = '..\/input\/models' \nos.listdir(path_models)","d1d1aa8c":"def rescale_pixelarray(dataset):\n    image = dataset.pixel_array\n    rescaled_image = image * dataset.RescaleSlope + dataset.RescaleIntercept\n    rescaled_image[rescaled_image < -1024] = -1024\n    return rescaled_image","d5fe8096":"def plot_example(data, sub_type='subdural'):\n    \"\"\" Plot 5 examples of a given subtype \"\"\"\n    \n    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = data[(data['Label']==1)&(data['sub_type']==sub_type)].index[i]\n        data_file = dicom.dcmread(path_train_img+'\/ID_'+data.loc[idx, 'PatientID']+'.dcm')\n        #img = data_file.pixel_array\n        img = rescale_pixelarray(data_file)\n        if type(data_file.WindowCenter) == dicom.multival.MultiValue:\n            window_center = int(data_file.WindowCenter[0])\n        else: \n            window_center = int(data_file.WindowCenter)\n            \n        if type(data_file.WindowWidth) == dicom.multival.MultiValue:\n            window_width = int(data_file.WindowWidth[0])\n        else:\n            window_width = int(data_file.WindowWidth)\n        img_min = window_center - window_width \/\/ 2\n        img_max = window_center + window_width \/\/ 2\n        window_image = img.copy()\n        window_image[window_image < img_min] = img_min\n        window_image[window_image > img_max] = img_max\n        axs[i].imshow(window_image, cmap=plt.cm.gray)\n        axs[i].set_title(data.loc[idx, 'PatientID']+'_'+data.loc[idx, 'sub_type'])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])","dc9db347":"def plot_types(data, num_types):\n    \"\"\" Plot image of patient with given number of sub types\"\"\"\n    \n    temp = data[(data['sub_type']!='any')&\n           (data['Label']==1)].groupby('PatientID').sum()\n    fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n   \n    idx = temp[temp['Label']==num_types].index[0]\n    sub_types = list(data[(data['PatientID']==idx)&\n                     (data['Label']!=0)&\n                     (data['sub_type']!='any')]['sub_type'].values)\n    \n    title = idx+':'\n    for sub_type in sub_types:\n        title = title+' '+sub_type\n        if sub_types.index(sub_type) < len(sub_types)-1:\n            title = title+','\n    data_file = dicom.dcmread(path_train_img+'\/ID_'+idx+'.dcm')\n    img = rescale_pixelarray(data_file)\n    if type(data_file.WindowCenter) == dicom.multival.MultiValue:\n        window_center = int(data_file.WindowCenter[0])\n    else: \n        window_center = int(data_file.WindowCenter)\n            \n    if type(data_file.WindowWidth) == dicom.multival.MultiValue:\n        window_width = int(data_file.WindowWidth[0])\n    else:\n        window_width = int(data_file.WindowWidth)\n    img_min = window_center - window_width \/\/ 2\n    img_max = window_center + window_width \/\/ 2\n    window_image = img.copy()\n    window_image[window_image < img_min] = img_min\n    window_image[window_image > img_max] = img_max\n    ax.imshow(window_image, cmap=plt.cm.gray)\n    ax.set_title(title)\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])","9df4d637":"#plot_example(train_data, sub_type='subdural')","57f4d66d":"q_size = 200\nimg_channel = 3\nnum_classes = 6","9e2dce5d":"list_train_img = os.listdir(path_train_img)\nlist_test_img = os.listdir(path_test_img)","0200df2a":"train_data = pd.read_csv(path_in + 'stage_2_train.csv')\nsub_org = pd.read_csv(path_in + 'stage_2_sample_submission.csv')","5793318c":"train_data.head()","146f9112":"train_data['sub_type'] = train_data['ID'].str.split(\"_\", n = 3, expand = True)[2]\ntrain_data['PatientID'] = train_data['ID'].str.split(\"_\", n = 3, expand = True)[1]\nsub_org['sub_type'] = sub_org['ID'].str.split(\"_\", n = 3, expand = True)[2]\nsub_org['PatientID'] = sub_org['ID'].str.split(\"_\", n = 3, expand = True)[1]","5bccfd4c":"train_data['sub_type'].value_counts()","22bcd480":"print('number of (unique) train patient ids:', len(train_data['PatientID'].unique()))\nprint('number of train images: ', len(list_train_img))\nprint('number of (unique) test patient ids:', len(sub_org['PatientID'].unique()))\nprint('number of test images: ', len(list_test_img))","c365f586":"plot_example(train_data, sub_type='intraparenchymal')","595acf27":"plot_example(train_data, sub_type='intraventricular')","953bd7d4":"plot_example(train_data, sub_type='subarachnoid')","df7ec6cf":"plot_example(train_data, sub_type='subdural')","5e3bc24a":"plot_example(train_data, sub_type='epidural')","f6e09f50":"group_type = train_data.groupby('sub_type').sum()\nfig = plt.figure(figsize=(9, 5))\nax = fig.add_subplot(111)\nax.bar(group_type.index, group_type['Label'])\nax.set_xticklabels(group_type.index, rotation=45)\nplt.grid()\nplt.show()","7178bce4":"train_data[(train_data['sub_type']!='any')&\n           (train_data['Label']==1)].groupby('PatientID').sum()['Label'].value_counts()","f7e43927":"plot_types(train_data, 1)","14a1737c":"plot_types(train_data, 2)","c8c9a3b9":"plot_types(train_data, 3)","9c444a3a":"plot_types(train_data, 4)","06c97a16":"plot_types(train_data, 5)","811c032b":"column_names = ['Label', 'PatientID', 'sub_type']\ntrain_data_pivot = train_data[column_names].drop_duplicates().pivot(index='PatientID',\n                                                                    columns='sub_type',\n                                                                    values='Label')\ntest_data_pivot = sub_org[column_names].drop_duplicates().pivot(index='PatientID',\n                                                                columns='sub_type',\n                                                                values='Label')","b92e41b1":"percentage = 0.25\nnum_train_img = int(percentage*len(train_data_pivot.index))\nnum_test_img = len(test_data_pivot.index)\nprint('num_train_data:', len(list_train_img), num_train_img)\nprint('num_test_data:', len(list_test_img))\nlist_train_img = list(train_data_pivot.index)\nlist_test_img = list(test_data_pivot.index)\nrandom_train_img = random.sample(list_train_img, num_train_img)","21ad4c59":"y_train_org = train_data_pivot.loc[random_train_img]","e812385e":"y_train, y_val = train_test_split(y_train_org, test_size=0.3)\ny_test = test_data_pivot","2839dfe7":"class_weight = dict(zip(range(0, num_classes), y_train.sum()\/y_train.sum().sum()))","df23140c":"class_weight","f5d9a0e0":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, labels, batch_size,\n                 img_size, img_channel, num_classes, shuffle=True):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_channel = img_channel\n        self.num_classes = num_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n     \n    \n    def __len__(self):\n        return int(np.floor(len(self.list_IDs)\/self.batch_size))\n    \n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n    \n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    \n    def rescale_pixelarray(self, dataset):\n        image = dataset.pixel_array\n        rescaled_image = image * dataset.RescaleSlope + dataset.RescaleIntercept\n        rescaled_image[rescaled_image < -1024] = -1024\n        return rescaled_image\n\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.empty((self.batch_size, self.img_size, self.img_size))\n        y = np.empty((self.batch_size, self.num_classes), dtype=int)\n        for i, ID in enumerate(list_IDs_temp):\n            data_file = dicom.dcmread(self.path+'\/ID_'+ID+'.dcm')\n            img = self.rescale_pixelarray(data_file)\n            img = cv2.resize(img, (self.img_size, self.img_size))\n            X[i, ] = img\n            y[i, ] = self.labels.loc[ID]\n        X = np.repeat(X[..., np.newaxis], 3, -1)\n        X = X.astype('float32')\n        X -= X.mean(axis=0)\n        std = X.std(axis=0)\n        X \/= X.std(axis=0)\n        return X, y","dfd42020":"conv_base = ResNet50(weights='..\/input\/models\/model_weights_resnet.h5',\n                     include_top=False,\n                     input_shape=(q_size, q_size, img_channel))\nconv_base.trainable = True","902cc9d5":"batch_size = 32\ntrain_generator = DataGenerator(path_train_img, list(y_train.index), y_train,\n                                batch_size, q_size, img_channel, num_classes)\nval_generator = DataGenerator(path_train_img, list(y_val.index), y_val,\n                                batch_size, q_size, img_channel, num_classes)","c5c3c485":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6, activation='sigmoid'))","2191f7ce":"model.compile(optimizer = RMSprop(lr=1e-5),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","699c7a19":"model.summary()","b66c5a9b":"epochs = 5","52cce744":"history = model.fit_generator(generator=train_generator,\n                              validation_data=val_generator,\n                              epochs = epochs,\n                              class_weight = class_weight,\n                              workers=4)","ed0c5c32":"loss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'bo', label='loss_train')\nplt.plot(epochs, loss_val, 'b', label='loss_val')\nplt.title('value of the loss function')\nplt.xlabel('epochs')\nplt.ylabel('value of the loss functio')\nplt.legend()\nplt.grid()\nplt.show()","dff23f23":"acc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, acc, 'bo', label='accuracy_train')\nplt.plot(epochs, acc_val, 'b', label='accuracy_val')\nplt.title('accuracy')\nplt.xlabel('epochs')\nplt.ylabel('value of accuracy')\nplt.legend()\nplt.grid()\nplt.show()","ea239110":"batch_size = 16\ntest_generator = DataGenerator(path_test_img, list(y_test.index), y_test,\n                                batch_size, q_size, img_channel, num_classes, shuffle=False)","ad97c3e4":"predict = model.predict_generator(test_generator, verbose=1)","a8dd6167":"assert(len(predict) == len(test_data_pivot))","a617cbf8":"submission = pd.DataFrame(predict, columns=y_train_org.columns)\nsubmission.insert(loc=0, column='PatientID', value=test_data_pivot.index)\nsubmission.index=submission['PatientID']\nsubmission = submission.drop(['PatientID'], axis=1)","da924343":"submission = submission.stack().reset_index()\nsubmission = submission.rename(columns={0: 'Label'})","02f202a0":"submission.insert(loc=0, column='ID', value='ID_'+submission['PatientID'].astype(str)+'_'+submission['sub_type'].astype(str))\nsubmission = submission.drop(['PatientID', 'sub_type'], axis=1)","577d7dd6":"submission.index = submission['ID']\nsubmission = submission.reindex(sub_org['ID'])\nsubmission.index = range(len(submission))","e098d381":"submission.to_csv('submission.csv', header = True, index=False)","55be47e2":"submission","3814ae1e":"### 5 Types (all types)","f17af108":"# Fit the model with the fit_generator method","a248ddef":"# Read Image Name","af445f26":"# Define the test data via Data Generator","d309f681":"# Parameters","669d1703":"# Calculate Class Weights","fe8a4204":"# Select Subset Input Data For Training\nThis is a big dataset. So we select a smaller subset for the training.","524705a9":"## Group Subtypes\nThere are 5 subtyps and the addditional label any, which should always be true if any of the sub-type labels is true.","f5d0ace9":"# Read Input Data","1a389239":"Define the sub paths with images","83d52bdc":"# Modify Input Data","ec3e8b77":"# Define train and validation data via Data Generator","caec396e":"# Define the model","31d08d6e":"## Subarachnoid\n* **Location**: Between the arachonid and the pia mater.\n* **Mechanism**: Rupture of aneurysms or arteriovenous malformations or trauma.\n* **Source**: Predominantly arterial.\n* **Shape**: Tracks along the sulci and fissures.\n* **Presentation**: Acute (worst headache of life).","601d87a3":"# Train And Test Pivot","aaeec104":"## Intraparenchymal\n* **Location**: Inside of the brain.\n* **Mechanism**: Hight blood pressure, trauma, arteriovenous, malformation, tumor, etc.\n* **Source**: Arterial or venous.\n* **Shape**: Typically rounded.\n* **Presentation**: Acute (sudden onest of headache, nausea, vomiting).","87f6f6fc":"# Export the prediction data","cb1f197f":"# Plot the accuracy values","b10fa40a":"# Load Pretrained Model","8c448e8b":"### 2 Types","e87e67ec":"Path to the pretrained data set.","8e16f338":"So we can see there are 23 patients which have all labels.","ce16e930":"# Data Generator","2fc2eecf":"# Overview","c25a54e2":"# EDA","b6c91445":"# Prepare the prediction data by the export format","606a82d9":"### 4 Types","061ec477":"# Path\nDefine the path for the subfolders with the data.","94057fa1":"# Load Libraries","a2fa1bde":"### 3 Types","6f1b347d":"## Subdural\n* **Location**: Between the Dura and the arachnoid.\n* **Mechanism**: Trauma.\n* **Source**: Venous (bridging veins).\n* **Shape**: Crescent.\n* **Presentation**: May be insidous (worsening headache).","ebf5a3b7":"# Functions\nWe define some helper functions.","a0bf2b10":"# Split Train And Val","b42bdfac":"# Intro\nWelcome to the [RSNA Intracranial Hemorrhage Detection](https:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection).\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/13451\/logos\/header.png)\n\nThis notebook is a starter code for all beginners and easy to understand. Used is a image generator based on this [template](https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly)\n\nThe hemorrhage types are explained [here](https:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection\/overview\/hemorrhage-types).\n\nThe model is based on ResNet50 and runs on GPU.\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","6d1d8c54":"# Compile the model","6e251bd7":"## Multilabel\nThere are a lot of patients with a multilabel.","7b7fa4a5":"# Predict the test images with the generator class","1b483d73":"## Intraventricular\n* **Location**: Inside of the ventricle.\n* **Mechanism**: Can be associated with both intraparenchymal and subarachnoid hermorrhages.\n* **Source**: Arterial or venous.\n* **Shape**: Conforms to ventricular shape.\n* **Presentation**: Acute (sudden onest of headache, nausea, vomiting).","55ae961e":"# Plot the loss values","beafa0c7":"### 1 Type","2fd50b2f":"## Epidural\n* **Location**: Between the dura and the skull.\n* **Mechanism**: Trauma or after surgery.\n* **Source**: Arterial.\n* **Shape**: Lentiform.\n* **Presentation**: Acute (skull fracture and altered mental status)"}}