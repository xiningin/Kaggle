{"cell_type":{"c7c54364":"code","99b2c727":"code","90531619":"code","a6193406":"code","ee0222a4":"code","315073b4":"code","4a7dd507":"code","965454a9":"code","ba3254c3":"code","1ca3d58b":"code","e335873a":"code","d2dce997":"code","2c9eaba6":"code","bab4fb9f":"code","d5ed0a87":"code","563d476d":"code","17e3e77c":"code","7c545b2f":"code","3a89467d":"code","8c60a6c9":"code","593bcda0":"code","df42b3e1":"code","3c953d79":"code","b28c676f":"code","278c20c0":"code","24be56c6":"code","e368cd10":"markdown","10e0a428":"markdown","a7306d90":"markdown","997f65e4":"markdown","6619d8a5":"markdown","6f72511b":"markdown","6717f463":"markdown","54a25fc2":"markdown","1462f69e":"markdown","24419bbd":"markdown","0fe1c2ed":"markdown"},"source":{"c7c54364":"import numpy as np\nimport pandas as pd\nimport datetime\nimport os\nimport xml.etree.ElementTree as ET\nimport scipy.stats as sts","99b2c727":"dataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'","90531619":"train_df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\nweather_df = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))","a6193406":"train_df.head()","ee0222a4":"# converting the categoral data to numirc represntation\ntrain_df['Side'] = np.where('R' == train_df['Side'], 1, 0)\n","315073b4":"dfTimestampDt = pd.to_datetime(train_df['timestamp']).dt\ntrain_df['Year'] = dfTimestampDt.year\ntrain_df['Month'] = dfTimestampDt.month\ntrain_df['Day'] = dfTimestampDt.day\ntrain_df['Hour'] = dfTimestampDt.hour","4a7dd507":"train_df.head()","965454a9":"# remove the unimportant features\ntrain_df.drop(columns=['Bump','Give_Way','No_Exit','Roundabout','timestamp'],inplace = True)","ba3254c3":"weather_df","1ca3d58b":"# remove the unimportant features\nweather_df.drop(columns=['Selected'],inplace = True)","e335873a":"# converting the categoral data to numirc represntation\nweather_df['Weather_Condition']= weather_df['Weather_Condition'].astype('category')\nweather_df['Weather_Condition']= weather_df['Weather_Condition'].cat.codes","d2dce997":"# Handling the dublicated and null values from the dataframe \nweather_df.drop_duplicates(['Year', 'Month', 'Day', 'Hour'], keep ='last', inplace=True)\nweather_df","2c9eaba6":"weather_df.fillna(np.mean(weather_df), inplace = True)\nweather_df.dropna()","bab4fb9f":"df = pd.merge(left = train_df, right = weather_df, how = 'left',\n              left_on=['Year', 'Month', 'Day', 'Hour'], \n              right_on=['Year', 'Month', 'Day', 'Hour'])\n\n","d5ed0a87":"df.drop(columns=['Year','Day','Month'],inplace = True)","563d476d":"df","17e3e77c":"#Handel the null values resulting from the merge\ndf.fillna(np.mean(df), inplace = True)\ndf","7c545b2f":"df.dropna(inplace = True)\ndf","3a89467d":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.3, random_state=42) \n\nX_train = train_df.drop(columns='Severity')\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns='Severity')\ny_val = val_df['Severity']","8c60a6c9":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","593bcda0":"print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","df42b3e1":"test_data = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\ntest_data.head()","3c953d79":"test_data['Side'] = np.where('R' == test_data['Side'], 1, 0)\n\ndfTimestampDt = pd.to_datetime(test_data['timestamp']).dt\ntest_data['Year'] = dfTimestampDt.year\ntest_data['Month'] = dfTimestampDt.month\ntest_data['Day'] = dfTimestampDt.day\ntest_data['Hour'] = dfTimestampDt.hour\n\ntest_data.drop(columns=['Bump','Give_Way','No_Exit','Roundabout','timestamp'],inplace = True)","b28c676f":"test_df = pd.merge(left = test_data, right = weather_df, how = 'left',\n              left_on=['Year', 'Month', 'Day', 'Hour'], \n              right_on=['Year', 'Month', 'Day', 'Hour'])\n\ntest_df.drop(columns=['Year','Day','Month'],inplace = True)\ntest_df.fillna(np.mean(test_df), inplace=True)\ntest_df.head()","278c20c0":"X_test = test_df\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","24be56c6":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","e368cd10":"## merging the dataframes","10e0a428":"The remaining steps is to submit the generated file and are as follows. \n\n1. Press `Save Version` on the upper right corner of this notebook.\n2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n3. Wait for the saved notebook to finish running the go to the saved notebook.\n4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n\nNow your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!","a7306d90":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","997f65e4":"## cleaning the weather file dataframe","6619d8a5":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data.","6f72511b":"## preparing the test set to the desired format","6717f463":"## Conclusion\n\nIn this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n\nYou're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission.","54a25fc2":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","1462f69e":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","24419bbd":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only.","0fe1c2ed":"## cleaning the train file dataframe"}}