{"cell_type":{"14fea248":"code","b0fb5089":"code","a90e7b72":"code","8c2e9405":"code","63d5adc0":"code","39023e25":"code","c5e3c631":"code","0f8e1a9e":"code","58e7dcd1":"code","90c0a37b":"code","49aa74d5":"code","89321b8c":"code","edbb88c7":"code","84a2a85a":"code","87cfc368":"code","3851b3b0":"code","96616263":"code","732a66c0":"code","5129ad91":"code","43b7668f":"code","271ba24b":"code","87f71526":"code","7d8ef73f":"code","b119af2c":"code","dc88ec77":"code","47d9eacc":"code","45651d12":"code","630eb16a":"code","3f362e63":"code","23879892":"code","8c39e4a8":"code","c800c899":"code","e4e2fa43":"code","ebb2ba69":"code","07ae5ad3":"code","213a8c46":"code","0b6692c4":"code","1308bdc4":"code","59bceab4":"code","d0652c62":"code","649fc8ab":"code","27d839e6":"code","62587a34":"code","54088ef0":"code","e321a252":"code","a71c290d":"code","67ac1853":"code","bf9d08fb":"code","93741099":"code","1855120d":"code","ccc779fa":"code","cf8498a4":"code","3a66cfd7":"code","9b749ba4":"code","f57970b2":"code","4e0fa750":"code","3b464dde":"code","1b66112f":"code","e8af8d08":"code","9541ff8e":"code","5c5b4afa":"code","3717eb9a":"code","40615c1b":"code","5645e3f0":"code","8818828b":"code","f5e789f8":"code","f3d50288":"code","9be78031":"code","86062417":"code","65025394":"code","ec93cb45":"code","aff64002":"code","c96afcb4":"code","b2e46dd0":"code","950d4c16":"code","8bf3e03f":"code","4e5266b6":"code","ffb7eab1":"code","986cc16f":"code","2e913cd7":"code","ae4b0e64":"code","3edcf0fe":"code","f9920da6":"code","f02c4cd3":"code","90011257":"code","8c7825a2":"code","068f45a5":"code","51422b53":"code","ca08fb03":"code","9cbb2151":"code","73dbd0d1":"code","95d617a4":"code","07fb3946":"code","69ed4250":"code","df0f6fad":"code","af38f12a":"code","ffa9c95e":"code","f49663ed":"code","c4dbe407":"code","1c3a30c6":"code","b1e97585":"code","413f2cef":"code","6756b70c":"code","9dcfa348":"code","88a8a0c7":"code","b42ba295":"code","08f879fa":"markdown","b84a0db1":"markdown","ac04f24a":"markdown","7a1679f8":"markdown","ee58bcc9":"markdown","eda59dbd":"markdown","a128f62a":"markdown","12f7bfa0":"markdown","7a167a81":"markdown","d0617549":"markdown","7bda7d22":"markdown","4a6f54b8":"markdown","1fc1ffbe":"markdown","7724bf5b":"markdown","1d428a41":"markdown","728aee45":"markdown","b34b66da":"markdown","d7f0e8a0":"markdown","52213b23":"markdown","a9256ac1":"markdown","bab993f5":"markdown","edacda54":"markdown","f60b096f":"markdown","b882bd5f":"markdown","77dd2343":"markdown","4fbc3b1c":"markdown","ba8fe671":"markdown","acbcda4a":"markdown","094d63cf":"markdown","c34c6bbe":"markdown"},"source":{"14fea248":"import numpy as np\n\n# [i \/ 6 for i in [1, 23, 4, 5, 6]]\n\n# np.array([1, 23, 4, 5, 6]) \/ 6 \n\nnp.array([1, 23, 4, 5, 6]) \/ np.array([1, 23, 4, 5, 6])","b0fb5089":"import torch","a90e7b72":"a, b = torch.Tensor(np.array([1,23,4,5,6])) \/ 6, torch.tensor([1,23,4,5,6]) \/ 6\na, b, np.array([1,23,4,5,6]) \/ 6","8c2e9405":"torch.from_numpy(np.array([1,23,4,5,6]))","63d5adc0":"torch.Tensor(np.array([1,23,4,5,6]))","39023e25":"a * np.array([1,23,4,5,6]), \n\n\nnp.array([1,23,4,5,6]) * a.numpy()","c5e3c631":"np.array([1,23,4,5,6]).shape","0f8e1a9e":"np.array([1,23,4,5,6]).size","58e7dcd1":"a.shape, a.size()#[0]","90c0a37b":"torch.std(a).item(), np.std(np.array([1,23,4,5,6]))","49aa74d5":"np.std([1,23,4,5,6]), \n#torch.std(np.array([1,23,4,5,6]))","89321b8c":"a.mean(), np.array([1,23,4,5,6]).mean()","edbb88c7":"type(a.median().item()), type(np.median(np.array([1,23,4,5,6])))","84a2a85a":"np.array(['1',23,4,True,6.1]), torch.tensor([1,23,4,True,6.1])","87cfc368":"torch.from_numpy(np.array([1,23,4,5,6])).dtype, \ntorch.tensor(np.array([1,23,4,1,6]))#.dtype","3851b3b0":"x = torch.empty(10, 10)\nprint(torch.mean(x, 1), x)","96616263":"torch.random.manual_seed(1)","732a66c0":"from random import seed\n\nseed(1)\ntorch.random.manual_seed(42)\n\nx = torch.rand(9, 9)\nprint(x)","5129ad91":"np.array([True, False, True]) + np.array([1,2,3]) + np.array([1.4, 0.9, 0.88], dtype=np.int)#.astype('int')","43b7668f":"torch.tensor(np.array([1, 1.9999, True, -1, 0, np.nan, np.inf]))","271ba24b":"torch.Tensor(np.array([1, 1.9999, True, -1, 0, np.nan, np.inf]))\/torch.Tensor(np.array([1, 1.9999, True, -1, 0, np.nan, np.inf]))","87f71526":"np.array([1, 0, 1, 1, 0], dtype='int8').dtype","7d8ef73f":"torch.tensor([1, 0, 1, 1, 0]).dtype","b119af2c":"torch.tensor(np.array([1, 0, 1, 1, 0], dtype='int8'))","dc88ec77":"torch.Tensor([0, 9])**torch.Tensor([0, 8])","47d9eacc":"x = torch.zeros(5, 3, dtype=torch.bool)\n#print(x.float() + x.int())\nprint(x)","45651d12":"b = np.array([1,2,3,4,5, 12123])\n\nb.astype('int8')","630eb16a":"x = torch.tensor([5.5, 3]).bool()#long()\nprint(x)","3f362e63":"type(torch.float16)","23879892":"x = x.new_ones(5, 3, dtype=torch.double) \nprint(x)\n\n#x = torch.tensor([1, 10, 100, 1000], dtype = torch.float)\n\nx = torch.randn_like(x, dtype=torch.float16)   \nprint(x)                               ","8c39e4a8":"print(x.shape)\nprint(x.size())\n\ntorch.Size([1,3, 4])","c800c899":"y = torch.rand(5, 3)\nprint(y + y)","e4e2fa43":"a = np.array([1,2,3,4])#.reshape(-1,1)\nb = np.array([4,3,2,1])#.reshape(1,-1)\n\nprint(a * b)\nprint(np.dot(a, b))\nprint(a.dot(b))","ebb2ba69":"a = torch.tensor([1,2,3,4])\nb = torch.tensor([4,3,2,1])\n\nprint(a * b)\nprint(torch.dot(a, b))\nprint(torch.dot(b, a))\nprint(a.dot(b))","07ae5ad3":"print(torch.add(torch.tensor(a), torch.tensor(b)))","213a8c46":"torch.add(torch.tensor(a), torch.tensor(b)).cpu().numpy()","0b6692c4":"torch.random.manual_seed(42)\n\nresult = torch.empty(5, 3)\nprint(result)\nx = torch.rand(5, 3)\ny = torch.rand(5, 3)\ntorch.add(x, y, out=result)\nprint(torch.add(x, y))\nprint(result)","1308bdc4":"y + y, y","59bceab4":"print(y)\nprint(y.add_(y)) # y = y.add(y)\nprint(y)","d0652c62":"y.add_(x)\nprint(y)","649fc8ab":"x, x > 0.5, x[x > 0.5]","27d839e6":"print(x[:, 1])","62587a34":"x = torch.randn(6, 6, 2)\nx","54088ef0":"x.view(-1, 3, 3), x.view(1, -1)","e321a252":"x.permute((1,2,0)).shape","a71c290d":"y = x.view(-1, 12)\nz = x.view(-1, 18)  # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())","67ac1853":"x = torch.randn(1)\nprint(x)\nprint(float(x[0]))\nprint(x.item())","bf9d08fb":"a = torch.ones(5)\nprint(np.array(a))","93741099":"b = a.numpy()\nprint(b)","1855120d":"a.add_(1)\nprint(a)\nprint(b)","ccc779fa":"import numpy as np\n\na = np.ones(5)\nb = torch.from_numpy(a)\nd = torch.tensor(a)\nprint(b)\nc = np.ones(5)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)\nprint(c)\nprint(d)","cf8498a4":"print(\"PyTorch version: {0}\\nCUDA version:{1}\\ncuDNN version:{2}\".format(torch.__version__, torch.version.cuda, torch.backends.cudnn.version()))","3a66cfd7":"torch.cuda.get_device_name()","9b749ba4":"x = torch.tensor([1,2,34,5])\nx2 = torch.tensor([1,2,34,5])","f57970b2":"x.cuda().cpu() + x2.to('cuda:0').to('cpu')","4e0fa750":"torch.device(\"cuda\")","3b464dde":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")      \n    y = torch.ones_like(x2, device=device)  \n    x2 = x2.to(device)                       \n    z = x2 + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))\nelse:\n    device = torch.device(\"cpu\")   ","1b66112f":"x2 + x.to(device)","e8af8d08":"x = torch.ones(2, 2, requires_grad=True)\nprint(x)","9541ff8e":"y = x + 2\nprint(y)","5c5b4afa":"y.backward","3717eb9a":"print(y.grad_fn)","40615c1b":"z = y * y * 3\nout = 0-z.mean()\n\nprint(z, out)","5645e3f0":"out.retain_grad()#.backward()","8818828b":"print(out.grad)","f5e789f8":"z.retain_grad()\nz.grad","f3d50288":"a = torch.randn(2, 2)\na = ((a * 3) \/ (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)","9be78031":"out.backward()","86062417":"print(x.grad)","65025394":"print(y.grad)","ec93cb45":"print(z.grad)","aff64002":"x = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\nprint(y)","c96afcb4":"v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\ny.backward(v)\n\nprint(x.grad)","b2e46dd0":"print(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n    print((x ** 2).requires_grad)","950d4c16":"import pandas as pd\n\nflats = pd.read_csv(\"..\/input\/kyiv-real-estate\/class_flat.csv\").select_dtypes(exclude=['object'])\n\nflats = flats.fillna(flats.mean())\n\nflats","8bf3e03f":"from sklearn.preprocessing import MinMaxScaler\n\nflats.iloc[:,1:-1] = MinMaxScaler().fit_transform(flats.iloc[:,1:-1])\n\nflats","4e5266b6":"X = torch.from_numpy(flats.iloc[:,1:-1].values)","ffb7eab1":"import torch.nn.functional as F\nimport torch.nn as nn\n\nlinear_layer = nn.Linear(9, 5)\nlinear_layer2 = nn.Linear(5, 1)\n#relu = nn.ReLU()\n\n#relu(linear_layer2(linear_layer(X.float())))\n\nF.relu(linear_layer2(linear_layer(X.float())))","986cc16f":"list(linear_layer.parameters()), list(linear_layer2.parameters())","2e913cd7":"class Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.linear_layer = nn.Linear(9, 5)\n        self.linear_layer2 = nn.Linear(5, 1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.linear_layer(x))\n        x = self.relu(self.linear_layer2(x))\n        return x\n\nnet = Net().cuda()","ae4b0e64":"#X = []\n#\n#for i in range(flats.shape[0]):\n#    X.append(flats.iloc[i,1:-1].values.reshape(-1, 9, 1).dot(flats.iloc[i,1:-1].values.reshape(-1, 1, 9)).reshape(1,9,9))\n#    \n#X = torch.from_numpy(np.array(X)).float()\n#X","3edcf0fe":"X.shape","f9920da6":"#import torch.nn.functional as F\n#import torch.nn as nn\n#\n#print(nn.Conv2d(1, 3, 2)(X).shape)\n#print(F.relu(nn.Conv2d(1, 3, 2)(X)).shape)\n#F.max_pool2d(F.relu(nn.Conv2d(1, 3, 2)(X)), (2, 2)).shape","f02c4cd3":"#x","90011257":"#x = X\n#\n#def num_flat_features(x):\n#    size = x.size()[1:]  \n#    num_features = 1\n#    for s in size:\n#        num_features *= s\n#    return num_features\n#\n#x = F.max_pool2d(F.relu(nn.Conv2d(1, 3, 3)(x)), (2, 2))\n#print(x.shape)\n#x = F.max_pool2d(F.relu(nn.Conv2d(3, 4, 2)(x)), 2)\n#print(x.shape)\n#x = x.view(-1, num_flat_features(x))\n#print((x < 0).sum())\n#print(x.shape)\n#x = F.relu(nn.Linear(4, 8)(x))\n#print(x.shape)\n#x = F.relu(nn.Linear(8, 4)(x))\n#print(x.shape)\n#x = F.sigmoid(nn.Linear(4, 1)(x))\n#print(x.shape)\n#x","8c7825a2":"#import torch\n#import torch.nn as nn\n#import torch.nn.functional as F\n#\n#class Net(nn.Module):\n#\n#    def __init__(self):\n#        super(Net, self).__init__()\n#        # 1 input image channel, 6 output channels, 3x3 square convolution\n#        # kernel\n#        self.conv1 = nn.Conv2d(1, 30, 2)\n#        self.conv2 = nn.Conv2d(30, 4, 2)\n#        # an affine operation: y = Wx + b\n#        self.flatten = nn.Linear(4, 8)\n#        self.fc2 = nn.Linear(8, 4)\n#        self.fc3 = nn.Linear(4, 1)\n#\n#    def forward(self, x):\n#        # Max pooling over a (2, 2) window\n#        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n#        # If the size is a square you can only specify a single number\n#        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n#        x = x.view(-1, self.num_flat_features(x))\n#        x = F.relu(self.flatten(x))\n#        x = F.relu(self.fc2(x))\n#        x = F.sigmoid(self.fc3(x))\n#        return x\n#\n#    def num_flat_features(self, x):\n#        size = x.size()[1:]  # all dimensions except the batch dimension\n#        num_features = 1\n#        for s in size:\n#            num_features *= s\n#        return num_features\n#\n#\n#net = Net().cuda()\n#print(net)","068f45a5":"#net.flatten.out_features","51422b53":"list(net.parameters())","ca08fb03":"#params = list(net.parameters())\n#print(len(params))\n#print(params[0].size())  # conv1's .weight","9cbb2151":"#input = torch.from_numpy(flats.iloc[:,1:-1].values.reshape(-1, 9, 1).dot(flats.iloc[:,1:-1].values.reshape(-1, 1, 9)).reshape(1,1,9,9)).float()\n#input","73dbd0d1":"#input = torch.randn(1, 1, 32, 32)\n#net = net.float()\n#out = net(X)\n#print(out)","95d617a4":"#net.zero_grad()\n#out.backward(torch.randn(14066,1))","07fb3946":"X = X.float().cuda()","69ed4250":"output = net(X)\n\noutput","df0f6fad":"target = torch.tensor(flats.bad_proposal.values.reshape(1,-1)).float()  # a dummy target, for example\ntarget = target.view(-1, 1).cuda() # make it the same shape as output\nprint(target)","af38f12a":"criterion = nn.BCELoss()\n\nloss = criterion(output, target)\nprint(loss)","ffa9c95e":"print(loss.grad_fn(torch.tensor(0).float().cuda())) \nprint(loss.grad_fn.next_functions[0][0])  # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])  # ReLU","f49663ed":"net.linear_layer.weight, net.linear_layer.bias","c4dbe407":"net.zero_grad()     # zeroes the gradient buffers of all parameters\n\nprint('linear_layer.grad before backward')\nprint(net.linear_layer.bias.grad)\n\nloss.backward()\n\nprint('linear_layer.bias.grad after backward')\nprint(net.linear_layer.bias.grad)","1c3a30c6":"import torch.optim as optim\n\noptimizer = optim.Adam(net.parameters(), lr=0.001)","b1e97585":"X_train = X[:10000, :]\nX_valid = X[10000:, :]\ny_train = target[:10000, :]\ny_valid = target[10000:, :]","413f2cef":"from sklearn.metrics import roc_auc_score\n\noptimizer.zero_grad()\n\nbest_score = 0.5\n\nfor epoche in range(100):\n    net.train()\n    output = net(X_train)\n    loss = criterion(output, y_train)\n    print(\"Train Loss BCE on epoche {}: {}\".format(epoche, loss))\n    loss.backward()\n    optimizer.step()\n  \n    with torch.no_grad():\n        net.eval()\n        output = net(X_valid)\n        loss = roc_auc_score(y_valid.cpu().numpy(), output.cpu().numpy())\n        print(\"Valid Loss BCE on epoche {}: {}\".format(epoche, loss))\n        if best_score < loss:\n            torch.save(output, \"output.pth\")\n            best_score = loss","6756b70c":"list(net.parameters())","9dcfa348":"output.mean(), output.min(), output.max()","88a8a0c7":"output.cpu().numpy()","b42ba295":"roc_auc_score(y_valid.cpu().numpy(), output.cpu().numpy())","08f879fa":"All the Tensors on the CPU except a CharTensor support converting to\nNumPy and back.\n\nCUDA Tensors\n------------\n\nTensors can be moved onto any device using the ``.to`` method.\n\n","b84a0db1":"\nAutograd: Automatic Differentiation\n===================================\n\nCentral to all neural networks in PyTorch is the ``autograd`` package.\nLet\u2019s first briefly visit this, and we will then go to training our\nfirst neural network.\n\n\nThe ``autograd`` package provides automatic differentiation for all operations\non Tensors. It is a define-by-run framework, which means that your backprop is\ndefined by how your code is run, and that every single iteration can be\ndifferent.","ac04f24a":"If you have a one element tensor, use ``.item()`` to get the value as a\nPython number\n\n","7a1679f8":"Get its size:\n\n","ee58bcc9":"Construct a randomly initialized matrix:\n\n","eda59dbd":"NumPy Bridge\n------------\n\nConverting a Torch Tensor to a NumPy array and vice versa is a breeze.\n\nThe Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other.","a128f62a":"See how the numpy array changed in value.\n\n","12f7bfa0":"``torch.Size`` is in fact a tuple, so it supports all tuple operations.","7a167a81":"Zero the gradient buffers of all parameters and backprops with random\ngradients:\n\n","d0617549":"You can also stop autograd from tracking history on Tensors\nwith ``.requires_grad=True`` by wrapping the code block in\n``with torch.no_grad():``\n\n","7bda7d22":"or create a tensor based on an existing tensor. These methods\nwill reuse properties of the input tensor, e.g. dtype, unless\nnew values are provided by user\n\n","4a6f54b8":"Gradients\n---------\nLet's backprop now.\nBecause ``out`` contains a single scalar, ``out.backward()`` is\nequivalent to ``out.backward(torch.tensor(1.))``.\n\n","1fc1ffbe":"``y`` was created as a result of an operation, so it has a ``grad_fn``.\n\n","7724bf5b":"Resizing: If you want to resize\/reshape tensor, you can use ``torch.view``:\n\n","1d428a41":"Do a tensor operation:\n\n","728aee45":"# Pytorch","b34b66da":"``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n    package only supports inputs that are a mini-batch of samples, and not\n    a single sample.\n    \n\nLoss Function\n-------------\nA loss function takes the (output, target) pair of inputs, and computes a\nvalue that estimates how far away the output is from the target.\n","d7f0e8a0":"Update the weights\n------------------\nThe simplest update rule used in practice is the Stochastic Gradient\nDescent (SGD):\n\n     ``weight = weight - learning_rate * gradient``","52213b23":"Print gradients d(out)\/dx\n\n\n","a9256ac1":"Addition: in-place\n\n","bab993f5":"\nNeural Networks\n===============\n\nNeural networks can be constructed using the ``torch.nn`` package.\n\nNow that you had a glimpse of ``autograd``, ``nn`` depends on\n``autograd`` to define models and differentiate them.\nAn ``nn.Module`` contains layers, and a method ``forward(input)``\\ that\nreturns the ``output``.\n\nIt is a simple feed-forward network. It takes the input, feeds it\nthrough several layers one after the other, and then finally gives the\noutput.\n\nA typical training procedure for a neural network is as follows:\n\n- Define the neural network that has some learnable parameters (or\n  weights)\n- Iterate over a dataset of inputs\n- Process input through the network\n- Compute the loss (how far is the output from being correct)\n- Propagate gradients back into the network\u2019s parameters\n- Update the weights of the network, typically using a simple update rule:\n  ``weight = weight - learning_rate * gradient``\n\nDefine the network\n------------------\n","edacda54":"Converting NumPy Array to Torch Tensor\n","f60b096f":"Backprop\n--------\nTo backpropagate the error all we have to do is to ``loss.backward()``.\nYou need to clear the existing gradients though, else gradients will be\naccumulated to existing gradients.\n\n\nNow we shall call ``loss.backward()``, and have a look at conv1's bias\ngradients before and after the backward.\n\n","b882bd5f":"**Read Later:**\n\nDocumentation of ``autograd`` and ``Function`` is at\nhttps:\/\/pytorch.org\/docs\/autograd\n\n","77dd2343":"``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\nflag in-place. The input flag defaults to ``False`` if not given.\n\n","4fbc3b1c":"Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n\nFor example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n\nYou can use standard NumPy-like indexing with all bells and whistles!\n\n","ba8fe671":"Create a tensor and set ``requires_grad=True`` to track computation with it\n\n","acbcda4a":"\nWhat is PyTorch?\n================\n\nIt\u2019s a Python-based scientific computing package targeted at two sets of\naudiences:\n\n-  A replacement for NumPy to use the power of GPUs\n-  a deep learning research platform that provides maximum flexibility\n   and speed\n\nTensors\n---------------\n\n\nTensors are similar to NumPy\u2019s ndarrays, with the addition being that\nTensors can also be used on a GPU to accelerate computing.\n\n","094d63cf":"Do more operations on ``y``\n\n","c34c6bbe":"Construct a tensor directly from data:\n\n"}}