{"cell_type":{"37a6c397":"code","c2703805":"code","d8731171":"code","54f45592":"code","7f782aa3":"code","5750dbf4":"code","efee923e":"code","c34a777f":"code","62eea0b2":"code","f8fea58c":"code","dc2270ad":"code","02e8b695":"code","07783ce1":"code","7ca6ae25":"code","125876dc":"code","71d30a01":"code","a0e233b7":"code","fcaa9f0a":"code","375961ff":"code","92e6a061":"code","a894c177":"markdown","f8de61cc":"markdown","d78ce9b0":"markdown","67da3a98":"markdown","2efc541c":"markdown","a646e405":"markdown","2ab4ffed":"markdown","f878903e":"markdown","ece401d2":"markdown","29e6fd46":"markdown","dac9643d":"markdown","2e4e02b3":"markdown","c1d15491":"markdown","2ff4e52c":"markdown","f674653c":"markdown","489bebf1":"markdown","3f83ec5b":"markdown","05101eb6":"markdown","41f2c84f":"markdown","a68ee281":"markdown"},"source":{"37a6c397":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","c2703805":"df = pd.read_csv('..\/input\/datasetknn\/DataSetKNN.csv')","d8731171":"df.head()","54f45592":"sns.set_style('whitegrid')\nsns.pairplot(df, hue='TARGET CLASS')","7f782aa3":"from sklearn.preprocessing import StandardScaler","5750dbf4":"scaler = StandardScaler()","efee923e":"scaler.fit(df.drop('TARGET CLASS', axis=1))","c34a777f":"scaled_features = scaler.transform(df.drop('TARGET CLASS', axis=1))","62eea0b2":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()","f8fea58c":"from sklearn.model_selection import train_test_split","dc2270ad":"X = df_feat\ny = df['TARGET CLASS']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","02e8b695":"from sklearn.neighbors import KNeighborsClassifier","07783ce1":"knn = KNeighborsClassifier(n_neighbors=1)","7ca6ae25":"knn.fit(X_train, y_train)","125876dc":"pred = knn.predict(X_test)","71d30a01":"from sklearn.metrics import classification_report,confusion_matrix","a0e233b7":"print(confusion_matrix(y_test,pred))\nprint(classification_report(y_test,pred))","fcaa9f0a":"error_rate = []\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))    ","375961ff":"sns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue',linestyle='dashed', marker='o',\n        markerfacecolor='red',markersize='10')\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","92e6a061":"knn = KNeighborsClassifier(n_neighbors=18)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\n\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","a894c177":"## Get the Data\n** Read the 'KNN_Project_Data csv file into a dataframe **","f8de61cc":"# Choosing a K Value\n\nCreating a for loop that trains various KNN models with different k values, then keeping track of the error_rate for each of these models with a list. ","d78ce9b0":"# Train Test Split\n\n**Use train_test_split to split your data into a training set and a testing set.**","67da3a98":"** Create a confusion matrix and classification report.**","2efc541c":"## Retrain with new K Value\n\n**Retrain the model with the best K value and re-doing the classification report and the confusion matrix.**","a646e405":"** Fit scaler to the features.**","2ab4ffed":"# Predictions and Evaluations\nLet's evaluate our KNN model!","f878903e":"**Fit this KNN model to the training data.**","ece401d2":"___\n\n<a href='http:\/\/www.pieriandata.com'> <img src='..\/Pierian_Data_Logo.png' \/><\/a>\n___","29e6fd46":"**Use the predict method to predict values using your KNN model and X_test.**","dac9643d":"# K Nearest Neighbors Project \n\n\n## Import Libraries\n**Import pandas,seaborn, and the usual libraries.**","2e4e02b3":"** Create a StandardScaler() object called scaler.**","c1d15491":"# Using KNN\n\n**Import KNeighborsClassifier from scikit learn.**","2ff4e52c":"**Create a KNN model instance with n_neighbors=1**","f674653c":"**Check the head of the dataframe.**","489bebf1":"**Convert the scaled features to a dataframe and check the head of this dataframe to make sure the scaling worked.**","3f83ec5b":"**Now create the following plot using the information from your for loop.**","05101eb6":"# Standardize the Variables\n\nTime to standardize the variables.\n\n** Import StandardScaler from Scikit learn.**","41f2c84f":"**Use the .transform() method to transform the features to a scaled version.**","a68ee281":"# EDA\n\nSince this data is artificial, we'll just do a large pairplot with seaborn.\n\n**Use seaborn on the dataframe to create a pairplot with the hue indicated by the TARGET CLASS column.**"}}