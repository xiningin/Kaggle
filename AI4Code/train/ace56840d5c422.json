{"cell_type":{"f38d78ec":"code","3786338c":"code","a03f2f4f":"code","280418ec":"code","3b109580":"code","233f67ef":"code","c6bf8654":"code","279b4e6d":"code","fca89777":"code","983cf40b":"code","5b85e2e8":"code","ad47b287":"code","895ff96d":"code","f2837d29":"markdown","aa796046":"markdown","9839e3ac":"markdown","868f796e":"markdown","2e88e3df":"markdown","6d306f75":"markdown","14f1b507":"markdown","1b8e30e5":"markdown","5a741be5":"markdown","89aa0787":"markdown","45367cdd":"markdown","571d913f":"markdown","7252e496":"markdown","ea40716e":"markdown","6a4ddc9b":"markdown"},"source":{"f38d78ec":"# Import dependencies\nimport os\nimport cv2\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom numpy import random\nfrom IPython.display import display\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import save_model\nfrom keras.callbacks import EarlyStopping","3786338c":"# Path to raw data\ndata_path = \"..\/input\/traffic-signs-classification\/myData\"\n\n# Listing sub directories\nsub_directories = os.listdir(data_path)\n\n# Loading labels\nlabels = pd.read_csv(\"..\/input\/traffic-signs-classification\/labels.csv\")","a03f2f4f":"# Finding number of classes in the data\nprint(\"Number of Classes: \",len(sub_directories))","280418ec":"# Finding number of images under each class\nno_of_images = []\nfor directory in sub_directories:\n    no_of_images.append(len(os.listdir(os.path.join(data_path, directory))))\n\nlabels[\"n_samples\"] = no_of_images\nlabels.sort_values([\"n_samples\"], inplace=True)\n\n# Displaying DataFrame containing class name, directory name and number of samples \ndisplay(labels)","3b109580":"# Visualising number of samples under each class\nf, ax = plt.subplots(figsize=(20, 7))\nsns.barplot(x=labels[\"Name\"], y=labels[\"n_samples\"], palette=\"deep\")\nplt.xlabel(\"CLASS NAME\")\nplt.ylabel(\"NUMBER OF SAMPLES\")\nplt.xticks(rotation=90)\nplt.show()","233f67ef":"# checking resolution of the images\nres = cv2.imread(os.path.join(data_path, sub_directories[0], os.listdir(os.path.join(data_path, sub_directories[0]))[0])).shape\nprint(\"Height: \", res[0])\nprint(\"Width: \", res[1])\nprint(\"Number of Channels: \", res[2])\nprint(\"Resolution: {}x{}\".format(res[0], res[1]))","c6bf8654":"# displaying some images randomly from each class\nfig = plt.figure(figsize=(40, 30))\nrows = 8\ncols = 6\nfor directory in sub_directories:\n    current_dir_files = os.listdir(os.path.join(data_path, directory))\n    img = cv2.imread(os.path.join(data_path, directory, current_dir_files[random.randint(len(current_dir_files))]))\n    fig.add_subplot(rows, cols, int(directory)+1)\n    plt.imshow(img)\n    plt.title(labels[\"Name\"][int(directory)], fontsize=14)","279b4e6d":"# Data Generators will augment the data and feed it to our models\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                             rotation_range=20,\n                             zoom_range=0.2,\n                             fill_mode=\"nearest\").flow_from_directory(\"..\/input\/traffic-signs-train-val-split\/traffic signs split\/train\",\n                                                                      target_size=(32, 32),\n                                                                      batch_size=32,\n                                                                      class_mode=\"categorical\")\n\nval_datagen = ImageDataGenerator(rescale=1.\/255).flow_from_directory(\"..\/input\/traffic-signs-train-val-split\/traffic signs split\/val\",\n                                                                     target_size=(32, 32),\n                                                                     batch_size=32,\n                                                                     class_mode=\"categorical\")","fca89777":"# Function to create model\ndef create_model(activation=\"relu\"):\n    \n    \"\"\" Creates and returns image classification model.\n    \n    Args:\n        activation (str): Activation function to be used in first \n                          few layers.\n    Returns:\n        model (tensorflow model): Compiled image classification model.\n    \"\"\"\n    \n    model = Sequential()\n    model.add(Conv2D(16, (3,3), activation=activation, input_shape=(32, 32, 3)))\n    model.add(MaxPool2D(2, 2))\n    model.add(Conv2D(32, (3,3), activation=activation))\n    model.add(MaxPool2D(2, 2))\n    model.add(Conv2D(64, (3,3), activation=activation))\n    model.add(Flatten())\n    model.add(Dense(512, activation=activation))\n    model.add(Dense(256, activation=\"tanh\"))\n    model.add(Dense(128, activation=\"tanh\"))\n    model.add(Dense(43, activation=\"softmax\"))\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","983cf40b":"# Creating model\nTrafficSignRecogniser = create_model()\n\n# Displays model architecture\nTrafficSignRecogniser.summary()","5b85e2e8":"# Trains the model\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=100, patience=5)\nhistory = TrafficSignRecogniser.fit_generator(train_datagen, validation_data=val_datagen, epochs=20, verbose=100, callbacks=[es])","ad47b287":"# Plots training loss and validation loss from training history\nhistory_dict = history.history\ntrain_acc = history_dict['loss']\nval_acc = history_dict['val_loss']\nepochs = range(1, len(history_dict['loss'])+1)\nplt.plot(epochs, train_acc,'b', label='Training error')\nplt.plot(epochs, val_acc,'b', color=\"orange\", label='Validation error')\nplt.title('Training and Validation error')\nplt.xlabel('Epochs')\nplt.ylabel('Error')\nplt.legend()\nplt.show()","895ff96d":"# Saves the model\nsave_model(TrafficSignRecogniser, \"TrafficSignRecogniser\")","f2837d29":"# **Defining and Compiling the model:**","aa796046":"# **Plotting the Error:**","9839e3ac":"**Read About Convolutional Networks:**\n<br>https:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","868f796e":"# **Data:**\n\n> **Raw Data:** https:\/\/www.kaggle.com\/flo2607\/traffic-signs-classification<br><br>\n> **Train-Val Split:** https:\/\/www.kaggle.com\/balamurugan1603\/traffic-signs-train-val-split","2e88e3df":"# **Doing a quick EDA:**","6d306f75":"# **Traffic Sign Recognition using CNN**","14f1b507":"*Before creating ImageDataGenerator object, We must prepare data which is compatible with ImageDataGenerator. So, I have created a different dataset where I have split the data into training and validation sets which is the one I used here.*","1b8e30e5":"# **Data Augmentation:**","5a741be5":"# **Training the model:**","89aa0787":"# **Dependencies:**","45367cdd":"By: [Balamurugan P](https:\/\/www.linkedin.com\/in\/bala-murugan-62073b212\/)\n\n> **TASK** : To classify traffic signs into 43 distinct classes.","571d913f":"*From the visulization, It is clear that our dataset has class imbalance.*","7252e496":"*EDA was done on data before splitting them into training and validation sets.*","ea40716e":"![image.png](attachment:0bca8834-25be-4fef-8530-4a08e4c216e9.png)","6a4ddc9b":"# **Saving the model:**"}}