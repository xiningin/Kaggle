{"cell_type":{"09723ea6":"code","20a4a957":"code","6fa906de":"code","839f1f7d":"code","8d2c6c5d":"code","31c8b684":"code","a5088c0e":"code","449e450a":"code","1542616a":"code","e9924c7b":"code","883cc8a1":"code","bb44e7e6":"code","4e858754":"code","f0ede866":"code","75314cb0":"code","35571090":"code","44de4887":"code","6209d1c2":"code","a605a8ea":"code","f993124a":"code","36294f18":"code","1e346e74":"code","8bbb0737":"code","e2b53e55":"code","c201fc69":"code","a1aede89":"code","f555ced0":"code","23e3ff57":"code","cbff3de3":"code","fb1e55d0":"code","299774fd":"code","493edcd1":"code","e638a31e":"code","ad159452":"code","f7fd1c0d":"code","0b5ce31a":"code","e6251006":"code","68450401":"code","020ea558":"code","ff9303f7":"code","58d89cd8":"code","812b459f":"markdown","6136b984":"markdown","cb48d199":"markdown","5d014f38":"markdown","beb8bf1a":"markdown","ec97ed9e":"markdown","613cc67c":"markdown","242ebc08":"markdown","b3cfcf6f":"markdown","bde54231":"markdown","a9ed1a2b":"markdown","0b2059ce":"markdown","a009e187":"markdown","8b8ac0d2":"markdown","178a8afb":"markdown","e18f7498":"markdown","5cb9ffcc":"markdown","044306b7":"markdown","051c9c72":"markdown","9e1197e6":"markdown","60bd73fd":"markdown","33d51341":"markdown","d2a332d0":"markdown","4d974c1b":"markdown","ffb79d21":"markdown","a5882f91":"markdown","e8ce35b0":"markdown","eae58cab":"markdown","04b6f147":"markdown","1bb01cb8":"markdown","1e0ccc8b":"markdown","75006c0d":"markdown","040cd188":"markdown","eea9d801":"markdown","2d14a946":"markdown","51393ae6":"markdown","76b7461d":"markdown","90a16e6f":"markdown","683e7ddb":"markdown","02716901":"markdown","3d3c3239":"markdown","de8e64bc":"markdown","7bf3ef7a":"markdown","2627db65":"markdown"},"source":{"09723ea6":"import os\nimport spacy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom textwrap import wrap","20a4a957":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        data = pd.read_csv(os.path.join(dirname, filename))","6fa906de":"data.head()","839f1f7d":"data.describe()","8d2c6c5d":"data.info()","31c8b684":"data.columns","a5088c0e":"data.isnull().sum()","449e450a":"data['Cabin'] = data['Cabin'].fillna(0)","1542616a":"data = data.dropna(axis=0)","e9924c7b":"data.isnull().sum()","883cc8a1":"data.groupby(data['Pclass']).mean()","bb44e7e6":"data.groupby(data['Pclass']).count()","4e858754":"import warnings\nwarnings.simplefilter('ignore')\nPclass = data.groupby(data['Pclass'])['Pclass'].count()\nsns.factorplot('Pclass', data=data, kind='count', aspect=1)\nplt.xlabel('class')\nplt.title('Classes')","f0ede866":"sns.factorplot('Pclass', data = data, hue = 'Sex', kind='count')","75314cb0":"pd.crosstab(index=data['Pclass'], columns=[data['Sex']],\n            margins=True).style.background_gradient(cmap='YlGn')","35571090":"data.Parch\ndata['parched'] = data['Parch'].apply(lambda x: x>0)\nparched = data[data['parched'] == True]\nparched['parched'].value_counts()","44de4887":"parched.head()","6209d1c2":"plt.hist(data['Parch'])\nplt.xlabel('parch')\nplt.ylabel('counts')\nplt.title('Histogram of parch')","a605a8ea":"pd.crosstab(index=data['Parch'], columns=[data['Pclass'], data['Sex']],\n            margins=True).style.background_gradient(cmap='YlGn')","f993124a":"pd.pivot_table(data=data, index='Sex', values='Ticket',\n                    columns='Embarked', aggfunc=len, margins=True)","36294f18":"pd.DataFrame(data.groupby('Ticket')['Fare'].mean())","1e346e74":"sample = data.sample(frac=0.2, random_state=2)\nprint(sample.shape)\nsample.tail()","8bbb0737":"fig, ax = plt.subplots(figsize=(17, 3))\nsns.histplot(x=\"Fare\", kde=True, data=sample)\nfig.suptitle('Distribution of Ticket\\'s price', fontsize=15)","e2b53e55":"sns.kdeplot(\n   data=sample,x='Pclass',y=\"Fare\",\n   fill=True, common_norm=False, palette=\"crest\",\n   alpha=.5, linewidth=0,\n)\nplt.title(\"Conditional distributions\")","c201fc69":"pd.crosstab(index=data['Fare'], columns=[data['Embarked'], data['Parch']],\n            margins=True)","a1aede89":"data.groupby(data['SibSp'])['SibSp'].count()","f555ced0":"pd.crosstab(index=data['SibSp'], columns=[data['Pclass']],\n            margins=True).style.background_gradient(cmap='YlGn')","23e3ff57":"print('Data type of siblings:', data['SibSp'].dtype, '\\n')","cbff3de3":"SibSp = (data.SibSp).values\nm = []\nfor i in range(SibSp.shape[0]):\n    m.append(np.mean(SibSp))\nplt.plot(SibSp, label='siblings')\nplt.plot(m, linewidth=3, color='r', label='Median')\nplt.legend()\nplt.title(\"Checking siblings outliers\")","fb1e55d0":"z = np.abs(stats.zscore(SibSp))\nprint(z)","299774fd":"plt.plot(z, c='g', alpha=0.3)\nplt.ylabel('Distance')\nplt.xlabel('index')\nplt.title('Distance of the SibSp value from the average')","493edcd1":"plt.boxplot(data['SibSp'], 0,'o',showbox=True,\n            showfliers=True, showcaps=True, showmeans=True)","e638a31e":"Q1 = np.percentile(SibSp, 25, interpolation='midpoint')\nQ3 = np.percentile(SibSp, 65, interpolation='midpoint')\nIQR = Q3 - Q1\nupper = np.where(SibSp>=(Q3+1.5*IQR))\nlower = np.where(SibSp<=(Q1-1.5*IQR))\nnewSibSp = pd.DataFrame(SibSp)\nnewSibSp.drop(upper[0], inplace=True)\nnewSibSp.drop(lower[0], inplace=True)\nprint(newSibSp.shape)\nnewSibSp.head()","ad159452":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.boxplot(newSibSp, 0,'o',showbox=True,\n            showfliers=True, showcaps=True, showmeans=True)\nplt.title(\"Modified Siblings\")\nplt.subplot(2,2,2)\nplt.boxplot(data['SibSp'], 0,'o',showbox=True,\n            showfliers=True, showcaps=True, showmeans=True)\nplt.title(\"Siblings real values\")","f7fd1c0d":"name = data.Name\nname = name.values\nlen(np.unique(name))","0b5ce31a":"print(\"Names:\", name)","e6251006":"names = data['Name'].apply(lambda x: x.split(', ')[0])","68450401":"names","020ea558":"data['titles'] = data['Name'].str.extract('([A-Za-z]+)\\.')\npd.crosstab(data.titles,data.Pclass).T.style.background_gradient(cmap='Set1_r')","ff9303f7":"LowerCase = names.apply(lambda x: x.lower())\nLowerCase","58d89cd8":"name = \" \".join(name for name in names)\n\nfor i in range(4):\n    wordcloud = WordCloud(width=400, height=400, max_font_size=50, max_words=70, colormap=\"Dark2\").generate(name).generate(name)\n    plt.figure(figsize=(10,10))\n    plt.subplot(2,2,i+1)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")","812b459f":"## Studying the siblings of the passengers","6136b984":"# Data cleaning","cb48d199":"# Studying the Name","5d014f38":"**Exploring the sex in each class and the values of parch**","beb8bf1a":"I tool the advantages of the pivot table from pandas. This table gives us a better dashboard table.","ec97ed9e":"The table shows that the third class was like the first_class as we can observe the \"Master\" title here.","613cc67c":"Extracting the counts of parach","242ebc08":"# Studying the Pclass","b3cfcf6f":"# About this notebook\n\nIn the following notebook, I reviewed the Titanic (test) dataset. \nI tried to examine the different parts of the dataset to have more insight into the issue.\n\n<img src= \"https:\/\/www.historic-uk.com\/wp-content\/uploads\/2017\/04\/the-sinking-of-the-rms-titanic.jpg\" alt =\"Titanic\" style='width: 300px;' class=\"center\">\n\nEach feature has been studied separately in related cells. I tried to include data description, data cleaning, statistical description, data distribution, correlations, and relationships in this notebook.\n\n\n\n<h4>If you are interested in this problem and detailed analysis, you can copy this Notebook as follows<\/h4>\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">\n  \n\n::: Updates :::\n* Last update: 08.Jul.2021\n* Updates: \n        * Add more methods to text analyzing\n        * Reviewd the Ticket part","bde54231":"Checking the outliers and dealing with them","a9ed1a2b":"> From the above plot, we observe some out range data that has a high distance to the mean.\n\nSo, we saw that there are some data with high distances. How about measuring the real gaps to the average? For this matter, I calculated it as following.","0b2059ce":"#### Total of passengers with regard to the port","a009e187":"# Table of contents\n\n* Importing Libraries\n* Obtaining Data\n* Overview\n    * Data description\n    * Data types\n* Data cleaning\n    * Missing values\n* \"Pclass\"\n* \"Parch\"\n* \"Ticket\"\n    * Ticket price\n* \"Siblings\"\n    * Outliers\n* \"Name\"\n    * Separating\n    * Word cloud","8b8ac0d2":"## Check Data description","178a8afb":"# Studying the Ticket","e18f7498":"# Importing Libraries\n","5cb9ffcc":"For the purpose of **NLP**, we could convert all letters to **lower case**. I used the lower function to do that.","044306b7":"## Outliers treatment","051c9c72":"From the following plot, we can observe the number of passengers of each class with regard to their sex. ","9e1197e6":"We can observe that most of the passengers had no siblings.","60bd73fd":"Here, let's see the updated box plot, in the following plot, we do not have any outliers as before.","33d51341":"85 samples have Parched","d2a332d0":"## Sampling the dataset","4d974c1b":"Another way to check these outliers is the box plot. Besides the quarters, mean and median, It will give us the area above or below the Max\/Min of the data.","ffb79d21":"We can see the first row of Parch has the highest values for all genders and classes. The highest value goes to the third class, which is regarding the men.","a5882f91":"The third class has the highest population on the ship, and most of them (almost 66%) are men.","e8ce35b0":"# An overview of dataset","eae58cab":"# Obtaining Data","04b6f147":"****\n**The price of each boarding a ship**","1bb01cb8":"**Checking the number of men and women in each class**","1e0ccc8b":"Printing the data file information, including size, Dtype, number of attributes, etc.","75006c0d":"# Studying the Parch","040cd188":"****In memorial of the passengers, I prefer to print all the names****","eea9d801":"> Based on the IQR definition, I defined the upper and lower bounds to drop the part of the feature values which I do not want in my experiments.","2d14a946":"Printing out the columns' names for further reviews","51393ae6":"Grouping different columns to extract detailed and summary info concerning various features.","76b7461d":"Checking the simple statistical description of the problem","90a16e6f":"I market the NaN values for \"*Cabin*\" feature to zero, to extend the experiments with the current data","683e7ddb":"## Reviewing the Ticket price","02716901":"## Check missing values","3d3c3239":"## Histogram of the ticket's price over a random sample","de8e64bc":"## Word cloud","7bf3ef7a":"## Splitting the names","2627db65":"## Check the data types"}}