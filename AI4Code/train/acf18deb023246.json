{"cell_type":{"a7125bb3":"code","e7b60b7c":"code","b98fd0ed":"code","7e25861d":"code","2fcbe676":"code","85ca8126":"code","603c73c8":"code","0897ba4b":"code","2cdd763a":"code","31cf8bd9":"code","4d5a01b6":"code","a4c6a8e7":"code","c3b55461":"code","920a7cd9":"code","da999802":"code","cea31c68":"code","2a473c89":"code","87e9a2b9":"markdown","2ea2941e":"markdown","f84fb3ba":"markdown","a5ed5305":"markdown","0c0f419e":"markdown","65a4255e":"markdown","2adb42f8":"markdown","c757ecb0":"markdown","132ea499":"markdown","5402fa54":"markdown","86ef10ec":"markdown","dd5f1974":"markdown"},"source":{"a7125bb3":"!pip install -U lightautoml","e7b60b7c":"!pip install vininfo","b98fd0ed":"# Standard python libraries\nimport logging\nimport os\nimport time\nimport requests\nimport re\nlogging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task","7e25861d":"from vininfo import Vin","2fcbe676":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 40 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 5400 # Time in seconds for automl run\nTARGET_NAME = 'final_price' # Target column name","85ca8126":"%%time\n\ntrain_data = pd.read_csv('..\/input\/lightautomlcourse-hw1\/train_data.csv')\ntrain_data.head()","603c73c8":"test_data = pd.read_csv('..\/input\/lightautomlcourse-hw1\/test_data.csv')\ntest_data.head()","0897ba4b":"submission = pd.read_csv('..\/input\/lightautomlcourse-hw1\/sample_submission.csv')\nsubmission.head()","2cdd763a":"%%time\n\ndef get_model(name):\n    if type(name)==str:\n        name=name.lower()\n        model_search = re.search('(\\d\\d+)', name)\n        if model_search:\n            return model_search.group(1)\n    return name\n\ndef get_model2(name):\n    if type(name)==str:\n        model_search = re.search('([\\w\\-]+)', name)\n        if model_search:\n            return model_search.group(1)\n    return name\n\ndef create_expert_feats(data):\n    data['current_mileage_over'] = data['current_mileage'].map(lambda x: False if x<750000 else True)\n \n    data['vehicle_model2'] = data['vehicle_model'].apply(get_model)\n    data['vehicle_model2'] = data['vehicle_model2'].apply(get_model2)\n    \n    data['has_vin'] = data[\"car_vin\"].map(lambda x: 1 - int(type(x) == float))\n    data[\"car_vin\"] = data[\"car_vin\"].map(lambda x: x if (type(x) != float and \\\n                      len(x)==19 and 'O' not in x and 'Q' not in x and 'I' not in x and \\\n                      Vin(x).verify_checksum()) else np.nan)\n    \n    data['vin_vds'] = data[\"car_vin\"].map(lambda x: Vin(x).vds[0:5] if (type(x) != float) else x)\n    data['vin_wmi'] = data[\"car_vin\"].map(lambda x: Vin(x).wmi if (type(x) != float) else x)\n    data['vin_wmi_vds'] = data['vin_wmi'] + data['vin_vds']\n    data['vin_country'] = data[\"car_vin\"].map(lambda x: Vin(x).country if (type(x) != float) else x)\n    data['vin_region'] = data[\"car_vin\"].map(lambda x: Vin(x).region if (type(x) != float) else x)\n    \n    data['used_years'] = 2021 - data['vehicle_year']\n\n    data['mileage_at_year'] = data['current_mileage'] \/ data['used_years']\n\ncreate_expert_feats(train_data)\ncreate_expert_feats(test_data)","31cf8bd9":"train_data.head()","4d5a01b6":"%%time\n\ntask = Task('reg', loss='mae', metric='mae')","a4c6a8e7":"%%time\n\nroles = {'target': TARGET_NAME,\n         'drop': [\n             'row_ID',\n         ],\n         }","c3b55461":"%%time \n\nautoml = TabularUtilizedAutoML(task = task,\n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                      )\noof_pred = automl.fit_predict(train_data, roles = roles)\nlogging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))","920a7cd9":"%%time\n\n# Fast feature importances calculation\nfast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)","da999802":"%%time\n\ntest_pred = automl.predict(test_data)\nlogging.info('Prediction for test data:\\n{}\\nShape = {}'\n              .format(test_pred, test_pred.shape))\n\nlogging.info('Check scores...')\nlogging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))","cea31c68":"submission[TARGET_NAME] = test_pred.data[:, 0]\nsubmission.head()","2a473c89":"submission.to_csv('lightautoml_sample_submission.csv', index = False)","87e9a2b9":"## Step 5. Generate submission","2ea2941e":"## Step 2. Setup columns roles","f84fb3ba":"# Step 0.0. Install LightAutoML","a5ed5305":"# Step 0.2. Parameters ","0c0f419e":"To create AutoML model here we use `TabularAutoML` preset, which looks like:\n\n![TabularAutoML preset pipeline](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML\/raw\/master\/imgs\/tutorial_2_pipeline.png)\n\nAll params we set above can be send inside preset to change its configuration:","65a4255e":"# Step 0.4. Some user feature preparation ","2adb42f8":"Roles setup here set target column and base date, which is used to calculate date differences:","c757ecb0":"# ========= AutoML preset usage =========\n\n\n## Step 1. Create Task","132ea499":"## Step 4. Predict to test data and check scores","5402fa54":"# Step 0.1. Import necessary libraries ","86ef10ec":"## Step 3. Create AutoML from preset","dd5f1974":"# Step 0.3. Data load "}}