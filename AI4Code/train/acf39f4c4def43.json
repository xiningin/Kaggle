{"cell_type":{"154c053f":"code","19a19bb2":"code","d076a3cc":"code","4fd6897b":"code","68bc1a95":"code","08aeb42c":"code","20639dac":"code","0f577fa7":"code","243a3a99":"code","7d38f476":"code","174172ab":"code","2c0fbaa7":"code","690e52a9":"code","f2483997":"code","bec3e4c0":"code","3426dc74":"code","9611404f":"code","9f086fea":"code","1626c7cb":"code","57e5e2f5":"code","a45b1014":"code","a3cac3bd":"code","a72885dc":"code","6a3c42da":"code","f76924f9":"code","b506af07":"code","17a9c00e":"code","268cf5a6":"code","b7b604f2":"code","fa0581d4":"code","1c845207":"code","298347da":"code","2c3e1280":"code","a03e3ce1":"code","358f1a81":"code","80ab69a9":"code","b56583d4":"code","a860916a":"code","bbc61c9e":"code","b280cfe8":"code","260d6700":"code","660879b1":"code","f52aa50a":"code","e1655a7e":"code","fd78243d":"code","d6fbb519":"code","ea978cdf":"code","92fc169d":"code","e29650a6":"code","77e17671":"code","933cab5a":"code","21d60b30":"code","5a049bdb":"code","49cb4d4a":"code","1a7a695b":"code","298e3a50":"code","faa11cdb":"code","6c3e3ed6":"code","1b16b509":"code","cbf46066":"code","3da57324":"code","f664ef39":"code","e2b120b4":"code","334fa780":"code","183f774b":"code","91a0be20":"code","81b30baa":"code","e8008bb0":"code","b538dbcf":"code","9ebb309f":"code","4f8ed173":"code","8481d820":"code","e525321c":"code","bc804c76":"markdown","35b548ef":"markdown","da9a09b1":"markdown","bb074774":"markdown","ea387b24":"markdown","05321d82":"markdown","ca9884fa":"markdown","e39f8a26":"markdown","0f849738":"markdown","10e0e1a3":"markdown","b5641a2e":"markdown","9374bb92":"markdown","be14e010":"markdown"},"source":{"154c053f":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder","19a19bb2":"import warnings\nwarnings.filterwarnings('ignore')","d076a3cc":"df=pd.read_csv(\"..\/input\/adult-data\/adult_data.csv\",sep=\",\",encoding='utf-8')\ndf.head(6)","4fd6897b":"df.columns","68bc1a95":"# This dataset contains 4812 samples and 28 features. \nprint(df.shape)\nprint(len(df))\nprint(len(df.columns))","08aeb42c":"df.info()","20639dac":"df.describe()","0f577fa7":"#Finding the correlation between the features before manipulating the data\ndf.corr()","243a3a99":"#Representing the correlation between the features before preprocessing the data \nplt.figure(figsize=(8,6))\nsns.heatmap(df.corr(),annot=True)","7d38f476":"df['gender'].value_counts()","174172ab":"# The percentage of males to females in workclasses according to the dataset.\ndf['gender'].value_counts().plot(kind=\"pie\", autopct=\"%.1f%%\",figsize=(5, 5))\nplt.show()","2c0fbaa7":"df['race'].value_counts()","690e52a9":"#Visual representation of the number of each race in workclasses according to the dataset. \nsns.countplot(x='race',data=df )","f2483997":"df[\"income\"].value_counts()","bec3e4c0":"#The percentage of people with income less than or equal to 50k to that of greater than 50\n#It shows a gap in wages.\nsns.countplot(x='income',data=df )","3426dc74":"df['income'].value_counts().plot(kind=\"pie\", autopct=\"%.1f%%\",figsize=(5, 5))\nplt.show()","9611404f":"#Representation of the relationship between the race and the income, white people are dominant in both. \nsns.countplot(df['income'], palette='coolwarm', hue='race', data=df)","9f086fea":"sns.countplot(df['income'], palette='coolwarm', hue='gender', data=df)","1626c7cb":"#Visual representation of the relationship between the marital status and the income. \nsns.countplot(df['income'], palette='coolwarm', hue='relationship', data=df)","57e5e2f5":"# - Exploring missing values in the dataset. \ndf.isnull().sum()","a45b1014":"df.isnull().sum().any() ","a3cac3bd":"df.columns","a72885dc":"#The feature x refers to the index of the worker as ordinary number so dropping the column is the best solution.\ndf.drop(\"x\",axis=1,inplace=True)\ndf.head(6)","6a3c42da":"len(df)-len(df.drop_duplicates())","f76924f9":"df=df.drop_duplicates()","b506af07":"len(df.drop_duplicates())","17a9c00e":"# To ensure the removal of duplicates.\nlen(df)-len(df.drop_duplicates())","268cf5a6":"df.nunique()","b7b604f2":"for i in df:\n    print(f\" {i}  :  {df[i].unique()}\")\n    print(\"\\n\")","fa0581d4":"df.info()","1c845207":"df.rename(columns={'fnlwgt': 'finalweight'}, inplace=True)","298347da":"categoricalfeatures=[i for i in df.columns if df.dtypes[i]=='object']\ncategoricalfeatures","2c3e1280":"df.isin(['?']).sum()","a03e3ce1":"df.shape","358f1a81":"# Note that: The percentage of the garbage value is approximately 12%. ","80ab69a9":"df= df.replace('?', np.NaN)","b56583d4":"df.isna().sum()","a860916a":"# Dropping the null values and ensuring that the data contains only valid values.\ndf.dropna(inplace=True)\ndf.isna().sum()","bbc61c9e":"for i in df:\n    print(f\" {i}  :  {df[i].unique()}\")\n    print(\"\\n\")","b280cfe8":"# education Category\ndf.education = df.education.replace(['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th','10th', '11th', '12th'], 'School')\ndf.education = df.education.replace('HS-grad', 'High school')\ndf.education = df.education.replace(['Assoc-voc', 'Assoc-acdm', 'Prof-school', 'Some-college'], 'Higher education')\ndf.education = df.education.replace('Bachelors', 'Undergrad')\ndf.education = df.education.replace('Masters', 'Graduate')\ndf.education = df.education.replace('Doctorate', 'PhD Holder')","260d6700":"df['education'].unique()","660879b1":"df['marital-status']= df['marital-status'].replace(['Married-civ-spouse', 'Married-AF-spouse'], 'Married')\ndf['marital-status']= df['marital-status'].replace(['Never-married'], 'Not-married')\ndf['marital-status']= df['marital-status'].replace(['Divorced', 'Separated','Widowed',\n                                                   'Married-spouse-absent'], 'Other')","f52aa50a":"df['marital-status'].unique()","e1655a7e":"df['native-country'].value_counts()","fd78243d":"#Defining binary encoding algorithm\ndef binary_encode(df, columns):\n    label_encoder = LabelEncoder()\n    for column in columns:\n        df[column] = label_encoder.fit_transform(df[column])\n    return df","d6fbb519":"#Applying binary encoding  \nbinaryfeatures=['gender', 'income']\ndf = binary_encode(df, binaryfeatures)\ndf","ea978cdf":"df.columns","92fc169d":"sns.boxplot(data=df,x=\"age\")","e29650a6":"df = df.drop(df[df['age']>77].index)","77e17671":"sns.boxplot(data=df,x=\"educational-num\")","933cab5a":"df = df.drop(df[df['educational-num']<3].index)","21d60b30":"sns.boxplot(data=df,x=\"capital-gain\")","5a049bdb":"df = df.drop(df[df['capital-gain']>17000].index)","49cb4d4a":"sns.boxplot(data=df,x=\"capital-loss\")","1a7a695b":"#hours-per-week\nsns.boxplot(data=df,x=\"hours-per-week\")","298e3a50":"#Defining the column that we want to predict\nx= df.drop(['income'], axis=1)\ny= df['income']","faa11cdb":"from sklearn.preprocessing import StandardScaler, LabelEncoder","6c3e3ed6":"#Creating a copy of the df to manipulate it \ndf2= df.copy()\ndf2= df2.apply(LabelEncoder().fit_transform)\ndf2.head()","1b16b509":"#fitting the data\nsc= StandardScaler().fit(df2.drop('income', axis=1))","cbf46066":"x= sc.transform(df2.drop('income', axis=1))\ny= df['income']","3da57324":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","f664ef39":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()","e2b120b4":"#Modeling \nmodel = lr.fit(x_train, y_train)\npred = model.predict(x_test)","334fa780":"lr.score(x_train, y_train)","183f774b":"#Accuracy\nlr.score(x_test, y_test)","91a0be20":"from sklearn.ensemble import RandomForestClassifier","81b30baa":"rf = RandomForestClassifier()","e8008bb0":"model1 = rf.fit(x_train, y_train)\npred1 = model1.predict(x_test)","b538dbcf":"rf.score(x_train, y_train)","9ebb309f":"#Accuracy after using Random forest\nrf.score(x_test, y_test)","4f8ed173":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","8481d820":"confusion_matrix(y_test, pred1)","e525321c":"print(classification_report(y_test, pred1))","bc804c76":"# - Encoding ","35b548ef":"<a id=\"4\"><\/a> <br>\n<font color='black' size=\"+2.5\"><b>4 - Data Processing<\/b><\/font><br>\n\nIn this section:\n- Handling missing values and duplicates.\n- Discovering unique values.\n- Dividing data into categorical and numerical features.\n- Handling garbage values in the categorical features.\n- Categorical encoding.\n- Feature Engineering.\n- Handling outliers.","da9a09b1":"### - Discovering unique values of the features","bb074774":"# - Data Visualization ","ea387b24":"- \"As shown above there're no missing values, despite that the data contains undesired garbage values that won't be clarified until finding the uniques of each feature.\"","05321d82":"# - Feature Engineering ","ca9884fa":"###                                                                 - Handling Missing values","e39f8a26":"# - Modeling ","0f849738":"### - Dividing features into numerical and categorical features to ease dealing with. ","10e0e1a3":"\n<font size=\"+2.5\"><b> Observation <\/b><\/font><br>\n\n- 1. There's '?' in the following columns: workclass, occupation and native-country. \n\n- 2. They're all categorical features so the best solution is to divide the features into numerical and categorical data and deal with this garbage value. \n","b5641a2e":"# - Dealing with outliers","9374bb92":"### - Note that: \n#### The correlation between the features and each other before the preprocessing is very low.","be14e010":"# - Data Exploration"}}