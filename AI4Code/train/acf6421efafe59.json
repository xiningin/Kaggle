{"cell_type":{"64db1b1f":"code","e97b4578":"code","3540b43c":"code","33aa3170":"code","e74b8ce9":"code","0d789e42":"code","d2338067":"code","67e703cd":"code","125433c6":"code","57ef4fd8":"code","76ef7f54":"code","1577ba3e":"code","fe14a8ea":"code","232b821d":"code","ee11ae35":"code","07350c35":"code","822bdbd3":"code","249abcdf":"code","1413955b":"code","860c1a9c":"code","a4ddc583":"code","01c23c24":"code","4fbc79d9":"code","c87de00c":"code","f212b258":"code","30366ddc":"code","e99e0af0":"code","03d3402c":"code","e70089c4":"code","cbef0558":"code","5201b418":"code","c454be28":"code","472e821a":"code","4db2bea3":"code","ddbe1b73":"code","ee8e275e":"code","ecb701c0":"code","e948ce52":"code","04c45666":"code","7d41ac6f":"code","b817ebe5":"code","7bea46f4":"code","8fe5a9bd":"code","4fbe518b":"code","457b751f":"code","232657f3":"code","2f5bddb8":"code","3327db76":"code","072d4523":"code","fc301ab9":"code","f3575d66":"code","4ebddff9":"code","84f2f492":"code","50539408":"code","b8a3412c":"code","f4d4ba36":"markdown","a182753a":"markdown","9724ed0e":"markdown","76bdc228":"markdown","24093969":"markdown","15b01938":"markdown","89da9cc2":"markdown","bca9f0be":"markdown","5cbb3884":"markdown","855b62c7":"markdown","a19f7bd8":"markdown","a5c8c821":"markdown","0a9f445b":"markdown","f6e0e567":"markdown","a0e97cac":"markdown","4dceacf9":"markdown","4c2f5d7d":"markdown","197b1e05":"markdown","ebbda08e":"markdown"},"source":{"64db1b1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n%matplotlib inline\n\n\nfrom sklearn import metrics\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e97b4578":"s=pd.read_csv('..\/input\/salary\/Salary.csv')","3540b43c":"s.head()","33aa3170":"s.shape","e74b8ce9":"s.info()","0d789e42":"s.describe()","d2338067":"sns.distplot(s.YearsExperience, color='b');","67e703cd":"sns.distplot(s.Salary, color='r')","125433c6":"sns.jointplot('YearsExperience','Salary', data=s, kind='reg');","57ef4fd8":"sns.pairplot(s, size = 2, height= 4, aspect = 2.5)","76ef7f54":"s.corr()","1577ba3e":"plt.figure(figsize=(15,7))\nsns.heatmap(s, annot=True)","fe14a8ea":"s.head()","232b821d":"s[['YearsExperience']]","ee11ae35":"feature_cols=['YearsExperience']\nX=s[feature_cols]","07350c35":"X.head()","822bdbd3":"X.columns","249abcdf":"X.shape","1413955b":"y=s.Salary\ny.head()","860c1a9c":"y.shape","a4ddc583":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=0)","01c23c24":"X_train.head()","4fbc79d9":"X_train.tail()","c87de00c":"X_test.head()","f212b258":"print('X train dataset shape is:', X_train.shape)\nprint('X test dataset shape is:', X_test.shape)\n\nprint('Y train dataset shape is:', y_train.shape)\nprint('Y train dataset shape is:', y_test.shape)","30366ddc":"X_train.describe()","e99e0af0":"X_test.describe()","03d3402c":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[ ['YearsExperience'] ] = scaler.fit_transform(X_train)\nX_test[ ['YearsExperience'] ] = scaler.transform(X_test)","e70089c4":"X_train.head()","cbef0558":"X_train.describe()","5201b418":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)","c454be28":"regressor.intercept_","472e821a":"regressor.coef_","4db2bea3":"feature_cols","ddbe1b73":"feature_cols.insert(0,'Intercept')\nfeature_cols","ee8e275e":"coef = regressor.coef_.tolist()\ncoef","ecb701c0":"coef.insert(0, regressor.intercept_)\ncoef","e948ce52":"y_pred_train=regressor.predict(X_train)","04c45666":"y_pred_test=regressor.predict(X_test)","7d41ac6f":"y_pred_train","b817ebe5":"y_pred_test","7bea46f4":"eq1 = zip(feature_cols, coef)\n\nfor c1,c2 in eq1:\n    print(c1,c2)","8fe5a9bd":"y = 82271.71428571429 + 32564.794416112774 \ny","4fbe518b":"from sklearn.metrics import mean_absolute_error, mean_squared_error","457b751f":"MAE_train = mean_absolute_error(y_train, y_pred_train)\nMAE_test = mean_absolute_error(y_test, y_pred_test)","232657f3":"print('MAE for training set is {}'.format(MAE_train))\nprint('MAE for test set is {}'.format(MAE_test))","2f5bddb8":"MSE_train = mean_squared_error(y_train, y_pred_train)\nMSE_test = mean_squared_error(y_test, y_pred_test)","3327db76":"print('MSE for training set is {}'.format(MSE_train))\nprint('MSE for test set is {}'.format(MSE_test))","072d4523":"RMSE_train = np.sqrt( mean_squared_error(y_train, y_pred_train))\nRMSE_test = np.sqrt(mean_squared_error(y_test, y_pred_test))","fc301ab9":"print('RMSE for training set is {}'.format(RMSE_train))\nprint('RMSE for test set is {}'.format(RMSE_test))","f3575d66":"from sklearn.metrics import r2_score\nr2_score_train = r2_score(y_train, y_pred_train)\nr2_score_test = r2_score(y_test, y_pred_test)","4ebddff9":"r2_score_train","84f2f492":"r2_score_test","50539408":"yhat = regressor.predict(X_train)\nSS_Residual = sum((y_train-yhat)**2)\nSS_Total = sum((y_train-np.mean(y_train))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_train)-1)\/(len(y_train)-X_train.shape[1]-1)\nprint(r_squared, adjusted_r_squared)","b8a3412c":"yhat = regressor.predict(X_test)\nSS_Residual = sum((y_test-yhat)**2)\nSS_Total = sum((y_test-np.mean(y_test))**2)\nr_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_r_squared = 1 - (1-r_squared)*(len(y_test)-1)\/(len(y_test)-X_test.shape[1]-1)\nprint(r_squared, adjusted_r_squared)","f4d4ba36":"### Model Evaluation using Rsquared value.","a182753a":"### Linear regression in scikit-learn","9724ed0e":"**Work Experience and Salary are highly correlated**","76bdc228":"## Introduction to Linear Regression\n\n__Linear regression__ is a _basic_ and _commonly_ used type of __predictive analysis__.  The overall idea of regression is to examine two things: \n- Does a set of __predictor variables__ do a good job in predicting an __outcome__ (dependent) variable?  \n- Which variables in particular are __significant predictors__ of the outcome variable, and in what way they do __impact__ the outcome variable?  \n\nThese regression estimates are used to explain the __relationship between one dependent variable and one or more independent variables__.  The simplest form of the regression equation with one dependent and one independent variable is defined by the formula :<br\/>\n$y = \\beta_0 + \\beta_1x$\n\n![image.png](attachment:image.png)\n\nWhat does each term represent?\n- $y$ is the response\n- $x$ is the feature\n- $\\beta_0$ is the intercept\n- $\\beta_1$ is the coefficient for x\n","24093969":"**Scaling the Dataset for normalisation**","15b01938":"### Is there a relationship between Years of experience and salary?","89da9cc2":"### Splitting X and y into training and test datasets.","bca9f0be":"## Model evaluation \n__Error__ is the _deviation_ of the values _predicted_ by the model with the _true_ values.<br\/>\nBelow are the types of error we will be calculating for our _linear regression model_:\n- Mean Absolute Error\n- Mean Squared Error\n- Root Mean Squared Error","5cbb3884":"### Visualising Pairwise correlation","855b62c7":"### Model Evaluation using __metrics.__\n__Mean Absolute Error__ (MAE) is the mean of the absolute value of the errors:\n$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\nComputing the MAE for our Sales predictions","a19f7bd8":"### Calculating and plotting heatmap correlation","a5c8c821":"__Mean Squared Error__ (MSE) is the mean of the squared errors:\n$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n\nComputing the MSE for our Sales predictions","0a9f445b":"### Interpreting Model Coefficients","f6e0e567":"### Using the Model for Prediction","a0e97cac":"**Observation**\n**Given Dataset is not normally distributed**\n","4dceacf9":"**r2 score of train data and test data 96 and 97**\n**Higher the r2 score indicates a better fit for the model.**","4c2f5d7d":"35 rows X 1 column","197b1e05":"__Root Mean Squared Error__ (RMSE) is the square root of the mean of the squared errors:\n\n$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n\nComputing the RMSE for our Sales predictions","ebbda08e":"### Preparing X and y using pandas"}}