{"cell_type":{"2a76dc7f":"code","804295f0":"code","0f623a48":"code","2f97b47a":"code","664e92f5":"code","f4bcce6e":"code","a7f39ea5":"code","815ec2b7":"code","3d5f51e2":"code","203d448c":"code","dbe03223":"code","d30cb52a":"code","69f5e614":"code","d489395f":"code","1b653080":"code","0e2420af":"code","b2b1028d":"code","df064fb4":"code","122d7703":"code","6e590a44":"code","7609313a":"code","40b68fdd":"code","aa238111":"code","8db48b93":"code","7165aaef":"code","fd39eb8d":"code","264ce3c6":"code","7a92b75d":"code","3f09f3cb":"code","66686dca":"code","cd34dc38":"code","c522381f":"code","1d3d24fd":"code","3d25696a":"code","96ce3e38":"code","740a892b":"code","e4f265ce":"code","b04890ad":"code","9a2edc27":"code","9483eef2":"code","67341ca3":"code","215bd13d":"code","ffd567fa":"code","cc4a706d":"code","08a35b4d":"code","9e34afaf":"code","f2831530":"code","5c65be32":"code","38f8a1db":"code","f95cd767":"code","521aa3d7":"code","67d4c938":"markdown","ad83c35f":"markdown","e9c2f56c":"markdown","2fde8c31":"markdown","7cf7be2c":"markdown","314be237":"markdown","55423d23":"markdown","11667406":"markdown","f55963d8":"markdown","607b0ab1":"markdown","3c3e92da":"markdown","37b46b4c":"markdown","e0df8278":"markdown","cc1fd4f9":"markdown","05634c2f":"markdown","e4d1abd4":"markdown","f4a32a54":"markdown","0855a9ca":"markdown"},"source":{"2a76dc7f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\ntrain = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')\ntest = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')\nsub = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/sample_submission.csv')","804295f0":"train.head()","0f623a48":"train.isnull().sum(), test.isnull().sum()","2f97b47a":"train['total_length'] = train['comment_text'].apply(len)\ntrain['capitals'] = train['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntrain['caps_vs_length'] = train.apply(lambda row: float(row['capitals'])\/float(row['total_length']),axis=1)\ntrain['num_exclamation_marks'] = train['comment_text'].apply(lambda comment: comment.count('!'))\ntrain['num_question_marks'] = train['comment_text'].apply(lambda comment: comment.count('?'))\ntrain['num_punctuation'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\ntrain['num_symbols'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntrain['num_words'] = train['comment_text'].apply(lambda comment: len(comment.split()))\ntrain['num_unique_words'] = train['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\ntrain['words_vs_unique'] = train['num_unique_words'] \/ train['num_words']\ntrain['num_smilies'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))","664e92f5":"features = ('total_length', 'capitals', 'caps_vs_length', 'num_exclamation_marks','num_question_marks', 'num_punctuation', 'num_words', 'num_unique_words','words_vs_unique', 'num_smilies', 'num_symbols')\ncolumns = ('target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'funny', 'wow', 'sad', 'likes', 'disagree', 'sexual_explicit','identity_annotator_count', 'toxicity_annotator_count')\nrows = [{c:train[f].corr(train[c]) for c in columns} for f in features]\ntrain_correlations = pd.DataFrame(rows, index=features)","f4bcce6e":"train_correlations","a7f39ea5":"plt.figure(figsize=(10, 6))\nsns.set(font_scale=1)\nax = sns.heatmap(train_correlations, vmin=-0.1, vmax=0.1, center=0.0)","815ec2b7":"demographics = train.loc[:, ['target']+list(train)[slice(8,32)]].dropna()\nweighted_toxic = demographics.iloc[:, 1:].multiply(demographics.iloc[:, 0], axis=\"index\").sum()\/demographics.iloc[:, 1:][demographics.iloc[:, 1:]>0].count()\nweighted_toxic = weighted_toxic.sort_values(ascending=False)\nplt.figure(figsize=(30,20))\nsns.set(font_scale=3)\nax = sns.barplot(x = weighted_toxic.values, y = weighted_toxic.index, alpha=0.8)\nplt.ylabel('Demographics')\nplt.xlabel('Weighted Toxic')\nplt.show()","3d5f51e2":"identities = tuple(train.iloc[:, 8:32])\nrows = [{c:train[f].corr(train[c]) for c in columns} for f in identities]\npoptoxicity_correlations = pd.DataFrame(rows, index=identities)","203d448c":"poptoxicity_correlations","dbe03223":"plt.figure(figsize=(12, 8))\nsns.set(font_scale=1)\nax = sns.heatmap(poptoxicity_correlations, vmin=-0.1, vmax=0.1, center=0.0)","d30cb52a":"withdate = train.loc[:, ['created_date', 'target']+list(train)[slice(8,32)]].dropna()\nraceweighted = withdate.iloc[:, 2:]\/withdate.iloc[:, 2:].sum()\nrace_target_weighted = raceweighted.multiply(withdate.iloc[:, 1], axis=\"index\")\nrace_target_weighted['created_date'] = pd.to_datetime(withdate['created_date']).values.astype('datetime64[M]')\nweighted_demo = race_target_weighted.groupby(['created_date']).sum().sort_index()","69f5e614":"import plotly\nimport plotly.plotly as py\nimport cufflinks as cf\nimport plotly.graph_objs as go\nplotly.tools.set_credentials_file(username='13217', api_key='FG6itEaCMouvPJVR7DlI')\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","d489395f":"weighted_demo[['white', 'asian', 'black', 'jewish', 'latino', 'other_race_or_ethnicity']].iplot(title = 'Time Series Toxicity & Race', filename='Time Series Toxicity & Race' )\n\n# Click on the legend to change display. Double click for single identity.","1b653080":"weighted_demo[['atheist', 'buddhist', 'christian', 'hindu', 'muslim', 'other_religion']].iplot(title = 'Time Series Toxicity & Religion', filename='Time Series Toxicity & Religion')\n\n# Click on the legend to change display. Double click for single identity.","0e2420af":"weighted_demo[['heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation']].iplot(title = 'Time Series Toxicity & Sexual Orientation', filename='Time Series Toxicity & Sexual Orientation')\n\n# Click on the legend to change display. Double click for single identity.","b2b1028d":"weighted_demo[['male', 'female', 'transgender', 'other_gender']].iplot(title = 'Time Series Toxicity & Gender', filename='Time Series Toxicity & Gender')\n\n# Click on the legend to change display. Double click for single identity.","df064fb4":"weighted_demo[['physical_disability', 'intellectual_or_learning_disability', 'psychiatric_or_mental_illness', 'other_disability']].iplot(title = 'Time Series Toxicity & Disability', filename='Time Series Toxicity & Disability')\n\n# Click on the legend to change display. Double click for single identity.","122d7703":"alldate_toxicity = train[train['target'] >= 0.5].loc[:, ['created_date', 'target', 'comment_text']].dropna()\nalldate_toxicity['created_date'] = pd.to_datetime(alldate_toxicity['created_date']).values.astype('datetime64[M]')\njan_2017_toxicity = alldate_toxicity[alldate_toxicity['created_date'] == '2017-01-01']\n\nfrom nltk.corpus import stopwords\ndef check_frequency(data = alldate_toxicity['comment_text'], n = 20):\n    stop = stopwords.words('english')\n    data  = data.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n    data = data.str.replace('[^\\w\\s]','')\n    data = data.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n    freq = pd.Series(' '.join(data).split()).value_counts()[:n]\n    return freq\n\ntop_10_toxicity_othertime = check_frequency(data = alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'], n = 10)\ntop_10_toxicity_jan_2017 = check_frequency(data = jan_2017_toxicity['comment_text'], n = 10)","6e590a44":"top_10_toxicity_jan_2017.index.difference(top_10_toxicity_othertime.index)","7609313a":"percent_toxicity_othertime = top_10_toxicity_othertime\/alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'].str.split().str.len().sum()\npercent_toxicity_jan_2017 = top_10_toxicity_jan_2017\/jan_2017_toxicity['comment_text'].str.split().str.len().sum()\ntop_toxicity = pd.concat([percent_toxicity_jan_2017, percent_toxicity_othertime], axis=1, sort=False)\ntop_toxicity.columns = ['Jan_2017', 'Other_Time']\ntop_toxicity['Difference'] = top_toxicity['Jan_2017'] - top_toxicity['Other_Time']","40b68fdd":"top_toxicity.head(30)","aa238111":"import plotly.graph_objs as go\ntrace1 = go.Bar(\n    x=top_toxicity.index,\n    y=top_toxicity['Jan_2017'],\n    name='Jan_2017'\n)\ntrace2 = go.Bar(\n    x=top_toxicity.index,\n    y=top_toxicity['Other_Time'],\n    name='Other_Time'\n)\n\ndata = [trace2, trace1]\nlayout = go.Layout(\n    barmode='group'\n)\nlayout = go.Layout(yaxis=dict(tickformat=\".2%\"))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, title = 'Top Toxicity Comarision', filename='top_toxicity_comarision')","8db48b93":"train['datetime64'] = pd.to_datetime(train['created_date']).values.astype('datetime64[h]')\ntrain['hour'] = train['datetime64'].dt.hour\nall_comments_by_hour = train['target'].groupby(train['hour']).sum().sort_index()\/train['target'].groupby(train['hour']).sum().sum()\ntoxic_comments_by_hour = train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sort_index()\/train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sum()\ncomments_hour_check = pd.concat([all_comments_by_hour, toxic_comments_by_hour], axis=1, sort=False)\ncomments_hour_check.columns = ['all_comments', 'toxic_comments']","7165aaef":"labels = ['Midnight', 'Morning', 'Noon', 'Evening', 'Midnight']\ntickvals = ['0', '6', '12', '18', comments_hour_check.index.max()]\n\ntrace1 = go.Scatter(\n    x=comments_hour_check.index,\n    y=comments_hour_check['all_comments'],\n    name = 'comment percent per H',\n    line = dict(\n        color = ('rgb(22, 96, 167)'),\n        width = 1)\n)\ntrace2 = go.Scatter(\n    x=comments_hour_check.index,\n    y=comments_hour_check['toxic_comments'],\n    name = 'toxic comment percent per H',\n    line = dict(\n        color = ('rgb(205, 12, 24)'),\n        width = 1,)\n)\n\ntrace3 = go.Bar(\n    x=comments_hour_check.index,\n    y=comments_hour_check['toxic_comments']-comments_hour_check['all_comments'],\n    name = 'More Toxic Comment Ratio'\n)\n\ndata = [trace1, trace2, trace3]\n\nlayout = go.Layout(yaxis=dict(tickformat=\".2%\"),\n                   title = 'Which Time are People More Toxic',\n                   xaxis=go.layout.XAxis(\n                       ticktext=labels, \n                       tickvals=tickvals\n                   ),\n                  )\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='Which Time are People More Toxic')","fd39eb8d":"def toxicwordcloud(subset=train[train.target>0.7], title = \"Words Frequented\", picture = \"..\/input\/imagesforkernal\/anger.png\"):\n    stopword=set(STOPWORDS)\n    toxic_mask=np.array(Image.open(picture))\n    toxic_mask=toxic_mask[:,:,1]\n    text=subset.comment_text.values\n    wc= WordCloud(background_color=\"black\",max_words=4000,mask=toxic_mask,stopwords=stopword)\n    wc.generate(\" \".join(text))\n    plt.figure(figsize=(8,8))\n    plt.xticks([])\n    plt.yticks([])\n    plt.axis('off')\n    plt.title(title, fontsize=20)\n    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)","264ce3c6":"toxicwordcloud(picture = \"..\/input\/imagesforkernal\/toxic-sign.png\")","7a92b75d":"toxicwordcloud(subset = train[(train['female'] >0)&(train['target']>0.8)],title = \"Words Frequented - Female Related\", picture = \"..\/input\/imagesforkernal\/anger.png\")","3f09f3cb":"toxicwordcloud(subset = train[(train['insult'] >0.8)&(train['target']>0.8)],title = \"Words Frequented - Insult Related\", picture = \"..\/input\/imagesforkernal\/biohazard-symbol.png\")","66686dca":"import operator \nimport re\nimport gensim","cd34dc38":"train = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')\ntest = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')","c522381f":"# Due to the memory limit, here we only are using glove, while if you have a better machine, you can also load crawl and other embeddings\n\ndf = pd.concat([train.iloc[:, [0,2]] ,test.iloc[:, :2]])\nglove = '..\/input\/glove840b300dtxt\/glove.840B.300d.txt'\n# crawl =  '..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec'\n    \ndef load_embed(file):\n    def get_coefs(word,*arr): \n        return word, np.asarray(arr, dtype='float32')\n    if file == '..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec':\n        embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(crawl)\n    else:\n        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n    return embeddings_index","1d3d24fd":"print(\"Extracting GloVe embedding\")\nembed_glove = load_embed(glove)\n# print(\"Extracting Crawl embedding\")\n# embed_crawl = load_embed(crawl)","3d25696a":"def build_vocab(texts):\n    sentences = texts.apply(lambda x: x.split()).values\n    vocab = {}\n    for sentence in sentences:\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab\n\nvocab = build_vocab(df['comment_text'])\n\ndef check_coverage(vocab, embeddings_index):\n    known_words = {}\n    unknown_words = {}\n    nb_known_words = 0\n    nb_unknown_words = 0\n    for word in vocab.keys():\n        try:\n            known_words[word] = embeddings_index[word]\n            nb_known_words += vocab[word]\n        except:\n            unknown_words[word] = vocab[word]\n            nb_unknown_words += vocab[word]\n            pass\n\n    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) \/ len(vocab)))\n    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words \/ (nb_known_words + nb_unknown_words)))\n    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n\n    return unknown_words","96ce3e38":"print(\"Glove : \")\noov_glove = check_coverage(vocab, embed_glove)\n# print(\"Crawl : \")\n# oov_crawl = check_coverage(vocab, embed_crawl)","740a892b":"df['lowered_comment'] = df['comment_text'].apply(lambda x: x.lower())\nvocab_low = build_vocab(df['lowered_comment'])\nprint(\"Glove : \")\noov_glove = check_coverage(vocab_low, embed_glove)\n# print(\"Crawl : \")\n# oov_crawl = check_coverage(vocab_low, embed_crawl)","e4f265ce":"def add_lower(embedding, vocab):\n    count = 0\n    for word in vocab:\n        if word in embedding and word.lower() not in embedding:  \n            embedding[word.lower()] = embedding[word]\n            count += 1\n    print(f\"Added {count} words to embedding\")\n    \nprint(\"Glove : \")\nadd_lower(embed_glove, vocab)\n# oov_glove = check_coverage(vocab_low, embed_glove)\n# print(\"Crawl : \")\n# add_lower(embed_crawl, vocab)\n# oov_crawl = check_coverage(vocab_low, embed_crawl)\n\n# Check Result\noov_glove[:10]","b04890ad":"contraction_mapping = {\n    \"Trump's\" : 'trump is',\"'cause\": 'because',',cause': 'because',';cause': 'because',\"ain't\": 'am not','ain,t': 'am not',\n    'ain;t': 'am not','ain\u00b4t': 'am not','ain\u2019t': 'am not',\"aren't\": 'are not',\n    'aren,t': 'are not','aren;t': 'are not','aren\u00b4t': 'are not','aren\u2019t': 'are not',\"can't\": 'cannot',\"can't've\": 'cannot have','can,t': 'cannot','can,t,ve': 'cannot have',\n    'can;t': 'cannot','can;t;ve': 'cannot have',\n    'can\u00b4t': 'cannot','can\u00b4t\u00b4ve': 'cannot have','can\u2019t': 'cannot','can\u2019t\u2019ve': 'cannot have',\n    \"could've\": 'could have','could,ve': 'could have','could;ve': 'could have',\"couldn't\": 'could not',\"couldn't've\": 'could not have','couldn,t': 'could not','couldn,t,ve': 'could not have','couldn;t': 'could not',\n    'couldn;t;ve': 'could not have','couldn\u00b4t': 'could not',\n    'couldn\u00b4t\u00b4ve': 'could not have','couldn\u2019t': 'could not','couldn\u2019t\u2019ve': 'could not have','could\u00b4ve': 'could have',\n    'could\u2019ve': 'could have',\"didn't\": 'did not','didn,t': 'did not','didn;t': 'did not','didn\u00b4t': 'did not',\n    'didn\u2019t': 'did not',\"doesn't\": 'does not','doesn,t': 'does not','doesn;t': 'does not','doesn\u00b4t': 'does not',\n    'doesn\u2019t': 'does not',\"don't\": 'do not','don,t': 'do not','don;t': 'do not','don\u00b4t': 'do not','don\u2019t': 'do not',\n    \"hadn't\": 'had not',\"hadn't've\": 'had not have','hadn,t': 'had not','hadn,t,ve': 'had not have','hadn;t': 'had not',\n    'hadn;t;ve': 'had not have','hadn\u00b4t': 'had not','hadn\u00b4t\u00b4ve': 'had not have','hadn\u2019t': 'had not','hadn\u2019t\u2019ve': 'had not have',\"hasn't\": 'has not','hasn,t': 'has not','hasn;t': 'has not','hasn\u00b4t': 'has not','hasn\u2019t': 'has not',\n    \"haven't\": 'have not','haven,t': 'have not','haven;t': 'have not','haven\u00b4t': 'have not','haven\u2019t': 'have not',\"he'd\": 'he would',\n    \"he'd've\": 'he would have',\"he'll\": 'he will',\n    \"he's\": 'he is','he,d': 'he would','he,d,ve': 'he would have','he,ll': 'he will','he,s': 'he is','he;d': 'he would',\n    'he;d;ve': 'he would have','he;ll': 'he will','he;s': 'he is','he\u00b4d': 'he would','he\u00b4d\u00b4ve': 'he would have','he\u00b4ll': 'he will',\n    'he\u00b4s': 'he is','he\u2019d': 'he would','he\u2019d\u2019ve': 'he would have','he\u2019ll': 'he will','he\u2019s': 'he is',\"how'd\": 'how did',\"how'll\": 'how will',\n    \"how's\": 'how is','how,d': 'how did','how,ll': 'how will','how,s': 'how is','how;d': 'how did','how;ll': 'how will',\n    'how;s': 'how is','how\u00b4d': 'how did','how\u00b4ll': 'how will','how\u00b4s': 'how is','how\u2019d': 'how did','how\u2019ll': 'how will',\n    'how\u2019s': 'how is',\"i'd\": 'i would',\"i'll\": 'i will',\"i'm\": 'i am',\"i've\": 'i have','i,d': 'i would','i,ll': 'i will',\n    'i,m': 'i am','i,ve': 'i have','i;d': 'i would','i;ll': 'i will','i;m': 'i am','i;ve': 'i have',\"isn't\": 'is not',\n    'isn,t': 'is not','isn;t': 'is not','isn\u00b4t': 'is not','isn\u2019t': 'is not',\"it'd\": 'it would',\"it'll\": 'it will',\"It's\":'it is',\n    \"it's\": 'it is','it,d': 'it would','it,ll': 'it will','it,s': 'it is','it;d': 'it would','it;ll': 'it will','it;s': 'it is','it\u00b4d': 'it would','it\u00b4ll': 'it will','it\u00b4s': 'it is',\n    'it\u2019d': 'it would','it\u2019ll': 'it will','it\u2019s': 'it is',\n    'i\u00b4d': 'i would','i\u00b4ll': 'i will','i\u00b4m': 'i am','i\u00b4ve': 'i have','i\u2019d': 'i would','i\u2019ll': 'i will','i\u2019m': 'i am',\n    'i\u2019ve': 'i have',\"let's\": 'let us','let,s': 'let us','let;s': 'let us','let\u00b4s': 'let us',\n    'let\u2019s': 'let us',\"ma'am\": 'madam','ma,am': 'madam','ma;am': 'madam',\"mayn't\": 'may not','mayn,t': 'may not','mayn;t': 'may not',\n    'mayn\u00b4t': 'may not','mayn\u2019t': 'may not','ma\u00b4am': 'madam','ma\u2019am': 'madam',\"might've\": 'might have','might,ve': 'might have','might;ve': 'might have',\"mightn't\": 'might not','mightn,t': 'might not','mightn;t': 'might not','mightn\u00b4t': 'might not',\n    'mightn\u2019t': 'might not','might\u00b4ve': 'might have','might\u2019ve': 'might have',\"must've\": 'must have','must,ve': 'must have','must;ve': 'must have',\n    \"mustn't\": 'must not','mustn,t': 'must not','mustn;t': 'must not','mustn\u00b4t': 'must not','mustn\u2019t': 'must not','must\u00b4ve': 'must have',\n    'must\u2019ve': 'must have',\"needn't\": 'need not','needn,t': 'need not','needn;t': 'need not','needn\u00b4t': 'need not','needn\u2019t': 'need not',\"oughtn't\": 'ought not','oughtn,t': 'ought not','oughtn;t': 'ought not',\n    'oughtn\u00b4t': 'ought not','oughtn\u2019t': 'ought not',\"sha'n't\": 'shall not','sha,n,t': 'shall not','sha;n;t': 'shall not',\"shan't\": 'shall not',\n    'shan,t': 'shall not','shan;t': 'shall not','shan\u00b4t': 'shall not','shan\u2019t': 'shall not','sha\u00b4n\u00b4t': 'shall not','sha\u2019n\u2019t': 'shall not',\n    \"she'd\": 'she would',\"she'll\": 'she will',\"she's\": 'she is','she,d': 'she would','she,ll': 'she will',\n    'she,s': 'she is','she;d': 'she would','she;ll': 'she will','she;s': 'she is','she\u00b4d': 'she would','she\u00b4ll': 'she will',\n    'she\u00b4s': 'she is','she\u2019d': 'she would','she\u2019ll': 'she will','she\u2019s': 'she is',\"should've\": 'should have','should,ve': 'should have','should;ve': 'should have',\n    \"shouldn't\": 'should not','shouldn,t': 'should not','shouldn;t': 'should not','shouldn\u00b4t': 'should not','shouldn\u2019t': 'should not','should\u00b4ve': 'should have',\n    'should\u2019ve': 'should have',\"that'd\": 'that would',\"that's\": 'that is','that,d': 'that would','that,s': 'that is','that;d': 'that would',\n    'that;s': 'that is','that\u00b4d': 'that would','that\u00b4s': 'that is','that\u2019d': 'that would','that\u2019s': 'that is',\"there'd\": 'there had',\n    \"there's\": 'there is','there,d': 'there had','there,s': 'there is','there;d': 'there had','there;s': 'there is',\n    'there\u00b4d': 'there had','there\u00b4s': 'there is','there\u2019d': 'there had','there\u2019s': 'there is',\n    \"they'd\": 'they would',\"they'll\": 'they will',\"they're\": 'they are',\"they've\": 'they have',\n    'they,d': 'they would','they,ll': 'they will','they,re': 'they are','they,ve': 'they have','they;d': 'they would','they;ll': 'they will','they;re': 'they are',\n    'they;ve': 'they have','they\u00b4d': 'they would','they\u00b4ll': 'they will','they\u00b4re': 'they are','they\u00b4ve': 'they have','they\u2019d': 'they would','they\u2019ll': 'they will',\n    'they\u2019re': 'they are','they\u2019ve': 'they have',\"wasn't\": 'was not','wasn,t': 'was not','wasn;t': 'was not','wasn\u00b4t': 'was not',\n    'wasn\u2019t': 'was not',\"we'd\": 'we would',\"we'll\": 'we will',\"we're\": 'we are',\"we've\": 'we have','we,d': 'we would','we,ll': 'we will',\n    'we,re': 'we are','we,ve': 'we have','we;d': 'we would','we;ll': 'we will','we;re': 'we are','we;ve': 'we have',\n    \"weren't\": 'were not','weren,t': 'were not','weren;t': 'were not','weren\u00b4t': 'were not','weren\u2019t': 'were not','we\u00b4d': 'we would','we\u00b4ll': 'we will',\n    'we\u00b4re': 'we are','we\u00b4ve': 'we have','we\u2019d': 'we would','we\u2019ll': 'we will','we\u2019re': 'we are','we\u2019ve': 'we have',\"what'll\": 'what will',\"what're\": 'what are',\"what's\": 'what is',\n    \"what've\": 'what have','what,ll': 'what will','what,re': 'what are','what,s': 'what is','what,ve': 'what have','what;ll': 'what will','what;re': 'what are',\n    'what;s': 'what is','what;ve': 'what have','what\u00b4ll': 'what will',\n    'what\u00b4re': 'what are','what\u00b4s': 'what is','what\u00b4ve': 'what have','what\u2019ll': 'what will','what\u2019re': 'what are','what\u2019s': 'what is',\n    'what\u2019ve': 'what have',\"where'd\": 'where did',\"where's\": 'where is','where,d': 'where did','where,s': 'where is','where;d': 'where did',\n    'where;s': 'where is','where\u00b4d': 'where did','where\u00b4s': 'where is','where\u2019d': 'where did','where\u2019s': 'where is',\n    \"who'll\": 'who will',\"who's\": 'who is','who,ll': 'who will','who,s': 'who is','who;ll': 'who will','who;s': 'who is',\n    'who\u00b4ll': 'who will','who\u00b4s': 'who is','who\u2019ll': 'who will','who\u2019s': 'who is',\"won't\": 'will not','won,t': 'will not','won;t': 'will not',\n    'won\u00b4t': 'will not','won\u2019t': 'will not',\"wouldn't\": 'would not','wouldn,t': 'would not','wouldn;t': 'would not','wouldn\u00b4t': 'would not',\n    'wouldn\u2019t': 'would not',\"you'd\": 'you would',\"you'll\": 'you will',\"you're\": 'you are','you,d': 'you would','you,ll': 'you will',\n    'you,re': 'you are','you;d': 'you would','you;ll': 'you will',\n    'you;re': 'you are','you\u00b4d': 'you would','you\u00b4ll': 'you will','you\u00b4re': 'you are','you\u2019d': 'you would','you\u2019ll': 'you will','you\u2019re': 'you are',\n    '\u00b4cause': 'because','\u2019cause': 'because',\"you've\": \"you have\",\"could'nt\": 'could not',\n    \"havn't\": 'have not',\"here\u2019s\": \"here is\",'i\"\"m': 'i am',\"i'am\": 'i am',\"i'l\": \"i will\",\"i'v\": 'i have',\"wan't\": 'want',\"was'nt\": \"was not\",\"who'd\": \"who would\",\n    \"who're\": \"who are\",\"who've\": \"who have\",\"why'd\": \"why would\",\"would've\": \"would have\",\"y'all\": \"you all\",\"y'know\": \"you know\",\"you.i\": \"you i\",\n    \"your'e\": \"you are\",\"arn't\": \"are not\",\"agains't\": \"against\",\"c'mon\": \"common\",\"doens't\": \"does not\",'don\"\"t': \"do not\",\"dosen't\": \"does not\",\n    \"dosn't\": \"does not\",\"shoudn't\": \"should not\",\"that'll\": \"that will\",\"there'll\": \"there will\",\"there're\": \"there are\",\n    \"this'll\": \"this all\",\"u're\": \"you are\", \"ya'll\": \"you all\",\"you'r\": \"you are\",\"you\u2019ve\": \"you have\",\"d'int\": \"did not\",\"did'nt\": \"did not\",\"din't\": \"did not\",\"dont't\": \"do not\",\"gov't\": \"government\",\n    \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"\u2018I\":'I',\n    '\u1d00\u0274\u1d05':'and','\u1d1b\u029c\u1d07':'the','\u029c\u1d0f\u1d0d\u1d07':'home','\u1d1c\u1d18':'up','\u0299\u028f':'by','\u1d00\u1d1b':'at','\u2026and':'and','civilbeat':'civil beat',\\\n    'TrumpCare':'Trump care','Trumpcare':'Trump care', 'OBAMAcare':'Obama care','\u1d04\u029c\u1d07\u1d04\u1d0b':'check','\u0493\u1d0f\u0280':'for','\u1d1b\u029c\u026as':'this','\u1d04\u1d0f\u1d0d\u1d18\u1d1c\u1d1b\u1d07\u0280':'computer',\\\n    '\u1d0d\u1d0f\u0274\u1d1b\u029c':'month','\u1d21\u1d0f\u0280\u1d0b\u026a\u0274\u0262':'working','\u1d0a\u1d0f\u0299':'job','\u0493\u0280\u1d0f\u1d0d':'from','S\u1d1b\u1d00\u0280\u1d1b':'start','gubmit':'submit','CO\u2082':'carbon dioxide','\u0493\u026a\u0280s\u1d1b':'first',\\\n    '\u1d07\u0274\u1d05':'end','\u1d04\u1d00\u0274':'can','\u029c\u1d00\u1d20\u1d07':'have','\u1d1b\u1d0f':'to','\u029f\u026a\u0274\u1d0b':'link','\u1d0f\u0493':'of','\u029c\u1d0f\u1d1c\u0280\u029f\u028f':'hourly','\u1d21\u1d07\u1d07\u1d0b':'week','\u1d07\u0274\u1d05':'end','\u1d07x\u1d1b\u0280\u1d00':'extra',\\\n    'G\u0280\u1d07\u1d00\u1d1b':'great','s\u1d1b\u1d1c\u1d05\u1d07\u0274\u1d1bs':'student','s\u1d1b\u1d00\u028f':'stay','\u1d0d\u1d0f\u1d0ds':'mother','\u1d0f\u0280':'or','\u1d00\u0274\u028f\u1d0f\u0274\u1d07':'anyone','\u0274\u1d07\u1d07\u1d05\u026a\u0274\u0262':'needing','\u1d00\u0274':'an','\u026a\u0274\u1d04\u1d0f\u1d0d\u1d07':'income',\\\n    '\u0280\u1d07\u029f\u026a\u1d00\u0299\u029f\u1d07':'reliable','\u0493\u026a\u0280s\u1d1b':'first','\u028f\u1d0f\u1d1c\u0280':'your','s\u026a\u0262\u0274\u026a\u0274\u0262':'signing','\u0299\u1d0f\u1d1b\u1d1b\u1d0f\u1d0d':'bottom','\u0493\u1d0f\u029f\u029f\u1d0f\u1d21\u026a\u0274\u0262':'following','M\u1d00\u1d0b\u1d07':'make',\\\n    '\u1d04\u1d0f\u0274\u0274\u1d07\u1d04\u1d1b\u026a\u1d0f\u0274':'connection','\u026a\u0274\u1d1b\u1d07\u0280\u0274\u1d07\u1d1b':'internet','financialpost':'financial post', '\u029ca\u1d20\u1d07':' have ', '\u1d04a\u0274':' can ', 'Ma\u1d0b\u1d07':' make ', '\u0280\u1d07\u029f\u026aa\u0299\u029f\u1d07':' reliable ', '\u0274\u1d07\u1d07\u1d05':' need ',\n    '\u1d0f\u0274\u029f\u028f':' only ', '\u1d07x\u1d1b\u0280a':' extra ', 'a\u0274':' an ', 'a\u0274\u028f\u1d0f\u0274\u1d07':' anyone ', 's\u1d1ba\u028f':' stay ', 'S\u1d1ba\u0280\u1d1b':' start', 'SHOPO':'shop',\n    }","9a2edc27":"def known_contractions(embed):\n    known = []\n    for contract in contraction_mapping:\n        if contract in embed:\n            known.append(contract)\n    return known\n\nprint(\"- Known Contractions -\")\nprint(\"   Glove :\")\nprint(known_contractions(embed_glove))\n# print(\"   Crawl :\")\n# print(known_contractions(embed_crawl))","9483eef2":"def clean_contractions(text, mapping):\n    specials = [\"\u2019\", \"\u2018\", \"\u00b4\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n    return text\n\ndf['treated_comment'] = df['lowered_comment'].apply(lambda x: clean_contractions(x, contraction_mapping))\n\nvocab = build_vocab(df['treated_comment'])\n\nprint(\"Glove : \")\noov_glove = check_coverage(vocab, embed_glove)\n# print(\"Crawl : \")\n# oov_paragram = check_coverage(vocab, embed_crawl)","67341ca3":"punct = \"\/-'?!.,#$%\\'()*+-\/:;<=>@[\\\\]^_`{|}~\" + '\"\"\u201c\u201d\u2019' + '\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014\u2013&'\n\ndef unknown_punct(embed, punct):\n    unknown = ''\n    for p in punct:\n        if p not in embed:\n            unknown += p\n            unknown += ' '\n    return unknown\n\nprint(\"Glove :\")\nprint(unknown_punct(embed_glove, punct))\n# print(\"Crawl :\")\n# print(unknown_punct(embed_crawl, punct))","215bd13d":"punct_mapping = {\"\u2018\": \"'\", \"\u20b9\": \"e\", \"\u00b4\": \"'\", \"\u00b0\": \"\", \"\u20ac\": \"e\", \"\u2122\": \"tm\", \"\u221a\": \" sqrt \", \"\u00d7\": \"x\", \"\u00b2\": \"2\", \"\u2014\": \"-\", \"\u2013\": \"-\", \"\u2019\": \"'\", \"_\": \"-\", \"`\": \"'\", '\u201c': '\"', '\u201d': '\"', '\u201c': '\"', \"\u00a3\": \"e\", '\u221e': 'infinity', '\u03b8': 'theta', '\u00f7': '\/', '\u03b1': 'alpha', '\u2022': '.', '\u00e0': 'a', '\u2212': '-', '\u03b2': 'beta', '\u2205': '', '\u00b3': '3', '\u03c0': 'pi', }\n\ndef clean_special_chars(text, punct, mapping):\n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    for p in punct:\n        text = text.replace(p, f' {p} ')\n    specials = {'\\u200b': ' ', '\u2026': ' ... ', '\\ufeff': '', '\u0915\u0930\u0928\u093e': '', '\u0939\u0948': ''}  # Other special characters that I have to deal with in last\n    for s in specials:\n        text = text.replace(s, specials[s])\n    return text\n\ndf['treated_comment'] = df['treated_comment'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\nvocab = build_vocab(df['treated_comment'])\n\nprint(\"Glove : \")\noov_glove = check_coverage(vocab, embed_glove)\n# print(\"Crawl : \")\n# oov_paragram = check_coverage(vocab, embed_crawl)","ffd567fa":"oov_glove[:10]","cc4a706d":"mispell_dict = {'SB91':'senate bill','tRump':'trump','utmterm':'utm term','FakeNews':'fake news','G\u0280\u1d07at':'great','\u0299\u1d0f\u1d1bto\u1d0d':'bottom','washingtontimes':'washington times','garycrum':'gary crum','htmlutmterm':'html utm term','RangerMC':'car','TFWs':'tuition fee waiver','SJWs':'social justice warrior','Koncerned':'concerned','Vinis':'vinys','Y\u1d0f\u1d1c':'you','Trumpsters':'trump','Trumpian':'trump','bigly':'big league','Trumpism':'trump','Yoyou':'you','Auwe':'wonder','Drumpf':'trump','utmterm':'utm term','Brexit':'british exit','utilitas':'utilities','\u1d00':'a', '\ud83d\ude09':'wink','\ud83d\ude02':'joy','\ud83d\ude00':'stuck out tongue', 'theguardian':'the guardian','deplorables':'deplorable', 'theglobeandmail':'the globe and mail', 'justiciaries': 'justiciary','creditdation': 'Accreditation','doctrne':'doctrine','fentayal': 'fentanyl','designation-': 'designation','CONartist' : 'con-artist','Mutilitated' : 'Mutilated','Obumblers': 'bumblers','negotiatiations': 'negotiations','dood-': 'dood','irakis' : 'iraki','cooerate': 'cooperate','COx':'cox','racistcomments':'racist comments','envirnmetalists': 'environmentalists',}","08a35b4d":"def correct_spelling(x, dic):\n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x\n\ndf['treated_comment'] = df['treated_comment'].apply(lambda x: correct_spelling(x, mispell_dict))\n\nvocab = build_vocab(df['treated_comment'])\n\nprint(\"Glove : \")\noov_glove = check_coverage(vocab, embed_glove)\n# print(\"Crawl : \")\n# oov_paragram = check_coverage(vocab, embed_crawl)","9e34afaf":"train['comment_text'] = df['treated_comment'][:1804874]\ntest['comment_text'] = df['treated_comment'][1804874:]","f2831530":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","5c65be32":"print('-' * 80)\nprint('train')\ntrain = reduce_mem_usage(train)\n\nprint('-' * 80)\nprint('test')\ntest = reduce_mem_usage(test)","38f8a1db":"!pip install edm","f95cd767":"df = train.sample(frac=0.003)\nsents = df[\"comment_text\"].values\nlabels = df[\"target\"].values\nfrom edm import report\nprint(report.get_difficulty_report(sents, labels))","521aa3d7":"train.to_pickle(\"train.pkl\")\ntest.to_pickle(\"test.pkl\")\ntrain.to_csv('train_cleaned.csv', index=None)\ntest.to_csv('test_cleaned.csv', index=None)","67d4c938":"![](https:\/\/habrastorage.org\/webt\/mh\/4h\/nr\/mh4hnrif7tzbmycmjpiduozssa4.png)","ad83c35f":"Many thanks to the following kagglers and their great kernels:\n\n@Andrew Lukyanenko, https:\/\/www.kaggle.com\/artgor\/toxicity-eda-model-interpretation-and-more\n\n@Eike Dehling: https:\/\/www.kaggle.com\/eikedehling\/feature-engineering\n\n@Jagan: https:\/\/www.kaggle.com\/jagangupta\/stop-the-s-toxic-comments-eda\n\n@Theo Viel: https:\/\/www.kaggle.com\/theoviel\/improve-your-score-with-some-text-preprocessing\n\n@Aditya Soni: https:\/\/www.kaggle.com\/adityaecdrid\/public-version-text-cleaning-vocab-65\n\n@Guillaume Martin: https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n\n@Shujian Liu: https:\/\/www.kaggle.com\/shujian\/test-the-difficulty-of-this-classification-tasks\n\nThanks @kotakota1110 for his suggestion in Time Series part.\n","e9c2f56c":"FE: Some features might have relations with Toxicity, like capitals letters in the text, punctuations in the texts. Add the new features into the training set.","2fde8c31":"Test the Difficulty of this Classification Tasks.\n(Borrowed from\n\nKernel: https:\/\/www.kaggle.com\/shujian\/test-the-difficulty-of-this-classification-tasks\n\nPaper: https:\/\/arxiv.org\/abs\/1811.01910\n\nCode: https:\/\/github.com\/Wluper\/edm)","7cf7be2c":"Which toxicity related word appears Top 10 in jan_2017, but not in other time Top 10?","314be237":"Let's see the correlations between new features and targets.","55423d23":"Meanwhile, we can check the correlations between identities and the comment labels.","11667406":"Percent of toxic comments related to different identities, using target and popolation amount of each identity as weights:","f55963d8":"The following contraction_mapping is borrowed from @Aditya Soni. Credit goes to https:\/\/www.kaggle.com\/adityaecdrid\/public-version-text-cleaning-vocab-65","607b0ab1":"None of them... All the same... Then let's theck their frequency","3c3e92da":"When plotting these charts, I found that most data have a peak around Jan 2017. A bit curious. Let's check what's different between Jan 2017 and other time.","37b46b4c":"**To be continued...**","e0df8278":"Some simple clasic text precessing and generating the new dataset","cc1fd4f9":"After checking the whole time series, I'm also curious about, Which Time are People More Toxic?","05634c2f":"Moreover, we can do something fun, digging into the text with WordCloud. Let's check the Words frequented in Toxic Comments.","e4d1abd4":"Correlations between new features and targets in heatmap:","f4a32a54":"**Content**\n\n* Text Features heatmap\n\n* Weighted toxic comments & different identities\n\n* Identities & Comment Labels.\n\n* Time Series Toxicity with Race, Religion, Sexual orientation, Gender and Disability (updated April 18, weighted the data again)\n\n* What happened in Jan 2017? (updated April 14)\n\n* Which Time are People More Toxic? (updated April 16)\n\n* Words Frequented and Toxic_Mask\n\n* Text Processing (updated April 21)\n\n* Memory Reducing (updated April 22)\n\n* Test the Difficulty of the Task (updated April 24)\n\n-----To be added","0855a9ca":"We can also check the Time Series for Toxicity with different identities:\n\n(Thanks again for @kotakota1110's suggestion. Now we are using \"target\" and \"identity data amount\" to weight the data twice, which make more sense.)"}}