{"cell_type":{"0f2f460e":"code","97ad72f1":"code","9b6e2730":"code","869f2d44":"code","4a851967":"code","93d23a28":"code","771e8b1d":"code","3462dc71":"code","23da2f39":"code","9bb162d1":"code","c20c8231":"code","2ee507a8":"code","2238e479":"code","04221795":"code","a206b1ba":"code","1f4771c8":"code","d6e8c1d9":"code","0e447956":"code","5b092e00":"code","c3da7d97":"code","0f6504e0":"code","be2e45de":"code","bcf7dd73":"code","08f276ad":"code","fc196de2":"code","69e9744d":"code","ceabecdc":"code","68b19d6e":"code","2eb6bd09":"code","1f38dc16":"code","0824d6b3":"code","ee85405d":"code","0e5e8fcc":"code","3c5d9cf1":"code","a2f5be17":"code","c0b13e6a":"code","fcef39bd":"markdown","5ae2ac1f":"markdown","77744031":"markdown","29d086f9":"markdown","ff64afbf":"markdown","f3b0bc75":"markdown","5450c4fa":"markdown","641659ec":"markdown","288b5b85":"markdown","47308eb6":"markdown","ed2627fb":"markdown","2edeb6db":"markdown"},"source":{"0f2f460e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport email\nimport string\nfrom bs4 import BeautifulSoup\nimport string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport os\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom wordcloud import WordCloud\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_recall_curve \nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import roc_curve\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(49)","97ad72f1":"easy_ham_path = '\/kaggle\/input\/spamassassin-public-corpus\/easy_ham\/easy_ham\/'\nhard_ham_path = '\/kaggle\/input\/spamassassin-public-corpus\/hard_ham\/hard_ham\/'\nspam_path = '\/kaggle\/input\/spamassassin-public-corpus\/spam_2\/spam_2\/'","9b6e2730":"def get_data(path):\n    data = []\n    files = os.listdir(path)\n    for file in files:\n        f = open(path+file, encoding = \"ISO-8859-1\")\n        words_list = f.read()\n        data.append(words_list)\n        f.close()\n    return data","869f2d44":"easy_ham = get_data(easy_ham_path)\nhard_ham = get_data(hard_ham_path)\nham = easy_ham + hard_ham\nspam = get_data(spam_path)","4a851967":"np.random.shuffle(ham)\nnp.random.shuffle(spam)","93d23a28":"print(spam[49]) # take a look to the structure of our data","771e8b1d":"stemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\nclass email_to_clean_text(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None): \n        return self\n    def transform(self, X):\n        text_list = []\n        for mail in X:\n            b = email.message_from_string(mail)\n            body = \"\"\n\n            if b.is_multipart():\n                for part in b.walk():\n                    ctype = part.get_content_type()\n                    cdispo = str(part.get('Content-Disposition'))\n\n                    # skip any text\/plain (txt) attachments\n                    if ctype == 'text\/plain' and 'attachment' not in cdispo:\n                        body = part.get_payload(decode=True)  # get body of email\n                        break\n            # not multipart - i.e. plain text, no attachments, keeping fingers crossed\n            else:\n                body = b.get_payload(decode=True) # get body of email\n            #####################################################\n            soup = BeautifulSoup(body, \"html.parser\") #get text from body (HTML\/text)\n            text = soup.get_text().lower()\n            #####################################################\n            text = re.sub(r'(https|http)?:\\\/\\\/(\\w|\\.|\\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE) #remove links\n            ####################################################\n            text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text, flags=re.MULTILINE) #remove email addresses\n            ####################################################\n            text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n            ####################################################\n            text = ''.join([i for i in text if not i.isdigit()]) # remove digits\n            ####################################################\n            stop_words = stopwords.words('english')\n            words_list = [w for w in text.split() if w not in stop_words] # remove stop words\n            ####################################################\n            words_list = [lemmatizer.lemmatize(w) for w in words_list] #lemmatization\n            ####################################################\n            words_list = [stemmer.stem(w) for w in words_list] #Stemming\n            text_list.append(' '.join(words_list))\n        return text_list","3462dc71":"email_to_text = email_to_clean_text()","23da2f39":"text_ham = email_to_text.transform(ham)\ntext_spam = email_to_text.transform(spam)","9bb162d1":"# for Visualization\ntext_easy_ham = email_to_text.transform(easy_ham)\ntext_hard_ham = email_to_text.transform(hard_ham)","c20c8231":"data = [len(ham)\/len(ham+spam), len(spam)\/len(ham+spam)]\nlabels = ['ham', 'spam']\ncolors = ['green', 'red']\nplt.figure(figsize=(12, 5))\nplt.pie(data, labels = labels, autopct='%.0f%%', colors=colors)\nplt.show()\n","2ee507a8":"plt.figure(figsize=(8, 5))\nsns.countplot(x = ['ham']*len(ham) + ['spam']*len(spam), palette=colors)\nplt.show()","2238e479":"def plot_WordCloud(text_list):\n    unique_string=(\" \").join(text_list)\n    wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n    plt.figure(figsize=(15,8))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()","04221795":"plot_WordCloud(text_easy_ham)","a206b1ba":"plot_WordCloud(text_hard_ham)","1f4771c8":"plot_WordCloud(text_spam)","d6e8c1d9":"y = len(text_ham)*[0] + len(text_spam)*[1]","0e447956":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(text_ham+text_spam, y,\n                                                    stratify=y, \n                                                    test_size=0.2)\n","5b092e00":"vectorizer = CountVectorizer(stop_words='english')\nvectorizer.fit(X_train)","c3da7d97":"X_train = vectorizer.transform(X_train).toarray()\ny_train = np.array(y_train).reshape(len(y_train), 1)","0f6504e0":"X_test = vectorizer.transform(X_test).toarray()\ny_test = np.array(y_test).reshape(len(y_test), 1)","be2e45de":"rfc = RandomForestClassifier(n_estimators=1200)\nrfc.fit(X_train, y_train)","bcf7dd73":"predictions = rfc.predict(X_test)","08f276ad":"print(\"accuracy score = {}%\".format(round(accuracy_score(y_test, predictions)*100, 2)))\nprint(\"f1 score = {}\".format(round(f1_score(y_test, predictions), 2)))","fc196de2":"conf_mx = confusion_matrix(y_test, predictions)","69e9744d":"fig, axes = plt.subplots(1, 2, sharex=True, figsize=(18,7))\nfig.suptitle('Confusion matrix', c='r')\nsns.heatmap(conf_mx\/np.sum(conf_mx), ax=axes[0], annot=True, \n            fmt='.2%', cmap='Blues')\naxes[0].set_xlabel('Predicted labels')\naxes[0].set_ylabel('Actual labels')\n\nsns.heatmap(conf_mx, ax=axes[1], annot=True, cmap='Blues', fmt='')\naxes[1].set_xlabel('Predicted labels')\naxes[1].set_ylabel('Actual labels')\nplt.show()","ceabecdc":"y_scores = cross_val_predict(rfc, X = X_train, y = y_train.reshape((1, len(y_train)))[0], cv=5, \n                             method=\"predict_proba\")","68b19d6e":" precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores[:,1])","2eb6bd09":"plt.figure(figsize=(10,4), dpi=200)\nplt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\nplt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\nplt.legend(loc=\"center right\", fontsize=16) # Not shown in the book\nplt.xlabel(\"Threshold\", fontsize=16)        # Not shown\nplt.grid(True) \nplt.title(\"precision recall curve\")\nplt.show()","1f38dc16":"fpr, tpr, thresholds = roc_curve(y_train, y_scores[:,1])\nroc_auc_score(y_train, y_scores[:,1])","0824d6b3":"plt.figure(figsize=(10, 6))\nplt.plot(fpr, tpr, linewidth=2, color='r')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.axis([0, 1, 0, 1])\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.grid(True)\nplt.title(\"ROC Curve\")\nplt.show()","ee85405d":"my_pipeline = Pipeline(steps=[\n    ('text', email_to_clean_text()),\n    ('vector', vectorizer),\n    ('model', rfc)])","0e5e8fcc":"y1 = np.array(len(ham)*[0]+len(spam)*[1]).reshape(len(ham+spam), 1)","3c5d9cf1":"y1","a2f5be17":"my_pipeline.fit(ham+spam, y1)\n","c0b13e6a":"my_pipeline.predict([hard_ham[77]])","fcef39bd":"# IMPORTING LIBRARIES","5ae2ac1f":"* [1. IMPORTING LIBRARIES](#1)\n* [2. LOADING DATA](#2)\n* [3. DATA PREPREPROCESSING](#3)\n* [4. Data Visualization](#4)\n* [5. Splitting dataset](#5)\n* [6. VECTORIZATION](#6)\n* [7. MODEL BUILDING](#7)\n* [8. Model Evaluation](#8)\n* [9. Data Pipeline](#9)","77744031":"# DATA PREPREPROCESSING","29d086f9":"**ham : 0**\n\n**spam : 1**","ff64afbf":"# Data Pipeline","f3b0bc75":"# Data Visualization","5450c4fa":"# LOADING DATA","641659ec":"# MODEL BUILDING","288b5b85":"# Model Evaluation","47308eb6":"**ham : 0**\n\n**spam : 1**","ed2627fb":"# VECTORIZATION","2edeb6db":"# Splitting dataset"}}