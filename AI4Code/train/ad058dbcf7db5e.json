{"cell_type":{"3e51396e":"code","6576e9df":"code","461d7190":"code","8e2e495b":"code","c497a525":"code","0f63869c":"code","3b74b773":"code","7a562b29":"code","9a4e02d2":"code","8a5533e2":"code","4a1a5448":"code","29c406a1":"code","de096439":"code","b9908f6c":"code","74e45ee3":"code","925b32ee":"code","c39157da":"code","f7b7033b":"code","593e672b":"code","44000398":"code","dab81408":"code","1bdd2cce":"code","746585ad":"code","7981d792":"code","3b347cf5":"code","b2d83268":"code","78292d0e":"code","c25b06a6":"code","54c3e5fa":"code","82f82351":"code","74a89cf0":"code","0b67b8f2":"code","c71e4208":"markdown","6fa26600":"markdown","6f4b255c":"markdown","0b611241":"markdown","f3b70f4b":"markdown","fb5ffea2":"markdown","a6966503":"markdown","580cf90f":"markdown","ab8bf83b":"markdown","82555be2":"markdown","c65244a0":"markdown","17623430":"markdown","913974c5":"markdown"},"source":{"3e51396e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6576e9df":"from pathlib import Path","461d7190":"dataset_path = Path(r'..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')\n\nfile_path = list(dataset_path.glob(r'**\/*.png'))\n\n# create labels from the folder name\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path))","8e2e495b":"file_path = pd.Series(file_path).astype(str)\nlabels = pd.Series(labels)\n\ndf = pd.concat([file_path, labels], axis=1)\n\ndf.columns = ['image', 'label']\n\ndf.head()","c497a525":"import matplotlib.pyplot as plt","0f63869c":"fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.image[i]))\n    ax.set_title(df.label[i])\n    \nplt.show()","3b74b773":"df.label.value_counts()","7a562b29":"df = df[df['label'].apply(lambda x: x[-2:] != 'GT')].reset_index(drop=True)\ndf.label.value_counts()","9a4e02d2":"from sklearn.model_selection import train_test_split","8a5533e2":"x_train, x_test = train_test_split(df, test_size=0.3,random_state=30)\nx_train, x_val = train_test_split(x_train, test_size=0.2, random_state=30)","4a1a5448":"print(\"Shape of training data\", x_train.shape)\nprint(\"Shape of test data\", x_test.shape)\nprint(\"Shape of validation data\", x_val.shape)","29c406a1":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D","de096439":"image_data_generator = ImageDataGenerator(rescale = 1.\/255,\n    rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain = image_data_generator.flow_from_dataframe(dataframe=x_train, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical', shuffle=False)\ntest = image_data_generator.flow_from_dataframe(dataframe=x_test, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical', shuffle=False)\nval = image_data_generator.flow_from_dataframe(dataframe=x_val, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical',shuffle=False)","b9908f6c":"input_shape = (200, 200, 3)","74e45ee3":"# define the model\n# base_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape=input_shape, include_top=False)\n\n# for layer in base_model.layers:\n#     layer.trainable = False\n        \n\n# model = Sequential()\n# model.add(base_model)\n# model.add(GlobalAveragePooling2D())\n# model.add(Dense(128))\n# model.add(Dropout(0.2))\n# model.add(Dense(9, activation='softmax'))\n# model.summary()\n        ","925b32ee":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape ),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(9, activation='softmax')\n])\n\nmodel.summary()","c39157da":"from tensorflow.keras.optimizers import Adam","f7b7033b":"model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)\n\nhistory = model.fit(train, validation_data=val, epochs=20, callbacks=callback)","593e672b":"model.save('model-1.h5')","44000398":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","dab81408":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","1bdd2cce":"pred = model.predict(test)","746585ad":"pred = np.argmax(pred, axis=1)","7981d792":"labels = train.class_indices","3b347cf5":"labels","b2d83268":"labels = dict((v,k) for k, v in labels.items())","78292d0e":"labels","c25b06a6":"y_pred = [labels[k] for k in pred]","54c3e5fa":"from sklearn.metrics import classification_report, confusion_matrix","82f82351":"print(classification_report(x_test.label, y_pred))","74a89cf0":"print(confusion_matrix(x_test.label, y_pred))","0b67b8f2":"test_accuracy = model.evaluate(test)[1]","c71e4208":"**Training Accuracy is 87.8%**\n**Validation Accuracy is 87.22%**","6fa26600":"## Read the data","6f4b255c":"## Train the model","0b611241":"Extract the class with highest probability for all the test files","f3b70f4b":"### Still Working on this problem statement. In the next versions, I will try to increase the validation and training accuracy.","fb5ffea2":"## Check number of diffrent class of fish in the dataset\nNote that the ground truth files have also been added (Files with 'GT' in their name)","a6966503":"# UPDATE (Version 1 to Version 2) - \nIn version 1, the validation accuracy was 82% and training accuracy 91%. This denotes that my model was overfitting.\nI version 2, I was able to incraese the validation accuracy from 82% to 87% and reduce the training accuracy to 87% as well. Now my model is no more overfitted.\n\n## What did I do to remove the overfitting?\n* I applied data augmentation techniques like rotating, flipping the training images to generate augmented data.\n* I added one more convolution and maxpooling layer to the model.","580cf90f":"We will remove the ground truth files, we don't need them.","ab8bf83b":"\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f","82555be2":"## Check model's performance","c65244a0":"## Define the model","17623430":"## Display the images in the dataset","913974c5":"## Create train, test and validation dataset"}}