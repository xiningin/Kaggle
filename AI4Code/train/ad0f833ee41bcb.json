{"cell_type":{"7d506b8f":"code","c0dfcfdf":"code","69a8e609":"code","ad1b1c6e":"code","b954510a":"code","9a489fdb":"code","cf157f8b":"code","275b93f2":"code","44a3c60d":"code","4eaf521f":"code","ce4471de":"code","02183a7e":"code","42214671":"code","793c7591":"code","9296aaa3":"code","0f085296":"code","a5a83704":"code","fef6d027":"code","1aebb9c2":"code","653ad693":"code","a6f66acd":"code","e7c78843":"code","4654861a":"code","03542fa7":"code","668eb70f":"code","d6d421e4":"code","2ebace7a":"code","6b8e8e7b":"code","b1e91fec":"code","02d81a8b":"code","614e8dec":"code","cd657a76":"code","233dea26":"code","ec9d8224":"code","4a7fe98f":"code","4462c7a8":"code","ed921223":"code","67c8da18":"code","8a0ca553":"code","b3843150":"code","1a676602":"code","1e303de9":"markdown","0e9b6de3":"markdown","0c57b308":"markdown","b85feed7":"markdown","53bec8df":"markdown","1fd5aa9c":"markdown","415a7cf2":"markdown"},"source":{"7d506b8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0dfcfdf":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","69a8e609":"dd = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","ad1b1c6e":"dd.info()","b954510a":"dd.head()","9a489fdb":"sns.heatmap(dd.isnull(),yticklabels=False, cbar=False, cmap='viridis')","cf157f8b":"# We get to know that age and cabin data are the ones missing. We can replace the age column since it is the necessary one here.","275b93f2":"sns.countplot(x='Survived',hue = 'Pclass', data=dd)","44a3c60d":"sns.countplot(x='Survived',hue = 'Sex', data=dd)","4eaf521f":"sns.countplot(x='SibSp',data=dd)","ce4471de":"sns.boxplot(x='Pclass', y='Age',data=dd)","02183a7e":"#imputing age for missing values","42214671":"def imp_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","793c7591":"dd['Age']= dd[['Age','Pclass']].apply(imp_age,axis = 1)","9296aaa3":"sns.heatmap(dd.isnull(), cmap='viridis',yticklabels=False)","0f085296":"dd.drop('Cabin',axis=1,inplace=True)","a5a83704":"dd.dropna(inplace=True)","fef6d027":"dd.head(2)","1aebb9c2":"gend = pd.get_dummies(dd['Sex'],drop_first=True)","653ad693":"embark = pd.get_dummies(dd['Embarked'],drop_first=True)","a6f66acd":"embark.head(2)\n","e7c78843":"dd = pd.concat([dd,gend,embark],axis=1)","4654861a":"dd.head()","03542fa7":"dd.drop(['Sex','Name', 'Embarked','Ticket'],axis=1,inplace=True)","668eb70f":"dd.head(2)","d6d421e4":"dd.drop(['PassengerId'],axis=1,inplace=True)","2ebace7a":"dd.head()\n","6b8e8e7b":"#Logistic Regression.\nX = dd.drop('Survived',axis = 1)\ny = dd['Survived']","b1e91fec":"from sklearn.model_selection import train_test_split","02d81a8b":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","614e8dec":"from sklearn.linear_model import LogisticRegression","cd657a76":"logmodel = LogisticRegression()","233dea26":"logmodel.fit(X_train,y_train)","ec9d8224":"predictions = logmodel.predict(X_test)","4a7fe98f":"from sklearn.metrics import classification_report","4462c7a8":"print(classification_report(y_test,predictions))","ed921223":"from sklearn.metrics import confusion_matrix","67c8da18":"conf = confusion_matrix(y_test,predictions)","8a0ca553":"conf","b3843150":"sns.heatmap(pd.DataFrame(conf),annot=True,fmt='g')","1a676602":"# Kind of acceptable, looking at the Heatmap.","1e303de9":"# TITANIC DATASET - LOGISTIC REGRESSION\n","0e9b6de3":"**Analysing the Siblings\/Spouse Data**","0c57b308":"**SURVIVAL BASED ON GENDER**","b85feed7":"**CREATING A CONFUSION MATRIX AND THEN A HEATNMAP**","53bec8df":"> Checking the head of the file to get a glimpse of the dataset.","1fd5aa9c":"**SURVIVAL BASED ON PASSENGER CLASS**","415a7cf2":"> Now we check for the null values.\n**We plot a hearmap for the same to check where the most of the null values are present.**"}}