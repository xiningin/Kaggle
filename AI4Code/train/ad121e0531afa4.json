{"cell_type":{"93cf18e4":"code","5de4dbdb":"code","172d88b5":"code","f8e86b1a":"code","55f77c79":"code","8087f244":"code","a195e4bf":"code","7d2a43eb":"code","ea566198":"code","c7922f84":"markdown","c0b96fd5":"markdown","9c569cc1":"markdown","910a0be5":"markdown","2285d1c3":"markdown","802cd710":"markdown","d5168df6":"markdown","b54188fd":"markdown","a5a7a4f4":"markdown","6c3b6f38":"markdown","2bd1562c":"markdown"},"source":{"93cf18e4":"# ! curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n# ! python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev","5de4dbdb":"%%sh\npip install -q pytorch-lightning==1.1.8\npip install -q timm\npip install -q albumentations\npip install -q --upgrade wandb","172d88b5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport timm\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nimport os\nimport cv2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nimport wandb\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.simplefilter('ignore')","f8e86b1a":"Config = dict(\n    NFOLDS = 5,\n    EPOCHS = 5,\n    LR = 2e-4,\n    IMG_SIZE = (224, 224),\n    MODEL_NAME = 'tf_efficientnet_b6_ns',\n    DR_RATE = 0.35,\n    NUM_LABELS = 1,\n    TRAIN_BS = 32,\n    VALID_BS = 16,\n    min_lr = 1e-6,\n    T_max = 20,\n    T_0 = 25,\n    NUM_WORKERS = 4,\n    infra = \"Kaggle\",\n    competition = 'petfinder',\n    _wandb_kernel = 'tanaym',\n    wandb = False\n)","55f77c79":"# Make a W&B Logger\nwandb_logger = WandbLogger(project='pytorchlightning', group='vision', job_type='train', anonymous='allow', config=Config)","8087f244":"class PetfinderData(Dataset):\n    def __init__(self, df, is_test=False, augments=None):\n        self.df = df\n        self.is_test = is_test\n        self.augments = augments\n        \n        self.images, self.meta_features, self.targets = self._process_df(self.df)\n    \n    def __getitem__(self, index):\n        img = self.images[index]\n        meta_feats = self.meta_features[index]\n        meta_feats = torch.tensor(meta_feats, dtype=torch.float32)\n        \n        img = cv2.imread(img)\n        img = img[:, :, ::-1]\n        img = cv2.resize(img, Config['IMG_SIZE'])\n        \n        if self.augments:\n            img = self.augments(image=img)['image']\n        \n        if not self.is_test:\n            target = torch.tensor(self.targets[index], dtype=torch.float32)\n            return img, meta_feats, target\n        else:\n            return img, meta_feats\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _process_df(self, df):\n        TRAIN = \"..\/input\/petfinder-pawpularity-score\/train\"\n        TEST = \"..\/input\/petfinder-pawpularity-score\/test\"\n        \n        if not self.is_test:\n            df['Id'] = df['Id'].apply(lambda x: os.path.join(TRAIN, x+\".jpg\"))\n        else:\n            df['Id'] = df['Id'].apply(lambda x: os.path.join(TEST, x+\".jpg\"))\n            \n        meta_features = df.drop(['Id', 'Pawpularity'], axis=1).values\n        \n        return df['Id'].tolist(), meta_features, df['Pawpularity'].tolist()","a195e4bf":"class Augments:\n    \"\"\"\n    Contains Train, Validation Augments\n    \"\"\"\n    train_augments = Compose([\n        Resize(*Config['IMG_SIZE'], p=1.0),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ],p=1.)\n    \n    valid_augments = Compose([\n        Resize(*Config['IMG_SIZE'], p=1.0),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ], p=1.)","7d2a43eb":"class PetFinderModel(pl.LightningModule):\n    def __init__(self, pretrained=True):\n        super(PetFinderModel, self).__init__()\n        self.model = timm.create_model(Config['MODEL_NAME'], pretrained=pretrained)\n        \n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features + 12, Config['NUM_LABELS'])\n        \n        self.train_loss = nn.MSELoss()\n        self.valid_loss = nn.MSELoss()\n\n    def forward(self, images, meta):\n        features = self.model(images)\n        features = torch.cat([features, meta], dim=1)\n        output = self.fc(features)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        train_loss = torch.sqrt(self.train_loss(out, target))\n        \n        logs = {'train_loss': train_loss}\n        \n        return {'loss': train_loss, 'log': logs}\n    \n    def validation_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        valid_loss = torch.sqrt(self.valid_loss(out, target))\n        \n        return {'val_loss': valid_loss}\n    \n    def validation_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        logs = {'val_loss': avg_loss}\n        \n        print(f\"val_loss: {avg_loss}\")\n        return {'avg_val_loss': avg_loss, 'log': logs}\n    \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.parameters(), lr=Config['LR'])\n        sch = torch.optim.lr_scheduler.CosineAnnealingLR(\n            opt, \n            T_max=Config['T_max'],\n            eta_min=Config['min_lr']\n        )\n        \n        return [opt], [sch]","ea566198":"# Run the Kfolds training loop\nkf = StratifiedKFold(n_splits=Config['NFOLDS'])\ntrain_file = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\n\nfor fold_, (train_idx, valid_idx) in enumerate(kf.split(X=train_file, y=train_file['Pawpularity'])):\n    print(f\"{'='*20} Fold: {fold_} {'='*20}\")\n    \n    train_df = train_file.loc[train_idx]\n    valid_df = train_file.loc[valid_idx]\n    \n    train_set = PetfinderData(\n        train_df,\n        augments = Augments.train_augments\n    )\n\n    valid_set = PetfinderData(\n        valid_df,\n        augments = Augments.valid_augments\n    )\n    \n    train = DataLoader(\n        train_set,\n        batch_size=Config['TRAIN_BS'],\n        shuffle=True,\n        num_workers=Config['NUM_WORKERS'],\n        pin_memory=True\n    )\n    valid = DataLoader(\n        valid_set,\n        batch_size=Config['VALID_BS'],\n        shuffle=False,\n        num_workers=Config['NUM_WORKERS']\n    )\n    \n    checkpoint_callback = ModelCheckpoint(\n        monitor=\"val_loss\",\n        dirpath=\".\/\",\n        filename=f\"fold_{fold_}_{Config['MODEL_NAME']}\",\n        save_top_k=1,\n        mode=\"min\",\n    )\n    \n    model = PetFinderModel()\n    trainer = pl.Trainer(\n        max_epochs=Config['EPOCHS'], \n        gpus=1, \n        callbacks=[checkpoint_callback], \n        logger= wandb_logger\n    )\n    trainer.fit(model, train, valid)","c7922f84":"<center><img src=\"https:\/\/i.imgur.com\/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\"\/><\/center><br>\n<p style=\"text-align:center\">WandB is a developer tool for companies turn deep learning research projects into deployed software by helping teams track their models, visualize model performance and easily automate training and improving models.\nWe will use their tools to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.<br><br><\/p>\n\n![img](https:\/\/i.imgur.com\/BGgfZj3.png)","c0b96fd5":"<h1 style='color: #fc0362; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 24px'>If you liked this notebook, kindly leave an upvote \u2b06\ufe0f<\/h1>","9c569cc1":"To login to W&B, you can use below snippet.\n\n```python\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\nwandb.login(key=wb_key)\n```\nMake sure you have your W&B key stored as `WANDB_API_KEY` under Add-ons -> Secrets\n\nYou can view [this](https:\/\/www.kaggle.com\/ayuraj\/experiment-tracking-with-weights-and-biases) notebook to learn more about W&B tracking.\n\nIf you don't want to login to W&B, the kernel will still work and log everything to W&B in anonymous mode.","910a0be5":"<div class=\"alert alert-info\">\n    <h2 align='center'>\ud83d\udc3e PyTorch Lightning Training Baseline for GPU & TPU + W&B Tracking \ud83d\ude84<\/h1>\n<\/div>\n\n<p style='text-align: center'>\n    To run the model on TPU, un-comment and run the below cell and change the <code>gpus=1<\/code> argument to <code>tpu_cores=1<\/code> or <code>tpu_cores=8<\/code> in the <code>Trainer<\/code> class.\n<\/p>","2285d1c3":"## [View the Complete Dashboard Here \ud83c\udfaf](https:\/\/wandb.ai\/anony-mouse-138818\/pytorchlightning\/runs\/1mgcybd2?apiKey=9c1b4ff53762c75e39d283f5434cc5552455b179)","802cd710":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>4. Pytorch Lightning Model Class<\/h1>","d5168df6":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>5. KFolds Model Training<\/h1>","b54188fd":"![](https:\/\/imgur.com\/XyvhYFZ.gif)","a5a7a4f4":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>1. Installation & Imports<\/h1>","6c3b6f38":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>3. Augmentations<\/h1>","2bd1562c":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>2. Dataset Class<\/h1>"}}