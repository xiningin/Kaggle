{"cell_type":{"6fde73b4":"code","ed85b7d9":"code","57106189":"code","095a61ff":"code","efbe3c14":"code","8c6b7511":"code","328165ca":"code","3057929b":"code","52f17056":"code","0781b937":"code","f851d2e4":"code","6cc6004d":"code","0359481f":"code","2393c3d9":"code","ba72a613":"code","88d9a393":"code","9f8a2ff8":"code","242e376a":"code","48625fbe":"code","4b75b6a8":"code","92143390":"code","bd64febb":"code","5b1443d0":"code","58a74e1e":"code","b2bd41ed":"code","104a4175":"code","b12f1603":"code","65cc9c61":"code","4eef54d0":"code","abdb1297":"markdown","bee58ff8":"markdown","661eb0cb":"markdown","16dd630f":"markdown","d858009f":"markdown","a0c29513":"markdown","cdbb95ef":"markdown","3339bc2f":"markdown","a81b3f69":"markdown","ed4648b4":"markdown","a787ae29":"markdown","78a8ac10":"markdown","de981fa2":"markdown","83ba6397":"markdown","901bafc5":"markdown","9e96477c":"markdown","504f65f1":"markdown"},"source":{"6fde73b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"white\") #white background style for seaborn plots\nsns.set(style=\"whitegrid\", color_codes=True)\nfrom sklearn.metrics import accuracy_score","ed85b7d9":"animal=pd.read_csv('..\/input\/zoo.csv')\nani_class=pd.read_csv('..\/input\/class.csv')","57106189":"animal.head()","095a61ff":"# Check class table for later use.\nani_class","efbe3c14":"# Check data type for each variable\nanimal.info()","8c6b7511":"animal.isnull().sum()","328165ca":"animal.describe()","3057929b":"# Check if class_type has correct values\nprint(animal.class_type.unique())","52f17056":"print(animal.legs.unique())","0781b937":"# just curious which animal has 5 legs\nanimal.loc[animal['legs'] == 5]","f851d2e4":"# Join animal table and class table to show actual class names\ndf=pd.merge(animal,ani_class,how='left',left_on='class_type',right_on='Class_Number')\ndf.head()","6cc6004d":"plt.hist(df.class_type, bins=7)","0359481f":"# See which class the most zoo animals belong to\nsns.factorplot('Class_Type', data=df,kind=\"count\", aspect=2)","2393c3d9":"# heatmap to show correlations\nplt.subplots(figsize=(20,15))\nax = plt.axes()\nax.set_title(\"Correlation Heatmap\")\ncorr = animal.corr()\nsns.heatmap(corr, annot=True,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","ba72a613":"# show vairable correlation which is more than 0.7 (positive or negative)\ncorr[corr != 1][abs(corr)> 0.7].dropna(how='all', axis=1).dropna(how='all', axis=0)","88d9a393":"df.groupby('Class_Type').mean()","9f8a2ff8":"# checking leg number in each class\ng = sns.FacetGrid(df, col=\"Class_Type\")\ng.map(plt.hist, \"legs\")\nplt.show()","242e376a":"from sklearn.model_selection import train_test_split\n# 80\/20 split\n#animal=animal.drop(['eggs', 'hair'], axis=1)\n#X = animal.iloc[:,1:15]\n#y = animal.iloc[:,15]\nX = animal.iloc[:,1:17]\ny = animal.iloc[:,17]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)","48625fbe":"from sklearn.linear_model import Perceptron\nppn = Perceptron(eta0=1, random_state=1)\nppn.fit(X_train, y_train)\n# make prediction\ny_pred = ppn.predict(X_test)\n# check model accuracy\naccuracy_score(y_pred,y_test)","4b75b6a8":"# 70\/30 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\nppn = Perceptron(eta0=1, random_state=1)\nppn.fit(X_train, y_train)\ny_pred = ppn.predict(X_test)\naccuracy_score(y_pred,y_test)","92143390":"from sklearn.model_selection import cross_val_score\nscore_ppn=cross_val_score(ppn, X,y, cv=5)\nscore_ppn","bd64febb":"# The mean score and the 95% confidence interval of the score estimate are:\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (score_ppn.mean(), score_ppn.std() * 2))","5b1443d0":"from sklearn import tree\ndt = tree.DecisionTreeClassifier()\nscore_dt=cross_val_score(dt, X,y, cv=5)\nscore_dt","58a74e1e":"# The mean score and the 95% confidence interval of the score estimate are:\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (score_dt.mean(), score_dt.std() * 2))","b2bd41ed":"from sklearn.svm import SVC\nsvc = SVC(kernel='linear', C=1)\nscore_svc=cross_val_score(svc, X,y, cv=5)\nscore_svc","104a4175":"# The mean score and the 95% confidence interval of the score estimate are:\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (score_svc.mean(), score_svc.std() * 2))","b12f1603":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\nscore_lr=cross_val_score(lr, X,y, cv=5)\nscore_lr","65cc9c61":"# The mean score and the 95% confidence interval of the score estimate are:\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (score_lr.mean(), score_lr.std() * 2))","4eef54d0":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'Logistic Regression', 'Perceptron', 'Decision Tree'],\n    'Score': [score_svc.mean(), score_lr.mean(), score_ppn.mean(), score_dt.mean()]})\nmodels.sort_values(by='Score', ascending=False)","abdb1297":"By spliting train\/test dataset again did make the model to fit better. But I would do a cross validation for this model.","bee58ff8":"**4.4 SVM**","661eb0cb":"**3. Exploratory Data Analysis **","16dd630f":"**4. Classification & Cross Validation **","d858009f":"**2. Assess Data Quality & Missing Values **","a0c29513":"**4.2 Perceptron Method \n**<br>Perceptron is good for multi-class classification, which might be a good method for us, since we have 7 animal classes.","cdbb95ef":"**4.1 Split train and test dataset **","3339bc2f":"It is too obvious that if \"milk\" exists, then the animal is mammal; if \"feathers\" exists, then it should be bird. ","a81b3f69":"**4.5 Multiclass Logistic Regression**","ed4648b4":"Good news is there's no missing value in this table! \nAnd data seems to be very clean that only full number is presented.","a787ae29":"So the accuracy for Perceptron model is around 0.89, which is fine, but I'd like to try some other models.","78a8ac10":"**4.3 Decision Tree**","de981fa2":"## **Introduction**\n\nThis notebook contains the steps enumerated below for analyzing characteristics of zoo animals and creating classifications.<br> \nData is available at: https:\/\/www.kaggle.com\/uciml\/zoo-animal-classification\/data <br><br>\n1. [Import Data & Python Packages](#1-bullet) <br>\n2. [Assess Data Quality & Missing Values](#2-bullet)<br>\n3. [Exploratory Data Analysis](#3-bullet) <br>\n4. [Classification & Cross Validation](#4-bullet) <br>\n    * [4.1 Split train and test dataset](#4.1-bullet) <br>\n    * [4.2 Perceptron Method](#4.2-bullet)<br>\n      * [4.2.1 Cross Validation for Perceptron Method](#4.2.1-bullet) <br>\n    * [4.3 Decision Tree](#4.3-bullet)<br>\n    * [4.4 SVM](#4.4-bullet)<br>\n    * [4.5 Multiclass Logistic Regression](#4.5-bullet)<br>\n5. [Summary](#5-bullet) <br>","83ba6397":"**1. Import Data & Python Packages **","901bafc5":"**5. Summary**","9e96477c":"After comparing the score of each model, the SVM model seems to be the most accurate.","504f65f1":"**4.2.1 Cross Validation for Perceptron Method**<br>\nK-fold CV - we split our data into k subsets, and train on k-1 one of those subset. What we do is to hold the last subset for test.<br>\n* A model is trained using k-1 of the folds as training data<br>\n* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy)."}}