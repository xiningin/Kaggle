{"cell_type":{"036e6663":"code","37736b35":"code","67cf27b1":"code","b8ea632b":"code","827c6c61":"code","11bfaa01":"code","5f8903b9":"code","b17c9c25":"code","a78dd67f":"code","e85a9f5d":"code","45231ebb":"code","4c133dbf":"code","aa14e93b":"code","773cc8d5":"code","0086bb3d":"code","97b3d3ed":"code","8bd5f664":"code","11d1396b":"code","e4d686c9":"code","c34ae4f6":"code","06541177":"code","a0c9c803":"markdown","62cf4fe9":"markdown","b2c45a84":"markdown","e99f4497":"markdown","39cd546c":"markdown","875a353f":"markdown","4232af88":"markdown"},"source":{"036e6663":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","37736b35":"train = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')","67cf27b1":"test = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')","b8ea632b":"train.head()","827c6c61":"test.head()","11bfaa01":"from sklearn.model_selection import train_test_split","5f8903b9":"X = train.drop(['Id', 'Cover_Type'], axis=1)\ny = train['Cover_Type']","b17c9c25":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","a78dd67f":"from sklearn.ensemble import RandomForestClassifier ","e85a9f5d":"rfc = RandomForestClassifier(n_estimators=100)","45231ebb":"rfc.fit(X_train, y_train)","4c133dbf":"from sklearn.metrics import classification_report, accuracy_score","aa14e93b":"rfc.score(X_train, y_train)","773cc8d5":"predictions = rfc.predict(X_test)","0086bb3d":"accuracy_score(y_test, predictions)","97b3d3ed":"print(classification_report(y_test, predictions))","8bd5f664":"test_Id = test['Id'] #store tests' Id column for the output file","11d1396b":"test = test.drop('Id', axis=1) #delete the Id column for the prediction","e4d686c9":"test.head()","c34ae4f6":"test_pred = rfc.predict(test)","06541177":"output = pd.DataFrame({'Id': test_Id,\n                       'Cover_Type': test_pred})\noutput.to_csv('submission.csv', index=False)","a0c9c803":"We'll then train a simple Random Forest Classifier with 100 trees.","62cf4fe9":"## Finding the 'Cover_Type' for Test","b2c45a84":"## Random Forests","e99f4497":"## Prediction and Evaluation","39cd546c":"Let's use 70% of the Data for training, and 30% for validation.","875a353f":"## Train Test Split","4232af88":"Save test predictions to file"}}