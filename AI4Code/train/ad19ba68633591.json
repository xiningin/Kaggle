{"cell_type":{"a020b87b":"code","b4c6160e":"code","4114dfd9":"code","39291961":"code","cb01c623":"code","a69a58bb":"code","3d45d8e8":"code","1c9307dc":"code","74839295":"code","1b169e1c":"code","d78c34a2":"code","ef4c53db":"code","6ba3e1d8":"code","9baee1fa":"code","f3b58e48":"code","816efe70":"code","6eb3fb70":"code","4ac29ee3":"code","91265625":"code","4e9baafb":"code","2fecd6ab":"code","09753b9e":"code","ab164754":"code","dedecbff":"code","7572be34":"code","05a8413f":"code","e3804b18":"code","456f7d6b":"markdown"},"source":{"a020b87b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b4c6160e":"%matplotlib inline\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm","4114dfd9":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)\n","39291961":"SAMPLE_PER_CATEGORY = 200\nSEED = 1987\ndata_dir = '..\/input\/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')","cb01c623":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","a69a58bb":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train\/{}\/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.head(2)\ntrain.shape","3d45d8e8":"train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\ntrain = train.sample(frac=1)\ntrain.index = np.arange(len(train))\ntrain.head(2)\ntrain.shape","1c9307dc":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test\/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.head(2)\ntest.shape","74839295":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    return img","1b169e1c":"fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\ngrid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\ni = 0\nfor category_id, category in enumerate(CATEGORIES):\n    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n        ax = grid[i]\n        img = read_img(filepath, (224, 224))\n        ax.imshow(img \/ 255.)\n        ax.axis('off')\n        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n            ax.text(250, 112, filepath.split('\/')[1], verticalalignment='center')\n        i += 1\nplt.show();","d78c34a2":"np.random.seed(seed=SEED)\nrnd = np.random.random(len(train))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\nytr = train.loc[train_idx, 'category_id'].values\nyv = train.loc[valid_idx, 'category_id'].values\nlen(ytr), len(yv)","ef4c53db":"from keras.applications.resnet50 import ResNet50,preprocess_input, decode_predictions\nINPUT_SIZE=224\nPOOLING='avg'\nx_train=np.zeros((len(train),INPUT_SIZE,INPUT_SIZE,3),dtype=np.float32)\nfor i,file in tqdm(enumerate(train['file'])):\n    img = read_img(os.path.join(data_dir,file),(INPUT_SIZE,INPUT_SIZE))\n    x=preprocess_input(np.expand_dims(img.copy(),axis=0)) #need to be changed for every model\n    x_train[i]=x\nprint('Train image shape: {} size: {:,}'.format(x_train.shape,x_train.size))","6ba3e1d8":"xtrain=x_train[train_idx]\nxvalid=x_train[valid_idx]\nprint((xtrain.shape,xvalid.shape))","9baee1fa":"from keras.preprocessing import image\nvgg_bottleneck = ResNet50(weights='imagenet', include_top=False)","f3b58e48":"train_vgg_bf = vgg_bottleneck.predict(xtrain, batch_size=32, verbose=1)\nvalid_vgg_bf = vgg_bottleneck.predict(xvalid, batch_size=32, verbose=1)\nprint('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\nprint('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))","816efe70":"train_vgg_bf=train_vgg_bf.reshape(1899,100352)\nvalid_vgg_bf=valid_vgg_bf.reshape(501,100352)","6eb3fb70":"import keras\none_hot_labels = keras.utils.to_categorical(ytr, num_classes=12)\nvalid_labels = keras.utils.to_categorical(yv, num_classes=12)","4ac29ee3":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nmodel=Sequential()\n\nmodel.add(Dense(1000, input_dim=100352, activation='relu',kernel_initializer='uniform'))\nkeras.layers.core.Dropout(0.3, noise_shape=None, seed=None)\n\nmodel.add(Dense(500,input_dim=1000,activation='sigmoid'))\nkeras.layers.core.Dropout(0.4, noise_shape=None, seed=None)\n\nmodel.add(Dense(150,input_dim=500,activation='sigmoid'))\nkeras.layers.core.Dropout(0.2, noise_shape=None, seed=None)\n\nmodel.add(Dense(units=12))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nmodel.summary()","91265625":"history= model.fit(train_vgg_bf,one_hot_labels, epochs=10, batch_size=128,validation_data=(valid_vgg_bf, valid_labels))\nprint(history.history.keys())\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('batch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nmodel.save_weights('fc_model.h5')","4e9baafb":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test\/{}'.format(file),file])\ntest=pd.DataFrame(test,columns=['file_path','file'])\ntest.head(2)","2fecd6ab":"x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in tqdm(enumerate(test['file_path'])):\n    img = read_img(os.path.join(data_dir,file), (INPUT_SIZE, INPUT_SIZE))\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_test[i] = x\nprint('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))","09753b9e":"test_x_bf = vgg_bottleneck.predict(x_test, batch_size=32, verbose=1)\nprint('Test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\n","ab164754":"test_x_bf=test_x_bf.reshape(794,100352)","dedecbff":"test_preds = model.predict(test_x_bf)","7572be34":"np.argmax(test_preds,axis=1).shape","05a8413f":"test_pred_one = np.argmax(test_preds,axis=1)\ntest['category_id'] = test_pred_one\ntest['species'] = [CATEGORIES[c] for c in test_pred_one]\ntest[['file', 'species']].to_csv('submission.csv', index=False)","e3804b18":"!ls","456f7d6b":"Extra Work"}}