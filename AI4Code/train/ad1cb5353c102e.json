{"cell_type":{"0ff9967f":"code","14ad0d7e":"code","bab12342":"code","c334758c":"code","26fb479a":"code","181fec16":"code","85b25915":"code","bde0b7aa":"code","6f02c5e0":"code","c4213fcb":"code","9f0157af":"code","508a0bde":"code","bbe2525c":"code","226150e7":"code","f773ab2d":"code","dd0053b1":"code","2b429ee3":"code","db6995cd":"code","3ad3556b":"code","08a47ec4":"code","4aecd3c9":"code","1824ef0b":"code","bf5e14fd":"code","cc634ee4":"code","f9c0dfd7":"code","b1da25d4":"code","54b3ff27":"code","38edd97f":"code","d7a91f9c":"code","990a9692":"code","f2c3ede4":"code","622d402e":"code","d3680178":"code","275c7d7e":"code","2ed2699f":"code","ed387ed6":"code","b63273dc":"code","0eac31d5":"code","d11a0b5e":"code","4a5ce356":"code","b232aba4":"code","59f4bcf3":"code","648a5caa":"code","ba982c2e":"code","12881993":"code","f575b506":"code","63e7d8bc":"code","5c2c3e58":"code","31be4ff4":"code","4e80ab3c":"code","d7425ecc":"code","66745ea9":"code","475316c4":"code","3848b678":"code","df4e08b6":"code","53a982f6":"code","d975b38e":"code","af823caf":"code","0904fcd2":"code","e610c594":"code","d9a3af6d":"code","c6dd4b58":"code","66d724e7":"code","fb7c7fd0":"code","870d1dc4":"code","908f55c3":"code","c308fee4":"code","4dca7f96":"markdown","6a2c8692":"markdown","326cd0ae":"markdown","43e44b16":"markdown","2004891b":"markdown","57a82d64":"markdown","37e728bf":"markdown","4b618b23":"markdown","60f57099":"markdown","d70cfc4a":"markdown","cdabba4e":"markdown","0c5ce81f":"markdown","550f9297":"markdown","0f49015e":"markdown","507ea439":"markdown","1cb00f64":"markdown","3f171b5f":"markdown","400a6ea1":"markdown","0bfea30e":"markdown","5b16781b":"markdown","13df3c8f":"markdown","1e3b109b":"markdown","362cc765":"markdown","87af8977":"markdown","412bd7dd":"markdown","1b28f3c0":"markdown","420ff6a9":"markdown","391e1307":"markdown","2e2e0a41":"markdown","efd5ad46":"markdown","65b8a8e5":"markdown","8424a165":"markdown","95eb98c7":"markdown","0649b5e7":"markdown","b65ada47":"markdown","de33072d":"markdown","77c722d6":"markdown","ba78da07":"markdown","9bcb62d9":"markdown","30245ce4":"markdown","3b076f09":"markdown","47415b31":"markdown","d924e522":"markdown","c53ac909":"markdown","dee81e0d":"markdown","17b2e846":"markdown","7bf84673":"markdown","dfbc3bab":"markdown","d1eac0b0":"markdown","1426a359":"markdown","48c6fe77":"markdown"},"source":{"0ff9967f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14ad0d7e":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import svm \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import svm \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bab12342":"home = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv',index_col='Id')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv',index_col='Id')","c334758c":"home.head()","26fb479a":"test.head()","181fec16":"home.shape","85b25915":"test.shape","bde0b7aa":"home.info()","6f02c5e0":"test.info()","c4213fcb":"#missing values\nmissing = home.isnull().sum()\nmissing = missing[missing>0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","9f0157af":"numerical_features = home.select_dtypes(exclude=['object']).drop(['SalePrice'], axis=1).copy()\nprint(numerical_features.columns)","508a0bde":"categorical_features = home.select_dtypes(include=['object']).copy()\nprint(categorical_features.columns)","bbe2525c":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9,4,i+1)\n    sns.distplot(numerical_features.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_features.columns[i])\nplt.tight_layout()\nplt.show()","226150e7":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9,4,i+1)\n    sns.boxplot(y=numerical_features.iloc[:,i])\n\nplt.tight_layout()\nplt.show()\n","f773ab2d":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9, 4, i+1)\n    sns.scatterplot(numerical_features.iloc[:, i],home['SalePrice'])\nplt.tight_layout()\nplt.show()","dd0053b1":"figure, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2)\nfigure.set_size_inches(16,28)\n_ = sns.regplot(home['LotFrontage'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['LotArea'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['MasVnrArea'], home['SalePrice'], ax=ax3)\n_ = sns.regplot(home['BsmtFinSF1'], home['SalePrice'], ax=ax4)\n_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax5)\n_ = sns.regplot(home['GrLivArea'], home['SalePrice'], ax=ax6)\n_ = sns.regplot(home['1stFlrSF'], home['SalePrice'], ax=ax7)\n_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax8)\n_ = sns.regplot(home['MiscVal'], home['SalePrice'], ax=ax9)\n_ = sns.regplot(home['LowQualFinSF'], home['SalePrice'], ax=ax10)","2b429ee3":"home.shape","db6995cd":"home = home.drop(home[home['LotFrontage']>200].index)\nhome = home.drop(home[home['LotArea']>100000].index)\nhome = home.drop(home[home['MasVnrArea']>1200].index)\nhome = home.drop(home[home['BsmtFinSF1']>4000].index)\nhome = home.drop(home[home['TotalBsmtSF']>4000].index)\nhome = home.drop(home[(home['GrLivArea']>4000) & (home['SalePrice']<300000)].index)\nhome = home.drop(home[home['1stFlrSF']>4000].index)\nhome = home.drop(home[home['EnclosedPorch']>500].index)\nhome = home.drop(home[home['MiscVal']>5000].index)\nhome = home.drop(home[(home['LowQualFinSF']>600) & (home['SalePrice']>400000)].index)","3ad3556b":"num_correlation = home.select_dtypes(exclude='object').corr()\nplt.figure(figsize=(20,20))\nplt.title('High Correlation')\nsns.heatmap(num_correlation > 0.8, annot=True, square=True)","08a47ec4":"corr = num_correlation.corr()\nprint(corr['SalePrice'].sort_values(ascending=False))","4aecd3c9":"home.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True) \ntest.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True)","1824ef0b":"# Useless Columns...\nhome=home.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) \ntest=test.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) ","bf5e14fd":"home.isnull().mean().sort_values(ascending=False).head(3)","cc634ee4":"home.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea', 'YrSold', 'MoSold'], axis=1, inplace=True)\ntest.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea', 'YrSold', 'MoSold'], axis=1, inplace=True)","f9c0dfd7":"test.isnull().mean().sort_values(ascending=False).head(3)","b1da25d4":"# Checking Home and Test data missing value percentage\nnull = pd.DataFrame(data={'Home Null Percentage': home.isnull().sum()[home.isnull().sum() > 0], 'Test Null Percentage': test.isnull().sum()[test.isnull().sum() > 0]})\nnull = (null\/len(home)) * 100\n\nnull.index.name='Feature'\nnull","54b3ff27":"home.isnull().sum().sort_values(ascending=False)[:50]","38edd97f":"home_num_features = home.select_dtypes(exclude='object').isnull().mean()\ntest_num_features = test.select_dtypes(exclude='object').isnull().mean()\n\nnum_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\nnum_null_features.index.name = 'Numerical Features'\nnum_null_features","d7a91f9c":"for df in [home, test]:\n    for col in ('GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n                'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotalBsmtSF',\n                'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal',\n                'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea'):\n                    df[col] = df[col].fillna(0)","990a9692":"_=sns.regplot(home['LotFrontage'],home['SalePrice'])\n","f2c3ede4":"home_num_features = home.select_dtypes(exclude='object').isnull().mean()\ntest_num_features = test.select_dtypes(exclude='object').isnull().mean()\n\nnum_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\nnum_null_features.index.name = 'Numerical Features'\nnum_null_features","622d402e":"cat_col = home.select_dtypes(include='object').columns\nprint(cat_col)","d3680178":"home_cat_features = home.select_dtypes(include='object').isnull().mean()\ntest_cat_features = test.select_dtypes(include='object').isnull().mean()\n\ncat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\ncat_null_features.index.name = 'Categorical Features'\ncat_null_features","275c7d7e":"cat_col = home.select_dtypes(include='object').columns\n\ncolumns = len(cat_col)\/4+1\n\nfg, ax = plt.subplots(figsize=(20, 30))\n\nfor i, col in enumerate(cat_col):\n    fg.add_subplot(columns, 4, i+1)\n    sns.countplot(home[col])\n    plt.xlabel(col)\n    plt.xticks(rotation=90)\n\nplt.tight_layout()\nplt.show()","2ed2699f":"var = home['KitchenQual']\nf, ax = plt.subplots(figsize=(10,6))\nsns.boxplot(y=home.SalePrice, x=var)\nplt.show()","ed387ed6":"f, ax = plt.subplots(figsize=(12,8))\nsns.boxplot(y=home.SalePrice, x=home.Neighborhood)\nplt.xticks(rotation=45)\nplt.show()","b63273dc":"## Count of categories within Neighborhood attribute\nfig = plt.figure(figsize=(12.5,4))\nsns.countplot(x='Neighborhood', data=home)\nplt.xticks(rotation=90)\nplt.ylabel('Frequency')\nplt.show()","0eac31d5":"for df in [home, test]:\n    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                  'BsmtFinType2', 'Neighborhood', 'BldgType', 'HouseStyle', 'MasVnrType', 'FireplaceQu', 'Fence'):\n        df[col] = df[col].fillna('None')","d11a0b5e":"for df in [home, test]:\n    for col in ('LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'RoofStyle',\n                  'Electrical', 'Functional', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'ExterQual', 'ExterCond',\n                  'Foundation', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition'):\n        df[col] = df[col].fillna(df[col].mode()[0])","4a5ce356":"home_cat_features = home.select_dtypes(include='object').isnull().mean()\ntest_cat_features = test.select_dtypes(include='object').isnull().mean()\n\ncat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\ncat_null_features.index.name = 'Categorical Features'\ncat_null_features","b232aba4":"_=sns.regplot(home['LotFrontage'],home['SalePrice'])\n","59f4bcf3":"home['LotFrontage'] = home.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\ntest['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))","648a5caa":"home.corr()['SalePrice'].sort_values(ascending=False)","ba982c2e":"home.isnull().sum().sort_values(ascending=False)","12881993":"test.isnull().sum().sort_values(ascending=False)","f575b506":"list(home.select_dtypes(exclude='object').columns)","63e7d8bc":"figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['2ndFlrSF'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['TotalBsmtSF'] + home['2ndFlrSF'], home['SalePrice'], ax=ax3)","5c2c3e58":"home['TotalSF']=home['TotalBsmtSF']  + home['2ndFlrSF']\ntest['TotalSF']=test['TotalBsmtSF']  + test['2ndFlrSF']","31be4ff4":"figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\nfigure.set_size_inches(14,10)\n_ = sns.barplot(home['BsmtFullBath'], home['SalePrice'], ax=ax1)\n_ = sns.barplot(home['FullBath'], home['SalePrice'], ax=ax2)\n_ = sns.barplot(home['BsmtHalfBath'], home['SalePrice'], ax=ax3)\n_ = sns.barplot(home['BsmtFullBath'] + home['FullBath'] + home['BsmtHalfBath'] + home['HalfBath'], home['SalePrice'], ax=ax4)\n","4e80ab3c":"home['TotalBath']=home['BsmtFullBath'] + home['FullBath'] + (0.5*home['BsmtHalfBath']) + (0.5*home['HalfBath'])\ntest['TotalBath']=test['BsmtFullBath'] + test['FullBath'] + test['BsmtHalfBath'] + test['HalfBath']\n","d7425ecc":"figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\nfigure.set_size_inches(18,8)\n_ = sns.regplot(home['YearBuilt'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['YearRemodAdd'], home['SalePrice'], ax=ax2)\n_ = sns.regplot((home['YearBuilt']+home['YearRemodAdd'])\/2, home['SalePrice'], ax=ax3)","66745ea9":"home['YrBltAndRemod']=home['YearBuilt']+(home['YearRemodAdd']\/2)\ntest['YrBltAndRemod']=test['YearBuilt']+(test['YearRemodAdd']\/2)","475316c4":"figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(home['OpenPorchSF'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['3SsnPorch'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax3)\n_ = sns.regplot(home['ScreenPorch'], home['SalePrice'], ax=ax4)\n_ = sns.regplot(home['WoodDeckSF'], home['SalePrice'], ax=ax5)\n_ = sns.regplot((home['OpenPorchSF']+home['3SsnPorch']+home['EnclosedPorch']+home['ScreenPorch']+home['WoodDeckSF']), home['SalePrice'], ax=ax6)","3848b678":"home['Porch_SF'] = (home['OpenPorchSF'] + home['3SsnPorch'] + home['EnclosedPorch'] + home['ScreenPorch'] + home['WoodDeckSF'])\ntest['Porch_SF'] = (test['OpenPorchSF'] + test['3SsnPorch'] + test['EnclosedPorch'] + test['ScreenPorch'] + test['WoodDeckSF'])","df4e08b6":"home['Has2ndfloor'] = home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasBsmt'] = home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasFirePlace'] = home['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\nhome['Has2ndFlr']=home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasBsmt']=home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n\ntest['Has2ndfloor'] = test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasBsmt'] = test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasFirePlace'] = test['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ntest['Has2ndFlr']=test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasBsmt']=test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)","53a982f6":"home['MSSubClass'] = home['MSSubClass'].apply(str)\nhome['LotArea'] = home['LotArea'].astype(np.int64)\n\ntest['MSSubClass'] = test['MSSubClass'].apply(str)\ntest['LotArea'] = test['LotArea'].astype(np.int64)","d975b38e":"fig = plt.figure(figsize=(11,11))\n\nprint (\"Skew of SalePrice:\", home.SalePrice.skew())\nplt.hist(home.SalePrice, normed=1, color='red')\nplt.show()","af823caf":"fig = plt.figure(figsize=(11,11))\n\nprint (\"Skew of Log-Transformed SalePrice:\", np.log1p(home.SalePrice).skew())\nplt.hist(np.log1p(home.SalePrice), color='green')\nplt.show()","0904fcd2":"X = home.drop(['SalePrice'], axis=1)\ny = np.log1p(home['SalePrice'])","e610c594":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=2)","d9a3af6d":"test.head()","c6dd4b58":"categorical_cols = [cname for cname in X.columns if\n                    X[cname].nunique() <= 30 and\n                    X[cname].dtype == \"object\"] \n                \n\n\nnumerical_cols = [cname for cname in X.columns if\n                 X[cname].dtype in ['int64','float64']]\n\n\nmy_cols = numerical_cols + categorical_cols\n\nX_train = X_train[my_cols].copy()\nX_valid = X_valid[my_cols].copy()\nX_test = test[my_cols].copy()\n","66d724e7":"num_transformer = Pipeline(steps=[\n    ('num_imputer', SimpleImputer(strategy='constant'))\n    ])\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, numerical_cols),       \n        ('cat',cat_transformer,categorical_cols),\n        ])","fb7c7fd0":"# Reversing log-transform on y\ndef inv_y(transformed_y):\n    return np.exp(transformed_y)\n\nn_folds = 10\n\n# XGBoost\nmodel = XGBRegressor(learning_rate=0.01, n_estimators=3460, max_depth=3, min_child_weight=0,gamma=0, subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror', nthread=-1,scale_pos_weight=1, seed=27, reg_alpha=0.00006)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('XGBoost: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))\n\n      \n# Lasso   \nmodel = LassoCV(max_iter=1e7,  random_state=14, cv=n_folds)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('Lasso: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))\n  \n      \n      \n# GradientBoosting   \nmodel = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=5)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('Gradient: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))","870d1dc4":"# model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n#                      max_depth=3, min_child_weight=0,\n#                      gamma=0, subsample=0.7,\n#                      colsample_bytree=0.7,\n#                      objective='reg:squarederror', nthread=-1,\n#                      scale_pos_weight=1, seed=27,\n#                      reg_alpha=0.00006)\n\n# clf = Pipeline(steps=[('preprocessor', preprocessor),\n#                           ('model', model)])\n\n\n# scores = cross_val_score(clf, X, y, scoring='neg_mean_squared_error', \n#                          cv=n_folds)\n# gbr_mae_scores = -scores\n\n# print('Mean RMSE: ' + str(gbr_mae_scores.mean()))\n# print('Error std deviation: ' +str(gbr_mae_scores.std()))","908f55c3":"model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                     max_depth=3, min_child_weight=0,\n                     gamma=0, subsample=0.7,\n                     colsample_bytree=0.7,\n                     objective='reg:squarederror', nthread=-1,\n                     scale_pos_weight=1, seed=27,\n                     reg_alpha=0.00006)\n\nfinal_model = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\n\nfinal_model.fit(X_train, y_train)\n\nfinal_predictions = final_model.predict(X_test)","c308fee4":"output = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': inv_y(final_predictions)})\n\noutput.to_csv('submission.csv', index=False)","4dca7f96":"### 3.2 Distribution of Data","6a2c8692":"### 6.1 Dealing with Data for Modelling","326cd0ae":"We create extra features in order to categorize data with and without a feature\n\nFor example:\n\n* 'HasPool' is 1 if you have pool and 0 if you don't have a pool","43e44b16":"### 5.3 Create 'YrBuiltAndRemod' feature","2004891b":"* Find the highly-correlated (correlations higher than 0.8)","57a82d64":"Drop column with a lower correlation to SalePrice of the pair\n\n(Ex: GarageCars(0.88) & GarageArea(0.876))\n\n#### DROP GarageArea","37e728bf":"### 5.5 Creating extra features and changing types","4b618b23":"## 2) READING DATA AND COMPREHENDING DATA\nIn this section:\n\n* 2.1 Reading Data\n* 2.2 Understanding the Data\n* 2.3 Checking for missing values\n","60f57099":"We select every numerical column from X and the categorical columns with unique values under 30","d70cfc4a":"LotFrontage is correlated to Neighborhood, so we fill in the median based off of Neighborhood feature","cdabba4e":"### 4.2 Removing Certain Features","0c5ce81f":"## 7) SUBMISSION","550f9297":"* We will deal with 'LotFrontage' later because it is an important feature","0f49015e":"### 5.1 Create 'TotalSF' feature","507ea439":"Our next step is setting up the final model","1cb00f64":"### 2.3 Checking for Missing Values","3f171b5f":"\nAs we can see the skew improved from approximately 1.88 to approximately 0.12 so we will log-transform SalePrice in the next section","400a6ea1":"### 4.4 Filling Categorical Missing Values","0bfea30e":"## 3) DATA VISUALIZATION\u00b6\nIn this section:\n\n* 3.1 Viewing Columns\n\n* 3.2 Distribution of Data\n\n* 3.3 Univariate Analysis of Data\n\n* 3.4 Bivariate Analysis of Data","5b16781b":"### 3.1 Viewing Columns","13df3c8f":"The graph shows that SalePrice is skewed to the right and must be modified","1e3b109b":"## TABLE OF CONTENTS:\n#### 1) IMPORTING LIBRARIES\n#### 2) READING DATA AND COMPREHENDING DATA\n#### 3) DATA VISUALIZATION\n#### 4) DATA PROCESSING\n#### 5) FEATURE ENGINEERING\n#### 6) MODELLING\n#### 7) SUBMISSION","362cc765":"We also have useless features so we also decide to drop the features below","87af8977":"Here we create a 'num_transformer' and a 'cat_transformer' for imputing and hot-encoding numerical and categorical values. We then store these transformers into a preprocessor column transformer","412bd7dd":"### 5.4 Create 'PorchSF' feature","1b28f3c0":"As we can see XGBoost performed the best so we will be using this. Let us check the Mean RMSE and the standard deviation of this model.\n\n* I commented out because it takes too long and we know this is already the best model","420ff6a9":"### 3.4 Bivariate Analysis","391e1307":"### 4.5 Filling Missing Values in 'LotFrontage'","2e2e0a41":"### 6.2 Finding the Best Model","efd5ad46":"### 6.3 Setting up Final Model for Submission","65b8a8e5":"For the remaining missing values we will impute them with 'SimpleImputer()' when modelling","8424a165":"### 5.2 Create 'TotalBath' feature","95eb98c7":"## 4) DATA PROCESSING\nIn this section:\n\n* 4.1 Outliers\n* 4.2 Removing Certain Features\n* 4.3 Filling Numerical Missing Values\n* 4.4 Filling Categorical Missing Values\n* 4.5 Filling Missing Values in 'LotFrontage'\n*\n","0649b5e7":"## 1) IMPORTING LIBRARIES","b65ada47":"We can clearly see features 'Alley', 'MiscFeature' and 'PoolQC' are missing over 90% of their values. So we decide to remove them. 'PoolArea' is pretty much a useless column because 99.6% of 'PoolQC' is missing so we also drop this feature.","de33072d":"Split X and y into train and valid data for model testing\n\n","77c722d6":"Highly-Correlated Features:\n\n* YearBuilt vs GarageYrBlt\n* 1stFlrSF vs TotalBsmtSF\n* GrLivArea vs TotRmsAbvGrd\n* GarageCars vs GarageArea","ba78da07":"## 5) FEATURE ENGINEERING\nIn this section:\n\n* 5.1 Create 'TotalSF' feature\n* 5.2 Create 'TotalBath' feature\n* 5.3 Create 'YrBuiltAndRemod' feature\n* 5.4 Create 'PorchSF' feature\n* 5.5 Creating extra features and changing types\n* 5.6 SalePrice Distribution Visualization","9bcb62d9":"Lets see which features have the most missing values...","30245ce4":"### 2.2 Understanding the Data","3b076f09":"We test three models: 'XGBoost', 'Lasso', and 'Gradient' and see which one performs the best","47415b31":"### 5.6 SalePrice Distribution Visualization","d924e522":"From these regplots we have confirmed there are outliers, so we decide to remove them.","c53ac909":"###  4.1 Outliers","dee81e0d":"### 4.3 Filling Numerical Missing Values","17b2e846":"### 2.1 Reading Data","7bf84673":"Some features are the wrong type so we convert them to the right type","dfbc3bab":"### 3.3 Univariate Analysis","d1eac0b0":"## 6) MODELLING\nIn this section:\n\n* 6.1 Dealing with Data for Modelling\n* 6.2 Finding the Best Model\n* 6.3 Setting up Final Model for Submission","1426a359":"Test data doesn't have any features that have over 90% of missing values. So we don't drop any features.","48c6fe77":"Notes on Outliers: According to the plots above, these are the features which appear to have outliers:\n\n* LotFrontage\n* LotArea\n* MasVnrArea\n* BsmtFinSF1\n* TotalBsmtSF\n* GrLivArea\n* 1stFlrSF\n* EnclosedPorch\n* MiscVal\n* LowQualFinSF\n\nLet's take a closer look at these features..."}}