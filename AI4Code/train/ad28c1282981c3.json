{"cell_type":{"2ea7c3d9":"code","c5eb9578":"code","7c4e4e3a":"code","01003e3f":"code","19c3b45a":"code","1dd7245c":"code","012c890c":"code","4aee1377":"code","cd761692":"code","34d30844":"code","2cf6e4f0":"code","8074dbca":"code","d2cb7d31":"code","91dafbca":"code","46e3957d":"code","91ad6f36":"code","3268fcb3":"code","777e4c07":"code","a57a9914":"code","4c932725":"code","091e0b3b":"code","db301e0c":"code","35be182b":"code","9c013eb8":"markdown","c7cc9abf":"markdown","dc2c8d2f":"markdown","9cbacabd":"markdown","3b5ad55e":"markdown","63dd6470":"markdown","ab62f7e7":"markdown","835c972a":"markdown","8f864e9c":"markdown","bbe7ac6b":"markdown"},"source":{"2ea7c3d9":"import numpy as np\nimport pandas as pd\nimport glob ","c5eb9578":"cur_path = \"\/kaggle\/input\/fault-induction-motor-dataset\/imbalance\/\"","7c4e4e3a":"normal_file_names = glob.glob(\"\/kaggle\/input\/fault-induction-motor-dataset\/normal\/\"+'\/normal\/*.csv')\nimnormal_file_names_6g = glob.glob(cur_path+'\/imbalance\/6g\/*.csv')\nimnormal_file_names_10g = glob.glob(cur_path+'\/imbalance\/10g\/*.csv')\nimnormal_file_names_15g = glob.glob(cur_path+'\/imbalance\\\\15g\/*.csv')\nimnormal_file_names_20g = glob.glob(cur_path+'\/imbalance\\\\20g\/*.csv')\nimnormal_file_names_25g = glob.glob(cur_path+'\/imbalance\\\\25g\/*.csv')\nimnormal_file_names_30g = glob.glob(cur_path+'\/imbalance\\\\30g\/*.csv')","01003e3f":"def dataReader(path_names):\n    data_n = pd.DataFrame()\n    for i in path_names:\n        low_data = pd.read_csv(i,header=None)\n        data_n = pd.concat([data_n,low_data],ignore_index=True)\n    return data_n","19c3b45a":"data_n = dataReader(normal_file_names)\ndata_6g = dataReader(imnormal_file_names_6g)\ndata_10g = dataReader(imnormal_file_names_10g)\ndata_15g = dataReader(imnormal_file_names_15g)\ndata_20g = dataReader(imnormal_file_names_20g)\ndata_25g = dataReader(imnormal_file_names_25g)\ndata_30g = dataReader(imnormal_file_names_30g)","1dd7245c":"data_n.info()","012c890c":"def downSampler(data,a,b):\n    \"\"\"\n    data = data\n    a = start index\n    b = sampling rate\n    \"\"\"\n    data_decreased = pd.DataFrame()\n    x = b\n    for i in range(int(len(data)\/x)):\n        data_decreased = data_decreased.append(data.iloc[a:b,:].sum()\/x,ignore_index=True)\n        a += x\n        b += x\n    return data_decreased","4aee1377":"data_n = downSampler(data_n, 0, 5000)\ndata_6g = downSampler(data_6g, 0, 5000)\ndata_10g = downSampler(data_10g, 0, 5000)\ndata_15g = downSampler(data_15g, 0, 5000)\ndata_20g = downSampler(data_20g, 0, 5000)\ndata_25g = downSampler(data_25g, 0, 5000)\ndata_30g = downSampler(data_30g, 0, 5000)","cd761692":"data_n","34d30844":"from scipy import signal\ndef FFT(data):\n    autocorr = signal.fftconvolve(data,data[::-1],mode='full')\n    return pd.DataFrame(autocorr)","2cf6e4f0":"data_n = FFT(data_n)\ndata_6g = FFT(data_6g)\ndata_10g = FFT(data_10g)\ndata_15g = FFT(data_15g)\ndata_20g = FFT(data_20g)\ndata_25g = FFT(data_25g)\ndata_30g = FFT(data_30g)","8074dbca":"y_1 = pd.DataFrame(np.ones(int(len(data_n)),dtype=int))\ny_2 = pd.DataFrame(np.zeros(int(len(data_6g)),dtype=int))\ny_3 = pd.DataFrame(np.full((int(len(data_10g)),1),2))\ny_4 = pd.DataFrame(np.full((int(len(data_15g)),1),3))\ny_5 = pd.DataFrame(np.full((int(len(data_20g)),1),4))\ny_6 = pd.DataFrame(np.full((int(len(data_25g)),1),5))\ny_7 = pd.DataFrame(np.full((int(len(data_30g)),1),6))\ny = pd.concat([y_1,y_2,y_3,y_4,y_5,y_6,y_7], ignore_index=True)\ny","d2cb7d31":"data = pd.concat([data_n,data_6g,data_10g,data_15g,data_20g,data_25g,data_30g],ignore_index=True)","91dafbca":"data","46e3957d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.25, shuffle=True)","91ad6f36":"print(\"Shape of Train Data : {}\".format(X_train.shape))\nprint(\"Shape of Test Data : {}\".format(X_test.shape))","3268fcb3":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(X_train,y_train)\nprint(\"SVM accuracy is {} on Train Dataset\".format(svm.score(X_train,y_train)))\nprint(\"SVM accuracy is {} on Test Dataset\".format(svm.score(X_test,y_test)))","777e4c07":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3) #n_neighbors = k\nknn.fit(X_train,y_train)\nprint(\"k={}NN Accuracy on Train Data: {}\".format(3,knn.score(X_train,y_train)))\nprint(\"k={}NN Accuracy on Test Data: {}\".format(3,knn.score(X_test,y_test)))","a57a9914":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='loss', patience=2)\nmodel = Sequential()\n\nmodel.add(Dense(32, activation='relu', input_shape=(15,),kernel_initializer='random_uniform'))\nmodel.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\nmodel.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\nmodel.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\nmodel.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\nmodel.add(Dense(7, activation='softmax',kernel_initializer='random_uniform'))\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","4c932725":"from sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)","091e0b3b":"hist = model.fit(X_train , y_train , epochs=20, validation_split=0.2)","db301e0c":"import matplotlib.pyplot as plt\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","35be182b":"import matplotlib.pyplot as plt\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","9c013eb8":"## Models: SVM, kNN, DNN","c7cc9abf":"## kNN Machine Learning","dc2c8d2f":"### plot training history","9cbacabd":"#### Down Sampling","3b5ad55e":"#### FFT Convolve","63dd6470":"### Train DNN","ab62f7e7":"## Prepare Data","835c972a":"## DNN Deep Learning\n### Build Model","8f864e9c":"## SVM Machine Learning","bbe7ac6b":"## [MAFAULDA: Machinery Fault Database](http:\/\/www02.smt.ufrj.br\/~offshore\/mfs\/page_01.html)\n## Dataset: [Induction Motor Faults dataset](https:\/\/www.kaggle.com\/uysalserkan\/fault-induction-motor-dataset)"}}