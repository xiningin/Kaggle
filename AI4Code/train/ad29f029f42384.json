{"cell_type":{"30011b71":"code","0b91d19d":"code","322cf081":"code","d0ac2451":"code","07fdd35e":"code","e70a54f5":"code","6b0d2fe9":"code","d8f3fe6c":"code","181be191":"code","d722575a":"code","2372b883":"code","2e5787dd":"code","24dee3fe":"code","e122147e":"code","31e91fe7":"code","05662811":"code","640ec384":"code","d8e2ce9b":"code","9522c938":"markdown","08931c1b":"markdown","6e101415":"markdown","cae587cd":"markdown","9f5350df":"markdown","78b3efb9":"markdown","428d2741":"markdown","6559225d":"markdown","c51fe268":"markdown","b0761a53":"markdown","2c74052f":"markdown"},"source":{"30011b71":"%%capture\n!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py\n!pip install timm\n!pip install onnx","0b91d19d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.onnx as onnx\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.distributed.parallel_loader as pl\n\nimport timm\nimport onnx\n\nimport gc\nimport os\nimport time\nimport random\nfrom datetime import datetime\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom sklearn import model_selection, metrics","322cf081":"# For parallelization in TPUs\nos.environ[\"XLA_USE_BF16\"] = \"1\"\nos.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"","d0ac2451":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nseed_everything(1001)","07fdd35e":"# general global variables\nDATA_PATH = \"..\/input\/aptos2019-blindness-detection\"\nTRAIN_PATH = \"..\/input\/aptos2019-blindness-detection\/train_images\"\nTEST_PATH = \"..\/input\/aptos2019-blindness-detection\/test_images\"\nMODEL_PATH = (\n    \"..\/input\/vit-base-models-pretrained-pytorch\/jx_vit_base_p16_224-80ecf9dd.pth\"\n)\n\n# model specific global variables\nIMG_SIZE = 224\nBATCH_SIZE = 32\nLR = 2e-05\nGAMMA = 0.7\nN_EPOCHS = 20","e70a54f5":"df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ndf.head()","6b0d2fe9":"df.info()","d8f3fe6c":"df.diagnosis.value_counts().plot(kind='bar')","181be191":"train_df, valid_df = model_selection.train_test_split(\n    df, test_size=0.1, random_state=42, stratify=df.diagnosis.values\n)","d722575a":"class DiabeticRetinopathyDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Helper Class to create the pytorch dataset\n    \"\"\"\n\n    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n        super().__init__()\n        self.df_data = df.values\n        self.data_path = data_path\n        self.transforms = transforms\n        self.mode = mode\n        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n\n    def __len__(self):\n        return len(self.df_data)\n\n    def __getitem__(self, index):\n        img_name, label = self.df_data[index]\n        img_path = os.path.join(self.data_path, self.data_dir, img_name+'.png')\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transforms is not None:\n            image = self.transforms(img)\n\n        return image, label","2372b883":"# create image augmentations\ntransforms_train = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.RandomHorizontalFlip(p=0.3),\n        transforms.RandomVerticalFlip(p=0.3),\n        transforms.RandomResizedCrop(IMG_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    ]\n)\n\n\ntransforms_valid = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    ]\n)","2e5787dd":"# timm (Torch Image Models)\nprint(\"Available Vision Transformer Models: \")\ntimm.list_models(\"vit*\")","24dee3fe":"class ViTBase16(nn.Module):\n    def __init__(self, n_classes, pretrained=False):\n\n        super(ViTBase16, self).__init__()\n\n        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n        if pretrained:\n            self.model.load_state_dict(torch.load(MODEL_PATH))\n\n        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n        # keep track of training loss\n        epoch_loss = 0.0\n        epoch_accuracy = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        self.model.train()\n        for i, (data, target) in enumerate(train_loader):\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = self.forward(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # Calculate Accuracy\n            accuracy = (output.argmax(dim=1) == target).float().mean()\n            # update training loss and accuracy\n            epoch_loss += loss\n            epoch_accuracy += accuracy\n\n            # perform a single optimization step (parameter update)\n            if device.type == \"xla\":\n                xm.optimizer_step(optimizer)\n\n                if i % 20 == 0:\n                    xm.master_print(f\"\\tBATCH {i+1}\/{len(train_loader)} - LOSS: {loss}\")\n\n            else:\n                optimizer.step()\n\n        return epoch_loss \/ len(train_loader), epoch_accuracy \/ len(train_loader)\n\n    def validate_one_epoch(self, valid_loader, criterion, device):\n        # keep track of validation loss\n        valid_loss = 0.0\n        valid_accuracy = 0.0\n\n        ######################\n        # validate the model #\n        ######################\n        self.model.eval()\n        for data, target in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            with torch.no_grad():\n                # forward pass: compute predicted outputs by passing inputs to the model\n                output = self.model(data)\n                # calculate the batch loss\n                loss = criterion(output, target)\n                # Calculate Accuracy\n                accuracy = (output.argmax(dim=1) == target).float().mean()\n                # update average validation loss and accuracy\n                valid_loss += loss\n                valid_accuracy += accuracy\n\n        return valid_loss \/ len(valid_loader), valid_accuracy \/ len(valid_loader)","e122147e":"def fit_tpu(\n    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\n):\n\n    valid_loss_min = np.Inf  # track change in validation loss\n\n    # keeping track of losses as it happen\n    train_losses = []\n    valid_losses = []\n    train_accs = []\n    valid_accs = []\n\n    for epoch in range(1, epochs + 1):\n        gc.collect()\n        para_train_loader = pl.ParallelLoader(train_loader, [device])\n\n        xm.master_print(f\"{'='*50}\")\n        xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n        train_loss, train_acc = model.train_one_epoch(\n            para_train_loader.per_device_loader(device), criterion, optimizer, device\n        )\n        xm.master_print(\n            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\"\n        )\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        gc.collect()\n\n        if valid_loader is not None:\n            gc.collect()\n            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n            valid_loss, valid_acc = model.validate_one_epoch(\n                para_valid_loader.per_device_loader(device), criterion, device\n            )\n            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n            valid_losses.append(valid_loss)\n            valid_accs.append(valid_acc)\n            gc.collect()\n\n            # save model if validation loss has decreased\n            if valid_loss <= valid_loss_min and epoch != 1:\n                xm.master_print(\n                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n                        valid_loss_min, valid_loss\n                    )\n                )\n            #                 xm.save(model.state_dict(), 'best_model.pth')\n\n            valid_loss_min = valid_loss\n\n    return {\n        \"train_loss\": train_losses,\n        \"valid_losses\": valid_losses,\n        \"train_acc\": train_accs,\n        \"valid_acc\": valid_accs,\n    }","31e91fe7":"model = ViTBase16(n_classes=5, pretrained=True)","05662811":"def _run():\n    train_dataset = DiabeticRetinopathyDataset(train_df, transforms=transforms_train)\n    valid_dataset = DiabeticRetinopathyDataset(valid_df, transforms=transforms_valid)\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True,\n    )\n\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False,\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=BATCH_SIZE,\n        sampler=train_sampler,\n        drop_last=True,\n        num_workers=8,\n    )\n\n    valid_loader = torch.utils.data.DataLoader(\n        dataset=valid_dataset,\n        batch_size=BATCH_SIZE,\n        sampler=valid_sampler,\n        drop_last=True,\n        num_workers=8,\n    )\n\n    criterion = nn.CrossEntropyLoss()\n    #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    device = xm.xla_device()\n    model.to(device)\n\n    lr = LR * xm.xrt_world_size()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n    start_time = datetime.now()\n    xm.master_print(f\"Start Time: {start_time}\")\n\n    logs = fit_tpu(\n        model=model,\n        epochs=N_EPOCHS,\n        device=device,\n        criterion=criterion,\n        optimizer=optimizer,\n        train_loader=train_loader,\n        valid_loader=valid_loader,\n    )\n\n    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n\n    xm.master_print(\"Saving Model\")\n    xm.save(\n        model.state_dict(), f'model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n    )","640ec384":"# Start training processes\ndef _mp_fn(rank, flags):\n    torch.set_default_tensor_type(\"torch.FloatTensor\")\n    a = _run()\n\n\n# _run()\nFLAGS = {}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\"fork\")","d8e2ce9b":"!pip install onnx\nimport torch.onnx as onnx\ntorch.save(model,'ViT4Vision.pth')\n\ninput_image = torch.zeros((1,3,224,224))\nonnx.export(model, input_image, 'ViT4Vision.onnx')","9522c938":"**CPU**\n\n![CPU Working](https:\/\/miro.medium.com\/max\/640\/1*ljApYgMaCiPs80uGjRlBYQ.gif)\n\n**GPU**\n\n![GPU Working](https:\/\/miro.medium.com\/max\/640\/1*-7vLF7dzLiDSZY1edgI76w.gif)\n\n**TPU**\n\n![TPU Working](https:\/\/miro.medium.com\/max\/640\/1*YZU6oT8QQGsWRltkJQ91SA.gif)","08931c1b":"![Pytorch-XLA](https:\/\/miro.medium.com\/max\/1400\/1*uR7-mfI6AE6cqGqG0rDE8w.png)\n\nXLA (accelerated linear algebra) is a compiler-based linear algebra execution engine. It is the backend that powers machine learning frameworks such as TensorFlow and JAX at Google, on a variety of devices including CPUs, GPUs, and TPUs.\n\nWe can leverate TPU's using PyTorch with XLA","6e101415":"![TPUv3](https:\/\/techcrunch.com\/wp-content\/uploads\/2019\/05\/empowering-businesses-with-google-cloud-ai_2x-1.png?w=990&crop=1)\n\nTensor Processing Units (TPUs) are Google\u2019s custom-developed application-specific integrated circuits (ASICs) used to accelerate machine learning workloads.\n\nTPU resources accelerate the performance of linear algebra computation, which is used heavily in machine learning applications. TPUs minimize the time-to-accuracy when you train large, complex neural network models. Models that previously took weeks to train on other hardware platforms can converge in hours on TPUs.","cae587cd":"As we can see there's huge class imbalance. So we stratify sampling data to maintain roughly equal number of examples per class in each sample","9f5350df":"___","78b3efb9":"As we can see from above, the lack of writing to memory after every operation, the superscalar architecture of TPU's and other such advances allow for very high throughput and thus lower training time. You can learn more about how TPU's work [here](https:\/\/storage.googleapis.com\/nexttpu\/index.html)  ","428d2741":"# Diabetic Retinopathy\n_Diabetic retinopathy is a diabetes complication that affects eyes. It's caused by damage to the blood vessels of the light-sensitive tissue at the back of the eye (retina)._\n\n![DR](https:\/\/www.mdpi.com\/applsci\/applsci-10-07274\/article_deploy\/html\/images\/applsci-10-07274-g001.png)\n\nDiabetic Retinopathy is classified into 5 categories\n1. No Diabetic Retinopathy\n2. Mild Diabetic Retinopathy\n3. Moderate Diabetic Retinopathy\n4. Severe Diabetic Retinopathy\n5. Prolifertative Diabetic Retinopathy\n\nIn this notebook we will aim to build a model to categories eye scans one of 5 aformentioned classes.","6559225d":"# Vision Transformers are for Vision\nIn this notebook we will use an Vision Transformers (ViT) as described in the [paper](https:\/\/arxiv.org\/abs\/2010.11929) \"An Image is worth 16x16 words: Transformers for Image Recognition at scale\" by _Alexey Dosovitskiy et al_ to train a model on the APTOS 2019 blindness detection contest dataset using TPU's","c51fe268":"The amazing Pytorch XLA Kernels by [Abhishek Thakur](https:\/\/www.kaggle.com\/abhishek) helped me put this kernel together.","b0761a53":"# A Primer on TPU and XLA","2c74052f":"___"}}