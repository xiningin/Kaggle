{"cell_type":{"301bcd22":"code","d6bfc84e":"code","0da21d63":"code","0d103ce8":"code","188a9a43":"code","27f5047a":"code","d8959912":"code","d44e61cb":"code","f3afe186":"code","36b556d8":"code","f606660b":"code","39c09214":"code","a6293f90":"code","f3cd8d47":"code","7e1d4003":"code","465a7fde":"code","8b67dfe0":"code","1dfbbd10":"code","538c021c":"code","9eb650fc":"code","3e2f422b":"code","252533c7":"code","51c11330":"code","438f1452":"code","aa28281f":"code","e7e62695":"code","8b7dc913":"code","34fb48b0":"code","9fa86a6a":"code","5711ac8f":"code","001fe923":"code","136f4ecb":"code","4e80cb0d":"code","a54ebf47":"code","3b1b586d":"code","462fcc67":"code","775b9a49":"code","4ae09a45":"code","b186544b":"code","ccdf70c3":"code","03f937d2":"code","f3c5e477":"code","219f3b00":"code","01b4c538":"code","1e1fbfba":"code","f349e4de":"code","23b62226":"code","93fa7a11":"code","d2809c2e":"code","04f7eb74":"code","1fb19cbd":"code","153a5047":"markdown","a6bc5b50":"markdown","8c5fbae8":"markdown","3366b935":"markdown","9d02c029":"markdown","169331cf":"markdown","da7e1d57":"markdown","120a81b6":"markdown","663b7097":"markdown","5d5e3f2a":"markdown","89936481":"markdown","c983e457":"markdown","6202bfe2":"markdown","9d6d4107":"markdown","897085ff":"markdown","33912650":"markdown","131b507d":"markdown","adb8dd3e":"markdown","ce58d08c":"markdown","1f6430ef":"markdown","2c1be707":"markdown","14c7b8a2":"markdown","082a2e41":"markdown","607b36c2":"markdown","514137eb":"markdown","f9bd4cde":"markdown","aeb1e245":"markdown"},"source":{"301bcd22":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6bfc84e":"train = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ntest = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')","0da21d63":"# Lets explore the Train dataset\ntrain.head()","0d103ce8":"test.head()","188a9a43":"train['excerpt'][0]","27f5047a":"train.shape","d8959912":"train.isnull().sum()","d44e61cb":"# Unique value in url_legal\ntrain['url_legal'].value_counts()","f3afe186":"train['license'].value_counts()","36b556d8":"import re\ndef extract_license(t):\n    if t==0:\n        return 0\n    else: \n        return re.split(\"\\d\",t)[0].replace('CC-','CC ').replace('BY ','BY-').strip()\n","f606660b":"train['license'].fillna(value=0, axis=0, inplace=True)\ntrain['license']=train['license'].apply(lambda x: extract_license(x))","39c09214":"train['license'].value_counts()","a6293f90":"train.isna().sum()","f3cd8d47":"train.info()","7e1d4003":"train.drop(['id'], axis=1, inplace=True)","465a7fde":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncolors=['#C7663E','#948078','#FA6767','#A0FAA0','#81C75B']\nsns.set(palette=colors, font='San', style='white', rc={'axes.facecolor':'whitesmoke', 'figure.facecolor':'whitesmoke'})\nsns.despine(left=False, right=False)\nsns.palplot(colors)","8b67dfe0":"train.info()","1dfbbd10":"train['url_legal'].value_counts().nlargest(5)","538c021c":"fig, ax= plt.subplot_mosaic(\"\"\"ac\n                                bd\n                                ee\"\"\", figsize=(20,8), constrained_layout=True)\nplt.suptitle(\"Univariated analysis of each features\", size=20, weight='bold')\n\n#ax['a'].set_title('url_legal feaure details (excluding 0 value)', size=10, weight='bold')\n#sns.countplot(data=train[train['url_legal']!=0], x='url_legal', ax=ax['a'], order=train[train['url_legal']!=0]['url_legal'].value_counts().index)\n\n\n#for i,j in enumerate(ax['a'].patches):\n#    ax['a'].text(x=j.get_x(),y=10, s=ax['a'].get_xticklabels()[i].get_text(), rotation=90)\n#ax['a'].set_xticks([])\n\nax['c'].set_title('legal feaure details (excluding 0 value)', size=10, weight='bold')\nsns.countplot(data=train[train['license']!=0], x='license', ax=ax['c'], order=train[train['license']!=0]['license'].value_counts().index)\nfor i,j in enumerate(ax['c'].patches):\n    ax['c'].text(x=j.get_x(),y=10, s=ax['c'].get_xticklabels()[i].get_text(), rotation=90)\nax['c'].set_xticks([])\n\nax['b'].set_title('Histogram for target feaure', size=10, weight='bold')\nsns.histplot(data=train, x='target', ax=ax['b'], kde=True)\nax['d'].set_title('Histogram for standar_error feaure', size=10, weight='bold')\nsns.histplot(data=train, x='standard_error', ax=ax['d'], kde=True)\n\nax['e'].text(x=0, y=0.8, s=\"1. url_legal - most of the contents are taken from wikipedia and followed by frontiersin, Africanstorybook etc\")\nax['e'].text(x=0, y=0.6, s=\"2. license - most of the contents are under CC BY and CC BY-SA licensed, except the contents without license\")\nax['e'].text(x=0, y=0.4, s=\"3. target - target feature explain about the content ease of reading, -ve value is tough and +ve is easy to read\")\nax['e'].text(x=0, y=0.2, s=\"4. standard_error - standar_error is the spread of scores by different raters for each content\")\nfor i in ['left','right','top','bottom']:\n    ax['e'].spines[i].set_visible(False)\n    ax['a'].spines[i].set_visible(False)\n    ax['b'].spines[i].set_visible(False)\n    ax['c'].spines[i].set_visible(False)\n    ax['d'].spines[i].set_visible(False)\nax['e'].set_xticks([])\nax['e'].set_yticks([])","9eb650fc":"fix, ax=plt.subplots(ncols=2, nrows=1, figsize=(15,8))\nsns.boxplot(data=train, x='target',ax=ax[0])\nsns.boxplot(data=train, x='standard_error', ax=ax[1])","3e2f422b":"#Since target feature is the target variable to predict, so let us explore with target feature with other features\nfig=plt.figure(figsize=(15,8))\nax=sns.boxplot(data=train, x='license',y='target')\nax.set_xticklabels(ax.get_xticklabels(), rotation=60);","252533c7":"fig=plt.figure(figsize=(8,8))\nax=sns.scatterplot(data=train, x='standard_error', y='target')\n#ax.set_xlim(0.4,0.7)","51c11330":"fig= plt.figure(figsize=(15,8))\nsns.jointplot(data=train, x='standard_error', y='target',kind='hex', xlim=(0.3, 0.7))","438f1452":"print(train[train['standard_error']==0]['excerpt'])\nprint(train[train['target']==0]['excerpt'])","aa28281f":"import math\ntrain['length']=train['excerpt'].apply(lambda x: len(x.split()))","e7e62695":"train.corr()","8b7dc913":"fig, ax=plt.subplots(ncols=3, nrows=1, figsize=(20,8))\nsns.regplot(data=train, x='length',y='target',line_kws={'color':'black'}, ax=ax[0] )\nsns.kdeplot(data=train, x='length', fill=True, ax=ax[1])\nax[1].axvline(train[train['target']==0]['length'].values)\nax[1].axvline(train[train['target']==train['target'].max()]['length'].values, ls='--')\nsns.boxplot(data=train, x='length', ax=ax[2])","34fb48b0":"train[train['standard_error']==train['standard_error'].min()]\n#train[train['target']==0]","9fa86a6a":"import plotly.express as ex\nfrom sklearn.cluster import KMeans\nX=train.drop(['excerpt','url_legal','license'], axis=1)\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\nex.scatter_3d(data_frame=X, x='standard_error',y='target',z='length', color=y_kmeans)","5711ac8f":"train['cluster']=y_kmeans\ntrain.corr()","001fe923":"from scipy.stats import f_oneway\nfrom statsmodels.formula.api import ols\nimport statsmodels.api as sm\ncl0 = train[train['cluster']==0]['target']\ncl1 = train[train['cluster']==1]['target']\ncl2 = train[train['cluster']==2]['target']\n\nsta, p_value=f_oneway(cl0,cl1,cl2, axis=0)\nprint(p_value)\nif p_value <0.05:\n    print(f\"{np.round(p_value,5)} cluster has significant differnce in the target feature\")\nelse:\n    print(\"cluster has significant no differnce in the target feature\")\n    \n    \nformula = 'target ~ C(cluster)'\nmodel = ols(formula, train).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(np.round(anova_table),3)","136f4ecb":"from sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\nX=train['excerpt']\nX_vect = vect.fit_transform(X)\nfrom sklearn.decomposition import LatentDirichletAllocation\ndecom = LatentDirichletAllocation(n_components=6, random_state=42)\nX_decm=decom.fit_transform(X_vect)","4e80cb0d":"train['topic']=X_decm.argmax(axis=1)\nfor index,topic in enumerate(decom.components_):\n    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n    print([vect.get_feature_names()[i] for i in topic.argsort()[-15:]])\n    print('\\n')\ntrain","a54ebf47":"print(train[train['topic']==4]['excerpt'].iloc[0])\nprint(\"\\n\\n\")\nprint(train[train['topic']==4]['excerpt'].iloc[1])","3b1b586d":"print(train[train['topic']==5]['excerpt'].iloc[0])\nprint(\"\\n\\n\")\nprint(train[train['topic']==5]['excerpt'].iloc[1])","462fcc67":"import nltk\n#nltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nstop_word = stopwords.words('english')\n\ndef clean_excerpt(x):\n    t = ' '.join(w for w in x.split() if w not in stop_word)\n    return t\n\ndef clean_punct(x):\n    t=' '.join(w for w in x.split() if w.isalnum())\n    return t\n\ntrain['excerpt_clean']=train['excerpt'].apply(clean_excerpt)\ntrain['excerpt_clean']=train['excerpt_clean'].apply(clean_punct)","775b9a49":"train","4ae09a45":"#lets do Stemming\n\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer=SnowballStemmer(language='english')\n\ndef clean_stem(x):\n    t= ' '.join(stemmer.stem(w) for w in x.split())\n    return t\n\ntrain['excerpt_clean']=train['excerpt_clean'].apply(clean_stem)\n","b186544b":"train['clean_length']=train['excerpt_clean'].apply(lambda x: len(x.split()))","ccdf70c3":"sns.heatmap(train.corr(), annot=True, linewidth=2)","03f937d2":"X","f3c5e477":"train.head()\ntrain=train[['target','license','excerpt_clean','clean_length']]\ntrain['license']=train['license'].apply(lambda x: 'no_license' if x==0 else x)","219f3b00":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nencode = LabelEncoder()\ntrain['license']=encode.fit_transform(train['license'])\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect=CountVectorizer(max_features=400)\nX_vect=vect.fit_transform(train['excerpt_clean'])\nX=pd.concat([train,pd.DataFrame(X_vect.toarray())], axis=1,ignore_index=True)\n\nX=X.drop([0,2], axis=1)\ny=train['target']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npred=model.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(f\"model train accuracy: {model.score(X_train, y_train)}\")\nprint(f\"model test accuracy: {model.score(X_test, y_test)}\")\nprint(f\"RSME: {np.sqrt(mean_squared_error(y_test, pred))}\")\nprint(f\"R-Sq: {r2_score(y_test, pred)}\")","01b4c538":"X_train.shape","1e1fbfba":"residual = y_test-pred\nfig, ax=plt.subplots(ncols=2, nrows=1, figsize=(15,4))\nax[0].scatter(y=y_test, x=pred)\nax[0].axhline(y=0, c='black', ls='--')\nax[1]=sns.kdeplot(residual)","f349e4de":"test","23b62226":"test","93fa7a11":"test","d2809c2e":"test= pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\nX_vect=vect.fit_transform(train['excerpt_clean'])\nX=pd.concat([train,pd.DataFrame(X_vect.toarray())], axis=1,ignore_index=True)\n\n\nX=X.drop([0,2], axis=1)\ny=train['target']\ntest.drop(['id','url_legal'], axis=1, inplace=True)\n\nmodel.fit(X,y)\nprint(f\"model train accuracy: {model.score(X, y)}\")\n\ntest['license'].fillna(value=0, axis=0, inplace=True)\ntest['license']=test['license'].apply(lambda x: 'no_license' if x==0 else x)\ntest['license']=test['license'].apply(lambda x: extract_license(x))\n\ntest['license']=encode.transform(test['license'])\ntest['excerpt_clean']=test['excerpt'].apply(clean_excerpt)\ntest['excerpt_clean']=test['excerpt_clean'].apply(clean_punct)\ntest['excerpt_clean']=test['excerpt_clean'].apply(clean_stem)\ntest['clean_length']=test['excerpt_clean'].apply(lambda x: len(x.split()))\ntest.drop(['excerpt'], axis=1, inplace=True)\n\nX_test_vect=vect.transform(test['excerpt_clean'])\nX_test=pd.concat([test,pd.DataFrame(X_test_vect.toarray())], axis=1,ignore_index=True)\nX_test.drop([1], axis=1, inplace=True)\npred=model.predict(X_test)","04f7eb74":"test= pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntest['target']=pred\nsample_df=test[['id','target']]\nsample_df.to_csv('submission.csv', index=False)","1fb19cbd":"sample_df","153a5047":"so, we can say that the length of the sentence has significant impact on the target prediction at 5% significance. ","a6bc5b50":"# Read Data","8c5fbae8":"### Hypothesis Testing","3366b935":"# EDA","9d02c029":"### Univariated analysis","169331cf":"**Observations:**\n1. excerpts from the license category CC BY, CC BY-NC, CC BY-NC-SA, CC BY_NC-ND, GNU free document license are comparitively less difficult compared to other license formats","da7e1d57":"# lets try to identify the topic based on excerpt","120a81b6":"Feature Details:\n1. id - unique value of the excerpt\n2. url_legal - Source of Url. there are some black cells as well. \n3. licencse - License of source material\n4. target - ease of reading, -ve is hard and +ve is easy. \n5. standar_error - measures the spread of score across multiple rater.","663b7097":"target feature & standar_error feature has only one 0 values. while creating model, let us try to check the accuracy after removing the 0 value. let see if this helps.","5d5e3f2a":"# Check for Null value","89936481":"# Modeling - Baseline model","c983e457":"we have successfully engineered the url_legal & licence features. let us use the EDA to explore more","6202bfe2":"# Topic Modeling","9d6d4107":"# Feature Engineering\nLet us try to extract the url_legal home page and categories the license type with in 6 category as mentioned above","897085ff":"### Excerpt Cleanup","33912650":"# Multivariated Analysis","131b507d":"**Observation**\n1. url_legal values with no url is distibured from -4 to +4, wikipedia & frontiersin excerpt aslo contains the readbility from easy to difficult, middle value is at -1.\n2. median value for the excerpt from africanstorybook, ck12, freekidsbooks, digitallibrary, google, osu, wikibooks are mostly bove 0, which means difficulty of reading this contents are less compared to other excerpts","adb8dd3e":"**Observations**\n1. There are outliers in standar_error features, which we need to check and address\n2. around 50% of the rating is around -2 to 0. so, most contents are predicted as moderate difficult.","ce58d08c":"we clearly see that the excerpt is same when the target & standard_error value is 0, which means that this particular excerpt is set as baseline to rate other excerpt. is this because fo the len of the sentance? let us explore further.","1f6430ef":"**Observations:**\nwhen the target value is close to -1 the stardard error is also less. and the standard error starts to increase for the target feature distribution is above -2 & 1. so, the raters have predicted the difficult for the less difficult & not so easy contents. beyond that, the rating differs.  \nOutlier in Standar_error features seems to be the only 0 error excerpt. let us find more info.","2c1be707":"Out of 2834 rows, url_legal & license has null values for 2004 rows. dropping null value would reduce the dataset size largely. So, we need to check if the feaure has realtionship in target feature. ","14c7b8a2":"### Try clustering to find the paterns","082a2e41":"Length\/no of words doesn't give much information on target feature. number of words are distributed from 140 to 200","607b36c2":"We can see some paterns. but it is helpful to predict target?","514137eb":"***Most topics are in 2,4 & 5 category***  \ntopic 2 - talks about galaxy, milky way, planets ets - only very few excerpts are in topic 2.  \ntopic 4 - talks about people, water, man, time, food etc  \ntopic 5 - talks about gas, computer, people, information, history, cells etc.  ","f9bd4cde":"***Please review and provide your inputs to improve the score. appriciate your expert opinion*** ","aeb1e245":"## Creative Common License types\nThe Creative Commons License Options\nThere are six different license types, listed from most to least permissive here:\n\nCC BY: This license allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use.\nCC BY includes the following elements:\nBY  \u2013 Credit must be given to the creator\n\n \n\nCC BY-SA: This license allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use. If you remix, adapt, or build upon the material, you must license the modified material under identical terms.\nCC BY-SA includes the following elements:\nBY  \u2013 Credit must be given to the creator\nSA  \u2013 Adaptations must be shared under the same terms\n\n \n\nCC BY-NC: This license allows reusers to distribute, remix, adapt, and build upon the material in any medium or format for noncommercial purposes only, and only so long as attribution is given to the creator. \nIt includes the following elements:\nBY  \u2013 Credit must be given to the creator\nNC  \u2013 Only noncommercial uses of the work are permitted\n\n \n\nCC BY-NC-SA: This license allows reusers to distribute, remix, adapt, and build upon the material in any medium or format for noncommercial purposes only, and only so long as attribution is given to the creator. If you remix, adapt, or build upon the material, you must license the modified material under identical terms. \nCC BY-NC-SA includes the following elements:\nBY  \u2013 Credit must be given to the creator\nNC  \u2013 Only noncommercial uses of the work are permitted\nSA  \u2013 Adaptations must be shared under the same terms\n\n \n\nCC BY-ND: This license allows reusers to copy and distribute the material in any medium or format in unadapted form only, and only so long as attribution is given to the creator. The license allows for commercial use. \nCC BY-ND includes the following elements:\nBY  \u2013 Credit must be given to the creator\nND  \u2013 No derivatives or adaptations of the work are permitted\n\n \n\nCC BY-NC-ND: This license allows reusers to copy and distribute the material in any medium or format in unadapted form only, for noncommercial purposes only, and only so long as attribution is given to the creator. \nCC BY-NC-ND includes the following elements:\nBY  \u2013 Credit must be given to the creator\nNC  \u2013 Only noncommercial uses of the work are permitted\nND  \u2013 No derivatives or adaptations of the work are permitted"}}