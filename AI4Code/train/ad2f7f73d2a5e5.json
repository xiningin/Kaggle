{"cell_type":{"56f0dacc":"code","bfe10a66":"code","1e199ef2":"code","377500af":"code","0c0d8270":"code","6311c580":"code","170f50d5":"code","3618e183":"code","52c021d7":"code","d5656064":"code","a14991ff":"code","3f7dca87":"code","c400c8ec":"code","374fae3d":"code","238c52d8":"code","9c4c1343":"code","610901ae":"code","33cac90a":"code","d5d01db3":"code","b48da1ba":"code","ae6e0309":"code","a2361b93":"code","7d48530b":"code","03595d26":"code","ca8950a1":"code","cbb6ad25":"code","d65929a5":"code","2172dd52":"code","19e0bf37":"code","a2207755":"code","18fa6181":"code","1871b431":"code","1c589f71":"code","a3064f80":"code","7bf4b51f":"code","8d288fea":"code","2b1d0d6f":"code","a8a7cb94":"code","cf895fb1":"code","ccc7c4cb":"code","1ac204ee":"code","9ef1194f":"code","114a0626":"code","52b506a3":"code","a3999829":"code","8f5940c6":"code","a2e1912c":"code","668bd5e0":"code","0ab1992a":"code","0d9671aa":"code","2af7104e":"code","723ebc1b":"code","6c425aee":"code","50718423":"code","6fe8f189":"code","e125ffb0":"code","7e1affe1":"code","590f738f":"code","c85885e6":"code","75685f0e":"code","a6186686":"code","352c4392":"code","8d028b93":"code","63126ecf":"code","38b396c6":"code","908e1c9b":"code","d331f77a":"code","eaf15039":"code","96054d00":"code","44c7ad5e":"code","9661e899":"code","0c4bae98":"code","b92c8899":"code","7e9c78e2":"code","0a0543ab":"code","29c8e460":"code","e11e10ad":"code","e97bcb01":"code","a47188a9":"code","b5a6084c":"code","e04e1f73":"code","074372a3":"code","082d02f5":"code","349b4e4a":"code","ac24c261":"code","b39b4c0f":"code","d311743d":"code","7d85abce":"code","f1ebcfa7":"code","233b2713":"code","a9e2ac09":"code","b640739e":"code","7351758f":"code","8a1b0038":"code","ab083a8f":"code","0eac595b":"code","0c112009":"code","db5a8825":"code","e99a87a2":"code","63ef7f60":"code","361b52dd":"code","1f44e632":"code","169e2eec":"code","fef62ec4":"code","ce4d6de3":"code","268e293e":"code","846a0bbe":"code","6cec79f8":"code","1459729e":"code","5d6b7be8":"code","bb7b7bcb":"code","223ebef5":"code","87bffab5":"code","4a4d5289":"code","418fba09":"code","c363176b":"code","23590576":"code","af0e6020":"code","6c2aa504":"code","abbda2c9":"code","125e4fa9":"code","3ab97696":"code","2ccfc672":"code","7cd9ec36":"code","1d9cb7dc":"code","0b6b27bd":"code","89e438a4":"code","06730a7f":"code","e2b67e2c":"code","5cc8d366":"code","c40dae14":"code","6518fc89":"code","e43435f6":"code","404e6ed1":"code","71eba6b5":"code","ec08b77d":"code","acc99613":"code","6faa1885":"code","77d3566a":"code","b62a0fd7":"code","e35831bf":"code","ef223108":"code","d2430c09":"code","254056f3":"code","e6f5f8e7":"code","af14aa59":"code","c90e5aaa":"code","46058458":"code","c2c9ac3c":"code","e988390f":"code","abca96c5":"code","de271f4f":"code","8b8a43cc":"code","c1733d3d":"code","561390b4":"code","eb0de26c":"code","1fc3128a":"code","5cc54527":"code","8d6af9a7":"code","cef156ad":"code","4a858bec":"code","42f1f6b1":"code","a65689a6":"code","689e4815":"code","b01f5171":"code","4292daab":"code","2d308c7b":"code","febe5c20":"code","cd31bf49":"code","32177200":"code","4d50fbf2":"code","e7f2b486":"code","5fc43c7c":"code","8ea5353e":"code","d3370823":"code","3a439f37":"code","be530f01":"code","0e3e47c1":"code","9c267552":"code","75e05232":"code","f4cae921":"code","891cd49b":"code","04547e4b":"code","d2595961":"code","fedbf078":"code","2c31587d":"code","f7bb38e4":"code","d645dde9":"code","c0e366f5":"code","032a7a46":"code","1d162811":"code","09870803":"code","762b4a0d":"code","34ba657b":"code","ddef9e7f":"code","279edacf":"code","c6b019c2":"code","8e1dc4f8":"code","fd012bda":"code","c6ac0e7f":"code","b9dab67a":"code","2a119221":"code","3d2f7cc9":"code","db17af32":"code","96b1209b":"code","c9c35ef8":"code","13cbf8bf":"code","ebaa6652":"code","81f096fa":"code","2e3ae36c":"code","1cc3df50":"code","ee0c170c":"code","4de0bba2":"code","1b62173d":"code","76424864":"code","0f0e22b5":"code","db1bf489":"code","19dd8126":"code","25a0f2be":"code","55e0b764":"code","0fa698a2":"code","fca5d064":"code","92017e72":"code","23abee07":"code","1d2e400d":"code","0e5da63c":"code","2b3f21b9":"code","80415015":"code","cb686973":"code","6eb6faa5":"code","8aebcbbf":"code","91a31813":"code","2a0f4edb":"code","480497c3":"code","d85bae33":"code","b40985b3":"code","d48ff196":"code","f6efebc1":"code","920ee8d6":"code","e0683a19":"code","bcaac9a9":"code","b6197e57":"code","2e8145c1":"code","2bd68b10":"code","aa143cd6":"code","cf37374c":"code","ad29965f":"code","26e2db42":"code","c0c13464":"code","5cf8b023":"code","d89fa9f1":"code","b92e6b06":"code","3654be51":"code","028b3229":"code","fe701af9":"code","60282fd1":"code","13b43e79":"code","8548fdd0":"code","1c9c8557":"code","40422327":"code","a4379eff":"code","741b748f":"code","be68a217":"code","2e65f581":"code","44a956ff":"code","7e1cba51":"code","e52c4f27":"code","99d41d53":"code","a8529e78":"code","973b5d10":"code","a87cb9ab":"code","55c6715c":"code","5fe9b0e4":"code","4d5c9e1c":"code","1e256ef3":"code","66951430":"code","d73329d0":"code","7f034cd3":"code","a4395df5":"code","6727197b":"code","bea17ed3":"code","5cceefaa":"code","075f7b22":"code","62445d53":"code","3cc8db4b":"code","9b969ac4":"code","f6f29d7d":"code","158bc21c":"code","68b6454b":"code","fb980bff":"code","a9377b64":"code","e231deb8":"code","7d2689e1":"code","30a8c467":"code","7b7b0abc":"markdown","27b37271":"markdown","c1be18a0":"markdown","6daf4d0f":"markdown","1d8ba96c":"markdown","f85d6bb1":"markdown","0e664d13":"markdown","9dab22f5":"markdown","0b8eb1c4":"markdown","df350120":"markdown","775cbead":"markdown","d79868e8":"markdown","9882ad59":"markdown","e35c7d7c":"markdown","1bcdfdfa":"markdown","bf7de1ea":"markdown","0d45d95a":"markdown","d5acb9a6":"markdown","c2e293da":"markdown","4c27795a":"markdown","00b4ea44":"markdown","a18b3336":"markdown","bfe44c9d":"markdown","77dd6af8":"markdown","c5824926":"markdown","cb0bf4ed":"markdown","0ada5f2d":"markdown","b2584da7":"markdown","03c70a76":"markdown","74f69510":"markdown","7ac0b253":"markdown","b339e5cc":"markdown","020f9c53":"markdown","4c7fead6":"markdown","137dede2":"markdown","fa348364":"markdown","961719f1":"markdown","3b10ab82":"markdown","b51a8d58":"markdown","6960d8eb":"markdown","078da5f3":"markdown","03263e8c":"markdown","2a6232f6":"markdown","0d876923":"markdown","ad910d76":"markdown","ed0a4492":"markdown","6f8c8c63":"markdown","82d0faa1":"markdown","6531944c":"markdown","cd3c5df8":"markdown","efe2ea8d":"markdown","b50c288f":"markdown","475c0211":"markdown","f8d22b82":"markdown","85b79df6":"markdown","be47ac96":"markdown","4c5db875":"markdown","9429b7af":"markdown","227d2b87":"markdown","5dd0f0d8":"markdown","77dd3190":"markdown","c7c2ed7e":"markdown","08ab4658":"markdown","1bc10e3d":"markdown","38604c34":"markdown","1652b791":"markdown","cabdce3b":"markdown","c1fda58e":"markdown","b011bc5c":"markdown","eeeb7480":"markdown","2ee682c0":"markdown","e9373e56":"markdown","6ba500dd":"markdown","1c35f60a":"markdown","5111fc88":"markdown","3bcb99d1":"markdown","3440cd1c":"markdown","d3b171e5":"markdown","dd5d1952":"markdown","1320b2c0":"markdown","6de9ad5d":"markdown","64402469":"markdown","47dc1531":"markdown","cfe61b79":"markdown","7c5c4648":"markdown","e39b338f":"markdown","f319549b":"markdown","fc6c0642":"markdown","877b9689":"markdown","51c0a43b":"markdown","be042020":"markdown","4acf8667":"markdown","68c7c560":"markdown","9f573985":"markdown","807a97ba":"markdown","78892f58":"markdown","5d841d18":"markdown","6bc13aa4":"markdown","43630e69":"markdown","8482678c":"markdown","e52a31b1":"markdown","58b57d8d":"markdown","ee7d6af6":"markdown","361fc850":"markdown","609789cf":"markdown","90c0bb49":"markdown","83310a43":"markdown","27ad7c06":"markdown","25feb94d":"markdown","5e63cbe9":"markdown","e8b20a5b":"markdown","4e9ad714":"markdown","22198d57":"markdown","03c4a969":"markdown","6b0b5286":"markdown","1b8378b7":"markdown","a3173d56":"markdown","1511320d":"markdown","ec6abf98":"markdown","c907d6c6":"markdown","992f79eb":"markdown","c5c965be":"markdown","8cbb8aee":"markdown","d6c0741c":"markdown","81b53033":"markdown","86fea613":"markdown","ade905f0":"markdown","b9cf1a23":"markdown","4ea9a542":"markdown","f942d9b5":"markdown","d7ba556c":"markdown","353b7d49":"markdown","92d62924":"markdown","e7d8d499":"markdown","8d85ae0f":"markdown","41a1621d":"markdown","cbe8e6a0":"markdown","36c9c3a1":"markdown","dc54c6b8":"markdown","244e211c":"markdown","fbb28c74":"markdown","170d12b0":"markdown","cb410830":"markdown","fd0b8792":"markdown","92edff6b":"markdown","928e71f0":"markdown","1e1d4726":"markdown"},"source":{"56f0dacc":"# let's import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n%config Inlinebackground.figureFormat='retina'\nsns.set(font_scale=1.5)\npd.options.display.max_rows = 200\npd.options.display.max_columns = 200","bfe10a66":"# let's load the datasets\n# cab data\ncab_data = pd.read_csv(r'cab_rides.txt', encoding='utf-16')\n# weather data\nweather_data = pd.read_csv(r'weather.txt', encoding='utf-16')","1e199ef2":"cab_data.head(3)","377500af":"weather_data.head(3)","0c0d8270":"cab_data.info() # basic descr.","6311c580":"# let's impute the unix epoch time to standard date time format\ncab_data['time_stamp'] = pd.to_datetime(cab_data['time_stamp'], unit='ms')\ncab_data['date'] = cab_data['time_stamp'].dt.date  # extract date\ncab_data['hour'] = cab_data['time_stamp'].dt.hour  # extract hour\n\ncab_data.drop('time_stamp', axis=1, inplace=True)  # drop time_stamp feature\n\n# before doing EDA, let's split the dataset into Uber and Lyft\nuber = cab_data[cab_data['cab_type']=='Uber']\nlyft = cab_data[cab_data['cab_type']=='Lyft']\n\ncab_data.head(3)","170f50d5":"overall = cab_data['distance'].describe() # measure of central tendency\noverall","3618e183":"lyft_distance = lyft['distance'].describe()\nuber_distance = uber['distance'].describe()","52c021d7":"df = pd.DataFrame({'Overall': overall.values,\n                  'Lyft': lyft_distance.values,\n                  'Uber': uber_distance.values}, index= ['Count', 'Mean', 'Std. Dev.', 'Min', '25%', '50%', '75%', 'Max'])\ndf","d5656064":"# df.to_csv(r'C:\\Users\\gokul\\Downloads\\distance_metrics.csv')","a14991ff":"def calculate_mop(**kwargs):\n    \"\"\" function to calculate and display the measures of dispersion.\"\"\"\n    for name, df in kwargs.items():\n        print(name, '\\n')\n        print(f'Standard deviation:     {df.std()}')\n        print(f'Skewness:               {df.skew()}')\n        print(f'Kurtosis:               {df.kurtosis()}\\n')","3f7dca87":"calculate_mop(Lyft= lyft['distance'], Uber= uber['distance'])","c400c8ec":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.distplot(lyft['distance'], ax=ax1, kde=True)\nax1.set_title('Distribution of distance in Lyft', fontsize=20)\nax1.set_ylim(0, 0.6)\na = sns.distplot(uber['distance'], ax=ax2)\nax2.set_title('Distribution of distance in Uber', fontsize=20)\nax2.set_ylim(0, 0.6)","374fae3d":"# a.figure.savefig(r'C:\\Users\\gokul\\Downloads\\distance.jpg')","238c52d8":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\nsns.boxplot(lyft['distance'], ax=ax1)\nax1.set_title('Lyft', fontsize=15)\nax1.set_xlim(0, 8)\nsns.boxplot(uber['distance'], ax=ax2)\nax2.set_title('Uber', fontsize=15)","9c4c1343":"# lyft[lyft['distance']<0.3] # can we remove records below 0.3 as cancellation records","610901ae":"# uber[uber['distance']<0.25].sort_values(by='distance', ascending=False).head(30)","33cac90a":"overall = cab_data['price'].describe()\noverall # measure of central tendency","d5d01db3":"uber_price = uber['price'].describe()\nuber_price","b48da1ba":"lyft[lyft.price<2.9].shape","ae6e0309":"lyft_price = lyft['price'].describe()\nlyft_price","a2361b93":"uber.price.sum(), lyft.price.sum()","7d48530b":"df = pd.DataFrame({'Overall': overall.values,\n                  'Lyft': lyft_price.values,\n                  'Uber': uber_price.values}, index= ['Count', 'Mean', 'Std. Dev.', 'Min', '25%', '50%', '75%', 'Max'])\ndf","03595d26":"# df.to_csv(r'C:\\Users\\gokul\\Downloads\\metrics.csv')","ca8950a1":"calculate_mop(Lyft= lyft['price'], Uber= uber['price']) # measure of dispersion","cbb6ad25":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\na = sns.distplot(lyft['price'], ax=ax1)\nax1.set_title('Distribution of price in Lyft', fontsize=20)\nax1.set(xlabel='Price')\nax1.set_ylim(0, 0.12)\nb =sns.distplot(uber[~uber['price'].isnull()]['price'], ax=ax2)\nax2.set_title('Distribution of price in Uber', fontsize=20)","d65929a5":"# a.figure.savefig(r'C:\\Users\\gokul\\Downloads\\price.jpg')","2172dd52":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\nsns.boxplot(lyft['price'], ax=ax1)\nax1.set_title('Lyft', fontsize=15)\n\nsns.boxplot(uber[~uber['price'].isnull()]['price'], ax=ax2)\nax2.set_title('Uber', fontsize=15)\nax2.set_xlim(0, 100)","19e0bf37":"lyft[(lyft['price']>40)].head(3)","a2207755":"uber[(uber['price']>40)].head(3)","18fa6181":"# a = uber[uber['price']<40].groupby(by=['source', 'destination']).median()#.head(10)\n# a","1871b431":"# a.to_csv(r'C:\\Users\\gokul\\Downloads\\tab.csv')","1c589f71":"uber[uber['price']>40].groupby(by=['source', 'destination']).mean().head(10)","a3064f80":"cab_data['cab_type'].value_counts() # frequency count","7bf4b51f":"cab_data['cab_type'].value_counts(normalize=True) # percentage of values","8d288fea":"plt.figure(figsize=(8,5))\nsns.countplot('cab_type', data=cab_data)\nplt.title('Frequency of Uber and Lyft data', fontsize=15)","2b1d0d6f":"lyft['name'].value_counts() # frequency count","a8a7cb94":"uber['name'].value_counts()","cf895fb1":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['name'], ax=ax1)\nax1.set_title('Frequency count of car models in Lyft', fontsize=20)\nsns.countplot(uber['name'], ax=ax2)\nax2.set_title('Frequency count of car models  in Uber', fontsize=20)","ccc7c4cb":"lyft['source'].value_counts() # frequency count","1ac204ee":"uber['source'].value_counts()","9ef1194f":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['source'], ax=ax1)\nax1.set_title('Frequency count of different source location in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, fontsize=15)\n# ax1.set_ylim(0, 25000)\nsns.countplot(uber['source'], ax=ax2)\nax2.set_title('Frequency count of different source location  in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, fontsize=15)","114a0626":"lyft['destination'].value_counts()","52b506a3":"uber['destination'].value_counts()","a3999829":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['destination'], ax=ax1)\nax1.set_title('Frequency count of different destination location in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, fontsize=15)\nax1.set_ylim(0, 30000)\nsns.countplot(uber['destination'], ax=ax2)\nax2.set_title('Frequency count of different destination location  in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, fontsize=15)","8f5940c6":"lyft['product_id'].value_counts()","a2e1912c":"uber['product_id'].value_counts()","668bd5e0":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['product_id'], ax=ax1)\nax1.set_title('Frequency count of different Product names in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, fontsize=15)\nsns.countplot(uber['product_id'], ax=ax2)\nax2.set_title('Frequency count of different Product names in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, fontsize=15)","0ab1992a":"lyft['surge_multiplier'].value_counts() # frequency count","0d9671aa":"uber['surge_multiplier'].value_counts()","2af7104e":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['surge_multiplier'], ax=ax1)\nax1.set_title('Frequency count of different surge multipliers in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=0, fontsize=15)\nax1.set_ylim(0, 350000)\nsns.countplot(uber['surge_multiplier'], ax=ax2)\nax2.set_title('Frequency count of different surge multipliers in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=0, fontsize=15)\nax2.set_ylim(0, 350000)","723ebc1b":"lyft['hour'].value_counts()","6c425aee":"uber['hour'].value_counts()","50718423":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.countplot(lyft['hour'], ax=ax1)\nax1.set_title('Frequency count of different destination location in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=0, fontsize=15)\nax1.set_ylim(0, 17500)\nsns.countplot(uber['hour'], ax=ax2)\nax2.set_title('Frequency count of different destination location  in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=0, fontsize=15)\nax2.set_ylim(0, 17500)","6fe8f189":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 7))\nsns.scatterplot(lyft['distance'], lyft['price'], ax=ax1)\nax1.set_title('Price vs Distance in Lyft', fontsize=20)\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=0, fontsize=15)\nsns.scatterplot(uber['distance'], uber['price'], ax=ax2)\nax2.set_title('Price vs Distance in Uber', fontsize=20)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation=0, fontsize=15)\nax2.set_ylim(0, 100)","e125ffb0":"lyft['distance'].corr(lyft['price'])","7e1affe1":"uber['distance'].corr(uber['price'])","590f738f":"a= pd.crosstab(cab_data['cab_type'], cab_data['source'])\na","c85885e6":"pd.crosstab(cab_data['cab_type'], cab_data['source'], normalize=True)","75685f0e":"plt.figure(figsize=(10,7))\npd.crosstab(cab_data['cab_type'], cab_data['source']).plot.bar(stacked=True, figsize=(20,7), rot=0)","a6186686":"pd.crosstab(cab_data['cab_type'], cab_data['destination'])","352c4392":"pd.crosstab(cab_data['cab_type'], cab_data['destination'], normalize=True)","8d028b93":"plt.figure(figsize=(10,7))\npd.crosstab(cab_data['cab_type'], cab_data['destination']).plot.bar(stacked=True, figsize=(20,7), rot=0)","63126ecf":"pd.crosstab(cab_data['cab_type'], cab_data['surge_multiplier'])","38b396c6":"pd.crosstab(cab_data['cab_type'], cab_data['surge_multiplier'], normalize=True)","908e1c9b":"plt.figure(figsize=(10,7))\npd.crosstab(cab_data['cab_type'], cab_data['surge_multiplier']).plot.bar(stacked=True, figsize=(20,7), rot=0)","d331f77a":"pd.crosstab(lyft['name'], lyft['source'])","eaf15039":"plt.figure(figsize=(10,7))\npd.crosstab(lyft['name'], lyft['source']).plot.bar(stacked=True, figsize=(20,7), rot=0)","96054d00":"cab_data['source'].nunique(), cab_data['destination'].nunique()","44c7ad5e":"pd.crosstab(uber['name'], uber['source'])","9661e899":"pd.crosstab(lyft['name'], lyft['surge_multiplier'])","0c4bae98":"pd.crosstab(lyft['name'], lyft['surge_multiplier'], normalize=True)","b92c8899":"plt.figure(figsize=(10,7))\npd.crosstab(lyft['name'], lyft['surge_multiplier']).plot.bar(stacked=True, figsize=(20,7), rot=0)","7e9c78e2":"pd.crosstab(uber['name'], uber['surge_multiplier'])","0a0543ab":"pd.crosstab(uber['source'], uber['destination'])","29c8e460":"weather_data.info() # basic info","e11e10ad":"# let's impute the unix epoch time to standard date time format\nweather_data['time_stamp'] = pd.to_datetime(weather_data['time_stamp'], unit='s')\nweather_data['date'] = weather_data['time_stamp'].dt.date\nweather_data['hour'] = weather_data['time_stamp'].dt.hour\n\nweather_data.drop('time_stamp', axis=1, inplace=True)\n\nweather_data.head(3)","e97bcb01":"weather_data['temp'].describe()","a47188a9":"calculate_mop(Temperature = weather_data['temp'])","b5a6084c":"plt.figure(figsize=(8,5))\nsns.distplot(weather_data['temp'])\nplt.title('Distribution of Temperature', fontsize=15)","e04e1f73":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data['temp'])\nplt.title('Distribution of Temperature', fontsize=15)","074372a3":"weather_data[weather_data.temp < 26].date.value_counts()","082d02f5":"weather_data[weather_data.temp > 53].date.value_counts()","349b4e4a":"weather_data[weather_data['temp']<27].shape","ac24c261":"weather_data[weather_data['temp']>52.5].shape","b39b4c0f":"weather_data[weather_data.temp>53].location.value_counts()","d311743d":"weather_data['clouds'].describe()","7d85abce":"calculate_mop(Clouds=weather_data['clouds'])","f1ebcfa7":"plt.figure(figsize=(8,5))\nsns.distplot(weather_data['clouds'])\nplt.title('Distribution of Clouds', fontsize=15)","233b2713":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data['clouds'])\nplt.title('Distribution of Clouds', fontsize=15)","a9e2ac09":"weather_data['pressure'].describe()","b640739e":"calculate_mop(Pressure=weather_data['pressure'])","7351758f":"plt.figure(figsize=(8,5))\nsns.distplot(weather_data['pressure'])\nplt.title('Distribution of Pressure', fontsize=15)","8a1b0038":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data['clouds'])\nplt.title('Distribution of Clouds', fontsize=15)","ab083a8f":"weather_data['rain'].describe()","0eac595b":"calculate_mop(Rain=weather_data['rain'])","0c112009":"plt.figure(figsize=(8,5))\na = sns.distplot(weather_data[~weather_data['rain'].isnull()]['rain'])\nplt.title('Distribution of Rain', fontsize=15)","db5a8825":"# a.figure.savefig(r'C:\\Users\\gokul\\Downloads\\rain.jpg')","e99a87a2":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data[~weather_data['rain'].isnull()]['rain'])\nplt.title('Distribution of Rain', fontsize=15)","63ef7f60":"weather_data[weather_data['rain']>0.13].date.value_counts()","361b52dd":"weather_data['humidity'].describe()","1f44e632":"calculate_mop(Humidity = weather_data['humidity'])","169e2eec":"plt.figure(figsize=(8,5))\nsns.distplot(weather_data['humidity'])\nplt.title('Distribution of Humidity', fontsize=15)","fef62ec4":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data['humidity'])\nplt.title('Distribution of Humidity', fontsize=15)","ce4d6de3":"weather_data['wind'].describe()","268e293e":"calculate_mop(Wind=weather_data['wind'])","846a0bbe":"plt.figure(figsize=(8,5))\nsns.distplot(weather_data['wind'])\nplt.title('Distribution of Wind', fontsize=15)","6cec79f8":"plt.figure(figsize=(8,5))\nsns.boxplot(weather_data['wind'])\nplt.title('Distribution of Wind', fontsize=15)","1459729e":"weather_data['location'].value_counts()","5d6b7be8":"sns.pairplot(weather_data[['temp', 'clouds', 'rain', 'pressure', 'humidity', 'wind']])","bb7b7bcb":"sns.boxplot(weather_data['temp'], y=weather_data['location'], orient='h')","223ebef5":"sns.boxplot(weather_data['rain'], y=weather_data['location'], orient='h')","87bffab5":"sns.boxplot(weather_data['clouds'], y=weather_data['location'], orient='h')","4a4d5289":"sns.boxplot(weather_data['pressure'], y=weather_data['location'], orient='h')","418fba09":"sns.boxplot(weather_data['humidity'], y=weather_data['location'], orient='h')","c363176b":"sns.boxplot(weather_data['wind'], y=weather_data['location'], orient='h')","23590576":"weather_data['date'].value_counts().sort_index()","af0e6020":"nrows, ncols = cab_data.shape\nprint(f'Cab ride dataset contains {nrows} rows and {ncols} columns.')","6c2aa504":"mv  = cab_data.isnull().sum().sum()\nprop = round(((mv\/cab_data.shape[0]) * 100),3)\nprint(f'Cab ride dataset contains {mv} missing values, which is {prop} % of whole data.')","abbda2c9":"cab_data.isnull().sum()","125e4fa9":"# let's check the cab type\ncab_data[cab_data['price'].isnull()]['cab_type'].value_counts() ","3ab97696":"cab_data[cab_data['cab_type']=='Uber'].name.value_counts()","2ccfc672":"cab_data[cab_data['price'].isnull()]['name'].value_counts() # car model","7cd9ec36":"# let's drop those records\ncab_data.dropna(how='any', inplace=True)\nnrows, ncols = cab_data.shape\nprint(f'Now the dataset contains {nrows} rows and {ncols} columns.')\n\nuber = cab_data[cab_data['cab_type']=='Uber']\nlyft = cab_data[cab_data['cab_type']=='Lyft']","1d9cb7dc":"cab_data.isnull().sum().sum() # check for missing values","0b6b27bd":"# cab_data.to_csv('C:\\Users\\gokul\\Downloads\\cabs.csv')","89e438a4":"nrows, ncols = weather_data.shape\nprint(f'Cab ride dataset contains {nrows} rows and {ncols} columns.')","06730a7f":"mv  = weather_data.isnull().sum().sum()\nprop = round(((mv\/weather_data.shape[0]) * 100),3)\nprint(f'Cab ride dataset contains {mv} missing values, which is {prop} % of whole data.')","e2b67e2c":"weather_data.isnull().sum()","5cc8d366":"# let's impute the missing values in the 'rain' column with 0\nweather_data['rain'].fillna(0, inplace=True)","c40dae14":"weather_data.isnull().sum().sum() # check for missing values","6518fc89":"# weather data supposed to contain 1 record per hour, since it has more than one values for few hours, \n# we took groupby average\nweather_data = weather_data.groupby(['location','date', 'hour']).mean()\nweather_data.reset_index(inplace=True)","e43435f6":"merged_data = pd.merge(cab_data, weather_data, how='left', left_on=['source', 'date', 'hour'],\n        right_on=['location', 'date', 'hour'])","404e6ed1":"merged_data.info()","71eba6b5":"merged_data[merged_data.temp.isnull()].groupby(['source', 'date', 'hour']).mean().head(6)","ec08b77d":"df1 = weather_data.loc[\n    (weather_data['date']==datetime.date(2018, 11, 28)) &\n    (weather_data['hour']==0)]\n\ndf2 = weather_data.loc[\n    (weather_data['date']==datetime.date(2018, 12, 4)) &\n    (weather_data['hour']==5)]\ndf3 = weather_data.loc[\n    (weather_data['date']==datetime.date(2018, 11, 28)) &\n    (weather_data['hour']==2)]\ndf4 = weather_data.loc[\n    (weather_data['date']==datetime.date(2018, 12, 4)) &\n    (weather_data['hour']==7)]\n\n\nlookup = pd.concat([df1, df2, df3, df4])\nlookup = lookup.groupby(['hour', 'location', 'date']).mean().reset_index()\ndf5 = weather_data.loc[\n    (weather_data['date']==datetime.date(2018, 12, 18)) &\n    (weather_data['hour']==18)]\n\nlookup = pd.concat([lookup, df5])\nlookup['hour'] += 1\nlookup.reset_index(inplace=True)","acc99613":"weather_data = pd.concat([weather_data, lookup], ignore_index=True) ","6faa1885":"weather_data.shape","77d3566a":"cab_data = pd.merge(cab_data, weather_data, how='left',\n                left_on=['source', 'date', 'hour'],\n                right_on=['location', 'date', 'hour'])","b62a0fd7":"cab_data.info()","e35831bf":"cab_data.drop('index', axis=1, inplace=True)","ef223108":"cab_data.shape, cab_data.drop_duplicates().shape","d2430c09":"# drop unnecessary features\ncab_data = cab_data.drop(['id', 'product_id', 'location', 'date'], axis=1)","254056f3":"corr_m = cab_data.corr()","e6f5f8e7":"x = np.tri(corr_m.shape[0],k=-1)","af14aa59":"plt.figure(figsize=(15,10))\na = sns.heatmap(corr_m, annot=True, mask=x)","c90e5aaa":"# a.figure.savefig(r'C:\\Users\\gokul\\Downloads\\corr.jpg')","46058458":"# Initial data preparation","c2c9ac3c":"data = cab_data.drop(['price', 'surge_multiplier'], axis=1) # we are dropping surge multiplier, to avoid data leak\nlabels = cab_data['price'].copy()","e988390f":"# model building libraries\n\n# from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder","abca96c5":"uber = cab_data[cab_data['cab_type']=='Uber']\nuber.reset_index(inplace=True)\nuber.drop('index', axis=1, inplace=True)\nlyft = cab_data[cab_data['cab_type']=='Lyft']\nlyft.reset_index(inplace=True)\nlyft.drop('index', axis=1, inplace=True)","de271f4f":"uber.drop('cab_type', axis=1, inplace=True)\nlyft.drop('cab_type', axis=1, inplace=True)","8b8a43cc":"lyft_data = lyft.copy() # backups\nuber_data = uber.copy()","c1733d3d":"uber_data.head()","561390b4":"uber.info()","eb0de26c":"ohe = OneHotEncoder()\ncar_type = pd.DataFrame(ohe.fit_transform(uber[['name']]).toarray(), columns=sorted(list(uber['name'].unique())))\nsource = pd.DataFrame(ohe.fit_transform(uber[['source']]).toarray(), \n                       columns=['src_'+loc for loc in sorted(list(uber['source'].unique()))])\ndestination = pd.DataFrame(ohe.fit_transform(uber[['destination']]).toarray(), \n                           columns=['dest_'+loc for loc in sorted(list(uber['destination'].unique()))])","1fc3128a":"ohe = OneHotEncoder()\nlyft_car_type = pd.DataFrame(ohe.fit_transform(lyft[['name']]).toarray(), columns=sorted(list(lyft['name'].unique())))\nlyft_source = pd.DataFrame(ohe.fit_transform(lyft[['source']]).toarray(),\n                           columns=['src_'+loc for loc in sorted(list(lyft['source'].unique()))])\nlyft_destination = pd.DataFrame(ohe.fit_transform(lyft[['destination']]).toarray(),\n                                columns=['dest_'+loc for loc in sorted(list(lyft['destination'].unique()))])","5cc54527":"uber = pd.concat([uber, car_type, source, destination], axis=1)\nuber.drop(['name', 'source', 'destination'], axis=1, inplace=True)","8d6af9a7":"lyft = pd.concat([lyft, lyft_car_type, lyft_source, lyft_destination], axis=1)\nlyft.drop(['name', 'source', 'destination'], axis=1, inplace=True)","cef156ad":"from sklearn.preprocessing import LabelEncoder","4a858bec":"uber_le = uber_data.copy()\nlyft_le = lyft_data.copy()\n\nlb = LabelEncoder()\n\nuber_le['name'] = lb.fit_transform(uber_data['name'])\nuber_le['source'] = lb.fit_transform(uber_data['source'])\nuber_le['destination'] = lb.fit_transform(uber_data['destination'])\n\nlyft_le['name'] = lb.fit_transform(lyft_le['name'])\nlyft_le['source'] = lb.fit_transform(lyft_le['source'])\nlyft_le['destination'] = lb.fit_transform(lyft_le['destination'])","42f1f6b1":"uber_leX = uber_le.drop(['price', 'surge_multiplier'], axis=1)\nuber_ley = uber_le['price'].copy()\n\nlyft_leX = lyft_le.drop(['price', 'surge_multiplier'], axis=1)\nlyft_ley = lyft_le['price'].copy()","a65689a6":"uber_X = uber.drop(['price', 'surge_multiplier'], axis=1)\nuber_y = uber['price'].copy()","689e4815":"lyft_X = lyft.drop(['price', 'surge_multiplier'], axis=1)\nlyft_y = lyft['price'].copy()","b01f5171":"uber_leX.shape","4292daab":"lyft_leX.shape","2d308c7b":"import statsmodels.api as sm","febe5c20":"x_constant = sm.add_constant(uber_X)\nuber_model = sm.OLS(uber_y, x_constant).fit()\nuber_model.summary()","cd31bf49":"x_constant = sm.add_constant(lyft_X)\nlyft_model = sm.OLS(lyft_y, x_constant).fit()\nlyft_model.summary()","32177200":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score, classification_report","4d50fbf2":"X_train, X_test, y_train, y_test = train_test_split(uber_X, uber_y, test_size=0.3, random_state=42)\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)","e7f2b486":"train_pred = lin_reg.predict(X_train)\nprint(f'Train score {np.sqrt(mean_squared_error(y_train, train_pred))}')\n\npredicted = lin_reg.predict(X_test)\nprint(f'Test score {np.sqrt(mean_squared_error(y_test, predicted))}')","5fc43c7c":"X_train, X_test, y_train, y_test = train_test_split(lyft_X, lyft_y, test_size=0.3, random_state=42)\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)","8ea5353e":"train_pred = lin_reg.predict(X_train)\nprint(f'Train score {np.sqrt(mean_squared_error(y_train, train_pred))}')\n\npredicted = lin_reg.predict(X_test)\nprint(f'Test score {np.sqrt(mean_squared_error(y_test, predicted))}')","d3370823":"import statsmodels.api         as     sm\nfrom   statsmodels.formula.api import ols\n \nmod = ols('price ~ source', data = uber_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","3a439f37":"mod = ols('price ~ source', data = lyft_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","be530f01":"mod = ols('price ~ destination', data = uber_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","0e3e47c1":"mod = ols('price ~ destination', data = lyft_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","9c267552":"mod = ols('price ~ name', data = uber_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","75e05232":"mod = ols('price ~ name', data = lyft_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","f4cae921":"mod = ols('price ~ cab_type', data = cab_data).fit()\naov_table = sm.stats.anova_lm(mod, typ=2)\nprint(aov_table)","891cd49b":"lyft_data.info()","04547e4b":"plt.figure(figsize=(15,10))\ncorr_m = lyft_data.corr()\nx = np.tri(corr_m.shape[0],k=-1)\nsns.heatmap(corr_m, annot=True, cmap=plt.cm.Reds, mask=x)\nplt.show()","d2595961":"corr_m['price'].abs().sort_values(ascending=False)[1:]","fedbf078":"plt.figure(figsize=(15,10))\ncorr_m = uber_data[['distance', 'destination', 'source', 'price','name', 'hour', 'temp', 'clouds', 'pressure', 'rain', 'humidity',\n       'wind']].corr()\nx = np.tri(corr_m.shape[0],k=-1)\nsns.heatmap(corr_m, annot=True, cmap=plt.cm.Reds, mask=x)\nplt.show()","2c31587d":"corr_m['price'].abs().sort_values(ascending=False)[1:]","f7bb38e4":"uber1_X = uber_X.copy()\nuber1_y = uber_y.copy()","d645dde9":"lyft1_X = lyft_X\nlyft1_y = lyft_y","c0e366f5":"#Backward Elimination\ncols = list(uber1_X.columns)\npmax = 1\ncounter=0\nwhile (len(cols)>0):\n    p= []\n    counter+=1\n\n    X_1 = uber1_X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(uber1_y,X_1).fit()\n#     print(counter)\n#     print(len(pd.Series(model.pvalues.values)))\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n#         print('inside')\n        cols.remove(feature_with_p_max)\n    else:\n        break\n    print(feature_with_p_max)\n#     print(len(cols))\nselected_features_BE = cols\nprint(selected_features_BE)","032a7a46":"len(selected_features_BE)","1d162811":"uber2 = uber1_X[selected_features_BE]","09870803":"uber2_X = uber2\nuber2_y = uber_data['price'].copy()","762b4a0d":"x_constant = sm.add_constant(uber2_X)\nuber_model = sm.OLS(uber2_y, x_constant).fit()\nuber_model.summary()","34ba657b":"#Backward Elimination\ncols = list(lyft1_X.columns)\npmax = 1\ncounter=0\nwhile (len(cols)>0):\n    p= []\n    counter+=1\n    X_1 = lyft1_X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(lyft1_y,X_1).fit()\n#     print(counter)\n#     print(len(pd.Series(model.pvalues.values)))\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n#         print('inside')\n        cols.remove(feature_with_p_max)\n    else:\n        break\n    print(feature_with_p_max)\n#     print(len(cols))\nselected_features_BE = cols\nprint('\\n',selected_features_BE)","ddef9e7f":"len(selected_features_BE)","279edacf":"lyft2 = lyft1_X[selected_features_BE]","c6b019c2":"lyft2_X = lyft2\nlyft2_y = lyft_data['price'].copy()","8e1dc4f8":"x_constant = sm.add_constant(lyft2_X)\nlyft_model = sm.OLS(lyft2_y, x_constant).fit()\nlyft_model.summary()","fd012bda":"from mlxtend.feature_selection import SequentialFeatureSelector as sfs","c6ac0e7f":"# Build RF classifier to use in feature selection\nclf = LinearRegression()\n\nX_train, X_test, y_train, y_test = train_test_split(uber1_X, uber1_y, test_size = 0.3, random_state = 0)\n\n\n# Build step forward feature selection\nsfs1 = sfs(clf,k_features = 38,forward=True,\n           floating=False, scoring='r2',\n           verbose=2,\n           cv=5)\n\n# Perform SFFS\nsfs1 = sfs1.fit(X_train, y_train)","b9dab67a":"# Build RF classifier to use in feature selection\nclf = LinearRegression()\n\nX_train, X_test, y_train, y_test = train_test_split(lyft1_X, lyft1_y, test_size = 0.3, random_state = 0)\n\n\n# Build step forward feature selection\nsfs1 = sfs(clf,k_features = 38,forward=True,\n           floating=False, scoring='r2',\n           verbose=2,\n           cv=5)\n\n# Perform SFFS\nsfs1 = sfs1.fit(X_train, y_train)","2a119221":"from sklearn.linear_model import LassoCV","3d2f7cc9":"reg = LassoCV()\nreg.fit(uber1_X, uber1_y)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(uber1_X,uber1_y))\ncoef = pd.Series(reg.coef_, index = uber1_X.columns)\ncoef","db17af32":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","96b1209b":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","c9c35ef8":"reg = LassoCV()\nreg.fit(lyft1_X, lyft1_y)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(lyft1_X, lyft1_y))\ncoef = pd.Series(reg.coef_, index = lyft1_X.columns)\ncoef","13cbf8bf":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","ebaa6652":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","81f096fa":"## Building of simple OLS model.\nX_constant = sm.add_constant(uber1_X)\nmodel = sm.OLS(uber1_y, X_constant).fit()\npredictions = model.predict(X_constant)\nmodel.summary()","2e3ae36c":"### calculating the vif values as multicollinearity exists\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(uber1_X.values, j) for j in range(1, uber1_X.shape[1])]\nvif","1cc3df50":"# removing collinear variables\n# function definition\n\ndef calculate_vif(x):\n    thresh = 5.0\n    output = pd.DataFrame()\n    k = x.shape[1]\n    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n    for i in range(1,k):\n        print(\"Iteration no.\")\n        print(i)\n        print(vif)\n        a = np.argmax(vif)\n        print(\"Max VIF is for variable no.:\")\n        print(a)\n        \n        if vif[a] <= thresh :\n            break\n        if i == 1 :          \n            output = x.drop(x.columns[a], axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n        elif i > 1 :\n            output = output.drop(output.columns[a],axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n        print(output.columns)\n    return(output)","ee0c170c":"## passing X to the function so that the multicollinearity gets removed.\ntrain_out = calculate_vif(uber1_X)","4de0bba2":"## includes only the relevant features.\ntrain_out.head()","1b62173d":"len(train_out.columns)","76424864":"uber_X = uber_X.drop(['wind', 'humidity', 'temp', 'clouds'], axis=1) #onehot encoded\nlyft_X = lyft_X.drop(['wind', 'humidity', 'temp', 'clouds'], axis=1)","0f0e22b5":"uber_leX = uber_leX.drop(['wind', 'humidity', 'temp', 'clouds'], axis=1) # label encoded\nlyft_leX = lyft_leX.drop(['wind', 'humidity', 'temp', 'clouds'], axis=1)","db1bf489":"uber_leX.head()","19dd8126":"lyft_leX.head()","25a0f2be":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nuber_std = pd.DataFrame(sc.fit_transform(uber_X[['distance', 'hour', 'pressure', 'rain']]), \n                        columns=['distance', 'hour', 'pressure', 'rain'])\n\nlyft_std = pd.DataFrame(sc.fit_transform(lyft_X[['distance', 'hour', 'pressure', 'rain']]),\n                        columns=['distance', 'hour', 'pressure', 'rain'])\n\nuber_X = uber_X.drop(['distance', 'hour', 'pressure', 'rain'], axis=1)\nlyft_X = lyft_X.drop(['distance', 'hour', 'pressure', 'rain'], axis=1)\n\nuber_X = pd.concat([uber_std, uber_X], axis=1)\nlyft_X = pd.concat([lyft_std, lyft_X], axis=1)","55e0b764":"from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.model_selection import GridSearchCV","0fa698a2":"X_trainu, X_testu, y_trainu, y_testu = train_test_split(uber_X, uber_y, test_size=0.3, random_state=42)","fca5d064":"lin_reg_uber = LinearRegression()\nlin_reg_uber.fit(X_trainu, y_trainu)\n\n# print(f'Train score : {lin_reg_uber.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, lin_reg_uber.predict(X_trainu)))}')\npredicted = lin_reg_uber.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')","92017e72":"train_cv = cross_val_score(LinearRegression(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(LinearRegression(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nl_reg_uber = {}\nl_reg_uber['Train'] = round(train_rmse, 4)\nl_reg_uber['Test'] = round(test_rmse, 4)\nl_reg_uber","23abee07":"X_trainl, X_testl, y_trainl, y_testl = train_test_split(lyft_X, lyft_y, test_size=0.3, random_state=42)","1d2e400d":"lin_reg_lyft = LinearRegression()\nlin_reg_lyft.fit(X_trainl, y_trainl)\n\n# print(f'Train score : {lin_reg_lyft.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, lin_reg_lyft.predict(X_trainl)))}')\npredicted = lin_reg_lyft.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')","0e5da63c":"train_cv = cross_val_score(LinearRegression(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(LinearRegression(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nl_reg_lyft = {}\nl_reg_lyft['Train'] = round(train_rmse, 4)\nl_reg_lyft['Test'] = round(test_rmse, 4)\nl_reg_lyft","2b3f21b9":"ridge_reg = Ridge(random_state=42)\nridge_reg.fit(X_trainu, y_trainu)\n\nridge_reg_predict = ridge_reg.predict(X_testu)\n\n# print(f'Train score : {ridge_reg.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, ridge_reg.predict(X_trainu)))}')\npredicted = ridge_reg.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\nnp.sqrt(np.abs(cross_val_score(Ridge(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')))","80415015":"train_cv = cross_val_score(Ridge(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(Ridge(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nr_reg_uber = {}\nr_reg_uber['Train'] = round(train_rmse, 4)\nr_reg_uber['Test'] = round(test_rmse, 4)\nr_reg_uber","cb686973":"lambdas=np.linspace(1,100,100)\nparams={'alpha':lambdas}\ngrid_search=GridSearchCV(Ridge(),param_grid=params,cv=10,scoring='neg_mean_absolute_error')\ngrid_search.fit(X_trainu,y_trainu)\ngrid_search.best_estimator_","6eb6faa5":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, model.predict(X_trainu)))}')\npredicted = model.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(model, X_trainu, y_trainu, cv=5, n_jobs=-1)","8aebcbbf":"ridge_reg = Ridge(random_state=42)\nridge_reg.fit(X_trainl, y_trainl)\n\nridge_reg_predict = ridge_reg.predict(X_testl)\n\n# print(f'Train score : {ridge_reg.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, ridge_reg.predict(X_trainl)))}')\npredicted = ridge_reg.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(Ridge(), X_trainl, y_trainl, cv=5, n_jobs=-1)","91a31813":"train_cv = cross_val_score(Ridge(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(Ridge(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nr_reg_lyft = {}\nr_reg_lyft['Train'] = round(train_rmse, 4)\nr_reg_lyft['Test'] = round(test_rmse, 4)\nr_reg_lyft","2a0f4edb":"lambdas=np.linspace(1,100,100)\nparams={'alpha':lambdas}\ngrid_search=GridSearchCV(Ridge(),param_grid=params,cv=10,scoring='neg_mean_absolute_error')\ngrid_search.fit(X_trainl,y_trainl)\ngrid_search.best_estimator_","480497c3":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, model.predict(X_trainl)))}')\npredicted = model.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(model, X_trainl, y_trainl, cv=5, n_jobs=-1)","d85bae33":"lasso_reg = Lasso(random_state=42)\nlasso_reg.fit(X_trainu, y_trainu)\n\nlasso_reg_predict = lasso_reg.predict(X_testu)\n\n# print(f'Train score : {lasso_reg.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, lasso_reg.predict(X_trainu)))}')\npredicted = lasso_reg.predict(X_testu)\n# print(np.sqrt(mean_squared_error(y_trainu, lasso_reg.predict(X_trainu))))\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(Lasso(), X_trainu, y_trainu, cv=5, n_jobs=-1)","b40985b3":"train_cv = cross_val_score(Lasso(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(Lasso(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nla_reg_uber = {}\nla_reg_uber['Train'] = round(train_rmse, 4)\nla_reg_uber['Test'] = round(test_rmse, 4)\nla_reg_uber","d48ff196":"lambdas=np.linspace(1,100,100)\nparams={'alpha':lambdas}\ngrid_search=GridSearchCV(Lasso(),param_grid=params,cv=10,scoring='neg_mean_absolute_error')\ngrid_search.fit(X_trainu,y_trainu)\ngrid_search.best_estimator_","f6efebc1":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, model.predict(X_trainu)))}')\npredicted = model.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(model, X_trainu, y_trainu, cv=5, n_jobs=-1)","920ee8d6":"lasso_reg = Lasso(random_state=42)\nlasso_reg.fit(X_trainl, y_trainl)\n\n# print(f'Train score : {lasso_reg.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, lasso_reg.predict(X_trainl)))}')\npredicted = lasso_reg.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(Lasso(random_state=42), X_trainl, y_trainl, cv=5, n_jobs=-1)","e0683a19":"train_cv = cross_val_score(Lasso(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(Lasso(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nla_reg_lyft = {}\nla_reg_lyft['Train'] = round(train_rmse, 4)\nla_reg_lyft['Test'] = round(test_rmse, 4)\nla_reg_lyft","bcaac9a9":"lambdas=np.linspace(1,100,100)\nparams={'alpha':lambdas}\ngrid_search=GridSearchCV(Lasso(),param_grid=params,cv=10,scoring='neg_mean_absolute_error')\ngrid_search.fit(X_trainl,y_trainl)\ngrid_search.best_estimator_","b6197e57":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, model.predict(X_trainl)))}')\npredicted = model.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\nnp.sqrt(np.abs(cross_val_score(model, X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_absolute_error')))","2e8145c1":"elastic_reg = ElasticNet(random_state=42)\nelastic_reg.fit(X_trainu, y_trainu)\n\nelastic_reg_predict = elastic_reg.predict(X_testu)\n\n# print(f'Train score : {elastic_reg.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, elastic_reg.predict(X_trainu)))}')\npredicted = elastic_reg.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(ElasticNet(), X_trainu, y_trainu, cv=5, n_jobs=-1)","2bd68b10":"train_cv = cross_val_score(ElasticNet(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(ElasticNet(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nel_reg_uber = {}\nel_reg_uber['Train'] = round(train_rmse, 4)\nel_reg_uber['Test'] = round(test_rmse, 4)\nel_reg_uber","aa143cd6":"# parametersGrid = {\"alpha\": [ 0.001, 0.01, 0.1, 1, 10, 100],\n#                   \"l1_ratio\": np.arange(0.2, 1.0, 0.1)}\nparams={'alpha':lambdas}\n\ngrid_search=GridSearchCV(ElasticNet(),param_grid=params,cv=10,scoring='r2')\ngrid_search.fit(X_trainu,y_trainu)\ngrid_search.best_estimator_","cf37374c":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainu, y_trainu)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainu, model.predict(X_trainu)))}')\npredicted = model.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\ncross_val_score(model, X_trainu, y_trainu, cv=5, n_jobs=-1)","ad29965f":"elastic_reg = ElasticNet(random_state=42)\nelastic_reg.fit(X_trainl, y_trainl)\n\nelastic_reg_predict = elastic_reg.predict(X_testl)\n\n# print(f'Train score : {elastic_reg.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, elastic_reg.predict(X_trainl)))}')\npredicted = elastic_reg.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\ncross_val_score(ElasticNet(), X_trainl, y_trainl, cv=5, n_jobs=-1)","26e2db42":"train_cv = cross_val_score(ElasticNet(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(ElasticNet(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nel_reg_lyft = {}\nel_reg_lyft['Train'] = round(train_rmse, 4)\nel_reg_lyft['Test'] = round(test_rmse, 4)\nel_reg_lyft","c0c13464":"# parametersGrid = {\"alpha\": [ 0.001, 0.01, 0.1, 1, 10, 100],\n#                   \"l1_ratio\": np.arange(0.2, 1.0, 0.1)}\nparams={'alpha':lambdas}\n\ngrid_search=GridSearchCV(ElasticNet(),param_grid=params,cv=10,scoring='r2')\ngrid_search.fit(X_trainl,y_trainl)\ngrid_search.best_estimator_","5cf8b023":"model = grid_search.best_estimator_\n\n# print(f'Train score : {model.score(X_trainl, y_trainl)}')\nprint(f'Train RMSE score : {np.sqrt(mean_squared_error(y_trainl, model.predict(X_trainl)))}')\npredicted = model.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(model, X_trainl, y_trainl, cv=5, n_jobs=-1)","d89fa9f1":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import roc_curve","b92e6b06":"X_trainu, X_testu, y_trainu, y_testu = train_test_split(uber_leX, uber_ley, test_size=0.3, random_state=42)","3654be51":"dtree = DecisionTreeRegressor()\n\ndtree.fit(X_trainu, y_trainu)\n\ntrain_pred = dtree.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = dtree.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(DecisionTreeRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1)","028b3229":"max_depth = range(1,20)\ntrain_results = []\ntest_results = []\nfor n in max_depth:\n    dt = DecisionTreeRegressor(max_depth=n)\n    dt.fit(X_trainu, y_trainu)\n    train_pred = dt.predict(X_trainu)\n    rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\n    train_results.append(rmse)\n    y_pred = dt.predict(X_testu)\n    ts_rmse = np.sqrt(mean_squared_error(y_testu, y_pred))\n    test_results.append(ts_rmse)","fe701af9":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depth, train_results, 'b', label='Train RMSE')\nline2, = plt.plot(max_depth, test_results, 'r--', label='Test RMSE')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('RMSE score')\nplt.xlabel('Tree depth')\nplt.show()","60282fd1":"dtree = DecisionTreeRegressor(max_depth=15)\n\ndtree.fit(X_trainu, y_trainu)\n\ntrain_pred = dtree.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = dtree.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(DecisionTreeRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1)","13b43e79":"train_cv = cross_val_score(DecisionTreeRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(DecisionTreeRegressor(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\ndt_reg_uber = {}\ndt_reg_uber['Train'] = round(train_rmse, 4)\ndt_reg_uber['Test'] = round(test_rmse, 4)\ndt_reg_uber","8548fdd0":"X_trainl, X_testl, y_trainl, y_testl = train_test_split(lyft_leX, lyft_ley, test_size=0.3, random_state=42)","1c9c8557":"dtree = DecisionTreeRegressor(max_depth=15)\n\ndtree.fit(X_trainl, y_trainl)\n\ntrain_pred = dtree.predict(X_trainl)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainl, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = dtree.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\n# cross_val_score(DecisionTreeRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1)","40422327":"train_cv = cross_val_score(DecisionTreeRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(DecisionTreeRegressor(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\ndt_reg_lyft = {}\ndt_reg_lyft['Train'] = round(train_rmse, 4)\ndt_reg_lyft['Test'] = round(test_rmse, 4)\ndt_reg_lyft","a4379eff":"param_grid = {'max_depth': np.arange(3, 30),\n             'min_samples_split': np.arange(.1,1.1,.1),\n             'min_samples_leaf': np.arange(.1,.6,.1)}","741b748f":"grid_srch_dtree = tree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=10,scoring='neg_mean_squared_error')\ngrid_srch_dtree.fit(X_trainu, y_trainu)\ngrid_srch_dtree.best_estimator_","be68a217":"from sklearn.ensemble import RandomForestRegressor\n# from sklearn.cross","2e65f581":"rf = RandomForestRegressor()\nrf.fit(X_trainu, y_trainu)\n\ntrain_pred = rf.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = rf.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(RandomForestRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","44a956ff":"train_cv = cross_val_score(RandomForestRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(RandomForestRegressor(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nrf_reg_uber = {}\nrf_reg_uber['Train'] = round(train_rmse, 4)\nrf_reg_uber['Test'] = round(test_rmse, 4)\nrf_reg_uber","7e1cba51":"param_grid = {'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200],\n              'max_features' : list(range(1,X_trainu.shape[1])),\n              'max_depth': np.arange(3, 30),\n             'min_samples_split': np.arange(.1,1.1,.1),\n             'min_samples_leaf': np.arange(.1,.6,.1)}","e52c4f27":"grid_srch_rf = tree = GridSearchCV(RandomForestRegressor(), param_grid, cv=10,scoring='neg_mean_squared_error')\ngrid_srch_rf.fit(X_trainu, y_trainu)\ngrid_srch_rf.best_estimator_","99d41d53":"rf = RandomForestRegressor()\nrf.fit(X_trainl, y_trainl)\n\ntrain_pred = rf.predict(X_trainl)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainl, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = rf.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(RandomForestRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","a8529e78":"train_cv = cross_val_score(RandomForestRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(RandomForestRegressor(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nrf_reg_lyft = {}\nrf_reg_lyft['Train'] = round(train_rmse, 4)\nrf_reg_lyft['Test'] = round(test_rmse, 4)\nrf_reg_lyft","973b5d10":"from sklearn.ensemble import AdaBoostRegressor","a87cb9ab":"abr = AdaBoostRegressor(random_state=42)\n\nabr.fit(X_trainu, y_trainu)\n\ntrain_pred = abr.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = abr.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(AdaBoostRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","55c6715c":"train_cv = cross_val_score(AdaBoostRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(AdaBoostRegressor(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nabr_reg_uber = {}\nabr_reg_uber['Train'] = round(train_rmse, 4)\nabr_reg_uber['Test'] = round(test_rmse, 4)\nabr_reg_uber","5fe9b0e4":"abr = AdaBoostRegressor(random_state=42)\n\nabr.fit(X_trainl, y_trainl)\n\ntrain_pred = abr.predict(X_trainl)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainl, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = abr.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(AdaBoostRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","4d5c9e1c":"train_cv = cross_val_score(AdaBoostRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(AdaBoostRegressor(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nabr_reg_lyft = {}\nabr_reg_lyft['Train'] = round(train_rmse, 4)\nabr_reg_lyft['Test'] = round(test_rmse, 4)\nabr_reg_lyft","1e256ef3":"from sklearn.ensemble import GradientBoostingRegressor","66951430":"X_trainu.head()","d73329d0":"gbr = GradientBoostingRegressor(random_state=42)\n\ngbr.fit(X_trainu, y_trainu)\n\ntrain_pred = gbr.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = gbr.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(GradientBoostingRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","7f034cd3":"train_cv = cross_val_score(GradientBoostingRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(GradientBoostingRegressor(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\ngbr_reg_uber = {}\ngbr_reg_uber['Train'] = round(train_rmse, 4)\ngbr_reg_uber['Test'] = round(test_rmse, 4)\ngbr_reg_uber","a4395df5":"gbr = GradientBoostingRegressor(random_state=42)\n\ngbr.fit(X_trainl, y_trainl)\n\ntrain_pred = gbr.predict(X_trainl)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainl, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = gbr.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(GradientBoostingRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","6727197b":"train_cv = cross_val_score(GradientBoostingRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(GradientBoostingRegressor(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\ngbr_reg_lyft = {}\ngbr_reg_lyft['Train'] = round(train_rmse, 4)\ngbr_reg_lyft['Test'] = round(test_rmse, 4)\ngbr_reg_lyft","bea17ed3":"from xgboost import XGBRegressor","5cceefaa":"xbr = XGBRegressor(random_state=42)\n\nxbr.fit(X_trainu, y_trainu)\n\ntrain_pred = xbr.predict(X_trainu)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainu, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = xbr.predict(X_testu)\nrmse = np.sqrt(mean_squared_error(y_testu, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(XGBRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","075f7b22":"train_cv = cross_val_score(XGBRegressor(), X_trainu, y_trainu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(XGBRegressor(), X_testu, y_testu, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nxbr_reg_uber = {}\nxbr_reg_uber['Train'] = round(train_rmse, 4)\nxbr_reg_uber['Test'] = round(test_rmse, 4)\nxbr_reg_uber","62445d53":"xbr = XGBRegressor(random_state=42)\n\nxbr.fit(X_trainl, y_trainl)\n\ntrain_pred = xbr.predict(X_trainl)\n\ntr_rmse = np.sqrt(mean_squared_error(y_trainl, train_pred))\nprint(f'Train score : {tr_rmse}')\npredicted = xbr.predict(X_testl)\nrmse = np.sqrt(mean_squared_error(y_testl, predicted))\nprint(f'Test score : {rmse}')\n\ncv = cross_val_score(XGBRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\nprint(np.sqrt(np.abs(cv)))","3cc8db4b":"train_cv = cross_val_score(XGBRegressor(), X_trainl, y_trainl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(XGBRegressor(), X_testl, y_testl, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nxbr_reg_lyft = {}\nxbr_reg_lyft['Train'] = round(train_rmse, 4)\nxbr_reg_lyft['Test'] = round(test_rmse, 4)\nxbr_reg_lyft","9b969ac4":"from catboost import CatBoostRegressor","f6f29d7d":"X = uber_data.drop(['surge_multiplier', 'price', 'humidity', 'clouds', 'temp', 'wind'], axis=1)\ny = uber_data['price'].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ncategorical_features_indices = np.where(X.dtypes != np.number)[0]\ncategorical_features_indices","158bc21c":"model=CatBoostRegressor(iterations=50, depth=3, learning_rate=0.1, loss_function='RMSE', verbose=400)\nmodel.fit(X_train, y_train,cat_features=[1,2,3,4],eval_set=(X_test, y_test),plot=True)","68b6454b":"train_cv = cross_val_score(CatBoostRegressor(), X_train, y_train, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(CatBoostRegressor(), X_test, y_test, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\ncbr_reg_uber = {}\ncbr_reg_uber['Train'] = round(train_rmse, 4)\ncbr_reg_uber['Test'] = round(test_rmse, 4)\ncbr_reg_uber","fb980bff":"X = lyft_data.drop(['surge_multiplier', 'price', 'humidity', 'clouds', 'temp', 'wind'], axis=1)\ny = lyft_data['price'].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ncategorical_features_indices = np.where(X.dtypes != np.number)[0]\ncategorical_features_indices","a9377b64":"model=CatBoostRegressor(iterations=50, depth=3, learning_rate=0.1, loss_function='RMSE')\nmodel.fit(X_train, y_train,cat_features=[1,2,3,4],eval_set=(X_test, y_test),plot=True)","e231deb8":"train_cv = cross_val_score(CatBoostRegressor(), X_train, y_train, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntrain_rmse = np.sqrt(np.abs(train_cv)).mean()\n\ntest_cv = cross_val_score(CatBoostRegressor(), X_test, y_test, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\ntest_rmse = np.sqrt(np.abs(test_cv)).mean()\n\nxbr_reg_lyft = {}\nxbr_reg_lyft['Train'] = round(train_rmse, 4)\nxbr_reg_lyft['Test'] = round(test_rmse, 4)\nxbr_reg_lyft","7d2689e1":"final_results = pd.DataFrame([l_reg_uber, r_reg_uber, la_reg_uber, el_reg_uber, dt_reg_uber,\n                              rf_reg_uber, abr_reg_uber, gbr_reg_uber, xbr_reg_uber, cbr_reg_uber],\n                            index=['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Elastic Net Regression',\n                                  'Decision Tree', 'Random Forest', 'Ada Boost', 'Gradient Boost', 'Xg Boost',\n                                  'Cat Boost'])\nfinal_results","30a8c467":"final_results = pd.DataFrame([l_reg_lyft, r_reg_lyft, la_reg_lyft, el_reg_lyft, dt_reg_lyft,\n                              rf_reg_lyft, abr_reg_lyft, gbr_reg_lyft, xbr_reg_lyft, cbr_reg_lyft],\n                            index=['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Elastic Net Regression',\n                                  'Decision Tree', 'Random Forest', 'Ada Boost', 'Gradient Boost', 'Xg Boost',\n                                  'Cat Boost'])\nfinal_results","7b7b0abc":"### Feature category        \n**Categorical**       \n    - location\n    \n**Continuous**     \n    - temp\n    - time stamp\n    - clouds\n    - pressure\n    - rain\n    - humidity\n    - wind","27b37271":"### Missing Value Treatment","c1be18a0":"**Outliers handling**      \nWe could see that, some rides higher price than usual for different car models. From our analysis, we came to know,\nduration of the trip also has impact on the price, and we do not posses data regarding the\nduration of the trip, so we cannot remove these outliers.","6daf4d0f":"**Lyft** (with weather conditions)","1d8ba96c":"From the frequency plot, we could almost all the car models are used in similar frequency.","f85d6bb1":"**Uber**","0e664d13":"**Cab type vs Surge multiplier**","9dab22f5":"### Feature transformation","0b8eb1c4":"**Xg Boosting**","df350120":"**Uber**","775cbead":"**Price and Name**","d79868e8":"### 2. Backward Elimination","9882ad59":"**Lyft** (with weather conditions)","e35c7d7c":"### 3. Step Forward Selection","1bcdfdfa":"**Continuous & Continuous**","bf7de1ea":"## Atrribute information","0d45d95a":"Distance is one of the important factors, which drives the price of the rides.  We could see that there is a positive \ncorrelation in the graph, with the presence of outliers as we saw before, because of the use of luxury car models and \nbad weather conditions.","d5acb9a6":"## Feature Selection","c2e293da":"**Uber** (with weather conditions)","4c27795a":"### 2. Ridge","00b4ea44":"We can see that, the surge multiplier doesn't vary for different car models in Lyft, except for few exceptions\nin Lyft XL, which is a high-end car services of Lyft.","a18b3336":"## Univariate analysis","bfe44c9d":"**Uber**","77dd6af8":"**Outliers handling**","c5824926":"From the correlation, we can see distance is moderately correlated,           \nfollowed by pressure, hour and wind. (we can ignore surge multiplier, as it leaks info about price.)          \nRain and temperature are not significant.","cb0bf4ed":"**Lyft results**","0ada5f2d":"**Destination**","b2584da7":"### 4. Lasso","03c70a76":"Let's check the missing values are occuring at random.","74f69510":"**Continuous**","7ac0b253":"**KNN taking long time, so dropping the model.**","b339e5cc":"Cat boost was designed to handle categorical values in the data automatically, it prevents overfitting, and has less prediction \ntime, because it builds symmetric trees.","020f9c53":"### Feature category        \n**Categorical**       \n    - Cab type\n    - Destination\n    - Source\n    - Product Id\n    - Name\n    - Id\n    - Surge Multiplier\n    \n**Continuous**     \n    - Distance\n    - Time stamp\n    - Price","4c7fead6":"**Hyperparameter Tuning**","137dede2":"The price distribution is right skewed, from the boxplot we could see the outliers present in the data.         \nOn average, the price range varies from 5 to 40 US dollars,           \nPresence of outliers is due to factors such as use of luxury or premium cars for rides, travelling in high traffic city \nand bad weather conditions.","fa348364":"**One Hot encoding**","961719f1":"### 3. Lasso","3b10ab82":"The missing values are present in the price (target) column.","b51a8d58":"**Category**","6960d8eb":"**Uber base model**","078da5f3":"**Uber results**","03263e8c":"The dataset contains relatively high proportion of Uber data, with both having records more than 300,000 data points.","2a6232f6":"**Categorical & Continuous**","0d876923":"**Cab type**","ad910d76":"**Cab type vs Source**","ed0a4492":"**Price (Target variable)**","6f8c8c63":"Hour has almost similar distribution for both Uber and Lyft.  This is due to fact that cab riders has the option to choose\nbetween Lyft and Uber for their customers.       \nWe can see that there is high usage in the hours from 10 to evening 7, this makes sense as this the office hours,\nwhere people likely to travel frequently.","82d0faa1":"**Source**","6531944c":"### Model Building","cd3c5df8":"**Lyft**","efe2ea8d":"**Categorical columns encoding**","b50c288f":"### Categorical & Categorical:","475c0211":"We have checked the Uber official website for different car models, and the missing values are less than 10%\nof the original data, we have decided to drop the records containing missing values in the target price feature.","f8d22b82":"**Lyft**","85b79df6":"### Continuous variables","be47ac96":"**Car model**","4c5db875":"From the above charts, we see that, there is a variety of surge mulipliers in Lyft, whereas in Uber, there is only one \nsurge multiplier.     \nThis has increased the number of riders in Uber, compared to Lyft.","9429b7af":"**HyperParameter tuning**","227d2b87":"# Objective","5dd0f0d8":"### Data Type      \n**Object**\n\n    - location\n    \n**Numeric**       \n    - temp\n    - clouds\n    - pressure\n    - rain\n    - time stamp\n    - humidity\n    - wind","77dd3190":"**Lyft** (with weather conditions)","c7c2ed7e":"# Exploratory Data Analysis","08ab4658":"We could see that all the features are significant in the Lyft model, according to the p-values.","1bc10e3d":"We can see that, the missing values are present only in the Uber data. Let's also check the car type and model.","38604c34":"**Lyft**","1652b791":"**Gradient Boosting**","cabdce3b":"**Hyperparameter Tuning**","c1fda58e":"**Dependent variables**:       \n\n    Distance - distance between source and destination             \n    Cab_type - Uber or Lyft                 \n    Time_stamp - epoch time when data was queried              \n    Destination - destination of the ride              \n    Source - the starting point of the ride              \n    Surge_multiplier - the multiplier by which price was increased, default 1              \n    Id - unique identifier              \n    Product_id - uber\/lyft identifier for cab-type              \n    Name - Visible type of the cab eg: Uber Pool, UberXL              \n\n**Target variable**:               \n\n    Price - price estimate for the ride in USD","b011bc5c":"**Humidity**","eeeb7480":"To analyze Uber and Lyft datasets.","2ee682c0":"### Data Type      \n**Object**\n\n    - Cab type\n    - Destination\n    - Source\n    - Id\n    - Product Id\n    - Name\n    \n**Numeric**       \n    - Distance\n    - Time stamp\n    - Price\n    - Surge Multiplier","e9373e56":"### Continuous & Continuous","6ba500dd":"We could see that there is null values in the data.","1c35f60a":"**Distance**","5111fc88":"Let's choose 15 as max depth","3bcb99d1":"### Univariate Analysis","3440cd1c":"**Uber**","d3b171e5":"### 4. Elastic Net","dd5d1952":"**Hyper Parameter Tuning**","1320b2c0":"### 5. KNN","6de9ad5d":"Since the data is collected within Boston city, the rain has effect on all the locations within the city,\namong those locations such as Financial District, Haymarket Square and North end have experienced high rainfall.","64402469":"### Base Model","47dc1531":"**Pressure**","cfe61b79":"**Price and Cab type**","7c5c4648":"**Uber** (with weather conditions)","e39b338f":"**Uber**","f319549b":"**Hyperparameter Tuning**","fc6c0642":"**Hyperparameter Tuning**","877b9689":"**Categorical variables**","51c0a43b":"**Cat Boost**","be042020":"**Lyft base model**","4acf8667":"**Car model vs Source**","68c7c560":"**Uber** (with weather conditions)","9f573985":"According to this website https:\/\/www.timeanddate.com\/weather\/usa\/boston\/historic?month=12&year=2018, \nthere was rain only on specific days at particular hours.     \nSo, we've decided not to remove these outliers.","807a97ba":"This table shows that, we cannot hope to go to any place within Boston city, \nAs we can see that, these destinations are within 3 miles from source. Are people in Massachussettes, choose to skip cabs \nwithin 3 miles, we need to analyze further to make any claims.","78892f58":"**Location**","5d841d18":"**Surge multiplier**","6bc13aa4":"### 5. Using VIF","43630e69":"We can see that, in the 'rain' feature 85.75 % of the data is missing. After checking the weather conditions from the \nofficial website of Boston and through observation, we can infer that,      \nThe missing values are due to unobserved input variable, that is there was no rain observed on those particular hour.        \n\nSo, we have decided to impute the missing values with zero, which denotes no rain.","8482678c":"### 5. Decision Tree","e52a31b1":"### 1. Linear Regression","58b57d8d":"### 6. Random Forest","ee7d6af6":"#### Cab rides dataset","361fc850":"**Car model vs Surge multiplier**","609789cf":"**Product Id**","90c0bb49":"    - temp\n    - time stamp\n    - clouds\n    - pressure\n    - rain\n    - humidity\n    - wind","83310a43":"**Weather dataset**","27ad7c06":"**Lyft**","25feb94d":"### Bi-variate analysis","5e63cbe9":"From the correlation, we can see distance is moderately correlated,           \nfollowed by pressure, hour and wind.          \nRain and clouds are not significant.","e8b20a5b":"**Wind**","4e9ad714":"## Bi-variate Analysis","22198d57":"### Hypothesis Testing","03c4a969":"**HyperParameterTuning**","6b0b5286":"**Lyft** (with weather conditions)","1b8378b7":"**Select Features**","a3173d56":"From the above graphs, we can see that most of the rides are in the range of approximately 0.5 to 5.5 miles. \nThe distribution is slightly right skewed in the both Lyft and Uber.\nDistance in Lyft is more dispersed than Uber.           \nBoth the data contains outliers, due to certain weather conditions riders have to travel extra distance than usual,\nand occassionally riders tend to travel long distances.","1511320d":"**Temperature**","ec6abf98":"**Clouds**","c907d6c6":"#### Scaling","992f79eb":"**Attribute Information**\n\nLocation - Location name              \nClouds              \nPressure - pressure in mb              \nRain - rain in inches for the last hr              \nTime_stamp - epoch time when row data was collected              \nHumidity - humidity in %              \nWind - wind speed in mph","c5c965be":"**Lyft**","8cbb8aee":"## Weather dataset","d6c0741c":"According to this website https:\/\/www.timeanddate.com\/weather\/usa\/boston\/historic?month=12&year=2018,\nthe data is legitimate. We can keep the outliers.","81b53033":"Temperature is slighty left skewed, and it makes sense, because this data is collected around the month of november,\nalthough occassionally we can see high temperature as well in locations such as Financial district, Boston university\nand Back bay.","86fea613":"**Hour**","ade905f0":"**Ada Boost**","b9cf1a23":"**Uber** (with weather conditions)","4ea9a542":"**Cab type vs Destination**","f942d9b5":"**Rain**","d7ba556c":"**Uber**","353b7d49":"**Uber**","92d62924":"**Uber**","e7d8d499":"**Outliers**       \nThese outliers are due to use of high-end cars and high surge multipliers. So, we decided to keep it.","8d85ae0f":"### 1. Correlation","41a1621d":"### 7. Boosting","cbe8e6a0":"**Label Encoding**","36c9c3a1":"**Source vs Destination**","dc54c6b8":"**Lyft**","244e211c":"Rain is right skewed, it is understandable as this data is collected for 17 days, only in few days, there was rain\nin Boston city.","fbb28c74":"**Lyft**","170d12b0":"We could see that Wind doesn't have significant impact on the price column.","cb410830":"**Price and Destination**","fd0b8792":"Weather data doesn't have records for this particular dates and hours, let's impute these values with the previous values.","92edff6b":"**HyperParameter Tuning**","928e71f0":"**Lyft**","1e1d4726":"**Price and Source**"}}