{"cell_type":{"97f4714b":"code","10779998":"code","79ce216f":"code","d42ba80a":"code","88fb1f43":"code","3293ce33":"code","393cc16d":"code","09338dfd":"code","0aec8b7d":"code","2672e3d7":"code","ada91a1a":"code","0217081b":"code","9c57453a":"code","71cd4ade":"code","0d8860cd":"code","8c29b4ca":"code","3fff7c4e":"code","2cc6a216":"code","1873ab44":"code","02161c4f":"code","10bc5dfb":"code","15ac9cfe":"code","36cb39e4":"code","1b640da9":"code","32cb4063":"code","94daea55":"code","89592716":"code","61f82662":"code","75c7cd56":"code","05539191":"code","3db7ca40":"code","d4035b04":"code","177168e7":"code","f98abbcd":"markdown","e6e03fc7":"markdown","666bccc7":"markdown","16c14e01":"markdown","1c0085a0":"markdown","dd76b657":"markdown","fa461f46":"markdown","c2bdfa67":"markdown","9ea13fd6":"markdown","3b6dec63":"markdown","43b9e864":"markdown","fa0e31ef":"markdown","c49a4f81":"markdown","ff16a528":"markdown","6159bccf":"markdown","aefbf428":"markdown","a2f96178":"markdown","f5b93903":"markdown","2c71c3d1":"markdown","ac97ea5c":"markdown","c733db08":"markdown","b0d36fe6":"markdown"},"source":{"97f4714b":"!nvidia-smi\n!pip install gdown\n!pip install tensorflow_text\n!pip install wordcloud\n!pip install tensorflow-gpu\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nfrom sklearn.model_selection import train_test_split\nimport tensorflow_hub as hub\nimport tensorflow_text\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.metrics import confusion_matrix\n%matplotlib inline\n!pip install --upgrade pip\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport numpy as np\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\n! pip install -q scikit-plot\nimport scikitplot as skplt\nimport pickle\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[]})\n\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\ntf.test.is_gpu_available()","10779998":"rcParams['figure.figsize'] = 12, 8\ndf = pd.read_csv('..\/input\/covid19-labeled-tweets\/COVID-19 labeled tweets.csv')\nprint(df.shape)\nprint(df.head())\n\nprint(df.label.value_counts())\nsns.countplot(\n  x='label',\n  data=df,\n  order=df.label.value_counts().index\n)\n\nplt.xlabel(\"type\")\nplt.title(\"Tweet type\");\n\n\npositive_tweets = df[df.label == \"positive\"]\nnegative_tweets = df[df.label == \"negative\"]\nneutral_tweets = df[df.label == \"neutral\"]\n\n\nprint(positive_tweets.shape, negative_tweets.shape, neutral_tweets.shape)\n\npos_df = positive_tweets\nneg_df = negative_tweets\nneu_df = neutral_tweets\ntweet_df = pos_df.append(neg_df).append(neu_df).reset_index(drop=True)\nprint(tweet_df.shape)\nprint(tweet_df.head())","79ce216f":"tweet_df.head()","d42ba80a":"use = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder-multilingual-large\/3\")\nsent_1 = [\"My Name is Sakib\"] \nsent_2 = [\"amazing location\"]\n\nemb_1 = use(sent_1)\nemb_2 = use(sent_2) \nprint(emb_1.shape) \nnp.inner(emb_1, emb_2).flatten()[0]","88fb1f43":"from sklearn.preprocessing import OneHotEncoder\n\ntype_one_hot = OneHotEncoder(sparse=False).fit_transform(\n  tweet_df.label.to_numpy().reshape(-1, 1)\n)\n\nprint(tweet_df)\ntrain_tweets, test_tweets, y_train, y_test =\\\n  train_test_split(\n    tweet_df.text, \n    type_one_hot, \n    test_size=.2, \n    random_state=RANDOM_SEED\n  )\n\nX_train = []\nfor r in tqdm(train_tweets):\n  emb = use(r)\n  tweet_emb = tf.reshape(emb, [-1]).numpy()\n  X_train.append(tweet_emb)\n\nX_train = np.array(X_train)\n\nX_test = []\nfor r in tqdm(test_tweets):\n  emb = use(r)\n  tweet_emb = tf.reshape(emb, [-1]).numpy()\n  X_test.append(tweet_emb)\n\nX_test = np.array(X_test)\nprint(X_train.shape, X_test.shape)\nprint()\nprint(X_train.shape, y_train.shape)","3293ce33":"from matplotlib import pyplot\nfrom imblearn.over_sampling import ADASYN\nfrom collections import Counter\noversample = ADASYN()\nX_train, y_train = oversample.fit_resample(X_train, y_train)\nX_test, y_test = oversample.fit_resample(X_test, y_test)","393cc16d":"# METRICS = [\n#       keras.metrics.TruePositives(name='tp'),\n#       keras.metrics.FalsePositives(name='fp'),\n#       keras.metrics.TrueNegatives(name='tn'),\n#       keras.metrics.FalseNegatives(name='fn'), \n#       keras.metrics.CategoricalAccuracy(name='accuracy'),\n#       keras.metrics.Precision(name='precision'),\n#       keras.metrics.Recall(name='recall'),\n#       keras.metrics.AUC(name='auc'),\n# ]\n# from imblearn.over_sampling import SMOTE\n\n# # sm = SMOTE('not majority')\n# # X_train, y_train = sm.fit_sample(X_train, y_train)\n# print(X_train.shape, y_train.shape)\n# gggg = pd.DataFrame(y_train)\n# gggg.columns = ['negative', 'neutral','positive']\n\n# print(f\"Negative: {gggg.negative.value_counts()[1]} \\nNeutral: {gggg.neutral.value_counts()[1]} \\nPositive: {gggg.positive.value_counts()[1]}\")\n# ggggg = pd.melt(gggg)\n# sns.countplot(data=ggggg.loc[ggggg['value']!=0], x='variable')","09338dfd":"# model = keras.Sequential()\n\n# model.add(\n#   keras.layers.Dense(\n#     units=256,\n#     input_shape=(X_train.shape[1], ),\n#     activation='relu'\n#   )\n# )\n# model.add(\n#   keras.layers.Dropout(rate=0.5)\n# )\n\n# model.add(\n#   keras.layers.Dense(\n#     units=128,\n#     activation='relu'\n#   )\n# )\n# model.add(\n#   keras.layers.Dropout(rate=0.5)\n# )\n\n# model.add(\n#   keras.layers.Dense(\n#     units=128,\n#     activation='relu'\n#   )\n# )\n# model.add(\n#   keras.layers.Dropout(rate=0.5)\n# )\n\n# model.add(keras.layers.Dense(3, activation='softmax'))\n# model.compile(\n#     loss='categorical_crossentropy', \n#     optimizer=keras.optimizers.Adam(0.001),\n#     #metrics=['accuracy']\n#     metrics=METRICS\n# )\n\n# EPOCHS = 120\n# BATCH_SIZE = 512\n\n# early_stopping = tf.keras.callbacks.EarlyStopping(\n#     monitor='val_auc', \n#     verbose=1,\n#     patience=10,\n#     mode='max',\n#     restore_best_weights=True)\n\n# history = model.fit(\n#     X_train, y_train, \n#     epochs=EPOCHS, \n#     batch_size=BATCH_SIZE, \n#     validation_split=0.1, \n#     verbose=1, \n#     callbacks = [early_stopping],\n#     shuffle=True\n# )\n\n# def plot_metrics(history):\n#   metrics = ['loss', 'auc', 'precision', 'recall']\n#   for n, metric in enumerate(metrics):\n#       name = metric.replace(\"_\",\" \").capitalize()\n#       plt.subplot(2,2,n+1)\n#       plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n#       plt.plot(history.epoch, history.history['val_'+metric], color=colors[0], linestyle=\"--\", label='Val')\n#       plt.xlabel('Epoch')\n#       plt.ylabel(name)\n#       if metric == 'loss':\n#         plt.ylim([0, plt.ylim()[1]])\n#       elif metric == 'auc':\n#         plt.ylim([0.8,1])\n#       else:\n#         plt.ylim([0,1])\n\n#       plt.legend()\n\n# plt.plot(history.history['loss'], label='train loss')\n# plt.plot(history.history['val_loss'], label='val loss')\n# plt.xlabel(\"epoch\")\n# plt.ylabel(\"Cross-entropy loss\")\n# plt.legend();\n\n# plt.plot(history.history['accuracy'], label='train accuracy')\n# plt.plot(history.history['val_accuracy'], label='val accuracy')\n# plt.xlabel(\"epoch\")\n# plt.ylabel(\"accuracy\")\n# plt.legend();\n# plot_metrics(history)\n\n# print(model.evaluate(X_test, y_test))\n\n# train_predictions_baseline = model.predict(X_train, batch_size=BATCH_SIZE)\n# test_predictions_baseline = model.predict(X_test, batch_size=BATCH_SIZE)\n\n# def plot_cm(labels, predictions, p=0.5):\n#   cm = confusion_matrix(labels, predictions)\n#   plt.figure(figsize=(5,5))\n#   sns.heatmap(cm, annot=True, fmt=\"d\")\n#   plt.title('Confusion matrix @{:.2f}'.format(p))\n#   plt.ylabel('Actual label')\n#   plt.xlabel('Predicted label')\n\n#   print('(True Negatives): ', cm[0][0])\n#   print('(False Positives): ', cm[0][1])\n#   print('(False Negatives): ', cm[1][0])\n#   print('(True Positives): ', cm[1][1])\n#   print('Total : ', np.sum(cm[1]))\n","0aec8b7d":"# baseline_results = model.evaluate(X_test, y_test,batch_size=BATCH_SIZE, verbose=0)\n\n# for name, value in zip(model.metrics_names, baseline_results):\n#   print(name, ': ', value)\n# print()\n\n# plot_cm(y_train.argmax(axis=1), train_predictions_baseline.argmax(axis=1))\n# plot_cm(y_test.argmax(axis=1), test_predictions_baseline.argmax(axis=1))","2672e3d7":"# baseline_results = model.evaluate(X_test, y_test,batch_size=BATCH_SIZE, verbose=0)\n# for name, value in zip(model.metrics_names, baseline_results):\n#   if(name=='accuracy'):\n#     dnn_acc_test=value\n#   elif(name=='precision'):\n#     dnn_precision_test=value\n#   elif(name=='recall'):\n#     dnn_recall_test=value\n#   print(name, ': ', value)\n# dnn_f1score_test=(2*dnn_precision_test*dnn_recall_test)\/(dnn_recall_test+dnn_precision_test)\n\n# print()\n# print()\n# baseline_results = model.evaluate(X_train, y_train,batch_size=BATCH_SIZE, verbose=0)\n\n# for name, value in zip(model.metrics_names, baseline_results):\n#   if(name=='accuracy'):\n#     dnn_acc_train=value\n#   elif(name=='precision'):\n#     dnn_precision_train=value\n#   elif(name=='recall'):\n#     dnn_recall_train=value\n#   print(name, ': ', value)\n# dnn_f1score_train = (2*dnn_precision_train*dnn_recall_train)\/(dnn_recall_train+dnn_precision_train)\n\n# r = evaluation.shape[0]\n# evaluation.loc[r] = ['RF',dnn_acc_train,dnn_precision_train,dnn_recall_train,dnn_f1score_train,dnn_acc_test,dnn_precision_test,dnn_recall_test,dnn_f1score_test]\n# evaluation","ada91a1a":"# import sklearn\n# def plot_roc(name, labels, predictions, **kwargs):\n#   fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n#   plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n#   plt.xlabel('False positives [%]')\n#   plt.ylabel('True positives [%]')\n#   plt.xlim([-0.5,20])\n#   plt.ylim([80,100.5])\n#   plt.grid(True)\n#   ax = plt.gca()\n#   ax.set_aspect('equal')\n# import sklearn\n# from scipy import interp\n# from itertools import cycle\n# def plot_roc(name, labels, predictions, **kwargs):\n#   fpr = dict()\n#   fpr = dict()\n#   tpr = dict()\n#   roc_auc = dict()\n#   lw = 2\n#   n_classes = labels.shape[1]\n#   for i in range(n_classes):\n#     fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(labels[:, i], predictions[:, i])\n#     roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n#   # Compute micro-average ROC curve and ROC area\n#   fpr[\"micro\"], tpr[\"micro\"], _ = sklearn.metrics.roc_curve(labels.ravel(), predictions.ravel())\n#   roc_auc[\"micro\"] = sklearn.metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\n#   # First aggregate all false positive rates\n#   all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n#   # Then interpolate all ROC curves at this points\n#   mean_tpr = np.zeros_like(all_fpr)\n#   for i in range(n_classes):\n#       mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n#   # Finally average it and compute AUC\n#   mean_tpr \/= n_classes\n\n#   fpr[\"macro\"] = all_fpr\n#   tpr[\"macro\"] = mean_tpr\n#   roc_auc[\"macro\"] = sklearn.metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n\n#   # Plot all ROC curves\n#   plt.figure()\n#   plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n#          label='micro-average ROC curve (area = {0:0.2f})'\n#                ''.format(roc_auc[\"micro\"]),\n#          color='deeppink', linestyle=':', linewidth=4)\n\n#   plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n#          label='macro-average ROC curve (area = {0:0.2f})'\n#                ''.format(roc_auc[\"macro\"]),\n#          color='navy', linestyle=':', linewidth=4)\n\n#   colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n#   class_label = ['negative','neutral', 'positive']\n#   for i, color in zip(range(n_classes), colors):\n#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n#              label='ROC curve of class {0} (area = {1:0.2f})'\n#              ''.format(class_label[i], roc_auc[i]))\n\n#   plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n#   plt.xlim([0.0, 1.0])\n#   plt.ylim([0.0, 1.05])\n#   plt.xlabel('False Positive Rate')\n#   plt.ylabel('True Positive Rate')\n#   plt.title('Some extension of Receiver Operating Characteristic to multi-class')\n#   plt.legend(loc=\"lower right\")\n#   plt.show()\n# plot_roc(\"Train Baseline\", y_train, train_predictions_baseline, color=colors[0])\n# plot_roc(\"Test Baseline\", y_test, test_predictions_baseline, color=colors[0], linestyle='--')\n# # plt.legend(loc='lower right')","0217081b":"# print(test_tweets.iloc[0])\n# print(\"negative\" if y_test[0][0] == 1 else (\"neutral\" if y_test[0][1] == 1 else \"positive\"))\n# print(y_test[0])\n# y_pred = model.predict(X_test[:1])\n# print(y_pred)\n# print(np.argmax(y_pred))\n# \"negative\" if np.argmax(y_pred) == 0 else (\"neutral\" if np.argmax(y_pred) == 1 else \"positive\")\n# print(test_tweets.iloc[1])\n# print(y_test[1])\n# print(\"negative\" if y_test[1][0] == 1 else (\"neutral\" if y_test[1][1] == 1 else \"positive\"))\n\n# y_pred = model.predict(X_test[1:2])\n# print(y_pred)\n# \"negative\" if np.argmax(y_pred) == 0 else (\"neutral\" if np.argmax(y_pred) == 1 else \"positive\")\n\n# print(test_tweets.iloc[5])\n# print(\"negative\" if y_test[5][0] == 1 else (\"neutral\" if y_test[5][1] == 1 else \"positive\"))\n\n# y_pred = model.predict(X_test[5:6])\n# print(y_pred)\n# \"negative\" if np.argmax(y_pred) == 0 else (\"neutral\" if np.argmax(y_pred) == 1 else \"positive\")\n\n# test_str = \"hello i am Mahbub\"\n# #y_pred = model.predict([[np.array(tf.reshape(use(test_str), [-1]).numpy())]])\n# y_pred = model.predict(use(test_str))\n# print(y_pred)\n# \"negative\" if np.argmax(y_pred) == 0 else (\"neutral\" if np.argmax(y_pred) == 1 else \"positive\")\n\n# # save model\n# model.save(\"saved_model.h5\")\n# print(\"Saved model\")\n\n# # load model\n# import tensorflow as tf \n# model = tf.keras.models.load_model('saved_model.h5')\n# model.summary()\n\n# r = evaluation.shape[0]\n# evaluation.loc[r] = ['DNN',dnn_acc_train,dnn_precision_train,dnn_recall_train,dnn_f1score_train,dnn_acc_test,dnn_precision_test,dnn_recall_test,dnn_f1score_test]\n# evaluation","9c57453a":"df = tweet_df\ndf[\"label\"] = df[\"label\"].astype('category')\ndf['label']=df['label'].cat.codes\ndf[\"label\"]=df[\"label\"].astype('float')","71cd4ade":"from sklearn.preprocessing import OneHotEncoder\ntype_one_hot = tweet_df['label']\n\nprint(tweet_df)\ntrain_tweets, test_tweets, y_train, y_test =\\\n  train_test_split(\n    tweet_df.text, \n    type_one_hot, \n    test_size=.1, \n    random_state=RANDOM_SEED\n  )\n\nX_train = []\nfor r in tqdm(train_tweets):\n  emb = use(r)\n  tweet_emb = tf.reshape(emb, [-1]).numpy()\n  X_train.append(tweet_emb)\n\nX_train = np.array(X_train)\n\nX_test = []\nfor r in tqdm(test_tweets):\n  emb = use(r)\n  tweet_emb = tf.reshape(emb, [-1]).numpy()\n  X_test.append(tweet_emb)\n\nX_test = np.array(X_test)\nprint(X_train.shape, X_test.shape)\nprint()\nprint(X_train.shape, y_train.shape)\noversample = ADASYN()\nX_train, y_train = oversample.fit_resample(X_train, y_train)\nX_test, y_test = oversample.fit_resample(X_test, y_test)","0d8860cd":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\n\nbase =RandomForestClassifier()\nclf = AdaBoostClassifier(n_estimators=100, base_estimator=base, random_state=500)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nr = evaluation.shape[0]\nevaluation.loc[r] = ['ADABOOST',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","8c29b4ca":"from scipy import interp\nfrom itertools import cycle\np=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","3fff7c4e":"from sklearn.ensemble import RandomForestClassifier\nclf =RandomForestClassifier()\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['RF',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","2cc6a216":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","1873ab44":"!pip install catboost\nfrom catboost import CatBoostClassifier\n\nclf = CatBoostClassifier(\n    iterations=1000, \n    learning_rate=0.1, \n    #verbose=5,\n    #loss_function='CrossEntropy'\n)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['CATBOOST',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","02161c4f":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","10bc5dfb":"import xgboost as xgb\nclf = xgb.XGBClassifier(random_state=700)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['XGBOOST',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","15ac9cfe":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","36cb39e4":"from sklearn import svm\nclf =svm.SVC(kernel='rbf',degree=100)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['SVM',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","1b640da9":"# MLR_y_test_prediction= model.predict(X_test)\n# np.savetxt('MLR_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\n# np.savetxt('MLR_test_actual.csv', y_test, delimiter=',', fmt='%s')","32cb4063":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","94daea55":"from sklearn.ensemble import GradientBoostingClassifier\nclf = GradientBoostingClassifier(random_state=1000, learning_rate=0.1,n_estimators=500)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['GradientBoosting',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","89592716":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","61f82662":"from sklearn.neural_network import MLPClassifier\nclf =MLPClassifier(solver='lbfgs', alpha=1e-5,\n                     hidden_layer_sizes=(16, 16), random_state=100)\n# clf =MLPClassifier()\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['ANN',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","75c7cd56":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","05539191":"from sklearn.neighbors import RadiusNeighborsClassifier\nclf = RadiusNeighborsClassifier(radius=5.0)\nclf.fit(X_train, y_train)\n\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['RadiusNeighbor Classifier',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","3db7ca40":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","d4035b04":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\n\nclf.fit(X_train, y_train)\n\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Decision Tree',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\nevaluation","177168e7":"p=y_train\nq=y_test\n# y_train=y_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_train=clf.predict(X_train)\ny_score_train = pred_train\npred_train=pd.DataFrame(pred_train)\n\n# pred_train=pred_train.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\npred_test=clf.predict(X_test)\ny_score_test = pred_test\n# y_test=y_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\npred_test=pd.DataFrame(pred_test)\n\n# pred_test=pred_test.replace([0,1,2,3], [\"B\",\"N\",\"SP\",\"TO\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(7,4),\n    title_fontsize='18',\n    text_fontsize='16',\n    title =' ',\n    cmap='BuGn'\n    )\ny_train=p\ny_test=q\n\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_train = [None] * len(y_train);    \nfor i in range(0, len(y_train)):    \n    roc_y_train[i] = y_train[i]; \n\nfrom sklearn.preprocessing import label_binarize\ny_score_train = label_binarize(y_score_train, classes=[1, 0, 2])\nroc_y_train = label_binarize(roc_y_train, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_train[:, i], y_score_train[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_train.ravel(), y_score_train.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nfrom sklearn.metrics import roc_curve, auc\nn_classes = 3\nroc_y_test = [None] * len(y_test);    \nfor i in range(0, len(y_test)):    \n    roc_y_test[i] = y_test[i]; \n    \n# y_score_test[50]=2\n# roc_y_test[50]=2\ny_test\nfrom sklearn.preprocessing import label_binarize\ny_score_test = label_binarize(y_score_test, classes=[1, 0, 2])\nroc_y_test = label_binarize(roc_y_test, classes=[1, 0, 2])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(roc_y_test[:, i], y_score_test[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(roc_y_test.ravel(), y_score_test.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr \/= n_classes\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","f98abbcd":"# Gradient Boost","e6e03fc7":"Confusion Matrix","666bccc7":"Testing User Input","16c14e01":"# DNN","1c0085a0":"# RadiusNeighborsClassifier","dd76b657":"Confusion Matrix","fa461f46":"Model","c2bdfa67":"Confusion Matrix","9ea13fd6":"Confusion Matrix","3b6dec63":"# Preprocessing","43b9e864":"# Decision Tree","fa0e31ef":"Evaluation With Confusion Matrix\n","c49a4f81":"# SVM","ff16a528":"Confusion Matrix","6159bccf":"# Adaboost","aefbf428":"# Random Forest","a2f96178":"Preprocessing","f5b93903":"# ANN\n","2c71c3d1":"ROC Curve for Traing and Testing data","ac97ea5c":"# CatBoost","c733db08":"# XgBoost","b0d36fe6":"Pre-processing for rest of the models"}}