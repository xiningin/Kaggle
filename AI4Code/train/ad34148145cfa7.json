{"cell_type":{"8f5a6e14":"code","e08d93c6":"code","fb00612d":"code","529360e9":"code","7a2a2da3":"code","9d8a9e78":"code","87032465":"code","b722d498":"code","27de2a87":"code","a7b38d3c":"code","d376b9ed":"code","34684bef":"code","78558e65":"code","b7d7c2c5":"code","96a08e99":"code","cdea8dbe":"code","1ba9cebd":"code","d994f213":"code","959c689c":"code","553c0f67":"code","83b52365":"code","5c6eb8ea":"code","068a9461":"code","568adb26":"code","ee91c0ee":"code","26fab3f9":"code","8aba2c07":"code","f1e433d7":"code","62acb3e9":"code","af364edc":"code","48ecf6b6":"code","60236c3c":"code","dc6cc803":"code","e256ccf1":"code","58f5b6a6":"code","e18b402c":"markdown","41b5f406":"markdown","9c5d62bf":"markdown","7fb059e0":"markdown","3ac191f1":"markdown","129ec451":"markdown"},"source":{"8f5a6e14":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","e08d93c6":"import os\nIS_LOCAL = False\n\nif(IS_LOCAL):\n    PATH=\"..\/input\/default-of-credit-card-clients-dataset\"\nelse:\n    PATH=\"..\/input\"\nprint(os.listdir(PATH))\n\ndata=pd.read_csv(PATH+\"\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv\")","fb00612d":"data.head()","529360e9":"data.drop(['ID'],axis=1,inplace=True)","7a2a2da3":"data.rename(columns=lambda x:x.lower(),inplace=True)","9d8a9e78":"data.rename(columns={'default.payment.next.month':'default'},inplace=True)","87032465":"print(data.default.value_counts().index[0],(data.default.value_counts()[0]\/len(data)*100),data.default.value_counts().index[1],(data.default.value_counts()[1]\/len(data)*100))","b722d498":"data.head()","27de2a87":"def check_count(var):\n    return(sorted(data[var].unique()))","a7b38d3c":"#check_count('sex')\n#check_count('education')\n#check_count('marriage')\ncheck_count('pay_0')","d376b9ed":"pay_features=['pay_0','pay_2','pay_3','pay_4','pay_5','pay_6']\n\nfor p in pay_features:\n    data.loc[data[p]<0,p]=0","34684bef":"check_count('pay_0')\n#check_count('pay_6')","78558e65":"def order_cat(df,col,order):\n    df[col]=df[col].astype('category')\n    df[col]=df[col].cat.reorder_categories(order,ordered=True)\n    df[col]=df[col].cat.codes.astype(int)\n\n\nfor col in pay_features:\n    order_cat(data,col,check_count(col))","b7d7c2c5":"data['grad_school']=(data['education']==1).astype('int')\ndata['university']=(data['education']==2).astype('int')\ndata['high_school']=(data['education']==3).astype('int')\ndata['others_education']=(data['education']==4).astype('int')\ndata['unknown_education']=(~data['education'].isin([1,2,3,4])).astype('int')\n\n\ndata['male']=(data['sex']==1).astype(int)\ndata['female']=(data['sex']==0).astype(int)\n\ndata['married']=(data['marriage']==1).astype(int)\ndata['single']=(data['marriage']==2).astype(int)\ndata['other_marriage']=(~data['marriage'].isin([1,2])).astype(int)","96a08e99":"data.drop(['sex','education','marriage'],axis=1,inplace=True)","cdea8dbe":"data.head()","1ba9cebd":"from sklearn.preprocessing import RobustScaler\n\nscaler=RobustScaler()\n\nlabel='default'\nX=data.drop(label,axis=1)\n\nfeatures=X.columns\n\nX=scaler.fit_transform(X)\ny=data[label]","d994f213":"def CFMatrix(cm,labels=['pay','default']):\n    df=pd.DataFrame(data=cm,index=labels,columns=labels)\n    df.index.name='TRUE'\n    df.columns.name='PREDICTION'\n    df.loc['Total']=df.sum()\n    df['Total']=df.sum(axis=1)\n    return df","959c689c":"from sklearn.metrics import accuracy_score,precision_score,recall_score, confusion_matrix\n\ndef predict(model,X_test,y_test):\n    \n    pred=model.predict(X_test)\n    \n    acc_score=accuracy_score(y_pred=pred,y_true=y_test)\n    precision=precision_score(y_pred=pred,y_true=y_test)\n    recall=recall_score(y_pred=pred,y_true=y_test)\n\n    print('Acc Score:',acc_score)\n    print('Precission: ',precision)\n    print('Recall: ',recall)\n    \n    return CFMatrix(confusion_matrix(y_pred=pred,y_true=y_test))","553c0f67":"from sklearn.metrics import roc_auc_score,roc_curve\n\ndef plot_roc_curve(model,X_test,y_test):\n    \n    log_roc_auc=roc_auc_score(y_test,model.predict(X_test))\n    \n    fpr,tpr,thresholds=roc_curve(y_test,model.predict_proba(X_test)[:,1])\n    \n    plt.figure()\n    plt.plot(fpr,tpr,label='Logistic Regression (area = %0.2f)'%log_roc_auc)\n    plt.plot([0,1],[0,1],'r--')\n    plt.xlim([0.0,1.0])\n    plt.ylim([0.0,1.05])\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Posiive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return","83b52365":"from sklearn.metrics import precision_recall_curve\n\ndef recall_to_precision(model,X_test,y_test):\n    precision_p,recall_p,thresholds=precision_recall_curve(y_true=y_test,probas_pred=model.predict_proba(X_test)[:,1])\n\n    fig,ax=plt.subplots(figsize=(8,5))\n\n    ax.plot(thresholds,precision_p[1:],label='Precision')\n    ax.plot(thresholds,recall_p[1:],label='Recall')\n\n    ax.set_xlabel('Classification Threshold')\n    ax.set_ylabel('Precision, Recall')\n    ax.set_title('Logistic Regression Classifier: Precision-Recall')\n    ax.hlines(y=0.6,xmin=0,xmax=1,color='red')\n    ax.legend()\n    ax.grid();\n    return","5c6eb8ea":"def predict_threshold(model,X_test,y_test,threshold):\n    pred_02_prob=model.predict_proba(X_test)[:,1]\n\n    pred_02= (pred_02_prob >= threshold).astype('int')\n\n    acc_score=accuracy_score(y_pred=pred_02,y_true=y_test)\n    precision=precision_score(y_pred=pred_02,y_true=y_test)\n    recall=recall_score(y_pred=pred_02,y_true=y_test)\n\n    print('Acc Score:',acc_score)\n    print('Precission: ',precision)\n    print('Recall: ',recall)\n\n    return CFMatrix(confusion_matrix(y_pred=pred_02,y_true=y_test))","068a9461":"def plot_feature_imp(model,features):\n    \n    df=pd.DataFrame({'features':features.tolist(),'relation':model.coef_.reshape(X_train.shape[1]).tolist()})\n    df=df.sort_values(by='relation',ascending=False)\n    \n    p_pos= np.arange(len(df.loc[df['relation']>=0,'relation']))\n    n_pos= np.arange(len(p_pos),len(p_pos)+len(df.loc[df['relation']<0,'relation']))\n    \n    plt.figure(figsize=(13,16))\n    plt.barh(p_pos,df.loc[df['relation']>=0,'relation'])\n    plt.barh(n_pos,df.loc[df['relation']<0,'relation'])\n    plt.yticks(np.arange(len(p_pos)+len(n_pos)),df['features'].tolist())\n    plt.title('Feature Coefficents with respect to Label')\n    plt.show()\n    return","568adb26":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=99,stratify=y)\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel= LogisticRegression(random_state=0)\n\nmodel.fit(X_train,y_train)\n\npredict(model,X_test,y_test)\n","ee91c0ee":"plot_roc_curve(model,X_test,y_test)","26fab3f9":"recall_to_precision(model,X_test,y_test)","8aba2c07":"predict_threshold(model,X_test,y_test,0.2)","f1e433d7":"plot_feature_imp(model,features)","62acb3e9":"#dual=[True,False]\nmax_iter=[100,110,120,130,140]\npenalty=['l1','l2']\n#C=np.logspace(-4,4,20)\nclass_weight=['balanced']\nsolver=['saga']\n\n#param_grid=dict(dual=dual,max_iter=max_iter,penalty=penalty,C=C,class_weight=class_weight,solver=solver)\nparam_grid=dict(max_iter=max_iter,penalty=penalty,class_weight=class_weight,solver=solver)","af364edc":"from sklearn.model_selection import GridSearchCV\n\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,cv=4,n_jobs=-1)\ngrid.fit(X_train,y_train)","48ecf6b6":"tuned_model=grid.best_estimator_\ntuned_model","60236c3c":"predict(tuned_model,X_test,y_test)","dc6cc803":"plot_roc_curve(tuned_model,X_test,y_test)","e256ccf1":"recall_to_precision(tuned_model,X_test,y_test)","58f5b6a6":"plot_feature_imp(tuned_model,features)","e18b402c":"## Normal Model","41b5f406":"### So from graph we can see with threshold of 0.2 we can can get Recall of 60%. \n### So lets now predict the test data with threshold of 0.2.","9c5d62bf":"### ROC curve shows 0.64 for AUC score.\n### But we want ot minimize the False Negative rate with respect to True positive, because we don't wan't to classify any person who is potential defaulter to be classified as non-defaulter. We can tolerate with some False Positive cases i.e. Non defaulters classified as defaulters. So we require high Recall rate, so lets compare the model to find true positive with respect to false positive rate.","7fb059e0":"## Feature Importance:","3ac191f1":"## Hyper-Parameter Tuning","129ec451":"## Predicted with 80% accuracy on the previous months credit card data wether a person will default in his upcoming month payment or not. Used Logistic regression with hyper-parameter tunning to find the best fit model and important features which matters most in default payment."}}