{"cell_type":{"a1aab228":"code","fda18cbc":"code","2b7c47a0":"code","17d86a77":"code","d77ffbeb":"code","f3b0ecb5":"code","ca4c8e49":"code","d72fb67b":"code","3ceeb656":"code","6f3160a8":"code","3763aa52":"code","3fcd515e":"code","17370532":"code","05911a03":"code","7dfe1ac9":"code","7df549bf":"code","55d4be63":"code","516538e0":"markdown","3cbe1f07":"markdown","5a1d09f0":"markdown","7ec45376":"markdown","3f774b2c":"markdown","a51411b8":"markdown","cd46bc0e":"markdown","4b3ff45b":"markdown","c7c27911":"markdown","a62ed559":"markdown","25e7f202":"markdown","3f937049":"markdown"},"source":{"a1aab228":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))","fda18cbc":"DATA = '..\/input'\nLABELS='train.csv'\nTRAIN = os.path.join(DATA, 'train')\nTEST = os.path.join(DATA, 'test')","2b7c47a0":"train_paths = [os.path.join(TRAIN,img) for img in os.listdir(TRAIN)]\ntest_paths = [os.path.join(TEST,img) for img in os.listdir(TEST)]","17d86a77":"import cv2\n#read image\nimg=cv2.imread(train_paths[5])\nblurred = cv2.GaussianBlur(img, (7,7), 0) # Remove noise\nplt.imshow(blurred)","d77ffbeb":"#close the small line gaps using errosion\nkernel = np.ones((3,3), np.uint8)\nerode = cv2.erode(blurred, kernel, iterations = 3)\nplt.imshow(erode)","f3b0ecb5":"#cannyedge \ndef canny_edge_detector(input_img, threshold1, threshold2, draw=True, save=True):\n    canny_img = cv2.cvtColor(np.copy(input_img), cv2.COLOR_BGR2GRAY)\n    edges = cv2.Canny(canny_img, threshold1, threshold2)\n    return edges","ca4c8e49":"#try adding Eroding before edge detection(increase black lines)\ncanny_edges = canny_edge_detector(input_img=erode, threshold1=100, threshold2=150) \nplt.imshow(canny_edges)","d72fb67b":"#close the small line gaps using dilation\nkernel = np.ones((5,5), np.uint8)\ndilation_canny = cv2.dilate(canny_edges, kernel, iterations = 3)\ncanny_blurred = cv2.GaussianBlur(dilation_canny, (3,3), 0) # Remove noise\nplt.imshow(canny_blurred)","3ceeb656":"from skimage import measure\nfrom shapely.geometry import Polygon,Point\nmin_contour_size = canny_blurred.size * 5 \/ 100\nprint(\"min size:\"+str(min_contour_size))","6f3160a8":"#box=(x0,y0,x1,t1)\ndef calc_box_size(box):\n    box_width=box[2]-box[0]\n    box_hight=box[3]-box[1]\n    box_area=box_width*box_hight\n    return box_area\n\ndef bounding_rectangle(polygon):\n  x0=min(polygon[:, 1])\n  y0=min(polygon[:, 0])\n  x1=max(polygon[:, 1])\n  y1=max(polygon[:, 0])\n  return x0,y0,x1,y1\n\ndef find_max_contour(image):\n  contours = measure.find_contours(image.copy(), 0.8)\n  max_area=0\n  max_x=0\n  max_y=0\n  min_x=image.shape[0]\n  min_y=image.shape[1]\n  #get def_box\n  for n, contour in enumerate(contours):\n    contour[:, 1], contour[:, 0]\n    max_c_x=max(contour[:, 1])\n    max_c_y=max(contour[:, 0])\n    min_c_x=min(contour[:, 1])\n    min_c_y=min(contour[:, 0])\n    if max_c_x>max_x:\n      max_x=max_c_x\n    if max_c_y>max_y:\n      max_y=max_c_y\n    if min_c_x<min_x:\n      min_x=min_c_x\n    if min_c_y<min_y:\n      min_y=min_c_y\n    \n  def_box=(min_x,min_y,max_x,max_y)\n  max_contour=None\n  for n, contour in enumerate(contours):\n    if contour.shape[0]<3: continue\n    box=bounding_rectangle(contour)    \n    box_size=calc_box_size(box)\n\n    if max_contour is None:\n      max_contour=contour\n      max_area=box_size\n    if box_size>max_area:\n      max_contour=contour\n      max_area=box_size\n  return max_contour,max_area,def_box","3763aa52":"contour,area,def_box=find_max_contour(canny_blurred) \nplt.imshow(img)\nplt.plot(contour[:, 1], contour[:, 0], linewidth=1)","3fcd515e":"import matplotlib.patches as patches\nbox=bounding_rectangle(contour)\nplt.imshow(img)\nplt.plot(contour[:, 1], contour[:, 0], linewidth=1)\n# Get the current reference\nax = plt.gca()\n# Create a Rectangle patch\nrect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=1,edgecolor='r',facecolor='none')\n# Add the patch to the Axes\nax.add_patch(rect)\ndef_rect = patches.Rectangle((def_box[0],def_box[1]),def_box[2]-def_box[0],def_box[3]-def_box[1],linewidth=1,edgecolor='g',facecolor='none')\n# Add the patch to the Axes\nax.add_patch(def_rect)\ndef_box","17370532":"def get_box_center(box):\n    #box polygon\n    x0=box[0]\n    y0=box[1]\n    x1=box[2]\n    y1=box[3]\n    x2=x1\n    y2=y0\n    x3=x0\n    y3=y1\n    in_box=[[x0,y0],[x1,y1],[x2,y2],[x3,y3]]\n    polygon_box = Polygon(in_box)\n    box_centr=polygon_box.centroid.coords\n    return box_centr\n\ndef get_serrounding_box_for_p(point,img_width,img_high,margin=0.2):\n    x0=point[0]-margin*img_width\n    y0=point[1]-margin*img_high\n    x1=point[0]+margin*img_width\n    y1=point[1]+margin*img_high\n    return (x0,y0,x1,y1)\n\n    \ndef validate_bb(image, box):\n    if box is None:\n        return False\n    #check min size\n    box_area=calc_box_size(box)\n    min_contour_size = image.size * 5 \/ 100\n    if box_area<min_contour_size:\n        return False\n    \n    #box polygon\n    box_centr=get_box_center(box)[0]\n    \n    #default polygon\n    img_centr=get_box_center((0,0,image.shape[1],image.shape[0]))[0]\n    srr_box=get_serrounding_box_for_p(img_centr,image.shape[1],image.shape[0],margin=0.2)\n    \n    #check box centered\n    if  box_centr[0]>srr_box[0] and box_centr[0]< srr_box[2] and box_centr[1]>srr_box[1] and box_centr[1]<srr_box[3]:\n        return True\n    \n    return False\n\nprint(validate_bb(img,box))","05911a03":"#get BB coordinates\ndef get_whale_bb(image_path):\n    img=cv2.imread(image_path)\n    blurred = cv2.GaussianBlur(img, (7,7), 0) # Remove noise\n    kernel = np.ones((3,3), np.uint8) \n    erode = cv2.erode(blurred, kernel, iterations = 3)\n    \n    ##find edges\n    canny_edges = canny_edge_detector(input_img=erode, threshold1=100, threshold2=150)   \n    kernel = np.ones((5,5), np.uint8)\n    dilation_canny = cv2.dilate(canny_edges, kernel, iterations = 3)#close the small line gaps using dilation\n    canny_blurred = cv2.GaussianBlur(dilation_canny, (3,3), 0) # Remove noise\n    \n    ##find contour\n    contour,area,def_box=find_max_contour(canny_blurred)\n    \n    ##find bb\n    box=None\n    if contour is not None:\n        box=bounding_rectangle(contour)\n        #check that box is not none, more than min size, with centroid in the center of image\n        valid=validate_bb(img, box)\n        if valid:\n            return box\n    \n    valid=validate_bb(img, def_box)\n    if valid:\n        return def_box\n    return None","7dfe1ac9":"bb_train = pd.DataFrame(columns=['image','x0','y0','x1','y1'])\nfor i in range(0,25):\n    img_path=train_paths[i]\n    bb=get_whale_bb(img_path)\n    if bb is None:\n        continue\n    tmpdf=pd.DataFrame([[img_path,bb[0],bb[1],bb[2],bb[3]]],columns=['image','x0','y0','x1','y1'])\n    bb_train=bb_train.append(tmpdf)\n\n#look at examples\nn=len(bb_train)\nimgs_df=bb_train[:n].reset_index()\nper_row=5\nrows=n\/\/per_row\ncols      = min(per_row, n)\nfig, axes = plt.subplots(rows,cols, figsize=(24\/\/per_row*cols,24\/\/per_row*rows))\nfor ax in axes.flatten(): \n    ax.axis('off')\nfor i,ax in enumerate(axes.flatten()): \n#     print (i)\n    image_path=imgs_df.loc[i,'image']\n    x0=float(imgs_df.loc[i,'x0'])\n    y0=float(imgs_df.loc[i,'y0'])\n    x1=float(imgs_df.loc[i,'x1'])\n    y1=float(imgs_df.loc[i,'y1'])\n    ax.imshow(cv2.imread(image_path))\n    \n    rect = patches.Rectangle((x0,y0),x1-x0,y1-y0,linewidth=1,edgecolor='r',facecolor='none')\n    ax.add_patch(rect) ","7df549bf":"#train bb \nprint(\"total train images:\"+str(len(train_paths)))\nbb_train = pd.DataFrame(columns=['image','x0','y0','x1','y1'])\nfor i in range(len(train_paths)):\n    if i%1000==0:\n        print(i)\n    img_path=train_paths[i]\n    bb=get_whale_bb(img_path)\n    if bb is None:\n        continue\n    tmpbb=pd.DataFrame([[img_path,bb[0],bb[1],bb[2],bb[3]]],columns=['Image','x0','y0','x1','y1'])\n    bb_train=bb_train.append(tmpbb)\n\nprint(\"total croped train images:\"+str(len(bb_train)))\nbb_train.to_csv('boxs_train.csv', header=True, index=False)\nprint(\"finished!\")","55d4be63":"#test bb \nprint(\"total test images:\"+str(len(train_paths)))\nbb_test = pd.DataFrame(columns=['image','x0','y0','x1','y1'])\nfor i in range(len(test_paths)):\n    if i%1000==0:\n        print(i)\n    img_path=test_paths[i]\n    bb=get_whale_bb(img_path)\n    if bb is None:\n        continue\n    tmpbb=pd.DataFrame([[img_path,bb[0],bb[1],bb[2],bb[3]]],columns=['Image','x0','y0','x1','y1'])\n    bb_test=bb_test.append(tmpbb)\n\nprint(\"total croped test images:\"+str(len(bb_test)))\nbb_test.to_csv('boxs_test.csv', header=True, index=False)\nprint(\"finished!\")","516538e0":"## step 2: get whale contour","3cbe1f07":"get contour with longiest contour line","5a1d09f0":"## *step 3: get bounding box*","7ec45376":"Erossion: A kernel(a matrix of odd size(3,5,7) is convolved with the image.  \nA pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).  \nThus all the pixels near boundary will be discarded depending upon the size of kernel.  \nSo the thickness or size of the foreground object decreases or simply white region decreases in the image.  ","3f774b2c":"dilation: A kernel(a matrix of odd size(3,5,7)) is convolved with the image  \nA pixel element in the original image is \u20181\u2019 if atleast one pixel under the kernel is \u20181\u2019.  \nIt increases the white region in the image or size of foreground object increases  ","a51411b8":"# Generate cropping method","cd46bc0e":"contour detection:  \nFind iso-valued contours in a 2D array for a given level value.  \nUses the \u201cmarching squares\u201d method to compute a the iso-valued contours of the input 2D array for a particular level value. Array values are linearly interpolated to provide better precision for the output contours.","4b3ff45b":"## step 1: edge detection","c7c27911":"Canny for edge detection","a62ed559":"## step 5: output bb for all test and train set to csv","25e7f202":"## step 4: validate bounding box","3f937049":"applay gaussian filter on image"}}