{"cell_type":{"2cbbc2d4":"code","03ad9b19":"code","e0400c75":"code","9f466165":"code","96c0a751":"code","b417a93f":"code","b7f754a2":"code","5eb9de26":"code","eb6792b9":"code","cc281a9f":"code","18ac7af7":"code","5cebbf3f":"code","b85fd825":"code","ebd0dadc":"code","5aa0a2c5":"code","ccd44c2b":"code","54c401f8":"code","31699bb6":"code","061f5bd5":"code","ff7e0744":"code","fb8e6aca":"code","9583e44d":"code","8c99f6c7":"code","81b4de22":"code","e1943cde":"code","8d0d1d22":"code","c5bd6247":"code","afa8b568":"code","65a2e0b2":"code","e2672a1c":"code","50b492bb":"code","f2cfe16a":"code","c49c10cd":"markdown","cf0f3170":"markdown","14018834":"markdown"},"source":{"2cbbc2d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03ad9b19":"# needed imports\nfrom matplotlib import pyplot as plt\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models,transforms, utils\nfrom torch.utils.data import random_split\nfrom torch.nn import Conv2d\nfrom torch import flatten\nfrom torch.optim import Adam\nfrom torch.nn import Linear\nfrom torch.nn import MaxPool2d\nfrom torch.nn import ReLU\nfrom torch.nn import LogSoftmax\nimport torch.nn.functional as F\nfrom torch.nn import Module\nimport torch.nn as nn\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport time\nimport torch\nimport cv2\nimport os\n","e0400c75":"#  define the configuration \nclass Config:\n    # specify image dimension\n    IMAGE_SIZE = 224\n\n    # specify ImageNet mean and standard deviation\n    #MEAN = [0.485, 0.456, 0.406]\n    #STD = [0.229, 0.224, 0.225]\n\n    # determine the device we will be using for inference\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # specify path to the ImageNet labels\n    IN_LABELS = \"ilsvrc2012_wordnet_lemmas.txt\"\n\n# initialize a config object\nconfig = Config()","9f466165":"#  define the functions \ndef plt_imshow(title, image):\n    # convert the image frame BGR to RGB color space and display it\n    image = cv2.imread(image)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #print(image.shape)\n    plt.imshow(image)\n    plt.title(title)\n    plt.grid(False)\n    plt.show()\n    \n# preprocess the images     \ndef preprocess_image(image):\n    # swap the color channels from BGR to RGB, resize it, and scale\n    # the pixel values to [0, 1] range\n    image = cv2.imread(image)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (config.IMAGE_SIZE, config.IMAGE_SIZE))\n    image = image.astype(\"float32\") \/ 255.0\n\n    # subtract ImageNet mean, divide by ImageNet standard deviation,\n    # set \"channels first\" ordering, and add a batch dimension\n    #image -= config.MEAN\n    #image \/= config.STD\n    image = np.transpose(image, (2, 0, 1))\n    #image = np.expand_dims(image, 0)\n\n    # return the preprocessed image\n    return image\n    ","96c0a751":"# convert the labels to dict \nlabels = pd.read_csv(\"..\/input\/dog-breed-identification\/labels.csv\")\nlabels.breed.value_counts()","b417a93f":"labels = dict(zip(labels.id, labels.breed))\n#print(labels)","b7f754a2":"label_names = list(set(labels.values()))\nlabels_num = my_dict = dict(zip(label_names, range(len(label_names))))\nfor key, value in labels.items():\n    #print(labels[key])\n    labels[key]= labels_num[value]\n","5eb9de26":"#  display image \nimg1 = \"..\/input\/dog-breed-identification\/train\/001513dfcb2ffafc82cccf4d8bbaba97.jpg\"\nidx = labels[img1.split(\"\/\")[-1].split(\".\")[0]]\nbreed_label = list(labels_num.keys())[list(labels_num.values()).index(idx)]\nplt_imshow(breed_label,img1)","eb6792b9":"#next(iter(test_loader))","cc281a9f":"class DogBreedsDataset(Dataset):\n    \"\"\"Dog Breeds dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.labels_frame = pd.read_csv(csv_file)\n        self.map = dict(zip(self.labels_frame['breed'].unique(),range(0,len(self.labels_frame['breed'].unique()))))\n        self.labels_frame['breed'] = self.labels_frame['breed'].map(self.map)\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def getmap(self):\n        return self.map\n        \n    def __getclasses__(self):\n        return self.labels_frame['breed'].unique().tolist()\n\n    def __len__(self):\n        return len(self.labels_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,\n                                self.labels_frame.iloc[idx, 0])\n        img_name = img_name + '.jpg'\n        \n        image = io.imread(img_name)\n        PIL_image = Image.fromarray(image)\n        label = self.labels_frame.iloc[idx, 1:]\n        label = [int(label) for x in label]\n        label = np.asarray(label)\n        label = torch.from_numpy(label)\n        \n        if self.transform:\n            image = self.transform(PIL_image)\n        #sample = {'image': image, 'label': label}\n        return image,label","18ac7af7":"class DogBreedsTestDataset(Dataset):\n    \"\"\"Dog Breeds Test dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.labels_frame = pd.read_csv(csv_file)\n        self.labels_frame = self.labels_frame[['id']]\n        self.root_dir = root_dir\n        self.transform = transform\n   \n    def __len__(self):\n        return len(self.labels_frame)\n\n\n    def __getitem__(self, idx):\n        title = self.labels_frame.iloc[idx, 0]\n        img_name = os.path.join(self.root_dir,\n                                title)\n        img_name = img_name + '.jpg'\n        \n        image = io.imread(img_name)\n        PIL_image = Image.fromarray(image)\n        # print(PIL_image)\n        if self.transform:\n            image = self.transform(PIL_image)\n        sample = {'image': image, 'title': title}\n        return image,title","5cebbf3f":"from sklearn.model_selection import train_test_split\ndata_dir = '..\/input\/dog-breed-identification'\nfor_stratify = pd.read_csv(\"..\/input\/dog-breed-identification\/labels.csv\")\n\n# how many samples per batch to load\nBATCH_SIZE = 20\n# percentage of training set to use as validation\nvalid_size = 0.2\n\n# TODO: Define transforms for the training data and testing data\ntransform = transforms.Compose([transforms.Resize(255),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ntest_transforms = transforms.Compose([\n                                      transforms.ToTensor()])\n","b85fd825":"train_data = DogBreedsDataset(csv_file='..\/input\/dog-breed-identification\/labels.csv',root_dir='..\/input\/dog-breed-identification\/train', transform=transform)\ntrain_indices, val_indices = train_test_split(list(range(len(for_stratify.breed))), test_size=0.2, stratify=for_stratify.breed)\n\ntrainData = torch.utils.data.Subset(train_data, train_indices)\nvalData = torch.utils.data.Subset(train_data, val_indices)\n\ntrainDataLoader = DataLoader(trainData, shuffle=True,batch_size=BATCH_SIZE)\nvalDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)","ebd0dadc":"print(len(trainData))\nprint(len(valData))\nprint(len(train_data)==(len(trainData)+len(valData)), len(train_data))","5aa0a2c5":"number_of_classes=len(np.unique(list(labels.values())))","ccd44c2b":"test_data = DogBreedsTestDataset(csv_file='..\/input\/dog-breed-identification\/sample_submission.csv',root_dir='..\/input\/dog-breed-identification\/test', transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=20)","54c401f8":"from PIL import Image\nfrom skimage import io, transform\n#test_data[0]","31699bb6":"test_data[0]","061f5bd5":"#pretraining \n# Load the pretrained model from pytorch\nvgg16 = models.vgg16(pretrained=True)\n\n# print out the model structure\nprint(vgg16)","ff7e0744":"\"\"\"#pretraining \n# Load the pretrained model from pytorch\nvgg19 = models.vgg19(pretrained=True)\n\n# print out the model structure\nprint(vgg19)\"\"\"","fb8e6aca":"# Freeze training for all \"features\" layers\nfor param in vgg16.features.parameters():\n    param.requires_grad = False","9583e44d":"train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","8c99f6c7":"n_inputs = vgg16.classifier[6].in_features\n\n# add last linear layer (n_inputs -> 5 flower classes)\n# new layers automatically have requires_grad = True\nlast_layer = nn.Linear(n_inputs, number_of_classes)\n\nvgg16.classifier[6] = last_layer\n\n# if GPU is available, move the model to GPU\nif train_on_gpu:\n    vgg16.cuda()\n\n# check to see that your last layer produces the expected number of outputs\nprint(vgg16.classifier[6].out_features)\n#print(vgg16)","81b4de22":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n# optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)\n\n# ADAM optim\noptimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.00001)","e1943cde":"feats_list = list(vgg16.features)","8d0d1d22":"new_feats_list = []\nfor feat in feats_list:\n    new_feats_list.append(feat)\n    if isinstance(feat, nn.Conv2d):\n        new_feats_list.append(nn.Dropout(p=0.5, inplace=True))\n\n# modify convolution layers\nvgg16.features = nn.Sequential(*new_feats_list)","c5bd6247":"vgg16","afa8b568":"from skimage import io, transform\nfrom PIL import Image\n# number of epochs to train the model\nn_epochs = 5\n\nloss_values = []\nfor epoch in range(1, n_epochs+1):\n    running_loss = 0.0\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    ###################\n    # train the model #\n    ###################\n    # model by default is set to train\n    \n    for batch_i, (data, target) in enumerate(trainDataLoader):\n        # move tensors to GPU if CUDA is available\n       \n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg16(data)\n        # calculate the batch loss\n        loss = criterion(output, torch.max(target, 1)[1])\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss \n        train_loss += loss.item()\n        running_loss += loss.item()\n        \n        if batch_i % 20 == 19:    # print training loss every specified number of mini-batches\n            print('Epoch %d, Batch %d loss: %.16f' %\n                  (epoch, batch_i + 1, train_loss \/ 20))\n            \n            train_loss = 0.0\n            \n    loss_values.append(running_loss \/ len(train_data))\n    \nplt.plot(loss_values)","65a2e0b2":"loss_values","e2672a1c":"valid_loss = 0.0\nvgg16.eval()\nfor batch_i, (data, target) in enumerate(valDataLoader):\n        # move tensors to GPU if CUDA is available\n       \n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n            \n        output = vgg16(data)\n        # calculate the batch loss\n        loss = criterion(output, torch.max(target, 1)[1])\n        \n        # update training loss \n        valid_loss += loss.item()\n        \n        if batch_i % 20 == 19:    # print validation loss every specified number of mini-batches\n            print('Validation Loss Batch %d loss: %.16f' %\n                  (batch_i + 1, valid_loss \/ 20))\n            valid_loss = 0.0","50b492bb":"from skimage import io, transform\nfrom PIL import Image\nresults = {}\nvgg16.eval()\n#test_data = DogBreedsTestset(csv_file='..\/input\/dog-breed-identification\/sample_submission.csv',root_dir='..\/input\/dog-breed-identification\/test', transform=transform)\n#test_loader = torch.utils.data.DataLoader(test_data, batch_size=20)\n\nfor batch_i, (data, title) in enumerate(test_loader):\n        # move tensors to GPU if CUDA is available\n        images,titles = data, title\n        #print(images.shape)\n        #print(titles)\n               \n        if train_on_gpu:\n            images = images.cuda()\n        #print(title)\n        logits = vgg16(images)\n        output = torch.nn.functional.softmax(logits, dim=1)\n        \n        for k in range(len(titles)):\n            name = titles[k]\n            results[name] = output[k].cpu().tolist()","f2cfe16a":"output_df = pd.DataFrame(results).transpose()\ninv_map = {v: k for k, v in train_data.getmap().items()}\noutput_df.rename(columns=inv_map,inplace=True)\noutput_df = output_df.reset_index()\noutput_df.rename(columns={'index':'id'},inplace=True)\noutput_df.to_csv('output2.csv',index=False)","c49c10cd":" #imports","cf0f3170":"Convert the lables to numbers ","14018834":"https:\/\/www.kaggle.com\/carloalbertobarbano\/vgg16-transfer-learning-pytorch"}}