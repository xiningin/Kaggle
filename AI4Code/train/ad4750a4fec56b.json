{"cell_type":{"40953cae":"code","428e3a10":"code","ab99e990":"code","74c91750":"code","41443c99":"code","4e150e83":"code","5de96ba6":"code","9c0bfbf2":"code","f7512aff":"code","85d150f8":"code","95144935":"code","255cc022":"code","1c6d65da":"code","2377e6e0":"code","5f3733b0":"code","6332965e":"code","aaab5d1e":"code","5c067493":"markdown","605db832":"markdown","ff2fd898":"markdown"},"source":{"40953cae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","428e3a10":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nfrom random import shuffle\nfrom time import time\n# tensorboard --logdir=logs\/ --host localhost --port 8088\n\nprint(f'TensorFlow Version - {tf.__version__}')\nprint(f'Keras Version - {tf.keras.__version__}')","ab99e990":"from zipfile import ZipFile as zf\ntrain_zip = zf('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r')\ntrain_zip.extractall()\ntrain_zip.close()\ntest_zip = zf('\/kaggle\/input\/dogs-vs-cats\/test1.zip', 'r')\ntest_zip.extractall()\ntest_zip.close()\nIMG_SIZE = 50\nLR = 0.0003\nBATCH_SIZE = 32","74c91750":"MODEL_NAME = 'cat_and_dog_LR-{}_MODEL-{}.h5'.format(LR,'CovNet-128(2)-64(2)-32(2)-512-128-1')\nMODEL_PATH = os.path.join('saved_models',MODEL_NAME)","41443c99":"TRAIN_DIR = '.\/train\/'\nTEST_DIR = '.\/test1\/'","4e150e83":"def get_model(saved=True):\n    '''\n        Return the model\n    '''\n    if os.path.isfile(MODEL_PATH) and saved :\n        print(\"Loading saved model {}\".format(MODEL_NAME))\n        return load_model(MODEL_PATH)\n    \n    # Declaring model\n    model = Sequential()\n\n    # 1st Block\n    model.add(Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 1),filters=128, kernel_size=5, strides=1,padding='same',name = 'block1_conv1'))\n    model.add(Conv2D(filters=128, kernel_size=5, strides=1,padding='same',name = 'block1_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block1_mxPool'))\n\n    # 2nd Block\n    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'block2_conv1'))\n    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'block2_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block2_mxPool'))\n    \n    # 3rd Block\n    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv1'))\n    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block3_mxPool'))\n\n    # 4th Block - FC Block\n    dr_rate = 0.35\n    model.add(Flatten(name = 'block4_flatten'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout1'))\n    model.add(Dense(512, activation='relu',name = 'block4_dense1'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout2'))\n    model.add(Dense(128, activation='relu',name = 'block4_dense2'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout3'))\n    model.add(Dense(1, activation='sigmoid',name = 'block4_dense3'))\n\n    return model","5de96ba6":"def get_label(img):\n    '''\n        Return the label for images\n    '''\n    word = img.split('.')[0]\n    if word == 'cat':\n        return [0]\n    else:\n        return [1]","9c0bfbf2":"def get_training_data():\n    '''\n        Return training data\n    '''\n    training_data = []\n    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):\n        return np.load('training_data_{}.npy'.format(IMG_SIZE))\n    else:\n        for img in tqdm(os.listdir(TRAIN_DIR)):\n            label = get_label(img)\n            path = os.path.join(TRAIN_DIR,img)\n            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n            img = img\/255\n            training_data.append([np.array(img),np.array(label)])\n        shuffle(training_data)\n        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)\n        return np.array(training_data)","f7512aff":"def get_testing_data():\n    '''\n        Return testing data\n    '''\n    testing_data = []\n    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):\n        return np.load('testing_data_{}.npy'.format(IMG_SIZE))\n    else:\n        for img in tqdm(os.listdir(TEST_DIR)):\n            img_id = int(img.split('.')[0])\n            path = os.path.join(TEST_DIR,img)\n            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n            img = img\/255\n            testing_data.append([np.array(img),img_id])\n        testing_data.sort(key = lambda x: x[1])\n        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)\n        return np.array(testing_data)","85d150f8":"data = get_training_data()\n\npartition = 1000             # Breaking -ve index\ntrain = data[:-partition]    # For Training purpose\ntest= data[-partition:]      # For Validation purpose\n\n# Training set\nX_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ny_train = np.array([i[1] for i in train])\n\n# Validation set\nX_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ny_val = np.array([i[1] for i in test])","95144935":"'''Effects added on image\n    Rotation - \u00b1 50 deegrees,\n    Width Shift - \u00b1 15 %\n    Height Shift - \u00b1 15 %\n    Zoom - 30%\n    Horizontal Flip\n    Vertical Flip\n'''\ndatagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.05,height_shift_range=0.05,\n                            zoom_range=0.05,horizontal_flip=True,vertical_flip=False)\n\n# Calculation of necessary internal data for all images.\ndatagen.fit(X_train)","255cc022":"model = get_model()\nmodel.summary()","1c6d65da":"# Optimizer (Adam Optimizer)\nadam = Adam(lr = LR)\n\n# Callbacks Declared\ntensorboard = TensorBoard(log_dir=\"logs\/{}\".format(time()),batch_size=BATCH_SIZE)\n# Supported in new version of keras ,update_freq='epoch')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.3,patience=3,verbose=1,\n                              mode='max', min_lr=0.000001)\nearly_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min')\n# Supported in new version of keras ,restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(filepath=MODEL_PATH,monitor='val_acc',verbose=1,save_best_only=True,\n                                  mode='max',period=3)\n\nmodel.compile(optimizer = adam,loss='binary_crossentropy',metrics=['accuracy'])","2377e6e0":"# Toggle if dont want to train using Image Augmentation\ngenerator_train = True\nEPOCHS = 30\ncallbacks=[tensorboard,reduce_lr,early_stop,model_checkpoint]\n\nif generator_train:\n    print(f'Training model {MODEL_NAME} using Image Augmentation')\n    hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=BATCH_SIZE),\n                               steps_per_epoch=len(X_train)\/\/BATCH_SIZE,epochs=EPOCHS,verbose=2,\n                               validation_data=(X_val,y_val),callbacks=callbacks)\nelse:\n    print(f'Training model {MODEL_NAME} using normal image data provided')\n    hist = model.fit(X_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(X_val,y_val),\n                     verbose=2,callbacks=callbacks)","5f3733b0":"test_data = get_testing_data()","6332965e":"X_test = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\nids = [i[1] for i in test_data]","aaab5d1e":"pred = model.predict(X_test)","5c067493":"# Preparation","605db832":"# Testing","ff2fd898":"# Training"}}