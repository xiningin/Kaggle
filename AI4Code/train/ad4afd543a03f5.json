{"cell_type":{"bba9c1ea":"code","ef2f6805":"code","404cbb88":"code","7aa8ab0f":"code","c6e6d129":"code","fd6a0ff7":"code","e0e817a7":"code","bd47067c":"code","fe522047":"code","4e43fc16":"code","f00c4fa4":"code","06f287f9":"code","d222471e":"code","a5463be7":"code","558ee910":"code","eb615eb6":"code","064bfa6f":"code","ece4a4e4":"code","b4c82b9c":"code","03f1a057":"code","eaddf527":"code","30ef074b":"code","a30bdaa0":"code","67202fa8":"code","4c623d5b":"code","8f82a693":"code","1fd20c9d":"code","44b13866":"code","a6e69d06":"code","67a2ca59":"code","16e4825e":"markdown","c787ed7b":"markdown","f0e8fa7a":"markdown","26a112ed":"markdown","45b0e9d9":"markdown","ee6f2989":"markdown","19e152ef":"markdown","2a50bf0c":"markdown","e6db33d1":"markdown","f4768af3":"markdown","392b32d9":"markdown"},"source":{"bba9c1ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef2f6805":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nimport io\nimport cv2\nimport matplotlib\nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nmatplotlib.pyplot.rcParams['figure.figsize'] = (10,5)","404cbb88":"color_codes = {\n    'Animal': [64, 128, 64],\n    'Archway': [192, 0, 128],\n    'Bicyclist': [0, 128, 192],\n    #'Bridge': [0, 128, 64],\n    'Building': [128, 0, 0],\n    'Car': [64, 0, 128],\n    'CartLuggagePram': [64, 0, 192],\n    'Child': [192, 128, 64], \n    'Column_Pole': [192, 192, 128],\n    'Fence': [64, 64, 128],\n    'LaneMkgsDriv': [128, 0, 192],\n    #'LaneMkgsNonDriv': [192, 0, 64],\n    'Misc_Text': [128, 128, 64],\n    #'MotorcycleScooter': [192, 0, 192],\n    'OtherMoving': [128, 64, 64],\n    #'ParkingBlock': [64, 192, 128],\n    'Pedestrian': [64, 64, 0],\n    'Road': [128, 64, 128],\n    #'RoadShoulder': [128, 128, 192],\n    'Sidewalk': [0, 0, 192],\n    'SignSymbol': [192, 128, 128],\n    'Sky': [128, 128, 128],\n    #'SUVPickupTruck': [64, 128, 192],\n    #'TrafficCone': [0, 0, 64],\n    'TrafficLight': [0, 64, 64],\n    #'Train': [192, 64, 128],\n    'Tree': [128, 128, 0],\n    'Truck_Bus': [192, 128, 192],\n    #'Tunnel': [64, 0, 64],\n    'VegetationMisc': [192, 192, 0],\n    'Void': [0, 0, 0],\n    'Wall': [64, 192, 0]\n}","7aa8ab0f":"print(f'Number of classes: {len(color_codes.keys())}')","c6e6d129":"NEW_SIZE = (256, 256)\nPATH = '\/kaggle\/input\/camseq-semantic-segmentation\/'\nN_CLASSES = len(color_codes.keys())\n\n\ndef arrays_from_single_folder(path=PATH, new_size=NEW_SIZE):  \n    images = []\n    masks = []\n    filenames = os.listdir(PATH)\n    filenames.sort()\n    for filename in filenames:\n        path_to_img = os.path.join(path, filename)\n        try :\n            if filename.split('.')[0][-2:] == '_L':\n                img = cv2.imread(path_to_img)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img, new_size) \n                masks.append(img)\n            else:\n                img = cv2.imread(path_to_img)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img, new_size) \n                img = img \/ 255.0\n                images.append(img)\n        except:\n            continue\n    return images, masks\n\n\ndef get_mask_channels(mask, color_codes):\n    n_channels = len(color_codes.keys())  # N_CLASSES\n    mask_channels = np.zeros((mask.shape[0], mask.shape[1], n_channels), \n                             dtype=np.float32)\n    for i, cls in enumerate(color_codes.keys()):\n        color = color_codes[cls]\n        sub_mask = np.all(mask==color, axis=-1) * i\n        mask_channels[:, :, i] = sub_mask\n    return mask_channels\n\n\ndef get_masks_one_hot(mask, color_codes):\n    n_channels = len(color_codes.keys())  # N_CLASSES\n    mask_channels = np.zeros((mask.shape[0], mask.shape[1], n_channels), \n                             dtype=np.float32)\n    for i, cls in enumerate(color_codes.keys()):\n        color = color_codes[cls]\n        sub_mask = np.all(mask==color, axis=-1) * 1\n        mask_channels[:, :, i] = sub_mask\n    return mask_channels","fd6a0ff7":"images, masks = arrays_from_single_folder(PATH, NEW_SIZE)\n\nmasks_channels = [get_mask_channels(mask, color_codes) for mask in masks]\n\nmasks_one_hot = [get_masks_one_hot(mask, color_codes) for mask in masks]","e0e817a7":"# classes 3, 11, 13, 15, 25, 28 are absent in the dataset (those classes were commented in 'color_codes')\nprint('masks_channels: ', np.unique(masks_channels))\n# check masks_one_hot variable (in must consist of 0 and 1)\nprint('masks_one_hot: ', np.unique(masks_one_hot))","bd47067c":"from sklearn.utils import class_weight\n\n# check data balance and create weithts in case of disbalance\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                  np.unique(masks_channels),\n                                                  np.array(masks_channels).reshape(-1))      \n# get class names and weights\ndict_of_classes = {}\nfor i, j in enumerate(color_codes.keys()):\n    try:\n        dict_of_classes[j] = class_weights[i]\n    except:\n        continue\n# look at classes and their weights\ndict_of_classes","fe522047":"plt.figure(figsize=(15, 10))\nplt.subplot(1,3,1)\nplt.imshow(images[7])\nplt.title('Original image')\nplt.subplot(1,3,2)\nplt.imshow(masks[7])\nplt.title(\"Image's mask\")\nplt.subplot(1,3,3)\nplt.imshow(masks_one_hot[7][:, :, 13]) ## road\nplt.title(\"Mask corresponding to 'road' in masks_one_hot\")\nplt.show()","4e43fc16":"from sklearn.model_selection import train_test_split\n\n# split data on train\/val\/test sets\nx_train, x_valtest, y_train, y_valtest = train_test_split(\n    images, masks_one_hot, test_size=0.2, random_state=42, shuffle=True)\nx_val, x_test, y_val, y_test = train_test_split(\n    x_valtest, y_valtest, test_size=0.2, random_state=42, shuffle=False)\n\nprint('Training set: {}\\nValidation set: {}\\nTesting set: {}'.format(\n    (len(x_train), len(y_train)), (len(x_val), len(y_val)), (len(x_test), len(y_test))))","f00c4fa4":"# snity check after train\/val\/test split\n\ni = 1\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(x_test[i])\nplt.title('Image')\nplt.subplot(1, 2, 2)\nplt.imshow(y_test[i][:,:,13])\nplt.title('Road')\nplt.show()","06f287f9":"from keras import backend as K\n\n\ndef weighted_CCE_loss(class_weights):\n    \"\"\" Weighted crossentropy loss \"\"\"\n    def weighted_loss(y_true, y_pred):\n        class_weights_tensor = tf.cast(class_weights, tf.float32)\n        y_pred_weighted = y_pred * class_weights_tensor\n        cce_loss = - K.sum(y_true * K.log(y_pred_weighted))\n        return cce_loss\n    return weighted_loss","d222471e":"# just sanity check of data again before training model\nx_train[0].min(), y_train[0].min(), x_train[0].max(), y_train[0].max()","a5463be7":"# build unet model for multiclass case\n\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ReLU\nfrom keras.layers import Conv2DTranspose, BatchNormalization, Dropout, Lambda\n\n\nKERNEL = kernel = tf.keras.initializers.HeNormal()\n\ndef multi_unet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, N_CLASSES):\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    # Encoder\n    c1 = Conv2D(64, (3, 3), padding='same', kernel_initializer=KERNEL)(inputs)\n    c1 = ReLU()(c1)\n    c1 = BatchNormalization()(c1)\n    c1 = Conv2D(64, (3, 3), padding='same', kernel_initializer=KERNEL)(c1)\n    c1 = BatchNormalization()(c1)\n    c1 = ReLU()(c1)\n    p1 = MaxPooling2D((2, 2), strides=2)(c1)\n\n    c2 = Conv2D(128, (3, 3), padding='same', kernel_initializer=KERNEL)(p1)\n    c2 = ReLU()(c2)\n    c2 = BatchNormalization()(c2)\n    c2 = Conv2D(128, (3, 3), padding='same', kernel_initializer=KERNEL)(c2)\n    c2 = BatchNormalization()(c2)\n    c2 = ReLU()(c2)\n    p2 = MaxPooling2D((2, 2), strides=2)(c2)\n     \n    c3 = Conv2D(256, (3, 3), padding='same', kernel_initializer=KERNEL)(p2)\n    c3 = ReLU()(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(256, (3, 3), padding='same', kernel_initializer=KERNEL)(c3)\n    c3 = ReLU()(c3)\n    c3 = BatchNormalization()(c3)\n    p3 = MaxPooling2D((2, 2), strides=2)(c3)\n     \n    c4 = Conv2D(512, (3, 3), padding='same', kernel_initializer=KERNEL)(p3)\n    c4 = ReLU()(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(512, (3, 3), padding='same', kernel_initializer=KERNEL)(c4)\n    c4 = ReLU()(c4)\n    c4 = BatchNormalization()(c4)\n    p4 = MaxPooling2D((2, 2), strides=2)(c4)\n     \n    c5 = Conv2D(1024, (3, 3), padding='same', kernel_initializer=KERNEL)(p4)\n    c5 = ReLU()(c5)\n    c5 = BatchNormalization()(c5)\n\n    # Decoder\n    u6 = Conv2DTranspose(512, (2, 2), strides=2, padding='same')(c5)\n    u6 = tf.concat([c4, u6], axis=3)\n    c6 = Conv2D(512, (3, 3), padding='same', kernel_initializer=KERNEL)(u6)\n    c6 = ReLU()(c6)\n    c6 = BatchNormalization()(c6)\n    c6 = Conv2D(512, (3, 3), padding='same', kernel_initializer=KERNEL)(c6)\n    c6 = ReLU()(c6)\n    c6 = BatchNormalization()(c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=2, padding='same')(c6)\n    u7 = tf.concat([c3, u7], axis=3)\n    c7 = Conv2D(256, (3, 3), padding='same', kernel_initializer=KERNEL)(u7)\n    c7 = ReLU()(c7)\n    c7 = BatchNormalization()(c7)\n    c7 = Conv2D(256, (3, 3), padding='same', kernel_initializer=KERNEL)(c7)\n    c7 = ReLU()(c7)\n    c7 = BatchNormalization()(c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=2, padding='same')(c7)\n    u8 = tf.concat([u8, c2], axis=3)\n    c8 = Conv2D(128, (3, 3), padding='same', kernel_initializer=KERNEL)(u8)\n    c8 = ReLU()(c8)\n    c8 = BatchNormalization()(c8)\n    c8 = Conv2D(128, (3, 3), padding='same', kernel_initializer=KERNEL)(c8)\n    c8 = ReLU()(c8)\n    c8 = BatchNormalization()(c8)\n    \n    u9 = Conv2DTranspose(64, (2, 2), strides=2, padding='same')(c8)\n    u9 = tf.concat([c1, u9], axis=3)\n    c9 = Conv2D(64, (3, 3), padding='same', kernel_initializer=KERNEL)(u9)\n    c9 = ReLU()(c9)\n    c9 = BatchNormalization()(c9)\n    c9 = Conv2D(64, (3, 3), padding='same', kernel_initializer=KERNEL)(c9)\n    c9 = ReLU()(c9)\n    c9 = BatchNormalization()(c9)\n\n    # set outputs\n    outputs = Conv2D(N_CLASSES, (1, 1), activation='softmax')(c9)\n    model = Model(inputs=inputs, outputs=outputs)\n    \n    return model","558ee910":"# declare the model and compile it\n\nmodel = multi_unet(\n    IMG_HEIGHT=NEW_SIZE[0], IMG_WIDTH=NEW_SIZE[1], IMG_CHANNELS=3,  N_CLASSES=N_CLASSES\n)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n    loss=weighted_CCE_loss(class_weights),\n    metrics=['accuracy']\n)\nmodel.summary()","eb615eb6":"# And fun comes..!\n\nEPOCHS = 100\nBATCH_SIZE = 8  # according to the original paper\n\nhistory = model.fit(np.array(x_train), np.array(y_train),\n                    validation_data=(np.array(x_val), np.array(y_val)), \n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    verbose=2)","064bfa6f":"import seaborn as sns\n\nloss = history.history['loss']\naccuracy = history.history['accuracy']\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']\nepoch = range(0, EPOCHS)\n\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.lineplot(epoch, loss)\nsns.lineplot(epoch, val_loss)\nplt.title('Loss', size=14)\nplt.legend(['loss', 'val_loss'])\nplt.subplot(1,2,2)\nsns.lineplot(epoch, accuracy)\nsns.lineplot(epoch, val_accuracy)\nplt.title('Accuracy', size=14)\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","ece4a4e4":"# make predictions\n\nprediction = model.predict(np.array(x_test))","b4c82b9c":"# look for all predictions and ground truth from one predicted picture\n\nfor i in range(N_CLASSES):\n    plt.subplot(1,2,1)\n    plt.imshow(prediction[3][:,:,i])\n    plt.title('Prediction')\n    plt.subplot(1,2,2)\n    plt.imshow(y_test[3][:,:,i])\n    plt.title('Ground truth')\n    plt.show()","03f1a057":"# get list of color codes \ncolor_codes_list = [color_codes[i] for i in color_codes.keys()]\n\n\ndef get_rgb_image(prediction, n_classes, color_codes):\n    \"\"\"Returns RGB image from predicted segmentation map\"\"\"\n    output_height = prediction.shape[0]\n    output_width = prediction.shape[1]\n    seg_img = np.zeros((output_height, output_width, 3))\n    for c in range(n_classes):\n        seg_img[:, :, 0] += ((prediction[:, :, c])*(color_codes[c][0])).astype('uint8')\n        seg_img[:, :, 1] += ((prediction[:, :, c])*(color_codes[c][1])).astype('uint8')\n        seg_img[:, :, 2] += ((prediction[:, :, c])*(color_codes[c][2])).astype('uint8')\n    return seg_img \/ 255.0\n\n\n# Visualize prediction and ground truth\nfor i in range(len(x_test)):\n    plt.figure(figsize=(15, 6))\n    plt.subplot(1,3,1)\n    plt.imshow(get_rgb_image(prediction[i], N_CLASSES, color_codes_list))\n    plt.title('Prediction')\n    plt.subplot(1,3,2)\n    plt.imshow(get_rgb_image(y_test[i], N_CLASSES, color_codes_list))\n    plt.title('Ground truth')\n    plt.subplot(1,3,3)\n    plt.imshow(x_test[i])\n    plt.title('Image')  \n    plt.show()","eaddf527":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import ReLU, Flatten, Reshape\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Model\n\n\nKERNEL = tf.keras.initializers.HeNormal()\n\ndef segnet(input_shape, n_classes):\n    inputs = Input(shape=input_shape)\n    # Encoder\n    #x, p_1 = encoder(inputs, 2, 64, 3, (2, 2), 2)(inputs)\n    x = Conv2D(64, 3, padding='same', kernel_initializer=KERNEL)(inputs)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(64, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = MaxPooling2D((2, 2), strides=2)(x)\n    p_1 = x\n    #x, p_2 = encoder(inputs, 2, 128, 3, (2, 2), 2)(inputs)\n    x = Conv2D(128, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(128, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = MaxPooling2D((2, 2), strides=2)(x)\n    p_2 = x\n    #x, p_3 = encoder(inputs, 2, 256, 3, (2, 2), 2)(inputs)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = MaxPooling2D((2, 2), strides=2)(x)\n    p_3 = x\n    #x, p_4 = encoder(inputs, 2, 512, 3, (2, 2), 2)(inputs)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = MaxPooling2D((2, 2), strides=2)(x)\n    p_4 = x\n\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = MaxPooling2D((2, 2), strides=2)(x)\n    p_5 = x\n    \n    # Decoder\n    o = tf.concat([x, p_5], axis=3)\n    x = UpSampling2D(2, interpolation='nearest')(o)\n    #x = tf.keras.layers.Conv2DTranspose(512, 2, strides=2, use_bias=False, padding='same')(o)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    o = tf.concat([x, p_4], axis=3)\n    x = UpSampling2D(2, interpolation='nearest')(o)\n    #x = tf.keras.layers.Conv2DTranspose(512, 2, strides=2, use_bias=False, padding='same')(o)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(512, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    \n    o = tf.concat([x, p_3], axis=3)\n    x = UpSampling2D(2, interpolation='nearest')(o)\n    #x = tf.keras.layers.Conv2DTranspose(256, 2, strides=2, use_bias=False, padding='same')(o)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(256, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    o = tf.concat([x, p_2], axis=3)\n    x = UpSampling2D(2, interpolation='nearest')(o)\n    #x = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, use_bias=False, padding='same')(o)\n    x = Conv2D(128, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(128, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    o = tf.concat([x, p_1], axis=3)\n    x = UpSampling2D(2, interpolation='nearest')(o)\n    #x = tf.keras.layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, padding='same')(o)\n    x = Conv2D(64, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(64, 3, padding='same', kernel_initializer=KERNEL)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    outputs = Conv2D(n_classes, 1, activation='softmax')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n\n    return model","30ef074b":"model_segnet= segnet(\n    input_shape=(NEW_SIZE[0], NEW_SIZE[1], 3), \n    n_classes=N_CLASSES\n)\nmodel_segnet.summary()","a30bdaa0":"# use the custom weighted crossentropy loss which has been initialized beforehand\n\nmodel_segnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n                     loss=weighted_CCE_loss(class_weights), \n                     metrics=['accuracy'])\nEPOCHS = 100\nBATCH_SIZE = 8\nhistory = model_segnet.fit(np.array(x_train), np.array(y_train),\n                           validation_data=(np.array(x_val), np.array(y_val)),     \n                           epochs=EPOCHS,\n                           batch_size=BATCH_SIZE,\n                           verbose=2)","67202fa8":"loss = history.history['loss']\naccuracy = history.history['accuracy']\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']\nepoch = range(0, EPOCHS)\n\nplt.figure(figsize=(18,5))\n\nplt.subplot(1,3,1)\nsns.lineplot(epoch, loss)\nsns.lineplot(epoch, val_loss)\nplt.title('Loss', size=14)\nplt.legend(['loss', 'val_loss'])\n\nplt.subplot(1,3,2)\nsns.lineplot(epoch, accuracy)\nsns.lineplot(epoch, val_accuracy)\nplt.title('Accuracy', size=14)\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","4c623d5b":"# make predictions\n\nprediction = model_segnet.predict(np.array(x_test))","8f82a693":"for i in range(N_CLASSES):\n    plt.subplot(1,2,1)\n    plt.imshow(prediction[3][:,:,i])\n    plt.subplot(1,2,2)\n    plt.imshow(y_test[3][:,:,i])\n    plt.show()","1fd20c9d":"# Visualize prediction and ground truth\n\nfor i in range(len(x_test)):\n    plt.figure(figsize=(15, 6))\n    plt.subplot(1,3,1)\n    plt.imshow(get_rgb_image(prediction[i], N_CLASSES, color_codes_list))\n    plt.title('Prediction')\n    plt.subplot(1,3,2)\n    plt.imshow(get_rgb_image(y_test[i], N_CLASSES, color_codes_list))\n    plt.title('Ground truth')\n    plt.subplot(1,3,3)\n    plt.imshow(x_test[i])\n    plt.title('Image')  \n    plt.show()","44b13866":"model_segnet_2= segnet(\n    input_shape=(NEW_SIZE[0], NEW_SIZE[1], 3), \n    n_classes=N_CLASSES\n)\n\n#  model_segnet_2.summary()\n\n# use the custom weighted crossentropy loss which has been initialized beforehand\nmodel_segnet_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                       loss=weighted_CCE_loss(class_weights), \n                       metrics=['accuracy'])","a6e69d06":"# make predictions for x_test\n\npredictions_segnet = model_segnet.predict(np.array(x_test))\npredictions_unet = model.predict(np.array(x_test))","67a2ca59":"# Visualize U-net, SegNet prediction and ground truth\n\nfor i in range(len(x_test)):\n    plt.figure(figsize=(18, 6))\n    plt.subplot(1,4,1)\n    plt.imshow(get_rgb_image(predictions_unet[i], N_CLASSES, color_codes_list))\n    plt.title('U-net')\n    plt.subplot(1,4,2)\n    plt.imshow(get_rgb_image(predictions_segnet[i], N_CLASSES, color_codes_list))\n    plt.title('SegNet')\n    plt.subplot(1,4,3)\n    plt.imshow(get_rgb_image(y_test[i], N_CLASSES, color_codes_list))\n    plt.title('Ground truth')\n    plt.subplot(1,4,4)\n    plt.imshow(x_test[i])\n    plt.title('Image')\n    plt.show()","16e4825e":"### **Create some necessary functions**","c787ed7b":"# **DO NOT FORGET TO UPVOTE, PLEASE!**","f0e8fa7a":"### **Look at our SegNet results**","26a112ed":"### **Prepare data for training**","45b0e9d9":"### **Look at our U-net results**","ee6f2989":"### **Check data balance and create weithts in case of disbalance**","19e152ef":"### **Set weighted crossentropy loss for training models**","2a50bf0c":"### **Build U-net model**","e6db33d1":"### **Let's try SegNet**","f4768af3":"### **Extract files from path and get images and transformed masks**","392b32d9":"### **Look at some images and masks**"}}