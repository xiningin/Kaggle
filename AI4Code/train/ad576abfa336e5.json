{"cell_type":{"6e2bbdaf":"code","096a0041":"code","f9294cd0":"code","f4f18395":"code","6794b10c":"code","e63a44ea":"code","6440be04":"code","2bd055e0":"code","1f6c0458":"code","f6fc9976":"code","70c0db19":"code","1e3e68e4":"code","28821677":"code","89517620":"code","d08106bb":"code","dc63be39":"markdown"},"source":{"6e2bbdaf":"##ref:https:\/\/www.kaggle.com\/appian\/panda-imagehash-to-detect-duplicate-images ","096a0041":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os,cv2,tqdm,glob\nimport cv2,sys\nimport imagehash\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image\n\nfuncs = [\n    imagehash.average_hash,\n    imagehash.phash,\n    imagehash.dhash,\n    imagehash.whash,\n    #lambda x: imagehash.whash(x, mode='db4'),\n]","f9294cd0":"new_tra = glob.glob(\"..\/input\/petfinder-pawpularity-score\/train\/*jpg\")\nold_tra = glob.glob(\"..\/input\/petfinder-adoption-prediction\/train_images\/*-1.jpg\")\nold_test = glob.glob(\"..\/input\/petfinder-adoption-prediction\/test_images\/*-1.jpg\")\npaths = new_tra+old_tra#+old_test\nprint(len(new_tra),len(old_tra),len(old_test))","f4f18395":"hashes = []\nfor path in tqdm(paths, total=len(paths)):\n\n    image = cv2.imread(path)\n    image = Image.fromarray(image)\n    hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))","6794b10c":"import torch\n\nhashes = torch.Tensor(np.array(hashes).astype(int)).cuda()","e63a44ea":"sims = np.array([(hashes[i] == hashes).sum(dim=1).cpu().numpy()\/256 for i in range(hashes.shape[0])])\nprint(sims.shape)","6440be04":"import matplotlib.pyplot as plt\n\nthreshold = 0.9\nduplicates = np.where(sims > threshold)\n\ncnt = 0\nfor i,j in zip(*duplicates):\n    if i == j:\n        continue\n    cnt+=1\nprint(\"DUPLICATE\",cnt)#3652\n    \n\nsys.exit()\n\npairs = {}\nfor i,j in zip(*duplicates):\n    if i == j:\n        continue\n\n    path1 = paths[i]\n    path2 = paths[j]\n    print(path1)\n    print(path2)\n\n    image1 = cv2.imread(path1)\n    image2 = cv2.imread(path2)\n    \n    if image1.shape[0] > image1.shape[1] \/ 2:\n        fig,ax = plt.subplots(figsize=(20,20), ncols=2)\n    elif image1.shape[1] > image1.shape[0] \/ 2:\n        fig,ax = plt.subplots(figsize=(20,20), nrows=2)\n    else:\n        fig,ax = plt.subplots(figsize=(20,30), nrows=2)\n    ax[0].imshow(image1)\n    ax[1].imshow(image2)\n    plt.show()","2bd055e0":"del hashes","1f6c0458":"new_tra_old_test = new_tra+old_test\nhashes_1 = []\nfor path in tqdm(new_tra_old_test, total=len(new_tra_old_test)):\n\n    image = cv2.imread(path)\n    image = Image.fromarray(image)\n    hashes_1.append(np.array([f(image).hash for f in funcs]).reshape(256))","f6fc9976":"hashes_1 = torch.Tensor(np.array(hashes_1).astype(int)).cuda()","70c0db19":"sims1 = np.array([(hashes_1[i] == hashes_1).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_1.shape[0])])\nprint(sims1.shape)","1e3e68e4":"threshold = 0.9\nduplicates1 = np.where(sims1 > threshold)\n\ncnt1 = 0\nfor i,j in zip(*duplicates1):\n    if i == j:\n        continue\n    cnt1+=1\nprint(\"DUPLICATE\",cnt1)#","28821677":"del hashes_1","89517620":"hashes_2 = []\nfor path in tqdm(new_tra, total=len(new_tra)):\n\n    image = cv2.imread(path)\n    image = Image.fromarray(image)\n    hashes_2.append(np.array([f(image).hash for f in funcs]).reshape(256))\n    \nhashes_2 = torch.Tensor(np.array(hashes_2).astype(int)).cuda()\nsims2 = np.array([(hashes_2[i] == hashes_2).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_2.shape[0])])\nprint(sims2.shape)","d08106bb":"threshold = 0.9\nduplicates2 = np.where(sims2 > threshold)\n\ncnt2 = 0\nfor i,j in zip(*duplicates2):\n    if i == j:\n        continue\n    cnt2+=1\nprint(\"DUPLICATE\",cnt2)#","dc63be39":"I think there is a lot overlap between the training data from the previous petfinder competition and the training data from this time."}}