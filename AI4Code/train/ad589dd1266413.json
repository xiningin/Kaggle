{"cell_type":{"d26394b1":"code","1cee62c9":"code","ca2454fe":"code","53a3382a":"code","a73de688":"code","8e137a00":"code","e3ea588c":"code","408a56ea":"code","c7c04092":"code","f67b4582":"code","dad3f80d":"code","e50b2d1f":"code","27b72516":"code","2aef9665":"code","0af0a756":"code","3c74f818":"code","1e5ece2d":"code","1c239541":"code","a8ba5183":"code","54fa3eed":"code","451acb04":"code","85c9c32f":"code","d598fda9":"code","37502573":"code","001ea1ad":"code","f803dab4":"code","1dbfde02":"code","efc712e1":"code","c2147516":"code","369e4d0f":"code","fa82458a":"code","901c2053":"code","936bae0a":"code","6fbe05a7":"code","c691b15c":"code","79a51bac":"code","fffecab7":"code","eb1b6ce6":"code","04f0369a":"code","8a244ddc":"code","825dc677":"code","125a6722":"code","ba00f2f8":"code","0225c501":"code","0cdbff1e":"code","b9df2302":"code","178f8079":"code","e8a6a2d1":"code","c9891113":"code","6a78c045":"code","ae4df649":"code","c7e964ff":"code","6d3b5c3f":"code","e41cdf28":"code","ec3a2283":"code","6c18f7d3":"code","dd15930c":"code","16fe207d":"code","bc56b832":"code","8107ed51":"markdown","0ab368da":"markdown","c5c85703":"markdown","662a25dc":"markdown","c4e92e80":"markdown","3faf71a5":"markdown","b2ee7653":"markdown","ef5fb719":"markdown","321e5ffb":"markdown","ba4bf321":"markdown"},"source":{"d26394b1":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","1cee62c9":"train = pd.read_csv(\"train_s3TEQDk.csv\")","ca2454fe":"train.head(5)","53a3382a":"train.info()","a73de688":"for i in train.columns:\n   print(\"\\nColumn Name:\",i,\"-->\",train[i].unique(),\"-->Unique Count\",len(train[i].unique()))","8e137a00":"train.isnull().sum()","e3ea588c":"cat_col = []\nfor x in train.dtypes.index:\n    if train.dtypes[x] == \"object\":\n        cat_col.append(x)\n        \ncat_col","408a56ea":"for col in cat_col:\n  print(col)\n  print(train[col].value_counts())\n  print()","c7c04092":"import plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\nep = train['Gender'].value_counts().reset_index()\nep.columns = [\n    'Gender', \n    'percent'\n]\nep['percent'] \/= len(train)\n\nfig = px.pie(\n    ep, \n    names='Gender', \n    values='percent', \n    title='Countplot of Gender', \n    width=800,\n    height=500 \n)\n","f67b4582":"fig.show()","dad3f80d":"fig = px.pie(train['Occupation'].value_counts(), values='Occupation', \n             names = train['Occupation'].value_counts().index,title = 'Occupation',template='ggplot2')\nfig.show()","e50b2d1f":"fig = px.pie(train['Channel_Code'].value_counts(), values='Channel_Code', \n             names = train['Channel_Code'].value_counts().index,title = 'Channel_Code',template='ggplot2')\nfig.show()","27b72516":"fig = px.pie(train['Credit_Product'].value_counts(), values='Credit_Product', \n             names = train['Credit_Product'].value_counts().index,title = 'Credit_Product',template='ggplot2')\nfig.show()","2aef9665":"fig = px.pie(train['Is_Active'].value_counts(), values='Is_Active', \n             names = train['Is_Active'].value_counts().index,title = 'Is_Active',template='ggplot2')\nfig.show()","0af0a756":"facet = sns.FacetGrid(train,hue='Is_Lead',aspect = 4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\nplt.show()","3c74f818":"facet = sns.FacetGrid(train,hue='Is_Lead',aspect = 4)\nfacet.map(sns.kdeplot,'Vintage',shade=True)\nfacet.set(xlim=(0,train['Vintage'].max()))\nfacet.add_legend()\nplt.show()","1e5ece2d":"facet = sns.FacetGrid(train,hue='Is_Lead',aspect = 4)\nfacet.map(sns.kdeplot,'Avg_Account_Balance',shade=True)\nfacet.set(xlim=(0,train['Avg_Account_Balance'].max()))\nfacet.add_legend()\nplt.show()","1c239541":"train['Gender'] = train['Gender'].map({'Male':int(0), 'Female':int(1)})","a8ba5183":"train['Occupation'] = train['Occupation'].map({'Other' : int(0), 'Salaried':int(1) ,'Self_Employed':int(2) ,  'Entrepreneur': int(3)})","54fa3eed":"train['Channel_Code'] = train['Channel_Code'].map({'X1':int(0) , 'X2': int(1), 'X3' : int(2) , 'X4' : int(3)})","451acb04":"train['Is_Active'] = train['Is_Active'].map({'Yes':int(0), 'No':int(1)})","85c9c32f":"train['Credit_Product'] = train['Credit_Product'].map({'Yes' : int(0) , 'No': int(1)})","d598fda9":"test = pd.read_csv('test_mSzZ8RL.csv')","37502573":"test.shape","001ea1ad":"from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\nlabels = {}\nfor col in train.select_dtypes(exclude = np.number).columns.tolist():\n    le = LabelEncoder().fit(pd.concat([train[col].astype(str),test[col].astype(str)]))   \n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))\n    labels [col] = le\nprint('Categorical columns:', list(labels.keys()))","f803dab4":"print(f'Percent of Nans in Train Data : {round(train.isna().sum().sum()\/len(train), 2)}')\nprint(f'Percent of Nans in Test  Data : {round(test.isna().sum().sum()\/len(test), 2)}')","1dbfde02":"train.isna().sum()","efc712e1":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nmice_imputer = IterativeImputer()","c2147516":"train['Credit_Product'] = mice_imputer.fit_transform(train[['Credit_Product']])\ntrain['Credit_Product'] = round(train['Credit_Product'])","369e4d0f":"train.isnull().sum()","fa82458a":"test['Gender'] = test['Gender'].map({'Male':int(0), 'Female':int(1)})","901c2053":"test['Occupation'] = test['Occupation'].map({'Other' : int(0), 'Salaried':int(1) ,'Self_Employed':int(2) ,  'Entrepreneur': int(3)})","936bae0a":"test['Channel_Code'] = test['Channel_Code'].map({'X1':int(0) , 'X2': int(1), 'X3' : int(2) , 'X4' : int(3)})","6fbe05a7":"test['Is_Active'] = test['Is_Active'].map({'Yes':int(0), 'No':int(1)})","c691b15c":"test['Credit_Product'] = test['Credit_Product'].map({'Yes' : int(0) , 'No': int(1)})","79a51bac":"test['Credit_Product'] = mice_imputer.fit_transform(test[['Credit_Product']])\ntest['Credit_Product'] = round(test['Credit_Product'])","fffecab7":"test.isna().sum()","eb1b6ce6":"train = train.drop(columns=['Age' , 'Region_Code'],\n                 axis=1)\ntrain = train.dropna(how='any')\nprint(train.shape)","04f0369a":"Features = ['ID', 'Age', 'Region_Code','Gender','Occupation','Channel_Code','Vintage','Credit_Product','Avg_Account_Balance', 'Is_Active']\nTarget = ['Is_Lead']","8a244ddc":"from sklearn.model_selection import train_test_split\nY = train['Is_Lead']\nX = train.drop(columns = ['Is_Lead'])\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=9)\n\nprint('X train shape: ', X_train.shape)\nprint('Y train shape: ', Y_train.shape)\nprint('X test shape: ', X_test.shape)\nprint('Y test shape: ', Y_test.shape)","825dc677":"from sklearn.tree import DecisionTreeClassifier\nimport sklearn.model_selection as ms\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.preprocessing import StandardScaler\n\n!pip install imbalanced-learn\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.pipeline import Pipeline\n\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nplt.style.use('fivethirtyeight')\n\nfrom plotly.offline import download_plotlyjs,init_notebook_mode\ninit_notebook_mode(connected=True)","125a6722":"rf_pipe = Pipeline(steps =[ ('std_scale',StandardScaler()), (\"RF\",RandomForestClassifier(random_state=0,max_depth= 10, max_features= 5,min_samples_leaf= 30, min_samples_split= 100, n_estimators= 500))])\nrf_pipe.fit(X_train , Y_train)","ba00f2f8":"feature_importances = pd.Series(rf_pipe.steps[1][1].feature_importances_,index =X_train.columns);\nfeature_importances.nlargest(15).plot(kind='barh');\nplt.title('Random forest features_importances');","0225c501":"rf_train_predict = rf_pipe.predict(X_train)\nrf_test_predict = rf_pipe.predict(X_test)\n\n","0cdbff1e":"print('Random Forest classification_report on test_set')\nprint(classification_report(Y_test,rf_test_predict))","b9df2302":"print('Random Forest classification_report on test_set')\nprint(classification_report(Y_train,rf_train_predict))","178f8079":"rf_probs_train = rf_pipe.predict_proba(X_train)\nrf_probs_train = rf_probs_train[:, 1]\n\nrf_probs_test = rf_pipe.predict_proba(X_test)\nrf_probs_test = rf_probs_test[:, 1]\n","e8a6a2d1":"auc_RF_train = roc_auc_score(Y_train,rf_probs_train)\nauc_RF_test = roc_auc_score(Y_test,rf_probs_test)\nprint(\"Random forest auc on train set\",auc_RF_train)\nprint(\"Random forest auc on test set\", auc_RF_test)","c9891113":"predict = rf_pipe.predict_proba(X_test)\npredict = predict[:,1]","6a78c045":"model = RandomForestRegressor(bootstrap=False, max_depth=15, max_features='log2',\n                      random_state=42)\n# We train model\nmodel.fit(train[features],train[target])","ae4df649":"predictions = model.predict(test[features])","c7e964ff":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom numpy import mean, std\n\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\nscores = cross_val_score(model, train[features], train[target], cv=cv, n_jobs=-1)\nprint('Mean of Scores: %.3f' % (mean(scores)))","6d3b5c3f":"from sklearn.metrics import mean_squared_error\nmean_squared_error(Y_test, predict)","e41cdf28":"test_new = pd.read_csv('test_mSzZ8RL.csv')","ec3a2283":"submission_rf_new = pd.DataFrame({'ID':test_new['ID'],'Is_Lead':predictions})                        \n\n#Visualize the first 10 rows\nsubmission_rf_new.head(10)","6c18f7d3":"submission_rf_new['Is_Lead'] = submission_rf_new['Is_Lead'].astype(int)","dd15930c":"filename = 'submission_rf_new.csv'\n\nsubmission_rf_new.to_csv(filename,index=True)\n\nprint('Saved file: ' + filename)","16fe207d":"submission.shape","bc56b832":"submission.head(10)","8107ed51":"So, this was a problem statement in Analytics Vidhya Job-a-thon of may 2021. I am not a part of this competition but I still want to explore the problem statement and challenge.\n\n","0ab368da":"Model","c5c85703":"Preprocessing and Visualization","662a25dc":"Training & Testing data","c4e92e80":"Submission File","3faf71a5":"JOB-A-THON MAY 2021\n","b2ee7653":"Problem statement - Credit Card Lead Prediction\n\nHappy Customer Bank is a mid-sized private bank that deals in all kinds of banking products, like Savings accounts, Current accounts, investment products, credit products, among other offerings.\n\nThe bank also cross-sells products to its existing customers and to do so they use different kinds of communication like telecasting, e-mails, recommendations on net banking, mobile banking, etc.\n\nIn this case, the Happy Customer Bank wants to cross-sell its credit cards to its existing customers. The bank has identified a set of customers that are eligible for taking these credit cards.\n\nNow, the bank is looking for your help in identifying customers that could show higher intent towards a recommended credit card, given:\n\nThis dataset was part of May 2021 Jobathon conducted my analytics vidhya, for more info check:https:\/\/datahack.analyticsvidhya.com\/contest\/job-a-thon-2\/","ef5fb719":"Importing Lib\n","321e5ffb":"<a href=\"https:\/\/colab.research.google.com\/github\/kritika200015\/AV-Job-A-Thon-May2021\/blob\/main\/Credit_Card_Customer_predictions.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","ba4bf321":"Imputing Missing data with MICE Imputer"}}