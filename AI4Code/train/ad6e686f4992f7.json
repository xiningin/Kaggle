{"cell_type":{"72396af9":"code","1937150b":"code","6344fd45":"code","03690bdf":"code","1eee6dcf":"code","bde53cac":"code","2e6beac6":"code","110af12c":"code","4b9c7284":"code","f603a244":"code","614dd09c":"code","a7371c04":"code","c463a530":"code","81389c0f":"code","91832a3a":"code","60656941":"code","b51b1f7c":"code","0fecc0ca":"code","9b95cf68":"code","0fbefad3":"code","a0430755":"code","b6359dc3":"code","f2f4b773":"code","77bb1e35":"code","9034957f":"code","4d31f7b2":"code","98f98c44":"code","3a244956":"code","ae09d48f":"code","85ada6f5":"code","c1591443":"code","5a9135d9":"code","9497a788":"code","594fdb84":"code","32da9e4f":"code","90c9b490":"code","928e5627":"code","f2bbf243":"code","76de53e1":"code","0d313cb6":"code","32261079":"code","129f6622":"code","466c994e":"code","565b105b":"code","b02fddb3":"markdown","5ed4e01f":"markdown","1bd2f40f":"markdown","d80b00f9":"markdown","229c50a5":"markdown","7f8f8272":"markdown","b9a1d01a":"markdown","010a5732":"markdown","e9c40750":"markdown","e5397e9f":"markdown","32c5eccc":"markdown","32616d13":"markdown","726c2a6c":"markdown","400c8fec":"markdown","41fd77ec":"markdown","7037c35c":"markdown"},"source":{"72396af9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1937150b":"filenames","6344fd45":"data_2019 = pd.read_csv('\/kaggle\/input\/world-happiness\/2019.csv')","03690bdf":"data_2019.shape             # data_2019 dataframe has a shape of 156 by 9.\n                            # shape is an attribute of dataframe hence parenthesis is not followed ","1eee6dcf":"data_2019.head()           # head() method by default returns 5 examples. We can specify required number of examples inside parenthesis","bde53cac":"data_2019.head(10)","2e6beac6":"data_2019.head(50)","110af12c":"rank_india = data_2019[data_2019[\"Country or region\"]==\"India\"][\"Overall rank\"]   # This is called subsetting of a dataframe\nprint(rank_india)                               ","4b9c7284":"print(\"Yeaaah!! India is ahead of {} countries and only 139 to cross\".format((data_2019.shape[0] - 140)))  # Just practising .format method\nprint(\"{} percent of the countries are happier than India\".format(round(140\/156,3)))","f603a244":"data_2019.info()                # Checking if there are any null values","614dd09c":"data_2019.describe()      # Identifying max min and median for each feature       ","a7371c04":"data_2019.columns","c463a530":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.pairplot(data_2019)","81389c0f":"sns.heatmap(data_2019.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","91832a3a":"plt.scatter(data_2019[\"GDP per capita\"],data_2019[\"Perceptions of corruption\"])\nplt.show()","60656941":"GDP_per_capita = data_2019[\"GDP per capita\"]\ncorruption = data_2019[\"Perceptions of corruption\"]\nScore = data_2019[\"Score\"]\n\nplt.style.use('ggplot')\nplt_1 = plt.figure(figsize=(12, 5))\n\nplt.subplot(1,2,1)\nplt.scatter(GDP_per_capita, corruption)\nplt.xlabel(\"GDP per capita\")\nplt.ylabel(\"Perception of corruption\")\n\nplt.subplot(1,2,2)\nplt.scatter(GDP_per_capita, Score)\nplt.xlabel(\"GDP per capita\")\nplt.ylabel(\"Score\")\nplt.show()","b51b1f7c":"from sklearn import linear_model\nfrom sklearn.model_selection import train_test_split","0fecc0ca":"GDP_per_capita = data_2019[\"GDP per capita\"].values.reshape(-1,1)\nScore = data_2019[\"Score\"].values.reshape(-1,1)\nprint(type(GDP_per_capita))","9b95cf68":"GDP_train, GDP_test, Score_train, Score_test = train_test_split(GDP_per_capita, Score, test_size = 0.3, random_state=42)","0fbefad3":"# Checking how the data is splitted\nplt.scatter(GDP_train,Score_train,c = \"red\")                    # plotting train data # learned how to give colour using 'c' argument\nplt.scatter(GDP_test,Score_test,c = \"green\")                    # plotting test data\nplt.xlabel(\"GDP per capita\")\nplt.ylabel(\"Score\")\nplt.show()","a0430755":"reg = linear_model.LinearRegression()\nreg.fit(GDP_train, Score_train)","b6359dc3":"intercept = reg.intercept_\nprint(intercept)                         # output is a list\ncoefficient= reg.coef_\nprint(coefficient)                       # output is a list of list. \n\n# Because generally there will be more than one input fetaures resulting in corresponding coefficients\n\nprint(\"Regression model : Score = {}*GDP per capita + {}\".format(coefficient[0][0],intercept[0]))","f2f4b773":"Score_test_predicted = reg.predict(GDP_test)\nScore_train_predicted = reg.predict(GDP_train)\nprint(Score_test_predicted)","77bb1e35":"from sklearn import metrics\nmetrics.mean_squared_error(Score_test,Score_test_predicted)\nr2_score_test = metrics.r2_score(Score_test,Score_test_predicted)\nr2_score_train = metrics.r2_score(Score_train,Score_train_predicted)\nprint(\"R2 score of test data is {}\".format(r2_score_test))\nprint(\"R2 score of train data is {}\".format(r2_score_train))","9034957f":"plt.scatter(GDP_test,Score_test,c = \"red\")                   # plotting train data\nplt.plot(GDP_test,Score_test_predicted,c = \"blue\")                # This will be a staright line since it is a linear model\nplt.xlabel(\"GDP per capita\")\nplt.ylabel(\"Score\")\nplt.show()","4d31f7b2":"error = (Score_train - Score_train_predicted)\nplt.hist(error, bins = 7)","98f98c44":"from sklearn import preprocessing             # scaling features to same scale","3a244956":"print(data_2019.shape)\nprint(data_2019.columns)\ndata_2019.drop([\"Country or region\"], axis = 1, inplace = True)","ae09d48f":"print(data_2019.shape)\ncolumns_names = data_2019.columns\ndata_2019_norm = preprocessing.normalize(data_2019)\ndata_2019_norm","85ada6f5":"df = pd.DataFrame(data_2019_norm, index = data_2019.index, columns = data_2019.columns)\ndf.head()","c1591443":"df.describe()","5a9135d9":"from sklearn import preprocessing\n  \nmin_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1))\n\ndata_2019_scaled= min_max_scaler.fit_transform(data_2019)\ndata_2019_scaled_df = pd.DataFrame(data_2019_scaled, index = data_2019.index, columns = data_2019.columns)","9497a788":"print(data_2019_scaled_df.describe())","594fdb84":"X = data_2019_scaled_df.drop([\"Score\"], axis = 1)   # Since X is a matrix capital letter is used. This is a Convectional way.\ny = data_2019_scaled_df[\"Score\"]                    # Target variable is a vector, hence small letter y\nX.head()","32da9e4f":"from sklearn import linear_model","90c9b490":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)","928e5627":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","f2bbf243":"reg = linear_model.LinearRegression()\nreg.fit(X_train, y_train)","76de53e1":"y_test_pred = reg.predict(X_test)\ny_train_pred = reg.predict(X_train)","0d313cb6":"r2_score_test = metrics.r2_score(y_test,y_test_pred)\nr2_score_train = metrics.r2_score(y_train,y_train_pred)\nprint(\"R2 score of test data is {}\".format(r2_score_test))\nprint(\"R2 score of train data is {}\".format(r2_score_train))","32261079":"os.listdir()","129f6622":"print(reg.fit(X_train, y_train).summary())","466c994e":"params = np.append(reg.intercept_,reg.coef_)\npredictions = reg.predict(X_train)","565b105b":"print(predictions)","b02fddb3":"## Observation from GDP vs Perception of corruption.\n* Higher GDP countries are likely to have higher corruption\n* And interestingly highly corrupted countries are having high score\n* lets plot GDP vs Perception of corruption separately","5ed4e01f":"**Not even in top 50?? Definitely I was not counted during the survey \ud83d\ude1c** <br>\nOkay, but at which rank india actually is?","1bd2f40f":"**How many countries data is present and how many features are affecting individuals happiness** <br>\nI want to see the full shape of data","d80b00f9":"Obervations. Not all features have come to 0 -1","229c50a5":"# 1. Exploratory Data Analysis (EDA)\n**Let us explore dataset of year 2019 and see who is happy and who is not!**","7f8f8272":"# Hello \ud83d\udc4b, <br>\nThis is my first Kaggle notebook. Any suggestions\/ideas in the notebook are always welcome. <br>\nI tried to keep this notebook as simple as possible. Using this notebook as a practise for my coding skills and tried describing it in a little funny way as well. \n# If you are a beginner then welcome and scroll down for a story!!!","b9a1d01a":"# 2. Simple Linear Regression\n\n**Analysing by going through each and every pairplot is definitely a tedious job. Sticking to the agenda of this notebook(run simple regression and multiple regression) lets start running a simple regression on Score vs GDP per capita.** <br>\nBefore actually performing regression let us refresh concepts with the below points <br>\n- Regression means going to the lowest form or in reverse direction. Lets take a calculator, we input the numbers and it runs the calculations and gives the output because the calaculator already has the model(equation) to give output. Whereas in regression, we have input and output data, we need to find the best fitting model. Thus the word 'regress' best fits.\n- Simple regression has only two variables (one input and one output)\n- Multiple regression has more than two variables (more than one input and one output variable)<br>\n\n\n***A linear relation between Score vs GDP per capita can be clearly seen in the above graph. Let's run regression on these two features ***","010a5732":"## Errors normally distributed?","e9c40750":"# 3. Multiple Linear regression <br>\nIts obvious that simple linear regression is not going to result in best fit for this dataset. Now we will try multiple regression.\n\n**Regression is**\n1. Outlier sensitive\n2. Features need to be scaled to avoid biased weightage to features","e5397e9f":"**Whaaaaaaaat!!! India is not in top 5 countries** <br>\nMay be India is in Top 10 countries. Lets see (add fingers cross symbol)","32c5eccc":"**May be in Top 50 countries**","32616d13":"**Whichever countries have higher GDP per capita and perceptions of corruption they are most likely to be the happier countries(score high)**","726c2a6c":"**Wow, Now, every feature is between 0 -1**","400c8fec":"***We are given 5 years of datasets. Let us consider only one year dataset since our intention of this notebook is to practise and understand regression***","41fd77ec":"0.48 is too bad fit !!","7037c35c":"# I want to explore the following topics in the following order\n    \n1. EDA with emphasis on India first then followed by all countries <br>\n2. Simple linear regression <br>\n3. Multiple Linear regression <br>\n4. Finding the feature with least contribution to the model <br>\n5. Finally develop an improved model by removing some features <br>\n6. Compare Acuuracies of models with All features and Reduced Features <br>"}}