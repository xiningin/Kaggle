{"cell_type":{"19722745":"code","67e8aa64":"code","4f5e5635":"code","d171e421":"code","af0335ac":"code","a7028f26":"code","3b5b64dc":"code","e13fa997":"code","46369e08":"code","b211c218":"code","bca28c9f":"code","9ceac2f8":"code","2d025133":"code","ffbee747":"code","97f05269":"code","50639900":"code","88ca5642":"code","b40eb39e":"code","5aaaecb1":"code","227eb888":"code","cff7a0c7":"code","393e1612":"code","56763b45":"code","2f6a4d09":"code","109ba21e":"code","9a1ce5d6":"code","028f36fa":"code","86e7803e":"code","2fc73900":"code","ba616c74":"code","80bd06a1":"code","1832914e":"code","300f68e4":"code","1de20582":"code","75398cb0":"code","5c649f40":"code","209eaa35":"code","3273666b":"code","9f5593e5":"code","d5a4a435":"code","33174fb8":"code","3db12430":"code","2d748955":"code","e7a0bd61":"markdown","92fb94a1":"markdown","9bd76f71":"markdown","f92bfc12":"markdown","76667ee0":"markdown","05837be6":"markdown","1c8b4e41":"markdown","0241af42":"markdown","4085214e":"markdown","a087eaa8":"markdown","c14762d3":"markdown","489d12f3":"markdown","64d3719b":"markdown","77809174":"markdown","bb5bd401":"markdown","1db022a3":"markdown","111d1039":"markdown","ba370e2f":"markdown","80f3e315":"markdown","be04900a":"markdown","692a22c2":"markdown","300bebfc":"markdown","f5aed2a9":"markdown","b1b3c4d5":"markdown","8a489fbc":"markdown","ad9cb4c7":"markdown","5626bf0c":"markdown","50c60600":"markdown","f7c471e3":"markdown","d0bea0b7":"markdown","849a8870":"markdown","631f5e59":"markdown","7bfbd224":"markdown","06ec5823":"markdown","e9213166":"markdown"},"source":{"19722745":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","67e8aa64":"data = pd.read_csv(\"..\/input\/student-grade-prediction\/student-mat.csv\")\ndata.head()","4f5e5635":"data.describe()","d171e421":"data.info()","af0335ac":"data.isnull().sum().any()","a7028f26":"sc_gp = data[data['school']=='GP']['G3'].value_counts()\nsc_ms = data[data['school']=='MS']['G3'].value_counts()\nsc_df = pd.DataFrame([sc_gp, sc_ms], index=['School GP', 'School MS'])\nsc_df = sc_df.T","3b5b64dc":"sns.lineplot(data=sc_df)","e13fa997":"fg, axs = plt.subplots(1, 2, figsize=(20,5))\n\naxs[0].set_title('Distribution of Age & Sex wrt Score G3')\nsns.barplot(x='age', y='G3', hue='sex', data=data, ax=axs[0])\n\naxs[1].set_title('Distribution of count of Age & Sex')\nsns.countplot(x='age', hue='sex', data=data, ax=axs[1])","46369e08":"fam_edu = data['Fedu'] + data['Medu']\nsns.swarmplot(x=fam_edu, y='G3', data=data)","b211c218":"fg, axs = plt.subplots(1, 2, figsize=(20,5))\n\naxs[0].set_title('Travel time wrt Score G3')\nsns.swarmplot(x='traveltime', y='G3', data=data, ax=axs[0])\n\naxs[1].set_title('Study time wrt Score G3')\nsns.swarmplot(x='studytime', y='G3', data=data, ax=axs[1])","bca28c9f":"fg, axs = plt.subplots(3,3, figsize=(20,15))\n\naxs[0,0].set_title('School Support vs G3')\nsns.swarmplot(x='schoolsup', y='G3', data=data, ax=axs[0,0])\naxs[0,0].set_xlabel('School Support')\n\naxs[0,1].set_title('Family Support vs G3')\nsns.swarmplot(x='famsup', y='G3', data=data, ax=axs[0,1])\naxs[0,1].set_xlabel('Family Support')\n\naxs[0,2].set_title('Paid for extra class vs G3')\nsns.swarmplot(x='paid', y='G3', data=data, ax=axs[0,2])\naxs[0,2].set_xlabel('Extra paid')\n\naxs[1,0].set_title('Extra-curricular activities vs G3')\nsns.swarmplot(x='activities', y='G3', data=data, ax=axs[1,0])\naxs[1,0].set_xlabel('Extra-curricular activities')\n\naxs[1,1].set_title('Nursery vs G3')\nsns.swarmplot(x='nursery', y='G3', data=data, ax=axs[1,1])\naxs[1,1].set_xlabel('Nursery')\n\naxs[1,2].set_title('Higher Education vs G3')\nsns.swarmplot(x='higher', y='G3', data=data, ax=axs[1,2])\naxs[1,2].set_xlabel('Higher Education')\n\naxs[2,0].set_title('Internet Access vs G3')\nsns.swarmplot(x='internet', y='G3', data=data, ax=axs[2,0])\naxs[2,0].set_xlabel('Internet Access')\n\naxs[2,1].set_title('Romantic Relation vs G3')\nsns.swarmplot(x='romantic', y='G3', data=data, ax=axs[2,1])\naxs[2,1].set_xlabel('Romantic Relation')","9ceac2f8":"#Lets check the alcohol consumption\nalc = data['Dalc'] + data['Walc']\nsns.swarmplot(x=alc, y='G3', data=data)","2d025133":"fg, axs = plt.subplots(1, 3, figsize=(20, 5))\ng1 = sns.distplot(data['G1'], ax=axs[0])\ng2 = sns.distplot(data['G2'], ax=axs[1])\ng3 = sns.distplot(data['G3'], ax=axs[2])","ffbee747":"fg, axs = plt.subplots(2,2, figsize=(20,10))\nb1 = sns.lineplot(x='G1', y='G3', data=data, ax=axs[0,0])\nb2 = sns.scatterplot(x='G1', y='G3', data=data, ax=axs[0,1])\nb3 = sns.lineplot(x='G2', y='G3', data=data, ax=axs[1,0])\nb4 = sns.scatterplot(x='G2', y='G3', data=data, ax=axs[1,1])","97f05269":"sns.countplot(x='G3', data=data, order=data['G3'].value_counts().index)","50639900":"#school\nsch_map = {'GP':1, 'MS':2}\ndata['school'] = data['school'].map(sch_map)","88ca5642":"#sex\nsex_map = {'F':1, 'M':2}\ndata['sex'] = data['sex'].map(sex_map)","b40eb39e":"#address\nfmap = {'U':1, 'R':2}\ndata['address'] = data['address'].map(fmap)","5aaaecb1":"#famsize\nfmap = {'LE3':1, 'GT3':2}\ndata['famsize'] = data['famsize'].map(fmap)","227eb888":"#Pstatus\nfmap = {'T':1, 'A':2}\ndata['Pstatus'] = data['Pstatus'].map(fmap)","cff7a0c7":"#Mjob and Fjob\nfmap = {'services':1, 'at_home':2, 'teacher':3, 'health':4, 'other':5}\ndata['Mjob'] = data['Mjob'].map(fmap)\ndata['Fjob'] = data['Fjob'].map(fmap)","393e1612":"#reason\nfmap = {'course':1, 'home':2, 'reputation':3, 'other':4}\ndata['reason'] = data['reason'].map(fmap)","56763b45":"#guardian\nfmap = {'mother':1, 'father':2, 'other':3}\ndata['guardian'] = data['guardian'].map(fmap)","2f6a4d09":"#schoolsup famsup paid\nfmap = {'yes':1, 'no':0}\ndata['schoolsup'] = data['schoolsup'].map(fmap)\ndata['famsup'] = data['famsup'].map(fmap)\ndata['paid'] = data['paid'].map(fmap)\ndata['activities'] = data['activities'].map(fmap)\ndata['nursery'] = data['nursery'].map(fmap)\ndata['higher'] = data['higher'].map(fmap)\ndata['internet'] = data['internet'].map(fmap)\ndata['romantic'] = data['romantic'].map(fmap)","109ba21e":"X = data.iloc[:, :32]\ny = data.iloc[:, -1]","9a1ce5d6":"from sklearn.feature_selection import SelectKBest, chi2\n\nk_best = SelectKBest(score_func=chi2, k=15)\nk_best.fit(X, y)\n\ndf_score = pd.Series(data=k_best.scores_, index=X.columns)\ndf_score","028f36fa":"df_score.nlargest(15).plot(kind='bar')","86e7803e":"plt.figure(figsize=(25, 10))\nsns.heatmap(data.corr(), annot=True, cmap='YlGnBu')","2fc73900":"data.corr()['G3'].nlargest(15)","ba616c74":"X = data[df_score.nlargest(15).index]\ny = data['G3']","80bd06a1":"from sklearn.model_selection import train_test_split, KFold, cross_val_score\n\nk_fold = KFold(n_splits=10, random_state=10, shuffle=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","1832914e":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.metrics import mean_squared_error","300f68e4":"classifiers = {\n    'Linear Regression' : LinearRegression(),\n    'Lasso': Lasso(),\n    'Ridge': Ridge(),\n    'ElasticNet': ElasticNet(),\n    'RandromForest': RandomForestRegressor(n_estimators=100),\n    'GradientBoost': GradientBoostingRegressor(n_estimators=100),\n    'SVM' : SVR()\n}\n\nfor key, clf in classifiers.items():\n    #clf.fit(X_train, y_train)\n    score = cross_val_score(clf, X_train, y_train, cv=k_fold, scoring='neg_mean_squared_error')\n    rmse = np.sqrt(-score)\n    rmse_score = round(np.mean(rmse), 2)\n    print('RMSE score with CV of {0} is {1}'.format(key, rmse_score))","1de20582":"from sklearn.model_selection import GridSearchCV\nclf = GradientBoostingRegressor()\nparams = {\n    'min_samples_split':[5,9,13],'max_leaf_nodes':[3,5,7,9],'max_features':[4,5,6,7]\n}\ngs = GridSearchCV(estimator=clf, param_grid=params, cv=k_fold, scoring='neg_mean_squared_error')\ngs.fit(X_train, y_train)","75398cb0":"gs.best_params_","5c649f40":"np.sqrt(-gs.best_score_)","209eaa35":"gb_clf = gs.best_estimator_","3273666b":"gb_clf.fit(X_train, y_train)\ny_predict = gb_clf.predict(X_test)\n\nmse = mean_squared_error(y_test, y_predict)\nrmse = np.sqrt(mse)\nrmse","9f5593e5":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import backend\ndef build_regressor():\n    regressor = Sequential()\n    \n    regressor.add(Dense(units=15, input_dim=15, activation='relu'))\n    regressor.add(Dense(units=32, activation='relu'))\n    regressor.add(Dense(units=1))\n    \n    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae'])\n    return regressor","d5a4a435":"from keras.wrappers.scikit_learn import KerasRegressor\nregressor = KerasRegressor(build_fn=build_regressor, batch_size=20, epochs=100)","33174fb8":"# Scale the train and test data before training the model\nfrom sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\ny_train = ss.fit_transform(np.array(y_train).reshape(-1, 1))\n\nX_test = ss.fit_transform(X_test)\ny_test = ss.fit_transform(np.array(y_test).reshape(-1,1))","3db12430":"results=regressor.fit(X_train, y_train)","2d748955":"y_pred = regressor.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nrmse","e7a0bd61":"# 2. Feature Engineering\nIn feature engineering, we convert the text values to numerical values to be readble by Machine Learning Algorithms.","92fb94a1":"### Compare family (father & mother) eduction with G3","9bd76f71":"> ### Compare the two schools GP & MS with the score G3 ","f92bfc12":"From the feature selection score, let us define X","76667ee0":"* Students living near the school have scoring better than the far students.\n* Students having more weekly study time (over 10hrs) are getting better score.","05837be6":"Students having more alcohol consumption has performing very poor.","1c8b4e41":"### Compare travel and study time with G3","0241af42":"### 2.2 Feature Selection","4085214e":"From the heatmap plot, G1 & G2 are highly correlated with G3\n","a087eaa8":"From the above lineplot, School GP is outperforming School MS","c14762d3":"From the above, GradientBoostRegressor is giving lesser error 1.66 with CV compared to other algorithms","489d12f3":"### 2.1 Convert to numerical","64d3719b":"# 4. Deep Learning with Keras","77809174":"### Compare Age and Sex with G3","bb5bd401":"There is a linear relation between G1&G3 and G2&G3","1db022a3":"### Students count","111d1039":"GradientBoostingRegressor is giving RMSE of **1.89** with hyper parameter tuning","ba370e2f":"There are no null values in the dataset","80f3e315":"### Compare other features\n","be04900a":"# 1. Exploratory Data Analysis","692a22c2":"* Students who doesn't have school support are showing negative trend.\n* Students who paid for extra classes are showing negative trend.\n* Students who went to nursery schools are performing better.\n* Students who with to proceed with higher eduction are performing better.\n* Students having internet access are performing better.\n* Students having no romantic relation are performing better.","300bebfc":"### 3.1 Find the scores","f5aed2a9":"From the plot, absense, G2, G1 and failures are having best scores","b1b3c4d5":"We do not get much information from Age and Sex","8a489fbc":"There are 33 columns in the dataset and this is going to be cumbersome for training our model. Let's train with best 15 columns only","ad9cb4c7":"### Compare G1 and G2 with G3","5626bf0c":"* Majority of the sudents has scored 10 in G3\n* Nearly 40 students has failed in G3","50c60600":"Students having good family education background are performing better.","f7c471e3":"I'm a beginner to Data Science. If you like my kernal, please support me by Upvoting it.\n\nThanks in advance.","d0bea0b7":"### Probability Distribution of Grades","849a8870":"### 3.2 Hyper parameter tuning using GridSearchCV","631f5e59":"### 2.3 Heatmap correlation","7bfbd224":"# 3. Machine Learning Algorithm","06ec5823":"RMSE error from Keras is 0.58 but this error is nearly 1.96 in Machine Learning\n\n**RMSE:\nKeras: 0.58\nML: 1.96**","e9213166":"### 2.4 Splitting data into train and test"}}