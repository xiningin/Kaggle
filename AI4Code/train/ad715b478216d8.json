{"cell_type":{"83561a8a":"code","3a3cec40":"code","e69a7ce6":"code","1714c69a":"code","81e12b95":"code","59ffde25":"code","184360cd":"code","8da87be7":"code","b621e013":"code","fc445234":"code","75d19677":"code","662c7085":"code","34057cc8":"code","efedb535":"code","e819a6f3":"code","9aee4a7a":"markdown","ff6577b4":"markdown","fc577123":"markdown","afd78555":"markdown","9b995c45":"markdown","0d9836de":"markdown","34f0aa08":"markdown","0efeac55":"markdown","3225c61c":"markdown","f9469150":"markdown","7fa509ef":"markdown","97422d57":"markdown","7c167464":"markdown","b46af2e1":"markdown","4bb2a465":"markdown"},"source":{"83561a8a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\nimport warnings as wrn\nwrn.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a3cec40":"data = pd.read_csv('\/kaggle\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv',encoding='latin1')","e69a7ce6":"data = data.loc[:,[\"gender\",\"description\"]]\n","1714c69a":"data.head()","81e12b95":"data.dropna(inplace=True)","59ffde25":"gnd =  [0 if each == \"male\" else 1 for each in data.gender]\ndata.gender = gnd","184360cd":"import nltk # Natural Language Tool Kit\nimport re # Regular Expression\n\nlemma = nltk.WordNetLemmatizer() # Lemmatizer (nltk library)\npattern = \"[^a-zA-Z]\"\n","8da87be7":"desc_list = []\nfor each in data.description:\n    each = re.sub(pattern,\" \",each) # Cleaning\n    each = each.lower() # Converting to lower\n    each = nltk.word_tokenize(each) # Converting string to list\n    each = [lemma.lemmatize(each) for each in each] # Lemmatizing\n    each = \" \".join(each) # Converting list to string\n    desc_list.append(each) ","b621e013":"desc_list[:5]","fc445234":"from sklearn.feature_extraction.text import CountVectorizer\n\nmost_used = 5000 # Most used 5000 words in bios\ncv = CountVectorizer(max_features=most_used,stop_words='english') ","75d19677":"sparce_matrix = cv.fit_transform(desc_list).toarray()\nsparce_matrix","662c7085":"from sklearn.model_selection import train_test_split\n\nx = sparce_matrix\ny = data.gender.values\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1,test_size=0.1)","34057cc8":"from sklearn.naive_bayes import GaussianNB\nNBC = GaussianNB()\nNBC.fit(x_train,y_train)\nprint(NBC.score(x_test,y_test))","efedb535":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nLR.fit(x_train,y_train)\nprint(LR.score(x_test,y_test))","e819a6f3":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(n_estimators=20,random_state=1)\n\nRFC.fit(x_train,y_train)\nprint(RFC.score(x_test,y_test))","9aee4a7a":"# Introduction\n\nHello people, welcome to my kernel! In this kernel I am going to classificate gender using Twitter Bio (Description) Data. In order to do this I am going to use Natural Language Processing.\n\nLet's take a look at our schedule\n\n# Schedule\n1. Importing Libraries and Data\n1. Preprocessing Data\n1. Classificiation Algorithms\n    * Naive Bayes Classification\n    * Logistic Regression Classification\n    * Random Forest Classification\n1. Result\n1. Conclusion","ff6577b4":"# Conclusion\n\nThanks for your attention. If there are any mistake or if you want to ask a question about anything, please contact me in comment section. If you upvote this kernel, I would be glad.","fc577123":"# Result\n\nAs we can see, our best classification algorithm for this dataset is Logistic Regression. Maybe Random Forest Classification would have been better but I could not increase n_estimator value, because It has taken too long time to train.\n","afd78555":"And now I am going to create bag of words. In order to do this I am going to import SKLearn library.","9b995c45":"And now I am going to create a for loop and I will apply those steps to each row. But before this, I am going to libraries that I need for preprocessing.","0d9836de":"# Classification Algorithms \n\nOur train and test splits are ready. In this section I am going to train some different classification algorithms and at the end of this section I am going to determine best classification algorithm for this dataset.\n\nI am going to train these classification algorithms:\n* Naive Bayes Classification\n* Logistic Regression Classification\n* Random Forest Classification","34f0aa08":"## Logistic Regression Classification\n\nIn this section I am going to train a Logistic Regression model using SKLearn library.","0efeac55":"* Our naive bayes classification score is so low. It means that Naive Bayes algorithm is not useful for this dataset.","3225c61c":"* Our logistic regression model's score is so much better than Naive Bayes score.","f9469150":"## Random Forest Classification \n\nIn this section I am going to train a RFC model. In order to do this I am going to use SKLearn library","7fa509ef":"# Importing Libraries and Data\n\nIn this section I am going to import the libraries and the data that I will use in this kernel. However I am not going to import machine learning libraries, I am going to add these libraries when I will use them","97422d57":"# Preprocessing\n\nIn this section I am going to prepare data for machine learning. In this section I am going to follow these steps.\n\n* Dropping Redundant Features\n* Dropping Nan Values\n* Converting Gender Feature to Int64\n* Cleaning Data using Regular Expressions (RE Library)\n* Converting Text to Lower\n* Converting String to List \n* Lemmatizing\n* Converting List to String\n* Creating Bag of Words\n* Train Test Splitting\n\nI am going to start with dropping redundant features","7c167464":"And now I am going to convert gender feature to Int64","b46af2e1":"Our bag of list is our sparce_matrix array. Sparce matrix is our x axis in machine learning. We are going to use it in classification. Now I am going to split arrays into two pieces, train and split","4bb2a465":"## Naive Bayes Classification Algorithm\n\nIn this section I am going to train a naive bayes classification model. In order to do this I am going to use SKLearn library."}}