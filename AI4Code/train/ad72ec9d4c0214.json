{"cell_type":{"34ca045d":"code","41d54427":"code","e576c3b6":"code","7ebab66b":"code","b2ee2827":"code","e2c19d5b":"code","3b866521":"code","aee420df":"code","73f88221":"code","30356468":"code","2382aaf0":"code","d544945b":"markdown","9c86b26f":"markdown","8eacfec5":"markdown","07535109":"markdown","2d518be0":"markdown","b731b087":"markdown","580b8bc1":"markdown"},"source":{"34ca045d":"import tensorflow as tf\nimport tensorflow.keras as keras\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython import display\nfrom tqdm.auto import trange","41d54427":"def plot_results(images, n_cols=None, title=None):\n    \n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    \n    fig = plt.figure(figsize=(n_cols, n_rows))\n    \n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")\n        \n    plt.suptitle(title)","e576c3b6":"BATCH_SIZE = 128\nCODINGS_SIZE = 32\nN_EPOCHS = 100\nD_STEPS = 5\nGP_WEIGHT = 10.0","7ebab66b":"def prepare_data(label, batch_size):\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n    X_all = np.concatenate([X_train, X_test])\n    y_all = np.concatenate([y_train, y_test])\n    \n    X_all = X_all.astype(np.float32) \/ 255\n    X_all = X_all.reshape(-1, 28, 28, 1) * 2. - 1.\n    X_train = X_all[np.where(y_all == label)]\n\n    dataset = tf.data.Dataset.from_tensor_slices(X_train)\n    dataset = dataset.shuffle(1024)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n    \n    return dataset\n\n\ndef prepare_images(label):\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n    X_all = np.concatenate([X_train, X_test])\n    y_all = np.concatenate([y_train, y_test])\n    \n    X_all = X_all.astype(np.float32) \/ 255\n    X_all = X_all.reshape(-1, 28, 28, 1) * 2. - 1.\n    X_train = X_all[np.where(y_all == label)]\n    \n    return X_train","b2ee2827":"def build_generator():\n    inputs = keras.Input(shape=[CODINGS_SIZE])\n    x = keras.layers.Dense(7 * 7 * 128)(inputs)\n    x = keras.layers.Reshape([7, 7, 128])(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"SAME\", activation=\"selu\")(x)\n    x = keras.layers.BatchNormalization()(x)\n    skip = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"SAME\", activation=\"selu\")(x)\n    skip = keras.layers.BatchNormalization()(skip)\n    skip = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"SAME\", activation=\"selu\")(skip)\n    skip = keras.layers.BatchNormalization()(skip)\n    x = keras.layers.add([x, skip])\n    x = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"SAME\",activation=\"selu\")(x)\n    skip = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"SAME\", activation=\"selu\")(x)\n    skip = keras.layers.BatchNormalization()(skip)\n    skip = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding=\"SAME\", activation=\"selu\")(skip)\n    skip = keras.layers.BatchNormalization()(skip)\n    x = keras.layers.add([x, skip])\n    outputs = keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\",activation=\"tanh\")(x)\n    return keras.models.Model(inputs, outputs, name='generator')","e2c19d5b":"def build_discriminator():\n    return keras.models.Sequential([\n    keras.layers.Conv2D(64, kernel_size=3, strides=1, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2), input_shape=[28, 28, 1]),\n    keras.layers.Conv2D(128, kernel_size=3, strides=1, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Dropout(0.4),\n    keras.layers.Conv2D(128, kernel_size=3, strides=1, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Conv2D(128, kernel_size=3, strides=1, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"SAME\", activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Dropout(0.4),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1)\n], name='discriminator')","3b866521":"class WGAN(keras.Model):\n    def __init__(\n        self,\n        discriminator,\n        generator,\n        latent_dim,\n        discriminator_extra_steps=5,\n        gp_weight=10.0,\n    ):\n        super().__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.d_steps = discriminator_extra_steps\n        self.gp_weight = gp_weight\n\n    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n        super().compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.d_loss_fn = d_loss_fn\n        self.g_loss_fn = g_loss_fn\n\n    def gradient_penalty(self, batch_size, real_images, fake_images):\n        \"\"\" Calculates the gradient penalty.\n\n        This loss is calculated on an interpolated image\n        and added to the discriminator loss.\n        \"\"\"\n        # Get the interpolated image\n        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n        diff = fake_images - real_images\n        interpolated = real_images + alpha * diff\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(interpolated)\n            # 1. Get the discriminator output for this interpolated image.\n            pred = self.discriminator(interpolated, training=True)\n\n        # 2. Calculate the gradients w.r.t to this interpolated image.\n        grads = gp_tape.gradient(pred, [interpolated])[0]\n        # 3. Calculate the norm of the gradients.\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.reduce_mean((norm - 1.0) ** 2)\n        return gp\n\n    def train_step(self, real_images):\n        if isinstance(real_images, tuple):\n            real_images = real_images[0]\n\n        batch_size = tf.shape(real_images)[0]\n\n        # For each batch, we are going to perform the\n        # following steps:\n        # 1. Train the generator and get the generator loss\n        # 2. Train the discriminator and get the discriminator loss\n        # 3. Calculate the gradient penalty\n        # 4. Multiply this gradient penalty with a constant weight factor\n        # 5. Add the gradient penalty to the discriminator loss\n        # 6. Return the generator and discriminator losses as a loss dictionary\n\n        # Train the discriminator for `x` more steps (typically 5) as compared to\n        # one step of the generator.\n        for i in range(self.d_steps):\n            random_latent_vectors = tf.random.normal(\n                shape=(batch_size, self.latent_dim)\n            )\n            with tf.GradientTape() as tape:\n                fake_images = self.generator(random_latent_vectors, training=True)\n                fake_logits = self.discriminator(fake_images, training=True)\n                real_logits = self.discriminator(real_images, training=True)\n\n                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n                d_loss = d_cost + gp * self.gp_weight\n\n            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n            self.d_optimizer.apply_gradients(\n                zip(d_gradient, self.discriminator.trainable_variables)\n            )\n\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        with tf.GradientTape() as tape:\n            generated_images = self.generator(random_latent_vectors, training=True)\n            gen_img_logits = self.discriminator(generated_images, training=True)\n            g_loss = self.g_loss_fn(gen_img_logits)\n\n        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n        self.g_optimizer.apply_gradients(\n            zip(gen_gradient, self.generator.trainable_variables)\n        )\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}    \n    \ndef discriminator_loss(real_img, fake_img):\n    real_loss = tf.reduce_mean(real_img)\n    fake_loss = tf.reduce_mean(fake_img)\n    return fake_loss - real_loss\n\n\ndef generator_loss(fake_img):\n    return -tf.reduce_mean(fake_img)    ","aee420df":"generator = build_generator()\ndiscriminator = build_discriminator()\nprint('Generator Summary\\n\\n')\ngenerator.summary()\nprint('\\n\\nDiscriminator Summary\\n\\n')\ndiscriminator.summary()\nkeras.utils.plot_model(generator, show_shapes=True, expand_nested=True, to_file='generator.png')\nkeras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, to_file='discriminator.png')\nfig, ax = plt.subplots(1, 2, figsize=(20, 12))\nax[0].imshow(plt.imread('generator.png'))\nax[0].set_title('Generator', fontsize=18)\nax[1].imshow(plt.imread('discriminator.png'))\nax[1].set_title('Discriminator', fontsize=18)\nax[0].axis(\"off\")\nax[1].axis(\"off\")\nplt.show()","73f88221":"for i in range(10):\n    LABEL = i\n    dataset = prepare_data(LABEL, BATCH_SIZE)\n\n    generator = build_generator()\n    discriminator = build_discriminator()\n    \n    gan = WGAN(\n        discriminator=discriminator, generator=generator, \n        latent_dim=CODINGS_SIZE, discriminator_extra_steps=D_STEPS, gp_weight=GP_WEIGHT\n    )\n    gan.compile(\n        d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n        g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n        g_loss_fn=generator_loss,\n        d_loss_fn=discriminator_loss,\n    )\n    \n    fig, ax = plt.subplots(figsize=(20, 6))\n    ax.set_title(f'Learning Curve-{LABEL}', fontsize=18)\n    history = gan.fit(dataset, epochs=N_EPOCHS, verbose=1)\n    pd.DataFrame(history.history).plot(ax=ax)\n    ax.grid()\n       \n    generator.save(f'MNIST-AUG-WGAN-{LABEL}.h5')","30356468":"from scipy.linalg import sqrtm\n\ndef frechet_distance(act1, act2):\n    mu1, sigma1 = np.mean(act1, axis=0), np.cov(act1, rowvar=False)\n    mu2, sigma2 = np.mean(act2, axis=0), np.cov(act2, rowvar=False)\n    ssdiff = np.sum((mu1 - mu2)**2.0)\n    covmean = sqrtm(sigma1.dot(sigma2))\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid\n\nevaluator = keras.models.Sequential(keras.models.load_model('..\/input\/mnist-net\/mnist_net.h5').layers[:-1])\nscores = []\n\nfor i in range(10):\n    generator = keras.models.load_model(f'MNIST-AUG-WGAN-{i}.h5')\n    fake_images = generator(tf.random.normal([128, CODINGS_SIZE]))\n    embeddings_real = evaluator(prepare_images(i))\n    embeddings_fake = evaluator(fake_images)\n    scores.append(frechet_distance(embeddings_real, embeddings_fake))\n    plot_results(fake_images, 16, f'Images Generated for class {i}')                     \n    plt.show()  ","2382aaf0":"pd.Series(scores, name=\"Frechet Distance\")","d544945b":"# Generated Images","9c86b26f":"#  Wasserstein GAN with Gradient Penalty (WGAN-GP) -MNIST Augmentation","8eacfec5":"# Evaluation","07535109":"# Build the Model\n\nThe original Wasserstein GAN leverages the Wasserstein distance to produce a value function that has better theoretical properties than the value function used in the original GAN paper. WGAN requires that the discriminator (aka the critic) lie within the space of 1-Lipschitz functions. The authors proposed the idea of weight clipping to achieve this constraint. Though weight clipping works, it can be a problematic way to enforce 1-Lipschitz constraint and can cause undesirable behavior, e.g. a very deep WGAN discriminator (critic) often fails to converge.\n\nThe WGAN-GP method proposes an alternative to weight clipping to ensure smooth training. Instead of clipping the weights, the authors proposed a \"gradient penalty\" by adding a loss term that keeps the L2 norm of the discriminator gradients close to 1.\n\n### Generator\n\nFor the generator, we take in random noise and eventually transform it to the shape of the MNIST images. The general steps are:\n\n* Feed the input noise to a dense layer.\n* Reshape the output to have three dimensions. This stands for the (length, width, number of filters).\n* Perform a deconvolution (with Conv2DTranspose), reducing the number of filters by half and using a stride of `2`.\n* The final layer upsamples the features to the size of the training images. In this case 28 x 28 x 1.\n\nNotice that batch normalization is performed except for the final deconvolution layer. As best practice, `selu` is the activation used for the intermediate deconvolution while `tanh` is for the output.\n\n### Discriminator\n\nThe discriminator will use strided convolutions to reduce the dimensionality of the input images. As best practice, these are activated by LeakyRELU. The output features will be flattened and fed to a 1-unit dense layer without any activation.","2d518be0":"## Utilities","b731b087":"# Prepare the Dataset","580b8bc1":"# GAN in Action"}}