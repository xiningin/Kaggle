{"cell_type":{"50333c31":"code","145b7e30":"code","e6d4824e":"code","d201bede":"code","db20c4a6":"code","488f3a9e":"code","e75912fb":"code","3716bf6a":"code","0cf677f0":"code","2deaabf9":"code","8212d397":"code","56a5438f":"code","2ba1f655":"code","b846c682":"code","d34c5111":"code","4cc7dba5":"code","ecb6658e":"markdown","e2de0dc8":"markdown","e3cd9719":"markdown","02763cff":"markdown","dbe40d21":"markdown","c9f658ce":"markdown","c72b3361":"markdown","7cc179f9":"markdown","e23734c4":"markdown","a08ed0b2":"markdown","326e4701":"markdown"},"source":{"50333c31":"import numpy as np \nimport pandas as pd\nimport os\nimport tqdm\nimport gc\nimport feather","145b7e30":"PATH = '..\/input\/'","e6d4824e":"print(os.listdir(\"..\/input\"))","d201bede":"%%time\n\nwith open(f'{PATH}NGS-2016-pre.csv') as file:\n    n_rows = len(file.readlines())\nprint('2016 pre rows:', n_rows)\n\nwith open(f'{PATH}NGS-2016-reg-wk1-6.csv') as file:\n    n_rows = len(file.readlines())\nprint('2016 wk1-6 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2016-reg-wk7-12.csv') as file:\n    n_rows = len(file.readlines())\nprint('2016 wk7-12 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2016-reg-wk13-17.csv') as file:\n    n_rows = len(file.readlines())\nprint('2016 wk13-17 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2016-post.csv') as file:\n    n_rows = len(file.readlines())\nprint('2016 post rows:', n_rows)\n\nwith open(f'{PATH}NGS-2017-pre.csv') as file:\n    n_rows = len(file.readlines())\nprint('2017 pre rows:', n_rows)\n\nwith open(f'{PATH}NGS-2017-reg-wk1-6.csv') as file:\n    n_rows = len(file.readlines())\nprint('2017 wk1-6 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2017-reg-wk7-12.csv') as file:\n    n_rows = len(file.readlines())\nprint('2017 wk7-12 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2017-reg-wk13-17.csv') as file:\n    n_rows = len(file.readlines())\nprint('2017 wk13-17 rows:', n_rows)\n\nwith open(f'{PATH}NGS-2017-post.csv') as file:\n    n_rows = len(file.readlines())\nprint('2017 post rows:', n_rows)","db20c4a6":"# Only load the first 5 rows to get an idea of what the data look like\ndf_temp = pd.read_csv(f'{PATH}NGS-2016-pre.csv', nrows=5)\ndf_temp.head()","488f3a9e":"# Get information on the datatypes\ndf_temp.info()","e75912fb":"# Find out the smallest data type possible for each numeric feature\nfloat_cols = df_temp.select_dtypes(include=['float'])\nint_cols = df_temp.select_dtypes(include=['int'])\n\nfor cols in float_cols.columns:\n    df_temp[cols] = pd.to_numeric(df_temp[cols], downcast='float')\n    \nfor cols in int_cols.columns:\n    df_temp[cols] = pd.to_numeric(df_temp[cols], downcast='integer')\n\nprint(df_temp.info())","3716bf6a":"dtypes = {'Season_Year': 'int16',\n         'GameKey': 'int16',\n         'PlayID': 'int16',\n         'GSISID': 'float32',\n         'Time': 'str',\n         'x': 'float32',\n         'y': 'float32',\n         'dis': 'float32',\n         'o': 'float32',\n         'dir': 'float32',\n         'Event': 'str'}\n\ncol_names = list(dtypes.keys())","0cf677f0":"ngs_files = ['NGS-2016-pre.csv',\n             'NGS-2016-reg-wk1-6.csv',\n             'NGS-2016-reg-wk7-12.csv',\n             'NGS-2016-reg-wk13-17.csv',\n             'NGS-2016-post.csv',\n             'NGS-2017-pre.csv',\n             'NGS-2017-reg-wk1-6.csv',\n             'NGS-2017-reg-wk7-12.csv',\n             'NGS-2017-reg-wk13-17.csv',\n             'NGS-2017-post.csv']","2deaabf9":"# Load each ngs file and append it to a list. \n# We will turn this into a DataFrame in the next step\n\ndf_list = []\n\nfor i in tqdm.tqdm(ngs_files):\n    df = pd.read_csv(f'{PATH}'+i, usecols=col_names,dtype=dtypes)\n    \n    df_list.append(df)","8212d397":"# Merge all dataframes into one dataframe\nngs = pd.concat(df_list)\n\n# Delete the dataframe list to release memory\ndel df_list\ngc.collect()\n\n# Convert Time to datetime\nngs['Time'] = pd.to_datetime(ngs['Time'], format='%Y-%m-%d %H:%M:%S')\n\n# See what we have loaded\nngs.info()","56a5438f":"# Turn Saeson_Year into a category and ultimately into an integer (this doesn't seem necessary)\nif False:\n    ngs['Season_Year'] = ngs['Season_Year'].astype('category').cat.codes","2ba1f655":"# There are 2536 out of 66,492,490 cases where GSISID is NAN. Let's drop those to convert the data type\nngs = ngs[~ngs['GSISID'].isna()]","b846c682":"# Convert GSISID to integer\nngs['GSISID'] = ngs['GSISID'].astype('int32')","d34c5111":"# Save to feather so we can use it in other kernels\nngs.reset_index(drop=True).to_feather(f'ngs.feather')","4cc7dba5":"!ls -lh","ecb6658e":"* NGS-2016-pre.csv\n* NGS-2016-reg-wk1-6.csv\n* NGS-2016-reg-wk7-12.csv\n* NGS-2016-reg-wk13-17.csv\n* NGS-2016-post.csv\n\n\n* NGS-2017-pre.csv\n* NGS-2017-reg-wk1-6.csv\n* NGS-2017-reg-wk7-12.csv\n* NGS-2017-reg-wk13-17.csv\n* NGS-2017-post.csv","e2de0dc8":"## How many rows are there per file","e3cd9719":"By 'downcasting' the numeric features we have almost halved the memory consumption. However, not all data types are correct yet. \n1. From the data disctionary we know that **Event** is text and should be data type 'object'. \n2. And **Time** is obviously datetime. It's faster though importing it as 'string' and then converting it.\n3. We can also go a step further with **SeasonYear**. The feature only contains two values: 2016 and 2017. If we changed that to 0 and 1, then we can reduce the data type further from int16 to int8, saving more memory. \n4. **GSISID** is only an integer and not a float. However, there are NANs in the data, which prevent us from converting this straight away.\n\nNow let's define the data types and then upload the NGS files.","02763cff":"## Import Libraries","dbe40d21":"## What data are available","c9f658ce":"## Load the Data and Define Data Types","c72b3361":"All files apart from the NGS files are quite small. The NGS files however, each can contain up to 9 million rows. In that case we need to reduce the amount of memory they take up. In this kernel I will show you how to do this in an easy way.\n\nThe NGS datasets contains player position, speed and direction data for each player during the entire course of the play. The NGS dataset is the only dataset that contains Timeas a variable. ","7cc179f9":"All NGS file have the same structure, which means we can load them individually and concatenate them afterwards. Before doing that we can have a sneak peak at what the data look like and then define the data types before loading the csv files. We coud obviously do this once we have loaded the files but this way saves time and memory right away. ","e23734c4":"Let's focus only on the NGS files. Below are the files.","a08ed0b2":"## Final Steps\n\n1. We can turn Season_Year into a category with the values 0 and 1 to save more memory. The feature only contains the values 2016 and 2017.\n2. We can delete the NANs in GSISD and then turn it into an integer. \n3. We can save this as a feather file, which is much faster to load. But we might have to define the data types again after loading.","326e4701":"This concludes this tutorial. I hope you found it useful and I'm keen to hear any feedback and how to improve things."}}