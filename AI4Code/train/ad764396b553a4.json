{"cell_type":{"4cd59804":"code","773295a2":"code","3f2876ad":"code","094266a9":"code","02a1096f":"code","9e12bd70":"code","57876f72":"code","00c4efa9":"code","bd06f9c6":"code","39d684f8":"code","8c0a8c55":"code","9ded778d":"code","21bb7f58":"code","661d7410":"code","6072405b":"code","c0001f5d":"code","b2e3f681":"code","ff24a146":"code","5c52abce":"code","818aac7b":"code","f187a65c":"code","dc4d2e5e":"markdown","f92fc687":"markdown","a7b894ec":"markdown","3fa67e78":"markdown","a1542fab":"markdown","d4eb99fb":"markdown"},"source":{"4cd59804":"import numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\nfrom collections import defaultdict","773295a2":"from keras.applications.densenet import DenseNet121\nfrom keras.applications.densenet import preprocess_input\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model, load_model\nfrom keras.layers import *\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import *\n\n# from keras.utils import multi_gpu_model","3f2876ad":"DATA_DIR = '..\/input' #Or wherever your data is\n# Test with training the stage 1 tuning labels (come up with your own labels)\nCHALLENGE_DATA_DIR = DATA_DIR + '\/'\nIMG_DIR = CHALLENGE_DATA_DIR + '\/stage_1_test_images\/stage_1_test_images'","094266a9":"tuning_labels = pd.read_csv(CHALLENGE_DATA_DIR + '\/tuning_labels.csv', \n                            names=['ImageID', 'Caption'],\n                            index_col=['ImageID'])\ntuning_labels.head()","02a1096f":"tuning_labels_freq = defaultdict(int)\n\nfor r in tuning_labels['Caption']:\n    labels = r.split()\n    for l in labels:\n        tuning_labels_freq[l] += 1\n\ntuning_labels_list = list(tuning_labels_freq.keys())\nprint('Unique tuning labels', len(tuning_labels_list))\n","9e12bd70":"label_2_idx = {}\nidx_2_label = {}\nfor i,v in enumerate(tuning_labels_list):\n    label_2_idx[v] = i\n    idx_2_label[i] = v","57876f72":"class_descriptions = pd.read_csv(CHALLENGE_DATA_DIR + '\/class-descriptions.csv', index_col='label_code')\n\nclass_descriptions.loc['\/m\/0104x9kv']['description']","00c4efa9":"all_img_ids = list(tuning_labels.index.unique())","bd06f9c6":"train_ids, test_ids = train_test_split(all_img_ids, test_size=0.01, random_state=21)\ntrain_ids, valid_ids = train_test_split(train_ids, test_size=0.1, random_state=21)\n\nprint('Training on {} samples'.format(len(train_ids)))\nprint('Validating on {} samples'.format(len(valid_ids)))\nprint('Testing on {} samples'.format(len(test_ids)))","39d684f8":"N_CLASSES = len(label_2_idx)\nBATCH_SIZE = 8\nINPUT_SIZE = 224\nprint(N_CLASSES)","8c0a8c55":"def caption_2_one_hot(caption, n_classes=1, lookup_dict=None):\n    y = np.zeros((n_classes))\n    for w in caption.split():\n        idx = lookup_dict[w]\n        y[idx] = 1\n    return y","9ded778d":"def ImageDataGen(ids, df,\n                 lookup_dict=label_2_idx,\n                 n_classes=N_CLASSES,\n                 img_dir=IMG_DIR, input_size=INPUT_SIZE,\n                 bs=BATCH_SIZE, returnIds=False):\n    while True:\n        for start in range(0, len(ids), bs):\n            x_batch = []\n            y_batch = []\n            end = min(start+bs, len(ids))\n            sample = ids[start:end]\n            for img_id in sample:\n                img = cv.imread('{}\/{}.jpg'.format(img_dir, img_id))\n                if img is not None:\n                    img = cv.resize(img, (input_size, input_size))\n                    img = preprocess_input(img.astype(np.float32))\n                    x_batch.append(img)\n                    caption = df.loc[img_id]['Caption']\n                    y = caption_2_one_hot(caption, n_classes=n_classes, lookup_dict=lookup_dict)\n                    y_batch.append(y)\n                    \n            x_batch = np.array(x_batch, np.float32)\n            y_batch = np.array(y_batch, np.float32)\n            \n            if returnIds:\n                yield x_batch, y_batch, sample\n            else:\n                yield x_batch, y_batch","21bb7f58":"test_gen = ImageDataGen(test_ids, tuning_labels)\ntest_batch = next(test_gen)\nfig = plt.figure(figsize=(20, 8))\nfor sample_idx in range(BATCH_SIZE):\n    ax = fig.add_subplot(3,3, sample_idx + 1)\n    ax.set_title(','.join([class_descriptions.loc[idx_2_label[i]]['description'] for i in (np.argwhere(test_batch[1][sample_idx]>0)).flatten()]))\n    ax.imshow(test_batch[0][sample_idx])\n    ax.set_axis_off()\nplt.show()\n    ","661d7410":"def ClsModel(n_classes=1, input_shape=(224,224,3)):\n    base_model = DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n    x = AveragePooling2D(pool_size=(3,3), name='avg_pool')(base_model.output)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu', name='dense_post_pool')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_classes, activation='sigmoid', name='predictions')(x)\n    model = Model(inputs=base_model.input, output=output)\n    return model","6072405b":"model = ClsModel(N_CLASSES)\nmodel.summary()","c0001f5d":"model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","b2e3f681":"model_checkpoint = ModelCheckpoint(('.\/densenet.{epoch:02d}.hdf5'),\n                                   monitor='val_loss',\n                                   verbose=1,\n                                   save_best_only=True,\n                                   save_weights_only=True)\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                                         patience=2, verbose=1)\n\ncallbacks = [model_checkpoint, reduce_learning_rate]","ff24a146":"train_gen = ImageDataGen(train_ids, tuning_labels)\nvalid_gen = ImageDataGen(valid_ids, tuning_labels)","5c52abce":"model.fit_generator(generator=train_gen, \n                    epochs=25, \n                    steps_per_epoch=np.ceil(len(train_ids)\/BATCH_SIZE),\n                   callbacks=callbacks,\n                    validation_data=valid_gen,\n                    validation_steps=np.ceil(len(valid_ids) \/ BATCH_SIZE))","818aac7b":"test_preds = model.predict(test_batch[0])","f187a65c":"fig = plt.figure(figsize=(20, 8))\npred_cutoff = 0.2\nfor sample_idx in range(BATCH_SIZE):\n    ax = fig.add_subplot(3,3, sample_idx + 1)\n    ax.set_title(','.join([class_descriptions.loc[idx_2_label[i]]['description'] for i in (np.argwhere(test_preds[sample_idx]>pred_cutoff)).flatten()]))\n    ax.imshow(test_batch[0][sample_idx])\n    ax.set_axis_off()\nplt.show()\n    ","dc4d2e5e":"# Get list of unique classes in tuning dataset","f92fc687":"# Load our (fake) datatset\nThis dataset should actually be all the images inside train_human_labels, train_machine_labels,  and train_bounding_boxes\nBut for demo purposes we'll just use the tuning labels as the dataset","a7b894ec":"# Define Model","3fa67e78":"# Prepare labels","a1542fab":"# Test Predict","d4eb99fb":"# Multi-Label Classification Example using Keras\n\nThis notebook is an example of a baseline model I trained. In this example, I used the tuning labels as training data, validation data, and test data. However the real baseline model used 1.7M training images from the Open Images Dataset and training labels created from concatenating thr train_human_labels, train_machine_labels, and train_bounding_boxes."}}