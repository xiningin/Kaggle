{"cell_type":{"627d6505":"code","3c517fdc":"code","21093f5e":"code","23558276":"code","395695c6":"code","d9e1602a":"code","dbc274a4":"code","b556a6de":"code","acc273c6":"code","a9e452f2":"code","549c91ba":"code","a6611b98":"code","930a3805":"code","2788ede5":"code","fb2344df":"code","598c3d8e":"code","a676fe98":"code","0a02172c":"code","07134abc":"code","cecfcc17":"code","6b96a179":"code","c63abe75":"code","5d6d1237":"code","690701e2":"code","537f0edf":"code","93ed7023":"code","4e10a241":"code","573be098":"code","414af7d3":"code","91247c99":"code","7ef38e1c":"code","47a05dae":"code","0f7777d6":"code","7d8a8e5b":"code","d5b0d034":"code","0b2765d1":"code","f8f4cff6":"code","db370fb7":"code","c04295bf":"code","afa1ae66":"code","49ba6860":"code","d9e000b4":"code","b1708fee":"code","10b206e1":"code","4dc30862":"code","20d4413f":"code","b45df90c":"code","0220f4a9":"code","c049a7b9":"code","81c8e8f7":"code","25931edb":"code","c7aa07c8":"code","e576ac6b":"markdown","2fa3d657":"markdown","a5de0d6b":"markdown","b27c9795":"markdown","02f811e3":"markdown","46bb0777":"markdown","da8f2d78":"markdown","8289c895":"markdown","c124865b":"markdown","0364b883":"markdown","7c8aef42":"markdown","e85852c8":"markdown","7d2cf775":"markdown","ef123cd3":"markdown","f89f8e52":"markdown","280617d0":"markdown","3a199e93":"markdown","4277e4bc":"markdown","5270f750":"markdown","985138e7":"markdown","de7fe87f":"markdown","80bcad5c":"markdown","fc9a0372":"markdown","f09e9bdb":"markdown","c6d5ae7b":"markdown","e115cc0b":"markdown","ce0179cc":"markdown","a8ad1f7d":"markdown","60cfb80d":"markdown","8674afda":"markdown"},"source":{"627d6505":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport PIL\nimport gc\nimport psutil\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.compat.v1 import set_random_seed\nfrom tqdm import tqdm\nfrom math import ceil\nimport math\nimport sys\nimport gc\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import array_to_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.activations import softmax\nfrom keras.activations import elu\nfrom keras.activations import relu\nfrom keras.optimizers import Adam\nfrom keras.optimizers import RMSprop\nfrom keras.optimizers import SGD\nfrom keras.layers.normalization import BatchNormalization\n\ngc.enable()\n\nprint(os.listdir(\"..\/input\/\"))","3c517fdc":"SEED = 7\nnp.random.seed(SEED)\nset_random_seed(SEED)\ndir_path = \"..\/input\/drdataset2\/DR\/\"\nIMG_DIM = 256  # 224 399 #\nBATCH_SIZE = 12\nCHANNEL_SIZE = 3\nNUM_EPOCHS = 17\nTRAIN_DIR = 'train_image'\nTEST_DIR = 'test_image'\nFREEZE_LAYERS = 2  # freeze the first this many layers for training\nCLASSS = {0: \"No DR\", 1: \"Non-Proliferative DR\", 2: \"Proliferative DR\", 3: \"Severe\", 4: \"Proliferative DR\"}","21093f5e":"df_train = pd.read_csv(os.path.join(dir_path, \"train.csv\"))\ndf_test = pd.read_csv(os.path.join(dir_path, \"test.csv\"))\nNUM_CLASSES = df_train['diagnosis'].nunique()","23558276":"print(\"Training set has {} samples and {} classes.\".format(df_train.shape[0], df_train.shape[1]))\nprint(\"Testing set has {} samples and {} classes.\".format(df_test.shape[0], df_test.shape[1]))","395695c6":"x_train, x_test, y_train, y_test = train_test_split(df_train.id_code, df_train.diagnosis, test_size=0.15,\n                                                    random_state=SEED, stratify=df_train.diagnosis)","d9e1602a":"chat_data = df_train.diagnosis.value_counts()\nchat_data.plot(kind='bar');\nplt.title('Sample Per Class');\nplt.show()\nplt.pie(chat_data, autopct='%1.1f%%', shadow=True, labels=[\"No DR\", \"Non-Proliferative DR (NPDR)\", \"Proliferative DR (PDR)\"])\nplt.title('Per class sample Percentage');\nplt.show()\n","dbc274a4":"# Train & Test samples ratio\n# Plot Data\nlabels = 'Train', 'Test'\nsizes = df_train.shape[0], df_test.shape[0]\ncolors = 'lightskyblue', 'lightcoral'\n# Plot\nplt.figure(figsize=(7, 5))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\nplt.axis('equal')\nplt.show()","b556a6de":"def draw_img(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(16, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}\/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx \/\/ 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axis[row, col].imshow(img)\n    plt.suptitle(class_label)\n    plt.show()","acc273c6":"CLASS_ID = 0\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","a9e452f2":"CLASS_ID = 1\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","549c91ba":"CLASS_ID = 2\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","a6611b98":"CLASS_ID = 'Test DataSet'\ndraw_img(df_test.sample(12, random_state=SEED), 'test_image', CLASS_ID)","930a3805":"def check_max_min_img_height_width(df, img_dir):\n    max_Height , max_Width =0 ,0\n    min_Height , min_Width =sys.maxsize ,sys.maxsize \n    for idx, row in df.iterrows():\n        imgPath=os.path.join(dir_path,f\"{img_dir}\/{row['id_code']}.png\") \n        img=cv2.imread(imgPath)\n        H,W=img.shape[:2]\n        max_Height=max(H,max_Height)\n        max_Width =max(W,max_Width)\n        min_Height=min(H,min_Height)\n        min_Width =min(W,min_Width)\n    return max_Height, max_Width, min_Height, min_Width","2788ede5":"check_max_min_img_height_width(df_train, TRAIN_DIR)","fb2344df":"check_max_min_img_height_width(df_test, TEST_DIR)","598c3d8e":"# Display some random images from Data Set with class categories ing gray\nfigure = plt.figure(figsize=(20, 16))\nfor target_class in (y_train.unique()):\n    for i, (idx, row) in enumerate(\n            df_train.loc[df_train.diagnosis == target_class].sample(5, random_state=SEED).iterrows()):\n        ax = figure.add_subplot(5, 5, target_class * 5 + i + 1)\n        imagefile = f\"..\/input\/drdataset2\/DR\/train_image\/{row['id_code']}.png\"\n        img = cv2.imread(imagefile)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        plt.imshow(img, cmap='gray')\n        ax.set_title(CLASSS[target_class])","a676fe98":"\n\ndef draw_img_light(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}\/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx \/\/ 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        img = cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMG_DIM\/10) ,-4 ,128) # the trick is to add this line\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        axis[row, col].imshow(img, cmap='gray')\n    plt.suptitle(class_label)\n    plt.show()","0a02172c":"CLASS_ID = 0\ndraw_img_light(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","07134abc":"CLASS_ID = 1\ndraw_img_light(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","cecfcc17":"CLASS_ID = 2\ndraw_img_light(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_image', CLASSS[CLASS_ID])","6b96a179":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #       print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #       print(img.shape)\n            return img","c63abe75":"def circle_crop(img):   \n    \"\"\"\n    Create circular crop around eye centre    \n    \"\"\"    \n    \n    #img = cv2.imread(img)\n    height, width, depth = img.shape\n    largest_side = np.max((height, width))\n    img = cv2.resize(img, (largest_side, largest_side))  \n    \n    x = int(width\/2)\n    y = int(height\/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    \n    return img ","5d6d1237":"def load_ben_color(image, sigmaX=25):\n    #image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #image = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    #image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n    image = circle_crop(image)  \n    return image","690701e2":"%%time\n\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(y_train.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"..\/input\/drdataset2\/DR\/train_image\/{row['id_code']}.png\"\n        image = load_ben_color(cv2.imread(path))\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","537f0edf":"# print(\"available RAM:\", psutil.virtual_memory())\ngc.collect()\n# print(\"available RAM:\", psutil.virtual_memory())\n\ndf_train.id_code = df_train.id_code.apply(lambda x: x + \".png\")\ndf_test.id_code = df_test.id_code.apply(lambda x: x + \".png\")\n#df_train['diagnosis'] = df_train['diagnosis'].astype('str')\n#df_test['diagnosis'] = df_test['diagnosis'].astype('str')","93ed7023":"df_train = pd.concat([df_train,pd.get_dummies(df_train['diagnosis'], prefix='diagnosis')],axis=1)\ndf_train.drop(['diagnosis'],axis=1, inplace=True)\ndf_train['diagnosis_0'] = df_train['diagnosis_0'].astype('str')\ndf_train['diagnosis_1'] = df_train['diagnosis_1'].astype('str')\ndf_train['diagnosis_2'] = df_train['diagnosis_2'].astype('str')","4e10a241":"df_train","573be098":"df_test = pd.concat([df_test,pd.get_dummies(df_test['diagnosis'], prefix='diagnosis')],axis=1)\ndf_test.drop(['diagnosis'],axis=1, inplace=True)\ndf_test['diagnosis_0'] = df_test['diagnosis_0'].astype('str')\ndf_test['diagnosis_1'] = df_test['diagnosis_1'].astype('str')\ndf_test['diagnosis_2'] = df_test['diagnosis_2'].astype('str')","414af7d3":"# Creating the imageDatagenerator Instance \ndatagenerator=ImageDataGenerator(#rescale=1.\/255,\n                                        validation_split=0.15, \n                                        horizontal_flip=True,\n                                        vertical_flip=True, \n                                        #rotation_range=40, \n                                        #zoom_range=0.2, \n                                        preprocessing_function=load_ben_color,\n                                        shear_range=0.1,\n                                        fill_mode='nearest')","91247c99":"#imgPath = f\"..\/input\/aptos2019-blindness-detection\/train_images\/cd54d022e37d.png\"\nimgPath = f\"..\/input\/drdataset2\/DR\/train_image\/02685f13cefd.png\"\n# Loading image\nimg = cv2.imread(imgPath)\n#img = x_train[0]\nimg = cv2.resize(img, (IMG_DIM, IMG_DIM))\ndata = img_to_array(img)\nsamples =np.expand_dims(data, 0)\ni=5\nit=datagenerator.flow(samples , batch_size=1)\nfor i in range(5):\n    plt.subplot(230 + 1 + i)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","7ef38e1c":"train_datagen=ImageDataGenerator(rescale=1.\/255,\n                                        validation_split=0.15, \n                                        horizontal_flip=True,\n                                        vertical_flip=True, \n                                        #rotation_range=40, \n                                        #zoom_range=0.2, \n                                        preprocessing_function=load_ben_color,\n                                        shear_range=0.1,\n                                        #fill_mode='nearest'\n                                )\ntest_datagen=ImageDataGenerator(rescale=1.\/255, preprocessing_function=load_ben_color)","47a05dae":"train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    #directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                    directory=\"..\/input\/drdataset2\/DR\/train_image\/\",\n                                                    x_col=\"id_code\",\n                                                    y_col=[\"diagnosis_0\",\"diagnosis_1\",\"diagnosis_2\"],\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"raw\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='training',\n                                                    shuffle=True,\n                                                    seed=SEED,\n                                                    )\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    #directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                    directory=\"..\/input\/drdataset2\/DR\/train_image\/\",                                                    \n                                                    x_col=\"id_code\",\n                                                    y_col=[\"diagnosis_0\",\"diagnosis_1\",\"diagnosis_2\"],\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"raw\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='validation',\n                                                    shuffle=True,\n                                                    seed=SEED\n                                                    )\n\n#del x_train\n#del x_test\n#del y_train\n#del y_test\ngc.collect()\n#  color_mode= \"grayscale\",","0f7777d6":"test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                #directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                directory=\"..\/input\/drdataset2\/DR\/test_image\/\",                                                    \n                                                x_col=\"id_code\",\n                                                y_col=[\"diagnosis_0\",\"diagnosis_1\",\"diagnosis_2\"],\n                                                batch_size=1,\n                                                class_mode=\"raw\",\n                                                target_size=(IMG_DIM, IMG_DIM),\n                                                shuffle=False,\n                                                )","7d8a8e5b":"def create_resnet(img_dim, CHANNEL, n_class):\n    input_tensor = Input(shape=(img_dim, img_dim, CHANNEL))\n    base_model = ResNet50(weights=None, include_top= False, input_tensor=input_tensor)\n    base_model.load_weights('..\/input\/resnet50weightsfile\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(2048, activation=elu)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(1024, activation=elu)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(512, activation=elu)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    output_layer = Dense(n_class, activation='softmax', name=\"Output_Layer\")(x)\n    model_resnet = Model(input_tensor, output_layer)\n\n    return model_resnet\n\ngc.collect()\nmodel_resnet = create_resnet(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)\nmodel_resnet.summary()","d5b0d034":"early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='auto')\n# Reducing the Learning Rate if result is not improving. \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=3, factor=0.2, min_lr=1e-8, mode='auto',\n                              verbose=1)\nNUB_TRAIN_STEPS = train_generator.n \/\/ train_generator.batch_size\nNUB_VALID_STEPS = valid_generator.n \/\/ valid_generator.batch_size\n\nNUB_TRAIN_STEPS, NUB_VALID_STEPS","0b2765d1":"model_resnet.layers[0].trainable =False\nlr = 1e-3\noptimizer = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True) # Adam(lr=lr, decay=0.01) \nmodel_resnet.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n# model.summary()\ngc.collect()\n\nmodel_resnet.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=5,\n                                     #use_multiprocessing=True,\n                                     #workers=3,\n                                     shuffle=True, \n                                     #callbacks=[early_stop, reduce_lr],\n                                     verbose=1)\n#gc.collect()","f8f4cff6":"# # Layers \n# for i, lay in enumerate(model_resnet.layers):\n#     print(i,lay.name)\n# Training All Layers\n\nfor layers in model_resnet.layers[10:-1]:\n    layers.trainable = True\n    \n    \nlr = 1e-3\noptimizer = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True) # Adam(lr=lr, decay=0.01) \nmodel_resnet.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n# model.summary()\ngc.collect()","db370fb7":"history1 = model_resnet.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=NUM_EPOCHS,\n                                     #use_multiprocessing=True,\n                                     #workers=3,\n                                     shuffle=True, \n                                     callbacks=[early_stop, reduce_lr],\n                                     verbose=1)\n#gc.collect()","c04295bf":"model_resnet.save(\"resnet_600.h5\")\nmodel_resnet.save_weights(\"resnet_600_weights.h5\")\n\n\n#from keras.models import model_from_json\n#model_json = model.to_json()\n#with open(\"model.json\", \"w\") as json_file:\n#    json_file.write(model_json)\n\n#model_yaml=model.to_yaml()\n#with open(\"model.yaml\",\"w\") as yaml_file:\n#    yaml_file.write(model_yaml)\n#model.save_weights(\"model.h5\")","afa1ae66":"score, acc = model_resnet.evaluate_generator(train_generator, steps=150, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\nprint(score, acc)","49ba6860":"def design_model():\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=(2, 2), input_shape=[IMG_DIM, IMG_DIM, CHANNEL_SIZE], activation=relu))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(rate=0.2))\n    model.add(Conv2D(filters=32, kernel_size=(2, 2), activation=relu))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(rate=0.2))\n    model.add(Conv2D(filters=64, kernel_size=(2, 2), activation=relu))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(rate=0.2))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(units=256, activation=relu))\n    #model.add(Dropout(rate=0.2))\n    model.add(Dense(units=512, activation=relu))\n    #model.add(Dropout(rate=0.2))\n    model.add(Dense(3, activation='softmax'))\n    return model\n\ngc.collect()\n\nmodel = design_model()\nmodel.summary()","d9e000b4":"model.compile(optimizer=Adam(lr = 0.001) , loss='categorical_crossentropy', metrics=['accuracy'])","b1708fee":" history2 = model.fit_generator(generator=train_generator,\n                     validation_data=valid_generator,\n                     steps_per_epoch=NUB_TRAIN_STEPS,\n                     validation_steps=NUB_VALID_STEPS,\n                     verbose=1,\n                     use_multiprocessing=True,\n                     workers=3,\n                     callbacks=[early_stop, reduce_lr],\n                     shuffle=True,\n                     max_queue_size=10,\n                     epochs=NUM_EPOCHS)","10b206e1":"model.save(\"CNN_new.h5\")\nmodel.save_weights(\"CNN_new_weights.h5\")","4dc30862":"score, acc = model.evaluate_generator(test_generator, steps=1136, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\nprint(score, acc)","20d4413f":"val_acc1 = history1.history['val_accuracy']\nval_acc2 = history2.history['val_accuracy']\n\nplt.plot(val_acc1, label=\"accuracy\")\nplt.plot(val_acc2)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Val Accuracy\")\nplt.legend(['ResNet50', 'CNN'])\nplt.plot(np.argmax(history1.history[\"val_accuracy\"]), np.max(history1.history[\"val_accuracy\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","b45df90c":"accu = history1.history['accuracy']\nval_acc = history1.history['val_accuracy']\n\nplt.plot(accu, label=\"accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['accuracy', 'val_accuracy'])\nplt.plot(np.argmax(history1.history[\"val_accuracy\"]), np.max(history1.history[\"val_accuracy\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","0220f4a9":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history1.history[\"loss\"], label=\"loss\")\nplt.plot(history1.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history1.history[\"val_loss\"]), np.min(history1.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","c049a7b9":"accu = history2.history['accuracy']\nval_acc = history2.history['val_accuracy']\n\nplt.plot(accu, label=\"accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['accuracy', 'val_accuracy'])\nplt.plot(np.argmax(history2.history[\"val_accuracy\"]), np.max(history2.history[\"val_accuracy\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","81c8e8f7":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history2.history[\"loss\"], label=\"loss\")\nplt.plot(history2.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history2.history[\"val_loss\"]), np.min(history2.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","25931edb":"#df_class = pd.concat([df_class,pd.get_dummies(df_class['diagnosis'], prefix='diagnosis')],axis=1)\n#df_class['diagnosis_0']=list(df_class['diagnosis']-1)\n#df_class['diagnosis_1']=list(df_class['diagnosis'])\n#df_class['diagnosis_2']=list(df_class['diagnosis']-1)\n#df_class.drop(['diagnosis'],axis=1, inplace=True)\n\n","c7aa07c8":"#df_class['diagnosis'] = df_class['diagnosis'].astype('str')\n#df_class = pd.concat([df_class,pd.get_dummies(df_class['diagnosis'], prefix='diagnosis')],axis=1)\n#df_class.drop(['diagnosis'],axis=1, inplace=True)\n#df_class['diagnosis_0'] = df_class['diagnosis_0'].astype('str')\n#df_class['diagnosis_1'] = df_class['diagnosis_1'].astype('str')\n#df_class['diagnosis_2'] = df_class['diagnosis_2'].astype('str')","e576ac6b":"<a id=\"6\"><\/a>\n### Split DataSet","2fa3d657":"# Sample User interface","a5de0d6b":"#del df_class\ndf_class = pd.read_csv(\"..\/input\/drdataset5\/DR_categorical\/0.csv\")","b27c9795":"<a id=\"8\"><\/a>\n# CNN-Model Architecture Design","02f811e3":"### EarlyStopping and Learning Rate","46bb0777":"<a id=\"3\"><\/a>\n## Data Visualization\n","da8f2d78":"> > ## Diabetic Retinopath detection with CNN\n### ---\n### Diabetic retinopathy affects blood vessels in the light-sensitive tissue called the retina that lines the back of the eye. It is the most common cause of vision loss among people with diabetes and the leading cause of vision impairment and blindness among working-age adults. It don't have any earaly symtoms. As of now, Retena photography is a way to detect the stage of Blindness. Automating it with ml, will help a lot in health domain. \n \n### ---------------------------------------\n### 1. [Import Required Libraries](#1)\n### 2. [Loading Data ](#2)\n### 3. [Data Visualization](#3)\n### 4. [Train and Test dataset](#4)\n### 5. [Data Pre-Processing](#6)\n### 6. [Image Data Generator](#7)\n### 7. [Model Architecture Design](#8)\n### 8. [Keras Callback Funcations](#9)\n### 9. [Transfer Learning](#10)\n### 10. [Validation Accuracy & Loss](#11)\n### 11. [Validation Accuracy](#12)\n### 12. [Test-Time Augmentation](#13)\n### 13. [Visualization Test Result](#14)\n### ------------------------------------\n\n\n## Stages Of Diabetic Retinopathy\n### - NO DR\n### - Non-Proliferative DR (NPDR)\n### - Proliferative DR (PDR)","8289c895":"<a id=\"6\"><\/a>\n## Max Min Height and Width","c124865b":"# Transfer Learning on ResNet50","0364b883":"tta_steps = 1\npreds_tta = []\nfor i in tqdm(range(tta_steps)):\n    dummy_generator.reset()\n    preds = classifier.predict_generator(generator=dummy_generator, steps=ceil(df_class.shape[0]))\n    #     print('Before ', preds.shape)\n    preds_tta.append(preds)\n#     print(i,  len(preds_tta))","7c8aef42":"dummy_datagen=ImageDataGenerator(rescale=1.\/255, preprocessing_function=load_ben_color)\ndummy_generator = dummy_datagen.flow_from_dataframe(dataframe=df_class,\n                                                    #directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n                                                    directory=\"..\/input\/drdataset5\/DR_categorical\/0\/\",                                                    \n                                                    x_col=\"id_code\",\n                                                    #y_col=\"diagnosis\",\n                                                    #y_col=[\"diagnosis_0\",\"diagnosis_1\",\"diagnosis_2\"],\n                                                    batch_size=1,\n                                                    class_mode=None,\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    #shuffle=False,\n                                                   seed = 7\n                                                  )","e85852c8":"\n## Image Data Generator","7d2cf775":"# Display Validation Accuracy & Loss\n","ef123cd3":"### Resnet","f89f8e52":"## Generator Pred","280617d0":"df_class.id_code = df_class.id_code.apply(lambda x: x + \".png\")\ndf_class['id_code'] = df_class['id_code'].astype('str')","3a199e93":"### CNN","4277e4bc":"#Label Dictionary\nlabel_maps = {0: 'No DR', 1: 'Non-Proliferative DR', 2: 'Proliferative DR'}\nlabel =[label_maps[k] for k in predicted_class_indices]\n\nprint(label)","5270f750":"<a id=\"1\"><\/a> \n# Import Libraries","985138e7":"from keras.models import load_model\nclassifier= load_model(\"..\/input\/drmodels\/model_saves\/resnet_2048.h5\")\n\nPatient101 = \"..\/input\/drdataset2\/DR\/train_images\/4e54ccfd49b2.png\"\nPatient102 = \"..\/input\/drdataset2\/DR\/train_images\/7a06ea127e02.png\"\nPatient103 = \"..\/input\/drdataset2\/DR\/train_images\/1d3e9b939732.png\"\n\nPatient201 = \"..\/input\/drdataset2\/DR\/train_images\/059bc89df7f4.png\"\nPatient202 = \"..\/input\/drdataset2\/DR\/train_images\/435d900fa7b2.png\"\nPatient203 = \"..\/input\/drdataset2\/DR\/train_images\/1006345f70b7.png\"\n\nPatient301 = \"..\/input\/drdataset2\/DR\/train_images\/5b3e7197ac1c.png\"\nPatient302 = \"..\/input\/drdataset2\/DR\/train_images\/7b211d8bd249.png\"\nPatient303 = \"..\/input\/drdataset2\/DR\/train_images\/dad71ba27a9b.png\"","de7fe87f":"<a id=\"7\"><\/a>\n## GrayScale Images\n#### Converting the Ratina Images into Grayscale. So, we can understand the regin or intest .","80bcad5c":"<a id=\"8\"><\/a>\n# Data Augmentation\n","fc9a0372":"<a id=\"2\"><\/a>\n### Loading Data","f09e9bdb":"## Gaussian Blur","c6d5ae7b":"### Train and Test dataset \n","e115cc0b":"### Compile model","ce0179cc":"## Accuracy ResNet50 vs CNN","a8ad1f7d":"<a id=\"2\"><\/a>\n## Exploratory Data Analysis\n#### - Loading Data \n#### - Data Disribution\n#### - Data Visualization\n","60cfb80d":"final_pred = np.mean(preds_tta, axis=0)\npredicted_class_indices = np.argmax(final_pred, axis=1)\n    len(predicted_class_indices)","8674afda":"\n<a id=\"2\"><\/a>\n# Pre-Processing\n#### - Padding (removal) \n#### - Gaussian Blur\n#### - Auto Cropping"}}