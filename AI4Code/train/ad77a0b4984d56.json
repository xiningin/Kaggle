{"cell_type":{"1d1cbd9f":"code","14bf5c2f":"code","5e5f5041":"code","3c38f4a7":"code","b0bf99eb":"code","41a7b90c":"code","c8e63abf":"code","82adf6e2":"code","40b7c591":"code","a0a38270":"code","30d574ce":"code","38cbe091":"code","6d9c56d6":"code","d475f19e":"code","dee1552f":"code","7b3b2928":"code","58a40293":"code","639aafb2":"code","f6354b6d":"code","e24dbd15":"code","13444add":"code","e32679f2":"code","422a7dca":"code","dd14c0af":"code","229bc341":"code","bb28b09b":"code","66e79f38":"code","d5305bfd":"markdown","41de8cee":"markdown","51b4e6fd":"markdown","61832ea7":"markdown","92118ddf":"markdown","97ba0cda":"markdown","601d44f0":"markdown","222b65ef":"markdown","603d96ad":"markdown","635a74a8":"markdown","db0d205e":"markdown","a55218ee":"markdown","80adfb93":"markdown","f874f7eb":"markdown","8919cbbb":"markdown","b52ebcfb":"markdown","c7d6c2a9":"markdown","b2030122":"markdown","b937e627":"markdown","4d280648":"markdown","f9bc0373":"markdown"},"source":{"1d1cbd9f":"import os\nimport time\nimport datetime\nimport numpy as np\nimport pandas as pd\n\n# Keras\nimport tensorflow.keras as keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K\n\n# Standard ML stuff\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD, FastICA\nfrom sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n\n# Oversampling of minority class 'Churn customers'\nfrom imblearn.over_sampling import SMOTE\n\n# Plotting\nimport matplotlib.pyplot as plt","14bf5c2f":"def get_keras_dataset(df):\n    X = {str(col) : np.array(df[col]) for col in df.columns}\n    return X","5e5f5041":"# Plot the results of the training\ndef plot_history(history):\n    fig = plt.figure(figsize=(15,8))\n    ax = plt.subplot(211)\n    \n    plt.xlabel('Epoch')\n    plt.ylabel('loss, acc')\n    \n    # Losses\n    ax.plot(history.epoch, history.history['loss'], label='Train LOSS')\n    ax.plot(history.epoch, history.history['val_loss'], label='Val LOSS')\n    ax.plot(history.epoch, history.history['acc'], label ='Train Accuracy')\n    ax.plot(history.epoch, history.history['val_acc'], label='Val Accuracy')\n    plt.legend()\n    \n    # Plot the learning_rate\n    if 'lr' in history.history:\n        ax = plt.subplot(212)\n        plt.ylabel('Learning rate')\n        ax.plot(history.epoch, history.history['lr'], label='learning_rate')\n        plt.legend()\n    plt.show()\n    plt.close(fig)","3c38f4a7":"# Load the dataset\ntelcom = pd.read_csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ntelcom.head()","b0bf99eb":"telcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\nprint(\"Missing values in TotalCharges: \", telcom[\"TotalCharges\"].isnull().sum())\n\ntelcom = telcom[telcom[\"TotalCharges\"].notnull()]\ntelcom = telcom.reset_index()[telcom.columns]\nprint(\"Missing values in TotalCharges: \", telcom[\"TotalCharges\"].isnull().sum())\n\ntelcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].astype(float)\nprint(\"dType TotalCharges: \", telcom['TotalCharges'].dtype)","41a7b90c":"telcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\", 0:\"No\"})","c8e63abf":"def tenure_lab(telcom) :\n    if telcom[\"tenure\"] <= 12 :\n        return \"Tenure_0-12\"\n    elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n        return \"Tenure_12-24\"\n    elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n        return \"Tenure_24-48\"\n    elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n        return \"Tenure_48-60\"\n    elif telcom[\"tenure\"] > 60 :\n        return \"Tenure_gt_60\"\n    \ntelcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom), axis=1)","82adf6e2":"numeric_cols = ['MonthlyCharges', 'TotalCharges', 'tenure']\ntarget_col = ['Churn']\nignored_cols = ['customerID']\ncategorical_cols = telcom.select_dtypes(include='object').columns\ncategorical_cols = [col for col in categorical_cols if col not in target_col + ignored_cols]","40b7c591":"for col in categorical_cols:\n    telcom[col] = LabelEncoder().fit_transform(telcom[col])\n\ntelcom['Churn'] = telcom['Churn'].map({'Yes' : 1, 'No' : 0})","a0a38270":"telcom[numeric_cols] = StandardScaler().fit_transform(telcom[numeric_cols])","30d574ce":"pca = PCA(n_components=3)\n_X = pca.fit_transform(telcom[numeric_cols + categorical_cols])\npca_data = pd.DataFrame(_X, columns=[\"PCA1\", \"PCA2\", \"PCA3\"])\ntelcom[[\"PCA1\", \"PCA2\", \"PCA3\"]] = pca_data\n\nfica = FastICA(n_components=3)\n_X = fica.fit_transform(telcom[numeric_cols + categorical_cols])\nfica_data = pd.DataFrame(_X, columns=[\"FICA1\", \"FICA2\", \"FICA3\"])\ntelcom[[\"FICA1\", \"FICA2\", \"FICA3\"]] = fica_data\n\ntsvd = TruncatedSVD(n_components=3)\n_X = tsvd.fit_transform(telcom[numeric_cols + categorical_cols])\ntsvd_data = pd.DataFrame(_X, columns=[\"TSVD1\", \"TSVD2\", \"TSVD3\"])\ntelcom[[\"TSVD1\", \"TSVD2\", \"TSVD3\"]] = tsvd_data\n\ngrp = GaussianRandomProjection(n_components=3)\n_X = grp.fit_transform(telcom[numeric_cols + categorical_cols])\ngrp_data = pd.DataFrame(_X, columns=[\"GRP1\", \"GRP2\", \"GRP3\"])\ntelcom[[\"GRP1\", \"GRP2\", \"GRP3\"]] = grp_data\n\nsrp = SparseRandomProjection(n_components=3)\n_X = srp.fit_transform(telcom[numeric_cols + categorical_cols])\nsrp_data = pd.DataFrame(_X, columns=[\"SRP1\", \"SRP2\", \"SRP3\"])\ntelcom[[\"SRP1\", \"SRP2\", \"SRP3\"]] = srp_data\n\n#tsne = TSNE(n_components=3)\n#_X = tsne.fit_transform(telcom[numeric_cols + categorical_cols])\n#tsne_data = pd.DataFrame(_X, columns=[\"TSNE1\", \"TSNE2\", \"TSNE3\"])\n#telcom[[\"TSNE1\", \"TSNE2\", \"TSNE3\"]] = tsne_data\n\nnumeric_cols.extend(pca_data.columns.values)\nnumeric_cols.extend(fica_data.columns.values)\nnumeric_cols.extend(tsvd_data.columns.values)\nnumeric_cols.extend(grp_data.columns.values)\nnumeric_cols.extend(srp_data.columns.values)\n#numeric_cols.extend(tsne_data.columns.values)","38cbe091":"train_df, test_df = train_test_split(telcom, test_size=0.15, random_state=42)\nprint(train_df.shape)","6d9c56d6":"train_df.head()","d475f19e":"smote = SMOTE(sampling_strategy='minority', random_state=42)\nos_smote_X, os_smote_Y = smote.fit_sample(train_df[numeric_cols + categorical_cols], train_df[target_col].values.ravel())\n\ntrain_df = pd.DataFrame(os_smote_X, columns=numeric_cols + categorical_cols)\ntrain_df['Churn'] = os_smote_Y\nprint(train_df.shape)","dee1552f":"os_smote_X","7b3b2928":"customer_id = telcom['customerID']\ntelcom = telcom.drop('customerID', axis=1)","58a40293":"K.clear_session()","639aafb2":"from keras.callbacks import EarlyStopping\n\nes = EarlyStopping(monitor='val_loss', mode='auto', verbose=1)\n\nFEATURE_COLS = numeric_cols + categorical_cols\nTARGET_COL = 'Churn'\nEPOCHS = 500\nBATCH_SIZE = 100000\nCLASS_WEIGHTS = {0 : 1., 1 : 2.5}","f6354b6d":"cat_inputs = []\nnum_inputs = []\nembeddings = []\nembedding_layer_names = []\nemb_n = 10","e24dbd15":"# Embedding for categorical features\nfor col in categorical_cols:\n    _input = layers.Input(shape=[1], name=col)\n    _embed = layers.Embedding(telcom[col].max() + 1, emb_n, name=col+'_emb')(_input)\n    cat_inputs.append(_input)\n    embeddings.append(_embed)\n    embedding_layer_names.append(col+'_emb')\n    \n# Simple inputs for the numeric features\nfor col in numeric_cols:\n    numeric_input = layers.Input(shape=(1,), name=col)\n    num_inputs.append(numeric_input)\n    \n# Merge the numeric inputs\nmerged_num_inputs = layers.concatenate(num_inputs)\n#numeric_dense = layers.Dense(20, activation='relu')(merged_num_inputs)\n\n# Merge embedding and use a Droput to prevent overfittting\nmerged_inputs = layers.concatenate(embeddings)\nspatial_dropout = layers.SpatialDropout1D(0.2)(merged_inputs)\nflat_embed = layers.Flatten()(spatial_dropout)\n\n# Merge embedding and numeric features\nall_features = layers.concatenate([flat_embed, merged_num_inputs])\n\n# MLP for classification\nx = layers.Dropout(0.2)(layers.Dense(100, activation='relu')(all_features))\nx = layers.Dropout(0.2)(layers.Dense(50, activation='relu')(x))\nx = layers.Dropout(0.2)(layers.Dense(25, activation='relu')(x))\nx = layers.Dropout(0.2)(layers.Dense(15, activation='relu')(x))\n\n# Final model\noutput = layers.Dense(1, activation='sigmoid')(x)\nmodel = models.Model(inputs=cat_inputs + num_inputs, outputs=output)","13444add":"def dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","e32679f2":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","422a7dca":"# TB Callback\nlog_folder = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H-%M-%S')\ntb_callback = callbacks.TensorBoard(\n    log_dir=os.path.join('tb-logs', log_folder),\n)\n\n# Best model callback\nbm_callback = callbacks.ModelCheckpoint(\n    filepath=os.path.join('tb-logs', log_folder, 'bm.h5'),\n    save_best_only=True,\n    save_weights_only=False\n)","dd14c0af":"_hist = model.fit(\n    x=get_keras_dataset(train_df[FEATURE_COLS]),\n    y=train_df[TARGET_COL],\n    validation_data=(get_keras_dataset(test_df[FEATURE_COLS]), test_df[TARGET_COL]),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[tb_callback, bm_callback],\n    verbose=2\n)","229bc341":"plot_history(_hist)","bb28b09b":"model = keras.models.load_model(os.path.join('tb-logs', log_folder, 'bm.h5'), compile=False)","66e79f38":"pred = np.around(model.predict(get_keras_dataset(test_df[FEATURE_COLS])))\n\nprint(accuracy_score(test_df[TARGET_COL], pred))\nprint(classification_report(test_df[TARGET_COL], pred))","d5305bfd":"# Data preparation","41de8cee":"### Placeholders for the model input and embedding layers","51b4e6fd":"# Begin the modelling process","61832ea7":"## SMOTE oversampling of minority class","92118ddf":"## Transform the numeric features","97ba0cda":"## Helper functions","601d44f0":"## Create categories for integer values ","222b65ef":"## Extract different feature groups","603d96ad":"## Split dataset in a traning and evaluation part","635a74a8":"## Add low dim representations as additional features","db0d205e":"## Delete the CustomerID","a55218ee":"### Evaluation","80adfb93":"### Keras model architecture","f874f7eb":"### Definition model callbacks","8919cbbb":"### Training","b52ebcfb":"## Replace space characters with nan","c7d6c2a9":"# Load the dataset","b2030122":"## Group customers by tenure","b937e627":"### Compile model with all parameters","4d280648":"\n### Define global parameters","f9bc0373":"## Encode the categorical features + target variable"}}