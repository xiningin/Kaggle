{"cell_type":{"7eaed589":"code","031530c7":"code","305d678c":"code","a399e8bc":"code","b2f1f21c":"code","07f1dba5":"code","c44ecaf6":"code","5c75e768":"code","d43dce79":"code","3ee2395a":"code","8d9ab422":"code","85885268":"code","f9989775":"code","23eb58aa":"code","7561e8d8":"code","5378d5db":"markdown","2126a1cc":"markdown","1c44c229":"markdown","f1938641":"markdown","96e8dffe":"markdown","62b9d9a3":"markdown","7491ba28":"markdown"},"source":{"7eaed589":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.metrics import plot_confusion_matrix \n","031530c7":"hd_dataset = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\", header=0)\nhd_dataset.head(10)","305d678c":"import os\nfrom IPython.display import Image\nImage(filename=\"..\/input\/heart-disease-column-dictionary\/heart_disease_column_attritube_dictionary.PNG\")# width= ???, height=???","a399e8bc":"predictors = hd_dataset.drop(['target'],axis=1) # Features","b2f1f21c":"target = hd_dataset['target'] # Target variable","07f1dba5":"plt.figure(dpi=125)\nmale =len(hd_dataset[hd_dataset['sex'] == 1])\nfemale = len(hd_dataset[hd_dataset['sex']== 0])\nsns.countplot('sex',data = hd_dataset,)\nplt.xlabel('Sex Female-0, Male-1')\nplt.ylabel('Count')\nplt.title('Count of Sex')\nMale, Female =hd_dataset.sex.value_counts()\nprint('Female -',Female)\nprint('Male -',Male)\nplt.show()","c44ecaf6":"#importing essential library\nfrom sklearn.model_selection import train_test_split\n\npredictors_teach, predictors_test, target_teach, target_test = sklearn.model_selection.train_test_split(predictors, target, test_size=0.3, random_state=1) # 70% training and 30% test\n\"\"\" Would you give the train_test_split command parameters within parentheses \n1. predictors, 2. target\n# .. as well as : \"test_size\" parameter with a value of 0.3\n\n# Would you also give the parameter random_state = 1 (it is not essential to understand this step)\"\"\"","5c75e768":"from sklearn.tree import DecisionTreeClassifier\n#decision_tree = DecisionTreeClassifier(criterion=\"gini\",min_impurity_decrease=0.02,max_depth=4 ,min_samples_leaf=20)\n\"\"\"accuracy_score: 0.6373626373626373\"\"\"\ndecision_tree= DecisionTreeClassifier(random_state=42\n                                       ,ccp_alpha=0.02)","d43dce79":"decision_tree = decision_tree.fit(predictors_teach, target_teach)","3ee2395a":"from sklearn.tree import export_graphviz\nfrom six import StringIO\nfrom IPython.display import Image\n!pip install pydotplus\nimport pydotplus\n\ndot_data = StringIO()\n# Code - explained: we create the required data structure for visualizing the decision tree\n# we slip this data structure into a variable called dot_data \n\nexport_graphviz(decision_tree, out_file=dot_data,\n                filled=True, rounded=True,impurity=False, proportion=True,precision=2,\n                special_characters=True, feature_names = predictors.columns,class_names=['no_disease','have_disease'])\n\n\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())\nImage(graph.create_png())\n","8d9ab422":"prediction = decision_tree.predict(predictors_test)\n# Code - explained: \n# I know that our decision tree model includes a \"predict\" command for forecasting.\n# could you give it the predictors_test table as a parameter.\n# could you then slip the resulting predictions (whether diabetes or not) into a variable called prediction \n\nfrom sklearn import metrics \n# I know the sklearn library contains a tool called \"metrics\"\n# I would like to import it for my use so I can measure the accuracy of my model \n\naccuracy = metrics.accuracy_score(target_test, prediction)\n# I know that \"metrics\" contains also \"accuracy_score\" which compares the prediction to the correct results.\n# could you give it the predictor variables reserved for testing as parameters as well as the prediction itself.\n# would you slip the end result into a variable called \"accuracy\" \n\nprint(\"accuracy_score:\",accuracy)\n# voisitko tulostaa kirjekuoren \"tarkkuus\" sis\u00e4ll\u00f6n\n# Could you please print the content of the variable \"accuracy\"","85885268":"confusion_matrix = metrics.confusion_matrix(target_test, prediction)\n# Code - Explained : I know that \"metrics\" contains the command \"confusion_matrix\" which compares the prediction with the correct results\n# I would like to give the target variable and the prediction as a parameter\n# could you slip the result into a variable called a \"confusion_matrix\" \n\nprint(confusion_matrix)\n","f9989775":"#confusion matrix visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax=plt.subplots(figsize=(5,5))\nsns.heatmap(confusion_matrix,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\n\n\nplt.show()","23eb58aa":"from sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion Matrix',\n                          cmap=plt.cm.Blues):\n    \n    # plt.cm.Oranges .. eli muitakin varivaihtoehtoja loytyy\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    Source: http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size = 24)\n    plt.colorbar(aspect=4)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n    plt.yticks(tick_marks, classes, size = 14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('Truth', size = 18)\n    plt.xlabel('Prediction', size = 18)","7561e8d8":"cm = confusion_matrix(target_test, prediction)\nplot_confusion_matrix(cm, classes = ['no_heart_disease', 'have_heart_disease'],\n                      normalize = False,\n                      title = 'Confusion Matrix')","5378d5db":"# Read our data","2126a1cc":"#  Short story explanation \n\nbased on our decison tree ,if the chest pain is< or equal to 0.5 that person has 46% change of not being suffer from heart disease and on the other hand that person has 54 % probability of having heart disease\n exang(1=yes ,0=No)angina is usually triggered by physical activity\n \n **gini** is the gini index or score for that node\n**samples** tell us how many samples are in that node\n**value** tells us how many samples in the node are in each category. In this example, we have two categories, No and Yes, referring to whether or not a patient has heart disease. The number of patients with No comes first because the categories are in alphabetical order. \n**class** tells us whichever category is represented most in the node.","1c44c229":"# let's split for training and testing purpose","f1938641":"# **INTRODUCTION**\n\nThis database contains 76 attributes and this original dataset comes from :\nhttps:\/\/www.kaggle.com\/ronitf\/heart-disease-uci\/code\n\n\n","96e8dffe":"# **Attribute Information:**\n \n* age \n* sex-1: male, 0: female\n* cp-chest pain type( 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic)\n* trestbps-resting blood pressure (in mm Hg on admission to the hospital)\n* chol-serum cholestoral in mg\/dl\n* fbs-fasting blood sugar > 120 mg\/dl\n* restecg-resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved\n* exercise induced angina\n* oldpeak = ST depression induced by exercise relative to rest\n* the slope of the peak exercise ST segment\n* number of major vessels (0-3) colored by flourosopy\n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target \u00b4-have disease or not (1=yes, 0=no) (= the predicted attribute)","62b9d9a3":"# **Importing essential libraries **","7491ba28":"# \n# Confusion matrix explanation to myself \ntotal of  predictions 91=(26+15+12+38)\n\n* 26 True Negatives (TN)\n* 12 False Negatives (FN)\n* 15 False Positives (FP)\n* 38 True Positives (TP)\n\n\nThe truth table reads the following:\n\n\"TP\" = True Positive : How many times the prediction was having heart disease (1) AND the prediction was CORRECT\n\"TN\" = True Negative : How many times the prediction was not having heart disease(0:negative) AND the prediction was CORRECT\n\"FP\" = False Positive : How many times the prediction was haivng heart disease (1:positive) BUT the prediction was WRONG\n\"FN\" = False Negative : How many times the prediction was not suffering from heart disease  (0:negative) BUT the prediction is FALSE AND the prediction was CORRECT\n\n# Note to myself\n\nN = Negative, in this case meaning \"no_disease\" (no heart disease)\nP = Positive, in this case meaning \"have_disease\"\nT = True, meaning the prediction was true\nF = False, meaning the prediction was false"}}