{"cell_type":{"7f1be64f":"code","91f69f2d":"code","c03a0f6f":"code","b9d5f3d1":"code","730c1a6f":"code","5ec6ddf4":"code","f17d1142":"code","5c8dc733":"code","cf8d2f69":"code","cb82950d":"code","1d868693":"code","9e9268dd":"code","ccc023bc":"code","0dfd1850":"code","59c519ff":"code","853ce631":"code","233a8dd6":"code","609cf211":"code","52a2ea9b":"code","ff884a96":"code","4ee513d0":"code","b54e87ec":"code","18c98577":"code","30e7891d":"code","b94b5685":"markdown","41c66b29":"markdown","a6f14e88":"markdown","c1129151":"markdown","84d40595":"markdown","68774268":"markdown","fc1eb3f0":"markdown","6a817706":"markdown"},"source":{"7f1be64f":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nfrom sklearn import metrics","91f69f2d":"os.chdir('\/kaggle\/input\/wallmart-sales\/')\ntotal_value = pd.read_csv('total_value.csv')\ntotal_value.head()","c03a0f6f":"os.chdir('\/kaggle\/input\/wallmart\/')\ncal = pd.read_csv('calendar.csv')","b9d5f3d1":"cal","730c1a6f":"# One-hot encoding months\nmonth = pd.get_dummies(cal['month'],prefix='month',drop_first=True)\n\n# Dropping unecessary cols\ncal.drop(['wm_yr_wk', 'weekday','d', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_TX', 'snap_WI'],1,inplace=True)\n\n# Handling events\ncal['event_name_1'] = cal['event_name_1'].fillna(0)\ncal['event_name_1'] = np.where(cal['event_name_1'] != 0,1,0)\n\n# One-hot encoding day of months\ncal['date'] = pd.to_datetime(cal['date'])\ncal['dayofmonth'] = cal['date'].dt.day     \ndom = pd.DataFrame(np.where(cal['dayofmonth']>=15,1,0),columns=['day_ge_15'])\n\n# One-hot encoding years\nyear = pd.get_dummies(cal['year'],prefix='year_',drop_first=True)\n\n# One-hot encoding weekdays\nwday = pd.get_dummies(cal['wday'],prefix='wday_',drop_first=True)\n\n# Combing and removing features\ncal.drop(['month','year','dayofmonth','wday'],1,inplace=True)\ncal = pd.concat([cal,month,year,dom,wday],axis=1)","5ec6ddf4":"# Function for filtering california store 3 items\ndef california_store_3(item):\n    state = item.split('_')[3] \n    store_no = int(item.split('_')[4])\n    if (state == 'CA' and store_no == 3): \n        return True\n    else: \n        return False","f17d1142":"item_list = list(total_value.columns[:-1])\ncalifornia_store_3_item = filter(california_store_3, item_list)\ncalifornia_store_3_item_list = [i for i in california_store_3_item]","5c8dc733":"california_store_3_df = total_value.loc[:,california_store_3_item_list]\ncalifornia_store_3_df","cf8d2f69":"# Concatinating categorical variables\ncalifornia_store_3_df = pd.concat([cal.iloc[:1941,:],california_store_3_df],1)\ncalifornia_store_3_df.head()","cb82950d":"california_store_3_df['date'] = pd.to_datetime(california_store_3_df['date'])","1d868693":"# 3049 items\ncalifornia_store_3_last_1_year_df = california_store_3_df[california_store_3_df['date'] >='2015-02-22']\ncalifornia_store_3_last_1_year_df.head()","9e9268dd":"# 3021 items\ncalifornia_store_3_last_1_year_df_without_Nas = california_store_3_last_1_year_df.dropna(axis=1)\ncalifornia_store_3_last_1_year_df_without_Nas.head()","ccc023bc":"# Fuction for filtering hobbies\ndef california_store_3_hobbies(item):\n    category = item.split('_')[0]\n    if (category == 'HOBBIES'): \n        return True\n    else: \n        return False","0dfd1850":"categorical_variables = list(california_store_3_last_1_year_df_without_Nas.columns[:26])\ncalifornia_store_3_last_1_year_without_Nas_item_list = list(california_store_3_last_1_year_df_without_Nas.columns[26:])\ncalifornia_store_3_last_1_year_without_Nas_item_hobbies = filter(california_store_3_hobbies, california_store_3_last_1_year_without_Nas_item_list)\ncalifornia_store_3_last_1_year_without_Nas_item_hobbies_list = categorical_variables + [i for i in california_store_3_last_1_year_without_Nas_item_hobbies]","59c519ff":"california_store_3_last_1_year_without_Nas_item_hobbies_df = california_store_3_last_1_year_df_without_Nas.loc[:,california_store_3_last_1_year_without_Nas_item_hobbies_list]\ncalifornia_store_3_last_1_year_without_Nas_item_hobbies_df","853ce631":"master_df = california_store_3_last_1_year_without_Nas_item_hobbies_df.copy()","233a8dd6":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[26:].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 hobbies sales\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","609cf211":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[:,26:26+15].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 hobbies sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","52a2ea9b":"master_df_15_items = master_df.iloc[:,:26+15]","ff884a96":"# loop for lstm\n\ncategorical_varibales = master_df_15_items.iloc[:,:26] \ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n    \n    # Making dataset\n    dataset = pd.concat([categorical_varibales,master_df[target_variable]],1)\n\n    # Splitting train and test data\n    split_date = '2016-04-24'\n    Train = dataset.loc[dataset['date'] <= split_date].copy()\n    Test = dataset.loc[dataset['date'] > split_date].copy()\n    \n    # Dropping date\n    Train.drop(['date'],axis=1,inplace=True)\n    Test.drop(['date'],axis=1,inplace=True)\n    \n    x_train = Train.drop([target_variable],1)\n    y_train = Train[target_variable]\n    x_test = Test.drop([target_variable],1)\n    y_test = Test[target_variable]\n\n    #Create model layers\n    model = tf.keras.Sequential([\n        tf.keras.layers.LSTM(64,input_shape=(len(x_test.keys()),1)),\n        tf.keras.layers.Dense(1)\n    ])\n\n    #Choose optimizer\n    optimizer = tf.keras.optimizers.Adam()\n\n    #Compile model with mean squared error as loss function\n    model.compile(loss='mse',\n                  optimizer=optimizer,\n                  metrics=['mae', 'mse'])\n\n    # Number of epochs\n    EPOCHS = 10\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    history=model.fit(np.reshape(x_train.values, (x_train.shape[0], x_train.shape[1], 1))\n    , y_train,epochs=EPOCHS, validation_split = 0.2,callbacks=[early_stop], verbose=1)\n    \n    # Predictions\n    test_predictions = model.predict(np.reshape(x_test.values, (x_test.shape[0], x_test.shape[1], 1))).flatten()\n    print(f'{target_variable}:{metrics.mean_squared_error(test_predictions,y_test)}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions = pd.concat([predictions, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual = pd.concat([actual, y_test], 1, ignore_index = True)","4ee513d0":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions.sum(axis=1),mode='lines',name='pred'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 hobbies sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","b54e87ec":"# Packages for arima\n!python3.7 -m pip install --upgrade pip\n!pip install pmdarima\nfrom pmdarima.arima import auto_arima","18c98577":"# loop for arima\n\ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n     \n    # Making dataset\n    dataset = master_df[target_variable]\n\n    # Splitting train and test data\n    df_arima_train = dataset[:-28]\n    y_test = dataset[-28:]    \n    \n    # Defining model\n    stepwise_model = auto_arima(df_arima_train,start_p=1,start_q=1,max_p=3,max_q=3,m=7,start_P=0,seasonal=True,d=1,D=1,trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n\n    # Predictions\n    test_predictions = stepwise_model.predict(n_periods=28)\n    ar_day_rmse = np.sqrt(metrics.mean_squared_error(test_predictions, y_test))\n    print(f'{target_variable}th rmse:{ar_day_rmse}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions_ar = pd.concat([predictions_ar, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual_ar = pd.concat([actual_ar, y_test], 1, ignore_index = True)","30e7891d":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions_ar.sum(axis=1),mode='lines',name='pred_ar'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual_ar.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 hobbies sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","b94b5685":"## Arima","41c66b29":"## LSTM","a6f14e88":"# Model building and preprocessing","c1129151":"## Pre-processing total_value dataset","84d40595":"## Reading data","68774268":"## Importing libraries","fc1eb3f0":"## Pre-processing cal dataset","6a817706":"### Seperating Hobbies items"}}