{"cell_type":{"b110a1d7":"code","bcfc1e73":"code","711a1fc0":"code","1987732b":"code","7cbbc7ad":"code","ee4f45cb":"code","31899d64":"code","3a11b214":"code","a9c88a35":"code","91369400":"code","20e01176":"code","de3e1b8a":"code","6a541413":"code","44858475":"code","db69b327":"code","442a311a":"code","75e026d7":"code","17583d99":"code","07ef3fc0":"code","06acb742":"code","31fe58ca":"code","ae283499":"code","470fb458":"code","d662456f":"code","f2225f60":"code","b0ef960d":"code","adc7e0d8":"code","df39ff69":"code","5f60b946":"code","7e9dd1b4":"code","d05d58e0":"code","45905025":"code","9cef3b38":"markdown","78158e06":"markdown","3678371d":"markdown"},"source":{"b110a1d7":"## importing libraries\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom pandas import plotting\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight') #538\n%matplotlib inline\nimport seaborn as sns\n\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\n\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n","bcfc1e73":"!ls ..\/input\/customer-segmentation-tutorial-in-python\/","711a1fc0":"# Reading dataset\ndata = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\ndat = ff.create_table(data.head())\npy.iplot(dat)","1987732b":"desc = ff.create_table(data.describe())\npy.iplot(desc)","7cbbc7ad":"data.isnull().sum()","ee4f45cb":"# Data visualization\n\nplt.rcParams['figure.figsize'] = (15,10)\nplotting.andrews_curves(data.drop(['CustomerID'],axis =1), \"Gender\")\nplt.title('Andrews curve for Gender')\nplt.show()","31899d64":"import warnings\nwarnings.filterwarnings('ignore')","3a11b214":"plt.rcParams['figure.figsize'] = (15,5)\n\nplt.subplot(1,2,1)\nsns.set(style ='whitegrid')\nsns.distplot(data['Annual Income (k$)'])\nplt.title('Distribution of Annual Income')\nplt.xlabel('Annual Income')\nplt.ylabel('Count')\nplt.show()\n\nplt.subplot(1,2,2)\nsns.set(style='whitegrid')\nsns.distplot(data['Age'], color ='red')\nplt.title('Distribution of Age')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()","a9c88a35":"data['Gender'].value_counts()","91369400":"explode =[0,0.1]\ncolors=['lightgreen','orange']\nlabels = ['Female','Male']\n\nplt.pie(data['Gender'].value_counts(), labels = labels, explode = explode, colors= colors, shadow = True, autopct =\"%.2f%%\")\nplt.legend()\nplt.title('Gender distribution')\nplt.axis('off')\nplt.show()","20e01176":"plt.rcParams['figure.figsize'] = (10,5)\nsns.countplot(data['Age'], palette ='hsv')\nplt.title('Distribution of Age')\nplt.show()","de3e1b8a":"plt.rcParams['figure.figsize'] = (10,5)\nsns.countplot(data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Distribution of Income')\nplt.show()","6a541413":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['Spending Score (1-100)'], palette = 'copper')\nplt.title('Distribution of Spending Score', fontsize = 20)\nplt.show()","44858475":"sns.pairplot(data)\nplt.show()","db69b327":"plt.rcParams['figure.figsize'] = (10,5)\nsns.heatmap(data.corr(), annot = True, cmap ='Wistia')\nplt.title('Heatmap')\nplt.show()","442a311a":"## Gender vs Spending scores\nplt.rcParams['figure.figsize'] = (10,5)\nsns.boxenplot(data['Gender'], data['Spending Score (1-100)'], palette = 'Blues')\nplt.title('Gender wise spending distribution')\nplt.show()","75e026d7":"plt.rcParams['figure.figsize'] = (18, 7)\nsns.violinplot(data['Gender'], data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Gender vs Spending Score', fontsize = 20)\nplt.show()","17583d99":"plt.rcParams['figure.figsize'] = (18, 7)\nsns.stripplot(data['Gender'], data['Age'], palette = 'Purples', size = 10)\nplt.title('Gender vs Spending Score', fontsize = 20)\nplt.show()","07ef3fc0":"sns.lineplot(data['Annual Income (k$)'], data['Age'], color='blue')\nsns.lineplot(data['Annual Income (k$)'], data['Spending Score (1-100)'], color='pink')\nplt.title('Distribution of Annual Income with Age and spending score')\nplt.show()\n","06acb742":"data.columns","31fe58ca":"x = data.iloc[:,[3,4]].values\nx.shape","ae283499":"# kmeans algorithm\n\n#elbow method to find best number of clusters\n\nwcss =[] # within cluster sum of squares\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    km.fit(x)\n    wcss.append(km.inertia_)\n    \nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()\n    \n#Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.\n#\u2018k-means++\u2019 : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. \n#inertia_ = Sum of squared distances of samples to their closest cluster center.\n","470fb458":"# Visualizing clusters\n\nkm = KMeans(n_clusters =5, init ='k-means++', n_init=10, random_state=10, max_iter =300)\ny_pred = km.fit_predict(x)","d662456f":"plt.scatter(x[y_pred==0, 0], x[y_pred==0,1], s=100, c ='pink',label='miser')\nplt.scatter(x[y_pred==1, 0], x[y_pred==1,1], s=100, c ='yellow',label='general')\nplt.scatter(x[y_pred==2, 0], x[y_pred==2,1], s=100, c ='cyan',label='target')\nplt.scatter(x[y_pred==3, 0], x[y_pred==3,1], s=100, c ='magenta',label='spendthrift')\nplt.scatter(x[y_pred==4, 0], x[y_pred==4,1], s=100, c ='orange',label='careful')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.style.use('fivethirtyeight')\nplt.title('Kmeans clustering')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending score')\nplt.legend()\nplt.grid()\nplt.show()","f2225f60":"# Hierarchical clustering\nimport scipy.cluster.hierarchy as sch\n\ndendrogram = sch.dendrogram(sch.linkage(x, method='ward'))\nplt.title('Dendogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean Distance')\nplt.show()\n\n#method=\u2019ward\u2019 uses the Ward variance minimization algorithm.","b0ef960d":"# Visualizing hierarchical clustering\n\nfrom sklearn.cluster import AgglomerativeClustering\n\nhc = AgglomerativeClustering(n_clusters =5, affinity = 'euclidean', linkage ='ward')\ny_hc = hc.fit_predict(x)","adc7e0d8":"plt.scatter(x[y_hc==0,0], x[y_hc==0,1], s=100, c='pink', label = 'miser')\nplt.scatter(x[y_hc == 1, 0], x[y_hc == 1, 1], s = 100, c = 'yellow', label = 'general')\nplt.scatter(x[y_hc == 2, 0], x[y_hc == 2, 1], s = 100, c = 'cyan', label = 'target')\nplt.scatter(x[y_hc == 3, 0], x[y_hc == 3, 1], s = 100, c = 'magenta', label = 'spendthrift')\nplt.scatter(x[y_hc == 4, 0], x[y_hc == 4, 1], s = 100, c = 'orange', label = 'careful')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.style.use('fivethirtyeight')\nplt.title('Hierarchial Clustering', fontsize = 20)\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.grid()\nplt.show()\n","df39ff69":"## Clustering based on Age\n\nx = data.iloc[:, [2, 4]].values\nx.shape","5f60b946":"wcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n\nplt.rcParams['figure.figsize'] = (15, 5)\nplt.plot(range(1, 11), wcss)\nplt.title('K-Means Clustering(The Elbow Method)', fontsize = 20)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.grid()\nplt.show()","7e9dd1b4":"kmeans = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\nymeans = kmeans.fit_predict(x)\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.title('Cluster of Ages', fontsize = 30)\n\nplt.scatter(x[ymeans == 0, 0], x[ymeans == 0, 1], s = 100, c = 'pink', label = 'Usual Customers' )\nplt.scatter(x[ymeans == 1, 0], x[ymeans == 1, 1], s = 100, c = 'orange', label = 'Priority Customers')\nplt.scatter(x[ymeans == 2, 0], x[ymeans == 2, 1], s = 100, c = 'lightgreen', label = 'Target Customers(Young)')\nplt.scatter(x[ymeans == 3, 0], x[ymeans == 3, 1], s = 100, c = 'red', label = 'Target Customers(Old)')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 50, c = 'black')\n\nplt.style.use('fivethirtyeight')\nplt.xlabel('Age')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.grid()\nplt.show()","d05d58e0":"x = data[['Age','Spending Score (1-100)','Annual Income (k$)']].values\nkm = KMeans(n_clusters =5, init='k-means++', n_init=10, random_state=10, max_iter =300)\nkm.fit(x)\nlabels =km.labels_\ncentroids = km.cluster_centers_","45905025":"entroids = km.cluster_centers_\ndata['labels'] =  labels\ntrace1 = go.Scatter3d(\n    x= data['Age'],\n    y= data['Spending Score (1-100)'],\n    z= data['Annual Income (k$)'],\n    mode='markers',\n     marker=dict(\n        color = data['labels'], \n        size= 10,\n        line=dict(\n            color= data['labels'],\n            width= 12\n        ),\n        opacity=0.8\n     )\n)\ndf = [trace1]\n\nlayout = go.Layout(\n    title = 'Character vs Gender vs Alive or not',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    ),\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Spending Score'),\n            zaxis = dict(title  = 'Annual Income')\n        )\n)\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","9cef3b38":"It has been shown the Andrews curves are able to preserve means, distance (up to a constant) and variances. Which means that Andrews curves that are represented by functions close together suggest that the corresponding data points will also be close together","78158e06":"# Clustering","3678371d":"Reference : \nhttps:\/\/www.kaggle.com\/roshansharma\/mall-customers-clustering-analysis"}}