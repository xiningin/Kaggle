{"cell_type":{"b8a87bef":"code","9f6a7178":"code","5765ae26":"code","ba21b213":"code","8e8ff0a7":"code","c6a6eb89":"code","b81aa445":"code","4bcec9af":"code","18cfab89":"code","996f8860":"code","02549660":"code","be38408a":"code","c84aefd1":"code","ceedac14":"code","f66283a8":"code","5fe9cf1c":"code","e1ce7b0b":"code","f0175f47":"code","302f85e4":"code","edff6657":"code","6fe95da5":"code","7949e0e3":"code","a13e44da":"code","d376c124":"code","1fbed1eb":"code","5a50e0a8":"code","d858af5e":"code","b7105f9c":"code","c94a6162":"markdown","b186a3b2":"markdown","4b417524":"markdown","41aadab4":"markdown","0a5c0a04":"markdown","f3f2df39":"markdown","4b5fd703":"markdown","a67c2468":"markdown","f1c91237":"markdown","a2c20e1c":"markdown","f7505903":"markdown","cbc1cc97":"markdown"},"source":{"b8a87bef":"import numpy as np\nimport geopandas as gpd\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport plotly.offline as plotly\nimport plotly.graph_objs as go\nimport plotly.tools as tools\n\nplotly.init_notebook_mode(connected=True)\n\n%matplotlib inline","9f6a7178":"police_uof_path = \"..\/input\/data-science-for-good\/cpe-data\/Dept_37-00027\/37-00027_UOF-P_2014-2016_prepped.csv\"\n\n# Use Pandas to read the \"prepped\" CSV, dropping the first row, which is just more headers\npolice_uof_df = pd.read_csv(police_uof_path).iloc[1:].reset_index(drop=True)","5765ae26":"police_shp_path = \"..\/input\/data-science-for-good\/cpe-data\/Dept_37-00027\/37-00027_Shapefiles\/APD_DIST.shp\"\n\n# Use Geopandas to read the Shapefile\npolice_shp_gdf = gpd.read_file(police_shp_path)\npolice_shp_gdf.crs = {'init' :'esri:102739'}\npolice_shp_gdf = police_shp_gdf.to_crs(epsg='4326')","ba21b213":"census_shp_path = \"..\/input\/cb-2017-48-tract-500k\/cb_2017_48_tract_500k.shp\"\ncensus_tracts_gdf = gpd.read_file(census_shp_path)\ncensus_tracts_gdf['GEOID'] = census_tracts_gdf['GEOID'].astype('int64')\ncensus_tracts_gdf = census_tracts_gdf.to_crs(epsg='4326')","8e8ff0a7":"census_race_file_path = \"..\/input\/texas-14-5yr-dp05-racesexage\/ACS_14_5YR_DP05.csv\"\n\n\ncensus_race_meta_file_path = \"..\/input\/texas-14-5yr-dp05-racesexage\/ACS_14_5YR_DP05_metadata.csv\"\n\ncensus_race_df = pd.read_csv(census_race_file_path)\ncensus_race_meta_df = pd.read_csv(census_race_meta_file_path,skiprows=2)\ncensus_race_meta_df.columns = ['header','description']\nmeta_mask = ~census_race_meta_df['description'].str.contains('Margin of Error|SEX AND AGE',regex=True)\ncensus_race_meta_df = census_race_meta_df[meta_mask] # Only keep \"Percent\" categories\n\ncensus_columns_to_drop = ['HC02','HC04']\ncolumn_mask = census_race_df.columns.str.contains('|'.join(census_columns_to_drop), regex=True)\ncensus_race_df = census_race_df.loc[:,census_race_df.columns[~column_mask]]\ncensus_race_df = census_race_df.iloc[1:].reset_index(drop=True)\n\n# Rename Census Tract ID column in ACS Poverty CSV to align with Census Tract Shapefile\ncensus_race_df = census_race_df.rename(columns={'GEO.id2':'GEOID'})","c6a6eb89":"print('Police UOF Race Labels:')\nprint(police_uof_df.SUBJECT_RACE.value_counts(dropna=False))\npolice_uof_df = police_uof_df.dropna(subset=['SUBJECT_RACE']).reset_index(drop=True)","b81aa445":"race_perc_col_begin = 'Percent; HISPANIC OR LATINO AND RACE - Total population - '\nrace_est_col_begin = 'Estimate; HISPANIC OR LATINO AND RACE - Total population - '\nrace_col_end = ['Hispanic or Latino (of any race)',\n                'Not Hispanic or Latino - White alone',\n                'Not Hispanic or Latino - Black or African American alone',\n                'Not Hispanic or Latino - American Indian and Alaska Native alone',\n                'Not Hispanic or Latino - Asian alone',\n                'Not Hispanic or Latino - Native Hawaiian and Other Pacific Islander alone',\n                'Not Hispanic or Latino - Some other race alone',\n                'Not Hispanic or Latino - Two or more races']\nrace_perc_cols = race_perc_col_begin+np.array(race_col_end,dtype=object)\nrace_est_cols = race_est_col_begin+np.array(race_col_end,dtype=object)","4bcec9af":"census_race_meta_df[census_race_meta_df['description'].isin(race_est_cols)].header.values","18cfab89":"meta_perc_mask = census_race_meta_df['description'].isin(race_perc_cols)\nmeta_est_mask = census_race_meta_df['description'].isin(race_est_cols)\nrace_perc_headers = census_race_meta_df[meta_perc_mask].header.values\nrace_est_headers = census_race_meta_df[meta_est_mask].header.values\nrace_desc = np.array(['Hispanic','White','Black','Native American','Asian',\n                      'Pacific Islander','Some Other Race','Two or more races']).astype(object)\nrace_perc_header_to_desc = dict(zip(race_perc_headers,race_desc+', Percent'))\nrace_est_header_to_desc = dict(zip(race_est_headers,race_desc+', Estimate'))\nfor item in list(zip(race_est_headers,race_desc)):\n    print('{0}: {1}, Estimate'.format(item[0],item[1]))\nprint('')\nfor item in list(zip(race_perc_headers,race_desc)):\n    print('{0}: {1}, Percent'.format(item[0],item[1]))","996f8860":"print(census_race_df.loc[0,race_perc_headers])\nprint('')\nprint('Sum: {0}'.format(census_race_df.loc[0,race_perc_headers].sum()))","02549660":"AX_LABEL_FONT_DICT = {'size':14}\nAX_TITLE_FONT_DICT = {'size':16}\n\nfig0,ax0 = plt.subplots()\n(police_shp_gdf.dissolve(by='SECTOR').reset_index()\n .plot(ax=ax0,column='SECTOR',legend=True))\nax0.set_xlabel('Latitude (deg)',fontdict=AX_LABEL_FONT_DICT)\nax0.set_ylabel('Longitude (deg)',fontdict=AX_LABEL_FONT_DICT)\nax0.set_title('Dept_37-00027: Police Precincts (SECTORS)',\n              fontdict=AX_TITLE_FONT_DICT)\nleg0 = ax0.get_legend()\nleg0.set_bbox_to_anchor((1.28, 1., 0., 0.))\nleg0.set_title('SECTOR',prop={'size':12})\nfig0.set_size_inches(7,7)","be38408a":"fig1,ax1 = plt.subplots()\ncensus_tracts_gdf.plot(ax=ax1,color='#74b9ff',alpha=.4,edgecolor='white')\npolice_shp_gdf.plot(ax=ax1,column='SECTOR')\nax1.set_xlabel('Latitude (deg)',fontdict=AX_LABEL_FONT_DICT)\nax1.set_ylabel('Longitude (deg)',fontdict=AX_LABEL_FONT_DICT)\nax1.set_title('Dept_37-00027 and Texas Census Tracts',\n              fontdict=AX_TITLE_FONT_DICT)\nfig1.set_size_inches(8,11)","c84aefd1":"police_sector_shp_gdf = police_shp_gdf.dissolve(by='SECTOR').reset_index()\n#joined_df = gpd.overlay(police_sector_shp_gdf,census_tracts_gdf)\njoined_df = pd.read_pickle(\"..\/input\/cpe-joined-df\/cpe_joined_df.pkl\")","ceedac14":"# fig2,ax2 = plt.subplots()\n# joined_df.plot(ax=ax2,column='SECTOR',legend=True)\n# ax2.set_xlabel('Latitude (deg)',fontdict=AX_LABEL_FONT_DICT)\n# ax2.set_ylabel('Longitude (deg)',fontdict=AX_LABEL_FONT_DICT)\n# ax2.set_title('Dept_37-00027: Police Precincts with Overlayed Census Tracts',\n#               fontdict=AX_TITLE_FONT_DICT)\n# leg2 = ax2.get_legend()\n# leg2.set_bbox_to_anchor((1.28, 1., 0., 0.))\n# leg2.set_title('SECTOR',prop={'size':12})\n# fig2.set_size_inches(7,7)","f66283a8":"def perc_tract_area(group, tracts_gdf):\n    joined_area = group.area.values\n    orig_tract_area = tracts_gdf.set_index('GEOID').loc[group['GEOID'].values,:].area.values\n    perc_of_orig_tract = joined_area\/orig_tract_area\n    group['perc_of_orig_tract'] = perc_of_orig_tract\n    return group","5fe9cf1c":"print(census_race_meta_df[census_race_meta_df['header'] == 'HC01_VC43'])","e1ce7b0b":"est_tot_pop_header = 'HC01_VC43'\njoined_with_perc_area = (joined_df\n                         .groupby('SECTOR')\n                         .apply(perc_tract_area, census_tracts_gdf)\n                         .sort_index())\n\njoined_perc_area_and_pop = (joined_with_perc_area\n                            .merge(census_race_df[['GEOID',est_tot_pop_header]],\n                                   on='GEOID')\n                            .sort_values('SECTOR')\n                            .reset_index())\n\n# Adjusting population based on percent area of census tract within police district\njoined_perc_area_and_pop['pop_adj_by_area'] = (joined_perc_area_and_pop['perc_of_orig_tract']*\n                                               joined_perc_area_and_pop[est_tot_pop_header])","f0175f47":"def adj_pop_weight_factor(group):\n    group['weight_factor'] = group['pop_adj_by_area']\/group['pop_adj_by_area'].sum()\n    return group","302f85e4":"# Calculate areal_fractions to use as weight factors\njoined_pop_weight_factor = (joined_perc_area_and_pop\n                            .groupby('SECTOR')\n                            .apply(adj_pop_weight_factor)\n                            .drop('index',axis=1))\n\nrace_est_merge_headers = np.insert(race_est_headers,0,'GEOID')\n\n\njoined_est_pop_weighted = (joined_pop_weight_factor\n                           .merge(census_race_df[race_est_merge_headers],on='GEOID')\n                           .sort_values('SECTOR').reset_index(drop=True))\n\n# Use areal_fractions to \"re-distribute\" population of partial census tracts\nest_pop_weighted = (joined_est_pop_weighted[race_est_headers]\n                    .multiply(joined_est_pop_weighted['weight_factor'], \n                              axis=\"index\"))\n\n\njoined_est_pop_weighted = (pd.concat([joined_est_pop_weighted,\n                                      est_pop_weighted.rename(columns=race_est_header_to_desc)],\n                                      axis=1)\n                           .drop(race_est_headers,axis=1))\n\n# Sum all intersected_tract populations\nrace_est_by_pol_sector = (joined_est_pop_weighted\n                          .groupby('SECTOR')[list(race_est_header_to_desc.values())]\n                          .sum())\nrace_perc_by_pol_sector = (race_est_by_pol_sector\n                           .divide(race_est_by_pol_sector.sum(axis=1),\n                                   axis='index'))*100.\nrace_perc_by_pol_sector.columns = (race_perc_by_pol_sector\n                                   .columns\n                                   .str\n                                   .replace('Estimate','Percent'))\nrace_perc_by_pol_sector.sort_index(axis=1,inplace=True)\nrace_perc_by_pol_sector","edff6657":"sectors_in_pol_shp = police_shp_gdf.SECTOR.value_counts(dropna=False).sort_index()\nprint(sectors_in_pol_shp)","6fe95da5":"print(police_uof_df.LOCATION_DISTRICT.value_counts().sort_index())","7949e0e3":"mask_missing_sectors = ~police_uof_df.LOCATION_DISTRICT.isin(['-','88',np.nan])\npolice_uof_df = police_uof_df[mask_missing_sectors].reset_index(drop=True)\nsectors_in_pol_uof = police_uof_df.LOCATION_DISTRICT.value_counts().sort_index()\nprint(sectors_in_pol_uof)","a13e44da":"sector_abbrev_dict = dict(zip(sectors_in_pol_uof.index,\n                              sectors_in_pol_shp.index))\nsector_abbrev_dict","d376c124":"police_uof_df.LOCATION_DISTRICT.replace(sector_abbrev_dict,inplace=True)","1fbed1eb":"race_uof_est_by_pol_sector = (police_uof_df\n                              .groupby('LOCATION_DISTRICT')['SUBJECT_RACE']\n                              .value_counts()\n                              .unstack())\nrace_uof_est_by_pol_sector.fillna(0,inplace=True)\nrace_uof_est_by_pol_sector.columns = race_uof_est_by_pol_sector.columns+', Estimate'\nrace_uof_est_by_pol_sector","5a50e0a8":"race_uof_perc_by_pol_sector = (race_uof_est_by_pol_sector\n                               .divide(race_uof_est_by_pol_sector.sum(axis=1),\n                                       axis='index'))*100.\nrace_uof_perc_by_pol_sector.columns = (race_uof_perc_by_pol_sector\n                                       .columns\n                                       .str\n                                       .replace('Estimate','Percent'))\nrace_uof_perc_by_pol_sector.drop('Unknown, Percent',axis=1,inplace=True)\nrace_uof_perc_by_pol_sector","d858af5e":"missing_cols_mask = ~(race_perc_by_pol_sector\n                      .columns\n                      .isin(race_uof_perc_by_pol_sector.columns))\nmissing_cols = race_perc_by_pol_sector.columns[missing_cols_mask]\nrace_uof_perc_by_pol_sector = pd.concat([race_uof_perc_by_pol_sector,\n                                         pd.DataFrame(columns=missing_cols)],\n                                         axis=1,sort=False).fillna(0)\nrace_uof_perc_by_pol_sector.sort_index(axis=1,inplace=True)","b7105f9c":"race_tick_labels = list(race_perc_by_pol_sector.columns.str.replace(', Percent',\"\"))\n\nfor district_str in race_perc_by_pol_sector.index:\n    race_breakdown_census = race_perc_by_pol_sector.loc[district_str,:]\n    trace1 = go.Bar(\n        y= race_breakdown_census.values,\n        x= race_tick_labels,\n        marker=dict(\n            color='#34495e',\n            line=dict(\n                color='rgba(255, 255, 255, 0.0)',\n                width=1),\n        ),\n        name='Census',\n        orientation='v',\n        showlegend = True\n    )\n\n    race_breakdown_uof = race_uof_perc_by_pol_sector.loc[district_str,:]\n    trace2 = go.Bar(\n        y= race_breakdown_uof.values,\n        x= race_tick_labels,\n        marker=dict(\n            color='#ffa500',\n            line=dict(\n                color='rgba(255, 255, 255, 0.0)',\n                width=1),\n        ),\n        name='Use of Force',\n        orientation='v',\n        showlegend = True\n    )\n\n    data = [trace1, trace2]\n    layout = go.Layout(\n        barmode='group',\n        title = \"Dept_37-00027: Racial Breakdown for Police Precinct (SECTOR) '{0}'\".format(district_str)\n    )\n\n    fig = go.Figure(data=data, layout=layout)\n    plotly.iplot(fig)","c94a6162":"The following cell is broken in the Kaggle Kernel. To run locally, uncomment all of the code below.","b186a3b2":"<a id='top'><\/a>\n\n## 0. Introduction\nFor a detailed introduction, check out my starter kernel [here](https:\/\/www.kaggle.com\/dsholes\/confused-start-here\/). To skip straight to the juicy, plotly plots, click [here](#juicy). To get right into the code, click [here](#code)\n\nI decided to focus my efforts on a methodology for **overlaying the census tract data with the police districts Use of Force (UOF) data**. As in my starter kernel, I'm only providing analysis for Dept_37-00027 (Austin, TX), but the methodology is applicable for all of the departments.\n\n## 1. Downloading Census Data\n\nOne thing to note is that the census data provided in the `cpe-data` folder sometimes doesn't cover all of the police districts. For example, the census data is just for one county (Travis County), but Dept_37-00027 spans multiple counties. Therefore, I'll \"briefly\" cover how to properly search for and download data from the Census website.\n\n- Go to the [ACS website](\nhttps:\/\/www.census.gov\/acs\/www\/data\/data-tables-and-tools\/data-profiles\/2016\/)\n- Select the U.S. State, e.g. Texas, that the police department is in.\n- Click the \"Get Data Profile\" button\n- Click \"Demographic Characteristics\"\n- Click \"Add\/Remove Geography\"\n- \"Select a geographic type\" > \"Census Tract - 140\"\n- \"Select a state\" > \"Texas\"\n- Click \"All Census Tracts within Texas\"\n- Click \"Add to your Selections\"\n- Click \"Show Table\"\n- Click \"Modify Table\"\n- Click \"Transpose Rows\/Columns\"\n- A side menu on the left allows you to select a year (I'm using 2014 to align with the Use of Force data)\n- Click \"Download\"\n- Select \"Use Data\"\n- Uncheck \"Merge the annotations and data into a single file\"\n- Uncheck \"Include descriptive data element names\"\n- Click \"OK\"\n- Click \"Download\"\n- Rejoice that you don't have to use this website every day\n\nOne nice thing about the American FactFinder website is that you can save a \"Query\" file, so you and your friends can avoid the 18 steps above if you ever need to re-download the data. To save the \"Query\" file, once the Table is formatted just like you want it:\n\n- Click \"Bookmark\/Save\" > \"Save Query\"\n\nA `.aff` file will be downloaded. To use this file in the future, go to the [Advanced Search page](https:\/\/factfinder.census.gov\/faces\/nav\/jsf\/pages\/searchresults.xhtml?refresh=t) of the American FactFinder website, and click \"load search\". Choose the `.aff` file and hit \"OK\".\n\n## 2. Methodology\n\nSince the UOF data for Dept_37-00027 has `SUBJECT_RACE`, AND since we've just downloaded a fresh \"Demographic Characteristics\" file from the Census, let's use race as our example for how to overlay census data, that's traditionally served up in tract form, onto police districts, or `SECTOR`s as it's called in the Dept_37-00027 UOF data file.\n\nThe basic idea is to add up the populations (by race) of all of the census tracts contained within a police district (or SECTOR). This gets complicated by the fact that some census tracts are not contained 100% within a police district. Therefore, we have to somehow break up the populations of certain census tracts and re-distribute the populations. The obvious way, given the shapefiles, is to use areal fractions of the census tracts within the police districts. There are flaws associated with this. It (incorrectly) assumes:\n- that population is distributed equally among the entire area of the tract, and \n- the racial populations have the same distribution across any sub-division of a tract.\n\nWe'll accept these flaws because it allows us to derive decent estimates given the data that we have access to. However, there are [resources](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC4134912\/) in the literature that may provide a \"smarter\" way of interpolating.\n\nIgnoring these issues, for each SECTOR we'll do the following:\n- Using `geopandas.overlay`, we'll find the census tract [intersections](http:\/\/geopandas.org\/set_operations.html)\n- We'll calculate the areal fraction of each of the intersected tracts to use as weighting factors for the intersected tract populations:\n    - `areal_fraction = intersected_tract_area\/original_census_tract_area`\n    - For example, let's assume a census tract, 48001950100, intersects with a police SECTOR.\n        - `tract_48001950100_area = 100`\n        - `intersected_tract_48001950100_area = 40`\n        - -->`areal_fraction_interesected_tract_48001950100 = 0.4`\n- Therefore, the population of the intersected tract will be the `areal_fraction*census_tract_population`, where `census_tract_population` is available for each race\n- Finally, all of these newly calculated intersected tract populations for each race can be added up for each SECTOR\n    - We can also get the SECTOR racial population breakdown as percentages by dividing each racial population by the sum of the total population for each SECTOR\n    \nThus, this method accounts for both the **relative populations within all the census tracts**, as well as the **division of some census tracts, split between multiple police SECTORs**.\n    \nTo implement the above, we'll need quite a few `groupby`s and `merge`s, but the pandas\/geopandas functions are fairly straightforward.\n    \nThe UOF data gives us the SECTOR as `LOCATION_DISTRICT` (note: they're abbreviated). Therefore, all we have to do is use another `groupby` on the `LOCATION_DISTRICT` and apply a `value_counts` on the `SUBJECT_RACE` column to get the racial population breakdown of the UOF data.\n\nOnce we have both Census and UOF racial population breakdowns for all SECTORs, we can make some nice plots using Plotly to visualize potential bias.\n\n**<font color='#d64541'>WARNING:<\/font>**\nI make a note in the code below, but it's worth repeating. It's important to note how the [census defines race and ethnicity](https:\/\/www.census.gov\/mso\/www\/training\/pdf\/race-ethnicity-onepager.pdf) versus how the police departments are labeling race. Dept_37-00027 essentially has 4 labels within the `SUBJECT_RACE` category. Three of those labels (Black, White, Asian) are Race (or how the census defines race), and one of those labels is actually ethnicity (Hispanic). For example, my race is White, but my family comes from Mexico, so my ethnicity is Hispanic or Latino (i.e. I would tick both the \"White\" and the \"Hispanic or Latino\" boxes on the census form). Obviously, this complicates the analysis, but it also points to how complicated the [idea of Race as a label or category is](https:\/\/www.scientificamerican.com\/article\/race-is-a-social-construct-scientists-argue\/). \n\nAt the end of the day, we're interested in bias, which is related to perception, or how these police officers perceive the people they're arresting. I assume a police officer picks a label for the `SUBJECT_RACE` category, it's not up to the person to self-identify, as is the case in the census. So a disproportionate number of Use of Force incidents for a given `SUBJECT_RACE` will hopefully still indicate bias, since the `SUBJECT_RACE` is how police officers perceive the individuals they're arresting. Given these limitations, we'll use the \"Hispanic or Latino\" vs \"Not Hispanic or Latino - RACE\" categories, and build a dataset where we treat \"Hispanic or Latino\" as a race. While this is incorrect given how the census defines race and ethnicity, we're doing our best to align the census data with the police Use of Force data.\n\nI've noticed some other Kernels that use the \"One Race\" columns for \"White, Black, Asian, etc.\" (e.g. HC01_VC49) in addition to the Hispanic\/Latino column (HC01_VC88). This is **<font color='#d64541'>incorrect<\/font>**. Because latino people can also be \"White, Black, and Asian\", this would be double counting. Instead, use the \"Not Hispanic or Latino - RACE\" (e.g. HC01_VC94 for \"White\").\n\n[Jump to conclusion...](#conclusion)","4b417524":"SECTORs in the police UOF data are abbreviated. For consistency, we replace the abbreviations with the proper names","41aadab4":"<a id='juicy'><\/a>","0a5c0a04":"The following lines fail in the Kaggle Kernels without `rtree`. I'm reading in a pickled GeoDataFrame from my local copy of this notebook. I suggest you run this notebook locally. ","f3f2df39":"It's important to note how the [census defines race and ethnicity](https:\/\/www.census.gov\/mso\/www\/training\/pdf\/race-ethnicity-onepager.pdf) versus how the police departments are labeling race. Note above, the police department essentially has 4 labels within the 'SUBJECT_RACE' category. Three of those labels (Black, White, Asian) are Race (or how the census defines race), and one of those labels is actually ethnicity (Hispanic). For example, my race is White, but my family comes from Mexico, so my ethnicity is Hispanic or Latino (i.e. I would tick both the \"White\" and the \"Hispanic or Latino\" boxes on the census form). Obviously, this complicates the analysis, but it also points to how complicated the [idea of Race as a label or category is](https:\/\/www.scientificamerican.com\/article\/race-is-a-social-construct-scientists-argue\/).\n\nAt the end of the day, we're interested in bias, which is related to perception, or how these police officers perceive the people they're arresting. I assume a police officer picks a label for the \"SUBJECT_RACE\" category, it's not up to the person to self-identify, as is the case in the census. So a disproportionate number of Use of Force incidents for a given \"SUBJECT_RACE\" will hopefully still indicate bias, since the \"SUBJECT_RACE\" is how police officers perceive the individuals they're arresting. Given these limitations, we'll use the \"Hispanic or Latino\" vs \"Not Hispanic or Latino - RACE\" categories, and build a dataset where we treat \"Hispanic or Latino\" as a race. While this is incorrect given how the census defines race and ethnicity, we're doing our best to align the census data with the police Use of Force data.","4b5fd703":"<a id='conclusion'><\/a>\n## 3. Conclusion\n\nThis areal_fraction methodology can be used with other demographic information from the Census. It allows us to create snapshot visuals for departments, to help inform decision makers of how bias may or may not arise in different precincts. Care must be taken that we understand the categories and data definitions used by both the Census and the police departments. Fancy visuals can be distracting and misleading if we don't actually understand the underlying data. It is important to maintain open and clear communication with the police departments gathering and delivering this data. Without input from police officers and other stakeholders, interpreting the police Use of Force data can be very difficult. Feel free to leave comments if you have any ideas for how to improve this methodology. Best of luck to the rest of the participants.\n\n[Back to top...](#top)","a67c2468":"Since there aren't any corresponding Sectors in the police precinct ShapeFile, we can drop \"88\", \"-\" and \"NaN\".","f1c91237":"Much better...","a2c20e1c":"<a id='code'><\/a>","f7505903":"The above sums to 100 with some rounding error. These are the census column keys that we'll use going forward as our best proxy for the \"race\" labels in the police \"Use of Force\" data. But now we get back to the issue that the boundaries of the census tracts do not align nicely with the police precinct boundaries.","cbc1cc97":"Interactive plotly magic below"}}