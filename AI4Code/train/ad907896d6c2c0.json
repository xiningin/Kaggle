{"cell_type":{"d5a9ca46":"code","92af2eab":"code","2b2ceca4":"code","2c24dd38":"code","1fe4414c":"code","a909fd43":"code","cb8fbd32":"code","4a8a12c9":"code","7d8fc186":"code","45aa9e19":"code","bf651f1a":"code","3503f642":"code","5c2773a2":"code","62ca4f86":"code","502793cd":"code","47b3aae5":"code","2fd91e84":"code","7b8ac428":"code","8937e0c4":"code","4a8377df":"code","fe3c6144":"markdown","7e5d8e7f":"markdown","d0f2523b":"markdown","478b0618":"markdown","68a0b06b":"markdown","31f9c712":"markdown","a6451db7":"markdown","ddbb0ac2":"markdown","34d1afab":"markdown","6a481eea":"markdown","a39ac431":"markdown","7baad17f":"markdown","3909d8c1":"markdown","1fc5b4b9":"markdown","310ada12":"markdown","c9a69e48":"markdown","2fde66b2":"markdown"},"source":{"d5a9ca46":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntestfile = pd.read_csv(\"..\/input\/test.csv\")\ntrain.head(6)","92af2eab":"train.info()\ncorrelations_data = train.corr()['trip_duration'].sort_values()\ncorrelations_data","2b2ceca4":"train.describe()","2c24dd38":"plt.subplots(figsize=(18,6))\nplt.title(\"Visualisation des outliers\")\ntrain.boxplot();","1fe4414c":"#We only keep rows with a trip_duration between 100 and 10000 seconds.\ntrain = train[(train.trip_duration < 10000) & (train.trip_duration > 100)]","a909fd43":"#Removing 'id' and store_and_fwd_flag' columns\ntrain.drop(['id'], axis=1, inplace=True)\ntrain.drop(['store_and_fwd_flag'], axis=1, inplace=True)\ntestfile.drop(['store_and_fwd_flag'], axis=1, inplace=True)","cb8fbd32":"#Datetyping the dates so we can work with it\ntrain['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntestfile['pickup_datetime'] = pd.to_datetime(testfile.pickup_datetime)\ntrain.info()","4a8a12c9":"#Date features creations and deletions\ntrain['week'] = train.pickup_datetime.dt.week\ntrain['weekday'] = train.pickup_datetime.dt.weekday\ntrain['hour'] = train.pickup_datetime.dt.hour\ntrain.drop(['pickup_datetime'], axis=1, inplace=True)\ntrain.drop(['dropoff_datetime'], axis=1, inplace=True)\ntestfile['week'] = testfile.pickup_datetime.dt.week\ntestfile['weekday'] = testfile.pickup_datetime.dt.weekday\ntestfile['hour'] = testfile.pickup_datetime.dt.hour\ntestfile.drop(['pickup_datetime'], axis=1, inplace=True)","7d8fc186":"#Visualising the distribution of trip_duration values\nplt.subplots(figsize=(18,6))\nplt.hist(train['trip_duration'].values, bins=100)\nplt.xlabel('trip_duration')\nplt.ylabel('number of train records')\nplt.show()","45aa9e19":"#Log transformation\nplt.subplots(figsize=(18,6))\ntrain['trip_duration'] = np.log(train['trip_duration'].values) #+1 is not needed here as our trip_duration values are all positive and not normalized. But it would be necessary to normalize and add 1 to make a robust code for new data.\nplt.hist(train['trip_duration'].values, bins=100)\nplt.xlabel('log(trip_duration)')\nplt.ylabel('number of train records')\nplt.show()","bf651f1a":"y = train[\"trip_duration\"]\ntrain.drop([\"trip_duration\"], axis=1, inplace=True)\nX = train\nX.shape, y.shape","3503f642":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","5c2773a2":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=42)\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape","62ca4f86":"from sklearn.ensemble import RandomForestRegressor\n\n#The randomforestregressor params are chosen in the following hyperparameters tuning\nm1 = RandomForestRegressor(n_estimators=19, min_samples_split=2, min_samples_leaf=4, max_features='auto', max_depth=80, bootstrap=True)\nm1.fit(X_train, y_train)\nm1.score(X_valid, y_valid)","502793cd":"#from sklearn.ensemble import GradientBoostingRegressor\n\n#gradient_boosted = GradientBoostingRegressor()\n#gradient_boosted.fit(X_train, y_train)\n#gradient_boosted.score(X_valid, y_valid)\n\n#score: around 0.5","47b3aae5":"from sklearn.metrics import mean_squared_error as MSE\n\nprint(np.sqrt(MSE(y_valid, m1.predict(X_valid))))\n#print(np.sqrt(MSE(y_valid, gradient_boosted.predict(X_valid))))\n","2fd91e84":"#from sklearn.model_selection import RandomizedSearchCV\n\n#n_estimators = [int(x) for x in np.linspace(start = 5, stop = 20, num = 16)]\n#max_features = ['auto', 'sqrt']\n#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n#max_depth.append(None)\n#min_samples_split = [2, 5, 10]\n#min_samples_leaf = [1, 2, 4]\n#bootstrap = [True, False]\n\n#random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n\n#random_cv = RandomizedSearchCV(estimator = m1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n#print(random_cv.best_params_)","7b8ac428":"test_columns = X_train.columns\npredictions = m1.predict(testfile[test_columns])","8937e0c4":"my_submission = pd.DataFrame({'id': testfile.id, 'trip_duration': np.exp(predictions)})\nmy_submission.head()","4a8377df":"my_submission.to_csv(\"sub.csv\", index=False)","fe3c6144":"### Hyperparameters tuning","7e5d8e7f":"## Predictions and Submission","d0f2523b":"We are going to look at the better combination of hyperparameters using RandomizedSearchCV. It took me 138.2min to run this cell so be patient if you're using it.","478b0618":"## Data Loading and Exploration","68a0b06b":"We have 1458644 rows for each column so there are no missing values.","31f9c712":"# New York City Taxi Trip Duration","a6451db7":"Now that we can work with our dates, we are going to create relevant date features for our model. We'll store the week, the weekday and the hour in our dataframe.","ddbb0ac2":"The distribution is right-skewed so we can consider a log-transformation of `trip_duration` data.","34d1afab":"First of all, let's select the features we need to make our predicting model.  \n`id` is unique and linked to a specific trip so there's not point in keeping it in our model. `store_and_fwd_flag` is not relevant to make predictions as I assume that vehicle memories work well and that it don't change the trip duration.","6a481eea":"Now that we have our features, we can take a look at our target.","a39ac431":"RandomForestRegressor seems to fit better than GradientBoostingRegressor. Now here is how I chose the RFR hyperparameters.","7baad17f":"## Data Cleaning","3909d8c1":"#### Deal with dates","1fc5b4b9":"## Features engineering (selection & transformations)","310ada12":"## Model Selection and Training","c9a69e48":"We clearly see `trip_duration` takes strange values for `min` and `max`. Let's have a quick visualisation with a boxplot.","2fde66b2":"There are outliers for `trip_duration`. I can't find a proper interpretation and it will probably damage our model, so I choose to get rid of them. We will only keep what I assume to be legit trips, i.e. between 100 and 10000 seconds."}}