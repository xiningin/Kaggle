{"cell_type":{"cd103d45":"code","17579311":"code","0fd8d57e":"code","e4fb6d0b":"code","d077dac3":"code","7e9b707e":"code","7fbe028c":"code","84a141e0":"code","df19c5d7":"code","119b3ef9":"markdown","4a9a5472":"markdown","07b9205d":"markdown","60910422":"markdown","d1dd9557":"markdown","572bc085":"markdown"},"source":{"cd103d45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17579311":"# Because the image dataset is so large, the train dataset is too large to be loaded in on Kaggle. Therefore we are using the test dataset\n# import the satellite data\nX_train = pd.read_csv('\/kaggle\/input\/deepsat-sat4\/X_test_sat4.csv', header = None).values.reshape([100000,28,28,4])\nY_train = pd.read_csv('\/kaggle\/input\/deepsat-sat4\/y_test_sat4.csv', header = None)\n\n# normalise the training data\nX_train_norm = X_train\/X_train.max()","0fd8d57e":"# we want to visualise the data that we are dealing with. Before that we want to have a list of the classifications for each image so that we can plot it with our image\n\nY_name = Y_train.copy()\n\ndef convert_bool_df_to_value(df):\n    \n    df.loc[:,'Name'] = np.zeros(len(df))\n\n    df.loc[:,'Name'][df[0] == 1] = 'Barren_Land'\n    df.loc[:,'Name'][df[1] == 1] = 'Trees'\n    df.loc[:,'Name'][df[2] == 1] = 'Grassland'\n    df.loc[:,'Name'][df[3] == 1] = 'Other'\n\n\n    return df['Name']\n\nY_name = convert_bool_df_to_value(Y_name)","e4fb6d0b":"fig = plt.figure(figsize = (20,20))\n\nfor num, X, name in zip(np.arange(1,101), X_train, Y_name):\n    ax = fig.add_subplot(10,10,num)\n    ax.imshow(X[:,:,:3])\n    ax.axis('off')\n    ax.set_title(name)\nplt.tight_layout()","d077dac3":"# Let's try to build a relivately simple model that has good accuracy\n\n#%%time\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential()\n\n# simple model consisting of 4 layers, focused on retrieving the most prominent features\nmodel.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape = (28,28,4)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(4, activation='softmax'))\n\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train_norm,Y_train, batch_size=32, epochs=50, verbose=1, validation_split=0.05)\nmodel.summary()","7e9b707e":"Y_pred = model.predict(X_train_norm)","7fbe028c":"Y_pred_name = Y_pred.copy()\n\n# set highest probability to 1 and rest to 0\nY_pred_name[range(len(Y_pred_name)),\n                   Y_pred_name.argmax(axis = 1)] = 1\nY_pred_name[Y_pred_name != 1.] = 0\n\n# convert bool variable to actual name\nY_pred_name = convert_bool_df_to_value(pd.DataFrame(Y_pred_name))","84a141e0":"Y_false = Y_pred_name[Y_pred_name != Y_name]\nY_true = Y_pred_name[Y_pred_name == Y_name]\nX_false = X_train[Y_pred_name != Y_name]","df19c5d7":"fig = plt.figure(figsize = (20,20))\nk = 1\n\nfor X, Y_n, Y_p in zip(X_train[:10000], Y_name[:10000], Y_pred_name[:10000]):\n    if Y_n != Y_p:\n        ax = fig.add_subplot(10,10,k)\n        ax.imshow(X[:,:,:3])\n        ax.axis('off')\n        ax.set_title('pred = {} \\n true = {}'.format(Y_p, Y_n), color = 'red')\n        k += 1\n    else:\n        continue\nplt.tight_layout()","119b3ef9":"Looks like our model has 98% accuracy after 50 epochs (15 min). Not bad for a simple model.","4a9a5472":"lets take a look at the first 100 images in the dataset (assuming the dataset is randomly shuffled)","07b9205d":"We can see there are definitely grouping features. Trees are greenish and have round edges. Barren land is relatively homogeneous and dirt colored. Grassland is also relatively homogeneous but more greenish colored. We hope that our model is able to pick up on these features.","60910422":"Our model still makes some mistakes. It seems biased towards predicting trees whenever there are sharp edges or shadows. Or whenever the distinction between grassland and barren land is not clear. But overall it does quite well with almost 99% accuracy.","d1dd9557":"# Welcome. This is an example of image classification using TensorFlow. We are using a satellite image dataset from Kaggle","572bc085":"lets make a plot of some of our falsily classified data to see what it looks like"}}