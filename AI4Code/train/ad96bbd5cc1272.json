{"cell_type":{"e11e6867":"code","b1e9600b":"code","4607d94c":"code","acd36f32":"code","c6745957":"code","a22a7a40":"code","b85b3d7c":"code","2d0a303c":"code","d69e97fe":"code","59f14d01":"markdown","2ba5dac4":"markdown","df819af8":"markdown","d19bead4":"markdown","bafaf197":"markdown","7fa18dd1":"markdown","3edc171f":"markdown","83eebee9":"markdown","d573b1db":"markdown","61bac6cd":"markdown","e0e219cc":"markdown"},"source":{"e11e6867":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\nfrom tqdm import tqdm_notebook\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntest['target'] = 'unknown'","b1e9600b":"def plot_2d(df, x, y):\n    plt.figure(figsize=(16,10))\n    sns.scatterplot(\n        x=x, y=y,\n        hue='target',\n        palette=sns.color_palette('bright', 3),\n        data=df,\n        legend='full',\n        alpha=0.9\n    )\n    plt.show()\n    \n\ndef plot_3d(df, x, y, z):\n    trace1 = go.Scatter3d(x=df[x].values, y=df[y].values, z=df[z].values,\n        mode='markers',\n        marker=dict(\n            color=df['target'].values,\n            colorscale = \"Jet\",\n            opacity=0.,\n            size=2\n        )\n    )\n\n    figure_data = [trace1]\n    layout = go.Layout(\n        scene = dict(\n            xaxis = dict(title=x),\n            yaxis = dict(title=y),\n            zaxis = dict(title=z),\n        ),\n        margin=dict(\n            l=0,\n            r=0,\n            b=0,\n            t=0\n        ),\n        showlegend=True\n    )\n\n    fig = go.Figure(data=figure_data, layout=layout)\n    py.iplot(fig, filename='3d_scatter')","4607d94c":"MAGIC_N = 42\ntrain_subset = train[train['wheezy-copper-turtle-magic'] == MAGIC_N]\ntest_subset = test[test['wheezy-copper-turtle-magic'] == MAGIC_N]\nconcated = pd.concat([train_subset, test_subset])\n\na = train_subset.std() > 1.2\ncols = [idx for idx in a.index if a[idx]]\nconcated = concated[cols + ['target']]","acd36f32":"X_embedded = TSNE(n_components=2, perplexity=25, random_state=50).fit_transform(concated[cols].values)\nconcated['tsne2_1'] = X_embedded[:, 0]\nconcated['tsne2_2'] = X_embedded[:, 1]","c6745957":"plot_2d(concated, x='tsne2_1', y='tsne2_2')","a22a7a40":"X_embedded = TSNE(n_components=3, perplexity=20, random_state=42).fit_transform(concated[cols].values)\nconcated['tsne3_1'] = X_embedded[:, 0]\nconcated['tsne3_2'] = X_embedded[:, 1]\nconcated['tsne3_3'] = X_embedded[:, 2]","b85b3d7c":"concated = concated.reset_index(drop=True)\nplot_3d(concated.loc[:len(train_subset)-1], x='tsne3_1', y='tsne3_2', z='tsne3_3')","2d0a303c":"train_projected = concated.loc[:len(train_subset)-1][['tsne2_1', 'tsne2_2', 'target']]\ntrain_projected['target'] = train_projected['target'].values.astype(int)\n\noof = np.zeros(len(train_projected))\n\nskf = StratifiedKFold(n_splits=5, random_state=42)\nfor trn_idx, val_idx in skf.split(train_projected['target'], train_projected['target']):\n    X_tr, y_tr = train_projected.loc[trn_idx][['tsne2_1', 'tsne2_2']], train_projected.loc[trn_idx]['target']\n    X_val, y_val = train_projected.loc[val_idx][['tsne2_1', 'tsne2_2']], train_projected.loc[val_idx]['target']\n    \n    clf = CatBoostClassifier(depth=5, eval_metric='AUC')\n    clf.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=333)\n    oof[val_idx] = clf.predict(X_val)","d69e97fe":"auc_score = roc_auc_score(train_projected['target'], oof)\nprint(f'AUC on wheezy-copper-turtle-magic={MAGIC_N} is - {auc_score}')","59f14d01":"# T_SNE Visualisation","2ba5dac4":"# Non-linear dimensionality reduction to 2 dims","df819af8":"Wow! It works pretty well. Blue and orange points looks differentiable. Probabaly some tree-based method will work with this.","d19bead4":"Chris done great investigation <a href=\"https:\/\/www.kaggle.com\/cdeotte\/support-vector-machine-0-925\">here<\/a>, that `wheezy-copper-turtle-magic` value identifies one of 512 datasets, combined in one. <br>\nAll datasets have target that **non-linarly** dependent on approximately 40 features, that have std > 1. <br>\nI decided to check how well t-sne will work with these datasets.","bafaf197":"## Thank you for reading!","7fa18dd1":"# Let's check how catboost will deal with it","3edc171f":"# Non-linear dimensionality reduction to 3 dims","83eebee9":"# Choose one of datasets and reduce amount of columns","d573b1db":"Score is not so high, but probably these features can be combined with original and you will have some boost. <br>\n**But be careful!** Results will be different because it will work on unseen private set.","61bac6cd":"# Plot functions \nI would like to thank @allunia for pretty `plot_3d` function taken from <a href=\"https:\/\/www.kaggle.com\/allunia\/instant-gratification-some-eda-to-go\">here<\/a>.","e0e219cc":"# Load data"}}