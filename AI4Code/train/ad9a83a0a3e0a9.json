{"cell_type":{"03975a32":"code","3f70ff0a":"code","497ffe16":"code","15d1eb75":"code","15926491":"code","9061a8f7":"code","4f2aea1d":"code","76d3d8f7":"code","fa77c9f6":"code","f5794cce":"code","3ed71f5f":"code","e758d06b":"code","04dd6094":"code","d8088cbb":"code","f4d8bc00":"code","07e660c4":"code","d5ea9db4":"code","59bc7e03":"code","0051d084":"code","ee0edf44":"code","f9d82380":"code","bd32b3ee":"code","dbb4b2ca":"code","a2d847a9":"code","0a31ded2":"code","cabe4beb":"code","8ea2b045":"code","1271e2d8":"code","c52c8ac1":"code","c75442bb":"code","6c689300":"code","927c1170":"code","dd18595f":"markdown","d205e2a7":"markdown","da98ecf9":"markdown","a428e065":"markdown","fbd8c9b4":"markdown","b41cf863":"markdown","4bb1904b":"markdown","6ac14e9c":"markdown","4b3fd3c9":"markdown","bea56c09":"markdown","cee9c691":"markdown","ce213165":"markdown","35277250":"markdown","5ef38e2e":"markdown","5c744775":"markdown"},"source":{"03975a32":"import numpy as np\nimport pandas as pd\nimport datetime\nfrom catboost import CatBoostClassifier\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\n\nimport subprocess\nfrom ast import literal_eval","3f70ff0a":"from sklearn.metrics import confusion_matrix\ndef qwk(act,pred,n=4,hist_range=(0,3)):\n    '''\n    cohen's kappa\ub294 \ub450 \ub370\uc774\ud130\uc758 \uac12 \uc911 \uc6b0\uc5f0\uc5d0 \uc758\ud574 \uc77c\uce58\ud558\ub294 \ubd80\ubd84\uc744 \uc81c\uc678\ud558\uace0 \n    \uc2e4\uc81c \ud3c9\uac00\uc5d0 \uc758\ud574 \uac12\uc774 \uc77c\uce58\ud558\ub294 \uc815\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uc774\ub2e4.\n    \ubc94\uc8fc\uac04 \ucc28\uc774\uc758 \ube44\uc911\uc744 \uc81c\uacf1\ud558\ubbc0\ub85c q(quadratic)\uac00 \ubd99\uc740 \uac83.\n    '''\n    O = confusion_matrix(act,pred)\n    O = np.divide(O,np.sum(O))\n    \n    W = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            W[i][j] = ((i-j)**2)\/((n-1)**2)\n            \n    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n    \n    E = np.outer(act_hist,prd_hist)\n    E = np.divide(E,np.sum(E))\n    \n    num = np.sum(np.multiply(W,O))\n    den = np.sum(np.multiply(W,E))\n        \n    return 1-np.divide(num,den)\n    ","497ffe16":"train = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\nspecs = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/specs.csv')\ntest = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')","15d1eb75":"# encode title\n# 'title' \ud56d\ubaa9\uc744 activity\ub77c\uace0 \uba85\uba85\ud558\uace0 0\ubd80\ud130 \uc2dc\uc791\ud558\ub294 \uc22b\uc790 \uac12\uc73c\ub85c \ubcc0\ud658\ud560 \uc218 \uc788\ub294 dictionary\ub97c \ub9cc\ub4e0\ub2e4.\nlist_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\n# train\/test \ub370\uc774\ud130\uc758 title\uc744 \uc22b\uc790\uac12\uc73c\ub85c \uce58\ud658\ud55c\ub2e4.\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)","15926491":"train.head(30)","9061a8f7":"train_labels.head()","4f2aea1d":"print(\"list_of_user_activities:\")\nprint(list_of_user_activities)\nprint(\"activities_map:\")\nprint(activities_map)","76d3d8f7":"win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110\nprint(win_code)","fa77c9f6":"train['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","f5794cce":"def make_session_data(user_sample, test_set=False):\n    '''\n    user_sample : train.groupby('installation_id', sort=False)\n        installation_id\ub85c \ubb36\uc778 \ubb49\ud145\uc774    \n    \n    test_set \uc778 \uacbd\uc6b0 \ub9c8\uc9c0\ub9c9 assessment\ub9cc \ub0a8\uae34\ub2e4.\n    '''\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = [] # \ubaa8\ub4e0 assessment \uc138\uc158\uc758 \uc694\uc57d\uc815\ubcf4(accuracy_group\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec column\uc774 \uc788\uc74c)\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    durations = []\n    \n    for i, session in user_sample.groupby('game_session', sort=False): #game_session \uae30\uc900\uc73c\ub85c \ub610 group \n        \"\"\"\n        session \uae30\uc900\uc73c\ub85c \ubb36\uc73c\uba74 \ud55c session \uc5d0\uc11c \uc77c\uc5b4\ub09c \uc774\ubca4\ud2b8\ub4e4\uc774 \ub098\uc5f4\ub41c dataframe\uc744 \uc5bb\uc744 \uc218 \uc788\ub2e4.\n        \uacb0\uad6d \uac01\uac01\uc758 session\ub9c8\ub2e4 \ucc98\ub9ac\ub97c \ud558\ub294 code block\uc784.\n        \"\"\"\n        # type : Clip\/Activity\/Assessment\/Game\n        # title : \uc5ec\uae30\uc11c\ub294 \uc22b\uc790\ub85c \ubcc0\uacbd\ub418\uc5b4 \uc788\uc74c\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        if test_set == True:\n            second_condition = True\n        else:\n            if len(session)>1:\n                second_condition = True\n            else:\n                second_condition= False\n        \n        # session_type\uc774 Assessment\uc778 \uacbd\uc6b0\ub9cc \ud544\uc694\ud558\ub2e4.\n        # session\uc774 Assessment(\ud3c9\uac00) \ud0c0\uc785\uc77c \uacbd\uc6b0 \uc5ec\uae30 \uc131\uacf5\/\uc2e4\ud328 \ub4f1\uc758 \uc815\ubcf4\uac00 \uc788\ub2e4.\n        # 'Assessment' \uc138\uc158\uc758 \uc774\ubca4\ud2b8\ub4e4\uc744 \ubd84\uc11d\ud574\uc11c \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud55c\ub2e4.\n        if (session_type == 'Assessment') & (second_condition):\n            '''\n            'Assessment' \uc138\uc158\uc5d0\uc11c \uc77c\uc5b4\ub09c \uc774\ubca4\ud2b8\ub4e4\uc758 \ubaa9\ub85d\n            '''\n            all_attempts = session.query(f'event_code == {win_code[session_title]}') #event_code\uac00 win_code(\ud558\ub098\ube7c\uace0 4100)\uc778 \uac83\uc744 \ubaa8\uc740\ub2e4.\n            true_attempts = all_attempts['event_data'].str.contains('true').sum() # \uc131\uacf5\ud69f\uc218(event_data\uc5d0 'true'\ubb38\uc790\uc5f4\uc774 \uc787\ub294\uac00?)\n            false_attempts = all_attempts['event_data'].str.contains('false').sum() # \uc2e4\ud328\ud69f\uc218(event_data\uc5d0 'false'\ubb38\uc790\uc5f4\uc774 \uc787\ub294\uac00?)\n            #print(\"\", all_attempts.shape[0], \"true:\", true_attempts, \"false:\", false_attempts)\n            features = user_activities_count.copy()\n            features['session_title'] = session_title\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)            \n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds) #\ub9c8\uc9c0\ub9c9\uc758 timestamp(2, \uc138\ubc88\uc9f8 column)\uc5d0\uc11c \ucc98\uc74c\uc744 \ube7c\uc11c session\uc758 \uc2e4\ud589\uc2dc\uac04\uc744 \uc5bb\ub294\ub2e4.\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            # \uc815\ud655\ub3c4\ub97c \uacc4\uc0b0\ud55c\ub2e4.\n            #print(\"true_attempts:\", true_attempts, \"false_attempts:\", false_attempts)\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            '''\n            accuracy_group:\n            session \uae30\uc900\uc73c\ub85c accuracy_group\ub97c \uacc4\uc0b0\ud560 \uc218 \uc788\ub2e4.\n                3: the assessment was solved on the first attempt\n                2: the assessment was solved on the second attempt\n                1: the assessment was solved after 3 or more attempts\n                0: the assessment was never solved\n                \n            \ucf54\ub4dc\ub97c \ubcf4\uba74 \ud3c9\uade0\ub0b4\uc11c \ud558\ub294 \uac83 \uac19\uc740\ub370, \uc544\ub9c8 1\uac1c\uc758 true\uc640 0\uac1c \uc774\uc0c1\uc758 false \ud639\uc740\n            0\uac1c\uc758 true\uc640 \uc5ec\ub7ec\uac1c\uc758 false\uac00 \uc788\ub294 \uc2dd\uc778\ub4ef.\n            '''\n            if accuracy == 0: # \ud574\uacb0 \ubabb\ud588\ub2e4.\n                features['accuracy_group'] = 0\n            elif accuracy == 1: #\uc2e4\ud328\uac00 \uc5c6\uc74c\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5: # \ud55c\ubc88 \uc2e4\ud328\ud558\uace0 \uc131\uacf5\n                features['accuracy_group'] = 2\n            else: # 3\ubc88 \uc774\uc0c1 \uc2e4\ud328\ud568.\n                features['accuracy_group'] = 1\n                \n            # update() : modify in place using non-NA values from another dataframe\n            # \uac19\uc740 column\uc774 \uc788\uc73c\uba74 \ub118\uc5b4\uc628 dataframe\uac12\uc73c\ub85c \ub300\uccb4\ud55c\ub2e4.\n            features.update(accuracy_groups)\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            features['accumulated_actions'] = accumulated_actions\n            accumulated_accuracy_group += features['accuracy_group']\n            accuracy_groups[features['accuracy_group']] += 1\n            if test_set == True:\n                all_assessments.append(features)\n            else:\n                if true_attempts+false_attempts > 0:\n                    all_assessments.append(features)\n                \n            counter += 1\n\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n    \n    \"\"\"\n    FIXME: \uc5ec\uae30\ub294 check\uac00 \ud544\uc694\ud568.    \n    if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    \n    test \ub370\uc774\ud130\uc758 \uacbd\uc6b0 \uae30\uae30(installation_id)\uc758 \ub9c8\uc9c0\ub9c9 assessment\uc758 accuracy_group\uc744 \uc608\uce21\ud574\uc57c \ud55c\ub2e4.\n    \uadf8\ub7ec\ubbc0\ub85c \ub9c8\uc9c0\ub9c9 assessment\ud56d\ubaa9\ub9cc \ub0a8\uae30\ub294 \ucf54\ub4dc\uac00 \uc788\ub294\uac74\ub370... \n    \uadf8\ub7ec\uba74 \uadf8 \uc55e\uc758 \ub370\uc774\ud130\ub4e4\uc740 \uc544\ubb34\ub7f0 \ud544\uc694\uac00 \uc5c6\ub294 \uac83\uc778\uc9c0...?\n    \ub2e4\ub978 \ud3c9\uac00\uac00 \uc774\ub8e8\uc5b4\uc9c4(Assessment\uc774\uace0 event_data\uc5d0 true\/false \uc788\uc74c) \uc138\uc158\ub3c4 \ub9ce\uc544\uc11c...\n    \n    \uc77c\ub2e8 \ub2e4\ub978 \ucee4\ub110\ub4e4\uc744 \ubcf4\uba74 \uc544\ub798\ucc98\ub7fc \ucc98\ub9ac(\uc81c\uac70\ud568)\ud558\ub294 \uac83 \uac19\ub2e4.\n    \uc810\uc218\uac00 \ub192\uc740 \ub178\ud2b8\ubd81\ub4e4\uc5d0\uc11c\ub3c4 \ubaa8\ub450 \ub0a0\ub9ac\ubbc0\ub85c \ub0a0\ub9ac\ub294\uac83\uc774 \ub9de\ub294\ub4ef.\n    \ub0a0\ub9ac\ub294 \ub178\ud2b8\ubd81\ub4e4:    \n        https:\/\/www.kaggle.com\/artgor\/quick-and-dirty-regression\n        https:\/\/www.kaggle.com\/hengzheng\/bayesian-optimization-seed-blending\n        \n    \"\"\"\n    if test_set:\n        return all_assessments[-1]\n    \n    # in the train_set, all assessments goes to the dataset\n    return all_assessments","3ed71f5f":"def make_assessment_group_data(df, is_test_set=False):\n    compiled_data = list() \n    total_cnt = df.installation_id.unique().shape[0]\n    for i, (ins_id, user_sample) in tqdm(enumerate(df.groupby('installation_id', sort=False)), total=total_cnt):        \n        sdata = make_session_data(user_sample, test_set=is_test_set)\n        \n        if type(sdata) is list:\n            compiled_data += sdata\n        else:\n            compiled_data.append(sdata)\n\n    newTrain = pd.DataFrame(compiled_data)    \n    return newTrain","e758d06b":"new_train = make_assessment_group_data(train)","04dd6094":"new_train.head()","d8088cbb":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\nprint(all_features)","f4d8bc00":"new_train.head()","07e660c4":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\ncat_features = ['session_title'] #train\uc758 'title' \ud56d\ubaa9\nX, y = new_train[all_features], new_train['accuracy_group']\ndel train","d5ea9db4":"X.head()","59bc7e03":"X.columns.tolist()","0051d084":"y.head()","ee0edf44":"def make_classifier():\n    clf = CatBoostClassifier(\n        loss_function='MultiClass',    \n        task_type=\"CPU\",\n        learning_rate=0.01,\n        iterations=2000,\n        od_type=\"Iter\",\n        early_stopping_rounds=500,\n        random_seed=2019)\n    \n    return clf","f9d82380":"# CV\nfrom sklearn.model_selection import KFold\noof = np.zeros(len(X))\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n\ntraining_start_time = time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n    start_time = time()\n    print(f'Training on fold {fold+1}')\n    clf = make_classifier()\n    clf.fit(X.loc[trn_idx, all_features], y.loc[trn_idx], eval_set=(X.loc[test_idx, all_features], y.loc[test_idx]),\n                          use_best_model=True, verbose=500, cat_features=cat_features)\n    \n#     preds += clf.predict(X_test).reshape(len(X_test))\/NFOLDS\n    oof[test_idx] = clf.predict(X.loc[test_idx, all_features]).reshape(len(test_idx))\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n    \nprint('-' * 30)\nprint('OOF QWK:', qwk(y, oof))\nprint('-' * 30)","bd32b3ee":"# train model on all data once\nclf = make_classifier()\nclf.fit(X, y, verbose=500, cat_features=cat_features)\n\ndel X, y","dbb4b2ca":"X_test = make_assessment_group_data(test, is_test_set=True)\nX_test.head()","a2d847a9":"X_test.head()","0a31ded2":"test_columns = X_test.columns.tolist()\nprint(len(test_columns), \"columns:\\n\", test_columns)","cabe4beb":"X_test = X_test[all_features]","8ea2b045":"# make predictions on test set once\npreds = clf.predict(X_test)","1271e2d8":"X_test.head(10)","c52c8ac1":"submission['accuracy_group'] = np.round(preds).astype('int') #\uc774 \ubd80\ubd84\uc5d0 OptimizedRounder\uac00 \ud544\uc694\ud568.\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head()","c75442bb":"submission['accuracy_group'].plot(kind='hist')","6c689300":"train_labels['accuracy_group'].plot(kind='hist')","927c1170":"pd.Series(oof).plot(kind='hist')","dd18595f":"activity(\uc6d0\ub798 title)\ub9c8\ub2e4 \ud574\ub2f9\ud558\ub294 win_code\ub97c \ub9cc\ub4e0\ub2e4.<br>\n'Bird Measurer (Assessment)'\ub9cc 4110\uc774\uace0 \ub098\uba38\uc9c0\ub294 4100\uc784","d205e2a7":"Note that Cross validation is only for the feature engineering part and you don't actually need it if you want to submit the results. You can safely comment it out. \n\nCV\ub85c \ud558\ub294 \uac83\uc740 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0, \uc804\uccb4 \ub370\uc774\ud130\ub85c \ud55c\ubc88\ub9cc train\ud55c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c\ub2e4\uace0 \ud55c\ub2e4.\n\uae30\uc874 \uc774\ubbf8\uc9c0 \ud310\ubcc4 \ubb38\uc81c\uc640\ub294 \ub2e4\ub978 \ubc29\ubc95\uc778 \uac83 \uac19\uc740\ub370... \n\uc774\uc0c1\ud558\ub124...?","da98ecf9":"make_session_data()\ud568\uc218\ub85c train \ub370\uc774\ud130\ub97c session\uc5d0 \ub300\ud55c \uc694\uc57d \uc815\ubcf4(accuracy_group \ud56d\ubaa9 \uc0dd\uc131\ud574\uc11c \ud3ec\ud568) \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud55c\ub2e4.","a428e065":"\uc704 train \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub358 \uac83\uacfc \ub3d9\uc77c\ud55c \ubc29\ubc95\uc73c\ub85c test\ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud574\uc11c \uc0dd\uc131\ud55c\ub2e4.","fbd8c9b4":"Below are the features I have generated. Note that all of them are **prior** to each event. For example, the first row shows **before** this assessment, the player have watched 3 clips, did 3 activities, played 4 games and solved 0 assessments, so on so forth.\n\n**new_train columns:**\n\n- 'Clip'\n- 'Activity'\n- 'Assessment'\n- 'Game'\n- 'session_title'\n- 'accumulated_correct_attempts'\n- 'accumulated_uncorrect_attempts'\n- 'duration_mean'\n- 'accumulated_accuracy'\n- 'accuracy_group'\n- 0\n- 1\n- 2\n- 3\n- 'accumulated_accuracy_group'\n- 'accumulated_actions'","b41cf863":"\ud544\uc694\ud55c csv \ud30c\uc77c\ub4e4\uc744 \uc77d\uc5b4\ub4e4\uc778\ub2e4.","4bb1904b":"- X: 'accuracy_group'\ub97c \uc81c\uc678\ud55c \ubaa8\ub4e0\uac83.\n- y: 'accuracy_group'","6ac14e9c":"## EDA","4b3fd3c9":"## 2019 Data Science Bowl\n\n\uc774 \ub178\ud2b8\ubd81\uc740 \ub2e4\uc74c \ub178\ud2b8\ubd81 \ub0b4\uc6a9\uc744 \ubd84\uc11d \ubc0f \uc815\ub9ac\ud55c \uac83\uc785\ub2c8\ub2e4 :\n    https:\/\/www.kaggle.com\/mhviraf\/a-new-baseline-for-dsb-2019-catboost-model\n   \n\n#### \uc694\uc57d :\n1. \uc774\ubca4\ud2b8 \ubaa9\ub85d\uc744 \uac01\uac01\uc758 session\ub9c8\ub2e4 accuracy_group\uc744 \uad6c\ud558\ub294 \ud568\uc218\ub97c \ub9cc\ub4e0\ub2e4. ------ A(x)\n2. train \ub370\uc774\ud130\ub97c \uc704 \ud568\uc218(A)\ub97c \uc0ac\uc6a9\ud574\uc11c \ubcc0\ud658\ud55c\ub2e4. ------ a = A(train)\n3. a\uc758 \ub370\uc774\ud130\uc5d0\uc11c accuracy_group\uc744 y, \ub098\uba38\uc9c0 \ud56d\ubaa9\uc744 X\ub85c \ud574\uc11c model\uc744 \ud6c8\ub828\ud55c\ub2e4.\n4. test\ub370\uc774\ud130\ub85c b = A(test)\ub97c \uad6c\ud574\uc11c \uc704 \ubaa8\ub378\ub85c predict\ud55c\ub2e4.\n\n\n#### Submission :\ntest_set\uc758 \uac01\uac01\uc758 installation_id\uc5d0 \uc874\uc7ac\ud558\ub294 \ub9c8\uc9c0\ub9c9 assessment\ub9c8\ub2e4 accuracy_group\uc744 \uc608\uce21\ud574\uc57c \ud55c\ub2e4.\n\ud30c\uc77c\uc740 installation_id, accuracy_group\uc758 \ub450 column\uc73c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc5b4\uc57c \ud55c\ub2e4.","bea56c09":"pred\ub97c accuracy_group\uc73c\ub85c \uc815\ud574\uc11c csv\ud30c\uc77c\uc744 \uc0dd\uc131\ud55c\ub2e4.<br>\nsubmission\uc740 sample_submission.csv\ud30c\uc77c\uc744 \uc77d\uc5b4\ub4e4\uc778 \uac83\uc778\ub370, sample_submission\uc758 installation_id \uc21c\uc11c\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud55c\ub2e4.<br>\n\uc704\uc5d0\uc11c groupby(sort=False)\uc5ec\uc11c \ubb38\uc81c \uc5c6\ub294\ub4ef.","cee9c691":"no intersection between installation ids of train and test","ce213165":"submission \ud3c9\uac00\ub294 QWK(Quadratic Weighted Kappa)\ub85c \uc774\ub8e8\uc5b4\uc9c4\ub2e4.\n\n**Cohen's Kappa**\n\n    \ub450 \uc5f0\uad6c\uc790\uac04 \ub3d9\uc77c\ud55c \uacb0\uacfc\ub97c \ub0b4\ub193\ub294\uc9c0\ub97c \uc218\uce58\ud654\ud558\ub294 \ubc29\ubc95\uc774\ub2e4.\n    \ub354 \uc790\uc138\ud788 \uc124\uba85\ud558\uba74, \ub450 \uc5f0\uad6c\uc790 \uac04 \uc77c\uce58\ud55c \uacb0\uacfc \uc911\uc5d0\uc11c \uc6b0\uc5f0\ud788 \uc77c\uce58\ud560 \uac00\ub2a5\uc131\ub97c \uc81c\uc678\ud558\uace0, \uc2e4\uc81c\ub85c \ud3c9\uac00\uac00 \uc77c\uce58\ud55c \uacb0\uacfc\uac00 \uc5b4\ub290 \uc815\ub3c4\uc778\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uc774\ub2e4.\n    nominal(category\uac04 \uac70\ub9ac\uac00 \uac19\uc740)\ud55c \ubc94\uc8fc\uc5d0 \uc0ac\uc6a9\ub41c\ub2e4.\n\n**Cohen's weighted Kappa**\n\n    Cohen's Kappa\uc640\ub294 \ub2e4\ub974\uac8c, ordinal(\uc21c\uc11c\uac00 \uc788\ub294, \uc608\ub97c \ub4e4\uc5b4 \uad00\uc808\uc5fc\uc758 5 \ub2e8\uacc4(1:\uc5c6\uc74c, 2:\uacbd\uc99d ... 5:\uc2ec\uac01) \ub4f1\uc744 \ud45c\ud604 \uc2dc) \ubcc0\uc218\ub97c \ub300\uc0c1\uc73c\ub85c \ud560 \uacbd\uc6b0\uc5d0\ub294 Cohen's weighted Kappa\ub97c \uc0ac\uc6a9\ud55c\ub2e4.<br>\n    \uc21c\uc11c(\ub610\ub294 \ub2e8\uacc4)\uac00 \uc788\ub294 \ubcc0\uc218\ub97c \ud310\ub2e8\ud558\ubbc0\ub85c \ubc94\uc8fc(\uce74\ud14c\uace0\ub9ac)\uac04 \uac70\ub9ac\ub294 \uc11c\ub85c \ub2e4\ub974\uace0, \ub450 \uc5f0\uad6c\uc790\uac04 \uacb0\uacfc\uac00 \ub2e4\ub97c \uacbd\uc6b0\uc5d0\ub3c4 \ub2e4\ub984\uc758 \ud06c\uae30\uc5d0 \uac00\uc911\uce58 \ucc28\uc774\uac00 \uc788\uc744 \uac83\uc774\ub2e4.<br>\n    \uc774\ub7f0 \uc2dd\uc73c\ub85c \uac01\uac01 \ub2e4\ub978 \ube44\uc911(weight)\ub97c \ub450\uc5b4 \ubd88\uc77c\uce58 \uc815\ub3c4\ub97c \ud3c9\uac00\ud558\ub294 \uac83\uc774\ub2e4.\n\n    \uac01 \ubc94\uc8fc\uac04 \ucc28\uc774\uc5d0 \ube44\uc911\uc744 \ubd80\uc5ec\ud558\ub294 \ubc29\ubc95\uc73c\ub85c\ub294 \uac12\uc758 \ucc28\uc774\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\ub294 linear \ubc29\ubc95\uacfc, \uc81c\uacf1\ud574\uc11c \uc0ac\uc6a9\ud558\ub294 quadratic \ubc29\ubc95\uc774 \uc788\ub2e4.\n    (1\uacfc 3\uc758 \ucc28\uc774 : linear = 2, quadratic = 4)","35277250":"## Submission\n\ntest \ub370\uc774\ud130\ub85c input\uc744 \uc0dd\uc131\ud55c\ub2e4.<br>\ntrain\uacfc \ub3d9\uc77c\ud55c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\ub418, make_session_data()\ud638\ucd9c\uc2dc test_set=True \ub85c \ud55c\ub2e4.","5ef38e2e":"train\ub370\uc774\ud130\uc5d0\uc11c accuracy_group \ucd94\ucd9c\n\nmake_session_data()\ub294 \uac01\uac01\uc758 installation_id\uc5d0 \ud574\ub2f9\ud558\ub294 event\ub97c \ubd84\uc11d\ud574\uc11c accuracy_group\uc744 \uad6c\ud558\ub294 \ub3d9\uc791\uc744 \ud55c\ub2e4.<br>\ninstallation_id\ub85c groupby()\ub97c \ud589\ud55c sub dataframe\uc744 \uc778\uc790\ub85c \ub118\uae34\ub2e4.","5c744775":"## Model"}}