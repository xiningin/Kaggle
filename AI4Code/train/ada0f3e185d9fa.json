{"cell_type":{"0977c8df":"code","da74ba6c":"code","c452dca2":"code","6aab75f9":"code","e46c416e":"code","c1a07731":"code","41df587e":"code","d0132b92":"code","b0828b47":"code","1242e182":"code","ebb5f9d6":"code","3d1af7fc":"code","8bb1dd9b":"code","fb651f19":"code","fba27bb9":"code","ab8c6c04":"code","40643e98":"code","97bc865e":"code","4b1de14b":"code","efa82f18":"markdown","108878ea":"markdown","5f3345d5":"markdown","c9754c34":"markdown","d536f8af":"markdown","d7ecd3ef":"markdown","6372cb66":"markdown","3d3f159c":"markdown"},"source":{"0977c8df":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","da74ba6c":"data = pd.read_csv('..\/input\/uci-semcom\/uci-secom.csv')","c452dca2":"data","6aab75f9":"data.info()","e46c416e":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop Time\n    df = df.drop('Time', axis=1)\n    \n    # Drop columns with more than 25% missing values\n    missing_value_columns = df.columns[df.isna().mean() >= 0.25]\n    df = df.drop(missing_value_columns, axis=1)\n    \n    # Fill remaining missing values\n    for column in df.columns:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # Remove columns with only one value\n    single_value_columns = [\n        '5', '13', '42', '49', '52', '69', '97', '141', '149', '178', '179', '186', '189', '190',\n        '191', '192', '193', '194', '226', '229', '230', '231', '232', '233', '234', '235', '236',\n        '237', '240', '241', '242', '243', '256', '257', '258', '259', '260', '261', '262', '263',\n        '264', '265', '266', '276', '284', '313', '314', '315', '322', '325', '326', '327', '328',\n        '329', '330', '364', '369', '370', '371', '372', '373', '374', '375', '378', '379', '380',\n        '381', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '414',\n        '422', '449', '450', '451', '458', '461', '462', '463', '464', '465', '466', '481', '498',\n        '501', '502', '503', '504', '505', '506', '507', '508', '509', '512', '513', '514', '515',\n        '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538'\n    ]\n    df = df.drop(single_value_columns, axis=1)\n    \n    # Give text labels to the training examples\n    df['Pass\/Fail'] = df['Pass\/Fail'].replace({-1: \"PASS\", 1: \"FAIL\"})\n    \n    # Split df into X and y\n    y = df['Pass\/Fail']\n    X = df.drop('Pass\/Fail', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n\n    return X_train, X_test, y_train, y_test","c1a07731":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","41df587e":"X_train","d0132b92":"y_train","b0828b47":"y_train.value_counts()","1242e182":"fig = px.pie(\n    y_train.value_counts(),\n    values='Pass\/Fail',\n    names=[\"PASS\", \"FAIL\"],\n    title=\"Class Distribution\",\n    width=500\n)\n\nfig.show()","ebb5f9d6":"def evaluate_model(model, X_test, y_test):\n    \n    acc = model.score(X_test, y_test)\n    print(\"Accuracy: {:.2f}%\".format(acc * 100))\n    \n    y_pred = model.predict(X_test)\n    \n    cm = confusion_matrix(y_test, y_pred, labels=['PASS', 'FAIL'])\n    clr = classification_report(y_test, y_pred, labels=['PASS', 'FAIL'])\n    \n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=[0.5, 1.5], labels=[\"PASS\", \"FAIL\"])\n    plt.yticks(ticks=[0.5, 1.5], labels=[\"PASS\", \"FAIL\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","3d1af7fc":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nevaluate_model(model, X_test, y_test)","8bb1dd9b":"oversampler = RandomOverSampler(random_state=1)\nX_train_os, y_train_os = oversampler.fit_resample(X_train, y_train)","fb651f19":"y_train.value_counts()","fba27bb9":"fig = px.pie(\n    y_train_os.value_counts(),\n    values='Pass\/Fail',\n    names=[\"PASS\", \"FAIL\"],\n    title=\"Class Distribution\",\n    width=500\n)\n\nfig.show()","ab8c6c04":"model = LogisticRegression()\nmodel.fit(X_train_os, y_train_os)\n\nevaluate_model(model, X_test, y_test)","40643e98":"oversampler = SMOTE(random_state=1)\nX_train_smote, y_train_smote = oversampler.fit_resample(X_train, y_train)","97bc865e":"y_train_smote.value_counts()","4b1de14b":"model = LogisticRegression()\nmodel.fit(X_train_smote, y_train_smote)\n\nevaluate_model(model, X_test, y_test)","efa82f18":"# Preprocessing","108878ea":"# Oversampling With SMOTE","5f3345d5":"# Task for Today  \n\n***\n\n## Semiconductor Test Result Prediction  \n  \nGiven *data about semiconductors*, let's try to predict whether a given semiconductor will **pass or fail** a QA test.  \n  \nWe will use a logistic regression model to make our predictions.","c9754c34":"# Training a Model (Imbalanced Classes)","d536f8af":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/XzmLJasJhS4","d7ecd3ef":"# Getting Started","6372cb66":"# Random Oversampling","3d3f159c":"# Examining Class Imbalance"}}