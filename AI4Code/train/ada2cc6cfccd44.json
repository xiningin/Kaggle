{"cell_type":{"d8ebc305":"code","50f48352":"code","ba4891ac":"code","9b0c0839":"code","dcdfbcfb":"code","4df5d84d":"code","ea113f9d":"code","38fecda7":"code","b56d6567":"code","19f09fd0":"code","d6bd0ff6":"code","e4d018f0":"code","86ade95a":"code","07595d0c":"code","c14be6b6":"code","ca239fb0":"code","ff6670f2":"code","911c9891":"code","9bb4f014":"code","5e8a8112":"code","f22e709f":"code","899d58e4":"code","95d5378b":"code","0d909dad":"code","1cba0c2a":"code","70ff33fb":"code","0c1e6492":"code","21c08e69":"code","910fa324":"code","d48186ca":"code","030aaab9":"code","0ef0f158":"code","49be4f9e":"code","6d32eaf4":"code","9526f309":"code","c076563e":"code","e674f9b0":"code","4ae88778":"code","d966cf96":"code","f81477f6":"code","4c6ba445":"code","e3b62a4d":"code","06b1d1d1":"code","96fa53de":"code","08ed568d":"code","3e5f1c86":"code","0d3bfb99":"code","da5db43c":"code","33db6e44":"code","caf87d70":"code","2ba5a121":"code","078d1249":"code","ac609e3f":"code","0e3214b2":"code","632cf7cf":"code","eae770d0":"code","1950eb78":"code","af4ab499":"code","0766d1f8":"code","082135b4":"code","dfb4cae3":"code","0dd332fc":"code","11d78827":"markdown","bc9fe7f8":"markdown","dce36fce":"markdown","9859ec6f":"markdown","0b31706f":"markdown"},"source":{"d8ebc305":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","50f48352":"# reading train and test data \napplication_train = pd.read_csv('..\/input\/application_train.csv')\napplication_test = pd.read_csv('..\/input\/application_test.csv')","ba4891ac":"#displaying shape\nprint('train shape:', application_train.shape)\nprint('test shape:', application_test.shape)","9b0c0839":"application_train.describe()","dcdfbcfb":"bureau = pd.read_csv('..\/input\/bureau.csv')\nbureau_balance = pd.read_csv('..\/input\/bureau_balance.csv')","4df5d84d":"print('bureau shape:', bureau.shape)\nprint('bureau balance shape:', bureau_balance.shape)\nbureau.describe()","ea113f9d":"print('total entry in bureau:', bureau.shape[0])\nprint('unique values in Application train:', len(application_train['SK_ID_CURR'].unique()), 'unique value in bureau:', len(bureau['SK_ID_CURR'].unique()))\nprint('avg number of loan taken by person', bureau.shape[0] \/ len(bureau['SK_ID_CURR'].unique()) )","38fecda7":"applicationColumn = application_train.columns.values\nbureauColumn = bureau.columns.values\nprint(set(applicationColumn) & set(bureauColumn))","b56d6567":"bureau_numeric = bureau.select_dtypes(include=[\"number\"])\nbureau_numeric = bureau_numeric.drop('SK_ID_BUREAU', axis = 1)\nbureau_numeric.head()","19f09fd0":"bureau_categorical = pd.get_dummies(bureau.select_dtypes(exclude = [\"number\"]))\nbureau_categorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\nbureau_categorical.head()","d6bd0ff6":"def splitData(dataframe):\n    df_numeric_data =dataframe.select_dtypes(include=[\"number\"])\n    df_categorical_data = dataframe.select_dtypes(exclude = [\"number\"])\n    return df_numeric_data, df_categorical_data","e4d018f0":"def handleNumericData(df, withColumn):\n    df.fillna(0,inplace = True)\n    ag = df.groupby(withColumn).agg(['count', 'mean'])\n    ag.columns = ag.columns.map('_'.join).str.strip('_')\n    ag = ag.reset_index()\n    return ag\n\n\ndef handleCategoricalData(df, withColumn):\n    ag = df.groupby(withColumn).agg(['sum', 'mean'])\n    ag.columns = ag.columns.map('_'.join).str.strip('_')\n    ag = ag.reset_index()\n    return ag\n\nbureau_categorical = handleCategoricalData(bureau_categorical, 'SK_ID_CURR')\nbureau_numeric = handleNumericData(bureau_numeric, 'SK_ID_CURR')","86ade95a":"bureau_updated = bureau_numeric.merge(bureau_categorical, on = 'SK_ID_CURR')","07595d0c":"bureau_updated.head()","c14be6b6":"# \n\nbureau_balance_numeric = bureau_balance.select_dtypes(include=[\"number\"])\nbureau_balance_numeric = handleNumericData(bureau_balance_numeric, 'SK_ID_BUREAU')\n\nbureau_balance_categorical = pd.get_dummies(bureau_balance.select_dtypes(exclude=[\"number\"]))\nbureau_balance_categorical['SK_ID_BUREAU'] = bureau_balance['SK_ID_BUREAU']\nbureau_balance_categorical = handleCategoricalData(bureau_balance_categorical, 'SK_ID_BUREAU')\n","ca239fb0":"bureau_balance = bureau_balance_numeric.merge(bureau_balance_categorical, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\nbureau_balance = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_balance, on = 'SK_ID_BUREAU', how = 'left')\nbureau_balance_by_client = handleNumericData(bureau_balance.drop(columns = ['SK_ID_BUREAU']),'SK_ID_CURR')","ff6670f2":"bureau_balance_by_client.head()","911c9891":"bureau_combined = bureau_updated.merge(bureau_balance_by_client, on = 'SK_ID_CURR')\nprint('bureau_combined shape:', bureau_combined.shape)\nbureau_combined.head()","9bb4f014":"application_train_updated = application_train.merge(bureau_combined, on = 'SK_ID_CURR')\napplication_test_updated = application_test.merge(bureau_combined, on = 'SK_ID_CURR')\n\nprint('application_train_updated shape:', application_train_updated.shape)\nprint('application_test_updated shape:', application_test_updated.shape)\n\napplication_train_updated.head()\n","5e8a8112":"application_train_updated.head(20)","f22e709f":"#starting with reading bureau and bureau balance\n\nbureau = pd.read_csv('..\/input\/bureau.csv')\nbureau_balance = pd.read_csv('..\/input\/bureau_balance.csv')\n\nbureau_combined = bureau.merge(bureau_balance,on = 'SK_ID_BUREAU', how = 'outer')","899d58e4":"import gc\ndel [[bureau,bureau_balance]]\ngc.collect()","95d5378b":"bureau_combined.head()","0d909dad":"corr_matrix = bureau_combined.corr().abs()\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.6)]\n#print(to_drop)\nbureau_combined.drop(to_drop, axis=1, inplace=True)","1cba0c2a":"import gc\ndel [[upper,corr_matrix]]\ngc.collect()","70ff33fb":"bureau_combined.head()","0c1e6492":"import scipy.stats\ndef splitData(dataframe, idColumn):\n    df_numeric_data =dataframe.select_dtypes(include=[\"number\"])\n    df_categorical_data = pd.get_dummies(dataframe.select_dtypes(exclude = [\"number\"]))\n    df_categorical_data[idColumn] = dataframe[idColumn]\n    return df_numeric_data, df_categorical_data\n\ndef handleNumericData(df, withColumn):\n    df.fillna(0,inplace = True)\n    ag = df.groupby(withColumn).agg(['mean', 'min', 'max'])\n    ag.columns = ag.columns.map('_'.join).str.strip('_')\n    ag = ag.reset_index()\n    return ag\n\n\ndef handleCategoricalData(df, withColumn):\n    \n    '''maxCategorical = categorical.groupby(withColumn).agg(lambda x: scipy.stats.mode(x)[0][0])\n    maxCategorical = maxCategorical.reset_index()\n    #maxCategorical.drop(withColumn,inplace = True)'''\n    \n    ag = df.groupby(withColumn).agg(['sum'])\n    ag.columns = ag.columns.map('_'.join).str.strip('_')\n    ag = ag.reset_index()\n    #ag = pd.concat([ag, maxCategorical], axis = 1)\n    #ag['Max'] = ag[list(ag.columns[1:])].max(axis=1)\n\n    return ag\n\ndef treatDataFrame(dataframe, idColumn):\n    numerical, categorical = splitData(dataframe, idColumn)\n    #del [[df_numeric_data,df_categorical_data]]\n    gc.collect()    \n    \n    numerical = handleNumericData(numerical, idColumn)\n    #del [[ag]]\n    gc.collect()    \n    \n    categorical = handleCategoricalData(categorical, idColumn)\n    #del [[ag]]\n    gc.collect()\n    \n    categorical.drop(idColumn,axis = 1, inplace= True)\n    combined_data = pd.concat([numerical, categorical], axis = 1)\n    del [[numerical,categorical]]\n    gc.collect()\n    return combined_data\n    ","21c08e69":"# handleCategoricalData(categorical.iloc[:10,:],'SK_ID_BUREAU')\n# #categorical.head()\n#bureau_balance.head()\nbureau_combined.drop('SK_ID_BUREAU', axis = 1, inplace = True)\nbureau_combined = treatDataFrame(bureau_combined, 'SK_ID_CURR')\nbureau_combined.head()","910fa324":"bureau_combined.to_csv('..\/bureau_combined.csv')","d48186ca":"sk_id = bureau['SK_ID_CURR']\nbureau.drop('SK_ID_CURR',axis = 1, inplace = True)\n\nbureau = treatDataFrame(bureau, 'SK_ID_BUREAU')\nbureau['SK_ID_CURR'] = sk_id\nbureau.head()","030aaab9":"import scipy.stats\n\nmaxCategorical.head()","0ef0f158":"categorical_dummies = pd.get_dummies(categorical)\ncategorical_dummies['SK_ID_BUREAU'] = bureau_balance['SK_ID_BUREAU']\ncategorical_dummies.head()","49be4f9e":"#ag = categorical_dummies.groupby('SK_ID_BUREAU').agg(['sum'])\n#agMode = categorical.groupby('SK_ID_BUREAU').agg(lambda x: x.value_counts().index[0])\nhandleCategoricalData(categorical_dummies, 'SK_ID_BUREAU').head()\n\n\n# ag.columns = ag.columns.map('_'.join).str.strip('_')\n# ag = ag.reset_index()\n# ag['Max'] = ag[list(ag.columns[1:])].max(axis=1)\n# ag.head()","6d32eaf4":"ag.head()","9526f309":"handleCategoricalData(categorical, 'SK_ID_BUREAU')","c076563e":"train = pd.read_csv('..\/input\/train-all\/train_all.csv')\nbureau_combined = pd.read_csv('..\/input\/bureau\/bureau_combined.csv')\n","e674f9b0":"print(train.shape)\nprint(bureau_combined.shape)","4ae88778":"train.head()","d966cf96":"target = train['TARGET']\ntrain.drop(['SK_ID_CURR', 'TARGET', 'Unnamed: 0'],axis = 1, inplace = True)","f81477f6":"number = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum() \/ train.isnull().count() * 100).sort_values(ascending = False)\n\nmissing_application_test = pd.concat([number , percent] , axis = 1 , keys = ['Total' , 'Percent'])\nprint(missing_application_test.shape)\nprint(missing_application_test.head(20))","4c6ba445":"train_full = train.loc[:, train.isnull().mean() < .5]","e3b62a4d":"print(train.shape)\nprint(train_full.shape)","06b1d1d1":"train_full.fillna(train_full.mean(),inplace = True)","96fa53de":"train_full.shape","08ed568d":"y_predict = rdf.predict(X_train)\nfrom sklearn.metrics import precision_recall_fscore_support\nprint('precision_recall_fscore_support score:', precision_recall_fscore_support(y_predict, y_train))","3e5f1c86":"import gc\ntest = pd.read_csv('..\/input\/home-credit-default-risk\/application_test.csv')\nnumerical, categorical = splitData(test, 'SK_ID_CURR')\nprint(test.shape)\ntest  = pd.merge(numerical,categorical, on = 'SK_ID_CURR', how = 'inner')\ntest.head()","0d3bfb99":"test  = pd.merge(test,bureau_combined, on = 'SK_ID_CURR', how = 'left')\nprint(test.shape)","da5db43c":"common_columns = list(set(test.columns) & set(train_full.columns)) \n","33db6e44":"train_common = train_full[common_columns]","caf87d70":"print(train_common.shape)\nprint(target.shape)","2ba5a121":"train_common.head()","078d1249":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(train_common, target.ravel())","ac609e3f":"print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","0e3214b2":"from sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(n_estimators = 100 , max_depth = 5, min_samples_leaf = 4, max_features = 0.5)\nrdf.fit(X_train_res , y_train_res)\n","632cf7cf":"print(len(test['SK_ID_CURR']))\ntest.fillna(test.mean(),inplace = True)\n","eae770d0":"test[common_columns].head()","1950eb78":"#X_train_res = sm.fit_sample(test[common_columns])\ny_pred_sample_score = rdf.predict(test[common_columns])\n","af4ab499":"len(y_pred_sample_score)","0766d1f8":"df = pd.DataFrame()\ndf['SK_ID_CURR'] = test['SK_ID_CURR']\ndf['TARGET'] = y_pred_sample_score\ndf.to_csv('sample_submission.csv', index=False)","082135b4":"df.head()","dfb4cae3":"sub = pd.read_csv('..\/input\/home-credit-default-risk\/sample_submission.csv')\nsub['TARGET'] = y_pred_sample_score\nsub.to_csv('submission2.csv',index = False)","0dd332fc":"sub.head()","11d78827":"Working on data","bc9fe7f8":"# Combining Application and Combined Data","dce36fce":"# Combining Bureau and Bureau Balance data","9859ec6f":"## Handling Bureau Data","0b31706f":"# Extracting from bureau balance"}}