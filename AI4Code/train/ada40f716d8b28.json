{"cell_type":{"f2d54450":"code","74ce0b05":"code","9c470ffc":"code","fbae6591":"code","ae354aad":"code","b42a27ba":"code","c57634d1":"code","9cc5cd13":"code","c3d3991c":"code","3594006d":"code","80918331":"code","113ff089":"code","bbfce371":"code","bec85573":"code","b14c18cf":"code","f8a5d7f4":"code","c9a77526":"code","0a7b1b2b":"code","56193202":"code","c70dbbc9":"code","8d6bdece":"code","f63dfcfe":"code","717957ec":"code","55853252":"code","68754b6e":"code","110a2568":"code","bc50063b":"code","3851b120":"code","28648f94":"code","a58fa446":"code","585e78e5":"code","1c628821":"code","6e5c0740":"code","bdcf4986":"code","89cc5d49":"code","2d9ddcb8":"code","12ffa38f":"code","0a7e2f76":"code","e3ce4f69":"markdown","0d6ed948":"markdown","47aeb328":"markdown","4be4de58":"markdown","fb473f9a":"markdown","ad2abd13":"markdown","75ec3849":"markdown"},"source":{"f2d54450":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74ce0b05":"#import os\n#print(os.listdir(\"..\/input\"))","9c470ffc":"import os\nfrom os import listdir\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n\nimport pydicom\nimport glob\nimport imageio\nfrom IPython.display import Image\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","fbae6591":"# List of files available in the given dataset\nlist(os.listdir(\"..\/input\/osic-pulmonary-fibrosis-progression\"))","ae354aad":"train_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\n\ntrain_df.head()","b42a27ba":"print('Shape of Training data: ', train_df.shape)\nprint('Shape of Test data: ', test_df.shape)","c57634d1":"train_df.info()","9cc5cd13":"test_df.info()","c3d3991c":"print(f\"The total patient ids are {train_df['Patient'].count()}\")\nprint(f\"Number of unique ids are {train_df['Patient'].value_counts().shape[0]} \")","3594006d":"new_df = train_df.groupby([train_df.Patient,train_df.Age,train_df.Sex, train_df.SmokingStatus])['Patient'].count()\nnew_df.index = new_df.index.set_names(['id','Age','Sex','SmokingStatus'])\nnew_df = new_df.reset_index()\nnew_df.rename(columns = {'Patient': 'freq'},inplace = True)\nnew_df.head()\n#print(new_df)\n","80918331":"fig = px.bar(new_df, x='id',y ='freq',color='freq')\nfig.update_layout(xaxis={'categoryorder':'total ascending'},title='No. of observations for each patient')\nfig.update_xaxes(showticklabels=False)\nfig.show()","113ff089":"fig = px.histogram(new_df, x='Age',nbins = 42)\nfig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                 marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title = 'Distribution of Age for unique patients')\nfig.show()","bbfce371":"patient1 = train_df[train_df.Patient == 'ID00007637202177411956430']\npatient2 = train_df[train_df.Patient == 'ID00012637202177665765362']\npatient3 = train_df[train_df.Patient == 'ID00082637202201836229724']\n\n\npatient1['text'] ='ID: ' + (patient1['Patient']).astype(str) + '<br>FVC ' + patient1['FVC'].astype(str) + '<br>Percent ' + patient1['Percent'].astype(str) + '<br>Week ' + patient1['Weeks'].astype(str)\npatient2['text'] ='ID: ' + (patient2['Patient']).astype(str) + '<br>FVC ' + patient2['FVC'].astype(str)+ '<br>Percent ' + patient2['Percent'].astype(str)  + '<br>Week ' + patient2['Weeks'].astype(str)\npatient3['text'] ='ID: ' + (patient3['Patient']).astype(str) + '<br>FVC ' + patient3['FVC'].astype(str) + '<br>Percent ' + patient3['Percent'].astype(str) + '<br>Week ' + patient3['Weeks'].astype(str)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=patient1['Weeks'], y=patient1['FVC'],hovertext = patient1['text'],\n                    mode='lines+markers',marker=dict(size = 12,line_width = 2),\n                    name='Ex-smoker'))\nfig.add_trace(go.Scatter(x=patient2['Weeks'], y=patient2['FVC'],hovertext = patient2['text'],\n                    mode='lines+markers',marker=dict(size = 12,line_width = 2),\n                    name='Never smoked'))\nfig.add_trace(go.Scatter(x=patient3['Weeks'], y=patient3['FVC'],hovertext = patient3['text'],\n                    mode='lines+markers',marker=dict(size = 12,line_width = 2), name='Currently smokes'))\n\nfig.update(layout_title_text='FVC vs Weeks for 3 different patients')\nfig.update_layout( width=700,height=500)\nfig.show()","bec85573":"import pydicom\nfrom pydicom.data import get_testdata_files\n\nprint(__doc__)\n\nPathDicom = '\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/'\nlstFilesDCM = []  # create an empty list\nfor dirName, subdirList, fileList in os.walk(PathDicom):\n    for filename in fileList:\n        if \".dcm\" in filename.lower():  # check whether the file's DICOM\n            lstFilesDCM.append(os.path.join(dirName,filename))","b14c18cf":"print(lstFilesDCM[0])","f8a5d7f4":"data_path = '..\/input\/osic-pulmonary-fibrosis-progression\/train\/'\n\ntrain_image_files = sorted(glob.glob(os.path.join(data_path, '*','*.dcm')))\npatients = os.listdir(data_path)\npatients.sort()\nprint('Some sample Patient ID''s :', len(train_image_files))\nprint(\"\\n\".join(train_image_files[:5]))","c9a77526":"def load_scan(path):\n    \"\"\"\n    Loads scans from a folder and into a list.\n    \n    Parameters: path (Folder path)\n    \n    Returns: slices (List of slices)\n    \"\"\"\n    \n    slices = [pydicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    \n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices","0a7b1b2b":"def get_pixels_hu(scans):\n    \"\"\"\n    Converts raw images to Hounsfield Units (HU).\n    \n    Parameters: scans (Raw images)\n    \n    Returns: image (NumPy array)\n    \"\"\"\n    \n    image = np.stack([s.pixel_array for s in scans])\n    image = image.astype(np.int16)\n\n    # Since the scanning equipment is cylindrical in nature and image output is square,\n    # we set the out-of-scan pixels to 0\n    image[image == -2000] = 0\n    \n    \n    # HU = m*P + b\n    intercept = scans[0].RescaleIntercept\n    slope = scans[0].RescaleSlope\n    \n    if slope != 1:\n        image = slope * image.astype(np.float64)\n        image = image.astype(np.int16)\n        \n    image += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)","56193202":"#print(patients[1:5])\nprint(patients[2])\n#print(patients[3])\nprint(patients[5])\n","c70dbbc9":"test_patient_scans = load_scan(data_path + patients[2])\ntest_patient_images = get_pixels_hu(test_patient_scans)\n\n#We'll be taking a random slice to perform segmentation:\n\nfor imgs in range(len(test_patient_images[:5])):\n    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(15,15))\n    ax1.imshow(test_patient_images[imgs], cmap=plt.cm.bone)\n    ax1.set_title(\"Original Slice\")\n    \n    ax2.imshow(test_patient_images[imgs], cmap=plt.cm.bone)\n    ax2.set_title(\"Original Slice\")\n    \n    ax3.imshow(test_patient_images[imgs], cmap=plt.cm.bone)\n    ax3.set_title(\"Original Slice\")\n    plt.show()\n    \nprint(len(test_patient_images))    ","8d6bdece":"from skimage import measure, morphology, segmentation\nimport scipy.ndimage as ndimage\nimport os\nimport copy\nfrom datetime import timedelta, datetime\nimport imageio\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport multiprocessing\nimport numpy as np\nimport os\nfrom pathlib import Path\nimport pydicom\nimport pytest\nimport scipy.ndimage as ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom skimage import measure, morphology, segmentation\nfrom skimage.transform import resize\nfrom time import time, sleep\nfrom tqdm import trange, tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import *\nfrom tensorflow.data import Dataset\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import transforms\nimport warnings\nimport seaborn as sns\nimport glob as glob\nimport imageio\nfrom IPython.display import Image\n\n#for masking\nfrom skimage.measure import label,regionprops\nfrom sklearn.cluster import KMeans\nfrom skimage.segmentation import clear_border\n","f63dfcfe":"def generate_markers(image):\n    \"\"\"\n    Generates markers for a given image.\n    \n    Parameters: image\n    \n    Returns: Internal Marker, External Marker, Watershed Marker\n    \"\"\"\n    \n    #Creation of the internal Marker\n    marker_internal = image < -400\n    marker_internal = segmentation.clear_border(marker_internal)\n    marker_internal_labels = measure.label(marker_internal)\n    \n    areas = [r.area for r in measure.regionprops(marker_internal_labels)]\n    areas.sort()\n    \n    if len(areas) > 2:\n        for region in measure.regionprops(marker_internal_labels):\n            if region.area < areas[-2]:\n                for coordinates in region.coords:                \n                       marker_internal_labels[coordinates[0], coordinates[1]] = 0\n    \n    marker_internal = marker_internal_labels > 0\n    \n    # Creation of the External Marker\n    external_a = ndimage.binary_dilation(marker_internal, iterations=10)\n    external_b = ndimage.binary_dilation(marker_internal, iterations=55)\n    marker_external = external_b ^ external_a\n    \n    # Creation of the Watershed Marker\n    marker_watershed = np.zeros((512, 512), dtype=np.int)\n    marker_watershed += marker_internal * 255\n    marker_watershed += marker_external * 128\n    \n    return marker_internal, marker_external, marker_watershed","717957ec":"test_patient_internal, test_patient_external, test_patient_watershed = generate_markers(test_patient_images[15])\n\nf, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(15,15))\n\nax1.imshow(test_patient_internal, cmap='gray')\nax1.set_title(\"Internal Marker\")\nax1.axis('off')\n\nax2.imshow(test_patient_external, cmap='gray')\nax2.set_title(\"External Marker\")\nax2.axis('off')\n\nax3.imshow(test_patient_watershed, cmap='gray')\nax3.set_title(\"Watershed Marker\")\nax3.axis('off')\n\nplt.show()","55853252":"sample_image = pydicom.dcmread(train_image_files[2])\nimg = sample_image.pixel_array\n\nplt.imshow(img, cmap='gray')\nplt.title('Original Image')","68754b6e":"img = (img + sample_image.RescaleIntercept) \/ sample_image.RescaleSlope\nimg = img < -400 #HU unit range for lungs CT SCAN\n\nplt.imshow(img, cmap='gray')\nplt.title('Binary Mask Image')","110a2568":"img = clear_border(img)\nplt.imshow(img, cmap='gray')\nplt.title('Cleaned Border Image')","bc50063b":"# https:\/\/www.raddq.com\/dicom-processing-segmentation-visualization-in-python\/\n\ndef make_lungmask(img, display=False):\n    row_size= img.shape[0]\n    col_size = img.shape[1]\n    \n    mean = np.mean(img)\n    std = np.std(img)\n    img = img-mean\n    img = img\/std\n    \n    # Find the average pixel value near the lungs\n        # to renormalize washed out images\n    middle = img[int(col_size\/5):int(col_size\/5*4),int(row_size\/5):int(row_size\/5*4)] \n    mean = np.mean(middle)  \n    max = np.max(img)\n    min = np.min(img)\n    \n    # To improve threshold finding, I'm moving the \n    # underflow and overflow on the pixel spectrum\n    img[img==max]=mean\n    img[img==min]=mean\n    \n    # Using Kmeans to separate foreground (soft tissue \/ bone) and background (lung\/air)\n    \n    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n    centers = sorted(kmeans.cluster_centers_.flatten())\n    threshold = np.mean(centers)\n    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n\n    # First erode away the finer elements, then dilate to include some of the pixels surrounding the lung.  \n    # We don't want to accidentally clip the lung.\n\n    eroded = morphology.erosion(thresh_img,np.ones([3,3]))\n    dilation = morphology.dilation(eroded,np.ones([8,8]))\n\n    labels = measure.label(dilation) # Different labels are displayed in different colors\n    label_vals = np.unique(labels)\n    regions = measure.regionprops(labels)\n    good_labels = []\n    for prop in regions:\n        B = prop.bbox\n        if B[2]-B[0]<row_size\/10*9 and B[3]-B[1]<col_size\/10*9 and B[0]>row_size\/5 and B[2]<col_size\/5*4:\n            good_labels.append(prop.label)\n    mask = np.ndarray([row_size,col_size],dtype=np.int8)\n    mask[:] = 0\n\n\n    #  After just the lungs are left, we do another large dilation\n    #  in order to fill in and out the lung mask \n    \n    for N in good_labels:\n        mask = mask + np.where(labels==N,1,0)\n    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n\n    if (display):\n        fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n        ax[0, 0].set_title(\"Original\")\n        ax[0, 0].imshow(img, cmap='gray')\n        ax[0, 0].axis('off')\n        ax[0, 1].set_title(\"Threshold\")\n        ax[0, 1].imshow(thresh_img, cmap='gray')\n        ax[0, 1].axis('off')\n        ax[1, 0].set_title(\"After Erosion and Dilation\")\n        ax[1, 0].imshow(dilation, cmap='gray')\n        ax[1, 0].axis('off')\n        ax[1, 1].set_title(\"Color Labels\")\n        ax[1, 1].imshow(labels)\n        ax[1, 1].axis('off')\n        ax[2, 0].set_title(\"Final Mask\")\n        ax[2, 0].imshow(mask, cmap='gray')\n        ax[2, 0].axis('off')\n        ax[2, 1].set_title(\"Apply Mask on Original\")\n        ax[2, 1].imshow(mask*img, cmap='gray')\n        ax[2, 1].axis('off')\n        \n        plt.show()\n    return mask*img","3851b120":"path = \"..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/19.dcm\"\ndataset = pydicom.dcmread(path)\nimg = dataset.pixel_array\n\n# Masked image\nmask_img = make_lungmask(img, display=True)","28648f94":"import re\npatient_dir = \"..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00010637202177584971671\"\ntest_patient_scans = load_scan(data_path + patients[2])\ndatasets = []\n\n# First Order the files in the dataset\nfiles = []\nfor dcm in list(os.listdir(patient_dir)):\n    files.append(dcm) \nfiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n\n# Read in the Dataset\nfor dcm in files:\n    path = patient_dir + \"\/\" + dcm\n    datasets.append(pydicom.dcmread(path))\n    \nimgs = []\nfor data in datasets:\n    img = data.pixel_array\n    imgs.append(img)\n    \n    \n# Show masks\nfig=plt.figure(figsize=(16, 6))\ncolumns = 10\nrows = 3\n\nfor i in range(1, columns*rows +1):\n    img = make_lungmask(datasets[i-1].pixel_array)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img, cmap=\"gray\")\n    plt.title(i, fontsize = 9)\n    plt.axis('off');","a58fa446":"print(files)","585e78e5":"def get_observation_data(path):\n    '''Get information from the .dcm files.\n    path: complete path to the .dcm file'''\n\n    image_data = pydicom.read_file(path)\n\n    # Dictionary to store the information from the image\n    observation_data = {\n        \"FileNumber\" : path.split('\/')[5],\n        \"Rows\" : image_data.Rows,\n        \"Columns\" : image_data.Columns,\n\n        \"PatientID\" : image_data.PatientID,\n        \"BodyPartExamined\" : image_data.BodyPartExamined,\n        \"SliceThickness\" : int(image_data.SliceThickness),\n        \"KVP\" : int(image_data.KVP),\n        \"DistanceSourceToDetector\" : int(image_data.DistanceSourceToDetector),\n        \"DistanceSourceToPatient\" : int(image_data.DistanceSourceToPatient),\n        \"GantryDetectorTilt\" : int(image_data.GantryDetectorTilt),\n        \"TableHeight\" : int(image_data.TableHeight),\n        \"RotationDirection\" : image_data.RotationDirection,\n        \"XRayTubeCurrent\" : int(image_data.XRayTubeCurrent),\n        \"GeneratorPower\" : int(image_data.GeneratorPower),\n        \"ConvolutionKernel\" : image_data.ConvolutionKernel,\n        \"PatientPosition\" : image_data.PatientPosition,\n\n        \"ImagePositionPatient\" : str(image_data.ImagePositionPatient),\n        \"ImageOrientationPatient\" : str(image_data.ImageOrientationPatient),\n        \"PhotometricInterpretation\" : image_data.PhotometricInterpretation,\n        \"ImageType\" : str(image_data.ImageType),\n        \"PixelSpacing\" : str(image_data.PixelSpacing),\n        \"WindowCenter\" : int(image_data.WindowCenter),\n        \"WindowWidth\" : int(image_data.WindowWidth),\n        \"Modality\" : image_data.Modality,\n        \"StudyInstanceUID\" : image_data.StudyInstanceUID,\n        \"PixelPaddingValue\" : image_data.PixelPaddingValue,\n        \"SamplesPerPixel\" : image_data.SamplesPerPixel,\n        \"SliceLocation\" : int(image_data.SliceLocation),\n        \"BitsAllocated\" : image_data.BitsAllocated,\n        \"BitsStored\" : image_data.BitsStored,\n        \"HighBit\" : image_data.HighBit,\n        \"PixelRepresentation\" : image_data.PixelRepresentation,\n        \"RescaleIntercept\" : int(image_data.RescaleIntercept),\n        \"RescaleSlope\" : int(image_data.RescaleSlope),\n        \"RescaleType\" : image_data.RescaleType\n    }\n    \n    return observation_data","1c628821":"class bcolors:\n    OKBLUE = '\\033[96m'\n    OKGREEN = '\\033[92m'","6e5c0740":"path = \"..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00010637202177584971671\/30.dcm\"\ndataset = pydicom.dcmread(path)\n\nprint(bcolors.OKBLUE + \"Patient id.......:\", dataset.PatientID, \"\\n\" +\n      \"Modality.........:\", dataset.Modality, \"\\n\" +\n      \"Rows.............:\", dataset.Rows, \"\\n\" +\n      \"Columns..........:\", dataset.Columns)\n\nplt.figure(figsize = (7, 7))\nplt.imshow(dataset.pixel_array, cmap=\"plasma\")\nplt.axis('off');","bdcf4986":"meta_data_df = []\nfor filename in tqdm(train_image_files):\n    try:\n        meta_data_df.append(get_observation_data(filename))\n    except Exception as e:\n        continue","89cc5d49":"meta_data_df = pd.DataFrame.from_dict(meta_data_df)\nmeta_data_df\n#print(\".....Done\")","2d9ddcb8":"meta_data_df.to_csv('metadata.csv',index=False)","12ffa38f":"#meta_data_df.to_csv('..\/input\/osic-dicom-image-features\/metadata.csv',index=False)","0a7e2f76":"dicom_df = pd.read_csv('\/kaggle\/working\/metadata.csv') \ndicom_df.shape","e3ce4f69":"# Visualizing the Data","0d6ed948":"shape of data","47aeb328":"# **Data Exploration**","4be4de58":"DICOM IMAGE PREPROCESSING","fb473f9a":"There are multiple records of the same patient as the number of unique ids are less than total patient ids record.","ad2abd13":"No missing value in either train\/test csv","75ec3849":"Marker Watershed Transformation"}}