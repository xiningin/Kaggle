{"cell_type":{"bb598c09":"code","fb268797":"code","d3b814e7":"code","ae57468c":"code","d94947a5":"code","3a9bdc8f":"code","4e35134d":"code","1cd11aa0":"code","bc8c0f42":"code","223c4c41":"code","8c650908":"code","95decd9b":"code","902ac3d9":"code","54264eec":"code","541c6c23":"code","51c5d0f4":"code","d583d7cb":"code","71548058":"markdown","9afc4392":"markdown","ce5f7ad8":"markdown","a4c67693":"markdown","6f0acdc0":"markdown","7d6c289f":"markdown","f6354f2a":"markdown","9de3d7ea":"markdown","cf800cf7":"markdown","6c8453e0":"markdown"},"source":{"bb598c09":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport category_encoders as ce\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler, RobustScaler, Normalizer\nfrom sklearn.preprocessing import QuantileTransformer, PowerTransformer, OneHotEncoder, OrdinalEncoder, LabelEncoder\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, LinearRegression, PassiveAggressiveClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","fb268797":"df = pd.read_csv('..\/input\/ml-hands-on-python-kaggle-01\/train.csv') \ndf_test = pd.read_csv('..\/input\/ml-hands-on-python-kaggle-01\/test.csv')\ndf_submit = pd.read_csv('..\/input\/ml-hands-on-python-kaggle-01\/sample_submission.csv')","d3b814e7":"# Drop ['ethnicity'] because it has low correlation\ndf = df.drop(['ethnicity'], axis=1)\nprint(df.info())\ndf","ae57468c":"# Drop ['ethnicity'] because it has low correlation\ndf_test = df_test.drop(['ethnicity'], axis=1)\nprint(df_test.info())\ndf_test","d94947a5":"def get_metrics(y_test, y_pred):\n    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred), 4))\n    print('F1_SCORE: ', round(f1_score(y_test, y_pred, average='macro'), 4))\n    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred),'\\n')\n    print(classification_report(y_test, y_pred, digits=4), '\\n')","3a9bdc8f":"def feature_engineering(X_train, X_val, index_scaler=0):\n    # Encode categorical variables\n    cols = [ 'work_type', \n             'education', \n             'marital_state', \n             'job', \n             'status', \n             #'ethnicity', \n             'sex', \n             'nationality'\n            ]\n    encoder = ce.OneHotEncoder(cols=cols)\n    X_train = encoder.fit_transform(X_train)\n    X_val = encoder.transform(X_val)\n    \n    # Feature scaling \n    list_scaler = [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), \n                   RobustScaler(), Normalizer(), QuantileTransformer(), PowerTransformer()]\n    \n    scaler = list_scaler[index_scaler]\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)  \n    return X_train, X_val","4e35134d":"def kfold(model, X, y, index_scaler=0):\n    kf = KFold(n_splits=5, random_state=42)\n    score = []\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = feature_engineering(X.iloc[train_index,:], X.iloc[val_index,:], index_scaler)\n        y_train, y_val = y[train_index], y[val_index]\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_val)\n        score.append(f1_score(y_val, y_pred, average=\"macro\"))\n\n    print(f\"Model {model.__class__.__name__}\")\n    print(f\"F1-macro: {score}\")\n    print(f\"Average F1-macro: {np.mean(score)}\\n\")\n    #print(f\"----------------------------------\\n\")","1cd11aa0":"def finetune_lgb(X, y, type='random', cv=None, random_state=None, scoring='f1_macro'):\n    parameters = {'num_leaves'        :np.arange(30, 81, 5), \n                  'min_child_samples' :np.arange(10, 31, 5), \n                  'max_depth'         :np.arange(-1, 25, 5),\n                  'learning_rate'     :np.arange(0.05, 0.21, 0.05), \n                  #'reg_alpha'         :[0,0.01,0.03] \n                  }\n    clf = LGBMClassifier()\n    if type=='random': \n        lgb = RandomizedSearchCV(clf, parameters, cv=cv, random_state=random_state, scoring=scoring)\n    else:\n        lgb = GridSearchCV(clf, parameters, cv=cv, scoring=scoring, verbose=1, n_jobs=4)\n    lgb.fit(X, y)\n    return lgb.best_estimator_","bc8c0f42":"data = df.drop(['ID', 'target_income'], axis=1)\nlabel = df['target_income']\ndata_train, data_val, label_train, label_val = train_test_split(data, label, test_size=0.2, random_state=0)","223c4c41":"# MinMaxScaler, MaxAbsScaler, StandardScaler, RobustScaler, \n# Normalizer, QuantileTransformer, PowerTransformer\nX_train, X_val = feature_engineering(data_train, data_val, index_scaler=0)\ny_train, y_val = label_train, label_val\nprint(X_train.shape, X_val.shape)","8c650908":"# LGBMClassifier(), XGBClassifier(), CatBoostClassifier(verbose = 200) \nmodel = LGBMClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\nget_metrics(y_val, y_pred)\nkfold(model, X=data, y=label, index_scaler=0)","95decd9b":"%%time\nX = np.concatenate((X_train, X_val), axis=0)\ny = np.concatenate((y_train, y_val), axis=0)\nprint(X.shape, y.shape)\nmodel = finetune_lgb(X, y, type='grid', cv=5, random_state=0, scoring='f1_macro')\nmodel.get_params","902ac3d9":"# Parameters\nindex_scaler = 0","54264eec":"data_test = df_test.drop(['ID'], axis = 1)\nX_train, X_test = feature_engineering(data, data_test, index_scaler)\ny_train = label\nprint(X_train.shape, X_test.shape)","541c6c23":"%%time\n# LGBMClassifier(), XGBClassifier(), CatBoostClassifier(verbose = 200)\nmodel = LGBMClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","51c5d0f4":"df_submit['target_income'] = y_pred\ndf_submit","d583d7cb":"path = f'.\/{model.__class__.__name__}_scaler={index_scaler}.csv'\ndf_submit.to_csv(path, index=False)\nprint(f\"Export {path} sucessfully!\")","71548058":"## Load Dataset","9afc4392":"## Result","ce5f7ad8":"## Finetune","a4c67693":"## K-Fold","6f0acdc0":"## Setup","7d6c289f":"My model achieved 0.87587 in Private Score.\n<p align=\"center\">\n<img src=\"https:\/\/imgur.com\/h9pyeUw.png\"\">\n<\/p>","f6354f2a":"## Model","9de3d7ea":"## Feature Engineering","cf800cf7":"## Function","6c8453e0":"## Predict test"}}