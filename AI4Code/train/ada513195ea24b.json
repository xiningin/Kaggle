{"cell_type":{"186e685f":"code","94f1fca5":"code","67e79725":"code","c56c18cf":"code","51c6ab83":"code","a2abd1da":"code","fff19ec3":"code","0671203f":"code","e75f55d0":"code","9abfc858":"code","4baf8ff4":"code","f1e3cbed":"code","b6aba02b":"code","6e741401":"code","e61b075c":"code","29f63977":"code","a4aa676e":"code","5c56b69f":"code","9341c28f":"code","eea7129a":"code","569d5655":"code","3427b36a":"code","48180045":"code","d1545463":"code","97e5dd40":"code","5f4a7448":"code","a4eba8e3":"code","4c9946f8":"code","bea467af":"code","0624be1a":"code","b49d21e7":"code","36242dea":"code","134c156a":"code","c0c5704d":"code","fb0e1b07":"code","58df5590":"code","86af5471":"code","7583c176":"code","f7046d9d":"code","f146de7f":"code","8369a284":"code","c1fb09e8":"code","eb81f295":"code","29e1f9e0":"code","5e0f54bf":"code","8132d1d6":"code","0beaf11a":"code","5e8dbe35":"code","355199cc":"code","7ec9e185":"code","dda8608b":"code","61a45d44":"code","2eaa2779":"code","9d4a42ac":"code","2fa530ea":"code","5184ee74":"code","c8e59c7f":"code","56f93935":"code","ab9de80f":"code","1ff460d7":"code","f3ff187e":"code","97487115":"code","56089c15":"code","d6eebbd4":"code","1a9f5345":"code","acb10689":"code","4e632d56":"code","0a90aeec":"code","bfc8125f":"code","befe8e50":"code","3938cb07":"code","28e9b501":"code","495895c8":"code","873022f2":"markdown","e7f9cd6c":"markdown","15af2b50":"markdown","74393473":"markdown","72da5299":"markdown","76c507df":"markdown","13ff4065":"markdown","e7c26fba":"markdown","a856ea7b":"markdown","b0ec80fb":"markdown","d7203782":"markdown","584e6d9c":"markdown","503f83bf":"markdown","b2050ef1":"markdown","d0eb5914":"markdown","e4ca93fb":"markdown","2dd44572":"markdown","2c4846fb":"markdown","cd5abbab":"markdown","2795e191":"markdown","4b5f510c":"markdown","4da454fb":"markdown","0e547048":"markdown","f4924d8b":"markdown","b59b9a6a":"markdown","45177014":"markdown","99227d38":"markdown","115a3dd0":"markdown","d634ee90":"markdown","e33812a8":"markdown","cfd38ca6":"markdown","8e228063":"markdown","3ccd8816":"markdown","b2f290b9":"markdown","221a2eb4":"markdown","e7d1df63":"markdown","38147645":"markdown","f2e1a87f":"markdown","6f605770":"markdown","3f9a3c6a":"markdown","9436da8a":"markdown"},"source":{"186e685f":"# import useful libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","94f1fca5":"# import train and test dataset\ndf_train = pd.read_csv(\"..\/input\/housing-project\/housing project train.csv\")\ndf_test = pd.read_csv(\"..\/input\/housing-project\/housing project test.csv\")\npd.set_option('Display.max_columns', None)\ndf_train.head()","67e79725":"# check shape of the dataset\nprint(df_train.shape)\nprint(df_test.shape)","c56c18cf":"# check information of the dataset\ndf_train.info()","51c6ab83":"# check discriptive analysis of numerical columns.\ndf_train.describe()","a2abd1da":"# check the number of null values present in dataset.\npd.set_option('Display.max_rows', None)\ndf_train.isnull().sum()","fff19ec3":"# Here we drop id column because it is not useful for our model\n# we also drop MiscFeature column because it contains extra categories of home and have almost 96% null values.\ndf_train.drop(\"Id\",axis=1,inplace=True)\ndf_train.drop(\"MiscFeature\",axis=1,inplace=True)\n\ndf_test.drop(\"Id\",axis=1,inplace=True)\ndf_test.drop(\"MiscFeature\",axis=1,inplace=True)","0671203f":"# instead of drop null values which will result in data loss, we will fill null values according to provided data description.\n# Fill null values of train data\n\ndf_train[\"LotFrontage\"].fillna(0,inplace=True)\ndf_train[\"MasVnrArea\"].fillna(0,inplace=True)\n\ndf_train[\"MasVnrType\"].fillna(\"None\",inplace=True)\n\n#NA in Alley column means No Alley, so we will replace NA by no alley.\ndf_train[\"Alley\"].fillna(\"No Alley\",inplace=True)\n\n#NA in BsmtQual,BsmtCond,BsmtExposure,BsmtFinType1,BsmtFinType2 column means No basement, so we will replace NA by no basement.\ndf_train[\"BsmtQual\"].fillna(\"No basement\",inplace=True)\ndf_train[\"BsmtCond\"].fillna(\"No basement\",inplace=True)\ndf_train[\"BsmtExposure\"].fillna(\"No basement\",inplace=True)\ndf_train[\"BsmtFinType1\"].fillna(\"No basement\",inplace=True)\ndf_train[\"BsmtFinType2\"].fillna(\"No basement\",inplace=True)\n\n#NA in FireplaceQu column means No Fireplace, so we will replace NA by no Fireplace.\ndf_train[\"FireplaceQu\"].fillna(\"No Fireplace\",inplace=True)\n\n#NA in GarageType,GarageYrBlt,GarageFinish,GarageQual,GarageCond columns mean No Garage, so we will replace NA by no garage.\ndf_train[\"GarageType\"].fillna(\"No Garage\",inplace=True)\ndf_train[\"GarageFinish\"].fillna(\"No Garage\",inplace=True)\ndf_train[\"GarageQual\"].fillna(\"No Garage\",inplace=True)\ndf_train[\"GarageCond\"].fillna(\"No Garage\",inplace=True)\ndf_train['GarageYrBlt'].fillna(\"No Garage\",inplace=True)\n\n#NA in PoolQC column means No Pool, so we will replace NA by no pool.\ndf_train[\"PoolQC\"].fillna(\"No Pool\",inplace=True)\n\n#NA in Fence column means No Fence, so we will replace NA by no fence.\ndf_train[\"Fence\"].fillna(\"No Fence\",inplace=True)","e75f55d0":"# fill null values for test data\n\ndf_test[\"LotFrontage\"].fillna(0,inplace=True)\ndf_test[\"MasVnrArea\"].fillna(0,inplace=True)\n\ndf_test[\"MasVnrType\"].fillna(\"None\",inplace=True)\n\n#NA in Alley column means No Alley, so we will replace NA by no alley.\ndf_test[\"Alley\"].fillna(\"No Alley\",inplace=True)\n\n#NA in BsmtQual,BsmtCond,BsmtExposure,BsmtFinType1,BsmtFinType2 column means No basement, so we will replace NA by no basement.\ndf_test[\"BsmtQual\"].fillna(\"No basement\",inplace=True)\ndf_test[\"BsmtCond\"].fillna(\"No basement\",inplace=True)\ndf_test[\"BsmtExposure\"].fillna(\"No basement\",inplace=True)\ndf_test[\"BsmtFinType1\"].fillna(\"No basement\",inplace=True)\ndf_test[\"BsmtFinType2\"].fillna(\"No basement\",inplace=True)\n\n#NA in FireplaceQu column means No Fireplace, so we will replace NA by no Fireplace.\ndf_test[\"FireplaceQu\"].fillna(\"No Fireplace\",inplace=True)\n\n#NA in GarageType,GarageYrBlt,GarageFinish,GarageQual,GarageCond columns mean No Garage, so we will replace NA by no garage.\ndf_test[\"GarageType\"].fillna(\"No Garage\",inplace=True)\ndf_test[\"GarageFinish\"].fillna(\"No Garage\",inplace=True)\ndf_test[\"GarageQual\"].fillna(\"No Garage\",inplace=True)\ndf_test[\"GarageCond\"].fillna(\"No Garage\",inplace=True)\ndf_test['GarageYrBlt'].fillna(\"No Garage\",inplace=True)\n\n#NA in PoolQC column means No Pool, so we will replace NA by no pool.\ndf_test[\"PoolQC\"].fillna(\"No Pool\",inplace=True)\n\n#NA in Fence column means No Fence, so we will replace NA by no fence.\ndf_test[\"Fence\"].fillna(\"No Fence\",inplace=True)","9abfc858":"# converting datatype of some variables into object to treat them as a categorical variables in train dataset.\ndf_train[\"MSSubClass\"] = df_train[\"MSSubClass\"].astype('object')\ndf_train['OverallQual'] = df_train['OverallQual'].astype('object')\ndf_train['OverallCond'] = df_train['OverallCond'].astype('object')\ndf_train['BsmtFullBath'] = df_train['BsmtFullBath'].astype('object')\ndf_train['BsmtHalfBath'] = df_train['BsmtHalfBath'].astype('object')\ndf_train['FullBath'] = df_train['FullBath'].astype('object')\ndf_train['HalfBath'] = df_train['HalfBath'].astype('object')\ndf_train['Fireplaces'] = df_train['Fireplaces'].astype('object')\ndf_train['GarageYrBlt'] = df_train['GarageYrBlt'].astype('object')","4baf8ff4":"# converting datatype of some variables into object to treat them as a categorical variables in train dataset.\ndf_test[\"MSSubClass\"] = df_test[\"MSSubClass\"].astype('object')\ndf_test['OverallQual'] = df_test['OverallQual'].astype('object')\ndf_test['OverallCond'] = df_test['OverallCond'].astype('object')\ndf_test['BsmtFullBath'] = df_test['BsmtFullBath'].astype('object')\ndf_test['BsmtHalfBath'] = df_test['BsmtHalfBath'].astype('object')\ndf_test['FullBath'] = df_test['FullBath'].astype('object')\ndf_test['HalfBath'] = df_test['HalfBath'].astype('object')\ndf_test['Fireplaces'] = df_test['Fireplaces'].astype('object')\ndf_test['GarageYrBlt'] = df_test['GarageYrBlt'].astype('object')","f1e3cbed":"sns.countplot(\"LotShape\", data=df_train)\nplt.title(\"General shape of property\", fontsize=14)\nplt.show()","b6aba02b":"sns.countplot(\"LandSlope\", data=df_train)\nplt.title(\"Slope of property\", fontsize=14)\nplt.show()","6e741401":"sns.countplot(\"OverallQual\", data=df_train)\nplt.title(\"Rates of overall material and finish of the house\", fontsize=14)\nplt.show()\n\ndf_train[\"OverallQual\"].value_counts()","e61b075c":"sns.countplot(\"RoofStyle\", data=df_train)\nplt.title(\"Type of roof\", fontsize=14)\nplt.show()\n\ndf_train[\"RoofStyle\"].value_counts()","29f63977":"sns.countplot(\"ExterCond\", data=df_train)\nplt.title(\"Present condition of the material on the exterior\", fontsize=14)\nplt.show()","a4aa676e":"sns.countplot(\"BsmtCond\", data=df_train)\nplt.title(\"General condition of the basement\", fontsize=14)\nplt.show()\n\ndf_train[\"BsmtCond\"].value_counts()","5c56b69f":"sns.countplot(\"CentralAir\", data=df_train)\nplt.title(\"Central air conditioning\", fontsize=14)\nplt.show()","9341c28f":"plt.bar(df_train[\"Street\"],df_train[\"SalePrice\"])\nplt.title(\"Street vs. Saleprice\", fontsize=14)\nplt.show()","eea7129a":"sns.barplot(x=\"LotShape\",y=\"SalePrice\",data=df_train)\nplt.title(\"Property Shape vs. Saleprice\", fontsize=14)\nplt.show()","569d5655":"sns.boxplot(x=\"OverallQual\",y=\"SalePrice\",data=df_train)\nplt.title(\"quality of houses vs. Saleprice\", fontsize=14)\nplt.show()","3427b36a":"sns.boxplot(x=\"OverallCond\",y=\"SalePrice\",data=df_train)\nplt.title(\"Condition of houses vs. Saleprice\", fontsize=14)\nplt.show()","48180045":"sns.boxplot(x=\"ExterQual\",y=\"SalePrice\",data=df_train)\nplt.title(\"Exterior quality vs. Saleprice\", fontsize=14)\nplt.show()","d1545463":"sns.scatterplot(x=\"TotalBsmtSF\",y=\"SalePrice\",data=df_train)\nplt.title(\"Basement area vs. Saleprice\", fontsize=14)\nplt.show()","97e5dd40":"sns.scatterplot(x=\"1stFlrSF\",y=\"SalePrice\",data=df_train)\nplt.title(\"First floor square feet vs. Saleprice\", fontsize=14)\nplt.show()","5f4a7448":"sns.boxplot(x=\"KitchenQual\",y=\"SalePrice\",data=df_train)\nplt.title(\"Kitchen quality vs. Saleprice\", fontsize=14)\nplt.show()","a4eba8e3":"sns.boxplot(x=\"TotRmsAbvGrd\",y=\"SalePrice\",data=df_train)\nplt.title(\"Total rooms above grade vs. Saleprice\", fontsize=14)\nplt.show()","4c9946f8":"sns.scatterplot(x=\"GarageArea\",y=\"SalePrice\",data=df_train)\nplt.title(\"Garage square feet vs. Saleprice\", fontsize=14)\nplt.show()","bea467af":"sns.boxplot(x=\"GarageQual\",y=\"SalePrice\",data=df_train)\nplt.title(\"Garage quality vs. Saleprice\", fontsize=14)\nplt.show()","0624be1a":"#split numerical and categorical columns of train dataset\nnumerical_col = df_train.select_dtypes(include=['float64','int64'])\ncat_col = df_train.select_dtypes(include=['object'])","b49d21e7":"#split numerical and categorical columns of test dataset\nnumerical_col_test = df_test.select_dtypes(include=['float64','int64'])\ncat_col_test = df_test.select_dtypes(include=['object'])","36242dea":"# check outliers through plotting boxplot.\nnumerical_col.plot.box(subplots=True,figsize=(12,16),layout=(5,6))\nplt.show()","134c156a":"# Check outliers using zscore\nfrom scipy.stats import zscore\nz = np.abs(zscore(numerical_col))\nthreshold=3\nprint(np.where(z>3))","c0c5704d":"# removing outliers\ndf_train1 = numerical_col[(z<3).all(axis=1)]\ndf_train1.head()","fb0e1b07":"# check shape of the dataset, before and after removing outliers.\nprint(df_train.shape)\nprint(df_train1.shape)","58df5590":"# check percentage loss of data after removing outliers.\npercentage_loss = ((1168-878)\/1168)*100\npercentage_loss","86af5471":"# check outliers using inter quartile range.\nQ1=numerical_col.quantile(0.25)\nQ3=numerical_col.quantile(0.75)\nIQR=Q3-Q1\nprint(IQR)","7583c176":"df_new1=numerical_col[~((numerical_col < (Q1 - 1.5 * IQR)) | (numerical_col > (Q3 + 1.5 * IQR))).any(axis=1)]\nprint(df_new1.shape)","f7046d9d":"# here, our target variable is saleprice, so we take it as a y variable. It is a regression type problem. \nx = df_train.drop([\"SalePrice\"],axis=1)\ny = df_train[\"SalePrice\"]","f146de7f":"x.skew()","8369a284":"# check skewness of the some features.\nsns.distplot(df_train[\"LotArea\"])","c1fb09e8":"sns.distplot(df_train[\"BsmtFinSF2\"])","eb81f295":"sns.distplot(df_train[\"LowQualFinSF\"])","29e1f9e0":"sns.distplot(df_train[\"PoolArea\"])","5e0f54bf":"sns.distplot(df_train[\"MiscVal\"])","8132d1d6":"# here, we remove skewness of numerical features using log method.\nx = x.select_dtypes(include=['float64','int64'])\nx = np.log1p(x)\n\n# remove skewness of test datasets numerical features.\nz = df_test.select_dtypes(include=['float64','int64'])\nz = np.log1p(z)","0beaf11a":"# merge numerical and categorical variables for train dataset\nx_new = pd.concat([x,cat_col],axis=1)\n\n# merge numerical and categorical variables data for test dataset.\ndf_test = pd.concat([z,cat_col_test],axis=1)","5e8dbe35":"# merge train and test dataset for encoding.\ndf = pd.concat((x_new,df_test))","355199cc":"# Here, we convert categorical data into numerical data for model building and we use one hot encoding method.\nx_encode = pd.get_dummies(df, drop_first=True)\nx_encode.shape","7ec9e185":"#scaling data with mean=0 and unit variance using standard scaler mothod\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_s = sc.fit_transform(x_encode)","dda8608b":"# here, we split train dataset and test dataset for further process.\nx = x_encode.head(1168) # we already split our target variable in above process as y \n\ndf_test = x_encode.tail(292)","61a45d44":"# split train and test data from training dataset.\nfrom sklearn.model_selection import train_test_split,cross_val_score\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)","2eaa2779":"# our target variable is saleprice so it's a regression type problem.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n\nmodel = [LinearRegression(),SVR(),KNeighborsRegressor(),DecisionTreeRegressor(),ExtraTreeRegressor()]\n\nfor i in model:\n    i.fit(x_train,y_train)\n    train=i.score(x_train,y_train)\n    predi=i.predict(x_test)\n    print(\"Accuracy of\",i,\"is:\")\n    print(\"Model training accuracy:\",train)\n    print(\"r2 score:\",r2_score(y_test,predi))\n    print(\"mean absolute error:\",mean_absolute_error(y_test,predi))\n    print(\"root mean squared error:\",np.sqrt(mean_squared_error(y_test,predi)))\n    print(\"******************************************************************\")\n    print(\"\\n\")","9d4a42ac":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\nmodel = [RandomForestRegressor(),AdaBoostRegressor(),GradientBoostingRegressor(),ExtraTreesRegressor(),XGBRegressor(),CatBoostRegressor()]\n\nfor m in model:\n    m.fit(x_train,y_train)\n    train = m.score(x_train,y_train)\n    predm = m.predict(x_test)\n    print(\"Accuracy of\",m,\"is:\")\n    print(\"Model training accuracy:\",train)\n    print(\"r2 score:\",r2_score(y_test,predm))\n    print(\"mean absolute error:\",mean_absolute_error(y_test,predm))\n    print(\"root mean squared error:\",np.sqrt(mean_squared_error(y_test,predm)))\n    print(\"******************************************************************\")\n    print(\"\\n\")","2fa530ea":"from sklearn.linear_model import Ridge,Lasso\nfrom sklearn.model_selection import GridSearchCV","5184ee74":"ls = Lasso()\nparameters = {'alpha':[0.001,0.01,0.02,0.1,0.2,0.5,0.8,0.9],'max_iter':[50,70,100,150,200,400,700,1000]}\nreg = GridSearchCV(ls,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","c8e59c7f":"ls = Lasso(alpha=0.9,max_iter=50)\nls.fit(x_train,y_train)\ntrain=ls.score(x_train,y_train)\npred_ls=ls.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_ls))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_ls))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_ls)))","56f93935":"# plot the model with regression line to check how well regression line is fit in our data.\nplt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=pred_ls, color='r')\nplt.plot(y_test,y_test,color='b')\nplt.xlabel(\"Actual saleprice \",fontsize=14)\nplt.ylabel(\"Predicted saleprice\",fontsize=14)\nplt.title(\"Lasso Regression\",fontsize=18)\nplt.show()","ab9de80f":"rg = Ridge()\nparameters={'alpha':[0.001,0.01,0.02,0.1,0.2,0.4,0.6,0.7,0.9,1],'max_iter':[50,100,200,400,800,1000,1200]}\nreg = GridSearchCV(rg,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","1ff460d7":"rg = Ridge(alpha=1,max_iter=50)\nrg.fit(x_train,y_train)\ntrain=rg.score(x_train,y_train)\npred_rg=rg.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_rg))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_rg))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_rg)))","f3ff187e":"# plot the model with regression line to check how well regression line is fit in our data.\nplt.figure(figsize=(8,6))\nplt.scatter(x=y_test, y=pred_rg, color='r')\nplt.plot(y_test,y_test, color='b')\nplt.xlabel(\"Actual saleprice\",fontsize=14)\nplt.ylabel(\"Predicted saleprice\",fontsize=14)\nplt.title(\"Ridge Regression\",fontsize=18)\nplt.show()","97487115":"rf = RandomForestRegressor()\nparameters={'n_estimators':[100,120,150,200,250],'ccp_alpha':[0.001,0.01,0.1,0.3]}\nreg = GridSearchCV(rf,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","56089c15":"rf = RandomForestRegressor(ccp_alpha=0.3,n_estimators=150)\nrf.fit(x_train,y_train)\ntrain = rf.score(x_train,y_train)\npred_rf=rf.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_rf))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_rf))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_rf)))","d6eebbd4":"gb = GradientBoostingRegressor()\nparameters={'learning_rate':[0.001,0.01,0.1,0.2],'n_estimators':[50,100,120],'max_depth':[3,4],'ccp_alpha':[0.001,0.01,0.1,0.2]}\nreg = GridSearchCV(gb,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","1a9f5345":"gb = GradientBoostingRegressor(ccp_alpha=0.2,learning_rate=0.1,max_depth=3,n_estimators=120)\ngb.fit(x_train,y_train)\ntrain=gb.score(x_train,y_train)\npred_gb=gb.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_gb))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_gb))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_gb)))","acb10689":"xg = XGBRegressor()\nparameters={'n_estimators':[100,200,250],'max_depth':[4,5],'learning_rate':[0.001,0.1,0.2,0.3]}\nreg = GridSearchCV(xg,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","4e632d56":"xg = XGBRegressor(learning_rate=0.3,max_depth=5,n_estimators=200)\nxg.fit(x_train,y_train)\ntrain=xg.score(x_train,y_train)\npred_xg=xg.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_xg))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_xg))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_xg)))","0a90aeec":"cat = CatBoostRegressor()\nparameters={'iterations':[500,700],'learning_rate':[0.001,0.01,0.1]}\nreg = GridSearchCV(cat,parameters)\nreg.fit(x_train,y_train)\n\nprint(reg.best_params_)","bfc8125f":"cat = CatBoostRegressor(iterations=500,learning_rate=0.1)\ncat.fit(x_train,y_train)\ntrain=cat.score(x_train,y_train)\npred_cat=cat.predict(x_test)\nprint(\"Model training accuracy:\",train)\nprint(\"r2_score:\",r2_score(y_test,pred_cat))\nprint(\"mean absolute error:\",mean_absolute_error(y_test,pred_cat))\nprint(\"root mean squared error\", np.sqrt(mean_squared_error(y_test,pred_cat)))","befe8e50":"# we got good accuracy using catboost. Now check accuracy of model with cross-validation.\naccuracy = cross_val_score(cat,x,y,cv = 10,scoring=\"r2\")\nprint(accuracy)\nprint(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)","3938cb07":"#save best result\ndf1 = pd.DataFrame(pred_cat)\ndf1.to_csv(\"cat_housing.csv\")\n#save best model\nimport joblib\njoblib.dump(cat,\"cat_housing.obj\")","28e9b501":"# check our test data with best model\ntest = cat.predict(df_test)\nprint(test)","495895c8":"#Save test data result\ndf2 = pd.DataFrame(pred_cat)\ndf2.to_csv(\"cat_test_housing.csv\")","873022f2":"From the above count plot we can see that, most of the properties have central air conditioning system.(Y=yes,N=no)","e7f9cd6c":"## Encoding Data","15af2b50":"Where garage quality is excellent, properties price is around 400000 dollar and price is around 100000 dollar where garage quality is poor.(Ex=Excellent,Gd=Good,TA=Typical\/Average,Fa=Fair,Po=Poor,NA=No Garage)","74393473":"From the above plot we can see that, out of 1168 houses 314 houses overall quality is average and 295 houses overall quality is above average.(10=Very Excellent,9=Excellent,8=Very Good,7=Good,6=Above Average,5=Average,4=Below Average,3=Fair,2=Poor,1=Very Poor)","72da5299":"From the above box plot we can see that, price of the houses is very high where overall quality of the houses is very excellent and price decrease from going 10 to 1. (10=Very Excellent,9=Excellent,8=Very Good,7=Good,6=Above Average,5=Average,4=Below Average,3=Fair,2=Poor,1=Very Poor)","76c507df":"## Bagging and Boosting method","13ff4065":"From the above all plot we can see taht, all plots mostly have right skewed and need to remove skewness. we use log method for remove skewness.","e7c26fba":"Properties price is very high where street is paved, while price is low where street is gravel. ","a856ea7b":"### Data cleaning ","b0ec80fb":"From the above scatterplot we can see that, First floor square feet and houses price are positively correlated to each other.","d7203782":"# Housing Project","584e6d9c":"## Hyperparameter Tuning","503f83bf":"Out of 1168 properties, Approximately 750 properties are in regular shape, while around 400 properties are slightly irregular.(Reg=Regular,IR1=Slightly irregular,IR2=Moderately Irregular,IR3=Irregular)","b2050ef1":"### Read and Understand data","d0eb5914":"Square feet area of garage and properties price is positively correlated to each other.","e4ca93fb":"## Handling Skewness","2dd44572":"## Lasso and Ridge regression with Hyperparameter Tuning","2c4846fb":"From the above plot we can see that, most of the properties land slope is gentle.(Gtl=Gentle slope,Mod=Moderate Slope,Sev=Severe Slope)","cd5abbab":"From the above plot we can see that, almost 1000 properties Present condition of the material on the exterior is average. (Ex=Excellent,Gd=Good,TA=Average\/Typical,Fa=Fair,Po=Poor)","2795e191":"From the above all observation, we can see that we get best accuracy using cat boost with hyperparameter tuning. Which give r2_score is 0.84 and mean absolute error is 17120.93.","4b5f510c":"From the above boxplot we can see that, almost every features have outliers and need to remove.","4da454fb":"## Scaling data","0e547048":"We get best model score using cross-validation with cat boost(87.01%). So, we can also say that our model is not underfitted and overfitted.","f4924d8b":"From the above bar plot we can see that, properties price is high where shape of the properties is moderately irregular, while price is low where shape of the properties regular compares to other categories.(Reg=Regular,IR1=Slightly irregular,IR2=Moderately Irregular,IR3=Irregular)","b59b9a6a":"From the above scatterplot we can see that, total square feet of basement area and saleprice are positively correlated to each other. ","45177014":"Properties price is high where quality of the material on the exterior is excellent, while price is low where quality of the material on the exterior is fair.(Ex=Excellent,Gd=Good,TA=Average\/Typical,Fa=Fair,Po=Poor)","99227d38":"# Find best Model","115a3dd0":"From the above plot we can see that, properties price is higher where total rooms above grade is 12 but price is lower where total rooms above grade is 14. ","d634ee90":"Out of 1168 houses, 1041 houses basement condition is typical, while 30 hoses are without basement.(Gd=Good,TA=Typical - slight dampness allowed,Fa=Fair - dampness or some cracking or settling,Po=Poor - Severe cracking, settling, or wetness)","e33812a8":"Out of 1168 houses, 915 houses roof style is Gable and only 2 houses roof style is shed.","cfd38ca6":"1. Train data have 1168 rows and 81 features.\n2. test data have 292 rows and 80 features.","8e228063":"1. From the above table we can see that, there is large difference between mean of the data and standard deviation of the data of many columns. it depicts skewness is present in data and need to remove.\n2. We can also see that, there is large difference between 75% of the data and maximum data. It depicts outliers present in data and need to remove.\n3. Here, some variables are categorical. So, in cleaning process we will chage datatype of some variables.\n4. properties minimum price is 34900 doller and maximum price is 755000 doller.","3ccd8816":"Here, percentage loss of data is also high by using inter qurtile range. so, removing outliers is not a good idea because it losses more data and it affects our model badely.","b2f290b9":"Here, percentage loss of data is very high using zscore. so, we don't use zscore for remove outliers. ","221a2eb4":"from the above observation we can see that, value above 4 depicts skewness, so check skewness of those features by using distribution plot and then decide remove skewness or not. ","e7d1df63":"From the above box plot we can see that, houses price is higher where kitchen quality is excellent and price is lower where kitchen quality is fair compare to other categories.(Ex=Excellent,Gd=Good,TA=Typical\/Average,Fa=Fair)","38147645":"### Data Analysis","f2e1a87f":"## Prepare data for model training","6f605770":"## Handling Outliers","3f9a3c6a":"From the above info we can see that, null value present in data and need to fill.","9436da8a":"1. From the above box plot we can see that, houses price is high where overall condition of the houses is excellent, while price of the houses is almost same where condition of the houses is above average,good and very good.\n2. Average condition houses price is higher than above average, good and very good condition houses. \n3. (9=Excellent,8=Very Good,7=Good,6=Above Average,5=Average,4=Below Average,3=Fair,2=Poor,1=Very Poor)"}}