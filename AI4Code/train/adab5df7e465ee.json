{"cell_type":{"9167edce":"code","5b607349":"code","5acc3831":"code","93c7bde4":"code","21953b6a":"code","a20d80dd":"code","d94ec0d4":"code","3cf461c0":"code","92746810":"code","7fac75cb":"code","a6a8268b":"code","a1e22968":"code","651bc6c6":"code","3e8f3446":"code","15dda154":"code","91c31d5a":"code","09024d42":"code","c77d864d":"code","89863b6d":"code","f8c540c6":"code","b5072022":"code","7762f5d8":"code","9062222c":"code","3e230161":"code","fefa8312":"code","4be78044":"code","578a2165":"code","ee2842f9":"code","a572fcc2":"code","44cf28b9":"code","31a2bc9e":"code","8880bd0b":"code","537d3b43":"code","f0562c5a":"code","c0220b65":"code","e5390383":"code","f0528c2a":"code","9845806f":"markdown","cf2b395a":"markdown","9848cf5d":"markdown","cd7ad389":"markdown","c836c850":"markdown","f1105dc2":"markdown","07fbcc27":"markdown","7a805d47":"markdown","5446a2c6":"markdown","36d7be69":"markdown","807b35ef":"markdown","d9403293":"markdown","4730f0cd":"markdown","e0da3023":"markdown","0fbd1f3c":"markdown","fdaf1cd1":"markdown","2c16ab17":"markdown","4cb2aef2":"markdown","6719c7d6":"markdown","2bfe33d7":"markdown","86945a28":"markdown","533bf8fe":"markdown","0440e8a7":"markdown","7b4935f7":"markdown"},"source":{"9167edce":"import pandas as pd\nimport numpy as np\n\n# DRAGONS\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cat\n\n# plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# pandas \/ plt options\npd.options.display.max_columns = 999\nplt.rcParams['figure.figsize'] = (14, 7)\nfont = {'family' : 'verdana',\n        'weight' : 'bold',\n        'size'   : 14}\nplt.rc('font', **font)\n\n# remove warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# garbage collector\nimport gc\ngc.enable()","5b607349":"import os\nprint(os.listdir(\"..\/input\"))\n\ntrain = pd.read_csv('..\/input\/create-extracted-json-fields-dataset\/extracted_fields_train.gz', dtype={'date': str, 'fullVisitorId': str, 'sessionId':str, 'visitId': np.int64})\ntest = pd.read_csv('..\/input\/create-extracted-json-fields-dataset\/extracted_fields_test.gz', dtype={'date': str, 'fullVisitorId': str, 'sessionId':str, 'visitId': np.int64})\ntrain.shape, test.shape","5acc3831":"train.head()","93c7bde4":"traincolumns_1 = train.columns\ntraincolumns_1","21953b6a":"train_store_1 = pd.read_csv('..\/input\/exported-google-analytics-data\/Train_external_data.csv', low_memory=False, skiprows=6, dtype={\"Client Id\":'str'})\ntrain_store_2 = pd.read_csv('..\/input\/exported-google-analytics-data\/Train_external_data_2.csv', low_memory=False, skiprows=6, dtype={\"Client Id\":'str'})\ntest_store_1 = pd.read_csv('..\/input\/exported-google-analytics-data\/Test_external_data.csv', low_memory=False, skiprows=6, dtype={\"Client Id\":'str'})\ntest_store_2 = pd.read_csv('..\/input\/exported-google-analytics-data\/Test_external_data_2.csv', low_memory=False, skiprows=6, dtype={\"Client Id\":'str'})\ndataset = pd.concat(objs=[train_store_1, train_store_2], axis=0)\ndataset.info()\ndel dataset","a20d80dd":"for df in [train_store_1, train_store_2, test_store_1, test_store_2]:\n    df[\"visitId\"] = df[\"Client Id\"].apply(lambda x: x.split('.', 1)[1]).astype(np.int64)","d94ec0d4":"train = train.merge(pd.concat([train_store_1, train_store_2], sort=False), how=\"left\", on=\"visitId\")\ntest = test.merge(pd.concat([test_store_1, test_store_2], sort=False), how=\"left\", on=\"visitId\")\n\n# Drop Client Id\nfor df in [train, test]:\n    df.drop(\"Client Id\", 1, inplace=True)\nleakcolumns = [x for x in train.columns if x not in traincolumns_1]\nleakcolumns","3cf461c0":"train.head()","92746810":"train.info()","7fac75cb":"train['has_revenue'] = train['totals.transactionRevenue'].apply(lambda x: 1 if x > 0 else 0)\n\nfor df in [train, test]:\n    df['browser.os'] = df['device.browser'] + '_' + df['device.operatingSystem']\n\nfor df in [train, test]:\n    df['date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n    df['sess_date_dow'] = df['date'].dt.dayofweek\n    df['sess_date_hours'] = df['date'].dt.hour\n    df['sess_date_dom'] = df['date'].dt.day\n    df.sort_values(['fullVisitorId', 'date'], ascending=True, inplace=True)\n    df['next_session_1'] = (\n        df['date'] - df[['fullVisitorId', 'date']].groupby('fullVisitorId')['date'].shift(1)\n    ).astype(np.int64) \/\/ 1e9 \/\/ 60 \/\/ 60\n    df['next_session_2'] = (\n        df['date'] - df[['fullVisitorId', 'date']].groupby('fullVisitorId')['date'].shift(-1)\n    ).astype(np.int64) \/\/ 1e9 \/\/ 60 \/\/ 60","a6a8268b":"def missing_values(data):\n    print(data.shape)\n    total = data.isnull().sum().sort_values(ascending = False) # getting the sum of null values and ordering\n    percent = (data.isnull().sum() \/ data.isnull().count() * 100 ).sort_values(ascending = False) #getting the percent and order of null\n    df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) # Concatenating the total and percent\n    print(\"Total columns at least one Values: \")\n    print (df[~(df['Total'] == 0)]) # Returning values of nulls different of 0\n    \nmissing_values(train) \n\nprint(\"\\n Total of Sales % of Total: \", round((train[train['totals.transactionRevenue'] != \\\n        np.nan]['totals.transactionRevenue'].count() \/ len(train['totals.transactionRevenue']) * 100),4))\n\n\ntrain_leak = train[train['Sessions'].isnull().values==False]\n\nmissing_values(train_leak) \n\nprint(\"\\n Total of Sales % of train_leak: \", round((train_leak[train_leak['totals.transactionRevenue'] != \\\n        np.nan]['totals.transactionRevenue'].count() \/ len(train_leak['totals.transactionRevenue']) * 100),4))\n","a1e22968":"test.info()\nmissing_values(test) ","651bc6c6":"for df in [train_store_1, train_store_2, test_store_1, test_store_2]:\n    del df\ngc.collect()","3e8f3446":"def plotdisturbtion(df_train):\n    # Printing some statistics of our data\n    print(\"Transaction Revenue Min Value: \", \n          df_train[df_train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"].min()) # printing the min value\n    print(\"Transaction Revenue Mean Value: \", \n          df_train[df_train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"].mean()) # mean value\n    print(\"Transaction Revenue Median Value: \", \n          df_train[df_train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"].median()) # median value\n    print(\"Transaction Revenue Max Value: \", \n          df_train[df_train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"].max()) # the max value\n\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    ax = sns.distplot(np.log(df_train[df_train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"] + 0.01), bins=40, kde=True)\n    ax.set_xlabel('Transaction RevenueLog', fontsize=15) #seting the xlabel and size of font\n    ax.set_ylabel('Distribuition', fontsize=15) #seting the ylabel and size of font\n    ax.set_title(\"Distribuition of Revenue Log\", fontsize=20) #seting the title and size of font\n\n    plt.subplot(1,2,2)\n    plt.scatter(range(df_train.shape[0]), np.sort(df_train['totals.transactionRevenue'].values))\n    plt.xlabel('Index', fontsize=15) # xlabel and size of words\n    plt.ylabel('Revenue value', fontsize=15) # ylabel and size of words\n    plt.title(\"Revenue Value Distribution\", fontsize=20) # Setting Title and fontsize\n    plt\n    \nprint('whole data')\nplotdisturbtion(train)\nprint('leak data row')\nplotdisturbtion(train_leak)","15dda154":"from plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\ninit_notebook_mode(connected=True)\n\ndef barplot_percentage(count_feat, color1= 'green', \n                       color2= 'rgb(26, 118, 255)',color3= 'red',num_bars= None):\n\n    train_channel = 100*train[train[count_feat].isin(train[count_feat]\\\n            .value_counts()[:7].index.values)][count_feat].value_counts()\/len(train)\n    train_channel = train_channel.to_frame().reset_index()\n\n    test_channel = 100*test[test[count_feat].isin(train[count_feat]\\\n            .value_counts()[:7].index.values)][count_feat].value_counts()\/len(test)\n    test_channel = test_channel.to_frame().reset_index()\n    \n    leak_channel = 100*train_leak[train_leak[count_feat].isin(train[count_feat]\\\n            .value_counts()[:7].index.values)][count_feat].value_counts()\/len(train_leak)\n    leak_channel = leak_channel.to_frame().reset_index()\n    \n    if num_bars:\n        train_channel = train_channel.head(num_bars)\n        test_channel = test_channel.head(num_bars)\n        leak_channel = leak_channel.head(num_bars)\n\n    trace0 = go.Bar(\n        x=train_channel['index'],\n        y=train_channel[count_feat],\n        name='Train set',\n        marker=dict(color=color1)\n    )\n    trace1 = go.Bar(\n        x=test_channel['index'],\n        y=test_channel[count_feat],\n        name='Test set',\n        marker=dict(color=color2,)\n    )\n    trace2 = go.Bar(\n        x=leak_channel['index'],\n        y=leak_channel[count_feat],\n        name='leak data set',\n        marker=dict(color=color3,)\n    )\n\n    layout = go.Layout(\n        height=400,\n        title='{} grouping'.format(count_feat),\n        xaxis=dict(\n            tickfont=dict(size=14, color='rgb(107, 107, 107)')\n        ),\n        yaxis=dict(\n            title='Percentage of visits',\n            titlefont=dict(size=16, color='rgb(107, 107, 107)'),\n            tickfont=dict(size=14, color='rgb(107, 107, 107)')\n        ),\n        legend=dict(\n            x=1.0,\n            y=1.0,\n            bgcolor='rgba(255, 255, 255, 0)',\n            bordercolor='rgba(255, 255, 255, 0)'\n        ),\n        barmode='group',\n        bargap=0.15,\n        bargroupgap=0.1\n    )\n\n    fig = go.Figure(data=[trace0, trace1,trace2], layout=layout)\n    iplot(fig)\n    ","91c31d5a":"for x in ['geoNetwork.country','geoNetwork.region','geoNetwork.metro','channelGrouping','browser.os']:\n    barplot_percentage(x)","09024d42":"for x in ['geoNetwork.networkDomain','trafficSource.medium','device.browser']:\n    barplot_percentage(x)","c77d864d":"train.columns","89863b6d":"print(train['has_revenue'].unique())\n# print(train['has_revenue'])\ntrain['totals.transactionRevenue'] = train['totals.transactionRevenue'].fillna(0)\ntrain_leak['totals.transactionRevenue'] = train_leak['totals.transactionRevenue'].fillna(0)\ntrain.shape","f8c540c6":"import seaborn as sns\nimport matplotlib.pyplot as plt","b5072022":"def plotrevenues(col_1,col_2):\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and revenue\")\n    ax = sns.scatterplot(x=col_1 , y='totals.transactionRevenue',\n                     data=train,color='orange', hue='has_revenue')\n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and revenue\")\n    ax = sns.scatterplot(x=col_2, y='totals.transactionRevenue',\n                     data=train,color='orange', hue='has_revenue')\n    plt\n    \n    cnt_col1 = train.groupby(col_1)['totals.transactionRevenue'].agg(['mean','count'])\n    cnt_col2= train.groupby(col_2)['totals.transactionRevenue'].agg(['mean','count'])\n    \n    cnt_col1 = cnt_col1.reset_index()\n    cnt_col2 = cnt_col2.reset_index()\n    \n    cnt_col1 = cnt_col1[cnt_col1['count']>10]\n    cnt_col2 = cnt_col2[cnt_col2['count']>10]\n    \n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and mean revenue\")\n    ax = sns.scatterplot(x=col_1, y='mean',\n                     data=cnt_col1,color='blue')\n    \n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and mean revenue\")\n    ax = sns.scatterplot(x=col_2, y='mean',\n                     data=cnt_col2,color='blue')\n    plt\n\nplotrevenues('totals.pageviews','totals.hits')\n# plotrevenues('next_session_1','next_session_2')\nplotrevenues('visitNumber','sess_date_dow')\n# plotrevenues('sess_date_hours','sess_date_dom')\n\n","7762f5d8":"train_session_filter = train[train['next_session_1']>-500000]\ntrain_session_filter = train_session_filter[train_session_filter['next_session_2']>-500000]\ntrain_session_filter = train_session_filter[train_session_filter['totals.transactionRevenue'] < 100000000]\ndef plotrevenues_filter(col_1,col_2):\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and revenue\")\n    ax = sns.scatterplot(x=col_1 , y='totals.transactionRevenue',\n                     data=train_session_filter,color='orange', hue='has_revenue')\n    \n#     plt.figure(figsize=(14,5))\n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and revenue\")\n    ax = sns.scatterplot(x=col_2, y='totals.transactionRevenue',\n                     data=train_session_filter,color='orange', hue='has_revenue')\n    plt\n    \n    \n    t_s_f = train_session_filter[[col_1,col_2,'totals.transactionRevenue']]\n    \n    t_s_f[col_1] = t_s_f[col_1].apply(lambda x: int(x\/10))\n    t_s_f[col_2] = t_s_f[col_2].apply(lambda x: int(x\/10))\n    \n    \n    cnt_col1 = t_s_f.groupby(col_1)['totals.transactionRevenue'].agg(['mean','count'])\n    cnt_col2= t_s_f.groupby(col_2)['totals.transactionRevenue'].agg(['mean','count'])\n    \n    cnt_col1 = cnt_col1.reset_index()\n    cnt_col2 = cnt_col2.reset_index()\n    \n    cnt_col1 = cnt_col1[cnt_col1['count']>5]\n    cnt_col2 = cnt_col2[cnt_col2['count']>5]\n    \n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and mean revenue\")\n    ax = sns.scatterplot(x=col_1, y='mean',\n                     data=cnt_col1,color='blue')\n    \n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and mean revenue\")\n    ax = sns.scatterplot(x=col_2, y='mean',\n                     data=cnt_col2,color='blue')\n    plt\n    \nplotrevenues_filter('next_session_1','next_session_2')","9062222c":"for df in [train_leak]:\n    df[\"Revenue\"].fillna('$', inplace=True)\n    df[\"Revenue\"] = df[\"Revenue\"].apply(lambda x: x.replace('$', '').replace(',', ''))\n    df[\"Revenue\"] = pd.to_numeric(df[\"Revenue\"], errors=\"coerce\")\n    df[\"Revenue\"].fillna(0.0, inplace=True)\n    \nfor df in [train_leak]:\n    df[\"Avg. Session Duration\"][df[\"Avg. Session Duration\"] == 0] = \"00:00:00\"\n    df[\"Avg. Session Duration\"] = df[\"Avg. Session Duration\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n    df[\"Bounce Rate\"] = df[\"Bounce Rate\"].astype(str).apply(lambda x: x.replace('%', '')).astype(float)\n    df[\"Goal Conversion Rate\"] = df[\"Goal Conversion Rate\"].astype(str).apply(lambda x: x.replace('%', '')).astype(float)","3e230161":"leakcolumns","fefa8312":"def plotrevenues_leak(col_1,col_2):\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and revenue\")\n    ax = sns.scatterplot(x=col_1 , y='totals.transactionRevenue',\n                     data=train_leak_filter,color='orange', hue='has_revenue')\n    \n#     plt.figure(figsize=(14,5))\n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and revenue\")\n    ax = sns.scatterplot(x=col_2, y='totals.transactionRevenue',\n                     data=train_leak_filter,color='orange', hue='has_revenue')\n    plt\n        \n    cnt_col1 = train_leak_filter.groupby(col_1)['totals.transactionRevenue'].agg(['mean','count'])\n    cnt_col2= train_leak_filter.groupby(col_2)['totals.transactionRevenue'].agg(['mean','count'])\n    \n    cnt_col1 = cnt_col1.reset_index()\n    cnt_col2 = cnt_col2.reset_index()\n    \n    cnt_col1 = cnt_col1[cnt_col1['count']>5]\n    cnt_col2 = cnt_col2[cnt_col2['count']>5]\n    \n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,1)\n    plt.title(\"Number of \" + col_1 + \" and mean revenue\")\n    ax = sns.scatterplot(x=col_1, y='mean',\n                     data=cnt_col1,color='blue')\n    \n    plt.subplot(1,2,2)\n    plt.title(\"Number of \" + col_2 + \"and mean revenue\")\n    ax = sns.scatterplot(x=col_2, y='mean',\n                     data=cnt_col2,color='blue')\n    plt","4be78044":"train_leak_filter = train_leak[train_leak['Sessions']<200] ","578a2165":"plotrevenues_leak('Sessions','Avg. Session Duration')\nplotrevenues_leak('Bounce Rate','Revenue')\nplotrevenues_leak('Transactions','Goal Conversion Rate')","ee2842f9":"def topcolumn_proces(colname):\n    browsers_top= train[train[colname].isin(train[colname].value_counts()[:6].index.values)][colname]\n    browsercolumns = browsers_top.unique()\n    def source_mapping(x):\n        if x in browsercolumns:\n            return x\n        else:\n            return 'others'\n    train[colname+'_new'] = train[colname].map(lambda x:source_mapping(str(x))).astype('str')\n    train_leak[colname+'_new'] = train_leak[colname].map(lambda x:source_mapping(str(x))).astype('str')\nfor x in ['geoNetwork.country','channelGrouping','browser.os','trafficSource.medium']:\n    topcolumn_proces(x)    ","a572fcc2":"train_Revenue_filter = train[train['totals.transactionRevenue']<5000000000]","44cf28b9":"# train_n = train[train[\"Bounce Rate\"] > 0]\ndef plotjointplot(df,colname,cate_name):\n    g = sns.jointplot(df[colname], df['totals.transactionRevenue'],  s=1, size=12)\n    g.ax_joint.cla()\n    plt.sca(g.ax_joint)\n    categorycolumns = train[cate_name+'_new'].unique()\n    for cate_col in categorycolumns:\n        v = df[df[cate_name+'_new'] == cate_col]\n        plt.scatter(v[colname], v['totals.transactionRevenue'], s=4, label='{}'.format(cate_col))\n    plt.xlabel(colname,fontsize=15)\n    plt.ylabel('totals.transactionRevenue',fontsize=15)\n    plt.legend()\n    plt","31a2bc9e":"train_Ru_Pg_filter = train_Revenue_filter[train_Revenue_filter['totals.pageviews']<200]\ntrain_Ru_hits_filter = train_Revenue_filter[train_Revenue_filter['totals.hits']<250]\ntrain_Ru_vis_filter = train_Revenue_filter[train_Revenue_filter['visitNumber']<100]\n\n# for x in ['geoNetwork.country','channelGrouping','browser.os','trafficSource.medium']:\n#     plotjointplot(train_Ru_Pg_filter,'totals.pageviews',x)\nplotjointplot(train_Ru_Pg_filter,'totals.pageviews','geoNetwork.country')\nplotjointplot(train_Ru_hits_filter,'totals.hits','browser.os')\nplotjointplot(train_Ru_vis_filter,'visitNumber','geoNetwork.country')","8880bd0b":"train_leak_filter = train_leak[train_leak['totals.transactionRevenue']<200000000]\ntrain_leak_filter = train_leak_filter[train_leak_filter['Sessions']<200] ","537d3b43":"for x in ['browser.os']:\n    for y in leakcolumns:\n        plotjointplot(train_leak_filter,y,x)","f0562c5a":"def plotmapvisit(df_train):\n    # Counting total visits by countrys\n    countMaps = pd.DataFrame(df_train['geoNetwork.country'].value_counts()).reset_index()\n    countMaps.columns=['country', 'counts'] #renaming columns\n    countMaps = countMaps.reset_index().drop('index', axis=1) #reseting index and droping the column\n\n    data = [ dict(\n            type = 'choropleth',\n            locations = countMaps['country'],\n            locationmode = 'country names',\n            z = countMaps['counts'],\n            text = countMaps['country'],\n            autocolorscale = False,\n            marker = dict(\n                line = dict (\n                    color = 'rgb(180,180,180)',\n                    width = 0.5\n                ) ),\n            colorbar = dict(\n                autotick = False,\n                tickprefix = '',\n                title = 'Number of Visits'),\n          ) ]\n\n    layout = dict(\n        title = 'Couting Visits Per Country',\n        geo = dict(\n            showframe = False,\n            showcoastlines = True,\n            projection = dict(\n                type = 'Mercator'\n            )\n        )\n    )\n\n    figure = dict( data=data, layout=layout )\n    iplot(figure, validate=False, filename='map-countrys-count')\nplotmapvisit(train)","c0220b65":"plotmapvisit(train_leak)","e5390383":" def plotmaprevenues(df_train):\n    # I will crete a variable of Revenues by country sum\n    sumRevMaps = df_train[df_train['totals.transactionRevenue'] > 0].groupby(\"geoNetwork.country\")[\"totals.transactionRevenue\"].count().to_frame().reset_index()\n    sumRevMaps.columns = [\"country\", \"count_sales\"] # renaming columns\n    sumRevMaps = sumRevMaps.reset_index().drop('index', axis=1) #reseting index and drop index column\n\n    data = [ dict(\n            type = 'choropleth',\n            locations = sumRevMaps['country'],\n            locationmode = 'country names',\n            z = sumRevMaps['count_sales'],\n            text = sumRevMaps['country'],\n            autocolorscale = False,\n            marker = dict(\n                line = dict (\n                    color = 'rgb(180,180,180)',\n                    width = 0.5\n                ) ),\n            colorbar = dict(\n                autotick = False,\n                tickprefix = '',\n                title = 'Count of Sales'),\n          ) ]\n\n    layout = dict(\n        title = 'Total Sales by Country',\n        geo = dict(\n            showframe = False,\n            showcoastlines = True,\n            projection = dict(\n                type = 'Mercator'\n            )\n        )\n    )\n\n    figure = dict( data=data, layout=layout )\n\n    iplot(figure, validate=False, filename='map-countrys-total')\nplotmaprevenues(train)","f0528c2a":"plotmaprevenues(train_leak)","9845806f":"**<font size=5>Process some category columns<\/font>**","cf2b395a":"\n**<font size=3>whole data set :  revenues counts<\/font>**","9848cf5d":"**<font size=5>Objectives:<font>**\n<font size=3>\n* Explore importance of leak data in the whole data set.  \n*     What is the % missing 'totals.transactionRevenue' in leak data row.  \n*     What is the % of frequence in leak data row.  \n*     What is the correlation of importance feature between 'totals.transactionRevenue' <font>\n    \n**<font size=3>I would try my best hope you like it<font>**\n\n","cd7ad389":"**<font size=3>leak data all highly correlated to revenue<\/font>**","c836c850":"**<font size=3>Wow totals.pageviews totals.hits highly correlated with revenue<\/font>**","f1105dc2":"**<font size=3>Filter feature session1 and session2<\/font>**","07fbcc27":"**<font size=5>Plot jointplot plot<\/font>**","7a805d47":"**<font size=5>Geolocation plot to visually understand the data<\/font>**  \n\n\n**<font size=3>whole data set :  vistis<\/font>**","5446a2c6":"\n**<font size=5>Processed feature for further use<\/font>**","36d7be69":"**<font size=3>leak data set : vistis<\/font>**","807b35ef":"**<font size=5>Distribuition of Category columns<\/font>**","d9403293":"**<font size=3>leak data set :  revenues counts<\/font>**","4730f0cd":"<font size=3>\nWhole data row 1.2744% have 'totals.transactionRevenue' value  \n    \n Leak data row 42.4326% have 'totals.transactionRevenue' value\n<\/font>\n","e0da3023":"**<font size=3>Filter  leak data revenue and sessions<\/font>**","0fbd1f3c":"**<font size=5>Distribuition and Trend of Number columns<\/font>**","fdaf1cd1":"**<font size=3>Filter pageviews hits visitnumber<\/font>**","2c16ab17":"**<font size=5>Distribuition of transactions Revenues<\/font>**","4cb2aef2":"**<font size=3>It is my first EDA:))))))))))<\/font>**","6719c7d6":"**<font size=5>Check extend feature<\/font>**","2bfe33d7":"**<font size=5>Distribuition and Trend of leak Number columns<\/font>**","86945a28":"**<font size=5>Knowing the missing values<\/font>**","533bf8fe":"**<font size=5>load data<\/font>**","0440e8a7":"**<font size=3>Filter revenue > 5000000000<\/font>**","7b4935f7":"**<font size=3>Remove session > 200<\/font>**"}}