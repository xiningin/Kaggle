{"cell_type":{"187ac5b4":"code","b6cb7c74":"code","0e2b4268":"code","6cc0bbc2":"code","410189e7":"code","ec2d8478":"code","b57f0b0e":"code","961c8edc":"code","222cfd18":"code","3a072929":"code","5b1bca63":"code","53a48470":"code","53df54a2":"code","5f1ebe30":"code","0acb7ede":"code","56295062":"code","848c0931":"code","612c3f9c":"code","cebd99d4":"code","79cb46f5":"code","0a22bd27":"code","c4e6d29b":"code","1395e934":"code","78c3b2c8":"code","c96c002f":"code","3cd77e37":"code","95d03e20":"code","4916ee42":"code","8648803c":"markdown","ca3a8583":"markdown","2ab1a856":"markdown","2d039f05":"markdown","de5541ed":"markdown","0c9544f6":"markdown","d03add07":"markdown","60e5ac4a":"markdown","62e6485f":"markdown","5d5a02d9":"markdown","4bc7b414":"markdown","3bb1f99f":"markdown","437f90e6":"markdown","528ab1e3":"markdown","71d15e3a":"markdown","813f7fe1":"markdown","9edd4837":"markdown"},"source":{"187ac5b4":"import pandas as pd\nfrom textblob import TextBlob\nfrom plotly.offline import iplot\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport nltk\nimport string\nimport re\nfrom wordcloud import WordCloud , STOPWORDS\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b6cb7c74":"import os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0e2b4268":"data = pd.read_csv(\"..\/input\/data.csv\")","6cc0bbc2":"stop = set(stopwords.words('english'))\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\n\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return cleaned","410189e7":"final_string=[]\nfor i, sent in enumerate(tqdm(data['raw_text'].values)):\n    filtered_sentence=[]\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n\n    final_string.append(str1)\ndata['Cleaned_rawText']=final_string\ndata['Cleaned_rawText']=data['Cleaned_rawText'].str.decode(\"utf-8\")","ec2d8478":"def plot_wordcloud(text,mask=None,max_words=500,max_font_size=100,figure_size=(24.0,16.0),title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    plt.imshow(wordcloud);\n    plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                              'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()      ","b57f0b0e":"plot_wordcloud(data['raw_text'], title=\"Word Cloud of raw_text\")","961c8edc":"def features(data):\n    #Number of words\n    data['number_of_words']=data['raw_text'].apply(lambda x:len(str(x).split()))\n    # Number of unique words in the text \n    data['number_unique_words']=data['raw_text'].apply(lambda x:len(set(str(x).split())))\n    # Number of characters in the text\n    data['num_char']=data['raw_text'].apply(lambda x:len(str(x)))\n    # Number of stopwords in the text\n    data['num_of_stopwords']=data['raw_text'].apply(lambda x:len([ w for w in str(x).lower().split() if w in STOPWORDS]))\n    # Number of punctuation in the text\n    data['num_punctuation'] = data['raw_text'].apply(lambda x:len([c for c in str(x) if c in string.punctuation]))\n    # Number of upper case words\n    data['num_words_upper']=data['raw_text'].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n    return data","222cfd18":"data = features(data)","3a072929":"# Average Word length\ndef avg_word(sentence):\n    words = sentence.split(\" \")\n    return (sum(len(word) for word in words)\/len(words))","5b1bca63":"data['raw_avg_word_length']=data['raw_text'].apply(lambda x: avg_word(x))","53a48470":"data.columns","53df54a2":"data['num_char'].describe()","5f1ebe30":"plt.figure(figsize=(10.0,8.0))\nsns.boxplot(data['num_char'],orient='v')","0acb7ede":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['num_char'],kde=True)","56295062":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['number_of_words'])","848c0931":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['number_unique_words'])","612c3f9c":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['num_of_stopwords'])","cebd99d4":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['num_punctuation'])","79cb46f5":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['num_words_upper'])","0a22bd27":" plt.figure(figsize=(10.0,8.0))\nsns.distplot(data['raw_avg_word_length'])","c4e6d29b":"#By using textblob to get polarity of text\ndef get_polarity(text):\n    try:\n        pol = TextBlob(text).sentiment.polarity\n    except:\n        pol = 0.0\n    return pol","1395e934":"data['raw_text_polarity'] = data['Cleaned_rawText'].apply(get_polarity)","78c3b2c8":"# data.head()","c96c002f":"# data[data['raw_text_polarity']==1].head(2)","3cd77e37":"# data[data['raw_text_polarity']==-1].head(2)","95d03e20":"posdf = data[data['raw_text_polarity']==1]\nnegdf = data[data['raw_text_polarity']==-1]","4916ee42":"pos_text_data =\" \".join(posdf.Cleaned_rawText)\nneg_text_data = \" \".join(negdf.Cleaned_rawText)\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=[20, 20])\nwordcloud1 = WordCloud(background_color='white', height=400).generate(pos_text_data)\nax1.imshow(wordcloud1)\nax1.axis('off');\nax1.set_title('Positive text');\n\nwordcloud2 = WordCloud(background_color='white', height=400).generate(neg_text_data)\nax2.imshow(wordcloud2)\nax2.axis('off');\nax2.set_title('Negative text');","8648803c":"# 2. Loading and Reading the data","ca3a8583":"<h1>4. Some Feature engineering:<\/h1>\n\n<ol><b>Now let us create some meta features and then look at how they are distributed between the classes. The ones that we will create are<\/b>\n    <li> Number of words in the text<\/li>\n    <li> Number of unique words in the text<\/li>\n    <li> Number of characters in the text<\/li>\n    <li> Number of stopwords<\/li>\n    <li> Number of punctuations<\/li>\n    <li> Number of upper case words<\/li>\n    <li> Number of title case words<\/li>\n    <li> Average length of the words<\/li>\n<\/ol>","2ab1a856":"## Wordcloud:\n### summarizing the context from data\n","2d039f05":"> <b>From wordcloud we can conclude that most of our raw_text summarize the context related to like <font color='red'>inspiring,\n    spirituality , masterpiece , mentally , simplistically. <\/font><\/b>","de5541ed":"# 1. Importing packages","0c9544f6":"><b><font color='red'>From the wordcloud we can observe that our raw_text features consist of positive and negative sentence like some of the follow:<br><font color='green'>Positive words: Best, Perfect ... <br> <font color='blue'>Negative words: Evil, Worst ...<\/font><\/b>","d03add07":"# 5. Checking the distribution of our feature","60e5ac4a":"### 4. feature - num_of_stopwords","62e6485f":"### 7. feature - raw_avg_word_length","5d5a02d9":"### 5. feature - num_punctuation","4bc7b414":"## Wordcloud for positive and negative text","3bb1f99f":"### 1. feature - num_char","437f90e6":"# 6. Polarity check for raw_text\n\n### Which raw_text is positive or negative","528ab1e3":"### 3. feature - number_unique_words","71d15e3a":"### 2. feature - number_of_words","813f7fe1":"# 3. Pre-processing","9edd4837":"### 6. feature - num_words_upper"}}