{"cell_type":{"df816084":"code","69f20a47":"code","cd1e7f83":"code","d4db7e08":"code","b0c7159f":"code","fc56e0ec":"code","4d664be9":"markdown","b0e3b836":"markdown","50788101":"markdown","a54bea86":"markdown","5a3e85a3":"markdown","da2d035c":"markdown","ac193fcd":"markdown"},"source":{"df816084":"import pandas as pd\nimport pickle\n\nDATA_PATH = \"\/kaggle\/input\/defi-ia-insa-toulouse\"\ntrain_df = pd.read_json(DATA_PATH+\"\/train.json\")\ntest_df = pd.read_json(DATA_PATH+\"\/test.json\")\ntrain_label = pd.read_csv(DATA_PATH+\"\/train_label.csv\")","69f20a47":"train_df[\"description_lower\"] = [x.lower() for x in train_df.description]\ntest_df[\"description_lower\"] = [x.lower() for x in test_df.description]","cd1e7f83":"from sklearn.feature_extraction.text import TfidfVectorizer\ntransformer = TfidfVectorizer().fit(train_df[\"description_lower\"].values)\nprint(\"NB features: %d\" %(len(transformer.vocabulary_)))\nX_train = transformer.transform(train_df[\"description_lower\"].values)\nX_test = transformer.transform(test_df[\"description_lower\"].values)\nX_train","d4db7e08":"from sklearn.linear_model import LogisticRegression\nY_train = train_label.Category.values\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)","b0c7159f":"predictions = model.predict(X_test)\npredictions","fc56e0ec":"test_df[\"Category\"] = predictions\nbaseline_file = test_df[[\"Id\",\"Category\"]]\nbaseline_file.to_csv(\"\/kaggle\/working\/baseline.csv\", index=False)","4d664be9":"In this notebook we describe the code use to produce the baseline. ","b0e3b836":"# Data and Libraries","50788101":"# Vectorization\n\nWe use TfidfVectorizer to transform words from text to numerical vector data.  \n\nMore vectorize are available on scikit-learn -> https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.feature_extraction.text\n\nYou also may want to have a look at words embedding methods (Word2vec, Glove, etc..)","a54bea86":"# Learning\n\nWe use a simple Logistic Regression model with scikit learn default arguments'value to train the baseline model. ","5a3e85a3":"# Cleaning\n\nThe only cleaning transformation applied here is that we `lower` the data so that all words are lower case. \nHence `research`and `Research` will be considered as similar word.\n\nYou might want to look at other cleaning step such that removing stopwords, stemming words, etc.","da2d035c":"# File Generation","ac193fcd":"# Prediction"}}