{"cell_type":{"9c025bba":"code","ed8a1a94":"code","88743030":"code","4b814836":"code","8ff13dd1":"code","342219bd":"code","c65fe26b":"code","6f59eb38":"code","25239860":"code","edef552d":"code","cab0526f":"code","1932d469":"code","fa937fc4":"code","044b3ee9":"code","15bb3400":"code","a63aca1b":"code","380144cc":"code","5122433b":"code","dbe55490":"code","7dbc8f54":"code","bee93902":"code","5e43398e":"code","bea15b2f":"code","0b8af319":"code","b5a4454d":"code","ca202390":"code","bfca41d4":"code","d0b5e153":"code","337edc32":"code","d796c4aa":"code","107f49e0":"code","e7affbcd":"code","be2cd131":"code","bd985896":"code","32af4cd2":"code","8373298d":"code","c8ce7c9d":"code","99951dc0":"code","f3d47834":"code","16e8b159":"code","ba7e0906":"code","6ee2fcb8":"code","78ff656b":"code","192e530d":"code","224185d4":"code","9268e012":"code","c167406c":"code","753ec4f2":"code","8ea6eb15":"code","4632d261":"code","1ffa8c30":"code","863a53ec":"code","818aefd3":"code","b9d92260":"code","4f3150b0":"code","bd08ece7":"code","d00ffd68":"code","7e6bd764":"code","62e5512a":"code","793c7ad4":"code","b4f97afa":"code","d64e99b9":"code","ee97ea03":"code","a8c62f3b":"code","6c925e61":"code","bd4c7240":"code","90c575b6":"code","ecd860cd":"code","531a4c57":"code","57cfe1a7":"code","3a6ef7ce":"code","4d7d8ae6":"code","a0c06f96":"code","44a7cbfb":"code","00bf5f60":"code","13780f29":"code","d68ad9a2":"code","8489e44e":"code","61000c6a":"code","6ad3a548":"code","14cf8d45":"code","60b64d99":"code","c5273070":"code","75f57ece":"code","0149cde8":"code","5eb3b4f4":"code","93102f13":"code","86c6eba0":"code","75bc68df":"code","92f81b4a":"code","00677f6d":"markdown","c4b6ba13":"markdown","d34bfe1b":"markdown","6c28f96c":"markdown","7737d255":"markdown","90b00e26":"markdown","553fb635":"markdown","2d6d3441":"markdown","8cf6e842":"markdown","d7f5312e":"markdown","b2032d61":"markdown","2043edcc":"markdown","c4ceddf4":"markdown","6df90166":"markdown","fb61c0c5":"markdown","663e5bca":"markdown","6098528a":"markdown","38aa8a97":"markdown","dbe774aa":"markdown","e5a455a3":"markdown","90170e10":"markdown","2190f216":"markdown","626cea05":"markdown","05fead67":"markdown","ab89d850":"markdown","cfcf16e5":"markdown","cf710bdf":"markdown","2ef3b8d3":"markdown","cd4578ae":"markdown","1308ed1d":"markdown","dc3e5d25":"markdown","75155678":"markdown","a2fee80c":"markdown","8a2b8979":"markdown","d721fcbf":"markdown","5da8f2d4":"markdown","25df4a60":"markdown","209ec5d1":"markdown","7010f69d":"markdown","f5e70c06":"markdown","95d2dc20":"markdown","92d26c0d":"markdown","f139cd57":"markdown","3783628f":"markdown","c9cf6977":"markdown","cbe8a15c":"markdown","575a1bae":"markdown","6e99d5ca":"markdown","eeec222c":"markdown","bc1ba13f":"markdown","8957623b":"markdown"},"source":{"9c025bba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ed8a1a94":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]\n\n","88743030":"train_df.columns","4b814836":"train_df.head()","8ff13dd1":"train_df.describe()","342219bd":"train_df.info()","c65fe26b":"def bar_plot(variable):\n    \n    # get feature \n    \n    var = train_df[variable]\n    \n    # count number of categorical variable\n    \n    varValue = var.value_counts()\n    \n    # visualize\n    \n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))\n    \n    ","6f59eb38":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"Cabin\", \"Name\", \"SibSp\", \"Parch\"]\n\nfor c in category1:\n    bar_plot(c)","25239860":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\n\nfor c in category2:\n    \n    print(\"{} \\n\".format(train_df[c].value_counts()))","edef552d":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(format(variable))\n    plt.show()\n    ","cab0526f":"numericVar = [\"Fare\", \"Age\",\"PassengerId\"]\n\nfor n in numericVar:\n    plot_hist(n)\n    ","1932d469":"# Pclass vs Survived\n\ntrain_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"],as_index= False).mean().sort_values(by=\"Survived\",ascending = False)","fa937fc4":"# Sex vs Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","044b3ee9":"# SibSp vs Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","15bb3400":"# Parch vs Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","a63aca1b":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        \n        # 1st quartile\n        \n        Q1 = np.percentile(df[c],25)\n        \n        # 3rd quartile \n        \n        Q3 = np.percentile(df[c],75)\n        \n        # IQR\n        \n        IQR = Q3 - Q1\n        \n        # Outtlier step\n        \n        outlier_step = IQR * 1.5\n        \n        # detect outlier and their indeces\n        \n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        \n        # store indeces\n        \n        outlier_indices.extend(outlier_list_col)\n        \n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v>2) #ikiden fazlaysa\n    return multiple_outliers","380144cc":"train_df.loc[detect_outliers(train_df,[\"Age\", \"SibSp\", \"Parch\",\"Fare\"])]","5122433b":"# drop outliers\n\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\", \"SibSp\", \"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","dbe55490":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop=True)","7dbc8f54":"train_df.columns[train_df.isnull().any()]","bee93902":"train_df.isnull().sum()","5e43398e":"train_df[train_df[\"Embarked\"].isnull()]","bea15b2f":"train_df.boxplot(column=\"Fare\", by = \"Embarked\")\nplt.show()","0b8af319":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"c\")\n","b5a4454d":"train_df[train_df[\"Fare\"].isnull()]","ca202390":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))\n","bfca41d4":"train_df[train_df[\"Fare\"].isnull()]","d0b5e153":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\") # Korelasyonuna bakmak i\u00e7in corr methodunu \u00e7a\u011f\u0131r\u0131yoruz. \nplt.show()","337edc32":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","d796c4aa":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","107f49e0":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","e7affbcd":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","be2cd131":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","bd985896":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","32af4cd2":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","8373298d":"train_df[train_df[\"Age\"].isnull()]","c8ce7c9d":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()\n","99951dc0":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","f3d47834":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","16e8b159":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","ba7e0906":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","6ee2fcb8":"train_df[train_df[\"Age\"].isnull()]","78ff656b":"train_df[\"Name\"].head(10)","192e530d":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","224185d4":"train_df[\"Title\"].head(10)","9268e012":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()\n","c167406c":"# convert to categorical type\n\n\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)\n","753ec4f2":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","8ea6eb15":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","4632d261":" train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","1ffa8c30":"train_df.head()","863a53ec":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","818aefd3":"train_df.head()","b9d92260":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","4f3150b0":"train_df.head()","bd08ece7":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()\n","d00ffd68":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","7e6bd764":"train_df.head(10)","62e5512a":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","793c7ad4":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","b4f97afa":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","d64e99b9":"train_df[\"Embarked\"].head()","ee97ea03":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","a8c62f3b":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","6c925e61":"train_df[\"Ticket\"].head(20)","bd4c7240":"a = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","90c575b6":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","ecd860cd":"train_df[\"Ticket\"].head(20)","531a4c57":"train_df.head()","57cfe1a7":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","3a6ef7ce":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","4d7d8ae6":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","a0c06f96":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","44a7cbfb":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","00bf5f60":"train_df.columns","13780f29":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","d68ad9a2":"train_df_len","8489e44e":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)\ntest.head()","61000c6a":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","6ad3a548":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","14cf8d45":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","60b64d99":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])\n","c5273070":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","75f57ece":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train, y_train)\nprint(\"KNN score (Train): {0:.2}\".format(neigh.score(X_train, y_train)))\nprint(\"KNN score (Test): {0:.2}\".format(neigh.score(X_test, y_test)))","0149cde8":"from sklearn import svm\nsvclass = svm.SVC(gamma='scale')\nsvclass.fit(X_train, y_train) \nprint(\"SVM score (Train): {0:.2}\".format(svclass.score(X_train, y_train)))\nprint(\"SVM score (Test): {0:.2}\".format(svclass.score(X_test, y_test)))","5eb3b4f4":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators=100,\n                                criterion='gini',\n                                max_depth=5,\n                                min_samples_split=10,\n                                min_samples_leaf=5,\n                                random_state=0)\nX_train.head()\nforest.fit(X_train, y_train)\nprint(\"Random Forest score (Train): {0:.2}\".format(forest.score(X_train, y_train)))\n<a id = \"22\"><\/a>print(\"Random Forest score (Test): {0:.2}\".format(forest.score(X_test, y_test)))","93102f13":"from sklearn import tree\ndt = tree.DecisionTreeClassifier()\ndt = dt.fit(X_train, y_train)\nprint(\"Decision Tree score (Train): {0:.2}\".format(dt.score(X_train, y_train)))\nprint(\"Decision Tree score (Test): {0:.2}\".format(dt.score(X_test, y_test)))","86c6eba0":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","75bc68df":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\n\ndef f(x):\n    \"\"\" function to approximate by polynomial interpolation\"\"\"\n    return x * np.sin(x)\n\n\n# generate points used to plot\nx_plot = np.linspace(0, 10, 100)\n\n# generate points and keep a subset of them\nx = np.linspace(0, 10, 100)\nrng = np.random.RandomState(0)\nrng.shuffle(x)\nx = np.sort(x[:20])\ny = f(x)\n\n# create matrix versions of these arrays\nX = x[:, np.newaxis]\nX_plot = x_plot[:, np.newaxis]\n\ncolors = ['teal', 'yellowgreen', 'gold']\nlw = 2\nplt.plot(x_plot, f(x_plot), color='cornflowerblue', linewidth=lw,\n         label=\"ground truth\")\nplt.scatter(x, y, color='navy', s=30, marker='o', label=\"training points\")\n\nfor count, degree in enumerate([3, 4, 5]):\n    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n    model.fit(X, y)\n    y_plot = model.predict(X_plot)\n    plt.plot(x_plot, y_plot, color=colors[count], linewidth=lw,\n             label=\"degree %d\" % degree)\n\nplt.legend(loc='lower left')\n\nplt.show()\n","92f81b4a":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","00677f6d":"First class passengers are older than second, and second is older than third class.","c4b6ba13":"## Pclass -- Survived -- Age","d34bfe1b":"* Those who have more SibSp have less chance of survival.\n* if having 0, 1, 2 SibSp,more chance to survive.\n","6c28f96c":"<a id = \"37\"><\/a>\n## Ensemble Modeling","7737d255":"<a id = '9'><\/a>\n\n## Find Missing Value","90b00e26":"* Small familes have more chance to survive than large families.","553fb635":"<a id = \"30\"><\/a>\n## Train - Test Split","2d6d3441":"<a id = \"36\"><\/a>\n## Decision Tree","8cf6e842":"<a id = '7'><\/a>\n# Outlier Detection","d7f5312e":"<a id = \"15\"><\/a>\n## Pclass -- Survived","b2032d61":"<a id = \"28\"><\/a>\n## Drop Passenger ID and Cabin","2043edcc":"<a id = \"31\"><\/a>\n## Simple Logistic Regression","c4ceddf4":"<a id = \"32\"><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n#### We will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","6df90166":"<a id = \"33\"><\/a>\n## KNN Classifier","fb61c0c5":"* Small families have more chance to survive.\n* There is std in survival of passenger with parch = 3","663e5bca":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","6098528a":"* Female passengers have much better survival rate than males.\n* males have better surv\u015fval rate in pclass 3 in C.\n* embarked and sex will be used in training.","38aa8a97":"<a id = '8'><\/a>\n# Missing Value\n\n* Find Missing Value\n* Fill Missing Value","dbe774aa":"<a id = \"13\"><\/a>\n## SibSp -- Survived","e5a455a3":"<a id = \"26\"><\/a>\n## Pclass","90170e10":"<a id= '4'><\/a>\n## Categorical Variable","2190f216":"<a id = \"29\"><\/a>\n# Modeling","626cea05":"<a id = \"22\"><\/a>\n## Family Size","05fead67":"<a id = '1'> <\/a>\n\n# Load and Check Data","ab89d850":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass.","cfcf16e5":"<a id = \"24\"><\/a>\n## Embarked","cf710bdf":"* Those who make high payments have a higher survival rate.","2ef3b8d3":"<a id = \"21\"><\/a>\n## Name -- Title","cd4578ae":"<a id = \"20\"><\/a>\n# Feature Engineering","1308ed1d":"<a id = \"27\"><\/a>\n## Sex","dc3e5d25":"<a id = '6'><\/a>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","75155678":"<a id = \"17\"><\/a>\n## Embarked -- Sex -- Pclass -- Survived","a2fee80c":"<a id = '12'><\/a>\n## Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","8a2b8979":"<a id = \"38\"><\/a>\n### Polynomial interpolation","d721fcbf":"Missing Value bulmadan \u00f6nce train ve test dataframelerini yukar\u0131dan a\u015fa\u011f\u0131 birle\u015ftiriyoruz.","5da8f2d4":"<a id = \"35\"><\/a>\n## Random Forest Classifier","25df4a60":"# Introduction\n\n> This kernel about one of the most notorious shipwrecks in the history. The Titanic sunk on April 15, 1912. Titanic carried 2224 people. 1514 people died in the icy waters. \n\n<font color = 'red'>\n    \nContent:\n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n   * [Univariate Variable Analysis](#3)\n     * [Categorical Variable](#4)\n       * [Numerical Variable](#5)     \n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n   * [Find Missing Value](#9)\n     * [Fill Missing Value](#10)\n6. [Visualization](#11)\n   * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n     * [SibSp -- Survived](#13) \n       * [Parch -- Survived](#14)\n         * [Pclass -- Survived](#15)\n           * [Age -- Survived](#16)\n             * [Embarked -- Sex -- Fare -- Survived](#17)\n               * [Fill Missing: Age Feature](#18)\n7. [Feature Engineering](#20)\n   * [Name -- Title](#21)\n     * [Family -- Size](#22)\n       * [Embarked](#23)\n         * [Ticket](#24)\n           * [Pclass](#25)\n             * [Sex](#26)\n               * [Drop Passenger ID and Cabin](#27)\n8. [Modelling](#28)\n   * [Train - Test Split](#29)\n     * [Simple Logistic Regression](#30)\n       * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#31)\n         * [Ensemble Modeling](#32)\n           * [KNN](#33)\n             * [Support Vector Machines](#34)\n               * [Random Forest Classifier](#35)\n                 * [Decision Tree](#36)\n                   * [Prediction and Submission](#37)\n                     * [Polynomial interpolation](#38)\n         ","209ec5d1":"<a id = '2'><\/a>\n# Variable Description\n\n1. PassengerId: unique id number to each passenger\n2. Survived: passenger survive(1), died(2)\n3. Pclass: passenger class\n4. Name: passenger's name\n5. Sex: passenger's gender\n6. Age: passenger's age\n7. SibSp: number of siblings\/spouses\n8. Parch: number of parents\/children\n9. Ticket: ticket number\n10. Fare: amount of money spent on ticket\n11. Cabin: cabin category\n12. Embarked: part where passenger embarked(C = Cherbourg, Q = Queenstown, S = Southampton) ","7010f69d":"<a id = \"18\"><\/a>\n## Embarked -- Sex -- Fare -- Survived","f5e70c06":"<a id = \"25\"><\/a>\n## Ticket","95d2dc20":"<a id = \"19\"><\/a>\n## Fill Missing: Age Feature","92d26c0d":"<a id = \"14\"><\/a>\n## Parch -- Survived","f139cd57":"<a id = '3' > <\/a>\n# Univariate Variable Analysis\n\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Sibsp, Parch\n* Numerical Variable: Fare, Age, PassengerId","3783628f":"<a id = '10'><\/a>\n\n## Fill Missing Value\n* Embarked has 2 missing value.\n* Fare has 1 missing value.","c9cf6977":"<a id = '5'> <\/a>\n\n## Numerical Variable","cbe8a15c":"* float64(2) : Age, Fare\n* int64(5): PassengerId, Survived, Pclass, SibSp, Parch\n* object(5): Name, Sex, Ticket, Cabin, Embarked","575a1bae":"* Sex is not informative for age prediction","6e99d5ca":"<a id = \"39\"><\/a>\n## Prediction and Submission","eeec222c":"<a id = '11'><\/a>\n# Visualization","bc1ba13f":"<a id = \"16\"><\/a>\n## Age -- Survived","8957623b":"<a id = \"34\"><\/a>\n## Support Vector Machines (Support Vector Classifier)"}}