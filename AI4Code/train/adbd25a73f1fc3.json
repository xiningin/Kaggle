{"cell_type":{"28018fc7":"code","b88a18a3":"code","3b42c705":"code","8af83bfe":"code","9397a3e8":"code","4cc9f1bb":"code","4f361fce":"code","a206f1a1":"code","4e05865d":"code","f442e93f":"code","9085581a":"code","72d2401f":"code","2eaddda2":"code","cb03af92":"code","5588672a":"code","c941e2fa":"code","924a2c7f":"code","bfb5366e":"code","7923a820":"code","dfb260a9":"code","5d732db7":"code","7563c058":"code","8c5ff4e8":"code","ff1a98dd":"code","8350ca41":"code","add59c48":"code","042b718d":"code","15f2c77b":"code","22db11b3":"markdown"},"source":{"28018fc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b88a18a3":"#Importing the necessary libraries \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"darkgrid\")","3b42c705":"#Loading the Titanic Datasets \n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf=train.copy()\ndf.head()","8af83bfe":"df.info()","9397a3e8":"df.isnull().sum()","4cc9f1bb":"# Look at numeric and categorical values separately\n\ndf_num = train[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\ndf_cat = train[[\"Survived\", \"Pclass\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]]","4f361fce":"df_num.hist(figsize=(20,15)) ","a206f1a1":"plt.figure(figsize=(20,10)) \nsns.heatmap(df.corr(),annot=True)","4e05865d":"df.corr()","f442e93f":"sns.pairplot(df, hue='Survived', vars=  [[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]],height=4,aspect=2)","9085581a":"df.head()","72d2401f":"df_cat.columns.tolist()","2eaddda2":"for i in ['Pclass', 'Sex','Embarked']:\n    sns.countplot(x=i, data=df, palette='hls', hue='Survived')\n    plt.xticks(rotation=45)\n    plt.show()\n","cb03af92":"df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)","5588672a":"print(df.columns)\nprint(df_num.columns)\nprint(df_cat.columns)","c941e2fa":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\n\nnum_attribs = ['Age', 'SibSp', 'Parch', 'Fare']\ncat_attribs = [ 'Pclass', 'Sex','Embarked']\n\n\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", StandardScaler(), num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])","924a2c7f":"df['Age'] = SimpleImputer(strategy='mean').fit_transform(df[['Age']])","bfb5366e":"df['Embarked'] = SimpleImputer(strategy='constant',fill_value='S').fit_transform(df[['Embarked']])","7923a820":"X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n       'Embarked']]\ny= df['Survived']\n\nX = full_pipeline.fit_transform(X)\nprint(X.shape)","dfb260a9":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold","5d732db7":"def larger_model():\n # create model\n km = Sequential()\n km.add(Dense(X.shape[1], input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n km.add(Dense(35, kernel_initializer='normal', activation='relu'))\n km.add(Dense(25, kernel_initializer='normal', activation='relu'))\n km.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n # Compile model\n km.compile(loss='binary_crossentropy', optimizer='adam')\n return km\n\n# evaluate model with standardized dataset\nestimator = KerasRegressor(build_fn=larger_model, epochs=100, batch_size=5, verbose=1)\n#kfold = KFold(n_splits=5)\n#results = cross_val_score(estimator, X, y, cv=kfold)\n#print(\"Baseline: %.2f (%.2f) \" % (results.mean(), results.std()))","7563c058":"estimator.fit(X,y)","8c5ff4e8":"test_data = test.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1)","ff1a98dd":"test_data['Age'] = SimpleImputer(strategy='mean').fit_transform(test_data[['Age']])\ntest_data['Fare'] = SimpleImputer(strategy='mean').fit_transform(test_data[['Fare']])","8350ca41":"test_data = full_pipeline.fit_transform(test_data)\nprint(test_data.shape)","add59c48":"test['Survived'] = estimator.predict(test_data)\n#solution = test[['PassengerId', 'Survived']]\ntest.info()","042b718d":"test['Survived'] = test['Survived'].apply(lambda x: round(x,0)).astype('int')\ntest.head()","15f2c77b":"solution = test[['PassengerId', 'Survived']]\nsolution.to_csv(\"titanic_solution.csv\", index=False)","22db11b3":"# Hi,fellow kagglers. This is one of my first notebook here in kaggle. I demonstrated the use of a simple Keras Regressor(Neural network) in solving this classic Titanic problem.\n \n#           The Data Preparation is same just like other ML models. I imputed the null values and One hot encoded the categorical values.Also I have normalised the dtaa before feeding it to the neural net.Any suggestions are welcome , actually I am looking forward to your hacks to improve the model as well as myself."}}