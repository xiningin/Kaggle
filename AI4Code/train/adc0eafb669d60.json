{"cell_type":{"3fa1d400":"code","9fcdc291":"code","29571b30":"code","5a3c76f9":"code","88942925":"code","2e9f8746":"code","4c2da0b2":"code","22dda65f":"code","999ae781":"code","c1109229":"code","70d687c7":"code","df411e7a":"code","41c33bad":"code","f7d5166e":"code","808048b9":"code","87be97b1":"code","cf8bf947":"code","d22dd389":"code","39e996ca":"code","79d16fa1":"code","b55d750f":"code","73519d2e":"code","4c43924e":"code","493b574d":"code","e28d9bff":"code","35fa3b27":"code","7a9fba90":"code","576623ae":"code","d3829a61":"code","79e599ad":"code","f66213a4":"code","52ec9d52":"code","480511ee":"code","5dac3c69":"code","e01b8769":"code","ace88b55":"code","2adb767e":"code","675b8fe3":"code","d60b11fd":"code","d60c36e5":"code","5bf03240":"markdown","80792539":"markdown","e33c14dc":"markdown","d68c7fc0":"markdown","15fb9b0c":"markdown","d4264b79":"markdown"},"source":{"3fa1d400":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9fcdc291":"sample_submission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')\ntrain_targets_scored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\ntrain_features = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntest_features = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')","29571b30":"import matplotlib.pyplot as plt\n%matplotlib inline","5a3c76f9":"train_features.shape","88942925":"train_features.head()","2e9f8746":"## Checking there is mistakes\ntrain_features.sig_id.nunique()","4c2da0b2":"train_features.cp_type.value_counts()","22dda65f":"train_features.cp_time.value_counts()","999ae781":"train_features.cp_dose.value_counts()","c1109229":"train_targets_scored.head()","70d687c7":"train_targets_scored.sum()[1:].sort_values()","df411e7a":"train_features[:1]","41c33bad":"gs = train_features[:1][[col for col in train_features.columns if 'g-' in col]].values.reshape(-1, 1)","f7d5166e":"plt.plot(gs)","808048b9":"plt.plot(sorted(gs))","87be97b1":"train_features['g-0'].plot(kind='hist')","cf8bf947":"train_features['c-0'].plot(kind='hist')","d22dd389":"train_features = pd.concat([train_features, pd.get_dummies(train_features['cp_time'], prefix='cp_time')], axis=1)\ntrain_features = pd.concat([train_features, pd.get_dummies(train_features['cp_dose'], prefix='cp_dose')], axis=1)\ntrain_features = pd.concat([train_features, pd.get_dummies(train_features['cp_type'], prefix='cp_type')], axis=1)\ntrain_features = train_features.drop(['cp_type', 'cp_time', 'cp_dose'], axis=1)\ntrain_features.head()","39e996ca":"import torch\nimport pandas as pd\nimport torch.nn as nn\n\nclass MoaDataset:\n    def __init__(self, dataset, targets):\n        self.dataset = dataset\n        self.targets = targets\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, idx):\n        return {\n            \"x\" : torch.tensor(self.dataset[idx, :], dtype=torch.float),\n            \"y\" : torch.tensor(self.targets[idx, :], dtype=torch.float)\n        }","79d16fa1":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(num_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.3),\n            nn.PReLU(),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.3),\n            nn.PReLU(),\n            nn.Linear(1024, num_targets)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n","b55d750f":"!pip install pytorch-lightning","73519d2e":"import pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split","4c43924e":"class MoaDataModule(pl.LightningDataModule):\n    def __init__(self, hparams, data, targets):\n        super().__init__()\n        self.hparams = hparams\n        self.data = data\n        self.targets = targets\n        \n    def preprare_data(self):\n        ## For prepraring the data like downlaoding and all. Here we are not using it.\n        pass\n    \n    def setup(self, stage=None):\n        train_data, valid_data, train_targets, valid_targets = train_test_split(self.data, self.targets, \\\n                                                                                test_size=0.1, random_state=100)\n        self.train_dataset = MoaDataset(dataset=train_data.iloc[:,1:].values,\n                                        targets=train_targets.iloc[:, 1:].values)\n        self.valid_dataset = MoaDataset(dataset=valid_data.iloc[:,1:].values,\n                                        targets=valid_targets.iloc[:, 1:].values)\n        \n    def train_dataloader(self):\n        train_loader = torch.utils.data.DataLoader(\n            self.train_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=True)\n        return train_loader\n        \n    def val_dataloader(self):\n        valid_loader = torch.utils.data.DataLoader(\n            self.valid_dataset,\n            batch_size=1024,\n            num_workers=0,\n            shuffle=False)\n        return valid_loader\n    \n    def test_dataloader(self):\n        pass","493b574d":"class LitMoA(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(LitMoA, self).__init__()\n        self.hparams = hparams\n        self.model = model\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n    def forward(self, x):\n        return self.model(x)\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                              patience=3,\n                                                              threshold=0.00001,\n                                                              mode='min',\n                                                              verbose=True)\n        \n        return ([optimizer],\n               [{\"scheduler\" : scheduler, \"interval\" : \"epoch\", \"monitor\":\"valid_loss\"}])\n    \n    def training_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        \n        logs = {'train_loss' : loss}\n        return {\"loss\" : loss, \"log\" : logs, \"progress_bar\":logs}\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'train_loss' : avg_loss}\n        return {\"log\" : logs, \"progress_bar\" : logs}\n    \n    def validation_step(self, batch, batch_idx):\n        data = batch['x']\n        target = batch['y']\n        out = self(data)\n        loss = self.criterion(out, target)\n        \n        logs = {'valid_loss' : loss}\n        return {\"loss\" : loss, \"log\" : logs, \"progress_bar\":logs}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        logs = {'valid_loss' : avg_loss}\n        return {\"log\" : logs, \"progress_bar\" : logs}\n    \n\n    ","e28d9bff":"trainer = pl.Trainer(gpus=1,\n                    max_epochs=5,\n                    weights_summary='full')","35fa3b27":"model = Model(879, 206)   \nmodel = LitMoA(hparams={}, model=model)\ndm = MoaDataModule(hparams={}, data=train_features, targets=train_targets_scored)","7a9fba90":"trainer.fit(model, dm)","576623ae":"test_features = pd.concat([test_features, pd.get_dummies(test_features['cp_time'], prefix='cp_time')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_dose'], prefix='cp_dose')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_type'], prefix='cp_type')], axis=1)\ntest_features = test_features.drop(['cp_type', 'cp_time', 'cp_dose'], axis=1)\ntest_features.head()","d3829a61":"import torch\nimport pandas as pd\nimport torch.nn as nn\n\nclass Test_MoaDataset:\n    def __init__(self, dataset):\n        self.dataset = dataset\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, idx):\n        return {\n            \"x\" : torch.tensor(self.dataset[idx, :], dtype=torch.float)\n        }","79e599ad":"test_dataset = Test_MoaDataset(dataset=test_features.iloc[:, 1:].values)","f66213a4":"test_loader = torch.utils.data.DataLoader(\n                test_dataset,\n                batch_size=1024,\n                num_workers=0,\n                shuffle=False)","52ec9d52":"predictions = np.zeros((test_features.shape[0], 206))\ninference_model = model.model\ninference_model.eval()\nfor ind, batch in enumerate(test_loader):\n    p = inference_model(batch['x'])[0].detach().cpu().numpy()\n    predictions[ind * 1024 : (ind+1)*2014] = p","480511ee":"predictions","5dac3c69":"test_features1 = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\")\ns = pd.DataFrame({\"sig_id\" : test_features1[\"sig_id\"].values})","e01b8769":"s","ace88b55":"for col in train_targets_scored.columns[1:].tolist():\n    s[col]=0","2adb767e":"s.loc[:, train_targets_scored.columns[1:]] = predictions\ns.head()","675b8fe3":"s.loc[s['sig_id'].isin(test_features1.loc[test_features1['cp_type']=='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] =0","d60b11fd":"s","d60c36e5":"s.to_csv('submission.csv', index=False)","5bf03240":"### Model","80792539":"# Mechanism of Actions Predictions","e33c14dc":"## Baseline Implementation","d68c7fc0":"### Creating OHE for non-numerical features and dropping the non-numerical features","15fb9b0c":"### Dataset","d4264b79":"## EDA"}}