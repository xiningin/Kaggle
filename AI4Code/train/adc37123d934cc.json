{"cell_type":{"f7e6622b":"code","7a6ccc09":"code","eb077d4c":"code","ac879777":"code","96ff3d31":"code","4646dfcb":"code","18235e39":"code","411d5b93":"code","5c773339":"code","f78f41da":"code","16d7b040":"code","ac35817e":"code","af180f12":"code","41524f49":"code","91d7eb66":"code","5949c923":"code","9a5ae202":"code","d5c251a5":"code","c790f353":"code","fcc4cbd9":"code","bdc94713":"code","817f400a":"code","89addfbb":"code","2913d507":"code","9555aec3":"code","7006a049":"code","4eeab997":"code","a94d657a":"code","04065785":"code","8bf37db2":"code","81c1b044":"code","24eab4f5":"code","1ab4e198":"code","e8156cb7":"code","c9ea99e2":"code","4cc51537":"code","e023e59c":"code","9e3b0096":"code","36f68697":"code","c74c12b5":"code","78640918":"code","06772e83":"code","6d076b26":"code","e6b5f9f2":"code","2c110e26":"code","4e66f130":"code","821dd571":"code","15fd131e":"code","e3820d04":"code","b9a5cd88":"code","fab28648":"markdown","eb6c5526":"markdown","05773bcc":"markdown","4f24d9f1":"markdown","8f83bb21":"markdown","b2332458":"markdown","297537e1":"markdown","a19391fb":"markdown","48ad5d3f":"markdown","376a67a5":"markdown"},"source":{"f7e6622b":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","7a6ccc09":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom PIL import Image\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder","eb077d4c":"from skmultilearn.model_selection import IterativeStratification","ac879777":"project_name = 'protein_classifier'","96ff3d31":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\nTRAIN_DIR = DATA_DIR + '\/train'\nTEST_DIR = DATA_DIR + '\/test'\n\nTRAIN_CSV = DATA_DIR + '\/train.csv'\nTEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'","4646dfcb":"!head \"{TRAIN_CSV}\"","18235e39":"!head '{TEST_CSV}'","411d5b93":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()","5c773339":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","f78f41da":"def encode_label(label):\n    \"\"\"Encodes the multi labels into a vector(tensor).\"\"\"\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    \"\"\"Decodes a tensor into a sequence of labels.\"\"\"\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","16d7b040":"encode_label('2 4 5')","ac35817e":"decode_target(torch.tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0.]))","af180f12":"decode_target(torch.tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0.]), text_labels=True)","41524f49":"class HumanProteinDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['Image'], row['Label']\n        img_fname = self.root_dir + \"\/\" + str(img_id) + \".png\"\n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        return img, encode_label(img_label)","91d7eb66":"transform = transforms.Compose([transforms.ToTensor()])\ndataset = HumanProteinDataset(TRAIN_CSV, TRAIN_DIR, transform=transform)","5949c923":"len(dataset)","9a5ae202":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', decode_target(target, text_labels=True))","d5c251a5":"show_sample(*dataset[0], invert=False)","c790f353":"show_sample(*dataset[0], invert=True)","fcc4cbd9":"torch.manual_seed(10)","bdc94713":"val_pct = 0.1\nval_size = int(val_pct * len(dataset))\ntrain_size = len(dataset) - val_size","817f400a":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","89addfbb":"batch_size = 64","2913d507":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","9555aec3":"def show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break","7006a049":"show_batch(train_dl, invert=False)","4eeab997":"train_df.head()","a94d657a":"train_df['Label'].value_counts().head()","04065785":"train_df['Label'].value_counts().tail()","8bf37db2":"df = train_df.copy()","81c1b044":"df = df.set_index('Image').sort_index()","24eab4f5":"df['Label'] = df['Label'].apply(lambda x: x.split(' '))","1ab4e198":"df.head()","e8156cb7":"df = df.explode('Label')\ndf.head()","c9ea99e2":"df['Label'].value_counts()","4cc51537":"df = pd.get_dummies(df);df","e023e59c":"df = df.groupby(df.index).sum(); df.head()","9e3b0096":"df.columns = labels.keys() ; df.head()","36f68697":"X, y = df.index.values, df.values","c74c12b5":"k_fold = IterativeStratification(n_splits = 5, order=2)\n\nsplits = list(k_fold.split(X, y))","78640918":"splits[0][0].shape , splits[0][1].shape","06772e83":"df.tail(), len(df)","6d076b26":"splits[0][0], splits[0][1]","e6b5f9f2":"fold_splits = np.zeros(df.shape[0]).astype(int)\n\nfor i in range(5):\n    fold_splits[splits[i][1]] = i # Note the validation fold set#\n\ndf['Split'] = fold_splits","2c110e26":"df.tail(10)","4e66f130":"train_df = df[df['Split'] != 0]\nvalid_df = df[df['Split'] == 0]","821dd571":"train_df.head()","15fd131e":"valid_df.head()","e3820d04":"from pathlib import Path\nfrom tqdm.notebook import tqdm\nimport cv2\n\ntrain_set = set(Path(TRAIN_DIR).iterdir())\ntest_set = set(Path(TEST_DIR).iterdir())\nwhole_set = train_set.union(test_set)\n\nx_tot, x2_tot = [], []\nfor file in tqdm(whole_set):\n   img = cv2.imread(str(file), cv2.COLOR_RGB2BGR)\n   img = img\/255.0\n   x_tot.append(img.reshape(-1, 3).mean(0))\n   x2_tot.append((img**2).reshape(-1, 3).mean(0))","b9a5cd88":"#image stats\nimg_avr =  np.array(x_tot).mean(0)\nimg_std =  np.sqrt(np.array(x2_tot).mean(0) - img_avr**2)\nprint('mean:',img_avr, ', std:', np.sqrt(img_std))\nmean = torch.as_tensor(x_tot)\nstd =torch.as_tensor(x2_tot)","fab28648":"## Training & Validation sets","eb6c5526":"## DataLoader","05773bcc":"# Model","4f24d9f1":"Lets test the encode and decode methods.","8f83bb21":"## Distribution of Individual Classes","b2332458":"# Exploring Data","297537e1":"The textual labels are consolidated in a dictionary.","a19391fb":"This is a multi-label classification. Some images can have one or a list of labels.\ntrain.csv contains image id and its label(s) of the train dataset. Similarly, the submission.csv contains the image id and default label for the images in test dataset.","48ad5d3f":"# Distribution of combinations","376a67a5":"# Creating Datasets & Data Loaders"}}