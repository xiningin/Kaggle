{"cell_type":{"63f7191e":"code","ecf2ecfb":"code","47ad04bf":"code","c2bebb59":"code","9a8b668d":"code","e9014f4f":"code","e363226a":"code","a10d2877":"code","6c977880":"code","2e5fe950":"code","8bf00b61":"code","36d61f99":"code","0da96e54":"code","e857c0e0":"code","a89eec24":"code","742db67c":"code","2c268cf8":"code","feead98f":"code","2ef5f281":"code","43d0bf91":"code","1cebbb15":"code","20d96ae0":"code","11859ed9":"code","22b13960":"markdown","c7ae46ff":"markdown","48bc8528":"markdown","1addc3b9":"markdown","03d0c9ec":"markdown","cf49a176":"markdown"},"source":{"63f7191e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecf2ecfb":"df = pd.read_csv('\/kaggle\/input\/kyphosis-dataset\/kyphosis.csv')","47ad04bf":"df.head()","c2bebb59":"df.isnull().sum()","9a8b668d":"import seaborn as sns\nsns.heatmap(df.isnull());","e9014f4f":"sns.pairplot(df, hue='Kyphosis', palette='Set1');","e363226a":"from sklearn.model_selection import train_test_split","a10d2877":"X = df.drop('Kyphosis', axis=1)\ny = df['Kyphosis']","6c977880":"X.head()","2e5fe950":"y.head()","8bf00b61":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)","36d61f99":"from sklearn.tree import DecisionTreeClassifier","0da96e54":"#make a object of the model\ndtree = DecisionTreeClassifier()","e857c0e0":"#now the important part are fit the train part of data\ndtree.fit(X_train, y_train)","a89eec24":"predictions = dtree.predict(X_test)","742db67c":"from sklearn.metrics import classification_report, confusion_matrix","2c268cf8":"#This part will print the short report where we will see the precision, recall and f1-score results and also will see the accuracy\nprint(classification_report(y_test, predictions))","feead98f":"print(confusion_matrix(y_test, predictions))","2ef5f281":"from sklearn.ensemble import RandomForestClassifier","43d0bf91":"rfc = RandomForestClassifier(n_estimators=50)\nrfc.fit(X_train, y_train)","1cebbb15":"rfc_pred = rfc.predict(X_test)","20d96ae0":"print(confusion_matrix(y_test, rfc_pred))","11859ed9":"print(classification_report(y_test, rfc_pred))","22b13960":"## Prediction and Evaluation\nIn this part we predict our model to see the accuracy of model and its performance","c7ae46ff":"## Train Test Split \nThe main and most important part of Machine Learning Model are splitting the data into train and test part.","48bc8528":"## Decision Tree\nNow apply Decision Tree Model","1addc3b9":"## Random Forest\nNow we will appy Random Forest Model.","03d0c9ec":"let's see null values with headmap diagram","cf49a176":"lets see the number data with respect to Kyphosis with the help of pairplot"}}