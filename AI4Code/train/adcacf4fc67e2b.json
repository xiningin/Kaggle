{"cell_type":{"3fd0ff91":"code","d430e80b":"code","733e0729":"code","f206922f":"code","8bd4b2c9":"code","577ee163":"code","87a77f19":"code","d51e4e71":"code","8cf8c642":"code","c4077252":"code","2b09534f":"code","b10b8475":"code","70b1875c":"code","cce96aa2":"code","273a0ff3":"code","f68ab244":"code","165016a6":"code","cedd1f62":"code","355a8ba2":"code","894f8a0c":"code","a1de163b":"code","c78f8626":"code","8329e828":"code","85177f41":"code","8bb4b7bf":"code","0aa32cfc":"code","7595ba25":"code","d3141a94":"code","9e8be41b":"code","f8b0da20":"code","924eb1b1":"code","1fa4cfec":"markdown","a2c33df6":"markdown","1558035c":"markdown","932f6aa6":"markdown","80f8577d":"markdown","25f350da":"markdown","54271d6c":"markdown","aa19c771":"markdown","36b2e166":"markdown","05171eac":"markdown"},"source":{"3fd0ff91":"import os\nimport json\nimport pandas as pd\nimport numpy as np\nimport datetime as datetime\nimport matplotlib.pyplot as plt\nfrom PIL import Image","d430e80b":"# setup the directories\nDATA_DIR = '..\/input\/iwildcam2021-fgvc8\/'\nTRAIN_DIR = DATA_DIR + 'train\/'\nTEST_DIR = DATA_DIR + 'test\/'\nMETADATA_DIR = DATA_DIR + 'metadata\/'\n\n# load the megadetector results\nmegadetector_results = json.load(open(METADATA_DIR + 'iwildcam2021_megadetector_results.json'))\n#megadetector_results['images'][:2]\n\n# load train images annotations\ntrain_info = json.load(open(METADATA_DIR + 'iwildcam2021_train_annotations.json'))\n# split json into several pandas dataframes\ntrain_annotations = pd.DataFrame(train_info['annotations'])\ntrain_images = pd.DataFrame(train_info['images'])\ntrain_categories = pd.DataFrame(train_info['categories'])\n\n# load test images info\ntest_info = json.load(open(METADATA_DIR + 'iwildcam2021_test_information.json'))\n# split json into several pandas dataframes\ntest_images = pd.DataFrame(test_info['images'])\n#test_categories = pd.DataFrame(test_info['categories'])","733e0729":"train_info.keys()","f206922f":"train_images.keys()","8bd4b2c9":"train_annotations.keys()","577ee163":"train_categories.keys()\ntrain_categories","87a77f19":"test_info.keys()","d51e4e71":"test_images.head()","8cf8c642":"#test_categories.head() #there is nothing like in the test json file, it is created for future ","c4077252":"print('Number of images in the train set is {}'.format(train_annotations.image_id.nunique()))\nprint('Number of images in the test set is {}'.format(test_images.file_name.nunique()))","2b09534f":"plt.pie([train_annotations.image_id.nunique(), test_images.file_name.nunique()], labels=['Train', 'Test'], autopct='%1.1f%%', \n           startangle=90, colors=['#fa4252', '#91bd3a'])\nplt.axis('equal')\nplt.title('Number of images in train and test sets', fontsize=14, color='violet')\nplt.show()","b10b8475":"print('The number of unique locations is {}'.format(train_images.location.nunique()))\nprint('The average number of images per location is {}'.format(train_images.groupby(by=['location']).id.count().mean()))\nprint('The minimum number of images per location is {}'.format(train_images.groupby(by=['location']).id.count().min()))\nprint('The maximum number of images per location is {}'.format(train_images.groupby(by=['location']).id.count().max()))","70b1875c":"plt.figure(figsize=(20,5))\nplt.hist(train_images.groupby(by=['location']).id.count(), bins=40, color='#91bd3a')\nplt.title('The distribution of the number of the images per location', fontsize=14)\nplt.show()","cce96aa2":"# convert datetimes to just dates\ndef to_date(datetime_str):\n    \"\"\"Convert datetime string to date.\"\"\"\n    # datetime string example: 2013-08-08 11:45:00.000\n    dt = datetime_str.split(' ')[0]\n    return dt\n    \ntrain_images['date'] = train_images.apply(lambda row: to_date(row.datetime), axis=1)\n# group by date\nimg_per_date = train_images.groupby(by=['date']).id.count()","273a0ff3":"print('The average number of images per day is {}'.format(img_per_date.mean()))\nprint('The maximum number of images per day is {}'.format(img_per_date.max()))\nprint('The minimum number of images per day is {}'.format(img_per_date.min()))","f68ab244":"train_images.keys()","165016a6":"# group by sequence id\nframes_per_sequence = train_images.groupby(by=['seq_id']).seq_frame_num.max()\n\nprint('The average number of frames is {}'.format(frames_per_sequence.mean()))\nprint('The minimum number of frames is {}'.format(frames_per_sequence.min()))\nprint('The maximum number of frames is {}'.format(frames_per_sequence.max()))","cedd1f62":"plt.hist(frames_per_sequence.values, bins=40, color='#91bd3a')\nplt.title('The distribution of the number of frames')\nplt.show()","355a8ba2":"print('The minimum width of the images is {}'.format(train_images.width.min()))\nprint('The maximum width of the images is {}'.format(train_images.width.max()))\nprint('The minimum height of the images is {}'.format(train_images.height.min()))\nprint('The maximum height of the images is {}'.format(train_images.height.max()))","894f8a0c":"# plot histograms to show the distribution of width and height values\nfig, axs = plt.subplots(1, 2, figsize=(15,7))\naxs[0].hist(train_images.width.values, bins=20, color = '#91bd3a')\naxs[0].set_title('Width distribution')\naxs[0].set_xlim(1000, 3000)\n\naxs[1].hist(train_images.width.values, bins=20, color = '#91bd3a')\naxs[1].set_title('Height distribution')\naxs[1].set_xlim(1000, 3000)\n\nplt.suptitle('Image Dimensions')\nplt.show()","a1de163b":"def get_first_category(img_id):\n    \"\"\"Find first the image category by id.\"\"\"\n    # get category id\n    category_id = train_annotations[train_annotations.image_id == img_id].category_id.values[0]\n    # get category name\n    category_name = train_categories[train_categories.id == category_id].name.values[0]\n    return category_id, category_name\n\ndef visualize_image_grid(rows, cols):\n    \"\"\"Visualize random grid of images with the first category.\"\"\"\n    filenames = train_images.file_name.unique()\n    \n    np.random.seed(42)\n    img_idx = np.random.randint(len(filenames), size=rows * cols)\n    \n    fig, axs = plt.subplots(rows, cols, figsize=(15,7))\n    \n    for r in range(rows):\n        for c in range(cols):\n            # get the image and image id\n            filename = filenames[img_idx[rows*r + c]]\n            img_id = filename.split('.')[0]\n            # get the category\n            category_id, category = get_first_category(img_id)\n            \n            img = Image.open(TRAIN_DIR + filename)\n            \n            axs[r,c].imshow(img)\n            axs[r,c].axis('off')\n            axs[r,c].set_title('{}:{}'.format(category_id, category))\n            \n    plt.suptitle('Train images', fontsize=16)\n    plt.show()","c78f8626":"visualize_image_grid(3, 3)","8329e828":"def visualize_cetagory(category_id, rows=3, cols=3, seed=42):\n    \"\"\"Function to visualize images of a specific category.\"\"\"\n    # filter by the category_id\n    copy = train_annotations[train_annotations.category_id == category_id]\n    # get the category name\n    category_name = train_categories[train_categories.id == category_id].name.values[0]\n    \n    # get random indices\n    np.random.seed(seed)\n    img_idx = np.random.randint(len(copy), size=rows * cols)\n    \n    # plot images\n    fig, axs = plt.subplots(rows, cols, figsize=(15,7))\n    \n    for r in range(rows):\n        for c in range(cols):\n            # get the image and image id\n            filename = copy.iloc[img_idx[rows*r + c]].image_id + '.jpg'\n            img_id = filename.split('.')[0]\n            \n            img = Image.open(TRAIN_DIR + filename)\n            \n            axs[r,c].imshow(img)\n            axs[r,c].axis('off')\n            axs[r,c].set_title('{}:{}'.format(category_id, category_name))\n            \n    plt.suptitle('Train images for {}:{}'.format(category_id, category_name), fontsize=16)\n    plt.show()","85177f41":"train_annotations['category_id']","8bb4b7bf":"visualize_cetagory(112) #any number for cateroy id","0aa32cfc":"# load train images annotations\ntrain_info = json.load(open(METADATA_DIR + 'iwildcam2021_train_annotations.json'))\n# split json into several pandas dataframes\ntrain_annotations = pd.DataFrame(train_info['annotations'])\ntrain_images = pd.DataFrame(train_info['images'])\ntrain_categories = pd.DataFrame(train_info['categories'])","7595ba25":"import collections\nimport seaborn as sns\n# Preperation for visualization\ndf_categories = pd.DataFrame(train_info[\"categories\"])\nlabels_id = [item[\"id\"] for item in train_info[\"categories\"]]\ncnt = collections.Counter([item[\"category_id\"] for item in train_info[\"annotations\"]])\ndf_categories_count = pd.DataFrame.from_dict(cnt, orient='index').reset_index()\ndf_categories_count = df_categories_count.rename(columns={'index':'id', 0:'count'})\n\ndf_categories_count = df_categories_count.merge(df_categories, on='id').sort_values(by=['count'], ascending=False)","d3141a94":"fig = plt.figure(figsize=(30, 4))\nax = sns.barplot(x=\"id\", y=\"count\",data=df_categories_count, order=labels_id)\nax.set(ylabel='count')\nax.set(ylim=(0,80000))\nplt.title('distribution of count per id in train')","9e8be41b":"import plotly.express as px\nfig = px.bar(df_categories_count, x=\"id\", y=\"count\", \n             title='distribution of count per id in train',\n             width=1400, height=400, color='id')\nfig.show()","f8b0da20":"df_categories_count.iloc[:10]","924eb1b1":"df_categories_count.iloc[-10:]\n","1fa4cfec":"Original Notebook: [https:\/\/www.kaggle.com\/aleksandradeis\/iwildcam-eda](http:\/\/)","a2c33df6":"# Image Dimensional Exploration","1558035c":"# Specific Image Category Visualization","932f6aa6":"# Analyze the number of sequences","80f8577d":"# Visualize images for top categories","25f350da":"# Location Data Exploration","54271d6c":"# Train Set Imnages Exploration","aa19c771":"The annotation data seems to be biased to some extent. To see the breakdown, let's look at the top 10 categories. Empty is the most, but annotations stating that animals are in the picture also seem to vary among the top 10.","36b2e166":"# Timeline for Captured Images","05171eac":"On the other hand, fewer categories have only about one sample. We need to be careful when splitting the dataset to train and validation data when training the model."}}