{"cell_type":{"9b5b9a65":"code","b3333b92":"code","91f3cbd4":"code","e3eaf112":"code","34899ce1":"code","cea32631":"code","df6902df":"code","466ec4fa":"code","1e254811":"code","2bad99bd":"code","686c323a":"code","dcb2b72a":"code","4bdcd5d0":"code","1179bf16":"code","7b6df14c":"code","465af7e9":"code","ecfcd311":"code","48091eb0":"code","b00fd2f7":"code","d5b559b3":"code","79b9d5e9":"code","5b389c5c":"code","5590bc26":"code","5e7e4ae8":"code","14d35bca":"code","745e8475":"code","6d372337":"code","b71150ba":"code","ad1c1648":"code","701be900":"code","55aee8d4":"code","7837ec96":"code","694bb884":"code","87fd7338":"code","fea9daa7":"code","f412cfa9":"code","074f51a1":"code","7da4b309":"code","e9821e9d":"code","7aaa9804":"code","1d439aaa":"code","38dae517":"code","711e6a97":"code","34517ebd":"code","643782ad":"code","64d16324":"code","9f55553f":"code","5cba42f1":"code","8430fb46":"code","cd3da7f5":"code","5612322f":"code","11164446":"markdown","20298eac":"markdown","0d1d5b06":"markdown","21a9c412":"markdown","bd81327d":"markdown","cf18baf2":"markdown","2114232c":"markdown","04ecbf72":"markdown","ed9ccb21":"markdown","1d4e8bd6":"markdown","44b988cc":"markdown","0a4056a2":"markdown","51ab0c91":"markdown","15f30788":"markdown","afaabf41":"markdown","00ec2309":"markdown","9a54614c":"markdown","8ad7ed1b":"markdown","3284afc0":"markdown","8bb9cd4a":"markdown","88b46dc8":"markdown","42d9b524":"markdown","be216160":"markdown","51d85a33":"markdown","95fd3c98":"markdown","4ea05ed1":"markdown","0387d20e":"markdown","de45e197":"markdown","413b742d":"markdown","b8e95205":"markdown","7dbb5521":"markdown","ff0fb47f":"markdown"},"source":{"9b5b9a65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\neps = np.finfo(float).eps\nfrom numpy import log2 as log\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3333b92":"df_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_learn = pd.read_csv('..\/input\/titanic\/train.csv')","91f3cbd4":"df_train = pd.concat([df_learn, df_test], axis=0).reset_index(drop=True)","e3eaf112":"df_train.info()","34899ce1":"df_train.describe()","cea32631":"print(df_train['Pclass'].unique())\nprint(df_train['Sex'].unique())\nprint(df_train['Embarked'].unique())","df6902df":"print(\"Pclass\\n\",df_train['Pclass'].value_counts())\nprint(\"Sex\\n\",df_train['Sex'].value_counts())\nprint(\"Embarked\\n\",df_train['Embarked'].value_counts())","466ec4fa":"df_train['Embarked'].replace(['S','C','Q'],[0,1,2], inplace=True)\ndf_train['Sex'].replace(['male','female'],[0,1],inplace=True)","1e254811":"sns.heatmap(df_train[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\",\"Embarked\", \"Survived\"]].corr(), annot = True)\nplt.show()","2bad99bd":"survived_by_Sex = df_train.groupby('Sex')['Survived'].mean()\nsurvived_by_Pclass = df_train.groupby('Pclass')['Survived'].mean()\nsurvived_by_Embarked = df_train.groupby('Embarked')['Survived'].mean()","686c323a":"fig, (axis1,axis2,axis3) = plt.subplots(1, 3, figsize=(16,6))\n\nax = survived_by_Sex.plot.bar(ax=axis1, color='#5975A4', title='Survival Rate by Sex', sharey=True)\nax.set_ylabel('Survival Rate')\nax.set_ylim(0.0,1.0)\nax = survived_by_Pclass.plot.bar(ax=axis2, color='#5F9E6E', title='Survival Rate by Pclass', sharey=True)\nax.set_ylim(0.0,1.0)\nax = survived_by_Embarked.plot.bar(ax=axis3, color='#B55D60', title='Survival Rate by Embarked', sharey=True)\nax.set_ylim(0.0,1.0)","dcb2b72a":"grouped_data = pd.concat(\n    [df_train.groupby(['Pclass', 'Sex', 'Embarked'])['Survived'].mean(),\n     df_train.groupby(['Pclass', 'Sex', 'Embarked'])['Survived'].count()],\n    axis=1)\ngrouped_data.columns = ['Survived', 'Count']\ngrouped_data","4bdcd5d0":"g = sns.catplot(\n    x='Sex', \n    y='Survived', \n    col='Embarked',\n    row='Pclass',\n    data=df_train,\n    margin_titles=True, \n    kind=\"bar\", \n    ci=None)","1179bf16":"df_Pclass_by_sex = df_train.groupby(['Pclass', 'Sex'])['Fare'].mean()\nax = df_Pclass_by_sex.plot.bar(figsize=(16,4), title='Fare Average by Class and Sex')\nax.set_ylabel('Average Fare')","7b6df14c":"df_Pclass_by_sex","465af7e9":"df_train_clean_embarked = df_train.dropna(subset=['Embarked'])\nembarked = df_train_clean_embarked.groupby('Embarked').mean()\nembarked['Count'] = df_train_clean_embarked['Embarked'].value_counts()\nembarked","ecfcd311":"fig, (axis1,axis2) = plt.subplots(1, 2, figsize=(14,6))\n\nsns.countplot(x='Embarked', data=df_train_clean_embarked, order=[0,1,2], ax=axis1)\nsns.barplot(x=embarked.index, y='Survived', data=embarked, order=[0,1,2], ax=axis2)","48091eb0":"df_train['Family'] = df_train['Parch'] + df_train['SibSp']","b00fd2f7":"df_train['Family'] = df_train['Family'].replace([0,1,2,3,4,5,6,7,8,9,10],[0,1,1,1,1,1,1,1,1,1,1])\nsurvived_by_family = df_train.groupby('Family')['Survived'].mean()\nax = survived_by_family.plot.bar(color='#5975A4', title='Survival Rate by Family Presence')\nax.set_ylabel('Survival Rate')\n","d5b559b3":"df_train.info()","79b9d5e9":"family_by_class = df_train.groupby('Pclass')['Family'].mean()\nfamily_by_class","5b389c5c":"family_by_sex = df_train.groupby('Sex')['Family'].mean()\nfamily_by_sex\n","5590bc26":"fig, (axis1,axis2) = plt.subplots(1,2, figsize=(16,6))\n\nax = family_by_class.plot.bar(ax=axis1, color='#5975A4', title='Family Presence by Class', sharey=True)\nax.set_ylabel('Average Family Presence')\nax.set_ylim(0.0,1.0)\nax = family_by_sex.plot.bar(ax=axis2, color='#5F9E6E', title='Family Presence by Sex', sharey=True)\nax.set_ylim(0.0,1.0)","5e7e4ae8":"df_train[df_train['Embarked'].isnull()]","14d35bca":"df_train[\"Embarked\"] = df_train[\"Embarked\"].fillna(1)","745e8475":"data_age_nan_index = df_train[df_train[\"Age\"].isnull()].index\nfor i in data_age_nan_index:\n    mean_age = df_train[\"Age\"][(df_train[\"Pclass\"]==df_train.iloc[i][\"Pclass\"]) & (df_train[\"Embarked\"]==df_train.iloc[i][\"Embarked\"]) & (df_train[\"Sex\"]==df_train.iloc[i][\"Sex\"])].mean()\n    df_train[\"Age\"].iloc[i] = mean_age","6d372337":"df_train.info()","b71150ba":"df_train[\"Fare\"] = df_train[\"Fare\"].fillna(np.mean(df_train[((df_train[\"Pclass\"]==2) & (df_train[\"Embarked\"]==0))][\"Fare\"]))\ndf_train[df_train[\"Fare\"].isnull()]","ad1c1648":"df_train['Age_Group']=pd.cut(df_train['Age'], 5)\ndf_train.groupby(['Age_Group'])['Survived'].mean().to_frame().style.background_gradient(cmap='winter')","701be900":"df_train['Age_Group'] = LabelEncoder().fit_transform(df_train['Age_Group'])","55aee8d4":"sns.catplot(x=\"Age_Group\", y =\"Survived\", data=df_train, kind=\"bar\", height=3)\nplt.show()","7837ec96":"df_train['Fare_Group']=pd.qcut(df_train['Fare'],3)\ndf_train.groupby(['Fare_Group'])['Survived'].mean().to_frame().style.background_gradient(cmap='winter')","694bb884":"df_train['Fare_Group'] = LabelEncoder().fit_transform(df_train['Fare_Group'])","87fd7338":"sns.catplot(x=\"Fare_Group\", y =\"Survived\", data=df_train, kind=\"bar\", height=3)\nplt.show()","fea9daa7":"sns.heatmap(df_train[[\"Cabin\",\"Pclass\",\"Embarked\",\"Sex\",\"Age\",\"Age_Group\",\"Fare_Group\",\"Family\", \"Survived\"]].corr(), annot = True)\nplt.show()","f412cfa9":"df_train.drop(labels=[\"SibSp\",\"Parch\",\"Cabin\",\"Fare\",\"Age\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace = True)\ndf_train.head()","074f51a1":"df_train['Embarked']=df_train['Embarked'].astype(int)","7da4b309":"#Generating the dummy attributes from the discrete values of attributes to elevate the data cleanliness\ndf_train = pd.get_dummies(df_train, columns=['Pclass'])\ndf_train = pd.get_dummies(df_train, columns=['Sex'])\ndf_train = pd.get_dummies(df_train, columns=['Embarked'])\ndf_train = pd.get_dummies(df_train, columns=['Family'])\ndf_train = pd.get_dummies(df_train, columns=['Age_Group'])\ndf_train = pd.get_dummies(df_train, columns=['Fare_Group'])","e9821e9d":"df_train.head()","7aaa9804":"df_train.info()","1d439aaa":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","38dae517":"df_train.info()","711e6a97":"test = df_train[len(df_learn):]\ntest.drop(labels=\"Survived\", axis=1, inplace=True)\n\ndf_train = df_train[:len(df_learn)]\n\nX_train = df_train.drop(labels = \"Survived\", axis=1)\ny_train = df_train[\"Survived\"]\n\n#generating the testing and training sets using the train_test_split model\n# test size = 0.30, random_state = 0\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=10)","34517ebd":"test","643782ad":"#1. Logistic Regression\nlog_reg = LogisticRegression(random_state=10)\nlog_reg.fit(X_train, y_train)\nprint(\"Logistic Regression Accuracy: \", log_reg.score(X_test,y_test))","64d16324":"#2 Random Forest Classifier\nrf_reg = RandomForestClassifier(random_state=10)\nrf_reg.fit(X_train, y_train)\nprint(\"Random Forest Classifier Accuracy: \", rf_reg.score(X_test,y_test))","9f55553f":"#3. SVM CLassifier\nsvm_clsf = SVC()\nsvm_clsf.fit(X_train, y_train)\nprint(\"SVM CLassifier Accuracy: \", svm_clsf.score(X_test,y_test))","5cba42f1":"#4. KNN Classifier\nbest_knn = []\nfor n in range(1,12):\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train, y_train)\n    best_knn.insert(n, knn.score(X_test,y_test))\nbest_knn","8430fb46":"knn_clsf = KNeighborsClassifier(n_neighbors=8)\nknn_clsf.fit(X_train, y_train)\nprint(\"KNN Classifier Accuracy: \", knn_clsf.score(X_test,y_test))","cd3da7f5":"#5. Voting Classification\nvoting_classfication = VotingClassifier(estimators = [('lg', log_reg), ('rfg', rf_reg), ('svc', svm_clsf), ('knn', knn_clsf)], voting=\"hard\", n_jobs=-1)\nvoting_classfication.fit(X_train, y_train)\nprint(\"Voting Classification Accuracy: \", voting_classfication.score(X_test,y_test))","5612322f":"test_result = pd.Series(svm_clsf.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([df_test[\"PassengerId\"], test_result],axis = 1)\nresults.to_csv(\"titanic_submission.csv\", index = False)","11164446":"We can see that aproximately 38% of the passengers survived and the highest fare is over 15 times the average. Now let's look at the data with some important relation with output attribute. So we are generating the heatmap to understand the correlation of each attribute with **Survived**","20298eac":"As we have generated some of useful features from the given data, let's check its effets and relation with the output.","0d1d5b06":"Looking at the correlation matrix, we can understand the importance of attributes on the output.","21a9c412":"Now looking insights the training data.","bd81327d":"We can see that family presence is higher on: - first class; - female sex;\n\nWe have already discovered that these Pclass, Sex and Family show a higher survival rate, so maybe the higher survival rate for passengers with family members is more due to them than to the presence of family itself.","cf18baf2":"From this initial observation we notice that,\nfrom 1309 passenger records of training data and testing data: \n- 263 have missing ages; \n- only 295 have cabin records available; \n- 2 embarkments are missing;\n- 1 Fare value is missing.\nThe cabin values are not going to be used in this analysis, so they will not be touched.\n","2114232c":"Here we'll understand the EDA for the Titanic Dataset. ALso we will check the accuracy of various models on dataset. Following notebook is the outline of the work.","04ecbf72":"From the graph above that the presence of family is effective on the survival.The data shows that having a family member aboard indicates a better chance for survival.","ed9ccb21":"The average fare paid by women is higher than men\u2019s on every class, although the fares on second class are almost equal.","1d4e8bd6":"# 1. Reading the Dataset in the dataframe.\n\nHere we are firstly loading the dataset in the dataframe. As we are given separate Training and Testing dataset, we will load them in separate dataframes. We are writing the necessary codes to setup the environment.","44b988cc":"Now reading the dataset in the dataframe.","0a4056a2":"* Now from the given dataset, we are separating the output attribute and saving in y_train and remaining input attributes in X_train. \n* We are using train_test_split for training and testing data partition. Where we will provide the 30% of data for validation and reamining for the training.","51ab0c91":"Here *titanic_submission.csv* contains the output of the test data provided.","15f30788":"As we can see that women are having higher survival rate than men in any Passenger class and any embarked station. Now let's look at the average fare paid by men and women.","afaabf41":"# 4. Feature Exploration\nNow let's have age divided in groups and label them using Label Encoder.","00ec2309":"Let's replace the null values by 1 in **Emabarked** column.","9a54614c":"The survival rate for passengers embarked on Cherbourg is higher than both other ports\u2019. That is no wonder, since the mean \u2018Pclass\u2019 value for this port is 1.89 - way lower than Queenstown\u2019s 2.90 and Southampton\u2019s 2.35 - which means that people that embarked there belonged to richer classes, which we\u2019ve already seen that have better survival rates than the poorer ones.","8ad7ed1b":"Now let's understand the effect of **Family** attribute on survival.","3284afc0":"Let\u2019s check some other numbers about family presence, like it\u2019s relation with class, sex.","8bb9cd4a":"As the **Age** column contains 144 missing values. So we have to look into and make necessary replacements. We are checking the missing values of age by their Sex,Pclass and Embarked value and replacing by the mean age of the same tuples.","88b46dc8":"Simillarly we are dividing the Fare in various groups and label them.","42d9b524":"**Fare** attribute has one missing value. Let's fill it.","be216160":"# 6. Generating Model and Validating against Dataset prepared\n\nNow we are in a stage where we can use the task relavant data for necessary model of classification. From the libraries we are importing various classification models and testing.","51d85a33":"# 2. Understanding the data\n* Here we will look into the data. We will understand the effect of some attributes on the output. As the dataset has binary output attribute **\"Survived\"**, which naturally depends on the *Age & Sex*. In addition to this we may consider the existance of *family* for the survival. The dataset is having *SibSp* and *Parch* columns. So we can have implication of *family* from it. In the given dataset some of the columns like *Name,PassengerId,* are not having any relation with the **Survived** so we will drop them as well.\n\n* Firstly we'll observe numeric attributes with necessary statistical parameters.","95fd3c98":"# 3. Cleaning the data\n\nHere we will clean the data from the given dataset. As some of the columns contain missing values, we need to fill in the values. Let's replace the values.","4ea05ed1":"Now let's combine both data and creating a single dataframe using pd.concat","0387d20e":"# 5. Finalizing the dataset\n\nFrom the above heatmap we can see that some of the features are not useful. So we are dropping them and finalizing the dataset to use with classification methods.\n* Ticket, Cabin, Name, PassengerId and Age are deleted according to the result of the correlation matrix.\n* Also SibSp and Parch Attributes are combined in the Family attribute so are also dropping them as well.\n","de45e197":"Lets check the unique attribute values of every attributes.","413b742d":"Now let's introduce a new attribute called **Family**. **Family** attribute is made up from existing two attributes **Parch** and **SibSp**. Now lets generate the attribute and create a **family** attribute.","b8e95205":"We are converting the symbolic or character data in the integer to better use. \nReplacing the attribute values.\n* Embarked (S - 0, C - 1, Q - 2)\n* Sex (male - 0, female - 1)","7dbb5521":"From the above heatmap we can understand that Sex has the highest importance. Along with this Fare Embarked,Parch are also having some importance.","ff0fb47f":"So from the above results, we can see that the SVM Classifier is having the best accuracy among all. So we will check our test dataset with this model and generate the output for validation.\n* So we will load the test data and then apply our model to generate results."}}