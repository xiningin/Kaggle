{"cell_type":{"0754fdda":"code","dcc5e803":"code","fb22f81a":"code","80544a2d":"code","3d16838c":"code","67dc82f0":"code","1d76f55a":"code","d47204df":"code","4d4d7101":"code","7eb0241a":"code","5f75b4ce":"code","5a6fd816":"code","4b19180e":"code","c25c921b":"code","bb4b161f":"code","43e14fb6":"code","3e4c3a6c":"code","25d91dbc":"code","ac0e841e":"code","96f01c15":"code","1e25e5b0":"code","23908d94":"code","d6d34cd1":"code","36016ded":"code","759e6c99":"code","a5123ff7":"markdown","ebaf0d17":"markdown","b392eaec":"markdown","56c4738a":"markdown","d5896675":"markdown","d0201f90":"markdown","60eae484":"markdown","734c67e5":"markdown","1e648abb":"markdown","18ce3e90":"markdown","53ebe8bb":"markdown","09d1c0d9":"markdown","fcc31ddf":"markdown","c0350f13":"markdown","090e33bf":"markdown","88486da8":"markdown"},"source":{"0754fdda":"!pip install pyspark","dcc5e803":"# Creating spark session \nfrom pyspark.sql import SparkSession\nfrom pyspark.conf import SparkConf\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.types import *\n\nspark = SparkSession.builder.appName(\"movierecommender\") \\\n.config(conf=SparkConf([('spark.executor.memory', '16g'), \n                        ('spark.app.name', 'Spark Updated Conf'), \n                        ('spark.executor.cores', '6'), \n                        ('spark.cores.max', '6'), \n                        ('spark.driver.memory','16g')])) \\\n.getOrCreate()","fb22f81a":"# Loading data\nmovies = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"..\/input\/movielens-20m-dataset\/movie.csv\",inferSchema=\"true\")\nratings = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"..\/input\/movielens-20m-dataset\/rating.csv\",inferSchema=\"true\")","80544a2d":"# Preprocessing data for exploratory data analysis\nmovielens = ratings.join(movies,[\"movieId\"],\"left\")\nmovielens.summary().show()","3d16838c":"# Final Schema for dataset\nmovielens.printSchema()","67dc82f0":"# Train set test set split\n(train_set,temp) = movielens.randomSplit([8.0,1.0],seed=1)","1d76f55a":"# Make sure userId and movieId in validation set are also in train set (to avoid Cold Start Problem)\nvalidation_set = (temp\n    .join(train_set,[\"userId\"],\"left_semi\")\n    .join(train_set,[\"movieId\"],\"left_semi\"))\n\nremoved = (temp\n .join(validation_set,[\"movieId\",\"userId\"],\"left_anti\")\n)\n\ntrain_set = train_set.union(removed)","d47204df":"# Visualization Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom statsmodels.distributions.empirical_distribution import ECDF\n%matplotlib inline  \nplt.rcParams[\"figure.figsize\"] = (10,8)\n","4d4d7101":"# Distribution of user ratings\nratings_hist=(train_set\n .groupBy(f.col(\"rating\")).count()\n .sort(f.col(\"rating\").desc())        \n).toPandas()\n\nratings_hist.plot.bar(\"rating\",\"count\")\nplt.title(\"Distribution of user ratings\")\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Number of user ratings\")\nplt.legend().remove()","7eb0241a":"# Density Distribution and normalized ECDF of ratings grouped by movie\nmovies_ratings =(train_set\n .groupBy(f.col(\"movieId\")).count()    \n).toPandas()\n\nplt.subplot(2, 2, 1)\nsns.kdeplot(movies_ratings[\"count\"])\nplt.xlabel(\"\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribution of ratings by movie\")\n\nplt.subplot(2,2,2)\nplt.plot(ECDF(movies_ratings[\"count\"]).x,ECDF(movies_ratings[\"count\"]).y)\nplt.xlabel(\"Number of Ratings per movie\")\nplt.ylabel(\"Cumulative Frequency\")","5f75b4ce":"# Density Distribution and normalized ECDF of ratings grouped by user\nuser_ratings =(train_set\n .groupBy(f.col(\"userId\")).count()    \n).toPandas()\n\nplt.subplot(2, 2, 1)\nsns.kdeplot(user_ratings[\"count\"])\nplt.xlabel(\"\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribution of ratings by user\")\n\nplt.subplot(2,2,2)\nplt.plot(ECDF(user_ratings[\"count\"]).x,ECDF(user_ratings[\"count\"]).y)\nplt.xlabel(\"Number of Ratings per user\")\nplt.ylabel(\"Cumulative Frequency\")","5a6fd816":"# Average rating of movies based on genre\navg_genre_rating = (train_set\n .select(\"movieId\",\"userId\",\"genres\",\"rating\")\n .withColumn(\"genres_array\", f.split(\"genres\", \"\\|\"))\n .withColumn(\"genre\", f.explode(\"genres_array\"))\n .groupBy(\"genre\").agg(f.mean(f.col(\"rating\")).alias(\"genre_rating\"),\n                       f.countDistinct(\"movieId\").alias(\"num_movies\"),\n                       f.countDistinct(\"movieId\",\"userId\").alias(\"num_ratings\"))\n).toPandas()\n\n\navg_genre_rating.plot.barh(\"genre\",\"genre_rating\")\nplt.title(\"Visualizing average rating for each genre\")\navg_genre_rating.plot.barh(\"genre\",\"num_ratings\")\nplt.title(\"Visualizing number of ratings for each genre\")\navg_genre_rating.plot.barh(\"genre\",\"num_movies\")\nplt.title(\"Visualizing number of movies in each genre\")","4b19180e":"# Analyzing day of the month - Timestamp of rating\nday_month_rating = (train_set\n .withColumnRenamed(\"timestamp\",\"date\")\n .withColumn(\"day\",f.dayofmonth(f.col(\"date\")))\n .groupBy(\"day\").agg(f.mean(f.col(\"rating\")).alias(\"avg_rating\"),\n                     f.countDistinct(\"movieId\").alias(\"num_movies\"),\n                     f.countDistinct(\"movieId\",\"userId\").alias(\"num_ratings\"))\n).toPandas()\n\nday_month_rating.plot.scatter(\"day\",\"avg_rating\")\nplt.title(\"Visualizing average rating rated each day\")\nday_month_rating.plot.scatter(\"day\",\"num_ratings\")\nplt.title(\"Visualizing number of ratings rated each day\")\nday_month_rating.plot.scatter(\"day\",\"num_movies\")\nplt.title(\"Visualizing number of movies rated each day\")","c25c921b":"# Analyzing day of the week - Timestamp of rating\nday_week_rating = (train_set\n .withColumnRenamed(\"timestamp\",\"date\")\n .withColumn(\"day\",f.dayofweek(f.col(\"date\")))\n .groupBy(\"day\").agg(f.mean(f.col(\"rating\")).alias(\"avg_rating\"),\n                     f.countDistinct(\"movieId\").alias(\"num_movies\"),\n                     f.countDistinct(\"movieId\",\"userId\").alias(\"num_ratings\"))\n).toPandas()\n\nday_week_rating.plot.scatter(\"day\",\"avg_rating\")\nplt.title(\"Visualizing average rating rated each day\")\nday_week_rating.plot.scatter(\"day\",\"num_ratings\")\nplt.title(\"Visualizing number of ratings rated each day\")\nday_week_rating.plot.scatter(\"day\",\"num_movies\")\nplt.title(\"Visualizing number of movies rated each day\")","bb4b161f":"release_year_rating = (train_set\n .select(\"title\",\"movieId\",\"userId\",\"rating\")\n .withColumn(\"releaseyear\",f.substring('title',-5,4))\n .filter(f.col(\"releaseyear\")>1900)\n .groupBy(\"releaseyear\").agg(f.mean(f.col(\"rating\")).alias(\"avg_rating\"),\n                             f.countDistinct(\"movieId\").alias(\"num_movies\"),\n                             f.countDistinct(\"movieId\",\"userId\").alias(\"num_ratings\"))\n).toPandas()\n\nplt.figure(figsize=(8,13))\nplt.subplot(3, 1, 1)\nplt.scatter(release_year_rating.releaseyear.astype('int64'),release_year_rating.avg_rating)\nplt.title(\"Visualizing average rating vs Release Year\")\nplt.xticks([])\nplt.subplot(3, 1, 2)\nplt.scatter(release_year_rating.releaseyear.astype('int64'),release_year_rating.num_ratings)\nplt.title(\"Visualizing number of ratings vs Release Year\")\nplt.xticks([])\nplt.subplot(3, 1, 3)\nplt.scatter(release_year_rating.releaseyear.astype('int64'),release_year_rating.num_movies)\nplt.title(\"Visualizing number of movies vs Release Year\")","43e14fb6":"from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator","3e4c3a6c":"# Basic Model parameters\nals = ALS(\n        userCol = \"userId\",\n        itemCol = \"movieId\",\n        ratingCol = \"rating\",\n)","25d91dbc":"# Evaluator\nevaluator = RegressionEvaluator(\n    metricName = \"rmse\",\n    labelCol = \"rating\", \n    predictionCol = \"prediction\"\n)\n# Fit and Transform\nmodel = als.fit(train_set)\npredictions = model.transform(validation_set)","ac0e841e":"rmse = evaluator.evaluate(predictions.na.drop())\nprint(rmse)","96f01c15":"\n# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n# # Creating Hyperparameter grid for tuning the model \n# parameter_grid = (\n#     ParamGridBuilder()\n#     .addGrid(als.rank ,[1,5,10])\n#     .addGrid(als.maxIter,[20])\n#     .addGrid(als.regParam,[0.05,0.1])\n#     .build()\n# )\n\n# # Cross validation on the hyperparameter grid\n# crossvalidator = CrossValidator(\n#     estimator=als,\n#     estimatorParamMaps=parameter_grid,\n#     evaluator=evaluator,\n#     numFolds=1,\n# )\n# # Model fitting and predictions\n# crossval_model = crossvalidator.fit(train_set)\n# predictions = crossval_model.transform(validation_set)","1e25e5b0":"# rmse = evaluator.evaluate(predictions)\n# print(rmse)","23908d94":"# opt_model = crossval_model.bestModel\n# opt_model","d6d34cd1":"# Recommending top 10 movies for all users\nrecommend_all_users = model.recommendForAllUsers(10).cache()\nrecommend_all_users.show(20,False)","36016ded":"# Checking movie title from the previous generated recommendations\nUSER_ID = 1238\n(\n    recommend_all_users\n    .filter(f\"userId == {USER_ID}\")\n    .withColumn(\"rec\",f.explode(\"recommendations\"))\n    .select(\"userId\",\n            f.col(\"rec\").movieId.alias(\"movieId\"),\n            f.col(\"rec\").rating.alias(\"rating\"),\n           )\n    .join(movies,\"movieId\")\n    .orderBy(\"rating\",ascending=False)\n    .select(\"movieId\",\"title\")\n).show(truncate=False)","759e6c99":"# Consider any random user from the userId\nUSER_ID = 1238 \n\n# Movies not rated by the selected user\nmovies_to_be_rated = (\n    ratings\n    .filter(f\"userId != {USER_ID}\")\n    .select(\"movieId\").distinct()\n    .withColumn(\"userId\",f.lit(USER_ID))\n)\n# Predictions on unwatched movies only\nuser_movie_preds = model.transform(movies_to_be_rated)\nuser_movie_preds.show()\n\n# Movie recommendations for userId - Manually feeding unwatched movies\n(user_movie_preds\n.dropna()\n.orderBy(\"prediction\",ascending = False)\n.limit(10)\n.join(movies,[\"movieId\"])\n.select(\"userId\",\"movieId\",\"title\",f.col(\"prediction\").alias(\"rating\"))\n.orderBy(\"rating\",ascending = False)\n).show(truncate=False)","a5123ff7":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n    \n    \nCollaborative filtering can be further divided into memory-based and model-based collaborative filtering. The memory-based approach uses user rating data to compute similarity between users or items. Memory-based systems are not always as fast and scalable as we would like them to be, especially in the context of actual systems that make real-time recommendations on the basis of large datasets. \n\nAlthough there are a number of algorithms that can be used to build the model in model-based approach, one of the most popular ones is the Matrix Factorization technique. Matrix factorization achieves collaborative filtering by approximating an incomplete rating matrix using the product of two matrices in a joint latent factor space of dimensionality f. Before we can get into further details of matrix factorization we will describe some key elements of this technique: The rating matrix, latent factors and the latent vectors. A rating matrix is a matrix of u(users) by i(items) of explicit user ratings over items. This is generally sparse because, not all users could have watched all movies. An entry in this sparse matrix corresponds to the rating, given by user u, of an item i. The latent vector of factors are inferred features from movie rating patterns of users, and are estimated by minimizing the loss function. Examples for latent factors in the context of movies, can be genre, depth of a character, amount of action, age group of the target audience or can even be completely uninterpretable. These inferred features are often called latent vectors and the k attributes are often called the latent factors. Furthermore, the expressive power of the model can be tuned by modifying the number of latent factors. \n\n![mf1.png](attachment:mf1.png)\n\nIn this notebook, we will talk about\u00a0building our movie recommender system with one of the sophisticated algorithms which is more efficient and appropriate for recommender systems : Matrix Factorization. Matrix factorization achieves collaborative filtering by approximating an incomplete rating matrix using the product of two low-rank matrices.\n\n![Untitled.png](attachment:Untitled.png)","ebaf0d17":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n    \n#### <center> Recommendations for All users  <\/center>\n \nIn this section, we generate recommendations based on the requirements. \n\nRecommendations can be generated for all users, a list of users, or a single user.","b392eaec":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n    \n    \n###  <center>  Train-Validation Split <\/center> \n\nWe then create a 80\/20 train-validation split of the movielens dataset for model evaluation purposes. The model is created and trained on the train set and tested on the validation set. ","56c4738a":"> #### Timestamp","d5896675":"<span style='font-family:serif'>\n    \n### <center> Movie Recommender System using PySpark <\/center>\n\n","d0201f90":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n    \n###  <center>  Exploratory Data Analysis <\/center> \n\nData ingestion is followed by data exploration where we intend to gain some insights about the dataset we just loaded. We study each attribute and its characteristics like name, type, percentage of missing values, outliers, type of distribution and many others. The subsequent tasks include studying correlations between the attributes and identifying the promising transformations if needed. Data visualization is quite an important tool for accomplishing these tasks. We document all these intuitions thus obtained by summarizing and visualizing the dataset, aiding the understanding of the project.\n\nWith an initial glance of the movielens dataset, we observe that movie information is available in movieId and title columns; user information is available in userId column, timestamp is measured in seconds with \u201c1970-01-01 UTC\u201d as origin; rating column is our target variable; Each movie rating has been categorized into one or more genres which is available in genres column.","60eae484":"> #### Genres","734c67e5":"> #### Rating","1e648abb":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n\nA recommender system analyzes data, on both products and users, to make item suggestions to a given user, indexed by u, or predict how that user would rate an item, indexed by i. \n\n![Screen%20Shot%202021-02-14%20at%209.11.49%20PM.png](attachment:Screen%20Shot%202021-02-14%20at%209.11.49%20PM.png)\n> Popularity based recommendation systems\n    \nThe popularity-based recommendation system utilizes the data available on top movie review websites to recommend the most popular movies to users based on their star ratings, thus increasing content consumption. Although this kind of recommendation system is simple to implement and scalable, it does not provide personalization to the user.  Additionally, since the data that this kind of system relies upon is purely based on the ratings provided on the rating websites, it might not reflect user preferences or account regional dialect of every user.\n    \n> Association Rule Mining\n\nAssociation rule mining (also called as Market Basket Analysis), at a basic level, is a rule-based method that analyzes for patterns of co-occurrences, in a database(also called Basket Data). It identifies frequent if-then associations called association rules which consists of an antecedent (if) and a consequent (then). An example of an association rule based on basket data is that 90% of people who watch Star Wars and The Empire Strikes Back! in a given week , also watch A New Hope later that week. This method is greatly useful when user choices are not easily accessible. For example, companies that do not have an online presence uses association rule mining to study purchase patterns and placing the frequently bought items in the same aisle. Although the analysis is easy to understand and interpret, the method can get computationally expensive for large datasets.\n\n![Unknown.png](attachment:Unknown.png)\n\nAs user preferences became easily accessible, recommender systems have been developed to embed user choice and behavior patterns into the algorithms. The other two approaches, content-based filtering and collaborative filtering employs the usage of customer preferences in their algorithms. \n\n> Content-based filtering \n\nA content-based filtering technique analyzes the past choices of a user and constructs profiles based on the user actions alone to build a preference profile, instead of pairing users with the products that similar users liked. \n\n> Collaborative filtering\n\nCollaborative filtering systems on the other hand, analyzes interactions or similarity between users and items. Its distinct because it looks at the behavior of multiple customers cross-referencing their purchase histories with each other. Good personalized recommendations enhances the user experience, thereby improving customer satisfaction and loyalty. This technique is generally more accurate than content filtering. This is because this technique analyzes user preferences and uses these for providing personalized recommendations to other similar users. \n\n![content-CF.png](attachment:content-CF.png)\n\n> Hybrid approach \n\nThe hybrid approach of recomender systems use a combination of content-based and collaborative filtering. \n\n***","18ce3e90":"> #### MovieId & Title","53ebe8bb":"> #### Release Year","09d1c0d9":"#### <center>  Recommendation for a particular user based on predictions for unwatched movies<\/center>","fcc31ddf":"#### <center>  Detailed recommendation for the selected user <\/center>","c0350f13":"> #### UserId","090e33bf":"> ### Building a recommender system using ALS ","88486da8":"<div style=\"font-size: 14px\">\n    \n<span style='font-family:Georgia'>\n    \nData Source: \n\nThe datasets describe ratings and free-text tagging activities from MovieLens, a movie recommendation service. It contains 20000263 ratings and 465564 tag applications across 27278 movies. These data were created by 138493 users between January 09, 1995 and March 31, 2015. This dataset was generated on October 17, 2016.    "}}