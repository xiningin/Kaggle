{"cell_type":{"4ac51864":"code","749bbdcc":"code","2eb38c66":"code","b31db16a":"code","974b1415":"code","e4a0762d":"code","010484ba":"code","a697e0cc":"code","a241bd2e":"code","0eedd5d7":"code","45073877":"code","710acd80":"code","dae62e39":"markdown"},"source":{"4ac51864":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom xgboost import XGBRegressor","749bbdcc":"from catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor","2eb38c66":"# pd.set_option('display.max_columns',None) \n# pd.set_option('display.max_rows', None)","b31db16a":"df = pd.read_csv('..\/input\/tps-aug-2021-train-with-folds\/train_folds.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","974b1415":"features = [col for col in df.columns if col not in ('id','loss','Kfold')]\ndf_test = df_test[features]","e4a0762d":"SEED = 27\nN_ESTIMATORS = 10000\nVERBOSE = 1000\n\nlgb_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'n_estimators': N_ESTIMATORS,\n    'random_state': SEED,\n    'learning_rate': 5e-3,\n    'subsample': 0.8,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.6,\n    'reg_alpha': 6.4,\n    'reg_lambda': 1.8,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'importance_type': 'gain',\n    }\n\nctb_params = {\n    'bootstrap_type': 'Poisson',\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'random_seed': SEED,\n    'task_type': 'GPU',\n    'max_depth': 8,\n    'learning_rate': 5e-3,\n    'n_estimators': N_ESTIMATORS,\n    'max_bin': 280,\n    'min_data_in_leaf': 64,\n    'l2_leaf_reg': 0.01,\n    'subsample': 0.8\n}\n\n# xgb_params = {\n#     'objective': 'reg:squarederror',\n#     'learning_rate': 5e-3,\n#     'seed': SEED,\n#     'subsample': 0.8,\n#     'colsample_bytree': 0.6,\n#     'n_estimators': N_ESTIMATORS,\n#     'max_depth': 11,\n#     'alpha': 20,\n#     'lambda': 9,\n#     'min_child_weight': 256,\n#     'importance_type': 'total_gain',\n    \n# }\n\n","010484ba":"# Model hyperparameters\n#  xgb_params = {'n_estimators': 10000,\n#               'learning_rate': 0.35,\n#               'subsample': 0.926,\n#               'colsample_bytree': 0.84,\n#               'max_depth': 2,\n#               'booster': 'gbtree', \n#               'reg_lambda': 35.1,\n#               'reg_alpha': 34.9, 'random_state':27,\n#               'n_jobs': 4}\nxgb_params ={'n_estimators': 2000,\n             'subsample': 0.6,\n             'colsample_bytree': 0.9,\n             'eta': 0.007939812697028495,\n             'reg_alpha': 46, 'reg_lambda': 64, 'max_depth': 12,\n             'min_child_weight': 20, 'random_state': 27}\n# xgb_params = {'colsample_bytree': 0.8413485408956082,\n#               'gamma': 7.169901458931625,\n#               'learning_rate': 0.41588056022137915,\n#               'max_depth': 12,'min_child_weight': 7.0,\n#               'n_estimators': 10000,'random_state': 21,\n#               'reg_alpha': 72,'reg_lambda': 55,'subsample': 0.8772846596931277}","a697e0cc":"scaler = StandardScaler()\n\npreds = []\nscores = []\nfinal_pred_valid ={}\nfor fold in range(10):\n    X_train = df[df.Kfold != fold].reset_index(drop=True)\n    X_valid = df[df.Kfold == fold].reset_index(drop=True)\n    X_test = df_test.copy()\n    \n    valid_ids = X_valid.id.values.tolist()\n    \n    y_train, y_valid = X_train.loss, X_valid.loss\n    X_train, X_valid = X_train[features],X_valid[features]\n    \n    X_train = scaler.fit_transform(X_train)\n    X_valid = scaler.transform(X_valid)\n    X_test  = scaler.transform(X_test)\n    \n    model = XGBRegressor(**xgb_params,\n                         tree_method='gpu_hist', \n                         gpu_id=0, predictor=\"gpu_predictor\")\n        \n    model.fit(X_train, y_train,verbose=1000,\n              eval_set=[(X_train,y_train),(X_valid, y_valid)],\n              eval_metric='rmse', early_stopping_rounds=100)\n    \n    pred_valid = model.predict(X_valid)\n    pred_test = model.predict(X_test)\n    \n    preds.append(pred_test)\n    final_pred_valid.update(dict(zip(valid_ids, pred_valid)))\n    \n    rmse = mean_squared_error(pred_valid, y_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n    \nprint(np.mean(scores), np.std(scores))\n\nfinal_pred_valid = pd.DataFrame.from_dict(final_pred_valid, orient='index').reset_index()\nfinal_pred_valid.columns = ['id','pred_1']\nfinal_pred_valid.to_csv('train_pred_1.csv', index=False)\n\nsample_sub.loss = np.mean(np.column_stack(preds), axis=1)\nsample_sub.columns = [\"id\", \"pred_1\"]\nsample_sub.to_csv(\"test_pred_1.csv\", index=False)","a241bd2e":"# preds = []\n# scores = []\n# final_pred_valid ={}\n# for fold in range(10):\n#     X_train = df[df.Kfold != fold].reset_index(drop=True)\n#     X_valid = df[df.Kfold == fold].reset_index(drop=True)\n#     X_test = df_test.copy()\n    \n#     valid_ids = X_valid.id.values.tolist()\n    \n#     y_train, y_valid = X_train.loss, X_valid.loss\n#     X_train, X_valid = X_train[features],X_valid[features]\n    \n#     X_train = scaler.fit_transform(X_train)\n#     X_valid = scaler.transform(X_valid)\n#     X_test  = scaler.transform(X_test)\n    \n#     model = LGBMRegressor(**lgb_params)\n        \n#     model.fit(X_train, y_train, verbose=VERBOSE,\n#              eval_set=[(X_train,y_train),(X_valid, y_valid)],\n#              eval_metric='rmse', early_stopping_rounds=100)\n    \n#     pred_valid = model.predict(X_valid)\n#     pred_test = model.predict(X_test)\n    \n#     preds.append(pred_test)\n#     final_pred_valid.update(dict(zip(valid_ids, pred_valid)))\n    \n#     rmse = mean_squared_error(pred_valid, y_valid, squared=False)\n#     print(fold, rmse)\n#     scores.append(rmse)\n    \n# print(np.mean(scores), np.std(scores))\n# final_pred_valid = pd.DataFrame.from_dict(final_pred_valid, orient='index').reset_index()\n# final_pred_valid.columns = ['id','pred_2']\n# final_pred_valid.to_csv('train_pred_2.csv', index=False)\n\n# sample_sub.loss = np.mean(np.column_stack(preds), axis=1)\n# sample_sub.columns = [\"id\", \"pred_1\"]\n# sample_sub.to_csv(\"test_pred_1.csv\", index=False)","0eedd5d7":"# final_pred_valid = pd.DataFrame.from_dict(final_pred_valid, orient='index').reset_index()\n# final_pred_valid.columns = ['id','pred_2']\n# final_pred_valid.to_csv('train_pred_2.csv', index=False)\n\n# sample_sub.loss = np.mean(np.column_stack(preds), axis=1)\n# sample_sub.columns = [\"id\", \"pred_1\"]\n# sample_sub.to_csv(\"test_pred_1.csv\", index=False)","45073877":"# final_prediction = np.mean(np.column_stack(preds),axis=1)","710acd80":"# sample_sub.loss = final_prediction\n# sample_sub.to_csv(\"submission.csv\", index=False)","dae62e39":"**Loading Data**"}}