{"cell_type":{"7146b37e":"code","440226c7":"code","46e344e2":"code","d7500f96":"code","6b984781":"code","37ade376":"code","ff027064":"code","4d116b52":"code","a2a800c1":"code","2d3ddabf":"code","119e135e":"code","f15f5cc2":"code","4146c659":"code","cff5fdc4":"code","5128a3e7":"markdown","8f6c12ed":"markdown","0b80e4e3":"markdown","4ba25ea5":"markdown","6bd09ace":"markdown","b38d5740":"markdown","6ac992b8":"markdown","a869b122":"markdown"},"source":{"7146b37e":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-3\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-3\/eval.csv\")\n\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","440226c7":"print(train_data.isna().sum().sum())\nprint(test_data.isna().sum().sum())","46e344e2":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n#pre-preprocessing pipe\npppipe = Pipeline([(\"scaler\", StandardScaler()), (\"reducer\", PCA(n_components=0.99))])\n\nX = train_data.drop([\"id\", \"Eat\"], axis=1)\ny = train_data[\"Eat\"]\n\nX_reduced = pd.DataFrame(pppipe.fit_transform(X))\ntest_reduced = pppipe.transform(test_data.drop(\"id\", axis=1))\nprint(X_reduced.shape, test_reduced.shape)","d7500f96":"for i in range(5):\n    plt.scatter(X_reduced.loc[:,i], y, alpha=0.1)\n    plt.xlabel(\"Principal component: \" + str(i+1))\n    plt.ylabel(\"Atomization Energy\")\n    plt.show()\n    plt.clf()","6b984781":"from sklearn.model_selection import train_test_split\n\nX_remain, X_test, y_remain, y_test = train_test_split(X_reduced, y, test_size=0.1)\nX_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=0.2)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","37ade376":"from keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nearly_stopping_monitor = EarlyStopping(monitor=\"val_loss\", patience=10)\n\ndef create_m1(activation):\n    model = Sequential()\n    model.add(Dense(300, input_shape = (X_train.shape[1],), activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(100, activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(1))\n    model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n    return model\n\nm1 = KerasRegressor(build_fn = create_m1)\n\nparams = {'activation': [\"relu\", \"leaky_relu\"], \"batch_size\" : [32, len(X_train)]}\n\nm1_search = GridSearchCV(m1, param_grid = params, cv = 3, scoring=\"neg_mean_squared_error\", refit=True)\n\nm1_search.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\nprint(\"Done!\", m1_search.best_params_)","ff027064":"def create_m2(activation):\n    model = Sequential()\n    model.add(Dense(200, input_shape = (X_train.shape[1],), activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(200, activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(1))\n    model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n    return model\n\nm2 = KerasRegressor(build_fn = create_m2)\n\nparams = {'activation': [\"relu\", \"leaky_relu\"], \"batch_size\" : [32, len(X_train)]}\n\nm2_search = GridSearchCV(m2, param_grid = params, cv = 3, scoring=\"neg_mean_squared_error\", refit=True)\n\nm2_search.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\nprint(\"Done!\", m2_search.best_params_)","4d116b52":"def create_m3(activation):\n    model = Sequential()\n    model.add(Dense(200, input_shape = (X_train.shape[1],), activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(150, activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(100, activation = activation))\n    model.add(BatchNormalization())\n    model.add(Dense(1))\n    model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n    return model\n\nm3 = KerasRegressor(build_fn = create_m3)\n\nparams = {'activation': [\"relu\", \"leaky_relu\"], \"batch_size\" : [32, len(X_train)]}\n\nm3_search = GridSearchCV(m3, param_grid = params, cv = 3, scoring=\"neg_mean_squared_error\", refit=True)\n\nm3_search.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\nprint(\"Done!\", m3_search.best_params_)","a2a800c1":"from sklearn.metrics import mean_squared_error as MSE\n\nm1 = m1_search.best_estimator_\nm2 = m2_search.best_estimator_\nm3 = m3_search.best_estimator_\n\nm1_scores = []\nm2_scores = []\nm3_scores = []\n\nfor i in range(30):\n    X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=0.2, random_state=i)\n    m1.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\n    predictions = m1.predict(X_val)\n    score = MSE(predictions, y_val)\n    m1_scores.append(score)\n    print(\"Score appended!\")\n\nm1_scores = pd.DataFrame(m1_scores)","2d3ddabf":"for i in range(30):\n    X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=0.2, random_state=i)\n    m2.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\n    predictions = m2.predict(X_val)\n    score = MSE(predictions, y_val)\n    m2_scores.append(score)\n    print(\"Score appended!\")\n\nm2_scores = pd.DataFrame(m2_scores)","119e135e":"for i in range(30):\n    X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=0.2, random_state=i)\n    m3.fit(X_train, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\n    predictions = m3.predict(X_val)\n    score = MSE(predictions, y_val)\n    m3_scores.append(score)\n    print(\"Score appended!\")\n\nm3_scores = pd.DataFrame(m3_scores)","f15f5cc2":"print(m1_scores.describe())\nprint(m2_scores.describe())\nprint(m3_scores.describe())\n\nsns.displot(m1_scores, legend=False)\nplt.xlabel(\"MSE\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Model 1\")\nplt.show()\nplt.clf()\n\nsns.displot(m2_scores, legend=False)\nplt.xlabel(\"MSE\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Model 2\")\nplt.show()\nplt.clf()\n\nsns.displot(m3_scores, legend=False)\nplt.xlabel(\"MSE\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Model 3\")\nplt.show()\nplt.clf()","4146c659":"m3.fit(X_remain, y_remain, epochs=2000, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\npredictions = m3.predict(X_test)\nscore = MSE(predictions, y_test)\nprint(\"Test MSE is \" + str(score))","cff5fdc4":"from keras.callbacks import ModelCheckpoint\n\nmodelCheckpoint = ModelCheckpoint(\"best_model.hdf5\", save_best_only = True)\nm3.fit(X_reduced, y, epochs=2000, validation_split=0.25, callbacks=[early_stopping_monitor, modelCheckpoint], verbose=0)\n\nm3.model.load_weights(\"best_model.hdf5\")\npredictions = m3.predict(test_reduced)\noutput = pd.DataFrame({'id': test_data.id, 'Eat': predictions})\nprint(output.shape)\nprint(output.to_string())\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5128a3e7":"# EDA and Feature Engineering\nFirstly, it's worth checking if there are any missing values, and fortunately there are not.\n\nUnfortunately, I have no way to confindently identify outliers and choose a strategy for handling them given that I know nothing about the source material and there are far too many columns to individually analyze. Given that there are no missing values, I think that's a sign that this data is very clean and any outliers are probably actual values and not mistakes in reporting, and are thus permissible.","8f6c12ed":"Now the final submission data is generated.","0b80e4e3":"Once the best version of each model has been trained, a distribution of scores is generated for each, reincorporating the validation data that was split off earlier.","4ba25ea5":"With only 34 dimensions remaining, I can interrogate the data a little more thoroughly. Above are the scatter plots for the first 5 principal components against the target variable. There are clear relationships that the model could determine, although the further down the list of principal components, the more vertical (and thus, less informational) the relationship seems to be. The first principal component has by far the most clear relationship with the target. \n\n# Building the Models\nNow it's time to build and evaluate three neural networks. Before doing this though, I need to subset the data in order to obtain validation and test data. ","6bd09ace":"Next, the models are built and iteratively search through hyperparameters to find the best combination.","b38d5740":"# Loading in the Data","6ac992b8":"# Selecting the Best Model\nNow we have three distributions of validation scores for the three potential models. The distributions seem to make it very clear that model 3 is the best and should be used for the final submission. It has a high density of scores below 0.1 MSE, whereas the other two have most of their scores above 0.1 MSE. Its mean MSE is 0.11 compared to 0.15 and 0.16, and it has the lowest standard deviation. Therefore, it will be the model used to generate submission data. As a final measure of success, it will be tested on the test data to get a sense of how it will place on the leaderboard.","a869b122":"Next, I need to deal with the absurd number of dimensions of the data. If I leave all 1276 features, the models will take very long to train and risk overfitting because of the curse of dimensionality. In order to do dimensionality reduction, I use PCA to identify the axes about which 99% of the variance of the data is explained and drop the rest. This leaves only 34 dimensions, which is much more manageable. To make PCA more effective, the data is scaled beforehand. The same transformations that were done to the training data are done to the test data."}}