{"cell_type":{"d90cda7c":"code","9cdfdded":"code","4d3da936":"code","5d8a4248":"code","ddbe89d7":"code","37e749f8":"code","dee46746":"code","952e0953":"code","af9262b1":"code","5eef9b27":"code","fadd811d":"code","fe982f79":"code","bc63a72d":"code","73a0a8b5":"code","2d261dff":"code","8345aece":"code","bf6cced3":"code","b7641097":"code","ecae71fc":"code","d3d58a2f":"code","b6caff55":"code","f86f0a59":"code","e8c1e74a":"code","c4393158":"code","e768833d":"code","acb55746":"code","057364f8":"code","99cee6cf":"code","4c36ea20":"code","42afe147":"code","08f6ca27":"code","6268ccd4":"code","a92703a2":"code","707f9100":"code","b0387fa7":"code","9a609b73":"code","179c9a86":"code","bf15fd9d":"code","73b6d82c":"code","820622fc":"code","18d63b58":"code","01f4b7d6":"code","4aab89f6":"code","8817e40b":"code","1bcfc67c":"code","e26188fd":"code","b7f32bf0":"markdown"},"source":{"d90cda7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cdfdded":"import random as rnd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn .linear_model import LogisticRegression\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import accuracy_score\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","4d3da936":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombine=[train,test]\n                  ","5d8a4248":"print(train.columns.values)\n\n","ddbe89d7":"print(train.head())","37e749f8":"train.info()\nprint('_'*40)\ntest.info()","dee46746":"train.describe()","952e0953":"train.describe(include=['O'])","af9262b1":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5eef9b27":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","fadd811d":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","fe982f79":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bc63a72d":"print(test.head())","73a0a8b5":"\ng = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","2d261dff":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","8345aece":"grid = sns.FacetGrid(train, row='Embarked', height=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","bf6cced3":"g=sns.FacetGrid(train,row='Embarked', col='Survived', height=2.2, aspect=1.6)\ng.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ng.add_legend()","b7641097":"print(train.shape,test.shape,combine[1].shape,combine[0].shape)","ecae71fc":"train=train.drop(['Ticket','Cabin'],axis=1)\ntest=test.drop(['Ticket','Cabin'],axis=1)\n","d3d58a2f":"combine=[train,test]\nprint(train.shape,test.shape,combine[0].shape,combine[1].shape)","b6caff55":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","f86f0a59":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","e8c1e74a":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","c4393158":"\ntrain = train.drop(['Name', 'PassengerId'], axis=1)\ntest = test.drop(['Name'], axis=1)\ncombine = [train, test]\ntrain.shape, test.shape","e768833d":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain.head()\n","acb55746":"grid = sns.FacetGrid(train, row='Pclass', col='Sex', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","057364f8":"\nguess_ages = np.zeros((2,3))\nguess_ages","99cee6cf":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain.head()","4c36ea20":"train['AgeBand'] = pd.cut(train['Age'], 5)\ntrain[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","42afe147":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain.head()","08f6ca27":"train = train.drop(['AgeBand'], axis=1)\ncombine = [train, test]\ntrain.head()","6268ccd4":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","a92703a2":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","707f9100":"train = train.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest = test.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train, test]\n\ntrain.head()","b0387fa7":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","9a609b73":"\nfreq_port = train.Embarked.dropna().mode()[0]\nfreq_port","179c9a86":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bf15fd9d":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","73b6d82c":"test['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\ntest.head()","820622fc":"train['FareBand'] = pd.qcut(train['Fare'], 4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","18d63b58":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)\ncombine = [train, test]\n    \ntrain.head(10)","01f4b7d6":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","4aab89f6":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","8817e40b":"coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","1bcfc67c":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","e26188fd":"from IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\ncreate_download_link(submission)\n","b7f32bf0":"MODEL\n"}}