{"cell_type":{"4215f838":"code","b1bc0718":"code","dea0e0f3":"code","38c3f95b":"code","276e762c":"code","72bb2e09":"code","22a95f19":"code","d0ee1393":"code","7f0e04f3":"code","8c5584bc":"code","78606037":"code","fb8aae67":"code","94bd3928":"code","72cc10b4":"code","c811a17c":"code","72ed5c9c":"code","2eaf69e1":"code","28293150":"code","8f0b7a76":"code","4dc89189":"code","b25392b4":"code","22f21dbd":"code","d3cc486d":"code","9e506d14":"code","c7752507":"code","0dc89d20":"code","798a9fec":"code","6fd8a964":"code","e2685c62":"code","063146b6":"code","93c89816":"code","c74a4152":"code","88d43740":"markdown","4dedb1fa":"markdown"},"source":{"4215f838":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1bc0718":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error, mean_squared_log_error","dea0e0f3":"submission = pd.read_csv('..\/input\/bike-sharing-demand\/sampleSubmission.csv')\ntrain_data = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest_data = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","38c3f95b":"print('Train Shape: ', train_data.shape)\nprint('Test Shape: ', test_data.shape)","276e762c":"train_data.sample(10)","72bb2e09":"X = train_data.iloc[:, 0:9]\nY = train_data['count']\n\nprint('Train X Shape: ', X.shape)\nprint('Train Y Shape: ', Y.shape)\nprint('Test Shape: ', test_data.shape)","22a95f19":"train_data.isna().sum(axis=0)","d0ee1393":"sns.displot(Y, kde=True)","7f0e04f3":"sns.displot(np.log(Y), kde=True)","8c5584bc":"sns.displot(X.temp, kde=True)","78606037":"sns.displot(X.atemp, kde=True)","fb8aae67":"sns.displot(X.humidity, kde=True)","94bd3928":"from sklearn.base import BaseEstimator, TransformerMixin\nimport calendar\nfrom datetime import datetime\n\nclass ProcessDateTime(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Transforming datetime...')\n        \n        x_copy = X.copy()\n        x_copy['month'] = x_copy.datetime.apply(lambda x : calendar.month_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['weekday'] = x_copy.datetime.apply(lambda x : calendar.day_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['hour'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").hour)\n        x_copy['minute'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").minute)\n        x_copy = x_copy.drop(['datetime'], axis=1)\n        \n        return x_copy","72cc10b4":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime())\n])\n\npipeline.fit_transform(X)","c811a17c":"class ProcessSeasonWeather(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        print('Transforming season and weather...')\n        x_copy = X.copy()\n        x_copy['season'] = x_copy['season'].map({\n            1: 'Spring',\n            2: 'Summer',\n            3: 'Fall',\n            4: 'Winter'\n        })\n        x_copy['weather'] = x_copy['weather'].map({\n            1: \"Clear+FewClouds+PartlyCloudy,PartlyCloudy\",\n            2: \"Mist+Cloudy,Mist+BrokenClouds,Mist+FewClouds,Mist\",\n            3: \"LightSnow,LightRain+Thunderstorm+ScatteredClouds,LightRain+ScatteredClouds\",\n            4: \"HeavyRain+IcePallets+Thunderstorm+Mist,Snow+Fog\" \n        })\n        return x_copy\npipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather())\n])","72ed5c9c":"pipeline.fit_transform(X)","2eaf69e1":"class DummyEncoding(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Dummy encoding...')\n        x_copy = X.copy()\n        x_copy = pd.get_dummies(x_copy)\n        return x_copy\n    \nclass RemoveFeature(BaseEstimator, TransformerMixin):\n    def __init__(self, features=[]):\n        self._features = features\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Removing features...')\n        x_copy = X.copy()\n        for f in self._features:\n            if f in x_copy.columns:\n                x_copy = x_copy.drop([f], axis=1)\n        return x_copy\n","28293150":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed']))\n])","8f0b7a76":"pipeline.fit_transform(X)","4dc89189":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed'])),\n    ('scaler', StandardScaler())\n])","b25392b4":"pipeline.fit_transform(X)","22f21dbd":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(['windspeed'])),\n    ('scaler', MinMaxScaler())\n])\n\npipeline.fit(X)\nX = pipeline.transform(X)\nX_test = pipeline.transform(test_data)","d3cc486d":"print(X.shape)\nprint(X_test.shape)","9e506d14":"pd.DataFrame(X)","c7752507":"lr = LinearRegression()\nsgd = SGDRegressor()\nrr = Ridge()\nls = Lasso()\nen = ElasticNet()","0dc89d20":"import sklearn\nsklearn.metrics.SCORERS.keys()","798a9fec":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=27)\n\ngrid_ridge_lasso = {\n    'alpha': np.arange(0, 1, 0.05)\n}\n\ngrid_elastic = {\n    'alpha': np.arange(0, 1, 0.05),\n    'l1_ratio': np.arange(0, 1, 0.05)\n}\nlr_score = cross_val_score(lr, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\nsgd_score = cross_val_score(sgd, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\n\nrr_search = GridSearchCV(rr, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nrr_score = rr_search.fit(X, np.log(Y+0.0001))\n\nls_search = GridSearchCV(ls, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nls_score = ls_search.fit(X, np.log(Y+0.0001))\n\nen_search = GridSearchCV(en, grid_elastic, cv=cv, scoring='neg_mean_squared_log_error')\nen_score = en_search.fit(X, np.log(Y+0.0001))","6fd8a964":"print(np.mean(lr_score))\nprint(np.mean(sgd_score))\n\nprint(rr_score.best_score_)\nprint(ls_score.best_score_)\nprint(en_score.best_score_)","e2685c62":"np.exp(rr_score.best_estimator_.predict(X_test))","063146b6":"predictions = np.exp(rr_score.best_estimator_.predict(X_test))\npredictions = predictions.astype('int')","93c89816":"predictions","c74a4152":"pd.DataFrame({\n    'datetime': test_data.datetime,\n    'count': predictions\n})\nsubmission.to_csv('\/kaggle\/working\/submission.csv', index=False)","88d43740":"Preprocessing & Feature Engineering with Pipeline","4dedb1fa":"Modeling"}}