{"cell_type":{"2cd892cb":"code","f835cc7a":"code","985925b9":"code","1957c4eb":"code","415b1fad":"markdown","544e91ae":"markdown"},"source":{"2cd892cb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio,display\nimport librosa","f835cc7a":"sr    = 48000 # sample rate\n\n# do re mi fa sol la ti do, my MUSIC 117 works!\ndo    = 261.6\nseq   = np.exp([np.log(do) + np.log(2)\/12 * x for x in np.cumsum([0,2,2,1,2,2,2,1])])\nwav   = 4e-1 * np.concatenate([np.sin( 2 * np.pi\/sr * s * np.arange(sr)) for s in seq])\n\nplt.figure(figsize=(15,5))\nplt.plot(wav,'.-')                              \nplt.axvline(sr,color='r',ls='-')\nplt.xlim(int(sr*0.99),int(sr*1.01))\nplt.title('wave plot at the transition between \"do\" and \"re\"')\nplt.xlabel('sample')\nplt.ylabel('pressure')\nplt.grid(True)\n\ndisplay(Audio( wav ,rate=sr,normalize=False))","985925b9":"train_tp = pd.read_csv('\/kaggle\/input\/rfcx-species-audio-detection\/train_fp.csv')\ntrain_tp.head()","1957c4eb":"for sid,df in train_tp.groupby('species_id'):\n    print('='*10 + f'species_id {sid}' + '='*10)\n    agg = []\n    for index,row in df.sample(20).iterrows():\n        wav, sr = librosa.load(f'\/kaggle\/input\/rfcx-species-audio-detection\/train\/{row[\"recording_id\"]}.flac', sr=None)\n        clip    = wav[int(row[\"t_min\"]*sr):int(row[\"t_max\"]*sr)]\n        agg.append(clip \/ np.max(np.abs(clip)) * 2)        \n        agg.append(np.sin( 2 * np.pi\/sr * 8 * do * np.arange(int(sr\/10)))) # beep\n    display(Audio(np.concatenate(agg),rate=sr))","415b1fad":"### By a pretrained human brain, many species' characteristics can be learnt by less than 20 clips.","544e91ae":"### it still feels amazing to me, the variety of sounds we hear can be each represented by a single time series"}}