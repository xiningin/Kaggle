{"cell_type":{"a0315c18":"code","ded40dc8":"code","fee4150f":"code","042aa527":"code","976a3c7c":"code","d605c693":"code","95bef612":"code","383e4512":"code","b181670d":"code","45394961":"code","6ed741f0":"code","809dec3c":"code","c1bb4557":"code","3708a1d0":"code","814e0255":"code","d823c9b4":"code","a9c77d2c":"code","836b5f8b":"code","29360c39":"code","f4b5773d":"code","e0445252":"code","ff7fda70":"code","51e2fd6f":"code","5c560eaf":"code","450eee27":"code","5bbe3287":"code","11d07f5f":"code","c1569302":"code","b0571bfe":"markdown","f15c460c":"markdown","91a734d3":"markdown","60a2f64e":"markdown","b59ba7a7":"markdown","044ea05f":"markdown","3d7789ac":"markdown","0dbc4c0a":"markdown","ccaf0caf":"markdown","863deea5":"markdown","bd8cf4d8":"markdown","ebb09cf8":"markdown","46cc4b29":"markdown","151ce4ee":"markdown"},"source":{"a0315c18":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ded40dc8":"df = pd.read_csv('..\/input\/filetest-links-in-regression-testing\/df.csv', index_col=0)","fee4150f":"# transform modified files list\ndf['mod_files'] = df['mod_files'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\ndf['name'] = df['name'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n","042aa527":"df.head()","976a3c7c":"# List of unique files and tests\nall_files = list(df['mod_files'].explode().unique())\nall_tests = list(df['name'].explode().unique())","d605c693":"import collections\nfrom collections import defaultdict\n\ndef get_data_info():\n    \"\"\"\n    Prints stats about the transformation steps applied to the raw dataset\n    :return:\n    \"\"\"\n    files = list(df['mod_files'].explode())\n    tests = list(df['name'].explode())\n    \n    # revisions\n    print(f'Nr of Revisions - {len(df.revision)}')\n\n    # Files\n    print(f'\\nNumber of Files - {len(files)}')\n\n    dist = collections.Counter(files)\n    mpf = sum(dist.values()) \/ len(dist.keys())\n    print(f'   Total number of modifications - {sum(dist.values())}')\n    print(f'   Average number of modification per file - {mpf}')\n    \n    print('\\n   Most Common Files')\n    print(dist.most_common(5))\n    \n    \n    # Tests\n    print(f'\\nNumber of Tests - {len(tests)}')\n\n    # Count test frequency\n    dist = collections.Counter(tests)\n    tpt = sum(dist.values()) \/ len(dist.keys())\n\n    print(f'   Total number of transitions - {sum(dist.values())}')\n    print(f'   Average number of transitions per test - {tpt}')\n\n    print('\\n   Most Common tests')\n    print(dist.most_common(5))","95bef612":"get_data_info()","383e4512":"def create_pairs(df):\n    \"\"\"\n    Each row of the dataset corresponds to 1 revisions, composed of lists of modified files and tests.\n    This function explodes the lists and forms pair-wise combinations between items in both lists.\n    :param data:\n    :return: pairs: dict of tuples of pairs (test, file). Each key is a revision.\n    \"\"\"\n    df = df.explode('name')\n    df = df.explode('mod_files')\n    grouped = df.groupby(['revision'])\n\n    pairs = defaultdict(list)\n    for name, group in grouped:\n        for row in group.iterrows():\n            pairs[name].append((row[1]['mod_files'], row[1]['name']))\n    return pairs","b181670d":"pairs = create_pairs(df)","45394961":"# encode files and test to ints\nfile_index = {file: idx for idx, file in enumerate(all_files)}\nindex_file = {idx: file for file, idx in file_index.items()}\n\ntest_index = {test: idx for idx, test in enumerate(all_tests)}\nindex_test = {idx: test for test, idx in test_index.items()}","6ed741f0":"P = {}\nfor k, v in pairs.items():\n    if v != []:\n        P[k] = [(file_index[t[0]], test_index[t[1]]) for t in v]\npairs = P","809dec3c":"def clean_pairs(pairs, threshold: int):\n    \"\"\"\n    Remove pairs that are very rare, thus very unlikely representing a real connection in the data. They most likely\n    occurred by chance.\n    :param threshold_pairs:\n    :return:\n    \"\"\"\n    all_tuples = [t for k, v in pairs.items() for t in v]\n    C = collections.Counter(all_tuples)\n\n    for k, v in pairs.items():\n        pairs[k] = [t for t in v if C[t] > threshold]\n    \n    pairs = dict( [(k,v) for k,v in pairs.items() if len(v)>0])\n    return pairs","c1bb4557":"print(f'Number of pairs - {sum(len(v) for v in pairs.values())}')\n\npairs = clean_pairs(pairs, threshold=3)\n\nprint(f'Number of pairs after cleaning - {sum(len(v) for v in pairs.values())}')","3708a1d0":"print(f'Total Nr. Commits - {len(pairs)}')\nprint(f'Total Nr. Commits Training (80%) - {np.round(len(pairs)*0.8)}')\nprint(f'Total Nr. Commits Testing (20%)- {np.round(len(pairs)*0.2)}')\n\nfrom sklearn.model_selection import train_test_split\n\ns = pd.Series(pairs)\ntraining_data , test_data  = [i.to_dict() for i in train_test_split(s, train_size=0.8, shuffle=False)]","814e0255":"import random\nimport numpy as np\nfrom tensorflow import keras\n\nrandom.seed(0)\n\n\nclass DataGenerator(keras.utils.Sequence):\n    \"\"\"\n    Generates data for Keras Model. Receives pairs of (files, tests) and generates random combinations of\n    (file, test, label). Where the label is either 1 if the pair exists in the data or 0 otherwise. The class balance\n    is given by the negative_ratio parameter, if parameter is 1, class balance is 50% each.\n    \"\"\"\n\n    def __init__(self, pairs, nr_files, nr_tests, negative_ratio=1.0, batch_size=10, classification=True, shuffle=True):\n        \"\"\"\n        Data Generator constructor.\n        :param pairs:\n        :param negative_ratio:\n        :param classification:\n        :param shuffle:\n        \"\"\"\n        self.pairs = pairs\n        self.nr_files = nr_files\n        self.nr_tests = nr_tests\n        self.negative_ratio = negative_ratio\n\n        self.batch_size = batch_size\n\n        self.shuffle = shuffle\n        self.classification = classification\n\n        self.on_epoch_end()\n\n    def __len__(self):\n        \"\"\"\n        Steps needed to complete one epoch, i.e. go through the entire dataset\n        :return:\n        \"\"\"\n        return len(self.pairs) \/\/ self.batch_size\n\n    def on_epoch_end(self):\n        \"\"\"\n        When epoch is finished shuffle indexes\n        :return:\n        \"\"\"\n        self.indexes = np.array(list(self.pairs.keys()))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __getitem__(self, index):\n        \"\"\"\n        Returns data generated in one batch\n        :param index:\n        :return:\n        \"\"\"\n        # Generate indexes of the batch\n        index = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        # Find list of IDs\n        batch = [self.pairs[k] for k in index][0]\n        # Generate data\n        X, y = next(self.data_generation(batch))\n        return X, y\n\n    def data_generation(self, pairs):\n        \"\"\"Generate batches of samples for training\"\"\"\n        batch_size = int(len(pairs) * (1 + self.negative_ratio))\n        batch = np.zeros((batch_size, 3))\n        pairs_set = list(set(pairs))\n\n        # Adjust label based on task\n        if self.classification:\n            neg_label = 0\n        else:\n            neg_label = -1\n\n        # This creates a generator\n        while True:\n            for idx, (file_id, test_id) in enumerate(pairs):\n                batch[idx, :] = (file_id, test_id, 1)\n\n            # Increment idx by 1\n            idx += 1\n\n            # Add negative examples until reach batch size\n            while idx < batch_size:\n\n                # random selection\n                random_file = random.sample(pairs, 1)[0][0]\n                # random_test = random.randrange(self.nr_tests) # to select random test\n                random_test = random.randrange(self.nr_tests)\n\n                # Check to make sure this is not a positive example\n                if (random_file, random_test) not in pairs_set:\n                    # Add to batch and increment index\n                    batch[idx, :] = (random_file, random_test, neg_label)\n                    idx += 1\n\n            np.random.shuffle(batch)\n            yield {'file': batch[:, 0], 'test': batch[:, 1]}, batch[:, 2]\n","d823c9b4":"# Parameter Grid\nparam_grid = {'embedding_size': 100,\n               'negative_ratio': 1,\n               'batch_size': 5,\n               'nb_epochs': 10,\n               'classification': True,\n               'optimizer': 'SGD'\n            }","a9c77d2c":"def build_model():\n    \"\"\"\n    Build model architecture\/framework\n    :return: model\n    \"\"\"\n\n    from keras.layers import Input, Embedding, Dot, Reshape, Dense\n    from keras.models import Model\n\n    # Both inputs are 1-dimensional\n    file = Input(name='file', shape=[1])\n    test = Input(name='test', shape=[1])\n\n    # Embedding the book (shape will be (None, 1, 50))\n    file_embedding = Embedding(name='file_embedding',\n                               input_dim=len(file_index),\n                               output_dim=param_grid['embedding_size'])(file)\n\n    # Embedding the link (shape will be (None, 1, 50))\n    test_embedding = Embedding(name='test_embedding',\n                               input_dim=len(test_index),\n                               output_dim=param_grid['embedding_size'])(test)\n\n    # Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))\n    merged = Dot(name='dot_product', normalize=True, axes=2)([file_embedding, test_embedding])\n\n    # Reshape to be a single number (shape will be (None, 1))\n    merged = Reshape(target_shape=[1])(merged)\n\n    # If classification, add extra layer and loss function is binary cross entropy\n    if param_grid['classification']:\n        merged = Dense(1, activation='sigmoid')(merged)\n        model = Model(inputs=[file, test], outputs=merged)\n        model.compile(optimizer=param_grid['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Otherwise loss function is mean squared error\n    else:\n        model = Model(inputs=[file, test], outputs=merged)\n        model.compile(optimizer=param_grid['optimizer'], loss='mse', metrics=['mae'])\n\n    model.summary()\n    return model","836b5f8b":"model = build_model()","29360c39":"from sklearn.model_selection import KFold\n\ndef train_CV(k_folds=5):\n    cv_accuracy_train = []\n    cv_accuracy_val = []\n    cv_loss_train = []\n    cv_loss_val = []\n\n    s = np.array(list(training_data.keys()))\n    kfold = KFold(n_splits=k_folds, shuffle=True)\n    idx = 0\n    for train_idx, val_idx in kfold.split(s):\n        print(\"=========================================\")\n        print(\"====== K Fold Validation step => %d\/%d =======\" % (idx, k_folds))\n        print(\"=========================================\")\n        pairs_train = {s[key]: training_data[s[key]] for key in train_idx}\n        pairs_val = {s[key]: training_data[s[key]] for key in val_idx}\n\n        train_gen = DataGenerator(pairs=pairs_train, batch_size=param_grid['batch_size'],\n                                  nr_files=len(all_files), nr_tests=len(all_tests),\n                                  negative_ratio=param_grid['negative_ratio'])\n\n        val_gen = DataGenerator(pairs=pairs_val, batch_size=param_grid['batch_size'],\n                                nr_files=len(all_files), nr_tests=len(all_tests),\n                                negative_ratio=param_grid['negative_ratio'])\n\n        # Train\n        h = model.fit(train_gen,\n                           validation_data=val_gen,\n                           epochs=param_grid['nb_epochs'],\n                           verbose=2)\n    \n        if param_grid['classification']:\n            cv_accuracy_train.append(np.array(h.history['accuracy'])[-1])\n            cv_accuracy_val.append(np.array(h.history['val_accuracy'])[-1])\n            cv_loss_train.append(np.array(h.history['loss'])[-1])\n            cv_loss_val.append(np.array(h.history['val_loss'])[-1])\n            idx += 1\n            \n        else:\n            cv_accuracy_train.append(np.array(h.history['mae'])[-1])\n            cv_accuracy_val.append(np.array(h.history['val_mae'])[-1])\n            cv_loss_train.append(np.array(h.history['loss'])[-1])\n            cv_loss_val.append(np.array(h.history['val_loss'])[-1])\n            idx += 1\n    \n    cv_results = pd.DataFrame({'acc_train': cv_accuracy_train,\n                       'loss_train': cv_loss_train,\n                       'acc_val': cv_accuracy_val,\n                       'loss_val': cv_loss_val\n                       },\n                      columns=['acc_train', 'loss_train', 'acc_val', 'loss_val'])\n\n    return cv_results","f4b5773d":"cv_results = train_CV()","e0445252":"import matplotlib.pyplot as plt\n\ndef plot_acc_loss(df):\n    plt.rcParams.update({'font.size': 16})\n\n    l = np.array(df['loss_train'])\n    lt = np.array(df['loss_val'])\n    a = np.array(df['acc_train'])\n    at = np.array(df['acc_val'])\n    e = range(len(l))\n\n    fig, ax1 = plt.subplots()\n\n    color = 'tab:red'\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Loss', color=color)\n    ax1.plot(e, l, color=color, lw=2, label='Train')\n    ax1.plot(e, lt, color=color, lw=2, linestyle='--', label='Validation')\n    ax1.tick_params(axis='y', labelcolor='r')\n    ax1.legend(loc='upper right')\n    ax1.grid(None)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\n    color = 'tab:blue'\n    ax2.set_ylabel('Accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(e, a, color=color, lw=2)\n    ax2.plot(e, at, color=color, lw=2, linestyle='--')\n\n    ax2.tick_params(axis='y', labelcolor=color)\n    ax2.grid(None)\n    plt.grid()\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n\n    plt.show()","ff7fda70":"plot_acc_loss(cv_results)","51e2fd6f":"def aptd(commit: int, test_schedule: list):\n    \"\"\"\n    Calculates the Average Percentage of Fault Detection. Given a prioritiation the APFD is near 1, if all relevant\n    tests are applied at the beginning and 0 otherwise.\n    :param prioritization:\n    :return: apfd\n    \"\"\"\n    tests = [v[1] for v in test_data[commit]]\n    labels = []\n    for t in all_tests:\n        if test_index[t] in tests:\n            labels.append(1)\n        else:\n            labels.append(0)\n\n            \n    # Order test labels  \n    prioritization = [labels[i] for i in test_schedule]\n    \n    n = len(prioritization)\n    m = sum(prioritization)\n\n    pos = 0\n    if m != 0:\n        for i in range(n):\n            if prioritization[i] == 1:\n                pos += i\n        return np.round(1 - pos \/ (n * m) + 1 \/ (2 * n),2)\n    else:\n        return None","5c560eaf":"from random import shuffle\nschedule = list(range(0, len(all_tests)))\n\ni=0\nscores=[]\nwhile i<100:\n    scores.append(aptd(commit=297060, test_schedule=schedule))\n    shuffle(schedule)\n    i+=1\n    \nprint(f'Average scores obtained for random orderings - {np.round(np.mean(scores),1)}')","450eee27":"def eval_schedules():\n    aptd_scores = []\n    i=0\n    for k,pairs in test_data.items(): # for each commit\n        files = list(set([f[0] for f in pairs]))\n        preds_per_file = []\n        for f in files: # for each file\n            unseen_pairs = []\n            for t in all_tests:\n                unseen_pairs.append((f, test_index[t]))\n\n            def generate_predictions(pairs, batch_size):\n                batch = np.zeros((batch_size, 2))\n                while True:\n                    for idx, (file_id, test_id) in enumerate(pairs):\n                        batch[idx, :] = (file_id, test_id)\n                    # Increment idx by 1\n                    idx += 1\n                    yield {'file': batch[:, 0], 'test': batch[:, 1]}\n\n            if unseen_pairs:\n                x = next(generate_predictions(unseen_pairs, len(unseen_pairs)))\n                preds_per_file.append(model.predict(x).flatten())\n\n        pred = [max(idx) for idx in zip(*preds_per_file)]  # return maximum score of test \n        test_schedule = np.argsort(-np.asarray(pred))\n\n        aptd_scores.append(aptd(commit=k, test_schedule=test_schedule))  # calculate apfd\n        print(f'APTD -> {aptd(commit=k, test_schedule=test_schedule)}', flush=True)\n        \n    return aptd_scores","5bbe3287":"aptd_scores = eval_schedules()","11d07f5f":"import seaborn as sns\n\ndef plot_single(aptd):\n    \"\"\"\n    APFD plot for single Embedding Neural Network model\n    :param df_metrics:\n    :return:\n    \"\"\"\n    plt.rcParams.update({'font.size': 18})\n\n    miu = np.round(np.mean(aptd), 2)\n    sigma = np.round(np.std(aptd), 2)\n    label = 'Regression:\\n ' + 'APTD $=$ ' + str(miu) +'0'  + ' $ \\pm $' + str(sigma)\n\n    sns.distplot(aptd, kde=True,\n                 bins=int(180 \/ 5), color=sns.color_palette()[0],\n                 hist_kws={'edgecolor': 'black'},\n                 kde_kws={'linewidth': 4, 'clip': (0.0, 1.0)}, label=label)\n\n    plt.grid()\n    plt.xlabel('APTD')\n    plt.rcParams.update({'font.size': 14})\n\n    plt.legend(frameon=True, loc='upper left')\n    plt.tight_layout()\n\n    # plt.title('APFD Distribution - 100 revisions ')\n    plt.show()","c1569302":"plot_single(aptd_scores)","b0571bfe":"# Data Cleaning\n\nBecause we generated pairs based on pairwise combinations, it is likely that some pairs pose themselves as \"false positive\" or they were created by chance.\n\nTo reduce this tendency we can remove less frequent pairs, by a given threshold.\n\n","f15c460c":"# Predict Meaningful Test Schedules\n\nOur embeddings are trained, the next step is to formulate test schedules based on the relations test have with the files modified in a certain commit. \n\nASSUMPTION: Let's assume that every test has to be run in a commit. What we want is to prioritize the more relevant ones at the top of the test schedule. \n\nTo evaluate new test schedules, we use the Average Percentage of Transition Detection (APTD), that ranges from 0 to 1. If all relevant tests are applied at the beginning, then APTD=1, if all relevant tests are applied at the very end of the schedule, APTD=0. \n\nSo let's define the APTD metric.","91a734d3":"Now we have to encode the strings for files and tests to integers.","60a2f64e":"# Data Visualisation","b59ba7a7":"# Create a Training Set\n\nOur model has to able to perform the following Supervised Learning Task: given a file and test pair determine if whether or not that pair is linked, so the input will be of the form: (file, test, label). The label is positive if the pair is present in the data and negative if it is not.\n\nTo create a training set we resort to the Keras Class - DataGenerator(), that we will implement below:\n\n- Negative_Ratio: proportionality of negative samples vs. positive samples. If negative_ratio=1, proportion is 50\/50. If it is equal to 2, there are twice as many negative samples, and so on.\n- batch_size: number of commits processed before updating the network weights.\n- Classification: if true, else Regression.\n- shuffle: if True, shuffle samples in batch.\n","044ea05f":"# Data Preparation\n\n\nNow we need to create the input of our Machine Learning model, that will be pairs of the form (file, test).","3d7789ac":"# Identifying File-Test Links\n\nThis notebook tries to find links\/connections between the files that were modified in a commit with the test that were affected by those modifications, i.e. tests that were passing and are now failing (regressions) or tests that were failing and are now passing (progression). \n\nLet's assume that in a commit, all tests from the system are run against it. This becomes a problem when teams and project grow, so this solution does not scale. \n\nOur intent is to find out as soon as possible, which tests are more likely to be affected in a given commit, such that, if there is a problem with a commit, the developer can quickly have an estimate on its status and, if that is the case, ammend the defective commit quickly. \n\nThe details of the this problem can be found in this free-access paper: \n\nhttps:\/\/arxiv.org\/abs\/2012.10154\n\nIn this notebook, I propose a solution using Neural Network Embeddings to classify (file, test) pairs as linked or not. \n\nFeel free to make comments, discuss the problem and submit your own solutions, because in fact, this is a very open problem with many solutions. ","0dbc4c0a":"## Split data intro train and test","ccaf0caf":"Average value for APTD = 0.6 which is not bad ! Random prioritizations yield an average APTD of 0.5, so definetely an improvement. \n\n\n\nTry your own models and try to achieve higher results of APTD.\n\n\n\n","863deea5":"The result is a dictionary where the keys are the commit ID's and the values are pair-wise combinations of the files and tests. ","bd8cf4d8":"# Create Test Set\n\nTo create the test Set, we need to pair each file with every test and then collecting the maximum likelihood of that test being linked to any of the modified files, resulting in the final test schedule that will be evaluated by the APTD.","ebb09cf8":"Sanity Check: This results is expected, random ordering will eventually evenly spread out relevant tests.","46cc4b29":"# Modelling\n\nNow we can create our Machine Learning Model based on Neural Network Embeddings. \n\n","151ce4ee":"# Get the Data"}}