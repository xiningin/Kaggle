{"cell_type":{"e0ef975b":"code","d4528070":"code","4348c981":"code","a397eae1":"code","794bb324":"code","abfdf4ac":"code","4c6c799c":"code","02f32285":"code","776b6e01":"code","04acaade":"code","17e25185":"code","09afd4f4":"code","64c08209":"code","88d0a319":"code","6374c6b8":"code","a50cd143":"code","d925d9d0":"code","f1b48f66":"code","d04aa16b":"code","1991e652":"code","8cda2e49":"code","e331dfe2":"code","21f4458f":"code","e95a0e2d":"code","f3e74a85":"code","dac47c8f":"code","f970fdf2":"code","3aa68aad":"code","72f37385":"code","3d90c2f2":"code","51e5c7c3":"code","8d2f6731":"code","f56edb45":"code","cc2fc32c":"code","ce6cd1e7":"code","c5c46cb5":"code","4163d63d":"code","03712695":"code","58bfeea0":"code","a29db89b":"code","ffd50ea9":"code","3f53bf4d":"code","2f476bb3":"code","41a23b5f":"code","72993af6":"code","89f9b956":"code","cf6b5cd0":"code","421d9e20":"code","7d46aa21":"code","a3891c65":"code","d2054b45":"code","4d5263fa":"code","c85c5206":"code","afff9f47":"code","4ec4063f":"code","24606cd2":"code","df356387":"code","1f9a50bf":"code","18ae7176":"code","ed9ec072":"code","e81f224d":"code","b398511b":"code","1639cc8d":"code","8d04a900":"code","706171e4":"code","40aeb334":"code","1de99ae9":"markdown","2aa4419f":"markdown","6524f80b":"markdown","28eacf5a":"markdown","e9216087":"markdown","8e8582e2":"markdown","fa56e3da":"markdown","98581d6f":"markdown","551e73c7":"markdown","d692e630":"markdown","8f05229d":"markdown","bb2a9b7c":"markdown","e6adb0a7":"markdown","b5660f4a":"markdown","2848cfbe":"markdown","daeba589":"markdown","326809f9":"markdown","6fd98273":"markdown","94443883":"markdown","b07e6d4f":"markdown","5fb7371a":"markdown","d8477547":"markdown","4fecc40e":"markdown","3cac71fe":"markdown","d3a0bfbc":"markdown","167c3284":"markdown","0c8017f8":"markdown","5a17c7ed":"markdown","8f6d042e":"markdown","77244a65":"markdown"},"source":{"e0ef975b":"import os\nimport time\nimport math\nimport warnings\nimport numpy as np\nimport pandas as pd\n#import tensorflow as tf\nimport matplotlib.pyplot as plt\n\n#print(tf.__version__)\n","d4528070":"EPS = 0.00001   #-5dB","4348c981":"MAIN_DIR = '..\/input\/seti-breakthrough-listen'\nTRAIN_DIR = '..\/input\/seti-breakthrough-listen\/train'\nSUB_DIR = '..\/input\/seti-breakthrough-listen\/test'","a397eae1":"train_df = pd.read_csv(os.path.join(MAIN_DIR, 'train_labels.csv'))\ntest_df = pd.read_csv(os.path.join(MAIN_DIR, 'sample_submission.csv'))","794bb324":"def return_filpath(name, folder=TRAIN_DIR):\n    path = os.path.join(folder, name[0], f'{name}.npy')\n    return path\n\ntrain_df['image_path'] = train_df['id'].apply(lambda x: return_filpath(x))\ntest_df['image_path'] = test_df['id'].apply(lambda x: return_filpath(x, folder=SUB_DIR))\n\ndf_0     = train_df[train_df['target']==0]\ndf_1     = train_df[train_df['target']==1]","abfdf4ac":"len(df_0)","4c6c799c":"avg_sample = 10001 #debug, should use full available datas","02f32285":"avg_df1 =np.zeros((6,273,256), dtype = np.float32)  #max_32bit = 2**31-1\nmax_31bit = 2**30-1\n\nfor i,fn in enumerate(df_1.image_path[:avg_sample]):\n    spec   = np.load(fn)                           #6x273x256\n    \n    for k in range( len(avg_df1) ):\n        if i == 0:\n            avg_df1[k,] = spec[k,]\n\n        else:\n            #intensity is in 16bits\n            avg_df1[k,] = avg_df1[k,] + spec[k,]  #32bit accumulator=16bit+log2(train_df.shape[0])= 16+15.6 = 31.6bits\n\n        if(i%2000 == 0):\n            dat_min=np.min(avg_df1[k,])\n            dat_max=np.max(avg_df1[k,])\n            print(k, dat_min, dat_max)\n\n            if (np.abs(dat_max) > max_31bit):\n                print(k,'close to overflow')\n    \navg_df1 = avg_df1\/(i+1)","776b6e01":"np.min(np.min(avg_df1,axis=1), axis=1)","04acaade":"np.max(np.max(avg_df1,axis=1), axis=1)","17e25185":"pos_df1 =np.zeros((6,273,256), dtype = np.float32)\n\npos_df1[0,] = avg_df1[0,]- np.min(avg_df1[0,])\npos_df1[1,] = avg_df1[1,]- np.min(avg_df1[1,])\npos_df1[2,] = avg_df1[2,]- np.min(avg_df1[2,])\npos_df1[3,] = avg_df1[3,]- np.min(avg_df1[3,])\npos_df1[4,] = avg_df1[4,]- np.min(avg_df1[4,])\npos_df1[5,] = avg_df1[5,]- np.min(avg_df1[5,])","09afd4f4":"np.min(np.min(pos_df1,axis=1), axis=1), np.max(np.max(pos_df1,axis=1), axis=1)","64c08209":"def plot_avg_noise(data, avg=True):\n    fig, ax = plt.subplots(nrows=1,ncols=3,figsize=(24, 5)) \n    ax[0].plot(np.log(np.sum(data, axis=0)+EPS))\n    ax[1].imshow( np.log(data+EPS).T, aspect = 0.5*float(data.shape[1]) \/ data.shape[0])\n    ax[2].plot(np.log(np.sum(data.T, axis=0)+EPS))\n\n    ax[0].set_xlabel('freq (bins)')\n    ax[0].set_ylabel('intensity (x10 dB)')\n    ax[0].set_title('power spec across freq')\n    \n    ax[1].set_xlabel('time (segments) ')\n    ax[1].set_ylabel('freq (bins)')\n    if avg:\n        ax[1].set_title('avg S+N spec (x10 dB)')\n    else:\n        ax[1].set_title('S+N spec (x10 dB)')\n        \n    ax[2].set_xlabel('time (segments) ')\n    ax[2].set_ylabel('intensity (x10 dB)')\n    ax[2].set_title('power spec across time')","88d0a319":"#plot_avg_noise(pos_df1[0,])  #A0\n#plot_avg_noise(pos_df1[1,])  #B\nplot_avg_noise(pos_df1[2,])  #A1\n#plot_avg_noise(pos_df1[3,])  #C\n#plot_avg_noise(pos_df1[4,])  #A2\n#plot_avg_noise(pos_df1[5,])  #D","6374c6b8":"avg_df0 =np.zeros((6,273,256), dtype = np.float32)  #max_32bit = 2**31-1\nmax_31bit = 2**30-1\n\nfor i,fn in enumerate(df_0.image_path[:avg_sample]):\n    spec   = np.load(fn)                           #6x273x256\n    \n    for k in range( len(avg_df0) ):\n        if i == 0:\n            avg_df0[k,] = spec[k,]\n\n        else:\n            #intensity is in 16bits\n            avg_df0[k,] = avg_df0[k,] + spec[k,]  #32bit accumulator=16bit+log2(train_df.shape[0])= 16+15.6 = 31.6bits\n\n        if(i%2000 == 0):\n            dat_min=np.min(avg_df0[k,])\n            dat_max=np.max(avg_df0[k,])\n            print(k, dat_min, dat_max)\n\n            if (np.abs(dat_max) > max_31bit):\n                print(k,'close to overflow')\n    \navg_df0 = avg_df0\/(i+1)","a50cd143":"pos_df0 =np.zeros((6,273,256), dtype = np.float32)\n\npos_df0[0,] = avg_df0[0,]- np.min(avg_df0[0,])\npos_df0[1,] = avg_df0[1,]- np.min(avg_df0[1,])\npos_df0[2,] = avg_df0[2,]- np.min(avg_df0[2,])\npos_df0[3,] = avg_df0[3,]- np.min(avg_df0[3,])\npos_df0[4,] = avg_df0[4,]- np.min(avg_df0[4,])\npos_df0[5,] = avg_df0[5,]- np.min(avg_df0[5,])","d925d9d0":"#plot_avg_noise(pos_df0[0,])  #A0\n#plot_avg_noise(pos_df0[1,])  #B\nplot_avg_noise(pos_df0[2,])   #A1\n#plot_avg_noise(pos_df0[3,])  #C\n#plot_avg_noise(pos_df0[4,])  #A2\n#plot_avg_noise(pos_df0[5,])  #D\n","f1b48f66":"pos_df_trn =np.zeros((6,273,256), dtype = np.float32)  \npos_df_trn = (pos_df0 + pos_df1)\/2","d04aa16b":"#plot_avg_noise(pos_df_trn[0,])  #A0\n#plot_avg_noise(pos_df_trn[1,])  #B\nplot_avg_noise(pos_df_trn[2,])  #A1\n#plot_avg_noise(pos_df_trn[3,])  #C\n#plot_avg_noise(pos_df_trn[4,])  #A2\n#plot_avg_noise(pos_df_trn[5,])  #D\n","1991e652":"avg_df_test =np.zeros((6,273,256), dtype = np.float32)  #max_32bit = 2**31-1\nmax_31bit = 2**30-1\n\nfor i,fn in enumerate(test_df.image_path[:avg_sample]):\n    spec   = np.load(fn)                           #6x273x256\n    \n    for k in range( len(avg_df_test) ):\n        if i == 0:\n            avg_df1[k,] = spec[k,]\n\n        else:\n            #intensity is in 16bits\n            avg_df_test[k,] = avg_df_test[k,] + spec[k,]  #32bit accumulator=16bit+log2(train_df.shape[0])= 16+15.6 = 31.6bits\n\n        if(i%2000 == 0):\n            dat_min=np.min(avg_df_test[k,])\n            dat_max=np.max(avg_df_test[k,])\n            print(k, dat_min, dat_max)\n\n            if (np.abs(dat_max) > max_31bit):\n                print(k,'close to overflow')\n    \navg_df_test = avg_df_test\/(i+1)","8cda2e49":"pos_df_tst =np.zeros((6,273,256), dtype = np.float32)\n\npos_df_tst[0,] = avg_df_test[0,]- np.min(avg_df_test[0,])\npos_df_tst[1,] = avg_df_test[1,]- np.min(avg_df_test[1,])\npos_df_tst[2,] = avg_df_test[2,]- np.min(avg_df_test[2,])\npos_df_tst[3,] = avg_df_test[3,]- np.min(avg_df_test[3,])\npos_df_tst[4,] = avg_df_test[4,]- np.min(avg_df_test[4,])\npos_df_tst[5,] = avg_df_test[5,]- np.min(avg_df_test[5,])","e331dfe2":"plot_avg_noise(pos_df_tst[0,])  #A0","21f4458f":"plot_avg_noise(pos_df_tst[1,])  #B","e95a0e2d":"plot_avg_noise(pos_df_tst[2,])  #A1","f3e74a85":"plot_avg_noise(pos_df_tst[3,])  #C","dac47c8f":"plot_avg_noise(pos_df_tst[4,])  #A2","f970fdf2":"plot_avg_noise(pos_df_tst[5,])  #D","3aa68aad":"#Comparing Test ['A0','B','A1','C','A2','D']\nfig, ax = plt.subplots(nrows=1,ncols=2,figsize=(24, 5)) \n#across time\nax[0].plot(np.log(np.sum(pos_df_tst[0,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df_tst[1,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df_tst[2,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df_tst[3,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df_tst[4,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df_tst[5,].T, axis=0)+EPS))\n#across freq\nax[1].plot(np.log(np.sum(pos_df_tst[0,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df_tst[1,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df_tst[2,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df_tst[3,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df_tst[4,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df_tst[5,], axis=0)+EPS))\n\nax[1].set_xlabel('freq (bins)')\nax[1].set_ylabel('intensity (x10 dB)')\nax[1].set_title('power spec across freq')\nax[1].legend(['A0','B','A1','C','A2','D'])\n\nax[0].set_xlabel('time (segments)')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across time')\nax[0].legend(['A0','B','A1','C','A2','D'])","72f37385":"#Target = 0\n#across time\nfig, ax = plt.subplots(nrows=1,ncols=2,figsize=(24, 5)) \nax[0].plot(np.log(np.sum(pos_df0[0,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df0[1,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df0[2,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df0[3,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df0[4,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df0[5,].T, axis=0)+EPS))\n#across freq\nax[1].plot(np.log(np.sum(pos_df0[0,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[1,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[2,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[3,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[4,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[5,], axis=0)+EPS))\n\nax[1].set_xlabel('freq (bins)')\nax[1].set_ylabel('intensity (x10 dB)')\nax[1].set_title('power spec across freq')\nax[1].legend(['A0','B','A1','C','A2','D'])\n\nax[0].set_xlabel('time (segments)')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across time')\nax[0].legend(['A0','B','A1','C','A2','D'])","3d90c2f2":"#Target = 1\nfig, ax = plt.subplots(nrows=1,ncols=2,figsize=(24, 5)) \n#across time\nax[0].plot(np.log(np.sum(pos_df1[0,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df1[1,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df1[2,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df1[3,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df1[4,].T, axis=0)+EPS))\nax[0].plot(np.log(np.sum(pos_df1[5,].T, axis=0)+EPS))\n#across freq\nax[1].plot(np.log(np.sum(pos_df1[0,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[1,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[2,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[3,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[4,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[5,], axis=0)+EPS))\n\nax[1].set_xlabel('freq (bins)')\nax[1].set_ylabel('intensity (x10 dB)')\nax[1].set_title('power spec across freq')\nax[1].legend(['A0','B','A1','C','A2','D'])\n\nax[0].set_xlabel('time (segments)')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across time')\nax[0].legend(['A0','B','A1','C','A2','D'])","51e5c7c3":"#Across time\n#Train, Target 0 vs Target 1\nfig, ax = plt.subplots(nrows=1,ncols=6,figsize=(24, 5)) \n#across time\n#df1\nax[0].plot(np.log(np.sum(pos_df1[0,].T, axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[1,].T, axis=0)+EPS))\nax[2].plot(np.log(np.sum(pos_df1[2,].T, axis=0)+EPS))\nax[3].plot(np.log(np.sum(pos_df1[3,].T, axis=0)+EPS))\nax[4].plot(np.log(np.sum(pos_df1[4,].T, axis=0)+EPS))\nax[5].plot(np.log(np.sum(pos_df1[5,].T, axis=0)+EPS))\n#df0\nax[0].plot(np.log(np.sum(pos_df0[0,].T, axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[1,].T, axis=0)+EPS))\nax[2].plot(np.log(np.sum(pos_df0[2,].T, axis=0)+EPS))\nax[3].plot(np.log(np.sum(pos_df0[3,].T, axis=0)+EPS))\nax[4].plot(np.log(np.sum(pos_df0[4,].T, axis=0)+EPS))\nax[5].plot(np.log(np.sum(pos_df0[5,].T, axis=0)+EPS))\n\nax[0].set_xlabel('time (segments)')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across time')\nax[0].legend(['A0-df1','A0-df0'])\nax[1].legend(['B-df1','B-df0'])\nax[2].legend(['A1-df1','A1-df0'])\nax[3].legend(['C-df1','C-df0'])\nax[4].legend(['A2-df1','A2-df0'])\nax[5].legend(['D-df1','D-df0'])","8d2f6731":"#Across freq\n#Train, Target 0 vs Target 1\nfig, ax = plt.subplots(nrows=1,ncols=6,figsize=(24, 5)) \n#df1\nax[0].plot(np.log(np.sum(pos_df1[0,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df1[1,], axis=0)+EPS))\nax[2].plot(np.log(np.sum(pos_df1[2,], axis=0)+EPS))\nax[3].plot(np.log(np.sum(pos_df1[3,], axis=0)+EPS))\nax[4].plot(np.log(np.sum(pos_df1[4,], axis=0)+EPS))\nax[5].plot(np.log(np.sum(pos_df1[5,], axis=0)+EPS))\n#df0\nax[0].plot(np.log(np.sum(pos_df0[0,], axis=0)+EPS))\nax[1].plot(np.log(np.sum(pos_df0[1,], axis=0)+EPS))\nax[2].plot(np.log(np.sum(pos_df0[2,], axis=0)+EPS))\nax[3].plot(np.log(np.sum(pos_df0[3,], axis=0)+EPS))\nax[4].plot(np.log(np.sum(pos_df0[4,], axis=0)+EPS))\nax[5].plot(np.log(np.sum(pos_df0[5,], axis=0)+EPS))\n\nax[0].set_xlabel('freq (bins)')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across freq')\nax[0].legend(['A0-df1','A0-df0'])\nax[1].legend(['B-df1','B-df0'])\nax[2].legend(['A1-df1','A1-df0'])\nax[3].legend(['C-df1','C-df0'])\nax[4].legend(['A2-df1','A2-df0'])\nax[5].legend(['D-df1','D-df0'])","f56edb45":"#Target = 1\n#(t,f,i) = (time, freq, intensity)\narr = np.load('..\/input\/seti-breakthrough-listen\/train\/5\/54e340be921d.npy').astype(np.float32)  #narrowband,A0(f80,i48), dc spike(f90,i70)\n\n#A2(f160) doppler overlapped with dc spike at f160 + bright pixels noises.  maybe multi signals bright pixel A1(f105)->A2(f110)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/099e8de5c54a.npy').astype(np.float32)  #not bright pixel, narrow band\n\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0689caff3aab.npy').astype(np.float32)  #blank, un-visible, A1 \n\n\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0f6dda0952ea.npy').astype(np.float32)  #narowband,A0,A1,A2(f125,i55dB-52dB)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/2\/20b6bba77e00.npy').astype(np.float32)  #narrowband,A0,A1,A2(f125,i57dB-60dB)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/8\/87cca65ea82e.npy').astype(np.float32)  #square pulse narrowband, A2(f160,i60dB)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/09cd074d5b1c.npy').astype(np.float32)  #squiggle square pulse narrowband A0(t170,f168,i67), A2(f180,i72)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0cb54f44a200.npy').astype(np.float32)  #squiggle square pulse narrowband\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/1\/15af5fff3abb.npy').astype(np.float32)  #squiggle square pulse narrowband, A2(f40)\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0fe5c29a86b0.npy').astype(np.float32)  #square pulse narrowband\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/1\/118a3d42b310.npy').astype(np.float32)  #square pulse narrowband\n#arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0b4b11cd4692.npy').astype(np.float32)  #square pulse narrowband\n\n\n#https:\/\/www.kaggle.com\/tomooinubushi\/easter-egg-detection-with-template-matching\n#all eggs are periodic, have no doppler shift and target are ones.  Got to think a little harder.\n#almost all eggs are hiding at the low freq band edge and have some kind of hiding pattern.\n\negg_paths=['..\/input\/seti-breakthrough-listen\/train\/2\/2503d7f6e5c4.npy', #kaggle (t20,f20)\n           '..\/input\/seti-breakthrough-listen\/train\/8\/805a7f4cac38.npy', #kaggle (t70,f50) \n           '..\/input\/seti-breakthrough-listen\/test\/e\/e05a5e667d06.npy',  #kaggle (t120,f80)\n           '..\/input\/seti-breakthrough-listen\/test\/1\/1397c4ab0e5c.npy',  #alien (t10,f50)\n           '..\/input\/seti-breakthrough-listen\/train\/4\/4f7bb8cf2d15.npy', #alien (t60,f80)\n           '..\/input\/seti-breakthrough-listen\/test\/1\/1725ceec6de4.npy',  #alien (t110,f110)\n           '..\/input\/seti-breakthrough-listen\/test\/7\/72bc12d576e2.npy',  #rocket (t10,f20)\n           '..\/input\/seti-breakthrough-listen\/train\/6\/6c12bab0aeb4.npy', #rocket (t60,f50)\n           '..\/input\/seti-breakthrough-listen\/test\/1\/1e6e43ddc15a.npy']  #rocket (t110,f80)\n             \n\negg_ids=['2503d7f6e5c4', \n        '805a7f4cac38', \n        'e05a5e667d06', \n        '1397c4ab0e5c', \n        '4f7bb8cf2d15', \n        '1725ceec6de4', \n        '72bc12d576e2', \n        '6c12bab0aeb4', \n        '1e6e43ddc15a']\n\n\n#arr = np.load(egg_paths[7]).astype(np.float32)  #\n\n#fn='2503d7f6e5c4'\n#fn='0689caff3aab'\n#train_df[train_df['id']==fn].target","cc2fc32c":"arr_pos =np.zeros((6,273,256), dtype = np.float32) \n\n#remove negative value (linear scale)\narr_pos[0,] = arr[0,]- np.min(arr[0,])\narr_pos[1,] = arr[1,]- np.min(arr[1,])\narr_pos[2,] = arr[2,]- np.min(arr[2,])\narr_pos[3,] = arr[3,]- np.min(arr[3,])\narr_pos[4,] = arr[4,]- np.min(arr[4,])\narr_pos[5,] = arr[5,]- np.min(arr[5,])","ce6cd1e7":"plot_avg_noise(arr_pos[0,], avg=False)  #A0","c5c46cb5":"plot_avg_noise(arr_pos[1,], avg=False)  #B","4163d63d":"plot_avg_noise( arr_pos[2,:,:], avg=False )  #A1","03712695":"plot_avg_noise(arr_pos[3,], avg=False)  #C","58bfeea0":"plot_avg_noise(arr_pos[4,], avg=False)  #A2","a29db89b":"plot_avg_noise(arr_pos[5,], avg=False)  #D","ffd50ea9":"# Remove the noise\ndata_clean =np.zeros((6,273,256), dtype = np.float32) \n\ndata_clean = arr_pos - pos_df0   #pos_df0 contains only N_bg  \ndata_clean[data_clean < 0] = 0.00001   #-5dB","3f53bf4d":"np.min(data_clean), np.min(arr_pos)","2f476bb3":"fig, ax = plt.subplots(nrows=2,ncols=6,figsize=(24,4)) \n\n#original imag\nax[0,0].imshow(np.log(arr_pos[0,]+EPS).T, aspect = 0.5*float(arr_pos[0,].shape[1]) \/ arr_pos[0,].shape[0]) #, cmap=\"gray\")\nax[0,1].imshow(np.log(arr_pos[1,]+EPS).T, aspect = 0.5*float(arr_pos[1,].shape[1]) \/ arr_pos[1,].shape[0]) #, cmap=\"gray\")\nax[0,2].imshow(np.log(arr_pos[2,]+EPS).T, aspect = 0.5*float(arr_pos[2,].shape[1]) \/ arr_pos[2,].shape[0]) #, cmap=\"gray\")\nax[0,3].imshow(np.log(arr_pos[3,]+EPS).T, aspect = 0.5*float(arr_pos[3,].shape[1]) \/ arr_pos[3,].shape[0]) #, cmap=\"gray\")\nax[0,4].imshow(np.log(arr_pos[4,]+EPS).T, aspect = 0.5*float(arr_pos[4,].shape[1]) \/ arr_pos[4,].shape[0]) #, cmap=\"gray\")\nax[0,5].imshow(np.log(arr_pos[5,]+EPS).T, aspect = 0.5*float(arr_pos[5,].shape[1]) \/ arr_pos[5,].shape[0]) #, cmap=\"gray\")\n#removed noise imag\nax[1,0].imshow(np.log(data_clean[0,]+EPS).T, aspect = 0.5*float(data_clean[0,].shape[1]) \/ data_clean[0,].shape[0]) #, cmap=\"gray\")\nax[1,1].imshow(np.log(data_clean[1,]+EPS).T, aspect = 0.5*float(data_clean[1,].shape[1]) \/ data_clean[1,].shape[0]) #, cmap=\"gray\")\nax[1,2].imshow(np.log(data_clean[2,]+EPS).T, aspect = 0.5*float(data_clean[2,].shape[1]) \/ data_clean[2,].shape[0]) #, cmap=\"gray\")\nax[1,3].imshow(np.log(data_clean[3,]+EPS).T, aspect = 0.5*float(data_clean[3,].shape[1]) \/ data_clean[3,].shape[0]) #, cmap=\"gray\")\nax[1,4].imshow(np.log(data_clean[4,]+EPS).T, aspect = 0.5*float(data_clean[4,].shape[1]) \/ data_clean[4,].shape[0]) #, cmap=\"gray\")\nax[1,5].imshow(np.log(data_clean[5,]+EPS).T, aspect = 0.5*float(data_clean[5,].shape[1]) \/ data_clean[5,].shape[0]) #, cmap=\"gray\")ax[1].set_xlabel('time')\n\nax[1,0].set_xlabel('time (segments)')\nax[1,0].set_ylabel('freq (bins))')\nax[1,0].set_title('spec A0')\nax[1,1].set_title('spec B')\nax[1,2].set_title('spec A1')\nax[1,3].set_title('spec C')\nax[1,4].set_title('spec A2')\nax[1,5].set_title('spec D')","41a23b5f":"#Visualize across time\n\nfig, ax = plt.subplots(nrows=1,ncols=6,figsize=(24, 5)) \nax[0].plot(np.log(np.sum(arr_pos[0,].T, axis=0)+EPS),'b')    #S+N\nax[0].plot(np.log(np.sum(pos_df0[0,].T, axis=0)+EPS),'b--')  #avg target 0 as background noise\nax[0].plot(np.log(np.sum(pos_df_trn[0,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[0].plot(np.log(np.sum(pos_df_tst[0,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[0].plot(np.log(np.sum(data_clean[0,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[1].plot(np.log(np.sum(arr_pos[1,].T, axis=0)+EPS),'b')    #S+N\nax[1].plot(np.log(np.sum(pos_df0[1,].T, axis=0)+EPS),'b--')  #avg\nax[1].plot(np.log(np.sum(pos_df_trn[1,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[1].plot(np.log(np.sum(pos_df_tst[1,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[1].plot(np.log(np.sum(data_clean[1,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[2].plot(np.log(np.sum(arr_pos[2,].T, axis=0)+EPS),'b')    #S+N\nax[2].plot(np.log(np.sum(pos_df0[2,].T, axis=0)+EPS),'b--')  #avg\nax[2].plot(np.log(np.sum(pos_df_trn[2,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[2].plot(np.log(np.sum(pos_df_tst[2,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[2].plot(np.log(np.sum(data_clean[2,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[3].plot(np.log(np.sum(arr_pos[3,].T, axis=0)+EPS),'b')    #S+N\nax[3].plot(np.log(np.sum(pos_df0[3,].T, axis=0)+EPS),'b--')  #avg\nax[3].plot(np.log(np.sum(pos_df_trn[3,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[3].plot(np.log(np.sum(pos_df_tst[3,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[3].plot(np.log(np.sum(data_clean[3,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[4].plot(np.log(np.sum(arr_pos[4,].T, axis=0)+EPS),'b')    #S+N\nax[4].plot(np.log(np.sum(pos_df0[4,].T, axis=0)+EPS),'b--')  #avg\nax[4].plot(np.log(np.sum(pos_df_trn[4,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[4].plot(np.log(np.sum(pos_df_tst[4,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[4].plot(np.log(np.sum(data_clean[4,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[5].plot(np.log(np.sum(arr_pos[5,].T, axis=0)+EPS),'b')    #S+N\nax[5].plot(np.log(np.sum(pos_df0[5,].T, axis=0)+EPS),'b--')  #avg\nax[5].plot(np.log(np.sum(pos_df_trn[5,].T, axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[5].plot(np.log(np.sum(pos_df_tst[5,].T, axis=0)+EPS),'c--')  #avg tran target= unknown\nax[5].plot(np.log(np.sum(data_clean[5,].T, axis=0)+EPS),'r')  #S+N - avg\n\nax[0].set_xlabel('time (segments))')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across time')\n\nax[0].legend(['A0','avg_df0 A0','avg_trn A0','avg_tst A0','A0-avg_df0 A0'])\nax[1].legend(['B','avg_df0 B'])\nax[2].legend(['A1','avg_df0 A1'])\nax[3].legend(['C','avg_df0 C'])\nax[4].legend(['A2','avg_df0 A2'])\nax[5].legend(['D','avg_df0 D'])","72993af6":"#Visualize across freq\n\nfig, ax = plt.subplots(nrows=1,ncols=6,figsize=(24, 5)) \nax[0].plot(np.log(np.sum(arr_pos[0,], axis=0)+EPS),'b')    #S+N\nax[0].plot(np.log(np.sum(pos_df0[0,], axis=0)+EPS),'b--')  #avg target 1\nax[0].plot(np.log(np.sum(pos_df_trn[0,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[0].plot(np.log(np.sum(pos_df_tst[0,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[0].plot(np.log(np.sum(data_clean[0,], axis=0)+EPS),'r')  #S+N - avg\n\nax[1].plot(np.log(np.sum(arr_pos[1,], axis=0)+EPS),'b')    #S+N\nax[1].plot(np.log(np.sum(pos_df0[1,], axis=0)+EPS),'b--')  #avg\nax[1].plot(np.log(np.sum(pos_df_trn[1,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[1].plot(np.log(np.sum(pos_df_tst[1,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[1].plot(np.log(np.sum(data_clean[1,], axis=0)+EPS),'r')  #S+N - avg\n\nax[2].plot(np.log(np.sum(arr_pos[2,], axis=0)+EPS),'b')    #S+N\nax[2].plot(np.log(np.sum(pos_df0[2,], axis=0)+EPS),'b--')  #avg\nax[2].plot(np.log(np.sum(pos_df_trn[2,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[2].plot(np.log(np.sum(pos_df_tst[2,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[2].plot(np.log(np.sum(data_clean[2,], axis=0)+EPS),'r')  #S+N - avg\n\nax[3].plot(np.log(np.sum(arr_pos[3,], axis=0)+EPS),'b')    #S+N\nax[3].plot(np.log(np.sum(pos_df0[3,], axis=0)+EPS),'b--')  #avg\nax[3].plot(np.log(np.sum(pos_df_trn[3,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[3].plot(np.log(np.sum(pos_df_tst[3,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[3].plot(np.log(np.sum(data_clean[3,], axis=0)+EPS),'r')  #S+N - avg\n\nax[4].plot(np.log(np.sum(arr_pos[4,], axis=0)+EPS),'b')    #S+N\nax[4].plot(np.log(np.sum(pos_df0[4,], axis=0)+EPS),'b--')  #avg\nax[4].plot(np.log(np.sum(pos_df_trn[4,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[4].plot(np.log(np.sum(pos_df_tst[4,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[4].plot(np.log(np.sum(data_clean[4,], axis=0)+EPS),'r')  #S+N - avg\n\nax[5].plot(np.log(np.sum(arr_pos[5,], axis=0)+EPS),'b')    #S+N\nax[5].plot(np.log(np.sum(pos_df0[5,], axis=0)+EPS),'b--')  #avg\nax[5].plot(np.log(np.sum(pos_df_trn[5,], axis=0)+EPS),'g--')  #avg tran target= combined(0 & 1)\nax[5].plot(np.log(np.sum(pos_df_tst[5,], axis=0)+EPS),'c--')  #avg tran target= unknown\nax[5].plot(np.log(np.sum(data_clean[5,], axis=0)+EPS),'r')  #S+N - avg\n\nax[0].set_xlabel('freq (bins))')\nax[0].set_ylabel('intensity (x10 dB)')\nax[0].set_title('power spec across freq')\n\nax[0].legend(['A0','avg_df0 A0','avg_trn A0','avg_tst A0','A0-avg_df0 A0'])\nax[1].legend(['B','avg_df0 B'])\nax[2].legend(['A1','avg_df0 A1'])\nax[3].legend(['C','avg_df0 C'])\nax[4].legend(['A2','avg_df0 A2'])\nax[5].legend(['D','avg_df0 D'])","89f9b956":"def plot_no_bckgnd(data_clean):    \n    fig, ax = plt.subplots(nrows=2,ncols=3,figsize=(24, 10)) \n    #Visualize across time\n    ax[0,0].plot(np.log(np.sum(data_clean[0,].T, axis=0)+EPS),'b')  #S+N - avg\n    ax[0,0].plot(np.log(np.sum(data_clean[1,].T, axis=0)+EPS),'r--')  #S+N - avg\n    ax[0,1].plot(np.log(np.sum(data_clean[2,].T, axis=0)+EPS),'b')  #S+N - avg\n    ax[0,1].plot(np.log(np.sum(data_clean[3,].T, axis=0)+EPS),'g--')  #S+N - avg\n    ax[0,2].plot(np.log(np.sum(data_clean[4,].T, axis=0)+EPS),'b')  #S+N - avg\n    ax[0,2].plot(np.log(np.sum(data_clean[5,].T, axis=0)+EPS),'y--')  #S+N - avg\n    ax[0,0].set_xlabel('time (segments))')\n    ax[0,0].set_ylabel('intensity (x10 dB)')\n    ax[0,0].set_title('power spec across time')\n    ax[0,0].legend(['A0','B'])\n    ax[0,1].legend(['A1','C'])\n    ax[0,2].legend(['A2','D'])\n\n    #Visualize across freq\n    ax[1,0].plot(np.log(np.sum(data_clean[0,], axis=0)+EPS),'b')  #S+N - avg\n    ax[1,0].plot(np.log(np.sum(data_clean[1,], axis=0)+EPS),'r--')  #S+N - avg\n    ax[1,1].plot(np.log(np.sum(data_clean[2,], axis=0)+EPS),'b')  #S+N - avg\n    ax[1,1].plot(np.log(np.sum(data_clean[3,], axis=0)+EPS),'g--')  #S+N - avg\n    ax[1,2].plot(np.log(np.sum(data_clean[4,], axis=0)+EPS),'b')  #S+N - avg\n    ax[1,2].plot(np.log(np.sum(data_clean[5,], axis=0)+EPS),'y--')  #S+N - avg\n    ax[1,0].set_xlabel('freq (bins))')\n    ax[1,0].set_ylabel('intensity (x10 dB)')\n    ax[1,0].set_title('power spec across freq')\n    ax[1,0].legend(['A0','B'])\n    ax[1,1].legend(['A1','C'])\n    ax[1,2].legend(['A2','D'])\n    \n    fig, ax = plt.subplots(nrows=1,ncols=6,figsize=(24,8)) \n    #removed noise imag\n    ax[0].imshow(np.log(data_clean[0,]+EPS).T, aspect = 0.5*float(data_clean[0,].shape[1]) \/ data_clean[0,].shape[0]) \n    ax[1].imshow(np.log(data_clean[1,]+EPS).T, aspect = 0.5*float(data_clean[1,].shape[1]) \/ data_clean[1,].shape[0]) \n    ax[2].imshow(np.log(data_clean[2,]+EPS).T, aspect = 0.5*float(data_clean[2,].shape[1]) \/ data_clean[2,].shape[0])\n    ax[3].imshow(np.log(data_clean[3,]+EPS).T, aspect = 0.5*float(data_clean[3,].shape[1]) \/ data_clean[3,].shape[0]) \n    ax[4].imshow(np.log(data_clean[4,]+EPS).T, aspect = 0.5*float(data_clean[4,].shape[1]) \/ data_clean[4,].shape[0]) \n    ax[5].imshow(np.log(data_clean[5,]+EPS).T, aspect = 0.5*float(data_clean[5,].shape[1]) \/ data_clean[5,].shape[0]) \n\n    ax[0].set_xlabel('time (segments)')\n    ax[0].set_ylabel('freq (bins))')\n    ax[0].set_title('spec A0')\n    ax[1].set_title('spec B')\n    ax[2].set_title('spec A1')\n    ax[3].set_title('spec C')\n    ax[4].set_title('spec A2')\n    ax[5].set_title('spec D')\n\n    return\n\n\ndef plot_clean_data(arr):\n    \n    arr_pos =np.zeros((6,273,256), dtype = np.float32) \n    #remove negative value (linear scale)\n    arr_pos[0,] = arr[0,]- np.min(arr[0,])\n    arr_pos[1,] = arr[1,]- np.min(arr[1,])\n    arr_pos[2,] = arr[2,]- np.min(arr[2,])\n    arr_pos[3,] = arr[3,]- np.min(arr[3,])\n    arr_pos[4,] = arr[4,]- np.min(arr[4,])\n    arr_pos[5,] = arr[5,]- np.min(arr[5,])\n\n    # Remove the noise\n    data_clean =np.zeros((6,273,256), dtype = np.float32) \n    data_clean = arr_pos - pos_df0   #pos_df0 contains only noises  \n    data_clean[data_clean < 0] = 0.00001\n\n    plot_no_bckgnd(data_clean)\n    return","cf6b5cd0":"arr = np.load('..\/input\/seti-breakthrough-listen\/train\/5\/54e340be921d.npy').astype(np.float32)  #narrowband,A0(f80,i48)\nplot_clean_data(arr)  ","421d9e20":"#A2(f160) doppler(narrow band) and dc spike f160 + bright pixels noises, May be A1(f105)->A2(f110)\narr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/099e8de5c54a.npy').astype(np.float32)  #not bright pixel, need a larger plot to see a doppler shift at f160\nplot_clean_data(arr) ","7d46aa21":"# Needle is synchronized with RFI pulses\narr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/0689caff3aab.npy').astype(np.float32)  #blank, un-visible, A1 \nplot_clean_data(arr) ","a3891c65":"arr = np.load(egg_paths[7]).astype(np.float32)  #rocket\nplot_clean_data(arr) ","d2054b45":"#First Step\n\navg_df1_no_bckgnd =np.zeros((6,273,256), dtype = np.float32)  #max_32bit = 2**31-1\nmax_31bit = 2**30-1\n\nfor i,fn in enumerate(df_1.image_path[:avg_sample]):\n    spec   = np.load(fn)                           #6x273x256\n    \n    for k in range( len(avg_df1_no_bckgnd) ):\n        if i == 0:\n            avg_df1_no_bckgnd[k,] = spec[k,]-avg_df0[k,]  #remove N_bg background noise\n\n        else:\n            #intensity is in 16bits\n            avg_df1_no_bckgnd[k,] = avg_df1_no_bckgnd[k,] + spec[k,]-avg_df0[k,]  \n\n        if(i%2000 == 0):\n            dat_min=np.min(avg_df1_no_bckgnd[k,])\n            dat_max=np.max(avg_df1_no_bckgnd[k,])\n            print(k, dat_min, dat_max)\n\n            if (np.abs(dat_max) > max_31bit):\n                print(k,'close to overflow')\n    \navg_df1_no_bckgnd = avg_df1_no_bckgnd\/(i+1)","4d5263fa":"df1_no_bckgnd_pos =np.zeros((6,273,256), dtype = np.float32)\n\ndf1_no_bckgnd_pos[0,] = avg_df1_no_bckgnd[0,]- np.min(avg_df1_no_bckgnd[0,])\ndf1_no_bckgnd_pos[1,] = avg_df1_no_bckgnd[1,]- np.min(avg_df1_no_bckgnd[1,])\ndf1_no_bckgnd_pos[2,] = avg_df1_no_bckgnd[2,]- np.min(avg_df1_no_bckgnd[2,])\ndf1_no_bckgnd_pos[3,] = avg_df1_no_bckgnd[3,]- np.min(avg_df1_no_bckgnd[3,])\ndf1_no_bckgnd_pos[4,] = avg_df1_no_bckgnd[4,]- np.min(avg_df1_no_bckgnd[4,])\ndf1_no_bckgnd_pos[5,] = avg_df1_no_bckgnd[5,]- np.min(avg_df1_no_bckgnd[5,])\n\ndf1_no_bckgnd_pos[df1_no_bckgnd_pos <= 0] = 1  #0dB","c85c5206":"#This is the spectrum shape of df1 with background noise removed.\nplot_no_bckgnd(df1_no_bckgnd_pos)","afff9f47":"#this is natural log, limits 16bit and 17bit\nnp.log(2**15), np.log(2**-15),np.log(2**16), np.log(2**-16)","4ec4063f":"#Second Step\n\nref_pwr = 1.0   #this can be used for data augmentation, ref_pwr +- deviation\npsd_mask_df1 =np.zeros((6,273,256), dtype = np.float32)\n\nfor k in range(6):\n    psd_mask_df1[k,] = ref_pwr \/ df1_no_bckgnd_pos[k,]  #linear scale   \n    print('k=',k, np.min(df1_no_bckgnd_pos[k,]), '\\t', np.max(df1_no_bckgnd_pos[k,]),'\\t psd min= ', np.min(psd_mask_df1[k,]), 'max= ',np.max(psd_mask_df1[k,]))","24606cd2":"np.min(df1_no_bckgnd_pos), np.max(df1_no_bckgnd_pos), np.log(np.min(df1_no_bckgnd_pos)) , np.log(np.max(df1_no_bckgnd_pos)) ","df356387":"#This is reciprocal of df1_no_bckgnd_pos PSD\nplot_no_bckgnd(psd_mask_df1)","1f9a50bf":"arr = np.load('..\/input\/seti-breakthrough-listen\/train\/5\/54e340be921d.npy').astype(np.float32)  #narrowband,A0(f80,i48)\n\narr_pos =np.zeros((6,273,256), dtype = np.float32) \n#remove negative value (linear scale)\narr_pos[0,] = arr[0,]- np.min(arr[0,])\narr_pos[1,] = arr[1,]- np.min(arr[1,])\narr_pos[2,] = arr[2,]- np.min(arr[2,])\narr_pos[3,] = arr[3,]- np.min(arr[3,])\narr_pos[4,] = arr[4,]- np.min(arr[4,])\narr_pos[5,] = arr[5,]- np.min(arr[5,])\n\n# Remove the noise\ndata_clean =np.zeros((6,273,256), dtype = np.float32) \ndata_clean = arr_pos - pos_df0   #S+N - N\ndata_clean[data_clean <= 0] = 1\n\n#Equalize the Spectrum\ndata_clean_psd =np.zeros((6,273,256), dtype = np.float32)\ndata_clean_psd = data_clean*psd_mask_df1\n\nplot_no_bckgnd(data_clean_psd)","18ae7176":"#Delta btw A0-B, A1-C, A2-D\nDelta =np.zeros((3,273,256), dtype = np.float32)\nDelta[0] =data_clean_psd[0,] - data_clean_psd[1,]\nDelta[1] =data_clean_psd[2,] - data_clean_psd[3,]\nDelta[2] =data_clean_psd[4,] - data_clean_psd[5,]\n\nDelta[Delta<=0] = 1\n\n#plot Delta\nplot_avg_noise(Delta[0,], False)  #Delta A0\nplot_avg_noise(Delta[1,], False)  #Delta A1\nplot_avg_noise(Delta[2,], False)  #Delta A2","ed9ec072":"#https:\/\/github.com\/ibm-watson-data-lab\/ibmseti\n#Sum polarization,       S = spect_L + spect_R\n#Asymmetry polarization, A = (spect_L - spect_R) \/ (spect_L + spect_R)\n\n#I'm not sure about the definition of polarization and this is done correctly.\n\n#polarize,\npol =np.zeros((6,273,256), dtype = np.float32)\n\n#sum_polarize, A0+B, A1+C, A2+D\npol[1,] = data_clean_psd[0,] + data_clean_psd[1,]\npol[3,] = data_clean_psd[2,] + data_clean_psd[3,]\npol[5,] = data_clean_psd[4,] + data_clean_psd[5,]\n\npol[pol ==0] = 1   #avoid divide by zero\n#polarize, Asymmetry btw A0-B\/(A0+B), (A1-C)\/(A1+C), (A2-D)\/(A2+D)\npol[0,] = (data_clean_psd[0,] - data_clean_psd[1,]) \/ pol[1]\npol[2,] = (data_clean_psd[2,] - data_clean_psd[3,]) \/ pol[3]\npol[4,] = (data_clean_psd[4,] - data_clean_psd[5,]) \/ pol[5]\n\npol[pol <=0 ] = 1\n\n#plot polarization\nplot_no_bckgnd(pol) ","e81f224d":"#Asymmetry polarization\nplot_avg_noise(pol[0,], False)  #Asymmetry polarize A0\nplot_avg_noise(pol[2,], False)  #Asymmetry polarize A2\nplot_avg_noise(pol[4,], False)  #Asymmetry polarize A4\n","b398511b":"#Sum polarization\nplot_avg_noise(pol[1,], False)  #sum polarize A0+B\nplot_avg_noise(pol[3,], False)  #sum polarize A1+C\nplot_avg_noise(pol[5,], False)  #sum polarize A2+D","1639cc8d":"def plot_all(arr):\n    arr_pos =np.zeros((6,273,256), dtype = np.float32) \n    #remove negative value (linear scale)\n    arr_pos[0,] = arr[0,]- np.min(arr[0,])\n    arr_pos[1,] = arr[1,]- np.min(arr[1,])\n    arr_pos[2,] = arr[2,]- np.min(arr[2,])\n    arr_pos[3,] = arr[3,]- np.min(arr[3,])\n    arr_pos[4,] = arr[4,]- np.min(arr[4,])\n    arr_pos[5,] = arr[5,]- np.min(arr[5,])\n\n    # Remove the noise\n    data_clean =np.zeros((6,273,256), dtype = np.float32) \n    data_clean = arr_pos - pos_df0   #S+N -N\n    data_clean[data_clean <= 0] = 1\n\n    #Equalize the Spectrum\n    data_clean_psd =np.zeros((6,273,256), dtype = np.float32)\n    data_clean_psd = data_clean*psd_mask_df1\n\n    plot_no_bckgnd(data_clean_psd)\n\n    #Delta btw A0-B, A1-C, A2-D\n    Delta =np.zeros((3,273,256), dtype = np.float32)\n    Delta[0] =data_clean_psd[0,] - data_clean_psd[1,]\n    Delta[1] =data_clean_psd[2,] - data_clean_psd[3,]\n    Delta[2] =data_clean_psd[4,] - data_clean_psd[5,]\n\n    Delta[Delta<=0] = 1\n\n    #plot Delta\n    plot_avg_noise(Delta[0,], False)  #Delta A0\n    plot_avg_noise(Delta[1,], False)  #Delta A1\n    plot_avg_noise(Delta[2,], False)  #Delta A2\n\n    #polarize,\n    pol =np.zeros((6,273,256), dtype = np.float32)\n\n    #sum_polarize, A0+B, A1+C, A2+D\n    pol[1,] = data_clean_psd[0,] + data_clean_psd[1,]\n    pol[3,] = data_clean_psd[2,] + data_clean_psd[3,]\n    pol[5,] = data_clean_psd[4,] + data_clean_psd[5,]\n\n    pol[pol ==0] = 1   #avoid divide by zero\n    #polarize, Asymmetry btw A0-B\/(A0+B), (A1-C)\/(A1+C), (A2-D)\/(A2+D)\n    pol[0,] = (data_clean_psd[0,] - data_clean_psd[1,]) \/ pol[1]\n    pol[2,] = (data_clean_psd[2,] - data_clean_psd[3,]) \/ pol[3]\n    pol[4,] = (data_clean_psd[4,] - data_clean_psd[5,]) \/ pol[5]\n\n    pol[pol <=0 ] = 1\n\n    #plot polarization\n    plot_no_bckgnd(pol) \n\n    #Asymmetry polarization\n    plot_avg_noise(pol[0,], False)  #Asymmetry polarize A0\n    plot_avg_noise(pol[2,], False)  #Asymmetry polarize A2\n    plot_avg_noise(pol[4,], False)  #Asymmetry polarize A4\n\n    #Sum polarization\n    plot_avg_noise(pol[1,], False)  #sum polarize A0+B\n    plot_avg_noise(pol[3,], False)  #sum polarize A1+C\n    plot_avg_noise(pol[5,], False)  #sum polarize A2+D","8d04a900":"arr = np.load('..\/input\/seti-breakthrough-listen\/train\/0\/099e8de5c54a.npy').astype(np.float32)  #not bright pixel, need a larger plot to see a doppler shift at f160\nplot_all(arr)","706171e4":"arr = np.load(egg_paths[7]).astype(np.float32)  #rocket,  A1(t180, f100-256)\nplot_all(arr)","40aeb334":"arr = np.load(egg_paths[0]).astype(np.float32)  #kaggle\nplot_all(arr)","1de99ae9":"Freq-domain:\n\nA0 plot, notice the band-edges, they are reciprocal PSD of the above First Step.","2aa4419f":"**1) Average TARGET = 1 (S+N)**","6524f80b":"Freq-domain:\n\nA2 plot: Bright pixel at tone 110, RFI at tones 90, 120, and doppler shift starting at tone 160(for sure).  DC spike at tone 160 as well.  Need a larger plot to see them.\n\nA1 plot: DC spike, possible needle at tone 105 with intensity barely above the noise floor 67dB.  From A1 to A2, bright pixel tone 105 shfted to tone 110 (maybe)\n\nC plot: DC spike tone 160. RFI tone 120.\n\nA0 plot: noise floor is too high 65-67dB.","28eacf5a":"**3) Average Train Data:** Combined Target(0 & 1), Average(Target0 + Target1)\/2","e9216087":"**7) Comparing Train Target=1** [A0,B,A1,C,A2,D]","8e8582e2":"Freq-domain:\n\nA0 plot, see the lower band-edge freq bin0-10 roll-off, and upper band-edge freq bin 220-256.\nThe plots are in natural log. The needle intensities on the band edges are weak.\nThe pass-band ripple is due to averaging over a small number of samples. \nIn order to bring the band edges signal up is to have the amplitude equalizer. It is the mirror image of the spectrum. See Step 2.","fa56e3da":"**2) Average Target = 0 (background noises only)**","98581d6f":"**10d) Rocket**","551e73c7":"**10) Analyzing Signals**\n\nPlots are the same, only on the cleaned data.  A0_B, A1_C, A2_D overlap plots","d692e630":"Freq-domain :\n\nA0 plot, Needle at tone 80, DC spike at tone 90.\n\nA1 plot, suspect needle doppler shifted into DC spike.\n\nA2 plot, probably doppler shifted into bursty RFI narrowband(f110-f200)","8f05229d":"**Approximate Background Noise**","bb2a9b7c":"**5) Comparing Test Target**=unknown [A0,B,A1,C,A2,D]","e6adb0a7":"**10b) Bright-Pixel** ?","b5660f4a":"For the model, i think the  \"BiRNN multihead attention model\", att_mh_rnn.py used in keywords spotting(kws)\n\nhttps:\/\/github.com\/google-research\/google-research\/tree\/master\/kws_streaming\/models\n\nis suitable for this application.  Target-On A, should pay attention to B,C,D.\n\n","2848cfbe":"**11e) Sum Polarization\/Asymmetry Polarization**","daeba589":"**6) Comparing Train Target=0** [A0,B,A1,C,A2,D]","326809f9":"**8) Comparing Train Target=0 vs Target=1**","6fd98273":"**11a)  Step1, avg_df1_no_bckgnd** = Averaging (df1-avg_df0)","94443883":"**11b) Step 2, psd_mask_df1** = 1 \/ avg_df1_no_bckgnd,  this is just the reciprocal  ","b07e6d4f":"Time-domain: \n\nA0 plot, pulses are increasing in intensity, there are 2 signals pulses very close to each other(t46,t48),(t92,t96),. . more like synchronized.\n\nA1 plot, pulses (t90,t92), t90 has the highest intensity.\n\nFreq-domain:\n\nvery low noise floor.  The nominal training df1 noise floor is about 45dB. DC spike is about 85dB, this limited the dynamic range(16bit is about 96dB). \n\nThe signal is under the mud, zero SNR. Need to knock down DC spike to bring up the signal.  Your NN is learning the DC spike, not needle.","5fb7371a":"**4) Average Test Data**, Target unknown","d8477547":"**11) Flattening the Spectrum** (amplitude equalizer)","4fecc40e":"Approximate Background Noise\n\n1) Average TARGET = 1 (S+N)\n\n2) Average Target = 0 (N)\n\n3) Average Train Data: Combined Target(0 & 1), Average(Target0 + Target1)\/2\n\n4) Average Test Data, Target unknown\n\n5) Comparing Test Target=unknown [A0,B,A1,C,A2,D]\n\n6) Comparing Train Target=0 [A0,B,A1,C,A2,D]\n\n7) Comparing Train Target=1 [A0,B,A1,C,A2,D]\n\n8) Comparing Train Target=0 vs Target=1\n\n9) Removing Background\n\n9a) Load data\n\n9b) Removing Background noise(target=0)\n\n10) Analyzing Signals\n\n10a) Narrowband\n\n10b) Bright Pixel\n\n10c) Synchronized Needle\n\n10d) Rocket\n\n11) Flattening the Spectrum (amplitude equalizer)\n\n11a) Step1, avg_df1_no_bckgnd = Averaging (df1-avg_df0)\n\n11b) Step 2, psd_mask_df1 = 1 \/ avg_df1_no_bckgnd, this is just the reciprocal\n\n11c) Delta btw A0-B, A1-C, A2-D\n\n11e) Sum Polarization\/Asymmetry Polarization\n","3cac71fe":"**10a) NarrowBand**","d3a0bfbc":"Looks like AM modulation, high freq riding on very low freq wave.","167c3284":"**11c) Delta btw A0-B, A1-C, A2-D**","0c8017f8":"**10c) Synchronized Needle**","5a17c7ed":"**9b) Removing Background noise(target=0)**","8f6d042e":"**9) Removing Background**\n\n**9a) Load data**","77244a65":"To flatten the receiver spectrum.  This is done by simple two steps.  The first step is to remove the background noise from the receiver signal, then averaged over many samples.\n\nFirst Step: ( only show df_1, it can be df_trn, df_tst, df_0)\n\n   avg_df1_no_bckgnd = avg( df_1 - avg_df0) <-- ~ avg(S) <-- avg( S+N - N )\n\nSecond Step:\n\n   psd_mask_df1 = 1 \/ avg_df1_no_bckgnd,  this is just the reciprocal\n\nEqualize the Spectrum:\n\ndata_clean = arr_pos - pos_df0   #  \n\ndata_clean_psd = data_clean * psd_mask_df1  # this is effectively amplitude equalizer\n\nThe advantage of this is on the band edges, it will equalize the amplitude and bias, such that the digital resolution is maintained.\n"}}