{"cell_type":{"41f78b33":"code","75899966":"code","10141503":"code","f6c4b1fe":"code","617a868e":"code","019cd069":"code","0537dd2a":"markdown","f957519a":"markdown","3b464e5a":"markdown","d8e5871d":"markdown","942268e6":"markdown","1dae9467":"markdown"},"source":{"41f78b33":"import os\nimport cv2\nimport csv\nfrom tqdm import tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.measure import label, regionprops\nfrom skimage.util.montage import montage2d as montage\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nship_dir = '..\/input'\ntrain_image_dir = os.path.join(ship_dir, 'train')\ntest_image_dir = os.path.join(ship_dir, 'test')\n\nfrom skimage.morphology import label\ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\n# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list, all_masks=None):\n    # Take the individual ship masks and create a single mask array for all ships\n    if all_masks is None:\n        all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)","75899966":"masks = pd.read_csv(os.path.join('..\/input',\n                                 'train_ship_segmentations.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks.head()","10141503":"images_with_ship = masks.ImageId[masks.EncodedPixels.isnull()==False]\nimages_with_ship = np.unique(images_with_ship.values)\nprint('There are ' +str(len(images_with_ship)) + ' image files with masks')","f6c4b1fe":"for i in range(10):\n    image = images_with_ship[i]\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5))\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    rle_0 = masks.query('ImageId==\"'+image+'\"')['EncodedPixels']\n    mask_0 = masks_as_image(rle_0)\n    #\n    # \n    lbl_0 = label(mask_0) \n    props = regionprops(lbl_0)\n    img_1 = img_0.copy()\n    print ('Image', image)\n    for prop in props:\n        print('Found bbox', prop.bbox)\n        cv2.rectangle(img_1, (prop.bbox[1], prop.bbox[0]), (prop.bbox[3], prop.bbox[2]), (255, 0, 0), 2)\n\n\n    ax1.imshow(img_0)\n    ax1.set_title('Image')\n    ax2.set_title('Mask')\n    ax3.set_title('Image with derived bounding box')\n    ax2.imshow(mask_0[...,0], cmap='gray')\n    ax3.imshow(img_1)\n    plt.show()","617a868e":"import gc \nbboxes_dict = {}\ni = 0\ncount_ships = 0\nfor image in tqdm(images_with_ship):\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    rle_0 = masks.query('ImageId==\"'+image+'\"')['EncodedPixels']\n    mask_0 = masks_as_image(rle_0)\n\n    lbl_0 = label(mask_0) \n    props = regionprops(lbl_0)\n    bboxes = []\n    count_ships = count_ships + len(props)\n    for prop in props:\n        bboxes.append(prop.bbox)\n        \n        \n    i = i + 1\n    if i % 500 == 0:\n        gc.collect()    \n\n    bboxes_dict[image] = bboxes.copy()","019cd069":"dict_images = list(bboxes_dict.keys())\nmyData = [['image_name','width','height','class','xmin','ymin','xmax','ymax']]\nmyFile = open('train.csv', 'w')\nwith myFile:\n            writer = csv.writer(myFile)\n            writer.writerows(myData)\nfor i in range(29070):\n    image = dict_images[i]\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    rle_0 = masks.query('ImageId==\"'+image+'\"')['EncodedPixels']\n    mask_0 = masks_as_image(rle_0)\n    img_1 = img_0.copy()\n    bboxs = bboxes_dict[image]\n    width, height = img_1.shape[:2]\n    for bbox in bboxs:\n        cv2.rectangle(img_1, (bbox[1], bbox[0]), (bbox[3], bbox[2]), (255, 0, 0), 2)\n        myData = [[image,width,height,'ship',bbox[1], bbox[0], bbox[3], bbox[2]]]\n        with open('train.csv','a',newline='') as myFile:\n            writer = csv.writer(myFile)\n            writer.writerows(myData)","0537dd2a":"In order to extract the bounding box we:\n1. Load mask as binary numpy array using Kevin's `masks_as_image`)\n\n2. Label  connected regions of this mask using `skimage.measure.label`\n\n3. Measure morphological properties of these connected regions and keep the bounding box (`skimage.measure.regionprops`). For each connected region a bounding box of the form  (min_row, min_col, max_row, max_col) is returned.  \n","f957519a":"and keep only those that contain ships. Keep in mind that image files can be repeated many times in the csv file. So a unique operator will give us the unique filenames that contain ships.","3b464e5a":"Here we calculate the bounding boxes for all `29070` images and save then into a dictionary. ","d8e5871d":"Let us save extracted bounding boxes in CSV file ","942268e6":"Let us read the masks:","1dae9467":"Current competition metric implies segmenation task. However one valid approach could incorporate object detection. In this direcrion and borrowing stuff from Kevin's excellent kernel [https:\/\/www.kaggle.com\/kmader\/baseline-u-net-model-part-1](http:\/\/), we attempt to extract bounding boxes information from binary rle-encoded masks.\nAnd produce correspoding CSV file for tensorflow training \nThis kernal is a small derivative from Costas Voglis kernal [https:\/\/www.kaggle.com\/voglinio\/from-masks-to-bounding-boxes](http:\/\/,)"}}