{"cell_type":{"0826080f":"code","8911a6c8":"code","0368e96d":"code","a03d3b8c":"code","5db69b9a":"code","31ea29ea":"code","2be514e3":"code","70482320":"code","cba01aa2":"code","7d96cd00":"code","8c13dd9a":"code","93533049":"markdown","d4dc4648":"markdown","5e03990f":"markdown","ff4417fe":"markdown","cc1f5159":"markdown","ed6a19d1":"markdown","ba589463":"markdown","e97fcb97":"markdown","791c9795":"markdown"},"source":{"0826080f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as   plt\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers, optimizers, losses, metrics\nfrom tensorflow.python.ops.numpy_ops import np_utils\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers.experimental import RandomFourierFeatures\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten, Dropout\n#from tensorflow.keras.layers.core import Dense, Activation, Dropout\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\ntrain_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_images = np.array(train_data.iloc[:,0:-1]).reshape((-1,28,28,1))\nlabels = train_data.iloc[:,0]\n","8911a6c8":"pretrained_conv_base = False # set to False if you want to train CNN from scratch\nclassifier = 'SVM' # what classifier to use ('SVM' or 'softmax')","0368e96d":"if pretrained_conv_base == True:\n    # VGG16 convolutional base requires minimum resoltion of 32x32x3\n    #padding\n    train_images = np.pad(train_images,((0, 0), (2, 2), (2, 2),(0,0)) )\n    \n    #repeat grayscale values across all 3 channels\n    train_images = np.repeat(train_images, 3, axis=3)\n    \n    print('Images have been padded and copied to all 3 channels')\n    \n    \n   ","a03d3b8c":"strat_split = StratifiedShuffleSplit(n_splits=1,test_size = 0.15, random_state = 39) \nfor train_index, val_index in strat_split.split(train_images, labels):\n    train_X = train_images[train_index,:,:,:]\n    train_y = to_categorical(labels.iloc[train_index].values.astype('int32'))\n    val_X = train_images[val_index,:,:,:]\n    val_y = to_categorical(labels.iloc[val_index].values.astype('int32'))","5db69b9a":"batch_size = 64\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255\n    rotation_range=40,\n    rotation_range=20,\n    width_shift_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.2,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    shear_range=0.1,\n    zoom_range=0.2,\n    zoom_range=0.1,\n    horizontal_flip=True\n    )\n\ntrain_generator = train_datagen.flow(train_X,train_y,batch_size = batch_size)\n\n# no data augmentation for validation data \ntest_datagen = ImageDataGenerator(rescale=1.\/255) \nvalidation_generator = test_datagen.flow(val_X,val_y ,batch_size = batch_size)","31ea29ea":"model = Sequential()\nif pretrained_conv_base == True:\n    print('Pretrained convolutional base is used')\n    # load and freeze convolutional base\n    conv_base = VGG16(weights='imagenet', include_top=False,input_shape = (32,32,3))\n    print('Number of trainable weights before freezing the conv base : ', len(model.trainable_weights))    \n    conv_base.trainable = False\n    print('Number of trainable weights after freezing the conv base : ', len(model.trainable_weights))    \n\n    model.add(conv_base)\n\nelif pretrained_conv_base == False :\n    print('Convolutional base will be trained from scratch')\n    model.add(layers.Conv2D(16,(4,4), activation = 'relu', input_shape=(28,28,1)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(32,(4,4), activation = 'relu'))\n    model.add(layers.MaxPooling2D(2,2))\n    model.add(layers.Conv2D(64,(4,4),activation='relu'))\n\n# add flatten and dropout layer    \nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.1))\n\n","2be514e3":"if classifier == 'SVM':\n    #Layer that projects its inputs into a random feature space.\n    model.add(RandomFourierFeatures(output_dim=4096, kernel_initializer=\"gaussian\", trainable = True))\n    model.add(layers.Dense(10))\n    \nelif classifier == 'softmax':\n    model.add(layers.Dense(64,activation = 'relu'))\n    model.add(layers.Dense(10,activation = 'softmax'))\n    \nmodel.summary()    ","70482320":"# compile model according to classifier\nif classifier == 'SVM':\n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=1e-3),\n        loss=losses.hinge,\n        metrics=[metrics.CategoricalAccuracy(name=\"acc\")],\n    )\n    \nelif classifier == 'softmax':\n    model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\nhistory = model.fit(train_generator,steps_per_epoch=100, epochs = 40,validation_data=validation_generator, validation_steps = 50)","cba01aa2":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc)+1)\nplt.plot(epochs,acc,'bo', label = 'Training acc')\nplt.plot(epochs,val_acc, 'b', label = 'Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,loss,'bo', label = 'Training loss')\nplt.plot(epochs,val_loss, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","7d96cd00":"# make predictions\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest_images = np.array(test_data).reshape((-1,28,28,1))\n\nif pretrained_conv_base == True:\n    test_images = np.pad(test_images,((0, 0), (2, 2), (2, 2),(0,0)) )\n\n    #repeat grayscale values across all 3 channels\n    test_images = np.repeat(test_images, 3, axis=3)\n    \n\n# rescaling\ntest_generator = test_datagen.flow(test_images ,batch_size = batch_size)\n\npredicted_1hot = model.predict(test_generator)\npredicted_category = np.argmax(predicted_1hot,axis=1)\n","8c13dd9a":"# submit\nsubmission  = pd.DataFrame(predicted_category, columns = ['Label'])\nsubmission['ImageId'] = submission.index + 1\nsubmission=submission.reindex(columns=['ImageId','Label'])\nsubmission.to_csv('\/kaggle\/working\/submission.csv', header = True, index=False)\n\n","93533049":"**Preprocessing and stratified sampling**","d4dc4648":"**Data augmentation**","5e03990f":"Choose classifier : Keras implementation of SVM or softmax","ff4417fe":"Settings","cc1f5159":"**Adding a classifier**","ed6a19d1":"**Submission**","ba589463":"**Training**","e97fcb97":"**Initializing a CNN**","791c9795":"**Evaluation**"}}