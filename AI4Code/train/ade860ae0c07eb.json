{"cell_type":{"8a638ce7":"code","dd44e97f":"code","d8f2543b":"code","bffac7fd":"code","c7e1fb35":"code","51eb43ec":"code","3b3a1df0":"code","5bc8a4b2":"code","42d8dcec":"code","125cb1c4":"code","72d29289":"code","1a8c297e":"code","91b4d5fc":"code","ac0dc4ee":"code","3d723a6b":"code","360607be":"code","fdf2ec5c":"code","534da643":"code","9934c05e":"code","3d069881":"code","d24a0441":"code","79acafca":"code","f864e8b2":"code","35df0879":"code","c219adae":"code","5233c823":"code","dddc19ac":"code","050e64aa":"code","30d8b710":"code","80c32601":"code","f80de183":"code","3672b48e":"code","cd4af118":"code","d63522ba":"code","7af0fe2e":"code","4da9adcc":"code","c8301062":"code","76daee17":"code","609dc1fe":"code","a2c615f0":"code","171d21f1":"code","60839841":"code","a6f164de":"code","41976c07":"code","8306bc1f":"code","00a11f09":"code","fcacfe73":"code","31b78b90":"code","40f93e8e":"code","00c47a0d":"code","ba37fd23":"code","be3821bb":"code","6f934684":"code","1170987c":"code","6807e55f":"markdown","3b00295e":"markdown","33f6710d":"markdown","c4d8c9e0":"markdown","0a5f6a22":"markdown","e3ad8163":"markdown","95fc7624":"markdown","4588b5a5":"markdown","95537386":"markdown","ef315427":"markdown","46174092":"markdown","8bfc2229":"markdown","b975c44b":"markdown","015d7b33":"markdown","6fe3323f":"markdown"},"source":{"8a638ce7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.max_columns', None)\n\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.","dd44e97f":"# *** Read Data ***\ndf = pd.read_csv('..\/input\/train.csv')\ndfTest  = pd.read_csv('..\/input\/test.csv')\ndfSub   = pd.read_csv('..\/input\/sample_submission.csv')","d8f2543b":"# *** Data View ***\nprint(df.head())\nprint(dfSub.head())","bffac7fd":"# *** First Data Impression ***\nprint('Train Data Info')\nprint(df.info())\nprint('\\nTest Data Info \\n')\nprint(dfTest.info())\nprint('\\nSubmission Data Info \\n')\nprint(dfSub.info())","c7e1fb35":"# *** Check Missing Values ***\nprint('Missing Values in Training Data')\nprint(df.isnull().sum())\nprint('Missing Values in Test Data')\nprint(df.isnull().sum())","51eb43ec":"# *** Check Unique Values ***\nprint('Unique Values in Training Data')\nprint(df.nunique())\nprint('Unique Values in Test Data')\nprint(dfTest.nunique())","3b3a1df0":"# *** Explore Trainin Data ***\n# scalar_coupling_constant\ndf['scalar_coupling_constant'].describe(percentiles = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","5bc8a4b2":"# Plot the Distribution\nsns.boxplot(df['scalar_coupling_constant'])","42d8dcec":"# Check the dot plot to make the distribution even more clear\nsns.stripplot(x = df['scalar_coupling_constant'])","125cb1c4":"sns.distplot(df['scalar_coupling_constant'])","72d29289":"# Distribution of scalar_coupling_constant by molecule_name\ndf.groupby('molecule_name')['scalar_coupling_constant'].mean().reset_index().head()","1a8c297e":"df.groupby('molecule_name')['scalar_coupling_constant'].mean().reset_index()['scalar_coupling_constant']. \\\n        describe(percentiles = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","91b4d5fc":"sns.distplot(df.groupby('molecule_name')['scalar_coupling_constant'].mean().reset_index()['scalar_coupling_constant'])","ac0dc4ee":"# Lets Explore the Atom Index Combination in Detail\n(df['atom_index_0'].map(str) + '--' + df['atom_index_1'].map(str)).nunique()","3d723a6b":"(df['atom_index_0'].map(str) + '--' + df['atom_index_1'].map(str)).value_counts().nlargest(10) ","360607be":"(df['atom_index_0'].map(str) + '--' + df['atom_index_1'].map(str)).value_counts().nsmallest(10) ","fdf2ec5c":"df[df['atom_index_0'].map(str) == df['atom_index_1'].map(str)].shape","534da643":"# *** Distribution of Index 0 and 1\ndf['atom_index_0'].value_counts()","9934c05e":"df['atom_index_0'].value_counts(normalize = True)","3d069881":"df['atom_index_1'].value_counts()","d24a0441":"df['atom_index_1'].value_counts(normalize = True)","79acafca":"countDist = (df['atom_index_0'].map(str) + '--' + df['atom_index_1'].map(str)).value_counts().reset_index(). \\\n             rename(columns = {0 : 'combinationCount'})\nsns.distplot(countDist['combinationCount'])","f864e8b2":"df['molecule_name'].value_counts().nlargest(10)","35df0879":"df['molecule_name'].value_counts().reset_index()['molecule_name']. \\\n                         describe(percentiles = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","c219adae":"ax = sns.boxplot(x=df['molecule_name'].value_counts().reset_index()['molecule_name'])","5233c823":"# *** Simple Linear Regression Model ***\ndf['randomNum'] = df['id'].map(lambda x : random.uniform(0, 1))\ndfTrain = df.query('randomNum <= 0.7')\ndfValid  = df.query('randomNum > 0.7')\ndel dfTrain['randomNum']\ndel dfValid['randomNum']\ndel df['randomNum'] ","dddc19ac":"molecule_name_risk = dfTrain.groupby('molecule_name')['scalar_coupling_constant'].mean().reset_index()\nmolecule_name_risk.rename(columns = {'scalar_coupling_constant' : 'molecule_name_risk'}, inplace = True)\n\ndfTrain = pd.merge(dfTrain, molecule_name_risk, on = 'molecule_name')\n\nindex_0_risk = dfTrain.groupby('atom_index_0')['scalar_coupling_constant'].mean().reset_index()\nindex_0_risk.rename(columns = {'scalar_coupling_constant' : 'index_0_risk'}, inplace = True)\n\ndfTrain = pd.merge(dfTrain, index_0_risk, on = 'atom_index_0')\n\nindex_1_risk = dfTrain.groupby('atom_index_1')['scalar_coupling_constant'].mean().reset_index()\nindex_1_risk.rename(columns = {'scalar_coupling_constant' : 'index_1_risk'}, inplace = True)\n\ndfTrain = pd.merge(dfTrain, index_1_risk, on = 'atom_index_1')\n\ntype_risk = dfTrain.groupby('type')['scalar_coupling_constant'].mean().reset_index()\ntype_risk.rename(columns = {'scalar_coupling_constant' : 'type_risk'}, inplace = True)\n\ndfTrain = pd.merge(dfTrain, type_risk, on = 'type')","050e64aa":"dfTrain.drop(['molecule_name', 'atom_index_0', 'atom_index_1', 'type'], axis = 1, inplace = True)","30d8b710":"dfValid = pd.merge(dfValid, molecule_name_risk, on = 'molecule_name')\ndfValid = pd.merge(dfValid, index_0_risk, on = 'atom_index_0')\ndfValid = pd.merge(dfValid, index_1_risk, on = 'atom_index_1')\ndfValid = pd.merge(dfValid, type_risk, on = 'type')","80c32601":"dfValid.isnull().sum()","f80de183":"print(dfValid.head())","3672b48e":"dfValid.drop(['molecule_name', 'atom_index_0', 'atom_index_1', 'type'], axis = 1, inplace = True)","cd4af118":"molecule_name_risk.head()","d63522ba":"print(dfTrain.head())","7af0fe2e":"lmReg = LinearRegression()\nlmReg.fit(dfTrain.drop(['id', 'scalar_coupling_constant'], axis = 1), dfTrain['scalar_coupling_constant'])\ndfValid['scalar_coupling_constant_pred'] = lmReg.predict(dfValid.drop(['id', 'scalar_coupling_constant'], axis = 1))","4da9adcc":"dfValid['predDiff'] = dfValid['scalar_coupling_constant'] - dfValid['scalar_coupling_constant_pred'] ","c8301062":"dfValid['predDiff'].describe(percentiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99])","76daee17":"dfValid['scalar_coupling_constant'].describe(percentiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99])","609dc1fe":"# The coefficients\nprint('Coefficients: \\n', lmReg.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\"\n      % mean_squared_error(dfValid['scalar_coupling_constant'], dfValid['scalar_coupling_constant_pred'] ))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(dfValid['scalar_coupling_constant'], dfValid['scalar_coupling_constant_pred']))","a2c615f0":"# Plot outputs\nsns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(dfValid[['scalar_coupling_constant', 'scalar_coupling_constant_pred']]))","171d21f1":"ax = sns.lineplot(data = dfValid[['scalar_coupling_constant', 'scalar_coupling_constant_pred']])","60839841":"#dfTest = pd.merge(dfTest, molecule_name_risk, on = 'molecule_name')\ndfTest = pd.merge(dfTest, index_0_risk, on = 'atom_index_0')\ndfTest = pd.merge(dfTest, index_1_risk, on = 'atom_index_1')\ndfTest = pd.merge(dfTest, type_risk, on = 'type')\ndfTest['molecule_name_risk'] = 0","a6f164de":"dfTest['scalar_coupling_constant_pred'] = lmReg.predict(dfTest.drop(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', \\\n                                                                    'type'], axis = 1))","41976c07":"dfSub['scalar_coupling_constant'] = dfTest['scalar_coupling_constant_pred']","8306bc1f":"dfSub.to_csv('sample_submission.csv', index = False)","00a11f09":"molecule_name_risk = df.groupby('molecule_name')['scalar_coupling_constant'].mean().reset_index()\nmolecule_name_risk.rename(columns = {'scalar_coupling_constant' : 'molecule_name_risk'}, inplace = True)\n\ndf = pd.merge(df, molecule_name_risk, on = 'molecule_name')\n\nindex_0_risk = df.groupby('atom_index_0')['scalar_coupling_constant'].mean().reset_index()\nindex_0_risk.rename(columns = {'scalar_coupling_constant' : 'index_0_risk'}, inplace = True)\n\ndf = pd.merge(df, index_0_risk, on = 'atom_index_0')\n\nindex_1_risk = df.groupby('atom_index_1')['scalar_coupling_constant'].mean().reset_index()\nindex_1_risk.rename(columns = {'scalar_coupling_constant' : 'index_1_risk'}, inplace = True)\n\ndf = pd.merge(df, index_1_risk, on = 'atom_index_1')\n\ntype_risk = df.groupby('type')['scalar_coupling_constant'].mean().reset_index()\ntype_risk.rename(columns = {'scalar_coupling_constant' : 'type_risk'}, inplace = True)\n\ndf = pd.merge(df, type_risk, on = 'type')\n\ndf.drop(['molecule_name', 'atom_index_0', 'atom_index_1', 'type'], axis = 1, inplace = True)","fcacfe73":"df.head()","31b78b90":"dfTest  = pd.read_csv('..\/input\/test.csv')\ndfTest = pd.merge(dfTest, index_0_risk, on = 'atom_index_0')\ndfTest = pd.merge(dfTest, index_1_risk, on = 'atom_index_1')\ndfTest = pd.merge(dfTest, type_risk, on = 'type')\ndfTest['molecule_name_risk'] = 0","40f93e8e":"dfTest.head()","00c47a0d":"dfTest.drop(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type'], axis = 1).head()","ba37fd23":"df.head()","be3821bb":"lmReg = LinearRegression()\nlmReg.fit(df.drop(['id', 'scalar_coupling_constant'], axis = 1), df['scalar_coupling_constant'])\ndfTest['scalar_coupling_constant_pred'] = lmReg.predict(dfTest.drop(['id', 'molecule_name', \\\n                                                        'atom_index_0', 'atom_index_1', 'type'], axis = 1))","6f934684":"dfSub['scalar_coupling_constant'] = dfTest['scalar_coupling_constant_pred']\ndfSub.to_csv('sample_submission.csv', index = False)","1170987c":"dfSub.head()","6807e55f":"- Submission Score : 2.09\n- Build Model on Complete Training Data","3b00295e":"- 50% of the coupling constant values are in between -0.2 to 2.2\n- Some values even crosses 200","33f6710d":"Looks Like the counts doesn't vary much. let's check:","c4d8c9e0":"- There are 513 index combination\n- Let's check the distribution of count","0a5f6a22":"- 85,003 molecules in train data and 45,772 molecules in test data\n- 8 types of coupling in both training and test data","e3ad8163":"- We can conclude that same pair of indexes never come together\n- Let's check the complete distribution of index pair count","95fc7624":"- Top 12 index 1 accounts for 80% of the data\n- Top indexes by count varies in index 0 and index 1","4588b5a5":"- We will use simple risk based features","95537386":"- It looks very rare for the same index pairs to come together\n> - Lets verify this ","ef315427":"- It is evident that the top 10 combinations are originationg from 9 to 12\n- Now I am interested in lookin the bottom ten also","46174092":"No Missing Values in either train or test data","8bfc2229":"- The median count is somewhere between 50 and 60.\n- From the above table it is 54.\n- Hardly a little more than 1% of molecules have occured more than 100 ","b975c44b":"- Almost All the mean vaues of coupling constant for a molecule are in between 10 to 30\n- From the distribution table also, it is very much clear","015d7b33":"- Top 12 index 0 accounts for 90% of the data","6fe3323f":"- With this probability distribution graph, the actual data nature has been revealed completely\n- Apart from the two very obvious peak, there is a very small third peak at the end of dostribution around 200"}}