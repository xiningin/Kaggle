{"cell_type":{"a9eaa0c9":"code","f52ada0e":"code","18306773":"code","2de4e767":"code","7a88ed2f":"code","ac2f6aa5":"code","71e0011c":"code","1d6eccc2":"code","138fd3b3":"code","13c2555f":"code","9f8e91cf":"code","fe2276cc":"code","8e00a733":"code","ff8ccec7":"code","e07f3497":"code","7090d262":"code","9ba44881":"code","ac82dc13":"code","94492b1c":"code","62063cd2":"code","69619b0f":"code","0d8b78c3":"code","c9b1bbae":"code","b02cbd39":"code","a8a6f405":"code","4a644fd1":"code","4bcd35d8":"code","8b31bf67":"code","ee56fcbe":"code","fcc78035":"code","560f67f0":"code","7aa06e8d":"code","53642683":"code","9f046aac":"code","b0d13511":"code","4ff247b4":"code","57cb9ee8":"code","6da655d6":"code","9b4615cd":"code","d14d8198":"code","31f12b90":"code","b36bd1b7":"code","b765c022":"code","1ff3bad5":"code","686f3839":"code","21fca4a8":"code","53b8dc79":"code","b71887bf":"code","8987058f":"code","3c764f2e":"code","dff54315":"code","f21dd1a8":"code","a8301338":"code","a0834ee2":"code","b711e381":"code","4c42523b":"code","c301df56":"code","aa070d71":"code","a884a3d9":"code","ad0f3930":"code","7cdec03e":"code","07f97f21":"code","8922fb41":"code","7178832a":"code","7b920c8f":"code","fc58a305":"code","3b37c05b":"code","d7dc4978":"code","7ece530f":"code","e581672f":"code","ef702efb":"code","3ac2fa9d":"code","35506e72":"code","5ceb4aa8":"code","c9900a84":"code","3aabbf8c":"code","4944b059":"code","bc08a301":"code","ada53b8f":"code","a79e9fe5":"code","b8675142":"code","4b7cfc23":"code","a16fa6ae":"markdown","117bf770":"markdown","a6081f5c":"markdown","2e5a9d23":"markdown","f0927b05":"markdown","32e6e134":"markdown","02a69b7d":"markdown","385d8760":"markdown","90d10a92":"markdown","f2c6a9a0":"markdown","75895f52":"markdown","bdbf2bf1":"markdown","a4075d5f":"markdown","a9234184":"markdown","2e033a93":"markdown","db9f7398":"markdown","faf3f8ec":"markdown","b46371cc":"markdown","2d4e8156":"markdown","1ade711d":"markdown","2436e980":"markdown","19eae166":"markdown","94d0f0e7":"markdown","e17d916b":"markdown","c8686c88":"markdown","bdb5383f":"markdown","1d5bb784":"markdown","72598fa1":"markdown","4243f947":"markdown"},"source":{"a9eaa0c9":"import os\nos.environ['USER'] = 'root'\nos.system('pip install ..\/input\/xlearn\/xlearn\/xlearn-0.40a1\/')","f52ada0e":"import json\nimport random\nimport os\nimport gc\nimport html\nimport time\nimport re\nfrom collections import defaultdict\nimport math\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport xlearn as xl\nimport scipy\nfrom scipy import ndimage\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error, roc_auc_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import linear_model\nfrom tqdm._tqdm_notebook import tqdm_notebook as tqdm\nfrom nltk.stem.snowball import SnowballStemmer, PorterStemmer\n\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\nimport keras\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom torchvision import models, transforms\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore', UserWarning)\n%matplotlib inline\n\n# treat np.inf as nan value too, because machine learning algorithms should not get inf as input\npd.set_option(\"use_inf_as_na\", True)\ntqdm.pandas()","18306773":"TRAIN_PATH = '..\/input\/petfinder-adoption-prediction\/train\/train.csv'\nTEST_PATH = '..\/input\/petfinder-adoption-prediction\/test\/test.csv'\nTRAIN_SENTIMENT_PATH = '..\/input\/petfinder-adoption-prediction\/train_sentiment\/'\nTEST_SENTIMENT_PATH = '..\/input\/petfinder-adoption-prediction\/test_sentiment\/'\nTRAIN_METADATA_PATH = '..\/input\/petfinder-adoption-prediction\/train_metadata\/'\nTEST_METADATA_PATH = '..\/input\/petfinder-adoption-prediction\/test_metadata\/'\nTRAIN_IMAGES_PATH = '..\/input\/petfinder-adoption-prediction\/train_images\/'\nTEST_IMAGES_PATH = '..\/input\/petfinder-adoption-prediction\/test_images\/'\nEMBEDDING_FILE_SMALL = '..\/input\/petfinder-external\/glove.6B.200d.txt'\nEMBEDDING_FILE_CRAWL = '..\/input\/petfinder-external\/crawl-300d-2M.vec'\nPRETRAINED_WEIGHT_PATH = '..\/input\/petfinder-external\/DenseNet-BC-121-32-no-top.h5'\n","2de4e767":"train_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\ntrain_df.head()","7a88ed2f":"# state GDP: https:\/\/en.wikipedia.org\/wiki\/List_of_Malaysian_states_by_GDP\nstate_gdp = {\n    41336: 116.679,\n    41325: 40.596,\n    41367: 23.02,\n    41401: 190.075,\n    41415: 5.984,\n    41324: 37.274,\n    41332: 42.389,\n    41335: 52.452,\n    41330: 67.629,\n    41380: 5.642,\n    41327: 81.284,\n    41345: 80.167,\n    41342: 121.414,\n    41326: 280.698,\n    41361: 32.270\n}\n\n# state population: https:\/\/en.wikipedia.org\/wiki\/Malaysia\nstate_population = {\n    41336: 33.48283,\n    41325: 19.47651,\n    41367: 15.39601,\n    41401: 16.74621,\n    41415: 0.86908,\n    41324: 8.21110,\n    41332: 10.21064,\n    41335: 15.00817,\n    41330: 23.52743,\n    41380: 2.31541,\n    41327: 15.61383,\n    41345: 32.06742,\n    41342: 24.71140,\n    41326: 54.62141,\n    41361: 10.35977\n}\n\ntrain_df[\"state_gdp\"] = train_df['State'].map(state_gdp)\ntrain_df[\"state_population\"] = train_df['State'].map(state_population)\ntest_df[\"state_gdp\"] = test_df['State'].map(state_gdp)\ntest_df[\"state_population\"] = test_df['State'].map(state_population)\ntrain_df[\"gdp_vs_population\"] = train_df[\"state_gdp\"] \/ train_df[\"state_population\"]\ntest_df[\"gdp_vs_population\"] = test_df[\"state_gdp\"] \/ test_df[\"state_population\"]","ac2f6aa5":"puncts = ['\u3002', ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', \n          '\/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '\u2022', '~', '_', '{', '}', \n          '^', '`', '<', '\u00b0', '\u2122', '\u2665', '\u00bd', '\u2026', '\u201c', '\u201d', '\u2013', '\u25cf', '\u00b2', '\u00ac', '\u2191',\n          '\u2014', '\uff1a', '\u2019', '\u2606', '\u00e9', '\u00af', '\u2666', '\u2018', '\uff09', '\u2193', '\u3001', '\uff08', '\uff0c', '\u266a', \n          '\u00b3', '\u2764', '\u00ef', '\u221a']\n\nmispell_dict = {\n    \"I'd\": 'I would',\n    \"I'll\": 'I will',\n    \"I'm\": 'I am',\n    \"I've\": 'I have',\n    \"ain't\": 'is not',\n    \"aren't\": 'are not',\n    \"can't\": 'cannot',\n    'cancelled': 'canceled',\n    'centre': 'center',\n    'colour': 'color',\n    \"could've\": 'could have',\n    \"couldn't\": 'could not',\n    \"didn't\": 'did not',\n    \"doesn't\": 'does not',\n    \"don't\": 'do not',\n    'enxiety': 'anxiety',\n    'favourite': 'favorite',\n    \"hadn't\": 'had not',\n    \"hasn't\": 'has not',\n    \"haven't\": 'have not',\n    \"he'd\": 'he would',\n    \"he'll\": 'he will',\n    \"he's\": 'he is',\n    \"here's\": 'here is',\n    \"how's\": 'how is',\n    \"i'd\": 'i would',\n    \"i'll\": 'i will',\n    \"i'm\": 'i am',\n    \"i've\": 'i have',\n    \"isn't\": 'is not',\n    \"it'll\": 'it will',\n    \"it's\": 'it is',\n    'labour': 'labor',\n    \"let's\": 'let us',\n    \"might've\": 'might have',\n    \"must've\": 'must have',\n    'organisation': 'organization',\n    \"she'd\": 'she would',\n    \"she'll\": 'she will',\n    \"she's\": 'she is',\n    \"shouldn't\": 'should not',\n    \"that's\": 'that is',\n    'theatre': 'theater',\n    \"there's\": 'there is',\n    \"they'd\": 'they would',\n    \"they'll\": 'they will',\n    \"they're\": 'they are',\n    \"they've\": 'they have',\n    'travelling': 'traveling',\n    \"wasn't\": 'was not',\n    'watsapp': 'whatsapp',\n    \"we'd\": 'we would',\n    \"we'll\": 'we will',\n    \"we're\": 'we are',\n    \"we've\": 'we have',\n    \"weren't\": 'were not',\n    \"what's\": 'what is',\n    \"where's\": 'where is',\n    \"who'll\": 'who will',\n    \"who's\": 'who is',\n    \"who've\": 'who have',\n    \"won't\": 'will not',\n    \"would've\": 'would have',\n    \"wouldn't\": 'would not',\n    \"you'd\": 'you would',\n    \"you'll\": 'you will',\n    \"you're\": 'you are',\n    \"you've\": 'you have',\n    '\uff0c': ',',\n    '\uff0f': '\/',\n    '\uff1f': '?'\n}","71e0011c":"def safe_get(data, *keys):\n    try:\n        current = data\n        for key in keys:\n            current = current[key]\n    except:\n        current = None\n    return current        ","1d6eccc2":"for df, path in ([train_df, TRAIN_SENTIMENT_PATH], [test_df, TEST_SENTIMENT_PATH]):\n    doc_sent_mags = np.full(len(df), np.nan)\n    doc_sent_scores = np.full(len(df), np.nan)\n    sentence_texts = np.full(len(df), '', dtype=object)\n    nf_count = 0\n    \n    for i, pet in enumerate(df['PetID']):\n        try:\n            with open(path + pet + '.json', 'r') as f:\n                sentiment = json.load(f)\n            \n            doc_sent_mag = safe_get(sentiment, 'documentSentiment', 'magnitude')\n            if doc_sent_mag is not None:\n                doc_sent_mags[i] = doc_sent_mag\n\n            doc_sent_score = safe_get(sentiment, 'documentSentiment', 'score')\n            if doc_sent_score is not None:\n                doc_sent_scores[i] = doc_sent_score\n\n            text = ' '.join([x['text']['content'] for x in sentiment['sentences']])\n            text = html.unescape(text)\n            sentence_texts[i] = text\n        except:\n            nf_count += 1\n            sentence_texts[i] = df.iloc[i]['Description']\n            \n    print('Not found: ', nf_count)\n    df.loc[:, 'doc_sent_mag'] = doc_sent_mags\n    df.loc[:, 'doc_sent_score'] = doc_sent_scores\n    df.loc[:, 'sentence_text'] = sentence_texts","138fd3b3":"for df, path in ([train_df, TRAIN_METADATA_PATH], [test_df, TEST_METADATA_PATH]):\n    for image in range(1, 31):\n        vertex_xs = np.full(len(df), np.nan)\n        vertex_ys = np.full(len(df), np.nan)\n        bounding_confidences = np.full(len(df), np.nan)\n        bounding_importance_fracs = np.full(len(df), np.nan)\n        dominant_blues = np.full(len(df), np.nan)\n        dominant_greens = np.full(len(df), np.nan)\n        dominant_reds = np.full(len(df), np.nan)\n        dominant_pixel_fracs = np.full(len(df), np.nan)\n        dominant_scores =np.full(len(df), np.nan)\n        top_label_descriptions = np.full(len(df), '', dtype=object)\n        label_descriptions = np.full(len(df), '', dtype=object)\n        label_scores = np.full(len(df), np.nan)\n        nf_count = 0\n        nl_count = 0\n\n        for i, pet in enumerate(df['PetID']):\n            try:\n                with open(path + pet + f'-{image}.json', 'r') as f:\n                    data = json.load(f)\n\n                for feature_array, keys in [\n                    (vertex_xs, ['cropHintsAnnotation', 'cropHints', 0, \n                                 'boundingPoly', 'vertices', 2, 'x']),\n                    (vertex_ys, ['cropHintsAnnotation', 'cropHints', 0, \n                                 'boundingPoly', 'vertices', 2, 'y']),\n                    (bounding_confidences, ['cropHintsAnnotation', 'cropHints', 0, \n                                            'confidence']),\n                    (bounding_importance_fracs, ['cropHintsAnnotation', 'cropHints', 0, \n                                                 'importanceFraction']),\n                    (dominant_blues, ['imagePropertiesAnnotation', 'dominantColors', \n                                      'colors', 0, 'color', 'blue']),\n                    (dominant_greens, ['imagePropertiesAnnotation', 'dominantColors', \n                                       'colors', 0, 'color', 'green']),\n                    (dominant_reds, ['imagePropertiesAnnotation', 'dominantColors', \n                                     'colors', 0, 'color', 'red']),\n                    (dominant_pixel_fracs, ['imagePropertiesAnnotation', 'dominantColors', \n                                            'colors', 0, 'pixelFraction']),\n                    (dominant_scores, ['imagePropertiesAnnotation', 'dominantColors', \n                                       'colors', 0, 'score'])\n                ]:\n                    x = safe_get(data, *keys)\n                    if x is not None:\n                        feature_array[i] = x\n                    \n                if data.get('labelAnnotations'):\n                    file_annots = data['labelAnnotations'][:int(len(data['labelAnnotations']) * 0.3)]\n                    \n                    if len(file_annots) > 0:\n                        label_score = np.asarray([x['score'] for x in file_annots]).mean()\n                        label_description = ' '.join([x['description'] for x in file_annots])\n\n                        top_label_descriptions[i] = file_annots[0]['description']\n                        label_descriptions[i] = label_description\n                        label_scores[i] = label_score\n                else:\n                    nl_count += 1\n            except:\n                nf_count += 1\n\n        df.loc[:, f'vertex_x_{image}'] = vertex_xs\n        df.loc[:, f'vertex_y_{image}'] = vertex_ys\n        df.loc[:, f'bounding_confidence_{image}'] = bounding_confidences\n        df.loc[:, f'bounding_importance_{image}'] = bounding_importance_fracs\n        df.loc[:, f'dominant_blue_{image}'] = dominant_blues\n        df.loc[:, f'dominant_green_{image}'] = dominant_greens\n        df.loc[:, f'dominant_red_{image}'] = dominant_reds\n        df.loc[:, f'dominant_pixel_frac_{image}'] = dominant_pixel_fracs\n        df.loc[:, f'dominant_score_{image}'] = dominant_scores\n        df.loc[:, f'top_label_description_{image}'] = top_label_descriptions\n        df.loc[:, f'label_description_{image}'] = label_descriptions\n        df.loc[:, f'label_score_{image}'] = label_scores","13c2555f":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything()\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(['\\s*'.join(key) \n                                               for key in mispell_dict.keys()]))\n    return mispell_dict, mispell_re\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\n\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[re.sub('\\s', '', match.group(0))]\n    return mispellings_re.sub(replace, text)\n\ndef fix_distribution(y_train, pred):\n    \"\"\"\n    Convert predictions to labels such that the labels have \n    the same distribution as in the y_train array.\n    \"\"\"\n    base = pd.Series([0, 0, 0, 0, 0], index=np.arange(0, 5))\n    thresholds = (base + pd.Series(y_train).value_counts()).fillna(0).cumsum()\n    thresholds = thresholds \/ len(y_train) * len(pred)\n    \n    pred_ranks = pd.Series(pred).rank()\n    ranked_scores = np.zeros(len(pred))\n\n    for j, threshold in list(enumerate(thresholds))[::-1]:\n        ranked_scores[pred_ranks <= threshold] = j\n    return ranked_scores\n\ndef process_text_rnn(text):\n    \"\"\"Process text for RNNs.\"\"\"\n    if text is None:\n            return ''\n    text = clean_text(text)\n    text = replace_typical_misspell(text)\n    for char in '()*,.\/:;\\\\\\t\\n':\n        text = text.replace(char, '')\n    text = re.sub('\\s+', ' ', text)\n    return text\n\nstemmer = PorterStemmer()\n\ndef process_text(text):\n    \"\"\"\n    Process text for other models (LGB, FFM). \n    Additionally replaces numbers by # and stems the text.\n    \"\"\"\n    if text is None:\n        return ''\n    text = clean_text(text)\n    text = replace_typical_misspell(text)\n    text = clean_numbers(text)\n    for char in '()*,.\/:;\\\\\\t\\n':\n        text = text.replace(char, '')\n    text = re.sub('\\s+', ' ', text)\n    text = ' '.join(stemmer.stem(word) for word in text.split())\n    return text","9f8e91cf":"aggregate_features = []\n\nfor feature in ['vertex_x', 'vertex_y', 'bounding_confidence', 'bounding_importance', \n                'dominant_blue', 'dominant_green', 'dominant_red', \n                'dominant_pixel_frac', 'dominant_score', 'label_score']:\n    feature_names = [feature + f'_{i}' for i in range(1, 31)]\n    \n    for df in [train_df, test_df]:\n        df[feature + '_mean'] = df[feature_names].mean(axis=1)\n        df[feature + '_sum'] = df[feature_names].sum(axis=1)\n        df[feature + '_var'] = df[feature_names].var(axis=1)\n    \n    aggregate_features += [feature + '_mean', feature + '_sum', feature + '_var']","fe2276cc":"for df in [train_df, test_df]:\n    df['all_label_descriptions'] = df['label_description_1'].str.cat(\n        df[[f'label_description_{i}' for i in range(2, 31)]], sep=' '\n    ).replace('\\s+', ' ', regex=True)\n    df['no_name'] = (df['Name'].fillna('None').str.match(r'\\b(No|Not|None)\\b')) | \\\n                    (df['Name'].fillna('').apply(len) <= 2)\n    df['sentence_text_rnn'] = df['sentence_text'].progress_apply(lambda x: process_text_rnn(x))\n    df['sentence_text_stemmed'] = df['sentence_text'].progress_apply(lambda x: process_text(x))   ","8e00a733":"for features in [['Dewormed', 'Vaccinated']]:\n    feature = '_'.join(features)\n\n    train_df[feature] = train_df[features].astype(str).apply(lambda x: '_'.join(x), axis=1)\n    test_df[feature] = test_df[features].astype(str).apply(lambda x: '_'.join(x), axis=1)","ff8ccec7":"all_num_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'doc_sent_mag', \n                    'doc_sent_score', 'MaturitySize', 'FurLength', 'Health', 'state_gdp', \n                    'state_population', 'gdp_vs_population'] + aggregate_features\n\nall_cat_features = ['Dewormed', 'Vaccinated', 'Sterilized', 'Breed1', 'Type', \n                    'Dewormed_Vaccinated', 'Breed2', 'State', 'Gender', 'Color1', \n                    'Color2', 'Color3', 'no_name', 'RescuerID']\n\nfor image in [1]:\n    all_num_features += [f'dominant_score_{image}', f'dominant_pixel_frac_{image}', \n                         f'dominant_red_{image}', f'dominant_green_{image}', \n                         f'dominant_blue_{image}', f'bounding_importance_{image}', \n                         f'bounding_confidence_{image}', f'vertex_x_{image}', \n                         f'vertex_y_{image}', f'label_score_{image}']\n    all_cat_features += [f'top_label_description_{image}']","e07f3497":"for feature in all_num_features:\n    train_df[feature].fillna(-1, inplace=True)\n    test_df[feature].fillna(-1, inplace=True)","7090d262":"for feature in all_cat_features:\n    if feature + '_count' in train_df.columns:\n        train_df.drop(feature + '_count', axis=1, inplace=True)\n\n    if feature + '_count' in test_df.columns:\n        test_df.drop(feature + '_count', axis=1, inplace=True)    \n    \n    valcounts = train_df[feature].append(test_df[feature]).value_counts()\n    \n    train_df = train_df.join(valcounts.rename(feature + '_count'), on=feature, how='left')\n    test_df = test_df.join(valcounts.rename(feature + '_count'), on=feature, how='left')\n    \n    if feature + '_count' not in all_num_features:\n        all_num_features.append(feature + '_count')","9ba44881":"bin_counts = defaultdict(lambda: 20)\nbin_counts['RescuerID_count'] = 10\n\nfor feature in all_num_features:\n    if '_binned' in feature:\n        continue\n    \n    n_bins = bin_counts[feature]\n    \n    if n_bins:\n        bins = np.unique(train_df[feature].quantile(np.linspace(0, 1, n_bins)).values)\n        \n        for df in [train_df, test_df]:\n            n_bins = bin_counts[feature]\n            df[feature + '_binned'] = pd.cut(\n                df[feature], bins=bins, duplicates='drop'\n            ).cat.codes\n\n        if feature + '_binned' not in all_num_features:\n            all_num_features.append(feature + '_binned')","ac82dc13":"for feature in all_cat_features:\n    encoder = LabelEncoder()\n    encoder.fit(train_df[feature].append(test_df[feature]))\n    train_df[feature + '_label'] = encoder.transform(train_df[feature])\n    test_df[feature + '_label'] = encoder.transform(test_df[feature])","94492b1c":"for feature in all_num_features:\n    if feature.endswith('_log'):\n        continue\n    \n    train_df[feature + '_log'] = np.log(train_df[feature] + 2)\n    test_df[feature + '_log'] = np.log(test_df[feature] + 2)\n    if feature + '_log' not in all_num_features:\n        all_num_features.append(feature + '_log')","62063cd2":"for feature in all_num_features:\n    scaler = StandardScaler()\n    scaler.fit(train_df[feature].append(test_df[feature]).astype(np.float64).values[:, np.newaxis])\n    \n    train_df[feature + '_scaled'] = scaler.transform(train_df[feature].astype(np.float64).values[:, np.newaxis])\n    test_df[feature + '_scaled'] = scaler.transform(test_df[feature].astype(np.float64).values[:, np.newaxis])","69619b0f":"y_train = train_df['AdoptionSpeed'].values","0d8b78c3":"n_splits = 5\nn_repeats = 5\n\nkfold = RepeatedStratifiedKFold(n_splits=n_splits, \n                                n_repeats=n_repeats,\n                                random_state=42)\nsplits = list(kfold.split(np.empty_like(y_train), y_train))","c9b1bbae":"import multiprocessing\nfrom keras.applications.densenet import preprocess_input, DenseNet121","b02cbd39":"def resize_to_square(im, size):\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(size) \/ max(old_size)\n    new_size = tuple([int(x * ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = size - new_size[1]\n    delta_h = size - new_size[0]\n    top, bottom = delta_h \/\/ 2, delta_h - (delta_h \/\/ 2)\n    left, right = delta_w \/\/ 2, delta_w - (delta_w \/\/ 2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n    return new_im\n\ndef load_image(path, pet_id, size, flip=False):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n        \n    if flip:\n        image = cv2.flip(image, 1)\n    \n    new_image = resize_to_square(image, size)\n    new_image = preprocess_input(new_image)\n    return new_image\n\ndef extract_img_features():\n    img_size = 512\n    batch_size = 16\n    \n    inp = Input((img_size, img_size, 3))\n\n    backbone = DenseNet121(input_tensor=inp, weights=PRETRAINED_WEIGHT_PATH, include_top=False)\n    x = backbone.output\n    out = GlobalAveragePooling2D()(x)\n    m = Model(inp, out)\n    \n    img_feature_dim = int(m.output.shape[1])\n    \n    img_features_train = np.zeros((len(train_df), img_feature_dim))\n    img_features_test = np.zeros((len(test_df), img_feature_dim))\n    img_features_train_flipped = np.zeros((len(train_df), img_feature_dim))\n\n    for df, path, features, kwargs in [\n        (train_df, TRAIN_IMAGES_PATH, img_features_train, {}),\n        (test_df, TEST_IMAGES_PATH, img_features_test, {}),\n        (train_df, TRAIN_IMAGES_PATH, img_features_train_flipped, {'flip': True})\n    ]:\n        pet_ids = df['PetID'].values\n        n_batches = int(np.ceil(len(pet_ids) \/ batch_size))\n\n        for b in tqdm(range(n_batches)):\n            start = b*batch_size\n            end = (b+1)*batch_size\n            batch_pets = pet_ids[start:end]\n            batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n            for i,pet_id in enumerate(batch_pets):\n                try:\n                    batch_images[i] = load_image(path, pet_id, img_size, **kwargs)\n                except:\n                    pass\n            batch_preds = m.predict(batch_images)\n            for i,pet_id in enumerate(batch_pets):\n                features[b * batch_size + i] = batch_preds[i]\n                \n    np.save('img_features_train.npy', img_features_train)\n    np.save('img_features_test.npy', img_features_test)    \n    np.save('img_features_train_flipped.npy', img_features_train_flipped)","a8a6f405":"p = multiprocessing.Process(target=extract_img_features)\np.start()\np.join()","4a644fd1":"img_features_train = np.load('img_features_train.npy')\nimg_features_test = np.load('img_features_test.npy')\nimg_features_train_flipped = np.load('img_features_train_flipped.npy')\n\nimg_feature_dim = img_features_train.shape[1]\nimg_feature_dim","4bcd35d8":"class Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        \n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n        \n        weight = torch.zeros(feature_dim, 1)\n        nn.init.xavier_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n        \n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n        \n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim\n        step_dim = self.step_dim\n\n        eij = torch.mm(\n            x.contiguous().view(-1, feature_dim), \n            self.weight\n        ).view(-1, step_dim)\n        \n        if self.bias:\n            eij = eij + self.b\n            \n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n        \n        if mask is not None:\n            a = a * mask\n\n        a = a \/ torch.sum(a, 1, keepdim=True) + 1e-10\n\n        weighted_input = x * torch.unsqueeze(a, -1)\n        return torch.sum(weighted_input, 1)\n    \nclass CyclicLR(object):\n    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n                 step_size=2000, factor=0.6, min_lr=1e-4, mode='triangular', gamma=1.,\n                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n\n        if not isinstance(optimizer, torch.optim.Optimizer):\n            raise TypeError('{} is not an Optimizer'.format(\n                type(optimizer).__name__))\n        self.optimizer = optimizer\n\n        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n            if len(base_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} base_lr, got {}\".format(\n                    len(optimizer.param_groups), len(base_lr)))\n            self.base_lrs = list(base_lr)\n        else:\n            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n\n        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n            if len(max_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} max_lr, got {}\".format(\n                    len(optimizer.param_groups), len(max_lr)))\n            self.max_lrs = list(max_lr)\n        else:\n            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n\n        self.step_size = step_size\n\n        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n                and scale_fn is None:\n            raise ValueError('mode is invalid and scale_fn is None')\n\n        self.mode = mode\n        self.gamma = gamma\n\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = self._triangular_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = self._triangular2_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = self._exp_range_scale_fn\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n\n        self.batch_step(last_batch_iteration + 1)\n        self.last_batch_iteration = last_batch_iteration\n        \n        self.last_loss = np.inf\n        self.min_lr = min_lr\n        self.factor = factor\n        \n    def batch_step(self, batch_iteration=None):\n        if batch_iteration is None:\n            batch_iteration = self.last_batch_iteration + 1\n        self.last_batch_iteration = batch_iteration\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr\n\n    def step(self, loss):\n        if loss > self.last_loss:\n            self.base_lrs = [max(lr * self.factor, self.min_lr) for lr in self.base_lrs]\n            self.max_lrs = [max(lr * self.factor, self.min_lr) for lr in self.max_lrs]\n            \n    def _triangular_scale_fn(self, x):\n        return 1.\n\n    def _triangular2_scale_fn(self, x):\n        return 1 \/ (2. ** (x - 1))\n\n    def _exp_range_scale_fn(self, x):\n        return self.gamma**(x)\n\n    def get_lr(self):\n        step_size = float(self.step_size)\n        cycle = np.floor(1 + self.last_batch_iteration \/ (2 * step_size))\n        x = np.abs(self.last_batch_iteration \/ step_size - 2 * cycle + 1)\n\n        lrs = []\n        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n        for param_group, base_lr, max_lr in param_lrs:\n            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n            if self.scale_mode == 'cycle':\n                lr = base_lr + base_height * self.scale_fn(cycle)\n            else:\n                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n            lrs.append(lr)\n        return lrs\n    \ndef train_model(model, train, valid, test, loss_fn, output_dim, lr=0.001, validate=True, enable_clr=True, verbose=False):\n    param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n    optimizer = torch.optim.Adam(param_lrs, lr=lr)\n\n    if enable_clr:\n        step_size = 300\n        scheduler = CyclicLR(optimizer, base_lr=0.002, max_lr=0.006,\n                             step_size=step_size, mode='exp_range',\n                             gamma=0.99994)\n    \n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n\n    best_loss = np.inf\n    \n    for epoch in range(n_epochs):\n        start_time = time.time()\n        model.train()\n        avg_loss = 0.\n        \n        model.epoch_started(epoch)\n        \n        for data in tqdm(train_loader, disable=(not verbose)):\n            x_batch = data[:-1]\n            y_batch = data[-1]\n\n            y_pred = model(*x_batch)\n            if enable_clr:\n                scheduler.batch_step()\n            \n            loss = loss_fn(y_pred, y_batch)\n\n            optimizer.zero_grad()\n\n            loss.backward()\n\n            optimizer.step()\n            avg_loss += loss.item() \/ len(train_loader)\n            \n        model.eval()\n        valid_preds = np.zeros((len(valid), output_dim))\n        \n        if validate:\n            avg_val_loss = 0.\n            for i, data in enumerate(valid_loader):\n                x_batch = data[:-1]\n                y_batch = data[-1]\n\n                y_pred = model(*x_batch).detach()\n\n                avg_val_loss += loss_fn(y_pred, y_batch).item() \/ len(valid_loader)\n                valid_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n\n            if avg_val_loss < best_loss:\n                if verbose:\n                    print('Saving model to best_model.torch')\n                torch.save(model.state_dict(), 'best_model.torch')\n                best_loss = avg_val_loss\n\n            elapsed_time = time.time() - start_time\n            if verbose:\n                print('Epoch {}\/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n                      epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n        else:\n            elapsed_time = time.time() - start_time\n            if verbose:\n                print('Epoch {}\/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n                      epoch + 1, n_epochs, avg_loss, elapsed_time))\n   \n    valid_preds = np.zeros((len(valid), output_dim))\n    \n    avg_val_loss = 0.\n    for i, data in enumerate(valid_loader):\n        x_batch = data[:-1]\n        y_batch = data[-1]\n        \n        y_pred = model(*x_batch).detach()\n\n        avg_val_loss += loss_fn(y_pred, y_batch).item() \/ len(valid_loader)\n        \n        valid_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n    \n    if verbose:\n        print('Validation loss: ', avg_val_loss)\n    \n    test_preds = np.zeros((len(test), output_dim))\n    \n    for i, x_batch in enumerate(test_loader):\n        y_pred = model(*x_batch).detach()\n\n        test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n\n    if validate:\n        model.load_state_dict(torch.load('best_model.torch'))\n\n        valid_preds_earlystop = np.zeros((len(valid), output_dim))\n\n        avg_val_loss = 0.\n        for i, data in enumerate(valid_loader):\n            x_batch = data[:-1]\n            y_batch = data[-1]\n\n            y_pred = model(*x_batch).detach()\n            \n            avg_val_loss += loss_fn(y_pred, y_batch).item() \/ len(valid_loader)            \n            valid_preds_earlystop[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n    \n        if verbose:\n            print('Validation loss: ', avg_val_loss)\n\n        test_preds_earlystop = np.zeros((len(test), output_dim))\n\n        for i, x_batch in enumerate(test_loader):\n            y_pred = model(*x_batch).detach()\n\n            test_preds_earlystop[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n\n        return valid_preds, test_preds, valid_preds_earlystop, test_preds_earlystop\n    else:\n        return valid_preds, test_preds","8b31bf67":"max_features = None\nmaxlen = 200","ee56fcbe":"train_text = list(train_df['sentence_text_rnn'].fillna(''))\ntest_text = list(test_df['sentence_text_rnn'].fillna(''))\nall_text = train_text + test_text\n\ntokenizer = Tokenizer(num_words=max_features, filters='')\ntokenizer.fit_on_texts(all_text)\ntrain_sequences = tokenizer.texts_to_sequences(train_text)\ntest_sequences = tokenizer.texts_to_sequences(test_text)\n\ntrain_text_tokens = pad_sequences(train_sequences, maxlen=maxlen)\ntest_text_tokens = pad_sequences(test_sequences, maxlen=maxlen)","fcc78035":"max_features = max_features or len(tokenizer.word_index) + 1\nmax_features","560f67f0":"def load_glove(word_index, max_features, path):\n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n    \n    embeddings_index = []\n    for o in tqdm(open(path)):\n        try:\n            embeddings_index.append(get_coefs(*o.split(\" \")))\n        except Exception as e:\n            print(e)\n    \n    embeddings_index = dict(embeddings_index)\n            \n    all_embs = np.stack(list(embeddings_index.values()))\n    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n\n    nb_words = min(max_features, len(word_index) + 1)\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    unknown_words = []\n    \n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word.lower())\n        \n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(word.upper())\n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(word.capitalize())\n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(stemmer.stem(word))\n            \n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n        else:\n            unknown_words.append(word)\n\n    return embeddings_index, embedding_matrix, unknown_words\n\ndef load_crawl(word_index, max_features, path):\n    def get_coefs(word,*arr): return word, np.asarray(list(arr) + [0] * max(0, (300 - len(arr))), dtype='float32')\n    \n    embeddings_index = []\n    for o in tqdm(open(path)):\n        if len(o) <= 100:\n            continue\n\n        try:\n            embeddings_index.append(get_coefs(*o.strip().split(\" \")))\n        except Exception as e:\n            print(e)\n\n    embeddings_index = dict(embeddings_index)\n\n    all_embs = np.stack(list(embeddings_index.values()))\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n\n    nb_words = min(max_features, len(word_index) + 1)\n    embedding_matrix = np.zeros((nb_words, embed_size))\n    unknown_words = []\n    \n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word.lower())\n        \n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(word.upper())\n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(word.capitalize())\n        if embedding_vector is None:\n            embedding_vector = embeddings_index.get(stemmer.stem(word))\n        \n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n        else:\n            unknown_words.append(word)\n\n    return embeddings_index, embedding_matrix, unknown_words","7aa06e8d":"num_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'doc_sent_mag',\n                'doc_sent_score', 'MaturitySize', 'FurLength', 'Health', \n                'RescuerID_count_binned', 'Breed1_count_log', 'Breed2_count_log', \n                'gdp_vs_population']\n\ncat_features = ['Dewormed', 'Vaccinated', 'Sterilized', 'Breed1', 'Type',\n                'Breed2', 'State', 'Gender', 'Color1', 'Color2', 'Color3', 'no_name']\n\nfor image in [1]:\n    num_features += [f'dominant_score_{image}', f'dominant_pixel_frac_{image}', \n                     f'dominant_red_{image}', f'dominant_green_{image}', \n                     f'dominant_blue_{image}', f'bounding_importance_{image}', \n                     f'bounding_confidence_{image}', f'vertex_x_{image}', \n                     f'vertex_y_{image}', f'label_score_{image}']\n    cat_features += [f'top_label_description_{image}']","53642683":"batch_size = 128\nn_epochs = 10","9f046aac":"train_text = train_df['sentence_text_stemmed'].fillna('')\ntest_text = test_df['sentence_text_stemmed'].fillna('')\nall_text = list(train_text) + list(test_text)\n\nword_vectorizer = Pipeline([\n    ('cv', TfidfVectorizer(min_df=2,\n                           strip_accents='unicode', \n                           analyzer='word',\n                           stop_words='english',\n                           token_pattern=r'[\\w@]{1,}',\n                           ngram_range=(1, 3), \n                           use_idf=1, \n                           smooth_idf=1, \n                           sublinear_tf=1)),\n])\n\nword_vectorizer.fit(all_text)\n\nword_features_train_desc = word_vectorizer.transform(train_text)\nword_features_test_desc = word_vectorizer.transform(test_text)","b0d13511":"train_text = train_df['all_label_descriptions'].fillna('')\ntest_text = test_df['all_label_descriptions'].fillna('')\nall_text = list(train_text) + list(test_text)\n\nword_vectorizer = Pipeline([\n    ('cv', TfidfVectorizer(ngram_range=(1, 2),\n                           use_idf=1,\n                           smooth_idf=1,\n                           sublinear_tf=1)), \n    ('dim_reduce', TruncatedSVD(n_components=5, random_state=10, algorithm='arpack'))\n])\n\nword_vectorizer.fit(all_text)\n\nword_features_train_label = scipy.sparse.csr_matrix(word_vectorizer.transform(train_text))\nword_features_test_label = scipy.sparse.csr_matrix(word_vectorizer.transform(test_text))","4ff247b4":"word_features_train = scipy.sparse.hstack([word_features_train_desc, word_features_train_label], format='coo')\nword_features_test = scipy.sparse.hstack([word_features_test_desc, word_features_test_label], format='coo')\n\ndel word_features_train_desc\ndel word_features_test_desc\ndel word_features_train_label\ndel word_features_test_label\nprint(word_features_train.shape)","57cb9ee8":"def scipy_sparse_to_pytorch_dense(matrix):\n    values = matrix.data\n    indices = np.vstack((matrix.row, matrix.col))\n\n    i = torch.LongTensor(indices)\n    v = torch.FloatTensor(values)\n    shape = matrix.shape\n\n    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).cuda().to_dense()\n\nword_tensor_train = scipy_sparse_to_pytorch_dense(word_features_train)\nword_tensor_test = scipy_sparse_to_pytorch_dense(word_features_test)","6da655d6":"features = [\n    word_tensor_train,\n    torch.tensor(img_features_train, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([train_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\ntest_features = [\n    word_tensor_test,\n    torch.tensor(img_features_test, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([test_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(test_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\n\ny_train = train_df['AdoptionSpeed'].values\ny_train_torch = torch.tensor(y_train[:, np.newaxis], dtype=torch.float32).cuda()\n\ntest_dataset = torch.utils.data.TensorDataset(*test_features)","9b4615cd":"class RNNModel(nn.Module):\n    def __init__(self, seed):\n        super(RNNModel, self).__init__()\n        \n        seed_everything(seed)\n        \n        fc_dropout = 0.1\n        embed_size = 300\n        emb_dropout = 0.1\n        cat_emb_dropout = 0.0\n        emb_conc_dropout = 0.1\n        img_act_dropout = 0.1\n        img_dropout = 0.1\n        num_dropout = 0.0\n        word_dropout = 0.8\n        batch_word_dropout = 0.4\n        \n        embedding_feature_sizes = [train_df[x + '_label'].append(test_df[x + '_label']).max() + 1 \\\n                                   for x in cat_features]\n        embedding_sizes = [20, 20, 20, 40, 20, 40, 40, 20, 20, 20, 20, 20, 20]\n        self.embeddings = nn.ModuleList([\n            nn.Embedding(embedding_feature_sizes[i], embedding_sizes[i]) for i in range(len(cat_features))\n        ])\n        self.cat_embedding_dropout = nn.Dropout(cat_emb_dropout)\n        \n        self.embedding_linear = nn.Linear(np.sum(embedding_sizes), 32)\n        self.embed_dropout = nn.Dropout(emb_conc_dropout)\n        \n        self.num_linear = nn.Linear(len(num_features), 64)\n        self.num_dropout = nn.Dropout(num_dropout)\n        \n        self.img_act_linear = nn.Linear(img_feature_dim, 64)\n        self.img_act_dropout = nn.Dropout(img_act_dropout)\n        \n        self.word_linear = nn.Linear(word_features_train.shape[1], 8)\n        self.word_dropout = nn.Dropout(word_dropout)\n        self.batch_word_dropout = nn.Dropout2d(batch_word_dropout)\n        \n        self.dropout = nn.Dropout(fc_dropout)\n        self.linear = nn.Linear(self.img_act_linear.out_features + \\\n                                self.num_linear.out_features + \\\n                                self.embedding_linear.out_features + \\\n                                self.word_linear.out_features, 16)\n        self.out = nn.Linear(self.linear.out_features, 1)\n        \n    def epoch_started(self, epoch):\n        pass\n    \n    def forward(self, x_words, x_img_act, x_num, x_cat):\n        activation = F.elu\n            \n        img_act_out = activation(\n            self.img_act_dropout(\n                self.img_act_linear(x_img_act)\n            )\n        )\n        \n        word_out = activation(\n            self.word_dropout(self.batch_word_dropout(\n                self.word_linear(\n                    x_words\n                ).unsqueeze(1)\n            ).squeeze(1))\n        )\n        \n        embedding_out = []\n        for i in range(len(cat_features)):\n            x = self.embeddings[i](x_cat[:, i])\n            x = self.cat_embedding_dropout(x)\n            embedding_out.append(x)\n        \n        embedding_conc = torch.cat(embedding_out, 1)\n        embedding_conc = activation(\n            self.embed_dropout(\n                self.embedding_linear(embedding_conc)\n            )\n        )\n        \n        num_out = activation(\n            self.num_dropout(\n                self.num_linear(x_num)\n            )\n        )\n        \n        conc = torch.cat([img_act_out, num_out, embedding_conc, word_out], 1)\n\n        conc = self.dropout(conc)\n        conc = activation(\n            self.linear(conc)\n        )\n        out = self.out(conc)\n        \n        return out","d14d8198":"def run_nn(index, train_index, val_index):\n    full_dataset = torch.utils.data.TensorDataset(*features, y_train_torch)\n    train_dataset = torch.utils.data.Subset(full_dataset, train_index)\n    valid_dataset = torch.utils.data.Subset(full_dataset, val_index)\n    \n    model = RNNModel(seed=index + 1)\n    model.cuda()\n    \n    valid_preds, test_preds, _, _ = train_model(model, train_dataset, \n                                                valid_dataset, test_dataset, \n                                                loss_fn=nn.MSELoss(reduction='mean'),\n                                                output_dim=1,\n                                                enable_clr=True)\n\n    return valid_preds[:, 0], test_preds[:, 0], model","31f12b90":"%%time\ntrain_preds_nn_1 = np.zeros((n_repeats, len(train_df)))\ntest_preds_nn_1 = np.zeros((n_repeats, len(test_df), n_splits))\n\nfor i, (train_index, val_index) in enumerate(splits):\n    train_preds_nn_1[i \/\/ n_splits, val_index], test_preds_nn_1[i \/\/ n_splits, :, i % n_splits], _ = run_nn(i, train_index, val_index)","b36bd1b7":"del word_features_train\ndel word_features_test\ndel features\ndel test_features\ngc.collect()\ntorch.cuda.empty_cache()","b765c022":"batch_size = 128\nn_epochs = 10","1ff3bad5":"seed_everything()\n_, crawl_matrix, unknown_words_crawl = load_crawl(tokenizer.word_index, max_features, EMBEDDING_FILE_CRAWL)\nprint('words unknown: ', len(unknown_words_crawl))","686f3839":"features = [\n    torch.tensor(train_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_train, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([train_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\ntest_features = [\n    torch.tensor(test_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_test, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([test_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(test_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\n\ny_train = train_df['AdoptionSpeed'].values\ny_train_torch = torch.tensor(y_train[:, np.newaxis], dtype=torch.float32).cuda()\n\ntest_dataset = torch.utils.data.TensorDataset(*test_features)","21fca4a8":"class RNNModel(nn.Module):\n    def __init__(self, seed):\n        super(RNNModel, self).__init__()\n        \n        seed_everything(seed)\n        \n        fc_dropout = 0.1\n        embed_size = 300\n        emb_dropout = 0.15\n        cat_emb_dropout = 0.0\n        emb_conc_dropout = 0.1\n        img_act_dropout = 0.1\n        img_dropout = 0.1\n        num_dropout = 0.0\n        hidden_size = 20\n        \n        embedding_feature_sizes = [train_df[x + '_label'].append(test_df[x + '_label']).max() + 1 \\\n                                   for x in cat_features]\n        embedding_sizes = [20, 20, 20, 40, 20, 40, 40, 20, 20, 20, 20, 20, 20]\n        self.embeddings = nn.ModuleList([\n            nn.Embedding(embedding_feature_sizes[i], embedding_sizes[i]) for i in range(len(cat_features))\n        ])\n        self.cat_embedding_dropout = nn.Dropout(cat_emb_dropout)\n        \n        self.embedding_linear = nn.Linear(np.sum(embedding_sizes), 32)\n        self.embed_dropout = nn.Dropout(emb_conc_dropout)\n        \n        self.num_linear = nn.Linear(len(num_features), 64)\n        self.num_dropout = nn.Dropout(num_dropout)\n        \n        self.img_act_linear = nn.Linear(img_feature_dim, 64)\n        self.img_act_dropout = nn.Dropout(img_act_dropout)\n        \n        self.embedding = nn.Embedding(max_features, embed_size,\n                                      _weight=nn.Parameter(torch.tensor(crawl_matrix, dtype=torch.float32)))\n        self.embedding.weight.requires_grad = False\n        self.embedding_dropout = nn.Dropout2d(emb_dropout)\n        \n        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True, dropout=0.1)\n        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n        \n        self.dropout = nn.Dropout(fc_dropout)\n        self.linear = nn.Linear(self.img_act_linear.out_features + \\\n                                self.num_linear.out_features + \\\n                                self.embedding_linear.out_features + \\\n                                hidden_size * 4, 16)\n        self.out = nn.Linear(self.linear.out_features, 1)\n        \n    def epoch_started(self, epoch):\n        pass\n \n    def forward(self, x_words, x_img_act, x_num, x_cat):\n        activation = F.elu\n\n        img_act_out = activation(\n            self.img_act_dropout(\n                self.img_act_linear(x_img_act)\n            )\n        )\n\n        embedding_out = []\n        for i in range(len(cat_features)):\n            x = self.embeddings[i](x_cat[:, i])\n            x = torch.squeeze(self.cat_embedding_dropout(torch.unsqueeze(x, 0)), 0)\n            embedding_out.append(x)\n        \n        embedding_out = torch.cat(embedding_out, 1)\n        embedding_out = activation(\n            self.embed_dropout(\n                self.embedding_linear(embedding_out)\n            )\n        )\n        \n        num_out = activation(\n            self.num_dropout(\n                self.num_linear(x_num)\n            )\n        )\n        \n        h_embedding = self.embedding(x_words)\n        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)), 0)\n        \n        h_lstm, _ = self.lstm(h_embedding)\n        h_lstm_atten = self.lstm_attention(h_lstm)\n\n        max_pool, _ = torch.max(h_lstm, 1)\n        \n        conc = torch.cat([img_act_out, num_out, embedding_out, max_pool, h_lstm_atten], 1)\n\n        conc = self.dropout(conc)\n        conc = activation(\n            self.linear(conc)\n        )\n        out = self.out(conc)\n        \n        return out\n\ndef run_nn(index, train_index, val_index):\n    full_dataset = torch.utils.data.TensorDataset(*features, y_train_torch)\n    train_dataset = torch.utils.data.Subset(full_dataset, train_index)\n    valid_dataset = torch.utils.data.Subset(full_dataset, val_index)\n    \n    model = RNNModel(seed=index + 1)\n    model.cuda()\n    \n    valid_preds, test_preds, _, _ = train_model(model, train_dataset, \n                                                valid_dataset, test_dataset, \n                                                loss_fn=nn.MSELoss(reduction='mean'),\n                                                output_dim=1,\n                                                enable_clr=True)\n    \n    return valid_preds[:, 0], test_preds[:, 0], model","53b8dc79":"%%time\ntrain_preds_nn_2 = np.zeros((n_repeats, len(train_df)))\ntest_preds_nn_2 = np.zeros((n_repeats, len(test_df), n_splits))\n\nfor i, (train_index, val_index) in enumerate(splits):\n    train_preds_nn_2[i \/\/ n_splits, val_index], test_preds_nn_2[i \/\/ n_splits, :, i % n_splits], _ = run_nn(i, train_index, val_index)","b71887bf":"seed_everything()\n_, glove_matrix_small, unknown_words_small = load_glove(tokenizer.word_index, max_features, EMBEDDING_FILE_SMALL)\nprint('words unknown: ', len(unknown_words_small))","8987058f":"features = [\n    torch.tensor(train_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_train_flipped, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([train_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\ntest_features = [\n    torch.tensor(test_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_test, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([test_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(test_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\n\ny_train = train_df['AdoptionSpeed'].values\ny_train_torch = torch.tensor(y_train[:, np.newaxis], dtype=torch.float32).cuda()\n    \ntest_dataset = torch.utils.data.TensorDataset(*test_features)","3c764f2e":"class RNNModel(nn.Module):\n    def __init__(self, seed):\n        super(RNNModel, self).__init__()\n        \n        seed_everything(seed)\n        \n        fc_dropout = 0.1\n        embed_size = 200\n        emb_dropout = 0.2\n        cat_emb_dropout = 0.0\n        emb_conc_dropout = 0.1\n        img_act_dropout = 0.1\n        img_dropout = 0.1\n        num_dropout = 0.0\n        hidden_size = 20\n        \n        embedding_feature_sizes = [train_df[x + '_label'].append(test_df[x + '_label']).max() + 1 \\\n                                   for x in cat_features]\n        embedding_sizes = [20, 20, 20, 40, 20, 40, 40, 20, 20, 20, 20, 20, 20]\n        self.embeddings = nn.ModuleList([\n            nn.Embedding(embedding_feature_sizes[i], embedding_sizes[i]) for i in range(len(cat_features))\n        ])\n        self.cat_embedding_dropout = nn.Dropout(cat_emb_dropout)\n        \n        self.embedding_linear = nn.Linear(np.sum(embedding_sizes), 32)\n        self.embed_dropout = nn.Dropout(emb_conc_dropout)\n        \n        self.num_linear = nn.Linear(len(num_features), 64)\n        self.num_dropout = nn.Dropout(num_dropout)\n        \n        self.img_act_linear = nn.Linear(img_feature_dim, 64)\n        self.img_act_dropout = nn.Dropout(img_act_dropout)\n        \n        self.embedding = nn.Embedding(max_features, embed_size,\n                                      _weight=nn.Parameter(torch.tensor(glove_matrix_small, dtype=torch.float32)))\n        self.embedding.weight.requires_grad = False\n        self.embedding_dropout = nn.Dropout2d(emb_dropout)\n        \n        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True, dropout=0.1)\n        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n        \n        self.dropout = nn.Dropout(fc_dropout)\n        self.linear = nn.Linear(self.img_act_linear.out_features + \\\n                                self.num_linear.out_features + \\\n                                self.embedding_linear.out_features + \\\n                                hidden_size * 4, 16)\n        self.out = nn.Linear(self.linear.out_features, 1)\n        \n    def epoch_started(self, epoch):\n        if epoch >= 6:\n            self.embedding.weight.requires_grad = True\n \n    def forward(self, x_words, x_img_act, x_num, x_cat):\n        activation = F.elu\n\n        img_act_out = activation(\n            self.img_act_dropout(\n                self.img_act_linear(x_img_act)\n            )\n        )\n\n        embedding_out = []\n        for i in range(len(cat_features)):\n            x = self.embeddings[i](x_cat[:, i])\n            x = torch.squeeze(self.cat_embedding_dropout(torch.unsqueeze(x, 0)), 0)\n            embedding_out.append(x)\n        \n        embedding_out = torch.cat(embedding_out, 1)\n        embedding_out = activation(\n            self.embed_dropout(\n                self.embedding_linear(embedding_out)\n            )\n        )\n        \n        num_out = activation(\n            self.num_dropout(\n                self.num_linear(x_num)\n            )\n        )\n        \n        h_embedding = self.embedding(x_words)\n        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)), 0)\n        \n        h_lstm, _ = self.lstm(h_embedding)\n        h_lstm_atten = self.lstm_attention(h_lstm)\n\n        max_pool, _ = torch.max(h_lstm, 1)\n        \n        conc = torch.cat([img_act_out, num_out, embedding_out, max_pool, h_lstm_atten], 1)\n\n        conc = self.dropout(conc)\n        conc = activation(\n            self.linear(conc)\n        )\n        out = self.out(conc)\n        \n        return out\n\ndef run_nn(index, train_index, val_index):\n    full_dataset = torch.utils.data.TensorDataset(*features, y_train_torch)\n    train_dataset = torch.utils.data.Subset(full_dataset, train_index)\n    valid_dataset = torch.utils.data.Subset(full_dataset, val_index)\n    \n    model = RNNModel(seed=index + 1)\n    model.cuda()\n    \n    valid_preds, test_preds, _, _ = train_model(model, train_dataset, \n                                                valid_dataset, test_dataset, \n                                                loss_fn=nn.SmoothL1Loss(reduction='mean'),\n                                                output_dim=1,\n                                                enable_clr=True)\n    return valid_preds[:, 0], test_preds[:, 0], model","dff54315":"%%time\ntrain_preds_nn_3 = np.zeros((n_repeats, len(train_df)))\ntest_preds_nn_3 = np.zeros((n_repeats, len(test_df), n_splits))\n\nfor i, (train_index, val_index) in enumerate(splits):\n    train_preds_nn_3[i \/\/ n_splits, val_index], test_preds_nn_3[i \/\/ n_splits, :, i % n_splits], _ = run_nn(i, train_index, val_index)","f21dd1a8":"features = [\n    torch.tensor(train_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_train, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([train_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\ntest_features = [\n    torch.tensor(test_text_tokens, dtype=torch.long).cuda(),\n    torch.tensor(img_features_test, dtype=torch.float32).cuda(),\n    torch.tensor(np.hstack([test_df[[x + '_scaled' for x in num_features]].values]), dtype=torch.float32).cuda(),\n    torch.tensor(test_df[[x + '_label' for x in cat_features]].values, dtype=torch.long).cuda(),\n]\nall_features = [\n    torch.tensor(np.vstack([train_text_tokens, test_text_tokens]), dtype=torch.long).cuda(),\n    torch.tensor(np.vstack([img_features_train, img_features_test]), dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_scaled' for x in num_features]].append(test_df[[x + '_scaled' for x in num_features]]).values, dtype=torch.float32).cuda(),\n    torch.tensor(train_df[[x + '_label' for x in cat_features]].append(test_df[[x + '_label' for x in cat_features]]).values, dtype=torch.long).cuda(),\n]\n\ny_train_torch = torch.tensor(\n    train_df[['Type', 'Age_scaled', 'Breed1_label']].append(test_df[['Type', 'Age_scaled', 'Breed1_label']]).values, \n    dtype=torch.float32\n).cuda()\n# rescale Type feature from 1 to 2 to 0 to 1 for binary crossentropy\ny_train_torch[:, 0] -= 1\n\nfull_dataset = torch.utils.data.TensorDataset(*all_features, y_train_torch)","a8301338":"out_shape = 3 + train_df['Breed1_label'].append(test_df['Breed1_label']).max()\n\nclass ExtractorLoss(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super(ExtractorLoss, self).__init__()\n        self.mse_loss = nn.MSELoss()\n        self.bce_loss = nn.BCEWithLogitsLoss()\n        self.ce_loss = nn.CrossEntropyLoss()\n        \n    def forward(self, y_pred, y_true):\n        return self.bce_loss(y_pred[:, [0]], y_true[:, [0]]) + \\\n               self.mse_loss(y_pred[:, [1]], y_true[:, [1]]) + \\\n               self.ce_loss(y_pred[:, 2:], y_true[:, 2].long())\n        \nclass ExtractorModel(nn.Module):\n    def __init__(self, seed):\n        super(ExtractorModel, self).__init__()\n        \n        seed_everything(seed)\n        \n        img_dropout = 0.1\n        emb_dropout = 0.0\n        hidden_size = 20\n        embed_size = 300\n        \n        self.img_linear = nn.Linear(img_feature_dim, 64)\n        self.img_dropout = nn.Dropout(img_dropout)\n        \n        self.linear = nn.Linear(self.img_linear.out_features, 16)\n        self.out = nn.Linear(self.linear.out_features, out_shape)\n        \n    def epoch_started(self, epoch):\n        pass\n        \n    def forward(self, x_words, x_img_act, x_num, x_cat, extract_features=False):\n        activation = F.elu\n        \n        h1 = activation(\n            self.img_dropout(\n                self.img_linear(x_img_act)\n            )\n        )\n        \n        h2 = activation(\n            self.linear(h1)\n        )\n        \n        if extract_features:\n            return torch.cat([h1, h2], 1)\n        \n        out = self.out(h2)\n        return out\n\nfull_dataset = torch.utils.data.TensorDataset(*all_features, y_train_torch)\n# set valid and test dataset to the same dataset to be able to use train_model without any modifications\nvalid_dataset = full_dataset\ntest_dataset = torch.utils.data.TensorDataset(*all_features)\n\nmodel = ExtractorModel(seed=1234)\nmodel.cuda()\n\n(valid_preds, test_preds, \n valid_preds_earlystop, test_preds_earlystop) = train_model(model, full_dataset, valid_dataset, test_dataset, \n                                                            loss_fn=ExtractorLoss(),\n                                                            output_dim=out_shape,\n                                                            enable_clr=True)","a0834ee2":"def predict_batches(model, x, shape=64, batch_size=64, **kwargs):\n    loader = torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=False)\n    \n    out = np.zeros((len(x), shape))\n    \n    for i, batch in enumerate(loader):\n        start, end = i * batch_size, (i + 1) * batch_size\n        end = min(end, len(x))\n        \n        out[start:end] = model(*batch , **kwargs).detach().cpu().numpy()\n    return out","b711e381":"train_dataset = torch.utils.data.TensorDataset(*features)\ntest_dataset = torch.utils.data.TensorDataset(*test_features)\n\ntrain_activations = predict_batches(model, train_dataset, batch_size=512, shape=64 + 16, extract_features=True)\ntest_activations = predict_batches(model, test_dataset, batch_size=512, shape=64 + 16, extract_features=True)","4c42523b":"train_text = train_df['sentence_text_stemmed'].fillna('')\ntest_text = test_df['sentence_text_stemmed'].fillna('')\nall_text = list(train_text) + list(test_text)\n\nword_vectorizer = Pipeline([\n    ('cv', TfidfVectorizer(min_df=3,  \n                           max_features=10000,\n                           strip_accents='unicode', \n                           analyzer='word',\n                           token_pattern=r'[\\w@]{1,}',\n                           ngram_range=(1, 3), \n                           use_idf=1, \n                           smooth_idf=1, \n                           sublinear_tf=1)),\n    ('svd', TruncatedSVD(n_components=120, algorithm='arpack', random_state=10))\n])\n\nword_vectorizer.fit(all_text)\n\nword_features_train_desc = word_vectorizer.transform(train_text)\nword_features_test_desc = word_vectorizer.transform(test_text)","c301df56":"from sklearn.decomposition import NMF\n\ntrain_text = train_df['all_label_descriptions'].fillna('')\ntest_text = test_df['all_label_descriptions'].fillna('')\nall_text = list(train_text) + list(test_text)\n\nword_vectorizer = Pipeline([\n    ('cv', TfidfVectorizer(ngram_range=(1, 2),\n                           use_idf=1,\n                           smooth_idf=1,\n                           sublinear_tf=1)), \n    ('dim_reduce', TruncatedSVD(n_components=5, random_state=10, algorithm='arpack'))\n])\n\nword_vectorizer.fit(all_text)\n\nword_features_train_label = word_vectorizer.transform(train_text)\nword_features_test_label = word_vectorizer.transform(test_text)","aa070d71":"word_features_train = np.hstack([word_features_train_desc, word_features_train_label])\nword_features_test = np.hstack([word_features_test_desc, word_features_test_label])\nword_features_train.shape","a884a3d9":"num_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'doc_sent_mag',\n                'doc_sent_score', 'MaturitySize', 'FurLength', 'Health', \n                'RescuerID_count', 'Breed1_count', 'Breed2_count', 'State_count', \n                'gdp_vs_population'] + aggregate_features\n\ncat_features = ['Dewormed', 'Vaccinated', 'Sterilized', 'Breed1', 'Type', \n                'Dewormed_Vaccinated', 'Breed2', 'State', 'Gender', 'Color1',\n                'Color2', 'Color3', 'no_name']\n\nfor image in [1]:\n    cat_features += [f'top_label_description_{image}']","ad0f3930":"feature_names = [f'activation_{i}' for i in range(64)] + \\\n                [f'word_{i}' for i in range(word_features_train.shape[1])] + \\\n                num_features + cat_features\nx_train = np.hstack([\n    train_activations[:, :64],\n    word_features_train,\n    train_df[num_features],\n    train_df[[x + '_label' for x in cat_features]]\n])\nx_test = np.hstack([\n    test_activations[:, :64],\n    word_features_test,\n    test_df[num_features],\n    test_df[[x + '_label' for x in cat_features]]    \n])\n\nprint(len(feature_names))\ny_train = train_df['AdoptionSpeed'].values\nx_train.shape, x_test.shape","7cdec03e":"params = {\n    'application': 'regression',\n    'boosting': 'gbdt',\n    'metric': 'mse',\n    'num_leaves': 102,\n    'learning_rate': 0.02,\n    'bagging_fraction': 0.9951448659512921,\n    'bagging_freq': 3,\n    'feature_fraction': 0.6867901263802068,\n    'verbosity': -1,\n    'early_stop': 100,\n    'verbose_eval': 1000,\n    'num_rounds': 10000,\n    'raw_seed': 1234,\n    'max_bin': 127,\n    'min_child_samples': 38,\n    'lambda_l1': 0.42651295024341174,\n    'lambda_l2': 0.15395842517107572,\n    'max_depth': 14,\n    'min_split_gain': 0.023658591149106636\n}","07f97f21":"def run_lightgbm(x_train, y_train, x_valid, y_valid, x_test, index):\n    params['seed'] = params['raw_seed'] + index\n    num_rounds = params['num_rounds']\n    verbose_eval = params['verbose_eval']\n    early_stop = params['early_stop']\n\n    x_train_proc, x_valid_proc, x_test_proc = x_train, x_valid, x_test\n\n    dtrain = lgb.Dataset(x_train_proc, y_train, feature_name=feature_names, \n                         categorical_feature=cat_features)\n    dvalid = lgb.Dataset(x_valid_proc, y_valid, feature_name=feature_names,\n                         categorical_feature=cat_features)\n\n    model = lgb.train(params,\n                      train_set=dtrain,\n                      valid_sets=(dtrain, dvalid),\n                      num_boost_round=num_rounds,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n    return  model.predict(x_valid_proc), model.predict(x_test_proc)","8922fb41":"%%time\ntrain_preds_lgb = np.zeros((n_repeats, len(train_df)))\ntest_preds_lgb = np.zeros((n_repeats, len(test_df), n_splits))\n\nfor i, (train_index, val_index) in enumerate(splits):\n    train_preds_lgb[i \/\/ n_splits, val_index], test_preds_lgb[i \/\/ n_splits, :, i % n_splits] = run_lightgbm(x_train[train_index], y_train[train_index],\n                                                                                                             x_train[val_index], y_train[val_index], x_test, i)","7178832a":"train_text = train_df['sentence_text_stemmed'].fillna('')\ntest_text = test_df['sentence_text_stemmed'].fillna('')\nall_text = list(train_text) + list(test_text)\n\nword_vectorizer = Pipeline([\n    ('cv', TfidfVectorizer(min_df=3,  \n                           max_features=10000,\n                           strip_accents='unicode', \n                           analyzer='word', \n                           token_pattern=r'[\\w@]{1,}',\n                           ngram_range=(1, 3), \n                           use_idf=1, \n                           smooth_idf=1, \n                           sublinear_tf=1)),\n    ('svd', TruncatedSVD(n_components=10, algorithm='arpack', random_state=10))\n])\n\nword_vectorizer.fit(all_text)\n\nword_features_train = word_vectorizer.transform(train_text)\nword_features_test = word_vectorizer.transform(test_text)","7b920c8f":"num_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'doc_sent_mag',\n                'doc_sent_score', 'MaturitySize', 'FurLength', 'Health', 'RescuerID_count',\n                'Breed1_count', 'Breed2_count', 'State_count', 'gdp_vs_population']\n\ncat_features = ['Dewormed', 'Vaccinated', 'Sterilized', 'Breed1', 'Type', \n                'Dewormed_Vaccinated', 'Breed2', 'State', 'Gender', 'Color1', \n                'Color2', 'Color3', 'no_name'] \n\nfor image in [1]:\n    num_features += [f'dominant_score_{image}', f'dominant_pixel_frac_{image}', \n                     f'dominant_red_{image}', f'dominant_green_{image}', \n                     f'dominant_blue_{image}', f'bounding_importance_{image}', \n                     f'bounding_confidence_{image}', f'vertex_x_{image}', \n                     f'vertex_y_{image}', f'label_score_{image}']\n    cat_features += [f'top_label_description_{image}']","fc58a305":"n_word_bins = 10\nword_bins = np.unique(pd.Series(word_features_train.flatten()).quantile(np.linspace(0, 1, n_word_bins)))\n\nn_img_bins = 10\nimg_bins = np.unique(pd.Series(train_activations[:, 64:].flatten()).quantile(np.linspace(0, 1, n_img_bins)))","3b37c05b":"feature_names = [f'activation_{i}' for i in range(16)] + \\\n                [f'word_{i}' for i in range(10)] + num_features + cat_features\nx_train = np.hstack([\n    np.digitize(word_features_train, word_bins),\n    np.digitize(train_activations[:, 64:], img_bins),\n    train_df[[x + '_binned' for x in num_features]],\n    train_df[[x + '_label' for x in cat_features]]    \n])\nx_test = np.hstack([\n    np.digitize(word_features_test, word_bins),\n    np.digitize(test_activations[:, 64:], img_bins),\n    test_df[[x + '_binned' for x in num_features]],\n    test_df[[x + '_label' for x in cat_features]]    \n])\n\nprint(len(feature_names))\ny_train = train_df['AdoptionSpeed'].values\nx_train.shape, x_test.shape","d7dc4978":"categories = num_features + [x + '_label' for x in cat_features]\nfield_features = defaultdict()\n\nmax_val = 1\nw = np.round(math.sqrt(2) \/ math.sqrt(x_train.shape[1]), 20)\n\nfor feature_arr, filename in [\n    (x_train, 'train.libffm'),\n    (x_test, 'test.libffm')\n]:\n    with open(filename, 'w') as the_file:\n        for i in tqdm(range(len(feature_arr))):\n            ffeatures = []\n\n            for j in range(feature_arr.shape[1]):\n                feature = feature_arr[i, j]\n                field = j\n\n                ff = str(field) + '_____' + str(feature)\n\n                if ff not in field_features:\n                    if len(field_features) == 0:\n                        field_features[ff] = 1\n                        max_val += 1\n                    else:\n                        field_features[ff] = max_val + 1\n                        max_val += 1\n\n                fnum = field_features[ff]\n                ffeatures.append('{}:{}:{}'.format(field, fnum, w))\n\n            line = [str(y_train[i])] + ffeatures\n            the_file.write('{}\\n'.format(' '.join(line)))\nmax_val","7ece530f":"ffm_train_data = pd.read_csv('train.libffm', squeeze=True, header=None)","e581672f":"def run_xlearn(index, train_index, val_index):\n    x_train_proc, x_valid_proc = ffm_train_data[train_index], ffm_train_data[val_index]\n    for path, data in [\n        ['ffm_train.txt', x_train_proc],\n        ['ffm_valid.txt', x_valid_proc]\n    ]:\n        with open(path, 'w') as f:\n            f.write(data.str.cat(sep='\\n'))\n\n    model = xl.create_ffm()\n    model.setTrain('.\/ffm_train.txt')\n    model.setValidate('.\/ffm_valid.txt')\n    \n    param = {\n        'task': 'reg', \n        'lr': 0.2,\n        'lambda': 0.0,\n        'opt': 'adagrad',\n        'k': 4,\n        'stop_window': 1\n    }\n    model.fit(param, '.\/model.out')\n    \n    model.setTest(\".\/ffm_train.txt\")\n    model.predict(\".\/model.out\", \".\/output.txt\")\n    \n    with open('output.txt', 'r') as f:\n        train_preds = np.array([float(x.strip()) for x in f.readlines()])\n    \n    model.setTest(\".\/ffm_valid.txt\")\n    model.predict(\".\/model.out\", \".\/output.txt\")\n    \n    with open('output.txt', 'r') as f:\n        valid_preds = np.array([float(x.strip()) for x in f.readlines()])\n    \n    model.setTest(\".\/test.libffm\")\n    model.predict(\".\/model.out\", \".\/output.txt\")\n    \n    with open('output.txt', 'r') as f:\n        test_preds = np.array([float(x.strip()) for x in f.readlines()])\n    \n    print(cohen_kappa_score(y_train[val_index], fix_distribution(y_train[train_index], valid_preds), weights='quadratic'))\n    return valid_preds, test_preds","ef702efb":"%%time\ntrain_preds_ffm = np.zeros((n_repeats, len(train_df)))\ntest_preds_ffm = np.zeros((n_repeats, len(test_df), n_splits))\n\nfor i, (train_index, val_index) in enumerate(splits):\n    train_preds_ffm[i \/\/ n_splits, val_index], test_preds_ffm[i \/\/ n_splits, :, i % n_splits] = run_xlearn(i, train_index, val_index)","3ac2fa9d":"params = {\n    'application': 'binary',\n    'boosting': 'gbdt',\n    'metric': 'auc',\n    'num_leaves': 80,\n    'max_depth': 9,\n    'learning_rate': 0.04,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 1,\n    'feature_fraction': 0.8,\n    'verbosity': -1,\n    'early_stop': 50,\n    'verbose_eval': 100,\n    'num_rounds': 10000\n}","35506e72":"num_features = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'doc_sent_mag',\n                'doc_sent_score', 'MaturitySize', 'FurLength', 'Health', 'RescuerID_count',\n                'Breed1_count', 'Breed2_count', 'State_count']\n\ncat_features = ['Dewormed', 'Vaccinated', 'Sterilized', 'Breed1', 'Type',\n                'Breed2', 'State', 'Gender', 'Color1', 'Color2', 'Color3', 'no_name']\n\nfor image in [1]:\n    num_features += [f'dominant_score_{image}', f'dominant_pixel_frac_{image}', f'dominant_red_{image}', \n                     f'dominant_green_{image}', f'dominant_blue_{image}', f'bounding_importance_{image}',\n                     f'bounding_confidence_{image}',  f'vertex_x_{image}', f'vertex_y_{image}', \n                     f'label_score_{image}']\n    cat_features += [f'top_label_description_{image}']","5ceb4aa8":"feature_names = num_features + cat_features\n\nx_train = np.hstack([\n    train_df[num_features].append(test_df[num_features]),\n    train_df[[x + '_label' for x in cat_features]].append(test_df[[x + '_label' for x in cat_features]])\n])\ny_train_adv = np.concatenate([np.zeros((len(train_df))), np.ones(len(test_df))])\n\nprint(f'n pos: {(y_train_adv == 1).sum()}')\nprint(f'n neg: {(y_train_adv == 0).sum()}')\nx_train.shape, y_train_adv.shape","c9900a84":"def run_adversarial_validation(x_train, y_train):\n    splits = list(StratifiedKFold(n_splits=5, random_state=42, shuffle=True).split(x_train, y_train))\n    feature_importance = np.zeros((len(feature_names)))\n    models = []\n\n    train_preds = np.zeros((x_train.shape[0]))\n    num_rounds = params['num_rounds']\n    verbose_eval = params['verbose_eval']\n    early_stop = params['early_stop']\n\n    for i, (train_index, val_index) in enumerate(splits):\n        dtrain = lgb.Dataset(x_train[train_index], y_train[train_index], \n                             feature_name=feature_names)\n        dvalid = lgb.Dataset(x_train[val_index], y_train[val_index], \n                             feature_name=feature_names)\n\n        model = lgb.train(params,\n                          train_set=dtrain,\n                          valid_sets=(dtrain, dvalid),\n                          num_boost_round=num_rounds,\n                          verbose_eval=verbose_eval,\n                          early_stopping_rounds=early_stop)\n        feature_importance += model.feature_importance() \/ model.feature_importance().sum()\n        train_preds[val_index] = model.predict(x_train[val_index])\n        models.append(model)\n\n    print('Overall AUC: ', roc_auc_score(y_train, train_preds))\n    return train_preds","3aabbf8c":"adv_scores = run_adversarial_validation(x_train, y_train_adv)","4944b059":"sns.jointplot(np.arange(len(train_df)), adv_scores[:len(train_df)], size=10, stat_func=None,\n              marginal_kws=dict(bins=15), joint_kws=dict(s=3))","bc08a301":"print('NN1: ', cohen_kappa_score(y_train, fix_distribution(y_train, train_preds_nn_1.mean(axis=0)), weights='quadratic'))\nprint('NN2: ', cohen_kappa_score(y_train, fix_distribution(y_train, train_preds_nn_2.mean(axis=0)), weights='quadratic'))\nprint('NN3: ', cohen_kappa_score(y_train, fix_distribution(y_train, train_preds_nn_3.mean(axis=0)), weights='quadratic'))\nprint('LGB: ', cohen_kappa_score(y_train, fix_distribution(y_train, train_preds_lgb.mean(axis=0)), weights='quadratic'))\nprint('FFM: ', cohen_kappa_score(y_train, fix_distribution(y_train, train_preds_ffm.mean(axis=0)), weights='quadratic'))","ada53b8f":"pd.DataFrame(np.hstack([\n    test_preds_nn_1.mean(axis=0).mean(axis=1)[:, np.newaxis],\n    test_preds_nn_2.mean(axis=0).mean(axis=1)[:, np.newaxis],\n    test_preds_nn_3.mean(axis=0).mean(axis=1)[:, np.newaxis],\n    test_preds_lgb.mean(axis=0).mean(axis=1)[:, np.newaxis],\n    test_preds_ffm.mean(axis=0).mean(axis=1)[:, np.newaxis]\n]), columns=['NN1', 'NN2', 'NN3', 'LGB', 'FFM']).corr()","a79e9fe5":"scores = []\nsample_weights = adv_scores[:len(train_df)]\nall_preds = []\nto_stack_train = [\n    train_preds_nn_1,\n    train_preds_nn_2,\n    train_preds_nn_3,\n    train_preds_lgb,\n    train_preds_ffm\n]\nto_stack_test = [\n    test_preds_nn_1,\n    test_preds_nn_2,\n    test_preds_nn_3,\n    test_preds_lgb,\n    test_preds_ffm\n]\n\nfor i in range(n_repeats):\n    print(f'Repeat {i}')\n    \n    clf = linear_model.LinearRegression()\n    x_train = np.hstack([x[i][:, np.newaxis] for x in to_stack_train])\n    x_test = np.hstack([x[i].mean(axis=1)[:, np.newaxis] for x in to_stack_test])\n\n    corrs = np.array([pd.DataFrame(x[i]).corr().values.mean() for x in to_stack_test])\n    \n    clf.fit(x_train, y_train, sample_weight=sample_weights)\n    coef = clf.coef_\n    print('coefs: ', coef)\n    print('corrs: ', corrs)\n    coef = coef \/ (corrs ** 2)\n    coef = coef \/ coef.sum()\n    print('Adjusted coefs: ', coef)\n    print()\n    \n    all_preds.append((x_test * coef).sum(axis=1))\n    \nfixed_scores = fix_distribution(y_train, np.array(all_preds).mean(axis=0))","b8675142":"pd.Series(fixed_scores).plot.hist(bins=9)","4b7cfc23":"submission = test_df[['PetID']].copy()\nsubmission['AdoptionSpeed'] = fixed_scores.astype(np.int32)\nsubmission.to_csv('submission.csv', index=False)","a16fa6ae":"Convert categorical features to labels.","117bf770":"# Stacking","a6081f5c":"Get text processed for RNN and for LGB \/ FFM and concatenate the used label descriptions to another feature. Also, create a feature no_name which is 1 if the pet does not seem to have a name.","2e5a9d23":"## Adversarial validation","f0927b05":"Build standard scaled numerical features.","32e6e134":"Punctutations and common misspellings as used in multiple solutions of the recent [quora competition](https:\/\/www.kaggle.com\/c\/quora-insincere-questions-classification):\n- [Solution 1](https:\/\/www.kaggle.com\/tks0123456789\/pme-ema-6-x-8-pochs)\n- [Solution 2](https:\/\/www.kaggle.com\/canming\/ensemble-mean-iii-64-36)\n- [Solution 3](https:\/\/www.kaggle.com\/mchahhou\/fork-of-quora-lb-no-cv-2)\n\nThey are considered common sense and not external data.","02a69b7d":"# Image extractor","385d8760":"# Training NN 2 - Non-trainable 300d crawl embeddings","90d10a92":"Build bin features. Bins are constructed by quantiles.","f2c6a9a0":"Malaysian state GDP and population as discussed [here](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/discussion\/78040).","75895f52":"Other than that, I only used Crawl and GloVe embeddings. They will be loaded when needed to save some precious RAM earlier. ","bdbf2bf1":"Define all numerical and categorical features.","a4075d5f":"All this code might seem a little overwhelming at first, but it is really not that complex. There are seven parts:\n- Preprocessing\n- Training NN1\n- Training NN2\n- Training NN3\n- Image Extractor\n- Training LightGBM\n- Training xlearn\n- Stacking\n\nI'll briefly describe each of them.\n\n### Preprocessing\n\nIn the preprocessing part, external data sources are loaded and the features are processed by:\n- scaling them appropriately\n- building frequency encoded features of some variables\n- binning some features\n- scaling some features logarithmically\n\nFurthermore, the image activations of a pretrained Densenet121 model are extracted for all features twice (once on the regular images, once on horizontally flipped images). The important variables in this section are:\n- `train_df` and `test_df` - Dataframes holding raw data and all processed tabular features\n- `all_cat_features` - List of strings determining all available categorical features.\n- `all_num_features` - List of strings determining all available numerical features.\n- `\u00ecmg_features_train`, `img_features_train_flipped` and `\u00ecmg_features_test` - numpy arrays consisting of the 1024d image activations extracted from Densenet121 for the first image of each pet.\n- `train_text_tokens` and `test_text_tokens` - numpy arrays consisting of tokenized words, later used in the RNN models.\n\n### Training NN1\n\nNN1 is trained with MSE loss using regular image features and a TfIdf representation of text. Important variables:\n\n- `train_preds_nn_1` - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\n- `test_preds_nn_1` - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n\n### Training NN2\n\nNN1 is trained with MSE loss using regular image features and a non-trainable 300d crawl embedding for text. Important variables:\n\n- `train_preds_nn_2` - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\n- `test_preds_nn_2` - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n\n### Training NN3\n\nNN3 is trained with SmoothL1 loss using horizontally flipped image features and a trainable 200d GloVe embedding for text. Important variables:\n\n- `train_preds_nn_3` - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\n- `test_preds_nn_3` - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n\n### Image Extractor\n\nTrains an image activation extractor NN on train + test data. Input are the 1024d Densenet121 features. The model is trained to predict Age, Breed1 and Type of pets. Important variables:\n\n- `train_activations` - (n_train x 80) numpy array consisting of extracted image activations for the train set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet.\n- `test_activations` - (n_test x 80) numpy array consisting of extracted image activations for the test set. Consists of 64 activations from the first hidden layer + 16 activations of the second hidden layer for each pet.\n\n### Training LightGBM\n\nText features are represented by 120d SVD of a TfIdf matrix for the LightGBM model. The 64d activations from the first hidden layer of the image extractor NN are used to represent images. Important variables:\n\n- `train_preds_lgb` - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\n- `test_preds_lgb` - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n\n### Training xlearn\n\nText features are represented by 10d SVD of a TfIdf matrix for the xlearn model. The 16d activations from the second hidden layer of the image extractor NN are used to represent images. All numerical features are binned in quantile bins and treated as categorical. . Important variables:\n\n- `train_preds_ffm` - (n_repeats x n_train) numpy array consisting of out-of-fold train predictions.\n- `test_preds_ffm` - (n_repeats x n_test x n_splits) numpy array consisting of test predictions of each fold.\n\n### Stacking\n\nCombines the previously generated predictions using a linear regression. The scores are converted to labels by following the train distribution. Important variables:\n\n- `fixed_scores` - the final labels for each pet.","a9234184":"# Preprocessing","2e033a93":"Sentiment data and image metadata.","db9f7398":"Build count features.","faf3f8ec":"## Data sources","b46371cc":"# Training NN 1 - TfIdf matrix","2d4e8156":"## Fit a linear regression & convert predictions to labels","1ade711d":"# Training xlearn","2436e980":"## Utility functions","19eae166":"Define the commonly used Attention and CyclicLR classes and a function to train the model. Taken from my [PyTorch starter kernel](https:\/\/www.kaggle.com\/bminixhofer\/deterministic-neural-networks-using-pytorch). \n`train_model` is slightly changed to only optionally enable CLR and additionally return predictions generated from an early stopped version of the model.","94d0f0e7":"Set target and construct repeated stratified KFold CV.","e17d916b":"Build logarithmically scaled numerical features. Note the +2 because NA values are filled with -1.","c8686c88":"# Training NN 3 - Trainable 200d GloVe embeddings + flipped image activations","bdb5383f":"# Training LightGBM","1d5bb784":"## Extract image features","72598fa1":"Build feature concatenations.","4243f947":"Get mean, sum and variance of image features over all 30 images."}}