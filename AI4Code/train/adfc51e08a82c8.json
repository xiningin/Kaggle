{"cell_type":{"76aa8f2a":"code","7b25a568":"code","8cd0214e":"code","7c3a851a":"code","6a0cb17e":"code","d3aac8ab":"code","5013be8b":"code","634f9ce5":"code","8af21b69":"code","800c71e7":"code","975d2601":"code","d70d454a":"code","94876e92":"code","32974647":"code","0cf0ef2e":"code","714d5a6b":"code","1a41c643":"code","aab02a5a":"code","cdcacb31":"code","ec13fa99":"code","70323c67":"code","ed478ece":"markdown","fd007954":"markdown","36c84bf4":"markdown","805fc797":"markdown","3b480116":"markdown","443f61cf":"markdown","cdd1777c":"markdown","e593050b":"markdown","a0832d9a":"markdown","bffe8274":"markdown","68551338":"markdown","cdbb538d":"markdown","6182e732":"markdown","febcb1ab":"markdown","a7fb0018":"markdown","428253a9":"markdown","b2871489":"markdown","97538b9f":"markdown","c5ca8027":"markdown","583b17f5":"markdown","e7180d90":"markdown","9d2074fb":"markdown"},"source":{"76aa8f2a":"#matplot lib, to see the images\n%matplotlib inline\nimport matplotlib \nimport matplotlib.pyplot as plt\n\n#OpenCv is the main librarie of image manipulation\n!pip install opencv-python\nimport cv2\nimport numpy as np\nimport dlib\n\n#to visualize the images with better quality\nimport os\nfrom IPython.display import Image\n\n#to import from website\n!pip install wget\nimport wget\n\nprint('ready!')","7b25a568":"url='https:\/\/files.alerta.rcnradio.com\/alerta_bogota\/public\/styles\/article_desktop\/public\/2019-10\/el_man_0.jpg?itok=wWjcWmPw'\nwget.download(url, 'sa.jpg')\nurl2='https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/c\/c5\/Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg\/220px-Scarlett_Johansson_in_Kuwait_01b-tweaked.jpg'\nwget.download(url2, 'sj.jpg')\nprint('Images Downloaded!')","8cd0214e":"pattern='..\/input\/shape-predictor-68-face-landmarks\/shape_predictor_68_face_landmarks.dat'","7c3a851a":"#IMAGE 1\nimg1 = cv2.imread(\".\/sj.jpg\") \nImage(\".\/sj.jpg\")","6a0cb17e":"#IMAGE 2\nimg2 = cv2.imread(\".\/sa.jpg\") \nImage(\".\/sa.jpg\")","d3aac8ab":"img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\nmask = np.zeros_like(img1_gray)\nplt.imshow(img1_gray, cmap='gray')\nplt.show ","5013be8b":"img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\nplt.imshow(img2_gray, cmap='gray')\nplt.show","634f9ce5":"detector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(pattern)\nfaces = detector(img1_gray)\nfor face in faces:\n    landmarks = predictor(img1_gray, face)\n    landmarks_points = []\n    for n in range(0, 68):\n        x = landmarks.part(n).x\n        y = landmarks.part(n).y\n        landmarks_points.append((x, y))\n\nprint('next')","8af21b69":"points = np.array(landmarks_points, np.int32)\nconvexhull = cv2.convexHull(points)\nprint('next')","800c71e7":"faces2 = detector(img2_gray)\nfor face in faces2:\n  landmarks = predictor(img2_gray, face)\n  landmarks_points2 = []\n  for n in range(0, 68):\n    x = landmarks.part(n).x\n    y = landmarks.part(n).y\n    landmarks_points2.append((x, y))\n    #cv2.circle(img2, (x, y), 3, (0, 255, 0), -1) #This line help to print landmarks in the face\n    \nprint('next')","975d2601":"points2 = np.array(landmarks_points2, np.int32)\nconvexhull2 = cv2.convexHull(points2)\nprint('next')","d70d454a":"rect = cv2.boundingRect(convexhull)#find the rectangle sourrounding convex hull\nsubdiv = cv2.Subdiv2D(rect)\nsubdiv.insert(landmarks_points)\ntriangles = subdiv.getTriangleList()\ntriangles = np.array(triangles, dtype=np.int32)\nfor t in triangles:\n   pt1 = (t[0], t[1])\n   pt2 = (t[2], t[3])\n   pt3 = (t[4], t[5])\n   #cv2.line(img, pt1, pt2, (0, 0, 255), 2) #this unselected lines help o vizualize the triangles \n   #cv2.line(img, pt2, pt3, (0, 0, 255), 2) #on the face\n   #cv2.line(img, pt3, pt1, (0, 0, 255), 2)\n\nprint('next')","94876e92":"img2_new_face = np.zeros_like(img2)\nplt.imshow(img2_new_face)\nplt.show","32974647":"def extract_index_nparray(nparray):\n    index = None\n    for num in nparray[0]:\n        index = num\n        break\n    return index\nprint('next')","0cf0ef2e":"indexes_triangles = []\nfor t in triangles:\n        pt1 = (t[0], t[1])\n        pt2 = (t[2], t[3])\n        pt3 = (t[4], t[5])\n        index_pt1 = np.where((points == pt1).all(axis=1))\n        index_pt1 = extract_index_nparray(index_pt1)\n        index_pt2 = np.where((points == pt2).all(axis=1))\n        index_pt2 = extract_index_nparray(index_pt2)\n        index_pt3 = np.where((points == pt3).all(axis=1))\n        index_pt3 = extract_index_nparray(index_pt3)\n        if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n            triangle = [index_pt1, index_pt2, index_pt3]\n            indexes_triangles.append(triangle)\n        #cv2.line(img, pt1, pt2, (0, 0, 255), 2)\n        #cv2.line(img, pt2, pt3, (0, 0, 255), 2)\n        #cv2.line(img, pt1, pt3, (0, 0, 255), 2)\nprint('next')","714d5a6b":"# Triangulation of both faces\nfor triangle_index in indexes_triangles:\n    # Triangulation of the first face\n    tr1_pt1 = landmarks_points[triangle_index[0]]\n    tr1_pt2 = landmarks_points[triangle_index[1]]\n    tr1_pt3 = landmarks_points[triangle_index[2]]\n    triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n\n    rect1 = cv2.boundingRect(triangle1)\n    (x, y, w, h) = rect1\n    cropped_triangle = img1[y: y + h, x: x + w]\n    cropped_tr1_mask = np.zeros((h, w), np.uint8)\n    points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n                      [tr1_pt2[0] - x, tr1_pt2[1] - y],\n                      [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n    cropped_triangle = cv2.bitwise_and(cropped_triangle, cropped_triangle,\n                                       mask=cropped_tr1_mask)\n    #cv2.line(img, tr1_pt1, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt3, tr1_pt2, (0, 0, 255), 2)\n    #cv2.line(img, tr1_pt1, tr1_pt3, (0, 0, 255), 2)\n\n     # Triangulation of second face\n    tr2_pt1 = landmarks_points2[triangle_index[0]]\n    tr2_pt2 = landmarks_points2[triangle_index[1]]\n    tr2_pt3 = landmarks_points2[triangle_index[2]]\n    triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n    rect2 = cv2.boundingRect(triangle2)\n    (x, y, w, h) = rect2\n    cropped_triangle2 = img2[y: y + h, x: x + w]\n    cropped_tr2_mask = np.zeros((h, w), np.uint8)\n    points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n                       [tr2_pt2[0] - x, tr2_pt2[1] - y],\n                       [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n    cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n    cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2,\n                                       mask=cropped_tr2_mask)\n    #cv2.line(img2, tr2_pt1, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt3, tr2_pt2, (0, 0, 255), 2)\n    #cv2.line(img2, tr2_pt1, tr2_pt3, (0, 0, 255), 2)\n    \n    # Let's Warp triangles\n    points = np.float32(points)\n    points2 = np.float32(points2)\n    M = cv2.getAffineTransform(points, points2)\n    warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n    warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)##\n\n    # *****Reconstructing destination face************************************************\n    img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n    img2_new_face_rect_area_gray= cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n\n    #To remove the lines between triangles\n    _, mask_triangles_designed=cv2.threshold(img2_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n    warped_triangle=cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n\n    img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n    img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n\n    # Face swapped (putting 1st face into 2nd face)\n    img2_face_mask = np.zeros_like(img2_gray)\n    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n\n    img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)\n    result = cv2.add(img2_head_noface, img2_new_face)\n\n    #plt.imshow(img2_new_face)\n    plt.imshow(result)","1a41c643":"#cv2_imshow(cropped_triangle)#cropped triangle 1\n#cv2_imshow(cropped_triangle2)#\"cropped triangle 2\"\n#cv2_imshow(warped_triangle)#\"Warped triangle\"\n#we havent cv2_imshow on kaggle","aab02a5a":"plt.imshow(img2_new_face)","cdcacb31":"plt.imshow(img2_head_noface)\nplt.show","ec13fa99":"(x, y, w, h) = cv2.boundingRect(convexhull2)\ncenter_face2 = (int((x + x + w)\/2), int((y + y + h)\/2))\nseamlessclone= cv2.seamlessClone(result, img2, img2_head_mask, center_face2, cv2.MIXED_CLONE)","70323c67":"\nplt.imshow(seamlessclone)\nplt.show","ed478ece":"Now we calculate the convex hull ","fd007954":"#### Applying Delaunay triangulation to image 1\n\"For morphing images the Delaunay triangulation provides a 'good' way to create a triangular mesh from points that are going to be moved. The triangular shapes are distorted from one image to the next \" from [Delaunay triangulation](https:\/\/en.wikibooks.org\/wiki\/Trigonometry\/For_Enthusiasts\/Delaunay_triangulation)","36c84bf4":"Detecting face landmark in image 2","805fc797":" Next is a function to extract the indexes of the triangles from the landmarks point array:","3b480116":"This is the face from image 1, adapted to the shape of the face of image 2","443f61cf":"#### Triangulation of the 2nd face from the 1st face using Delaunay Triangulation","cdd1777c":"### Getting images","e593050b":"Image2-background body","a0832d9a":"### Result","bffe8274":"\nwe will use the following facial patterns file :","68551338":"and convex hull to image 2","cdbb538d":"### Neccessary Libraries","6182e732":"#### Exploring Images\nImage 1-principal face","febcb1ab":"And here we have made space in image 2, to place the face of image 1","a7fb0018":"# Face Swap\n\n#### In this code, we will be able to exchange the faces of two photographs, from a facial recognition pattern. \n\nBased on [PySource.com code](https:\/\/pysource.com\/2019\/04\/04\/face-swapping-opencv-with-python-part-1\/)\n\nJhonny Calvo","428253a9":"we need the next black pattern to put the face from image 1","b2871489":"### Transforming images to adecuate analysist format\n#### Let's work with image 1 first\n\nSetting both images in gray color\n","97538b9f":"#### Finding the indexes of each triangle (or specific landmarks points each triangle connects).","c5ca8027":"Next line, help to visualize triangles from images 1 and images 2\nand the warped triangle","583b17f5":"### Splitting the face into triangles\nWe need to divide both faces into triangles, to match the shape of both faces","e7180d90":"### Detecting face landmark\nHere, we detect the facial pattern in the images, such as the face shape as a landmark reference","9d2074fb":"\nThe following line helps to soften the edges of the face and the background body, as well as to place them in the same colors"}}