{"cell_type":{"adfef883":"code","157aa939":"code","3f321d59":"code","6232107b":"code","82cb4275":"code","40d72fde":"code","75c416ef":"code","f8c66863":"code","414aba18":"code","16f833e3":"code","25c3f5da":"code","f4fd0ecd":"code","999e2fc0":"code","beb6669b":"code","d33b0504":"code","5a2c3445":"code","7db07a79":"code","bbd9c776":"code","f44ef44e":"code","3638e5ad":"code","b634df70":"code","03df8506":"code","725f1874":"code","a2d18fbb":"code","7cdbd29a":"code","ab576f2b":"code","e7333137":"code","3865bd77":"code","aebc137f":"code","6eb6996d":"code","8b939eea":"code","35fe6cb9":"code","da1b8764":"code","8235c189":"code","c041feef":"code","192df700":"code","22ae22ff":"code","7348af46":"code","fb25891f":"code","e480495e":"code","fed8c8eb":"code","b6ee0d02":"code","ff7a64e3":"code","e1509b3d":"code","2783b832":"code","716ca84b":"code","3bbbd89d":"code","9936e434":"code","d083f0c7":"code","deef09ef":"code","683edc01":"code","ea5ba4ca":"markdown","13f62cbb":"markdown","ef721378":"markdown"},"source":{"adfef883":"import os\nfrom tqdm.auto import tqdm\nimport math\n\nimport pandas as pd\nimport numpy as np\nimport scipy\nfrom scipy.integrate import simpson\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, auc , classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB, ComplementNB\n\npd.set_option('max_column',None)\nplt.style.use(\"ggplot\")\nsns.set_style('darkgrid')","157aa939":"defaultcard = pd.read_csv('\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv')\ndefaultcard.drop(columns='ID', inplace=True)\ndefaultcard.head()","3f321d59":"defaultcard.info()","6232107b":"defaultcard.describe()","82cb4275":"defaultcard.shape","40d72fde":"defaultcard.rename(columns={'default.payment.next.month':'target', 'PAY_0':'PAY_1'}, inplace=True)\ndefaultcard.head()","75c416ef":"defaultcard['target'].value_counts(normalize=True)","f8c66863":"defaultcard = defaultcard.drop_duplicates(subset=[col for col in defaultcard.columns if col != 'target'])\ndefaultcard.shape","414aba18":"# Compute pay balance\nbill_amt = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\npay_amt  = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n#defaultcard['remaining_pay_balance'] = defaultcard[bill_amt].sum(axis=1) - defaultcard[pay_amt].sum(axis=1)\n#defaultcard = defaultcard[(defaultcard['remaining_pay_balance'] > 0) | (defaultcard['remaining_pay_balance'] == 0)]\n#defaultcard.shape","16f833e3":"defaultcard['EDUCATION'].value_counts()","25c3f5da":"defaultcard.loc[:,'EDUCATION'].replace({0:4, 5:4, 6:4}, inplace=True)","f4fd0ecd":"defaultcard['EDUCATION'].value_counts()","999e2fc0":"defaultcard['MARRIAGE'].value_counts()","beb6669b":"defaultcard.loc[:, 'MARRIAGE'].replace({0:3}, inplace=True)","d33b0504":"defaultcard['PAY_1'].value_counts()","5a2c3445":"bill_statement_sum = defaultcard[bill_amt].sum(axis=1)\nprint(f\"Number of observation with zero total bill amount {sum(bill_statement_sum == 0)}\")","7db07a79":"bill_statement_sum_index = bill_statement_sum.loc[bill_statement_sum > 0].index\ndefaultcard = defaultcard.loc[bill_statement_sum_index]\ndefaultcard.shape","bbd9c776":"folds = defaultcard.copy()","f44ef44e":"features_col = [col for col in folds.columns if col not in ['target', 'remaining_pay_balance']]\nassert len(features_col) == 23\nfeatures = folds[features_col]\ntarget = folds['target']","3638e5ad":"folds.shape","b634df70":"SEED=2020\nX, X_test, y, y_test = train_test_split(features,\n                                        target,\n                                        test_size=.2,\n                                        shuffle=True,\n                                        random_state=SEED,\n                                        stratify=target\n                                        )","03df8506":"X_test.shape","725f1874":"unique_train, count_train = np.unique(y, return_counts=True)\nprint(f\"y train value counts: \\n {np.asanyarray((unique_train, count_train\/y.shape[0])).T}\")\nprint('\\n')\nunique_test, count_test = np.unique(y_test, return_counts=True)\nprint(f\"y test value counts: \\n {np.asanyarray((unique_test, count_test\/y_test.shape[0])).T}\")","a2d18fbb":"# https:\/\/github.com\/tensorbored\/kds\/blob\/master\/kds\/metrics.py\ndef decile_table(y_true, y_prob, labels=True, round_decimal=3):\n    \"\"\"Generates the Decile Table from labels and probabilities\n    \n    The Decile Table is creared by first sorting the customers by their predicted \n    probabilities, in decreasing order from highest (closest to one) to \n    lowest (closest to zero). Splitting the customers into equally sized segments, \n    we create groups containing the same numbers of customers, for example, 10 decile \n    groups each containing 10% of the customer base.\n    \n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct\/actual) target values.\n        y_prob (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier\/algorithm.\n        labels (bool, optional): If True, prints a legend for the abbreviations of\n            decile table column names. Defaults to True.\n        round_decimal (int, optional): The decimal precision till which the result is \n            needed. Defaults to '3'.\n    Returns:\n        dt: The dataframe dt (decile-table) with the deciles and related information.\n    Example:\n        >>> import kds\n        >>> from sklearn.datasets import load_iris\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn import tree\n        >>> X, y = load_iris(return_X_y=True)\n        >>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=3)\n        >>> clf = tree.DecisionTreeClassifier(max_depth=1,random_state=3)\n        >>> clf = clf.fit(X_train, y_train)\n        >>> y_prob = clf.predict_proba(X_test)\n        >>> kds.metrics.decile_table(y_test, y_prob[:,1])\n    \"\"\"\n    y_true = np.array(y_true)\n    y_prob = np.array(y_prob)\n\n    df = pd.DataFrame()\n    df['y_true'] = y_true\n    df['y_prob'] = y_prob\n    # df['decile']=pd.qcut(df['y_prob'], 10, labels=list(np.arange(10,0,-1))) \n    # ValueError: Bin edges must be unique\n\n    df.sort_values('y_prob', ascending=False, inplace=True)\n    df['decile'] = np.linspace(1, 11, len(df), False, dtype=int)\n\n    # dt abbreviation for decile_table\n    dt = df.groupby('decile').apply(lambda x: pd.Series([\n        np.min(x['y_prob']),\n        np.max(x['y_prob']),\n        np.mean(x['y_prob']),\n        np.size(x['y_prob']),\n        np.sum(x['y_true']),\n        np.size(x['y_true'][x['y_true'] == 0]),\n    ],\n        index=([\"prob_min\", \"prob_max\", \"prob_avg\",\n                \"cnt_cust\", \"cnt_resp\", \"cnt_non_resp\"])\n    )).reset_index()\n\n    dt['prob_min']=dt['prob_min'].round(round_decimal)\n    dt['prob_max']=dt['prob_max'].round(round_decimal)\n    dt['prob_avg']=round(dt['prob_avg'],round_decimal)\n    # dt=dt.sort_values(by='decile',ascending=False).reset_index(drop=True)\n\n    tmp = df[['y_true']].sort_values('y_true', ascending=False)\n    tmp['decile'] = np.linspace(1, 11, len(tmp), False, dtype=int)\n\n    dt['cnt_resp_rndm'] = np.sum(df['y_true']) \/ 10\n    dt['cnt_resp_wiz'] = tmp.groupby('decile', as_index=False)['y_true'].sum()['y_true']\n\n    dt['resp_rate'] = round(dt['cnt_resp'] * 100 \/ dt['cnt_cust'], round_decimal)\n    dt['cum_cust'] = np.cumsum(dt['cnt_cust'])\n    dt['cum_resp'] = np.cumsum(dt['cnt_resp'])\n    dt['cum_resp_wiz'] = np.cumsum(dt['cnt_resp_wiz'])\n    dt['cum_non_resp'] = np.cumsum(dt['cnt_non_resp'])\n    dt['cum_cust_pct'] = round(dt['cum_cust'] * 100 \/ np.sum(dt['cnt_cust']), round_decimal)\n    dt['cum_resp_pct'] = round(dt['cum_resp'] * 100 \/ np.sum(dt['cnt_resp']), round_decimal)\n    dt['cum_resp_pct_wiz'] = round(dt['cum_resp_wiz'] * 100 \/ np.sum(dt['cnt_resp_wiz']), round_decimal)\n    dt['cum_non_resp_pct'] = round(\n        dt['cum_non_resp'] * 100 \/ np.sum(dt['cnt_non_resp']), round_decimal)\n    dt['KS'] = round(dt['cum_resp_pct'] - dt['cum_non_resp_pct'], round_decimal)\n    dt['lift'] = round(dt['cum_resp_pct'] \/ dt['cum_cust_pct'], round_decimal)\n\n    if labels is True:\n        print_labels()\n\n    return dt[['decile', 'cum_resp_pct', 'cum_resp_pct_wiz']]\n\ndef area_ratio(pcg):\n    # Area of the model \n    area_model = auc(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct.values))\n    # Area of the base model\n    area_base = auc(np.append(np.arange(0, 100, 10), 100), np.append(np.arange(0, 10, 1), 10))\n    # Area between model and base\n    diff_base_model = area_model - area_base\n    # Area of the wizard\n    area_wizard = auc(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct_wiz.values))\n    # Area between wizard and base\n    diff_wizard_base = area_wizard - area_base\n    # area ratio\n    area_ratio = diff_base_model \/ diff_wizard_base\n    return area_ratio\n\ndef plot_lift_chart(pcg, area_ratio, title='Cumulative Gain Plot',\n                         title_fontsize=14, text_fontsize=10, figsize=None):\n    \"\"\"Generates the cumulative Gain Plot from labels and probabilities\n    The cumulative gains chart is used to determine the effectiveness of a\n    binary classifier. A detailed explanation can be found at\n    http:\/\/www2.cs.uregina.ca\/~dbd\/cs831\/notes\/lift_chart\/lift_chart.html \n    The implementation here works only for binary classification.\n    \n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n        y_prob (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Decile-wise Lift Plot\".\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values (8, 10, 12, etc.)\n            Defaults to 14.\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values (8, 10, 12, etc.)\n            Defaults to 10.\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n    Returns:\n        None\n    Example:\n        >>> import kds\n        >>> from sklearn.datasets import load_iris\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn import tree\n        >>> X, y = load_iris(return_X_y=True)\n        >>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=3)\n        >>> clf = tree.DecisionTreeClassifier(max_depth=1,random_state=3)\n        >>> clf = clf.fit(X_train, y_train)\n        >>> y_prob = clf.predict_proba(X_test)\n        >>> kds.metrics.plot_cumulative_gain(y_test, y_prob[:,1])\n    \"\"\"\n\n    # Cumulative Gains Plot\n    # plt.subplot(2, 2, 3)\n    plt.plot(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct.values), marker='o', label='Model')\n    plt.plot(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct_wiz.values), 'c--', label='Wizard')\n    # plt.plot(list(np.arange(1,11)), np.ones(10), 'k--',marker='o')\n    plt.plot([0, 10], [0, 100], 'k--', marker='o', label='Random')\n    plt.text(4, 30, f\"Area ratio: {area_ratio}\")\n    plt.title(title, fontsize=title_fontsize)\n    plt.xlabel('Deciles', fontsize=text_fontsize)\n    plt.ylabel('% Resonders', fontsize=text_fontsize)\n    plt.legend(borderpad=1)\n    plt.grid(True)\n    # plt.show()","7cdbd29a":"scaler = MinMaxScaler() # StandardScaler MinMaxScaler\nscaler.fit(X)\nscaled_x = scaler.transform(X)\nscaled_test = scaler.transform(X_test)\nX.loc[:, features_col] = scaled_x\nX_test.loc[:, features_col] = scaled_test","ab576f2b":"knn = KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree', n_jobs=-1, weights='uniform')\nknn.fit(X, y)\ntrain_pred = knn.predict(X)\ntrain_proba = knn.predict_proba(X)\ntrain_pcg = decile_table(y, train_proba[:, 1], labels=False)\ntest_pred = knn.predict(X_test)\ntest_proba = knn.predict_proba(X_test)\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\nerror_rate_train = 1 - accuracy_score(y, train_pred)\narea_ratio_train = area_ratio(train_pcg)\nerror_rate_test = 1 - accuracy_score(y_test, test_pred)\narea_ratio_test = area_ratio(test_pcg)\nprint(f\"KNN error rate on train set (training): {error_rate_train} | area ratio on train set (training): {area_ratio_train}\\n\")\nprint(f\"KNN error rate on test (valid) set: {error_rate_test} | area ratio on test (valid) set: {area_ratio_test} \\n\")\nplot_lift_chart(test_pcg, area_ratio_test, title='Lift Chart KNN on test set')","e7333137":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\nknn = KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree', n_jobs=-1)\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    knn.fit(x_train, y_train)\n    \n    oof_pred_label = knn.predict(x_valid)\n    oof_pred_proba = knn.predict_proba(x_valid)\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = knn.predict_proba(X_test)\n    valid_pcg = decile_table(y_valid, oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid, oof_pred_label)\n    area_ratio_valid = area_ratio(valid_pcg)\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    error_rate_valids.append(score_valid)\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\ntest_pcg = decile_table(y_test, test_proba[:,1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart KNN on test set')\nprint(\"\\n\")","3865bd77":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics","aebc137f":"#%%time\n#params = {\n#        \"objective\": \"binary:logistic\",\n#        \"max_depth\": 6,\n#        \"n_estimators\":3000,\n#        \"learning_rate\": 0.001,\n#        \"colsample_bytree\": 0.8,\n#        \"subsample\": 0.8,\n#        \"eval_metric\":'error',\n#        #\"reg_alpha\" : 0,\n#        \"min_child_weight\": 80,\n#        \"n_jobs\": 2,\n#        \"seed\": 2001,\n#        'tree_method': \"gpu_hist\",\n#        \"gpu_id\": 0,\n#        'predictor': 'gpu_predictor'\n#}\n#xgb_clf_default = xgb.XGBClassifier(**params)\n#xgb_clf_default.fit(X,y)\n#y_pred = xgb_clf_default.predict_proba(X_test)\n#predictions = [round(value) for value in y_pred]\n## evaluate predictions\n#accuracy = accuracy_score(y_test, y_pred)\n#print(\"XGBoost Classifier Accuracy: %.2f%%\" % (accuracy * 100.0))","6eb6996d":"#unique_train, count_train = np.unique(y_pred, return_counts=True)\n#print(f\"y train value counts: \\n {np.asanyarray((unique_train, count_train\/y_pred.shape[0])).T}\")","8b939eea":"#y_pred.sum()","35fe6cb9":"from functools import partial\nimport optuna\n","da1b8764":"def objective(trial):\n\n\n    param_grid = {\n        \"objective\": \"binary:logistic\",\n        \"eval_metric\":'error', # specify eval metric for xgboost\n        'tree_method':'gpu_hist', \n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01, 0.02]),\n        'max_depth': trial.suggest_categorical('max_depth', [5,6,7,9,11]),\n        'min_child_weight': trial.suggest_categorical('min_child_weight', [10, 30, 60, 100, 200])}\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    xgb_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        d_train = xgb.DMatrix(X.iloc[trn_idx].values, y.iloc[trn_idx].values)\n        d_val = xgb.DMatrix(X.iloc[vld_idx].values, y.iloc[vld_idx].values)\n        \n        # Fit and train xgboost\n        model = xgb.train(param_grid, d_train, evals=[(d_val, \"val\")], num_boost_round=10000, verbose_eval=50,\n                          early_stopping_rounds=100)\n    \n        # Predictions and score on validation data\n        pred_val = model.predict(d_val)\n        predictions = [round(value) for value in pred_val]\n        score = 1 - accuracy_score(y.iloc[vld_idx], predictions)\n        print(f\"Fold {counter} Xgboost {score}\")\n        xgb_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(xgb_score))","8235c189":"y.iloc[vld_idx]","c041feef":"#study = optuna.create_study(direction='minimize')\n#study.optimize(objective, n_trials=100)\n#print('Number of finished trials:', len(study.trials))\n#print('Best trial:', study.best_trial.params)","192df700":"Best_trial= {'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 100, \"objective\": \"binary:logistic\",\n        \"eval_metric\":'error' , 'tree_method':'gpu_hist'}","22ae22ff":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train xgboost\n    model = xgb.XGBClassifier(**Best_trial)\n    model.fit(x_train, y_train, \n                eval_set=[(x_valid,y_valid)], # evaluation on the validation set\n                verbose=100, early_stopping_rounds=200)\n    \n    oof_pred_label = model.predict(x_valid)\n    oof_pred_proba = model.predict_proba(x_valid)\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label)\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    error_rate_valids.append(score_valid)\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart XGBClassifier on test set')\nprint(\"\\n\")","7348af46":"from sklearn.linear_model import LogisticRegression","fb25891f":"#LogisticRegression(\n#    C=1.0,\n#    fit_intercept=True,\n#    intercept_scaling=1,\n#    class_weight=None,\n#    random_state=None,\n#    solver='lbfgs',\n#    max_iter=100,\n#    multi_class='auto',\n#    verbose=0,\n#    warm_start=False,\n#    n_jobs=None,\n#    l1_ratio=None,)","e480495e":"def objective_logistic(trial):\n\n    \n\n    solver = trial.suggest_categorical(\"solver\", [ 'liblinear',  'lbfgs', 'sag', 'saga'])\n    C = trial.suggest_float(\"C\", 0.0, 1.0)\n\n   \n    \n\n        # 'penalty' parameter isn't relevant for this solver,\n        # so we always specify 'l2' as the dummy value.\n\n\n    logistic = LogisticRegression(max_iter=200, solver=solver, C=C,random_state=SEED)\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    logistic_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n        y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n        \n        # Fit and train logistic\n        logistic.fit(x_train,y_train)\n    \n        # Predictions and score on validation data\n        pred_val = logistic.predict(x_valid)\n        \n        score = 1 - accuracy_score(y_valid, pred_val)\n        print(f\"Fold {counter} logistic {score}\")\n        logistic_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(logistic_score))","fed8c8eb":"#study = optuna.create_study(direction=\"minimize\")\n#study.optimize(objective_logistic, n_trials=100)\n#\n#print(\"Number of finished trials: \", len(study.trials))\n#print(\"Best trial:\")\n#trial = study.best_trial\n#print(\"  Value: \", trial.value)\n#print(\"  Params: \")\n#for key, value in trial.params.items():\n#    print(\"    {}: {}\".format(key, value))","b6ee0d02":"Params = {'solver': 'saga' ,'C': 0.9960292949722489} ","ff7a64e3":"%%time\nfrom sklearn.metrics import accuracy_score\n\nNSPLITS = 5\nSHUFFLE = True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nscores_valid = []\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\nLogistic = LogisticRegression(**Params,penalty='l2',max_iter=200)\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    print(f\"CV{counter}\")\n    xtrain, xvalid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    ytrain, yvalid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    Logistic.fit(xtrain, ytrain)\n    \n    oof_pred_label = Logistic.predict(xvalid)\n    oof_pred_proba = Logistic.predict_proba(xvalid) # return probability estimates for the test data X\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    \n    \n    y_pred_test = Logistic.predict_proba(X_test)\n    score_valid = 1 - accuracy_score(yvalid , oof_pred_label)\n    print(f\"error fold {counter} rate score {score_valid}\")\n    scores_valid.append(score_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1 \n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\nprint(f\"error rate cv score : {np.mean(np.array(scores_valid))}\")\nprint(f\"error rate test validation score : {1 - accuracy_score(y_test , y_pred_label)}\")","e1509b3d":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train LogisticRegression\n    model = LogisticRegression(**Params,penalty='l2',max_iter=200)\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid) #the predicted label for the test folds\n    \n    oof_pred_proba = model.predict_proba(x_valid) \n    \n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    \n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label) # score de chaque fold\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    \n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid) # append error rate folds\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS # predictproba for all the folds ***\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\n\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\n\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart logistic on test set')\nprint(\"\\n\")\n","2783b832":"oof_proba","716ca84b":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train RandomForestClassifier\n    model = RandomForestClassifier(max_depth=7,n_estimators=400,criterion='gini',verbose=0)\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid) #the predicted label for the test folds\n    \n    oof_pred_proba = model.predict_proba(x_valid) \n    \n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    \n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label) # score de chaque fold\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    \n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid) # append error rate folds\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS # predictproba for all the folds ***\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\n\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\n\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart RandomForestClassifier on test set')\nprint(\"\\n\")\n","3bbbd89d":"def objective_random_forest(trial):\n\n    \n\n    params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n            'max_depth': trial.suggest_int('max_depth', 4, 50),\n            'min_samples_split': trial.suggest_int('min_samples_split', 1, 150),\n            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 60)\n        }\n\n    \n    rfc = RandomForestClassifier(**params,n_jobs=2,random_state=SEED)\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    rfc_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n        y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n        \n        # Fit and train RandomForestClassifier\n        rfc.fit(x_train,y_train)\n    \n        # Predictions and score on validation data\n        pred_val = rfc.predict(x_valid)\n        \n        score = 1 - accuracy_score(y_valid, pred_val)\n        print(f\"Fold {counter} RFC {score}\")\n        rfc_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(rfc_score))","9936e434":"#study = optuna.create_study(direction=\"minimize\")\n#study.optimize(objective_random_forest, n_trials=100)\n#\n#print(\"Number of finished trials: \", len(study.trials))\n#print(\"Best trial:\")\n#trial = study.best_trial\n#print(\"  Value: \", trial.value)\n#print(\"  Params: \")\n#for key, value in trial.params.items():\n#    print(\"    {}: {}\".format(key, value))","d083f0c7":"Params= {\n    'n_estimators': 972,\n    'max_depth': 45,\n    'min_samples_split': 85,\n    'min_samples_leaf': 18}","deef09ef":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis","683edc01":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train LinearDiscriminantAnalysis\n    model = LinearDiscriminantAnalysis(solver='svd')\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid)\n    oof_pred_proba = model.predict_proba(x_valid)\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label)\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    error_rate_valids.append(score_valid)\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart LinearDiscriminantAnalysis on test set')\nprint(\"\\n\")","ea5ba4ca":"#### LinearDiscriminantAnalysis","13f62cbb":"#### optuna for random forest classifier","ef721378":"##### random forest classifier without hyperparameter tuning"}}