{"cell_type":{"2b76f260":"code","45aa7df0":"code","36f33d0a":"code","99983616":"code","67d8a3d6":"code","658240b6":"code","a9cbf57a":"code","6a6b26bf":"code","d77ea244":"code","87c03edc":"code","3682f346":"code","262c06a3":"code","dd131765":"code","55300b9b":"code","84ad5e4d":"code","1be214b2":"code","dc521178":"code","203cdff5":"code","67bc4167":"code","ad988058":"code","610a269c":"code","75f0c619":"code","30603bd6":"code","5092bd66":"code","76bdd0a0":"code","abd7af31":"code","ef1c2ac5":"code","54c6068c":"code","5be91045":"code","87250063":"code","faed1068":"code","44e53ae5":"code","b10a7df3":"code","a043024a":"code","1c970901":"code","719d2946":"code","9c9c9797":"code","10c5d8c9":"code","e629bdbb":"code","8d765cc8":"code","b9eea9d7":"code","56d33666":"code","30588dff":"code","e22c6caf":"code","d7c0b1cb":"code","b3b58ff1":"code","b0fbbc67":"code","0bfcc72f":"code","35b978dd":"code","d70eafcc":"code","2e2f89a3":"code","86dde45e":"code","f88ee303":"code","7ac9f6de":"code","25f6d3d9":"code","6df2637b":"code","f370a838":"code","a98f99ef":"code","0d0d6529":"code","020d45b2":"code","c59f46a8":"code","fcb08e2f":"code","a409d2d9":"code","0ac261c8":"code","0ed45bba":"code","d637f9c0":"code","67cb25ad":"code","c6bd646e":"code","ac100d94":"code","1412bad8":"code","cd7d8c9e":"code","ccf596d8":"code","5803eb04":"code","54504faf":"code","6fa126e6":"code","0f97342d":"code","e8a6b2e4":"code","7e63f391":"code","e12393dc":"code","7478c416":"code","9468c1f2":"code","b4f16601":"code","dbf7bf51":"code","529d467a":"code","50dc5cd6":"code","9bc3065a":"code","f82a59dd":"code","b6e598e2":"markdown","70fb1223":"markdown","688507a1":"markdown","47b37d59":"markdown","4368226a":"markdown","2aad2420":"markdown","300a12d0":"markdown","bf38ce7f":"markdown","19ed81b9":"markdown","767f65ed":"markdown","37f379ab":"markdown","031b36f6":"markdown","206a5e65":"markdown","94191e04":"markdown","861cbe4c":"markdown","7b8e32d4":"markdown","55f9c414":"markdown","f959ebec":"markdown","26f501a6":"markdown","69deb7ab":"markdown","a676ef83":"markdown","7b957750":"markdown","d5edf568":"markdown","b57baef6":"markdown","9cf3fe6f":"markdown","3c9d3713":"markdown","642bafc3":"markdown","83fa630a":"markdown","2fa317b9":"markdown","2cebf23e":"markdown","f9d0577c":"markdown","6f4295f0":"markdown","1cde8a7d":"markdown","2b348150":"markdown","8450acd2":"markdown","b6b06824":"markdown","6a58b54f":"markdown","c5473610":"markdown"},"source":{"2b76f260":"from IPython.display import Image\nImage(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/5095eabce4b06cb305058603\/5095eabce4b02d37bef4c24c\/1352002236895\/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")","45aa7df0":"import pandas as pd\nimport os\nos.listdir('..\/input')\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","36f33d0a":"train.head()","99983616":"test.head()","67d8a3d6":"train.shape","658240b6":"test.shape","a9cbf57a":"train.info()","6a6b26bf":"test.info()","d77ea244":"train.isnull().sum()","87c03edc":"test.isnull().sum()","3682f346":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","262c06a3":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","dd131765":"bar_chart('Sex')","55300b9b":"bar_chart('Pclass')","84ad5e4d":"bar_chart('SibSp')","1be214b2":"bar_chart('Parch')","dc521178":"bar_chart('Embarked')","203cdff5":"train.head()","67bc4167":"Image(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/t\/5090b249e4b047ba54dfd258\/1351660113175\/TItanic-Survival-Infographic.jpg?format=1500w\")","ad988058":"train.head(10)","610a269c":"train_test_data = [train, test] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","75f0c619":"train['Title'].value_counts()","30603bd6":"test['Title'].value_counts()","5092bd66":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","76bdd0a0":"train.head()","abd7af31":"test.head()","ef1c2ac5":"bar_chart('Title')","54c6068c":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","5be91045":"train.head()","87250063":"test.head()","faed1068":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","44e53ae5":"bar_chart('Sex')","b10a7df3":"train.head(100)","a043024a":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","1c970901":"train.head(30)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","719d2946":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show() ","9c9c9797":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","10c5d8c9":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","e629bdbb":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","8d765cc8":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","b9eea9d7":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","56d33666":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","30588dff":"train.info()","e22c6caf":"test.info()","d7c0b1cb":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","b3b58ff1":"train.head()","b0fbbc67":"bar_chart('Age')","0bfcc72f":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","35b978dd":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","d70eafcc":"train.head()","2e2f89a3":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","86dde45e":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(50)","f88ee303":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()  ","7ac9f6de":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","25f6d3d9":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","6df2637b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","f370a838":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","a98f99ef":"train.head()","0d0d6529":"train.Cabin.value_counts()","020d45b2":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","c59f46a8":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","fcb08e2f":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","a409d2d9":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","0ac261c8":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","0ed45bba":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","d637f9c0":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","67cb25ad":"train.head()","c6bd646e":"train.head()","ac100d94":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","1412bad8":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","cd7d8c9e":"train_data.head(10)","ccf596d8":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","5803eb04":"train.info()","54504faf":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","6fa126e6":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","0f97342d":"# kNN Score\nround(np.mean(score)*100, 2)","e8a6b2e4":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","7e63f391":"# decision tree Score\nround(np.mean(score)*100, 2)","e12393dc":"clf = RandomForestClassifier(n_estimators=13, max_depth=5)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","7478c416":"# Random Forest Score\nround(np.mean(score)*100, 2)","9468c1f2":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","b4f16601":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","dbf7bf51":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","529d467a":"round(np.mean(score)*100,2)","50dc5cd6":"clf = RandomForestClassifier(n_estimators=13, max_depth=5)\nclf.fit(train_data, target)\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","9bc3065a":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","f82a59dd":"submission = pd.read_csv('submission.csv')\nsubmission.head()","b6e598e2":"## References\n\nThis notebook is created by learning from the following notebooks:\n\n- [Mukesh ChapagainTitanic Solution: A Beginner's Guide](https:\/\/www.kaggle.com\/chapagain\/titanic-solution-a-beginner-s-guide?scriptVersionId=1473689)\n- [How to score 0.8134 in Titanic Kaggle Challenge](http:\/\/ahmedbesbes.com\/how-to-score-08134-in-titanic-kaggle-challenge.html)\n- [Titanic: factors to survive](https:\/\/olegleyz.github.io\/titanic_factors.html)\n- [Titanic Survivors Dataset and Data Wrangling](http:\/\/www.codeastar.com\/data-wrangling\/)\n","70fb1223":"### 4.6 Fare","688507a1":"### 4.2 Name","47b37d59":"#### 4.4.1 some age is missing\nLet's use Title's median age for missing Age","4368226a":"#### 4.5.1 filling missing values","2aad2420":"The Chart confirms **a person aboarded with more than 2 siblings or spouse** more likely survived  \nThe Chart confirms ** a person aboarded without siblings or spouse** more likely dead","300a12d0":"### 6.2 Cross Validation (K-fold)","bf38ce7f":"### 6.2.2 Decision Tree","19ed81b9":"### Data Dictionary\n- Survived: \t0 = No, 1 = Yes  \n- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n- sibsp:\t# of siblings \/ spouses aboard the Titanic  \t\n- parch:\t# of parents \/ children aboard the Titanic  \t\n- ticket:\tTicket number\t\n- cabin:\tCabin number\t\n- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  ","767f65ed":"### 4.4 Age","37f379ab":"The Chart confirms **1st class** more likely survivied than **other classes**  \nThe Chart confirms **3rd class** more likely dead than **other classes**","031b36f6":"### 6.2.4 Naive Bayes","206a5e65":"The Chart confirms **a person aboarded with more than 2 parents or children** more likely survived  \nThe Chart confirms ** a person aboarded alone** more likely dead","94191e04":"### 6.2.5 SVM","861cbe4c":"We can see that *Age* value is missing for many rows. \n\nOut of 891 rows, the *Age* value is present only in 714 rows.\n\nSimilarly, *Cabin* values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values.","7b8e32d4":"### 4.8 FamilySize","55f9c414":"### 4.3 Sex\n\nmale: 0\nfemale: 1","f959ebec":"#### Title map\nMr : 0  \nMiss : 1  \nMrs: 2  \nOthers: 3\n","26f501a6":"more than 50% of 1st class are from S embark  \nmore than 50% of 2nd class are from S embark  \nmore than 50% of 3rd class are from S embark\n\n**fill out missing embark with S embark**","69deb7ab":"## 2. Collecting the data\n\ntraining data set and testing data set are given by Kaggle\nyou can download from  \nmy github [https:\/\/github.com\/minsuk-heo\/kaggle-titanic\/tree\/master](https:\/\/github.com\/minsuk-heo\/kaggle-titanic)  \nor you can download from kaggle directly [kaggle](https:\/\/www.kaggle.com\/c\/titanic\/data)  \n\n### load train, test dataset using Pandas","a676ef83":"The Chart confirms **Women** more likely survivied than **Men**","7b957750":"### 4.5 Embarked","d5edf568":"## 3. Exploratory data analysis\nPrinting first 5 rows of the train dataset.","b57baef6":"# Titanic: Machine Learning from Disaster\n### Predict survival on the Titanic\n- Defining the problem statement\n- Collecting the data\n- Exploratory data analysis\n- Feature engineering\n- Modelling\n- Testing","9cf3fe6f":"## 5. Modelling","3c9d3713":"There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information.","642bafc3":"### 4.7 Cabin","83fa630a":"### import python lib for visualization","2fa317b9":"### 6.2.3 Ramdom Forest","2cebf23e":"### 6.2.1 kNN","f9d0577c":"### 4.1 how titanic sank?\nsank from the bow of the ship where third class rooms located  \nconclusion, Pclass is key feature for classifier","6f4295f0":"### Bar Chart for Categorical Features\n- Pclass\n- Sex\n- SibSp ( # of siblings and spouse)\n- Parch ( # of parents and children)\n- Embarked\n- Cabin","1cde8a7d":"The Chart confirms **a person aboarded from C** slightly more likely survived  \nThe Chart confirms **a person aboarded from Q** more likely dead  \nThe Chart confirms **a person aboarded from S** more likely dead","2b348150":"#### 4.4.2 Binning\nBinning\/Converting Numerical Age to Categorical Variable  \n\nfeature vector map:  \nchild: 0  \nyoung: 1  \nadult: 2  \nmid-age: 3  \nsenior: 4","8450acd2":"**Total rows and columns**\n\nWe can see that there are 891 rows and 12 columns in our training dataset.","b6b06824":"## 1. Defining the problem statement\nComplete the analysis of what sorts of people were likely to survive.  \nIn particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy.","6a58b54f":"## 4. Feature engineering\n\nFeature engineering is the process of using domain knowledge of the data  \nto create features (**feature vectors**) that make machine learning algorithms work.  \n\nfeature vector is an n-dimensional vector of numerical features that represent some object.  \nMany algorithms in machine learning require a numerical representation of objects,  \nsince such representations facilitate processing and statistical analysis.","c5473610":"## 7. Testing"}}