{"cell_type":{"c9769b97":"code","0b128965":"code","14d9ec53":"code","7221e1f9":"code","91921334":"code","60583850":"code","5612eba2":"code","c701ca84":"code","81a9038f":"code","9810e6d6":"code","6a6a0e3d":"code","13bfd575":"code","a525a734":"code","13322fbf":"code","e43aec02":"code","72abc35f":"code","f7ebe0d9":"code","16b3365f":"markdown","2f443319":"markdown","af3ac082":"markdown","7ce0929d":"markdown","15897825":"markdown","db8192c9":"markdown","801276d4":"markdown"},"source":{"c9769b97":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","0b128965":"BATCH_SIZE = 128\nEPOCHS = 10\nLEARNING_RATE = 0.001","14d9ec53":"def download_mnist_datasets():\n    train_data  = datasets.MNIST(\n        root=\"data\",\n        download = True,\n        train = True,\n        transform=ToTensor()\n    )\n    \n    validation_data  = datasets.MNIST(\n        root=\"data\",\n        download = True,\n        train = False,\n        transform=ToTensor()\n    )\n    \n    return train_data, validation_data","7221e1f9":"train_data, validation_data = download_mnist_datasets()","91921334":"train_data_loader = DataLoader(train_data, batch_size = BATCH_SIZE)","60583850":"class FeedForwardNet(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.dense_layers = nn.Sequential(\n            nn.Linear(28*28, 256),\n            nn.ReLU(),\n            nn.Linear(256, 10)\n        )\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, input_data):\n        flattened_data = self.flatten(input_data)\n        logits = self.dense_layers(flattened_data)\n        predictions = self.softmax(logits)\n        return predictions","5612eba2":"if torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nprint(f\"using {device} device\")","c701ca84":"feed_forward_net = FeedForwardNet().to(device)","81a9038f":"def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n    for inputs,targets in data_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        #calculate loss\n        predictions = model(inputs)\n        loss = loss_fn(predictions, targets)\n        \n        \n        #backpropagate loss & update weights\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n    \n    print(f\"Loss: {loss.item()}\")\n        \n\ndef train(model, data_loader, loss_fn, optimiser, device, epochs):\n    for i in range(epochs):\n        print(f\"Epoch {i+1}\")\n        train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n        print(\"------------------------------------\")\n    print(\"Training Finished\")","9810e6d6":"loss_fn = nn.CrossEntropyLoss()\noptimiser = torch.optim.Adam(feed_forward_net.parameters(),\n                            lr = LEARNING_RATE)","6a6a0e3d":"train(feed_forward_net, train_data_loader, loss_fn, optimiser, device, epochs = EPOCHS)","13bfd575":"#store the model\ntorch.save(feed_forward_net.state_dict(), \".\/feedforwardnet.pth\")\nprint(\"Model trained and stored at feedforwardnet.pth\")","a525a734":"feed_forward_net = FeedForwardNet()\nstate_dict = torch.load(\".\/feedforwardnet.pth\")\nfeed_forward_net.load_state_dict(state_dict)","13322fbf":"input, target = validation_data[0][0], validation_data[0][1]","e43aec02":"class_mapping = [\n    \"0\",\n    \"1\",\n    \"2\",\n    \"3\",\n    \"4\",\n    \"5\",\n    \"6\",\n    \"7\",\n    \"8\",\n    \"9\"\n]","72abc35f":"def predict(model, input, target, class_mapping):\n    model.eval()  # opposite of model.train\n    with torch.no_grad():\n        predictions = model(input)\n        #predictions are tensor object dim (1,10) (#sample, class)\n        predicted_index = predictions[0].argmax(0)\n        predicted = class_mapping[predicted_index]\n        \n        expected = class_mapping[target]\n    \n    return predicted, expected","f7ebe0d9":"predicted, expected = predict(feed_forward_net, input, target, \n                              class_mapping )\n\nprint(f\"Predicted : {predicted}, Expected : {expected}\")","16b3365f":"# **Load back the model**","2f443319":"# **#1 Download Dataset**","af3ac082":"# **Make a prediction**","7ce0929d":"# **#3 Create Model**\nIn Pytorch, the model we want to create should be a class, which will inherit from **nn.Module**","15897825":"**Get a sample from the validation dataset (making test set)**","db8192c9":"# **#2 Creating dataloader**\nIt allows data to be loaded in batches. It is helpful in case of large datasets, relieving the pressure of memory as it fetches data in a batch format. A data loader is an iterable object.","801276d4":"# **#4 Training the Model**"}}