{"cell_type":{"61430314":"code","6b2f4988":"code","0bb47554":"code","b79f60c4":"code","6a7b49dc":"code","e9f5f333":"code","7701ae35":"code","6b58cde2":"code","b102683b":"code","5da64ffa":"code","894cbce7":"code","d6a4417d":"code","a17e906a":"code","15d68027":"code","8261f19e":"code","84716660":"code","82c3c6ce":"code","6aff28f5":"code","d85c4969":"code","78de852c":"code","54b2c89b":"code","bde9a71e":"code","6eb5df74":"code","781e69cd":"code","c4bcc54f":"code","14f20a5f":"code","4d8873bf":"markdown"},"source":{"61430314":"from collections import defaultdict\nfrom scipy.stats import itemfreq\nfrom scipy import ndimage as ndi\nimport matplotlib.pyplot as plt\nfrom skimage import feature\nfrom PIL import Image as IMG\nimport numpy as np\nimport pandas as pd \nimport operator\nimport cv2\nimport os \n\nfrom IPython.core.display import HTML \nfrom IPython.display import Image\n\nimages_path = '..\/input\/train_images\/'\nimgs = os.listdir(images_path)\n\nfeatures = pd.DataFrame()\nfeatures['image'] = imgs","6b2f4988":"features = features.loc[['-1.' in x for x in features.image]]","0bb47554":"images_path = '..\/input\/test_images\/'\nimgs = os.listdir(images_path)\n\nfeatures_test = pd.DataFrame()\nfeatures_test['image'] = imgs\nfeatures_test = features_test.loc[['-1.' in x for x in features_test.image]]","b79f60c4":"def color_analysis(img):\n    # obtain the color palatte of the image \n    palatte = defaultdict(int)\n    for pixel in img.getdata():\n        palatte[pixel] += 1\n    \n    # sort the colors present in the image \n    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n    \n    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 1000\n    for i, x in enumerate(sorted_x[:pixel_limit]):\n        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n            dark_shade += x[1]\n        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n            light_shade += x[1]\n        shade_count += x[1]\n        \n    light_percent = round((float(light_shade)\/shade_count)*100, 2)\n    dark_percent = round((float(dark_shade)\/shade_count)*100, 2)\n    return light_percent, dark_percent","6a7b49dc":"def perform_color_analysis(img):\n\n    path = images_path + img \n    im = IMG.open(path) #.convert(\"RGB\")\n    \n    # cut the images into two halves as complete average may give bias results\n    size = im.size\n    halves = (size[0]\/2, size[1]\/2)\n    im1 = im.crop((0, 0, size[0], halves[1]))\n    im2 = im.crop((0, halves[1], size[0], size[1]))\n\n    try:\n        light_percent1, dark_percent1 = color_analysis(im1)\n        light_percent2, dark_percent2 = color_analysis(im2)\n    except Exception as e:\n        light_percent1, dark_percent1 = -1, -1\n        light_percent2, dark_percent2 = -1, -1\n\n    light_percent = (light_percent1 + light_percent2)\/2 \n    dark_percent = (dark_percent1 + dark_percent2)\/2 \n    \n    return dark_percent, light_percent","e9f5f333":"from tqdm import tqdm\ntqdm.pandas()\nimport time","7701ae35":"images_path='..\/input\/train_images\/'","6b58cde2":"start=time.time()\nfeatures['dullness_whiteness'] = features['image'].apply(lambda x : perform_color_analysis(x))\nprint(time.time()-start)","b102683b":"features['dullness'] = features.dullness_whiteness.map(lambda x: x[0])","5da64ffa":"features['whiteness'] = features.dullness_whiteness.map(lambda x: x[1])","894cbce7":"topdull = features.sort_values('dullness', ascending = False)","d6a4417d":"for j,x in topdull.head(5).iterrows():\n    \n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")<\/h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","a17e906a":"topbright = features.sort_values('whiteness', ascending = False)\nfor j,x in topbright.head(5).iterrows():\n    images_path='..\/input\/train_images\/'\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")<\/h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","15d68027":"def average_pixel_width(img):\n    path = images_path + img \n    im = IMG.open(path)    \n    im_array = np.asarray(im.convert(mode='L'))\n    edges_sigma1 = feature.canny(im_array, sigma=3)\n    apw = (float(np.sum(edges_sigma1)) \/ (im.size[0]*im.size[1]))\n    return apw*100","8261f19e":"features['average_pixel_width'] = features['image'].apply(average_pixel_width)\ntempdf = features.sort_values('average_pixel_width').head()\ntempdf","84716660":"for j,x in tempdf.head(6).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Average Pixel Width : \" + str(x['average_pixel_width']) +\")<\/h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","82c3c6ce":"def getSize(filename):\n    filename = images_path + filename\n    st = os.stat(filename)\n    return st.st_size\n\ndef getDimensions(filename):\n    filename = images_path + filename\n    img_size = IMG.open(filename).size\n    return img_size ","6aff28f5":"features['image_size'] = features['image'].apply(getSize)\nfeatures['temp_size'] = features['image'].apply(getDimensions)\nfeatures['width'] = features['temp_size'].apply(lambda x : x[0])\nfeatures['height'] = features['temp_size'].apply(lambda x : x[1])\n\nfeatures.head()","d85c4969":"def get_blurrness_score(image):\n    path =  images_path + image \n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n    return fm","78de852c":"features['blurrness'] = features['image'].apply(get_blurrness_score)","54b2c89b":"tempdf = features.sort_values('blurrness')\nfor y,x in tempdf.head(5).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Blurrness : \" + str(x['blurrness']) +\")<\/h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","bde9a71e":"images_path='..\/input\/test_images\/'","6eb5df74":"start=time.time()\nfeatures_test['dullness_whiteness'] = features_test['image'].apply(lambda x : perform_color_analysis(x))\nprint(time.time()-start)","781e69cd":"features_test['dullness'] = features_test.dullness_whiteness.map(lambda x: x[0])\nfeatures_test['whiteness'] = features_test.dullness_whiteness.map(lambda x: x[1])","c4bcc54f":"features_test['average_pixel_width'] = features_test['image'].apply(average_pixel_width)\nfeatures_test['image_size'] = features_test['image'].apply(getSize)\nfeatures_test['temp_size'] = features_test['image'].apply(getDimensions)\nfeatures_test['width'] = features_test['temp_size'].apply(lambda x : x[0])\nfeatures_test['height'] = features_test['temp_size'].apply(lambda x : x[1])\nfeatures_test['blurrness'] = features_test['image'].apply(get_blurrness_score)","14f20a5f":"features.to_csv('train_image.csv',index=False)\nfeatures_test.to_csv('test_image.csv',index=False)","4d8873bf":"Image Statistics on PetFinder images.\n\nTechniques and ideas from Shivam Banshal's notebook: https:\/\/www.kaggle.com\/shivamb\/ideas-for-image-features-and-image-quality\/notebook"}}