{"cell_type":{"5357ce7f":"code","71df5173":"code","33dbd344":"code","0b4e6ea2":"code","36d8d40d":"code","e31f2d93":"code","d18e2be1":"code","a61c5ebc":"code","536729de":"code","53a2c4e9":"code","949e701d":"code","80ac32fc":"code","ec462138":"code","06d73d6b":"code","8d3cfba3":"code","6c8b5594":"code","ece0551a":"code","8db56ff0":"code","805ead46":"code","202927e1":"code","275601bb":"code","f7ff87ce":"code","25f7dd44":"code","67f85e9a":"code","e67b2c7c":"code","a4045699":"code","74f8ae81":"code","0cc741d4":"code","6fbdbb09":"code","32a6b9de":"code","57fecf75":"code","9df20b02":"code","9929e98e":"code","2bd5bb2f":"code","5942c824":"code","69b33e8f":"code","df4215e6":"code","4f434ad3":"code","d211f755":"code","2fbfe519":"code","3ba92ccc":"code","82605a3c":"code","edfaeaef":"code","e65b9daf":"code","0ef54d1a":"code","190ae93a":"code","009b42ae":"code","b22821f4":"code","22712a77":"code","29c77593":"code","fab2231d":"code","df45748b":"code","f2ebe1d4":"code","3449be81":"code","39f562eb":"code","e8da8a39":"code","67eee0e4":"code","4602303a":"code","84a78495":"code","c7cc2711":"code","e9825d26":"code","af315041":"code","18af7935":"code","a5abc74c":"code","ddfa82a5":"code","729910d4":"code","28afaf7a":"code","dfbe4277":"code","c188ff15":"code","7eb21eba":"code","89925c4d":"code","9ad6a1d2":"code","ff1d4d92":"code","25d112e3":"code","c10362a0":"code","a535c7e8":"code","5f9913b9":"code","589e677f":"code","8a944532":"code","515d1717":"code","55637786":"code","6e95d11e":"code","8a3a0239":"code","22bc07e4":"code","6e3035b7":"code","14c29753":"code","cfb68df9":"code","ab75e1b7":"code","ef2df414":"code","bf7e2c5c":"code","452dcee9":"code","2ad743ef":"code","2aa018d8":"code","7b9705d2":"code","97b7410a":"code","07b29774":"code","6f1c6d38":"code","30e6e4a5":"code","7376614f":"code","9845fe0e":"code","c63e0968":"code","1df6692b":"code","0c5e17e5":"code","33a9b6e0":"code","658597d3":"code","05f5aad3":"code","194bbe53":"code","45b5c820":"code","254070e9":"code","d77cbf40":"code","28bf22c6":"code","a1d07963":"code","05a504e8":"code","fa97fe64":"code","08be5175":"code","df21b0c9":"code","e348b4c5":"code","c6ef0041":"code","b959af1b":"code","9f4f3d5d":"code","3bfe64c2":"code","caf7433c":"code","4b1da277":"code","a48865bb":"code","2319eb5f":"code","b8231a74":"code","9d3ce666":"markdown","89820316":"markdown","1458031d":"markdown","bc8b41a7":"markdown","57b0b944":"markdown","42b25176":"markdown","091b9d49":"markdown","d841fa35":"markdown","b7ca4f35":"markdown","fa3a1a1f":"markdown","378bb82b":"markdown","4e1ef072":"markdown","6263f2db":"markdown","fab5bf92":"markdown","2f76ae84":"markdown","0f0cd670":"markdown","bb7e9cf7":"markdown","25443b7b":"markdown","4374d38f":"markdown","d6f80663":"markdown","e9be2ca8":"markdown","fa3bb340":"markdown","1fc89980":"markdown","33d5fa4d":"markdown","6a94b496":"markdown","73867b18":"markdown","4c5f078e":"markdown","dd3471c2":"markdown","1639da1a":"markdown","62d05973":"markdown","f414b4a8":"markdown","afa8a251":"markdown","6a7f33f2":"markdown","b75aaeee":"markdown","4c9cd607":"markdown","0edc06c7":"markdown","d7e1e095":"markdown","4a8defeb":"markdown","e78a124e":"markdown","a5d8ce86":"markdown","03fe0e64":"markdown","24d61444":"markdown","b675c731":"markdown","b427ebd5":"markdown","865bb45c":"markdown","a090df91":"markdown","8f03b9ce":"markdown","203943d2":"markdown","aa3d520b":"markdown","e7024a93":"markdown","71b01605":"markdown","36af46a0":"markdown"},"source":{"5357ce7f":"!wget 'https:\/\/anaconda.org\/conda-forge\/gdcm\/2.8.9\/download\/linux-64\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q\n!conda install 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y","71df5173":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n","33dbd344":"import matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom as dicom\nimport cv2\nimport ast\nimport warnings\nwarnings.filterwarnings('ignore')","0b4e6ea2":"path = '\/kaggle\/input\/siim-covid19-detection\/'","36d8d40d":"os.listdir(path)","e31f2d93":"train_image = pd.read_csv(path+'train_image_level.csv')\ntrain_study = pd.read_csv(path+'train_study_level.csv')\nsample_submission = pd.read_csv(path+'sample_submission.csv')","d18e2be1":"len(sample_submission)","a61c5ebc":"train_image","536729de":"train_study","53a2c4e9":"temp = train_image.loc[0, 'StudyInstanceUID']\ntemp","949e701d":"temp_depth2 = os.listdir(path+'train\/'+temp)\ntemp_depth2[0]","80ac32fc":"temp_train_path = path+'train\/'+temp+'\/'+temp_depth2[0]\ntemp_train_path","ec462138":"os.listdir('\/kaggle\/input\/siim-covid19-detection\/train\/5776db0cec75\/81456c9c5423')  ","06d73d6b":"train_image.loc[0, 'id']","8d3cfba3":"def extraction(i):\n    path_train = path + 'train\/' + train_image.loc[i, 'StudyInstanceUID']\n    last_folder_in_path = os.listdir(path_train)[0]\n    path_train = path_train + '\/{}\/'.format(last_folder_in_path)\n    img_id = train_image.loc[i, 'id'].replace('_image','.dcm')\n    print(img_id)\n    data_file = dicom.dcmread(path_train+img_id)\n    img = data_file.pixel_array\n    return img","6c8b5594":"sample_img = extraction(0)","ece0551a":"sample_img","8db56ff0":"sample_img.shape","805ead46":"train_image.loc[0, 'boxes']","202927e1":"boxes = ast.literal_eval(train_image.loc[0, 'boxes'])\nboxes","275601bb":"fig, ax = plt.subplots(1,1, figsize=(8,4))\nfor box in boxes:\n    p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                      box['width'], box['height'],\n                                      ec='r', fc='none', lw=1.5)\n    ax.add_patch(p)\nax.imshow(sample_img, cmap='gray')\nplt.show()\n","f7ff87ce":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\n\nfor row in range(9):\n    img = extraction(row)\n    # if (nan == nan)\n    # False\n    if (train_image.loc[row,'boxes'] == train_image.loc[row,'boxes']):\n        boxes = ast.literal_eval(train_image.loc[row,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_image.loc[row, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])","25f7dd44":"train_image","67f85e9a":"OpacityCount = train_image['label'].str.count('opacity')\nOpacityCount","e67b2c7c":"train_image['OpacityCount'] = OpacityCount.values","a4045699":"train_image","74f8ae81":"train_image['id'].isnull().sum()","0cc741d4":"id_extract = lambda x : x[0]","6fbdbb09":"train_study","32a6b9de":"train_study['id'].isnull().sum()","57fecf75":"train_study['id'].str.split('_')","9df20b02":"train_study['id'].str.split('_').apply(id_extract)","9929e98e":"train_study['id'] = train_study['id'].str.split('_').apply(id_extract)","2bd5bb2f":"sum(train_study['id'].str.contains(train_image['StudyInstanceUID'][0]))","5942c824":"train_study = train_study.rename({'id':'StudyInstanceUID'}, axis=1)","69b33e8f":"train_study","df4215e6":"train_df = pd.merge(train_image, train_study, on='StudyInstanceUID')\ntrain_df","4f434ad3":"train_df['OpacityCount'].value_counts()","d211f755":"train_df.iloc[:,5:].columns","2fbfe519":"i = 5\nfor col in train_df.iloc[:,5:].columns:\n    print('The Count of {} : '.format(col), sum(train_df.iloc[:,i]))\n    i += 1","3ba92ccc":"train_df[train_df['OpacityCount'] == 0]","82605a3c":"OCount = sorted(list(train_df['OpacityCount'].value_counts().index))\nprint(OCount)","edfaeaef":"for count in OCount:\n    print('Opacity Count = {}\\n------------------------------'.format(count))\n    print(train_df[train_df['OpacityCount'] == count].iloc[:,5:].sum())\n    print(' ')","e65b9daf":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0ef54d1a":"for count in OCount:\n    Count_Series = train_df[train_df['OpacityCount'] == count].iloc[:,5:].sum()\n    fig = plt.figure(figsize=(12,3))\n    sns.barplot(x=Count_Series.index, y=Count_Series.values\/sum(train_df['OpacityCount']==count))\n    plt.title('OpacityCount : {} '.format(count))\n    plt.plot();","190ae93a":"sum(train_df['OpacityCount']==1)","009b42ae":"train_df[(train_df['OpacityCount']==1)&(train_df['Indeterminate Appearance'] == 1)]","b22821f4":"train_df[(train_df['OpacityCount']==1)&(train_df['Atypical Appearance'] == 1)]","22712a77":"train_df[(train_df['OpacityCount']==1)&(train_df['Typical Appearance'] == 1)]","29c77593":"len(train_df[(train_df['OpacityCount']==1)&(train_df['Indeterminate Appearance'] == 1)]) + len(train_df[(train_df['OpacityCount']==1)&(train_df['Atypical Appearance'] == 1)]) + len(train_df[(train_df['OpacityCount']==1)&(train_df['Typical Appearance'] == 1)])","fab2231d":"sum(train_df['OpacityCount']==1)","df45748b":"sample_submission","f2ebe1d4":"train_study","3449be81":"train_image","39f562eb":"train_df","e8da8a39":"len(train_df['StudyInstanceUID'])","67eee0e4":"len(train_df['StudyInstanceUID'].unique())","4602303a":"train_image['StudyInstanceUID'].unique().sort() == train_study['StudyInstanceUID'].unique().sort()","84a78495":"len(train_image['StudyInstanceUID'].unique())","c7cc2711":"train_image[train_image.duplicated(['StudyInstanceUID'])==True]['StudyInstanceUID']","e9825d26":"du_StudyId = train_image[train_image.duplicated(['StudyInstanceUID'])==True]['StudyInstanceUID'].values","af315041":"du_images = train_image[train_image['StudyInstanceUID'].isin(du_StudyId)].sort_values(by=['StudyInstanceUID'])\ndu_images","18af7935":"train_df[train_df['StudyInstanceUID'].str.contains('74ba8f2')]","a5abc74c":"os.listdir(path + 'train\/' + '74ba8f2badcb')","ddfa82a5":"long_path = path + 'train\/' + '74ba8f2badcb\/'\nfor i in os.listdir(long_path):\n    print(os.listdir(long_path+i))","729910d4":"os.listdir('\/kaggle\/input\/siim-covid19-detection\/train\/ff0879eb20ed\/d8a644cc4f93')","28afaf7a":"def error_processed_extraction(i):\n    long_path = path + 'train\/' + train_df.loc[i, 'StudyInstanceUID'] + '\/'\n    img_id = train_df.loc[i, 'id'].replace('_image','.dcm')\n    for dcm in os.listdir(long_path):\n        dcm_path = long_path+dcm+'\/'\n        if img_id == os.listdir(dcm_path)[0]:\n            data_file = dicom.dcmread(dcm_path+img_id)\n            print('index : {} - DCM File Path :{}'.format(i, dcm_path+img_id))\n        else:\n            continue\n            \n    img = data_file.pixel_array\n    return img","dfbe4277":"OpacityType = list(train_df.iloc[:,5:].columns)\nOpacityType","c188ff15":"train_df[train_df[OpacityType[0]]==1]","7eb21eba":"Negative_Idx = list(train_df[train_df[OpacityType[0]]==1].index)\nNegative_Idx[:9]","89925c4d":"train_df.iloc[Negative_Idx, :]","9ad6a1d2":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Negative_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(str(train_df.loc[idx, 'label'].split(' ')[0])+ str(idx))\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","ff1d4d92":"Typical_Idx = list(train_df[train_df[OpacityType[1]]==1].index)\nTypical_Idx[:9]","25d112e3":"train_df.iloc[Typical_Idx, :]","c10362a0":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Typical_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='r', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","a535c7e8":"Indeterminate_Idx = list(train_df[train_df[OpacityType[2]]==1].index)\nIndeterminate_Idx[:9]","5f9913b9":"train_df.iloc[Indeterminate_Idx, :]","589e677f":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Indeterminate_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='b', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","8a944532":"Atypical_Idx = list(train_df[train_df[OpacityType[3]]==1].index)\nAtypical_Idx[:9]","515d1717":"train_df.iloc[Atypical_Idx, :]","55637786":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Atypical_Idx[:9]:\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='g', fc='none', lw=2.\n                                            )\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","6e95d11e":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)]","8a3a0239":"i=0\nfig, axes = plt.subplots(nrows=1,ncols=3, figsize=(12,4))\nfor type in OpacityType[1:]:\n    sr = train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)].loc[:,type].value_counts()\n    sns.barplot(x=sr.index, y=sr.values, ax=axes[i])\n    axes[i].set_title(type)\n    i += 1","22bc07e4":"Anom_Count = train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1)][OpacityType[1:]].sum()\nAnom_Count","6e3035b7":"plt.figure(figsize=(8,4))\nsns.barplot(x=Anom_Count.index, y=Anom_Count.values)\nplt.title('Count of \"label==none\"')\nplt.show()","14c29753":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Typical Appearance']==1)].head()","cfb68df9":"Outlier_Typical_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Typical Appearance']==1)].index)\nOutlier_Typical_Idx[:6]","ab75e1b7":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Typical_Idx[:6]:\n    img = error_processed_extraction(idx)\n\n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","ef2df414":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Indeterminate Appearance']==1)].head()","bf7e2c5c":"Outlier_Indeterminate_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Indeterminate Appearance']==1)].index)\nOutlier_Indeterminate_Idx[:6]","452dcee9":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Indeterminate_Idx[:6]:\n    img = error_processed_extraction(idx)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","2ad743ef":"train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Atypical Appearance']==1)].head()","2aa018d8":"Outlier_Atypical_Idx = list(train_df[(train_df['OpacityCount']==0) & (train_df['Negative for Pneumonia']!=1) & (train_df['Atypical Appearance']==1)].index)\nOutlier_Atypical_Idx[:6]","7b9705d2":"fig, axes = plt.subplots(2,3, figsize=(20,10))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in Outlier_Atypical_Idx[:6]:\n    img = error_processed_extraction(idx)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","97b7410a":"for _, row in train_df.iloc[:5].iterrows():\n    print(row)","07b29774":"from glob import glob","6f1c6d38":"for _, row in train_df.iloc[:5].iterrows():\n    image_id = row['id'].split('_')[0]\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{path}\/train\/{study_id}\/*\/{image_id}.dcm')\n    print(img_path)","30e6e4a5":"path_list = []\nfor _, row in train_df.iterrows():\n    image_id = row['id'].split('_')[0]\n    study_id = row['StudyInstanceUID']\n    img_path = glob(f'{path}\/train\/{study_id}\/*\/{image_id}.dcm')\n    if len(img_path)==1:\n        path_list.append(img_path[0])\n    else:\n        print(img_path)","7376614f":"len(path_list)","9845fe0e":"path_list[:10]","c63e0968":"train_df['Path'] = path_list","1df6692b":"train_df","0c5e17e5":"train_df.to_csv('train_df.csv')","33a9b6e0":"data_file = dicom.read_file(path_list[0])","658597d3":"data_file.pixel_array","05f5aad3":"data_file","194bbe53":"data_file.Rows","45b5c820":"data_file.Columns","254070e9":"# Test function, We don't use this\ndef extract_img_size(path_list):\n    origin_img_heights = []\n    origin_img_widths = []\n    i = 0\n    for path in path_list:\n        data_file = dicom.read_file(path)\n        origin_img_heights.append(data_file.Rows)\n        origin_img_widths.append(data_file.Columns)\n        i += 1\n        if i % 100 == 0:\n            print('{}\/{}'.format(i,len(path_list)))\n            \n    return origin_img_heights, origin_img_widths","d77cbf40":"origin_img_heights, origin_img_widths = extract_img_size(path_list[:10])","28bf22c6":"origin_img_heights","a1d07963":"origin_img_widths","05a504e8":"# We use this function\nimport cv2\ndef extract_resized_and_origin_img_info(path_list):\n    img_list = []\n    origin_img_heights = []\n    origin_img_widths = []\n    i = 0\n    for path in path_list:\n        data_file = dicom.read_file(path)\n        img = data_file.pixel_array\n\n            \n        origin_img_heights.append(img.shape[0])\n        origin_img_widths.append(img.shape[1])\n\n        \n        # scailing to 0~255\n        img = (img - np.min(img)) \/ np.max(img)\n        img = (img * 255).astype(np.uint8)\n        \n        # resizing to 4000+ to 150 default\n        img = cv2.resize(img, (150,150))\n        img_list.append(img)\n        img_array = np.array(img_list)\n        i += 1\n        if i % 100 == 0:\n            print('{} \/ {}'.format(len(img_array),len(path_list)))\n    return img_array, origin_img_heights, origin_img_widths","fa97fe64":"test_imgs, origin_img_heights2, origin_img_widths2 = extract_resized_and_origin_img_info(path_list[:10])","08be5175":"test_imgs.shape","df21b0c9":"test_imgs[0].shape","e348b4c5":"test_imgs[0]","c6ef0041":"print('pixel range : ', '{} ~ {}'.format(min(test_imgs[0].reshape(-1)),max(test_imgs[0].reshape(-1))))","b959af1b":"origin_img_heights2","9f4f3d5d":"origin_img_widths2","3bfe64c2":"print((origin_img_heights == origin_img_heights2), (origin_img_widths == origin_img_widths2))","caf7433c":"x_scale_list=[]\ny_scale_list=[]\nif len(origin_img_heights) == len(origin_img_widths):\n    for i in range(len(origin_img_heights)):\n        x_scale = 150 \/ origin_img_widths[i]\n        x_scale_list.append(x_scale)\n        print(i)\n        y_scale = 150 \/ origin_img_heights[i]\n        y_scale_list.append(y_scale)","4b1da277":"x_scale_list","a48865bb":"y_scale_list","2319eb5f":"fig, axes = plt.subplots(3,3, figsize=(20,16))\nfig.subplots_adjust(hspace=.1, wspace=.1)\naxes = axes.ravel()\nrow = 0\nfor idx in range(9):\n    img = error_processed_extraction(idx)\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x'], box['y']),\n                                              box['width'], box['height'],\n                                              ec='b', fc='none', lw=2.)\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","b8231a74":"fig, axes = plt.subplots(3,3, figsize=(16,16))\nfig.subplots_adjust(hspace=.1, wspace=.05)\naxes = axes.ravel()\nrow = 0\nfor idx in range(9):\n    img = test_imgs[idx]\n    # if (nan == nan)\n    # False\n    if (train_df.loc[idx,'boxes'] == train_df.loc[idx,'boxes']):\n        boxes = ast.literal_eval(train_df.loc[idx,'boxes'])\n        for box in boxes:\n            p = matplotlib.patches.Rectangle((box['x']*x_scale_list[idx], box['y']*y_scale_list[idx]),\n                                              box['width']*x_scale_list[idx], box['height']*y_scale_list[idx],\n                                              ec='b', fc='none', lw=2.)\n            axes[row].add_patch(p)\n    \n    axes[row].imshow(img, cmap='gray')\n    axes[row].set_title(train_df.loc[idx, 'label'].split(' ')[0])\n    axes[row].set_xticklabels([])\n    axes[row].set_yticklabels([])\n    row += 1","9d3ce666":"\nOutliers detected through above visualizations. let's check them","89820316":"### 8-a. Negative for Pneumonia","1458031d":"## 9. Feature Engineering III","bc8b41a7":"### 8-c. Indeterminate Appearance","57b0b944":"### 7-c. modify some of the code in function that extract image(.dcm)","42b25176":"All Image path have been saved (6334)","091b9d49":"\nSearch all paths through a loop and check whether it matches the id value.","d841fa35":"The number of `StudyInstanceUID` in train_study(original id) is different from the number of `StudyInstanceUID` in train_df(==train_image)\n\nLet's check them","b7ca4f35":"### 6-a. Count Opacity in Image","fa3a1a1f":"## Step 7. Feature Engineering II","378bb82b":"Now, Let's check duplicated images(id)","4e1ef072":"Thanks for nice reference : \n\n`handling dcm file`\n- [SIIM-FISABIO-RSNA_COVID-19_Detection_Starter, DrCapa](https:\/\/www.kaggle.com\/drcapa\/siim-fisabio-rsna-covid-19-detection-starter)\n\n`Image Visualization`\n- [2. ONE STOP:Understanding+InDepth EDA+Model](https:\/\/www.kaggle.com\/harshsharma511\/one-stop-understanding-indepth-eda-model-progress)\n\n`using gdcm without internet access`\n- [pydicom_conda_helper](https:\/\/www.kaggle.com\/awsaf49\/pydicom-conda-helper)\n\n`Get the box informations`\n- [catch up on positive samples \/ plot submission.csv](https:\/\/www.kaggle.com\/yujiariyasu\/catch-up-on-positive-samples-plot-submission-csv?scriptVersionId=63394385)","6263f2db":"### 3-a. explore path with python code","fab5bf92":"### 6-d. Check the Relation between 'OpacityCount' and other Columes in train_study","2f76ae84":"### 10-a. Add image path to a separate column","0f0cd670":"### 9-c. Show Outliers in `Indeterminate Appearance`","bb7e9cf7":"## Step 4. Show Sample Image","25443b7b":"## Step 10. Image Data Preprocessing","4374d38f":"\n\n```\nStep 1. Import Libraries\nStep 2. Load Data\nStep 3. Read DCM File\n     3-a. explore path with python code\n     3-b. make image extractor(function)\nStep 4. Show Sample Image\n     4-a. explore image data with python code\n     4-b. check position to draw box\nStep 5. Show Multiple Images\nStep 6. Feature Engineering I\n     6-a. count opacity\n     6-b. simplify 'id'\n     6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'\n     6-d. check the relation between 'OpacityCount' and other columes in train_study\n     6-e. visualize the relation between 'OpacityCount' and other columes in train_study\n     6-f. check duplicate values(One row and Two Appearances)\nStep 7. Feature Engineering II\n     7-a. explore data analysis\n     7-b. check duplicates in dataset\n     7-c. modify some of the code in function that extract image(.dcm)\nStep 8. Visualize X-ray with bbox\n     8-a. negative for pneumonia\n     8-b. typical appearance\n     8-c. indeterminate appearance\n     8-d. atypical Appearance\nStep 9. Featrue Engineering III\n     9-a. anomaly detection\n     9-b. show outliers in `Typical Appearance`\n     9-c. show outliers in `Intermiate Appearance`\n     9-d. show outliers in `Atypical Appearance`\nStep 10. Image Data Preprocessing\n     10-a. add image path to a separate column\n     10-b. Resize the image (uniform to 150x150) and Scale each pixel values (uniform range 1~255)\n     10-c. Calculate the resize ratio(x, y) and Apply the same to the bounding box\n```  ","d6f80663":"## Step 1. Import Libraries","e9be2ca8":"### 4-b. check position to draw box","fa3bb340":"### 10-c. Calculate the resize ratio(x, y) and Apply the same to the bounding box","1fc89980":"### 6-c. rename colume 'id' to 'StudyInstanceUID for merge on 'StudyInstanceUID'","33d5fa4d":"Before vs after resizing","6a94b496":"## Step 3. Read DCM File","73867b18":"### 6-b. Simplify 'id' (study)","4c5f078e":"### 3-b. make image extractor(function)","dd3471c2":"### 6-f. Check Duplicate Values(One row and Two Appearances)","1639da1a":"Naturally, because `train_df` is a merged data frame based on `train_image`, `train_image` has also the same result.","62d05973":"## 8. Visualize X-ray with bbox","f414b4a8":"## Step 2. Load Data","afa8a251":"### 9-a. anomaly detection\n\n- Cases with no opacity detected but classified as symptomatic","6a7f33f2":"exactly same result on two function","b75aaeee":"### 6-e. Visualize the Relation between 'OpacityCount' and other Columes in train_study","4c9cd607":"### 8-d. Atypical Appearance","0edc06c7":"We need to load the gdcm package before import `pydicom`. because some of the dcm files are `jpeg lossless` type.","d7e1e095":"### 4-a. Explore Image Data with python code","4a8defeb":"**Anomaly 304 rows : label is 'none' but Non Negative for Pneumonia**","e78a124e":"### 8-b. Typical Appearance","a5d8ce86":"# SIIM: Step-by-Step Image Detection for Beginners [Part 1 - EDA to Preprocessing]","03fe0e64":"### 9-d. Show Outliers in `Atypical Appearance`","24d61444":"We can find that No duplicates in train_study(original ID) because the length of unique `StudyInstanceUID` in train_df and the length of train_study's rows are the same","b675c731":"## Step 6. Feature Engineering I","b427ebd5":"### 9-b. Show Outliers in `Typical Appearance`","865bb45c":"### 10-b. Resize the image (uniform to 150x150) and Scale each pixel values (uniform range 1~255)","a090df91":"We use this dataframe at Part 2. Let's save this to csv file.","8f03b9ce":"```\n232 original ID\n280 duplicate ID\n```\n\n- one or more duplicate Image at the same ID","203943d2":"### 7-b. Check duplicates in dataset","aa3d520b":"So, Some of the code(function extraction) needs to be modified to accurately target the image to be extracted.","e7024a93":"Duplicate ID - ex. 1 ID(74ba8f2badcb) - 4 Path(in each path, All 4 Images are the same)","71b01605":"### 7-a. explore data analysis","36af46a0":"## Step 5. Show Multiple Images"}}