{"cell_type":{"b170de96":"code","f4d7cd05":"code","8621e7b2":"code","525197bd":"code","4c8f1b53":"code","d158d496":"code","feb7ac80":"code","9a204ca7":"code","2592b3bd":"code","5718be53":"code","baf960b7":"code","284bed91":"code","16602b76":"code","1747e314":"code","08198683":"code","3e4cb305":"code","788f22d7":"code","609a09be":"code","fabf2163":"code","b7a9f714":"code","076e3fe8":"code","cdc504d4":"code","914b667b":"code","607aef73":"code","49c141fa":"code","20b3a5d9":"code","ded91441":"code","663947ea":"code","4f2f82e7":"code","5bbb5202":"code","4143266b":"code","996ff7da":"code","b0730e2d":"code","8a63cbef":"code","b7730fc3":"code","a8b25764":"code","ab56c088":"code","02fd8cd0":"code","0bf30bc0":"code","e0f1cffa":"code","2e5e1a38":"code","57efa436":"markdown","fb80d652":"markdown","5f947719":"markdown","84e8165b":"markdown","9208f733":"markdown","04a2746b":"markdown","dbb95bd0":"markdown","2a4474c5":"markdown","b6591463":"markdown","897cf034":"markdown","1aa4f7b8":"markdown","79a642fd":"markdown","d42fdf29":"markdown","1053acd6":"markdown","241caf38":"markdown","a6783a4b":"markdown","b03354b0":"markdown","ad9a9e86":"markdown","1ab1d481":"markdown","8ae83f28":"markdown","c4d9b717":"markdown","6b123c4c":"markdown"},"source":{"b170de96":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","f4d7cd05":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","8621e7b2":"# Print Train Data\ntrain = pd.read_csv('..\/input\/train.csv')\nprint(train.info())\ntrain.head()","525197bd":"# Print Test Data\ntest = pd.read_csv('..\/input\/test.csv')\nprint(test.info())\ntest.head()","4c8f1b53":"\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nallData = pd.concat([train,test], axis = 0)\n\nnullTrain = train.isnull().sum()\/len(train)\nprint('----------')\nprint('Null Value - Train')\nprint(nullTrain[nullTrain > 0])\n\nnullTest = test.isnull().sum()\/len(test)\nprint('----------')\nprint('Null Value - Test')\nprint(nullTest[nullTest > 0])\n","d158d496":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nallData = pd.concat([train,test], axis = 0)\nallDataTransform = allData\nallDataTransform['Age'] = allDataTransform['Age'].fillna(allData['Age'].mean())\nallDataTransform['Embarked'] = allDataTransform['Embarked'].fillna(allData['Embarked'].mode())\nallDataTransform['Fare'] = allDataTransform['Fare'].fillna(allData['Fare'].mean())\nallDataTransform['Fare'] = allDataTransform['Fare'].apply(lambda fare: allData['Fare'].mean() if fare == 0 else fare)\nallDataTransform['Cabin'] = allDataTransform['Cabin'].fillna('N')\nallDataTransform['Cabin'] = allDataTransform['Cabin'].apply(lambda cabinCode: 'N' if cabinCode == 'N' else 'C')\nallDataTransform['Family'] = allDataTransform['SibSp'] +  allDataTransform['Parch']\n\nallDataTransform=allDataTransform.drop(columns=['SibSp'])\nallDataTransform=allDataTransform.drop(columns=['Parch'])","feb7ac80":"allDataTransform.head()","9a204ca7":"catCol = ['Pclass', 'Sex' , 'Embarked','Cabin']\nnumCol = ['Age','Fare','Family']","2592b3bd":"import seaborn as sns\nsns.heatmap(allDataTransform[numCol].corr(),annot=True)","5718be53":"s = allDataTransform[allDataTransform['Survived'] > 0]\nd = allDataTransform[allDataTransform['Survived'] == 0]\nplot = sns.distplot(s['Age'], color=\"b\")\nplot = sns.distplot(d['Age'] , color=\"r\")","baf960b7":"def groupAge(age):\n    if age >= 50: return 'O'\n    elif age >= 40 : return 'M'\n    elif age >= 30 : return 'A'\n    elif age >= 20 : return 'Y'\n    elif age >= 10 : return 'T'\n    elif age >= 0: return 'K'\n\nallDataTransform['AgeGroup'] = allDataTransform['Age'].apply(lambda x: groupAge(x))\n","284bed91":"s = allDataTransform[allDataTransform['Survived'] > 0]\nd = allDataTransform[allDataTransform['Survived'] == 0]\nplot = sns.distplot(s['Family'], color=\"b\")\nplot = sns.distplot(d['Family'] , color=\"r\")","16602b76":"def familySize(n):\n    if n >= 5: return 'L'\n    elif n >= 3 : return 'M'\n    elif n >= 2 : return 'S'\n    elif n >= 1 : return 'N'\n    elif n == 0 : return 'I'\nallDataTransform['familySizeGroup'] = allDataTransform['Family'].apply(lambda x: familySize(x))\n","1747e314":"sns.lmplot(\"Survived\", \"Fare\", data=allDataTransform)","08198683":"s = allDataTransform[allDataTransform['Survived'] > 0]\nd = allDataTransform[allDataTransform['Survived'] == 0]\nplot = sns.distplot(s['Fare'], color=\"b\")\nplot = sns.distplot(d['Fare'] , color=\"r\")","3e4cb305":"import pandas_profiling as pdp\npdp.ProfileReport(allDataTransform)","788f22d7":"# still have NA Value in Embarked????\nallDataTransform[allDataTransform['Embarked'].isnull()==True]\n","609a09be":"allDataTransform['Embarked'] = allDataTransform['Embarked'].fillna('S')\nallDataTransform[allDataTransform['Embarked'].isnull()==True]\n","fabf2163":"allDataTransformDummy = pd.get_dummies(allDataTransform, columns = [\"Embarked\"], prefix=\"Em\")\n# allDataTransformDummy = pd.get_dummies(allDataTransformDummy, columns = [\"Cabin\"], prefix=\"Cabin\")\n# allDataTransformDummy = pd.get_dummies(allDataTransformDummy, columns = [\"Sex\"], prefix=\"Sex\")\nallDataTransformDummy = pd.get_dummies(allDataTransformDummy, columns = [\"AgeGroup\"], prefix=\"Age\")\nallDataTransformDummy = pd.get_dummies(allDataTransformDummy, columns = [\"Pclass\"], prefix=\"Class\")\nallDataTransformDummy = pd.get_dummies(allDataTransformDummy, columns = [\"familySizeGroup\"], prefix=\"Family\")\n\nallDataTransformDummy.head()\n","b7a9f714":"from sklearn.preprocessing import LabelEncoder\ncatCol = ['Sex','Cabin']\nfor col in catCol:\n    lib = LabelEncoder()\n    lib.fit(list(allDataTransformDummy[col].values))\n    allDataTransformDummy[col] = lib.transform(list(allDataTransformDummy[col].values))\n\nallDataTransformDummy.head()\nprint(allDataTransformDummy.columns)","076e3fe8":"# AllCol = allDataTransformDummy.columns\n# AllCol.remove","cdc504d4":"#We have 892 Train Data\ntrainData = allDataTransformDummy[allDataTransformDummy['PassengerId']<892]\nRelated = ['Survived','Age', 'Cabin', 'Fare', 'Sex',\n         'Family', 'Em_C', 'Em_Q', 'Em_S', 'Age_A',\n       'Age_K', 'Age_M', 'Age_O', 'Age_T', 'Age_Y', 'Class_1', 'Class_2',\n       'Class_3', 'Family_L', 'Family_M', 'Family_N', 'Family_S']\n\nsns.heatmap(trainData[Related].corr(),annot=True)","914b667b":"corr = trainData[Related].corr()\ncorr","607aef73":"trainData = allDataTransformDummy[allDataTransformDummy['PassengerId']<892]\n\ncorr = trainData[Related].corr()\n\ncorrPos = corr[corr['Survived']>=0.1]['Survived']\ncorrNeg = corr[corr['Survived']<=-0.1]['Survived']\n\ncorrHigh = corrPos.append(corrNeg)\nprint(corrHigh)\ncorrHigh.index\n\nrel = []\nfor x in corrHigh.index:\n    rel.append(x)\n\nprint(rel)","49c141fa":"from sklearn.linear_model import LogisticRegression\nrelCol = rel\n# relCol = ['Age','Cabin','Embarked', 'Parch' , 'Pclass','Sex','SibSp''Fare']\ntrainData = allDataTransformDummy[allDataTransformDummy['PassengerId']<892]\ntestData = allDataTransformDummy[allDataTransformDummy['PassengerId']>=892]\ntrainResult = trainData['Survived']\n# trainResult = trainData['Survived'].apply(lambda x: int(str(x)[:1]))\n\ntrainDataNeeded = trainData[relCol]\ntestDataNeeded = testData[relCol]\n\ntrainDataNeeded = trainDataNeeded.drop(columns=['Survived'])\ntestDataNeeded = testDataNeeded.drop(columns=['Survived'])\n\ntrainDataAll = trainData.drop(columns=['Survived'])\ntestDataAll = testData.drop(columns=['Survived'])\n\ntrainDataAll = trainDataAll.drop(columns=['Name','Ticket'])\ntestDataAll = testDataAll.drop(columns=['Name','Ticket'])\n\n# trainDataNeeded = trainDataNeeded.drop(columns=['Em_C','Em_S','Fare'])\n# testDataNeeded = testDataNeeded.drop(columns=['Em_C','Em_S','Fare'])\n\ntrainDataNeeded.head()\n\n","20b3a5d9":"trainResult.head()","ded91441":"LogReg = LogisticRegression().fit(trainDataNeeded, trainResult)\nmodelScore = LogReg.score(trainDataNeeded, trainResult)\nprint('Score: ' + str(modelScore))","663947ea":"predict = LogReg.predict(testDataNeeded)\npredict = pd.DataFrame(predict, columns =['Survived'])\npredictResult = pd.concat([testData['PassengerId'], predict], axis = 1)\npredictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n\nfileName = \"Result_{model}_{score}.csv\".format(model='LogisticRegression', score=round(modelScore,2))\npredictResult.to_csv(fileName, index=False)\npredictResult.head()\nprint(fileName)","4f2f82e7":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import plot_tree\n\n\n# from sklearn.preprocessing import Imputer\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\n\n#split test and train\n# train_X, test_X, train_y, test_y = train_test_split(trainDataNeeded, trainResult, test_size=0.25)\n\n\n\n","5bbb5202":"XGB_Class = XGBClassifier().fit(trainDataNeeded, trainResult, verbose=False)\nmodelScore = XGB_Class.score(trainDataNeeded, trainResult)\nprint('Score: ' + str(modelScore))","4143266b":"predictions = XGB_Class.predict(testDataNeeded)\npredictions = pd.DataFrame(predictions, columns =['Survived'])\npredictResult = pd.concat([testData['PassengerId'], predictions], axis = 1)\npredictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n\nfileName = \"Result_{model}_{score}.csv\".format(model='Tree_XGB', score=round(modelScore,2))\npredictResult.to_csv(fileName, index=False)\nprint('File: ' + str(fileName))\npredictResult.head()","996ff7da":"\nplot_tree(XGB_Class)\nplt.show()\n\nprint(XGB_Class.feature_importances_)\nprint(trainDataNeeded.columns)\n\n#Help~~ \n#Anyone knows how to plot a larger graph? resolution is too small now\n#Appreciate if you can leave me a comment.\n#Thanks a lot in advance","b0730e2d":"XGB_Reg = XGBRegressor().fit(trainDataNeeded, trainResult, verbose=False)\nmodelScore = XGB_Reg.score(trainDataNeeded, trainResult)\nprint('Score: ' + str(modelScore))","8a63cbef":"\npredictions = XGB_Reg.predict(testDataNeeded)\npredictions = pd.DataFrame(predictions, columns =['Survived'])\npredictResult = pd.concat([testData['PassengerId'], predictions], axis = 1)\npredictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n\nfileName = \"Result_{model}_{score}.csv\".format(model='Regression_XGB', score=round(modelScore,2))\npredictResult.to_csv(fileName, index=False)\nprint('File: ' + str(fileName))\npredictResult.head()","b7730fc3":"print(XGB_Reg.feature_importances_)\nprint(trainDataNeeded.columns)","a8b25764":"myPara = {\n    'n_estimators': range(10,20,1),\n    'max_depth': range(5,10,1),\n    'learning_rate': [.175, .178, .18 , .182, .185],\n#     'colsample_bytree': [.6, .7, .8, .9 ,1]\n}\nmodelEstimator = XGBClassifier(learning_rate=0.05, max_depth=2)\nGridSearch = GridSearchCV(estimator = modelEstimator, \n                          param_grid = myPara,\n                          scoring = 'accuracy',\n                          cv = 6\n                         )\n\nGridSearch.fit(trainDataNeeded,trainResult)\nprint(\"best score:\",GridSearch.best_score_)\nprint(\"best alpha:\",GridSearch.best_params_)","ab56c088":"predictions = GridSearch.predict(testDataNeeded)\npredictions = pd.DataFrame(predictions, columns =['Survived'])\npredictResult = pd.concat([testData['PassengerId'], predictions], axis = 1)\npredictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n\nfileName = \"Result_{model}_{score}.csv\".format(model='Tree_XGB_GSCV', score=round(GridSearch.best_score_,2))\npredictResult.to_csv(fileName, index=False)\nprint('File: ' + str(fileName))\npredictResult.head()","02fd8cd0":"# try will all para =======\n\nprint (trainDataAll.head())\n\nmyPara = {\n    'n_estimators': range(10,20,1),\n    'max_depth': range(2,10,1),\n    'learning_rate': [.177,.178,.179 ,.180, .182,.185],\n#     'colsample_bytree': [.6, .7, .8, .9 ,1]\n}\n\nmodelEstimator = XGBClassifier(learning_rate=0.1, max_depth=3)\nGridSearch = GridSearchCV(estimator = modelEstimator, \n                          param_grid = myPara,\n                          cv = 5\n                         )\n\nGridSearch.fit(trainDataAll,trainResult)\nprint(\"best score:\",GridSearch.best_score_)\nprint(\"best alpha:\",GridSearch.best_params_)","0bf30bc0":"predictions = GridSearch.predict(testDataAll)\npredictions = pd.DataFrame(predictions, columns =['Survived'])\npredictResult = pd.concat([testData['PassengerId'], predictions], axis = 1)\npredictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n\nfileName = \"Result_{model}_{score}.csv\".format(model='TreeALL_XGB_GSCV', score=round(GridSearch.best_score_,2))\npredictResult.to_csv(fileName, index=False)\nprint('File: ' + str(fileName))\npredictResult.head()","e0f1cffa":"\n\n# myPara = {\n#     'n_estimators': range(10,30,2),\n#     'max_depth': range(2,20,2),\n#     'learning_rate': [.1, .2, .3  ],\n# #     'colsample_bytree': [.6, .7, .8, .9 ,1]\n# }\n# modelEstimator = XGBRegressor(learning_rate=0.05, max_depth=2)\n# GridSearch = GridSearchCV(estimator = modelEstimator, \n#                           param_grid = myPara,\n#                           cv = 5\n#                          )\n\n# GridSearch.fit(trainDataNeeded,trainResult)\n# print(\"best score:\",GridSearch.best_score_)\n# print(\"best alpha:\",GridSearch.best_params_)","2e5e1a38":"# predictions = GridSearch.predict(testDataNeeded)\n# predictions = pd.DataFrame(predictions, columns =['Survived'])\n# predictResult = pd.concat([testData['PassengerId'], predictions], axis = 1)\n# predictResult['Survived'] = predictResult['Survived'].apply(lambda x: str(x)[:1])\n# predictResult.to_csv(\"Result_XGB_Reg_GSCV.csv\", index=False)\n# predictResult.head()","57efa436":"# Fix Data","fb80d652":"# Try to do some grouping on Age","5f947719":"# Relationship of Survived\/Dead vs Age","84e8165b":"# Regression with Boosting and GridSearchCV","9208f733":"# Log Regression Model","04a2746b":"# Try to do some grouping on family Size","dbb95bd0":"View Para Analysis Report using pandas_profiling","2a4474c5":"# Relationship of Survived\/Dead vs Fare","b6591463":"# View Train Test DataSet","897cf034":"# Decision Tree with Boosting and GridSearchCV to get the best para","1aa4f7b8":"# Import XGB Boosting Model","79a642fd":"# Decision Tree (all Para) with Boosting and GridSearchCV","d42fdf29":"# Decision Tree with Boosting","1053acd6":"# Check Correlations","241caf38":"# Check Corr again after data transformation","a6783a4b":"# List out para with high corr","b03354b0":"# Select Para for model","ad9a9e86":"# Regression with Boosting","1ab1d481":"# Relationship of Survived\/Dead vs family Size","8ae83f28":"# Fill in NA with Means\/Mode and data Transformation","c4d9b717":"**The testing result so bad at 0.45, disabled**","6b123c4c":"# Get Dummy Variables for Group Para"}}