{"cell_type":{"a3b8f623":"code","a8a3e0a9":"code","f1d890fc":"code","16531b9b":"code","f5a00e11":"code","4f35d5c1":"code","d939f0d8":"code","be66d9de":"code","8fdba486":"code","3cc0338d":"code","d310ff83":"code","02d83893":"code","3ef88865":"code","eafd020e":"code","150a5876":"code","1cc7f00e":"code","9f042e5a":"code","16775e6f":"code","84f0eb18":"code","12fd1f28":"markdown","ccb389a6":"markdown","a8279654":"markdown","85276bd4":"markdown","57b32887":"markdown","18d003bd":"markdown","d7c22d54":"markdown","e12bef73":"markdown","5bf27d60":"markdown","65f3f032":"markdown","6332d889":"markdown","8efb2424":"markdown","06a93212":"markdown"},"source":{"a3b8f623":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a8a3e0a9":"df = pd.read_csv(\"\/kaggle\/input\/exchange-rates\/exchange_rates.csv\")\ndf = df.drop(df.index[0:5]).dropna()\ndf.head()\n","f1d890fc":"df.columns","16531b9b":"df.head()","f5a00e11":"df.dtypes","4f35d5c1":"df[df.columns[0]]","d939f0d8":"df = df[df != 'ND']\ndf.dropna()","be66d9de":"from datetime import datetime\n\ndf[df.columns[0]] = pd.to_datetime(df[df.columns[0]]) \ndf[df.columns[1:len(df.columns)]] = df[df.columns[1:len(df.columns)]].astype(float)\n","8fdba486":"import matplotlib.pyplot as plt\n\nprint(len(df))\nprint(df.dtypes)","3cc0338d":"import seaborn as sns\n\nfor i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    sns.lineplot(x = df[df.columns[0]], y = df[df.columns[i]])","d310ff83":"for i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    sns.lineplot(x = df[df.columns[0]], y = np.log(df[df.columns[i]]))","02d83893":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(timeseries):\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n       dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","3ef88865":"for i in range(1,len(df.columns)):\n    df[df.columns[i]] = df[df.columns[i]].fillna(method='ffill')\n    print('\\n',df.columns[i])\n    adf_test(df[df.columns[i]])","eafd020e":"for i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    df[df.columns[i]] = df[df.columns[1]] - df[df.columns[i]].shift(1)\n    df[df.columns[i]].dropna().plot()\n    ","150a5876":"plt.figure(figsize=(15,4))\ndf[df.columns[1]].dropna().plot()\nadf_test(df[df.columns[1]].dropna())","1cc7f00e":"from statsmodels.tsa.arima_model import ARIMA\n# using 1,1,1 ARIMA Model\nmodel = ARIMA(df[df.columns[1]].dropna(), order=(1,1,0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","9f042e5a":"plt.figure(figsize=(15,4))\nresiduals = pd.DataFrame(model_fit.resid)\nresiduals.plot(title=\"Residuals\")\nresiduals.plot(kind='kde', title='Density')\nplt.show()","16775e6f":"data = df[df.columns[1]].dropna().values\n\nsize = int(len(data) * 0.7)\ntrain, test = data[0:size], data[size:len(data)]\nhistory = [x for x in train]\npredictions = list()\n\nfor t in range(len(test)):\n    model = ARIMA(history, order=(1,1,1))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))\n","84f0eb18":"from sklearn.metrics import mean_squared_error\n\n#error = mean_squared_error(test, predictions)\n#print('Test MSE: %.3f' % error)\nplt.figure(figsize=(15,4))\nplt.plot(test, label = 'actual')\nplt.plot(predictions, color='red', label = 'predicted')\nplt.legend()\nplt.show()","12fd1f28":"## 6. Optimization\n\nOptimization could be done from the stationary test of datas, or from the ARIMA models. The p, d, and q values could be varied. This work would be done later. ","ccb389a6":"# ARIMA Forecasting using Statsmodel\n\nForecasting is a magic nowadays. Finance institution seeking for good forecasting model to ensure the \"uncertain future\". It also be a magic if you could done well forecasting for your financial activity :)","a8279654":"We dont see the function as stationary, so we need to make it stationary. ","85276bd4":"I think the first was stationary, but the rest is works for later, so it needs different treatment. We will proceed to the first.","57b32887":"We will try to differentiate the data ","18d003bd":"## 5. Predicting Values\n\nWe will split the data into train and test set, with ratio of 7:3. \n\n(Thanks to https:\/\/machinelearningmastery.com\/arima-for-time-series-forecasting-with-python\/) ","d7c22d54":"## 1. Load the Data\n\nWe will drop first 5 row to make the data fully numerical. ","e12bef73":"Yea, too long to wait, so I decide to immediately plot it. Not even halfway but I am impatient for the graph. The graph took differential form. ","5bf27d60":"## 3. See the trend\n\n","65f3f032":"yea the p-value was less than 0.05 so it should be significant. We can plot the residuals to ensure the mean is near-zero. ","6332d889":"## 2. Drop ND and NA values\n\nWe will use the numerical values only, so we will drop all the NaN and ND valued rows. ","8efb2424":"## 4. Make Stationary Data\n\nWe will use ADF (Augmented Dickey Fuller) for statistical test \n\n(Thanks to https:\/\/www.analyticsvidhya.com\/blog\/2018\/09\/non-stationary-time-series-python\/ for the lesson!)","06a93212":"We see that the format was not fixed, so we will fix it. "}}