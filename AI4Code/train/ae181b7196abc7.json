{"cell_type":{"476f2623":"code","1ce0bd44":"code","30e1acee":"code","441d3c5e":"code","dd145d2c":"code","a386f5f0":"code","c2247f86":"code","7c5402c3":"code","298cb1c7":"code","b5807f03":"code","7d9f585b":"code","fbc84da3":"code","0e416c1b":"code","ccf0463e":"code","55ca5a36":"code","84138517":"code","f2f73625":"code","095536b5":"markdown","bc5d23cb":"markdown","0dd128d1":"markdown","f37040fb":"markdown","5f7124d3":"markdown","e234269f":"markdown","dd881f6f":"markdown","886e748f":"markdown","4964bbaf":"markdown","a01ab9db":"markdown"},"source":{"476f2623":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport glob, os\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\nimport torchvision\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm","1ce0bd44":"# check if CUDA is available\nuse_cuda = torch.cuda.is_available()\nprint(use_cuda)","30e1acee":"data_dir = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/'","441d3c5e":"# Verification of the number of Images \n\n# load filenames for Test and Train images\nsize = 0\nsize = np.array(glob(data_dir+\"images\/*\"))\n\n# Check one image\n#Image.open(open(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg\", 'rb'))\n\n# print number of images in each dataset\nprint('There are %d total images.' % len(size))\n\n# Open a file in pandas df format\nsample_csv = pd.read_csv(data_dir + 'sample_submission.csv')\ntest_csv = pd.read_csv(data_dir + 'test.csv')\ntrain_csv = pd.read_csv(data_dir + 'train.csv')\n\ntrain_csv","dd145d2c":"class CustomDataset(Dataset):\n    def __init__(self, csv_file, id_col, target_col, root_dir, sufix=None, transform=None):\n        \"\"\"\n        Args:\n            csv_file   (string):             Path to the csv file with annotations.\n            root_dir   (string):             Directory with all the images.\n            id_col     (string):             csv id column name.\n            target_col (string):             csv target column name.\n            sufix      (string, optional):   Optional sufix for samples.\n            transform  (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.data      = pd.read_csv(csv_file)\n        self.id        = id_col\n        self.target    = target_col\n        self.root      = root_dir\n        self.sufix     = sufix\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get the image name at the different idx\n        img_name = self.data.loc[idx, self.id]\n        \n        # if there is not sufic, nothing happened. in this case sufix is '.jpg'\n        if self.sufix is not None:\n            img_name = img_name + self.sufix\n        \n        # it opens the image of the img_name at the specific idx\n        image = Image.open(os.path.join(self.root, img_name))\n        \n        # if there is not transform nothing happens, here we defined below two transforms for train and for test\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        # define the label based on the idx\n        label = self.data.iloc[idx, 1:5].values.astype('int64')\n        label = np.argwhere(label ==1)\n        label = label.item(0)\n        label = torch.tensor(label)\n        \n        return image, label\n    \ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ])\n}\n\nparams = {\n    'id_col':     'image_id',  \n    'target_col': ['healthy', 'multiple_diseases', 'rust', 'scab'],\n    'sufix':      '.jpg',\n    'transform':  data_transforms['train']\n}\n\ntrain_dataset = CustomDataset(csv_file=data_dir+'train.csv', root_dir=data_dir+'images', **params)\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)","a386f5f0":"# Run the Train Dataset and the Train loader to get the value and shape\nprint('TRAINING')\nimg, lab = train_dataset.__getitem__(0)\n\nprint('DATASET')\nprint('image at the first row: ', img.shape)\nprint('image size at the first row: {}'.format(img.size()))\nprint('Lab at the first row: ', lab)\nprint('lab format at the first row: {}'.format(lab))\nprint('lab format at the first row: {}'.format(lab.shape))\n\n\nprint()\nprint('Train Loader type')\ntrain_iter = iter(train_loader)\nprint(type(train_iter))\n\nimages, labels = train_iter.next()\nprint()\nprint('DATALOADER')\nprint('images type on batch size = {}'.format(type(images)))\nprint('images shape on batch size = ', images.shape)\nprint('labels type on batch size = {}'.format(type(labels)))\nprint('labels shape on batch size = ', labels.shape)\n\n","c2247f86":"# define the CNN architecture\nclass Net(nn.Module):\n    ### TODO: choose an architecture, and complete the class\n    def __init__(self):\n        super(Net, self).__init__()\n        ## Define layers of a CNN\n        # CL sees 224 x 224 x 3 image tensor\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.conv11= nn.Conv2d(16, 16, 2, padding=0)\n        self.conv1_1 = nn.Conv2d(16, 32, 3, padding=1)\n        \n        # CL sees 112 x 112 x 16\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv22 = nn.Conv2d(64, 64, 2, padding=0)\n        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n        \n        \n        # CL sees 56 x 56 x 32\n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.conv33 = nn.Conv2d(256, 256, 2, padding=0)\n        self.conv3_1 = nn.Conv2d(256, 512, 3, padding=1)\n        \n        \n        # CL sees 56 x 56 x 32\n        #self.conv4 = nn.Conv2d(256, 512, 2, padding=0)\n        #self.conv4_1 = nn.Conv2d(512, 512, 3, padding=1)\n        #self.batchnorm512 = nn.BatchNorm2d(512)\n        \n        #batchNorm\n        self.batchnorm16 = nn.BatchNorm2d(16)\n        self.batchnorm32 = nn.BatchNorm2d(32)\n        self.batchnorm64 = nn.BatchNorm2d(64)\n        self.batchnorm128 = nn.BatchNorm2d(128)\n        self.batchnorm256 = nn.BatchNorm2d(256)\n        self.batchnorm512 = nn.BatchNorm2d(512)\n        self.batchnorm1024 = nn.BatchNorm2d(1024)\n        self.batchnorm2048 = nn.BatchNorm2d(2048)\n        \n        # Max pooling layer\n        self.pool = nn.MaxPool2d(3, 3)\n        self.AVGpool = nn.AvgPool2d(3, 3)\n        \n        # linear layer (64 * 28 * 28 -> 500)\n        self.fc1 = nn.Linear(512 * 7 * 7, 500)\n        \n        # linear layer (500 -> 250)\n        self.fc2 = nn.Linear(500, 250)\n        \n        # linear layer \n        #self.fc3 = nn.Linear(500, 250)\n        \n        # linear layer (250 -> 4)\n        self.fc4 = nn.Linear(250, 4)\n        \n        # dropout layer (p=0.25)\n        self.dropout = nn.Dropout2d(0.2)\n        \n        # LogSoftmax\n        self.LogSM = nn.LogSoftmax()\n    \n    def forward(self, x):\n        ## Define forward behavior\n        # 1st CNN\n        # 3 => 16\n        x = self.conv1(x)\n        x = F.relu6(x)\n        x = self.conv11(x)\n        x = F.relu6(x)\n        x = self.batchnorm16(x)\n        \n        # 16 => 32\n        x = self.conv1_1(x)\n        x = F.relu6(x)\n        x = self.batchnorm32(x)\n        \n        x = self.AVGpool(x)\n        x = self.dropout(x)\n        \n        # 2nd CNN\n        # 32 => 64\n        x = self.conv2(x)\n        x = F.relu6(x)\n        x = self.conv22(x)\n        x = F.relu6(x)\n        x = self.batchnorm64(x)\n        \n        # 64 => 128\n        x = self.conv2_1(x)\n        x = F.relu6(x)\n        x = self.batchnorm128(x)\n        \n        x = self.AVGpool(x)\n        x = self.dropout(x)\n        \n        # 3rd CNN\n        # 128 => 256\n        x = self.conv3(x)\n        x = F.relu6(x)\n        x = self.conv33(x)\n        x = F.relu6(x)\n        x = self.batchnorm256(x)\n\n        # 256 => 512\n        x = self.conv3_1(x)\n        x = F.relu6(x)\n        x = self.batchnorm512(x)\n        \n        x = self.AVGpool(x)\n        x = self.dropout(x)\n        \n        \n        #print(x.shape)\n        # flatten image input\n        #print(x.shape)\n        x = x.view(-1, 512 * 7 * 7)\n        #x = self.dropout(x)\n        \n        # add 1st hidden layer, with relu activation function\n        x = self.fc1(x)\n        x = F.relu6(x)\n        x = self.dropout(x)\n        \n        #h2\n        x = self.fc2(x)\n        x = F.relu6(x)\n        x = self.dropout(x)\n        \n        #h3\n        #x = self.fc3(x)\n        #x = F.relu(x)\n        #x = self.dropout(x)\n        x = self.LogSM(self.fc4(x))\n\n        return x\n\n#-#-# You do NOT have to modify the code below this line. #-#-#\n\n# instantiate the CNN\nmodel_patho = Net()\n\n# move tensors to GPU if CUDA is available\nif use_cuda:\n    model_scratch.cuda()\n\n    \nmodel_patho = Net()","7c5402c3":"### TODO: select loss function\ncriterion = nn.CrossEntropyLoss()\n\n### TODO: select optimizer\noptimizer = optim.SGD(model_patho.parameters(), lr=0.001)","298cb1c7":"def train(n_epochs, loaders, model, optimizer, criterion):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf \n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for idx, (data, target) in enumerate(loaders):\n\n            ## find the loss and update the model parameters accordingly\n            ## record the average training loss, using something like\n            ## train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            #update training loss\n            train_loss += loss.item()*data.size(0)\n            \n        # calculate average losses\n        train_loss = train_loss\/len(loaders.sampler)\n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            torch.save(model.state_dict(), 'model_patho_32.pt')\n            ))\n            \n    # return trained model\n    return model","b5807f03":"model_res = train(20, train_loader, model_patho, optimizer, criterion)","7d9f585b":"model_check = Net()\n# load the model that got the best validation accuracy\nmodel_check.load_state_dict(torch.load('\/kaggle\/input\/plantpathomodel\/'+'model_patho_32.pt'))","fbc84da3":"class CustomDataset_test(Dataset):\n    def __init__(self, csv_file, id_col, target_col, root_dir, sufix=None, transform=None):\n        \"\"\"\n        Args:\n            csv_file   (string):             Path to the csv file with annotations.\n            root_dir   (string):             Directory with all the images.\n            id_col     (string):             csv id column name.\n            target_col (string):             csv target column name.\n            sufix      (string, optional):   Optional sufix for samples.\n            transform  (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.data      = pd.read_csv(csv_file)\n        self.id        = id_col\n        self.target    = target_col\n        self.root      = root_dir\n        self.sufix     = sufix\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get the image name at the different idx\n        img_name = self.data.loc[idx, self.id]\n        \n        # if there is not sufic, nothing happened. in this case sufix is '.jpg'\n        if self.sufix is not None:\n            img_name = img_name + self.sufix\n        \n        # it opens the image of the img_name at the specific idx\n        image = Image.open(os.path.join(self.root, img_name))\n        \n        # if there is not transform nothing happens, here we defined below two transforms for train and for test\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        label = self.data.loc[idx, self.id]\n        label = int(label[5:])\n        label = torch.tensor(label)\n        \n        return image, label\n\ndata_transforms_test = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ])\n}\n\nparams = {\n    'id_col':     'image_id',  \n    'target_col': ['healthy', 'multiple_diseases', 'rust', 'scab'],\n    'sufix':      '.jpg',\n    'transform':  data_transforms['test']\n}\n\ntest_dataset = CustomDataset_test(csv_file=data_dir+'test.csv', root_dir=data_dir+'images', **params)\ntest_loader = DataLoader(test_dataset, batch_size = 4, shuffle=True)","0e416c1b":"print('TRAINING')\nimg_test, lab_test = test_dataset.__getitem__(0)\n\nprint('DATASET TEST')\nprint('image at the first row: {}', img_test.shape)\nprint('image size at the first row: {}'.format(img_test.size()))\nprint('Lab at the first row: ', lab_test)\nprint('lab format at the first row: {}'.format(lab_test))\nprint('lab format at the first row: {}'.format(lab_test.shape))\n\nprint()\nprint('Train Loader type')\ntest_iter = iter(test_loader)\nprint(type(test_iter))\n\n\nimages_test, labels_test = train_iter.next()\nprint()\nprint('DATALOADER TEST')\nprint('images test',images_test[0][0][0][0])\nprint('images type on batch size = {}'.format(type(images_test)))\nprint('images shape on batch size = {}', images_test.shape)\nprint('labels type on batch size = {}'.format(type(labels_test)))\nprint('labels shape on batch size = {}', labels_test)","ccf0463e":"classes = ('healthy', 'multiple_diseases', 'rust', 'scab')\n\ndataiter_test = iter(test_loader)\nprint('data_iter\\n',dataiter_test)\nimages_test = dataiter_test.next()\nimages_test_data = images_test[0]\nprint('image test data',images_test_data)\nimages_test_label = images_test[1]\nprint(images_test_label)\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# print images\nimshow(torchvision.utils.make_grid(images_test_data))\n#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","55ca5a36":"model_test = Net()\nmodel_test.load_state_dict(torch.load('\/kaggle\/input\/plantpathomodel\/'+'model_patho_32.pt'))\nmodel_test = model_test.eval()\n\nout_fwd = model_test.forward(images_test_data)\nprint('Result preditcion model on dataset:\\n {}\\n'.format(out_fwd))\nprobs = torch.exp(out_fwd)\nprint('probs\\n', probs)\ntop_probs, top_labs = probs.topk(4)\nprint('top_probs:\\n {} \\n top_labs:\\n {}'.format(top_probs, top_labs))\nprint(classes[top_labs[0][0].detach().numpy()])\nprint(classes[top_labs[1][0].detach().numpy()])\nprint(classes[top_labs[2][0].detach().numpy()])\nprint(classes[top_labs[3][0].detach().numpy()])\n","84138517":"submission_df = pd.read_csv(data_dir + 'sample_submission.csv')\n\nsubmission_df.iloc[:, 1:] = 0\n\nsubmission_df.head()","f2f73625":"submission_df_test = pd.read_csv(data_dir + 'sample_submission.csv')\n\nmodel_test = Net()\nmodel_test.load_state_dict(torch.load('\/kaggle\/input\/plantpathomodel\/'+'model_patho_32.pt'))\nmodel_test = model_test.eval()\n\nbatch_size = 4\n\nfor data in enumerate(test_loader):\n    images_data = data[1][0]\n    #print(images_data)\n    label_data = data[1][1]\n    #print(label_data)   \n    probs = torch.exp(model_test(images_data))\n    #print(probs)\n    label_data = label_data.numpy()\n    #print(label_data)\n    probs = probs.detach().numpy()\n    #print(probs)\n    for i in range(len(label_data)):\n        #print(i)\n        ind = label_data[i]\n        #print(ind)\n        res_probs = probs[i]\n        #print(res_probs)\n        res_add = ['Test_'+str(ind), res_probs[0], res_probs[1],res_probs[2],res_probs[3]]\n        submission_df_test.loc[ind] = res_add         \n        \npd.set_option(\"display.max_rows\", 10, \"display.max_columns\", None)\nprint(submission_df_test)\nsubmission_df_test.to_csv(path_or_buf='sample_submission_2.csv', index=False)\n","095536b5":"## Show the images in the Dataloader and ID_number of the images","bc5d23cb":"# Test","0dd128d1":"# Dataset & Dataloader","f37040fb":"### The model was already trained, so jump to the model_check directly and load the state_dict of the trained model","5f7124d3":"## Run through the Test Dataset and Test Dataloader to check size of the images and labels","e234269f":"# Architecture model","dd881f6f":"## test on the images in the dataloader what is the prediction","886e748f":"# Training","4964bbaf":"# Submission","a01ab9db":"# Import"}}