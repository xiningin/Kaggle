{"cell_type":{"2ae0f579":"code","5152e733":"code","e6ffa9f3":"code","c737ff0b":"code","fd3c0e61":"code","a6230478":"code","9469a4f9":"code","20e664e0":"code","959636e2":"code","e9ecaee2":"code","4d3846eb":"markdown","8db5af25":"markdown","fd7fda44":"markdown","7eda149d":"markdown"},"source":{"2ae0f579":"import pandas as pd\nimport numpy as np\ndf=pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv', sep=',')\ndataset = df.values\ndataset = dataset[:,1:] # Removed serial number column","5152e733":"# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX = dataset[:,:7]\ny = dataset[:,7]\n\nscaler = preprocessing.StandardScaler().fit(X)\nscaler.transform(X)\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0) # 70% training and 20% test\n\npositives = X[y>=0.5,:]\nprint(\"% +ve\",len(positives)*100\/len(dataset))\nnegatives = X[y<0.5,:]\nprint(\"% -ve\",len(negatives)*100\/len(dataset))","e6ffa9f3":"import matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\n\nfor i in range(7):\n    n, bins, patches = plt.hist(negatives[:,i], 5, facecolor='red', alpha=0.5)\n    n, bins, patches = plt.hist(positives[:,i], 5, facecolor='green', alpha=0.5)\n    plt.xlabel(df.columns[i+1])\n    plt.show()","c737ff0b":"import torch\n\nX_train = torch.from_numpy(X_train).float()\nX_test = torch.from_numpy(X_test).float()\ny_train = torch.from_numpy(y_train).float()\ny_test = torch.from_numpy(y_test).float()","fd3c0e61":"class Feedforward(torch.nn.Module):\n        def __init__(self):\n            super(Feedforward, self).__init__()\n            self.a1 = torch.nn.Linear(7,10)\n            self.a2 = torch.nn.Linear(10,10)\n            self.a3 = torch.nn.Linear(10, 1)\n            \n            self.relu = torch.nn.ReLU()\n            self.sigmoid = torch.nn.Sigmoid()        \n        def forward(self, x):\n            z1 = self.relu(self.a1(x))\n            z2 = self.relu(self.a2(z1))\n            z3 = self.sigmoid(self.a3(z2))\n            return z3","a6230478":"class RMSELoss(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = torch.nn.MSELoss()\n        \n    def forward(self,y_pred,y_real):\n        return torch.sqrt(self.mse(y_pred,y_real))","9469a4f9":"model = Feedforward()\ncriterion = RMSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.006)","20e664e0":"model.train()\nepoch = 100000\nloss_arr = []\nfor epoch in range(epoch):\n    optimizer.zero_grad()    # Forward pass\n    y_pred = model(X_train)    # Compute Loss\n    loss = criterion(y_pred.squeeze(), y_train)\n    if (epoch+1)%5000 == 0:\n        print('Epoch {}: train loss: {}'.format((epoch+1), loss.item()))    # Backward pass\n        loss_arr.append(float(loss.item()))\n    loss.backward()\n    optimizer.step()\nprint('Done.')","959636e2":"plt.plot(list(range(len(loss_arr))),loss_arr,color='green')\nplt.ylabel('loss')\nplt.xlabel('iter')\nplt.show()","e9ecaee2":"from sklearn import metrics\nmodel.eval()\ny_pred = model(X_test)\nafter_train = criterion(y_pred.squeeze(), y_test) \nprint('Loss on last 100 datapoints ' , after_train.item())\nprint(\"R^2 Score:\",metrics.r2_score(y_test.detach().numpy(), y_pred.detach().numpy()))","4d3846eb":"## Analysing Trained model","8db5af25":"## Analysing Dataset","fd7fda44":"## Training","7eda149d":"# Task Evaluation"}}