{"cell_type":{"aa7ad181":"code","3e0c8551":"code","e4274587":"code","5017ef35":"code","f09c36ce":"code","29bfbd44":"code","97f2fb78":"code","d74c8230":"code","d51a049c":"code","5847a0f7":"code","b68998e1":"code","54919ed5":"code","a672c593":"code","e45490cf":"code","cdffe0f7":"code","d6fb877e":"code","c5102767":"code","4590bbdc":"code","15011b4f":"code","8d3679d4":"code","17c9f2f9":"code","c47ac376":"code","7cf98f49":"code","294f194f":"code","7b6d5c77":"code","40050152":"code","1e66ac80":"code","5f78baf0":"code","800a1887":"code","2d52ad65":"code","37d357e6":"code","8be05657":"code","053c4708":"code","60d3c8dd":"code","cd498b4f":"code","fc314c9e":"markdown","85a6ca03":"markdown","8b76263a":"markdown","8abb0b2d":"markdown","b265d4c5":"markdown","521ccff7":"markdown","c97ebab5":"markdown","a8195b5e":"markdown","566be1e4":"markdown","e9c4c87c":"markdown","0d3eae88":"markdown","2ad8012c":"markdown","20e86967":"markdown","2422f161":"markdown","a913c33c":"markdown","61c533c0":"markdown","7c68ce82":"markdown","5b84d17d":"markdown","a6e697c9":"markdown","2830d4b0":"markdown","dd897d38":"markdown","2923db94":"markdown","bd3aa065":"markdown","7313b45a":"markdown","b229d9b1":"markdown","548bcb74":"markdown","1fa76bca":"markdown","23ada9dc":"markdown","c72b445d":"markdown","5c21d50b":"markdown","ee8e4d9c":"markdown","d74b46c1":"markdown","ea5dac1a":"markdown","3108a4a9":"markdown","11652d52":"markdown"},"source":{"aa7ad181":"# install sklego to apply easily GMM model\n!pip install sklego","3e0c8551":"# Import required Libraries\n\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\nimport copy\n\n# Classifier Libraries\nfrom sklearn.ensemble import IsolationForest\nfrom sklego.mixture import GMMClassifier, GMMOutlierDetector\nimport collections\n\n\n# train\/test split libraries and preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n\n# libraries to handle imbalanced datasets\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\n\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, \\\naccuracy_score, classification_report, balanced_accuracy_score, cohen_kappa_score, average_precision_score\nfrom collections import Counter\n","e4274587":"# omit warnings \n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# to show multiple results inside a single cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity='all'","5017ef35":"# read dataset and show a random sample\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.sample(20).head()","f09c36ce":"# Show basic statistics for PCA features (V1 to V28 fields)\ndf.iloc[:,1:28].describe()\n\n# Show basic statistics for Amount\ndf.loc[:,['Amount']].describe()\n\n# check null values\npd.DataFrame(df.isnull().sum(), columns=['# nulls'])\n\n# show column names\nprint(f'Dataset column names:\\n {df.columns.to_list()}')","29bfbd44":"# show KDE plot for Amount\nax = df[['Amount']].plot.kde()\n_= ax.set_title('KDE Amount')\n_= ax.set_xlim([-100,26000])","97f2fb78":"# Show proportion of Classes\n# 1 means Fraud, 0 Normal\nax = df['Class'].value_counts(sort=True).plot.bar(color=[ 'deepskyblue','coral'])\n_= ax.set_title('Class Distributions \\n (0: No Fraud || 1: Fraud)')\nprint('Number of samples in each class:\\n')\ndf['Class'].value_counts()\nprint('Proportion of the classes in the data:\\n')\nprint(round(df['Class'].value_counts() \/ len(df),3))","d74c8230":"# remove output from input features\nX = df.drop('Class', axis=1)\n# set output\ny = df['Class']\n\n# set a stratified KFold splitting schema (without shuffle, in this case random_state cannot be set, see documentation) \nskf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\n# retrive indexes for train\/test using stratified K=5 fold schema\n# preserving the percentage of samples for each class (y) in very fold split as the whole dataset\n\n# list that will contains fold splits (unbalanced)\nfolds=[]\n\nfor i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain,original_y_train = X.iloc[train_index],y.iloc[train_index]\n    original_Xtest,original_y_test = X.iloc[test_index],y.iloc[test_index]\n    # fold split list contain 6 named items\n    # id = index fold (0 to 4 for a K=5 fold split)\n    # train = dataframe features for training split\n    # y_train = serie for training output split\n    # test = dataframe features for test split\n    # y_test = serie for test aoutput split\n    # index_train = array indexes from X for training split number=id\n    # index_test = array indexes from X for test split number=id\n    folds.append({'id':i, 'train':original_Xtrain, 'y_train':original_y_train,\n                  'test' :original_Xtest, 'y_test':original_y_test,\n                 'index_train':train_index, 'index_test':test_index})\n    ","d51a049c":"# how access fold split data\n# folds[0]['train'] # pandas DataFrame\n# folds[0]['y_train'] # pandas Serie\n# folds[0]['index_train'] # numpy array","5847a0f7":"# check shape of fold 0 and 4\nprint(f'Shape inputs features fold 0\\n{folds[0][\"train\"].shape}')\nprint(f'Shape output fold 0\\n{folds[0][\"y_train\"].shape}')\nprint(f'Shape inputs features fold 4\\n{folds[4][\"train\"].shape}')\nprint(f'Shape output fold 4\\n{folds[4][\"y_train\"].shape}')","b68998e1":"# Check class proportions in each fold both for training and test\ndef check_proportions(label_split, label_nfold, y):\n    print(f'\\n\\nProportion of the classes in {label_split} data ({label_nfold}):\\n')\n    #yt=folds[0]['y_train']\n    unique, counts = np.unique(y, return_counts=True)\n    print(f'\"{unique[0]}\": {counts[0]\/len(y):.3f}')\n    print(f'\"{unique[1]}\": {counts[1]\/len(y):.3f}')\n\nfor (i, fold) in enumerate(folds):\n    check_proportions('training','fold: '+str(i+1) ,folds[i]['y_train'])\n    \nfor (i, fold) in enumerate(folds):\n    check_proportions('test','fold: '+str(i+1) ,folds[i]['y_test'])    ","54919ed5":"# First 5 samples from training split in first fold split\nprint('First 5 samples from X training split in fold 1\\n')\nfolds[0]['train'].head() # This is a pandas DataFrame\nprint('First 5 samples from y training split in fold 1\\n')\nfolds[0]['y_train'].head() # This is a pandas Serie\n","a672c593":"# check count classes in fold splits\nnp.unique(folds[0]['y_test'], return_counts=True)","e45490cf":"# transform raw feature to a scaled version \ndef scale_data(fold_list):\n    for  fold in fold_list:\n\n        # define scaler (eventually evaluate a different scaler as RobustScaler)\n        std_scalerAmount = StandardScaler()\n        # fit scaler on training only data\n        # Scaler need to be fitted on training set only to avoid data leakage !!!!!!!!!!!!\n        _= std_scalerAmount.fit(fold['train']['Amount'].values.reshape(-1,1))\n        #print(fold['train']['Amount'])\n        \n\n        fold['train']=fold['train'].assign(Amount_Scaled = std_scalerAmount.transform(fold['train']['Amount'].values.reshape(-1,1)))\n        fold['test']=fold['test'].assign(Amount_Scaled = std_scalerAmount.transform(fold['test']['Amount'].values.reshape(-1,1)))\n\n        # Time scaled(?)\n        std_scalerTime = StandardScaler()\n        _= std_scalerTime.fit(fold['train']['Time'].values.reshape(-1,1))\n        fold['train']=fold['train'].assign(Time_Scaled = std_scalerTime.transform(fold['train']['Time'].values.reshape(-1,1)))\n        fold['test']=fold['test'].assign(Time_Scaled = std_scalerTime.transform(fold['test']['Time'].values.reshape(-1,1)))\n        # print(fold['train'].columns)","cdffe0f7":"# Check raw and scaled features\nscale_data(folds)\npd.options.display.float_format = '{:,.2f}'.format\nfolds[0]['train'][['Amount','Amount_Scaled','Time','Time_Scaled']].describe()","d6fb877e":"# sample a fraction of fold split (returning its indexes) to reduce computation time for t-SNE\nind_subset=folds[0]['train'].sample(random_state=42, frac=0.30, replace=False).index\n\n# define dataframe to use with t-SNE\ndata_subset=folds[0]['train'].loc[ind_subset,:]\ny_subset=folds[0]['y_train'].loc[ind_subset]\n\n# define input features (all but Amount and Time, but with Amount_scaled and Time_scaled)\ncol_features=list(set(data_subset.columns).difference(['Time','Amount']))\nprint(f'Used features:{col_features}\\n')\n","c5102767":"time_start = time.time()\n# Define t-SNE\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state=42, n_jobs=-1)\n\n# fit t-SNE using only features in col_features list\ntsne_results = tsne.fit_transform(data_subset.loc[:,col_features])\nprint(f'\\nt-SNE done! Time elapsed: {(time.time()-time_start):.2f} seconds\\n')","4590bbdc":"def plot_tSNE(data, y, label_title='Clusters using t-SNE (on unbalanced fold split)'):\n    f, ax = plt.subplots(figsize=(10,8))\n\n    data['tsne-2d-one'] = tsne_results[:,0]\n    data['tsne-2d-two'] = tsne_results[:,1]\n    data['y']=y\n\n    _= sns.scatterplot(\n        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n        hue=\"y\",\n        palette=sns.color_palette(\"hls\", 2),\n        data=data,\n        legend=\"full\",\n        ax=ax,\n        alpha=0.6\n    )\n    _= f.suptitle(label_title, fontsize=14)\n\nplot_tSNE(data_subset, y_subset)","15011b4f":"# Helper fucntion  to check classes distribution in data\ndef checkDistribution(y, label_title='Distribution over-sampling by SMOTE'):\n    cmap = LinearSegmentedColormap.from_list(\"Custom cmap\", [\"cadetblue\",\"coral\"],2)\n    color=cmap([0,1])\n    fig, ax= plt.subplots(figsize=(6,4))\n    ax = pd.DataFrame({'Class':y})['Class'].value_counts().sort_index().plot.bar( ax=ax) \n    _ = ax.set_title(label_title)\n    _ = ax.set_xlabel('Classes (Fraud=1, No Fraud=0)')\n    _ = ax.set_ylabel('Count')\n    ax.patches[0].set_facecolor('cadetblue') # color for NO Fraud = 0 class\n    ax.patches[1].set_facecolor('coral')     # color for Fraud = 1 class\n\n#checkDistribution(folds[0]['y_train'])","8d3679d4":"# original solution consisting in copying old list lead \n# to a modification of starting list so I duplicated the procedure\n# using the same skf used to create folds list (stratified k-Fold unbalanced)\n\nfolds_smote =[]\n\n\n\nfor i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    # define SMOTE    \n    sm = SMOTE(random_state=42, sampling_strategy='minority')\n    # fit SMOTE on training only\n    new_Xtrain, new_y_train = sm.fit_sample(X.iloc[train_index],y.iloc[train_index])\n    # leave test as original\n    original_Xtest,original_y_test = X.iloc[test_index],y.iloc[test_index]\n    folds_smote.append({'id':i, 'train':new_Xtrain, 'y_train':new_y_train,\n                  'test' :original_Xtest, 'y_test':original_y_test,\n                 'index_train':train_index, 'index_test':test_index})\n\n# scale data balanced with SMOTE\nscale_data(folds_smote)\n\n# Check scaled data\npd.options.display.float_format = '{:,.2f}'.format\nfolds_smote[0]['train'][['Amount','Amount_Scaled','Time','Time_Scaled']].describe()","17c9f2f9":"# Check distribution in training and test for a specific folder\ncheckDistribution(folds[4]['y_train'].ravel(),label_title='Distribution Fold 4 (training set, NO SMOTE)')\ncheckDistribution(folds_smote[4]['y_train'].ravel(),label_title='Distribution Fold 4 (training set, SMOTE over-sampling)')\ncheckDistribution(folds_smote[4]['y_test'].ravel(), label_title='Distribution Fold 4 (test set)')","c47ac376":"# helper function to plot confusion matrix\ndef plot_cm(cm, model_title):\n    df_cm = pd.DataFrame(cm, ['NO Fraud', 'Fraud'], ['Pred NO Fraud', 'Pred Fraud'])\n    fig, ax = plt.subplots(figsize=(8, 4))\n    sns.set(font_scale=1.4)  # for label size\n    sns.heatmap(df_cm, annot=True, ax=ax, annot_kws={\n                    \"size\": 16}, fmt='g')  # font size\n    ax.set_title(f'Confusion Matrix model: {model_title}')\n\n\n# helper function to convert score to prediction 0=Normal, 1=Fail\ndef score_to_pred(df_pred, threshold=1):\n    # Creating class labels based on decision function\n    df_y_pred = df_pred.copy()\n    \n    # for models like IF (as implemented in scikit-learn, see documentation)\n    # IF score >=0 means normal\/inlier\n    # IF score < 0 means outlier\n    # same apply for GMM as implemented in scikit-lego\n    \n    df_y_pred[df_pred['y_pred'] >= threshold] = 0\n    df_y_pred[df_pred['y_pred'] < threshold] = 1  \n\n    # uncomment to view results\n    # print(df_y_pred['y_pred'].value_counts())\n\n    return df_y_pred['y_pred'].values\n\n# helper function to compute classification metrics and\n# print classification report\n\n\ndef compute_metrics(y_true, y_pred):\n    f1 = f1_score(y_true, y_pred)\n    bac = balanced_accuracy_score(y_true, y_pred)\n    # can swap order, it does not matter\n    kappa = cohen_kappa_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    report = classification_report(y_true,y_pred)\n    #ap=average_precision_score(y_true, y_pred)\n\n    return (f1, bac, kappa, cm, report)\n\ndef print_metrics(f1,bac,kappa,cm,report,ap,  model_name):\n    print(f'{model_name} F1: {f1:.3f}')\n    print(f'{model_name} Balanced Accuracy: {bac:.3f}')\n    print(f'{model_name} Cohen Kappa: {kappa:.3f}')\n    print(f'\\n\\n{report}\\n')\n    ","7cf98f49":"def CV_model(model_name,model, folds, col_features):\n    models_fitted=[]\n    for (i, fold) in enumerate(folds):\n        \n        # define train features and output\n        X_train=fold['train'][col_features]\n        y_train=fold['y_train']\n        \n        # define test features and output\n        X_test=fold['test'][col_features]\n        y_test=fold['y_test']\n\n        # fit model\n        print(f'Fitting model fold split #:{i+1}\\n')\n        model.fit(X_train)\n\n        # add model training prediction to fold split\n        fold.update({f'pred_train-{model_name}': model.predict(X_train)})\n\n         # add model test prediction to fold split\n        fold.update({f'pred_test-{model_name}': model.predict(X_test)})\n        \n        # add to list of fitted models\n        models_fitted.append(model)\n    \n    # return a list of fitted models\n    return (models_fitted)\n\n# Helper functions to compute and plot classifier metrics   \ndef CV_metrics (model_name, fold_list, is_train=False):\n    \n    f1_list = []\n    bac_list = []\n    kappa_list = []\n    cm_list = []\n    report_list = []\n\n    \n    # define label for prediction based on model_name and if is training or test\n    # are in the format pred_train-<Model_Name> or pred_test-<Model_Name> \n    y_pred_label= f'pred_train-{model_name}' if is_train else f'pred_test-{model_name}'\n    \n    y_true_label='y_train' if is_train else 'y_test'\n    \n    for fold in fold_list:\n        # retrive true class and predicted one(by model <model_name>) for train or test split\n        y_true=fold[y_true_label]\n        y_pred=pd.DataFrame({'y_pred':fold[y_pred_label]})\n        # compute metrics\n        (f1, bac , kappa, cm, report)=compute_metrics(y_true,score_to_pred(y_pred))\n        # add metrics to lists\n        f1_list.append(f1)\n        bac_list.append(bac)\n        kappa_list.append(kappa)\n        cm_list.append(cm)\n        report_list.append(report)\n\n    \n    return (f1_list,bac_list, kappa_list, cm_list, report_list)\n\n\ndef plot_CV_Metric(metric, title_label, y_label):\n    df_metric=pd.DataFrame(metric, columns=[y_label])\n    print(f'\\n{df_metric.describe()}\\n')\n    ax=df_metric.plot.box()\n    _= ax.set_ylabel(y_label)\n    _= ax.set_xlabel(' ')\n    _= ax.set_xticks([])\n    _= ax.set_title(title_label)    ","294f194f":"# define input features \ncol_features_if=list(set(folds[0]['train'].columns).difference(['Time','Amount_Scaled','Time_Scaled']))\ncol_features_if=sorted(col_features)\nprint('Features used by Isolation Forest model:\\n')\nprint (', '.join(map(str, col_features_if)))\n#print('\\n'.join(col_features))\n","7b6d5c77":"# The anomaly score of the input samples. The lower, the more abnormal. \n# Negative scores represent outliers, positive scores represent inliers.\nrng = np.random.RandomState(42)\nmodel_if = IsolationForest(n_estimators=100, max_samples='auto', contamination=0.02,\n                      max_features=.8, bootstrap=False, n_jobs=-1, random_state=rng,\n                      verbose=0)","40050152":"model_if_fitted = CV_model('IF', model_if, folds, col_features_if)","1e66ac80":"# compute IF metrics in training\n(f1_train_IF, bac_train_IF , kappa_train_IF,cm_train_IF, report_train_IF)=CV_metrics('IF',folds, is_train=True)\n\n# compute IF metrics in test\n(f1_test_IF, bac_test_IF , kappa_test_IF,cm_test_IF, report_test_IF)=CV_metrics('IF',folds)","5f78baf0":"plot_CV_Metric(f1_train_IF, 'CV Isolation Forest (training)', y_label='F1')\nplot_CV_Metric(bac_train_IF, 'CV Isolation Forest (training)', y_label='Balanced Accuracy')\nplot_CV_Metric(kappa_train_IF, 'CV Isolation Forest (training)', y_label='Cohen Kappa')\n\nprint(f'\\n{report_train_IF[0]}\\n')\nplot_cm(cm_train_IF[0],'Isolation Forest (training) Fold #1')\n","800a1887":"# #print(f'Isolation Forest predicted class count:\\n{pred_if_test[\"y_pred\"].value_counts()}\\n\\n')\n# #np.unique(y_train, return_counts=True)\n# print_metrics(f1_if_test, bac_if_test , kappa_if_test,cm_if_test, report_test, model_name='Isolation Forest (test)')\n\n# #cm_if\n# plot_cm(cm_if_test, 'Isolation Forest (test)')\nplot_CV_Metric(f1_test_IF, 'CV Isolation Forest (test)', y_label='F1')\nplot_CV_Metric(bac_test_IF, 'CV Isolation Forest (test)', y_label='Balanced Accuracy')\nplot_CV_Metric(kappa_test_IF, 'CV Isolation Forest (test)', y_label='Cohen Kappa')\n\nprint(report_test_IF[0])\nplot_cm(cm_test_IF[0],'Isolation Forest (test) Fold #1')","2d52ad65":"# define input features \ncol_features_gmm=list(set(folds_smote[0]['train'].columns).difference(['Time','Amount','Time_Scaled']))\ncol_features_gmm=sorted(col_features_gmm)\nprint('Features used by Gaussian Mixture Model :\\n')\nprint (', '.join(map(str, col_features_gmm)))","37d357e6":"# n_components and threshold should be set using a gridsearch procedure\n# what follow is a first try where threshold was set according to percentage of fraud known using class labels\nmodel_gmm = GMMOutlierDetector(n_components=8, threshold=0.90, \\\n                         random_state=42, warm_start=False, verbose=1)","8be05657":"\nmodel_gmm_fitted = CV_model('GMM', model_gmm, folds_smote, col_features_gmm)\n\n","053c4708":"# compute GMM metrics in training (dataset balanced with SMOTE)\n(f1_train_GMM, bac_train_GMM , kappa_train_GMM,cm_train_GMM, report_train_GMM)=CV_metrics('GMM',folds_smote, is_train=True)\n\n# compute GMM metrics in test\n(f1_test_GMM, bac_test_GMM , kappa_test_GMM,cm_test_GMM, report_test_GMM)=CV_metrics('GMM',folds_smote, is_train=False)","60d3c8dd":"plot_CV_Metric(f1_train_GMM, 'CV Isolation Forest (training)', y_label='F1')\nplot_CV_Metric(bac_train_GMM, 'CV Isolation Forest (training)', y_label='Balanced Accuracy')\nplot_CV_Metric(kappa_train_GMM, 'CV Isolation Forest (training)', y_label='Cohen Kappa')\n\nprint(f'\\n{report_train_IF[0]}\\n')\nplot_cm(cm_train_GMM[0],'GMM (training) Fold #1')","cd498b4f":"plot_CV_Metric(f1_test_GMM, 'CV GMM (test)', y_label='F1')\nplot_CV_Metric(bac_test_GMM, 'CV GMM (test)', y_label='Balanced Accuracy')\nplot_CV_Metric(kappa_test_GMM, 'CV GMM (test)', y_label='Cohen Kappa')\n\nprint(report_test_GMM[0])\nplot_cm(cm_test_GMM[0],'GMM (test) Fold #1')","fc314c9e":"Additional resources:   \n ","85a6ca03":"### Set Features IF","8b76263a":"### Fit Isolation Forest model","8abb0b2d":"### Data sample","b265d4c5":"## Split into Train\/Test & Preprocessing\n[StratifiedKFold](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold.split)","521ccff7":"> <h1>So far:<\/h1>\n* Applied a stratified Kfold (K=5) split schema\n* Each fold is highly unbalanced but contains same proportion of \"0\" and \"1\" classes as whole dataset\n* IF does not require to scale features but GMM do (need to scale only Amount)\n* Classes in each fold can be balanced with techniques as SMOTE (this could improve classifier accuracy, need to be verified)\n* To evaluate classifier performance only training split should be balanced (DO NOT BALANCE TEST SPLITS)\n* Fit scaler to training data only to avoid data leakage\n* Credit card fraud dataset being higly umbalanced require, to correctly evaluate classifier performace, metrics as:    \n  F1, AUPRC (as suggested in contest), Kohen-Kappa, balanced accuracy (not simple accuracy or ROC AUC)\n","c97ebab5":"## GMM recap\n\nK-Fold CV (k=5) results for GMM yeld (mean values on test set):\n\nBalanced Accuray = 0.66\nF1 = 0.01\n","a8195b5e":"### Metrics for GMM on Training (dataset balanced with SMOTE)","566be1e4":"## EDA summary results:\n> The dataset under investigation is highly imbalanced with **0.998% of samples belonging to class '0' (or normal\/inlier, i.e. NO FRAUD) and only 0.002% of fraudolent transactions or class '1' (anomaly\/outlier)**.   \nAmount variable show a distribution right skewed.   \nAll PCA features (V1 to V28) does not need to be normalized.\nThere are no missing values in the dataset.    \nOnly 'Amount' has to be normalized.     \n**Class is the binary output variable (1==FRAUD, 0==NORMAL)**.   ","e9c4c87c":"# Gaussian Mixture Models (GMM)\n> \"Gaussian Mixture (GM) model is usually an unsupervised clustering model that is as easy to grasp as the k-means but has more flexibility than k-means. Fundamentally, GM is a parametric model (i.e. we assume a specific distribution for the data) that uses the Expectation Maximization (EM) algorithm to learn the parameters of the distribution.\" ([extracted from](https:\/\/codefying.com\/2016\/09\/03\/gaussian-mixture-model-with-application-to-anomaly-detection\/))   \nThe algorithm train upon K clusters. Thus given a new data point, the algorithm finds its distance from every distribution & hence the probability of that point belonging to each cluster. Therefore if for a particular cluster, if the probability is very low that\u2019s an indication of the data point being an anomaly.\n\nHere an easy to use implementation (available [here](https:\/\/scikit-lego.readthedocs.io\/en\/latest\/index.html)) hase been employed:   \nsame as for IF, the `.predict` method of `GMMOutlierDetector` returns 1 for inliers, -1 for outliers\n\n[scikit-lego GMMOutlierDetector](https:\/\/scikit-lego.readthedocs.io\/en\/latest\/api\/API%20Reference.html?highlight=gmmoutlier#sklego.mixture.GMMOutlierDetector)   \n[Detect Anomalies using GMM](https:\/\/www.kaggle.com\/albertmistu\/detect-anomalies-using-gmm)   \n[Understanding Anomaly Detection using GMM](https:\/\/towardsdatascience.com\/understanding-anomaly-detection-in-python-using-gaussian-mixture-model-e26e5d06094b)","0d3eae88":"### Check Class distributions","2ad8012c":"## Define scaler to Scale Data ","20e86967":"## Isolation Forest recap\nK-Fold CV (k=5) results for IF yeld (mean values on test set):   \n\n**Balanced Accuray = 0.85**   \n**F1 = 0.11**","2422f161":"# Isolation Forest\nThis is an ensemble model ( derived from extrimely randomized random forest) able to explicitly identifies anomalies instead of profiling normal data points. In this regard it works better if trained on data containing both normal and anomalies samples. It's an unsupervised model, this meand that class labels are not required to fit the model (but they are required instead  to compute metrics).\n\n### The idea behind the Isolation Forest is as follows:\n\n>We start by building multiple decision trees such that the trees isolate the observations in their leaves. Ideally, each leaf of the tree isolates exactly one observation from your data set. The trees are being split randomly. We assume that if one observation is similar to others in our data set, it will take more random splits to perfectly isolate this observation, as opposed to isolating an outlier.   \nFor an outlier that has some feature values significantly different from the other observations, randomly finding the split isolating it should not be too hard. As we build multiple isolation trees, hence the isolation forest, for each observation we can calculate the average number of splits across all the trees that isolate the observation. **The average number of splits is then used as a score, where the less splits the observation needs, the more likely it is to be anomalous.**   ([extracted from](https:\/\/www.h2o.ai\/blog\/anomaly-detection-with-isolation-forests-using-h2o\/))   \nLink to [original paper](https:\/\/cs.nju.edu.cn\/zhouzh\/zhouzh.files\/publication\/icdm08b.pdf)   \n\nAdditional resources:   \n[Outlier Detection with Isolation Forest](https:\/\/towardsdatascience.com\/outlier-detection-with-isolation-forest-3d190448d45e)   \n[Unsupervised fraud detection using Isolation Forest](https:\/\/www.kaggle.com\/rgaddati\/unsupervised-fraud-detection-isolation-forest)   \n[Isolation Forest for fraud detection](https:\/\/www.kaggle.com\/nilanml\/fraud-detection-using-isolation-forest)  ","a913c33c":"## How apply SMOTE\n> As clearly explained by in [Janio Martinez in his kernel](https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets) balacing techniques (e.g. oversample minority class) have to be applied during cross validation (CV) in order to avoid data leakage that could result in overfitting during CV.\n**This means that SMOTE should be applied \"during\" cross validation and not \"prior\" to the cross validation process. Synthetic data are created only for the training set without affecting the test set.**","61c533c0":"### Main sections:\n* Explanatory Data Analysis (EDA)\n* Split dat into train\/test & preprocessing\n* Handle imbalanced datasets (e.g. by using Synthetic Minority Oversampling Technique, a.k.a. SMOTE)\n* Isolation Forest (IF)\n* Gaussian Mixture models (GMM)","7c68ce82":"## Solving the class imbalance in ML (using SMOTE)\n","5b84d17d":"# t-SNE\n>**t-distributed Stochastic Neighbor Embedding (t-SNE)** is a machine learning algorithm for visualization developed by Laurens van der Maaten and Geoffrey Hinton. It is a nonlinear dimensionality reduction technique well-suited for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability. \n\n* t-SNE algorithm should accurately cluster the cases that were fraud and non-fraud in our dataset.\n* By appling the t-SNE algorithm to the raw unbalanced dataset an to the balanced one (further on this notebook) we should have an indication on how tough should be for the selected predictive models to correctly classify cases\n\nAdditional resources on t-SNE:\n* [t-SNE clearly explained](https:\/\/www.youtube.com\/watch?v=NEaUSP4YerM)   \n* [An introduction to t-SNE with Python](https:\/\/medium.com\/@violante.andre\/an-introduction-to-t-sne-with-python-example-47e6ae7dc58f)\n* [t-SNE state of art](https:\/\/medium.com\/@sourajit16.02.93\/tsne-t-distributed-stochastic-neighborhood-embedding-state-of-the-art-c2b4b875b7da)\n* [How use t-SNE effectively](https:\/\/distill.pub\/2016\/misread-tsne\/)\n* [How to tune hyperparameters of t-SNE](https:\/\/towardsdatascience.com\/how-to-tune-hyperparameters-of-tsne-7c0596a18868)\n* [t-SNE and autoencoders](https:\/\/www.kaggle.com\/rohitgr\/autoencoders-tsne)","a6e697c9":"### Metrics for Isolation Forest (test)","2830d4b0":"# Credit card fraud detection\n[Kaggle credit card fraud contest](https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud)     \n\n**How to deal with inbalanced datasets add apply unsupervised models.**   \n\nThis kernel is mainly focus on techniques for imbalanced dataset and use of unsupervised models to detect anomalies.   \nTwo unsupervised models will be tested:\n* **Isolation Forest**\n* **Gaussian Mixture Models**\n\nOn \"credit card fraud detection\" contest are available many interesting kernels, to cite a few that inspired this one:   \n\n[Credit Fraud || Dealing with Imbalanced Datasets](https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets) \n \n \n[In depth skewed data classif. (93% recall acc now)](https:\/\/www.kaggle.com\/joparga3\/in-depth-skewed-data-classif-93-recall-acc-now#Credit-card-fraud-detection)   \n\nI higly suggest to consider also the following resources:   \n[Develop a Model for the Imbalanced Classification of Good and Bad Credit](https:\/\/machinelearningmastery.com\/imbalanced-classification-of-good-and-bad-credit\/?fbclid=IwAR3eS-pztGsb9lfvkRIy7ZTzx5b7jpFkL0ah156qoXLVKcd13fTf_2iu8NU) by Jason Brownlee (at his blog many oother resources regarding classification for unbalanced datasets)  \n","dd897d38":"### Set features GMM","2923db94":"### Helper functions to perform CV","bd3aa065":"### Define IF\n> Here is used the IF implementation available in sklearn.ensemble.   \nTo note that `.predict` method returns -1 for outliers and 1 for inliers.\n\nAnother interesting implementation of IF is that available in H2O (see http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/if.html)","7313b45a":"## How work SMOTE\n[SMOTE explained](http:\/\/rikunert.com\/SMOTE_explained)   \n\nThe following figure synthesize how SMOTE work:   \n>\"What smote does is simple.   \nFirst it finds the n-nearest neighbors in the minority class for each of the samples in the class.   \nThen it draws a line between the neighbors and generates random points on the lines.\" ([sinthetic explanation extracted from this](https:\/\/medium.com\/coinmonks\/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167))      \n\n\n![smote how works](https:\/\/miro.medium.com\/max\/1020\/1*6UFpLFl59O9e3e38ffTXJQ.png)\n\nAdditional resources:   \n[How to Deal with Imbalanced Data using SMOTE](https:\/\/medium.com\/analytics-vidhya\/balance-your-data-using-smote-98e4d79fcddb)   \n[imbalanced-learn documentation](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/auto_examples\/index.html#examples-based-on-real-world-datasets)\n","b229d9b1":"# EDA\n> As stated on Kaggle contest page:   \n\"The datasets contains transactions made by credit cards in September 2013 by european cardholders.   \nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions.   \n**The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.**   \n**It contains only numerical input variables which are the result of a PCA transformation.**   \nUnfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data.    \nFeatures V1, V2, \u2026 V28 are the principal components obtained with PCA, **the only features which have not been transformed with PCA are 'Time' and 'Amount'**.   \nFeature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning.    \n**Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.**\"","548bcb74":"### Define GMM model","1fa76bca":"### Data basic statistics","23ada9dc":"### Metrics for GMM on Test","c72b445d":"### Helper functions to compute classification metrics","5c21d50b":"> A variety of techniques exists to solve class imbalance in ML, one of the most employed is **Synthetic Minority Over-sampling TEchnique (SMOTE)**. Class imbalance in ML, especially for supervised classifier (e.g. logistic regression), can be problematic as due to one class being higly predominat this results in a bias for ML model that tend to always predicts the predominant class.   \nEssentially exits four methods of addressing class imbalance:\n* Synthesisis of new minority class instances\n* Over-sampling of minority class\n* Under-sampling of majority class\n* Tweak the cost function to make misclassification of minority instances more important than misclassification of majority instances\n\n","ee8e4d9c":"### Fit GMM on data balanced with SMOTE","d74b46c1":"### Summary so far\n> Standardized Amount and Time (Amount_scaled and Time_scaled respectively).   \nCreated two list from whole dataset using stratified K-fold (k=5):\n* folds (unbalanced data)\n* folds_smote (balanced classes by SMOTE)\n* use `.loc[:,col_features]` with col_features a list of names features to use in model\n","ea5dac1a":"### Subselect a fraction from fold split to apply t-SNE","3108a4a9":"[Handle copy warning in Pandas](https:\/\/www.dataquest.io\/blog\/settingwithcopywarning\/)","11652d52":"### Metrics for Isolation Forest (training)"}}