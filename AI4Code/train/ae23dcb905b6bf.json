{"cell_type":{"3253aba8":"code","643fb8e8":"code","447db719":"code","fedf1e0f":"code","5ea1a762":"code","e4df9aed":"code","7cb7b30f":"code","008c9e1b":"code","3ca8751f":"code","3a5c6069":"code","34c02843":"code","72268b99":"code","742b2cfe":"code","18b41771":"code","445ce95a":"code","fccfb4e1":"code","a855cabb":"code","ca76df50":"code","7989ec90":"code","8cf44b55":"code","cf37abd5":"code","ec9e1d02":"code","97d25eeb":"code","4fe84fc1":"code","c6039df2":"code","cbf64971":"code","0f68d055":"code","985e70fc":"code","c24e197a":"code","426e56b2":"code","e992b716":"code","c8d8de84":"code","ad117fbf":"code","ed3dc24d":"code","78cffc38":"code","e162356a":"code","37e66456":"code","e4cf22d1":"code","ef88166c":"code","9e158603":"code","10092449":"code","e675e23b":"code","9e1a8fc3":"code","52d87651":"code","1b6dbf2f":"code","a2093ce8":"code","53ee6122":"code","bb1be1da":"code","3b725467":"code","27701362":"code","d3c3bd87":"markdown","0fac6b97":"markdown","9828c6c4":"markdown","1b1c6cb8":"markdown","a2e8a083":"markdown","8e2d0927":"markdown","243d5066":"markdown","5c5d3c7e":"markdown","730d7cae":"markdown","01a3fb7b":"markdown","15a7db04":"markdown","0f009b8a":"markdown"},"source":{"3253aba8":"!cd ..\/input\/sarcasm","643fb8e8":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport json\nimport string\n\nfrom IPython.display import Image\n\nfrom nltk.util import ngrams\nimport re\n\nfrom scipy.sparse import hstack\nfrom sklearn import preprocessing, metrics, ensemble, naive_bayes, linear_model, model_selection\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import defaultdict\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncolor = sns.color_palette()\n\n%matplotlib inline\npd.options.mode.chained_assignment = None\npd.options.display.max_rows = 100","447db719":"train_df = pd.read_csv('..\/input\/sarcasm\/train-balanced-sarcasm.csv')","fedf1e0f":"train_df.head()","5ea1a762":"train_df.info()","e4df9aed":"train_df.dropna(subset=['comment'], inplace=True)","7cb7b30f":"train_df.info()","008c9e1b":"train_df['label'].value_counts()","3ca8751f":"training_df, testing_df = train_test_split(train_df, random_state=17)","3a5c6069":"train_texts = training_df['comment'] \nvalid_texts = testing_df['comment']\ny_train = training_df['label']\ny_valid = testing_df['label']","34c02843":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_df[\"comment\"], max_words=800, title=\"Word Cloud of Comments\")","72268b99":"train1_df = train_df[train_df[\"label\"]==1]\ntrain0_df = train_df[train_df[\"label\"]==0]\n\ndef generate_ngrams(s, n_gram:int):\n    #Generate a list of n-grams from the input data \n    \n    s = s.lower()\n    s = re.sub(r'[0-9-,.$\"!?+\\s]', ' ', s)\n    tokens = [token for token in s.split(\" \") if token != \"\" if token not in STOPWORDS if len(token) > 1]\n    output = list(ngrams(tokens, n_gram))\n    \n    #clean duplicate n-grams in case dimension is > 1 e,g: (fake, fake)\n    if n_gram > 1:\n        full_output = [i for i in output if i[0] != i[1]]\n    else:\n        return output\n    return full_output\n\ndef count_ngrams(train_df, n_gram:int):\n    #We count the n-grams repetitions in specific feature\n    #train_df - DataFrame\n    \n    freq_dict = defaultdict(int)\n    for sent in train_df['comment']:\n        for word in generate_ngrams(sent, n_gram):\n            freq_dict[word] += 1\n    \n    #check commutations (donald, trump) <-> (trump, donald) if n-gram > 1\n    final_dict = defaultdict(int)\n    if n_gram > 1:\n        for key, value in freq_dict.items():\n            if (key[1], key[0]) in final_dict.keys() or (key[0], key[1]) in final_dict.keys():\n                pass\n            else:\n                final_dict[key] = value \n    else:\n        final_dict = freq_dict\n    \n    fd_sorted = pd.DataFrame(sorted(final_dict.items(), key=lambda x: x[1])[::-1])\n    fd_sorted.columns = [\"word\", \"wordcount\"]\n    return fd_sorted\n\ndef ngram_compare_plot(x1, x2, y1, y2, barcolor:str):\n    #Create a plot to compare words used in sarcastic comments and non-saracstic comments\n    \n    fig, axes = plt.subplots(ncols=2, figsize=(16,26), sharey=False)\n    \n    axes[0].xaxis.tick_top()   \n    axes[0].invert_yaxis()\n    axes[0].patch.set_facecolor('black')\n    axes[0].barh([' '.join(list(y)) for y in y1], x1, align = 'center', zorder=10, color = barcolor)\n    axes[0].set(title='Frequent words in sarcastic comments')\n    \n    axes[1].xaxis.tick_top() \n    axes[1].invert_yaxis()\n    axes[1].patch.set_facecolor('black')\n    axes[1].barh([' '.join(list(y)) for y in y2], x2, align = 'center', zorder=10, color = barcolor)\n    axes[1].set(title='Frequent words in non-sarcastic comments')\n \n    \n    for ax in axes.flat:\n        ax.margins(0.01)\n        ax.grid(True)\n    \n    plt.show()","742b2cfe":"train_ngrams1_sarcasm = count_ngrams(train1_df, n_gram=1)\ntrain_ngrams1_nosarcasm = count_ngrams(train0_df, n_gram=1)","18b41771":"ngram_compare_plot(list(train_ngrams1_sarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams1_nosarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams1_sarcasm['word'][:50].values), \\\n                   list(train_ngrams1_nosarcasm['word'][:50].values), 'teal')","445ce95a":"train_ngrams2_sarcasm = count_ngrams(train1_df, n_gram=2)\ntrain_ngrams2_nosarcasm = count_ngrams(train0_df, n_gram=2)","fccfb4e1":"ngram_compare_plot(list(train_ngrams2_sarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams2_nosarcasm['wordcount'][:50].values), \\\n                   list(train_ngrams2_sarcasm['word'][:50].values), \\\n                   list(train_ngrams2_nosarcasm['word'][:50].values), 'salmon')","a855cabb":"train_df['has_downvote'] = train_df['downs'].apply(lambda x: 'Yes' if x == -1 else 'No')","ca76df50":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='has_downvote', hue='label', data=train_df)\n\nplt.legend(title='Downvote influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('Has a downvote')\nplt.show(scores)","7989ec90":"train_df['score_negative'] = train_df['score'].apply(lambda x: 'Yes' if x < 0 else 'No')","8cf44b55":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='score_negative', hue='label', data=train_df)\n\nplt.legend(title='Score influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('Is the comment score negative?')\nplt.show(scores)","cf37abd5":"train_df['downvotes_more'] = (train_df['downs'].abs() >= train_df['ups'].abs())","ec9e1d02":"train_df['downvotes_more'] = train_df['downvotes_more'].apply(lambda x: 'Yes' if x == True else 'No')","97d25eeb":"plt.figure(figsize=(15,8))\nupvotes = sns.countplot(x='downvotes_more', hue='label', data=train_df)\n\n\nplt.legend(title='Downvotes influence on label', loc='upper left', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('More downvotes than upvotes')\nplt.show(scores)","4fe84fc1":"train_df['upvotes_more3'] = train_df['ups'].apply(lambda x: 'Yes' if x > 0 else 'No')","c6039df2":"plt.figure(figsize=(15,8))\nscores = sns.countplot(x='upvotes_more3', hue='label', data=train_df)\n\nplt.legend(title='Upvote influence on label', loc='upper right', labels=['Not sarcasm', 'Sarcasm'])\nplt.xlabel('More than 3 upvotes')\nplt.show(scores)","cbf64971":"train_df['score_negative'] = train_df['score'].apply(lambda x: '1' if x < 0 else '0')\ntraining_df['score_negative'] = training_df['score'].apply(lambda x: '1' if x < 0 else '0')\ntesting_df['score_negative'] = testing_df['score'].apply(lambda x: '1' if x < 0 else '0')","0f68d055":"train_df.head()","985e70fc":"train_df['author'].value_counts()","c24e197a":"train_df[train_df['author'] == 'Biffingston']['label'].value_counts()","426e56b2":"mlist = ['author', 'score', 'ups', 'downs', 'date', \\\n         'created_utc', 'downvotes_more', 'upvotes_more3', 'has_downvote', 'parent_comment']\ntrain_df.drop(mlist, 1, inplace=True)","e992b716":"train_df.head()","c8d8de84":"def text_format(s):\n    s = s.lower()\n    s = re.sub(r'[0-9-,.$\"!?+\\s]', ' ', s)\n    output = str(s)\n    return output","ad117fbf":"train_texts.apply(lambda x: text_format(x));\nvalid_texts.apply(lambda x: text_format(x));","ed3dc24d":"misc = ['author', 'score', 'ups', 'downs', 'date', 'created_utc']\ntraining_df.drop(misc, 1, inplace=True)\ntesting_df.drop(misc, 1, inplace=True)\nscore_negative = train_df['score_negative']\nscore_negative_train, score_negative_test = train_test_split(score_negative, random_state=17) ","78cffc38":"score_negative.shape, score_negative_test.shape, score_negative_train.shape","e162356a":"subreddits = train_df['subreddit']\ntrain_subreddits, valid_subreddits = train_test_split(subreddits, random_state=17)","37e66456":"tf_idf_texts  = TfidfVectorizer(max_features=50000, min_df=2, ngram_range=(1,2))\ntf_idf_subreddits = TfidfVectorizer(ngram_range=(1, 1))","e4cf22d1":"%%time\nX_train_texts = tf_idf_texts.fit_transform(train_texts)\nX_valid_texts = tf_idf_texts.transform(valid_texts)","ef88166c":"X_train_texts.shape, X_valid_texts.shape","9e158603":"%%time\nX_train_subreddits = tf_idf_subreddits.fit_transform(train_subreddits)\nX_valid_subreddits = tf_idf_subreddits.transform(valid_subreddits)","10092449":"X_train = hstack([X_train_texts, X_train_subreddits])\nX_valid = hstack([X_valid_texts, X_valid_subreddits])","e675e23b":"logit = LogisticRegression(C=1, n_jobs=4, solver='lbfgs', \n                           random_state=17, verbose=1)","9e1a8fc3":"score_train_reshaped = score_negative_train.values.reshape((len(score_negative_train.values), 1))\nscore_test_reshaped = score_negative_test.values.reshape((len(score_negative_test.values), 1))","52d87651":"X_training = hstack([X_train, score_train_reshaped.astype(float)])\nX_validation = hstack([X_valid, score_test_reshaped.astype(float)])","1b6dbf2f":"logit.fit(X_training, y_train)","a2093ce8":"%%time\nvalid_pred = logit.predict(X_validation)","53ee6122":"accuracy_score(y_valid, valid_pred)","bb1be1da":"logit.fit(X_train, y_train)","3b725467":"%%time\nvalid_pred = logit.predict(X_valid)","27701362":"accuracy_score(y_valid, valid_pred)","d3c3bd87":"## <center> Assignment 4 (demo)\n### <center>  Sarcasm detection with logistic regression\n    \n**Same assignment as a [Kaggle Kernel](https:\/\/www.kaggle.com\/kashnitsky\/a4-demo-sarcasm-detection-with-logit) + [solution](https:\/\/www.kaggle.com\/kashnitsky\/a4-demo-sarcasm-detection-with-logit-solution).**\n\n\nWe'll be using the dataset from the [paper](https:\/\/arxiv.org\/abs\/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https:\/\/www.kaggle.com\/danofer\/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https:\/\/habrastorage.org\/webt\/1f\/0d\/ta\/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" \/>","0fac6b97":"Some comments are missing, so we drop the corresponding rows.","9828c6c4":"## 2.1 Engineering our features","1b1c6cb8":"We notice that the dataset is indeed balanced","a2e8a083":"We will be using logistic regression with bag of words so lets find out the most used n-grams in this set.","8e2d0927":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words\/bigrams which a most predictive of sarcasm (you can use [eli5](https:\/\/github.com\/TeamHG-Memex\/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n","243d5066":"We split data into training and validation parts.","5c5d3c7e":"**Now lets find if comment upvotes, downvotes and scores show any reaction to sarcasm in comments.**","730d7cae":"**We can see that if score is negative the post is more inclined to have sarcastic content, hence we leave it as our feature**","01a3fb7b":"Lets draw a wordcloud with the most used words.","15a7db04":"## 2.2 Training the model","0f009b8a":"\n## [mlcourse.ai](https:\/\/mlcourse.ai) - Open Machine Learning Course\n\nAuthor: [Yury Kashnitsky](https:\/\/www.linkedin.com\/in\/festline\/). All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license."}}