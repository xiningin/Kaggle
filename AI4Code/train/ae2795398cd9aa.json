{"cell_type":{"5147a2b9":"code","8f029c9d":"code","c5abd682":"code","74f7bfc8":"code","6a71fdd6":"code","6ebc897d":"code","66cc6935":"code","ee3034e7":"code","97e92c77":"code","a92e3687":"code","c410cf24":"code","d5840582":"code","9c94759b":"code","6234324c":"code","84beeb30":"code","67133b87":"code","9af74456":"code","adc2d643":"code","f4f79420":"code","26ad057b":"code","76a0ecf9":"code","da20fd12":"code","2b8ffb24":"code","37824a2e":"code","ef6e40bb":"code","1cd407ea":"code","7d5c6d51":"code","76a8e81e":"code","c1ffc9b6":"code","acd1c97c":"code","752a154a":"code","72fb1ce8":"code","2860cd38":"code","01f2ef3a":"code","a36e1801":"code","c85e56fd":"code","a62c090b":"code","2a852103":"code","07d091d3":"code","c4707088":"code","ee5ef2e0":"code","36de0a8a":"code","0f11c159":"code","9a1d68fd":"code","80676884":"code","469484d7":"markdown","05eda77f":"markdown","e53f4da2":"markdown","e3322906":"markdown","5c1e5b9b":"markdown","98ad1468":"markdown","b27cb51b":"markdown","1f72b7d1":"markdown","b607d311":"markdown","615935e1":"markdown","d1551835":"markdown","2dec2af0":"markdown","9aa30c20":"markdown","378d3e41":"markdown","87f02aee":"markdown","905eff05":"markdown","cc4462d6":"markdown"},"source":{"5147a2b9":"\n!pip install pandarallel\n\nimport pandas as pd\nimport pandarallel\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport mplleaflet\nfrom collections import Counter\n\nimport json\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedKFold\nfrom tensorflow import keras\n\nfrom mlxtend.regressor import StackingRegressor\n\npandarallel.pandarallel.initialize(progress_bar=True)\n\nsns.set_style('darkgrid')\nsns.set_palette('deep')\n\nnp.random.seed(15)","8f029c9d":"train = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/train.csv')\ntest = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/test.csv')\nsample = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/sample_submission.csv')\nwith open('..\/input\/bigquery-geotab-intersection-congestion\/submission_metric_map.json') as f:\n    submission_metric_map = json.load(f)","c5abd682":"time_features = ['Hour', 'Month', 'Weekend']","74f7bfc8":"fig, axes = plt.subplots(2,1, figsize=[15,10])\n\nsns.countplot(data=train[train['Weekend']==0], hue='City', x='Hour', ax=axes[0],);\nsns.countplot(data=train[train['Weekend']==1], hue='City', x='Hour', ax=axes[1]);\naxes[0].legend([])\naxes[1].legend(loc=[-0.2,0.7])\naxes[0].set_title(\"Weekdays\")\naxes[1].set_title(\"Weekends\")\nfig.set_dpi(500)","6a71fdd6":"sns.countplot(x='Month', hue='City', data=train)","6ebc897d":"street_features = ['EntryStreetName', 'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Path']","66cc6935":"train.drop('Path', axis=1, inplace=True)\ntest.drop('Path', axis=1, inplace=True)","ee3034e7":"directions = {\n    'N': 0,\n    'NE': 1\/4,\n    'E': 1\/2,\n    'SE': 3\/4,\n    'S': 1,\n    'SW': 5\/4,\n    'W': 3\/2,\n    'NW': 7\/4\n}","97e92c77":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)","a92e3687":"test['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","c410cf24":"train['diffHeading'] = (train['ExitHeading']-train['EntryHeading'])\ntest['diffHeading'] = (test['ExitHeading']-test['EntryHeading'])","d5840582":"word_count = Counter()\nfor name in train['EntryStreetName']:\n    if pd.isna(name):\n        continue\n    for word in name.split():\n        word_count[word]+=1\n        \nfor name in train['ExitStreetName']:\n    if pd.isna(name):\n        continue\n    for word in name.split():\n        word_count[word]+=1","9c94759b":"sorted(word_count.items(),key=lambda item: item[1], reverse=True)[:20]","6234324c":"road_encoding = {\n    'Street': 0,\n    'St': 0,\n    'Avenue': 1,\n    'Ave': 1,\n    'Boulevard': 2,\n    'Road': 3,\n    'Drive': 4,\n    'Lane': 5,\n    'Tunnel': 6,\n    'Highway': 7,\n    'Way': 8,\n    'Parkway': 9,\n    'Parking': 9,\n    'Oval': 10,\n    'Square': 11,\n    'Place': 12,\n    'Bridge': 13,\n    'Unknown': 14\n}","84beeb30":"def encode(x):\n    if pd.isna(x):\n        return road_encoding['Unknown']\n    for road in road_encoding.keys():\n        if road in x:\n            return road_encoding[road]\n        \n    return road_encoding['Unknown']","67133b87":"train['EntryType'] = train['EntryStreetName'].parallel_apply(encode)\ntrain['ExitType'] = train['ExitStreetName'].parallel_apply(encode)\ntest['EntryType'] = test['EntryStreetName'].parallel_apply(encode)\ntest['ExitType'] = test['ExitStreetName'].parallel_apply(encode)","9af74456":"train['EqualStreets'] = (train['EntryStreetName']==train['ExitStreetName'])\ntest['EqualStreets'] = (test['EntryStreetName']==test['ExitStreetName'])","adc2d643":"plt.figure(figsize=[10,10])\ntmp = train[train['City']=='Boston'].groupby(['Latitude', 'Longitude'])['RowId'].count().reset_index()\nsns.kdeplot(tmp['Longitude'], tmp['Latitude'])\n\nmplleaflet.display()","f4f79420":"cities = train['City'].unique()\nscalers_lat = {}\nscalers_lon = {}\nfor city in cities:\n    latitudes = np.array(train[train['City']==city]['Latitude']).reshape(-1,1)\n    longitudes = np.array(train[train['City']==city]['Longitude']).reshape(-1,1)\n    scalers_lat[city] = StandardScaler().fit(latitudes)\n    scalers_lon[city] = StandardScaler().fit(longitudes)","26ad057b":"train['Latitude'] = train.parallel_apply(lambda row: scalers_lat[row['City']].transform(np.array(row['Latitude']).reshape(1,1)), axis=1)","76a0ecf9":"train['Longitude'] = train.parallel_apply(lambda row: scalers_lon[row['City']].transform(np.array(row['Longitude']).reshape(1,1)), axis=1)","da20fd12":"test['Latitude'] = test.parallel_apply(lambda row: scalers_lat[row['City']].transform(np.array(row['Latitude']).reshape(1,1)), axis=1)","2b8ffb24":"test['Longitude'] = test.parallel_apply(lambda row: scalers_lon[row['City']].transform(np.array(row['Longitude']).reshape(1,1)), axis=1)","37824a2e":"sns.kdeplot(train['Longitude'])","ef6e40bb":"new_train_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'DistanceToFirstStop',\n       'Month', 'TotalTimeStopped', 'Percentile', 'City', 'diffHeading', 'EntryType', 'ExitType', 'EqualStreets']","1cd407ea":"new_test_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend',\n       'Month', 'Percentile', 'City', 'diffHeading', 'EntryType', 'ExitType', 'EqualStreets']","7d5c6d51":"new_train = pd.DataFrame(columns=new_train_columns)","76a8e81e":"new_test = pd.DataFrame(columns=new_test_columns)","c1ffc9b6":"for per in [20, 40, 50, 60, 80]:\n    new_df = train.copy()\n    new_df['TotalTimeStopped'] = new_df['TotalTimeStopped_p'+str(per)]\n    new_df['DistanceToFirstStop'] = new_df['DistanceToFirstStop_p'+str(per)]\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_df.drop(['TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80', 'RowId'], axis=1,inplace=True)\n    new_train = pd.concat([new_train, new_df], sort=True)","acd1c97c":"for per in [20, 50, 80]:\n    new_df = test.copy()\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_test = pd.concat([new_test, new_df], sort=True)","752a154a":"new_train = pd.concat([new_train.drop('City', axis=1), pd.get_dummies(new_train['City'])], axis=1)","72fb1ce8":"new_test = pd.concat([new_test.drop('City', axis=1), pd.get_dummies(new_test['City'])], axis=1)","2860cd38":"new_train = new_train.reindex(sorted(new_train.columns), axis=1)\nnew_test = new_test.reindex(sorted(new_test.columns), axis=1)","01f2ef3a":"new_test = new_test.sort_values(by=['RowId', 'Percentile'])","a36e1801":"X_train = np.array(new_train.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', \n                                   'TotalTimeStopped', 'DistanceToFirstStop'], axis=1), dtype=np.float32)\nX_test = np.array(new_test.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', \n                                 'RowId'], axis=1), dtype=np.float32)","c85e56fd":"y_train = np.array(new_train[['TotalTimeStopped', 'DistanceToFirstStop']], dtype=np.float32)","a62c090b":"from tensorflow.keras import backend as K\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean((y_true-y_pred)**2))","2a852103":"def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=45)(x)\n    act1 = keras.layers.PReLU()(fc1)\n    bn1 = keras.layers.BatchNormalization()(act1)\n    dp1 = keras.layers.Dropout(0.15)(bn1)\n    concat1 = keras.layers.Concatenate()([x, dp1])\n    fc2 = keras.layers.Dense(units=60)(concat1)\n    act2 = keras.layers.PReLU()(fc2)\n    bn2 = keras.layers.BatchNormalization()(act2)\n    dp2 = keras.layers.Dropout(0.2)(bn2)\n    concat2 = keras.layers.Concatenate()([concat1, dp2])\n    fc3 = keras.layers.Dense(units=40)(concat2)\n    act3 = keras.layers.PReLU()(fc3)\n    bn3 = keras.layers.BatchNormalization()(act3)\n    dp3 = keras.layers.Dropout(0.2)(bn3)\n    concat3 = keras.layers.Concatenate([concat2, dp3])\n    output = keras.layers.Dense(units=2, activation='softmax')(concat2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model\n\ndef train_model(X_train, y_train, X_val, y_val):\n    model = get_model()\n    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss='mse', metrics=[rmse])\n    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n    return model","07d091d3":"rkf = RepeatedKFold(n_splits=5, n_repeats=5)\n\nmodels = []\n\nfor tr_idx, vl_idx in rkf.split(X_train, y_train):\n    \n    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n    \n    model = train_model(x_tr, y_tr, x_vl, y_vl)\n    models.append(model)","c4707088":"y_pred = np.mean([model.predict(X_test) for model in models], axis=1)","ee5ef2e0":"l = []\nfor i in range(1920335):\n    for j in [0,3,1,4,2,5]:\n        l.append(str(i)+'_'+str(j))\nsample['TargetId'] = l","36de0a8a":"sample['Target'] = y_pred.reshape(-1)","0f11c159":"sample['temp_1'] = sample['TargetId'].parallel_apply(lambda x : int(x.split('_')[0]))\nsample['temp_2'] = sample['TargetId'].parallel_apply(lambda x : int(x.split('_')[1]))\nsample = sample.sort_values(by=['temp_1', 'temp_2'])\ndel sample['temp_1']\ndel sample['temp_2']","9a1d68fd":"sample.to_csv('sample_submission.csv', index=False)","80676884":"submission_metric_map","469484d7":"### Looking at street names","05eda77f":"## Baseline model\n<a id='baseline'><\/a>","e53f4da2":"## Imports and initial exploration\n<a id='imports'><\/a>","e3322906":"### Latitude and Longitude\n<a id='latlon'><\/a>","5c1e5b9b":"### Time features\n<a id='hmw'><\/a>","98ad1468":"We can see clearly path is just a concatenation of the other features, so we can just drop it","b27cb51b":"### Exploring street features\n<a id='streetfeatures'><\/a>","1f72b7d1":"## Exploratory Data Analysis\n<a id='eda'><\/a>","b607d311":"Let's create a new dataframe with the new following features: TotaTimeStopped, DistanceToFirstStop and Percentile.\n\nCreating a dataframe in the following way can enable us to use the percentile as a feature and can help us boost the model","615935e1":"a) Street (for any thoroughfare) \n\nb) Road (for any thoroughfare) \n\nc) Way (for major roads - also appropriate for pedestrian routes) \n\nd) Avenue (for residential roads) \n\ne) Drive (for residential roads) \n\nf) Grove (for residential roads) \n\ng) Lane (for residential roads) \n\nh) Gardens (for residential roads) subject to there being no confusion with any local open space \n\ni) Place (for residential roads) \n\nj) Crescent (for a crescent shaped road) \n\nk) Court\/Close (for a cul-de-sac only) \n\nl) Square (for a square only) \n\nm) Hill (for a hillside road only) \n\nn) Circus (for a large roundabout) \n\no) Vale (for residential roads) \n\np) Rise (for residential roads) \n\nq) Row (for residential roads) \n\nr) Wharf (for residential roads) \n\ns) Mews (for residential roads) \n\nt) Mead (for residential roads) \n\nu) Meadow (for residential roads)","d1551835":"The cardinal directions can be expressed using the following equation:\n$$\n\\frac{\\theta}{\\pi}\n$$\nWhere $\\theta$ is the angle between the we want to encode direction and the north direction measured clockwise","2dec2af0":"We\u2019ve all been there: Stuck at a traffic light, only to be given mere seconds to pass through an intersection, behind a parade of other commuters. Imagine if you could help city planners and governments anticipate traffic hot spots ahead of time and reduce the stop-and-go stress of millions of commuters like you.","9aa30c20":"We all know there is probably a high correlation between the time features and the  values we want to predict, let's visualize this interaction","378d3e41":"# Table of contents\n- [Imports and initial exploration](#imports)\n\n- [Exploratory Data Analysis](#eda)\n    - [Time features](#hmw)\n    - [Exploring street features](#streetfeatures)\n    - [Latitude and Longitude](#latlon)\n    \n- [Preprocessing](#prepro)\n\n- [Baseline model](#baseline)","87f02aee":"Let's use the following road types: Street, Avenue, Road, Boulevard, Broad and Drive\n\nAfter searching on the <a href='https:\/\/360.here.com\/2016\/12\/30\/whats-the-difference-between-a-road-a-street-and-an-avenue\/'>internet<\/a> their differences, I found that Avenue and Street are basically the same thing.","905eff05":"## Preprocessing\n<a id='prepro'><\/a>","cc4462d6":"# BigQuery-Geotab Intersection Congestion"}}