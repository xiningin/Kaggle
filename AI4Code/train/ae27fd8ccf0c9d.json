{"cell_type":{"cb46e31d":"code","af126fd1":"code","27e8f3e3":"code","27d6aab9":"code","d557c2a2":"code","ff96dd76":"code","767e39b1":"code","0b39e3f5":"code","a7e2974d":"code","23495608":"code","558b1900":"code","805b9ecb":"code","7eec359b":"code","9ce192bd":"code","6917e0a1":"code","13876971":"code","b378f0f5":"code","cbfa0618":"code","7e2eb2e5":"code","a711389b":"code","5324a01c":"code","024211bb":"code","202ea2cf":"code","75d513e2":"code","12385d30":"code","e7fad71f":"code","2492b9d8":"code","87587d57":"code","e5abc70f":"code","3127c2b0":"markdown","d92d6425":"markdown","2323c372":"markdown","405a0086":"markdown","af859784":"markdown","4148c411":"markdown","d4f1b778":"markdown","10defe9d":"markdown","21681804":"markdown","20c77e28":"markdown","25b2ae3f":"markdown","dc90e4c0":"markdown","f184ffe2":"markdown","51146ac0":"markdown","e4fe8764":"markdown","6a72affa":"markdown","a25831bf":"markdown","b2b5cd62":"markdown","185fc671":"markdown","f9321d87":"markdown","011c28d3":"markdown","fe49a53a":"markdown","567eb498":"markdown"},"source":{"cb46e31d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nimport pandas_profiling\n%matplotlib inline\n\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\nimport sklearn.metrics as metrics\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","af126fd1":"# Path to the dataset\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","27e8f3e3":"%%time\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')\norg_len = len(train.drop('id',axis=1))","27d6aab9":"train.head()","d557c2a2":"test.head()","ff96dd76":"print(\"Train data set dtypes: \\n\")\nprint(f\"Shape : {train.shape}\")\nprint(f\"{train.dtypes.value_counts()}\")\n\nprint('*'*30)\n\nprint(\"Test data set dtypes: \\n\")\nprint(f\"Shape : {test.shape}\")\nprint(f\"{test.dtypes.value_counts()}\")","767e39b1":"# Gives a details on Count number of non-NA\/null observations, Maximum and Minimum of the values in the object, Mean and Standard Deviation of the Values\ntrain.describe()","0b39e3f5":"profile = pandas_profiling.ProfileReport(train,minimal=True)\nprofile.to_file(output_file=\"output.html\")\nprofile","a7e2974d":"train_cont = train.drop('id',axis=1)","23495608":"fig = plt.figure(figsize=(18,16))\n\nfor index,col in enumerate(train_cont):\n    plt.subplot(5,3,index+1)\n    sns.distplot(train_cont.loc[:,col], kde=False)\nfig.tight_layout(pad=1.0)","558b1900":"    for c in train_cont.columns:\n        fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n        sns.boxplot(y=c, data=train_cont, ax=axs[0]) # 1\n\n        sns.violinplot(y=c, data=train_cont, ax=axs[1]) # 2\n\n        sns.stripplot(y=c, data=train_cont, size=4, color=\".3\", linewidth=0, ax=axs[2]) # 3\n\n\n        fig.suptitle(c, fontsize=15, y=1.1)\n        axs[0].set_title('Box Plot')\n        axs[1].set_title('Violin Plot')\n        axs[2].set_title('Strip Plot')\n\n        plt.tight_layout()\n        plt.show()","805b9ecb":"fig = plt.figure(figsize=(18,16))\ntrain_cont = train.drop('id',axis=1)\nfor index,col in enumerate(train_cont):\n    plt.subplot(5,3,index+1)\n    sns.scatterplot(x=train_cont.iloc[:,index], y=train['target'],alpha=0.5)\nfig.tight_layout(pad=1.0)","7eec359b":"plt.figure(figsize=(16,12))\ncorr = train_cont.corr()\nsns.heatmap(corr,cmap='Blues',linewidth=0.5,annot=True)","9ce192bd":"train_cont['new'] = train_cont['cont2']*train_cont['cont3']*train_cont['cont6']*train_cont['cont7']*train_cont['cont11']*train_cont['cont12']\ntest['new'] = test['cont2']*test['cont3']*test['cont6']*test['cont7']*test['cont11']*test['cont12']","6917e0a1":"train_cont['new1'] = train_cont['cont9']*train_cont['cont10']*train_cont['cont1']\ntest['new1'] = test['cont9']*test['cont10']*test['cont1']","13876971":"features = train_cont.drop('target',axis=1).columns\ntrain_cont['mean'] = train_cont[features].mean(axis=1)\ntest['mean'] = test[features].mean(axis=1)","b378f0f5":"# removing outlier in lower region\nlow_cont = ['target', 'cont10', 'cont9', 'cont7']\n# removing outlier in upper region\nup_cont = ['cont10']\nn999 = [ np.percentile(train_cont[i],99.9) for i in train_cont[up_cont]]\nn001 = [ np.percentile(train_cont[i],0.1) for i in train_cont[low_cont]]","cbfa0618":"import gc\nfor i, j in enumerate(low_cont):\n    train_cont = train_cont[train_cont[j] > n001[i]]\n    gc.collect()\nfor i, j in enumerate(up_cont):\n    train_cont = train_cont[train_cont[j] < n999[i]]\n    gc.collect()","7e2eb2e5":"    for c in train_cont.columns:\n        fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n        sns.boxplot(y=c, data=train_cont, ax=axs[0]) # 1\n        sns.stripplot(y=c, data=train_cont, size=4, color=\".3\", linewidth=0, ax=axs[1]) # 2\n\n\n        fig.suptitle(c, fontsize=15, y=1.1)\n        axs[0].set_title('Box Plot')\n        axs[1].set_title('Strip Plot')\n\n        plt.tight_layout()\n        plt.show()","a711389b":"str(round(((org_len - len(train_cont))\/org_len)*100,2))+'%'","5324a01c":"X_train = train_cont.drop('target',axis=1)\ny_train = train_cont['target']","024211bb":"import optuna\nfrom sklearn.model_selection  import KFold\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 350, 1000),\n        'max_depth': trial.suggest_int('max_depth', 6, 13),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.009, 0.10),\n        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n        'gamma': trial.suggest_int('gamma', 0, 0.05),\n        'objective':'reg:squarederror',\n        'eval_metric' : 'rmse',\n        'tree_method':'gpu_hist',\n       }\n        \n    clf = xgb.XGBRegressor(**params)\n    rmse_scores = []\n    X_train_k = X_train.values\n    y_train_k = y_train.values\n    skf = KFold(n_splits=3,shuffle=True)\n    for train_idx, valid_idx in skf.split(X_train_k,y_train_k):\n        train_data = X_train_k[train_idx, :], y_train_k[train_idx]\n        valid_data = X_train_k[valid_idx, :], y_train_k[valid_idx]\n        \n        clf.fit(X_train_k[train_idx, :], y_train_k[train_idx])\n        pred = clf.predict(X_train_k[valid_idx, :])\n        rmse = np.sqrt(mean_squared_error(y_train_k[valid_idx],pred))\n        rmse_scores.append(rmse)\n    print(f'Trial done: Accuracy values on folds: {rmse_scores}')\n    return np.average(rmse_scores)","202ea2cf":"#  Just for lesser time I've used less trials,Please do increase the trials \nn_trials = 5\n\nFIT_XGB = True\n\nif FIT_XGB:\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","75d513e2":"optuna.visualization.plot_slice(study)","12385d30":"#best_param = study.best_params\nbest_param = {'n_estimators': 751, 'max_depth': 10, \n              'learning_rate': 0.019789645280696613, \n              'subsample': 0.8730019407814834, \n              'colsample_bytree': 0.6012295369579667,'gamma':0}\nbest_param['objective'] ='reg:squarederror'\nbest_param['tree_method'] ='gpu_hist'\nbest_param['eval_metric'] ='rmse'","e7fad71f":"model = xgb.XGBRegressor(**best_param)\nmodel.fit(X_train,y_train)","2492b9d8":"xgb.plot_importance(model)","87587d57":"predictions_final = model.predict(test.drop('id',axis=1))","e5abc70f":"submission = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"target\":predictions_final\n    })\nsubmission.to_csv('my_submission.csv', index=False)","3127c2b0":"Heatmap","d92d6425":"**We'll be using XGBRegressor**","2323c372":"### **Removing Outliers** ","405a0086":"# Understanding Data","af859784":"**Few Outliers in target, cont10, cont9, cont7** <br>\n**Cont2 have some regular interval gaps**<br>\n**Cont5 is dominated with lesser value**","4148c411":"No good correlation with target column \ud83d\udc40","d4f1b778":"### No Missing Values\n**As we can see above the count of no_null values are equal to the len of columns (300000)**","10defe9d":"# Loading Data\n","21681804":"# Importing Libraries ","20c77e28":"# Univariate Analysis\n**We will usually use Distribution plot to visualize their data distribution for continuous Values**","25b2ae3f":"### **Feature Engineering**\n\n**Tried some randomn combinations**","dc90e4c0":"Scatterplot with the target","f184ffe2":"# Pandas Profiling \ud83d\udc3c \n**pandas_profiling extends the pandas DataFrame for quick data analysis.**","51146ac0":"# Submission","e4fe8764":"# Bi-variate Analysis","6a72affa":"# Data Processing ","a25831bf":"### Model Importance ","b2b5cd62":"# Tuning","185fc671":"# Modelling ","f9321d87":"**Percentage of data removed**","011c28d3":"# If you liked it. Please do upvote \u270c\u2714\ud83d\ude3a","fe49a53a":"**After removing outlier**","567eb498":"## Fitting"}}