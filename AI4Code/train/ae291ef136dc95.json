{"cell_type":{"55c57455":"code","bfd06239":"code","591e63a4":"code","5b16c302":"code","76a1d584":"code","8cbd19a4":"code","f779184e":"code","1d6d5617":"code","ca06d460":"code","db05a849":"code","77051f25":"code","9fad59c1":"code","6c309de8":"code","6911e472":"code","bfe5c2d2":"code","1232173e":"code","a3a3c712":"code","11b16f43":"code","fd4bd7e2":"code","f0e1a73b":"code","704ed4a0":"code","6c75cfaf":"code","a62fac91":"code","e4d1971a":"code","c3864028":"code","9dba1813":"code","fd5a56d6":"code","6b41ae60":"markdown","9fa97178":"markdown","de03261a":"markdown","b5c6569e":"markdown","c571efbd":"markdown","a597673e":"markdown","55fe834c":"markdown","19dc6de9":"markdown","4f80c059":"markdown","f35da605":"markdown","0c5d402c":"markdown"},"source":{"55c57455":"# \uc2dc\ud5d8\ud658\uacbd \uc138\ud305 (\ucf54\ub4dc \ubcc0\uacbd X)\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndef exam_data_load(df, target, id_name=\"\", null_name=\"\"):\n    if id_name == \"\":\n        df = df.reset_index().rename(columns={\"index\": \"id\"})\n        id_name = 'id'\n    else:\n        id_name = id_name\n    \n    if null_name != \"\":\n        df[df == null_name] = np.nan\n    \n    X_train, X_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=2021)\n    y_train = X_train[[id_name, target]]\n    X_train = X_train.drop(columns=[id_name, target])\n    y_test = X_test[[id_name, target]]\n    X_test = X_test.drop(columns=[id_name, target])\n    return X_train, X_test, y_train, y_test \n    \ndf = pd.read_csv(\"..\/input\/adult-census-income\/adult.csv\")\nX_train, X_test, y_train, y_test = exam_data_load(df, target='income', null_name='?')\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","bfd06239":"# \uc2dc\ud5d8\ud658\uacbd\uc5d0\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc81c\uacf5\ub428\n# import pandas as pd\n# X_test = pd.read_csv(\"data\/X_test.csv\")\n# X_train = pd.read_csv(\"data\/X_train.csv\")\n# y_train = pd.read_csv(\"data\/y_train.csv\")","591e63a4":"import pandas as pd\nimport numpy as np","5b16c302":"# \ub370\uc774\ud130 \ud06c\uae30 \ud655\uc778","76a1d584":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","8cbd19a4":"# \ub370\uc774\ud130 \ud655\uc778","f779184e":"X_train.head()","1d6d5617":"# \ud0c0\uac9f \uc218 \ud655\uc778","ca06d460":"y_train['income'].value_counts() # \ud56d\ubaa9\ubcc4 \uac1c\uc218","db05a849":"# type\ud655\uc778","77051f25":"X_train.info()","9fad59c1":"# \ud53c\ucc98 \uad6c\ubd84\n# Numeric features # \uc22b\uc790 \ubcc0\uc218?\nnumeric_features = [\n                    'age',\n                    'fnlwgt', \n                    'education.num',\n                    'capital.gain', \n                    'capital.loss', \n                    'hours.per.week',                     \n                   ]\n\n# Categorical features # \uad6c\ubd84 \ubcc0\uc218?\ncat_features = [\n                 'workclass',              \n                 'education',            \n                 'marital.status', \n                 'occupation', \n                 'relationship', \n                 'race', \n                 'sex',\n                 'native.country'\n]","6c309de8":"X_train[numeric_features].describe()","6911e472":"X_train[cat_features].describe()","bfe5c2d2":"X_train.isnull().sum() #\uacb0\uce21\uac12\uc758 \uac1c\uc218 \uad6c\ud558\uae30","1232173e":"X_test.isnull().sum() #\uacb0\uce21\uac12\uc758 \uac1c\uc218 \uad6c\ud558\uae30","a3a3c712":"X_train['workclass'].value_counts() # ['workclass'] \ucd1d\uac1c\uc218","11b16f43":"X_train['occupation'].value_counts() # ['occupaton'] \ucd1d\uac1c\uc218","fd4bd7e2":"X_train['native.country'].value_counts() # ['native.country'] \ucd1d\uac1c\uc218","f0e1a73b":"def data_fillna(df):\n    df['workclass'] = df['workclass'].fillna(df['workclass'].mode()[0])\n    df['occupation'] = df['occupation'].fillna(\"null\")\n    df['native.country'] = df[\"native.country\"].fillna(df['native.country'].mode()[0])\n    return df\n\nX_train = data_fillna(X_train)\nX_test = data_fillna(X_test)\n\nX_train.isnull().sum()","704ed4a0":"# \ub77c\ubca8\uc778\ucf54\ub529 # \ubc94\uc8fc\ud615 \ubcc0\uc218\ub97c \uc218\uce58\ud615 \ubcc0\uc218\ub85c \ubcc0\uacbd \nfrom sklearn.preprocessing import LabelEncoder\n\nall_df = pd.concat([X_train.assign(ind=\"train\"), X_test.assign(ind=\"test\")])\nle = LabelEncoder()\nall_df[cat_features] = all_df[cat_features].apply(le.fit_transform)\n\nX_train = all_df[all_df['ind'] == 'train']\nX_train = X_train.drop('ind',axis=1)\nX_train\n\nX_test = all_df[all_df['ind'] == 'test']\nX_test = X_test.drop('ind',axis=1)\nX_test","6c75cfaf":"# \uc2a4\ucf00\uc77c\ub9c1\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\nX_test[numeric_features] = scaler.transform(X_test[numeric_features])\nX_train","a62fac91":"# target\uac12 \ubcc0\uacbd\ny = (y_train['income'] != '<=50K').astype(int)\ny[:5]","e4d1971a":"# \ud559\uc2b5\uc6a9 \ub370\uc774\ud130\uc640 \uac80\uc99d\uc6a9 \ub370\uc774\ud130\ub85c \uad6c\ubd84\nfrom sklearn.model_selection import train_test_split\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y, test_size=0.15, random_state=2021)\nX_tr.shape, X_val.shape, y_tr.shape, y_val.shape","c3864028":"from sklearn.tree import DecisionTreeClassifier # \uc758\uc0ac\uacb0\uc815\ud2b8\ub9ac\nfrom sklearn.metrics import accuracy_score\n\nmodel = DecisionTreeClassifier(random_state = 2022)\nmodel.fit(X_tr, y_tr)\npred = model.predict(X_val)\nprint('accuracy score:', (accuracy_score(y_val, pred)))","9dba1813":"from sklearn.ensemble import RandomForestClassifier # \ub79c\ub358 \ud3ec\ub808\uc2a4\ud2b8\n\nmodel = RandomForestClassifier(random_state = 2022)\nmodel.fit(X_tr, y_tr)\npred = model.predict(X_val)\nprint('accuracy score:', (accuracy_score(y_val, pred)))","fd5a56d6":"y_test = (y_test['income'] != '<=50K').astype(int)\npred = model.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint('accuracy score:', (accuracy_score(y_test, pred)))","6b41ae60":"## \ucc44\uc810 (\uc218\ud5d8\uc790\ub294 \ud655\uc778 \ubd88\uac00)","9fa97178":"## \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30","de03261a":"## \uac80\uc99d\uc6a9 \ub370\uc774\ud130 \ubd84\ub9ac","b5c6569e":"## \ubaa8\ub378 & \ud3c9\uac00","c571efbd":"## \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(\uc0dd\ub7b5)","a597673e":"## \uacb0\uce21\uce58 \ucc98\ub9ac","55fe834c":"## \ud53c\ucc98\uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\n##### https:\/\/teddylee777.github.io\/scikit-learn\/labelencoder-%EC%82%AC%EC%9A%A9%EB%B2%95","19dc6de9":"- \uacb0\uce21\uce58\ub294 \ucd5c\ube48\uac12\uacfc \ucc28\uc774\uac00 \ud06c\uba74 \ucd5c\ube48\uac12\uc73c\ub85c \uac12\uc774 \ube44\uc2b7\ud558\uba74 \ubcc4\ub3c4\uc758 \uac12\uc73c\ub85c \ub300\uccb4\ud568","4f80c059":"## EDA","f35da605":"# \uc131\uc778 \uc778\uad6c\uc870\uc0ac \uc18c\ub4dd \uc608\uce21\n\n- age: \ub098\uc774\n- workclass: \uace0\uc6a9 \ud615\ud0dc\n- fnlwgt: \uc0ac\ub78c\uc758 \ub300\ud45c\uc131\uc744 \ub098\ud0c0\ub0b4\ub294 \uac00\uc911\uce58(final weight)\n- education: \uad50\uc721 \uc218\uc900\n- education.num: \uad50\uc721 \uc218\uc900 \uc218\uce58\n- marital.status: \uacb0\ud63c \uc0c1\ud0dc\n- occupation: \uc5c5\uc885\n- relationship: \uac00\uc871 \uad00\uacc4\n- race: \uc778\uc885\n- sex: \uc131\ubcc4\n- capital.gain: \uc591\ub3c4 \uc18c\ub4dd\n- capital.loss: \uc591\ub3c4 \uc190\uc2e4\n- hours.per.week: \uc8fc\ub2f9 \uadfc\ubb34 \uc2dc\uac04\n- native.country: \uad6d\uc801\n- income: \uc218\uc775 (\uc608\uce21\ud574\uc57c \ud558\ub294 \uac12)","0c5d402c":"# \uc0ac\uc6a9\uc790 \ucf54\ub529"}}