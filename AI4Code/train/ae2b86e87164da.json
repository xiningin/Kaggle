{"cell_type":{"f7f55bf0":"code","63d75d20":"code","e0caf1f9":"code","4f4ee21e":"code","1c482a92":"code","886e50fa":"code","5aa5cae3":"code","06d1498c":"code","ef71e341":"code","27b147b0":"code","149c52a6":"code","0c3a956c":"code","b1fa18b6":"code","c9347f82":"code","99e0b481":"code","d5054df2":"code","91a29789":"code","03cc1051":"code","64880428":"code","a6eeda21":"code","069475fb":"code","38d7f95a":"code","8072cef8":"code","2c59b624":"code","fb2a5479":"code","9a3336fc":"code","2e113b09":"code","3ec07435":"code","8ab139e7":"code","985d1f55":"code","72f734a8":"code","fdf779da":"code","06ebb8df":"code","664f591b":"code","451df952":"code","2e074bb1":"code","f3d01cda":"code","1336fe61":"code","746691f0":"code","1a63aaa1":"code","d2e013f6":"code","06cdadf3":"code","750f0d2f":"code","976a085c":"code","59411e0e":"code","6afebf93":"code","b1144c43":"code","ed478b1b":"code","259e8db1":"code","e7693083":"code","2c1bdc7f":"code","71755341":"code","8770107c":"code","d2f2814e":"markdown","0f4fe424":"markdown","cc3aa35c":"markdown","c5bca292":"markdown","f2d8f3a7":"markdown","c564f528":"markdown","a7cddf80":"markdown","a90e44e7":"markdown","4b794cc8":"markdown","54437fb3":"markdown","c946c91c":"markdown","943a300f":"markdown","c2754d23":"markdown","86ad0f7d":"markdown","b066ec64":"markdown","731154bc":"markdown"},"source":{"f7f55bf0":"import os\nimport warnings\nimport pandas as pd \nimport numpy as np\n\ndatos=pd.read_csv(\"..\/input\/competicin-bootcamp\/train.csv\");\ntest_set=pd.read_csv(\"..\/input\/competicin-bootcamp\/test.csv\");\nwarnings.filterwarnings(\"ignore\")","63d75d20":"print(\"Dataset: Filas, Columnas\",datos.shape)","e0caf1f9":"resumen= datos.describe()\nresumen = resumen.transpose()\nresumen.head(5)","4f4ee21e":"datos.info()","1c482a92":"pd.set_option('display.max_columns',None)\ndatos.head()","886e50fa":"#Cargamos librer\u00edas de visualizaci\u00f3n matplotlib\nimport matplotlib.pyplot as plt","5aa5cae3":"datos.select_dtypes('float').columns","06d1498c":"datos.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(color = 'orange', figsize = (10, 6),edgecolor = 'k', linewidth = 2);\nplt.xlabel('N\u00famero de valores \u00fanicos'); plt.ylabel('N\u00famero');\nplt.title('Columnas Int64');","ef71e341":"datos.select_dtypes('float').head()","27b147b0":"datos.select_dtypes('object').head()","149c52a6":"#Distribuci\u00f3n de la variable clase\ndistribucion = datos['Target'].value_counts().sort_index()\n\nfrom collections import OrderedDict\n\n#Usaremos un OrderedDict para mapear los niveles de pobreza a colores porque mantiene las claves y valores en el mismo orden que especificamos (a diferencia de un diccionario de Python normal).\ncolores = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\nniveles = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\ndistribucion.plot.bar(figsize = (8, 6), \n                      color = colores.values(),\n                      edgecolor = 'k', linewidth = 2)\n\nplt.xlabel('Niveles de pobreza'); \nplt.ylabel('N\u00famero'); \nplt.xticks([x - 1 for x in niveles.keys()], \n           list(niveles.values()), rotation = 0)\n\nplt.title('Distribuci\u00f3n de las muestras con Matplotlib');","0c3a956c":"#Cargamos las librer\u00edas de plotly\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport plotly.figure_factory as ff\n\n#Necesario para que se vean las gr\u00e1ficas con plotly\ninit_notebook_mode(connected=True) ","b1fa18b6":"trace = go.Bar(y=list(distribucion), x=list(niveles.values()), marker=dict(color=list(colores.values()), opacity=0.6))\nlayout = dict(title=\"Distribuci\u00f3n de las muestras con plotly\", xaxis=dict(\n        title='Niveles de pobreza'), yaxis=dict(title='N\u00famero'), margin=dict(l=200), width=800, height=400)\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","c9347f82":"#Cargamos las librer\u00edas para bokeh\nfrom bokeh.plotting import figure, output_file, show\nfrom bokeh.io import output_file,show,output_notebook,push_notebook\n\n#Necesario para que se vean las gr\u00e1ficas con bokeh\noutput_notebook()  ","99e0b481":"#Ejemplo de gr\u00e1fica con Bokeh\nobjetivo=list(niveles.values())\nvalores=list(distribucion)\np = figure(x_range=objetivo, plot_height=250, title=\"Distribuci\u00f3n de las muestras con Bokeh\")\np.vbar(x=objetivo, top=valores, color = list(colores.values()),width=0.9)\np.xgrid.grid_line_color = None\np.y_range.start = 0\n\nshow(p)","d5054df2":"correctos = datos.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nno_correctos = correctos.index[correctos!=True]\n\nprint(\"Hogares con diferentes clasificaciones: \",no_correctos.nunique())","91a29789":"datos[datos['idhogar'] == correctos.index[correctos!=True][0]][['idhogar', 'parentesco1', 'Target']]","03cc1051":"correctos_list =  correctos.index[correctos==True]\ncorrectos_df = pd.DataFrame(columns=('idhogar', 'parentesco1', 'Target'))\nfor correcto in correctos_list:\n   correctos_df = correctos_df.append(datos[datos['idhogar'] == correcto][['idhogar', 'parentesco1', 'Target']])\n\ncorrectos_df.head(10)","64880428":"cabezas_familia = datos.groupby('idhogar')['parentesco1'].sum()\n\nhogares_sin_cf = datos.loc[datos['idhogar'].isin(cabezas_familia[cabezas_familia == 0].index), :]\nhogares_con_cf_mult = datos.loc[datos['idhogar'].isin(cabezas_familia[cabezas_familia > 1].index), :]\n\n#nunique valores unicos\nprint('Hogares sin cabeza de familia: ',hogares_sin_cf['idhogar'].nunique(), \n      ' Hogares con m\u00e1s de un cabeza de familia: ', hogares_con_cf_mult['idhogar'].nunique())","a6eeda21":"nulos = pd.DataFrame(datos.isnull().sum()).rename(columns = {0: 'total'})\n\nnulos['porcentaje'] = nulos['total'] \/ len(datos)\n\ncolumnas = nulos[nulos['porcentaje']>0].sort_values('porcentaje', ascending = False).head(10).reset_index().rename(index=str, columns={\"index\": \"nombre\"})","069475fb":"labels = list(columnas['nombre'])\nvalues = list(columnas['porcentaje'])\n\nnulos = {'data': \n       [{'type':'pie',\n                 'labels':labels,\n                 'domain': {\"x\": [0, 1]},\n                 'name': 'Valores nulos',\n                 'hoverinfo':'label+percent+name',\n                 'values': values\n        }],\n        'layout':\n        {\n          'title':'Porcentaje de nulos',\n           'annotations': [\n            {\n                'font': {\n                    'size': 18\n                },\n                'showarrow': False,\n                'text': '',\n                'x': 0.16,\n                'y': 0.5\n            }]\n        }\n      }\n               \n\niplot(nulos)","38d7f95a":"datos['idRegion']=0\ndatos['Region']=\"Vacio\"\ndatos['Zona']=\"vac\u00edo\"\n\n\nfor index, row in datos.iterrows():\n    datos.at[index,'Region']=np.where(row['lugar1']==1, \"Region Central\", np.where(row['lugar2']==1, \"Region Chorotega\", np.where(row['lugar3']==1, \"Region Pacifico Central\", np.where(row['lugar4']==1, \"Region Brunca\", np.where(row['lugar5']==1, \"Huetar Atlantica\", np.where(row['lugar6']==1, \"Huetar Norte\", \"Sin_espeficar\"))))))\n    datos.at[index,'idRegion']=np.where(row['lugar1']==1, 1, np.where(row['lugar2']==1, 2, np.where(row['lugar3']==1, 3, np.where(row['lugar4']==1, 4, np.where(row['lugar5']==1, 5, np.where(row['lugar6']==1, 6, 7))))))\n    datos.at[index, 'Zona']=np.where(row['area1']==1, \"Rural\", np.where(row['area2']==1, \"Urbana\", \"Sin_especificar\"))\n    \nsubset_maxima=datos[datos[\"Target\"]==1][['idRegion','Region','Zona']]\ns_maxima_gb= subset_maxima.groupby(['idRegion',subset_maxima['Region'].apply(str),subset_maxima['Zona'].apply(str)]).size().reset_index()\ns_maxima_gb.rename(columns={0 : 'Numero'},inplace=True)","8072cef8":"fig = {'data': [{'type':'pie',\n                 'labels':s_maxima_gb['Region'],\n                 'domain': {\"x\": [.1, .48],\"y\": [0, .82]},\n                 'name': 'Regiones',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4,\n                 'values': s_maxima_gb['Numero']\n                },\n                {'type':'pie',\n                 'labels':s_maxima_gb['Zona'],\n                 'values': s_maxima_gb['Numero'],\n                 'domain': {\"x\": [.52, 1], \"y\": [0,.82]},\n                 'name': 'Zonas',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4,\n                }\n               ],\n      'layout':{\n          'title':'Distribuci\u00f3n por regiones de riesgo extremo',\n           'annotations': [\n            {\n                'font': {\n                    'size': 18\n                },\n                'showarrow': False,\n                'text': 'Regiones',\n                'x': 0.25,\n                'y': 1\n            },\n            {\n                'font': {\n                    'size': 20\n                },\n                'showarrow': False,\n                'text': 'Zona',\n                'x': 0.78,\n                'y': 1\n            }\n        ]}\n      }\niplot(fig)","2c59b624":"#Ejercicio 1. Completar los subsets para los otros 3 targets\n#Ejemplo --> subset_maxima=datos[datos[\"Target\"]==1][['idRegion','Region','Zona']]\n\n#Fin Ejercicio\n","fb2a5479":"#Ejercicio 2. Completar con las agregaciones para los otros 3 targets\n#ejemplo --> s_maxima_gb= subset_maxima.groupby(['idRegion',subset_maxima['Region'].apply(str),subset_maxima['Zona'].apply(str)]).size().reset_index()\n#ejemplo --> s_maxima_gb.rename(columns={0 : 'Numero'},inplace=True)\n\n#Fin Ejercicio","9a3336fc":"#Ejercicio 3. Completar los huecos \"\"\"..completar...\"\"\" con los subconjuntos creados en el apartado anterior\n\n\"\"\"--Quitar comentario\n\ncorregido = {'data': [\n                {'type':'pie',\n                 'labels':s_maxima_gb['Region'],\n                 'values': s_maxima_gb['Numero'],\n                 'domain': {\"x\": [.1, .48],\n                            \"y\": [0, .22]},\n                 'name': 'Regiones',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                 \n                },\n                {'type':'pie',\n                 'labels':s_maxima_gb['Zona'],\n                 'values': s_maxima_gb['Numero'],\n                 'domain': {\"x\": [.52, 1],\n                            \"y\": [0,.22]},\n                 'name': 'Zonas',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                },   \n                {'type':'pie',\n                'labels': ...completar...,\n                'values': ...completar...,\n                'domain': {\"x\": [.1, .48],\n                            \"y\": [.24, .46]},\n                 'name': 'Regiones',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                },\n                {'type':'pie',\n                 'labels':...completar...,\n                 'values':...completar...,\n                 'domain': {\"x\": [.52, 1],\n                            \"y\": [.24, .46]},\n                 'name': 'Zonas',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4,\n                },\n                 {'type':'pie',\n                 'labels':...completar...,\n                 'values':...completar...,\n                 'domain': {\"x\": [.1, .48],\n                            \"y\": [.48, .70]},\n                 'name': 'Regiones',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                },\n                {'type':'pie',\n                 'labels':...completar...,\n                 'values':...completar...,\n                 'domain': {\"x\": [.52, 1],\n                            \"y\": [.48, .70]},\n                 'name': 'Zonas',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                },\n                {'type':'pie',\n                 'labels':...completar...,\n                 'values':...completar...,\n                 'domain': {\"x\": [.1, .48],\n                            \"y\": [.72, .94]},\n                 'name': 'Regiones',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                },\n                {'type':'pie',\n                 'labels':...completar...,\n                 'values':...completar...,\n                 'domain': {\"x\": [.52, 1],\n                            \"y\": [.72, .94]},\n                 'name': 'Zonas',\n                 'hoverinfo':'label+percent+name',\n                 'hole': .4\n                }              \n               ],\n      'layout':{\n          'title':'Distribuci\u00f3n por regiones del riesgo',\n           'width':1000,\n           'height':1000,\n           'annotations': [\n            {\n                'font': {\n                    'size': 18\n                },\n                'showarrow': False,\n                'text': 'Regiones',\n                'x': 0.25,\n                'y': 1\n            },\n            {\n                'font': {\n                    'size': 20\n                },\n                'showarrow': False,\n                'text': 'Zona',\n                'x': 0.78,\n                'y': 1\n            },\n            {\n                'font': {\n                    'size': 14\n                },\n                'showarrow': False,\n                'text': 'No Vulnerable',\n                'x': 0,\n                'y': 0.83\n            },\n                {\n                'font': {\n                    'size': 14\n                },\n                'showarrow': False,\n                'text': 'Vulnerable',\n                'x': 0,\n                'y': 0.59\n            },\n            {\n                'font': {\n                    'size': 14\n                },\n                'showarrow': False,\n                'text': 'Moderado',\n                'x': 0,\n                'y': 0.33\n            },\n            {\n                'font': {\n                    'size': 14\n                },\n                'showarrow': False,\n                'text': 'M\u00e1ximo',\n                'x': 0,\n                'y': 0.11\n            }\n              \n        ]}\n      }\n\"\"\"\n#Fin Ejercicio\n","2e113b09":"#Resultado final, comprobar que es correcto\n\n#iplot(corregido)","3ec07435":"#Creamos un df con las coordenadas de cada regi\u00f3n\ncoor_regiones = pd.DataFrame([\n        {'idRegion':1,'lon':-84.094, 'lat': 9.916},\n        {'idRegion':2,'lon':-85.658, 'lat': 10.205},\n        {'idRegion':3,'lon':-84.62, 'lat': 9.635},\n        {'idRegion':4,'lon':-83.182, 'lat': 8.764},\n        {'idRegion':5,'lon':-83.176, 'lat': 9.977},\n        {'idRegion':6,'lon':-84.286, 'lat': 10.683},\n])\n\ns_maxima_gb_agg = s_maxima_gb.groupby(['idRegion',s_maxima_gb['Region'].apply(str)])[['Numero']].sum().reset_index()\nresult_maxima = pd.merge(s_maxima_gb_agg, coor_regiones, on='idRegion')","8ab139e7":"cases = []\ncolors = 'rgb(190,39,0)'\n\n\ncases.append(go.Scattergeo(\n        lon = result_maxima['lon'], #-(max(range(6,10))-i),\n        lat = result_maxima['lat'],\n        text = result_maxima['Numero'],\n        name = 'Extreme',\n        marker = dict(\n            size = result_maxima['Numero']\/10,\n            color = colors,\n            line = dict(width = 0)\n        )\n    ) )\n\nlayout = go.Layout(\n    title = 'Localizaci\u00f3n de hogares con riesgo m\u00e1ximo',\n    autosize=False,\n    width=700,\n    height=600,\n    geo = dict(\n        resolution = 50,\n        scope = 'north america',\n        showframe = False,\n        showcoastlines = True,\n        showland = True,\n        landcolor = \"rgb(229, 229, 229)\",\n        countrycolor = \"rgb(255, 255, 255)\" ,\n        coastlinecolor = \"rgb(255, 255, 255)\",\n        projection = dict(\n            type = 'mercator'\n        ),\n        lonaxis = dict( range= [ -86.5, -80.8 ] ),\n        lataxis = dict( range= [ 6.9, 12.5 ] ),\n        domain = dict(\n            x = [ 0, 1 ],\n            y = [ 0, 1 ]\n        )\n    ),\n    legend = dict(\n           traceorder = 'reversed'\n    )\n)\n\nfig = go.Figure(layout=layout, data=cases)\niplot(fig)\n","985d1f55":"#Ejercicio 4. Comppletar con las agregaciones con los otros targets.\n\n#ejemplo --> s_maxima_gb_agg = s_maxima_gb.groupby(['idRegion',s_maxima_gb['Region'].apply(str)])[['Numero']].sum().reset_index()\n#ejemplo --> result_maxima = pd.merge(s_maxima_gb_agg, coor_regiones, on='idRegion')\n\n#Para no tener que copiar&pegar asignar el resultado de las agregaciones a las siguiente variables:\n\n#result_moderado=\n#result_vulnerable=\n#result_no_vulnerable=","72f734a8":"#Continuaci\u00f3n Ejercicio 4. Ejecutar y comprobar que las otras regiones aparecen marcadas en el mapa\n\"\"\"\ncases = []\n\ncolors =['red','orange','yellow','green']\n\n\ncases.append(go.Scattergeo(\n        lon = result_maxima['lon'], \n        lat = result_maxima['lat'],\n        text = result_maxima['Numero'],\n        name = 'Extremo',\n        marker = dict(\n            size = result_maxima['Numero']\/10,\n            color = colors[0],\n            line = dict(width = 0)\n        )\n    ) )\n\ncases.append(go.Scattergeo(\n        lon = result_moderado['lon'], \n        lat = result_moderado['lat'],\n        text = result_moderado['Numero'],\n        name = 'Moderado',\n        marker = dict(\n            size = result_moderado['Numero']\/10,\n            color = colors[1],\n            line = dict(width = 0)\n        )\n    ) )\n\ncases.append(go.Scattergeo(\n        lon = result_vulnerable['lon'], \n        lat = result_vulnerable['lat'],\n        text = result_vulnerable['Numero'],\n        name = 'Vulnerable',\n        marker = dict(\n            size = result_vulnerable['Numero']\/10,\n            color = colors[2],\n            line = dict(width = 0)\n        )\n    ) )\n\ncases.append(go.Scattergeo(\n        lon = result_no_vulnerable['lon'], \n        lat = result_no_vulnerable['lat'],\n        text = result_no_vulnerable['Numero'],\n        name = 'No Vulnerable',\n        marker = dict(\n            size = result_no_vulnerable['Numero']\/30,\n            color = colors[3],\n            line = dict(width = 0)\n        )\n    ) )\n\n\nlayout = go.Layout(\n    title = 'Localizaci\u00f3n de hogares por riesgo',\n    autosize=False,\n    width=700,\n    height=600,\n    geo = dict(\n        resolution = 50,\n        scope = 'north america',\n        showframe = False,\n        showcoastlines = True,\n        showland = True,\n        landcolor = \"rgb(229, 229, 229)\",\n        countrycolor = \"rgb(255, 255, 255)\" ,\n        coastlinecolor = \"rgb(255, 255, 255)\",\n        projection = dict(\n            type = 'mercator'\n        ),\n        lonaxis = dict( range= [ -86.5, -80.8 ] ),\n        lataxis = dict( range= [ 6.9, 12.5 ] ),\n        domain = dict(\n            x = [ 0, 1 ],\n            y = [ 0, 1 ]\n        )\n    ),\n    legend = dict(\n           traceorder = 'reversed'\n    )\n)\n\nfig = go.Figure(layout=layout, data=cases)\n#Fin Ejercicio\n\"\"\"","fdf779da":"#Resultado final, comprobar que es correcto\n\n#iplot(fig)","06ebb8df":"#Comprobamos los valores que ten\u00edan nulos\niplot(nulos)","664f591b":"#Antes de comenzar el tratamiento de los datos, hacemos una copia del dataframe original que hemos utilizado en la visualizaci\u00f3n para comenzar a preparar los conjuntos de train y set\ntrain_set=datos.copy()\n\n# Sustitu\u00edmos los valores nulos por la mediana\ntrain_set['meaneduc'] = train_set['meaneduc'].fillna(datos['meaneduc'].median())\ntrain_set['SQBmeaned'] = train_set['SQBmeaned'].fillna(datos['SQBmeaned'].median())\ntrain_set['v2a1'] = train_set['v2a1'].fillna(datos['v2a1'].median())\ntrain_set['v18q1'] = train_set['v18q1'].fillna(-1)\ntrain_set['rez_esc'] = train_set['rez_esc'].fillna(-1)\n#hacemos lo mismo con el conjunto de test\ntest_set['meaneduc'] = test_set['meaneduc'].fillna(datos['meaneduc'].median())\ntest_set['SQBmeaned'] = test_set['SQBmeaned'].fillna(datos['SQBmeaned'].median())\ntest_set['v2a1'] = test_set['v2a1'].fillna(datos['v2a1'].median())\ntest_set['v18q1'] = test_set['v18q1'].fillna(-1)\ntest_set['rez_esc'] = test_set['rez_esc'].fillna(-1)","451df952":"nulos_train = pd.DataFrame(train_set.isnull().sum()).rename(columns = {0: 'total'}) \nnulos_test = pd.DataFrame(test_set.isnull().sum()).rename(columns = {0: 'total'})\nprint(\"Nulos encontrados en Train:\",len(nulos_train[nulos_train['total']>0]),\" Test: \",len(nulos_test[nulos_test['total']>0]))","2e074bb1":"test_set.select_dtypes('object').head()","f3d01cda":"#R\u00e1pidamente podemos ver los valores \u00fanico de la columna que queramos transformar\npd.DataFrame(np.unique(datos['edjefe'],return_counts=True))","1336fe61":"cols = ['edjefe', 'edjefa']\ntrain_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\ntest_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)\n\ntrain_set['dependency']=train_set['dependency'].replace({'no':train_set['meaneduc'].median() , 'yes':train_set['meaneduc'].median()}).astype(float)\ntest_set['dependency']=test_set['dependency'].replace({'no':test_set['meaneduc'].median() , 'yes':test_set['meaneduc'].median()}).astype(float)\n\n#Podemos ver que ya no aparecen los valores susitituidos\npd.DataFrame(np.unique(train_set['edjefe'],return_counts=True))\n","746691f0":"def owner_is_adult(x):\n    if x['age'] <= 18:\n        return 0\n    else:\n        return 1\n\ntrain_set['head>18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\ntest_set['head>18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)","1a63aaa1":"train_set[['age','head>18']].head(5)","d2e013f6":"from sklearn.model_selection import train_test_split\n\n#Separamos las etiquetas para entrenar los modelos\nX = train_set.drop(['Id','idhogar','Target','idRegion','Region','Zona'], axis=1) \ny = train_set['Target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","06cdadf3":"# Ejecutamos OverSampling para resolver el desbanlaceado de clases\nfrom imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=42)\nX_ros,y_ros= ros.fit_resample(X_train,y_train)\n# Verificamos el resultado\ny_ros.value_counts()","750f0d2f":"from sklearn.ensemble import RandomForestClassifier\n\nrfd = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\nrfd.fit(X_train, y_train)","976a085c":"from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, plot_confusion_matrix\n\npredict_rfd = rfd.predict(X_test)\naccuracy_rfd = accuracy_score(y_test, predict_rfd)\naccuracy_rfd","59411e0e":"feats = [c for c in X.columns]\n\nfig=plt.figure(figsize=(15, 20))\npd.Series(rfd.feature_importances_,index=feats).sort_values().plot.barh()","6afebf93":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test, predict_rfd)","b1144c43":"rfb = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\nrfb.fit(X_ros, y_ros)","ed478b1b":"predict_rfb = rfb.predict(X_test)\naccuracy_rfb = accuracy_score(y_test, predict_rfb)\naccuracy_rfb","259e8db1":"fig=plt.figure(figsize=(15, 20))\npd.Series(rfb.feature_importances_, index=feats).sort_values().plot.barh()\n","e7693083":"skplt.metrics.plot_confusion_matrix(y_test, predict_rfb)","2c1bdc7f":"print('RandomForestClassifier=', accuracy_rfd,'\\nRandomForestClassifier Oversampling=',accuracy_rfb)","71755341":"test = test_set.drop(['Id','idhogar'], axis=1)\ntest_set['Target'] = rfb.predict(test).astype(int)\ntest_set","8770107c":"test_set[['Id', 'Target']].to_csv('submission.csv', index=False)","d2f2814e":"**VALORES NULOS**","0f4fe424":"**Exploraci\u00f3n**\n\nEl primer paso es explorar nuestro conjunto de datos, ayud\u00e1ndonos del diccionario para saber qu\u00e9 es cada columna:","cc3aa35c":"**CORREGIR VALORES**\nExisten columnas con campos de distinto tipo","c5bca292":"**ENTRENAMIENTO DE MODELOS**","f2d8f3a7":"Ahora vamos a pintar sobre un mapa las diferentes regiones que contemplan nuestro dataset y mostramos el n\u00famero de casos en funci\u00f3n del target","c564f528":"* v2a1, Monthly rent payment\n* v18q1, number of tablets household owns\n* rez_esc, years behind in school\n* meaneduc, average years of education for adults (18+)\n* overcrowding, persons per room\n* SQBovercrowding, overcrowding squared\n* SQBdependency, dependency squared\n* SQBmeaned, square of the mean years of education of adults (>=18)","a7cddf80":"**Ejecuci\u00f3n RANDOMFOREST sin tratar el desbalanceo**","a90e44e7":"**INFORMACI\u00d3N GEOGR\u00c1FICA**","4b794cc8":"Descripci\u00f3n de campos con nulos:\n* rez_esc, Years behind in school\n* v18q1, number of tablets household owns\n* v2a1, Monthly rent payment\n* meaneduc,average years of education for adults (18+)\n* SQBmeaned, square of the mean years of education of adults (>=18) in the household","54437fb3":"**Ejecuci\u00f3n RANDOMFOREST con tratamiento del desbalanceo**","c946c91c":"Vamos a comprobar si en las muestras existen errores de clasificaci\u00f3n","943a300f":"![](https:\/\/cowboyproductions52.com\/wp-content\/uploads\/2017\/06\/articles-how-to-spend-your-first-24-hours-in-san-jos-costa-rica.jpg)","c2754d23":"**Resumen**\n\nLa mayor dificultad que tienen la mayor\u00eda de programas sociales, es contar con la certeca de que la ayuda que prestan llega a las personas adecuadas. Es especialmente complicado cuando, un determinado programa, se enfoca en el segmento m\u00e1s pobre de la poblaci\u00f3n, ya que, los m\u00e1s pobres, raramente proporcionan los registros necesarios para ser calificados como tales.\n\nHaciendo uso de un algoritmo llamado Proxy Means Test (o PMT). Con PMT, las agencias usan un modelo que considera varios atributos familiares del hogar, como el material de sus paredes y techo, o los activos que se encuentran en \u00e9l para clasificarlos y predecir su nivel de necesidad.","86ad0f7d":"Este es un problema de clasificaci\u00f3n multiclase:\n\n* Supervisado: se proveen las etiquetas en el conjunto de entrenamiento\n* Clasificaci\u00f3n multiclase: las etiquetas son valores discreto (4 clases)","b066ec64":"**TRATAMIENTO E INGENIER\u00cdA DE CARACTER\u00cdSTICAS**","731154bc":"**A\u00d1ADIR CARACTER\u00cdSTICAS NUEVAS**"}}