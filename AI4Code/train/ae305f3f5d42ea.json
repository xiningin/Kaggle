{"cell_type":{"93557144":"code","de94a853":"code","f38d3356":"code","a218af89":"code","76c6caf0":"code","810e28ef":"code","1ac9ff81":"code","76522421":"code","ba182142":"code","6ec0596d":"code","fb61034d":"code","a6da0922":"code","dba0da11":"code","af69a360":"code","cfe14507":"code","38c04030":"code","99b075ba":"code","3afea685":"code","05b0418d":"code","3cdb778b":"code","05f4465c":"code","041e2540":"code","d3da3300":"code","113a3424":"code","ad1c5f74":"code","baa92461":"code","d1a0979d":"code","58a65491":"code","7b193fad":"code","e1199440":"code","90ebc671":"code","9fbd996e":"markdown","5b7febe1":"markdown","a3b76606":"markdown","068b15e2":"markdown","55cb68ad":"markdown","1cfb00a8":"markdown","a78e9e9a":"markdown","f0550a29":"markdown","b66ae03c":"markdown","a09ee7ff":"markdown"},"source":{"93557144":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de94a853":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline","f38d3356":"train_ds=pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest_ds=pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")","a218af89":"test_ds.head()","76c6caf0":"y=test_ds['label'].to_numpy()\nx = test_ds.drop('label',axis=1).values","810e28ef":"x=torch.tensor(x)\ny=torch.tensor(y)","1ac9ff81":"train_ds.head()","76522421":"train_ds.shape","ba182142":"len(test_ds)","6ec0596d":"label=train_ds['label']   #pandas series","fb61034d":"train_ds=train_ds.drop('label',axis=1)","a6da0922":"plt.imshow(train_ds[0:1].values.reshape(28,28))\nplt.axis(\"off\")\nprint(label[0])","dba0da11":"train_ds=train_ds.values\nlabel=label.to_numpy()\n","af69a360":"np.max(train_ds[0])","cfe14507":"label=torch.tensor(label)\ntrain_ds=torch.tensor(train_ds)","38c04030":"traiin_ds=TensorDataset(train_ds,label)","99b075ba":"test_ds=TensorDataset(x,y)","3afea685":"traiin_ds[0:2]","05b0418d":"train_ds,val_ds=random_split(traiin_ds, (50000,10000))","3cdb778b":"img,lab = train_ds[7]\nprint(img.shape)\nprint(lab)\nplt.imshow(img.reshape(28,28))","05f4465c":"batch_size=128","041e2540":"train_loader=DataLoader(train_ds,batch_size,shuffle=True)\nval_loader=  DataLoader(train_ds,batch_size*2)","d3da3300":"test_loader=DataLoader(test_ds,batch_size*2)","113a3424":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n    \nmodel=NeuralNetwork().to('cuda')","ad1c5f74":"model.parameters()","baa92461":"optimizer=torch.optim.SGD\nopt= optimizer(model.parameters(),lr=0.001)\nloss_func=F.cross_entropy","d1a0979d":"def fit(epochs,model,data):\n    \n    hist=[]\n    for epoch in range(epochs):\n        for img,label in data:\n#             print(img.shape)\n            img,label=img.to(\"cuda\"),label.to('cuda')\n            out = model(img\/255)\n            loss= loss_func(out,label)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n            hist.append(loss)\n            \n        \n        if (epoch+1)%10==0:\n            print(f\"epoch : [{epoch+1}\/{epochs}] ; loss : {loss.item()}\")\n    ","58a65491":"fit(100,model,train_loader)","7b193fad":"def acc(data):\n    accy=[]\n    for img ,label in data:\n        img,label = img.to('cuda'),label.to('cuda')\n        out=model(img\/255)\n#         out=F.softmax(out)\n        _,pred_index=torch.max(out,dim=1)\n        x=torch.sum(pred_index==label)\/len(pred_index)\n        x=x*100\n        x=x.to(\"cpu\").numpy()\n        accy.append(x)\n        \n        \n    return np.mean(accy)  \n        ","e1199440":"acc(val_loader)","90ebc671":"acc(test_loader)\n    ","9fbd996e":"## model training","5b7febe1":"## converting to numpy  arrays","a3b76606":"## define dependent and independent features\n","068b15e2":"## Define dependent and independent features for test data","55cb68ad":"## create batches","1cfb00a8":"## Import libraries","a78e9e9a":"## Do Upvote","f0550a29":"## Reading files","b66ae03c":"## Model","a09ee7ff":"## converting  test data to tensor"}}