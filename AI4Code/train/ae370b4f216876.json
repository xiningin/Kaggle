{"cell_type":{"102b0b71":"code","4c00fd78":"code","e403cbc1":"code","11f84f27":"code","7e783548":"code","a7e821d0":"code","ef977293":"markdown","56a202bb":"markdown","3d63ed6c":"markdown","8ca90e93":"markdown"},"source":{"102b0b71":"#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport math\nimport operator\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4c00fd78":"# importing data\ndata=pd.read_csv('..\/input\/Iris.csv',index_col='Id')\ndata.head()","e403cbc1":"data.shape","11f84f27":"# Defining a function to calculate euclidean distance between two data points\ndef euclideanDistance(data1,data2,length):\n    distance=0\n    for x in range(length):\n        distance+=np.square(data1[x]-data2[x])\n    return np.sqrt(distance)\n\n# Defining our KNN model\ndef knn(train,test,k):\n    \n    \n    length=test.shape[1]\n    result=[]\n    # calculating euclideanDistance between each row of training data and test data\n    for y in range(len(test)):\n        distances={}\n        sort={}\n        for x in range(len(train)):\n            dist=euclideanDistance(test.iloc[y],train.iloc[x],length)\n            distances[x]=dist\n           \n        #sorting them on the basis of distance\n        sorted_d=sorted(distances.items(),key=operator.itemgetter(1))\n    \n        neighbors=[]\n    \n        # Extracting top k neighbors\n        for  x in range(k):\n            neighbors.append(sorted_d[x][0])\n        \n        classvotes={}\n    \n        # calculate most frequent class in the neighbors\n        for x in range(len(neighbors)):\n            response=train.iloc[neighbors[x]][-1]\n        \n            if response in classvotes:\n                classvotes[response]+=1\n            else:\n                classvotes[response]=1\n         \n        sortedvotes=sorted(classvotes.items(),key=operator.itemgetter(1),reverse=True)\n        result.append(sortedvotes[0][0])\n    return (result)\n\n    ","7e783548":"# creating a dummy test set\ntestset=[[7.2,3.6,5.1,2.5],[7.5,3.8,5.3,2.8]]\ntest=pd.DataFrame(testset)\n# setting no. of neighbors\nk=3\n#Running our model\nresult=knn(data,test,k)\nprint(result)\n","a7e821d0":"from sklearn.neighbors import KNeighborsClassifier\nneigh=KNeighborsClassifier(n_neighbors=3)\nneigh.fit(data.iloc[:,0:4],data['Species'])\n\nprint(neigh.predict(test))","ef977293":"# Introduction \nK-Nearest Neighbour (KNN) can be used for solving classification as well as regression problems. However , it is more widely used in classification problems in industry.\n \nIn this notebook , we are going to create KNN algorithm from scratch and use it to solve IRIS dataset. Further we will compare our results with KNeighborsClassifier of sklearn.\n\nWe can implement KNN by following below steps:\n* Load the data\n* Initialize the value of k\n* Iterate over all the test data points.\n* for getting the predicted class, iterate from one to total no. of training data points\n    1. Calculate the distance between test data and each row of training data. Here we will use Euclidean distance as our distance metric since it\u2019s the most popular method. The other metrics that can be used are Manhatten,Chebyshev, cosine, etc.\n    2. Sort the calculated distances in ascending order based on distance values.\n    3. Get top k rows from the sorted array.\n    4. Get the most frequent class of these rows.\n    5. Return the predicted class.","56a202bb":"# Implementation\nYou can dowload the iris dataset from [here](https:\/\/gist.githubusercontent.com\/gurchetan1000\/ec90a0a8004927e57c24b20a6f8c8d35\/raw\/fcd83b35021a4c1d7f1f1d5dc83c07c8ffc0d3e2\/iris.csv)","3d63ed6c":"# Comaring Our model with scikit-learn","8ca90e93":"* Both models are predicting the same class. Hence our model is working correctly.\n"}}