{"cell_type":{"5728806f":"code","b012bbc5":"code","c432eb97":"code","25ecedd5":"code","84a199d0":"code","5b9f9499":"code","865f6277":"code","42cf9f72":"code","d786115f":"code","5c91af5f":"code","c39721bb":"code","54a0fdee":"code","07c00503":"code","dc0416b5":"code","ad83f7eb":"code","8acc4bc6":"code","15e2a432":"code","91063d3e":"code","9a4efc2e":"code","4c2977b9":"code","bd9b1369":"code","6e59ca7b":"code","31eb5f4c":"code","ca0da6e8":"code","3a2f4d0d":"code","a41a6d42":"code","00034bc9":"code","5826dcbe":"code","ca130399":"code","5e5852a5":"code","cea9a37e":"code","f0bb121d":"code","3cf563eb":"code","2ed580a0":"code","7aea9a2d":"code","0e0b8ce5":"markdown","76d1ff80":"markdown","965d91a2":"markdown","f67c05fe":"markdown","98c11f4f":"markdown","619bbe13":"markdown","a3a67142":"markdown"},"source":{"5728806f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams['figure.figsize'] = (8,6)\nplt.style.use('fivethirtyeight')","b012bbc5":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","c432eb97":"train = pd.read_csv(\"..\/input\/train.csv\", parse_dates=[\"first_active_month\"])\ntest = pd.read_csv(\"..\/input\/test.csv\", parse_dates=[\"first_active_month\"])","25ecedd5":"train.shape, test.shape","84a199d0":"train.head()","5b9f9499":"target_col = 'target'\n\nplt.scatter(range(train.shape[0]), np.sort(train[target_col].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Loyalty Score', fontsize=12)\nplt.title(\"Loyalty score on target\")\nplt.show()","865f6277":"sns.distplot(train[target_col].values, bins=50, kde=False, color=\"red\")\nplt.title(\"Histogram of Loyalty score\")\nplt.xlabel('Loyalty score', fontsize=12)\nplt.show()","42cf9f72":"train[train['target']<-30]['target'].count()","d786115f":"cnt_srs = train['first_active_month'].dt.date.value_counts()\ncnt_srs = cnt_srs.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\nplt.xticks(rotation='vertical')\nplt.xlabel('First active month', fontsize=12)\nplt.ylabel('Number of cards', fontsize=12)\nplt.title(\"First active month count in train set\")\nplt.show()\n\n\ncnt_srs = test['first_active_month'].dt.date.value_counts()\ncnt_srs = cnt_srs.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\nplt.xticks(rotation='vertical')\nplt.xlabel('First active month', fontsize=12)\nplt.ylabel('Number of cards', fontsize=12)\nplt.title(\"First active month count in test set\")\nplt.show()","5c91af5f":"# feature 1\n\nsns.violinplot(x=\"feature_1\", y=target_col, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 1', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 1 distribution\")\nplt.show()\n\n# feature 2\n\nsns.violinplot(x=\"feature_2\", y=target_col, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 2', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 2 distribution\")\nplt.show()\n\n# feature 3\n\nsns.violinplot(x=\"feature_3\", y=target_col, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 3', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 3 distribution\")\nplt.show()","c39721bb":"import datetime\ntrain['elapsed_time'] = (datetime.date(2018, 2, 1) - train['first_active_month'].dt.date).dt.days\ntest['elapsed_time'] = (datetime.date(2018, 2, 1) - test['first_active_month'].dt.date).dt.days","54a0fdee":"train['month'] = train.first_active_month.dt.month\ntrain['year'] = train.first_active_month.dt.year\ntest['month'] = test.first_active_month.dt.month\ntest['year'] = test.first_active_month.dt.year","07c00503":"import gc\ngc.collect()","dc0416b5":"def binarize(df):\n    for col in ['authorized_flag', 'category_1']:\n        df[col] = df[col].map({'Y':1, 'N':0})\n    return df","ad83f7eb":"holidays = [\n        ('Christmas_Day_2017', '2017-12-25'),  # Christmas: December 25 2017\n        ('Mothers_Day_2017', '2017-06-04'),  # Mothers Day: May 14 2017\n        ('fathers_day_2017', '2017-08-13'),  # fathers day: August 13 2017\n        ('Children_day_2017', '2017-10-12'),  # Childrens day: October 12 2017\n        ('Valentine_Day_2017', '2017-06-12'),  # Valentine's Day : 12th June, 2017\n        ('Black_Friday_2017', '2017-11-24'),  # Black Friday: 24th November 2017\n        ('Mothers_Day_2018', '2018-05-13'),\n    ]\n\ndef dist_holiday(df, col_name, date_holiday, date_ref, period=100):\n    df[col_name] = np.maximum(np.minimum((pd.to_datetime(date_holiday) - df[date_ref]).dt.days, period), 0)","8acc4bc6":"historical = pd.read_csv(\"..\/input\/historical_transactions.csv\", parse_dates=['purchase_date'])\nhistorical = binarize(historical)\nhistorical = pd.get_dummies(historical, columns=['category_2', 'category_3'])\nhistorical = reduce_mem_usage(historical)","15e2a432":"gdf = historical.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].size().reset_index()\ngdf.columns = [\"card_id\", \"historical_transactions\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","91063d3e":"cnt_srs = train.groupby(\"historical_transactions\")['target'].mean()\ncnt_srs = cnt_srs.sort_index()\ncnt_srs = cnt_srs[:-50]\n\nsns.scatterplot(data=cnt_srs)\nplt.title('Loyalty score by Number of historical transactions')\nplt.show()","9a4efc2e":"for d_name, d_day in holidays:\n    dist_holiday(historical, d_name, d_day, 'purchase_date')","4c2977b9":"agg_func = {\n        'category_1': ['sum', 'mean'],\n        'category_2_1.0': ['sum', 'mean'],\n        'category_2_2.0': ['sum', 'mean'],\n        'category_2_3.0': ['sum', 'mean'],\n        'category_2_4.0': ['sum', 'mean'],\n        'category_2_5.0': ['sum', 'mean'],\n        'category_3_A': ['sum', 'mean'],\n        'category_3_B': ['sum', 'mean'],\n        'category_3_C': ['sum', 'mean'],\n        'authorized_flag': ['nunique', 'mean', 'sum'],\n        'merchant_id': ['nunique'],\n        'merchant_category_id': ['nunique'],\n        'state_id': ['nunique'],\n        'city_id': ['nunique'],\n        'subsector_id': ['nunique'],\n        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std','skew'],\n        'installments': ['sum', 'mean', 'max', 'min', 'std', 'skew'],\n        'purchase_date': [np.ptp, 'min', 'max'],\n        'month_lag': ['min', 'max'],\n        'Christmas_Day_2017': ['mean', 'sum'],\n        'Mothers_Day_2017': ['mean', 'sum'],\n        'fathers_day_2017': ['mean', 'sum'],\n        'Children_day_2017': ['mean', 'sum'],\n        'Valentine_Day_2017': ['mean', 'sum'],\n        'Black_Friday_2017': ['mean', 'sum'],\n        'Mothers_Day_2018': ['mean', 'sum']\n        }","bd9b1369":"# Adding more features from historical transactions\n\nhistorical.loc[:, 'purchase_date'] = pd.DatetimeIndex(historical['purchase_date']).\\\n                                      astype(np.int64) * 1e-9\ngdf = historical.groupby(\"card_id\").agg(agg_func)\ngdf.columns = ['_historical_'.join(col).strip() for col in gdf.columns.values]\ngdf.reset_index(inplace=True)\n\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","6e59ca7b":"new= pd.read_csv(\"..\/input\/new_merchant_transactions.csv\", parse_dates=['purchase_date'])\nnew = binarize(new)\nnew = pd.get_dummies(new, columns=['category_2', 'category_3'])\nnew = reduce_mem_usage(new)","31eb5f4c":"gdf = new.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].size().reset_index()\ngdf.columns = [\"card_id\", \"new_transactions\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","ca0da6e8":"cnt_srs = train.groupby(\"new_transactions\")[target_col].mean()\ncnt_srs = cnt_srs.sort_index()\n\nsns.scatterplot(data=cnt_srs, size=(20,15))\nplt.title('Loyalty score by Number of new merchant transactions')\nplt.show()","3a2f4d0d":"for d_name, d_day in holidays:\n    dist_holiday(new, d_name, d_day, 'purchase_date')","a41a6d42":"# Adding more features from new transactions\nnew.loc[:, 'purchase_date'] = pd.DatetimeIndex(new['purchase_date']).\\\n                                      astype(np.int64) * 1e-9\ngdf = new.groupby(\"card_id\").agg(agg_func)\ngdf.columns = ['_new_'.join(col).strip() for col in gdf.columns.values]\ngdf.reset_index(inplace=True)\n\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","00034bc9":"del new, historical","5826dcbe":"import gc\ngc.collect()","ca130399":"target = train['target']\ndel train['target']\n\nfeatures = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\ncategorical_feats = [c for c in features if 'feature_' in c]","5e5852a5":"xgb_params = {\n            'gpu_id': 0,  \n            'objective': 'reg:linear', \n            'eval_metric': 'rmse', \n            'silent': True, \n            'booster': 'gbtree', \n            'n_jobs': 4, \n            'tree_method': 'gpu_hist', \n            'grow_policy': 'lossguide', \n            'max_depth': 12, \n            'seed': 538, \n            'colsample_bylevel': 0.9, \n            'colsample_bytree': 0.8, \n            'gamma': 0.0001, \n            'learning_rate': 0.006150886706231842, \n            'max_bin': 128, \n            'max_leaves': 47, \n            'min_child_weight': 40, \n            'reg_alpha': 10.0, \n            'reg_lambda': 10.0, \n            'subsample': 0.9,\n            'n_estimators': 20000\n}","cea9a37e":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfolds = KFold(n_splits=10, shuffle=True, random_state=15)\noof = np.zeros(len(train))\nxgb_predictions = np.zeros(len(test))\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    X_train, y_train = (train.iloc[trn_idx][features], target.iloc[trn_idx])\n    X_valid, y_valid = (train.iloc[val_idx][features], target.iloc[val_idx])\n    \n    clf = xgb.XGBRegressor(**xgb_params)\n    clf.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], verbose=1000, early_stopping_rounds = 1000)\n    oof[val_idx] = clf.predict(X_valid, ntree_limit=clf.best_ntree_limit)\n    \n    xgb_predictions += clf.predict(test[features], ntree_limit=clf.best_ntree_limit) \/ folds.n_splits","f0bb121d":"print(\"CV score with XGB: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))","3cf563eb":"xgb.plot_importance(clf, height=0.8, grid=False, title='XGBoost - Feature Importance', max_num_features=20)\nplt.figure(figsize=(20,18))\nplt.show()","2ed580a0":"sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\nsub_df[\"target\"] = xgb_predictions\nsub_df.to_csv(\"xgb_preds_updated.csv\", index=False)","7aea9a2d":"plt.figure(figsize=(20,18))\nxgb.plot_tree(clf, num_trees=3)\nplt.show()","0e0b8ce5":"Similar kind of distribution on all 3","76d1ff80":"**New Merchant Transactions**:\nIn this section, let us look at the new merchant transactions data and do some analysis","965d91a2":"**Historical Transactions:**\nNow let us look at the historical transactions data for the cards.","f67c05fe":"Distribution of the feature 1,2,3","98c11f4f":"Some of the loyalty values are far apart (less than -30) compared to others. Let us just get their count.","619bbe13":"We have similar distribution in both test and train dataset","a3a67142":"**Baseline Model**\n\nLet us build a baseline model using the features created so far."}}