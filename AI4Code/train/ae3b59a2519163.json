{"cell_type":{"4b7719fc":"code","11dc76f6":"code","918e187d":"code","91215dc1":"code","bedd94da":"code","a7c36535":"code","fd685c8d":"code","76a18f81":"code","40a3cec9":"code","3d8048f6":"code","c3eb53c9":"code","46aabfef":"code","00da6ae6":"code","dd54c999":"code","b01a396d":"code","79d8230f":"code","ce5a3135":"code","353e74c4":"code","b4417597":"code","123e5656":"code","55f41df4":"code","a28ae13a":"code","05f17911":"code","19f4ea4a":"code","2a54904b":"code","4f494e3b":"code","dc6929d8":"code","92d39245":"code","465e2d84":"code","8c1c44f0":"code","a29073a7":"markdown","3c41417f":"markdown","ca91bdac":"markdown","e03fdc5f":"markdown","a7c324eb":"markdown","a0952f25":"markdown","f9731bcf":"markdown","ac439011":"markdown","3fb4b57f":"markdown","c4f94d3e":"markdown","2d8b5845":"markdown"},"source":{"4b7719fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/iris-flower-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11dc76f6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","918e187d":"df=pd.read_csv(\"..\/input\/iris-flower-dataset\/IRIS.csv\")","91215dc1":"df.head()","bedd94da":"df.tail()","a7c36535":"df.shape","fd685c8d":"df.info()","76a18f81":"# Check statistical info of data","40a3cec9":"df.describe()","3d8048f6":"df.isnull().sum()","c3eb53c9":"df.columns","46aabfef":"df.nunique()\n\n#unique- will say about unique values\n#nunique- will say how many number of unique values","00da6ae6":"df.min()","dd54c999":"df.max()","b01a396d":"a=sns.pairplot(df, hue='species', markers='+')\nplt.show()","79d8230f":"df.head()","ce5a3135":"a = sns.violinplot(y='species', x='sepal_length', data=df, inner='quartile')\nplt.show()\na = sns.violinplot(y='species', x='sepal_width', data=df, inner='quartile')\nplt.show()\na = sns.violinplot(y='species', x='petal_length', data=df, inner='quartile')\nplt.show()\na = sns.violinplot(y='species', x='petal_width', data=df, inner='quartile')\nplt.show()","353e74c4":"# List of variables to map\n\nvarlist =  ['species']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Iris-setosa': 0, 'Iris-virginica': 1,'Iris-versicolor': 2})\n\n# Applying the function to the housing list\ndf[varlist] = df[varlist].apply(binary_map)","b4417597":"from sklearn.model_selection import train_test_split\n\nused_features =[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"species\"]\n\nx = df[used_features].values\ny = df[\"species\"]","123e5656":"x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.3,random_state=1)","55f41df4":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a28ae13a":"df.head()","05f17911":"df.tail()","19f4ea4a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","2a54904b":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","4f494e3b":"#Import descision tree classifier from sk learn library\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Fitting the decession tree with default hyperparameters,apart from \n#max_depth which is 5 so that we can plot and read the tree\n\ndt_default=DecisionTreeClassifier(max_depth=15)","dc6929d8":"# Fiting on Train data\ndt_default.fit(x_train,y_train)","92d39245":"#lets check the evaluation metrics of our default model\n\n#Importing classification report and confusion matrix from sklearn metrics\n\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn import tree\n\n#Making predictions\ny_pred_default=dt_default.predict(x_test)\n\n#Printing classification report\nprint(classification_report(y_test,y_pred_default))","465e2d84":"print(confusion_matrix(y_test,y_pred_default))","8c1c44f0":"print(accuracy_score(y_test,y_pred_default))","a29073a7":"# Check missing values","3c41417f":"Checking various datatypes in data","ca91bdac":"# Check unique values","e03fdc5f":"# Creating the model","a7c324eb":"# Now let's us bulid a classifier which can predict survival creating train and test data sets using accent y variables","a0952f25":"#Problem Statement:\n\n#This data set consists of the physical parameters of three species of flower \u2014 Versicolor, Setosa and Virginica. The numeric parameters which the dataset contains are Sepal width, Sepal length, Petal width and Petal length. In this data we will be predicting the classes of the flowers based on these parameters.The data consists of continuous numeric values which describe the dimensions of the respective features. We will be training the model based on these features.","f9731bcf":"# Visualising the data","ac439011":"Importing Necessary Libraries","3fb4b57f":"# Checking size of data\n","c4f94d3e":"Reading of Iris data","2d8b5845":"Build a decision tree classifier & also print the confusion matrix"}}