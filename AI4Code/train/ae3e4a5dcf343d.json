{"cell_type":{"0bee9b1f":"code","11f8f631":"code","272e2efc":"code","4ba14e0d":"code","58ac2b8b":"code","c412c97b":"code","ac05e5d9":"code","ccfdd1b9":"code","8be6468a":"code","4ab75d7f":"code","8f2ffd73":"code","913ae231":"code","a75e13e7":"code","e9ca95b0":"code","92beab3f":"code","2753e18f":"code","e25d007a":"code","5d4cb18c":"code","c991e9a7":"code","5bc60033":"code","a562cf08":"code","29a626a1":"code","6df0fa15":"code","da64b39f":"code","cfac1bf3":"code","64753032":"code","d7a44d27":"code","431dd965":"code","ddedd762":"code","b579f272":"code","251eec05":"code","8b512eb9":"code","f80235b7":"code","3646bf2c":"code","ab99887b":"code","f53c6970":"markdown","4a0839c7":"markdown","05cf1324":"markdown","da4a0bdb":"markdown","abd50471":"markdown","3c70c13b":"markdown","3c95dd63":"markdown","b258fc44":"markdown","95ab9e53":"markdown"},"source":{"0bee9b1f":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torchvision import transforms, models\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, random_split, DataLoader, WeightedRandomSampler\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport time\nimport os\nfrom PIL import Image\n\n! pip install jovian\nimport jovian","11f8f631":"METADATA_COVID = '..\/input\/covid-chest-xray\/metadata.csv'\nCOVID_ROOT = '..\/input\/covid-chest-xray\/images'\n\nPNEUMONIA_ROOT = '..\/input\/chest-xray-pneumonia\/chest_xray'\nPNEUMONIA_TRAIN_ALL = PNEUMONIA_ROOT + '\/train'\n# PNEUMONIA_TRAIN = PNEUMONIA_ROOT+'\/train\/PNEUMONIA'\n# NORMAL_TRAIN = PNEUMONIA_ROOT+'\/train\/NORMAL'\n# PNEUMONIA_TEST = PNEUMONIA_ROOT+'\/test\/PNEUMONIA'\n# NORMAL_TEST = PNEUMONIA_ROOT+'\/test\/NORMAL'\n\n#target label\nTARGET_LABEL = {0: 'NORMAL',\n               1: 'PNEUMONIA',\n               2: 'COVID19'}\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nproject_name = 'chest X-ray'","272e2efc":"pneumonia_data = []\nfor dirname, _, filenames in os.walk(PNEUMONIA_TRAIN_ALL):\n    for filename in filenames:\n        if filename.endswith(\".jpeg\"):\n            pneumonia_data.append(os.path.join(dirname, filename))\n\nimage = []\nlabel = []\nfor i in range(len(pneumonia_data)):\n    image.append(pneumonia_data[i].split('\/')[-1])\n    label.append(pneumonia_data[i].split('\/')[-2])","4ba14e0d":"# pneoumonia and normal data\ndf_pneumonia = pd.DataFrame({\"label\": label, \"image_file\": image})\ndf_pneumonia.head()","58ac2b8b":"sns.countplot(df_pneumonia['label'])\nplt.title('Pneumonia train dataset');","c412c97b":"#covid19 data\ndf = pd.read_csv(METADATA_COVID)\ndf_pa = df.drop(df[df.view != 'PA'].index) #only take PA(from back to front film closer to chest) View\ncovid19 = df_pa[df_pa['finding']=='COVID-19'] #only take covid-19 label\ncovid19 = covid19[['finding', 'filename']] #take its label and image file\ncovid19.columns = (['label', 'image_file']) #change columns name same to pneumonia\n#covid19[covid19['image_file'].str.endswith('.gz')]\ncovid19.reset_index(drop=True, inplace=True)","ac05e5d9":"print('Data size:' , len(covid19))\ncovid19.head()","ccfdd1b9":"#takes normal and pneumonia only 300 images\nnormal = df_pneumonia[df_pneumonia['label']=='NORMAL']\nnormal = normal.sample(frac=1, axis=0, random_state=7).reset_index(drop=True) #suffle rows\nnormal = normal[:141] #same with covid19 data\n\npneumonia = df_pneumonia[df_pneumonia['label']=='PNEUMONIA']\npneumonia = pneumonia.sample(frac=1, axis=0, random_state=7).reset_index(drop=True)\npnuemonia = pneumonia[:141] #same with covid19 data\n\n#concat all data (covid, pneumonia and normal)\nall_data = pd.concat([normal, pnuemonia, covid19], ignore_index=True)\nall_data = all_data.sample(frac=1, axis=0, random_state=7).reset_index(drop=True)\nall_data.head(10)","8be6468a":"sns.countplot(all_data['label'])\nplt.title('All Datasets');","4ab75d7f":"#split dataset\nX_trainval, X_test, y_trainval, y_test = train_test_split(all_data['image_file'].values,\n                                                      all_data['label'].values, test_size=0.05,\n                                                      stratify=all_data['label'].values, random_state=7)\n\nX_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, stratify=y_trainval, test_size=0.1,\n                                                  random_state=7)\n\nlen(X_train), len(X_val), len(X_test)","8f2ffd73":"class Xray_split(Dataset):\n    def __init__(self, root_dir_pnue, root_dir_covid, X, y, transform=None):\n        self.pnue_root = root_dir_pnue\n        self.covid_root = root_dir_covid\n        self.X = X\n        self.y = y\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        image, label = self.X[idx], self.y[idx]\n        if self.y[idx] == 'COVID-19':\n            label = 2\n            img_fname = str(self.covid_root) + \"\/\" + str(image)\n            img = Image.open(img_fname).convert(\"L\")           \n            if self.transform:\n                img = self.transform(img)\n        \n        if self.y[idx] == 'NORMAL':\n            label = 0\n            img_fname = str(self.pnue_root) + \"\/NORMAL\/\" + str(image)\n            img = Image.open(img_fname)\n          \n \n            if self.transform:\n                img = self.transform(img)\n        \n        if self.y[idx] == 'PNEUMONIA':\n            label = 1\n            img_fname = str(self.pnue_root) + \"\/PNEUMONIA\/\" + str(image)\n            img = Image.open(img_fname)\n            \n            if self.transform:\n                img = self.transform(img)\n                \n        return img, int(label)","913ae231":"# mean = [0.4947]\n# std = [0.2226]\nmean = [0.0960, 0.0960, 0.0960]\nstd = [0.9341, 0.9341, 0.9341]\n\ntrain_transform = transforms.Compose([transforms.Resize((512, 512)),\n                                      transforms.Grayscale(3), #output 3 channel grayscale\n                                      transforms.RandomResizedCrop((224, 224)),\n                                      transforms.RandomRotation(15),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean, std)\n                                     ])\n\nval_transform = transforms.Compose([transforms.Resize((512, 512)),\n                                    transforms.Grayscale(3),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean, std),\n                                   ])\n\ntest_transform = transforms.Compose([transforms.Resize((512, 512)),\n                                     transforms.Grayscale(3),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean, std),\n                                   ])\n\n\ntrain_set = Xray_split(PNEUMONIA_TRAIN_ALL, COVID_ROOT, X_train, y_train, train_transform)\nval_set = Xray_split(PNEUMONIA_TRAIN_ALL, COVID_ROOT, X_val, y_val, val_transform)\ntest_set = Xray_split(PNEUMONIA_TRAIN_ALL, COVID_ROOT, X_test, y_test, test_transform)","a75e13e7":"#look the training data (already transformed)\nfig = plt.figure(figsize=(20, 5))\n\nfor i in range(30):\n    image, label = train_set[i]\n    ax = fig.add_subplot(3, 10, i+1, xticks=[], yticks = [])\n    ax.imshow(image[0], cmap='gray')\n    ax.set_title(TARGET_LABEL[label], color=(\"green\" if label == 0 else 'red'))","e9ca95b0":"#find the mean and std\n\n# nimages = 0\n# mean = 0.\n# std = 0.\n# for batch, _ in train_loader:\n#     # Rearrange batch to be the shape of [B, C, W * H]\n#     batch = batch.view(batch.size(0), batch.size(1), -1)\n#     # Update total number of images\n#     nimages += batch.size(0)\n#     # Compute mean and std here\n#     mean += batch.mean(2).sum(0) \n#     std += batch.std(2).sum(0)\n\n# # Final step\n# mean \/= nimages\n# std \/= nimages\n\n# print(mean)\n# print(std)","92beab3f":"batch_size = 32 #have used 64 and 128 but 32 works better\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size*2, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)","2753e18f":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(20, 25))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break","e25d007a":"show_batch(train_loader)","5d4cb18c":"#for get learning rate parameter\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\n#training loop\ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler):\n    torch.cuda.empty_cache()\n    \n    #save variabel\n    train_losses = []\n    test_losses = []\n    train_scores = []\n    val_score = []\n    lrs = []\n\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        train_score = 0\n        \n        #training loop#\n        for image, label in train_loader:\n            #training phase\n            model.train()\n            \n            image = image.to(device); label = label.to(device);\n            \n            output = model(image)\n            #accuracy calulcation\n            ps = torch.exp(output)\n            _, top_class = ps.topk(1, dim=1)\n            correct = top_class == label.view(*top_class.shape)\n            train_score += torch.mean(correct.type(torch.FloatTensor))\n            #loss\n            loss = criterion(output, label)\n            #backward pass\n            loss.backward()\n            #update weight\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            scheduler.step() \n            lrs.append(get_lr(optimizer))\n            running_loss += loss.item()\n            \n        else:\n            model.eval()\n            test_loss = 0\n            scores = 0\n            #validation loop#\n            with torch.no_grad():\n                for image, label in val_loader:\n                    image = image.to(device); label = label.to(device);\n\n                    output = model(image)\n\n                    #accuracy calulcation\n                    ps = torch.exp(output)\n                    _, top_class = ps.topk(1, dim=1)\n                    correct = top_class == label.view(*top_class.shape)\n                    scores += torch.mean(correct.type(torch.FloatTensor))\n                    #loss\n                    loss = criterion(output, label)                                  \n                    test_loss += loss.item()\n            \n            #calculation mean for each batch\n            train_losses.append(running_loss\/len(train_loader))\n            test_losses.append(test_loss\/len(val_loader))\n            train_scores.append(train_score\/len(train_loader))\n            val_score.append(scores\/len(val_loader))\n\n            print(\"Epoch: {}\/{}.. \".format(e+1, epochs),\n                  \"Train Loss: {:.3f}.. \".format(running_loss\/len(train_loader)),\n                  \"Val Loss: {:.3f}.. \".format(test_loss\/len(val_loader)),\n                  \"Train acc Score: {:.3f}.. \".format(train_score\/len(train_loader)),\n                  \"Val acc : {:.3f}.. \".format(scores\/len(val_loader)),\n                  \"Lr: {:.4f} \".format(get_lr(optimizer)),\n                  \"Time: {:.2f}s\" .format(time.time()-since)\n                 )\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses, \n               'train_acc': train_scores, 'val_acc':val_score, 'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)\/60))\n    return history\n\ndef plot_loss(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_loss'], label='Train_loss')\n    plt.plot(epoch, history['val_loss'], label='val_loss')\n    plt.title('Loss per epoch')\n    plt.ylabel('Loss')\n    plt.xlabel('epoch')\n    plt.legend(); \n    plt.show()\n\ndef plot_score(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_acc'], label='Train_acc')\n    plt.plot(epoch, history['val_acc'], label='val_acc')\n    plt.title('Accuracy per epoch')\n    plt.ylabel('score')\n    plt.xlabel('epoch')\n    plt.legend(); \n    plt.show()\n\ndef plot_lr(history):\n    plt.plot(history['lrs'], label='learning rate')\n    plt.title('One Cycle Learning Rate')\n    plt.ylabel('Learning Rate')\n    plt.xlabel('steps')\n    plt.legend(); \n    plt.show()","c991e9a7":"output_label = 3\n\nmodel_mobile = models.mobilenet_v2(pretrained=True)\n\nmodel_mobile.classifier = nn.Sequential(nn.Linear(in_features=1280, out_features=output_label))\n\nmodel_mobile.to(device);\nmodel_mobile","5bc60033":"max_lr = 0.0001\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_mobile.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, \n                                            steps_per_epoch=len(train_loader))\n\nhistory_mobile = fit(epoch, model_mobile, train_loader, val_loader, criterion, optimizer, sched)","a562cf08":"torch.save(model_mobile.state_dict(),'mobilenet.pth')\nplot_score(history_mobile, epoch)\nplot_loss(history_mobile, epoch)\nplot_lr(history_mobile)","29a626a1":"jovian.reset()\njovian.log_hyperparams(arch='mobile_net', \n                       epochs=epoch, \n                       lr=max_lr, \n                       scheduler='one-cycle', \n                       weight_decay=weight_decay,\n                       opt='Adam')\n\njovian.log_metrics(val_loss=history_mobile['val_loss'][-1], \n                   val_acc=history_mobile['val_acc'][-1].item(),\n                   train_loss=history_mobile['train_loss'][-1],\n                   time='7.79m')","6df0fa15":"model_resnet18 = models.resnet18(pretrained=True)\nmodel_resnet18.fc = nn.Linear(512, output_label)\n\nmodel_resnet18.to(device)\nmodel_resnet18","da64b39f":"max_lr = 0.0001\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_resnet18.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, \n                                            steps_per_epoch=len(train_loader))\n\nhistory_re18 = fit(epoch, model_resnet18, train_loader, val_loader, criterion, optimizer, sched)","cfac1bf3":"torch.save(model_resnet18.state_dict(),'resnet18.pth')\nplot_score(history_re18, epoch)\nplot_loss(history_re18, epoch)\nplot_lr(history_re18)","64753032":"jovian.log_hyperparams(arch='resnet18', \n                       epochs=epoch, \n                       lr=max_lr, \n                       scheduler='one-cycle', \n                       weight_decay=weight_decay, \n                       opt='Adam')\n\njovian.log_metrics(val_loss=history_re18['val_loss'][-1], \n                   val_acc=history_re18['val_acc'][-1].item(),\n                   train_loss=history_re18['train_loss'][-1],\n                   time='7.58m')","d7a44d27":"model_vgg16 = models.vgg16(pretrained=True)\nmodel_vgg16.classifier = nn.Sequential(nn.Linear(in_features=25088, out_features=30, bias=True),\n                                        nn.ReLU(inplace=True),\n                                        nn.Dropout(p=0.5, inplace=False),\n                                        nn.Linear(in_features=30, out_features=3, bias=True)\n                                       )\nmodel_vgg16.to(device)\nmodel_vgg16","431dd965":"optimizer = optim.Adam(model_vgg16.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, \n                                            steps_per_epoch=len(train_loader))\n\nhistory_vgg16 = fit(epoch, model_vgg16, train_loader, val_loader, criterion, optimizer, sched)","ddedd762":"torch.save(model_vgg16.state_dict(),'vgg16.pth')\nplot_score(history_vgg16, epoch)\nplot_loss(history_vgg16, epoch)\nplot_lr(history_vgg16)","b579f272":"jovian.log_hyperparams(arch='VGG16', \n                       epochs=epoch, \n                       lr=max_lr, \n                       scheduler='one-cycle', \n                       weight_decay=weight_decay, \n                       opt='Adam')\n\njovian.log_metrics(val_loss=history_vgg16['val_loss'][-1], \n                   val_acc=history_vgg16['val_acc'][-1].item(),\n                   train_loss=history_vgg16['train_loss'][-1],\n                   time='8.44m')","251eec05":"def predict_dataset(dataset, model):\n    model.eval()\n    model.to(device)\n    torch.cuda.empty_cache()\n    predict = []\n    y_true = []\n    for image, label in dataset:\n        #image = image.to(device); label= label.to(device)\n        image = image.unsqueeze(0)\n        image = image.to(device);\n        \n        output = model(image)\n        ps = torch.exp(output)\n        _, top_class = ps.topk(1, dim=1)\n        \n        predic = np.squeeze(top_class.cpu().numpy())\n        predict.append(predic)\n        y_true.append(label)\n    return list(y_true), list(np.array(predict).reshape(1,-1).squeeze(0))\n\ndef report(y_true, y_predict, title='MODEL OVER TEST SET'):\n    print(classification_report(y_true, y_predict))\n    sns.heatmap(confusion_matrix(y_true, y_predict), annot=True)\n    plt.yticks(np.arange(0.5, len(TARGET_LABEL)), labels=list(TARGET_LABEL.values()), rotation=0);\n    plt.xticks(np.arange(0.5, len(TARGET_LABEL)), labels=list(TARGET_LABEL.values()), rotation=45)\n    plt.title(title)\n    plt.show()\n    \ndef plot_predict(test_set, y_predict):\n    \"\"\"it takes longer time to plot, if you want it faster\n    comment or delete tight_layout\n    \"\"\"\n    fig = plt.figure(figsize=(20, 20))\n\n    for i in range(len(test_set)):\n        image, label = test_set[i]\n        ax = fig.add_subplot(4, 6, i+1, xticks=[], yticks = [])\n        ax.imshow(image[0], cmap='gray')\n        ax.set_title(\"{}({})\" .format(TARGET_LABEL[y_predict[i]], TARGET_LABEL[label]), \n                      color=(\"green\" if y_predict[i] == label else 'red'), fontsize=12)\n\n    plt.tight_layout() #want faster comment or delete this\n    plt.show()","8b512eb9":"y_true, y_predict = predict_dataset(test_set, model_mobile)\nreport(y_true, y_predict, title='Mobilenet_v2 Over Test Set')\nplot_predict(test_set, y_predict)","f80235b7":"y_true, y_predict = predict_dataset(test_set, model_resnet18)\nreport(y_true, y_predict, 'Resnet18')\nplot_predict(test_set, y_predict)","3646bf2c":"y_true, y_predict = predict_dataset(test_set, model_vgg16)\nreport(y_true, y_predict, 'VGG16')\nplot_predict(test_set, y_predict)","ab99887b":"jovian.commit(project=project_name, environment=None)","f53c6970":"# Import Library","4a0839c7":"## VGG16","05cf1324":"# Data Preparation","da4a0bdb":"## Resnet18","abd50471":"## Mobilenet_v2","3c70c13b":"# Evaluation and Report","3c95dd63":"# Modelling","b258fc44":"## Load All Data and Exploration","95ab9e53":"# Dataloader"}}