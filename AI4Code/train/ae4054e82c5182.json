{"cell_type":{"c2b776cd":"code","505c925a":"code","49efb01a":"code","5006f025":"code","008a2824":"code","dce684da":"code","5357fc36":"code","4c37e6b8":"code","81ba7029":"code","a7d17485":"code","18039a2d":"code","4a2d62c7":"code","3078374e":"code","10813dfd":"markdown","63efa465":"markdown","90b42085":"markdown","d6227194":"markdown"},"source":{"c2b776cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","505c925a":"# importing Natural Language Toolkit \nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","49efb01a":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import average_precision_score","5006f025":"df = pd.read_csv('..\/input\/fraud_email_.csv')\ndf.head()","008a2824":"df.isnull().any()","dce684da":"df = df.dropna()","5357fc36":"import nltk\nnltk.download('stopwords')","4c37e6b8":"stopset = set(stopwords.words(\"english\"))\nvectorizer = TfidfVectorizer(stop_words=stopset,binary=True)","81ba7029":"# Extract feature column 'Text'\nX = vectorizer.fit_transform(df.Text)\n# Extract target column 'Class'\ny = df.Class","a7d17485":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, train_size=0.80, random_state=42)","18039a2d":"clf = RandomForestClassifier(n_estimators=15)","4a2d62c7":"y_pred = clf.fit(X_train, y_train).predict_proba(X_test)","3078374e":"print(average_precision_score(y_test ,y_pred[:, 1]))","10813dfd":"## Test Train Split","63efa465":"# Introduction \n\nI have created this dataset and notebook due to lack of data for fraudulent emails for supervised learning algorithms. I faced this issue when I was developing an approach for one of my projects. This notebook only contains necessary steps, not complete EDA. Feel free to leave your feedback and valuable comment.","90b42085":"## Import Data and Libraries ","d6227194":"## Model"}}