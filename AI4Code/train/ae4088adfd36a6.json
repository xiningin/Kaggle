{"cell_type":{"ddd73524":"code","396d3c1f":"code","f8cfa359":"code","09241196":"code","1806faca":"code","79744f0a":"code","3bed9921":"code","79e5fa27":"code","0e9c4b1d":"code","2542a230":"code","87a13d94":"code","0834678d":"code","7a7bf4af":"code","58abbee1":"code","11203d3c":"code","6f96ee1f":"code","95ed91d0":"code","9cb8be2b":"code","7fe30828":"code","59da9eb1":"code","d0dbff8d":"code","1caee761":"code","c8393f1d":"code","ae9270da":"code","7b121698":"code","da2e0ef6":"code","48d1762c":"code","f3faa09d":"code","022c9405":"code","c33cc4b6":"code","4ed6ad70":"code","b388894e":"code","69b77dd4":"code","40888bb6":"code","549c32e0":"code","8cfad418":"code","8844cffc":"code","1732ae21":"code","3cd69dd2":"code","74b28fd5":"code","a4a1d83d":"code","2d16a593":"code","099aa8fd":"code","2990f023":"code","02c4afd8":"code","fd00149a":"code","fd26cf70":"code","c3ecd46e":"code","4066ac11":"code","e8df7b55":"code","7cb85099":"code","a5f870c5":"code","1627a37a":"code","42a87024":"code","d4b36008":"code","4d8121e8":"code","f006db00":"code","0d6d9356":"code","3404a1d6":"markdown","8c02eca6":"markdown","04fc785f":"markdown","fadb3dc3":"markdown","96aa8588":"markdown","5391594d":"markdown","e2d7cb90":"markdown","26003176":"markdown","8e9ab8dd":"markdown","4501a102":"markdown","418b2450":"markdown","f02ddb67":"markdown","4099aae7":"markdown","cf3419c7":"markdown","9c1e2dd3":"markdown","c843a82b":"markdown","2af78de8":"markdown","0898e81a":"markdown","33d35613":"markdown","abea4050":"markdown","761e1dba":"markdown","99983148":"markdown","9bd996db":"markdown","73d86aba":"markdown","65dc0da2":"markdown","d51d47e5":"markdown","1ea88093":"markdown","89b7d032":"markdown","1c7e1ecc":"markdown","e4616525":"markdown","790fa37c":"markdown","f4b4a999":"markdown","f97c1bb5":"markdown","07a0f77b":"markdown","b34e8031":"markdown","87e508b0":"markdown","13caf496":"markdown","1dd8aa31":"markdown","642cb451":"markdown","9f68def3":"markdown"},"source":{"ddd73524":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # For Bar Plots\nimport matplotlib as mpl\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","396d3c1f":"professionals = pd.read_csv('..\/input\/professionals.csv', parse_dates = ['professionals_date_joined'])\nstudents = pd.read_csv('..\/input\/students.csv', parse_dates = ['students_date_joined'])\ngroups = pd.read_csv('..\/input\/groups.csv')\ngroup_memberships = pd.read_csv('..\/input\/group_memberships.csv')\nemails = pd.read_csv('..\/input\/emails.csv', parse_dates = ['emails_date_sent'])\nmatches = pd.read_csv('..\/input\/matches.csv')\nquestions = pd.read_csv('..\/input\/questions.csv', parse_dates = ['questions_date_added'])\nanswers = pd.read_csv('..\/input\/answers.csv', parse_dates = ['answers_date_added'])\ntag_questions = pd.read_csv('..\/input\/tag_questions.csv')\ntags = pd.read_csv('..\/input\/tags.csv')\n\ntag_users = pd.read_csv('..\/input\/tag_users.csv')\ncomments = pd.read_csv('..\/input\/comments.csv')","f8cfa359":"#Function to show data labels on chart\ndef add_value_labels(ax, cntin, spacing=1):\n    # For each bar: Place a label\n    for rect in ax.patches:\n        # Get X and Y placement of label from rect.\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n\n        # Number of points between bar and label. Change to your liking.\n        space = spacing\n        # Vertical alignment for positive values\n        va = 'bottom'\n\n        # If value of bar is negative: Place label below bar\n        if y_value < 0:\n            # Invert space to place label below\n            space *= -1\n            # Vertically align label at top\n            va = 'top'\n\n        # Use Y value as label and format number with one decimal place\n        if cntin=='K':\n            label = \"{:.2f}\".format(y_value\/1000)+\"K\"\n        else:\n            label = \"{:.1f}\".format(y_value)\n\n        # Create annotation\n        ax.annotate(\n            label,                      # Use `label` as label\n            (x_value, y_value),         # Place label at end of the bar\n            xytext=(0, space),          # Vertically shift label by `space`\n            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n            ha='center',                # Horizontally center label\n            va=va)                      # Vertically align label differently for\n                                        # positive and negative values.\n","09241196":"print(\"Count of professionals and columns - \" + str(professionals.shape))\nprint(\"Unique Industries - \" + str(professionals.professionals_industry.nunique()))\nprint(\"Missing values in Industry - \" + str(professionals.professionals_industry.isna().sum()))\nprint(\"Unique Locations - \" + str(professionals.professionals_location.nunique()))\nprint(\"Missing values in Location - \" + str(professionals.professionals_location.isna().sum()))","1806faca":"professionals_industries = professionals.professionals_industry.value_counts().sort_values(ascending=True).tail(14)\nax = professionals_industries.plot(kind='barh',figsize=(10, 8),width=0.8) \nax.set_title(\"Top 14 industries Professionals belong to\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","79744f0a":"professionals_locations = professionals.professionals_location.value_counts().sort_values(ascending=True).tail(14)\nax = professionals_locations.plot(kind='barh',figsize=(10, 8),width=0.8) \nax.set_title(\"Top 14 Locations Professionals hail from\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","3bed9921":"import datetime\ndf_profs = professionals.copy()\ndf_profs['YearJoined']=df_profs['professionals_date_joined'].dt.year\nprof_yrjoined = df_profs.groupby('YearJoined').count()\nprof_yrjoined = prof_yrjoined.drop ('professionals_id',axis=1)\nprof_yrjoined = prof_yrjoined.drop ('professionals_location',axis=1)\nprof_yrjoined = prof_yrjoined.drop ('professionals_industry',axis=1)\nprof_yrjoined = prof_yrjoined.drop ('professionals_headline',axis=1)\nprof_yrjoined = prof_yrjoined.rename(columns={'professionals_date_joined':'Count'})\n\nprof_yrjoined.head()","79e5fa27":"plt.plot(prof_yrjoined, color='orange')\nplt.xlabel('Year Joined')\nplt.ylabel('Number of Professionals')\nplt.title('Trend of number of Professionals joining Career Village')\nplt.show()","0e9c4b1d":"import datetime\ndf_profs = professionals.copy()\ndf_profs['YearJoined']=df_profs['professionals_date_joined'].dt.year\nprof_yrjoined = df_profs[df_profs['YearJoined'].isin(['2016','2017','2018'])][['YearJoined','professionals_industry','professionals_date_joined']].groupby(['YearJoined','professionals_industry']).count()\n\nprof_yrjoined=prof_yrjoined[prof_yrjoined['professionals_date_joined'] > 109]\nprof_yrjoined = prof_yrjoined.rename(columns={'professionals_date_joined':'Count'})\ndf_profscopy = prof_yrjoined.unstack()\ndf_profscopy.plot(kind='barh', stacked=True, figsize=[16,6])","2542a230":"import datetime\ndf_profs = professionals.copy()\ndf_profs['YearJoined']=df_profs['professionals_date_joined'].dt.year\ndf_profs['Count'] = df_profs[df_profs['YearJoined'].isin(['2016','2017','2018'])][['YearJoined','professionals_industry','professionals_date_joined']].groupby(['YearJoined','professionals_industry']).transform('count')\n\nprof_yrjoined=df_profs[df_profs['Count'] > 109][['YearJoined','professionals_industry','Count']].drop_duplicates()\n\ngroup_size=prof_yrjoined.groupby('YearJoined').count()['Count'].tolist()\ngroup_names=prof_yrjoined['YearJoined'].unique().tolist()\nsubgroup_names=prof_yrjoined['professionals_industry'].tolist()\nsubgroup_size=prof_yrjoined['Count'].tolist()\n","87a13d94":"# Libraries\nimport matplotlib.pyplot as plt\n \n# Make data: I have 3 groups and 7 subgroups\n \n# Create colors\na, b, c=[plt.cm.Blues, plt.cm.Reds, plt.cm.Greens]\n \n# First Ring (outside)\nfig, ax = plt.subplots()\nax.axis('equal')\nmypie, _ = ax.pie(group_size, radius=1.3, labels=group_names, colors=[a(0.6), b(0.6), c(0.6)] )\nplt.setp( mypie, width=0.3, edgecolor='white')\n \n# Second Ring (Inside)\nmypie2, _ = ax.pie(subgroup_size, radius=3.5-0.3, labels=subgroup_names, labeldistance=0.8, colors=[a(0.5), a(0.4), a(0.3), b(0.5), b(0.4), c(0.6), c(0.5), c(0.4), c(0.3), c(0.2)])\nplt.setp( mypie2, width=0.4, edgecolor='white')\nplt.margins(0,0)\n \n# show it\nplt.show()","0834678d":"print(\"Count of Students and columns - \" + str(students.shape))\nprint(\"Unique Locations - \" + str(students.students_location.nunique()))\nprint(\"Missing values in Location - \" + str(students.students_location.isna().sum()))","7a7bf4af":"import datetime\ndf_students = students.copy()\ndf_students['YearJoined']=df_students['students_date_joined'].dt.year\nstudent_yrjoined = df_students.groupby('YearJoined').count()\nstudent_yrjoined = student_yrjoined.drop ('students_id',axis=1)\nstudent_yrjoined = student_yrjoined.drop ('students_location',axis=1)\nstudent_yrjoined = student_yrjoined.rename(columns={'students_date_joined':'Count'})\n\nstudent_yrjoined.head()","58abbee1":"plt.plot(student_yrjoined, color='orange')\nplt.xlabel('Year Joined')\nplt.ylabel('Number of Students')\nplt.title('Trend of number of Students joining Career Village')\nplt.show()","11203d3c":"students_locations = students.students_location.value_counts().sort_values(ascending=True).tail(14)\nax = students_locations.plot(kind='barh',figsize=(10, 8),width=0.8) \nax.set_title(\"Top 14 Locations Students hail from\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","6f96ee1f":"group_det = group_memberships.join(groups, how = 'inner').groupby('groups_group_type').count()\ngroup_det = group_det.drop ('group_memberships_user_id',axis=1)\ngroup_det = group_det.drop ('groups_id',axis=1)\ngroup_det = group_det.rename(columns={'group_memberships_group_id':'Count'})\ngroup_det","95ed91d0":"prof_grp = professionals.merge(group_memberships, how = 'left',\n                                            left_on ='professionals_id',\n                                            right_on ='group_memberships_user_id')\n\nprof_grp = pd.merge(groups, prof_grp, how='inner',\n                left_on ='groups_id',\n                right_on ='group_memberships_group_id')\n\nprof_grp=prof_grp.groupby('groups_group_type').count()\n\nprof_grp = prof_grp.rename(columns={'group_memberships_group_id':'Professionals_Count'})\nprof_grp[['Professionals_Count']]\n\nSt_grp = students.merge(group_memberships, how = 'left',\n                                            left_on ='students_id',\n                                            right_on ='group_memberships_user_id')\n\nSt_grp = pd.merge(groups, St_grp, how='inner',\n                left_on ='groups_id',\n                right_on ='group_memberships_group_id')\n\nSt_grp=St_grp.groupby('groups_group_type').count()\n\nSt_grp = St_grp.rename(columns={'group_memberships_group_id':'Students_Count'})\nSt_grp[['Students_Count']]\nallingrp=prof_grp[['Professionals_Count']].join(St_grp[['Students_Count']], how='inner')\nallingrp","9cb8be2b":"atag = pd.merge(answers, tag_questions, how = 'inner',\n                                            left_on ='answers_question_id',\n                                            right_on ='tag_questions_question_id')\nprint('Number of total tags are ' + str(len(atag)) + ' for ' + str(len(atag.answers_id.unique())) + ' questions')","7fe30828":"qtag = pd.merge(pd.merge(questions, tag_questions, how='inner',\n                                           left_on = 'questions_id',\n                                           right_on = 'tag_questions_question_id'),\n                                                tags, how='inner',\n                                                left_on='tag_questions_tag_id',\n                                                right_on='tags_tag_id')\nptag = pd.merge(pd.merge(professionals, tag_users, how='inner',\n                                           left_on = 'professionals_id',\n                                           right_on = 'tag_users_user_id'),\n                                                tags, how='inner',\n                                                left_on='tag_users_tag_id',\n                                                right_on='tags_tag_id')\nqtag=qtag.groupby('tags_tag_name').count()\nptag=ptag.groupby('tags_tag_name').count()\nqtag = qtag.rename(columns={'tag_questions_question_id':'TagsInQuestions'})\nptag = ptag.rename(columns={'tag_users_user_id':'TagsFollowedByProfessionals'})\ntagcounts=qtag[['TagsInQuestions']].join(ptag[['TagsFollowedByProfessionals']], how='inner')\ntagcounts=tagcounts[(tagcounts['TagsInQuestions'] > 100) & (tagcounts['TagsFollowedByProfessionals'] > 100)]\ntagcounts=tagcounts.sort_values(by=['TagsInQuestions'], ascending=False)\ntaglist=tagcounts.index[:].tolist()","59da9eb1":"import numpy as np\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nimport pandas as pd\n \n# y-axis in bold\nrc('font', size='10')\n \n# Values of each group\nbars1 = tagcounts['TagsInQuestions'].tolist()\nbars2 = tagcounts['TagsFollowedByProfessionals'].tolist()\n \n# Heights of bars1 + bars2\nbars = np.add(bars1, bars2).tolist()\n \n# The position of the bars on the x-axis\nr = list(range(0,len(tagcounts)))\n \n# Names of group and bar width\nnames= taglist\nbarWidth = 0.8\n \nplt.figure(figsize=(20, 8))  # width:20, height:8\n# Create brown bars\nplt.bar(r, bars1, color='#ff9700', edgecolor='white', align='edge', width=barWidth)\n# Create green bars (middle), on top of the firs ones\nplt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white',align='edge', width=barWidth)\n\nb1 = mpatches.Patch(facecolor='#ff9700', label='In Questions', linewidth = 0.5, edgecolor = 'black')\nb2 = mpatches.Patch(facecolor='#557f2d', label = 'Followed by Professionals', linewidth = 0.5, edgecolor = 'black')\nplt.legend(handles=[b1, b2], title=\"Tags\", loc=1, fontsize='12', fancybox=True)\n\n# Custom X axis\nplt.xticks(r, names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Tags\", fontsize=18)\nplt.ylabel(\"Count\", fontsize=18)\nplt.title(\"Popular Tags within questions vs tags followed by professionals\",fontsize=20)\n\n# Show graphic\nplt.show()","d0dbff8d":"questions_received = matches.merge(right=emails, how = 'left',\n                                            left_on ='matches_email_id',\n                                            right_on ='emails_id')\nemailsreceived = professionals.merge(right=emails, how = 'left',\n                                            left_on ='professionals_id',\n                                            right_on ='emails_recipient_id')\nanswersgiven_cnt = answers.groupby(['answers_author_id']).count()\nanswersgiven_cnt = answersgiven_cnt.sort_values('answers_author_id')\nanswersgiven_cnt = answersgiven_cnt.reset_index()\nanswersgiven_cnt = answersgiven_cnt.rename(columns={'answers_id': 'answers_given'})\nanswersgiven_cnt = answersgiven_cnt.drop(['answers_date_added','answers_body','answers_question_id'], axis=1)\n\nquestions_received_cnt = questions_received.groupby(['emails_recipient_id']).count()\nquestions_received_cnt = questions_received_cnt.sort_values('emails_recipient_id')\nquestions_received_cnt = questions_received_cnt.reset_index()\nquestions_received_cnt = questions_received_cnt.rename(columns={'emails_id': 'questions_received'})\nquestions_received_cnt = questions_received_cnt.drop(['matches_email_id','matches_question_id','emails_date_sent','emails_frequency_level'], axis=1)\n\nemailsreceived_cnt = emailsreceived.groupby(['emails_recipient_id','professionals_date_joined','professionals_location','professionals_industry']).count()\nemailsreceived_cnt = emailsreceived_cnt.sort_values('emails_recipient_id')\nemailsreceived_cnt = emailsreceived_cnt.reset_index()\nemailsreceived_cnt = emailsreceived_cnt.rename(columns={'emails_id': 'emails_received'})\nemailsreceived_cnt = emailsreceived_cnt.drop(['professionals_id','professionals_headline','emails_date_sent','emails_frequency_level'], axis=1)\n\nprof_e_q_det = emailsreceived_cnt.merge(questions_received_cnt, how='inner')\nprof_e_q_det = prof_e_q_det.merge(answersgiven_cnt, how='left',\n                                 left_on ='emails_recipient_id',\n                                 right_on ='answers_author_id')\nprof_e_q_det = prof_e_q_det.drop(['answers_author_id'],axis=1)\nprof_e_q_det = prof_e_q_det.fillna(0)\nprof_e_q_det.head()\n","1caee761":"plt.figure(figsize=(10,10))\nplt.scatter(prof_e_q_det['questions_received'],prof_e_q_det['answers_given'],  color='k', s=25, alpha=0.2)\nplt.xlim(-5, 90)\nplt.ylim(-5,50)\nplt.plot([-5,90], [-5,50], 'k-', color = 'r')\n\nplt.xlabel('Questions Received')\nplt.ylabel('Answers Given')\nplt.title('Questions Received vs Answers Given by Professionals')\nplt.legend()\nplt.show()","c8393f1d":"answers_tags = answers.merge(right=tag_questions, how = 'inner',\n                                            left_on ='answers_question_id',\n                                            right_on ='tag_questions_question_id')\nanswers_tags = answers_tags.merge(right=tag_users, how = 'left',\n                                            left_on =['tag_questions_tag_id','answers_author_id'],\n                                            right_on =['tag_users_tag_id','tag_users_user_id'])\n\nquestion_tags_followed = answers_tags.fillna(-1).groupby(['tag_questions_tag_id','tag_users_tag_id']).count()\nquestion_tags_followed = question_tags_followed.sort_values('tag_questions_tag_id')\nquestion_tags_followed = question_tags_followed.reset_index()\nquestion_tags_followed = question_tags_followed.rename(columns={'answers_id': 'Count'})\nquestion_tags_followed = question_tags_followed.merge(right=tags, how = 'inner',\n                                            left_on ='tag_questions_tag_id',\n                                            right_on ='tags_tag_id')\nquestion_tags_followed = question_tags_followed.drop(['answers_author_id','answers_question_id','answers_date_added','answers_body','tag_questions_question_id','tag_users_user_id','tags_tag_id'], axis=1)\nquestion_tags_followed.head(10)\n\n\n\n","ae9270da":"followed = question_tags_followed[question_tags_followed['tag_users_tag_id']>0]\nnotfollowed = question_tags_followed[question_tags_followed['tag_users_tag_id']<0]\nfoldf = pd.merge(followed, notfollowed, how='outer',\n                                left_on='tag_questions_tag_id',\n                                right_on='tag_questions_tag_id')\nfoldf['diff']=(foldf['Count_x']-foldf['Count_y']).abs()\nfoldf = foldf.sort_values('diff', ascending=False)\nfoldf=foldf.head(40)","7b121698":"import numpy as np\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nimport pandas as pd\n \n# y-axis in bold\nrc('font', size='10')\n \n# Values of each group\nbars1 = foldf['Count_x']\nbars2 = foldf['Count_y']\n\n\n# Heights of bars1 + bars2\nbars = np.add(bars1, bars2).tolist()\n \n# The position of the bars on the x-axis\nr = list(range(0,40))\n \n# Names of group and bar width\nnames= foldf['tags_tag_name_x']\nbarWidth = 0.8\n \nplt.figure(figsize=(20, 8))  # width:20, height:8\n# Create brown bars\nplt.bar(r, bars1, color='#ff9700', edgecolor='white', align='edge', width=barWidth)\n# Create green bars (middle), on top of the firs ones\nplt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white',align='edge', width=barWidth)\n\nb1 = mpatches.Patch(facecolor='#ff9700', label='Followed', linewidth = 0.5, edgecolor = 'black')\nb2 = mpatches.Patch(facecolor='#557f2d', label = 'Not Followed', linewidth = 0.5, edgecolor = 'black')\nplt.legend(handles=[b1, b2], title=\"Question Tags\", loc=1, fontsize='12', fancybox=True)\n\n# Custom X axis\nplt.xticks(r, names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Tags\", fontsize=18)\nplt.ylabel(\"Count\", fontsize=18)\nplt.title(\"Questions answered by professionals who followed tags or not\",fontsize=20)\n\n# Show graphic\nplt.show()","da2e0ef6":"followedtags=followed.copy()\nfollowedtags = followedtags[['tags_tag_name','Count']].sort_values('Count',ascending=True).tail(25)\nfollowedtags.set_index('tags_tag_name', inplace=True)\n\nax = followedtags.plot(kind='barh',figsize=(12, 8),width=0.8) \nax.set_title(\"Top 25 tags followed by Professionals who answered\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nax.set_ylabel('Tag Names', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","48d1762c":"notfollowedtags=answers_tags.copy()\nnotfollowedtags=notfollowedtags[notfollowedtags.tag_users_user_id.isnull()==True]\nnotfollowedtags = notfollowedtags.groupby(['answers_author_id','answers_id']).count()\nnotfollowedtags = notfollowedtags.reset_index()\n\nnotfollowedtags = notfollowedtags.groupby(['answers_author_id']).count()\nnotfollowedtags = notfollowedtags.rename(columns={'answers_id': 'Count'})\nnotfollowedtags = notfollowedtags.merge(right=professionals, how = 'inner',\n                                            left_on ='answers_author_id',\n                                            right_on ='professionals_id')\nnotfollowedtags = notfollowedtags.drop(['tag_questions_tag_id','tag_users_tag_id','answers_question_id','answers_date_added','answers_body','tag_questions_question_id','tag_users_user_id','professionals_headline'], axis=1)\n\nnotfollowedtags.head()","f3faa09d":"notfollowedtags_industry=notfollowedtags.copy()\nnotfollowedtags_industry = notfollowedtags_industry.groupby(['professionals_industry'])['Count'].sum()\nnotfollowedtags_industry = notfollowedtags_industry.reset_index()\nnotfollowedtags_industry = notfollowedtags_industry.sort_values('Count',ascending=True).tail(25)\nnotfollowedtags_industry.set_index('professionals_industry', inplace=True)\nax = notfollowedtags_industry.plot(kind='barh',figsize=(12, 8),width=0.8) \nax.set_title(\"Top 25 industries of professionals who answered but did not follow tags\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nax.set_ylabel('Industries', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","022c9405":"notfollowedtags_location=notfollowedtags.copy()\nnotfollowedtags_location = notfollowedtags_location.groupby(['professionals_location'])['Count'].sum()\nnotfollowedtags_location = notfollowedtags_location.reset_index()\nnotfollowedtags_location = notfollowedtags_location.sort_values('Count',ascending=True).tail(25)\nnotfollowedtags_location.set_index('professionals_location', inplace=True)\nax = notfollowedtags_location.plot(kind='barh',figsize=(12, 8),width=0.8) \nax.set_title(\"Top 25 Locations of professionals who answered but did not follow tags\", fontsize=20)\nax.set_xlabel('Number of Professionals', fontsize=12)\nax.set_ylabel('Industries', fontsize=12)\nfor p in ax.patches:\n     ax.annotate(str(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))","c33cc4b6":"print(\"Count of Questions and columns - \" + str(questions.shape))\nprint(\"Mail notifications sent for above questions - \" + str(emails.shape))\nprint(\"Questions mailed in above mails - \" + str(matches.shape))\nprint(\"Number of Questions for which mail notification sent - \" + str(matches.matches_question_id.nunique()))","4ed6ad70":"emails_matches = pd.merge(emails, matches, how='inner',\n                               left_on='emails_id',\n                               right_on='matches_email_id')\nemails_response = pd.merge(emails_matches, answers, how='left',\n                               left_on=['matches_question_id','emails_recipient_id'],\n                               right_on=['answers_question_id','answers_author_id'])\nemails_noresponse = emails_response[emails_response['answers_question_id'].isnull()]\nemails_noresponse = emails_noresponse.groupby(['emails_frequency_level']).count()\nemails_noresponse = emails_noresponse.rename(columns={'matches_question_id': 'Count'})\nemails_noresponse = emails_noresponse.reset_index()\n\nemails_freq_level_cnt = emails_matches.copy()\nemails_freq_level_cnt = emails_freq_level_cnt.groupby(['emails_frequency_level']).count()\nemails_freq_level_cnt = emails_freq_level_cnt.rename(columns={'matches_email_id': 'Count'})\nemails_freq_level_cnt = emails_freq_level_cnt.drop(['emails_id','emails_recipient_id','emails_date_sent','matches_question_id'],axis=1)\nemails_freq_level_cnt = emails_freq_level_cnt.reset_index()\n\nplt.figure(figsize=(20,12))\nax1=plt.subplot(221)\nemails_freq_level_cnt[['emails_frequency_level','Count']].plot(kind='bar', ax=ax1, legend=False, width=0.3)\n\nax1.set_title(\"Total Questions sent per Email Frequency level\", fontsize=15)\nax1.set_xticklabels(emails_freq_level_cnt['emails_frequency_level'], fontsize=10, rotation=30)\nadd_value_labels(ax1,'N')\n\nax2=plt.subplot(222)\nemails_noresponse[['emails_frequency_level','Count']].plot(kind='bar', ax=ax2, legend=False, width=0.3)\n\nax2.set_title(\"Response not received per Email Frequency level\", fontsize=15)\nax2.set_xticklabels(emails_noresponse['emails_frequency_level'], fontsize=10, rotation=30)\nadd_value_labels(ax2,'N')\n\n","b388894e":"import matplotlib.pyplot as plt\nfrom pandas.plotting import table\nplt.figure(figsize=(12,6))\n# plot chart\nax1 = plt.subplot(121, aspect='equal')\nemails_freq_level_cnt.plot(kind='pie', y = 'Count', ax=ax1, autopct='%1.2f%%', \n startangle=90, shadow=False, labels=emails_freq_level_cnt['emails_frequency_level'], legend = False, fontsize=11)\n\n# plot table\nax2 = plt.subplot(122)\nplt.axis('off')\ntbl = table(ax2, emails_freq_level_cnt, loc='center')\ntbl.auto_set_font_size(False)\ntbl.set_fontsize(9)\nplt.show()","69b77dd4":"yearmonthwise_emails=emails_matches.copy()\nyearmonthwise_emails['YearMailed']=yearmonthwise_emails['emails_date_sent'].dt.year\nyearmonthwise_emails['MonthMailed']=yearmonthwise_emails['emails_date_sent'].dt.month\n\nplt.figure(figsize=(20,12))\nax1=plt.subplot(221)\nyearmonthwise_emails[['YearMailed','emails_date_sent']].groupby('YearMailed').count().sort_values('YearMailed').plot(kind='bar', ax=ax1, legend=False)\nylabels = ['{:,.1f}'.format(y) + 'M' for y in ax1.get_yticks()\/1000000]\nax1.set_yticklabels(ylabels)\nadd_value_labels(ax1,'K')\n\nax2=plt.subplot(222)\nyearmonthwise_emails[['MonthMailed','emails_date_sent']].groupby('MonthMailed').count().sort_values('emails_date_sent', ascending=False).plot(kind='bar', ax=ax2, legend=False)\nylabels = ['{:,.1f}'.format(y) + 'M' for y in ax2.get_yticks()\/1000000]\nax2.set_yticklabels(ylabels)\nadd_value_labels(ax2,'K',spacing=2)","40888bb6":"answers_emails_response = emails_response[emails_response['answers_question_id'].isnull()==False]\nanswers_noemails_response=answers[~answers[['answers_question_id','answers_author_id']].apply(tuple,1).isin(emails_response[['matches_question_id','emails_recipient_id']].apply(tuple,1))]\nprint(\"Count of Answers and columns - \" + str(answers.shape))\nmcnt=emails_response[emails_response['answers_question_id'].isnull()==False].count()['emails_recipient_id']\nprint(\"Answers in response of Mail notifications - \" + str(mcnt))\nprint(\"Number of Professionals who answered without Mail notifications - \" + str(emails_response[emails_response['answers_question_id'].isnull()].emails_recipient_id.nunique()))\nprint(\"Number of Answers without Mail notifications - \" + str(answers_noemails_response.count()['answers_id']))","549c32e0":"dfProf = emails.groupby('emails_recipient_id').first().reset_index()\nanswers_noemails_response_prof=answers_noemails_response.copy()\nanswers_noemails_response_prof = pd.merge(answers_noemails_response, dfProf, how = 'left',\n                                    left_on='answers_author_id',\n                                    right_on='emails_recipient_id')\n\nanswers_noemails_response_prof.fillna('No_Prior_Email_Sent', inplace=True)\n\nplt.figure(figsize=(20,12))\nax1=plt.subplot(221)\nanswers_emails_response[['emails_frequency_level','answers_question_id']].groupby('emails_frequency_level').count().plot(kind='bar', ax=ax1, legend=False, width=0.3)\nadd_value_labels(ax1,'N')\nax1.set_title(\"Answered questions in response to mail\", fontsize=20)\nax1.set_xlabel('')\n\nax2=plt.subplot(222)\nanswers_noemails_response_prof[['emails_frequency_level','answers_id']].groupby('emails_frequency_level').count().plot(kind='bar', ax=ax2, legend=False, width=0.3)\nax2.set_xlabel('')\nax2.set_title(\"Answered questions without mail notification\", fontsize=20)\nadd_value_labels(ax2,'N')\n","8cfad418":"questions_sent_mean_yearly = emails_matches.copy()\nquestions_sent_mean_yearly['YearSent']=questions_sent_mean_yearly['emails_date_sent'].dt.year\nquestions_sent_mean_yearly = questions_sent_mean_yearly.groupby(['YearSent','matches_question_id']).count().reset_index().groupby('YearSent')['emails_id'].mean()\n\nanswers_mean_yearly = answers.copy()\nanswers_mean_yearly = answers_mean_yearly.merge(questions, how='inner',\n                                               left_on='answers_question_id',\n                                               right_on='questions_id')\nanswers_mean_yearly['YearAsked']=answers_mean_yearly['questions_date_added'].dt.year\nanswers_mean_yearly = answers_mean_yearly.groupby(['YearAsked','answers_question_id']).count().reset_index().groupby('YearAsked')['questions_id'].mean()\n\nplt.figure(figsize=(20,12))\nax1=plt.subplot(221)\nax1 = questions_sent_mean_yearly.plot(kind='barh',width=0.5) \nax1.set_title(\"Average number of mails sent per question year wise\", fontsize=15)\nfor p in ax1.patches:\n     ax1.annotate(str(\"{:.2f}\".format(p.get_width())), (p.get_width() * 1.005, p.get_y() * 1.005))\n\nax2=plt.subplot(222)\nax2 = answers_mean_yearly.plot(kind='barh',width=0.5) \nax2.set_title(\"Average number of answers per question year wise\", fontsize=15)\nfor p in ax2.patches:\n     ax2.annotate(str(\"{:.2f}\".format(p.get_width())), (p.get_width() * 1.005, p.get_y() * 1.005))","8844cffc":"questions_det_cnt = questions.copy()\nquestions_det_cnt['YearAsked']=questions_det_cnt['questions_date_added'].dt.year\nquestions_yrly_cnt = questions_det_cnt.groupby('YearAsked').count().reset_index()\nquestions_yrly_cnt = questions_yrly_cnt.rename(columns={'questions_id': 'questions_asked'})\nquestions_yrly_cnt = questions_yrly_cnt.drop(['questions_author_id','questions_date_added','questions_title','questions_body'],axis=1)\n\nquestions_yrly_cnt_notanswered = questions_det_cnt[~questions_det_cnt.questions_id.isin(answers.answers_question_id)][['YearAsked','questions_id']].groupby('YearAsked').count().reset_index()\nquestions_yrly_cnt_notanswered = questions_yrly_cnt_notanswered.rename(columns={'questions_id': 'not_answered'})\n\nquestions_yrly_cnt = questions_yrly_cnt.merge(questions_yrly_cnt_notanswered, how='left',\n                                           left_on='YearAsked',\n                                           right_on='YearAsked')\n\nquestions_yrly_cnt.fillna(0, inplace=True)\n\n\nquestions_yrly_cnt['percent_notanswered']= 100 * (questions_yrly_cnt['not_answered'] \/ questions_yrly_cnt['questions_asked'])\nquestions_yrly_cnt.head(10)\n\n","1732ae21":"questions_yrly_cnt_chart = questions_yrly_cnt.copy()\nquestions_yrly_cnt_chart = questions_yrly_cnt_chart.drop(['percent_notanswered'],axis=1)\nplt.figure(figsize=(20,12))\nax1=plt.subplot(221)\nquestions_yrly_cnt_chart.groupby('YearAsked').sum().plot(kind='bar', ax=ax1, legend=True, width=0.5)\n\nax1.set_title(\"Questions Asked vs Questions Unanswered year wise\", fontsize=20)\nax1.set_xlabel('')\nadd_value_labels(ax1,'N')\n\n\nquestions_yrly_cnt_chart=questions_yrly_cnt_chart[questions_yrly_cnt['not_answered']>0]\n\ncolors = ['yellowgreen','red','violet','lightskyblue','white','lightcoral']\nx=questions_yrly_cnt_chart['YearAsked']\ny=questions_yrly_cnt_chart['not_answered']\nporcent = 100.*y\/y.sum()\n\nax2=plt.subplot(222)\nax2, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)\nlabels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]\n\nplt.legend(ax2, labels, loc='upper right', bbox_to_anchor=(-0.1, 1.),\n           fontsize=8)\nplt.title(\"% Distribution of questions unanswered till date\", fontsize=20)\nsort_legend = True\nif sort_legend:\n    ax2, labels, dummy =  zip(*sorted(zip(ax2, labels, y),\n                                          key=lambda x: x[2],\n                                          reverse=True))","3cd69dd2":"speedtoanswer = answers.copy()\n#speedtoanswer['YearAnswered']=speedtoanswer['answers_date_added'].dt.year\nspeedtoanswer=speedtoanswer.sort_values(['answers_question_id','answers_date_added'], ascending=True).groupby('answers_question_id').first()\nspeedtoanswer=speedtoanswer.merge(questions, how='inner',\n                                     left_on='answers_question_id',\n                                     right_on='questions_id')\nspeedtoanswer['first_answer_days']=speedtoanswer['answers_date_added']-speedtoanswer['questions_date_added']\nspeedtoanswer['first_answer_days']=speedtoanswer['first_answer_days']\/ np.timedelta64(1, 'D')\nspeedtoanswer['YearAsked']=speedtoanswer['questions_date_added'].dt.year\nspeedtoanswer=speedtoanswer.groupby('YearAsked')['first_answer_days'].mean()\nspeedtoanswer.head(10)","74b28fd5":"plt.plot(speedtoanswer, color='orange')\nplt.xlabel('Year Joined')\nplt.ylabel('Average speed')\nplt.title('Trend of average days to get first answer for the questions asked')\nplt.show()","a4a1d83d":"activitylevel_prof = answers.copy()\nactivitylevel_prof = activitylevel_prof.merge(professionals, how='inner',\n                                             left_on='answers_author_id',\n                                             right_on='professionals_id')\nactivitylevel_prof['ProfJoiningYear']=activitylevel_prof['professionals_date_joined'].dt.year\nactivitylevel_prof['TimeToAnswer']=(activitylevel_prof['answers_date_added']-activitylevel_prof['professionals_date_joined']).abs()\nactivitylevel_prof['TimeToAnswer']=activitylevel_prof['TimeToAnswer']\/ np.timedelta64(1, 'D')\nactivitylevel_prof['WeekofAnswer']=round(activitylevel_prof['TimeToAnswer']\/7,0)\nactivitylevel_prof=activitylevel_prof.groupby(pd.cut(activitylevel_prof['WeekofAnswer'],np.arange(0, 400, 25))).count()['answers_id']\n\nax = activitylevel_prof.plot.bar(rot=0, color=\"b\", figsize=(20,6))\nadd_value_labels(ax,'N')\nplt.xlabel('Week after joining')\nplt.ylabel('Number of questions answered')\nplt.title('Trend of number of questions answered by professionals since joining')\nplt.show()\n","2d16a593":"ans_mailsent=emails_response[emails_response['answers_question_id'].isnull()==False][['answers_id','answers_question_id','answers_author_id','answers_date_added']]\nans_nomailsent=answers_noemails_response.copy()\nans_nomailsent=answers_noemails_response[['answers_id','answers_question_id','answers_author_id','answers_date_added']]\nq_ans = questions.copy()\nq_ans['YearAsked']=q_ans['questions_date_added'].dt.year\nans_mailsent=ans_mailsent.merge(q_ans, how='inner',\n                               left_on='answers_question_id',\n                               right_on='questions_id')\nans_mailsent['DaysToAnswer_MailSent']=ans_mailsent['answers_date_added']-ans_mailsent['questions_date_added']\nans_mailsent['DaysToAnswer_MailSent'] = ans_mailsent['DaysToAnswer_MailSent'] \/ np.timedelta64(1, 'D')\nans_mailsent=ans_mailsent.groupby('YearAsked')['DaysToAnswer_MailSent'].mean().reset_index()\n\nans_nomailsent=ans_nomailsent.merge(q_ans, how='inner',\n                               left_on='answers_question_id',\n                               right_on='questions_id')\nans_nomailsent['DaysToAnswer_NoMailSent']=ans_nomailsent['answers_date_added']-ans_nomailsent['questions_date_added']\nans_nomailsent['DaysToAnswer_NoMailSent'] = ans_nomailsent['DaysToAnswer_NoMailSent'] \/ np.timedelta64(1, 'D')\nans_nomailsent=ans_nomailsent.groupby('YearAsked')['DaysToAnswer_NoMailSent'].mean().reset_index()\n\nans_avgspeedtoanswer = ans_nomailsent.merge(ans_mailsent, how='outer',\n                                           left_on='YearAsked',\n                                           right_on='YearAsked')\nans_avgspeedtoanswer.set_index('YearAsked')","099aa8fd":"ans_avgspeedtoanswer.plot(x='YearAsked', y=['DaysToAnswer_NoMailSent', 'DaysToAnswer_MailSent'], color=['green','blue'])\nplt.xlabel('Year When Question Added')\nplt.ylabel('Average speed to Answer')\nplt.title('Trend of average days taken to answer when mail sent and without mail notification')\nplt.show()","2990f023":"answers_prof_student_loc = answers.copy()\nanswers_prof_student_loc = answers_prof_student_loc.merge(professionals, how='inner',\n                                                         left_on='answers_author_id',\n                                                         right_on='professionals_id')\nanswers_prof_student_loc = answers_prof_student_loc.merge(questions, how='inner',\n                                                         left_on='answers_question_id',\n                                                         right_on='questions_id')\nanswers_prof_student_loc = answers_prof_student_loc.merge(students, how='inner',\n                                                         left_on='questions_author_id',\n                                                         right_on='students_id')\nanswers_prof_student_loc = answers_prof_student_loc[['professionals_location', 'professionals_industry','students_location']]\n\n# group by industry and professionals location to get number of unique locations of professionals\nanswers_prof_ind_loc = answers_prof_student_loc.groupby(['professionals_industry','professionals_location']).count().reset_index()\nanswers_prof_ind_loc = answers_prof_ind_loc.groupby(['professionals_industry']).count()['professionals_location'].reset_index()\nanswers_prof_ind_loc = answers_prof_ind_loc.rename(columns={'professionals_location': 'ProfessionalCount'})\n\n# group by industry and students location to get number of unique locations of students\nanswers_stud_ind_loc = answers_prof_student_loc.groupby(['professionals_industry','students_location']).count().reset_index()\nanswers_stud_ind_loc = answers_stud_ind_loc.groupby(['professionals_industry']).count()['students_location'].reset_index()\nanswers_stud_ind_loc = answers_stud_ind_loc.rename(columns={'students_location': 'StudentCount'})\n\nindustrywise_locations = answers_stud_ind_loc.merge(answers_prof_ind_loc, how='outer',\n                                                   left_on='professionals_industry',\n                                                   right_on='professionals_industry')\nindustrywise_locations=industrywise_locations.sort_values('ProfessionalCount', ascending=False).head(50)\nindustrywise_locations.head(10)","02c4afd8":"import numpy as np\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nimport pandas as pd\n \n# y-axis in bold\nrc('font', size='10')\n \n# Values of each group\nbars1 = industrywise_locations['ProfessionalCount']\nbars2 = industrywise_locations['StudentCount']\n\n\n# Heights of bars1 + bars2\nbars = np.add(bars1, bars2).tolist()\n \n# The position of the bars on the x-axis\nr = list(range(0,50))\n \n# Names of group and bar width\nnames= industrywise_locations['professionals_industry']\nbarWidth = 0.8\n \nplt.figure(figsize=(20, 8))  # width:20, height:8\n# Create brown bars\nplt.bar(r, bars1, color='#ff9700', edgecolor='white', align='edge', width=barWidth)\n# Create green bars (middle), on top of the firs ones\nplt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white',align='edge', width=barWidth)\n\nb1 = mpatches.Patch(facecolor='#ff9700', label='Unique Professional Locations', linewidth = 0.5, edgecolor = 'black')\nb2 = mpatches.Patch(facecolor='#557f2d', label = 'Unique Student Locations', linewidth = 0.5, edgecolor = 'black')\nplt.legend(handles=[b1, b2], title=\"Question Tags\", loc=1, fontsize='12', fancybox=True)\n\n# Custom X axis\nplt.xticks(r, names)\nplt.xticks(rotation=90)\nplt.xlabel(\"Industry\", fontsize=18)\nplt.ylabel(\"Unique Locations\", fontsize=18)\nplt.title(\"Number of Unique locations of professionals and students industry wise\",fontsize=20)\n\n# Show graphic\nplt.show()","fd00149a":"#remove_punctuation\ndef replacepuntuation(s):\n    import string\n    for c in string.punctuation:\n        s=s.replace(c,\" \")\n    return s","fd26cf70":"#Function to create bag of words for professionals to be able to recommend relevant questions\ndef create_profinfo_textlib(q_date):\n    professionals_info = tag_users.merge(right=tags, how = 'left',\n                                            left_on ='tag_users_tag_id',\n                                            right_on ='tags_tag_id')\n\n    professionals_info=professionals_info.drop(['tags_tag_id','tag_users_tag_id'],axis=1)\n    professionals_info =professionals_info.pivot_table(index='tag_users_user_id',values='tags_tag_name',aggfunc=lambda x: \" \".join(x))\n    professionals_info = professionals.merge(professionals_info, how='left',\n                                            left_on='professionals_id',\n                                            right_on='tag_users_user_id')\n    professionals_info = professionals_info[professionals_info['professionals_date_joined']<=q_date]\n    professionals_info=professionals_info.fillna('')\n    professionals_info['bow']= professionals_info['professionals_headline'] + ' ' + professionals_info['tags_tag_name']\n    professionals_info['ibow']=professionals_info['professionals_industry']\n    professionals_info=professionals_info.drop(['professionals_location','professionals_industry', 'professionals_headline', 'professionals_date_joined', 'tags_tag_name'],axis=1)\n    professionals_answers=professionals_info.merge(answers, how='left',\n                                            left_on='professionals_id',\n                                            right_on='answers_author_id')\n    professionals_answers=professionals_answers.merge(questions, how='left',\n                                            left_on='answers_question_id',\n                                            right_on='questions_id')\n\n    professionals_answers_tags=professionals_answers.merge(tag_questions, how='left',\n                                            left_on='answers_question_id',\n                                            right_on='tag_questions_question_id')\n\n\n    professionals_answers_tags = professionals_answers_tags.merge(right=tags, how = 'left',\n                                            left_on ='tag_questions_tag_id',\n                                            right_on ='tags_tag_id')\n    professionals_answers_tags=professionals_answers_tags.drop(['bow','answers_id','tag_questions_tag_id','tag_questions_question_id','tags_tag_id','answers_author_id','answers_question_id','answers_date_added','answers_body','questions_id','questions_author_id','questions_date_added','questions_title','questions_body'],axis=1)\n    professionals_answers_tags=professionals_answers_tags.fillna('')\n    professionals_answers_tags =professionals_answers_tags.pivot_table(index='professionals_id',values='tags_tag_name',aggfunc=lambda x: \" \".join(x))\n\n    professionals_answers=professionals_answers.fillna('')\n    professionals_answers['qbow']= professionals_answers['questions_title'] + ' ' + professionals_answers['questions_body']\n    professionals_answers=professionals_answers.drop(['bow','answers_id','answers_author_id','answers_question_id','answers_date_added','answers_body','questions_id','questions_author_id','questions_date_added','questions_title','questions_body'],axis=1)\n    professionals_answers =professionals_answers.pivot_table(index='professionals_id',values='qbow',aggfunc=lambda x: \" \".join(x))\n    professionals_info=professionals_info.merge(professionals_answers, how='left',\n                                            left_on='professionals_id',\n                                            right_on='professionals_id')\n    professionals_info=professionals_info.merge(professionals_answers_tags, how='left',\n                                            left_on='professionals_id',\n                                            right_on='professionals_id')\n    \n    professionals_info['qbow']=professionals_info['qbow'] + ' ' +  professionals_info['tags_tag_name']\n    professionals_info=professionals_info.drop(['tags_tag_name'], axis=1)\n    return professionals_info","c3ecd46e":"#Function to create bag of words for questions to find similar questions asked by other students\ndef create_quesinfo_textlib(q_date):\n    question_info = questions.copy()\n    question_info['bow']=question_info['questions_title'] + ' ' + question_info['questions_body']\n    question_info = question_info[question_info['questions_date_added']<=q_date]\n    question_tags = question_info.merge(right=tag_questions, how = 'left',\n                                            left_on ='questions_id',\n                                            right_on ='tag_questions_question_id')\n\n    question_tags = question_tags.merge(right=tags, how = 'left',\n                                            left_on ='tag_questions_tag_id',\n                                            right_on ='tags_tag_id')\n\n    question_tags=question_tags.drop(['questions_author_id','questions_date_added', 'questions_title','questions_body','bow','tag_questions_question_id','tags_tag_id'],axis=1)\n    question_tags=question_tags.fillna('')\n    question_tags =question_tags.pivot_table(index='questions_id',values='tags_tag_name',aggfunc=lambda x: \" \".join(x))\n    question_tags.head()\n\n    question_info = question_info.merge(question_tags, how='left',\n                                            left_on='questions_id',\n                                            right_on='questions_id')\n    \n    question_info = question_info[['questions_id','bow','tags_tag_name']]\n    return question_info","4066ac11":"# This is the start point when any question is asked in system. Pass questions_id as parameter to my recommendation engine\n# Below are the different question ids I have tested my recommender. \nq_id='2f6a9a99d9b24e5baa50d40d0ba50a75'\nq_id='eb0027b3dcd04d88b76a493fc1558c15'\nq_id='4c6d71aaf2724b9f8d439ae086d4f3da'\nq_id='caca9ab7e13d4297a82b9abe8f11f0b8'\nq_id='eb80205482e4424cad8f16bc25aa2d9c'\nq_id='baa937b4cd184a22acfd76249d25042c'\nq_id='6351c23f2e144b359c3301d40b3d81ef'\nq_id='c9bd1bedf1e341799026ea304dec6e3c'\n\n#Find the question date based on which we will create dictionary of questions and professional details\nquest = questions[questions['questions_id']==q_id]\nq_date=quest['questions_date_added'].values[0]\n\n#Create bag of words for finding similar questions\nquestion_info=create_quesinfo_textlib(q_date)\n\n#Create bag of words to find professionals whom to recommend this question\nprofessionals_info=create_profinfo_textlib(q_date)","e8df7b55":"# Using TF-IDF model we will compare bag of words of question asked with professionals which existed when question was asked\n#Below we are creating questions dictionary which existed when question was asked\nimport gensim\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\n\nprint(\"Number of Questions:\",len(question_info['bow']))\nprint(\"Tokenizing data...\")\ngen_docs = [[replacepuntuation(w.lower()) for w in word_tokenize(text)] \n            for text in question_info['bow']]\nprint(\"Creating dictionary...\")\ndictionary = gensim.corpora.Dictionary(gen_docs)\nprint(\"Creating Document-Term Matrix...\")\ncorpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\nprint(\"Creating TF-IDF Model...\")\ntf_idf = gensim.models.TfidfModel(corpus)\nprint(\"Creating Similarity Checker...\")\n\nsims = gensim.similarities.Similarity(\"\",tf_idf[corpus],num_features=len(dictionary))\nprint(\"Processing Completed!\")","7cb85099":"import warnings\nwarnings.filterwarnings(\"ignore\")\n# compare bag of words of questions asked and other questions dictionary\nquestion_asked = question_info[question_info['questions_id']==q_id]\nQuery=question_asked['bow'].values[0]\nqtags=question_asked['tags_tag_name'].values[0]\n\nquery_doc = [replacepuntuation(w.lower()) for w in word_tokenize(Query)]\nquery_doc_bow = dictionary.doc2bow(query_doc)\nquery_doc_tf_idf = tf_idf[query_doc_bow]\nsim_threshold=0.40\nsim=sims[query_doc_tf_idf]\nquestion_info['sim']=sim\nsimilar_questions=question_info[(question_info['sim']>=sim_threshold) & (question_info['sim'] < 1)]\nsimilar_questions=similar_questions.sort_values('sim',ascending=False)\ntop3_simq = similar_questions\ntop3_simq_ans = top3_simq[top3_simq['questions_id'].isin(answers['answers_question_id'])]\ntop3_simq_ans= top3_simq_ans.merge(answers, how='left',\n                                  left_on='questions_id',\n                                  right_on='answers_question_id')\ntop3_simq_ans= top3_simq_ans.merge(professionals,how='left',\n                                  left_on='answers_author_id',\n                                  right_on='professionals_id')\n\n#Use sklearn to find the closest match to the industry when we find similar questions \nimport nltk, string\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nremove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n\ndef normalize(text):\n    return nltk.word_tokenize(text.lower().translate(remove_punctuation_map))\n\nvectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n\ndef cosine_sim(text1, text2):\n    tfidf = vectorizer.fit_transform([text1, text2])\n    return ((tfidf * tfidf.T).A)[0,1]\n\n#Extract bag of words of similar questions and industry names of professionals who answered those questions\nindustries= top3_simq_ans[top3_simq_ans['professionals_industry'].isnull()==False][['professionals_industry','bow']].values.tolist()\n#industries= top3_simq_ans[top3_simq_ans['professionals_industry'].isnull()==False][['professionals_industry']].values.flatten()\ntop3_simq = top3_simq_ans[top3_simq_ans['professionals_industry'].isnull()==False][['bow']].values.flatten()\np_rank = pd.DataFrame( columns=['industry','bow', 'cos'])\ni = 0\nwhile i < len(industries):\n    cos = cosine_sim(qtags, industries[i][0])\n    p_rank.loc[i] = industries[i][0],industries[i][1],cos\n    i += 1\n\n#Filter industry names who are closest match\nindustry_list=np.unique(p_rank[p_rank['cos']>0].values[:,0]).flatten()\n#top3_simq=np.unique(p_rank[p_rank['cos']>0].values[:,1]).flatten()\n\n#Extract question tags of question asked\nquestions_bow1=qtags\n#Extract question title and body of asked question as well as similar questions as found by TF-IDF similarity checker\nquestions_bow2=Query + ' ' + ' '.join(top3_simq)\n#EXtract the relevant industry names\nquestions_bow3=' '.join(industry_list)\nprint(questions_bow1)                        \nprint(questions_bow2)                        \nprint(questions_bow3)  ","a5f870c5":"# Using TF-IDF model we will compare bag of words of question with professionals bag of words \n#which existed when question was asked\n#Below we are creating professionals dictionary for professionals which existed in system when question was asked\n#3 comparisions will be done to get relevant professional matches\n#This is the first dictionary of professionals which will contain their details like headline and tags they follow\nimport gensim\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\n\nprint(\"Number of Professionals:\",len(professionals_info['bow']))\nprint(\"Tokenizing data...\")\ngen_docs_prof = [[replacepuntuation(w.lower()) for w in word_tokenize(text)] \n            for text in professionals_info['bow']]\nprint(\"Creating dictionary...\")\ndictionary_prof = gensim.corpora.Dictionary(gen_docs_prof)\nprint(\"Creating Document-Term Matrix...\")\ncorpus_prof = [dictionary_prof.doc2bow(gen_doc) for gen_doc in gen_docs_prof]\nprint(\"Creating TF-IDF Model...\")\ntf_idf_prof = gensim.models.TfidfModel(corpus_prof)\nprint(\"Creating Similarity Checker...\")\nsims_prof = gensim.similarities.Similarity(\"\",tf_idf_prof[corpus_prof],num_features=len(dictionary_prof))\nprint(\"Processing Completed!\")","1627a37a":"#3 comparisions will be done to get relevant professional matches\n#This is the second dictionary of professionals which will contain their details like questions they answered earlier\nimport gensim\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\n\nprint(\"Number of Professionals:\",len(professionals_info['qbow']))\nprint(\"Tokenizing data for professionals answers...\")\ngen_docs_prof_q = [[replacepuntuation(w.lower()) for w in word_tokenize(text)] \n            for text in professionals_info['qbow']]\nprint(\"Creating dictionary...\")\ndictionary_prof_q = gensim.corpora.Dictionary(gen_docs_prof_q)\nprint(\"Creating Document-Term Matrix...\")\ncorpus_prof_q = [dictionary_prof_q.doc2bow(gen_doc) for gen_doc in gen_docs_prof_q]\nprint(\"Creating TF-IDF Model...\")\ntf_idf_prof_q = gensim.models.TfidfModel(corpus_prof_q)\nprint(\"Creating Similarity Checker...\")\nsims_prof_q = gensim.similarities.Similarity(\"\",tf_idf_prof_q[corpus_prof_q],num_features=len(dictionary_prof_q))\nprint(\"Processing Completed!\")","42a87024":"#3 comparisions will be done to get relevant professional matches\n#This is the third dictionary of professionals which will contain their details like Industry they belong to\nimport gensim\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\n\nprint(\"Number of Professionals:\",len(professionals_info['ibow']))\nprint(\"Tokenizing data for professionals industry...\")\ngen_docs_prof_i = [[replacepuntuation(w.lower()) for w in word_tokenize(text)] \n            for text in professionals_info['ibow']]\nprint(\"Creating dictionary...\")\ndictionary_prof_i = gensim.corpora.Dictionary(gen_docs_prof_i)\nprint(\"Creating Document-Term Matrix...\")\ncorpus_prof_i = [dictionary_prof_i.doc2bow(gen_doc) for gen_doc in gen_docs_prof_i]\nprint(\"Creating TF-IDF Model...\")\ntf_idf_prof_i = gensim.models.TfidfModel(corpus_prof_i)\nprint(\"Creating Similarity Checker...\")\nsims_prof_i = gensim.similarities.Similarity(\"\",tf_idf_prof_i[corpus_prof_i],num_features=len(dictionary_prof_i))\nprint(\"Processing Completed!\")","d4b36008":"import warnings\nwarnings.filterwarnings(\"ignore\")\n#3 comparisions will be done to get relevant professional matches\n#we saw dictionary of professionals which will contain their details. Each one will be compared with similar dictionary\n#for questions we seen above. I have given weights and thresholds for the similarity match of all 3 comparisions\n#depending on the importance of the data based on analysis done\n\nquery_doc1 = [replacepuntuation(w.lower()) for w in word_tokenize(questions_bow1)]\nquery_doc2 = [replacepuntuation(w.lower()) for w in word_tokenize(questions_bow2)]\nquery_doc3 = [replacepuntuation(w.lower()) for w in word_tokenize(questions_bow3)]\n\nquery_doc_bow = dictionary_prof.doc2bow(query_doc1)\nquery_doc_tf_idf = tf_idf_prof[query_doc_bow]\nsim1_threshold=0.1\nsim1=sims_prof[query_doc_tf_idf]\nprofessionals_info['sim1']=sim1\n\nquery_doc_bow_q= dictionary_prof_q.doc2bow(query_doc2)\nquery_doc_tf_idf_q = tf_idf_prof_q[query_doc_bow_q]\nsim2_threshold=0.3\nsim2=sims_prof_q[query_doc_tf_idf_q]\nprofessionals_info['sim2']=sim2\n\nquery_doc_bow_i= dictionary_prof_i.doc2bow(query_doc3)\nquery_doc_tf_idf_i = tf_idf_prof_i[query_doc_bow_i]\nsim3_threshold=0.3\nsim3=sims_prof_i[query_doc_tf_idf_i]\nprofessionals_info['sim3']=sim3\n\nprofessionals_info['sim'] = professionals_info['sim1'] + professionals_info['sim2'] + + professionals_info['sim3']\nprofessionals_info['sim12'] = professionals_info['sim1'] + professionals_info['sim2']\nprofessionals_info['sim13'] = professionals_info['sim1'] + professionals_info['sim3']\nprofessionals_info['sim23'] = professionals_info['sim2'] + professionals_info['sim3']\nsim12_threshold=0.4\nsim13_threshold=0.3\nsim23_threshold=0.3\n\nsuggested_professionals=professionals_info[(((professionals_info['sim2']>=sim2_threshold) & (professionals_info['sim13']>0)) | \\\n                                            (professionals_info['sim1']>=sim13_threshold) | \\\n                                            (professionals_info['sim2']>=sim12_threshold) | \\\n                                            (((professionals_info['sim2']==0) & (professionals_info['sim12']>=sim12_threshold)) & \\\n                                            ((professionals_info['sim13']>=sim13_threshold) | (professionals_info['sim1']>=sim1_threshold)) & \\\n                                             ((professionals_info['sim23']>=sim23_threshold) | (professionals_info['sim3']>=sim3_threshold))))]\n\n#Here I have just added up the 3 match resuts. We can set weight to all the 3 results and sort based on sum in order\n#to tweak to get best results\nsuggested_professionals=suggested_professionals.sort_values('sim',ascending=False)\n\n#This engine will pull 125 relevant matches considering that not many mails should be sent per question\n#If needed the number can be altered or below clause can be removed\nif round(len(suggested_professionals)) > 125:\n    display_size=125\nelse:\n    display_size=round(len(suggested_professionals))\n    \ntop3_simq = suggested_professionals.head(display_size)\n#This will give relevant professionals to recommend questions to\ntop3_simq","4d8121e8":"#This is a validation summary to list details of old recommender which career village uses vs new recommender created above\nvalidateres = top3_simq.copy()\nares=answers[answers['answers_question_id']==q_id]\nprint('question id ' +q_id)\npres=validateres[validateres['professionals_id'].isin(ares['answers_author_id'])]\nnres=validateres[~validateres['professionals_id'].isin(ares['answers_author_id'])]\nmres = matches[matches['matches_question_id']==q_id]\nemails_response_res=emails_response[emails_response['matches_question_id']==q_id]\npores=ares[ares[['answers_question_id','answers_author_id']].apply(tuple,1).isin(emails_response_res[['matches_question_id','emails_recipient_id']].apply(tuple,1))]\nnew_matches=validateres[~validateres['professionals_id'].isin(emails_response_res['emails_recipient_id'])]\nmcnt=mres.count().values[0]\npocnt=pores.count().values[0]\nnew_matches_cnt=new_matches.count().values[0]\nnocnt=mcnt-pocnt\nacnt=ares.count().values[0]\nrcnt=top3_simq.count().values[0]\npcnt=pres.count().values[0]\nncnt=nres.count().values[0]\n# as per the email sent and details stored in matches file\nprint('total mails sent by old recommender: ' + str(mcnt))\n# as per the answers received in system\nprint('total answers: ' + str(acnt))\n# Did any professional who was mailed answered the question\nprint('positive: ' + str(pocnt))\n# How many professionals did not respond to this question even after getting mail\nprint('negative: ' + str(nocnt))\n# As per the relevant matches displayed above by my recommender\nprint('total mails sent by my recommender: ' + str(rcnt))\noldcnt=top3_simq[top3_simq['professionals_id'].isin(answers['answers_author_id'])].count().values[0]\nnewcnt=top3_simq[~top3_simq['professionals_id'].isin(answers['answers_author_id'])].count().values[0]\n# How many professionals have been at some point active in system by answering questions\nprint('active professionals ' + str(oldcnt))\n# How many professionals are recommended this question who have not answered any question or are new to career village\nprint('Inactive professionals ' + str(newcnt))\n# How many professionals are recommended by above recommender who have actually answered this question.\n# This is because we are passing questions_id which was asked earlier and validating success of this recommender\nprint('positive: ' + str(pcnt))\n# How many professionals are recommended this question and did not answer. Though we have not actually compared results\n# of old recommender with new, we do not know how many new professionals are recommended and may be probable to answer if\n# they get mail\nprint('negative: ' + str(ncnt))\nprint('New matches added: ' + str(new_matches_cnt))","f006db00":"# This is validation result of why people who have answered were not recommended by new recommender\n# Mainly I have noticed that people who answered are not recommended by my recommender is because professionals have joined\n# later than the date when question asked\nimport numpy as np\nnotincl=ares[~ares['answers_author_id'].isin(pres['professionals_id'])]\nprofdet=notincl.merge(professionals, how='inner',\n                  left_on='answers_author_id',\n                  right_on='professionals_id')\nprofdet['q_date']=q_date\nprofdet['comments']=''\nprofdet['comments']=np.where((profdet['q_date'] < profdet['professionals_date_joined']), \\\n                             profdet['comments'] + ' ' + 'Professional not joined when question asked', \\\n                             profdet['comments'])\n\nprofdet[['q_date','professionals_date_joined','answers_date_added','comments']]","0d6d9356":"# this is just a place to know bag of words of any professional in the result set of recommender\n# It will show all the 3 bag of words of professionals which is used to compare with question bag of words\np_id='fa15dfc3aa1744919d070ced9bd3fe98'\nprint(top3_simq[top3_simq['professionals_id']==p_id]['bow'].values[0])\nprint('\\n\\n'+top3_simq[top3_simq['professionals_id']==p_id]['qbow'].values[0])\nprint('\\n\\n'+top3_simq[top3_simq['professionals_id']==p_id]['ibow'].values[0])","3404a1d6":"#Above chart shows that professonals have answered a lot within 25 weeks of joining and later reduced as time passes by. After 25 weeks, professionals have shown 70% decrease in responding to questions. This calls for some action from management to improve engagement level of professionals by introducing programs which can enhance and sustain motivation to help students","8c02eca6":"#Above charts shows that 98% of the time there is no response to mail","04fc785f":"# Validation Results of my Recommender","fadb3dc3":"![Imgur](https:\/\/i.imgur.com\/2164gCZ.png)","96aa8588":"# Validation Summary of new Recommender<a id='validation_summary'><\/a>","5391594d":"1. Professionals should be encouraged to enter missing details like headline, location and industry to get relevant matches\n2. Career Village should track login activities of professionals to determine the activity level which can be used in future enhancements of Recommendation engine\n3. Career Village should save user search queries including keywords and number of times searched, to be used in future enhancements of Recommendation Engine\n4. Currently full data is not available for hearts given or students upvote for useful answers. This data can be used in future enhancements of Recommendation Engine.\n5. Cleaning of tag words should be done to remove duplicates\n6. When student is submitting question, change relevant algorithms to display appropriate tags for selection. ","e2d7cb90":"#Above chart shows that initially in 2011 when no mails were sent, the average days taken to answer was very high. In Year 2013 and 2014 when mails were sent, the speed to answer increased when mail sent but eventually 2016 onwards people getting mails took more time to answer compared to professionals who were themselves searching for relevant questions and answering them. According to Career Village management there needs to be improvement in this area so that professionals are not demotivated by number of mails or irrelevant matches and hence response time should not be detoriated","26003176":"# Stacked Bar chart to show top 40 tags\n#whether professionals followed it or not when they answered questions\n#This shows that there are majority of answers given by professionals without mail notification","8e9ab8dd":"# PROCESS CHANGES NEEDED<a id='process_changes'><\/a>","4501a102":"# Answers\n#Total Answers: 51,123\n#Answers in response to mail \u2013 17576, answered without mail notification 33615","418b2450":"#Above result shows that average number of days to get first answer is quite high as 40 days in 2018 and Career Village needs improvement in speed to answer and reduce the same to 1 day","f02ddb67":"![Imgur](https:\/\/i.imgur.com\/ThWSNbh.png)","4099aae7":"<b><i>This is noble work done by Career Village along with contribution of professionals in opening a door to connect and have dialogue with students for their dream career. But there is need to bring change in processes listed above to further enhance the Recommendation Engine. Also professionals have gone out of their way to help students by answering questions through searches in system. But continued motivation is also important for success of Career Village and their endeavour to help students at the right time when they seek advice. I would love to see some rewarding benefits for professionals for their timely contributions if it is not already happening. Ofcourse needless to say that if needed build SLAs around reward system. This will neccessarily not defeat the purpose behind the noble cause and idea behind the concept of the system<\/i><\/b>","cf3419c7":"# Professionals\n#Total Professionals: 28152\n#Industries they belong to: 2470\n#Tagged to Unknown Industries: 2576\n#Locations they belong to: 2582\n#Tagged to Unknown Locations: 3098","9c1e2dd3":"# Tags\n#49437 answers were received where questions were tagged\n#Total question tags for 49437 answers were 176350","c843a82b":"# Goals for Recommendation Engine<a id='goals'><\/a>","2af78de8":"#Professionals have set different email frequency levels to receive notifications for questions asked by Students. \n#The above charts shows that professionals have answered more by doing relevant searches on Career Village site rather than in response to mail notifications. This shows that not relevant questions are sent by mail. It also shows that 5265 answer authors have either not set that email frequency preference level or we have some missing data here.","0898e81a":"# Summary of Professionals \n#with details like total number of email received, questions received answers given","33d35613":"# RECOMMENDATION ENGINE FOR CAREER VILLAGE<a id='recommendation_engine'><\/a>","abea4050":"# Questions sent by mail or response received \n#for different email frequency as set by professionals\n#1. Bar Chart for Count distribution\n#a. Questions sent as Mail Notification\n#b. Response received from those professionals\n#2. Pie chart for % distribution","761e1dba":"# DATA ANALYSIS<a id='data_analysis'><a id='data_analysis'><\/a>","99983148":"#The above chart shows that average number of mails sent per question has been rising over years and number of answers received for each question has decreased considerably from 2014 onwards and there is a need for more engagement of professionals","9bd996db":"1. Reduce number of mail notifications sent per question\n2. Increase relevant matches for questions and increase response rate such that \n    a. all questions gets minimum 1 answer\n    b. Questions receive quality response\n3. Decrease average days taken to answer \n4. Get first response to question within 24 hours\n5. Increase number of answers per question\n6. Use learning from data analysis to identify right input parameters for balancing the solution to achieve highest potential","73d86aba":"Since majority have joined from year 2016 to year 2018, it would be good to know the industry wise count in these years","65dc0da2":"# ER Diagram","d51d47e5":"# CONCLUSIONS OF DATA ANALYSIS<a id='conclusion'><\/a>","1ea88093":"#Above chart has data from questions and answers Career Village has received. There seems to be some co-relation betweem Professionals industry and location they come from, for professionals who have answered and helped students. We see that with the students ask questions which belong to any domain but they hail from many different locations across the globe but professionals from a particular industry answering questions come from comparatively very less unique locations. This can be one of the input to recommendation engine while coming up with a model to send relevant questions to professionals","89b7d032":"Except for few locations students count has been consistent across the globe compared to professionals","1c7e1ecc":"![Imgur](https:\/\/i.imgur.com\/TPvx7Xj.png)","e4616525":"# Questions\n#Total Questions: 23,931\n#Mail notifications sent for above questions: 43,16,275 in 18,50,101 emails comprising of 1 or more questions \n#and mailed according to the email frequency level preference of Professionals. i.e. daily, immediate or weekly.\n#Out of total questions - 23931, matched for sending mail were 21894","790fa37c":"# Key Takeaways<a id='key_takeaways'><\/a>","f4b4a999":"# Summary of Mail Notifications\n#1. Year wise Questions sent\n#2. Month wise Questions sent\n\n#It shows that year or year more questions are mailed as it depends on tags professionals follow\n#And every year population of professionals seems to increase \n#It also shows that there are highest number of questions asked and hence highest mail notifications sent in month of May and October","f97c1bb5":"# Kernal Contents\n\n#1 [DATA ANALYSIS](#data_analysis)\n#2 [CONCLUSION OF DATA ANALYSIS](#conclusion)\n#3 [GOALS FOR RECOMMENDATION ENGINE](#goals)\n#4 [PROCESS CHANGES NEEDED](#process_changes)\n#5 [RECOMMENDATION ENGINE FOR CAREER VILLAGE](#recommendation_engine)\n#6 [VALIDATION SUMMARY OF MY NEW RECOMMENDER](#validation_summary)\n#7 [KEY TAKEAWAYS](#key_takeaways)","07a0f77b":"# Groups\n#Total Groups: 49\n#27660 professionals have not enrolled in any groups (out of total 28,152)\n#Only 6256 answers have been answered by professionals enrolled in any groups","b34e8031":"# Students\n#Total Students: 30,971\n#Locations they belong to: 5480\n#Tagged to Unknown Locations: 2033","87e508b0":"# Summary of Professionals characterstics\n#People who answered but without any mail notification of question\n#or without following tags\n#They are the ones who are actively supporting students and are self motivated\n#Lets look at 2 bar charts \n#1. Top Indusries these professionals belong to\n#2. Top Locations these professionals come from","13caf496":"# Scatterplot for Questions Received vs Answers given\n#shows that Majority of them have been sent large number of questions but response is low\n#whereas some professionals have shown interest in answering more than questions being mailed","1dd8aa31":"# Industrywise Unique Locations where answers come from","642cb451":"1. Professionals from industry like Telecommunications, Information Technology and computer software dominate the entire distribution\n2. Majority of professionals are from US and second dominant location is India \n3. There is a steep increase in professionals from 2016 onwards with the same dominant industries and locations which talked in 1 & 2\n4. There was a sudden increase in students in year 2016 but did not consistently increase later\n5. Students are dominantly from US but also have couple of places in India like Bengalaru and Chennai where the count is rising\n6. There is no correlation between locations where the questions come from and locations where it has been answered by professionals\n7. There seems to be correlation between locations and industries of professionals where we see a particular industry professionals hail from some specific locations and are not spread across the entire globe compared to Students data.\n8. Professionals have joined groups more than students but not necessarily answered questions from students of same group\n9. Question tags are the way to invite answers from professionals who follow tags but 66% of answered where received from professionals who did not follow tags or received mail\n10. There are some popular question tags like college, career, business, doctor, science which are very generic and not followed as much by professionals\n11. There is a evidence that large number of mails and questions are being sent to professionals and there is almost no responses from many of them after being engaged with CV for a while\n12. There are some industry related tags like telecommunications, computer software, information technology which are followed by professionals, but questions are not tagged by such industry specific tags\n13. Generic tags like college, career, engineering are followed by few professionals but they have answered highest number of questions with those tags.\n14. Industry synonym tags are followed by max professionals and answered highest when tagged in question\n15. Professionals from industries like Telecommunications, Technology Start-ups, Research \/ Education etc shows average time take to answer question is relevantly high\n16. There is no specific concern of when questions are answered less or more as it seems that month when more questions were asked, CV received answers more in those months\n17. There is 0.40 % chance of responding to mails by professionals to answer which is very low\n18. 85% of questions are mailed for email frequency set daily and of which 98% of time there is no response. May be because mails are not relevant, getting too much of mails or too many questions etc\n19. There is concern over some questions not being answered and the percentage seems to be increasing year after year\n20. Also to note that people answering without mail notifications are maximum where daily email frequency level set. This shows that there is huge gap in sending relevant matches to professionals. It\u2019s not only the professional\u2019s activity which is low but serious improvement needed in email recommendations engine\n21. There is increasing trend of days taken to answer year wise which needs attention to be decrease it substantially\n22. Professionals activity level is pretty much good in initial days of year of joining and engagement of some professionals detoriates after few months","9f68def3":"# Activity level of Professionals"}}