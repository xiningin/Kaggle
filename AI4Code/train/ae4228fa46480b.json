{"cell_type":{"521e880a":"code","b5b0934f":"code","e36a9486":"code","dac4e966":"code","329ba87a":"code","334515db":"code","1772b4b1":"code","381e94c4":"code","086bd333":"code","c58f44cf":"code","e45ce4d4":"code","a192d1c5":"code","be80a7a8":"code","84bff9c6":"code","2d840df5":"markdown","c29b850d":"markdown","778f688b":"markdown","d4851a2f":"markdown","20910c6b":"markdown","17345864":"markdown","b9661460":"markdown","f955bd37":"markdown"},"source":{"521e880a":"from sklearn.datasets import load_iris\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom scipy.linalg import eigh\nimport seaborn as sn\nfrom sklearn import decomposition\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import accuracy_score,confusion_matrix,mean_squared_error,r2_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns',10000)\nnp.random.seed(2)#This is important for scientific works, only with a seed you can replicate computations that uses random elements.","b5b0934f":"iris_data=load_iris()\nprint(iris_data.keys())","e36a9486":"pd.set_option('display.max_columns',1000)\npd.set_option('display.max_rows',1000)\npd.set_option('display.width',1000)\n","dac4e966":"df_data=pd.DataFrame(iris_data.data,columns=iris_data.feature_names,index=None)\ndf_target=pd.DataFrame(iris_data.target,columns=['class'])\ndf_target.loc[df_target['class'] ==0, 'Target_names'] = 'setosa'\ndf_target.loc[df_target['class'] ==1, 'Target_names'] = 'versicolor'\ndf_target.loc[df_target['class'] ==2, 'Target_names'] = 'virginica'\ntarget_names=iris_data.target_names\nprint('features :\\n',df_data.head(5))\nprint('labels :\\n',df_target)","329ba87a":"df_data","334515db":"df_data['species']=df_target['Target_names']\nsn.pairplot(data=df_data,kind='scatter', hue='species')","1772b4b1":"df_data=df_data.drop(['species'],axis=1)\nstandardized_data = StandardScaler().fit_transform(df_data)\nprint('standardized_data shape :\\n',standardized_data.shape)\nprint('standardized_data data :\\n',standardized_data)","381e94c4":"sample_data=standardized_data\npca = decomposition.PCA()\npca.n_components = 4\npca_data = pca.fit_transform(sample_data)\n# pca_reduced will contain the 2-d projects of simple data\nprint(\"shape of pca_reduced.shape = \", pca_data.shape)","086bd333":"pca.n_components = 4\npca_data = pca.fit_transform(sample_data)\npercentage_var_explained = pca.explained_variance_ \/ np.sum(pca.explained_variance_);\ncum_var_explained = np.cumsum(percentage_var_explained)\n# Plot the PCA spectrum\nplt.figure(1, figsize=(6, 4))\nplt.clf()\nplt.plot(cum_var_explained, linewidth=2)\nplt.axis('tight')\nplt.grid()\nplt.xlabel('n_components')\nplt.ylabel('Cumulative_explained_variance')\nplt.show()","c58f44cf":"y=df_target['Target_names']\nx=pca_df.drop(['label'], axis=1)\nX_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.20,random_state=0)\nmodel=RandomForestClassifier(max_depth=6)\nmodel.fit(X_train,Y_train)\nyp=model.predict(X_test)\nprint('accuracy ',accuracy_score(Y_test,yp))","e45ce4d4":"model = TSNE(n_components=, random_state=0)\n# configuring the parameteres\n# the number of components = 2\n# default perplexity = 30\n# default learning rate = 200\n# default Maximum number of iterations for the optimization = 1000\ntsne_data = model.fit_transform(df_data)\n# creating a new data frame which help us in ploting the result data\ntsne_data = np.vstack((tsne_data.T, df_target['Target_names'])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"Dim_3\", \"Dim_4\", \"label\"))\n","a192d1c5":"y=df_target['Target_names']\nx=tsne_df.drop(['label'], axis=1)\nX_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.20,random_state=0)\nprint(X_train.shape)\nmodel=RandomForestClassifier()\nmodel.fit(X_train,Y_train)\nyp=model.predict(X_test)\nprint('accuracy ',accuracy_score(Y_test,yp))","be80a7a8":"model = TSNE(n_components=2, random_state=0, perplexity=40,  n_iter=4000)\ntsne_data = model.fit_transform(df_data)\n# creating a new data fram which help us in ploting the result data\ntsne_data = np.vstack((tsne_data.T, df_target['Target_names'])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n# Ploting the result of tsne\nsn.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\nplt.title('With perplexity = 40, n_iter=4000')\nplt.show()\n","84bff9c6":"y=df_target['Target_names']\nx=tsne_df.drop(['label'], axis=1)\nX_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.20,random_state=0)\nmodel=RandomForestClassifier()\nmodel.fit(X_train,Y_train)\nyp=model.predict(X_test)\nprint('acc ',accuracy_score(Y_test,yp))","2d840df5":"aaplying random forest classifier on TSNE transformed data with 40 perplexity","c29b850d":"from scikit-learn load the iris data","778f688b":"just importing the necessary libraries","d4851a2f":"TSNE with 40 perplexity and 4k iters","20910c6b":"now applying random forest classifier on pca tranformed data","17345864":"now applying random forest classifier on TSNE tranformed data","b9661460":"PCA vs TSNE ","f955bd37":"setting the pandas display window in order to see all columns and rows"}}