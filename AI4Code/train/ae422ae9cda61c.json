{"cell_type":{"694eb949":"code","c0b9eb3e":"code","32c046ee":"code","c551333a":"code","b0607b58":"code","e6aa18aa":"code","c32feb1d":"code","c152a944":"code","745318e4":"code","170b76cd":"code","c9121f20":"markdown"},"source":{"694eb949":"# Install pytorch-tabnet : latest develop branch \n!pip install git+https:\/\/github.com\/dreamquark-ai\/tabnet.git@develop","c0b9eb3e":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nimport torch\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nimport copy\nimport torch","32c046ee":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv')\n\n# remove the only 5 cover type target\ntrain = train[train.Cover_Type!=5].reset_index(drop=True)\nprint(train.shape)\nprint(test.shape)\n\n\na = train.nunique().reset_index(drop=False).rename(columns={\"index\": \"feat_name\", 0: \"count\"})\n\n# drop columns with a single value\ndrop_cols = [\"Id\"] + list(a[a[\"count\"] < 2 ].feat_name)\ntarget = [\"Cover_Type\"]\n\n# categorical features are columns with small modalities\ncat_features = [col for col in list(a[a[\"count\"] < 10 ].feat_name) if col not in drop_cols+target]\nnum_features = [col for col in train.columns if col not in drop_cols+target+cat_features]\n\nfeatures = cat_features + num_features","c551333a":"# This is only needed if using embeddings (not used at the moment)\n\nfrom sklearn.preprocessing import LabelEncoder\n\ncategorical_columns = []\ncategorical_dims =  {}\nfor col in cat_features:\n    l_enc = LabelEncoder()\n    train[col] = train[col].fillna(\"VV_likely\")\n    train[col] = l_enc.fit_transform(train[col].values)\n    categorical_columns.append(col)\n    categorical_dims[col] = len(l_enc.classes_)\n    \n    test[col] = l_enc.transform(test[col].values)\n    \ncat_idxs = [] #[ i for i, f in enumerate(features) if f in cat_features]\ncat_dims = [] #[ categorical_dims[f] for i, f in enumerate(features) if f in cat_features]\n\nX_test = test[features].values","b0607b58":"BS = 8192*2\nVBS = BS #512\nmax_epochs=50\n\ntabnet_params = {\"n_d\" : 64,\n                 \"n_a\" : 64,\n                 \"n_steps\" : 5,\n                 \"gamma\" : 1.5,\n                 \"n_independent\" : 2,\n                 \"n_shared\" : 2,\n                 \"cat_idxs\" : cat_idxs,\n                 \"cat_dims\" : cat_dims,\n                 \"cat_emb_dim\" : 1,\n                 \"lambda_sparse\" : 1e-4,\n                 \"momentum\" : 0.3,\n                 \"clip_value\" : 2.,\n                 \"optimizer_fn\" : torch.optim.Adam,\n                 \"optimizer_params\" :dict(lr=2e-2),}\n\n\nparams = copy.deepcopy(tabnet_params)\nparams[\"scheduler_fn\"]=torch.optim.lr_scheduler.StepLR\nparams[\"scheduler_params\"]={\"is_batch_level\":False,\n                            \"gamma\":0.95,\n                            \"step_size\": 2,}","e6aa18aa":"# Pretrain the model on test set\n\nX_unsup_valid = train[features].values\nparams = tabnet_params.copy()\n\nunsupervised_model = TabNetPretrainer(**params)\n\nunsupervised_model.fit(\n    X_train=X_test,\n    eval_set=[X_unsup_valid],\n    pretraining_ratio=0.8,\n    max_epochs=50,\n    patience=5,\n    batch_size=4096,\n    virtual_batch_size=4096\n)\n","c32feb1d":"\n# Split for cross validation or single validation\nfrom sklearn.model_selection import StratifiedKFold\n\nN_SPLITS=5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=0)\n\ncv_preds = np.zeros((X_test.shape[0], N_SPLITS))\n\nfold_idx=0\nfor train_idx, val_idx in skf.split(train, train[target]):\n\n    # Create the numpy datasets\n\n    X_train = train.loc[train_idx, features].values\n    Y_train = train.loc[train_idx, target].values.reshape(-1)\n\n    X_val = train.loc[val_idx, features].values\n    Y_val = train.loc[val_idx, target].values.reshape(-1)\n\n    # Train a tabnet classifier\n\n    params = copy.deepcopy(tabnet_params)\n\n    # Scheduling scheme here is the only part not similar to the original paper\n    # but the dataset is not exactly the same\n\n    # params[\"scheduler_fn\"]=torch.optim.lr_scheduler.StepLR\n    # params[\"scheduler_params\"]={\"is_batch_level\":False,\n    #                             \"gamma\":0.95,\n    #                             \"step_size\": 5,}\n    params[\"scheduler_fn\"]=torch.optim.lr_scheduler.OneCycleLR\n    params[\"scheduler_params\"]={\"is_batch_level\":True,\n                                \"max_lr\":5e-2,\n                                \"steps_per_epoch\":int(X_train.shape[0] \/ BS),\n                                \"epochs\":max_epochs}\n\n    clf = TabNetClassifier(**params)\n\n    clf.fit(\n        X_train,\n        Y_train,\n        eval_set=[(X_train, Y_train), (X_val, Y_val)],\n        eval_name=['train', 'valid'],\n        eval_metric=['accuracy'],\n        max_epochs=max_epochs,\n        patience=20,\n        drop_last=True,\n        batch_size=BS,\n        virtual_batch_size=VBS,\n    #     weights=1,\n        from_unsupervised=unsupervised_model\n    )\n    \n    preds = clf.predict(X_test)\n    cv_preds[:, fold_idx] = preds\n    fold_idx+=1","c152a944":"# Voting ensembling\n\nfrom scipy import stats\nfinal_res, _ = stats.mode(cv_preds, axis=1)","745318e4":"df_submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\ndf_submission['Cover_Type']= final_res.astype(int)\ndf_submission.to_csv('submission.csv',index=False)","170b76cd":"df_submission.Cover_Type.value_counts()","c9121f20":"# About this notebook\n\nThis notebook is a simple pipeline using pytorch-tabnet (https:\/\/github.com\/dreamquark-ai\/tabnet) following the original paper's parameters (https:\/\/arxiv.org\/abs\/1908.07442).\n\nIt performs pretraining on test set and standard 5 fold cross validation with voting ensembling of the folds.\n\nAlmost no preprocessing is done (except from removing class 5 row and ignoring trivial columns), no feature engineering is done.\n\nThis is just a very basic starting pipeline.\n"}}