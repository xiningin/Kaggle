{"cell_type":{"b6440243":"code","7a6d13d6":"code","326d74bd":"code","18fdb6f6":"code","133617ea":"code","30bc3db4":"code","5c33b7f6":"code","66189240":"code","6ea3a6ba":"code","8de53391":"code","74eca369":"code","7792ea8d":"code","610e3c9b":"code","ffd17efc":"code","c6dc6203":"code","4dbc95df":"code","df8b8f52":"code","cb657f15":"code","ce069dc0":"code","a39c958c":"code","c9fcf0b7":"code","ed70f448":"markdown","24ea4d87":"markdown","cfcb4a90":"markdown","cc87b00e":"markdown","75022394":"markdown","70948823":"markdown","ef4bfa75":"markdown","8c774251":"markdown","ff73162d":"markdown","8b0400e6":"markdown"},"source":{"b6440243":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport numpy as np\nimport pandas as pd\nimport sqlite3\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.manifold import TSNE\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7a6d13d6":"conn = sqlite3.connect('..\/input\/database.sqlite')\n\ndf = pd.read_sql (\"\"\"SELECT * from Reviews WHERE Score != 3\"\"\", conn)\n\ndf['P\/N'] = np.select((df['Score'] > 3, df['Score'] < 3), ('Positive', 'Negative'))\ndf = df.drop(columns = 'Score')\nraw_df_shape = df.shape\nprint(raw_df_shape)","326d74bd":"df = df.sort_values('ProductId', axis = 0, ascending = True)\ndf = df.drop_duplicates(subset = {'UserId', 'ProfileName', 'Time', 'Text'}, keep = 'first', inplace = False)\n# helpfulness denominator should be greater than helpfulness numerator\n\ndf = df[df.HelpfulnessDenominator >= df.HelpfulnessNumerator]\nclean_df_shape = df.shape\nprint(clean_df_shape)","18fdb6f6":"print('Data points still remaining : ', clean_df_shape[0]*100\/raw_df_shape[0], '%')","133617ea":"df['P\/N'].value_counts()\ndf = df.reset_index().drop('index', axis = 1)\ndf.head(2).T","30bc3db4":"\"\"\"Text processing taken into consideration step wise\n1. Removing HTML tags\n2. Removing punctuations\n3. Removing stopwords\n4. Tokenizing sentences into words\n5. Checking if size of words is greater than 1\n6. Snowball Stemming \n\"\"\"\nimport re\nimport timeit\nimport numpy as np\nimport time\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\n\nstopwords = set(stopwords.words('english'))\nsnowballstemmer = SnowballStemmer('english')\nlemmatizer = WordNetLemmatizer()\n\n\nt0 = time.time()\nprocessed_positive_words_list = []\nprocessed_negative_words_list = []\nprocessed_sentence_list = []\n\nfor i in df.index:\n    this_sentence = []\n    stemmedwords = []\n    text = df.iloc[i]['Text']\n    \n    #Remove HTML Tags\n    text = re.sub('<.*?>', ' ', text) \n    \n    #Clear punctuation and numbers\n    text = re.sub('[^A-Za-z]+', ' ', text)\n    \n    #Convert all uppercase characters into lowercase\n    text = text.lower()\n    #Tokenize string\n    #removing stopwords\n    #stemming words\n    #checking wordlength\n    for words in word_tokenize(text):\n        if len(words) > 1 and words not in stopwords:\n            stemmedwords.append(snowballstemmer.stem(words))\n            \n    if df.iloc[i]['P\/N'] == 'Positive':\n        processed_positive_words_list+=(stemmedwords)\n    elif df.iloc[i]['P\/N'] == 'Negative':                \n        processed_negative_words_list+=(stemmedwords)\n                \n    #Joining words\n    clean_sentence = \" \".join(stemmedwords)\n    processed_sentence_list.append(clean_sentence)\n\n    print((i*100\/364159),end =\"\\r\")\n    \nt1 = time.time()\nprint('time elapsed',t1-t0, 'secs')\n","5c33b7f6":"processed_all_words = processed_positive_words_list + processed_negative_words_list\nprint(\"Total number of words in processed_words_list : \", len(processed_all_words))\nprint(\"Total number of sentences in preprocessed_sentence_list : \", len(processed_sentence_list))\nprint(\"Total number of positive words : \", len(processed_positive_words_list))\nprint(\"Total number of negative words : \", len(processed_negative_words_list))","66189240":"#type(processed_sentence_list)\ndf['Cleaned_Text'] = processed_sentence_list\ndf.head(2).T","6ea3a6ba":"processed_positive_words_list[:10]","8de53391":"processed_negative_words_list[:10]","74eca369":"# store final table into an SQlLite table for future.\ntry:\n    os.remove('amazon_review_df.sqlite')\nexcept:\n    print('Exception : file not exist')\nconn = sqlite3.connect('amazon_review_df.sqlite')\nc=conn.cursor()\nconn.text_factory = str\ndf.to_sql('Reviews', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)\n","7792ea8d":"# store processed positive, negative and sentance list into an SQlLite table for future.\ntry:\n    os.remove('positive_words.txt')\nexcept:\n    print('Exception : file not exist')\ntry:\n    os.remove('negative_words.txt')\nexcept:\n    print('file not exist')\n\nwith open('positive_words.txt', 'w') as f:\n    for x in processed_positive_words_list:\n        f.write(x)\n        f.write(',')\n    f.close()\n\nwith open('negative_words.txt', 'w') as f:\n    for x in processed_negative_words_list:\n        f.write(x)\n        f.write(',')\n    f.close()\n","610e3c9b":"conn = sqlite3.connect('amazon_review_df.sqlite')\ndisplay= pd.read_sql_query(\"\"\"\nSELECT * from Reviews\"\"\", conn)\ndisplay.head(2).T","ffd17efc":"processed_positive_words_list = []\nprocessed_negative_words_list = []\n\nwith open('positive_words.txt', 'r') as f:\n    for line in f.readlines():\n        line = line.replace(\"\\\"\", \"\")\n    processed_positive_words_list = line.split(',')\nwith open('negative_words.txt', 'r') as f:\n    for line in f.readlines():\n        line = line.replace(\"\\\"\", \"\")\n    processed_negative_words_list = line.split(',')","c6dc6203":"processed_positive_words_list[:10]","4dbc95df":"processed_negative_words_list[:10]","df8b8f52":"words_counts = pd.Series(processed_all_words).value_counts()\nrare_words = list(words_counts.where(words_counts.values == 1).dropna().index)","cb657f15":"print('No of rare words : ', len(rare_words))\nprint('No of unique words : ', len(words_counts))\n#print(words_counts.index)\nwords_counts","ce069dc0":"stopwords = frozenset(rare_words)\ncount_vect = CountVectorizer(stop_words=stopwords)\nfinal_counts = count_vect.fit_transform(df['Cleaned_Text'].values)\nprint(\"the shape of BOW vectorizer after rare words removal\",final_counts.get_shape())\nprint(\"the number of unique words after rare words removal\", final_counts.get_shape()[1])","a39c958c":"# features = final_counts\n# labels = df['P\/N']\n\ntsne_model = TSNE(n_components=2, random_state=0)\nt0 = time.time()\ntsne_transform = tsne_model.fit_transform(final_counts.todense()).T\nprint('Elapsed time :', time.time()-t0);\n","c9fcf0b7":"# visualizing t-SNE\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprint(tsne_transform.shape)\n\ntsne_data = np.vstack((tsne_transform, display['P\/N'])).T\ntsne_df = pd.DataFrame(data = tsne_data, columns=('Dimention 1', 'Dimention 2', 'Label'))\nsns.FacetGrid(tsne_df, size = 8, hue = 'Label').map(plt.scatter, 'Dimention 1', 'Dimention 2', marker = '.').add_legend()","ed70f448":"### Read from my_amazon_review_df.sqlite","24ea4d87":"#### Checking how much data still remains","cfcb4a90":"### Rare Words Removal","cc87b00e":"### BoW Vectorization\n### Finding the rare words\n\nMotivation : Exclude the typos and spelling mistakes.","75022394":"### Storing final table to sql for future ","70948823":"#### The Amazon Fine food reviews dataframe has the following contents:\nFeatures : \nId : Review ID,  'ProductId' : product ID,  'UserId' : , 'ProfileName : customer name', 'HelpfulnessNumerator : people found helpful', 'HelpfulnessDenominator : people indicated whether the found helpful', 'Score : star rating', 'Time : time of review', 'Summary : breif summary of the report ', 'Text : original review'\n\n#### Objective : To predict whether a review new is positive or not.","ef4bfa75":"#### Test Preprocessing ( Removing HTML Tags, punctuations, check for alphanumerics, check if length of words is less than or equal to 2, convert word into lowercase and snowball stemming.   ","8c774251":"#### Number of positive and negative reviews","ff73162d":"### T-SNE Visualization: ","8b0400e6":"#### Data Cleaning : deduplication"}}