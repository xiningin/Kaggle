{"cell_type":{"d9efa63d":"code","5a35a05a":"code","ac80aae4":"code","e81d2698":"code","e411825a":"code","93d6abbf":"code","4520d98d":"code","721bc630":"code","d6eddc00":"code","e6d9a4c4":"code","d3c7d783":"code","c2ce81cc":"code","c66720e7":"code","0c1cef9f":"code","e8adf50a":"code","728dae49":"code","7b524f6e":"code","920e049c":"code","e9df0b6a":"code","31abd098":"code","1a667f21":"code","7bd952d6":"code","4843e3ab":"code","7d59974b":"code","b04a1d87":"code","1bfc43d3":"code","bf2c52e0":"code","0131ec41":"code","264f6691":"code","b5a122f8":"code","4692458f":"code","6a8bb4e7":"code","79d49be8":"code","a726a917":"code","08fd737d":"code","3b9509c2":"code","48c8f638":"code","a8b8063b":"code","60702cf6":"code","9f8f28ca":"code","28d2df4b":"code","6e2fc51f":"code","a9dd52f4":"code","ca244b86":"code","2a443fd1":"code","45a0a1d1":"code","39839092":"code","1b4caddc":"code","435dddf1":"code","1bb5b339":"code","c6a5b7c7":"code","97eae8ea":"code","d3413383":"code","41b43dae":"code","677fa09f":"code","e5628401":"code","71f7c8c0":"code","06466e54":"code","5e61072c":"code","b285d3d3":"code","8f746094":"code","a4c8a5a1":"code","928ac00d":"code","cc133f45":"code","1db56655":"code","77281c60":"code","f48d1122":"code","9c348aaa":"code","b57f6b1f":"code","0e0197a6":"code","464e8c4e":"code","dc573b00":"code","ea8411c0":"code","04a5733d":"code","d115ed3f":"code","24351ec0":"code","7511d2f8":"code","5d45fb15":"code","6e9c339a":"code","05da64ff":"code","09a4fd7d":"code","9f581546":"code","9100fca4":"code","cbf9a2f8":"code","8ad7ed19":"code","553963ba":"code","6d6fb430":"code","c0e283a3":"code","1fbb4e24":"code","2a4ee8e9":"code","3ae25bbe":"code","61369f60":"code","e3020524":"code","b753b7d8":"code","6f3277b0":"code","2319f88d":"code","149bc5b7":"code","e05f7b2e":"code","51d35792":"code","f33a1b2b":"code","b5bf5261":"code","21ea1e48":"code","bc954143":"code","d09ca882":"code","90667aea":"code","d1fc5f32":"code","07399836":"code","2bc362a1":"code","8168bf0e":"code","8b497459":"code","9c9fd4b7":"code","3ef88f60":"code","8e538f51":"code","c12c2372":"code","10b84f61":"code","b8835bbc":"code","4dbf48d3":"code","5a75b080":"code","acae9a0b":"code","547fd613":"code","d5fd4689":"code","c1355d34":"code","529a5db2":"code","a6986730":"code","d43314e9":"code","5b017e03":"code","041e4fbf":"code","f9f6dac9":"code","0a511dfd":"code","1272f6d7":"code","4952e887":"code","c7349550":"code","6f0f10b3":"code","9e3f7adf":"code","16ea77b0":"code","61e6cfc2":"code","a2eef083":"code","75aca51a":"code","b6ed2e90":"code","d148864c":"code","a8b8328a":"code","a305f07b":"code","cce61521":"code","832952c1":"code","89dac6cb":"markdown","57e7fd4f":"markdown","26f43f2e":"markdown","02314000":"markdown","44e59a1f":"markdown","518176f1":"markdown","4fd9eef8":"markdown","7a62556a":"markdown","320d13a9":"markdown","c72134f8":"markdown","d56ce73f":"markdown","3d79224d":"markdown","9b65dfbd":"markdown","9e842521":"markdown","d4f3e995":"markdown","c8154a78":"markdown","2dd4e176":"markdown","695e1f22":"markdown","1c8c0950":"markdown","5ff9f1e3":"markdown","56f8a227":"markdown","93003bf1":"markdown","e735564e":"markdown","aa90bfae":"markdown","fbf7e55f":"markdown","6d2751fc":"markdown","a1af4163":"markdown","33073c24":"markdown","592da848":"markdown","eeb44531":"markdown","e7e91cd9":"markdown","9082b24b":"markdown","6b851191":"markdown","87432cf2":"markdown"},"source":{"d9efa63d":"\"\"\"\nCreate by Karl Bina, Computer vision and data science engineer (Telitem Company)\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        ","5a35a05a":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","ac80aae4":"train_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","e81d2698":"print(train_set.shape)\nprint(test_set.shape)","e411825a":"train_set.head()","93d6abbf":"test_set.head()","4520d98d":"train = train_set.copy()\ntest = test_set.copy()","721bc630":"train.shape","d6eddc00":"train.dtypes.value_counts()","e6d9a4c4":"train.dtypes.value_counts().plot.pie()","d3c7d783":"(train.isna().sum() \/ train.shape[0]).sort_values(ascending=False)","c2ce81cc":"import seaborn as sns","c66720e7":"plt.figure(figsize=(16,8))\nsns.heatmap(train.isna(), cbar=False)","0c1cef9f":"train['SalePrice'].value_counts(normalize=True)","e8adf50a":"train['SalePrice'].mean()","728dae49":"for col in train.select_dtypes('float64'):\n    if col == 'Id':\n        pass\n    else:\n        plt.figure(figsize=(10,8))\n        sns.distplot(train[col])","7b524f6e":"for col in train.select_dtypes('int'):\n    try:\n        plt.figure(figsize=(8,8))\n        sns.distplot(train[col])\n    except RuntimeError as re:\n        if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n            plt.figure(figsize=(8,8))\n            sns.distplot(train[col], kde_kws={'bw': 0.1})\n        else:\n            raise re","920e049c":"train.head(3)","e9df0b6a":"plt.figure(figsize=(18,8))\ntrain.corr()['SalePrice'].plot.bar()\nplt.xlabel('Variable')\nplt.ylabel('Correlation')\nplt.title('Correlation SalePrice')","31abd098":"correlation_SalePrice = pd.DataFrame(train.corr()['SalePrice'])","1a667f21":"plt.figure(figsize=(12,12))\nsns.heatmap(correlation_SalePrice, annot=True)","7bd952d6":"train['SalePrice'].describe()","4843e3ab":"plt.figure(figsize=(10,8))\nsns.distplot(train['SalePrice'])","7d59974b":"train.corr()['SalePrice'][train.corr()['SalePrice'] > 0.5]","b04a1d87":"train.corr()['SalePrice'][(train.corr()['SalePrice'] > 0) & (train.corr()['SalePrice'] < 0.5)]","1bfc43d3":"for col in train.drop(['SalePrice'], axis=1).select_dtypes('int64'):\n    plt.figure(figsize=(10,4))\n    plt.scatter(train[col],train['SalePrice'])\n    plt.title('Relation between SalePrice and {}'.format(col))\n    plt.xlabel(col)\n    plt.ylabel('SalePrice')\n    plt.show()","bf2c52e0":"plt.figure(figsize=(12,8))\nsns.boxplot(x=\"OverallQual\", y=\"SalePrice\",palette=[\"m\", \"g\"], data=train)","0131ec41":"plt.figure(figsize=(12,8))\nsns.boxplot(x=\"GarageQual\", y=\"SalePrice\",palette=[\"m\", \"g\"], data=train)","264f6691":"plt.figure(figsize=(12,8))\nsns.boxplot(x=\"GarageCars\", y=\"SalePrice\",palette=[\"m\", \"g\"], data=train)","b5a122f8":"plt.figure(figsize=(18,8))\nsns.boxplot(x=\"MoSold\", y=\"SalePrice\", data=train)","4692458f":"plt.figure(figsize=(18,8))\nsns.boxplot(x=\"YearBuilt\", y=\"SalePrice\", data=train)\nplt.xticks(rotation=90)\nplt.show()","6a8bb4e7":"train.corr()['SalePrice'][train.corr()['SalePrice'] > 0.50]","79d49be8":"display_pair = train[[\"SalePrice\",\"OverallQual\",\"YearBuilt\",\"TotalBsmtSF\",\"GrLivArea\",\"FullBath\",\"GarageCars\",\"GarageArea\"]]\ndisplay_pair.shape","a726a917":"#plt.figure()\n#sns.pairplot(display_pair)\n#plt.show()","08fd737d":"plt.figure(figsize=(20,12))\nsns.heatmap(train.corr()[(train.corr()['SalePrice'] > 0)])","3b9509c2":"from scipy.stats import norm\nfrom scipy import stats","48c8f638":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train['SalePrice'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train['SalePrice'], plot=plt)","a8b8063b":"train['SalePrice'] = np.log1p(train['SalePrice'])","60702cf6":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train['SalePrice'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train['SalePrice'], plot=plt)","9f8f28ca":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train['GrLivArea'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train['GrLivArea'], plot=plt)","28d2df4b":"train['GrLivArea'] = np.log1p(train['GrLivArea'])\ntest['GrLivArea'] = np.log1p(test['GrLivArea'])","6e2fc51f":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train['GrLivArea'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train['GrLivArea'], plot=plt)","a9dd52f4":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train['TotalBsmtSF'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train['TotalBsmtSF'], plot=plt)","ca244b86":"train['logHasBsmt'] = pd.Series(len(train['TotalBsmtSF']), index=train.index)\ntrain['logHasBsmt'] = 0 \ntrain.loc[train['TotalBsmtSF']>0,'logHasBsmt'] = 1","2a443fd1":"test['logHasBsmt'] = pd.Series(len(test['TotalBsmtSF']), index=test.index)\ntest['logHasBsmt'] = 0 \ntest.loc[test['TotalBsmtSF']>0,'logHasBsmt'] = 1","45a0a1d1":"train.loc[train['logHasBsmt']==1,'TotalBsmtSF'] = np.log1p(train['TotalBsmtSF'])\ntest.loc[test['logHasBsmt']==1,'TotalBsmtSF'] = np.log1p(test['TotalBsmtSF'])","39839092":"train.head()","1b4caddc":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.distplot(train[train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm)\nplt.subplot(2,2,2)\nres = stats.probplot(train[train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","435dddf1":"# Inspired by juliencs's script https:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset","1bb5b339":"def Encodage(df):\n    df.loc[:,\"Alley\"] = df.loc[:, \"Alley\"].fillna(\"None\")\n    df.loc[:, \"BedroomAbvGr\"] = df.loc[:, \"BedroomAbvGr\"].fillna(0)\n    df.loc[:, \"BsmtQual\"] = df.loc[:, \"BsmtQual\"].fillna(\"No\")\n    df.loc[:, \"BsmtCond\"] = df.loc[:, \"BsmtCond\"].fillna(\"No\")\n    df.loc[:, \"BsmtExposure\"] = df.loc[:, \"BsmtExposure\"].fillna(\"No\")\n    df.loc[:, \"BsmtFinType1\"] = df.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n    df.loc[:, \"BsmtFinType2\"] = df.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n    df.loc[:, \"BsmtFullBath\"] = df.loc[:, \"BsmtFullBath\"].fillna(0)\n    df.loc[:, \"BsmtHalfBath\"] = df.loc[:, \"BsmtHalfBath\"].fillna(0)\n    df.loc[:, \"BsmtUnfSF\"] = df.loc[:, \"BsmtUnfSF\"].fillna(0)\n    df.loc[:, \"CentralAir\"] = df.loc[:, \"CentralAir\"].fillna(\"N\")\n    df.loc[:, \"Condition1\"] = df.loc[:, \"Condition1\"].fillna(\"Norm\")\n    df.loc[:, \"Condition2\"] = df.loc[:, \"Condition2\"].fillna(\"Norm\")\n    df.loc[:, \"EnclosedPorch\"] = df.loc[:, \"EnclosedPorch\"].fillna(0)\n    df.loc[:, \"ExterCond\"] = df.loc[:, \"ExterCond\"].fillna(\"TA\")\n    df.loc[:, \"ExterQual\"] = df.loc[:, \"ExterQual\"].fillna(\"TA\")\n    df.loc[:, \"Fence\"] = df.loc[:, \"Fence\"].fillna(\"No\")\n    df.loc[:, \"FireplaceQu\"] = df.loc[:, \"FireplaceQu\"].fillna(\"No\")\n    df.loc[:, \"Fireplaces\"] = df.loc[:, \"Fireplaces\"].fillna(0)\n    df.loc[:, \"Functional\"] = df.loc[:, \"Functional\"].fillna(\"Typ\")\n    df.loc[:, \"GarageType\"] = df.loc[:, \"GarageType\"].fillna(\"No\")\n    df.loc[:, \"GarageFinish\"] = df.loc[:, \"GarageFinish\"].fillna(\"No\")\n    df.loc[:, \"GarageQual\"] = df.loc[:, \"GarageQual\"].fillna(\"No\")\n    df.loc[:, \"GarageCond\"] = df.loc[:, \"GarageCond\"].fillna(\"No\")\n    df.loc[:, \"GarageArea\"] = df.loc[:, \"GarageArea\"].fillna(0)\n    df.loc[:, \"GarageCars\"] = df.loc[:, \"GarageCars\"].fillna(0)\n    df.loc[:, \"HalfBath\"] = df.loc[:, \"HalfBath\"].fillna(0)\n    df.loc[:, \"HeatingQC\"] = df.loc[:, \"HeatingQC\"].fillna(\"TA\")\n    df.loc[:, \"KitchenAbvGr\"] = df.loc[:, \"KitchenAbvGr\"].fillna(0)\n    df.loc[:, \"KitchenQual\"] = df.loc[:, \"KitchenQual\"].fillna(\"TA\")\n    df.loc[:, \"LotFrontage\"] = df.loc[:, \"LotFrontage\"].fillna(0)\n    df.loc[:, \"LotShape\"] = df.loc[:, \"LotShape\"].fillna(\"Reg\")\n    df.loc[:, \"MasVnrType\"] = df.loc[:, \"MasVnrType\"].fillna(\"None\")\n    df.loc[:, \"MasVnrArea\"] = df.loc[:, \"MasVnrArea\"].fillna(0)\n    df.loc[:, \"MiscFeature\"] = df.loc[:, \"MiscFeature\"].fillna(\"No\")\n    df.loc[:, \"MiscVal\"] = df.loc[:, \"MiscVal\"].fillna(0)\n    df.loc[:, \"OpenPorchSF\"] = df.loc[:, \"OpenPorchSF\"].fillna(0)\n    df.loc[:, \"PavedDrive\"] = df.loc[:, \"PavedDrive\"].fillna(\"N\")\n    df.loc[:, \"PoolQC\"] = df.loc[:, \"PoolQC\"].fillna(\"No\")\n    df.loc[:, \"PoolArea\"] = df.loc[:, \"PoolArea\"].fillna(0)\n    df.loc[:, \"SaleCondition\"] = df.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n    df.loc[:, \"ScreenPorch\"] = df.loc[:, \"ScreenPorch\"].fillna(0)\n    df.loc[:, \"TotRmsAbvGrd\"] = df.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n    df.loc[:, \"Utilities\"] = df.loc[:, \"Utilities\"].fillna(\"AllPub\")\n    df.loc[:, \"WoodDeckSF\"] = df.loc[:, \"WoodDeckSF\"].fillna(0)\n    return df","c6a5b7c7":"def Replace_numerica_features(df):\n    df = df.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n                      })\n    return df","97eae8ea":"def Replace_category_features(df):\n    df = df.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n                     )\n    return df","d3413383":"def Simplifications_of_existing_features(df):\n    df[\"SimplOverallQual\"] = df.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, \n                                                       4 : 2, 5 : 2, 6 : 2, \n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 \n                                                      })\n    df[\"SimplOverallCond\"] = df.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, \n                                                           4 : 2, 5 : 2, 6 : 2, \n                                                           7 : 3, 8 : 3, 9 : 3, 10 : 3 \n                                                          })\n    df[\"SimplPoolQC\"] = df.PoolQC.replace({1 : 1, 2 : 1, \n                                                 3 : 2, 4 : 2 \n                                                })\n    df[\"SimplGarageCond\"] = df.GarageCond.replace({1 : 1, \n                                                         2 : 1, 3 : 1, \n                                                         4 : 2, 5 : 2 \n                                                        })\n    df[\"SimplGarageQual\"] = df.GarageQual.replace({1 : 1, \n                                                         2 : 1, 3 : 1, \n                                                         4 : 2, 5 : 2 \n                                                        })\n    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, \n                                                           2 : 1, 3 : 1, \n                                                           4 : 2, 5 : 2 \n                                                          })\n    df[\"SimplFireplaceQu\"] = df.FireplaceQu.replace({1 : 1, \n                                                           2 : 1, 3 : 1, \n                                                           4 : 2, 5 : 2 \n                                                          })\n    df[\"SimplFunctional\"] = df.Functional.replace({1 : 1, 2 : 1, \n                                                         3 : 2, 4 : 2, \n                                                         5 : 3, 6 : 3, 7 : 3, \n                                                         8 : 4 \n                                                        })\n    df[\"SimplKitchenQual\"] = df.KitchenQual.replace({1 : 1, \n                                                           2 : 1, 3 : 1, \n                                                           4 : 2, 5 : 2 \n                                                          })\n    df[\"SimplHeatingQC\"] = df.HeatingQC.replace({1 : 1, \n                                                       2 : 1, 3 : 1, \n                                                       4 : 2, 5 : 2 \n                                                      })\n    df[\"SimplBsmtFinType1\"] = df.BsmtFinType1.replace({1 : 1, \n                                                             2 : 1, 3 : 1, \n                                                             4 : 2, 5 : 2, 6 : 2 \n                                                            })\n    df[\"SimplBsmtFinType2\"] = df.BsmtFinType2.replace({1 : 1, \n                                                             2 : 1, 3 : 1, \n                                                             4 : 2, 5 : 2, 6 : 2 \n                                                            })\n    df[\"SimplBsmtCond\"] = df.BsmtCond.replace({1 : 1, \n                                                     2 : 1, 3 : 1, \n                                                     4 : 2, 5 : 2 \n                                                    })\n    df[\"SimplBsmtQual\"] = df.BsmtQual.replace({1 : 1, \n                                                     2 : 1, 3 : 1, \n                                                     4 : 2, 5 : 2 \n                                                    })\n    df[\"SimplExterCond\"] = df.ExterCond.replace({1 : 1, \n                                                       2 : 1, 3 : 1, \n                                                       4 : 2, 5 : 2 \n                                                      })\n    df[\"SimplExterQual\"] = df.ExterQual.replace({1 : 1, \n                                                       2 : 1, 3 : 1, \n                                                       4 : 2, 5 : 2 \n                                                      })\n    df[\"OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"]\n    df[\"GarageGrade\"] = df[\"GarageQual\"] * df[\"GarageCond\"]\n    df[\"ExterGrade\"] = df[\"ExterQual\"] * df[\"ExterCond\"]\n    df[\"KitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"KitchenQual\"]\n    df[\"FireplaceScore\"] = df[\"Fireplaces\"] * df[\"FireplaceQu\"]\n    df[\"GarageScore\"] = df[\"GarageArea\"] * df[\"GarageQual\"]\n    df[\"PoolScore\"] = df[\"PoolArea\"] * df[\"PoolQC\"]\n    df[\"SimplOverallGrade\"] = df[\"SimplOverallQual\"] * df[\"SimplOverallCond\"]\n    df[\"SimplExterGrade\"] = df[\"SimplExterQual\"] * df[\"SimplExterCond\"]\n    df[\"SimplPoolScore\"] = df[\"PoolArea\"] * df[\"SimplPoolQC\"]\n    df[\"SimplGarageScore\"] = df[\"GarageArea\"] * df[\"SimplGarageQual\"]\n    df[\"SimplFireplaceScore\"] = df[\"Fireplaces\"] * df[\"SimplFireplaceQu\"]\n    df[\"SimplKitchenScore\"] = df[\"KitchenAbvGr\"] * df[\"SimplKitchenQual\"]\n    df[\"TotalBath\"] = df[\"BsmtFullBath\"] + (0.5 * df[\"BsmtHalfBath\"]) + \\\n    df[\"FullBath\"] + (0.5 * df[\"HalfBath\"])\n    df[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n    df[\"AllFlrsSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n    df[\"AllPorchSF\"] = df[\"OpenPorchSF\"] + df[\"EnclosedPorch\"] + \\\n    df[\"3SsnPorch\"] + df[\"ScreenPorch\"]\n    df[\"HasMasVnr\"] = df.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n                                                   \"Stone\" : 1, \"None\" : 0})\n    df[\"BoughtOffPlan\"] = df.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n                                                          \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n    return df","41b43dae":"def Polynomials_features(df):\n    df[\"OverallQual-s2\"] = df[\"OverallQual\"] ** 2\n    df[\"OverallQual-s3\"] = df[\"OverallQual\"] ** 3\n    df[\"OverallQual-Sq\"] = np.sqrt(df[\"OverallQual\"])\n    df[\"AllSF-2\"] = df[\"AllSF\"] ** 2\n    df[\"AllSF-3\"] = df[\"AllSF\"] ** 3\n    df[\"AllSF-Sq\"] = np.sqrt(df[\"AllSF\"])\n    df[\"AllFlrsSF-2\"] = df[\"AllFlrsSF\"] ** 2\n    df[\"AllFlrsSF-3\"] = df[\"AllFlrsSF\"] ** 3\n    df[\"AllFlrsSF-Sq\"] = np.sqrt(df[\"AllFlrsSF\"])\n    df[\"GrLivArea-2\"] = df[\"GrLivArea\"] ** 2\n    df[\"GrLivArea-3\"] = df[\"GrLivArea\"] ** 3\n    df[\"GrLivArea-Sq\"] = np.sqrt(df[\"GrLivArea\"])\n    df[\"SimplOverallQual-s2\"] = df[\"SimplOverallQual\"] ** 2\n    df[\"SimplOverallQual-s3\"] = df[\"SimplOverallQual\"] ** 3\n    df[\"SimplOverallQual-Sq\"] = np.sqrt(df[\"SimplOverallQual\"])\n    df[\"ExterQual-2\"] = df[\"ExterQual\"] ** 2\n    df[\"ExterQual-3\"] = df[\"ExterQual\"] ** 3\n    df[\"ExterQual-Sq\"] = np.sqrt(df[\"ExterQual\"])\n    df[\"GarageCars-2\"] = df[\"GarageCars\"] ** 2\n    df[\"GarageCars-3\"] = df[\"GarageCars\"] ** 3\n    df[\"GarageCars-Sq\"] = np.sqrt(df[\"GarageCars\"])\n    df[\"TotalBath-2\"] = df[\"TotalBath\"] ** 2\n    df[\"TotalBath-3\"] = df[\"TotalBath\"] ** 3\n    df[\"TotalBath-Sq\"] = np.sqrt(df[\"TotalBath\"])\n    df[\"KitchenQual-2\"] = df[\"KitchenQual\"] ** 2\n    df[\"KitchenQual-3\"] = df[\"KitchenQual\"] ** 3\n    df[\"KitchenQual-Sq\"] = np.sqrt(df[\"KitchenQual\"])\n    df[\"GarageScore-2\"] = df[\"GarageScore\"] ** 2\n    df[\"GarageScore-3\"] = df[\"GarageScore\"] ** 3\n    df[\"GarageScore-Sq\"] = np.sqrt(df[\"GarageScore\"])\n    return df","677fa09f":"train = Encodage(train)\ntrain = Replace_numerica_features(train)\ntrain = Replace_category_features(train)\ntrain = Simplifications_of_existing_features(train)\ntrain = Polynomials_features(train)\ntrain.head()","e5628401":"test_data = test_set.copy()","71f7c8c0":"df_test = Encodage(test)\ndf_test = Replace_numerica_features(df_test)\ndf_test = Replace_category_features(df_test)\ndf_test = Simplifications_of_existing_features(df_test)\ndf_test = Polynomials_features(df_test)","06466e54":"target = train[\"SalePrice\"]","5e61072c":"categorical_features = train.select_dtypes(include = [\"object\"]).columns\nnumerical_features = train.select_dtypes(exclude = [\"object\"]).columns\ncorrelation_SalePrice = pd.DataFrame(train.corr()['SalePrice']).sort_values(by=\"SalePrice\",ascending=False)\nplt.figure(figsize=(18,18))\nsns.heatmap(correlation_SalePrice, annot=True)","b285d3d3":"numerical_features = numerical_features.drop(\"SalePrice\")","8f746094":"categorical_features_test = df_test.select_dtypes(include = [\"object\"]).columns\nnumerical_features_test = df_test.select_dtypes(exclude = [\"object\"]).columns","a4c8a5a1":"train_num = train[numerical_features]\ntrain_cat = train[categorical_features]","928ac00d":"test_num = df_test[numerical_features_test]\ntest_cat = df_test[categorical_features_test]","cc133f45":"train_num = train_num.fillna(train_num.median())","1db56655":"test_num = test_num.fillna(test_num.median())","77281c60":"train_num.head()","f48d1122":"train_cat.head()","9c348aaa":"test_num.head()","b57f6b1f":"test_cat.head()","0e0197a6":"from scipy.stats import skew ","464e8c4e":"\"\"\"\nIn statistics, skewness is a measure of the asymmetry of the probability distribution of a random variable\nabout its mean. In other words, skewness tells you the amount and direction of skew . The skewness value \ncan be positive or negative, or even undefined. If skewness is 0, the data are perfectly symmetrical,\nalthough it is quite unlikely for real-world data. As a general rule of thumb:\n- If skewness is less than -1 or greater than 1, the distribution is highly skewed.\n- If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n- If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n\"\"\"\ndef skewness(dFrame):\n    skewness = dFrame.apply(lambda x: skew(x))\n    skewness = skewness[abs(skewness) > 0.5]\n    print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n    skewed_features = skewness.index\n    dFrame[skewed_features] = np.log1p(dFrame[skewed_features])\n    return dFrame","dc573b00":"train_num = skewness(train_num)\ntest_num = skewness(test_num)","ea8411c0":"train_num.head()","04a5733d":"test_num.head()","d115ed3f":"train_cat = pd.get_dummies(train_cat)\ntest_cat = pd.get_dummies(test_cat)","24351ec0":"train_cat.head()","7511d2f8":"test_cat.head()","5d45fb15":"train_data_set = pd.concat([train_num, train_cat], axis=1)\ntest_data_set = pd.concat([test_num, test_cat], axis=1)","6e9c339a":"#del best_coor[0]\n#best_coor.insert(0,'Id')","05da64ff":"#train_data_set = train_data_set[best_coor]\n#test_data_set = test_data_set[best_coor]","09a4fd7d":"# we can combine categorical and numerical features\ntrain_data_set.head()","9f581546":"test_data_set.head()","9100fca4":"from sklearn.model_selection import train_test_split","cbf9a2f8":"print(train_data_set.shape)\nprint(target.shape)","8ad7ed19":"X_train, X_test, y_train, y_test = train_test_split(train_data_set, target, test_size=0.2, random_state=0)","553963ba":"print(X_train.shape)\nprint(X_test.shape)","6d6fb430":"train_data_set.head()","c0e283a3":"test_data_set.head()","1fbb4e24":"print(test_data_set.shape)","2a4ee8e9":"from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, make_scorer\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom math import sqrt\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.model_selection import cross_val_score, KFold","3ae25bbe":"List_of_model = []","61369f60":"preprocessor = make_pipeline(SelectKBest(f_classif, k='all'))","e3020524":"score = make_scorer(mean_squared_error, greater_is_better=False)","b753b7d8":"alphas = 10**np.linspace(10,-2,100)*0.5","6f3277b0":"Linear_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), LinearRegression())\nRidgeCV_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), RidgeCV(alphas = alphas))\nRidge_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), Ridge(alpha=0.01))\nLassoCV_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), LassoCV(alphas = None, cv = 10, max_iter = 100000))\nLasso_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), Lasso(alpha = 0.01))\nElasticNet_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), ElasticNet(alpha=0.01, l1_ratio=0.5))\nRandomForestRegressor_pipe = make_pipeline(preprocessor, StandardScaler(), RandomForestRegressor(max_depth=2, random_state=0))\nAdaBoostRegressor_pipe = make_pipeline(preprocessor, StandardScaler(), AdaBoostRegressor(random_state=0, n_estimators=100))\nSVR_pipe = make_pipeline(preprocessor, StandardScaler(), SVR(C=1.0, epsilon=0.2))\nDecisionTreeRegressor_pipe = make_pipeline(preprocessor, StandardScaler(), DecisionTreeRegressor(max_depth=3,random_state=0))\nKNeighborsRegressor_pipe = make_pipeline(preprocessor, StandardScaler(), KNeighborsRegressor())","2319f88d":"List_of_model = {'Linear_Regression_pipe': Linear_Regression_pipe,\n                'Ridge_Regression_pipe': Ridge_Regression_pipe,\n                'RidgeCV_Regression_pipe': RidgeCV_Regression_pipe,\n                'Lasso_Regression_pipe': Lasso_Regression_pipe,\n                'LassoCV_Regression_pipe': LassoCV_Regression_pipe,\n                'ElasticNet_Regression_pipe': ElasticNet_Regression_pipe,\n                'RandomForestRegressor_pipe': RandomForestRegressor_pipe,\n                'AdaBoostRegressor_pipe': AdaBoostRegressor_pipe,\n                'SVR_pipe': SVR_pipe,\n                'DecisionTreeRegressor_pipe': DecisionTreeRegressor_pipe,\n                'KNeighborsRegressor_pipe': KNeighborsRegressor_pipe}","149bc5b7":"def RMSE_Cross_validation(model,X,y,score):\n    rmse = np.sqrt(-cross_val_score(model, X, y, cv=5, scoring=score))\n    return (rmse)","e05f7b2e":"dict_rmse = {}","51d35792":"def Model_Evaluation(model, key):\n    model.fit(X_train, y_train)\n    predic_train = model.predict(X_train)\n    y_pred = model.predict(X_test) \n      \n    print(\"{} Performance for training and testing set\".format(key))\n    print(\"----------------------------------------------------------------------------\")\n    rmse_train = RMSE_Cross_validation(model,X_train, y_train,\"neg_mean_squared_error\").mean()\n    rmse_test = RMSE_Cross_validation(model,X_test, y_test,\"neg_mean_squared_error\").mean()\n    print(\"Train Mean Squared Error:\",rmse_train )\n    print(\"Test MSE:\", rmse_test)\n    dict_rmse.update({key:rmse_train})\n    dict_rmse.update({key+'test': rmse_test})\n    plt.figure()\n    plt.title(key)\n    plt.scatter(predic_train, predic_train - y_train, c=\"green\", marker=\"o\", label=\"Training\")\n    plt.scatter(y_pred, y_pred - y_test, c=\"blue\", marker=\"s\", label=\"Testing\")\n    plt.xlabel(\"Predict value\")\n    plt.ylabel(\"Residuals\")\n    plt.legend()\n    plt.show()\n    \n    plt.figure()\n    plt.title(key)\n    plt.scatter(predic_train, y_train, c=\"green\", marker=\"o\", label=\"Training\")\n    plt.scatter(y_pred, y_test, c=\"blue\", marker=\"s\", label=\"Testing\")\n    plt.xlabel(\"Predict value\")\n    plt.ylabel(\"Real value\")\n    plt.legend()\n    plt.show()\n    predictors = X_train.columns\n    if (key == \"Ridge_Regression_pipe\"):\n        sortval = pd.Series(model.named_steps['ridge'].coef_, predictors).sort_values()\n        coef = pd.concat([sortval.head(10),sortval.tail(10)\n                         ])\n        coef.plot(kind='bar', title='Modal Coefficients')\n    elif (key == \"RidgeCV_Regression_pipe\"):\n        sortval = pd.Series(model.named_steps['ridgecv'].coef_, predictors).sort_values()\n        coef = pd.concat([sortval.head(10), sortval.tail(10)])\n        coef.plot(kind='bar', title='Modal Coefficients')\n    elif (key == \"Lasso_Regression_pipe\"):\n        sortval = pd.Series(model.named_steps['lasso'].coef_, predictors).sort_values()\n        coef = pd.concat([sortval.head(10), sortval.tail(10)])\n        coef.plot(kind='bar', title='Modal Coefficients')\n    elif (key == \"LassoCV_Regression_pipe\"):\n        sortval = pd.Series(model.named_steps['lassocv'].coef_, predictors).sort_values()\n        coef = pd.concat([sortval.head(10), sortval.tail(10)])\n        coef.plot(kind='bar', title='Modal Coefficients')\n    elif (key == \"ElasticNet_Regression_pipe\" ):\n        sortval = pd.Series(model.named_steps['elasticnet'].coef_, predictors).sort_values()\n        coef = pd.concat([sortval.head(10), sortval.tail(10)])\n        coef.plot(kind='bar', title='Modal Coefficients')","f33a1b2b":"for key, model  in List_of_model.items():\n    Model_Evaluation(model, key)","b5bf5261":"dict_rmse","21ea1e48":"list_model_optimize = []","bc954143":"alphas = 10**np.linspace(10,-2,50)*0.5","d09ca882":"preprocessor = make_pipeline(SelectKBest(f_classif, k='all'))","90667aea":"LassoCV_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), LassoCV(alphas=alphas, cv=5, n_jobs=-1, max_iter = 105000))\nElasticNet_Regression_pipe = make_pipeline(preprocessor, StandardScaler(), ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter = 105000))","d1fc5f32":"list_model_optimize = {'LassoCV_Regression_pipe': LassoCV_Regression_pipe,\n                        'ElasticNet_Regression_pipe': ElasticNet_Regression_pipe}","07399836":"list_columns = test_data_set.columns.tolist()\nlist_columns_train = train_data_set.columns.tolist()\nlist_final = []\nfor col in list_columns:\n    if col in list_columns_train:\n        list_final.append(col)\ntrain_final_set = train_data_set[list_final]\ntest_final_set = test_data_set[list_final]","2bc362a1":"print(train_final_set.shape)\nprint(test_final_set.shape)","8168bf0e":"def Model_Evaluation_submission(model, key):\n    model.fit(train_final_set, target)\n    predic_train = model.predict(train_final_set)\n    y_pred = model.predict(test_final_set) \n      \n    print(\"{} Performance for training and testing set\".format(key))\n    print(\"----------------------------------------------------------------------------\")\n    rmse_train = RMSE_Cross_validation(model,train_final_set, target,\"neg_mean_squared_error\").mean()\n    print(\"Train Mean Squared Error:\",rmse_train )\n    print(\"Score:\",model.score(train_final_set, target))\n    \n    plt.figure()\n    plt.title(key)\n    plt.scatter(predic_train, target, c=\"green\", marker=\"o\", label=\"Training\")\n    plt.xlabel(\"Predict value\")\n    plt.ylabel(\"Real value\")\n    plt.legend()\n    plt.show()\n    return y_pred","8b497459":"for key, model  in list_model_optimize.items():\n    Model_Evaluation(model, key)","9c9fd4b7":"lasso_pred = Model_Evaluation_submission(LassoCV_Regression_pipe,\"lasso\")","3ef88f60":"lasso_pred","8e538f51":"ElasticNet_pred = Model_Evaluation_submission(ElasticNet_Regression_pipe,\"ElasticNet\")","c12c2372":"ElasticNet_pred","10b84f61":"from sklearn.ensemble import BaggingRegressor\nimport xgboost as xgb\nimport lightgbm as lgbm","b8835bbc":"regrElasticNet = BaggingRegressor(base_estimator=ElasticNet(alpha=0.01, l1_ratio=0.5), n_estimators=2400,n_jobs=1, random_state=0).fit(train_final_set, target)\ny_baggin_elasticNet = regrElasticNet.predict(test_final_set)","4dbf48d3":"y_pred_bagging_elasticNet = np.expm1(y_baggin_elasticNet);\ny_pred_bagging_elasticNet","5a75b080":"regrElasticNet.score(train_final_set,target)","acae9a0b":"xgb_model = xgb.XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=100, min_child_weight=1.7817, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=0)","547fd613":"xgb_model_pipe = make_pipeline(preprocessor, StandardScaler(), xgb_model)\nxgb_model_pipe.fit(train_final_set,target)\nxgb_predict = xgb_model_pipe.predict(test_final_set)\nxgb_score = xgb_model_pipe.score(train_final_set, target)","d5fd4689":"xgb_train_predict = xgb_model_pipe.predict(train_final_set)","c1355d34":"xgb_predict = np.expm1(xgb_predict)\nprint(xgb_predict)","529a5db2":"xgb_score","a6986730":"print(RMSLE(target, xgb_train_predict))","d43314e9":"lgbm_model = lgbm.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","5b017e03":"lgbm_model_pipe = make_pipeline(preprocessor, StandardScaler(), lgbm_model)\nlgbm_model_pipe.fit(train_final_set,target)\nlgbm_predict = lgbm_model_pipe.predict(test_final_set)\nlgbm_score = lgbm_model_pipe.score(train_final_set, target)","041e4fbf":"lgbm_train_predict = lgbm_model_pipe.predict(train_final_set)","f9f6dac9":"lgbm_predict = np.expm1(lgbm_predict)\nprint(lgbm_predict)\n","0a511dfd":"lgbm_score","1272f6d7":"print(RMSLE(target, lgbm_train_predict))","4952e887":"def RMSLE(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","c7349550":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.preprocessing import RobustScaler","6f0f10b3":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","9e3f7adf":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))","16ea77b0":"stacked_averaged_models = StackingAveragedModels(base_models = (xgb_model, lgbm_model, regrElasticNet),\n                                                 meta_model = lasso)","61e6cfc2":"n_folds = 5","a2eef083":"def rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_final_set.values)\n    rmse= np.sqrt(-cross_val_score(model, train_final_set.values, target, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","75aca51a":"score = rmsle_cv(lasso)","b6ed2e90":"print(\"lasso score mean :{} score std {}\".format(score.mean(),score.std()))","d148864c":"stacked_averaged_models.fit(train_final_set.values, target)\nstacked_train_pred = stacked_averaged_models.predict(train_final_set.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test_final_set.values))\nprint(RMSLE(target, stacked_train_pred))","a8b8328a":"print('RMSLE score train :',RMSLE(target,stacked_train_pred*0.80 +xgb_train_predict*0.1 + lgbm_train_predict*0.1 ))","a305f07b":"predict_ens_final = stacked_pred*0.80 + xgb_predict*0.1 + lgbm_predict*0.1","cce61521":"predict_ens_final","832952c1":"submission_id = pd.DataFrame(test_final_set[\"Id\"])\nsubmission_salePrice = pd.DataFrame({\"SalePrice\":predict_ens_final})\nsubmission = pd.concat([submission_id,submission_salePrice],axis=1)\nsubmission.to_csv('house_submission.csv', header= True, index= False) ","89dac6cb":"* LightGBM Regressor","57e7fd4f":"# **Deep analysis**","26f43f2e":"**Target analysis**","02314000":"Okay, it's really better now","44e59a1f":"It is better to see with seaborn than the variables which are in the best correlation, for a global view this is important.","518176f1":"# **PRE-PROCESSING**","4fd9eef8":"We can see that with year the Sale Price have got inflation during years.","7a62556a":"* We will add cross validation for sklearn.","320d13a9":"This graph shows the correlation between variables, and we see that other variables have a negative correlation or a value less than 0.40.\nThe objective here is to find the best variables with the best correlation for the future model.","c72134f8":"Just by showing the different relationships between variables with SalePrice, we can see the good linear relationships with TotalBsmtSF, GrLivArea. But some variables also give a better correlation like OverallQual, YearBuilt, 1stFlrSF, GarageCars, GarageArea.","d56ce73f":"\n    SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n    MSSubClass: The building class\n    MSZoning: The general zoning classification\n    LotFrontage: Linear feet of street connected to property\n    LotArea: Lot size in square feet\n    Street: Type of road access\n    Alley: Type of alley access\n    LotShape: General shape of property\n    LandContour: Flatness of the property\n    Utilities: Type of utilities available\n    LotConfig: Lot configuration\n    LandSlope: Slope of property\n    Neighborhood: Physical locations within Ames city limits\n    Condition1: Proximity to main road or railroad\n    Condition2: Proximity to main road or railroad (if a second is present)\n    BldgType: Type of dwelling\n    HouseStyle: Style of dwelling\n    OverallQual: Overall material and finish quality\n    OverallCond: Overall condition rating\n    YearBuilt: Original construction date\n    YearRemodAdd: Remodel date\n    RoofStyle: Type of roof\n    RoofMatl: Roof material\n    Exterior1st: Exterior covering on house\n    Exterior2nd: Exterior covering on house (if more than one material)\n    MasVnrType: Masonry veneer type\n    MasVnrArea: Masonry veneer area in square feet\n    ExterQual: Exterior material quality\n    ExterCond: Present condition of the material on the exterior\n    Foundation: Type of foundation\n    BsmtQual: Height of the basement\n    BsmtCond: General condition of the basement\n    BsmtExposure: Walkout or garden level basement walls\n    BsmtFinType1: Quality of basement finished area\n    BsmtFinSF1: Type 1 finished square feet\n    BsmtFinType2: Quality of second finished area (if present)\n    BsmtFinSF2: Type 2 finished square feet\n    BsmtUnfSF: Unfinished square feet of basement area\n    TotalBsmtSF: Total square feet of basement area\n    Heating: Type of heating\n    HeatingQC: Heating quality and condition\n    CentralAir: Central air conditioning\n    Electrical: Electrical system\n    1stFlrSF: First Floor square feet\n    2ndFlrSF: Second floor square feet\n    LowQualFinSF: Low quality finished square feet (all floors)\n    GrLivArea: Above grade (ground) living area square feet\n    BsmtFullBath: Basement full bathrooms\n    BsmtHalfBath: Basement half bathrooms\n    FullBath: Full bathrooms above grade\n    HalfBath: Half baths above grade\n    Bedroom: Number of bedrooms above basement level\n    Kitchen: Number of kitchens\n    KitchenQual: Kitchen quality\n    TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n    Functional: Home functionality rating\n    Fireplaces: Number of fireplaces\n    FireplaceQu: Fireplace quality\n    GarageType: Garage location\n    GarageYrBlt: Year garage was built\n    GarageFinish: Interior finish of the garage\n    GarageCars: Size of garage in car capacity\n    GarageArea: Size of garage in square feet\n    GarageQual: Garage quality\n    GarageCond: Garage condition\n    PavedDrive: Paved driveway\n    WoodDeckSF: Wood deck area in square feet\n    OpenPorchSF: Open porch area in square feet\n    EnclosedPorch: Enclosed porch area in square feet\n    3SsnPorch: Three season porch area in square feet\n    ScreenPorch: Screen porch area in square feet\n    PoolArea: Pool area in square feet\n    PoolQC: Pool quality\n    Fence: Fence quality\n    MiscFeature: Miscellaneous feature not covered in other categories\n    MiscVal: $Value of miscellaneous feature\n    MoSold: Month Sold\n    YrSold: Year Sold\n    SaleType: Type of sale\n    SaleCondition: Condition of sale\n","3d79224d":"**normal probability Histogram**","9b65dfbd":"There is many method to replace missing values, but we can use mean, median or mode.","9e842521":"the target of data is salePrice (good new)","d4f3e995":"# CONCLUSION","c8154a78":"# **EXPLORATORY DATA ANALYSIS**","2dd4e176":"It is better to try many machine learning models, I have a particular view of the result, so I can try another model like BaggingRegressor or xgboost.","695e1f22":"As you can see, we will training many model of Machine Learning regressor and we can see that little be model \ngive the best score.\nThe next step is optimize hyper-param of best model, example we can change alpha value, n_estimator or iteration of model.","1c8c0950":"# DATA VISUALIZATION WITH SEABORN","5ff9f1e3":"# Missing Values","56f8a227":"Interestingly, we are looking at the tilt of the skewed normal distribution to the right. (Mode < Median < Mean)","93003bf1":"**First we will study shape analysis**","e735564e":"Here, we will use only TotalBsmtSF > 0 for display distribution","aa90bfae":"# **OPTIMIZATION**","fbf7e55f":"* XGBoost Regressor","6d2751fc":"I will use three different regression methods to create predictions (XGBoost, LightGBM and ElasticNet) and stack them to produce a final prediction.","a1af4163":"* **knowledge of variables**","33073c24":"# **MISSING VALUES**","592da848":"# **Categorical features Relationship **","eeb44531":"# **MODELING**","e7e91cd9":"hummm, that's no better because the probability doesn't follow the diagonal line. we will use the logarithm to solve this problem.","9082b24b":"All rigth, we know the correlation of SalePrice with other variables, it's good information, but it's better if know the target distribution.\n","6b851191":"As you can see, Elastic Net_Regression_pipe and LassoCV_Regression_pipe give the best RMSE, so we'll keep the models and can optimize for final.","87432cf2":"It's a good challenge and don't forget that the different steps during the processing of the project are important in machine learning."}}