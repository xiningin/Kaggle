{"cell_type":{"99de6884":"code","54808823":"code","2e1ccf5b":"code","53107a4a":"code","a158ca0f":"code","e4561671":"code","b57b3486":"code","4fa34771":"code","62680e1a":"code","bf4156d8":"code","cb321a6b":"code","62bcb287":"code","3ce54f60":"code","1d23dc9b":"code","f11a30ff":"code","732ac9b9":"code","c3578734":"code","a4a33072":"code","dd5481a2":"code","e540eb7e":"code","f78f2138":"code","b0e3719f":"code","21fafc5b":"code","8dd94181":"code","dc267479":"markdown","54d6ecb2":"markdown","7f825a54":"markdown","5c7e2dc4":"markdown","91c3f5df":"markdown","ab0a5964":"markdown","d505a702":"markdown","60b0210f":"markdown","9b8f216f":"markdown","ed519b17":"markdown","628adbb5":"markdown","24cc2462":"markdown","26b63e7c":"markdown","f7a60ec2":"markdown","e5b323f0":"markdown"},"source":{"99de6884":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport sys\nimport os\nimport random\nfrom pathlib import Path\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras import optimizers\nfrom keras.initializers import Constant\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU\nimport tensorflow_addons as tfa\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport tensorflow as tf\n","54808823":"IMAGE_PATH = '..\/input\/chinese-mnist\/data\/data\/'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nRANDOM_STATE = 42\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2\nBATCH_SIZE = 32\nNO_EPOCHS = 50\nPATIENCE = 5\nVERBOSE = 1","2e1ccf5b":"data_df = pd.read_csv('..\/input\/chinese-mnist\/chinese_mnist.csv')\nprint(data_df.shape) \ndata_df.sample(100).head(4)","53107a4a":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","a158ca0f":"def create_file_name(x):\n    \n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","e4561671":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)\ndata_df.head()","b57b3486":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","4fa34771":"def read_image_sizes(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    return list(image.shape)","62680e1a":"tqdm.pandas()\nm = np.stack(data_df['file'].progress_apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h'])\ndata_df = pd.concat([data_df,df],axis=1, sort=False)\ndata_df.head()","bf4156d8":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.unique()}\")","cb321a6b":"train_df, test_df = train_test_split(data_df, \n                                     test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data_df[\"code\"].values)","62bcb287":"train_df, val_df = train_test_split(train_df, \n                                    test_size=VAL_SIZE, random_state=RANDOM_STATE, stratify=train_df[\"code\"].values)","3ce54f60":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))","1d23dc9b":"def read_image(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT, 1), mode='reflect')\n    return image[:,:,:]","f11a30ff":"def categories_encoder(dataset, var='character'):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = pd.get_dummies(dataset[var], drop_first=False)\n    return X, y","732ac9b9":"X_train, y_train = categories_encoder(train_df)\nX_val, y_val = categories_encoder(val_df)\nX_test, y_test = categories_encoder(test_df)","c3578734":"model=Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), input_shape=(64, 64, 1), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 128, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 160, kernel_size=(3,3),  padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 256, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Conv2D(filters = 256, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 384, kernel_size=(3,3),  padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Conv2D(filters = 384, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(15, activation='softmax'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","a4a33072":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** (x+NO_EPOCHS))\nearlystopper = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\ncheckpointer = ModelCheckpoint('best_model.h5',\n                                monitor='val_accuracy',\n                                verbose=VERBOSE,\n                                save_best_only=True,\n                                save_weights_only=True)","dd5481a2":"train_model  = model.fit(X_train, y_train,\n                  batch_size=BATCH_SIZE,\n                  epochs=NO_EPOCHS,\n                  verbose=1,\n                  validation_data=(X_val, y_val),\n                  callbacks=[earlystopper, checkpointer, annealer])","e540eb7e":"def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['accuracy']\n    val_acc = hist['val_accuracy']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    #define the traces\n    \n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    #add traces to the figure\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    #set the layout for the figure\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n    #plot\n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(train_model)","f78f2138":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","b0e3719f":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","21fafc5b":"def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])","8dd94181":"model_optimal = model\nmodel_optimal.load_weights('best_model.h5')\nscore = model_optimal.evaluate(X_test, y_test, verbose=0)\nprint(f'Best validation loss: {score[0]}, accuracy: {score[1]}')\n\ntest_accuracy_report(model_optimal)","dc267479":"# Conclusions\n\n- The model shows no signs of being over-fitting or under-fitting\n- Metrics of more than 99% accuracy were obtained in both the test data and the validation data\n- The architecture of the network is not exactly the same as the paper used but it has the same amount of layers.\n- In the table above we can notice the accuracy per element, revealing that the element with less accuracy has a value of 0.97\n- These results confirm the efficiency of the study done by Xiaoa","54d6ecb2":"# Reviewing the metrics in the validation and test sets","7f825a54":"# Visualizing the evolution of loss and accuracy","5c7e2dc4":"# Checking the amount of images\n","91c3f5df":"# Checking the amount of images stored","ab0a5964":"# Libraries\n","d505a702":"# Parameters to be used in the convolutional network","60b0210f":"# Creating network topology, inspired by [Xiaoa (2017)](https:\/\/arxiv.org\/pdf\/1702.07975.pdf)\n\n- the architecture is composed of 7 layers of convolution\n- A hidden layer of 1024 neurons\n- as an activation function PRelu is used\n- It was not necessary to use a pruning process, as used in the paper\n\n\n","9b8f216f":"# Encoding images to create network","ed519b17":"# Checking the dimension of the images","628adbb5":"# Checking samples and sub-samples of the data","24cc2462":"# Creating datasets to build the network","26b63e7c":"# Data","f7a60ec2":"# Training the neural network","e5b323f0":"# Adding the full name of the image"}}