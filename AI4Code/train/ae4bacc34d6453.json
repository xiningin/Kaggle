{"cell_type":{"0cc63aaf":"code","ef215a94":"code","cd9c86d3":"code","350899d3":"code","e10fd3ad":"code","eb41daa8":"code","c989a3bb":"code","d5a0623b":"code","8d45403f":"code","c193ec27":"code","7270278e":"code","cf5ae121":"code","10d816b3":"code","941d827d":"code","af3ca3e3":"code","80a066a4":"code","49bbcbb2":"code","10dcc56e":"code","d4d4150e":"code","e36ff932":"code","48ca9900":"code","6a3dfbf1":"code","d46f96bc":"code","b627b294":"code","365fa39b":"code","a664d730":"code","210293d1":"markdown","60c6e427":"markdown","8a487a6e":"markdown","1b7f1b8b":"markdown","b1bd6416":"markdown","51930c54":"markdown","cb5d7ca2":"markdown","fbdb4fd9":"markdown","a88f7471":"markdown","efa0fe8b":"markdown","ce2b26f5":"markdown","14918602":"markdown","4aac6f0e":"markdown","b1558a59":"markdown","3373ced4":"markdown","d7163b8e":"markdown","331d036b":"markdown"},"source":{"0cc63aaf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor \nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import metrics","ef215a94":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')","cd9c86d3":"train.head(10)","350899d3":"test.head(10)","e10fd3ad":"train.shape, test.shape","eb41daa8":"train.describe()","c989a3bb":"test.describe()","d5a0623b":"train.isnull().sum()","8d45403f":"test.isnull().sum()","c193ec27":"target = train[\"loss\"].value_counts()\ntarget","7270278e":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'])\\\n                            .background_gradient(subset=['std'])\\\n                            .background_gradient(subset=['min'])\\\n                            .background_gradient(subset=['50%'])","cf5ae121":"train['f60'].describe","10d816b3":"test.drop(columns=['id']).describe().T.style.bar(subset=['mean'])\\\n                            .background_gradient(subset=['std'])\\\n                            .background_gradient(subset=['min'])\\\n                            .background_gradient(subset=['50%'])","941d827d":"test['f60'].describe","af3ca3e3":"sns.distplot(train['loss'])","80a066a4":"fig, ax = plt.subplots(figsize=(10, 6))\nsns.countplot(data = train, \n              x = 'loss', \n              color = 'blue')","49bbcbb2":"fig, ax = plt.subplots(figsize = (40, 32))\nsns.heatmap(train.corr(), annot = True, \n            fmt = \".2f\", \n            cmap = 'coolwarm',\n            cbar_kws = {\"shrink\": .8})","10dcc56e":"# Train data\nX = train.drop(columns = ['loss'])\ny = train['loss'].values\n# Test data\nX_test = test\nprint('Train set:', X.shape)\nprint('Test set:', X_test.shape)","d4d4150e":"X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True)","e36ff932":"model1_1 = LinearRegression()\nmodel1_1.fit(X_train, y_train)\npred1_1 = model1_1.predict(X_test)\n\nrmse1_1 = metrics.mean_squared_error(y_test, pred1_1, squared = False)\nprint('model 1_1 MSE score: ', rmse1_1)","48ca9900":"model1_2 = CatBoostRegressor()\nmodel1_2.fit(X_train, y_train, verbose = 0)\npred1_2 = model1_2.predict(X_test, verbose = 0)\n\nrmse1_2 = metrics.mean_squared_error(y_test, pred1_2, squared = False)\nprint('model 1_2 MSE score: ', rmse1_2)","6a3dfbf1":"model1_3 = XGBRegressor()\nmodel1_3.fit(X_train, y_train, verbose = 0)\npred1_3 = model1_3.predict(X_test)\n\nrmse1_3 = metrics.mean_squared_error(y_test, pred1_3, squared = False)\nprint('model 1_3 MSE score: ', rmse1_3)\n","d46f96bc":"model1_4 = LGBMRegressor()\nmodel1_4.fit(X_train, y_train, verbose = 0)\npred1_4 = model1_4.predict(X_test)\n\nrmse1_4 = metrics.mean_squared_error(y_test, pred1_4, squared = False)\nprint('model 4 MSE score: ', rmse1_4)","b627b294":"model1_5 = AdaBoostRegressor()\nmodel1_5.fit(X_train, y_train)\npred1_5 = model1_5.predict(X_test)\n\nrmse1_5 = metrics.mean_squared_error(y_test, pred1_5, squared = False)\nprint('model 1_5 MSE score: ', rmse1_5)","365fa39b":"sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\nsub.head()","a664d730":"test_pred_cat = model1_2.predict(test)\ntest_pred_lgbm = model1_4.predict(test)\ntest_pred = 0.6 * test_pred_cat + 0.4 * test_pred_lgbm\nsub['loss'] = test_pred\nsub.to_csv(\"submission.csv\", index = False)","210293d1":"# 4- Modelos de regresion","60c6e427":"**2- Cat Boost**","8a487a6e":"**Datos nulos**","1b7f1b8b":"**1- Regresion Lineal**","b1bd6416":"**4- Light Gradient Regressor**","51930c54":"# 3- Mostramos los datos","cb5d7ca2":"# **2- Cargamos los datos**","fbdb4fd9":"**Descricion de los datos**","a88f7471":"**5- Ada Boost Regressor**","efa0fe8b":"En la celda superior podemos ver la suma de los valores iguales en la columna objetivo, donde la mayor cuenta es al principio y va perdiendo cantidad a medida que avanza, haciendo el minimo en el ultimo valor de la columna 'loss'","ce2b26f5":"# 5- Subimos los datos","14918602":"Como hemos visto en esta peque\u00f1a exploracion, no hay datos nulos y todos los datos son de tipo numerico","4aac6f0e":"**Separamos los datos en train y test**","b1558a59":"# TABULAR PLAYGROND AGOSTO 2021\n\nEn esta edicion del concurso, se nos pide usar una regresi\u00f3n lineal para evaluar, sobre un conjunto de datos sinteticos, que suman 150.000 filas y 92 columnas \n\nComo viene siendo costumbre hasta ahora, lo primero que haremos ser\u00e1 dividir el ejercicio en partes, primero,cargamos las librerias que vamos a usar y a\u00f1adiendo las que necesitemos a medida que vamos avanzando en el trabajo, despues cargamos los datos y hacemos una exploracion en ellos, una vez obtenida la informaci\u00f3n que consideramos importante y sacado conclusiones en base a ello, se limpian los datos para que el entrenamiento nos resulte lo mejor posible. Con los dartos limpios, entrenamos los modelos y subimos los datos con el mejor de ellos\n\n# **1- Cargamos las librerias**\n\npandas nos permite leer los datos del dataset\n\nnumpy es una libreria matematica\n\nseaborn y matplotlib.pyplot  son librerias graficas\n\ntrain_test_split nos permitir\u00e1 dividir el dataset entre entrenamiento y validaci\u00f3n\n\nLinearRegression, XGBRegressor, ADA, CAT y LGBM crean modelos de regresion","3373ced4":"**Tam\u00f1o de los datos**","d7163b8e":"**3- Extreme Gradiente Boost Regresssor**","331d036b":"Vemos que no hay correlacion aparente entre los distintos valores de las columnas, por lo que no es necesario pensar en eliminar alguna de ellas"}}