{"cell_type":{"d98cdf53":"code","f8c65524":"code","4b99bbed":"code","1198e652":"code","1198bd66":"code","dc4b6ac5":"code","3115fd54":"code","5f8cf8b7":"code","36c21be8":"code","e3bfe025":"code","953d764e":"code","ccee31ab":"code","5ee78455":"code","5337554c":"code","74abb503":"code","96bad5f9":"code","8709416c":"code","1ddeec87":"code","38c0a1be":"code","ac41f3a2":"code","5e0fd399":"markdown","297b7163":"markdown","799eaba0":"markdown","db202fab":"markdown","1638f393":"markdown","1194f9a9":"markdown","6f9e60c4":"markdown","65c4d5cc":"markdown","bbfce2c7":"markdown","d1bf439a":"markdown","3a990e45":"markdown","2394d669":"markdown","2bc8413d":"markdown"},"source":{"d98cdf53":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom pylab import rcParams\nimport copy\nimport time\n%matplotlib inline","f8c65524":"train_ds = datasets.MNIST(root='\/tmp', train=True, download=True, transform=transforms.ToTensor())\ntest_ds = datasets.MNIST(root='\/tmp', train=False, download=True, transform=transforms.ToTensor())","4b99bbed":"batch_size = 128","1198e652":"train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)","1198bd66":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","dc4b6ac5":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28*28, 1000)\n        self.fc2 = nn.Linear(1000, 1000)\n        self.fc3 = nn.Linear(1000, 500)\n        self.fc4 = nn.Linear(500, 200)\n        self.fc5 = nn.Linear(200, 10)\n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        out = self.fc5(x)\n        return out","3115fd54":"model = Net().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()","5f8cf8b7":"num_epochs = 25","36c21be8":"training_losses = []\ntraining_accuracies = []\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.\n    correct = 0\n    total = 0\n    for batch_idx, (data, target) in tqdm(enumerate(train_dl)):\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        running_loss+=loss.item()\n        _, predicted = torch.max(output.data, 1)\n        total+=target.size(0)\n        correct+=(predicted==target).sum().item()\n    training_losses.append(running_loss\/total)\n    training_accuracies.append(correct\/total)","e3bfe025":"plt.figure(1, figsize=(15, 3))\nplt.subplot(121)\nplt.plot(training_losses)\nplt.xlabel('Epoch')\nplt.ylabel('Training Loss')\nplt.subplot(122)\nplt.plot(training_accuracies)\nplt.xlabel('Epoch')\nplt.ylabel('Training Accuracy')","953d764e":"def test(model, test_dl):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in tqdm(test_dl):\n            data = data.to(device)\n            target = target.to(device)\n            output = model(data)\n            _, predicted = torch.max(output.data, 1)\n            total+=target.size(0)\n            correct+=(predicted==target).sum().item()\n    return correct\/total","ccee31ab":"original_accuracy = test(model, test_dl)\noriginal_accuracy","5ee78455":"def weight_prune(model, pruning_percentage, test_dl):\n    model1 = copy.deepcopy(model)\n    length = len(list(model1.parameters()))\n    for i, param in enumerate(model1.parameters()):\n        if len(param.size())!=1 and i<length-2:\n            weight = param.detach().cpu().numpy()\n            weight[np.abs(weight)<np.percentile(np.abs(weight), pruning_percentage)] = 0\n            weight = torch.from_numpy(weight).to(device)\n            param.data = weight\n    return test(model1, test_dl)","5337554c":"pruning_percent = [0, 25, 50, 60, 70, 80, 90, 95, 97, 99]","74abb503":"accuracy_weight_pruning = []\nfor percent in pruning_percent:\n    accuracy_weight_pruning.append(weight_prune(model, percent, test_dl))","96bad5f9":"rcParams['figure.figsize'] = 12, 8\nplt.plot(pruning_percent, np.size(pruning_percent)*[original_accuracy], 'r',\n         pruning_percent, accuracy_weight_pruning, 'b')\nplt.grid()\nplt.legend([['Original Accuracy'], \n            ['Accuracy with weight pruning']],\n           loc='lower left', fontsize='xx-large')\nplt.xlabel('Pruning Percentage', fontsize='xx-large')\nplt.ylabel('Accuracy', fontsize='xx-large')\nplt.xticks(pruning_percent)\nplt.yticks(np.arange(0, 1.05, 0.05))\nplt.show()","8709416c":"def neuron_pruning(model, pruning_percentage, test_dl):\n    model1 = copy.deepcopy(model)\n    length = len(list(model1.parameters()))\n    for i, param in enumerate(model1.parameters()):\n        if len(param.size())!=1 and i<length-2:\n            weight = param.detach().cpu().numpy()\n            norm = np.linalg.norm(weight, axis=0)\n            weight[:, np.argwhere(norm<np.percentile(norm, pruning_percentage))] = 0\n            weight = torch.from_numpy(weight).to(device)\n            param.data = weight\n    return test(model1, test_dl)","1ddeec87":"accuracy_neuron_pruning = []\nfor percent in pruning_percent:\n    accuracy_neuron_pruning.append(neuron_pruning(model, percent, test_dl))","38c0a1be":"rcParams['figure.figsize'] = 12, 8\nplt.plot(pruning_percent, np.size(pruning_percent)*[original_accuracy], 'r', pruning_percent, accuracy_neuron_pruning, 'b')\nplt.grid()\nplt.legend([['Original Accuracy'], ['Accuracy with neuron pruning']], loc='lower left', fontsize='xx-large')\nplt.xlabel('Pruning Percentage', fontsize='xx-large')\nplt.ylabel('Accuracy', fontsize='xx-large')\nplt.xticks(pruning_percent)\nplt.yticks(np.arange(0, 1.05, 0.05))\nplt.show()","ac41f3a2":"rcParams['figure.figsize'] = 12, 8\nplt.plot(pruning_percent, np.size(pruning_percent)*[original_accuracy], 'r',\n         pruning_percent, accuracy_weight_pruning, 'b',\n         pruning_percent, accuracy_neuron_pruning, 'g')\nplt.grid()\nplt.legend([['Original Accuracy'],\n            ['Accuracy with weight pruning'], \n            ['Accuracy with neuron pruning']], \n           loc='lower left', fontsize='xx-large')\nplt.xlabel('Pruning Percentage', fontsize='xx-large')\nplt.ylabel('Accuracy', fontsize='xx-large')\nplt.xticks(pruning_percent)\nplt.yticks(np.arange(0, 1.05, 0.05))\nplt.show()","5e0fd399":"### Lets first import the libraries to create a neural network","297b7163":"# Comparing weight pruning and neuron pruning by plotting them on same plot.","799eaba0":"### We will be using the MNIST data as it will be easier to explain using this data as it is not quite large in size","db202fab":"### Plotting the original accuracy in red and the accuracies for the weight-pruned accuracies in blue","1638f393":"In this kernel, i'll try to show how we can apply pruning techniques to neural networks using pytorch library","1194f9a9":"### Here we have created plots for training loss and training accuracy of the model as the epoch increases","6f9e60c4":"###### In production, large neural networks can become a problem because they have quite a lot amount of weights. This can lead to increasing the size of the model as well as the time taken to predict the result. To overcome this problem, we use a method called pruning. There are a lot of methods of pruning a neural network. In this kernel, I basically implement two main methods of pruning:\n\n###### 1. Weight Pruning<br\/> 2. Neuron Pruning","65c4d5cc":"# Neuron Pruning\n\n## In neuron pruning, we rank the columns of the weight by their l2-norm and the smallest k% are deleted.\n\nFor this purpose, I used the numpy's linalg.norm() method, which by default gives the l2-norm and set the columns where the norm is less than the pruning percentage to zero. Again I use copy module's deepcopy function to create a new sparse model.\n\nWe don't have to prune the weights for the last output layer. That is why, I have used **i<length-2** because the *length-2* parameter corresponds to the weight for the last layer.","bbfce2c7":"## Training the model\n\n    ### The model is trained for 25 epochs and gets >96% accuracy","d1bf439a":"## Creating a model \n\n### Lets create a 4-layer fully connected neural network to classify digits of MNIST","3a990e45":"# Weight pruning\n\n## In weight pruning, we prune away k% of weights. \n\nFor this, I have used the percentile function in numpy to get the kth smallest value in the weight. For all values in weight smaller than k, their weight will be set to zero. Also, we have to make sure that we don't affect the original model. For that purpose, I have used the copy module's deepcopy function to copy the model weights.\n\nWe don't have to prune the weights for the last output layer. That is why, I have used **i<length-2** because the *length-2* parameter corresponds to the weight for the last layer.","2394d669":"## Conclusion\n\nThis pruning method can be applied to any neural networks to decrease their size and time it takes to predict the answer for the test set. There are more advanced pruning techniques to apply to neural networks. I encourage the reader to search for these techniques on the internet and apply on his project to make his production time fast.","2bc8413d":"## Plotting the accuracy achieved due to neuron pruning"}}