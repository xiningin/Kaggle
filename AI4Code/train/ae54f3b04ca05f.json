{"cell_type":{"130e1f1d":"code","5bfff9f9":"code","1d25baeb":"code","0ad2ddc7":"code","7b75563f":"code","b5c99940":"code","94504c5b":"code","11ba0e8f":"code","8f78b193":"code","9bba2b4d":"code","bd778e03":"code","c938954c":"code","1d51b572":"code","d59cb45e":"code","d377b732":"code","931cd06a":"code","0b426c0f":"code","dcdc3d81":"code","94caf5cc":"code","8cd48209":"code","8d89cb6f":"code","3ccbcec6":"code","b313dc41":"code","fdad2945":"code","b11be6ad":"code","a67bd711":"code","885e2e29":"code","9524be01":"markdown","15792c75":"markdown","04b83084":"markdown","756fcab6":"markdown","8c153ca8":"markdown","6b9a111f":"markdown","44e86e1a":"markdown","5d13cefa":"markdown","9bbc5505":"markdown","a96a73b6":"markdown","6616d776":"markdown","73372c5d":"markdown","487dc6fd":"markdown","9b84abb1":"markdown","5654258e":"markdown","44d843be":"markdown"},"source":{"130e1f1d":"import pandas as pd\ntrain = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","5bfff9f9":"train.head(10)","1d25baeb":"import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=train.item_cnt_day)\nplt.title(\"aykiri deger tespit edildi -> item_cnt_day\")\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)\nplt.title(\"aykiri deger tespit edildi -> item_price\")\nplt.show()","0ad2ddc7":"train = train[train.item_price <= 100000]\ntrain = train[train.item_cnt_day <= 1000]\nbelow_zero = train[train[\"item_price\"] <= 0]\nbelow_zero.head()","7b75563f":"shop_32 = train[ (train.shop_id==32) & (train.item_id==2973)]\nshop_32.head(10)","b5c99940":"plt.plot(shop_32[\"item_price\"], 'o')\nplt.title(\"urunun fiyat degisimi\")\nplt.show()","94504c5b":"value = train[(train[\"shop_id\"] == 32) & (train[\"item_id\"] == 2973) & (train[\"date_block_num\"] == 4) & (train[\"item_price\"] > 0)][\"item_price\"].median()\ntrain.loc[train[\"item_price\"] < 0, 'item_price'] = value","11ba0e8f":"#\u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56 - dukkanin ismi\ntrain.loc[train[\"shop_id\"] == 0, 'shop_id'] = 57\ntest.loc[test[\"shop_id\"] == 0, 'shop_id'] = 57\n\n#\u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\" - dukkanin ismi\ntrain.loc[train[\"shop_id\"] == 1, 'shop_id'] = 58\ntest.loc[test[\"shop_id\"] == 1, 'shop_id'] = 58\n\n#\u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\u00b2 - dukkanin ismi\ntrain.loc[train[\"shop_id\"] == 10, 'shop_id'] = 11\ntest.loc[test[\"shop_id\"] == 10, 'shop_id'] = 11","8f78b193":"shops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nshops.head(10)","9bba2b4d":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops = shops[['shop_id','city']]\nshops.head(10)","bd778e03":"categorie = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ncategorie.head(10)","c938954c":"def extract_subtype(string):\n    if len(string) == 2:\n        return string[1].strip()\n    else:\n        return string[0]\n\ncategorie['type'] = categorie['item_category_name'].str.split('-').map(lambda x: x[0].strip())\ncategorie['sub_type'] = categorie['item_category_name'].str.split('-').map(lambda x: extract_subtype(x))\ncategorie = categorie[['item_category_id','type', 'sub_type']]\ncategorie.head(10)","1d51b572":"train['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain.head(10)","d59cb45e":"df = train.pivot_table(index=['item_id', 'shop_id'], values=['item_cnt_day'], columns='date_block_num', fill_value=0)\ndf.head(10)","d377b732":"df = pd.merge(test, df, on=['item_id', 'shop_id'], how='left')\ndf = df.fillna(0)\ndf.head()","931cd06a":"for i in range(34):\n    df[('item_cnt_day', i)].clip(0, 20)","0b426c0f":"df = pd.merge(df, shops, on=[\"shop_id\"], how='left')\ndf.head()","dcdc3d81":"items = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitems = items.drop(\"item_name\", axis=1)\nitems.head()","94caf5cc":"df = pd.merge(df, items, on=[\"item_id\"], how='left')\ndf.head()","8cd48209":"df = pd.merge(df, categorie, on=[\"item_category_id\"], how='left')\ndf.head()","8d89cb6f":"df = df.drop(['shop_id', 'item_id', 'ID', 'item_category_id'], axis=1)\ndf.head()","3ccbcec6":"df = pd.get_dummies(df, columns=[\"city\", \"type\", \"sub_type\"])\ndf.head(10)","b313dc41":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\n\nX_time_series = df.iloc[:, :34]\nX_city = df.iloc[:, 34:62]\nX_type = df.iloc[:, 63:]\n\nX_train_series = np.expand_dims(X_time_series.values[:, :-1], axis=2)\nX_train_city = np.expand_dims(X_city.values, axis=2)\nX_train_type = np.expand_dims(X_type.values, axis=2)\ny_train = X_train_series[:, -1:]\n\nX_test_series = np.expand_dims(X_time_series.values[:, 1:], axis=2)\nX_test_city = np.expand_dims(X_city.values, axis=2)\nX_test_type = np.expand_dims(X_type.values, axis=2)","fdad2945":"input_time_series = keras.layers.Input(shape=(33, 1))\ninput_city = keras.layers.Input(shape=(28, 1))\ninput_type = keras.layers.Input(shape=(64, 1))\n\n\n#WaveNet\nwave_1 = keras.layers.Conv1D(filters=16, kernel_size=2, padding=\"causal\", dilation_rate=1, kernel_initializer=\"glorot_normal\")(input_time_series)\nBN_1 = keras.layers.BatchNormalization()(wave_1)\nrelu_1 = keras.layers.Activation(\"relu\")(BN_1)\n\nwave_2 = keras.layers.Conv1D(filters=32, kernel_size=2, padding=\"causal\", dilation_rate=2, kernel_initializer=\"glorot_normal\")(relu_1)\nBN_2 = keras.layers.BatchNormalization()(wave_2)\nrelu_2 = keras.layers.Activation(\"relu\")(BN_2)\n\nwave_3 = keras.layers.Conv1D(filters=64, kernel_size=2, padding=\"causal\", dilation_rate=4, kernel_initializer=\"glorot_normal\")(relu_2)\nBN_3 = keras.layers.BatchNormalization()(wave_3)\nrelu_3 = keras.layers.Activation(\"relu\")(BN_3)\n\nwave_4 = keras.layers.Conv1D(filters=128, kernel_size=2, padding=\"causal\", dilation_rate=8, kernel_initializer=\"glorot_normal\")(relu_3)\nBN_4 = keras.layers.BatchNormalization()(wave_4)\nrelu_4 = keras.layers.Activation(\"relu\")(BN_4)\n\nbefore_concat = keras.layers.Conv1D(filters=256, kernel_size=1, kernel_initializer=\"glorot_normal\")(relu_4)\nbefore_concat_BN = keras.layers.BatchNormalization()(before_concat)\nbefore_concat_relu = keras.layers.Activation(\"relu\")(before_concat_BN)\n\n\n#Flatten\nflattened_time_series = keras.layers.Flatten()(before_concat_relu)\nflattened_city = keras.layers.Flatten()(input_city)\nflattened_product = keras.layers.Flatten()(input_type)\nconcat = keras.layers.concatenate([flattened_time_series, flattened_city])\n\n\n#First Hidden\nhidden_1 = keras.layers.Dense(512, kernel_initializer=\"glorot_normal\")(concat)\nhidden_BN_1 = keras.layers.BatchNormalization()(hidden_1)\nhidden_relu_1 = keras.layers.Activation(\"relu\")(hidden_BN_1)\n\nhidden_2 = keras.layers.Dense(512, kernel_initializer=\"glorot_normal\")(concat)\nhidden_BN_2 = keras.layers.BatchNormalization()(hidden_2)\nhidden_relu_2 = keras.layers.Activation(\"relu\")(hidden_BN_2)\n\n\nconcat_2 = keras.layers.concatenate([hidden_relu_2, flattened_product])\n\n\n#Second Hidden\nhidden_3 = keras.layers.Dense(256, kernel_initializer=\"glorot_normal\")(concat_2)\nhidden_BN_3 = keras.layers.BatchNormalization()(hidden_3)\nhidden_relu_3 = keras.layers.Activation(\"relu\")(hidden_BN_3)\n\nhidden_4 = keras.layers.Dense(256, kernel_initializer=\"glorot_normal\")(hidden_relu_3)\nhidden_BN_4 = keras.layers.BatchNormalization()(hidden_4)\nhidden_relu_4 = keras.layers.Activation(\"relu\")(hidden_BN_4)\n\n#Third Hidden\n\nhidden_5 = keras.layers.Dense(128, kernel_initializer=\"glorot_normal\")(hidden_relu_4)\nhidden_BN_5 = keras.layers.BatchNormalization()(hidden_5)\nhidden_relu_5 = keras.layers.Activation(\"relu\")(hidden_BN_5)\ndropout_1 = keras.layers.Dropout(rate=0.5)(hidden_relu_5)\n\nhidden_6 = keras.layers.Dense(64, kernel_initializer=\"glorot_normal\")(dropout_1)\nhidden_BN_6 = keras.layers.BatchNormalization()(hidden_6)\nhidden_relu_6 = keras.layers.Activation(\"relu\")(hidden_BN_6)\ndropout_2 = keras.layers.Dropout(rate=0.5)(hidden_relu_6)\n\nhidden_7 = keras.layers.Dense(32, kernel_initializer=\"glorot_normal\")(dropout_2)\nhidden_BN_7 = keras.layers.BatchNormalization()(hidden_7)\nhidden_relu_7 = keras.layers.Activation(\"relu\")(hidden_BN_7)\ndropout_3 = keras.layers.Dropout(rate=0.5)(hidden_relu_7)\n\n\n#End\noutput = keras.layers.Dense(1)(dropout_3)\n\nmodel = keras.models.Model(inputs=[input_time_series, input_city, input_type], outputs=[output])\nmodel.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(momentum=0.9), metrics=['mae'])\nmodel.summary()","b11be6ad":"callbacks = [\n    keras.callbacks.EarlyStopping(patience=5),\n    keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True),\n]\n\nhistory = model.fit([X_train_series, X_train_city, X_train_type], y_train, batch_size=256, epochs=100, callbacks=callbacks)","a67bd711":"import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\ndef plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n    \nplot_learning_curves(history)","885e2e29":"prediction = model.predict([X_test_series, X_test_city, X_test_type])\nprediction = prediction.clip(0, 20)\nfrom os import chdir\nchdir('..\/working')\n\nsubmission = pd.DataFrame({'ID': test['ID'], 'item_cnt_month': prediction.ravel()})\nsubmission.to_csv('submission.csv',index=False)\n","9524be01":"**Aykiri degerlerin kontrolu sorgulaniyor**","15792c75":"**Dataset'in okunma islemi gerceklestiriliyor**","04b83084":"**Tarihi kullanacagimiz sekile uygun hale getiriyoruz**","756fcab6":"**Dukkanlarin satis bilgileri**","8c153ca8":"**Urunlerdeki ilk kelime turu belirledigi icin ayiriyoruz**","6b9a111f":"**Derin ogrenme modelleri sehir, tur ve alt tur gibi kategorik degiskenleri yonetmediginden dolayi One Hot Encoding yapildi**","44e86e1a":"**Aykiri degerler kaldiriliyor**","5d13cefa":"**Bazi dukkanlardan birkac tane var ama farkli id'lere sahipler. Bu duzeltiliyor**","9bbc5505":"**Kategorileri egitime sokabilmek icin asagidaki adimlar izleniyor**","a96a73b6":"**Pasif durumda olan dukkanlar test setine dahil edildi**","6616d776":"**Urunler kategorize ediliyor**","73372c5d":"**Bazi dukkanlarin isimleri karisabiliyor bulunduklari sehirlerden dolayi, bu duzeltiliyor**","487dc6fd":"**Bir onceki ayin satislari(0-20) tahmin edilecegindan dolayi egitim verileri duzenlendi**","9b84abb1":"**Once WaveNet mimarisi ile satis gecmisine bakacak. Sonra sehir bilgilerini ve ele alinan oge turu ile alt turu eklenecek**","5654258e":"**Cok sayida egitilecek veri oldugundan dolayi ezberlemeye basladiginda durdurmak icin callback kullanildi**","44d843be":"**Egitim icin kullanilacak setin ilk 10 tanesi**"}}