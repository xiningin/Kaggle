{"cell_type":{"58420529":"code","84076444":"code","5a51beba":"code","53ffc953":"code","7ef3fa08":"code","56e6a915":"code","c2bd6203":"code","0bd1d6ab":"code","fb84186f":"code","a5615a41":"code","d356c6b4":"code","b22c28ef":"code","e9347b4b":"code","6a2f9839":"code","31b92800":"code","ab804cf0":"code","b6d426ce":"code","af0dcf04":"code","9f806c9e":"code","1a743bc4":"code","05293a33":"code","15329761":"code","a3719a18":"code","9abb1722":"code","7d60a8e4":"code","14eb3359":"code","6de68e7f":"code","9573c957":"code","59ede3b1":"markdown","8baf7d42":"markdown","ff274dbc":"markdown","9aa602af":"markdown","a81a0a78":"markdown","abb5ad57":"markdown","b4881017":"markdown","2030fc30":"markdown","9beff0ed":"markdown","384b5410":"markdown","cca01c10":"markdown","d01f5481":"markdown","6250b258":"markdown","580328e6":"markdown","a11e8cd2":"markdown","b8ce5d42":"markdown","7dc3a8a7":"markdown","627de60b":"markdown","4882ad75":"markdown","275d3b1d":"markdown","f777eaed":"markdown","7a21bd2d":"markdown","c7e6c102":"markdown","f79a694a":"markdown"},"source":{"58420529":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84076444":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import r2_score","5a51beba":"data=pd.read_csv(\"\/kaggle\/input\/zomato-bangalore-restaurants\/zomato.csv\")\ndata.head(3)","53ffc953":"print(len([data.menu_item[i]=='[]' for i in range(len(data))]),len(data))\n\n# since all rows are empty,we are going to remove the columns\ndata.drop(\"menu_item\",axis=1,inplace=True)\n\ndata.drop([\"url\",\"address\",\"phone\"],axis=1,inplace=True)","7ef3fa08":"data.isnull().sum()","56e6a915":"data.info()","c2bd6203":"# we are removing the null values' rows in any of the below columns\ndata.dropna(subset=[\"location\",\"cuisines\",\"rest_type\"],how=\"any\",inplace=True)","0bd1d6ab":"data.rate=data.rate.astype(str)  \n\ndata.rate=data.rate.loc[data.rate!=\"NEW\"]  # we have to select the integer string values only\n\ndata.rate=data.rate.loc[data.rate!=\"-\"]\n\ndata.rate=data.rate.str.replace(\"\/5\",\"\")  # removing \"\/5\" in integer string\n\ndata.rate=data.rate.apply(lambda x:float(x)) # converting to float\n\nmyimputer=SimpleImputer(strategy=\"mean\") # replacing null values with mean\n\ndata.rate=pd.DataFrame(myimputer.fit_transform(np.array(data.rate).reshape(-1,1)))","fb84186f":"# \"dish_liked\" column\n# Now we are going to use simple imputer to replace the missing values\n\nmyimputer=SimpleImputer(strategy=\"most_frequent\")\n\ndata.dish_liked=pd.DataFrame(myimputer.fit_transform(np.array(data.dish_liked).reshape(-1,1)))\n\ndata.head(2)","a5615a41":"# for approx_cost column\n\n# we have convert it to float type\n\n\ndata['approx_cost(for two people)']=data['approx_cost(for two people)'].str.replace(\",\",\"\") # removing , in integers\n\ndata['approx_cost(for two people)']=data['approx_cost(for two people)'].apply(lambda x:float(x)) # converting to float\n\nmyimputer=SimpleImputer(strategy=\"mean\")  # replacing the missing value with mean value\n\ndata['approx_cost(for two people)']=pd.DataFrame(myimputer.fit_transform(np.array(data['approx_cost(for two people)']).reshape(-1,1)))","d356c6b4":"data.dropna(how=\"any\",subset=list(data.columns),inplace=True)","b22c28ef":"data[data.duplicated()]\n# since we have single duplicated row,we neglect it or we can remove the row","e9347b4b":"data.drop_duplicates(keep=\"first\").head(2)  # we keep only the first occured row","6a2f9839":"data2=data.groupby(\"name\").name.agg([\"count\"]).reset_index()\n\n# renaming columns as count column which is obtained is function name.so we cant use it\n\ndata2.rename(columns={\"name\":\"name\",\"count\":\"repetition\"},inplace=True)\n\nprint(data2.head())\n\ndata2.name[data2.repetition.max()] # the restaurant having more number of branches","31b92800":"maximum=data.votes.max()\n\n# renaming columns as count column which is obtained is function name.so we cant use it\n\ndata.name[data.votes==maximum]\n\n# The Byg Brewski Brewing Company restaurant has highest votes with 3 different branches","ab804cf0":"maximum=data.rate.max()\n\nprint(maximum)\n\n# renaming columns as count column which is obtained is function name.so we cant use it\n\nlen(data.name[data.rate==maximum])\n\n# There 55 highest rated restaurants","b6d426ce":"plt.figure(1,(20,10))\nsns.countplot(data.book_table,data=data,hue=\"listed_in(type)\")\nplt.show()\n\n# most of restaurants dont allow booking table ","af0dcf04":"plt.figure(1,(20,10))\nsns.countplot(data.online_order,data=data,hue=\"listed_in(type)\")\nplt.show()","9f806c9e":"plt.figure(1,(30,20))\nax=sns.countplot(data[\"listed_in(city)\"],data=data)\nax.set_xticklabels(ax.get_xticklabels(),rotation=90,ha=\"right\")\nplt.show()","1a743bc4":"#Restaurant Type\nax=sns.countplot(data['rest_type'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\nfig = plt.gcf()   # it is used to get the current figure.if we dont get,figure() function creates the one\nfig.set_size_inches(15,15)   # sets the inches of rest_type\nplt.title('Restuarant Type')","05293a33":"plt.figure(1,(10,10))\ndata2=data.name.value_counts()[:15]\nax=sns.barplot(x=data2.index,y=data2,palette=\"bright\") # different types of palettes--bright,muted,dark,colorblind\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplt.ylabel(\"rate\")\nplt.show()","15329761":"plt.figure(1,(15,7))\nax=sns.countplot(data.rate,data=data,hue=\"listed_in(type)\")\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplt.show()","a3719a18":"#Encode the input Variables\ndef Encode(dat):\n    for column in dat.columns[~dat.columns.isin(['rate', 'cost', 'votes'])]:\n        dat[column] = dat[column].factorize()[0]   # it used for the numeric representation of an array to identify the distinct values\n    return dat","9abb1722":"finaldata = Encode(data.copy())\nfinaldata.head()","7d60a8e4":"corr=finaldata.corr(method=\"pearson\")\nplt.figure(1,(15,8))\nsns.heatmap(corr,annot=True)\nplt.show()","14eb3359":"\nx = finaldata.iloc[:,[2,3,8,9,11]]\ny = finaldata['approx_cost(for two people)']\n#Getting Test and Training Set\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.1,random_state=101)\n","6de68e7f":"from sklearn.tree import DecisionTreeRegressor\nmodel=DecisionTreeRegressor(min_samples_leaf=0.01,random_state=101) \n# when min_smaples_leaf is int,then it is number required to considered as leaf\n# if it is float, required number of leaf =len(data)*0.00007  her we get 3\nmodel.fit(x_train,y_train)\npred=model.predict(x_test)\nr2_score(pred,y_test)\n","9573c957":"from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor(n_estimators=500,random_state=101,min_samples_leaf=.0001)\nrf.fit(x_train,y_train)   # n_estimators--The number of trees in forest\ny_predict=rf.predict(x_test)\nfrom sklearn.metrics import r2_score\nr2_score(y_test,y_predict)","59ede3b1":"## <font color=\"orange\"> Notice--Missing Values","8baf7d42":"## <font color=\"orange\"> Removing the unnecessary columns\n    * We are removing the url,address and phone as they are not contributing to pprox_cost\n","ff274dbc":"### <font color=\"orange\">Notice from plot\n*    <font color=\"green\"> Most of the online orders have delivery\n*    <font color=\"green\"> Most of the Dine-Out doesnt deliver the food\n*    <font color=\"green\"> Desserts are not delivered in most restaurants\n    \n    ","9aa602af":"## <font color=\"red\">EDA\n    * lets find the famous restaurant from various features(ratings,votes)","a81a0a78":"### <font color=\"red\"> Creating Model","abb5ad57":"### <font color=\"orange\"> DecisionTree Regressor","b4881017":"### <font color=\"orange\"> Most voted Restaurant","2030fc30":"### <font color=\"orange\">Duplicated rows","9beff0ed":"### <font color=\"orange\">Dropping Duplicated rows","384b5410":"* #### <font color=\"green\"> since null values in location and cuisines are less in number \n*     <font color=\"green\">we cant give any most frequent value to location and cuisines to missing values as it changes its popularity\n*     <font color=\"green\"> we cannot remove all rows of missing values in dish_liked as it is larger in count.so we replace with most\n       frequent item\n*     <font color=\"green\">  for approx_cost,lets take mean value of this column to replace the missing values\n*     <font color=\"green\">   for rest_type,we remove those values as it is smaller count   \n*     <font color=\"green\">  for rate,we gonna replace with mean value   ","cca01c10":"### <font color=\"orange\"> Adjusting the rate column  (\/5) type","d01f5481":"### <font color=\"orange\"> Finding max branch restaurant","6250b258":"## <font color=\"orange\"> RndomforestRegressor","580328e6":"### <font color=\"orange\"> Most rated Restaurant","a11e8cd2":"## <font color=\"Red\"> Contents\n*    <font color=\"Green\"> Loading Dataset\n*    <font color=\"Green\"> Importing libraries\n*     <font color=\"Green\"> Removing the unnecessary columns\n*     <font color=\"Green\"> checking the number of null values in each column\n        *  <font color=\"Green\">  Notice--Missing Values\n        *   <font color=\"Green\">  Adjusting the rate column (\/5) type     \n        *   <font color=\"Green\"> Adjusting dish_liked column by most frequent by SimpleImputer\n        *   <font color=\"Green\">  Duplicated rows\n        *   <font color=\"Green\"> Dropping Duplicated rows\n* <font color=\"darkpink\"> Finding max branches' restaurant\n* <font color=\"darkpink\">  Most voted Restaurant\n* <font color=\"darkpink\">  Most rated Restaurant\n* <font color=\"Green\"> EDA\n* <font color=\"Green\"> Data Visulisation\n* <font color=\"Green\">  Creating Model\n* <font color=\"Green\"> DecisionTreeRegressor\n* <font color=\"Green\"> RandomForestRegressor","b8ce5d42":"### <font color=\"orange\"> Encoding the data","7dc3a8a7":"### <font color=\"orange\"> Adjusting approx_cost column","627de60b":"### <font color=\"darkpurple\">If this kernel helps you,please upvote it\ud83d\ude01\ud83d\ude01\ud83d\ude01","4882ad75":"### <font color=\"orange\">Notice from plot\n*    <font color=\"green\"> BTM has highest number of restaurants\n*    <font color=\"green\"> Koramangala 4th,5th,6th blocks are next to it\n*    <font color=\"green\"> Banashankari,New Bel Road has low number of restaurants","275d3b1d":"## <font color=\"orange\"> checking the number of null values in each column","f777eaed":"### <font color=\"Red\"> Data Visualisation","7a21bd2d":"### <font color=\"orange\"> Correlation","c7e6c102":"##### <font color=\"green\"> THe casual dining and cafe are in more number of restaurants","f79a694a":"### <font color=\"orange\"> Adjusting dish_liked column by most frequent"}}