{"cell_type":{"3ccc8369":"code","eb9384cf":"code","542f0b9e":"code","7f70e2ae":"code","499ab26a":"code","8e142231":"code","72306525":"code","b5c29935":"code","f7e632cc":"code","8e6fe561":"code","f619eb0a":"code","db873a1c":"code","c90697ac":"code","ad5a5806":"code","f60ad898":"code","149183b6":"code","7256a99c":"code","fcbd456e":"code","7740f162":"code","5e190f61":"code","ef879468":"code","42a81140":"code","e5ff0b58":"code","f5d98790":"code","5cb89f4c":"code","97cf48e0":"code","79f3e628":"code","de65588f":"code","c1f80e99":"code","e424a7c7":"code","ebc5155a":"markdown","96026a16":"markdown","042b9ddb":"markdown","6e7236f8":"markdown"},"source":{"3ccc8369":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","eb9384cf":"import matplotlib.pyplot as plt\nimport seaborn as sns","542f0b9e":"%matplotlib inline","7f70e2ae":"train = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')\ntest = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')","499ab26a":"train.shape, test.shape, ","8e142231":"train.head(2)","72306525":"test.head(2)","b5c29935":"train.info(null_counts=True)","f7e632cc":"(train['target'] > 0).mean(), (train['target'] >= 0.5).mean()","8e6fe561":"train['target'].hist(bins=100)","f619eb0a":"train[['severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']].hist(bins=100, figsize=(10, 10))","db873a1c":"train[['asian', 'black', 'jewish', 'latino', 'other_race_or_ethnicity', 'white']].hist(bins=100, figsize=(10, 10))","c90697ac":"demographics = train.loc[:, ['target']+list(train)[slice(8,32)]].dropna()\nweighted_toxic = demographics.iloc[:, 1:].multiply(demographics.iloc[:, 0], axis=\"index\").sum()\/demographics.iloc[:, 1:][demographics.iloc[:, 1:]>0].count()\nweighted_toxic = weighted_toxic.sort_values(ascending=False)\nplt.figure(figsize=(30,20))\nsns.set(font_scale=3)\nax = sns.barplot(x = weighted_toxic.values, y = weighted_toxic.index, alpha=0.8)\nplt.ylabel('Demographics')\nplt.xlabel('Weighted Toxic')","ad5a5806":"word_length = train['comment_text'].str.split().apply(len).value_counts().sort_index()","f60ad898":"fig, ax = plt.subplots(figsize=(10, 8))\nsns.distplot(word_length, bins=100, ax=ax)","149183b6":"import numpy as np\nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import LearningRateScheduler\n\n\nEMBEDDING_FILES = [\n    '..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec',\n    '..\/input\/glove840b300dtxt\/glove.840B.300d.txt'\n]\n\nNUM_MODELS = 2\nBATCH_SIZE = 512\nLSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nEPOCHS = 4\nMAX_LEN = 220\n","7256a99c":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n\n\ndef build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            pass\n    return embedding_matrix\n    \n\ndef build_model(embedding_matrix, num_aux_targets):\n    words = Input(shape=(MAX_LEN,))\n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n    x = SpatialDropout1D(0.3)(x)\n    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n\n    hidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    result = Dense(1, activation='sigmoid')(hidden)\n    aux_result = Dense(num_aux_targets, activation='sigmoid')(hidden)\n    \n    model = Model(inputs=words, outputs=[result, aux_result])\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    return model\n    \n\ndef preprocess(data):\n    '''\n    Credit goes to https:\/\/www.kaggle.com\/gpreda\/jigsaw-fast-compact-solution\n    '''\n    punct = \"\/-'?!.,#$%\\'()*+-\/:;<=>@[\\\\]^_`{|}~`\" + '\"\"\u201c\u201d\u2019' + '\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014\u2013&'\n    def clean_special_chars(text, punct):\n        for p in punct:\n            text = text.replace(p, ' ')\n        return text\n\n    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n    return data","fcbd456e":"x_train = preprocess(train['comment_text'])\ny_train = np.where(train['target'] >= 0.5, 1, 0)\ny_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\nx_test = preprocess(test['comment_text'])","7740f162":"tokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(x_train) + list(x_test))\n\nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\nx_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\nx_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)","5e190f61":"x_train.shape","ef879468":"len(tokenizer.word_index)","42a81140":"tokenizer.word_index","e5ff0b58":"embedding_matrix = np.concatenate(\n    [build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)","f5d98790":"embedding_matrix.shape","5cb89f4c":"checkpoint_predictions = []\nweights = []\n\nfor model_idx in range(NUM_MODELS):\n    model = build_model(embedding_matrix, y_aux_train.shape[-1])\n    for global_epoch in range(EPOCHS):\n        model.fit(\n            x_train,\n            [y_train, y_aux_train],\n            batch_size=BATCH_SIZE,\n            epochs=1,\n            verbose=2,\n            callbacks=[\n                LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** global_epoch))\n            ]\n        )\n        checkpoint_predictions.append(model.predict(x_test, batch_size=2048)[0].flatten())\n        weights.append(2 ** global_epoch)\n\npredictions = np.average(checkpoint_predictions, weights=weights, axis=0)\n\nsubmission = pd.DataFrame.from_dict({\n    'id': test['id'],\n    'prediction': predictions\n})","97cf48e0":"submission.to_csv('submission.csv', index=False)","79f3e628":"model.predict(x_train, batch_size=2048)[0].flatten()","de65588f":"MODEL_NAME = 'my_model'\ntrain[MODEL_NAME] = model.predict(pad_text(validate_df[TEXT_COLUMN], tokenizer))[:, 1]","c1f80e99":"# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n","e424a7c7":"SUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\nbias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, 'target')\nbias_metrics_df\na","ebc5155a":"## EDA","96026a16":"**Competition Objective**  \nIdentifing toxicity in online conversations with minimal unintended model bias.\n\n* **Toxicity**: severe_toxicity, obscene, threat, insult, identity_attack, sexual_explicit\n* A subset of comments have been labelled with a variety of **identity attributes**\n\nIdentity attributes:\n* **race or ethnicity**: asian, black, jewish, latino, other_race_or_ethnicity, white\n* **gender**: female, male, transgender, other_gender\n* **sexual orientation**: bisexual, heterosexual, homosexual_gay_or_lesbian, other_sexual_orientation\n* **religion**: atheist, buddhist, christian, hindu, muslim, other_religion\n* **disability**: intellectual_or_learning_disability, other_disability, physical_disability, psychiatric_or_mental_illness\n\n**Evaluation metrics**  \nOverall AUC  \nBias AUCs\n* Subgroup AUC: examples that mention the specific identity subgroup\n* BPSN (Background Positive, Subgroup Negative) AUC: non-toxic examples that mention the identity and the toxic examples that do not\n* BNSP (Background Negative, Subgroup Positive) AUC: toxic examples that mention the identity and the non-toxic examples that do not","042b9ddb":"## Metrics","6e7236f8":"## Train"}}