{"cell_type":{"c7a4b125":"code","86db0d2c":"code","ef1766b3":"code","1ff46503":"code","71e5fde7":"code","1402efa7":"code","461acd35":"code","a52d89db":"code","d74ed150":"code","48e72ac1":"code","562bc24c":"code","474c37d5":"code","40b0b57e":"code","50fb9e4d":"code","4820ae7b":"markdown","edd5a681":"markdown"},"source":{"c7a4b125":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86db0d2c":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport tensorflow as tf","ef1766b3":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain.head()","1ff46503":"print(train.shape)\nprint(test.shape)","71e5fde7":"train_y = train['label']\ntrain_x = train.drop(['label'],axis=1)\ntest_x = test\ntrain_y = train_y.astype('float32')\ntrain_x = train_x.astype('int32')\ntest_x = test_x.astype('float32')","1402efa7":"graph = sns.countplot(train_y)","461acd35":"train_x = train_x.values.reshape(-1,28,28,1)\ntest_x = test_x.values.reshape(-1,28,28,1)\ntrain_x = train_x\/255\ntest_x = test_x\/255\ntrain_x.shape, test_x.shape","a52d89db":"#one hot encoding\ntrain_y = tf.keras.utils.to_categorical(train_y,10)\ntrain_y.shape","d74ed150":"print(train['label'].head())","48e72ac1":"print(train_y[0:5,:])","562bc24c":"#defining the model\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nimport keras\nfrom keras.utils.np_utils import to_categorical\n\n\nmodel=models.Sequential([\n    Conv2D(32, (5,5) , activation='relu' , input_shape=(28,28,1)),\n    MaxPooling2D(pool_size=(2,2)),\n    \n    Conv2D(64,(5,5), activation ='relu'),\n    MaxPooling2D(pool_size=(2,2)),\n    Dropout(0.25),\n    \n    Conv2D(64,(3,3), activation ='relu'),\n    MaxPooling2D(pool_size=(2,2)),\n    Dropout(0.25),\n    \n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(10, activation='softmax')\n])\nmodel.summary()","474c37d5":"\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(train_x, train_y, epochs=5, batch_size=64)","40b0b57e":"results = model.predict(test_x)\n\nresults = np.argmax(results,axis=1)\n\nresults = pd.Series(results,name=\"Label\")","50fb9e4d":"submission = pd.concat([pd.Series(range(1,28001),name='ImageId'),results],axis=1)\n\nsubmission.to_csv(\"submission2.csv\", index=False)","4820ae7b":"Importing packages","edd5a681":"Reading dataset"}}