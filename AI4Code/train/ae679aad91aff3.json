{"cell_type":{"0254ed57":"code","b010f123":"code","e9b9dad4":"code","4e3fbc8b":"code","83e5b965":"code","10b91415":"code","87bdf791":"code","f30b7454":"code","7aeeabb0":"code","993a1e0c":"code","556aad4a":"code","e1410dbb":"code","9e42f7b6":"code","f95ae638":"code","e5bdfa51":"code","3bf90abf":"code","00461125":"code","c9c0d9df":"code","cf25d5d4":"code","dca19cbf":"code","305380ee":"code","cd125e76":"code","b009baf9":"code","d1b1f2b2":"code","a1451f38":"code","17a3c2d3":"code","6ec91fcb":"code","0f5351e6":"code","a041075d":"code","d989a114":"code","6d16126f":"code","8e9b3186":"code","bbfa6c8c":"markdown","bafae2fb":"markdown","ae502b9d":"markdown","74065c51":"markdown","21180761":"markdown","99e5b46b":"markdown","50c42436":"markdown","0d27f6e9":"markdown"},"source":{"0254ed57":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, SpatialDropout1D, LSTM","b010f123":"# download data from here\n# https:\/\/www.kaggle.com\/saurabhshahane\/twitter-sentiment-dataset\n\ndf = pd.read_csv(\"..\/input\/twitter-sentiment-dataset\/Twitter_Data.csv\")\ndf.head()","e9b9dad4":"df.category.unique()\n\n# -1 is negative\n# 0 is neutral\n# +1 is positive","4e3fbc8b":"df.isna().sum()","83e5b965":"df[df['category'].isna()]","10b91415":"df[df['clean_text'].isna()]","87bdf791":"# delete these...","f30b7454":"df.drop(df[df['clean_text'].isna()].index, inplace=True)\ndf.drop(df[df['category'].isna()].index, inplace=True)","7aeeabb0":"df.info()","993a1e0c":"# word cloud is the only visualiztion i know for nlp so, lets do it","556aad4a":"# positive tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == 1.0]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","e1410dbb":"# negative tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == -1.0 ]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","9e42f7b6":"# positive tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == 0.0 ]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","f95ae638":"vec = CountVectorizer(max_features=10000)\nvec.fit(df['clean_text'])\n\ntrn, val = train_test_split(df, test_size=0.3, random_state=42)\n\ntrn_abs = vec.transform(trn['clean_text'])\nval_abs = vec.transform(val['clean_text'])","e5bdfa51":"from sklearn.multiclass import OneVsRestClassifier\nclf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\nclf.fit(trn_abs, trn['category'])\n\nval_preds = clf.predict(val_abs)\nf1_score(val['category'], val_preds, average='micro')","3bf90abf":"print(clf.score(val_abs, val['category']))","00461125":"accuracy_score(val['category'], val_preds)","c9c0d9df":"confusion_matrix(val['category'], val_preds)","cf25d5d4":"print(classification_report(val['category'], val_preds))","dca19cbf":"vec = TfidfVectorizer(max_features=10000)\n_ = vec.fit(list(df['clean_text']))\n\ntrn_abs = vec.transform(trn['clean_text'])\nval_abs = vec.transform(val['clean_text'])","305380ee":"clf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\n_ = clf.fit(trn_abs, trn['category'])\n\nval_preds = clf.predict(val_abs)\nf1_score(val['category'], val_preds, average='micro')\n\n# i've seen tfidf perform bad in another case as well...","cd125e76":"print(clf.score(val_abs, val['category']))","b009baf9":"# i need to learn more about the below code but i thought i'd try it..","d1b1f2b2":"# tokenize\ntok = Tokenizer(num_words = 1000000)\n# fit\ntok.fit_on_texts(df['clean_text'].str.lower().tolist())\n\nvocab_size = len(tok.word_index) + 1","a1451f38":"\nX_trn = tok.texts_to_sequences(trn['clean_text'])\nX_val = tok.texts_to_sequences(val['clean_text'])","17a3c2d3":"maxlen = 200\nX_trn = pad_sequences(X_trn, maxlen=maxlen)\nX_val = pad_sequences(X_val, maxlen=maxlen)","6ec91fcb":"embedding_dim = 50\nvocab_size = len(tok.word_index) + 1\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size,\n                    output_dim=embedding_dim,\n                    input_length=maxlen))\n\nmodel.add(Flatten())\nmodel.add(Dense(200, activation='relu', name = 'Fully_Connected'))\nmodel.add(Dense(1, activation='sigmoid', name = 'Output'))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n              loss='binary_crossentropy',\n              metrics=['accuracy'],\n              )\n\nmodel.summary()","0f5351e6":"model.fit(X_trn, trn['category'], validation_data=(X_val, val['category']), verbose=True, epochs=20, batch_size=256,\n          callbacks = [tf.keras.callbacks.ReduceLROnPlateau()])","a041075d":"val_preds = model.predict(X_val)\n\nf1_score(val['category'], val_preds, average='micro')","d989a114":"accuracy_score(val['category'], val_preds)","6d16126f":"confusion_matrix(val['category'], val_preds)","8e9b3186":"print(classification_report(val['category'], val_preds))","bbfa6c8c":"### download data from here\n https:\/\/www.kaggle.com\/saurabhshahane\/twitter-sentiment-dataset\n","bafae2fb":"### Using count vectorizer and one vs rest approach","ae502b9d":"## Imports","74065c51":"### Word embeddings","21180761":"## **Tfidf Vectorizer**","99e5b46b":"# Thank you\n## Don't forget to like or upvote if it was worth your time","50c42436":"## sentiment analysis of twitter text","0d27f6e9":"### Performance metrics"}}