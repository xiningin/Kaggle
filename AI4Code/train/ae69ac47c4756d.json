{"cell_type":{"f25d6b71":"code","b4792d09":"code","af8e1df9":"code","9c1457db":"code","69803927":"code","eb86b0e8":"code","ffa78223":"code","e4ba17c4":"code","3dafbbc9":"code","11bf4ba1":"code","78d4435e":"code","2a00b294":"code","13e04fd8":"code","da13af05":"code","456958e6":"code","4c02aefd":"code","53504740":"code","b30e6996":"code","5c767eaf":"code","5d8e0347":"code","6e3ed234":"code","11b44bf3":"code","a0611ea4":"code","1da4f803":"code","97894f50":"code","429d7ead":"code","2c2a895d":"code","438ff03f":"code","9e48dffa":"code","51d26127":"code","f31732a3":"code","cf490d96":"code","005af63c":"code","727d87b0":"code","f34cd5d3":"code","b3c9b76d":"code","a4206f4c":"code","e43effde":"code","b9dc2016":"code","fe4c1e0f":"code","f2aa8de4":"code","e210e0e6":"markdown","5f22c80d":"markdown","d8428270":"markdown","0fbaf40a":"markdown","ed8891c3":"markdown","6a82ae38":"markdown"},"source":{"f25d6b71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b4792d09":"dataset = pd.read_csv(\"\/kaggle\/input\/vehicle-dataset-from-cardekho\/car data.csv\")\ndataset.head()","af8e1df9":"dataset.shape","9c1457db":"print(dataset['Fuel_Type'].unique())\nprint(dataset['Seller_Type'].unique())\nprint(dataset['Transmission'].unique())\nprint(dataset['Owner'].unique())","69803927":"#check missing null values\ndataset.isnull().sum()","eb86b0e8":"dataset.describe()","ffa78223":"dataset.columns","e4ba17c4":"final_dataset=dataset[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]","3dafbbc9":"final_dataset.head()","11bf4ba1":"final_dataset['Current_Year']=2020","78d4435e":"final_dataset.head()","2a00b294":"final_dataset['no_of_year']=final_dataset['Current_Year']-final_dataset['Year']","13e04fd8":"final_dataset.head()","da13af05":"final_dataset.drop(['Year'],axis=1,inplace=True)","456958e6":"final_dataset.head()","4c02aefd":"final_dataset = pd.get_dummies(final_dataset,drop_first=True)","53504740":"final_dataset.head()","b30e6996":"final_dataset.corr()","5c767eaf":"import seaborn as sns\nimport matplotlib.pyplot as plt","5d8e0347":"sns.pairplot(final_dataset)","6e3ed234":"%matplotlib inline\ncorrmat = final_dataset.corr()\ntop_corr_features=corrmat.index\nplt.figure(figsize=(15,15))\n# plot heat map\ng=sns.heatmap(final_dataset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","11b44bf3":"final_dataset.head()","a0611ea4":"# X is independent features and Y is dependent features\nX=final_dataset.drop('Selling_Price',axis=1)\nY = final_dataset['Selling_Price']","1da4f803":"## feature importance\nfrom sklearn.ensemble import ExtraTreesRegressor\nmodel = ExtraTreesRegressor()\nmodel.fit(X,Y)","97894f50":"print(model.feature_importances_)","429d7ead":"# plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_,index=X.columns)\nfeat_importances.nlargest(5).plot(kind='barh')\nplt.show()","2c2a895d":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)","438ff03f":"X_train.shape","9e48dffa":"from sklearn.ensemble import RandomForestRegressor\nrf_random = RandomForestRegressor()","51d26127":"#Hyperparameter tuning in Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","f31732a3":"from sklearn.model_selection import RandomizedSearchCV","cf490d96":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","005af63c":"# use the random grid to search for best heperparameters\nrf = RandomForestRegressor()","727d87b0":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","f34cd5d3":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","b3c9b76d":"rf_random.fit(X_train,Y_train)","a4206f4c":"predictions = rf_random.predict(X_test)","e43effde":"predictions","b9dc2016":"sns.distplot(Y_test-predictions)","fe4c1e0f":"plt.scatter(Y_test,predictions)","f2aa8de4":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncv = ShuffleSplit(n_splits=5, test_size=0.2,random_state=0)\ncross_val_score(RandomForestRegressor(),X,Y,cv=cv)","e210e0e6":"# Analysing the Dataset","5f22c80d":"# checking which feature is important by the help of ExtraTreeRegressor algo","d8428270":"Hyperparameter tuning by the help of Randomized searchcv","0fbaf40a":"# Checking NaN value present in out dataset or not","ed8891c3":"# Now, Its time to build our model by the help of Random Forest Algorithm","6a82ae38":"# <<<<<<<<<<<<<<<<-------If you like this approach!!!!! Pleaseeee Upvote------->>>>>>>>>>>>>>>>>>>"}}