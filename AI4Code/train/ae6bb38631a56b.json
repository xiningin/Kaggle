{"cell_type":{"27dcfd03":"code","cdd80a60":"code","4753981b":"code","847e8b3b":"code","43e40e1f":"code","6b362925":"code","8b59bef8":"code","8bbae5e3":"code","2309ee11":"code","c1277700":"code","662d0e29":"code","70441c0f":"code","a96866bd":"code","7ddb38b3":"code","e4b70b7c":"code","b02aebcc":"code","88b5b4f3":"code","3836e2e3":"code","a57c3afd":"code","60511ab7":"code","c8f7029f":"code","33d1cff3":"code","8bc52b49":"code","6a80d50b":"code","722718d9":"code","2f51e284":"code","a6af7617":"code","2daaa4a2":"code","d215ae7b":"code","9e4f5364":"markdown","d41a8b3e":"markdown","37381036":"markdown","14434df0":"markdown","b9d4a6b7":"markdown"},"source":{"27dcfd03":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models,Sequential\nimport cv2, numpy as np\nimport os\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","cdd80a60":"import sys\nsys.path.append('..\/input\/swintransformertf')\nfrom swintransformer import SwinTransformer","4753981b":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU\/GPU\/multi-GPU\/cluster-GPU detection code\n\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","847e8b3b":"# Tabular data file paths\nTRAIN_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/train.csv'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\n# Image data directories\nTRAIN_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/train'\nTEST_DIRECTORY = '..\/input\/petfinder-pawpularity-score\/test'\nIMG_MODEL = '..\/input\/keras-applications-models\/EfficientNetB0.h5'","43e40e1f":"# Parameters for processing tabular data\nTARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.25\nSEED = 5","6b362925":"# TensorFlow settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 8\nDROPOUT_RATE = 0.2\nLEARNING_RATE = 1e-4\nDECAY_STEPS = 100\nDECAY_RATE = 0.96\nEPOCHS = 20\nPATIENCE = 5","8b59bef8":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['categorical_crossentropy']\n    val_rmse = hist.history['val_categorical_crossentropy']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","8bbae5e3":"set_seed(SEED)\nset_display()","2309ee11":"# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","c1277700":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","662d0e29":"# Reconstruct the paths to train and test images.\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\n# Keep a portion of the labeled data for validation.\ntrain_subset, valid_subset = train_test_split(\n    data_train[['path', TARGET_NAME]],\n    test_size=VAL_SIZE, shuffle=True, random_state=SEED\n)","70441c0f":"# Create TensorFlow datasets\n\ntrain_ds = get_dataset(x=train_subset['path'], y=tf.one_hot(train_subset[TARGET_NAME]\/\/10,depth=10,dtype=tf.float32))\nvalid_ds = get_dataset(x=valid_subset['path'], y=tf.one_hot(valid_subset[TARGET_NAME]\/\/10,depth=10,dtype=tf.float32))\ntest_ds = get_dataset(x=data_test['path'])\n\nprint(train_ds)","a96866bd":"with strategy.scope():\n    img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[*[224,224], 3])\n    pretrained_model = SwinTransformer('swin_large_224', num_classes=10,include_top=False, pretrained=True, use_tpu=True)\n    \n    model = tf.keras.Sequential([\n        img_adjust_layer,\n        pretrained_model,\n        tf.keras.layers.Dense(10,activation='softmax')\n    ])","7ddb38b3":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-8),\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy']\n)\nmodel.summary()","e4b70b7c":"# To gradually decrease learning rate\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)","b02aebcc":"# Compile the model\n","88b5b4f3":"model.summary()","3836e2e3":"\n#model = tf.keras.models.Sequential(\n   # [\n #       tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n   #    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n    #    model,\n    #    tf.keras.layers.BatchNormalization(),\n     #   tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n    #    tf.keras.layers.Dense(512, activation='relu'),\n    #    tf.keras.layers.Dense(10, activation='softmax')\n    #]\n#)\n#model.summary()","a57c3afd":"# To monitor validation loss and stop the training.\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n\nfrom tensorflow.keras import backend as K\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_true*100 - y_pred*100)))\n\n#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n #                   loss=rmse,\n #                   metrics=[rmse])","60511ab7":"#history=model.fit(train_ds, validation_data=valid_ds,epochs=EPOCHS,verbose=2)\nhistory=model.fit(train_ds, validation_data=valid_ds,epochs=EPOCHS,verbose=2)","c8f7029f":"plot_history(history)","33d1cff3":"train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","8bc52b49":"label = 'Pawpularity'\n\nfeatures = ['Subject Focus','Eyes','Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur']","6a80d50b":"x = train[features]\ny = train[label]\ny = y \/100\nx_test = test[features]\n\nx, x_val, y, y_val = train_test_split(\n    x, y, test_size=0.0033, random_state=42)\nprint(x,y)","722718d9":"from xgboost import XGBRegressor","2f51e284":"my_model = XGBRegressor(n_estimators=1500, learning_rate=0.003, n_jobs=12)\nmy_model.fit(x,y, \n             early_stopping_rounds=5, \n             eval_set=[(x_val,y_val)], \n             verbose=2)\nfrom sklearn.metrics import mean_absolute_error\n\npredictions = my_model.predict(x_val)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions*100, y_val*100)))","a6af7617":"pred2 = my_model.predict(x_test)*100\npred2","2daaa4a2":"# Predict popularity score for the test\npred1 = model.predict(test_ds,use_multiprocessing=True, workers=os.cpu_count())*100\n\nTARGET_NAME = pred2*0.61+pred1*0.39\n\n\n\n\n","d215ae7b":"data_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\ndata_test[['Id', TARGET_NAME]].head()","9e4f5364":"## Functions","d41a8b3e":"model=tf.keras.models.load_model('..\/input\/keras-applications-models\/EfficientNetB0.h5')\nmodel.trainable = False\n\nmodel= tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\"),\n        model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n        tf.keras.layers.Dense(32, activation='elu'),\n        tf.keras.layers.Dense(1)\n    ]\n)\nmodel.summary()","37381036":"## Data Processing","14434df0":"good leif\n","b9d4a6b7":"## Inference"}}