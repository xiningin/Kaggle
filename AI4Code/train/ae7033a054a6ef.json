{"cell_type":{"1c0390a7":"code","47f2f1e0":"code","d6baeb74":"code","d6d57172":"code","47b119df":"code","b6a2d379":"code","befd6da1":"code","b82322d9":"code","86dc7577":"code","1167fce1":"code","ba8dc632":"code","c84e1cfd":"code","70e75a58":"code","fed9c0e8":"code","6f6c0c45":"code","91cf71c0":"code","df63ac1d":"code","e6909c7c":"code","2a168127":"code","d7241afa":"code","54d319e7":"code","9a8491e3":"code","45871c9c":"code","106cf96e":"code","cde3b4a2":"code","aef94fe2":"code","1f97f424":"code","5442c8b3":"code","16eff311":"code","5e78fd0c":"code","2e09ffcf":"code","d1465902":"markdown","c6641bb6":"markdown","59553576":"markdown","9b866ac0":"markdown","c1e1b709":"markdown","7184a1ef":"markdown","b76be477":"markdown","e5f78ea4":"markdown"},"source":{"1c0390a7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tensorflow import keras  # tensorflow is our library, keras on top of it makes it simpler\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom keras.activations import relu","47f2f1e0":"train_data = pd.read_csv('..\/input\/train.csv')","d6baeb74":"train_data.shape","d6d57172":"train_data.head()   # looking to our DataFrame","47b119df":"train_data.info()    # we see that they are all integers","b6a2d379":"train_data.describe()   # we see that it needs to be scaled (now it's between 0 and 255 )","befd6da1":"train_y = train_data[\"label\"] \n\ntrain_data.drop([\"label\"],axis=1,inplace=True)\n\ntrain_x = train_data","b82322d9":"train_x = train_x.values.reshape(-1,28,28,1)\ntrain_y = train_y.values","86dc7577":"from keras.utils.np_utils import to_categorical\ntrain_y = to_categorical(train_y)","1167fce1":"train_y.shape","ba8dc632":"len(train_y[5])","c84e1cfd":"train_x.shape","70e75a58":"train_x = train_x \/ 255.0","fed9c0e8":"train_x.shape","6f6c0c45":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Dropout,Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom tensorflow.nn import leaky_relu ","91cf71c0":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (5,5),padding = 'same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(32,kernel_size=(5,5),padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),padding=\"same\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),padding=\"same\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(32,activation=leaky_relu))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(20,activation=leaky_relu))\n\nmodel.add(Dense(10, activation = \"softmax\"))","df63ac1d":"model.summary()","e6909c7c":"model.compile(Adam(lr=0.0003),loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])","2a168127":"datagen = ImageDataGenerator(\n       # rotation_range=0.5, \n       # zoom_range = 0.5, \n       # width_shift_range=0.5,  \n       # height_shift_range=0.5\n)\n\ndatagen.fit(train_x)","d7241afa":"model.fit_generator(datagen.flow(train_x,train_y, batch_size=80),steps_per_epoch=525,epochs=30)","54d319e7":"test_x = pd.read_csv('..\/input\/test.csv')\n\ntest_x.head(10)","9a8491e3":"test_x = test_x.values.reshape(-1,28,28,1)","45871c9c":"test_x = test_x \/ 255.0","106cf96e":"predictions = model.predict(test_x)","cde3b4a2":"predictions[354]","aef94fe2":"pred = np.argmax(predictions, axis=1)","1f97f424":"import matplotlib.pyplot as plt\nplt.imshow(test_x[358][:,:,0],cmap='gray')\nplt.show()","5442c8b3":"pred[358]","16eff311":"my_submission = pd.DataFrame({'ImageId': range(1,len(test_x)+1) ,'Label':pred })\n\nmy_submission.to_csv(\"cnn_results3.csv\",index=False)","5e78fd0c":"my_submission.head(10)","2e09ffcf":"#efe erg\u00fcn","d1465902":"### Scaling","c6641bb6":"## Keras Model Starts Here","59553576":"importing the required libraries","9b866ac0":"# My first exploration","c1e1b709":"### EDA","7184a1ef":"getting the Dataset","b76be477":"Labels and Features are splitted","e5f78ea4":"Transformed to numpy arrays"}}