{"cell_type":{"92c7a2a6":"code","a2af66ba":"code","96259737":"code","36a58889":"code","2e2fbc7b":"code","1a6411ad":"code","b71095c2":"code","44004758":"code","5121959b":"code","a03de1a2":"code","9f92d2dd":"code","03476250":"code","64e73238":"code","ec45dceb":"code","1df36b37":"code","72b92484":"code","5972f0e8":"code","f36b76a5":"code","fe768e28":"code","180fa8c7":"code","207a2096":"code","07e0ef22":"code","b96c4cd5":"code","124cf33e":"code","43cd1110":"code","dc51f062":"code","f0724e69":"code","a451ffa2":"code","751459f3":"code","e60e0482":"code","2d44cb06":"markdown","06fcb019":"markdown","51493b2e":"markdown","13314ff4":"markdown","75ae1bb4":"markdown","b2ad4c96":"markdown","4bff3e50":"markdown","bf5096f3":"markdown","037d9b7d":"markdown","3d7ab010":"markdown","935921ad":"markdown","0b1d6786":"markdown","f6f8cf7a":"markdown","ddf0fc6d":"markdown","8b86bd44":"markdown","b7bdfed7":"markdown","772459c6":"markdown","5625a095":"markdown","1d9dc4d6":"markdown","85567345":"markdown","f08bb917":"markdown","bab823f5":"markdown","3feaed97":"markdown","c39db2f8":"markdown"},"source":{"92c7a2a6":"from warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import Imputer\nimport seaborn as sns","a2af66ba":"from warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n","96259737":"train_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.set_index('PassengerId',inplace=True)\ntest_data=pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_data.head()","36a58889":"#checking if there is missing value in training and testing dataset\nprint('Missing values in training dataset:\\n')\nprint(train_data.isnull().sum())\nprint('\\nMissing values in testing dataset:\\n') \nprint(test_data.isnull().sum())      ","2e2fbc7b":"# for training data\nimp=Imputer(missing_values='NaN',strategy='median',axis=1)\nAge_train=imp.fit_transform(train_data.Age.values.reshape(1,-1))\nAge_train=Age_train.astype('int64').T\ntrain_data['Age']=Age_train\ntrain_data['Embarked'].fillna('S',inplace=True)\ntrain_data.drop('Cabin',axis=1,inplace=True)\ntrain_data.isnull().sum()\n","1a6411ad":"# for testing data\nAge_test=imp.fit_transform(test_data.Age.values.reshape(1,-1))\nAge_test=Age_test.astype('int64').T\ntest_data['Age']=Age_test\ntest_data['Fare'].fillna(np.mean(test_data['Fare']),inplace=True)\ntest_data.drop('Cabin',axis=1,inplace=True)\ntest_data.isnull().sum()","b71095c2":"# converting sex column to categorical data\nfor sex in train_data.Sex:\n    if sex=='female':\n         train_data.replace(sex,0,inplace=True)\n    else:\n         train_data.replace(sex,1,inplace=True)\nfor sex in test_data.Sex:\n    if sex=='female':\n         test_data.replace(sex,0,inplace=True)\n    else:\n         test_data.replace(sex,1,inplace=True)    ","44004758":"plt.figure(figsize=(10,7))\nax1=sns.countplot(x='Sex',hue='Survived',data=train_data,linewidth=2,edgecolor=(0,0,0),color='g')\nplt.title(\"Survived\/Not Survived distribution according to gender\",fontsize=20)\nlabels=['female','male']\nplt.xticks(sorted(train_data.Survived.unique()),labels,fontsize=18)\nplt.yticks(fontsize=16)\nplt.xlabel('Sex',fontsize=20)\nplt.ylabel('No. of passengers',fontsize=20)\nleg=ax1.get_legend()\nleg.set_title('Survived')\nleg.texts[0].set_text('No')\nleg.texts[1].set_text('Yes')","5121959b":"plt.figure(figsize=(10,7))\nax2=sns.countplot(x='Pclass',hue='Survived',data=train_data,edgecolor=(0,0,0),linewidth=2,color='r')\nplt.title('Survived\/Not Survived according to Class',fontsize=20)\nplt.xlabel('Passenger\\'s Class',fontsize=20)\nplt.xticks(fontsize=15)\nplt.ylabel('No.of Passengers',fontsize=20)\nplt.yticks(fontsize=15)\nleg=ax2.get_legend()\nleg.texts[0].set_text('No')\nleg.texts[1].set_text('Yes')\n","a03de1a2":"train_data.drop(['Name','Ticket'],axis=1,inplace=True)\ntest_data.drop(['Name','Ticket'],axis=1,inplace=True)\ntrain_data.head()","9f92d2dd":"# creating age group feature\ndef age_group(age):\n    a=''\n    if (age<=1):\n        a='infant'\n    elif (1<age<=10):\n        a='child'\n    elif (10<age<=17):\n        a='teenager'\n    elif (17<age<=30):\n        a='young_adult'\n    elif (30<age<=40):\n        a='adult'    \n    else:\n        a='old'\n    return a\ntrain_data['Age_group']=train_data.Age.map(age_group)\ntest_data['Age_group']=test_data.Age.map(age_group)","03476250":"# creating family group feature\ntrain_data['family_size']=train_data['SibSp']+train_data['Parch']+1\ntest_data['family_size']=test_data['SibSp']+test_data['Parch']+1\ndef family_group(family_size):\n    a=''\n    if family_size<=1:\n        a='alone'\n    elif family_size<4:\n        a='small'\n    else:\n        a='large'\n    return a\ntrain_data['family_group']=train_data.family_size.map(family_group)\ntest_data['family_group']=test_data.family_size.map(family_group)\n","64e73238":"# creating fare_per_person column\ntrain_data['fare_per_person']=train_data['Fare']\/train_data['family_size']\ntest_data['fare_per_person']=test_data['Fare']\/test_data['family_size']\n# creating fare_group feature\ndef fare_group(fare):\n    a=''\n    if fare<10:\n        a='very_low'\n    elif fare<20:\n        a='low'\n    elif fare<30:\n        a='medium'\n    elif fare<40:\n        a='high'\n    else:\n        a='very high'\n    return a    \ntrain_data['fare_group']=train_data.fare_per_person.map(fare_group)      \ntest_data['fare_group']=test_data.fare_per_person.map(fare_group)        ","ec45dceb":"train_data.head()","1df36b37":"test_data.head()","72b92484":"# creating dummy variables for Embarked,age_group, family_group \ntrain_data=pd.get_dummies(train_data,columns=['Embarked','Age_group','family_group','fare_group'],drop_first=True)\ntrain_data.head()\ntest_data=pd.get_dummies(test_data,columns=['Embarked','Age_group','family_group','fare_group'],drop_first=True)","5972f0e8":"# drop unnecessary columns\ntrain_data.drop(['Age','SibSp','Parch','Fare','family_size','fare_per_person'],axis=1,inplace=True)\ntest_data.drop(['Age','SibSp','Parch','Fare','family_size','fare_per_person'],axis=1,inplace=True)","f36b76a5":"test_data.head()","fe768e28":"train_data.head()","180fa8c7":"X_train=train_data.drop('Survived',1)\ny_train=train_data['Survived']\nX_test=test_data.drop('PassengerId',1)\nX_train.shape","207a2096":"clf=KNeighborsClassifier(n_neighbors=3)\nscoring='accuracy'\nscore_1=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_1=round(np.mean(score_1)*100,2)\nscore_1","07e0ef22":"clf=GaussianNB()\nscoring='accuracy'\nscore_2=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_2=round(np.mean(score_2)*100,2)\nscore_2","b96c4cd5":"clf=LogisticRegression()\nscoring='accuracy'\nscore_3=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_3=round(np.mean(score_3)*100,2)\nscore_3","124cf33e":"clf=DecisionTreeClassifier(max_depth=5)\nscoring='accuracy'\nscore_4=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_4=round(np.mean(score_4)*100,2)\nscore_4","43cd1110":"clf=RandomForestClassifier(n_estimators=20)\nscoring='accuracy'\nscore_5=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_5=round(np.mean(score_5)*100,2)\nscore_5","dc51f062":"clf=SVC(probability=True)\nscoring='accuracy'\nscore_6=cross_val_score(clf,X_train,y_train,n_jobs=1,cv=5,scoring=scoring)\nscore_6=round(np.mean(score_6)*100,2)\nscore_6","f0724e69":"plt.figure(figsize=(15,10))\ny=[score_1,score_2,score_3,score_4,score_5,score_6]\nx=['KNeighborsClassifier',\n   'GaussianNB',\n   'LogisticRegression',\n   'DecisionTreeClassifier',\n   'RandomForestClassifier',\n   'SVC']\nplt.title('Comparing accuracy of different models',fontsize=20)\nsplot=sns.barplot(x,y,edgecolor=(0,0,0),linewidth=2)\nplt.xticks(fontsize=15,rotation=45)\nplt.yticks(fontsize=15)\nplt.xlabel('Models',fontsize=20)\nplt.ylabel('Accuracy',fontsize=20)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n\n","a451ffa2":"clf=RandomForestClassifier(n_estimators=20)\n# training our model\nclf.fit(X_train,y_train)\n#predicting for test dataset\nprediction=clf.predict(X_test)","751459f3":"# creating our submission dataframe\nsubmission=pd.DataFrame({'PassengerId':sorted(test_data['PassengerId']),'Survived':prediction})\nsubmission","e60e0482":"# writing to csv file\nsubmission.to_csv('submission.csv',index=False)","2d44cb06":"## SVC","06fcb019":"## KNeighborsClassifier","51493b2e":"## Our challenge ","13314ff4":"# Plotting Survived distributions","75ae1bb4":"#### The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.","b2ad4c96":"# Feature Engineering","4bff3e50":"# Titanic\n","bf5096f3":"### Creating Features and Labels","037d9b7d":"# Loading our dataset","3d7ab010":"# Comparing cross_val_score","935921ad":"## DecisionTreeClassifier","0b1d6786":"KNeighborsClassifier\n\nGaussianNB\n\nLogisticRegression\n\nDecisionTreeClassifier\n\nRandomForestClassifier\n\nSVC\n\n","f6f8cf7a":"## GaussianNB","ddf0fc6d":"# Creating Model","8b86bd44":"## LogisticRegression","b7bdfed7":"### From above graph we can see that survial is directly depend on the Class.\n\n1st class passenger survived percentage is ~63%\n\n2nd class passenger survived percentage is ~47%\n\n3rd class passenger survived percentage is only ~24%\n","772459c6":"We have to analyse what sorts of people were likely to survive. In particular, we have to apply the tools of machine learning to predict which passengers survived the tragedy.","5625a095":"## Treating missing values","1d9dc4d6":"# Calculating cross_val_score","85567345":"# Cleaning the dataset","f08bb917":"# Importing Libraries","bab823f5":"## Creating dummy variables","3feaed97":"### We are calculating cross_val_score for following classifiying models","c39db2f8":"## RandomForestClassifier"}}