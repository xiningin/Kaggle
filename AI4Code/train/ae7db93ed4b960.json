{"cell_type":{"e752e7d8":"code","01a1b20c":"code","c42f728a":"code","c8cd7666":"code","4f424cac":"code","bd0b7040":"code","985f9e8f":"code","f6ef5ba2":"code","967db1bf":"code","799b9265":"code","e844007d":"code","ee808b35":"code","b6a5ff99":"code","7fa9dee0":"code","0403951e":"code","daeec69e":"code","0da8afff":"code","1141d08d":"code","eab79f05":"code","7a42d59b":"code","2b9257b1":"code","56159b18":"code","1d9eab53":"code","c57e8fc0":"code","00d4be1b":"code","37d4b2cd":"code","0a6e0dd8":"code","c18f9257":"markdown","e2013ea5":"markdown","cde5643e":"markdown","47090d3b":"markdown","4f7bbdc1":"markdown","c501a76b":"markdown","0c80e729":"markdown","87f0288a":"markdown","a8e26c10":"markdown","fe232d0d":"markdown"},"source":{"e752e7d8":"import gensim\nimport pandas as pd\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom  sklearn.decomposition import PCA","01a1b20c":"# reading w2v embedding\nfile=\"\/kaggle\/input\/googlenewsvectorsnegative300\/GoogleNews-vectors-negative300.bin\"\n# labeled dataset\ndataset_url=\"https:\/\/bit.ly\/2CdYYuf\"\n\nembeddings = gensim.models.KeyedVectors.load_word2vec_format(file, binary=True)\ndf = pd.read_csv(dataset_url, sep='\\t', header=None)\nstopwords = nltk.corpus.stopwords.words('english')","c42f728a":"df.head()","c8cd7666":"df.info()","4f424cac":"df.columns=['reviews', 'class'] # 1: review 2: sentiment","bd0b7040":"def get_w2v_dataset(data):\n    df_vectors = pd.DataFrame() \n    for doc in data:\n        doc_list = nltk.word_tokenize(doc)\n        temp=pd.DataFrame()\n        for d in doc_list:\n            if d not in stopwords:\n                try:\n                    vec = embeddings[d]\n                    temp = temp.append(pd.Series(vec), ignore_index=True)\n                except:\n                    pass\n    #     print(temp.mean(axis=0)) # for each feature find mean for the sentence.\n        vector_doc = temp.mean(axis=0)\n        df_vectors = df_vectors.append(vector_doc, ignore_index=True)\n    return df_vectors\n\ndef get_tfidf_dataset(data):    \n    tf_vect = TfidfVectorizer()    \n    return tf_vect.fit_transform(data)\n\n","985f9e8f":"X=get_w2v_dataset(df['reviews'])\ny=df['class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.2)","f6ef5ba2":"X.head()","967db1bf":"# X_train.var()[X_train.var()>0.005]\n# X_train.var()[X_train.var()<-0.005]","799b9265":"X_vect = get_tfidf_dataset(df['reviews'])\n# y=df['class']\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_vect, y, random_state=2, test_size=0.2)","e844007d":"X_vect","ee808b35":"clf_wv = LogisticRegression(C=1, n_jobs=-1, class_weight='balanced')\nclf_wv.fit(X_train, y_train)\ny_pred = clf_wv.predict(X_test)\n\n# Updating predicted data datatype\ny_pred = pd.Series(y_pred)","b6a5ff99":"# C:Inverse of regularization strength, must be +\nclf_tf = LogisticRegression(max_iter=100, C=0.1, n_jobs=-1, class_weight='balanced')\nclf_tf.fit(X_train_2, y_train_2)\ny_pred_2 = clf_tf.predict(X_test_2)\n\n# Updating predicted data datatype\ny_pred_2 = pd.Series(y_pred_2)","7fa9dee0":"type(y_pred), type(y_test), type(y_test_2), type(y_pred_2)","0403951e":"print(classification_report(y_train, clf_wv.predict(X_train)))","daeec69e":"print(classification_report(y_test, y_pred))","0da8afff":"print(confusion_matrix(y_test, y_pred))","1141d08d":"print(accuracy_score(y_test, y_pred))","eab79f05":"print(classification_report(y_train_2, clf_tf.predict(X_train_2)))","7a42d59b":"print(classification_report(y_test_2, y_pred_2))","2b9257b1":"print(confusion_matrix(y_test_2, y_pred_2))","56159b18":"print(accuracy_score(y_test_2, y_pred_2))","1d9eab53":"pca = PCA(n_components=3, random_state=2)\npca.fit(X_train)\nX_train_1_pca = pca.transform(X_train)\nX_test_1_pca = pca.transform(X_test)","c57e8fc0":"X_train_1_pca[0]","00d4be1b":"clf_wv = LogisticRegression(C=100,  penalty='elasticnet', class_weight='balanced', solver='saga', l1_ratio=0.5)\nclf_wv.fit(X_train_1_pca, y_train)\ny_pred_pca = clf_wv.predict(X_test_1_pca)\n\n# Updating predicted data datatype\ny_pred_pca = pd.Series(y_pred_pca)","37d4b2cd":"print(classification_report(y_train, clf_wv.predict(X_train_1_pca)))","0a6e0dd8":"print(classification_report(y_test, y_pred_pca))","c18f9257":"reference https:\/\/www.kaggle.com\/ananyabioinfo\/text-classification-using-word2vec","e2013ea5":"## Results model 1 with word2vec","cde5643e":"### Training_model #2","47090d3b":"### Training set #2","4f7bbdc1":"### Training_model #1","c501a76b":"Using PCA to limit the dimensions","0c80e729":"### performance on training data","87f0288a":"### Training set #1","a8e26c10":"## Results model #2 with tfidf","fe232d0d":"### performance on training data"}}