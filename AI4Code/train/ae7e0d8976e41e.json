{"cell_type":{"db79f7a1":"code","62655ad8":"code","951da033":"code","e4648856":"code","ad64adb3":"code","abf4e9b1":"code","7b0b2e26":"code","2192a71f":"code","7c9d877d":"code","e5e9c663":"code","00157fb1":"code","52ee423f":"code","439c6b91":"code","ee2e1c03":"code","edbb427f":"code","f2b9a34c":"code","00394fc1":"code","885dc210":"code","fa6adfd7":"code","bf05a388":"code","db1b8a07":"code","b68cda21":"code","b449933b":"code","77e751cb":"code","a973e7da":"code","e2bbf577":"code","a4b32758":"code","fa11d4ff":"code","6fd6b39e":"code","c184182c":"code","73c9d3f5":"code","9e4af68c":"code","008cab35":"code","aa33e04f":"code","384ca3c6":"code","690c05ad":"code","4914d8bb":"code","967e12b2":"code","0b109a5f":"code","eeb5b45e":"code","5e0b261c":"code","d561017a":"code","be8d1525":"code","3f0ead2a":"code","de734422":"code","b0a07956":"code","6fdd4d27":"code","857b25a3":"code","951ab269":"code","441c3556":"code","d63149ee":"code","299d3574":"code","128486eb":"code","1dfdb55f":"code","d95406aa":"code","e208e6ff":"code","c49133ab":"code","35a89af0":"code","4223d6df":"code","e34308bd":"code","08a48266":"code","29f36f1e":"code","23c8b306":"code","5d4a99a6":"code","42c48a42":"code","ae5410fc":"code","2ab33f23":"code","91ebe3be":"code","7d36f7ce":"code","ac04cadd":"code","708543c9":"code","51cde81b":"code","5a471144":"code","51cc5e02":"code","eabf70f7":"code","7da2a735":"code","8e6805bb":"code","03c5bb30":"code","67ad138f":"markdown","5525140b":"markdown","00adf503":"markdown","6ce66174":"markdown","6591910d":"markdown","7cfa0c9a":"markdown","e3da9b8f":"markdown","e6413410":"markdown","bbdd0b94":"markdown","4b192774":"markdown","ccbce2e7":"markdown","e0c62ef9":"markdown","f3e8240e":"markdown","6514eec1":"markdown","38709a2b":"markdown"},"source":{"db79f7a1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import tools\nimport plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","62655ad8":"df = pd.read_csv(\"..\/input\/german-credit-data-with-risk\/german_credit_data.csv\", index_col=0)\ndf.head()","951da033":"df.info()","e4648856":"df.isnull().sum()","ad64adb3":"for col in list(df):\n    print(col)","abf4e9b1":"for col in list(df):\n    print(col)\n    print(df[col].unique())\n    ","7b0b2e26":"missing_values=pd.DataFrame({'Missing Values':df.isnull().sum(),'Missing % Values':(df.isnull().sum()\/1000)*100})\nmissing_values","2192a71f":"numerical = ['Credit amount','Age','Duration']\ncategorical = ['Sex','Job','Housing','Saving accounts','Checking account','Purpose']\ndf.shape","7c9d877d":"for cat in categorical:\n    df[cat] = df[cat].fillna(df[cat].mode().values[0])\ndf.isnull().sum()\n\n# Since we had a small data set its better to fill the data with its mean rather than removing the rows or columns which can result in biased results and predictions.","e5e9c663":"missing_values=pd.DataFrame({'Missing Values':df.isnull().sum(),'Missing % Values':(df.isnull().sum()\/1000)*100})\nmissing_values","00157fb1":"df.describe()","52ee423f":"df = df.rename(columns={\"Credit amount\": \"Credit_amount\",\"Saving accounts\":\"Saving_accounts\",\"Checking account\":\"Checking_account\"})","439c6b91":"df","ee2e1c03":"df.info()","edbb427f":"male_credit = df[\"Credit_amount\"].loc[df[\"Sex\"] == \"male\"].values\nfemale_credit = df[\"Credit_amount\"].loc[df[\"Sex\"] == \"female\"].values\ntotal_credit = df['Credit_amount'].values\n\nfig, ax = plt.subplots(1, 3, figsize=(15,5))\n\nsns.distplot(male_credit, ax=ax[0], color=\"blue\")\nax[0].set_title(\"Male Credit Distribution\", fontsize=15)\nsns.distplot(female_credit, ax=ax[1], color=\"red\")\nax[1].set_title(\"Female Credit Distribution\", fontsize=15)\nsns.distplot(total_credit, ax=ax[2], color=\"green\")\nax[2].set_title(\"Total Credit Distribution\", fontsize=15)\nplt.show()","f2b9a34c":"plt.figure(figsize=(14,5))\ngx=sns.boxplot(x='Sex', y='Age', data=df, palette=\"RdBu\")\ngx.set_title(\"Age vs Sex\")\ngx.set_ylabel(\"Age\")\ngx.set_xlabel(\"Sex\")\nplt.show()\n#This plot shows how many people are male and female within the specified age.","00394fc1":"plt.figure(figsize=(15,5))\nsns.histplot(data=df, x=\"Purpose\", kde=True, color=\"y\")\n# This plot shows the purpose of loan that people took.","885dc210":"plt.figure(figsize=(15,5))\nsns.histplot(data=df, x=\"Housing\", color=\"b\")\n# This plot shows how many people own the house and how many are on rent or free. ","fa6adfd7":"male_age = df[\"Age\"].loc[df[\"Sex\"] == \"male\"].values\nfemale_age = df[\"Age\"].loc[df[\"Sex\"] == \"female\"].values\nAll_age = df['Age'].values\nfig, ax = plt.subplots(1, 3, figsize=(15,5))\nsns.histplot(male_age,ax=ax[0],color=\"blue\")\nax[0].set_title(\"Male Age\", fontsize=15)\nsns.histplot(female_age, ax=ax[1], color=\"red\")\nax[1].set_title(\"Female Age\", fontsize=15)\nsns.histplot(All_age, ax=ax[2], color=\"green\")\nax[2].set_title(\"All Age \", fontsize=15)\nplt.show()\n# This plot shows what kind of people(men or female) have taken loan the most with respect to their age.","bf05a388":"df[\"Purpose\"].unique()\nsex_purpose = pd.crosstab(df['Purpose'], df['Sex'])\ndisplay(sex_purpose)\n#This Frame Shows the purpose of having credits for each gender","db1b8a07":"number_of_jobs = pd.crosstab(df[\"Job\"], df[\"Sex\"])\nnumber_of_jobs\n#This Frame Shows the No of Jobs for each gender","b68cda21":"#dividing Age groups into different categories\ndf['Age_Group'] = np.nan\n\nlst = [df]\n\nfor col in lst:\n    col.loc[(col['Age'] > 18) & (col['Age'] <= 29), 'Age_Group'] = 'Young'\n    col.loc[(col['Age'] > 29) & (col['Age'] <= 40), 'Age_Group'] = 'Young Adults'\n    col.loc[(col['Age'] > 40) & (col['Age'] <= 55), 'Age_Group'] = 'Senior'\n    col.loc[col['Age'] > 55, 'Age_Group'] = 'Elder' \n    \ndf","b449933b":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True)\nplt.show()","77e751cb":"df[\"Risk\"].unique()","a973e7da":"df.replace(['good','bad'],[1,0],inplace=True)","e2bbf577":"pd.to_numeric(df[\"Risk\"],errors='coerce')","a4b32758":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True)\nplt.show()","fa11d4ff":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics","6fd6b39e":"df_clean=df.copy()","c184182c":"cat_features = ['Sex','Housing', 'Saving_accounts', 'Checking_account','Purpose']\nnum_features=['Age', 'Job', 'Credit_amount', 'Duration','Risk']\nfor variable in cat_features:\n    dummies = pd.get_dummies(df_clean[cat_features])\n    df1= pd.concat([df_clean[num_features], dummies],axis=1)\nRisk= df1['Risk']          \ndf2=df1.drop(['Risk'],axis=1)","73c9d3f5":"X_train,X_test,Y_train,Y_test = train_test_split(df2,Risk,test_size=0.20,random_state = 30)","9e4af68c":"from yellowbrick.classifier import ConfusionMatrix, ClassificationReport, ROCAUC\nfrom yellowbrick.features import FeatureImportances\n\n\n\ndef visualize(model):\n\n    \n    fig, axes = plt.subplots(1, 3,figsize=(15,5))\n    fig.subplots_adjust(wspace=0.7)\n    \n    visualgrid = [\n        #FeatureImportances(model,ax=axes[0][0]),\n        ROCAUC(model, ax=axes[1],cmap='coolwarm'),\n        ConfusionMatrix(model,cmap='PuOr', ax=axes[2]),\n        ClassificationReport(model, cmap='PuRd',ax=axes[0])\n        \n    ]\n\n    for viz in visualgrid:\n        viz.fit(X_train, Y_train)\n        viz.score(X_test, Y_test)\n        viz.finalize()\n\n    plt.show()","008cab35":"#Logistic Regression\nmodel = LogisticRegression()\nmodel.fit(X_train,Y_train)\npredictions=model.predict(X_test)\nprobabilities = model.predict_proba(X_test)","aa33e04f":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions))\nmodel_roc_auc = roc_auc_score(Y_test,predictions) \nprint (\"Area under curve : \",model_roc_auc)","384ca3c6":"lr = LogisticRegression()\nlr.fit(X_train, Y_train)\nY_test_pred = lr.predict(X_test)\n\nconfusion_matrix = confusion_matrix(Y_test, Y_test_pred)\nconfusion_matrix","690c05ad":"from sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(predictions,Y_test)\nsns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True)\nplt.ylabel('Actual label'),\nplt.xlabel(\"Predicted\")\nplt.title(\"CONFUSION MATRIX\",color = \"grey\")\n","4914d8bb":"model_roc_auc = roc_auc_score(Y_test,predictions) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","967e12b2":"visualize(model)","0b109a5f":"#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=15)\n#Train the model using the training sets \nknn.fit(X_train, Y_train)\n\n#Predict the response for test dataset\npredictions  = knn.predict(X_test)\nprobabilities = model.predict_proba(X_test)\nfpr,tpr,thresholds = roc_curve(Y_test,probabilities[:,1])","eeb5b45e":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions))\nmodel_roc_auc = roc_auc_score(Y_test,predictions) \nprint (\"Area under curve : \",model_roc_auc)","5e0b261c":"conf_matrix = confusion_matrix(predictions,Y_test)\nconf_matrix","d561017a":"conf_matrix = confusion_matrix(predictions,Y_test)\nsns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n            xticklabels=[\"not churn\",\"churn\"],\n            yticklabels=[\"not churn\",\"churn\"],linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\nplt.title(\"CONFUSION MATRIX\",color = \"Brown\")","be8d1525":"model_roc_auc = roc_auc_score(Y_test,predictions) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","3f0ead2a":"visualize(knn)","de734422":"#Decision Trees\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","b0a07956":"clf=DecisionTreeClassifier(criterion=\"entropy\", max_depth=6)\nclf.fit(X_train,Y_train)","6fdd4d27":"plt.figure(figsize=(30,17))\nplot_tree(clf,fontsize=9,filled=True)\nplt.show()","857b25a3":"prediction_test=clf.predict(X_test) ","951ab269":"prediction_test","441c3556":"confusion_matrix(prediction_test,Y_test)","d63149ee":"print (\"\\n Classification report : \\n\",classification_report(Y_test,prediction_test))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,prediction_test))\nmodel_roc_auc = roc_auc_score(Y_test,prediction_test) \nprint (\"Area under curve : \",model_roc_auc)","299d3574":"conf_matrix = confusion_matrix(prediction_test,Y_test)\nsns.heatmap(pd.DataFrame(conf_matrix), annot=True, cmap=\"Greens\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","128486eb":"model_roc_auc = roc_auc_score(Y_test,prediction_test) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","1dfdb55f":"visualize(clf)","d95406aa":"#GaussianNB\nfrom sklearn.naive_bayes import GaussianNB","e208e6ff":"#Model Training\nmodel_nb = GaussianNB()\nmodel_nb.fit(X_train, Y_train);\n\n# Model Prediction\npredictions_NB = model_nb.predict(X_test)\nprobabilities = model_nb.predict_proba(X_test)\nfpr,tpr,thresholds = roc_curve(Y_test,probabilities[:,1])","c49133ab":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions_NB))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions_NB))\nmodel_roc_auc = roc_auc_score(Y_test,predictions_NB) \nprint (\"Area under curve : \",model_roc_auc)","35a89af0":"conf_matrix = confusion_matrix(predictions_NB,Y_test)\nsns.heatmap(pd.DataFrame(conf_matrix), annot=True, cmap=\"Greens\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","4223d6df":"model_roc_auc = roc_auc_score(Y_test,predictions_NB) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","e34308bd":"visualize(model_nb)","08a48266":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier","29f36f1e":"\n#Model Training\nmodel_rfc = RandomForestClassifier()\nmodel_rfc.fit(X_train, Y_train);\n\n#Prediction\npredictions_rfc = model_rfc.predict(X_test)\nprobabilities = model_rfc.predict_proba(X_test)\nfpr,tpr,thresholds = roc_curve(Y_test,probabilities[:,1])","23c8b306":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions_rfc))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions_rfc))\nmodel_roc_auc = roc_auc_score(Y_test,predictions_rfc) \nprint (\"Area under curve : \",model_roc_auc)","5d4a99a6":"conf_matrix = confusion_matrix(predictions_rfc,Y_test)\nsns.heatmap(pd.DataFrame(conf_matrix), annot=True, cmap=\"Greens\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","42c48a42":"model_roc_auc = roc_auc_score(Y_test,predictions_rfc) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","ae5410fc":"visualize(model_rfc)","2ab33f23":"#XG BOOST\nimport xgboost as xgb","91ebe3be":"#Model Training\nmodel_xgb  = xgb.XGBClassifier()\nmodel_xgb.fit(X_train, Y_train);\n\n#Prediction\npredictions_xgb = model_xgb.predict(X_test)\nprobabilities = model_xgb.predict_proba(X_test)\nfpr,tpr,thresholds = roc_curve(Y_test,probabilities[:,1])","7d36f7ce":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions_xgb))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions_xgb))\nmodel_roc_auc = roc_auc_score(Y_test,predictions_xgb) \nprint (\"Area under curve : \",model_roc_auc)","ac04cadd":"conf_matrix = confusion_matrix(predictions_xgb,Y_test)\nsns.heatmap(pd.DataFrame(conf_matrix), annot=True, cmap=\"Blues\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","708543c9":"model_roc_auc = roc_auc_score(Y_test,predictions_xgb) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","51cde81b":"visualize(model_xgb)","5a471144":"#Ada Boost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier","51cc5e02":"#Model Training\nmodel_adaboost = AdaBoostClassifier()\nmodel_adaboost.fit(X_train, Y_train);\n\n#Prediction\npredictions_ada = model_adaboost.predict(X_test)\nprobabilities = model_adaboost.predict_proba(X_test)\nfpr,tpr,thresholds = roc_curve(Y_test,probabilities[:,1])","eabf70f7":"print (\"\\n Classification report : \\n\",classification_report(Y_test,predictions_ada))\nprint (\"Accuracy Score   : \",accuracy_score(Y_test,predictions_ada))\nmodel_roc_auc = roc_auc_score(Y_test,predictions_ada) \nprint (\"Area under curve : \",model_roc_auc)","7da2a735":"conf_matrix = confusion_matrix(predictions_ada,Y_test)\nsns.heatmap(pd.DataFrame(conf_matrix), annot=True, cmap=\"coolwarm\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","8e6805bb":"model_roc_auc = roc_auc_score(Y_test,predictions_ada) \ny_pred_proba = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nprint (\"Area under curve : \",model_roc_auc)\nplt.show()","03c5bb30":"visualize(model_adaboost)","67ad138f":"# XG BOOST","5525140b":"# Applying Some of the Machine Learning Algorithm's in order to find; Assess accuracy, F1 Score and Precision recall","00adf503":"# Random Forest","6ce66174":"# The Above plots shows the distribution of Credit_Amount for each Gender and overall","6591910d":"# Exploratory Data Analysis - EDA","7cfa0c9a":"# Decision Tree Algorithm","e3da9b8f":"# Finding correlated variables and variables affecting the target variable the most.","e6413410":"#### Credit amount and Duration attributes have a strong postive relationship. Greater the credit amount, greater will be the duration.\n#### Credit amount and Duration have a negative correlatiopn with the target variable(Risk), which means poeple who have larger credit loans have higher risk\n#### larger duration of loan tend towards Bad Risk.\n#### Feature Purpose have no relation with the target variable (Risk).","bbdd0b94":"# Gaussian NB ","4b192774":"## Input Split","ccbce2e7":"* The Above Analysis Shows all the Classification Report, ROC Curves and Confusion Matrix of all the Algorithms used which include;\n1. Logistic Regression\n2. KNN\n3. Decision Trees\n4. Gaussain NB\n5. Random Forest\n6. XG - Boost\n7. Ada - Boost\n\n* We have got different accuracy scores in the all of the above models, which shows a successful modelling tests.\nNote : This is my first kaggle notebook, if you have any suggestions and recommendations for me to improve, please do comment.\nLooking Forward to Improve.","e0c62ef9":"# KNN -  K-Nearest Neighbors Algorithm","f3e8240e":"# Conclusion","6514eec1":"# Ada - Boost","38709a2b":"# Logistic Regression"}}