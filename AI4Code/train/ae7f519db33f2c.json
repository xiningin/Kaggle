{"cell_type":{"7fc087d2":"code","6d1ae211":"code","3b5f2e0a":"code","5fa86b27":"code","35b5a02a":"code","19842ea6":"code","20f93a02":"markdown","077ce903":"markdown","0c8d3560":"markdown","b9cb2518":"markdown","447ae8c4":"markdown","2573927f":"markdown"},"source":{"7fc087d2":"import numpy as np\nimport tensorflow as tf","6d1ae211":"# creating the input data to our neural network\n# Are four elemtents of x1 and x2 columns\ndata_input_x = np.array([[0.0, 0.0], \n                         [0.0, 1.0],\n                         [1.0, 0.0],\n                         [1.0, 1.0]])\ndata_input_x","3b5f2e0a":"# creating the classification that we know to out input data ('classe' column)\ndata_y = np.array([[0.0], [0.0], [0.0], [1.0]])\ndata_y","5fa86b27":"def step_function(sum_value):\n    return tf.cast(tf.to_float(tf.math.greater_equal(sum_value, 1)), tf.float64)","35b5a02a":"# Define the variables used during de processing\n# Two weights to only one neuron\n# Weights are initialized with zero\nweights = tf.Variable(tf.zeros([2,1], dtype = tf.float64))\n\n# define our outputlayer calculation\noutput_layer = tf.matmul(data_input_x, weights)\n\n# define our activation function to transform the output layer values into knowed classes (0 or 1)\npredictions = step_function(output_layer)\n\n# define score function to evaluate the accuracy\nerror = tf.subtract(data_y, predictions)\n\n# define delta function used to adjust the weights during the training\ndelta = tf.matmul(data_input_x, error, transpose_a = True)\nlearningRate = 0.1\ntrain = tf.assign(weights, tf.add(weights, tf.multiply(delta, learningRate)))\n\n# Create the initializer function TensorFlow Variables used during the processing\ninit = tf.global_variables_initializer()","19842ea6":"with tf.Session() as s:\n    s.run(init)\n    print('Output layer result: \\n', s.run(output_layer))\n    print('Prediction result: \\n', s.run(predictions))\n    print('Error result: \\n', s.run(error))\n    print('\\n')\n    for epoch in range(15):\n        train_error, _ = s.run([error, train])\n        train_error_sum = tf.reduce_sum(train_error)\n        print('Epoch: ', epoch+1, ' - Error: ', s.run(train_error_sum))\n        if train_error_sum.eval() == 0.0:\n            break; # learned and got 100% accuracy\n    print('\\nWeights to the best accuracy: \\n', s.run(weights))","20f93a02":"## Creating the data","077ce903":"## Import libraries","0c8d3560":"# Neural Network with TensorFlow from zero\n\n## Introduction\n\n***This is a simple kernel to show on TensorFlow an implementation from zero of a single-layer perceptron using Step Function to Activation.***\n\n## Scenario\n\nWe will implement a scenario represented by the image:\n    \n![Single-Layer-Perceptron-with-TensorFlow](https:\/\/i.imgur.com\/dvwQFZx.png)\nSource: https:\/\/www.udemy.com\/tensorflow-machine-learning-deep-learning-python","b9cb2518":"## TensorFlow implementation\n\n### Definitions\n","447ae8c4":"## Step Activation Function\n\nWe will use a very simple activation function called Step. It returns 0 or 1.\n\nUsually, we do not use it into a real life scenario of binary classification.\n\n![Step Function Representation](https:\/\/i.imgur.com\/dMcJsL9.png)\nSource: https:\/\/medium.com\/the-theory-of-everything\/understanding-activation-functions-in-neural-networks-9491262884e0","2573927f":"### Execution"}}