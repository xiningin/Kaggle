{"cell_type":{"31446fd4":"code","6ebf390a":"code","c5542734":"code","840b69a9":"code","cca8ad83":"code","7cccd27d":"code","c9c41c77":"code","59a23657":"code","2a640c59":"code","bb1b242f":"code","b0c0c109":"code","41fdc301":"code","416c5d0a":"code","8244809f":"code","33f3025b":"markdown","45d5afe6":"markdown","c43c3d8b":"markdown","3c1c40be":"markdown","aefec27b":"markdown","03b353dc":"markdown","017a9aa6":"markdown","f9ade047":"markdown","35fe641e":"markdown","05b2fe59":"markdown","e7e4c690":"markdown","ee69ca87":"markdown"},"source":{"31446fd4":"from tensorflow.keras.applications import EfficientNetB0\nimport tensorflow as tf","6ebf390a":"model = EfficientNetB0(include_top=False, weights='imagenet')","c5542734":"IMG_SIZE = 224","840b69a9":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU\/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()","cca8ad83":"import tensorflow_datasets as tfds\n\nbatch_size = 64\n\ndataset_name = \"stanford_dogs\"\n(ds_train, ds_test), ds_info = tfds.load(\n    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n)\nNUM_CLASSES = ds_info.features[\"label\"].num_classes","7cccd27d":"NUM_CLASSES","c9c41c77":"size = (IMG_SIZE, IMG_SIZE)\nds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\nds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))","59a23657":"from tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\n\nimg_augmentation = Sequential(\n    [\n        preprocessing.RandomRotation(factor=0.15),\n        preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        preprocessing.RandomFlip(),\n        preprocessing.RandomContrast(factor=0.1)\n    ],\n    \n    name = 'img_augmentation'\n)","2a640c59":"def input_preprocess(image, label):\n    label = tf.one_hot(label, NUM_CLASSES)\n    return image, label\n\n\nds_train = ds_train.map(\n    input_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\nds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n\nds_test = ds_test.map(input_preprocess)\nds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)","bb1b242f":"from tensorflow.keras.applications import EfficientNetB0\n\nwith strategy.scope():\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = img_augmentation(inputs)\n    outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(\n        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n\nmodel.summary()\n\nepochs = 3  # @param {type: \"slider\", min:10, max:100}\nhist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","b0c0c109":"import matplotlib.pyplot as plt\n\n\ndef plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()\n\n\nplot_hist(hist)","41fdc301":"from tensorflow.keras.layers.experimental import preprocessing\n\n\ndef build_model(num_classes):\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = img_augmentation(inputs)\n    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n\n    # Freeze the pretrained weights\n    model.trainable = False\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n\n    # Compile\n    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n    model.compile(\n        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n    return model","416c5d0a":"with strategy.scope():\n    model = build_model(num_classes=NUM_CLASSES)\n\nepochs = 3  # @param {type: \"slider\", min:8, max:80}\nhist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\nplot_hist(hist)","8244809f":"def unfreeze_model(model):\n    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-20:]:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n\n\nunfreeze_model(model)\n\nepochs = 3  # @param {type: \"slider\", min:8, max:50}\nhist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\nplot_hist(hist)","33f3025b":"Second case : Using weight='imagenet', Freeze pretrained weight.","45d5afe6":"number of classes is 120","c43c3d8b":"Check model accuracy","3c1c40be":"Third case : Train pretraind weight, without batchnormalization layers.","aefec27b":"## 1. Load EfficientNet(Base:B0)","03b353dc":"## 3. Data preprocessing","017a9aa6":"## 4. Train model","f9ade047":"I try to 'weight=None', this train processing time is very long...","35fe641e":"In case of EfficientNetB0 model, image resolution is 224","05b2fe59":"For transfer learning, we set parameter 'include_top' is False","e7e4c690":"For B0 to B7 base models, the input shapes are different. Here is a list of input shape expected for each model\n\nBase model |\tresolution |\n-----------|---------------|\nEfficientNetB0 |\t224 |\nEfficientNetB1 |\t240 |\nEfficientNetB2 |\t260 |\nEfficientNetB3 |\t300 |\nEfficientNetB4 |\t380 |\nEfficientNetB5 |\t456 |\nEfficientNetB6 |\t528 |\nEfficientNetB7 |\t600 |","ee69ca87":"## 2. Load dataset(Stanford_dogs)"}}