{"cell_type":{"964b7ddc":"code","17835acc":"code","7a530a5f":"code","e78bfe52":"code","2f0ef859":"code","00310d7c":"code","dbe29283":"code","1dd666f8":"code","a6cf2eca":"code","f7b61501":"code","ba09c43a":"code","7d9232bc":"code","8d6dbc8a":"code","4bf91d6c":"code","3cf3f873":"code","e87aa2cb":"code","a8718dc5":"code","b59dc4a2":"code","eb63e75d":"code","b9763a9a":"code","3ec657bb":"code","7d529aea":"code","ec6787fb":"code","d5888099":"code","7cee3e1c":"code","3564858c":"code","196220fd":"code","9764c368":"code","bfe79753":"code","096a9a86":"code","52133256":"code","03d6cd5b":"code","3a3a788b":"code","f5d531af":"code","214b98d2":"code","75eb1b5b":"code","b7dc0738":"code","ca7aa8d2":"code","0731ae04":"code","6fc4311d":"code","ae8c42e7":"code","2e315fd2":"code","7b33de30":"code","52ca7eca":"code","580ea277":"code","58cb2633":"code","103c5a16":"code","8b0fe7d7":"code","c15018fd":"code","b1c5d9f0":"code","93682219":"code","1b4f7801":"code","673db249":"code","4cd98afc":"code","a0f3bc2b":"code","8c018879":"code","9c1a187b":"code","bdd31d8b":"code","083805ce":"code","84e9bd40":"code","cad8a6d4":"code","d691b384":"code","4d073f5c":"code","ef5d92d6":"code","f5a57e36":"code","88578054":"code","c9d84111":"code","708d068b":"code","dbe552cb":"code","9201f6c7":"code","f6f45a90":"code","6fb89ab8":"code","fec83c29":"code","acb2572d":"code","32699ae4":"code","4f49d6aa":"code","3e4847e6":"code","a0f198f0":"code","426dbce9":"code","12c96f57":"code","a2efa83b":"code","d15d1982":"code","fc570dc3":"code","61bdfb75":"code","5bfc1c49":"code","1360a655":"code","4daeeaf0":"code","eb33a123":"code","b1386f46":"code","8f17cf2c":"code","aa883e69":"code","07d655b2":"code","d0745dcc":"code","8c7e3153":"code","41b36aa7":"code","fa717fa0":"code","71da8bab":"code","a8d956c5":"code","ae7e50b6":"code","4a55f7d0":"markdown","604ffe1d":"markdown","2a3a2b79":"markdown","68c3b976":"markdown","2726580d":"markdown","764c93ca":"markdown","858137a1":"markdown","7c98f7dc":"markdown","d2c2c5ea":"markdown","ece1e690":"markdown","c11d39da":"markdown","2163c8b8":"markdown","f02a9399":"markdown","ce5d8b07":"markdown","a99d9c59":"markdown","60a3c409":"markdown","8e413222":"markdown","5367dc37":"markdown","5e3183be":"markdown","ccff45ad":"markdown","4b42a4ad":"markdown","88782079":"markdown","5500cf79":"markdown","3a97e176":"markdown","5fdf3e4d":"markdown","da9f08ce":"markdown","e876a606":"markdown","7297f423":"markdown","56fa4266":"markdown","77e0776b":"markdown","3a76f6fa":"markdown","c1fc23c4":"markdown"},"source":{"964b7ddc":"#import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\npd.set_option('display.max_colwidth', None)\n%matplotlib inline\nplt.style.use(\"seaborn\")\n#hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","17835acc":"#import the dataset\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf = pd.read_csv('\/kaggle\/input\/usa-housing\/USA_Housing.csv')","7a530a5f":"df","e78bfe52":"df.info()","2f0ef859":"df['Address'].tail()","00310d7c":"def extract_address(x):\n    try:\n        address = x.split('\\n')[1].split(',')[1].split()[0]\n    except IndexError:\n        address = x.split('\\n')[1].split(\" \")[1]\n    return address","dbe29283":"df['Address'] = df['Address'].apply(extract_address)\ndf","1dd666f8":"df['Address'].nunique()","a6cf2eca":"df.describe()","f7b61501":"import missingno as msno\nmsno.matrix(df)","ba09c43a":"import random\ndef random_color():\n    r = lambda: random.randint(0,255)\n    return '#%02X%02X%02X' % (r(),r(),r())","7d9232bc":"sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1.8})\nfor i in df.columns[:-1]:\n    fig,ax = plt.subplots(figsize = (6,3))\n    sns.histplot(df[i],kde = True,color = random_color())","8d6dbc8a":"#Address count plot\nfig,ax = plt.subplots(figsize = (18,6))\nsns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"Address\", data=df)","4bf91d6c":"df.skew()","3cf3f873":"df.kurt()","e87aa2cb":"for i in df.columns[:-1]:\n    print(i)\n    print('IQR: ',df[i].quantile(.75) - df[i].quantile(.25))\n    print('-'*3)","a8718dc5":"sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 1.8})\nfor i in df.columns[:-1]:\n    fig,ax = plt.subplots(figsize = (9,3))\n    color = np.random.rand(3,)\n    ax = sns.boxplot(x=df[i],color = random_color())","b59dc4a2":"def bivariate_plot(column,color):\n    sns.set_context(\"paper\", font_scale=1.8, rc={\"lines.linewidth\": 1.8})\n    sns.set_style('white')\n    import scipy.stats\n    fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize = (21,6))\n    sns.regplot(data = df,x=column, y='Price',ax = ax1,color = color,line_kws ={'color' :'red'})\n    sns.kdeplot(data=df,x=column,y=\"Price\",ax =ax2,color = color,)\n    df.plot.hexbin(x=column, y='Price', gridsize=9,ax = ax3,cmap=plt.cm.Blues)\n    fig.suptitle(column, fontsize=18)\n    sns.despine()\n    plt.show()\n    print('Pearson\\' correlation coefficient :',df[column].corr(df['Price']))\n    print('Spearman\\'s correlation coefficient :',df[column].corr(df['Price'],method = 'spearman'))\n    print('Kendall\\'s correlation coefficient :',df[column].corr(df['Price'],method = 'kendall'))","eb63e75d":"bivariate_plot('Avg. Area Income','#0089fa')","b9763a9a":"bivariate_plot('Avg. Area House Age','#00b032')","3ec657bb":"bivariate_plot('Avg. Area Number of Rooms','#ff5ef2')","7d529aea":"bivariate_plot('Avg. Area Number of Bedrooms','#ff6b6b')","ec6787fb":"bivariate_plot('Area Population','#d6a400')","d5888099":"sns.set_context(\"paper\", font_scale=1.2, rc={\"lines.linewidth\": 1.8})\nsns.pairplot(df,vars = ['Avg. Area Income',\n                        'Avg. Area House Age','Avg. Area Number of Rooms',\n                        'Avg. Area Number of Rooms','Area Population','Price'],kind= 'reg')","7cee3e1c":"fig,ax = plt.subplots(figsize = (18,6))\nsns.set_theme(style=\"darkgrid\")\nax = sns.barplot(x=\"Address\", y=\"Price\", data=df,palette = 'mako')\nax.set_title('Address Vs Price',size = 18)","3564858c":"fig,ax = plt.subplots(figsize = (18,6))\nsns.set_theme(style=\"darkgrid\")\nax = sns.barplot(x=\"Address\", y=\"Area Population\", data=df,palette = 'rocket')\nax.set_title('Address Vs Area Population',size = 18)","196220fd":"#correlation matrix\ncorr = df.corr(method = 'pearson')\ncorr","9764c368":"sns.heatmap(corr,xticklabels = corr.columns,yticklabels = corr.columns,annot=True)","bfe79753":"def remove_outliers(df):\n    outliers = {}\n    for col in df.columns:\n        if str(df[col].dtype) != 'object':\n            df = df[np.abs(df[col]-df[col].mean()) < (3*df[col].std())]\n            olrs = df[~(np.abs(df[col]-df[col].mean()) < (3*df[col].std()))]\n            outliers = pd.DataFrame(olrs)        \n    return df            \ndf_outlier = remove_outliers(df)","096a9a86":"def diagnostic_plots(df, variable):\n    \n    plt.figure(figsize=(15,6))\n    plt.subplot(1, 2, 1)\n    df[variable].hist(bins=30)\n    plt.subplot(1, 2, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.suptitle(variable, fontsize=16)\n    plt.show()","52133256":"diagnostic_plots(df_outlier, 'Avg. Area Income')","03d6cd5b":"diagnostic_plots(df_outlier, 'Avg. Area House Age')","3a3a788b":"diagnostic_plots(df_outlier, 'Avg. Area Number of Rooms')","f5d531af":"diagnostic_plots(df_outlier, 'Area Population')","214b98d2":"diagnostic_plots(df_outlier, 'Price')","75eb1b5b":"y = df_outlier['Price']\n#log transform target variable\ny = np.log1p(y)","b7dc0738":"from sklearn.model_selection import train_test_split","ca7aa8d2":"X_train, X_test, y_train, y_test = train_test_split(\n    df_outlier.drop(['Price','Address'],axis = 1), y, test_size=0.3, random_state=0)","0731ae04":"from sklearn.preprocessing import MinMaxScaler","6fc4311d":"scaler = MinMaxScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_test_std = scaler.transform(X_test)","ae8c42e7":"from sklearn.model_selection import cross_val_score\n#create an empty dictionary to store data.\nmodel_performance = {}","2e315fd2":"from sklearn import metrics\ndef print_evaluate(true,predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)","7b33de30":"def plot(Model,test_pred):\n    fig,ax = plt.subplots(figsize = (9,6))\n    plt.scatter(y_test, test_pred, c='#0097e3',s = 6)\n    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', c='red', lw=2.7)\n    plt.xlabel('Actuals')\n    plt.ylabel('Predicted Values')\n    plt.title('Actuals Vs Predicted Values')\n    plt.suptitle(Model,fontsize = 16)\n    plt.show()\n    # increase size","52ca7eca":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train_std,y_train)","580ea277":"test_pred = lin_reg.predict(X_test_std)\ntrain_pred = lin_reg.predict(X_train_std)","58cb2633":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","103c5a16":"plot('Linear Regression',test_pred)","8b0fe7d7":"#get the cross val score\nscore = cross_val_score(lin_reg, X_train_std, y_train, cv=9,).mean()","c15018fd":"model_performance['Linear Regression(Simple)'] = score","b1c5d9f0":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nparameters = {\"alpha\": [0.01,0.09,0.1,1,2,5,10,100],\"normalize\":[True,False] ,\"positive\" : [True,False],\n              'fit_intercept' : [True,False]}","93682219":"gridsearch = GridSearchCV(Lasso(), parameters)\ngridsearch.fit(X_train_std, y_train)","1b4f7801":"gridsearch.best_params_","673db249":"#building the best Lasso Regression Model\nlasso_reg = Lasso(alpha = 0.01,fit_intercept = True,normalize = False, positive = True)\nlasso_reg.fit(X_train_std,y_train)","4cd98afc":"test_pred = lasso_reg.predict(X_test_std)\ntrain_pred = lasso_reg.predict(X_train_std)","a0f3bc2b":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","8c018879":"plot('L1 Linear Regression',test_pred)","9c1a187b":"#get the cross val score\nscore = cross_val_score(lasso_reg, X_train_std, y_train, cv=9,).mean()\nmodel_performance['Linear Regression(Lasso)'] = score","bdd31d8b":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nparameters = {\"alpha\": [0.01,0.09,0.1,1,2,5,10,100],\"normalize\":[True,False] ,\n              'fit_intercept' : [True,False]}","083805ce":"gridsearch = GridSearchCV(Ridge(), parameters)\ngridsearch.fit(X_train_std, y_train)","84e9bd40":"gridsearch.best_params_","cad8a6d4":"#Building the best Ridge mdoel\nridge_reg = Ridge(alpha = 0.1,fit_intercept = True,normalize = False)\nridge_reg.fit(X_train_std,y_train)","d691b384":"test_pred = ridge_reg.predict(X_test_std)\ntrain_pred = ridge_reg.predict(X_train_std)","4d073f5c":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","ef5d92d6":"plot('L2 Linear Regression',test_pred)","f5a57e36":"#get the cross val score\nscore = cross_val_score(ridge_reg, X_train_std, y_train, cv=9,).mean()\nmodel_performance['Linear Regression(Ridge)'] = score","88578054":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score \ndegrees = [2, 3, 4, 5, 6] # Change degree \"hyperparameter\" here\nnormalizes = [True, False] # Change normalize hyperparameter here\nbest_score = 0\nbest_degree = 0\npoly_reg = {\n    'degree' : [],\n    'normalize' : [],\n    'scores' : [],\n    'r2_score' : [],\n}\nfor degree in degrees:\n    for normalize in normalizes:\n        poly_features = PolynomialFeatures(degree = degree)\n        scaler = MinMaxScaler()\n        \n        X_train_poly = scaler.fit_transform(poly_features.fit_transform(X_train))\n        X_test_poly = scaler.transform(poly_features.transform(X_test))\n        \n        polynomial_regressor = LinearRegression(normalize=normalize)\n        polynomial_regressor.fit(X_train_poly, y_train)\n        scores = cross_val_score(polynomial_regressor, X_train_poly, y_train, cv=6)\n        test_pred = polynomial_regressor.predict(X_test_poly)\n        \n        r2_score = metrics.r2_score(y_test, test_pred)\n        \n        # Change k-fold cv value here\n        poly_reg['degree'].append(degree)\n        poly_reg['normalize'].append(normalize)\n        poly_reg['scores'].append(scores.mean())\n        poly_reg['r2_score'].append(r2_score)\n    ","c9d84111":"pd.DataFrame(poly_reg)","708d068b":"poly_reg = PolynomialFeatures(degree = 3)\nfrom sklearn.preprocessing import PolynomialFeatures\nscaler = MinMaxScaler()\n\n#polynomial scale\npoly_reg = PolynomialFeatures(degree = 3)\nX_train_poly = poly_reg.fit_transform(X_train)\nX_test_poly = poly_reg.transform(X_test)\n\n#standaer scale\nX_train_std_ploy = scaler.fit_transform(X_train_poly)\nX_test_std_ploy = scaler.transform(X_test_poly)\n\nploy_reg = LinearRegression()\nploy_reg.fit(X_train_std_ploy, y_train)","dbe552cb":"test_pred = ploy_reg.predict(X_test_std_ploy)\ntrain_pred = ploy_reg.predict(X_train_std_ploy)","9201f6c7":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","f6f45a90":"plot('Polynomial Regression',test_pred)","6fb89ab8":"#get the cross val score\nscore = cross_val_score(ploy_reg, X_train_std_ploy, y_train, cv=9,).mean()\nmodel_performance['Polynomial Regression'] = score","fec83c29":"scaler = MinMaxScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_test_std = scaler.transform(X_test)\nfrom sklearn.neighbors import KNeighborsRegressor","acb2572d":"neigh = KNeighborsRegressor(n_neighbors=3)\nneigh.fit(X_train_std, y_train)","32699ae4":"test_pred = neigh.predict(X_test_std)\ntrain_pred = neigh.predict(X_train_std)","4f49d6aa":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","3e4847e6":"parameters = {\n    'n_neighbors' :np.arange(1,50),\n    \"weights\" : ['uniform','distance'],\n    \"p\" : [1,2],    \n}","a0f198f0":"gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\ngridsearch.fit(X_train_std, y_train)","426dbce9":"gridsearch.best_params_","12c96f57":"#buliding the best KNNRegressor model\nneigh = KNeighborsRegressor(n_neighbors=11,p = 2,weights = 'distance')\nneigh.fit(X_train_std, y_train)","a2efa83b":"test_pred = neigh.predict(X_test_std)\ntrain_pred = neigh.predict(X_train_std)","d15d1982":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","fc570dc3":"plot('KNN Regression',test_pred)","61bdfb75":"#get the cross val score\nscore = cross_val_score(neigh, X_train_std, y_train, cv=9,).mean()\nmodel_performance['KNN Regression'] = score","5bfc1c49":"from sklearn.svm import SVR","1360a655":"regr = SVR(kernel = 'linear')","4daeeaf0":"regr.fit(X_train_std, y_train)","eb33a123":"test_pred = regr.predict(X_test_std)\ntrain_pred = regr.predict(X_train_std)","b1386f46":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","8f17cf2c":"parameters = {\n    'kernel' :['linear', 'poly', 'rbf', 'sigmoid'],\n    'gamma' : ['scale','auto'],\n\n}","aa883e69":"gridsearch = GridSearchCV(SVR(), parameters)\ngridsearch.fit(X_train_std, y_train)","07d655b2":"gridsearch.best_params_","d0745dcc":"#building the best SVR() mdoel\nregr = SVR(kernel = 'rbf',gamma = 'scale')\nregr.fit(X_train_std, y_train)","8c7e3153":"test_pred = regr.predict(X_test_std)\ntrain_pred = regr.predict(X_train_std)","41b36aa7":"print(\"------TEST------\")\nprint()\nprint_evaluate(y_test,test_pred)\nprint()\nprint(\"------TRAIN------\")\nprint_evaluate(y_train,train_pred)","fa717fa0":"plot('Support vector Regressor',test_pred)","71da8bab":"#get the cross val score\nscore = cross_val_score(regr, X_train_std, y_train, cv=9,).mean()\nmodel_performance['SVR(kernel = rbf)'] = score","a8d956c5":"model_df = pd.DataFrame.from_dict(model_performance,orient = 'index',columns = ['Mean CV Score'])\nmodel_df = model_df.sort_values(by ='Mean CV Score',ascending = False)\nmodel_df","ae7e50b6":"sns.barplot(x=\"Mean CV Score\", y=model_df.index, data=model_df,color = '#a30023')","4a55f7d0":"#### Check the quantiles","604ffe1d":"### Multivariate  Data Analysis","2a3a2b79":"#### Linear Regression","68c3b976":"The best polynomial degree is 3","2726580d":"#### Support Vector Regressor (SVR)","764c93ca":"#### KNN Regression","858137a1":"##### Hyperparameter Tuning","7c98f7dc":"The best model is of Polynomial degree 3.","d2c2c5ea":"#### Standard Scaling","ece1e690":"#### Removing with Outliers","c11d39da":"#### Skewness\n","2163c8b8":"#### Visualizing","f02a9399":"#### Kurtosis","ce5d8b07":"### Bivariate Data Analysis","a99d9c59":"#### Lasso Regression (L1 Regularization)","60a3c409":"### Variable Transforamtion (if necessary)","8e413222":"### USA House Price Prediction\n\n![](https:\/\/i.imgur.com\/9bXjPA5.gif)\n\nI deployed the model.you can visit it [here](https:\/\/dibkb-houseprice.herokuapp.com\/)","5367dc37":"#### Distribution of numerical columns","5e3183be":"#### Check for missing values","ccff45ad":"#### Descriptive Statistics","4b42a4ad":"#### PloynomialRegrression","88782079":"#### Regressionrplot,Bivariate KDE,Hexbin and correlation coefficients","5500cf79":"#### Visualizing the model performance","3a97e176":"### Univariate Data Analysis","5fdf3e4d":"#### Measuring Performance","da9f08ce":"#### Chosing the best degree polynomial\n","e876a606":"#### Feature Engineeing","7297f423":"#### IQR (Inter Quartile Range)","56fa4266":"##### Hyperparameter Tuning","77e0776b":"#### Ridge Regression (L2 Regularization)","3a76f6fa":"### Model Building","c1fc23c4":"All the Variavble except (Avg. Area Number of Bedrooms) are approximately normally distributed."}}