{"cell_type":{"83103ed1":"code","05f159c4":"code","d4a6be32":"code","f21c3d66":"code","c94b459b":"code","8262387f":"code","4fe437a5":"code","712b5a0e":"code","a74e670c":"code","5de49145":"code","46e752c9":"code","56508c6d":"code","97396d64":"code","ec8c2ce1":"code","03f68af3":"code","89ac068b":"code","08932fe4":"code","df1c7ad7":"code","2a47d866":"code","a2b47320":"code","992fb40c":"code","45ff6f3f":"code","7621d453":"code","a1f5bbe5":"code","50db4357":"code","7bd63981":"code","893d7d1e":"code","044927bc":"code","7391053c":"code","89d03b6b":"code","ac01ee8b":"code","949f8d20":"code","5b3f5477":"code","e0319525":"code","e2dee56b":"code","a02a0221":"code","b56f1b53":"code","7fc5b0f1":"code","3a338a5e":"code","7e2a22fd":"code","4f74a367":"code","e7f6be2a":"code","8959b955":"code","9514b3d7":"markdown","49ea36af":"markdown","6e334d84":"markdown","8040bf32":"markdown","841be3b2":"markdown","65e56ed7":"markdown","335e41e2":"markdown"},"source":{"83103ed1":"import numpy as np \nimport pandas as pd \nimport pickle\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","05f159c4":"import pandas as pd\nimport numpy as np\n\ndf_ = pd.read_csv(\"..\/input\/online-retail-ii-uci\/online_retail_II.csv\")\n# Let's copy the dataset for furher changes\ndf = df_.copy()\ndf.head()","d4a6be32":"# Data Pre-Processing\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe","f21c3d66":"df = retail_data_prep(df)","c94b459b":"# Let's prepare data type for Germany customers\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\n# output will represent in just one column\npd.set_option('display.expand_frame_repr', False)\n\ndf_ge = df[df['Country'] == \"Germany\"]\n\n\ndf_ge.groupby(['Invoice', 'Description']). \\\n    agg({\"Quantity\": \"sum\"}). \\\n    unstack(). \\\n    fillna(0). \\\n    applymap(lambda x: 1 if x > 0 else 0).iloc[0:5, 0:5]","8262387f":"def create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","4fe437a5":"ge_inv_pro_df = create_invoice_product_df(df_ge)\nge_inv_pro_df.head()","712b5a0e":"ge_inv_pro_df = create_invoice_product_df(df_ge, id=True)\nge_inv_pro_df.head()","a74e670c":"# Let's create function that ca help find stock code for further needs\n\ndf_ge['InvoiceDate']=pd.to_datetime(df['InvoiceDate'])\n\ndef check_id(dataframe, stock_code):\n    product_name = dataframe.loc[dataframe[\"StockCode\"] == stock_code, \"Description\"].values[0]\n    print(product_name)\n\ncheck_id(df_ge, \"21987\")\n# #check_id(df_ge, 23235)\n# #check_id(df_ge, 22747)","5de49145":"# Let's install mlxtend library\n!pip install mlxtend","46e752c9":"from mlxtend.frequent_patterns import apriori, association_rules\n\n# Let's apply content based recommendation\n\n# Possibilities of all product combinations\nfrequent_itemsets = apriori(ge_inv_pro_df, min_support=0.01, use_colnames=True)\nfrequent_itemsets.sort_values(\"support\", ascending=False).head(10)","56508c6d":"rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\nrules.sort_values(\"support\", ascending=False).head()","97396d64":"rules.sort_values(\"lift\", ascending=False).head(20)","ec8c2ce1":"check_id(df_ge, \"21987\")","03f68af3":"check_id(df_ge, \"22747\")","89ac068b":"def arl_recommender(rules_df, product_id, rec_count=1):\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n    recommendation_list = []\n\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n\n    return recommendation_list[:rec_count]","08932fe4":"arl_recommender(rules, \"21987\", 3)","df1c7ad7":"def create_user_movie_df():\n    import pandas as pd\n    movie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\n    rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n    comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n    rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n    common_movies = df[~df[\"title\"].isin(rare_movies)]\n    user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n    return user_movie_df","2a47d866":"user_movie_df = create_user_movie_df()","a2b47320":"def item_based_recommender(movie_name, user_movie_df):\n    movie_name = user_movie_df[movie_name]\n    return user_movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)","992fb40c":"item_based_recommender(\"Matrix, The (1999)\", user_movie_df)","45ff6f3f":"# If we dont know the name of the movie name or release year exactly\n# we can create a function that can find the keywords in the movie title\ndef check_film(keyword, user_movie_df):\n    return [col for col in user_movie_df.columns if keyword in col]\n\ncheck_film(\"Mission\", user_movie_df)","7621d453":"item_based_recommender(check_film(\"Sherlock\", user_movie_df)[0], user_movie_df)","a1f5bbe5":"# Loading the dataset takes time so, we can upload to pkl file\n# We need to import pickle library\nimport pickle\npickle.dump(user_movie_df, open(\"user_movie_df.pkl\", 'wb'))\nuser_movie_df = pickle.load(open('user_movie_df.pkl', 'rb'))","50db4357":"# Let's use pck file that we created after data preprocessing\nuser_movie_df = pickle.load(open('user_movie_df.pkl', 'rb'))","7bd63981":"# Preparing movie list for random user in order to recommend a movie list\nrandom_user = int(pd.Series(user_movie_df.index).sample(1, random_state=45).values)\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\nmovies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\nuser_movie_df.loc[user_movie_df.index == random_user, user_movie_df.columns == \"Schindler's List (1993)\"]\nlen(movies_watched)","893d7d1e":"# Let's access same watched movie list for different users\nmovies_watched_df = user_movie_df[movies_watched]\nuser_movie_count = movies_watched_df.T.notnull().sum()\nuser_movie_count = user_movie_count.reset_index()\nuser_movie_count.columns = [\"userId\", \"movie_count\"]\nuser_movie_count[user_movie_count[\"movie_count\"] > 20].sort_values(\"movie_count\", ascending=False)\nuser_movie_count[user_movie_count[\"movie_count\"] == 33].count()\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > 20][\"userId\"]","044927bc":"users_same_movies.head()","7391053c":"# Let's count the same watched movie list\nusers_same_movies.count()","89d03b6b":"# Preparing same behavior action of users\n\n\"\"\"\nTo prepare user behaviour action matrix;\n1-) We need to built correlation matrix of the users\n2-) After preparing correlation matrix, we need to define top users\n\"\"\" \n\nfinal_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies)],\n                      random_user_df[movies_watched]])","ac01ee8b":"final_df.head()","949f8d20":"final_df.count()","5b3f5477":"corr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()","e0319525":"corr_df.head()","e2dee56b":"corr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\ncorr_df.head()","a02a0221":"corr_df.index.names = ['user_id_1', 'user_id_2']\ncorr_df.count()","b56f1b53":"corr_df.reset_index(inplace=True)\ncorr_df.head()","7fc5b0f1":"corr_df.sort_values(by=\"corr\", ascending=False).head()","3a338a5e":"# Definig top users\n# We are searching high correlation (higher than 65%)\ntop_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n    [\"user_id_2\", \"corr\"]].reset_index(drop=True)\n\ntop_users = top_users.sort_values(by='corr', ascending=False)\ntop_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)","7e2a22fd":"# Let's create recommendation score using rating dataset for top users\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\n\ntop_users_ratings = top_users_ratings[top_users_ratings[\"userId\"] != random_user]\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\ntop_users_ratings.head()","4f74a367":"# Group by for weighed rating score\ntop_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"}).head(20)","e7f6be2a":"recommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\nrecommendation_df = recommendation_df.reset_index()\nrecommendation_df[[\"movieId\"]].nunique()","8959b955":"movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5]. \\\n    sort_values(\"weighted_rating\", ascending=False)\n\nmovies_to_be_recommend.head(5)","9514b3d7":"## Let's Code and Practice \ud83d\ude80\ud83d\udc68\ud83c\udffc\u200d\ud83d\udcbb\n\nWe will use open source Online Retail dataset and suggest products to users at the basket stage.\n\nLet's check the dataset for first insight\n\n- InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'C', it indicates a cancellation.\n\n- StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n\n- Description: Product (item) name. Nominal.\n\n- Quantity: The quantities of each product (item) per transaction. Numeric.\n\n- InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n\n- UnitPrice: Unit price. Numeric. Product price per unit in sterling (\u00a3).\n\n- CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n\n- Country: Country name. Nominal. The name of the country where a customer resides.","49ea36af":"## Lets Code and Practice \ud83d\ude80\ud83d\udc68\ud83c\udffc\u200d\ud83d\udcbb\n\nWe will use Movie and Rating Dataset.\n\n__Movie Dataset__:\n\n- movieId: Unique movie ID\n\n- title: Movie Name\n\n__Rating Dataset__:\n\n- userId: Unique user ID\n\n- movieId: Unique movie ID\n\n- rating: User ratings for movies\n\n- timestamp: Date for rating","6e334d84":"# Content Based Recommendations\n\nContent based filtering uses specific items to recommend other items similar based on customer likes or behaviours\n\n![image](https:\/\/miro.medium.com\/max\/998\/1*O_GU8xLVlFx8WweIzKNCNw.png)\n\nIn the Google Machine Learning documentation:\n\nTo demonstrate content-based filtering, let\u2019s give some examples for the Google Play store. The following figure shows a feature matrix where each row represents an app and each column represents a feature. Features could include categories (such as Education, Casual, Health), the publisher of the app, and many others. To simplify, assume this feature matrix is binary: a non-zero value means the app has that feature.\n\nYou also represent the user in the same feature space. Some of the user-related features could be explicitly provided by the user. For example, a user selects \"Entertainment apps\" in their profile. Other features can be implicit, based on the apps they have previously installed. For example, the user installed another app published by Science R Us.\n\nThe model should recommend items relevant to this user. To do so, you must first pick a similarity metric (for example, dot product). Then, you must set up the system to score each candidate item according to this similarity metric. Note that the recommendations are specific to this user, as the model did not use any information about other users.\n\n__Using Dot Product as a Similarity Measure__\n\n(x,y we can think like coordinate system) is the number of features that are active in both vectors simultaneously. A high dot product then indicates more common features, thus a higher similarity. (Check the figure)\n\n\n__Advantages__\n\n- The model doesn't need any data about other users, since the recommendations are specific to this user. This makes it easier to scale to a large number of users.\n\n- The model can capture the specific interests of a user, and can recommend niche items that very few other users are interested in.\n\n__Disadvantages__\n\n- Since the feature representation of the items are hand-engineered to some extent, this technique requires a lot of domain knowledge. Therefore, the model can only be as good as the hand-engineered features.\n\n- The model can only make recommendations based on existing interests of the user. In other words, the model has limited ability to expand on the users' existing interests.\n\nSource: [Google Recommendation Systems Documentation](https:\/\/developers.google.com\/machine-learning\/recommendation\/content-based\/basics)","8040bf32":"# Recommendation System\nA recommendation system, is a subclass of information filtering system that looks for to predict or model the \"rating\" or \"preference\" a user would give to an item.\n\nRecommender systems are used in a different areas, such as playlist generators for video and music services, product recommenders for online stores, or content recommenders for social media platforms and open web content recommenders. These systems can operate using a single input, like music, or multiple inputs within and across platforms like news, books, and search queries. Besides that, there are also popular recommender systems for specific topics like restaurants and online dating.\n\nRecommender systems usually make use of either or both collaborative filtering and content-based filtering (user-based approach) as well as other systems such as knowledge-based systems. __Collaborative filtering__ approaches build a model from a user's past behavior (items previously purchased or selected and\/or numerical ratings given to those items) as well as similar decisions made by other users. This model is then used to predict items (or ratings for items) that the user may have an interest in. __Content-based filtering__\nof discrete, pre-tagged characteristics of an item in order to recommend additional items with similar properties. Current recommender systems typically combine one or more approaches into a __hybrid system.__\n\n![image.png](https:\/\/miro.medium.com\/max\/2000\/1*rCK9VjrPgpHUvSNYw7qcuQ@2x.png)\n\n\nSource: \n\n- [Recommendation System](https:\/\/towardsdatascience.com\/introduction-to-recommender-systems-6c66cf15ada)\n\n- [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Recommender_system)","841be3b2":"# Collaborative Filtering Methods\n\nTo address some of the limitations of content-based filtering, collaborative filtering uses similarities between users and items simultaneously to provide recommendations (hybrid). This allows for serendipitous recommendations; that is, collaborative filtering models can recommend an item to user A based on the interests of a similar user B. Furthermore, the embeddings can be learned automatically, without relying on hand-engineering of features.\n\n![Collaborative Filtering](https:\/\/media.springernature.com\/lw685\/springer-static\/image\/art%3A10.1007%2Fs11227-020-03266-2\/MediaObjects\/11227_2020_3266_Fig1_HTML.png)\n\nCollaborative filtering methods are based on the past records between users and items in order to give new recommendations. User-item interactions matrix stores the item-user intereactions.\n\n![User-item interactions matrix](https:\/\/buomsoo-kim.github.io\/data\/images\/2020-08-08\/0.png)\n\n\nThen, the main idea that rules collaborative methods is that these past user-item interactions are sufficient to detect similar users and\/or similar items and make predictions based on these estimated proximities.\n\nThe class of collaborative filtering algorithms is divided into two sub-categories that are generally called memory based and model based approaches. Memory based approaches directly works with values of recorded interactions, assuming no model, and are essentially based on nearest neighbours search (for example, find the closest users from a user of interest and suggest the most popular items among these neighbours). Model based approaches assume an underlying \u201cgenerative\u201d model that explains the user-item interactions and try to discover it in order to make new predictions.\n\n\n![Memory Based](https:\/\/miro.medium.com\/max\/2000\/1*yV3-_A1q37WheNJCvzutqg@2x.png)\n\nThe main advantage of collaborative filtering methods is that it doesn't require information about users or items and it only looks for the users and items correlation, because of that reason it can apply in different cases. \n\n__Moreover, if users interactions increase with the items, the new recommendations become more accurate__\n\n\n__However__, collaborative filtering suffers from the \u201ccold start problem\u201d. It is impossible to recommend anything to new users or to recommend a new item to any users if we have less interactions.\n\n\nSource: \n\n- [Towards Data Science](https:\/\/towardsdatascience.com\/introduction-to-recommender-systems-6c66cf15ada)\n\n- [Google Documentation](https:\/\/developers.google.com\/machine-learning\/recommendation\/collaborative\/basics)","65e56ed7":"## Item-Based Collaborative Filtering","335e41e2":"## User-Based Collaborative Filtering"}}