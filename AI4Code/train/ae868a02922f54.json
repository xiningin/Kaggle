{"cell_type":{"6cd69f07":"code","b54ae2b7":"code","8421256c":"code","93953bb9":"code","62d655ce":"code","1e74340d":"code","db5bbfb1":"code","b2f060f2":"code","4754c8fa":"code","e41e4603":"code","43090be9":"code","236e89be":"code","81864688":"code","f798af68":"code","682f8f7e":"code","15fefc2e":"code","0f54689e":"code","ce21300e":"code","77ae125c":"code","d06e18a5":"code","953a8819":"code","7dcc96de":"code","f18caded":"code","6cef025b":"code","81a7cc77":"code","22a2c60f":"code","ed532f71":"code","73b2a39c":"code","46e468f8":"code","c0e19aed":"code","713b48c6":"code","0844ab62":"code","87cc168c":"code","47d68e59":"code","3da5e27d":"code","4cfc4277":"code","9744ae33":"code","fc0e9980":"markdown","06d51a19":"markdown","22bd2521":"markdown","e0b8165a":"markdown","16ab4312":"markdown","566d0ece":"markdown","32345e7f":"markdown","91ff9d82":"markdown","d5e459ce":"markdown","b862b18b":"markdown","c2cf8f69":"markdown","7cd796ef":"markdown","bd5e1a4c":"markdown","932c41e2":"markdown","e21c424e":"markdown","66ae9508":"markdown"},"source":{"6cd69f07":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nimport nltk","b54ae2b7":"file = pd.read_csv(\"..\/input\/hashtag-safaricom-tweets\/safaricom_tweets.csv\")\nfile.head()","8421256c":"file.columns","93953bb9":"file.shape","62d655ce":"tweets_df = file[[\"Tweet Id\", \"Screen Name\", \"Text\"]]\ntweets_df.head()","1e74340d":"tweets_df.shape","db5bbfb1":"from nltk.tokenize import word_tokenize","b2f060f2":"nltk.download('punkt')","4754c8fa":"!pip install emoji","e41e4603":"import emoji\ndef tokenize_tweets(text):\n  #remove emojis\n  text = emoji.demojize(text)\n  #remove urls\n  text = re.sub('http[s]?:\/\/\\S+', '', text)\n  #remove punctuations\n  text = re.sub(r'[^\\w\\s]','',text)\n  #strip numbers\n  text = re.sub('[0-9]+', '', text)\n  text = word_tokenize(text)\n  \n  return text\ntweets_df[\"Tweets\"] = tweets_df[\"Text\"].apply(lambda x: tokenize_tweets(x))\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop = stopwords.words(\"english\")\ntweets_df[\"stop_words\"] = tweets_df[\"Tweets\"].apply(lambda x: [w for w in x if w in stop])\ntweets_df[\"Tweets\"] = tweets_df[\"Tweets\"].apply(lambda x: [w.lower() for w in x if w not in stop])\n\ntweets_df.head(10)","43090be9":"tweets_df.head()","236e89be":"string.punctuation","81864688":"from nltk.stem.porter import *\nstemmer = PorterStemmer()\ntweets_df[\"Tweets\"] = tweets_df[\"Tweets\"].apply(lambda x: [stemmer.stem(w) for w in x])\ntweets_df.head()","f798af68":"\ndef remove_punct(text):\n  text = \" \".join([char for char in text if char not in string.punctuation])\n  text = re.sub('[0-9]+', '', text)\n  \n  \n  return text\ntweets_df['tweet_punct'] = tweets_df['Tweets'].apply(lambda x: remove_punct(x))\n","682f8f7e":"tweets_df.head(10)","15fefc2e":"\ntweets_df.head()","0f54689e":"import matplotlib.pyplot as plt\nall_words = ' '.join([text for text in tweets_df['tweet_punct']])\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n","ce21300e":"from collections import Counter\n\ncnt = Counter()\nfor text in tweets_df[\"tweet_punct\"].values:\n    for word in text.split():\n        cnt[word] += 1\n        \ncnt.most_common(10)","77ae125c":"!pip install vaderSentiment","d06e18a5":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()","953a8819":"def sentiment_score_compound(sentence):\n    score = analyzer.polarity_scores(sentence)\n    return score['compound']\n\ndef sentiment_score_pos(sentence):\n    score = analyzer.polarity_scores(sentence)\n    return score['pos']\n\ndef sentiment_score_neg(sentence):\n    score = analyzer.polarity_scores(sentence)\n    return score['neg']\n\ndef sentiment_score_neu(sentence):\n    score = analyzer.polarity_scores(sentence)\n    return score['neu']\ntweets_df[\"tweets_sent_compound\"] = tweets_df[\"tweet_punct\"].apply(lambda x: sentiment_score_compound(x))\ntweets_df[\"tweets_sent_pos\"] = tweets_df[\"tweet_punct\"].apply(lambda x: sentiment_score_pos(x))\ntweets_df[\"tweets_sent_neg\"] = tweets_df[\"tweet_punct\"].apply(lambda x: sentiment_score_neg(x))\ntweets_df.head()","7dcc96de":"tweets_df.tail()","f18caded":"wordlist = nltk.FreqDist(all_words)\nword_features = wordlist.keys()","6cef025b":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\ntweets_list = []\nfor tweet in tweets_df[\"tweet_punct\"]:\n  \n  tweets_list.append(tweet)\nlen(tweets_list)\n#tweets_df.shape\n","81a7cc77":"X = tweets_df[\"tweet_punct\"]\n\nvec = TfidfVectorizer(min_df=5, max_df=0.95, sublinear_tf = True,use_idf = True,ngram_range=(1, 2))","22a2c60f":"len(all_words)","ed532f71":"def label_value(val):\n  if val < 0:\n    return 0\n  elif val == 0:\n    return 1\n  else:\n    return 2\ntweets_df[\"label\"] = tweets_df[\"tweets_sent_compound\"].apply(lambda x: label_value(x))\ntweets_df.head()","73b2a39c":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(binary=True)\ncv.fit(tweets_list)\nX = cv.transform(tweets_list)\ny = tweets_df[\"label\"].values\n","46e468f8":"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, train_size = 0.2, random_state = 0\n)\n","c0e19aed":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","713b48c6":"pred = lr.predict(X_val)\nprint(accuracy_score(y_val, pred))\nprint(classification_report(y_val, pred))\nprint(confusion_matrix(y_val, pred))","0844ab62":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_vectorizer.fit(tweets_list)\nX = tfidf_vectorizer.transform(tweets_list)\ny = tweets_df[\"label\"].values\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, train_size = 0.2, random_state = 0\n)","87cc168c":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","47d68e59":"pred = lr.predict(X_val)\nprint(accuracy_score(y_val, pred))\nprint(classification_report(y_val, pred))\nprint(confusion_matrix(y_val, pred))","3da5e27d":"from sklearn.svm import LinearSVC\nngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\nngram_vectorizer.fit(tweets_list)\nX = ngram_vectorizer.transform(tweets_list)\ny = tweets_df[\"label\"].values\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, train_size = 0.2, random_state = 0\n)\nsvm = LinearSVC()\nsvm.fit(X_train, y_train)","4cfc4277":"pred = svm.predict(X_val)\nprint(accuracy_score(y_val, pred))\nprint(classification_report(y_val, pred))\nprint(confusion_matrix(y_val, pred))","9744ae33":"from sklearn.naive_bayes import MultinomialNB\nMNB = MultinomialNB()\nMNB.fit(X_train, y_train)\npred = MNB.predict(X_val)\nprint(accuracy_score(y_val, pred))\nprint(classification_report(y_val, pred))\nprint(confusion_matrix(y_val, pred))","fc0e9980":"<h1>Data cleaning and preprocessing<\/h1>\n<ul>\n<li>Tokenization<\/li>\n<li>Lemmertization<\/li>\n<li>Remove punctuation tags<\/li>\n<li>Remove emojis<\/li>\n<li>Strip numerical values<\/li>\n<li>Remove stop-words<\/li>\n<\/ul>","06d51a19":"<h1>Data overview<\/h1>","22bd2521":"<h1>Na\u00efve Bayes classifier<\/h1>","e0b8165a":"<h1> Importing pandas and other basic libraries<\/h1>","16ab4312":"<h1>Logistic Regression<\/h1>","566d0ece":"<h1>Get most frequent words<\/h1>","32345e7f":"<h1>Data visualization (word cloud)<\/h1>","91ff9d82":"<h1>Vectorization<\/h1>","d5e459ce":"<h1>Getting sentiments label<\/h1>","b862b18b":"<h1>Support Vector Machine<\/h1>","c2cf8f69":"<h1>Get the dataset (Safaricom hashtag tweets upto 31st March)<\/h1>","7cd796ef":"<p> If tweet is negative lable is 0 neutral 1  positive 2 <\/p>\n<p> This is because classifiers only take integers <\/p> ","bd5e1a4c":"<h1>tf-idf vectorization<\/h1>","932c41e2":"<h1>Rows and Columns count<\/h1>","e21c424e":"<h1>Import sklearn<\/h1>","66ae9508":"<h1>Classification model<\/h1>"}}