{"cell_type":{"a14377a2":"code","7ba5eccd":"code","c70d8cf3":"code","814d25c7":"code","1f366423":"code","8bb8b888":"code","b21b4089":"code","a0498196":"code","cb20af76":"code","3c642578":"code","b0ef7c74":"code","8f93d8bb":"code","fd3ec822":"code","7d57e895":"code","49b170bd":"code","3edf7105":"code","9ea08336":"code","8ba50a07":"code","adf5ce55":"code","a40f92d5":"code","df4cc8e9":"code","e77fd659":"code","520cd748":"code","ba9ff43c":"code","70cee78c":"code","6ef639fe":"code","5f6afc65":"code","dbe6b5c9":"code","9fe8e738":"code","cb315c7a":"code","9c04652e":"code","357db3cd":"markdown","3d002603":"markdown"},"source":{"a14377a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\nimport shutil\nfrom tqdm import tqdm\nimport cv2\nimport time\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nimport random\nimport re\n#os.mkdir('..\/data\/')\nprint(os.listdir(\"..\"))\n# Any results you write to the current directory are saved as output.\n\nfrom keras import backend\nfrom keras.applications.inception_v3 import InceptionV3,preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom keras.models import Model, load_model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical","7ba5eccd":"#Total labels to classify\nlabels=['dog','cat']","c70d8cf3":"#Helper functions to resuhffle data\n#Keeping all new data in ..\/data directory as ..\/input ir RO.\ndef create_directory(labels):\n    src_dir='..\/data'\n    if not os.path.exists(src_dir+'\/train'):\n        print('Creating Directory', src_dir+'\/train')\n        os.makedirs(src_dir+'\/train',exist_ok=True)\n    else:\n        print(src_dir+'\/train', ' exists!')\n    \n        #functions to create directory with the label names\n    for l in labels:\n        dir_path=r''+src_dir+'\/train\/'+l\n        if not os.path.exists(dir_path):\n            print('Creating Directory',dir_path)\n            os.mkdir(dir_path)\n        else:\n            print(dir_path, ' exists!')\n                \n    if not os.path.exists(src_dir+'\/test\/test_data'):\n        print('Creating Directory', src_dir+'\/test\/test_data')\n        os.makedirs(src_dir+'\/test\/test_data',exist_ok=True)\n    else:\n        print(src_dir+'\/test\/test_data', ' exists!')\n        \n","814d25c7":"create_directory(labels =labels)\n#shutil.rmtree(path='..\/data')","1f366423":"#Function to move the images tp their corresponding folders:\ndef move_files(train_path,test_path):\n    print('Moving Training Files ..')\n    time.sleep(1)\n    for i in tqdm(os.listdir(train_path)):        \n        if 'dog' in i:\n            shutil.copyfile(train_path+i,'..\/data\/train\/dog\/'+i )\n        elif 'cat' in i:\n            shutil.copyfile(train_path+i,'..\/data\/train\/cat\/'+i )\n        else:\n            print('unkown File', i)\n            \n    print('Moving Testing Files ..')\n    time.sleep(1)\n    for i in tqdm(os.listdir(test_path)):                \n        shutil.copyfile(test_path+i,'..\/data\/test\/test_data\/'+i )\n        \n    #print('File Copy in complete!')","8bb8b888":"move_files('..\/input\/train\/','..\/input\/test\/')","b21b4089":"# Get count of number of files in this folder and all subfolders\ndef get_num_files(path):\n    if not os.path.exists(path):\n        return 0\n    return sum([len(files) for r, d, files in os.walk(path)])","a0498196":"#Setting Image and model parameters\nImage_width,Image_height = 299,299\nbatch_size=50\nNumber_FC_Neurons=1024\ntrain_dir = '..\/data\/train\/'\n\ntotal_samples = get_num_files(train_dir)\nval_split=0.3\nn_train=total_samples*(1-val_split)\nn_val=total_samples*val_split\nnum_classes = len(labels)\nprint(n_train,n_val)\n\ngc.collect()","cb20af76":"# Define data pre-processing \ntrain_image_gen = ImageDataGenerator(rescale=1\/255,horizontal_flip=True,validation_split=val_split)\n'''train_image_gen = ImageDataGenerator(rescale=1\/255,\n        preprocessing_function=preprocess_input,\n        horizontal_flip=True,\n        validation_split=0.3\n    )'''","3c642578":"train_generator = train_image_gen.flow_from_directory(train_dir,target_size=(Image_width,Image_height),batch_size=batch_size,seed=42,subset='training',shuffle=True,class_mode='categorical')\nval_generator = train_image_gen.flow_from_directory(train_dir,target_size=(Image_width,Image_height),batch_size=batch_size,seed=42,subset='validation',shuffle=True,class_mode='categorical')","b0ef7c74":"#Load the inception model and load with its pre trained weight. But exclude the last layer aa we would train that.\n\nInceptionV3_base_model = InceptionV3(weights='imagenet', include_top=False)    #To exclude final conv layer \nprint('Inception v3 base model without last FC loaded')","8f93d8bb":"#Defining the new Final conv layers \n#Using Functional APIs\nx = InceptionV3_base_model.output\nx_pool = GlobalAveragePooling2D()(x)\nx_dense = Dense(Number_FC_Neurons,activation='relu')(x_pool)\nfinal_pred = Dense(num_classes,activation='softmax')(x_dense)\nmodel = Model(inputs=InceptionV3_base_model.input,outputs=final_pred)\n\nmodel.summary()","fd3ec822":"#Adding Callback For early stopping.\n#We use validation loss as the monitoring parameter which we need to minimize.\n#Also, we'll use the result from the best epoch, thus, restore_best_weights=True(Default is False)\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n\ncb_checkpoint = ModelCheckpoint(filepath = '..\/working\/best.hd5', monitor = 'val_loss', save_best_only = True, mode = 'auto',)\ncb_stopping = EarlyStopping(monitor='val_loss',patience=10,mode=min,restore_best_weights=True)\ncb_tensorboard = TensorBoard(log_dir='.\/logs', histogram_freq=0, write_graph=True,write_images=False)\nmy_callback=[cb_stopping, cb_checkpoint,cb_tensorboard]","7d57e895":"#Freeze all the layers in InceptionV3 model to train only our additional layers\n'''for layer in InceptionV3_base_model.layers:\n    layer.trainable=False\n'''\n#Fine tune model by retraining the few end layers of the inception model\nlayer_to_Freeze=172    \nfor layer in model.layers[:layer_to_Freeze]:\n    layer.trainable =False\nfor layer in model.layers[layer_to_Freeze:]:\n    layer.trainable=True\n#Define model compile for basic transfer learning\n#Using categorical_crossentropy loss as we need to classify only 2 classes and using softmax output layer.\n#Please read difference between categorical_crossentropy and binary_crossentropy here:= https:\/\/stackoverflow.com\/questions\/47877083\/keras-binary-crossentropy-categorical-crossentropy-confusion\nsgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nmodel.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])\n","49b170bd":"# Fit the transfer learning model to the data from the generators.  \n# Since the data is coming from the generators that we created ,we use fit_generator() method. \n# And we need to specify the train and val_generator as the source of data.\n# Please note the difference between fit() and fit_generator()\n\nhistory_transfer_learning = model.fit_generator(train_generator,epochs=30,\n                                                steps_per_epoch=n_train\/\/batch_size,\n                                                validation_data=val_generator,\n                                                validation_steps=n_val\/\/batch_size,\n                                                verbose=1,\n                                                callbacks=my_callback,\n                                                class_weight='auto')\n\n#Always save your trained model, as training process is tedious. It's better to train once and then load the already trained model.\n#model.save('model.hd5')","3edf7105":"#incase you have already trained your model, then you can load it by using following Function.\n#Loading the best model.\nfrom keras.models import load_model\nprint('Loading best model...')\nbest_model = load_model('..\/working\/best.hd5')\nprint('Best model loaded!')\n#os.listdir('..\/working')","9ea08336":"#Clearing memory leak\n#backend.clear_session()\ngc.collect()","8ba50a07":"#Evaluating Metrics on Validation set\n#y_pred = model.predict_generator(val_generator,verbose=1)\n\n#Converting probability to target\n#y_pred[y_pred > 0.5]=1\n#y_pred[y_pred < 0.5]=0\n\n#Use Evaluate() or evalute_generator() to check your model accuracy on validation set.\nscore = best_model.evaluate_generator(val_generator,verbose=1)\nprint('Test loss: ', score[0])\nprint('Test accuracy', score[1])\n\n","adf5ce55":"epoch_list = list(range(1,len(history_transfer_learning.history['acc'])+1))  #Values for x axis[1,2,3,4...# of epochs]\nplt.plot(epoch_list, history_transfer_learning.history['acc'],epoch_list,history_transfer_learning.history['val_acc'])\nplt.legend(('Training accuracy','Validation Accuracy'))\nplt.show()\n","a40f92d5":"\nepoch_list = list(range(1,len(history_transfer_learning.history['loss'])+1))  #Values for x axis[1,2,3,4...# of epochs]\nplt.plot(epoch_list, history_transfer_learning.history['loss'],epoch_list,history_transfer_learning.history['val_loss'])\nplt.legend(('Training loss','Validation loss'))\nplt.show()\n","df4cc8e9":"test_dir='..\/data\/test\/'","e77fd659":"os.listdir('..\/working\/')","520cd748":"# Define data pre-processing \ntest_image_gen = ImageDataGenerator(rescale=1\/255)\ntest_generator = test_image_gen.flow_from_directory(test_dir,target_size=(Image_width,Image_height),batch_size=1,seed=42,class_mode=None,shuffle=False)","ba9ff43c":"#test_generator.reset()\ny_pred = model.predict_generator(generator=test_generator,verbose=1)","70cee78c":"#submission = pd.DataFrame({'id':np.arange(1,len(test_generator.filenames)+1),'label':y_pred.clip(min=0.02,max=0.98)[:,1]})\nsubmission = pd.DataFrame({'id':pd.Series(test_generator.filenames),'label':pd.Series(y_pred.clip(min=0.02,max=0.98)[:,1])})\n#submission = pd.DataFrame({'id':pd.Series(test_generator.filenames),'label':pd.Series(y_pred[:,1])})\nsubmission['id'] = submission.id.str.extract('(\\d+)')\nsubmission['id']=pd.to_numeric(submission['id'])\n#submission.sort_values(by='id',inplace=True)\n","6ef639fe":"#y_pred.clip(min=0.02,max=0.98)[:100,1]\n#score","5f6afc65":"#submission.nunique(axis=0)\nsubmission.head(10)","dbe6b5c9":"#submission.shape\n#y_pred[:15,:]","9fe8e738":"submission.to_csv('DogVsCats_submission.csv',index=False)","cb315c7a":"from keras.preprocessing.image import load_img\n\nfig,ax = plt.subplots(5,5, figsize=(15,15))\nfor i,fn in enumerate(test_generator.filenames[:25]):\n    path='..\/data\/test\/'+fn\n    #print(path)    \n    #print(i)\n    img=load_img(path, target_size=(Image_width, Image_height))\n    ax[i\/\/5, i%5].imshow(img)\n    ax[i\/\/5, i%5].axis('off')\n    \n    if (submission['label'][i]) > 0.5:\n        label='Dog'\n    elif (submission['label'][i])<0.5:\n            label='Cat'\n    ax[i\/\/5, i%5].set_title(\"It's a \"+label)\nplt.show()","9c04652e":"len(model.layers)","357db3cd":"#### **We' ll try to train our model using an already existing Conv NN called InceptionV3 model using Transfer Learning. We'll internally move the files to arrange them in subfolders in order to make use of flow_from_directory() function.** \n### **This will help use to train the model in batch mode instead of loading every thing in the memory.**","3d002603":"## Preprocessing and Loading of data"}}