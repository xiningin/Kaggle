{"cell_type":{"795c5789":"code","15b77ab0":"code","9543daf7":"code","f2549b81":"code","92aede6b":"code","2e64539f":"code","c4e1a744":"code","a2e84608":"code","499217c2":"code","d0186e02":"code","4b1e8e9e":"code","63534f10":"code","30316351":"code","07959dbe":"code","a8d6941e":"code","24fae00a":"code","ea81cd93":"code","927a2cc0":"code","75d48c52":"code","3e26828b":"code","95499b3d":"code","dcaa201d":"code","19505c2d":"code","3ce1bdc5":"code","d3065b3f":"code","16c8d3de":"code","78cd1395":"code","fb3d2027":"code","7e46c217":"code","984858e3":"code","135ae7c2":"code","2c8de9db":"code","30d03d38":"code","95610160":"code","92f5b69b":"code","ac4d117e":"code","dd411fcf":"code","116fc758":"code","de8bf4da":"code","f990fc3a":"code","21b4bbc2":"code","dc65350c":"code","dc32c8e0":"code","99f50dcd":"code","f78ddbfe":"code","7fd253be":"code","b99e5ac9":"code","79e8ff79":"code","77f8cabb":"code","852268cf":"code","6424a154":"code","ad55e08d":"code","bc5025c2":"code","68685ba1":"code","efbe9ad5":"code","bb09cfe9":"code","e915202b":"code","c08d0119":"code","80a72d11":"code","1687147c":"code","d69bb697":"code","8c9e853e":"code","43fdc7eb":"code","acdfa692":"code","c8aeee7e":"code","202fc5b9":"markdown","01fff59f":"markdown","627f948d":"markdown","c80e642b":"markdown","226bdd0e":"markdown","1a4f51ed":"markdown","f04fdc83":"markdown","8dba18e7":"markdown","87af3dc0":"markdown","abc43fdb":"markdown","aabbc6c5":"markdown","2473a1dd":"markdown","a5802019":"markdown","42c3fc62":"markdown","4919cd69":"markdown","50fe59a8":"markdown","75870b76":"markdown","b906cbc0":"markdown","cfb86b61":"markdown","62a14071":"markdown","3b7a0897":"markdown","cf1ba27a":"markdown","e2d5b691":"markdown","b240d04a":"markdown"},"source":{"795c5789":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15b77ab0":"import matplotlib.pyplot as plt\nimport cv2 \nfrom random import shuffle \nfrom tqdm import tqdm \nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"..\/input\"))\nimport csv","9543daf7":"import tensorflow as tf\nprint(tf.__version__)","f2549b81":"train_cats = \"..\/input\/iehack1\/animals\/train\/cats\"\ntrain_dogs = \"..\/input\/iehack1\/animals\/train\/dogs\"\ntrain_panda = \"..\/input\/iehack1\/animals\/train\/panda\"\n\ntest_cats = \"..\/input\/iehack1\/animals\/test\/cats\"\ntest_dogs = \"..\/input\/iehack1\/animals\/test\/dogs\"\ntest_panda = \"..\/input\/iehack1\/animals\/test\/panda\"\n","92aede6b":"image_size = 128","2e64539f":"img = cv2.imread(\"..\/input\/iehack1\/animals\/train\/panda\/panda_00019.jpg\")\nimg = cv2.resize(img, (image_size, image_size))\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","c4e1a744":"train_data_dogs = []\ntrain_data_cats = []\ntrain_data_panda = []\n\nfor image in tqdm(os.listdir(train_dogs)): \n    path = os.path.join(train_dogs, image)\n    img1 = cv2.imread(path) \n    img1 = cv2.resize(img1, (image_size, image_size))   \n    np_img1 = np.asarray(img1)\n    train_data_dogs.append(np_img1) \n    \nfor image2 in tqdm(os.listdir(train_cats)): \n    path = os.path.join(train_cats, image2)\n    img2 = cv2.imread(path) \n    img2 = cv2.resize(img2, (image_size, image_size))\n    np_img2 = np.asarray(img2)\n    train_data_cats.append(np_img2) \n    \nfor image3 in tqdm(os.listdir(train_panda)): \n    path = os.path.join(train_panda, image3)\n    img3 = cv2.imread(path) \n    img3 = cv2.resize(img3, (image_size, image_size)) \n    np_img3 = np.asarray(img3)\n    train_data_panda.append(np_img3) \n\ntrain_data = np.concatenate((train_data_dogs, train_data_cats, train_data_panda),axis=0) ","a2e84608":"test_data_dogs = []\ntest_data_cats = []\ntest_data_panda = []\ntest_file_names =[]\n\nfor image in tqdm(os.listdir(test_dogs)): \n    path = os.path.join(test_dogs, image)\n    img1 = cv2.imread(path) \n    img1 = cv2.resize(img1, (image_size, image_size))  \n    np_img1 = np.asarray(img1)\n    test_data_dogs.append(np_img1) \n    test_file_names.append(image)\nfor image2 in tqdm(os.listdir(test_cats)): \n    path = os.path.join(test_cats, image2)\n    img2 = cv2.imread(path) \n    img2 = cv2.resize(img2, (image_size, image_size))\n    np_img2 = np.asarray(img2)\n    test_data_cats.append(np_img2) \n    test_file_names.append(image2)\nfor image3 in tqdm(os.listdir(test_panda)): \n    path = os.path.join(test_panda, image3)\n    img3 = cv2.imread(path) \n    img3 = cv2.resize(img3, (image_size, image_size))\n    np_img3 = np.asarray(img3)\n    test_data_panda.append(np_img3) \n    test_file_names.append(image3)\ntest_data = np.concatenate((test_data_dogs, test_data_cats, test_data_panda),axis=0) ","499217c2":"train_data = train_data\/255.0\ntest_data = test_data\/255.0","d0186e02":"ydogs_train = np.zeros(888).reshape(888,1)\nycats_train = np.zeros(888).reshape(888,1)+1\nypanda_train = np.zeros(888).reshape(888,1)+2\n\nydogs_test = np.zeros(112).reshape(112,1)\nycats_test = np.zeros(112).reshape(112,1)+1\nypanda_test = np.zeros(112).reshape(112,1)+2\n\ny_train = np.concatenate((ydogs_train, ycats_train, ypanda_train),axis=0).reshape(2664,1) \ny_test = np.concatenate((ydogs_test, ycats_test, ypanda_test),axis=0).reshape(336,1)","4b1e8e9e":"train_data.shape","63534f10":"y_train.shape","30316351":"number_of_train = train_data.shape[0]\nnumber_of_test = test_data.shape[0]","07959dbe":"# from sklearn.utils import shuffle\n# training_images, training_labels = shuffle(train_data, y_train, random_state=0)\n# randomize_train = np.arange(number_of_train)\n# np.random.shuffle(randomize_train)\n# dim1= np.arange(64)\n# dim3 = np.arange(3)\n# dim4 = np.arange(1)\n# training_images = train_data[randomize_train,dim1,dim1,dim3]\n# training_labels = y_train[randomize_train,dim4]\n\nseed = 1\nrand_state = np.random.RandomState(seed)\nrand_state.shuffle(train_data)\nrand_state.seed(seed)\nrand_state.shuffle(y_train)\n# rand_state.seed(seed)\n# rand_state.shuffle(c)\n\nseed = 2\nrand_state = np.random.RandomState(seed)\nrand_state.shuffle(test_data)\nrand_state.seed(seed)\nrand_state.shuffle(y_test)\nrand_state.seed(seed)\nrand_state.shuffle(test_file_names)","a8d6941e":"train_data.T.shape","24fae00a":"training_images = train_data\ntraining_labels = y_train\n\n# y_train = np.array(one_hot_encoding(y_train1))\n# y_test = np.array(one_hot_encoding(y_test1))\n\ntest_images = test_data\ntest_labels= y_test\nprint(\"x train: \",training_images.shape)\nprint(\"x test: \",test_images.shape)\nprint(\"y train: \",training_labels.shape)\nprint(\"y test: \",test_labels.shape)","ea81cd93":"seed = 3\na = np.array([1,2,3,4])\nb = np.array([1,2,3,4])\nc = np.array([1,2,3,4])\nrand_state = np.random.RandomState(seed)\nrand_state.shuffle(a)\nrand_state.seed(seed)\nrand_state.shuffle(b)\nrand_state.seed(seed)\nrand_state.shuffle(c)","927a2cc0":"print(a)\nprint(b)\nprint(c)","75d48c52":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\ntest_datagen = ImageDataGenerator(rescale=1\/255)\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        \"..\/input\/iehack1\/animals\/train\/\", \n        target_size=(image_size, image_size),  # All images will be resized to 150x150\n#         batch_size=10,  #i guess the default batch size is 32\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='sparse')\n\ntest_generator = test_datagen.flow_from_directory(\n        \"..\/input\/iehack1\/animals\/test\/\", \n        target_size=(image_size, image_size),  # All images will be resized to 150x150\n#         batch_size=10,\n        # Since we use binary_crossentropy loss, we need binary labels\n        shuffle= False,\n        class_mode='sparse')","3e26828b":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.80):\n      print(\"\\nReached 80% accuracy so cancelling training!\")\n      self.model.stop_training = True","95499b3d":"model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)])","dcaa201d":"model.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(training_images, training_labels, epochs=5, callbacks = [myCallback()])","19505c2d":"model.evaluate(test_images, test_labels)","3ce1bdc5":"classifications = model.predict(test_images)","d3065b3f":"print(classifications[0])","16c8d3de":"classifications.shape","78cd1395":"predictions = np.argmax(classifications, axis = 1)","fb3d2027":"predictions.shape","7e46c217":"test_labels.shape","984858e3":"def calc_accuracy(y_test1, y_pred_temp):\n    count = 0\n    for i in range(len(y_pred_temp)):\n        if(y_test1[i,0]==y_pred_temp[i]):\n            count+=1\n    acc = count\/len(y_pred_temp)*100\n    return acc","135ae7c2":"accuracy_manual_check= calc_accuracy(test_labels,predictions)","2c8de9db":"accuracy_manual_check","30d03d38":"predictions","95610160":"my_submission = pd.DataFrame({'Data_file': np.squeeze(test_file_names), 'Class': np.squeeze(predictions)})\nmy_submission.to_csv('Using_keras_simple_nn.csv', index=False)","92f5b69b":"my_submission.head(10)","ac4d117e":"img = cv2.imread(\"..\/input\/iehack1\/animals\/test\/cats\/cats_00404.jpg\")\n# img = cv2.resize(img, (image_size, image_size))\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","dd411fcf":"img = cv2.imread(\"..\/input\/iehack1\/animals\/test\/cats\/cats_00894.jpg\")\n# img = cv2.resize(img, (image_size, image_size))\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","116fc758":"training_images=training_images.reshape(2664, image_size,image_size, 3)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(336, image_size,image_size, 3)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(image_size,image_size, 3)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)","de8bf4da":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint(test_acc)","f990fc3a":"training_images=training_images.reshape(2664, image_size,image_size, 3)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(336, image_size,image_size, 3)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu', input_shape=(image_size,image_size, 3)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)","21b4bbc2":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint(test_acc)","dc65350c":"training_images=training_images.reshape(2664, image_size,image_size, 3)\ntraining_images=training_images \/ 255.0\ntest_images = test_images.reshape(336, image_size,image_size, 3)\ntest_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu', input_shape=(image_size,image_size, 3)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(64, activation='relu'),\n  tf.keras.layers.Dense(32, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)","dc32c8e0":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint(test_acc)","99f50dcd":"import matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=0\nSECOND_IMAGE=7\nTHIRD_IMAGE=26\nCONVOLUTION_NUMBER = 1\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1,image_size,image_size, 3))[x]\n  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[0,x].grid(False)\n  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1,image_size,image_size, 3))[x]\n  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[1,x].grid(False)\n  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1,image_size,image_size, 3))[x]\n  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[2,x].grid(False)","f78ddbfe":"# training_images=training_images.reshape(2664, image_size,image_size, 3)\n# training_images=training_images \/ 255.0\n# test_images = test_images.reshape(336, image_size,image_size, 3)\n# test_images=test_images\/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu', input_shape=(image_size,image_size, 3)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(28, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(64, activation='relu'),\n  tf.keras.layers.Dense(32, activation='relu'),\n  tf.keras.layers.Dense(3, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","7fd253be":"history = model.fit(\n      train_generator,\n      steps_per_epoch=8,  \n      epochs=5,\n      verbose=1)\n#       validation_data = test_generator,\n#       validation_steps=8)","b99e5ac9":"test_loss, test_acc = model.evaluate_generator(test_generator)\nprint(test_acc)\n","79e8ff79":"test_loss, test_acc = model.evaluate(test_generator)\nprint(test_acc)","77f8cabb":"  classes = model.predict(test_generator, batch_size=10)\n  print(classes[0])","852268cf":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n# Let's prepare a random input image from the training set.\n# horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n# human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n# img_path = random.choice(horse_img_files + human_img_files)\n\nimg_path = \"..\/input\/iehack1\/animals\/train\/panda\/panda_00019.jpg\"\n\nimg = load_img(img_path, target_size=(image_size,image_size,3))  # this is a PIL image\nx = img_to_array(img)  # Numpy array with shape (128, 128, 3)\nx = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 128, 128, 3)\n\n# Rescale by 1\/255\nx \/= 255\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers[1:]]\n\n# Now let's display our representations\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  if len(feature_map.shape) == 4:\n    # Just do this for the conv \/ maxpool layers, not the fully-connected layers\n    n_features = feature_map.shape[-1]  # number of features in feature map\n    # The feature map has shape (1, size, size, n_features)\n    size = feature_map.shape[1]\n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    for i in range(n_features):\n      # Postprocess the feature to make it visually palatable\n      x = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std()\n      x *= 64\n      x += 128\n      x = np.clip(x, 0, 255).astype('uint8')\n      # We'll tile each filter into this big horizontal grid\n      display_grid[:, i * size : (i + 1) * size] = x\n    # Display the grid\n    scale = 20. \/ n_features\n    plt.figure(figsize=(scale * n_features, scale))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","6424a154":"# my_submission_good = pd.DataFrame({'Data_file': np.squeeze(test_file_names), 'Class': np.squeeze(predictions)})\n# my_submission_good.to_csv('so_far_good.csv', index=False)\n# my_submission_good.head(10)","ad55e08d":"#loading the vgg16 model\nfrom keras.applications.vgg16 import VGG16\n# load model\nmodel = VGG16()\n# summarize the model\nmodel.summary()","bc5025c2":"#set the number of epochs\nepoch_number = 10\n\n# from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n# load model without classifier layers\nmodel = VGG16(include_top=False, input_shape=(image_size, image_size, 3))\n# mark loaded layers as not trainable\nfor layer in model.layers:\n    layer.trainable = False\n# remove the output layer\n# model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n# add new classifier layers\nflat1 = Flatten()(model.layers[-1].output)\nclass1 = Dense(1024, activation='relu')(flat1)\noutput = Dense(3, activation='softmax')(class1)\n# my_new_model.add(Dense(3, activation='softmax'))#3 classes\nmodel = Model(inputs=model.inputs, outputs=output)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n# model.fit_generator(\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=8,  \n      epochs=epoch_number,\n      verbose=1)","68685ba1":"test_loss, test_acc = model.evaluate_generator(test_generator)\nprint(test_acc)\n","efbe9ad5":"  classes = model.predict(test_generator, batch_size=10)\n  print(classes[0])","bb09cfe9":"predictions_transfer = np.argmax(classes, axis = 1)","e915202b":"predictions_transfer[0:5]","c08d0119":"type(predictions_transfer[278])","80a72d11":"test_generator.filenames[0:5]\n#This does not work if shuffle is True (default). \n#You will always get the filenames in the order they are first processed, \n#not neccesarily in the order they are returned from the generator\n#So set shuffle = False in test_generator","1687147c":"test_filenames = [name.split('\/')[1] for name in test_generator.filenames]\ntest_filenames[0:5]","d69bb697":"my_submission_good = pd.DataFrame({'Data_file': np.squeeze(test_filenames), 'Class': np.squeeze(predictions_transfer.astype(np.int))})\nmy_submission_good.to_csv('so_far_good_class_int.csv', index=False)\nmy_submission_good.head(10)","8c9e853e":"predictions_transfer_names = predictions_transfer\npredictions_transfer_names = np.char.replace(predictions_transfer_names.astype(np.str),'0','cat')\npredictions_transfer_names = np.char.replace(predictions_transfer_names.astype(np.str),'1','dog')\npredictions_transfer_names = np.char.replace(predictions_transfer_names.astype(np.str),'2','panda')\npredictions_transfer_names[0:10]","43fdc7eb":"my_submission_good = pd.DataFrame({'Data_file': np.squeeze(test_filenames), 'Class': np.squeeze(predictions_transfer_names.astype(np.str))})\nmy_submission_good.to_csv('so_far_good_class_name_string.csv', index=False)\nmy_submission_good.head(10)","acdfa692":"# ! cd .. && cd .. && ls \n# !ls","c8aeee7e":"# !jupyter nbconvert --to pdf \/kaggle\/working\/__notebook_source__.ipynb --output \/kaggle\/working\/output_pdf_version2.pdf","202fc5b9":"### Get the current version of notebook in pdf form","01fff59f":"# Using Simple neural network","627f948d":"## Submit Predictions","c80e642b":"### Observations:\n- Performance using transfer learning is much better<br>\n- The amount of data in this hackathon isn't sufficient to get high accuracy<br>\n- The model using transfer learning has higher start, higher slope(steeper rate of improvement) and the converged skill of the trained model is better than it otherwise would be(higher asymptote","226bdd0e":"Callback for kinda early stopping","1a4f51ed":"Let's pick a random image from the training set, and then generate a figure where each row is the output of a layer, and each image in the row is a specific filter in that output feature map.","f04fdc83":"## Using Transfer Learning","8dba18e7":"\n## Visualizing Intermediate Representations","87af3dc0":"## Evaluating and predicting","abc43fdb":"# Using conv nets","aabbc6c5":"### Using Image Data gen from here for prectictions etc:","2473a1dd":"## Alternative way to preprocess images using keras Imagedatagen","a5802019":"## Preprocessing the training and test images","42c3fc62":"### Submitting the best preditions made so far:\n","4919cd69":"Manually checking random predictions","50fe59a8":"## Importing libraries","75870b76":"Note:<br> Done using transfer learning and CNN. <br>Not sure about the file name and the prediction format<br><br>\nIn this prediction, <br> cat has class 0\n<br> dog has class 1\n<br> panda has class 2","b906cbc0":"These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. ","cfb86b61":"### Using VGG16 model","62a14071":"## Defining the model","3b7a0897":"### Submit predictions","cf1ba27a":"Submitting predictions by changing the format to string\n<br> and with class names","e2d5b691":"Shuffling the train and tet datas","b240d04a":"![image.png](attachment:image.png)"}}