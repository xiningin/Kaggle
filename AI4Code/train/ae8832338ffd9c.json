{"cell_type":{"de7437fe":"code","fb70bb53":"code","754d9156":"code","fe7bdee3":"code","9c6121c3":"code","e456ecf8":"code","f9ce0691":"code","237c88b6":"code","0f09b7fa":"code","dd174f06":"code","f9296b55":"code","30657069":"code","3598c180":"code","c821c335":"code","ed8c9f65":"code","bccdc0d6":"code","b3f33f5d":"code","4b5af049":"code","01d070f0":"code","7c61e7ee":"code","1a9b82c1":"code","8e5e6513":"code","21ba7eb5":"code","355e3da3":"code","7e1a6d8c":"code","ef76691c":"code","83ed8f79":"code","f1c62adc":"code","b177eb1f":"code","bc06649b":"code","7e9991ab":"code","b5435053":"code","08251717":"code","98f9f22e":"code","0a5a3146":"code","3b34c479":"code","5ead449c":"code","a26057b2":"code","2e24a7a4":"code","4b8aef0e":"code","28f04897":"code","b3c155cc":"code","656be0f0":"code","26b98ba8":"code","f86e910b":"code","26cf30ae":"code","3a313ff9":"code","c3607c31":"code","ec06501f":"code","adffa052":"code","f03bebe0":"code","d08e1315":"code","b419f08c":"code","bfaec8dd":"code","2a8354dd":"code","c3df0bc0":"code","2c01e83d":"code","b3534775":"code","b33b2388":"code","4818d5d8":"code","211c977b":"code","82b211c1":"code","f6453897":"code","31144b93":"code","931ce327":"code","1b6e0fc8":"code","b3bd236d":"code","69ac5b26":"code","8906be07":"code","a11efa50":"code","e33868ee":"code","755e6fa8":"code","0dfb1530":"code","353858a9":"code","ffb93165":"code","83356bbb":"code","bb718126":"code","f58f46a3":"code","1a47e912":"code","fe5639d2":"code","a04c7e1a":"code","3b8860ec":"code","e29643f9":"code","48531601":"markdown","f458f0b7":"markdown","ff2e979f":"markdown","8de3a72e":"markdown","7902bb8f":"markdown","f6fb7f2c":"markdown","0b464234":"markdown","20a7f74f":"markdown","4321b459":"markdown","77a06802":"markdown","ad0328af":"markdown","0456f0b1":"markdown","53b22db1":"markdown","8a104bf9":"markdown","868df07e":"markdown","3cd56cfc":"markdown","f0fd20b7":"markdown","84e17ca6":"markdown","989211ef":"markdown","d0e1bce5":"markdown","887c4d03":"markdown","d77fefd7":"markdown","beb79b3b":"markdown","6511aa2c":"markdown","f2e430c9":"markdown","7125010f":"markdown","02cdc84d":"markdown","21c9f460":"markdown","c444fff6":"markdown","010b6d0c":"markdown","5e36cf42":"markdown","eb2f910a":"markdown","0d38de4f":"markdown","8350e91f":"markdown","7dad9580":"markdown","b12392c5":"markdown","06cf1111":"markdown","ca579fbb":"markdown","69ec84ab":"markdown","2d3c7b51":"markdown","e390e2c1":"markdown","3156c166":"markdown","b013ac73":"markdown","13b04907":"markdown","445e2393":"markdown","116b3808":"markdown","fcc7c48c":"markdown","1463ca80":"markdown","603644ea":"markdown","45733f12":"markdown","f4b2f543":"markdown","b12bc7a7":"markdown","479fe0e4":"markdown","d3f5084f":"markdown","ef6ec251":"markdown","f191cd18":"markdown","9cce73a7":"markdown","16c9a1c2":"markdown"},"source":{"de7437fe":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge","fb70bb53":"file=\"..\/input\/auto.csv\"\ndf = pd.read_csv(file, header=None)","754d9156":"# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)","fe7bdee3":"# create headers list\nheaders = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\nprint(\"headers\\n\", headers)","9c6121c3":"df.columns = headers\ndf.head(5)","e456ecf8":"#Data Types\ndf.dtypes","f9ce0691":"df.describe(include=\"all\")","237c88b6":"# replace \"?\" to NaN\ndf.replace(\"?\", np.nan, inplace = True)\ndf.head(5)","0f09b7fa":"#The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data\n#True indicates Missing Data\nmissing_data = df.isnull()\nmissing_data.head(10)","dd174f06":"for column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\") ","f9296b55":"avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\nprint(\"Average of normalized-losses:\", avg_norm_loss)","30657069":"avg_bore=df['bore'].astype('float').mean(axis=0)\nprint(\"Average of bore:\", avg_bore)","3598c180":"avg_stroke=df['stroke'].astype('float').mean(axis=0)\nprint(\"Average of stroke:\", avg_stroke)","c821c335":"avg_horsepower=df['horsepower'].astype('float').mean(axis=0)\nprint(\"Average of horsepower:\", avg_horsepower)","ed8c9f65":"avg_peak_rpm=df['peak-rpm'].astype('float').mean(axis=0)\nprint(\"Average of peak-rpm:\", avg_peak_rpm)","bccdc0d6":"df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)\ndf[\"bore\"].replace(np.nan, avg_bore, inplace=True)\ndf['stroke'].replace(np.nan,avg_stroke, inplace= True) \ndf['horsepower'].replace(np.nan, avg_horsepower, inplace=True)\ndf['peak-rpm'].replace(np.nan, avg_peak_rpm, inplace=True)\ndf.head()","b3f33f5d":"#We can see here that \"foor\" is the most frequent value of the \ndf['num-of-doors'].value_counts()","4b5af049":"#We replace the missing 'num-of-doors' values by \"foor\"\ndf[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)","01d070f0":"# simply drop whole row with NaN in \"price\" column\ndf.dropna(subset=[\"price\"], axis=0, inplace=True)\n\n# reset index, because we droped two rows\ndf.reset_index(drop=True, inplace=True)","7c61e7ee":"df.head()","1a9b82c1":"#Lets list the data types for each column\ndf.dtypes","8e5e6513":"df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\ndf[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\ndf[[\"price\"]] = df[[\"price\"]].astype(\"float\")\ndf[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\ndf[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)","21ba7eb5":"df.dtypes","355e3da3":"# replace (original value) by (original value)\/(maximum value)\ndf['length'] = df['length']\/df['length'].max()\ndf['width'] = df['width']\/df['width'].max()\ndf['height'] = df['height']\/df['height'].max()\ndf[[\"length\",\"width\",\"height\"]].head()","7e1a6d8c":"#Lets plot the histogram of horspower, to see what the distribution of horsepower looks like.\n%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\nplt.pyplot.hist(df[\"horsepower\"])\n\n# set x\/y labels and plot title\nplt.pyplot.xlabel(\"horsepower\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"horsepower bins\")\n","ef76691c":"bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\nbins","83ed8f79":"#We set group names:\ngroup_names = ['Low', 'Medium', 'High']","f1c62adc":"# We apply the function \"cut\" to determine what each value of \"df['horsepower']\" belongs to\ndf['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\ndf[['horsepower','horsepower-binned']].head(20)","b177eb1f":"# number of vehicles in each bin\ndf[\"horsepower-binned\"].value_counts()","bc06649b":"#distribution of each bin\n%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\npyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n\n# set x\/y labels and plot title\nplt.pyplot.xlabel(\"horsepower\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"horsepower bins\")","7e9991ab":"dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\ndummy_variable_1.head()","b5435053":"#change column names for clarity\ndummy_variable_1.rename(columns={'fuel-type-diesel':'diesel', 'fuel-type-diesel':'gas'}, inplace=True)\ndummy_variable_1.head()","08251717":"dummy_variable_2 = pd.get_dummies(df[\"aspiration\"])\ndummy_variable_2.head()","98f9f22e":"# merge data frame \"df\" and \"dummy_variable_1\" \ndf = pd.concat([df, dummy_variable_1], axis=1)\ndf = pd.concat([df, dummy_variable_2], axis=1)\ndf.head()","0a5a3146":"df.corr()","3b34c479":"#Let's find the scatterplot of \"engine-size\" and \"price\"\n# Engine size as potential predictor variable of price\nsns.regplot(x=\"engine-size\", y=\"price\", data=df)","5ead449c":"sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)","a26057b2":"sns.regplot(x=\"peak-rpm\", y=\"price\", data=df)","2e24a7a4":"#Let's look at the relationship between \"body-style\" and \"price\"\nsns.boxplot(x=\"body-style\", y=\"price\", data=df)","4b8aef0e":"sns.boxplot(x=\"engine-location\", y=\"price\", data=df)","28f04897":"sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)","b3c155cc":"df.describe()","656be0f0":"df.describe(include=['object'])","26b98ba8":"from sklearn.linear_model import LinearRegression","f86e910b":"#Create the linear regression object\nlm = LinearRegression()\nlm","26cf30ae":"#we will create a linear function with \"highway-mpg\" as the predictor variable and the \"price\" as the response variable\nX = df[['highway-mpg']]\nY = df['price']","3a313ff9":"#Fit the linear model using highway-mpg.\nlm.fit(X,Y)","c3607c31":"#We can output a prediction\ny_pred=lm.predict(X)\ny_pred[0:5]","ec06501f":"#the value of the intercept (a)\nlm.intercept_","adffa052":"#the value of the Slope (b)\nlm.coef_","f03bebe0":"#Let's develop a model using these variables as the predictor variables\nZ = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\nlm.fit(Z, df['price'])","d08e1315":"# the value of the intercept(a)\nlm.intercept_\n","b419f08c":"#the values of the coefficients (b1, b2, b3, b4)\nlm.coef_","bfaec8dd":"sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)","2a8354dd":"#First lets make a prediction\nY_pred = lm.predict(Z)","c3df0bc0":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n\nplt.title('Actual vs Fitted Values for Price')\nplt.xlabel('Price (in dollars)')\nplt.ylabel('Proportion of Cars')\n\nplt.show()\nplt.close()","2c01e83d":"#We will use the following function to plot the data:\n\ndef PlotPolly(model, independent_variable, dependent_variabble, Name):\n    x_new = np.linspace(15, 55, 100)\n    y_new = model(x_new)\n\n    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n    ax = plt.gca()\n    ax.set_facecolor((0.898, 0.898, 0.898))\n    fig = plt.gcf()\n    plt.xlabel(Name)\n    plt.ylabel('Price of Cars')\n\n    plt.show()\n    plt.close()","b3534775":"x = df['highway-mpg']\ny = df['price']","b33b2388":"# Here we use a polynomial of the 3rd order (cubic) \nf = np.polyfit(x, y, 3)\np = np.poly1d(f)\nprint(p)","4818d5d8":"PlotPolly(p, x, y, 'highway-mpg')","211c977b":"#highway_mpg_fit\nlm.fit(X, Y)\n# Find the R^2\nprint('The R-square is: ', lm.score(X, Y))","82b211c1":"from sklearn.metrics import mean_squared_error\nYhat=lm.predict(X)\nprint('The output of the first four predicted value is: ', Yhat[0:4])\n","f6453897":"mse = mean_squared_error(df['price'], Yhat)\nprint('The mean square error of price and predicted value is: ', mse)","31144b93":"# fit the model \nlm.fit(Z, df['price'])\n# Find the R^2\nprint('The R-square is: ', lm.score(Z, df['price']))","931ce327":"Y_predict_multifit = lm.predict(Z)\nprint('The mean square error of price and predicted value using multifit is: ', \\\n      mean_squared_error(df['price'], Y_predict_multifit))","1b6e0fc8":"from sklearn.metrics import r2_score\nr_squared = r2_score(y, p(x))\nprint('The R-square value is: ', r_squared)","b3bd236d":"print('The mean squared error value is: ',mean_squared_error(df['price'], p(x)))","69ac5b26":"#First lets only use numeric data\ndf=df._get_numeric_data()\ndf.head()","8906be07":"y_data = df['price']\nx_data=df.drop('price',axis=1)","a11efa50":"from sklearn.model_selection import train_test_split\n\n\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)\n\n\nprint(\"number of test samples :\", x_test.shape[0])\nprint(\"number of training samples:\",x_train.shape[0])\n","e33868ee":"lr = LinearRegression()\nlr.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)","755e6fa8":"#Prediction using training data:\nyhat_train = lr.predict(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\nyhat_train[0:5]","0dfb1530":"#Prediction using test data:\nyhat_test = lr.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\nyhat_test[0:5]","353858a9":"def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 12\n    height = 10\n    plt.figure(figsize=(width, height))\n\n    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n\n    plt.title(Title)\n    plt.xlabel('Price (in dollars)')\n    plt.ylabel('Proportion of Cars')\n\n    plt.show()\n    plt.close()","ffb93165":"Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\nDistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)","83356bbb":"Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\nDistributionPlot(y_test,yhat_test,\"Actual Values (Test)\",\"Predicted Values (Test)\",Title)","bb718126":"from sklearn.model_selection import GridSearchCV","f58f46a3":"parameters1= [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]\nparameters1","1a47e912":"RR=Ridge()\nRR","fe5639d2":"Grid1 = GridSearchCV(RR, parameters1,cv=4)","a04c7e1a":"Grid1.fit(x_data[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_data)","3b8860ec":"BestRR=Grid1.best_estimator_\nBestRR","e29643f9":"BestRR.score(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_test)","48531601":"**How to work with missing data?**\n\nSteps for working with missing data:\n\n1. Identify missing data\n2. deal with missing data\n3. correct data format","f458f0b7":"As the highway-mpg goes up, the price goes down: this indicates an inverse\/negative relationship between these two variables. Highway mpg could potentially be a predictor of price.\nWe can examine the correlation between 'highway-mpg' and 'price' and see it's approximately -0.704","ff2e979f":"**Identify missing values**\n\n\nConvert \"?\" to NaN\nIn the car dataset, missing data comes with the question mark \"?\". We replace \"?\" with NaN (Not a Number), which is Python's default missing value marker, for reasons of computational speed and convenience","8de3a72e":"\n\nNow, we finally obtain the cleaned dataset with no missing values and all data in its proper format.","7902bb8f":"**Grid Search**","f6fb7f2c":"**Model 2: Multiple Linear Regression**","0b464234":"**Replace \"NaN\" by mean value in \"normalized-losses\",\"bore\",\"stroke\",\"horsepower\" and \"peak-rpm\" columns**","20a7f74f":"**Add Headers**\n\nPandas automatically set the header by an integer from 0.\nTo better describe our data we can introduce a header\nThus, we have to add headers manually.","4321b459":"**Analyzing Individual Feature Patterns using Visualization**","77a06802":"We can see that the fitted values are reasonably close to the actual values","ad0328af":"We see that the distributions of price between the different body-style categories have a significant overlap, and so body-style would not be a good predictor of price.\nLet's examine engine \"engine-location\" and \"price\":","0456f0b1":"As the engine-size goes up, the price goes up: this indicates a positive direct correlation between these two variables. Engine size seems like a pretty good predictor of price since the regression line is almost a perfect diagonal line.\nWe can examine the correlation between 'engine-size' and 'price' and see it's approximately 0.87","53b22db1":"**Indicator variable (or dummy variable)**","8a104bf9":"** Measures for In-Sample Evaluation**","868df07e":"**Strategy**\n\n**Replace by mean:**\n\n\"normalized-losses\": 41 missing data, replace them with mean\n\n\"stroke\": 4 missing data, replace them with mean\n\n\"bore\": 4 missing data, replace them with mean\n\n\"horsepower\": 2 missing data, replace them with mean\n\n\"peak-rpm\": 2 missing data, replace them with mean\n\n***Replace by frequency:***\n\n\"num-of-doors\":  2 missing data, replace them with \"four\".\n\nReason:Since four doors is most frequent, it is most likely to occur.\n\n***Drop the whole row:***\n\n\"price\": 4 missing data, simply delete the whole row\n\nReason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us\n\n","3cd56cfc":"**Model Evaluation and Refinement**","f0fd20b7":"***Conclusion:***\n\nComparing these three models, we conclude that the MLR model is the best model to be able to predict price from our dataset. This result makes sense, since we have 27 variables in total, and we know that more than one of those variables are potential predictors of the final car price.","84e17ca6":"**Multiple Linear Regression**","989211ef":"We build a bin array, with a minimum value to a maximum value, with bandwidth calculated above. The bins will be values used to determine when one bin ends and another begins.","d0e1bce5":"Simple Linear Regression. \n","887c4d03":"**Based on the summary above, each column has 205 rows of data, seven columns containing missing data:**\n1. \"normalized-losses\" : 41 missing data\n2. \"num-of-doors\" : 2 missing data\n3. \"bore\" : 4 missing data\n4. \"stroke\" : 4 missing data\n5. \"horsepower\" : 2 missing data\n6. \"peak-rpm\" : 2 missing data\n7. \"price\" : 4 missing data","d77fefd7":"Here we see that the distribution of price between these two engine-location categories, front and rear, are distinct enough to take engine-location as a potential good predictor of price.\n\nLet's examine \"drive-wheels\" and \"price\".","beb79b3b":"Highway mpg is a potential predictor variable of price","6511aa2c":"**Categorical variables**\n\nThese are variables that describe a 'characteristic' of a data unit, and are selected from a small group of categories. The categorical variables can have the type \"object\" or \"int64\". A good way to visualize categorical variables is by using boxplots.","f2e430c9":"**Dealing with MISSING Data**\n\n***1. drop data***\n\na. drop the whole row: Whole columns should be dropped only if most entries in the column are empty. In our dataset, none of the columns are empty enough to drop entirely.\n\nb. drop the whole column\n\n***2. replace data***\n\na. replace it by mean\n\nb. replace it by frequency\n\nc. replace it based on other functions","7125010f":"An indicator variable (or dummy variable) is a numerical variable used to label categories. \nWe can use categorical variables for regression analysis in the later modules.\nWe see the column \"fuel-type\" has two unique values, \"gas\" or \"diesel\". Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"fuel-type\" into indicator variables.\nWe will use the panda's method 'get_dummies' to assign numerical values to different categories of fuel type.","02cdc84d":"**Decision Making: Determining a Good Model Fit**","21c9f460":"Let's take a look at the values for the different models.\n\n**Simple Linear Regression: Using Highway-mpg as a Predictor Variable of Price.**\n\n**R-squared:** 0.49659118843391759\n**MSE:** 3.16 x10^7\n\n**Multiple Linear Regression: Using Horsepower, Curb-weight, Engine-size, and Highway-mpg as Predictor Variables of Price.**\n\n**R-squared:** 0.8093732522175299\n**MSE:** 1.2 x10^7\n\n**Polynomial Fit: Using Highway-mpg as a Predictor Variable of Price.**\n\n**R-squared:** 0.674194666390652\n**MSE:** 2.05 x 10^7","c444fff6":"we want to use more variables in our model to predict car price\nFrom the previous section we know that other good predictors of price could be:\n* Horsepower\n* Curb-weight\n* Engine-size\n* Highway-mpg","010b6d0c":"Let's see if \"Peak-rpm\" as a predictor variable of \"price\".","5e36cf42":"**The linear function we get in this example:**\n\nPrice = -15811.863767729243 +53.53022809x horsepower + 4.70805253 x curb-weight + 81.51280006 x engine-size + 36.1593925 x highway-mpg","eb2f910a":"We successfully narrow the intervals from 57 to 3!","0d38de4f":"Now that we have visualized the different models, and generated the R-squared and MSE values for the fits, how do we determine a good model fit?\n\n1. What is a good R-squared value?\nWhen comparing models, **the model with the higher R-squared value is a better fit for the data.**\n\nWhat is a good MSE?\nWhen comparing models, **the model with the smallest MSE value is a better fit for the data.**","8350e91f":"One way to look at the fit of the model is by looking at the distribution plot: We can look at the distribution of the fitted values that result from the model and compare it to the distribution of the actual values.","7dad9580":"We can already see from plotting that this polynomial model performs better than the linear model. This is because the generated polynomial function \"hits\" more of the data points.","b12392c5":"Here we see that the distribution of price between the different drive-wheels categories differs; as such drive-wheels could potentially be a predictor of price.","06cf1111":"**Data Normalization**","ca579fbb":"** Descriptive Statistical Analysis**","69ec84ab":"**The final estimated linear model we get**\n\n**price**=38423.305858157386-821.73337832***highway-mpg**\n","2d3c7b51":"**Polynomial Regression**\n\nPolynomial regression is a particular case of the general linear regression model or multiple linear regression models.","e390e2c1":"**Calculate the average of the column**","3156c166":"**Linear Regression and Multiple Linear Regression**","b013ac73":"**Convert data types to proper format**","13b04907":"Normalization is the process of transforming values of several variables into a similar range\n\nlet's say we want to scale the columns \"length\", \"width\" and \"height\"\n","445e2393":"**Model Evaluation using Visualization**\n\nRegression Plot\nWhen it comes to simple linear regression, an excellent way to visualize the fit of our model is by using regression plots.\nLet's visualize Horsepower as potential predictor variable of price:","116b3808":"**Binning**\n\n**Why binning?**\nBinning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis.\n\nIn our dataset, \"horsepower\" is a real valued variable ranging from 48 to 288, it has 57 unique values. What if we only care about the price difference between cars with high horsepower, medium horsepower, and little horsepower (3 types)? \nCan we rearrange them into three \u2018bins' to simplify analysis?\n\nWe will use the Pandas method 'cut' to segment the 'horsepower' column into 3 bins","fcc7c48c":"**Evaluation of Multiple Linear Regression**","1463ca80":"Peak rpm does not seem like a good predictor of the price at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore it's it is not a reliable variable.\nWe can examine the correlation between 'peak-rpm' and 'price' and see it's approximately -0.101616","603644ea":"We replace headers and recheck our data frame","45733f12":"**Count missing values in each column**","f4b2f543":"Finally, let's drop all rows that do not have price data:","b12bc7a7":"We will use  a quantitative measure to determine how accurate the model is.\n\nTwo very important measures that are often used in Statistics to determine the accuracy of a model are:\n\n* R^2 (R-squared): known as the coefficient of determination\n\nIs a measure to indicate how close the data is to the fitted regression line.\n\nThe value of the R-squared is the percentage of variation of the response variable (y) that is explained by a linear model.\n\n* Mean Squared Error (MSE)\n\nThe Mean Squared Error measures the average of the squares of errors, that is, the difference between actual value (y) and the estimated value (\u0177).\n","479fe0e4":"**replace the missing 'num-of-doors' values by the most frequent **","d3f5084f":"**Now, we obtain the dataset with no missing values.\nThe last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).**","ef6ec251":"**Evaluating for Missing Data**","f191cd18":"**Model 3: Polynomial Fit**","9cce73a7":"**Model 1: Simple Linear Regression**","16c9a1c2":"**Continuous numerical variables:**\n\nContinuous numerical variables are variables that may contain any value within some range. Continuous numerical variables can have the type \"int64\" or \"float64\". A great way to visualize these variables is by using scatterplots with fitted lines.\n\nIn order to start understanding the (linear) relationship between an individual variable and the price. We can do this by using \"regplot\", which plots the scatterplot plus the fitted regression line for the data.\n\nLet's see several examples of different linear relationships:"}}