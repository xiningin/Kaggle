{"cell_type":{"a963a6f5":"code","d65c8237":"code","5ca68659":"code","3c6b549a":"code","3b92fbc2":"code","8e4b328b":"code","058716ed":"code","1dea0cbc":"code","16a6f4ba":"code","b4dce892":"code","410f45f9":"code","d541d939":"code","922520b5":"code","9d85f627":"code","ffdf5ddf":"code","ff978361":"code","53b4c9b3":"code","e188fed1":"code","4c50fb7f":"code","4dbacd07":"code","fed6ebb2":"code","137171d1":"markdown"},"source":{"a963a6f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport nltk\nimport nltk.corpus\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d65c8237":"sample_submission = pd.read_csv(\"\/kaggle\/input\/kaggledaysariana\/Sample_Submission_kaggle.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/kaggledaysariana\/test.csv\")\ndf = pd.read_csv(\"\/kaggle\/input\/kaggledaysariana\/train.csv\")\ndf1=df[0:2000]","5ca68659":"df1.head()","3c6b549a":"df1.country.unique()","3b92fbc2":"most_freq= [x for x in df1.country.value_counts().sort_values(ascending=False).head(10).index]\nmost_freq","8e4b328b":"#for c in most_freq:\n    #df[c]=np.where(df[\"country\"]==c,1,0)\n#df[[\"country\"]+most_freq].head(40) ","058716ed":"#df.drop([\"country\"],axis=1)","1dea0cbc":"def one_hot_mostfreq(data,variable,mostfreq):\n    for c in mostfreq:\n        data[variable +\"_\" +c]=np.where(data[variable]== c , 1,0)\n #reread the data\ndf=pd.read_csv(\"\/kaggle\/input\/kaggledaysariana\/train.csv\")\none_hot_mostfreq(df,\"country\",most_freq)\ndf.head(20)\n\n#usecols=[\"description\",\"country\",\"points\",\"price\",\"province\",\"designation\",\"region_1\",\"region_2\",\"taster_name\",\"taster_twitter_handle\",\"title\"])\n\n        \n        ","16a6f4ba":"most_freq= [x for x in df.province.value_counts().sort_values(ascending=False).head(10).index]\none_hot_mostfreq(df,\"province\",most_freq)\ndf.head(10)","b4dce892":"df=df.drop([\"country\",\"province\"],axis=1)\ndf.head(20)\n","410f45f9":"desc =df1[\"description\"]\ndesc","d541d939":"liste=[]\nfor c in desc:\n    li= word_tokenize(c)\n    liste.append(np.char.lower(li))\nliste","922520b5":"#filtered_sentence = [w for w in liste if not w in stop_words]\nstop_words = set(stopwords.words('english'))\nfiltered_sentence = []\nfor w in liste:\n    lis=[]\n    for item in w:\n        if item not in stop_words:\n            lis.append(item)\n    filtered_sentence.append(lis)\n              \nfiltered_sentence\n  \n","9d85f627":"symbols = \"!,.;\\\"#$%&()*+-\/,:;<=>?@'[\\]^_`{|}~\\n\"\nfor c in symbols:\n    for w in filtered_sentence:\n        if c in w:\n            w.remove(c)\nfiltered_sentence\n        ","ffdf5ddf":"for w in filtered_sentence:\n    for i in w:\n        if len(i)==1:\n            w.remove(i)\nfiltered_sentence\n        ","ff978361":"from nltk.stem import PorterStemmer\nfrom nltk.stem import LancasterStemmer\nporter = PorterStemmer()\nsteemed_lis=[]\nfor w in filtered_sentence:\n    li=[]\n    for i in w:\n        word=porter.stem(i)\n        li.append(word)\n    steemed_lis.append(li)\n        \nsteemed_lis        \n      \n        ","53b4c9b3":"from nltk.stem import PorterStemmer\nfrom nltk.stem import LancasterStemmer\nporter = PorterStemmer()\nsteemed_lis=[]\nfor w in filtered_sentence:\n    li=[]\n    for i in w:\n        word=porter.stem(i)\n        li.append(word)\n    steemed_lis.append(li)\n        \nsteemed_lis        \n      \n        ","e188fed1":"\n#from num2words import num2words \n#for i in steemed_lis :\n   # steemed_lis=num2words(i)\n#steemed_lis    ","4c50fb7f":"DF = {}\nfor w in steemed_lis:\n    li=[]\n    for i in range(len(w)):\n        tokens = steemed_lis[i]\n        for x in tokens:\n            try:\n                DF[x].add(i)\n            except:\n                DF[x] = {i}","4dbacd07":"for i in DF:\n    DF[i]=len(DF[i])\nDF    \n    ","fed6ebb2":"#ps = PorterStemmer()\n\n#vectors=[]\n#vectorizer = TfidfVectorizer()\n#for c in liste:\n    #vectors.append(vectorizer.fit_transform(c))\n    #feature_names = vectorizer.get_feature_names()\n    #dense = vectors.todense()\n    #denselist = dense.tolist()\n#dataf = pd.DataFrame(denselist, columns=feature_names)","137171d1":"*df.country.value_counts().sort_values(ascending=False).head(20)*"}}