{"cell_type":{"1027ec1d":"code","8c5cdbde":"code","5499786d":"code","0bfb5371":"code","39bb5c28":"code","5b20fe48":"code","c7a65cc3":"code","f49ffd61":"code","ec52285a":"code","4bc604ad":"code","a42305c0":"code","a7ee2e49":"code","0134602a":"code","9fd59c09":"code","588603f5":"code","953bf023":"code","dc95ef35":"code","d0da2547":"code","cd9b8cff":"code","5067fb78":"markdown","f205e603":"markdown","939aeaff":"markdown","240ab9a0":"markdown","2691684d":"markdown","beae989e":"markdown","6f1cc040":"markdown","56dd3b16":"markdown","61e42688":"markdown"},"source":{"1027ec1d":"# Importing Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","8c5cdbde":"# Importing Data Sets\ndataset = pd.read_csv('..\/input\/data-for-data-preprocessing\/Data.csv')\nX = dataset.iloc[:, :-1].values #iloc function helps to locate indexes and by using that function we will extract our independent variables(Features) with their respective rows.\ny = dataset.iloc[:, -1].values #Dependent Variables","5499786d":"print(X)","0bfb5371":"print(y)","39bb5c28":"dataset.head()","5b20fe48":"# Now we are going to handle missing data in Data Set.\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n# In upper line of code we have replaced all missing values that\n# are appearing in data set by mean values of column containing\n# Null values\nimputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])","c7a65cc3":"print(X)","f49ffd61":"# Now we are going to encode Categorical Data\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n# In mentioned code we have transform Categorical values into Binary valuses as we have 3 distinct \n#countries so we gave a binary value to each country","ec52285a":"print(X)","4bc604ad":"# Now we are going to encode (Give Binary values) to our Dependent Variable\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit_transform(y)\ny = le.fit_transform(y)","a42305c0":"print(y)","a7ee2e49":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","0134602a":"print(X_train)","9fd59c09":"print(X_test)\n","588603f5":"print(y_train)","953bf023":"print(y_test)","dc95ef35":"# Now we are going to do Feature Scaling\n# We donot need to apply FS on the column that we have created for the Country names using (OneHotEncoding & LabelEncoding) it will have no impact on data and it is not a good practise.\n# We will apply Feature Scaling on Age and Salary columns\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n\n# Please note that we have to apply the same scaler on test set as we have applied on training set.\n# You can see that Fit_Transform is used to scale the values of training set.\n# and for test set we only use transform, we did not use fit_transform because we have to apply same scaler on test set.","d0da2547":"print(X_train)","cd9b8cff":"print(X_test)","5067fb78":"So, that concludes the basics of Data Preprocessing. Please feel free to add in case i missed something and correct me if there is any mistake.","f205e603":"**Encoding Categorical Data:**\nAs we can see that dataset contains one column named as Country that have descriptive values. With descriptive values,\nit will be difficult for ML Model to compute some coorelations between features, for avoiding that situation you should have to convert those descriptive values into binary values.\nThe process of converting descriptive values into binary values is called **OneHotEncoding**.\nWe are going to replace this country column with 3 new columns which will have **OneHotEncoding** values for all 3 Descriptive values **(France, Spain, Germany)** that are appearing in Country column.\nWe will also going to convert descriptive values **(YES, NO)** in Dependent Variable into Binary Values. it is okay for ML Model to have binary outcome.","939aeaff":"The Dataset we have here belongs to a Retail company that collect data from their customers which represents, weather or not they purchasecertian products. Each of the row have different customer with their Age, Salary & Purchased **(NO: Not Purchased, YES: Purchased)**.","240ab9a0":"As you can see in the data that there are missing values. Generally you should not have any missing values in data for a sinmple reason, it will cause error in ML model therefore you must hanndle missing values in data.\nThere are multiple ways to handle missing values in data. One of them is that you should remove\/drop rows that contains missing values\nbut this technique is more suitable when you have large amount of data and the ratio of missing values is not more than 1% but in our current scenario, dataset is limited, so we are going to handle missing values by taking average of values appearing in a column that has missing value.\nTo do this we are going to use SimpleImputer function of SickitLearn Library.","2691684d":"**Feature Scaling:**\nWhy we apply Feature Scaling?\nFeature scaling will allow to put all our features on the same scale. Why we do this?. \nWell thats because for some of the Machine Learning models thats in order to avoid some features to be dominated by other \nfeatures in such a way that the dominated features are not even considered by some Machine Learning models.\nNow you also need to be aware that we wont have to apply feature scaling for all the Machine Learning Models \nbut just for some of them.\n\nPlease note that, we have to apply feature scaling after the split of data set into Test set and Training Set.\nThe reason behind that is, the Test Set is basically a brand new set\nthat we are going to use in model after training Data using Training Set\nand in Feature Scaling we have to calculate the mean, Variance, & Standard Deviation\nand if we apply feature scaling before spliting data set\nit will give us the values of calculations by applying on compelete\nData Set. But we only need that for Training Set. It will cause Information Leakage if we use all data for feature scaling.","beae989e":"Now we have handeled Missing values as well as converted descriptive data into binary values. Now we are going to split the data into Training and Test set.\nWe will give 80% data to Training Set and 20% data to Test Set and to make sure we have a same random factor we will assign random_state=1","6f1cc040":"As discussed earlier, we have to encode Dependent Variable as well and for that we are going to use different class named as **LabelEncoder**\nwhich is used to assign binary values to Target Variable.","56dd3b16":"Importing the Dataset.\nWe are going to use read_csv function to read dataset and load that\ndata into DataFrame. After loading dataset we have to add new entities\n1: Matrix of features 2: The Dependent Variable Vector.\n**Features:** are the columns with which you are going to predict the Dependent Variable.\n**Dependend Variable:** Is basically our Target Variable that we have to predict using Features.","61e42688":"Importing the Libraries.\nWe are going to import  libraries numpy, matplotlib and pandas."}}