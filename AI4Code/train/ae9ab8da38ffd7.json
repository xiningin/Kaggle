{"cell_type":{"b6ee9f14":"code","3ba76143":"code","38351981":"code","ce018be9":"code","97b59cd4":"code","31db69aa":"code","cae55f9c":"code","8d290c04":"code","adb97ffa":"code","142ed981":"code","73813177":"code","a4afa46b":"code","fcc96801":"code","02a67375":"code","be20b803":"code","5577f25a":"code","f4dffd19":"code","7211b778":"code","040f15bb":"code","376d2312":"code","7ed2bcc1":"code","14169816":"code","3a74b884":"code","16ccca54":"code","db8704ce":"code","46973983":"code","8467730d":"code","6234bf8c":"code","6ba50c25":"code","15423150":"markdown","671f9a16":"markdown","2c5b7032":"markdown","b314980a":"markdown","0ee20f80":"markdown","f3e9d3e4":"markdown","f76fe988":"markdown"},"source":{"b6ee9f14":"import os\nimport numpy as np","3ba76143":"# loiding the training data\ncats_path = os.listdir(\"..\/input\/dogs-cats-images\/dataset\/training_set\/cats\/\")\ndogs_path = os.listdir(\"..\/input\/dogs-cats-images\/dataset\/training_set\/dogs\/\")\ncats_full_path = [\"..\/input\/dogs-cats-images\/dataset\/training_set\/cats\/\" + fname for fname in cats_path]\ndogs_full_path = [\"..\/input\/dogs-cats-images\/dataset\/training_set\/dogs\/\" + fname for fname in dogs_path]\nX = cats_full_path + dogs_full_path\ncats_labels = [0]*len(cats_full_path)\ndogs_labels = [1]*len(dogs_full_path)\ny = cats_labels + dogs_labels","38351981":"from IPython.display import display, Image","ce018be9":"# showing an image example\nImage(cats_full_path[7])","97b59cd4":"len(X), len(y)","31db69aa":"from sklearn.model_selection import train_test_split\n\n# creating a validation set from train set\nX_train, X_val, y_train, y_val = train_test_split(X,\n                                                  y, \n                                                  test_size=0.2,\n                                                  random_state=42, shuffle=True, stratify=y)","cae55f9c":"import tensorflow as tf","8d290c04":"# Check GPU \nprint(\"GPU available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\");","adb97ffa":"# image size\nIMG_SIZE = 200\n\ndef process_image(image_path):\n    \"\"\"\n    Convert an image file path and turns it into a Tensor.\n    \"\"\"\n    # Read an image from path\n    image = tf.io.read_file(image_path)\n    # Decode the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n    image = tf.image.decode_jpeg(image, channels=3)\n    # Convert the colour channel values from 0-225 to 0-1 values\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to our desired size IMG_SIZE\n    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n    return image","142ed981":"# function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n    \"\"\"\n    Takes an image file path name and the associated label,\n    processes the image and returns a tuple of (image, label).\n    \"\"\"\n    image = process_image(image_path)\n    return image, label","73813177":"# batch size of 32 is a good default\nBATCH_SIZE = 32\n\n# function to turn data into batches\ndef create_data_batches(x, y, batch_size=BATCH_SIZE):\n    \"\"\"\n    Creates batches of data out of image (x) and label (y) pairs.\n    \"\"\"\n    print(\"Creating data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels  \n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n    return data_batch","a4afa46b":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val)","fcc96801":"# function which builds our model\ndef create_model():\n    # building the model\n    model = tf.keras.models.Sequential([\n    # building our CNN \n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 'Cat' and 1 for 'Dog' \n    tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        loss=tf.keras.losses.binary_crossentropy,\n        optimizer=tf.keras.optimizers.Adam(), \n        metrics='accuracy'\n    )\n    \n    return model","02a67375":"# Creating our model \nmodel = create_model()\nmodel.summary()","be20b803":"# Create early stopping (callback function) (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) # stops after 3 rounds of no improvements","5577f25a":"# number of epochs\nNUM_EPOCHS = 20","f4dffd19":"# function to train and return a trained model\ndef train_model():\n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n    # Create a model\n    model = create_model()\n\n    history = model.fit(\n        train_data,\n        epochs=NUM_EPOCHS,\n        validation_data=val_data,\n        callbacks= [early_stopping])\n  \n    return model, history","7211b778":"# Fit the model to the data\nmodel, history = train_model()","040f15bb":"# model accuracy\ntest_data = create_data_batches(X_val, y_val)\nmodel.evaluate(test_data)","376d2312":"import matplotlib.pyplot as plt","7ed2bcc1":"# Accuracy Evaluation\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.xlabel('Number Of Epochs')\nplt.ylabel('Accuracy %')\nplt.title('Accuracy Evaluation')\nplt.legend()\nplt.show()","14169816":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss Evaluation')\nplt.ylabel('Loss %')\nplt.xlabel('Number Of Epochs')\nplt.legend(['Train Loss', 'Val Loss'], loc='lower left')\nplt.show()","3a74b884":"# Make predictions on the validation data (not used to train on)\npredictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\n# Check the shape of predictions\npredictions.shape","16ccca54":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(pred_probs):\n    \"\"\"\n    Turns an array of prediction probabilities into a label.\n    \"\"\"\n    return 0 if pred_probs<.5 else 1\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","db8704ce":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n    \"\"\"\n    Takes a batched dataset of (image, label) Tensors and returns separate arrays\n    of images and labels.\n    \"\"\"\n    images = []\n    labels = []\n    # Loop through unbatched data\n    for image, label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labels.append(label)\n    return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","46973983":"def plot_pred(pred_probs, labels, images):\n    \"\"\"\n    View the prediction, ground truth label and image for a random sample n.\n    \"\"\"\n    n = np.random.randint(0,len(images))    \n    pred_prob, true_label, image = pred_probs[n], labels[n], images[n]\n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n  \n    # Plot image & remove ticks\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n    # Change the color of the title depending on if the prediction is right or wrong\n    if pred_label == true_label:\n        color = \"green\"\n    else:\n        color = \"red\"\n\n    plt.title(\"pred=> {} with prob= {:2.0f}% : label= ({})\".format(pred_label,\n                                      pred_prob[0]*100,\n                                      true_label),\n                                      color=color)","8467730d":"# View an example prediction, original image and truth label\nplot_pred(pred_probs=predictions,\n          labels=val_labels,\n          images=val_images)","6234bf8c":"# loiding the test data\ntest_cats_path = os.listdir(\"..\/input\/dogs-cats-images\/dataset\/test_set\/cats\/\")\ntest_dogs_path = os.listdir(\"..\/input\/dogs-cats-images\/dataset\/test_set\/dogs\/\")\ntest_cats_full_path = [\"..\/input\/dogs-cats-images\/dataset\/test_set\/cats\/\" + fname for fname in cats_path]\ntest_dogs_full_path = [\"..\/input\/dogs-cats-images\/dataset\/test_set\/dogs\/\" + fname for fname in dogs_path]\n# creating test feature\nX_test = cats_full_path + dogs_full_path\ntest_cats_labels = [0]*len(cats_full_path)\ntest_dogs_labels = [1]*len(dogs_full_path)\n# creating test label\ny_test = test_cats_labels + test_dogs_labels","6ba50c25":"# Create test\ntest_data = create_data_batches(X_test, y_test)\nmodel.evaluate(test_data)","15423150":"## Spliting the Data ","671f9a16":"## Evaluating model accuracy ","2c5b7032":"## Visualizing the predections","b314980a":"## Convert images to tensors\n","0ee20f80":"## Evaluating model loss ","f3e9d3e4":"# Evaluating The Test Data","f76fe988":"## Training Set"}}