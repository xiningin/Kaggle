{"cell_type":{"310f0345":"code","a0f37aa3":"code","bdb4ffaf":"code","b472eea2":"code","b2c8bf53":"code","738e56ea":"code","ac7f9323":"code","75ee4c61":"code","9fd34f9f":"code","58868268":"code","927f0f25":"code","a40a228e":"code","99b2a1e2":"code","27f70be4":"code","39045046":"code","e49aa0c7":"code","7826c299":"code","f15c8dfa":"code","99764bb2":"code","ff0d4a2c":"code","a11c18f7":"code","26cdf77c":"code","6d4d2f77":"code","adeb4e36":"code","7e2c60fa":"code","d2509893":"code","4f128b84":"code","5f47b6b0":"code","f8393750":"code","54cdbf17":"code","37502511":"code","97a9d864":"code","1a1b7ce3":"code","a67a513a":"code","4ed5d53c":"code","566039ff":"code","35605ecd":"code","d8de4c96":"code","6b61142d":"code","5b23eba6":"code","a7566342":"code","b09a885c":"code","7dfc9779":"markdown","750ff2c9":"markdown","55741fd0":"markdown","2706fde1":"markdown","20c0c7d3":"markdown","4d72985f":"markdown","cd2bfb07":"markdown"},"source":{"310f0345":"from fastai.tabular.all import *\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fastai.callback import *\nfrom tqdm.notebook import tqdm\nfrom ml_stratifiers import MultilabelStratifiedKFold","a0f37aa3":"pd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 50)","bdb4ffaf":"path = Path('..\/input\/lish-moa')","b472eea2":"test_features = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntrain_features = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')","b2c8bf53":"train_features.head()","738e56ea":"train_targets_scored.head()","ac7f9323":"cols = train_targets_scored.columns.tolist()[1:]","75ee4c61":"train_features.sig_id.nunique()","9fd34f9f":"train_features.cp_type.value_counts()","58868268":"train_features.cp_time.value_counts()","927f0f25":"train_features.cp_dose.value_counts()","a40a228e":"train_targets_scored.sum()[1:].sort_values().head(10)","99b2a1e2":"train_targets_scored.sum()[1:].sort_values().tail(50)","27f70be4":"train_targets_scored.sum()[1:].sort_values().tail(50).index[-24:]","39045046":"trn_df = train_features.merge(train_targets_scored,on='sig_id',how='left')","e49aa0c7":"targets = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","7826c299":"def make_folds(folds = 5, random_state = 0, stratify = True, scored = None):\n    \n    drug = pd.read_csv('..\/input\/lish-moa\/train_drug.csv')\n    if scored is None:\n        scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\n    targets = scored.columns[1:]\n    scored = scored.merge(drug, on='sig_id', how='left')\n\n    # LOCATE DRUGS\n    vc = scored.drug_id.value_counts()\n    vc1 = vc.loc[vc<=18].index.sort_values()\n    vc2 = vc.loc[vc>18].index.sort_values()\n\n    # STRATIFY DRUGS 18 OR LESS\n    dct1 = {}; dct2 = {}\n    if stratify:\n        skf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=random_state)\n    else:\n        skf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n    tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n        dd = {k:fold for k in tmp.index[idxV].values}\n        dct1.update(dd)\n    \n    # STRATIFY DRUGS MORE THAN 18\n    if stratify:\n        skf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=random_state)\n    else:\n        skf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n    tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop=True)\n    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n        dd = {k:fold for k in tmp.sig_id[idxV].values}\n        dct2.update(dd)\n    \n    # ASSIGN FOLDS\n    scored['fold'] = np.nan\n    scored['fold'] = scored.drug_id.map(dct1)\n    scored.loc[scored.fold.isna(),'fold'] = scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n    scored.fold = scored.fold.astype('int8')\n    \n    return scored[['sig_id','fold']].copy()","f15c8dfa":"FOLDS = 10; SEED = 42\nff = make_folds(folds=FOLDS, random_state=SEED, stratify=True, scored=targets)\n\ntrn_df['kfold'] = ff.fold.values","99764bb2":"df = trn_df.copy()","ff0d4a2c":"df.head()","a11c18f7":"sig_ids = test_features[test_features['cp_type'] == 'ctl_vehicle']['sig_id'].values","26cdf77c":"len(cols)","6d4d2f77":"cat_names = ['cp_type', 'cp_time', 'cp_dose']\ncont_names = [c for c in train_features.columns if c not in cat_names and c != 'sig_id']","adeb4e36":"sig = lambda x : 100\/(1+np.exp(-x\/5))","7e2c60fa":"df[cont_names]  = sig(df[cont_names]) ","d2509893":"test_features[cont_names] = sig(test_features[cont_names])","4f128b84":"def get_data(fold):\n    \n    val_idx = df[df.kfold==fold].index\n    dls = TabularDataLoaders.from_df(df, path=path, y_names=cols,\n                                        cat_names = cat_names,\n                                        cont_names = cont_names,\n                                        procs = [Categorify, FillMissing, Normalize],\n                                        valid_idx=val_idx,\n                                        #y_block=MultiCategoryBlock(encoded=True,vocab=cols),\n                                        bs=64)\n    return dls\n    ","5f47b6b0":"test_sc = []\n\nfor i in tqdm(range(FOLDS)):\n    \n    dls = get_data(i) # Data\n    \n    learn = tabular_learner(dls , y_range=(0,1), layers=[1024, 512, 512, 256], loss_func = BCELossFlat(), model_dir='\/kaggle\/working\/') # Model\n    \n    name = 'best_model_' + str(i) \n    cb = SaveModelCallback(monitor='valid_loss',fname=name ,mode='min') # Callbacks\n    \n    lr = 9e-3\n    learn.fit_one_cycle(10, slice(lr\/(2.6**4),lr),cbs=cb) # Training\n    \n    learn.load(name) # Load best model\n    \n    test_dl = learn.dls.test_dl(test_features)\n    sub = learn.get_preds(dl=test_dl) # prediction\n    test_sc.append(sub[0].numpy())\n    \n    learn.export('\/kaggle\/working\/'+name+'.pkl') # export model\n    \ntest_sc = np.array(test_sc)","f8393750":"avg_prds = test_sc.mean(axis=0)","54cdbf17":"submission = sample_submission.copy()\nsubmission[cols] = avg_prds\nsubmission.loc[submission['sig_id'].isin(test_features.loc[test_features['cp_type'] =='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] = 0\nsubmission['atp-sensitive_potassium_channel_antagonist'] = 0\nsubmission['erbb2_inhibitor'] = 0","37502511":"submission.head()","97a9d864":"submission.to_csv('submission_tabular.csv',index=False)","1a1b7ce3":"import sys\nsys.path.append('..\/input\/pytorch-tabnet')\nsys.path.append('..\/input\/fastai-tabnet')","a67a513a":"from fastai.basics import *\nfrom pytorch_tabnet import *\nfrom fast_tabnet.core import *","4ed5d53c":"test_sc_tab = []\nlr = 9e-3\n\nfor i in tqdm(range(FOLDS)):\n    \n    dls = get_data(i) # Data\n    emb_szs = get_emb_sz(dls)\n    \n    model = TabNetModel(emb_szs, len(dls.cont_names), dls.c, n_d=8, n_a=32, n_steps=1); \n    \n    opt_func = partial(Adam, wd=0.01, eps=1e-5)\n    learn = Learner(dls, model, BCEWithLogitsLossFlat(), opt_func=opt_func, lr=lr, model_dir='\/kaggle\/working\/')\n    \n    name = 'best_model_tabnet_' + str(i) \n    \n    cb = SaveModelCallback(monitor='valid_loss',fname=name ,mode='min') # Callbacks\n    \n    lr = 9e-3\n    learn.fit_one_cycle(30, slice(lr\/(2.6**4),lr),cbs=cb) # Training\n    \n    learn.load(name) # Load best model\n    \n    test_dl = learn.dls.test_dl(test_features)\n    sub = learn.get_preds(dl=test_dl) # prediction\n    test_sc_tab.append(sub[0].numpy())\n    \n    learn.export('\/kaggle\/working\/'+name+'.pkl') # export model\n    \ntest_sc_tab = np.array(test_sc_tab)","566039ff":"avg_prds_tab = test_sc_tab.mean(axis=0)","35605ecd":"submission_tab = sample_submission.copy()\nsubmission_tab[cols] = avg_prds_tab\nsubmission_tab.loc[submission_tab['sig_id'].isin(test_features.loc[test_features['cp_type'] =='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] = 0\nsubmission_tab['atp-sensitive_potassium_channel_antagonist'] = 0\nsubmission_tab['erbb2_inhibitor'] = 0","d8de4c96":"submission_tab.to_csv('submission_tabnet.csv',index=False)","6b61142d":"final_prds = np.array((list(avg_prds),list(avg_prds_tab))).mean(axis=0)","5b23eba6":"fin_wt_prds = avg_prds*(0.75) + avg_prds_tab*(0.25)","a7566342":"submission_fin = sample_submission.copy()\nsubmission_fin[cols] = fin_wt_prds\nsubmission_fin.loc[submission_fin['sig_id'].isin(test_features.loc[test_features['cp_type'] =='ctl_vehicle', 'sig_id']), train_targets_scored.columns[1:]] = 0\nsubmission_fin['atp-sensitive_potassium_channel_antagonist'] = 0\nsubmission_fin['erbb2_inhibitor'] = 0","b09a885c":"results = submission_fin.copy()\nfor cl in cols:\n    results[cl].clip(0.0002, 0.999, inplace = True)\nresults.to_csv('submission.csv',index=False)","7dfc9779":"## Lets Build A TabNet Mobel","750ff2c9":"* Lest try a sepearate model for these in the next version","55741fd0":"* **atp-sensitive_potassium_channel_antagonist,erbb2_inhibitor** both have only one True values so we can keep them zero","2706fde1":"# Ensemble of fastai tabular learner and TabNet:","20c0c7d3":"## Combining both fastai tabular learner and TabNet predictions","4d72985f":"## Tabnet Model 5 fold","cd2bfb07":"* **tabular_learner** : **Uses in particular,embeddings for categorical variables with linear layers. [https:\/\/docs.fast.ai\/tabular.learner]**\n* **TabNet** : **This is an adaptation of TabNet (Attention-based network for tabular data) [https:\/\/arxiv.org\/pdf\/1908.07442.pdf]**"}}