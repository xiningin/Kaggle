{"cell_type":{"287175bf":"code","881f0f9b":"code","ed1b720b":"code","c9c0d107":"code","7eda0d91":"code","9112683c":"code","b3e27e91":"code","0344394a":"code","716af483":"code","9eaef0cb":"code","b751c8ab":"code","396f1503":"code","022b68e3":"markdown","ff2deae8":"markdown","26f48a2a":"markdown","46197982":"markdown","2ab27fcb":"markdown"},"source":{"287175bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport os\nimport glob\nimport shutil\nimport sys\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport keras\nimport os\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","881f0f9b":"!pip install -U git+https:\/\/github.com\/qubvel\/efficientnet","ed1b720b":"from efficientnet.keras import EfficientNetB0\nfrom efficientnet.keras import center_crop_and_resize, preprocess_input","c9c0d107":"width = 150\nheight = 150\ninput_shape = (height, width, 3)\n\n\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)","7eda0d91":"train_dir = '..\/input\/herbarium-2021-fgvc8\/train\/images'\ntest_dir = '..\/input\/herbarium-2021-fgvc8\/test\/images'\nbatch_size = 512","9112683c":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(height, width),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle = True,\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(height, width),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle = False,\n        subset='validation')\n\nprint(train_generator.class_indices)","b3e27e91":"import os, os.path\nepochs = 1\nNUM_TRAIN = sum([len(files) for r, d, files in os.walk(train_dir)])\ndropout_rate = 0.2","0344394a":"num_classes = len(os.listdir(train_dir))\n\nmodel = models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.GlobalMaxPooling2D(name=\"gmp\"))\nif dropout_rate > 0:\n    model.add(layers.Dropout(dropout_rate, name=\"dropout\"))\nmodel.add(layers.Dense(num_classes, activation='softmax', name=\"out\"))","716af483":"model.summary()\n\nbase_model.trainable = False","9eaef0cb":"import tensorflow as tf\ntf.test.gpu_device_name()","b751c8ab":"model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.01),\n              metrics=['acc'])\n\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch= (NUM_TRAIN*0.8) \/\/batch_size,\n      epochs=epochs,\n      validation_data=validation_generator,\n      validation_steps= (NUM_TRAIN*0.2) \/\/batch_size,\n      verbose=1,\n      use_multiprocessing=True,\n      workers=4)","396f1503":"model.save('effnetB0.h5')","022b68e3":"## Installing EfficientNet","ff2deae8":"## Importing EfficientNet","26f48a2a":"## Loading Pretrained Model","46197982":"## Using image data generator","2ab27fcb":"## Train model"}}