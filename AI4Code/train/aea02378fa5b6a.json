{"cell_type":{"c38f17a5":"code","ef2ed699":"code","a9737902":"code","588af810":"code","1ee11e3d":"code","2818130b":"code","caf358ca":"code","855f6f72":"code","a86b79c1":"code","782475b3":"code","3ab15836":"code","09d896a9":"code","af4079d3":"code","7ce5c42d":"code","64f2bb31":"code","d2758bea":"code","1a2e7eb8":"code","0dbc963b":"code","7b2ef1bd":"code","f371d736":"code","28847544":"code","f79415d6":"code","7dd9ae5e":"code","edae8c2c":"code","aaad1372":"code","c88b172b":"code","3942bd19":"code","56c5edab":"code","c4ed2e6d":"code","ec074860":"code","175bc978":"code","745543ba":"code","67e5aeb9":"code","38d77db9":"code","be72bd49":"code","a9c556c3":"code","c84f38bd":"code","e511134d":"code","8b708b64":"code","347deb2e":"code","8cdc77c8":"code","5e628e0d":"code","8d60ec71":"code","4b163438":"code","2f78d044":"code","2ef2beab":"code","206e4f28":"code","58ac4a9c":"code","c850cab8":"code","4df409ff":"markdown","efbb20cc":"markdown","91272061":"markdown","7870ad14":"markdown","0061103c":"markdown","70a7f227":"markdown","ffc7789b":"markdown","510dcdfe":"markdown","2d602dcc":"markdown","0680678f":"markdown","1174fe92":"markdown","d9440ae3":"markdown","a18c95b4":"markdown"},"source":{"c38f17a5":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","ef2ed699":"import os\nos.listdir('..\/input\/titanic') #Check whether the path to dataset is correct","a9737902":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]","588af810":"import re\ndef getTicketType(ticket):\n    try:\n        word1 = re.findall(\"[a-zA-Z]+\", ticket)[0]\n    except IndexError:\n        word1 = 'Other'\n    return word1\ngetTicketType(\"STON\/O2. 3101282\")","1ee11e3d":"train_df['TicketType'] = train_df['Ticket'].apply(getTicketType)\nset(train_df['TicketType'].values)\n","2818130b":"train_df.head(5)","caf358ca":"observedField = 'TicketType'\ntrain_df[[observedField, 'Survived']].groupby([observedField], as_index=False).mean().sort_values(by='Survived', ascending=False)","855f6f72":"observedField = 'Embarked'\ntrain_df[[observedField, 'Survived']].groupby([observedField], as_index=False).mean().sort_values(by='Survived', ascending=False)","a86b79c1":"observedField = 'Cabin'\ntrain_df[[observedField, 'Survived']].groupby([observedField], as_index=False).mean().sort_values(by='Survived', ascending=False)","782475b3":"#feature = 'Pclass'\ndef get_conditional_prob_of_survive(feature):\n    '''\n    Function for returning a resulting dataframe\n    '''\n    return (train_df[[feature, 'Survived']].groupby([feature], as_index=False).\n             mean().\n             sort_values(by='Survived', ascending=False))\nget_conditional_prob_of_survive(\"Pclass\")","3ab15836":"get_conditional_prob_of_survive('Sex')","09d896a9":"#train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)\nget_conditional_prob_of_survive('Parch')","af4079d3":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\n","7ce5c42d":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\ngrid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","64f2bb31":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\n# X: Pclass\n# Y: Survived\n# Lines: sex\n# Just noting, it's the first time I use seaborn\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex',palette='deep')\n\ngrid.add_legend()","d2758bea":"# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\ngrid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","1a2e7eb8":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1) #Drop unused colimes\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape\n","0dbc963b":"for dataset in combine:\n    # Change famale to 1 male to 0\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","7b2ef1bd":"train_df[train_df['Age'].isnull()]","f371d736":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\ngrid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","28847544":"guess_ages = np.zeros((2,3))","f79415d6":"# For train data\n# Guess value (Using median)\nfor sex in range(0,2):\n    for pclass in range(1,4):\n        guess_df = train_df[(train_df['Sex'] == sex) & \\\n                                  (train_df['Pclass'] == pclass)]['Age'].dropna()\n        age_guess = guess_df.median() #Guess age\n        guess_ages[sex,pclass-1] = int( age_guess\/0.5 + 0.5 ) * 0.5\n\n# Reassign value\nfor sex in range(0, 2):\n    for pclass in range(1,4):\n        train_df.loc[(\n                        (train_df.Age.isnull())&\n                        (train_df.Sex == sex)&\n                        (train_df.Pclass == pclass)\n                    ),\n                    'Age'] = guess_ages[sex,pclass-1]\n\ntrain_df['Age'] = train_df['Age'].astype(int)\ntrain_df","7dd9ae5e":"# Do the same with testing\n# Guess value (Using median)\nfor sex in range(0,2):\n    for pclass in range(1,4):\n        guess_df = test_df[(train_df['Sex'] == sex) & \\\n                                  (test_df['Pclass'] == pclass)]['Age'].dropna()\n        age_guess = guess_df.median() #Guess age\n        guess_ages[sex,pclass-1] = int( age_guess\/0.5 + 0.5 ) * 0.5\n\n# Reassign value\nfor sex in range(0, 2):\n    for pclass in range(1,4):\n        test_df.loc[(\n                        (test_df.Age.isnull())&\n                        (test_df.Sex == sex)&\n                        (test_df.Pclass == pclass)\n                    ),\n                    'Age'] = guess_ages[sex,pclass-1]\n\ntest_df['Age'] = test_df['Age'].astype(int)\ntest_df","edae8c2c":"train_df['AgeBand'] = pd.cut(train_df['Age'], #Columns to be proceeded \n                             5 #Number of bands\n                            )\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","aaad1372":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","c88b172b":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","3942bd19":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","56c5edab":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","c4ed2e6d":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","ec074860":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","175bc978":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","745543ba":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","67e5aeb9":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","38d77db9":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","be72bd49":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'],\n                                           as_index=False).mean().sort_values(by='FareBand', ascending=True)","a9c556c3":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","c84f38bd":"test_df.head(10)","e511134d":"test_df = test_df.drop(['Name'], axis = 1)","8b708b64":"train_df = train_df.drop(['TicketType','Name'], axis=1)","347deb2e":"X_train = train_df.drop([\"Survived\",\"PassengerId\"], axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","8cdc77c8":" #Pclass\tSex\tAge\tFare\tEmbarked\tIsAlone\tAge*Class\nX_train","5e628e0d":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","8d60ec71":"from numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(20, input_dim=7, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","4b163438":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","2f78d044":"model.fit(X_train.values, Y_train.values, epochs=150, batch_size=10)","2ef2beab":"Y_preds_ = model.predict(X_test.values)","206e4f28":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_preds_.T[0]\n    })","58ac4a9c":"submission['Survived'] = submission['Survived'].apply(lambda x: int(x > 0.5))","c850cab8":"submission.to_csv('submission.csv', index=False)","4df409ff":"See, we got 177 people who have no age recorded.","efbb20cc":"### Embarked","91272061":"## Import","7870ad14":"# Plotting conditional probability","0061103c":"# Wrangling","70a7f227":"As well, cabin seems difficult to analyse, so I drop it.","ffc7789b":"Ticket type seems not to be too less information to analyse, so I decided to drop it out.","510dcdfe":"### Ticket type","2d602dcc":"# The high fare high survive rate","0680678f":"# Hello!\n\nI'm Prem. This will be my first competition in Kaggle. Thank to Manav Sehgal, I can import data and start this project easily.","1174fe92":"# Survived probability\n\nFrom,\n\n$$\n\\begin{split}\nP(Survived = 1|feature) &= \\frac{\\text{#(Survive = 1 & feature)}}{\\#\\text{feature}}\\\\\n\\end{split}\n$$","d9440ae3":"# Some people's age is missing, then I need to fix it","a18c95b4":"### Cabin "}}