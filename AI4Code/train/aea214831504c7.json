{"cell_type":{"67b0b098":"code","d0ad83d1":"code","eaf288f8":"code","2b50815e":"code","6e3a522a":"code","7e7dd8c1":"code","015241ae":"code","53286e71":"code","96802003":"code","3d51c87c":"code","22fef478":"code","48f403fa":"code","c5548774":"code","8234512e":"code","c0cbc969":"code","22050283":"code","a1fc9c16":"code","6cd16060":"code","b2c02f88":"code","e0304baa":"code","0bb753c1":"code","755ed87a":"code","9c4f3cb7":"code","0fb5ff80":"code","532bb85b":"code","3170e066":"code","e3701042":"code","60dedcfd":"code","b49fab4d":"code","db4d95eb":"code","14d2d242":"code","e8ba9967":"code","0dfded22":"code","2200ad8a":"code","565f30d4":"code","9ec527ef":"code","105ae1bd":"code","3e6c5015":"code","628b515e":"code","518057e5":"code","1a3e1d4e":"code","b53381c1":"markdown","52547a2a":"markdown"},"source":{"67b0b098":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0ad83d1":"#Utils\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom catboost import CatBoostClassifier\nimport seaborn as sns\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport category_encoders as ce\nimport timeit\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import RobustScaler\nimport tensorflow as tf\nimport keras\nfrom sklearn.utils import class_weight","eaf288f8":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","2b50815e":"pip install git+https:\/\/github.com\/keras-team\/keras-tuner.git@1.0.2rc0","6e3a522a":"!pip install autokeras","7e7dd8c1":"import autokeras as ak","015241ae":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv', sep=',')\ntrain = train.set_index('id')","53286e71":"test= pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv', sep=',')\ntest = test.set_index('id')","96802003":"plt.figure(figsize=(10,5))\nsns.countplot(x='target',data=train, palette='viridis').set_title('#istances per Class')","3d51c87c":"plt.figure(figsize=(10,5))\ndf= train['target'].value_counts(normalize=True).reset_index()\nsns.barplot(x='index',y='target',data=df, palette='viridis').set_title('%istances per Class')","22fef478":"cols = train.columns[:-1] \ndf_unique = pd.concat([train[cols], test[cols]], axis=0)","48f403fa":"plt.figure(figsize=(16,5))\ndf_unique[cols].nunique().plot(kind='bar', cmap='Spectral', title='Unique values by Feature')","c5548774":"train_eda = train\ntrain_eda = train_eda.astype('str')\ntrain_eda['Total'] = pd.Series(train_eda[cols].fillna('').values.tolist()).str.join('')","8234512e":"plt.figure(figsize=(16,5))\ntrain_eda['Total'].value_counts()[:20].plot(kind='bar',title='Duplicated istances')","c0cbc969":"cols = train.columns[:-1]\ntarget = train['target']\ntrain2 = train.loc[train_eda.index]","22050283":"train = train[cols]","a1fc9c16":"train['count0'] = (train[cols]==0).sum(axis=1)\ntrain['count1'] = (train[cols]==1).sum(axis=1)\ntrain['count2'] = (train[cols]==2).sum(axis=1)","6cd16060":"train.max()","b2c02f88":"tr= train.to_numpy()","e0304baa":"tr.shape","0bb753c1":"target2 = pd.get_dummies(target)\ntarget2.head()","755ed87a":"model_input = ak.Input()\n\nnode1 = ak.Embedding(max_features=360)(model_input)\n\nnode5 = ak.ConvBlock()(node1)\n\nnode3= ak.RNNBlock()(node5)\n\nnode4 = ak.SpatialReduction()(node3)\n\nnode2 = ak.DenseBlock()(node4)\n\noutput = ak.ClassificationHead()(node2)","9c4f3cb7":"model = ak.AutoModel(inputs=[model_input], outputs=[output], max_trials=5, tuner='bayesian', overwrite=True, loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.015))","0fb5ff80":"model.fit(x=tr, y=target2, batch_size=64, validation_split=0.25, epochs=150, verbose=1, shuffle=True)","532bb85b":"# get the best model\nmodel1=model.export_model()","3170e066":"# summarize the loaded model\nmodel1.summary()","e3701042":"tf.keras.utils.plot_model(\n    model1,\n    to_file=\"model1.png\",\n    show_shapes=True,\n    show_dtype=True,\n    show_layer_names=True)","60dedcfd":"# save the best model\ntry:\n    model1.save(\"model_autokeras_TPS06\", save_format=\"h5\")\nexcept Exception:\n    model1.save(\"model_autokeras.h5\")","b49fab4d":"test['count0'] = (test[cols]==0).sum(axis=1)\ntest['count1'] = (test[cols]==1).sum(axis=1)\ntest['count2'] = (test[cols]==2).sum(axis=1)","db4d95eb":"tst = test.to_numpy()","14d2d242":"preds = model1.predict(tst, batch_size=64)","e8ba9967":"oof = model1.predict(tr, batch_size=64)","0dfded22":"oof_df = pd.DataFrame(oof, index=train.index)","2200ad8a":"predictions = pd.DataFrame(preds, index=test.index)","565f30d4":"predictions.head()","9ec527ef":"sub_sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv', sep=',')\nsub_sample = sub_sample.set_index('id')","105ae1bd":"sub_sample['Class_1'] = predictions[0]\nsub_sample['Class_2'] = predictions[1]\nsub_sample['Class_3'] = predictions[2]\nsub_sample['Class_4'] = predictions[3]\nsub_sample['Class_5'] = predictions[4]\nsub_sample['Class_6'] = predictions[5]\nsub_sample['Class_7'] = predictions[6]\nsub_sample['Class_8'] = predictions[7]\nsub_sample['Class_9'] = predictions[8]","3e6c5015":"sub_sample.head()","628b515e":"sub_sample = sub_sample.reset_index()","518057e5":"oof_df = oof_df.reset_index()\noof_df.to_csv('oof_df.csv', index=False)","1a3e1d4e":"sub_sample.to_csv('submission.csv',index=False)","b53381c1":"## AutoKeras","52547a2a":"## Load Data"}}