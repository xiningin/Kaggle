{"cell_type":{"ddacbff8":"code","b345b949":"code","f591de65":"code","cddc85e8":"code","7b861590":"code","b1e7a81b":"code","1681f822":"code","d1523eea":"code","4bc73fff":"code","c6d63d19":"code","4d764dfa":"code","2247add0":"code","e37cf895":"code","ea274aaf":"code","1c336ccd":"code","7140e53a":"code","eae77214":"code","d304ca59":"code","d96a0fec":"code","d615661e":"code","30c1f03a":"code","fcc1741a":"code","cbd43f16":"code","354f9773":"code","5073bf6f":"code","f0d175aa":"code","ea226027":"code","a33ca616":"code","6b1e7cdd":"code","954df4bd":"code","2c63eba4":"code","dbbdb0a0":"code","36a02949":"code","82945ad8":"code","77067438":"code","1c4f8f7a":"code","de108fa7":"code","60dcb94f":"code","8e2879ed":"code","fb8433b7":"code","bea7d6b5":"code","94f91e22":"code","6fcad9f7":"code","66a51761":"markdown","8cf6ae8e":"markdown","2719af44":"markdown","2bb63522":"markdown","587b2a72":"markdown","194da1af":"markdown","eb8662bf":"markdown","dcb4a4fe":"markdown","8a47748a":"markdown","701a7ef1":"markdown","20557bbc":"markdown","346a5cd6":"markdown","62c229e3":"markdown","f06bcf14":"markdown","81a2fabe":"markdown","ad181053":"markdown","7954c4fe":"markdown"},"source":{"ddacbff8":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns\n%matplotlib inline \nplt.rcParams[\"figure.figsize\"]=(18,9)\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","b345b949":"# For descriptive statics library categorical and numeric data\n!pip install researchpy ","f591de65":"\n# Madrid Weather Data.csv has 1826 rows \ndata = pd.read_csv('..\/input\/madrid-weather\/Madrid_Weather_1991_1995.csv', delimiter=',')\ndata.head()","cddc85e8":"data.dataframeName=\"Madrid Weather Data\"\nrow, col = data.shape\nprint(f'There are {row} rows and {col} columns')","7b861590":" # for data information features,its type,how many null value each features\ndata.info()","b1e7a81b":"from pandas.api.types import CategoricalDtype\n\n\ncat_type = CategoricalDtype(categories=[\"0\",\"1\"], ordered=False)\n\ndata[\"Indicator_For_Occurrence_Of_Fog\"]=data[\"Indicator_For_Occurrence_Of_Fog\"].astype(cat_type)\ndata[\"Indicator_For_Occurrence_Of_Rain\"]=data[\"Indicator_For_Occurrence_Of_Rain\"].astype(cat_type)\ndata[\"Indicator_For_Occurrence_Of_Snow\"]=data[\"Indicator_For_Occurrence_Of_Snow\"].astype(cat_type)\ndata[\"Indicator_For_Occurrence_Of_Hail\"]=data[\"Indicator_For_Occurrence_Of_Hail\"].astype(cat_type)\ndata[\"Indicator_For_Occurrence_Of_Thunder\"]=data[\"Indicator_For_Occurrence_Of_Thunder\"].astype(cat_type)\ndata[\"Indicator_For_Occurrence_Of_Tornado_Funnel_Cloud\"]=data[\"Indicator_For_Occurrence_Of_Tornado_Funnel_Cloud\"].astype(cat_type)\ndata.info()","1681f822":"#data = data.drop(['Unnamed: 0'], axis=1) # Drop unused data features  \ndata.columns","d1523eea":"data.nunique()\n","4bc73fff":"data.dropna(axis=\"index\",how=\"any\") #drop any NAN value .we know data that is not have nan value","c6d63d19":"data_year=data.groupby(['Year'])\ndata_year[\"Average_Temperature\"].mean()","4d764dfa":"data_year=data.groupby(['Month'])\ndata_year[\"Average_Temperature\"].mean()","2247add0":"# for descriptive Statics \ndata.describe(include=\"all\").T","e37cf895":"import researchpy as rs \ndata_cont=data.select_dtypes([\"int\",\"float\"])\nsummary=rs.summary_cont(data.select_dtypes([\"int\",\"float\"]))\nsummary[summary.N>1800].sort_values(by=\"N\",ascending=True)","ea274aaf":"data.select_dtypes(\"object\")","1c336ccd":"from sklearn.impute import SimpleImputer\n\n\nfeatures =data.select_dtypes(\"object\")\n  \n","7140e53a":"for col in features.columns:\n    \n    data[col].replace({\"-\": np.NAN}, inplace=True)\n    data[col]=data[col].astype(\"float\")\n    \ndata.isna().sum() # show columns with NaN","eae77214":"data[features.columns]","d304ca59":"imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n\nfor col in features.columns:\n\n    imput=data[col].values.reshape(-1,1)\n    imputer = imputer.fit(imput)\n    imput= imputer.transform(imput)\n    data.loc[:,col]=imput","d96a0fec":"data[features.columns] ","d615661e":"data.isna().sum() # show columns with NaN","30c1f03a":"data.drop(data.columns[-6:],axis=1,inplace=True) # drop rows with NaN\ndata.drop(data.columns[0],axis=1,inplace=True) # drop rows unused\ndata.shape","fcc1741a":"data.isna().sum() # show columns with NaN","cbd43f16":"columnNames = list(data)\ncolumnNames","354f9773":"data.shape","5073bf6f":"data.select_dtypes(\"object\").columns","f0d175aa":"data.select_dtypes([\"int\",\"float\"]).columns","ea226027":"valueCounts =data.iloc[:, 1].value_counts(ascending=True)\nvalueCounts","a33ca616":"# Plot Correlation matrix\ndef plotCorr(df, graphsize,minunieval):\n    filename = \"Weather of Madrid\"\n    df.dropna('index',inplace=True) # drop rows with NaN\n    df = df[[col for col in df if df[col].nunique() > minunieval]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr();\n    plt.figure(num=None, figsize=(graphsize, graphsize), dpi=80, facecolor='w', edgecolor='k')\n    # plot a heatmap with annotation\n    sns.heatmap(corr, annot=True, annot_kws={\"size\": 12})\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","6b1e7cdd":"plotCorr(data, 10,10)","954df4bd":"from scipy.stats import pearsonr,kendalltau,spearmanr\n\ntest ,p_value=pearsonr(data.copy().Maximum_Temperature,data.copy().Minimum_Temperature)\nprint(f\"test :  %.5f  P value : %.3f\" % (test ,p_value))\n","2c63eba4":"def corr_coef(x,y,textsize=10,label=None,color=None,**kwargs):\n    ax = plt.gca()\n    corr,p = pearsonr(x,y)\n    ax.annotate('Corr. coef = {:.2f}'.format(corr), xy=(0.5,0.5), xycoords='axes fraction', ha='center', va='center')\n    ax.set_axis_off()","dbbdb0a0":"# Scatter and density plots\ndef plot_ScatterMtrx(df, plotSize, textSize,minunieq,colsize):\n    df = df.select_dtypes(include =[\"int\",\"float\"]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df.dropna('index',inplace=True)\n    df = df[[col for col in df if df[col].nunique() > minunieq]] # keep columns where there are more than min_value unique values\n    columnNames = df.columns\n    if len(columnNames) > colsize: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:colsize]\n    df = df[columnNames]\n    # with kde\n    plt.figure(figsize=[plotSize, plotSize])\n    #g = sns.PairGrid(data.copy())\n    g=sns.pairplot(df,diag_kind=\"kde\",plot_kws=dict( alpha=0.5))\n    g.map_diag(sns.distplot)\n    g.map_lower(sns.regplot)\n    g.map_upper(corr_coef)\n\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","36a02949":"plot_ScatterMtrx(data.copy(), 18,10,5,8)","82945ad8":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,precision_score\nfrom sklearn.metrics import confusion_matrix\n","77067438":"y = data['Average_Temperature']\nx = data.drop(['Average_Temperature'], axis=1)","1c4f8f7a":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.3, random_state=42)","de108fa7":"type(x_train)","60dcb94f":"x_train.shape,y_train.shape","8e2879ed":"clf = MLPRegressor(hidden_layer_sizes=(50,100,50),activation=\"relu\" ,max_iter=300, alpha=0.001,\n                     solver='adam', verbose=10,  random_state=42,tol=0.0001)","fb8433b7":"clf.fit(x_train,y_train)\n","bea7d6b5":"y_pred=clf.predict(x_test)","94f91e22":"mean_absolute_error(y_test, y_pred)","6fcad9f7":"mean_squared_error(y_test, y_pred)","66a51761":"Let's take a quick look at what the data looks like:","8cf6ae8e":"**Showing Average Tempeture by Years**","2719af44":"### Let's check Istanbul Weather Data","2bb63522":"**Correlation for Number features**","587b2a72":"### Data \u0130mputing for missing values ","194da1af":"## Models\n","eb8662bf":"There is 1 csv file in the current version of the dataset:\n","dcb4a4fe":"## Introduction\n","8a47748a":"###  Data Visualitions","701a7ef1":"##  Library import and checking Data","20557bbc":"**Showing Average Tempeture by Mounts**","346a5cd6":"Correlation matrix:","62c229e3":"**Check Nan values**","f06bcf14":"#### Descriptive Statics","81a2fabe":"#### Corelation types for Normally or Non-Normal Distributuons ","ad181053":"## **Explatory Data Analysys**","7954c4fe":"Scatter and density plots:"}}