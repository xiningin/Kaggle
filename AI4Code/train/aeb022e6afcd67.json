{"cell_type":{"712446e9":"code","59d90257":"code","1cc072d1":"code","ea691180":"code","0096cf85":"code","0a074546":"code","849d077a":"code","9e1d72e1":"code","20dea97a":"code","ecf12811":"code","7ddbe27a":"code","77170cf2":"code","d1fe232d":"code","4d64cb89":"code","2ee07939":"code","b163ceeb":"code","3d192bed":"code","d9c9ea67":"code","35a66649":"code","20136e95":"code","36c36baf":"code","d930922d":"code","6ea98313":"code","3bc9c7bc":"code","9079c4a7":"code","ac609cc6":"code","83d0dc22":"markdown","706b8c01":"markdown","d8924fd3":"markdown","24d20aae":"markdown","f1ddacc4":"markdown","562439d0":"markdown","fc106668":"markdown","5e6bdd87":"markdown","94b82211":"markdown","189d2a49":"markdown","f7a0ca93":"markdown","5b1cec10":"markdown","4376914f":"markdown","e19b8391":"markdown"},"source":{"712446e9":"!ls \/kaggle\/input\/cassava-leaf-disease-classification","59d90257":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport cv2\n\nprint('tensorflow version:', tf.__version__)","1cc072d1":"# seed\u56fa\u5b9a\ndef seed_everything(seed=1234):\n    #random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=42)","ea691180":"# GPU\u306e\u78ba\u8a8d\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","0096cf85":"class CFG:\n    debug=True\n    size=64\n    epochs=10\n    batch_size=64\n    val_batch_size=128\n    seed=42\n    target_size=5\n    target_col='label'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","0a074546":"if os.path.exists('\/kaggle\/input'):\n    # kaggle\u74b0\u5883\n    DATA_DIR = '\/kaggle\/input\/cassava-leaf-disease-classification\/'\nelse:\n    # \u30ed\u30fc\u30ab\u30eb\u74b0\u5883\n    DATA_DIR = '..\/..\/data\/raw\/'\n    \nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","849d077a":"train = pd.read_csv(DATA_DIR + 'train.csv')\ntest = pd.read_csv(DATA_DIR + 'sample_submission.csv')\nlabel_map = pd.read_json(DATA_DIR + 'label_num_to_disease_map.json', \n                         orient='index')\ndisplay(train.head())\ndisplay(test.head())\ndisplay(label_map)","9e1d72e1":"# \u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f\nimage = plt.imread(DATA_DIR + 'train_images\/1000015157.jpg')\n\n# \u753b\u50cf\u306e\u8868\u793a\nplt.imshow(image);","20dea97a":"label0_images = train[train['label'] == 0]['image_id'].to_list()\nlabel1_images = train[train['label'] == 1]['image_id'].to_list()\nlabel2_images = train[train['label'] == 2]['image_id'].to_list()\nlabel3_images = train[train['label'] == 3]['image_id'].to_list()\nlabel4_images = train[train['label'] == 4]['image_id'].to_list()","ecf12811":"def showImages(images):\n\n    random_images = [np.random.choice(images) for i in range(8)]\n\n    plt.figure(figsize=(12,5))\n\n    for i in range(8):\n        plt.subplot(2, 4, i + 1)\n        img = plt.imread(DATA_DIR + \"\/train_images\/\"+ random_images[i])\n        plt.imshow(img)\n        plt.axis('off')\n\n    plt.tight_layout()","7ddbe27a":"# label 0\nshowImages(label0_images)","77170cf2":"# label 1\nshowImages(label1_images)","d1fe232d":"# label 2\nshowImages(label2_images)","4d64cb89":"# label 3\nshowImages(label3_images)","2ee07939":"# label 4\nshowImages(label4_images)","b163ceeb":"sns.distplot(train['label'], kde=False)","3d192bed":"if CFG.debug:\n    train = train[:3000]\n\ntrain['label'] = train['label'].astype(str)\nfolds = train.copy()\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.groupby(['fold', CFG.target_col]).size())","d9c9ea67":"folds.head()","35a66649":"# https:\/\/keras.io\/ja\/preprocessing\/image\/\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.1,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1.\/255)","20136e95":"generator = train_datagen.flow_from_dataframe(dataframe = train,\n                                              directory = DATA_DIR + \"train_images\",\n                                              x_col = 'image_id',\n                                              y_col = 'label',\n                                              target_size = (CFG.size, CFG.size),\n                                              color_mode = \"rgb\",\n                                              class_mode = \"categorical\",\n                                              batch_size = 1,\n                                              shuffle = True,\n                                              subset = 'training')","36c36baf":"# \u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30fc\u30678\u679a\u751f\u6210\u3057\u3066\u3001\u8868\u793a\u3059\u308b\u3002\nplt.figure(figsize=(10, 5))\nfor i in range(8):\n    batches = next(generator)  # (NumBatches, Height, Width, Channels) \u306e4\u6b21\u5143\u30c7\u30fc\u30bf\u3092\u8fd4\u3059\u3002\n    # \u753b\u50cf\u3068\u3057\u3066\u8868\u793a\u3059\u308b\u305f\u3081\u30013\u6b21\u5143\u30c7\u30fc\u30bf\u306b\u3059\u308b\u3002\n    gen_img = batches[0][0]\n\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(gen_img)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","d930922d":"def vgg16_model(num_classes=None):\n\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(CFG.size, CFG.size, 3), pooling='avg')\n    output = Dense(num_classes, activation='softmax')(base_model.output)\n    model = Model(base_model.input, output)\n    \n    return model","6ea98313":"model=vgg16_model(CFG.target_size)\nmodel.summary()","3bc9c7bc":"def train_loop(folds, fold):\n\n    print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # train data, validation data\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    # ====================================================\n    # generator\n    # ====================================================\n    \n    train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n    val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    train_generator = train_datagen.flow_from_dataframe(dataframe = train_folds,\n                                                        directory = DATA_DIR + \"train_images\",\n                                                        x_col = 'image_id',\n                                                        y_col = 'label',\n                                                        target_size = (CFG.size, CFG.size),\n                                                        color_mode = \"rgb\",\n                                                        class_mode = \"categorical\",\n                                                        batch_size = CFG.batch_size,\n                                                        shuffle = True)\n\n    val_generator = val_datagen.flow_from_dataframe(dataframe = valid_folds,\n                                                    directory = DATA_DIR + \"train_images\",\n                                                    x_col = 'image_id',\n                                                    y_col = 'label',\n                                                    target_size = (CFG.size, CFG.size),\n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    batch_size = CFG.val_batch_size,\n                                                    shuffle = False)\n \n    # ====================================================\n    # callbacks\n    # ====================================================  \n    save_model = tf.keras.callbacks.ModelCheckpoint(\n                    f'fold-{fold}.h5', monitor='val_loss', verbose=0, save_best_only=True,\n                    save_weights_only=True, mode='min', save_freq='epoch')\n\n    \n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5, min_delta = 0.0001,\n                                                      verbose=1, mode='min'),\n    \n    reduce_lr_op = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2,\n                                     verbose = 1, min_delta = 0.0001, mode = 'min')\n    \n    callbacks = [save_model, early_stopping, reduce_lr_op]\n\n    # ====================================================\n    # optimizer #SGD\n    # ====================================================   \n    optimizer = Adam(lr=0.0001)\n    \n    # ====================================================\n    # loss\n    # ====================================================\n    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False, label_smoothing=0.0001,name='categorical_crossentropy' )\n    \n    # ====================================================\n    # model\n    # ====================================================\n    model = vgg16_model(num_classes=CFG.target_size)    \n    model.compile(optimizer = optimizer, loss = loss, metrics = ['categorical_accuracy'])\n\n    # ====================================================\n    # training\n    # ====================================================\n    train_steps = train_generator.n\/\/train_generator.batch_size\n    val_steps = val_generator.n\/\/val_generator.batch_size\n    \n    \n    history = model.fit(\n                    train_generator,\n                    steps_per_epoch=train_steps,\n                    epochs=CFG.epochs,\n                    validation_data=val_generator,\n                    callbacks=callbacks,\n                    validation_steps=val_steps\n                    )\n\n    # ====================================================\n    # predict\n    # ====================================================\n    print('Loading best model...')\n    model.load_weights(f'fold-{fold}.h5')\n    \n    print('Predicting OOF...')\n    pred = model.predict(val_generator, verbose=1)\n    \n    valid_folds[[str(c) for c in range(5)]] = pred\n    valid_folds['preds'] = pred.argmax(1) \n    \n    # ====================================================\n    # plot\n    # ====================================================   \n    plt.figure(figsize=(10,3))\n    plt.plot(np.arange(len(history.history['categorical_accuracy'])),history.history['categorical_accuracy'],'-o',label='Train ACC',color='#ff7f0e')\n    plt.plot(np.arange(len(history.history['val_categorical_accuracy'])),history.history['val_categorical_accuracy'],'-o',label='Val ACC',color='#1f77b4')\n    x = np.argmax( history.history['val_categorical_accuracy'] ); y = np.max( history.history['val_categorical_accuracy'] )\n    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max acc\\n%.2f'%y,size=14)\n    plt.ylabel('ACC',size=14); plt.xlabel('Epoch',size=14)\n    plt.legend(loc=2)\n    plt2 = plt.gca().twinx()\n    plt2.plot(np.arange(len(history.history['loss'])),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n    plt2.plot(np.arange(len(history.history['val_loss'])),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n    ydist = plt.ylim()[1] - plt.ylim()[0]\n    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n    plt.ylabel('Loss',size=14)\n    plt.title(f'FOLD {fold} - Image Size {CFG.size}',size=16)\n    plt.legend(loc=3)\n    plt.show()\n\n    return valid_folds","9079c4a7":"folds.head()","ac609cc6":"def get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)\n\n\ndef get_result(result_df):\n    preds = result_df['preds'].values\n    labels = result_df[CFG.target_col].astype(int).values\n    score = get_score(labels, preds)\n    print(f'Score: {score:<.5f}')\n\n\n# train \noof_df = pd.DataFrame()\nfor fold in range(CFG.n_fold):\n    if fold in CFG.trn_fold:\n        _oof_df = train_loop(folds, fold)\n        oof_df = pd.concat([oof_df, _oof_df])\n        print(f\"========== fold: {fold} result ==========\")\n        get_result(_oof_df)\n# CV result\nprint(f\"========== CV ==========\")\nget_result(oof_df)\n# save result\noof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","83d0dc22":"#  2. \u30c7\u30fc\u30bf\u7406\u89e3","706b8c01":"# 1. \u6e96\u5099 ","d8924fd3":"# \u6982\u8981\nTensorflow, Keras\u306b\u3088\u308b\u753b\u50cf\u5206\u985e\u306e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002<br> \n\u3053\u306enotebook\u3067\u306f\u7c21\u5358\u306aEDA\u3068\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u884c\u3044\u307e\u3059\u3002<br> \n\n### 1. \u6e96\u5099 \n- \u30d5\u30a1\u30a4\u30eb\u69cb\u6210\n- \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n- \u8a2d\u5b9a\n\n### 2. \u30c7\u30fc\u30bf\u7406\u89e3\n- \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n- \u753b\u50cf\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316\n- \u5404\u753b\u50cf\u306b\u5bfe\u3057\u3066\u306e\u30e9\u30d9\u30eb\u6bd4\u7387\u306e\u78ba\u8a8d\n\n### 3. \u30e2\u30c7\u30ea\u30f3\u30b0\n- \u30c7\u30fc\u30bf\u5206\u5272\u65b9\u6cd5\u306e\u5b9a\u7fa9\n- \u30c7\u30fc\u30bf\u524d\u51e6\u7406\u306e\u5b9a\u7fa9\n- \u5206\u985e\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\n- \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\uff08\u5c64\u5316k\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\uff09\n - \u640d\u5931\u95a2\u6570\u306e\u5b9a\u7fa9<br>\n - \u6700\u9069\u5316\u624b\u6cd5\u306e\u5b9a\u7fa9<br>\n - \u30b9\u30b3\u30a2\u306e\u7b97\u51fa<br>\n\n### 4. \u63a8\u8ad6\nhttps:\/\/www.kaggle.com\/takuyatone\/cassava-keras-tf-baseline-inference","24d20aae":"## \u8a2d\u5b9a","f1ddacc4":"## \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","562439d0":"## \u5206\u985e\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9","fc106668":"## \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2","5e6bdd87":"## \u30c7\u30fc\u30bf\u5206\u5272\u65b9\u6cd5\u306e\u5b9a\u7fa9","94b82211":"## \u30c7\u30fc\u30bf\u524d\u51e6\u7406\u306e\u5b9a\u7fa9","189d2a49":"## \u5404\u753b\u50cf\u306b\u5bfe\u3057\u3066\u306e\u30e9\u30d9\u30eb\u6bd4\u7387\u306e\u78ba\u8a8d","f7a0ca93":"## \u30d5\u30a1\u30a4\u30eb\u69cb\u6210","5b1cec10":"## \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","4376914f":"## \u753b\u50cf\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316","e19b8391":"# 3. \u30e2\u30c7\u30ea\u30f3\u30b0"}}