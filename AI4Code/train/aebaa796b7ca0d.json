{"cell_type":{"9461da0a":"code","41651dae":"code","2736ea28":"code","842a4512":"code","b4a52d4c":"code","20fca256":"code","51f2d4c9":"code","b615ebff":"code","b6510ab5":"code","ba9dece5":"code","0c14fdda":"code","f110d70d":"code","d8f3e078":"code","e09863bb":"markdown"},"source":{"9461da0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41651dae":"# importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2736ea28":"# importing the datasets \n\ndataset_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndataset_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndataset_train.head()","842a4512":"# dropping the name column\ndataset_train.drop([\"Name\"], axis=1, inplace= True)\ndataset_test.drop([\"Name\"], axis=1, inplace= True)\ndataset_train['related'] = dataset_train['SibSp'] + dataset_train['Parch']\ndataset_test['related'] = dataset_test['SibSp'] + dataset_test['Parch']\ndataset_train.head()","b4a52d4c":"# visualizing the data to know the relation between survival and other parameters\nsns.barplot(x='Sex',y='Survived',data=dataset_train)\n","20fca256":"# high survival rate if you boarded from Cherbyl\nsns.barplot(x='Embarked',y='Survived',data=dataset_train)\n","51f2d4c9":"sns.barplot(x='Pclass',y='Survived',data=dataset_train)\n","b615ebff":"sns.barplot(x='related',y='Survived',data=dataset_train)","b6510ab5":"# handling NAN entries in the dataset\n# for the Age column, I have first grouped the data according to \n# sex and Class and then taken the median\ndataset_train.isnull().sum()\ngrouped = dataset_train.groupby(['Sex','Pclass'])  \ngrouped.Age.median()\ndataset_train.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\ngrouped = dataset_test.groupby(['Sex','Pclass']) \ndataset_test.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\n\ndataset_train['Fare']=dataset_train['Fare'].fillna(dataset_train['Fare'].median())\ndataset_test['Fare']=dataset_test['Fare'].fillna(dataset_test['Fare'].median())\ndataset_train['Cabin'] = dataset_train['Cabin'].fillna('U')\ndataset_test['Cabin'] = dataset_test['Cabin'].fillna('U')\ndataset_train['Cabin'] = [x[:1] for x in dataset_train['Cabin']]\ndataset_test['Cabin'] = [x[:1] for x in dataset_test['Cabin']]\n\ndataset_train['Embarked'].describe()\ndataset_train['Embarked']=dataset_train['Embarked'].fillna('S')\ndataset_test['Embarked']=dataset_test['Embarked'].fillna('S')\ndataset_train.isnull().sum()\n","ba9dece5":"# handling Categorical values\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\ndataset_train['Sex']= labelencoder.fit_transform(dataset_train['Sex'])\ndataset_test['Sex']= labelencoder.fit_transform(dataset_test['Sex'])\n#dataset_train['Sex'].unique() \nonehotencoder = OneHotEncoder(handle_unknown='ignore')\ndataset_train=dataset_train.join(pd.DataFrame(onehotencoder.fit_transform(dataset_train[['Embarked']]).toarray()))\ndataset_test = dataset_test.join(pd.DataFrame(onehotencoder.fit_transform(dataset_test[['Embarked']]).toarray()))\ncabin_dummies = pd.get_dummies(dataset_train.Cabin, prefix=\"Cabin\")\ndataset_train = pd.concat([dataset_train,cabin_dummies],axis=1)\ncabin_dummies = pd.get_dummies(dataset_test.Cabin, prefix=\"Cabin\")\ndataset_test = pd.concat([dataset_test,cabin_dummies],axis=1)\n\nclass_dummies = pd.get_dummies(dataset_train.Pclass, prefix=\"Pclass\")\ndataset_train = pd.concat([dataset_train,class_dummies],axis=1)\nclass_dummies = pd.get_dummies(dataset_test.Pclass, prefix=\"Pclass\")\ndataset_test = pd.concat([dataset_test,class_dummies],axis=1)\ndataset_train.head()","0c14fdda":"\nX = dataset_train.loc[:,[\"Age\",\"Fare\",\"Sex\",\"related\",\"Cabin_A\",\"Cabin_B\",\"Cabin_C\",\"Cabin_D\",\"Cabin_E\",\"Cabin_F\",\"Cabin_G\",\"Cabin_T\",\"Cabin_U\",0,1,2,\"Pclass_1\",\"Pclass_2\",\"Pclass_3\"]]\nY = dataset_train.loc[:,[\"Survived\"]]\nprint(X)\nprint(Y)\ndataset_test[\"Cabin_T\"]=0","f110d70d":"\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2) \ntest = dataset_test.loc[:,[\"Age\",\"Fare\",\"Sex\",\"related\",\"Cabin_A\",\"Cabin_B\",\"Cabin_C\",\"Cabin_D\",\"Cabin_E\",\"Cabin_F\",\"Cabin_G\",\"Cabin_T\",\"Cabin_U\",0,1,2,\"Pclass_1\",\"Pclass_2\",\"Pclass_3\"]]\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nlogisticregressor = LogisticRegression()\nlogisticregressor.fit(X_test,Y_test)\np1 = logisticregressor.predict(test)\noutput = pd.DataFrame({\"PassengerId\" : dataset_test.PassengerId, \"Survived\" : p1})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\nacc1 = logisticregressor.score(X_test,Y_test)\nprint(acc1)\n","d8f3e078":"\nrandom = RandomForestClassifier(n_estimators=10,random_state=0)\nrandom.fit(X,Y)\np2 = random.predict(test)\noutput2 = pd.DataFrame({\"PassengerId\" : dataset_test.PassengerId, \"Survived\" : p2})\noutput2.to_csv('submission_1.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\nacc2 = random.score(X,Y)\nprint(acc2)","e09863bb":"This is my first Machine learning model. I've used logistic regression which is giving 75% score and random forest which gave me 77% score. \nI have used Age, Pclass, Cabin, Fare, Sex and Embarked variables. Now I'm stuck and unable to improve the score. **Welcome all suggestions**. "}}