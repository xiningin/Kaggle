{"cell_type":{"9329fccb":"code","79f5c7ec":"code","e491f5ef":"code","43543c12":"code","ac179be7":"code","c9e6c64b":"code","befb1c67":"code","bd909086":"code","1cd59f45":"code","eab3d799":"code","d3cc04f0":"code","898e084d":"code","07b3c0e3":"code","de2ccd0b":"code","09d20fa3":"code","eb716508":"code","0dfff079":"code","adb0e718":"code","a7e1a61f":"code","97d35731":"code","364e4efa":"code","49351a55":"code","89451efb":"code","f168afb9":"code","c3f569ab":"code","1906b712":"code","b47a8bb1":"code","6bc61418":"code","105ab0f3":"code","f5399742":"code","af02f15d":"code","c26d84ae":"code","11cc7154":"markdown","ab348748":"markdown","f2cdbc77":"markdown","7833db2c":"markdown","9c21fa7c":"markdown","3a19915e":"markdown","8e529d25":"markdown","193f2359":"markdown"},"source":{"9329fccb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","79f5c7ec":"df = pd.read_csv('\/kaggle\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = 500_000, \n                   parse_dates = ['pickup_datetime']).drop(columns = 'key')\n\n# Remove na\ndf = df.dropna()\ndf.head()","e491f5ef":"df.describe()","43543c12":"plt.figure(figsize = (10,8))\nplt.hist(df['fare_amount'])\nplt.title('Fare Distribution')","ac179be7":"print(f\"Number of negative fares: {len(df[df['fare_amount'] < 0])}\")\nprint(f\"Number of fares equal to 0: {len(df[df['fare_amount'] == 0])}\")","c9e6c64b":"df = df[df['fare_amount'].between(left = 2.5, right= df['fare_amount'].max())]","befb1c67":"def ecdf(x):\n    x = np.sort(x)\n    n = len(x)\n    # Going from 1\/n to 1\n    y = np.arange(1, n + 1, 1) \/ n\n    return x, y","bd909086":"x, y = ecdf(df['fare_amount'])\nplt.figure(figsize = (8, 6))\nplt.plot(x, y)\nplt.ylabel('Percentile'); \nplt.xlabel('Fare Amount');\nplt.title('Fare Amount ECDF'); ","1cd59f45":"df = df[df['fare_amount'].between(left = 2.5, right= 70)]","eab3d799":"x, y = ecdf(df['fare_amount'])\nplt.figure(figsize = (8, 6))\nplt.plot(x, y)\nplt.ylabel('Percentile'); \nplt.xlabel('Fare Amount');\nplt.title('Fare Amount ECDF'); ","d3cc04f0":"df['passenger_count'].value_counts().plot.bar();\nplt.title('Passenger Counts')\nplt.xlabel('Passengers Numbers') \nplt.ylabel('Frequency')","898e084d":"df = df.loc[df['passenger_count'] < 6]","07b3c0e3":"fig, axes = plt.subplots(1, 2, figsize = (20, 8), sharex=True, sharey=True)\naxes = axes.flatten()\n\n# Plot Longitude (x) and Latitude (y)\nsns.regplot('pickup_longitude', 'pickup_latitude', fit_reg = False, \n            data = df, ax = axes[0]);\nsns.regplot('dropoff_longitude', 'dropoff_latitude', fit_reg = False, \n            data = df, ax = axes[1]);\naxes[0].set_title('Pickup Locations')\naxes[1].set_title('Dropoff Locations');","de2ccd0b":"# Absolute difference in latitude and longitude\ndf['abs_lat_diff'] = (df['dropoff_latitude'] - df['pickup_latitude']).abs()\ndf['abs_lon_diff'] = (df['dropoff_longitude'] - df['pickup_longitude']).abs()","09d20fa3":"sns.lmplot('abs_lat_diff', 'abs_lon_diff', fit_reg = False, data = df)\nplt.title('Absolute latitude difference vs Absolute longitude difference')","eb716508":"zero_diff = df[(df['abs_lat_diff'] == 0) & (df['abs_lon_diff'] == 0)]\nzero_diff.shape","0dfff079":"def minkowski_distance(x1, x2, y1, y2, p):\n    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 \/ p)","adb0e718":"df['euclidean'] = minkowski_distance(df['pickup_longitude'], df['dropoff_longitude'],\n                                       df['pickup_latitude'], df['dropoff_latitude'], 2)","a7e1a61f":"plt.figure(figsize = (10,8))\nplt.hist(df['euclidean'])\nplt.title('Euclidean Distance Distribution')\nax = plt.subplot(111)\nax.set_xlim([0, 500])","97d35731":"plt.figure(figsize = (10, 6))\n\nfor p, grouped in df.groupby('passenger_count'):\n    sns.kdeplot(grouped['fare_amount'], label = f'{p} passengers');\n    \nplt.xlabel('Fare Amount'); plt.ylabel('Density')\nplt.title('Distribution of Fare Amount by Number of Passengers');","364e4efa":"df.groupby('passenger_count')['fare_amount'].agg(['mean', 'count'])","49351a55":"df.groupby('passenger_count')['fare_amount'].mean().plot.bar(color = 'b');\nplt.title('Average Fare by Passenger Count');","89451efb":"# Radius of the earth in kilometers\nR = 6378\n\ndef haversine_np(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n\n    All args must be of equal length.    \n    \n    source: https:\/\/stackoverflow.com\/a\/29546836\n\n    \"\"\"\n    # Convert latitude and longitude to radians\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    # Find the differences\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    # Apply the formula \n    a = np.sin(dlat\/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon\/2.0)**2\n    # Calculate the angle (in radians)\n    c = 2 * np.arcsin(np.sqrt(a))\n    # Convert to kilometers\n    km = R * c\n    \n    return km","f168afb9":"df['haversine'] =  haversine_np(df['pickup_longitude'], df['pickup_latitude'],\n                         df['dropoff_longitude'], df['dropoff_latitude']) ","c3f569ab":"sns.kdeplot(df['haversine']);","1906b712":"corrs = df.corr()\ncorrs['fare_amount'].plot.bar(color = 'b');\nplt.title('Correlation with Fare Amount');","b47a8bb1":"test = pd.read_csv('\/kaggle\/input\/new-york-city-taxi-fare-prediction\/test.csv', \n                   parse_dates = ['pickup_datetime'])\n\n# Create absolute differences\ntest['abs_lat_diff'] = (test['dropoff_latitude'] - test['pickup_latitude']).abs()\ntest['abs_lon_diff'] = (test['dropoff_longitude'] - test['pickup_longitude']).abs()\n\n# Save the id for submission\ntest_id = list(test.pop('key'))\n\ntest['euclidean'] = minkowski_distance(test['pickup_longitude'], test['dropoff_longitude'],\n                                       test['pickup_latitude'], test['dropoff_latitude'], 2)\n\ntest['haversine'] = haversine_np(test['pickup_longitude'], test['pickup_latitude'],\n                         test['dropoff_longitude'], test['dropoff_latitude'])\n\ntest.describe()","6bc61418":"from sklearn.model_selection import train_test_split\n\n# Split data\nX_train, X_valid, y_train, y_valid = train_test_split(df, np.array(df['fare_amount']), \n                                                      test_size = 0.30)","105ab0f3":"import xgboost as xgb\n\nxgbr = xgb.XGBRegressor()\nxgbr.fit(X_train[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']], y_train)","f5399742":"from sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore', category = RuntimeWarning)\n\ndef metrics(train_pred, valid_pred, y_train, y_valid):\n    \"\"\"Calculate metrics:\n       Root mean squared error and mean absolute percentage error\"\"\"\n    \n    # Root mean squared error\n    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))\n    \n    # Calculate absolute percentage error\n    train_ape = abs((y_train - train_pred) \/ y_train)\n    valid_ape = abs((y_valid - valid_pred) \/ y_valid)\n    \n    # Account for y values of 0\n    train_ape[train_ape == np.inf] = 0\n    train_ape[train_ape == -np.inf] = 0\n    valid_ape[valid_ape == np.inf] = 0\n    valid_ape[valid_ape == -np.inf] = 0\n    \n    train_mape = 100 * np.mean(train_ape)\n    valid_mape = 100 * np.mean(valid_ape)\n    \n    return train_rmse, valid_rmse, train_mape, valid_mape\n\ndef evaluate(model, features, X_train, X_valid, y_train, y_valid):\n    \"\"\"Mean absolute percentage error\"\"\"\n    \n    # Make predictions\n    train_pred = model.predict(X_train[features])\n    valid_pred = model.predict(X_valid[features])\n    \n    # Get metrics\n    train_rmse, valid_rmse, train_mape, valid_mape = metrics(train_pred, valid_pred,\n                                                             y_train, y_valid)\n    \n    print(f'Training:   rmse = {round(train_rmse, 2)} \\t mape = {round(train_mape, 2)}')\n    print(f'Validation: rmse = {round(valid_rmse, 2)} \\t mape = {round(valid_mape, 2)}')","af02f15d":"evaluate(xgbr, ['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count'],\n         X_train, X_valid, y_train, y_valid)","c26d84ae":"preds = xgbr.predict(test[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']])\n\nsub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\nsub.to_csv('sub_rf_simple.csv', index = False)\n\nsns.distplot(sub['fare_amount'])\nplt.title('Distribution of Random Forest Predicted Fare Amount');","11cc7154":"## Feature Engineering","ab348748":"## Data Exploration and Data Cleaning","f2cdbc77":"### Haversine distance","7833db2c":"The Empirical Comulative Distribution Function (ECDF) can be used to show distributions of a single variable. ECDF shows the variable on the X axis and the Percentile on the Y axis.","9c21fa7c":"# New York City Taxi Fare Prediction","3a19915e":"This notebook was inspired from the \"Another Machine Learning Walk-Through and a Challenge\" by Will Koehrsen.\n\n- https:\/\/towardsdatascience.com\/another-machine-learning-walk-through-and-a-challenge-8fae1e187a64","8e529d25":"### Empirical Comulative Distribution Function","193f2359":"### Adding Featured Engineered Features to Test Data"}}