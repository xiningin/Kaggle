{"cell_type":{"964e9e41":"code","2c948ebd":"code","a6cb0e69":"code","13370690":"code","79999c13":"code","689ae2d1":"code","f347ebb1":"code","dc6e8cf3":"code","eb371188":"code","1ad53d2d":"code","3b0bb074":"code","090deb9b":"code","b112234e":"code","bf83938d":"code","b6deff68":"code","646671a9":"code","0ba49bb1":"code","c764494c":"code","541af20c":"code","91c401c8":"code","595b7915":"code","9f77aaaf":"code","aba5e98b":"code","a80ee716":"code","7b3349cd":"code","97fb57df":"code","89844416":"code","41df9c32":"code","5ee00e1c":"code","502937e9":"code","286ee453":"code","aa9cac77":"code","91b3ed04":"code","a5d544ee":"code","a57b143c":"code","613dff7a":"code","87161fd0":"code","7a75dbce":"code","e8b8153e":"markdown","dc712c30":"markdown","6faa497d":"markdown","4daccfa3":"markdown","d0785239":"markdown","731321fd":"markdown","d1031ea4":"markdown","0c898911":"markdown","a474959e":"markdown","ec3f7fe2":"markdown","36a6f2ca":"markdown","c7730283":"markdown","a0b3174c":"markdown","c2d50974":"markdown","5432c744":"markdown","654b532e":"markdown","10dcb150":"markdown","91ec88d2":"markdown"},"source":{"964e9e41":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","2c948ebd":"text_0=pd.read_csv('..\/input\/emg-4\/0.csv', header=None)\ntext_1=pd.read_csv('..\/input\/emg-4\/1.csv', header=None)\ntext_2=pd.read_csv('..\/input\/emg-4\/2.csv', header=None)\ntext_3=pd.read_csv('..\/input\/emg-4\/3.csv', header=None)","a6cb0e69":"text_0.head()","13370690":"text_1.head()","79999c13":"text_2.head()","689ae2d1":"text_3.head()","f347ebb1":"text_0.shape, text_1.shape, text_2.shape, text_3.shape","dc6e8cf3":"text_0.iloc[:,-1].value_counts()==2910, text_1.iloc[:,-1].value_counts()==2903, text_2.iloc[:,-1].value_counts()==2943, text_3.iloc[:,-1].value_counts()==2922","eb371188":"print('Number of null values in text_0: ',text_0.isna().sum().sum()),\nprint('Number of null values in text_1: ',text_1.isna().sum().sum()),\nprint('Number of null values in text_2: ',text_2.isna().sum().sum()),\nprint('Number of null values in text_3: ',text_3.isna().sum().sum())","1ad53d2d":"allFiles=['..\/input\/emg-4\/0.csv','..\/input\/emg-4\/1.csv','..\/input\/emg-4\/2.csv','..\/input\/emg-4\/3.csv']\n\nlist = []\nfor file in allFiles:\n    read = pd.read_csv(file, header = None)\n    list.append(read)\ndf = pd.concat(list)","3b0bb074":"df.shape","090deb9b":"sns.countplot(x=64,data=df)","b112234e":"def read_data():\n    print(allFiles)\n    list = []\n    for file in allFiles:\n        read = pd.read_csv(file, header = None)\n        list.append(read)\n    df = pd.concat(list)\n    X = df.iloc[:, :-1].values\n    Y = df.iloc[:, -1].values\n    from sklearn.model_selection import train_test_split\n    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.15)\n    return Xtrain, Xtest, Ytrain, Ytest","bf83938d":"X_train, X_test, y_train, y_test = read_data()","b6deff68":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","646671a9":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import label_binarize","0ba49bb1":"from sklearn.preprocessing import StandardScaler\ns = StandardScaler()","c764494c":"X_train_s = s.fit_transform(X_train)\nX_test_s = s.transform(X_test)","541af20c":"from sklearn.svm import SVC","91c401c8":"svc= SVC(kernel='rbf',C=15,gamma=0.01,decision_function_shape='ovr',probability=True)\nsvc.fit(X_train_s,y_train)\ny_pred_svm=svc.predict(X_test_s)","595b7915":"y_pred_svm=svc.predict(X_test_s).T\npd.DataFrame(y_pred_svm,columns=['Class predicted']).head(10)","9f77aaaf":"print(classification_report(y_test,y_pred_svm))","aba5e98b":"import warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","a80ee716":"from sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(oob_score=True,\n                            random_state=42,\n                            warm_start=True,\n                            n_jobs=-1)\noob_list = []\nfor n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n    RF.set_params(n_estimators=n_trees)\n    RF.fit(X_train_s, y_train)\n    oob_error = 1 - RF.oob_score_\n    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n\nrf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\nrf_oob_df","7b3349cd":"sns.set_context('talk')\nsns.set_style('white')\n\nax = rf_oob_df.plot(legend=False, marker='o', figsize=(14, 7), linewidth=5)\nax.set(ylabel='out-of-bag error');","97fb57df":"RF_300 = RandomForestClassifier(n_estimators=300\n          ,oob_score=True \n          ,random_state=42\n          ,n_jobs=-1)\n\nRF_300.fit(X_train_s,y_train)\noob_error300 = 1 - RF_300.oob_score_\noob_error300","89844416":"y_pred_rf=RF_300.predict(X_test_s)","41df9c32":"y_pred_rf=RF_300.predict(X_test_s).T\npd.DataFrame(y_pred_rf,columns=['Class predicted']).head(10)","5ee00e1c":"print(classification_report(y_test,y_pred_rf))","502937e9":"!pip install catboost","286ee453":"from catboost import Pool, CatBoostClassifier","aa9cac77":"model = CatBoostClassifier(iterations=300,\n                           learning_rate=0.7,\n                           random_seed=42,\n                           depth=5)\n\nmodel.fit(X_train_s, y_train, \n          cat_features=None, \n          eval_set=(X_test_s, y_test), \n          verbose=False)","91b3ed04":"prediction=model.predict(X_test_s)","a5d544ee":"prediction","a57b143c":"print(classification_report(y_test,prediction))","613dff7a":"metrics = []\nmodels = ['Support Vector Classifier', 'Random Forest', 'Catboost']\npredictions=[y_pred_svm, y_pred_rf, prediction]\n\nfor lab,i in zip(models, predictions):\n    precision, recall, fscore, _ = score(y_test, i, average='weighted')\n    accuracy = accuracy_score(y_test, i)\n    auc = roc_auc_score(label_binarize(y_test, classes=[0,1,2,3]),\n                        label_binarize(i, classes=[0,1,2,3]),\n                        average='weighted')\n    metrics.append(pd.Series({'precision':precision, 'recall':recall,\n                              'fscore':fscore, 'accuracy':accuracy,\n                              'auc':auc}, name=lab))\n    \nmetrics = pd.concat(metrics, axis=1)","87161fd0":"metrics","7a75dbce":"from sklearn.metrics import confusion_matrix\n\nf,ax = plt.subplots(figsize=(15, 15))\nconfusion_mtx = confusion_matrix(y_test,prediction)\nsns.set(font_scale=1.4)\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\",ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix Validation set\")\nplt.show()","e8b8153e":"# Introduction: \nThe following project aims to build a complex and robust model which could be able to classify with minimum error hand gestures. The dataset contains more than 11k instances where each one corresponds to a measurement obtained by a medical diagnostic procedure called Electromyography (EMG) in which through transducers is gathered electrical activity from muscles. The current dataset contains measurements for 4 different classes where 0:Rock, 1:Scissors, 2:Paper, 3:Ok. \n\n","dc712c30":"Let's dive deeper into the 4 different classes (0:Rock, 1:Scissors, 2:Paper, 3:Ok).\nOne big suggestion I will give in order to tackle the misclassifications in class 2 and 3 is to add another transducer which can measure the activity of the thumb, because this has to bend when doing 'Ok' (muscular contraction means higher electrical magnitude), whereas 'Paper' has all fingers opened (relaxed) and therefore thumb will have low magnitude. Adding more transducers and instances could improve our prediction significantly. ","6faa497d":"Checking if there is any null value in the four files:","4daccfa3":"As we see above Catboost had the highest metrics, this confirms why it's widely used and prefered in the data science community. To finish I will print the confusion matrix of this model as a heat map:","d0785239":"The matrix confirms the problems our models had to classify correctly the classes 2 and 3, which is the main reason it couldn't reach a better accuracy. In order to reduce such misclassifications another approach must be taken.","731321fd":"## SVC","d1031ea4":"Above we can see the four files contain 65 columns, the first 64 correspond to the measurement of 8 transducers from the EMG, whereas the last one is the class of the instance. Below I am showing the shape of each file, take into account that these contain different number of instances, but in proportion are balanced.","0c898911":"Defining a function which can read the files, concatenate them, define features and labels and finally split into training and testing sets:","a474959e":"As we all know the data must be scaled before being fed to the model and the method used is standardization:","ec3f7fe2":"Let's begin by reading the csv files with header=None, so as to create one with column names from 0 to 64:","36a6f2ca":"The line below prints True for each class if all instances of each file belong to only one class:","c7730283":"The joined dataset should contain 11678 instances and 65 columns. Let's see a countplot of each class:","a0b3174c":"## Catboost Classifier:","c2d50974":"The next line prints the shape of each set created, we can confirm that the function has worked properly and our data is ready to be used by our model.","5432c744":"## Random Forest","654b532e":"Wow!, Catboost has a significantly better performance compared to the previous models, let's see more error metrics for these models summarized into a table:","10dcb150":"# Modeling\n\nThe following models will be built and compared using their corresponding error measurements:\n\n1.   SVC with RBF kernel.\n2.   Random Forest with the best number of trees.\n3.   Catboost with best hyperparameters.\n\n\nBefore building the different models let's declare some error metrics in order to compare the performace of each one:","91ec88d2":"Defining a list containing the path of the files in a list in order to be concatenated and used as only one file:"}}