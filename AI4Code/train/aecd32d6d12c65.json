{"cell_type":{"38cb6abd":"code","677999be":"code","73297e83":"code","9afd55f1":"code","7b8d62f8":"code","bb6c58dd":"code","7c56cec8":"code","3863a45b":"code","26edcb5d":"code","6d165aa4":"code","e66718d7":"code","7e0c48da":"code","1502c27c":"code","f8031834":"code","bd13b45c":"code","a69b6357":"code","dcf0bc79":"code","7f582782":"code","b964d614":"code","046578d6":"code","b67657d9":"markdown","d0654707":"markdown","539e495b":"markdown","5013e738":"markdown","4cf20f1c":"markdown","7dd39320":"markdown","8599bd4d":"markdown","020a7cbe":"markdown","63432790":"markdown","87dfc1a5":"markdown","23066b2c":"markdown","b5f460a4":"markdown","9645b6ea":"markdown","321fb786":"markdown","bb0eede8":"markdown","0529da5b":"markdown","62fb0ff1":"markdown","41e61601":"markdown","2789c7af":"markdown","1d2a86db":"markdown"},"source":{"38cb6abd":"!pip install hyperopt\n!pip install mlflow\n!pip install pyspark\n!pip install findspark","677999be":"import mlflow\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.metrics\nimport sklearn.model_selection\nimport sklearn.ensemble\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\nfrom sklearn.feature_selection import f_classif, chi2\nimport pyspark\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom scipy.stats import shapiro\nimport warnings\n\nwarnings.filterwarnings('ignore')","73297e83":"data = pd.read_csv('..\/input\/water-potability\/water_potability.csv')","9afd55f1":"data.info()","7b8d62f8":"fig, ax = plt.subplots(figsize=(15, 10))\ndata.hist(grid=True,ax=ax)","bb6c58dd":"##################################### PH #####################################\n\nphMean_0 = data[data['Potability'] == 0]['ph'].mean(skipna=True)\ndata.loc[(data['Potability'] == 0) & (data['ph'].isna()), 'ph'] = phMean_0\nphMean_1 = data[data['Potability'] == 1]['ph'].mean(skipna=True)\ndata.loc[(data['Potability'] == 1) & (data['ph'].isna()), 'ph'] = phMean_1\n\n##################################### Sulfate #####################################\n\nSulfateMean_0 = data[data['Potability'] == 0]['Sulfate'].mean(skipna=True)\ndata.loc[(data['Potability'] == 0) & (data['Sulfate'].isna()), 'Sulfate'] = SulfateMean_0\nSulfateMean_1 = data[data['Potability'] == 1]['Sulfate'].mean(skipna=True)\ndata.loc[(data['Potability'] == 1) & (data['Sulfate'].isna()), 'Sulfate'] = SulfateMean_1\n\n################################ Trihalomethanes#####################################\n\nTrihalomethanesMean_0 = data[data['Potability'] == 0]['Trihalomethanes'].mean(skipna=True)\ndata.loc[(data['Potability'] == 0) & (data['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_0\nTrihalomethanesMean_1 = data[data['Potability'] == 1]['Trihalomethanes'].mean(skipna=True)\ndata.loc[(data['Potability'] == 1) & (data['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_1","7c56cec8":"data.corr().style.background_gradient(cmap='coolwarm')","3863a45b":"under = RandomUnderSampler(sampling_strategy=0.9)\nX, y = under.fit_resample(data.iloc[:,:-1], data.iloc[:,-1])","26edcb5d":"## standard scaler\nscaler = StandardScaler()\nscaler.fit(X)\nX_scaled=scaler.transform(X)\nX_scaled_df = pd.DataFrame(X_scaled, columns=data.columns[:-1])","6d165aa4":"# https:\/\/towardsdatascience.com\/mistakes-in-applying-univariate-feature-selection-methods-34c43ce8b93d\n\n# Our features are continous\n# as our target is categorical we can perform a ANOVA Test to check an linear depencies between features and the target\nN_continuous = 5\nN_categorical = 5\n\nf_scores = f_classif(X_scaled_df.values,y)\n_, p = f_scores\nmost_f = p.argsort()\nmost_dependent_numerical_variables = [X_scaled_df.columns[element] for element in most_f[:N_continuous]]\n\nmost_dependent_numerical_variables","e66718d7":"### Select the most important features\n\nX_selected = X_scaled_df[most_dependent_numerical_variables]\n               \nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n  X_selected,\n  y,\n  test_size=0.2,\n  random_state=0\n)\n\n\nwith mlflow.start_run(run_name='logistic_regression') as run:\n  model = LogisticRegression(C=0.2, class_weight='None', penalty='l2',\n                   solver='saga',random_state=0)\n  \n  # Models, parameters, and training metrics are tracked automatically\n  model.fit(X_train, y_train)\n\n  predicted_probs = model.predict_proba(X_test)\n  roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n  \n  # The AUC score on test data is not automatically logged, so log it manually\n  mlflow.log_metric(\"test_auc\", roc_auc)\n  print(\"Test AUC of: {}\".format(roc_auc))","7e0c48da":"# we split the data\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n  X,\n  y,\n  test_size=0.2,\n  random_state=0\n)","1502c27c":"#with mlflow.start_run(run_name='logistic_regression') as run:\n    #model_4 = LogisticRegression(random_state=0)\n  \n    # Models, parameters, and training metrics are tracked automatically\n    #model_4.fit(X_train, y_train)\n\n    #predicted_probs = model_4.predict_proba(X_test)\n    #roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n  \n    # The AUC score on test data is not automatically logged, so log it manually\n    #mlflow.log_metric(\"test_auc\", roc_auc)\n    #print(\"Test AUC of: {}\".format(roc_auc))","f8031834":"# GridSearch\nparam={'solver':('Newton-cg','lbfgs','liblinear', 'sag', 'saga'),'penalty':('l1', 'l2', 'elasticnet', 'none'),\n       'n_jobs':(-1,1,2,3),'class_weight':('balanced','None'),\n       'C':(0.2, 0.1, 0.15, 0.12, 0.3, 0.4, 0.6, 0.5, 1, 1.2, .3, 1.4, 1.5),\n       'max_iter':(100, 150, 200)}\n\nh = GridSearchCV(LogisticRegression(), param, cv=5, n_jobs=5).fit(X_train, y_train)\n\nh.best_estimator_","bd13b45c":"with mlflow.start_run(run_name='logistic_regression') as run:\n  model_3 =LogisticRegression(C=0.3, class_weight='None', penalty='l1',\n                   solver='saga',max_iter=150,random_state=0)\n  \n  # Models, parameters, and training metrics are tracked automatically\n  model_3.fit(X_train, y_train)\n\n  predicted_probs = model_3.predict_proba(X_test)\n  roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n  \n  # The AUC score on test data is not automatically logged, so log it manually\n  mlflow.log_metric(\"test_auc\", roc_auc)\n  print(\"Test AUC of: {}\".format(roc_auc))","a69b6357":"with mlflow.start_run(run_name='gradient_boost') as run:\n  model_2 = sklearn.ensemble.GradientBoostingClassifier(\n    random_state=0, \n    \n    # Try a new parameter setting for n_estimators\n    n_estimators=200,\n  )\n  model_2.fit(X_train, y_train)\n\n  predicted_probs = model_2.predict_proba(X_test)\n  roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n  mlflow.log_metric(\"test_auc\", roc_auc)\n  print(\"Test AUC of: {}\".format(roc_auc))","dcf0bc79":"clf = sklearn.ensemble.GradientBoostingClassifier(n_estimators=137, learning_rate=0.18,max_depth=3, random_state=0)\n\nscoring = ['accuracy', 'roc_auc', 'f1', 'precision', 'recall']\n\nresult = cross_validate(clf, X_train, y_train, cv=5, scoring=scoring, return_estimator=True)\n\nprint(\"Accuracy confidence interval: {} +- {}\".format(result['test_accuracy'].mean(), result['test_accuracy'].std()))\nprint(\"ROC AUC confidence interval: {} +- {}\".format(result['test_roc_auc'].mean(), result['test_roc_auc'].std()))\nprint(\"F1 confidence interval: {} +- {}\".format(result['test_f1'].mean(), result['test_f1'].std()))\nprint(\"Precison confidence interval: {} +- {}\".format(result['test_precision'].mean(), result['test_precision'].std()))\nprint(\"Recall confidence interval: {} +- {}\".format(result['test_recall'].mean(), result['test_recall'].std()))","7f582782":"result = cross_validate(clf, X_test, y_test, cv=5, scoring=scoring, return_estimator=True)\n\nprint(\"Accuracy confidence interval: {} +- {}\".format(result['test_accuracy'].mean(), result['test_accuracy'].std()))\nprint(\"ROC AUC confidence interval: {} +- {}\".format(result['test_roc_auc'].mean(), result['test_roc_auc'].std()))\nprint(\"F1 confidence interval: {} +- {}\".format(result['test_f1'].mean(), result['test_f1'].std()))\nprint(\"Precison confidence interval: {} +- {}\".format(result['test_precision'].mean(), result['test_precision'].std()))\nprint(\"Recall confidence interval: {} +- {}\".format(result['test_recall'].mean(), result['test_recall'].std()))","b964d614":"def train_model(params):\n  mlflow.autolog()\n  with mlflow.start_run(nested=True):\n    model_hp = sklearn.ensemble.GradientBoostingClassifier(\n      random_state=0,\n      **params\n    )\n    model_hp.fit(X_train, y_train)\n    predicted_probs = model_hp.predict_proba(X_test)\n    # Tune based on the test AUC\n    # In production settings, you could use a separate validation set instead\n    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n    mlflow.log_metric('test_auc', roc_auc)\n    \n    # Set the loss to -1*auc_score so fmin maximizes the auc_score\n    return {'status': STATUS_OK, 'loss': -1*roc_auc}\n\n# SparkTrials distributes the tuning using Spark workers\n# Greater parallelism speeds processing, but each hyperparameter trial has less information from other trials\n# i choose parallelism =2\n#spark_trials = SparkTrials(\n  #parallelism=4\n#)\n\nsearch_space = {\n  'n_estimators': scope.int(hp.quniform('n_estimators', 20, 1000, 1)),\n  'learning_rate': hp.loguniform('learning_rate', -3, 0),\n  'max_depth': scope.int(hp.quniform('max_depth', 2, 5, 1)),\n}\n\n\nwith mlflow.start_run(run_name='gb_hyperopt') as run:\n  # Use hyperopt to find the parameters yielding the highest AUC\n  best_params = fmin(\n    fn=train_model, \n    space=search_space, \n    algo=tpe.suggest, \n    max_evals=32)","046578d6":"#best_run = mlflow.search_runs(\n#  order_by=['metrics.test_auc DESC', 'start_time DESC'],\n#  max_results=10,\n#).iloc[0]\n#print('Best Run')\n#print('AUC: {}'.format(best_run[\"metrics.test_auc\"]))\n#print('Num Estimators: {}'.format(best_run[\"params.n_estimators\"]))\n#print('Max Depth: {}'.format(best_run[\"params.max_depth\"]))\n#print('Learning Rate: {}'.format(best_run[\"params.learning_rate\"]))","b67657d9":"# Let's check correlation","d0654707":"# Gradient Boosting","539e495b":"## Gradient Boosting with MLflow","5013e738":"we have not significant correlation between features","4cf20f1c":"# Logistic Regression","7dd39320":"# Replace Nan with means with respect to their class","8599bd4d":"### let's train and evaluate  our model","020a7cbe":"we can see that the data is unbalanced. More we have some missing values to deal with.\n\nwe shall replace this Nan with the means","63432790":"# Import Data","87dfc1a5":"### Logistic regression with the selected features and Mlflow","23066b2c":"# Undersampling","b5f460a4":"AUC is lesser than before","9645b6ea":"# First Exploration","321fb786":"## first we scale the data as the features are continuous","bb0eede8":"## Train LR model with MLflow (all features)","0529da5b":"## Parallel training with Hyperopt and SparkTrials (need to set up spark)","62fb0ff1":"## GreadSearch+Logistic Regression","41e61601":"# Let's train some models","2789c7af":"### let's train and evaluate our model with mlflow","1d2a86db":"## we first try to select some feature to train a logistic regression"}}