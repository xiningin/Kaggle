{"cell_type":{"d203fc02":"code","74ad540a":"code","9dbd9432":"code","35229a2f":"code","4e349b6d":"code","2eea225a":"code","0385b1a8":"code","88be0047":"code","d2c3f7b5":"code","93002a20":"code","83075a18":"code","95d2ddfb":"code","be37605c":"code","3433840b":"code","3ccf3dac":"code","bb755647":"code","c903be92":"code","87c9d8e6":"code","8c04125e":"code","c883df7b":"code","87779d8b":"code","352fb112":"code","05d3d06c":"code","8260e896":"code","e826e5e7":"code","540e3dce":"code","44b5f1f4":"code","d0e01440":"code","b37921e4":"code","41c36b7c":"code","242ee504":"code","cd8d7cb5":"code","617d7c0b":"code","7ada2e61":"code","dfbfddf6":"code","5d247060":"code","0e6d1581":"code","1aad2992":"code","1b090d43":"code","7e1cf9bf":"code","68b904d6":"code","be210a5b":"code","1f62488b":"code","9f5a8254":"code","3168f98f":"code","833af0cf":"code","e2226bdb":"code","941a274e":"code","23e9a656":"code","9bc4063a":"code","3916c1b3":"code","60d0c215":"code","bd7eb35d":"code","77924ecc":"code","c35c835f":"code","13a67e25":"code","030fe5c3":"code","82d9070e":"code","21364feb":"code","869ae172":"code","ce32c3dd":"code","7c6ff44f":"code","b438a92b":"code","66cb90a1":"code","eb81e447":"code","6d42f807":"code","5767b471":"code","122a02d5":"code","3f3b6430":"code","7d06d01d":"code","a613e13e":"code","9936062a":"code","7b28ba20":"code","487022ff":"code","1f007220":"code","7bd4a02d":"code","ba6149b4":"code","304f2c93":"markdown","3477908c":"markdown","a3a60f85":"markdown","51706e76":"markdown","7b42dfa5":"markdown","9b4cee7b":"markdown","91e3af22":"markdown","280ba215":"markdown","a5ec4cad":"markdown","83c64168":"markdown","b1710290":"markdown","be8a21f0":"markdown","18e89e93":"markdown","119c9752":"markdown","c183e682":"markdown","0626a8f3":"markdown","6ca0aded":"markdown"},"source":{"d203fc02":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","74ad540a":"testdf = pd.read_csv(\"..\/input\/mobile-price-classification\/test.csv\")\ntraindf = pd.read_csv(\"..\/input\/mobile-price-classification\/train.csv\")","9dbd9432":"traindf.head(10)","35229a2f":"testdf.head(10)","4e349b6d":"print(traindf['px_height'].all())","2eea225a":"traindf['px_height'].replace(0, traindf['px_height'].mean(), inplace=True)","0385b1a8":"print(traindf['px_height'].all())","88be0047":"traindf['px_size'] = np.round((traindf['px_height'] * traindf['px_width']), 2)\ntraindf.head()","d2c3f7b5":"traindf['px_size'] = traindf['px_size'] \/ 926","93002a20":"traindf.head()","83075a18":"testdf.head()","95d2ddfb":"ids = testdf['id'] \ntestdf.drop('id', inplace=True, axis=1)","be37605c":"traindf.drop(labels=['blue', 'dual_sim', 'm_dep', 'mobile_wt', 'talk_time', 'px_height', 'px_width'], inplace=True, axis=1)\ntestdf.drop(labels=['blue', 'dual_sim', 'm_dep', 'mobile_wt', 'talk_time', 'px_height', 'px_width'], inplace=True, axis=1)","3433840b":"print(traindf['sc_h'].all())\nprint(traindf['sc_w'].all())","3ccf3dac":"traindf['sc_w'].replace(0, int(traindf['sc_w'].mean()), inplace=True)","bb755647":"print(traindf['sc_w'].all())","c903be92":"traindf['sc_size'] = np.round((traindf['sc_h'] * traindf['sc_w']), 2)\ntraindf.drop(['sc_h', 'sc_w'], axis=1, inplace=True)","87c9d8e6":"traindf.head(10)","8c04125e":"traindf.shape","c883df7b":"traindf.all()","87779d8b":"traindf['pc'].replace(0, np.round(traindf['pc'].mean(), 0), inplace=True)","352fb112":"traindf.head()","05d3d06c":"traindf['pc'].head()","8260e896":"traindf.all()","e826e5e7":"traindf.head()","540e3dce":"testdf.head()","44b5f1f4":"testdf['sc_w'].replace(0, int(testdf['sc_w'].mean()), inplace=True)","d0e01440":"print(testdf['sc_w'].all())","b37921e4":"print(testdf['sc_h'].all())","41c36b7c":"testdf['sc_size'] = np.round((testdf['sc_h'] * testdf['sc_w']), 0)\ntestdf.drop(['sc_h', 'sc_w'], axis=1, inplace=True)","242ee504":"testdf.head()","cd8d7cb5":"traindf.head()","617d7c0b":"traindf.drop(['px_size'], axis=1, inplace=True)","7ada2e61":"traindf.head()","dfbfddf6":"testdf.head()","5d247060":"testdf.shape","0e6d1581":"traindf.shape","1aad2992":"y_train = traindf['price_range']\ntraindf.drop(['price_range'], inplace=True, axis=1)","1b090d43":"y_train.shape","7e1cf9bf":"y_train = pd.DataFrame(y_train)","68b904d6":"y_train.head()","be210a5b":"X_train = traindf","1f62488b":"X_train.shape","9f5a8254":"X_train.head()","3168f98f":"X_test = testdf","833af0cf":"X_test.shape","e2226bdb":"X_test.head()","941a274e":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","23e9a656":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","9bc4063a":"accuracyDetails = {}","3916c1b3":"cv = KFold(n_splits=10, random_state=1, shuffle=True)","60d0c215":"model = RandomForestClassifier(n_estimators = 40)\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","bd7eb35d":"print(scores*100)","77924ecc":"print(\"Mean Accuracy for the Model using Random Forest = {}\".format(np.round(scores.mean()*100, 2)))","c35c835f":"accuracyDetails['Random Forest'] = np.round(scores.mean()*100, 2)","13a67e25":"model = SVC()\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","030fe5c3":"print(scores*100)","82d9070e":"print(\"Mean Accuracy for the Model using SVM = {}\".format(np.round(scores.mean()*100, 2)))","21364feb":"accuracyDetails['SVM'] = np.round(scores.mean()*100, 2)","869ae172":"model = KNeighborsClassifier(n_neighbors=7)\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","ce32c3dd":"print(scores*100)","7c6ff44f":"print(\"Mean Accuracy for the Model using KNN = {}\".format(np.round(scores.mean()*100, 2)))","b438a92b":"accuracyDetails['KNN'] = np.round(scores.mean()*100, 2)","66cb90a1":"model = LogisticRegression(solver='liblinear')\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","eb81e447":"print(scores*100)","6d42f807":"print(\"Mean Accuracy for the Model using Logistic Regression = {}\".format(np.round(scores.mean()*100, 2)))","5767b471":"accuracyDetails['Logistic Regression'] = np.round(scores.mean()*100, 2)","122a02d5":"print(accuracyDetails)","3f3b6430":"SVM = SVC()\nSVM.fit(X_train, y_train['price_range'])","7d06d01d":"y_pred = SVM.predict(X_test)","a613e13e":"df_y_pred = pd.DataFrame(y_pred)","9936062a":"df_y_pred.head()","7b28ba20":"y_pred.shape","487022ff":"X_test.shape","1f007220":"ans = pd.DataFrame([ids.T, y_pred.T], index=['id', 'price_range']).T","7bd4a02d":"ans.head()","ba6149b4":"ans.to_csv('My_Predictions.csv')","304f2c93":"### Random Forest's Cross validation","3477908c":"### X_test","a3a60f85":"### >> Feature Selection","51706e76":"### SVM's Cross validation","7b42dfa5":"## Saving model as My_Predictions.csv","9b4cee7b":"### Logistic Regression's Cross validation","91e3af22":"## Data Pre-processing","280ba215":"## Conclusion: Support Vector Machine works best here in this case because it performed best in k-fold cross validation","a5ec4cad":"## Reading Dataset","83c64168":"# Mobile Price Classification","b1710290":"### y_train","be8a21f0":"Problem Description:\n> Bob has started his own mobile company.\n> He wants to give a tough fight to big companies like Apple, Samsung, etc.\n> He does not know how to estimate the price of mobiles his company creates.\n> In this competitive mobile phone market you cannot simply assume things.\n> To solve this problem he collects sales data of mobile phones of various companies.\n\n> Bob wants to find out some relation between features of a mobile phone(eg:- RAM, Internal Memory, etc) and its selling price.\n> But he is not so good at Machine Learning. So he needs your help to solve this problem.\n\n> \"In this problem, you do not have to predict the actual price but a price range indicating how high the price is.\"\n\nMy Solution:\n> As there is no target test data provided, I opted to go with K-Fold cross-validation first for most of the popular classification algorithms which include SVM, KNN, Random Forest, & Logistic Regression, and the accuracies are 82.05%, 80.4%, 80.35% & 73.55% respectively.\n\n> Considering these metrics I opted for going with SVM among them.","18e89e93":"### KNN's Cross validation","119c9752":"### >> Feature Extraction","c183e682":"### X_train","0626a8f3":"# Using Support Vector Machine for Predictions","6ca0aded":"## Cross Validation using different Classification Algorithms to select best model"}}