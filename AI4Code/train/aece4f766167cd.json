{"cell_type":{"7e25e4a4":"code","6537ed63":"code","b9f68ffa":"code","10679c03":"code","9d245f7d":"code","ef338ec8":"code","615010ed":"markdown","a3210efa":"markdown","08c44bdc":"markdown","66f6bafb":"markdown","69ec69f1":"markdown","62d8337a":"markdown"},"source":{"7e25e4a4":"import os\nimport time\nimport cv2\n\nimport numpy as np\nimport tensorflow as tf\nimport h5py\nimport time\nimport inspect\nfrom skimage.transform import resize\nfrom skimage.measure import compare_psnr\nfrom skimage.measure import compare_ssim\n","6537ed63":"\n\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\n\nclass Vgg19:\n    def __init__(self, vgg19_npy_path=None):\n        self.data_dict = np.load('..\/input\/vgg19.npy', encoding='latin1').item()\n\n    def feature_map(self, rgb):\n        \"\"\"\n        load variable from npy to build the VGG\n\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        \"\"\"\n\n        start_time = time.time()\n        rgb_scaled = rgb * 255.0\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n\n        self.conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n        self.conv1_2 = self.conv_layer(self.conv1_1, \"conv1_2\")\n        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n\n        self.conv2_1 = self.conv_layer(self.pool1, \"conv2_1\")\n        self.conv2_2 = self.conv_layer(self.conv2_1, \"conv2_2\")\n        self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n\n        self.conv3_1 = self.conv_layer(self.pool2, \"conv3_1\")\n        self.conv3_2 = self.conv_layer(self.conv3_1, \"conv3_2\")\n        self.conv3_3 = self.conv_layer(self.conv3_2, \"conv3_3\")\n        self.conv3_4 = self.conv_layer(self.conv3_3, \"conv3_4\")\n        self.pool3 = self.max_pool(self.conv3_4, 'pool3')\n\n        self.conv4_1 = self.conv_layer(self.pool3, \"conv4_1\")\n        self.conv4_2 = self.conv_layer(self.conv4_1, \"conv4_2\")\n        self.conv4_3 = self.conv_layer(self.conv4_2, \"conv4_3\")\n        self.conv4_4 = self.conv_layer(self.conv4_3, \"conv4_4\")\n        self.pool4 = self.max_pool(self.conv4_4, 'pool4')\n\n        output = self.pool4\n\n        self.conv5_1 = self.conv_layer(self.pool4, \"conv5_1\")\n        self.conv5_2 = self.conv_layer(self.conv5_1, \"conv5_2\")\n        self.conv5_3 = self.conv_layer(self.conv5_2, \"conv5_3\")\n        self.conv5_4 = self.conv_layer(self.conv5_3, \"conv5_4\")\n        self.pool5 = self.max_pool(self.conv5_4, 'pool5')\n\n        return self.pool4\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n\n    def conv_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def get_conv_filter(self, name):\n        return tf.constant(self.data_dict[name][0], name=\"filter\")\n\n    def get_bias(self, name):\n        return tf.constant(self.data_dict[name][1], name=\"biases\")\n","b9f68ffa":"import tensorflow as tf\n\ndef Conv(input_, kernel_size, stride, output_channels, padding = 'SAME', mode = None):\n\n    with tf.variable_scope(\"Conv\") as scope:\n\n        input_channels = input_.get_shape()[-1]\n        kernel_shape = [kernel_size, kernel_size, input_channels, output_channels]\n\n        kernel = tf.get_variable(\"Filter\", shape = kernel_shape, dtype = tf.float32, initializer = tf.keras.initializers.he_normal())\n        \n        # Patchwise Discriminator (PatchGAN) requires some modifications.\n        if mode == 'discriminator':\n            input_ = tf.pad(input_, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"CONSTANT\")\n\n        return tf.nn.conv2d(input_, kernel, strides = [1, stride, stride, 1], padding = padding)\n\ndef TransposeConv(input_, output_channels, kernel_size = 4):\n\n    with tf.variable_scope(\"TransposeConv\") as scope:\n\n        input_height, input_width, input_channels = [int(d) for d in input_.get_shape()[1:]]\n        batch_size = tf.shape(input_)[0] \n\n        kernel_shape = [kernel_size, kernel_size, output_channels, input_channels]\n        output_shape = tf.stack([batch_size, input_height*2, input_width*2, output_channels])\n\n        kernel = tf.get_variable(name = \"filter\", shape = kernel_shape, dtype=tf.float32, initializer = tf.keras.initializers.he_normal())\n        \n        return tf.nn.conv2d_transpose(input_, kernel, output_shape, [1, 2, 2, 1], padding=\"SAME\")\n\ndef MaxPool(input_):\n    with tf.variable_scope(\"MaxPool\"):\n        return tf.nn.max_pool(input_, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\ndef AvgPool(input_, k = 2):\n    with tf.variable_scope(\"AvgPool\"):\n        return tf.nn.avg_pool(input_, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n\ndef ReLU(input_):\n    with tf.variable_scope(\"ReLU\"):\n        return tf.nn.relu(input_)\n\ndef LeakyReLU(input_, leak = 0.2):\n    with tf.variable_scope(\"LeakyReLU\"):\n        return tf.maximum(input_, leak * input_)\n\ndef BatchNorm(input_, isTrain, name='BN', decay = 0.99):\n    with tf.variable_scope(name) as scope:\n        return tf.contrib.layers.batch_norm(input_, is_training = isTrain, decay = decay)\n\ndef DropOut(input_, isTrain, rate=0.2, name='drop') :\n    with tf.variable_scope(name) as scope:\n        return tf.layers.dropout(inputs=input_, rate=rate, training=isTrain)\n","10679c03":"class GAN():\n\n    def __init__(self,lr,D_filters,layers,growth_rate,gan_wt,l1_wt,vgg_wt,restore,batch_size,decay,epochs,model_name,save_samples,sample_image_dir,A_dir,B_dir,custom_data,val_fraction,val_threshold,val_frequency,logger_frequency):\n        \n        self.num_discriminator_filters = D_filters\n        self.layers = layers\n        self.growth_rate = growth_rate\n        self.gan_wt = gan_wt\n        self.l1_wt = l1_wt\n        self.vgg_wt = vgg_wt\n        self.restore = restore\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.lr = lr\n        self.model_name = model_name\n        self.decay = decay\n        self.save_samples = save_samples\n        self.sample_image_dir = sample_image_dir\n        self.A_dir = A_dir\n        self.B_dir = B_dir\n        self.custom_data = custom_data\n        self.val_fraction = val_fraction\n        self.val_threshold = val_threshold\n        self.val_frequency = val_frequency\n        self.logger_frequency = logger_frequency\n        \n        self.EPS = 10e-12\n        self.score_best = -1\n        self.ckpt_dir = os.path.join(os.getcwd(), self.model_name, 'checkpoint')\n        self.tensorboard_dir = os.path.join(os.getcwd(), self.model_name, 'tensorboard')\n\n    def Layer(self, input_):\n        \"\"\"\n        This function creates the components inside a composite layer\n        of a Dense Block.\n        \"\"\"\n        with tf.variable_scope(\"Composite\"):\n            next_layer = BatchNorm(input_, isTrain = self.isTrain)\n            next_layer = ReLU(next_layer)\n            next_layer = Conv(next_layer, kernel_size = 3, stride = 1, output_channels = self.growth_rate)\n            next_layer = DropOut(next_layer, isTrain = self.isTrain, rate = 0.2)\n\n            return next_layer\n\n    def TransitionDown(self, input_, name):\n\n        with tf.variable_scope(name):\n\n            reduction = 0.5\n            reduced_output_size = int(int(input_.get_shape()[-1]) * reduction)\n\n            next_layer = BatchNorm(input_, isTrain = self.isTrain, decay = self.decay)\n            next_layer = Conv(next_layer, kernel_size = 1, stride = 1, output_channels = reduced_output_size)\n            next_layer = DropOut(next_layer, isTrain = self.isTrain, rate = 0.2)\n            next_layer = AvgPool(next_layer)\n\n            return next_layer\n\n    def TransitionUp(self, input_, output_channels, name):\n\n        with tf.variable_scope(name):\n            next_layer = TransposeConv(input_, output_channels = output_channels, kernel_size = 3)\n            \n            return next_layer\n\n    def DenseBlock(self, input_, name, layers = 4):\n\n        with tf.variable_scope(name):\n            for i in range(layers):\n                with tf.variable_scope(\"Layer\" + str(i + 1)) as scope:\n                    output = self.Layer(input_)\n                    output = tf.concat([input_, output], axis=3)\n                    input_ = output\n\n        return output\n\n    def generator(self, input_):\n        \"\"\"\n        54 Layer Tiramisu\n        \"\"\"\n        with tf.variable_scope('InputConv') as scope:\n            input_ = Conv(input_, kernel_size = 3, stride=1, output_channels = self.growth_rate * 4)\n\n        collect_conv = []\n\n        for i in range(1, 6):\n            input_ = self.DenseBlock(input_, name = 'Encoder' + str(i), layers = self.layers)\n            collect_conv.append(input_)\n            input_ = self.TransitionDown(input_, name = 'TD' + str(i))\n\n        input_ = self.DenseBlock(input_, name = 'BottleNeck', layers = 15)\n\n        for i in range(1, 6):\n            input_ = self.TransitionUp(input_, output_channels = self.growth_rate * 4, name = 'TU' + str(6 - i))\n            input_ = tf.concat([input_, collect_conv[6 - i - 1]], axis = 3, name = 'Decoder' + str(6 - i) + '\/Concat')\n            input_ = self.DenseBlock(input_, name = 'Decoder' + str(6 - i), layers = self.layers)\n\n        with tf.variable_scope('OutputConv') as scope:\n            output = Conv(input_, kernel_size = 1, stride = 1, output_channels = 3)\n\n        return tf.nn.tanh(output)\n\n    def discriminator(self, input_, target, stride = 2, layer_count = 4):\n        \"\"\"\n        Using the PatchGAN as a discriminator\n        \"\"\"\n        input_ = tf.concat([input_, target], axis=3, name='Concat')\n        layer_specs = self.num_discriminator_filters * np.array([1, 2, 4, 8])\n\n        for i, output_channels in enumerate(layer_specs, 1):\n\n            with tf.variable_scope('Layer' + str(i)) as scope:\n         \n                if i != 1:\n                    input_ = BatchNorm(input_, isTrain = self.isTrain)\n         \n                if i == layer_count:\n                    stride = 1\n         \n                input_ = LeakyReLU(input_)\n                input_ = Conv(input_, output_channels = output_channels, kernel_size = 4, stride = stride, padding = 'VALID', mode = 'discriminator')\n\n        with tf.variable_scope('Final_Layer') as scope:\n            output = Conv(input_, output_channels = 1, kernel_size = 4, stride = 1, padding = 'VALID', mode = 'discriminator')\n\n        return tf.sigmoid(output)\n\n    def build_vgg(self, img):\n\n        model = Vgg19()\n        img = tf.image.resize_images(img, [224, 224])\n        layer = model.feature_map(img)\n        return layer\n\n    def build_model(self):\n\n        with tf.variable_scope('Placeholders') as scope:\n            self.RealA = tf.placeholder(name='A', shape=[None, 256, 256, 3], dtype=tf.float32)\n            self.RealB = tf.placeholder(name='B', shape=[None, 256, 256, 3], dtype=tf.float32)\n            self.isTrain = tf.placeholder(name = \"isTrain\", shape = None, dtype = tf.bool)\n            self.step = tf.train.get_or_create_global_step()\n\n        with tf.variable_scope('Generator') as scope:\n            self.FakeB = self.generator(self.RealA)\n\n        with tf.name_scope('Real_Discriminator'):\n            with tf.variable_scope('Discriminator') as scope:\n                self.predict_real = self.discriminator(self.RealA, self.RealB)\n\n        with tf.name_scope('Fake_Discriminator'):\n            with tf.variable_scope('Discriminator', reuse=True) as scope:\n                self.predict_fake = self.discriminator(self.RealA, self.FakeB)\n\n        with tf.name_scope('Real_VGG'):\n            with tf.variable_scope('VGG') as scope:\n                self.RealB_VGG = self.build_vgg(self.RealB)\n\n        with tf.name_scope('Fake_VGG'):\n            with tf.variable_scope('VGG', reuse=True) as scope:\n                self.FakeB_VGG = self.build_vgg(self.FakeB)\n\n        with tf.name_scope('DiscriminatorLoss'):\n            self.D_loss = tf.reduce_mean(-(tf.log(self.predict_real + self.EPS) + tf.log(1 - self.predict_fake + self.EPS)))\n\n        with tf.name_scope('GeneratorLoss'):\n            self.gan_loss = tf.reduce_mean(-tf.log(self.predict_fake + self.EPS))\n            self.l1_loss = tf.reduce_mean(tf.abs(self.RealB - self.FakeB))\n            self.vgg_loss = (1e-5) * tf.losses.mean_squared_error(self.RealB_VGG, self.FakeB_VGG)\n\n            self.G_loss = self.gan_wt * self.gan_loss + self.l1_wt * self.l1_loss + self.vgg_wt * self.vgg_loss\n\n        with tf.name_scope('Summary'):\n            D_loss_sum = tf.summary.scalar('Discriminator Loss', self.D_loss)\n            G_loss_sum = tf.summary.scalar('Generator Loss', self.G_loss)\n            gan_loss_sum = tf.summary.scalar('GAN Loss', self.gan_loss)\n            l1_loss_sum = tf.summary.scalar('L1 Loss', self.l1_loss)\n            vgg_loss_sum = tf.summary.scalar('VGG Loss', self.gan_loss)\n            output_img = tf.summary.image('Output', self.FakeB, max_outputs = 1)\n            target_img = tf.summary.image('Target', self.RealB, max_outputs = 1)\n            input_img = tf.summary.image('Input', self.RealA, max_outputs = 1)\n\n            self.image_summary = tf.summary.merge([output_img, target_img, input_img])\n            self.G_summary = tf.summary.merge([gan_loss_sum, l1_loss_sum, vgg_loss_sum, G_loss_sum])\n            self.D_summary = D_loss_sum\n\n        with tf.name_scope('Variables'):\n            self.G_vars = [var for var in tf.trainable_variables() if var.name.startswith(\"Generator\")]\n            self.D_vars = [var for var in tf.trainable_variables() if var.name.startswith(\"Discriminator\")]\n\n        with tf.name_scope('Save'):\n            self.saver = tf.train.Saver(max_to_keep=3)\n\n        with tf.name_scope('Optimizer'):\n\n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n            with tf.control_dependencies(update_ops):\n\n                with tf.name_scope(\"Discriminator_Train\"):\n                    D_optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)\n                    self.D_grads_and_vars = D_optimizer.compute_gradients(self.D_loss, var_list = self.D_vars)\n                    self.D_train = D_optimizer.apply_gradients(self.D_grads_and_vars, global_step = self.step)\n\n                with tf.name_scope(\"Generator_Train\"):\n                    G_optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)\n                    self.G_grads_and_vars = G_optimizer.compute_gradients(self.G_loss, var_list = self.G_vars)\n                    self.G_train = G_optimizer.apply_gradients(self.G_grads_and_vars, global_step = self.step)\n\n    def train(self):\n\n        start_epoch = 0\n        logger_frequency = self.logger_frequency\n        val_frequency = self.val_frequency\n        val_threshold = self.val_threshold\n\n        if not os.path.exists(self.model_name):\n            os.mkdir(self.model_name)\n\n        print('Loading Model')\n        self.build_model()\n        print('Model Loaded')\n\n        print('Loading Data')\n\n        if self.custom_data:\n\n            # Please ensure that the input images and target images have\n            # the same filename.\n\n            data = sorted(os.listdir(self.A_dir))\n\n            total_image_count = int(len(data) * (1 - self.val_fraction))\n            batches = total_image_count \/\/ self.batch_size\n\n            train_data = data[: total_image_count]\n            val_data = data[total_image_count: ]\n            val_image_count = len(val_data)\n            \n            self.A_train = np.zeros((total_image_count, 256, 256, 3))\n            self.B_train = np.zeros((total_image_count, 256, 256, 3))\n            self.A_val = np.zeros((val_image_count, 256, 256, 3))\n            self.B_val = np.zeros((val_image_count, 256, 256, 3))\n\n            print(self.A_train.shape, self.A_val.shape)\n            dim=(256,256)\n            for i, file in enumerate(train_data):\n                im1= cv2.imread(os.path.join(os.getcwd(), self.A_dir, file), 1)\n                im1=cv2.resize(im1, dim, interpolation = cv2.INTER_AREA)\n                self.A_train[i] =im1.astype(np.float32)\n                #print(os.path.join(os.getcwd(), self.B_dir, file))\n                im2=cv2.imread(os.path.join(os.getcwd(), self.B_dir, file), 1)\n                print(im2.shape)\n                im2=cv2.resize(im2, dim, interpolation = cv2.INTER_AREA)\n                \n                self.B_train[i] = im2.astype(np.float32)\n              \n            for i, file in enumerate(val_data):\n                im3= cv2.imread(os.path.join(os.getcwd(), self.A_dir, file), 1)\n                im3=cv2.resize(im3, dim, interpolation = cv2.INTER_AREA)\n                self.A_val[i] = im3.astype(np.float32)\n                im4=cv2.imread(os.path.join(os.getcwd(), self.B_dir, file), 1)\n                im4=cv2.resize(im4, dim, interpolation = cv2.INTER_AREA)\n                self.B_val[i] = im4.astype(np.float32)\n              \n\n        else:\n    \n            self.A_train = np.load('..\/input\/A_train.npy').astype(np.float32)\n            self.B_train = np.load('..\/input\/B_train.npy').astype(np.float32)\n            self.A_val = np.load('..\/input\/A_val.npy').astype(np.float32)  # Valset 2\n            self.B_val = np.load('..\/input\/B_val.npy').astype(np.float32)\n\n            total_image_count = len(self.A_train)\n            val_image_count = len(self.A_val)\n            batches = total_image_count \/\/ self.batch_size\n\n        self.A_val = (self.A_val \/ 255) * 2 - 1\n        self.B_val = (self.B_val \/ 255) * 2 - 1\n        self.A_train = (self.A_train \/ 255) * 2 - 1\n        self.B_train = (self.B_train \/ 255) * 2 - 1\n    \n        print('Data Loaded')\n        \n\n        with tf.Session() as self.sess:\n\n            init_op = tf.global_variables_initializer()\n            self.sess.run(init_op)\n\n            if self.restore:\n                print('Loading Checkpoint')\n                ckpt = tf.train.latest_checkpoint(self.ckpt_dir)\n                self.saver.restore(self.sess, ckpt)\n                self.step = tf.train.get_or_create_global_step()\n                print('Checkpoint Loaded')\n\n            self.writer = tf.summary.FileWriter(self.tensorboard_dir, tf.get_default_graph())\n            total_parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables()])\n            G_parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables() if v.name.startswith(\"Generator\")])\n            D_parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables() if v.name.startswith(\"Discriminator\")])\n            loss_operations = [self.D_loss, self.G_loss, self.gan_loss, self.l1_loss, self.vgg_loss]\n\n            counts = self.sess.run([G_parameter_count, D_parameter_count, total_parameter_count])\n\n            print('Generator parameter count:', counts[0])\n            print('Discriminator parameter count:', counts[1])\n            print('Total parameter count:', counts[2])\n\n            # The variable below is divided by 2 since both the Generator \n            # and the Discriminator increases step count by 1\n            start = self.step.eval() \/\/ (batches * 2)\n\n            for i in range(start, self.epochs):\n\n                print('Epoch:', i)\n                shuffle = np.random.permutation(total_image_count)\n\n                for j in range(batches):\n\n                    if j != batches - 1:\n                        current_batch = shuffle[j * self.batch_size: (j + 1) * self.batch_size]\n                    else:\n                        current_batch = shuffle[j * self.batch_size: ]\n\n                    a = self.A_train[current_batch]\n                    b = self.B_train[current_batch]\n                    feed_dict = {self.RealA: a, self.RealB: b, self.isTrain: True}\n\n                    begin = time.time()\n                    step = self.step.eval()\n\n                    _, D_summary = self.sess.run([self.D_train, self.D_summary], feed_dict = feed_dict)\n\n                    self.writer.add_summary(D_summary, step)\n\n                    _, G_summary = self.sess.run([self.G_train, self.G_summary], feed_dict = feed_dict)\n\n                    self.writer.add_summary(G_summary, step)\n\n                    print('Time Per Step: ', format(time.time() - begin, '.3f'), end='\\r')\n\n                    if j % logger_frequency == 0:\n                        D_loss, G_loss, GAN_loss, L1_loss, VGG_loss = self.sess.run(loss_operations, feed_dict=feed_dict)\n\n                        GAN_loss = GAN_loss * self.gan_wt\n                        L1_loss = L1_loss * self.l1_wt\n                        VGG_loss = VGG_loss * self.vgg_wt\n\n                        trial_image_idx = np.random.randint(total_image_count)\n                        a = self.A_train[trial_image_idx]\n                        b = self.B_train[trial_image_idx]\n\n                        if a.ndim == 3:\n                            a = np.expand_dims(a, axis = 0)\n\n                        if b.ndim == 3:\n                            b = np.expand_dims(b, axis = 0)\n\n                        feed_dict = {self.RealA: a, self.RealB: b, self.isTrain: False}\n                        img_summary = self.sess.run(self.image_summary, feed_dict=feed_dict)\n                        self.writer.add_summary(img_summary, step)\n\n                        line = 'Batch: %d, D_Loss: %.3f, G_Loss: %.3f, GAN: %.3f, L1: %.3f, P: %.3f' % (\n                            j, D_loss, G_loss, GAN_loss, L1_loss, VGG_loss)\n                        print(line)\n\n                    # The variable `step` counts both D and G updates as individual steps.\n                    # The variable `G_D_step` counts one D update followed by a G update\n                    # as a single step.\n                    G_D_step = step \/\/ 2\n                    print('GD', G_D_step, 'val', val_threshold)\n\n                    if (val_threshold > G_D_step) and (j % val_frequency == 0):\n                        self.validate()\n\n\n    def validate(self):\n\n        total_ssim = 0\n        total_psnr = 0\n        psnr_weight = 1\/20\n        ssim_weight = 1\n        val_image_count = len(self.A_val)\n \n        for i in range(val_image_count):\n\n            x = np.expand_dims(self.A_val[i], axis = 0)\n            feed_dict = {self.RealA: x ,self.isTrain: False}\n            generated_B = self.FakeB.eval(feed_dict = feed_dict)\n\n            print('Validation Image', i, end = '\\r')\n\n            generated_B = (((generated_B[0] + 1)\/2) * 255).astype(np.uint8)\n            real_B = (((self.B_val[i] + 1)\/2)*255).astype(np.uint8)\n\n            psnr = compare_psnr(real_B, generated_B)\n            ssim = compare_ssim(real_B, generated_B, multichannel = True)\n\n            total_psnr = total_psnr + psnr\n            total_ssim = total_ssim + ssim\n\n        average_psnr = total_psnr \/ val_image_count\n        average_ssim = total_ssim \/ val_image_count\n\n        score = average_psnr * psnr_weight + average_ssim * ssim_weight\n\n\n        if(score > self.score_best):\n\n            self.score_best = score\n\n            self.saver.save(self.sess, os.path.join(self.ckpt_dir, 'gan'), global_step = self.step.eval())\n            line = 'Better Score: %.6f, PSNR: %.6f, SSIM: %.6f' %(score, average_psnr, average_ssim)\n            print(line)\n\n            with open(os.path.join(self.ckpt_dir, 'logs.txt'),'a') as f:\n                line += '\\n'\n                f.write(line)\n\n            if self.save_samples:\n\n                try:\n                    image_list = os.listdir(self.sample_image_dir)\n                    print(image_list)\n                except:\n                    print('Sample images not found. Terminating program')\n                    exit(0)\n                \n                for i, file in enumerate(image_list, 1):\n                    \n                    print('Sample Image', i, end = '\\r')\n\n                    x = cv2.imread(os.path.join(self.sample_image_dir, file), 1)\n                    x = (x\/255)*2 - 1\n                    x = np.reshape(x,(1,256,256,3))\n\n                    feed_dict = {self.RealA: x, self.isTrain: False}\n                    img = self.FakeB.eval(feed_dict = feed_dict)\n\n                    img = img[0,:,:,:]\n                    img = (((img + 1)\/2) * 255).astype(np.uint8)\n                    cv2.imwrite(os.path.join(self.ckpt_dir, file), img)\n\n    \n    def test(self, input_dir, GT_dir):\n\n        total_ssim = 0\n        total_psnr = 0\n        psnr_weight = 1\/20\n        ssim_weight = 1\n\n        GT_list = os.listdir(GT_dir)\n        input_list = os.listdir(input_dir)\n\n        print('Loading Model')\n        self.build_model()\n        print('Model Loaded')\n\n        with tf.Session() as self.sess:\n\n            init_op = tf.global_variables_initializer()\n            self.sess.run(init_op)\n\n            print('Loading Checkpoint')\n            ckpt = tf.train.latest_checkpoint(self.ckpt_dir)\n            self.saver.restore(self.sess, ckpt)\n            self.step = tf.train.get_or_create_global_step()\n            print('Checkpoint Loaded')\n\n            for i, (img_file, GT_file) in enumerate(zip(input_list, GT_list), 1):\n\n                img = cv2.imread(os.path.join(input_dir, img_file), 1)\n                GT = cv2.imread(os.path.join(GT_dir, GT_file), 1).astype(np.uint8)\n\n                print('Test image', i, end = '\\r')\n\n                img = ((np.expand_dims(img, axis = 0) \/ 255) * 2) - 1\n                feed_dict = {self.RealA: img, self.isTrain: False}\n                generated_B = self.FakeB.eval(feed_dict = feed_dict)\n                generated_B = (((generated_B[0] + 1)\/2) * 255).astype(np.uint8)        \n\n                psnr = compare_psnr(GT, generated_B)\n                ssim = compare_ssim(GT, generated_B, multichannel = True)\n\n                total_psnr = total_psnr + psnr\n                total_ssim = total_ssim + ssim\n\n            average_psnr = total_psnr \/ len(GT_list)\n            average_ssim = total_ssim \/ len(GT_list)\n\n            score = average_psnr * psnr_weight + average_ssim * ssim_weight\n\n            line = 'Score: %.6f, PSNR: %.6f, SSIM: %.6f' %(score, average_psnr, average_ssim)\n            print(line)\n\n\n    def inference(self, input_dir, result_dir):\n\n        input_list = os.listdir(input_dir)\n\n        if not os.path.exists(result_dir):\n            os.mkdir(result_dir)\n\n        print('Loading Model')\n        self.build_model()\n        print('Model Loaded')\n\n        with tf.Session() as self.sess:\n\n            init_op = tf.global_variables_initializer()\n            self.sess.run(init_op)\n\n            print('Loading Checkpoint')\n            ckpt = tf.train.latest_checkpoint(self.ckpt_dir)\n            self.saver.restore(self.sess, ckpt)\n            self.step = tf.train.get_or_create_global_step()\n            print('Checkpoint Loaded')\n\n            for i, img_file in enumerate(input_list, 1):\n\n                img = cv2.imread(os.path.join(input_dir, img_file), 1)\n\n                print('Processing image', i, end = '\\r')\n\n                img = ((np.expand_dims(img, axis = 0) \/ 255) * 2) - 1 \n                feed_dict = {self.RealA: img, self.isTrain: False}\n                generated_B = self.FakeB.eval(feed_dict = feed_dict)\n                generated_B = (((generated_B[0] + 1)\/2) * 255).astype(np.uint8)\n\n                cv2.imwrite(os.path.join(result_dir, img_file), generated_B)\n\n            print('Done.')\n","9d245f7d":"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\n\n\nlr = 0.001    \nD_filters = 64\nlayers = 4\ngrowth_rate= 12\ngan_wt = 2\nl1_wt=100\nvgg_wt= 10\nrestore = False\nbatch_size= 10\ndecay= 0.99\nepochs= 2\nmodel_name = 'model66'\nsave_samples= False\nsample_image_dir= 'samples' \nA_dir= 'A'\nB_dir= 'B' \ncustom_data= False\nval_fraction= 0.15\nval_threshold= 300000\nval_frequency= 10\nlogger_frequency= 10\nmode= 'train'\n\n\n\n    ","ef338ec8":"net = GAN(lr, D_filters, layers, growth_rate, gan_wt, l1_wt, vgg_wt, restore, batch_size, decay, epochs, model_name, save_samples, sample_image_dir, A_dir, B_dir, custom_data, val_fraction, val_threshold, val_frequency, logger_frequency)\nif mode == 'train':\n    net.train()\nif mode == 'test':\n    net.test(A_dir, B_dir)\nif mode == 'inference':\n    net.inference(A_dir, B_dir)\n","615010ed":"## GAN model","a3210efa":"## vgg19 implementation","08c44bdc":"# calling main function","66f6bafb":"### layer and operation implementation","69ec69f1":"# module","62d8337a":"#### parameter "}}