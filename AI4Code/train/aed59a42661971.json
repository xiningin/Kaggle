{"cell_type":{"a4345e6d":"code","438381e6":"code","bc8dbc2e":"code","e43c17d1":"code","e1473bba":"code","347376e5":"code","447b4817":"code","b700639f":"code","abf69138":"code","918b8868":"code","c14561cc":"code","95b753eb":"code","d1a44415":"code","9691480a":"code","72782796":"code","5e9b7905":"code","a84aa713":"code","7a246d51":"code","01d0a3d6":"code","f57ab904":"code","ea0e5a43":"code","c7fbd052":"code","c2aef11a":"code","ccdf82bd":"code","5d0a867c":"code","beafb721":"code","6d98364f":"code","65917283":"code","6e36536b":"code","cb6a56f5":"code","8522884e":"code","59ed02de":"code","d72b5960":"code","0342627f":"code","e2e4b696":"code","1610a11a":"code","83a4c445":"code","728e5239":"code","bbf1809f":"code","47adb172":"code","331514c8":"code","3499bb78":"code","1d4be3cc":"markdown","5024a466":"markdown","3e7ac9cd":"markdown","bdc99ffe":"markdown","ace846e1":"markdown","03a78fe8":"markdown","42889e1a":"markdown","858177ed":"markdown","8c5abfce":"markdown"},"source":{"a4345e6d":"# 1. Importa os pacotes necess\u00e1rios\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression","438381e6":"# 2. Cria o dataset. Criamos em formato de array. O reshape cria em duas dimens\u00f5es (uma coluna e v\u00e1rias linhas)\nx = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\ny = np.array([5, 20, 14, 32, 22, 38])","bc8dbc2e":"x","e43c17d1":"# 3. Cria o modelo de regress\u00e3o linear e aplica o modelo (fit)\nmodelo = LinearRegression()\nmodelo.fit(x,y)\n\n# ... ou assim em uma linha\nmodelo = LinearRegression().fit(x,y)\nmodelo","e1473bba":"# 4. Avalia o modelo\nprint('coeficiente de determina\u00e7\u00e3o:', modelo.score(x, y))\n\n# Intercept\nprint('intercept:', modelo.intercept_)\n\n# Slope\nprint('slope:', modelo.coef_)","347376e5":"# 5. Cria um novo conjunto de dados x. Arange gera um array com elementos de 0(inclusivo) a 5 (exclusivo)\nnovo_x = np.arange(5).reshape((-1, 1))\nprint(novo_x)","447b4817":"# 6. Aplica o modelo num novo conjunto de dados\nprevisao_y = modelo.predict(novo_x)\nprint(previsao_y)","b700639f":"# Outra forma id\u00eantica de aplicar o modelo para prever resultados \nprevisao_y = modelo.intercept_ + modelo.coef_ * novo_x\nprint('previs\u00e3o:', previsao_y)","abf69138":"# 1. Importe o numpy \n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression","918b8868":"# 2. Crie x contendo um array em duas dimens\u00f5es com os valores de Horas_de_Estudo j\u00e1 registrados no passado (vide tabela acima)\nhoras_estudo = np.array([1,5,7,8,10,11,14,15,15,19]).reshape((-1, 1))\nprint(horas_estudo)","c14561cc":"# 3. Crie y contendo um array com os valores hist\u00f3ricos da Nota j\u00e1 registrados no passado (vide tabela acima)\nnota = np.array([53,74,59,43,56,84,96,69,84,83]).reshape((-1, 1))\nprint(nota)\n","95b753eb":"# 4. Importe a biblioteca de regress\u00e3o linear do sklearn\nfrom sklearn.linear_model import LinearRegression","d1a44415":"# 5. Crie o modelo de regress\u00e3o linear, fazendo o fit de x e y.\n\nmodelo = LinearRegression()\n\nmodelo.fit(horas_estudo,nota)","9691480a":"# 6. Avalie o modelo. Qual seu score, intercept e slope?\n\nscore = modelo.score(x,y)\nintercept = modelo.intercept_\ncoef = modelo.coef_\n\nprint(score)\nprint(intercept)\nprint(coef)","72782796":"\n\n# 7. Crie novo_x contendo um array as seguintes horas de estudo dos novos alunos: 6, 9, 12, 15, 16, 4\nnova_horas_estudo = np.array([6,9,12,15,16,4]).reshape((-1, 1))\nprint(nova_horas_estudo)","5e9b7905":"# 8. Aplique o modelo criado fazendo uma previs\u00e3o de notas no novo conjunto de dados (novo_x)\n\nprevisao_nota = modelo.predict(nova_horas_estudo)\nprint(previsao_nota)","a84aa713":"\n# 9. Conseguiu descobrir quais ser\u00e3o as notas dos novos alunos? Imprima as notas dos novos alunos.\n\nprint(previsao_nota)","7a246d51":"# RESPOSTA - 1. Exerc\u00edcio\n\n# 1. Importe o numpy \nimport numpy as np\n\n# 2. Crie x contendo um array em duas dimens\u00f5es com os valores de Horas_de_Estudo j\u00e1 registrados no passado (vide tabela acima)\nx = np.array([1,5,7,8,10,11,14,15,15,19]).reshape((-1,1))\n\n# 3. Crie y contendo um array com os valores hist\u00f3ricos da Nota j\u00e1 registrados no passado (vide tabela acima)\ny = np.array([53,74,59,43,56,84,96,69,84,83])\n\n# 4. Importe a biblioteca de regress\u00e3o linear do sklearn\nfrom sklearn.linear_model import LinearRegression\n\n# 5. Crie o modelo de regress\u00e3o linear, fazendo o fit de x e y.\nmodelo = LinearRegression().fit(x,y)\n\n# 6. Avalie o modelo. Qual seu score, intercept e slope?\nmodelo.score(x,y)\nmodelo.intercept_\nmodelo.coef_\n\n# 7. Crie novo_x contendo um array as seguintes horas de estudo dos novos alunos: 6, 9, 12, 15, 16, 4\nnovo_x = np.array([6,9,12,15,16,4]).reshape((-1,1))\n\n# 8. Aplique o modelo criado fazendo uma previs\u00e3o de notas no novo conjunto de dados (novo_x)\nprevisao = modelo.predict(novo_x)\n\n# 9. Conseguiu descobrir quais ser\u00e3o as notas dos novos alunos? Imprima as notas dos novos alunos.\nprint(previsao)","01d0a3d6":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nx = np.array([[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]])\ny = np.array([4, 5, 20, 14, 32, 22, 38, 43])\n\nmodel = LinearRegression().fit(x, y)\n\nprint('coefficient of determination:', model.score(x, y))\nprint('intercept:', model.intercept_)\nprint('slope:', model.coef_)\n\nnovo_x = np.arange(10).reshape((-1, 2))\n\nprevisao_y = model.predict(novo_x)\nprint(previsao_y)","f57ab904":"# Importa o pandas\nimport pandas as pd\n\n# Importa os dados de admissoes e imprime suas primeiras linhas\nadmissoes = pd.read_csv('..\/input\/ipeadata\/ipea_admissoes.csv')\nadmissoes.head()\n\n# Importa os dados de demissoes e imprime suas primeiras linhas\ndemissoes = pd.read_csv('..\/input\/ipeadata\/ipea_demissoes.csv')\ndemissoes.head()\n\n# Renomeie a coluna de 'data' de demissoes para 'Data' com D mai\u00fasculo. Crie um dataset \u00fanico chamado emprego com o merge dos dados de admissoes e demissoes. Imprima suas primeiras linhas\ndemissoes = demissoes.rename(columns={'data':'Data'})\nempregos = pd.merge(admissoes, demissoes)\nempregos.head()\n\n# Fa\u00e7a uma an\u00e1lise explorat\u00f3ria com describe() e info(). Os dados s\u00e3o todos num\u00e9ricos e a alvo (demiss\u00f5es) \u00e9 cont\u00ednua?\nempregos.describe()\n\n# Fa\u00e7a uma an\u00e1lise explorat\u00f3ria com info(). Os dados s\u00e3o todos num\u00e9ricos?\nempregos.info()\n\n# Existe uma rela\u00e7\u00e3o de linearidade entre os dados? Veja isso com um gr\u00e1fico.\nimport seaborn as sns\nsns.jointplot(x='demissoes',y='admissoes',data=empregos, kind='reg')\n\n# Existem outliers? \nempregos.boxplot('admissoes')\n\n# Mostra os outliers\nimport matplotlib.pyplot as plt\nplt.scatter(empregos.admissoes, empregos.demissoes, c = \"blue\", marker = \"s\")\nplt.title(\"Mostra os outliers\")\nplt.xlabel(\"admissoes\")\nplt.ylabel(\"demissoes\")\nplt.show()\n\n# Existem valores NAs ?\nempregos.isnull().sum()\n\n# Quais vari\u00e1veis s\u00e3o mais importantes para prever as demiss\u00f5es?\ncorrelacao = empregos.corr()\ncorrelacao.sort_values([\"demissoes\"], ascending = False, inplace = True)\nprint(correlacao.demissoes)\n\n# Plota num gr\u00e1gico a importancia das vari\u00e1veis\nplt.figure(figsize=(5,5))\ncorrelacao = empregos.corr()\ncorr_cols = correlacao.nlargest(10, 'demissoes')['demissoes']\nsns.heatmap(empregos[corr_cols.index].corr(), annot=True, square=True)\n\n# Seleciona as colunas de x e de y\nx = pd.DataFrame(empregos, columns=('Data','admissoes')) # Para regress\u00e3o linear multipla com duas colunas\nx = pd.DataFrame(empregos.admissoes) # Para regress\u00e3o linear simples\ny = empregos.demissoes\n\n# Divide o dataset entre treino (70%) e teste (30%), sendo admissoes a variavel independente e demissoes a variavel target. Welcome to Cross-validation!!!\nfrom sklearn.model_selection import train_test_split\nxtreino, xteste, ytreino, yteste = train_test_split(x, y, test_size=0.3)\nxtreino.shape, xteste.shape, ytreino.shape, yteste.shape\n\n# Gera o modelo de regress\u00e3o linear (lm) no dataset de treino\nfrom sklearn.linear_model import LinearRegression\nmodelolm = LinearRegression().fit(xtreino, ytreino)\n\n# Faz as previsoes no dataset de teste\nprevisoes = modelolm.predict(xteste)\nprevisoes[0:9]\n\n# Valida\u00e7\u00e3o e Performance do Modelo. Qual foi o score (R2)?\nmodelolm.score(xteste, yteste)\n\n# Qual foi o Intercept?\nmodelolm.intercept_\n\n# Qual foi o Slope?\nmodelolm.coef_\n\n# Avalia\u00e7\u00e3o dos Erros do Modelo - MAE\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(yteste, previsoes)\nmae\n\n# Descobrir a quantidade de demissoes de apenas um valor unico de admissoes\nprint(modelolm.predict(np.array([1201201]).reshape((-1, 1))))","ea0e5a43":"# Importa o pandas\nimport pandas as pd\n\n# Importa os dados de admissoes e imprime suas primeiras linhas\nadmissoes = pd.read_csv('..\/input\/ipeadata\/ipea_admissoes.csv')\nadmissoes.head()","c7fbd052":"# Importa os dados de demissoes e imprime suas primeiras linhas\ndemissoes = pd.read_csv('..\/input\/ipeadata\/ipea_demissoes.csv')\ndemissoes.head()","c2aef11a":"# Renomeie a coluna de 'data' de demissoes para 'Data' com D mai\u00fasculo. Crie um dataset \u00fanico chamado emprego com o merge dos dados de admissoes e demissoes. Imprima suas primeiras linhas\ndemissoes = demissoes.rename(columns={'data':'Data'})\nempregos = pd.merge(admissoes, demissoes)\nempregos.head()","ccdf82bd":"# Fa\u00e7a uma an\u00e1lise explorat\u00f3ria com describe() e info(). Os dados s\u00e3o todos num\u00e9ricos e a alvo (demiss\u00f5es) \u00e9 cont\u00ednua?\nempregos.describe()","5d0a867c":"# Fa\u00e7a uma an\u00e1lise explorat\u00f3ria com info(). Os dados s\u00e3o todos num\u00e9ricos?\nempregos.info()","beafb721":"# Existe uma rela\u00e7\u00e3o de linearidade entre os dados? Veja isso com um gr\u00e1fico.\nimport seaborn as sns\nsns.jointplot(x='demissoes',y='admissoes',data=empregos, kind='reg')","6d98364f":"# Existem outliers? \nempregos.boxplot('admissoes')","65917283":"# Mostra os outliers\nimport matplotlib.pyplot as plt\nplt.scatter(empregos.admissoes, empregos.demissoes, c = \"blue\", marker = \"s\")\nplt.title(\"Mostra os outliers\")\nplt.xlabel(\"admissoes\")\nplt.ylabel(\"demissoes\")\nplt.show()","6e36536b":"# Existem valores NAs ?\nempregos.isnull().sum()","cb6a56f5":"# Quais vari\u00e1veis s\u00e3o mais importantes para prever as demiss\u00f5es?\ncorrelacao = empregos.corr()\ncorrelacao.sort_values([\"demissoes\"], ascending = False, inplace = True)\nprint(correlacao.demissoes)","8522884e":"# Plota num gr\u00e1gico a importancia das vari\u00e1veis\nplt.figure(figsize=(5,5))\ncorrelacao = empregos.corr()\ncorr_cols = correlacao.nlargest(10, 'demissoes')['demissoes']\nsns.heatmap(empregos[corr_cols.index].corr(), annot=True, square=True)","59ed02de":"# Seleciona as colunas de x e de y\n#x = pd.DataFrame(empregos, columns=('Data','admissoes')) # Para regress\u00e3o linear multipla com duas colunas\nx = pd.DataFrame(empregos.admissoes) # Para regress\u00e3o linear simples\ny = empregos.demissoes","d72b5960":"# Divide o dataset entre treino (70%) e teste (30%), sendo admissoes a variavel independente e demissoes a variavel target. Welcome to Cross-validation!!!\nfrom sklearn.model_selection import train_test_split\nxtreino, xteste, ytreino, yteste = train_test_split(x, y, test_size=0.3)\nxtreino.shape, xteste.shape, ytreino.shape, yteste.shape","0342627f":"# Gera o modelo de regress\u00e3o linear (lm) no dataset de treino\nfrom sklearn.linear_model import LinearRegression\nmodelolm = LinearRegression().fit(xtreino, ytreino)","e2e4b696":"# Faz as previsoes no dataset de teste\nprevisoes = modelolm.predict(xteste)\nprevisoes[0:9]","1610a11a":"# Extra: Como desabilitar Notacao Cient\u00edfica\npd.set_option('display.float_format', '{:.2f}'.format)\n\n# Para desabilitar notacao cient\u00edfica de  array\nimport numpy as np\nnp.set_printoptions(suppress=True)","83a4c445":"# Valida\u00e7\u00e3o e Performance do Modelo. Qual foi o score (R2)?\nmodelolm.score(xteste, yteste)","728e5239":"# Qual foi o Intercept?\nmodelolm.intercept_","bbf1809f":"# Qual foi o Slope?\nmodelolm.coef_","47adb172":"# Avalia\u00e7\u00e3o dos Erros do Modelo - MAE\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(yteste, previsoes)\nmae","331514c8":"# Descobrir a quantidade de demissoes de apenas um valor unico de admissoes\nprint(modelolm.predict(np.array([1201201]).reshape((-1, 1))))","3499bb78":"# RESPOSTA - 1. Exerc\u00edcio\n\n# 1. Importe o numpy \nimport numpy as np\n\n# 2. Crie x contendo um array em duas dimens\u00f5es com os valores de Horas_de_Estudo j\u00e1 registrados no passado (vide tabela acima)\nx = np.array([1,5,7,8,10,11,14,15,15,19]).reshape((-1,1))\n\n# 3. Crie y contendo um array com os valores hist\u00f3ricos da Nota j\u00e1 registrados no passado (vide tabela acima)\ny = np.array([53,74,59,43,56,84,96,69,84,83])\n\n# 4. Importe a biblioteca de regress\u00e3o linear do sklearn\nfrom sklearn.linear_model import LinearRegression\n\n# 5. Crie o modelo de regress\u00e3o linear, fazendo o fit de x e y.\nmodelo = LinearRegression().fit(x,y)\n\n# 6. Avalie o modelo. Qual seu score, intercept e slope?\nmodelo.score(x,y)\nmodelo.intercept_\nmodelo.coef_\n\n# 7. Crie novo_x contendo um array as seguintes horas de estudo dos novos alunos: 6, 9, 12, 15, 16, 4\nnovo_x = np.array([6,9,12,15,16,4]).reshape((-1,1))\n\n# 8. Aplique o modelo criado fazendo uma previs\u00e3o de notas no novo conjunto de dados (novo_x)\nprevisao = modelo.predict(novo_x)\n\n# 9. Conseguiu descobrir quais ser\u00e3o as notas dos novos alunos? Imprima as notas dos novos alunos.\nprint(previsao)","1d4be3cc":"## Regress\u00e3o Linear Simples\n![Exemplo de Regress\u00e3o Linear Simples](https:\/\/files.realpython.com\/media\/fig-lin-reg.a506035b654a.png)\n\nNeste curso vamos usar o [Numpy](https:\/\/docs.scipy.org\/doc\/numpy\/user\/index.html) e o [scikit-learn](https:\/\/scikit-learn.org\/stable\/index.html). ","5024a466":"## Conclus\u00e3o\nFique atento porque a regress\u00e3o linear n\u00e3o \u00e9 uma ferramenta chave que vai funcionar em todos os casos. Para dados complexos, n\u00e3o lineares com outliers e missing values n\u00e3o ir\u00e1 ter um bom resultado. Lembre os **requisitos para usar Regress\u00e3o Linear**:\n* A vari\u00e1vel dependente precisa ser num\u00e9rica e cont\u00ednua.\n* As vari\u00e1veis preditoras s\u00e3o vari\u00e1veis num\u00e9ricas e podem ser cont\u00ednuas, discretas e at\u00e9 categ\u00f3ricas.\n* As preditoras devem ser independentes entre si.\n* Os dados n\u00e3o podem ter missing values e outliers.\n* Deve existir uma rela\u00e7\u00e3o linear entre as vari\u00e1veis.\n![Rela\u00e7\u00e3o de Linearidade](https:\/\/cdncontribute.geeksforgeeks.org\/wp-content\/uploads\/python-linear-regression-4.png)\n\n### Material Complementar\nSe voc\u00ea gostou da Regress\u00e3o Linear, provavelmente vai querer conhecer o Generalized Linear Model (GLM). A GLM n\u00e3o faz parte deste curso, mas a aplica\u00e7\u00e3o \u00e9 semelhante \u00e0 realizada aqui, com o diferencial de que vai performar melhor quando os res\u00edduos ou erros de predi\u00e7\u00e3o n\u00e3o seguem uma distribui\u00e7\u00e3o normal. Um material complementar sobre GLM pode ser acessado [aqui](https:\/\/scikit-learn.org\/stable\/modules\/linear_model.html). Para usar parametros estat\u00edsticos avan\u00e7ado na regress\u00e3o linear, procure pela biblioteca [statsmodel](https:\/\/www.statsmodels.org\/stable\/index.html).\n\n### Pr\u00f3xima Aula\nAinda bem que existem outras t\u00e9cnicas de aprendizado de m\u00e1quina que que podem funcionar melhor que a regress\u00e3o linear quando esta n\u00e3o tem um bom resultado. Algumas delas s\u00e3o a \u00c1rvore de Decis\u00e3o, a Random Forest e a Support Vector Machines (SVM). Vamos conhecer estas t\u00e9cnicas nas pr\u00f3ximas aulas. \n\nPr\u00f3xima aula: [5. Random Forest](https:\/\/www.kaggle.com\/debkings\/5-random-forest)","3e7ac9cd":"## Regress\u00e3o Linear M\u00faltipla\nAqui o intercept ser\u00e1 o valor de y quando $x_1=x_2=x_n=0$. <br\/>\nA regress\u00e3o linear \u00e9 representada por: $y = intercept + slope_1*x_1 + slope_2*x_2$ <br\/>\nO objetivo da regress\u00e3o \u00e9 determinar os valores do intercept ($b_0$) e dos slopes ($b_1$) e ($b_2$) e ($b_n$).","bdc99ffe":"### Avalia\u00e7\u00e3o do Modelo\n1. **Coeficiente de determina\u00e7\u00e3o**: mostra o quanto a varia\u00e7\u00e3o em y pode ser explicada pela depend\u00eancia em `x`. Quanto maior o coeficiente, maior a indica\u00e7\u00e3o de que o modelo se encaixou ou acertou (**better fit**) e significa que a varia\u00e7\u00e3o do resultado pode ser explicada pelas diferentes entradas. Mais pr\u00f3ximo de 1.0 tamb\u00e9m corresponde \u00e0 soma dos erros ao quadrado ou **Sum of Squared Residuals (SSR)** mais pr\u00f3xima de 0 e um modelo perfeitamente inserido nos valores previstos, onde a resposta do previsto e do que realmente aconteceu \u00e9 id\u00eantica e sem erros. \n2. **Overfitting**: s\u00e3o casos onde um modelo aprendeu t\u00e3o bem que vai acertar em 100% dos casos conhecidos, tem um coeficiente 1.0 ou bem pr\u00f3ximo de 1.0.\n3. **Underfitting**: tem o valor de coeficiente pr\u00f3ximo de 0 e um SSR maior. Evidencia o caso onde o modelo n\u00e3o capturou as depend\u00eancias e os relacionamentos entre as vari\u00e1veis e a SSR \u00e9 alta.\n4. **Intercept ($b_0$)**:  mostra o ponto onde a regress\u00e3o estimada cruza o eixo y quando `x=0`. <br\/>\n5. **Slope ($b_1$)**: representa o quanto vai aumentar (ou diminuir) a resposta da predi\u00e7\u00e3o quando $x_i$ aumentar 1. <br\/>\n6. **F\u00f3rmula da regress\u00e3o linear simples**: $y = intercept + slope*x$  <br\/>\n7. **Res\u00edduos**: $residuos = y_i - b_0 - b_1*x_i$ quando `i=1`.\n\nN\u00e3o existe um n\u00famero m\u00e1gico ou um valor exato, mas \u00e9 importante saber que o valor muito pr\u00f3ximo de 0.0 ou de 1.0 podem n\u00e3o ser um bom resultado. Devemos buscar um modelo que seja gen\u00e9rico o suficiente para lidar com novos dados de entrada e que ao mesmo tempo minimize o SSR.<br\/> ","ace846e1":"## Resposta dos Exerc\u00edcios","03a78fe8":"**[Voltar para a P\u00e1gina Inicial do Curso](https:\/\/www.kaggle.com\/c\/ml-em-python)**\n\n# **Regress\u00e3o Linear**\nA regress\u00e3o linear representa a rela\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas, usada para quantificar e fazer previs\u00f5es baseadas no relacionamento entre vari\u00e1veis. A rela\u00e7\u00e3o de linearidade significa que quando uma (ou mais de uma no caso da regress\u00e3o linear m\u00faltipla) vari\u00e1vel independente aumenta ou diminui, a vari\u00e1vel dependente aumenta ou diminui tamb\u00e9m. A regress\u00e3o linear \u00e9 uma t\u00e9cnica **supervisionada** que faz previs\u00f5es de valores de **dados cont\u00ednuos**. Por ser supervisionado, cada ver que treinarmos o modelo, ele estar\u00e1 capturando padr\u00f5es que depois ser\u00e3o usados para prever valores de novos dados. O objetivo da regress\u00e3o linear \u00e9 descobrir como certas vari\u00e1veis s\u00e3o relacionadas, como uma influencia a outra. Existem basicamente dois **tipos**:\n* **Regress\u00e3o Linear Simples:** examina a rela\u00e7\u00e3o linear entre duas vari\u00e1veis.  Tem um preditor e uma predi\u00e7\u00e3o. Ou seja, uma vari\u00e1vel independente e uma vari\u00e1vel dependente (target). \n* **Regress\u00e3o Linar M\u00faltipla:** examina a rela\u00e7\u00e3o linar entre mais de duas vari\u00e1veis. Tem m\u00faltiplos preditores e uma predi\u00e7\u00e3o. Ou seja, v\u00e1rias vari\u00e1veis independentes e uma vari\u00e1vel dependente (target). \n\nPor exemplo, podemos observar que os sal\u00e1rios de empregados de uma empresa depende de algumas vari\u00e1veis como sua experi\u00eancia, grau de escolaridade, cargo, cidade em que trabalha, e v\u00e1rias outras caracter\u00edsticas. Este \u00e9 um problema de regress\u00e3o onde cada empregado representa uma observa\u00e7\u00e3o e \u00e9 pressuposto que as vari\u00e1veis de experi\u00eancia, escolaridade, cargo e cidade s\u00e3o independentes entre si, enquanto que sal\u00e1rio depende delas. Perceba que a regress\u00e3o linear pode ser usada tanto para descobrir como uma vari\u00e1vel influencia a outra, quanto para fazer previs\u00f5es futuras usando observa\u00e7\u00f5es passadas. Usando este mesmo exemplo, podemos descobrir quanto o grau de escolaridade impacta no sal\u00e1rio. Ao mesmo tempo, podemos usar os dados de observa\u00e7\u00f5es dos \u00faltimos anos para prever como ser\u00e3o os sal\u00e1rios nos pr\u00f3ximos meses ou anos se informarmos como entrada a experi\u00eancia, escolaridade, cargo e cidade. Veja a nomenclatura usada aqui:\n* **vari\u00e1vel independente** = features independentes, inputs, regressores ou vari\u00e1veis preditoras. Usadas para prever o resultado. (x)\n* **vari\u00e1vel dependente** = features dependentes, target, alvo, outputs ou responses. \u00c9 a que queremos descobrir. (y)\n* **res\u00edduos** = s\u00e3o os erros de predi\u00e7\u00e3o, representam a diferen\u00e7a entre a previs\u00e3o e o que realmente aconteceu.","42889e1a":"## 1. Exerc\u00edcio\nVoc\u00ea consegue prever a nota de um estudante de acordo com a quantidade de horas que ele estudou para uma prova?\n\n| Estudante | Horas_de_Estudo | Nota |\n|-----------|-----------------|------|\n| 1         | 1               | 53   |\n| 2         | 5               | 74   |\n| 3         | 7               | 59   |\n| 4         | 8               | 43   |\n| 5         | 10              | 56   |\n| 6         | 11              | 84   |\n| 7         | 14              | 96   |\n| 8         | 15              | 69   |\n| 9         | 15              | 84   |\n| 10        | 19              | 83   |\n","858177ed":"... agora passo a passo em detalhes","8c5abfce":"## Regress\u00e3o Linear com Dados do IPEA\nLembra dos dados de admiss\u00f5es e demiss\u00f5es do Brasil disponibilizados no site do IPEADATA estudados na aula 2? Vamos importar os dados aqui, eles est\u00e3o num dataset do Kaggle chamado ipeadata. Vamos descobrir se existe uma rela\u00e7\u00e3o de linearidade entre admiss\u00f5es e demiss\u00f5es e depois gerar um modelo de regress\u00e3o linear para descobrir a quantidade de demiss\u00f5es futuras.\n"}}