{"cell_type":{"3a38a3d4":"code","364e4519":"code","ea286b69":"code","548cc556":"code","2b21733e":"code","ece76562":"code","b34c5356":"code","9dc0b880":"markdown"},"source":{"3a38a3d4":"import numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.mixture.gaussian_mixture import _estimate_log_gaussian_prob\nfrom scipy.special import comb, logsumexp, expit\nfrom tqdm import tqdm_notebook\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","364e4519":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","ea286b69":"class MyGM(GaussianMixture):\n    \n    def __init__(self, n_components=1, covariance_type='full', tol=1e-3,\n                 reg_covar=1e-6, max_iter=100, n_init=1, init_params='kmeans',\n                 weights_init=None, means_init=None, precisions_init=None,\n                 random_state=None, warm_start=False,\n                 verbose=0, verbose_interval=10, init_clusters=None, y=None):\n        super().__init__(\n            n_components=n_components, tol=tol, reg_covar=reg_covar,\n            max_iter=max_iter, n_init=n_init, init_params=init_params,\n            random_state=random_state, warm_start=warm_start,\n            verbose=verbose, verbose_interval=verbose_interval)\n        self.init_clusters_ = np.asarray(init_clusters).astype('int')\n        self.y = y\n        \n    def _initialize_parameters(self, X, random_state):\n        \"\"\"Initialize the model parameters.\n        Parameters\n        ----------\n        X : array-like, shape  (n_samples, n_features)\n        random_state : RandomState\n            A random number generator instance.\n        \"\"\"\n        n_samples, _ = X.shape\n\n        if self.init_params == 'kmeans':\n            resp = np.zeros((n_samples, self.n_components))\n            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n                                   random_state=random_state).fit(X).labels_\n            resp[np.arange(n_samples), label] = 1\n        elif self.init_params == 'random':\n            resp = random_state.rand(n_samples, self.n_components)\n            resp \/= resp.sum(axis=1)[:, np.newaxis]\n        elif self.init_params == 'clusters':\n            resp = np.zeros((n_samples, self.n_components))\n            resp[np.arange(self.init_clusters_.shape[0]), self.init_clusters_] = 1\n        else:\n            raise ValueError(\"Unimplemented initialization method '%s'\"\n                             % self.init_params)\n\n        self._initialize(X, resp)\n     \n    def estimate_log_ratio(self, X):\n            weighted_log_prob = self._estimate_weighted_log_prob(X)            \n            return weighted_log_prob[:, 1] - weighted_log_prob[:, 0]\n        \n    # override estimate step\n    # for this competition\n    def _estimate_log_prob(self, X):\n        base_pred = _estimate_log_gaussian_prob(\n            X, self.means_, self.precisions_cholesky_, self.covariance_type)\n        new_pred = base_pred\n        \n        if self.y is None:\n            pass\n        else:\n            for i in range(base_pred.shape[0]):\n                yi = self.y[i]\n                if yi not in [0, 1]:\n                    pass\n                else:\n                    for j in range(base_pred.shape[1]):\n                        if (j - yi) % 2 == 0:\n                            new_pred[i, j] += np.log(0.975)\n                        else:\n                            new_pred[i, j] += np.log(0.025)\n        return new_pred\n    ","548cc556":"oof_preds = np.zeros(train.shape[0])\ntest_preds = np.zeros(test.shape[0])","2b21733e":"\nfor i in tqdm_notebook(range(512)):\n    \n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    \n    for train_index, test_index in skf.split(train3, train2['target']):\n\n        # initialize with train, 3 clusters each\n        train_x_0 = train3[train_index][train2['target'].values[train_index] == 0]\n        train_x_1 = train3[train_index][train2['target'].values[train_index] == 1]\n\n        gm0 = GaussianMixture(n_components=3)\n        _ = gm0.fit(train_x_0)\n        cls0 = gm0.predict(train_x_0)\n        gm1 = GaussianMixture(n_components=3)\n        _ = gm1.fit(train_x_1)\n        cls1 = gm1.predict(train_x_1)\n\n        # concat train and test\n        train_test3 = np.concatenate([train3[train_index], test3], axis=0)\n\n        train_cls = np.ones(train3[train_index].shape[0]).astype(np.int)\n        train_cls[train2['target'].values[train_index] == 0] = cls0 * 2\n        train_cls[train2['target'].values[train_index] == 1] = cls1 * 2 + 1\n\n        gm_train = MyGM(\n            n_components=6, init_params='clusters', init_clusters=train_cls, \n            weights_init=[1\/6, 1\/6, 1\/6, 1\/6, 1\/6, 1\/6],  reg_covar=1, tol=2, y=train2['target'].values[train_index]\n        )\n        _ = gm_train.fit(train3[train_index])\n        gm_train.y = None\n        train_test_cls = gm_train.predict(train_test3)\n\n        gm_all = MyGM(\n            n_components=6, init_params='clusters', init_clusters=train_test_cls, \n            weights_init=[1\/6, 1\/6, 1\/6, 1\/6, 1\/6, 1\/6],  reg_covar=1, tol=2, \n            y=np.concatenate([train2['target'].values[train_index], 2*np.ones(test3.shape[0]).astype(np.int)], axis=0)\n        )\n        gm_all.y = None\n        _ = gm_all.fit(train_test3)\n        \n        oof_pred6 = gm_all.predict_proba(train3[test_index])\n        oof_preds[idx1[test_index]] = oof_pred6[:, 1::2].sum(axis=1) \/ oof_pred6.sum(axis=1)\n        test_pred6 = gm_all.predict_proba(test3)\n        test_preds[idx2] += test_pred6[:, 1::2].sum(axis=1) \/ test_pred6.sum(axis=1)\n\n","ece76562":"roc_auc_score(train[\"target\"], oof_preds)","b34c5356":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['target'] = test_preds\nsub.to_csv('submission.csv',index=False)","9dc0b880":"My GM, modified CPMP's"}}