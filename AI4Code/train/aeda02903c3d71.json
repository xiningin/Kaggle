{"cell_type":{"ba82c31d":"code","40733d6d":"code","d2072a16":"code","e2c12958":"code","5ced2a2b":"code","db968d5d":"code","adbe22ef":"code","3c030316":"code","3cc1068a":"code","4b10ffdd":"code","411e4b58":"markdown","819a7cdb":"markdown","f9a169b0":"markdown","5ce128e7":"markdown"},"source":{"ba82c31d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","40733d6d":"import keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\nimport cv2","d2072a16":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_cat,list_dog, mode='fit',\n                 cat_path='train',dog_path='train',\n                 batch_size=32, dim=(256, 256), n_channels=3,\n                 n_classes=1, random_state=2020, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.mode = mode\n        self.cat_path = cat_path\n        self.dog_path = dog_path\n        self.list_cat = list_cat\n        self.list_dog = list_dog\n        \n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.list_IDs=list_cat+list_dog\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        if self.mode == 'fit' or self.mode == 'val':\n            X,y = self.__generate_Xy(list_IDs_batch)\n            return X, y\n        \n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_Xy(self, list_IDs_batch):\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size, 1))\n        for i, ID in enumerate(list_IDs_batch):\n            label=0    \n            im_name = ID\n            if im_name[0:3]==\"cat\":   #If it is a cat image  \n                self.base_path=self.cat_path\n                label=0\n            elif im_name[0:3]==\"dog\":    #If it is a dog image\n                self.base_path=self.dog_path\n                label=1\n            img_path = f\"{self.base_path}\/{im_name}\"\n            img = self.__load_rgb(img_path)\n               \n            if self.mode=='fit':\n                img= self.vertical_flip(img)\n                img= self.horizontal_flip(img)\n                if np.random.rand() < 0.2:     \n                    img= self.image_translation(img)\n                if np.random.rand() < 0.2:\n                    img= self.image_rotation(img)\n                if np.random.rand() < 0.2:\n                    img= self.image_contrast(img)\n            img = img.astype(np.float32) \/ 255.\n            X[i,] = img\n            y[i,] = label\n        return X.astype(np.float32),y.astype(np.float32)\n    ###################################################3\n    def vertical_flip(self,image, rate=0.5):\n        if np.random.rand() < rate:\n            image = image[::-1, :, :]\n        return image\n\n\n    def horizontal_flip(self,image, rate=0.5):\n        if np.random.rand() < rate:\n            image = image[:, ::-1, :]\n        return image\n\n    def image_contrast(self,img):\n        params = np.random.randint(6, 17)*0.1\n        alpha = params\n        new_img = cv2.multiply(img, np.array([alpha]))                    # mul_img = img*alpha\n        return new_img\n\n    def image_rotation(self,img):\n        params = np.random.randint(-20, 20)\n        rows, cols, ch = img.shape\n        M = cv2.getRotationMatrix2D((cols\/2, rows\/2), params, 1)\n        dst = cv2.warpAffine(img, M, (cols, rows))\n        return dst\n      \n      \n    def image_translation(self,img):\n        params = np.random.randint(-50, 51)\n        if not isinstance(params, list):\n            params = [params, params]\n        rows, cols, ch = img.shape\n\n        M = np.float32([[1, 0, params[0]], [0, 1, params[1]]])\n        dst = cv2.warpAffine(img, M, (cols, rows))\n        return dst\n\n    #######################################\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img=cv2.resize(img, (self.dim[1],self.dim[0]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        return img","e2c12958":"train_cats=\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/cats\/\"\ntrain_dogs=\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/dogs\/\"\ntest_cats=\"\/kaggle\/input\/cat-and-dog\/test_set\/test_set\/cats\/\"\ntest_dogs=\"\/kaggle\/input\/cat-and-dog\/test_set\/test_set\/dogs\/\"\ncat_files=os.listdir(train_cats)\ndog_files=os.listdir(train_dogs)\n\nval_cat_files=os.listdir(test_cats)\nval_dog_files=os.listdir(test_dogs)","5ced2a2b":"# 900 train images\n# 100 validation images\n\nBatch_size=32\n#train generator\ntrain_gen=DataGenerator(cat_files[0:450],dog_files[0:450],cat_path=train_cats,dog_path=train_dogs,batch_size=Batch_size)  # Half dog Images and Cat Images\n\n#validation data generator\nval_gen=DataGenerator(val_cat_files[0:50],val_dog_files[0:50],cat_path=test_cats,dog_path=test_dogs,mode='val',batch_size=Batch_size)","db968d5d":"resnet50=keras.applications.ResNet50(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(256,256,3)\n)\n\nmodel = Sequential()\nmodel.add(resnet50)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n    \nmodel.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.0001),\n        metrics=['accuracy']\n    )\nmodel.summary()","adbe22ef":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","3c030316":"#train generator sample\nfor i in range(5):\n    plt.figure()\n    plt.imshow(train_gen[0][0][i])\n    plt.title(\"Label= \"+str(train_gen[0][1][i]))","3cc1068a":"history = model.fit_generator(train_gen,\n                              epochs = 30, validation_data = val_gen,\n                              verbose = 1,callbacks=[learning_rate_reduction])","4b10ffdd":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","411e4b58":"Conclusion: \n- Our model is achieving 90%+ accuracy for the given test images\n\n\nSome further improvements that we can do to improve the accuracy of the model are\n- We can use more complex augmentation \n- We can use focal loss\n- We can use deeper models \n- We can use the different backbone of models like DenseNet, EfficientNet\n- Ensembling the different models provides better results.  ","819a7cdb":"Reference:\n- Previous work by me in my private kernels\n- Publicly available Kaggle kernels","f9a169b0":"# Custom Data Generator","5ce128e7":"# MODEL: RESNET 50"}}