{"cell_type":{"d431bc15":"code","c9f8f652":"code","12b85ced":"code","86842057":"code","82eb2f23":"code","e63c145f":"code","b81618bc":"code","e759ce7c":"code","dccf6eb2":"code","db79016c":"code","195dca91":"code","a39e2b08":"code","a0cb6ef6":"code","98d84c61":"code","42b76f9d":"code","222d9369":"code","967ab54a":"code","64100661":"code","9475d0ec":"code","98cf1436":"code","75b20a70":"code","9161281c":"code","dba51ea4":"code","7c99bf98":"code","d7d8cd7b":"markdown","54d65ae5":"markdown","ce8e0543":"markdown"},"source":{"d431bc15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c9f8f652":"import matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_log_error","12b85ced":"train = pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/train.csv')\ntest = pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/test.csv')\nsample_submission = pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/sample_submission.csv')\n\ntrain_copy = train.copy()\ntest_copy = test.copy()","86842057":"train.head()","82eb2f23":"train.columns","e63c145f":"train.head()","b81618bc":"# train['Temperature(\ufffdK)'] = (train['Temperature(\ufffdC)'] * (9\/5)) + 32\n# train['Dew point temperature(\ufffdK)'] = (train['Dew point temperature(\ufffdC)']* (9\/5)) + 32\n\ntrain.Date = pd.to_datetime(train.Date, format='%d\/%m\/%Y')\ntrain['day'] = train['Date'].dt.day_name()\ntrain['month'] = train['Date'].dt.month_name()\ntrain['year'] = pd.DatetimeIndex(train['Date']).year\ntrain['day_night'] = train['Hour'].apply(lambda x: 'Night' if (x >= 20) or (x<=5) else \"Day\")\n#-------------------------------------------\ntrain[\"weather\"] = train.Seasons.map({'Spring': \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n                                        'Summer' : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n                                        'Autumn' : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n                                        'Winter' :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })\n\n# #-------------------------------------------\nhours_binning = []\nfor i in train['Hour']:\n    if i < 8 :\n        hours_binning.append(1)\n    elif i >= 22 :\n        hours_binning.append(2)\n    elif i > 9 and i<18 :\n        hours_binning.append(3)\n    elif i == 8 :\n        hours_binning.append(4)\n    elif i == 9 :\n        hours_binning.append(5)\n    elif i == 20 or i == 21 :\n        hours_binning.append(6)\n    elif i == 19 or i == 18 :\n        hours_binning.append(7)\n        \ntrain['hours_binning'] = hours_binning\n\n# #-------------------------------------------\nday_condition = []\nfor i in train['Humidity(%)']:\n    if i >= 0 and i<= 20 :\n        day_condition.append(\"uncomfortably dry\")\n    elif i >= 21 and i<=60 :\n        day_condition.append(\"comfort\")\n    elif i >= 61 and i<=100 :\n        day_condition.append(\"uncomfortably wet\")\n        \ntrain['day_condition'] = day_condition\n\n","e759ce7c":"train[[\"y\", \"Temperature(\ufffdC)\", \"Humidity(%)\",'Wind speed (m\/s)','Visibility (10m)','Dew point temperature(\ufffdC)','Solar Radiation (MJ\/m2)', 'Rainfall(mm)','Snowfall (cm)']].hist(figsize=(10,9));","dccf6eb2":"train['Functioning Day'].value_counts()","db79016c":"for i in train.columns:\n    plt.figure(figsize=(8, 5))\n    sns.scatterplot(data = train, x = 'y', y = i)\n    plt.title('{} vs y'.format(i))\n    plt.show()","195dca91":"#train = train.drop(columns=['Rainfall(mm)','Snowfall (cm)'], axis=1)\ntrain.head()","a39e2b08":"train.columns","a0cb6ef6":"plt.figure(figsize=(15, 5))\nsns.boxplot(data = train)\nplt.tick_params(axis='x', rotation=30)\nplt.yscale('symlog')\n","98d84c61":"plt.figure(figsize=(15, 5))\nsns.boxplot(data = train[['Wind speed (m\/s)','Solar Radiation (MJ\/m2)']])\nplt.tick_params(axis='x', rotation=30)\n","42b76f9d":"numerical = train[['Hour', 'Temperature(\ufffdC)', 'Humidity(%)', 'Wind speed (m\/s)','Visibility (10m)', 'Dew point temperature(\ufffdC)',\n                            'Solar Radiation (MJ\/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'year', 'hours_binning']]\n\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nETR = ExtraTreesRegressor()\nETR.fit(numerical,train['y'])\nprint(ETR.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(ETR.feature_importances_, index=numerical.columns)\nfeat_importances.nlargest(15).plot(kind='barh')\nplt.show()","222d9369":"numerical = train[['Hour', 'Temperature(\ufffdC)', 'Humidity(%)', 'Wind speed (m\/s)','Visibility (10m)', 'Dew point temperature(\ufffdC)',\n                            'Solar Radiation (MJ\/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'year', 'hours_binning','y']]\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(22,11))\nplt.title('Pearson Correlation of Features', y=1.05, size=20)\nsns.heatmap(numerical.corr(),linewidths=0.1,vmin= -1.0,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True);","967ab54a":"categorical = train[['Seasons','Holiday', 'Functioning Day', 'day', 'month', 'day_night','weather','y']]\n\nfrom scipy.stats import f_oneway\n \n# Running the one-way anova test between CarPrice and FuelTypes\n# Assumption(H0) is that FuelType and CarPrices are NOT correlated\n \n# Finds out the Prices data for each FuelType as a list\nfor i in categorical.columns:\n    CategoryGroupLists=categorical.groupby(i)['y'].apply(list)\n\n    # Performing the ANOVA test\n    # We accept the Assumption(H0) only when P-Value > 0.05\n    AnovaResults = f_oneway(*CategoryGroupLists)\n    print('P-Value for Anova {} is: '.format(i), AnovaResults[1], '\\ncorrelated = {} \\n'.format(AnovaResults[1] < 0.05))","64100661":"categorical_features_indices = np.where(train.dtypes == np.object)[0]\ntrain.iloc[categorical_features_indices]","9475d0ec":"from sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\n\n\ntrain_modified = train.drop(columns = ['y','ID','day_condition'],axis=1)\n\ny = train['y']\ny =  np.log1p(y)\n\nX_train, X_val, y_train, y_val = train_test_split(train_modified, y, test_size=0.2, random_state=42) \n\ncategorical_features_indices = np.where(train_modified.dtypes == np.object)[0]\n\nmodel= CatBoostRegressor(iterations = 4998,\n                         loss_function='RMSE',\n                         learning_rate = 0.01, \n                         depth = 8, \n                         l2_leaf_reg = 2)\n                         #,early_stopping_rounds = 10 )\n\n\nmodel.fit(X_train, y_train, cat_features=categorical_features_indices,eval_set=(X_val, y_val),plot=True)\n","98cf1436":"print(model.score(X_train, y_train))\nprint(model.score(X_val, y_val))","75b20a70":"from sklearn.metrics import r2_score\n\n#model_predicted = np.exp(model.predict(X_val))\nmodel_predicted = model.predict(X_val)\n\nr2 = r2_score(y_val, model_predicted)\nprint('R2: {:.6f}'.format(r2))","9161281c":"cat_predicted = np.exp(model.predict(X_val))\ncat_predicted","dba51ea4":"importance = model.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","7c99bf98":"testing = test.copy()\ntesting.columns\ntesting.Date = pd.to_datetime(testing.Date, format='%d\/%m\/%Y')\ntesting['day'] = testing['Date'].dt.day_name()\ntesting['month'] = testing['Date'].dt.month_name()\ntesting['year'] = pd.DatetimeIndex(testing['Date']).year\ntesting['day_night'] = testing['Hour'].apply(lambda x: 'Night' if (x >= 20) or (x<=5) else \"Day\")\n#-------------------------------------------\ntesting[\"weather\"] = testing.Seasons.map({'Spring': \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n                                        'Summer' : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n                                        'Autumn' : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n                                        'Winter' :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })\n\n# #-------------------------------------------\nday_condition = []\nfor i in testing['Humidity(%)']:\n    if i >= 0 and i<= 20 :\n        day_condition.append(\"uncomfortably dry\")\n    elif i >= 21 and i<=60 :\n        day_condition.append(\"comfort\")\n    elif i >= 61 and i<=100 :\n        day_condition.append(\"uncomfortably wet\")\n        \ntesting['day_condition'] = day_condition\n# #-------------------------------------------\n\nhours_binning = []\nfor i in testing['Hour']:\n    if i < 8 :\n        hours_binning.append(1)\n    elif i >= 22 :\n        hours_binning.append(2)\n    elif i > 9 and i<18 :\n        hours_binning.append(3)\n    elif i == 8 :\n        hours_binning.append(4)\n    elif i == 9 :\n        hours_binning.append(5)\n    elif i == 20 or i == 21 :\n        hours_binning.append(6)\n    elif i == 19 or i == 18 :\n        hours_binning.append(7)\n        \ntesting['hours_binning'] = hours_binning\n\n\ntesting = testing.drop(columns = ['ID','day_condition'],axis=1)\n\n\nCB_predicted = model.predict(testing)\ntest['y'] = np.exp(CB_predicted)\ntest[['ID', 'y']].to_csv('\/kaggle\/working\/CB_4500_submission.csv', index=False)","d7d8cd7b":"### checking correlation between features and y","54d65ae5":"## Feature Engineering","ce8e0543":"we will take only 'humidity' instead of the dew point as it is considered as relative for it "}}