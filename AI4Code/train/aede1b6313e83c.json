{"cell_type":{"0996be7b":"code","3e45c78a":"code","e72a7d94":"code","af8f5a6d":"code","6985db24":"code","e693a3d8":"code","660f858a":"code","3a218f64":"code","4700b958":"code","c30d0801":"code","5bdda0fe":"code","f29010ed":"code","dc11bf2b":"code","0b8cded8":"code","5562813a":"code","9c4b427d":"code","4da039f1":"code","62459de9":"code","0d5d1e5a":"code","0ef744a8":"code","415dc94e":"code","57a24da6":"code","7ba27cbf":"markdown","8c618b1e":"markdown","5c6c3eb9":"markdown","89415c27":"markdown","682089cc":"markdown","42f0e362":"markdown","a9f65142":"markdown","1c2a7656":"markdown","667c7ee9":"markdown","0e449fde":"markdown","d795ea1b":"markdown","0c63cef8":"markdown","667bfdd1":"markdown","677f2688":"markdown","dd0e4a69":"markdown","2f58e58f":"markdown"},"source":{"0996be7b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndf = pd.read_csv(\"..\/input\/forestfires.csv\")\ndf.head()","3e45c78a":"df_coordinates = df.loc[:, [\"X\", \"Y\"]]\ncoordinates = df_coordinates.values","e72a7d94":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 20):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, \n                    n_init = 10, random_state = 0)\n    #max_iter - max number of iteration to define the final clusers\n    #n_init - number of k_means algorithm running\n    kmeans.fit(coordinates)\n    wcss.append(kmeans.inertia_)\n    #inertia_ Sum of squared distances of samples to their closest cluster center.\nplt.plot(range(1, 20), wcss)\nplt.title('Define the number of clusters')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","af8f5a6d":"from scipy.spatial import distance\nfrom sklearn.metrics.pairwise import euclidean_distances\nplt.figure()\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, \n                    n_init = 10, random_state = 0)\nclusters = kmeans.fit_predict(coordinates)\ndf[\"Cluster\"]= clusters\nplt.subplot()\nplt.scatter(df['X'].values, df['Y'].values, marker='o', c=clusters, alpha=0.8)\nplt.title(\"Clusters\")\nplt.show()\ncentroids = kmeans.cluster_centers_\nprint(centroids)\nprint(\"\\nCalculating distance between clusters\\n\")\nprint(euclidean_distances(centroids,centroids))","6985db24":"df_cluster0 = df[(df[\"Cluster\"] == 0)] \ndf_cluster0.head()","e693a3d8":"import seaborn as sns\nimport numpy as np\ndef build_cluster_corr(df_cluster):\n    df_cluster_indicators = df_cluster.loc[:, [\"area\",\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", \"rain\"]]\n    plt.clf()\n    plt.figure(figsize=(10,10))\n    cmap = sns.diverging_palette(20, h_pos=220, s=75, l=50, sep=10, center='light', as_cmap=True)     \n    corr_matrix = df_cluster_indicators.corr()\n    corr_matrix[np.abs(corr_matrix) < 0.65] = 0\n    sns.heatmap(corr_matrix, cmap=cmap, annot=True)     \n    plt.show()","660f858a":"build_cluster_corr(df_cluster0)","3a218f64":"df_cluster0_indicators = df_cluster0.loc[:, [\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\"]]\nX = df_cluster0_indicators.values\nY = df_cluster0['area'].values\nSL = 0.05\nX_opt_ = X[:, [0, 1, 2, 3, 4, 5, 6]]","4700b958":"import matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\nimport numpy as np\ndef forward_selection(x, y, sl):\n    result = np.empty((len(X),1))\n    numVars = len(x[0])\n    all_regressors_OLS = smf.OLS(y, x).fit()\n    maxVar = max(all_regressors_OLS.pvalues).astype(float)\n    for i in range(0, numVars):\n        regressor_OLS = smf.OLS(y, x[:,i]).fit()\n        for j in range(0, numVars - i):\n            p = regressor_OLS.pvalues[0].astype(float)\n            if p > sl:\n                if (p == maxVar):\n                    result = np.insert(result, 0, j, axis=1)\n                    \n    plt.figure(figsize=(10,10))\n    plt.scatter(result, y, color = 'red')\n    plt.plot(result, regressor_OLS.predict(result), color = 'blue')\n    plt.title('Forward Selection results')\n    plt.xlabel('Predictor')\n    plt.ylabel('area')\n    plt.show()\n    print(regressor_OLS.summary())\n    print(result)\n    return result\n\nX_Modeled_ = forward_selection(X_opt_, Y, SL)","c30d0801":"def backward_elimination(x, y, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = smf.OLS(y, x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    \n    plt.figure(figsize=(10,10))\n    plt.scatter(x, y, color = 'red')\n    plt.plot(x, regressor_OLS.predict(x), color = 'blue')\n    plt.title('Backward Elimination results')\n    plt.xlabel('Predictor')\n    plt.ylabel('area')\n    plt.show()\n    print(regressor_OLS.summary())\n    print(x)\n    return x\n\nX_Modeled_ = backward_elimination(X_opt_, Y, SL)","5bdda0fe":"df_cluster1 = df[(df[\"Cluster\"] == 1)] \ndf_cluster1.head()","f29010ed":"build_cluster_corr(df_cluster1)","dc11bf2b":"df_cluster1_indicators = df_cluster1.loc[:, [\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", 'rain']]\nX = df_cluster1_indicators.values\nY = df_cluster1['area'].values\nSL = 0.05\nX_opt_ = X[:, [0, 1, 2, 3, 4, 5, 6, 7]]\nX_Modeled_ = backward_elimination(X_opt_, Y, SL)","0b8cded8":"df_cluster2 = df[(df[\"Cluster\"] == 2)] \ndf_cluster2.head()","5562813a":"build_cluster_corr(df_cluster2)","9c4b427d":"df_cluster2_indicators = df_cluster2.loc[:, [\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", 'rain']]\nX = df_cluster2_indicators.values\nY = df_cluster2['area'].values\nSL = 0.05\nX_opt_ = X[:, [0, 1, 2, 3, 4, 5, 6, 7]]\nX_Modeled_ = backward_elimination(X_opt_, Y, SL)","4da039f1":"df_cluster3 = df[(df[\"Cluster\"] == 3)] \ndf_cluster3.head()","62459de9":"build_cluster_corr(df_cluster3)","0d5d1e5a":"df_cluster3_indicators = df_cluster2.loc[:, [\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\"]]\nX = df_cluster3_indicators.values\nY = df_cluster3['area'].values\nSL = 0.05\nX_opt_ = X[:, [0, 1, 2, 3, 4, 5, 6]]\nX_Modeled_ = backward_elimination(X_opt_, Y, SL)","0ef744a8":"df_cluster4 = df[(df[\"Cluster\"] == 4)] \ndf_cluster4.head()","415dc94e":"build_cluster_corr(df_cluster4)","57a24da6":"df_cluster4_indicators = df_cluster4.loc[:, [\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", 'rain']]\nX = df_cluster4_indicators.values\nY = df_cluster4['area'].values\nSL = 0.05\nX_opt_ = X[:, [0, 1, 2, 3, 4, 5, 6, 7]]\nX_Modeled_ = backward_elimination(X_opt_, Y, SL)","7ba27cbf":"The  model for this cluster is : area = 1.777  * wind","8c618b1e":"So, the best model for this cluster is area = 0.1324 * DMC","5c6c3eb9":"## Cluster 2","89415c27":"And for each cluster, the burned area prediction was found\n## Cluster 0","682089cc":"First, the coordinates were clusterized. The cluster amount was chosen using the elbow method","42f0e362":"The DMC predicor was chosen with r squared 14 %. ","a9f65142":"## Cluster 1","1c2a7656":"In this reaserch i tried to make a prediction for the burned area within the Montesinho park. Forest Fires Data Set was used for this analysis. The data was clusterized. Stepwise regression methods were applied to choose one best predictor. It is interesting to see, which one of them has the biggest impact on the burned area in each cluster. ","667c7ee9":"There is no predictor was chose by forward selection. I think the reason of that are unsignificant correlation values between the data, because the forward selection train the model using each predictor separately, so it is hard to choose really significant results. So the backward elimination algoritm was applied, to train the model using all predictors, and then choose the best one. ","0e449fde":"There is really small correlation values between data and dependent variable, so the stepwise regression methods was applied to chose the best predictors.","d795ea1b":"The model for this cluster is : area = 1.4330  * FFMC","0c63cef8":"## Cluster 4","667bfdd1":"## Cluster 3","677f2688":"The best model for this cluster is backward elimination algoritm result: area = 0.9878  * temp","dd0e4a69":"There is last bend somewhere near fifth point, and then the curve is more smoothed. So, as i can see, the optimal number of clusters  is 5\nSo, kmeans algithm with the same configurations was applied to find the clusters.","2f58e58f":"The model for this cluster is: area = 0.2047 * DMC"}}