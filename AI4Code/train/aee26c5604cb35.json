{"cell_type":{"ef6b844f":"code","40383e0b":"code","6fc2661f":"code","f88eaaa5":"code","bb5fd536":"code","b1f07eef":"code","346b170c":"code","a15a01af":"code","26e17ca4":"code","42b7cf7f":"code","73b8e1b2":"code","e58d6fb8":"code","cd35ecfb":"code","aa408c2d":"code","9f75f3cd":"code","ca70aeae":"code","287947db":"code","be092b3b":"code","0bbf3819":"code","0b836aca":"code","180e32c6":"code","ed83f2db":"code","9c762967":"code","dca2fd67":"code","b517d386":"code","e9587e09":"code","07218ca7":"markdown","0c400263":"markdown","3ff9adc7":"markdown","039a2fff":"markdown","59227a09":"markdown","b0974d68":"markdown","9ace2241":"markdown","fdc32ac2":"markdown","12fb0ebf":"markdown","ec22fb96":"markdown","3dfcf987":"markdown","1f212f67":"markdown","1a9a3a84":"markdown","f24f9a5a":"markdown","ba3cc12d":"markdown","d3ded98e":"markdown","e29086cd":"markdown","be99e50d":"markdown","676d038c":"markdown","25c59c0a":"markdown","b34acb73":"markdown"},"source":{"ef6b844f":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","40383e0b":"data = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv', parse_dates=True)\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\nsemp_sub = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\npseudolabels = pd.read_csv('..\/input\/tps-lightautoml-baseline-with-pseudolabels\/lightautoml_with_pseudolabelling_kernel_version_15.csv')","6fc2661f":"data['date_time'] = pd.to_datetime(data['date_time'])\ntest_data['date_time'] = pd.to_datetime(test_data['date_time'])","f88eaaa5":"data.head()","bb5fd536":"def make_new_features(df):\n    df[\"month\"] = df[\"date_time\"].dt.month\n    df[\"day_of_week\"] = df[\"date_time\"].dt.dayofweek\n    df[\"day_of_year\"] = df[\"date_time\"].dt.dayofyear\n    df[\"hour\"] = df[\"date_time\"].dt.hour\n    df[\"quarter\"] = df[\"date_time\"].dt.quarter\n    df[\"week_of_year\"] = df[\"date_time\"].dt.isocalendar().week.astype(\"int\")\n    df[\"working_hours\"] =  df[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\n    df[\"is_weekend\"] = (data[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","b1f07eef":"make_new_features(data)\nmake_new_features(test_data)","346b170c":"for col in ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']:\n    test_data[col] = pseudolabels[col]","a15a01af":"full_data = pd.concat([data, test_data]).reset_index(drop = True)","26e17ca4":"test_data = test_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\nall_data = [full_data, test_data]\n\nfor df in all_data:\n    df['date_time'] = df['date_time'].astype('datetime64[ns]').astype(np.int64)\/10**9\ndata = data.sample(frac=1)","42b7cf7f":"x_data = full_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\ny_data = full_data[['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']]\nx_data.shape, y_data.shape","73b8e1b2":"x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)","e58d6fb8":"!pip install scikit-learn-intelex -q --progress-bar off","cd35ecfb":"from sklearnex import patch_sklearn\npatch_sklearn()","aa408c2d":"from sklearn.multioutput import RegressorChain\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor\nfrom sklearn.metrics import mean_squared_log_error\nimport numpy as np\nimport optuna \nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso","9f75f3cd":"def get_stacking_regressor( C1=None,\n                            n_estimators=None, min_samples_split=None,\n                            alpha1=None, alpha2=None\n                            ):\n    svr = SVR(C=C1)\n    rf = RandomForestRegressor(n_estimators=n_estimators, min_samples_split=min_samples_split,\n                               random_state=0, n_jobs=-1)\n    lasso = Lasso(alpha=alpha1, random_state=0, max_iter=100000)\n\n    \n    lasso_f = Lasso(alpha=alpha2, random_state=0, max_iter=100000)\n    stacking_estimators = [\n        ('svr', svr),\n        ('rf', rf),\n        ('lasso', lasso),\n    ]\n    \n    return StackingRegressor(estimators=stacking_estimators, final_estimator=lasso_f)","ca70aeae":"def objective(trial):\n    params ={\n        'n_estimators': trial.suggest_int('n_estimators', 1300, 2000),\n        'alpha1': trial.suggest_float('alpha1', 0.0, 0.15),\n        'alpha2': trial.suggest_float('alpha2', 0.0, 0.05),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n        'C1': trial.suggest_loguniform('C1', 1e-3, 1e2),\n    }\n    model = RegressorChain(get_stacking_regressor(**params), random_state=47).fit(x_train, y_train)\n    y_pred = model.predict(x_val)\n    loss = np.sqrt(mean_squared_log_error(y_val, np.abs(y_pred)))\n    return loss\n\n","287947db":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","be092b3b":"%%time\nstudy.optimize(objective, n_trials=10)","0bbf3819":"%%time\nnew_model_rf = RegressorChain(get_stacking_regressor(**study.best_params)).fit(x_data, y_data)\n","0b836aca":"%%time\ny_pred = new_model_rf.predict(test_data)","180e32c6":"semp_sub['target_carbon_monoxide'] = y_pred[:, 0]\nsemp_sub['target_benzene'] = y_pred[:, 1]\nsemp_sub['target_nitrogen_oxides'] = y_pred[:, 2]\nsemp_sub.to_csv('submission.csv', index=False)\nsemp_sub.head()","ed83f2db":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","9c762967":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso","dca2fd67":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","b517d386":"%%time\nstudy.optimize(objective, n_trials=10)","e9587e09":"%%time\nnew_model_rf = RegressorChain(get_stacking_regressor(**study.best_params)).fit(x_data, y_data)","07218ca7":"<big><strong>Select parameters<\/strong><\/big>","0c400263":"<big>Patch original scikit-learn.<\/big>","3ff9adc7":"<big>Now let's combine the test and train datasets.<\/big>","039a2fff":"<h2>Prediction<\/h2>","59227a09":"<big>I added new feature to the dataset.<\/big> \n<big>It was obtained by <code>feature_importances_<\/code>.<\/big>","b0974d68":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but\u202fit\u202fsometimes works for hours.<\/big><br><br>\n\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, <strong>\u202f<a href='https:\/\/github.com\/intel\/scikit-learn-intelex'>Intel\u00ae Extension for Scikit-learn*<\/a><\/strong>.<\/big><br><br>\n\n<big>I will show you how to <strong>speed up your kernel more than 3 times<\/strong> without changing your code!<\/big><big>","9ace2241":"<big>Let's see the execution time without patch.<\/big>","fdc32ac2":"<h2>Training the model with the selected parameters<\/h2>","12fb0ebf":"<h2>Installing Intel(R) Extension for Scikit-learn<\/h2>\n\n<big>Use Intel\u00ae Extension for Scikit-learn* for fast compute Scikit-learn estimators.<\/big>","ec22fb96":"<big><strong>Pseudodating<\/strong><\/big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.<\/big>","3dfcf987":"<h2>Using optuna to select parameters for Stacking algorithm<\/h2><br><br>\n<big>Stacking or generalization is an ensemble of machine learning algorithms.\n\nThis generalization consists of output combination of individual estimators and the final prediction based on it. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.<\/big><br><br>\n<big>We adjust hyperparameters for the best result.<\/big><br><br>\n<big>Parameters for Random Forest:<\/big><br>\n<big>* <code>n_estimators<\/code> -  The number of trees to be used in the algorithm.<br><\/big>\n<big>* <code>min_samples_split<\/code> - The minimum number of samples in a leaf to split.<br><br> <\/big>\n<big>Parameter for SVR:<\/big><br>\n<big>* <code>C<\/code> -  Parameter inverse to the regularization coefficient<br><\/big><br>\n<big>Parameter for Lasso:<\/big><br>\n<big>* <code>alpha<\/code> - Regularization parameter. Regularization improves the solution and reduces the variance of estimates.<br> <\/big>\n","1f212f67":"<big>Now split the data into training and validation sets.<\/big>","1a9a3a84":"<big>Let's see the execution time.<\/big>","f24f9a5a":"<big>Next step is split the data into features and targets.<\/big>","ba3cc12d":"<h2>Importing data<\/h2>","d3ded98e":"<h2>Now we use the same algorithms with original scikit-learn<h2>","e29086cd":"<big>Select parameters for Stacking algorithm.<\/big>","be99e50d":"<h2>Preprocessing<\/h2>\n\n<big>I added some features based on date<\/big>","676d038c":"<h2>Conclusions<\/h2>\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel\u00ae Extension for Scikit-learn. Noted that Intel\u00ae Extension for Scikit-learn gives you opportunities to:<\/big>\n\n* <big>Use your Scikit-learn code for training and inference without modification.<\/big>\n* <big>Speed up selection of parameters <strong>from 1 hour 41 minutes to 31 minutes.<\/strong><\/big>\n* <big>Get predictions of the similar quality.<\/big>\n","25c59c0a":"<big>Save the results in 'submission.csv'.<\/big>","b34acb73":"<big>Let\u2019s run the same code with original scikit-learn and compare its execution time with the execution time of the patched by Intel(R) Extension for Scikit-learn.<\/big>"}}