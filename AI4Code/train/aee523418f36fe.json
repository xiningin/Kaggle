{"cell_type":{"7541972c":"code","230e66a9":"code","df9ce056":"code","4b969f71":"code","7b5a0673":"code","7619ff24":"code","51dc6c46":"code","1e810458":"code","091809c9":"code","e088556e":"code","8570334a":"code","142d2e53":"code","39ec36bb":"code","6b17c0e2":"code","452a5db4":"code","999f7011":"markdown","61ed3b4c":"markdown","669f3521":"markdown"},"source":{"7541972c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","230e66a9":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import IsolationForest\n\nfrom xgboost import XGBRegressor","df9ce056":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 150)\npd.options.display.float_format = '{:20,.2f}'.format","4b969f71":"data_dict = {}\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        key = filename.partition('.csv')[0]\n        data_dict[key] = pd.read_csv(os.path.join(dirname, filename))\ndata_dict.keys()","7b5a0673":"sales_train = data_dict['sales_train']","7619ff24":"sales_train.head()","51dc6c46":"def index_cols(df, series_name):\n    '''\n    This function accepts a pivot table with column names in the format 1, 2, 3, ... and renames each\n    column into a tuple such that the first element is the original column name and the second element\n    is a suffix passed as an argument (\"series_name\")    \n    '''\n    for col in df.columns:\n        df = df.rename(columns={col:(col, series_name)})\n    \n    return df","1e810458":"# Append cnt data together yielding a single dataframe per item-store with the full history of sales for that item-store\n# as well as the average sale cnt of the item for each period and the average sale cnt at the store for each time period\n\nshop_item_cnt = pd.pivot_table(sales_train, values='item_cnt_day', index=['shop_id', 'item_id'], columns=['date_block_num'], aggfunc=np.sum)\nshop_item_cnt = shop_item_cnt.fillna(0) \nshop_item_cnt = shop_item_cnt.astype('int64')\nshop_item_cnt = index_cols(shop_item_cnt, 'cnt')\nshop_item_cnt = shop_item_cnt.reset_index()\n\nshop_cnt = pd.pivot_table(sales_train, values='item_cnt_day', index='shop_id', columns=['date_block_num'], aggfunc=np.sum)\nshop_cnt = shop_cnt.fillna(0) \nshop_cnt = shop_cnt.astype('int64')\nshop_cnt = index_cols(shop_cnt, 'shop_total_cnt')\nshop_cnt = shop_cnt.reset_index()\n\nitem_cnt = pd.pivot_table(sales_train, values='item_cnt_day', index='item_id', columns=['date_block_num'], aggfunc=np.sum)\nitem_cnt = item_cnt.fillna(0) \nitem_cnt = item_cnt.astype('int64')\nitem_cnt = index_cols(item_cnt, 'item_total_cnt')\nitem_cnt = item_cnt.reset_index()","091809c9":"shop_item_cnt = shop_item_cnt.merge(shop_cnt, how='left', left_on=['shop_id'], right_on=['shop_id'])\nshop_item_cnt = shop_item_cnt.merge(item_cnt, how='left', left_on=['item_id'], right_on=['item_id'])","e088556e":"def format_train(df, target_month, max_lag=3):\n    '''\n    Takes the pivot table dataset prepared earlier and grabs the month of interest. The number of preceding months\n    defined in the max_lag argument are also selected and included in the results set.\n    \n    Transfoms the pivot data into one row per store-item combo for a specific month with the preceding n months history.\n    '''\n    \n    df = df.copy()\n    for col in df.columns:\n        if type(col) is tuple:\n            if col[0] >= target_month - max_lag and col[0] <= target_month:\n                new_col_name = (target_month-col[0], col[1])\n                df = df.rename(columns={col:new_col_name})\n            else:\n                df = df.drop(columns=col)\n    \n    return df","8570334a":"def remove_outliers(df, contamination=0.01):\n    \n    df = df.copy()\n    \n    clf = IsolationForest(random_state=0, contamination=contamination)\n    out = clf.fit_predict(df.drop(columns=['shop_id', 'item_id']))\n    \n    df['outlier'] = out\n    df = df.loc[df['outlier'] != -1]\n    df = df.drop(columns=['outlier'])\n    \n    return df","142d2e53":"def rmse(y, yhat):\n    '''Simple function to calculte the RMSE between two series of equal lengths'''\n    rmse = (((yhat - y)**2).mean())**(1\/2)\n    return rmse","39ec36bb":"rmse_linear_total = []\nrmse_bays_total = []\nrmse_xgb_total = []\n\nfor r in range(31, 34):\n    \n    forecast_month = r\n    \n    # My forecast model relies on taking the forecast month from prior years and using that data to predict sales for this year. So to predict\n    # November 2015 we'd look at the n months leading up to November 2014 and Noveber 2013, build a model off that data, and use it to forecast\n    # November 2015.\n        \n    # Grab labels from this year (test set) and prior years (trianing set)\n    yo0y = format_train(shop_item_cnt, forecast_month)\n    yo1y = format_train(shop_item_cnt, forecast_month-12)\n    yo2y = format_train(shop_item_cnt, forecast_month-24)\n    \n    # Consolidate prior year's data in into asingle dataset\n    consolidated_hist = pd.concat([yo1y, yo2y])\n    consolidated_hist = remove_outliers(consolidated_hist, 0.01)\n    \n    # Select training and test sets and labels\n    X_train = consolidated_hist.drop(columns=[(0,'cnt'),(0,'shop_total_cnt'),(0,'item_total_cnt')])\n    y_train = consolidated_hist[(0,'cnt')].to_numpy()\n    X_test = yo0y.drop(columns=[(0,'cnt'),(0,'shop_total_cnt'),(0,'item_total_cnt')])\n    y_test = yo0y[(0,'cnt')].to_numpy()\n    \n    #Model and forecast\n    m_linear = LinearRegression()\n    m_linear.fit(X_train, y_train)\n    l_y_hat = m_linear.predict(X_test)\n    \n    m_bayes = BayesianRidge()\n    m_bayes.fit(X_train, y_train)\n    b_y_hat = m_bayes.predict(X_test)\n    \n    m_xgb = XGBRegressor()\n    m_xgb.fit(X_train, y_train)\n    x_y_hat = m_xgb.predict(X_test)\n    \n    rmse_linear = rmse(y_test, l_y_hat)\n    rmse_bayes = rmse(y_test, b_y_hat)\n    rmse_xgboost = rmse(y_test, x_y_hat)\n    \n    print('Forecast Month: {0}'.format(forecast_month))\n    print('LinearRegression RMSE: {0}'.format(rmse_linear))\n    print('BayesianRidge RMSE: {0}'.format(rmse_bayes))\n    print('XGBoost RMSE: {0}'.format(rmse_xgboost))\n    \n    rmse_linear_total.append(rmse_linear)\n    rmse_bays_total.append(rmse_bayes)\n    rmse_xgb_total.append(rmse_xgboost)\n\n# Print overall evaluations\nprint('Mean')\nprint('LinearRegression RMSE: {0}'.format(np.mean(rmse_linear_total)))\nprint('BayesianRidge RMSE: {0}'.format(np.mean(rmse_bays_total)))\nprint('XGBoost RMSE: {0}'.format(np.mean(rmse_xgb_total)))","6b17c0e2":"forecast_month = 34\n\nyo0y = format_train(shop_item_cnt, forecast_month).reset_index()\nyo1y = format_train(shop_item_cnt, forecast_month-12).reset_index()\nyo2y = format_train(shop_item_cnt, forecast_month-24).reset_index()\n\n\nconsolidated_hist = pd.concat([yo1y, yo2y])\nconsolidated_hist = remove_outliers(consolidated_hist)\n\nX_train = consolidated_hist.drop(columns=[(0,'cnt'),(0,'shop_total_cnt'),(0,'item_total_cnt')])\ny_train = consolidated_hist[(0,'cnt')].to_numpy()\nX_test = yo0y\nm = BayesianRidge()\n\n\nm.fit(X_train, y_train)\n\ny_hat = m.predict(X_test)","452a5db4":"i = X_test.copy()\ni['item_cnt_month'] = y_hat\n\ntest = data_dict['test']\n\ntest = test.merge(i, how='left', left_on=['shop_id', 'item_id'], right_on=['shop_id', 'item_id'])\n\ntest.loc[test['item_cnt_month'].isna() == True]\n\ntest = test[['ID', 'item_cnt_month']].fillna(0)\n\ntest.to_csv('output.csv', index=False)","999f7011":"In general linear methods appear superior to XGBoost for this formulation of the data. This is perhaps not too suprising because the data consists exclusively of quantitative variables and should demonstrate consistent seasonalilty. XGB may perform better when categorical values such as item_id and shop_id are incorporated as well as when multiple different months are provided in the training set.\n\nOverall I'm pretty impressed with the applicability of straightforward linear methods to this problem. That fact that this workbook is not near the top ranked workbooks implies there are still substantial gains to be had but I linear methods appear to function passably well enough to actually be useful (if not ideal) in a real workd scenario.\n\nThe forecast accuray here does not reflect the many items that have logged 0 sales over the prior months that have been omitted from the forcast model. These should will have a forecat value of 0 and should bring down the overall model error to soem degree. The actual forecast accuray will depend strongly on whether the month itself is a high or low error month as forecast accuracy fluctuates substantially. ","61ed3b4c":"## Model Evaluation\n* LinearRegression\n* BaryesianRidgeRegression\n* XGBoost","669f3521":"## Actually Forecast"}}