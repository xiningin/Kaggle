{"cell_type":{"1f7acb4c":"code","bb440dc4":"code","59738949":"code","03622156":"code","e74cdfda":"code","aa8eb37a":"code","a8700e94":"code","bcfd42e0":"code","857cbffd":"code","59701e83":"code","5bbe3c93":"markdown","6153513d":"markdown","b443796e":"markdown","56a3ca4a":"markdown","c749ab5b":"markdown"},"source":{"1f7acb4c":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\nimport os\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization,Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.keras import applications, optimizers","bb440dc4":"train_dir='..\/input\/100-bird-species\/birds\/train'\nval_dir='..\/input\/100-bird-species\/birds\/valid'\ntest_dir='..\/input\/100-bird-species\/birds\/test'","59738949":"train_IDG=ImageDataGenerator(rescale=1\/255)\nval_IDG=ImageDataGenerator(rescale=1\/255)\ntest_IDG=ImageDataGenerator(rescale=1\/255)","03622156":"train_img=train_IDG.flow_from_directory(train_dir, target_size=(224,224),\n                                              color_mode='rgb', class_mode='sparse',batch_size=256)\nval_img=val_IDG.flow_from_directory(val_dir, target_size=(224,224),\n                                          color_mode='rgb', class_mode='sparse',batch_size=256)\ntest_img=test_IDG.flow_from_directory(test_dir, target_size=(224,224),\n                                            color_mode='rgb', class_mode='sparse',batch_size=256)","e74cdfda":"dirs = train_img.class_indices\nrdirs = {v:k  for k,v in dirs.items()}","aa8eb37a":"model = applications.VGG16()\nmodel.summary()","a8700e94":"vgg16 = applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nfor layer in vgg16.layers: layer.trainable=False\nmodel=Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(275,activation='softmax'))\nprint(model.summary())","bcfd42e0":"model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nhistory=model.fit(train_img,validation_data=val_img, epochs=10,verbose=1)","857cbffd":"model.evaluate(test_img)","59701e83":"for i in range(5):\n    choice = random.randint(0,274)\n    dir = rdirs[choice]\n    files = os.listdir(test_dir+'\/'+dir)\n    img = random.choice(files)\n    a = cv2.imread(test_dir+'\/'+dir+'\/'+img)  \n    a = cv2.resize(a,(224,224))\n    plt.imshow(a)\n    plt.show()\n    a = np.array(a\/255)\n    answer = model.predict(np.array([a]))\n    pred = np.argmax(answer)\n    print(\"predict:\",rdirs[pred],\"actual:\",rdirs[choice])","5bbe3c93":"## Build model with the VGG16","6153513d":"## Evaluate","b443796e":"## Import image from the directory","56a3ca4a":"## Train Model","c749ab5b":"## Importing Libraries"}}