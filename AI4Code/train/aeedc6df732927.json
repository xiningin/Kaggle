{"cell_type":{"ed1d55c3":"code","1ed7e634":"code","e1bea6f8":"code","2375a3b5":"code","6bf2f19e":"code","fc4065fe":"code","5101c8d9":"code","9ee7692d":"code","81313512":"code","c30dd202":"code","6ff7a16b":"code","f4bd2d52":"code","6394b5ae":"code","f48ea6a0":"code","9db5668b":"code","ecaf8d55":"code","2f8fde35":"code","580573b1":"code","60ced008":"code","c1d44adf":"code","ced91ebc":"code","ddf69d3c":"code","dc90e082":"code","306c94c9":"code","4bafc44d":"code","0bf10f3d":"markdown","f3cf76b1":"markdown","ba5236ac":"markdown","1b987a45":"markdown","68848e61":"markdown","f4e8888d":"markdown","c998d19a":"markdown","436ffbbc":"markdown","a22b8715":"markdown"},"source":{"ed1d55c3":"#Importing Libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model, decomposition, datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler","1ed7e634":"from sklearn.metrics import r2_score,classification_report,f1_score,matthews_corrcoef,recall_score,plot_roc_curve\nfrom sklearn.metrics import accuracy_score, confusion_matrix,precision_score,mean_squared_error,mean_absolute_error\n%matplotlib inline\nimport seaborn as sns","e1bea6f8":"#Loading the dataset\ndata = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\ndata.head()","2375a3b5":"X = data.drop('DEATH_EVENT',axis=1)\ny = data['DEATH_EVENT']","6bf2f19e":"X.shape","fc4065fe":"## Train test Split\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)","5101c8d9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","9ee7692d":"log_reg = LogisticRegression()","81313512":"log_reg.fit(X_train,y_train)","c30dd202":"logr_pred = log_reg.predict(X_test)","6ff7a16b":"accuracyLR = accuracy_score(y_test,logr_pred)\naccuracyLR","f4bd2d52":"log_reg = LogisticRegression()\ngrid = {\"penalty\" : [\"l1\", \"l2\"],\"C\" : np.arange(0,100,1)}\nlog_reg_cv = GridSearchCV(log_reg, grid, cv=3)\nlog_reg_cv.fit(X_train,y_train)","6394b5ae":"print(\"Tuned hyperparameter n_estimators: {}\".format(log_reg_cv.best_params_)) \nprint(\"Best score: {}\".format(log_reg_cv.best_score_))\nprint(\"Best Estimator: {}\".format(log_reg_cv.best_estimator_))","f48ea6a0":"results_NB = pd.DataFrame(log_reg_cv.cv_results_['params'])\nresults_NB['test_score'] = log_reg_cv.cv_results_['mean_test_score']\nresults_NB","9db5668b":"#Performance Comparison for Logistics Regression\nimport matplotlib.pyplot as plt\nfor i in ['l1', 'l2']:\n    temp = results_NB[results_NB['penalty'] == i]\n    temp_average = temp.groupby('C').agg({'test_score': 'mean'})\n    plt.plot(temp_average, marker = '.', label = i)\n    \n    \nplt.legend()\nplt.xlabel('C')\nplt.ylabel(\"Mean CV Score\")\nplt.title(\"Logistic Regression Performance Comparison\")\nplt.show()","ecaf8d55":"model_LR = log_reg_cv.best_estimator_\nmodel_LR.fit(X_train,y_train)\npredictions_LR =  model_LR.predict(X_test)\nprint('\\n')\nprint('Accuracy: ', accuracy_score(y_test,predictions_LR))\nprint('f1-score:', f1_score(y_test, predictions_LR))\nprint('Precision score: ', precision_score(y_test,predictions_LR))\nprint('Recall score: ', recall_score(y_test,predictions_LR))\nprint('MCC: ',matthews_corrcoef(y_test,predictions_LR) )\nprint('Mean Squared Error:', mean_squared_error(y_test, predictions_LR) ** 0.5)\nprint('Mean Absolute Error:', mean_absolute_error(y_test, predictions_LR) ** 0.5)\nprint('\\n')\nprint(classification_report(y_test, predictions_LR))\nprint('\\n')\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, predictions_LR), annot=True, ax = ax, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')","2f8fde35":"\nfrom sklearn.metrics import roc_curve, auc","580573b1":"clf = LogisticRegression()\nmodel=log_reg.fit(X_train,y_train)\npred_val = log_reg.predict(X_test)\n\n### Compute ROC curve and ROC area for predictions on validation set\nfpr, tpr, _ = roc_curve(y_test, pred_val)\nroc_auc = auc(fpr, tpr)\n\n### Plot\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","60ced008":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(\"accuracy: \", accuracy_score(y_test, predictions))","c1d44adf":"grid = {\"n_estimators\" : np.arange(0,200,2)}\nrf = RandomForestClassifier()\nrf_random = GridSearchCV(rf, grid, cv=3)\nrf_random.fit(X_train,y_train)","ced91ebc":"print(rf_random.best_params_)\nprint(rf_random.best_estimator_)","ddf69d3c":"results_NB = pd.DataFrame(rf_random.cv_results_['params'])\nresults_NB['test_score'] = rf_random.cv_results_['mean_test_score']\nresults_NB","dc90e082":"#NB Performance Comparison \nplt.plot(results_NB['n_estimators'], results_NB['test_score'], marker = '.') \nplt.xlabel('n_estimators')\nplt.ylabel(\"Mean CV Score\")\nplt.title(\"NB Performance Comparison\")\nplt.show()","306c94c9":"model_RF = rf_random.best_estimator_\nmodel_RF.fit(X_train,y_train)\npredictions_RF =  model_RF.predict(X_test)\nprint('\\n')\nprint('Accuracy: ', accuracy_score(y_test,predictions_RF))\nprint('f1-score:', f1_score(y_test, predictions_RF))\nprint('Precision score: ', precision_score(y_test,predictions_RF))\nprint('Recall score: ', recall_score(y_test,predictions_RF))\nprint('MCC: ',matthews_corrcoef(y_test,predictions_RF) )\nprint('Mean Squared Error:', mean_squared_error(y_test, predictions_RF) ** 0.5)\nprint('Mean Absolute Error:', mean_absolute_error(y_test, predictions_RF) ** 0.5)\nprint('\\n')\nprint(classification_report(y_test, predictions_RF))\nprint('\\n')\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, predictions_RF), annot=True, ax = ax, fmt='g')\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')","4bafc44d":"\n### Fit a sklearn classifier on train dataset and output probabilities\nclf = RandomForestClassifier()\nmodel=clf.fit(X_train, y_train)\npred_val = clf.predict(X_test)\n\n\n\n### Compute ROC curve and ROC area for predictions on validation set\nfpr, tpr, _ = roc_curve(y_test, pred_val)\nroc_auc = auc(fpr, tpr)\n\n### Plot\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='black',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='green', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","0bf10f3d":"# Hyper parameter tuning of Logistics Regression","f3cf76b1":"PY SAGAR -- Compared Logistic Regression and Random Forest -(With Confusion Matrix, HyperParameter Tuning,ROC Curve)","ba5236ac":"Got Accuracy of 82 percent after hyper parameter tuning","1b987a45":"# Random Forest","68848e61":"Here DEATH EVENT is Dependent Feauture","f4e8888d":"Got Accuracy of 86.6 % Accuracy in Logistics Regression","c998d19a":"# Hyperparameter Tuning of Random Forest","436ffbbc":"Area under curve is 0.81,Performance of Model is Good","a22b8715":"Area under curve is 0.87,Means model is good"}}