{"cell_type":{"6fda4784":"code","2ce87e22":"code","a8b067c0":"code","4a1806ba":"code","d7cbc41a":"code","72445792":"code","1f04a48c":"code","58fc84e5":"code","6ddd4293":"code","f98f6bb8":"code","4bee7a08":"code","2c9fd0f2":"code","ca71fbdf":"code","6a07ffbd":"code","ed338479":"code","2a538e10":"code","9c7f4c9a":"code","a8803b16":"code","bcc3260f":"code","79363abd":"code","985e7ea4":"code","e2dcd1dc":"code","2ce0fe64":"code","3b3d2f6a":"code","02b710a5":"code","08255244":"code","471058f2":"code","2f757438":"code","101522c0":"code","5da31a72":"code","1c6b83d6":"code","9e648074":"code","b9e7c52e":"code","5c56735b":"code","8a7735b7":"code","6ed74df7":"code","1e8f8917":"code","05e64104":"code","34582101":"code","eb33c28c":"code","bcf031d2":"code","8249ce87":"code","ffb32011":"code","9d197ec0":"code","18f8426f":"code","4c5fe496":"code","58ee7531":"code","afd762b5":"code","acbeacec":"code","f70cdcd6":"markdown","5cff5314":"markdown","9390130a":"markdown","6a39f76b":"markdown","4dbc20f6":"markdown","51465caa":"markdown","622e7ae6":"markdown","864323a2":"markdown","3e82bb04":"markdown"},"source":{"6fda4784":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error\n#XGBoost\nfrom xgboost import XGBRegressor\n#warnings\nimport warnings\nwarnings.filterwarnings('ignore')","2ce87e22":"df=pd.read_csv('\/kaggle\/input\/autompg-dataset\/auto-mpg.csv', na_values=['?'])","a8b067c0":"data=df.copy()","4a1806ba":"df.head()","d7cbc41a":"df.drop('car name', axis=1, inplace=True)","72445792":"df.shape","1f04a48c":"df.info()","58fc84e5":"df['origin'] = df['origin'].replace([1, 2, 3], ['USA', 'Europe', 'Japan'])","6ddd4293":"df.head()","f98f6bb8":"df['origin'].value_counts()","4bee7a08":"df['origin'].value_counts(normalize=True)","2c9fd0f2":"df.nunique()","ca71fbdf":"df.describe().T","6a07ffbd":"#The dataset contains a few unknown values.\ndf.isnull().sum()","ed338479":"df.isnull().sum().sum()\/df.shape[0]","2a538e10":"df.isnull().sum()\/df.shape[0]","9c7f4c9a":"df.dropna(axis=0, inplace=True)","a8803b16":"df.isnull().sum()","bcc3260f":"#Correlation\nf, ax = plt.subplots(figsize= [14, 8])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()","79363abd":"sns.pairplot(df, diag_kind='kde', markers='+')","985e7ea4":"df['origin'].value_counts().plot.bar()","e2dcd1dc":"plt.figure(figsize=[14, 6])\nplt.pie(x=df['origin'].value_counts(), autopct=\"%.2f\", labels=['USA', 'Europe', 'Japan'])\nplt.title(\"Origin Distribution\", fontsize=14)","2ce0fe64":"sns.barplot(x='origin', y='mpg', data=df)","3b3d2f6a":"plt.figure(figsize=[14, 6])\nsns.barplot(x=df['model year']+1900, y=df['mpg'])\nplt.title('Consumption Gallon by Years')","02b710a5":"#Boxplot\nfor col in df._get_numeric_data().columns:       \n    plt.figure()\n    sns.boxplot(df[col])","08255244":"for i in df._get_numeric_data().columns:\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n    sns.histplot(df[i], bins=10, ax=axes[0])\n    axes[0].set_title(i)\n    \n    sns.boxplot(df[i], ax=axes[1])\n    axes[1].set_title(i)\n   \n    sns.kdeplot(df[i], ax=axes[2])\n    axes[2].set_title(i)\n    plt.show()","471058f2":"#Outliers\ndef outlier(df, column):\n    Q1=df[column].quantile(0.00)\n    Q3=df[column].quantile(0.95)\n    IQR_hp=Q3-Q1\n    top_limit=Q3+ 1.5*IQR_hp\n    bottom_limit=Q1- 1.5*IQR_hp\n    return df[ (df[column]>=bottom_limit) & (df[column]<=top_limit) ]","2f757438":"df=outlier(df, 'horsepower')\ndf=outlier(df, 'acceleration')","101522c0":"#Skewness\n#feature- dependent variable\nsns.distplot(df['mpg'])","5da31a72":"sns.distplot(df['mpg'], fit=norm)","1c6b83d6":"(mu, sigma)=norm.fit(df['mpg'])\nprint(mu, sigma)","9e648074":"#qq plot\nfig=plt.figure()\nstats.probplot(df['mpg'], plot=plt)\nplt.show()","b9e7c52e":"df['mpg']=np.log1p(df['mpg'])","5c56735b":"sns.distplot(df['mpg'], fit=norm)","8a7735b7":"(mu, sigma)=norm.fit(df['mpg'])\nprint(mu, sigma)","6ed74df7":"fig=plt.figure()\nstats.probplot(df['mpg'], plot=plt)\nplt.show()","1e8f8917":"#feature- independent variable\nskewed_feats=df.drop('origin', axis=1).apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness=pd.DataFrame(skewed_feats, columns=['skewned'])","05e64104":"skewness","34582101":"df['cylinders']=df['cylinders'].astype(str)","eb33c28c":"df=pd.get_dummies(df, drop_first=True)","bcf031d2":"df.head()","8249ce87":"#Split and stand\nX=df.drop(['mpg'], axis=1)\nY=df['mpg']\nscaler=StandardScaler()\nX=scaler.fit_transform(X)","ffb32011":"def train_show_results(X, Y, model, split_share=0.3):\n    print(f\"Training using {model}\")\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=split_share)\n    m=model.fit(X_train, Y_train)\n    preds=m.predict(X_test)\n    mse=mean_squared_error(Y_test, preds)\n    print(f\"MSE: {mse}\")\n    print(\"###########################\")","9d197ec0":"models=[LinearRegression(), Ridge(), Lasso(), ElasticNet(), XGBRegressor(), \n        XGBRegressor(objective='reg:linear', max_depth=5, min_child_weight=4, subsample=0.7, n_estimators=100, learning_rate=0.7)]\nfor model in models:\n    train_show_results(X, Y, model)","18f8426f":"def model_tuning(X, Y, model, tuned_params, split_share=0.3, n_folds=5, slogx=True):\n    print(f\"Training using {model} with {tuned_params}\")\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=split_share)\n    clf=GridSearchCV(model, tuned_params, cv=n_folds,\n                 scoring='neg_mean_squared_error', n_jobs=5)\n    clf.fit(X_train, Y_train)\n    scores=clf.cv_results_['mean_test_score']\n    best_model=clf.best_estimator_\n    best_model.fit(X_train, Y_train)\n    Y_pred=best_model.predict(X_test)\n    mse=mean_squared_error(Y_test, Y_pred)\n    print(f\"MSE: {mse}\")\n    if slogx:  \n        plt.semilogx(tuned_params['alpha'], scores)","4c5fe496":"alphas=np.logspace(-4, -0.5, 30)\ntuned_params={'alpha':alphas}\nmodel_tuning(X, Y, Ridge(random_state=42, max_iter=10000), tuned_params)","58ee7531":"alphas=np.logspace(-4, -0.5, 30)\ntuned_params={'alpha':alphas}\nmodel_tuning(X, Y, Lasso(random_state=42, max_iter=10000), tuned_params)","afd762b5":"alphas=np.logspace(-4, -0.5, 30)\neNet=ElasticNet(random_state=42, max_iter=10000)\ntuned_params={'alpha':alphas, 'l1_ratio':np.arange(0.0, 1.0, 0.05)}\nmodel_tuning(X, Y, ElasticNet(random_state=42, max_iter=10000), tuned_params, slogx=False)","acbeacec":"parameters = {'nthread':[4],\n              'objective':['reg:linear'],\n              'learning_rate': [.03, 0.05, .07],\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [500]}\n\nmodel_xgb=XGBRegressor()\n\nmodel_tuning(X, Y, model_xgb, parameters, slogx=False)","f70cdcd6":"# Feature Engineering","5cff5314":"# Exploratory Data Analysis","9390130a":"# Get the data","6a39f76b":"# Model tuning","4dbc20f6":"# One Hot encoding","51465caa":"# Missing Values","622e7ae6":"# Model","864323a2":"**I could say our model did ok with the small data we have!\nThank you for checking out my work!**","3e82bb04":"# Import libraries"}}