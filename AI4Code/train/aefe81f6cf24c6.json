{"cell_type":{"4ac0b2f4":"code","13188058":"code","37fe2853":"code","f38ac00a":"code","0a2440bd":"code","96759319":"code","618561ad":"code","89026362":"code","56f8eca4":"code","64385efa":"code","b71c976d":"code","2a262b60":"code","7d22d0ea":"code","a6254ed1":"markdown"},"source":{"4ac0b2f4":"DEBUG = False","13188058":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\nimport time\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')","37fe2853":"train = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\")\nall_train_len = len(train)\ntest = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\")\ntrain_targets_scored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_nonscored.csv\")\nsub = pd.read_csv(\"..\/input\/lish-moa\/sample_submission.csv\")\n\nif DEBUG:\n    train = train[:1000]\n    train_targets_scored = train_targets_scored[:1000]\n    test = test[:1000]\n    sub = sub[:1000]","f38ac00a":"def label_encoding(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            lbl = preprocessing.LabelEncoder()\n            train[f] = lbl.fit_transform(list(train[f].values))\n        except:\n            print(f)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","0a2440bd":"#features\ndrop_features = [\"sig_id\",\"cp_type\"]","96759319":"res = train[\"cp_type\"]==\"trt_cp\"\ntrain = train[res].reset_index(drop=True)\ntrain_targets_scored = train_targets_scored[res].reset_index(drop=True)\ntrain, test = label_encoding(train, test, ['cp_dose','cp_time'])\n\ncategorical_features = ['cp_dose','cp_time']","618561ad":"def run_lgbm(target_col: str):\n    \n    X_train = train.drop(drop_features, axis=1)\n    y_train = train_targets_scored[target_col]\n    X_test = test.drop(drop_features, axis=1)\n    y_preds = []\n    models = []\n    oof_train = np.zeros((len(X_train),))\n\n    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train,y_train)):\n        X_tr = X_train.loc[train_index, :]\n        X_val = X_train.loc[valid_index, :]\n        y_tr = y_train[train_index]\n        y_val = y_train[valid_index]\n\n        lgb_train = lgb.Dataset(X_tr,\n                                y_tr,\n                                categorical_feature=categorical_features)\n\n        lgb_eval = lgb.Dataset(X_val,\n                               y_val,\n                               reference=lgb_train,\n                               categorical_feature=categorical_features)\n\n        model = lgb.train(params,\n                          lgb_train,\n                          valid_sets=[lgb_train, lgb_eval],\n                          verbose_eval=False,\n                          num_boost_round=1000,\n                          early_stopping_rounds=10)\n\n\n        oof_train[valid_index] = model.predict(X_val,\n                                               num_iteration=model.best_iteration)\n        y_pred = model.predict(X_test,\n                               num_iteration=model.best_iteration)\n\n        y_preds.append(y_pred)\n        models.append(model)\n    \n    with open(target_col + \".pickle\", mode='wb') as fp:\n        pickle.dump(models , fp)\n\n    return oof_train, sum(y_preds) \/ len(y_preds)","89026362":"cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n\nparams = {\n    'num_leaves': 24,\n    'max_depth': 5,\n    'objective': 'binary',\n    'learning_rate': 0.01,\n    #'device': 'gpu',\n    #'gpu_platform_id': 0,\n    #'gpu_device_id': 0\n}\n\ncategorical_cols = ['cp_type', 'cp_dose']\noof = train_targets_scored.copy()","56f8eca4":"for target_col in train_targets_scored.columns[:3] if DEBUG else train_targets_scored.columns:\n    t1=time.time()\n    if target_col == \"sig_id\":continue\n    print(\"Training\",target_col)\n    _oof, _preds = run_lgbm(target_col)\n    oof[target_col] = _oof\n    sub[target_col] = _preds\n    t2=time.time()\n    print(t2-t1)","64385efa":"for idx,i in enumerate(test[\"cp_type\"]):\n    if i == \"ctl_vehicle\":\n        sub.loc[idx,1:] = 0 #\u5168\u30660\u306b","b71c976d":"scores = []\nfor target_col in train_targets_scored.columns[:3] if DEBUG else train_targets_scored.columns:\n    if target_col != \"sig_id\":\n        scores.append(log_loss(train_targets_scored[target_col], oof[target_col]))\nprint(np.sum(scores))","2a262b60":"sub.head()","7d22d0ea":"sub.to_csv('submission.csv', index=False)","a6254ed1":"# LightGBM  \n\u307e\u305atrain\u306ecp_type\u304cctl_vehicle\u3067\u3042\u308b\u3082\u306e\u3092\u5168\u3066\u843d\u3068\u3059\u3002  \ntest\u306ecp_type\u304cctl_vehicle\u306f\u5168\u30660\u3067\u63d0\u51fa\u3059\u308b\u3002\n\u3042\u3068\u306f\u5217\u3054\u3068\u306bLGBM\u3092\u56de\u3059\u3002"}}