{"cell_type":{"7fdfa3f6":"code","3a0f8abe":"code","81e02c33":"code","f650b8ce":"code","fa079bd7":"code","3c386bbb":"code","e12c2ec5":"code","5f256603":"code","2154f88a":"code","54e2d0e7":"code","970a8bdf":"code","516aa5ed":"code","300150ae":"code","56585672":"code","bfda6ff3":"code","5ada1b8c":"code","f241240b":"code","d3ab8902":"code","fc4c7920":"code","13c33ebe":"code","263be847":"code","9d29b90a":"code","e9092ad9":"code","cd83e4c3":"markdown","1f41f216":"markdown"},"source":{"7fdfa3f6":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","3a0f8abe":"!pip install \/kaggle\/input\/kerasapplications -q\n!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps","81e02c33":"import os\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport efficientnet.tfkeras as efn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure\nfrom skimage import io","f650b8ce":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","fa079bd7":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","3c386bbb":"def preprocess_image(img):\n    equ_img = exposure.equalize_adapthist(img\/255, clip_limit=0.05, kernel_size=24)\n    return equ_img","e12c2ec5":"folder_path = \"..\/input\/siim-covid19-detection\"\ntrain_path = folder_path + \"\/train\/\"\ntest_path = folder_path + \"\/test\/\"\n    \ntrain_image_data = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_image_level.csv\")\n#display(train_image_data)\n#train_image_data = train_image_data.drop(labels=['boxes', 'label'], axis=1)\ntrain_image_data = train_image_data.rename(columns = {'id':'image_id', \"StudyInstanceUID\": \"study_id\"})\ntrain_image_data[\"study_id\"] = [item + \"_study\" for item in train_image_data['study_id']]\ntrain_image_data = train_image_data[[\"study_id\", \"image_id\", \"boxes\", \"label\"]]\n\nimage_paths_arr = []\nfor i in range(0, len(train_image_data)):\n    study_path = train_path + str(train_image_data['study_id'][i][:-6])\n    series = os.listdir(study_path)\n    for j in range(0, len(series)):\n        series_path = study_path + \"\/\" + series[j]\n        images = os.listdir(series_path)\n        for k in range(0, len(images)):\n            if images[k][:-4] in train_image_data['image_id'][i]:\n                image_path = series_path + \"\/\" + images[k]\n                image_paths_arr.append(image_path)\n                \ntrain_image_data['path'] = image_paths_arr\n\ntrain_study_data = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_study_level.csv\")\n\nvariables = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nfor var in variables:\n    train_image_data[var] = \"\"\n    for i in range(0, len(train_image_data)):\n        train_image_data[var][i] = int(train_study_data[var][train_study_data.index[train_study_data['id'] == train_image_data['study_id'][i]]])\n        \ntrain_image_data['Final Label'] = \"\"\nfor i in range(0, len(train_image_data)):\n    for j in range(0, 4):\n        if (train_image_data[variables[j]][i] == 1):\n            train_image_data['Final Label'][i] = j\n\ntrain_image_data = train_image_data[['path', 'study_id', 'image_id', 'Final Label', 'boxes', 'label']]\n        \ndisplay(train_image_data)","5f256603":"this_image_info = train_image_data[10:20]\ndisplay(this_image_info)","2154f88a":"path = this_image_info['path'][10]","54e2d0e7":"os.mkdir('\/kaggle\/working\/normaldir')","970a8bdf":"xray = read_xray(path)\nim = resize(xray, size=600)  \nim = np.array(im)\nio.imsave('\/kaggle\/working\/normaldir\/normal.png', im)\n#im = preprocess_image(im)\n#io.imsave('test2.png', im)","516aa5ed":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nimport json\n\ndef dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef get_bbox (image_path, save_path):\n\n    thickness = 10\n\n    #print(image_path)\n    img = dicom2array(path=image_path)\n    img = np.stack([img, img, img], axis=-1)\n    \n    l = this_image_info.loc[this_image_info['path'] == image_path].values[0][5]\n    if 'none' in l:\n        #plt.figure()\n        #plt.imshow(img)\n        img = tf.keras.preprocessing.image.array_to_img(img)\n        img.save(save_path)\n        return\n    \n    b = this_image_info.loc[this_image_info['path'] == image_path].values[0][4][1:-1]\n    b = b.split('}, {')\n    for i in range(len(b)):\n        if b[i][0] is not '{':\n            b[i] = '{' + b[i]\n        if b[i][-1] is not '}':\n            b[i] = b[i] + '}'\n        b[i] = b[i].replace(\"\\'\", \"\\\"\")\n        b[i] = json.loads(b[i])\n    \n    for i in b:\n        img = cv2.rectangle(img, (int(float(i['x'])), int(float(i['y']))), (int(float(i['x'] + i['width'])), int(float(i['y']+i['height']))), [255,0,0], thickness)\n    \n    #plt.figure()\n    #plt.imshow(img)\n    img = tf.keras.preprocessing.image.array_to_img(img)\n    img.save(save_path)\n    return","300150ae":"get_bbox(path, 'bbox.jpg')","56585672":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\nimport shutil \nimport tensorflow as tf\n%matplotlib inline\n\n\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport pprint\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport wandb\n\nimport PIL\nfrom PIL import Image\nfrom colorama import Fore, Back, Style\nviz_counter=0\n\ndef create_dir(dir, v=1):\n    \"\"\"\n    Creates a directory without throwing an error if directory already exists.\n    dir : The directory to be created.\n    v : Verbosity\n    \"\"\"\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n        if v:\n            print(\"Created Directory : \", dir)\n        return 1\n    else:\n        if v:\n            print(\"Directory already existed : \", dir)\n        return 0\n\nvoi_lut=True\nfix_monochrome=True\n\ndef dicom_dataset_to_dict(filename):\n    \"\"\"Credit: https:\/\/github.com\/pydicom\/pydicom\/issues\/319\n               https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    #====== DICOM IMAGE DATA ======\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n    else:\n        data = dicom_header.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    modified_image_data = (data * 255).astype(np.uint8)\n    \n    return dicom_dict, modified_image_data\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n\n\nimport os, fnmatch\ndef find(pattern, path):\n    \"\"\"Utility to find files wrt a regex search\"\"\"\n    result = []\n    for root, dirs, files in os.walk(path):\n        for name in files:\n            if fnmatch.fnmatch(name, pattern):\n                result.append(os.path.join(root, name))\n    return result","bfda6ff3":"viz_counter=0","5ada1b8c":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","f241240b":"model = unet(input_size=(512,512,1))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\n#model.summary()","d3ab8902":"model_weights_path = \"..\/input\/unet-lung-segmentation-weights-for-chest-x-rays\/cxr_reg_weights.best.hdf5\"\n\nmodel.load_weights(model_weights_path)\n\nShape_X,Shape_Y=512,512","fc4c7920":"os.mkdir('\/kaggle\/working\/segmentdir')","13c33ebe":"filenames = '.\/normaldir\/normal.png'\nmodified_image_data= cv2.imread(filenames, 0)\nresized_image_data = cv2.resize(modified_image_data,(Shape_Y,Shape_X)) # cv2 has this opposite\n# props(resized_image_data)\nprep_unet_input_img_1 = resized_image_data.reshape(1,Shape_X,Shape_Y,1)\nprep_unet_input_img = (prep_unet_input_img_1-127.0)\/127.0\npred_img = model.predict(prep_unet_input_img)\npred_img_preprocessed_1 = np.squeeze(pred_img)\npred_img_preprocessed = (pred_img_preprocessed_1*255>127).astype(np.int8)\n# props(pred_img_preprocessed)\n# print(\"Unique Values :\",np.unique(pred_img_preprocessed))\nres = cv2.bitwise_and(resized_image_data,resized_image_data,mask = pred_img_preprocessed)\nfile_name = filenames.split(\"\/\")[-1]\nsave_path = '\/kaggle\/working\/segmentdir\/segment.png'\ncv2.imwrite(save_path,res)","263be847":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch","9d29b90a":"dim = 512 #1024, 256, 'original'\n#save_dir = f'\/kaggle\/tmp\/segmented_data\/{split}\/segmented'\ntest_dir = '\/kaggle\/working\/segmentdir'\n#weights_dir = '\/kaggle\/input\/siim-cov19-yolov5-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\nweights_dir = '\/kaggle\/input\/yolov5-segmented\/segmentedbest.pt'\n\n#shutil.copytree('\/kaggle\/input\/yolov5-repo\/yolov5-master', '\/kaggle\/working\/yolov5')\n#os.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\n#from IPython.display import Image, clear_output  # to display images\n\n#clear_output()\n#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n\n!python ..\/input\/yolov5-repo\/yolov5-master\/detect.py --weights $weights_dir\\\n--img 512\\\n--conf 0.1\\\n--iou 0.5\\\n--augment\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\nimage_ids = []\nPredictionStrings = []\n\n","e9092ad9":"dim = 512 #1024, 256, 'original'\n#save_dir = f'\/kaggle\/tmp\/segmented_data\/{split}\/segmented'\ntest_dir = '\/kaggle\/working\/normaldir'\n#weights_dir = '\/kaggle\/input\/siim-cov19-yolov5-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\nweights_dir = '\/kaggle\/input\/weights-of-yolov5-150-epochs\/best.pt'\n\n#shutil.copytree('\/kaggle\/input\/yolov5-repo\/yolov5-master', '\/kaggle\/working\/yolov5')\n#os.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\n#from IPython.display import Image, clear_output  # to display images\n\n#clear_output()\n#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n\n!python ..\/input\/yolov5-repo\/yolov5-master\/detect.py --weights $weights_dir\\\n--img 512\\\n--conf 0.1\\\n--iou 0.5\\\n--augment\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\nimage_ids = []\nPredictionStrings = []","cd83e4c3":"# Setup","1f41f216":"# Image Processing"}}