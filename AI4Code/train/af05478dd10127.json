{"cell_type":{"b8f02d5d":"code","f775e67c":"code","4c5c90bb":"code","2e64ee69":"code","81eb3f29":"code","126be536":"code","ea49a609":"code","a699a512":"code","aeb84998":"code","5efe7bee":"markdown","53019ec8":"markdown","6239958a":"markdown"},"source":{"b8f02d5d":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n","f775e67c":"import sys\nimport subprocess\nimport pkg_resources\n\nrequired = {'torch','torchvision'} \ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\n\nif missing:\n    # implement pip as a subprocess:\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install',*missing])","4c5c90bb":"import torch\nimport torchvision\n\nfrom torchvision.datasets import FashionMNIST\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n#Prepare a tensor transform in order to make our images into tensors\ntransform = transforms.ToTensor()\n\n#Download the data if needed, perform a transform in order to make the data into tensors.\ntrain_data = FashionMNIST(root='..\/input\/fshnmnist', train=True, download=False,transform=transform)\n\ntest_data = FashionMNIST(root='..\/input\/fshnmnist', train=False,\n                                  download=False, transform=transform)\n#batch data together in groups of 30\nbatch_size = 30\nprint(\"preparing to load data!\")\n#Load the data, and shuffle it while doing so.\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n\ntest_loader = DataLoader(test_data,batch_size=batch_size,shuffle=True)\nprint(\"Done loading data!\")\n\n\n# specify the image classes\nclasses = ['T-shirt', 'Pants', 'Pullover', 'Dress', 'Coat', \n           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","2e64ee69":"import numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n    \n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(batch_size):\n    ax = fig.add_subplot(2, batch_size\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(classes[labels[idx]])","81eb3f29":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n                \n        self.conv1 = nn.Conv2d(1, 10, 3)\n        \n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.dropout = nn.Dropout(0.2)\n        self.pool = nn.MaxPool2d(2, 2) \n        self.fc1 = nn.Linear(20*5*5, 10)\n    \n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.pool(x)\n        # flatten\n        x = x.view(x.size(0), -1)\n        \n        x = self.fc1(x)\n        \n        x = F.log_softmax(x, dim=1)\n        # final output\n        return x\n    \n    def _train_(self, data_loader, n_epochs, optimizer, criterion):\n    \n        for epoch in range(n_epochs):  # loop over the dataset multiple times\n\n            running_loss = 0.0\n            for batch_i, data in enumerate(data_loader):\n                # get the input images and their corresponding labels\n                inputs, labels = data       \n\n                # zero the parameter (weight) gradients\n                optimizer.zero_grad()\n\n                # forward pass to get outputs\n                outputs = net(inputs)\n\n                # calculate the loss\n                loss = criterion(outputs, labels)\n\n                # backward pass to calculate the parameter gradients\n                loss.backward()\n\n                # update the parameters\n                optimizer.step()\n\n                # print loss statistics\n                # to convert loss into a scalar and add it to running_loss, we use .item()\n                running_loss += loss.item()\n                if batch_i % 1000 == 999:    # print every 1000 mini-batches\n                    print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss\/1000))\n                    running_loss = 0.0\n\n        print('Finished Training')\n        \n\n\n","126be536":"import torch.optim as optim\n#instantiate network and define optimizer (Adam) and crossentropy Loss function\nnet = Net()\n","ea49a609":"# Calculate accuracy before training\ncorrect = 0\ntotal = 0\n\n# Iterate through test dataset\nfor images, labels in test_loader:\n\n    # forward pass to get outputs\n    # the outputs are a series of class scores\n    outputs = net(images)\n\n    # get the predicted class from the maximum value in the output-list of class scores\n    _, predicted = torch.max(outputs.data, 1)\n\n    # count up total number of correct labels\n    # for which the predicted and true labels are equal\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\n\n# calculate the accuracy\naccuracy = 100 * correct \/ total\n\n# print it out!\nprint('Accuracy before training: ', accuracy)","a699a512":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net.parameters())\n\nn_epochs = 12\nnet._train_(train_loader, n_epochs, optimizer, criterion)","aeb84998":"test_loss = torch.zeros(1)\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\n# set the module to evaluation mode\nnet.eval()\n\nfor batch_i, data in enumerate(test_loader):\n    \n    # get the input images and their corresponding labels\n    inputs, labels = data\n    \n    # forward pass to get outputs\n    outputs = net(inputs)\n\n    # calculate the loss\n    loss = criterion(outputs, labels)\n            \n    # update average test loss \n    test_loss = test_loss + ((torch.ones(1) \/ (batch_i + 1)) * (loss.data - test_loss))\n    \n    # get the predicted class from the maximum value in the output-list of class scores\n    _, predicted = torch.max(outputs.data, 1)\n    \n    # compare predictions to true label\n    correct = np.squeeze(predicted.eq(labels.data.view_as(predicted)))\n    \n    # calculate test accuracy for *each* object class\n    # we get the scalar value of correct items for a class, by calling `correct[i].item()`\n    for i in range(len(labels.data)):\n        label = labels.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\nprint('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\n        \nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","5efe7bee":"We will now define the network itself using PyTorch","53019ec8":"First, we must download and load the data.\nWe will be using PyTorch for this one.","6239958a":"We must ensure we have the correct packages, we will be working with PyTorch"}}