{"cell_type":{"41e5155a":"code","9f13635e":"code","a54ab24a":"code","03570444":"code","aa68d18a":"code","46eb60e3":"code","b17c9ba1":"code","139b2b27":"code","fda2410b":"code","e52772b5":"code","d1cbf7ca":"code","5f19f337":"code","141ce814":"code","9bbcedf2":"code","0af46183":"code","ce0a3bba":"code","bb997d98":"code","df31df9f":"code","c88351d3":"code","9e939ed3":"code","84f171d3":"code","f61916c1":"code","53389ac9":"code","00bdad7e":"code","fe6bdb01":"code","e88d9b89":"code","ea747a89":"code","c60f4ddd":"code","80d3c2ff":"code","355a7f28":"code","a1006d8b":"code","8221f894":"code","9080b486":"code","7d29d81f":"code","acd31b14":"code","302da4c4":"code","15bcf89d":"code","0c0559b4":"markdown","ae9a22ce":"markdown","950bbf4e":"markdown","8edb3db6":"markdown","b372e1fa":"markdown","757b0765":"markdown"},"source":{"41e5155a":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords \n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score","9f13635e":"\ndata_test = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\", encoding='ISO-8859-1')\ndata_train = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\", encoding='ISO-8859-1')","a54ab24a":"data_test.head()","03570444":"data_train.head()","aa68d18a":"data_train.shape","46eb60e3":"data_test.shape","b17c9ba1":"data_train.isnull().sum()","139b2b27":"data_train.duplicated().sum()","fda2410b":"data_train.nunique()","e52772b5":"plt.figure(figsize=(14,6))\nsns.countplot(data=data_train, x='Sentiment', \n              order=[\"Extremely Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Extremely Positive\"])","d1cbf7ca":"data_train['TweetAt'].unique()","5f19f337":"location_top10 = data_train['Location'].value_counts()[:10]\nlocation_top10","141ce814":"plt.figure(figsize=(16,6))\nsns.countplot(data=data_train[data_train['Location'].isin(location_top10.index)], x='Location')","9bbcedf2":"plt.figure(figsize=(16,6))\nplt.grid()\n\nplt.hist(data_train['OriginalTweet'].str.len())","0af46183":"data_train.OriginalTweet[10]","ce0a3bba":"def wordCloud(sentiment):\n    text = \",\".join(\n               review for review in data_train[data_train['Sentiment'] == sentiment].OriginalTweet \n        if 'COVID' not in review and 'https' not in review and 'Covid' not in review)\n\n    wordcloud = WordCloud(max_words=200, colormap='Set2', background_color=\"black\").generate(text)\n    plt.figure(figsize=(15,10))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.figure(1,figsize=(12, 12))\n    plt.title('Prevalent words in ' + sentiment + ' tweets', fontsize=19)\n    plt.show()","bb997d98":"wordCloud(\"Extremely Negative\")","df31df9f":"wordCloud(\"Negative\")","c88351d3":"wordCloud(\"Neutral\")","9e939ed3":"wordCloud(\"Positive\")","84f171d3":"wordCloud(\"Extremely Positive\")","f61916c1":"data_train.OriginalTweet[8]","53389ac9":"X_train = data_train['OriginalTweet'].str.replace(r'http\\S+', \"\")\nX_train = X_train.str.replace(r\"#\\S+\", \"\")\nX_train = X_train.str.replace(r\"@\\S+\", \"\")\nX_train = X_train.str.replace(\"\\r\", \"\")\nX_train = X_train.str.replace(\"\\n\", \"\")\nX_train = X_train.str.replace(r\"[^\\w\\s]\", \"\")\nX_train = X_train.str.lower()","00bdad7e":"X_train[8]","fe6bdb01":"def remove_stopwords(text):\n    text_without_stopwords = list(filter(lambda i: i.strip() not in set(stopwords.words('english')), text.split()))\n    return \" \".join(text_without_stopwords)","e88d9b89":"X_train = X_train.apply(lambda word: remove_stopwords(word))","ea747a89":"X_train","c60f4ddd":"count_vectorizer = TfidfVectorizer()\nX_train= count_vectorizer.fit_transform(X_train)\nX_test = count_vectorizer.transform(data_test['OriginalTweet'])\n\nle = preprocessing.LabelEncoder()\nle.fit(data_train['Sentiment'])\ny_train = le.transform(data_train['Sentiment'])\ny_test = le.transform(data_test['Sentiment'])","80d3c2ff":"le.classes_","355a7f28":"clf = LogisticRegression(random_state = 1)\nclf.fit(X_train, y_train)","a1006d8b":"cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)","8221f894":"y_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))","9080b486":"print(confusion_matrix(y_test, y_pred))","7d29d81f":"def classes_def(x):\n    if x == \"Extremely Positive\" or x == \"Positive\":\n        return 2\n    elif x == \"Extremely Negative\" or x == \"Negative\":\n        return 0\n    else:\n        return 1\n    \ny_train_3classes = data_train['Sentiment'].apply(lambda x:classes_def(x))\ny_test_3classes = data_test['Sentiment'].apply(lambda x:classes_def(x))","acd31b14":"clf.fit(X_train, y_train_3classes)\ncross_val_score(clf, X_train, y_train_3classes, scoring='accuracy', cv=5)","302da4c4":"y_pred = clf.predict(X_test)\nprint(classification_report(y_test_3classes, y_pred))","15bcf89d":"index_to_word = {v:k for k,v in count_vectorizer.vocabulary_.items()}\nwords_coef = {(index_to_word[i], clf.coef_[0][i]) for i in range(clf.coef_.shape[1])}\nsorted(words_coef, key=lambda word_coef: word_coef[1], reverse=True)[:10]","0c0559b4":"Let's look at the most important words for negative classification.","ae9a22ce":"# Data preprocessing","950bbf4e":"Looks like the classifier don't distinguish Extremely Negative and Extremely Positive from Negative and Positive. Let's reduce sentiments shades.","8edb3db6":"Words look correct.","b372e1fa":"# Data importing and EDA","757b0765":"We see that for all sentiments words like 'coronavirus', 'people', 'store', 'supermarket', 'price' are often used."}}