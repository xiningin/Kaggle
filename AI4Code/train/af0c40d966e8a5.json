{"cell_type":{"2654496d":"code","16f8ec15":"code","1e9e668a":"code","f892dc32":"code","951bf8b8":"code","9fa1082f":"code","be1ccaf1":"code","d8954d87":"code","f91929c2":"code","39e88950":"code","66b1afad":"code","e692df97":"code","9046b329":"code","9bdcda4c":"code","12aef639":"code","d0e6a3d2":"code","39366a24":"code","4ccd7fdf":"code","0b4ed9cc":"code","d9f87133":"markdown","87718266":"markdown","b0c220b2":"markdown","83648c82":"markdown","42c79c10":"markdown","1fdce38e":"markdown","8bcf51ad":"markdown","e75bd323":"markdown"},"source":{"2654496d":"#import numpy for number array handling and represent rgb image pixel values\nimport numpy as np\n\n#import tensorflow to use any tools needed for deep learning\nimport tensorflow as tf\n\n#import keras api needed to implement deep learning techiques\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#import libraries for visualization of data\nimport matplotlib.pyplot as plt\n\n#Allow charts and graphics to display right below the page of browser setup\n%matplotlib inline","16f8ec15":"#paths to the train, validation and test image datasets \ntrain_path = '..\/input\/garbage-classification\/garbage classification\/Garbage classification'\nvalid_path = '..\/input\/garbage-classification\/garbage classification\/Garbage classification'\n\n\n# extract images to training set by applying data preprocessing and data augmentation\ntrain_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.1).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n\n\n# extract images to validation set\nvalid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    validation_split=0.1).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')\n","1e9e668a":"# plot images after applying VGG16 data preprocessing method\ndef plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","f892dc32":"imgs, labels = next(train_batches)\nplotImages(imgs)","951bf8b8":"# set the input image size for proposed CNN model\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\n# import the convolution base of the VGG16 model with pre-trained weights\nbase_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')","9fa1082f":"# summary of convolution base of VGG16 model\nbase_model.summary()","be1ccaf1":"# Initialize a sequential model to group a linear stack of layers\nmodel = Sequential()\n\n# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated \n# during training inorder to extract features\nbase_model.trainable=False\n\n# add VGG16 convolution base to initialize sequential model\nmodel.add(base_model)\n\n# add global average pooling layer\nmodel.add(GlobalAveragePooling2D())\n\n# add densely-connected NN layer with 512 hidden units\nmodel.add(Dense(units=512, activation='relu'))  # use ReLU activation function\nmodel.add(BatchNormalization())                 # normalize and scale inputs or activations\nmodel.add(Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n\n# add densely-connected NN layer with 128 hidden units\nmodel.add(Dense(units=128, activation='relu')) # use ReLU activation function\nmodel.add(BatchNormalization())                # normalize and scale inputs or activations\nmodel.add(Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n\n# add densely-connected NN layer with 6 hidden units\nmodel.add(Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions","d8954d87":"# summary of proposed CNN model(architecture)\nmodel.summary()","f91929c2":"# compile the built CNN model by selecting suitable optimizer and loss function\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","39e88950":"# train the model with appropriate number of epochs\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=18, verbose=2)","66b1afad":"# store the losses of training\nloss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss']","e692df97":"# store the accuracy of training\naccuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']","9046b329":"# unfreeze the convolution base of VGG16 inorder to fine-tune which adapt these pre-trained weights \n# to work with the new dataset\nbase_model.trainable=True","9bdcda4c":"# summary of the fine-tune CNN model\nmodel.summary()","12aef639":"# train and fine-tune the model with appropriate number of epochs\nmodel_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=4, verbose=2)","d0e6a3d2":"# append the losses to previous stored losses\nloss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])","39366a24":"# append the accuracy to previous stored accuracy\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])","4ccd7fdf":"# plot the training and validation losses\nepochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()","0b4ed9cc":"# plot the training and validation accuracy\nepochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","d9f87133":"# 6. Train the CNN model","87718266":"# 1. initial Setup and Imports","b0c220b2":"# 2. Load and Split images along with applying Data Preprocessing and Data Augmentation","83648c82":"# 8. Visulization of Accuracy and Loss in Training and  Validation sets","42c79c10":"# 3. Visualization of the images after Preprocessing","1fdce38e":"# 5. Compile the Built CNN Model","8bcf51ad":"# 7. Fine Tune the CNN model","e75bd323":"# 4. Building CNN Architecture"}}