{"cell_type":{"99341fbb":"code","fa6f3264":"code","c9f2fb88":"code","6e979070":"code","da25666f":"code","1bb5a8dc":"code","84ffc2f1":"code","0d523496":"code","ec7c98c9":"code","58a0f10b":"code","5550c656":"code","d6ede2ad":"markdown"},"source":{"99341fbb":"import numpy as np\nimport pandas as pd\nimport glob\nfrom tqdm import tqdm\nimport sys, os\n\n\ndef load_data(mode, path=\"\/kaggle\/input\/optiver-realized-volatility-prediction\"):\n    # mode = \"train\"\/\"test\"\n    file_name = f'{path}\/{mode}.csv'\n    return pd.read_csv(file_name)\n\ndf = load_data(\"test\")\nprint(df.shape, df[\"stock_id\"].max())\ndf.head()","fa6f3264":"SCALE = 100\nPATH = \"\/kaggle\/input\/optiver-realized-volatility-prediction\"\n\norder_book_paths = glob.glob(f'{PATH}\/book_test.parquet\/*\/*')\nlen(order_book_paths)","c9f2fb88":"trade_paths = glob.glob(f'{PATH}\/trade_test.parquet\/*\/*')\nlen(trade_paths)","6e979070":"order_books = dict()\n\n\nfor path in tqdm(order_book_paths):\n    stock_id = int(path.split(\"=\")[1].split(\"\/\")[0])\n    book_df = pd.read_parquet(path)\n    books_by_time = dict()\n    \n    for time_id in book_df.time_id.unique():\n        books_by_time[time_id] = book_df[book_df[\"time_id\"] == time_id].reset_index(drop=True)\n    \n    order_books[stock_id] = books_by_time","da25666f":"trades = dict()\n\n\nfor path in tqdm(trade_paths):\n    stock_id = int(path.split(\"=\")[1].split(\"\/\")[0])\n    trade_df = pd.read_parquet(path)\n    trade_by_time = dict()\n    \n    for time_id in trade_df.time_id.unique():\n        trade_by_time[time_id] = trade_df[trade_df[\"time_id\"] == time_id].reset_index(drop=True)\n    \n    trades[stock_id] = trade_by_time","1bb5a8dc":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\n\nmeans_order = torch.FloatTensor([  0.9997,   1.0003, 769.9902, 766.7346,   0.9995,   1.0005, 959.3417,\n        928.2203, 300])\nstds_order = torch.FloatTensor([3.6881e-03, 3.6871e-03, 5.3541e+03, 4.9549e+03, 3.7009e-03, 3.6991e-03,\n        6.6838e+03, 5.7353e+03, 300])\n\nmeans_trade = torch.FloatTensor([300, 1.0, 100, 3.0])\nstds_trade = torch.FloatTensor([300, 0.004, 153, 3.5])\n\n\n\nclass OptiverDataset(Dataset):\n    \n    def __init__(self, df, aug=False):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.aug = aug\n        self.seq_len = 600\n        self.order_features = ['bid_price1', 'ask_price1', 'bid_size1', 'ask_size1','bid_price2', \n                         'ask_price2', 'bid_size2', 'ask_size2', \"seconds_in_bucket\"]\n        self.trade_features = [\"seconds_in_bucket\", \"price\", \"size\", \"order_count\"]\n        \n    \n    def extract_features(self, data_dict, stock_id, time_id, features, means, stds):\n        X = -torch.ones((self.seq_len, len(features)))\n        try:\n            df = data_dict[stock_id][time_id]\n            feature_array = df[features].values\n            X[-feature_array.shape[0]:] = (torch.FloatTensor(feature_array) - means)\/stds\n        except:\n            pass\n        return X\n\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        X1 = self.extract_features(order_books, row.stock_id, row.time_id, self.order_features,\n                                  means_order, stds_order)\n        try:\n            X2 = self.extract_features(trades, row.stock_id, row.time_id, self.trade_features,\n                                      means_trade, stds_trade) \n        except:\n            X2 = -torch.ones((self.seq_len, len(self.trade_features)))\n        target = torch.FloatTensor([0.0])\n        stock = torch.LongTensor([row.stock_id])\n        return X1, X2, stock, target\n\n    def __len__(self):\n        return self.df.shape[0]\n    \nds = OptiverDataset(df)\nds[1]","84ffc2f1":"class ConvBlock(nn.Module):\n    def __init__(self, in_dim, out_dim, kernel_size, stride=1):\n        super().__init__()\n        self.lin = nn.Conv1d(in_dim, out_dim, kernel_size, stride=stride)\n        self.bn = nn.BatchNorm1d(out_dim)\n        self.activation = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.lin(x)\n        x = self.bn(x)\n        return self.activation(x)\n        \n\nclass SubModel(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.convs1 = nn.Sequential(ConvBlock(in_dim, 16, 3),\n                                   ConvBlock(16, 32, 3))\n        self.stock_conv = ConvBlock(36, 64, 4, stride=4)\n        self.avg_pool = nn.AdaptiveAvgPool1d(8)\n        self.max_pool = nn.AdaptiveMaxPool1d(8)\n        self.convs2 = nn.Sequential(ConvBlock(128, 128, 2, stride=2),\n                                    ConvBlock(128, 32, 2, stride=2),\n                                    ConvBlock(32, 8, 2, stride=2))\n        \n    def forward(self, x, s):\n        x = self.convs1(x.transpose(2, 1))\n        x = self.stock_conv(torch.cat([x, s.repeat(1, 1, x.shape[2])], axis=1))\n        x = torch.cat([self.avg_pool(x), self.max_pool(x)], axis=1)\n        x = self.convs2(x).squeeze(-1)\n        return x\n    \n    \nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.order_model = SubModel(in_dim=9)\n        self.trade_model = SubModel(in_dim=4)\n        self.top = nn.Linear(16, 1)\n        self.stock_emb = nn.Embedding(127, 4)\n        \n    def forward(self, inputs):\n        x1, x2, s = inputs\n        s = self.stock_emb(s).transpose(2, 1)\n        \n        x1 = self.order_model(x1, s)\n        x2 = self.trade_model(x2, s)\n        x = self.top(torch.cat([x1, x2], axis=1))\n        return x\n    \n    \n","0d523496":"def read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\ndef inference(model, loader, num_folds=5):\n    model.eval()\n    \n    tbar = tqdm(loader, file=sys.stdout)\n    \n    preds = []\n    \n    model_weights = {i: torch.load(f\"\/kaggle\/input\/optiver-nn\/optiver_nn_v01_{i}.pth\") for i in range(num_folds)}\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            model.load_state_dict(model_weights[0])\n            pred = model(inputs)\/num_folds\n            for i in range(1, num_folds):\n                model.load_state_dict(model_weights[i])\n                pred += model(inputs)\/num_folds\n\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(preds)\n\nNW = 4\nBS = 256\nloader = DataLoader(ds, batch_size=BS, shuffle=False, num_workers=NW, pin_memory=False, drop_last=False)\n\n\nmodel = Model()\nmodel = model.cuda()\n\ny = inference(model, loader)","ec7c98c9":"df[\"target\"] = np.clip(y, 0.0, None)\/SCALE\n\ndf.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"target\"])","58a0f10b":"df.head()","5550c656":"def adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 10:\n        lr = 1e-3\n    elif epoch < 27:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer\n\ndef rmspe(y_true, y_pred):\n    y_pred = np.clip(y_pred, 0, None)\n    return (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\n\ndef loss_func(y_pred, y_true):\n    return torch.mean(torch.square((y_true - y_pred) \/ y_true))\n\n\ndef validate(model, val_loader):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs)\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)\n\n\n\ndef train(model, train_loader, val_loader, epochs):\n    \n    optimizer = get_optimizer(model)\n    \n    for e in range(epochs):\n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            pred = model(inputs)\n\n            loss = loss_func(pred, target)\n            loss.backward()\n            optimizer.step()\n            \n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n            \n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n            \n        val_labels, val_preds = validate(model, val_loader)\n        val_metric = np.round(rmspe(val_labels, val_preds), 4)\n\n        train_metric = np.round(rmspe(np.concatenate(labels), np.concatenate(preds)), 4)\n        log_text = f\"Epoch {e+1}\\n Train metric: {train_metric}\\nValidation metric: {val_metric}\\n\"\n            \n        print(log_text)\n    return model, val_preds\n\n\n\ndef kfold_train(BS=512, NW=8, NUM_FOLDS=5):\n    oof_preds = np.zeros(df.shape[0])\n\n    for fold in range(NUM_FOLDS):\n        print(f\"Fold {fold + 1}\")\n        train_ind = np.where(df[\"time_id\"].values % NUM_FOLDS != fold)[0]\n        val_ind = np.where(df[\"time_id\"].values % NUM_FOLDS == fold)[0]\n\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n\n\n        train_ds = OptiverDataset(train_df, aug=False)\n        val_ds = OptiverDataset(val_df, aug=False)\n\n        train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n                                  pin_memory=False, drop_last=True)\n        val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                                  pin_memory=False, drop_last=False)\n\n        model = Model()\n        model.cuda()\n        model, val_preds = train(model, train_loader, val_loader, epochs=30)\n\n        oof_preds[val_ind] = val_preds\n\n        torch.save(model.state_dict(), f\"models\/optiver_nn_v01_{fold}.pth\")\n        \n    df[\"nn_pred\"] = oof_preds\/SCALE\n    df.to_csv(\"cache\/optiver_nn_v01_oof.csv\", index=False, columns=[\"stock_id\", \"time_id\", \"nn_pred\"])","d6ede2ad":"## Required functions for training\n\n1 fold takes 1 hour on a laptop with Nvidia Quadro RTX 5000."}}