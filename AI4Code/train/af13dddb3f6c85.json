{"cell_type":{"3052e9ca":"code","b829ff4c":"code","b955bfdc":"code","268432de":"code","7e8cf862":"code","6c846f15":"code","680b00e1":"code","29aec588":"code","2b769cdd":"code","bb1271a0":"code","74a820e6":"code","79239ad5":"code","a11d3661":"code","44b18248":"markdown","d9e7999e":"markdown"},"source":{"3052e9ca":"import numpy as np\n\nimport os\nimport json\nimport h5py\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nimport glob\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","b829ff4c":"def load_data(data_path, target_size=(128,128)):\n    img_arr_img = []\n    filelist_img = glob.glob(data_path+\"*.png\")\n    image_paths = sorted(filelist_img)\n    \n    for image_path in image_paths:\n        try:\n            image = cv2.imread(image_path)\n            image = cv2.resize(image, dsize=target_size)#interpolation=cv2.INTER_CUBIC) #\/255.0\n            #cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n            img_arr_img.append(image)\n        except (RuntimeError, TypeError,NameError) as e:\n            print(e)\n            pass\n    return np.asarray(img_arr_img), image_paths ","b955bfdc":"path_infected = '\/kaggle\/input\/cell_images\/cell_images\/Parasitized\/'\npath_uninfected = '\/kaggle\/input\/cell_images\/cell_images\/Uninfected\/'\n\nX_infected, filenames_infected = load_data(path_infected)\nX_uninfected, filenames_uninfected = load_data(path_uninfected)","268432de":"# We stack vertically X_infected and X_uninfected to make the data tensor X\nX = np.vstack((X_uninfected, X_infected))\n\n# Let's create the labels vector\n# 0 stands for not infected\n# 1 stands for infected\nlabels = [0]*X_uninfected.shape[0] + [1]*X_infected.shape[0]\n\n# We need to separate the data into train and test arrays \nX_train, X_test, y_train, y_test = train_test_split(X,labels,test_size=0.1,random_state=42)\n","7e8cf862":"fig=plt.figure(figsize=(28, 28))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(X_train[i])\n    if y_train[i] == 0:\n        plt.title('Uninfected')\n    else:\n        plt.title('Infected')\n    \nplt.show()\n","6c846f15":"from keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n\nK.set_image_data_format('channels_last')\nnp.random.seed(0)\n\ndef create_model(input_shape, with_summary):\n    model = Sequential()\n    model.add(Conv2D(10, kernel_size=5, padding=\"same\", input_shape=input_shape, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Conv2D(20, kernel_size=3, padding=\"same\", activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Conv2D(30, kernel_size=3, padding=\"same\", activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    #model.add(Conv2D(500, kernel_size=3, padding=\"same\", activation = 'relu'))\n    #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    #model.add(Conv2D(1024, kernel_size=3, padding=\"valid\", activation = 'relu'))\n    #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(units=30, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(units=10, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(units=5, activation='relu'))\n    #model.add(Dropout(0.1))\n\n    model.add(Dense(1))\n    model.add(Activation(\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    if with_summary:\n        model.summary()\n\n    return model\n\ndef save_history(hist, filepath):\n    with open(filepath, 'w') as f:\n        json.dump(hist.history, f)\n\ndef plot_loss(history_filepath):\n    with open(history_filepath) as json_data:\n        history = json.load(json_data)\n        #print(history)\n    print(history.keys())\n    plt.plot(history['loss'])\n    plt.plot(history['acc'])\n    plt.title('Training metrics')\n    #plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['loss', 'accuracy'], loc='upper left')\n    plt.show()","680b00e1":"input_shape = (128, 128, 3)\nmodel = create_model(input_shape=input_shape, with_summary=True)","29aec588":"hist = model.fit(X_train, y_train,batch_size=512,epochs=20)","2b769cdd":"print(model.evaluate(X_test, y_test))\nmodel.save_weights('\/kaggle\/working\/cnn_model_20ep.h5') #model weights saved ","bb1271a0":"save_history(hist, filepath='\/kaggle\/working\/training_history.json')\nplot_loss(history_filepath='\/kaggle\/working\/training_history.json')","74a820e6":"predictions = model.predict(X_test)\n\nfig=plt.figure(figsize=(28, 28))\ncolumns = 5\nrows = 5\nrandom_number = np.random.randint(0,X_test.shape[0]-26)\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(X_test[i+random_number])\n    gt = ['Not infected', 'Infected']\n    plt.title('Infection likelihood {:.1%}\\n Ground Truth:{} '.format(float(predictions[i+random_number]), gt[y_test[i+random_number]]))\n    \nplt.show()","79239ad5":"from sklearn.metrics import classification_report, confusion_matrix\n\nthreshold = 0.65\npredictions_final = [int(pred>threshold) for pred in predictions]\n\nprint(classification_report(y_test, predictions_final))","a11d3661":"def draw_confusion_matrix(true,preds):\n    conf_matx = confusion_matrix(true, preds)\n    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n    plt.show()\n\ndraw_confusion_matrix(y_test, predictions_final)","44b18248":"# The Convolutionnal neural network managed to reach 97% accuracy on the images it trained on. After evaluating its performance on the test dataset, we get an accuracy of 94% for a binary crossentropyloss of 0.2 which is not bad after 20 epochs.\n\n# Let's display 25 random test examples prediction results :","d9e7999e":"# Let's use the classification_report function from sklearn and play with the threshold value until optimal scores for precision, recall and f1-score are reached."}}