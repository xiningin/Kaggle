{"cell_type":{"aa96a1b2":"code","f53886aa":"code","0e64a774":"code","fb234bcf":"code","70a98456":"code","bf34f327":"code","52d5bef0":"code","0629de80":"code","5cdd246c":"code","acd1c24e":"code","dec1bc06":"code","bed92423":"code","7c2bc9bc":"code","492f0ed8":"code","518ceb66":"code","d14733c3":"code","c8d8eb7d":"code","9a231708":"code","23d5f846":"code","ec609014":"markdown","88e2f1a4":"markdown","08d7f836":"markdown","05d0f8fb":"markdown","f597327c":"markdown","db845be8":"markdown","8a4e16bf":"markdown","df05118d":"markdown","8a05385c":"markdown","c4408d57":"markdown"},"source":{"aa96a1b2":"#===========================================================\n# Library\n#===========================================================\nimport os\nimport gc\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\nfrom contextlib import contextmanager\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom scipy.sparse import csr_matrix\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom functools import partial\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn import preprocessing\nimport category_encoders as ce\nfrom sklearn.metrics import mean_squared_error\n\n\nimport torch\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f53886aa":"os.listdir('..\/input\/trends-assessment-prediction\/')","0e64a774":"#===========================================================\n# Utils\n#===========================================================\ndef get_logger(filename='log'):\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nlogger = get_logger()\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\n\ndef seed_everything(seed=777):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n    \ndef load_df(path, df_name, debug=False):\n    if path.split('.')[-1]=='csv':\n        df = pd.read_csv(path)\n        if debug:\n            df = pd.read_csv(path, nrows=1000)\n    elif path.split('.')[-1]=='pkl':\n        df = pd.read_pickle(path)\n    if logger==None:\n        print(f\"{df_name} shape \/ {df.shape} \")\n    else:\n        logger.info(f\"{df_name} shape \/ {df.shape} \")\n    return df","fb234bcf":"#===========================================================\n# Config\n#===========================================================\nOUTPUT_DICT = ''\n\nID = 'Id'\nTARGET_COLS = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\nSEED = 42\nseed_everything(seed=SEED)\n\nN_FOLD = 5","70a98456":"train = pd.read_csv('..\/input\/trends-assessment-prediction\/train_scores.csv', dtype={'Id':str})\nreveal_ID = pd.read_csv('..\/input\/trends-assessment-prediction\/reveal_ID_site2.csv', dtype={'Id':str})\nICN_numbers = pd.read_csv('..\/input\/trends-assessment-prediction\/ICN_numbers.csv')\nloading = pd.read_csv('..\/input\/trends-assessment-prediction\/loading.csv', dtype={'Id':str})\nfnc = pd.read_csv('..\/input\/trends-assessment-prediction\/fnc.csv', dtype={'Id':str})\nsample_submission = pd.read_csv('..\/input\/trends-assessment-prediction\/sample_submission.csv', dtype={'Id':str})","bf34f327":"sample_submission['ID_num'] = sample_submission[ID].apply(lambda x: int(x.split('_')[0]))\ntest = pd.DataFrame({ID: sample_submission['ID_num'].unique().astype(str)})\ndel sample_submission['ID_num']; gc.collect()\ntest.head()","52d5bef0":"Fold = KFold(n_splits=N_FOLD, shuffle=True, random_state=SEED)\nfor n, (train_index, val_index) in enumerate(Fold.split(train)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ntrain.head()","0629de80":"train.isnull().sum()","5cdd246c":"full = pd.concat([train, test], axis=0, sort=False)\nfull = full.set_index([ID, 'fold']) \\\n    .stack(dropna=False).reset_index().rename(columns={'level_2': 'feature',\n                                                       0: 'target'})\nfull['full_Id'] = [f'{i}_{j}' for i, j in zip(full['Id'], full['feature'])]","acd1c24e":"# merge\nfull = full.merge(loading, on=ID, how='left')\nfull = full.merge(fnc, on=ID, how='left')\nfull.head()","dec1bc06":"# category\nfeature_dict = {'age': 0,\n                'domain1_var1': 1,\n                'domain1_var2': 2,\n                'domain2_var1': 3,\n                'domain2_var2': 4}\nfull['feature_cat'] = full['feature'].map(feature_dict)\nfull.head()","bed92423":"train = full.loc[full['target'].notnull()].reset_index(drop=True)\ntrain['fold'] = train['fold'].astype(int)\ntest = full.loc[full['target'].isnull()].reset_index(drop=True)       ","7c2bc9bc":"train.shape, test.shape","492f0ed8":"# metric\n\nclass Metric():\n    # https:\/\/www.kaggle.com\/girmdshinsei\/for-japanese-beginner-with-wrmsse-in-lgbm\n    def __init__(self, feature):\n        super().__init__()\n        self.feature_name = ['age', 'domain1_var1', 'domain1_var2',\n                             'domain2_var1', 'domain2_var2']\n        self.feature_mat_csr = self._get_feature_matrix_csr(feature)\n\n    def _get_feature_matrix_csr(self, feature):\n        mat = pd.get_dummies(feature).loc[:, self.feature_name].values\n        mat_csr = csr_matrix(mat)\n        return mat_csr\n\n    def _calc_fwnae_csr(self, preds, y_true):\n        scores = np.abs(preds - y_true) * self.feature_mat_csr \/ (y_true * self.feature_mat_csr)\n        score = np.average(scores, weights=np.array([0.3, 0.175, 0.175, 0.175, 0.175]))\n        return score\n\n    def _calc_fwnae(self, preds, y_true):\n        scores = np.abs(preds - y_true) * self.feature_mat_csr \/ np.dot(y_true, self.feature_mat)\n        score = np.average(scores, weights=np.array([0.3, 0.175, 0.175, 0.175, 0.175]))\n        return score\n\n    def fwnae_lgb(self, preds, data):\n        \"\"\"\n        # this function is calculate feature-weighted, normalized absolute errors\n        # https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/overview\/evaluation\n        \"\"\"\n        y_true = data.get_label()  # actual obserbed values\n        fwnae = self._calc_fwnae_csr(preds, y_true)\n\n        return 'fwnae', fwnae, False\n\n    def _calc_each_fwnae_csr(self, preds, y_true):\n        scores = np.abs(preds - y_true) * self.feature_mat_csr \/ (y_true * self.feature_mat_csr)\n        return scores\n\n    def calc_each_fwnae(self, preds, y_train):\n        scores = self._calc_each_fwnae_csr(preds, y_train)\n        scores_dict = {i: j for i, j in zip(self.feature_name, scores)}\n        score = np.average(scores, weights=np.array([0.3, 0.175, 0.175, 0.175, 0.175]))\n        return scores_dict, score\n","518ceb66":"#===========================================================\n# model\n#===========================================================\ndef run_single_lightgbm(param, train_df, test_df, folds, features, target, fold_num=0, categorical=[]):\n    \n    trn_idx = folds[folds.fold != fold_num].index\n    val_idx = folds[folds.fold == fold_num].index\n    logger.info(f'len(trn_idx) : {len(trn_idx)}')\n    logger.info(f'len(val_idx) : {len(val_idx)}')\n    metric = Metric(folds.iloc[val_idx]['feature'])\n    \n    if categorical == []:\n        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n                               label=target.iloc[trn_idx])\n        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n                               label=target.iloc[val_idx])\n    else:\n        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features],\n                               label=target.iloc[trn_idx],\n                               categorical_feature=categorical)\n        val_data = lgb.Dataset(train_df.iloc[val_idx][features],\n                               label=target.iloc[val_idx],\n                               categorical_feature=categorical)\n\n    oof = np.zeros(len(train_df))\n    predictions = np.zeros(len(test_df))\n\n    num_round = 2000\n\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets=[val_data],\n                    feval=metric.fwnae_lgb,\n                    verbose_eval=100,\n                    early_stopping_rounds=100)\n\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_num\n\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration)\n    \n    # RMSE\n    logger.info(\"fold{} RMSE score: {:<8.5f}\".format(fold_num, np.sqrt(mean_squared_error(target[val_idx], oof[val_idx]))))\n    \n    return oof, predictions, fold_importance_df\n\n\ndef run_kfold_lightgbm(param, train, test, folds, features, target, n_fold=5, categorical=[]):\n    \n    logger.info(f\"================================= {n_fold}fold lightgbm =================================\")\n    \n    oof = np.zeros(len(train))\n    predictions = np.zeros(len(test))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_ in range(n_fold):\n        print(\"Fold {}\".format(fold_))\n        _oof, _predictions, fold_importance_df = run_single_lightgbm(param,\n                                                                     train,\n                                                                     test,\n                                                                     folds,\n                                                                     features,\n                                                                     target,\n                                                                     fold_num=fold_,\n                                                                     categorical=categorical)\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        oof += _oof\n        predictions += _predictions \/ n_fold\n\n    # RMSE\n    logger.info(\"CV RMSE score: {:<8.5f}\".format(np.sqrt(mean_squared_error(target, oof))))\n\n    logger.info(f\"=========================================================================================\")\n    \n    return feature_importance_df, predictions, oof\n\n    \ndef show_feature_importance(feature_importance_df):\n    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n            .groupby(\"Feature\")\n            .mean()\n            .sort_values(by=\"importance\", ascending=False)[:50].index)\n    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\n    plt.figure(figsize=(8, 16))\n    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('Features importance (averaged\/folds)')\n    plt.tight_layout()\n    plt.savefig(OUTPUT_DICT+f'feature_importance.png')","d14733c3":"TARGET_COLS = ['target']\ntarget = train[TARGET_COLS[0]]\n\n# features\nfolds = train[['fold', 'feature']]\ncat_features = []\nnum_features = [c for c in test.columns if (test.dtypes[c] != 'object') & (c not in cat_features)]\nfeatures = num_features + cat_features\nDROP_COLS = ['fold', 'feature', 'full_Id']\ndrop_features = [ID] + TARGET_COLS + DROP_COLS\nfeatures = [c for c in features if c not in drop_features]\n\nlgb_param = {'objective': 'regression',\n         'boosting_type': 'gbdt',\n         'learning_rate': 0.03,\n         'seed': SEED,\n         'max_depth': -1,\n         'verbosity': -1\n        }\n\nfeature_importance_df, predictions, oof = run_kfold_lightgbm(lgb_param, train, test, folds, features, target, \n                                                             n_fold=N_FOLD, categorical=cat_features)\n\nshow_feature_importance(feature_importance_df)","c8d8eb7d":"metric = Metric(folds['feature'])\nscores = metric.calc_each_fwnae(oof, train['target'].values)\n\nlogger.info(f'Local Score: {scores[1]}')\nlogger.info(f'Local Score: {scores[0]}')","9a231708":"sample_submission.head()","23d5f846":"sample_submission.set_index(ID, inplace=True)\nsub = test[['full_Id']]\nsub['Predicted'] = predictions\nsub.set_index('full_Id', inplace=True)\nsample_submission['Predicted'] = sub['Predicted']\nsample_submission.reset_index(inplace=True)\nsample_submission.to_csv('submission.csv', index=False)","ec609014":"# MODEL","88e2f1a4":"# Library","08d7f836":"# prepare folds","05d0f8fb":"# Submission","f597327c":"# Data Loading","db845be8":"# Utils","8a4e16bf":"## update\n* ver2  \nChanged from deleting lines with missing values to deleting only missing values.","df05118d":"# FE","8a05385c":"# Config","c4408d57":"This notebook is based on this [baseline notebook](https:\/\/www.kaggle.com\/yasufuminakama\/trends-lgb-baseline).  \n\nThe two major changes are as follows.\n* Calculate early stooping using the feature-weighted, normalized absolute errors.\n* There's only one model.\n\nI tried a few things, including changing the ovjective of Lightgbm, but I couldn't get a better score than the original beseline notebook.  \nIt might be better to create five models per feature."}}