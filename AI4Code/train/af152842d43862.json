{"cell_type":{"645cf64a":"code","63c4ab0c":"code","65933ad4":"code","761b57ec":"code","26de5bb3":"code","30065433":"code","28213829":"markdown"},"source":{"645cf64a":"import pandas as pd\nimport seaborn as sns\nimport datetime as datetime\nfrom matplotlib import pyplot as plt\nimport re\nfrom textblob import TextBlob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom pandas.tseries.offsets import BDay\n\n\nmusk_tweets_data_file = '..\/input\/elon-musks-tweets\/data_elonmusk.csv'\ntesla_stock_data_file = '..\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv'\n\ntweets_df = pd.read_csv(musk_tweets_data_file, encoding='latin1')\ntesla_stock_price_df = pd.read_csv(tesla_stock_data_file)\n\ndef clean_tweet(tweet):\n    \"\"\" Utility function to clean tweet text by removing links, special characters using simple regex statements. \"\"\"\n    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\/\/\\S+)\", \" \", tweet).split())\n\n# Return the polarity of the tweet using TextBlob analysis\ndef analyse_tweet(tweet):\n    \"\"\" Utility function to classify sentiment of passed tweet using textblob's sentiment method \"\"\"\n    clean_tweet(tweet)\n    # create TextBlob object of passed tweet text\n    tweet_analysis = TextBlob(tweet)\n    return tweet_analysis.sentiment.polarity\n\n# Analyse tweet using TextBlob and categorize it as 'positive', 'negative' or 'neutral'\ndef get_tweet_sentiment(tweet):\n    tweet_polarity = analyse_tweet(tweet)\n    # set sentiment\n    if tweet_polarity > 0:\n        return 'positive'\n    elif tweet_polarity == 0:\n        return 'neutral'\n    else:\n        return 'negative'\n\ndef filter_by_daterange(df):\n    start_date = pd.to_datetime(\"2012-1-1\").date()\n    end_date = pd.to_datetime(\"2017-12-31\").date()\n    mask = (df['Time'] > start_date) & (df['Time'] <= end_date)\n    df = df.loc[mask]\n    #Filter only Business day\n    isBusinessDay = BDay().onOffset\n    match_series = pd.to_datetime(df['Time']).map(isBusinessDay)\n    df[match_series]\n    return df\n\ndef clean_tweet_data(tweets):\n    # Drop unwanted columns\n    tweets = tweets.drop('row ID',1)\n    tweets = tweets.drop('User',1)\n    # Convert 'Time' column to datetime and strip time information.\n    tweets['Time'] = pd.to_datetime(tweets['Time']).dt.date\n    # Consider only dates between a range\n    tweets = filter_by_daterange(tweets)\n    # Add sentiment of the tweet to the data.\n    tweets['Sentiment'] = tweets.apply(lambda row : get_tweet_sentiment(row['Tweet']), axis=1)\n    tweets_sentiment = tweets[['Time', 'Sentiment']].copy() \n    # Will consider maximum tweet sentiment as the sentiment of the day.\n    tweets_sentiment = tweets_sentiment.groupby(tweets_sentiment.Time)\\\n                        .agg(lambda x: x.value_counts().index[0])\n    tweets_sentiment.sort_values(by=['Time'], inplace=True)\n    return tweets_sentiment\n\ndef clean_stock_data(stock_data):\n    #Remove null stock data.\n    stock_data = stock_data.dropna()\n    #Convert 'Date' column to datetime and strip time information.\n    stock_data['Time'] = pd.to_datetime(stock_data['Date']).dt.date\n    stock_data = stock_data.drop('Date',1)\n    #Consider only dates between a range\n    stock_data = filter_by_daterange(stock_data)    \n    #Calculate daily change percentage\n    stock_data['daily_percentage_change'] = (stock_data['Close'] - stock_data['Open']) \/ stock_data['Open'] * 100\n    stock_daily_change = stock_data[['Time', 'daily_percentage_change']].copy()\n    stock_daily_change.sort_values(by=['Time'], inplace=True)\n    return stock_daily_change\n\ndef merge_tweets_and_stock_data(tweets_sentiment_data, stock_price_change_data):\n    #Combine two dataframes based on time.\n    sentiment_stock_change_data = pd.merge(tweets_sentiment_data, stock_price_change_data, on='Time', how='inner')\n    return sentiment_stock_change_data\n\ndef make_sentiment_column_categorical(tweet_sentiment_with_price_change):\n    #Change 'Sentiment' column to categorical column.\n    tweet_sentiment_with_price_change['Sentiment'] = tweet_sentiment_with_price_change['Sentiment'].astype('category')\n    tweet_sentiment_with_price_change['Sentiment'] = tweet_sentiment_with_price_change['Sentiment'].cat.codes\n    return tweet_sentiment_with_price_change\n\ndef do_linear_regression(X, Y):\n    #Split data in train and test\n    X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n    # Train the model\n    linear_regression_model = LinearRegression()\n    linear_regression_model.fit(X_train, Y_train)\n    # Calculate the r2_score (variance score) using sklearn linear_model.\n    r2_score_1 = linear_regression_model.score(X, Y)\n    # Predict stock change percentage with the trained model using test data.\n    y_predicted = linear_regression_model.predict(x_test)\n    # r2_score using sklearn metrics (1 is perfect prediction)\n    r2_score_2 = r2_score(y_test, y_predicted)\n    # Plot residuals of the data using seaborn residplot\n    plt.figure(figsize=(15,4))\n    sns.residplot(sentiment, price_change)\n    plt.xlabel(\"Sentiment\")\n    plt.ylabel(\"Price change\")\n    plt.title(\"Residual Plot - Tweet Sentiment vs Tesla Price Change Percent using linear regression\")\n    plt.show()\n    # Plot actual vs predicted stock price change from the model\n    plt.figure(figsize=(15,4))\n    plt.scatter(X, Y,  color='black')\n    plt.plot(y_test, y_predicted, color='blue', linewidth=3)\n    plt.xlabel(\"Sentiment\")\n    plt.ylabel(\"Stock Price Change Percent\")\n    plt.title(\"Scatter Plot - Tweet Sentiment vs Tesla Stock Price Change Percent using linear regression\")\n    plt.show()\n    \n    return r2_score_1, r2_score_2\n\ndef do_random_forest_analysis(X, Y):\n    #Split data in train and test\n    X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n    #Train the model.\n    random_forest_model = RandomForestRegressor()\n    random_forest_model.fit(X_train, Y_train)\n    #Calculate the r2 score by applying the model.\n    r2_score_1 = random_forest_model.score(X, Y)\n    # Predict stock change percentage with the trained model using test data.\n    y_predicted = random_forest_model.predict(x_test)\n    # r2_score using sklearn metrics (1 is perfect prediction)\n    r2_score_2 = r2_score(y_test, y_predicted)\n    # Plot residuals of the data using seaborn residplot\n    plt.figure(figsize=(15,4))\n    sns.residplot(sentiment, price_change)\n    plt.xlabel(\"Sentiment\")\n    plt.ylabel(\"Price change\")\n    plt.title(\"Residual Plot - Tweet Sentiment vs Tesla Price Change Percent using Random Forest\")\n    plt.show()\n    # Plot actual vs predicted stock price change from the model\n    plt.figure(figsize=(15,4))\n    plt.scatter(X, Y,  color='black')\n    plt.plot(y_test, y_predicted, color='blue', linewidth=3)\n    plt.xlabel(\"Sentiment\")\n    plt.ylabel(\"Stock Price Change Percent\")\n    plt.title(\"Scatter Plot - Tweet Sentiment vs Tesla Stock Price Change Percent using Random Forest\")\n    plt.show()\n    return r2_score_1, r2_score_2","63c4ab0c":"cleaned_tweets_with_sentiment = clean_tweet_data(tweets_df)\nprint(\" Cleaned tweets count = \", cleaned_tweets_with_sentiment.Sentiment.count())\n\ntesla_stock_with_daily_change = clean_stock_data(tesla_stock_price_df)\nprint(\"\\n Stock price change data count = \", tesla_stock_with_daily_change.daily_percentage_change.count())\n\nsentiment_stock_change_df = merge_tweets_and_stock_data(cleaned_tweets_with_sentiment, tesla_stock_with_daily_change)\n\npositive_sentiment_stock_change_data = sentiment_stock_change_df.loc[sentiment_stock_change_df['Sentiment'] == 'positive']\nnegative_sentiment_stock_change_data = sentiment_stock_change_df.loc[sentiment_stock_change_df['Sentiment'] == 'negative']\nneutral_sentiment_stock_change_data = sentiment_stock_change_df.loc[sentiment_stock_change_df['Sentiment'] == 'neutral']\n\nprint(\"\\n Total number of days with sentiment value in tweets\", sentiment_stock_change_df.Time.count())\nprint(\"\\n No of days with positive tweet sentiment\", positive_sentiment_stock_change_data.Time.count())\nprint(\"\\n No of days with negative tweet sentiment\", negative_sentiment_stock_change_data.Time.count())\nprint(\"\\n No of days with neutral tweet sentiment\", neutral_sentiment_stock_change_data.Time.count())","65933ad4":"# Calculating the mean and standard deviation of the stock price change percentage per sentiment of tweets.\ngrouped_sentiment_stock_change = sentiment_stock_change_df.groupby(['Sentiment'], as_index=False)\nmean_stock_price_change = grouped_sentiment_stock_change.mean()\nstddev_stock_price_change = grouped_sentiment_stock_change['daily_percentage_change'].apply(lambda x: x.std())\n\nprint(\"\\nMean of stock price change percent per sentiment\")\nprint(mean_stock_price_change)\n\nprint(\"\\nStddev stock price change percent per sentiment\")\nprint(stddev_stock_price_change)","761b57ec":"plt.figure(figsize=(10, 10))\nsns.violinplot(x=sentiment_stock_change_df.Sentiment, y=sentiment_stock_change_df.daily_percentage_change, data=sentiment_stock_change_df, height=8)\n\n# Ploting cholestrol data based on heart disease(ANYCHD).\nplt.figure(figsize=(10, 8))\nsns.boxplot(data=sentiment_stock_change_df, x=sentiment_stock_change_df.Sentiment, y=sentiment_stock_change_df.daily_percentage_change)","26de5bb3":"plt.figure(figsize=(20, 8))\nsns.scatterplot(x=sentiment_stock_change_df['Time'], y=sentiment_stock_change_df['daily_percentage_change'], \n                data=sentiment_stock_change_df,hue=sentiment_stock_change_df['Sentiment']);\n\nsentiment_stock_change_df[['Time', 'daily_percentage_change']].set_index('Time').plot()","30065433":"sentiment_stock_change_updated = make_sentiment_column_categorical(sentiment_stock_change_df)\nsentiment = sentiment_stock_change_updated.Sentiment.values.reshape(-1, 1)\nprice_change = sentiment_stock_change_updated.daily_percentage_change.values.reshape(-1, 1)\n\nr2_score_1, r2_score_2 = do_linear_regression(sentiment, price_change)\nprint('R2 (Variance) score using linear_regression model = ', r2_score_1)\nprint('R2 (Variance) score using sklearn metrics with linear_regression = ', r2_score_2)\n\nr2_score_1, r2_score_2 = do_random_forest_analysis(sentiment, price_change)\nprint('R2 (Variance) score using random forest model = ', r2_score_1)\nprint('R2 (Variance) score using sklearn metrics with random forest = ', r2_score_2)","28213829":"### Big Data Class Project \n### Analyze the effect Elon Musk's tweets on Tesla stock price.\n    - Using data set available from kaggle\n        - Elon Musk tweets from 2012 to 2017 https:\/\/www.kaggle.com\/kulgen\/elon-musks-tweets\n            - This contains all tweets made by @elonmusk, his official Twitter handle, between 11\/16\/2012 and 09\/29\/2017.\n        - Tesla stock price data https:\/\/www.kaggle.com\/rpaguirre\/tesla-stock-price\n            - 06\/29\/2010 to 03\/17\/2017.\n\n    - Special Library Used : TextBlob\n        - pip install -U textblob\n        - https:\/\/textblob.readthedocs.io\/en\/dev\/install.html\n#### Approach taken to correlate the two data sets.\n    - Tweet\n        - Clean tweet data and stock data.\n        - Make sure both the data belong to a given date range. (May be not required)\n        - Remove unwanted columns from the column.\n            - Tweet -> remove 'user', 'row ID' -> not required.\n        - Analyze tweets using TextBlob library.\n        - Based on this analyses, categorize tweet as 'positive', 'negative' or neutral\n        - Since there are multiple tweets in a day, get the maximum sentiment of the day and assign this to the day.\n\n    - Stock data\n        - Calculate the day's percent change. [(close_price-open_price)\/(close_price)]*100\n        - Merge Tweet and Stock data on 'Time' field.\n            - Use inner merge, i.e consider only matching dates.\n\n### Analysis:\n    - Run machine learning on the merged\/prepaired and calculate correlation between tweet sentiment and stock price change sentiment.\n    - Used linear regression and random forest to develop the model.\n\n### Conclusion:\n    - As per the data, the model was not able to predict any correlation between Elon Musk's tweets and Tesla stock price changes."}}