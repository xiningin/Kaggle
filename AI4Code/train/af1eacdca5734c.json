{"cell_type":{"ed5edc70":"code","bdcaeac8":"code","28885e19":"code","7ffeecde":"code","6b8fb6cd":"code","2ef1ffe7":"code","1e829f68":"code","5dbc30e2":"code","32509b64":"code","99f50bcd":"code","2b9f07a2":"code","1274f218":"code","4fe83fa9":"code","9991c076":"code","7a0d6564":"code","0403b652":"code","4821c4df":"code","639d5b74":"code","866b37ad":"code","debd25e3":"code","503b7c7a":"code","0c075621":"markdown","12a9ef86":"markdown","93306274":"markdown","9f42d9ae":"markdown","b3f2ff1e":"markdown","5ce555a4":"markdown","ff646c50":"markdown","c9c43de3":"markdown","0d183ef7":"markdown","61f5981e":"markdown","00e2af58":"markdown","5df69427":"markdown","500a84ae":"markdown","fb331194":"markdown","31558916":"markdown","adfafce4":"markdown","537129f0":"markdown","2e0def7b":"markdown","1ec043fc":"markdown"},"source":{"ed5edc70":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport seaborn as sns","bdcaeac8":"training_data = pd.read_csv('..\/input\/train.csv')\ntesting_data = pd.read_csv('..\/input\/test.csv')","28885e19":"training_data.head()","7ffeecde":"testing_data.head()","6b8fb6cd":"label = training_data.label.value_counts()\nlabel","2ef1ffe7":"sns.countplot(training_data['label'])\nplt.title(\"Distribution of feature\")\nplt.ylabel(\"Number of Occurences\")\nplt.xlabel(\"Labels\")","1e829f68":"train_data = training_data.drop(['label'], axis=1).values.astype('float32') # all pixel values\ntarget = training_data['label'].values.astype('int32') # only labels i.e targets digits\ntest_data = testing_data.values.astype('float32')\ntrain_data = train_data.reshape(train_data.shape[0], 28, 28) \/ 255.0\ntest_data = test_data.reshape(test_data.shape[0], 28, 28) \/ 255.0","5dbc30e2":"import keras\nnum = 10\ntarget = keras.utils.to_categorical(target,num)","32509b64":"plt.figure(figsize=(10,10))\nfor i in range(50):  \n    plt.subplot(5, 10, i+1)\n    plt.imshow(train_data[i].reshape((28,28)),interpolation='nearest')\nplt.show()","99f50bcd":"import tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nnum_classes = 10\ninput_shape = (28, 28, 1)","2b9f07a2":"X_train, X_val, Y_train, Y_val = train_test_split(train_data, target , test_size = 0.1, random_state=42)","1274f218":"X_train = X_train.reshape(X_train.shape[0], 28, 28,1)  \nX_val = X_val.reshape(X_val.shape[0], 28, 28,1)  \ntest_data = test_data.reshape(test_data.shape[0], 28, 28,1)","4fe83fa9":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally \n        height_shift_range=0.1,  # randomly shift images vertically \n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)  # fitting X_train model ","9991c076":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',   # quality to be monitored \n                                            patience=3,          # no of epoch with no improvement after learning rate will be reduced\n                                            verbose=1,           # update message\n                                            factor=0.5,          # reducing learning rate \n                                            min_lr=0.0001)       # lower bound learning rate ","7a0d6564":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\n","0403b652":"model.compile(loss='categorical_crossentropy',\n              optimizer='Adam',\n              metrics=['accuracy'])","4821c4df":"fitting = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = 90),\n                              epochs = 50, validation_data = (X_val, Y_val),\n                              verbose = 1, callbacks = [learning_rate_reduction])","639d5b74":"print(model.summary())","866b37ad":"predicted_classes = model.predict_classes(test_data)","debd25e3":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predicted_classes)+1)),\n                         \"Label\": predicted_classes})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","503b7c7a":"submissions.head()","0c075621":"Reshaping train, test set for making ready to go through modelling purpose","12a9ef86":"Creating csv final submission file from above prediction against image id's ","93306274":"Previewing first fifty images ","9f42d9ae":"Splitting training set and test set via<br>\n**train_test_split** function ","b3f2ff1e":"Transforming Train_data and Test_data into images\\labels.","5ce555a4":"Converting label into categorical form (One Hot Encoding) <br>\nCreated 10 different feature columns as label were 10 ","ff646c50":"Getting the predictions for our test data that has no labels or target values ","c9c43de3":"Importing important python libraries for data maniputaltion, data analysis and for <br>\nperforming mathematical operations .","0d183ef7":"Solved Digit Recognizer problem in easy and intuitive way so to also understand a begineer .<br>\nConvolutional Neural Network (CNN) is deep learning's artificial neural network used for <br>\nimagery research and other object recognition . <br>","61f5981e":"Here summary of the model can be interpreted with each layer separetly containing <br>\nnumber of parameters it had used along with its output shape","00e2af58":"Information of **ReduceLROnPlateau** can be obtained from [here](https:\/\/keras.io\/callbacks\/)","5df69427":"Compiling the model and placing the parameters that are to be displayed when model is runned \/ fitted .\nLoss function has given paramter as **categorical_crossentropy** because we have categorical and more <br>\nthan 2 attributes in output .\nOptimizer is a function that minimizes the loss function of a model to gain higher accuracy peek . ","500a84ae":"Importing all the necessary keras library <br>\nIf not works add 'python' after tensorflow <br>\ne.g from tensorflow.python.keras.models import Sequential<br>","fb331194":"Loading training and testing dataset with pd.read_csv function from pandas","31558916":"Values occuring of target feature -> label","adfafce4":"Everything about the cnn layers that are [Convolutional](https:\/\/keras.io\/layers\/convolutional\/), [MaxPooling](https:\/\/keras.io\/layers\/pooling\/), [Activation](https:\/\/keras.io\/activations\/), [BatchNormalization](https:\/\/keras.io\/layers\/normalization\/) can be found here ","537129f0":"Information of **ImageDataGenerator** can be obtained from [here](https:\/\/keras.io\/preprocessing\/image\/#imagedatagenerator-class)","2e0def7b":"**Dropout** function used to avoid overfiting of model by terminating \/ disabling random node while building<br>\nso neurons doesnot become dependent on any neuron or to avoid correlations while learning<br>\n**Flatten** used to make all the previous output into one single column to obtain the interpreted result ","1ec043fc":"fitting model through all the above parameters and the functions"}}