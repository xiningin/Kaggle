{"cell_type":{"8f2bacc9":"code","e8eea8c3":"code","d855c08f":"code","4aa2860e":"code","dca9397b":"code","592f5069":"code","03a776bc":"code","a6432df7":"code","9b371653":"code","14e43aaf":"code","746f401c":"code","1c1a9349":"code","5364f227":"code","1cb4ff87":"code","5e04cd0c":"code","e60e3fb6":"code","139effed":"code","8bd3954c":"code","c32ca870":"code","db56cd27":"code","cac1e288":"markdown"},"source":{"8f2bacc9":"# necessary libaries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ndf.head()","e8eea8c3":"df.columns","d855c08f":"# select numerical cols\nselected_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea', 'SalePrice']\ndf = df[selected_cols]\ndf","4aa2860e":"df.describe()","dca9397b":"df.isna().sum()","592f5069":"# select only 2 attributes and 1 target\n# for 3d plot\n\ndrop_cols = ['LotFrontage', 'GarageArea', 'PoolArea', 'MasVnrArea']\ndf = df.drop(columns = drop_cols, axis = 1)\ndf.head()","03a776bc":"sns.heatmap(df.corr())","a6432df7":"sns.pairplot(data = df, height=1.5)","9b371653":"# data preparation\n\nX = df.iloc[:,0:-1].values\ny = df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\n \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=1)","14e43aaf":"# multiple linear regression model\n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\n\n# fit lr model\nlr.fit(X_train, y_train)\n\n# predict\ny_pred_lr = lr.predict(X_test).round(0)","746f401c":"# polynomial linear regression model\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# set up polynomial degree\npoly = PolynomialFeatures(degree = 2) \n\n# transform X into poly before fitting\nX_poly_train = poly.fit_transform(X_train)\n\n# fit ploy lr model with train set\nlr_poly = LinearRegression()\nlr_poly.fit(X_poly_train, y_train)\n\n# predict\nX_poly_test = poly.fit_transform(X_test)\ny_pred_poly = lr_poly.predict(X_poly_test).round(0)","1c1a9349":"# pred and target\ndf2 = pd.DataFrame()\ndf2['y_pred_lr'] = y_pred_lr\ndf2['y_pred_poly'] = y_pred_poly\ndf2['y_test'] = y_test","5364f227":"fig, ax = plt.subplots()\n\nfrom matplotlib.ticker import StrMethodFormatter, NullFormatter\nax.yaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))\nax.yaxis.set_minor_formatter(NullFormatter())\n\nplt.scatter(x = y_test, y = y_pred_lr, c = 'b', alpha = 0.5, s = 4)\nplt.scatter(x = y_test, y = y_pred_poly, c = 'r', alpha = 0.5, s = 4)\n\nax.set_xlabel('acutual price')\nax.set_ylabel('predicted price')\n\nplt.show()","1cb4ff87":"# Return the coefficient (R^2) of determination  of the prediction.\nprint('entire data score')\n\nlr = LinearRegression()\nlr.fit(X, y)\nprint(f'linear model: {lr.score(X,y)}')\n\nX_poly = poly.fit_transform(X)\nlr_poly = LinearRegression()\nlr_poly.fit(X_poly, y)\nprint(f'poly model: {lr_poly.score(X_poly,y)}')\n\nprint('training score')\nprint(f'linear model: {lr.score(X_train,y_train)}')\nprint(f'poly model: {lr_poly.score(X_poly_train,y_train)}')\nprint('testing score')\nprint(f'linear model: {lr.score(X_test,y_test)}')\nprint(f'poly model: {lr_poly.score(X_poly_test,y_test)}')","5e04cd0c":"print(X[:,0].max())\nprint(X[:,1].max())\nprint(y.max())","e60e3fb6":"# 3d plot gif\n\n# for ii in np.arange(0, 180, 1):\n#    ax1.view_init(elev=32, azim=ii*2)\n#    fig.savefig('poly%d.png' % ii)","139effed":"# 3d plot\n# https:\/\/aegis4048.github.io\/mutiple_linear_regression_and_visualization_in_python\nfrom mpl_toolkits.mplot3d import Axes3D\n\n######################################## Data preparation #########################################\n\nX = df[['LotArea', 'GrLivArea']].values.reshape(-1,2)\nY = df['SalePrice']\n\n######################## Prepare model data point for visualization ###############################\n\nx = X[:, 0]\ny = X[:, 1]\nz = Y\n\nx_pred = np.linspace(0, 215245, 20)\ny_pred = np.linspace(0, 5642, 20)\nxx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\nmodel_viz = np.array([xx_pred.flatten(), yy_pred.flatten()]).T","8bd3954c":"################################################ Train #############################################\n\nlr = LinearRegression()\nlr.fit(X, Y)\npredicted = lr.predict(model_viz)\n\n############################################## Evaluate ############################################\n\nr2 = lr.score(X, Y)\n\n############################################## Plot ################################################\n\nplt.style.use('default')\n\nfig = plt.figure(figsize=(12, 4))\n\nax1 = fig.add_subplot(131, projection='3d')\nax2 = fig.add_subplot(132, projection='3d')\nax3 = fig.add_subplot(133, projection='3d')\n\naxes = [ax1, ax2, ax3]\n\nfor ax in axes:\n    ax.plot(x, y, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.5)\n    ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n    ax.set_xlabel('LotArea', fontsize=12)\n    ax.set_ylabel('GrLivArea', fontsize=12)\n    ax.set_zlabel('SalePrice', fontsize=12)\n    ax.locator_params(nbins=4, axis='x')\n    ax.locator_params(nbins=5, axis='x')\n\nax1.view_init(elev=28, azim=120)\nax2.view_init(elev=4, azim=114)\nax3.view_init(elev=60, azim=165)\n\nfig.suptitle('Multiple linear regression, Entire dataset score: $R^2 = %.3f$' % r2, fontsize=20)\n\nfig.tight_layout()","c32ca870":"################################################ Train #############################################\n\npoly = PolynomialFeatures(degree = 2) \nX_poly = poly.fit_transform(X)\nlr_poly = LinearRegression()\nlr_poly.fit(X_poly, Y)\n\npredicted = lr_poly.predict(poly.fit_transform(model_viz))\n\n############################################## Evaluate ############################################\n\nr2 = lr_poly.score(poly.fit_transform(X), Y)\n\n############################################## Plot ################################################\n\nplt.style.use('default')\n\nfig = plt.figure(figsize=(12, 4))\n\nax1 = fig.add_subplot(131, projection='3d')\nax2 = fig.add_subplot(132, projection='3d')\nax3 = fig.add_subplot(133, projection='3d')\n\naxes = [ax1, ax2, ax3]\n\nfor ax in axes:\n    ax.plot(x, y, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.5)\n    ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n    ax.set_xlabel('LotArea', fontsize=12)\n    ax.set_ylabel('GrLivArea', fontsize=12)\n    ax.set_zlabel('SalePrice', fontsize=12)\n    ax.locator_params(nbins=4, axis='x')\n    ax.locator_params(nbins=5, axis='x')\n\nax1.view_init(elev=28, azim=120)\nax2.view_init(elev=4, azim=114)\nax3.view_init(elev=60, azim=165)\n\nfig.suptitle('Polynomial regression, 2nd degree, Entire dataset score: $R^2 = %.3f$' % r2, fontsize=20)\n\nfig.tight_layout()","db56cd27":"################################################ Train #############################################\nfor n_poly in [2,4,6,12,30,50]:\n    poly = PolynomialFeatures(degree = n_poly) \n    X_poly = poly.fit_transform(X)\n    lr_poly = LinearRegression()\n    lr_poly.fit(X_poly, Y)\n\n    predicted = lr_poly.predict(poly.fit_transform(model_viz))\n\n    ############################################## Evaluate ############################################\n\n    r2 = lr_poly.score(poly.fit_transform(X), Y)\n\n    ############################################## Plot ################################################\n\n    plt.style.use('default')\n\n    fig = plt.figure(figsize=(12, 4))\n\n    ax1 = fig.add_subplot(131, projection='3d')\n    ax2 = fig.add_subplot(132, projection='3d')\n    ax3 = fig.add_subplot(133, projection='3d')\n\n    axes = [ax1, ax2, ax3]\n\n    for ax in axes:\n        ax.plot(x, y, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.5)\n        ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n        ax.set_xlabel('LotArea', fontsize=12)\n        ax.set_ylabel('GrLivArea', fontsize=12)\n        ax.set_zlabel('SalePrice', fontsize=12)\n        ax.locator_params(nbins=4, axis='x')\n        ax.locator_params(nbins=5, axis='x')\n\n    ax1.view_init(elev=28, azim=120)\n    ax2.view_init(elev=4, azim=114)\n    ax3.view_init(elev=60, azim=165)\n\n    fig.suptitle('Polynomial regression, %s degree, Entire dataset score: $R^2 = %.3f$' % (n_poly, r2), fontsize=20)\n\n    fig.tight_layout()\n    fig.show()","cac1e288":"![](https:\/\/media0.giphy.com\/media\/0uYLL4dtgr3uY8sAxv\/giphy.gif)\n![](https:\/\/media0.giphy.com\/media\/KVrxhHKyxHZnWkmGlH\/giphy.gif)\n"}}