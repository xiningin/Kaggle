{"cell_type":{"2861b8cf":"code","0ea0fd05":"code","8267dc05":"code","23a47601":"code","b01e4824":"code","b603b411":"code","6ddf3ef2":"code","5e65cb18":"code","c18034a5":"code","54342046":"code","a71dc9ff":"code","ba8275ec":"code","3b1d1d3a":"code","d824c18d":"code","e2655f9f":"code","27428948":"code","d29bf81d":"code","cbd2f685":"code","d8abcf3d":"code","22eca141":"code","a8903129":"code","1e35f50a":"code","c87db0b5":"code","c179c365":"code","2e619540":"code","6a01326d":"code","9cef4369":"code","ace94355":"code","88bf582b":"code","ac76e7df":"code","50e85d5c":"code","339c471c":"code","a2fa0111":"code","27d8732c":"code","49d2517a":"code","1a4ce29c":"code","ef4202e5":"code","a9a449c0":"code","b08ac197":"code","1e6cabdf":"code","83e9ef3f":"code","b4fff472":"code","2b37fa0f":"code","9b266872":"code","1b23f763":"code","57e514c4":"code","5e13917f":"code","538553f9":"code","5780255b":"code","71cc1142":"code","0987ab13":"code","9e928cf5":"code","6ca8a697":"code","2d8496a1":"code","d6bb90ad":"code","237bed51":"code","2b9ef36f":"code","a0eb3e2b":"code","fa2ba5eb":"code","d2c120f5":"code","639139d5":"code","945472e9":"code","bde89ccb":"code","6062a3bf":"code","d0cdf7f9":"code","f89c831b":"code","4bd896e1":"code","903ef750":"code","16ec0285":"markdown","2427c5d6":"markdown","4e116057":"markdown","7095aa91":"markdown","f5ff8c87":"markdown","0b98cc26":"markdown","efd8d666":"markdown","11f0b6bb":"markdown","ca3e5463":"markdown","5dbd436b":"markdown","480767ac":"markdown","8067fba1":"markdown","be51cc18":"markdown","2227d6ef":"markdown","ad731a54":"markdown","334a2d2a":"markdown","933f549d":"markdown","822cd794":"markdown","9b0a7bfc":"markdown","d65cc709":"markdown","7700461e":"markdown","2089fc6d":"markdown","8a3d38d3":"markdown","02681cf1":"markdown","836481a8":"markdown","78e09437":"markdown","6d668c01":"markdown","18b9f094":"markdown","a1a0612b":"markdown","2b58a527":"markdown","2fd19064":"markdown","155d3788":"markdown","b7b19636":"markdown","a8e9d340":"markdown","fe6ed2e3":"markdown","db0c4a03":"markdown","84ed1821":"markdown","0bb95fc5":"markdown","1fa9b738":"markdown","964c0f61":"markdown","f0499a91":"markdown","3f867b98":"markdown","68c53156":"markdown","4e297bcd":"markdown","7653b1dc":"markdown","e5eca262":"markdown"},"source":{"2861b8cf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\ninit_notebook_mode(connected=True)\nfrom plotly import tools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","0ea0fd05":"df = pd.read_csv(\"..\/input\/H-1B_Disclosure_Data_FY17.csv\")","8267dc05":"df.head()","23a47601":"df.VISA_CLASS.value_counts()","b01e4824":"df.EMPLOYER_COUNTRY.value_counts()","b603b411":"df = df[df.VISA_CLASS == 'H-1B']\ndf= df[df.EMPLOYER_COUNTRY == 'UNITED STATES OF AMERICA']","6ddf3ef2":"df.apply(lambda x:len(x.unique()))","5e65cb18":"df.isnull().sum()[df.isnull().sum() > 0]","c18034a5":"to_select = ['CASE_STATUS', 'EMPLOYMENT_START_DATE','EMPLOYER_NAME', 'EMPLOYER_STATE','JOB_TITLE', 'SOC_NAME','FULL_TIME_POSITION',\n            'PREVAILING_WAGE','PW_UNIT_OF_PAY','WORKSITE_STATE']","54342046":"df = df[to_select]","a71dc9ff":"df.isnull().sum()[df.isnull().sum() > 0]","ba8275ec":"df = df[df['EMPLOYMENT_START_DATE'].notnull()]\ndf = df[df['JOB_TITLE'].notnull()]\ndf = df[df['SOC_NAME'].notnull()]\ndf = df[df['FULL_TIME_POSITION'].notnull()]\ndf = df[df['PW_UNIT_OF_PAY'].notnull()]\ndf = df[df['WORKSITE_STATE'].notnull()]\ndf = df[df['EMPLOYER_NAME'].notnull()]","3b1d1d3a":"df.isnull().sum()[df.isnull().sum() > 0]","d824c18d":"df.head()","e2655f9f":"df['EMPLOYMENT_START_DATE'] = pd.to_datetime(df['EMPLOYMENT_START_DATE'])","27428948":"df.groupby(['FULL_TIME_POSITION','PW_UNIT_OF_PAY']).describe()['PREVAILING_WAGE']","d29bf81d":"for i in df.index:   \n        if df.loc[i,'PW_UNIT_OF_PAY'] == 'Month':\n            df.loc[i,'PREVAILING_WAGE'] = df.loc[i,'PREVAILING_WAGE'] * 12\n        if df.loc[i,'PW_UNIT_OF_PAY'] == 'Week':\n            df.loc[i,'PREVAILING_WAGE'] = df.loc[i,'PREVAILING_WAGE'] * 48\n        if df.loc[i,'PW_UNIT_OF_PAY'] == 'Bi-Weekly':\n            df.loc[i,'PREVAILING_WAGE'] = df.loc[i,'PREVAILING_WAGE'] * 24","cbd2f685":"df.PW_UNIT_OF_PAY.replace(['Bi-Weekly','Month','Week'],['Year','Year','Year'], inplace=True)","d8abcf3d":"df.groupby(['FULL_TIME_POSITION','PW_UNIT_OF_PAY']).describe()['PREVAILING_WAGE']","22eca141":"df['countvar'] = 1","a8903129":"dftop = df.groupby('EMPLOYER_NAME',as_index=False).count()\ndftop = dftop.sort_values('countvar',ascending= False)[['EMPLOYER_NAME','countvar']][0:30]","1e35f50a":"t1 = go.Bar(x=dftop.EMPLOYER_NAME.values,y=dftop.countvar.values,name='top30')\nlayout = go.Layout(dict(title= \"TOP EMPLOYERS SPONSORING\",yaxis=dict(title=\"Num of applications\")))\ndata = [t1]\nfig =go.Figure(data,layout)\niplot(fig)","c87db0b5":"dftop1 = df.groupby(['EMPLOYER_NAME','CASE_STATUS'],as_index=False).count()\ndftop1=dftop1[dftop1.EMPLOYER_NAME.isin(dftop.EMPLOYER_NAME)]","c179c365":"t1 = go.Bar(x=dftop1[dftop1.CASE_STATUS == 'CERTIFIED'].sort_values('countvar',ascending= False)['EMPLOYER_NAME'].values,y=dftop1[dftop1.CASE_STATUS == 'CERTIFIED'].sort_values('countvar',ascending= False)['countvar'].values,name='CERTIFIED')\nt2 = go.Bar(x=dftop1[dftop1.CASE_STATUS == 'CERTIFIED-WITHDRAWN'].sort_values('countvar',ascending= False)['EMPLOYER_NAME'].values,y=dftop1[dftop1.CASE_STATUS == 'CERTIFIED-WITHDRAWN'].sort_values('countvar',ascending= False)['countvar'].values,name='CERTIFIED-WITHDRAWN')\nt3 = go.Bar(x=dftop1[dftop1.CASE_STATUS == 'DENIED'].sort_values('countvar',ascending= False)['EMPLOYER_NAME'].values,y=dftop1[dftop1.CASE_STATUS == 'DENIED'].sort_values('countvar',ascending= False)['countvar'].values,name='DENIED')\nt4 = go.Bar(x=dftop1[dftop1.CASE_STATUS == 'WITHDRAWN'].sort_values('countvar',ascending= False)['EMPLOYER_NAME'].values,y=dftop1[dftop1.CASE_STATUS == 'WITHDRAWN'].sort_values('countvar',ascending= False)['countvar'].values,name='WITHDRAWN')\n\ndata = [t1,t2,t3,t4]\nlayout = go.Layout(\n    barmode='stack'\n)\n\nfig =go.Figure(data,layout)\niplot(fig)","2e619540":"dfempst = df.groupby('EMPLOYER_STATE',as_index=False).count()[['EMPLOYER_STATE','countvar']].sort_values('countvar',ascending=False)","6a01326d":"t1 = go.Bar(x=dfempst.EMPLOYER_STATE.values,y=dfempst.countvar.values,name='Employerstate')\nlayout = go.Layout(dict(title= \"NUMBER OF APPLICATIONS PER STATE\",xaxis=dict(title=\"STATES\"),yaxis=dict(title=\"Num of applications\")))\ndata = [t1]\nfig =go.Figure(data,layout)\niplot(fig)","9cef4369":"data=[dict(\n    type='choropleth',\n    locations = dfempst.EMPLOYER_STATE,\n    z = dfempst.countvar,\n    locationmode = 'USA-states',marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Number of applications\")\n)]\nlayout= dict(title=\"2011-2018 H1B VISA APPLICATIONS ( EMPLOYER STATE)\",geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\nfig = dict( data=data, layout=layout )\niplot(fig)","ace94355":"dfjob = df.groupby('JOB_TITLE',as_index=False).count()[['JOB_TITLE','countvar']].sort_values('countvar',ascending=False)[0:20]","88bf582b":"t1 = go.Bar(x=dfjob.JOB_TITLE.values,y=dfjob.countvar.values,name='jobtitle')\nlayout = go.Layout(dict(title= \"TOP 20 JOBS\",yaxis=dict(title=\"Num of applications\")))\ndata = [t1]\nfig =go.Figure(data,layout)\niplot(fig)","ac76e7df":"df['year'] = df.EMPLOYMENT_START_DATE.apply(lambda x: x.year)","50e85d5c":"dfyear = df.groupby('year',as_index=False).count()[['year','countvar']]","339c471c":"t1 = go.Scatter(\n    x=dfyear.year,\n    y=dfyear.countvar\n)\nlayout = go.Layout(dict(title= \" NUMBER OF APPLICATIONS PER YEAR\",xaxis=dict(title=\"YEARS\"),yaxis=dict(title=\"Num of applications\")))\ndata = [t1]\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","a2fa0111":"t1 = go.Bar(x=df.groupby('CASE_STATUS').count().index,y=df.groupby('CASE_STATUS').count()['countvar'],name='CASESTATUSWISE')\ndata = [t1]\niplot(data)","27d8732c":"t1 = go.Bar(x=df[df.FULL_TIME_POSITION == 'Y'].groupby('CASE_STATUS').count().index,y=df[df.FULL_TIME_POSITION == 'Y'].groupby('CASE_STATUS').count()['countvar'],name='FULL-TIME ')\nt2 = go.Bar(x=df[df.FULL_TIME_POSITION == 'N'].groupby('CASE_STATUS').count().index,y=df[df.FULL_TIME_POSITION == 'N'].groupby('CASE_STATUS').count()['countvar'],name='PART-TIME ')\ndata = [t1,t2]\nlayout = go.Layout(barmode='stack')\nfig = go.Figure(data =data,layout =layout)\niplot(fig)","49d2517a":"df.PREVAILING_WAGE.describe()","1a4ce29c":"df.PW_UNIT_OF_PAY.value_counts()","ef4202e5":"dum = df[(df.FULL_TIME_POSITION == 'Y') & (df.PW_UNIT_OF_PAY == 'Year')]\nind1 = dum[(dum.PREVAILING_WAGE > 270000) | (dum.PREVAILING_WAGE < 40000)].index\ndf = df.drop(ind1,axis=0)","a9a449c0":"dum = df[(df.FULL_TIME_POSITION == 'N') & (df.PW_UNIT_OF_PAY == 'Year')]\nind1 = dum[(dum.PREVAILING_WAGE > 150000) | (dum.PREVAILING_WAGE < 32000)].index\ndf = df.drop(ind1,axis=0)","b08ac197":"dum = df[(df.PW_UNIT_OF_PAY == 'Hour')]\nind1 = dum[(dum.PREVAILING_WAGE > 110) | (dum.PREVAILING_WAGE < 15)].index\ndf = df.drop(ind1,axis=0)","1e6cabdf":"k = df[(df.PW_UNIT_OF_PAY == 'Hour') & (df.FULL_TIME_POSITION == 'Y')].index\ndf.loc[k,'PREVAILING_WAGE'] = df.loc[k,'PREVAILING_WAGE'] * 1920","83e9ef3f":"k = df[(df.PW_UNIT_OF_PAY == 'Hour') & (df.FULL_TIME_POSITION == 'N')].index\ndf.loc[k,'PREVAILING_WAGE'] = df.loc[k,'PREVAILING_WAGE'] * 1440","b4fff472":"df=df.drop(['PW_UNIT_OF_PAY'],axis=1)","2b37fa0f":"t1 = go.Scatter(\n    x=df.groupby('year').mean().index,\n    y=df.groupby('year').mean().PREVAILING_WAGE\n)\n\nlayout = go.Layout(dict(title= \" AVERAGE ANNUAL PAY vs YEAR\",xaxis=dict(title=\"YEARS\"),yaxis=dict(title=\"AVERAGE ANNUAL PAY\")))\ndata = [t1]\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","9b266872":"dum = df[[\"EMPLOYER_STATE\",\"JOB_TITLE\"]]\ndum = dum.groupby([\"EMPLOYER_STATE\",\"JOB_TITLE\"]).size().reset_index()\ndum.columns = ['EMPLOYER_STATE', 'JOB_TITLE', \"COUNT\"]\ndum = dum.groupby(['EMPLOYER_STATE', 'JOB_TITLE']).agg({'COUNT':sum})\ndum = dum['COUNT'].groupby(level=0, group_keys=False)\ndum = dum.apply(lambda x: x.sort_values(ascending=False).head(1))\ndum = pd.DataFrame(dum).reset_index()","1b23f763":"data=[dict(\n    type='choropleth',\n    locations = dum.EMPLOYER_STATE,\n    z = dum.COUNT,\n    locationmode = 'USA-states',\n    text = dum.JOB_TITLE,\n    marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Number of application\")\n)]\nlayout= dict(title=\"Top job title in the state\",geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\nfig = dict( data=data, layout=layout )\niplot(fig)","57e514c4":"dum = df.groupby('EMPLOYER_STATE',as_index=False).mean()[['EMPLOYER_STATE','PREVAILING_WAGE']]","5e13917f":"data=[dict(\n    type='choropleth',\n    locations = dum.EMPLOYER_STATE,\n    z = dum.PREVAILING_WAGE,\n    locationmode = 'USA-states',\n    marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Avg salary in USD\")\n)]\nlayout= dict(title=\"Average salaries per state\",geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\nfig = dict( data=data, layout=layout )\niplot(fig)","538553f9":"df['OCCUPATION'] = np.nan\ndf['SOC_NAME'] = df['SOC_NAME'].str.lower()\ndf.OCCUPATION[df['SOC_NAME'].str.contains('computer','programmer')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('data scientist','data analyst')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('data engineer','data base')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('machine learning','artifical intelligence')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('spark','apache')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('hadoop','big data')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('sql','cyber')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('developer','full stack')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('fullstack','etl')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('data','network')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('software tester','cloud')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('information','informatica')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('jira','programmer')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('software','web developer')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('database')] = 'Computer Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('math','statistic')] = 'Mathematical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('predictive model','stats')] = 'Mathematical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('teacher','linguist')] = 'Education Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('professor','Teach')] = 'Education Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('school principal')] = 'Education Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('medical','doctor')] = 'Medical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('physician','dentist')] = 'Medical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('Health','Physical Therapists')] = 'Medical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('surgeon','nurse')] = 'Medical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('psychiatr')] = 'Medical Occupations'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('chemist','physicist')] = 'Advance Sciences'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('biology','scientist')] = 'Advance Sciences'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('biologi','clinical research')] = 'Advance Sciences'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('public relation','manage')] = 'Management Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('management','operation')] = 'Management Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('chief','plan')] = 'Management Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('executive')] = 'Management Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('advertis','marketing')] = 'Marketing Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('promotion','market research')] = 'Marketing Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('business','business analyst')] = 'Business Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('business systems analyst')] = 'Business Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('accountant','finance')] = 'Financial Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('financial')] = 'Financial Occupation'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('engineer','architect')] = 'Architecture & Engineering'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('surveyor','carto')] = 'Architecture & Engineering'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('technician','drafter')] = 'Architecture & Engineering'\ndf.OCCUPATION[df['SOC_NAME'].str.contains('information security','information tech')] = 'Architecture & Engineering'\ndf['OCCUPATION']= df.OCCUPATION.replace(np.nan, 'Others', regex=True)\ndf['SOC_NAME'] = df['SOC_NAME'].str.upper()\n","5780255b":"df.head()","71cc1142":"df.OCCUPATION.value_counts()","0987ab13":"dum = df.groupby('OCCUPATION',as_index = False).mean()[['OCCUPATION','PREVAILING_WAGE']]\nt1 =go.Bar(x=dum.OCCUPATION,y=dum.PREVAILING_WAGE,name='wageperoccuaption')\nlayout = go.Layout(dict(title= \" AVERAGE ANNUAL PAY vs OCCUPATION\",yaxis=dict(title=\"AVERAGE ANNUAL PAY\")))\ndata = [t1]\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","9e928cf5":"dfcomp = df[df.OCCUPATION == 'Computer Occupations']","6ca8a697":"dum = dfcomp.groupby('EMPLOYER_STATE',as_index=False).mean()[['EMPLOYER_STATE','PREVAILING_WAGE']]","2d8496a1":"data=[dict(\n    type='choropleth',\n    locations = dum.EMPLOYER_STATE,\n    z = dum.PREVAILING_WAGE,\n    locationmode = 'USA-states',\n    marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Avg salary in USD\")\n)]\nlayout= dict(title=\"Average salaries of TECH(IT) per state\",geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\nfig = dict( data=data, layout=layout )\niplot(fig)","d6bb90ad":"dum = df.groupby('SOC_NAME',as_index=False).mean()[['SOC_NAME','PREVAILING_WAGE']]\ndum.sort_values('PREVAILING_WAGE',ascending= False).head(20)","237bed51":"dum = dfcomp.groupby('SOC_NAME',as_index=False).mean()[['SOC_NAME','PREVAILING_WAGE']]\ndum.sort_values('PREVAILING_WAGE',ascending= False).head(20)","2b9ef36f":"df['DS'] = np.nan\ndf.DS[df['JOB_TITLE'].str.contains('DATA SCIENTIST')] = 'DATA SCIENTIST'\ndf.DS[df['JOB_TITLE'].str.contains('DATA ANALYST')] = 'DATA ANALYST'\ndf.DS[df['JOB_TITLE'].str.contains('MACHINE LEARNING')] = 'MACHINE LEARNING'\ndf.DS[df['JOB_TITLE'].str.contains('BUSINESS ANALYST')] = 'BUSINESS ANALYST'\ndf.DS[df['JOB_TITLE'].str.contains('DEEP LEARNING')] = 'DEEP LEARNING'\ndf.DS[df['JOB_TITLE'].str.contains('ARTIFICIAL INTELLIGENCE')] = 'ARTIFICIAL INTELLIGENCE'\ndf.DS[df['JOB_TITLE'].str.contains('BIG DATA')] = 'BIG DATA'\ndf.DS[df['JOB_TITLE'].str.contains('HADOOP')] = 'HADOOP'\ndf.DS[df['JOB_TITLE'].str.contains('DATA ENGINEER')] = 'DATA ENGINEER'\ndf['DS']= df.DS.replace(np.nan, 'Others', regex=True)","a0eb3e2b":"df.DS.value_counts()","fa2ba5eb":"dum = df.groupby('DS',as_index=False).mean()[['DS','PREVAILING_WAGE']]","d2c120f5":"t1 =go.Bar(x=dum.DS,y=dum.PREVAILING_WAGE,name='DataScience')\ndata = [t1]\niplot(data)","639139d5":"dum = df.groupby(['year','DS']).count().reset_index()[['year','DS','countvar']]","945472e9":"data = []\nfor i in dum.DS.unique():\n    if i != 'Others':\n        data.append(go.Scatter(x = dum[dum.DS == i].year,y= dum[dum.DS == i].countvar,name=i))\n\nlayout = go.Layout(dict(title= \"GROWTH IN DATA SCIENCE\",xaxis=dict(title=\"YEARS\"),yaxis=dict(title=\"Number of applications\")))\n        \nfig = go.Figure(data,layout)    \niplot(fig)    \n","bde89ccb":"dum = df[[\"DS\",\"EMPLOYER_STATE\"]]\ndum = dum.groupby([\"DS\",\"EMPLOYER_STATE\"]).size().reset_index()\ndum.columns = [\"DS\",\"EMPLOYER_STATE\", \"COUNT\"]\ndum = dum.groupby([\"DS\",\"EMPLOYER_STATE\"]).agg({'COUNT':sum})\ndum = dum['COUNT'].groupby(level=0, group_keys=False)\ndum = dum.apply(lambda x: x.sort_values(ascending=False).head(1))\ndum = pd.DataFrame(dum).reset_index()\ndum[0:-1]","6062a3bf":"dum = df[[\"DS\",\"EMPLOYER_NAME\"]]\ndum = dum.groupby([\"DS\",\"EMPLOYER_NAME\"]).size().reset_index()\ndum.columns = [\"DS\",\"EMPLOYER_NAME\", \"COUNT\"]\ndum = dum.groupby([\"DS\",\"EMPLOYER_NAME\"]).agg({'COUNT':sum})\ndum = dum['COUNT'].groupby(level=0, group_keys=False)\ndum = dum.apply(lambda x: x.sort_values(ascending=False).head(1))\ndum = pd.DataFrame(dum).reset_index()\ndum[0:-1]","d0cdf7f9":"dfvadc = df[(df.EMPLOYER_STATE == 'VA') | (df.EMPLOYER_STATE == 'DC')]","f89c831b":"dfvadc = dfvadc[dfvadc.DS != 'Others']","4bd896e1":"dum = dfvadc[[\"DS\",\"EMPLOYER_NAME\"]]\ndum = dum.groupby([\"DS\",\"EMPLOYER_NAME\"]).size().reset_index()\ndum.columns = [\"DS\",\"EMPLOYER_NAME\", \"COUNT\"]\ndum = dum.groupby([\"DS\",\"EMPLOYER_NAME\"]).agg({'COUNT':sum})\ndum = dum['COUNT'].groupby(level=0, group_keys=False)\nnewdum = dum.apply(lambda x: x.sort_values(ascending=False).head(1))\nnewdum = pd.DataFrame(newdum).reset_index()\nnewdum[0:-1]","903ef750":"pd.DataFrame(dum.apply(lambda x: x.sort_values(ascending=False).head(15))).reset_index()['EMPLOYER_NAME']","16ec0285":"###### We got rid of null values","2427c5d6":"### Distribution of Case_Status column\/ Full_Time position","4e116057":"### Extracting the YEAR from the EMPLOYMENT_START_DATE.","7095aa91":"#### Replace the names bi-weekly, month and week by year.","f5ff8c87":"### My knowledge about H1B\n- The full time H1B employees have a minimum salary of 65k now, as we have data fromm 2011 I'm setting the minimum salary to be 40K.\n- There is no limit for maximum salary. But, any package above 200K is skeptical. But, considering the Doctors in mind. I will chose the cutoff for 270K.","0b98cc26":"#### The following cell shows us how the wage is varied.\n- You might notice some abornmal values like the max hourly pay as 2017,143166 etc etc.\n- These are called the outliers and our data has a lot of them","efd8d666":"## TOP 20 MOST PAID FIELDS.\n- Medical field domination ","11f0b6bb":"## We focus on H1-B visa and Employers from USA only","ca3e5463":"# Number of Applications per State.\n- Barplot and Choropleth graph","5dbd436b":"### DROP the useless columns.\n- By examining the above two columns we can remove all the useless columns.\n- Since we have a lot of those columns to drop, I instead selected the ones I need","480767ac":"- The partime employees might have a minimum salary of 30K-32K(in 2011) and maximum couldnt be more than 150K","8067fba1":"A COMPREHENSIVE ANALYSIS ON H1-B VISAS - Saiteja Nakka\n- To know about the data visit https:\/\/storage.googleapis.com\/kaggle-datasets\/11361\/15737\/h1b-2017-metadata.pdf?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1539822929&Signature=sd7i4%2BNuZyrh5E19BShsF8wGJB08CNYsf%2BvX4%2FAufvXe57w9dK7uVIV0uwqZI6ZKRNp56amXAAZsKciXmABlbuZ4rmRanmNjhM6JP3Iuv4UyIa7IvKJKnVaSq%2F8ppYYZMVveVivH3yVJn3eWfNhvhrBdShRC%2BcG4j8KuvCdpO70wzUX7bNvfA2McsSp5zMIbYA9mtu0Sqk6gtAuSmgfY9Q7e5U1wRSnKKEJzINXIVUtShZPZ3WBJyf8Yypxoj7QfXNzXMUXtUSMSTY45UYIvVtoRTs4jucgpMptXA5pvlGmIDShct5qgw%2Fn83%2Bv3Gm8J%2BgXNxMkv5AQw6kavgmYQmA%3D%3D","be51cc18":"#### Columns which have missing values in it","2227d6ef":"#### As, we now have all data in year pay scale. We go ahead and remove PW_UNIT_PAY","ad731a54":"### Average salary of H1B employee in each state.\n- As expected, california pays more","334a2d2a":"### Average salary of IT H1B employee in each state.\n- As expected, california pays more","933f549d":"### Converting the hourly pay to annual pay.\n- FULL_TIMERS: As they work 40hours a week and we have 48 weeks in a year, we multiply with 40*48\n- PART_TIMERS: As they work something around 25-35 hours a week, let me take the average of 30 hours a week,So we multiply with 30*48.","822cd794":"### To make our analysis easy lets first convert the Monthly, Weekly and Bi-weekly pay to Annual pay\n- The hourly pay conversion takes a lot of time. So, i have done in following stages after outliers were removed.\n- Montly pay is multiplied by 12. ( As we have 12 months in a year)\n- Weekly pay is multiplied by 48. ( Even though we have 52 weeks per year, I felt this might be better)\n- Bi-Weekly pay is multiplied by 24. ( As we have two bi-weeks in a month)","9b0a7bfc":"#### Hourly Pay\n- The minimum hourly salary should atleast 15. I cant imagine less than 15 cuz gas stations pay 10-12\/hour\n- the maximum salary may be around 110\/hour.(Purely my guess)","d65cc709":"#### Examine the new column we created.","7700461e":"### VIRGINIA and DC","2089fc6d":"## The newly created column contents","8a3d38d3":"#### Number of applications per year\n- As this the data upto 2017, the employment_start_date has only very few 2018 dates.\n- And of those few, some are removed during the process of dealing with missing values","02681cf1":"## Top 20 Job titles","836481a8":"## IT and TECH Analysis.\n- The following was taken from @DhrumilVora.(Kaggle)\n- It creates a new column occupation based on the key words from the SOC_NAME column.","78e09437":"## Companies to FOCUS (for me)","6d668c01":"## Dealing with outliers in Pay scale.\n- In the below code, see the difference between the 75th percentile and the max value, that huge difference clearly indicates the presence of outliers.\n- The min has value of 0, which is obviously false. ( No one works for free)","18b9f094":"# H1-B VISA ","a1a0612b":"### GROWTH IN DATA SCIENCE FROM YEARS","2b58a527":"#### Creating a new dummy column\n- As, we are going to deal with a lot of groupby methods below, it will be easy for us if we have a count column.","2fd19064":"### DATA SCIENCE JOB AND THE EMPLOYER WHICH IT TOPS\n- Means, the respective data science job and the Employer which has the most number of respective job.","155d3788":"## END\n- SAITEJA NAKKA","b7b19636":"### Top Employers sponsoring H1-B's\n- The plots are made using plotly which are interactive. So, you can hover over the plot to know more details","a8e9d340":"### Distribution of Case_Status column\n- A lot of them were certified. (Hope's alive :) )","fe6ed2e3":"### Working only on the TECH\/IT data.","db0c4a03":"### HOTTEST JOB IN EVERY STATE\n#### - In the plot below hover around the states in map to know more.","84ed1821":"## TOP 20 MOST PAID TECH FIELDS.","0bb95fc5":"#### Number of unique values each column has","1fa9b738":"### Average Annual pay of each year from 2011-2018","964c0f61":"#### Checking again.\n- Now you that we have unit of pay in hour and year only.","f0499a91":"### Top Employers and its Case status bar.","3f867b98":"## DATA SCIENCE: \n- I'm going to do some analysis on our domain.\n- Created a new column DS as shown below. ","68c53156":"### Convert the EMPLOYMENT_START_DATE to pandas date time format","4e297bcd":"## Dealing with missing values\n- The following method is same as dropna.","7653b1dc":"### The Average annual salaries of the newly created departments.","e5eca262":"### DATA SCIENCE JOB AND THE STATE WHICH IT TOPS\n- Means, the respective data science job and the state which has the most number of respective job.\n- To explain, the business analysts are more in New Jersey while the data analysts are more in california."}}