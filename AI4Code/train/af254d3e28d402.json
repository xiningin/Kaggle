{"cell_type":{"432b5613":"code","163b9d14":"code","64d7620a":"code","02842d01":"code","9a255b36":"code","d9b97ee6":"code","cc9851dd":"code","5ce7b0aa":"code","4d576458":"code","255ea657":"code","f7f95e83":"code","f38f04d9":"code","6367bcc3":"code","8f563389":"code","86a37130":"code","9bb280d9":"code","3270be57":"code","4f328932":"code","0d2d74b8":"code","d4624aa8":"code","7d237dae":"code","aa49376b":"code","59985bde":"code","5a611b05":"code","af7da7c0":"code","d6e78595":"code","af462a4b":"markdown","55704e6f":"markdown","2ced290d":"markdown"},"source":{"432b5613":"import pandas as pd                #Pandas library for data analysis\nimport numpy as np                 #For numerical analysis of data\nimport matplotlib.pyplot as plt    #Python's plotting \n\n\nimport plotly.express as px       #Plotly for plotting the COVID-19 Spread.\nimport plotly.offline as py       #Plotly for plotting the COVID-19 Spread.\nimport seaborn as sns             #Seaborn for data plotting\nimport plotly.graph_objects as go #Plotlygo for plotting\n\nfrom plotly.subplots import make_subplots\n\n\nimport glob                       #For assigning the path\nimport os                         #OS Library for implementing the functions.\n\nimport warnings\nwarnings.filterwarnings('ignore') \n\n#Selcting the other essential libraries for data manipulation\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nimport datetime as dt\nimport xgboost as xgb\nfrom xgboost import XGBRegressor","163b9d14":"#Reading the cumulative cases dataset\ncovid_cases = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\n\n#Viewing the dataset\ncovid_cases.head()","64d7620a":"#Importing the essential datasets from the challenge\n\ntraining_data = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/train.csv\")\ntesting_data = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/test.csv\")","02842d01":"#Checking for the null values in dataset\nprint(training_data.isnull().sum())\nprint(testing_data.isnull().sum())\n\n#Checking for the datatypes for the columns\nprint(training_data.dtypes)\nprint(testing_data.dtypes)\n\n#Filling the values\ntraining_data['Province_State'].fillna(\"\",inplace = True)\ntesting_data['Province_State'].fillna(\"\",inplace = True)","9a255b36":"#Groping the same cities and countries together along with their successive dates.\n\ncountry_list = covid_cases['Country\/Region'].unique()\n\ncountry_grouped_covid = covid_cases[0:1]\n\nfor country in country_list:\n    test_data = covid_cases['Country\/Region'] == country   \n    test_data = covid_cases[test_data]\n    country_grouped_covid = pd.concat([country_grouped_covid, test_data], axis=0)\n    \ncountry_grouped_covid.reset_index(drop=True)\ncountry_grouped_covid.head()\n\n#Dropping of the column Last Update\ncountry_grouped_covid.drop('Last Update', axis=1, inplace=True)\n\n#Replacing NaN Values in Province\/State with a string \"Not Reported\"\ncountry_grouped_covid['Province\/State'].replace(np.nan, \"Not Reported\", inplace=True)\n\n#Printing the dataset\ncountry_grouped_covid.head()\n\n#country_grouped_covid holds the dataset for the country","d9b97ee6":"#Creating a dataset to analyze the cases country wise - As of 04\/10\/2020\n\nlatest_data = country_grouped_covid['ObservationDate'] == '04\/10\/2020'\ncountry_data = country_grouped_covid[latest_data]\n\n#The total number of reported Countries\ncountry_list = country_data['Country\/Region'].unique()\nprint(\"The total number of countries with COVID-19 Confirmed cases = {}\".format(country_list.size))","cc9851dd":"#Plotting a bar graph for confirmed cases vs deaths due to COVID-19 in World.\n\nunique_dates = country_grouped_covid['ObservationDate'].unique()\nconfirmed_cases = []\nrecovered = []\ndeaths = []\n\nfor date in unique_dates:\n    date_wise = country_grouped_covid['ObservationDate'] == date  \n    test_data = country_grouped_covid[date_wise]\n    \n    confirmed_cases.append(test_data['Confirmed'].sum())\n    deaths.append(test_data['Deaths'].sum())\n    recovered.append(test_data['Recovered'].sum())\n    \n#Converting the lists to a pandas dataframe.\n\ncountry_dataset = {'Date' : unique_dates, 'Confirmed' : confirmed_cases, 'Recovered' : recovered, 'Deaths' : deaths}\ncountry_dataset = pd.DataFrame(country_dataset)\n\n#Plotting the Graph of Cases vs Deaths Globally.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=country_dataset['Date'], y=country_dataset['Confirmed'], name='Confirmed Cases of COVID-19', marker_color='rgb(55, 83, 109)'))\nfig.add_trace(go.Bar(x=country_dataset['Date'],y=country_dataset['Deaths'],name='Total Deaths because of COVID-19',marker_color='rgb(26, 118, 255)'))\n\nfig.update_layout(title='Confirmed Cases and Deaths from COVID-19',xaxis_tickfont_size=14,\n                  yaxis=dict(title='Reported Numbers',titlefont_size=16,tickfont_size=14,),\n    legend=dict(x=0,y=1.0,bgcolor='rgba(255, 255, 255, 0)',bordercolor='rgba(255, 255, 255, 0)'),barmode='group',bargap=0.15, bargroupgap=0.1)\nfig.show()\n\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=country_dataset['Date'], y=country_dataset['Confirmed'], name='Confirmed Cases of COVID-19', marker_color='rgb(55, 83, 109)'))\nfig.add_trace(go.Bar(x=country_dataset['Date'],y=country_dataset['Recovered'],name='Total Recoveries because of COVID-19',marker_color='rgb(26, 118, 255)'))\n\nfig.update_layout(title='Confirmed Cases and Recoveries from COVID-19',xaxis_tickfont_size=14,\n                  yaxis=dict(title='Reported Numbers',titlefont_size=16,tickfont_size=14,),\n    legend=dict(x=0,y=1.0,bgcolor='rgba(255, 255, 255, 0)',bordercolor='rgba(255, 255, 255, 0)'),\n    barmode='group',bargap=0.15, bargroupgap=0.1)\nfig.show()","5ce7b0aa":"#Generating a function to concatenate all of the files available.\n\nfolder_name = '..\/input\/covcsd-covid19-countries-statistical-dataset'\nfile_type = 'csv'\nseperator =','\ndataframe = pd.concat([pd.read_csv(f, sep=seperator) for f in glob.glob(folder_name + \"\/*.\"+file_type)],ignore_index=True,sort=False)","4d576458":"#Selecting the columns that are required as is essential for the data-wrangling task\n\ncovid_data = dataframe[['Date', 'State', 'Country', 'Cumulative_cases', 'Cumulative_death',\n       'Daily_cases', 'Daily_death', 'Latitude', 'Longitude', 'Temperature',\n       'Min_temperature', 'Max_temperature', 'Wind_speed', 'Precipitation',\n       'Fog_Presence', 'Population', 'Population Density\/km', 'Median_Age',\n       'Sex_Ratio', 'Age%_65+', 'Hospital Beds\/1000', 'Available Beds\/1000',\n       'Confirmed Cases\/1000', 'Lung Patients (F)', 'Lung Patients (M)',\n       'Life Expectancy (M)', 'Life Expectancy (F)', 'Total_tests_conducted',\n       'Out_Travels (mill.)', 'In_travels(mill.)', 'Domestic_Travels (mill.)']]","255ea657":"#Merging the columns together\n\ntraining_data['Country_Region'] = training_data['Country_Region'] + ' ' + training_data['Province_State']\ntesting_data['Country_Region'] = testing_data['Country_Region'] + ' ' + testing_data['Province_State']\ndel training_data['Province_State']\ndel testing_data['Province_State']\n\n#Creating a function to split-date\n\ndef split_date(date):\n    date = date.split('-')\n    date[0] = int(date[0])\n    if(date[1][0] == '0'):\n        date[1] = int(date[1][1])\n    else:\n        date[1] = int(date[1])\n    if(date[2][0] == '0'):\n        date[2] = int(date[2][1])\n    else:\n        date[2] = int(date[2])    \n    return date\n\ntraining_data.Date = training_data.Date.apply(split_date)\ntesting_data.Date = testing_data.Date.apply(split_date)","f7f95e83":"#Manipulation of columns for both training dataset\n\nyear = []\nmonth = []\nday = []\n\nfor i in training_data.Date:\n    year.append(i[0])\n    month.append(i[1])\n    day.append(i[2])\n    \ntraining_data['Year'] = year\ntraining_data['Month'] = month\ntraining_data['Day'] = day\ndel training_data['Date']\n\n#Manipulation of columns for both testing dataset\n\nyear = []\nmonth = []\nday = []\nfor i in testing_data.Date:\n    year.append(i[0])\n    month.append(i[1])\n    day.append(i[2])\n    \ntesting_data['Year'] = year\ntesting_data['Month'] = month\ntesting_data['Day'] = day\ndel testing_data['Date']\ndel training_data['Id']\ndel testing_data['ForecastId']\ndel testing_data['Year']\ndel training_data['Year']","f38f04d9":"#Filtering of the dataset to view the latest contents (as of 30-03-2020)\nlatest_data = covid_data['Date'] == '30-03-2020'\ncountry_data_detailed = covid_data[latest_data]\n\n#Dropping off unecssary columns from the country_data_detailed dataset\ncountry_data_detailed.drop(['Daily_cases','Daily_death','Latitude','Longitude'],axis=1,inplace=True)\n\n#Viewing the dataset\ncountry_data_detailed.head(3)","6367bcc3":"#Replacing the text Not Reported and N\/A with numpy missing value cmputation\n\ncountry_data_detailed.replace('Not Reported',np.nan,inplace=True)\ncountry_data_detailed.replace('N\/A',np.nan,inplace=True)\n\n\n#Viewing the dataset\ncountry_data_detailed.head(3)","8f563389":"#Converting the datatypes\n\ncountry_data_detailed['Lung Patients (F)'].replace('Not reported',np.nan,inplace=True)\ncountry_data_detailed['Lung Patients (F)'] = country_data_detailed['Lung Patients (F)'].astype(\"float\")","86a37130":"#Getting the dataset to check the correlation \ncorr_data = country_data_detailed.drop(['Date','State','Country','Min_temperature','Max_temperature','Out_Travels (mill.)',\n                                        'In_travels(mill.)','Domestic_Travels (mill.)','Total_tests_conducted','Age%_65+'], axis=1)\n\n#Converting the dataset to the correlation function\ncorr = corr_data.corr()","9bb280d9":"#Plotting a heatmap\n\ndef heatmap(x, y, size,color):\n    fig, ax = plt.subplots(figsize=(20,3))\n    \n    # Mapping from column names to integer coordinates\n    x_labels = corr_data.columns\n    y_labels = ['Cumulative_cases', 'Cumulative_death']\n    x_to_num = {p[1]:p[0] for p in enumerate(x_labels)} \n    y_to_num = {p[1]:p[0] for p in enumerate(y_labels)} \n    \n    n_colors = 256 # Use 256 colors for the diverging color palette\n    palette = sns.cubehelix_palette(n_colors) # Create the palette\n    color_min, color_max = [-1, 1] # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n\n    def value_to_color(val):\n        val_position = float((val - color_min)) \/ (color_max - color_min) # position of value in the input range, relative to the length of the input range\n        ind = int(val_position * (n_colors - 1)) # target index in the color palette\n        return palette[ind]\n\n    \n    ax.scatter(\n    x=x.map(x_to_num),\n    y=y.map(y_to_num),\n    s=size * 1000,\n    c=color.apply(value_to_color), # Vector of square color values, mapped to color palette\n    marker='s'\n)\n    \n    # Show column labels on the axes\n    ax.set_xticks([x_to_num[v] for v in x_labels])\n    ax.set_xticklabels(x_labels, rotation=30, horizontalalignment='right')\n    ax.set_yticks([y_to_num[v] for v in y_labels])\n    ax.set_yticklabels(y_labels)\n    \n    \n    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n    \n    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5]) \n    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n    \ncorr = pd.melt(corr.reset_index(), id_vars='index') \ncorr.columns = ['x', 'y', 'value']\nheatmap(x=corr['x'],y=corr['y'],size=corr['value'].abs(),color=corr['value'])","3270be57":"#Creating a correlation matrix\n\nmatrix = corr_data.corr()\nprint(matrix)","4f328932":"#Reading the temperature data file\ntemperature_data = pd.read_csv('..\/input\/covcsd-covid19-countries-statistical-dataset\/temperature_data.csv')\n\n#Viewing the dataset\ntemperature_data.head()","0d2d74b8":"#Checking the dependence of Temperature on Confirmed COVID-19 Cases\n\nunique_temp = temperature_data['Temperature'].unique()\nconfirmed_cases = []\ndeaths = []\n\nfor temp in unique_temp:\n    temp_wise = temperature_data['Temperature'] == temp\n    test_data = temperature_data[temp_wise]\n    \n    confirmed_cases.append(test_data['Daily_cases'].sum())\n    deaths.append(test_data['Daily_death'].sum())\n    \n#Converting the lists to a pandas dataframe.\n\ntemperature_dataset = {'Temperature' : unique_temp, 'Confirmed' : confirmed_cases, 'Deaths' : deaths}\ntemperature_dataset = pd.DataFrame(temperature_dataset)","d4624aa8":"#Plotting a scatter plot for cases vs. Temperature\n\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\nfig.add_trace(go.Scattergl(x = temperature_dataset['Temperature'],y = temperature_dataset['Confirmed'], mode='markers',\n                                  marker=dict(color=np.random.randn(10000),colorscale='Viridis',line_width=1)),secondary_y=False)\n\nfig.add_trace(go.Box(x=temperature_dataset['Temperature']),secondary_y=True)\n\nfig.update_layout(title='Daily Confirmed Cases (COVID-19) vs. Temperature (Celcius) : Global Figures - January 22 - March 30 2020',\n                  yaxis=dict(title='Reported Numbers'),xaxis=dict(title='Temperature in Celcius'))\n\nfig.update_yaxes(title_text=\"BoxPlot Range \", secondary_y=True)\n\nfig.show()\n","7d237dae":"#Conducting Statistical Tests over the dataset\n\nsample = temperature_dataset['Temperature'].sample(n=250)\ntest = temperature_dataset['Temperature']\n\nfrom scipy.stats import ttest_ind\n\nstat, p = ttest_ind(sample, test)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","aa49376b":"training_data['ConfirmedCases'] = training_data['ConfirmedCases'].apply(int)\ntraining_data['Fatalities'] = training_data['Fatalities'].apply(int)\n\ncases = training_data.ConfirmedCases\nfatalities = training_data.Fatalities\ndel training_data['ConfirmedCases']\ndel training_data['Fatalities']\n\nlb = LabelEncoder()\ntraining_data['Country_Region'] = lb.fit_transform(training_data['Country_Region'])\ntesting_data['Country_Region'] = lb.transform(testing_data['Country_Region'])\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(training_data.values)\nx_test = scaler.transform(testing_data.values)","59985bde":"from xgboost import XGBRegressor\n\nrf = XGBRegressor(n_estimators = 1500 , max_depth = 15, learning_rate=0.1)\nrf.fit(x_train,cases)\ncases_pred = rf.predict(x_test)\n\nrf = XGBRegressor(n_estimators = 1500 , max_depth = 15, learning_rate=0.1)\nrf.fit(x_train,fatalities)\nfatalities_pred = rf.predict(x_test)","5a611b05":"#Rouding off the prediction values and converting negatives to zero\ncases_pred = np.around(cases_pred)\nfatalities_pred = np.around(fatalities_pred)\n\ncases_pred[cases_pred < 0] = 0\nfatalities_pred[fatalities_pred < 0] = 0","af7da7c0":"#Importing the dataset for generating output\nsubmission_dataset = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/submission.csv\")\n\n#Adding results to the dataset\nsubmission_dataset['ConfirmedCases'] = cases_pred\nsubmission_dataset['Fatalities'] = fatalities_pred\n\nsubmission_dataset.head()","d6e78595":"#Submitting the dataset\nsubmission_dataset.to_csv(\"submission.csv\" , index = False)","af462a4b":"<h3> Plotting a Running Map for observing the spread of COVID-19 Confirmed Cases <\/h3>\n","55704e6f":"<a id='ov1'><h3> General Observations from the above Choreopleth Graphs <\/h3><\/a>\n\n1. The cases of COVID-19 starts from China as the epicenter with first initial COVID-19 Cases reported in Australia, US, Canada.\n\n2. Gradually cases in China increases and the confirmed cases is more than anywhere else in the world.\n\n3. Europe emerges later as the new epicenter for the virus, where there is a rapid rise in COVID-19 Cases in European Countries. This outbreak occurs where the confirmed number of COVID-19 Cases in China saturates.\n\n4. The confirmed cases of COVID-19 gradually spreads throughout the world, with spike in confirmed cases seen in European regions and US.\n\n5. As of April 3rd 2020, USA has the highest number of confimed COVID-19 Cases reported, with some European Countries emerging as the 2nd-4th highest cases of COVID-19\n\n<a id='barspread'><h3> Analysis of Spread and deaths due to COVID-19 from Bar Graphs <\/h3><\/a>","2ced290d":"<a id='data'><h3>Datasets used in the notebook<h3><\/a>\n\n1. We read the Novel-Corona-Virus-2019-dataset managed by SRK into this notebook. The dataset hold s information about the cumulative case counts of COVID-19 Across the world. The dataset can be viewed and downloaded from - [here](https:\/\/www.kaggle.com\/sudalairajkumar\/novel-corona-virus-2019-dataset)\n\n2. The dataset CovCSD - COVID-19 Countries Statistical Dataset created by me (Available at https:\/\/www.kaggle.com\/aestheteaman01\/covcsd-covid19-countries-statistical-dataset) is loaded here. The information for the dataset can be seen at the description section for the dataset.\n\n3. The default dataset available with this notebook"}}