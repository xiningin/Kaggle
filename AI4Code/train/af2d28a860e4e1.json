{"cell_type":{"77f23468":"code","6993b2d2":"code","80866d65":"code","97df1950":"code","0e65eb2c":"code","2238cb53":"code","3dc4703b":"code","29632d00":"code","a94d6658":"code","4e2b4150":"code","dbb3498f":"code","ec76f32e":"code","b72a566f":"code","0862d671":"code","fb746153":"code","deab3911":"code","2c4bd776":"code","5d699462":"code","1c32f7e9":"code","c95eebe5":"code","0a18dc30":"code","aa4bd6c4":"code","fc25296a":"code","5159a401":"code","7950e3e0":"code","4ae39496":"code","94e0afac":"code","88b48445":"code","4b9a2e7e":"code","a444bffd":"code","0ca6afb9":"code","11db5576":"code","1c4581f0":"code","bb11750b":"code","2e69f4ca":"code","656b162a":"code","281fd951":"code","7591e4aa":"code","396a4836":"code","1f905aeb":"code","e4f33790":"code","034a879b":"code","c1b742e1":"code","8c1daaa1":"code","83723974":"code","180bf1e1":"code","04b389df":"code","dac600de":"code","1655890c":"markdown","89b3a15b":"markdown","38406977":"markdown","ac00fea1":"markdown","672ad4f1":"markdown","bfe69415":"markdown","93856b78":"markdown","8538d5a4":"markdown","d608ec84":"markdown","f7e81ecc":"markdown","b323b414":"markdown","39221dd2":"markdown","dcdde3a8":"markdown","501b3418":"markdown","6ab238a8":"markdown","cdfa6395":"markdown","08a12bb5":"markdown","a3d43990":"markdown","341fdb55":"markdown","bbbe86cc":"markdown","6d563b02":"markdown","086720e9":"markdown","c08204ae":"markdown","afb9e622":"markdown","ca67bebe":"markdown","29f99623":"markdown","0891c249":"markdown","cc2a420a":"markdown","2c9068c8":"markdown","63084a2f":"markdown","512dcff0":"markdown","c3af62e6":"markdown","6d8ccca9":"markdown","c3b7c35c":"markdown","1eee1708":"markdown","59e0e280":"markdown","56c6448b":"markdown","f141ca66":"markdown","aaa307a9":"markdown"},"source":{"77f23468":"import torch","6993b2d2":"torch.__version__","80866d65":"x = torch.empty([5, 3])\nprint(x)","97df1950":"y = torch.empty(5, 3)\nprint(y)","0e65eb2c":"a = torch.rand(5, 4)\nprint(a)","2238cb53":"z = torch.zeros(5, 3, dtype=torch.long)\nprint(z)","3dc4703b":"b = torch.tensor([5.09, 3])\nprint(b)","29632d00":"c = torch.randn_like(z, dtype=torch.float32)\nprint(c)","a94d6658":"c = c.new_ones(5, 6, dtype=torch.double)\nprint(c)","4e2b4150":"print(c.size())","dbb3498f":"d = torch.randn(5, 6, dtype=torch.double)\nprint(c + d)","ec76f32e":"e = torch.randn(5, 6, dtype = torch.float)\nprint(c + e)","b72a566f":"print(torch.add(c, d))","0862d671":"result = torch.empty(5, 6, dtype=torch.double)\ntorch.add(c, d, out=result)\nprint(result)","fb746153":"e = d\ne.add_(c)\nprint(e)","deab3911":"print(e[:, 1])","2c4bd776":"x = torch.randn(4, 5)\ny = x.view(20)\nz = x.view(-1, 2, 2)\nprint(x, \"\\n\", x.size())\nprint(y, \"\\n\", y.size())\nprint(z, \"\\n\", z.size())","5d699462":"print(e.numpy())","1c32f7e9":"a = torch.ones(2, 3)\nb = a.numpy()\nprint(b)\na = a.add_(1)\nprint(a)\nprint(b)","c95eebe5":"import numpy as np\na = np.ones((5, 2))\nb = torch.from_numpy(a) ## This is the command\nprint(b)\nnp.add(a, 3, out = a)\nprint(a)\nprint(b)","0a18dc30":"x = torch.ones(2, 3, requires_grad=True)\nprint(x)","aa4bd6c4":"y = x + 2\nprint(y)","fc25296a":"print(y.grad_fn)","5159a401":"z = y * y * 3\nout = z.mean()\nprint(z)\nprint(out)","7950e3e0":"out.backward()","4ae39496":"print(x.grad)","94e0afac":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","88b48445":"# A new class Net is created. It inherits from the nn.Module class\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # super initializes a class of the superclass nn.Module\n        #The following attributes are added to the class instance during the initialization\n        \n        # The convolutional layers are defined. Note that these are all functions but are defined like attributes\n        self.conv1 = nn.Conv2d(1, 6, 5) #input channels = 1, output channels = 1, window size = 5\n        self.conv2 = nn.Conv2d(6, 16, 5) #input channels = 6, output channels = 16, window size = 5\n        \n        # The fully connected layers are defined\n        self.fc1 = nn.Linear(16 * 5 * 5, 120) #input nodes = 16 * 5 * 5 (since each of the 16 channels are of the size 5 * 5), output = 120\n        self.fc2 = nn.Linear(120, 84) #input = 120 output = 84\n        self.fc3 = nn.Linear(84, 10) #last layer: input = 84, output = 10\n        \n        \n    def forward(self, x):\n        \"\"\"This method defines the forward pass of the neural network\"\"\"\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # The first convolutional layer with all the max pooling and relu layers: there is a 2X2 max pooling\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # The second conv layer: 2 X 2 max pooling\n        x = x.view(-1, self.num_flat_features(x)) # The reshape (flattening) layer which changes the shape of the tensor from that of a multichannel 2D tensor to a 1D tensor\n        x = F.relu(self.fc1(x)) # Fully connected layer with activation\n        x = F.relu(self.fc2(x)) # Fully connected layer with activation\n        x = self.fc3(x) # Output layer\n        \n        return x\n    \n    def num_flat_features(self, x):\n        \"\"\"This method helps get the shape of the individual comeponents of the tensor\"\"\"\n        size = x.size()[1:] # The shape of the tensor without the first dimension which defines the number of samples\n        num_features = 1 # the shapes are are multiplied together to give the number of features\n        for s in size:\n            num_features *= s\n        return num_features\n    \nnet = Net()\nprint(net)","4b9a2e7e":"params = list(net.parameters())\nprint(len(params))\nfor i in range(len(params)):\n    print(params[i].size())","a444bffd":"inp = torch.randn(1, 1, 32, 32)\nout = net(inp)\nprint(out)","0ca6afb9":"net.zero_grad()","11db5576":"out.backward(torch.randn(1, 10))","1c4581f0":"out = net(inp)\ntarget = torch.randn(10)\ntarget = target.view(1, -1)\ncriteria = nn.MSELoss()\n\nloss = criteria(out, target)\nprint(loss)","bb11750b":"print(loss.grad_fn)\nprint(loss.grad_fn.next_functions[0][0])\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])","2e69f4ca":"net.zero_grad() # clearing all the gradients\n\nprint(\"Conv 1 bias before backward()\")\nprint(net.conv1.bias.grad)\n\nloss.backward()\nprint(\"Conv 2 bias after backward()\")\nprint(net.conv1.bias.grad)","656b162a":"learning_rate = 0.001\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)","281fd951":"import torch.optim as optim\noptimizer = optim.SGD(net.parameters(), lr = 0.01)\n\noptimizer.zero_grad()\nout = net(inp)\nloss = criteria(out, target)\nloss.backward()\noptimizer.step()","7591e4aa":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","396a4836":"transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True, download=True, transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root=\".\/data\", train = False, download=True, transform=transform)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 4, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","1f905aeb":"import matplotlib.pyplot as plt\nimport random\ndef plot_figs(num_figs = 10):\n    fig, axes = plt.subplots(1, num_figs, figsize=(1 * num_figs, 1))\n    num_train = len(trainset.train_labels)\n    random_nums = random.sample(range(num_train), num_figs)\n    for i in range(num_figs):\n        axes[i].imshow(trainset.train_data[random_nums[i]])\n        axes[i].set_title(classes[trainset.train_labels[random_nums[i]]])\n        axes[i].set_xticks([])\n        axes[i].set_yticks([])\n    plt.show()","e4f33790":"plot_figs(10)","034a879b":"# before defining the convnet we need to figure out the shape of the inputs\ntrainset.train_data[0].shape","c1b742e1":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 8, 5)\n        self.conv2 = nn.Conv2d(8, 16, 5)\n        \n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","8c1daaa1":"net = ConvNet()","83723974":"# Define a loss function and an optiizer\n\nimport torch.optim as optim\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)","180bf1e1":"# Train the network\n\nfor epoch in range(2):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        \n        optimizer.zero_grad()\n        \n        outputs = net(inputs)\n        \n        loss = criteria(outputs, labels)\n        loss.backward()\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 2000 == 1999:\n            print(\"[{}, {}], Loss: {}\".format(epoch + 1, i + 1, running_loss \/ 2000.))\n            running_loss = 0.0\nprint(\"Finished Training\")","04b389df":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))","dac600de":"import numpy as np\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\noutputs = net(images)\n_, predicted = torch.max(outputs, 1)\n\nimshow(torchvision.utils.make_grid(images))\nfor i in range(4):\n   print(\"Actual {}\\tPredicted: {}\".format(classes[labels[i]], classes[predicted[i]]))","1655890c":"Similarly arrays defined in numpy can also be converted to torch tensors in the following way. As in the above case, the tensor mutates if the original numpy array changes.","89b3a15b":"The dimensions of the tensors can be given in two ways as shown above. Please note that the data types of the tensors are important as we will see later","38406977":"# Training an actual classifier","ac00fea1":"Now we will update all the weights","672ad4f1":"We will use the CIFAR 10 dataset which comes preloaded in the torchvision package. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.","bfe69415":"The backprops are initialized with random gradients","93856b78":"We can specify the data type in the above way. For a complete list of all the available datatypes, refer to this link: \nhttps:\/\/pytorch.org\/docs\/stable\/tensors.html","8538d5a4":"When we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient. lets see for example what happens","d608ec84":"Since the tensor c is of dtype tensor.double and the tensor e is of dtype tensor.float, these two cannot be added. Therefore always be sure about the datatype of the tensors you are defining.","f7e81ecc":"Now, we define a simple random tensor and compute the output","b323b414":"To convert a torch tensor to a numpy array the following command can be used","39221dd2":"Testing the performance on the test set","dcdde3a8":"The learnable parameters of the network can be returned using the net.parameters() function","501b3418":"First we import all the necesarry packages and methods","6ab238a8":"Now we will do the actual backprop step. But we first need to clear all the accumulated gradients, else gradients will be accumulated into the existing gradients","cdfa6395":"# simple neural network\nWe finally look at how to code a simple convolutional neural network in pytorch. This neural network has two convolutinal layers followed by two feed forward fully connected layers and an output multiclass layer.","08a12bb5":"The tensors can be indexed just like in numpy","a3d43990":"The values of a defined tensor can be changed in the following way","341fdb55":"We can also copy the dimensions of one tensor while creating another as shown below","bbbe86cc":"First we import all the important libraries","6d563b02":"If another tensor results from any operation on a requires_grad = True tensor, then the grad_fn attribute of the new tensor records what operation has given that tensor","086720e9":"# Basics","c08204ae":"Below is an example of adding in place. Note that \"operation\" followed by \"_ \" signifies an operation in place","afb9e622":"# Foreword\nThis is a very simple introduction to coding up neural networks in PyTorch, a deep learning library developed and maintained by Facebook. Let's jump right in.\n\nP.S. This tutorial is based on the first three tutorials in the PyTorch website. So if you have done that already, you may find this redundant\nAlso, this turorial is for PyTorch version 0.4. If you are using some other version of PyTorch, you might face issues.","ca67bebe":"We can see that all the dimensions of the learnable parameters are compliant","29f99623":"### Introduction and similarity with Numpy","0891c249":"The shape of the tensors can be found using the tensor.size() function","cc2a420a":"Other ways of adding two tensors are demonstrated below","2c9068c8":"## End\nThat brings us to the end of the first tutorial. We have more to follow. Here's the link to the next tutorial: https:\/\/www.kaggle.com\/krishanudb\/basic-computation-graph-using-pytorch","63084a2f":"We zero the gradient buffers of all the parameters","512dcff0":"## Define a convolutional neural network","c3af62e6":"Note how even after defining a numpy array from a torch tensor, the numpy array can still change if the original tensor is changed","6d8ccca9":"The actual neural network class is defined below","c3b7c35c":"All tensors can be defined as requiring gradients. If the option requires_grad = True, then all the operations done on the tensor will be recorded","1eee1708":"Now we define the loss function. The loss function always takes the paired output - target tensors and computes the loss (distance between them in any predefined space). There are many predefined loss function in the torch package. Here we use the MSE Loss (Mean Squared Error Loss). For a complete list of loss functions please visit: \nhttps:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions","59e0e280":"That was the simplest way of updating parameters. However, there are more advanced ways of updating the parameters, using the optim method","56c6448b":"# Autograd\nAutograd is one of the most important methods of torch. It is used mainly for computing gradients and other backward propagation methods\nautograd provides differentiation for all operations on Tensors","f141ca66":"The tensor.view() method is used to reshape the tensor. It is similar to teh reshape functino in numpy.\nThe -1 option is used so that the method can automatically decipher the dimensions given the other dimensions","aaa307a9":"When done defining all the operations, simply calling tensor.backward() function computes the gradients automatically. The gradient for this tensor will accumulate in the tensor.grad atribute"}}