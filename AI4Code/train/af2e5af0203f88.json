{"cell_type":{"be09ba81":"code","c5a5438f":"code","56aa61e6":"code","f8a1cfbb":"code","fc51a921":"code","f16cadd9":"code","ff31a4d9":"code","1b218624":"code","e9b6389d":"code","bd78331e":"code","c3219ae2":"code","975dda0c":"code","93232d42":"code","9118cd67":"code","f862a592":"code","1bd1770c":"code","e91e50a1":"code","8e2ad2c5":"code","1935ad16":"markdown","28616a9c":"markdown","9707113e":"markdown","4678e981":"markdown","b14012de":"markdown","cdec5cec":"markdown","05799e28":"markdown","0a339c6e":"markdown","21458cc8":"markdown"},"source":{"be09ba81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c5a5438f":"print(os.listdir())","56aa61e6":"print(os.getcwd())","f8a1cfbb":"os.chdir('..\/input\/')","fc51a921":"print(os.listdir())","f16cadd9":"data_dir = '.'\nfname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n\nf = open(fname)\ndata = f.read()\nf.close()\n\nlines = data.split('\\n')\nheader = lines[0].split(',')\nlines = lines[1:]\n\nprint(header)\nprint(len(lines))","ff31a4d9":"float_data = np.zeros((len(lines), len(header) - 1))\nfor i, line in enumerate(lines):\n    values = [float(x) for x in line.split(',')[1:]]\n    float_data[i, :] = values","1b218624":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\ntemp = float_data[:, 1]\nplt.plot(range(len(temp)), temp)","e9b6389d":"plt.plot(range(1440), temp[:1440])","bd78331e":"mean = float_data[:200000].mean(axis=0)\nfloat_data -= mean\nstd = float_data[:200000].std(axis=0)\nfloat_data \/= std","c3219ae2":"float_data.shape","975dda0c":"def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n    if max_index is None:\n        max_index = len(data) - delay - 1\n    i = min_index + lookback\n    while 1:\n        if shuffle:\n            rows = np.random.randint(\n            min_index + lookback, max_index, size=batch_size)\n        else:\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n            \n        samples = np.zeros((len(rows),\n                           lookback \/\/ step,\n                           data.shape[-1]))\n        targets = np.zeros((len(rows)))\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay][1]\n        yield samples, targets\n    ","93232d42":"lookback = 1440\nstep = 6\ndelay = 144\nbatch_size = 128","9118cd67":"train_gen = generator(float_data,\n                     lookback = lookback,\n                     delay = delay,\n                     min_index = 0,\n                     max_index = 200000,\n                     shuffle=True,\n                     step = step,\n                     batch_size = batch_size)\n\nval_gen = generator(float_data,\n                   lookback = lookback,\n                   delay = delay,\n                   min_index = 200001,\n                   max_index = 300000,\n                   step = step,\n                   batch_size=batch_size)\n\ntest_gen = generator(float_data,\n                    lookback=lookback,\n                    delay=delay,\n                    min_index=300001,\n                    max_index=None,\n                    step = step,\n                    batch_size = batch_size)","f862a592":"val_steps = (300000 - 200001 - lookback)\ntest_steps = (len(float_data) - 300001 - lookback)","1bd1770c":"def evaluation_naive_method():\n    batch_maes = []\n    for step in range(val_steps):\n        samples, targets = next(val_gen)\n        preds = samples[:, -1, 1]\n        mae = np.mean(np.abs(preds - targets))\n        batch_maes.append(mae)\n    print(np.mean(batch_maes))\n    \nevaluation_naive_method()","e91e50a1":"celsius_mae = 0.29 * std[1]\nprint(celsius_mae)","8e2ad2c5":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(layers.Flatten(input_shape=(lookback \/\/ step, float_data.shape[-1])))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1))\n\nmodel.compile(optimizer=RMSprop(), loss='mae')\n\nhistory = model.fit_generator(train_gen,\n                             steps_per_epoch=500,\n                             epochs=20,\n                             validation_data=val_gen,\n                             validation_steps=val_steps)","1935ad16":"### Plotting the first 10 days of the temperature timeseries","28616a9c":"### Normalize the data","9707113e":"### Parsing the Data","4678e981":"### Plotting the Temperature TimeSeries","b14012de":"### Converting the MAE back to a celcius error","cdec5cec":"### Training and evaluating a densely connected model","05799e28":"### Preparing the training, validation and test generators","0a339c6e":" ### Generator Yielding Time Series Samples and their Targets","21458cc8":"### Computing the common-sense baseline MAE"}}