{"cell_type":{"9ca2da05":"code","6c36b95a":"code","2d487cd9":"code","5bc85e7a":"code","a4d1b816":"code","cf6deb86":"code","b70c55cb":"code","e64a53ba":"code","7774e285":"code","03482f7c":"code","d825a355":"code","3f7b86b8":"code","018fed2f":"code","f96d2e3c":"code","6c3e729a":"code","8fcfa397":"code","1e1b6af5":"code","75eb061b":"code","ab27ac70":"code","f8452642":"code","792c36ad":"code","a9e91f84":"code","c6c68fb0":"code","44b6c55d":"code","17ce54fb":"code","09bb9777":"code","f7673837":"code","d9a46cd7":"code","5f7300e0":"code","ef3c3ac4":"code","1a325ab6":"code","5a105307":"code","f615ddb3":"code","df042b01":"code","767afbbf":"code","aeffa62d":"code","b3c2a739":"code","18ce6297":"code","8faecc64":"code","19df5acf":"code","c805c49c":"code","b65303bc":"code","12d7eb2f":"code","9a16632a":"code","ff387f25":"code","80821e5a":"code","21a5d9ce":"code","b6645d61":"code","91fd1624":"code","52004c2a":"code","51663518":"code","56049e9c":"code","04636841":"code","7c74a365":"code","e718ff89":"code","25ce35c6":"markdown","e6ba1e32":"markdown","86fb3dca":"markdown","6aed74c8":"markdown","9d253f03":"markdown","29668e19":"markdown","f827c242":"markdown","65d325c1":"markdown","68e65579":"markdown","fc7f65a3":"markdown","3d44b80d":"markdown","f6c6e47e":"markdown","772f4acc":"markdown","a3a87691":"markdown","66ee62bb":"markdown","88251d31":"markdown","ebc63dcb":"markdown","e6c05bd8":"markdown","2d02ced2":"markdown","a096cfe2":"markdown","238d81bb":"markdown","29eaea32":"markdown","4a569268":"markdown","40969a2f":"markdown","5fcba72b":"markdown","c1210d8a":"markdown","2c5cbe38":"markdown","4cb0db25":"markdown","29378ecf":"markdown","1b74d508":"markdown","2cdc5c80":"markdown","86b34891":"markdown","ee814ab2":"markdown","aede1582":"markdown","4c988332":"markdown","3b6664ff":"markdown","a60982e4":"markdown","0fbac12a":"markdown","41a4e02d":"markdown","577e1ff9":"markdown"},"source":{"9ca2da05":"import numpy as np\nimport pandas as pd\n\nfrom itertools import combinations\nimport re\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport seaborn as sns\nimport plotly.express as px\n\n\n%matplotlib inline","6c36b95a":"df = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\ndf.head()","2d487cd9":"## Creating a new list of headers. Using regex, we only keep Q plus the question number and whether it was a\n## B question\ncols = df.columns.copy()\ntop_h = []\n\nfor i in cols:\n    top_h.append(''.join(re.findall(r'[Q]\\d+|[B]', i)).lower())\n\n## reassign the first member as 'q0' for consistency\ntop_h[0] = 'q0'\npd.Series(top_h).unique()","5bc85e7a":"## writing a short description of what each question asks for\n\nq_list = ['duration', 'age', 'gender', 'country', 'education', 'title', 'yrs_of_experience', 'language',\n          'language_recommend', 'ide', 'notebook', 'computing_platform', 'hardware', 'tpu_use', 'viz', 'yrs_ml', 'ml',\n          'ml_algorithm', 'comp_vision', 'nlp', 'industry', 'company_size', 'ds_team', 'ml_at_workplace', 'roles',\n          'salary', 'ml_spend', 'cloud_platf', 'fav_cloud', 'cloud_prod', 'data_storage_prod', 'managed_ml_prod',\n          'bd_prod', 'fav_bd', 'bi_tool', 'fav_bi', 'auto_ml', 'auto_ml_prod', 'ml_experiment_manager', 'publishing',\n          'ds_course', 'ds_tool', 'media_source', 'future_cloud_platf', 'future_cloud_prod',\n          'future_data_storage_prod', 'future_managed_ml_prod', 'future_bd_prod', 'future_bi_tool', 'future_auto_ml',\n          'future_auto_ml_prod', 'future_ml_experiment_manager']","a4d1b816":"## next, we define a dictionary that maps each unique question number to the corresponding short description\n\nd_header = {}\nfor i in list(zip(pd.Series(top_h).unique(), q_list)):\n    d_header.update({i[0] : i[1]})","cf6deb86":"## finally, we create the final list of question headers using the original question numbers and their corresponding\n## descriptions from the dictionary\n\ntop_h2 = []\n\nfor i in top_h:\n    top_h2.append(i + '_' + d_header[i])\n\nprint(top_h2[: 20])","b70c55cb":"## next, we start defining our sub-headers\n\nlow_h = []\n\nfor i in range(len(top_h2)):\n    ## if the count of an individual header is greater than 1, that means its a multiple choice type question.\n    ## for these, we want each sub-header to represent the answer given\n    if top_h2.count(top_h2[i]) != 1:\n        ## these questions all would have ' - Selected Choice - ' before the given answer, so we sliced the strings\n        ## to return only what's on the right of this\n        low_h.append(df.iloc[0, i][df.iloc[0, i].rfind(' - ') + 3:])\n    else:\n        ## when there is only one of the unique header in the list, we just repeated the short description after the\n        ## question number to create the subheader\n        low_h.append(top_h2[i][top_h2[i].find('_') + 1:])","e64a53ba":"## finally, we also formatted the strings to make them more compact (note that 'c++' would become 'cpp', which is \n## something to keep in mind when working with the language columns)\n\nfor i in range(len(low_h)):\n    low_h[i] = low_h[i].split('(')[0].strip().lower().replace('&', '').replace('++', 'pp').replace('+', '').replace('\/', '').replace('.', '_').replace('-', '_').replace('  ', ' ').replace(' ', '_')\n","7774e285":"## now, we are ready to create a MultiIndex object using pandas\n\nindex = pd.MultiIndex.from_arrays([top_h2, low_h])\nindex[: 5]","03482f7c":"## we then drop the first row of the data frame (this will be replaced by the sub-headers) and assign the MultiIndex\n## object as the columns\n\ndf.drop(0, axis = 0, inplace = True)\ndf.columns = index\ndf.head()","d825a355":"## to make slicing possible, columns on both level have to be lexsorted\n\ncols = list(df.columns)\ncols.sort(key = lambda x: x[1])\ncols.sort()\ncols[: 5]","3f7b86b8":"df = df[cols]\ndf.head()","018fed2f":"## first, we define an IndexSlice object that makes navigation between columns possible.\n\ndef binaray(df, cols, idx = pd.IndexSlice):\n    '''binary ray: takes a data frame and a list of column names to binarise\n    - df: pandas.DataFrame with double column headers\n    - cols: list of super-header column names or string of a single column name\n    - idx: pandas.IndexSlice object'''\n    if type(cols) == str:\n        ## if its only a single column name, we create a list from it\n        cols = [cols]\n    if not (set(cols) <= set(df.columns.levels[0])):\n        ## making sure that all columns specified are in the columns actually \u2013 this is to prevent running the code\n        ## twice on the same column, causing it to make all values 1\n        return 'error: some column names were specified incorrectly'\n    for c in cols:\n        ## looping through the sub-headers and replacing null values with 0 and other by 1\n        for i in df[c].columns:\n            n_val = np.where(df[c][i].isnull(), 0, 1)\n            df.loc[:, idx[c, i]] = n_val\n    return df","f96d2e3c":"## creating a list of all columns that need to be binarised\n\nbinary_list = []\n\nfor i in df.columns.levels[0]:\n    uniques = True\n    for j in df[i].columns:\n        if len(df[i][j].unique()) != 2:\n            uniques = False\n    if uniques:\n        binary_list.append(i)","6c3e729a":"## then binarising them\n\nbinaray(df, binary_list)\ndf.head()","8fcfa397":"## looking at the distribution of the time it took for respondentss, we decided that 5 minutes to 2 hrs was a\n## reasonable limit to cut respondents\n\nf, ax = plt.subplots(figsize=(15, 6))\nax.set_xscale(\"log\")\n\nsns.distplot(df.q0_duration.duration.astype('int') \/ 60)\nplt.show()","1e1b6af5":"df_fil = df.loc[(df.q0_duration.duration.astype('int') >= 300) & (df.q0_duration.duration.astype('int') <= 7200), :].copy()\n","75eb061b":"## we also replace some of the values in the age and education columns, to make the analysis neater\n\ndf_fil[('q1_age', 'age')] = df_fil.q1_age.age.replace(['60-69', '70+'], '60+')\ndf_fil[('q4_education', 'education')] = (df_fil.q4_education.education\n                                         .replace(['Doctoral degree', 'Professional doctorate'], 'PhD'))\ndf_fil[('q4_education', 'education')] = (df_fil.q4_education.education\n                                         .replace('Some college\/university study without earning a bachelor\u2019s degree',\n                                                  'College\/university study without Bachelor\u2019s'))\ndf_fil[('q4_education', 'education')] = (df_fil.q4_education.education\n                                         .replace('I prefer not to answer', 'Prefer not to answer'))\n","ab27ac70":"## grouping of titles\n\nd_title = {'Data Scientist': 'Data Scientist', 'Machine Learning Engineer': 'Data Scientist',\n           'Data Engineer': 'Data Scientist', 'Data Analyst': 'Data Scientist', 'Software Engineer': 'Developer',\n           'DBA\/Database Engineer': 'Developer', 'Statistician': 'Other Data Role',\n           'Program\/Project Manager': 'Other Data Role', 'Research Scientist': 'Other Data Role',\n           'Business Analyst': 'Other Data Role', 'Product Manager': 'Other Data Role',\n           'Developer Relations\/Advocacy': 'Other Data Role', 'Student': 'Student\/Not Employed',\n           'Currently not employed': 'Student\/Not Employed', 'Other': 'Other'}\n\n## putting students and not employed separately\n\nd_title2 = {'Data Scientist': 'Data Scientist', 'Machine Learning Engineer': 'Data Scientist',\n           'Data Engineer': 'Data Scientist', 'Data Analyst': 'Data Scientist', 'Software Engineer': 'Developer',\n           'DBA\/Database Engineer': 'Developer', 'Statistician': 'Other Data Role',\n           'Program\/Project Manager': 'Other Data Role', 'Research Scientist': 'Other Data Role',\n           'Business Analyst': 'Other Data Role', 'Product Manager': 'Other Data Role',\n           'Developer Relations\/Advocacy': 'Other Data Role', 'Student': 'Student',\n           'Currently not employed': 'Not Employed', 'Other': 'Other'}","f8452642":"df_fil[('r01_title', 'title')] = df_fil.q5_title.title.map(d_title)\ndf_fil[('r01_title', 'title_sep')] = df_fil.q5_title.title.map(d_title2)\ndf_fil.head()","792c36ad":"## we also created different segments of survey respondents, such as people in data science related roles:\n\ndf_ds = df_fil[df_fil.r01_title.title == 'Data Scientist']\ndf_ds = df_ds[df_ds.q6_yrs_of_experience.yrs_of_experience != 'I have never written code']\n\n## jobseekers\n\ndf_js = df_fil[df_fil.r01_title.title == 'Student\/Not Employed'].copy()","a9e91f84":"## creating a pivot table for a stacked barchart visualisation:\n\nst_role = (df_fil.groupby([('r01_title', 'title'), ('q5_title', 'title')]).count()\n           .pivot_table([('q0_duration', 'duration')], [('r01_title', 'title')], [('q5_title', 'title')]).fillna(0)\n           .reindex(['Other', 'Developer', 'Other Data Role','Student\/Not Employed', 'Data Scientist'], copy = True))\n## renaming columns, which have tuple names, due to pivoting a multi-header set\nst_role.columns = [i[2] for i in st_role.columns]","c6c68fb0":"fig, ax = plt.subplots(1, figsize=(12, 10))\n\ncolors = ['mediumorchid', 'darkgreen', 'yellow', 'paleturquoise', 'teal', 'cornflowerblue', 'maroon',\n          'midnightblue', 'grey', 'violet', 'lightpink', 'crimson', 'darkorange', 'peachpuff', 'palegreen']\nbottom = np.zeros(len(st_role))\n\nfor i, col in enumerate(st_role.columns):\n    ax.bar(st_role.index, st_role[col], bottom = bottom, label = col, color = colors[i])\n    bottom += np.array(st_role[col])\n\ntotals = st_role.sum(axis=1)\n\n# Set an offset that is used to bump the label up a bit above the bar.\ny_offset = 4\n# Add labels to each bar.\nfor i, total in enumerate(totals):\n    ax.text(totals.index[i], total + y_offset, round(total), ha='center',\n          weight = 'bold')\n        \n# for s in ['top', 'left', 'right']:\n#     ax.spines[s].set_visible(False)\nax.set_xticklabels(st_role.index, fontfamily = 'serif')\n# ax.set_yticklabels(np.arange(0, 4001, 500),fontfamily='serif')\nfig.text(0.1, 0.95, 'Roles', fontsize = 15, fontweight = 'bold', fontfamily = 'serif')    \nax.grid(axis = 'y', linestyle = '-', alpha = 0.4)    \nax.set_title('Total Job Roles')\nax.legend(bbox_to_anchor = (1, 1))\nplt.xticks(rotation = 45,\n           horizontalalignment = 'right',\n           fontweight ='normal',\n           fontfamily = 'sans-serif')\nax.set_ylim([0, 7500])\n\n\nplt.show()","44b6c55d":"agedict = {'18-21': '18-21','22-24': '22-24','25-29': '25-29','30-34': '30:34'}\nfor i in df_js[('q1_age', 'age')].unique():\n    if i not in agedict:\n        agedict[i] = '35+'\n\ndf_js[('r02_age', 'age')] = df_js[('q1_age', 'age')].map(agedict)\n\n\ngenddict = {'Man':'Male','Woman':'Female'}\nfor i in df_js[('q2_gender', 'gender')].unique():\n    if i not in genddict:\n        genddict[i] = 'Other'\n\ndf_js[('r03_gender', 'gender')] = df_js[('q2_gender', 'gender')].map(genddict)","17ce54fb":"sj_age = df_js.r02_age.age.value_counts()\nlabels_age = ['18-21','22-24','25-29','30-34','35+']\ncolors_age = ['darkgreen', 'green', 'darkgrey', 'darkgrey', 'darkgrey']\n\nsj_gender = df_js.r03_gender.gender.value_counts()\nlabels_gender = ['Male','Female','Other']\ncolors_gender = ['darkgreen', 'orange', 'darkgrey']\n\nlabels_edu = df_js.q4_education.education.value_counts().index\ncolors_edu = ['darkgreen', 'green', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey']\n\n\nplt.figure(figsize = (15, 15))\n\nplt.subplot(2, 2, 1)\nplt.pie(x = sj_age, labels = labels_age, autopct='%.0f%%', colors = colors_age)\nplt.title('Age Breakdown of Students and Those Who are Unemployed', fontsize = 14)\n\nplt.subplot(2, 2, 2)\nplt.pie(x = sj_gender, labels = labels_gender, colors = colors_gender, autopct = '%.0f%%')\nplt.title('Gender Breakdown of Students and Those Who are Unemployed', fontsize = 14)\n\nplt.subplot(2, 2, 4)\nplt.pie(x = df_js.q4_education.education.value_counts(), labels = labels_edu, autopct = '%.0f%%', colors = colors_edu)\nplt.title('Education Level of Students and Those Who are Unemployed', fontsize = 14)\n\nax = plt.axes([0.1, 0.1, 0.3, 0.3])\nax.text(0.1, 0.5, 'AGE:\\nLargest Group: 18-21\\nSmallest Group: 35+\\n\\n\\n\\nGENDER:\\nMale: 75%\\nFemale: 23%\\n\\n\\n\\nEDUCATION:\\nLargest Groups: Bachelor\\'s and Master\\'s Degrees',\n        fontsize = 14)\nax.axis('off')\n\nplt.show()\n","09bb9777":"labels_lan = pd.Series(df_js.q7_language.sum().sort_values(ascending = False).index).replace('cpp', 'c++')\ncolors_lan = ['darkgreen', 'green', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey',\n          'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey']\n\nlabels_exp = pd.Series(df_js.q6_yrs_of_experience.yrs_of_experience.value_counts().index)\nlabels_exp[6] = 'No Experience'\ncolors_exp = ['darkgreen', 'green', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey', 'darkgrey']\n\n\nplt.figure(figsize = (15, 15))\n\n\nax1 = plt.axes([0.0, 0.6, 0.7, 0.4])\nax2 = plt.axes([0.3, 0.1, 0.7, 0.4])\nax3 = plt.axes([0.72, 0.6, 0.3, 0.4])\nax4 = plt.axes([0.0, 0.1, 0.3, 0.4])\n\nax1.bar(labels_lan, df_js.q7_language.sum().sort_values(ascending = False), color = colors_lan)\nplt.ylabel('Number of Occurences')\nplt.xlabel('')\nplt.xticks(rotation=45)\n\nax2.bar(labels_exp, df_js.q6_yrs_of_experience.yrs_of_experience.value_counts(), color = colors_exp)\nplt.ylabel('Number of Occurences')\n\nax3.text(0.0, 0.75, 'This was a \\'Select All Which Apply\\' question\\nand so respondents could select as many\\nlanguages as they knew. In this group we\\ncan see that the top languages known are\\nPython + SQL. These were also the top\\nlanguages in combination of any.',\n        fontsize = 12)\nax3.set_title('LANGUAGES KNOWN', loc = 'left', fontsize = 16)\nax3.axis('off')\n\nax4.text(0.0, 0.85, 'The majority of students\/unemployed have been\\ncoding for around 1-3 years. This may be due\\nto them taking a STEM degree.',\n         fontsize = 12)\nax4.set_title('CODING EXPERIENCE IN YEARS', loc = 'left', fontsize = 16)\nax4.axis('off')\n\nplt.show()","f7673837":"plt.figure(figsize = (15, 8))\n\nax1 = plt.axes([0.0, 0.0, 0.35, 1.0])\nax2 = plt.axes([0.4, 0.0, 0.35, 1.0], sharey = ax1)\nax3 = plt.axes([0.8, 0.0, 0.2, 1.0])\nax3.axis('off')\n\nx_ax1 = [i.replace('_', ' ').title() for i in df_js.q40_ds_course.sum().sort_values(ascending = False).index]\n\nsns.barplot(x = x_ax1,\n            y = df_js.q40_ds_course.sum().sort_values(ascending = False),\n            palette = 'Greens',\n            ax = ax1)\n\nax1.set_xlabel('Top Used Course Platforms for Students\/Not Employed', fontsize = '14', fontweight = 'bold')\nax1.set_ylabel('Count', fontsize = '14', fontweight = 'bold')\nax1.set_xticklabels(labels = x_ax1, rotation = 40, fontfamily = 'sans-serif', ha = 'right')\n\n\nx_ax2 = [i.replace('_', ' ').title() for i in df_ds.q40_ds_course.sum().sort_values(ascending = False).index]\n\nsns.barplot(x = x_ax2,\n            y = df_ds.q40_ds_course.sum().sort_values(ascending = False),\n            palette = \"Blues\",\n            ax = ax2)\n\nax2.set_xlabel('Top Used Course Platforms for Data Scientists', fontsize = '14', fontweight = 'bold')\nax2.set_xticklabels(labels = x_ax2, rotation = 40, fontfamily = 'sans-serif', ha = 'right')\n\n\nax3.text(0.0, 0.5,\n         'JOBSEEKERS:\\n8,790 respondents\\n3 courses taken on average\\n\\n\\n\\nDATA SCIENTISTS:\\n6,969 respondents\\n2 courses taken on average\\n\\n\\n\\nData Scientists use Coursera\\nmore often, whilst Students\\nuse Kaggle Learn Courses\\nmore.',\n         fontsize = 14)\nax3.set_title('Online Courses Taken by\\nJobseekers and Data Scientists', fontsize = 16, loc = 'left')\n\nplt.show()\n","d9a46cd7":"## creating age groups for visualisation\n\nage_gr = df_fil.groupby([('r01_title', 'title_sep'), ('q1_age', 'age')]).size().unstack(level = -1).reset_index()\nage_gr = age_gr.transpose()\nage_gr = age_gr.rename(columns = age_gr.iloc[0])\nage_gr = age_gr.drop(age_gr.index[0])","5f7300e0":"fields = ['Data Scientist', 'Student', 'Not Employed', 'Developer', 'Other Data Role', 'Other']\ncolors = ['cornflowerblue', 'forestgreen', '#94C973', 'grey', '#AEAEAE', 'lightgrey', 'cadetblue']\nlabels = ['Data Scientist', 'Student', 'Not Employed', 'Developer', 'Other Data Role', 'Other']\n\n\nfig, ax = plt.subplots(1, figsize=(12, 10))\n\nleft = len(age_gr) * [0]\nfor idx, name in enumerate(fields):\n    plt.barh(age_gr.index, age_gr[name], left = left, color = colors[idx])\n    left = left + age_gr[name]\n\nplt.title('Age Split by Role', loc = 'left')\nplt.legend(labels, bbox_to_anchor = ([1, 1, 0, 0]), ncol = 4, frameon = False, loc = 2, prop = {'size': 10})\nplt.xlabel('Number of Survey Respondents')\n\n# remove spines\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\n\n# adjust limits and draw grid lines\nplt.ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax.set_axisbelow(True)\nax.xaxis.grid(color = 'gray', linestyle = 'dashed')\n\n\nplt.show()","ef3c3ac4":"## preparing data for the horizontal bar chart\n\ngr2 = (df_fil.groupby([('q5_title', 'title'), ('q2_gender', 'gender')]).size().unstack(level=-1).reset_index())\ngr2 = gr2.fillna(0)\ngr2 = gr2.transpose()\ngr2 = gr2.rename(columns = gr2.iloc[0])\ngr2 = gr2.drop(gr2.index[0])\ncols = gr2.columns  \ngr2[cols] = round(gr2[cols] \/ (gr2[cols].sum())*100, 2)\ngr2 = gr2.reindex(index = ['Man','Woman','Nonbinary', 'Prefer to self-describe', 'Prefer not to say'])\ngr2 = gr2.transpose()\ngr2 = gr2.sort_values(by = ['Woman'], ascending=False)","1a325ab6":"pie_colors = [\"lightblue\", \"#7393B3\", \"lightgrey\", \"darkgrey\", \"Navy\"]\n\ngr2_fields = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\ngr2_colors = [\"Navy\", \"lightblue\", \"#7393B3\", \"darkgrey\", \"lightgrey\"]\ngr2_labels = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\n\n\nplt.figure(figsize = (15, 15))\n\nax1 = plt.axes([0.0, 0.6, 0.4, 0.4])\nax1.axis('off')\nax2 = plt.axes([0.0, 0.0, 0.8, 0.5])\nax3 = plt.axes([0.45, 0.65, 0.55, 0.35])\nax3.set_xticks([])\nax3.set_yticks([])\n\n## ax1\nax1.pie(df_ds.groupby([('q2_gender', 'gender')]).count().iloc[:, 0], autopct = '%1.1f%%', colors = pie_colors)\nax1.legend(labels = df_ds.groupby([('q2_gender', 'gender')]).count().iloc[:, 0].index)\n\n## ax2\nleft = len(gr2) * [0]\nfor idx, name in enumerate(gr2_fields):\n    ax2.barh(gr2.index, gr2[name], left = left, color = gr2_colors[idx])\n    left = left + gr2[name]\n# title, legend, labels\nax2.set_title('Percentage Split of Roles by Gender', loc = 'left')\nax2.legend(labels, bbox_to_anchor = ([1, 1, 0, 0]), ncol = 1, frameon = False, loc = 2, prop = {'size': 10})\nax2.set_xlabel('Percentage of Survey Respondents')\n# remove spines\nax2.spines['right'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax2.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax2.set_axisbelow(True)\nax2.xaxis.grid(color = 'gray', linestyle = 'dashed')\n\n\n#ax3.text(0.05, 0.1, 'Roles with highest proportion of women\\nare Student, Not Employed and Data\\nAnalyst. Such positions are often\\nassociated with Entry level roles and, in\\ncorrelation, little to no pay.\\nRoles with lowest proportion of women\\nare Managerial positions\\n(Program\/Project Manager and Product\\nManager) and Engineering roles\\n(DBA\/Database Engineer and Machine\\nLearning Engineer): Financially and\\nhierarchically superior to the latter.\\nThere is a need for greater diversity\\nwith respect to gender. ')\n\nax3.text(0.05, 0.1, 'Students\/Unemployed: 23% Females and 75% Males\\nData Science: 16.9% Females and 81.3% Males\\n\\n\\n - Tech roles are still very much dominated by men.\\n - Roles with highest proportion of women are Student, Not Employed and\\n   Data Analyst. Such positions are often associated with Entry level roles\\n   and, in correlation, little to no pay.\\n - Roles with lowest proportion of women are Managerial positions\\n   (Program\/Project Manager and Product Manager) and Engineering roles\\n   (DBA\/Database Engineer and Machine Learning Engineer): Financially and\\n   hierarchically superior to the latter.\\n - There is a need for greater diversity with respect to gender.\\n\\n - Limited data on proportion of the population that is non-binary, but a 2021\\n   study states 0.36% of the US population openly identifies as non-binary.\\n - Based on this alone, the proportion of Non-binary individuals in Data Science\\n   is in line with population expectations.',\n         fontsize = 14)\n\nplt.show()\n","5a105307":"## preparing data for stacked bar charts\n\ngen_role_percent = (df_fil.groupby([('q4_education', 'education'), ('q2_gender', 'gender')])\n                    .size().unstack(level = -1).reset_index())\ngen_role_percent = gen_role_percent.fillna(0)\ncols = ['Man', 'Woman', 'Nonbinary', 'Prefer not to say', 'Prefer to self-describe']   \ngen_role_percent[cols] = round(gen_role_percent[cols] \/ (gen_role_percent[cols].sum())*100, 2)\ngen_role_percent = gen_role_percent.transpose()\ngen_role_percent = gen_role_percent.rename(columns=gen_role_percent.iloc[0])\ngen_role_percent = gen_role_percent.drop(gen_role_percent.index[0])\n\n\nedu_gen = (df_ds.groupby([('q4_education', 'education'), ('q2_gender', 'gender')])\n           .size().unstack(level=-1).reset_index())","f615ddb3":"perc_fields = ['Bachelor\u2019s degree', 'College\/university study without Bachelor\u2019s', 'Master\u2019s degree',\n               'No formal education past high school', 'PhD', 'Prefer not to answer']\nperc_colors = [\"#6495ED\", \"#89CFF0\", \"#3F00FF\", '#F0FFFF', \"midnightblue\", \"grey\"]\nperc_labels = ['Bachelor\u2019s degree', 'College\/university study without Bachelor\u2019s', 'Master\u2019s degree',\n               'No formal education past high school', 'PhD', 'Prefer not to answer']\n\n\nfields = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\ncolors = [\"Navy\", \"lightblue\", \"#7393B3\", \"darkgrey\", \"lightgrey\"]\nlabels = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\n\n\nplt.figure(figsize = (15, 6))\n\nax1 = plt.axes([0.0, 0.0, 0.45, 1.0])\nax2 = plt.axes([0.55, 0.0, 0.45, 1.0])\n\n\n## ax1\n\nleft = len(gen_role_percent) * [0]\nfor idx, name in enumerate(perc_fields):\n    ax1.barh(gen_role_percent.index, gen_role_percent[name], left = left, color = perc_colors[idx])\n    left = left + gen_role_percent[name]\n\nax1.set_title('Percentage Split of Genders by Education', loc='left')\nax1.legend(perc_labels, ncol = 1, frameon = True, loc = 'upper right', prop = {'size': 10})\nax1.set_xlabel('Percentage of Survey Respondents')\nax1.set_yticklabels(['Woman', 'Prefer to\\nself-describe', 'Prefer not\\nto say', 'Non-binary', 'Man'], rotation = 40)\n# remove spines\nax1.spines['right'].set_visible(False)\nax1.spines['left'].set_visible(False)\nax1.spines['top'].set_visible(False)\nax1.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax1.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax1.set_axisbelow(True)\nax1.xaxis.grid(color = 'gray', linestyle = 'dashed')\n\n\n## ax2\n\nleft = len(edu_gen) * [0]\nfor idx, name in enumerate(fields):\n    plt.barh(edu_gen[('q4_education', 'education')], edu_gen[name], left = left, color=colors[idx])\n    left = left + edu_gen[name]\n\nax2.set_title('Education Split by Gender', loc = 'left')\nax2.legend(labels, ncol = 1, frameon = True, loc = 'upper right', prop = {'size': 10})\nax2.set_xlabel('Number of Survey Respondents')\nax2.set_yticklabels(['Prefer not\\nto answer', 'PhD', 'No formal\\neducation\\npast high school', 'Master\\'s\\ndegree',\n                     'College\/university\\nwihtout degree', 'Bachelor\\'s\\ndegree'], rotation = 40)\n# remove spines\nax2.spines['right'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax2.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax2.set_axisbelow(True)\nax2.xaxis.grid(color = 'gray', linestyle = 'dashed')\n\n\nplt.show()","df042b01":"## preparing data for horizontal bar charts\n\nage_gen = df_ds.groupby([('q2_gender', 'gender'), ('q1_age', 'age')]).size().unstack(level=-1).reset_index()\nage_gen = age_gen.transpose()\nage_gen = age_gen.rename(columns = age_gen.iloc[0])\nage_gen = age_gen.drop(age_gen.index[0])\n\nstu_gen = (df_js[df_js.r01_title.title == 'Student\/Not Employed']\n           .groupby([('q2_gender', 'gender'), ('q1_age', 'age')]).size().unstack(level=-1).reset_index())\nstu_gen = stu_gen.transpose()\nstu_gen = stu_gen.rename(columns=stu_gen.iloc[0])\nstu_gen = stu_gen.drop(stu_gen.index[0])","767afbbf":"stu_fields = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\nstu_colors = ['darkgreen', '#76B947', '#B2D2A4', 'darkgrey', 'lightgrey']\nstu_labels = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\n\nage_fields = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\nage_colors = ['Navy', 'lightblue', '#7393B3', 'darkgrey', 'lightgrey']\nage_labels = ['Woman', 'Man', 'Nonbinary', 'Prefer to self-describe', 'Prefer not to say']\n\n\nplt.figure(figsize = (15, 6))\n\nax1 = plt.axes([0.0, 0.0, 0.45, 1.0])\nax2 = plt.axes([0.55, 0.0, 0.45, 1.0])\n\n\n## ax1\n\nleft = len(stu_gen) * [0]\nfor idx, name in enumerate(stu_fields):\n    ax1.barh(stu_gen.index, stu_gen[name], left = left, color = stu_colors[idx])\n    left = left + stu_gen[name]\n\nax1.set_title('Split of Age Groupings of Students\/Not Employed by Gender', loc='left')\nax1.legend(stu_labels, ncol = 1, frameon = True, loc = 'upper right', prop = {'size': 10})\nax1.set_xlabel('Number of Survey Respondents')\n# remove spines\nax1.spines['right'].set_visible(False)\nax1.spines['left'].set_visible(False)\nax1.spines['top'].set_visible(False)\nax1.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax1.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax1.set_axisbelow(True)\nax1.xaxis.grid(color='gray', linestyle='dashed')\n\n\n## ax2\n\nleft = len(age_gen) * [0]\nfor idx, name in enumerate(age_fields):\n    ax2.barh(age_gen.index, age_gen[name], left = left, color = age_colors[idx])\n    left = left + age_gen[name]\n\nax2.set_title('Split of Age Groupings of Data Scientists by Gender', loc = 'left')\nax2.legend(age_labels, ncol = 1, frameon = True, loc = 'upper right', prop = {'size': 10})\nax2.set_xlabel('Number of Survey Respondents')\n# remove spines\nax2.spines['right'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax2.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax2.set_axisbelow(True)\nax2.xaxis.grid(color = 'gray', linestyle = 'dashed')\n\n\nplt.show()","aeffa62d":"## preparing data for horizontal bar chart and pie chart\n\ngen_role_percent = (df_fil.groupby([('q4_education', 'education'), ('q2_gender', 'gender')])\n                    .size().unstack(level = -1).reset_index())\ngen_role_percent = gen_role_percent.fillna(0)\ncols = ['Man', 'Woman', 'Nonbinary', 'Prefer not to say', 'Prefer to self-describe']   \ngen_role_percent[cols] = round(gen_role_percent[cols] \/ (gen_role_percent[cols].sum())*100, 2)\ngen_role_percent = gen_role_percent.transpose()\ngen_role_percent = gen_role_percent.rename(columns=gen_role_percent.iloc[0])\ngen_role_percent = gen_role_percent.drop(gen_role_percent.index[0])\n\n\nedu_pie = (df_fil.groupby([('r01_title', 'title_sep'), ('q4_education', 'education')])\n           .size().unstack(level = -1).reset_index())\nedu_pie = edu_pie.loc[edu_pie[('r01_title', 'title_sep')] == 'Data Scientist'].copy()\nedu_pie = edu_pie.transpose()\nedu_pie = edu_pie.rename(columns = edu_pie.iloc[0])\nedu_pie = edu_pie.drop(edu_pie.index[0])\nedu_pie = edu_pie.sort_values('Data Scientist')","b3c2a739":"bar_fields = ['Bachelor\u2019s degree', 'College\/university study without Bachelor\u2019s', 'Master\u2019s degree',\n          'No formal education past high school', 'PhD', 'Prefer not to answer']\nbar_colors = [\"#6495ED\", \"#89CFF0\", \"#3F00FF\", '#F0FFFF', \"midnightblue\", \"grey\"]\nbar_labels = ['Bachelor\u2019s degree', 'College\/university study without Bachelor\u2019s', 'Master\u2019s degree',\n          'No formal education past high school', 'PhD', 'Prefer not to answer']\n\npie_colors = [\"#F0FFFF\", \"grey\", \"#89CFF0\", 'midnightblue', \"#6495ED\", \"#3F00FF\"]\n\n\nplt.figure(figsize = (15, 6))\n\nax1 = plt.axes([0.0, 0.0, 0.45, 1.0])\nax2 = plt.axes([0.55, 0.0, 0.45, 1.0])\n\n\n## ax1\n\nleft = len(gen_role_percent) * [0]\nfor idx, name in enumerate(bar_fields):\n    ax1.barh(gen_role_percent.index, gen_role_percent[name], left = left, color = bar_colors[idx])\n    left = left + gen_role_percent[name]\n# title, legend, labels\nax1.set_title('Percentage Split of Genders by Education', loc = 'left')\nax1.legend(bar_labels, ncol = 1, frameon = True, loc = 'upper right', prop={'size': 10})\nax1.set_xlabel('Percentage of Survey Respondents')\n# remove spines\nax1.spines['right'].set_visible(False)\nax1.spines['left'].set_visible(False)\nax1.spines['top'].set_visible(False)\nax1.spines['bottom'].set_visible(False)\n# adjust limits and draw grid lines\nax1.set_ylim(-0.5, ax.get_yticks()[-1] + 0.5)\nax1.set_axisbelow(True)\nax1.xaxis.grid(color = 'gray', linestyle='dashed')\n\n\n## ax2\n\nax2.pie(edu_pie['Data Scientist'].values, autopct = '%1.1f%%', colors = pie_colors)\nax2.legend(labels = edu_pie.index)\n\n\nplt.show()","18ce6297":"## preparing data for bar charts\n\nrole_course = df_fil[['r01_title', 'q7_language']]\nrole_course = role_course.drop(columns = {('r01_title', 'title_sep'), ('q7_language', 'none')})\nrole_course = role_course.groupby(('r01_title', 'title')).sum()\nlang_filt = role_course.drop(['Developer', 'Other', 'Other Data Role'])\nlang_filt = lang_filt.transpose().reset_index()\nlang_filt.drop(columns = 'level_0', inplace = True)\n\ndf_lan = pd.melt(lang_filt, id_vars = ['level_1'], var_name = 'Role', value_name = 'Value')\ndf_lan = df_lan.sort_values(['Role', 'Value'], ascending = False)\ndf_lan.level_1 = df_lan.level_1.replace('cpp', 'c++')","8faecc64":"plt.figure(figsize = (10, 6))\nsns.barplot(x = 'level_1', y = \"Value\", hue = 'Role', data = df_lan, palette = ['green', 'cornflowerblue'])\nplt.xticks(rotation = 45,\n           horizontalalignment = 'right',\n           fontweight = 'normal',\n           fontsize = 'large',\n           fontfamily = 'sans-serif')\nplt.ylabel(\"Count of Survey Respondents\", size = 14)\nplt.xlabel(\"Language\", size = 14)\nplt.title(\"Popular Languages amongst Data Scientists and Students\/Not Employed\", size = 16)\n\nplt.show()","19df5acf":"## for this, we defined a function to select popular combinations\n\ndef combo_01(df, column, num):\n    '''function that takes a multiheaded binary frame and checks for the count of unique combinations.\n    \n    df: data frame\n    column: name of super header (str)\n    num: the number of elements in each unique combination (int)\n    \n    returns a dictionary where the key is the combination and values are the counts.'''\n    row_matrix = []\n    for i in range(len(df)):\n        # we create a binary string indicating whether the given language is known or not\n        row_matrix.append(''.join([str(j) for j in df[column].iloc[i, :]]))\n    \n    # we retain the base ten value of each laguage based on their position in the frame. python, for example is fourth\n    # from the right, therefore its binary representation is 1000, so in base ten its 8\n    d_val = {}\n    for i in range(len(df[column].columns)):\n        d_val[df[column].columns[i]] = 2 ** (len(df[column].columns) - 1 - i)\n    \n    d_comb = {}\n    for i in combinations(df[column].columns, num):\n        com = 0\n        val = 0\n        # using our dictionary of language values, we create a sum of the combination of languages. we will use this\n        # to compare each row's binary represenation and see if it matches a combination\n        for j in range(len(i)):\n            com += d_val[i[j]]\n        # we are looking through our binary strings based on each row\n        for k in range(len(row_matrix)):\n            # we use binary operators to see if a row satisfies our criteria\n            if (int(row_matrix[k], 2) & com) == com:\n                # if it does, we add a value to that combination\n                val += 1\n            else:\n                continue\n        # finally, we update our dictionary of combinations and their values\n        d_comb['-'.join(i)] = val\n    \n    return d_comb","c805c49c":"## for more flexible comparison, we also created rookie and experienced data scientists (based on years of experience)\n## as well as a successful data scientist category (based on salary)\n\ndf_roo = df_ds[[(x in ['1-3 years', '< 1 years']) for x in df_ds.q6_yrs_of_experience.yrs_of_experience]]\ndf_exp = df_ds[[not (x in ['1-3 years', '< 1 years']) for x in df_ds.q6_yrs_of_experience.yrs_of_experience]]\ndf_suc = df_ds[[(x in ['100,000-124,999''125,000-149,999', '200,000-249,999', '150,000-199,999', '300,000-499,999',\n                       '250,000-299,999', '$500,000-999,999', '>$1,000,000']) for x in df_ds.q25_salary.salary]]","b65303bc":"## preparing data for dumbbell plot\n\nlan_roo = pd.Series(combo_01(df_roo, 'q7_language', 2)) \/ len(df_roo) * 100\nlan_exp = pd.Series(combo_01(df_exp, 'q7_language', 2)) \/ len(df_roo) * 100\nlan_js = pd.Series(combo_01(df_js, 'q7_language', 2)) \/ len(df_js) * 100\n\nlan_roo = lan_roo[[('python' in i) for i in lan_roo.index]].copy()\nlan_exp = lan_exp[[('python' in i) for i in lan_exp.index]].copy()\nlan_js = lan_js[[('python' in i) for i in lan_js.index]].copy()\n\ndf_lan = lan_roo.to_frame().join(lan_exp.to_frame(), rsuffix = '_e').join(lan_js.to_frame(), rsuffix = '_su')\ndf_lan.columns = ['rookies', 'exp', 'js']\ndf_lan = df_lan.sort_values(by = 'js', ascending = False).iloc[: 10, :].copy()\ndf_lan.index = [i.replace('python', '').replace('-', '').replace('pp', '++') for i in df_lan.index]","12d7eb2f":"fig = plt.figure(figsize = (14, 6))\nax = fig.add_subplot(1, 1, 1)\n\n# Reorder df following the values of the first value:\ndf_lan = df_lan.sort_values(by = 'js')\nmy_range = range(1, len(df_lan.index) + 1)\n\n# The horizontal plot is made using the hline function\nplt.hlines(y = my_range, xmin = df_lan['js'], xmax = df_lan['rookies'], color = 'grey', alpha = 0.4)\nplt.scatter(df_lan['js'], my_range, color = 'forestgreen', alpha = 1, label = 'student \/ unemployed')\nplt.scatter(df_lan['rookies'], my_range, color = 'cornflowerblue', alpha = 0.4 , label = 'rookie data scientist')\nplt.scatter(df_lan['exp'], my_range, color = 'cadetblue', alpha = 0.4 ,\n            label = 'experienced data scientists', s = 120)\nplt.legend(loc = 'lower right')\n\n\n\n# Add title and axis names\nplt.yticks(my_range, df_lan.index)\nplt.title('Most Popular Languages Used in Combination with Python Amongst\\nStudents\/Unemployed, \"Rookie\"- and Succesful Data Scientists')\nplt.xlabel('Percentage of group regularly using the language')\nplt.ylabel('Languages')\n\nax.xaxis.set_major_formatter(mtick.PercentFormatter())\n\n\nplt.show()\n","9a16632a":"js_palette = sns.color_palette(\"Greens\", n_colors=12)\njs_palette.reverse()\njs_labels = [i.replace('_', ' ').title() for i in df_js.q17_ml_algorithm.sum().index]\n\nds_palette = sns.color_palette(\"Blues\", n_colors=12)\nds_palette.reverse()\nds_labels = [i.replace('_', ' ').title() for i in df_ds.q17_ml_algorithm.sum().index]\n\n# Segment explosions\nexplode = (0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05)\n\n\nplt.figure(figsize = (15, 8))\n\nplt.subplot(1, 2, 1)\nplt.pie(df_js.q17_ml_algorithm.sum(), colors = js_palette, labels = js_labels, explode = explode,\n        autopct='%1.1f%%', pctdistance=0.8)\n\n# Donut\n#draw circle\ncentre_circle = plt.Circle((0, 0), 0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.tight_layout()\n\n\n\n\nplt.subplot(1, 2, 2)\n\nplt.pie(df_ds.q17_ml_algorithm.sum(), colors = ds_palette, labels = ds_labels, explode = explode,\n        autopct = '%1.1f%%', pctdistance = 0.8)\n\n\ncentre_circle = plt.Circle((0,0),0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.tight_layout()\n\n\nplt.show()","ff387f25":"js_palette = sns.color_palette(\"Greens\", n_colors=12)\njs_palette.reverse()\njs_labels = [i.replace('_', ' ').title() for i in df_js.q16_ml.sum().index]\n\nds_palette = sns.color_palette(\"Blues\", n_colors=12)\nds_palette.reverse()\nds_labels = [i.replace('_', ' ').title() for i in df_ds.q16_ml.sum().index]\n\n# Segment explosions\nexplode = (0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05)\n\n\nplt.figure(figsize = (15, 8))\n\nplt.subplot(1, 2, 1)\nplt.pie(df_js.q16_ml.sum(), colors = js_palette, labels = js_labels, explode = explode,\n        autopct='%1.1f%%', pctdistance=0.8)\n\n# Donut\n#draw circle\ncentre_circle = plt.Circle((0, 0), 0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.tight_layout()\n\n\n\n\nplt.subplot(1, 2, 2)\n\nplt.pie(df_ds.q16_ml.sum(), colors = ds_palette, labels = ds_labels, explode = explode,\n        autopct = '%1.1f%%', pctdistance = 0.8)\n\n\ncentre_circle = plt.Circle((0,0),0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.tight_layout()\n\n\nplt.show()","80821e5a":"js_palette = sns.color_palette(\"Greens\", n_colors=12)\njs_palette.reverse()\njs_labels = [i.replace('_', ' ').title() for i in df_js.q14_viz.sum().index]\n\nds_palette = sns.color_palette(\"Blues\", n_colors=12)\nds_palette.reverse()\nds_labels = [i.replace('_', ' ').title() for i in df_ds.q14_viz.sum().index]\n\n# Segment explosions\nexplode = (0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05)\n\n\nplt.figure(figsize = (15, 8))\n\nplt.subplot(1, 2, 1)\nplt.pie(df_js.q14_viz.sum(), colors = js_palette, labels = js_labels, explode = explode,\n        autopct='%1.1f%%', pctdistance=0.8)\n\n# Donut\n#draw circle\ncentre_circle = plt.Circle((0, 0), 0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)  \nplt.tight_layout()\n\n\n\n\nplt.subplot(1, 2, 2)\n\nplt.pie(df_ds.q14_viz.sum(), colors = ds_palette, labels = ds_labels, explode = explode,\n        autopct = '%1.1f%%', pctdistance = 0.8)\n\n\ncentre_circle = plt.Circle((0,0),0.60,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.tight_layout()\n\n\nplt.show()","21a5d9ce":"## preparing data for bar chart\n\nind_datsci = df_ds.groupby([('q20_industry', 'industry')]).count()[('q0_duration', 'duration')].sort_values(ascending = False)\n","b6645d61":"plt.figure(figsize = (12, 6))\npalette = sns.color_palette(\"Blues\", n_colors = 20)\npalette.reverse()\n\nsns.barplot(x = ind_datsci.index,\n            y = ind_datsci.values,\n            palette = palette)\n\nplt.xlabel('Industries Data Scientists Work in',\n           fontsize = '15',\n           fontweight = 'bold')\n\nplt.ylabel('Count',\n           fontsize = '15',\n           fontweight = 'bold')\n\nplt.xticks(rotation = 45,\n           horizontalalignment = 'right',\n           fontweight = 'normal',\n           fontsize = 'large',\n           fontfamily = 'sans-serif')\n\nplt.show()","91fd1624":"## preparing data for dumbbell plot\n\nind = df_suc.q20_industry.industry.value_counts(normalize = True)[: 5].index\nind.append(df_roo.q20_industry.industry.value_counts(normalize = True)[: 5].index)\nind.append(df_exp.q20_industry.industry.value_counts(normalize = True)[: 5].index)\n\ndf_suc2 = df_suc[[(x in ind) for x in df_suc.q20_industry.industry]].copy()\ndf_roo2 = df_roo[[(x in ind) for x in df_roo.q20_industry.industry]].copy()\ndf_exp2 = df_exp[[(x in ind) for x in df_exp.q20_industry.industry]].copy()\n\nroo2 = df_roo2.q20_industry.industry.value_counts(normalize = True) * 100\nsuc2 = df_suc2.q20_industry.industry.value_counts(normalize = True) * 100\nexp2 = df_exp2.q20_industry.industry.value_counts(normalize = True) * 100\n\ndf_com2 = roo2.to_frame().join(suc2, rsuffix = '_s').join(exp2, rsuffix = '_e')\ndf_com2.columns = ['rookies', 'successful', 'exp']\ndf_com2['min'] = df_com2.min(axis = 1)","52004c2a":"fig = plt.figure(figsize = (12, 4))\nax = fig.add_subplot(1, 1, 1)\n\n# Reorder df following the values of the first value:\ndf_com2 = df_com2.sort_values(by = 'min', ascending = False)\nmy_range = range(1, len(df_com2.index) + 1)\n\n# The horizontal plot is made using the hline function\nplt.hlines(y = my_range, xmin = df_com2['rookies'], xmax = df_com2['exp'], color = 'grey', alpha = 0.4)\nplt.scatter(df_com2['rookies'], my_range, color = 'cornflowerblue', alpha = 1,\n            label = 'rookies')\nplt.scatter(df_com2['exp'], my_range, color = 'forestgreen', alpha = 0.4 ,\n            label = 'experienced')\nplt.scatter(df_com2['successful'], my_range, color = 'cadetblue', alpha = 0.4 ,\n            label = 'successful', s = 120)\nplt.legend()\n\n\n\n# Add title and axis names\nplt.yticks(my_range, df_com2.index)\nplt.title('Distribution of \"Rookie\" and Experienced\\nData Scientists per industries')\nplt.xlabel('Percentage of group per industry')\nplt.ylabel('Industry')\n\nax.xaxis.set_major_formatter(mtick.PercentFormatter())\n\n\nplt.show()","51663518":"df_ds.q21_company_size.value_counts()","56049e9c":"## preparing data for dumbbell plot\n\nroo = df_roo.q21_company_size.company_size.value_counts(normalize = True) * 100\nsuc = df_suc.q21_company_size.company_size.value_counts(normalize = True) * 100\nexp = df_exp.q21_company_size.company_size.value_counts(normalize = True) * 100\n\ndf_com = roo.to_frame().join(suc, rsuffix = '_s').join(exp, rsuffix = '_e')\ndf_com.columns = ['rookies', 'successful', 'exp']\ndf_com = df_com.reindex(['10,000 or more employees', '1000-9,999 employees', '250-999 employees', '50-249 employees',\n                         '0-49 employees'], copy = True)","04636841":"fig = plt.figure(figsize = (12, 4))\nax = fig.add_subplot(1, 1, 1)\n\n# Reorder df following the values of the first value:\n#df_com = df_com.sort_values(by = df_com.index)\nmy_range = range(1, len(df_com.index) + 1)\n\n# The horizontal plot is made using the hline function\nplt.hlines(y = my_range, xmin = df_com['rookies'], xmax = df_com['exp'], color = 'grey', alpha = 0.4)\nplt.scatter(df_com['rookies'], my_range, color = 'cornflowerblue', alpha = 1,\n            label = 'rookies')\nplt.scatter(df_com['exp'], my_range, color = 'forestgreen', alpha = 0.4 ,\n            label = 'experienced')\nplt.scatter(df_com['successful'], my_range, color = 'cadetblue', alpha = 0.4 ,\n            label = 'successful', s = 120)\nplt.legend()\n\n\n\n# Add title and axis names\nplt.yticks(my_range, df_com.index)\nplt.title('Distribution of \"Rookie\" and Experienced\\nData Scientists at Firms')\nplt.xlabel('Percentage of people at company')\nplt.ylabel('Company size')\n\nax.xaxis.set_major_formatter(mtick.PercentFormatter())\n\n\nplt.show()","7c74a365":"## preparing data for polar bar chart\n\nind_size = df_ds.groupby([('q20_industry', 'industry'), ('q21_company_size', 'company_size')]).count()[('q0_duration', 'duration')].to_frame()\nind_size.reset_index(level=(0, 1), inplace=True)\nind_size.columns = ['Industry', 'Company Size', 'count']","e718ff89":"fig = px.bar_polar(ind_size, r=\"count\", theta=\"Industry\",\n                   color=\"Company Size\", \n                   template=\"none\",\n                   color_discrete_sequence= px.colors.sequential.Teal)\n\nfig.show()","25ce35c6":"## Online courses","e6ba1e32":"#### Gender and education\n\nThe data supports the premise that women feel they need to be further educated to land a career.\n\nDespite the number of degrees being almost equal to male respondents, there are less women in Data Science.\n\nIn reality, a STEM background or post graduate degree is not a requirement for being a great Data Scientist.","86fb3dca":"#### Are more women getting into Data Science?\n\nFrom these graphs, we can see that a lot more women seem to decide to continue their studies, in comparison to men who seem to jump straight into a Data career between 18-21.\n\nIt is shocking that there were only male Data Scientists between the ages of 22-24.\n\nIt seems that a lot of women decide against education after 30.","6aed74c8":"#### Data Scientists:\nThe highest number of Data Scientists are within the 25-29 age bracket.\n<br><br>\n#### Jobseekers:\nStudents populate the lower age brackets, particularly 18-21.\n<br><br><br>\nA low number of individuals in the 18-21 age bracket are Data Scientists. This is likely because many people are pursuing higher education at these ages and may not necessarily be looking for a job as yet.\n<br>\nJobseekers should be encouraged by the range of ages in the field. One is never too young or too old to be a Data Scientist.","9d253f03":"There were 15 unique roles defined in the dataset. We split these into 5 major categories. For most of this book, we will focus on the two largest, Student\/Not Employed and the Data Scientist, categories.","29668e19":"The most popular industry for both seasoned and newbie data scientists is computers and technology.\n\n\nHowever, as employees gain experience, they seem to pursue their career in other areas.\n\n\nMost notable is the pharmaceutical industry where only 7% of career starters end up but takes almost 15% of successful data scientists.","f827c242":"# General Overview of Jobseekers","65d325c1":"#### Most popular ML frameworks\n\n\nScikit-Learn is most popular with very big or very small companies.\n\n\nTensorflow, Keras and Pytorch are most popular with company size 0-49.\n\n\nJobseekers can focus their studies on based on where they might like to work. Doing some research would be beneficial.","68e65579":"#### How to define a Data Scientist:\n\n\nData Scientist is still a relatively new role.\n\n\nThe following roles were chosen for this analysis:\n\n- Data Scientist\n\n- Data Analyst\n\n- Data Engineer\n\n- Machine Learning Engineer","fc7f65a3":"The next step is to create a binary representation of the multiple choice questions. Since indexing with double headers is somewhat tricky, a function to do this was created.","3d44b80d":"#### Education and role\n\nMajority of Data Scientists hold a Master's Degree, with 8.2% holding less than a Bachelor's.\n\nContrast, most students hold a Bachelor's degree. ","f6c6e47e":"#### Most popular visualisation tools\n\n\nMatplotlib and Seaborn are clear leaders for visualization which makes sense are they are relatively simple to use.\n\n\nTools like ploty should not be discounted as it has features which make it standout.\n\n\nggplot and ggplot2 tend to be more favourable among those who use the language R.","772f4acc":"-------- ","a3a87691":"#### Most popular machine learning algorithms\n\n\nJobseekers are interested in the same ML Algorithms as Data Scientists\n\n\nThis is great statistically but there is no right or wrong ML algorithm, jobseekers should consider what type of work they would like to do as this will dictate the oath they should take","66ee62bb":"#### Jobseekers now and beyond\n\n\nJobseekers should take heart that they are on the right track.\n\n\nThere is a need for diversity in the Data Science space. Persons who fall outside the norm should not be afraid to step forward.\n\n\nJobseekers sould focus their upskilling in the area they want to work and not just the popular things.\u200b\n\n\nWhile smaller companies might be more open to beginners, that doesn\u2019t mean that larger companies should not be given a chance.","88251d31":"# What can current Data Scientists tell aspiring Data Scientist?\n### Exploring the landscape of Kaggle Users ","ebc63dcb":"## Education level","e6c05bd8":"# General Overview of Roles","2d02ced2":"#### Company size and experience\n\nIt appears that smaller companies are more likely to employ data scientists with less than 3 years of experience.\n\n\nThe least ideal place for those early in their career is companies with 250-999 employees. They employed only 11% of these respondents.\n\n\nHowever, these companies also signify the turning point as these and larger organisations tend to employ a larger percentage of experienced data scientists.","a096cfe2":"## Conclusion","238d81bb":"The most common company size for Data Scientists to work in is 0-49 employees by far.\n\n\nThis is followed by large companies, particularly those of 10,000 employees or more.","29eaea32":"## Cleaning: Addressing headers","4a569268":"We hope our insights were useful for jobseekers out there and the data science community alike. We definitelt enjoyed working on it!","40969a2f":"## Languages","5fcba72b":"Python is the most popular language in both the jobseeker and data scientist groups. We wanted to see which other languages are most popularly combined with it.","c1210d8a":"#### Language popularity and experience\n\nThe proportion of jobseekers using Python (93%) is practically the same as people already in the industry.\n\nHowever, when it comes to using other languages in conjunction with Python, their numbers vary and in the case of SQL, significantly fall behind.\n\nJobseekers may want to consider exploring languages other than python. SQL, for example, would pair well with python because of its database management capabilities.","2c5cbe38":"The most common industry for Data Scientists to work in is Computers\/Technology.\n\n\nThis is followed by Academics\/Education and Accounting\/Finance.\n\n\nJobseekers should take note of the list of industries. Data Scientists are needed every where.","4cb0db25":"## Cleaning: Filtering and creating subsets","29378ecf":"## Imports","1b74d508":"#### Industry and company size\n\n\nThe largest Sector by far is Computers\/Technology, no matter the company size.\n\n\nWhen it comes to Academics\/Education and Accounting\/Finance, most Data Scientists tend to work in companies with 0-49 employees.","2cdc5c80":"## Age by role","86b34891":"The plan is to create a data frame with double headers. The top row would be the question number (with a short name) while the bottom row the question in short \/ possible answers where its a multiple choice type of question.","ee814ab2":"## Data science tools","aede1582":"Our team set out the aim of looking into what distinguishes jobseekers from those in the data science industry. We looked at differences in skills and experience as well as trends regarding education and gender.\n\n\nWe hope you will enjoy this notebook!\n\nAlice, Aron, Ellisha, Yasmin","4c988332":"## Gender diversity","3b6664ff":"## Company size","a60982e4":"## Industry","0fbac12a":"From this insight, we can see that continuous online learning is important to both of our key groups. Jobseekers on average have taken one further course than Data Scientists, potentially showing that they're slightly more eager to learn.","41a4e02d":"## Cleaning: Getting binary","577e1ff9":"# Jobseekers vs Data Scientists"}}