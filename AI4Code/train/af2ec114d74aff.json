{"cell_type":{"6469370a":"code","f502d21c":"code","79fa67f3":"code","9ac4253c":"code","315a4cbe":"code","51442d92":"code","ca30e95b":"code","f34b075f":"code","e5fb5d7c":"code","f8532a46":"code","8b460597":"code","1c786539":"code","7b4f4c6d":"code","d2384c9d":"code","d5d002ec":"code","8b304a72":"code","690e4999":"code","02e7fad6":"code","8de9cbcc":"code","01fdb50c":"code","63fde819":"code","22589cd7":"code","1293d617":"code","01327c21":"code","f9ee82fd":"code","a97d3e72":"code","ea4e8c70":"code","28d05fc7":"code","6d303955":"code","cc18881a":"code","6222865d":"code","af50d311":"code","b6908197":"code","48b708f8":"code","971c0e5e":"code","5a3854f8":"code","a016bd67":"code","01ab5971":"code","77d475ec":"code","f079fc37":"code","d06feb6c":"code","1c97d4b3":"code","7991fa0e":"code","ad24b2af":"code","469dfcb9":"code","0f99cd52":"code","2630df48":"code","882a8dcd":"code","94f216eb":"code","24aa8d15":"code","a4d0f031":"code","5c7cf971":"code","d3841f24":"code","24cea42b":"code","6a9e3564":"code","fb703df7":"code","94627e4c":"code","3a2b5436":"code","d2024ba6":"code","74379260":"code","a88648c3":"code","48800351":"code","4031989c":"code","9fc90fe1":"code","3ca4606c":"markdown","9fedaa2b":"markdown","5637629d":"markdown","96e4ffd7":"markdown","1ccacb29":"markdown","700fc889":"markdown","0ab66a7c":"markdown","5e996c4a":"markdown","3f53e841":"markdown","cf4283fe":"markdown","2c512046":"markdown","cec05c11":"markdown","0a9099ca":"markdown","16037b52":"markdown","d6adea0f":"markdown","ed8ac93b":"markdown","e245889a":"markdown","5c44aa91":"markdown","0b0d93b5":"markdown","e8e924ef":"markdown","741b80cc":"markdown","2bb9b62e":"markdown","29439bad":"markdown","7bc07bcd":"markdown","666ecf51":"markdown","bd555204":"markdown","b542041e":"markdown","c68dd693":"markdown","09c5492f":"markdown","292998ff":"markdown","e815181c":"markdown","36d40b64":"markdown","7a91e9d3":"markdown","1597eef2":"markdown","0d8bf858":"markdown","23510097":"markdown","c166ede5":"markdown","f2d33835":"markdown"},"source":{"6469370a":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom collections import Counter\nfrom wordcloud import WordCloud","f502d21c":"os.listdir('..\/input\/riiid-test-answer-prediction')","79fa67f3":"train_df = pd.read_csv('..\/input\/riiid-test-answer-prediction\/train.csv', nrows=1000000)\nlectures = pd.read_csv('..\/input\/riiid-test-answer-prediction\/lectures.csv')\nquestions = pd.read_csv('..\/input\/riiid-test-answer-prediction\/questions.csv')\nexample_test = pd.read_csv('..\/input\/riiid-test-answer-prediction\/example_test.csv')\nexample_sample_submission = pd.read_csv('..\/input\/riiid-test-answer-prediction\/example_sample_submission.csv')","9ac4253c":"example_sample_submission.head(2)","315a4cbe":"example_test.head(2)","51442d92":"train_df.head()","ca30e95b":"if len(train_df) == len(train_df.row_id.unique()):\n    print('row_id column is the key')","f34b075f":"print('total train samples ', len(train_df))","e5fb5d7c":"train_df.info()","f8532a46":"train_df.describe()","8b460597":"print(\"No of students = \", len(train_df['user_id'].unique()))","1c786539":"print(\"distribution of number of samples per student\")","7b4f4c6d":"sns.set()\nfig = plt.figure(figsize=(15,6))\nfig = sns.kdeplot(train_df.groupby(by='user_id').count()['row_id'], shade=True, gridsize=50, color='g', legend=False)\nfig.figure.suptitle(\"User_id distribution\", fontsize = 20)\nplt.xlabel('User_id counts', fontsize=16)\nplt.ylabel('Probability', fontsize=16);","d2384c9d":"print(\"How many question does each student attempt\")","d5d002ec":"df = train_df[train_df['content_type_id'] == 0]\n\ndf = df.groupby(by='user_id').count()\n\nfig = plt.figure(figsize=(15,6))\nfig = sns.kdeplot(df['row_id'], shade=True, gridsize=50, color='r', legend=False)\nfig.figure.suptitle(\"User attempted questions distribution\", fontsize = 20)\nplt.xlabel('Questions counts', fontsize=16)\nplt.ylabel('Probability', fontsize=16)\nplt.legend(['Questions Attempted','Questions Correctly answered'])","8b304a72":"print(\"distribution of correct and incorrect and no answers\")","690e4999":"df = train_df[train_df['content_type_id'] == 0]\n\ndf2 = df[df['answered_correctly'] == 1]\ndf3 = df[df['answered_correctly'] == 0]\n\ndf2 = df2.groupby(by='user_id').count()\ndf3 = df3.groupby(by='user_id').count()\n\nfig = plt.figure(figsize=(15,6))\nfig = sns.kdeplot(df2['row_id'], shade=True, gridsize=50, color='b', legend=False)\nfig = sns.kdeplot(df3['row_id'], shade=True, gridsize=50, color='r', legend=False)\n\nfig.figure.suptitle(\"User attempted questions distribution\", fontsize = 20)\nplt.xlabel('Questions counts', fontsize=16)\nplt.ylabel('Probability', fontsize=16)\nplt.legend(['Correctly answered','Incorrectly answered'])","02e7fad6":"print(\"What is the distribution of students correctly answering a question ?\")","8de9cbcc":"values = []\n\ndf = train_df[train_df['content_type_id'] == 0]\n\nfor group, frame in df.groupby(by='user_id'):\n    \n    value = len(frame[frame['answered_correctly'] == 1]) \/ len(frame)\n    values.append(value)","01fdb50c":"fig = plt.figure(figsize=(15,6))\nfig = sns.kdeplot(values, shade=True, gridsize=50, color='b', legend=False)\nfig.figure.suptitle(\"User correctly answering distribution\", fontsize = 20)\nplt.xlabel('Percent Correct', fontsize=16)\n\nprint('MEAN: ', np.mean(values))\nprint(\"MAX: \", np.max(values))\nprint('MIN: ', np.min(values))","63fde819":"print(\"What precent of students see explanations ?\")","22589cd7":"values = []\n\ndf = train_df[train_df['content_type_id'] == 0]\n\nfor group, frame in df.groupby(by='user_id'):\n    \n    value = len(frame[frame['prior_question_had_explanation'] == True]) \/ len(frame)\n    values.append(value)","1293d617":"px.histogram(values)","01327c21":"print(\"Total task container id's having questions: \", len((train_df['task_container_id'][train_df['content_type_id'] == 0]).unique()))","f9ee82fd":"questions.head()","a97d3e72":"questions.info()","ea4e8c70":"questions.describe()","28d05fc7":"print('Total number of questions: ', len(questions['question_id'].unique()))\nprint(\"Total number of unique bundles: \", len(questions['bundle_id'].unique()))","6d303955":"fig = plt.figure(figsize=(10,6))\nfig = sns.countplot(questions.groupby(by='bundle_id').count()['question_id'])\nplt.xlabel('bundle_id')\nplt.title('Question in bundles');","cc18881a":"fig = plt.figure(figsize=(10,6))\nfig = sns.countplot(questions['correct_answer'])\nplt.xlabel('Answers')\nplt.title('Correct Answers distribution')","6222865d":"print(\"Distribution of number of tags per question\")\nprint(\"I think of tags as subject includings like (maths, algebra, numbers. history etc. in encoded form)\")","af50d311":"no_of_tags = []\nfor i in questions['tags']:\n    value = len(str(i).strip().split(' '))\n    no_of_tags.append(value)","b6908197":"plt.figure(figsize=(10,6))\nsns.countplot(no_of_tags)\nplt.xlabel('No of tags')\nplt.title('No of tags per question')","48b708f8":"print(\"distribution of tags\")","971c0e5e":"total = []\n\nfor i in questions['tags']:\n    for j in str(i).strip().split(' '):\n        total.append(j)","5a3854f8":"keys = set(total)\nfinal = {}\nfor i in keys:\n    final[i] = total.count(i)","a016bd67":"values = sorted(final.items(), key=lambda x: x[1], reverse=True)\nd = []\nfor i in values:\n    d.append(i[1])","01ab5971":"plt.figure(figsize=(10,6))\npx.line(d, title='Tags distribution')","77d475ec":"tags = WordCloud().generate_from_frequencies(final)\npx.imshow(tags, title='Most frequent Tags')","f079fc37":"lectures.head()","d06feb6c":"lectures.info()","1c97d4b3":"lectures.describe()","7991fa0e":"print('Total no. of lectures: ', len(lectures['lecture_id'].unique()))\nprint('Only one tag per row: ', )\nprint('Total no. of tags in lecture: ', len(lectures['tag'].unique()))","ad24b2af":"# distribution of lecture tags\n\ntotal = []\n\nfor i in lectures['tag']:\n    for j in str(i).strip().split(' '):\n        total.append(j)","469dfcb9":"keys = set(total)\nfinal = {}\nfor i in keys:\n    final[i] = total.count(i)","0f99cd52":"values = sorted(final.items(), key=lambda x: x[1], reverse=True)\nd = []\nfor i in values:\n    d.append(i[1])","2630df48":"plt.figure(figsize=(10,6))\npx.line(d, title='Tags distribution in lectures')","882a8dcd":"# Most common tags\n\ntags = WordCloud().generate_from_frequencies(final)\npx.imshow(tags, title='Most frequent lecture Tags')","94f216eb":"# Looking at parts\nprint('Total type of parts: ', len(lectures.part.unique()))\nprint('Values of parts: ', lectures.part.unique())","24aa8d15":"# Counts of parts\nplt.figure(figsize=(10,6))\nsns.countplot(lectures['part'])\nplt.title('Counts of Parts in Lectures');","a4d0f031":"# how many different unique tags does each part have or do they common tags as well ?\n\nno_unique_tags_l = []\nunique_tags_l = {}\ngroups = []\n\nfor group, frame in lectures.sort_values(by='part').groupby(by='part'):\n    \n    unique_tags = frame['tag'].unique()\n    no_unique_tags = len(unique_tags)\n    \n    unique_tags_l[group] = unique_tags\n    no_unique_tags_l.append(no_unique_tags)\n    groups.append(group)\n    \nno_unique_tags_l = pd.DataFrame(no_unique_tags_l, columns=['count'])\nno_unique_tags_l['group'] = groups","5c7cf971":"# Number of unique tags in each part ( here unique means internally part wise)\nplt.figure(figsize=(10,6))\nsns.barplot(x=no_unique_tags_l['group'], y=no_unique_tags_l['count'])\nplt.title('No. of unique tags in each part')","d3841f24":"final_unqiue = []\nparts = []\n\n\nfor part, array in unique_tags_l.items():\n    \n    unique_tags = []\n        \n    other_parts = list(unique_tags_l.keys())\n    final = set(other_parts)\n    final.remove(part)\n    \n    for j in final:\n        \n        for k in array:\n            \n            if k not in unique_tags_l[j]:\n                \n                unique_tags.append(k)\n    \n    final_unqiue.append(len(unique_tags))\n    parts.append(part)\n    \nfinal_unqiue = pd.DataFrame(final_unqiue, columns=['tags'])\nfinal_unqiue['part'] = parts","24cea42b":"# let's see how many tags are there in each part which are not in any other part\n\nplt.figure(figsize=(10,6))\nsns.barplot(x=no_unique_tags_l['group'], y=no_unique_tags_l['count'])\nplt.title('No. of unique tags in each part not in any other');","6a9e3564":"print(\"Finally let's look at type_of lecture\")","fb703df7":"px.bar(lectures, x='type_of', color=lectures['type_of'], labels={'value':'type_of'}, title='Type of lectures distribution Overall')","94627e4c":"px.bar(lectures, x='type_of', color=lectures['type_of'], labels={'value':'type_of'}, title='Type of lectures distribution based on each part', facet_col='part')","3a2b5436":"train_df.head()","d2024ba6":"print(\"we will see first 8 students for trends\")","74379260":"no_students = 8\nscores = []\nuser_ids = []\nquestion_attempted_l = []\ncorrectly_answered_l = []\nprior_questions_explanations = []\n\nfor count, (group, frame) in enumerate(train_df.groupby(by='user_id')):\n    \n    if count == no_students:\n        break\n    \n    frame = frame.sort_values(by='timestamp')\n    \n    percentage = []\n    question_attempted = []\n    correctly_answered = []\n    explanations = []\n    attempted = 0\n    correct_answers = 0\n    explanation = 0\n    \n    df = frame[frame['content_type_id'] == 0]\n    \n    for answered_correctly, had_explanation in zip(df['answered_correctly'], df['prior_question_had_explanation']):\n        \n        attempted += 1\n        question_attempted.append(attempted)\n        \n        if answered_correctly == 1:\n            correct_answers += 1\n            \n        if had_explanation:\n            explanation += 1\n            \n        correctly_answered.append(correct_answers)\n            \n        percent = correct_answers \/ attempted * 100\n        percentage.append(percent)\n        explanations.append(explanation)\n        \n    \n    scores.append(percentage)\n    user_ids.append(group)\n    question_attempted_l.append(question_attempted)\n    correctly_answered_l.append(correctly_answered)\n    prior_questions_explanations.append(explanations)","a88648c3":"# Trend in attempted question and correctly answering\n\nplt.figure(figsize=(15,20))\n\nfor i in range(1,9):\n    plt.subplot(4,2,i)\n    plt.plot(question_attempted_l[i-1], question_attempted_l[i-1], label='Questions attempted')\n    plt.plot(question_attempted_l[i-1], correctly_answered_l[i-1], label='Questions correctly answered')\n    plt.plot(question_attempted_l[i-1], scores[i-1], label='Percentage correctly answered')\n    plt.plot(question_attempted_l[i-1], prior_questions_explanations[i-1], label='Prior_questions_explanations')\n    plt.legend()\n    plt.ylim(0,100)\n    plt.xlim(0,50)\n    plt.tight_layout(pad = 2)\n    plt.title(f'user_id: {user_ids[i-1]}')","48800351":"# Does students time spend on answering prior questions\n\nno_students = 8\ntime_spend_l = []\n\nfor count, (group, frame) in enumerate(train_df.groupby(by='user_id')):\n    \n    if count == no_students:\n        break\n    \n    frame = frame.sort_values(by='timestamp')\n    total_time_spends = []\n    time_spends = 0\n    \n    for time_spend in frame['prior_question_elapsed_time'][frame['content_type_id'] == 0]:\n        \n        if time_spend > 0:\n            time_spends += time_spend\n            total_time_spends.append(time_spends)\n        \n    \n    time_spend_l.append(total_time_spends)","4031989c":"time_spend_l = np.array(time_spend_l)\nfor index, value in enumerate(time_spend_l):\n    time_spend_l[index] = np.array(time_spend_l[index]) \/ 10000","9fc90fe1":"# Trend in time spend with percentage\n\nplt.figure(figsize=(15,20))\n\nfor i in range(1,9):\n    plt.subplot(4,2,i)\n    plt.plot(question_attempted_l[i-1], correctly_answered_l[i-1], label='Questions correctly answered')\n    plt.plot(question_attempted_l[i-1][1:], time_spend_l[i-1], label='time spend in 10000')\n    plt.plot(question_attempted_l[i-1], scores[i-1], label='Percentage correctly answered')\n    plt.legend()\n    plt.ylim(0,100)\n    plt.xlim(0,50)\n    plt.tight_layout(pad = 2)\n    plt.title(f'user_id: {user_ids[i-1]}')","3ca4606c":"There is mostly a linear increase in prior question time elapsed.","9fedaa2b":"Quite Superising that the number of tags is not decreasing constantly but has a huge dip at 2.","5637629d":"Now comes the troubling part. Tags in lectures has no relation with tags in questions and hence they could be different altogether.","96e4ffd7":"So, we could rest assured that one tag comes only in one part.","1ccacb29":"## WORK IN PROGRESS","700fc889":"Suprisingly intention belongs to only one part and starter is only in 2 parts.","0ab66a7c":"## lectures file","5e996c4a":"So, it also follow the same distribution as above.","3f53e841":"Upnext, we have `prior_question_elapsed_time` column which tells how long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle. (so it depends on the number of questions that bundle had).","cf4283fe":"#### So this is a binary classification and timeseries problem where you predict \"ansered_correctly\" by a student \"user_id\" over time \"timestamp\".","2c512046":"## Analizing the train.csv file","cec05c11":"### Before we move into the real EDA which is with respect to time_stamp let's have a look at questions and lectures files","0a9099ca":"So, most of the students have < 2K samples.","16037b52":"## Before anything else let's see what is our target","d6adea0f":"#### Also the evaluation metric is area under the ROC curve.","ed8ac93b":"The distribution of tags is very skewed. Only 40 tags occur almost > 80% of time.","e245889a":"`lecture_id`: foreign key for the train\/test content_id column, when the content type is lecture (1).\n\n`part`: top level category code for the lecture. (This confuses me. If we have tag then why do we need part?)\n\n`tag`: one tag codes for the lecture. The meaning of the tags will not be provided, but these codes are sufficient for clustering the lectures together.\n\n`type_of`: brief description of the core purpose of the lecture","5c44aa91":"Upnext, we have `user_answer` column where user gives a MCQ type answer say 1,2 or 3 etc. and whether that answer was correct or not is recorded in the next `answered_correctly` column which we need to predict.","0b0d93b5":"Now that is some amazing pattern. The first idea is that the tags could be like subject title. Like lectures with high importance comes from a important chapter and that chapter may have only certen types of tags. Say math chapter may have (Maths, numbers, Algebra) as tags(encoded). ","e8e924ef":"So much to see. So much trends and patterns. Well those who had prior explanation had better results. So the trend has many types. sudden spikes(+ve, -ve), consistency, continuous increment, decrement.<br>\nBad Students: Almost no one started watching explanations until they started performing bad.","741b80cc":"Next, we have `task_container_id` columns which means id's for set's of questions. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a `task_container_id`. ( A correlation\/similarity is in a column `bundle_id` from `question.csv` file)","2bb9b62e":"#### Just in case you are wondering why a example_test file then the reason is that the actual test file could only be seen from the time series api of the riid. rest info is here - https:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction ","29439bad":"## Now it's time to use the time stamp and see a few students from train file","7bc07bcd":"Well I think that the majority of the question sets in task_container_id is from bundle 1","666ecf51":"At the last we have `prior_question_had_explanation` (bool) column which tells whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback. ( In case the questions are related then this can help much.)","bd555204":"the graph shows that the average accuracy of a student is near 54% in answering correctly. Some have scored perfect and some have scored zero. (We have outliars as getting all zeros is by probability as hard as getting all correct so we have to handle that)","b542041e":"## Importing Libraries and data","c68dd693":"## Pls. Upvote if this helps. It motivates me.","09c5492f":"So they follow the same distribution. Majority of student have attempted < 2K questions.","292998ff":"## Pls. Upvote if this helps. It motivates me.","e815181c":"## Understanding The Problem","36d40b64":"we have been provided with `content_id` column which tells us user interestion with the content (not entirely sure wheather its like a book id fixed for that book for all user's or a id generated for each interaction but we will see it later on.), also we have a `content_type_id` column in which 0 means he answered a question and 1 means the content was a lecture and hence he watched a lecture. If he watched a lecture then there was no question hence we need not predict the `answered_correctly` and skip the row for prediction.","7a91e9d3":"There is a considerable amount of students who never watched prior explanations and yet answered correctly. Any further than this we will need to use timestamps or other files.","1597eef2":"## Questions file","0d8bf858":"So we can see that the probability of ansering correctly is mostly 2.5 times that of answering incorrectly.","23510097":"`question_id`: foreign key for the train\/test content_id column, when the content type is question (0).\n\n`bundle_id`: code for which questions are served together.\n\n`correct_answer`: the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n\n`part`: top level category code for the question.\n\n`tags`: one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together.","c166ede5":"#### OK!! So we basically have to predict a probability for \"answered_correctly\" for a given \"row_id\" and \"group_num\" With that out of the way let's look at our training data","f2d33835":"So the answers almost have a uniform distribution."}}