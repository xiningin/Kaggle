{"cell_type":{"d8ca5e55":"code","7b794441":"code","37e8df97":"code","fdaaa65e":"code","b2230bd4":"code","f6f658bc":"code","e52a90f7":"code","5203b945":"code","8b442407":"code","29147595":"code","a253615c":"code","5ff432b2":"code","30ffd8aa":"code","83465efe":"markdown","83d83b4e":"markdown","3fade3a1":"markdown","f0df997c":"markdown","d78d710d":"markdown","3b7a675a":"markdown","6658856b":"markdown","5aa5e695":"markdown","73a8a3bd":"markdown","7abd5165":"markdown","4aaaa0fa":"markdown","001098df":"markdown","62d71753":"markdown","7e4d58de":"markdown","809e1ccd":"markdown","ac43adcc":"markdown","fbe86950":"markdown","d2dccf83":"markdown","ac07aa06":"markdown","ac2dc294":"markdown","d330afe3":"markdown","2131f62c":"markdown","d4fac182":"markdown","15cf2bed":"markdown","1340f032":"markdown","0d262f75":"markdown","71622ef8":"markdown","d2f3b7d3":"markdown"},"source":{"d8ca5e55":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', ]#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)","7b794441":"train.info()","37e8df97":"train.head()","fdaaa65e":"print(train.info()) # before\n# In python listwise\ntrain.dropna(inplace=True)\nprint(train.info()) # after\n\n#pairwise info is a bit scarce to implement in python, hence I will keep it at here. Since most of the time, listwise is used.\n#if you found any resources to link to please let me know :) \n#either way, deletion is best not done.\n\n#In python drop\n#del mydata.column_name (alternative)\nprint(train.head()) #before\ntrain.drop('Embarked', axis=1, inplace=True)\nprint(train.head()) #after","b2230bd4":"#need to reload the dataset so it is not deleted\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', ]#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)\n\nprint(train.tail()) #before\ntrain['Age'].fillna(train['Age'].mean(), inplace = True) #fill with mean\n#train['Age'].fillna(train['Age'].median(), inplace = True) #fill with median\n#had to split due to 2 modes, but normally u wont need to as it will only have one\ntrain['Cabin'].fillna(train['Cabin'].mode()[0].split(\" \")[0], inplace = True) \n#train['Cabin'].fillna(train['Cabin'].mode()[0], inplace = True) #without split\nprint(train.tail()) #after\n\n## alternative: Fill missing values in Age feature with each sex\u2019s mean value of ## Age \n##train['Age'].fillna(train.groupby('Sex')['Age'].transform(\"mean\"), inplace=True)\n","f6f658bc":"#need to reload the dataset so it is not deleted\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', ]#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)\n\nprint(train.tail()) #before\ntrain['age_was_missing'] = train['Age'].isnull()\ntrain['Age'].fillna(train['Age'].mean(), inplace = True) #fill with mean, can fill with 0's or 1's too.\nprint(train.tail()) #after","e52a90f7":"#need to reload the dataset so it is not deleted for demonstration\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', ]#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)\n\n#convert Sex to numerical for regression\ntrain['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n#linear regression\nprint(train.tail()) #before\ntrain['Age']= train.apply(\n    lambda row: \n            0.25743277 * row.Fare + 0.50958711*row.Sex\n            if np.isnan(row.Age) else row.Age, axis=1)\nprint(train.tail()) #after\n","5203b945":"#prep data before doing imputation\n\nfrom sklearn.compose import ColumnTransformer\n\n#need to reload the dataset so it is not deleted for demonstration\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', 'Cabin']#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)\n\nprint(pd.DataFrame(train)) #before)\n#convert Sex to numerical \ntrain['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n#need to fill embarked before one hotting it, so here i will use just the mode to fill\n#alternative: https:\/\/stackoverflow.com\/questions\/37292872\/how-can-i-one-hot-encode-in-python to one hot\n#but dont forget to to the dummy trap prevention line\n\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace = True) #without split\n#convert to one hot #prevent dummy variable trap by passing drop =\"first\"\nct = ColumnTransformer(\n   [('oh_enc', OneHotEncoder(sparse=False, drop='first'), [3]),],  # the column numbers I want to apply this to\n   remainder='passthrough'  # This leaves the rest of my columns in place\n)\ntrain = ct.fit_transform(train)\n\n\nprint(pd.DataFrame(train)) # after\n\ntrain_mice = train\ntrain_knn = train","8b442407":"#implementation\nfrom fancyimpute import IterativeImputer\nMICE_imputer = IterativeImputer()\n# train = train.copy()\n# train.iloc[:, :] = MICE_imputer.fit_transform(train)\ntrain_mice=MICE_imputer.fit_transform(train_mice)\nprint(pd.DataFrame(train_mice)) #after\n\n","29147595":"#double check whethere there are still nulls\npd.DataFrame(train).isna().sum()","a253615c":"#implementation\nfrom fancyimpute import KNN    \n\n# Use 3 nearest rows which have a feature to fill in each row's missing features\ntrain_knn = KNN(k=3).fit_transform(train_knn)\nprint(pd.DataFrame(train_knn)) #after","5ff432b2":"from sklearn.ensemble import RandomForestRegressor\n\n#prep data before doing imputation\nfrom sklearn.compose import ColumnTransformer\n#need to reload the dataset so it is not deleted for demonstration\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndrop_column = ['PassengerId','Survived', 'Ticket', 'Pclass', 'Name', 'SibSp', 'Parch', 'Cabin']#drop a few so it is easier to visualize\ntrain.drop(drop_column, axis=1, inplace = True)\n\nprint(pd.DataFrame(train)) #before)\n#convert Sex to numerical \ntrain['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n#alternative: https:\/\/stackoverflow.com\/questions\/37292872\/how-can-i-one-hot-encode-in-python to one hot\n#but dont forget to to the dummy trap prevention line\n\n#fill Nan in embarked with the mode\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace = True)\n\n#split the data based on missing value in the Age column\ntrainWithAge = train[pd.isnull(train['Age']) == False]\ntrainWithoutAge = train[pd.isnull(train['Age'])]\n\n#another method to one hot a column, and drop first column to prevent dummy variable trap\ntrainWithoutAge_one_hot_encoded_embarked = pd.get_dummies(trainWithoutAge['Embarked'], drop_first=True)\ntrainWithAge_one_hot_encoded_embarked = pd.get_dummies(trainWithAge['Embarked'], drop_first= True)\ntrainWithAge = pd.concat([trainWithAge, trainWithAge_one_hot_encoded_embarked], axis = 1)\ntrainWithoutAge = pd.concat([trainWithoutAge, trainWithoutAge_one_hot_encoded_embarked], axis = 1)\n\n#remove the original column and also preventing the dummy variable trap\ntrainWithAge.drop(['Embarked'], axis=1, inplace = True)\ntrainWithoutAge.drop(['Embarked'], axis=1, inplace = True)\n\nprint(trainWithAge)\nprint(trainWithoutAge)","30ffd8aa":"#implement random forest\nindependentVariables = ['Sex', 'Fare', 'Q', 'S']\nprint(trainWithoutAge) #before\n\nrf = RandomForestRegressor()\n#train the model with the available values\nrf.fit(trainWithAge[independentVariables], trainWithAge['Age'])\n\n#predict\ngeneratedAgeValues = rf.predict(X = trainWithoutAge[independentVariables])\n\n#store the results into the column, the astype int converts it to interger, u can keep it as float if you want to\ntrainWithoutAge['Age'] = generatedAgeValues.astype(int)\n\nprint(trainWithoutAge) #after\n\n#combine them back, reset the index, and drop the extra index column\ntrain = trainWithAge.append(trainWithoutAge)\ntrain.reset_index(inplace=True)\ntrain.drop('index',inplace=True,axis=1)\nprint(train)","83465efe":"(c) Not Missing At Random (NMAR): \n- When the missing data has a structure to it, we cannot treat it as missing at random. In the above example, if the data was missing for all students from specific schools, then the data cannot be treated as MAR.- https:\/\/www.datascience.com\/blog\/missing-data-imputation\n\n- Two possible reasons are that the missing value depends on the hypothetical value (e.g. People with high salaries generally do not want to reveal their incomes in surveys) or missing value is dependent on some other variable\u2019s value (e.g. Let\u2019s assume that females generally don\u2019t want to reveal their ages! Here the missing value in age variable is impacted by gender variable) - https:\/\/towardsdatascience.com\/how-to-handle-missing-data-8646b18db0d4\n\n- (i) Missingness that depends on unobserved predictors. Missingness is no longer \u201cat random\u201d if it depends on information that has not been recorded and this information also predicts the missing values. For example, suppose that \u201csurly\u201d people are less likely to respond to the earnings question, surliness is predictive of earnings, and \u201csurliness\u201d is unobserved. Or, suppose that people with college degrees are less likely to reveal their earnings, having a college degree is predictive of earnings, and there is also some nonresponse to the education question. Then, once again, earnings are not missing at random.\n- (ii) Missingness that depends on the missing value itself. Finally, a particularly difficult situation arises when the probability of missingness depends on the (potentially missing) variable itself. For example, suppose that people with higher earnings are less likely to reveal them. In the extreme case (for example, all persons earning more than $100,000 refuse to respond), this is called censoring, but even the probabilistic case causes difficulty. - http:\/\/www.stat.columbia.edu\/~gelman\/arm\/missing.pdf\n\n- If neither MCAR nor MAR holds, then we speak of missing not at random (MNAR). MNAR means that the probability of being missing varies for reasons that are unknown to us. For example, the weighing scale mechanism may wear out over time, producing more missing data as time progresses, but we may fail to note this. If the heavier objects are measured later in time, then we obtain a distribution of the measurements that will be distorted. MNAR includes the possibility that the scale produces more missing values for the heavier objects (as above), a situation that might be difficult to recognize and handle. An example of MNAR in public opinion research occurs if those with weaker opinions respond less often. MNAR is the most complex case. Strategies to handle MNAR are to find more data about the causes for the missingness, or to perform what-if analyses to see how sensitive the results are under various scenarios. - https:\/\/stefvanbuuren.name\/fimd\/sec-MCAR.html\n\nKeywords to take here are, has a structure, dependent on some variables' values, depends on information that has not been recorded, or on itself.","83d83b4e":"If you're imputing categorical columns, from here https:\/\/github.com\/iskandr\/fancyimpute\/issues\/55 they said that:\n> You can modify the code yourself to round the one hot columns to 0\/1 at end of each round\n\nSo there you go you can just do it yourself.\n\nhttps:\/\/s3.amazonaws.com\/assets.datacamp.com\/production\/course_17404\/slides\/chapter4.pdf for extra resources too.","3fade3a1":" However, there can be multiple reasons why deleting missing observations may not be the most feasible option:\n\n- There may not be enough observations with non-missing data to produce a reliable analysis\n- In predictive analytics, missing data can prevent the predictions for those observations which have missing data\n- External factors may require specific observations to be part of the analysis\n\nIn such cases, we impute values for missing data. A common technique is to use the mean or median of the non-missing observations. This can be useful in cases where the number of missing observations is low. However, **for large number of missing values, using mean or median can result in loss of variation in data and it is better to use imputations**. Moreover, mean imputation distorts relationships between variables by \u201cpulling\u201d estimates of the correlation toward zero.","f0df997c":"There you go, however for now it isn't as easy to implement comparing to R, as R can handle categorical data without you needing to one hot or encode them (though factorizing is pretty much similar, and I'm not sure whether MICE will have an issue too if some of the categorical columns have NaN, let me know if you have tried it! :) I'll give it a try and update my materials once I have done so!). So if you do have spare time, what you can do is do imputations at R, then save it then do your other functions in python. Either way, you decide how you want to handle things. :)","d78d710d":"**Extra Info**\n\nCapabilities of mice package:\nThe mice package contains functions to:\n- Inspect the missing data pattern\n- Impute the missing data m times, resulting in m completed data sets\n- Diagnose the quality of the imputed values\n- Analyze each completed data set\n- Pool the results of the repeated analyses\n- Store and export the imputed data in various formats\n- Generate simulated incomplete data\n- Incorporate custom imputation methods\n- Choose which cells to impute","3b7a675a":"From here https:\/\/scikit-learn.org\/stable\/auto_examples\/impute\/plot_iterative_imputer_variants_comparison.html, you can see that you can implement the random forest imputation similar to R's missForest with either:\n- sklearn.ensemble.ExtraTreesRegressor (similar to missForest in R)\n- sklearn.ensemble.RandomForestRegressor (missForest)\n\nIrl, you could always try out both, and see which one works better, I myself have not tried to compare them yet, so I will update the materials after I compared them or seen someone comparing them. And also, for using the random forest imputation, it works as a normal model, so you would need to split the data into 2, data with missing values for a specific column, and data without missing values. Then, you use the data with non-missing values to train the model\/regressor, then put in the data with missing values to estimate the missing values.","6658856b":"**Mean, Median and Mode Imputation**\n- Computing the overall mean, median or mode is a very basic imputation method, it is the only tested function that takes no advantage of the time series characteristics or relationship between the variables. However, the disadvantages are described above when using them.\n\nYou may have other methods like last value carry forward, linear interpolation etc, but in my opinion, they wouldnt do any much better compared to mean imputation, so I will not talk about them, but if you are interested, you can always search online :) that's how i learnt. no shortcuts. \n\nTo sum it up,as before, mean computation will underestimate the variance, disturb the relations between variables, bias almost any estimate other than the mean and bias the estimate of the mean when data are not MCAR. Mean imputation should perhaps only be used as a rapid fix when a handful of values are missing, and it should be avoided in general.","5aa5e695":"In addition to using the mean imputation, there is another common way which is adding another column that identifies whether the values are given or not, and using the mean for the missing values in the original feature\/variable. However, you will be adding extra columns into your dataset for each feature that you are extending this method.\n\nNote: https:\/\/www.kaggle.com\/dansbecker\/handling-missing-values introduces it as one of the ways to handle missing values too, so it is worth noting. I'm not sure what it is called, but it's something like **Missingness Indicator Column**. As long as you get the point then it's fine. :D\n\n(i) Categorical predictors: For unordered categorical predictors, a simple and often useful approach to imputation is to add an extra category for the variable indicating missingness.\n\n(ii) Coutinuous predictors: Similar as above, but the missing values in the partially observed predictor are replaced by zeroes or by the mean (this choice is essentially irrelevant). However, **this strategy is prone to yield biased coefficient estimates for the other predictors** included in the model because it forces the slope to be the same across both missing-data groups. Adding interactions between an indicator for response and these predictors can help to alleviate this bias (this leads to estimates similar to complete-case estimates).\n","73a8a3bd":"**KNN (K Nearest Neighbors) Imputation**\n\nFor those who are not familiar with KNN I suggest you search and read about it, as I'm not going to go through it here. :(\n\nThe distance metric varies according to the type of data:\n1. Continuous Data: The commonly used distance metrics for continuous data are Euclidean, Manhattan and Cosine\n2. Categorical Data: Hamming distance is generally used in this case. It takes all the categorical attributes and for each, count one if the value is not the same between two points. The Hamming distance is then equal to the number of attributes for which the value was different.","7abd5165":"Overview \n* Imputation: Impute the missing entries of the incomplete data sets m times (m=3 in the figure). Note that imputed values are drawn from a distribution. In another term, the technique creates multiple versions of the imputed data. Then you would a number of complete datasets in that case.\n\n* Analysis: Analyze each of the m completed data sets. It estimates the parameters of interest from each imputed dataset. This is typically done by applying the analytic method that we would have used had the data been complete, and since we have a number of complete datasets from the previous stage, we can apply it.\n\n* Pooling: Integrate the m analysis results into a final result. The m parameter estimates are pooled into one estimate, and to estimate its variance. The variance combines the conventional sampling variance (within-imputation variance) and the extra variance caused by the missing data (between-imputation variance). Under the appropriate conditions, the pooled estimates are unbiased and have the correct statistical properties.","4aaaa0fa":"When dealing with real world data, it is very common for us to be seeing missing values in our dataset to be used, either training or test set. Understanding the nature of missing data is critical in determining what treatments can be applied to overcome the lack of data. \n\nMissing data may come in a variety of ways, it can be an empty string, it can be NA, N\/A, None, -1 or 999. The best way to prepare for dealing with missing values is to understand the data you have: understand how missing values are represented, how the data was collected, where missing values are not supposed to be and where they are used specifically to represent the absence of data. Domain knowledge and data understanding are the most important factors to successfully deal with missing data, moreover, these factors are the most important in any part of the data science project.\n","001098df":"One of the most attractive features of the KNN algorithm is that it is **simple to understand and easy to implement**. \n\nOne of the obvious drawbacks of the KNN algorithm is that it becomes **time-consuming when analyzing large datasets** because it searches for similar instances through the entire dataset. Furthermore, t**he accuracy of KNN can be severely degraded with high-dimensional data because there is little difference between the nearest and farthest neighbor**.","62d71753":"**Linear Regression**\nAnother method to fill your missing values. To begin, several predictors of the variable with missing values are identified using a correlation matrix. The best predictors are selected and used as independent variables in a regression equation. The variable with missing data is used as the dependent variable. Cases with complete data for the predictor variables are used to generate the regression equation; the equation is then used to predict missing values for incomplete cases. \n\nIn an iterative process, values for the missing variable are inserted and then all cases are used to predict the dependent variable. These steps are repeated until there is little difference between the predicted values from one step to the next, that is they converge.\n\nIt \u201ctheoretically\u201d provides good estimates for missing values. However, there are several disadvantages of this model which tend to outweigh the advantages. First, because the replaced values were predicted from other variables they **tend to fit together \u201ctoo well\u201d and so standard error is deflated**. One must also **assume that there is a linear relationship between the variables used** in the regression equation when there may not be one.","7e4d58de":"NOTE: unfortunately, at this time of date September 2019, the fancyimpute to do MICE in python can only impute numerical data, unlike in R where you can just factorize the variables, but what you can do is to one hot them (for nominal) or encode them (for ordinal) beforehand before doing them if you do want to include the categorical columns. If not, you can just drop them. so here, I will drop 'Cabin' column as it has more than 70% missing data, and also one hot the 'Embarked', and encode the 'Sex'\n\nDo not forget that we have to remove one column of the one hot to prevent the dummy variable trap.","809e1ccd":"**Random Forest Imputation**\n\n- Random forest is a non-parametric imputation method applicable to various variable types that works well with both data missing at random and not missing at random. Random forest uses multiple decision trees to estimate missing values and outputs OOB (out of bag) imputation error estimates. \n\n- One caveat is that random forest works best with large datasets and using random forest on small datasets runs the risk of overfitting. The extent of overfitting leading to inaccurate imputations will depend upon how closely the distribution for predictor variables for non-missing data resembles the distribution of predictor variables for missing data.\n\n- For example, if the distribution of race\/ethnicity for non-missing data is similar to the distribution of race\/ethnicity for missing data, overfitting is not likely to throw off results. However, if the two distributions differ, the accuracy of imputations will suffer.","ac43adcc":"(b)Missing At Random (MAR): \n- The key difference between MCAR and MAR is that under MAR the data is not missing randomly across all observations, but is missing randomly only within sub-samples of data. For example, if high school GPA data is missing randomly across all schools in a district, that data will be considered MCAR. However, if data is randomly missing for students in specific schools of the district, then the data is MAR.- https:\/\/www.datascience.com\/blog\/missing-data-imputation\n\n- Missing at random means that the propensity for a data point to be missing is not related to the missing data, but it is related to some of the observed data - https:\/\/towardsdatascience.com\/how-to-handle-missing-data-8646b18db0d4\n\n- A more general assumption, missing at random, is that the probability a variable is missing depends only on available information. Thus, if sex, race, education, and age are recorded for all the people in the survey, then \u201cearnings\u201d is missing at random if the probability of nonresponse to this question depends only on these other, fully recorded variables. It is often reasonable to model this process as a logistic regression, where the outcome variable equals 1 for observed cases and 0 for missing. - http:\/\/www.stat.columbia.edu\/~gelman\/arm\/missing.pdf\n\n- If the probability of being missing is the same only within groups defined by the observed data, then the data are missing at random (MAR). MAR is a much broader class than MCAR. For example, when placed on a soft surface, a weighing scale may produce more missing values than when placed on a hard surface. Such data are thus not MCAR. If, however, we know surface type and if we can assume MCAR within the type of surface, then the data are MAR. Another example of MAR is when we take a sample from a population, where the probability to be included depends on some known property. MAR is more general and more realistic than MCAR. Modern missing data methods generally start from the MAR assumption.- https:\/\/stefvanbuuren.name\/fimd\/sec-MCAR.html\n\nKeywords to take here are, missing within sub-samples of data, related to observed data, depends only on available information, and missing only within groups defined by the observed data.\n","fbe86950":"![image.png](attachment:image.png)\nSource: https:\/\/stefvanbuuren.name\/fimd\/sec-nutshell.html","d2dccf83":"When data is missing at random, we can use list-wise or pair-wise deletion of the missing observations.\n- **Listwise deletion** (complete-case analysis) removes all data for an observation that has one or more missing values. Particularly if the missing data is limited to a small number of observations, you may just opt to eliminate those cases from the analysis. However in most cases, it is often disadvantageous to use listwise deletion. This is because the assumptions of MCAR (Missing Completely at Random) are typically rare to support. As a result, listwise deletion methods produce biased parameters and estimates.\n\n- **Pairwise deletion** analyses all cases in which the variables of interest are present and thus maximizes all data available by an analysis basis. A strength to this technique is that it increases power in your analysis but it has many disadvantages. It assumes that the missing data are MCAR. If you delete pairwise then you\u2019ll end up with different numbers of observations contributing to different parts of your model, which can make interpretation difficult. You can see an illustration of pairwise deletion below.\n\n- **Dropping Variables**. It is always better to keep data than to discard it. Sometimes you can drop variables if the data is missing for more than 60%-70% observations but only if that variable is insignificant. Having said that, imputation is always a preferred choice over dropping variables\n","ac07aa06":"![image.png](attachment:image.png)\n* Example of Pairwise deletion","ac2dc294":"Implementation in R\n\nTo set up the data for MICE, it is important to note that the algorithm uses all the variables in the data for predictions. \n- In this case, variables that may not be useful for predictions should be removed before implementing this algorithm. \n\nSecondly, as mentioned above, the algorithm treats different variables differently. \n- So, all categorical variables should be treated as factor variables before implementing MICE.","d330afe3":"Okay, so this 3 are the more general cases to missing data, you can split them more to be more detailed in regards to each type of missing data, but for now let's just categorize them into this three. Wow, after reading so much, I still dont know how to apply what I have read into my dataset. What?? Calm down. Let's move on.","2131f62c":"General impossibility of proving that data are missing at random\n\nMissingness at random is relatively easy to handle\u2014simply include as regression inputs all variables that affect the probability of missingness. Unfortunately, we generally cannot be sure whether data really are missing at random, or whether the missingness depends on unobserved predictors or the missing data themselves. The fundamental difficulty is that these potential \u201clurking  variables\u201d are unobserved\u2014by definition\u2014and so we can never rule them out. We generally must make assumptions, or check with reference to other studies (for example, surveys in which extensive follow-ups are done in order to ascertain the earnings of nonrespondents).\nIn practice, we typically try to include as many predictors as possible in a model so that the \u201cmissing at random\u201d assumption is reasonable. For example, it may be a strong assumption that nonresponse to the earnings question depends only on sex, race, and education\u2014but this is a lot more plausible than assuming that the probability of nonresponse is constant, or that it depends only on one of these predictors - http:\/\/www.stat.columbia.edu\/~gelman\/arm\/missing.pdf\n\nSo in simple terms, what it means is that we try to add in more predictors (independent variables) as much as we can into let's say a regression function to make it look more random-like, because if it does not look random, then it would be harder to fill the missing data.","d4fac182":"**Multivariate Imputation By Chained Equations (MICE)**\n\n- Before I get to the details of it, you can read more about this method here https:\/\/stefvanbuuren.name\/fimd\/sec-nutshell.html, as there are a lot of info to this.\n\n- MICE assumes that the missing data are Missing at Random (MAR). It imputes data on a variable-by-variable basis by specifying an imputation model per variable. MICE uses predictive mean matching (PMM) for continuous variables, logistic regressions for binary variables, bayesian polytomous regressions for factor variables, and proportional odds model for ordered variables to impute missing data.\n\n- The method is based on Fully Conditional Specification, where each incomplete variable is imputed by a separate model. The MICE algorithm can impute mixes of continuous, binary, unordered categorical and ordered categorical data. In addition, MICE can impute continuous two-level data, and maintain consistency between imputations by means of passive imputation. Many diagnostic plots are implemented to inspect the quality of the imputations.","15cf2bed":"Data can be missing in the following ways, so we will go through it one by one.\n","1340f032":"To sum up data imputations is tricky and should be done with care. It is important to understand the nature of the data that is missing when deciding which algorithm to use for imputations. \n\nAmong all the methods discussed above, multiple imputation and KNN are widely used, and multiple imputation being simpler is generally preferred.\n\nFinally, you can test the quality of your imputations by normalized root mean square error (NRMSE) for continuous variables and proportion of falsely classified (PFC) for categorical variables.\n\nOkay. that is it for now. There are a lot more imputation methods out there, some might be better, so if you're really interested you can search online for more! \n\nP.S. I'll add more here if I have used\/applied them and find them good.","0d262f75":"Next, we show ways on how to deal with missing data, NOTE: there are various methods to do so, but here I'm only mentioning the most commonly used ones. You could always search to find out more about other methods, who knows they might work better.","71622ef8":"(a) Missing Completely At Random (MCAR): \n- When missing values are randomly distributed across all observations, then we consider the data to be missing completely at random. A quick check for this is to compare two parts of data \u2013 one with missing observations and the other without missing observations. On a t-test, if we do not find any difference in means between the two samples of data, we can assume the data to be MCAR. - https:\/\/www.datascience.com\/blog\/missing-data-imputation\n\n-  The fact that a certain value is missing has nothing to do with its hypothetical value and with the values of other variables. - https:\/\/towardsdatascience.com\/how-to-handle-missing-data-8646b18db0d4\n\n- A variable is missing completely at random if the probability of missingness is the same for all units, for example, if each survey respondent decides whether to answer the \u201cearnings\u201d question by rolling a die and refusing to answer if a \u201c6\u201d shows up. If data are missing completely at random, then throwing out cases with missing data does not bias your inferences - http:\/\/www.stat.columbia.edu\/~gelman\/arm\/missing.pdf\n\n- If the probability of being missing is the same for all cases, then the data are said to be missing completely at random (MCAR). This effectively implies that causes of the missing data are unrelated to the data. We may consequently ignore many of the complexities that arise because data are missing, apart from the obvious loss of information. An example of MCAR is a weighing scale that ran out of batteries. Some of the data will be missing simply because of bad luck. Another example is when we take a random sample of a population, where each member has the same chance of being included in the sample. The (unobserved) data of members in the population that were not included in the sample are MCAR. While convenient, MCAR is often unrealistic for the data at hand. - https:\/\/stefvanbuuren.name\/fimd\/sec-MCAR.html\n\nKeywords to take here are. randomly distributed, nothing to do with its hypothetical value, and probability of missing is the same for all cases. Also, removing it does not bias your inferences.\n","d2f3b7d3":"Before that, let us prepare our dataset to be playing around with this tools. :) "}}