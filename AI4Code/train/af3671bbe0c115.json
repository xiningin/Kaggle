{"cell_type":{"8286e828":"code","e0b804b5":"code","2ddae714":"code","dd7dbe9f":"code","bc3bf008":"code","e827623c":"code","6ab349fc":"code","a2e60286":"code","a9a51a6d":"code","67b89c4e":"code","8e2e19ce":"code","b226c08a":"code","759a8f6a":"markdown","4d2e9af2":"markdown","27b652d6":"markdown","e69452fa":"markdown","254873f6":"markdown"},"source":{"8286e828":"import pandas as pd\nimport numpy as np\nimport spacy\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS","e0b804b5":"#Loading the dataset\ndf = pd.read_csv('..\/input\/spamclass\/Spam SMS Collection', sep='\\t', names=['label', 'message'])","2ddae714":"#First five observations\ndf.head()","dd7dbe9f":"#Shape of the dataset\ndf.shape","bc3bf008":"#Count of output feature\ndf['label'].value_counts()","e827623c":"#Create list of punctuation marks\nimport string\npunctuations=string.punctuation\n\n#Create list of stopwords\nnlp=spacy.load('en')\nstop_words=spacy.lang.en.stop_words.STOP_WORDS\n\n#Load English tokenizer, tagger, parser, NER and word vectors\nparser=English()\n\n#Create tokenizer function\ndef spacy_tokenizer(sentence):\n  #Creating our token object, which is used to create documents with linguistic annotations.\n  mytokens=parser(sentence)\n  #Lemmatizing each token and converting each token into lowercase\n  mytokens=[word.lemma_.lower().strip() if word.lemma_!='-PRON' else word.lower_ for word in mytokens]\n  #Removing stopwords\n  mytokens=[word for word in mytokens if word not in stop_words and word not in punctuations]\n  #Return preprocessed list of tokens\n  return mytokens","6ab349fc":"#To further clean our text data, we\u2019ll also want to create a custom transformer for removing initial and end spaces and converting text into lower case.\nfrom sklearn.base import TransformerMixin\nclass predictors(TransformerMixin):\n  def transform(self,X, **transform_params):\n    return[clean_text(text)for text in X]\n\n  def fit(self,X,y=None, **fir_params):\n    return self\n  \n  def get_params(self,deep=True):\n    return {}\n#Basic function to clean the text\ndef clean_text(text):\n  #Removing spaces and converting text into lowercase\n  return text.strip().lower()","a2e60286":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nbow_vector=CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1,3))\ntfidf_vector= TfidfVectorizer(tokenizer=spacy_tokenizer)","a9a51a6d":"from sklearn.model_selection import train_test_split\nX=df['message']\ny=pd.get_dummies(df['label'])\ny=y.drop(['spam'],1)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)","67b89c4e":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nsvc=SVC(class_weight='balanced')\nparams={'kernel':['linear','rbf','poly','sigmoid'],'C':[0.01,0.1,1,10],'gamma':[0.01,0.1,1,10]}\ngs_svc=GridSearchCV(svc,params)","8e2e19ce":"pipe= Pipeline([('cleaner', predictors()),\n                 ('vectorizer',tfidf_vector),\n                 ('classifier', gs_svc)])\npipe.fit(X_train,y_train)","b226c08a":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npredicted=pipe.predict(X_test)\nprint('Accuracy:',metrics.accuracy_score(predicted,y_test))\nprint('Precision:',metrics.precision_score(predicted,y_test))\nprint('Recall:',metrics.recall_score(predicted,y_test))\n\ncfm=metrics.confusion_matrix(y_test,predicted)\nlbl1=['Predicted Negetive', 'Predicted Positive']\nlbl2=['Actual Negetive', 'Actual Positive']\nsns.heatmap(cfm, annot=True, cmap='Blues',fmt='d',xticklabels=lbl1,yticklabels=lbl2)\nplt.show()","759a8f6a":"##Vectorization","4d2e9af2":"##Pipeline","27b652d6":"##Import Data","e69452fa":"##Train Test Split","254873f6":"##Import Packages"}}