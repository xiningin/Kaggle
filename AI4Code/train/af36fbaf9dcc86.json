{"cell_type":{"6e6b5220":"code","817e3115":"code","ccea279a":"code","bf66bbc2":"code","2bbd0b91":"code","506dd6e9":"code","5340fe2e":"code","5bfbb4b7":"code","e00e55dd":"code","b07e73db":"code","017f8d28":"code","785e1d63":"code","64275186":"code","064ece36":"code","e59ef882":"code","d0c9c7ea":"code","203dc3fa":"code","17a88ab3":"code","8751c95a":"code","16e01d86":"code","4b3cd23a":"code","b091c9e5":"code","accca049":"code","66a4efcd":"code","e9174499":"code","5ac22b2d":"code","ad1eddf2":"code","2380ceaf":"code","61b766cc":"code","924ec8bc":"code","06764e3e":"code","05eff26e":"code","de2a46f9":"code","94825428":"code","6263eeda":"code","61a38db2":"code","445a754c":"code","0980a697":"code","4ee2489d":"code","1f89869e":"code","aac25d54":"code","fca375e1":"code","47e18958":"code","dee93732":"code","c920d033":"code","fa14d7c8":"code","7d57f7fa":"code","2e8cc083":"code","4522f23d":"code","7eb8eab1":"code","ce99ff85":"code","c1315b5a":"markdown","ecb89e9f":"markdown","09aaeb6d":"markdown","22e1e229":"markdown","7b9ac6dd":"markdown","e2a83afe":"markdown","60df9c8c":"markdown","ef6313ea":"markdown","4df47a89":"markdown","be5e201c":"markdown","3d4dbb68":"markdown","b38f9a9f":"markdown","1eed706a":"markdown","5534b30e":"markdown","c1cfbc25":"markdown","d736ff33":"markdown","ab906457":"markdown","6df29b4e":"markdown","37553ffe":"markdown","58a1a456":"markdown","00177576":"markdown","3ce38e28":"markdown","5746652b":"markdown","0806805e":"markdown","6dc54da4":"markdown","ad4c092e":"markdown","6939330c":"markdown","cab8806e":"markdown","39c7b324":"markdown","29d7de23":"markdown","5cec700c":"markdown","a1dc72ec":"markdown","5151d39d":"markdown","75d98f37":"markdown","4f14ae9a":"markdown","155d0172":"markdown","5382cde9":"markdown","208c16f9":"markdown","36c6c107":"markdown","b5aa4e0f":"markdown","424dbf2e":"markdown","2041d2e6":"markdown","48d85fc3":"markdown","6d440281":"markdown","c7d752c6":"markdown","341d2d36":"markdown","968af24d":"markdown","1c563593":"markdown","79c2e69a":"markdown","43692710":"markdown","2852ac82":"markdown","0394755d":"markdown","c7f45461":"markdown","c408341b":"markdown","be29fcd1":"markdown","54d33e30":"markdown","3e772108":"markdown","721528af":"markdown","198f545e":"markdown","2e724b07":"markdown","4be7c1a9":"markdown","ece075e8":"markdown","c4ca9fcf":"markdown","567635a0":"markdown","1ebaaec8":"markdown","f087fbc7":"markdown","3fc66f79":"markdown","f2f75def":"markdown","ca87648c":"markdown","cbc3e572":"markdown","556236bc":"markdown","6f2375da":"markdown","a9649eb7":"markdown","52fc17a6":"markdown","05d25f4a":"markdown"},"source":{"6e6b5220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","817e3115":"import numpy as np\nimport datetime as dt\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n!pip install openpyxl\n\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n%matplotlib inline","ccea279a":"df=pd.read_excel(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\")","bf66bbc2":"df.shape","2bbd0b91":"df.dtypes","506dd6e9":"df.describe()","5340fe2e":"df.head()","5bfbb4b7":"print('A total of '+ str(df.Invoice.nunique()) +' unique invoices were generated.')","e00e55dd":"print('We have '+ str(df.StockCode.nunique()) +' unique products sold online.')\n","b07e73db":"# We are renaming the CustomerID for our conveniency\ndf = df.rename(columns={'Customer ID':'CustomerID'})\n\nprint('We have '+ str(df.CustomerID.nunique()) +' unique Customers in our dataset.')","017f8d28":"print('We have customers spread across '+ str(df.Country.nunique()) +' countries. ')","785e1d63":"df.isnull().sum().sort_values(ascending=False)","64275186":"corrDf = df.corr()\nsns.heatmap(corrDf, \n        xticklabels=corrDf.columns,\n        yticklabels=corrDf.columns, cmap='coolwarm_r')","064ece36":"df = df[(df['Quantity']>0) & (df['Price']>0)] \ndf.describe()","e59ef882":"df.shape","d0c9c7ea":"df=df.drop_duplicates()\ndf.shape","203dc3fa":"df.InvoiceDate.max()","17a88ab3":"# Create a column Amount(Total cost)\ndf['Amount'] = df['Quantity'] * df['Price']","8751c95a":"pin_date = dt.datetime(2010, 12,10)\n\nrfm = df.groupby('CustomerID').agg({'InvoiceDate': lambda InvoiceDate: (pin_date - InvoiceDate.max()).days,\n                                     'Invoice': lambda Invoice: Invoice.nunique(),\n                                     'Amount': lambda Amount: Amount.sum()})\n\nrfm.head()","16e01d86":"rfm.columns = ['recency', 'frequency', 'monetary']\nrfm = rfm[rfm[\"monetary\"] > 0]\nrfm.head()","4b3cd23a":"rfm[\"recency_score\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n\n\nrfm[\"frequency_score\"] = pd.qcut(rfm['frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n\nrfm[\"monetary_score\"] = pd.qcut(rfm['monetary'], 5, labels=[1, 2, 3, 4, 5])\n\nrfm['score']=rfm['recency_score'].astype(int)+rfm['frequency_score'].astype(int)+rfm['monetary_score'].astype(int)","b091c9e5":"rfm.head()","accca049":"rfm[rfm['score']== 15].sort_values('monetary', ascending=False).head()","66a4efcd":"rfm[rfm['score']==15].count()","e9174499":"def rfm_level(score):\n    if  ((score >1) and (score < 4)):\n        return 'Inactive'\n    elif ((score >3) and (score < 8)):\n        return 'Average'\n    elif ((score > 7) and (score <11)):\n        return 'Good'\n    else:\n        return 'Active'","5ac22b2d":"rfm['level'] = rfm['score'].apply(lambda score : rfm_level(score))\nrfm.head()","ad1eddf2":"plt.figure(figsize=(10,5))\nsns.set_context(\"poster\", font_scale=0.7)\nsns.set_palette('twilight')\nsns.countplot(rfm['level'])","2380ceaf":"rfm.groupby('level').agg({\n    'recency' : ['mean', 'min','max'],\n    'frequency' : ['mean', 'min','max'],\n    'monetary' : ['mean','min','max','count']\n})","61b766cc":"cross_table1 = pd.crosstab(index=rfm['monetary_score'], columns=rfm['frequency_score'])\ncross_table2 = pd.crosstab(index=rfm['monetary_score'], columns=rfm['recency_score'])\ncross_table3 = pd.crosstab(index=rfm['frequency_score'], columns=rfm['recency_score'])\nplt.figure(figsize=(20,30))\nplt.subplot(311)\nax1 = sns.heatmap(cross_table1, cmap='viridis', annot=True, fmt=\".0f\")\nax1.invert_yaxis()\nax1.set_ylabel('Monetary')\nax1.set_xlabel('Frequency')\nax1.set_title('Monetary vs Frequency')\nplt.subplot(312)\nax2 = sns.heatmap(cross_table2, cmap='viridis', annot=True, fmt=\".0f\")\nax2.invert_yaxis()\nax2.set_ylabel('Monetary')\nax2.set_xlabel('Recency')\nax2.set_title('Monetary vs Recency')\nplt.subplot(313)\nax3 = sns.heatmap(cross_table3, cmap='viridis', annot=True, fmt=\".0f\")\nax3.invert_yaxis()\nax3.set_ylabel('Frequency')\nax3.set_xlabel('Recency')\nax3.set_title('Recency vs Frequency')\nplt.show()","924ec8bc":"active = rfm[rfm['level'] == 'Active']\naverage = rfm[rfm['level'] == 'Average']\ngood = rfm[rfm['level'] == 'Good']\ninactive = rfm[rfm['level'] == 'Inactive']","06764e3e":"active_df = pd.DataFrame()\nactive_df[\"customer_id\"] = rfm[rfm[\"level\"] == \"Active\"].index\n\nactive_df.to_excel(\"active_customers.xlsx\", sheet_name='Active Customers Index')","05eff26e":"average_df = pd.DataFrame()\naverage_df[\"customer_id\"] = rfm[rfm[\"level\"] == \"Average\"].index\n\naverage_df.to_excel(\"average_customers.xlsx\", sheet_name='Average Customers Index')","de2a46f9":"good_df = pd.DataFrame()\ngood_df[\"customer_id\"] = rfm[rfm[\"level\"] == \"Good\"].index\n\ngood_df.to_excel(\"good_customers.xlsx\", sheet_name='Good Customers Index')","94825428":"inactive_df = pd.DataFrame()\ninactive_df[\"customer_id\"] = rfm[rfm[\"level\"] == \"Inactive\"].index\n\ninactive_df.to_excel(\"inactive_customers.xlsx\", sheet_name='Inactive Customers Index')","6263eeda":"rfm.describe()","61a38db2":"plt.boxplot(rfm.recency)\nQ1 = rfm.recency.quantile(0.25)\nQ3 = rfm.recency.quantile(0.75)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.recency >= Q1 - 1.5*IQR) & (rfm.recency <= Q3 + 1.5*IQR)]","445a754c":"plt.boxplot(rfm.frequency)\nQ1 = rfm.frequency.quantile(0.25)\nQ3 = rfm.frequency.quantile(0.75)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.frequency >= Q1 - 1.5*IQR) & (rfm.frequency <= Q3 + 1.5*IQR)]","0980a697":"plt.boxplot(rfm.monetary)\nQ1 = rfm.monetary.quantile(0.25)\nQ3 = rfm.monetary.quantile(0.75)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.monetary >= (Q1 - 1.5*IQR)) & (rfm.monetary <= (Q3 + 1.5*IQR))]","4ee2489d":"rfm1=rfm[['recency','frequency','monetary']]\nscaler = StandardScaler()\nx_scaled=scaler.fit(rfm1)\nx_scaled = scaler.fit_transform(rfm1)\nx_scaled","1f89869e":"model = KMeans()\nvisualizer = KElbowVisualizer(model, k=(1,12))\nvisualizer.fit(x_scaled)  \nvisualizer.show()   ","aac25d54":"kmeans_scaled = KMeans(3)\nkmeans_scaled.fit(x_scaled)\nidentified_clusters = kmeans_scaled.fit_predict(rfm1)\nclusters_scaled = rfm1.copy()\nclusters_scaled['cluster_pred']=kmeans_scaled.fit_predict(x_scaled)\nprint(identified_clusters)\nsns.set(style=\"darkgrid\")\nprint(\" Our cluster centers are as follows\")\nprint(kmeans_scaled.cluster_centers_)\nf, ax = plt.subplots(figsize=(25, 5))\nax = sns.countplot(x=\"cluster_pred\", data=clusters_scaled)\nclusters_scaled.groupby(['cluster_pred']).count()","fca375e1":"fig = plt.figure()\nax = plt.axes(projection='3d')\nxline=clusters_scaled['recency']\nyline=clusters_scaled['frequency']\nzline=clusters_scaled['monetary']\n\nax.scatter3D(xline, zline,yline,c=clusters_scaled['cluster_pred'])\nax.view_init(30, 60)","47e18958":"from sklearn.metrics import silhouette_samples, silhouette_score\nsil_score = silhouette_score(x_scaled, kmeans_scaled.labels_, metric='euclidean')\nprint('Silhouette Score: %.3f' % sil_score)\n\nfrom yellowbrick.cluster import SilhouetteVisualizer\nmodel = KMeans(3)\nvisualizer = SilhouetteVisualizer(model)\nvisualizer.fit(x_scaled)   \nvisualizer.poof()   \n   ","dee93732":"rfm1['cluster']= clusters_scaled['cluster_pred']\nrfm1['level']=rfm['level']\n\nrfm1.groupby('cluster').agg({\n    'recency' : ['mean','min','max'],\n    'frequency' : ['mean','min','max'],\n    'monetary' : ['mean','min','max','count']\n})","c920d033":"rfm1.head()","fa14d7c8":"rfm1.groupby(['cluster','level']).size()","7d57f7fa":"rfm_scaled=pd.DataFrame()\nrfm_scaled=rfm1.copy()\nscaler=StandardScaler()\nrfm_scaled[['recency', 'frequency','monetary']] = scaler.fit_transform(rfm_scaled[['recency', 'frequency','monetary']])\nrfm_scaled['cust_id']=rfm1.index","2e8cc083":"rfm_scaled.head()","4522f23d":"rfm_melted = pd.melt(frame= rfm_scaled, id_vars= ['cust_id', 'level', 'cluster'], var_name = 'metrics', value_name = 'value')\nrfm_melted.head()","7eb8eab1":"sns.lineplot(x = 'metrics', y = 'value', hue = 'level', data = rfm_melted)\nplt.title('Snake Plot of RFM')\nplt.legend(loc = 'upper right')\n","ce99ff85":"sns.lineplot(x = 'metrics', y = 'value', hue = 'cluster', data = rfm_melted)\nplt.title('Snake Plot of Clusters')\nplt.legend(loc = 'upper right')","c1315b5a":"### Saving in separate excel file","ecb89e9f":"# **RFM Segmentation**","09aaeb6d":"### **Finding unique values**","22e1e229":"The customers having a score of '15' are considered as the 'best customers' as they have have the highest recency, frequency and monetary score.\n\nThey are asset to the company.","7b9ac6dd":"1079 customers have bought 939.92 units by shopping thrice every 70 days\n\nThey are loyal customers.","e2a83afe":"We made two kinds of segmentation, RFM quantiles and K-Means clustering methods.\n\nCustomers have been categorized into 4 buckets based on Recency, Frequency and Monetary value of their purchases. Targeted strategy to be applied for each customer segment.\n\nWith the result,\n\n* We figured out \u2018best\u2019 customers, the most profitable group.\n* This also tells us on which customer group we should focus on and to whom to give special offers or promotions among the customers.\n* We can select the best communication channel for each segment and improve new marketing strategies.","60df9c8c":"## K Means","ef6313ea":"## Conclusion","4df47a89":"### Observations","be5e201c":"### Changing the column names","3d4dbb68":"### Average customers","b38f9a9f":"We are going to **seggregate** the level of the customer **based on the score**.\n\nHere we have classified them into **4 levels**.\n\n**Active** : High revenue generating and frequent buyers .\n\n**Good**: Customers whose purchases are fairly frequent and generate moderate revenue.\n\n**Average** : Customers who are less active and are not very frequent buyers and generate low revenue.\n\n**Inactive**: Customers generating very low revenue and are occasional buyers.","1eed706a":"To calculate the Recency value, we need to find the last invoice date in our dataset.","5534b30e":"### **Corelation Check**","c1cfbc25":"#### Outlier treatment for recency\n","d736ff33":"### Active Customers","ab906457":"### Nature of the cluster","6df29b4e":" We are saving the customers in separate files, so that it will be easy for the company to send relevent offers and messages to group of customers who belong to the same segment","37553ffe":"### Inactive customers","58a1a456":"### Good Customers","00177576":"### **Number of best customers** ","3ce38e28":"#### Looking at the RFM data\n","5746652b":"The variables are not corelated with each other.","0806805e":"#### Melting the dataframe","6dc54da4":"### Visualising number of customers for each level","ad4c092e":"### Best customers","6939330c":"With the help of score, we will be able to identify the best customers in our e-commerce company.","cab8806e":"![image.png](attachment:98f53269-60ee-4de6-843c-1fa23dce5fa9.png)","39c7b324":"There is **no negative** value in the dataset.","29d7de23":"##### Outlier treatment for monetary","5cec700c":"We need to assign a score from 1 to 5 to recency, frequency and monetary value individually for each customer.","a1dc72ec":"According to the Elbow method, the number of clusters is **3**.","5151d39d":"We can say that 1597 customers bought 4540.46 units by shopping 9 times approximately every 26 days.\n\nThey are previliged customers.\n\n\nSurprise offers can be given on birthdays and anniversary.","75d98f37":"We are going to apply **unsupervised machine learning** to identify different groups\/clusters based on segmentation of customers according to their purchasing behaviour.\n\n\nThe overall clusters will be based on the 3 factors - **recency, frequency and monetary values**","4f14ae9a":"We have a lot of customers without Customer ID.","155d0172":" Customer Segmentation is a practice of dividing a company's customers into groups that reflects the similarity among customers in each group. It can be done based on their needs, interests, priorities, by geography,etc.\n\n\nWith our dataset we are proceeding with RFM Segmentation.","5382cde9":"**Transforming** and storing the RFM values for plotting a snake plot.","208c16f9":" A big **Thank You** to all the Data Science aspirants across the globe who have shared their work in Kaggle. This has enhanced my coding skills and improved my understanding of Data Science concepts. I have used few excerpts of code in the above excercise as well.\n\n","36c6c107":"### Snake plot with clusters using K-Means","b5aa4e0f":"## **Seggregate the levels**","424dbf2e":"We are checking our dataset for null values.","2041d2e6":"202 customers have bought approximately 142.49 units by shopping once every 273 days.\n\n\nPersonalised emails and SMS can be sent to the customers regarding the offers.\n\nMore marketing strategies can be introduced to improve the frequency of orders.\n","48d85fc3":"## **RFM Analysis**","6d440281":"The first step in building an RFM model is to assign Recency, Frequency and Monetary values to each customer. So, RFM analysis can be carried out only on customers who have customerID.\n\n**RFM Metrics**\n\n**Recency**  : It is the amount of time since the customers most recent transaction. It is measured                 in days.\n \n**Frequency**: Total number of transactions made by the customer.\n \n**Monetary** : Total amount the customer has spent across all transactions.","c7d752c6":"## RFM Clustering","341d2d36":"### Transforming the data","968af24d":"### Validation","1c563593":"### Comparing RFM analysis and Clusters","79c2e69a":"# **Loading Packages**\n\nWe are loading the necessary packages for our code.","43692710":"### Visualizing against each of the factors ","2852ac82":"### Applying K-Means","0394755d":"There are 349 Best customers in the company who are frequent buyers and also generate high revenue.","c7f45461":"### Analysing each level\n\nTo understand each segment of customers better, we are going to deep dive on each segment. ","c408341b":"### **Calculate the score**","be29fcd1":"### **Dropping negative values**\n\nWe are dropping rows which has negative quantity and price. ","54d33e30":" From the above summary we get to know that,\n    \n- **Cluster 0** is the most valuable group of customers with **highest mean frequency** (purchase most often), **least mean recency** (has recently purchased from the company) and the **highest mean monetary** (high purchasing amount).\n    \n    \n- On the other hand, **Cluster 2** is the group of customers with **least frequency** and **monetary** and **recency values**.\n","3e772108":"# **Reading the data**\nWe are reading the excel file.","721528af":"We will use Silhoutte score to validate our clusters.","198f545e":"Below is the **conversion** of columns into rfm scores between 1 to 5. \n\n**'5'** being the **highest** and **'1'** being the **least**.\n\n- The higher the **monetary** value, higher is the score ie,'5' . \n\n\n- Smaller value of **recency** indicates recent purchases, so it takes the higher value of 5. \n\n\n- Frequency is the same as monetary, higher the **frequency**, higher the score.","2e724b07":"#### Checking outliers","4be7c1a9":"### Snake plot based on RFM segmentation","ece075e8":"#### Outlier treatment for frequency","c4ca9fcf":"We need to check whether the predicted clusters are **homogeneous** or **heterogeneous** in nature.","567635a0":"#### Elbow method","1ebaaec8":"### **Removing duplicates**\n\nWe are removing duplicated data from our dataset.","f087fbc7":"1434 customers have bought approximately 939.92 units by shopping once every 151 days.\n\nTiered pricing of products can be introduced.","3fc66f79":"## **Data Preprocessing**\n\n\n### **Null Value Check**","f2f75def":"### Segmenting customers based on their levels","ca87648c":"**Cluster 1** is **heterogenous** in nature. It comprises **Active, Average and Good customers**.\n\n**Cluster 0** is **homogeneous** in nature and has **Active customers** in majority.\n ","cbc3e572":"We are going to **determine the number of clusters** using Elbow method.","556236bc":"### Visualizing the clusters","6f2375da":"From the above bar graph, we can infer that\n* There are only few Inactive customers in the online retail store when compared to the other levels.\n* It is good to notice that there are more number of Active customers.","a9649eb7":"When we look into the features Quantity and Price,\n\n* We can see the negative values, which indicates returned product\n* Also, comparing the 75% and the max values, we can clearly see the presence of outliers in the data.","52fc17a6":"# **Checking the data**\n\nTo know more about our dataset, we are running few lines of code to check the **dimensions** of our dataset, **data types** of the variables and **basic infomation** about the variables.","05d25f4a":"### Cluster Profiling\n\nWe are going to analyse and understand our clusters."}}