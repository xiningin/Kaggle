{"cell_type":{"be7e7a05":"code","91c685b2":"code","afe5701d":"code","21d723c5":"code","86f8084a":"code","79dcef6f":"code","1ce0ed89":"code","5ca39e77":"code","77d38c77":"code","e3f3c9e0":"code","8677fd8e":"code","2500e369":"code","ad76cfda":"code","db4bf5dc":"code","ef75603c":"code","f00d4b27":"code","5432845e":"code","fffc8f6b":"code","eb2945a2":"code","f3911af9":"code","8cfec3a8":"code","25571a9d":"code","f1a6da0b":"code","82272de4":"code","7948627a":"code","b8054d01":"code","180b587a":"code","fc47e814":"code","f566920a":"code","777c997f":"code","4e93b3c5":"code","10c524cf":"code","2e4f9ddf":"markdown","5940f6e9":"markdown","348e44a0":"markdown","bdeb4dcd":"markdown","d899d706":"markdown","449a003e":"markdown"},"source":{"be7e7a05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91c685b2":"df_mat=pd.read_csv('\/kaggle\/input\/student-performance-data-set\/student\/student-mat.csv',sep=';')\ndf_por=pd.read_csv('\/kaggle\/input\/student-performance-data-set\/student\/student-por.csv',sep=';')","afe5701d":"df_mat","21d723c5":"df_por","86f8084a":"df_mat.info()","79dcef6f":"for i in df_mat.columns:\n    print(df_mat[i].value_counts())","1ce0ed89":"result = df_mat.select_dtypes(include='number')","5ca39e77":"for i in result.columns:\n    percentile25 = df_mat[i].quantile(0.25)\n    percentile75 = df_mat[i].quantile(0.75)\n    \n    iqr = percentile75-percentile25\n    \n    upper_limit = percentile75 + 1.5 * iqr\n    lower_limit = percentile25 - 1.5 * iqr\n    \n    df_mat[df_mat[i] > upper_limit]\n    df_mat[df_mat[i] < lower_limit]\n    \n    df = df_mat[df_mat[i] < upper_limit ]\n    df = df_mat[df_mat[i] > lower_limit ]\n    \n","77d38c77":"df","e3f3c9e0":"df_mat.columns","8677fd8e":"col=['schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n       'higher', 'internet', 'romantic']\ndic={'no':0,'yes':1}\n\nfor i in col:\n    \n    df_mat[i]=df_mat[i].map(dic)","2500e369":"df.corr()['G3'].sort_values()","ad76cfda":"df.drop(columns=['schoolsup','health','Dalc','Walc','famsup','freetime'],inplace=True)","db4bf5dc":"df.drop(columns=['nursery','romantic'],inplace=True)","ef75603c":"df","f00d4b27":"df=df.drop(columns=['Mjob','Fjob','school'])","5432845e":"df.reason.value_counts()","fffc8f6b":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndf.address=le.fit_transform(df.address)\ndf.sex=le.fit_transform(df.sex)\ndf.famsize=le.fit_transform(df.famsize)\ndf.Pstatus=le.fit_transform(df.Pstatus)\ndf.paid=le.fit_transform(df.paid)\ndf.activities=le.fit_transform(df.activities)\ndf.higher=le.fit_transform(df.higher)\ndf.internet=le.fit_transform(df.internet)\n","eb2945a2":"df.guardian=le.fit_transform(df.guardian)","f3911af9":"df.corr()['G3'].sort_values()","8cfec3a8":"df.drop(columns=['studytime','famsize','famrel','absences','activities','Pstatus','guardian'],inplace=True)","25571a9d":"df","f1a6da0b":"## one hot encoding the 'Location' column\ndummies = pd.get_dummies(df['reason'])\ndf = pd.concat([df,dummies], axis='columns')\ndf.drop('reason', axis=1, inplace=True)","82272de4":"df.corr()['G3'].sort_values()","7948627a":"df.drop(columns=['course','home','other','reputation'],inplace=True)","b8054d01":"from sklearn.model_selection import train_test_split\nX=df.drop('G3',axis=1)\nY=df.G3\n\nx_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = .25, random_state = 111)","180b587a":"X.columns","fc47e814":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\nRF=RandomForestRegressor(max_depth=100)\nmodel=RF.fit(x_train,y_train)","f566920a":"y_pred=model.predict(x_test)","777c997f":"from sklearn.metrics import explained_variance_score\n\nexplained_variance_score( y_pred,y_test)","4e93b3c5":"def predict_price(sex, age, address, Medu, Fedu, traveltime, failures,\n       paid, higher, internet, goout, G1, G2):\n   \n    x = np.zeros(len(X.columns))\n    x[0] = sex \n    x[1] = age\n    x[2] = address \n    x[3] = Medu \n    x[4] = Fedu\n    x[5] = traveltime \n    x[6] = failures\n    x[7] =paid\n    x[8] = higher \n    x[9] = internet\n    x[10] =  goout\n    x[11] =  G1\n    x[12] =  G2\n    \n    \n    \n    return model.predict([x])[0]","10c524cf":"predict_price(1,17, 1, 1,1,1, 1,\n       0,1, 1,4, 4,1)","2e4f9ddf":"# On client Demand","5940f6e9":"* schoolsup    -0.082788\n* health       -0.061335\n* Dalc         -0.054660\n* Walc         -0.051939\n* famsup       -0.039157\n* freetime      0.011307\n\n**These features are having very less correlation, Lets drop them**","348e44a0":"* Correlation","bdeb4dcd":"# Removing Outliers,if any","d899d706":"# Data is imbalanced, We will use Tree based models","449a003e":"1. **See value counts of F job and M job ,'other' is almost equal or greater than rest of value. and here other is generic value. For betterment lets drop these columns**\n\n2. **We should also drop school as out of 2 school, 1 has 70% more enrollement**\n"}}