{"cell_type":{"c8344243":"code","3e8b0420":"code","a6b16819":"code","430118c6":"code","e503843b":"code","00baf490":"code","d56af677":"markdown","e6cdf5a1":"markdown","e28ab7a5":"markdown","912f6837":"markdown","3385bed7":"markdown","8ba67e5a":"markdown","98815d24":"markdown","33d1e280":"markdown","e26025b7":"markdown","17760cba":"markdown","de6d0ba6":"markdown","ffb282ce":"markdown","4929611f":"markdown","b246cdb3":"markdown","5b2cf31a":"markdown","2fa07b03":"markdown","0db50f78":"markdown","47144c54":"markdown","3c149313":"markdown","068da84a":"markdown","2d7d4464":"markdown","349658d0":"markdown","13bd2578":"markdown","09acc7d1":"markdown","da705e2a":"markdown","28bd8a1c":"markdown","4f822211":"markdown"},"source":{"c8344243":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e8b0420":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.datasets import make_blobs","a6b16819":"centers = [[1, 1], [-1, -1], [1, -1]]\nX, y = make_blobs(n_samples=100, centers=centers,random_state=2,cluster_std=0.2)\nfig,ax = plt.subplots(figsize=(10,10))\nplt.xlabel('X1',fontsize=20)\nplt.ylabel('X2',fontsize=20)\nax.set_title(\"Actual Data(3 clusters)\",fontsize=30)\nax.scatter(X[:,0],X[:,1],c=y,s=50,cmap = 'spring');","430118c6":"eps = 1\nminpts = 3\nD = X\n\ndef update_labels(X,pt,eps,labels,cluster_val):\n    neighbors = []\n    label_index = []\n    for i in range(X.shape[0]):\n        if np.linalg.norm(X[pt]-X[i])<eps:\n            neighbors.append(X[i])\n            label_index.append(i)\n    if len(neighbors) <minpts:\n        for i in range(len(labels)):\n            if i in label_index:\n                labels[i]=-1\n    else:\n        for i in range(len(labels)):\n            if i in label_index:\n                labels[i]=cluster_val\n    return labels\n\nlabels = [0]*X.shape[0]\nC = 1\nfor p in range(X.shape[0]):\n    if labels[p]==0:\n        labels = update_labels(X,p,eps,labels,C)\n        C= C+1\n        \nfig,ax = plt.subplots(figsize=(10,10))\nplt.xlabel('X1',fontsize=20)\nplt.ylabel('X2',fontsize=20)\nax.set_title(\"DBSCAN clustered data (self-implementation)\",fontsize=30)\nax.scatter(X[:,0],X[:,1],c=labels,s=50,cmap = 'winter');","e503843b":"from sklearn.cluster import DBSCAN\n\ndbscan = DBSCAN(eps = 0.6).fit(X)\ndbscanlabels = dbscan.labels_\nfig,ax = plt.subplots(figsize=(10,10))\nplt.xlabel('X1',fontsize=20)\nplt.ylabel('X2',fontsize=20)\nax.set_title(\"DBSCAN clustered data (Using sklearn library)\",fontsize=30)\nax.scatter(X[:,0],X[:,1],c=dbscanlabels,s=50,cmap = 'Wistia');","00baf490":"from sklearn import metrics\nprint(\"Silhouette score: {:.2f}%\".format(metrics.silhouette_score(X,labels)*100))","d56af677":"* Divides the dataset into n dimensions.\n* Takes a random point p\n* Finds its neighbour points\n* If Neighbour(p){not member of any other cluster}>=MinPts i.e. p is a core point then forms a cluster,if not then moves to another point\n* Marks points in low density area as noise or outliers","e6cdf5a1":"DBSCAN(dataset, eps, MinPts){\n\nC = 1\n\nfor each unvisited point p in dataset {\n\n         mark p as visited\n         # find neighbors\n         Neighbors N = find the neighboring points of p\n\n         if |N|>=MinPts:\n             N = N U N'\n             if p' is not a member of any cluster:\n                 add p' to cluster C \n}","e28ab7a5":"* DBSCAN does not work well when dealing with clusters of varying densities. \n* DBSCAN also does not work well when dealing with multi-dimensional dataset.","912f6837":"# Applications","3385bed7":"# Parameters","8ba67e5a":"Density-based spatial clustering of applications with noise (DBSCAN) is a well-known data clustering algorithm that is commonly used in data mining and machine learning.DBSCAN groups together points that are close to each other based on a distance measurement (usually Euclidean distance) and a minimum number of points.It also marks as outliers the points that are in low-density regions.","98815d24":"* Silhouette Score\n* Inertia(More often used in other clustering methods like k-means)","33d1e280":"* Anomaly detection in temperation data\n* Image of satellite\n* Scientific literature\n* Crystallography of x-ray\n* Others...","e26025b7":"**Using scikit-learn**","17760cba":"# Data Points","de6d0ba6":"# Algorithm","ffb282ce":"![How DBSCAN algorithm actually works(visualization)](https:\/\/miro.medium.com\/proxy\/1*tc8UF-h0nQqUfLC8-0uInQ.gif)","4929611f":"**Generating 2-dmensional test dataset**","b246cdb3":"# Metrics for measuring DBSCAN model's performance","5b2cf31a":"# Implementation","2fa07b03":"* DBSCAN is great at separating clusters of high density versus clusters of low density within a given dataset.\n* It is great with handling outliers within the dataset.\n* We do not need to specify numbers of clusters.","0db50f78":"# DBSCAN","47144c54":"![Data points and parameters](https:\/\/miro.medium.com\/max\/1000\/1*zbm_3K647rvNDmgL6HWUNQ.png)","3c149313":"# Computational Complexity","068da84a":"* O(n^2), where n is number of dataset objects\n* O(nlogn) when we use spatial index\n\nDBSCAN works well for even arbitrary-shape clusters.But it is computationally expensive on larger dataset.","2d7d4464":"**Self implementation**","349658d0":"# Pseudocode","13bd2578":"This is an average score.We can get a better model using hyper parameter tuning...","09acc7d1":"# Advantages","da705e2a":"* Core Point: A point is a core point if it has more than MinPts points within eps.\n* Border Point: A point which has fewer than MinPts within eps but it is in the neighborhood of a core point.\n* Noise or outlier: A point which is not a core point or border point.","28bd8a1c":"# Disadvantages","4f822211":"epsom(eps) : It defines the neighborhood around a data point.\n\nMinPts: Minimum number of neighbors (data points) within eps radius.As a general rule, the minimum MinPts can be derived from the number of dimensions D in the dataset as, MinPts >= D+1. The minimum value of MinPts must be chosen at least 3."}}