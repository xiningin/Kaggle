{"cell_type":{"b7099005":"code","dd5dd80c":"code","85aea5d1":"code","4b3ac97e":"code","342b6457":"code","a0e8d92a":"code","b8db4936":"code","53fd8cf1":"code","fd42e972":"code","3d92a1b3":"code","f43327f6":"code","bc143b7a":"code","add2283f":"code","83f43852":"code","f0c2a8d2":"code","8208941f":"code","dc9384f7":"code","82e92ed8":"code","04b5fb13":"code","475e5671":"code","5eb0b283":"code","eaa7297f":"code","f5e4a4b0":"code","a136af8c":"code","1911c2d0":"code","a3d56ac7":"code","91040e5e":"code","45984458":"code","1510cd09":"code","1f7ee56c":"markdown","5710d6fe":"markdown","3cd05827":"markdown","71f87684":"markdown","664bf71d":"markdown","c647fd61":"markdown","73ca6175":"markdown","66110e65":"markdown","a0c6d20f":"markdown","9bd72ff1":"markdown","bf211297":"markdown","bee93691":"markdown","5bdfcd67":"markdown","0bdc85d3":"markdown","d2816a83":"markdown","6897698b":"markdown","f5f63e17":"markdown","959df42f":"markdown","7e75a0fe":"markdown","55c44707":"markdown","5ec79a3d":"markdown","5fd33183":"markdown","2c27526f":"markdown"},"source":{"b7099005":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd5dd80c":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","85aea5d1":"from keras.datasets import mnist\n\nfrom keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","4b3ac97e":"df=pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_RGB.csv')","342b6457":"df.shape","a0e8d92a":"df.head()","b8db4936":"df.label.value_counts()","53fd8cf1":"n_samples = len(df.index)\nimages = np.array(df.drop(['label'],axis=1))\nimages = images.reshape(n_samples,28,28,3)","fd42e972":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(df.label[i])","3d92a1b3":"y = df['label']\nX = df.drop(['label'] , axis=1)","f43327f6":"X = X\/255","bc143b7a":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","add2283f":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(200,60))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","83f43852":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","f0c2a8d2":"pd.crosstab(y_test, y_mlp, rownames=['Reel'], colnames=['Prediction'], margins=True)","8208941f":"from keras.utils.np_utils import to_categorical","dc9384f7":"print(y[0])\ny_cat = to_categorical(y)\nprint(y_cat[0])","82e92ed8":"num_classes = y_cat.shape[1]\nprint(num_classes)","04b5fb13":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=1)","475e5671":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","5eb0b283":"from keras.models import Sequential\nfrom keras.layers import Dense","eaa7297f":"model = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(60, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","f5e4a4b0":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","a136af8c":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=30, verbose=1)","1911c2d0":"model.evaluate(X_test,y_test)","a3d56ac7":"print(train.history['accuracy'])","91040e5e":"print(train.history['val_accuracy'])","45984458":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","1510cd09":"plot_scores(train)","1f7ee56c":"On s\u00e9pare train et test :","5710d6fe":"# MNIST","3cd05827":"On d\u00e9finit une fonction pour afficher un graphique des scores :","71f87684":"La matrice de confusion :","664bf71d":"On d\u00e9finit un mod\u00e8le \u00e0 deux couches cach\u00e9es de 200 et 60 neurones\nLa derni\u00e8re couche comporte 25 neurones (le nombre de classes) pour la classification :","c647fd61":"Pertinence :","73ca6175":"Comme l'activation d'un neurone donne une valeur (probabilit\u00e9) entre 0 ou 1, on code la cible (classes entre 0 et 24) sous la forme d'un vecteur de 0 ou 1 (one hot encoding) avec to_categorical :","66110e65":"On normalise les valeurs entre 0 et 1 :","a0c6d20f":"La variable train m\u00e9morise l'historique des scores sur l'ensemble d'apprentissage :","9bd72ff1":"et sur l'ensemble de validation :","bf211297":"S\u00e9paration train \/ test :","bee93691":"On convertit les lignes de pixels en matrices (images) :","5bdfcd67":"Pour Keras, il est n\u00e9cessaire d'avoir des tableaux et non des dataframes :","0bdc85d3":"On s\u00e9pare la cible et les caract\u00e9ristiques :\n","d2816a83":"On utilise une architecture en couches (mod\u00e8le Sequential), avec des couches denses :","6897698b":"Initialisations","f5f63e17":"Pertinence :","959df42f":"On affiche les 50 premiers :","7e75a0fe":"# R\u00e9seaux denses (sklearn)","55c44707":"On \"compile\" le mod\u00e8le, avec une categorical_crossentropy comme mesure de distance (distance probabiliste multi classes)","5ec79a3d":"# R\u00e9seaux denses (Keras\/Tensorflow)","5fd33183":"On utilise la m\u00e9thode MLPClassifier de sklearn pour utiliser un r\u00e9seau de neurones \u00e0 deux couches cach\u00e9es de 200 et 60 neurones :","2c27526f":"# DATASET"}}