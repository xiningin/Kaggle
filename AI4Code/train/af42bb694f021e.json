{"cell_type":{"cc558f04":"code","0b28a5c1":"code","dfbbdc5a":"code","f089098f":"code","09e2368c":"code","dabf2e45":"code","81e19c37":"code","51f566de":"code","48e27561":"code","65f0ad01":"code","4ad34f5f":"code","294f041a":"code","f0b13287":"code","f9ac8235":"code","ee86cdea":"code","7497ab79":"code","0f48a9fd":"code","9885b16a":"code","201e9f79":"code","6693cbdf":"code","55355a52":"code","001128d4":"code","f6dab4ef":"code","2de06ac8":"code","1d442f63":"code","0b15f4b8":"code","3b61478b":"code","5e7dc126":"code","f75c117d":"code","9604df7d":"code","9eefffba":"code","04e4e036":"code","0d8e08db":"code","00f8daad":"code","c9c8488a":"code","162cc252":"code","f663035c":"code","c7cc5b0d":"code","339c4a2a":"code","dafd86d1":"code","cc04075f":"code","f24fe264":"code","33d4dd2f":"code","6d633620":"code","fcb96983":"code","3a2eaea1":"code","12696c02":"code","7606ad6a":"code","abbbd210":"code","cb9a35de":"code","35830daa":"code","8e9ac7dd":"code","ee3c3948":"markdown","6051d3b1":"markdown","52c18285":"markdown","dca54419":"markdown","e262b718":"markdown","8b1c64f8":"markdown","88918a9e":"markdown","eb8467e2":"markdown"},"source":{"cc558f04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport gc\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import rankdata\n\nprint(os.listdir(\"..\/input\"))","0b28a5c1":"train = pd.read_csv(\"..\/input\/intercampusai2019\/train.csv\")\ntest = pd.read_csv(\"..\/input\/intercampusai2019\/test.csv\")\nprint(\"Number of rows and columns in train set :\",train.shape)\nprint(\"Number of rows and columns in test set :\",test.shape)","dfbbdc5a":"train.head()","f089098f":"test.head()","09e2368c":"sns.countplot(train['Promoted_or_Not'], palette='Set3')\n","dabf2e45":"train.Promoted_or_Not.value_counts()","81e19c37":"train.describe()","51f566de":"test.describe()\n","48e27561":"train.isnull().sum()","65f0ad01":"feats = [f for f in train.columns if f not in ['EmployeeNo','Promoted_or_Not']]\nfor i in feats:\n    print ('==' + str(i) + '==')\n    print ('train:' + str(train[i].nunique()\/train.shape[0]))\n    print ('test:' + str(test[i].nunique()\/test.shape[0]))","4ad34f5f":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","294f041a":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","f0b13287":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train[features].mean(axis=0),color=\"yellow\",kde=True,bins=50, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"red\", kde=True,bins=50, label='test')\nplt.legend()\nplt.show()","f9ac8235":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=0),color=\"red\", kde=True,bins=50, label='train')\nsns.distplot(test[features].std(axis=0),color=\"yellow\", kde=True,bins=50, label='test')\nplt.legend()\nplt.show()","ee86cdea":"correlations = train[features].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorrelations.head(10)","7497ab79":"correlations.tail(10)","0f48a9fd":"feats_target = [f for f in train.columns if f not in ['EmployeeNo']]\ncorrelations = train[feats_target].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorr = correlations[correlations['level_0']=='Promoted_or_Not']\ncorr.head()","9885b16a":"# creating a copy of train\ndata = train.copy()","201e9f79":"data.Promoted_or_Not.value_counts()","6693cbdf":"data.isnull().sum()\n# we have null values in the qualification tables lets clean that up","55355a52":"# so what i did here was fill in the null values in the qualification features with no qualification\ndata.Qualification = data.Qualification.fillna(\"no qualification\")\ntest.Qualification  = test.Qualification.fillna(\"no qualification\")","001128d4":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()","f6dab4ef":"data.head()","2de06ac8":"TARGET = np.array( list(data['Promoted_or_Not'].values) )\n","1d442f63":"data.shape","0b15f4b8":"TARGET.shape","3b61478b":"features = [x for x in data.columns if x not in [\"Promoted_or_Not\",\"EmployeeNo\"]]","5e7dc126":"# model.predict_proba(test)","f75c117d":"##what is happening here is that i am combinning both the train and test together\nntrain = data.shape[0]\nntest = test.shape[0]\n\nall_data = pd.concat((data, test)).reset_index(drop=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","9604df7d":"#feature engineering \nall_data[\"age\"] = all_data.Year_of_recruitment - all_data.Year_of_birth\nall_data.drop(\"Year_of_birth\", axis  = 1,inplace  = True)","9eefffba":"all_data.Channel_of_Recruitment.unique()","04e4e036":"# label encoding some of the categorical features\nall_data.Channel_of_Recruitment = pd.DataFrame(label.fit_transform(all_data.Channel_of_Recruitment))\nall_data.Division  =pd.DataFrame(label.fit_transform(all_data.Division))\nall_data.State_Of_Origin = pd.DataFrame(label.fit_transform(all_data.State_Of_Origin))","0d8e08db":"all_data.dtypes","00f8daad":"all_data.head()","c9c8488a":"all_data.drop('EmployeeNo',axis = 1,inplace =True)","162cc252":"#import geocoder\nall_data = pd.get_dummies(all_data)\n\n","f663035c":"# remove constant features\n[feat for feat in all_data.columns if all_data[feat].std() == 0]\n## no constant features :)\n","c7cc5b0d":"\n#Get the new dataset\ndata = all_data[:ntrain]\ntest = all_data[ntrain:]","339c4a2a":"test.head()","dafd86d1":"test.drop(\"Promoted_or_Not\",axis = 1,inplace = True)","cc04075f":"sample = pd.read_csv(\"..\/input\/intercampusai2019\/sample_submission2.csv\")\nsample.head()","f24fe264":"data.shape","33d4dd2f":"# splitting the training features into test and train for valisdation\nX= data.drop( 'Promoted_or_Not', axis = 1)\ny = data[\"Promoted_or_Not\"]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","6d633620":"# data =  data.drop(\"Promoted_or_Not\",axis =1)","fcb96983":"\nfrom catboost import CatBoostClassifier\nmodel=CatBoostClassifier(iterations=1000, depth=7, learning_rate=0.05,eval_metric=\"Accuracy\")\nmodel.fit(X_train,y_train)\n","3a2eaea1":"predictions  = model.predict(test).astype(int)","12696c02":"test = pd.read_csv(\"..\/input\/intercampusai2019\/test.csv\")\n","7606ad6a":"sample.head()","abbbd210":"sample.EmployeeNo = test.EmployeeNo","cb9a35de":"sample.Promoted_or_Not = predictions","35830daa":"sample.head()","8e9ac7dd":"sample.to_csv(\"low1.csv\",index = False)","ee3c3948":"BASIC DESCRIPTION","6051d3b1":"Distribution of mean and std","52c18285":"TARGET EXPLAORATION","dca54419":"# Reading the datasets","e262b718":"Missing Value Check\u00b6\n","8b1c64f8":"Feature Correlation","88918a9e":"Target and Feature Correlation\n","eb8467e2":"Uniqule Count Check\u00b6\n"}}