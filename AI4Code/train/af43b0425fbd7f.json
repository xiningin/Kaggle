{"cell_type":{"4d7e70b4":"code","f6b00110":"code","8d2ba3df":"code","06329794":"code","1c556d02":"code","b7fdb8b1":"code","af7bf766":"code","9f059d73":"code","c2b5df0b":"code","76391fca":"code","7da91ba6":"code","bcd13b45":"code","c76311a2":"code","bb24124c":"code","30c1409c":"code","1e2b7061":"code","84ac7e94":"code","7f4d9b90":"code","34bbc8c7":"code","12ffddc6":"code","7a62acaa":"code","d482af35":"code","d88e856c":"code","1ee7b893":"code","6a151219":"code","7917fc58":"code","62f7aa63":"code","1fb306c3":"markdown","5e71a05d":"markdown"},"source":{"4d7e70b4":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt\nimport seaborn as sns","f6b00110":"#sns.load_dataset('test.csv')\ntestdata = pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')\ntraindata = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\nsample = pd.read_csv('..\/input\/iba-ml1-mid-project\/sample_submission.csv')\ndata = pd.concat([traindata, testdata])\nprint(testdata.shape)\nprint(traindata.shape)\nprint(data.shape)","8d2ba3df":"traindata.head()","06329794":"print(testdata.columns)\nprint(traindata.columns)","1c556d02":"traindata.isnull().sum()","b7fdb8b1":"traindata.info()","af7bf766":"duplicates = traindata[traindata.duplicated()]\nduplicates\ntraindata_cln = traindata.drop_duplicates()\ntraindata_cln = traindata_cln.drop(columns=['Id'])","9f059d73":"import string as st\ntraindata_cln['defaulted_on_loan'] = traindata_cln['defaulted_on_loan'].astype('category')\ntraindata_cln.dropna(subset=['defaulted_on_loan'])\n#traindata_cln['credit_line_utilization']= traindata_cln['credit_line_utilization'].replace(',', '.')\ntraindata_cln.loc[:, ['credit_line_utilization']] = traindata_cln['credit_line_utilization'].astype(str).str.replace(',', '.', regex=True).astype(np.float64)\nfloat_cols = traindata_cln.loc[:, traindata_cln.dtypes == np.float64]\nint_cols = traindata_cln.loc[:, traindata_cln.dtypes == np.int64]\nnum_cols = float_cols+int_cols\ncat_cols = traindata_cln.loc[:, traindata_cln.dtypes == np.object]\nprint(num_cols.columns)\nprint('======================')\nprint(int_cols.columns)\nprint('======================')\nprint(float_cols.columns)\nprint('======================')\nprint(cat_cols.columns)\nprint('======================')\nprint(traindata_cln[['credit_line_utilization']].head(28))","c2b5df0b":"from sklearn.impute import SimpleImputer as simp\nfrom sklearn.impute import SimpleImputer \nimputer=SimpleImputer(missing_values=np.nan,strategy='mean')\nimputer=imputer.fit(float_cols)\ntraindata_cln.loc[:, traindata_cln.dtypes == np.float64]=imputer.transform(float_cols)\n\n#from sklearn.impute import SimpleImputer as simp\n#from sklearn.impute import SimpleImputer \n#imputer=SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n#imputer=imputer.fit(cat_cols)\n#traindata_cln.loc[:, traindata_cl.dtypes == np.object]=imputer.transform(cat_cols)\n\ntraindata_cln.isnull().sum()\n","76391fca":"traindata_cln['defaulted_on_loan'] ","7da91ba6":"traindata_cln[['credit_line_utilization']]","bcd13b45":"from sklearn.preprocessing import StandardScaler\nStandardScaler(with_mean=0, with_std=1).fit_transform(traindata_cln)","c76311a2":"y_train = traindata_cln['defaulted_on_loan'] \nx_train = traindata_cln[traindata_cln.columns.drop('defaulted_on_loan')]\nprint(x_train.shape)\nprint('==============================================')\nprint(y_train.shape)","bb24124c":"# identify outliers in the training dataset\nfrom sklearn.ensemble import IsolationForest\niso = IsolationForest(contamination=0.1)\nyhat = iso.fit_predict(x_train)","30c1409c":"from sklearn.model_selection import train_test_split\nxtr_train, xtr_test, ytr_train, ytr_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)","1e2b7061":"duplicates = testdata[testdata.duplicated()]\nduplicates\ntestdata_cln = testdata.drop_duplicates()\ntestdata_cln = testdata_cln.drop(columns=['Id'])","84ac7e94":"testdata_cln.isnull().sum()","7f4d9b90":"testdata_cln.loc[:, ['credit_line_utilization']] = testdata_cln['credit_line_utilization'].astype(str).str.replace(',', '.', regex=True).astype(np.float64)\nfloat_colst = testdata_cln.loc[:, traindata_cln.dtypes == np.float64]\nint_colst = testdata_cln.loc[:, testdata_cln.dtypes == np.int64]\nnum_colst = float_colst+int_colst\ncat_colst = testdata_cln.loc[:, testdata_cln.dtypes == np.object]\nprint(num_colst.columns)\nprint('======================')\nprint(int_colst.columns)\nprint('======================')\nprint(float_colst.columns)\nprint('======================')\nprint(cat_colst.columns)\nprint('======================')\nprint(testdata_cln[['credit_line_utilization']].head(28))","34bbc8c7":"from sklearn.impute import SimpleImputer as simp\nfrom sklearn.impute import SimpleImputer \nimputer=SimpleImputer(missing_values=np.nan,strategy='mean')\nimputer=imputer.fit(float_colst)\ntestdata_cln.loc[:, testdata_cln.dtypes == np.float64]=imputer.transform(float_colst)\n\n\ntestdata_cln.isnull().sum()","12ffddc6":"from sklearn.preprocessing import StandardScaler\nStandardScaler(with_mean=0, with_std=1).fit_transform(testdata_cln)","7a62acaa":"#y_test = testdata_cln['defaulted_on_loan'] \nx_test= testdata_cln\nprint(x_test.shape)\n","d482af35":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestClassifier\n# Instantiate model with 1000 decision trees\nrf = RandomForestClassifier(max_depth = 12, random_state = 20)\n# Train the model on training data\nrf.fit(xtr_train, ytr_train)","d88e856c":"y_tr_pred = rf.predict_proba(xtr_test)\n#y_tr_pred = (y_tr_pred >= 0.5).astype(np.float64)\ny_tr_pred = y_tr_pred[:,1:]\ny_tr_pred","1ee7b893":"from sklearn.metrics import accuracy_score, f1_score\n#accuracy_score(y_train, y_tr_pred)\n#f1_score(y_train, y_tr_pred)\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nlr_auc = roc_auc_score(ytr_test, y_tr_pred)\nlr_auc","6a151219":"y_pred = rf.predict_proba(x_test)\n#y_tr_pred = (y_tr_pred >= 0.5).astype(np.float64)\ny_pred = y_pred[:,1:]\ny_pred","7917fc58":"y_test_pred = pd.DataFrame(y_pred)\ny_test_pred.insert(0, 'Id', range(1, 1 + len(y_test_pred)))\ny_test_pred\ny_test_pred.columns = ['Id', 'Predicted']\ny_test_pred.reset_index(drop=True)\ny_test_pred.to_csv('ytestpred.csv', index = False)\nprint(y_test_pred)","62f7aa63":"# Import a module to display a link to the file\nfrom IPython.display import FileLink\n# Import a module to delete the file\nimport os\n# Create a download function\ndef csv_download_link(df, csv_file_name, delete_prompt=True):\n    \"\"\"Display a download link to load a data frame as csv within a Jupyter notebook\n\n    Parameters\n    ----------\n    df : pandas data frame\n    csv_file_name : str\n    delete_prompt : bool\n    \"\"\"\n    df.to_csv(csv_file_name, index=False)\n    display(FileLink(csv_file_name))\n    if delete_prompt:\n        a = input('Press enter to delete the file after you have downloaded it.')\n        os.remove(csv_file_name)\ncsv_download_link(y_test_pred, 'ytestpredrand.csv')","1fb306c3":"# Model","5e71a05d":"# Test data"}}