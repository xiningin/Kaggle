{"cell_type":{"3962e173":"code","db3aca81":"code","50a69fe6":"code","87e1a8cf":"code","ba05c508":"code","bdcfca42":"code","d13e3498":"code","a24c58db":"code","0612f9dd":"code","c119eab3":"code","7f229dcb":"code","c1ac6512":"code","f8ec3b80":"code","4cc1860a":"code","9966f66c":"code","b59dbe1e":"code","67abd242":"code","da43026c":"code","553b4a9e":"code","1c6ea193":"code","1647b367":"code","8c63216e":"code","c5e6ba5e":"code","9f516593":"markdown","4bb822ec":"markdown","bb666967":"markdown","266583d1":"markdown","8cf0f915":"markdown","6e35d150":"markdown","9d5eb387":"markdown","34533417":"markdown","c2a1bd17":"markdown","4bc5f06a":"markdown","c1710105":"markdown","2094b87e":"markdown","1d94b2ed":"markdown","ba2218cf":"markdown","df40daf4":"markdown","eaf08617":"markdown","b58fb79f":"markdown","b6c3f89c":"markdown","f78f17f7":"markdown","211bd711":"markdown","c4d471cf":"markdown"},"source":{"3962e173":"# import packages\nimport os\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib import ticker\nimport seaborn as sns\n\n# setting up options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nwarnings.filterwarnings('ignore')\n\n# import datasets\ntrain_df = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\n\ntrain_df['date_time'] = pd.to_datetime(train_df['date_time'])\ntest_df['date_time'] = pd.to_datetime(test_df['date_time'])","db3aca81":"train_df.head()","50a69fe6":"print(f'Number of rows: {train_df.shape[0]};  Number of columns: {train_df.shape[1]}; No of missing values: {sum(train_df.isna().sum())}')","87e1a8cf":"train_df.dtypes","ba05c508":"train_df.describe()","bdcfca42":"test_df.head()","d13e3498":"print(f'Number of rows: {test_df.shape[0]};  Number of columns: {test_df.shape[1]}; No of missing values: {sum(test_df.isna().sum())}')","a24c58db":"test_df.dtypes","0612f9dd":"test_df.describe()","c119eab3":"features = [feature for feature in train_df.columns if feature not in [\"date_time\", \"target_carbon_monoxide\", \n                                                                       \"target_benzene\", \"target_nitrogen_oxides\"]]\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(6, 6), facecolor='#f6f5f5')\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.2, hspace=0.25)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 3):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    sns.kdeplot(test_df[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#287094', alpha=0.95, linewidth=0, zorder=2)\n    sns.kdeplot(train_df[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#fcd12a', alpha=0.95, linewidth=0, zorder=2)\n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    run_no += 1\n    \nax0.text(-10, 0.086, 'Features Distribution', fontsize=8, fontweight='bold')\nax0.text(-10, 0.081, 'Features comparison between train and test dataset', fontsize=5)\nfig.legend(['test', 'train'], ncol=2, facecolor=background_color, edgecolor=background_color, fontsize=4, bbox_to_anchor=(0.24, 0.91))\n    \nax8.remove()","7f229dcb":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10,8), facecolor='#f6f5f5')\ngs = fig.add_gridspec(8, 1)\ngs.update(wspace=0, hspace=1.5)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 8):\n    for col in range(0, 1):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    sns.lineplot(ax=locals()[\"ax\"+str(run_no)], y=train_df[col], x=train_df['date_time'], color='#fcd12a')\n    sns.lineplot(ax=locals()[\"ax\"+str(run_no)], y=test_df[col], x=test_df['date_time'], color='#287094')\n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    spring = np.arange(np.datetime64(\"2010-03-10\"), np.datetime64(\"2010-06-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(spring, np.max(train_df[col]), color='#ff69b4', alpha=0.2, zorder=2, linewidth=0)\n    summer = np.arange(np.datetime64(\"2010-06-01\"), np.datetime64(\"2010-09-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(summer, np.max(train_df[col]), color='#fcd12a', alpha=0.2, zorder=2, linewidth=0)\n    autumn = np.arange(np.datetime64(\"2010-09-01\"), np.datetime64(\"2010-12-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(autumn, np.max(train_df[col]), color='#ff9200', alpha=0.2, zorder=2, linewidth=0)\n    winter = np.arange(np.datetime64(\"2010-12-01\"), np.datetime64(\"2011-03-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(winter, np.max(train_df[col]), color='#287094', alpha=0.2, zorder=2, linewidth=0)\n    spring_2 = np.arange(np.datetime64(\"2011-03-01\"), np.datetime64(\"2011-04-05\"))\n    locals()[\"ax\"+str(run_no)].fill_between(spring_2, np.max(train_df[col]), color='#ff69b4', alpha=0.2, zorder=2, linewidth=0)\n    run_no += 1\n    \nax0.text(14660, 80, 'Time Series', fontsize=8, fontweight='bold')\nax0.text(14660, 65, 'Showing time series data starting from train dataset followed by test dataset', fontsize=5)\nfig.legend(['test', 'train'], ncol=2, facecolor=background_color, edgecolor=background_color, fontsize=4, bbox_to_anchor=(0.2, 0.895))\n\nplt.show()","c1ac6512":"train_df['train_test'] = 'train'\ntest_df['train_test'] = 'test'\ncombine_df = pd.concat([train_df, test_df], axis=0)\ncombine_df['month'] = combine_df['date_time'].dt.month\n\ntrain_df = train_df.drop('train_test', axis=1)\ntest_df = test_df.drop('train_test', axis=1)\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10,20), facecolor='#f6f5f5')\ngs = fig.add_gridspec(8, 1)\ngs.update(wspace=0, hspace=0.5)\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#fcd12a', '#287094'])\n\nrun_no = 0\nfor row in range(0, 8):\n    for col in range(0, 1):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    sns.violinplot(ax=locals()[\"ax\"+str(run_no)], y=combine_df[col], x=combine_df['month'],hue=combine_df['train_test'], \n                   split = True, saturation=1, linewidth=1, inner=\"quartile\", legend=False, zorder=2)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].set_axisbelow(True) \n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize = 8)\n    locals()[\"ax\"+str(run_no)].get_legend().remove()\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=8, width=0.5, length=1.5)\n    run_no += 1\n    \nax0.text(-0.5, 70, 'Monthly Distribution', fontsize=10, fontweight='bold')\nax0.text(-0.5, 63, 'Showing features monthly distribution on train and test dataset (months are in number)', fontsize=8)\nax0.legend(ncol=2, facecolor=background_color, edgecolor=background_color, fontsize=7, bbox_to_anchor=(0.16, 1.19))\n\nplt.show()","f8ec3b80":"targets = [\"target_carbon_monoxide\", \"target_benzene\", \"target_nitrogen_oxides\"]\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(5, 1), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 3)\ngs.update(wspace=0.2, hspace=0.5)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 1):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in targets:\n    sns.kdeplot(train_df[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#fcd12a', alpha=0.95, linewidth=0, zorder=2)\n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    run_no += 1\n    \nax0.text(-1.2, 0.44, 'Target Distribution', fontsize=8, fontweight='bold')\nax0.text(-1.2, 0.40, 'Target variables are showing a lognormal distribution', fontsize=5)\n\nplt.show()","4cc1860a":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10,3), facecolor='#f6f5f5')\ngs = fig.add_gridspec(3, 1)\ngs.update(wspace=0, hspace=1)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 3):\n    for col in range(0, 1):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in targets:\n    sns.lineplot(ax=locals()[\"ax\"+str(run_no)], y=train_df[col], x=train_df['date_time'], color='#fcd12a')\n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    spring = np.arange(np.datetime64(\"2010-03-10\"), np.datetime64(\"2010-06-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(spring, np.max(train_df[col]), color='#ff69b4', alpha=0.2, zorder=2, linewidth=0)\n    summer = np.arange(np.datetime64(\"2010-06-01\"), np.datetime64(\"2010-09-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(summer, np.max(train_df[col]), color='#fcd12a', alpha=0.2, zorder=2, linewidth=0)\n    autumn = np.arange(np.datetime64(\"2010-09-01\"), np.datetime64(\"2010-12-02\"))\n    locals()[\"ax\"+str(run_no)].fill_between(autumn, np.max(train_df[col]), color='#ff9200', alpha=0.2, zorder=2, linewidth=0)\n    winter = np.arange(np.datetime64(\"2010-12-01\"), np.datetime64(\"2011-01-03\"))\n    locals()[\"ax\"+str(run_no)].fill_between(winter, np.max(train_df[col]), color='#287094', alpha=0.2, zorder=2, linewidth=0)\n    run_no += 1\n    \nax0.text(14663, 18, 'Time Series', fontsize=8, fontweight='bold')\nax0.text(14663, 15, 'Showing target time series data', fontsize=5)\n\nplt.show()","9966f66c":"chart_df = pd.DataFrame(train_df[features].corrwith(train_df['target_carbon_monoxide']))\nchart_df.columns = ['corr']\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(6, 1.5), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.4, hspace=0.1)\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#00A4CCFF']*6)\n\nax = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor(background_color)\nax_sns = sns.barplot(ax=ax, x=chart_df.index, y=chart_df['corr'], color='#fcd12a',\n                      zorder=2, linewidth=0, alpha=1, saturation=1)\nax_sns.set_xlabel(\"Features\",fontsize=4, weight='bold')\nax_sns.set_ylabel(\"Correlation\",fontsize=4, weight='bold')\nax_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.tick_params(labelsize=4, width=0.5, length=1.5)\nax.text(-0.5, 1.25, 'Carbon Monoxide', fontsize=6, ha='left', va='top', weight='bold')\nax.text(-0.5, 1.13, 'Correlation between carbon monoxide and feature values', fontsize=4, ha='left', va='top')\n# data label\nfor p in ax.patches:\n    percentage = f'{p.get_height():.2f}'\n    x = p.get_x() + p.get_width() \/ 2\n    y = p.get_height() + 0.05\n    ax.text(x, y, percentage, ha='center', va='bottom', fontsize=4,\n           bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\n\nplt.show()","b59dbe1e":"features = [feature for feature in train_df.columns if feature not in [\"date_time\", \"target_carbon_monoxide\", \n                                                                       \"target_benzene\", \"target_nitrogen_oxides\"]]\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(8, 8), facecolor='#f6f5f5')\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.2, hspace=0.25)\n\nbackground_color = \"#f6f5f5\"\ncmap = sns.light_palette('#fcd12a', as_cmap=True)\n\nrun_no = 0\nfor row in range(0, 3):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    locals()[\"ax\"+str(run_no)].hexbin(x=train_df[col], y=train_df['target_carbon_monoxide'], gridsize=15, \n                                      cmap=cmap, zorder=2, facecolor='black', mincnt=1)\n    locals()[\"ax\"+str(run_no)].set_ylabel('target_carbon_monoxide', fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    run_no += 1\n    \nax0.text(0, 14.5, 'Carbon Monoxide', fontsize=10, fontweight='bold')\nax0.text(0, 13.6, 'Hexabin plot between features and carbon monoxide', fontsize=7)\n\nax8.remove()","67abd242":"chart_df = pd.DataFrame(train_df[features].corrwith(train_df['target_benzene']))\nchart_df.columns = ['corr']\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(6, 1.5), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.4, hspace=0.1)\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#00A4CCFF']*6)\n\nax = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor(background_color)\nax_sns = sns.barplot(ax=ax, x=chart_df.index, y=chart_df['corr'], color='#fcd12a',\n                      zorder=2, linewidth=0, alpha=1, saturation=1)\nax_sns.set_xlabel(\"Features\",fontsize=4, weight='bold')\nax_sns.set_ylabel(\"Correlation\",fontsize=4, weight='bold')\nax_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.tick_params(labelsize=4, width=0.5, length=1.5)\nax.text(-0.5, 1.35, 'Benzene', fontsize=6, ha='left', va='top', weight='bold')\nax.text(-0.5, 1.2, 'Correlation between benzene and feature values', fontsize=4, ha='left', va='top')\n# data label\nfor p in ax.patches:\n    percentage = f'{p.get_height():.2f}'\n    x = p.get_x() + p.get_width() \/ 2\n    y = p.get_height() + 0.05\n    ax.text(x, y, percentage, ha='center', va='bottom', fontsize=4,\n           bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\n\nplt.show()","da43026c":"features = [feature for feature in train_df.columns if feature not in [\"date_time\", \"target_carbon_monoxide\", \n                                                                       \"target_benzene\", \"target_nitrogen_oxides\"]]\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(8, 8), facecolor='#f6f5f5')\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.2, hspace=0.25)\n\nbackground_color = \"#f6f5f5\"\ncmap = sns.light_palette('#fcd12a', as_cmap=True)\n\nrun_no = 0\nfor row in range(0, 3):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    locals()[\"ax\"+str(run_no)].hexbin(x=train_df[col], y=train_df['target_benzene'], gridsize=15, \n                                      cmap=cmap, zorder=2, facecolor='black', mincnt=1)\n    locals()[\"ax\"+str(run_no)].set_ylabel('target_benzene', fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    run_no += 1\n    \nax0.text(0, 75, 'Benzene', fontsize=10, fontweight='bold')\nax0.text(0, 70, 'Hexabin plot between features and benzene', fontsize=7)\n\nax8.remove()","553b4a9e":"chart_df = pd.DataFrame(train_df[features].corrwith(train_df['target_nitrogen_oxides']))\nchart_df.columns = ['corr']\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(6, 1.5), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.4, hspace=0.1)\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#00A4CCFF']*6)\n\nax = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor(background_color)\nax_sns = sns.barplot(ax=ax, x=chart_df.index, y=chart_df['corr'], color='#fcd12a',\n                      zorder=2, linewidth=0, alpha=1, saturation=1)\nax_sns.set_xlabel(\"Features\",fontsize=4, weight='bold')\nax_sns.set_ylabel(\"Correlation\",fontsize=4, weight='bold')\nax_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.tick_params(labelsize=4, width=0.5, length=1.5)\nax.text(-0.5, 0.95, 'Nitrogen Oxides', fontsize=6, ha='left', va='top', weight='bold')\nax.text(-0.5, 0.85, 'Correlation between nitrogen oxides and feature values', fontsize=4, ha='left', va='top')\n# data label\nfor p in ax.patches:\n    percentage = f'{p.get_height():.2f}'\n    x = p.get_x() + p.get_width() \/ 2\n    y = p.get_height() + 0.05\n    ax.text(x, y, percentage, ha='center', va='bottom', fontsize=4,\n           bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\n\nplt.show()","1c6ea193":"features = [feature for feature in train_df.columns if feature not in [\"date_time\", \"target_carbon_monoxide\", \n                                                                       \"target_benzene\", \"target_nitrogen_oxides\"]]\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(8, 8), facecolor='#f6f5f5')\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.2, hspace=0.25)\n\nbackground_color = \"#f6f5f5\"\ncmap = sns.light_palette('#fcd12a', as_cmap=True)\n\nrun_no = 0\nfor row in range(0, 3):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor col in features:\n    locals()[\"ax\"+str(run_no)].hexbin(x=train_df[col], y=train_df['target_nitrogen_oxides'], gridsize=15, \n                                      cmap=cmap, zorder=2, facecolor='black', mincnt=1)\n    locals()[\"ax\"+str(run_no)].set_ylabel('target_nitrogen_oxides', fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=5, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=5, width=0.5, length=1.5)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n    run_no += 1\n    \nax0.text(0, 1700, 'Nitrogen Oxides', fontsize=10, fontweight='bold')\nax0.text(0, 1600, 'Hexabin plot between features and nitrogen oxides', fontsize=7)\n\nax8.remove()","1647b367":"train_corr = train_df[features].corr()\ntest_corr = test_df[features].corr()\ndiff_corr = abs(train_corr - test_corr)\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10, 5), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 3)\ngs.update(wspace=0.5, hspace=0)\n\nbackground_color = \"#f6f5f5\"\ncmap_train = sns.dark_palette('#fcd12a', as_cmap=True)\ncmap_test = sns.dark_palette('#287094', as_cmap=True)\ncmap_diff = sns.dark_palette('#ff69b4', as_cmap=True)\n\nmask = np.triu(np.ones_like(train_corr, dtype=bool))\n\nrun_no = 0\nfor row in range(0, 1):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n        \nsns.heatmap(train_corr, ax=ax0, cmap=cmap_train, square=True, mask=mask, linewidths=.5, linecolor='#f6f5f5', \n            cbar_kws={\"shrink\": .3}, annot=True, annot_kws={\"fontsize\":4})\nax0.set_xlabel(col, fontsize=5, fontweight='bold')\nax0.tick_params(labelsize=5, width=0.5, length=1.5)\nax0.set_xlabel('Train Dataset', fontsize=5, fontweight='bold')\ncax = plt.gcf().axes[-1]\ncax.tick_params(labelsize=5)\n\nsns.heatmap(test_corr, ax=ax1, cmap=cmap_test, square=True, mask=mask, linewidths=.5, linecolor='#f6f5f5', \n            cbar_kws={\"shrink\": .3}, annot=True, annot_kws={\"fontsize\":4})\nax1.set_xlabel(col, fontsize=5, fontweight='bold')\nax1.tick_params(labelsize=5, width=0.5, length=1.5)\nax1.set_xlabel('Test Dataset', fontsize=5, fontweight='bold')\ncax = plt.gcf().axes[-1]\ncax.tick_params(labelsize=5)\n\nsns.heatmap(diff_corr, ax=ax2, cmap=cmap_diff, square=True, mask=mask, linewidths=.5, linecolor='#f6f5f5', \n            cbar_kws={\"shrink\": .3}, annot=True, annot_kws={\"fontsize\":4})\nax2.set_xlabel(col, fontsize=5, fontweight='bold')\nax2.tick_params(labelsize=5, width=0.5, length=1.5)\nax2.set_xlabel('Absolute Correlation Differences', fontsize=5, fontweight='bold')\ncax = plt.gcf().axes[-1]\ncax.tick_params(labelsize=5)\n\nax0.text(0, -0.8, 'Features Correlation', fontsize=10, fontweight='bold')\nax0.text(0, -0.2, 'Correlation between features in train and test dataset with their absolute correlation differences', fontsize=7)\n\nplt.show()","8c63216e":"targets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\nchart_df = train_df[targets].corr()\nchart_df","c5e6ba5e":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(8, 2), facecolor='#f6f5f5')\ngs = fig.add_gridspec(1, 3)\ngs.update(wspace=0.2, hspace=0.25)\n\nbackground_color = \"#f6f5f5\"\ncmap = sns.light_palette('#fcd12a', as_cmap=True)\n\nrun_no = 0\nfor row in range(0, 1):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\n\nax0.hexbin(x=train_df['target_carbon_monoxide'], y=train_df['target_benzene'], gridsize=15, \n           cmap=cmap, zorder=2, facecolor='black', mincnt=1)\nax0.set_ylabel('target_benzene', fontsize=5, fontweight='bold')\nax0.set_xlabel('target_carbon_monoxide', fontsize=5, fontweight='bold')\nax0.tick_params(labelsize=5, width=0.5, length=1.5)\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n\nax1.hexbin(x=train_df['target_carbon_monoxide'], y=train_df['target_nitrogen_oxides'], gridsize=15, \n           cmap=cmap, zorder=2, facecolor='black', mincnt=1)\nax1.set_ylabel('target_nitrogen_oxides', fontsize=5, fontweight='bold')\nax1.set_xlabel('target_carbon_monoxide', fontsize=5, fontweight='bold')\nax1.tick_params(labelsize=5, width=0.5, length=1.5)\nax1.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\nax1.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n\nax2.hexbin(x=train_df['target_benzene'], y=train_df['target_nitrogen_oxides'], gridsize=15, \n           cmap=cmap, zorder=2, facecolor='black', mincnt=1)\nax2.set_ylabel('target_nitrogen_oxides', fontsize=5, fontweight='bold')\nax2.set_xlabel('target_benzene', fontsize=5, fontweight='bold')\nax2.tick_params(labelsize=5, width=0.5, length=1.5)\nax2.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.7)\nax2.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.7)\n\nax0.text(0, 75, 'Target Correlations', fontsize=10, fontweight='bold')\nax0.text(0, 70, 'target_carbon_monoxide has a high correlation with other targets', fontsize=7)\n\nplt.show()","9f516593":"[back to top](#table-of-contents)\n<a id=\"6\"><\/a>\n# 6 Correlation\nExplore correlation between features and their targets and also between features themselves.\n\n<a id=\"6.1\"><\/a>\n## 6.1 Target and Features\nExplore correlation between features variables and their target variables: `target_carbon_monoxide`, `target_benzene`, and `target_nitrogen_oxides`.\n\n**Observations:**\n- **General** \n    - `deg_C`, `relative_humidity` and `absolute_humidity` don't show any strong correlation with target variables.\n    - `sensor_1`, `sensor_2` and `sensor_5` are the promising variables to be used for making a prediction as they have the highest correlation with the targets.\n    - `deg_C` is mostly concentrated between 10 to 30 degree Celsius, `relative_humidity` in a range of 20% - 80% and `absolute_humidity` at range of 0.75 to 1.5.\n\n- **Carbon Monoxide**\n    - `sensor_1`, `sensor_2` and `sensor_5` have a very high correlation (above 0.8) with carbon monoxide.\n    - `sensor_1` is highly dense at 750 - 1,250, `sensor_2` at range of 1,000 - 2,000 and `sensor_5` has a range of concentration between 500 - 1,500.\n\n- **Benzene**\n    - `sensor_1`, `sensor_2`, `sensor_4` and `sensor_5` have a very high correlation with benzene with `sensor_2` has a correlation of 0.96.\n    - `sensor_3` has a strong negative correlation of -0.74 with the benzene.\n    - `sensor_1` and `sensor_2` is highly dense at 750 - 1,250, `sensor_4` has a range of concentration between 1,250 - 1,750,  `sensor_5` at a range between 500 - 1,500 which is roughly a same density in the carbon monoxide target.\n    \n- **Nitrogen Oxides**\n    - `sensor_1`, `sensor_2`, and `sensor_5` have a medium correlation (0.6 - 0.71) with nitrogen oxides which are not as strong as the correlation with carbon monoxide and benzene.\n    - ` sensor_1` has a concentration range between 750 - 1,125, `sensor_2` and `sensor_5` at range of 500 - 1,250.\n\n","4bb822ec":"[back to top](#table-of-contents)\n<a id=\"6.2\"><\/a>\n## 6.2 Features\n\nExplore correlation between features variable in train and test dataset.\n\n**Observations:**\n- Highest correlation between features which are relatively the same between train and test dataset can be find in:\n    - Negative correlation:`sensor_3 and sensor_2`, `sensor_3 and sensor_4` and `sensor_3 and sensor_5`.\n    - Positive correlation: `sensor_1 and sensor_2`, `sensor_1 and sensor_5`, `sensor_2 and sensor_4`, `sensor_2 and sensor_5`. \n- Some of the features correlation between train and test are different due to differences in timeline. The test is starting from `winter` to `spring`, while the train is starting from `spring` to `winter`. Some differences can be seen on below correlation:\n    - High correlation of `0.78` between `sensor_4 and sensor_5` in test dataset is not reflected in train dataset.\n    - Reverse correlation in `deg_C and sensor_5` which has a negative correlation of `-0.051` in train dataset but has a positive correlation `0.036` in test dataset. This also happen in `relative_humidity and sensor_2` and also `deg_C and sensor_5`.\n- Top 5 differences in features correlation between train and test dataset are:\n    - `relative_humidity and sensor_4`\n    - `relative_humidity and absolute_humidity`\n    - `absolute_humidity and sensor_1`\n    - `deg_C and sensor_3`\n    - `deg_C and sensor_1`","bb666967":"[back to top](#table-of-contents)\n<a id=\"6.3\"><\/a>\n## 6.3 Targets\n\nExplore correlation between targets in the train dataset to see if one\/multi targets can be used to predict the other target.\n\n**Observations:**\n- `target_carbon_monoxide` has a high correlation with `target_benzene` (0.88), `target_nitrogen_oxides` (0.81). This may suggest `target_carbon_monoxide` can be used to predict `target_benzene` and `target_nitrogen_oxides`. \n- A good prediction on `target_carbon_monoxide` will help to predict the others targets. As a reminder, there are 3 features:`sensor_1`, `sensor_2` and `sensor_5` have a very high correlation (above 0.8) with the `target_carbon_monoxide`.\n-  Correlation between `target_benzene` and `target_nitrogen_oxides` are not as strong as with `target_carbon_monoxide` with 0.66.","266583d1":"The dimension and number of missing values in the test dataset is as below:","8cf0f915":"[back to top](#table-of-contents)\n<a id=\"1\"><\/a>\n# 1 Introduction\n\nKaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, Kaggle have launched many Playground competitions that are more approachable than Featured competition, and thus more beginner-friendly.\n\nThe goal of these competitions is to provide a fun, but less challenging, tabular dataset. These competitions will be great for people looking for something in between the Titanic Getting Started competition and a Featured competition.\n\nThe dataset is used for this competition is based on a real dataset, but has synthetic-generated aspects to it. The original dataset deals with predicting air pollution in a city via various input sensor values (e.g., a time series).\n\nSubmissions are evaluated using the mean column-wise root mean squared logarithmic error. The RMSLE for a single column calculated as:\n\n$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\text{log}(p_{i}+1)-\\text{log}(a_{i}+1))^2}, $$\n\n\nwhere $n$ is the total number of observations, $p_{i}$ is your prediction, $a_{i}$ is the actual value, $\\text{log}(x)$ is the natural logarithm of $x$.\n\nThe final score is the mean of the RMSLE over all columns, in this case, 3.","6e35d150":"### 3.1.3 Basic statistics\nBelow is the basic statistics for each variables which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile` and `maximum`.","9d5eb387":"### 3.2.3 Basic statistics\nBelow is the basic statistics for each variables which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile` and `maximum`.","34533417":"<a id=\"5.2\"><\/a>\n## 5.2 Time Series\nThe challenge in making the prediction in this time series is: there is only 1 month target data on the `winter` that is available and there is no available information on how the target transitioning from `winter` to `spring`.\n\nThis section will explore target variable in a time series format with the coresponding seasons as has been done in previous sections:\n- **Spring**: start from March to May\n- **Summer**: start from June to August\n- **Autumn** : start from September to November\n- **Winter**: start from December to February\n\n**Observations:**\n- It seems since `autumn` 2010 there is an increasing value and volatility in all target values.\n- All the highest values in all target variables are achieved in `autumn` 2010. Thing to be thought: \"Is this a permanent changes or cyclical changes?\"\n- `target_carbon_monoxide` volatility is decreasing when it enters `winter` and continue in a decreasing trend. Thing to be considered: \"will it be it continue to decreasing and match previous year volatility and value?\"\n- `target_benzene` volatility is decreasing when it enters `winter`. Thing to be thought: \"Will it be any increasing volatility and value that will match `spring` cycle in the previous year?\"\n- `target_nitrogen_oxides` volatility and value is increasing since `autumn` and continue to have a high value since then. One thing to be considered: \"is this a permanent changes or is it due to seasonal condition?\", if this is a permanent changes, dropping train dataset from March 2010 to September 2010 can be consider as this will not reflect the future condition.","c2a1bd17":"[back to top](#table-of-contents)\n<a id=\"2\"><\/a>\n# 2 Preparations\nPreparing packages and data that will be used in the analysis process. Packages that will be loaded are mainly for data manipulation and data visualization. There are 2 datasets that are used in the analysis, they are train and test dataset. The main use of train dataset is to train models and use it to predict test dataset. While sample submission file is used to informed participants on the expected submission for the competition. *(to see the details, please expand)*","4bc5f06a":"[back to top](#table-of-contents)\n<a id=\"5\"><\/a>\n# 5 Target\nAnalyzing target variable by looking on how this variable are distributed and how each feature are distributed among each classes.\n\n<a id=\"5.1\"><\/a>\n## 5.1 Distribution\nTarget variables consists of `target_carbon_monoxide`, `target_benzene`, and `target_nitrogen_oxides`.\n\n**Observations:**\n- `target_carbon_monoxide`, `target_benzene`, and `target_nitrogen_oxides` are showing a lognormal distribution.","c1710105":"<a id=\"4.2\"><\/a>\n## 4.2 Time Series\nThe dataset is showing a time series data, it started from train dataset than followed with test dataset. Season will be an important factor to consider in the time series:\n- **Spring**: start from March to May\n- **Summer**: start from June to August\n- **Autumn** : start from September to November\n- **Winter**: start from December to February\n\n**Observations:**\n- `deg_C` is showing a relatively higher temperature in the `summer` and it shows a downtrend in the `autumn`. As expected `winter` is showing a relatively lower temperature before increasing back again in `spring`.\n- `relative_humidity` is showing an increasing trend in the `autumn` and more volatile in the `winter`. It also shows a relatively lower value in the summer.\n- `absolute_humidity` is showing a lower value in `winter` and slowly increasing when approaches `spring`. It also show a relatively high value in `summer` and `autumn`.\n- `sensor_1` is showing lower volatility in `summer` compared to other seasons.\n- `sensor_2` and `sensor_5` are showing higher volatility in `autumn` compared to other seasons.\n- `sensor_3` is showing lower volatility and value in the `winter` while `sensor_4` is showing more volatility.","2094b87e":"The dimension and number of missing values in the train dataset is as below:","1d94b2ed":"[back to top](#table-of-contents)\n<a id=\"3\"><\/a>\n# 3 Dataset Overview\nThe intend of the overview is to get a feel of the data and its structure in train, test and submission file. An overview on train and test datasets will include a quick analysis on missing values and basic statistics, while sample submission will be loaded to see the expected submission.\n\nThe main objective of the competition is predicting the values of air pollution measurements over time, based on basic weather information (temperature and humidity) and the input values of 5 sensors. Three target values to predict are: `target_carbon_monoxide`, `target_benzene`, and `target_nitrogen_oxides`\n\nAs there is no official data definition, a guess of data definition has been performed. The data may contains the following descriptions:\n- **date_time** is date and time when the sensors recording occured within interval of 1 hour.\n- **deg_C** is air temperature measured in Celsius\/Centigrade.\n- **relative_humidity** is a term used to describe the amount of water vapor that exists in a gaseous mixture of air and water and is expressed in a percentage.\n- **absolute_humidity** is the measure of water vapor (moisture) in the air, regardless of temperature.\n- **sensor_1** to **sensor_5** is the sensors recording value.\n\nThree target values:\n- **target_carbon_monoxide** is a colorless, odorless, tasteless, flammable gas that is slightly less dense than air.\n- **target_benzene** is is a chemical that is a colorless or light yellow liquid at room temperature. It has a sweet odor and is highly flammable.\n- **target_nitrogen_oxides** is a family of poisonous, highly reactive gases. These gases form when fuel is burned at high temperatures.\n\n<a id=\"3.1\"><\/a>\n## 3.1 Train dataset\nAs stated before, train dataset is mainly used to train predictive model as there is an available target variable in this set. This dataset is also used to explore more on the data itself including find a relation between each predictors and the target variable.\n\n**Observations:**\n- Date and time of sensors recording is starting from `10-Mar-2010` at `6 p.m.` to `31-Dec-2010` which is a span of  `10 months` of recording.\n- The lowest temperature that has been recorded in `deg_C` is `1.3` with the highest temperature of `46.1`. The mean of `20.9`  can be considered a normal temperature in many countries if it measures in Celsius so it may be reasonable to assume the value in the column is in degree Celsius.\n- `relative_humidity` is measured in percentage and has a range of `8.9%` to `90.8%` in the `train` dataset. \n- `absolute_humidity` has a range of `0.2` to `2.2`.         \n- It seems all the records from `sensor_1` to `sensor_5` were coming from a same type of machine that may be place in several different places as there are no big differences between each sensor which have a range from `242.7` to `2913.8`. \n- `target_carbon_monoxide` has a range of `0.1` to `12.5`, `target_benzene` has a range of `0.1` to `63.7` and `target_nitrogen_oxides` has a range of `1.91` to `1472.3`. Though the minimum values between these targets are quite similar, the maximum and the mean of the targets value are quite different.\n\n### 3.1.1 Quick view\nBelow is the first 5 rows of train dataset:","ba2218cf":"### 3.2.2 Data types\nConsistent with the train dataset, all of the other columns are in `float64` except for `date_time` column. *(to see the details, please expand)*","df40daf4":"# Table of Contents\n<a id=\"table-of-contents\"><\/a>\n- [1 Introduction](#1)\n- [2 Preparations](#2)\n- [3 Datasets Overview](#3)\n    - [3.1 Train dataset](#3.1)\n    - [3.2 Test dataset](#3.2)\n- [4 Features](#4)\n    - [4.1 Distribution](#4.1)\n    - [4.2 Time Series](#4.2)\n    - [4.3 Matching Distribution](#4.3)\n- [5 Target](#5)\n    - [5.1 Distribution](#5.1)\n    - [5.2 Time Series](#5.2)\n- [6 Correlation](#6)\n    - [6.1 Target and Features](#6.1)\n    - [6.2 Features](#6.2)\n    - [6.3 Target](#6.3)\n- [7 Winners Solution](#7)","eaf08617":"[back to top](#table-of-contents)\n<a id=\"3.2\"><\/a>\n## 3.2 Test dataset\nTest dataset is used to make a prediction based on the model that has previously trained. Exploration in this dataset is also needed to see how the data is structured and especially on it\u2019s similiarity with the train dataset.\n\n**Observations:**\n- Test observations started from `01-Jan-2011` to `04-Apr-2011` at `14 p.m.` It seems the `train` and `test` dataset are coming from a different cycle. The train dataset only cover less than 1 month of test dataset which is from `10-Mar` to `04-Apr`.\n- The lowest temperature that has been recorded in `deg_C` is `-1.8` with the highest temperature of `30` with a mean of `10.8` degree Celsius. This somehow is expected as there is a differences in season cycles between the train and test dataset. \n- `relative_humidity` has a range of `9.8%` to `88.8%` which is quite resemble the train dataset. \n- `absolute_humidity` has a range of `0.18` to `1.39`. Maximum absolute humidity is higher in the train dataset compared to test dataset.         \n- `sensor_1` to `sensor_5` have a range from `205.3` to `2593.8` which are quite same with the train dataset, though it's not perfect.\n\n### 3.2.1 Quick view\nBelow is the first 5 rows of test dataset:","b58fb79f":"<a id=\"4.3\"><\/a>\n## 4.3 Matching Distribution\nThis section will try to see if the features monthly distribution between test and train dataset is the same, which mainly focus on `Jan`, `Feb`, `Mar` and `Apr`. This is important as most of the `test` dataset are not available in the `train` dataset and are in different years. `Jan` and `Feb` in `train` will mostly will be compared with the `Dec` in train dataset as the nearest month available.\n\n**Observations:**\n- All the features in `Apr` are showing a different distribution between `train` and `test` dataset except for feature `deg_C`. This may due to differences in the number of observations.\n- **deg_C** \n    - `Jan` and `Feb` in `test` dataset are resembling `Dec` in train dataset. \n    - `Mar` in the `test` dataset is not fully resembling `Mar` in `train` dataset.\n- **relative_humidity** \n    - `Jan` in `test` dataset is quite resembling `Dec` in `train` dataset.\n    - It's quite hard to find a match distribution for `Feb` in `test` dataset. \n    - `Mar` in the `test` dataset is not fully resembling `train` but not very far.   \n- **absolute_humidity**\n    - `Jan` in the `test` dataset is quite resembling `Dec` dataset but still not the same.\n    - Comparing `Feb`, `Mar` in the `test` dataset with `train` dataset shows the distribution are very different.\n- **sensor_1** and **sensor_2**\n    - `Jan` in `test` dataset is showing a resemblance with the `Dec` in `train` dataset but `Feb` in `train` dataset is showing more resemblance to `Dec` in `test` dataset.\n    - `Mar` in `test` dataset is quite same with the observations in the `train` dataset.\n- **sensor_3**\n    - `Jan` in `test` dataset is showing a resemblance with the `Dec` in `train` dataset but `Feb` in `train` dataset is showing more resemblance to `Dec` in `test` dataset.\n    - `Mar` in `test` dataset is different with the observations in the `train` dataset.\n- **sensor_4**\n    - `Jan` in `test` dataset is showing a different distribution compared to `Dec` in `train` dataset. \n    - `Feb` in `train` dataset is showing more resemblance to `Dec` in `test` dataset but is not perfectly same.\n    - `Mar` in `test` dataset is different with the observations in the `train` dataset.\n- **sensor_4**\n    - `Jan` and`Feb` in `test` dataset are showing a different distribution compared to `Dec` dataset.\n    - `Mar` in `test` dataset is different with the observations in the `train` dataset.","b6c3f89c":"The train dataset has `7,111` of rows with `12` of columns and there is `0` missing values which is good as there will be no additional steps needed to fill the missing value.\n\n### 3.1.2 Data types\nExcept `date_time` column, all of the other columns are in `float64` type.","f78f17f7":"[back to top](#table-of-contents)\n<a id=\"7\"><\/a>\n# 7 Winners Solution\nCongratulations for all the winners and thank you for sharing your solution. Below are the winners and their solutions:\n- 1st place position: [Laura Desplans](https:\/\/www.kaggle.com\/desplanl) - [Holy cow, I ranked 1st! Solution\/Discussion](https:\/\/www.kaggle.com\/c\/tabular-playground-series-jul-2021\/discussion\/256486)","211bd711":"Similar to the train dataset, test dataset has `2,247` of rows with `9` of columns and there is `0` missing value. There is no target columns in the test dataset. ","c4d471cf":"[back to top](#table-of-contents)\n<a id=\"4\"><\/a>\n# 4 Features\nNumber of features available to be used to create a prediction model are `8` columns. \n\n<a id=\"4.1\"><\/a>\n## 4.1 Distribution\nComparing features distribution between train and test dataset on each features.\n\n**Observations:**\n- `deg_C` is showing a different distribution between train and test dataset, this is expected due to different season cycle between train and test dataset.\n- `absolute_humidity` and `sensor_4` are also showing a different distribution between test and train dataset.\n- `relative_humidity`, `sensor_1`, `sensor_2`, `sensor_3` and `sensor_5` are showing quite a same distribution between train and test dataset."}}