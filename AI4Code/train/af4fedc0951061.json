{"cell_type":{"dab7bf36":"code","e55aa36d":"code","07764a35":"code","d301b08d":"code","497ca8d3":"code","c1aabb37":"code","832f610e":"code","d3702a4e":"code","06a987e2":"code","b6708d43":"code","a584179c":"code","d41fbee6":"code","f090fc01":"code","1b7d5183":"code","ce594f7f":"code","09c68d16":"code","d55b3399":"code","3799c6ee":"code","cf344418":"code","a138f1a5":"code","d00594ef":"code","e61943ad":"code","36ccf408":"code","0554634d":"code","fc4b5e28":"code","4d56fe4a":"code","a7abbfa6":"code","4bb11996":"code","0252416c":"code","eada76cc":"code","b1b32d02":"code","3044c05e":"code","bcb346ee":"code","5960d185":"code","41b7e041":"code","2e15199c":"code","418c70fb":"code","82580652":"code","41b10e12":"code","4320c219":"code","b4e65f8d":"code","e15ffebc":"code","8c48974f":"code","ba7a8840":"code","a7ffc97d":"code","180ac9bc":"code","d50456ee":"code","bb0709b0":"markdown","2fa1be75":"markdown","1184087f":"markdown","265a2321":"markdown"},"source":{"dab7bf36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e55aa36d":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\nplt.style.use('fivethirtyeight')","07764a35":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","d301b08d":"df=df.drop('Unnamed: 32', axis=1)\n","497ca8d3":"diagnosis={'M':1, 'B':0}\ndf['diagnosis']=[diagnosis[x] for x in df['diagnosis']]","c1aabb37":"col=['radius_mean', 'texture_mean', 'perimeter_mean',\n        'smoothness_mean', \n        'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'smoothness_se',\n        'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n        'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","832f610e":"X=df.drop(col, axis=1)\ny=df['diagnosis']\nX_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","d3702a4e":"from sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf","06a987e2":"# Import the AdaBoost classifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\n# Create adaboost classifer object\nabc = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=0)\n\n# Train Adaboost Classifer\nmodel1 = abc.fit(X_train, y_train)\n\n\n#Predict the response for test dataset\ny_pred = model1.predict(X_train)","b6708d43":"y_pred=model1.predict(X_train)\n","a584179c":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","d41fbee6":"y_test_pred=model1.predict(x_test)\n","f090fc01":"ada_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",ada_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","1b7d5183":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=model1.classes_)\ndisp.plot()","ce594f7f":"from sklearn.model_selection import cross_val_score    \nscores = cross_val_score(model1, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","09c68d16":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","d55b3399":"y_test_pred_prob=model1.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","3799c6ee":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","cf344418":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=model1.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Addaboost\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","a138f1a5":"from sklearn.ensemble import GradientBoostingClassifier\n","d00594ef":"model1=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)","e61943ad":"model1.fit(X_train, y_train)","36ccf408":"y_pred=model1.predict(X_train)\n","0554634d":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","fc4b5e28":"y_test_pred=model1.predict(x_test)\n","4d56fe4a":"xgb_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",xgb_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","a7abbfa6":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=model1.classes_)\ndisp.plot()","4bb11996":"from sklearn.model_selection import cross_val_score    \nscores = cross_val_score(model1, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","0252416c":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","eada76cc":"y_test_pred_prob=model1.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","b1b32d02":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='XGBoost')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","3044c05e":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=model1.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"XGBoost\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","bcb346ee":"# split training feature and target sets into training and validation subsets\nfrom sklearn.model_selection import train_test_split\n\nX_train_sub, X_validation_sub, y_train_sub, y_validation_sub = train_test_split(X_train, y_train, random_state=0)","5960d185":"learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n    gb.fit(X_train_sub, y_train_sub)\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train_sub, y_train_sub)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation_sub, y_validation_sub)))\n    print()","41b7e041":"# Output confusion matrix and classification report of Gradient Boosting algorithm on validation set\n\ngb = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.5, max_features=2, max_depth = 2, random_state = 0)\ngb.fit(X_train_sub, y_train_sub)\npredictions = gb.predict(X_validation_sub)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_validation_sub, predictions))\nprint()\nprint(\"Classification Report\")\nprint(classification_report(y_validation_sub, predictions))","2e15199c":"cfm=confusion_matrix(y_validation_sub, predictions)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=gb.classes_)\ndisp.plot()","418c70fb":"from catboost import CatBoostClassifier\n\nclf = CatBoostClassifier(\n    iterations=5, \n    learning_rate=0.1, \n    #loss_function='CrossEntropy'\n)","82580652":"clf.fit(X_train, y_train, \n        eval_set=(X_validation_sub, y_validation_sub), \n        verbose=False\n)","41b10e12":"y_pred=clf.predict(X_train)\n","4320c219":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","b4e65f8d":"y_test_pred=clf.predict(x_test)\n","e15ffebc":"cat_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",cat_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","8c48974f":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=clf.classes_)\ndisp.plot()","ba7a8840":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","a7ffc97d":"y_test_pred_prob=clf.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","180ac9bc":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","d50456ee":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=clf.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Catboost\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","bb0709b0":"# Build the AdaBoost model ","2fa1be75":"# CatBoost Classifier in Python\n","1184087f":"# XGBoost","265a2321":"# Cross Validation "}}