{"cell_type":{"43ec351c":"code","b8356b83":"code","609fa289":"code","fd9ca570":"code","1b0873ae":"code","3fb14108":"code","705531df":"code","526eafb6":"code","7ef9e33e":"code","471602f9":"code","7571cd4f":"code","af4da1d4":"code","1f551f45":"code","251b0fe7":"code","f59df4ab":"code","db9a6c7b":"code","012f3895":"code","50323c46":"code","e0a167df":"code","e6eba7eb":"code","ef2a7cf0":"code","9854e4c3":"code","66f55325":"code","a94ab687":"code","0ea99ce5":"code","e29b739b":"code","6d7dff08":"code","4789ae07":"code","76ad16fb":"code","5c675fee":"code","3076e6b5":"code","9f2bb431":"code","fc1e491f":"code","bfb86825":"markdown","f2c21517":"markdown","4360c1bc":"markdown","7e5036c3":"markdown","c95bda95":"markdown","50a133d1":"markdown","373e757b":"markdown","ed425944":"markdown","021dcf73":"markdown","d2a9500d":"markdown","7db32ad1":"markdown","72319b7a":"markdown","870b71d8":"markdown","38b33960":"markdown","1a982e32":"markdown","158fe138":"markdown","8e68e3d1":"markdown"},"source":{"43ec351c":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport glob\nimport pathlib\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nfrom tqdm import tqdm\nimport time","b8356b83":"base_dir = '\/kaggle\/input\/data-science-bowl-2018\/'\nunzip_base_dir = '\/kaggle\/working\/'\nstage_train_zip = base_dir + 'stage1_train.zip'\nstage_train_labels_zip= base_dir + 'stage1_train_labels.csv.zip'\n\nstage_train_unzip = unzip_base_dir + 'stage1_train\/'\nstage_train_labels_unzip= unzip_base_dir + 'stage1_train_labels\/'","609fa289":"import zipfile\nfor path, unzip_path in zip([stage_train_zip,stage_train_labels_zip ], [stage_train_unzip, stage_train_labels_unzip]):\n    print(path)\n    print(unzip_path)\n    print('---')\n    with zipfile.ZipFile(path, 'r') as zip_ref:\n        zip_ref.extractall(unzip_path)","fd9ca570":"test_data = r\"\/kaggle\/input\/data-science-bowl-2018\/stage1_test.zip\"\ntest_data_unzip = unzip_base_dir + 'stage1_test\/'\nwith zipfile.ZipFile(test_data, 'r') as zip_ref:\n    zip_ref.extractall(test_data_unzip)","1b0873ae":"test = pathlib.Path(test_data_unzip)\nlsttest_files = glob.glob(str(test\/'*\/'))\nlsttest_files[:10]","3fb14108":"def get_image(image_path):\n    temp_path = glob.glob(image_path+'\/images\/*')\n    img = tf.io.read_file(temp_path[0])\n    img = tf.io.decode_image(img)\n    img = tf.image.resize(img, (128,128))\n\n    arr = img[:, :, :3].numpy()\n    new_arr = ((arr - arr.min()) * (1\/(arr.max() - arr.min())))\n    return new_arr\n\ntest_images = []\nfor i in lsttest_files:\n    test_images.append(get_image(i))","705531df":"# We will convert test images to the tensor\ntest_dataset = tf.convert_to_tensor(np.array(test_images))","526eafb6":"path = pathlib.Path(stage_train_unzip)\nlst_files = glob.glob(str(path\/'*\/'))","7ef9e33e":"BATCH_SIZE = 64","471602f9":"class create_ds(keras.utils.Sequence):\n    def __init__(self, lst_files, batch_size):\n        self.lst_files = lst_files\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return len(self.lst_files)\/\/self.batch_size\n\n    \n    def get_image(self, image_path):\n        temp_path = glob.glob(image_path+'\/images\/*')\n        img = tf.io.read_file(temp_path[0])\n        img = tf.io.decode_image(img)\n        img = tf.image.resize(img, (128,128))\n\n        arr = img[:, :, :3].numpy()\n        new_arr = ((arr - arr.min()) * (1\/(arr.max() - arr.min())))\n        \n        ma = glob.glob(image_path+'\/masks\/*')\n        mask_ = tf.zeros(shape = (128, 128, 1))\n        \n        # Get all mask in particular folder and append to mask with all pixel value equal to zero\n        for mask_path in ma:\n            mask = tf.io.read_file(mask_path)\n            mask = tf.io.decode_image(mask)\n            mask = tf.image.resize(mask, (128,128))\n           \n            mask_ = tf.maximum(mask_, mask)\n        \n        return new_arr, mask_.numpy()\n        \n    # Create batches of given batch and return to the dataset object    \n    def __getitem__(self, idx):\n        batch = self.lst_files[idx * self.batch_size : (idx+1)*self.batch_size]\n        \n        temp_image = []\n        temp_label = []\n        for path in batch:\n            new_arr, mask = self.get_image(path)\n            temp_image.append(new_arr)\n            temp_label.append(mask\/255.0)\n        \n        return tf.convert_to_tensor(np.array(temp_image), dtype='float32'), tf.convert_to_tensor(np.array(temp_label),dtype ='float32')\n    ","7571cd4f":"import plotly.graph_objects as go\n\n# We will pass the df which we created using model.history, So we wo=ill plot train, test loss. Train test accuracy\ndef plot_train_valid_curcve(df):\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['loss'],\n                            mode='lines',\n                            name='Train_loss'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_loss'],\n                            mode='lines',\n                            name='val_loss'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['accuracy'],\n                            mode='lines',\n                            name='Train_accuracy'))\n\n        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_accuracy'],\n                            mode='lines',\n                            name='val_accuracy'))\n        fig.show()\n        \n# Let's see what we got as a prediction\ndef plot_predicted_image(x_test, valid, pred):\n    ''' Function to plot Actual image, actual mask, Predicted Mask\n    \n    Param X-test : Actual image\n    Param valid  : Validation mask\n    Param pred   : Predicted image\n    '''\n    \n    fig = plt.figure(figsize = (15,7))\n    plt.subplot(1, 3,1)\n    plt.title('Actual Image')\n    plt.imshow(x_test)\n    \n#     fig = plt.figure(figsize = (20,7))\n    plt.subplot(1, 3,2)\n    plt.title('Actual Mask')\n    plt.imshow(valid)\n    \n    plt.subplot(1, 3,3)\n    plt.title('Predicted mask')\n    plt.imshow(pred)","af4da1d4":"# let's split the data into train test split\nfrom sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(lst_files)","1f551f45":"# Creating the data using the class we created where we leverage the functionality of keras.sequence\ntrain_ds = create_ds(lst_files=train, batch_size = BATCH_SIZE) \nvalid_ds= create_ds(lst_files=valid, batch_size = BATCH_SIZE)","251b0fe7":"# the dimension of image\nIMAGE_HEIGHT=128\nIMAGE_WIDTH=128\nCHANNEL = 3","f59df4ab":"def get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL):\n    inputs = keras.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL))\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(inputs)\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_1)\n    # conv_1\n\n    conv_2 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_1)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n\n    conv_3 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_2)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n\n    conv_4 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_3)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n\n    conv_5 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_4)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    \n    conv_6 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding='same')(conv_5)\n    conv_6 = keras.layers.concatenate([conv_4, conv_6])\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n\n    conv_7 = keras.layers.Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding='same')(conv_6)\n    conv_7 = keras.layers.concatenate([conv_3, conv_7])\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n\n    conv_8 = keras.layers.Conv2DTranspose(filters = 32, kernel_size = 2, strides = 2, padding='same')(conv_7)\n    conv_8 = keras.layers.concatenate([conv_2, conv_8])\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n\n\n    conv_9 = keras.layers.Conv2DTranspose(filters = 16, kernel_size = 2, strides = 2, padding='same')(conv_8)\n    conv_9 = keras.layers.concatenate([conv_1, conv_9])\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n\n    output = keras.layers.Conv2D(filters = 1, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    model = keras.Model(inputs, output)\n    return model","db9a6c7b":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)\nmodel.summary()","012f3895":"\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])","50323c46":"# We will create baseline model and execute for 10 epochs\n\nstart = time.time()\nhistory = model.fit(train_ds, validation_data=valid_ds, epochs = 10, verbose=False)\n\nend = time.time()\nprint(f'Time required for the execution is {end - start}')","e0a167df":"df = pd.DataFrame(history.history)","e6eba7eb":"plot_train_valid_curcve(df)","ef2a7cf0":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)","9854e4c3":"# As we have already created class through which we can call image and mask, We will write for loop and create data pipeline ,\n# Let's see if we can spped up the processing.\n\nx_train_slices = []\ny_train_slices = []\n\nx_test_slices = []\ny_test_slices = []\n\nfor (train, train_label)  in tqdm(train_ds):\n    for x_train, y_train in zip(train, train_label):\n        x_train_slices.append(x_train.numpy())\n        y_train_slices.append(y_train.numpy())\n        \nfor (valid, valid_label)  in tqdm( valid_ds):\n    for  x_test, y_test in zip( valid, valid_label):\n        \n        x_test_slices.append(x_test.numpy())\n        y_test_slices.append(y_test.numpy())","66f55325":"train_tensor_ds = tf.data.Dataset.from_tensor_slices((x_train_slices, y_train_slices))\nvalid_tensor_ds = tf.data.Dataset.from_tensor_slices((x_test_slices, y_test_slices))","a94ab687":"BATCH_SIZE = 64\ntrain_tensor_ds = train_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\nvalid_tensor_ds = valid_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)","0ea99ce5":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])","e29b739b":"\nstart = time.time()\nhistory = model.fit(train_tensor_ds, validation_data = valid_tensor_ds, epochs = 100, verbose=False)\n\nend = time.time()\n\nprint(f'Time required for the execution is {end - start}')","6d7dff08":"df = pd.DataFrame(history.history)","4789ae07":"plot_train_valid_curcve(df)","76ad16fb":"pred = model.predict(np.array(x_test_slices))\npred_t = (pred >0.5).astype('uint8')\n\nfor plot_image in range(3):\n    random_image = np.random.randint(0, len(x_test_slices))\n    plot_predicted_image(np.array(x_test_slices)[random_image], np.array(y_test_slices)[random_image],  pred_t[random_image])","5c675fee":"def scheduler(epoch):\n    if epoch <50:\n        return 0.001\n#     elif ( 30 <= epoch and epoch <=50):\n#         return 0.001\n    elif (50<= epoch and epoch <=70 ):\n        return 0.0001\n    \n    elif (epoch>70):\n        return 0.0001 \ncall_back = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=True)","3076e6b5":"model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nstart = time.time()\n\nhistory = model.fit(train_tensor_ds, validation_data = valid_tensor_ds, epochs = 100, callbacks = [call_back], verbose=False)\n\nend = time.time()\n\nprint(f'Time required for the execution is {end - start}')","9f2bb431":"df1 = pd.DataFrame(history.history)\nplot_train_valid_curcve(df1)","fc1e491f":"pred = model.predict(np.array(x_test_slices))\npred_t = (pred >0.5).astype('uint8')\n\nfor plot_image in range(3):\n    random_image = np.random.randint(0, len(x_test_slices))\n    plot_predicted_image(np.array(x_test_slices)[random_image], np.array(y_test_slices)[random_image],  pred_t[random_image])","bfb86825":"In this model we will try to use learning scheduler and let's see this makes any difference","f2c21517":"## Model 3","4360c1bc":"## Importing liabraries","7e5036c3":"This class will create dataset for training,As we know by using this type of class, It is computationally expensive. So for just demostration purpose i am using this class to pass data to the model","c95bda95":"Define the input zip path and output unzip path","50a133d1":"This function is just to get an image given path, So for test purpose we will use this function to get test image","373e757b":"As we have seen previous data pipeline was taking too much time for each epoch so we will use tf.data.Dataset object","ed425944":"## Create model","021dcf73":"Check the prediction on test image","d2a9500d":"## Model 2","7db32ad1":"## 1) Unzip the data","72319b7a":"Function to plot the ","870b71d8":"get_model will give us model with Unet. One point to be noted here we have used padding as same, If we read the architecture carefully they are using \ndifferent concatenationa as well as loss function. For this notebook we will get overview of unet","38b33960":"let's have all filepath of images in list","1a982e32":"## 2) Create data pipeline using tensor slices","158fe138":"This notebook gives us understandin how to proceed with image segmentation!! Please upvote if you like.\nIn next vesion I will use different loss function and accuracy metric.","8e68e3d1":"As we can see from the time required  to train the model is significantly reduced"}}