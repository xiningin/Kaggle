{"cell_type":{"926339bf":"code","2cb00b88":"code","4fe36ed4":"code","45a966cd":"code","79754cf4":"code","30fc0605":"code","4dca9ec6":"code","5cc69c87":"code","19b65c12":"code","c9765c05":"code","bc6e549e":"code","cacb13d4":"code","f5351c72":"code","3cb03942":"code","37e3f7f1":"code","e05769f1":"code","c149feaf":"code","ccb6abc8":"code","ae98c92e":"code","ac0acd9e":"code","9a4e559b":"markdown"},"source":{"926339bf":"from sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nimport json","2cb00b88":"print (\"Read Dataset ... \")\ndef read_dataset(path):\n\treturn json.load(open(path))\nfrom random import shuffle\ntrain = read_dataset('..\/input\/train.json')\nshuffle(train)\nshuffle(train)\ntest = read_dataset('..\/input\/test.json')","4fe36ed4":"print (\"Prepare text data of Train and Test ... \")\ndef generate_text(data):\n    DATA=[doc['ingredients'][:] for doc in data]\n    return DATA","45a966cd":"train_text = generate_text(train)\ntest_text = generate_text(test)\ntestids = [i['id'] for i in test ]\ntrain_target = [doc['cuisine'] for doc in train]\ntrain_target[0:3]","79754cf4":"print(len(train_text))\nprint(testids[0:3])","30fc0605":"C=sorted(list(set(train_target)))\nMap= dict((c, i) for i, c in enumerate(C))\nprint(Map)\n\ntrain_target = [Map[i] for i in train_target]\ntrain_target[0:3]","4dca9ec6":"feachers_set= set()\nfor i in train_text:\n    for j in i:\n        feachers_set.add(j)\nfor i in test_text:\n    for j in i:\n        feachers_set.add(j)\nfeachers_set = list(feachers_set )\nprint(len(feachers_set))","5cc69c87":"X_train =[]\nX_test = []\n\nfor j in train_text:\n    x=[0 for i in range(len(feachers_set))]\n    for i in j:\n        k= feachers_set.index(i)\n        if k>=0:\n            x[k]=1\n        else :\n            print(\"error\")\n    X_train.append(x)\n#print(X_train[1])    ","19b65c12":"for j in test_text:\n    x=[0 for i in range(len(feachers_set))]\n    for i in j:\n        k= feachers_set.index(i)\n        if k>=0:\n            x[k]=1\n        else :\n            print(\"error\")\n    X_test.append(x)","c9765c05":"length1 = len(X_train)\nlength2=  len(X_test)\nxlines=X_train[:]+X_test[:]\nlength3=len(xlines)\nprint(length1, length2, length3)\nCHIX=4000\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2,f_classif, mutual_info_classif\nfrom sklearn import decomposition\nLENGTH= 3000\n\npca = decomposition.PCA(n_components=LENGTH)\npca.fit(xlines)\nxlines = pca.transform(xlines)\nxlines=xlines.tolist()\nprint(len(xlines[0]))\n#print(xlines[0])","bc6e549e":"print(xlines[0][1:10])","cacb13d4":"x_train = xlines[0: length1]\nx_test = xlines[length1:]\nprint(len(x_train), len(x_test))\n","f5351c72":"from keras.utils import np_utils\nimport numpy as np\nfrom sklearn.utils import class_weight\nY=np_utils.to_categorical(train_target)\nX=np.array(x_train)\nprint(len(Y[0]),Y[0])\n\n    ","3cb03942":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout ,ActivityRegularization,LeakyReLU\nfrom keras.regularizers import l1_l2,l1\n\nmodel = Sequential()\nmodel.add(Dense(1000, activation='relu',input_shape=(LENGTH,)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1000, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.1))\n#model.add(ActivityRegularization(l2=0.1))\n#model.add(Dropout(0.1))\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.1))\n#model.add(ActivityRegularization(l2=0.1))\n#model.add(Dropout(0.2))\nmodel.add(Dense(len(Y[0]), activation='softmax'))\nmodel.compile(optimizer='nadam',\n          loss='categorical_crossentropy',\n          metrics=['accuracy'])\nmodel.summary()","37e3f7f1":"from keras.callbacks import ModelCheckpoint\npath_model='model_simple_keras_starter.h5' \ncheckpointer = ModelCheckpoint('model_simple_keras_starter.h5',monitor='val_acc', verbose=1, save_best_only=True)\nmodel.fit(X,Y,epochs=50, \n            verbose=1,\n          batch_size=64,\n            validation_data=(X[33000:],Y[33000:]),\n            shuffle=True,\n            callbacks=[\n                checkpointer,\n            ]\n          \n         )","e05769f1":"model.load_weights('model_simple_keras_starter.h5')\nscore = model.evaluate(X[33000:],Y[33000:], verbose=0)\nprint('Test accuracy:', score)","c149feaf":"revmap={}\nfor i in Map.keys():\n    revmap[Map[i]]=i\nprint(revmap)","ccb6abc8":"XX=np.array(x_test)\nAns= model.predict(XX)\nAns=[np.argmax(pred) for pred in Ans]","ae98c92e":"print(Ans[1])\nactcual =[]\nfor i in Ans:\n    actcual.append(revmap[i])","ac0acd9e":"import pandas as pd\nsub = pd.DataFrame({'id': testids, 'cuisine': actcual}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)","9a4e559b":"Adding noise "}}