{"cell_type":{"95beef33":"code","023c3a9c":"code","d6939e34":"code","f5e5f685":"code","1aedf364":"code","538b6e64":"code","495c6d67":"code","9132fb1a":"code","d161523e":"code","3ee92aa3":"code","4636d4ac":"code","0adc298c":"code","38338446":"code","04fbb66a":"code","c724acce":"code","46d864fc":"code","6f2ec0ec":"code","5f977453":"code","aa060e75":"code","f7aa1fa8":"code","696acaa5":"code","46e1e75e":"code","34f27df4":"code","5425ecd6":"code","ef515224":"code","83c4be1b":"code","665f25b9":"code","db37d893":"code","a65d9576":"code","3f4a9760":"code","4510eb0e":"markdown","dfc06c70":"markdown","506d40e3":"markdown","e6669961":"markdown","924e4bb0":"markdown","ca0696f2":"markdown","ad6cec0f":"markdown","d21498b6":"markdown","8dbd1f30":"markdown","f3ed7dd4":"markdown","4cd97fbb":"markdown","3e9ff27d":"markdown","7c1776c1":"markdown","1d6c506b":"markdown","812c0497":"markdown","a00d8009":"markdown","028a5011":"markdown","ef346517":"markdown","3a0181c4":"markdown","8bb64f68":"markdown","50073c9e":"markdown"},"source":{"95beef33":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","023c3a9c":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\nsns.set_style(style='darkgrid')\n\n%matplotlib inline","d6939e34":"from sklearn.metrics import mean_absolute_error\n\ndef eval1(predic,ytest):\n  print(\"-----------------------------------------------------------------\")\n  print(\" price mean absolute error (mae) = \"+ str(mean_absolute_error(predic,ytest)))\n  print(\"-----------------------------------------------------------------\")","f5e5f685":"def lrmod(x_train,y_train,x_test):\n  lr1=LinearRegression()\n  lr1.fit(x_train,y_train)\n  pred=lr1.predict(x_test)\n  return (pred,lr1)","1aedf364":"def rfmod(x_train,y_train,x_test,p_grid):\n  rf1=GridSearchCV(RandomForestRegressor(),param_grid=p_grid,verbose=3,n_jobs=-1,refit=True)\n  rf1.fit(x_train,y_train)\n  pred=rf1.predict(x_test)\n  return (pred,rf1)","538b6e64":"def svmod(x_train,y_train,x_test,p_grid):\n  svg=GridSearchCV(SVR(),param_grid=p_grid,verbose=3,n_jobs=-1,refit=True,cv=4)\n  svg.fit(x_train,y_train)\n  pred=svg.predict(x_test)\n  return (pred,svg)","495c6d67":"def transformer1(x_train,x_test):\n  m1=MinMaxScaler()\n  x_train=m1.fit_transform(x_train)\n  x_test=m1.transform(x_test)\n  return x_train,x_test","9132fb1a":"def transformer2(x_train,x_test):\n  m1=StandardScaler()\n  x_train=m1.fit_transform(x_train)\n  x_test=m1.transform(x_test)\n  return x_train,x_test","d161523e":"data=pd.read_csv('..\/input\/used-bikes-prices-in-india\/Used_Bikes.csv')\n","3ee92aa3":"data","4636d4ac":"data.info()","0adc298c":"data.describe(include='all')","38338446":"data.isna().any()","04fbb66a":"plt.figure(figsize=(10,10))\nsns.heatmap(data.isna().transpose(),cmap='viridis',xticklabels=False,cbar=False)","c724acce":"plt.figure(figsize=(20,6))\nsns.countplot(data=data,x='brand',palette='rainbow')\nplt.tight_layout()","46d864fc":"f,axes=plt.subplots(2,2,figsize=(15,7))\n\nsns.histplot(x='price',data=data,kde=True,color='red',ax=axes[0,0],bins=50)\n\nsns.scatterplot(y='price',x='kms_driven',data=data,ax=axes[0,1])\nsns.scatterplot(y='price',x='power',data=data,ax=axes[1,0])\nsns.scatterplot(y='price',x='age',data=data,ax=axes[1,1])\n\nplt.tight_layout()","6f2ec0ec":"f,axes2=plt.subplots(1,2,figsize=(15,7))\n\nsns.scatterplot(y='kms_driven',x='power',data=data,ax=axes2[0])\nsns.scatterplot(y='kms_driven',x='age',data=data,ax=axes2[1])\n\nplt.tight_layout()","5f977453":"data.drop(['bike_name','city'],axis=1,inplace=True)","aa060e75":"owndum=pd.get_dummies(data['owner'],drop_first=True)\nbrandum=pd.get_dummies(data['brand'],drop_first=True)","f7aa1fa8":"data=pd.concat([data,owndum,brandum],axis=1)","696acaa5":"data.drop(['brand','owner'],axis=1,inplace=True)","46e1e75e":"y=data['price'].values\nX=data.drop(['price'],axis=1).values","34f27df4":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=42)","5425ecd6":"x_train,x_test=transformer1(x_train,x_test)","ef515224":"pred1,lrob=lrmod(x_train,y_train,x_test)","83c4be1b":"n_est=list(range(100,700,100))\nn_estimators=dict(n_estimators=n_est)\npred2,rfob=rfmod(x_train,y_train,x_test,n_estimators)","665f25b9":"C=[100,1000];Ga=[1,0.1,0.01]\np=dict(C=C,gamma=Ga)\npred3,svob=svmod(x_train,y_train,x_test,p)","db37d893":"eval1(pred1,y_test)\n\nplt.figure(figsize=(10,8))\nplt.xlabel('Linear Regression predictions')\nplt.ylabel('Actual Values')\nsns.scatterplot(x=pred1,y=y_test)","a65d9576":"eval1(pred2,y_test)\nprint()\nprint(rfob.best_params_)\nprint()\nplt.figure(figsize=(10,8))\nplt.xlabel('Random Forest Regression Predictions')\nplt.ylabel('Actual Values')\nsns.scatterplot(x=pred2,y=y_test)","3f4a9760":"eval1(pred3,y_test)\nprint()\nprint(svob.best_params_)\nprint()\nplt.figure(figsize=(10,8))\nplt.xlabel('SVM Predictions')\nplt.ylabel('Actual Values')\nsns.scatterplot(x=pred3,y=y_test)","4510eb0e":"## LINEAR REGRESSION","dfc06c70":"# NULL CHECK","506d40e3":"# EVALUATIONS","e6669961":"# X,Y,SPLITTING","924e4bb0":"## SVR ","ca0696f2":"# NOTE:\n## **If extrapolation is not the issue then I would go for Random Forest Regressor**","ad6cec0f":"# IMPORT LIBRARY","d21498b6":"# DATA PREPROCESS","8dbd1f30":"## DATA SCALERS","f3ed7dd4":"# GETTING DATA","4cd97fbb":"# MODEL RUN","3e9ff27d":"# DATA DESCRIPTION","7c1776c1":"## RANDOM FOREST","1d6c506b":"## MODEL FUNCTIONS","812c0497":"## LINEAR REGRESSION\n","a00d8009":"# EDA(Exploratory Data Analysis)","028a5011":"## SVR (GRID SEARCH)","ef346517":"# PRE-MADE FUNCTIONS","3a0181c4":"# DATA SCALING","8bb64f68":"## EVALUATORS","50073c9e":"## RANDOM FOREST REGRESSOR (GRID SEARCH)"}}