{"cell_type":{"7c2fa96a":"code","cb4e3f42":"code","ce39c6b8":"code","7daa73e6":"code","d786e7d9":"code","42d97376":"code","14002db7":"code","378f2447":"code","55cb64d9":"code","703f1715":"code","acf2ce9f":"code","2ef05fcb":"code","89e65c63":"code","bfd7c2d7":"code","05d043be":"code","b1903b80":"code","675defec":"code","cf7dd56c":"code","aac6cd12":"code","71fa6347":"code","e0e70e54":"code","b44ed304":"code","6bc7a3ea":"code","c50c10ad":"code","002cdd00":"code","00b3b783":"code","9bfb3149":"code","68c9d3c7":"code","aa5108e6":"code","48a92ad8":"code","0e854ff0":"code","baab48ce":"code","a94ac3a0":"code","c936a085":"code","c9bb1ab7":"code","8bca723c":"markdown","799ca8a1":"markdown","2d99a1d6":"markdown","321f7ef2":"markdown","576f9d54":"markdown","49b78d3e":"markdown","359e5ab0":"markdown","0823b5b6":"markdown","4f31e345":"markdown","456a864e":"markdown","7c5b4b8a":"markdown","6e878a93":"markdown","d4309a45":"markdown","ffcadfe3":"markdown","f9ccd7f2":"markdown","21fbee82":"markdown","ce5cb315":"markdown"},"source":{"7c2fa96a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","cb4e3f42":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","ce39c6b8":"print(train.shape)\nprint(test.shape)","7daa73e6":"train.head(5)","d786e7d9":"test.head(5)","42d97376":"X_train=train.drop(labels = [\"label\"],axis = 1) \nY_train=train['label']\nprint(X_train.shape)\nprint(Y_train.shape)","14002db7":"Y_train.value_counts()","378f2447":"import seaborn as sns\nplt.figure(figsize=(8,4))\nsns.countplot(x='label', data=train);","55cb64d9":"X_train=X_train.astype('float32')\/255\ntest=test.astype('float32')\/255","703f1715":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","acf2ce9f":"X_train.shape","2ef05fcb":"test.shape","89e65c63":"from keras.utils.np_utils import to_categorical\nY_train = to_categorical(Y_train, num_classes = 10)","bfd7c2d7":"Y_train.shape","05d043be":"print(Y_train[:5])","b1903b80":"from sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size = 0.1, random_state=42)","675defec":"plt.figure(figsize=(6,6))\nplt.imshow(X_train[1][:,:,0])\nplt.title(Y_train[1].argmax());","cf7dd56c":"from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential,Model\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint,LearningRateScheduler\nimport keras\nfrom keras import backend as K","aac6cd12":"inputShape=(28,28,1)\ninput = Input(inputShape)\n\nx = Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same')(input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool1')(x)\n\n\n\nx = Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool2')(x)\n\nx = Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool3')(x)\n\n\nx = Flatten()(x)\nx = Dense(64,activation = 'relu',name='fc0')(x)\nx = Dropout(0.25)(x)\nx = Dense(32,activation = 'relu',name='fc1')(x)\nx = Dropout(0.25)(x)\nx = Dense(10,activation = 'softmax',name='fc2')(x)\n\nmodel = Model(inputs = input,outputs = x,name='Predict')","71fa6347":"model.summary()","e0e70e54":"# define SGD optimizer\nmomentum = 0.5\nsgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False) \n\n# compile the model\nmodel.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])","b44ed304":"import math\ndef step_decay(epoch):\n    \n    \n    initial_lrate=0.1\n    drop=0.6\n    epochs_drop = 3.0\n    lrate= initial_lrate * math.pow(drop,  \n           math.floor((1+epoch)\/epochs_drop))\n    return lrate\n   \n\nlrate = LearningRateScheduler(step_decay)\ncallbacks_list = [ lrate]\n","6bc7a3ea":"history=model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid),\n                          epochs=20,callbacks=callbacks_list,verbose=1)","c50c10ad":"import matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, color='red', label='Training loss')\nplt.plot(epochs, val_loss, color='green', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","002cdd00":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nplt.plot(epochs, acc, color='red', label='Training acc')\nplt.plot(epochs, val_acc, color='green', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","00b3b783":"print(\"on valid data\")\npred1=model.evaluate(X_valid,Y_valid)\nprint(\"accuaracy\", str(pred1[1]*100))\nprint(\"Total loss\",str(pred1[0]*100))","9bfb3149":"#from keras.models import Model\n#layer_outputs = [layer.output for layer in model.layers]\n#activation_model = Model(inputs=model.input, outputs=layer_outputs)\n#activations = activation_model.predict(X_train[10].reshape(1,28,28,1))\n \ndef display_activation(activations, col_size, row_size, act_index): \n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1","68c9d3c7":"plt.imshow(X_train[10][:,:,0]);","aa5108e6":"#display_activation(activations, 8, 8, 1)","48a92ad8":"#display_activation(activations, 8, 8, 3)","0e854ff0":"#display_activation(activations, 8, 8, 7)","baab48ce":"from sklearn.metrics import confusion_matrix\nY_prediction = model.predict(X_valid)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_prediction,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_valid,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) ","a94ac3a0":"plt.figure(figsize=(10,8))\nsns.heatmap(confusion_mtx, annot=True, fmt=\"d\");","c936a085":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n","c9bb1ab7":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(results)+1)),\"Label\": results})\nsubmissions.to_csv(\"sample-submission.csv\", index=False, header=True)","8bca723c":"## Building CNN architecture using keras ","799ca8a1":"#### Displaying output of layer 4","2d99a1d6":"#### Normalizing data","321f7ef2":"###  Visualizing the number of different labels in traing data","576f9d54":"## Data preprocess","49b78d3e":"### Plotting training and validation loss","359e5ab0":"#### Split training data into training data and validation data","0823b5b6":"#### Confusion matrix","4f31e345":"#### Displaying above image after layer 2","456a864e":"### Visualize CNN Layers","7c5b4b8a":"#### Reshape\nReshaping image into 3D matrix","6e878a93":"### Plotting training and validation accuracy","d4309a45":"#### Loading data","ffcadfe3":"#### Label Encoding","f9ccd7f2":"#### Step Decay \nwe will drop learning rate after every 3 epochs","21fbee82":"#### Optimizer","ce5cb315":"#### Displaying output of layer 8"}}