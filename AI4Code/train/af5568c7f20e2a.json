{"cell_type":{"68d67595":"code","639bd1c6":"code","b84c64f0":"code","aa319607":"code","21fee426":"code","28de51ff":"code","57d3550c":"code","5585e141":"code","fe7fcdbd":"markdown","5bd6c19e":"markdown","7449682c":"markdown","05cfcc71":"markdown"},"source":{"68d67595":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","639bd1c6":"train = pd.read_csv('\/kaggle\/input\/data-science-nigeria-ai-in-citie\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/data-science-nigeria-ai-in-citie\/test.csv')","b84c64f0":"train['no_medboat'] = train['MedBoat'].isnull()\ntest['no_medboat'] = test['MedBoat'].isnull()","aa319607":"train.corr()","21fee426":"predictions = test['no_medboat'].map({True:0,False:1})","28de51ff":"submission = pd.read_csv('\/kaggle\/input\/data-science-nigeria-ai-in-citie\/sample_submission.csv')","57d3550c":"submission['Survived'] = predictions","5585e141":"submission.to_csv('sub.csv', index=False)","fe7fcdbd":"As a tutor for Port Harcourt City, I decided to take a look at the competition and achieve what I believed should be a baseline model for the competition. Here are my key findings from domain knowledge:\n- Predicting that all the males died, you get a public and private leaderboard score of around 0.78 and 0.77 respectively\n\n- Predicting that only the adult males died (by simple boolean indexing into the dataframe) gets you a public leaderboard score of 0.81 but a private leaderboard score of 0.77 \n\nKindly note that I achieved these two results by just indexing into the dataframe without any machine learning models using domain knowledge. This is important as in one's journey as a data scientist or machine learning engineer, one should not be too quick to use machine learning before setting non-ML baselines. Not doing this is a recipe for disaster. \n\nI decided to do a mini exploratory data analysis for the dataset to see if I can set what I called an \"EDA + Domain Knowledge\" baseline and here was when I found out something interesting. Having read what the features were all supposed to represent from the competition page (something beginners dont usually do), I decided to create a new feature called \"no_medboat\" to represent those that did not have access to a MedBoat as shown by NaN in the MedBoat feature. Kindly note that NaN may have more meaning than just no data and as a data sceintist, you have to be aware of that. Not all NaNs should be dropped or Filled!","5bd6c19e":"This simple submission gets a public and private leadboard score of around 0.97 which ended up 5th on the private leaderboard, not too bad for a five line non-machine learning solution in a machine learning competition.\n![image.png](attachment:image.png)\n\nThe main reason why I share this is because as a beginner about three years ago, I was so fascinated with building machine learning models that I didn't bother too much about data cleaning, exploratory data analysis, domain knowledge and feature engineering. I only came to the realization at the Data Science Bootcamp of 2018 which I was privileged to qualify for. So no matter where you ended up on the leaderboard, I want you to understand that proper machine learning modelling is about the entire pipeline and not just model.fit\n\nBefore you call model.fit, you must have:\n- understood what each feature represent and how certain values could mean certain things using domain knowledge,\n- properly cleaned your data,\n- come up with hypothesis and test them using the data during exploratory data analysis,\n- engineer relevant features using the knowledge you now have from the domain and EDA\n- set up good non-machine learning\/ simple machine learning baselines.\n\nI hope this advice can help one or two people kick on in their data science careers like some of us did. Remember that the goal is 1 million AI talents in 10 years and you also have a big part to play in this dream. Cheers!","7449682c":"After creating this feature, I decided to check the correlation of the dataset and see what I found:","05cfcc71":"Almost everyone who did not have access to a med boat died as shown by the whooping correlation value of -0.95. Using this knowledge, I created a new submission"}}