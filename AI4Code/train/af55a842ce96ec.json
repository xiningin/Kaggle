{"cell_type":{"0788a647":"code","c479f74e":"code","e227cb3d":"code","4c07998b":"code","16344522":"code","f11a8467":"code","b79d4806":"code","ee4a0af8":"code","7ec1c8a2":"code","4492714b":"code","59cfb174":"code","1f8af7ce":"code","54f335e2":"code","0905220d":"code","356e5bac":"code","e9bf9082":"code","27fa61b8":"code","89c822fa":"code","e0184f98":"code","9fd37f7e":"code","8fd74818":"code","99f6e74e":"code","25032225":"code","e51c985d":"code","83ed046e":"markdown","94df3f43":"markdown","84adcdce":"markdown","64093201":"markdown","00092012":"markdown","c522a77d":"markdown","0c55b585":"markdown"},"source":{"0788a647":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c479f74e":"import pandas as pd                                                  # to import csv and for data manipulation\nimport matplotlib.pyplot as plt                                      # to plot graph\nimport seaborn as sns                                                # for intractve graphs\nimport numpy as np                                                   # for linear algebra\nimport datetime                                                      # to deal with date and time\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler                     # for preprocessing the data\nfrom sklearn.ensemble import RandomForestClassifier                  # Random forest classifier\nfrom sklearn.tree import DecisionTreeClassifier                      # for Decision Tree classifier\nfrom sklearn.svm import SVC                                          # for SVM classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics, preprocessing, model_selection","e227cb3d":"train_df = pd.read_csv('\/kaggle\/input\/who-wins-the-big-game\/train.csv')\ntrain_df.head()","4c07998b":"test_df = pd.read_csv('\/kaggle\/input\/who-wins-the-big-game\/test.csv')\ntest_df.head()","16344522":"sub_df = pd.read_csv('\/kaggle\/input\/who-wins-the-big-game\/sample_submission.csv')\nsub_df.head()","f11a8467":"print(\"The total number of Rows in Train dataset is : \", train_df.shape[0])\nprint(\"The total number of Rows in Test dataset is : \", test_df.shape[0])\nprint(\"The total number of Rows in both Train and Test dataset is : \", train_df.shape[0]+test_df.shape[0])","b79d4806":"train_df.keys()","ee4a0af8":"train_df.columns","7ec1c8a2":"test_df.columns","4492714b":"train_df.dtypes","59cfb174":"test_df.dtypes","1f8af7ce":"train_df['Won_Championship'].value_counts()","54f335e2":"# Normalise can be set to true to print the proportions instead of Numbers.\ntrain_df['Won_Championship'].value_counts(normalize=True)","0905220d":"train_df['Won_Championship'].value_counts().plot.bar(figsize=(4,4),title='Won_Championship - Split for Train Dataset')\nplt.xlabel('Won_Championship')\nplt.ylabel('Count')","356e5bac":"for col in train_df.columns:\n    if train_df[col].dtype==object:\n        print(col)\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n        train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n        test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))","e9bf9082":"X = train_df.drop(['ID','Won_Championship'],axis=1)\ny = train_df['Won_Championship']\n\ntest_X = test_df.drop(['ID'],axis=1)\n# TODO: Shuffle and split the data into training and testing subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=100)\n\n# Success\nprint (\"Training and testing split was successful.\")","27fa61b8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel_log = LogisticRegression()\nmodel_log.fit(X_train, y_train)\npred_cv = model_log.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","89c822fa":"confusion_matrix = confusion_matrix( y_valid,pred_cv)\nprint(\"the recall for this model is :\",confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[1,0]))\n\nfig= plt.figure(figsize=(6,3))# to plot the graph\nprint(\"TP\",confusion_matrix[1,1,]) \nprint(\"TN\",confusion_matrix[0,0]) \nprint(\"FP\",confusion_matrix[0,1]) \nprint(\"FN\",confusion_matrix[1,0])\nsns.heatmap(confusion_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\nplt.title(\"Confusion_matrix\")\nplt.xlabel(\"Predicted_class\")\nplt.ylabel(\"Real class\")\nplt.show()\nprint(confusion_matrix)\nprint(\"\\n--------------------Classification Report------------------------------------\")\nprint(classification_report(y_valid, pred_cv)) ","e0184f98":"model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel_rf.fit(X_train, y_train)\npred_cv = model_rf.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","9fd37f7e":"pred_test = model_rf.predict(test_X)\npred_test = pd.DataFrame(pred_test)\npred_test.columns = ['Won_Championship']","8fd74818":"importances=pd.Series(model_rf.feature_importances_, index=X.columns).sort_values()\nimportances.plot(kind='barh', figsize=(20,20))\nplt.xlabel('Importance of Attributes - Score')\nplt.ylabel('Attribute Name')\nplt.title(\"Attribute Importance by RandomForest Application\")","99f6e74e":"sub_df = test_df[['ID']]\n# # Fill the target variable with the predictions\nsub_df['Won_Championship'] = pred_test['Won_Championship']\n# # # Converting the submission file to csv format\nsub_df.to_csv('submission.csv', index=False)","25032225":"sub_df.shape","e51c985d":"sub_df.head()","83ed046e":"### Baseline model","94df3f43":"### Read data","84adcdce":"Here there is no class imbalance problem . Hence we can proceed further without addressing any class imbalance issues","64093201":"#### Logistic Regression","00092012":"### Structure, Features and DataTypes","c522a77d":"### Load packages","0c55b585":"#### RandomForestClassifier"}}