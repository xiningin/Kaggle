{"cell_type":{"ef01979c":"code","e2954d9c":"code","f94bf23e":"code","d5c153e9":"code","c1cb577a":"code","1dd5c7f0":"code","e3642cd7":"code","4aa0d67a":"code","b4263f36":"code","67e839cf":"code","fc8d96eb":"code","9b9f229d":"code","1f290deb":"code","63d96182":"code","a23e01ac":"code","ac96d599":"code","2c9fc003":"code","5a4510ce":"code","a2805f4a":"code","2276070c":"code","4a9409dc":"code","a4bacbbf":"code","dd22189d":"code","fa5c730f":"code","1c63c847":"code","d0d8ac7c":"code","aa0c216d":"code","c194faf1":"code","dae568aa":"code","a5a0d397":"code","330d334f":"code","339965a3":"code","b87f076a":"code","13b763b6":"code","2ba932ef":"code","a0953393":"code","e04b8940":"code","4c5ee41c":"markdown","2d3acb1c":"markdown","21d6ffb8":"markdown","a37a7888":"markdown","5f4e8ed0":"markdown","e387e094":"markdown","840a1ec6":"markdown","4c930f54":"markdown","9de19ee9":"markdown","94ae2ab6":"markdown","6ff213d1":"markdown","1bb6ae5a":"markdown","4e77dd41":"markdown","18c4724f":"markdown","ec6455e2":"markdown","36ccbab1":"markdown","d582e4af":"markdown","fbf1c8d5":"markdown","846f01e0":"markdown"},"source":{"ef01979c":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import EfficientNetB3\n\n\nimport os\nimport glob\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","e2954d9c":"class Config:\n    \n    seed = 44\n    num_classes = 11\n    class_list = [0,1,2,3,4,5,6,7,8,9,10]\n    batch_size = 32\n    n_epochs = 15\n    drop_rate = 0.4\n   \n    #scheduler = 'CosineAnnealingLR'\n    \n    scheduler_params = {           \n                    'ReduceLROnPlateau': \n                        {\n                            'monitor':'val_loss',\n                            'mode':'max',\n                            'factor':0.5,\n                            'patience':2,\n                            'threshold':0.0001,\n                            'threshold_mode':'rel',\n                            'cooldown':0,\n                            'min_lr':1e-5,\n                            'eps':1e-08,\n                            'verbose':True\n                        },\n                \n                }\n    \n    \n    # optimizer\n    optimizer = tf.keras.optimizers.Adam(lr = 1e-4)\n\n    # criterion\n    loss = 'binary_crossentropy'\n    \n    target_size_dim = 300\n    \n    metrics = tf.keras.metrics.AUC(multi_label=True)\n    \n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=1, mode='auto', epsilon=0.0001, \n                                       cooldown=5, min_lr=0.00001)\n    \n    checkpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode= 'min', \n                             save_weights_only = False)\n\n    checkpoint_last = ModelCheckpoint('last_model.hdf5', \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=False, \n                             mode= 'min', \n                             save_weights_only = False)\n\n\n    early = EarlyStopping(monitor= 'val_loss', \n                      mode= 'min', \n                      patience=5)\n    \n    labels = [\n                'ETT - Abnormal',\n                'ETT - Borderline',\n                'ETT - Normal',\n                'NGT - Abnormal',\n                'NGT - Borderline',\n                'NGT - Incompletely Imaged',\n                'NGT - Normal', \n                'CVC - Abnormal',\n                'CVC - Borderline',\n                'CVC - Normal',\n                'Swan Ganz Catheter Present'\n            ]\n    \n    paths = {\n                'train_path':'..\/input\/ranzcr-clip-trainset-256x256',\n                'test_path': '..\/input\/siim-isic-melanoma-classification\/jpeg\/test',\n                'csv_path': '..\/input\/ranzcr-clip-catheter-line-classification\/train.csv',\n                'model_weight_path_folder': '..\/input\/tfkerasefficientnetimagenetnotop'\n            }","f94bf23e":"config = Config","d5c153e9":"type(config.reduceLROnPlat)","c1cb577a":"np.random.seed(config.seed)\ntf.random.set_seed(config.seed)\nos.environ['PYTHONHASHSEED'] = str(config.seed)","1dd5c7f0":"df = pd.read_csv(config.paths['csv_path'])\ndf.head()","e3642cd7":"print('Number of Records: {} and Number of Patients: {}'.format(len(df), df['PatientID'].nunique()))","4aa0d67a":"df['PatientID'].value_counts()","b4263f36":"df['path'] = '..\/input\/ranzcr-clip-catheter-line-classification\/train\/' + df['StudyInstanceUID']+'.jpg'","67e839cf":"X_train, X_valid = train_test_split(df, test_size = 0.1, random_state=config.seed, shuffle=True)","fc8d96eb":"Train_df = tf.data.Dataset.from_tensor_slices((X_train.path.values, X_train[config.labels].values))\n\nValid_df = tf.data.Dataset.from_tensor_slices((X_valid.path.values, X_valid[config.labels].values))","9b9f229d":"for path, label in Train_df.take(5):\n    print ('Path: {}, Label: {}'.format(path, label))","1f290deb":"def process_data_train(image_path, label):\n    \n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.random_brightness(img, 0.3)\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.resize(img, [config.target_size_dim, config.target_size_dim])\n    #img = tf.image.per_image_standardization(img)\n    \n    return img, label\n\ndef process_data_valid(image_path, label):\n    \n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [config.target_size_dim, config.target_size_dim])\n    \n    return img, label","63d96182":"Train_df = Train_df.map(process_data_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\nValid_df = Valid_df.map(process_data_valid, num_parallel_calls=tf.data.experimental.AUTOTUNE)","a23e01ac":"for image, label in Train_df.take(1):\n    \n    plt.imshow(image.numpy().astype('uint8'))\n    plt.show()\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", config.labels[np.argmax(label.numpy())])","ac96d599":"def configure_for_performance(ds, batch_size = config.batch_size):\n    \n    ds = ds.cache('\/kaggle\/dump.tfcache') \n    ds = ds.repeat()\n    ds = ds.shuffle(buffer_size=1024)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    \n    return ds\n\ntrain_ds_batch = configure_for_performance(Train_df)\nvalid_ds_batch = Valid_df.batch(config.batch_size*2)","2c9fc003":"image_batch, label_batch = next(iter(train_ds_batch))","5a4510ce":"plt.figure(figsize=(10, 10))\nfor i in range(16):\n    \n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = config.labels[np.argmax(label_batch[i].numpy())]\n    plt.title(label)\n    plt.axis(\"off\")","a2805f4a":"data_augmentation = keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.05, interpolation='nearest'),\n    ]\n)","2276070c":"plt.figure(figsize=(10, 10))\n\nfor i in range(16):\n    \n    augmented_images = data_augmentation(image_batch)\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n    label = config.labels[np.argmax(label_batch[i].numpy())]\n    plt.title(label)\n    plt.axis(\"off\")","4a9409dc":"def load_pretrained_model(weights_path, drop_connect, target_size_dim, layers_to_unfreeze=5):\n    \n    model = EfficientNetB3(\n            weights=None, \n            include_top=False, \n            drop_connect_rate=0.4\n        )\n    \n    model.load_weights(weights_path)\n    \n    model.trainable = True\n\n    return model\n\ndef build_my_model(base_model, optimizer, metrics, loss):\n    \n    inputs = tf.keras.layers.Input(shape=(config.target_size_dim, config.target_size_dim, 3))\n    x = data_augmentation(inputs)\n    outputs_eff = base_model(x)\n    global_avg_pooling = GlobalAveragePooling2D()(outputs_eff)\n    dense_1= Dense(256)(global_avg_pooling)\n    bn_1 = BatchNormalization()(dense_1)\n    activation = Activation('relu')(bn_1)\n    dropout = Dropout(0.3)(activation)\n    dense_2 = Dense(len(config.labels), activation='sigmoid')(dropout)\n\n    my_model = tf.keras.Model(inputs, dense_2)\n    \n    my_model.compile(\n        optimizer=config.optimizer,\n        loss=config.loss,\n        metrics=config.metrics\n    )\n    \n    return my_model","a4bacbbf":"model_weights_path = '..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb3_notop.h5'\nmodel_weights_path\n","dd22189d":"base_model = load_pretrained_model(model_weights_path, config.drop_rate, config.target_size_dim)\n\nmy_model = build_my_model(base_model, config.optimizer, metrics = [config.metrics], loss=config.loss)\n\nmy_model.summary()","fa5c730f":"callbacks_list = [config.checkpoint, config.checkpoint_last, config.early, config.reduceLROnPlat]","1c63c847":"steps_per_epoch = len(X_train) \/\/ config.batch_size\n\nhistory = my_model.fit(\n                          train_ds_batch, \n                          validation_data = valid_ds_batch, \n                          epochs = config.n_epochs, \n                          callbacks = callbacks_list,\n                          steps_per_epoch = steps_per_epoch\n                      )","d0d8ac7c":"my_model.load_weights('best_model.hdf5') ## load the best model or all your metrics would be on the last run not on the best one","aa0c216d":"pred_valid_y = my_model.predict(valid_ds_batch, verbose = True, workers=4)\npred_valid_y_labels = np.argmax(pred_valid_y, axis=-1)","c194faf1":"valid_labels = np.concatenate([y.numpy() for x, y in valid_ds_batch], axis=0)","dae568aa":"valid_labels","a5a0d397":"test_images = glob.glob('..\/input\/ranzcr-clip-catheter-line-classification\/test\/*.jpg')","330d334f":"df_test = pd.DataFrame(np.array(test_images), columns=['Path'])\ndf_test.head()","339965a3":"test_ds = tf.data.Dataset.from_tensor_slices((df_test.Path.values))\n\n\ndef process_test(image_path):\n\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [config.target_size_dim, config.target_size_dim])\n    \n    return img\n    \ntest_ds = test_ds.map(process_test, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(config.batch_size*2)","b87f076a":"pred_y = my_model.predict(test_ds, workers=4, verbose=1)","13b763b6":"df_ss = pd.DataFrame(pred_y, columns = config.labels)","2ba932ef":"df_test['image_id'] = df_test.Path.str.split('\/').str[-1].str[:-4]\ndf_ss['StudyInstanceUID'] = df_test['image_id']\ndf_ss.head()","a0953393":"cols_reordered = ['StudyInstanceUID', 'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal',\n       'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n       'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n       'Swan Ganz Catheter Present']\n\ndf_order = df_ss[cols_reordered]","e04b8940":"df_order.to_csv('submission.csv', index=False)","4c5ee41c":"Distribution of patient in all the records","2d3acb1c":"<h1 style=\"border:2px solid Purple;text-align:center\">TensorFlow Implementation<\/h1>","21d6ffb8":"**Please upvote the Notebook if you liked the content**","a37a7888":"<h1 style=\"border:2px solid Purple;text-align:center\">Data Generator<\/h1>","5f4e8ed0":"I took a lot of help from Harveen's Notebook [here](https:\/\/www.kaggle.com\/harveenchadha\/efficientnetb3-tf2-keras-baseline\/notebook), please upvote his work as well.","e387e094":"<h1 style=\"border:2px solid Purple;text-align:center\">Model Evaluation<\/h1>","840a1ec6":"<h1 style=\"border:2px solid Purple;text-align:center\">Prepare Data<\/h1>","4c930f54":"<h1 style=\"border:2px solid Purple;text-align:center\">Configurations<\/h1>","9de19ee9":"    Columns of the Dataframe    \n    \n    StudyInstanceUID --> unique ID for each image\n    ETT - Abnormal --> endotracheal tube placement abnormal\n    ETT - Borderline --> endotracheal tube placement borderline abnormal\n    ETT - Normal --> endotracheal tube placement normal\n    NGT - Abnormal --> nasogastric tube placement abnormal\n    NGT - Borderline --> nasogastric tube placement borderline abnormal\n    NGT - Incompletely Imaged --> nasogastric tube placement inconclusive due to imaging\n    NGT - Normal --> nasogastric tube placement borderline normal\n    CVC - Abnormal --> central venous catheter placement abnormal\n    CVC - Borderline --> central venous catheter placement borderline abnormal\n    CVC - Normal --> central venous catheter placement normal\n    Swan Ganz Catheter Present\n    PatientID --> unique ID for each patient in the dataset","94ae2ab6":"<h1 style=\"border:2px solid Purple;text-align:center\">Model Creation<\/h1>","6ff213d1":"<h1 style=\"border:2px solid Purple;text-align:center\">Model Training<\/h1>","1bb6ae5a":"Splitting the df for training and Validation","4e77dd41":"**This is nice and simple baseline implemented in Tensorflow. And good for those who want to get started with this competition with baseline Tensorflow implementation.**","18c4724f":"**Do remember to upvote if you liked the content :)**","ec6455e2":"<h1 style=\"border:2px solid Purple;text-align:center\">Test Predictions<\/h1>","36ccbab1":"<h1 style=\"border:2px solid Purple;text-align:center\">Data Loader<\/h1>","d582e4af":"tf.data.Datasetfrom_tensor_slices --> Creates a Dataset whose elements are slices of the given tensors.\n\nThe given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.","fbf1c8d5":"<h1 style=\"border:2px solid Purple;text-align:center\">Final Submission<\/h1>","846f01e0":"<h1 style=\"border:2px solid Purple;text-align:center\">Basic Imports<\/h1>"}}