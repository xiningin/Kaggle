{"cell_type":{"5e5693f7":"code","d9a129b7":"code","7b7caa1a":"code","ae3a62d7":"code","52c8e755":"code","fba1f0db":"code","e42a89ee":"code","1838d439":"code","6d86cbce":"code","4712d629":"code","6286e7cb":"code","36607c64":"code","3d1c6e53":"code","c1d95061":"code","1b058804":"code","d2b3545d":"code","ad5dda16":"code","12a6d148":"code","51064f26":"code","54ab4874":"code","c2ba8a11":"code","64c53ee1":"code","773c936c":"code","44b39f98":"code","1f43af6e":"code","89e7b326":"code","0f79ac68":"code","acbd170e":"code","5e0c8682":"code","b2def182":"code","9fd0abaf":"code","9d2da24f":"code","f16b73f8":"code","c2e5d2f2":"markdown","2bdcfd75":"markdown","4ecdfc98":"markdown","b02cb219":"markdown"},"source":{"5e5693f7":"!pip install --upgrade pip setuptools wheel -q\n!pip uninstall -y tensorflow tensorflow-gpu -q\n!conda install tensorflow-gpu -y","d9a129b7":"## Install ImageDataAugmentor\n!pip install --upgrade albumentations -q\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor -q\n#!rm -r ImageDataAugmentor\/.git\/ #<- To get rid of Kaggle's \"Output path contains too many nested subdirectories\"-error","7b7caa1a":"import tensorflow as tf\nprint(tf.__version__)\nprint(tf.test.gpu_device_name())","ae3a62d7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, sys\nimport cv2\nimport itertools\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle\n\nfrom tensorflow.keras.utils import Sequence, to_categorical\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","52c8e755":"IMG_SIZE = 28\nSEED = 2021","fba1f0db":"os.listdir('..\/input\/')","e42a89ee":"## Fetch the prepared data\ntrain_df = pd.read_csv('..\/input\/train.csv')\nprint(\"Data fetched!\")\n\n## Constants\nnum_classes = train_df.label.nunique()\ncols = train_df.columns[1:]","1838d439":"## Define train and test arrays\nY_train = train_df['label']\nX_train = train_df.drop('label', axis = 1)","6d86cbce":"## Split train into train & validation sets\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=SEED, stratify=Y_train)","4712d629":"## Visualize the data\nplt.figure(figsize=(16,8))\nplt.subplot(121)\nsns.countplot(Y_train)\nplt.title('Train')\n\nplt.subplot(122)\nsns.countplot(Y_val)\nplt.title('Validation')\nplt.show()","6286e7cb":"## Visualize the images\ntmp = train_df.sample(frac=1).sort_values('label')\ntmp = tmp.groupby('label').head(10)\ntmp = tmp.set_index('label')\nrows = len(tmp)\/\/10+1\n\nplt.figure(figsize=(16,16))\nfor idx in range(len(tmp)):\n    plt.subplot(rows, 10, idx+1)\n    letter = tmp.iloc[idx].values.reshape(IMG_SIZE,IMG_SIZE)\n    plt.imshow(letter)\n    plt.title(tmp.index.values[idx])\n    plt.axis('off')\n\nplt.subplots_adjust(hspace=0.5, wspace=0.5)\nplt.show()","36607c64":"## Reshape data into tensor format\nX_train = X_train.values.reshape(-1,IMG_SIZE, IMG_SIZE, 1).astype(np.uint8)\nX_val = X_val.values.reshape(-1,IMG_SIZE, IMG_SIZE, 1).astype(np.uint8)","3d1c6e53":"## Transform targets into categorical vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes=num_classes)\nY_val = to_categorical(Y_val, num_classes=num_classes)","c1d95061":"## Define the model\nmodel = None\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5),padding='Same', \n                 activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5),padding='Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),padding='Same', \n                 activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),padding='Same', \n                 activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\"softmax\"))","1b058804":"## Define the optimizer & compile the model\noptimizer = Adam(lr=0.001, decay=0.001)\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","d2b3545d":"## Reduce the learning rate in case the learner hits a plateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","ad5dda16":"## Fix some parameters (adjust for best performance)\nepochs = 30\nbatch_size = 500","12a6d148":"## Data augmentation: just picked some from https:\/\/albumentations.readthedocs.io\/en\/latest\/api\/augmentations.html that sounded relevant\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.ShiftScaleRotate(\n        p=0.8, #apply these to 80% of the images\n        shift_limit=0.1, #translate by (-0.1%, 0.1%)\n        scale_limit=0.1, #zoom by (-0.1%, 0.1%)\n        rotate_limit=20, #rotate by (-20, 20)\n        border_mode=cv2.BORDER_CONSTANT, value = [0,0,0], #fill emptyness with (0,0,0)\n        ),\n    albumentations.Blur(blur_limit=1, p=0.2),\n    albumentations.ElasticTransform(alpha=0.1, sigma=5, alpha_affine=2,\n                                     border_mode=cv2.BORDER_CONSTANT, value = [0,0,0], #fill emptyness with (0,0,0)\n                                    ),\n    albumentations.ToFloat(max_value=255),\n])","51064f26":"## Define the train & validation generators\ntrain_data_gen = ImageDataAugmentor(augment=AUGMENTATIONS, seed=SEED)\ntraining_generator = train_data_gen.flow(X_train, Y_train, \n                                         batch_size=batch_size, \n                                         shuffle=True,\n                                         \n                                         )\n\nval_data_gen = ImageDataAugmentor(augment=albumentations.ToFloat(max_value=255), seed=SEED)\nvalidation_generator = val_data_gen.flow(X_val, Y_val, \n                                         batch_size=batch_size, \n                                         shuffle=True,\n                                         )","54ab4874":"## Visualize the augmented data\ntraining_generator.show_data()","c2ba8a11":"## Train the model\nhistory = model.fit(training_generator,\n                    steps_per_epoch=len(training_generator),\n                    epochs=epochs, \n                    validation_data=validation_generator,\n                    validation_steps=len(validation_generator),\n                    verbose=1, \n                    callbacks=[learning_rate_reduction]\n                   )","64c53ee1":"## Visualize the training history\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot(title='Losses')\nhistory_df[['acc','val_acc']].plot(title='Accuracies')\nplt.show()","773c936c":"## Calculate the accuracy from validation\nfl, fac = model.evaluate(X_val\/255., Y_val, verbose=0)\nprint(\"Final Loss =\",fl)\nprint(\"Final Accuracy =\",fac)","44b39f98":"## ## Uncomment to save the model\n## model.save(\"digit_model.h5\")","1f43af6e":"## Make predictions from test set\nY_pred_ohv = model.predict(X_val\/255.)\n\n## Flatten the predicted categorical labels\nY_pred = np.argmax(Y_pred_ohv, axis = 1) \n\n## Flatten the real categorical labels\nY_true = np.argmax(Y_val, axis = 1) ","89e7b326":"## Define the confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues): \n    ''' \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`\n    ''' \n \n    if normalize: \n        cm = np.round(cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap) \n    plt.title(title) \n    plt.colorbar() \n    tick_marks = np.arange(len(classes)) \n    plt.xticks(tick_marks, classes, rotation=45) \n    plt.yticks(tick_marks, classes) \n\n \n    thresh = cm.max() \/ 2. \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): \n        plt.text(j, i, cm[i, j], \n                 horizontalalignment=\"center\", \n                 color=\"white\" if cm[i, j] > thresh else \"black\") \n \n    plt.tight_layout() \n    plt.ylabel('True label') \n    plt.xlabel('Predicted label')\n    #plt.plot()","0f79ac68":"## Determine the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred) \n\n## Plot\nplt.figure(figsize=(16,8)) \nplt.subplot(121)\nplot_confusion_matrix(confusion_mtx, classes = range(num_classes))\nplt.subplot(122)\nplot_confusion_matrix(confusion_mtx, classes = range(num_classes), normalize=True)\nplt.show()\n","acbd170e":"## Checking the errors and visualizing them\nerrors = (Y_true- Y_pred != 0)\n\nY_true_errors = Y_true[errors]\nY_pred_errors = Y_pred[errors]\nX_val_errors = X_val[errors]\nY_ohv_errors = Y_pred_ohv[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    n = 0\n    nrows = 3\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True, figsize=(12,12))\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((IMG_SIZE,IMG_SIZE)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n## Probability of wrong prediction\ny_pred_errors_prob = np.max(Y_ohv_errors,axis = 1)\n\n## Probability of true values in error set\ntrue_prob_errors = np.diagonal(np.take(Y_ohv_errors, Y_pred_errors, axis=1))\n\n## Difference between true and error set\ndelta_pred_true_errors = y_pred_errors_prob - true_prob_errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n## Top 9 errors \nmost_important_errors = sorted_dela_errors[-9:]\n\n## Show the top 9 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_true_errors, Y_pred_errors)","5e0c8682":"## ## Uncomment to load the previously saved the model\n## model = None\n## model = load_model(\"digit_model.h5\")","b2def182":"## Fetch the test data\ntest_df = pd.read_csv('..\/input\/test.csv')\nprint(\"Data fetched!\")","9fd0abaf":"## Reshape data into tensor format\nX_test = test_df.values.reshape(-1,IMG_SIZE, IMG_SIZE, 1)","9d2da24f":"## Make predictions\nY_test = model.predict(X_test\/255.)\n\n## Flatten the predicted categorical labels\nY_test = np.argmax(Y_test, axis = 1) ","f16b73f8":"## Prepare the submission\nsubmit = pd.read_csv('..\/input\/sample_submission.csv')\nsubmit['Label'] = Y_test\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","c2e5d2f2":"## Fetch the data","2bdcfd75":"## Import necessary packages and functions","4ecdfc98":"## Robust digit training with ImageDataAugmentor\n\n> Data augmentation is an integral part in most of the of the contemporary ML pipelines. Using augmentations an image dataset can be artificially expanded by creating modified versions of the original images. Augmentations can be used in making a ML algorithm more robust by creating variations of the training set of images that are likely to be seen by the model in the real use case.\n\n> This kernel demonstrates the usage of ImageDataAugmentor [https:\/\/github.com\/mjkvaak\/ImageDataAugmentor\/blob\/master\/README.md], which is a custom image data generator for Keras supporting the use of modern augmentation modules (e.g. imgaug and albumentations). For reference, albumentations outperforms the Keras build in augmentation module in speed in EVERY transformation task - plus includes a huge number of augmentations that don't exist in the latter [https:\/\/github.com\/albu\/albumentations#benchmarking-results]. ","b02cb219":"## Predict on custom data\nThis could be your own data "}}