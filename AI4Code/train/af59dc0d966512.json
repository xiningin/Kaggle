{"cell_type":{"c005520b":"code","f95bbd2a":"code","3e0297e3":"code","fc1839a7":"code","85721e75":"code","c11b1a4d":"code","3e7393d1":"code","61ca1c3e":"code","f31b1b42":"code","e8b63e30":"code","b6506cff":"code","e06f0e96":"code","77c6f457":"code","1d7fd560":"code","45743c43":"code","97d9f3c7":"code","42e8d11e":"code","6fe30537":"code","19418662":"code","f2d6d187":"code","4c253571":"code","6d1db97a":"code","dec92dc4":"code","c70ef152":"code","f6e29d51":"code","1e464504":"code","29b835d9":"code","8a2c5499":"code","7e7f88d5":"code","814aacfb":"code","81e72afb":"code","8a310d20":"code","48802516":"code","3d6ac9b4":"code","79bc1b32":"code","149478ee":"code","dad84b73":"code","46b2c07c":"code","75fc7af4":"code","8abea3ce":"code","f28d4642":"code","cb8f2dd8":"code","910670ae":"code","3aa3e367":"code","a5107fa6":"code","81131b33":"code","546d6fdb":"code","e45abbaf":"code","fcf1b00b":"code","e5c37cfa":"code","a5047e04":"code","08ede993":"code","75f0067d":"code","458202fe":"code","c36e41d3":"code","b7bd080d":"code","953a6eef":"code","b8b5adef":"code","c56416f3":"code","513586e1":"code","32e792ee":"code","defe8b39":"code","b438803c":"code","7023c852":"code","b111b9ad":"code","a7c620f2":"code","9846aa1a":"code","275e24a6":"code","926b6f14":"code","97d70e00":"code","69f2f746":"code","8eaaa13f":"code","f9d20689":"code","b8adfd7f":"code","065937db":"code","060be043":"code","5ca251b1":"code","a52dac37":"code","fce4826c":"code","a6af53bc":"code","24efc159":"markdown","d853d523":"markdown","393405ac":"markdown","b22f98e0":"markdown","a0cbaf5a":"markdown","825c6c3a":"markdown","b5e0d2b2":"markdown","e692b713":"markdown","3981c44c":"markdown","714002c8":"markdown","336e64b5":"markdown","71b54b1c":"markdown","0cc8b25e":"markdown","4f6570dc":"markdown","407bd832":"markdown","6c9f70b2":"markdown","1ee42e8b":"markdown","dc909ecf":"markdown","725e5e37":"markdown","2818ee62":"markdown","0960cd58":"markdown","658e97ca":"markdown","9fe3a6df":"markdown","393d91d6":"markdown","620939e1":"markdown","6b781b85":"markdown","9a371b71":"markdown","c6b17e0e":"markdown","78eef616":"markdown","fdc04b25":"markdown","900be581":"markdown","b7924119":"markdown","60c12bf4":"markdown","e5273bbf":"markdown","4e58800b":"markdown"},"source":{"c005520b":"import pandas as pd \nimport numpy as np \nimport seaborn as sb \nimport matplotlib.pyplot as plt \nimport geopandas as geo\n%matplotlib inline","f95bbd2a":"# read in data\ncali= geo.read_file(r\"..\/input\/covid19\/CA_Counties_TIGER2016.shp\")\ncali.head()","3e0297e3":"# read in data\ncases=pd.read_csv(r\"https:\/\/raw.githubusercontent.com\/nytimes\/covid-19-data\/master\/us-counties.csv\")\ncali_cases= cases[cases[\"state\"]==\"California\"]\ncali_cases.head()","fc1839a7":"cali_cases=cali_cases.reset_index().drop(\"index\", axis=1)","85721e75":"cali_cases=cali_cases.drop(\"fips\",axis=1)\ncali_cases.info()","c11b1a4d":"# When I combined the data, I chose inner join since I wanted to keep the counties that were present in both datasets. \ncovid=cali_cases.merge(cali, left_on=\"county\",right_on=\"NAME\", how=\"inner\")\ncovid.head()","3e7393d1":"# Keep interested columns \ncovid=covid[[\"date\",\"county\",\"cases\",\"deaths\",\"geometry\"]]\ncovid.shape","61ca1c3e":"covid.head()","f31b1b42":"# Calculates the new cases\/deaths and growths for one county\ndef fun(name,covid=covid):\n    county=covid[covid[\"county\"]== name]\n    county= county.reset_index()\n    new_cases= [county[\"cases\"][0]]+[county[\"cases\"][i]-county[\"cases\"][i-1]for i in range(1,len(county[\"cases\"]))]\n    new_deaths= [county[\"cases\"][0]]+[county[\"deaths\"][i]-county[\"deaths\"][i-1]for i in range(1,len(county[\"cases\"]))]\n    county[\"new_cases\"]=new_cases\n    county[\"new_deaths\"]= new_deaths\n    g=[0]\n    for i in range(1,len(county[\"new_cases\"])): \n        x= ((county[\"new_cases\"][i]-county[\"new_cases\"][i-1])\/county[\"new_cases\"][i-1])*100\n        g.append(x)\n    county[\"cases_growth\"]= g\n    h=[0]\n    for i in range(1,len(county[\"new_deaths\"])): \n        x= ((county[\"new_deaths\"][i]-county[\"new_deaths\"][i-1])\/county[\"new_deaths\"][i-1])*100\n        h.append(x)\n    county[\"death_growth\"]= h\n    county[\"date\"]= pd.to_datetime(county[\"date\"])\n    return county\n","e8b63e30":"# Implements the function on all counties and puts them into one dataframe\ncounties= covid[\"county\"].unique()\ngdf= fun(counties[0])\nfor i in counties[1:]: \n    x= fun(i)\n    gdf= pd.concat([gdf,x], ignore_index=True)\ngdf.shape","b6506cff":"gdf.head(10)","e06f0e96":"# total represents all of california data\ntotal= gdf.groupby(\"date\").sum()\ntotal=total.reset_index().drop(\"index\",axis=1)\ntotal.head()","77c6f457":"fig,axes= plt.subplots(1,2,figsize=(20,5))\nfig.suptitle(\"COVID New Cases\")\nshrunk=total[total[\"date\"]>=\"2020-03-01\"]\naxes[0].plot(\"date\",\"new_cases\", data=shrunk)\naxes[0].set_title(\"Number of New Cases\")\naxes[1].plot(\"date\",\"new_deaths\", data=shrunk, color=\"red\")\naxes[1].set_title(\"Number of New Deaths\")\nfor ax in axes: \n       ax.tick_params(\"x\",labelrotation=90)\n       ax.set_xlabel(\"Date\")\n       ax.set_ylabel(\"Number of New Cases\")\n        ","1d7fd560":"# Need to recalcuate growth percentages after groupby\ng=[0]\nfor i in range(1,len(total[\"new_cases\"])): \n        x= ((total[\"new_cases\"][i]-total[\"new_cases\"][i-1])\/total[\"new_cases\"][i-1])*100\n        g.append(x)\ntotal[\"cases_growth\"]= g\nh=[0]\nfor i in range(1,len(total[\"new_deaths\"])): \n        x= ((total[\"new_deaths\"][i]-total[\"new_deaths\"][i-1])\/total[\"new_deaths\"][i-1])*100\n        h.append(x)\ntotal[\"death_growth\"]= h","45743c43":"plt.figure(figsize=(8,8))\nshrunk=total[total[\"date\"]>=\"2020-03-01\"]\nplt.plot(\"date\",\"cases_growth\", data=shrunk)\nplt.plot(\"date\",\"death_growth\", data=shrunk)\nplt.xticks(rotation=90)\nplt.legend();\nplt.title(\"COVID Daily Growth Rate\");","97d9f3c7":"# Calculate the average number of people who contract the coronavirus daily\ndef average_new_cases_percent(table, start,end): \n    shrunk=table[(table[\"date\"]>= start) & (table[\"date\"]<= end) ]\n    shrunk=shrunk.reset_index()\n    return (np.mean(shrunk[\"new_cases\"])\/shrunk[\"e_totpop\"][0])*100\ndef average_new_death_percent(table, start,end): \n    shrunk=table[(table[\"date\"]>= start) &( table[\"date\"]<= end)]\n    shrunk= shrunk.reset_index()\n    return (np.mean(shrunk[\"new_deaths\"])\/shrunk[\"e_totpop\"][0])*100\n\ndef ave(d,start,end): \n    av_cases=[]\n    av_deaths=[]\n    for i in d[\"county\"].unique(): \n        df=d[d[\"county\"]==i]\n        av_cases.append(average_new_cases_percent(df,start,end))\n        av_deaths.append(average_new_death_percent(df,start,end))\n    averages= pd.DataFrame()\n    averages[\"county\"]= d[\"county\"].unique()\n    averages[\"av_cases_daily\"]= av_cases\n    averages[\"av_deaths_daily\"]= av_deaths\n    print(\"Top 25 cases:\")\n    print(averages.sort_values(by=\"av_cases_daily\", ascending=False).head(25).reset_index()[[\"county\",\"av_cases_daily\"]])\n\n    return averages\n    \n    \n    ","42e8d11e":"# Combining the cases dataframe with a dataframe that contains the estimated population.(read in a later cell)#\nnew= gdf.merge(jo ,on=\"county\")\nnew.head()","6fe30537":"av=ave(new,\"2020-03-01\",\"2020-6-09\")","19418662":"Imperial= av.loc[34][1]\nsb.distplot(av[\"av_cases_daily\"]);\nplt.scatter(Imperial, 0, color='red', s=100);\nplt.title(\"Average Percent of Population contracting COVID Daily  \");","f2d6d187":"# only kept Counties with 100+ cases\ncovid[\"date\"]= pd.to_datetime(covid[\"date\"])\nfinal= covid[covid[\"date\"]==\"2020-6-09\"]\nfinal[\"d\/c\"]=final[\"deaths\"]\/ final[\"cases\"]\nsfinal= final[final[\"cases\"]>99]\nprint(\"Top 25 death ratio:\")\nprint(sfinal.sort_values(by=\"d\/c\", ascending=False).head(25).reset_index().drop(\"index\", axis=1)[[\"county\",\"cases\",\"deaths\",\"d\/c\"]])","4c253571":"Yolo=sfinal.sort_values(by=\"d\/c\", ascending=False).head(1)[\"d\/c\"][1867]\nsb.distplot(sfinal[\"d\/c\"]);\nplt.scatter(Yolo, 0, color='red', s=100)\nplt.title(\"Death\/Cases ratio\");","6d1db97a":"# Shapiro Wilk Test to test for normality ; no YOLO\nfrom scipy import stats\nno=sfinal.drop(1867)\nprint(no.skew())\np_value=stats.shapiro(no[\"d\/c\"])[1]\nif p_value< .05: \n    print(\"Reject Null hypothesis of normality\")\nelse: \n    print(\"Fail to reject Null Hypothesis\")","dec92dc4":"# read in dataset with population numbers\nsocial= pd.read_csv(r\"..\/input\/covid19\/cdcs-social-vulnerability-index-svi-2016-overall-svi-county-level.csv\")\nsocial= social[social[\"state\"]==\"CALIFORNIA\"]\npop= social[[\"county\",'e_totpop']]\njo=pop.copy()","c70ef152":"# join the dataset with COVID-19 cases \nfinal1=covid[covid[\"date\"]==\"2020-6-09\"]\ngrouped=pop.merge(final1, on=\"county\", how=\"inner\")\n","f6e29d51":"# Calculate percent \ngrouped[\"casesp\"]= (grouped[\"cases\"]\/grouped[\"e_totpop\"])*100\ngrouped[\"deathsp\"]= (grouped[\"deaths\"]\/grouped[\"e_totpop\"])*100\ngrouped.head()","1e464504":"print(grouped.sort_values(\"casesp\", ascending=False)[[\"county\",\"e_totpop\",\"cases\",\"casesp\"]].reset_index().drop(\"index\", axis=1).head(25))","29b835d9":"plt.close()\nchanged= grouped.copy()\npiv_cases=geo.GeoDataFrame(changed)\npiv_cases[\"casesp\"]= piv_cases[\"casesp\"].replace(max(piv_cases[\"casesp\"]),.65)\npiv_cases[\"casesp\"]= piv_cases[\"casesp\"].replace(max(piv_cases[\"casesp\"]),.65)\nax= piv_cases.plot(column=\"casesp\",cmap=\"OrRd\",figsize=(10,10),legend=True,edgecolor=\"black\",linewidth=0.4)\nax.set_title(\"Percentage of People with COVID-19 up to June 9th \")\nax.set_axis_off()","8a2c5499":"# keep all features represented as a percent \nkeep=[\"county\",\"geometry\",\"ep_pov\",\"ep_unemp\",\"ep_nohsdp\",\n     \"ep_age65\",\"ep_age17\",\"ep_disabl\",\"ep_sngpnt\",\n      \"ep_minrty\",\"ep_limeng\",\n     \"ep_munit\",\"ep_mobile\",\"ep_crowd\",\"ep_noveh\",\"ep_groupq\"]","7e7f88d5":"social=social[keep]\n","814aacfb":"# combinbe cases and SVI data\nsocial_cases=grouped.merge(social,on=\"county\")\nsocial_cases.head()","81e72afb":"# Create correlation heatmap\nplt.figure(figsize=(10,10))\nplt.title(\"Heatmap for Social Vulnerability Features\")\nkeep1= keep[2:]+[\"casesp\",\"deathsp\",\"county\"]\npplot= social_cases[keep1]\npcorr= pplot.corr()\nax=sb.heatmap(pcorr,vmin=-1, vmax=1, center=0, cmap=sb.diverging_palette(20, 220, n=200),square=True)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right');\n","8a310d20":"interested=[\"ep_pov\",\"ep_munit\",\"ep_crowd\",\"casesp\"]\npplot1=pplot[interested]\n\n","48802516":"# find where counties are and remove\nprint(np.where(pplot[\"county\"]==\"Imperial\"))\nprint(np.where(pplot[\"county\"]==\"Kings\"))","3d6ac9b4":"none=pplot.drop([54,55])","79bc1b32":"v=[\"ep_pov\",\"ep_munit\",\"ep_crowd\"]\nfig,ax=plt.subplots(1,3,figsize=(25,5))\nfig.suptitle('Casesp vs Social Factors without Imperial and Kings County', fontsize=20)\nfor rows,j in zip(ax,v): \n    rows.scatter(x=none[j],y=none[\"casesp\"])\n    rows.set_xlabel(j)\n    rows.set_ylabel(\"casesp\")","149478ee":"# need to scale the variables \ndef min_max(x): \n    return (x- min(x))\/(max(x)-min(x))\n    ","dad84b73":"none[\"crowd2\"]= none[\"ep_crowd\"]**2","46b2c07c":"for i in [\"ep_munit\",\"ep_crowd\",\"crowd2\"]: \n    none[i]= min_max(none[i])","75fc7af4":"# build stats models\nimport statsmodels.api as sm\nnone[\"intercept\"]=1\nmod1= sm.OLS(none[\"casesp\"],none[[\"intercept\",\"ep_munit\",\"ep_crowd\",\"crowd2\"]])\nres1=mod1.fit()","8abea3ce":"res1.summary()","f28d4642":"mod2= sm.OLS(none[\"casesp\"],none[[\"intercept\",\"ep_munit\",\"ep_crowd\"]])\nres2=mod2.fit()\nres2.summary()","cb8f2dd8":"print(social.sort_values(\"ep_munit\", ascending=False)[[\"county\",\"ep_munit\"]].reset_index().drop(\"index\", axis=1).loc[:9])","910670ae":"print(social.sort_values(\"ep_crowd\", ascending=False)[[\"county\",\"ep_crowd\"]].reset_index().drop(\"index\", axis=1).loc[:9])","3aa3e367":"new=social.merge(cali, left_on=\"county\",right_on=\"NAME\", how=\"inner\")[[\"county\",\"geometry_y\",\"ep_crowd\",\"ep_munit\"]]\nnew.rename(columns = {'geometry_y':'geometry'}, inplace = True)","a5107fa6":"plt.close()\n\nnew=geo.GeoDataFrame(new)\nax= new.plot(column=\"ep_munit\",cmap=\"Greens\",figsize=(10,10),legend=True,edgecolor=\"black\",linewidth=0.4)\nax.set_title(\"Percent of People in Housing with 10 or more Units \")\nax.set_axis_off()","81131b33":"plt.close()\n\nnew=geo.GeoDataFrame(new)\nax= new.plot(column=\"ep_crowd\",cmap=\"Greens\",figsize=(10,10),legend=True,edgecolor=\"black\",linewidth=0.4)\nax.set_title(\"Percent of Houses with More People than Rooms \")\nax.set_axis_off()","546d6fdb":"# read in Google Mobility Data\nglob=pd.read_csv(r\"..\/input\/covid19\/Global_Mobility_Report.csv\")\nusa= glob[glob[\"country_region\"]== \"United States\"]\ncal= usa[usa[\"sub_region_1\"]== \"California\"]\ncal.head()","e45abbaf":"cali_total= cal[cal[\"sub_region_2\"].isna()==True]","fcf1b00b":"cali_total[\"date\"]=pd.to_datetime(cali_total[\"date\"])","e5c37cfa":"col=cali_total.columns[7:]","a5047e04":"col[3:6]","08ede993":"cal[\"date\"]=pd.to_datetime(cal[\"date\"])","75f0067d":"plt.close()\nfig, axes= plt.subplots(2,3, figsize=(20,20))\nfig.suptitle(\"California Mobility Data\", size=15);\nplt.subplots_adjust(wspace = 0.2,hspace = 0.2)\nfor i in range(2):\n    x=col[:3]\n    y=col[3:6]\n    for j in range(3): \n        if i==0: \n            axes[i,j].plot(cali_total[\"date\"],cali_total[x[j]])\n            axes[i,j].tick_params(axis='x',rotation=90);\n            axes[i,j].set_title(x[j]);\n            axes[i,j].set_ylabel(\"Percent from Baseline\");\n            axes[i,j].set_xlabel(\"Date\");\n        if i==1: \n            axes[i,j].plot(cali_total[\"date\"],cali_total[y[j]])\n            axes[i,j].tick_params(axis='x',rotation=90);\n            axes[i,j].set_title(y[j]);\n            axes[i,j].set_ylabel(\"Percent from Baseline\");\n            axes[i,j].set_xlabel(\"Date\");","458202fe":"# read in data\nhealth=pd.read_csv(r\"..\/input\/covid19\/crowd-sourced-covid-19-testing-locations.csv\")\nhealth.head()","c36e41d3":"# California represented two ways CA and California\nhealth[\"location_address_region\"].unique()","b7bd080d":"# Find just california and CA\ncali_health=health[(health[\"location_address_region\"]==\"CA\" )|(health[\"location_address_region\"]==\"California\")]\ncali_health.head()","953a6eef":"cali_health.shape","b8b5adef":"cali_health[\"is_location_screening_patients\"].value_counts()","c56416f3":"# The following cells make sure the coordinate system is same for plotting\nscreening= cali_health[cali_health[\"is_location_screening_patients\"]==\"t\"]","513586e1":"screening=geo.GeoDataFrame(screening)\n","32e792ee":"cali.crs = {'init' :'epsg:4326'}","defe8b39":"screening.crs=cali.crs","b438803c":"screening.drop(\"geometry\", axis=1, inplace=True)","7023c852":"gdf = geo.GeoDataFrame(\n    screening, geometry=geo.points_from_xy(screening[\"lng\"], screening[\"lat\"]))","b111b9ad":"gdf.crs=cali.crs","a7c620f2":"# Note: Because LA has such a large population, using the real population of LA creates a poor map. Therefore, I changed it to another value. The axis is still correct. \nplt.close()\npiv_cases=geo.GeoDataFrame(grouped)\npiv_cases.crs= cali.crs\npiv_cases[\"e_totpop\"]=piv_cases[\"e_totpop\"].replace(max(piv_cases[\"e_totpop\"]),3253356)\n\nbase= piv_cases.plot(column=\"e_totpop\",cmap='BuGn',figsize=(10,10),legend=True,edgecolor=\"black\",linewidth=0.4)\ngdf = gdf.to_crs({'init': 'epsg:3857'})\nax=gdf.plot(ax=base,figsize=(10,10),zorder=2,color=\"red\")\nax.set_title(\"Population vs COVID Testing Centers \")\nax.set_axis_off()","9846aa1a":"# read in Data\nbed_counts=pd.read_csv(r\"..\/input\/covid19\/bed_counts.csv\")\nbed_counts.head()","275e24a6":"# change Counties to Lowercase\nbed_counts[\"county\"]= [i.lower() for i in bed_counts[\"COUNTY_NAME\"]]","926b6f14":"# Capitalize first letter of each word in County Name \ndef capital(ls): \n    if len(ls)==1: \n        return ls[0].capitalize()\n    else: \n        return ls[0].capitalize()+\" \" +capital(ls[1:])","97d70e00":"bed_counts[\"county\"]= [capital(i.split())for i in bed_counts[\"county\"]]","69f2f746":"icu_beds= bed_counts[[\"county\",\"INTENSIVE CARE\"]]","8eaaa13f":"# Get ICU COVID data\nicu_counts=pd.read_csv(r\"..\/input\/covid19\/icu_cases.csv\")\nicu_counts.head()","f9d20689":"icu_counts[\"total_icu\"]= icu_counts[\"ICU COVID-19 Positive Patients\"]+ icu_counts[\"ICU COVID-19 Suspected Patients\"]","b8adfd7f":"icu_counts[\"Most Recent Date\"]=pd.to_datetime(icu_counts[\"Most Recent Date\"])","065937db":"icu= icu_counts[icu_counts[\"Most Recent Date\"]==\"2020-06-09\"]","060be043":"# combine all data sets \nk=icu.merge(icu_beds, left_on=\"County Name\", right_on=\"county\", how=\"inner\").drop(\"county\", axis=1)\ncali_icu= k.merge(cali, left_on=\"County Name\", right_on=\"NAME\", how=\"inner\")\ncali_icu.head()\n","5ca251b1":"cali_icu.shape","a52dac37":"# Calculate Percentage \ncali_icu[\"percent\"]=(cali_icu[\"total_icu\"]\/cali_icu[\"INTENSIVE CARE\"])*100","fce4826c":"print(cali_icu.sort_values(by=\"percent\", ascending=False)[[\"County Name\",\"total_icu\",\"INTENSIVE CARE\",\"percent\"]].reset_index().drop(\"index\", axis=1).head(10))","a6af53bc":"# Imperial counnty reduced on map because it is an outlier. However, axis is still correct. \nplt.close()\nco= cali_icu.copy()\nco[\"percent\"]=co[\"percent\"].replace(max(co[\"percent\"]),37)\npiv_cases=geo.GeoDataFrame(co)\nax=piv_cases.plot(column=\"percent\",cmap='Purples',figsize=(10,10),legend=True,edgecolor=\"black\",linewidth=0.4)\nax.set_title(\"Percent of ICU Beds Used by Covid-19\")\nax.set_axis_off()","24efc159":"## Analysis of Risk Factors","d853d523":"## Abstract for Kaggle: ","393405ac":"The first map represents MUNIT while the second represent CROWD.  Regarding the first map, it shows that a majority of this type of apartment housing is concentrated in urban, high populated counties. In fact, San Francisco County leads this category with 36.5% of its housing in this manner. This is followed by Los Angeles County (26.5%), Alpine(24.6%), Alameda(21.2%), and Santa Clara(21.1%).  This is to be expected of these regions as they contain a high volume of people in a confined area.  However, the percentages depicted by the second map of overcrowded houses seems to be distributed more evenly across California.  Central California seems to possess lots of crowding relative to the other counties, which differs from the second map. The top crowded counties are Monterey(12.8%), Los Angeles (11.8%), Imperial(10.4%), Santa Barbara(10.2%), Tulare(9.9%).  It is especially noteworthy that Los Angeles county, which I deemed the hardest hit by COVID-19 is near the top on both lists. ","b22f98e0":"### Source : CDC Social Vulnerability Score 2016 ","a0cbaf5a":"Now, let\u2019s consider the number of people with COVID-19 as a percent of population as of June 9th:","825c6c3a":"The Coronavirus Data was obtained from the New York Times GitHub, and the California shapefile was obtained by the California Government. The first step is to preprocess and clean the data. ","b5e0d2b2":"The source I will be analyzing is the Center for Disease Controls Social Vulnerability score data, which I obtained from Kaggle. This dataset, which is on the county level, comprises of features that can be grouped into four categories- Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing & Transportation. Furthermore, in the dataset, one feature is represented in three different formats- as a value, as a percent, and as a percentile. In my analysis, I will only look at the values as a percentage.","e692b713":"The data for testing access was obtained on Kaggle by the organization Coders against COVID-19. This dataset is a crowdsourced list of testing centers across the United States. ","3981c44c":"The data for ICU bed counts and COVID patients win ICU where obtained by the California Department of Public Health. ","714002c8":"1. Scientific Rigor: My project utilizes very credible data from the New York Times, CDC, California Department of Health, Google, and Coders AGainst COVID. \n2. Scientific Model and Strategy: My procedures are very data driven. I back all my conclusions with data, and use statistical techniques like regressions to find patterns and relationships in the data. \n3. Novel Insights: I have summarized my key findings in the end of the notebook. However, some important novel insights are the third and forth key point: \n    3.While Imperial and Kings counties have been able to keep the death: cases ratio low, the low ICU availability and the high percentage of the population with the virus may be a strong indication that these counties might experience a higher death\/cases ratio in the coming weeks.\n    \n    4.There is a strong relationship between a counties COVID-19 cases as a percentage of population and the metrics: percentage of people with housing with 10 or more units and percentage of houses with more rooms than people. This may be due in part to California\u2019s social distancing policies. \n4. Market Translation and Applicability: This notebook resolves a need for State-wide Public Health officials as it analyzes very recent COVID-19 data, identifies hard hit and potentially at risk counties, and provides some insights into why counties differ in their COVID-19 cases as a percent of county population. \n5. Speed to market: The important features of the regression and ICU results should be integrated in risk-assesment tools when determing resource allocation. \n6. Longevity of solution in market: This notebook can be duplicated in other states easily, because all the data is publically available in the same datasets used here. \n7. Ability of user to collaborate and contribute to other solutions within the Kaggle community: Lots of these data sources were obtaied from Kaggle, so I am contributing by analyzing them and providing insights. \n \n","336e64b5":"The COVID Percentage Daily Growth Rate is interesting as it shows some dates had an unusually high peak.  While the early peaks in March could be attributed to small numbers, the large peak in cases in Mid-April, and the large peak in deaths in Mid-May is interesting. There could be many possible reasons.  One reason could be delays in hospital\/ other sources reporting, which could erroneously attribute more cases to a certain day.  Another reason could be abnormal social events. For instance, it may not be a coincidence that the spike in growth in Mid-April (approx.- 15th-20th) occurred during the increase in stay at home order protests (https:\/\/www.foxnews.com\/us\/california-protest-erupts-over-states-coronavirus-stay-at-home-rules). However, I do not know the exact reason and it could still be something else. ","71b54b1c":"****I decided to preform two least squares regressions. The first regression is the model with all our features.  The P-values show ep_munit is an extremely significant variable as it has a very small p-value.  Crowd 2 also has a small p-value of 0.069, though it is not significant in this model as this is above the custom 0.05 threshold. Furthermore, it appears that ep_crowd is not significant in this model. The model explained 58.4% of the variation(r^2). The second model is a simpler model, as it contains just the variables without the squared feature. In this model, both variables are statistically significant with low p-values. Also, the R-Squared and adjusted R-squared values are only about .02 lower than the more complex model. This increases favorability for the simpler model as it is more transparent and almost as effective. \n\nFrom this regression analysis, it is clear that the ep_munit and ep_crowd characteristics are very important characteristics that could explain the difference in spread of COVID-19 in California. Just these two variables explain more than a majority (55.6%) of the variation in total cases as a percentage as a population.  Intuitively, this provides evidence to the theory that counties with more apartment\/dorm-like structures, should have a higher COVID case percentage since people are in more frequent contact with each other.  \n","0cc8b25e":"# COVID 19 in California Exploratory Data Analysis","4f6570dc":"To calculate the number of COVID-19 ICU patients, I decided to add the number of ICU COVID positive patients with ICU COVID Suspected Patients.","407bd832":"## Analysis of Testing Access, and ICU availability across California","6c9f70b2":"As the Coronavirus continues to spread it has become ever more apparent that we are dealing with the biggest public health challenge of our generation. Fortunately, California\u2019s state and county officials have been working tirelessly for months to help protect and ensure the safety of all citizens. Thus, the purpose of this project is to utilize my data wrangling, visualization, and analytical skills to obtain some insight on the spread of the coronavirus in California and learn about the challenges that our government experts are facing while making these tough decisions. In this report, I will not only share my results but also go in-depth into the decisions taken to come to my conclusions. \nThis analysis is divided into three parts: \n1.\tOverview of the Spread of COVID-19 in California \n2.\tAnalysis of some Factors that could explain the differences in spread among counties\n3.\tAnalysis of Testing Access, and ICU availability across California. \n","1ee42e8b":"The question of whether there are certain groups of people that are restricted access to testing can only truly be answered at a county level. However, to get a general sense if there were any high population areas that did not have any adequate testing centers, I decided to plot the COVID testing centers on top of a population map of California. It appears that the testing centers are concentrated in high population counties with lower population counties having relatively fewer testing centers. This is logical as the more populous areas should have more resources allocated towards them. ","dc909ecf":"The data for ICU bed counts and COVID patients with ICU where obtained by the California Department of Public Health. To calculate the number of COVID-19 ICU patients, I decided to add the number of ICU COVID positive patients with ICU COVID Suspected Patients. Looking at the map, it is clear that Southern California ICUs are filling fast due to COVID 19. This is probably due to the higher number of COVID cases as a percent of population. Additionally, the county with the highest Percentage is Imperial (approx. 64%), which is nearly 1.8x higher the next largest county, Kings County (approx. 37%).  Following these counties is San Joaquin (approx. 31%), Orange (approx. 27%) and San Diego (approx. 26%). Los Angeles County is ranked 8th on the list with approx. 24%. Based on this data and previous findings, Imperial County and Kings County are the counties that could be most at risk. While they have been able to keep the death: cases ratio low, the low ICU availability and the high percentage of the population with the virus may be a strong indication that these counties might experience a higher death\/cases ratio in the coming weeks. Therefore, more resources should be provided to these two counties to ensure that this does not happen. ","725e5e37":"## Key Findings \n\n1.\tFrom April 15 to mid-May (approx. May-15th), the rate of overall increase is smaller than from mid-May to June-9th.\n2.\tEven though Imperial county has a very high percentage of cases, LA county's top three presence when it comes to cases and deaths makes it the hardest hit county. \n3.\tWhile Imperial and Kings counties have been able to keep the death: cases ratio low, the low ICU availability and the high percentage of the population with the virus may be a strong indication that these counties might experience a higher death\/cases ratio in the coming weeks.\n4.\tThere is a strong relationship between a counties COVID-19 cases as a percentage of population and the metrics: percentage of people with housing with 10 or more units and percentage of houses with more rooms than people. This may be due in part to California\u2019s social distancing policies.  \n","2818ee62":"### Testing Access","0960cd58":"I read in the data, checked it for nulls, merged the dataset, and kept the columns I wanted. The next step is to realize that the NYT coronavirus dataset contains the cumulative number of cases and deaths. However, for my analysis, I want the daily number of new cases\/deaths, and the growth in daily new cases\/deaths. This would be better than cumulative for a time series, because it would give me a clearer sense of how the coronavirus has progressed daily over the past few months.","658e97ca":"Before I delve into individual counties, I first want to learn about how California has progressed as a whole. ","9fe3a6df":"There are a total of 182 centers in California in this dataset. However, only 170 centers screen for COVID-19.","393d91d6":"These graphs represent the number of new cases \/deaths and the growth rates from March 1st until June 9th.  The number of new cases has fluctuated greatly from day to day but has shown a trend of overall increase.  However, while the number of new deaths fluctuates a lot more, we do not see this same pattern of overall increase from April-15 to June. Additionally, looking closer at the rate of overall increase for new cases from the COVID new cases graphs, it appears that from April 15 to mid-May (approx. May-15th), the rate of overall increase is smaller than from mid-May to June-9th. This could be due to reopening policies and the protests. ","620939e1":"Lets visualize these two features: ","6b781b85":"My next preprocessing step was to remove outliers. This is a tough task since this is a small dataset. While removing lots of large data points will increase our r^2 performance, we also might lose important information. Therefore, to balance this I decided to just remove Kings and Imperial County. ","9a371b71":"### ICU Availability","c6b17e0e":"## Overview of the Spread of COVID-19 in California","78eef616":"Here are scatterplots which compare our features.  From the first plot, poverty is not correlated. Thus, I decided not to use it for the regression.  By observing the plots for crowd, I decided that adding a square polynomial feature would be beneficial due to the fact that the cases percentage seems to grow faster for 8-12 percent than for 2-6 percent. I decided to leave ep_munit alone. Initially, it may appear that ep_munit could benefit from the addition of a fractional polynomial feature since it appears to level off after 20%. However, the larger datapoints are sparse, and therefore there is reason to believe that this phenomenon could just be caused by a lack of data.  The final step was to min-max scale the variables. ","fdc04b25":"Like the percentage distribution, there is an outlier in the total death\/cases ratio. However, this time it is Yolo county, with a death: cases ratio of approximately 0.11 which is approximately double the next largest county (San Diego), which has a ratio of 0.05. Following San Diego is Los Angeles County with 0.041, Tulare 0.039, and San Mateo 0.038. Yolo Counties position on top could be due to a combination of its low total number of cases (only 228), and the \"riskiness\" of the population who have contracted the virus. Also, it is interesting that Los Angeles and Tulare have maintained high positions on both lists, while Kings and Imperial counties are not even in the top 25 when considering death: cases ratio. Furthermore, because some counties have very few cases and deaths, I decided to limit the distribution to counties with 100 or more cases. \n\nAlso, it is apparent from the histogram and the Shapiro\u2013Wilk test, that this distribution is normal when Yolo County is removed.  ","900be581":"This map clearly shows that the counties with a higher percentage of COVID-19 cases are mostly in Southern California, with the number of lightly impacted counties increasing as we progress north. Furthermore, the county with the highest percentage is Imperial with approx. 1.75% infected, which is more than 10x higher than the median county. Following Imperial is Kings with approx.  1.08% infected, Los Angeles with approx. 0.65% infected, Tulare with approx. 0.52% infected and Santa Barbara with approx. 0.41 % infected. Taking all three of these statistics into account, I believe that the county hit the hard by COVID-19 has been Los Angeles county. Even though Imperial county has a very high percentage of cases, LA county's top three presence when it comes to cases and deaths makes it the hardest hit county.  ","b7924119":"The distribution seems to be right skewed. Most of the percentages are between .001% and .002%. The outliers are Imperial (shown in red), with a percentage of approximately 0.0213%, and Kings County with a percentage of approximately 0.0145%. These are more than 10x higher than the median California county! Following these counties are Los Angeles County with approx. 0.0065%, Tulare with approx.  0.0058%, and Modoc with approx. 0.0055%. It is important to note that these are not the percentage of people with COVID-19 cases (to come later), but instead represent the percentage of people we can expect to obtain COVID-19 on a typical day.   ","60c12bf4":"Furthermore, the strong relationship between the percentage of COVID-19 cases in a county and housing characteristics may be due in part to California\u2019s social distancing policies.  The time series graphs represent Google Mobility for grocery\/pharmacy, parks, transit, retail\/recreation, residential and workplace.  While Mobility in places like parks and grocery have returned to base levels recently, overall, the mobility in public places has been drastically reduced during the period. This trend and the drastic increase in residential mobility are strong indicators that the social distancing efforts have been efficient. However, the trade-off with this policy is that it leads people in overcrowded and compact living spaces at risk, thus providing a potential hypothesis to explain the results of the regression. ","e5273bbf":"Now that we understand how the Coronavirus has progressed in California as a whole, lets analyze the growth in specific counties and uncover which counties have been hit the hardest. To do this, I will be utilizing two metrics- average number of people who contract the coronavirus daily as a percentage of total population and the ratio of total death\/cases. I chose to observe the percent of total population instead of the number of people, because I did not want to bias my results against small counties. Also, I decided to use the ratio of death\/cases to understand where the virus is more deadly since the total percentage of population is very small and the death\/cases ratio is a better representation off the killing efficiency of the virus.  ","4e58800b":"To determine which features are most relevant, I will perform a multivariate regression with the social vulnerability variables as the features and the number of cases as a percent of county population as the label. However, first, I did some preprocessing. The first step of the preprocessing was to choose the best features that minimize co-linearity. While there are statistical tools that can do this like the Variation Inflation Factor, I decided to create a heatmap of the correlation coefficients and choose features that intuitively related to the spread of COVID-19 and are not that similar to increase transparency. Here are the features I picked and why:\n\nep_pov: I chose the Percentage of persons below poverty, as poverty may influence social distancing adherence.  \n\nep_crowd: I chose the percentage of occupied housing units with more people than rooms. This seems vital to the spread of COVID-19 as this means that there would be more frequent human interactions.  This feature seems to be correlated with the Age65 and minorities which is why I did not include these features in my model, as I believe crowd could explain why these communities could experience any disparities.\n\nep_munit:  I chose the percentage of housing in structures with 10 or more units estimate for the same reason as ep_crowd.  Interestingly, these two features are not linearly correlated, which makes it an appropriate choice.  \n"}}