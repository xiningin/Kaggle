{"cell_type":{"cfc8e17f":"code","7c08d8f3":"code","a6b2eca9":"code","5595af4f":"code","7bb84bc9":"code","9faa7b06":"code","bfb49d3a":"code","be9f3619":"code","f1c07670":"code","2b8e7c79":"code","4feb7b44":"code","72ebefca":"code","61413c39":"code","4c04a2a1":"code","7f284120":"code","58d1d101":"code","9488a69a":"code","4ea8024a":"code","08ebc393":"code","b12e16f7":"code","bd7708d1":"code","d18d1765":"code","99c82001":"code","646af119":"code","6baf3370":"code","c7b37a18":"code","89c7aac3":"code","a13721db":"code","85b912ce":"code","9456cb42":"code","39beaf9f":"code","cc86aa1f":"code","0eddbd65":"code","f7cbc047":"code","0c3eabf7":"code","ebb572b7":"code","33761e71":"code","2ebb8cd0":"markdown","2d11eb0c":"markdown","d2945c4f":"markdown","df741a5f":"markdown","483f7db8":"markdown","6656aedb":"markdown","71aa8101":"markdown","05f858b2":"markdown","ffef5232":"markdown","5964655e":"markdown","d6aab310":"markdown","6519f34b":"markdown","c95a25c6":"markdown","62e25663":"markdown","b5a63307":"markdown","fff0f3f2":"markdown","5e725533":"markdown","45f4d61b":"markdown"},"source":{"cfc8e17f":"!pip install skimpy","7c08d8f3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimpy import skim\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nimport statsmodels.api as sm","a6b2eca9":"dt_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndt_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","5595af4f":"dt_train.shape","7bb84bc9":"dt_train.head()","9faa7b06":"dt_train.isna().sum()","bfb49d3a":"pd.unique(dt_train[\"Age\"])","be9f3619":"len(pd.unique(dt_train[\"Age\"]))","f1c07670":"plt.hist(dt_train['Age'])","2b8e7c79":"age = dt_train['Age']\nage.mean()","4feb7b44":"age.median()","72ebefca":"print(\"Q1 = \", age.quantile(0.25))\nprint(\"Q3 = \", age.quantile(0.75))\nprint(\"IQR = \", age.quantile(0.75) - age.quantile(0.25))","61413c39":"print(pd.unique(dt_train[\"Embarked\"]))\nprint(sns.countplot(x=dt_train[\"Embarked\"]))","4c04a2a1":"skim(dt_train)","7f284120":"sns.countplot(x=dt_train[\"Survived\"])","58d1d101":"surv_pclass = dt_train.groupby([\"Survived\", \"Pclass\"]).size().reset_index(name = \"counts\")\nsurv_pclass.groupby(\"Pclass\", group_keys=False).sum(\"counts\")","9488a69a":"survived = surv_pclass.groupby(\"Survived\").apply(lambda g: g.counts.sum())","4ea8024a":"surv_merge = pd.merge(surv_pclass, survived.to_frame(\"Total\"), on = \"Survived\", how = \"left\")\nsurv_merge[\"Prop\"] = surv_merge[\"counts\"]\/surv_merge[\"Total\"]","08ebc393":"surv_merge","b12e16f7":"sns.barplot(data = surv_merge, x=\"Survived\", y = \"Prop\", hue = \"Pclass\")","bd7708d1":"sns.displot(data = dt_train, hue = \"Pclass\", x = \"Fare\", kind = \"kde\", linewidth = 3)","d18d1765":"dt_train.groupby(\"Sex\").count()","99c82001":"print(\n    \"Male survival rate: \",\n    round(dt_train[(dt_train[\"Sex\"] == \"male\") & (dt_train[\"Survived\"] == 1)].shape[0]\/577 * 100, 2),\n    \"%\"\n)\n\nprint(\n    \"Female survival rate: \",\n    round(dt_train[(dt_train[\"Sex\"] == \"female\") & (dt_train[\"Survived\"] == 1)].shape[0]\/314 * 100, 2),\n    \"%\"\n)","646af119":"dt_train.groupby(\"Sex\").sum()","6baf3370":"print(\n    \"Of the\", 233 + 109, \"survivors,\", round(233\/(233 + 109) * 100, 2), \"% were female.\"\n)","c7b37a18":"dt_train[dt_train[\"Survived\"] == 0].groupby(\"Sex\").count()","89c7aac3":"print(\n    \"Of the\", 468 + 81, \"non-survivors,\", round(468\/(468 + 81) * 100, 2), \"% were male.\"\n)","a13721db":"train_set, validation_set = train_test_split(dt_train, test_size=0.2, random_state=0)","85b912ce":"def build_features(df):\n    concat = pd.concat(\n        [\n            df[[\"PassengerId\", \"Survived\"]],\n            pd.get_dummies(df[\"Sex\"]),\n            pd.get_dummies(df[\"Pclass\"], prefix = \"class\")\n        ],\n        axis = 1\n    )\n    return concat[[\"female\", \"class_2\", \"class_1\", \"Survived\"]]","9456cb42":"train_baseline = build_features(train_set)\nvalidation_baseline = build_features(validation_set)","39beaf9f":"logit_baseline=sm.Logit(\n    train_baseline[\"Survived\"],\n    sm.add_constant(train_baseline[[\"female\", \"class_2\", \"class_1\"]])\n)\nlogit_fit=logit_baseline.fit()\nprint(logit_fit.summary())","cc86aa1f":"log_reg = LogisticRegression()\nlog_reg.fit(\n    train_baseline[[\"female\", \"class_2\", \"class_1\"]],\n    train_baseline[\"Survived\"]\n)","0eddbd65":"X_val = validation_baseline[[\"female\", \"class_2\", \"class_1\"]]\ny_val = validation_baseline[\"Survived\"]\n\nprint(\"Accuracy on validation set: {:.2f}\".format(log_reg.score(X_val, y_val)*100), \"%\")","f7cbc047":"confusion_matrix = confusion_matrix(y_val, log_reg.predict(X_val))\nprint(confusion_matrix)","0c3eabf7":"test_concat = pd.concat(\n        [\n            dt_test[[\"PassengerId\"]],\n            pd.get_dummies(dt_test[\"Sex\"]),\n            pd.get_dummies(dt_test[\"Pclass\"], prefix = \"class\")\n        ],\n        axis = 1\n    )\ntest_concat.head()","ebb572b7":"test_pred = log_reg.predict(test_concat[[\"female\", \"class_2\", \"class_1\"]])\ntest_concat[\"Survived\"] = test_pred","33761e71":"test_concat[[\"PassengerId\", \"Survived\"]].to_csv(\".\/baseline_predictions.csv\", index = False)","2ebb8cd0":"# Data Cleaning and EDA","2d11eb0c":"From what we've seen so far, we can use 'Sex' and 'Pclass' as predictors to build a first model which we will use as a baseline. PyStan? Maybe.","d2945c4f":"## Within the survivors, what is the male-female proportion?","df741a5f":"# Baseline Model","483f7db8":"The data set has 891 observations of 12 variables. Each row corresponds to a single passenger and contains information such as his name, sex, age, and whether or not he survived. 'Survived' is the response variable and it takes the values 1 (passenger survived) and 0 (passenger did not survive).","6656aedb":"The goal of this project is becoming familiar with Python and Jupyter notebooks by making a submission to the [Titanic Kaggle competition](https:\/\/www.kaggle.com\/c\/titanic\/overview).","71aa8101":"The distribution of 'Age' is right skewed, with a peak at around 20 to 30 years of age. We can calculate some summary statistics like the mean, median, standard deviation, and IQR. Because the column is a Pandas Series, the methods automatically ignore missing values (not the case with NumPy arrays).","05f858b2":"Now let's take a look at the distribution of the response variable.","ffef5232":"Using the `statsmodels` package to get coefficients:","5964655e":"We can see that the data set has more people that did not survive, but the distribution does hint future problems with an imbalanced response.","d6aab310":"This plot is interesting because it shows that, from those people who did not survive, almost 70% had 3rd class tickets.","6519f34b":"Most of the observations for 'Embarked' take the 'S' value. This, along with the fact that some observations are missing, makes this variable a candidate to be removed from the model.\n\nThe package `skimpy`, inspired by the R package `skimr`, offers a function called `skim()` for easilly visualizing the structure of a data set.","c95a25c6":"## Which predictors are associated with the response?","62e25663":"By calling the `isna()` method on our data frame we can see that some variables like 'Age', 'Cabin', and 'Embarked' (port at which the person embarked) have missing values. Let's take a look at these variables.","b5a63307":"There are 89 unique values for 'Age'. Ages less than a year are written as a fraction and estimated ages have a '.5' appended to them. We can also visualize this variable in a histogram.","fff0f3f2":"# Submission of baseline model","5e725533":"The competition provides three data sets: 'train.csv', 'test.csv', and 'gender_submission.csv'. The goal is to fit a model on the training data and upload the test set predictions. The 'gender_submission' file provides an example on how to submit predictions. Let's take a look at the raw training data first.","45f4d61b":"# TITANIC KAGGLE COMPETITION\n## Jose Pliego\n## September 2021"}}