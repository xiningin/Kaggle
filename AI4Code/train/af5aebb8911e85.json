{"cell_type":{"e7f16eb6":"code","dc8350e5":"code","aed80851":"code","752aafe2":"code","e38adca7":"code","eb008269":"code","6d3b10c8":"code","d35651c4":"code","e6abb136":"code","e33265c4":"code","2df00793":"code","bc20b7f7":"code","ea9ff0ee":"code","5e41cc5e":"code","8b09a7b5":"code","36bac914":"code","dba9632b":"code","f497d722":"code","f9560d28":"code","6603dc0b":"code","522242d4":"code","9f3c892b":"code","b2174ebb":"markdown","e0858877":"markdown","fb2456f0":"markdown","a3e94f6d":"markdown","92c3701a":"markdown","35ba3c21":"markdown","1c3463fe":"markdown","5f4a3f53":"markdown","cef0f26b":"markdown","88c1ddf0":"markdown","5c7a852f":"markdown","f585205a":"markdown","3ffc58df":"markdown","73d35d4d":"markdown","a6c6bd84":"markdown"},"source":{"e7f16eb6":"!pip install sadedegel\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom sadedegel.bblock import Doc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import vstack, csr_matrix # dealing with sparse matrices in  tfidf embeddings\nfrom sklearn.preprocessing import normalize\nimport altair as alt\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nimport seaborn as sns\n","dc8350e5":"df = pd.read_csv(\"..\/input\/duygu-analizi-icin-urun-yorumlari\/magaza_yorumlari_duygu_analizi.csv\", encoding=\"utf-16\")\ndf","aed80851":"df.isna().value_counts()","752aafe2":"df = df.dropna()\ndf","e38adca7":"sns.countplot(data=df, x='Durum')","eb008269":"df[df.Durum == 'Tarafs\u0131z']","6d3b10c8":"df = df[df.Durum.isin([\"Olumlu\", \"Olumsuz\"])]","d35651c4":"# let's take 5 examples\n\ntext = df.iloc[:5]['G\u00f6r\u00fc\u015f'].tolist()\nprint(text)","e6abb136":"vectorizer = CountVectorizer(binary=True)\nvectorizer.fit(text)","e33265c4":"# transforming text to tf-idf values\ntransformed_text=vectorizer.transform(text)\n# converting array to dataframe\ntransformed_text=pd.DataFrame.sparse.from_spmatrix(transformed_text)\ntransformed_text\n# renaming vocab columns\nmapped_text=transformed_text.rename(columns={v: k for k, v in vectorizer.vocabulary_.items()})\nmapped_text","2df00793":"vectorizer = CountVectorizer()\nvectorizer.fit(text)","bc20b7f7":"# transforming text to tf-idf values\ntransformed_text=vectorizer.transform(text)\n# converting array to dataframe\ntransformed_text=pd.DataFrame.sparse.from_spmatrix(transformed_text)\ntransformed_text\n# renaming vocab columns\nmapped_text=transformed_text.rename(columns={v: k for k, v in vectorizer.vocabulary_.items()})\nmapped_text","ea9ff0ee":"# create the transform\nvectorizer = TfidfVectorizer()\n# tokenize and build vocab\nvectorizer.fit(text)\n# vocab\nprint(vectorizer.vocabulary_)","5e41cc5e":"# transforming text to tf-idf values\ntransformed_text=vectorizer.transform(text)\n# converting array to dataframe\ntransformed_text=pd.DataFrame.sparse.from_spmatrix(transformed_text)\ntransformed_text\n# renaming vocab columns\nmapped_text=transformed_text.rename(columns={v: k for k, v in vectorizer.vocabulary_.items()})\nmapped_text","8b09a7b5":"mapped_text['ald\u0131m']","36bac914":"# Step 1\ndoc_0 = Doc(df.iloc[0][\"G\u00f6r\u00fc\u015f\"])\ndoc_0","dba9632b":"# Step 2\ntfidf_embedding_0 = doc_0.tfidf\ntfidf_embedding_0.shape","f497d722":"\nX_str = df[\"G\u00f6r\u00fc\u015f\"]\nX = []\n\nfor txt in tqdm(X_str):\n    d = Doc(txt)\n    X.append(d.tfidf)\n\n\nX = np.stack(X, axis=0)\nprint(\"Shape of embeddings matrix: \", X.shape)","f9560d28":"y = df[\"Durum\"]\nX_train, X_val, y_train, y_val = train_test_split(X,y, stratify=df[\"Durum\"], test_size=0.2)","6603dc0b":"clf = RandomForestClassifier().fit(X_train, y_train) # train","522242d4":"y_pred = clf.predict(X_val)\ny_pred","9f3c892b":"from sklearn.metrics import  accuracy_score\n\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred, normalize=True))","b2174ebb":"## Sadedegel","e0858877":"Datasette **Olumsuz**, **Tarafs\u0131z** ve **Olumlu** diye ayr\u0131lan 11428 tane \u00fcr\u00fcn yorumu bulunmaktad\u0131r.","fb2456f0":"\u015eimdi s\u0131ra modellemede. E\u011fitimi h\u0131zl\u0131 olsun diye en basit s\u0131n\u0131fland\u0131rma metodunu, LogisticRegression'\u0131 kullanaca\u011f\u0131z.","a3e94f6d":"### Sklearn","92c3701a":"Datam\u0131z\u0131 haz\u0131rlaman\u0131n son ad\u0131m\u0131 train ve test b\u00f6l\u00fcmlerine b\u00f6lmek:","35ba3c21":"## Preprocessing","1c3463fe":"### Data","5f4a3f53":"### Lets repeat with TFIDF","cef0f26b":"Geriye kalan tek \u015fey s\u0131n\u0131fland\u0131r\u0131c\u0131y\u0131 e\u011fitmek i\u00e7in bir matris olu\u015fturmak.","88c1ddf0":"Datam\u0131z\u0131 y\u00fckledikten sonra ham metni TF-IDF embedding matrisine \u00e7evirece\u011fiz.\n\n\u00d6nce birka\u00e7 \u00f6rnek metin alaca\u011f\u0131z,\n- Vocabulary in\u015fas\u0131.\n- Simple Bag of Words (Binary, Count)\n- TF-IDF de\u011ferleri","5c7a852f":"Her bir dok\u00fcman (bizim durumda her bir yorum) i\u00e7in a\u015fa\u011f\u0131daki ad\u0131mlar uygulanacakt\u0131r:\n<ol>\n    <li style=\"font-weight:bold\"><span style=\"font-weight:normal\">Yorum, Sadedegel Doc objesine \u00e7evrilir.<\/span><\/li>\n    <li style=\"font-weight:bold\"><span style=\"font-weight:normal\">Doc objesinin .tfidf attribute'undan V boyutunda bir vekt\u00f6r al\u0131n\u0131r (N: Dok\u00fcmandaki c\u00fcmle say\u0131s\u0131, V: Vocabulary boyutu)<\/span><\/li>\n    <li style=\"font-weight:bold\"><span style=\"font-weight:normal\">Olu\u015fan V boyutunda vekt\u00f6r s\u0131n\u0131fland\u0131r\u0131cya verilir.<\/span><\/li>\n<\/ol>\n\n1 dok\u00fcman (yorum) \u00fcst\u00fcnde t\u00fcm preprocessing ad\u0131mlar\u0131:","f585205a":"S\u0131n\u0131fland\u0131rma modelimiz haz\u0131r!\nTest datas\u0131n\u0131n \u00fcst\u00fcnde deneme vakti.","3ffc58df":"Modelimizin performans\u0131n\u0131 \u00f6l\u00e7mek i\u00e7in accuracy metri\u011fini kullanaca\u011f\u0131z.","73d35d4d":"## \u00dcr\u00fcn yorumlar\u0131ndan duygu analizi\n### with Sadedegel and Sklearn\n#### by Global Maksimum DS Team","a6c6bd84":"---\n\n### Train and validate"}}