{"cell_type":{"b6c41951":"code","606d8535":"code","ab798487":"code","c292805e":"code","545367a0":"code","ad290372":"code","6ab7fa7d":"code","aeb2e9d5":"code","55b7de47":"code","e24f07e4":"code","e1b6b650":"code","8d2024b1":"code","9ec64a89":"code","9b13fa8b":"code","d13f0898":"code","16658d3a":"code","d51a0865":"code","b4e6b0f5":"code","de2da5e2":"code","340464e8":"code","ee3ff998":"code","1504a060":"markdown","2fd68066":"markdown","d9160459":"markdown","5a3ba9c3":"markdown","30bd8ce1":"markdown","7b4c71d3":"markdown","8c45a62b":"markdown","0a85eeb9":"markdown","1dd82dcb":"markdown","b6b5a4a6":"markdown","6bf806d2":"markdown","e148efee":"markdown","e92c3291":"markdown"},"source":{"b6c41951":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler","606d8535":"df_train = pd.read_csv('..\/input\/google-stock-price-201221\/train.csv')\ndf_test = pd.read_csv('..\/input\/google-stock-price-201221\/test.csv')","ab798487":"print(df_train.shape, df_test.shape)","c292805e":"df_train.info()","545367a0":"plt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\n\nplt.plot(df_train.Open, color='cyan', label='open')\nplt.plot(df_train.Close, color='green', label='close')\nplt.plot(df_train.Low, color='blue', label='low')\nplt.plot(df_train.High, color='red', label='high')\nplt.title('Stock price')\nplt.xlabel('Time [days]')\nplt.ylabel('Price')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2);\nplt.plot(df_train.Volume, color='orange', label='volume')\nplt.title('Stock volume')\nplt.xlabel('Days')\nplt.ylabel('Volume')\nplt.legend(loc='best')\n\nplt.show()","ad290372":"train_set = df_train.iloc[:,1:2].values","6ab7fa7d":"sc = MinMaxScaler(feature_range = (0,1))\ntrain_set_scaled = sc.fit_transform(train_set)","aeb2e9d5":"print(train_set_scaled)","55b7de47":"x_train = []\ny_train = []\n \nfor i in range(60,2264):\n    x_train.append(train_set_scaled[i-60:i,0])\n    y_train.append(train_set_scaled[i,0])\n    \nx_train, y_train = np.array(x_train), np.array(y_train)","e24f07e4":"x_train","e1b6b650":"y_train","8d2024b1":"print(x_train.shape , y_train.shape)","9ec64a89":"x_train = x_train.reshape(2204, 60, 1)\nx_train.shape","9b13fa8b":"model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(60, activation = 'relu', return_sequences = True, input_shape = (60, 1)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(60, activation = 'relu', return_sequences = True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(80, activation = 'relu', return_sequences = True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(120, activation = 'relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1)\n])","d13f0898":"model.summary()","16658d3a":"model.compile(optimizer = 'Adam', loss = 'mean_squared_error')","d51a0865":"model.fit(x_train, y_train, 32, 100)","b4e6b0f5":"curr_stock_price = df_test.iloc[0:45,1:2].values\ncurr_stock_price.shape","de2da5e2":"#Concatenating the training and test set\ndf_total = pd.concat((df_train['Open'], df_test['Open']), axis=0)\n\n#Getting the stock prices of previous 60 days for each day of months Jan,2021 and Feb,2021\ninputs = df_total[len(df_total)-len(df_test)-60:].values\ninputs = inputs.reshape(-1,1)\n\n#Normalization (as discussed earlier)\ninputs = sc.transform(inputs)\n\n#Making a Test Set\nx_test = []\nfor i in range(60, 100):\n    x_test.append(inputs[i-60:i,0])\n\n#Converting the test set into a Numpy array\nx_test = np.array(x_test)\n\n#Since RNN, accepts 3D input we need to reshape the test set again\nx_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))\n\n#Here, we predict the stock prices and Denormalize our predicted values for plotting\npred_stock_price = model.predict(x_test)\npred_stock_price = sc.inverse_transform(pred_stock_price)","340464e8":"for i in range(0,10):\n    print(pred_stock_price[i], curr_stock_price[i])","ee3ff998":"plt.plot(curr_stock_price, color='indigo', label='Current Google Stock Price') \nplt.plot(pred_stock_price, color='cyan', label='Predicted Google Stock Price') \nplt.title('Google Stock Price Prediction') \nplt.ylabel('Google Stock Price')\nplt.xlabel('Time')\nplt.legend()\nplt.show()","1504a060":"## Feature Scaling: Why Normalization?\nNormalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2020\/03\/Norm_eq.gif)\n\nIt will be beneficial to normalize your training data. Having different features with widely different scales fed to your model will cause the network to weight the features not equally. This can cause a falsely prioritisation of some features over the others in the representation. Despite that the whole discussion on data preprocessing is controversial either on when exactly it is necessary and how to correctly normalize the data for each given model and application domain there is a general consensus in Machine Learning that running a general Normalization preprocessing step is helpful.","2fd68066":"# Data Preprocessing","d9160459":"I am building the model around the column Open so generating a training set seperately using that. ","5a3ba9c3":"# Model Building and Training\n\nHere, the first task for us is to initialize our RNN model. The key is to develop a basic model at first and then keep on tuning the Hyper parameters for a better fit and balancing the Bias-Variance Trade off. \n\nIn this model, I have used 4 LSTM layers followed by Dropout. Adding a Dropout layer helps our model with regularization and prevents overfitting.\n\n## LSTM: \nLong short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can process not only single data points (such as images), but also entire sequences of data (such as speech or video).\n\n![](https:\/\/static.javatpoint.com\/tutorial\/tensorflow\/images\/long-short-term-memory-rnn-in-tensorflow.jpg)","30bd8ce1":"# Model Predictions!!\n\nMaking a data structure such that it holds the Stock market trends for Two months of 2021 i.e. January and Februrary.","7b4c71d3":"# Exploratory Data Analysis","8c45a62b":"We can see that our model is able to predict the trends of the market. \n### If you like this notebook, please give an Upvote! Don't forget to check out my other notebooks too! ###\n1. https:\/\/www.kaggle.com\/anshankul\/ann-for-image-classification-fashion-mnist\n2. https:\/\/www.kaggle.com\/anshankul\/feature-selection-feature-engineering-techniques\n3. https:\/\/www.kaggle.com\/anshankul\/insurance-charges-prediction\n\n**For Further Reference:**\n1. https:\/\/stackoverflow.com\/questions\/43467597\/should-i-normalize-my-features-before-throwing-them-into-rnn\n2. https:\/\/stackoverflow.com\/questions\/48475255\/python-lstm-based-rnn-required-3d-input\n3. https:\/\/www.geeksforgeeks.org\/intuition-of-adam-optimizer\/\n4. https:\/\/en.wikipedia.org\/wiki\/Mean_squared_error\n5. https:\/\/www.kaggle.com\/raoulma\/ny-stock-price-prediction-rnn-lstm-gru","0a85eeb9":"Next, I will generate a data structure that could hold 1 output for each set of 60 timesteps. I will develop a network that will be able to predict the current trend for the Stock price based on 60 timesteps.","1dd82dcb":"# Google Stock Price Prediction\n![](https:\/\/moneyexcel.com\/wp-content\/uploads\/2018\/06\/stock-price.png)\n\n**Description:**\nThis notebook demonstrates real time stock prediction using the trends of past 60 days as input built using a recurrent neural network. Recurrent neural networks with basic, LSTM cells are implemented.\n\n**Dataset:**\nThe training set contains Google stock price values from January, 2012 to December, 2020. The test set contains the Google stock price values from January, 2021 to September, 2021. \nDataset has been extracted from the site https:\/\/finance.yahoo.com\/quote\/GOOG\/history\/\n\n**Content:**\n\n1. Importing Libraries and Dataset\n2. Exploratory Data Analysis\n3. Data Preprocessing\n4. Model Building and Training\n5. Model Predictions\n","b6b5a4a6":"All the values have been pushed between 0 and 1.","6bf806d2":"As we can see, we need to make variable x_train 3 dimensional so that it can be given as the input to our Recurrent Neural Network. A single training example for LSTM network consists of a sequence and a label and hence, it needs to be converted to 3 dimensional structure.","e148efee":"Now, to compile our model I choose the Adam Optimizer and for loss function I use the infamous Mean Squared Error as our problem deals with continuous Numerical data. \n\n**Adam:** Adaptive Moment Estimation is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large problem involving a lot of data or parameters. It requires less memory and is efficient. Intuitively, it is a combination of the \u2018gradient descent with momentum\u2019 algorithm and the \u2018RMSP\u2019 algorithm.\n\n**Mean Squared error:** In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors\u2014that is, the average squared difference between the estimated values and the actual value.","e92c3291":"# Importing the Libraries and dataset"}}