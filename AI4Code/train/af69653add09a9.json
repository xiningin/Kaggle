{"cell_type":{"04318741":"code","55820c08":"code","1af8eb47":"code","528558a1":"code","386bc6f7":"code","345f9f3e":"code","90554c6e":"code","201a8188":"code","510f9f3e":"code","80125ca5":"code","a5d7de25":"code","46fd855f":"code","5cd6b802":"code","3be01571":"code","e27f66e9":"code","6fd90c67":"code","ffc2a63a":"code","dfd2e03e":"code","d923be91":"code","daa9ac08":"code","843f16c9":"code","95eeba20":"code","da21856e":"code","49e81490":"code","d6d1b96c":"code","541da511":"code","82592dc0":"code","b27b0258":"code","bc6f6c42":"code","1451375d":"code","de784552":"code","9945447e":"code","d7a286b1":"markdown","011755c1":"markdown","7d7e5ba9":"markdown","528bb402":"markdown","4c79c24d":"markdown","df3fc52f":"markdown","84ded144":"markdown","ef39c436":"markdown","0de8f2ac":"markdown","1efa4536":"markdown","ef3e2b45":"markdown","1a48550c":"markdown","f16f7d9f":"markdown","a479b168":"markdown","a6661d65":"markdown","cb26065e":"markdown","06717c9b":"markdown","931f4a20":"markdown","f81b082e":"markdown","48b985e3":"markdown","e82b7943":"markdown","095f5ef4":"markdown","f3c6a3bd":"markdown","b5af1a03":"markdown","0212ed54":"markdown","28318f5e":"markdown","a4caae2e":"markdown"},"source":{"04318741":"import cv2\nimport matplotlib.pyplot as plt ","55820c08":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"..\/input\/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","1af8eb47":"import os ,shutil ","528558a1":"orginal_data_dir = '\/kaggle\/input\/natural-images\/natural_images'\n# This is the directory where all our images_ data are stored \nbasedir = os.getcwd()+'\/natural_images_all'\nos.mkdir(basedir)\n# This is the basedirectoy where all the test,train,crossvalidation images are stored ","386bc6f7":"# Sample picture \nimport cv2\nimport matplotlib.pyplot as plt\nimg=cv2.imread(orginal_data_dir+'\/motorbike\/motorbike_0006.jpg')\nplt.imshow(img)\nprint(type(img))\n","345f9f3e":"#Creating test,train,crossvalidationdirctories to store the images \ntrain_dir = os.path.join(basedir,'train')\nos.mkdir(train_dir)\n\n\nvalidation_dir = os.path.join(basedir,'validation')\nos.mkdir(validation_dir)\n\ntest_dir = os.path.join(basedir,'test')\nos.mkdir(test_dir)","90554c6e":"train_dir","201a8188":"def makesubfolders(folderPath , name):\n    x = os.path.join(folderPath,name)\n    os.mkdir(x)\n    return x\n    ","510f9f3e":"# Creating subfolders for training classes \ntrain_cats_dir =makesubfolders(train_dir,'cats')\n\ntrain_dogs_dir=makesubfolders(train_dir,'dogs')\n\ntrain_fruits_dir=makesubfolders(train_dir,'fruits')\n\ntrain_persons_dir=makesubfolders(train_dir,'persons')\n\ntrain_motorbikes_dir=makesubfolders(train_dir,'motorbikes')\n\ntrain_airplanes_dir=makesubfolders(train_dir,'airplanes')\n\ntrain_cars_dir=makesubfolders(train_dir,'cars')\n\ntrain_flowers_dir=makesubfolders(train_dir,'flowers')\n\n\n# Doing the same for crossvalidation data \nvalidation_cats_dir =makesubfolders(validation_dir,'cats')\n\nvalidation_dogs_dir=makesubfolders(validation_dir,'dogs')\n\nvalidation_fruits_dir=makesubfolders(validation_dir,'fruits')\n\nvalidation_persons_dir=makesubfolders(validation_dir,'persons')\n\nvalidation_motorbikes_dir=makesubfolders(validation_dir,'motorbikes')\n\nvalidation_airplanes_dir=makesubfolders(validation_dir,'airplanes')\n\nvalidation_cars_dir=makesubfolders(validation_dir,'cars')\n\nvalidation_flowers_dir=makesubfolders(validation_dir,'flowers')\n\n\n# Doing the same for test data \ntest_cats_dir =makesubfolders(test_dir,'cats')\n\ntest_dogs_dir=makesubfolders(test_dir,'dogs')\n\ntest_fruits_dir=makesubfolders(test_dir,'fruits')\n\ntest_persons_dir=makesubfolders(test_dir,'persons')\n\ntest_motorbikes_dir=makesubfolders(test_dir,'motorbikes')\n\ntest_airplanes_dir=makesubfolders(test_dir,'airplanes')\n\ntest_cars_dir=makesubfolders(test_dir,'cars')\n\ntest_flowers_dir=makesubfolders(test_dir,'flowers')\n\n\n","80125ca5":"print(len(os.listdir(test_dir)))\nprint(len(os.listdir(train_dir)))","a5d7de25":"def Copyfiles(folderName,z,dstName):\n    list_imgs = os.listdir(orginal_data_dir+folderName)\n   \n    train_len = int(.64*len(list_imgs))\n    test_len = int(.2*len(list_imgs))+train_len\n    validation_len = int(.16*len(list_imgs))+test_len\n    \n    \n    train_fnames = [list_imgs[i] for i in range (train_len)]\n    for i in train_fnames: \n        y = z+i\n        src = os.path.join(orginal_data_dir , y)\n        t = os.path.join(train_dir,dstName)\n        dst = os.path.join(t,i)\n        shutil.copyfile(src,dst)\n\n    test_fnames = [list_imgs[i] for i in range (train_len,test_len)]\n    for i in test_fnames:\n        y = z+i\n        src = os.path.join(orginal_data_dir , y)\n        test = os.path.join(test_dir,dstName)\n        dst = os.path.join(test,i)\n        shutil.copyfile(src,dst)\n        \n    validation_fnames=[list_imgs[i] for i in range(test_len,validation_len)]\n    for i in validation_fnames: \n        y = z+i\n        src = os.path.join(orginal_data_dir , y)\n        validation = os.path.join(validation_dir,dstName)\n        dst = os.path.join(validation,i)\n        shutil.copyfile(src,dst)\n    \n    \n    ","46fd855f":"# Copying the cats into train,test,validaiton folder \nCopyfiles('\/cat','cat\/','cats')\nCopyfiles('\/dog','dog\/','dogs')\nCopyfiles('\/car','car\/','cars')\nCopyfiles('\/airplane','airplane\/','airplanes')\nCopyfiles('\/flower','flower\/','flowers')\nCopyfiles('\/motorbike','motorbike\/','motorbikes')\nCopyfiles('\/fruit','fruit\/','fruits')\nCopyfiles('\/person','person\/','persons')\nprint('successfully copied to destination folders ')\n","5cd6b802":"from keras.preprocessing.image import ImageDataGenerator \ntrain_datagen = ImageDataGenerator(rescale = 1\/255)\n# Rescales the image every pixel to 0 to 1 \n\ntrain_generator=train_datagen.flow_from_directory(\n    train_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have 8 to classes we need to go with bianaty it labels the data based on the directories \n\n)#this method loads the data from the directory and iterates over all the files \n\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\nvalidation_generator=validation_datagen.flow_from_directory(\n    validation_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have only to classes we need to go with bianaty it labels the data based on the directories \n\n)\n","3be01571":"for data_batch,label_batch in validation_generator:\n    print(\"The shape of the 1st data batch is \" ,data_batch.shape)\n    print(\"The shape of the 1st label batch is \" ,label_batch.shape)\n    break","e27f66e9":"for data_batch,label_batch in train_generator:\n    print(label_batch[0])\n    plt.imshow(data_batch[0])\n   \n    break","6fd90c67":"#Building a simple network \nfrom keras import layers \nfrom keras import models \nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape =(150,150,3)))\n# here we are defining a conv layer with the basic config after this layer will get a image with the depth of 32 and 148 x 148 because we are not doing pooling \nmodel.add(layers.MaxPooling2D((2,2)))\n# Here again applied a Maxpooling layer of the 2 x 2 here zero parameter will be trained \nmodel.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n# above is the second conv layer \nmodel.add(layers.MaxPooling2D((2,2)))\n# Again Maxpooling layer \nmodel.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512,activation='relu'))\n\nmodel.add(layers.Dense(8,activation = 'softmax'))","ffc2a63a":"model.summary()","dfd2e03e":"from keras import optimizers \nmodel.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['accuracy'])","d923be91":"history = model.fit_generator(train_generator,#The generator we are sending as the data \n                              steps_per_epoch =100 ,# this parameters specificies how many batches it need to iterate utill it gets the entire data are one epoch is completed \n                              epochs = 30,\n                              validation_data = validation_generator,# we can also send the validation data so it validates at the same time \n                              validation_steps=50 # number of iteration it need to run before it gets the entire validation data from each batch \n                             )","daa9ac08":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\n# returns the training accuracies while training \nval_acc = history.history['val_accuracy']\n# returns the validation accuracy at different levels \nloss = history.history['loss']\n# returns the loss at different levels over training data \nval_loss = history.history['val_loss']\n#returns the validation loss through put the process \nepochs = range(1,len(acc)+1)\n\nplt.plot(epochs,acc,'bo',label='Training accuracy',color='pink')\nplt.plot(epochs,val_acc,'b',label='validation accuracy',color='black')\nplt.title('Training and validation accuracy ')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,loss,'bo',label='Training loss',color='pink')\nplt.plot(epochs,val_loss,'b',label='Validation loss',color='black')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n","843f16c9":"os.chdir(basedir)\nos.mkdir(os.getcwd()+'\/model')\nos.chdir(os.getcwd()+'\/model')\nmodel.save('model1')","95eeba20":"test_datagen = ImageDataGenerator(rescale=1\/255)\n\ntest_generator=validation_datagen.flow_from_directory(\n    test_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have only to classes we need to go with bianaty it labels the data based on the directories \n\n)","da21856e":"model.evaluate_generator(test_generator)","49e81490":"x =0 \nfor i,j in test_generator:\n   \n        print('Class predicted by model ',model.predict_classes(i[19].reshape((1,)+i[19].shape)))\n        print('The image belongs to ',j[19])\n        plt.imshow(i[19])\n        break\n\n","d6d1b96c":"datagen = ImageDataGenerator(rotation_range = 60,  # how much rotaion of the imgage need to be done between (0-180)\n                             width_shift_range = 0.2, # how much width the image can be shifted of the total size of the image \n                             height_shift_range = 0.2, # similar with height \n                             shear_range = .2,\n                             zoom_range = .2 ,# how much can an image can be zoomed \n                             fill_mode = 'nearest' # after moving image there may be few empty pixels so we are making them to fill by nearest pixels \n                             \n                \n                            \n                            \n                            )","541da511":"from keras.preprocessing import image \nfname = os.path.join(train_cats_dir,os.listdir(train_cats_dir)[78])\nimg = image.load_img(fname , target_size=(150,150))\nx = image.img_to_array(img) #Converts image into array \nx = x.reshape((1,)+x.shape)\ni=0\nfor batch in datagen.flow(x,batch_size=1):\n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i = i+1\n    if i%4 == 0 :\n        break\nplt.show()","82592dc0":"#Building a simple network \nfrom keras import layers \nfrom keras import models \nmodel1 = models.Sequential()\nmodel1.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape =(150,150,3)))\n# here we are defining a conv layer with the basic config after this layer will get a image with the depth of 32 and 148 x 148 because we are not doing pooling \nmodel1.add(layers.MaxPooling2D((2,2)))\n# Here again applied a Maxpooling layer of the 2 x 2 here zero parameter will be trained \nmodel1.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n# above is the second conv layer \nmodel1.add(layers.MaxPooling2D((2,2)))\n# Again Maxpooling layer \nmodel1.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n\nmodel1.add(layers.MaxPooling2D((2,2)))\n\nmodel1.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n\nmodel1.add(layers.MaxPooling2D((2,2)))\n\nmodel1.add(layers.Flatten())\n\nmodel1.add(layers.Dropout(.5)) # Addding extra droup out layer that retains every neuron with the probability of .5\n\nmodel1.add(layers.Dense(512,activation='relu'))\n\nmodel1.add(layers.Dense(8,activation = 'softmax'))","b27b0258":"model1.summary()","bc6f6c42":"model1.compile(loss = 'categorical_crossentropy',optimizer = optimizers.RMSprop(lr = 1e-4),metrics = ['accuracy'])\n","1451375d":"train_datagen1 = ImageDataGenerator(rescale=1\/250,rotation_range = 40,  # how much rotaion of the imgage need to be done between (0-180)\n                             width_shift_range = 0.2, # how much width the image can be shifted of the total size of the image \n                             height_shift_range = 0.2, # similar with height \n                             shear_range = .2,\n                             zoom_range = .2 ,# how much can an image can be zoomed \n                             fill_mode = 'nearest', # after moving image there may be few empty pixels so we are making them to fill by nearest pixels \n                            horizontal_flip = True\n                                  )\nvalidation_datagen1 = ImageDataGenerator(rescale = 1\/255)# we don't need to do dataaugmentation on the validation and the training data \n\ntest_datagen1 = ImageDataGenerator(rescale = 1\/255)\n\ntrain_generator1 = train_datagen1.flow_from_directory(\n    train_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have 8 to classes we need to go with bianaty it labels the data based on the directories \n\n)#this method loads the data from the directory and iterates over all the files \n\nvalidation_generator1 = validation_datagen1.flow_from_directory(\n    validation_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have 8 to classes we need to go with bianaty it labels the data based on the directories \n\n)#this method loads the data from the directory and iterates over all the files \n\ntest_generator1 = train_datagen1.flow_from_directory(\n    test_dir,# the train data directory path where both cats and dogs images present in different directories \n    target_size=(150,150),#resizing every image by 150 X 150 size so all the images will be of the same size and shape \n    batch_size = 20 ,# 20 images will be grouped together and soteres as single object and it will be returned at one iteration \n    class_mode ='categorical'# because we have 8 to classes we need to go with bianaty it labels the data based on the directories \n\n)#this method loads the data from the directory and iterates over all the files \n\n\n","de784552":"history1 = model1.fit_generator(train_generator1,steps_per_epoch =100 , epochs = 50 ,validation_data = validation_generator1,validation_steps = 50)","9945447e":"model1.evaluate_generator(test_generator1)","d7a286b1":"<h2>1.Creating the folders <\/h2>","011755c1":"* <h4>Checking the shape of the sample<\/h4>","7d7e5ba9":"<h3>Keras_ImageDataGenerator:<\/h3>","528bb402":"<h2>Building A simple Model <\/h2>","4c79c24d":"> We need to train 3M + parameters ","df3fc52f":"<h3>2.1.Example of how it works<\/h3>","84ded144":"<h3>1.2.Creating subfolders for each class in each dir <\/h3>","ef39c436":"<h4>Evaluating the Model On Test data<\/h4>","0de8f2ac":"<p>Now we have got labels and the images stored as 20 batch generators  <\/p>","1efa4536":"<h3>1.3.Copying Images<\/h3>","ef3e2b45":"<h4>We can still use ImageDataGenerator to perform data augmentaion<\/h4> ","1a48550c":"<h4>2.3.Loading data to train the model <\/h4>","f16f7d9f":"<p> As we can see above each image is stored as 150 X 150 X 3 shape<\/p>","a479b168":"<strong>Well I have created this folders because it will be easy to use and preprocess the data using the ImageDataGenerator for keras<\/strong> ","a6661d65":"<h5>2.1.1.Setting up a data augmentation object<\/h5>","cb26065e":"> From the above simple model we have got an accuracy of about 99% on the training data but very low i.e.. max of 90 % on the validation data because the model is overfitting the training images so we need to add regularization techniques to avoid overfitting the model ","06717c9b":"> <p>Above is the sample the first image <\/p>","931f4a20":"<h2>Saving the model<\/h2>","f81b082e":"<p>As we can see from the above the images are moved up and down in this way the augmentaion will generate hundereds of new images to train<\/p>","48b985e3":"<p>Now clearily from above results we can observe that our model is overfitting the data so we need to reduce thid effect and make the model work well on both crossvalidation data and test data as well.This happening manily because of two reasons the model is two complex so it is not generalising well and training data is small so it does't have much information to learn the features that it encounter in the feature .So now we will perform something called <strong><i>data augmentation<\/i><\/strong> to generate more data from the current data by modifying the current data . ","e82b7943":"<h3>2.Applying Data Augmentaion and Regularization<\/h3>","095f5ef4":"<h5>2.1.2.Displaying some randomly generated images <\/h5>","f3c6a3bd":"> Copying the images in such a way that training data consits of 64% of each class of images and test cosists of 20% and crossvalidation consists of 16% of images of each class  ","b5af1a03":"<h5>What does it do ?<\/h5>\n<ol>\n<li>Reads the picture files <\/li>\n<li>Decodes the JPEG pictures to RGB pictures <\/li>\n<li>Converts the images into floating point tensors <\/li>\n<li>Rescales the images from 255 to 0 to 1 because the neurons gets saturated if they have high input values <\/li>\n<\/ol>","0212ed54":"<h3>1.1.Creating train,test,crossvalidation dirs<\/h3>","28318f5e":"> On test data our naive model is predicting with an acccuracy of 90 % we will add regularization techniques and some data augmentaion techniques so our model will be improved ","a4caae2e":"<h4>2.2 Defining a new network to train with the Augmented data <\/h4>"}}