{"cell_type":{"bd697def":"code","3c656e46":"code","55c4e9b9":"code","a05b3389":"code","3776eea8":"code","fabad995":"code","9a9f1122":"code","dba165cf":"code","e507c931":"code","b6810754":"code","90641a69":"code","8859be9c":"code","c226dc23":"code","92f4fe86":"code","5c2e9213":"code","8d783203":"code","2dd891af":"code","f08c8a56":"code","f1a6dd34":"code","c6392275":"code","60c4bf17":"code","3ae97354":"code","a329a751":"code","752272a3":"code","d4fa3f7d":"code","e2c2c2ba":"code","58ec5e02":"code","c37e3455":"code","355ff17f":"markdown","4a11a84a":"markdown","9a11dad4":"markdown","85bad1d3":"markdown","a538f0b7":"markdown","6f025788":"markdown","cba0fe75":"markdown","0bb01731":"markdown","3d346ef4":"markdown","b450bf13":"markdown","0f605352":"markdown","91cf36f5":"markdown","8737a744":"markdown"},"source":{"bd697def":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c656e46":"p_data = pd.read_csv('\/kaggle\/input\/passenger-list-for-the-estonia-ferry-disaster\/estonia-passenger-list.csv')","55c4e9b9":"p_data.info()","a05b3389":"p_data.describe(include='all')","3776eea8":"p_data.head()","fabad995":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nplt.figure(figsize=(11,5))\nsns.boxplot(x='Survived',y='Age',data=p_data)\nplt.show()","9a9f1122":"print('Age Kurt: ' ,p_data['Age'].kurt())\nprint('Age Skew: ' ,p_data['Age'].skew())","dba165cf":"plt.figure(figsize=(11,7))\nax = sns.countplot(x='Category',hue='Survived',data= p_data)\nax.set_xticklabels(['Passenger','Crew'])\nax.text(-0.22,700,p_data['Survived'][(p_data['Category']=='P') & (p_data['Survived']==0) ].count(),fontsize=12, fontweight='bold')\nax.text(0.19,100,p_data['Survived'][(p_data['Category']=='P') & (p_data['Survived']==1) ].count(),fontsize=12, fontweight='bold')\nax.text(0.79,157,p_data['Survived'][(p_data['Category']=='C') & (p_data['Survived']==0) ].count(),fontsize=12, fontweight='bold')\nax.text(1.19,45,p_data['Survived'][(p_data['Category']=='C') & (p_data['Survived']==1) ].count(),fontsize=12, fontweight='bold')\n\nplt.show()","e507c931":"print(\"Precent Of Passenger Survived: \",\"{:.2%}\".format(98\/698))\nprint(\"Precent Of Crew Survived: \",\"{:.2%}\".format(39\/154))","b6810754":"plt.figure(figsize=(11,7))\ncdata = p_data.groupby('Country').sum()\nax = sns.barplot(x=cdata.index,y='Survived',data=cdata)\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nax.set(title='Survivers Per Country')\nplt.show()","90641a69":"#lets check our age range first\nprint(\"Ages Range between\",p_data['Age'].min(),',',p_data['Age'].max())","8859be9c":"#we will divide ages into groups\nage_groups = pd.cut(p_data['Age'], 5,labels=['0-18','19-35','36-52','53-69','70-87'])\npa_data = p_data.copy()\npa_data['Age Groups'] = age_groups\np_data['Age Groups'] = age_groups\nplt.figure(figsize=(12,8))\nax = sns.countplot(pa_data['Age Groups'][pa_data['Survived']==1],hue=pa_data['Category'][pa_data['Survived']==1])\nax.set_ylabel('Number Of Survivers')\nax.set_title('Number Of Survivers According To Age Group And Individual Category')\nplt.show()","c226dc23":"plt.figure(figsize=(12,8))\nax = sns.countplot(pa_data['Age Groups'][pa_data['Survived']==1],hue=pa_data['Sex'][pa_data['Survived']==1])\nax.set_ylabel('Number Of Survivers')\nax.set_title('Number Of Survivers According To Age Group And Individual Geneder')\nplt.show()","92f4fe86":"#firt we will select the features that will be used in our models\nfeatures = ['Sex','Age','Category','Age Groups','Country']\n","5c2e9213":"y = p_data.pop('Survived')\np_data","8d783203":"p_data['Country'] = p_data.Country.astype('category').cat.codes\np_data['Sex'] = p_data.Sex.astype('category').cat.codes\np_data['Category'] = p_data.Category.astype('category').cat.codes\np_data['Age Groups'] = p_data['Age Groups'].astype('category').cat.codes\n\np_data","2dd891af":"#We Will Add A Feature Called \"Survival Chance Using The Insight We Have Learnd From The EDA\"\nhigh_survival_chance   =    p_data[(p_data['Age Groups']== 1) & (p_data['Sex']== 1) & (p_data['Category']== 0) ].copy()\nhigh_survival_chance['Survival Chance'] = 3\nmedium_survival_chance =    p_data[(p_data['Age Groups']!= 1) & (p_data['Sex']== 1) & (p_data['Category']== 0) ].copy()\nmedium_survival_chance['Survival Chance'] = 2\nlow_survival_chance    =    p_data[(p_data['Age Groups']!= 1) & (p_data['Sex']!= 1) & (p_data['Category']== 0) ].copy()\nlow_survival_chance['Survival Chance'] = 1\nc_target = [high_survival_chance,medium_survival_chance,low_survival_chance]\ncommon = pd.concat(c_target)\nvery_low_survival_chance =  p_data[~p_data.isin(common)].dropna().copy()\nvery_low_survival_chance['Survival Chance'] = 0\np_data = pd.concat([very_low_survival_chance,high_survival_chance,medium_survival_chance,low_survival_chance])\nfeatures.append('Survival Chance')","f08c8a56":"X = p_data[features]","f1a6dd34":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler","c6392275":"train_x,test_x,train_y,test_y = train_test_split(X,y,test_size=0.3)\n#scaler = StandardScaler()\n#train_x = scaler.fit_transform(train_x)\n#test_x = scaler.fit_transform(test_x)","60c4bf17":"def optimal_knn(train_x,test_x,train_y,test_y,n_list):\n    results = []\n    for n in n_list:\n        model = KNeighborsClassifier(n_neighbors=n)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        results.append(f1(np.round(pred),test_y))\n    return results\ndef optimal_n(train_x,test_x,train_y,test_y,n_list):\n    results = []\n    for n in n_list:\n        model = AdaBoostClassifier(n_estimators=n)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        results.append(f1(np.round(pred),test_y))\n    return results","3ae97354":"KNN_scores = optimal_knn(train_x,test_x,train_y,test_y,[2,3,6,10])\nKNN_scores\nada_scores = optimal_n(train_x,test_x,train_y,test_y,[2,3,6,10])\nada_scores\nplt.plot(KNN_scores)\nplt.plot(ada_scores)\nplt.legend(['KNN','ADABOOST'])\n","a329a751":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nnp.random.seed(42)","752272a3":"model = Sequential()\nmodel.add(Dense(6,activation='tanh',input_dim=6))\nmodel.add(Dense(4,activation='tanh'))\nmodel.add(Dense(4,activation='tanh'))\nmodel.add(Dense(1,activation='tanh'))\nmodel.compile(optimizer='adam', \n              loss='BinaryCrossentropy', \n              metrics=['accuracy'])\nmodel.fit(train_x,train_y,epochs=25)","d4fa3f7d":"pred = model.predict(test_x)","e2c2c2ba":"pred = (pred>0.14).astype(int)\n","58ec5e02":"cm = confusion_matrix(pred,test_y)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm,annot=True,fmt='g',cmap='YlGnBu',xticklabels=['Predicted Not Survived','Predicted Survived'],yticklabels=['Not Survived','Survived'])\n","c37e3455":"print(classification_report(pred,test_y))","355ff17f":"## We can see that male passenger aged 19-35 and crew members aged 19-35 are the top survivers and as the age increases the probability of survival decreases ","4a11a84a":"### All Models return extremely low scores , our data is unbalanced . lets see if neural networks can get us better results","9a11dad4":"### Lets try and awnser our first question. Who's more likely to survive the sinking based on data? \n### Well we already observed that crew members have a higher chance of survival as more crew membres survived.\n### Lets check if gender or age has any effect on the survival probability\u200b of an individual ","85bad1d3":"<h1>The Estonia Disaster Analysis And Predictions<\/h1>\n\nLets first talk about how are we planning to tackle this problem, what are our goals, and what or methodology.\n\nFirt of all lets make our objective clear.. our objective is to build a classifier that will predict did an individual survive the disaster or not.\n\n<h3>Question's we would like to anwser during our analysis:<\/h3>\n\n* Who's more likely to survive the sinking based on data?\n* Is age an indicator for survival?\n* Is gender an indicator for survival?\n* Did the crew aboard have a higher chance of survival than passengers?\n\n<h3>Our methodology will be:<\/h3>\n\n1. Load the data and review the data for missing value and outliers if found any we will decide how to fix\/adjust them\n\n2. engage in EDA and try to find interesting trends\/correlations and on the way try to awnser some the the question we would like to awnser\n\n3. select the features we will be using in our model, check if any feature engineering can be done in order to increase our models accuracy,encode categorical data if it exsits.\n\n4. split our data into train\/test set and normalize the input data.\n\n5. select a couple of models for our problem and try and find the optimal parameters for each model.\n\n6. review the result of all models and select a model for production.\n\n7. use the whole data to train the final model.\n\n8. review the final model result, go back to step 5 if needed.","a538f0b7":"### We can se most of our survivers are from Estonia and Sweden","6f025788":"## Now we can conclude the analysis part and awnser the questions we asked at the begining \n","cba0fe75":"# Model Selection And Evaluation","0bb01731":"* Who's more likely to survive the sinking based on data : **Male Crew Members Aged between 19-35**\n* Is age an indicator for survival : **Yes Chances Of Survival bellow age 19 and above 69 are vary low**\n* Is gender an indicator for survival : **Yes as we saw earlier more males survived then females**\n* Did the crew aboard have a higher chance of survival than passengers : **Yes we saw that proportionally\u200b more crew membres survived then passengers**\n","3d346ef4":"<h2>We can see that the number of passenger survivers is higher then the number of crew members survived but proportionally 25% of the crew has survived and only 14% of the passengers survived which makes sense becuase the crew is more likely to be trained to deal with extreme situations \u200b <\/h2>","b450bf13":"# EDA","0f605352":"# Feature Engineering And Data Normalization","91cf36f5":"# The best we could manage was a fairly low accuracy,in conclusion is seems like the data is unbalanced and most approaches we used in this notebook had very bad results. ","8737a744":"<h3>Lets explore our data and try to get a feel for what we are working with, are there any correlations? , we will also try to awnser some of the interesting questions we described in the begining <\/h3>"}}