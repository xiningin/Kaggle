{"cell_type":{"54480704":"code","549b6408":"code","cf126e0a":"code","5b40a2df":"code","348fa572":"code","89a985e5":"code","50a342a7":"code","b7fdc96c":"code","beb399ea":"code","e4e77da7":"code","bc01a0fe":"code","7d9d6df6":"code","1e3f47f9":"code","8a56a3d8":"code","33f35faa":"code","508992b7":"code","ed236f39":"code","dda91309":"code","8ef9f851":"code","ac5b9217":"code","118c1098":"markdown","9ee6b5d6":"markdown"},"source":{"54480704":"import os\nimport glob\nimport warnings\nimport math\nimport cv2\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow_addons.layers import WeightNormalization\nfrom sklearn.metrics import classification_report","549b6408":"###################\nimage_path = '..\/input\/stanford-dogs-dataset\/images\/Images'\nnum_of_categories = 120\nimage_size = 192\nbatch_size = 16\n###################","cf126e0a":"def read_images():\n    target_files = os.listdir(image_path)[:num_of_categories]\n    image_set = []\n    label_set = []\n    breed_ID = 0\n    for each_file in target_files:\n        for image in os.listdir(image_path + '\/' + each_file):            \n            image = cv2.imread(image_path + '\/' + each_file + '\/' + image, cv2.IMREAD_COLOR)\n            image = cv2.resize(image,(image_size,image_size))\n            image_set.append(image)\n            label_set.append(breed_ID)\n        breed_ID += 1\n    image_set = np.array(image_set)\n    label_set = np.array(label_set)\n    label_set = keras.utils.to_categorical(label_set)\n    np.save('image_set_%s.npy'%image_size,image_set)\n    np.save('label_set_%s.npy'%image_size,label_set)\n\n# read_images()\n\ndef split(image_set, label_set):\n    x_train, x_test, y_train, y_test = train_test_split(image_set, label_set, train_size = 0.8, random_state = np.random)\n    return x_train, x_test, y_train, y_test\n\n# x_train, x_test, y_train, y_test = split(image_set, label_set)","5b40a2df":"train_size = int(20580*0.8)\ntest_size = int(20580*0.2)","348fa572":"### Image loading method 1: image_datagen and flow_from_directory\n\ndef image_preprocess(image):\n    image = tf.image.per_image_standardization(image)\n    return image\n\ndef image_datagen_load():\n\n    datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=30, width_shift_range=0.2, zca_whitening=True, shear_range=0.2,\n        height_shift_range=0.2, brightness_range=[0.9,1.1], zoom_range=0.1, fill_mode='constant', cval=0.0, horizontal_flip=True, \n        rescale=1\/255., preprocessing_function=None, validation_split=0.2, dtype='float32')\n\n    train_datagen = datagen.flow_from_directory('..\/input\/stanford-dogs-dataset\/images\/Images\/',\n        target_size=(image_size, image_size), color_mode='rgb', classes=None, interpolation='hamming',\n        class_mode='categorical', batch_size=batch_size, shuffle=True, subset='training')\n\n    test_datagen = datagen.flow_from_directory('..\/input\/stanford-dogs-dataset\/images\/Images\/',\n        target_size=(image_size, image_size), color_mode='rgb', classes=None, interpolation='hamming',\n        class_mode='categorical', batch_size=batch_size, shuffle=False, subset='validation')\n    \n    return train_datagen, test_datagen","89a985e5":"### Image loading method 2: image_dataset_from_directory\n\ndef image_dataset_load():\n\n    train_dataset = keras.preprocessing.image_dataset_from_directory('..\/input\/stanford-dogs-dataset\/images\/Images\/', labels='inferred', \n        label_mode='categorical', class_names=None, color_mode=\"rgb\", batch_size=batch_size,\n        image_size=(image_size, image_size), shuffle=False, validation_split=0.2, subset='training', \n        interpolation='lanczos5')\n\n    test_dataset = keras.preprocessing.image_dataset_from_directory('..\/input\/stanford-dogs-dataset\/images\/Images\/', labels='inferred', \n        label_mode='categorical', class_names=None, color_mode=\"rgb\", batch_size=batch_size, \n        image_size=(image_size, image_size), shuffle=False, validation_split=0.2, subset='validation', \n        interpolation='lanczos5')\n\n    autotune = tf.data.experimental.AUTOTUNE\n\n    train_dataset = train_dataset.batch(batch_size).repeat().shuffle(1024).cache().prefetch(autotune)\n    test_dataset = test_dataset.batch(batch_size).repeat().shuffle(1024).cache().prefetch(autotune)\n    \n    return train_dataset, test_dataset","50a342a7":"### Decide which image loading method to use\n\ntrain, test = image_datagen_load()","b7fdc96c":"filters = 32\nkernel_size = (3,3)\nstride = (1,1)\npool_size = (3,3)\nl2 = tf.keras.regularizers.l2(0.00005)","beb399ea":"def conv2D(x,filters=filters,kernel=kernel_size,stride=stride,pad='same',activate=True,WN=False,l1l2=None):\n    if activate:\n        y = keras.layers.Conv2D(filters=filters,kernel_size=kernel,strides=stride,padding=pad,kernel_regularizer=l1l2,activation='relu')\n    else:\n        y = keras.layers.Conv2D(filters=filters,kernel_size=kernel,strides=stride,padding=pad,kernel_regularizer=l1l2,activation=None)\n    if WN:\n        x = WeightNormalization(y)(x)\n    else:\n        x = y(x)\n    return x\n\ndef selu(x):\n    x = tf.nn.selu(x)\n    return x\n\ndef maxpool2D(x,pool_size=pool_size,stride=stride,pad='same'):\n    x = keras.layers.MaxPool2D(pool_size=pool_size,strides=stride,padding=pad)(x)\n    return x\n\ndef BN(x):\n    x = keras.layers.BatchNormalization()(x)\n    return x\n\ndef concat(x): # input as list\n    x = keras.layers.Concatenate()(x)\n    return x\n\ndef res_add(raw_x,transformed_x,keep_scale):\n    x = keras.layers.Add()([raw_x*keep_scale,transformed_x*(1-keep_scale)])\n    return x\n\ndef stem(x):\n    x = conv2D(x,32,(1,1))\n    x = conv2D(x,32,(3,3))\n    x = conv2D(x,64,(3,3),(2,2))\n    x = conv2D(x,64,(3,3))\n    x_1 = maxpool2D(x,(3,3),(2,2))                 # ---|\n    x_2 = conv2D(x,96,(3,3),(2,2))                 # ---|\n    x = concat([x_1,x_2])           # size\/2, 160 channels\n    x_1 = conv2D(x,64,(1,1))                       # ---|\n    x_1 = conv2D(x_1,96,(3,3))                         #|\n    x_2 = conv2D(x,64,(1,1))                           #|\n    x_2 = conv2D(x_2,64,(1,7))                         #|\n    x_2 = conv2D(x_2,64,(7,1))                         #|\n    x_2 = conv2D(x_2,96,(3,3))                     # ---|\n    x = concat([x_1,x_2])           # size\/2, 192 channels                        \n    x_1 = maxpool2D(x,(3,3),(2,2))                 # ---|\n    x_2 = conv2D(x,192,(3,3),(2,2))                # ---|\n    x = concat([x_1,x_2])            \n    return x                        # size\/2, 384 channels\n\ndef blockA(x):\n    x_1 = x                         # highway\n    x_2_1 = conv2D(x,32,(1,1))\n    x_2_2 = conv2D(x,32,(1,1))\n    x_2_2 = conv2D(x_2_2,32,(3,3))\n    x_2_3 = conv2D(x,32,(1,1))\n    x_2_3 = conv2D(x_2_3,48,(3,3))\n    x_2_3 = conv2D(x_2_3,64,(3,3))\n    x_2 = concat([x_2_1,x_2_2,x_2_3])\n    x_2 = conv2D(x_2,384,(1,1),activate=False)\n    x = res_add(x_1,x_2,0.3)        # x_1 and x_2 must have the same number of channels to add up\n    x = selu(x)\n    return x                        # size fixed, channel fixed\n\ndef reduceA(x):\n    x_1 = maxpool2D(x,(3,3),(2,2))  # size\/2, channel fixed\n    x_2 = conv2D(x,384,(3,3),(2,2))\n    x_3 = conv2D(x,192,(1,1))\n    x_3 = conv2D(x_3,192,(3,3))\n    x_3 = conv2D(x_3,384,(3,3),(2,2))\n    x = concat([x_1,x_2,x_3]) \n    return x                        # size\/2, 1152 channel\n\ndef blockB(x):\n    x_1 = x\n    x_2_1 = conv2D(x,192,(1,1))\n    x_2_2 = conv2D(x,128,(1,1))\n    x_2_2 = conv2D(x_2_2,160,(1,7))\n    x_2_2 = conv2D(x_2_2,192,(7,1))\n    x_2 = concat([x_2_1,x_2_2])\n    x_2 = conv2D(x_2,1152,(1,1),activate=False)\n    x = res_add(x_1,x_2,0.3)\n    x = selu(x)\n    return x                        # size fixed, channel fixed\n\ndef reduceB(x):\n    x_1 = maxpool2D(x,(3,3),(2,2))\n    x_2 = conv2D(x,256,(1,1))\n    x_2 = conv2D(x_2,384,(3,3),(2,2))\n    x_3 = conv2D(x,256,(1,1))\n    x_3 = conv2D(x_3,288,(3,3))\n    x_3 = conv2D(x_3,320,(3,3),(2,2))\n    x = concat([x_1,x_2,x_3])\n    return x                        # size\/2, 1856 channel\n\ndef blockC(x):\n    x_1 = x\n    x_2_1 = conv2D(x,192,(1,1))\n    x_2_2 = conv2D(x,192,(1,1))\n    x_2_2 = conv2D(x_2_2,224,(1,3))\n    x_2_2 = conv2D(x_2_2,256,(3,1))\n    x_2 = concat([x_2_1,x_2_2])\n    x_2 = conv2D(x_2,1856,(1,1),activate=False)\n    x = res_add(x_1,x_2,0.3)\n    x = selu(x)\n    return x                        # size fixed, channel fixed\n    \n\ndef outputs(x):\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dropout(0.5)(x, training=True)\n    x = keras.layers.Dense(num_of_categories, activation='softmax')(x)\n    return x\n\ninputs = keras.Input(shape=(image_size,image_size,3))\nx = stem(inputs)\nfor i in range(1):\n    x = blockA(x)\nx = reduceA(x)\nfor i in range(2):\n    x = blockB(x)\nx = reduceB(x)\nfor i in range(1):\n    x = blockC(x)\noutputs = outputs(x)","e4e77da7":"###################\ntotal_epoch = 50\nlr_init = 0.00001\n###################","bc01a0fe":"def scheduler_1(epoch):\n    epoch += 1\n    threshold = 15\n    lr_init = 0.0001\n    lr = lr_init\n    depre = 0.95**(epoch-threshold)\n    if epoch <= threshold:\n        return lr_init\n    elif lr > lr_init\/50:\n        lr = lr_init * depre\n        return lr\n    else:\n        return lr","7d9d6df6":"def scheduler_2(epoch):\n    epoch += 1\n   \n    if epoch == 1:\n        return lr_init\n    \n    elif epoch >= 2 and epoch <= 20:\n        return (0.5*epoch**3)*math.exp(-0.5*epoch)*lr_init\n    \n    else:\n        return scheduler_2(20-1)\n    \n\nstage = [i for i in range(0,30)]\nlearning_rate = [scheduler_2(x) for x in stage]\nplt.plot(stage, learning_rate)\nprint(learning_rate)","1e3f47f9":"model = keras.Model(inputs, outputs,name='model')\nloss = keras.losses.CategoricalCrossentropy()\noptimizer = keras.optimizers.Nadam(learning_rate=lr_init)\nmetrics = [keras.metrics.CategoricalAccuracy(name='acc')]\nmodel.compile(loss=loss,optimizer=optimizer,metrics=metrics)\n\ntry:\n    model_this = model\n    model_this.load_weights('..\/input\/classifying-120-classes-with-inception-resnetv2\/model_weights.h5')\n    print('loaded previous weights')\nexcept:\n    model_last = keras.models.load_model('..\/input\/classifying-120-classes-with-inception-resnetv2\/model.h5')\n    print('loaded previous model')\n\nmodel = model_this\nprint(model.summary())","8a56a3d8":"scheduler = keras.callbacks.LearningRateScheduler(scheduler_2, verbose=1)\nearlystop = keras.callbacks.EarlyStopping(monitor='val_acc',mode='max',verbose=1,patience=5,restore_best_weights=True)\ncheckpoint = keras.callbacks.ModelCheckpoint('temp',save_weights_only=True,monitor='val_acc',mode='max',save_best_only=True)\n\nhistory = model.fit(train, batch_size=bat ch_size, epochs=total_epoch, callbacks=[scheduler,earlystop,checkpoint],\n                    validation_data=test, steps_per_epoch=train_size\/\/batch_size, validation_steps=test_size\/\/batch_size)","33f35faa":"model.save('model.h5', overwrite=True)\nmodel.save_weights('model_weights.h5', overwrite=True)","508992b7":"print('max validation accuracy during training: ',max(history.history['val_acc']))\nprint('min validation loss during training: ',min(history.history['val_loss']))","ed236f39":"pred = model.predict(test, batch_size=batch_size, steps=test_size\/\/batch_size, verbose=1)\npred = np.argmax(pred, axis=-1)","dda91309":"class_to_id={}\nid_to_class={}\nfor key, value in test.class_indices.items():\n    class_to_id[key[10:]] = value\n    id_to_class[value] = key[10:]\n\nreport = classification_report(test.classes, pred, target_names=class_to_id)\nprint(report)","8ef9f851":"plt.title('model accuracy')\nplt.plot(history.history['acc'],label='train accuracy')\nplt.plot(history.history['val_acc'],label='test accuracy')\nplt.legend()\nplt.show()","ac5b9217":"plt.title('model loss')\nplt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='test loss')\nplt.legend()\nplt.show()","118c1098":"#### Classifying 120 classes without pre-trained models from *keras.applications* can be a challenging task. In this notebook, I am trying to accomplish this by using InceptionNet and Resnet architectures to create a deep enough CNN for this task. Feedback is welcome!\n#### What I did with this model:\n* Train from scratch without pre-trained models from keras\n* Bulit based on Inception-Resnetv2 CNN but the size is reduced substantially to save training time\n* Using NAdam optimization (Adam with Nesterov)\n* continue training using the model weights from the last version\n* Replaced ReLU by SELU for a self-normalizing neural network\n* No Batch Normalization because of using SELU","9ee6b5d6":"### Consider adopting a dog!\n\n![Adopt a dog](https:\/\/hongkongdogrescue.com\/wp-content\/uploads\/2016\/03\/Adopting-a-Dog.png)\n\n\n"}}