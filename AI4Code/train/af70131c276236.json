{"cell_type":{"4566a9f8":"code","b1d51725":"code","cfcc709a":"code","c314ae21":"code","62ec5ce5":"code","797b9671":"code","59c47482":"code","6c05db42":"code","1f045818":"code","56be06ed":"code","7cb987bd":"code","6069513e":"code","0da5cba6":"code","aadb426b":"code","deff4f33":"code","ca400441":"code","e950e82a":"code","33806392":"code","56ce51d0":"code","1286aa71":"code","795ada9b":"code","e0dd1b60":"code","004fbccb":"code","3b0642d7":"code","b35ba19f":"code","25a151a4":"code","81d5ccbf":"code","ba53b67c":"code","7d9da00a":"code","06f3c840":"code","47073e9f":"code","b61c58f2":"code","d0932c6e":"code","c5b65dea":"code","0ab9e8ff":"code","930a92ce":"code","cfa82a5a":"code","3365525a":"code","f75c486c":"code","ad5eb8f9":"code","c0bcb7c5":"code","4875ffa1":"code","786576af":"code","db431f0e":"code","a997ed9e":"markdown","312676a4":"markdown","e8930cd1":"markdown","efa89466":"markdown","33f8f5d5":"markdown","7898384e":"markdown","67478062":"markdown","e1daf5dc":"markdown","71e5ae21":"markdown","6a2e4fc6":"markdown","69c213cc":"markdown","e8783966":"markdown","f376f802":"markdown","c63f8d51":"markdown","56ba96a5":"markdown","02cdd2cd":"markdown","87f9f6b8":"markdown","fa966e46":"markdown","6106e84c":"markdown","9d62146b":"markdown","4333a9f8":"markdown"},"source":{"4566a9f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1d51725":"heart= pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","cfcc709a":"heart.head()","c314ae21":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns","62ec5ce5":"heart.info()","797b9671":"heart.describe()","59c47482":"heart.isnull().sum()","6c05db42":"categoricalCol = heart.select_dtypes(object).columns\nnumericalCol = heart.select_dtypes(exclude=object).columns\nprint('Categorical Columns: ', categoricalCol)\nprint('Numerical Columns: ', numericalCol)","1f045818":"TargetColumn= heart['HeartDisease']","56be06ed":"plt.figure(figsize=(8,5))\nsns.set(font_scale=1.3)\nplot = sns.histplot(data=heart, x='Sex', hue='HeartDisease', multiple='dodge', shrink=0.8, palette=('rainbow'))\nplot.set(title='Histg. based on Sex with H.D. categorization', xlabel='Sex', ylabel='Count')","7cb987bd":"malesubdata= heart.loc[(heart.Sex == 'M')]\nfemalesubdata = heart.loc[(heart.Sex== 'F')]\nprint('M(HD==1): {}, M(HD==0): {}, P(M)(HD==1): {}'.format(malesubdata.loc[malesubdata.HeartDisease == 1].shape[0], malesubdata.loc[malesubdata.HeartDisease == 0].shape[0], malesubdata.loc[malesubdata.HeartDisease == 1].shape[0]\/malesubdata.shape[0]))\nprint('F(HD==1): {}, F(HD==0): {}, P(F)(HD==1): {}'.format(femalesubdata.loc[femalesubdata.HeartDisease == 1].shape[0], femalesubdata.loc[femalesubdata.HeartDisease == 0].shape[0], femalesubdata.loc[femalesubdata.HeartDisease == 1].shape[0]\/femalesubdata.shape[0]))","6069513e":"#Now we will see the scatter plot of age vs cholestrol with respect to Heart Disease\nplt.figure(figsize=(12,8))\nsns.set(font_scale=1.2)\nsns.scatterplot(data=heart, x='Age', y='Cholesterol', hue='HeartDisease')","0da5cba6":"plt.figure(figsize=(6,5))\n\nsns.heatmap(heart.corr(), annot=True)","aadb426b":"print(np.unique(heart.Oldpeak))\nsns.lmplot(data=heart, x='Age', y='Oldpeak', hue='HeartDisease', height=8)","deff4f33":"plt.figure(figsize=(20,15))\n\nplt.subplot(2,3,1)\nsns.countplot(data=heart, x='Age', hue='HeartDisease')\n\nplt.subplot(2,3,2)\nsns.countplot(data=heart, x='Sex', hue='HeartDisease')\n\nplt.subplot(2,3,3)\nsns.countplot(data=heart, x='ChestPainType', hue='HeartDisease')\n\nplt.subplot(2,3,4)\nsns.countplot(data=heart, x='RestingBP', hue='HeartDisease')\n\nplt.subplot(2,3,5)\nsns.countplot(data=heart, x='Oldpeak', hue='HeartDisease')\n\nplt.subplot(2,3,6)\nsns.countplot(data=heart, x='FastingBS', hue='HeartDisease')\n\nplt.show()","ca400441":"plt.figure(figsize=(10,5))\n\nsns.swarmplot(data=heart, x='Sex', y='MaxHR', hue='HeartDisease')","e950e82a":"#importing all the classification models \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, accuracy_score","33806392":"Heart = heart.copy()\nHeart[categoricalCol] = Heart[categoricalCol].astype('category')\nHeart[categoricalCol]= Heart[categoricalCol].apply(lambda x:x.cat.codes)\n\nprint(np.unique(Heart.ChestPainType))\nHeart.head()","56ce51d0":"X= Heart.drop(['HeartDisease'], axis=1)\ny= Heart['HeartDisease']","1286aa71":"X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=4)","795ada9b":"lr = LogisticRegression(max_iter=500)\nlr.fit(X_train, y_train)","e0dd1b60":"prediction = lr.predict(X_test)","004fbccb":"confusion_matrix(y_test, prediction)","3b0642d7":"lrc = accuracy_score(y_test, prediction)\nlrc","b35ba19f":"from sklearn import tree","25a151a4":"decisionTree = DecisionTreeClassifier(criterion= 'entropy', max_depth=5)\ndecisionTree.fit(X_train, y_train)","81d5ccbf":"plt.figure(figsize=(55,18))\ntree.plot_tree(decisionTree, feature_names=numericalCol.tolist()+ categoricalCol.tolist(), class_names=['Yes', 'No'], filled=True)","ba53b67c":"y_pred = decisionTree.predict(X_test)\nconfusion_matrix(y_test, y_pred)","7d9da00a":"dtc = accuracy_score(y_test, y_pred)\ndtc","06f3c840":"rf =RandomForestClassifier(criterion= 'entropy', max_depth=5)\nrf.fit(X_train, y_train)","47073e9f":"y_pred = rf.predict(X_test)\nconfusion_matrix(y_test, y_pred)","b61c58f2":"rfc = accuracy_score(y_test, y_pred)\nrfc","d0932c6e":"svm = SVC()\nsvm.fit(X_train, y_train)","c5b65dea":"y_pred = svm.predict(X_test)\nconfusion_matrix(y_test, y_pred)","0ab9e8ff":"svc = accuracy_score(y_test, y_pred)\nsvc","930a92ce":"adaBoost= AdaBoostClassifier(n_estimators=100)\nadaBoost.fit(X_train, y_train)","cfa82a5a":"y_test= adaBoost.predict(X_test)\nconfusion_matrix(y_test, y_pred)","3365525a":"adac = accuracy_score(y_test, y_pred)\nadac","f75c486c":"gboost = GradientBoostingClassifier(max_depth=5)\ngboost.fit(X_train, y_train)","ad5eb8f9":"y_pred= gboost.predict(X_test)\nconfusion_matrix(y_test, y_pred)","c0bcb7c5":"gbc = accuracy_score(y_test, y_pred)\ngbc","4875ffa1":"accuracy = [lrc, dtc, rfc, svc, adac, gbc]\nmodel = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'Ada Boost', 'Gradient Boosting']\nmodelAccuracy= pd.DataFrame(data={'Model': model, 'Accuracy': accuracy})","786576af":"modelAccuracy.sort_values(by=['Accuracy'], ascending=False, inplace=True)","db431f0e":"plt.figure(figsize=(8,5))\nsns.barplot(x='Accuracy', y='Model', data=modelAccuracy)","a997ed9e":"**We can see from the above calculation that male have more chance of getting heart disease as compared to female**","312676a4":"This graph shows that Oldpeak and Age increases so does the Heart disease also increases.","e8930cd1":"**Checking the first 5 data**","efa89466":"**As from this graph we can clearly see that Gradient Boost method worked really well, as it holds the best result**","33f8f5d5":"**EDA**","7898384e":"**The isnull().sum() depicts the null value in our dataset. If there is any null value the numbers will be automatically shown  below.**","67478062":"From this graph we infer that, a male requires certain MaxHR to be healthy, and if it falls below a certain range in male. The chance if getting Heart disease is pretty much high. \n\nOn the other hand we also observe that in female the chances of getting low MaxHR is very low as compared to male.","e1daf5dc":"**Decision Tree**","71e5ae21":"**Importing the dataset**","6a2e4fc6":"**Here we import various packages for our dataset**","69c213cc":"**Accuracy comparison of all the models used above**","e8783966":"**The describe() function describes about the data, and also calculates the mean, count, std, min of the our dataset.**","f376f802":"**Here we will find out the categorical and numerical values in our dataset.**","c63f8d51":"**Support Vector Machine**","56ba96a5":"**Gradient Boosting Classifier**","02cdd2cd":"**Using this info() method we can check the information about this data. It tell us the Null count and Dtype of this data.**","87f9f6b8":"****Modelling, Training and Prediction****","fa966e46":"**Random Forest**","6106e84c":"**Now we will set aside the Target variable for our training and analysis","9d62146b":"**Ada Boost Classifier**","4333a9f8":"As we can see oldpeak and MaxHR have the highest absolute relation to the target variable"}}