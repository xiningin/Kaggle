{"cell_type":{"65d44b92":"code","062f50c5":"code","7a6d8ac9":"code","b654648a":"code","de2b894e":"code","60bf78a1":"code","8448b7fd":"code","19fcfde0":"code","a12ecb55":"code","36661b58":"code","05161116":"code","2bca0100":"markdown","2d88c2f2":"markdown","3386afb6":"markdown","a4bf9ac7":"markdown"},"source":{"65d44b92":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom tqdm import tqdm\nimport networkx as nx\n\nimport matplotlib.pyplot as plt\nfrom pylab import plot, ylim, xlim, show, xlabel, ylabel, grid\nfrom scipy.cluster.hierarchy import dendrogram\n\nfrom networkx.algorithms import community\nimport itertools\nimport graphviz","062f50c5":"#Loading the dataset and viewing first few rows\nundf = pd.read_csv('\/kaggle\/input\/un-resolutions\/UN DATA.csv',low_memory=False)\nundf.insert(2, 'YEAR', undf['Date'].str.extract(r'([0-9]{4})').astype(int))\nundf = undf[undf['YEAR'] > 2010]\nundf = undf[undf['Council'].eq('General Assembly')]","7a6d8ac9":"metacols = undf.columns[:12].to_list()\nstatecols = [c for c in undf.columns if c not in metacols]\n\ngadf = undf[statecols]\nvdf = pd.DataFrame(index=statecols, columns=statecols)\nfor from_state in tqdm(statecols,desc='Building edge list'):\n    f_df = gadf[from_state].fillna('FNA')\n    t_df = gadf.fillna('TNA')\n    e = (t_df.T == f_df).sum(axis=1)\n    vdf.loc[from_state] = e\n    vdf.loc[from_state, from_state] = (~f_df.eq('FNA')).sum()\n\nminimal_value = 10\nempties = vdf.sum(axis=1) <= minimal_value\nstates = empties[~empties].index.tolist()\ncommon_votes = vdf.loc[states, states]\nnormalized_common_votes = common_votes \/ common_votes.max(axis=1)","b654648a":"common_votes.head(10)","de2b894e":"min_votes = 900\nmax_edges_per_state = 20","60bf78a1":"vdf = common_votes\nvdf = vdf[vdf.max(axis=1) > min_votes]\nvdf = vdf[list(vdf.index)]\nnvdf = vdf \/ vdf.max(axis=1)\nfor c in nvdf.columns:\n    nvdf.loc[c, c] = 0\n    z = nvdf.sort_values(by=c, ascending=False)[c].iloc[max_edges_per_state:].index.to_list()\n    nvdf.loc[c, z] = 0\n\nreduced_nvdf = nvdf.copy()\nfor c in reduced_nvdf.columns:\n    reduced_nvdf.loc[c, c] = 0\n    z = reduced_nvdf.sort_values(by=c, ascending=False)[c].iloc[15:].index.to_list()\n    reduced_nvdf.loc[c, z] = 0\nG = nx.from_pandas_adjacency(reduced_nvdf.astype(float), create_using=nx.DiGraph)","8448b7fd":"k = 1\ntot = 20\nset2key = lambda subset: ';'.join(sorted(list(subset)))\ncomp = community.girvan_newman(G)\ncommunities_t = [t for t in tqdm((itertools.islice(comp, k, k + tot)), desc='Bulding communities',total=tot-k+1)]\nsingle_states = reduced_nvdf.index.to_list()\ncollective_group = set(single_states)\n# building initial dict of node_id to each possible subset:\nnode_id = 0\ninit_node2community_dict = dict()  # {node_id: communities_t[0][0].union(communities_t[0][1])}\nindividual_community = [set([s]) for s in single_states]\ncommunities = [tuple([collective_group])] + communities_t + [individual_community]","19fcfde0":"for comm in communities:\n    for subset in list(comm):\n        if subset not in init_node2community_dict.values():\n            init_node2community_dict[node_id] = subset\n            node_id += 1\n\nidx2community = {set2key(v): k for k, v in init_node2community_dict.items()}\n# turning this dictionary to the desired format in @mdml's answer\nnode_id_to_children = {e: [] for e in init_node2community_dict.keys()}\nfor comm_level_idx in range(len(communities) - 1):\n    comm_level_parent = communities[comm_level_idx]\n    comm_level_child = communities[comm_level_idx + 1]\n    for parent in comm_level_parent:\n        parent_idx = idx2community[set2key(parent)]\n        for child in comm_level_child:\n            intersection_size = len(child.intersection(parent))\n            if intersection_size == 0:\n                pass\n            else:\n                child_idx = idx2community[set2key(child)]\n                if child_idx != parent_idx:\n                    node_id_to_children[parent_idx] = node_id_to_children[parent_idx] + [child_idx]\n\n# also recording node_labels dict for the correct label for dendrogram leaves\nnode_labels = dict()\nfor node_id, group in init_node2community_dict.items():\n    if len(group) == 1:\n        node_labels[node_id] = list(group)[0]\n    else:\n        node_labels[node_id] = ''\n\n# also needing a subset to rank dict to later know within all k-length merges which came first\nsubset_rank_dict = dict()\nrank = 0\nfor e in communities[::-1]:\n    for p in list(e):\n        if tuple(p) not in subset_rank_dict:\n            subset_rank_dict[tuple(sorted(p))] = rank\n            rank += 1\nsubset_rank_dict[tuple(sorted(itertools.chain.from_iterable(communities[-1])))] = rank\n\n\n# my function to get a merge height so that it is unique (probably not that efficient)\ndef get_merge_height(sub):\n    sub_tuple = tuple(sorted([node_labels[i] for i in sub]))\n    n = len(sub_tuple)\n    other_same_len_merges = {k: v for k, v in subset_rank_dict.items() if len(k) == n}\n    if len(other_same_len_merges) == 0:\n        range = 1\n        min_rank, max_rank = 1, 1\n    else:\n        min_rank, max_rank = min(other_same_len_merges.values()), max(other_same_len_merges.values())\n        range = (max_rank - min_rank) if max_rank > min_rank else 1\n    return float(len(sub)) + 0.8 * (subset_rank_dict[sub_tuple] - min_rank) \/ range\n\n\n# finally using @mdml's magic, slightly modified:\nGt = nx.DiGraph(node_id_to_children)\nnodes = Gt.nodes()\nleaves = set(n for n in nodes if Gt.out_degree(n) == 0)\ninner_nodes = [n for n in nodes if Gt.out_degree(n) > 0]","a12ecb55":"# Compute the size of each subtree\nsubtree = dict((n, [n]) for n in leaves)\nfor u in inner_nodes:\n    children = set()\n    node_list = list(node_id_to_children[u])\n    while len(node_list) > 0:\n        v = node_list.pop(0)\n        children.add(v)\n        node_list += node_id_to_children[v]\n    subtree[u] = sorted(children & leaves)\n\ninner_nodes.sort(key=lambda n: len(subtree[n]))  # <-- order inner nodes ascending by subtree size, root is last\n\n# Construct the linkage matrix\nleaves = sorted(leaves)\nindex = dict((tuple([n]), i) for i, n in enumerate(leaves))\nZ = []\nk = len(leaves)\nfor i, n in enumerate(inner_nodes):\n    children = node_id_to_children[n]\n    x = children[0]\n    for y in children[1:]:\n        z = tuple(sorted(subtree[x] + subtree[y]))\n        i, j = index[tuple(sorted(subtree[x]))], index[tuple(sorted(subtree[y]))]\n\n        subtree_n = subtree[n]\n        merge_height = get_merge_height(subtree_n)\n        zval = [i, j, merge_height, len(z)]\n        Z.append(zval)  # <-- float is required by the dendrogram function\n        index[z] = k\n        subtree[z] = list(z)\n        x = z\n        k += 1","36661b58":"fig1, ax1 = plt.subplots(1, figsize=(10, 35))\nlabels = [node_labels[node_id] for node_id in leaves]\ndendrogram(Z, orientation='right', labels=labels, ax=ax1)\nplt.yticks(fontsize=9)\nplt.show()","05161116":"top_a = 10\nidx = 5\nfor tidx, allies in enumerate(communities):\n    r = [len(a) for a in allies if len(a) > 1]\n    partitions = len(r)\n    if partitions >= top_a:\n        idx = tidx\n        break\n\nallies = sorted(allies, key=lambda s: -len(s))[:top_a]\nrandom.shuffle(allies)\n\nalliesdf = pd.DataFrame(index=[f'Member {i + 1}' for i in range(max([len(a) for a in allies]))],\n                        columns=[f'Alliance {i + 1}' for i in range(len(allies))],\n                        data=''\n                        )\nfor i, a in enumerate(allies):\n    at = list(a) + ([''] * (alliesdf.shape[0] - len(a)))\n    alliesdf[f'Alliance {i + 1}'] = at\n\npd.set_option('display.max_rows', 500)\nalliesdf","2bca0100":"# Every UN resolution and the votes it got","2d88c2f2":"# Dendrogram of alliances\nIf these countries \"merge\" sooner, they are more likely to vote together","3386afb6":"# Understand alliances using Community detection","a4bf9ac7":"# Top 10 voting blocks\nAll countries in a certain colum (Alliance) tend to vote the same way"}}