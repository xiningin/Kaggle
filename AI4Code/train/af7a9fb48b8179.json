{"cell_type":{"9d628a05":"code","edfd3ec9":"code","1393f885":"code","92222b02":"code","5ca84f28":"code","01eb37ee":"code","63b8955b":"code","5a3dddd1":"code","45afc6b7":"code","2fbe26f9":"code","644719e2":"code","b58d13a8":"code","400deb19":"code","21dbb88b":"code","64e389bb":"code","cfc349c2":"code","a810d29a":"code","619d6ee7":"code","3462af29":"code","5a97ffff":"code","ecc11cb9":"code","2b66f392":"code","b440e23c":"code","a6194aa6":"code","01ce282f":"code","44363d09":"code","1eea1531":"code","cb2b4ffd":"code","d5c24aa9":"code","e4bf9c91":"code","871aa7cb":"code","8b9cdbba":"code","d3701492":"code","fc3917ed":"code","a804ecf8":"code","b02e2f4e":"code","80247e52":"code","9b671624":"code","a0ae178b":"code","3679d80a":"code","d797fa8e":"code","c5e2ca27":"code","e3661fcf":"code","1c903008":"code","bdb48cd7":"code","a4f7b12a":"markdown","6eeb379d":"markdown","e4a5d085":"markdown","b5ce79a9":"markdown","ef23597d":"markdown","5543fe3b":"markdown","3de0088a":"markdown"},"source":{"9d628a05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","edfd3ec9":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\nimport seaborn as sns","1393f885":"ds_train = pd.read_csv('..\/input\/train.csv')\nds_test = pd.read_csv('..\/input\/test.csv')","92222b02":"ds_train.head()","5ca84f28":"ds_test.head()","01eb37ee":"ds_train.describe()    # checking statistics of data like any outliers ","63b8955b":"ds_test.describe()","5a3dddd1":"ds_train.info()  # checking null values","45afc6b7":"ds_test.info()","2fbe26f9":"# Correlation matrix - linear relation among independent attributes and with the Target attribute\n\nsns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorreln = ds_train.corr()\n\n# Generate a mask for the upper triangle\n#mask = np.zeros_like(correln, dtype=np.bool)\n#mask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(correln,  cmap=cmap, vmax=.3, #mask=mask,\n            linewidths=.5, cbar_kws={\"shrink\": .7})\n","644719e2":"# Parch and Sex Vs Survived\n\ng = sns.FacetGrid(ds_train, col=\"Parch\",  row=\"Sex\", hue = 'Survived')\ng = g.map(plt.hist, \"Survived\")","b58d13a8":"# Passenger class and Sex Vs Survived\n\ng = sns.FacetGrid(ds_train, col=\"Pclass\",  row=\"Sex\", hue = 'Survived')\ng = g.map(plt.hist, \"Survived\")","400deb19":"print(ds_train.dtypes)","21dbb88b":"ds_train[\"Embarked\"].value_counts()","64e389bb":"ds_train['Embarked']=ds_train['Embarked'].replace(np.nan,\"S\")\nds_test['Embarked']=ds_test['Embarked'].replace(np.nan,\"S\")","cfc349c2":"ds_test[ds_test['Fare'].isna()]['Pclass']","a810d29a":"ds_test['Fare'] = np.where(ds_test['Fare'].isna(), np.nanmedian(ds_test[ds_test['Pclass']==3]['Fare']), ds_test['Fare'])\n# imputing fare with respect to pclass with a median value of Fare considering only Pclass of 3 as fare greatly changed with Pclass","619d6ee7":"ds_train[\"Sex\"] = ds_train[\"Sex\"].map({\"male\" : 0, \"female\" : 1}).astype(\"category\")\nds_train['Pclass'] = ds_train['Pclass'].astype(\"category\")\nds_train['Embarked'] = ds_train['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(\"category\")\n\nds_test['Sex'] = ds_test['Sex'].map({'male':0, 'female':1}).astype(\"category\")  \nds_test['Pclass'] = ds_test['Pclass'].astype(\"category\")\nds_test['Embarked'] = ds_test['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(\"category\")","3462af29":"# Imputing missing values in Cabin with \"Unknown\"\n\nds_train['Cabin']=ds_train['Cabin'].replace(np.nan,\"Unknown\").astype(\"category\")\nds_test['Cabin']=ds_test['Cabin'].replace(np.nan,\"Unknown\").astype(\"category\")","5a97ffff":"ds_train['title'] = ds_train['Name'].str.split(',').apply(lambda x: x[1])\nds_test['title'] = ds_test['Name'].str.split(',').apply(lambda x: x[1])","ecc11cb9":"ds_train['title'] = ds_train['title'].str.split('.').apply(lambda x: x[0])\nds_test['title'] = ds_test['title'].str.split('.').apply(lambda x: x[0])","2b66f392":"ds_train['title'].value_counts()","b440e23c":"ds_train['title'] = ds_train['title'].apply(lambda x: x.strip())\nds_test['title'] = ds_test['title'].apply(lambda x: x.strip())","a6194aa6":"# Refining Titles in train dataset\n\nds_train['title'] = np.where(((ds_train['title']== 'Rev') | (ds_train['title']== 'Col') |\n                                (ds_train['title']== 'Major') | (ds_train['title']== 'Capt') |\n                                (ds_train['title']== 'Don') | (ds_train['title']== 'Sir') |\n                                (ds_train['title']== 'Jonkheer') | (ds_train['title']== 'Dr')), 'Mr', ds_train['title'])\n\nds_train['title'] = np.where(((ds_train['title']== 'Mlle') | (ds_train['title']== 'Lady') | \n                             (ds_train['title']== 'the Countess') | (ds_train['title']== 'Mme') |\n                             (ds_train['title']== 'Dona')), 'Mrs', ds_train['title'])\n\nds_train['title'] = np.where(ds_train['title']=='Ms', 'Miss',ds_train['title'])","01ce282f":"# Refining Titles in test dataset\n\nds_test['title'] = np.where(((ds_test['title']== 'Rev') | (ds_test['title']== 'Col') |\n                                (ds_test['title']== 'Major') | (ds_test['title']== 'Capt') |\n                                (ds_test['title']== 'Don') | (ds_test['title']== 'Sir') |\n                                (ds_test['title']== 'Jonkheer') | (ds_test['title']== 'Dr')), 'Mr', ds_test['title'])\n\nds_test['title'] = np.where(((ds_test['title']== 'Mlle') | (ds_test['title']== 'Lady') | \n                             (ds_test['title']== 'the Countess') | (ds_test['title']== 'Mme') |\n                             (ds_test['title']== 'Dona')), 'Mrs', ds_test['title'])\n\nds_test['title'] = np.where(ds_test['title']=='Ms', 'Miss',ds_test['title'])","44363d09":"ds_train['title'].value_counts()","1eea1531":"# Title encoding\n\nds_train['title_enc'] = ds_train['title'].map({'Mr':0, 'Miss':1,'Mrs':2,'Master':3}).astype('category')\nds_test['title_enc'] = ds_test['title'].map({'Mr':0, 'Miss':1,'Mrs':2,'Master':3}).astype('category')","cb2b4ffd":"# Imputing with median of the respective group - Train dataset\n\nds_train['Age'] = np.where(((ds_train['title']=='Mrs') & (ds_train['Age'].isna())), np.nanmedian(ds_train[ds_train['title']=='Mrs']['Age']), ds_train['Age'])\nds_train['Age'] = np.where(((ds_train['title']=='Miss') & (ds_train['Age'].isna())), np.nanmedian(ds_train[ds_train['title']=='Miss']['Age']), ds_train['Age'])\nds_train['Age'] = np.where(((ds_train['title']=='Mr') & (ds_train['Age'].isna())), np.nanmedian(ds_train[ds_train['title']=='Mr']['Age']), ds_train['Age'])\nds_train['Age'] = np.where(((ds_train['title']=='Master') & (ds_train['Age'].isna())), np.nanmedian(ds_train[ds_train['title']=='Master']['Age']), ds_train['Age'])","d5c24aa9":"# Imputing Age in test datase using the above strategy - Test dataset\n\nds_test['Age'] = np.where(((ds_test['title']=='Mrs') & (ds_test['Age'].isna())), np.nanmedian(ds_test[ds_test['title']=='Mrs']['Age']), ds_test['Age'])\nds_test['Age'] = np.where(((ds_test['title']=='Miss') & (ds_test['Age'].isna())), np.nanmedian(ds_test[ds_test['title']=='Miss']['Age']), ds_test['Age'])\nds_test['Age'] = np.where(((ds_test['title']=='Mr') & (ds_test['Age'].isna())), np.nanmedian(ds_test[ds_test['title']=='Mr']['Age']), ds_test['Age'])\nds_test['Age'] = np.where(((ds_test['title']=='Master') & (ds_test['Age'].isna())), np.nanmedian(ds_test[ds_test['title']=='Master']['Age']), ds_test['Age'])","e4bf9c91":"ds_train.isna().sum()","871aa7cb":"ds_test.isna().sum()","8b9cdbba":"ds_train.columns","d3701492":"ds_test.columns","fc3917ed":"tr_ds_reducd = ds_train.drop(['Name','PassengerId','Ticket','Cabin','title'], axis = 1)\ntest_ds_reducd = ds_test.drop(['Name','PassengerId','Ticket','Cabin','title'], axis = 1)","a804ecf8":"test_ds_reducd.columns","b02e2f4e":"y = tr_ds_reducd['Survived']\nx = tr_ds_reducd.drop(['Survived'], axis=1)","80247e52":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(x,y)","9b671624":"# Scaling attributes - Standard Scaler\n\nnum_cols = ['Age','Fare']\n\nX_train_scaled = X_train.copy()\nX_val_scaled = X_val.copy()\nX_test_scaled = test_ds_reducd.copy()\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train[num_cols])\nX_train_scaled[num_cols] = scaler.transform(X_train_scaled[num_cols])\nX_val_scaled[num_cols] = scaler.transform(X_val_scaled[num_cols])\nX_test_scaled[num_cols] = scaler.transform(X_test_scaled[num_cols])","a0ae178b":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression()","3679d80a":"log_reg.fit(X_train_scaled,y_train)","d797fa8e":"tr_pred = log_reg.predict(X_train_scaled)\nval_pred = log_reg.predict(X_val_scaled)\nlog_test_pred = log_reg.predict(X_test_scaled)","c5e2ca27":"from sklearn.metrics import accuracy_score","e3661fcf":"accuracy_score(y_train, tr_pred)","1c903008":"accuracy_score(y_val, val_pred)","bdb48cd7":"print(log_test_pred)","a4f7b12a":"### Applying Logistic Regression \n","6eeb379d":"Clearly Embarked, Age and Cabin has Missing Values in train data","e4a5d085":"Clearly Age, Fare and Cabin has Missing Values in test data","b5ce79a9":"Splitting the train data into train and validation","ef23597d":"Observations:\n\n1) Females survival rate is higher\n\n2) Pclass 1 and 2 had greater survival rates than class 3 across male and female categories","5543fe3b":"#### Finding correlations between features, How they are related to each other\n","3de0088a":"Fare has highest positive correlation with Survived follwed by Parch and Pclass displayed by color Dark red, light red and light blue"}}