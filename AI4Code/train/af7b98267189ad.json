{"cell_type":{"6b076922":"code","fd8e8ce5":"code","55f20d4c":"code","872e8dd2":"code","0053e567":"code","4ad5766e":"code","c1369603":"code","1ce15b63":"code","b2a5e1e3":"code","4fe429b7":"code","4b50d730":"code","89caee1c":"code","8d4e4992":"markdown","7f713ea4":"markdown","0afbbbc7":"markdown"},"source":{"6b076922":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt","fd8e8ce5":"image_path = '..\/input\/experiment-images\/image.jpg'\nimage = cv2.imread(image_path)\nimage = image[:,:,::-1]\nplt.imshow(image)","55f20d4c":"def nst(trained_model_path,image):\n\n    model = trained_model_path\n    net = cv2.dnn.readNetFromTorch(model)\n\n    image = cv2.imread(image)\n    (h,w) = image.shape[:2]\n\n    blob = cv2.dnn.blobFromImage(image, 1.0, (w,h),\n            (103.939, 116.779, 123.680), swapRB = False, crop = False)\n\n    net.setInput(blob)\n    output = net.forward()\n\n    output = output.reshape((3,output.shape[2],output.shape[3]))\n    output[0] += 103.939\n    output[1] += 116.779\n    output[2] += 123.680\n    \n    output = output.transpose(1,2,0)\n    output = np.clip(output, 0, 255)\n    output= output.astype('uint8')\n\n    return output ","872e8dd2":"path = '..\/input\/trained-model-for-fast-nst\/candy.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","0053e567":"path = '..\/input\/trained-model-for-fast-nst\/composition_vii.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","4ad5766e":"path = '..\/input\/trained-model-for-fast-nst\/feathers.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","c1369603":"path = '..\/input\/trained-model-for-fast-nst\/la_muse.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","1ce15b63":"path = '..\/input\/trained-model-for-fast-nst\/mosaic.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","b2a5e1e3":"path = '..\/input\/trained-model-for-fast-nst\/starry_night.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","4fe429b7":"path = '..\/input\/trained-model-for-fast-nst\/the_scream.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","4b50d730":"path = '..\/input\/trained-model-for-fast-nst\/the_wave.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","89caee1c":"path = '..\/input\/trained-model-for-fast-nst\/udnie.t7'\noutput = nst(path, image_path)\noutput = output[:,:,::-1]\nplt.imshow(output)","8d4e4992":"For more understanding follow the [tutorial](https:\/\/www.pyimagesearch.com\/2018\/08\/27\/neural-style-transfer-with-opencv\/) from PyImageSearch.","7f713ea4":"Neural style transfer is an optimisation technique used to take two images content image and style image  and transfer style from style image to content images which gives transformed output image.\n\nReference : [A Neural Algorithm of Artistic Style](https:\/\/arxiv.org\/abs\/1508.06576)\n\nAnd Fast Neural style tranfer is faster technique in comparison to above.\n\nReference : [ Perceptual Losses for Real-Time Style Transfer and Super- Resolution](https:\/\/cs.stanford.edu\/people\/jcjohns\/eccv16\/)","0afbbbc7":"## Fast neural style transfer"}}