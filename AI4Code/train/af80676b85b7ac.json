{"cell_type":{"83fdd050":"code","bd331678":"code","8c30f07c":"code","5737b83f":"code","38788267":"code","54b75a4c":"code","6ce5c882":"code","c5629501":"code","614b1230":"code","75685eb3":"code","88cb1d15":"code","70361957":"code","357163cc":"code","fe4cd8d6":"code","bf66c6ae":"code","d0e4d666":"code","ef0cc7fd":"code","640d9565":"code","4f4f69ad":"code","cb3faa6a":"code","8ec5a7d9":"code","361b2398":"code","d95e1e94":"code","497c797a":"code","b67d957c":"code","da803864":"code","39585929":"code","9108269d":"code","aacdd687":"code","296d3e48":"code","9d176501":"code","8712e9dd":"code","c5e28726":"code","615734c0":"code","718702e8":"code","44c89739":"code","d5a19715":"code","c34602be":"code","e3105b9a":"code","f7ef9e68":"code","8f6a68f1":"code","21e14293":"code","f920e376":"code","0e727166":"code","97cac45f":"code","7cc87eee":"code","113fee7c":"code","7b984f2b":"code","9b39540a":"code","a2380a08":"code","d5871656":"code","a29f0eac":"code","5dbcd941":"code","67064120":"code","36d597fa":"code","1caec014":"code","25ee0bb0":"code","36fea0bc":"code","9f63efd5":"markdown","7c6e67e8":"markdown","1c006958":"markdown","94eee823":"markdown","895997f6":"markdown","08aeecf3":"markdown","644c8100":"markdown","7694f150":"markdown","dd026b03":"markdown","bdd6520f":"markdown","62916c13":"markdown","60b8899e":"markdown","c00bc8c4":"markdown","ef52d081":"markdown","490a8b84":"markdown","fd394adb":"markdown","f7404180":"markdown","059ad8b3":"markdown","46ea15a4":"markdown","9633d7ed":"markdown","02f682ff":"markdown","47c6ce39":"markdown","1bc15e83":"markdown","a67e6c8d":"markdown","f363abb5":"markdown","52f93779":"markdown","e89dc2eb":"markdown","0cd4ac56":"markdown","ad7505ad":"markdown","86796d0f":"markdown","1c668aa1":"markdown","ebd0810d":"markdown","828967bc":"markdown","a5051539":"markdown","7068c2d0":"markdown"},"source":{"83fdd050":"# data preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# plot\nimport seaborn as sns \nsns.set_style('whitegrid') \n\nimport matplotlib.pyplot as plt \nplt.style.use('seaborn-white')\nfrom mpl_toolkits.mplot3d import Axes3D \n!pip install chart-studio\nimport chart_studio.plotly as py\nfrom plotly import __version__\n\nimport graphviz","bd331678":"# loading dataset\ndf = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","8c30f07c":"df.info()","5737b83f":"df.head(5)","38788267":"df.tail(5)","54b75a4c":"df.describe()","6ce5c882":"# renaming 'tenure' and 'gender'\ndf = df.rename(columns={'tenure': 'Tenure', 'gender': 'Gender'})\n\n# converting 'TotalCharges' to numerical data type\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce', downcast='float')\n\n# converting 'SeniorCitizen' to object data type\ndf['SeniorCitizen'] = df['SeniorCitizen'].astype(np.object)\n\n# check\ndf.info()","c5629501":"# Pie chart of churn\nchurn_rate = df.Churn.value_counts() \/ len(df.Churn)\nlabels = 'Non-Churn', 'Churn'\n\nfig, ax = plt.subplots()\nax.pie(churn_rate, labels=labels, autopct='%.f%%')  \nax.set_title('Churn vs Non Churn', fontsize=16)","614b1230":"# numerical features grouped by churn\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,5))\n    sns.distplot(df[df.Churn == 'No'][col],\n                 bins=10,\n                 color='orange',\n                 label='Non-Churn',\n                 kde=True)\n    sns.distplot(df[df.Churn == 'Yes'][col],\n                 bins=10,\n                 color='blue',\n                 label='Churn',\n                 kde=True)\n    plt.legend(labels)","75685eb3":"# check outliers\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.boxplot(df[col])","88cb1d15":"# distribution\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.kdeplot(df[col])","70361957":"# correlation between numerical features\nplt.figure(figsize=(10, 8))\nfeature_corr = df.corr()\nsns.heatmap(feature_corr, annot=True, cmap='coolwarm')","357163cc":"for col in ['Gender', 'SeniorCitizen', 'Partner', 'Dependents']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","fe4cd8d6":"for col in ['PhoneService', 'MultipleLines']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","bf66c6ae":"for col in ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n            'TechSupport','StreamingTV', 'StreamingMovies']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","d0e4d666":"for col in ['PaperlessBilling', 'PaymentMethod', 'Contract',]:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","ef0cc7fd":"# summarize duplicates\nsum(df.duplicated('customerID'))\n#df2 = df.drop_duplicates('customerID')","640d9565":"# remove customerID and PhoneService\ndf2 = df.drop(['customerID'], axis = 1)\ndf2.head(5)","4f4f69ad":"# Dummy Variables(One-Hot Encoding)\nGender = pd.get_dummies(df2['Gender'], prefix='Genger', drop_first=True)\nPartner = pd.get_dummies(df2['Partner'], prefix='Partner', drop_first=True)\nDependents = pd.get_dummies(df2['Dependents'], prefix='Dependents', drop_first=True)\nMultipleLines = pd.get_dummies(df2['MultipleLines'], prefix='MultipleLines', drop_first=True)\nInternetService = pd.get_dummies(df2['InternetService'], prefix='InternetService', drop_first=True)\nOnlineSecurity = pd.get_dummies(df2['OnlineSecurity'], prefix='OnlineSecurity', drop_first=True)\nOnlineBackup = pd.get_dummies(df2['OnlineBackup'], prefix='OnlineBackup', drop_first=True)\nDeviceProtection = pd.get_dummies(df2['DeviceProtection'], prefix='DeviceProtection', drop_first=True)\nTechSupport = pd.get_dummies(df2['TechSupport'], prefix='TechSupport', drop_first=True)\nStreamingTV = pd.get_dummies(df2['StreamingTV'], prefix='StreamingTV', drop_first=True)\nStreamingMovies = pd.get_dummies(df2['StreamingMovies'], prefix='StreamingMovies', drop_first=True)\nPaperlessBilling = pd.get_dummies(df2['PaperlessBilling'], prefix='PaperlessBilling', drop_first=True)\nPaymentMethod = pd.get_dummies(df2['PaymentMethod'], prefix='PaymentMethod', drop_first=True)\nChurn = pd.get_dummies(df2['Churn'], prefix='Churn', drop_first=True)\nPaymentMethod = pd.get_dummies(df2['PhoneService'], prefix='PhoneService', drop_first=True)\n\n\ndf3 = pd.concat([df2, Gender, Partner, Dependents, MultipleLines, InternetService, \n                 OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, \n                 StreamingMovies, PaperlessBilling, PaymentMethod, Churn], axis=1)","cb3faa6a":"# Label Encoding\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndf3['Contract']= label_encoder.fit_transform(df3['Contract']) ","8ec5a7d9":"# drop original columns\nlist = ['Gender', 'Partner', 'Dependents', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', \n'PaymentMethod', 'Churn', 'Contract', 'PhoneService']\ndf3.drop(df3[list], axis=1, inplace=True)\ndf3.head()","361b2398":"# train test split\nfrom sklearn.model_selection import train_test_split # split dataset\nX_train, X_test, y_train, y_test = train_test_split(df3.drop('Churn_Yes',axis=1),df3['Churn_Yes'],test_size=0.3,random_state=101)","d95e1e94":"#check\nfor i in [X_train, X_test, y_train, y_test]:\n    i.index = range(i.shape[0]) \n    print(i.index)","497c797a":"#summarize missing values - X_train\nX_train.isnull().sum()","b67d957c":"# fill missing value w\/ mean \nX_train['TotalCharges'].fillna(value=X_train['TotalCharges'].mean(), inplace=True)\n# check missing values\nX_train.isnull().sum()","da803864":"#summarize missing values - y_train\ny_train.isnull().sum()","39585929":"#summarize missing values - X_test\nX_test.isnull().sum()","9108269d":"# fill missing value w\/ mean \nX_test['TotalCharges'].fillna(value=X_test['TotalCharges'].mean(), inplace=True)\n# check missing values\nX_test.isnull().sum()","aacdd687":"#summarize missing values - y_test\ny_test.isnull().sum()","296d3e48":"y_train","9d176501":"# check outliers\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.boxplot(X_train[col])","8712e9dd":"## Standardization\nstandard_scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_standard = standard_scaler.transform(X_train)\nX_test_standard = standard_scaler.transform(X_test)\n\n#from sklearn.preprocessing import StandardScaler\n#scaler_s = StandardScaler() \n#data_standard_scaled = scaler_s.fit_transform(data)","c5e28726":"# Normalization\nminmax_scaler = preprocessing.MinMaxScaler().fit(X_train)\nX_train_minmax = minmax_scaler.transform(X_train)\nX_test_minmax = minmax_scaler.transform(X_test)\n\n#from sklearn.preprocessing import MinMaxScaler\n#scaler_m = MinMaxScaler() \n#data_normal_scaled = scaler_m.fit_transform(data)","615734c0":"# training \nfrom sklearn.linear_model import LogisticRegression\nlm = LogisticRegression(random_state=0, max_iter=1000, solver='lbfgs', class_weight='balanced')\nlm.fit(X_train_standard, y_train)","718702e8":"# predicting\ny_pred = lm.predict(X_test_standard)","44c89739":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","d5a19715":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","c34602be":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = lm.predict_proba(X_test_standard)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n#logis\nfrom astropy.table import Table\ndict1 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nlogis_matrix = Table(rows=dict1)\nprint(logis_matrix)","e3105b9a":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(lm, X_test_standard, y_test, ax = ax)","f7ef9e68":"# training and predicting\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train_minmax,y_train)\ny_pred = knn.predict(X_test_minmax)","8f6a68f1":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","21e14293":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","f920e376":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = knn.predict_proba(X_test_minmax)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict2 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nknn_matrix = Table(rows=dict2)\nprint(knn_matrix)","0e727166":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(knn, X_test_minmax, y_test, ax = ax)","97cac45f":"# training and predicting\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0, max_depth=5)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)","7cc87eee":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","113fee7c":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","7b984f2b":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = clf.predict_proba(X_test)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict3 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\ntree_matrix = Table(rows=dict3)\nprint(tree_matrix)","9b39540a":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(clf, X_test, y_test, ax = ax)","a2380a08":"from sklearn import tree\nfrom sklearn.tree import export_graphviz\ndot_data = tree.export_graphviz(clf, out_file=None, \n                                feature_names=X_train.columns,\n                                class_names='Churn_Yes',\n                                filled=True,\n                                max_depth=3)\n\ngraph = graphviz.Source(dot_data, format=\"png\") \n\ngraph","d5871656":"importances = clf.feature_importances_\nweights = pd.Series(importances,index=X_train.columns.values)\nweights.sort_values()[-10:].plot(kind = 'barh')","a29f0eac":"# training and predicting\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier()\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)","5dbcd941":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","67064120":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","36d597fa":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = forest.predict_proba(X_test)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict4 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nforest_matrix = Table(rows=dict4)\nprint(tree_matrix)","1caec014":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(forest, X_test, y_test, ax = ax)","25ee0bb0":"importances = forest.feature_importances_\nweights = pd.Series(importances,index=X_train.columns.values)\nweights.sort_values()[-10:].plot(kind = 'barh')","36fea0bc":"print('logistic regression')\nprint(logis_matrix)\nprint('knn')\nprint(knn_matrix)\nprint('decision tree')\nprint(tree_matrix)\nprint('random forest')\nprint(forest_matrix)","9f63efd5":"# VII. Conclusion","7c6e67e8":"### 3. About the Data\nThis dataset has 7,043 samples and 21 attributes(2 integer, 1 float, and 18 objects)\n* Target Feature: Churn\n* Numeric Features: Tenure, MonthlyCharges, and TotalCharges\n* Categorical Features: CustomerID, Gender, SeniorCitizen, Partner, Dependents, PhoneService, MulitpleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod","1c006958":"* From the summary table below, we may infer that the feature TotalCharges has some **missing values**.","94eee823":"(4) Phone Service: PhoneService is a **redundant feature** since we can get the same information from teh feature Multiple Lines. So, we could drop this column.\n\n(5) Multiple Lines: Customer who has multiple lines is slightly more likely to churn.","895997f6":"(6) Internet Service: If customer's Internet service provider is Fiber optic, then he\/she is more likely to churn.\n\n(7) Online Security: Customer who does not have online security is more likely to churn.\n\n(8) Online Backup: Customer who does not have online backup is more likely to churn.\n\n(9) Device Protection: Customer who does not have device protection is more likely to churn.\n\n(10) Tech Support: Customer who does not have tech support is more likely to churn.\n\n(11) Streaming TV \/ Streaming Movies: Streaming TV and Streaming Movies have no big effect on churn rate; however, if customer does not have internet service, then he\/she is less likely to churn.","08aeecf3":"(4) Outliers: The box plots show there is **no outliers** in this data set.","644c8100":"# I. Introduction\nNowadays, companies are increasingly aware of the importance of subscription services, and the churn rate is a critical indicator to track the health of a subscription-based company. To be more precise, the company can take measures in advance by predicting the customer churn rate to retain customers consistently. Therefore, this project goal is to make a churn prediction so that Telco can optimize products and services proactively.","7694f150":" ### 1. Importing Modules","dd026b03":"### 2. Loading Dataset","bdd6520f":"### 4. Splitting the Data into Training Set(70%) and Test Set(30%)\nWe split the data in 70:30 ratio so that 70% of the data will be used for training the model while 30% will be used for testing the model.","62916c13":"# IV. Exploratory Data Analysis(EDA)","60b8899e":"### 1. Removing Duplicates\nThere is no repeated value in this data set.","c00bc8c4":"### 2. Droping Unnecessary Columns\n\nRemove the useless feature customerID.","ef52d081":"(4) Skewness: The density plots show they are **not normal distributions**.","490a8b84":"### 3. Categorical Features\n\n(1) Gender: The churn rate is similar between male and female, indicating **Gender may not be a good predictor**.\n\n(2) Senior Citizen: Customer who is senior citizen is more likely to churn.\n\n(2) Partner: Customer who does not have partner is more likely to churn.\n\n(3) Dependents: Customer who does have dependents is more likely to churn.","fd394adb":"#### Data Transformation: Normalization (Min-Max Scalar) ","f7404180":"(6) Correlation: The correlation matrix plot shows that these numeric features have a positive relationship.","059ad8b3":"### 4. Data Reshaping\n* Rename the features 'tenure' and 'gender'\n* Convert the feature 'TotalCharges' to numerical data type\n* Converting the feature 'SeniorCitizen' to object data type","46ea15a4":"## 2. K Nearest Neighbors ","9633d7ed":"# II. Data Description\nThe raw data contains 7043 rows (customers) and 21 columns (features).\n* customer ID: Customer ID\n* gender: Whether the customer is a male or a female\n* SeniorCitizen: Whether the customer is a senior citizen or not (1, 0)\n* Partner: Whether the customer has a partner or not (Yes, No)\n* Dependents: Whether the customer has dependents or not (Yes, No)\n* tenure: Number of months the customer has stayed with the company\n* PhoneService: Whether the customer has a phone service or not (Yes, No)\n* MultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service)\n* InternetService: Customer\u2019s internet service provider (DSL, Fiber optic, No)\n* OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n* OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n* DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n* TechSupport: Whether the customer has tech support or not (Yes, No, No internet service)\n* StreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service)\n* StreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service)\n* Contract: The contract term of the customer (Month-to-month, One year, Two year)\n* PaperlessBilling: Whether the customer has paperless billing or not (Yes, No)\n* PaymentMethod: The customer\u2019s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n* MonthlyCharges: The amount charged to the customer monthly\n* TotalCharges: The total amount charged to the customer\n* Churn: Whether the customer churned or not (Yes or No)","02f682ff":"## 1. Logistic Regression ","47c6ce39":"## 4. Random Forest","1bc15e83":"### 6. Identifying Outliers\n\nThe training data set does not have outliers.","a67e6c8d":"### 5. Identifying Missing Values\n\nFor training set, the feature TotalCharges has **null\/missing values**, so we can impute the missing values and replace them with average.","f363abb5":"Since this is an imbalanced dataset, we decide to use weighted logistic regression.","52f93779":"## 3. Decision Tree","e89dc2eb":"### 3. Categorical Data Encoding\n\nEncode categorical variables, we use One-Hot Encoding for nominal variables and Label Encoding for ordinal variables.\n\n* One-Hot Encoding: Gender, Partner, Dependents, MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, PaperlessBilling, PaymentMethod, Churn\n\n* Label Encoding: Contract","0cd4ac56":"# VI. Model Building & Evaluation","ad7505ad":"### 7. Feature Scaling - Standardization \/ Normalization","86796d0f":"# V. Data Preprocessing","1c668aa1":"(12) Paper less Billing: Customer who has paperless billing is more likely to churn.\n\n(13) Payment Method: Customer who uses electronic check to pay bills is more likely to churn than those who using other payment methods.\n\n(14) Contract: The churn rate goes down as the length of contract increases.","ebd0810d":"### 2. Numeric Features\n(1) Tenure: Customer with less tenure is more likely to churn.\n\n(2) Monthly Charges: Customer with low monthly charges is less likely to churn; however, the churn trend between churn customers and non-churn customers gets similar as monthly charges go up.\n\n(3) Total Charges: The distribution is similar for both churn customers and non-churn customers, implying that the feature Monthly Charges may not be a good predictor.","828967bc":"### 1. Target Variable\n(1) Churn: Customer churn rate of Telco from this dataset is 27%, implying this is an ****imbalanced dataset****.","a5051539":"# III. Data Collection","7068c2d0":"Based on the performance metrics below, the best model is Logistic Regression with F1-score of 62% and auc score of 0.84."}}