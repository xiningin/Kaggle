{"cell_type":{"a154c772":"code","62883c5d":"code","e3a4f2a6":"code","603e909d":"code","e5a023df":"code","67654291":"code","78ca7cfc":"code","8bd797e7":"code","978c629c":"code","bb295276":"code","471c9c6b":"code","1b1d6e70":"code","4e7e71b6":"code","291b4ed0":"code","31cfeab7":"code","74811462":"code","48b0e9fd":"code","51ff6989":"code","8ffd5a22":"code","0b8b936a":"code","a916e9fc":"code","23302668":"markdown","f30e7809":"markdown","1ee4ae1b":"markdown","7c109506":"markdown","6f54ff2e":"markdown","6abc9c8f":"markdown","b9930f4c":"markdown","1f771222":"markdown","22ff82e2":"markdown","4f648284":"markdown","19522146":"markdown","325b0949":"markdown","178a871e":"markdown","b93512ce":"markdown","5bb4adc8":"markdown","6161998d":"markdown","c4cb2631":"markdown","acfb2243":"markdown"},"source":{"a154c772":"!pip install feyn","62883c5d":"import feyn\nimport pandas as pd\nimport sklearn.model_selection","e3a4f2a6":"data = '\/kaggle\/input\/mushroom-classification\/mushrooms.csv'\ndf = pd.read_csv(data)\ndf","603e909d":"df.isna().sum()","e5a023df":"df.drop('veil-type', axis=1, inplace=True)","67654291":"df[\"class\"]=df[\"class\"].replace({\"p\":True, \"e\":False}).astype(bool)","78ca7cfc":"df","8bd797e7":"train, test = sklearn.model_selection.train_test_split(df, stratify=df[\"class\"], train_size=.66, random_state=1)\ntest, holdout = sklearn.model_selection.train_test_split(test, stratify=test[\"class\"], test_size=.5, random_state=1)","978c629c":"stypes = {}\n\nfor col in train.columns:\n    if train[col].dtype == 'O':\n        stypes[col] = 'c'\n        \nstypes[\"class\"] = 'b'","bb295276":"stypes","471c9c6b":"ql = feyn.connect_qlattice()","1b1d6e70":"ql.reset(random_seed=1)","4e7e71b6":"models = ql.auto_run(train, output_name=\"class\", kind=\"classification\", stypes=stypes, criterion=\"bic\", max_complexity=5)","291b4ed0":"models[0].plot(train,test)","31cfeab7":"from feyn.plots.interactive import interactive_activation_flow","74811462":"interactive_activation_flow(models[0], train)","48b0e9fd":"models[0].plot_probability_scores(test)","51ff6989":"models[0].plot_confusion_matrix(test)","8ffd5a22":"predictions = models[0].predict(holdout)","0b8b936a":"predictions","a916e9fc":"holdout[\"class\"]","23302668":"We can see that the model does a pretty good job. Most often, it correctly assigns high probability scores to poisonous mushrooms and low ones to edible mushrooms.\n\nThe fact that we see most of our predictions at low or high probability scores is great! **Most of our predictions are not ambiguous**. Our model will most likely strongly suggest that a mushroom is poisonous, or strongly suggest that it is not. \n\n# Confusion Matrices: when the model fails\nIt is important to note the small sliver of pink that we see in the left-most part of the plot at around 0.1-0.2. These are poisonous mushrooms that the model does not predict as such.\n\nWe can visualize this better using a **confusion matrix**\n\nThe confusion matrix shows four mushrooms that are predicted as edible, but are not. Without setting the threshold, it automatically uses 0.5 (in other words, everything that has a probability score of 0.5 or higher is considered as predicted to be poisonous). We see a small sliver of pink at 0.8-0.9. These mushrooms scored a 0.8-0.9 probability of being dangerous and are still considered as being predicted as poisonous: a correct, albiet less confident, classification","f30e7809":"# Getting the Data\nFirst let's load the dataset and take a look","1ee4ae1b":"This gives us an array of values between 0 and 1 telling us the probability that the given mushroom is poisonous. Just by looking at the first few entries and comparing them to the true toxicity of the mushroom, we can see that our model gives a pretty good indication of whether or no the mushroom is safe (e.g. for the first mushroom our model says that there is a 2.66% chance that the mushroom is poisonous, and it is, in fact, edible)","7c109506":"# Understanding our model\nWe can see how each feature contributes to the model using plot_flow_interactive ","6f54ff2e":"# Looking at probablity scores\nAnother way to visualize how the model is performing on it's predictions is by using a probability score plot. This shows the histogram of probabilities assigned by the model that the edible (negative class) mushrooms and poisonous (positive class) mushrooms are poisonous.","6abc9c8f":"# What did we find?\n`models` is a list of graphs sorted by accuracy. Each model shows how the selected features, or inputs, interact to achieve the output. We can access the best graph and see how it performs on the train and test sets by calling:","b9930f4c":"Let's change our target column, `class`, to boolean","1f771222":"# First impressions:\nWe notice that:\n- The target variable is `class`, and can be represented as a boolean\n- All data types are categorical. The QLattice works with both categorical and numerical data, but needs to be told which entries are categorical (i.e. it assumes they are numerical)\n- There are no missing entries\n\nSince all entries are the same, we'll remove the `veil-type` column","22ff82e2":"# Setting data types\nAs mentioned earlier, the QLattice needs to be told which entries are categorical. We accomplish this by running through the dataframe and recording which columns contain object types. This is recorded in the dictionary `stypes` and passed to the QLattice to indicated that these features should be treated as categorical. ","4f648284":"# Search for the best model\nWe are now ready to instruct the QLattice to search for the best mathematical model to explain the data. Here we use the high-level convenience function that does everything with sensible defaults: https:\/\/docs.abzu.ai\/docs\/guides\/essentials\/auto_run.html.\n\u200b\nFor more detailed control, we could use the primitives: https:\/\/docs.abzu.ai\/docs\/guides\/primitives\/using_primitives.html\n\u200b\nNOTE: This will take a minute to complete. It invoves work done on the QLattice machine remotely as well as in the local notebook. The part that runs locally is slowing things down because of the limited CPU resources on Kaggle. Running the same on my machine locally only takes 10 seconds!","19522146":"# A useful model\nImagine you're our in nature and you come across some delicious looking mushrooms. Wonder if these tasty looking treats are edible? We can note some quick observations of it's odor, spore print color, and it's color below the stalk, then use our model to predict whether or not it is poisonous.\n\nWe will simulate this using our holdout set and the **predict function**","325b0949":"# Using the QLattice to understand mushroom toxicity \nThe QLattice is a supervised machine learning tool for symbolic regression developed by [Abzu](https:\/\/www.abzu.ai) . It is inspired by Richard Feynman's path integral formulation. That's why the python module to use it is called *Feyn*, and the *Q* in QLattice is for Quantum.\n\nAbzu provides free QLattices for non-commercial use to anyone. These free community QLattices gets allocated for you automatically if you use Feyn without an active subscription, as we will do in this notebook. Read more about how it works here: https:\/\/docs.abzu.ai\/docs\/guides\/getting_started\/community.html\n\nThe feyn Python module is not installed on Kaggle by default so we have to pip install it first. \n\n__Note__: the pip install will fail unless you enable *Internet* in the *settings* to the right--->","178a871e":"# Resetting and reproducability\nThe QLattice has the potential to store learnings between sessions to enable transfer of learning and federated learning. This is not possible with Community QLattices, since a new one gets allocated whenever we run the notebook, so it is not strictly necessary to call the reset function on our new QLattice.\n\nBut the reset function also allows us to provide a random seed, which will ensure that we get the same results every time we run this notebook","b93512ce":"# Splitting the data\nLet's split the data into train, test, and validation sets. We will stratify by `class` and take 2\/3 of the entire dataset for training. We also create a holdout set to represent how our model could perform in the real world. More on this later","5bb4adc8":"# What did we learn?\n1. We can predict toxicity with **only three features** very well! \n2. The QLattice is extremely **easy to use**. Admittedly, other machine learning algorithms can also acheive this high accuracy, however, the QLattice requires no onehot encoding\n3. With QLattice models we can clearly see **how** the features interact to predict the target and feyn includes some cool plots and tools to visualize this\n4. Our model has useful applications","6161998d":"# Python imports\nIn this notebook we will only use three python modules: the `feyn` module to access the QLattice, the `pandas` module to access the data, and `sklearn` to split the data into train and test sets","c4cb2631":"Look at that performance!! With only three features: odor, spore print color, and stalk color below ring we can predict if a given mushroom is edible or poisonous with incredible accuracy. What's more, we can also see specifically **how** each feature interacts with one another to predict toxicity.","acfb2243":"# Allocate a QLattice\nThe actual QLattice is a quantum simulator that runs on Abzu's hardware, but we can allocate one with a single line of code. Cool, huh?"}}