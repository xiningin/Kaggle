{"cell_type":{"373284d8":"code","a1cd5bf0":"code","10762bc0":"code","f6970421":"code","fdb9ab9c":"code","30b11cdb":"code","c4ec4489":"code","326ac45d":"code","d334490a":"code","d005763a":"code","fd67421c":"code","345ada2c":"code","198c41f4":"markdown","79e246d3":"markdown"},"source":{"373284d8":"# Importing modules \nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\nfrom keras.models import Sequential\n\nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(1)","a1cd5bf0":"# Processing training data\n# -> appending images in a list 'train_images'\n# -> appending labels in a list 'train_labels'\n\ntrain_images = []       \ntrain_labels = []\nshape = (200,200)  \ntrain_path = '..\/input\/fruit-images-for-object-detection\/train_zip\/train'\n\nfor filename in os.listdir('..\/input\/fruit-images-for-object-detection\/train_zip\/train'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(train_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        train_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        train_images.append(img)\n\n# Converting labels into One Hot encoded sparse matrix\ntrain_labels = pd.get_dummies(train_labels).values\n\n# Converting train_images to array\ntrain_images = np.array(train_images)\n\n# Splitting Training data into train and validation dataset\nx_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)","10762bc0":"# Processing testing data\n# -> appending images in a list 'test_images'\n# -> appending labels in a list 'test_labels'\n# The test data contains labels as well also we are appending it to a list but we are'nt going to use it while training.\n\ntest_images = []\ntest_labels = []\nshape = (200,200)\ntest_path = '..\/input\/fruit-images-for-object-detection\/test_zip\/test'\n\nfor filename in os.listdir('..\/input\/fruit-images-for-object-detection\/test_zip\/test'):\n    if filename.split('.')[1] == 'jpg':\n        img = cv2.imread(os.path.join(test_path,filename))\n        \n        # Spliting file names and storing the labels for image in list\n        test_labels.append(filename.split('_')[0])\n        \n        # Resize all images to a specific shape\n        img = cv2.resize(img,shape)\n        \n        test_images.append(img)\n        \n# Converting test_images to array\ntest_images = np.array(test_images)","f6970421":"# Visualizing Training data\nprint(train_labels[0])\nplt.imshow(train_images[0])","fdb9ab9c":"# Visualizing Training data\nprint(train_labels[4])\nplt.imshow(train_images[4])","30b11cdb":"# Creating a Sequential model\nmodel= Sequential()\nmodel.add(Conv2D(kernel_size=(3,3), filters=32, activation='tanh', input_shape=(200,200,3,)))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dense(15,activation='relu'))\nmodel.add(Dense(4,activation = 'softmax'))\n    \nmodel.compile(\n              loss='categorical_crossentropy', \n              metrics=['acc'],\n              optimizer='adam'\n             )","c4ec4489":"# Model Summary\nmodel.summary()","326ac45d":"# Training the model\nhistory = model.fit(x_train,y_train,epochs=50,batch_size=50,validation_data=(x_val,y_val))","d334490a":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d005763a":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","fd67421c":"# Evaluating model on validation data\nevaluate = model.evaluate(x_val,y_val)\nprint(evaluate)","345ada2c":"# Testing predictions and the actual label\ncheckImage = test_images[0:1]\nchecklabel = test_labels[0:1]\n\npredict = model.predict(np.array(checkImage))\n\noutput = { 0:'apple',1:'banana',2:'mixed',3:'orange'}\n\nprint(\"Actual :- \",checklabel)\nprint(\"Predicted :- \",output[np.argmax(predict)])","198c41f4":"### Context\n- A different dataset for object detection.\n- 240 images in train folder\n- 60 images in test folder.\n\n### Content\n- 3 different fruits:\n\n     a. Apple\n\n     b. Banana\n\n     c. Orange","79e246d3":"## Fruit Images for Object Detection\n### Containing labelled fruit images to train object detection systems."}}