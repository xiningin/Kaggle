{"cell_type":{"68219f59":"code","eb46948c":"code","bc83bb3e":"code","1fdc02bd":"code","5f8e6b52":"code","e7c32a69":"code","983609c8":"code","5bf56e06":"code","e50684b1":"code","b1a7b9c4":"code","5df64a86":"code","39262890":"code","da587ee8":"code","a9150eed":"code","dadd85e7":"code","8cde61d6":"code","2dd0335e":"code","289aaba6":"code","2899265d":"code","5653d176":"code","05eed748":"code","82cfbe5d":"code","0c606013":"code","2dc4e600":"code","c3736570":"code","6840ce7c":"code","f0d93602":"code","5e454dda":"code","62bc3888":"code","f75d7cd8":"code","1bea65d8":"code","62c09f8c":"code","6488e105":"code","ccc261df":"code","ae07ee60":"code","16d93cea":"code","0653c5d4":"code","3ba67b37":"code","cbab71a8":"code","9256a335":"code","040331b1":"code","ff959215":"code","a13e4e23":"code","c2f39f2a":"code","3555c48f":"code","03830344":"code","d1cf1dbd":"code","cc0a5e10":"code","e26aabe7":"code","5109c7ee":"code","5b27f294":"code","e7394172":"code","2fdc1d45":"code","9b85aced":"code","c65f95af":"code","04515737":"code","47e8a3d4":"code","1abc6c36":"code","4dcbc39a":"code","39f857cb":"code","6ce0733e":"code","3f8dd36f":"code","6e4fa3d1":"code","19bf39e9":"code","897e9ebc":"code","ec8fc017":"markdown","087f80e2":"markdown","648bb03c":"markdown","63144a11":"markdown","35e9345a":"markdown","94c0821e":"markdown","87314c9e":"markdown","a350aeb6":"markdown","12be7d4f":"markdown","5c9afaa9":"markdown","40b76cc4":"markdown","f0f065e1":"markdown","88dfc5ca":"markdown","ac79ff06":"markdown","bd89c19a":"markdown","0b9b200e":"markdown","8841d21f":"markdown","19132f0b":"markdown","59210dc1":"markdown","d1060f06":"markdown","d3050415":"markdown"},"source":{"68219f59":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')","eb46948c":"data = pd.read_csv(\"\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv\")","bc83bb3e":"data.head()","1fdc02bd":"# drop unnecessary columns\n\ndata = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)","5f8e6b52":"data.head()","e7c32a69":"data.info()","983609c8":"# transform vairbales in right format\n\nfor col in ['NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited']:\n    data[col] = data[col].astype('category')","5bf56e06":"data.info()","e50684b1":"data.describe().T","b1a7b9c4":"plt.figure(figsize=(12,5))\n\nsns.distplot(data['EstimatedSalary'],kde = False)","5df64a86":"plt.figure(figsize=(12,5))\n\nsns.distplot(data['CreditScore'],kde = False)","39262890":"plt.figure(figsize=(12,5))\n\nsns.distplot(data[(data['CreditScore'] <=840) & (data['CreditScore'] >=450)]['CreditScore'],kde = False)","da587ee8":"data = data[(data['CreditScore'] <=840) & (data['CreditScore'] >=450)]","a9150eed":"plt.figure(figsize=(12,5))\n\nsns.distplot(data['Balance'],kde = False)","dadd85e7":"balance = [0 if i == 0 else 1 for i in data['Balance']]","8cde61d6":"pd.Series(balance).value_counts()\/len(data)*100","2dd0335e":"# add the new binary variable and drop the original \n\ndata['has_balance'] = pd.Series(balance)\ndata = data.drop('Balance', axis = 1)","289aaba6":"data['Geography'].value_counts()\/len(data)*100","2899265d":"data['NumOfProducts'].value_counts()","5653d176":"data['more_than1product'] = pd.Series([0 if i == 1 else 1 for i in data['NumOfProducts']])\ndata = data.drop('NumOfProducts', axis=1)","05eed748":"data['more_than1product'].value_counts()","82cfbe5d":"data.head()","0c606013":"data['IsActiveMember'].value_counts()","2dc4e600":"data['HasCrCard'].value_counts()","c3736570":"data['Tenure'].value_counts()","6840ce7c":"data['Gender'].value_counts()","f0d93602":"data.head()","5e454dda":"data.info()","62bc3888":"data['has_balance'] = pd.Categorical(data['has_balance'])\ndata['more_than1product'] = pd.Categorical(data['more_than1product'])","f75d7cd8":"sns.heatmap(data.corr(), annot=True)","1bea65d8":"len(data)","62c09f8c":"backup = data.copy()","6488e105":"data = backup","ccc261df":"data['Exited'].value_counts()","ae07ee60":"from sklearn.utils import resample\n\n# # Separate majority and minority classes\n# df_majority = data[data.Exited==0]\n# df_minority = data[data.Exited==1]\n#  \n# # Upsample minority class\n# df_minority_upsampled = resample(df_minority, \n#                                  replace=True,     # sample with replacement\n#                                  n_samples=7600,    # to match majority class\n#                                  random_state=404) # reproducible results\n#  \n# # Combine majority class with upsampled minority class\n# df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n#  \n# # Display new class counts\n# df_upsampled.Exited.value_counts()","16d93cea":"len(data)","0653c5d4":"data.head()","3ba67b37":"data.columns","cbab71a8":"data.info()","9256a335":"from numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten, Dropout\n\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom scipy.stats import zscore","040331b1":"def encode_columns(column, data):\n    \n    data = pd.concat([data,pd.get_dummies(data[column],prefix=column)],axis=1)\n    data.drop(column, axis=1, inplace=True)\n    \n    return data","ff959215":"data.columns","a13e4e23":"### ------------- encode categorical columns ----------------\n\ncategorical_columns = ['Geography',\n                       'Gender',\n                       'HasCrCard',\n                       'IsActiveMember',\n                       'has_balance',\n                       'more_than1product']\n    \nfor col in categorical_columns:\n    data=encode_columns(col,data)","c2f39f2a":"data.info()","3555c48f":"data['CreditScore'] = zscore(data['CreditScore'])\ndata['Age'] = zscore(data['Age'])\ndata['Tenure'] = zscore(data['Tenure'])\ndata['EstimatedSalary'] = zscore(data['EstimatedSalary'])","03830344":"x = data.drop('Exited', axis=1)\ny = data['Exited']","d1cf1dbd":"x = np.asarray(x)\ny = np.asarray(y)","cc0a5e10":"from tensorflow.keras.callbacks import EarlyStopping","e26aabe7":"# Split into train\/test\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=x.shape[1], activation='relu', kernel_initializer='random_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(25,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\n\n\n# compile the model\n#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, \n                        verbose=1, mode='min', restore_best_weights=True)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nprint(model.summary())","5109c7ee":"history = model.fit(X_train, y_train, validation_split=0.2, callbacks=[monitor], verbose=1, epochs=1000)\n\nloss, accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint('Accuracy: %f' % (accuracy*100))\nprint('\\n')","5b27f294":"plt.rcParams[\"figure.figsize\"] = (11,5)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model train vs validation loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","e7394172":"from sklearn.metrics import roc_curve, auc\n\n\n# Plot an ROC. pred - the predictions, y - the expected output.\ndef plot_roc(pred,y):\n    fpr, tpr, _ = roc_curve(y, pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(7,7))\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC)')\n    plt.legend(loc=\"lower right\")\n    plt.show()","2fdc1d45":"prediction_proba = model.predict(X_test)","9b85aced":"plot_roc(prediction_proba,y_test)","c65f95af":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import cross_validate, StratifiedKFold, KFold","04515737":"randf = RandomForestClassifier(class_weight={0: 0.60, 1:0.4}, random_state=22, criterion=\"entropy\")\n\nrandf.fit(X_train, y_train)\n\nrandf_prediction=randf.predict(X_test)\n\naccuracy_score(y_pred = randf_prediction, y_true= y_test)","47e8a3d4":"from sklearn.metrics import  plot_roc_curve\nplot_roc_curve(randf, X_test, y_test)\nplt.title(\"ROC for RF\")\nplt.show()","1abc6c36":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix","4dcbc39a":"dtree = DecisionTreeClassifier(class_weight={0: 0.60, 1:0.4},random_state=22, criterion='entropy')\ndtree.fit(X_train,y_train)","39f857cb":"tree_predictions = dtree.predict(X_test)","6ce0733e":"print(classification_report(y_test,tree_predictions))","3f8dd36f":"pipe_randf=make_pipeline(StandardScaler(), randf)","6e4fa3d1":"pipe_dtree = make_pipeline(StandardScaler(), \n                           dtree)","19bf39e9":"CV_dtree=cross_validate(pipe_dtree,X_train,y_train,scoring=[\"accuracy\",\"recall\",\"precision\"],\n                      cv=StratifiedKFold(n_splits=5))","897e9ebc":"print(\"The mean accuracy in the Cross-Validation is: {:.2f}%\".format((np.mean(CV_dtree[\"test_accuracy\"])*100)))","ec8fc017":"## Target variable","087f80e2":"Somewhat balanced, I leave it like this","648bb03c":"### Country","63144a11":"### Has Credit Card","35e9345a":"### Tenure","94c0821e":"### Salary","87314c9e":"## Other models","a350aeb6":"## Neural Network","12be7d4f":"Up or downsampling did not improve the results","5c9afaa9":"### Active Member","40b76cc4":"Creating binary variable --> balance = 0 or balance > 0","f0f065e1":"### Credit Score","88dfc5ca":"Slight outliers with a credit score of zero and above 800.\n\nI cut them out of the data to have a somewhat normal distribution.","ac79ff06":"very unbalanced target variable --> over or undersampling recommended","bd89c19a":"Uniform distribution, no outliers","0b9b200e":"Create new variable and drop original one","8841d21f":"### Gender","19132f0b":"Slightly unbalanced","59210dc1":"### Balance","d1060f06":"## Exploration","d3050415":"### Number of products"}}