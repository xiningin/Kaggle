{"cell_type":{"15942edf":"code","10e4b54c":"code","15725527":"code","e88c2615":"code","283f8b01":"code","ade90f5a":"code","ea78aed9":"code","c08c5567":"code","333e3b3f":"code","c26db6ce":"code","7d0f7c32":"code","0e27d8be":"code","6cc4f6a7":"code","abe4eca8":"code","5f449a15":"code","ae8a29f2":"code","5fbfeba3":"code","42d92c97":"code","5d666ff4":"code","29aa3722":"code","aa087358":"code","072c1f0b":"code","744fbd7e":"code","6b75809f":"code","f2ef6ce2":"code","ec176cd0":"code","bd0da0f5":"code","3f274790":"code","40ba3a46":"code","2bdce9a8":"code","726c2235":"markdown","f9cb443a":"markdown","61897519":"markdown","3bfc8f47":"markdown","6c6b7a29":"markdown","f08d9a32":"markdown","d5b920e7":"markdown","15363b94":"markdown","9ce7e93a":"markdown","7ef8d670":"markdown","a486e9bf":"markdown","db3cc612":"markdown","b0eac23e":"markdown","03d1e9ef":"markdown","085eb00d":"markdown","3f3c4e58":"markdown","10435a2d":"markdown"},"source":{"15942edf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10e4b54c":"import tensorflow as tf","15725527":"data = pd.read_csv(\"\/kaggle\/input\/predicting-churn-for-bank-customers\/Churn_Modelling.csv\")\ndata.head()","e88c2615":"# RowNumber,CustomerId and Surname are not value adding attributes when determining if a particular customer is going to stay in the bank or going to leave the bank. We can remove this two columns from our dependant data set.\nX = data.iloc[:,3:-1].values\nY = data.iloc[:,-1].values\n# 2D arrays of both X & Y created","283f8b01":"print(X)","ade90f5a":"print(Y)","ea78aed9":"data.describe()\n# There are no missing values in the data set.","c08c5567":"#Encoding the Gender column using Label Encoder\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n#Gender column is the second column in the data set.\n#X[:,2] means select all the rows and select second column the X data set.\nX[:,2] = label.fit_transform(X[:,2])","333e3b3f":"print(X)","c26db6ce":"# One Hot encoding the Geography column\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n# The columns created via one hot encoding needs to be transformed in 2d array.","7d0f7c32":"print(X)\n#Post One Hot encoding, the geography column has not moved to the first column of the data set.","0e27d8be":"from sklearn.model_selection import train_test_split","6cc4f6a7":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)","abe4eca8":"X_train.shape,X_test.shape,Y_train.shape,Y_test.shape","5f449a15":"# We shall pe using Standardization for feature scaling\nfrom sklearn.preprocessing import StandardScaler","ae8a29f2":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n# We need to standardize the test data using the same scaler with which we standardized the training data","5fbfeba3":"ann_variable = tf.keras.models.Sequential()","42d92c97":"ann_variable.add(tf.keras.layers.Dense(units=8,activation='relu'))\n#units tell the number of neurons to be used in the hidden layer\n#relu determines the rectifier threshold activation function used in the ANN","5d666ff4":"ann_variable.add(tf.keras.layers.Dense(units=8,activation='relu'))","29aa3722":"ann_variable.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n#The output layer is going to contain 1 neuron in our current case. Hence units is 1\n#Acitvation function is sigmoid as the objective of the output layer is to have binary output","aa087358":"ann_variable.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n#optimizer updates the weights. adam represents the stochastic gradient method.\n#loss calculated the difference b\/w actual and predictd values.","072c1f0b":"ann_variable.fit(X_train,Y_train,batch_size=32,epochs=200)","744fbd7e":"Y_pred = ann_variable.predict(X_test)","6b75809f":"Y_pred","f2ef6ce2":"#Transforming the predicted data into binary representation","ec176cd0":"Y_pred = (Y_pred > 0.5)","bd0da0f5":"Y_pred","3f274790":"from sklearn.metrics import confusion_matrix,accuracy_score","40ba3a46":"confusion_matrix(Y_pred,Y_test)","2bdce9a8":"accuracy_score(Y_pred,Y_test)","726c2235":"## Adding the Output Layer","f9cb443a":"## Feature Scaling","61897519":"## Building the ANN","3bfc8f47":"# Data Preprocessing","6c6b7a29":"# Taking care of missing data set","f08d9a32":"## Accuracy score of 85.30% achieved using ANN model.","d5b920e7":"## Splitting the data set into testing and training data set","15363b94":"# Building Artificial Neural Network","9ce7e93a":"# Training the ANN model","7ef8d670":"# Importing the libraries","a486e9bf":"# Predicting the results","db3cc612":"## Adding the input and hidden layer","b0eac23e":"# Determining the Accuracy of the model","03d1e9ef":"## Addition of another hidden layer","085eb00d":"## Dividing the data into dependant and independant sets","3f3c4e58":"## Reading the data set","10435a2d":"## Encoding the categorical variables in X data set"}}