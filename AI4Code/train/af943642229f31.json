{"cell_type":{"da632c2d":"code","d8093d84":"code","94c5e839":"code","4a1c96a0":"code","b4280009":"code","0225b456":"code","9ee173a4":"code","745e239b":"code","188d21d3":"code","65063473":"code","2ef3d746":"code","fab1e9b0":"code","d3b01da8":"code","f2a8f60e":"code","435b6f38":"code","5a5a1caf":"code","794c9ac4":"code","ea4fc04e":"code","f8608b33":"code","e23cf4ef":"code","c704935b":"code","62e53872":"code","803562f3":"code","53707f1f":"code","3312562a":"code","70dbf792":"code","7cedc7e8":"code","3fed4d96":"code","738dadd3":"code","14d46967":"code","0d5b8653":"code","3c4c56ba":"code","16970584":"code","0da219f7":"code","8a7e2ef9":"code","63fe2c3f":"code","599b7756":"code","3ed80a23":"code","6c130213":"code","a0dbec53":"code","0270c260":"code","2e8413ff":"code","ad0d3c51":"code","0b8e7032":"code","8f376847":"code","fc30a878":"code","9ac5e864":"code","7beff58c":"code","f0eecdc8":"code","fea4ec47":"code","40a4be35":"code","77fdb73b":"code","e74b4663":"code","b81b36f8":"code","c32ef159":"code","f7203b54":"code","17c766f6":"code","71ed9e1f":"code","354dfe2b":"code","61a611b7":"code","d9fc46f3":"code","10488d43":"code","b76e0169":"code","dacaa5f3":"code","6ca79d22":"markdown","ff76afbf":"markdown","aa6c23c9":"markdown","aa0cffe4":"markdown","f1d1d7f6":"markdown","3dc7ed87":"markdown","69fb1149":"markdown","323d7bbf":"markdown","69a6586a":"markdown","c9c95a65":"markdown","91bd8c4b":"markdown","6af70c2e":"markdown","7376cd4e":"markdown","f5de4387":"markdown","32ec9f00":"markdown","28bc86de":"markdown","4e34d98a":"markdown","d3a7c360":"markdown","21738531":"markdown","1a3f1ff0":"markdown","eae5b3fa":"markdown","97cbfef8":"markdown","b75bfbc5":"markdown","bc89786c":"markdown","589b34c8":"markdown","d4d1d4fb":"markdown","27e1b2d2":"markdown","aa637546":"markdown","715dee99":"markdown","10bbe0cd":"markdown","153dad0a":"markdown","da63bf13":"markdown","bea0f9d7":"markdown","618c51bf":"markdown","f484d45e":"markdown","45f48479":"markdown","d82f36f9":"markdown","f47af2e8":"markdown","0a7fb0f8":"markdown","04c78f0e":"markdown","253594d2":"markdown","7660557e":"markdown","2211338c":"markdown","02ba268d":"markdown","a393c126":"markdown"},"source":{"da632c2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport matplotlib.cm\nfrom matplotlib import gridspec\nimport matplotlib as mpl\nimport seaborn as sns\n \nfrom mpl_toolkits.basemap import Basemap\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.colors import Normalize\n\nmpl.rcParams['axes.labelsize'] = 15\nmpl.rcParams['xtick.labelsize'] = 15\nmpl.rcParams['ytick.labelsize'] = 15\nmpl.rcParams['axes.titlesize'] = 15\nmpl.rcParams['figure.titlesize'] = 18\nmpl.rcParams['legend.fontsize'] = 14\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d8093d84":"\"\"\"OK, so in the second version of this notebook I have cleaned my act up and added some more structure to my take on the Dutch electricity landscape. While later versions might include gas as well, I think it is interesting to start out with electricity as there are a number of interesting dynamics transforming this landscape at the moment. Many thanks to Luca Basanisi for putting together this dataset, because most of us dealing with large datasets know that getting the data into the right format is one of the most time-consuming steps towards making sense out of the information at hand.  \"\"\"","94c5e839":"def load_and_reindex(path,filelist):\n    start_time = datetime.now()\n    df = None\n    for file in filelist:\n        year = file[-8:-4]\n        manager = file.split('_')[0]\n        if df is None:\n            df = pd.read_csv(path+file)\n            df['year'] = year\n            df.index = manager+'_'+year+'_'+df.index.astype(str)\n        else:\n            temp = pd.read_csv(path+file)\n            temp['year'] = year\n            temp.index = manager+'_'+year+'_'+temp.index.astype(str)\n            df = df.append(temp)\n    # adding columns of interest\n    df['low_tarif_consumption'] = df['annual_consume'].multiply(df['annual_consume_lowtarif_perc']\/100)\n    df['num_active_connections'] = df['num_connections'].multiply(df['perc_of_active_connections']\/100).astype(int)\n    try:\n        df['num_smartmeters'] = df['num_connections'].multiply(df['smartmeter_perc']\/100).astype(int)\n    except ValueError:\n        df['num_smartmeters'] = df['num_connections'].multiply(df['smartmeter_perc']\/100)\n        #print('Number of smartmeters could not be calculated')\n    df['net_annual_consumption'] = df['annual_consume'].multiply(df['delivery_perc']\/100)\n    df['self_production'] = df['annual_consume'] - df['net_annual_consumption']\n    df['self_prod_perc'] = df['self_production'].divide(df['annual_consume']\/100)\n    \n    time_elapsed = datetime.now() - start_time\n    print('Made main dataframe, time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n    return(df)","4a1c96a0":"path = '..\/input\/dutch-energy\/dutch-energy\/Electricity\/'\nfiles_all = [f for f in os.listdir(path)]\nelec_all = load_and_reindex(path,files_all)","b4280009":"# make pivot tables of relevant parameter such that we have total per city per year\nannual_consume = pd.pivot_table(elec_all,values='annual_consume',index='city',columns='year',aggfunc=np.sum)\nnum_connections = pd.pivot_table(elec_all,values='num_connections',index='city',columns='year',aggfunc=np.sum)\nnum_active_connections = pd.pivot_table(elec_all,values='num_active_connections',index='city',columns='year',aggfunc=np.sum)\nperc_active_connections = pd.pivot_table(elec_all,values='perc_of_active_connections',index='city',columns='year',aggfunc=np.mean)\nsmartmeter_perc = pd.pivot_table(elec_all,values='smartmeter_perc',index='city',columns='year',aggfunc=np.mean)\nsmartmeter_perc_median = pd.pivot_table(elec_all,values='smartmeter_perc',index='city',columns='year',aggfunc=np.median)\nnum_smartmeters = pd.pivot_table(elec_all,values='num_smartmeters',index='city',columns='year',aggfunc=np.sum)\nself_production = pd.pivot_table(elec_all,values='self_production',index='city',columns='year',aggfunc=np.sum)\nself_prod_perc_mean = pd.pivot_table(elec_all,values='self_prod_perc',index='city',columns='year',aggfunc=np.mean)\nnet_annu_consume = pd.pivot_table(elec_all,values='net_annual_consumption',index='city',columns='year',aggfunc=np.sum)\nannu_cons_lowtarif_perc = pd.pivot_table(elec_all,values='annual_consume_lowtarif_perc',index='city',columns='year',aggfunc=np.mean)","0225b456":"#print(annual_consume.sort_values('2018',ascending=False).head())\nspecs = {'markersize':20,'markerfacecolor':'w','linewidth':2}\nplt.plot(annual_consume.columns.astype(int)-1,annual_consume.sum(),'-o',**specs)\n#plt.yscale('log')\nplt.ylabel('Energy consumption (kWh)')\nplt.xlabel('Year')\nplt.title('Total yearly energy consumption')","9ee173a4":"annual_consume.drop('2009',axis=1,inplace=True)\nnum_connections.drop('2009',axis=1,inplace=True)\nsmartmeter_perc.drop('2009',axis=1,inplace=True)\nnum_smartmeters.drop('2009',axis=1,inplace=True)\nself_production.drop('2009',axis=1,inplace=True)\nnet_annu_consume.drop('2009',axis=1,inplace=True)","745e239b":"annual_consume.sum()\/annual_consume.sum()[0]*100","188d21d3":"f = plt.figure()\n\ngs = gridspec.GridSpec(5,2)\nf.set_figwidth(13)\nf.set_figheight(10)\nplt.suptitle('Electricity Netherlands',fontsize=20)\n\nax1 = f.add_subplot(gs[0:2,0])\nax1.plot(annual_consume.columns.astype(int),annual_consume.sum(),'-o',**specs)\nax1.plot(annual_consume.columns.astype(int),net_annu_consume.sum(),'-o',**specs)\nlgnd = plt.legend(['gross','net'])\n\n#plt.yscale('log')\nplt.ylabel('Energy consumption (kWh)')\nplt.xlabel('');plt.xticks([])\nplt.title('Total yearly energy consumption')\n\nax11 = f.add_subplot(gs[2,0])\nax11.fill_between(annual_consume.columns.astype(int),0,annual_consume.sum()\/annual_consume.sum()[0]*100-100)#,'-o',**specs)\n#plt.yscale('log')\nplt.ylabel('as % of 2009')\nplt.ylim(-4,3)\nplt.xlabel('');plt.xticks([])\n#plt.title('Total yearly energy consumption')\n\nax2 = f.add_subplot(gs[0:2,1])\nax2.plot(num_connections.columns.astype(int),num_connections.sum(),'-og',**specs)\n#plt.yscale('log')\nplt.ylabel('Count')\nplt.xlabel('');plt.xticks([])\nplt.title('Total number of connections')\n\nax21 = f.add_subplot(gs[2,1])\nax21.fill_between(annual_consume.columns.astype(int),0,num_connections.sum()\/num_connections.sum()[0]*100-100,color='g')#,'-o',**specs)\n#plt.yscale('log')\n#plt.ylabel('as % of 2008')\nplt.xlabel('');plt.xticks([])\n#plt.title('Total yearly energy consumption')\n\nax3 = f.add_subplot(gs[3:,0])\nax3.plot(self_production.columns.astype(int),self_production.sum(),'-oc',**specs)\n#plt.yscale('log')\nplt.ylabel('Energy  (kWh)')\nplt.xlabel('Year')\nplt.title('Total yearly self-production')\n\nax4 = f.add_subplot(gs[3:,1])\nax4.plot(num_smartmeters.columns.astype(int),num_smartmeters.sum(),'-om',**specs)\n#plt.yscale('log')\nplt.ylabel('Count')\nplt.xlabel('Year')\nplt.title('Total number of smartmeters')\n\ngs.update(wspace=.51,hspace=.3)\n\n\n\n","65063473":"from scipy.optimize import curve_fit\nx = num_smartmeters.columns.astype(int)-1\n# exponential fit\ndef exponenial_func(x, a, b, c):\n    return 1\/(a*np.exp(-b*x)+c)\n#p_opt, p_cov = curve_fit(exponenial_func, x, y, p0=(1e-16, 1e-6, ))\nxfit = np.linspace(2009,2021,20)\n#yfit = exponenial_func(xfit,*p_opt)\n# this doesn't seem to work well, since we're working with large numbers here. \n# lin fit in lin-log space does the trick for here (although this is not the most elegant solution):\nme,be = np.polyfit(x,np.log(num_smartmeters.sum()),1)\n# linear fit\nm,b = np.polyfit(x,num_connections.sum(),1)\n\nf,ax = plt.subplots(1,2,figsize=(16,8))\n\nax[0].plot(num_smartmeters.columns.astype(int)-1,num_connections.sum(),'og',**specs)\nax[0].plot(num_smartmeters.columns.astype(int)-1,num_smartmeters.sum(),'om',**specs)\nax[0].plot(xfit,m*xfit+b,'g')#,'linewidth'=3)\nax[0].plot(xfit,np.exp(me*xfit+be),'m')#,'linewidth'=3)\n#plt.yscale('log')\nax[0].set_ylabel('Count')\nax[0].set_xlabel('Year')\nax[0].legend(['# connections','# smartmeters','lin fit','exp fit'],loc=4)\nax[0].set_ylim(bottom=-1e6,top=1e7)\n#plt.xlim(0,10)\nax[0].set_title('Smartmeters vs. connections')\n\nspecs2 = {'markersize':20,'fillstyle':'none','linewidth':2}\n# this is the mean of the mean per city:\nax[1].plot(num_smartmeters.columns.astype(int), smartmeter_perc.mean(),'om',**specs2)\n# this is the median of the mean per city:\nax[1].plot(num_smartmeters.columns.astype(int), smartmeter_perc.median(),'og',**specs2)\nax[1].set_title('Smartmeters, percentage of total')\nax[1].set_xlabel('Year')\nax[1].set_ylabel('% of meters being smart')\nax[1].legend(['mean','median'], fontsize=14)","2ef3d746":"import seaborn as sns\n\ndef gauss(x, *p):\n    A, mu, sigma = p\n    return A*np.exp(-(x-mu)**2\/(2.*sigma**2))\n\ndef gauss2(x, *p):\n    A1, mu1, sigma1, A2, mu2, sigma2 = p\n    return A1*np.exp(-(x-mu1)**2\/(2.*sigma1**2)) + A2*np.exp(-(x-mu2)**2\/(2.*sigma2**2))\n\ny = '2018'\nX_dataG = np.linspace(-1,100,102)\n# extract y_data\ncounts,bins = np.histogram(smartmeter_perc[y],bins=X_dataG,density=True)#[y].hist(bins=40)\ny_data = counts\n# initial guesses p0\n# initialize them differently (one at 20 and the other at 80 %) so the optimization algorithm works better\n# this can be circumvented using simulated annealing or sth in the like\np0 = [.03, 20, 1.,.01, 80, 1.]\n\n#optimize and in the end you will have 6 coeff (3 for each gaussian)\ncoeff, var_matrix = curve_fit(gauss2, X_dataG[1:], y_data, p0=p0)\n\n#plot each gaussian separately \npg1 = coeff[0:3]\npg2 = coeff[3:]\n# using the single gauss function\ng1 = gauss(X_dataG, *pg1)\ng2 = gauss(X_dataG, *pg2)\n\n\n\nf,axs = plt.subplots(3,2,figsize=(16,20))\naxs = axs.ravel()\nsmartmeter_perc['2018'].hist(bins=40,alpha=.3,color='r',ax=axs[0])\n#axs[0].set_xlabel('Smartmeters (% of total in a city)')\naxs[0].set_ylabel('count')\naxs[0].set_title('Distribution of smartmeters per city 2018')\nX_data = np.linspace(0,100,40)\nelec_all['provider'] = ['liander' if 'liander' in f else 'stedin' if 'stedin' in f else 'enexis' if 'enexis' in f else 'none' for f in elec_all.index]\nsmart_provider_2018 = pd.pivot_table(elec_all[elec_all.year=='2018'],values='smartmeter_perc',index='city',columns='provider',aggfunc=np.mean)\npleg = []\nfor provider in smart_provider_2018.columns:\n    smart_provider_2018[provider].hist(bins=40,alpha=.3,ax=axs[1])\n    pleg.append(provider)\naxs[1].legend(pleg)\naxs[1].set_title('Smartmeters per city per provider,2018')\nleg = []\n\nfor i in range(2014,2019):\n    y=str(i)\n    smartmeter_perc[y].hist(bins=40,alpha=.3,ax=axs[2])\n    axs[3].hist(smartmeter_perc[y],bins=X_data,density=True,alpha=.3)\n    sns.distplot(smartmeter_perc[y],bins=X_data,hist=False,kde=True,ax=axs[4])\n    leg.append(y)\naxs[5].hist(smartmeter_perc['2018'],bins=X_data,alpha=.3,color='r',density=True)\naxs[5].plot(X_dataG, g1, label='Gaussian1',linewidth=3)\naxs[5].plot(X_dataG, g2, label='Gaussian2',linewidth=3)\naxs[5].legend()\n\n#ax[2].set_xlabel('Smartmeters (% of total in a city)')\naxs[2].set_ylabel('count')\naxs[2].set_title('Distribution of smartmeters per city 2014-2018')\naxs[2].legend(leg)\naxs[3].set_ylabel('Density')\naxs[3].set_title('Normalized distribution of smartmeters per city 2014-2018')\naxs[4].set_xlabel('Smartmeters (% of total in a city)')\naxs[4].legend(leg)\naxs[4].set_ylabel('Density')\nplt.suptitle('Mean number of smartmeters per city', fontsize=20)\n","fab1e9b0":"gausparams = pd.DataFrame(index=range(2014,2019),columns=['A1','mu1','s1','A2','mu2','s2'])\np0 = [.12, 20, 1.,.01, 80, 1.]\nfor year in gausparams.index:\n    counts,bins = np.histogram(smartmeter_perc[str(year)],bins=X_dataG,density=True)#[y].hist(bins=40)\n    y_data = counts\n    if year<=2016: #fit with 1 gaussian\n        coeff, var_matrix = curve_fit(gauss, X_dataG[1:], y_data, p0=p0[:3])\n        gausparams.loc[year,:3] = coeff\n    else: #fit with 2\n        coeff, var_matrix = curve_fit(gauss2, X_dataG[1:], y_data, p0=p0)\n        gausparams.loc[year,:] = coeff\n\nxfit = list(gausparams.index)\ny = list(gausparams['A1'])\nxpred = np.linspace(2014,2020,20)\nm,b = np.polyfit(xfit,y,1)\n\nplt.plot(xfit,y,'og',**specs2,label='Data')\nplt.plot(xpred,m*xpred+b,'-g',linewidth=2,label='fit')\nplt.axhline(0)\nplt.title('Decline of lagging smartmeter population')\nplt.xlabel('Year')\nplt.ylabel('Gauss fit amplitude')\nplt.legend()","d3b01da8":"\"\"\"f,axs = plt.subplots(2,2,figsize=(15,15))\naxs = axs.ravel()\nleg = []\nfor i in range(2014,2019):\n    j=i-2014\n    y=str(i)\n    smartmeter_perc[y].hist(bins=40,alpha=.3,ax=axs[0])\n    \n    sns.distplot(smartmeter_perc[y],bins=X_data,hist=False,kde=True,ax=axs[1])\n\n    leg.append(y)\n    axs[2].clear()\n    axs[2].hist(smartmeter_perc[y],bins=X_data,alpha=.3,color='r',density=True)\n    gy = list(gausparams.loc[i,['A1','mu1','s1']])\n    axs[3].plot(xfit[j],gy[0],'og',**specs2,label='Data')\n    g1 = gauss(X_dataG,*gy)\n    axs[2].plot(X_dataG, g1, label='Gaussian1',linewidth=3)\n    #axs[2].plot(X_dataG, g2, label='Gaussian2',linewidth=3)\n\n    axs[0].legend(leg)\n\n    #ax[2].set_xlabel('Smartmeters (% of total in a city)')\n    axs[0].set_ylabel('count')\n    axs[0].set_title('Distribution of smartmeters per city')\n    axs[0].set_xlim(-5,105)\n    axs[1].set_xlim(-5,105)\n    axs[2].set_xlim(-5,105);axs[2].set_ylim(0,.13)\n    axs[3].set_xlim(2013.5,2020.5);axs[3].set_ylim(-.01,.13)\n    axs[0].legend(leg)\n    axs[1].set_ylabel('Density')\n    axs[1].set_title('Normalized distribution of smartmeters')\n    axs[2].set_xlabel('Smartmeters (% of total in a city)')\n\n    axs[2].set_ylabel('Density')\n    axs[3].axhline(0)\n    axs[3].set_title('Lagging smartmeter population')\n    axs[3].set_xlabel('Year')\n    axs[3].set_ylabel('Gauss fit amplitude')\n    #plt.suptitle('Mean number of smartmeters per city', fontsize=20)\n    f.savefig('smartmeters_'+y+'.png') \n    if y=='2018':\n        axs[3].plot(xpred,m*xpred+b,'-g',linewidth=2,label='fit')\n        f.savefig('smartmeters2019.png')\n        \nimport imageio\nimport glob\nfiles = glob.glob('*.png')\nfiles = np.sort(files)\n# make a copy of each image to slow down gif by factor 2\nfrom shutil import copyfile\nfor file in files:\n    copyfile(file, file.split('.')[0]+'_1.png')\nfiles = glob.glob('*.png')\nfiles = np.sort(files)\nimages = []\nfor file in files:\n    # imageio.imread(file) creates a numpy matrix array\n    # In this case a 200 x 200 matrix for every file, since the files are 200 x 200 pixels.\n    images.append(imageio.imread(file))\n    print(file)\nimageio.mimsave('smartmeter-laggingpop.gif', images)\n\n# step 3: prep the gif for display in notebook \nfrom IPython.display import Image\nImage(\"smartmeter-laggingpop.gif\")\"\"\"","f2a8f60e":"f, axs = plt.subplots(2,3, figsize=(18, 12))#, facecolor='w', edgecolor='k')\n#f.subplots_adjust(hspace = .5, wspace=.001)\naxs = axs.ravel()\nfor i in range(2013,2019):\n    j=i-2013\n    y=str(i)\n    axs[j].scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    axs[j].scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    axs[j].scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    axs[j].set_title(y,fontsize=18)\n    if (i==2013) | (i==2016):\n        axs[j].set_ylabel('mean % of lowtarif consumption')\n    if i>=2016:\n        axs[j].set_xlabel('mean % of smartmeters')\n    if i==2018:\n        lgnd = plt.legend(['Enexis','Liander','Stedin'],loc='lower right')\n        lgnd.legendHandles[0]._sizes = [50]\n        lgnd.legendHandles[1]._sizes = [50]\n        lgnd.legendHandles[2]._sizes = [50]\nplt.suptitle('Evolution of smartmeter-lowtarif per city\\n(sphere radius correlates with city size)',fontsize=25)","435b6f38":"\"\"\"#step 1: make a sequence of images\n\nfor i in range(2013,2019):\n    f = plt.figure(figsize=(7,7))\n    y=str(i)\n    plt.scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('enexis'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    plt.scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('liander'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    plt.scatter(elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').median()['smartmeter_perc']\n             ,elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').median()['annual_consume_lowtarif_perc']\n             ,s=elec_all[(elec_all.year==y)&(elec_all.index.str.contains('stedin'))].groupby('city').sum()['num_connections'].divide(1e2),alpha=.2)\n    plt.title(y,fontsize=18)\n    plt.ylabel('mean % of lowtarif consumption')\n    plt.ylim(-5,107)\n    plt.xlabel('mean % of smartmeters')\n    plt.xlim(-10,105)\n    lgnd = plt.legend(['Enexis','Liander','Stedin'],loc='lower right')\n    lgnd.legendHandles[0]._sizes = [50]\n    lgnd.legendHandles[1]._sizes = [50]\n    lgnd.legendHandles[2]._sizes = [50]\n    f.savefig(y+'.png')\n    plt.close(f)\n\n# step 2: making a gif with the sequence of images:\n\nimport imageio\nimport glob\nfiles = glob.glob('*.png')\nfiles = np.sort(files)\n# make a copy of each image to slow down gif by factor 2\nfrom shutil import copyfile\nfor file in files:\n    copyfile(file, file.split('.')[0]+'_1.png')\nfiles = glob.glob('*.png')\nfiles = np.sort(files)\nimages = []\nfor file in files:\n    # imageio.imread(file) creates a numpy matrix array\n    # In this case a 200 x 200 matrix for every file, since the files are 200 x 200 pixels.\n    images.append(imageio.imread(file))\n    print(file)\nimageio.mimsave('smartmeter-lotarif.gif', images)\n\n# step 3: prep the gif for display in notebook \nfrom IPython.display import Image\nImage(\"smartmeter-lotarif.gif\")\"\"\"","5a5a1caf":"f = plt.figure()\ngs = gridspec.GridSpec(1,5)\n\nax1 = f.add_subplot(gs[0,0])\nelec_all[elec_all.year=='2018'].groupby('city').sum()['self_production'].divide(1e3).sort_values(ascending=False)[:20].plot.barh(color='darkblue',width=.9,alpha=.7,ax=ax1)\n# could have achieved the same with self_production.sort_values('2018',ascending=False).divide(1e3)[:20]\nplt.gca().invert_yaxis()\nplt.xlabel('Energy produced (MWh)');plt.ylabel('')\nplt.title('Self production top 20, 2018')\n\nax2 = f.add_subplot(gs[0,2])\nself_production.divide(num_active_connections).loc[self_production.sort_values('2018',ascending=False).divide(1e3)[:20].index,:].sort_values('2018',ascending=False)['2018'].plot.barh(color='m',width=.9,alpha=.7,ax=ax2)\nplt.gca().invert_yaxis()\nplt.xlabel('Energy produced per connection (kWh)');plt.ylabel('')\nplt.title('Self production per connection, for the top 20 biggest producers, 2018')\n\nax3 = f.add_subplot(gs[0,4])\nself_production.divide(annual_consume\/100).loc[self_production.sort_values('2018',ascending=False).divide(1e3)[:20].index,:].sort_values('2018',ascending=False)['2018'].plot.barh(color='g',width=.9,alpha=.7,ax=ax3)\nplt.gca().invert_yaxis()\nplt.xlabel('Energy produced (% of used)');plt.ylabel('')\nplt.title('Self production, % of consumption, top 20 2018')\n\nf.set_figheight(7)\nf.set_figwidth(20)\n\n","794c9ac4":"f = plt.figure()\ngs = gridspec.GridSpec(1,3)\n\nax1 = f.add_subplot(gs[0,0])\nself_production.divide(num_active_connections).sort_values('2018',ascending=False)['2018'][:20].plot.barh(color='m',width=.9,alpha=.7,ax=ax1)\nplt.gca().invert_yaxis()\nplt.xlabel('Energy produced per connection (kWh)');plt.ylabel('')\nplt.title('Self production per connection, top 20 2018')\n\nax2 = f.add_subplot(gs[0,2])\nself_production.divide(annual_consume\/100).sort_values('2018',ascending=False)['2018'][:20].plot.barh(color='g',width=.9,alpha=.7,ax=ax2)\nplt.gca().invert_yaxis()\nplt.xlabel('Energy produced (% of consumption)');plt.ylabel('')\nplt.title('Self production, % of consumption, top 20 2018')\n\nf.set_figheight(7)\nf.set_figwidth(13)","ea4fc04e":"from collections import defaultdict\nfrom scipy import interpolate\n\n\ndef streamgraph(dataframe, **kwargs):\n    \"\"\" Wrapper around stackplot to make a streamgraph \"\"\"\n    X = dataframe.columns\n    Xs = np.linspace(dataframe.columns[0], dataframe.columns[-1], num=1024)\n    Ys = [interpolate.PchipInterpolator(X, y)(Xs) for y in dataframe.values]\n    return plt.stackplot(Xs, Ys, labels=dataframe.index, **kwargs)\n\ndef add_widths(x, y, width=1):\n    \"\"\" Adds flat parts to widths \"\"\"\n    new_x = []\n    new_y = []\n    for i,j in zip(x,y):\n        new_x += [i-width, i, i+width]\n        new_y += [j, j, j]\n    return new_x, new_y\n\ndef bumpsplot(dataframe, color_dict=defaultdict(lambda: \"k\"), \n                         linewidth_dict=defaultdict(lambda: 4),\n                         labels=[]):\n    r = dataframe.rank(method=\"first\")\n    r = (r - r.max() + r.max().max()).fillna(0) # Sets NAs to 0 in rank\n    for j in r.index:\n        x = np.arange(r.shape[1])\n        y = r.loc[j].values\n        color = color_dict[j]\n        lw = linewidth_dict[j]\n        x, y = add_widths(x, y, width=0.1)\n        xs = np.linspace(0, x[-1], num=1024)\n        plt.plot(xs, interpolate.PchipInterpolator(x, y)(xs), color=color, linewidth=lw, alpha=0.5)\n        if j in labels:\n            plt.text(x[0] - 0.1, y[0], s=j, horizontalalignment=\"right\", verticalalignment=\"center\", color=color)\n            plt.text(x[-1] + 0.1, y[-1], s=j, horizontalalignment=\"left\", verticalalignment=\"center\", color=color)\n    plt.xticks(np.arange(r.shape[1]), dataframe.columns)\n    \n    \nuserank = self_production.sort_values('2010',ascending=False)\ncities = list(userank[:75].index)\ntop_cities = list(self_production['2018'].sort_values(ascending=False).index[:20])\nfinallist = top_cities+list(set(cities).difference(set(top_cities)))\nwinter_colors = defaultdict(lambda: \"grey\")\nlw = defaultdict(lambda: 1)\n\ntop_cities = list(self_production['2018'].sort_values(ascending=False).index[:20])\nfor i,c in enumerate(top_cities):\n    winter_colors[c] = sns.color_palette(\"husl\", n_colors=len(top_cities))[i]\n    lw[c] = 4\n\nf = plt.figure(figsize=(18,18))\nbumpsplot(userank.loc[finallist,:],color_dict=winter_colors,labels=top_cities)\nplt.gca().get_yaxis().set_visible(False)\n\n#plt.gcf().subplots_adjust(left=0.25,bottom=.05,right=.75,top=.95)\nsns.despine(left=True)  \nplt.title('The road to becoming the top 20 electricity producers 2018')\nplt.show()","f8608b33":"from matplotlib.ticker import MaxNLocator\n\n\n\nf = plt.figure()\ngs = gridspec.GridSpec(1,2)\n\nax1 = f.add_subplot(gs[0,0])\nself_production.divide(annual_consume\/100)['2012'].plot.hist(bins=np.logspace(-2,2,40),alpha=.3,ax=ax1)\nself_production.divide(annual_consume\/100)['2014'].plot.hist(bins=np.logspace(-2,2,40),alpha=.3,ax=ax1)\nself_production.divide(annual_consume\/100)['2018'].plot.hist(bins=np.logspace(-2,2,40),alpha=.3,ax=ax1)\n#plt.axvline(self_production.divide(annual_consume\/100)['2018'].median(),color='k')\nplt.xscale('log')\nplt.legend(['2012','2014','2018'])#,'2018 median'])\nplt.xlabel('Energy production per city (% of consumption)')\n\nax2 = f.add_subplot(gs[0,1])\nax2.plot(list(range(2010,2019)),self_production.divide(annual_consume\/100).median(),'o',**specs2)\nxfit = list(range(2013,2019))\nyfit = self_production.divide(annual_consume\/100).median()[3:]\nm,b = np.polyfit(xfit,yfit,1)\nxpred = np.linspace(2013,2022,20)\nax2.plot(xpred,m*xpred+b)\nax2.xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.ylabel('percentage of total consumption')\nplt.xlabel('Year')\nplt.legend(['Data', 'fit'])\nplt.suptitle('Self-production per city',fontsize=18)\n\nf.set_figheight(7)\nf.set_figwidth(13)","e23cf4ef":"provider_self_prod = pd.pivot_table(elec_all,values='self_production',index='provider',columns='year',aggfunc=np.sum)\nprovider_prod = pd.pivot_table(elec_all,values='annual_consume',index='provider',columns='year',aggfunc=np.sum)\nprovider_net_prod = pd.pivot_table(elec_all,values='net_annual_consumption',index='provider',columns='year',aggfunc=np.sum)\n\nf = plt.figure()\ngs = gridspec.GridSpec(2,3)\n\nax1 = f.add_subplot(gs[0,0])\nprovider_prod.T.plot.bar(ax=ax1,legend=False)\n#ax[0].set_yscale('log')\n#ax[0].set_ylim(1e8,1e9)\nax1.set_ylabel('Annual production (kWh)')\nax1.set_title('Gross annual production')\nax1.set_xlabel('');ax1.set_xticks([])\n\nax2 = f.add_subplot(gs[0,1])\nprovider_self_prod.divide(provider_prod\/100).T.plot(ax=ax2)\nax2.set_ylabel('Self-production (% of total)')\nplt.suptitle('Electricity production per provider',fontsize=18)\nax2.set_title('Self-production annual')\nax2.set_xlabel('')\n\nax3 = f.add_subplot(gs[0,2])\nprovider_prod['2018'].plot.pie(ax=ax3)\nax3.set_title('Market share 2018\\n(based on gross prod.)')\nax3.set_ylabel('')\n\nax4 = f.add_subplot(gs[1,0])\nprovider_net_prod.T.plot.bar(ax=ax4,legend=False)\n#ax[0].set_yscale('log')\n#ax[0].set_ylim(1e8,1e9)\nax4.set_ylabel('Annual production (kWh)')\nax4.set_title('Net annual production')\n\nax5 = f.add_subplot(gs[1,1])\nprovider_self_prod.T.plot.bar(ax=ax5,legend=False)\n#ax[0].set_yscale('log')\n#ax[0].set_ylim(1e8,1e9)\nax5.set_ylabel('Self-production (kWh)')\nax5.set_title('Annual self-production')\n\nax6 = f.add_subplot(gs[1,2])\nprovider_self_prod['2018'].plot.pie(ax=ax6)\nax6.set_title('Market share 2018\\n(based on self-prod.)')\nax6.set_ylabel('')\n\nf.set_figheight(12)\nf.set_figwidth(18)","c704935b":"from scipy import stats\n\ndef make_log_df(x_data,y_data,year,offset):\n    x = np.log10(x_data[year].dropna())\n    y = np.log10(y_data[year].dropna())\n    xfit = x.loc[y[y!=-np.inf].index]\n    yfit = y[y!=-np.inf]\n    # df for regression in log space\n    data_for_reg = yfit.to_frame()\n    data_for_reg.rename(index=str,columns={year:'y_'+year},inplace=True)\n    data_for_reg = data_for_reg.join(xfit.to_frame())\n    data_for_reg.rename(index=str,columns={year:'x_'+year},inplace=True)\n    \n    # set the cities with zero (-inf) to arbitrary dropout value\n    y.loc[y[y==-np.inf].index] = -1\n    # this includes dropout values intended not to be included in the regression,\n    # but for plotting purposes only\n    plot_data = y.to_frame().rename(index=str,columns={year:'y_'+year})\n    plot_data = plot_data.join(x.to_frame().rename(index=str,columns={year:'x_'+year}))\n    data_for_reg,fitparams = classify(data_for_reg,offset,year)\n    return(data_for_reg,plot_data,fitparams) \n\ndef classify(df,offset,year):\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df['x_'+year],df['y_'+year])\n    df['offset_'+year] = df['y_'+year] - (df['x_'+year]*slope+intercept)\n    df['cat_'+year] = ['over' if f>offset else 'under' if f<-offset else 'in' for f in df['offset_'+year]]\n    fit = [slope, intercept, r_value, p_value, std_err]\n    return(df,fit)\n    \ny1 = np.log10(self_prod_perc_mean['2018'].dropna())\nx1 = np.log10(annual_consume['2018'].dropna())\nregdata,pldata,fit = make_log_df(annual_consume,self_prod_perc_mean,'2018',.15) \n#plt.scatter(x1,y1,alpha=.2)\nsns.jointplot('x_2018','y_2018',data=regdata,kind='reg',scatter_kws={'alpha':0.1,'s':80},height=7)\nplt.ylabel('Self-production (%)')\nplt.xlabel('Number of active connections')\nloc,label = plt.yticks()\nyticks = [round(10**float(f),2) for f in loc]\nplt.yticks(loc,yticks)\nplt.suptitle('Self-production vs city size 2018')","62e53872":"f,ax = plt.subplots(1,2,figsize=(16,8))\nleg = [];slope_evol = [];offset = []\nfor i in range(2012,2019):\n    y=str(i)\n    regdata,plotdata,fit = make_log_df(num_active_connections,self_prod_perc_mean,y,.15)\n    leg.append(y)\n    sns.regplot('x_'+y,'y_'+y,regdata,x_ci='ci',scatter=True,scatter_kws={'alpha':0.05},ax=ax[0])\n    slope_evol.append(fit[0])\n    offset.append(fit[1])\n    ax[0].set_ylim(-2,2) # 0.01 to 100%\n    ax[0].legend(leg)\n    ax[0].set_ylabel('Self-production (%)')\n    ax[0].set_xlabel('Log$_{10}$ Num active connections')\n\n\"\"\"    abel = [round(10**(item.get_position()[]),2) for item in ax[0].get_yticklabels()]\n    ax[0].set_yticklabels(abel)\n\n    ax[0].set_yticklabels(abel)\n\"\"\"\nax[1].plot(range(2012,2019),slope_evol,'ob',**specs)\nax[1].set_xlim(2011,2019)\nax[1].set_ylim(-.4,0)\nax[1].set_ylabel('Slope of fit')\nax[1].set_xlabel('Year')\nplt.suptitle('City size vs. self-production percentage')","803562f3":"\nregdata,plotdata,fit = make_log_df(num_active_connections,self_prod_perc_mean,'2018',.15)\nlut = {'in':[.5,.5,.5],'over':'g','under':'r'}\ncolor = regdata['cat_2018'].map(lut)\n\nf = plt.figure(figsize=(14,12))\ngs = gridspec.GridSpec(2,2)\nxregr = np.linspace(1,6,10)\n#slope, intercept, r_value, p_value, std_err = stats.linregress(regdata['x'],regdata['y'])\n#plt.plot(num_active_connections['2015'],self_prod_perc_mean['2015'],'o',ms=10,alpha=.2)\nax1 = f.add_subplot(gs[0,0])\n#sns.regplot('x','y',regdata,x_ci='ci',scatter=False,scatter_kws={'alpha':0.1,'s':75})#,ax=ax)\n#sns.jointplot('x','y',data=data,kind='reg')\nplt.scatter(regdata['x_2018'],regdata['y_2018'],alpha=.31,color=color)\n#plt.plot(x,y,'o',ms=10,alpha=.1,color=[.5,.5,.5])\nplt.plot(xregr,fit[0]*xregr+fit[1],'k')\n#plt.plot(xregr,slope*xregr+intercept+.15,'.-k')\n#plt.plot(xregr,slope*xregr+intercept-.15,'.-k')\n#plt.xscale('log');plt.yscale('log')\nplt.ylabel('Self-production (%)')\nplt.xlabel('Number of active connections (x1000)')\nplt.ylim(-1,2)\nloc,label = plt.yticks()\nyticks = [round(10**float(f),2) for f in loc]\nplt.yticks(loc,yticks)\nloc,label = plt.xticks()\nxticks = [round((10**float(f))\/1e3,3) for f in loc]\nplt.xticks(loc,xticks,fontsize=13)\n#plt.text(2.5,-.5,\"$y=$\"+str(round(slope,3))+\"$x+$\"+str(round(10**intercept,3)),fontsize=15)\n#plt.grid()\nplt.xlim(0,6)\n#plt.axvline(np.log10(5e4))\n\nax2 = f.add_subplot(gs[0,1])\nax2.scatter(regdata['x_2018'],regdata['y_2018'],s=num_active_connections.loc[regdata.index,'2018']\/1e3,alpha=.4,color=color)\n#plt.plot(x,y,'o',ms=10,alpha=.1,color=[.5,.5,.5])\nax2.plot(xregr,fit[0]*xregr+fit[1],'k')\n#plt.ylabel('Self-production (%)')\nplt.xlabel('Number of active connections (x1000)')\nplt.ylim(0,1.)\nplt.xlim(left=np.log10(4e4),right=6)\nloc,label = plt.yticks()\nyticks = [round(10**float(f),2) for f in loc]\nplt.yticks(loc,yticks)\nloc,label = plt.xticks()\nxticks = [round((10**float(f))\/1e3) for f in loc]\nplt.xticks(loc,xticks,fontsize=13)\ntwenty18 = num_active_connections['2018'].to_frame()\ntwenty18_L = twenty18[twenty18>5e4].dropna()\nfor cit in twenty18_L.index:\n    x = regdata.loc[cit,'x_2018']\n    y = regdata.loc[cit,'y_2018']\n    plt.text(x+.02,y,cit)\n    \nplt.suptitle('Self-production vs city size 2018, over & underperformers')\nall_offset = pd.DataFrame(index=twenty18_L.index,columns=[0])\nfor year in range(2012,2019):\n    year = str(year)\n    regdata,plotdata,fit = make_log_df(num_active_connections,self_prod_perc_mean,year,.15)\n    if year=='2012':\n        all_offset = regdata.loc[twenty18_L.index,:]\n    else:\n        all_offset = all_offset.join(regdata.loc[twenty18_L.index,:])\nax3 = f.add_subplot(gs[1,:])\nvalues = sns.color_palette('husl',len(all_offset));keys = all_offset.index\nlut = dict(zip(keys,values))\ncolors = all_offset.index.map(lut)\nall_offset.loc[:,['offset_2012','offset_2013','offset_2014','offset_2015','offset_2016','offset_2017','offset_2018']].T.plot(ax=ax3,color=colors)\nplt.axhline(0,color='k',linewidth=3)\nloc,label = plt.xticks()\nplt.ylabel('Percentage points above or below regression')\nplt.xticks(loc,[int(f+2012) for f in loc])\n\nloc,label = plt.yticks()\nyticks = [round(10**float(abs(f)),2) if f>0 else -round(10**float(abs(f)),2) if f<0 else 0 for f in loc]\nplt.yticks(loc,yticks)\nplt.legend(bbox_to_anchor=(1.5, 1), loc='upper right', ncol=2)","53707f1f":"f = plt.figure()\ngs = gridspec.GridSpec(1,2)\nax1 = f.add_subplot(gs[0,0])\nlabels = ['smartmeter_perc','annual_consume_lowtarif_perc','delivery_perc','self_prod_perc']\ndat = elec_all[(elec_all.city.isin(['ROTTERDAM','AMSTERDAM']))&(elec_all.year=='2018')].melt(id_vars='city',value_vars=labels) ##'num_active_connections', 'num_smartmeters'])#\ng = sns.violinplot(x='variable',y='value',hue=dat.city,split=True,data=dat,ax=ax1)\nplt.xlabel('');plt.ylabel('percentage')\ng.set_xticklabels(labels,rotation=30,ha='right')\n#plt.yscale('log')\nax2 = f.add_subplot(gs[0,1])\ndat = elec_all[(elec_all.city.isin(['UTRECHT',\"MAASTRICHT\"]))&(elec_all.year=='2018')].melt(id_vars='city',value_vars=labels) ##'num_active_connections', 'num_smartmeters'])#\ng = sns.violinplot(x='variable',y='value',hue=dat.city,split=True,data=dat,ax=ax2)\nplt.xlabel('');plt.ylabel('')\ng.set_xticklabels(labels,rotation=30,ha='right') \nf.set_figheight(7)\nf.set_figwidth(14)\nplt.suptitle('Comparison of individual cities, 2018.')","3312562a":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA","70dbf792":"#.pivot_table(elec2018,index='city',columns=sumcols,aggfunc=np.sum)\nelec_all.loc[:,(elec_all.dtypes=='float64')|(elec_all.dtypes=='int64')]\nsumcols = ['annual_consume','num_connections','low_tarif_consumption','num_active_connections','num_smartmeters','net_annual_consumption','self_production']\nmeancols = ['annual_consume_lowtarif_perc','delivery_perc','perc_of_active_connections','smartmeter_perc','self_prod_perc']\ndf = elec_all[elec_all.year=='2018'].groupby('city').sum()[sumcols]\ndf = df.join(elec_all[elec_all.year=='2018'].groupby('city').mean()[meancols])\n\nx = StandardScaler().fit_transform(df) # transform the variables (mean=0, var=1)\ndf_standard = pd.DataFrame(x,index=df.index,columns=df.columns)\n\nx_emb = TSNE(n_components=2,perplexity=80,random_state=23944).fit_transform(x) # actual t-SNE (reduction from 11 dims to 2)\ntsne_cities = pd.DataFrame(x_emb,index=df.index)\ntsne_cities = tsne_cities.join(df['num_active_connections'])\n\n# color by provider (to see if the cities cluster by provider)\nenexis = elec_all[(elec_all.year=='2018')&(elec_all.index.str.contains('enexis'))].groupby('city').count().index\nliander = elec_all[(elec_all.year=='2018')&(elec_all.index.str.contains('liander'))].groupby('city').count().index\nstedin = elec_all[(elec_all.year=='2018')&(elec_all.index.str.contains('stedin'))].groupby('city').count().index\ntsne_cities.loc[enexis,'provider'] = 'enexis'\ntsne_cities.loc[liander,'provider'] = 'liander'\ntsne_cities.loc[stedin,'provider'] = 'stedin'\nkeys = ['enexis','liander','stedin']\nlut = dict(zip(keys,sns.color_palette('dark',3)))\ncolors = tsne_cities.provider.map(lut)","7cedc7e8":"f = plt.figure(figsize=(8,8))\ngs = gridspec.GridSpec(1,1)\nax1 = f.add_subplot(gs[0,0])\ntsne_cities.loc[enexis].plot.scatter(0,1,s=df.loc[enexis,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[enexis],ax=ax1)\ntsne_cities.loc[liander].plot.scatter(0,1,s=df.loc[liander,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[liander],ax=ax1)\ntsne_cities.loc[stedin].plot.scatter(0,1,s=df.loc[stedin,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[stedin],ax=ax1)\nlgnd = plt.legend(['Enexis','Liander','Stedin'],loc='lower right')\nlgnd.legendHandles[0]._sizes = [50]\nlgnd.legendHandles[1]._sizes = [50]\nlgnd.legendHandles[2]._sizes = [50]\nplt.title('Electricity consumption-based\\nt-SNE of all Dutch cities, 2018')\nplt.xlabel('t-SNE1');plt.ylabel('t-SNE2')","3fed4d96":"tsne_cities[(tsne_cities[0]>=0)&(tsne_cities[1]<-30)].sort_values('num_active_connections',ascending=False)\ntsne_cities[(tsne_cities[0]>=15)&(tsne_cities[1]<0)&(tsne_cities[0]<25)]\n\ncol1 =  self_prod_perc_mean.loc[tsne_cities.index,'2018'].to_frame()\ncol2 =  smartmeter_perc.loc[tsne_cities.index,'2018'].to_frame()\ncol3 =  annu_cons_lowtarif_perc.loc[tsne_cities.index,'2018'].to_frame()\ncol4 =  np.log10(annual_consume.loc[tsne_cities.index,'2018'].to_frame())\n","738dadd3":"f = plt.figure(figsize=(18,15))\n\ngs = gridspec.GridSpec(2,2)\nax1 = f.add_subplot(gs[0,0])\ntsne_cities.plot.scatter(0,1,alpha=.5,c=col1['2018'],cmap='RdBu_r',ax=ax1)\nax1.arrow(4,-20,-10,-3,width=.5,length_includes_head=True)\nax1.text(5,-20,'region 1')\nplt.title('Self production percentage')\nplt.xlabel('');plt.ylabel('')\n\nax2 = f.add_subplot(gs[0,1])\ntsne_cities.plot.scatter(0,1,alpha=.5,c=col2['2018'],cmap='RdBu_r',ax=ax2)\nax2.arrow(25,-18,0,8,width=.5,length_includes_head=True)\nax2.text(20,-20,'region 2')\nax2.arrow(9,-30,-5,-5,width=.5,length_includes_head=True)\nax2.text(10,-30,'region 3')\nplt.title('Smartmeter percentage')\nplt.xlabel('');plt.ylabel('')\n\nax3 = f.add_subplot(gs[1,0])\ntsne_cities.plot.scatter(0,1,alpha=.5,c=col3['2018'],cmap='RdBu_r',ax=ax3)\nplt.title('Annual lowtarif cons. percentage')\nplt.xlabel('');plt.ylabel('')\n\nax4 = f.add_subplot(gs[1,1])\ntsne_cities.plot.scatter(0,1,alpha=.5,c=col4['2018'],cmap='RdBu_r',ax=ax4)\nplt.title('Log10 Annual consumption')\nplt.xlabel('');plt.ylabel('')\n","14d46967":"region1_idx = tsne_cities[(tsne_cities[0]>-15)&(tsne_cities[0]<-5)&(tsne_cities[1]<-20)&(tsne_cities[1]>-30)].index\nprint('region 1 head')\ntsne_cities.join(self_prod_perc_mean.loc[region1_idx,'2018']).sort_values('2018',ascending=False).head()","0d5b8653":"df_norm = df[sumcols].divide(df[sumcols].sum(),axis=1)\ndf_norm = df_norm.join(df[meancols].divide(100))\ndf_norm.var()","3c4c56ba":"x = StandardScaler().fit_transform(df_norm[meancols]) # transform the variables (mean=0, var=1)\n\n\nx_emb = TSNE(n_components=2,perplexity=80,random_state=23944).fit_transform(x) # actual t-SNE (reduction from 11 dims to 2)\ntsne_norm_cities = pd.DataFrame(x_emb,index=df.index)\ntsne_norm_cities = tsne_norm_cities.join(df['num_active_connections'])\n","16970584":"f = plt.figure(figsize=(8,8))\ngs = gridspec.GridSpec(1,1)\nax1 = f.add_subplot(gs[0,0])\ntsne_norm_cities.loc[enexis].plot.scatter(0,1,s=df.loc[enexis,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[enexis],ax=ax1)\ntsne_norm_cities.loc[liander].plot.scatter(0,1,s=df.loc[liander,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[liander],ax=ax1)\ntsne_norm_cities.loc[stedin].plot.scatter(0,1,s=df.loc[stedin,'num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[stedin],ax=ax1)\nlgnd = plt.legend(['Enexis','Liander','Stedin'],loc='lower right')\nlgnd.legendHandles[0]._sizes = [50]\nlgnd.legendHandles[1]._sizes = [50]\nlgnd.legendHandles[2]._sizes = [50]\nplt.title('Electricity consumption-based\\nt-SNE of all Dutch cities, 2018, normalized')\nplt.xlabel('t-SNE1');plt.ylabel('t-SNE2')","0da219f7":"tsne_norm_cities[(tsne_norm_cities[0]<-18)&(tsne_norm_cities[1]<-30)&((tsne_norm_cities.index.isin(liander))|(tsne_norm_cities.index.isin(stedin)))]","8a7e2ef9":"#'DEVENTER' in enexis\nprint(set(enexis).intersection(set(liander)))\nprint(set(enexis).intersection(set(stedin)))","63fe2c3f":"f = plt.figure(figsize=(20,11))\n\ngs = gridspec.GridSpec(2,3)\nax1 = f.add_subplot(gs[0,1])\ntsne_norm_cities.plot.scatter(0,1,s=tsne_norm_cities['num_active_connections'].divide(2e2),alpha=.5,c=col1['2018'],cmap='RdBu_r',vmax=30,ax=ax1)\n#ax1.arrow(4,-20,-10,-3,width=.5,length_includes_head=True)\n#ax1.text(5,-20,'region 1')\nplt.title('Self production percentage')\nplt.xlabel('');plt.ylabel('')\n\nax2 = f.add_subplot(gs[0,2])\ntsne_norm_cities.plot.scatter(0,1,s=tsne_norm_cities['num_active_connections'].divide(2e2),alpha=.5,c=col2['2018'],cmap='RdBu_r',ax=ax2)\n#ax2.arrow(25,-18,0,8,width=.5,length_includes_head=True)\n#ax2.text(20,-20,'region 2')\n#ax2.arrow(9,-30,-5,-5,width=.5,length_includes_head=True)\n#ax2.text(10,-30,'region 3')\nplt.title('Smartmeter percentage')\nplt.xlabel('');plt.ylabel('')\n\nax3 = f.add_subplot(gs[1,0])\ntsne_norm_cities.plot.scatter(0,1,s=tsne_norm_cities['num_active_connections'].divide(2e2),alpha=.5,c=col3['2018'],cmap='RdBu_r',ax=ax3)\nplt.title('Annual lowtarif cons. percentage')\nplt.xlabel('');plt.ylabel('')\n\nax4 = f.add_subplot(gs[0,0])\ntsne_norm_cities.plot.scatter(0,1,s=tsne_norm_cities['num_active_connections'].divide(2e2),alpha=.5,c=col4['2018'],cmap='RdBu_r',ax=ax4)\nplt.title('Log10 Annual consumption')\nplt.xlabel('');plt.ylabel('')\n\ncol5 =  perc_active_connections.loc[tsne_cities.index,'2018'].to_frame()\nax5 = f.add_subplot(gs[1,1])\ntsne_norm_cities.plot.scatter(0,1,s=tsne_norm_cities['num_active_connections'].divide(2e2),alpha=.5,c=col5['2018'],cmap='RdBu_r',vmin=60,ax=ax5)\nplt.title('Percent of active connections')\nplt.xlabel('');plt.ylabel('')","599b7756":"\nprint('high smartmeter %; high % active connections; low lowtarif consumption %')\nlist(tsne_norm_cities[(tsne_norm_cities[0]<-18)&(tsne_norm_cities[1]<-30)].sort_values('num_active_connections',ascending=False).head().index)","3ed80a23":"\nprint('low smartmeter %; high % active connections; low lowtarif consumption %')\nlist(tsne_norm_cities[(tsne_norm_cities[0]<-20)&(tsne_norm_cities[1]>-10)].sort_values('num_active_connections',ascending=False).head().index)","6c130213":"\nprint('low smartmeter %; medium % active connections; medium-low lowtarif consumption %')\nlist(tsne_norm_cities[(tsne_norm_cities[0]<5)&(tsne_norm_cities[1]>10)].sort_values('num_active_connections',ascending=False).head().index)","a0dbec53":"\nprint('low smartmeter %; medium % active connections; high lowtarif consumption %')\nlist(tsne_norm_cities[(tsne_norm_cities[0]>5)&(tsne_norm_cities[1]>10)].sort_values('num_active_connections',ascending=False).head().index)","0270c260":"\nprint('high smartmeter %; medium % active connections; high lowtarif consumption %')\nlist(tsne_norm_cities[(tsne_norm_cities[0]>25)].sort_values('num_active_connections',ascending=False).head().index)","2e8413ff":"path = '..\/input\/dutch-energy\/dutch-energy\/Gas\/'\nfiles_all = [f for f in os.listdir(path)]\ngas_all = load_and_reindex(path,files_all)","ad0d3c51":"# make pivot tables of relevant parameter such that we have total per city per year\ngas_annual_consume = pd.pivot_table(gas_all,values='annual_consume',index='city',columns='year',aggfunc=np.sum)\ngas_num_connections = pd.pivot_table(gas_all,values='num_connections',index='city',columns='year',aggfunc=np.sum)\ngas_num_active_connections = pd.pivot_table(gas_all,values='num_active_connections',index='city',columns='year',aggfunc=np.sum)\ngas_smartmeter_perc = pd.pivot_table(gas_all,values='smartmeter_perc',index='city',columns='year',aggfunc=np.mean)\ngas_smartmeter_perc_median = pd.pivot_table(gas_all,values='smartmeter_perc',index='city',columns='year',aggfunc=np.median)\ngas_num_smartmeters = pd.pivot_table(gas_all,values='num_smartmeters',index='city',columns='year',aggfunc=np.sum)\ngas_self_production = pd.pivot_table(gas_all,values='self_production',index='city',columns='year',aggfunc=np.sum)\ngas_self_prod_perc_mean = pd.pivot_table(gas_all,values='self_prod_perc',index='city',columns='year',aggfunc=np.mean)\ngas_net_annu_consume = pd.pivot_table(gas_all,values='net_annual_consumption',index='city',columns='year',aggfunc=np.sum)\ngas_annu_cons_lowtarif_perc = pd.pivot_table(gas_all,values='annual_consume_lowtarif_perc',index='city',columns='year',aggfunc=np.mean)","0b8e7032":"gas_self_production[gas_self_production.T.sum()!=0]","8f376847":"df_all = elec_all[elec_all.year=='2018'].groupby('city').sum()[sumcols]\ndf_all = df_all.join(elec_all[elec_all.year=='2018'].groupby('city').mean()[meancols])\nvalues = ['elec_'+f for f in sumcols+meancols]\ndf_all.rename(index=str,columns=dict(zip(sumcols+meancols,values)),inplace=True)\ndf_all = df_all.join(gas_all[gas_all.year=='2018'].groupby('city').sum()[sumcols])\ndf_all = df_all.join(gas_all[gas_all.year=='2018'].groupby('city').mean()[meancols])\nvalues_g = ['gas_'+f for f in sumcols+meancols]\ndf_all.rename(index=str,columns=dict(zip(sumcols+meancols,values_g)),inplace=True)\ndf_all['gas_smartmeter_perc'] = df_all['gas_smartmeter_perc'].fillna(0)\ndf_all.sort_values('elec_annual_consume',ascending=False).head()","fc30a878":"print('Cities in gas dataset but not in electricity:'+str(set(gas_all.city).difference(set(elec_all.city))))\nprint('Cities in electricity dataset but not in gas:'+str(set(elec_all.city).difference(set(gas_all.city))))","9ac5e864":"df_all = df_all.dropna(how='any',axis=0)\nx = StandardScaler().fit_transform(df_all) # transform the variables (mean=0, var=1)\ndf_standard = pd.DataFrame(x,index=df_all.index,columns=df_all.columns)\n\nx_emb = TSNE(n_components=2,perplexity=80,random_state=23944).fit_transform(x) # actual t-SNE (reduction from 11 dims to 2)\ntsne_cities = pd.DataFrame(x_emb,index=df_all.index)\ntsne_cities = tsne_cities.join(df_all['elec_num_active_connections'])\n\n# color by provider (ignoring the discrepancies between the gas\/elec cities)\nprovider_city = pd.DataFrame(index=elec_all[(elec_all.year=='2018')].groupby('city').count().index,columns=['provider'])\nprovider_city.loc[enexis,'provider'] = 'enexis'\nprovider_city.loc[liander,'provider'] = 'liander'\nprovider_city.loc[stedin,'provider'] = 'stedin'\ntsne_cities['provider'] = provider_city.loc[tsne_cities.index,'provider']\nkeys = ['enexis','liander','stedin']\nlut = dict(zip(keys,sns.color_palette('dark',3)))\ncolors = tsne_cities.provider.map(lut)","7beff58c":"f = plt.figure(figsize=(8,8))\ngs = gridspec.GridSpec(1,1)\nax1 = f.add_subplot(gs[0,0])\n#tsne_cities.plot.scatter(0,1,s=df_all['elec_num_active_connections'].divide(1e2),alpha=.1,ax=ax1)\ntsne_cities.loc[tsne_cities[tsne_cities['provider']=='enexis'].index].plot.scatter(0,1,s=tsne_cities.loc[tsne_cities[tsne_cities['provider']=='enexis'].index,'elec_num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[tsne_cities[tsne_cities['provider']=='enexis'].index],ax=ax1)\ntsne_cities.loc[tsne_cities[tsne_cities['provider']=='liander'].index].plot.scatter(0,1,s=tsne_cities.loc[tsne_cities[tsne_cities['provider']=='liander'].index,'elec_num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[tsne_cities[tsne_cities['provider']=='liander'].index],ax=ax1)\ntsne_cities.loc[tsne_cities[tsne_cities['provider']=='stedin'].index].plot.scatter(0,1,s=tsne_cities.loc[tsne_cities[tsne_cities['provider']=='stedin'].index,'elec_num_active_connections'].divide(1e2),alpha=.1,figsize=(8,8),color=colors.loc[tsne_cities[tsne_cities['provider']=='stedin'].index],ax=ax1)\nlgnd = plt.legend(['Enexis','Liander','Stedin'],loc='lower right')\nlgnd.legendHandles[0]._sizes = [50]\nlgnd.legendHandles[1]._sizes = [50]\nlgnd.legendHandles[2]._sizes = [50]\nplt.title('All energy consumption-based\\nt-SNE of all Dutch cities, 2018')\nplt.xlabel('t-SNE1');plt.ylabel('t-SNE2')","f0eecdc8":"\"\"\"bli = elec_all[elec_all.city.isin(['ALMERE','DORDRECHT'])][meancols+[sumcols[0]]+[sumcols[3]]]\nxc = StandardScaler().fit_transform(bli) # transform the variables (mean=0, var=1)\ndf_almdor = pd.DataFrame(x,index=df.index,columns=df.columns)\n\nxc_emb = TSNE(n_components=2,perplexity=80,random_state=23944).fit_transform(xc) # actual t-SNE (reduction from 11 dims to 2)\ntsne_almdo = pd.DataFrame(xc_emb,index=bli.index)\ntsne_almdo['city'] = elec_all.loc[tsne_almdo.index,'city']\"\"\"","fea4ec47":"\"\"\"lut = {'ALMERE':'r','DORDRECHT':'b'}\ncoloer = tsne_almdo['city'].map(lut)\ntsne_almdo.plot.scatter(0,1,alpha=.01,figsize=(8,8),color=coloer)\"\"\"","40a4be35":"elec_all.loc[:,(elec_all.dtypes=='float64')|(elec_all.dtypes=='int64')]\nsumcols = ['annual_consume','num_connections','low_tarif_consumption','num_active_connections','num_smartmeters','net_annual_consumption','self_production']\nmeancols = ['annual_consume_lowtarif_perc','delivery_perc','perc_of_active_connections','smartmeter_perc','self_prod_perc']\n\ndf = elec_all[elec_all.year=='2018'].groupby('city').sum()[sumcols]\ndf = df.join(elec_all[elec_all.year=='2018'].groupby('city').mean()[meancols])\nx = StandardScaler().fit_transform(df) \npca = PCA(n_components=4)\nprincipalComp = pca.fit_transform(x)\nprincipaldf = pd.DataFrame(data=principalComp,columns=['PC1','PC2','PC3','PC4'])\n#finaldf = pd.concat([principaldf,df[target]],axis=1)","77fdb73b":"col1 =  self_prod_perc_mean.loc[df.index,'2018'].to_frame()\ncol2 =  smartmeter_perc.loc[df.index,'2018'].to_frame()\ncol3 =  annu_cons_lowtarif_perc.loc[df.index,'2018'].to_frame()\ncol4 =  np.log10(annual_consume.loc[df.index,'2018'].to_frame())\n\nf = plt.figure(figsize=(28,7))\ngs = gridspec.GridSpec(1,4)\n\nax1 = f.add_subplot(gs[0,0])\nprincipaldf.plot.scatter('PC1','PC2',s=df['num_active_connections'].divide(1e2),alpha=.1,c=col4['2018'],cmap='RdBu_r',ax=ax1) #pc2 ~ size \nplt.xlabel('PC1')\nplt.title('Color: size')\n\nax2 = f.add_subplot(gs[0,1])\nprincipaldf.plot.scatter('PC1','PC2',s=np.log10(df['num_active_connections'])*50,alpha=.1,c=col1['2018'],cmap='RdBu_r',ax=ax2) #pc2 ~ self prod \nplt.xlabel('PC1')\nplt.title('Color: self-production')\n\nax3 = f.add_subplot(gs[0,2])\nprincipaldf.plot.scatter('PC2','PC3',s=df['num_active_connections'].divide(1e2),alpha=.1,c=col3['2018'],cmap='RdBu_r',ax=ax3) # pc3 ~ lowtarif\nplt.xlabel('PC2')\nplt.title('Color: lowtarif consumption')\n\nax4 = f.add_subplot(gs[0,3])\nprincipaldf.plot.scatter('PC3','PC4',s=np.log10(df['num_active_connections'])*50,alpha=.1,c=col2['2018'],cmap='RdBu_r',ax=ax4) # pc4 ~ smartmeter perc\nplt.xlabel('PC3')\nplt.title('Color: smartmeter percentage')","e74b4663":"\"\"\"leaders2015 = elec_all[elec_all.year=='2015'].groupby('city').mean()#['smartmetaer_perc']\nleaders2015size = elec_all[elec_all.year=='2015'].groupby('city').sum()\nidx = leaders2015[leaders2015['smartmeter_perc']>60].index\nleaders2015size.loc[idx,:].sort_values('num_connections',ascending=False)\n#elec_all[elec_all.city.isin(idx)]\"\"\"","b81b36f8":"from mpl_toolkits.basemap import Basemap\nfrom matplotlib.patches import Polygon as PG\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.colors import Normalize\nimport geopandas as gpd\nimport folium\nfrom matplotlib.patches import Patch\nfrom shapely.geometry import Point, Polygon\nimport shapely.speedups\nshapely.speedups.enable()\nfrom geopandas import GeoDataFrame","c32ef159":"municip_geo = gpd.read_file('\/kaggle\/input\/municip_shapefile\/NLD_adm2.shp')\nmunicip_geo.head(2)","f7203b54":"f, ax = plt.subplots(figsize = (10,15))\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=ax)\nm.drawmapboundary(fill_color='#46bcec')\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\n# this seems like a very roundabout way\nprovinces = municip_geo.NAME_1.unique()\ncolors = sns.color_palette('Paired',len(provinces))\nlut = dict(zip(provinces,colors))\nlegend_elements = []\nfor province in provinces: \n    prov = []\n    for info, shape in zip(m.geometry_info, m.geometry):\n        if (info['NAME_1'] == province) & (province not in ['Zeeuwse meren','IJsselmeer']):\n            prov.append( PG(np.array(shape), True) )    \n    ax.add_collection(PatchCollection(prov, facecolor= lut[province], edgecolor='k', linewidths=.1, zorder=2))\n    if province not in ['Zeeuwse meren','IJsselmeer']:\n        legend_elements.append(Patch(facecolor=lut[province], edgecolor='k',\n                         label=province))\nax.legend(handles=legend_elements)\n\n\n","17c766f6":"# first get the data into the right form\nelec_all['zipcode_from_int'] = elec_all['zipcode_from'].str[:-2].astype(int)\nelec_all['zipcode_to_int'] = elec_all['zipcode_to'].str[:-2].astype(int)\nelec_all['zidiff'] = elec_all['zipcode_to_int'] - elec_all['zipcode_from_int']\nsumcols = ['annual_consume','num_connections','low_tarif_consumption','num_active_connections','num_smartmeters','net_annual_consumption','self_production']\nmeancols = ['annual_consume_lowtarif_perc','delivery_perc','perc_of_active_connections','smartmeter_perc','self_prod_perc']\nelec_all['provider'] = [f[0] for f in elec_all.index.str.split('_')]\n\n# add postalcode geolocations \npostalcode_geoloc = pd.read_csv('\/kaggle\/input\/postalcodegeolocation\/4pp.csv').set_index('postcode',drop=False)\n\n\"\"\"\nAll these functions assume the existence of lists and dataframes loaded above\nIt's a bit messy, but fairly obvious what I am using here\n\nDataframes:     postalcode_geoloc\n                elec_all\n                municip_geo\n                \nLists:          meancols\n                sumcols\n\"\"\"\n\ndef make_group_zipcode(year,df):\n    df = df[df.year==year]\n    pc_df = df.groupby('zipcode_from_int').sum()[sumcols]#.count()['city']\n    pc_df = pc_df.join(df.groupby('zipcode_from_int').mean()[meancols])\n    pc_df = pc_df.join(df.groupby('zipcode_from_int').count()['city']).rename({'city':'code_count'},axis=1)\n    pc_df = pc_df.join(df.groupby('zipcode_from_int').first()[['city','provider']])\n    values = [year+'_'+f for f in pc_df.columns]\n    pc_df.rename(dict(zip(pc_df.columns,values)),axis=1,inplace=True)\n    pc_df = pc_df.join(postalcode_geoloc,how='left') #add geolocation\n    \n    geometry = [Point(xy) for xy in zip(pc_df.longitude, pc_df.latitude)]\n    crs = {'init': 'epsg:4326'}\n    gdf = GeoDataFrame(pc_df, crs=crs, geometry=geometry) # make geopandas df\n    pc_df = attach_municip(pc_df,gdf)\n    return pc_df\n\ndef attach_municip(df,geodf):\n    for municip in municip_geo.ID_2:\n        idx = municip_geo[municip_geo.ID_2==municip].index[0]\n        municip_name = municip_geo.loc[idx,'NAME_2']\n        ingroup = list(geodf[geodf['geometry'].within(municip_geo.loc[idx,'geometry'])==True].index)\n        df.loc[ingroup,'ID_2'] = municip\n        df.loc[ingroup,'NAME_2'] = municip_name\n    return(df)\n\ndef merge_energy_data_into_municip(df,year):\n    pc_df = make_group_zipcode(year,df)\n    firstcols = ['NAME_2','provincie','netnummer',year+'_provider']\n    meancols_y = [year+'_'+f for f in meancols]\n    sumcols_y = [year+'_'+f for f in sumcols]\n    sumcols_y.append(year+'_code_count')\n    final_frame = pc_df.groupby('ID_2').first()[firstcols]\n    final_frame['ID_2'] = final_frame.index\n    final_frame = final_frame.join(pc_df.groupby('ID_2').mean()[meancols_y])\n    final_frame = final_frame.join(pc_df.groupby('ID_2').sum()[sumcols_y])\n    polygon_frame = pd.DataFrame({\n        'shapes': [PG(np.array(shape),True) for shape in m.geometry],\n        'ID_2': [area['ID_2'] for area in m.geometry_info]})\n    polygon_frame = polygon_frame.merge(final_frame, on='ID_2', how='left')\n    return final_frame, polygon_frame\n    \n    \n\n    ","71ed9e1f":"pc_2018 = make_group_zipcode('2018',elec_all)\nf,ax = plt.subplots(figsize=(11,13))\n#pc2018.plot.scatter('longitude','latitude',s=pc2018['2018_num_active_connections'].astype(float).divide(2e2)\n#                    ,alpha=.4,ax=ax)\npc_2018.plot.scatter('longitude','latitude',s=pc_2018['2018_num_active_connections'].astype(float).divide(2e2)\n                    ,alpha=.4,ax=ax)\nplt.title('Number of active connections per 4-digit postal code, 2018')","354dfe2b":"# let's make polygon dataframes for all years\nfin_2011, poly2011 = merge_energy_data_into_municip(elec_all,'2011')\nfin_2012, poly2012 = merge_energy_data_into_municip(elec_all,'2012')\nfin_2013, poly2013 = merge_energy_data_into_municip(elec_all,'2013')\nfin_2014, poly2014 = merge_energy_data_into_municip(elec_all,'2014')\nfin_2015, poly2015 = merge_energy_data_into_municip(elec_all,'2015')\nfin_2016, poly2016 = merge_energy_data_into_municip(elec_all,'2016')\nfin_2017, poly2017 = merge_energy_data_into_municip(elec_all,'2017')\nfin_2018, poly2018 = merge_energy_data_into_municip(elec_all,'2018')","61a611b7":"f, ax = plt.subplots(1,2,figsize = (20,24))\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=ax[0])\nm.drawmapboundary(fill_color='#46bcec')\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\n\nproviders = ['enexis','liander','stedin']\ncolors = sns.color_palette('dark',len(providers))\nlut = dict(zip(providers,colors))\n\n# there must be a cleaner way to do all this, but I'm leaving it for now\npc_lian = poly2018[poly2018['2018_provider']=='liander'] \npc_enex = poly2018[poly2018['2018_provider']=='enexis'] \npc_sted = poly2018[poly2018['2018_provider']=='stedin'] \npcna = poly2018[poly2018['provincie'].isna()] # municipalities not having data\npcij = poly2018[(poly2018.ID_2==146)|(poly2018.ID_2==400)] #polygons ijsselmeer, zeeuwse meren\n\n\npcl = PatchCollection(pc_lian.shapes, zorder=2)\npce = PatchCollection(pc_enex.shapes, zorder=2)\npcs = PatchCollection(pc_sted.shapes, zorder=2)\npna = PatchCollection(pcna.shapes, zorder=2)\npij = PatchCollection(pcij.shapes, zorder=2)\n\npcl.set_facecolor(lut['liander'])\npce.set_facecolor(lut['enexis'])\npcs.set_facecolor(lut['stedin'])\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\n\npna.set_edgecolor('white')\npij.set_edgecolor('white')\npcs.set_edgecolor('white')\npce.set_edgecolor('white')\npcl.set_edgecolor('white')\n\n\nax[0].add_collection(pcl)\nax[0].add_collection(pce)\nax[0].add_collection(pcs)\n\nax[0].add_collection(pna)\nax[0].add_collection(pij)\n\nlegend_elements = []\nfor provider in providers: \n    legend_elements.append(Patch(facecolor=lut[provider], edgecolor='white',\n                         label=provider))\nlegend_elements.append(Patch(facecolor='gray',edgecolor='white',label='no data (2018)'))\nax[0].legend(handles=legend_elements)\nax[0].set_title('Electricity providers per municipality')\n\n\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=ax[1])\nm.drawmapboundary(fill_color='#46bcec')\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\n\npc2 = poly2018[~poly2018['provincie'].isna()] # all others \n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \n#cmap = plt.get_cmap('Oranges') \npc = PatchCollection(pc2.shapes,zorder=2)\npna2 = PatchCollection(pcna.shapes, zorder=2)\npij2 = PatchCollection(pcij.shapes, zorder=2)\n\npc.set_facecolor(cmap(norm(np.log10(pc2['2018_annual_consume'].values))))\npna2.set_facecolor('gray')\npij2.set_facecolor('#46bcec')\n\npna2.set_edgecolor('white')\npij2.set_edgecolor('white')\n\nax[1].add_collection(pc)\nax[1].add_collection(pna2)\nax[1].add_collection(pij2)\nax[1].set_title('Log10 annual electricity consumption, 2018')\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n \nmapper.set_array(poly2018['2018_annual_consume'])\n#f.colorbar(mapper, shrink=0.4,ax=ax[1],la)\n","d9fc46f3":"# join all poly_dfs at the hip\n\n# there is a smarter way but im getting tired\nexcludecols = ['shapes', 'ID_2', 'NAME_2', 'provincie', 'netnummer']\nincols = [f for f in poly2011.columns if f not in excludecols]\ncombineddf = poly2018.join(poly2011[incols],how='left')\nyear = '2012'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2012[incols],how='left')\n\nyear = '2013'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2013[incols],how='left')\n\nyear = '2014'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2014[incols],how='left')\n\nyear = '2015'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2015[incols],how='left')\n\nyear = '2016'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2016[incols],how='left')\n\nyear = '2017'\nincols = [year+f[4:] for f in incols]\ncombineddf = combineddf.join(poly2017[incols],how='left')","10488d43":"\"\"\"# alrighty, there's probably a way to do this in a loop, but I'll refrain to the more elaborate way here\nparam = 'smartmeter_perc'\n\nf = plt.figure(figsize = (20,35))\ngs = gridspec.GridSpec(4,2)\n\npatch1 = combineddf[~combineddf['provincie'].isna()] # all others \npatch2 = combineddf[combineddf['provincie'].isna()] # municipalities not having data\npatch3 = combineddf[(combineddf.ID_2==146)|(combineddf.ID_2==400)] #polygons ijsselmeer&zeeuwse meren\n\ny2011 = f.add_subplot(gs[0,0]);year='2011'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2011)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\n#norm = mpl.colors.Normalize(vmin=0, vmax=100)\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2011.add_collection(pc)\ny2011.add_collection(pna)\ny2011.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\n\n\ny2012 = f.add_subplot(gs[0,1]);year='2012'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2012)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2012.add_collection(pc)\ny2012.add_collection(pna)\ny2012.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\ny2013 = f.add_subplot(gs[1,0]);year='2013'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2013)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2013.add_collection(pc)\ny2013.add_collection(pna)\ny2013.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\ny2014 = f.add_subplot(gs[1,1]);year='2014'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2014)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2014.add_collection(pc)\ny2014.add_collection(pna)\ny2014.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\ny2015 = f.add_subplot(gs[2,0]);year='2015'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2015)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2015.add_collection(pc)\ny2015.add_collection(pna)\ny2015.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\ny2016 = f.add_subplot(gs[2,1]);year='2016'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2016)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2016.add_collection(pc)\ny2016.add_collection(pna)\ny2016.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\ny2017 = f.add_subplot(gs[3,0]);year='2017'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2017)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2017.add_collection(pc)\ny2017.add_collection(pna)\ny2017.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\n\n\ny2018 = f.add_subplot(gs[3,1]);year='2018'\nm = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n            projection='merc',\n            lat_0=54.5, lon_0=-4.36,\n            llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2018)\nm.drawmapboundary(fill_color='#46bcec') #46bcec\nm.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\nm.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\nm.drawcoastlines()\n\nnorm = Normalize()\ncmap = plt.get_cmap('RdBu_r') \ncmap = plt.get_cmap('Oranges') \npc = PatchCollection(patch1.shapes,zorder=2)\npna = PatchCollection(patch2.shapes, zorder=2)\npij = PatchCollection(patch3.shapes, zorder=2)\npc.set_facecolor(cmap(norm(patch1[year+'_'+param].values)))\npna.set_facecolor('gray')\npij.set_facecolor('#46bcec')\ny2018.add_collection(pc)\ny2018.add_collection(pna)\ny2018.add_collection(pij)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\nmapper.set_array(combineddf[year+'_'+param])\nplt.colorbar(mapper, shrink=0.4)\nplt.title('Smartmeter percentage, '+year)\"\"\"","b76e0169":"\"\"\"# gonna save some figs here for gifs, \nparam = 'smartmeter_perc';fancy_name = 'Smartmeter percentage'\nparam = 'self_prod_perc';fancy_name = 'Self-production percentage'\nparam = 'annual_consume_lowtarif_perc';fancy_name = 'Lowtarif consumption percentage'\nparam = 'perc_of_active_connections';fancy_name = 'Percentage of active connections'\nparam = 'annual_consume';fancy_name = 'Log10 annual consumption (kWh)'\nparam = 'self_production';fancy_name = 'Log10 self-production (kWh)'\nfor i in range(2011,2019):\n    year = str(i)\n    f = plt.figure(figsize = (10,10))\n    gs = gridspec.GridSpec(1,1)\n\n    patch1 = combineddf[~combineddf['provincie'].isna()] # all others \n    patch2 = combineddf[combineddf['provincie'].isna()] # municipalities not having data\n    patch3 = combineddf[(combineddf.ID_2==146)|(combineddf.ID_2==400)] #polygons ijsselmeer&zeeuwse meren\n\n    y2011 = f.add_subplot(gs[0,0]);\n    m = Basemap(resolution='h', # c, l, i, h, f or None (courseness)\n                projection='merc',\n                lat_0=54.5, lon_0=-4.36,\n                llcrnrlon=3.15, llcrnrlat= 50.7, urcrnrlon=7.3, urcrnrlat=53.84, ax=y2011)\n    m.drawmapboundary(fill_color='#46bcec') #46bcec\n    m.fillcontinents(color='#f2f2f2',lake_color='#46bcec')\n    m.readshapefile('\/kaggle\/input\/municip_shapefile\/NLD_adm2','geometry')\n    m.drawcoastlines()\n\n    #norm = Normalize()\n    norm = mpl.colors.Normalize(vmin=0, vmax=7)\n    cmap = plt.get_cmap('RdBu_r') \n    #cmap = plt.get_cmap('Oranges') \n    pc = PatchCollection(patch1.shapes,zorder=2)\n    pna = PatchCollection(patch2.shapes, zorder=2)\n    pij = PatchCollection(patch3.shapes, zorder=2)\n    pc.set_facecolor(cmap(norm(np.log10(patch1[year+'_'+param].values+0.00001))))\n    pna.set_facecolor('gray')\n    pij.set_facecolor('#46bcec')\n    y2011.add_collection(pc)\n    y2011.add_collection(pna)\n    y2011.add_collection(pij)\n    mapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n    mapper.set_array(combineddf[year+'_'+param])\n    plt.colorbar(mapper, shrink=0.4)\n    plt.title(fancy_name+', '+year)\n    \n    f.savefig(param+'_'+year+'_rdbu.png')\n    plt.close(f)\n\n\"\"\"","dacaa5f3":"\"\"\"\n# step 2: making a gif with the sequence of images:\n\nimport imageio\nimport glob\nfiles = glob.glob(param+'*')\nfiles = np.sort(files)\n# make a copy of each image to slow down gif by factor 2\nfrom shutil import copyfile\nfor file in files:\n    copyfile(file, file.split('.')[0]+'_1.png')\n    copyfile(file, file.split('.')[0]+'_2.png')\n    if '2018' in file:\n        copyfile(file, file.split('.')[0]+'_3.png')\n        copyfile(file, file.split('.')[0]+'_4.png')\nfiles = glob.glob(param+'*')\nfiles = np.sort(files)\nimages = []\nfor file in files:\n    # imageio.imread(file) creates a numpy matrix array\n    # In this case a 200 x 200 matrix for every file, since the files are 200 x 200 pixels.\n    images.append(imageio.imread(file))\n    print(file)\nimageio.mimsave('map_selfprod.gif', images)\n\n# step 3: prep the gif for display in notebook \nfrom IPython.display import Image\nImage(\"map_selfprod.gif\")\"\"\"","6ca79d22":"Ok, so we see above which of the large cities (num_active_connections>5e4) are over\/underperforming compared to the regression performed on all Dutch cities. The largest cities seem to be doing worst in terms of becoming self-reliant, and that mostly has to do with the rapid growth of self-production in smaller towns. Over the years (bottom panel) the growth of self-production in large cities is lower than that of the bigger places, turning most large cities into places that are underperforming compared to the fit. This likely has to do with there being a limit to which urbanized places can become self-reliant (e.g. a flat in a high-rise building will not have the option to place solar panels). On a positive note, three Dutch cities seem to be doing a pretty good job at showing that others could do better: **Almere, Apeldoorn** and **Zwolle**.\n\nMy guess is also that Enexis will have a larger fraction of out\/overperformers than the other two providers. (And as a side note: Eindhoven's data is off, as we see again)","ff76afbf":"Peculiar to see that a very limited number of (random?) towns produce a limited amount of gas?","aa6c23c9":"We see in the t-SNE above that cities cluster together by their size (as the marker size scales with city size) and the provider they have. This because the provider influences parameters such as self-production, smartmeter percentage and lowtarif consumption. This can be an active influence: the amount of effort put into smartmeter implementation - or passive: the geographic location that is fixed and some areas just being more amenable to self-production than others.","aa0cffe4":"Top center cluster, left side:","f1d1d7f6":"What we see is that the yearly total energy consumption has remained roughly the same, while there is a linear increase in the number of connections. This implies that on average the annual amount of electricity used by a connection (=~household) is going down. In addition, the amount of electricity produced by households has been increasing linearly since 2012. At the same time we see that the number of smartmeters is increasing exponentially and one could expect that the number of smartmeters will start approaching the number of connections in the not too far future. ","3dc7ed87":"<a id=\"intro\"><\/a>\n# 1. Introduction\nAs a first approach it suffices to look at the energy parameters at the city level. This is convenient, as we then do not have to start messing around with postal code areas (some of which have been created or shuffled around in the intervening years). We can increase the resolution at a later point if that is of interest, but so for now we can make pivot tables containing the aggregate of an energy parameter of interest, per city per year:","69fb1149":"These mostly seem to be rural places in the (north)east. But let's look at the current top 20 and how they ranked over the past years:","323d7bbf":"<a id=\"geomapping\"><\/a>\n# 6. Geographical projections\n\nAlright, so let's try and project the information at onto a map of the Netherlands, as this could make regional differences clear at a glance. What we have at hand is the polygon structure of the 491 municipalities of the Netherlands which we can project onto a map and e.g. color per province, like such:","69a6586a":"By fitting the \"lagging\" population with a single gaussian and plotting the (normalized) amplitude vs. year, we see a linear decrease. A simple linear fit shows that this peak is likely to become zero within 2 years of the 2018 timepoint, so around the start of 2020.  So in 2020, one can expect the average city to have around 80% smartmeters. This nicely follows Pareto's law (80% of the work done in 20% of the time and vice versa). If we then assume that the remaining 20% will take 80% of the time, and that the transition started around 2012, the Netherlands will be a 100% smartgrid in 8years\/2x8 = 32+2020 = 2052. But this is just a back-of-the-envelope calculation of course. \n\nDoes connection to the smart grid also mean a smarter\/more economical use of electricity? Let's see what the correlation between percent smartmeter and percent lowtarif consumption tells us, per city, with a different color for each provider. Many things can be observed here. In general, we see the smartgrid transition started with a handful of small cities for each provider. The percentage of lowtarif consumption tends to cluster per provider, indicating that there might be different definitions of what lowtarif means. I wonder what's going on with Enexis there.","c9c95a65":"Alright, so now we have all the things at hand to start plotting a bunch of stuff, and below are the maps I thought were worth making. Sequences over time, in spirit of the other images in this analysis. For these maps this gives a more qualitative than a quantitative expression, but insightful nonetheless. Also in a way more informative to see the aggregate information of a municipality instead of for every town and village. \n![](https:\/\/i.imgur.com\/sn27hXs.gif)\n![](https:\/\/i.imgur.com\/CuDeBa6.gif)\n![](https:\/\/i.imgur.com\/KXjwZXZ.gif)\n![](https:\/\/i.imgur.com\/pY6ICM4.gif)\n![](https:\/\/i.imgur.com\/yx5aBAn.gif)\n![](https:\/\/i.imgur.com\/Hn9l5xx.gif)","91bd8c4b":"<a id=\"tsne\"><\/a>\n# 5. Global analysis - feature selection and dimensional reduction\n\nHow similar or different are cities from eachother in terms of electricity consumption and behavior? Are there different classes of cities based on energy parameters? Does the average street in Rotterdam behave differently than the average street in Eindhoven? These are questions one could attempt to answer using principle component analysis (PCA) or other dimensional reduction techniques (e.g. TSNE, UMAP), or at least make classifying easier. Admittedly, there are not too many dimensions that are independent of each other, so one can also answer these questions by juggling around with the data in different ways, but this might become less obvious if you add more parameters such as the gas data or other metadata such as income, house prices, ... That and I just want to apply some things that I use in my genomics research and see how they pan out. ","6af70c2e":"# Analysis items:\n## [1. Introduction: Country-wide picture](#intro)<br>\n## [2. Transition to the smart grid](#smartgrid)<br>\n## [3. Non-centralized electricity production by households](#selfprod)<br>\n## [4. Some individual city stats](#cityviolins)<br>\n## [5. Global analysis - feature selection and dimensional reduction](#tsne)<br>\n## [6. Geographical projections ](#geomapping)<br>\n## [7. Conclusions](#conclusions)<br>","7376cd4e":"<a id=\"smartgrid\"><\/a>\n# 2. Transition to the smart grid\n\nLet's look into the evolution of smartmeters per city for a bit first.","f5de4387":"Squinting at the data one can see that on average, connection to the smartgrid is positively correlated with the percentage of lowtarif consumption. This effect is most prominent for Liander cities, where for instance Amsterdam (biggest orange circle) moves from the bottom left towards the top right as the years pass. That being said, correlation needs not imply causation, as we all know:\n\n![](https:\/\/imgs.xkcd.com\/comics\/cell_phones.png)\n\nOr here is the animated verison again (code commented out below).\n![](https:\/\/i.imgur.com\/teiW0ug.gif)","32ec9f00":"Another convenient way to present this kind of data - I find - is to save a sequence of images like those above as a gif (or movie), for instance using the [imageio](http:\/\/https:\/\/imageio.github.io) package, like so (code commented out below):\n![](https:\/\/i.imgur.com\/MsOXTk7.gif)","28bc86de":"I'm going to ignore that for now. ","4e34d98a":"Right side cluster:","d3a7c360":"Now comes the hard part: aggregating the information from the 2469 unique cities in the dataset into the 491 municipalities. Without going into a manual adding of geolocation and municipality each city belongs to of course. The easiest way of doing this I found was by using the 4-digit postal codes. I obtained a list of the 4-digit postal code location [here](https:\/\/github.com\/bobdenotter\/4pp). This allows me to easily merge the energy dataframe (grouped by the 4-digit postal codes with relevant parameters summed or averaged) with geolocation per postal code. We get:","21738531":"What we see is that over the past 7 years the slope of the fit became less negative. The negative initial slope (at 2012) makes sense as it is much easier for small towns to get a relatively high percentage of self-produced electricity than it is for large places. As self-production is a nation-wide trend, it is also logical that the slope of the fit becomes less negative, as the larger places catch up as the years pass. However, the rate at which the slope increases is slowing down and it seems like this slope-of-slopes might be asymtotic at a negative value. This could be logical, as it is probably impossible for large cities to be as self-reliant when it comes to electricity production as smaller towns are (i.e. in the limit of 100% urbanization, which might mean 100% high-rise buildings, it is likely impossible for each apartment building to produce its own electricity (with current technologies at hand, that is.)).\n\nLet's look at the largest Dutch cities and where they stand. We could for instance classify cities into over- or underperforming when above or below the linear regression by a certain amount, as shown below (gray is neither over or underperforming (arbitrary offset chosen here). ","1a3f1ff0":"<a id=\"cityviolin\"><\/a>\n# 4. City stats","eae5b3fa":"Extrapolation of the fit $y=mx+b$ to the data (below, right) would suggest that the median reaches 50% self-production in $\\frac{50-b}{m}\\approx2041$. But this might level off way before that due to technical hurdles, revoking of subsidies or other regulations in the meantime. It's hard for me to assess what factors put a cap on (or speed up?) this trend at the moment.\n\nBy looking at the data per provider, we can get an idea of how different regions of the Netherlands are performing with respect to one-another. [Amsterdam=liander, Rotterdam=stedin, the east and north = enexis] We can see that self-production is a growing trend in all regions, but that the Enexis region is outperforming the other regions likely because there is more space to place windmills or solar panels. Self production became a thing roughly in 2012.","97cbfef8":"Indeed there is, strange. I will leave this as is and continue with the global analysis below.","b75bfbc5":"We can also look at the importance of parameters using PCA:","bc89786c":"<a id=\"selfprod\"><\/a>\n# 3. Non-centralized electricity production by households \n\nLet's look at electricity production per city for a bit now.","589b34c8":"Ok, let's look at the correlation between self production and city size for a bit more, as we have seen above that it is easier for smaller, more rural places to become more self-reliant when it comes to electricity. Perhaps the city size is a reasonable proxy as to what degree a city can produce its own energy (though I suspect building structure, climate etc also play a crucial role), as for instance it might turn out that in the limit of large cities, it is just more efficient to have a majority of the electricity produced in a centralized manner.","d4d1d4fb":"First of all, we see that the distribution is bimodal (2018 shown here): a population of early adopters and a lagging population. It is interesting to look into this - as in: what type of city can be typically found in one or the other - further below. First let's see at what year, given the decline rate of the lagging mode, we expect all cities to have ~80% smartmeters. If we normalize the area under the curve we can fit the data.\n\nAnother observation would be that of the three large electricity providers, Enexis is leading the transition to the smart grid.","27e1b2d2":"Perhaps it is more interesting to not let city size weigh in so much, so let's select the features that are normalized (the percentages), these also happen to be the features with the highest variance, which implies these will be more defining of a given city than features with less variance. ","aa637546":"What we see here is that there is indeed a negative correlation between city size and the percentage of energy that is self-produced. ","715dee99":"<a id=\"conclusions\"><\/a>\n# 7. Conclusions:\n* Total electricity consumption seems have been roughly constant over the past decade, or even a slight decline in the \"randstad\" (Liander&Stedin).\n* This while the number of connections is growing linearly, **so the consumption per connection ($\\approx$household) seeminly decreased**, possibly by large-scale introduction of more energy-efficient products such as the LED light. **\n* There are other exciting developments unfolding now, such as **transition to a smart grid** as well as the emergence of a significant fraction of **self-production of electricity by households**. \n* Of the three providers, Enexis seems to be leading these transitions - this might be due to the different makeup of the Enexis territory compared to that of Liander and Stedin (the latter two cover the more densely populated randstad).\n* Within two years of the 2018 dataset it is expected that almost all cities will have >50% (or actually around 80%) smartmeter percentages. **It seems like the 80% smartmeters by 2020 is within reach** The complete transition (to 100%) might take an additional 3 decades.\n* The self-production fraction (as the median of the % of total consumption for all cities combined) has been increasing linearly from <1% in 2012 to $\\sim$10% now. At this rate a median of 50% is expected to be reached by 2041.\n* Leaders in the self-production transition are smaller places in rural areas, **especially in Groningen**, but the large cities at the top of the list in absolute terms, with many of them having been in the top 10 absolute self-producers since the beginning of this revolution in 2012.\n\n** Though the percentage of active connections seems to decrease as well, as we see in the last map directly above.\n\n\nTechnical issues with the dataset:\n* The province of Zeeland seems to be missing entirely, but this could be due to there being a fourth provider \n* Something is wrong with the historical (pre-2017) data for Eindhoven\n* Some cities seem to have multiple providers. This might actually be true, but seems unlikely for some larger cities in Enexis territory like Weert and Deventer\n* Some cities seem to be producing gas, this seems unlikely\n* There are many minor errors, such as 's Gravenhage appearing more than once (but overall I ignore this since there is one 's Gravenhage that is the right size, the others are almost negligibly small.\n\n\n","10bbe0cd":"We see that the early adopters in self-production of electricity - like Amersfoort, The Hague, Rotterdam, Zoetermeer - are still in the top absolute energy producers of 2018, but we also see several other big cities (Eindhoven (something is wrong with pre-2017 data), Tilburg, Zwolle, Maastricht) catch up, starting around 2012.  What is the mean or median fraction of self-produced energy (as a function of the electricity consumed) for the Dutch cities in 2018? We can see that for all Dutch cities combined, the percentage self-produced follows a log-normal distribution centered around 10% in the most recent year of this dataset (below, left), and that the median of this distribution shifts upward linearly with time, starting around 2012. ","153dad0a":"Ok, so coloring the t-SNE by the values of the independent parameters, we get an idea of why the cities are grouped together in a certain way. For instance region 1 (indicated in top left) is a cluster of tiny cities that have a very high percentage of self-production, which we saw earlier. There are also some other small towns with a high percentage of self-production (towards upper right corner of plot), but these are different in other ways, as the remaining subplots show.  Two groups containing fairly large cities (region 2 and 3) do not cluster together with the other large cities in the middle. It is clear from the smartmeter subplot that these are the leading cities in terms of smartmeters, but they are different from each other in terms of lowtarif consumption percentage (which tends to be provider-specific).","da63bf13":"Interesting, these are all cities literally deep within Enexis territory, so perhaps there is some overlap?","bea0f9d7":"Above we see that each city can have its own specific dynamics. Here I chose to display only those parameters that are on the percentage scale, mainly out of laziness. One could also normalize other data to visualize it in this manner of course. As delivery % = 100 - self-production %, these graphs have a bit of redundancy in them.","618c51bf":"For those who have stared at a map of the Netherlands more than once, it becomes pretty clear that the entire province of Zeeland is missing(!). It turns out **Zeeland is not part of the electricity dataset**. They might have a different provider.  Anyway, ignoring this, I think we now have at hand the right information to start binning the postal code based information into the polygons of the 491 municipalities minus Zeeland. This involves determining which postal codes belong to which polygon. Exellent documentation on how to determine wheter a point falls within a polygon can be found [here](http:\/\/https:\/\/automating-gis-processes.github.io\/CSC18\/lessons\/L4\/point-in-polygon.html), and everything is summarized into the functions I wrote above.","f484d45e":"Ok, so the 'year' 2009 - which allegedly covers the consumption in the year before (which is why I changed the x-axis in the plot) - seems to be incomplete. I will therefore drop this year in all following electricity analyses.\n\nFirst, let's have a look at the country as a whole:","45f48479":"Alright, so here we see the large cities cluster into roughly 4 or 5 regions, and we see (especially clear from the first panel) that they group based on other parameters besides size. These other parameters are of course the features we used to perform our dimensional reduction on, the percentages of: lowtarif consumption, self-production, active connections and smartmeters. From the top middle we see that the large cities do not really distinguish themselves in terms of self-production. **So the defining features are: lowtarif consumption, active connections and smartmeter percentage**. Top right shows that two groups have a high fraction of smartmeters compared to the rest. Lowtarif consumption (bottom left panel) we see the approximate Enexis -  non-Enexis divide again, but splitting one of the 4 major clusters down the middle (hence I think it is justified to call 5 clusters of large cities here). Bottom middle we see the percentage of active connections is higher among the Enexis (left two) clusters. \n\nThis is all great, but it would be insightful to see which cities are representative of these 5 clusters, and perhaps color them geographically to gain more insight as to why certain cities have certain feature values. \n\nBottom left Enexis cluster:","d82f36f9":"Middle left Enexis cluster:","f47af2e8":"By just joining these two datasets, I have noticed there is an outersect between the cities in gas and electricity:","0a7fb0f8":"Version 3 of the notebook, new features are: \n*  a more elaborate feature selection in the dimensional reduction section\n*  data visualization by projecting the data on a map \n\nTook some time to figure out, and there are definitely many more possible approaches than this, but it's a good first try. Let me know what you think!","04c78f0e":"Top center cluster, right side:","253594d2":"Again we see cities clustering by size and the parameters being provider-specific. This might be an artifact (providers have different definitions\/ ways of classifying things) or represent the different ways in which the companies operate. We could also do this for the individual postal code areas in two cities that are of similar size but divergent otherwise, or cities that are very alike. But I'll leave it as is for now.","7660557e":"We see now that the cities cluster less by size than in the first round, and still largely cluster by provider, and more specifically by Enexis vs. non-Enexis. Why that is we'll see in the multi-panel figure below. Interesting to note is that there are a couple of large non-Enexis cities deep within Enexis territory, let's see who they are:","2211338c":"We see that in absolute terms Almere is the biggest producer of energy. When normalized by the number of active connections (which is - I think -  a proxy for the number of inhabitants) this yields the average electricity produced per household per city. The larger cities in the 'randstad' move down the ladder. If we take the actual top 20 cities with the highest average electricity production per household, we expect this ranking to be dominated by small towns in windy (rural) places:","02ba268d":"Fitting the data shows that the number of smartmeters should reach the total number of connections in mid 2018. We probably could also have gotten this from the percent of smartmeters parameter in the first place, but let's look at this in greater detail, because simply taking the countrywide mean here oversimplifies what is actually going on. \n\nFor instance, one can notice an increasing discrepancy between the mean and median (of the mean) percentage of smartmeters. This is an indication that we are not dealing with a normal distribution of these things across the cities, which is not a surprise in itself.","a393c126":"\nPerhaps adding some gas parameters would make it more interesting."}}