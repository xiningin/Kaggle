{"cell_type":{"5b272868":"code","52819ae2":"code","c96bfbf9":"code","d4ee25f1":"code","285b369a":"code","c62efee5":"code","04eb54c3":"code","7789a219":"code","143f930a":"code","552a02e7":"code","08bd205a":"code","0bc6f4e7":"code","aa956d61":"code","d0a73305":"code","ec05d066":"code","7d38b86c":"code","b412408d":"code","0a7321b2":"code","a6c9dfb5":"code","2f3d88a5":"code","8f9b9d80":"code","dc192e5f":"code","da3d159e":"code","30298c80":"code","05714919":"code","8637b292":"code","17275d34":"code","6df0878e":"code","5e0005ee":"code","209c4cb2":"code","2fee39f6":"code","59f6f891":"markdown","235790db":"markdown","e312c72c":"markdown","e7a3d6f6":"markdown","b79aabd6":"markdown","d5f4c972":"markdown","2f9b6f02":"markdown","6ea3ebaa":"markdown","1f3f4daa":"markdown","7b7cedc9":"markdown","cba3c14e":"markdown","07282f75":"markdown","69bdb616":"markdown","60e3107e":"markdown","2679c3e7":"markdown","f2bd9332":"markdown","c0db38ea":"markdown","d3492afc":"markdown","0748e2b7":"markdown","48842548":"markdown","0eff159a":"markdown"},"source":{"5b272868":"# https:\/\/www.kaggle.com\/bonhart\/brain-tumor-multi-class-segmentation-baseline\n%%time\n\nimport numpy as np\n\nimages = np.load(\"\/kaggle\/input\/brain-tumor\/brain_tumor_dataset\/images.npy\", allow_pickle=True)\nmasks = np.load(\"\/kaggle\/input\/brain-tumor\/brain_tumor_dataset\/masks.npy\", allow_pickle=True)\nlabels = np.load(\"\/kaggle\/input\/brain-tumor\/brain_tumor_dataset\/labels.npy\")\ninteger_to_class = {1: 'meningioma', 2: 'glioma', 3: 'pituitary tumor'}\n\nprint(f\"images:{images.shape}, \\\nmasks:{masks.shape}, \\\nlabels:{labels.shape}\")","52819ae2":"data = np.column_stack((images, masks, labels))\ndata.shape","c96bfbf9":"from sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(data, test_size=0.08, random_state=42)\ntrain_data, test_data = train_test_split(train_data, test_size=0.12, random_state=42)\n\nprint(\"Train:\", train_data.shape,\n      \"\\nVal:\", val_data.shape, \n      \"\\nTest:\", test_data.shape,)","d4ee25f1":"import matplotlib.pyplot as plt\nplt.style.use(\"dark_background\")\n\n# https:\/\/www.kaggle.com\/awsaf49\/brain-tumor-visualization\/data\n\nlabels, counts = np.unique(data[:,2], return_counts=True)\n\nplt.figure(figsize=(10,6))\nplt.bar(labels, counts, color=[\"aqua\", \"violet\", \"greenyellow\"],\n        tick_label=['Meningioma(1)', 'Glioma(2)', 'Pituitary Tumor(3)'])\n\n\n# Annotate\nfor row, value in zip(labels,counts):\n    plt.annotate(int(value), xy=(row, value-150), \n                rotation=0, color=\"black\", \n                ha=\"center\", verticalalignment='bottom', \n                fontsize=15, fontweight=\"bold\")","285b369a":"import cv2\n\ndef data_to_viz(data, label, n=5):\n    \n    # logical slice for receiving data with the expected label\n    expected_index = np.where(data[:,2] == label)\n    expected_data = data[expected_index]\n    \n    # n random samples\n    index = np.random.choice(expected_data.shape[0], n, replace=False)\n    data_to_viz = expected_data[index]\n    \n    imgs = []\n    masks = []\n    labels = []\n    for data_i in data_to_viz:\n        \n        # img\n        imgs.append(cv2.resize(data_i[0], (512, 512)))\n\n        # mask\n        masks.append(cv2.resize(data_i[1].astype(\"uint8\"), \n                                (512, 512)))\n\n        # label\n        labels.append(data_i[2])\n\n    return np.hstack(imgs), np.hstack(masks), labels","c62efee5":"meningiomas_imgs, meningiomas_masks, meningiomas_labels = data_to_viz(data, label=1, n=5)\nglioma_imgs, glioma_masks, glioma_labels  = data_to_viz(data, label=2, n=5)\ntumor_imgs, tumor_masks, tumor_labels = data_to_viz(data, label=3, n=5)\n\nprint(\"Meningiomas:\",\n      meningiomas_imgs.shape, meningiomas_masks.shape, meningiomas_labels)\nprint(\"Glioma:\",\n      glioma_imgs.shape, glioma_masks.shape, glioma_labels)\nprint(\"Pituitary Tumor:\",\n      tumor_imgs.shape, tumor_masks.shape, tumor_labels)","04eb54c3":"# Data to visualization\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\n# Plot\nfig = plt.figure(figsize=(25., 25.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(3, 1),  # creates 1x4 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\n\ngrid[0].imshow(meningiomas_imgs, cmap=\"bone\")\ngrid[0].imshow(np.ma.masked_where(meningiomas_masks == False, \n                                  meningiomas_masks), cmap='rainbow', alpha=0.3)\n\ngrid[0].set_title(\"Meningiomas\", fontsize=20)\ngrid[0].axis(\"off\")\n\ngrid[1].imshow(glioma_imgs, cmap=\"bone\")\ngrid[1].imshow(np.ma.masked_where(glioma_masks == False,\n                                  glioma_masks), cmap='rainbow', alpha=0.3)\ngrid[1].set_title(\"Glioma\", fontsize=20)\ngrid[1].axis(\"off\")\n\ngrid[2].imshow(tumor_imgs, cmap=\"bone\")\ngrid[2].imshow(np.ma.masked_where(tumor_masks == False,\n                                  tumor_masks), cmap='rainbow', alpha=0.3)\n\ngrid[2].set_title(\"Pituitary Tumor\", fontsize=20)\ngrid[2].axis(\"off\")\n\n\n# annotations\nplt.suptitle(\"Brain MRI Images for Brain Tumor Detection\\nBrainTumorRetrieval Dataset\",\n             y=.80, fontsize=30, weight=\"bold\")\n\n# save and show\nplt.savefig(\"dataset.png\", pad_inches=0.2, transparent=True)\nplt.show()","7789a219":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensor\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","143f930a":"class BrainMriDataset(Dataset):\n    def __init__(self, data, transforms, n_classes=3):\n        \n        self.data = data\n        self.transforms = transforms\n        self.n_classes = n_classes\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n\n        image = self.data[idx][0].astype(\"float32\")\n\n        # global standardization of pixels\n        mean, std = image.mean(), image.std()\n        image = (image - mean) \/ std\n        \n        # convert to rgb\n        image_rgb = np.stack([image]*3).transpose(1,2,0)\n        \n        # create target masks\n        label = self.data[idx][2] -1\n        mask = np.expand_dims(self.data[idx][1], -1)\n        \n        target_mask = np.zeros((mask.shape[0], mask.shape[1], \n                                self.n_classes))\n        target_mask[:,:, label : label + 1] = mask.astype(\"uint8\")\n        \n        #  binary mask\n        target_mask = np.clip(target_mask, 0, 1).astype(\"float32\")\n        \n        # augmentations\n        augmented = self.transforms(image=image_rgb, \n                                    mask=target_mask)\n        image = augmented['image']\n        mask = augmented['mask']\n        \n        return image, mask","552a02e7":"transforms = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, \n                       border_mode=0),\n                        \n    A.GridDistortion(p=0.5),\n    A.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n    A.Resize(156, 156, p=1.),\n    A.RandomCrop(128, 128, p=1.)\n    ])","08bd205a":"# train\ntrain_dataset = BrainMriDataset(data=train_data, transforms=transforms)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, num_workers=4, \n                              shuffle=True)\n\n# validation\nval_dataset = BrainMriDataset(data=val_data, transforms=transforms)\nval_dataloader = DataLoader(val_dataset, batch_size=16, num_workers=4, \n                            shuffle=True)\n\n# test\ntest_dataset = BrainMriDataset(data=test_data, transforms=transforms)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, num_workers=4, \n                             shuffle=True)","0bc6f4e7":"def show_aug(inputs, nrows=3, ncols=5, image=True):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 15:\n        inputs = inputs[:15]\n        \n    for idx in range(len(inputs)):\n    \n        # normalization\n        if image is True:           \n            img = inputs[idx].numpy()#.transpose(1,2,0)\n            #mean = [0.485, 0.456, 0.406]\n            #std = [0.229, 0.224, 0.225] \n            #img = (img*std+mean).astype(np.float32)\n            #img = np.clip(img, 0,1)\n        else:\n            img = inputs[idx].numpy().astype(np.float32)\n            img = img[0,:,:]\n        \n        #plot\n        #print(img.max(), len(np.unique(img)), img.mean())\n        plt.subplot(nrows, ncols, i_+1)\n        plt.imshow(img); \n        plt.axis('off')\n \n        i_ += 1\n        \n    return plt.show()\n\n    \nimages, masks = next(iter(train_dataloader))\nprint(images.shape, masks.shape)\n\nshow_aug(images)\nshow_aug(masks)\n","aa956d61":"from torchvision.models import resnext50_32x4d\n\nclass ConvRelu(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel, padding):\n        super().__init__()\n\n        self.convrelu = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.convrelu(x)\n        return x\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        \n        self.conv1 = ConvRelu(in_channels, in_channels \/\/ 4, 1, 0)\n        \n        self.deconv = nn.ConvTranspose2d(in_channels \/\/ 4, in_channels \/\/ 4, kernel_size=4,\n                                          stride=2, padding=1, output_padding=0)\n        \n        self.conv2 = ConvRelu(in_channels \/\/ 4, out_channels, 1, 0)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.deconv(x)\n        x = self.conv2(x)\n\n        return x","d0a73305":"class ResNeXtUNet(nn.Module):\n\n    def __init__(self, n_classes):\n        super().__init__()\n        \n        self.base_model = resnext50_32x4d(pretrained=True)\n        self.base_layers = list(self.base_model.children())\n        filters = [4*64, 4*128, 4*256, 4*512]\n        \n        # Down\n        self.encoder0 = nn.Sequential(*self.base_layers[:3])\n        self.encoder1 = nn.Sequential(*self.base_layers[4])\n        self.encoder2 = nn.Sequential(*self.base_layers[5])\n        self.encoder3 = nn.Sequential(*self.base_layers[6])\n        self.encoder4 = nn.Sequential(*self.base_layers[7])\n\n        # Up\n        self.decoder4 = DecoderBlock(filters[3], filters[2])\n        self.decoder3 = DecoderBlock(filters[2], filters[1])\n        self.decoder2 = DecoderBlock(filters[1], filters[0])\n        self.decoder1 = DecoderBlock(filters[0], filters[0])\n\n        # Final Classifier\n        self.last_conv0 = ConvRelu(256, 128, 3, 1)\n        self.last_conv1 = nn.Conv2d(128, n_classes, 3, padding=1)\n                       \n        \n    def forward(self, x):\n        # Down\n        x = self.encoder0(x)\n        e1 = self.encoder1(x)\n        e2 = self.encoder2(e1)\n        e3 = self.encoder3(e2)\n        e4 = self.encoder4(e3)\n\n        # Up + sc\n        d4 = self.decoder4(e4) + e3\n        d3 = self.decoder3(d4) + e2\n        d2 = self.decoder2(d3) + e1\n        d1 = self.decoder1(d2)\n        #print(d1.shape)\n\n        # final classifier\n        out = self.last_conv0(d1)\n        out = self.last_conv1(out)\n        out = torch.sigmoid(out)\n        \n        return out\n","ec05d066":"def dice_coef_metric(inputs, target):\n    intersection = 2.0 * (target * inputs).sum()\n    union = target.sum() + inputs.sum()\n    if target.sum() == 0 and inputs.sum() == 0:\n        return 1.0\n\n    return intersection \/ union\n\ndef dice_coef_loss(inputs, target):\n    num = target.size(0)\n    inputs = inputs.reshape(num, -1)\n    target = target.reshape(num, -1)\n    smooth = 1.0\n    intersection = (inputs * target)\n    dice = (2. * intersection.sum(1) + smooth) \/ (inputs.sum(1) + target.sum(1) + smooth)\n    dice = 1 - dice.sum() \/ num\n    return dice\n\ndef bce_dice_loss(inputs, target):\n    dicescore = dice_coef_loss(inputs, target)\n    bcescore = nn.BCELoss()\n    bceloss = bcescore(inputs, target)\n\n    return bceloss + dicescore","7d38b86c":"model = ResNeXtUNet(n_classes=3).to(device)\nadam = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(adam, step_size=10, gamma=0.1)","b412408d":"def train_one_epoch(model, optimizer, lr_scheduler, data_loader, epoch):\n    print(\"Start Train ...\")\n    model.train()\n\n    losses = []\n    accur = []\n\n    for data, target in data_loader:\n\n        data = data.permute(0,3,1,2).to(device)\n        targets = target.permute(0,3,1,2).to(device)\n\n        outputs = model(data)\n\n        out_cut = np.copy(outputs.data.cpu().numpy())\n        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n\n        train_dice = dice_coef_metric(out_cut, targets.data.cpu().numpy())\n\n        loss = bce_dice_loss(outputs, targets)\n\n        losses.append(loss.item())\n        accur.append(train_dice)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    print(\"Epoch [%d]\" % (epoch))\n    print(\"Mean loss on train:\", np.array(losses).mean(), \"Mean DICE on train:\", np.array(accur).mean())\n\n    return np.array(losses).mean(), np.array(accur).mean()","0a7321b2":"def val_epoch(model, data_loader_valid, epoch, threshold=0.3):\n    if epoch is None:\n        print(\"Test Start...\")\n    else:\n        print(\"Start Validation ...\")\n\n    model.eval()\n    val_acc = []\n\n    with torch.no_grad():\n        for data, targets in data_loader_valid:\n\n            data = data.permute(0,3,1,2).to(device)\n            targets = targets.permute(0,3,1,2).to(device)\n\n            outputs = model(data)\n\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            val_dice = dice_coef_metric(out_cut, targets.data.cpu().numpy())\n            val_acc.append(val_dice)\n\n        print(\"Epoch:  \" + str(epoch) + \"  Threshold:  \" + str(threshold)\\\n              + \" Mean Validation DICE Score:\", np.array(val_acc).mean())\n        \n        return np.array(val_acc).mean()","a6c9dfb5":"from tqdm import trange\nimport os\nimport glob\n\nweights_dir = \"weights\"\nif os.path.exists(weights_dir) == False:\n    os.mkdir(weights_dir)\n\nnum_epochs = 30\nloss_history = []\ntrain_dice_history = []\nval_dice_history = []\n\nfor epoch in trange(num_epochs):\n    loss, train_dice = train_one_epoch(model, adam, scheduler, \n                                       train_dataloader, epoch)\n    \n    val_dice = valscore = val_epoch(model, val_dataloader, epoch)\n\n    # train history\n    loss_history.append(loss)\n    train_dice_history.append(train_dice)\n    val_dice_history.append(val_dice)\n\n    # save best weights\n    best_dice = max(val_dice_history)\n    if val_dice >= best_dice:\n        torch.save({'state_dict': model.state_dict()},\n                   os.path.join(weights_dir, f\"{val_dice:0.5f}_.pth\"))\n","2f3d88a5":" # Dirty tricks\n\"\"\" with torch.no_grad():\n        for data, targets in data_loader_valid:\n            data = data.permute(0,3,1,2).to(device)\n            outputs = model(data)\n\n\nmodel.eval()\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n     m.track_runing_stats=False\"\"\";","8f9b9d80":"# Load the best weights\nbest_weights =  sorted(glob.glob(weights_dir + \"\/*\"),\n                       key= lambda x: x[8:-5])[-1]\ncheckpoint = torch.load(best_weights)\nmodel.load_state_dict(checkpoint['state_dict'])\n\nprint(f'Loaded model: {best_weights.split(\"\/\")[1]}')","dc192e5f":"def plot_model_history(train_history,\n                       val_history,\n                       loss_history ,\n                       num_epochs):\n    \n    x = np.arange(num_epochs)\n\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n    plt.plot(x, loss_history, label='dice + bce', lw=3)\n\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"DICE\", fontsize=15)\n    plt.legend()\n\n    return plt.show()","da3d159e":"plot_model_history(train_dice_history, val_dice_history, loss_history, num_epochs)","30298c80":"test_iou = val_epoch(model, test_dataloader, epoch=None, threshold=0.5)\nprint(f\"\"\"Mean IoU of the test images - {np.around(test_iou, 2)*100}%\"\"\")","05714919":"dices = []\nthresholds = [0.1, 0.2, 0.33, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.88]\nfor i in thresholds:\n    test_dice = val_epoch(model, test_dataloader,threshold=i, epoch=None)\n    dices.append(test_dice)","8637b292":"import random\nimport matplotlib.colors as mcolors\n\ncolors = random.choices(list(mcolors.CSS4_COLORS.keys()),k=len(thresholds))\n\nplt.figure(figsize=(10,6))\nplt.bar(thresholds, dices, width=0.05, color=colors)\nplt.ylabel(\"Dice\", fontsize=15)\nplt.xlabel(\"Threshold values\", fontsize=15)\nplt.title(\"Global IoU with different thresholds\", fontsize=15)\n\n\n# Annotate\nfor row, value in zip(thresholds, dices):\n    plt.annotate(f\"{value*100:0.2f}%\", xy=(row, value), \n                 rotation=0, color=\"white\", \n                 ha=\"center\", verticalalignment='bottom', \n                 fontsize=10, fontweight=\"bold\")","17275d34":"test_predictions = []\ntest_ground_truths = []\nfor data, target in test_dataloader:\n    with torch.no_grad():\n        data = data.permute(0,3,1,2).to(device)\n        target = target.permute(0,3,1,2)\n        prediction = model(data)\n        test_predictions.append(prediction.detach().cpu())\n        test_ground_truths.append(target)","6df0878e":"test_predictions = torch.cat(test_predictions)\ntest_ground_truths = torch.cat(test_ground_truths)\n#test_predictions = test_predictions.reshape(test_predictions.shape[0], -1)\n#test_ground_truths = test_ground_truths.reshape(test_ground_truths.shape[0], -1)\n\nprint(test_predictions.shape, test_ground_truths.shape)","5e0005ee":"# data\ndice1 = dice_coef_metric(test_predictions[:,0,:,:], test_ground_truths[:,0,:,:])\ndice2 = dice_coef_metric(test_predictions[:,1,:,:], test_ground_truths[:,1,:,:])\ndice3 = dice_coef_metric(test_predictions[:,2,:,:], test_ground_truths[:,2,:,:])\ndices = [dice1, dice2, dice3]\n\n# x, y\nx = np.arange(3)\ndices = [dice1, dice2, dice3]\n\n# plot\nplt.figure(figsize=(10, 6))\nplt.bar(x, dices, \n        color=[\"aqua\", \"violet\", \"greenyellow\"], width=0.5)\n\n                                        \nplt.xticks(x, ['Meningioma(1)', 'Glioma(2)', 'Pituitary Tumor(3)'], fontsize=15)\nplt.ylabel(\"Dice\", fontsize=15)\nplt.title(\"Dice for each class\", fontsize=15)\n\n\n# Annotate\nfor row, value in zip(x, dices):\n    plt.annotate(f\"{value*100:0.3f}%\", xy=(row, value), \n                 rotation=0, color=\"white\", \n                 ha=\"center\", verticalalignment='bottom', \n                 fontsize=10, fontweight=\"bold\")\n    \nplt.show()","209c4cb2":"index = np.random.choice(test_data.shape[0], 1, replace=False)\n\n# image\nimage = test_data[index][0][0]\n\n# global standardization of pixels\nmean, std = image.mean(), image.std()\nimage = (image - mean) \/ std  \nimage = cv2.resize(image, (128, 128))\n# convert to rgb\nimage = np.stack([image]*3).transpose(1,2,0)\n\n# mask\nmask = test_data[index][0][1]\n\n# label\nlabel = test_data[index][0][2]\n\nprint(image.shape, mask.shape, label)","2fee39f6":"#----------- Data -------------#\n\n# predictions\npreds = torch.tensor(image.astype(np.float32)).unsqueeze(0).permute(0,3,1,2)\npreds = model(preds.to(device))\npreds = preds.detach().cpu().numpy()\n\n# threshold\npreds[np.nonzero(preds < 0.4)] = 0.0\npreds[np.nonzero(preds >= 0.4)] = 255.#1.0\npreds = preds.astype(\"uint8\")\n\npred_1 = preds[:,0,:,:]\npred_2 = preds[:,1,:,:]\npred_3 = preds[:,2,:,:]\n\n\n#------------ Plot ------------#\n\n# data plot\nfig, ax = plt.subplots(nrows=1,  ncols=2, figsize=(10, 10))\n\nax[0].imshow(image)\nax[0].set_title(\"Image\")\nax[1].imshow(mask)\nax[1].set_title(f'Ground Truth with label \"{integer_to_class[label].capitalize()}\"')\n#ax[1].imshow(preds[0,:,:,:])\n#ax[0].set_title(\"Preiction\")\nplt.suptitle(\"Random Test Sample\",\n             y=.75, fontsize=20, weight=\"bold\")\n\n# prediction plot\nfig, ax = plt.subplots(nrows=1,  ncols=3, figsize=(10, 10))\n\nax[0].imshow(pred_1[0,:,:])\nax[0].set_title(f'{integer_to_class[1].capitalize()}')\nax[1].imshow(pred_2[0,:,:])\nax[1].set_title(f'{integer_to_class[2].capitalize()}')\nax[2].imshow(pred_3[0,:,:])\nax[2].set_title(f'{integer_to_class[3].capitalize()}')","59f6f891":"### Random test sample","235790db":"### Class distribution","e312c72c":"### Data Generators","e7a3d6f6":"### Global IoU with different thresholds","b79aabd6":"# UNet","d5f4c972":"# Data","2f9b6f02":"Plot","6ea3ebaa":"# Test prediction","1f3f4daa":"# Datataset and DataGenerator","7b7cedc9":"### Samples of images of each class","cba3c14e":"Since the net did not reach a plateau, batch norm layers did not accumulate stable statistics; therefore, saved model weights in the early steps of the train loop - shows worse results, how to fix it? reach a plateau or go forward several epochs with ```torch.no_grad_():``` (dirty tricks) before saving weights or before switching the model to eval mode ```model.eval()``` for the weights that are.","07282f75":"### IoU for each class\n","69bdb616":"# Metric and Loss","60e3107e":"# What does the data look like?","2679c3e7":"### Data Transformation","f2bd9332":"# Train Model","c0db38ea":"Stacking rows as a data frame.","d3492afc":"Split data on train val test","0748e2b7":"Data","48842548":"### This kernel is fork of [this](https:\/\/www.kaggle.com\/bonhart\/brain-mri-data-visualization-unet-fpn#DataGenerator-and-Data-Augmentation) kernel.\n\n### Steps:\n+ Data Preparation\n+ Visualization data\n+ Datataset and DataGenerator\n+ UNet\n+ Train model\n+ Test predictions","0eff159a":"### Train history"}}