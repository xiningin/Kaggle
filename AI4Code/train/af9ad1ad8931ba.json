{"cell_type":{"3f173461":"code","a3243d27":"code","4f8dc294":"code","88feb3e9":"code","7bbd04f7":"code","6a6b7f38":"code","6bc39d36":"code","5aa54234":"code","17fac3f6":"code","9dd177e4":"code","9662b50b":"code","dfa617ab":"code","0509e352":"code","61ed5ba0":"code","3b8faf3b":"code","e89ec429":"code","9c08de9a":"code","bd5e077c":"code","95262b96":"code","09993b7a":"code","bd6cfade":"code","781ed715":"code","5a6f53bf":"code","9bfba620":"markdown","ea550f5b":"markdown","63c236e5":"markdown","bc18a09a":"markdown"},"source":{"3f173461":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a3243d27":"import os\nimport shutil\nimport re\nimport math\n\nimport pandas as pd\nimport numpy as np\n\nimport PIL.Image\n\nfrom random import shuffle\nfrom glob import glob\n\nfrom sklearn.model_selection import train_test_split\n\n#from tensorflow.python.keras.applications import VGG16\n\nfrom keras.applications import VGG16\n\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\n#from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nfrom keras import models\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom keras.optimizers import Adam","4f8dc294":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","88feb3e9":"df.diagnosis.value_counts()","7bbd04f7":"image_train, image_test, y_train, y_test = train_test_split(np.array(df.path), \n                                                            np.array(df.diagnosis), \n                                                            test_size=0.3,\n                                                            random_state=123, \n                                                            stratify=df.diagnosis)","6a6b7f38":"image_train","6bc39d36":"image_and_class_train = dict(zip(image_train, y_train))\nimage_and_class_test = dict(zip(image_test, y_test))","5aa54234":"IMG_SIZE = (224, 224)  # \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0438\nNUM_CLASSES = 5        # \u0447\u0438\u0441\u043b\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432","17fac3f6":"# \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c\ndef load_image(path, target_size=IMG_SIZE):\n    img = load_img(path, target_size=target_size)  # \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n    array = img_to_array(img)\n    return preprocess_input(array)  # \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u043b\u044f VGG16","9dd177e4":"# \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0442\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0434\u0438\u0441\u043a\u0430\ndef fit_generator(files, batch_size=32):\n    while True:\n        shuffle(files)\n        for k in range(math.ceil(len(files) \/ batch_size)):   # \u043e\u043a\u0440\u0443\u0433\u043b\u044f\u0435\u043c \u0434\u043e \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u0433\u043e \u0446\u0435\u043b\u043e\u0433\u043e \u0432\u0432\u0435\u0440\u0445\n            i = k * batch_size                                # k -- \u043d\u043e\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 \u0432 \u043f\u0440\u043e\u0445\u043e\u0434\u0435                      \n            j = i + batch_size\n            if j > len(files):\n                j = len(files)\n            x = np.array([load_image(path) for path in files[i:j]])         # \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0432 \u0432\u0438\u0434\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u044b\n            label = np.array([image_and_class_train[path] for path in files[i:j]])   # \u043c\u0435\u0442\u043a\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n            y = keras.utils.to_categorical(label, num_classes=NUM_CLASSES)      # one hot \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n            yield (x, y)","9662b50b":"# \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0442\u0435\u043d\u0438\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0434\u0438\u0441\u043a\u0430\ndef predict_generator(files):\n    while True:\n        for path in files:\n            yield np.array([load_image(path)])","dfa617ab":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 20))\nfor i, path in enumerate(image_train[:10], 1):\n    subplot = fig.add_subplot(math.ceil(i \/ 5), 5, i)\n    plt.imshow(plt.imread(path));\n    subplot.set_title('{} \\n label: {}'.format(os.path.basename(path), image_and_class_train[path]))","0509e352":"conv_base = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))","61ed5ba0":"# \u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u0441\u0435 \u0432\u0435\u0441\u0430 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u043a\u0440\u043e\u043c\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e \u0431\u043b\u043e\u043a\u0430 \nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv3':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","3b8faf3b":"conv_base.summary()","e89ec429":"model_2 = models.Sequential()\nmodel_2.add(conv_base)  # \u043a\u0443\u0441\u043e\u043a VGG-16 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0432 \u043c\u043e\u0434\u0435\u043b\u044c\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Flatten())\n#model_1.add(layers.Dense(512, activation='relu'))\nmodel_2.add(layers.Dense(NUM_CLASSES, activation='softmax'))\nmodel_2.summary()","9c08de9a":"model_2.compile(optimizer=Adam(lr=0.005), \n              loss='categorical_crossentropy',  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c 'categorical_crossentropy' (log loss\n              metrics=['accuracy'])","bd5e077c":"shuffle(image_train)  # \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443\n\ntrain_val_split = 100  # \u0447\u0438\u0441\u043b\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0432 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435\n\nvalidation_data = next(fit_generator(image_train[:train_val_split], train_val_split))\n\n# \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nhistory = model_2.fit_generator(fit_generator(image_train[train_val_split:]),  # \u0434\u0430\u043d\u043d\u044b\u0435 \u0447\u0438\u0442\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439-\u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u043c\n        steps_per_epoch=10,  # \u0447\u0438\u0441\u043b\u043e \u0432\u044b\u0437\u043e\u0432\u043e\u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0437\u0430 \u044d\u043f\u043e\u0445\u0443\n        epochs=100,  # \u0447\u0438\u0441\u043b\u043e \u044d\u043f\u043e\u0445 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n        validation_data=validation_data\n#         callbacks=[EarlyStopping(patience = 5),\n#                    ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n#                                   verbose=1,\n#                                   save_best_only=True)]\n                               )","95262b96":"start = 0\nplt.plot(history.history['loss'][start:])\nplt.plot(history.history['val_loss'][start:])\nplt.legend(['Train loss', 'Validation loss'])","09993b7a":"plt.plot(history.history['acc'][start:])\nplt.plot(history.history['val_acc'][start:])\nplt.legend(['Train acc', 'Validation acc'])","bd6cfade":"# \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432\u0435\u0441\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0435\u0433\u043e loss \n#model_2.load_weights('weights.10-3.12.hdf5')","781ed715":"pred = model_2.predict_generator(predict_generator(image_test), len(image_test), max_queue_size=500)","5a6f53bf":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 20))\nfor i, (path, score) in enumerate(zip(image_test[70:][:10], pred[70:][:10]), 1):\n    subplot = fig.add_subplot(math.ceil(i \/ 5), 5, i)\n    plt.imshow(plt.imread(path))\n    subplot.set_title('label: {} \\n prediction: {} \\n model confidence: {:.3f}'\\\n                      .format(image_and_class_test[path],\n                              int(np.argmax(score)),\n                             np.max(score)))","9bfba620":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0432\u0438\u0434\u0430 {\u0438\u043c\u044f_\u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 : \u043a\u043b\u0430\u0441\u0441, ...} \u0434\u043b\u044f \u0431\u044b\u0441\u0442\u0440\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a \u043c\u0435\u0442\u043a\u0435 \u043a\u043b\u0430\u0441\u0441\u0430 \u043f\u043e \u0438\u043c\u0435\u043d\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438","ea550f5b":"**\u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c**\n\n\u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043d\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 'ImagNet' \u043c\u043e\u0434\u0435\u043b\u044c VGG16 ","63c236e5":"**\u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445:**","bc18a09a":"**\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f**"}}