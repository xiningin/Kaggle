{"cell_type":{"e262a17d":"code","85659b8a":"code","de8d0390":"code","0aad4f4e":"code","1b386420":"code","43f7a191":"code","64068ce1":"code","3ee2cb83":"code","60bdcb61":"code","c895945c":"code","a36cf583":"code","e77f592c":"code","09a13ba3":"code","d4b971dd":"code","20d1affd":"code","db9bad89":"code","006485f6":"markdown","d0124e6a":"markdown","aed0508d":"markdown","c1821cb6":"markdown"},"source":{"e262a17d":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.rcParams['font.size'] = 8\nplt.rcParams['figure.figsize'] = (8,8)\n\nimport os\nimport numpy as np\nimport cv2\nimport pickle\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras import backend as K\n\nfrom sklearn.cluster import KMeans","85659b8a":"!find ..\/input\/train -name \"*.jpg\" > train_images.txt\n\nwith open(\"train_images.txt\", \"r\") as f:\n    train_images = f.read().split('\\n')[:-1]\n\nimg_width, img_height, channels = 224, 224, 3\ninput_shape = (img_width, img_height, channels)\n\ndef load_data(files):\n    arr = np.empty((len(files), img_width, img_height, channels), dtype=np.float32)\n    for i, imgfile in enumerate(files):\n        img = load_img(imgfile)\n        x = img_to_array(img).reshape(img_width, img_height, channels)\n        x = x.astype('float32') \/ 255.\n        arr[i] = x\n    return arr\n\nX = load_data(files=train_images)","de8d0390":"nb_rows, nb_cols = 5, 5\nplt.figure(figsize=(15,15))\nfor k in range(nb_rows * nb_cols):\n    plt.subplot(nb_rows, nb_cols, k+1)\n    plt.imshow(X[k])\n    plt.axis('off')","0aad4f4e":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Conv2D(8, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n\nmodel.add(Conv2D(8, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(3, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n\nmodel.summary()","1b386420":"model.fit(X, X, epochs=20, batch_size=128, shuffle=True)","43f7a191":"def plot_some(im_list):\n    plt.figure(figsize=(15,4))\n    for i, array in enumerate(im_list):\n        plt.subplot(1, len(im_list), i+1)\n        plt.imshow(array)\n        plt.axis('off')\n    plt.show()\n\nimg_decoded = model.predict(X[:5])\n\nprint('Before autoencoding:')\nplot_some(X[:5])\nprint('After decoding:')\nplot_some(img_decoded)","64068ce1":"X_sample = X[:100]\nprint(X_sample.shape)\n\nget_encoded = K.function([model.layers[0].input], [model.layers[5].output])\nencoded_sample = get_encoded([X_sample])[0]\nprint(encoded_sample.shape)","3ee2cb83":"for n_image in range(0, 5):\n    \n    plt.figure(figsize=(12,4))\n\n    plt.subplot(1,4,1)\n    plt.imshow(X_sample[n_image][:,:,::-1])\n    plt.axis('off')\n    plt.title('Original Image')\n\n    plt.subplot(1,4,2)\n    plt.imshow(encoded_sample[n_image].mean(axis=-1))\n    plt.axis('off')\n    plt.title('Encoded Mean')\n\n    plt.subplot(1,4,3)\n    plt.imshow(encoded_sample[n_image].max(axis=-1))\n    plt.axis('off')\n    plt.title('Encoded Max')\n\n    plt.subplot(1,4,4)\n    plt.imshow(encoded_sample[n_image].std(axis=-1))\n    plt.axis('off')\n    plt.title('Encoded Std')\n\n    plt.show()","60bdcb61":"X_encoded = np.empty((len(X), 28, 28, 8), dtype='float32')\n\nstep = 100\nfor i in range(0, len(X), step):\n    x_batch = get_encoded([X[i:i+step]])[0]\n    X_encoded[i:i+step] = x_batch\n\nprint(X_encoded.shape)","c895945c":"X_encoded_reshape = X_encoded.reshape(X_encoded.shape[0], X_encoded.shape[1]*X_encoded.shape[2]*X_encoded.shape[3])\nprint(X_encoded_reshape.shape)","a36cf583":"n_clusters = 100                      # just for fun\n\nkm = KMeans(n_clusters=n_clusters)\nkm.fit(X_encoded_reshape)","e77f592c":"plt.figure(figsize=(20, 5))\ncluster_elements = [(km.labels_==i).sum() for i in range(n_clusters)]\nplt.bar(range(n_clusters), cluster_elements, width=1)","09a13ba3":"average_clusters_encoded = []\nfor i in range(n_clusters):\n    average_clusters_encoded.append(X_encoded[km.labels_==i].mean(axis=0))\n\naverage_clusters_encoded = np.asarray(average_clusters_encoded)\n\nprint(average_clusters_encoded.shape)","d4b971dd":"get_decoded = K.function([model.layers[6].input],\n                         [model.layers[-1].output])\n\ndecoded_clusters = get_decoded([average_clusters_encoded])","20d1affd":"plt.figure(figsize=(20, 20))\n\nfor i in range(n_clusters):\n    plt.subplot(10, 10, i+1)\n    plt.imshow(decoded_clusters[0][i][:,:,::-1])\n    plt.title('Cluster {}'.format(i))\n    plt.axis('off')\n\nplt.show()","db9bad89":"plt.figure(figsize=(20, 20))\n\ncluster = 5\nrows, cols = 10, 10\nstart = 0\n\nlabels = np.where(km.labels_==cluster)[0][start:start+rows*cols]\nfor i, label in enumerate(labels):\n    plt.subplot(rows, cols, i+1)\n    plt.imshow(X[label])\n    plt.axis('off')","006485f6":"# autoencoder model","d0124e6a":"# KMean Cluster","aed0508d":"# load train images","c1821cb6":"# save the encoder output"}}