{"cell_type":{"c26693c8":"code","5294e40a":"code","7af8f392":"code","7026e048":"code","36992c5b":"code","105df789":"code","ada55f5c":"code","b3e7a30f":"code","8c7a49d1":"code","b2e148b7":"code","1bc03637":"code","ae04400d":"code","6401fffb":"code","149f0930":"code","a442d428":"code","5ebd791d":"code","54419c40":"code","13142654":"code","bd24555e":"code","1497f40d":"code","beafade5":"code","cdb3c491":"code","1d258bc5":"code","ae72f31c":"code","5422255d":"code","a26f0570":"code","a936fb77":"code","1fbd26bd":"code","df5bfd25":"code","42ad6e53":"code","a2acb84d":"code","36f29cc1":"markdown","9adaf586":"markdown","a1a43503":"markdown","8297f01a":"markdown","926cc833":"markdown","16f3bf41":"markdown","a85086d6":"markdown","92d87d8b":"markdown"},"source":{"c26693c8":"#Import Libraries\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings('ignore')","5294e40a":"# Open data set\n\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test =  pd.read_csv('..\/input\/test.csv')\n\ndf_train.head()","7af8f392":"df_test.head()","7026e048":"df_train.info()","36992c5b":"df_train.describe()","105df789":"df_train.duplicated().sum()","ada55f5c":"# Para suavizar a presen\u00e7a e o efeito dos outliers nos modelos, irei aplicar uma transforma\u00e7\u00e3o nos dados num\u00e9ricos.\n\n# Padronizando os dados com StandartScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Utilizando apenas as colunas num\u00e9ricas que n\u00e3o foram codificadas como a do tipo de solo e a designa\u00e7\u00e3o da \u00e1rea.\ncolunas = ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n           'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points','Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', \n           'Wilderness_Area4','Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', \n           'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13',\n           'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', \n           'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', \n           'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', \n            'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n\n\nscaler = StandardScaler()\n#Treino\n\nscaler.fit(df_train[colunas])\ndf_train[colunas] = scaler.transform(df_train[colunas])\n\n#Teste\n\nscaler.fit(df_test[colunas])\ndf_test[colunas] = scaler.transform(df_test[colunas])","b3e7a30f":"df_train.head()","8c7a49d1":"# Correla\u00e7\u00e3o das colunas num\u00e9ricas\n\ndf_train[colunas].corr()","b2e148b7":"#Removendo atributos\n\ndf_train = df_train.drop(['Soil_Type7','Soil_Type15'],1)\n\ndf_test = df_test.drop(['Soil_Type7','Soil_Type15'],1)","1bc03637":"# Vizualiza\u00e7\u00e3o dos dados\n\n# Depois de cuidar da assimetria dos dados, vamos come\u00e7ar as vizualisa\u00e7\u00f5es para tentar entender melhor o problema\n\n#Gr\u00e1fico 1\ndf_train.plot(x = 'Aspect', y = 'Hillshade_3pm',c = ('red','blue'),kind = 'scatter', figsize = (5,5));\n","ae04400d":"#Gr\u00e1fico 2\ndf_train.plot(x = 'Slope', y = 'Hillshade_Noon',c = ('red','blue'),kind = 'scatter', figsize = (5,5));","6401fffb":"#Gr\u00e1fico 3\ndf_train.plot(x = 'Horizontal_Distance_To_Hydrology', y = 'Vertical_Distance_To_Hydrology',c = ('red','blue'),kind = 'scatter', figsize = (5,5));\n","149f0930":"#Gr\u00e1fico 4\ndf_train.plot(x = 'Hillshade_9am', y = 'Hillshade_3pm',c = ('red','blue'),kind = 'scatter', figsize = (5,5));\n","a442d428":"#Gr\u00e1fico 5\ndf_train.plot(x = 'Hillshade_Noon', y = 'Hillshade_3pm',c = ('red','blue'),kind = 'scatter', figsize = (5,5));","5ebd791d":"# Importando as bibliotecas necess\u00e1rias\n\nfrom collections import Counter\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn import cross_validation\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","54419c40":"# Distribui\u00e7\u00e3o do atributo Cover-Type\n\nprint(Counter(df_train['Cover_Type']))","13142654":"# Prepara\u00e7\u00e3o das vari\u00e1veis\n\nX = df_train.drop(['Cover_Type','Id'],1)\nY = df_train['Cover_Type']\n\n# M\u00e9tricas\n\nseed = 42\nscoring = 'accuracy'\nvalidation_size = 0.30","bd24555e":"# Separando em Teste e Treino\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=validation_size, random_state = seed)","1497f40d":"# Vamos verificar o comportamento desses 3 algoritmos\n\nmodels = []\nmodels.append(('RF',RandomForestClassifier()))\nmodels.append(('ETC',ExtraTreesClassifier()))\nmodels.append(('KNN', KNeighborsClassifier()))\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","beafade5":"# Comparando os algor\u00edtmos\n\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","cdb3c491":"# Grid Search\n#model = ExtraTreesClassifier(random_state = 0) \n\n# Grid search par\u00e2metros\n#param_grid = {\n #   \"n_estimators\": [500, 550, 600, 650, 700, 750, 800 , 850, 900, 950]\n#}\n\n# Executando grid search\n#CV_model = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=KFold(n_splits=10, random_state=seed))\n#CV_model_result = CV_model.fit(X_train, Y_train)\n\n# Resultados\n#print(\"Best: %f using %s\" % (CV_model_result.best_score_, CV_model_result.best_params_))","1d258bc5":"#Avaliando a precis\u00e3o do modelo ETC depois de ter encontrado o melhor par\u00e2metro\n\nETC = ExtraTreesClassifier( n_estimators = 550)\nETC.fit(X_train, Y_train)\npredicoes1 = ETC.predict(X_test)\nprint(\"Precis\u00e3o: {} \\n\".format(accuracy_score(Y_test, predicoes1)))\nprint(confusion_matrix(Y_test, predicoes1))\nprint(classification_report(Y_test, predicoes1))","ae72f31c":"RF = RandomForestClassifier()\nRF.fit(X_train, Y_train)\npredicoes2 = RF.predict(X_test)\nprint(\"Precis\u00e3o: {} \\n\".format(accuracy_score(Y_test, predicoes2)))\nprint(confusion_matrix(Y_test, predicoes2))\nprint(classification_report(Y_test, predicoes2))","5422255d":"# Banco de dados de teste\nX_tes = df_test.drop(['Id'],1)\n","a26f0570":"#Previs\u00f5es com os valores do banco de dados teste\ntest_predicoes1 = ETC.predict(X_tes)\ntest_predicoes2 = RF.predict(X_tes)","a936fb77":"valores_pred = np.column_stack((predicoes1, predicoes2))\nvalores_pred_test = np.column_stack((test_predicoes1, test_predicoes2))","1fbd26bd":"# Modelo final\nmodelo_fin = ExtraTreesClassifier( n_estimators = 550)\nmodelo_fin.fit(valores_pred,Y_test)","df5bfd25":"#Predi\u00e7\u00e3o final\npredicao_final = modelo_fin.predict(valores_pred_test)","42ad6e53":"# Acuracia do modelo final\nmodelo_fin.score(valores_pred, Y_test)","a2acb84d":"my_submission = pd.DataFrame({'Id': df_test.Id, 'Cover_Type': predicao_final})\nmy_submission.to_csv('submission11.csv', index=False)","36f29cc1":"# Modelagem","9adaf586":"Vamos imprimir a matriz de covariancia entre as vari\u00e1veis e assim poderemos verificar o comportamentos da vari\u00e1veis mais dependente uma da outra, e veremos se isso realmente atrapalha ou n\u00e3o nosso banco de dados, para isso plotaremos o gr\u00e1fico de disper\u00e7\u00e3o com grau de depend\u00eancia superior a 0.6","a1a43503":"# Pr\u00e9 processamento dos dados","8297f01a":"## Observa\u00e7\u00f5es:\n\nAntes de come\u00e7ar adicionar, remover ou transformar alguma coisa, preciso expor o que entendi nessas an\u00e1lises iniciais do meu banco de dados de treino. Primeiro, a ausencia de valores ausentes e duplicados nesse banco de dados, possue outliers que precisam ser entendidos para identificar se realmente prejudicam o nosso modelo e tamb\u00e9m \u00e9 preciso fazer uma verifica\u00e7\u00e3o mais profunda para encontrar atributos correlacionados que podem prejudicar nosso modelo. ","926cc833":"Com base no teste dos algor\u00edtmos, tanto o RandomForest e o ExtraTrees obtiveram os melhores resultados, ent\u00e3o para tentar melhorar a predi\u00e7\u00e3o do meu projeto irei pegar a m\u00e9dia da previs\u00e3o dos dois modelos.","16f3bf41":"### Observa\u00e7\u00e3o\n\nComo podemos ver dois atributos possuem valores NaN na matriz de correla\u00e7\u00e3o, ent\u00e3o para melhorar o conjunto de dados irei remove-los do nosso conjunto de dados.","a85086d6":"Ap\u00f3s avaliarmos esse algor\u00edtmo iremos colocar agora em produ\u00e7\u00e3o e aplicar os dados de teste.","92d87d8b":"## Observa\u00e7\u00e3o:\n\nOs gr\u00e1ficos acima tiveram rela\u00e7\u00f5es de correla\u00e7\u00e3o positiva como o gr\u00e1fico 1,3 e 5 e correla\u00e7\u00e3o negativa 2 e 4."}}