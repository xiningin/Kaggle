{"cell_type":{"4c36ce25":"code","a8248f86":"code","dda47eb3":"code","9e8ab819":"code","cfcf698c":"code","36c1e58b":"code","53230adc":"code","3d02237d":"code","99aef059":"code","2784a61a":"code","41b58e99":"code","b7345751":"code","dbe0f284":"code","c3bee34f":"code","f32ee8aa":"code","7baae299":"code","601384b5":"code","44db5ee6":"code","08338bc6":"markdown","6b87405f":"markdown","d4e2e417":"markdown","65676eac":"markdown","199a41b1":"markdown","08a9c0d3":"markdown","448b7974":"markdown","e0edb664":"markdown","452e63ac":"markdown"},"source":{"4c36ce25":"import torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport PIL.Image as Image\nfrom torchvision import datasets,models\nimport matplotlib.pyplot as plt\nfrom torch.autograd import Variable\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a8248f86":"im=Image.open('..\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.1000.jpg')\nim","dda47eb3":"im2=Image.open('..\/input\/cat-and-dog\/training_set\/training_set\/dogs\/dog.1016.jpg')\nim2","9e8ab819":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\n        \n        ","cfcf698c":"input_path='..\/input\/cat-and-dog'\ndata_image={\n    'train': datasets.ImageFolder(input_path+'\/training_set\/'+'training_set',data_transforms['train'])\n    , 'test':datasets.ImageFolder(input_path+'\/test_set\/'+'test_set',data_transforms['validation'])\n    \n    \n}","36c1e58b":"train_loader=torch.utils.data.DataLoader(data_image['train'],\n                                batch_size=1,\n                                shuffle=True,\n                                num_workers=0)","53230adc":"validation_loader=torch.utils.data.DataLoader(data_image['test'],\n                                batch_size=1,\n                                shuffle=True,\n                                num_workers=0)","3d02237d":"def imshow(image, ax=None, title=None, normalize=True):\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax","99aef059":"trainimages, trainlabels = next(iter(train_loader))\n\nprint('training images')\n\nimshow(trainimages[0])\nprint(trainlabels[0])\n\nprint(trainimages[0].size())","2784a61a":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","41b58e99":"# Creating the CNN neural network\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n        self.conv1=nn.Conv2d(3,6,3)\n        self.conv2=nn.Conv2d(6,16,3)\n        self.f1=nn.Linear(16*54*54,2)     \n\n    def forward(self,x):\n        x=torch.tensor(x,dtype=self.conv1.weight.dtype)\n        x=F.max_pool2d(self.conv1(x),(2,2))\n        x=F.max_pool2d(self.conv2(x),2)\n        x=x.view(-1,self.get_size(x))\n        x=self.f1(x)\n        return x\n    def get_size(self,x):\n        nn=1\n        ps=x.size()[1:]\n        for i in ps:\n            nn*=i\n        return nn","b7345751":"cnn=CNN()\ncnn=cnn.to(device)","dbe0f284":"# Cross Entropy Loss  \nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer \nlearning_rate = 0.001\noptimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)","c3bee34f":"batch_size=1\nn_iters = 10000\nnum_epochs = n_iters \/ (8005 \/ batch_size)\nnum_epochs = int(num_epochs)","f32ee8aa":"# Traning the Model\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list=[]\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        # Define variables\n        train = Variable(images.view(1, 3,224,224)).to(device)\n        labels = Variable(labels).to(device)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = cnn(train)\n        # Calculate softmax and cross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculate gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        # Prediction\n        if count % 50 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Predict test dataset\n            for images, labels in validation_loader: \n                test = Variable(images.view(1,3,224,224)).to(device)\n                labels=Variable(labels).to(device)\n                \n                # Forward propagation\n                outputs = cnn(test)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += len(labels)\n                \n                # Total correct predictions\n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))","7baae299":"plt.plot(iteration_list,loss_list)\nplt.plot(iteration_list,np.array(accuracy_list)\/100)","601384b5":"catty=Image.open('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4004.jpg')\nplt.imshow(Image.open('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4004.jpg'))\ncatty=catty.resize((224,224),resample=0)\nval=np.array(catty).astype(float)\nval=torch.from_numpy(val).cuda()\nif torch.max(cnn(val.view(1,3,224,224)).data, 1)[1]==0 :\n    print(\"It's a cat\")\nelse:\n    print(\"It's a dog\")","44db5ee6":"catty=Image.open('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4010.jpg')\nplt.imshow(Image.open('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4010.jpg'))\ncatty=catty.resize((224,224),resample=0)\nval=np.array(catty).astype(float)\nval=torch.from_numpy(val).cuda()\nif torch.max(cnn(val.view(1,3,224,224)).data, 1)[1]==0 :\n    print(\"It's a cat\")\nelse:\n    print(\"It's a dog\")","08338bc6":"# Predicting some of the data","6b87405f":"# Having a look at the data","d4e2e417":"# Importing The Packages","65676eac":"# Checking if there is GPU","199a41b1":"# Thank you!!\n![](https:\/\/i.pinimg.com\/originals\/8c\/40\/05\/8c4005377742272315e792545a9c93df.gif)","08a9c0d3":"# Making Train and Validation Loader","448b7974":"# Making the Neural Network","e0edb664":"# Converting the Folders into dataset","452e63ac":"# Training The Model"}}