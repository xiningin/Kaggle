{"cell_type":{"eac36c80":"code","f5a81230":"code","af73335e":"code","78c55a23":"code","b78e7d37":"code","c4339551":"code","4f7223f5":"code","d4318cd1":"code","2739f617":"code","4dde55c1":"code","7c008af7":"code","81e0263d":"code","e7d1705d":"code","c0985b1a":"code","67dfa554":"code","10175d84":"code","1b0e0c11":"markdown"},"source":{"eac36c80":"!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py > \/dev\/null 2>&1\n!python pytorch-xla-env-setup.py --version 20210331 --apt-packages libomp5 libopenblas-dev > \/dev\/null 2>&1","f5a81230":"import sys\nsys.path.append(\"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/\")\n\nimport platform\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nimport cv2\nimport random\nimport glob\nimport gc\nfrom math import ceil\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom skimage.exposure import exposure, equalize_hist,equalize_adapthist\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport timm\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, StepLR\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\nimport warnings\n\nwarnings.simplefilter('ignore')\nnp.set_printoptions(suppress=True)\nos.environ['XLA_USE_BF16']=\"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'","af73335e":"from torch.autograd import Variable\n\nclass bceFocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target, reduction='mean'):\n        n = input.shape[-1]\n        input = input.view(-1).float()\n        target = target.view(-1).float()\n        loss = -target*F.logsigmoid(input)*torch.exp(self.gamma*F.logsigmoid(-input)) -\\\n           (1.0 - target)*F.logsigmoid(-input)*torch.exp(self.gamma*F.logsigmoid(input))\n        \n        return n*loss.mean() if reduction=='mean' else loss\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim()>2:\n            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1,1)\n\n        logpt = F.log_softmax(input)\n        logpt = logpt.gather(1,target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type()!=input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0,target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","78c55a23":"class Config:\n    image_size = 384\n    batch_size = 8*8\n    epochs = 5\n    seed = 2021\n    lr = 5e-5 \/ 8  \n    workers = 8\n    drop_last = True\n    \n    def get_loss_fn():\n        #return nn.CrossEntropyLoss()\n        return nn.MSELoss()\n        #return FocalLoss(gamma=1.5)\n\n    def get_optimizer(model, learning_rate):\n        return torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    def get_scheduler(optimizer):\n        return ReduceLROnPlateau(optimizer, \n                                 mode='min', \n                                 factor=0.5, \n                                 patience=3, \n                                 threshold=0.0001,\n                                 verbose=False, \n                                 min_lr=1e-6,\n                                 eps=1e-08)\n    \n\n# Make results reproducible\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(Config.seed)","b78e7d37":"train = pd.read_csv(\"..\/input\/simple-eda-using-pandas-profiling\/train.csv\",index_col=0)\ntrain","c4339551":"classes = train.columns[1:13]\ncategory_name_to_id = {index:class_name for index, class_name in enumerate(classes)}\nlen(category_name_to_id)","4f7223f5":"def get_train_transforms():\n    return A.Compose(\n            [\n             A.RandomSizedCrop(\n                         min_max_height=[int(0.95*Config.image_size), int(1.0*Config.image_size)],\n                         height=Config.image_size,\n                         width=Config.image_size, \n                         p=1.0),\n                      \n              #A.HorizontalFlip(p=0.5),\n              #A.VerticalFlip(p=0.5),\n              A.Rotate(\n                    limit=5,\n                    p=0.6,\n                ),              \n            ])","d4318cd1":"class inputds(Dataset):\n    def __init__(self, df, augments=True):\n        super().__init__()\n        self.df = df.sample(frac=1).reset_index(drop=True)\n        if augments:\n          self.augments = get_train_transforms()\n        else:\n          self.augments = None\n\n        \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        index = row.Id\n        imagepad = cv2.imread(f\"..\/input\/petfinder-imgds\/image_size{Config.image_size}\/image_size{Config.image_size}\/{index}.jpg\", cv2.IMREAD_COLOR)\n        h,w,c= imagepad.shape\n        image = np.zeros((Config.image_size,Config.image_size,3))\n        if h > w:\n          x = h\n          y = random.randint(0,Config.image_size-w)\n          image[0:x,y:y+w] = imagepad\n        else:\n          x = random.randint(0,Config.image_size-h)\n          y = w\n          image[x:x+h,0:y] = imagepad\n\n\n        #image = cv2.resize(image,(384,224))\n        #if self.augments:\n        #image = self.augments(image=image)[\"image\"]\n        image = torch.tensor(image\/255.0,dtype=torch.float)\n        image = image.permute(2, 0, 1)\n        labels = np.array([row[category_name_to_id[i]] for i in range(12)])\n        score = row.Pawpularity\/100\n\n        return image, labels, score\n    \n    def __len__(self):\n        return len(self.df)","2739f617":"\"\"\"\nds =  inputds(train,augments=True)\nfor i,(image,labels, score) in enumerate(ds):\n    print(image.shape,labels.shape,score)\n    plt.imshow(image.permute(1,2,0))\n    plt.show()\n    if i==20:\n        break\n\"\"\"","4dde55c1":"from sklearn.model_selection import KFold, StratifiedKFold\nRANDOM_STATE = 35\n\nkfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n#skfold = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\nsplits= kfold.split(train)\ntrain_indexs = []\ntest_indexs = []\nfor i,(train_index, test_index) in enumerate(splits):\n    print(train_index.shape,test_index.shape)\n    train_indexs.append(train_index)\n    test_indexs.append(test_index)","7c008af7":"from timm.models.efficientnet import *\nclass Net0(nn.Module):\n    def __init__(self):\n        super(Net0, self).__init__()\n\n        self.eff = tf_efficientnet_b3(pretrained=True, drop_rate=0.3, drop_path_rate=0.2,in_chans=3)\n\n        self.rlogit = nn.Linear(1000,128)\n        self.dropout = nn.Dropout(0.1)\n        self.fc1 = nn.Linear(140,64)\n        self.fc2 = nn.Linear(64,1)\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image, dense):\n        #batch_size = len(image)\n        x = image\n\n        x = self.eff(x)  \n        x = self.dropout(x)\n        x = self.rlogit(x)\n        x = torch.cat([x, dense], dim=1)\n        x = self.fc1(x)\n        score = self.fc2(x)\n        \n        return score","81e0263d":"#!pip install torchsummary\n#from torchsummary import summary\n#summary(Net0(),(3,384,384))\nmodel_=Net0()","e7d1705d":"class Record:\n    '''\n    Records labels and predictions within one epoch\n    '''\n    def __init__(self):\n        self.labels = []\n        self.preds = []\n        \n    def update(self, cur_labels, cur_logits):\n        cur_labels = cur_labels.detach().cpu().numpy()\n        cur_logits = cur_logits.sigmoid().detach().cpu().numpy()\n        #cur_logits = np.exp(cur_logits.detach().cpu().numpy())\n        #cur_preds = cur_logits \/ np.sum(cur_logits, axis=1, keepdims=True)\n        self.labels.append(cur_labels)\n        self.preds.append(cur_logits)\n\n    def get_labels(self):\n        return np.concatenate(self.labels) # (n, )\n\n    def get_preds(self):\n        return np.concatenate(self.preds, axis=0) # (n, 4)\n    \n    @staticmethod\n    def get_acc(confusion_mat):\n        return round(np.sum(np.eye(4) * confusion_mat) \/ np.sum(confusion_mat) * 100, 2)\n\n    @staticmethod\n    def get_rmse(preds,labels):\n        return np.sqrt(mean_squared_error(preds*100, labels*100))","c0985b1a":"class Trainer:\n    def __init__(self, model, optimizer, loss_fn, maskloss_fn, device):\n        \"\"\"\n        Constructor for Trainer class\n        \"\"\"\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.maskloss_fn = maskloss_fn\n        self.device = device\n    \n    def train_one_cycle(self, train_loader):\n        \"\"\"\n        Runs one epoch of training, backpropagation and optimization\n        \"\"\"\n        self.model.train()\n        total_loss = 0\n        total_nums = 0\n        #record = Record()\n\n        for idx, (xtrain, xlabel, ys) in enumerate(train_loader):\n            xtrain = xtrain.to(self.device, dtype=torch.float)\n            xlabel = xlabel.to(self.device, dtype=torch.float)\n            ys = ys.to(self.device, dtype=torch.float)\n            \n\n            self.optimizer.zero_grad()\n            preds = self.model(xtrain,xlabel)\n            loss1 = self.loss_fn(preds[:,0], ys)\n            loss = torch.sqrt(loss1)\n            \n            total_loss += (loss.detach().item() * ys.size(0))\n            total_nums += ys.size(0)\n            \n            loss.backward()\n            del loss\n            xm.optimizer_step(self.optimizer)\n            \n        self.model.eval()\n        return total_loss \/ total_nums\n\n    def valid_one_cycle(self, valid_loader):\n        \"\"\"\n        Runs one epoch of prediction\n        \"\"\"\n        self.model.eval()\n        total_loss = 0\n        total_nums = 0\n        record = Record()\n        \n        for idx, (xval, xlabel, ys) in enumerate(valid_loader):\n            with torch.no_grad():\n                xval = xval.to(self.device, dtype=torch.float)\n                xlabel = xlabel.to(self.device, dtype=torch.float)\n                ys = ys.to(self.device, dtype=torch.float)\n\n                pred = self.model(xval,xlabel)\n                record.update(ys, pred)\n\n        return record.get_labels(), record.get_preds()","67dfa554":"def _mp_fn(rank, flags):\n    '''\n    Train and valid\n    '''\n    torch.set_default_tensor_type('torch.FloatTensor')\n\n    # Sets a common random seed both for initialization and ensuring graph is the same\n    torch.manual_seed(Config.seed)\n\n    # Acquires the (unique) Cloud TPU core corresponding to this process's index\n    device = xm.xla_device()\n    \n    # load the model into each tpu core\n    model = model_.to(device)\n    \n    # Creates the (distributed) train sampler\n    # which let this process only access its portion of the training dataset.  \n    train_sampler = DistributedSampler(\n        train_set,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True,\n    )\n    train_loader = DataLoader(\n        train_set,\n        batch_size=int(Config.batch_size\/xm.xrt_world_size()),\n        sampler=train_sampler,\n        drop_last=Config.drop_last,\n        num_workers=Config.workers,\n    )\n    valid_sampler = DistributedSampler(\n        valid_set,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False,\n    )\n    valid_loader = DataLoader(\n        valid_set,\n        batch_size=int(Config.batch_size\/xm.xrt_world_size()),\n        sampler=valid_sampler,\n        drop_last=Config.drop_last,\n        num_workers=Config.workers,\n    )\n\n    optimizer = Config.get_optimizer(model, Config.lr * xm.xrt_world_size())\n    #loss_fn = Config.get_loss_fn()\n    loss_fn = nn.BCEWithLogitsLoss()\n    maskloss_fn = bceFocalLoss(gamma=1.5)\n    #maskloss_fn = nn.BCEWithLogitsLoss()\n                               \n    scheduler = Config.get_scheduler(optimizer)\n    \n    trainer = Trainer(\n        model=model,\n        optimizer=optimizer,\n        loss_fn=loss_fn,\n        maskloss_fn = maskloss_fn,\n        device=device,\n    )\n\n    \n    for epoch in range(Config.epochs):\n        xm.master_print(f\"{'-'*30} EPOCH: {epoch+1}\/{Config.epochs} {'-'*30}\")\n        \n        # Run one training epoch\n        para_loader = pl.ParallelLoader(train_loader, [device])\n        #train_loss, train_labels, train_preds = trainer.train_one_cycle(para_loader.per_device_loader(device))\n        train_loss = trainer.train_one_cycle(para_loader.per_device_loader(device))\n\n        # Compute training metrics\n        train_loss_avg = xm.mesh_reduce('train_loss_reduce', train_loss, lambda alist: sum(alist) \/ len(alist))\n        \"\"\"\n        train_labels_concat = xm.mesh_reduce('train_labels_concat', train_labels, lambda alist: np.concatenate(alist))  # (8n, )\n        train_preds_concat = xm.mesh_reduce('train_preds_concat', train_preds, lambda alist: np.concatenate(alist, axis=0))  # (8n, 4)\n        train_confusion_mat = confusion_matrix(train_labels_concat, np.argmax(train_preds_concat, axis=1))\n        train_acc = Record.get_acc(train_confusion_mat)\n        try:\n          train_auc = Record.get_auc(train_labels_concat, train_preds_concat)\n          xm.master_print(f\"Train Loss: {train_loss_avg:.4f}  Train Acc: {train_acc}%  Train AUC: {train_auc}\")\n        except:\n          print(\"cannot get auc\")\n          xm.master_print(f\"Train Loss: {train_loss_avg:.4f}  Train Acc: {train_acc}%\")\n        \"\"\"\n        xm.master_print(f\"Train Loss: {train_loss_avg:.4f}\")\n        #xm.master_print(train_confusion_mat)\n\n        # Run one validation epoch\n        para_loader = pl.ParallelLoader(valid_loader, [device])\n        valid_labels, valid_preds = trainer.valid_one_cycle(para_loader.per_device_loader(device))\n        \n        \n        # Compute validation metrics\n        #valid_loss_avg = xm.mesh_reduce('valid_loss_reduce', valid_loss, lambda alist: sum(alist) \/ len(alist))\n        \n        valid_labels_concat = xm.mesh_reduce('valid_labels_concat', valid_labels, lambda alist: np.concatenate(alist))\n        valid_preds_concat = xm.mesh_reduce('valid_preds_concat', valid_preds, lambda alist: np.concatenate(alist, axis=0))\n        valid_loss_avg = Record.get_rmse(valid_preds_concat,valid_labels_concat)\n        \"\"\"\n        valid_confusion_mat = confusion_matrix(valid_labels_concat, np.argmax(valid_preds_concat, axis=1))\n        valid_acc = Record.get_acc(valid_confusion_mat)\n        try:\n          valid_auc = Record.get_auc(valid_labels_concat, valid_preds_concat)\n          xm.master_print(f\"Valid Loss: {valid_loss_avg:.4f}  Valid Acc: {valid_acc}%  Valid AUC: {valid_auc}\")\n          xm.master_print(valid_confusion_mat)\n          xm.save(model.state_dict(), f\"{dir}\/pretrained_model_{flags['fold']}_{valid_auc}.bin\")\n        except:\n          print(\"cannot get auc\")\n          xm.master_print(f\"Valid Loss: {valid_loss_avg:.4f}  Valid Acc: {valid_acc}%\")\n        \"\"\"\n        xm.master_print(f\"Valid Loss: {valid_loss_avg:.4f}\")\n        savename = f\"pretrained_model_{flags['fold']}_{valid_loss_avg}.bin\"\n        xm.master_print(f\"saveweight:{savename}\")\n        xm.save(model.state_dict(),savename)\n        if rank == 0:\n          for path in sorted(glob.glob(f\"pretrained_model_{flags['fold']}_*.bin\"))[3:]:\n            os.remove(path)\n        \n\n        scheduler.step(valid_loss_avg\/100)\n        \n    # Only main process save model weights","10175d84":"#%%time\nfor i in range(5):\n    FLAGS = {}\n    FLAGS['fold'] = i\n    fold = i\n    train_data, valid_data = train.iloc[train_indexs[fold],:],train.iloc[test_indexs[fold],:]\n    print(f\"fold:{fold},Training on {train_data.shape[0]} samples and Validation on {valid_data.shape[0]} samples\")\n\n    train_set = inputds(df=train_data, augments=True)\n    valid_set = inputds(df=valid_data, augments=False)\n    xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')\n    #break","1b0e0c11":"# check shape\n\n512,768,1024"}}