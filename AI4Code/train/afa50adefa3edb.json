{"cell_type":{"fc6213bf":"code","0a8d0c3c":"code","a75590b7":"code","1fb60632":"code","1b735904":"code","c98e9d31":"code","9bb0d654":"code","c7434f0c":"code","3e0e37ae":"code","f740c3e3":"code","9ba57364":"code","da740cdc":"code","1968a9de":"code","9c44d358":"code","767a1c56":"code","1e1054ea":"code","67e2a236":"code","5851495f":"markdown"},"source":{"fc6213bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0a8d0c3c":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport cv2\nimage=cv2.imread('..\/input\/train\/train\/cmd\/train-cmd-1992.jpg')\nplt.imshow(image)\nplt.show()","a75590b7":"gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\nfirst_gray = cv2.GaussianBlur(gray, (5, 5), 0)\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n# noise removal\nkernel = np.ones((3,3),np.uint8)\nopening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n\n# sure background area\nsure_bg = cv2.dilate(opening,kernel,iterations=3)\n\n# Finding sure foreground area\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n\n# Finding unknown region\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg,sure_fg)\nplt.imshow(sure_bg)\n#plt.imshow(first_gray)\nplt.show()\n","1fb60632":"# Marker labelling\nret, markers = cv2.connectedComponents(sure_fg)\n# Add one to all labels so that sure background is not 0, but 1\nmarkers = markers+1\n# Now, mark the region of unknown with zero\nmarkers[unknown==255] = 0\nplt.imshow(markers)\nplt.show()\nmarkers = cv2.watershed(image,markers)\nimage[markers == -1] = [255,0,0]\nplt.imshow(image)\nplt.show()\n","1b735904":"#edges = cv2.Sobel(image,cv2.CV_64F,1,0, ksize=1)\nedges=cv2.Canny(image,200,300)\nplt.subplot(121),plt.imshow(first_gray,cmap = 'gray')\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\nplt.show()","c98e9d31":"np.mean(edges)\nnp.mean(image)","9bb0d654":"import cv2 \nimport os \nimport numpy as np \nfrom random import shuffle \nfrom tqdm import tqdm ","c7434f0c":"TRAIN_DIR = '..\/input\/train\/train\/cgm'\nTEST_DIR = '..\/input\/test\/test\/0'\n#IMG_SIZE = 96\nLR = 1e-3\nMODEL_NAME = 'cassava-{}-{}.model'.format(LR, '6conv-basic') \nclass_c=''\n\n","3e0e37ae":"import numpy.ma as ma\ndef create_train_data(): \n training_data = [] \n for img in tqdm(os.listdir(TRAIN_DIR)): \n             # labeling the images \n            #label = label_img(img) \n   # grayc=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    #edgedet=cv2.Canny(np.array(grayc),200,300,10)\n    #m=np.ma.mean(img)\n    path = os.path.join(TRAIN_DIR, img) \n              # loading the image from the path and then converting  into gray\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n              # resizing the image \n    img = cv2.resize(img, (100,100)) \n              # forming the training data list with numpy array of the images \n            #training_data.append([np.array(img), np.array(label)]) \n    label=os.path.basename(TRAIN_DIR)\n    training_data.append([np.array(np.mean(img)), np.array(label)])\n            \n               # shuffling of the training data to preserve the random state of our data \nshuffle(training_data) \n         # saving our trained data for further uses if required \nnp.save('train_data.npy', training_data) \nprint(*training_data, sep=\",\")\nreturn training_data \n","f740c3e3":"print(os.path.basename(TRAIN_DIR))","9ba57364":"import numpy.ma as ma\ndef process_test_data(): \n    testing_data = [] \n    for img in tqdm(os.listdir(TEST_DIR)): \n         #edge_test=cv2.Canny(np.asarray(img),200,300)\n         path = os.path.join(TEST_DIR, img) \n         img_num = img.split('.')[0] \n         img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n         img = cv2.resize(img, (666, 500)) \n         testing_data.append([np.array(np.ma.mean(img)), np.array(img_num)]) \n         \n    shuffle(testing_data) \n    np.save('test_data.npy', testing_data) \n    return testing_data ","da740cdc":"#executing model\ntrain_data = create_train_data() \ntest_data = process_test_data() ","1968a9de":"import tflearn \nfrom tflearn.layers.conv import conv_2d, max_pool_2d \nfrom tflearn.layers.core import input_data, dropout, fully_connected \nfrom tflearn.layers.estimator import regression \n  \nimport tensorflow as tf \ntf.reset_default_graph() \nconvnet = input_data(shape =[None, 666, 500, 1], name ='input') \n  \nconvnet = conv_2d(convnet, 32, 5, activation ='relu') \nconvnet = max_pool_2d(convnet, 5) \n  \nconvnet = conv_2d(convnet, 64, 5, activation ='relu') \nconvnet = max_pool_2d(convnet, 5) ","9c44d358":"convnet = conv_2d(convnet, 128, 5, activation ='relu') \nconvnet = max_pool_2d(convnet, 5) \n  \nconvnet = conv_2d(convnet, 64, 5, activation ='relu') \nconvnet = max_pool_2d(convnet, 5) \n  \nconvnet = conv_2d(convnet, 32, 5, activation ='relu') \nconvnet = max_pool_2d(convnet, 5) ","767a1c56":"convnet = fully_connected(convnet, 1024, activation ='relu') \nconvnet = dropout(convnet, 0.8) ","1e1054ea":"convnet = fully_connected(convnet, 2, activation ='softmax') \nconvnet = regression(convnet, optimizer ='adam', learning_rate = LR, \n      loss ='categorical_crossentropy', name ='targets') ","67e2a236":"model = tflearn.DNN(convnet, tensorboard_dir ='log')","5851495f":"second submission"}}