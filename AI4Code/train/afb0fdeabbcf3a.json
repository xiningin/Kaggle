{"cell_type":{"7ec5bb04":"code","417915bd":"code","73438b5e":"code","fed16c29":"code","730b1166":"code","7e5fbe7e":"code","028a84ee":"code","4f8c9a85":"code","f1877ae2":"code","fe4c2451":"code","8a397418":"code","892bd9fe":"code","8e05946f":"code","13c9ca9d":"code","1829ce7a":"code","31919369":"code","6b3281c7":"code","176b2c13":"markdown"},"source":{"7ec5bb04":"import riiideducation\nenv = riiideducation.make_env()","417915bd":"iter_test = env.iter_test()","73438b5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport riiideducation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport seaborn as sns\nimport os\npath=\"\/kaggle\/input\/riiid-test-answer-prediction\/\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndtype = {\n    'timestamp':'int64',\n    'content_type_id':'bool',\n    'content_id':'int16',\n    'answered_correctly':'int8',\n    'prior_question_elapsed_time':'float32',\n    'prior_question_had_explanation':'int8'\n}\ncols = [\n    'timestamp',\n    'content_type_id',\n    'content_id',\n    'answered_correctly',\n    'prior_question_elapsed_time',\n    'prior_question_had_explanation'\n]\ndf_lect = pd.read_csv(path+'lectures.csv', sep=',')\ndf_q = pd.read_csv(path+'questions.csv', sep=',')\ndf_sub = pd.read_csv(path+'example_sample_submission.csv', sep=',')\ndf_test = pd.read_csv(path+'example_test.csv', sep=',')\ndf_train = pd.read_csv(path+'train.csv',sep=',',usecols=cols,dtype=dtype)\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fed16c29":"df_train.info()","730b1166":"df_q['tags'] = df_q['tags'].astype(str)\n\ntags = [x.split() for x in df_q['tags'].values]\ntags = [item for elem in tags for item in elem]\ntags = set(tags)\ntags_df = pd.DataFrame()\ntags = list(tags)\ncorrect = df_train[df_train.answered_correctly != -1].groupby([\"content_id\", 'answered_correctly'], as_index=False).size()\ncorrect = correct.pivot(index= \"content_id\", columns='answered_correctly', values='size')\ncorrect.columns = ['Wrong', 'Right']\ncorrect = correct.fillna(0)\ncorrect[['Wrong', 'Right']] = correct[['Wrong', 'Right']].astype(int)\ndf_q = df_q.merge(correct, left_on = \"question_id\", right_on = \"content_id\", how = \"left\")\n\ndel correct\n\nfor i in range(len(tags)):\n    df = df_q[df_q.tags.str.contains(tags[i])].agg({'Wrong': ['sum'], 'Right': ['sum']})\n    df['tag'] = tags[i]\n    df = df.set_index('tag')\n    tags_df = tags_df.append(df)\n    \ndel tags\n\ntags_df['Percent_correct'] = tags_df.Right\/(tags_df.Right + tags_df.Wrong)\ntags_df = tags_df.sort_values(by = \"Percent_correct\")\n\ntags_df.head()","7e5fbe7e":"\ndf_train = df_train[df_train.content_type_id==False]\ndf_train[df_train.content_type_id==False]\ndel df_train['content_type_id']","028a84ee":"diff = 1\/tags_df.Percent_correct\ndiff","4f8c9a85":"\ndel df_q['question_id']\ndel df_q['part']\ndf_q['dif'] = df_q['Wrong']\/(df_q['Right']+df_q['Wrong'])\ndf_q\ndf_q.groupby('bundle_id')['dif'].mean()","f1877ae2":"df_lect","fe4c2451":"del df_q['correct_answer']\ndel df_q['tags']\ndel df_q['Wrong']\ndel df_q['Right']\ndf_train = df_train.merge(df_q,how = 'inner',left_on='content_id',right_on='bundle_id')\ndel df_train['content_id']\nanswers = df_train['answered_correctly']\ndel df_train['answered_correctly']\ndel df_train['bundle_id']\ndf_train","8a397418":"df_train = df_train.fillna(0)","892bd9fe":"df_train\ndf_train['timestamp'] = df_train['timestamp'].astype('float32')\ndf_train['prior_question_had_explanation'] = df_train['prior_question_had_explanation'].astype('float32')\nanswers = answers.to_numpy(dtype='bool')  \nanswers = np.array([answers, ~answers],dtype='int8').transpose()","8e05946f":"from sklearn import preprocessing\ndf_train = df_train.values\nmin_max_scaler = preprocessing.MinMaxScaler()\ndf_train = min_max_scaler.fit_transform(df_train)\n","13c9ca9d":"import tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.Sequential()\nact = 'relu'\nmodel.add(keras.layers.Dense(350, input_dim=4, activation=act))\n\nmodel.add(keras.layers.Dense(105, activation=act))\n\nmodel.add(keras.layers.Dense(2, activation='softmax'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['AUC'])","1829ce7a":"model.fit(df_train, answers, epochs=5, batch_size=10000,verbose=1,validation_split=0.3)\ndel df_train\ndel answers\nmodel.save('model')","31919369":"def Predict(df_test, df_q, model):\n    df_test = df_test.merge(df_q,how = 'inner',left_on='content_id',right_on='bundle_id')\n    row_id = df_test.row_id\n    df_test = df_test[['timestamp','prior_question_elapsed_time','prior_question_had_explanation','dif']]\n    df_test['timestamp'] = df_test['timestamp'].astype('float32')\n    df_test['prior_question_had_explanation'] = df_test['prior_question_had_explanation'].astype('float32')\n    df_test = df_test.values\n    min_max_scaler = preprocessing.MinMaxScaler()\n    df_test = min_max_scaler.fit_transform(df_test)\n    pred = model.predict(df_test)\n    return pred.reshape((2,len(pred)))[0]\n    \n    ","6b3281c7":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df[test_df['content_type_id']==0]\n    test_df['answered_correctly'] = Predict(test_df,df_q,model)\n    test_df = test_df[['row_id', 'answered_correctly']]\n    test_df.reset_index(drop=True, inplace=True).float_format='%.20f'.format\n    env.predict(test_df)\ntest_df","176b2c13":"model.fit(df_train, answers, epochs=1)"}}