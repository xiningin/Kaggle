{"cell_type":{"6217ce38":"code","0e64cac0":"code","86cb3e85":"code","7c9f17d8":"code","9b563597":"code","63060302":"code","664dfbe7":"code","6f1466c3":"code","2c5b9000":"code","3fa0fcc6":"code","51487100":"code","b5ae40ac":"code","e984ae12":"code","83b024da":"code","835ccae4":"code","472d23aa":"code","1d8a283e":"code","0630b6d0":"code","9a132b34":"code","2e51219a":"code","71a752a3":"code","f50aaf23":"code","d5600b26":"markdown","dbecd8a5":"markdown","05ae1ca1":"markdown","23af6b11":"markdown","ac7b588b":"markdown","e1a342b2":"markdown","5f67ed17":"markdown","464cccff":"markdown","18119a05":"markdown","b7ddeba1":"markdown","8711c494":"markdown","c992a95a":"markdown","fcc6d87d":"markdown"},"source":{"6217ce38":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom matplotlib import pyplot as plt","0e64cac0":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","86cb3e85":"PATH = \"\/kaggle\/input\/learn-together\/\"\n\nTRAIN_PATH = os.path.join(PATH,\"train.csv.zip\")\nTEST_PATH = os.path.join(PATH,\"test.csv.zip\")\nSUBMISSION_PATH = os.path.join(PATH,\"sample_submission.csv\")","7c9f17d8":"train_data = pd.read_csv(TRAIN_PATH, compression='zip')\ntest_data = pd.read_csv(TEST_PATH, compression='zip')","9b563597":"print(\"Shape of Train set:\",train_data.shape)\ntrain_data.head()","63060302":"print(\"Shape of Test set:\",test_data.shape)\ntest_data.head()","664dfbe7":"train_data.describe()","6f1466c3":"train_data.info()","2c5b9000":"train_data.duplicated().sum()","3fa0fcc6":"train_data['Cover_Type'].value_counts().plot(kind='bar')","51487100":"pairplot_cols = [\"Elevation\",\"Aspect\",\"Slope\"]\nsns.pairplot(train_data, \n             x_vars=pairplot_cols,\n             y_vars=pairplot_cols,\n             hue=\"Cover_Type\")","b5ae40ac":"def add_features(X_):\n    X = X_.copy()\n\n    X['Hydro_Elevation_diff'] = X[['Elevation','Vertical_Distance_To_Hydrology']].diff(axis='columns').iloc[:, [1]]\n\n    X['Hydro_Euclidean'] = np.sqrt(X['Horizontal_Distance_To_Hydrology']**2 + X['Vertical_Distance_To_Hydrology']**2)\n\n    X['Hydro_Fire_sum'] = X[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points']].sum(axis='columns')\n\n    X['Hydro_Fire_diff'] = X[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points']].diff(axis='columns').iloc[:, [1]].abs()\n\n    X['Hydro_Road_sum'] = X[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Roadways']].sum(axis='columns')\n\n    X['Hydro_Road_diff'] = X[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Roadways']].diff(axis='columns').iloc[:, [1]].abs()\n\n    X['Road_Fire_sum'] = X[['Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']].sum(axis='columns')\n\n    X['Road_Fire_diff'] = X[['Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']].diff(axis='columns').iloc[:, [1]].abs()\n    \n    # Compute Soil_Type number from Soil_Type binary columns\n    X['Stoneyness'] = sum(i * X['Soil_Type{}'.format(i)] for i in range(1, 41))\n    \n    # For all 40 Soil_Types, 1=rubbly, 2=stony, 3=very stony, 4=extremely stony, 0=?\n    stoneyness = [4, 3, 1, 1, 1, 2, 0, 0, 3, 1, \n                  1, 2, 1, 0, 0, 0, 0, 3, 0, 0, \n                  0, 4, 0, 4, 4, 3, 4, 4, 4, 4, \n                  4, 4, 4, 4, 1, 4, 4, 4, 4, 4]\n    \n    # Replace Soil_Type number with \"stoneyness\" value\n    X['Stoneyness'] = X['Stoneyness'].replace(range(1, 41), stoneyness)\n    \n    return X\n\n\ndef drop_features(X_):\n    X = X_.copy()\n    drop_cols = ['Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type14', 'Soil_Type15', \n                 'Soil_Type16', 'Soil_Type18', 'Soil_Type19', 'Soil_Type21', 'Soil_Type25', \n                 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type34', 'Soil_Type36', \n                 'Soil_Type37']\n    \n    X = X.drop(drop_cols, axis='columns')\n\n    return X\n","e984ae12":"print('  -- Processing train data')\ntrain_data = add_features(train_data)\ntrain_data = drop_features(train_data)\n\nprint('  -- Processing test data')\ntest_data = add_features(test_data)\ntest_data = drop_features(test_data)","83b024da":"train_data.drop(['Id'], axis=1, inplace=True)\ntest_data_ids = test_data.pop('Id')\nY = train_data.pop('Cover_Type')\nX = train_data","835ccae4":"X.shape, Y.shape","472d23aa":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)","1d8a283e":"from mlxtend.classifier import StackingCVClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nsvm_clf = SVC(verbose=0, random_state=42, probability=True)\nrf_clf = RandomForestClassifier(verbose=0, random_state=42)\n\nensemble = [('svm', svm_clf),\n            ('rf', rf_clf)]\n\nstack = StackingCVClassifier(classifiers=[clf for _, clf in ensemble],\n                             meta_classifier=rf_clf,\n                             cv=5,\n                             use_probas=True,\n                             use_features_in_secondary=False,\n                             verbose=1,\n                             random_state=42,\n                             n_jobs=-1)\nstack.fit(X_train,Y_train)","0630b6d0":"Y_pred = stack.predict(X_test)","9a132b34":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(Y_test, Y_pred))\nplt.show()","2e51219a":"from sklearn.metrics import accuracy_score\naccuracy_score(Y_test, Y_pred)","71a752a3":"final_stack = StackingCVClassifier(classifiers=[clf for _, clf in ensemble],\n                             meta_classifier=rf_clf,\n                             cv=5,\n                             use_probas=True,\n                             use_features_in_secondary=False,\n                             verbose=1,\n                             random_state=42,\n                             n_jobs=-1)\n\nfinal_stack.fit(X, Y)\npredictions = final_stack.predict(test_data)","f50aaf23":"pd.DataFrame(data={\"Id\": test_data_ids,\"Cover_Type\": predictions}).to_csv(\"submission.csv\", index=False)","d5600b26":"# Classification Accuracy","dbecd8a5":"**Making the Confusion Matrix**","05ae1ca1":"# Evaluating on val set","23af6b11":"**Loading Train and Test data**","ac7b588b":"# Some Data Visualizations","e1a342b2":"# Classifier","5f67ed17":"# Train Test Split","464cccff":"# Classify forest types based on information about the area\n![Competition Image](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/15767\/logos\/header.png)\n\n**Data fields:**\n* **Elevation** - Elevation in meters\n* **Aspect** - Aspect in degrees azimuth\n* **Slope** - Slope in degrees\n* **Horizontal_Distance_To_Hydrology** - Horz Dist to nearest surface water features\n* **Vertical_Distance_To_Hydrology** - Vert Dist to nearest surface water features\n* **Horizontal_Distance_To_Roadways** - Horz Dist to nearest roadway\n* **Hillshade_9am** (0 to 255 index) - Hillshade index at 9am, summer solstice\n* **Hillshade_Noon** (0 to 255 index) - Hillshade index at noon, summer solstice\n* **Hillshade_3pm** (0 to 255 index) - Hillshade index at 3pm, summer solstice\n* **Horizontal_Distance_To_Fire_Points** - Horz Dist to nearest wildfire ignition points\n* **Wilderness_Area** (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation\n* **Soil_Type** (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n* **Cover_Type** (7 types, integers 1 to 7) - Forest Cover Type designation\n\n**To predict:** an integer classification for the forest cover type.\n\nThe seven types are:\n1. Spruce\/Fir\n2. Lodgepole Pine\n3. Ponderosa Pine\n4. Cottonwood\/Willow\n5. Aspen\n6. Douglas-fir\n7. Krummholz\n\nThe training set (15120 observations) contains both features and the Cover_Type.\n\nThe test set (565892 observations) contains only the features.\n\n> Read more about competition here: https:\/\/www.kaggle.com\/c\/learn-together","18119a05":"**Prediction on test set**","b7ddeba1":"# Training model on full Train set","8711c494":"**Setting paths to data**","c992a95a":"# Importing Data","fcc6d87d":"# Importing Libraries"}}