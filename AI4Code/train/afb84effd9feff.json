{"cell_type":{"2b90002e":"code","2829b0d1":"code","1e391dd6":"code","24d4a39a":"code","6a537a7c":"code","5f060bca":"code","d94d0205":"code","db6d6642":"code","fc021080":"code","987cacd6":"code","8a872d35":"code","c990797e":"code","b61bc929":"markdown","3cd8ad4c":"markdown","74225b1e":"markdown","c8a1a829":"markdown","85bd65e8":"markdown","07a49c95":"markdown","a44a90e5":"markdown","4195b1d5":"markdown","7f088c18":"markdown","256b16db":"markdown","91b6092e":"markdown","0dc378f8":"markdown","05c70c33":"markdown","0ee87fbc":"markdown","dcb8b700":"markdown","8d2b7978":"markdown","71697e75":"markdown","21c1c105":"markdown"},"source":{"2b90002e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","2829b0d1":"#import data\n\nimport pandas as pd\n\ndf=pd.read_csv('\/kaggle\/input\/pima-indians_diabetes.csv')\n\ndf.info()","1e391dd6":"# EDA : describe data quickly by pandas-profiling\n\nfrom pandas_profiling import ProfileReport\n\nprofile=ProfileReport(df,title='Descriptive Analysis of Diabetes',html={'style':{'full_width':True}})","24d4a39a":"profile.to_widgets()","6a537a7c":"# TYPE OF MISSINGNESS\n\n\"\"\"We can use pandas profiling report for that, but i imlement 'missingno' package as being different tool\"\"\"\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\nmsno.matrix(df)\n\nplt.show()","5f060bca":"\"\"\"Analyzing the missingness of a variable against another variable helps \nyou determine any relationships between missing and non-missing values. \"\"\"\n\nimport numpy as np\nfrom numpy.random import rand\n\ndef dummy(df, scaling_factor=0.075):\n    df_dummy = df.copy(deep=True)\n    for col_name in df_dummy:\n        \n        col = df_dummy[col_name]\n        col_null = col.isnull()    \n    # Calculate number of missing values in column \n        num_nulls = col_null.sum()\n    # Calculate column range\n        col_range = col.max() - col.min()\n    # Scale the random values to scaling_factor times col_range\n        dummy_values = (rand(num_nulls) - 2) * scaling_factor * col_range + col.min()\n        col[col_null] = dummy_values\n    return df_dummy\n\n\n# Fill dummy values in diabetes_dummy\ndiabetes_dummy = dummy(df)\n\n# Sum the nullity of Skin_Fold and BMI\nnullity0 = df['Skin_Fold'].isnull()+df['BMI'].isnull()\n\n# Create a scatter plot of Skin Fold and BMI \ndiabetes_dummy.plot(x='Skin_Fold', y='BMI', kind='scatter', alpha=0.5,\n                    \n                    # Set color to nullity of BMI and Skin_Fold\n                    c=nullity0, \n                    cmap='rainbow')\n\n\nplt.show()","d94d0205":"# Sum the nullity of Skin_Fold and Serum_Insulin\nnullity1 = df['Skin_Fold'].isnull()+df['Serum_Insulin'].isnull()\n\n# Create a scatter plot of Skin Fold and BMI \ndiabetes_dummy.plot(x='Skin_Fold', y='Serum_Insulin', kind='scatter', alpha=0.5,\n                    \n                    # Set color to nullity of BMI and Skin_Fold\n                    c=nullity1, \n                    cmap='rainbow')","db6d6642":"# Correlations among Missingness\n\n# We can use heatmap or dendrogram which you have already seen at the profile-report. But in this code-line, i will missingno package.\n\n\n# Plot missingness heatmap of diabetes\nmsno.heatmap(df)\n\n# Plot missingness dendrogram of diabetes\nmsno.dendrogram(df)\n\n# Show plot\nplt.show()","fc021080":"# I will delete MAR type of missingness. I implement both 'all' and 'any' strategies to give example.Furthermore: \n\"\"\"https:\/\/www.w3resource.com\/pandas\/dataframe\/dataframe-dropna.php\"\"\"\n\n# Print the number of missing values in MAR types\nprint(df['Glucose'].isnull().sum())\nprint(df['BMI'].isnull().sum())\n\ndf_2 = df.copy(deep=True)\n\n# Drop rows where 'Glucose' has a missing value\ndf_2.dropna(subset=['Glucose'], how='any', inplace=True)\n\n# Drop rows where 'BMI' has a missing value\ndf_2.dropna(subset=['BMI'], how='all', inplace=True)\n\ndf_2.info()\n\ndf_drop=df.copy(deep=True)\ndf_drop.dropna(how='any',inplace=True)","987cacd6":"# I will create dummy dataframe for all techniques which i implement\n\n\n\nfrom sklearn.impute import SimpleImputer\n\n## Mean Imputation\n\n# Make a copy of diabetes\ndiabetes_mean = df_2.copy(deep=True)\n\n# Create mean imputer object\nmean_imputer = SimpleImputer(strategy='mean')\n\n# Impute mean values in the DataFrame diabetes_mean\ndiabetes_mean.iloc[:, :] = mean_imputer.fit_transform(diabetes_mean)\n\n## Median Imputation\n\n# Make a copy of diabetes\ndiabetes_median = df_2.copy(deep=True)\n\n# Create median imputer object\nmedian_imputer = SimpleImputer(strategy='median')\n\n# Impute median values in the DataFrame diabetes_median\ndiabetes_median.iloc[:, :] = median_imputer.fit_transform(diabetes_median)\n\n## Mode Imputation\n\n# Make a copy of diabetes\ndiabetes_mode = df_2.copy(deep=True)\n\n# Create mode imputer object\nmode_imputer = SimpleImputer(strategy='most_frequent')\n\n# Impute using most frequent value in the DataFrame mode_imputer\ndiabetes_mode.iloc[:, :] = mode_imputer.fit_transform(diabetes_mode)\n\n## Constant Imputation\n\n# Make a copy of diabetes\ndiabetes_constant = df_2.copy(deep=True)\n\n# Create median imputer object\nconstant_imputer = SimpleImputer(strategy='constant', fill_value=0)\n\n# Impute missing values to 0 in diabetes_constant\ndiabetes_constant.iloc[:, :] = constant_imputer.fit_transform(diabetes_constant)\n","8a872d35":"# Import KNN from fancyimpute\nfrom fancyimpute import KNN\n\n# Copy diabetes to diabetes_knn_imputed\ndiabetes_knn_imputed = df_2.copy(deep=True)\n\n# Initialize KNN\nknn_imputer = KNN()\n\n# Impute using fit_tranform on diabetes_knn_imputed\ndiabetes_knn_imputed.iloc[:, :] = knn_imputer.fit_transform(diabetes_knn_imputed)\n\n\n# Import IterativeImputer from fancyimpute\nfrom fancyimpute import IterativeImputer\n\n# Copy diabetes to diabetes_mice_imputed\ndiabetes_mice_imputed = df_2.copy(deep=True)\n\n# Initialize IterativeImputer\nmice_imputer = IterativeImputer()\n\n# Impute using fit_tranform on diabetes\ndiabetes_mice_imputed.iloc[:, :] = mice_imputer.fit_transform(diabetes_mice_imputed)","c990797e":"# Basic Graphics to demonstrate bias\n\ndf['Skin_Fold'].plot(kind='kde', c='red', linewidth=3)\ndf_drop['Skin_Fold'].plot(kind='kde')\ndiabetes_mean['Skin_Fold'].plot(kind='kde')\n#diabetes_median['Skin_Fold'].plot(kind='kde')\n#diabetes_mode['Skin_Fold'].plot(kind='kde')\n#diabetes_constant['Skin_Fold'].plot(kind='kde')\ndiabetes_knn_imputed['Skin_Fold'].plot(kind='kde')\ndiabetes_mice_imputed['Skin_Fold'].plot(kind='kde')\nlabels = ['First_Df','Baseline (Drop Any)', 'Mean Imputation', 'KNN Imputation',\n'MICE Imputation']\nplt.legend(labels)\nplt.xlabel('Skin Fold')\n\n#'Median_Imputation','Mode_Imputation','Constant_Imputation'","b61bc929":"I prefer to use pandas-profiling for small dataset, because it provides us with fundamental descriptive statistics and visualisation by one single code line. If you wonder about detail of usage and development history of pandas-profiling, you can look at https:\/\/github.com\/pandas-profiling\/pandas-profiling or https:\/\/pypi.org\/project\/pandas-profiling\/.  ","3cd8ad4c":"****Imputation Techniques****\n\nImputation techniques are differantiated from fundamental feature of the dataset. For example,while we implement KNN imputation at regression or classification problem, we implement linear interpolatation at time series analysis. In the diabetes dataset, we are striking to solve a classification problem. Therefore, I will mention about first-case imputation techniques. First of all, we seperately behave on variables according to their types, including categorical and numeric-float. In the  diabetes dataset, there is no categorical variable, so we will investigate how to deal with categorical variables at another kernel.\n\n**Basic Imputation**\n\n* Mode        \n* Mean       \n* Median\n* Constant\n\nBasic imputation technique reduce variance in the dataset as main disadvantage.\n\n**Advance Imputation**\n\nIt means actually, create ML models to predict composition of missing value. In this kernel, we will mention about;\n\n* KNN \n* MICE\n\nActaully there ara many sources to explain all of these methods, but i attach an short one. https:\/\/www.paultwin.com\/wp-content\/uploads\/Lodder_1140873_Paper_Imputation.pdf\n\n","74225b1e":"\nFirst of all, we should understand why data goes missing. In the terminology, the reason which triggers missing condition is composed of three concepts;\n\n1. MAR - Missing at Random\n\nIt means that propensity of missingness is not related to the missing data itself,rather it is related some of the observed data. In this situation, we cannot say major problem for removing missing values from dataset.\n\n2. MCAR - Missing Completely at Random\n\nIt means that propensity of missingness is not related to neither the missing data itself nor the observed data. In this situation, we can remove missing values from dataset.\n\n3. MNAR - Missing not at Random \n\nIt means that propensity of missingness is correlated with hypothetical value or some other variables' value. In this situation, imputation has high probability of giving better prediction result than removing them. Actually, we can say that imputation is necessity for better results.\n","c8a1a829":"# Exploratory Analysis","85bd65e8":"The above graphic gives us missingness pattern of each variable. We can say that 'BMI' and 'Glucose' are MCAR type; correlation is high but number of missing value is low, while 'Skin_Fold' and 'Serum_Insulin' are MNAR, plus Diastolic is MAR. We will use different techniques to evaluate them, but firstly we will look at correation of missingess. I will demonstrate relationship of missingness above as being between missing and non-missing values. Beacuse, we also should look at relationship missing value and non-missing observed values to determine missingness type.","07a49c95":"Red point reflects missing and blue point reflects non-missing values. As you can see, the 'BMI' and the 'Skin_Fold' variables are not correlated. The missing values of the 'Skin_Fold' variable spreadout throughout y axis. However, the missing values of the 'Serum_Insulin' spreadout throughout x_axis, so the correlated relationship can be seen at this graphic also.","a44a90e5":"1. KNN-MICE Imputation","4195b1d5":"****Interpretation about Profile-Report****\n\nIn this kernel, we will focus on how to deal with missing data.On the Missing widget, you can deeply investigate missing's count, correlations, and some visualisation such as Heatmap, dendrogram. In the dataset, while all number of observation is 768, missing cell ratio is 9.4%. When we look at details of missing data, 'Serum_Insulin' (49%) and 'Skin_Fold'(30%) have higher missing proportion among variables. The variable of 'BMI', 'Glucose','Diastolic_BP' have relatively small proportion of missingness within observation's volume.","7f088c18":"# Preprocessing of Missing Data\n1. Loading Dataset\n2. Exploratory Analysis - EDA\n3. Apporaches on Evaluation of the Missing Values\n4. Delete or Impute\n5. Evalutaion of Imputation Techniques","256b16db":"**Basic Linear Model**\n\nActually, I have to make some preprocessing implementation, such as scaling,splitting data, etc.. before fitting model algorithms on data , after fitting, to implement hypertuning.However, in this kernel we are focusing on missing values and i will evaluate effects of imputations' techniques by simple linear model result","91b6092e":"# Evaluation of Imputation Techniques\n","0dc378f8":"**Implementation of Deletion**","05c70c33":" **Implementation Imputation Techniques**","0ee87fbc":"# Delete or Impute\n\n****Lets Practice on Dataset****","dcb8b700":"1. Mean-Median-Mode-Constant Imputations","8d2b7978":"# Apporaches on Evaluation of the Missing Values","71697e75":"# Loading Dataset","21c1c105":"**Summary**\n\nAt the final graphic, we can see which imputation technique how generates bias from original dataset. While mean imputation is completely out of shape as compared to other impututations, the MICE and the KNN has lower bias. However, dataset which is generated by dropping any values is most resembled to original dataset."}}