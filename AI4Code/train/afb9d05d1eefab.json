{"cell_type":{"d73997fa":"code","19d1685c":"code","4920af69":"code","4c5a1907":"code","17e4d9ba":"code","9d991f38":"code","12863df3":"code","936b68bc":"code","cb44acbe":"code","1ccbe691":"code","cf9e192e":"code","4b731650":"code","21426160":"code","657ebc72":"code","66e3f2da":"code","0a3962a2":"code","60ea456e":"code","ab7a0ca2":"code","6cdbfdcb":"code","bc2899a2":"code","860ea2a2":"code","c05c6715":"code","58fbc10f":"code","add99396":"code","83fc1b8e":"code","331ea6c0":"code","c73db58a":"code","56c7b3e8":"code","dbf7fd2a":"code","331ab4dd":"code","7eeefd76":"code","0ef3911d":"code","3f64345a":"code","0820250f":"code","278e51a6":"code","496d8968":"code","ba1fb007":"code","56c192f8":"code","10874890":"code","620dbea4":"code","cb950958":"code","0b9184eb":"code","da97683d":"code","4baa16cd":"code","a985e6c6":"code","539acda6":"code","498aa483":"code","81c36c34":"code","3f0935d3":"code","b7f544e1":"code","cc0cd9bd":"code","a5cf5344":"code","da32ac44":"code","191074cb":"code","6a12db8b":"code","1d6e1e9e":"code","10e9a156":"code","94b1fd5d":"code","1050f5f5":"code","62526a43":"code","7771a807":"code","046edd78":"code","a6edec28":"code","a11b0b62":"code","72f61357":"code","341fdb18":"code","9bdc5697":"code","1f2c9414":"code","6defefa5":"code","b46ea8d5":"code","7823c264":"code","ab6857f6":"code","0c559914":"code","adf6b228":"code","b9c4f2cc":"code","e213776b":"code","d5d70ef0":"code","11e11b2e":"code","8ee8fe19":"code","2bd37f6b":"code","dad1b778":"code","412658e4":"code","38abae02":"code","c20030d6":"code","f768baf5":"code","a793b898":"code","56cd6563":"code","8aba0cc0":"code","84dca7ab":"code","f12dfaa1":"code","9d6b545d":"code","ac8f5f11":"code","fda3bdd8":"code","c3aebe15":"markdown","54ec6345":"markdown","c3284ce8":"markdown","3e008453":"markdown","fc8d1897":"markdown","8c06a3ae":"markdown","fb2899cc":"markdown","f6897b8c":"markdown","af905c50":"markdown","fac03b9b":"markdown","51171c47":"markdown","6f77bfa7":"markdown","9d3ace13":"markdown","1f348d3a":"markdown","29c0d46c":"markdown","74e14325":"markdown","6f176df7":"markdown","efbfdaa0":"markdown","684ef236":"markdown","f89521b9":"markdown","e50e879e":"markdown","7ecba368":"markdown","86bba06b":"markdown","d0a1670d":"markdown","039ede51":"markdown","5b3f629d":"markdown","ed016cf5":"markdown","8d45e0dd":"markdown","d8f270c4":"markdown","c40de21d":"markdown","22cceec3":"markdown","a84cd25d":"markdown","770f2858":"markdown","e5b0e4cc":"markdown","27e49768":"markdown","e893fc97":"markdown","43cb8102":"markdown","bf4c891f":"markdown","2f428176":"markdown","ca94570e":"markdown","50bc5674":"markdown","e7c5d4c4":"markdown","ad652292":"markdown","ea864b21":"markdown","3063de7c":"markdown","9e1f129b":"markdown","2003e9ea":"markdown"},"source":{"d73997fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns # For visialuzation\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # turn off warnings\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","19d1685c":"# plt.style.available shows which pilot types are usable","4920af69":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_PassengerId = test_df[\"PassengerId\"]","4c5a1907":"train_df.columns","17e4d9ba":"train_df.head()","9d991f38":"train_df.describe() #statisticals informations on numerical values","12863df3":"train_df.info()","936b68bc":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue) # x axis: number of category(m\/f), y axis: count of category\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","cb44acbe":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\nfor c in category1:\n    bar_plot(c)","1ccbe691":"category2 = [\"Cabin\",\"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","cf9e192e":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50) # bins' default is 10\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\") \n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","4b731650":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","21426160":"# Pclass vs Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","657ebc72":"# Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","66e3f2da":"# SibSp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","0a3962a2":"# Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","60ea456e":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indices\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 - outlier_step)].index\n        # store indices\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) # If there are more than one outlier, drop it\n    \n    return multiple_outliers","ab7a0ca2":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","6cdbfdcb":"# drop outliers\n#train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","bc2899a2":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","860ea2a2":"train_df.head()","c05c6715":"train_df.columns[train_df.isnull().any()]","58fbc10f":"train_df.isnull().sum()","add99396":"train_df[train_df[\"Embarked\"].isnull()]\n# Filling according to same values","83fc1b8e":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")\nplt.show()","331ea6c0":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","c73db58a":"train_df[train_df[\"Fare\"].isnull()]","56c7b3e8":"np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"])","dbf7fd2a":"train_df[\"Fare\"] =train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","331ab4dd":"train_df[train_df[\"Fare\"].isnull()]","7eeefd76":"train_df.isnull().sum()","0ef3911d":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\") #fmt virg\u00fclden sonra 2 basamak annot \u00fcst\u00fcnfde korelasyon de\u011ferlerini g\u00f6r\u00fcyoruz\nplt.show()","3f64345a":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","0820250f":"g = sns.factorplot(x = \"Parch\", y = \"Survived\",kind = \"bar\", size = 6, data = train_df)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","278e51a6":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\",kind = \"bar\", size = 6, data = train_df)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","496d8968":"g = sns.FacetGrid(train_df, col = \"Survived\",size = 6)\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","ba1fb007":"g = sns.FacetGrid(train_df, col =\"Survived\",row = \"Pclass\",size = 4)\ng.map(plt.hist, \"Age\",bins = 25)\ng.add_legend()\nplt.show()","56c192f8":"g = sns.FacetGrid(train_df,row = \"Embarked\", size = 4)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend() #Sa\u011fdaki g\u00f6stergeler\nplt.show()","10874890":"g = sns.FacetGrid(train_df,row = \"Embarked\", col = \"Survived\", size = 4)\ng.map(sns.barplot, \"Sex\",\"Fare\")\ng.add_legend() #Sa\u011fdaki g\u00f6stergeler\nplt.show()","620dbea4":"train_df[train_df[\"Age\"].isnull()]","cb950958":"sns.factorplot(x = \"Sex\",y=\"Age\",data = train_df, kind=\"box\")\nplt.show()","0b9184eb":"sns.factorplot(x = \"Sex\",y=\"Age\",hue= \"Pclass\", data = train_df, kind=\"box\")\nplt.show()","da97683d":"sns.factorplot(x = \"Parch\",y=\"Age\", data = train_df, kind=\"box\")\nsns.factorplot(x = \"SibSp\",y=\"Age\", data = train_df, kind=\"box\")\nplt.show()","4baa16cd":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","a985e6c6":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),annot= True)\nplt.show()","539acda6":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","498aa483":"train_df[train_df[\"Age\"].isnull()]","81c36c34":"train_df[\"Name\"].head(10)","3f0935d3":"s = \"McCarthy, Mr. Timothy J\"\ns.split(\".\")[0].split(\",\")[-1].strip()","b7f544e1":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","cc0cd9bd":"train_df[\"Title\"].head(10)","a5cf5344":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","da32ac44":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","191074cb":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","6a12db8b":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","1d6e1e9e":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","10e9a156":"train_df.head()","94b1fd5d":"# Merge the Title\ntrain_df = pd.get_dummies(train_df,columns=[\"Title\"])\n","1050f5f5":"train_df.head()","62526a43":"train_df.head()","7771a807":"# +1 is self person\ntrain_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","046edd78":"train_df.head()","a6edec28":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","a11b0b62":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","72f61357":"train_df.head(20)","341fdb18":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","9bdc5697":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","1f2c9414":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","6defefa5":"train_df[\"Embarked\"].head()","b46ea8d5":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","7823c264":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","ab6857f6":"train_df[\"Ticket\"].head(20)","0c559914":"a = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","adf6b228":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","b9c4f2cc":"train_df[\"Ticket\"].head(20)","e213776b":"train_df.head()","d5d70ef0":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\") # Replace Ticket with T\ntrain_df.head(10)","11e11b2e":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","8ee8fe19":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","2bd37f6b":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","dad1b778":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","412658e4":"train_df.columns","38abae02":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","c20030d6":"train_df_len","f768baf5":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","a793b898":"test.head()","56cd6563":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","8aba0cc0":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) # %100, float 2 digit\nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","84dca7ab":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state), # Support Vector Classifier\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20), # Decision Tree Parameter\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],  # Support Vector Classifier Parameter\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10], # Random Forest Parameter\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),  # Logistic Regression Parameter\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(), # KNN Parameter\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","f12dfaa1":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","9d6b545d":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","ac8f5f11":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","fda3bdd8":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","c3aebe15":"<a id='18'><\/a>\n## Embarked -- Sex -- Pclass -- Survived","54ec6345":"* float64(2): Fare and Age\n* int64(5): Pclass, Sibsp, Parch, PassengerId and Survived\n* object(5): Embarked, Cabin, Ticket, Name and Sex","c3284ce8":"1st class passengers are older than 2nd class and 2nd class is older than 3rd class.","3e008453":"<a id='7'><\/a>\n# Outlier Detection","fc8d1897":"<a id='30'><\/a>\n## Train - Test Split","8c06a3ae":"<a id='34'><\/a>\n## Prediction and Submission","fb2899cc":"* pclass is important feature for model training","f6897b8c":"<a id='22'><\/a>\n## Name -- Title","af905c50":"Age is not correlated with sex but it is correlated with parch, sibsp and pclass.","fac03b9b":"# Introduction\nThe sinking of Titanic is one of them most notorious ship wreck in the history. In 1912, during her voyage, the Titanic sank after colliding with and iceberg, killing 1582 out of 2224 passenger and crew.\n<font color= 'pink'>\nContent:\n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n     * [Univariate Variable Analysis](#3)\n        * [Categorical Variable Analysis](#4)\n        * [Numerical Variable Analysis](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing; Age Feature](#20)\n7. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop Passenger ID and Cabin](#28)\n8. [Modelling](#29)\n    * [Train - Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)","51171c47":"<a id='3'><\/a>\n# Univariate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n* Numerical Variable: Age, PassengerId and Fare","6f77bfa7":"<a id='11'><\/a>\n# Visualization","9d3ace13":"<a id='10'><\/a>\n## Fill Missing Value\n* Embarked has 2 missing value\n* Fare has only 1","1f348d3a":"<a id='5'><\/a>\n## Numerical Variable","29c0d46c":"<a id='4'><\/a>\n## Categorical Variable","74e14325":"<a id='28'><\/a>\n## Drop Passenger ID and Cabin","6f176df7":"<a id='15'><\/a>\n## Pclass -- Survived","efbfdaa0":"<a id='21'><\/a>\n# Feature Engineering","684ef236":"<a id='29'><\/a>\n# Modeling","f89521b9":"<a id='24'><\/a>\n## Embarked","e50e879e":"<a id='2'><\/a>\n# Variable Description\n1. PassengerId: unique id number to each passanger\n1. Survived: passenger survive(1) or died(0)\n1. Pclass: passenger class\n1. Name: name\n1. Sex: gender of passenger\n1. Age: age of passenger\n1. SibSp: number of siblings\/spouses\n1. Parch: number of parents\/children\n1. Ticket: ticket number\n1. Fare: amount of money for ticket\n1. Cabin: cabin category\n1. Embarked: port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)","7ecba368":"* SibSp and parch can be used for new feature extraction with threshold = 3\n* Small families have more chance to survive.\n* There is a std in survival of passenger eith parch = 3","86bba06b":"<a id='9'><\/a>\n## Find Missing Value","d0a1670d":"<a id='16'><\/a>\n## Age -- Survived","039ede51":"<a id='20'><\/a>\n## Fill Missing; Age Feature","5b3f629d":"<a id='26'><\/a>\n## Pclass","ed016cf5":"Sex is not informative for age prediction, age distribution seems to be same. ","8d45e0dd":"<a id='31'><\/a>\n## Simple Logistic Regression","d8f270c4":"<a id='12'><\/a>\n## Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","c40de21d":"<a id = \"1\"><\/a>\n# Load and Check Data","22cceec3":"<a id='19'><\/a>\n## Embarked -- Sex -- Fare -- Survived","a84cd25d":"<a id='33'><\/a>\n## Ensemble Modeling","770f2858":"<a id='8'><\/a>\n# Missing Value\n* Find Missing Value\n* Fill Missing Value","e5b0e4cc":"<a id='13'><\/a>\n## SibSp -- Survived","27e49768":"<a id='14'><\/a>\n## Parch -- Survived","e893fc97":"Small families have more chance to survive than large families.","43cb8102":"* Passangers who pay higher fare have better survival rate. Fare can be used as categorical for training.","bf4c891f":"<a id='17'><\/a>\n## Pclass -- Survived -- Age","2f428176":"<a id='32'><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","ca94570e":"<a id='27'><\/a>\n## Sex","50bc5674":"<a id='6'><\/a>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","e7c5d4c4":"Fare feature seems to have correlation with survived feature (0.30)","ad652292":"* Having a lot of SibSp have less chance to survive\n* If SibSp == 0 or 1 or 2, passenger has more chance to survive\n* We can consider a new feature describing these categories","ea864b21":"<a id='23'><\/a>\n## Family Size","3063de7c":"* age <= 10 has a high survival rate,\n* older passengers (80) survived,\n* large number of 20 years old did not survived\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","9e1f129b":"* Female passengers have much better survival rate than males.\n* Males have better survived rate in Pclass 3 in Embarked == C.\n* Embarked and sex will be used in training.","2003e9ea":"<a id='25'><\/a>\n## Ticket"}}