{"cell_type":{"5c279e63":"code","76845fa6":"code","2559f986":"code","8e50822a":"code","8ce0d88a":"code","026da8b7":"code","98b17f7b":"code","9d0132d9":"code","a3907be0":"code","33b350b3":"code","6aa24218":"code","aa2c0c83":"code","cbda0fd2":"code","30c2b793":"code","254d03ec":"code","93f8f917":"code","4a9b18ab":"markdown","03392880":"markdown","fcc67523":"markdown","908fec27":"markdown","aa400335":"markdown","b21f3a7c":"markdown","a9858df3":"markdown","2ce0c3f1":"markdown","89584ba8":"markdown","1724dca9":"markdown","b2f568cb":"markdown","34533c9e":"markdown","49504a63":"markdown","f401fbee":"markdown","6694b8c8":"markdown"},"source":{"5c279e63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\n# set the matplotlib backend so figures can be saved in the background\nimport matplotlib .pyplot as plt\n# import the necessary packages\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras import backend as K\nimport random\nimport os\n\n# Any results you write to the current directory are saved as output.","76845fa6":"# referred https:\/\/www.kaggle.com\/justdvnsh\/v2-plant-seedling-classification \n\nclass SmallVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes):\n        model = Sequential()\n        model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (width, height, 3)))\n        model.add(Conv2D(32, (3,3), activation = 'relu'))\n        model.add(Conv2D(32, (3,3), activation = 'relu'))\n        model.add(MaxPooling2D(pool_size = (2,2))) \n        model.add(Dropout(0.3))\n\n        model.add(Conv2D(64, (3,3), activation ='relu'))\n        model.add(Conv2D(64, (3,3), activation ='relu'))\n        model.add(Conv2D(64, (3,3), activation ='relu'))\n        model.add(MaxPooling2D(pool_size = (2,2)))\n        model.add(Dropout(0.3))\n\n        model.add(Conv2D(128, (3,3), activation ='relu'))\n        model.add(Conv2D(128, (3,3), activation ='relu'))\n        model.add(Conv2D(128, (3,3), activation ='relu'))\n        model.add(MaxPooling2D(pool_size = (2,2)))\n        model.add(Dropout(0.3))\n\n        \n        model.add(Dense(256, activation = \"relu\"))\n        model.add(Flatten())\n        model.add(Dropout(0.3))\n        model.add(Dense(12, activation = \"softmax\"))\n       \n    \n        # return the constructed network architecture\n        return model","2559f986":"data = []\nlabels = []\n\nfor path, _, files in os.walk('..\/input\/nonsegmentedv2'):\n    imagesPaths =  sorted([image for image in files])\n    #print(imagesPaths)\n    for imagePath in imagesPaths:\n        image = cv2.imread('..\/input\/nonsegmentedv2\/'+ path.split('\/')[3] + '\/' + imagePath)\n        image = cv2.resize(image, (96,96))\n        data.append(image)\n        labels.append(path.split('\/')[3])\n        \n","8e50822a":"data = np.array(data, dtype='float32')\nlabels = np.array(labels)","8ce0d88a":"# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)","026da8b7":"## Here We are just doing the one-hot encoding for the labels.\nlb = LabelBinarizer()\ntrainY = lb.fit_transform(trainY)\ntestY = lb.transform(testY)","98b17f7b":"# construct the image generator for data augmentation\n# construct the image generator for data augmentation\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                        horizontal_flip=True, fill_mode=\"nearest\")\n \n\"\"\"\nImage augmentation allows us to construct \u201cadditional\u201d training data from our existing training data by randomly rotating, shifting, shearing, zooming, and flipping.\n\nData augmentation is often a critical step to:\n\n1) Avoiding overfitting\n2) Ensuring your model generalizes well\n\"\"\"\n    \n# initialize our VGG-like Convolutional Neural Network\nmodel = SmallVGGNet.build(width=96, height=96, depth=3,classes=len(lb.classes_))","9d0132d9":"# initialize our initial learning rate, # of epochs to train for,\n# and batch size\n\nEPOCHS = 100\nBS = 32\n                                                     \n# initialize the model and optimizer \nprint(\"[INFO] training network...\")\n\nmodel.compile(Adam(lr=0.0001), loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\n# train the network\nh = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n                                validation_data=(testX, testY), \n                                steps_per_epoch=len(trainX) \/\/ BS,\n                                epochs=EPOCHS, )","a3907be0":"# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions = model.predict(testX, batch_size=32)\nprint(classification_report(testY.argmax(axis=1),\n                            predictions.argmax(axis=1), target_names=lb.classes_))\n \n# plot the training loss and accuracy\nN = np.arange(0, EPOCHS)\nplt.figure()\nplt.plot(N, h.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, h.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, h.history[\"acc\"], label=\"train_acc\")\nplt.plot(N, h.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()","33b350b3":"from keras.models import model_from_json\nimport json","6aa24218":"model_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(\"amodel.h5\")\nprint(\"Saved model\")","aa2c0c83":"!ls","cbda0fd2":"#loading saved model\n\njson_file = open('model.json','r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n#load weights into new model\nloaded_model.load_weights(\"amodel.h5\")\nprint(\"Loaded model\")","30c2b793":"#predictiong using loaded model\nloaded_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', \n              metrics=['accuracy'])","254d03ec":"image = cv2.imread('..\/input\/nonsegmentedv2\/Fat Hen\/100.png')\nimage = cv2.resize(image, (96,96))\nnp_image = np.array(image)\ny = np.expand_dims(np_image, axis=0)\npred = loaded_model.predict(y)\nprint(pred)\npred.shape","93f8f917":"y_pred_binary = pred.argmax(axis=1)\n\n\nif y_pred_binary==[0]:\n    print(\"Black-Grass\")\nelif y_pred_binary==[1]:\n    print(\"Charlock\") \nelif y_pred_binary==[2]:\n    print(\"Cleavers\") \nelif y_pred_binary==[3]:\n    print(\"Common Chickweed\") \nelif y_pred_binary==[4]:\n    print(\"Common Wheat\") \nelif y_pred_binary==[5]:\n    print(\"Fat Hen\") \nelif y_pred_binary==[6]:\n    print(\"Loose silky-bent\") \nelif y_pred_binary==[7]:\n    print(\"Maize\") \nelif y_pred_binary==[8]:\n    print(\"Scentless Mayweed\") \nelif y_pred_binary==[9]:\n    print(\"Shepherd's Purse\") \nelif y_pred_binary==[10]:\n    print(\"Small-flowered Cranesbill\") \nelif y_pred_binary==[11]:\n    print(\"Sugar beet\") \n","4a9b18ab":"Setting the Optimizer for the loaded model :","03392880":"# Defining the Model Architecture with minute changes to SmallVGGNet layers:","fcc67523":"# Splitting of Train and Test data in 3:1 ratio : ","908fec27":"# Plant Seedling Classification among 12 species\n#### The Plant Seedlings Dataset contains images of unique plants belonging to 12 species at several growth stages. It comprises annotated RGB images with a physical resolution of roughly 10 pixels per mm. The database have been recorded at Aarhus University Flakkebjerg Research station in a collaboration between University of Southern Denmark and Aarhus University.\n\n### This trained model has the Validation Accuracy of 86%.","aa400335":"Importing Packages required for Saving and Loading the Trained model : ","b21f3a7c":"# Training the Model :","a9858df3":"# Loading the Model :","2ce0c3f1":"### Setting up the ImageDataGenerator :","89584ba8":"# Importing all the required packages:","1724dca9":"#### As we can see here , we got a 86% accuracy.\n","b2f568cb":"# All the Images and their respective Labels are being saved into 2 separate arrays:","34533c9e":"# Saving the Model :","49504a63":"# Printing Classification Report and Plots for visualizing Train_loss, Val_loss, Train_acc, Val_acc :","f401fbee":"# Predicting the Plant Specie of a Sample Input Image :","6694b8c8":"### Converting arrays into Numpy arrays : "}}