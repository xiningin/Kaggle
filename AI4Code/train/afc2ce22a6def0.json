{"cell_type":{"c32cb717":"code","65e69c4f":"code","7c1af3cb":"code","80df6f9c":"code","cf8d42fc":"code","ded5b17a":"code","110c8228":"code","28279cbf":"code","aaacab99":"code","be374547":"code","efc6319d":"code","0c4b2f76":"code","590c4992":"code","1d7c7e5a":"code","1307d845":"code","2e9cf90e":"code","cd04d870":"code","037c4ddf":"code","b2fc3fe3":"code","8a00bba5":"code","12e417e5":"code","1412abab":"code","9704c97d":"code","08a2ee40":"code","0a04e552":"code","9ad2d6c3":"code","57f1ee32":"markdown","e6e4d8db":"markdown","87393901":"markdown","5b44cd8d":"markdown","ba32a45f":"markdown","c8af85c2":"markdown","a036cf9c":"markdown","6a83107a":"markdown","3315a459":"markdown","1347d1e3":"markdown","8a791682":"markdown","88f1535e":"markdown","392c0eb8":"markdown","958e1940":"markdown","0fdce8a7":"markdown","be1a3e22":"markdown","6d333b64":"markdown","e7ce5da0":"markdown","83c41923":"markdown","6e128467":"markdown","59566fb4":"markdown","9495ae7a":"markdown","60d82bb7":"markdown","7f10e3c3":"markdown"},"source":{"c32cb717":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","65e69c4f":"import warnings\nwarnings.filterwarnings('ignore')","7c1af3cb":"train = pd.read_csv('..\/input\/telstra-recruiting-network\/train.csv.zip')\ntest = pd.read_csv('..\/input\/telstra-recruiting-network\/test.csv.zip')\nseverity_type = pd.read_csv('..\/input\/telstra-recruiting-network\/severity_type.csv.zip', error_bad_lines= False, warn_bad_lines= False)\nresource_type = pd.read_csv('..\/input\/telstra-recruiting-network\/resource_type.csv.zip', error_bad_lines= False, warn_bad_lines= False)\nlog_failure = pd.read_csv('..\/input\/telstra-recruiting-network\/log_feature.csv.zip', error_bad_lines= False, warn_bad_lines= False)\nevent_type = pd.read_csv('..\/input\/telstra-recruiting-network\/event_type.csv.zip', error_bad_lines=False, warn_bad_lines= False)","80df6f9c":"print('The shape of test set is: {}\\n'.format(test.shape))\nprint('The shape of train set is: {}\\n'.format(train.shape))\nprint('The shape of severity_type is: {}\\n'.format(severity_type.shape))\nprint('The shape of resource_type is: {}\\n'.format(resource_type.shape))\nprint('The shape of log_failure is: {}\\n'.format(log_failure.shape))\nprint('The shape of event_type is: {}'.format(event_type.shape))","cf8d42fc":"train.head()","ded5b17a":"train_1 = train.merge(severity_type, how = 'left', left_on='id', right_on='id')\ntrain_2 = train_1.merge(resource_type, how = 'left', left_on='id', right_on='id')\ntrain_3 = train_2.merge(log_failure, how = 'left', left_on='id', right_on='id')\ntrain_4 = train_3.merge(event_type, how = 'left', left_on='id', right_on='id')","110c8228":"train_4.head()","28279cbf":"train_4.drop_duplicates(subset= 'id', keep= 'first', inplace = True)\ntrain_4.head()","aaacab99":"plt.figure(figsize = (8,6))\nsns.countplot(train_4['fault_severity'])\nplt.show()","be374547":"plt.figure(figsize = (8,6))\nsns.countplot(train_4['severity_type'])\nplt.show()","efc6319d":"plt.figure(figsize = (14,6))\nsns.countplot(train_4['resource_type'])\nplt.tight_layout()\nplt.show()","0c4b2f76":"from catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split","590c4992":"X = train_4[['id', 'location', 'severity_type', 'resource_type',\n       'log_feature', 'volume', 'event_type']]\ny = train_4.fault_severity","1d7c7e5a":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.20, random_state=101)","1307d845":"categorical_features_indices = np.where(X_train.dtypes == object)[0]","2e9cf90e":"train_dataset = Pool(data=X_train,\n                     label=y_train,\n                     cat_features=categorical_features_indices)\n\neval_dataset = Pool(data=X_validation,\n                    label=y_validation,\n                    cat_features=categorical_features_indices)","cd04d870":"model = CatBoostClassifier(iterations=1000,\n                           learning_rate=1,\n                           depth=2,\n                           loss_function='MultiClass',\n                           random_seed=1,\n                           bagging_temperature=22,\n                           od_type='Iter',\n                           metric_period=100,\n                           od_wait=100)","037c4ddf":"model.fit(train_dataset, eval_set= eval_dataset, plot= True)","b2fc3fe3":"# Get predicted classes\npreds_class = model.predict(eval_dataset)\n\n# Get predicted probabilities for each class\npreds_proba = model.predict_proba(eval_dataset)","8a00bba5":"test.head()","12e417e5":"test_1 = test.merge(severity_type, how = 'left', left_on='id', right_on='id')\ntest_2 = test_1.merge(resource_type, how = 'left', left_on='id', right_on='id')\ntest_3 = test_2.merge(log_failure, how = 'left', left_on='id', right_on='id')\ntest_4 = test_3.merge(event_type, how = 'left', left_on='id', right_on='id')","1412abab":"test_4.head()","9704c97d":"test_4.drop_duplicates(subset= 'id', keep= 'first', inplace = True)\ntest_4.head()","08a2ee40":"test_4.isnull().sum()","0a04e552":"predict_test=model.predict_proba(test_4)\npred_df=pd.DataFrame(predict_test,columns=['predict_0', 'predict_1', 'predict_2'])\nsubmission_cat=pd.concat([test[['id']],pred_df],axis=1)\nsubmission_cat.to_csv('sub_cat_1.csv',index=False,header=True)","9ad2d6c3":"submission_cat.head()","57f1ee32":"**As the model was getting overfit  after initial iterations so it was stopped by overfitting detector in Catboost.**","e6e4d8db":"**Count plot for fault severity**","87393901":"Not very balanced data set as values with fault_severity \u2018zero\u2019 (indicating no fault) are very high as compared with others. So ML models might be biased towards fault severity value of \u2018zero\u2019.","5b44cd8d":"# Making predictions on test set","ba32a45f":"**As we can see that there are some duplicates. So let's remove them all.**","c8af85c2":"# Telstra Network Disruptions","a036cf9c":"**Count plot for resource type**","6a83107a":"**Reading the files**","3315a459":"**Checking the head after merging**","1347d1e3":"**Making the initial imports and suppress the un-wanted warning messages**","8a791682":"**These are the predicted probabilites. The column with the highest value is the predicted class of severity.**","88f1535e":"**Checking the head of training file before merging it with other files**","392c0eb8":"**Remove duplicate values**","958e1940":"# Data Preprocessing","0fdce8a7":"Most of the resource types are either type_2 or type_8.","be1a3e22":"# Exploratory Data Analysis (EDA)","6d333b64":"Catboost is an opensource machine learning algorithm from Yandex (Russian search engine like Google). It can work with wide range of data types and can help solve various problems. The catboost algo does not need extensive training (computing efficiency)  and can better handle categorical features.","e7ce5da0":"**Printing the shape of all given files**","83c41923":"Telstra is the largest Telecom Service Provider in Australia. They posted this challenge on kaggle few years ago as part of their recruitment exercise to hire potential data scientists. We are given a data set which is from Telstra\u2019s service logs and we are required to predict the severity of service disruptions (if a disruption is a temporary glitch or is it critical and will result in total loss of service).  This challenge was crafted as a simulation of the type of problem one might encounter as a member of data science team at Telstra.","6e128467":"Severity_type_1 and 2 are very high as compared with others.","59566fb4":"# CatBoost","9495ae7a":"# Getting the test set ready to feed into the model","60d82bb7":"**Count plot for severity type**","7f10e3c3":"**Merging the data sets to have all the available info**"}}