{"cell_type":{"e39a2653":"code","e3d3f496":"code","cc82f6fd":"code","2a94388d":"code","55d8e444":"code","c424f9f1":"code","1acd9c82":"code","02f96386":"code","c4009379":"code","dc8e6a34":"code","ba3efdd6":"code","f5ddf5f7":"code","c3946da7":"code","ee616fe5":"code","03dc7a13":"code","cc9b09a7":"code","56b5b344":"code","a530a410":"code","0adf33e3":"code","8394ed11":"code","96c4dce8":"markdown","687cde0b":"markdown","f7e31c65":"markdown","7364609b":"markdown","fce36517":"markdown","1d15bcfe":"markdown","1739bad8":"markdown","6d5686ca":"markdown","51927703":"markdown","7ecfde24":"markdown","3504773c":"markdown","9df63edf":"markdown","a85ee0af":"markdown","43583f98":"markdown","50ec256a":"markdown","d79c81c4":"markdown","e6ffb45f":"markdown","ca8f7ad2":"markdown","18a86311":"markdown","147c34d6":"markdown","c4c6a2c2":"markdown"},"source":{"e39a2653":"# Importing necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn import neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3d3f496":"# Reading the data \ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","cc82f6fd":"# Display the first 5 rows\ntrain.head()\n\ntrain.shape # No. of observations, variables\ntrain.columns # Features\/variables\ntrain.info() # check data types of each attribute\n\n# My hypothesis is that PClass (proxy for SES), Sex, Age, SibSp, and Parch had the highest impact on whether\n# a passenger survived. I will explore these, starting with Sex.\n\n# Calculating rate of survival for women vs. men.\nwomen = train.loc[train.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nmen = train.loc[train.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(\"Rate of Survival \\n\"\"Women: \" + str(rate_women) + \"\\nMen: \" + str(rate_men))","2a94388d":"# Determine missing values\ntrain.isnull().sum()","55d8e444":"from sklearn.ensemble import RandomForestClassifier\n\ny = train[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\n# output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n# print(output)\n# output.to_csv('submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")\n\nprint(model.score(X, y))\n","c424f9f1":"sns.barplot(x='Sex', y = 'Survived', data = train)","1acd9c82":"sns.barplot(x='Pclass', y = 'Survived', data = train)","02f96386":"# There are some missing values for ages in both the training and the test data.\nprint(\"Missing values for training data\" + \"\\n\" + str(train.isnull().sum()))\nprint(\"Missing values for test data\" + \"\\n\" + str(test.isnull().sum()))","c4009379":"# Padding the training data\ntrain['Age'].fillna(method = 'pad', inplace = True)\n\n# Padding the test data\ntest['Age'].fillna(method = 'pad', inplace = True)\ntest['Fare'].fillna(method = 'pad', inplace = True)","dc8e6a34":"sns.barplot(x= 'Age', y = 'Survived', data = train)","ba3efdd6":"# My first model is a linear regression model with\n# features I believe are of most importance.\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Instantiate the model and our feature\nmodel = LinearRegression()\nfeatures = [\"Sex\", \"Pclass\"]\n\n# Getting random entries for this label\nx_train = pd.get_dummies(train[features])\ny_train = train[\"Survived\"]\nx_test = pd.get_dummies(test[features])\n\n# Training model\nmodel.fit(x_train, y_train)\n\n# Our predictions\ny_pred = model.predict(x_test)\nprint(model.score(x_train, y_train))","f5ddf5f7":"# Instantiate the model and our feature\nmodel = LinearRegression()\nfeatures = [\"Sex\", \"Pclass\", \"Age\"]\n\n# Getting random entries for this label\nx_train = pd.get_dummies(train[features])\ny_train = train[\"Survived\"]\nx_test = pd.get_dummies(test[features])\n\n# Training model\nmodel.fit(x_train, y_train)\n\n# Our predictions\ny_pred = model.predict(x_test)\nprint(model.score(x_train, y_train))","c3946da7":"features = [\"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\ny = train[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 1) \n\nknn = neighbors.KNeighborsClassifier(n_neighbors=6)\nknn.fit(X_train, y_train)\n\npredictions = knn.predict(X_test)","ee616fe5":"# Scikit provides a convenient report to give an idea of the accuracy of a model using a number of measures. \nprint(classification_report(y_test, predictions))\n\n# displaying our score\nprint(knn.score(X_test, y_test))","03dc7a13":"features = [\"Sex\",\"Parch\", \"Fare\"]\nX_train = pd.get_dummies(train[features])\ny_train = train[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 1) \n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)","cc9b09a7":"# Determining the accuracy and scoring of the predictions due to the model\nprint(classification_report(y_test, predictions)) \nprint(model.score(X_test, y_test))","56b5b344":"## Building the model to match submission Data","a530a410":"features = [\"Sex\",\"Parch\", \"Fare\"]\nX_train = pd.get_dummies(train[features])\ny_train = train[\"Survived\"]\n\nX_test = pd.get_dummies(test[features])\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n","0adf33e3":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8394ed11":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","96c4dce8":"### As expected, those with a higher (proxy) SES survived compared to lower SES. ","687cde0b":"### Exploring missing values\n","f7e31c65":"### This is a reasonable model for prediction on new data. Let's see if we can do better.","7364609b":"There are 2 missing values from the training data but 86 missing from the test data, roughly 10%. We *can* pad the data to get a decent approximation. ","fce36517":"### Let's make some plots to explore variables I believe are likely to affect survival rate.","1d15bcfe":"### But these three alone are not adequate enough to predict survival chance on new data. ","1739bad8":"### Evaluating the model","6d5686ca":"### Building the model","51927703":"# My Models","7ecfde24":"## Model: Linear Regression (Sex, Pclass, and Age)","3504773c":"### Building the Model","9df63edf":"## Exploring the Data","a85ee0af":"### Without age","43583f98":"## Tutorial: First Machine Learning Model (Random Forest)\n### Building & Running`","50ec256a":"### From the chart below we can see that more women survived when compared to men. ","d79c81c4":"## Reading the Data","e6ffb45f":"## Nearest Neighbor Classifier","ca8f7ad2":"### Evaluating the Model","18a86311":"## Decision Tree Model","147c34d6":"### There is limited information we get from this bar plot other than it appears that younger and older folks had a higher survival rate. ","c4c6a2c2":"## This is slightly better. "}}