{"cell_type":{"3ff00118":"code","89da196d":"code","030b1f79":"code","bb70a3f9":"code","d978605e":"code","6ce33c73":"code","a7fe4cb0":"code","69046620":"code","07622806":"code","5f418029":"code","092606a0":"code","9716ea4a":"code","ddc63435":"code","c93cd622":"code","5e4115b5":"code","3372d48c":"code","88a781a4":"code","26aaaf51":"code","61585e66":"code","e65694f5":"code","de804586":"code","1df0ca6a":"code","5a37cfd1":"code","f14b8cad":"code","0f620543":"markdown","991c89e9":"markdown","963a6316":"markdown","f40b3c3c":"markdown","60055798":"markdown","6b977c1d":"markdown"},"source":{"3ff00118":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_colwidth', None)\n\nimport string\nimport keras\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89da196d":"df=pd.read_csv('\/kaggle\/input\/medicaltranscriptions\/mtsamples.csv')","030b1f79":"df.head(1)","bb70a3f9":"tweet = \"I am tired! I like fruit...and milk\"\ntranslator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\ntweet.translate(translator)","d978605e":"no_punc_translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\ndf['transcription_lower']=df['transcription'].apply(lambda x: ' '.join([i for i in str(x).lower().translate(no_punc_translator).split(' ') if i.isalpha()]))","6ce33c73":"df.head(1)","a7fe4cb0":"df['medical_specialty'].nunique()","69046620":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","07622806":"vectorizer=CountVectorizer(analyzer='word')\nfeature_space=vectorizer.fit_transform(list(df['transcription_lower']))","5f418029":"count_vect_df = pd.DataFrame(feature_space.todense(), columns=vectorizer.get_feature_names())\nnew_df=pd.concat([df, count_vect_df], axis=1)","092606a0":"new_df.columns","9716ea4a":"X=new_df.loc[:, 'aa':]\n\n\nlb_make = LabelEncoder()\nnew_df[\"medical_specialty_code\"] = lb_make.fit_transform(new_df[\"medical_specialty\"])\n\n\nY=new_df['medical_specialty_code']","ddc63435":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","c93cd622":"y_train=keras.utils.to_categorical(y_train, df['medical_specialty'].nunique())\ny_test=keras.utils.to_categorical(y_test, df['medical_specialty'].nunique())","5e4115b5":"print(X_train.shape)\n# print(X_train[0])\n\nprint(y_train.shape)\nprint(y_train[0])","3372d48c":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.callbacks import ModelCheckpoint","88a781a4":"def build_sequential(input_size, output_size):\n    model=Sequential()\n    model.add(Dense(512, input_shape=(input_size, )   ))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(len(output_size)))\n    model.add(Activation('softmax'))\n    return model","26aaaf51":"# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.CategoricalAccuracy()])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size=200\nepochs=5\n\n# checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=False, mode='auto')\n\nhistory=model.fit(np.array(X_train), np.array(y_train), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)","61585e66":"print (model.evaluate(np.array(X_test), np.array(y_test)))","e65694f5":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm","de804586":"# word level tf-idf\ntfidf_vect = TfidfVectorizer(analyzer='word', max_features=10000)\ntfidf_feature_space = tfidf_vect.fit_transform(df['transcription_lower'])\ntfidf_vect_df = pd.DataFrame(tfidf_feature_space.todense(), columns=tfidf_vect.get_feature_names())\ntfidf_df=pd.concat([df, tfidf_vect_df], axis=1)\n\nX_tfidf=tfidf_df.loc[:, 'abc':]\nencoder = LabelEncoder()\ntfidf_df[\"medical_specialty_code\"] = encoder.fit_transform(tfidf_df[\"medical_specialty\"])\nY_tfidf=tfidf_df['medical_specialty_code']\n\nX_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, Y_tfidf, test_size=0.2, random_state=42)\n\ny_train_tfidf=keras.utils.to_categorical(y_train_tfidf, df['medical_specialty'].nunique())\ny_test_tfidf=keras.utils.to_categorical(y_test_tfidf, df['medical_specialty'].nunique())\n\nmodel = build_sequential(X_train_tfidf.shape[1], encoder.classes_)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size=100\nepochs=30\n\n# checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=False, mode='auto')\n\nhistory=model.fit(np.array(X_train_tfidf), np.array(y_train_tfidf), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.3)","1df0ca6a":"X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, Y_tfidf, test_size=0.2, random_state=42)\n# svm_classifier=svm.SVC()\n# svm_classifier.fit(X_train_tfidf, y_train_tfidf)\n# predictions = svm_classifier.predict(X_test_tfidf)\nmetrics.accuracy_score(predictions, y_test_tfidf)","5a37cfd1":"# tfidf_df['medical_specialty'].unique()\ntfidf_df[['medical_specialty','Unnamed: 0']].groupby('medical_specialty').count()","f14b8cad":"# ngram level tf-idf \ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram.fit(trainDF['text'])\nxtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\nxvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n\n# characters level tf-idf\ntfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram_chars.fit(trainDF['text'])\nxtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \nxvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) ","0f620543":"# Converting medical_specialty to Categorical ","991c89e9":"# check number of target classes","963a6316":"# feature generation with Count Vectorizer","f40b3c3c":"# create  a new column with only lower case transcription without numerics","60055798":"# SVM multiclass classifier","6b977c1d":"# select the columns only from Count Vectorized transcript texts"}}