{"cell_type":{"af360c22":"code","26658417":"code","66e8885f":"code","1c70e556":"code","a9f43107":"code","8d3a90c1":"code","7a186fdf":"code","ff35aba8":"code","a90d630d":"code","5ae137ed":"code","5f5fe824":"code","3cae80ca":"code","8aa318b6":"code","294b3dbf":"code","9f0f4a29":"code","9d16f8ee":"code","356bb3fd":"code","4a36bb2c":"code","e776f7ab":"code","4b6d0e80":"code","2dc1e8dd":"code","991179dd":"code","f03b8ae8":"code","eee7b349":"code","bd40a73b":"code","f2fd2ade":"code","52342c0f":"code","9a61201b":"code","c7b4d92f":"code","989452c9":"code","6c7df9a3":"code","7ea3d584":"markdown","770e5cdd":"markdown","a01408a4":"markdown","1f1d9bb2":"markdown","63b2ba6e":"markdown","d110030d":"markdown","e0ce1834":"markdown","ad346db1":"markdown","2e00bb98":"markdown","9d0bd381":"markdown","c46a6a85":"markdown","ba4dd2de":"markdown","9244da90":"markdown","8aa42b62":"markdown","ae6029e5":"markdown","c7b82d9b":"markdown","7f3c4b8a":"markdown","44d23ab1":"markdown","a6993302":"markdown","65968c88":"markdown","73750f2b":"markdown","f0a4add3":"markdown","1b920b50":"markdown","7ade47c4":"markdown","03b2ec7e":"markdown","5dc0a7df":"markdown","a185bbbb":"markdown","e91116ca":"markdown","2e4214f2":"markdown","9d0bed07":"markdown","36ea1df3":"markdown","10017910":"markdown","3880fcd3":"markdown","24d1da07":"markdown","78d67603":"markdown","a884f9ea":"markdown","4099d52f":"markdown","87f21af8":"markdown","5aa1c63d":"markdown","a1fcd487":"markdown","76c4dab0":"markdown","1f46a2f3":"markdown","f060e9d2":"markdown","470540d9":"markdown","f581f229":"markdown","5ff0aa2d":"markdown","4d14a0cc":"markdown","fba4e425":"markdown","195b8f43":"markdown","c4678999":"markdown"},"source":{"af360c22":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pylab as plt\n\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\npio.templates.default = \"none\"\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","26658417":"df17= pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv\", encoding=\"ISO-8859-1\")\ndf18= pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\", )\ndf19= pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\", )\ndf20= pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\", )\ndf21= pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\", )","66e8885f":"\n#\uc9c8\ubb38 \uc81c\uac70\ud558\uae30, replace\ndf17= df17.iloc[1:, :].replace(\"People 's Republic of China\",'China')\ndf18= df18.iloc[1:, :].replace('Republic of Korea','South Korea')\ndf19= df19.iloc[1:, :].replace('Republic of Korea','South Korea')\ndf20= df20.iloc[1:, :].replace('Republic of Korea','South Korea')\ndf21= df21.iloc[1:, :]\n\n## East Asia\uc5d0\ub294 \ub300\ud55c\ubbfc\uad6d, \uc77c\ubcf8, \uc911\uad6d, \ud0c0\uc774\uc644, \ubabd\uace8, \ubd81\uc870\uc120 \ucd1d 6\uac1c\uc758 \uad6d\uac00\uac00 \uc18d\ud574 \uc788\ub2e4. \n## \uc774\uc720\ub294 \uc54c \uc218 \uc5c6\uc9c0\ub9cc, 18\ub144\ub3c4\uc5d4 \ud0c0\uc774\uc644\uc774 \uc5c6\ub2e4. \nEastAsia17 = ['China',\"People 's Republic of China\", 'Taiwan', 'South Korea', 'Japan']\nEastAsia18= ['China', 'South Korea', 'Japan', 'Republic of Korea'] \nEastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']\nEastAsia20 = ['China','Taiwan', 'South Korea','Republic of Korea', 'Japan']\nEastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']\nEastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', \"People 's Republic of China\" ]\n\ndf21_Ea = df21[df21['Q3'].isin(EastAsia)]\ndf21_Wo = df21[~df21['Q3'].isin(EastAsia)]\ndf21['region']=[\"EastAsia\" if x in EastAsia else \"World\" for x in df21['Q3']]\n\ndf20_Ea = df20[df20['Q3'].isin(EastAsia)]\ndf20_Wo = df20[~df20['Q3'].isin(EastAsia)]\ndf20['region']=[\"EastAsia\" if x in EastAsia else \"World\" for x in df20['Q3']]\n\ndf19_Ea = df19[df19['Q3'].isin(EastAsia)]\ndf19_Wo = df19[~df19['Q3'].isin(EastAsia)]\ndf19['region']=[\"EastAsia\" if x in EastAsia else \"World\" for x in df19['Q3']]\n\ndf18_Ea = df18[df18['Q3'].isin(EastAsia)]\ndf18_Wo = df18[~df18['Q3'].isin(EastAsia)]\ndf18['region']=[\"EastAsia\" if x in EastAsia else \"World\" for x in df18['Q3']]\n\ndf17_Ea = df17[df17['Country'].isin(EastAsia)]\ndf17_Wo = df17[~df17['Country'].isin(EastAsia)]\ndf17['region']=[\"EastAsia\" if x in EastAsia else \"World\" for x in df17['Country']]\n\ndf21['year'] = '2021'\ndf20['year'] = '2020'\ndf19['year'] = '2019'\ndf18['year'] = '2018'\ndf17['year'] = '2017'\n\nyears = ['2017', '2018', '2019', '2020', '2021']\n\ndf21_Ea = df21[df21['Q3'].isin(EastAsia21)]\nEa21= (\n    df21_Ea['Q3'].value_counts().to_frame()\n    .reset_index().rename(columns={'index':'Country', 'Q3':'21'}))\n\ndf20_Ea=df20[df20['Q3'].isin(EastAsia)]\nEa20= (\n    df20_Ea['Q3'].replace('Republic of Korea','South Korea')\n    .value_counts().to_frame().reset_index()\n    .rename(columns={'index':'Country', 'Q3':'20'}))\n\ndf19_Ea=df19[df19['Q3'].isin(EastAsia)]\nEa19= (df19_Ea['Q3'].replace('Republic of Korea','South Korea')\n       .value_counts().to_frame().reset_index()\n       .rename(columns={'index':'Country', 'Q3':'19'}))\n\ndf18_Ea=df18[df18['Q3'].isin(EastAsia)]\nEa18= (df18_Ea['Q3'].replace('Republic of Korea','South Korea')\n       .value_counts().to_frame().reset_index()\n       .rename(columns={'index':'Country', 'Q3':'18'}))\nEa18.value_counts()\n#df18 \uc5f4\uc5d0 taiwan = 0\uc744 \ucd94\uac00 \ud574\uc57c \ud569\ub2c8\ub2e4. \n\ndf17_Ea = df17[df17['Country'].isin(EastAsia)]\nEa17= (df17_Ea['Country'].replace(\"People 's Republic of China\",'China')\n       .value_counts().to_frame().reset_index()\n       .rename(columns={'index':'Country', 'Country':'17'}))\n\n#data\ub97c \ud569\uccd0\uc11c \ud558\ub098\uc758 dataframe\uc73c\ub85c \ub9cc\ub4e4\uc5b4 \uc90c.\ndf5years = pd.merge(Ea17, Ea18, on='Country', how='outer')\ndf5year =pd.merge(Ea19,Ea20, on='Country', how='outer')\ndf5year=pd.merge(df5year, Ea21, on='Country', how='outer')\n\ndf5years = pd.merge(df5years, df5year, on='Country', how='outer')\n\nEa21 = len(df21_Ea)\nWo21 = len(df21) - len(df21_Ea)\n\nEa20 = len(df20_Ea)\nWo20 = len(df20) - len(df20_Ea)\n\nEa19 = len(df19_Ea)\nWo19 = len(df19) - len(df19_Ea)\n\nEa18 = len(df18_Ea)\nWo18 = len(df18) -  len(df18_Ea)\n\nEa17 = len(df17_Ea)\nWo17 = len(df17) - len(df17_Ea)\n\nyears = ['2017','2018','2019','2020', '2021']\n\ndef percent (a, b):\n    result =a\/(a+b)*100\n    result = np.round(result, 2)\n    return result\n\ndef percentR (b, a):\n    result =a\/(a+b)*100\n    result = np.round(result, 2)\n    return result\n\npercent = [percent(Ea17, Wo17), percent(Ea18, Wo18), percent(Ea19, Wo19), \n                                                 percent(Ea20, Wo20), percent(Ea21, Wo21)]","1c70e556":"fig = go.Figure()\ny=[len(df17_Ea),len(df18_Ea), len(df19_Ea),len(df20_Ea),len(df21_Ea)]\n\nfig.add_trace(go.Bar(x=years, y=y,\n                base=0,\n                marker_color='#F2D64B',\n                yaxis = \"y1\",\n                name='East Asia',\n                text= percent,\n                texttemplate='%{text}  %', \n                textposition='outside',\n                hovertemplate='<b>KaggleUser<\/b>: %{x}<br>'+ '<b>Count<\/b>: %{y}'))\n\nfig.add_trace(go.Scatter(name = \"World\",\n           x=years, \n           y=[len(df17), len(df18), len(df19), len(df20), len(df21)],\n           marker_color='#979DA6',\n           mode = 'lines+markers', # please check option here\n           yaxis = \"y2\"))\n\nfig.update_traces(hovertemplate='<b>Count<\/b>: %{y}<br><extra><\/extra>'+\n                                '<b>Year<\/b>: %{x}<br>')\n\nfig.update_layout(yaxis  = dict(title = \"Kaggle User in East Asia\",showgrid = False, range=[0, len(df21_Ea)*1.2]),\n                  yaxis2 = dict(title = \"Kaggle User in World\", overlaying = \"y1\", side = \"right\", \n                  showgrid = False, \n                  zeroline = False, range=[0, len(df21)*1.2]))\n\nfig.update_layout(title='<b>Kaggle Users<\/b>',title_font_size=20,\n                  margin = dict(t=200, l=100, r=50, b=200),\n                  height=700, width=700)\n\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.9,\n                                    y=-0.25,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n\n\ndef world_map(locations,counts,title):\n    data = [ dict(\n            type = 'choropleth',\n            locations = locations,\n            z = counts,\n            colorscale = 'Reds',\n            locationmode = 'country names',\n            autocolorscale = False,\n            reversescale = False,\n            marker = dict(\n                line = dict(color = '#F7F7F7', width = 1.5)),\n                colorbar = dict(autotick = True, legth = 3, len=0.75, title = 'respodents',\n                               max = 1000, min = 0))]\n    layout = dict(\n        title=title,\n        titlefont={'size': 28},\n        width=700, \n        height=600,\n        paper_bgcolor='#FFFFFF', \n        margin=dict(l=50, r=50, t=100, b=100),\n        geo = dict(\n            showframe = True,\n            showcoastlines = True,\n            fitbounds=\"locations\"))\n   \n    fig = dict(data=data, layout=layout)\n    iplot(fig, validate=False, filename='world-map')\n\nz = df21_Ea['Q3'].value_counts()\n \nworld_map(locations=z.index, counts=z.values, title= '<b>EastAsia Countries<b>')","a9f43107":"A18 = (\n    df18['Q3']\n    .replace({'Republic of Korea':'South Korea',\n             'I do not wish to disclose my location' : 'Other'})\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q3':'2018'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\n\nA19 = (\n    df19['Q3']\n    .replace('Republic of Korea','South Korea')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q3':'2019'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\n\nA17 = (\n    df17['Country']\n    .replace({'United States': 'United States of America',\n              'Hong Kong': 'Hong Kong (S.A.R.)', \n              'United Kingdom':'United Kingdom of Great Britain and Northern Ireland',\n             })\n    .replace(\"People 's Republic of China\",'China')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Country':'2017'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\n\nA18A19=pd.merge(A18,A19, how='outer',on='type').fillna(0)\nA18A17=pd.merge(A18,A17, how='outer',on='type').fillna(0)\nA18A19['minus']= A18A19['2018']-A18A19['2019']\nA18A17['minus']= A18A17['2018']-A18A17['2017']\n\nA18A17=A18A17.sort_values(by=\"minus\", ascending=False)\nA18A19=A18A19.sort_values(by=\"minus\", ascending=False)\n\n\nfig = go.Figure(data=[  \n        go.Bar(x =A18A19['type'],\n        y = A18A19['minus'],\n        marker_color='#979DA6',\n        name = '2018-2019', base=0),\n        go.Bar(x =A18A17['type'],\n        y = A18A17['minus'],\n               marker_color='#F2D64B',\n        name = '2018-2017', base=0)\n        ])\n\nfig.update_layout(title='<b>        Predicting outliers (2018)<\/b>',title_font_size=20,\n                  margin = dict(t=200, l=100, r=10, b=200),\n                  height=700, width=700,\n                  xaxis_title=None,\n                  yaxis_title=None)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","8d3a90c1":"#data preprocessing\ntotal17 = ( \n    df17['region']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'region':'respodents'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\ntotal18 = (\n    df18['region']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'region':'respodents'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\ntotal19 = (\n    df19['region']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'region':'respodents'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\ntotal20 = (\n    df20['region']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'region':'respodents'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\ntotal21 = (\n    df21['region']\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'region':'respodents'})\n    .groupby('type')\n    .sum()\n    .reset_index()\n)\n\n#graph\ncolors = ['#F2D64B','#979DA6']\n\nfig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],\n                   subplot_titles=(\"2017\", \"2018\", \"2019\", \"2020\", \"2021\"))\nfig.add_trace(go.Pie(marker=dict(colors=colors),labels=total21['type'], values=total21['respodents'], name=\"2021\", scalegroup='one'), 1, 5)\nfig.add_trace(go.Pie(marker=dict(colors=colors),labels=total20['type'], values=total20['respodents'], name=\"2020\", scalegroup='one'), 1, 4)\nfig.add_trace(go.Pie(marker=dict(colors=colors),labels=total19['type'], values=total19['respodents'], name=\"2019\", scalegroup='one'), 1, 3)\nfig.add_trace(go.Pie(marker=dict(colors=colors),labels=total18['type'], values=total18['respodents'], name=\"2018\", scalegroup='one'), 1, 2)\nfig.add_trace(go.Pie(marker=dict(colors=colors),labels=total17['type'], values=total17['respodents'], name=\"2017\", scalegroup='one'), 1, 1)\n\nfig.update_traces(hole=.0, hoverinfo=\"label+percent+name\", textposition='inside', textinfo='percent+label',\n                  textfont_size=12)\n\nfig.update_layout(title='<b>World vs EastAsia<\/b>',title_font_size=23,\n                  margin = dict(t=300, l=0, r=0, b=200),\n                  height=700, width=700)\n\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.3,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.25,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","7a186fdf":"fig = go.Figure(data=[\n    go.Bar(name='2017', x=df5years['Country'], y=df5years['17'], marker_color='#F2798F',text=df5years['17'].tolist(), textposition='outside'),\n    go.Bar(name='2018', x=df5years['Country'], y=df5years['18'], marker_color='#88BFBA',text=df5years['18'].fillna(0).astype(int).tolist(), textposition='outside',),\n    go.Bar(name='2019', x=df5years['Country'], y=df5years['19'], marker_color='#CDD9A3',text=df5years['19'].tolist(), textposition='outside'),\n    go.Bar(name='2020', x=df5years['Country'], y=df5years['20'], marker_color='#F28705',text=df5years['20'].tolist(), textposition='outside',),\n    go.Bar(name='2021', x=df5years['Country'], y=df5years['21'], marker_color='#D9946C',text=df5years['21'].tolist(), textposition='outside')])\n\nfig.update_layout(barmode='group')\n\nfig.update_layout(title='<b>Kaggle User in East Asia<\/b>',title_font_size=23,\n                  margin = dict(t=200, l=100, r=10, b=200),\n                  height=600, width=700)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_traces(hovertemplate='<b>Count<\/b>: %{y}')\nfig.update_layout(legend=dict(\n    orientation=\"v\",\n    yanchor=\"bottom\",\n    y=1.15,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","ff35aba8":"#data preprocessing\nGender_17 = (\n    df17['GenderSelect']\n    .replace(['A different identity', 'Prefer to self-describe', 'Non-binary, genderqueer, or gender non-conforming'], 'Others')\n    .fillna('Others')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'GenderSelect':'Gender'})\n    .groupby('type')\n    .sum()\n    .reset_index())\nGender_18 = (\n    df18['Q1']\n    .replace(['Prefer not to say', 'Prefer to self-describe'], 'Others')\n    .fillna('Others')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q1':'Gender'})\n    .groupby('type')\n    .sum()\n    .reset_index())\nGender_19 = (\n    df19['Q2']\n    .replace(['Prefer not to say','Prefer to self-describe'],'Others')\n    .fillna('Others')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q2':'Gender'})\n    .groupby('type')\n    .sum()\n    .reset_index())\nGender_20 = (\n    df20['Q2']\n    .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others')\n    .replace(['Man', 'Woman'], ['Male', 'Female'])\n    .fillna('Others')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q2':'Gender'})\n    .groupby('type')\n    .sum()\n    .reset_index())\nGender_21 = (\n    df21['Q2']\n    .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others')\n    .replace(['Man', 'Woman'], ['Male', 'Female'])\n    .fillna('Others')\n    .value_counts()\n    .to_frame()\n    .reset_index()\n    .rename(columns={'index':'type', 'Q2':'Gender'})\n    .groupby('type')\n    .sum()\n    .reset_index())\n\ncolors = ['#D9946C','#88BFBA', '#CDD9A3']\n\nfig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_21['type'], values=Gender_21['Gender'], name=\"2021\", scalegroup='one', text=np.array(Gender_21['Gender'].sum()), title=\"2021\", titleposition='bottom center'),\n              1, 5)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_20['type'], values=Gender_20['Gender'], name=\"2020\", scalegroup='one', text=np.array(Gender_20['Gender'].sum()), title=\"2020\", titleposition='bottom center'),\n              1, 4)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_19['type'], values=Gender_19['Gender'], name=\"2019\", scalegroup='one', text=np.array(Gender_19['Gender'].sum()), title=\"2019\", titleposition='bottom center'),\n              1, 3)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_18['type'], values=Gender_18['Gender'], name=\"2018\", scalegroup='one', text=np.array(Gender_18['Gender'].sum()), title=\"2018\", titleposition='bottom center'),\n              1, 2)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_17['type'], values=Gender_17['Gender'], name=\"2017\", scalegroup='one', text=np.array(Gender_17['Gender'].sum()), title=\"2017\", titleposition='bottom center'),\n              1, 1)\n\nfig.update_traces(hole=.0, hoverinfo=\"label+percent+name\", \n                  textinfo='label+percent+value')\n\nfig.update_layout(title='<b>World Gender<\/b>',title_font_size=23,\n                  margin = dict(t=300, l=100, r=0, b=200),\n                  height=700, width=1000)\n\nfig.update_layout(legend=dict(\n    orientation=\"v\",\n    yanchor=\"bottom\",\n    y=1.3,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.85,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","a90d630d":"#data preprocessing\ngender21= df21_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})\ngender20= df20_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})\ngender19= df19_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})\ngender18= df18_Ea.loc[:, ['Q3', 'Q1', 'year']].rename(columns={'Q3':'Country', 'Q1':'Gender'})\ngender17= df17_Ea.loc[:, ['Country', 'GenderSelect', 'year']].rename(columns={'index':'type', 'GenderSelect':'Gender'})\n\nGender5y= pd.concat([gender17, gender18, gender19, gender20, gender21])\nGender5y= (Gender5y.replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary', 'A different identity'], 'Others')\n           .replace(['Man', 'Woman'], ['Male', 'Female'])\n           .groupby(['year', 'Gender'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\ngen17_5y = Gender5y[Gender5y['year'] == \"2017\"].reset_index(drop = True)\ngen18_5y = Gender5y[Gender5y['year'] == \"2018\"].reset_index(drop = True)\ngen19_5y = Gender5y[Gender5y['year'] == \"2019\"].reset_index(drop = True)\ngen20_5y = Gender5y[Gender5y['year'] == \"2020\"].reset_index(drop = True)\ngen21_5y = Gender5y[Gender5y['year'] == \"2021\"].reset_index(drop = True)\n\nGen5y_ = pd.concat([gen17_5y, gen18_5y, gen19_5y, gen20_5y, gen21_5y], ignore_index = True)\nGen5y_= pd.pivot(Gen5y_, index = \"year\", columns = \"Gender\", values = \"Count\").reset_index()\nGen5y_\n\nGen5y_['year'].unique()\n\n#graph\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x = Gen5y_['year'],\n    y = Gen5y_['Male'].tolist(),\n    name = 'Male',\nmarker_color='#88BFBA', text=Gen5y_['Male'].tolist(), textposition='outside'))\n\nfig.add_trace(go.Bar(\n    x = Gen5y_['year'],\n    y = Gen5y_['Female'].tolist(),\n    name = 'Female',\nmarker_color='#D9946C', text=Gen5y_['Female'].tolist(), textposition='outside'))\n\nfig.add_trace(go.Bar(\n    x = Gen5y_['year'],\n    y = Gen5y_['Others'].tolist(),\n    name = 'Others',\nmarker_color='#CDD9A3', text=Gen5y_['Others'].tolist(), textposition='outside'))\n\nfig.update_layout(barmode=\"group\") \n\nfig.update_layout(title='<b>Gender by year<\/b>',title_font_size=22,\n                  margin = dict(t=200, l=100, r=10, b=200),\n                  height=700, width=700,\n                  xaxis_title=None,\n                  yaxis_title=None)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","5ae137ed":"#data preprocessing\nData_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner',\n                'Predictive Modeler','Information technology, networking, or system administration', \n                'A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Humanities',\n                'Statistician', 'Mathematics or statistics', 'Medical or life sciences (biology, chemistry, medicine, etc.)', \n                'Physics or astronomy',  'Social sciences (anthropology, psychology, sociology, etc.)', 'Environmental science or geology',\n                'Humanities (history, literature, philosophy, etc.)']\nData_Scientist =['Data Scientist',  'Research Scientist', 'Researcher',\n                'Machine Learning Engineer', 'Scientist\/Researcher']\nDeveloper=['Developer Relations\/Advocacy','Data Engineer','Engineer','Engineering (non-computer focused)',\n           'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', \n           'Fine arts or performing arts','Product Manager', 'Software Developer\/Software Engineer',\n           'Product\/Project Manager','Program\/Project Manager','DBA\/Database Engineer']\nNot_Employed =['Currently not employed', 'Not employed', 'Student']\nOthers = ['I never declared a major', 'Other']\n\n\ndf21job_Ea = df21_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2021'}).fillna('Other')\ndf20job_Ea = df20_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2020'}).fillna('Other')\ndf19job_Ea = df19_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2019'}).fillna('Other')\ndf18job_Ea = df18_Ea.loc[:,['Q3','Q5']].rename(columns={ 'Q5':'2018'}).fillna('Other')\ndf17job_Ea = df17_Ea.loc[:,['Country','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Other')\n\ndf21job_Ea.value_counts('2021')\ndf21job_Ea['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist # Data Scientist\n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                   else \"Others\" \n                   for x in df21job_Ea['2021']]\ndf21job_Ea.value_counts('JOB')\n\ndf20job_Ea.value_counts('2020')\ndf20job_Ea['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                   else \"Other\"\n                   for x in df20job_Ea['2020']]\ndf20job_Ea[['2020','JOB']]\n\ndf19job_Ea.value_counts('2019')\ndf19job_Ea['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Other\"\n                   for x in df19job_Ea['2019']]\n\ndf19jobTest = df19job_Ea.loc[df19job_Ea.JOB == 'Other']\ndf19jobTest['2019'].value_counts()\n\n\ndf18job_Ea.value_counts('2018')\ndf18job_Ea['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Other\"\n                   for x in df18job_Ea['2018']]\n\ndf18jobTest = df18job_Ea.loc[df18job_Ea.JOB == 'Other']\ndf18jobTest['2018'].value_counts()\n\n\ndf17job_Ea.value_counts('2017')\ndf17job_Ea['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Other\"\n                   for x in df17job_Ea['2017']]\n\ndf17jobTest = df17job_Ea.loc[df17job_Ea.JOB == 'Other']\ndf17jobTest['2017'].value_counts()\n\n\ndf21jobTest = df21job_Ea.loc[df21job_Ea.JOB == 'Other']\ndf21jobTest['2021'].head()\ndf21job_Ea.value_counts('JOB')\n\ndfjob21 =df21job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:\"Count\"}).rename(columns={'Q3':'country'})\ndfjob20 =df20job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:\"Count\"}).rename(columns={'Q3':'country'})\ndfjob19 =df19job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:\"Count\"}).rename(columns={'Q3':'country'})\ndfjob18 =df18job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:\"Count\"}).rename(columns={'Q3':'country'})\ndfjob17 =df17job_Ea.groupby(['Country','JOB']).size().reset_index().rename(columns = {0:\"Count\"}).rename(columns={'Country':'country'})\n\ndf21_Ea_job =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf20_Ea_job =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf19_Ea_job =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf18_Ea_job =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf17_Ea_job =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\n\ndf21_DA=df21[df21['Q5'].isin(Data_Analyst)]\ndf21_DS=df21[df21['Q5'].isin(Data_Scientist)]\ndf21_D=df21[df21['Q5'].isin(Developer)]\ndf21_N=df21[df21['Q5'].isin(Not_Employed)]\ndf21_O=df21[df21['Q5'].isin(Others)]\n\nWorld_ = np.array([df21_DA['Q5'].count(), df21_DS['Q5'].count(), df21_D['Q5'].count(), df21_N['Q5'].count(), df21_O['Q5'].count()]) \nEast_Asia_ = df21_Ea_job['Count'].to_numpy()\nWorld =((World_\/World_.sum())*100).round(1)\nEast_Asia =((East_Asia_\/East_Asia_.sum())*100).round(1)\ny = df21_Ea_job.JOB.to_numpy()\n\nfig = go.Figure(data=[\n    go.Bar(y=y, x=World, orientation='h', name=\"World\", base=0, hovertemplate='<b>World<\/b>: %{x}%<br>', marker_color='#979DA6', text=World, textposition='outside'),\n    go.Bar(y=y, x=-East_Asia, orientation='h', name=\"East Asia\", base=0, hovertemplate='<b>East Asia<\/b>: %{x}%<br>', marker_color='#F2D64B', text=East_Asia, textposition='outside')])\n\nfig.update_layout(barmode='stack')\nfig.update_layout(title='<b>World vs EastAsia<\/b>',title_font_size=22,\n                  margin = dict(t=200, l=100, r=50, b=200),\n                  height=700, width=750,\n                  xaxis_title=None,\n                  yaxis_title=None)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","5f5fe824":"#data preprocessing\ndf21job= df21.loc[:,['region','Q5']].rename(columns={'Q5':'2021'}).fillna('Others')\ndf20job= df20.loc[:,['region','Q5']].rename(columns={'Q5':'2020'}).fillna('Others')\ndf19job= df19.loc[:,['region','Q5']].rename(columns={'Q5':'2019'}).fillna('Others')\ndf18job= df18.loc[:,['region','Q6']].rename(columns={ 'Q6':'2018'}).fillna('Others')\ndf17job= df17.loc[:,['region','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Others')\n\ndf21job['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist # Data Scientist\n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                   else \"Others\" \n                   for x in df21job['2021']]\n\n\ndf20job['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                   else \"Others\"\n                   for x in df20job['2020']]\n\n\ndf19job['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Others\"\n                   for x in df19job['2019']]\n\n\ndf18job['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Others\"\n                   for x in df18job['2018']]\n\n\ndf17job['JOB']=[\"Data Analyst\" if x in Data_Analyst\n                   else \"Data Scientist\" if x in Data_Scientist \n                   else \"Developer\" if x in Developer\n                    else \"NotEmployed\" if x in Not_Employed\n                    else \"Others\"\n                   for x in df17job['2017']]\n\ndf21_job =df21job.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf20_job =df20job.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf19_job =df19job.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf18_job =df18job.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf17_job =df17job.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\n\nmerge11=pd.merge(df21_job,df20_job, how='outer',on='JOB')\nmerge21=pd.merge(df19_job,df18_job, how='outer',on='JOB')\nmerge31=pd.merge(merge11,merge21, how='outer',on='JOB')\nmerge_Wo=(pd.merge(merge31,df17_job, how='outer',on='JOB')\n            .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0)\n            .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))\n\ndf21job_Ea = df21job[df21job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})\ndf20job_Ea = df20job[df20job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})\ndf19job_Ea = df19job[df19job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})\ndf18job_Ea = df18job[df18job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})\ndf17job_Ea = df17job[df17job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})\n\ndf21job_Ea =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf20job_Ea =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf19job_Ea =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf18job_Ea =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\ndf17job_Ea =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:\"Count\"})\n\nmerge1=pd.merge(df21job_Ea,df20job_Ea, how='outer',on='JOB')\nmerge2=pd.merge(df19job_Ea,df18job_Ea, how='outer',on='JOB')\nmerge3=pd.merge(merge1,merge2, how='outer',on='JOB')\nmerge=(pd.merge(merge3,df17job_Ea, how='outer',on='JOB')\n         .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0)\n         .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))\n\n#graph\nz1=((merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy()\/merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)\nz2=((merge.iloc[:,[1,2,3,4,5]].to_numpy()\/merge.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)\n\nx=['2017-year','2018-year','2019-year','2020-year','2021-year']\ny1=merge_Wo['JOB'].tolist()\ny2=merge['JOB'].tolist()\n\n\nfig1 = ff.create_annotated_heatmap(z1, x = x, y = y1, colorscale='sunset')\nfig2 = ff.create_annotated_heatmap(z2, x = x, y = y2, colorscale='sunset')\n\nfor annot in fig2['layout']['annotations']:\n    annot['xref'] = 'x2'\n    \nfig = make_subplots(rows=1, cols=2)\nfig.add_trace(fig1.data[0], row=1, col=1)\nfig.add_trace(fig2.data[0], row=1, col=2)\nfig.update_layout(fig1.layout, title='<b>           World vs EastAsia<\/b>',title_font_size=22,\n                  margin = dict(t=200, l=100, r=10, b=200),\n                  height=700, width=1150, coloraxis=dict(showscale=True, colorscale='sunset'))\nfig.update_traces(hovertemplate='<b>Job<\/b>: %{y}<br>'+\n                                '<b>Year<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\nfig.layout.annotations += fig2.layout.annotations\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.9,\n                                    y=-0.25,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\n\nfig.show()","3cae80ca":"#data preprocessing\n#World\nAge21_W = df21.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge20_W = df20.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge19_W = df19.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge18_W = df18.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')\n\nAge5y_W= pd.concat([Age21_W, Age20_W, Age19_W, Age18_W])\nAge5y_W= (Age5y_W.replace(['60-69', '70+', '70-79', '80+'], '60+')\n           .replace(['22-24', '25-29'], '22-29')\n           .replace(['30-34', '35-39'], '30-39')\n            .replace(['40-44', '45-49'], '40-49')\n        .replace(['50-54', '55-59'], '50-59')\n           .groupby(['year', 'age'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\nAge21_percent_W = Age5y_W[Age5y_W['year'] == \"2021\"].reset_index(drop = True)\nAge21_percent_W['percentage'] = Age21_percent_W[\"Count\"] \/ Age21_percent_W[\"Count\"].sum()\nAge21_percent_W['%'] = np.round(Age21_percent_W['percentage'] * 100, 1)\n\nAge20_percent_W = Age5y_W[Age5y_W['year'] == \"2020\"].reset_index(drop = True)\nAge20_percent_W['percentage'] = Age20_percent_W[\"Count\"] \/ Age20_percent_W[\"Count\"].sum()\nAge20_percent_W['%'] = np.round(Age20_percent_W['percentage'] * 100, 1)\n\nAge19_percent_W = Age5y_W[Age5y_W['year'] == \"2019\"].reset_index(drop = True)\nAge19_percent_W['percentage'] = Age19_percent_W[\"Count\"] \/ Age19_percent_W[\"Count\"].sum()\nAge19_percent_W['%'] = np.round(Age19_percent_W['percentage'] * 100, 1)\n\nAge18_percent_W = Age5y_W[Age5y_W['year'] == \"2018\"].reset_index(drop = True)\nAge18_percent_W['percentage'] = Age18_percent_W[\"Count\"] \/ Age18_percent_W[\"Count\"].sum()\nAge18_percent_W['%'] = np.round(Age18_percent_W['percentage'] * 100, 1)\n\nAge5y_percent_W = pd.concat([Age18_percent_W, Age19_percent_W, Age20_percent_W, Age21_percent_W], ignore_index = True)\nAge5y_percent_W= pd.pivot(Age5y_percent_W, index = \"year\", columns = 'age', values = \"%\").reset_index()\nAge5y_percent_W\n\nAge21 = df21_Ea.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge20 = df20_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge19 = df19_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')\nAge18 = df18_Ea.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')\n\nAge5y= pd.concat([Age21, Age20, Age19, Age18])\nAge5y= (Age5y.replace(['60-69', '70+', '70-79', '80+'], '60+')\n           .replace(['22-24', '25-29'], '22-29')\n           .replace(['30-34', '35-39'], '30-39')\n            .replace(['40-44', '45-49'], '40-49')\n        .replace(['50-54', '55-59'], '50-59')\n           .groupby(['year', 'age'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\n#EastAsia\nAge21_percent = Age5y[Age5y['year'] == \"2021\"].reset_index(drop = True)\nAge21_percent['percentage'] = Age21_percent[\"Count\"] \/ Age21_percent[\"Count\"].sum()\nAge21_percent['%'] = np.round(Age21_percent['percentage'] * 100, 1)\nAge21_percent\n\nAge20_percent = Age5y[Age5y['year'] == \"2020\"].reset_index(drop = True)\nAge20_percent['percentage'] = Age20_percent[\"Count\"] \/ Age20_percent[\"Count\"].sum()\nAge20_percent['%'] = np.round(Age20_percent['percentage'] * 100, 1)\nAge20_percent\n\nAge19_percent = Age5y[Age5y['year'] == \"2019\"].reset_index(drop = True)\nAge19_percent['percentage'] = Age19_percent[\"Count\"] \/ Age19_percent[\"Count\"].sum()\nAge19_percent['%'] = np.round(Age19_percent['percentage'] * 100, 1)\nAge19_percent\n\nAge18_percent = Age5y[Age5y['year'] == \"2018\"].reset_index(drop = True)\nAge18_percent['percentage'] = Age18_percent[\"Count\"] \/ Age18_percent[\"Count\"].sum()\nAge18_percent['%'] = np.round(Age18_percent['percentage'] * 100, 1)\nAge18_percent\n\nAge5y_percent = pd.concat([Age18_percent, Age19_percent, Age20_percent, Age21_percent], ignore_index = True)\nAge5y_percent= pd.pivot(Age5y_percent, index = \"year\", columns = 'age', values = \"%\").reset_index()\nAge5y_percent\n\nAge5y_percent_order = Age5y_percent_W['year'].tolist()\nAge5y_order = Age5y_W['age'].unique().tolist()\n\n#graph1\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['18-21'].tolist(), \n    mode = \"lines\", \n    name = '18-21',\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F2798F'))\n\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['22-29'].tolist(), \n    mode = \"lines\", \n    name = \"20s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#88BFBA'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['30-39'].tolist(), \n    mode = \"lines\", \n    name = \"30s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#CDD9A3'))\n\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['40-49'].tolist(), \n    mode = \"lines\", \n    name = \"40s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F28705'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['50-59'].tolist(), \n    mode = \"lines\", \n    name = \"50s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#D9946C'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent_W['60+'].tolist(), \n    mode = \"lines\", \n    name = \"60s<\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F2D64B'))\n\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Year<\/b>: %{x}<br>')\nfig.update_layout(yaxis_range = (0, 100), height=500, width=700,\n                 title_text=\"<b>World<\/b>\", title_font_size=20,\n                 title_x=0.5)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n\n#graph2\nAge5y_percent_order = Age5y_percent['year'].tolist()\nAge5y_order = Age5y['age'].unique().tolist()\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['18-21'].tolist(), \n    mode = \"lines\", \n    name = '18-21',\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F2798F'))\n\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['22-29'].tolist(), \n    mode = \"lines\", \n    name = \"20s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#88BFBA'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['30-39'].tolist(), \n    mode = \"lines\", \n    name = \"30s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#CDD9A3'))\n\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['40-49'].tolist(), \n    mode = \"lines\", \n    name = \"40s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F28705'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['50-59'].tolist(), \n    mode = \"lines\", \n    name = \"50s\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#D9946C'))\nfig.add_trace(go.Scatter(\n    x = Age5y_percent_order, \n    y = Age5y_percent['60+'].tolist(), \n    mode = \"lines\", \n    name = \"60s<\",\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F2D64B'))\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Year<\/b>: %{x}<br>')\nfig.update_layout(yaxis_range = (0, 100), height=500, width=700,\n                 title_text=\"<b>East Asia<\/b>\", title_font_size=20,\n                 title_x=0.5)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","8aa318b6":"#data processing\ndf21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')\n\ndf21Age_Ea=(df21Age_Ea.replace(['60-69', '70+', '70-79', '80+'], '60+')\n           .replace(['22-24', '25-29'], '22-29')\n           .replace(['30-34', '35-39'], '30-39')\n            .replace(['40-44', '45-49'], '40-49')\n        .replace(['50-54', '55-59'], '50-59'))\n\n# \uc5f0\ub839-\uc9c0\uc5ed %\ndfKo_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='South Korea']\ndfKo_Age21_per=dfKo_Age21['2021'].value_counts().to_frame().reset_index()\ndfKo_Age21_per['South Korea']=((dfKo_Age21_per['2021'] \/ len(dfKo_Age21))*100).round(2)\n\ndfTw_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Taiwan']\ndfTw_Age21_per=dfTw_Age21['2021'].value_counts().to_frame().reset_index()\ndfTw_Age21_per['Taiwan']=((dfTw_Age21_per['2021'] \/ len(dfTw_Age21))*100).round(2)\ndfTw_Age21_per\n\ndfCh_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='China']\ndfCh_Age21_per=dfCh_Age21['2021'].value_counts().to_frame().reset_index()\ndfCh_Age21_per['China']=((dfCh_Age21_per['2021'] \/ len(dfCh_Age21))*100).round(2)\ndfCh_Age21_per\n\ndf21Age_Ea.head()\ndfJp_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Japan']\ndfJp_Age21_per=dfJp_Age21['2021'].value_counts().to_frame().reset_index()\ndfJp_Age21_per['Japan']=((dfJp_Age21_per['2021'] \/ len(dfJp_Age21))*100).round(2)\ndfJp_Age21_per\n\n\nmerge1= pd.merge(dfKo_Age21_per,dfTw_Age21_per, on='index', how='outer')\nmerge2= pd.merge(dfCh_Age21_per,dfJp_Age21_per, on='index', how='outer')\nmerge= pd.merge(merge1,merge2, on='index', how='outer').fillna(0).sort_values(by=['index'],ascending=True)\n\n#graph\nx1=['South Korea','Taiwan','China','Japan']\ny1=merge.sort_values(by=['index'], ascending=True)['index'].tolist()\nz1=merge.iloc[:,[2,4,6,8]].to_numpy()\n\nfig = go.Figure(data=go.Heatmap(\n                   z=z1,\n                   x=x1,\n                   y=y1,\n                   hoverongaps = True,\n                   opacity=1.0, xgap=2.5, ygap=2.5))\nfig = ff.create_annotated_heatmap(z1, x = x1, y = y1, colorscale='sunset')\nfig.update_layout(height=500, width=600,\n                 title_text=\"<b>East Asia Age (2021)<\/b>\", title_font_size=20,\n                 title_x=0.5)\nfig.update_traces(hovertemplate='<b>Age<\/b>: %{y}<br>'+\n                                '<b>Country<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","294b3dbf":"# \uc5f0\ub3c4\ubcc4 \ub098\uc774 \ndf21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')\ndf20Age_Ea = df20_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2020'}).fillna('etc')\ndf19Age_Ea = df19_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2019'}).fillna('etc')\ndf18Age_Ea = df18_Ea.loc[:,['Q3','Q2']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'2018'}).fillna('etc')\ndf17Age_Ea = df17_Ea.loc[:,['Country','Age']].reset_index().rename(columns={'Country':'East_Asia', 'Age':'2017'}).fillna('etc')\n\n#data frame \uc815\ub9ac\ndfAge21 =df21Age_Ea.groupby(['East_Asia','2021']).size().reset_index().rename(columns = {0:\"Count\"})\ndfAge20 =df20Age_Ea.groupby(['East_Asia','2020']).size().reset_index().rename(columns = {0:\"Count\"})\ndfAge19 =df19Age_Ea.groupby(['East_Asia','2019']).size().reset_index().rename(columns = {0:\"Count\"})\ndfAge18 =df18Age_Ea.groupby(['East_Asia','2018']).size().reset_index().rename(columns = {0:\"Count\"})\ndfAge17 =(df17Age_Ea.groupby(['East_Asia','2017'])\n          .size().reset_index().rename(columns = {0:\"Count\"}))\n#graph\nfig = go.Figure()\n\nx = ['China','Japan','South Korea','Taiwan']\n\nfig.add_trace(go.Box( y=dfAge17['2017'][dfAge17['East_Asia']==\"Japan\"].to_numpy(),\n    name='Japan',\n    marker=dict(color='#CDD9A3')))\nfig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==\"China\"].to_numpy(),\n    name='China',\n    marker=dict(color='#88BFBA')))\nfig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==\"South Korea\"].to_numpy(),\n    name='South Korea',\n    marker=dict(color='#F2798F')))\nfig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==\"Taiwan\"].to_numpy(),\n    name='Taiwan',\n    marker=dict(color='#F28705'\n    ),))\n\nfig.update_layout(yaxis = dict(range=[0, 120]))\n\n\nfig.update_layout(yaxis_range = (0, 110), height=600, width=700,\n                  title_text=\"<b>Age in East Asia (2017)<\/b>\", title_font_size=20,\n                  margin = dict(t=100, l=50, r=50, b=100),\n                  title_x=0.5)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"v\",\n    yanchor=\"bottom\",\n    y=0.8,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","9f0f4a29":"#data preprocessing\ndegree_wo = (df21['Q4']\n             .replace(['No formal education past high school',\n                       'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n             .replace(['Doctoral degree',\n                       'Professional doctorate'],'Doctoral degree~')\n             .value_counts().to_frame())\ndegree_ea = (df21_Ea['Q4']\n             .replace(['No formal education past high school',\n                       'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n             .replace(['Doctoral degree',\n                       'Professional doctorate'],'Doctoral degree~')\n             .value_counts().to_frame())\n\n#graph\ncolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'pie'}, {'type':'pie'}]], subplot_titles=(\"World\", \"East Asia\"))\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_wo.index, values=degree_wo['Q4'].to_numpy(), name=\"World\"),\n              1, 1)\nfig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_ea.index, values=degree_ea['Q4'].to_numpy(), name=\"East Asia\"),\n              1, 2)\n\nfig.update_traces(hole=.0, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(title='<b>World vs East Asia<\/b>',title_font_size=22,\n                  margin = dict(t=200, l=30, r=0, b=200),\n                  height=700, width=700)\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1.0))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n","9d16f8ee":"#data preprocessing\ndf21_Ea_degree=(df21_Ea['Q4'].replace(['No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n                             .replace(['Doctoral degree','Professional doctorate'],'Doctoral degree~')\n                             .value_counts().to_frame().rename(columns={'Q4':'2021'}))\ndf20_Ea_degree=(df20_Ea['Q4'].replace(['No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n                             .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~')\n                             .value_counts().to_frame().rename(columns={'Q4':'2020'}))\ndf19_Ea_degree=(df19_Ea['Q4'].replace(['No formal education past high school','Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n                             .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~')\n                             .value_counts().to_frame().rename(columns={'Q4':'2019'}))\ndf18_Ea_degree=(df18_Ea['Q4'].replace(['No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n                             .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~')\n                             .value_counts().to_frame().rename(columns={'Q4':'2018'}))\ndf17_Ea_degree=(df17_Ea['FormalEducation']\n                .replace(['No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n                .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~')\n                .value_counts().to_frame()\n                .rename(columns={'FormalEducation':'2017'} ,index = {'I did not complete any formal education past high school':'No formal education past high school','Master\\'s degree':'Master\u2019s degree','Bachelor\\'s degree':'Bachelor\u2019s degree','Some college\/university study without earning a bachelor\\'s degree':'Some college\/university study without earning a bachelor\u2019s degree'})  )\n                \nconcat1 = pd.concat([df21_Ea_degree,df20_Ea_degree],axis=1, join='outer')  \nconcat2 = pd.concat([df19_Ea_degree,df18_Ea_degree],axis=1, join='outer')  \nconcat3 = pd.concat([concat1,concat2],axis=1, join='outer') \ndf21_Ea_degree_yearly_=concat3.join(df17_Ea_degree).fillna(0).transpose() #.transpose() \ud589 \uc5f4 \ubc14\uafb8\uae30\n\ndf21_Ea_degree_yearly=df21_Ea_degree_yearly_.stack().to_frame().reset_index().rename(columns={'level_0':'year','level_1':'degree',0:'value'})\ndf21_Ea_degree_yearly\n\n#graph\nfig = px.sunburst(df21_Ea_degree_yearly, path=['year','degree'], values=df21_Ea_degree_yearly['value'].tolist())\nfig.update_layout( margin = dict(t=10, l=10, r=10, b=10),colorway=(\"#F2798F\",\"#88BFBA\",\"#CDD9A3\",'#F28705','#D9946C'))\n\nfig.update_layout(title='<b>         Degree<\/b>',title_font_size=25,\n                  margin = dict(t=100, l=100, r=50, b=100),\n                  height=700, width=700)\nfig.update_traces(hovertemplate='<b>Name<\/b>: %{id}<br>'+\n                                '<b>Count<\/b>: %{value}<br>'+\n                                '<b>Parent<\/b>: %{parent}') \nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","356bb3fd":"#data preprocessing\ndf21Edu_Ea = df21_Ea.loc[:,['Q3','Q4']].reset_index().rename(columns={'Q3':'East_Asia', 'Q4':'Dgree'}).fillna('etc')\ndf21Edu_Ea =(df21Edu_Ea.replace({'I prefer not to answer':'etc'}).replace(['No formal education past high school',\n                       'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n             .replace(['Doctoral degree',\n                       'Professional doctorate'],'Doctoral degree~'))\n\ndf21Edu_Ea= (df21Edu_Ea\n           .groupby(['East_Asia', 'Dgree'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\n# \uc5f0\ub839-\uc9c0\uc5ed %\ndfKo_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='South Korea']\ndfKo_Edu21['%']=((dfKo_Edu21['Count'] \/ dfKo_Edu21['Count'].sum()*100)).round(2)\ndfKo_Edu21=dfKo_Edu21.sort_values(by='%', ascending=False)\ndfTw_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Taiwan']\ndfTw_Edu21['%']=((dfTw_Edu21['Count'] \/ dfTw_Edu21['Count'].sum())*100).round(2)\ndfTw_Edu21=dfTw_Edu21.sort_values(by='%', ascending=False)\ndfCh_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='China']\ndfCh_Edu21['%']=((dfCh_Edu21['Count'] \/ dfCh_Edu21['Count'].sum())*100).round(2)\ndfCh_Edu21=dfCh_Edu21.sort_values(by='%', ascending=False)\ndfJp_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Japan']\ndfJp_Edu21['%']=((dfJp_Edu21['Count'] \/ dfJp_Edu21['Count'].sum())*100).round(2)\ndfJp_Edu21=dfJp_Edu21.sort_values(by='%', ascending=False)\n\n# #data \uc644\uc131\n# dfEdu_21_per = pd.concat([dfKo_Edu21, dfTw_Edu21, dfCh_Edu21, dfJp_Edu21], ignore_index = True)\n# dfEdu_21_per= pd.pivot(dfEdu_21_per, index = \"Dgree\", columns = 'East_Asia', values = \"%\").reset_index()\n# dfEdu_21_per\n\n#graph\nfig = make_subplots(rows = 1, cols = 4, \n                    shared_yaxes=True, \n                    vertical_spacing = 0.05)\n\nfig.add_trace(go.Bar(x = dfCh_Edu21['Dgree'], \n                     y = dfCh_Edu21['%'], \n                     text = dfCh_Edu21['%'].astype(str) + \"%\", \n                     textposition='outside',\n                     name='China',\n                     marker_color='#88BFBA'), \n                     row = 1, col = 1)\n\nfig.add_trace(go.Bar(x = dfJp_Edu21['Dgree'], \n                     y = dfJp_Edu21['%'], \n                     text = dfJp_Edu21['%'].astype(str) + \"%\", \n                     textposition='outside',\n                     name='Japan',\n                     marker_color='#CDD9A3'), \n                      row = 1, col = 2)\n\nfig.add_trace(go.Bar(x = dfKo_Edu21['Dgree'], \n                     y = dfKo_Edu21['%'], \n                     text = dfKo_Edu21['%'].astype(str) + \"%\", \n                     textposition='outside',\n                     name='South Korea',\n                     marker_color='#F28705'), \n                      row = 1, col = 3)\n\nfig.add_trace(go.Bar(x = dfTw_Edu21['Dgree'], \n                     y = dfTw_Edu21['%'], \n                     text = dfTw_Edu21['%'].astype(str) + \"%\", \n                     textposition='outside',\n                     name='Taiwan',\n                     marker_color='#D9946C'), \n                     row = 1, col = 4)\n\nfig.update_layout(showlegend=True,title='<b>Degree in East Asia<\/b>',title_font_size=22,\n                  margin = dict(t=200, l=100, r=50, b=200),\n                  height=700, width=700)\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Degree<\/b>: %{x}<br>')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.5,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","4a36bb2c":"#Exp data \uc804\ucc98\ub9ac\n# Exp \ubf51\uc544\uc624\uae30\nExp21_Wo = df21.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')\nExp20_Wo = df20.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')\nExp19_Wo = df19.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'Country', 'Q15':'Exp'}).fillna('etc')\nExp18_Wo = df18.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'Country', 'Q8':'Exp'}).fillna('etc')\nExp17_Wo = df17.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'Country', 'Tenure':'Exp'}).fillna('etc')\n\nExp21_Wo= Exp21_Wo.replace({'I have never written code': '< 1 years',  '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp20_Wo= Exp20_Wo.replace({'I have never written code': '< 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp19_Wo= Exp19_Wo.replace({'I have never written code': '< 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp18_Wo= (Exp18_Wo.replace({'0-1': '< 1 years', '1-2': '1-2 years', '5-10':'5-10 years'})\n        .replace(['2-3', '3-4',  '4-5'],'3-5 years')\n       .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))\nExp17_Wo=(Exp17_Wo.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years',  'Less than a year':'< 1 years',\n       '3 to 5 years':'3-5 years', \"I don't write code to analyze data\":'< 1 years',\n       '6 to 10 years':'5-10 years'}))\n                                                                                                                   \n#data \uc815\uc81c(\ud55c\uaebc\ubc88\uc5d0 \uc774\ub984\ubc14\uafb8\uae30)\nExp5y_Wo= pd.concat([Exp17_Wo, Exp18_Wo, Exp19_Wo, Exp20_Wo, Exp21_Wo]).reset_index()\nExp5y_Wo=(Exp5y_Wo.groupby(['year', 'Exp'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\n#percent data \ub123\uae30\nExp21_per_W= Exp5y_Wo[Exp5y_Wo['year'] == \"2021\"].reset_index(drop = True)\nExp21_per_W['percentage'] = Exp21_per_W[\"Count\"] \/ Exp21_per_W[\"Count\"].sum()\nExp21_per_W['%'] = np.round(Exp21_per_W['percentage'] * 100, 1)\n\nExp20_per_W = Exp5y_Wo[Exp5y_Wo['year'] == \"2020\"].reset_index(drop = True)\nExp20_per_W['percentage'] = Exp20_per_W[\"Count\"] \/ Exp20_per_W[\"Count\"].sum()\nExp20_per_W['%'] = np.round(Exp20_per_W['percentage'] * 100, 1)\n\nExp19_per_W = Exp5y_Wo[Exp5y_Wo['year'] == \"2019\"].reset_index(drop = True)\nExp19_per_W['percentage'] = Exp19_per_W[\"Count\"] \/ Exp19_per_W[\"Count\"].sum()\nExp19_per_W['%'] = np.round(Exp19_per_W['percentage'] * 100, 1)\n\nExp18_per_W = Exp5y_Wo[Exp5y_Wo['year'] == \"2018\"].reset_index(drop = True)\nExp18_per_W['percentage'] = Exp18_per_W[\"Count\"] \/ Exp18_per_W[\"Count\"].sum()\nExp18_per_W['%'] = np.round(Exp18_per_W['percentage'] * 100, 1)\n\nExp17_per_W = Exp5y_Wo[Exp5y_Wo['year'] == \"2017\"].reset_index(drop = True)\nExp17_per_W['percentage'] = Exp17_per_W[\"Count\"] \/ Exp17_per_W[\"Count\"].sum()\nExp17_per_W['%'] = np.round(Exp17_per_W['percentage'] * 100, 1)\n\n#data \uc644\uc131\nExp5y_per_W = pd.concat([Exp17_per_W, Exp18_per_W, Exp19_per_W, Exp20_per_W, Exp21_per_W], ignore_index = True)\nExp5y_per_W= pd.pivot(Exp5y_per_W, index = \"year\", columns = 'Exp', values = \"%\").reset_index()\nExp5y_per_W.fillna('0')\nExp5y_percent_order = Exp5y_per_W['year'].tolist()\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['< 1 years'].tolist(), \n    mode = \"lines\", \n    name = '< 1 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#F2798F'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['1-2 years'].tolist(), \n    mode = \"lines\", \n    name = '1-2 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#88BFBA'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['3-5 years'].tolist(), \n    mode = \"lines\", \n    name = '3-5 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#CDD9A3'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['5-10 years'].tolist(), \n    mode = \"lines\", \n    name = '5-10 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#F28705'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['10+ years'].tolist(), \n    mode = \"lines\", \n    name = '10+ years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#D9946C'))\n\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_per_W['etc'].tolist(), \n    mode = \"lines\", \n    name = 'etc',\n    line = dict(width = 1),\n    stackgroup = \"one\",\n    marker_color='#F2D64B'))\n\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>')\nfig.update_layout(yaxis_range = (0, 100), title_font_size=20,\n                  title_text=\"<b>Experience in world<\/b>\",\n                  height=500, width=700,\n                  title_x=0.5)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n","e776f7ab":"#data preprocessing\nExp21 = df21_Ea.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')\nExp20 = df20_Ea.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')\nExp19 = df19_Ea.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q15':'Exp'}).fillna('etc')\nExp18 = df18_Ea.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q8':'Exp'}).fillna('etc')\nExp17 = df17_Ea.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'East_Asia', 'Tenure':'Exp'}).fillna('etc')\n\nExp21Uni=['3-5 years', '< 1 years', '1-3 years', '10-20 years',\n       'I have never written code', '5-10 years', '20+ years']\nExp20Uni= ['3-5 years', '< 1 years', '5-10 years', '1-2 years', 'etc',\n       '20+ years', '10-20 years', 'I have never written code']\nExp19Uni=['1-2 years', '5-10 years', '< 1 years',\n       'I have never written code', '3-5 years', '10-20 years',\n       '20+ years', 'etc']\nExp18Uni=['0-1', '2-3', '1-2', '5-10', '3-4', '10-15', '15-20', '4-5',\n       '20-25', '30 +', 'etc', '25-30']\nExp17Uni=['More than 10 years', '1 to 2 years', 'etc', 'Less than a year',\n       '3 to 5 years', \"I don't write code to analyze data\",\n       '6 to 10 years']\n\nExp21= Exp21.replace({'I have never written code': '< 1 years',  '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp20= Exp20.replace({'I have never written code': '< 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp19= Exp19.replace({'I have never written code': '< 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )\nExp18= (Exp18.replace({'0-1': '< 1 years', '1-2': '1-2 years', '5-10':'5-10 years'})\n        .replace(['2-3', '3-4',  '4-5'],'3-5 years')\n       .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))\nExp17=(Exp17.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years',  'Less than a year':'< 1 years',\n       '3 to 5 years':'3-5 years', \"I don't write code to analyze data\":'< 1 years',\n       '6 to 10 years':'5-10 years'}))\n                                                                                                                \nExp5y= pd.concat([Exp17, Exp18, Exp19, Exp20, Exp21]).reset_index()\nExp5y=(Exp5y.groupby(['year', 'Exp'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\nExp21_percent = Exp5y[Exp5y['year'] == \"2021\"].reset_index(drop = True)\nExp21_percent['percentage'] = Exp21_percent[\"Count\"] \/ Exp21_percent[\"Count\"].sum()\nExp21_percent['%'] = np.round(Exp21_percent['percentage'] * 100, 1)\nExp21_percent\n\nExp20_percent = Exp5y[Exp5y['year'] == \"2020\"].reset_index(drop = True)\nExp20_percent['percentage'] = Exp20_percent[\"Count\"] \/ Exp20_percent[\"Count\"].sum()\nExp20_percent['%'] = np.round(Exp20_percent['percentage'] * 100, 1)\nExp20_percent\n\nExp19_percent = Exp5y[Exp5y['year'] == \"2019\"].reset_index(drop = True)\nExp19_percent['percentage'] = Exp19_percent[\"Count\"] \/ Exp19_percent[\"Count\"].sum()\nExp19_percent['%'] = np.round(Exp19_percent['percentage'] * 100, 1)\nExp19_percent\n\nExp18_percent = Exp5y[Exp5y['year'] == \"2018\"].reset_index(drop = True)\nExp18_percent['percentage'] = Exp18_percent[\"Count\"] \/ Exp18_percent[\"Count\"].sum()\nExp18_percent['%'] = np.round(Exp18_percent['percentage'] * 100, 1)\nExp18_percent\n\nExp17_percent = Exp5y[Exp5y['year'] == \"2017\"].reset_index(drop = True)\nExp17_percent['percentage'] = Exp17_percent[\"Count\"] \/ Exp17_percent[\"Count\"].sum()\nExp17_percent['%'] = np.round(Exp17_percent['percentage'] * 100, 1)\nExp17_percent\n\n\n#graph\nExp5y_percent = pd.concat([Exp17_percent, Exp18_percent, Exp19_percent, Exp20_percent, Exp21_percent], ignore_index = True)\nExp5y_percent= pd.pivot(Exp5y_percent, index = \"year\", columns = 'Exp', values = \"%\").reset_index()\nExp5y_percent.fillna('0')\n\nExp5y_percent_order = Exp5y_percent['year'].tolist()\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['< 1 years'].tolist(), \n    mode = \"lines\", \n    name = '< 1 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#F2798F'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['1-2 years'].tolist(), \n    mode = \"lines\", \n    name = '1-2 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#88BFBA'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['3-5 years'].tolist(), \n    mode = \"lines\", \n    name = '3-5 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#CDD9A3'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['5-10 years'].tolist(), \n    mode = \"lines\", \n    name = '5-10 years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#F28705'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['10+ years'].tolist(), \n    mode = \"lines\", \n    name = '10+ years',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#D9946C'))\nfig.add_trace(go.Scatter(\n    x = Exp5y_percent_order, \n    y = Exp5y_percent['etc'].tolist(), \n    mode = \"lines\", \n    name = 'etc',\n    line = dict(width = 0.5),\n    stackgroup = \"one\",\n    marker_color='#F2D64B'))\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>')\nfig.update_layout(yaxis_range = (0, 100),\n                  title_text=\"<b>Experience in East Asia<\/b>\",\n                  height=500, width=700, title_font_size=20,\n                  title_x=0.5)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","4b6d0e80":"#data preprocessing\ndf21_salary_=df21['Q25'].value_counts().to_frame().rename(index={'$0-999':'<999','>$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)\ndf21_Ea_salary_=df21_Ea['Q25'].value_counts().to_frame().rename(index={'$0-999':'<999','>$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)\n\n#\ud37c\uc13c\ud2b8\ndf21_salary__=(df21_salary_['Q25']\/(df21_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'World'})\ndf21_Ea_salary__=(df21_Ea_salary_['Q25']\/(df21_Ea_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'EA'})\n\n#\uadf8\ub8f9\ud654\ndf21_salary=(df21_salary__.rename(index=\n                               {'1,000-1,999':'1,000-7,499',\n                                '2,000-2,999':'1,000-7,499',\n                                '3,000-3,999':'1,000-7,499',\n                                '4,000-4,999':'1,000-7,499',\n                                '5,000-7,499':'1,000-7,499'})\n                                .rename(index={'7,500-9,999':'7,500-24,999',\n                                '10,000-14,999':'7,500-24,999',\n                                '15,000-19,999':'7,500-24,999',\n                                '20,000-24,999':'7,500-24,999' })\n                                .rename(index={'25,000-29,999':'25,000-59,999',\n                                 '30,000-39,999':'25,000-59,999',\n                                 '40,000-49,999':'25,000-59,999',\n                                 '50,000-59,999':'25,000-59,999'})\n                                .rename(index={'60,000-69,999':'60,000-99,999',\n                                 '70,000-79,999':'60,000-99,999',\n                                 '80,000-89,999':'60,000-99,999',\n                                 '90,000-99,999':'60,000-99,999'})\n                                .rename(index={'100,000-124,999':'100,000-199,999',\n                                 '125,000-149,999':'100,000-199,999',\n                                 '150,000-199,999':'100,000-199,999'})\n                                .rename(index={'200,000-249,999':'200,000-1,000,000~',\n                                 '250,000-299,999':'200,000-1,000,000~',\n                                 '300,000-499,999':'200,000-1,000,000~',\n                                 '500,000-999,999':'200,000-1,000,000~',\n                                 '1,000,000~':'200,000-1,000,000~'})\n                                .reset_index().groupby('index').sum()\n                                 .reindex(index = ['<999', \n                                                  '1,000-7,499',\n                                                  '7,500-24,999', \n                                                  '25,000-59,999', \n                                                  '60,000-99,999', \n                                                 '100,000-199,999', \n                                                 '200,000-1,000,000~']))\n\ndf21_Ea_salary=(df21_Ea_salary__.rename(index=\n                               {'1,000-1,999':'1,000-7,499',\n                               '2,000-2,999':'1,000-7,499',\n                               '3,000-3,999':'1,000-7,499',\n                               '4,000-4,999':'1,000-7,499',\n                               '5,000-7,499':'1,000-7,499'})\n                                .rename(index={'7,500-9,999':'7,500-24,999',\n                               '10,000-14,999':'7,500-24,999',\n                               '15,000-19,999':'7,500-24,999',\n                               '20,000-24,999':'7,500-24,999'})\n                                .rename(index={'25,000-29,999':'25,000-59,999',\n                               '30,000-39,999':'25,000-59,999',\n                               '40,000-49,999':'25,000-59,999',\n                               '50,000-59,999':'25,000-59,999'})\n                                .rename(index={'60,000-69,999':'60,000-99,999',\n                               '70,000-79,999':'60,000-99,999',\n                               '80,000-89,999':'60,000-99,999',\n                               '90,000-99,999':'60,000-99,999'})\n                                .rename(index={'100,000-124,999':'100,000-199,999',\n                               '125,000-149,999':'100,000-199,999',\n                               '150,000-199,999':'100,000-199,999'})\n                                .rename(index={'200,000-249,999':'200,000-1,000,000~',\n                               '250,000-299,999':'200,000-1,000,000~',\n                               '300,000-499,999\t':'200,000-1,000,000~',\n                               '500,000-999,999':'200,000-1,000,000~',\n                               '1,000,000~':'200,000-1,000,000~'})\n                                .reset_index().groupby('index').sum()\n                                .reindex(index = ['<999', \n                                                  '1,000-7,499',\n                                                  '7,500-24,999', \n                                                  '25,000-59,999', \n                                                  '60,000-99,999', \n                                                 '100,000-199,999', \n                                                 '200,000-1,000,000~']))\n\n#graph\nWorld = df21_salary['World'].values\nEast_Asia = df21_Ea_salary['EA'].values\ny = df21_salary.index\n\nfig = go.Figure(data=[\n    go.Bar(y=y, x=World, orientation='h', name=\"World\", base=0, hovertemplate='<b>World<\/b>: %{x}%<br>', marker_color='#979DA6'),\n    go.Bar(y=y, x=-East_Asia, orientation='h', name=\"East Asia\", base=0, hovertemplate='<b>East Asia<\/b>: %{x}%<br>', marker_color='#F2D64B')\n    ])\n\nfig.update_layout(barmode='stack')\nfig.update_layout(\n    margin=dict(l=200, r=0, t=200, b=100),\n    autosize=False,\n    title_text=\"<b>                       Salary in East Asia vs World<\/b>\", height=600, width=700, title_font_size=20, title_x=0.5)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.1,\n    xanchor=\"right\",\n    x=1))\nfig.show()","2dc1e8dd":"#data preprocessing\nSalExp21= df21.loc[:, ['region', 'Q25', 'Q6']].rename(columns={'Q6':'Exp', 'Q25':'Salary'})\n\n\nSalExp21=(SalExp21\n          .replace(['0-999','$0-999','0'], '< 999')\n          .replace({'>$1,000,000':'200,000~'})\n          .replace(['1,000-1,999','2,000-2,999','3,000-3,999', \n        '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000')\n          .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', \n        '50,000-59,999'],'20,000-59,999') \n           .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', \n        '90,000-99,999'], '60,000-99,999')\n          .replace(['100,000-124,999', '300,000-499,999',\n        '125,000-149,999', '125,000-149,999',\n        '150,000-199,999'],'100,000-199,999')\n          .replace(['200,000-249,999', '250,000-299,999', \n        '1,000,000','$500,000-999,999'], '200,000~')\n        .replace({'I have never written code': '< 1 years'})\n          .replace(['10-20 years', '20+ years'], '10+ years' )\n         )\n\nsal_order=['< 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']\nExp21_order=['< 1 years', '1-3 years','3-5 years', '5-10 years', '10+ years' ]\n\n\n\nSalExp21_Ea = SalExp21[SalExp21['region'] == \"EastAsia\"].reset_index(drop = True)\nSalExp21_Ea=(SalExp21_Ea.groupby(['Exp', 'Salary'])\n           .size()\n          .unstack().fillna(0).astype('int64'))\n\nSalExp21_Wo = SalExp21[SalExp21['region'] == \"World\"].reset_index(drop = True)\nSalExp21_Wo=(SalExp21_Wo.groupby(['Exp', 'Salary'])\n           .size()\n          .unstack().fillna(0).astype('int64'))\nSalExp21_Wo\n\n\n\n#graph\n#World\nz = SalExp21_Wo\nz = z[sal_order]\nz = z.reindex(Exp21_order)\n\nz_data = z.apply(lambda x:np.round(x\/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = Exp21_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout( title_text=\"<b>Experience and salary in World<\/b>\",\n                  height=700, width=700, title_font_size=20,\n                  title_x=0.5,\n                  margin=dict(l=100, r=100, t=200, b=100))\n\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.85,\n                                    y=-0.1,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n\n\n#East Asia\nz = SalExp21_Ea\nz = z[sal_order]\nz = z.reindex(Exp21_order)\nz_data = z.apply(lambda x:np.round(x\/x.sum(), 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = Exp21_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout(title_text=\"<b>Experience and salary in East Asia<\/b>\",\n                  height=700, width=700, title_font_size=20,\n                  title_x=0.5,\n                  margin=dict(l=100, r=100, t=200, b=100))\n\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.85,\n                                    y=-0.1,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","991179dd":"#data preprocessing\nSalary21= df21.loc[:, ['region', 'Q25', 'year']].rename(columns={'Q3':'Country', 'Q25':'Salary'})\nsalary21_Index=['< 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']\n\nSalary21=(Salary21\n          .replace(['0-999','$0-999','0'], '< 999')\n          .replace({'>$1,000,000':'200,000~'})\n          .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000')\n          .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999',  '50,000-59,999'],'20,000-59,999') \n           .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999','90,000-99,999'], '60,000-99,999')\n          .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999', '150,000-199,999'],'100,000-199,999')\n          .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~')).fillna('0')\nsal_order=['< 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']\n\nSalary21=(Salary21.groupby(['region', 'Salary'])\n           .size()\n           .reset_index()\n           .rename(columns = {0:\"Count\"}))\n\nSalary21_Ea = Salary21[Salary21['region'] == \"EastAsia\"].reset_index(drop = True)\nSalary21_Ea['%']=((Salary21_Ea['Count'] \/ Salary21_Ea['Count'].sum())*100).round(2)\nSalary21_Wo = Salary21[Salary21['region'] == \"World\"].reset_index(drop = True)\nSalary21_Wo['%']=((Salary21_Wo['Count'] \/ Salary21_Wo['Count'].sum())*100).round(2)\n\nDgr_Sal_21= df21.loc[:, ['region', 'Q25', 'Q4']].rename(columns={'Q4':'Dgree', 'Q25':'Salary'})\nDgr_Sal_21 = (Dgr_Sal_21.replace(['0-999','$0-999','0'], '< 999')\n          .replace({'>$1,000,000':'200,000~'})\n          .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000')\n          .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') \n          .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999')\n          .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999','150,000-199,999'],'100,000-199,999')\n          .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~')\n          .replace({'I prefer not to answer':'etc'})\n          .replace(['No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n          .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~'))\n\n\n#EastAsia \ubf51\uae30\nDgr_Sal_21_Ea= Dgr_Sal_21[Dgr_Sal_21['region'] == \"EastAsia\"].reset_index(drop = True)\nDgr_Sal_21_Ea = Dgr_Sal_21_Ea.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')\n\ndgree_order=[ '~college','Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree~', 'etc']\n\n\n#graph\n#World\nz = Dgr_Sal_21.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')\nz = z[sal_order]\nz = z.reindex(dgree_order)\n\nz_data = z.apply(lambda x:np.round(x\/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = dgree_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout( title_text=\"<b>    Degree-Salary in World<\/b>\",\n                  height=700, width=700, title_font_size=20,\n                  title_x=0.5,\n                  margin=dict(l=150, r=100, t=200, b=50))\nfig.update_traces(hovertemplate='<b>Degree<\/b>: %{y}<br>'+\n                                '<b>Salary<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.1,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()\n\n\n#East Asia\nz = Dgr_Sal_21_Ea\nz = z[sal_order]\nz = z.reindex(dgree_order)\nz_data = z.apply(lambda x:np.round(x\/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = dgree_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout(title_text=\"<b>    Degree-Salary in East Asia<\/b>\",\n                  height=700, width=700, title_font_size=20,\n                  title_x=0.5,\n                  margin=dict(l=150, r=100, t=200, b=50))\nfig.update_traces(hovertemplate='<b>Degree<\/b>: %{y}<br>'+\n                                '<b>Salary<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.1,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","f03b8ae8":"#data preprocessing\n#world\nprogramming_list = [\"Python\", \"R\", \"SQL\", \"Java\", \"C\", \"Bash\", \"Javascript\", \"C++\"]\nprogramming_df = pd.Series(programming_list)\n\ndf_2019 = df19[df19['Q19'].isin(programming_df)]\ndf_2020 = df20[df20['Q8'].isin(programming_df)]\ndf_2021 = df21[df21['Q8'].isin(programming_df)]\n\ndf19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]\ndf19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasets\ndf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\ndf21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\n\ndf3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])\ndf3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:\"Count\"})\ndf3y_Lag\n\n# 2019\ndfLang_19 = df3y_Lag[df3y_Lag['year'] == \"2019\"].reset_index(drop = True)\ndfLang_19['percentage'] = dfLang_19[\"Count\"] \/ dfLang_19[\"Count\"].sum()\ndfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)\n\n# 2020\ndfLang_20 = df3y_Lag[df3y_Lag['year'] == \"2020\"].reset_index(drop = True)\ndfLang_20['percentage'] = dfLang_20[\"Count\"] \/ dfLang_20[\"Count\"].sum()\ndfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)\n\n# 2021\ndfLang_21 = df3y_Lag[df3y_Lag['year'] == \"2021\"].reset_index(drop = True)\ndfLang_21['percentage'] = dfLang_21[\"Count\"] \/ dfLang_21[\"Count\"].sum()\ndfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)\n\ndfLang_19=dfLang_19.sort_values(by='%', ascending=False)\ndfLang_20=dfLang_20.sort_values(by='%', ascending=False)\ndfLang_21=dfLang_21.sort_values(by='%', ascending=False)\n\n#graph\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x = dfLang_19['Language'], \n                     y = dfLang_19['%'], \n                     name = \"2019\", \n                     text = dfLang_19['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#CDD9A3'))\n\nfig.add_trace(go.Bar(x = dfLang_20['Language'], \n                     y = dfLang_20['%'], \n                     name = \"2020\", \n                     text = dfLang_20['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#F28705'))\n\nfig.add_trace(go.Bar(x = dfLang_21['Language'], \n                     y = dfLang_21['%'], \n                     name = \"2021\", \n                     text = dfLang_21['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#88BFBA'))\nfig.update_layout(title='<b>Language in World<\/b>',title_font_size=20,\n                  margin = dict(t=100, l=100, r=50, b=100),\n                  height=600, width=700,\n                  xaxis_title=None,\n                  yaxis_title=None)\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Language<\/b>: %{x}<br>')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"v\",\n    yanchor=\"bottom\",\n    y=0.8,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","eee7b349":"#data prprocessing\n#Ea\n\ndf_2019 = df19_Ea[df19_Ea['Q19'].isin(programming_df)]\ndf_2020 = df20_Ea[df20_Ea['Q8'].isin(programming_df)]\ndf_2021 = df21_Ea[df21_Ea['Q8'].isin(programming_df)]\n\ndf19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]\ndf19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasets\ndf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\ndf21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\n\n\ndf3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])\ndf3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:\"Count\"})\ndf3y_Lag\n\n\n# 2019\ndfLang_19 = df3y_Lag[df3y_Lag['year'] == \"2019\"].reset_index(drop = True)\ndfLang_19['percentage'] = dfLang_19[\"Count\"] \/ dfLang_19[\"Count\"].sum()\ndfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)\n\n# 2020\ndfLang_20 = df3y_Lag[df3y_Lag['year'] == \"2020\"].reset_index(drop = True)\ndfLang_20['percentage'] = dfLang_20[\"Count\"] \/ dfLang_20[\"Count\"].sum()\ndfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)\n\n# 2021\ndfLang_21 = df3y_Lag[df3y_Lag['year'] == \"2021\"].reset_index(drop = True)\ndfLang_21['percentage'] = dfLang_21[\"Count\"] \/ dfLang_21[\"Count\"].sum()\ndfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)\n\ndfLang_19=dfLang_19.sort_values(by='%', ascending=False)\ndfLang_20=dfLang_20.sort_values(by='%', ascending=False)\ndfLang_21=dfLang_21.sort_values(by='%', ascending=False)\n\n#graph\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x = dfLang_19['Language'], \n                     y = dfLang_19['%'], \n                     name = \"2019\", \n                     text = dfLang_19['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#CDD9A3'))\n\nfig.add_trace(go.Bar(x = dfLang_20['Language'], \n                     y = dfLang_20['%'], \n                     name = \"2020\", \n                     text = dfLang_20['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#F28705'))\n\nfig.add_trace(go.Bar(x = dfLang_21['Language'], \n                     y = dfLang_21['%'], \n                     name = \"2021\", \n                     text = dfLang_21['%'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#88BFBA'))\nfig.update_layout(title='<b>Language in EastAsia<\/b>',title_font_size=20,\n                  margin = dict(t=100, l=100, r=50, b=100),\n                  height=600, width=700,\n                  xaxis_title=None,\n                  yaxis_title=None)\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{text}')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","bd40a73b":"# data preprocessing\ndf21_Ea_DS = df21_Ea[df21_Ea['Q5'].isin(Data_Scientist)].fillna(0)\n\nsalary_order= ['<999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']\ndgree_order=[ '~college','Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree~', 'etc']\n\ndf21_Ea_DS=(df21_Ea_DS\n  #salary      \n          .replace({'$0-999':'<999','>$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'})\n         \n          .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-19,999')\n          .replace(['20,000-24,999','25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') \n          .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999')\n          .replace(['100,000-124,999','125,000-149,999','150,000-199,999'],'100,000-199,999')\n          .replace(['200,000-249,999', '250,000-299,999', '300,000-499,999','500,000-999,999', '1,000,000~'], '200,000~')\n  #degree          \n          .replace({'I prefer not to answer':'etc'})\n          .replace(['No formal education past high school','Some college\/university study without earning a bachelor\u2019s degree'],'~college')\n          .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~')\n          )\nsal_order= ['<999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']\ndgree_order=[ '~college','Bachelor\u2019s degree', 'Master\u2019s degree', 'Doctoral degree~', 'etc']\n\n","f2fd2ade":"df21_Ea_DS_= df21_Ea_DS.loc[:,['Q5','Q25']].reset_index().rename(columns={'Q5':'Data_Scientist', 'Q25':'Salary'}).fillna('etc')\ndf21_Ea_DS_= (df21_Ea_DS_.groupby(['Data_Scientist', 'Salary']).size()\n                         .reset_index()\n                         .rename(columns = {0:\"Count\"}))\n\n#Data Scientist\ndf21_Ea_DS_Ds = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == \"Data Scientist\"].reset_index(drop = True)\ndf21_Ea_DS_Ds['%']=((df21_Ea_DS_Ds['Count'] \/ df21_Ea_DS_Ds['Count'].sum())*100).round(2)\n\n#Machine Learning Engineer\ndf21_Ea_DS_Mle = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == \"Machine Learning Engineer\"].reset_index(drop = True)\ndf21_Ea_DS_Mle['%']=((df21_Ea_DS_Mle['Count'] \/ df21_Ea_DS_Mle['Count'].sum())*100).round(2)\n\n#Research Scientist\ndf21_Ea_DS_Rs = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == \"Research Scientist\"].reset_index(drop = True)\ndf21_Ea_DS_Rs['%']=((df21_Ea_DS_Rs['Count'] \/ df21_Ea_DS_Rs['Count'].sum())*100).round(2)\ndf21_Ea_DS_Rs\n\n\ndf21_Ea_DS_salary = pd.concat([df21_Ea_DS_Ds, df21_Ea_DS_Mle, df21_Ea_DS_Rs], ignore_index = True)\ndf21_Ea_DS_salary= pd.pivot(df21_Ea_DS_salary, index = \"Salary\", columns = 'Data_Scientist', values = \"%\").reset_index().fillna('0')\ndf21_Ea_DS_salary= df21_Ea_DS_salary.set_index(\"Salary\").reindex(sal_order)\n\n#graph\nfig = go.Figure()\nfig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, \n                     y = df21_Ea_DS_salary['Data Scientist'], \n                     name = \"Data Scientist\", \n                     text = df21_Ea_DS_salary['Data Scientist'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#F2798F'))\n\nfig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, \n                     y = df21_Ea_DS_salary['Machine Learning Engineer'], \n                     name = \"Machine Learning Engineer\", \n                     text = df21_Ea_DS_salary['Machine Learning Engineer'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#CDD9A3'))\n\nfig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, \n                     y = df21_Ea_DS_salary['Research Scientist'], \n                     name = \"Research Scientist\", \n                     text = df21_Ea_DS_salary['Research Scientist'].astype(str) + \"%\", \n                     textposition='auto', marker_color='#88BFBA'))\n\nfig.update_layout(barmode='stack',\n                 showlegend=True,\n                 height=600, width=700,\n                 title_text=\"<b>Data Scientist's Salary in East Asia<\/b>\",\n                 title_x=0.5,\n                 title_font_size=20, \n                  margin=dict(l=100, r=100, t=100, b=100))\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Salary<\/b>: %{x}$<br>')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"v\",\n    yanchor=\"bottom\",\n    y=0.8,\n    xanchor=\"right\",\n    x=1.2))\n\nfig.show()","52342c0f":"df21Ea_DS_ExSal = df21_Ea_DS.loc[:,['Q6','Q25']].reset_index().rename(columns={'Q25':'Salary', 'Q6':'Exp'}).fillna('etc')\ndf21Ea_DS_ExSal= (df21Ea_DS_ExSal.groupby(['Exp', 'Salary']).size().unstack().fillna(0).astype('int64'))\n\nExp_order=['< 1 years','1-3 years','3-5 years', '5-10 years', '10-20 years', '20+ years', 'I have never written code']\n\ndf21Ea_DS_ExSal\n\nz = df21Ea_DS_ExSal\nz = z[sal_order]\nz = z.reindex(Exp_order)\n\nz_data = z.apply(lambda x:np.round(x\/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = Exp_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout(title_text=\"<b>    Data Scientist's Experience & Salary <\/b>\",title_font_size=20,\n                  height=700, width=700,\n                  title_x=0.5,\n                  margin=dict(l=100, r=100, t=200, b=100))\nfig.update_traces(hovertemplate='<b>Salary<\/b>: %{y}<br>'+\n                                '<b>Experience<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\n\nfig.show()","9a61201b":"df21_Ea_degree = df21_Ea_DS['Q4'].value_counts().to_frame()\ndegree = df21_Ea_degree.index\nvalues = df21_Ea_degree['Q4'].tolist()\n\ncolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']\nfig = go.Figure(data=[go.Bar(name='Degree', x=degree, y=values ,orientation='v', marker_color=colors, text=values, textposition='outside')])\nfig.update_layout(title_text=\"<b>Data Scientist's Degree (2021)<\/b>\", title_font_size=20,\n                  height=600, width=700,\n                  title_x=0.5,\n                  margin=dict(l=100, r=100, t=200, b=100))\nfig.update_traces(hovertemplate='<b>Count<\/b>: %{y}<br>'+\n                                '<b>Degree<\/b>: %{x}<br>')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","c7b4d92f":"df21Ea_DS_EduSal= df21_Ea_DS.loc[:, ['Q4', 'Q25']].rename(columns={'Q4':'Edu', 'Q25':'Salary'})\ndf21Ea_DS_EduSal['Edu'].unique()\nEdu_order=['~college', 'Bachelor\u2019s degree','Master\u2019s degree', 'Doctoral degree~', 'etc']\n\ndf21Ea_DS_EduSal= (df21Ea_DS_EduSal.groupby(['Edu', 'Salary']).size().unstack().fillna(0).astype('int64'))\ndf21Ea_DS_EduSal\n\nz = df21Ea_DS_EduSal\nz = z[sal_order]\nz = z.reindex(Edu_order)\n\nz_data = z.apply(lambda x:np.round(x\/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrix\nx = sal_order\ny = Edu_order\n\nfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = \"sunset\")\nfig.update_layout(title_text=\"<b>       Data Scientist's Degree & Salary <\/b>\", title_font_size=20,\n                  height=700, width=700,\n                  title_x=0.5,\n                  margin=dict(l=150, r=100, t=200, b=50))\nfig.update_traces(hovertemplate='<b>Degree<\/b>: %{y}<br>'+\n                                '<b>Salary<\/b>: %{x}<br>'+\n                                '<b>Percent<\/b>: %{z}%')\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.1,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","989452c9":"#data preprocessing\ndf20_Ea_DS = df20_Ea[df20_Ea['Q5'].isin(Data_Scientist)]\ndf19_Ea_DS =df19_Ea[df19_Ea['Q5'].isin(Data_Scientist)]\ndf19Ea_DSLag = df19_Ea_DS.loc[:, [ 'Q5', 'Q19', 'year']]\ndf19Ea_DSLag = df19Ea_DSLag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasets\ndf20Ea_DSLag = df20_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\ndf21Ea_DSLag = df21_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)\n\ndf3y_Ds_Lag = pd.concat([df19Ea_DSLag, df20Ea_DSLag, df21Ea_DSLag])\ndf3y_Ds_Lag = df3y_Ds_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:\"Count\"})\ndf3y_Ds_Lag\n\n# 2019\ndfLang_Ds_19 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == \"2019\"].reset_index(drop = True)\ndfLang_Ds_19['percentage'] = dfLang_Ds_19[\"Count\"] \/ dfLang_Ds_19[\"Count\"].sum()\ndfLang_Ds_19['%'] = np.round(dfLang_Ds_19['percentage'] * 100, 1)\n\n# 2020\ndfLang_Ds_20 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == \"2020\"].reset_index(drop = True)\ndfLang_Ds_20['percentage'] = dfLang_Ds_20[\"Count\"] \/ dfLang_Ds_20[\"Count\"].sum()\ndfLang_Ds_20['%'] = np.round(dfLang_Ds_20['percentage'] * 100, 1)\n\n# 2021\ndfLang_Ds_21 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == \"2021\"].reset_index(drop = True)\ndfLang_Ds_21['percentage'] = dfLang_Ds_21[\"Count\"] \/ dfLang_Ds_21[\"Count\"].sum()\ndfLang_Ds_21['%'] = np.round(dfLang_Ds_21['percentage'] * 100, 1)\n\ndfLang_Ds_19=dfLang_Ds_19.sort_values(by='%', ascending=False)\ndfLang_Ds_20=dfLang_Ds_20.sort_values(by='%', ascending=False)\ndfLang_Ds_21=dfLang_Ds_21.sort_values(by='%', ascending=False)\n\n#graph\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x = dfLang_Ds_19['Language'], \n                     y = dfLang_Ds_19['%'], \n                     name = \"2019\", \n                     text = dfLang_Ds_19['%'].astype(str) + \"%\", \n                     textposition='auto', \n                     marker_color='#CDD9A3'))\n\nfig.add_trace(go.Bar(x = dfLang_Ds_20['Language'], \n                     y = dfLang_Ds_20['%'], \n                     name = \"2020\", \n                     text = dfLang_Ds_20['%'].astype(str) + \"%\", \n                     textposition='auto', \n                     marker_color='#F28705'))\n\nfig.add_trace(go.Bar(x = dfLang_Ds_21['Language'], \n                     y = dfLang_Ds_21['%'], \n                     name = \"2021\", \n                     text = dfLang_Ds_21['%'].astype(str) + \"%\", \n                     textposition='auto', \n                     marker_color='#88BFBA'))\n\nfig.update_layout(title='<b>        The language used by the data scientist<\/b>',title_font_size=22,\n                  margin = dict(t=120, l=100, r=10, b=150),\n                  height=600, width=700)\nfig.update_traces(hovertemplate='<b>Percent<\/b>: %{y}%<br>'+\n                                '<b>Language<\/b>: %{x}<br>')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=0.8,\n    xanchor=\"right\",\n    x=1))\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","6c7df9a3":"ds_pc=(df21_Ea_DS.loc[:, ['Q5','Q25','Q6','Q4','Q8']]\n                 .replace({'I have never written code': '< 1 years',  '1-3 years': '1-2 years'})\n                 .replace(['10-20 years', '20+ years'], '10+ years' )\n                 .replace([0,'<999'])\n                 )\nfig = px.parallel_categories(ds_pc, labels={'Q5':'Job', 'Q25':'Salary', 'Q6':'Experience', 'Q4':'Degree', 'Q8':'Language'})\n\nfig.update_layout(hovermode = 'x')\nfig.update_layout(title='<b>        Data Scientist<\/b>',title_font_size=20,\n                  margin = dict(t=120, l=100, r=10, b=150),\n                  height=600, width=700)\nfig.add_annotation(dict(font=dict(size=14),\n                                    x=0.8,\n                                    y=-0.2,\n                                    showarrow=False,\n                                    text=\"@green_yhjw\",\n                                    xanchor='left',\n                                    xref=\"paper\",\n                                    yref=\"paper\"))\nfig.show()","7ea3d584":"<h2>World & East Asia Programming Language: Bar plot <\/h2>\n- Python: 80% of the world and 85% of East Asia use it.\n\n<h4>\n<p style=\"color:#FF0000\";>\nWe've been working on the project as python, so I hope we can continue to learn python and become experienced Data Scientists!\n    <\/p><\/h4>","770e5cdd":"# 3.1 Kaggle's transformation (World\/East Asia)\n---\n# 3.1.1 user transformation\n","a01408a4":"<h2> > Age change in World and East Asia by year: Stacked scatter plot <\/h2>\n\n1. In the case of Age data, there is no 2017 data.\n2. 70% of the World respondents said 20s to 30s.\n3. 70% of East Asia respondents said 20s to 30s.\n4. The number of respondents increases, but the ratio seems to have stabilized.","1f1d9bb2":"<h2>Total population: <\/h2>\n\n1.4 billion (85%) in China, 130 million in Japan, 0.5 billion in Korea, and 0.2 billion in Taiwan.\n\n+ China: The number of respondents is smaller than the population.\n+ Japan: Starting in 2019, overtaking China\n+ Taiwan : 2018 data 0 =? Diplomatic issues? The growth trend is weak.\n+ Korea : Respondents at a similar level to Japan's population.\n+ East Asia: The number of respondents will increase further.","63b2ba6e":"# 3.2.5 Language\n---","d110030d":"\uc548\ub155\ud558\uc138\uc694 \ud55c\uad6d\uc5d0 \uc0ac\ub294 YH\uc785\ub2c8\ub2e4. <br>\npython\uc744 \ubc30\uc6b4\uc9c0 \ud55c\ub2ec\uc774 \ucc44 \uc548\ub418\uc11c \uba85\uc774 \ud55c \ud300\uc774 \ub418\uc5b4  \uc774\ubc88 \ub300\ud68c\uc5d0 \ucc38\uac00 \ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4. <br>\n\ub9ce\uc774 \ubd80\uc871\ud558\uc9c0\ub9cc \uc5ec\uae30\uae4c\uc9c0 \uc77d\uc5b4 \uc8fc\uc154\uc11c \uac10\uc0ac\ud569\ub2c8\ub2e4. <br>\n\uc544\uc9c1\uc740 \ub108\ubb34\ub108\ubb34 \ubd80\uc871\ud55c \uc81c\ucd9c\ubb3c \uc774\uc9c0\ub9cc, \uc55e\uc73c\ub85c \uc5f4\uc2ec\ud788 \ud574\uc11c \ucf00\uae00 \ub300\ud68c\uc5d0\uc11c 1\ub4f1\ud558\ub294 \uadf8 \ub0a0\uae4c\uc9c0 \uc9c0\ucf1c\ubd10 \uc8fc\uc138\uc694 ^^! <br>\n \ud639\uc2dc \ucf54\uba58\ud2b8\ub85c \ub2e4 \uc804\ud558\uc9c0 \ubabb\ud558\uc168\ub358 \ub9d0\uc774 \uc788\uc73c\uc2dc\ub2e4\uba74, \uc800\uc758 [github blog](https:\/\/yoonhwa-p.github.io\/)\uc5d0 \ubc29\ubb38\ud558\uc5ec \ub3c4\uc6c0\uc744 \uc8fc\uc138\uc694!  <br>\n\ubcc4\uac70 \uc5c6\uc9c0\ub9cc \ub180\ub7ec\uc624\uc138\uc694  ;-)\n\nHello, I'm YH and I live in Korea.<br>\nLess than a month after learning python, people became a team and participated in this competition.  <br>\nIt's not enough, but thank you for reading it up to here.  <br>\nIt's still not enough, but please watch until the day we win first place at the Kaggle competition ^^! <br>\n <br>\nIf there's anything you haven't said in the comments, please visit my [github blog](https:\/\/yoonhwa-p.github.io\/) and help me! <br>\n It's nothing special, but come and play. ;-) <br>\n \n <br>\n <br>\n \n\uc548\ub155\ud558\uc138\uc694 \uc800\ub294 YH\ub2d8\uacfc \uac19\uc774 Kaggle \ub300\ud68c\ub97c \uc900\ube44 \ud55cJW \uc785\ub2c8\ub2e4.  <br>\npython\uc744 \uc81c\ub300\ub85c \ubc30\uc6b0\uc9c0\ub3c4 \ubabb\ud55c\ucc44\ub85c \ub098\uc624\uac8c \ub41c \ub300\ud68c\ub77c \ucf54\ub4dc \ubd80\ubd84\uc5d0\uc11c \ubbf8\uc219\ud55c \uc810\ub3c4 \ub9ce\uace0  <br>\n\uc624\ub958\ub3c4 \ub9ce\uc2b5\ub2c8\ub2e4!   <br>\n\ud558\uc9c0\ub9cc \ub300\ud68c\ub97c \ucd9c\uc804\ud558\uba74\uc11c, python\uc5d0 \ub300\ud574\uc11c \ub9ce\uc740 \uacf5\ubd80\ub3c4 \ub418\uc5c8\uace0, \uc7ac\ubbf8\ub3c4 \uc788\uc5b4\uc11c \uc88b\uc740 \uae30\ud68c\uac00 \ub418\uc5c8\ub358\uac83 \uac19\uc2b5\ub2c8\ub2e4.  <br>\n   <br>\n\uc544\ub798\ub294 \uc800\uc758 \uae43\ud5c8\ube0c \uc8fc\uc18c \uc785\ub2c8\ub2e4  <br>\n\ub370\uc774\ud130 \uad00\ub828 \ubd84\uc57c\uc5d0\uc11c \uc77c\ud558\uc2dc\ub294 \ubd84\ub4e4\uc740 \uc800\uc5d0\uac8c \ud314\ub85c\uc6b0\ub97c \uac78\uc5b4\uc8fc\uc138\uc694!  <br>\n[github](https:\/\/github.com\/wldnjd2)   <br>\n \n Hello, I'm JW who prepared for the Kaggle competition with YH.  <br>\nIt's a competition where I didn't learn python properly, so I'm not good at codes.  <br>\nThere are a lot of errors, too!  <br>\nHowever, as I participated in the competition, I studied a lot about Python and it was a good opportunity because it was fun.  <br>\n  <br>\nBelow is my Git Hub address.  <br>\nFor those who work in data-related fields, please follow me!  <br>\n[github](https:\/\/github.com\/wldnjd2)   <br>\n ","e0ce1834":"# 3.1.8 Language transformation\n---","ad346db1":"<h2> World experience and annual salary: Heat Map <\/h2>\n\n<h4>Relatively **positive correlation.** <\/h4>\n\n- Even with 5-10 years of experience, more than 45% has an annual salary of less than $20,000\n\n- With more than 10 years of experience, more than 30% receive an annual salary of $100,000.","2e00bb98":"<h3> used data <\/h3>\n\nWe used all the data for five years. (2017~2021)\n\n<h3>  used Language and Library <\/h3>\n\n   + Numpy\n   + Metplotlib\n   + seaborn\n   + Plotly\n       - plotly.express : An interface where you can draw a graph easily and quickly.\n       - plotly.graph_objects : You can customize it in the way you want because you can do more detailed work than express.\n       - plotly.figure_factory : Used before express existed and remains in the module for compatibility with previous versions\n       - plotly.subplots : A module that displays multiple graphs in one figure.\n       - plotly.offline : Save locally and create HTML that opens in a web browser and make it standalone\n\n<h3> Grouping data sections <\/h3>\n\n   - East Asia and World\n        - East Asia : ['China','Taiwan', 'South Korea', 'Japan']\n        - World : all data\n   - Gender\n        - [Male, Female, Others]\n   - Job   <br>\n    **Data_Analyst** =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration', \n                        'A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', Humanities', 'Statistician', 'Mathematics or statistics', \n                        'Medical or life sciences (biology, chemistry, medicine, etc.)', Physics or astronomy', 'Social sciences (anthropology, psychology, sociology, etc.)', \n                        'Environmental science or geology', 'Humanities (history, literature, philosophy, etc.)'] <br>\n    **Data_Scientist** =['Data Scientist',  'Research Scientist', 'Researcher','Machine Learning Engineer', 'Scientist\/Researcher'] <br>\n    **Developer**=['Developer Relations\/Advocacy','Data Engineer','Engineer','Engineering (non-computer focused)',\n                         'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)',  'Fine arts or performing arts','Product Manager', 'Software Developer\/Software Engineer', \n                         'Product\/Project Manager','Program\/Project Manager','DBA\/Database Engineer']\n    **Not_Employed** = ['Currently not employed', 'Not employed', 'Student'] <br>\n    **Others** = ['I never declared a major', 'Other'] <br> <br>\n   - Age \n   [18-21, 20s, 30s, 40s, 50s, 60s<] <br>\n   - Degree  \n   ['college', 'Bachelor\u2019s degree','Master\u2019s degree', 'Doctoral degree~', 'etc'] <br>\n   - Experience \n   [<1, 1-3, 3-5, 5-10, 10+] <br>\n   - Salary \n   [<999, 1,000-20,000, 20,000-59,999, 60,000-99,999, 100,000-199,999, 200,000~] <br>\n    ","9d0bd381":"\n## Newbie as a data scientist in East Asia!\n\nHello, Kaggers! Nice to meet you! \n\nWe are a team in East Asia that wants to be **data scientists** \n\nAs newbies, we want to know what and\/or how Kaggler is!\n\nso, let's have a time to learn about Kaggle as a senior with us from now.\n\nIf you want to support us*(or feel qute)*, I ask for a comment! (PLZ) ^0^\n\nAnd !! Since we are **not native English speakers**, please ask questions if there is a context that you don't understand because it's not smooth.\n\nI'll do my best to answer.\n\n\n# 1 Introduction\n1. what is the Kaggle\na subsidiary of **Google LLC**, is an online **community of data scientists and machine learning practitioners**.\n\nIf we use kaggle, we can take the following advantages.\n\n    1) to find and publish data sets\n    2) to explore and build models in a web-based data-science environment\n    3) to work with other data scientists and machine learning engineers\n    4) to enter competitions to solve data science challenges\n    \nso, As data scientist beginners, we try to participate in the Kaggle competition.\n\n---\n\n2. **21 Kaggle** Machine Learning and Data Science Survey\n- The most comprehensive dataset available for ML and data science status\n\nThis is the theme of the competition we will participate in this time.\n\nTo become a data scientist, we compared what kind of job Kagglers has, how much experience he has, and how much money he earns by dividing into the world and East Asia.\n\nIn addition, there are detailed comparisons in East Asia, and ultimately, we will to find out what data the Kaggle competition data shows.\n\nThe 2021 survey, like 2017, 2018, 2019, and 2020, launched an industry-wide survey that comprehensively presents the current status of data science and machine learning.\n\nThe survey was conducted from 09\/01\/2021 to 10\/04\/2021, and after cleaning the data, Kaggle received 25,973 responses!\n\nThis year, Kaggle will award $30,000 in prize money to winner in this competition.\n\nwe want to receive $30,000 for winning the competition, but we just hope it will help us become a *data scientist* because it is difficult for a rookie.\n\n\n\nRef.\n\n\\[1\\] [Kgg_competitions](https:\/\/www.kaggle.com\/docs\/competitions)\n\n\\[2\\] [Kgg_definition](https:\/\/en.wikipedia.org\/wiki\/Kaggle)\n\n\\[3\\] [kaggle-survey-2021](https:\/\/www.kaggle.com\/c\/kaggle-survey-2021)","c46a6a85":"<h2>The correlation between the career of a Data Scientist and the annual salary.<\/h2>\n\nIf you don't have experience, you have the highest rate of $999.\n\nLess than 1 year, 1-3 years have the highest percentage of $999.\n\nThe highest percentage of $20,000 to $60,000 in 3-10 years.\n\n10-20 years have the highest percentage of $60,000 to $100,000.","ba4dd2de":"![image.png](attachment:85ab1662-6b79-4573-9fc6-fd4a06dac5d4.png)\n\n![image.png](attachment:a3267e76-64a2-45fa-9c8f-8136fc761106.png)\n\n","9244da90":"<h2>Comparison of educational background of Data Scientists. <br><\/h2>\n <br>\n- It has the highest level of Master's Degrees. <br>\n <br>\n- Next, Doctoral Degree, <br>\n <br>\n- The figure was high in the order of Bachelor's Degree. <br>\n","8aa42b62":"# 3.1.4 Age transformation\n---","ae6029e5":"<h2> Percentage of East Asia degrees by year: sunburst plot <\/h2>\n\nThe highest percentage of respondents with **master's degrees** per year","c7b82d9b":"<h2> 21' World Vs East Asia Age Ratio: Bar plot <\/h2>\n\n- Not Employed : More than 30% in both East Asia and the world, the highest.\n    \n    *Because \"Students\" is included.*\n- Data Scientist : High percentage in the world and East Asia.\n\n- Relatively low proportion in East Asia.\n    <strong>**= Absolute lack of numbers**<\/strong>\n \n \n<p style=\"color:#FF0000\";>\nWe would like to move forward by selecting a **data scientist** with insufficient numbers in East Asia.\n<\/p>","7f3c4b8a":"# 3. plots and description\n---","44d23ab1":"<h2> World job ratio in each country: pie plot <\/h2>\n\n- World: 90% or higher Bachelor's degree\n- East Asia: 85% bachelor's degree or higher","a6993302":"- Annual salary of Research Scientist.\n: The highest percentage of $2.6 million is 29.81%.\n\n- The annual salary of Machine Learning Engineer.\n: The highest rate of $999 is 31.89%.\n\n- The annual salary of Data Scientist is..\n: The ratio of $1,000 to $20,000 is the highest at 29.19%.\n\n\n<h2>\u21d2 The higher the annual salary, the lower the overall job rate.<\/h2>","65968c88":"# 3.1.7 Salary transformation\n---","73750f2b":"<h2> East Asia Degree Ratio: Bar plot<\/h2>\n\n40% of master's degrees or higher, and respondents have a high educational background.\n\n- China and Japan have similar trends to East Asia and the World. <br>\n    The number of people itself is large, so a representative trend seems to appear here. <br>\n    However, it is noteworthy that the two countries have the same tendency. <br>\n\n\n- Korea: It is the only country among the four countries with a high degree of education below Ph.D., bachelor's degree, and junior college. Only masters are low. \n    (Polarization of education?)\n\n- Taiwan: 1st place in master's ratio (55%), 2nd place in Ph.D. or higher (13.8%).\n    = The highest level of education.","f0a4add3":"<h2> World & East Asia Annual salary: Bar-H plot\n<\/h2>\n\n- \\$ 200,000 ~ : World (2.9%) is more than 50% compared to East Asia (1.3%)\n- \\$ ~250,000 : World (59.2%) is less than East Asia (50.3%) <br>\n    = East Asia's annual salary gap between rich and poor is less.\n- \\$ 25,000~60,000: The highest section in East Asia at 24%. <br>\n= The annual salary section that we aim for.","1b920b50":"# 3.1.2 Gender transformation\n---","7ade47c4":"<h2>World: The proportion of female respondents increases (still below 20%) <\/h2>\n\nThe number of respondents is increasing in all genders.\n\nOur team is also a team with high female members and wants to contribute as a respondent in 2022.","03b2ec7e":"# 3.2.2 Salary-Experience\n---","5dc0a7df":"<h2> Number of respondents <\/h2>\n    \n(bar, scatter plot : number of respondents to World and East Asia,\nMap plot : number of respondents to East Asia)\n    \n**World and East Asia: The same trend.**\n    \nEast Asia: 15% of the total continent and 20.3% of the population (16\/78.7: Ea\/Wo)\n    \n2018 Issue: Significant increase in respondents->Hypothesis: Due to the rapid increase in China.\n    \n2018 Outliers Considering: 2022 Kaggle survey Respondents: Increased in both World and East Asia\n    \nI wish our team the honor of becoming a respondent to the Kaggle survey in 2022....","a185bbbb":"<h3> Parallel Categories Diagram <br><\/h3>\n: Visualization of multidimensional categorical datasets <br>\n <br>\nAbout 555 Data Scientist Jobs, Visualize it. <br>\nThe higher the height of the category, the more data is generated. <br>\nIt indicates that the frequency increases. <br>","e91116ca":"<h2> 17'East Asia Age Ratio: Heat Map <\/h2>\n\n+ **East Asia** : 50% or more. Those in their 20s and 30s.\n+ **Korea**: Those in their 20s are the highest.\n    The number of respondents in their 50s and older is also large.\n+ **Taiwan** : The number of respondents in their 30s and older is relatively small.\n+ **China**: 70% or more of respondents in their 30s or younger.\n    Related to life expectancy?\n+ **Japan**: Like an aging country, all ages are evenly distributed.\n    Even if you're older, there are many respondents to Kaggle.","2e4214f2":"# 3.2.1 Salary\n---","9d0bed07":"> 17'East Asia's age ratio: Box plot\n\n> 2017: Data is not a section but an individual number.  <br>\n> If you divide the interval, you can add it to the previous graph. <br>\n> It was data that I could draw a bar plot, so I drew it. <br>\n> You can see a 100-year-old in China, but they don't remove missing values on purpose.","36ea1df3":"<h2> World & East Asia Degree\/Annual salary: Heat Map <\/h2>\n\n- \\\\$ ~20,000 : Regardless of degree, about 40% of the annual salary is \\$ 20,000 or less. <br>\n    Guess it's the ratio that comes from a student. <br>\n- \\$ 25,000-100,000 : Earned more than 40% with a bachelor's degree alone in East Asia  <br>\n    (World: less than 20%) <br>\n- \\$ 200,000~ : Even with a doctorate or higher, it is difficult to obtain it from East Asia.","10017910":"# 3.1.5 Degree transformation\n---","3880fcd3":"# 3.1.3 Job transformation\n---","24d1da07":"<h2>Relationship between Data Scientist's academic background and annual salary. <br><\/h2>\n <br>\n \n- If your educational background is below college, <br>\n: Less than 999 dollars. <br>\n<br>\n\n- The lowest annual salary accounts for the highest percentage.<br>\n <br>\n- Bachelor's degree, Master's Degree, Doctoral degree <br>\n:$2~60,000 dollars accounts for a large proportion <br>\n\n <br>\n<h2>\u21d2 The higher the education level, the higher the annual salary. <br><\/h2>","78d67603":"<h2>The language that Data Scientist uses a lot. <br><\/h2>\n <br>\n- Python accounts for the highest percentage of 80% or more. <br>\n <br>\n- Second, I use R the most. <br>\nR is used less frequently in the order of 2019, 20, and 21. <br>\n <br>\n- From 19 to 21, the percentage of use rate of use 10% -> 4%, a total of 6% decrease. <br>\n <br>\n- The third most frequently used language is SQL. <br>\nSQL increased 0.6 percent in 2020 from 2021. <br>\n <br>\n- The fourth most frequently used languages are C language and C++. <br>\n <br>\n<h2>\u21d2 To become a Data Scientist, Let's study Python first! <br><\/h2>","a884f9ea":"# 3.2.4 Salary-Degree\n---","4099d52f":"# 2. data Import and pre-treatments\n---","87f21af8":"# 3.1.6 Experience transformation\n---","5aa1c63d":"# 4. Ref.\n---","a1fcd487":" # 3.2 Position of Data Scientist in East Asia\n ---","76c4dab0":"# 5. close\n---","1f46a2f3":"<h2> Ref. <\/h2>\n\n- \ub3d9\uc544\uc2dc\uc544 \uc9c0\uc5ed https:\/\/ko.wikipedia.org\/wiki\/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84\n\n- \ub3d9\uc544\uc2dc\uc544 \uc778\uad6c https:\/\/ko.wikipedia.org\/wiki\/%EC%95%84%EC%8B%9C%EC%95%84%EC%9D%98_%EC%9D%B8%EA%B5%AC\n\n- \uc138\uacc4 \uc778\uad6c https:\/\/ko.wikipedia.org\/wiki\/%EC%84%B8%EA%B3%84_%EC%9D%B8%EA%B5%AC <br> https:\/\/ko.wikipedia.org\/wiki\/%EC%9D%B8%EA%B0%84_%EA%B0%9C%EB%B0%9C_%EC%A7%80%EC%88%98#2020%EB%85%84\n\n- \ub3d9\uc544\uc2dc\uc544 \uc778\uac04\uac1c\ubc1c\uc9c0\uc218  https:\/\/namu.wiki\/w\/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84\n\n-  Data Scientist\ub780  https:\/\/dataprofessional.tistory.com\/126 <br> https:\/\/terms.naver.com\/entry.naver?docId=1691563&cid=42171&categoryId=42183\n\n- Kaggle\uc774\ub780 https:\/\/ko.wikipedia.org\/wiki\/%EC%BA%90%EA%B8%80\n- Python\uc774\ub780 https:\/\/ko.wikipedia.org\/wiki\/%ED%8C%8C%EC%9D%B4%EC%8D%AC\n\n- Kaggle competition Ref. https:\/\/www.kaggle.com\/miguelfzzz\/the-typical-kaggle-data-scientist-in-2021 <br> https:\/\/www.kaggle.com\/desalegngeb\/how-popular-is-kaggle-in-africa\n\n\n- flaricon: <div>Icons made by <a href=\"https:\/\/www.freepik.com\" title=\"Freepik\">Freepik<\/a> from <a href=\"https:\/\/www.flaticon.com\/\" title=\"Flaticon\">www.flaticon.com<\/a><\/div>\n\n\n","f060e9d2":"<h2> Trends in World & East Asia Career: Stacked Scatter plot <\/h2>\n- < 2 years: 50% of the total. <br>\n- 3-5 years: Decrease in the world, maintain East Asia ratio <br>\n- 2021 'etc data' disappeared. <br>","470540d9":"<h3> Plus we could see the advantages of Plotly in this graph. \n<\/h3>\n\nMatplotlib draws a static graph, but Plotly can dynamically click and move, and it supports zooming out, zooming in, and downloading graphs.\n    \nBecause all of our graphs are made of plotly, the viewer can represent or remove items in the graph if desired. \n   **With a click**","f581f229":"<h2> World Job Ratio: Heat Map <\/h2> \n\nThe trend of increasing each job except Others. <br>\nData Scientist has a high proportion, and the trend is to increase further in 2022. <br>\n\n<h2> East Asia Job Ratio: Heat Map <\/h2> \nEast Asia : Increasing the ratio of data scientist. <br>\n","5ff0aa2d":"<h3>\n    \n    - Male (1004->2037 : 2017->2021) double increase\n    \n    - Female 183->327 : 2017->2021 increased 1.8 times\n    \n    - Others (8->64 : 2017->2021) 8x increase\n    \n<\/h3>\n[Compare the high and low points]\n\n+ It can be seen that the number of female respondents and the ratio of male respondents hardly change, which is a difference compared to World data.\n\n+ It can be seen that the degree of gender freedom in East Asia has increased relatively.\n+ Compared to World data, it can be seen that in 2021 (1.87: 2.6= Wo: Ea), compared to 2017 (1.96: 0.7 = Ea), which was relatively conservative.","4d14a0cc":"<h2>18\u2019 : <\/h2>\n\nUser change between United States and India.\n\nChina's markedly increase in 2018\n\n+ There is no Taiwan, but only China has increased. : East Asian political situation Issue can be suspected.","fba4e425":"# 3.2.3 Degree\n---","195b8f43":"# 1.3 Summary\n---\n","c4678999":"# 1.2 Contents\n---\n\n>     Introduction\n>     Contents\n>     Summary\n>     Data Import and Preprocessing\n>     Plots and Description\n\n>     Kaggle's transformation. (World\/East_Asia)\n>         1 user transformation\n>         2 Gender transformation\n>         3 Job transformation\n>         4 Age  transformation\n>         5 Degree transformation\n>         6 Experience transformation\n>         7 Salary transformation\n>         8 Language transformation\n\n>     Position of Data Scientist in East Asia\n>         1 Salary\n>         2 Salary-Experience\n>         3 Degree\n>         4 Salary-Degree\n>         5 Language\n\n>     Discussion\n>     Close"}}