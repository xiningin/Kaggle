{"cell_type":{"8187c246":"code","487027b8":"code","237049f9":"code","6eaaa293":"code","7bd3c8e3":"code","54c73423":"code","1c4462e8":"code","079c1874":"code","b35831da":"code","40fba4fd":"code","32a5e344":"code","1926a053":"code","dbaabc28":"code","c33475f9":"code","e0c4a525":"code","52d92216":"code","b1db67ff":"code","a0ec4ee3":"code","ff27dcb0":"code","819439d9":"code","e11f2f61":"code","7de56b36":"code","fc9415a4":"code","30dea78c":"code","da39b768":"code","573f8cbd":"code","20979fa1":"code","30313343":"code","268c43fd":"code","06937e05":"code","ef807a40":"markdown"},"source":{"8187c246":"# Clone the library","487027b8":"! git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","237049f9":"# Install the pre-requisistes","6eaaa293":"!pip install -r monk_v1\/installation\/requirements_kaggle.txt","7bd3c8e3":"# Add to path","54c73423":"import sys\nsys.path.append(\"\/kaggle\/working\/monk_v1\/monk\/\")","1c4462e8":"# Unzip datasets","079c1874":"!unzip -q \/kaggle\/input\/aerial-cactus-identification\/train.zip","b35831da":"!unzip -q \/kaggle\/input\/aerial-cactus-identification\/test.zip","40fba4fd":"# Import prototype","32a5e344":"from pytorch_prototype import prototype","1926a053":"# Set Dataset","dbaabc28":"gtf = prototype(verbose=1);\ngtf.Prototype(\"sample-project-1\", \"sample-experiment-1\");\n\ngtf.Dataset_Params(dataset_path=\"train\/\",\n           path_to_csv=\"\/kaggle\/input\/aerial-cactus-identification\/train.csv\",\n        input_size=(32, 32), batch_size=16, shuffle_data=True, num_processors=3);\n\ngtf.apply_random_horizontal_flip(train=True, val=True);\ngtf.apply_normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], train=True, val=True, test=True);\n\ngtf.Dataset();","c33475f9":"# Create model and debug simultaneously","e0c4a525":"network = [];\nnetwork.append(gtf.convolution(output_channels=16));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.convolution(output_channels=16));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());\ngtf.debug_custom_model_design(network);\n","52d92216":"subnetwork = [];\nbranch1 = [];\nbranch1.append(gtf.convolution(output_channels=16));\nbranch1.append(gtf.batch_normalization());\nbranch1.append(gtf.convolution(output_channels=16));\nbranch1.append(gtf.batch_normalization());\n\nbranch2 = [];\nbranch2.append(gtf.convolution(output_channels=16));\nbranch2.append(gtf.batch_normalization());\n\nbranch3 = [];\nbranch3.append(gtf.identity())\n\nsubnetwork.append(branch1);\nsubnetwork.append(branch2);\nsubnetwork.append(branch3);\nsubnetwork.append(gtf.concatenate());\n\n\nnetwork.append(subnetwork);\ngtf.debug_custom_model_design(network);\n\n\n","b1db67ff":"network.append(gtf.convolution(output_channels=32));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());\ngtf.debug_custom_model_design(network);\n\n","a0ec4ee3":"subnetwork = [];\nbranch1 = [];\nbranch1.append(gtf.convolution(output_channels=32));\nbranch1.append(gtf.batch_normalization());\nbranch1.append(gtf.convolution(output_channels=32));\nbranch1.append(gtf.batch_normalization());\n\nbranch2 = [];\nbranch2.append(gtf.convolution(output_channels=32));\nbranch2.append(gtf.batch_normalization());\n\nbranch3 = [];\nbranch3.append(gtf.identity())\n\nsubnetwork.append(branch1);\nsubnetwork.append(branch2);\nsubnetwork.append(branch3);\nsubnetwork.append(gtf.add());\n\n\nnetwork.append(subnetwork);\ngtf.debug_custom_model_design(network);\n\n\n","ff27dcb0":"network.append(gtf.convolution(output_channels=32));\nnetwork.append(gtf.batch_normalization());\nnetwork.append(gtf.relu());\nnetwork.append(gtf.max_pooling());\ngtf.debug_custom_model_design(network);\n\n\n\n","819439d9":"network.append(gtf.flatten());\nnetwork.append(gtf.fully_connected(units=1024));\nnetwork.append(gtf.dropout(drop_probability=0.2));\nnetwork.append(gtf.fully_connected(units=2));\ngtf.Compile_Network(network, data_shape=(3, 32, 32));","e11f2f61":"# Set training parameters","7de56b36":"gtf.Training_Params(num_epochs=50, display_progress=True, display_progress_realtime=True, \n        save_intermediate_models=False, save_training_logs=True);\n\n\ngtf.optimizer_sgd(0.001);\ngtf.lr_fixed();\ngtf.loss_softmax_crossentropy();","fc9415a4":"gtf.Train();","30dea78c":"# Step 0 - Using Pytorch\nfrom pytorch_prototype import prototype\n\n# Step 1 - Load experiment in evaluation mode\nptf = prototype(verbose=1);\nptf.Prototype(\"sample-project-1\", \"sample-experiment-1\", eval_infer=True)\n\n\n# Step 2 - Run inference on dataset\noutput = ptf.Infer(img_dir=\"test\/\");","da39b768":"num_0 = 0;\nnum_1 = 1;","573f8cbd":"# Create submission\nimport pandas as pd\nsub = pd.read_csv(\"\/kaggle\/input\/aerial-cactus-identification\/sample_submission.csv\");\nfor i in range(len(output)):\n    index = int(sub[sub['id']==output[i]['img_name']].index[0])\n    if(int(output[i]['predicted_class']) == 0):\n        num_0 += 1;\n    else:\n        num_1 += 1;\n    sub['has_cactus'][index] = int(output[i]['predicted_class'])\nsub.to_csv(\"submission.csv\", index=False);","20979fa1":"num_0, num_1","30313343":"!rm -r \/kaggle\/working\/monk_v1\/","268c43fd":"!rm -r test","06937e05":"!rm -r train","ef807a40":"\n## Author - Tessellate Imaging - https:\/\/www.tessellateimaging.com\/\n### Monk Library - https:\/\/github.com\/Tessellate-Imaging\/monk_v1\n\n### Monk is an opensource low-code tool for computer vision and deep learning\n\n### Monk features\n\n    low-code\n    unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n    syntax invariant wrapper\n\n### Enables\n\n    to create, manage and version control deep learning experiments\n    to compare experiments across training metrics\n    to quickly find best hyper-parameters\n\n### At present it supports transfer learning, and custom model creation for pytorch and gluon backend, but we are working each day to incorporate\n\n    GUI based custom model creation\n    various object detection and segmentation algorithms\n    deployment pipelines to cloud and local platforms\n    acceleration libraries such as TensorRT\n    preprocessing and post processing libraries\n\n### To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or dm us on linkedin\n\n    Abhishek - https:\/\/www.linkedin.com\/in\/abhishek-kumar-annamraju\/\n    Akash - https:\/\/www.linkedin.com\/in\/akashdeepsingh01\/\n\n"}}