{"cell_type":{"b79b922e":"code","5d8d4c9e":"code","3c871d4f":"code","cc115e41":"code","0ecfb914":"code","5444e6c1":"code","b5f4be6e":"code","a690b6a9":"code","8ee0d05b":"code","5449afe0":"code","1d30e931":"code","fcc4ce40":"code","8e76cc29":"code","ad07f3b6":"code","a9102a13":"code","f85cae55":"code","0f59e8e1":"code","9cf455f5":"code","cbcbbc4c":"code","cbaae26a":"code","3c75dcc9":"code","59bc9bd3":"code","cdb5cca5":"code","90728edc":"code","82667971":"code","ffd97eac":"code","d83a9e4b":"code","1888cee4":"code","ae24e528":"code","3299e33f":"code","75f5d4ae":"code","b31401de":"code","af665ad4":"code","b46bf218":"code","40b47075":"code","5db9177e":"code","2b7ee4e5":"code","c9579f23":"code","c8ae6dab":"code","8928988d":"code","ed7c32f6":"code","8536555a":"code","8c6f6e9c":"markdown","1afd04f9":"markdown","71c3e2ad":"markdown","dd208b5d":"markdown","4110cbb2":"markdown","a30f3026":"markdown","78a8a6f9":"markdown","87169e3d":"markdown","21923bf3":"markdown","af0f72a6":"markdown","d00ab224":"markdown","600daeaf":"markdown","3b57475f":"markdown","f7252714":"markdown","5edb187b":"markdown","cb68c24b":"markdown","44637fac":"markdown","995e08c8":"markdown","f2f6655e":"markdown","b9068047":"markdown","20ff3e81":"markdown","78557f18":"markdown","d6426ce1":"markdown","ad802300":"markdown","7ce314e0":"markdown","9f30b90a":"markdown","15c884ee":"markdown","a1a7bf0b":"markdown","374194a7":"markdown","796b029e":"markdown","f4f02259":"markdown","887cde63":"markdown","87f26e21":"markdown","a532e69e":"markdown","1663b9a8":"markdown","8eef1b0f":"markdown","70b8619f":"markdown","494cf876":"markdown","986fced6":"markdown","880a53f2":"markdown","99970696":"markdown","6bf43bee":"markdown","3a7b4ab2":"markdown","f30d7427":"markdown","725995f9":"markdown","c93b153c":"markdown","6d13f7c6":"markdown"},"source":{"b79b922e":"#importing useful libararies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sea\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score","5d8d4c9e":"#read the Sales Records excel file\ndf = pd.read_csv(r'..\/input\/income-classification\/income_evaluation.csv')","3c871d4f":"df.head(5)","cc115e41":"df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']","0ecfb914":"df.isna().sum()","5444e6c1":"df.dtypes","b5f4be6e":"num = [i for i in df.columns if df[i].dtype!='O']\ncat = [i for i in df.columns if df[i].dtype=='O']","a690b6a9":"df[cat].nunique().plot(kind='bar')","8ee0d05b":"for i in df[cat]:\n    print(df[i].value_counts())","5449afe0":"df.replace(' ?', np.nan, inplace= True)","1d30e931":"df.isna().sum()","fcc4ce40":"df.fillna(method = 'bfill', inplace=True)","8e76cc29":"df.isna().sum().sum()","ad07f3b6":"df.income.value_counts()","a9102a13":"sea.countplot(x= 'income' ,data =df)","f85cae55":"df.income.value_counts().plot(kind='pie')","0f59e8e1":"sea.countplot(x=\"income\", hue=\"sex\", data=df)","9cf455f5":"plt.subplots(figsize=(12, 8))\nsea.countplot(x=\"income\", hue=\"workclass\", data=df)","cbcbbc4c":"plt.subplots(figsize=(12, 8))\nsea.countplot(hue=\"sex\", x=\"workclass\", data=df)","cbaae26a":"for i in cat:\n    \n    print(i, ' contains ', len(df[i].unique()), ' labels')","3c75dcc9":"y = df.income","59bc9bd3":"df","cdb5cca5":"y = pd.get_dummies(y,drop_first=True)\n#df.drop(['income'],axis =1, inplace=True)","90728edc":"x = pd.get_dummies(df[cat])","82667971":"df.drop(df[cat],axis = 1,inplace = True)","ffd97eac":"df[num].head()","d83a9e4b":"sea.distplot(df.age, bins=10)","1888cee4":"sea.boxplot(df.age)","ae24e528":"df.corr()","3299e33f":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ndf = scaler.fit_transform(df)","75f5d4ae":"df = pd.DataFrame(df)\nx = pd.concat([x,df],axis=1)","b31401de":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","af665ad4":"X_train.head(2)","b46bf218":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","40b47075":"y_pred = logreg.predict(X_test)\naccuracy_score(y_test, y_pred)","5db9177e":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=10)\nrfc.fit(X_train, y_train)","2b7ee4e5":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","c9579f23":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=100)\nrfc.fit(X_train, y_train)","c8ae6dab":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","8928988d":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nmodel = BaggingClassifier(random_state=0)\nmodel.fit(X_train, y_train)","ed7c32f6":"y_pred = model.predict(X_test)\naccuracy_score(y_test, y_pred)","8536555a":"#import xgboost as xgb\n#model=xgb.XGBClassifier(base_estimator = rfc,random_state=1,learning_rate=0.1)\n#model.fit(X_train, y_train)\n#model.score(X_test,y_test)","8c6f6e9c":"See we can easily get the count of NaN values","1afd04f9":"### Fitting the Random forest Model with only 10 decision trees ","71c3e2ad":"#### Checking the data Types of the variables","dd208b5d":"### Checking the correlation between numerical variables.","4110cbb2":"### Fitting the Random forest Model with only 100 decision trees","a30f3026":"### Correcting the columns names","78a8a6f9":"### Testing the random forest model by predicting the test data and calculate the accuracy score ","87169e3d":"#### Remove the target variable income ","21923bf3":"**Observation**\n- most number of people are belong to 20 to 50 age group.","af0f72a6":"### Seperating categorical and numerical variables apart","d00ab224":"### lets encode the categorical varibles with one hot encoding","600daeaf":"### Testing the bagging model and calculate accuracy","3b57475f":"Checking the different categories in each categorical variables","f7252714":"**This Data Set Name is Income Classification**\n**Shape of the data set (32561,15)**\n**NuLL values:** Not Present\n\n**Variables:** 'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income'.\n\nThere are **9 categorical variables** and **6 Numerical variables.** \n\n**Income is the Target Variable**\n\n\nBy using this dataset, I try to make prediction whether the person is making over 50K or less than 50K. \nI have implemeted the Random Forest Classification with python. Also, I have also using ensemble learnig to increase the accuracy of our Model.\n","5edb187b":"**Observation**\n- In workclass the highest number of people doing work in private. And in all workclass males are highest. ","cb68c24b":"**Summary**\n- This income prediction classification problem, the logistic regerssion achieved 85.13%.\n- The simple baggging with no base model gives accuracy 84.39%\n- Ensemble learning bagging technique with base model Random forest with 10 decision tress, gives accuracy is 84.95%\n- Ensemble learning bagging technique with base model Random Forest with 100 decision trees, gives accuracy is 85.40%\n- In Ensemble learning Boosting technique with base model random forest, gives accuracy 86.94%","44637fac":"There are no missing values","995e08c8":"### Income distribution w.r.t workclass","f2f6655e":"#### view the Distribution of Age variable","b9068047":"**Observation**\n- There are more people who employed with private sector, in both categories of income. ","20ff3e81":"##### here you can see the counts of null values in the variables. \n\n### Now using fillna() function we need to replace the the null the previous column value ","78557f18":"**Obseravation**\n\n -There are some outliers present in Age variables.","d6426ce1":"** Observation**\n- This graph sows no of different categories in the categorical variables","ad802300":"###  Testing the logistic model by predicting the test data and calculate the accuracy score ","7ce314e0":"### Splitting the data into test and train","9f30b90a":"**Observation**\n- people who are earning less than 50K are high in numbers also Male are high in numbers","15c884ee":"Now, there is no null or invalid values left in our data","a1a7bf0b":"### Fitting the Logistic Regression model","374194a7":"### plotting the workclass w.r.t gender.","796b029e":"##### Accuracy increase by 0.1 by increasing the number of decision tress.","f4f02259":"## Fitting the Extream gradient boosting method with keeping hyperparamerter(learning rate is 0.1 ) then calculate accuracy.","887cde63":"### Scalling the Numerical varibales ","87f26e21":"**Observation**\n- Only two categories in income variable","a532e69e":"**Observation**\n- There are more than 75% number of people making less than 50k.","1663b9a8":"### ****Replacing all invalid values to NaN values, so we can easily fill that****","8eef1b0f":"### Checking the outliers in Numerical variables.","70b8619f":"### Checking missing values","494cf876":"**Observation**\n- There are some '?' values instead of null values are present in some variables. we need to remove these values.\n- You can see all different classes of categorical variables with their share or get the count of distribution of values.","986fced6":"## Bagging method of ensemble learning ","880a53f2":"### Testing the random forest model by predicting the test data and calculate the accuracy score with100 decision tress. ","99970696":"# EDA on Numerical Variables","6bf43bee":"**Observation**\n- there is no correlation beween the variables.","3a7b4ab2":"### visualize trainig data","f30d7427":"### See the income distribution with respect to gender","725995f9":"Lets have a look to our data","c93b153c":"### Our target variable income, lets visualize it, with repect to others variables","6d13f7c6":"### EDA on Categorical variables"}}