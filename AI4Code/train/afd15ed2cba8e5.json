{"cell_type":{"ab0bacee":"code","9b920b68":"code","de3f9189":"code","4330369d":"code","715272c0":"code","008d8403":"code","69d1091b":"code","4b85204c":"code","fda9b974":"code","71b567e0":"code","f913169e":"markdown","aae3c6cf":"markdown","ad262b45":"markdown","4015ad1a":"markdown","521f153e":"markdown","084d7212":"markdown","7ead497b":"markdown"},"source":{"ab0bacee":"import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection","9b920b68":"df_train = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ndf_train.head()","de3f9189":"#Total amount of data\nlen(df_train.value_counts())","4330369d":"#plot target distribution\ndf_train.target.hist()","715272c0":"df_train[\"kfold\"] = -1\ndf_train.head()","008d8403":"kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=0)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n    df_train.loc[valid_indicies, \"kfold\"] = fold","69d1091b":"#Amount of data in each fold\ndf_train.kfold.value_counts()","4b85204c":"def plot_fold_dist(fold):\n    for fold in range(len(df_train.kfold.unique())):\n        return df_train[df_train.kfold == fold].target.hist()\n        ","fda9b974":"plot_fold_dist(9)","71b567e0":"df_train.to_csv(\"train_folds.csv\", index=False)","f913169e":"Create folds: why?, because it generally results in models with low bias. [Read more](https:\/\/towardsdatascience.com\/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79)","aae3c6cf":"Import Libraries","ad262b45":"Append a new column called \"kfold\" with value \"-1\" to the end of the dataframe","4015ad1a":"Read csv as dataframe","521f153e":"Create 10 folds","084d7212":"save train-folds","7ead497b":"Plot target distribution for each fold, the distribution should be the same as the for all folds and the plot of the target distribution on the overal dataset made earlier "}}