{"cell_type":{"b36afec9":"code","39603973":"code","f981b837":"code","70be66c7":"code","34710fd6":"code","cea59a6f":"markdown"},"source":{"b36afec9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport time\nfrom datetime import datetime\n\nasset_details = pd.read_csv('..\/input\/g-research-crypto-forecasting\/asset_details.csv')","39603973":"dict_ticker = {'Bitcoin Cash':'BCH',\n'Binance Coin':'BNB',\n'Bitcoin':'BTC',\n'EOS.IO':'EOS',\n'Ethereum Classic':'ETC',\n'Ethereum':'ETH',\n'Litecoin':'LTC',\n'Monero':'XMR',\n'TRON':'TRX',\n'Stellar':'XLM',\n'Cardano':'ADA',\n'IOTA':'IOTA',\n'Maker':'MKR',\n'Dogecoin':'DOGE'}\n\nchunks = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    if dirname == '\/kaggle\/input\/raw-crypto-1m-data-from-binance\/compressed':\n        for filename in filenames:\n            ticker = filename.split('-')[0]\n            full_name = [i for i in dict_ticker if dict_ticker[i]==ticker][0]\n            Asset_ID = asset_details[asset_details.Asset_Name == full_name].Asset_ID.values[0]\n            \n            data = pd.read_parquet(dirname+'\/'+filename, engine='pyarrow')\n            data = data.reset_index()\n            data = data.rename(columns={'open_time':'timestamp','open':'Open','high':'High','low':'Low','close':'Close','quote_asset_volume':'Volume','number_of_trades':'Count'})\n            data.timestamp = (pd.to_datetime(data.timestamp).astype(int)\/ 10**9).astype(int)\n\n            #definition not okay so far\n            data['VWAP'] = (data.Low * data.taker_buy_base_asset_volume + data.High * data.taker_buy_quote_asset_volume)\/(data.taker_buy_base_asset_volume + data.taker_buy_quote_asset_volume)\n            \n            data = data.drop('volume',axis=1)\n            \n            data['Asset_ID'] = Asset_ID\n            \n            price_column = 'Close'\n\n            data['Time'] = pd.to_datetime(data['timestamp'], unit='s')\n            data.sort_values(by='Time', inplace=True)\n            data.set_index(keys='Time', inplace=True)\n            data['p1'] = data[price_column].shift(freq='-1T')\n            data['p16'] = data[price_column].shift(freq='-16T')\n            data['r'] = np.log(data.p16\/data.p1)\n            data.drop(['p1', 'p16'], axis=1, inplace=True)\n            data.reset_index(inplace=True)\n\n            chunks.append(data)\n\ndata = pd.concat(chunks)\ndata.sort_values(by='timestamp', inplace=True)","f981b837":"data['w'] = data['Asset_ID'].map(asset_details.set_index(keys='Asset_ID')['Weight'])\nweight_sum = asset_details.Weight.sum()\n\ndata['weighted_asset_r'] = data.w * data.r\ntime_group = data.groupby('Time')\n\nm = time_group['weighted_asset_r'].sum() \/ time_group['w'].sum()\n\ndata.set_index(keys=['Time'], inplace=True)\ndata['m'] = m\ndata.reset_index(inplace=True)\n\ndata['m2'] = data.m ** 2\ndata['mr'] = data.r * data.m\n\nids = list(asset_details.Asset_ID)\n\nchunks = []\nfor id in ids:\n    # type: pd.DataFrame\n    asset = data[data.Asset_ID == id].copy()\n    asset.sort_values(by='Time', inplace=True)\n    asset.set_index(keys='Time', inplace=True)\n    asset['mr_rolling'] = asset['mr'].rolling(window='3750T', min_periods=3750).mean()\n    asset['m2_rolling'] = asset['m2'].rolling(window='3750T', min_periods=3750).mean()\n    asset.reset_index(inplace=True)\n    chunks.append(asset)\n    debug = 1\n\ndata = pd.concat(chunks)\ndata.sort_values(by='Time', inplace=True)\ndata['beta'] = data['mr_rolling'] \/ data['m2_rolling']\n\ndata['Target'] = data['r'] - data['beta'] * data['m']","70be66c7":"data = data.drop(['taker_buy_base_asset_volume','taker_buy_quote_asset_volume','r','w','weighted_asset_r','m','m2','mr','mr_rolling','m2_rolling','beta','Time'],axis=1)\n\ncol_ordered = ['timestamp','Asset_ID','Count','Open','High','Low','Close','Volume','VWAP','Target']\ndata = data[col_ordered]\n\ndtype0 = {'Asset_ID': 'int8', 'Count': 'int32', 'Count': 'int32',\n       'Open': 'float32', 'High': 'float32', 'Low': 'float32', 'Close': 'float32',\n       'Volume': 'float32', 'VWAP': 'float32'}\n\ndata = data.astype(dtype0)","34710fd6":"data.to_parquet('add_train.parquet')","cea59a6f":"# Transforming 1m data we get from Binance\n\nForm and size modification.\n\nData set available here: https:\/\/www.kaggle.com\/lucasmorin\/gresearch-1m-data-from-binance\n\nRemaining points to deal with:\n- Vwap calculation (or import ?)\n- target calculation: code used from (https:\/\/www.kaggle.com\/alexfir\/recreating-target). We are discussing the remaining errors. \n- Filtering 0 volume data. (inclusion in target calculation ?)"}}