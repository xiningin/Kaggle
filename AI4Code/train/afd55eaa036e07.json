{"cell_type":{"8974b70e":"code","e49ce904":"code","c7f5f720":"code","2c196bc5":"code","38cfe213":"code","14fbf08b":"code","4da9cc7e":"code","ce54ba86":"code","603db0ae":"code","25f364ae":"code","0e8a7294":"code","b075863d":"code","dec970a7":"code","65c69242":"code","bf2df823":"code","df40ad8c":"code","f3ba22c9":"code","affbdc6a":"code","17f8f48d":"code","43d9ac2f":"code","7a934230":"code","65d91635":"code","1e4cbcac":"code","6e14097b":"code","37338315":"code","ac7fc9cb":"markdown"},"source":{"8974b70e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import train_test_split\n        \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import export_text\nfrom sklearn import metrics\n\nfrom sklearn.metrics import mean_squared_error\nimport math\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e49ce904":"columns = [\n    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n    'minimum_nights', 'number_of_reviews','reviews_per_month',\n    'calculated_host_listings_count', 'availability_365',\n    'price'\n]\n\ndf = pd.read_csv('\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndf.reviews_per_month = df.reviews_per_month.fillna(0)","c7f5f720":"df.price = np.log1p(df.price)","2c196bc5":"df.info()","38cfe213":"df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\ndf_train, df_val = train_test_split(df_full_train, test_size=0.2, random_state=42)\n\nlen(df_train), len(df_val), len(df_test)","14fbf08b":"df_full_train = df_full_train.reset_index(drop = True)\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)","4da9cc7e":"y_train = df_train.price.values.astype('int')\ny_val = df_val.price.values.astype('int')\ny_test = df_test.price.values.astype('int')\n\ndel df_train['price']\ndel df_val['price']\ndel df_test['price']","ce54ba86":"dv = DictVectorizer(sparse=False)\n\ntrain_dict = df_train.fillna(0).to_dict(orient='records')\nX_train = dv.fit_transform(train_dict)\n\nval_dict = df_val.fillna(0).to_dict(orient='records')\nX_val = dv.transform(val_dict)","603db0ae":"dt = DecisionTreeRegressor(max_depth=1)\ndt.fit(X_train, y_train)","25f364ae":"y_pred = dt.predict(X_val)","0e8a7294":"from sklearn.tree import export_text\n\nprint(export_text(dt, feature_names = dv.get_feature_names()))","b075863d":"df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\ndf_train, df_val = train_test_split(df_full_train, test_size=0.2, random_state=1)\n\ndf_full_train = df_full_train.reset_index(drop = True)\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n\ny_train = df_train.price.astype('int').values\ny_val = df_val.price.astype('int').values\ny_test = df_test.price.astype('int').values\n\ndel df_train['price']\ndel df_val['price']\ndel df_test['price']\n\ndv = DictVectorizer(sparse=False)\n\ntrain_dict = df_train.fillna(0).to_dict(orient='records')\nX_train = dv.fit_transform(train_dict)\n\nval_dict = df_val.fillna(0).to_dict(orient='records')\nX_val = dv.transform(val_dict)","dec970a7":"from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs = -1)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_val)","65c69242":"RMSE =  np.sqrt(metrics.mean_squared_error(y_val, y_pred))\nprint(RMSE)","bf2df823":"scores = []\n\nfor n in range(10, 201, 10):\n    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    y_pred = rf.predict(X_val)\n\n    rmse = np.sqrt(metrics.mean_squared_error(y_val, y_pred))\n    \n    scores.append((n, rmse))","df40ad8c":"df_scores = pd.DataFrame(scores, columns=['n_estimators', 'rmse'])\nplt.plot(df_scores.n_estimators, df_scores.rmse)","f3ba22c9":"scores = []\nfor d in [10, 15, 20, 25]:\n    for n in range(10, 201, 10):\n        rf = RandomForestRegressor(n_estimators=n, \n                                   max_depth=d,\n                                   random_state=1, \n                                   n_jobs=-1)\n        rf.fit(X_train, y_train)\n        y_pred = rf.predict(X_val)\n\n        rmse = np.sqrt(metrics.mean_squared_error(y_val, y_pred))\n\n        scores.append((d, n, rmse))","affbdc6a":"columns = ['max_depth', 'n_estimators', 'rmse']\ndf_scores = pd.DataFrame(scores, columns=columns)","17f8f48d":"for d in [10, 15, 20, 25]:\n    df_subset = df_scores[df_scores.max_depth == d]\n    \n    plt.plot(df_subset.n_estimators, df_subset.rmse,\n             label='max_depth=%d' % d)\n\nplt.legend()","43d9ac2f":"rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\nrf.fit(X_train, y_train)","7a934230":"feature_names=dv.get_feature_names()\nfeature_imp = rf.feature_importances_.round(3)\nlist(zip(feature_names, feature_imp))","65d91635":"import xgboost as xgb","1e4cbcac":"features = dv.get_feature_names()\ndtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\ndval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n\nwatchlist = [(dtrain, 'train'), (dval, 'val')]","6e14097b":"xgb_params = {\n    'eta': 0.3, \n    'max_depth': 6,\n    'min_child_weight': 1,\n\n    'objective': 'reg:squarederror',\n    'nthread': 8,\n\n    'seed': 1,\n    'verbosity': 1,\n}","37338315":"for eta in [0.3, 0.1, 0.01]:\n    xgb_params[\"eta\"] = eta\n    model = xgb.train(xgb_params, dtrain, num_boost_round=100)\n    y_pred = model.predict(dval)\n    RMSE = np.sqrt(metrics.mean_squared_error(y_val, y_pred))\n    print(f\"{eta}:{rmse}\")\n    \nprint(RMSE)","ac7fc9cb":"Q1: **room_type** is used to split the data"}}