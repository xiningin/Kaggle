{"cell_type":{"713c2304":"code","187ac948":"code","720be3b4":"code","6c20a0dd":"code","19535285":"code","c72d2aa3":"code","b9678d76":"code","866948fb":"code","6d111c61":"code","928dae0b":"code","e2d1378b":"code","a7e9d99d":"code","38fc5ae0":"code","6228b0e0":"code","109cbe46":"markdown","43da71a8":"markdown"},"source":{"713c2304":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\n%config Completer.use_jedi = False\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","187ac948":"data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndata.sample(5)","720be3b4":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest.head()","6c20a0dd":"data.info()","19535285":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef func_na(x,temp):\n    if pd.isna(x):\n        return np.random.choice(temp)\n    else:\n         return x\n\ndef data_preprocessing(data, flag):\n    numerical_column = [column for column in data.columns if data[column].dtypes == \"int64\"  or data[column].dtypes == \"float64\"]\n\n    categorical_column = [column for column in data.columns if data[column].dtypes == \"object\"]\n\n    num_df = data[numerical_column]\n    cat_df = data[categorical_column]\n\n    if flag == 'train':\n        sales_price_label = num_df['SalePrice']\n\n    # I want to Remove column year YearBuilt , YearRemodAdd , YrSold. I will add column stating how many years old house is\n\n        num_df['YearsOld'] = num_df.apply(lambda x : x['YrSold'] - x['YearBuilt'], axis = 1)\n        num_df.drop(['YrSold', 'YearBuilt', 'Id' , 'SalePrice'], axis = 1, inplace = True)\n    else:\n        num_df['YearsOld'] = num_df.apply(lambda x : x['YrSold'] - x['YearBuilt'], axis = 1)\n        num_df.drop(['YrSold', 'YearBuilt', 'Id' ], axis = 1, inplace = True)\n\n    OneHotEncoding_columns = ['LotShape','MSZoning', 'Street', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope','Neighborhood','Condition1', 'Condition2','BldgType',\n                             'HouseStyle', 'RoofMatl','Exterior1st', 'Exterior2nd' ,'Foundation','Heating', 'CentralAir','Functional','Electrical','MasVnrType',\n                             'GarageType', 'GarageFinish','PavedDrive','SaleType','SaleCondition','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n    label_encoding = [ 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond','HeatingQC','KitchenQual',\n                     'FireplaceQu', 'GarageQual','GarageCond' ]\n\n    replace = { 'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}\n    delete_column = ['Alley', 'PoolQC', 'Fence', 'MiscFeature']\n\n#     fill_previous_value = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','GarageType', 'GarageFinish','GarageQual',\n#                            'GarageCond','FireplaceQu']\n#     fill_previous_value = [clm for clm in data.columns if data[clm].isna().sum()>0 ]\n    fill_previous_value = label_encoding + OneHotEncoding_columns\n\n    cat_df.drop(delete_column, inplace =True, axis = 1)\n\n    for nan_column in fill_previous_value:\n        temp = cat_df[nan_column].unique().copy()\n        temp = temp[~pd.isna(temp)]\n\n        cat_df[nan_column] = cat_df.apply(lambda x : func_na(x[nan_column], temp), axis = 1)\n\n    # Now le\n    one_hot_df = cat_df[OneHotEncoding_columns]\n    label_encod_df = cat_df[label_encoding]\n\n\n    encod = OneHotEncoder()\n\n    encod.fit(one_hot_df)\n    one_hot_trans_df = encod.transform(one_hot_df)\n    feature_name = encod.get_feature_names(OneHotEncoding_columns)\n    label_encod_df.replace(replace, inplace=True)\n    \n\n    num_pipeline = Pipeline([\n     ('imputer', SimpleImputer(strategy=\"median\")),\n     ('std_scaler', StandardScaler()),\n     ])\n    housing_num_tr = num_pipeline.fit_transform(num_df)\n\n    frame = [pd.DataFrame(one_hot_trans_df.toarray(), columns = feature_name), label_encod_df , pd.DataFrame(housing_num_tr, columns = num_df.columns)]\n    \n    print(pd.DataFrame(one_hot_trans_df.toarray(), columns = feature_name).shape, label_encod_df.shape, pd.DataFrame(housing_num_tr).shape)\n    result = pd.concat(frame, axis = 1)\n\n    if flag == 'train':\n        return result, sales_price_label, encod\n    else:\n        return result, encod","c72d2aa3":"result_train, sales_price_label , encod= data_preprocessing(data, 'train')","b9678d76":"numerical_column = [column for column in test.columns if test[column].dtypes == \"int64\"  or test[column].dtypes == \"float64\"]\n\ncategorical_column = [column for column in test.columns if test[column].dtypes == \"object\"]\n\nnum_df = test[numerical_column]\ncat_df = test[categorical_column]\n\n# if flag == 'train':\n#     sales_price_label = num_df['SalePrice']\n\n# I want to Remove column year YearBuilt , YearRemodAdd , YrSold. I will add column stating how many years old house is\n\nnum_df['YearsOld'] = num_df.apply(lambda x : x['YrSold'] - x['YearBuilt'], axis = 1)\nnum_df.drop(['YrSold', 'YearBuilt', 'Id'], axis = 1, inplace = True)\n# else:\n#     num_df['YearsOld'] = num_df.apply(lambda x : x['YrSold'] - x['YearBuilt'], axis = 1)\n#     num_df.drop(['YrSold', 'YearBuilt', 'Id' ], axis = 1, inplace = True)\n\nOneHotEncoding_columns = ['LotShape','MSZoning', 'Street', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope','Neighborhood','Condition1', 'Condition2','BldgType',\n                         'HouseStyle', 'RoofMatl','Exterior1st', 'Exterior2nd' ,'Foundation','Heating', 'CentralAir','Functional','Electrical','MasVnrType',\n                         'GarageType', 'GarageFinish','PavedDrive','SaleType','SaleCondition','BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nlabel_encoding = [ 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond','HeatingQC','KitchenQual',\n                 'FireplaceQu', 'GarageQual','GarageCond' ]\n\nreplace = { 'Po':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}\ndelete_column = ['Alley', 'PoolQC', 'Fence', 'MiscFeature']\n\n#     fill_previous_value = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','GarageType', 'GarageFinish','GarageQual',\n#                            'GarageCond','FireplaceQu']\n#     fill_previous_value = [clm for clm in data.columns if data[clm].isna().sum()>0 ]\nfill_previous_value = label_encoding + OneHotEncoding_columns\n\ncat_df.drop(delete_column, inplace =True, axis = 1)\n\nfor nan_column in fill_previous_value:\n    temp = cat_df[nan_column].unique().copy()\n    temp = temp[~pd.isna(temp)]\n\n    cat_df[nan_column] = cat_df.apply(lambda x : func_na(x[nan_column], temp), axis = 1)\n\n# Now le\none_hot_df = cat_df[OneHotEncoding_columns]\nlabel_encod_df = cat_df[label_encoding]\n\n\n# encod = OneHotEncoder()\n\n# encod.fit(one_hot_df)\none_hot_trans_df = encod.transform(one_hot_df)\nfeature_name = encod.get_feature_names(OneHotEncoding_columns)\nlabel_encod_df.replace(replace, inplace=True)\n\n\nnum_pipeline = Pipeline([\n ('imputer', SimpleImputer(strategy=\"median\")),\n ('std_scaler', StandardScaler()),\n ])\nhousing_num_tr = num_pipeline.fit_transform(num_df)\n\nframe = [pd.DataFrame(one_hot_trans_df.toarray(), columns = feature_name), label_encod_df , pd.DataFrame(housing_num_tr, columns = num_df.columns)]\n\nprint(pd.DataFrame(one_hot_trans_df.toarray(), columns = feature_name).shape, label_encod_df.shape, pd.DataFrame(housing_num_tr).shape)\nresult = pd.concat(frame, axis = 1)\n","866948fb":"result.shape, result_train.shape","6d111c61":"# Let's truy to solve problem with neural network\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(result_train, sales_price_label, random_state = 42)","928dae0b":"from sklearn.ensemble import GradientBoostingRegressor\nreg= GradientBoostingRegressor(random_state=0)\nreg.fit(x_train, y_train)\npred = reg.predict(result)","e2d1378b":"# from sklearn.tree import DecisionTreeRegressor\n# lin_reg = DecisionTreeRegressor()\n# lin_reg.fit(result_train, sales_price_label)\n# pred = lin_reg.predict(result)","a7e9d99d":"\nx_train, x_valid, y_train, y_valid =        train_test_split(x_train_full, y_train_full)                                                            ","38fc5ae0":"subm = pd.DataFrame()\n\nsubm['Id'] = list(test['Id'])\nsubm['SalePrice'] = pred.tolist()","6228b0e0":"subm.to_csv('\/kaggle\/working\/Submission1.csv', index = False)","109cbe46":"As we can see fro the histogram above , some of the feature are skewed, and some are sparse.\nSo We nweed to transorm such kind of data , Because it is hard for a machine learning model to find pattern.","43da71a8":"### Data Exploration\n\n"}}