{"cell_type":{"0ba38767":"code","10c1ac85":"code","b84873f4":"code","17bb6679":"code","7c7e675b":"code","808decd8":"code","8077fd87":"code","ceea9c9d":"code","9dea2996":"code","898e9d1f":"code","73c569dd":"code","878a100f":"code","64f2e365":"code","684c6c88":"code","3571ad50":"code","d9cc0e17":"code","cbd3afa5":"code","9cb81413":"code","e19e6f87":"code","5536af92":"code","2f74a7a0":"markdown","393fe445":"markdown","4393236b":"markdown","6c4c1852":"markdown","d1f7bcae":"markdown","53a0f3fd":"markdown","aae2837b":"markdown","ff53e39a":"markdown","8aae563d":"markdown","4c182dfc":"markdown","c5eeffaf":"markdown","49d2180f":"markdown","c1b3cc18":"markdown","491e56b4":"markdown"},"source":{"0ba38767":"#Import the Packages\n\nimport torchvision\nimport torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms,models,datasets\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nfrom torch import optim\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nimport cv2, glob, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport os","10c1ac85":"#Defining the Directories\n\ndata_dir_Train = \"\/kaggle\/input\/intel-image-classification\/seg_train\"\ndata_dir_Test = \"\/kaggle\/input\/intel-image-classification\/seg_test\"\ndata_dir_pred = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\"\n\ntrain_data_dir = data_dir_Train + \"\/seg_train\"\ntest_data_dir = data_dir_Test + \"\/seg_test\/\"","b84873f4":"#Lets get the location of all the prediction files\npred_files = [os.path.join(data_dir_pred, f) for f in os.listdir(data_dir_pred)]\npred_files[:10]","17bb6679":"#Checking the number of Train Images\n\nfor i in os.listdir(train_data_dir):\n    new_loc= os.path.join(train_data_dir,i)\n    new= new_loc+ '\/*.jpg'\n    length= glob(new)\n    print(f'{i}:',len(length)) \n","7c7e675b":"#Checking the Number of Test Images for each class\n\nfor i in os.listdir(test_data_dir):\n    new_loc= os.path.join(test_data_dir,i)\n    new= new_loc+ '\/*.jpg'\n    length= glob(new)\n    print(f'{i}:',len(length)) ","808decd8":"#Getting the Classes and their meaning in a dictionary\nclasses= os.listdir(train_data_dir)\n#print(classes)\nclasses = {k:v for k , v in enumerate(sorted(classes))}\nclasses","8077fd87":"#Performing the Image Transformation and Data Augmentation on the Train Dataset and Transformation on Validation Dataset\n\nimport torchvision.transforms as transforms \nfrom torchvision.transforms import ToTensor,Normalize, RandomHorizontalFlip, Resize\n\n# convert data to a normalized torch.FloatTensor\ntransform = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(p=0.5), # randomly flip and rotate\n    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n    ])\n\n# Augmentation on test images not needed\ntransform_tests = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ])","ceea9c9d":"# ImageFloder function uses for make dataset by passing dir address as an argument\ntrain_data = torchvision.datasets.ImageFolder(root=train_data_dir,transform=transform)\ntest_data = torchvision.datasets.ImageFolder(root=test_data_dir,transform=transform_tests)\n\ntrn_dl = DataLoader(train_data,batch_size=32,drop_last=True,shuffle=True,num_workers=2)\nval_dl = DataLoader(test_data, batch_size =32, drop_last=True,shuffle=True,num_workers=2)\n\n","9dea2996":"im, label = train_data[1000]\nplt.imshow(im.permute(1,2,0).cpu())\nprint('Class:',classes[label])","898e9d1f":"im, label = train_data[5500]\nplt.imshow(im.permute(1,2,0).cpu())\nprint('Class:',classes[label])","73c569dd":"im, label = train_data[12000]\nplt.imshow(im.permute(1,2,0).cpu())\nprint('Class:',classes[label])","878a100f":"#Downloading the ResNet18 Model with their pretrained weights\n\nmodel = models.resnet18(pretrained=True)\nmodel.parameters","64f2e365":"#Defining the Model Function. Lets freeze all layers and change just a few layers to match our requirements\n\ndef get_model():\n    model = models.resnet18(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False     #Freezing all the layers and changing only the below layers\n    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n    model.fc = nn.Sequential(nn.Flatten(),\n    nn.Linear(512, 128),\n    nn.ReLU(),\n    nn.Dropout(0.2),\n    nn.Linear(128, 6))\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n    return model.to(device), loss_fn, optimizer","684c6c88":"#Creating the Utlity function to get the Losses and Accuracies for Train and Validation Dataset \n\ndef train_batch(x, y, model, opt, loss_fn):\n    prediction = model(x)\n    batch_loss = loss_fn(prediction, y)\n    batch_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return batch_loss.item()\n\n@torch.no_grad()\ndef accuracy(x, y, model):\n    model.eval()\n    prediction = model(x)\n    max_values, argmaxes = prediction.max(-1)\n    is_correct = argmaxes == y\n    return is_correct.cpu().numpy().tolist()\n\n@torch.no_grad()\ndef val_loss(x, y, model):\n    model.eval()\n    prediction = model(x)\n    val_loss = loss_fn(prediction, y)\n    return val_loss.item()","3571ad50":"#Initializing the Model, Loss Fuction and Optimizer to a Variable\n\nmodel, loss_fn, optimizer = get_model()","d9cc0e17":"# Start the Model Training and save the Losses and Accuracies of Both train and validation\n\ntrain_losses, train_accuracies = [], []\nval_losses, val_accuracies = [], []\nfor epoch in range(10):\n    print(epoch)\n    train_epoch_losses, train_epoch_accuracies = [], []\n    for ix, batch in enumerate(iter(trn_dl)):\n        x, y = batch\n        x, y= x.to(device), y.to(device)\n        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n        is_correct = accuracy(x, y, model)\n        train_epoch_accuracies.extend(is_correct)\n        train_epoch_losses.append(batch_loss)        \n    train_epoch_loss = np.array(train_epoch_losses).mean()\n    train_epoch_accuracy = np.mean(train_epoch_accuracies)        \n    print('Epoch:',epoch,'Train Loss:',train_epoch_loss,'Train Accuracy:',train_epoch_accuracy)\n\n    for ix, batch in enumerate(iter(val_dl)):\n        x, y = batch\n        x, y= x.to(device), y.to(device)\n        val_is_correct = accuracy(x, y, model)\n        validation_loss = val_loss(x, y, model)    \n        val_epoch_accuracy = np.mean(val_is_correct)\n\n    print('Epoch:',epoch,'Validation Loss:',validation_loss,'Validation Accuracy:',val_epoch_accuracy)\n\n    train_losses.append(train_epoch_loss)\n    train_accuracies.append(train_epoch_accuracy)\n    val_losses.append(validation_loss)\n    val_accuracies.append(val_epoch_accuracy)","cbd3afa5":"#Plotting the Losses and Accuracies\n\nepochs = np.arange(10)+1\nimport matplotlib.ticker as mtick\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\n%matplotlib inline\nplt.subplot(211)\nplt.plot(epochs, train_losses, 'bo', label='Training loss')\nplt.plot(epochs, val_losses, 'r', label='Validation loss')\nplt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\nplt.title('Training and validation loss with ResNet')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid('off')\nplt.show()\nplt.subplot(212)\nplt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\nplt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\nplt.title('Training and validation accuracy with ResNet')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n#plt.ylim(0.8,1)\nplt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \nplt.legend()\nplt.grid('off')\nplt.show()","9cb81413":"#Lets define the function to predict the images from prediction set\n\nfrom torch.autograd import Variable\n\ndef pred_class(img):\n    # transform images\n    img_tens = transform_tests(img)\n    # change image format (3,150,150) to (1,3,150,150) by help of unsqueeze function\n    # image needs to be in cuda before predition\n    img_im = img_tens.unsqueeze(0).cuda() \n    uinput = Variable(img_im)\n    uinput = uinput.to(device)\n    out = model(uinput)\n    # convert image to numpy format in cpu and snatching max prediction score class index\n    index = out.data.cpu().numpy().argmax()    \n    return index","e19e6f87":"#Prediction Results\n\nmodel.eval()\n\nplt.figure(figsize=(20,20))\nfor i, images in enumerate(pred_files):\n    # just want 25 images to print\n    if i > 24:break\n    img = Image.open(images)\n    index = pred_class(img)\n    plt.subplot(5,5,i+1)\n    plt.title(classes[index])\n    plt.axis('off')\n    plt.imshow(img)","5536af92":"torch.save(model.state_dict(),'model.pth')","2f74a7a0":"## <center> If you like this Notebook, Consider upvoting this Notebook! Thank you!! <\/center>","393fe445":"### Creating the Utlity Functions that helps in Training","4393236b":"In this Notebook, I am going to build a simple ResNet18 model and perform a few image augmentations on the train dataset.","6c4c1852":"## Image Predictions","d1f7bcae":"Let's check how many images are available for training in each class","53a0f3fd":"## Start the Training Process","aae2837b":"For doing the Image predictions, I am using this code from Sudhanshu which shows the prediction of images along with the actual image which looks clean!\n\nReference: https:\/\/www.kaggle.com\/billiemage\/pytorch-use-pretrained-model#Predictions-on-test-dataset\n\n","ff53e39a":"## <center> Welcome to my Notebook! <\/center>","8aae563d":"## Saving the Model","4c182dfc":"### Random Checking of Train Images","c5eeffaf":"#### <center> If you have any questions or suggestions, please feel free to add them to the comments :) <\/center>","49d2180f":"## Import the Packages","c1b3cc18":"## Building a ResNet Model With Data Augmentation","491e56b4":"There seems to almost similar number of images in each class for training. So there is no worry for class imbalance here."}}