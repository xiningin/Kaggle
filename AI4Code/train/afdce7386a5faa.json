{"cell_type":{"70531ad6":"code","876fe669":"code","8441344b":"code","c99fd87f":"code","60a4b932":"code","4e12dd81":"code","8151f902":"code","4b1e6351":"code","fb097718":"code","235ec109":"code","dbdd30d4":"code","d92c3bf5":"code","6ffd348f":"code","390cfbdb":"code","6c6fca5c":"code","89c52ada":"code","770b519f":"code","1f84bfb8":"code","31c35b67":"code","7f34fb78":"code","2a22d671":"code","1b517054":"code","374370bd":"code","1f5f23bf":"code","115456ec":"code","494056ec":"code","b8ac3c12":"code","71631a0c":"code","26ac1221":"code","d2e7a8a5":"code","8fac5a3f":"code","29ab3f34":"code","46d7a5ca":"code","7d7933be":"code","dd00719e":"code","9721b335":"code","8586b965":"code","188b25c6":"code","96329316":"code","320e121c":"code","050c0762":"code","8bb59dc7":"code","b5fe2f67":"code","f69d5205":"code","0809a56d":"code","7e967aec":"code","72d8a1aa":"code","92305b6c":"markdown"},"source":{"70531ad6":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","876fe669":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","8441344b":"train.shape,test.shape","c99fd87f":"train.head(6)","60a4b932":"test.head(6)","4e12dd81":"train.dtypes","8151f902":"train.columns[train.isnull().any()], test.columns[test.isnull().any()]","4b1e6351":"total = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data","fb097718":"total=test.isnull().sum().sort_values(ascending=False)\npercent=(test.isnull().sum()\/test.isnull().count()).sort_values(ascending=False)\nmissing_data=pd.concat([total,percent],axis=1,keys=['Total','Percent'])\nmissing_data","235ec109":"train=train.drop(['Ticket','Cabin'],axis=1)\ntest=test.drop(['Ticket','Cabin'],axis=1)","dbdd30d4":"combine=[train,test]\nfor dataset in combine:\n    dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\\.',expand=False)\npd.crosstab(train['Title'],train['Sex'])","d92c3bf5":"for dataset in combine:\n    dataset['Title']=dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\ntrain[['Title','Survived']].groupby(['Title'],as_index=False).mean()","6ffd348f":"title_mapping={'Mr':1,'Miss':2,'Mrs':3,'Master':4,'Rare':5}\nfor dataset in combine:\n    dataset['Title']=dataset['Title'].map(title_mapping)\n    dataset['Title']=dataset['Title'].fillna(0)\n       \ntrain.head(6)\n    ","390cfbdb":"train['Age']=train['Age'].fillna(train['Age'].median(skipna=True))\ntest['Age']=test['Age'].fillna(test['Age'].median(skipna=True))","6c6fca5c":"train['Age']=train['Age'].astype(int)\ntest['Age']=test['Age'].astype(int)","89c52ada":"train['AgeBand']=pd.cut(train['Age'],5)\ntrain[['AgeBand','Survived']].groupby(['AgeBand'],as_index=False).mean().sort_values(by='AgeBand',ascending=True)","770b519f":"combine=[train,test]\nfor dataset in combine:\n    dataset.loc[dataset['Age']<=16,'Age']=0\n    dataset.loc[(dataset['Age']>16)&(dataset['Age']<=32),'Age']=1\n    dataset.loc[(dataset['Age']>32)&(dataset['Age']<=48),'Age']=2\n    dataset.loc[(dataset['Age']>48)&(dataset['Age']<=64),'Age']=3\n    dataset.loc[(dataset['Age']>64),'Age']=4\n    \ntrain.head(6)","1f84bfb8":"train=train.drop(['AgeBand'],axis=1)\ncombine=[train,test]","31c35b67":"for dataset in combine:\n    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\n    \ntrain[['FamilySize','Survived']].groupby(['FamilySize'],as_index=False).mean().sort_values(by='Survived',ascending=False)\n    ","7f34fb78":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","2a22d671":"train = train.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest = test.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train, test]\n\ntrain.head()","1b517054":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(train['Embarked'].dropna().mode()[0])\n    \ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","374370bd":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","1f5f23bf":"test['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\ntest.head()","115456ec":"train['FareBand'] = pd.qcut(train['Fare'], 4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","494056ec":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)\ncombine = [train, test]\n    \ntrain.head(10)","b8ac3c12":"for dataset in combine:\n    dataset['Sex']=dataset['Sex'].map({'female':1,'male':0}).astype(int)\ntrain.head(10)","71631a0c":"plt.figure(figsize=(32,32)) \nsns.heatmap(train.corr(),vmin=0, annot=True, cbar=True, cmap=\"RdYlGn\")","26ac1221":"train=train.drop(['Name','PassengerId'],axis=1)\ntest=test.drop(['Name'],axis=1)","d2e7a8a5":"X_train=train.drop(['Survived'],axis=1)\nY_train=train.Survived\nX_test=test.drop('PassengerId',axis=1).copy()","8fac5a3f":"from sklearn.cross_validation import KFold,cross_val_score\nk_fold=KFold(len(Y_train),n_folds=10,shuffle=True,random_state=0)","29ab3f34":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier","46d7a5ca":"#svc\nsvc=SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","7d7933be":"#knn\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","dd00719e":"#Niave bayes\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","9721b335":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","8586b965":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","188b25c6":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","96329316":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred1 = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","320e121c":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN','Random Forest', 'Naive Bayes','Stochastic Gradient Decent', 'Linear SVC','Decision Tree'],\n    'Score': [acc_svc, acc_knn,acc_random_forest, acc_gaussian, acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","050c0762":"submission=pd.read_csv('..\/input\/gender_submission.csv')","8bb59dc7":"submission['Survived']= Y_pred1\nsubmission['PassengerId']=test['PassengerId']\npd.DataFrame(submission,columns=['PassengerId','Survived']).to_csv('randomforest.csv',index=False)\n","b5fe2f67":"scoring = 'accuracy'\nresults = cross_val_score(random_forest, X_train, Y_train, cv=k_fold, n_jobs=1, scoring=scoring)\nresults","f69d5205":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\"n_estimators\": [40,50,60],\n              \"max_depth\": [3, 5],\n              \"min_samples_split\": [5, 10],\n              \"min_samples_leaf\": [5, 6],\n              \"max_leaf_nodes\": [10, 15],\n              \"min_weight_fraction_leaf\": [0.1]}\nparam_grid","0809a56d":"grid_search = GridSearchCV(random_forest, param_grid=param_grid,scoring='accuracy',cv=k_fold,n_jobs=-1)\ngrid_search.fit(X_train, Y_train)","7e967aec":"print(grid_search.best_score_)\nprint(grid_search.best_params_)","72d8a1aa":"from xgboost import XGBClassifier\nxgb=XGBClassifier(max_depth=5, n_estimators=900, learning_rate=1,gamma=0,min_child_weight=2, reg_alpha=0.1,subsample=0.8,cv=k_fold)\nxgb.fit(X_train,Y_train)\nY_pred = xgb.predict(X_test)\nacc_xgb = round(xgb.score(X_train, Y_train) * 100, 2)\nacc_xgb","92305b6c":"**Please Upvote For Encouragement**"}}