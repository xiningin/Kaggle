{"cell_type":{"b46aa89e":"code","64503f2c":"code","97be0d91":"code","6fa3c686":"code","326ae0eb":"code","a8189b5c":"code","5dffa1a6":"code","ecbe578f":"code","b3d40706":"code","8fcd92ea":"code","a84139f9":"code","86b83aca":"markdown","c610c024":"markdown","701f4f62":"markdown","ed72a0db":"markdown","4639d172":"markdown","006d1e29":"markdown"},"source":{"b46aa89e":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","64503f2c":"data = pd.read_csv('..\/input\/memory-test-on-drugged-islanders-data\/Islander_data.csv')","97be0d91":"data","6fa3c686":"data.info()","326ae0eb":"def onehot_encode(df, column):\n    df = df.copy()\n    \n    dummies = pd.get_dummies(df[column], prefix=column)\n    \n    if len(df[column].unique()) == 2:\n        dummies = dummies.drop(dummies.columns[0], axis=1)\n        \n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    \n    return df","a8189b5c":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # One-hot encode categorical features\n    for column in ['first_name', 'last_name', 'Happy_Sad_group']:\n        df = onehot_encode(df, column=column)\n    \n    # Split df into X and y\n    y = df['Drug']\n    X = df.drop('Drug', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","5dffa1a6":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","ecbe578f":"X_train","b3d40706":"y_train.value_counts()","8fcd92ea":"models = {\n    \"                   Logistic Regression\": LogisticRegression(),\n    \"                   K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"                         Decision Tree\": DecisionTreeClassifier(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n    \"   Support Vector Machine (RBF Kernel)\": SVC(),\n    \"                        Neural Network\": MLPClassifier(),\n    \"                         Random Forest\": RandomForestClassifier(),\n    \"                     Gradient Boosting\": GradientBoostingClassifier(),\n    \"                               XGBoost\": XGBClassifier(eval_metric='mlogloss'),\n    \"                              LightGBM\": LGBMClassifier(),\n    \"                              CatBoost\": CatBoostClassifier(verbose=0)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","a84139f9":"for name, model in models.items():\n    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))","86b83aca":"# Training","c610c024":"# Preprocessing","701f4f62":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/IPH42lJCOLI","ed72a0db":"# Task for Today  \n\n***\n\n## Prescription Drug Type Prediction  \n\nGiven *data about subjects' performances on a memory test*, let's try to predict which **prescription drug** a given subject ingested.\n\nWe will use a variety of classification models to make our predictions.","4639d172":"# Getting Started","006d1e29":"# Results"}}