{"cell_type":{"6a1324de":"code","67a98533":"code","eedbeaaa":"code","e1e5e8b1":"code","d0492305":"code","65be3c78":"code","4a431431":"code","0aced8f9":"code","d323d972":"code","4ddcd50e":"code","01eb9fb0":"code","66889cea":"code","5bdc5c2e":"code","ea3edc68":"code","1136a0dd":"code","6c5bf36c":"code","fe0943dd":"code","71163da6":"code","d55bd35a":"code","583a0d47":"code","429b24c6":"code","9198119a":"code","8ac5457f":"code","0a9c5408":"code","06736f38":"code","8b2278aa":"code","8d21614b":"markdown"},"source":{"6a1324de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport random as rn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\n# plotly library\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold \nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import uniform\n\nimport itertools\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import np_utils\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n#from keras.layers import AvgPool2D, BatchNormalization, Reshape\nfrom keras.optimizers import Adadelta, RMSprop, Adam\nfrom keras.losses import categorical_crossentropy\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nimport tensorflow as tf\n\nimport os\nprint(os.listdir(\"..\/input\"))","67a98533":"img_rows, img_cols = 28, 28\nnp.random.seed(5)\n\ndef get_best_score(model):\n    \n    print(model.best_score_)    \n    print(model.best_params_)\n    print(model.best_estimator_)\n    \n    return model.best_score_\n\ndef print_validation_report(y_true, y_pred):\n    print(\"Classification Report\")\n    print(classification_report(y_true, y_pred))\n    acc_sc = accuracy_score(y_true, y_pred)\n    print(\"Accuracy : \"+ str(acc_sc))\n    \n    return acc_sc\n\ndef plot_confusion_matrix(y_true, y_pred):\n    mtx = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(8,8))\n    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n    #  square=True,\n    plt.ylabel('true label')\n    plt.xlabel('predicted label')\n    \ndef plot_history_loss_and_acc(history_keras_nn):\n\n    fig, axs = plt.subplots(1,2, figsize=(12,4))\n\n    axs[0].plot(history_keras_nn.history['loss'])\n    axs[0].plot(history_keras_nn.history['val_loss'])\n    axs[0].set_title('model loss')\n    axs[0].set_ylabel('loss')\n    axs[0].set_xlabel('epoch')\n    axs[0].legend(['train', 'validation'], loc='upper left')\n\n    axs[1].plot(history_keras_nn.history['acc'])\n    axs[1].plot(history_keras_nn.history['val_acc'])\n    axs[1].set_title('model accuracy')\n    axs[1].set_ylabel('accuracy')\n    axs[1].set_xlabel('epoch')\n    axs[1].legend(['train', 'validation'], loc='upper left')\n\n    plt.show()","eedbeaaa":"# read the data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ny = train[\"label\"]\nX = train.drop([\"label\"],axis = 1)\nX_test = test","e1e5e8b1":"# Normalization\nX = X\/255.0\nX_test = X_test\/255.0","d0492305":"# for best performance, especially of the NN classfiers,\n# set mode = \"commit\"\nmode = \"edit\"\nmode = \"commit\"\n#\n\nif mode == \"edit\" :\n    nr_samples = 1200\n\nif mode == \"commit\" :    \n    nr_samples = 30000\n\ny_train=y[:nr_samples]\nX_train=X[:nr_samples]\nstart_ix_val = nr_samples \nend_ix_val = nr_samples + int(nr_samples\/3)\ny_val=y[start_ix_val:end_ix_val]\nX_val=X[start_ix_val:end_ix_val]\n\nprint(\"nr_samples train data:\", nr_samples)\nprint(\"start_ix_val:\", start_ix_val)\nprint(\"end_ix_val:\", end_ix_val)","65be3c78":"#  print first five samples\nfig, axs = plt.subplots(1, 5, sharex=True, sharey=True, figsize=(10,6))\naxs = axs.flatten()\nfor i in range(0,5):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[i].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[i].set_title(y[i])\nplt.tight_layout()    \n","4a431431":"fig, ax = plt.subplots(figsize=(8,5))\ng = sns.countplot(y)","0aced8f9":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nli_idxs = []\nfor i in range(10):\n    for nr in range(10):\n        ix = y[y==nr].index[i]\n        li_idxs.append(ix) \n        \nfig, axs = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(10,12))\naxs = axs.flatten()\nfor n, i in enumerate(li_idxs):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[n].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[n].set_title(y[i])\nplt.tight_layout() ","d323d972":"# NN Classifiers with Keras\ny_train = to_categorical(y_train, 10)\ny_val_10 = to_categorical(y_val, 10)","4ddcd50e":"# Fully-Connected Neural Networks\ndef dense_model_0():\n    model = Sequential()\n    model.add(Dense(10, input_dim=784, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\nmodel_dense_0 = dense_model_0()\nmodel_dense_0.summary()","01eb9fb0":"batchsize = int(nr_samples\/15) \nmodel_dense_0.fit(X_train, y_train, epochs=50, batch_size=batchsize)\npred_val_dense0 = model_dense_0.predict_classes(X_val)\nacc_fc0 = print_validation_report(y_val, pred_val_dense0)","66889cea":"acc_fc0 = print_validation_report(y_val, pred_val_dense0)","5bdc5c2e":"plot_confusion_matrix(y_val, pred_val_dense0)","ea3edc68":"# 1 hidden layer\ndef dense_model_1():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\nmodel_dense_1 = dense_model_1()\nmodel_dense_1.summary()\nhistory_dense_1 = model_dense_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), epochs=50, batch_size=batchsize)\n","1136a0dd":"plot_history_loss_and_acc(history_dense_1)","6c5bf36c":"pred_val_dense1 = model_dense_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense1)\nprint(classification_report(y_val, pred_val_dense1))\nacc_fc1 = accuracy_score(y_val, pred_val_dense1)\nprint(acc_fc1)","fe0943dd":"# 2 hidden layers\ndef dense_model_2():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(200, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n# 3 hidden layers\ndef dense_model_3():\n    \n    model = Sequential()  \n    model.add(Dense(100, activation='relu', input_dim=784))\n    model.add(Dense(200, activation='relu')) \n    model.add(Dense(100, activation='relu')) \n    model.add(Dense(10, activation='softmax'))\n         \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #model.compile(optimizer=RMSprop(lr=0.001),\n    #         loss='categorical_crossentropy',\n    #         metrics=['accuracy'])\n    \n    return model\n","71163da6":"# Convolutional Neural Networks, CNN\n\nX_train.shape","d55bd35a":"X_train = X_train.values.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_val = X_val.values.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\ninput_shape = (img_rows, img_cols, 1)","583a0d47":"batchsize = 128\nepochs = 12\nactivation = 'relu'\nadadelta = Adadelta()\nloss = categorical_crossentropy\n\ndef cnn_model_1(activation):\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n    \n    model.add(Conv2D(64, (3, 3), activation=activation))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Flatten())\n\n    model.add(Dense(128, activation=activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss=loss, optimizer=adadelta, metrics=['accuracy'])\n\n    return model","429b24c6":"model_cnn_1 = cnn_model_1(activation)\nmodel_cnn_1.summary()","9198119a":"#model_cnn_1.fit(X_train, y_train, batch_size=batchsize, epochs=epochs, verbose=1)\nhistory_cnn_1 = model_cnn_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                   epochs=epochs, batch_size=batchsize, verbose=1)","8ac5457f":"plot_history_loss_and_acc(history_cnn_1)","0a9c5408":"pred_val_cnn1 = model_cnn_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_cnn1)\nprint(classification_report(y_val, pred_val_cnn1))\nacc_cnn1 = accuracy_score(y_val, pred_val_cnn1)\nprint(acc_cnn1)","06736f38":"# CNN model 2\n\nbatch_size=90\nepochs=30\ndef cnn_model_2(optimizer,loss):\n\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding = 'Same', activation=\"relu\", input_shape=input_shape ))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation=activation))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy']) \n\n    return model","8b2278aa":"# predictions \nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nif mode == \"edit\" :\n    X = X[:nr_samples\/\/2]\n    y = y[:nr_samples\/\/2]\n    X_test = X_test[:nr_samples\/\/2]\n    sample_submission = sample_submission[:nr_samples\/\/2]\n\n# reshape for CNN\nX = X.values.reshape(X.shape[0], img_rows, img_cols, 1)\nX_test = X_test.values.reshape(X_test.shape[0], img_rows, img_cols, 1)\ny = to_categorical(y, 10)\n\nbatchsize = 128\nepochs = 12\nmodel_cnn_1 = cnn_model_1('relu')\nmodel_cnn_1.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)\n\npred_test_cnn_1 = model_cnn_1.predict(X_test)\npred_test_cnn_1 = np.argmax(pred_test_cnn_1,axis=1)\nresult_cnn_1 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_1})\nresult_cnn_1.to_csv(\"subm_cnn_1.csv\",index=False)\n","8d21614b":"# CNN model 1\nConv2D (32, (3, 3)) \n\nConv2D (64, (3, 3))\n\nPooling2D (2,2)\n\nDropout (0.25) Flatten\n\nDense(128, relu)\n\nDropout (0.5)\n\nDense(10, softmax)\n"}}