{"cell_type":{"21494fad":"code","92634146":"code","38fc92ce":"code","0d9be4ca":"code","f69e7801":"code","ce5d44e6":"code","37399ef2":"code","edf53dc2":"code","5267ceb1":"code","f3357666":"code","413c6aa5":"code","9fd6d636":"code","b86ba6ae":"code","fe32bf76":"code","5d27ea0b":"code","06f1a3cd":"code","0cec57ad":"code","616a4fc8":"code","b486f2c9":"code","ae6d8dec":"code","c76feebe":"code","61148d50":"code","7738bae4":"code","97058a3e":"code","01d16a8b":"code","f7435bc2":"code","2f795648":"code","dda33ba5":"code","706f5456":"code","feb4e6ac":"code","f35f191f":"code","dde7f577":"markdown","fa51f69a":"markdown","70855d04":"markdown","1ed41df6":"markdown","8758d6ad":"markdown","fd205440":"markdown","b06c0353":"markdown","22098584":"markdown","1631aaf6":"markdown","e486964b":"markdown","5058c2de":"markdown","14d22d1b":"markdown","be8f4846":"markdown","a66e0ef7":"markdown","718184f3":"markdown","eb5573f4":"markdown","7d552a66":"markdown","709819c8":"markdown","0da5fc40":"markdown","9f6e6788":"markdown"},"source":{"21494fad":"import numpy as np\nimport pandas as pd\nimport seaborn as sns \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport pandas_profiling as pp","92634146":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38fc92ce":"df = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\")","0d9be4ca":"pp.ProfileReport(df)","f69e7801":"df = df.drop('Unnamed: 0', axis=1)","ce5d44e6":"df","37399ef2":"import plotly.express as px\n#conventional = df[df['type'] == 'conventional']\n#organic = df[df['type'] == 'organic']\n\nfig = px.histogram(df, x='AveragePrice', color='type',\n                   marginal='box', # or violin, rug\n                   hover_data=df.columns)\n\n\nfig.show()","edf53dc2":"fig = px.box(df, x='region', y='AveragePrice')\nfig.show()","5267ceb1":"corr = df.corr()\ncorr\n\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 10))\nax.set_title('Correlation Matrix', fontsize=16)\n\nsns.heatmap(corr, vmin=-1, vmax=1, cmap='viridis', annot=True)","f3357666":"df.isnull().any()","413c6aa5":"df.duplicated().any()","9fd6d636":"df","b86ba6ae":"df1 = df.copy()\n\n#Introducing new feature = 'season'\n\n\ndf1['Date'] = pd.to_datetime(df1['Date'])\ndf1['month'] = df1['Date'].dt.month\n\nconditions = [(df1['month'].between(3,5,inclusive=True)),\n           (df1['month'].between(6,8,inclusive=True)),\n           (df1['month'].between(9,11,inclusive=True)),\n           (df1['month'].between(12,2,inclusive=True))]\n\nvalues = [0,1,2,3]\n#spring = 0, summer = 1, fall = 2, winter = 3\ndf1['seasons'] = np.select(conditions, values)\n\n\n#encoding labels for 'type'\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf1['type'] = le.fit_transform(df1['type'])\n\n# and region (One Hot Encoding instead of labelizing)\nohe = pd.get_dummies(data=df1, columns=['region'])\n\n\nX = ohe.drop(['AveragePrice','Date','4046','4225','4770','Small Bags','Large Bags','XLarge Bags'], axis=1)\ny = df1['AveragePrice']","fe32bf76":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","5d27ea0b":"X_train","06f1a3cd":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\npipe0 = Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())])\npipe0.fit(X_train, y_train)\ny_pred0 = pipe0.predict(X_test)\nr2_score(y_test, y_pred0)","0cec57ad":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\npipe = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestRegressor())])\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nr2_score(y_test, y_pred)","616a4fc8":"from xgboost import XGBRegressor\n\npipe2 = Pipeline([('scaler', StandardScaler()), ('xgb', XGBRegressor())])\npipe2.fit(X_train, y_train)\ny_pred2 = pipe2.predict(X_test)\nr2_score(y_test, y_pred2)","b486f2c9":"pd.DataFrame(pipe2['xgb'].feature_importances_, index=X_train.columns, columns=['Feature Importances'])","ae6d8dec":"from sklearn.decomposition import PCA\npca = PCA(n_components=6)\n\nX_train_cut, X_test_cut, y_train_cut, y_test_cut = train_test_split(pca.fit_transform(X), y, test_size=0.33, random_state=0)\n\n\nfrom xgboost import XGBRegressor\n\npipe3 = Pipeline([('scaler', StandardScaler()), ('xgb', XGBRegressor())])\npipe3.fit(X_train_cut, y_train_cut)\ny_pred3 = pipe3.predict(X_test_cut)\nr2_score(y_test_cut, y_pred3)","c76feebe":"df = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\")","61148d50":"df2 = df[df['region'] == 'California'].drop(['Date','region'], axis=1)\ndf2 = df2[df['type'] == 'organic']","7738bae4":"from scipy import stats\n\nX_lin = df2['year'].reset_index(drop=True)\ny_lin = df2['AveragePrice'].reset_index(drop=True)\n\n\nslope, intercept, r, p, std_err = stats.linregress(X_lin, y_lin) # scipy\n\ndef prediction(x):\n  return slope * x + intercept\n\nname = 'Avg. Avocado price (organic) in 2019'\nmd = list(map(prediction, X_lin)) # scipy\n\nX_pred_lin = 2019\ny_pred_lin = prediction(X_pred_lin)\n\nprint('Predicted avicado price in California in 2019 is: %f USD' % y_pred_lin)\n\nX_lin2 = X_lin.append(pd.Series(X_pred_lin))\ny_lin2 = y_lin.append(pd.Series(y_pred_lin))\nmd2 = list(map(prediction, X_lin2)) \n\nplt.scatter(X_lin2, y_lin2) # Scatter Plot\nplt.plot(X_lin2, md2, color='green')\nplt.xticks(np.arange(min(X_lin2), max(X_lin2+1), 1.0))\nplt.show()\n\n#plt.ylim(ymin=0) # starts at zero\n#plt.legend(['Model Prediction using Linear Regression', 'Avocado Prices (2015-2018)'])\n#plt.show()","97058a3e":"#pip install fbprophet","01d16a8b":"from fbprophet import Prophet \nfrom fbprophet.plot import add_changepoints_to_plot","f7435bc2":"df = df[df['region'] == 'California']\ndf['Date'] = df['Date'].str[:-3] \ndf = df[df['type'] == 'organic']","2f795648":"agg = {'AveragePrice': 'mean'}\ndata = df.groupby(df['Date']).aggregate(agg).reset_index()\ndata.head()","dda33ba5":"df_ts = pd.DataFrame() \ndf_ts['ds'] = pd.to_datetime(data['Date']) \ndf_ts['y'] = data['AveragePrice'] \ndf_ts.head()","706f5456":"m = Prophet(yearly_seasonality=True, \\\n            daily_seasonality=False, weekly_seasonality=False) \nm.fit(df_ts)\nfuture = m.make_future_dataframe(periods=12*5, freq='M')","feb4e6ac":"forecast = m.predict(future) \nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'trend', 'trend_lower', 'trend_upper']].tail()","f35f191f":"fig = m.plot(forecast) \nfig.show()\na = add_changepoints_to_plot(fig.gca(), m, forecast)","dde7f577":"# Modeling","fa51f69a":"# Avocado price prediction\n\n* **Task type:** regression\n* **Models used:** linear, XGB regression\n* **Other methods used:** PCA, FB Prophet, Profile Report","70855d04":"<img src = \"https:\/\/img.freepik.com\/free-vector\/avocado-seamless-pattern-whole-d_127928-108.jpg?size=626&ext=jpg\" width=\"300\" height=\"50\">","1ed41df6":"## Using FB Prophet","8758d6ad":"# Prediction for the next year","fd205440":"**So, by reducing the number of features we sacrifice ~15% R2. Luckily, the dataset is not that huge and we have the option to stay with the initial number of feature. Anyway, PCA is a very good exercise.**","b06c0353":"**Checking for missing & duplicated data.**","22098584":"## Building a simple linear model","1631aaf6":"**So, on average, organic avocados are more expensive (as expected).**\n\n**Let's also check whether geography influences the price.**","e486964b":"# Data overview","5058c2de":"**The forecasts are as follows:**","14d22d1b":"**Correlation matrix**","be8f4846":"**Anyway, there's more to explore on this market. This was just an initial deepdive into the analysis.**","a66e0ef7":"**For this part of the notebook, I will use 2 techniques:**\n\n1. Build a simple linear model using scipy.\n2. Use FB prophet package and see what the result will be.","718184f3":"**We have a plenty of features now, due to the presence of dummies. Let's see if we can do dimensiality reduction and preserve the R2 score.**","eb5573f4":"**Apparently, the best model is the one with boosting (XGB).**","7d552a66":"**Interesting. So, the Prophet suggests the price of around $ 1.75 in 2019, and then the price for organic avocados will go up in California.**","709819c8":"**So, avocado type accounts for 86% of the price prediction.**\n\n**PLEASE NOTE! This is a historical analysis, and does not actually produce real-life value for the avocado market analysis. A predictory model will be built further on.**","0da5fc40":"# Data preprocessing","9f6e6788":"**As there are two types of avocados, let's see the price distribution of each one.**"}}