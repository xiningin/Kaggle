{"cell_type":{"13aa5b74":"code","533ab6cb":"code","cd03d3db":"code","1259d6c0":"code","2d832a54":"code","e8863aa6":"code","89c37c93":"code","cc88c7fa":"code","ee70712c":"code","03149649":"code","3da07768":"code","e110900c":"code","d6242db0":"code","d56334d0":"code","3b97ae20":"markdown","d223b361":"markdown","7028d280":"markdown","9ebc4117":"markdown","395a4409":"markdown","275b8687":"markdown","0210c184":"markdown","21a9b50f":"markdown","c91b3b5b":"markdown","00592f91":"markdown","204b943b":"markdown","016566c7":"markdown","c0eaaba0":"markdown","31292b17":"markdown","4f2eaa40":"markdown","d81eec1e":"markdown"},"source":{"13aa5b74":"import numpy\nimport pandas\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","533ab6cb":"dataframe = pandas.read_excel('..\/input\/retail-trade-report-department-stores\/retail-trade-report-department-stores.xls')\nprint(dataframe.head())","cd03d3db":"dataframe.drop(dataframe.columns[0], axis=1, inplace=True)\nprint(dataframe.head())","1259d6c0":"plt.figure(figsize=(18,5))\nplt.title('DEPARTMENT STORE SALE SALES')\nplt.xlabel('periods')\nplt.ylabel('estimated retail sales (in millions)')\nplt.plot(dataframe, 'k-')\nplt.grid()\nplt.show()","2d832a54":"numpy.random.seed(7)","e8863aa6":"dataset = dataframe.values\ndataset = dataset.astype('float32')\nprint(dataset[:5])","89c37c93":"scaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\nprint(dataset[:5])","cc88c7fa":"train_size = int(len(dataset) * 0.70)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]","ee70712c":"def create_dataset(dataset, look_back):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return numpy.array(dataX), numpy.array(dataY)","03149649":"look_back = 20\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","3da07768":"model = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory = model.fit(trainX, trainY, epochs=200, batch_size=1, verbose=2)","e110900c":"plt.figure(figsize=(15,7))\nplt.plot(history.history['loss'], 'k')\nplt.title('MODEL LOSS')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.grid()\nplt.show()","d6242db0":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\ntrainPredict = scaler.inverse_transform(trainPredict)\ntestPredict = scaler.inverse_transform(testPredict)","d56334d0":"trainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\nplt.figure(figsize=(18,5))\nplt.plot(scaler.inverse_transform(dataset), 'k')\nplt.plot(trainPredictPlot, 'r')\nplt.plot(testPredictPlot, 'g')\nplt.title('DEPARTMENT STORE SALE SALES')\nplt.ylabel('estimated retail sales (in millions)')\nplt.xlabel('periods')\nplt.grid()\nplt.show()","3b97ae20":"# 4. VISUALIZE DATA\nFor easier understanding of our dataset, we can build the plot. We set the size of our picture for our consideration, set the title of the plot and name the OX and OY axises. After that we build our plot, making it black straight line. The plot will have the grid turned on.","d223b361":"We can write a simple function to transform our single column of data into a n-column dataset: first column will have value of money and the next columns will also have value of money, but in next (n-1) periods.\nThe function takes two arguments: an **initial dataset** that is a NumPy array that we want to convert to a new dataset and a **look_back**, which is the number of previous time steps to use as input variables to predict the next time period.","7028d280":"Finally, we can generate predictions using train and test data to get a visual representation of the quality of the model. Because of how the dataset was prepared, we have to shift the predictions so that they are aligned on the X-axis with the original dataset. The original dataset is displayed in black, predictions for the training dataset in red, and predictions for the test dataset in green. \n\nWe can see that the model did an excellent job of forecasting both the train and the test dataset!","9ebc4117":"LSTMs are sensitive to input data scale, especially when sigmoid (by default) or tanh activation functions are used. Therefore, it is necessary to normalize data in a range from 0 to 1. We can easily make it using the **MinMaxScaler()**.\n\nWe can print first 5 values to make sure that everything was made right.","395a4409":"Also, we should split the dataset into train and test data. Let it will be **70%:30%** respectively. You can also try it with another ratio, like 60%:40%, 80%:20%, 90%:10% and so on.  \n","275b8687":"# 2. LIBRARIES\nFirstly, let think, which libraries we should use to make our project right:\n1. [NumPy](https:\/\/numpy.org\/) - for matrices and arrays, has a lot of math functions. \n2. [Pandas](https:\/\/pandas.pydata.org\/) - for data manipulation and analysis \n3. [Matplotlib](https:\/\/matplotlib.org\/) - for visualizations, like plots\n4. [Keras](https:\/\/keras.io\/) - for making neural networks (NN)\n5. [Sklearn](https:\/\/scikit-learn.org\/stable\/) - for data analysis","0210c184":"# 3. READ DATA\nAfter that, we should read data from out dataset. As I said earlier, I use Sales from the Retail Trade and Food Services Report from the US Census. We read it with the Pandas Library function **read_excel()**, because our data was in the Excel format. Function **head()** returns top 5 records from your dataset\n\n**In case you don't know how to add data to your kaggle kernel:**\n1. Press \"Add Data\" on the right top corner.\n2. Search nessesary data on the search line or add yours from \"Your Datasets\" button.\n3. After addind data you will see the notification in the left down corner of your kaggle kernel (notebook).\n4. You can see and copy the path to your data clicking the dropdown \"Data\" in the right top corner, near button \"Add data\".","21a9b50f":"# 1. LSTM NETWORKS\nLong short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. LSTM was proposed by [Sepp Hochreiter and J\u00fcrgen Schmidhuber](https:\/\/papers.nips.cc\/paper\/1996\/file\/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf) (1997).\n\n\nI will write some information for easier understanding, found in this source: [Understanding LSTM Networks](https:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/).\nLSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn. All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.","c91b3b5b":"As we can see, we have 2 columns here - date and value of money in millions. The period of the records is one month, from January,1992 to October, 2016.\nAs column with date is just for information purposes, we can delete it without regrets. After that we will have only one column with value of money.","00592f91":"# 6. TRAIN LSTM NEURAL NETWORK\nThe main part of this notebook!\n\nWe will make LSTM with 4 blocks inside and 1 output outside. \nI set **200 epochs**, but you can try on your own to change this parameter. Also, the loss function is calculated like **Mean Squared Error (MSE)**, I think, it is one of the most popular losses for such things.\n\nOnce the model is created, you can config the model with losses and metrics with **model.compile()**, train the model with **model.fit()**.\n\n","204b943b":"# 5. WORK WITH DATA\nFirstry, let initialize random number generator to ensure our results are reproducible.","016566c7":"Then we can make the NumPy array from the Pandas dataframe and convert integer values to floating point values, which are more suitable for working with a neural network. \n\nWe can print first 5 values to make sure that everything was made right.","c0eaaba0":"# 7. BUILD PLOT OF TRAINING HISTORY\nAs I said earlier, visualizing helps you to understand your data. Let's build loss history (for each epoch of training)","31292b17":"Next, we use this function to prepare datasets for train and for test neural network and transform the data into a structure corresponding to the input of the neural network. \n\nI set **look_back = 20,** because I had some tries before submiting it. For this dataset this parameter is better to be equal 20, than, as example, 1 or 10, but, maybe, for other datasets you should try on your own to change this parameter as you chagind the number of epochs to make your model better.","4f2eaa40":" # FORECASTING RETAIL TRADE REPORT DEPARTMENT STORES WITH LSTM NETWORKS \nIn this my first public notebook we will be looking at data from Sales from the Retail Trade and Food Services Report from the US Census and forecasting it with the help of LSTM Networks.\n\nThis dataset only covers Department Stores, though the report covers a wide range of retail types. The complete Retail Trade data is available in the [Census Account](https:\/\/data.world\/uscensusbureau\/monthly-retail-trade-survey).\nI have found it on this [website](https:\/\/data.world\/retail\/department-store-sales). I'm very thanful to them for sharing this data. I could't find it on [kaggle.com](https:\/\/www.kaggle.com\/), so I decided to upload this dataset by my own. [Here](https:\/\/www.kaggle.com\/maricinnamon\/retail-trade-report-department-stores) you can find it. \n\nAlso, I'm thanful to authors of this [book](https:\/\/kpfu.ru\/staff_files\/F1493580427\/NejronGafGal.pdf) for providing some important information about working with keras models.\n\nSo, let's start!","d81eec1e":"# 8. TEST LSTM NEURAL NETWORK\nAfter the model has been trained, we can evaluate the quality of the model in train and on test datasets. Note that we are inverting the predictions to ensure that the result is output in the same units as the original data.\nIt's time to do the model prediction with **model.predict()** on train and test set."}}