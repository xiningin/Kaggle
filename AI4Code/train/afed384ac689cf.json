{"cell_type":{"af2a6ac3":"code","e5dde87a":"code","e2655f38":"code","04d4a0a3":"code","08bae77a":"code","7a0e36d9":"code","2423717b":"code","492dbbf8":"code","2fed2da0":"code","bb25c143":"code","2fe1c053":"code","d8ef286a":"code","d89c7c04":"code","d4468d32":"code","18fb4bdb":"code","e9d8b116":"code","ed482582":"code","cb56152d":"code","bcdc9d08":"code","90a9a3f3":"code","1e26f32a":"code","f809749c":"code","2ca6c0f2":"code","653461bc":"code","f005f391":"code","584b574c":"code","172e61a3":"code","ee3259ec":"code","d7402409":"code","47bf673e":"code","decc1cb6":"code","cedb2eba":"code","47000e92":"code","4780364c":"code","df2f83e6":"code","63323583":"code","06dc1778":"code","a57238bf":"code","676a8731":"code","ceeb8700":"code","7e0de363":"code","20dea49d":"code","506e89e9":"code","d7d51af6":"code","ba7e7dfb":"code","cfc98834":"code","7c506333":"code","cda63239":"code","c73c90c4":"code","a0c1b5cb":"code","d87e7c29":"code","0d68757c":"code","949f3815":"code","81cc6a7f":"code","c4c47968":"code","94c61dce":"code","13a5a4ff":"code","0aeb2756":"code","9f99b5da":"code","a88c0c53":"code","b0349951":"code","d8d0a33a":"code","bbc3f395":"code","233efe3c":"code","49f7cf96":"code","14899dff":"code","2834dc03":"code","1dd49ab4":"code","0ec81b7d":"code","f3000dd6":"code","f0f5104f":"code","681dc5b7":"code","33ddd64a":"code","b2b7c0b8":"code","cdb50073":"code","998b83dd":"code","f5417661":"code","c20963e6":"code","9185443e":"code","157eaade":"code","6c210425":"code","5aae38a0":"code","aedd52cb":"markdown","35eca90c":"markdown","80c9b48d":"markdown","6e767498":"markdown","bb2ee491":"markdown","83ea196f":"markdown","18c78a9d":"markdown"},"source":{"af2a6ac3":"import sys\npackage_dir = '..\/input\/autokeras-april-2021'\nsys.path.insert(0, package_dir)","e5dde87a":"import os\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport autokeras as ak","e2655f38":"df = pd.read_csv(\"..\/input\/jigsaw-score-augumentation\/jigsaw_train_hate_annotationprob.csv\",index_col=0)\n","04d4a0a3":"df.describe()","08bae77a":"ruddit_df = pd.read_csv(\"..\/input\/ruddit-jigsaw-dataset\/Dataset\/ruddit_with_text.csv\",index_col=0)\n","7a0e36d9":"ruddit_df.head()","2423717b":"ruddit_df.describe()","492dbbf8":"df['target']=df['proposed_score3']+0.1*df['offensive_agreement_rating']","2fed2da0":"df= df[['text', 'target']]","bb25c143":"#df[\"target\"]=df['target']+0.066618","2fe1c053":"# ruddit_df['offensiveness_score']=ruddit_df['offensiveness_score']+0.889000\n\n# ruddit_df['offensiveness_score']=ruddit_df['offensiveness_score']*3.1091","d8ef286a":"ruddit_df.rename(columns={'txt':'text','offensiveness_score':'target'},inplace=True)\n","d89c7c04":"\nruddit_df= ruddit_df[['text', 'target']]","d4468d32":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(df, test_size=0.10)\n#valid, test = train_test_split(valid, test_size=0.3)","18fb4bdb":"df_test=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\",index_col=0)","e9d8b116":"comments_to_score=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\",index_col=0)","ed482582":"X_less_toxic =df_test.less_toxic.values\nX_more_toxic =df_test.more_toxic.values\nX_comments_to_score =comments_to_score.text.values","cb56152d":"train_data = train['text'].values\ntrain_target = train['target'].values\n\nvalid_data = valid['text'].values\nvalid_target = valid['target'].values\n\nprint(train_data.shape, train_target.shape)\nprint(valid_data.shape, valid_target.shape)","bcdc9d08":"input_node = ak.TextInput()\noutput_node = ak.TextToIntSequence()(input_node)\noutput_node = ak.Embedding()(output_node)\n# Use separable Conv layers in Keras.\noutput_node = ak.ConvBlock(separable=True)(output_node)\n#output_node = ak.ConvBlock(separable=True)(output_node)\noutput_node = ak.RegressionHead()(output_node)\nreg = ak.AutoModel(\n    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n)\nreg.fit(train_data, train_target, epochs=5,validation_split=0.15)","90a9a3f3":"#preds = reg.predict(X_less_toxic).squeeze().tolist()\n#p1 = predictor.predict(X_less_toxic)\np1 = reg.predict(X_less_toxic).squeeze().tolist()\n#p2 = predictor.predict(X_more_toxic)\np2 = reg.predict(X_more_toxic).squeeze().tolist()\n","1e26f32a":"def compare(p1,p2):\n    z=0\n    k=0\n    n=len(p1)\n    for i in range(len(p1)):\n        if p1[i]< p2[i]:\n            z=z+1\n        else:\n            k=k+1\n            #print('nu')\n    print(z\/n)\n    return z\/n","f809749c":"# Validation Accuracy\ncompare(p1,p2)","2ca6c0f2":"df_test['score_max']=p2\ndf_test['score_min']=p1\ndf_test['diff']=df_test['score_max']-df_test['score_min']\n\n","653461bc":"def correctie(diff):\n    if diff<0:\n        return diff+0.01\n    else:\n        return 0","f005f391":"df_test['err_corr']=df_test['diff'].apply(lambda x: correctie(x))","584b574c":"df_test['err_corr'].describe()","172e61a3":"train_data1 = df_test['more_toxic'].values\ntrain_target1 = df_test['err_corr'].values\n","ee3259ec":"# Initialize the text regressor.\n#reg1 = ak.TextRegressor(overwrite=True, max_trials=10)  # It tries 10 different models.\nreg1 = ak.AutoModel(inputs=input_node, outputs=output_node, overwrite=True, max_trials=2)\nreg1.fit(train_data1, train_target1, epochs=5,validation_split=0.15)","d7402409":"p3[0]","47bf673e":"p3 = reg1.predict(X_less_toxic).squeeze().tolist()\n#p2 = predictor.predict(X_more_toxic)\np4 = reg1.predict(X_more_toxic).squeeze().tolist()","decc1cb6":"compare(p3,p4)","cedb2eba":"compare(np.asarray(p1)-np.asarray(p3),np.asarray(p2)-np.asarray(p4))","47000e92":"compare(np.asarray(p1)+np.asarray(p3),np.asarray(p2)+np.asarray(p4))","4780364c":"compare(np.asarray(p1)+np.asarray(p3),np.asarray(p2))","df2f83e6":"compare(p1+p3,p2+p4)","63323583":"df_test['score_max']=np.asarray(p2)+np.asarray(p4)\ndf_test['score_min']=np.asarray(p1)+np.asarray(p3)\ndf_test['diff']=df_test['score_max']-df_test['score_min']","06dc1778":"df_test['err_corr']=df_test['diff'].apply(lambda x: correctie(x))","a57238bf":"df_test['err_corr'].describe()","676a8731":"train_data2 = df_test['less_toxic'].values\ntrain_target2 = -1*df_test['err_corr'].values\n","ceeb8700":"reg2 = ak.AutoModel(\n    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n)\nreg2.fit(train_data2, train_target2, epochs=5,validation_split=0.15)","7e0de363":"p5 = reg2.predict(X_less_toxic).squeeze().tolist()\n#p2 = predictor.predict(X_more_toxic)\np6 = reg2.predict(X_more_toxic).squeeze().tolist()","20dea49d":"compare(p5,p6)","506e89e9":"compare(np.asarray(p1)+np.asarray(p5),np.asarray(p2)+np.asarray(p6))","d7d51af6":"compare(np.asarray(p1)+np.asarray(p3)+np.asarray(p5),np.asarray(p2)+np.asarray(p4)+np.asarray(p6))","ba7e7dfb":"compare(np.asarray(p1)+np.asarray(p3),np.asarray(p2)+np.asarray(p6))","cfc98834":"df_test.head()","7c506333":"df_test['score_max']=np.asarray(p1)+np.asarray(p3)\ndf_test['score_min']=np.asarray(p2)+np.asarray(p6)\ndf_test['diff']=df_test['score_max']-df_test['score_min']","cda63239":"df_test['err_corr']=df_test['diff'].apply(lambda x: correctie(x))","c73c90c4":"train_data3 = df_test['less_toxic'].values\ntrain_target3 = -1*df_test['err_corr'].values","a0c1b5cb":"df_test['err_corr'].describe()","d87e7c29":"reg2 = ak.AutoModel(\n    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n)\nreg2.fit(train_data3, train_target3, epochs=5,validation_split=0.15)","0d68757c":"p7 = reg2.predict(X_less_toxic).squeeze().tolist()\n#p2 = predictor.predict(X_more_toxic)\np8 = reg2.predict(X_more_toxic).squeeze().tolist()","949f3815":"compare(p7,p8)","81cc6a7f":"compare(np.asarray(p1)+np.asarray(p3),np.asarray(p2)+np.asarray(p6)+np.asarray(p8))","c4c47968":"df_test['score_max']=np.asarray(p2)+np.asarray(p6)+np.asarray(p8)\ndf_test['score_min']=np.asarray(p1)+np.asarray(p3)\ndf_test['diff']=df_test['score_max']-df_test['score_min']","94c61dce":"df_test['err_corr']=df_test['diff'].apply(lambda x: correctie(x))","13a5a4ff":"df_test['err_corr'].describe()","0aeb2756":"df_test.head()","9f99b5da":"df_test.to_csv('validation_data_pseudo_scores.csv')","a88c0c53":"clasament_df=df_test[['less_toxic', 'score_min']]\nclasament_df.rename(columns={'less_toxic':'text','score_min':'score'},inplace=True)\nclasament_df1=df_test[['more_toxic', 'score_max']]\nclasament_df1.rename(columns={'more_toxic':'text','score_max':'score'},inplace=True)","b0349951":"clasament=pd.concat([clasament_df, clasament_df1])","d8d0a33a":"len(clasament)","bbc3f395":"clasament.head()","233efe3c":"import matplotlib.pyplot as plt\nimport seaborn as sns, numpy as np\n\nsns.set(rc={\"figure.figsize\": (30, 4)})\nx = clasament['score']\nax = sns.distplot(x)\nplt.show()","49f7cf96":"clasament.to_csv('validation_data_pseudo_scores_clasament.csv')","14899dff":"# Get the predictions \nscored_sub=reg.predict(X_comments_to_score).squeeze().tolist()","2834dc03":"comments_to_score['score']=scored_sub","1dd49ab4":"submission=comments_to_score[['score']]","0ec81b7d":"submission.to_csv('submission.csv')","f3000dd6":"submission.head()","f0f5104f":"# from sklearn.model_selection import train_test_split\n\n# train, valid = train_test_split(ruddit_df, test_size=0.10)\n# #valid, test = train_test_split(valid, test_size=0.3)","681dc5b7":"# train_data = train['text'].values\n# train_target = train['target'].values\n\n# valid_data = valid['text'].values\n# valid_target = valid['target'].values\n\n# print(train_data.shape, train_target.shape)\n# print(valid_data.shape, valid_target.shape)","33ddd64a":"# input_node = ak.TextInput()\n# output_node = ak.TextToIntSequence()(input_node)\n# output_node = ak.Embedding()(output_node)\n# # Use separable Conv layers in Keras.\n# output_node = ak.ConvBlock(separable=True)(output_node)\n# #output_node = ak.ConvBlock(separable=True)(output_node)\n# output_node = ak.RegressionHead()(output_node)\n# reg = ak.AutoModel(\n#     inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n# )\n# reg.fit(train_data, train_target, epochs=10,validation_split=0.12)","b2b7c0b8":"# input_node = ak.TextInput()\n# output_node2 = ak.TextBlock(block_type=\"transformer\",pretraining=\"fasttext\")(input_node)\n# output_node3 = ak.TextBlock(block_type=\"ngram\")(input_node)\n# output_node1 = ak.TextToIntSequence()(input_node)\n# output_node2 = ak.Embedding()(output_node2)\n# output_node1 = ak.Embedding()(output_node1)\n# #output_node = ak.ConvBlock(separable=True)(output_node)\n# output_node = ak.Merge()([output_node1, output_node2,output_node3 ])\n# output_node = ak.RegressionHead()(output_node)\n# reg = ak.AutoModel(\n#     inputs=input_node, outputs=output_node, overwrite=True, max_trials=3\n# )\n# reg.fit(train_data, train_target, epochs=6)","cdb50073":"# #preds = reg.predict(X_less_toxic).squeeze().tolist()\n# #p1 = predictor.predict(X_less_toxic)\n# p3 = reg.predict(X_less_toxic).squeeze().tolist()\n# #p2 = predictor.predict(X_more_toxic)\n# p4 = reg.predict(X_more_toxic).squeeze().tolist()","998b83dd":"# # Validation Accuracy\n# compare(p3,p4)","f5417661":"# compare(p4,p3)","c20963e6":"# compare(p1+p3,p2+p4)","9185443e":"# # Get the predictions \n# scored_sub1=reg.predict(X_comments_to_score).squeeze().tolist()","157eaade":"# comments_to_score['score']=scored_sub1+scored_sub","6c210425":"# submission=comments_to_score[['score']]","5aae38a0":"# submission.to_csv('submission.csv')","aedd52cb":"# Basic Text Regressor using Auto-Keras\n\nBasic implementatio for toxic comment challange.","35eca90c":"Train test split. Not used\/usefull. ","80c9b48d":"Load data","6e767498":"Simple model 0.6745383286834064 \n\n* validation score with second conv block and 3 epoch:\n0.6651720472963997\n","bb2ee491":"Validate results","83ea196f":"Ruddit -dumb test","18c78a9d":"Prepare a keras model. "}}