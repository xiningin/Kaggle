{"cell_type":{"b5e48740":"code","c82ecf46":"code","80006752":"code","54b0b7a9":"code","462e524b":"code","32fcf85b":"code","daced9b7":"code","c9cefe11":"code","8e3c8200":"code","49710ef5":"code","6725d6fd":"code","ead03a87":"code","1b20460e":"code","1c4297bb":"code","07bef760":"code","11c0f44f":"code","1535289c":"code","ce0824ff":"code","8d9429a6":"code","345caf7d":"code","2ea92175":"code","41505bd5":"code","979f7126":"code","9a7b904f":"code","00e4ab83":"code","4e3ee7cf":"code","02f6e404":"code","ea352f44":"code","f572175b":"code","bdc1f603":"markdown","3f86ab1b":"markdown","af582f26":"markdown","f837e34c":"markdown","e72e2160":"markdown","1c5cc0d4":"markdown","bbf83123":"markdown","ed1f15a4":"markdown","4368ade0":"markdown","8284bfdb":"markdown","9a7fd889":"markdown","98ee5723":"markdown","553143b9":"markdown","7353868f":"markdown","766bf34c":"markdown","9c569818":"markdown","96d7e7c1":"markdown","cec4870b":"markdown","dfc71da0":"markdown","d92d8484":"markdown","0d4e6bec":"markdown","d1bf8aa8":"markdown","16d9e10a":"markdown","b192f5a2":"markdown","a4362786":"markdown","98b64f01":"markdown","2f5f1230":"markdown","dda13d42":"markdown"},"source":{"b5e48740":"%load_ext tensorboard\n# Data Preprocessing Packages\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport re\nfrom scipy.io.arff import loadarff\n\n# Data Visualization Packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ML Packages\nfrom sklearn import model_selection, svm\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold, KFold, RandomizedSearchCV, train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nimport xgboost as xgb\nimport time\nimport tensorflow as tf\n\ngpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\n    \nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPool1D\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.naive_bayes import GaussianNB\nfrom skmultilearn.ensemble import RakelD\nfrom sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\nfrom sklearn.utils import class_weight\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom sklearn.metrics import multilabel_confusion_matrix,ConfusionMatrixDisplay, f1_score\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\nfrom sklearn import metrics","c82ecf46":"raw_data = loadarff('..\/input\/multilabel-classification-emotions\/emotions.arff')\ndf = pd.DataFrame(raw_data[0]).astype(float)\n#df.drop(columns = ['Unnamed: 0'],inplace = True)\ndf.head()","80006752":"df.info() #Acquiring basic information of each columns","54b0b7a9":"df.describe()","462e524b":"labels = ['amazed-suprised', 'happy-pleased', 'relaxing-calm', 'quiet-still', 'sad-lonely', 'angry-aggresive']\n\nfeats_df = df.drop(columns = labels)\nlabels_df = df[labels]","32fcf85b":"label_d = {'amazed-suprised' : 0, 'happy-pleased': 0, 'relaxing-calm' : 0, 'quiet-still' : 0, 'sad-lonely': 0, 'angry-aggresive' : 0}\nfor col in labels_df.columns:\n    label_d[col] += len(labels_df[labels_df[col] == 1])\n\nplt.figure(figsize = (16,8))\nplt.bar(range(len(label_d)), list(label_d.values()), align='center')\nplt.xticks(range(len(label_d)), list(label_d.keys()))\nplt.show()","daced9b7":"def transform_multiclass(orig_df):\n    df = orig_df.copy()\n    classe = []\n    for i in range(len(df)):\n        classe.append('')\n    \n    for i in range(len(df)):\n        if df['amazed-suprised'][i] == 1:\n            classe[i] = classe[i] + 'surprised-'\n        if df['happy-pleased'][i] == 1:\n            classe[i] = classe[i] + 'happy-'\n        if df['relaxing-calm'][i] == 1:\n            classe[i] = classe[i] + 'relaxing-'\n        if df['quiet-still'][i] == 1:\n            classe[i] = classe[i] + 'still-'\n        if df['sad-lonely'][i] == 1:\n            classe[i] = classe[i] + 'lonely-'\n        if df['angry-aggresive'][i] == 1:\n            classe[i] = classe[i] + 'angry-'\n            \n    df['Class'] = classe\n    df.drop(['angry-aggresive','amazed-suprised','happy-pleased','relaxing-calm','quiet-still','sad-lonely'],axis=1,inplace = True)\n    return df","c9cefe11":"class_label_df = transform_multiclass(labels_df)\nclass_label_df['Class'].unique()","8e3c8200":"plt.figure(figsize = (16,8))\nsns.countplot(y = class_label_df.Class)\nplt.show()\nclass_label_df.Class.value_counts()","49710ef5":"df.corr().style.background_gradient(cmap='coolwarm')","6725d6fd":"df.duplicated().unique()","ead03a87":"df.isnull().sum().unique()","1b20460e":"# Correlational Matrix\ncorr_matrix = feats_df.corr().abs()\n\n# Selects Upper section of the matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Finds column with correlation greater than 0.8\nto_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n\n#Remove highly correlated features\ndf.drop(df[to_drop], axis=1,inplace = True)","1c4297bb":"df['Class'] = class_label_df['Class']\ndf.head()","07bef760":"class_df = df.drop(labels,1)\nprint(class_df.shape)\nclass_df.head()","11c0f44f":"classes = class_label_df.Class.value_counts().index\nclass_series =class_label_df['Class'].value_counts()\noutliers = []\nfor label in classes:\n    if class_series[label] < 5:\n        outliers.append(label)\noutliers","1535289c":"for outlier in outliers:\n    class_df = class_df[class_df['Class'] != outlier]\n\nprint(class_df.shape)","ce0824ff":"X = class_df.drop('Class',1)\ny = class_df['Class']\n\nprint(X.shape, y.shape)","8d9429a6":"ros = RandomOverSampler()\nX_over, y_over = ros.fit_resample(X, y)\nprint(X_over.shape)\nprint(y_over.shape)","345caf7d":"y_over.value_counts()","2ea92175":"X_train, X_test, y_train, y_test = train_test_split(X_over,y_over,test_size = 0.2, random_state = 42)\n\ntrain_df = X_train.join(y_train)\ntest_df = X_test.join(y_test)","41505bd5":"test_df.shape","979f7126":"test_df.duplicated().sum()","9a7b904f":"test_df.drop_duplicates(inplace = True)\ntest_df.shape","00e4ab83":"train_df.shape","4e3ee7cf":"le = LabelEncoder()\n\nX_train = train_df.drop('Class',1).values\nX_train = preprocessing.scale(X_train)\ny_train = le.fit_transform(train_df['Class'])\n\nX_test = test_df.drop('Class',1).values\nX_test = preprocessing.scale(X_test)\ny_test = le.fit_transform(test_df['Class'])\n\nX_train","02f6e404":"classifier = RandomForestClassifier(n_estimators = 100,n_jobs = -1, verbose = 0, random_state = 30)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\ncm = metrics.confusion_matrix(y_test, y_pred)\nf1 = round(f1_score(y_test,y_pred, average = 'micro'),2)\naccuracy = round(accuracy_score(y_test,y_pred),2)\n\nprint(f'Accuracy: {accuracy*100}%\\n')\nprint(f'F1 Score: {f1*100}%\\n')\nprint(f'Confusion Matrix:\\n{cm}')","ea352f44":"#xgb_params = {\n#    'objective': 'multi:softmax'\n#}\n\nclassifier = OneVsRestClassifier(xgb.XGBClassifier(n_jobs = -1))\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\ncm = metrics.confusion_matrix(y_test, y_pred)\nf1 = round(f1_score(y_test,y_pred, average = 'micro'),3)\naccuracy = round(accuracy_score(y_test,y_pred),3)\n\nprint(f'Accuracy: {accuracy*100}%\\n')\nprint(f'F1 Score: {f1*100}%\\n')\nprint(f'Confusion Matrix:\\n{cm}')","f572175b":"BATCH_SIZE = 64\nEPOCHS = 100\ndense_layers = [1]\nconv_layers = [2]\nlayer_sizes = [128]\n\nX_train_n = X_train\ny_train_n = y_train\nX_test_n = X_test\ny_test_n = y_test\n\n\nX_train_n = preprocessing.scale(X_train_n)\nX_test_n = preprocessing.scale(X_test_n)\n\nX_train_n = np.reshape(X_train_n, (X_train_n.shape[0], X_train_n.shape[1] , 1))\nX_test_n = np.reshape(X_test_n, (X_test_n.shape[0], X_test_n.shape[1], 1))\nsw = class_weight.compute_sample_weight('balanced', y_train_n)\n\nfor dense_layer in dense_layers:\n    for layer_size in layer_sizes:\n        for conv_layer in conv_layers:\n            NAME = f'emotions_cnn-dense-{dense_layer}-layer{layer_size}-conv{conv_layer}-time-{int(time.time())}'\n            tb_callback = TensorBoard(log_dir = f'logs\/{NAME}')\n            \n            model2 = Sequential()\n            \n            if conv_layer > 0:\n                model2.add(Conv1D(layer_size, 3,padding='valid', input_shape=(53,1),activation='tanh'))\n                model2.add(BatchNormalization())\n                model2.add(MaxPooling1D(pool_size=(4)))\n                model2.add(Dropout(0.2)) \n                \n                for l in range(conv_layer - 1):\n                    model2.add(Conv1D(layer_size, 3,padding='valid',activation='tanh'))\n                    model2.add(BatchNormalization())\n                    model2.add(MaxPooling1D(pool_size=(2)))\n                    model2.add(Dropout(0.2)) \n            \n                                   \n            else:\n                model2.add(Flatten())\n                model2.add(Dense(layer_size, input_shape = (53,) ,activation='tanh'))\n            \n            model2.add(Dropout(0.2))  \n            model2.add(Flatten())\n            for l in range(dense_layer):\n                model2.add(Dense(layer_size, activation='relu'))\n                model2.add(BatchNormalization())\n                model2.add(Dropout(0.1))\n                \n            model2.add(Dropout(0.3))\n            model2.add(Dense(20, activation=\"softmax\"))\n\n            model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n            history = model2.fit(X_train_n, y_train_n, \n                                 batch_size=BATCH_SIZE, \n                                 epochs=EPOCHS,\n                                 verbose= 0,\n                                 validation_data=(X_test_n, y_test_n),\n                                 callbacks = [tb_callback])\n            \nscore = model2.evaluate(X_test_n, y_test_n, verbose=1)\n\nprint(f'Loss: {score[0]}\\nAccuracy: { round(score[1], 2)*100}%')\ny_pred = np.argmax(model2.predict(X_test_n), axis = 1)\n\n\ncm = metrics.confusion_matrix(y_test_n, y_pred)\nf1_score1 = round(f1_score(y_test_n,y_pred,average='micro'),3)\n\nprint(f'F1 Score: {f1_score1*100}%\\n')\nprint(f'Confusion Matrix:\\n{cm}')\n    \nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model train vs validation loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","bdc1f603":"### Analysis of the distribution of classes:\n\n1. I will split the dataset into Classes and Attributes, and analyze the Classes separately;\n2. Next, I will analyze the distribution of the classes;\n3. Then a detailed analysis of each combination will be made in the dataset.","3f86ab1b":"### **Convolutional Neural Networks:**\n\nThe architecture of the Neural Network was based on a SmallerVGGNet. I will use TensorBoard to optimize the number of Convolutional, Dense layers, and the size of each layer.","af582f26":"## Train and Validation:\n\nThe dataset was split between 80% training and 20% testing, using a certain number for random_state. Random_state guarantees that if the model achieves a good result it will be possible to achieve the same division in future classifications.\n<br\/>\n<br\/>\n<br\/>\n**Evaluation Metrics**:\n1. F1 Score: Can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n2. Confusion Matrix: Illustrates the number of correct and incorrect predictions in each class.\n3. Recall: Model completeness measure.\n4. Precision: The model's ability to correctly predict the absence of the condition for cases that do not have it.","f837e34c":"### Train and Test Split","e72e2160":"There is no duplicated record","1c5cc0d4":"Adicionando label com a classe de cada m\u00fasica","bbf83123":"Creating new dataframe without the older labels.","ed1f15a4":"### Splitting into train and test","4368ade0":"### Duplicated and Missing Data","8284bfdb":"### Results and future work:\n\nDespite not having reached a very high accuracy, it is possible to say that the result was satisfactory in the face of previous works related to this dataset. The method with the best results used the Convolutional Neural Network algorithm. The result of f1 score was 0.81.\n<br\/>\n<br\/>\nHowever, the experience that the dataset provides is not diverse and the model will not have good results without diversity in the data. If the goal is to create an emotion detector in music, it is desirable that more data be collected and that more people act in this process. Since in the creation of this dataset, only three people participated and for such a subjective task it is necessary to include the tastes and feelings of many people.","9a7fd889":"There is no null data","98ee5723":"Removing labels with less than 5 songs.","553143b9":"### Removing highly correlated features:","7353868f":"From this graph, it is possible to observe an imbalance between classes. Many songs convey relaxing-calm, and few represent quiet-still.","766bf34c":"## Data Cleaning:","9c569818":"### About the Data:\nThis dataset contains 593 different songs.\n\n1. Rhythmic Features: The rhythmic features were derived by extracting periodic changes from a beat histogram. An algorithm that identifies peaks using autocorrelation was implemented by the authors. They selected the two highest peaks and computed their amplitudes,their BMPs (beats per minute) and the high-to-low ratio of their BPMs. In addition, 3 features were calculated by summing the histogram bins between 40-90, 90-140 and 140-250 BPMs respectively. The whole process led to a total of 8 rhythmic features.\n<br\/>\n<br\/>\n2. Timbre Features: Mel Frequency Cepstral Coefficients (MFCCs) are used for speech recognition and music modeling. To derive MFCCs features, the signal was divided into frames and the amplitude spectrum was calculated for each frame. Next, its logarithm was taken and converted to Mel scale. Finally, the discrete cosine transform was implemented. They selected the first 13 MFCCs. Another set of 3 features that relate to timbre textures were extracted from the Short-Term Fourier Transform (FFT): *Spectral centroid, spectral rolloff and spectral flux*. For each of the 16 aforementioned features (13 MFCCs, 3 FFT) they calculated the mean, standard deviation (std), mean standard deviation (mean std) and standard deviation of standard deviation (std std) over all frames. This led to a total of 64 timbre features.\n<br\/>\n<br\/>\n3. Emotion Labels: These are the targets of the classification, there are 6 classes designed so that a song can represent more than one emotion. So making the problem a Multi-Label one.\n\nThe paper related to the production of this dataset is available at: https:\/\/ismir2008.ismir.net\/papers\/ISMIR2008_275.pdf","96d7e7c1":"The first observations to be made with this information are :\n\n1. There is no missing data, but that does not deny the hypothesis that there may be inconsistent information.\n2. There are **many** attributes in this dataset, most likely some of these are correlated.\n3. This is a multilabel classification problem, the distribution of classes will have to be analyzed in detail to avoid imbalanced data.","cec4870b":"### Data Correlation","dfc71da0":"With the correlation matrix above it is possible to observe that many attributes have a correlation rate greater than 0.8. I will remove these columns to reduce the dimensionality and repetition of information in the dataset.","d92d8484":"#### Using the RandomOverSampler","0d4e6bec":"# Multi-label classification of music into emotions\n\n## Abstract\nIn this notebook, I will discuss the results of my first assignment of the class Introduction to Artificial Intelligence. My job was to implement an automatic emotion detector in music from a pre-determined dataset. Finally, I will discuss my results and present some insights into the data.\n\n## Introduction\n\nMusic, as any piece of art, affects our emotions. As music databases expand the necessity of emotion detection into music increases. It can be used for recommendation systems, music selection, and even music therapy.\n\nHowever, one music can express more than one emotion at the same time. A retro wave song of the 80s can cause confusion and happiness for some people. To represent multiple classifications the dataset used for this task is structured with One-Hot-Encoded labels. That describes our assignment as a Multi-label Classification problem.\n\n## Dataset\n\nThis dataset is available at: https:\/\/bit.ly\/2XaEyMt","d1bf8aa8":"### Random Forest:\n\n","16d9e10a":"### XGBoost","b192f5a2":"### Handling the imbalance:\nAs the classes are unbalanced, I will use the RandomOverSampler oversampling technique. I will perform tests without using oversampling too, and I will select the method that obtains the best result.","a4362786":"## Acquiring Dataset","98b64f01":"## Exploratory Data Analysis:","2f5f1230":"## Imports","dda13d42":"Analyzing each combination of classes present in the dataset, it is possible to notice an imbalance in the labels. In order to solve this problem, I will remove the classes that have less than five songs. Then, I will make a RandomOverSample."}}