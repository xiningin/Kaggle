{"cell_type":{"39ea230d":"code","0b5c01de":"code","7ab0c007":"code","af6be18d":"code","e036b63b":"code","0356f1b1":"code","76bf3f29":"code","1da307fb":"code","a5677ef8":"code","f83b6651":"code","f7551bba":"code","afaa3334":"code","9514bffc":"code","c90802ea":"code","7e0faaa1":"markdown","d6988520":"markdown","2b3a6b2b":"markdown","ae2dceff":"markdown","c8694dc6":"markdown","812fc13d":"markdown","5df50a64":"markdown","0ca917bf":"markdown","b3aa3a31":"markdown","1378946e":"markdown"},"source":{"39ea230d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0b5c01de":"#  import\nimport numpy as np\nimport pandas as pd\n\n# Plotting\nfrom matplotlib import cm\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Statistical graphics\nimport seaborn as sns \n\n## To Show graphs in same window\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n#KMeans\nimport pylab as pl\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","7ab0c007":"comp_df=pd.read_csv(\"..\/input\/free-7-million-company-dataset\/companies_sorted.csv\")","af6be18d":"#Check of dataset\ncomp_df.head()\ncomp_df.tail()\n\ncomp_df.shape\n\ncomp_df.info()\ncomp_df.describe()\n\n#change name of columns and make it with fist upper letter.\ncomp_df.rename(columns={'year founded':'year_founded','size range':'size_range','linkedin url':'linkedin_url','current employee estimate':'current_employee_estimate','total employee estimate':'total_employee_estimate'}, inplace=True)\ncomp_df.columns=comp_df.columns.str.capitalize()\nprint(comp_df.columns)\ncomp_df['Country']=comp_df.Country.str.title()\ncomp_df.head()","e036b63b":"#add new variables-Continent\n#import dataset\ncontinent_df=pd.read_csv('..\/input\/continent\/country_continent.csv',delimiter=';',encoding = \"ISO-8859-1\") \ncontinent_df.head()\ncontinent_df.tail()\n\n#leave valuable columns\ncontinent_1=continent_df[['Continent','Country']]\ncontinent_1.head()\n\n#check if there are duplicates\nprint(any(continent_1['Country'].duplicated()))\ncontinent_1.head()","0356f1b1":"#new dataframe without missing values on 'Country'\ncomp_nonan_df = comp_df.dropna(axis=0, subset=['Country'])\ncomp_nonan_df.shape\ncomp_nonan_df.info()\ncomp_nonan_df.head()\n\n#connect dataframes: comp_nonan_df i continent_1f\nmarge_df=pd.merge(comp_nonan_df, continent_1,on='Country',how='left')\nmarge_df","76bf3f29":"#check if there are missing observations after concat\ncontin_null=marge_df[['Continent','Country']]\ncontin_null\ndf_null=contin_null.loc[contin_null['Continent'].isnull()]\ndf_null\n#check unique names of countries that have missing values\ndf_null['Country'].unique()\n\n#dict for NaN countries and they continent.\ndict_null=[{'United States':'North America', 'United Kingdom':'Europe', 'Czechia':'Europe', 'South Korea':'Asia',\n       'Taiwan':'Asia', 'Venezuela':'South America', 'Hong Kong':'Asia', 'Russia':'Europe', 'Iran':'Asia', 'Vietnam':'Asia',\n       'Palestine':'Asia', 'Trinidad And Tobago':'North America', 'Macau':'Asia', 'Syria':'Asia', 'Tanzania':'Africa',\n       'Isle Of Man':'Europe', 'Brunei':'Asia', 'Micronesia':'Oceania', 'C\u00f4te D\u2019Ivoire':'Africa',\n       'Macedonia':'Europe', 'Bolivia':'South America', 'Moldova':'Europe', 'Bosnia And Herzegovina':'Europe',\n       'Democratic Republic Of The Congo':'Africa', 'Netherlands Antilles':'Europe', 'Laos':'Asia',\n       'Saint Vincent And The Grenadines':'North America', 'Faroe Islands':'Europe',\n       'Saint Kitts And Nevis':'North America', 'Kosovo':'Europe', 'Cape Verde':'Africa',\n       'Svalbard And Jan Mayen':'Europe', 'Turks And Caicos Islands':'North America',\n       'S\u00e3o Tom\u00e9 And Pr\u00edncipe':'Africa', 'Caribbean Netherlands':'North America', 'Sint Maarten':'North America',\n       'North Korea':'Asia', 'Antigua And Barbuda':'North America', 'Republic Of The Congo':'Africa',\n       'Saint Martin':'North America', 'U.S. Virgin Islands':'North America', 'Saint Pierre And Miquelon':'North America',\n       'Saint Barth\u00e9lemy':'North America'}]\n\n##add dict to dataframe\ndf_5= pd.DataFrame(dict_null).transpose()\ndf_5=df_5.reset_index()\ndf_5.columns=['Country','Continent']\ndf_5.info()\n\n#concat df_5 and continent_1 \ncontinent_2=pd.concat([continent_1,df_5],sort=True)\ncontinent_2.info()\ncontinent_2.head()\n\n#concat comp_nonan_df, continent_2\nfi_df=pd.merge(comp_nonan_df, continent_2,on='Country',how='left')\nfi_df.info()\nfi_df.head()\n\n#check missing values\nfi_df['Continent'].isnull().any()\n\n#drop not needed columns\nfi_df.drop(['Unnamed: 0','Domain','Locality','Linkedin_url'], axis=1, inplace=True)\nfi_df.info()\nfi_df.head()","1da307fb":"#dataframe only EU\nEuropa_df=fi_df[(fi_df['Continent'] == 'Europe')]\nEuropa_df.head(2)\nEuropa_df.info()","a5677ef8":"#IMPORT\npkb_df=pd.read_csv(\"..\/input\/gdpset\/GDP.csv\",delimiter=';')\npkb_df.info()\npkb_df.head()\npkb_df=pkb_df.loc[:,['Country','GDP_2016','GDP_2017','GDP_PC_2018']]\npkb_sorted=pkb_df.sort_values(['GDP_2017'], ascending=[True])\npkb_sorted.set_index('Country')\npkb_sorted.head()","f83b6651":"# # MODELING\n\n#PREPARATION OF DATA\n#marge data Europa_df i pkb_df\npkb_eu=pd.merge(Europa_df, pkb_df,on='Country',how='left')\npkb_eu.info()\n\n#DEL NULL, CHANGE TYPE\npkb_eu_cl = pkb_eu.dropna(axis=0, subset=['GDP_2017'])\npkb_eu_cl['GDP_2017'] = pkb_eu_cl['GDP_2017'].astype('int64')\npkb_eu_cl['GDP_2016'] = pkb_eu_cl['GDP_2016'].astype('int64')\npkb_eu_cl['GDP_PC_2018'] = pkb_eu_cl['GDP_PC_2018'].astype('int64')\n\n#leave importante variables\npkb_eu_cl=pkb_eu_cl.loc[:,['Country','Total_employee_estimate','Current_employee_estimate', 'GDP_2017','GDP_2016','GDP_PC_2018']]\n\npkb_eu_cl.info()\npkb_eu_cl.head()","f7551bba":"#selection of variables for modeling\nX = pkb_eu_cl.loc[:,['Total_employee_estimate', 'GDP_2017']]","afaa3334":"#elbow curve chart to know  optimum amount of clusters (k)\nNc = range(1, 20)\n\nkmeans = [KMeans(n_clusters=i) for i in Nc]\n\nkmeans\n\nscore = [kmeans[i].fit(X).score(X) for i in range(len(kmeans))] \n\nscore\n\npl.plot(Nc,score)\n\npl.xlabel('Number of Clusters')\n\npl.ylabel('Score')\n\npl.title('Elbow Curve')\n\npl.show()","9514bffc":"#algorytm k-means for 5 clasters\nk = 5\nkmeans = KMeans(n_clusters=k)\nx_kmeans=kmeans.fit(X)\nlabels = kmeans.labels_\nlabels[::20]\ncentroids = kmeans.cluster_centers_\ncentroids\n\n#plot \nfor i in range(k):\n    # select only data observations with cluster label == i\n    ds = X[labels == i]\n    # plot the data observations\n    plt.plot(ds.iloc[:,0],ds.iloc[:,1],'o')\n    # plot the centroids\n    lines = plt.plot(centroids[i,0],centroids[i,1],'ro')\n    # make the centroid x's bigger\n    plt.setp(lines,ms=15.0)\n    plt.setp(lines,mew=2.0)\nplt.xlabel('Amount of employees')\nplt.ylabel('GDP_2017')\nplt.title('5 Cluster K-Means')\nplt.show()","c90802ea":"#ad column with cluster no-use predict.\npredict=kmeans.predict(X)\npredict_1=predict\npredict_1=predict +1\npkb_eu_cl['cluster'] =pd.Series(predict_1, index=pkb_eu_cl.index)\npkb_eu_cl.head()\n\n#check how algorytm asign countries in clusters\nfor i in range (1,6):\n    unique_countries=pkb_eu_cl[pkb_eu_cl.cluster== i].Country.unique()\n    print('Cluster', i)\n    print(unique_countries)\n    print()","7e0faaa1":"I have started with import of libraries and dataset,","d6988520":"> **Clustering algorytm K-means for selected countries**\n\nFor analysis, I prepared a collection containing 20 countries from Europe with the largest number of companies and  combined it with GDP for these countries.\n\nIn the analysis, I conducted a grouping of k-means using variables - Total employee estimate and GDP_2017.\n\nThe first step was to determine the curve, defining the number of clusters.","2b3a6b2b":"**Interpretation of the results of clustering:**\n 1. All clusters centroids are located at the lowest employment amount of companies, independently from GDP ranges.\n 2. Modeling shows that the number of companies and the size of employment in these companies are not decisive for the value of GDP.","ae2dceff":"> **Create dataframe for modeling**\n","c8694dc6":"Add new variable-continent to choose only EU countries.","812fc13d":"Elbow curve indicates that the division of 5 clusters should be sufficient for analysis.\nIn the k-means algorithm, I chose the fit method to perform the clustering.\nThe result of k-menas for 5 clusters:","5df50a64":"The graph for k-menas shows that the key element for the algorithm was GDP, because the clusters are distributed along a given GDP range and the colors do not mix.\n \nNext, I wanted to check how the algorithm assigned data to the clusters.\nFor this purpose, we used the \"predict\" method. Code below:","0ca917bf":"Hey,\nI will show k-means modeling.\nConduct clustering algorytm K-means for selected countries and compare sizes of company and GDP.","b3aa3a31":"Dataframe with only European countries.","1378946e":"GDP data frame"}}