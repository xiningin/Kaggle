{"cell_type":{"aecbe4c5":"code","0c510533":"code","66d024c0":"code","d2446319":"code","eac3bb40":"code","42c15e44":"code","41a6ac34":"code","63d6bb32":"code","1ea0a997":"code","4b785004":"code","e7d84e7d":"code","30df2069":"code","1ca95984":"code","3b762ca3":"code","e7ae81b1":"code","b6b9253a":"code","ee2d33f1":"markdown"},"source":{"aecbe4c5":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt","0c510533":"print(tf.__version__)","66d024c0":"tf.random.set_seed(99)","d2446319":"fas_mnist=tf.keras.datasets.fashion_mnist","eac3bb40":"(train_images,train_labels),(test_images,test_labels)=fas_mnist.load_data()","42c15e44":"train_images=train_images.reshape(60000, 28, 28)\ntrain_images=train_images \/ 255.0 #Standardising\ntest_images = test_images.reshape(10000, 28, 28)\ntest_images=test_images\/255.0 #Standardising","41a6ac34":"train_images.shape","63d6bb32":"test_images.shape","1ea0a997":"# The concept is simple, we take each HxW matrix of images --> Flatten it like sequence of Multi-dimensional time-series and feed to LSTM\n# HxW changes to TxD \n# In images H--> height, W--> width, similiarly T-->Timestamp(equals H), D-->Feature(equals W)\nmodel = tf.keras.Sequential([\n  tf.keras.Input(shape=(28,28)),\n  tf.keras.layers.GRU(128),\n  tf.keras.layers.Dense(128, activation='relu',input_shape=(28, 28, )),\n  tf.keras.layers.Dropout(0.2,input_shape=(128,)),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\n","4b785004":"model.summary()","e7d84e7d":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","30df2069":"def scheduler(epoch, lr):\n      if epoch < 8:\n        return lr\n      else:\n        return lr * tf.math.exp(-0.1)","1ca95984":"my_callbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=2),\n    tf.keras.callbacks.LearningRateScheduler(scheduler)\n]","3b762ca3":"trainer=model.fit(train_images, train_labels,validation_data=(test_images,test_labels), epochs=20,callbacks=my_callbacks)","e7ae81b1":"# Plot loss per iteration\nplt.plot(trainer.history['loss'], label='loss')\nplt.plot(trainer.history['val_loss'], label='val_loss')\nplt.legend()","b6b9253a":"# Plot accuracy per iteration\nplt.plot(trainer.history['accuracy'], label='acc')\nplt.plot(trainer.history['val_accuracy'], label='val_acc')\nplt.legend()","ee2d33f1":"## This Fashion MNIST dataset included in Tensorflow Library"}}