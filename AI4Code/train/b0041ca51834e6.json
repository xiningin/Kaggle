{"cell_type":{"95609d0d":"code","39999d84":"code","aef62255":"code","3e718d2b":"code","0828cac7":"code","b06d614d":"code","08bd5e5d":"code","677f6e2c":"code","4863a28f":"code","09016d47":"code","2798ddbd":"code","113822e7":"code","c6d7633b":"code","6238831c":"code","4acca18b":"code","41550a49":"code","38f4093a":"code","4b9af4d5":"code","039ff086":"code","19a2d678":"code","75a88940":"code","fdbb1383":"code","5ac87f32":"code","469f1a35":"code","21aa1f6b":"code","8cfd159b":"code","f4f7651c":"code","11cbf7ff":"code","ac2cc6fe":"code","0c9058f9":"code","dffc6b9d":"code","2cfae15d":"markdown","c2ca70de":"markdown","d6cb3be3":"markdown","88655926":"markdown","f5185dca":"markdown","e392fb1d":"markdown","74a51d72":"markdown","06403c2d":"markdown","c73e1471":"markdown","131b6c4b":"markdown","c38d9dce":"markdown","9a313dbb":"markdown","3f0b2f83":"markdown","6b7e97ef":"markdown","f72d5949":"markdown","91c2b0e8":"markdown"},"source":{"95609d0d":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39999d84":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","aef62255":"# Read the data\ndata = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata.head()","3e718d2b":"data.shape","0828cac7":"data.columns","b06d614d":"data.info()","08bd5e5d":"data.describe()","677f6e2c":"data.describe(include=['O'])","4863a28f":"data.hist(column=data.columns[1:],figsize=(8,8)) #to remove ID column\nplt.show()","09016d47":"def train_test_split(n_splits,test_size,data,target_label):\n    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n    for train_index, test_index in split.split(data, data[target_label]):\n        strat_train_set = data.loc[train_index]\n        strat_test_set = data.loc[test_index]\n        \n\n\n    X_train  = strat_train_set.drop(target_label,axis=1)\n    y_train = strat_train_set.loc[:,target_label]\n    X_test  = strat_test_set.drop(target_label,axis=1)\n    y_test = strat_test_set.loc[:,target_label]\n    return X_train,y_train,X_test,y_test\n\nX_train,y_train,X_test,y_test =train_test_split(3,0.2,data,\"Survived\")","2798ddbd":"from sklearn.impute import SimpleImputer\n# Drop cabin data and ID\nX = X_train.drop([\"Cabin\",\"PassengerId\"],axis=1)\n# Impute with age mean\nage_imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nX[\"Age\"] = age_imp.fit_transform(X[[\"Age\"]]).ravel()\n# Impute with mode Embarked\nembarked_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nX[\"Embarked\"] = embarked_imp.fit_transform(X[[\"Embarked\"]]).ravel()\n\n#X[\"Embarked\"].fillna(X[\"Embarked\"].mode()[0],inplace=True)\n#Check the data\nX.isnull().sum()","113822e7":"# Check for duplicates\nlen(X[X.duplicated()])","c6d7633b":"# Drop Name and Ticket columns\nX_new = X.drop([\"Name\",\"Ticket\"],axis=1)\n#Encode Sex column with onehot encoder\nX_new = pd.get_dummies(X_new, columns=['Sex'],drop_first=True)\n#Encode Embarked data with frequency ecnoder\nX_new[\"Embarked\"].replace(X_new.groupby(\"Embarked\").size(),inplace=True)\n#Check data\nX_new.head()\n","6238831c":"sns.boxplot(data=X_new,x=\"Pclass\",y=\"Fare\",hue=\"Embarked\")\nplt.show()","4acca18b":"#X_new.drop(X_new[X_new[\"Fare\"]>300].index,axis=0,inplace=True)\n#X_new.shape","41550a49":"#Check outliers\nsns.boxplot(data=X_new,orient=\"h\")","38f4093a":"#heat map for correlation matrix\ncorrelation_matrix =X_new.corr()\n#Visulaize heatmap for correlation matrix\nplt.figure(figsize=(15,8))\nsns.heatmap(correlation_matrix,annot=True)\nplt.show()","4b9af4d5":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=27)\nX_new, y_train = sm.fit_resample(X_new, y_train)\n# cut the age values to 3 groups:\"young\",\"adults\",\"old\"\nX_new[\"Age\"] = pd.cut(X_new[\"Age\"],bins=[float('-inf'),10.0,45.0,float('inf')],labels=[0,1,2],precision=1)\nX_new[\"Fare\"] = pd.cut(X_new[\"Fare\"],bins=[float('-inf'),50,100,200,250,300,np.inf],labels=[0,1,2,3,4,5],precision=1)\n\n#X_new.head(10)","039ff086":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\n\n#Polynomial transformat*ion\npoly_transform = PolynomialFeatures(degree=4)\nX_train_poly =poly_transform.fit_transform(X_new)\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_poly.astype(np.float64))","19a2d678":"from sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n#forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n#ovr_clf = OneVsRestClassifier(forest_clf)\n#ovr_clf.fit(X_train_scaled, y_train)\n#y_train_pred_forest = cross_val_score(ovr_clf, X_train_scaled, y_train, cv=3,scoring=\"accuracy\")\n#y_train_pred_forest = ovr_clf.predict(X_train)\n#y_train_pred_forest\n#clf=LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=1000)\n#clf.fit(X_train_scaled,y_train)\n#y_train_score = cross_val_score(clf, X_train_scaled, y_train, cv=3,scoring=\"accuracy\")\n#y_train_pred = clf.predict(X_train_scaled)\n#y_train_score\nfrom sklearn.linear_model import LogisticRegression\n#clf = LogisticRegression(random_state=0,max_iter=10000).fit(X_train_scaled, y_train)\n#y_train_score = cross_val_score(clf, X_train_scaled, y_train, cv=3,scoring=\"accuracy\")\n#y_train_score\nsmote = LogisticRegression(solver='liblinear').fit(X_train_scaled, y_train)\ny_train_score = cross_val_score(smote, X_train_scaled, y_train, cv=3,scoring=\"accuracy\")\ny_train_score\n#smote_pred = smote.predict(X_test)","75a88940":"\nX_test_new = X_test.drop([\"Cabin\",\"PassengerId\"],axis=1)\nX_test_new[\"Age\"] = age_imp.transform(X_test_new[[\"Age\"]]).ravel()\nX_test_new[\"Embarked\"] = embarked_imp.transform(X_test_new[[\"Embarked\"]]).ravel()\nX_test_new.drop([\"Name\",\"Ticket\"],axis=1,inplace=True)\nX_test_new = pd.get_dummies(X_test_new, columns=['Sex'],drop_first=True)\nX_test_new[\"Embarked\"].replace(X.groupby(\"Embarked\").size(),inplace=True)\n# cut the age values to 3 groups:\"young\",\"adults\",\"old\"\nX_test_new[\"Age\"] = pd.cut(X_test_new[\"Age\"],bins=[float('-inf'),10.0,45.0,float('inf')],labels=[0,1,2],precision=1)\nX_test_new[\"Fare\"] = pd.cut(X_test_new[\"Fare\"],bins=[float('-inf'),50,100,200,250,300,np.inf],labels=[0,1,2,3,4,5],precision=1)\n\n#X_new.head(10)\nX_new.head()","fdbb1383":"X_test_poly =poly_transform.transform(X_test_new)\nX_test_scaled = scaler.transform(X_test_poly.astype(np.float64))\ny_test_pred= smote.predict(X_test_scaled)\n","5ac87f32":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_test_pred)","469f1a35":"from sklearn.metrics import confusion_matrix\nconf_mx = confusion_matrix(y_test,y_test_pred)","21aa1f6b":"np.unique(y_test,return_counts=True)","8cfd159b":"conf_mx","f4f7651c":"plt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()","11cbf7ff":"df_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndf_test.head()","ac2cc6fe":"df_test_new = df_test.drop([\"Cabin\",\"PassengerId\"],axis=1)\ndf_test_new[\"Age\"] = age_imp.transform(df_test_new[[\"Age\"]]).ravel()\ndf_test_new[\"Fare\"] = df_test_new[\"Fare\"].fillna(X[\"Fare\"].mean())\n\ndf_test_new[\"Embarked\"] = embarked_imp.transform(df_test_new[[\"Embarked\"]]).ravel()\ndf_test_new.drop([\"Name\",\"Ticket\"],axis=1,inplace=True)\ndf_test_new = pd.get_dummies(df_test_new, columns=['Sex'],drop_first=True)\ndf_test_new[\"Embarked\"].replace(X.groupby(\"Embarked\").size(),inplace=True)\ndf_test_new[\"Age\"] = pd.cut(df_test_new[\"Age\"],bins=[float('-inf'),10.0,45.0,float('inf')],labels=[0,1,2],precision=1)\ndf_test_new[\"Fare\"] = pd.cut(df_test_new[\"Fare\"],bins=[float('-inf'),50,100,200,250,300,np.inf],labels=[0,1,2,3,4,5],precision=1)\ndf_test_new.head()\ndf_test_new.info()","0c9058f9":"df_test_poly =poly_transform.transform(df_test_new)\ndf_test_scaled = scaler.transform(df_test_poly.astype(np.float64))\ndf_test_pred= smote.predict(df_test_scaled)\ndf_test[\"Survived\"] = df_test_pred\n","dffc6b9d":"df_test[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2cfae15d":"## Submit Predictions","c2ca70de":"#### Missing values\n* Most cabin data are missing , and as the cabin number will not be of crucial importance in predicting the survival we can drop the whole column\n* Some age data is missing whcih we can impute with mean or median\n* Some Embarked data is missing which we can fill in with median","d6cb3be3":"#### Note\nNow there is no missing data ,let's see if there is any duplicates","88655926":"## Train model (Linear Regression)","f5185dca":"## Test the model","e392fb1d":"### Comments\n* The target class is imbalanced , most people didn't survive\n* Also Pclass is not balanced with the majority of class 3\n* The age is normally distributed \n* Fare , Sibsp and parch are very skewed and may contain outliers","74a51d72":"## Feature Engineering","06403c2d":"### Data preprocessing","c73e1471":"#### Outliers","131b6c4b":"## Train and test data split","c38d9dce":"We can see that there is an outlier in fare for Pclass1 which we can impute","9a313dbb":"## Data Visualization","3f0b2f83":"#### Data Types\n* We have 4 columns of type \"String\" : Name,Sex,Ticket,Embarked\n* Column Name and Ticket are not useful so we can drop them\n* Sex can be encoded to 0 and 1\n* Embarked can also be one hot encoded","6b7e97ef":"#### Note\nNow all data is in numeric form , we are ready for some data visualization","f72d5949":"## Exploratory data analysis (EDA)","91c2b0e8":"#### Duplicates"}}