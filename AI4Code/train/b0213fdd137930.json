{"cell_type":{"fe3359a5":"code","7a8cc2e0":"code","62e32394":"code","c93dfcee":"code","2887a53d":"code","76d1f01d":"code","c356f082":"code","c3275e2c":"code","18d85570":"code","333b6a8e":"code","4742e670":"code","c4f8838f":"code","9ce6fe4a":"code","80cdbff2":"code","a4abbe12":"code","de2e371a":"code","9351f19d":"code","d467ed81":"code","228c92f5":"markdown","9f82ad4f":"markdown","ad513d4b":"markdown","06257a80":"markdown","48354faa":"markdown","2141ea9f":"markdown","22992c46":"markdown"},"source":{"fe3359a5":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","7a8cc2e0":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\ntraindir = \"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\/train\"\nvaliddir = \"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\/valid\"\ntestdir = \"..\/input\/new-plant-diseases-dataset\/test\/test\"\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\nbatch_size = 128\ntraining_set = train_datagen.flow_from_directory(traindir,\n                                                 target_size=(224, 224),\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagen.flow_from_directory(validdir,\n                                            target_size=(224, 224),\n                                            batch_size=batch_size,\n                                            class_mode='categorical')\n","62e32394":"class_dict = training_set.class_indices\nprint(class_dict)","c93dfcee":"li = list(class_dict.keys())\nprint(li)","2887a53d":"train_num = training_set.samples\nvalid_num = valid_set.samples\nprint(\"train_num is:\",train_num)\nprint(\"valid_num is:\",valid_num)","76d1f01d":"depth,height, width=3,224,224\nn_classes=len(li)\nprint(\"n_classes:\",n_classes)","c356f082":"# model = Sequential()\n# inputShape = (height, width, depth)\n# chanDim = -1\n\n# model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization(axis=chanDim))\n# model.add(MaxPooling2D(pool_size=(3, 3)))\n# model.add(Dropout(0.25))\n# model.add(Conv2D(64, (3, 3), padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization(axis=chanDim))\n# model.add(Conv2D(64, (3, 3), padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization(axis=chanDim))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n# model.add(Conv2D(128, (3, 3), padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization(axis=chanDim))\n# model.add(Conv2D(128, (3, 3), padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization(axis=chanDim))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n# model.add(Flatten())\n# model.add(Dense(1024))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# model.add(Dense(n_classes))\n# model.add(Activation(\"softmax\"))\n# model.summary()","c3275e2c":"# model.compile(optimizer='adam',\n#               loss='categorical_crossentropy',\n#               metrics=['accuracy'])","18d85570":"# #fitting images to CNN\n# history = model.fit_generator(training_set,\n#                          steps_per_epoch=train_num\/\/batch_size,\n#                          validation_data=valid_set,\n#                          epochs=20,\n#                          validation_steps=valid_num\/\/batch_size,\n#                          )","333b6a8e":"# move the model \n%cp -arvf \"..\/input\/cnn-model\/cnn_model.h5\" .\/\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential, load_model\n# define the checkpoint\nfilepath = \".\/cnn_model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\n\n# load the model\nmodel = load_model(filepath)\n","4742e670":"# fit the model\nhistory = model.fit_generator(training_set,\n                         steps_per_epoch=train_num\/\/batch_size,\n                         validation_data=valid_set,\n                         epochs=30,\n                         validation_steps=valid_num\/\/batch_size,\n                         callbacks=callbacks_list\n                         )","c4f8838f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","9ce6fe4a":"x_test, y_test = valid_set.next() \nprint(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]}\")","80cdbff2":"\n# predicting an image\nimport os\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nimport numpy as np\ndirectory=\"..\/input\/new-plant-diseases-dataset\/test\/test\"\nfiles = [os.path.join(directory,p) for p in sorted(os.listdir(directory))]\nfor i in range(0,10):\n    image_path = files[i]\n    new_img = image.load_img(image_path, target_size=(224, 224))\n    img = image.img_to_array(new_img)\n    img = np.expand_dims(img, axis=0)\n    img = img\/255\n    prediction = model.predict(img)\n    probabilty = prediction.flatten()\n    max_prob = probabilty.max()\n    index=prediction.argmax(axis=-1)[0]\n    class_name = li[index]\n    #ploting image with predicted class name        \n    plt.figure(figsize = (4,4))\n    plt.imshow(new_img)\n    plt.axis('off')\n    plt.title(class_name+\" \"+ str(max_prob)[0:4]+\"%\")\n    plt.show()\n        ","a4abbe12":"#Confution Matrix and Classification Report\nfrom sklearn.metrics import classification_report, confusion_matrix\ny_pred = model.predict_generator(valid_set, valid_num\/\/batch_size+1)","de2e371a":"class_dict = valid_set.class_indices\nli = list(class_dict.keys())\nprint(li)","9351f19d":"y_pred = np.argmax(y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(valid_set.classes, y_pred))\nprint('Classification Report')\ntarget_names =li ## ['Peach___Bacterial_spot', 'Grape___Black_rot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\nprint(classification_report(valid_set.classes, y_pred, target_names=target_names))","d467ed81":"# save the model to disk\nprint(\"[INFO] Saving model...\")\nfilepath=\"cnn_model.h5\"\nmodel.save(filepath)\n\n# save the history to disk\nprint(\"[INFO] Saving history...\")\npickle.dump(model,open('history.pkl', 'wb'))","228c92f5":"# **fit the model**","9f82ad4f":"Model Accuracy","ad513d4b":"# **confusion_matrix**","06257a80":"# **Save history using Pickle and model**","48354faa":"# **continue training**","2141ea9f":"Import neccessary packages","22992c46":"Plot the train and val curve"}}