{"cell_type":{"37cbb254":"code","ae905b2f":"code","84097d11":"code","8244e2c0":"code","3b937401":"code","4f3600c7":"code","df0a492b":"code","b10b5e0d":"code","3d582c6b":"code","d002b8f3":"code","8fc6b05e":"code","e04739c1":"code","59ddb6de":"code","cfa2b3ef":"code","1e96bb63":"code","d05dc159":"code","67984a6c":"markdown","0795f087":"markdown","b6bbaad1":"markdown","e27d80c8":"markdown","5b14a708":"markdown","005ad5a2":"markdown","f85cd5d3":"markdown","2855be4a":"markdown","a4fabce4":"markdown"},"source":{"37cbb254":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae905b2f":"! pip install squarify\n! pip install --index-url https:\/\/test.pypi.org\/simple\/ PyARMViz","84097d11":"import numpy as np\nimport pandas as pd \n\n# mlxtend will be used for market basket analysis\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom mlxtend.preprocessing import TransactionEncoder\nimport squarify\nimport matplotlib\nfrom matplotlib import style\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PyARMViz import PyARMViz\nfrom PyARMViz.Rule import generate_rule_from_dict\n\nsns.set()\nmatplotlib.rcParams['figure.figsize'] = (36, 36)\nstyle.use('ggplot')","8244e2c0":"import pandas as pd\nbasket = pd.read_csv('https:\/\/github.com\/rajeevratan84\/datascienceforbusiness\/blob\/master\/Groceries_dataset.csv?raw=true')\nbasket","3b937401":"basket['Date'] = pd.to_datetime(basket['Date'])\nbasket[basket['Member_number'] == 1808].sort_values(by='Date')","4f3600c7":"transactions = [a[1]['itemDescription'].tolist() for a in list(basket.groupby(['Member_number','Date']))]\nprint(len(transactions))\ntransactions","df0a492b":"# We use TransactionEncoder from the mlxtend module to encode our date\nte = TransactionEncoder()\nte_ary = te.fit(transactions).transform(transactions)\nte_ary","b10b5e0d":"# Convert to a pandas datafrae\ntransactions = pd.DataFrame(te_ary, columns=te.columns_)\ntransactions","3d582c6b":"pf = transactions.describe()\nf = pf.iloc[0]-pf.iloc[3]\na = f.tolist()\nb = list(f.index)\nitem = pd.DataFrame([[a[r],b[r]]for r in range(len(a))], columns=['Count','Item'])\nitem = item.sort_values(['Count'], ascending=False).head(50)\nitem","d002b8f3":"fig, ax = plt.subplots()\n\n# set color scheme\ncmap = matplotlib.cm.coolwarm\n\n# Get upper and lower boudns for the color mapping\nmini = min(item[\"Count\"])\nmaxi = max(item[\"Count\"])\n\n# Set out color mapping limits \nnorm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\n\n# Obtain our raw colors \ncolors = [cmap(norm(value)) for value in item[\"Count\"]]\n\n# Create the TreeMap plot with Squarify\nsquarify.plot(sizes=item[\"Count\"], label=item[\"Item\"], alpha=0.8, color=colors)\nplt.axis('off')\nplt.title(\"Top 50 Frequent Basket Items\", fontsize=32)\nttl = ax.title\nttl.set_position([.5, 1.05])\n","8fc6b05e":"frequent_itemsets = apriori(transactions, min_support=0.001, use_colnames=True, max_len=5)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\nfrequent_itemsets.head(50)","e04739c1":"b = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.001)\nb['uni'] = np.nan\nb['ant'] = np.nan\nb['con'] = np.nan\nb['tot'] = 14963","59ddb6de":"transactions = [a[1]['itemDescription'].tolist() for a in list(basket.groupby(['Member_number','Date']))]\n\ndef trans():\n    for t in transactions:\n        yield t\n    \ndef ant(x):\n    cnt = 0\n    for t in trans():\n        t = set(t)\n        if x.intersection(t) == x:\n            cnt = cnt + 1 \n    return cnt\n\nbb = b.values.tolist()  ","cfa2b3ef":"rules_dict = []\nfor bbb in bb:\n    bbb[10] = ant(bbb[0])\n    bbb[11] = ant(bbb[1])\n    bbb[9] = ant(bbb[0].union(bbb[1]))\n    diction = {\n        'lhs': tuple(bbb[0]), \n        'rhs': tuple(bbb[1]),\n        'count_full': bbb[9],\n        'count_lhs': bbb[10],\n        'count_rhs': bbb[11],\n        'num_transactions': bbb[12]\n    }\n    rules_dict.append(diction)\n","1e96bb63":"rules = []\nfor rd in rules_dict: \n    rules.append(generate_rule_from_dict(rd))","d05dc159":"PyARMViz.generate_parallel_category_plot(rules)","67984a6c":"# 1.Loading our Groceries dataset","0795f087":"## Now let's create some illustrative plots\n","b6bbaad1":"### Here we illustrate our itemset relationships\n**Antecedent and Consequent**\n\nThe IF component of an association rule is known as the antecedent. The THEN component is known as the consequent. The antecedent and the consequent are disjoint; they have no items in common.","e27d80c8":"### And now we create item purhcase counts from our transaction data\n","5b14a708":"Let's find our Frequent Itemsets using our Apriori Module\nWe set the minimum support to 0.001 and maxlen of our itemset to be 5","005ad5a2":"### The above table gives all association rules for basket analysis","f85cd5d3":"# 3. About the Apriori Alogorithm\n\nAssociation rules analysis is a technique to uncover how items are associated to each other. There are three common ways to measure association.\n\nMeasure 1: Support. This says how popular an itemset is, as measured by the proportion of transactions in which an itemset appears. In the Table above, the support of {apple} is 4 out of 8, or 50%. Itemsets can also contain multiple items. For instance, the support of {apple, beer, rice} is 2 out of 8, or 25%.\n\nMeasure 2: Confidence. This says how likely item Y is purchased when item X is purchased, expressed as {X -> Y}. This is measured by the proportion of transactions with item X, in which item Y also appears. In Table 1, the confidence of {apple -> beer} is 3 out of 4, or 75%.\n\nMeasure 3: Lift. This says how likely item Y is purchased when item X is purchased, while controlling for how popular item Y is. In Table 1, the lift of {apple -> beer} is 1,which implies no association between items. A lift value greater than 1 means that item Y is likely to be bought if item X is bought, while a value less than 1 means that item Y is unlikely to be bought if item X is bought.","2855be4a":"# 2. Preparing our dataset","a4fabce4":"### Now let's visualize the 167 items as a Treemap"}}