{"cell_type":{"b3435862":"code","a885d57e":"code","ca7a19f8":"code","460e3eff":"code","d58ac220":"code","2405ca00":"code","af22d792":"code","d4a216c0":"code","8990394a":"code","84ef5713":"code","beffa2f7":"markdown","b7772949":"markdown","c65f7411":"markdown","2de566db":"markdown","ab190123":"markdown","813cf5bb":"markdown","6ab40b33":"markdown","2865cf50":"markdown","7162323c":"markdown","2bd95e9b":"markdown","51292305":"markdown"},"source":{"b3435862":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a885d57e":"import plotly.express as px\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import IsolationForest","ca7a19f8":"data = load_iris(as_frame=True)\nX, y = data.data, data.target\ndf = data.frame\ndf.head()","460e3eff":"iforest = IsolationForest(n_estimators=100, max_samples='auto',\n                         contamination=0.05, max_features=4,\n                         bootstrap=False, n_jobs=-1, random_state=1)","d58ac220":"pred= iforest.fit_predict(X)\ndf['scores'] = iforest.decision_function(X)\ndf['anomaly_label'] = pred","2405ca00":"df[df.anomaly_label == -1]","af22d792":"df[df.anomaly_label == 1]","d4a216c0":"df['anomaly']=df.anomaly_label.apply(lambda x : 'outliers' if x == -1 else 'inliers')\ndf.head()","8990394a":"fig=px.histogram(df, x='scores', color='anomaly')\nfig.show()","84ef5713":"fig = px.scatter_3d(df, x='petal width (cm)',\n                   y = 'petal length (cm)',\n                   z= 'sepal width (cm)', color='anomaly')\nfig.show()","beffa2f7":"## D. Reference\n\n1. Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. \u201cIsolation forest.\u201d Data Mining, 2008. ICDM\u201908. Eighth IEEE International Conference on.\n\n2. Eugenia Anello. \"Anomaly Detection With Isolation Forest\". https:\/\/betterprogramming.pub\/anomaly-detection-with-isolation-forest-e41f1f55cc6\n\n","b7772949":"### 4. Checking result\n\nAfter predicting anomaly score and make label from it, we encode the label to value -1 as **outliers** and 1 as **inliers**","c65f7411":"## A. Isoaltion Tree\n\n### 1. Introduction\n\nIsolation tree was firstly prpoposed by Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua in 2008 [1]. It is an unsupervised and non-parametric algorithm based trees. Basically we can identify how this algorithm works by its name. Isolated means separating an instances from the rest of another instances. Since we know that an anomalies are so rare and different they more suspectible to be isolated [1]. The main principle of how tree algorithm work is partitioning data point until the instances were isolated. From this concept we can know that anoamlies will have short paths in tree structure.\n\n### 2. How Isolation Tree Works\n\nBasically how isolation work are :\n1. Pick two random features\n2. Splitting random data point according to in the range minimum and maximum value of the choosen features.\n\n![How Isolation Tree Works](https:\/\/miro.medium.com\/max\/2400\/1*d-4xINDQHv0G82o2GUApJQ.png)\n\n\n\n","2de566db":"## C. Conclusion\n\nfrom the explanation above we can get more understanding about what anomaly is and the concept of anomaly detection briefly. We can see basically anomaly detection using isolation forest has certain similarity with another classification tree algorithm. Also, we can see how isolated forest anomaly detection algorithm work and build simple model to detect an anomaly in Iris dataset. From the model we have build we know there is some anomaly or outliers in the Iris dataset.","ab190123":"### 1. Import Library\n\nFirst we import the library that we will use. There are **sklearn** package and **plotly** package. In this part we also import the dataset we will use in this study. In this study I am using Iris dataset from scikit learn datasets.","813cf5bb":"### 2. Load dataset","6ab40b33":"### 5.Visualization","2865cf50":"## B. Implementation of Isolation Tree Using Scikit-Learn","7162323c":"### 3. Anomaly Score\n\nAnomaly score is value that states how anomalious obeserved data point. Anomaly value has range between 0 and 1. We can interpret score as follows:\n\n1. When Anomaly score equal to 1, it means the data point that anomaly and the paths length is short.\n2. When Anomaly score smaller than 0.5, it means the data point that normal and the paths length is long.\n3. When Anomaly score aroun 0.5, it means that the dataset we evaluate is free from anomaly.","2bd95e9b":"### 3. Build the model\n\nIn the model building there are certain parameter that we must aware to gain best model performance:\n\n1. **n_estiamtors** --> How many trees that we consider to use.\n2. **contamination** --> How many anomaly proportion in the dataset. Also we can define it as a threshold to decide the data point is anomaly or normal.\n\n3. **max_feature** --> maximum how many features that we use in the model training phase.\n4. **max_samples** --> maximum samples used that considered from matrix feature.","51292305":"# Anomaly Detection using Isolation Forest\n\nThis is my learning note about anomaly detection using **Isolation Forest** method. Anomaly is a data or observation value that very different from normal value. We also can undertand it as an **outliers**. How we deal with these kind of data is very difficult because it maybe the outlier it self is a new kind important inforation that means if we remove it we lost our vulnerable data. There are many application of anomaly detection in our daily lives such as credit card fraud detection, fault of machine in the manufacture context, malicious network activity and etc.\n\nThe main goal of anomaly detection is build a model that can detect and explain the anomaly of the data. There are many method that we can use to detect anomaly but in this case i will use **isolation forest** method. Basically this method works like another ensemble tree algorithm. But in this application to detect anomaly it is using distance of spliting in the tree to detect anoamlies.  "}}