{"cell_type":{"ac765df3":"code","2a73324c":"code","d5fab067":"code","d150defa":"code","fcc9d724":"code","21cb515a":"code","38204372":"code","214306c3":"code","c960eddf":"code","900b596b":"code","69468e6d":"code","68abab3e":"code","0d404fe8":"code","2709dad4":"code","41a6706f":"code","549571cc":"code","b9574db8":"code","43452319":"code","e7440469":"code","7e1986b2":"code","b70bb948":"code","0d38d585":"code","64dbb05a":"code","56b0b183":"markdown","5a77990b":"markdown","ccc79601":"markdown","48fdc281":"markdown","d410df98":"markdown"},"source":{"ac765df3":"import pathlib\nimport os\nimport numpy as np\nimport pandas as pb\nimport tensorflow as tf\nimport keras\nimport IPython.display as display\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","2a73324c":"data_dir = pathlib.Path(\"..\/input\/cheese\/cheese\")\nimage_count = len(list(data_dir.glob('*\/*.jpeg')))\nimage_count","d5fab067":"CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_Store\"])\nCLASS_NAMES","d150defa":"labels_to_class_names = dict(zip(range(len(CLASS_NAMES)), CLASS_NAMES))\nprint(labels_to_class_names)","fcc9d724":"BATCH_TRAIN_SIZE = 64\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nSTEPS_PER_EPOCH = np.ceil(image_count\/BATCH_TRAIN_SIZE)\nEPOCHS=12","21cb515a":"AUTOTUNE = tf.data.experimental.AUTOTUNE","38204372":"list_ds = tf.data.Dataset.list_files(str(data_dir\/'*\/*'))\n\nfor f in list_ds.take(5):\n    print(f.numpy())","214306c3":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == CLASS_NAMES\n\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image to the desired size.\n    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\ndef process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","c960eddf":"# Set `num_parallel_calls` so multiple images are loaded\/processed in parallel.\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nfor image, label in labeled_ds.take(2):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","900b596b":"train_ds = labeled_ds.take(np.ceil(3233*0.7)) \ntest_ds = labeled_ds.take(np.ceil(3233*0.7))\n\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())\n    \nfor image, label in test_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())\n","69468e6d":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=300):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    ds = ds.repeat()\n\n    ds = ds.batch(BATCH_TRAIN_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","68abab3e":"train_dsfinal = prepare_for_training(train_ds)\ntest_dsfinal = prepare_for_training(test_ds)","0d404fe8":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n      plt.axis('off')","2709dad4":"image_batch, label_batch = next(iter(train_dsfinal))\n\nshow_batch(image_batch.numpy(), label_batch.numpy())","41a6706f":"label_batch.shape\nprint(label_batch)","549571cc":"class CNNModel():\n    def __init__(self):\n        self.inputs = tf.keras.Input(shape=(224,224,3))\n        self.x1= tf.keras.layers.Conv2D(32 , 3, activation='relu')(self.inputs)\n        self.x1= tf.keras.layers.Conv2D(64, 3, activation='relu')(self.x1)\n        self.x1= tf.keras.layers.MaxPooling2D(2,2)(self.x1)\n        \n        self.x2= tf.keras.layers.Conv2D(32, 3, activation='relu')(self.x1)\n        self.x2= tf.keras.layers.Conv2D(64, 3, activation='relu')(self.x2)\n        self.x2= tf.keras.layers.MaxPooling2D(3,3)(self.x2)\n        \n        self.x3= tf.keras.layers.Conv2D(32, 3, activation='relu')(self.x2)\n        self.x3= tf.keras.layers.MaxPooling2D(2,2)(self.x3)\n        self.x = tf.keras.layers.Dropout(0.2)(self.x3)\n        \n        self.output = tf.keras.layers.Flatten()(self.x)\n        self.output = tf.keras.layers.Dense(224, activation='relu')(self.output)\n        self.output = tf.keras.layers.Dense(6, activation='softmax')(self.output) \n\n        self.model = tf.keras.Model(self.inputs, self.output)\n        \n        \n\n    def compile_cnn(self):\n        self.model.summary()\n        self.model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.RMSprop(lr=0.001), metrics=['accuracy'])\n        \n    def fit(self, dataset, n_epochs):\n        self.model.fit(\n            dataset,\n            steps_per_epoch=STEPS_PER_EPOCH,\n            epochs=n_epochs,\n            validation_data=test_dsfinal,\n            validation_steps=200\n        )\n\n# Create an instance of the model\nmodel = CNNModel()","b9574db8":"model.compile_cnn()","43452319":"history = model.fit(dataset = train_dsfinal, n_epochs = EPOCHS)","e7440469":"acc = model.model.history.history['accuracy']\nval_acc = model.model.history.history['val_accuracy']\n\nloss = model.model.history.history['loss']\nval_loss = model.model.history.history['val_loss']\n\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","7e1986b2":"model.model.evaluate(test_dsfinal, verbose=2, steps=64)","b70bb948":"model.model.save(\"model2.h5\")","0d38d585":"!pip install tensorflowjs","64dbb05a":"!tensorflowjs_converter --input_format keras model2.h5 tfjs\/model","56b0b183":"###### CNN on a 6 class problem on images\n\nConvolutional Neural Network on a to determine cheese types\n","5a77990b":"### Building model\n\nCNN model","ccc79601":"### Loading data\n\n- Using keras.preprocessing","48fdc281":"## Initialisation variables","d410df98":"Shuffle and batch the data for training"}}