{"cell_type":{"f97a2f7a":"code","9e52759a":"code","407b1dd2":"code","e6235eae":"code","bac610af":"code","9eaaac3e":"code","53a862ad":"code","106f895e":"code","62e5a399":"code","5e29eeb4":"code","197bac49":"code","04c97140":"code","aad5ef44":"code","980dbc7e":"code","e3829ba5":"code","5f0bd814":"code","b6fe9902":"code","cb5d9e22":"code","b68f979f":"code","4c8777d0":"code","6aed7faa":"code","bc9e5b8e":"code","781efed9":"code","2a949f8b":"code","98cd65cf":"code","2ff8c784":"code","0f7d4d9a":"code","4ace0e63":"code","9957129d":"code","1a87e7d0":"code","ed2f4228":"code","cfc934cc":"code","727af3a7":"code","51dc13dc":"code","9b0ade61":"code","b352572a":"code","90002bb5":"code","59e0fe7b":"code","22ed7820":"code","b35aa429":"code","71a1601f":"code","9c74ecb1":"code","56c46aa8":"markdown","4cd81125":"markdown","7f4f0dd6":"markdown","920e6a85":"markdown","ed1daa18":"markdown","0562fc08":"markdown","2a38e25e":"markdown","69671253":"markdown","1a5cdb5b":"markdown","8294c636":"markdown","ff9340d3":"markdown","0cb65867":"markdown","804da6ed":"markdown","154a9b6e":"markdown","19622450":"markdown","5777cf75":"markdown","b7fd81d7":"markdown","aff1812d":"markdown","a211c6a4":"markdown","40906752":"markdown","955b9054":"markdown","4784c3a3":"markdown"},"source":{"f97a2f7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e52759a":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nsns.set_style(\"whitegrid\")","407b1dd2":"data = pd.read_csv('\/kaggle\/input\/car-dekho-data\/car data.csv')\ndata.head()","e6235eae":"data.info()","bac610af":"df_num = data.select_dtypes(include=[np.float64, np.int64])\nprint(\"Columns with numerical data:\")\nfor col in df_num.columns:\n    print(col)","9eaaac3e":"df_cat = data.select_dtypes(include = ['object'])\nprint(\"Columns with categorical data:\")\nfor col in df_cat.columns:\n    print(col)","53a862ad":"data.describe()","106f895e":"# Correlation between numerical columns\nplt.figure(figsize = (10,8))\nsns.heatmap(data.corr(), annot = True)","62e5a399":"def plot_bar(column):\n    plt.figure(figsize = (12,5))\n    sns.countplot(data[column])\n    plt.title(column, fontsize = 20)\n    plt.xticks(fontsize = 14)\n    plt.xlabel('')\n    plt.show()","5e29eeb4":"for col in ['company','Fuel_Type','Seller_Type','Transmission']:\n    plot_bar(col)","197bac49":"def plot_hist(column):\n    plt.figure(figsize = (12,5))\n    sns.distplot(data[column])\n    plt.title(column, fontsize = 20)","04c97140":"for col in ['Year','Selling_Price','Present_Price','Kms_Driven']:\n    plot_hist(col)","aad5ef44":"print(\"Car sold by Owner number\\n{}\".format(data[\"Owner\"].value_counts()))","980dbc7e":"print(\"Number of cars sold through dealers: {}\".format(data.loc[data.Seller_Type == 'Dealer']['Seller_Type'].value_counts().sum()))\nprint(\"Number of cars sold without dealers: {}\".format(data.loc[data.Seller_Type == 'Individual']['Seller_Type'].value_counts().sum()))","e3829ba5":"print(\"Total number of cars with manual transmission: {}\".format(data.loc[data.Transmission == 'Manual']['Car_Name'].value_counts().sum()))\nprint(\"Total number of cars with automatic transmission : {}\".format(data.loc[data.Transmission == 'Automatic']['Car_Name'].value_counts().sum()))","5f0bd814":"print(\"Most Popular car Companys\\n{}\".format(data[\"company\"].value_counts()))","b6fe9902":"print(\"Most sold cars\\n{}\".format(data[\"Car_Name\"].value_counts().nlargest(15)))","cb5d9e22":"plt.figure(figsize = (10,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Seller_Type\"])\nplt.ylabel(\"Seller_Type\",fontsize = 15)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","b68f979f":"plt.figure(figsize = (12,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Fuel_Type\"])\nplt.ylabel(\"Fuel Type\",fontsize = 15)\nplt.yticks(fontsize = 14)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","4c8777d0":"plt.figure(figsize = (12,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Transmission\"])\nplt.ylabel(\"Transmission\",fontsize = 15)\nplt.yticks(fontsize = 14)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","6aed7faa":"keys = [year for year, df in data.groupby([\"Year\"])]\nplt.figure(figsize = (14,8))\nsns.barplot(keys, data.groupby([\"Year\"]).count()[\"Car_Name\"])\nplt.xlabel(\"Year\",fontsize = 15)\nplt.ylabel(\"Number of car sold\",fontsize = 15)","bc9e5b8e":"data['Car_Name'].value_counts().nlargest(10).plot(kind = 'bar', figsize = (14,8))","781efed9":"fig, axes = plt.subplots(1,3, figsize = (18,7))\ndf = data.loc[~data.company.isin(['bajaj','hero','yamaha','tvs'])]\ndf1 = data.loc[data.company.isin(['bajaj','hero','yamaha','tvs'])]\nsns.histplot(data[\"Selling_Price\"], ax = axes[0])\nsns.histplot(df[\"Selling_Price\"], ax = axes[1])\nsns.histplot(df1[\"Selling_Price\"], ax = axes[2])","2a949f8b":"plt.figure(figsize = (10,7))\nsns.histplot(df[\"Selling_Price\"], color = 'blue',label = 'Cars')\nsns.histplot(df1[\"Selling_Price\"], color = 'red', label = 'Two whellers')","98cd65cf":"# Chosing some features to train  the models on\nX = data.loc[:,[\"Year\",\"Kms_Driven\",\"Fuel_Type\",\"Seller_Type\",\"Transmission\",\"Owner\"]]\ny = data.loc[:,['Selling_Price']]","2ff8c784":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","0f7d4d9a":"# Applying Label Encoding \nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor col in ['Fuel_Type','Seller_Type','Transmission']:\n    X_train[col] = encoder.fit_transform(X_train[col])\n    X_test[col] = encoder.transform(X_test[col])","4ace0e63":"X_train.head(10)","9957129d":"# Applying Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train.loc[:,['Year','Kms_Driven']] = scaler.fit_transform(X_train.loc[:,['Year','Kms_Driven']])\nX_test.loc[:,['Year','Kms_Driven']] = scaler.transform(X_test.loc[:,['Year','Kms_Driven']])","1a87e7d0":"# Cross Validation\nfrom sklearn.model_selection import cross_val_score\ndef val_score(model, X, y):\n    score = -1*cross_val_score(model, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n    print(\"RMSE  : {}\".format(np.sqrt(score)))\n    print(\"Average error : {}\".format(np.sqrt(score.mean())))","ed2f4228":"from sklearn.metrics import mean_squared_error\ndef plot_learning_curves(model, X, y, ylim = None):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n    train_errors, val_errors = [], []\n    for m in range(1, len(X_train)):\n        model.fit(X_train[:m], y_train[:m])\n        y_train_predict = model.predict(X_train[:m])\n        y_val_predict = model.predict(X_val)\n        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n        val_errors.append(mean_squared_error(y_val_predict, y_val))\n    plt.figure(figsize = (10,7))\n    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n    plt.xlabel(\"Training set size\")\n    plt.ylabel(\"RMSE\")\n    plt.ylim(ylim)\n    plt.legend()","cfc934cc":"from sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\nval_score(linear_reg, X_train, y_train)\nplot_learning_curves(linear_reg, X_train, y_train)","727af3a7":"# Error of Decision Tree on train set and Test set\nlinear_reg.fit(X_train, y_train)\n\nprediction_train = linear_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = linear_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","51dc13dc":"from sklearn.svm import LinearSVR\nlinear_svr = LinearSVR()\nval_score(linear_svr, X_train, y_train)\nplot_learning_curves(linear_svr, X_train, y_train)","9b0ade61":"from sklearn.svm import SVR\nsvr_reg = SVR(kernel = 'rbf')\nval_score(svr_reg, X_train, y_train)\nplot_learning_curves(svr_reg, X_train, y_train)","b352572a":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\nval_score(tree_reg, X_train, y_train)\nplot_learning_curves(tree_reg, X_train, y_train)","90002bb5":"# Error of Decision Tree on train set and Test set\ntree_reg.fit(X_train, y_train)\n\nprediction_train = tree_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = tree_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","59e0fe7b":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nval_score(rf_reg, X_train, y_train)\nplot_learning_curves(rf_reg, X_train, y_train)","22ed7820":"# Error of Random Forest on train set and Test set\nrf_reg.fit(X_train, y_train)\n\nprediction_train = rf_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = rf_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","b35aa429":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n{'n_estimators': [3, 10, 30, 100, 300], 'max_features': [2, 4, 6, 8,10]},\n{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n]\nforest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=3,\nscoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)","71a1601f":"print(\"Best parameters\",grid_search.best_params_)\nprint(\"Best Estimators\",grid_search.best_estimator_)","9c74ecb1":"forest_reg = RandomForestRegressor(max_features = 2, n_estimators = 30)\nforest_reg.fit(X_train, y_train)\n\nprediction_train = forest_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = forest_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","56c46aa8":"There is strong correlation between Present Price of car and Selling Price of car which is obvious. Also there is good correlation between Year and Selling Price","4cd81125":"### Learning Curve of Random Forest model seems better. Adding more data can make it better as its curves are going down","7f4f0dd6":"#### Data After Applying Label Encoder becomes numerical. Because Linear Regression and SVM models don't work on categorical data.","920e6a85":"Most of Car sold by dealers generally get higher Price than sold by individuals","ed1daa18":"Petrol Type car are most sold but price of diesel car is higher than others.","0562fc08":"## Testing Models perfomance with their default features","2a38e25e":"More than 250 car sold are manual while less than 50 are Automatic","69671253":"### Random Forest seems best model according to learning curves. \n### So let's apply grid search to chose best hyperparameters for it.","1a5cdb5b":"## 3.SVM Kernel","8294c636":"Most of car sold have only one previous owner. ","ff9340d3":"## 2.SVM Linear","0cb65867":"It is Clear from boxplot that generally Diesel Type car are sold at higher price. Mean selling Price of Diesel Price is higher than Petrol type cars . While Boxplot of CNG cars is like a line, it shows only few CNG car are sold","804da6ed":"Car are sold generally through a dealer","154a9b6e":"### This Model is also underfitting, as train error and test error both are high.SVM Kernel works better when training data have more features","19622450":"### Bivariate Data Analysis","5777cf75":"### Preparing Data","b7fd81d7":"## 1.Linear Regression","aff1812d":"Car with automatic transmission have a large range of sales and third quarter of it is quite big. It shows that many of cars sold falls in this range. There is in comprasion small difference between median of Manual and Automatic Cars, because some Manual Car are sold at very high Price.","a211c6a4":"### Clearly Linear Regression model is Underfiting as train error is greater than val error","40906752":"### Decision Tree is too complex and overfitting. It predicts nearly perfect values for Train data but performing very poor on test data. Using more data and hyperparameters tunning  can make it better.","955b9054":"### Univarate data Analysis of data","4784c3a3":"### Basic Analysis"}}