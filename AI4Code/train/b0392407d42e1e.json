{"cell_type":{"9c90e5a4":"code","23ab0dec":"code","0f9c2b25":"code","da53ab19":"code","9c699c86":"code","2cb7e92d":"code","41189bda":"code","cfaa34c2":"code","43318bec":"code","f29d9f87":"code","a14bbb99":"code","0247eaf0":"code","b6608b15":"code","299beab9":"code","68fe2406":"code","e08ef594":"code","21cbf4e4":"code","185336f7":"code","5a5d90d9":"code","11fa4914":"code","5f2b7270":"code","e8efe6b8":"code","e2078434":"code","b4df3d09":"code","311454fa":"code","08ae2b6d":"code","3e78a7c8":"code","2f857f09":"code","f893bd06":"code","e374b854":"code","4c65f55e":"code","fcbe8585":"code","8fce3385":"code","f6118161":"code","b0a9acb3":"code","8c8da994":"code","e67dd819":"code","5aa185ff":"code","91150ea4":"code","d9caa3f6":"code","83bcbb41":"code","14ca3184":"code","f779974d":"code","f931859f":"code","f1578a68":"code","4695505a":"code","76959967":"code","e02cc8ee":"code","6ec36fd5":"code","2ef03f31":"code","80c1588b":"code","01ced0ea":"code","5454477d":"code","50b369a8":"code","5bdbad22":"code","10ab2ff8":"code","0273e120":"code","f5a579f8":"code","663e4ab3":"code","dad4e8f2":"code","04f8d8c9":"code","4a0eba43":"code","e5ef2df4":"code","aa6be3ec":"code","14c82bf7":"code","907e7738":"code","a827b8c6":"code","b9ce3735":"code","5909ee3a":"code","4445ede7":"markdown","8ab4b728":"markdown","e26911b9":"markdown","582a14b9":"markdown","29d891b4":"markdown","1221e56a":"markdown","b372a2f4":"markdown","b8d8898b":"markdown","69fbc510":"markdown","e1c794d6":"markdown","0e66c432":"markdown","40db4c2a":"markdown","20de37ff":"markdown","c2a344af":"markdown","1a51c742":"markdown","4f7e7f0f":"markdown","88616660":"markdown","680a1dd2":"markdown","45d9163a":"markdown","b075c9a2":"markdown","89d69e9d":"markdown","10e2aee8":"markdown","6ec25e5e":"markdown","b4957ac6":"markdown","85e73d5f":"markdown","b1002675":"markdown","ce7718ce":"markdown","017c3407":"markdown","df1f8320":"markdown","07342b3b":"markdown","a0b8bd18":"markdown","2597f97d":"markdown","d8ad87e8":"markdown","bfb18c9d":"markdown","160bb68c":"markdown","8fcc3416":"markdown","99776181":"markdown","11bdb648":"markdown","82bc2cf1":"markdown","8fcadeb3":"markdown","5aa9788a":"markdown","d2a08f80":"markdown","8f5d878a":"markdown","0a338ea4":"markdown","1a94b06a":"markdown","00ebe002":"markdown","988f74c7":"markdown","ea8f456b":"markdown","f4d9f55d":"markdown","87c4f116":"markdown","ac4c57d7":"markdown","926a68d7":"markdown","0389383e":"markdown","30a64431":"markdown","508843d8":"markdown","bb455d85":"markdown","8955c8c3":"markdown","6eb10478":"markdown","ec650f1b":"markdown","b6e8cbc4":"markdown","48e89194":"markdown","6c598158":"markdown","4924375d":"markdown","01dd7448":"markdown","a0963aff":"markdown","c9dec33a":"markdown","58584e7d":"markdown","058d0e03":"markdown","792f4c69":"markdown","11672e2e":"markdown","aea54014":"markdown","5c47d1c1":"markdown","2b9229c9":"markdown","c06ae4b2":"markdown","bc562cfb":"markdown","dc974033":"markdown","a758a9d5":"markdown","107eb59a":"markdown","69de5367":"markdown","18a10580":"markdown","8da9321a":"markdown","ce3de287":"markdown"},"source":{"9c90e5a4":"import os \n\n# For Loading and Manipulating data\nimport pandas as pd\nimport numpy as np\n\n# For visualization purposes\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# To change the style of the plots ( so that we all can see the same thing :) )\nplt.style.use('seaborn')\n\n# for coloring the printed output\nfrom termcolor import colored","23ab0dec":"def show_missing(dataframe):\n    \"\"\"\n    This function helps you to know the count and percentage of the missing values in each column in the given dataframe\n    \n    Args:\n    dataframe: the dataframe we want to investigate the NaNs on\n    \n    Returns:\n    missing_data: a dataframe which has:\n                     1- index of the columns names \n                     2- two columns: the count and percentage of the NaNs of that column\n    \"\"\"\n    missing_values = dataframe.isnull().sum()\n    missing_data = pd.DataFrame({'Count':missing_values.values,\n                                 'Percentage':(missing_values.values*100.00 \/ dataframe.shape[0]).round(2)}, \n                                  index=missing_values.index)\n    \n    \n    return missing_data\n\n#===========================================================================================================================#\n\ndef show_countplot(dataframe, x, y, hue=None, order=None, title='Title', x_rotation=0):\n    \"\"\"\n    In addition to plotting countplot, This function adds the percentage of each category above its bar.\n    \n    Args:\n    dataframe: the dataframe we want to work on\n    x: if we want to work on x-axis\n    y: if we want to work on y-axis\n    hue: if we want to add a third feature\n    order: to sepecify the order the bars will be displayed by\n    title: the title of the plot\n    x_rotation: to rotate x ticks if we wanted\n\n    \"\"\"  \n    ax = sns.countplot(data=dataframe, x=x, y=y, order=order, hue=hue, color='#4d83de')\n   \n    plt.title(title, fontsize=20, color='brown')\n    \n    plt.xlabel(x.title() if x else 'Count', fontsize=15)\n    plt.xticks(rotation=x_rotation, fontsize=12)\n    plt.ylabel(y.title() if y else 'Count', fontsize=15)\n    plt.yticks(fontsize=12)\n    \n    total = dataframe.shape[0]\n    for patch in ax.patches:\n        loc = patch.get_x() if x else patch.get_y()\n        width = patch.get_width()\n        height = patch.get_height()\n        \n        # text location\n        loc_x = (loc+width\/2) if x else (width*0.5)\n        loc_y = (height*0.5) if x else (loc+height\/2)\n        \n        # text\n        percent = (height*100\/total) if x else (width*100\/total)\n        \n        ax.text(loc_x, loc_y, f'{percent:.2f}%', ha='center', weight='bold', fontsize=10, color='white')\n\n#==============================================================================================================================#\n#------------------------------------------------------------------------------------------------------------------------------#\n# Note: the following functions may be a little vague right now but after seeing how we've used them every thing will be clear\n#------------------------------------------------------------------------------------------------------------------------------#\n#==============================================================================================================================#\n\ndef fill_it(product_name, sector, PEF):\n    \"\"\"\n    Filling the specified row by its approximated value\n    \n    Args:\n    product_name: to specify which row we're working on\n    sector: the approximated value of the sector for this product\n    PEF: the approximated value of the primary essential function for this product\n    \"\"\"\n    global products_info\n    products_info.loc[products_info['Product Name']==product_name, 'Sector(s)'] = sector\n    products_info.loc[products_info['Product Name']==product_name, 'Primary Essential Function'] = PEF\n\n    \ndef remove_it(product_name):\n    \"\"\"\n    Removing the specified row\n    \n    Args:\n    product_name: to specify which row we're working on\n    \"\"\"\n    global products_info\n    products_info = products_info[products_info['Product Name']!=product_name].copy()\n    \n#=================================================================================================================#\n\ndef eng_data():\n    \"\"\"\n    A function to generate the files of engagement data folder\n    \"\"\"\n    path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\n    files = os.listdir(path)\n\n    for file in files:\n        df = pd.read_csv(os.path.join(path,file))\n        \n        yield df\n        \n\ndef fill_data(data):\n    \"\"\"\n    A function that fill the NaNs of each generated file\n    \"\"\"\n    # If the product id does not exist then the whole record is not important \n    data.dropna(subset=['lp_id'], inplace=True)\n    \n    # if the id does exist but there is no information about it then also the whole column is not important\n    data.dropna(subset=['pct_access', 'engagement_index'], how='all', inplace=True)\n    \n    # if only one value in the row is missing we will fill it with \"-1\"\n    data.fillna(-1, inplace=True)\n    \n#=============================================================================================================#\n\ndef show_plots(dataframe, feature, title='Title'): \n    \"\"\"\n    This function helps us in the visualization stage\n    \n    Args:\n    dataframe: the dataframe we want to work on\n    feature: the feature we want to visualize\n    title: the title for the plot\n    \"\"\"\n    fig = plt.figure(figsize=(25,35))\n    fig.suptitle(title, fontsize=30, weight='bold', y=0.91)\n    \n    for i, product in enumerate(dataframe['Product Name'].unique()):\n        data = dataframe[dataframe['Product Name']==product]\n        data = data.groupby('month')[feature].mean()\n\n        plt.subplot(5, 4, i+1)\n        plt.plot(data.index, data.values)\n        plt.title(product, color='brown')\n        plt.xticks(ticks=range(1,13), labels=range(1, 13));  \n\n#=================================================================================================================#\n\ndef check(product):\n    \"\"\"\n    This function checks if the given series has all the months or not and if not it adds them.\n    \n    Args:\n    product: the row that we're working on\n    \n    Returns:\n    The modified Series (that has all the months in it)\n    \"\"\"\n    missing_months = sorted(set(range(1, 13)) - set(product.index))\n    product = product.values\n    for mm in missing_months:\n        product = np.insert(product, mm-1, 0)\n        \n    return pd.Series(product, index=range(1, 13))\n\n#=================================================================================================================#\n\ndef investigate(feature, size, title, order=None):  \n    \"\"\"\n    This function helps us in the visualization stage like 'show_plots' function\n    \n    Args:\n    feature: the feature we want to plot\n    size: the size of the plot\n    title: the title of the plot\n    order: the order of the bars\n    \"\"\"\n    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=size)\n    fig.suptitle(title, fontsize=30, weight='bold', y=0.93)\n\n    for i, subset in enumerate(to_investigate): \n        fig.sca(axes[i])\n        sub_df = districts_info[districts_info['state'].isin(subset)].copy()\n\n        show_countplot(sub_df, x=feature, y=None, order=order, title=titles[i])","0f9c2b25":"# reading the data\nproducts_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\nproducts_info.head()","da53ab19":"# get more info\nproducts_info.info()","9c699c86":"# investigating the missing values\nshow_missing(products_info)","2cb7e92d":"# Last but not least, Is there any duplicates?\nproducts_info.duplicated().sum()","41189bda":"# let's take a closer look at these 20 NaNs\nproducts_info[products_info['Sector(s)'].isnull()]","cfaa34c2":"# http:\/\/www.ixl.com\/\nfill_it('IXL Language', 'PreK-12', 'LC - Digital Learning Platforms')\n\n# https:\/\/www.yelp.com\/\n# It's not something for learning\nremove_it('Yelp')\n\n# http:\/\/www.learnplatform.com\/\nfill_it('LearnPlatform', 'PreK-12; Corporate', 'SDO - Data, Analytics & Reporting - Student Information Systems (SIS)')\n\n# http:\/\/genius.com\/static\/education\n# It's not something for learning\nremove_it('Education Genius')\n\n# http:\/\/www.microsoft.com\/en-us\/education\/products\/office\/default.aspx\nfill_it('Microsoft Office 365', 'PreK-12; Higher Ed; Corporate', 'LC - Study Tools')\n\n# http:\/\/www.classzone.com\/cz\/index.htm\n# It has been retired and is no longer accessible\nremove_it('ClassZone')\n\n# http:\/\/student.classdojo.com\/#\/login\nfill_it('ClassDojo for Students', 'PreK-12; Higher Ed', 'CM - Classroom Engagement & Instruction - Assessment & Classroom Response')\n\n# https:\/\/play.google.com\/music\/listen?u=0#\/sulp\n# Google Play Music is no longer available\nremove_it('Google Play Music')\n\n# https:\/\/sciencejournal.withgoogle.com\/\nfill_it('Google Science Journal', 'PreK-12; Higher Ed', 'LC - Study Tools - Tutoring')\n\n# https:\/\/edutrainingcenter.withgoogle.com\/\n# It is no longer available\nremove_it('Google Training Center')\n\n# https:\/\/info.flipgrid.com\/\nfill_it('Flipgrid One', 'PreK-12; Higher Ed; Corporate', 'CM - Virtual Classroom - Video Conferencing & Screen Sharing')\n\n# https:\/\/spark.adobe.com\/about\/page\n# It's not something for learning\nremove_it('Adobe Spark Page')\n\n# https:\/\/www.usnews.com\/best-colleges\/myfit\nfill_it('College Compass', 'Higher Ed; Corporate', 'SDO - Data, Analytics & Reporting - Site Hosting & Data Warehousing')\n\n# https:\/\/chrome.google.com\/webstore\/detail\/grammarly-for-chrome\/kbfnbcaeplbcioakkpcpgfkobkghlhen?hl=en\nfill_it('Grammarly for Chrome', 'PreK-12; Higher Ed; Corporate', 'LC - Content Creation & Curation')\n\n# https:\/\/www.maxpreps.com\/state\/connecticut.htm\n# It is no longer available\nremove_it('MaxPreps: Connecticut')\n\n# https:\/\/www.ducksters.com\/history\/\nfill_it('History for Kids', 'PreK-12', 'LC - Digital Learning Platforms')\n\n# https:\/\/safeyoutube.net\/\n# It is no longer accessible\nremove_it('SafeYouTube')\n\n# https:\/\/studio.code.org\nfill_it('Studio Code', 'PreK-12; Higher Ed', 'LC - Sites, Resources & Reference - Games & Simulations')\n\n# http:\/\/edpuzzle.com\nfill_it('Edpuzzle - Free (Basic Plan)', 'PreK-12; Higher Ed; Corporate', 'LC - Sites, Resources & Reference - Digital Collection & Repository')\n\n# http:\/\/www.truenorthlogic.com\/\n# It is no longer accessible\nremove_it('True North Logic')","43318bec":"show_missing(products_info)","f29d9f87":"# Remove useless columns\nproducts_info.drop('URL', axis=1, inplace=True)","a14bbb99":"# reading the data\ndistricts_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\ndistricts_info.head()","0247eaf0":"# get more info\ndistricts_info.info()","b6608b15":"show_missing(districts_info)","299beab9":"districts_info.duplicated().sum()","68fe2406":"# let's drop the rows that has NaNs in all the columns except for the district id\ndistricts_info = districts_info.dropna(how='all', subset=['state', 'locale', 'pct_black\/hispanic', 'pct_free\/reduced',\n                                                          'county_connections_ratio', 'pp_total_raw']) ","e08ef594":"districts_info.fillna(\"Unknown\", inplace=True)","21cbf4e4":"show_missing(districts_info)","185336f7":"to_merge = []           # putting the engagement data in one place for concatenation\neng_df = eng_data()     # defining the generator","5a5d90d9":"for data in eng_df:\n    fill_data(data)            # filling the NaNs\n    to_merge.append(data)\n    \nall_eng = pd.concat(to_merge)","11fa4914":"all_eng.head()","5f2b7270":"all_eng.info()","e8efe6b8":"# Check\nshow_missing(all_eng)","e2078434":"# Checking duplicates\nall_eng.duplicated().sum()","b4df3d09":"all_eng['time'] = pd.to_datetime(all_eng['time'])","311454fa":"all_eng.info()","08ae2b6d":"# droping duplicates\nall_eng.drop_duplicates(inplace=True)","3e78a7c8":"# duplicates\nall_eng.duplicated().sum()","2f857f09":"eng_product_merge = pd.merge(all_eng, products_info, left_on='lp_id',right_on='LP ID',how='inner').drop(columns='LP ID')\neng_product_merge.head()","f893bd06":"eng_product_merge.info()","e374b854":"eng_product_merge['month'] = eng_product_merge['time'].dt.month\neng_product_merge.head()","4c65f55e":"products_info['Provider\/Company Name'].nunique()","fcbe8585":"# Flip it\norder = products_info['Provider\/Company Name'].value_counts().index[:20]\n\nplt.figure(figsize=(15, 12))\nshow_countplot(products_info, x=None, y='Provider\/Company Name', order=order, title='Provide\/Company Name')","8fce3385":"sectors = eng_product_merge['Sector(s)'].str.split(';',expand=True)\n\n# removing unnecessary spaces\nfor col in sectors.columns:\n    sectors[col] = sectors[col].str.strip()\n\n# Counting the occurences of each sector in each column \ndic={}\nfor col in sectors.columns:\n    dic[col]=(dict(sectors[col].value_counts()))\n\n# Summing all together\nsectors = pd.DataFrame(dic)\nsectors_count = pd.DataFrame(sectors.fillna(0).values.sum(axis=1), index=sectors.index, columns=['Count'])\nsectors_count","f6118161":"plt.pie(sectors_count.values.ravel(), labels=sectors_count.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14})\n\nplt.title('Sector(s)', fontsize=15, color='brown');","b0a9acb3":"del sectors, sectors_count","8c8da994":"# Let's get the primary eseential function main categories ['LC', 'SDO', 'CM'] alone \neng_product_merge['PEF'] = eng_product_merge['Primary Essential Function'].str.split('-')\neng_product_merge['PEF'] = eng_product_merge['PEF'].apply(lambda x: x[0])\neng_product_merge['PEF'] = eng_product_merge['PEF'].str.strip()","e67dd819":"pef_count = eng_product_merge['PEF'].value_counts()\n\nplt.figure(figsize=(8, 8))\nplt.pie(pef_count.values, labels=pef_count.index, startangle = 90, autopct='%1.2f%%', \n                 counterclock = False, radius = 1.2, textprops={'fontsize': 14});\n\nplt.title('Primary Essential Function', fontsize=15, color='brown', y=1.1);","5aa185ff":"eng_product_merge['sub_PEF'] = eng_product_merge['Primary Essential Function'].str.split('-')\neng_product_merge['sub_PEF'] = eng_product_merge['sub_PEF'].apply(lambda y: ' '.join(map(lambda x: x.strip(), y[1:])))","91150ea4":"fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 25))\n\nfig.suptitle('Subcategories of each Primary Essential Function main categories', fontsize=25, y=0.92, x=0.3)\n\nfor i, pef in enumerate(['LC', 'CM', 'SDO']):\n    fig.sca(axes[i])\n    \n    temp = eng_product_merge[eng_product_merge['PEF']==pef].copy()\n    order = temp['sub_PEF'].value_counts().index\n    \n    show_countplot(temp, x=None, y='sub_PEF', order=order, title=pef)","d9caa3f6":"fig, axes =  plt.subplots(6, 1, figsize=(25,65))\nfig.suptitle('Districts Info', fontsize=25, y=0.9)\naxes = axes.ravel()\n\n# which axes to plot on\nto_plot=[(None, 'state'),\n         ('locale', None),\n         ('pct_black\/hispanic', None),\n         ('pct_free\/reduced', None),\n         ('county_connections_ratio', None),\n         ('pp_total_raw', None)]\n\nfor i,col in enumerate(districts_info.columns[1:]):\n    fig.sca(axes[i])\n    \n    order=districts_info[col].value_counts().index\n    show_countplot(districts_info, x=to_plot[i][0], y=to_plot[i][1], order=order, title=f'{col.title()} Percentage')","83bcbb41":"districts_info.drop('county_connections_ratio', axis=1, inplace=True)","14ca3184":"all_eng_copy = all_eng.set_index('time')\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(15, 12))\n\nfor i, col in enumerate(['engagement_index', 'pct_access']):\n    fig.sca(axes[i])\n    all_eng_copy[col].plot()\n    plt.title(col, fontsize=15, color='brown')\n\nplt.tight_layout()\ndel all_eng_copy","f779974d":"corr = all_eng['engagement_index'].corr(all_eng['pct_access'])\n\nprint(f\"Pearson's correlation between engagement index and perecentage access is: {colored(corr, 'green')}\")","f931859f":"top_products = eng_product_merge.groupby('Product Name')['engagement_index'].mean().sort_values(ascending=False)\ntop_10=pd.DataFrame(top_products[:10])\n\nplt.figure(figsize=(15,9))\n\nsns.barplot(x=top_10['engagement_index'],y=top_10.index, color='#4d83de')\nplt.title('Top 10 Products', color='brown', fontsize=15)\nplt.xlabel('Engagment Index', fontsize=12)\nplt.ylabel('Product Name', fontsize=12)\n\ndel top_products","f1578a68":"# number of products we have\neng_product_merge['Product Name'].nunique()","4695505a":"np.random.seed(42)      # to have a consistent output every time we run the code\n\nsampled_products = np.random.choice(eng_product_merge['Product Name'].unique(), size=20, replace=False)\nsampled_products = eng_product_merge[eng_product_merge['Product Name'].isin(sampled_products)].copy()","76959967":"show_plots(sampled_products, 'engagement_index', title='Engagement Index for 20 random sampled products')","e02cc8ee":"show_plots(sampled_products, 'pct_access',title='Percentage Access for 20 random sampled products')","6ec36fd5":"# For memory usage\ndel sampled_products","2ef03f31":"trunc_df = eng_product_merge[eng_product_merge['PEF']=='LC'].copy()\n\n#Let's take the 20 most used products for \"LC\" category and analyse their usage along the year\nsampled_products = trunc_df['Product Name'].value_counts().index[:20]\nsampled_products = trunc_df[trunc_df['Product Name'].isin(sampled_products)].copy()\n    \nshow_plots(sampled_products, 'engagement_index', title='LC: Engagement Index for 20 random sampled products')\n\n# for memory usage\ndel sampled_products, trunc_df","80c1588b":"trunc_df = eng_product_merge[eng_product_merge['PEF']=='CM'].copy()\n\n#Let's take the 20 most used products for \"LC\" category and analyse their usage along the year\nsampled_products = trunc_df['Product Name'].value_counts().index[:20]\nsampled_products = trunc_df[trunc_df['Product Name'].isin(sampled_products)].copy()\n    \nshow_plots(sampled_products, 'engagement_index', title='CM: Engagement Index for 20 random sampled products')\n\n# for memory usage\ndel sampled_products, trunc_df","01ced0ea":"trunc_df = eng_product_merge[eng_product_merge['PEF']=='SDO'].copy()\n\n#Let's take the 20 most used products for \"LC\" category and analyse their usage along the year\nsampled_products = trunc_df['Product Name'].value_counts().index[:20]\nsampled_products = trunc_df[trunc_df['Product Name'].isin(sampled_products)].copy()\n    \nshow_plots(sampled_products, 'engagement_index', title='SDO: Engagement Index for 20 random sampled products')\n\n# for memory usage\ndel sampled_products","5454477d":"colors = ['red', 'blue', 'green']\n\nfig = plt.figure(figsize=(15,20))\nfig.suptitle('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites', fontsize=30, weight='bold', y=0.93)\n\nfor i, pef in enumerate(['LC', 'CM', 'SDO']):\n    trunc_df = eng_product_merge[eng_product_merge['PEF']==pef].copy()\n    \n    most_used = trunc_df['Product Name'].value_counts().index[:20]\n    \n    plt.subplot(3, 1, i+1)\n    for product in most_used:\n        product_list = trunc_df[trunc_df['Product Name']== product].groupby('month')['pct_access'].mean()\n        plt.plot(product_list.index, product_list.values, color=colors[i]);\n    \n    plt.title(pef, fontsize=20, color='brown')\n    plt.xticks(ticks=range(1,13), labels=range(1, 13));","50b369a8":"colors = ['red', 'blue', 'green']\n\nfig = plt.figure(figsize=(15,20))\nfig.suptitle('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites', fontsize=30, weight='bold', y=0.93)\n\nfor i, pef in enumerate(['LC', 'CM', 'SDO']):\n    trunc_df = eng_product_merge[eng_product_merge['PEF']==pef].copy()\n    \n    most_used = trunc_df['Product Name'].value_counts().index[:20]\n    \n    plt.subplot(3, 1, i+1)\n    for product in most_used:\n        product_list = trunc_df[trunc_df['Product Name']== product].groupby('month')['lp_id'].count()\n        plt.plot(product_list.index, product_list.values, color=colors[i]);\n    \n    plt.title(pef, fontsize=20, color='brown')\n    plt.xticks(ticks=range(1,13), labels=range(1, 13));","5bdbad22":"colors = ['red', 'blue', 'green']\n\nfig = plt.figure(figsize=(12,7))\n\nfor i, pef in enumerate(['LC', 'CM', 'SDO']):\n    trunc_df = eng_product_merge[eng_product_merge['PEF']==pef].copy()\n\n    most_used = trunc_df['Product Name'].value_counts().index[:20]\n    \n    product_month = {}\n    for product in most_used:\n        product_month[product] = trunc_df[trunc_df['Product Name']== product].groupby('month')['lp_id'].count()\n        product_month[product] = check(product_month[product])\n    \n    product_month = pd.DataFrame(product_month)\n        \n    average_plot = product_month.mean(axis=1)\n    \n    plt.plot(average_plot.index, average_plot.values, color=colors[i], label=pef);\n    \nplt.title('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites (Averages)', fontsize=20, color='brown')\nplt.legend();\n\n# for memory usage\ndel product_month","10ab2ff8":"# so that our results always be the same\nnp.random.seed(42)\n\nstates = {} \nstates_to_take = np.random.choice(districts_info['state'].unique(), size=10, replace=False)\n\nfor state in states_to_take:\n    districts = districts_info[districts_info['state']==state].district_id.values\n    \n    to_merge = []\n    for district in districts:\n        to_merge.append(pd.read_csv(f'..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/{district}.csv'))\n    \n    states[state] = pd.concat(to_merge)","0273e120":"for state in states:\n    states[state] = pd.merge(states[state], products_info, left_on='lp_id', right_on='LP ID', how='inner').drop('LP ID', axis=1)\n    \n    # doing the same processes\n    states[state]['time'] = pd.to_datetime(states[state]['time'])\n    states[state]['month'] = states[state]['time'].dt.month\n    \n    states[state]['PEF'] = states[state]['Primary Essential Function'].str.split('-')\n    states[state]['PEF'] = states[state]['PEF'].apply(lambda x: x[0])\n    states[state]['PEF'] = states[state]['PEF'].str.strip()","f5a579f8":"fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(25,65))\nfig.suptitle('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites (from each state perspective)', fontsize=30, weight='bold', y=0.91)\n\ncolors = ['red', 'blue', 'green']\nfor i, state in enumerate(states):\n    for j, pef in enumerate(['LC', 'CM', 'SDO']):\n        data = states[state]\n        trunc_df = data[data['PEF']==pef].copy()\n\n        most_used = trunc_df['Product Name'].value_counts().index[:20]\n\n        for product in most_used:\n            product_list = trunc_df[trunc_df['Product Name']== product].groupby('month')['lp_id'].count()\n            axes[i, j].plot(product_list.index, product_list.values, color=colors[j], alpha=0.5);\n\n        axes[i, j].set_title(f'{state}\\n({pef})', fontsize=20, color=colors[j])\n        axes[i, j].set_xticks(range(1, 13));","663e4ab3":"fig, axes = plt.subplots(nrows=10, ncols=1, figsize=(25,65))\nfig.suptitle('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites (Averages-from each state perspective)', fontsize=30, weight='bold', y=0.91)\n\ncolors = ['red', 'blue', 'green']\nfor i, state in enumerate(states):\n    for j, pef in enumerate(['LC', 'CM', 'SDO']):\n        data = states[state]\n        trunc_df = data[data['PEF']==pef].copy()\n\n        most_used = trunc_df['Product Name'].value_counts().index[:20]\n        \n        product_month = {}\n        for product in most_used:\n            product_month[product] = trunc_df[trunc_df['Product Name']== product].groupby('month')['lp_id'].count()\n            product_month[product] = check(product_month[product])\n\n        product_month = pd.DataFrame(product_month)\n\n        average_plot = product_month.mean(axis=1)\n    \n        axes[i].plot(average_plot.index, average_plot.values, color=colors[j], label=pef);\n\n        axes[i].set_title(state, fontsize=20, color=colors[j])\n        axes[i].legend()","dad4e8f2":"# for memory usage\ndel states, product_month","04f8d8c9":"to_investigate = [['New York', 'Wisconsin', 'Minnesota', 'Washington'],\n                  ['Utah', 'New Jersey', 'California'],  \n                  ['Illinois', 'Texas']]             \n\ntitles = ['Decreasing the usage from its original value (before the drop)',\n          'Returning the usage to its original value (before the drop)',\n          'Increasing the usage from its original value (before the drop)']","4a0eba43":"order = ['City', 'Town', 'Suburb', 'Rural']\n\ninvestigate('locale', (15,20), 'From \"Locale\" Perspective', order=order)","e5ef2df4":"order = ['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[', '[0.8, 1[']\n    \ninvestigate('pct_black\/hispanic', (15,20), 'From \"pct_black\/hispanic\" Perspective', order=order)","aa6be3ec":"order = ['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[', '[0.8, 1[']\n\ninvestigate('pct_free\/reduced', (15,20), 'From \"pct_free\/reduced\" Perspective', order=order)","14c82bf7":"order = ['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[', '[12000, 14000[', '[14000, 16000[', \n         '[16000, 18000[', '[18000, 20000[']\n\ninvestigate('pp_total_raw', (15,20), 'From \"pp_total_raw\" Perspective', order=order)","907e7738":"sec_df = eng_product_merge.copy()\nsec_df['Sec'] = sec_df['Sector(s)'].str.split(';')\nsec_df = sec_df.explode('Sec')\nsec_df['Sec'] = sec_df['Sec'].str.strip()","a827b8c6":"fig = plt.figure(figsize=(17, 40))\nfig.suptitle('Impact of COVID-19 on (\"LC\", \"CM\", \"SDO\") websites (Averages-from each sector perspective)', fontsize=20, weight='bold', y=0.91)\nfor i, sector in enumerate(sec_df['Sec'].unique()):\n    plt.subplot(6, 1, i+1)\n    data = sec_df[sec_df['Sec']==sector]\n    \n    for pef in ['CM','SDO','LC']:\n        result = data[data['PEF']==pef].groupby('month')['lp_id'].count()\n        plt.plot(result.index, result.values, label=pef)\n        plt.title(sector, fontsize=12, color='brown')\n    plt.legend()","b9ce3735":"# for memory usage\ndel sec_df","5909ee3a":"for pef in ['LC', 'CM', 'SDO']:\n    temp = eng_product_merge[eng_product_merge['PEF']==pef].copy()\n\n    np.random.seed(42)\n    random_chosen = np.random.choice(temp['sub_PEF'].unique(), size=6, replace=False)\n\n    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 8))\n\n    fig.suptitle(pef, fontsize=15, y=0.96)\n\n    axes = axes.ravel()\n    for i, spef in enumerate(random_chosen):\n        fig.sca(axes[i])\n\n        sub_pef = temp[temp['sub_PEF']== spef].groupby('month')['lp_id'].count()\n        sub_pef = check(sub_pef)\n\n        plt.plot(sub_pef.index, sub_pef.values)\n        plt.title(spef, color='brown')\n\n    del temp\n    del sub_pef\n","4445ede7":"Let's explore \"engagement_index\" and \"perecentage access\" over the whole year<a id='pe'><\/a>","8ab4b728":"> Great, Now we're **ready** for some exploration :).","e26911b9":"_Sector(s)_ <a id='sec'>","582a14b9":"**We can see that:**\n* **<font color='#336699'>The states where the learning platforms usage has decreased from its original value ( Before the drop ) tends to have:<\/font>**\n    - A relatively low percentage of black\/Hispanic (About 5.56% of their districts have these students with a percentage of 60% or higher).\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has returned to its original value ( Before the drop ) tends to have:<\/font>**\n    - A a bit higher percentage of black\/Hispanic (About 9.31% of their districts have these students with a percentage of 60% or higher).\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has increased from its original value ( Before the drop ) tends to have:<\/font>**\n    - A relatively high percentage of black\/Hispanic (About 25% of their districts have these students with a percentage of 60% or higher)\n    \n<font color='red'>_Note:_\n> The states where the learning platforms usage has decreased from its original value ( Before the drop ) have the least chance of having a district with 60% or higher of black\/hispanic. which can indicate that may be the policies in that states (how they are treated by the law) are not the best or even some bad deeds from the white people there like: bullying and racism. All that we not give these students the right environment for learning.let us explain a bit more, If they have patients among their families or even themselves, these polices or bad deeds wouldn't let them be treated equally with white patients.<br>","29d891b4":"_Primary Essential Function_ <a id=pef>","1221e56a":"**_Let's see if the impact of COVID-19 differs between \"LC\", \"CM\",and \"SDO\" Websites_**","b372a2f4":"Let's convert the type of \"time\" column from `object` to `datetime`","b8d8898b":"### This analysis has been done on the whole analysis Let's investigate each state sperately and see if the that will lead us to something.","69fbc510":"> Very Good. Now our \"product_info\" is ready.","e1c794d6":"**From \"Locale\" Perspective**","0e66c432":"## Agenda:\n1. [Introduction](#1)\n    - 1.1 [Problem Statement](#2)\n    - 1.2 [Columns Description](#3)\n    - 1.3 [Challenges](#4)\n2. [Data Preparation & Cleaning](#5)\n    - 2.1 [Packages & Helping Functions](#6)\n    - 2.2 [Data Loading & Cleaning](#7) \n3. [General Exploration](#8)\n4. [Answering The Proposed Questions](#9)\n5. [Conclusion](#10)","40db4c2a":"<h2 align='center'><font color='#290066'>Districts Info<\/font><\/h2>","20de37ff":"#### As we can see there are:\n   - _Useless columns:_\n       - URL\n   \n   - _Columns has NaNs:_\n       - Provider\/Company Name\n       - Sector(s)\n       - Primary Essential Function","c2a344af":"<h2 align='center'><font color='#290066'>Engagement Data<\/font><\/h2>","1a51c742":"> 361 is a very large number for visualization. so we will take 20 random chosen products to tell us the overall picture.","4f7e7f0f":"<h2 align='center'><font color='#290066'>Engagement Data<\/font><\/h2>","88616660":"> As we can see the Effect of COVID-19 is almost the same for each Educational Sector.","680a1dd2":"**<font color='#4d2600'>Suggested Solutions:<\/font>**\n\n<q> Human rights should be granted for every human,not just a word everybody say to seek a position.We don't know exactly how, we don't have such an experience in these kinda things but more efforts should be exerted to guarantee that every human had his own rights.<\/q><br>\n\n> Poverity should not be an obstacle in the road of learning. This issue may be solved by:<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 The material of each week (Lectures and assignment) can be provide in DVDs in the begging of each week so that it the student can't afford a good internet connect he can buy this DVD.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 If these people have something to identify them ( like a card or something ) we can provide them with a place with a good internet connection ( in the school or even in every district )<br>\n\n> A limit should be put to school expenditure so that the fees doesn't go up. May be high fees makes it hard to a family to afford a good internet connection. Or may be high fees makes the school for rich people only and that will upset poor people which, in turn, makes them wants to work instead of leaning to make more money.<br>","45d9163a":"### 1.3 Challenges <a id=4><\/a>\n> Exploring <br>\n    (1) the state of digital learning in 2020 and <br>\n    (2) how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events.\n   \n**Below are some examples of questions that relate to the problem statement:**\n\n   - What is the picture of digital connectivity and engagement in 2020?\n   - What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n   - How does student engagement with different types of education technology change over the course of the pandemic?\n   - How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n   - Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?","b075c9a2":"Let's investigate the usage of 6 random chosen sub categories of the three main categories. <a id=sub>","89d69e9d":"<h2 align='center'>Before anwering any questions, we need to explore the data a little bit to know what are we dealing with.<\/h2><a id=8><\/a>","10e2aee8":"Let's plot the average line for each category","6ec25e5e":"**From \"pct_free\/reduced\" Perspective**<a id='fr'>","b4957ac6":"- **Check**","85e73d5f":"> We can observe that **the two plots are very similar**, so in the next plots, We will use `engagement index` because the percentage access is related to a certain district but we want now to make a general analysis for product usage not for specific districts.\n\n> **We can observe that the engagement index behaviour changes from product to product the:<br>**\n&nbsp;&nbsp;&nbsp;&nbsp; \u25cb Some products, their usage after the mentioned drop couldn't reach its original state before that drop like:<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 CoolMath Games <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 CK-12 <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 Adobe Character Animator <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 Microsoft Outlook <br><br>\n&nbsp;&nbsp;&nbsp;&nbsp; \u25cb Some products, their usage after the mentioned drop approximately reached its original state before that drop like:<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 Diax <br><br>\n&nbsp;&nbsp;&nbsp;&nbsp; \u25cb Other products, their usage after the mentioned drop surpassed its original state before that drop like:<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 Remind <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 Ellevation <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \u2022 ZOOM Cloud Meetings <br>\n\n<font color='#1B5EE9'>So now let's dig deeper and see what we will get.<\/font>","b1002675":"Let's dive deeper to **see the details of this picture :)**","ce7718ce":"## <font color='#660066'> LC <\/font>\n>**Most of the subcategories increased from their original values after the drop or at least returns to their original state like:** <br>\n    - Digital Learning Platform.    \n    - Sites, Resources & Reference Encyclopedia.     \n    - Study Tools.\n    \n<hr>\n\n>**So from the above plot we can conclude that:** <br>\n    <li> Most of the subcategories,if not all, returned to their original values or even surpassed it (the peak is most likely to be in October)    \n    <li> Before the drop`The career planning and job search` subcategory was decreasing (may be that is because of the spread of COVID-19 and the Emergency Declaration at that time) But after that drop it went up rapidly and surpassed its previous state (And of course that is because people became open to the idea of working from home and how they can keep working despite the circumstances).\n","017c3407":"**We can see that:**\n* **<font color='#336699'>The states where the learning platforms usage has decreased from its original value ( Before the drop ) tends to have:<\/font>**\n    - A relatively high percentage of students eligible for free or reduced-price lunch (About 83.33% of their districts have these students with a percentage of 20% or higher).\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has returned to its original value ( Before the drop ) tends to have:<\/font>**\n    - A relatively moderate percentage of students eligible for free or reduced-price lunch (About 67.44% of their districts have these students with a percentage of 20% or higher).\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has increased from its original value ( Before the drop ) tends to have:<\/font>**\n    - A bit lower percentage of students eligible for free or reduced-price lunch (About 60% of their districts have these students with a percentage of 20% or higher).\n    \n<font color='red'>_Note:_\n> Having a large percentage of the students eligible for free or reduced-price lunches leads to lower usage of learning platforms. Maybe the reason is the cost of having good internet access (As during COVID-19 the load on the companies that provide internet has increased. Which made the service that has a humble cost isn't good anymore)","df1f8320":"Regardless of this drop we've talked about before. It seems that approximately:\n- The usage of `LC` webistes **returns** to its original state before that drop\n- The usage of `CM` websites **Increased**\n- The usage of `SDO` webistes **decreased**","07342b3b":"<h2 align='center'><font color='#290066'>Districts Info<\/font><\/h2>","a0b8bd18":"#### <font color='red'>Let's fill the NaNs <\/font>","2597f97d":"**From \"pct_black\/hispanic\" Perspective**<a id='bh'>","d8ad87e8":"Let's explore the subcategories of each Primary Essential Function main categories.","bfb18c9d":"<h3><font color='#000099'> Before doing anything, Let's first combine \"all_eng\" and \"products_info\" datasets to have more info about each product. <\/font><\/h3>","160bb68c":"<h2 align='center'><font color='#290066'>Products Info<\/font><\/h2>","8fcc3416":"> Perfect!","99776181":"### We will try to fill the NaNs Manually by going to each URL and trying to estimate `Sector` and `Primary Essential Function`","11bdb648":"<h2 align='center'><font color='#290066'>Merged Data<\/font><\/h2>","82bc2cf1":"**From \"pp_total_raw\" Perspective**<a id='tr'>","8fcadeb3":"**_Let's see the impact of COVID-19 on \"SDO\" Websites_**","5aa9788a":"Let's plot the average lines instead of all that mess.","d2a08f80":"**We can see that:**\n* **<font color='#336699'>The states where the learning platforms usage has decreased from its original value ( Before the drop ) tends to have:<\/font>**\n    - Most of the expenditure lies between 14000-16000\\$\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has returned to its original value ( Before the drop ) tends to have:<\/font>**\n    - Most of the expenditure lies between 6000-10000\\$\n<hr>\n* **<font color='#336699'>The states where the learning platforms usage has increased from its original value ( Before the drop ) tends to have:<\/font>**\n    - Most of the expenditure lies between 12000-14000\\$\n    \n<font color='red'>_Note:_\n> It's not a must to increase the fees of a school to have a good student (that follows his lessons despite the circumstances) and of course we shouldn't lower it very much to provide a good education services.","8f5d878a":"<h2 align='center'><font color='blue'>Let's Answer the proposed Questions first then we will dive deeper in our analysis<\/font><\/h2><a id=9><\/a>","0a338ea4":"- **Check**","1a94b06a":"From the plots above, we can observe that the usage of learning platforms has **three** common behaviour ,_after the drop we've taked before about_,:\n* <font color='#862d59'>The usage has decreased from its original value ( Before the drop happened ):<\/font>\n    - New York\n    - WisConsin\n    - Minnesota\n    - Washington\n* <font color='#862d59'>The usage returns to its original value ( Before the drop happened ):<\/font>\n    - Utah\n    - New Jersey\n    - California\n* <font color='#862d59'>The usage has increased from its original value ( Before the drop happened ):<\/font>\n    - Illinois\n    - Texas\n    \n> The Last state `Indiana` was a little strange because the CM websites curve went up after the \"drop\" period but the other two curves went down.","00ebe002":"**_Let's see the impact of COVID-19 on \"CM\" Websites_**","988f74c7":"<h2 align='center'><font color='#290066'>2. Data Preparation & Cleaning<\/font><\/h2><a id=1><\/a><a id=5><\/a>","ea8f456b":"**From that we can conclude the following:**\n\n> The states where the learning platforms usage has decreased from its original value ( Before the drop ) have the least chance of having a district with 60% or higher of black\/hispanic >>[Reference](#bh)<< .which can indicate that may be the policies in that states (how they are treated by the law) are not the best or even some bad deeds from the white people there like: <font color='red'>bullying and racism<\/font>. All that we not give these students the right environment for learning.let us explain a bit more, If they have patients among their families or even themselves, these polices or bad deeds wouldn't let them be treated equally with white patients.<br>\n\n> Having a large percentage of the students eligible for free or reduced-price lunches leads to lower usage of learning platforms. Maybe the reason is the cost of having good internet access (As during COVID-19 the load on the companies that provide internet has increased. Which made the service that has a humble cost isn't good anymore). >>[Reference](#fr)<br>\n\n\n> <font color='red'>It's not a must to increase the fees<\/font> of a school to have a good student (that follows his lessons despite the circumstances) and of course we shouldn't lower it very much to provide a good education services. >>[Reference](#tr)<br>","f4d9f55d":"> As we can see, it's hard to plot all these lines in one plot because of the wide range between the values in `engagement_index` and of course `pct_access` so we needed to take another measure of the usage of e-learning platforms and online learning.That's why we've used **the number of e-learning products used during each month** as a measure of how active the e-learning was during that month.","87c4f116":"## <font color='#660066'> CM <\/font>\n>**As expected most of the subcategories increased from their original values after the drop like:** <br>\n    - Classroom Engagement & Instruction Assessment & Classroom Response.    \n    - Teacher Resources Professional Learning.     \n    - Virtual Classroom Video Conferencing & Screen Sharing.\n    \n<hr>\n\n>**So from the above plot we can conclude that:** <br>\n    <li> Also here most of the subcategories returned to their original values or even surpassed it (the peak is most likely to be in October)  <font color='red'> except <\/font> `Classroom Engagement & Instruction Communicaton & Messaging` which is kind of weird actually as `Classroom Engagement & Instruction Assessment & Classroom Response` or `Classroom engagement & Instruction Classroom Management` surpassed their orignal state before the drop which make us wonder why such a thing happend.If we think about it alittle deeper we will find that this is reasonable as `Classroom Engagement & Instruction Communicaton & Messaging` only providing one additional feature instead of Classroom engagment which is Communication and messaging but as we know it's not an important feature anymore we can do that by Facebook or Whatsapp.On the other hand, the `Classroom Engagement & Instruction Assessment & Classroom Response` or `Classroom engagement & Instruction Classroom Management` provides new features like Instruction assessment ( in the first one ) or Instruction Classroom management ( in the second one ). <br><br>\n    <li> The spread of virtual classroom video conferencing & screen sharing start increasing in March and it's still increasing and that's because of online learning from home. This is the way to communicate between the lecturer and their students","ac4c57d7":"- **Check**","926a68d7":"> From the previous plot we can see that \"Country connections ratio\" column is not important at all.That's why we will drop it","0389383e":"<h2 align='center'><font color='#290066'>5. Conclusion<\/font><\/h2><a id=10><\/a>","30a64431":"Actually we can answer the first proposed question **\"What is the picture of digital connectivity and engagement in 2020?\"** by the [previous exploration](#pe).from the engagement index plot we can see that the engagement with e-learning platform began low then was increasing with time then there was a drop (between July and September) then the engagement began to increase again.Two questions should be answered:<br>\n&nbsp;&nbsp;&nbsp;&nbsp;(1) what caused that drop? <br>\n&nbsp;&nbsp;&nbsp;&nbsp;(2) why the engagement began to rise again? <br>\n\n**For the first question, May be due to:**\n- Most of the american universities take the holiday between July and September.\n- According to [WHO](https:\/\/www.who.int\/emergencies\/diseases\/novel-coronavirus-2019\/interactive-timeline?gclid=CjwKCAjwyvaJBhBpEiwA8d38vF9MS1vRVTg1UPNPzmP8DNAgsBywY6M_Q3Q9giUSd5xtato7Y79zNBoC2mIQAvD_BwE#!) the number of corona cases passed 200000 during that period which ,in turn, attracted the attention to \"what we should do and how can we protect ourselves\". May all that distracted the students from learning. \n\n**For the second one:**\n- If the cause was the holiday. So obviously we can say that the rise was due to the begging of a new semester.\n- But if the cause was due to the distraction caused by the number of deaths So may people began used to it.","508843d8":"_Provider\/Company Name_","bb455d85":"Let's fill the remaining NaNs with <font color='red'>\"Unknown\" <\/font>value in order not to lose the information in the other columns\n\n**Note:** <br>\n  > we've tried to fill the NaNs based on the combination of <font color='#008000'>['state', 'locale', 'pct_black\/hispanic']<\/font> but it didn't work\n**Just for more clarity this is the piece of code we've used while trying to fill the NaNs in \"pct_free\/reduced\" column by the above method:**\n\n```\n#let's get the existing combinations of these three columns in our data.\n#geting the different combinations\nNaNs_df = districts_info[districts_info['pct_free\/reduced'].isnull()]\nNaNs_df = NaNs_df[['state', 'locale', 'pct_black\/hispanic']].copy()\nNaNs_df.drop_duplicates(inplace=True)   \n#now let's fill the NaNs according to these combinations\nfor i in range(NaNs_df.shape[0]):\n    state, locale, pct = NaNs_df.iloc[i, :].values\n    mask = (districts_info['state']==state)&(districts_info['locale']==locale)&(districts_info['pct_black\/hispanic']==pct)\n    value = districts_info.loc[mask, 'pct_free\/reduced'].dropna().mode()\n    districts_info.loc[mask&districts_info['pct_free\/reduced'].isnull(), 'pct_free\/reduced'] = value\n```","8955c8c3":"As we discussed above ... let's fill the NaNs with <font color='red'>\"Unknown\" <\/font> Value","6eb10478":"### 1.1 Problem Statement <a id=2><\/a>\n> Nelson Mandela believed education was the most powerful weapon to change the world. The COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Yet not every student has equal opportunities to learn. Effective policies and plans need to be enacted in order to make education more equitable.","ec650f1b":"### 1.2 Columns Description <a id=3><\/a>\n\n<h2 align='center'><font color='#290066'>Engagement data<\/font><\/h2><a id=1><\/a>\n\n| Column | Description |\n| -:- | -:- |\n| time | Date in \"YYYY-MM-DD\" |\n| lp_id | The unique identifier of the product |\n| pct_access | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day |\n\n\n<h2 align='center'><font color='#290066'>District Information data<\/font><\/h2><a id=1><\/a>\n\n| Column | Description |\n| -:- | -:- |\n| district_id | The unique identifier of the school district |\n| state | The state where the district resides in |\n| locale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information. |\n| pct_black\/hispanic | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data |\n| pct_free\/reduced | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data |\n| countyconnectionsratio | ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information. |\n| pptotalraw | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.|\n\n<h2 align='center'><font color='#290066'>Product Information data<\/font><\/h2><a id=1><\/a>\n\n| Column | Description |\n| -:- | -:- |\n| LP ID | The unique identifier of the product |\n| URL | Web Link to the specific product |\n| Product Name | Name of the specific product |\n| Provider\/Company Name | Name of the product provider |\n| Sector(s) | Sector of education where the product is used |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled |","b6e8cbc4":"### 2.2 Data Loading & Cleaning <a id=7>\n<h2 align='center'><font color='#290066'>Products info<\/font><\/h2>","48e89194":"## <font color='#660066'> SDO <\/font>\n>**Also here most of the subcategories increased from their original values after the drop like:** <br>\n    - Data Analytics & Reporting Student Information Systems (SIS).    \n    - Environmental, Health & Safety (EHS) Compilance.     \n    - School Management Software SSO.\n    \n<hr>\n\n>**So from the above plot we can conclude that:** <br>\n    <li> Also here most of the subcategories returned to their original values or even surpassed it (the peak is most likely to be in October) <font color='red'> except <\/font> `Learning Management Systems (LMS)`.By diving deeper into that subcategory we've found that its products provide features that are used in many other websites not only that but the other products provide more than that. <br>\n    <li> Products like \"SafeSchool\", \"Clever\",and \"Infinite Campus\" have got more attention because of COVID-19. <br>","6c598158":"### 2.1 Packages & Some Helping Functions <a id=6><\/a>","4924375d":"#### As we can see there are:  \n   - _Columns has wrong datatype:_\n       - time\n   \n   - _Duplicates:_\n       - 5056710 duplicated rows","01dd7448":"**We can see that:** <br>\n* **<font color='#336699'>The states where the learning platforms usage has decreased from its original value ( Before the drop ) tends to have**:<\/font>** <br>\n     - Less towns (0% compared to 14% and 5%) <br>\n     - More Rural areas (28% compared to 7% and 15%) <br>\n        <hr>\n* **<font color='#336699'>The states where the learning platforms usage has returned to its original value ( Before the drop ) tends to have: <\/font>**<br>\n     - More towns (14% compared to 0% and 5%). <br>\n     - Less Rural areas (7% compared to 28% and 15%)  <br>\n        <hr>\n* **<font color='#336699'>The states where the learning platforms usage has increased from its original value ( Before the drop ) tends to have**:<\/font>** <br>\n     - More Suburb (75% compared to 53% and 50%) <br>\n     - Less Cities (5% compared to 26% and 22%)   <br>","a0963aff":"Let's dig deeper and see if we can know the reason for the previous phenomena","c9dec33a":"#### As we can see NaNs is the only problem here so <font color='red'>Let's fill the NaNs <\/font>","58584e7d":"_Investigating the Impact of COVID-19 on each PEF for each sector separately_","058d0e03":"> As we know, this number is too large for visualization. so let's plot the most frequent 20 companies.","792f4c69":"> Great! :)","11672e2e":"- **Check**","aea54014":"> As expected, Quite high correlation. Which makes us use only one of them in our next analysis (By choosing the most suitable one for answering our questions)","5c47d1c1":"<h2 align='center'><font color='#290066'>1. Introduction<\/font><\/h2><a id=1><\/a>","2b9229c9":"Let's see, what are the most used products in 2020 ?","c06ae4b2":"Combining districts for each state together","bc562cfb":"**_Let's see the impact of COVID-19 on \"LC\" Websites_**","dc974033":"extracting the `month` from \"time\" feature","a758a9d5":"> Done :)","107eb59a":"Main Categories ['LC', 'SDO', 'CM']","69de5367":"\u25cb Products that are most used in 2020 are for <code>the PreK-12 sector<\/code>, and that\u2019s good because if students in this sector adapted themselves to use online tools and new technologies, that will help them in the future. >> [Reference](#sec)<br>\n\n\u25cb Most of the products that are used fall under the service of LC (Learning & Curriculum). >> [Reference](#pef)<br>\n\n\u25cb For LC category: >> [Reference](#sub)\n> <li> Most of the subcategories,if not all, returned to their original values or even surpassed it (the peak is most likely to be in October)    \n <li> Before the drop<code>The career planning and job search<\/code> subcategory was decreasing (may be that is because of <code>the spread of COVID-19 and the Emergency Declaration<\/code> at that time) But after that drop it went up rapidly and surpassed its previous state (And of course that is because people became open to the idea of working from home and how they can keep working despite the circumstances).\n\n\u25cb For CM category: >> [Reference](#sub)\n> <li> Also here most of the subcategories returned to their original values or even surpassed it (the peak is most likely to be in October)  <code> except <\/code> <code>Classroom Engagement & Instruction Communicaton & Messaging<\/code> which is kind of weird actually as <code>Classroom Engagement & Instruction Assessment & Classroom Response<\/code> or <code>Classroom engagement & Instruction Classroom Management<\/code> surpassed their orignal state before the drop which make us wonder why such a thing happend.If we think about it alittle deeper we will find that this is reasonable as <code>Classroom Engagement & Instruction Communicaton & Messaging<\/code> only providing one additional feature instead of Classroom engagment which is Communication and messaging but as we know it's not an important feature anymore we can do that by Facebook or Whatsapp.On the other hand, the <code>Classroom Engagement & Instruction Assessment & Classroom Response<\/code> or <code>Classroom engagement & Instruction Classroom Management<\/code> provides new features like Instruction assessment ( in the first one ) or Instruction Classroom management ( in the second one ). <br><br>\n    <li> The spread of virtual classroom video conferencing & screen sharing start increasing in March and it's still increasing and that's because of online learning from home. This is the way to communicate between the lecturer and their students.\n        \n\u25cb For SDO category: >> [Reference](#sub)\n> <li> Also here most of the subcategories returned to their original values or even surpassed it (the peak is most likely to be in October) <font color='red'> except <\/font> <code>Learning Management Systems (LMS)<\/code>.By diving deeper into that subcategory we've found that its products provide features that are used in many other websites not only that but the other products provide more than that. <br>\n   <li> Products like \"SafeSchool\", \"Clever\",and \"Infinite Campus\" have got more attention because of COVID-19. <br>\n       \n      \n\u25cb **<font color='#336699'>The states where the learning platforms usage has decreased from its original value ( Before the drop ) tends to have the following features:<\/font>** <br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A relatively low percentage of black\/Hispanic (About <font color='red'>5.56%<\/font> of their districts have these students with a percentage of <font color='red'>60%<\/font> or higher). >> [Reference](#bh)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A relatively high percentage of students eligible for free or reduced-price lunch (About <font color='red'>83.33%<\/font> of their districts have these students with a percentage of <font color='red'>20%<\/font> or higher). >> [Reference](#fr)             \n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 Most of the expenditure lies between <font color='red'>14000-16000\\$<\/font>. >>[Reference](#tr)<br>\n\n\u25cb **<font color='#336699'>The states where the learning platforms usage has returned to its original value ( Before the drop ) tends to have the following features:<\/font>** <br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A a bit higher percentage of black\/Hispanic (About <font color='red'>9.31%<\/font> of their districts have these students with a percentage of <font color='red'>60%<\/font> or higher). >> [Reference](#bh)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A relatively moderate percentage of students eligible for free or reduced-price lunch (About <font color='red'>67.44%<\/font> of their districts have these students with a percentage of <font color='red'>20%<\/font> or higher). >>[Reference](#fr)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 Most of the expenditure lies between <font color='red'>6000-10000\\$<\/font>. >>[Reference](#tr)<br>\n\n\u25cb **<font color='#336699'>The states where the learning platforms usage has increased from its original value ( Before the drop ) tends to have the following features:<\/font>**<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A relatively high percentage of black\/Hispanic (About <font color='red'>25%<\/font> of their districts have these students with a percentage of <font color='red'>60%<\/font> or higher). >> [Reference](#bh)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 A bit lower percentage of students eligible for free or reduced-price lunch (About <font color='red'>60%<\/font> of their districts have these students with a percentage of <font color='red'>20%<\/font> or higher). >>[Reference](#fr)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;\u2022 Most of the expenditure lies between <font color='red'>12000-14000\\$<\/font> >>[Reference](#tr)<br>","18a10580":"> We can see that their behaviour approximately the same over the year.Before finishing the exploration let's see the correlation between them.","8da9321a":"_From the previous exploration we knew that there is no need for investigating the percentage access but let's see if it will add something_","ce3de287":"### We've seen the impact of COVID-19 on different \"PEF\" and different states. What about Educational Sectors."}}