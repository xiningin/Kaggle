{"cell_type":{"193362ac":"code","56130bb9":"code","39052363":"code","1f96a427":"code","f70084f7":"code","75ff688e":"code","610f1e8b":"code","28375b9b":"code","be3a389b":"code","8a63cba6":"code","ce70321f":"code","d3767ff4":"code","dbb83e63":"code","a2192154":"code","5bc64ffd":"code","b9f15730":"code","65face7e":"code","c98ba71c":"code","e742cc1f":"code","d56c4322":"code","b7acf38c":"code","7b91be3d":"code","171ef0c3":"code","eb8118af":"code","31f0c027":"code","d266c4e2":"code","b1ac20e7":"code","3e336333":"code","b2b6618a":"markdown","a6b4fdef":"markdown","393a65f0":"markdown","dfac95f2":"markdown","2b6874ef":"markdown","0e9af29a":"markdown","b496735c":"markdown","321db4f1":"markdown","596f96b2":"markdown","5ab2b5d2":"markdown","3c76ce06":"markdown","8aa25a45":"markdown","a4d8a7e1":"markdown","38293b89":"markdown","25721cbf":"markdown","05ef20dc":"markdown","92cbe57c":"markdown","2cf5b4d9":"markdown","48682e06":"markdown","e6ceedea":"markdown","f19b9108":"markdown"},"source":{"193362ac":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","56130bb9":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","39052363":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization","1f96a427":"%matplotlib inline","f70084f7":"# load training and test data into dataframes\ntrain_set = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_set = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","75ff688e":"classes = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","610f1e8b":"# show the first few records of the train_set datafreame\ntrain_set.head()","28375b9b":"# show the first few records of the test_set datafreame\ntest_set.head()","be3a389b":"# check out the dataset format\ntrain_set.shape","8a63cba6":"test_set.shape","ce70321f":"# convert integers to floats\ntrain_arr = np.array(train_set, dtype = 'float')\ntest_arr = np.array(test_set, dtype = 'float')","d3767ff4":"# show some images from the train dataset\nplt.figure(figsize = (10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_arr[i,1:].reshape((28,28)), cmap = plt.cm.binary)\n    train_labels = train_set['label'][i]\n    plt.xlabel(classes[train_labels])\nplt.show()","dbb83e63":"# normalise to range (0:1)\n# exclude label column\nX_train = train_arr[:, 1:] \/ 255\n# include label column\ny_train = train_arr[:, 0]","a2192154":"# exclude label column\nX_test = test_arr[:, 1:] \/ 255\n# include label column\ny_test = test_arr[:,0]","5bc64ffd":"# X_train represents the images, y_train represents the labels\nX_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2)","b9f15730":"# check for sizes\nprint (X_test.shape)\nprint (X_train.shape)\nprint (X_validate.shape)","65face7e":"# reshape dataset to have 28\u00d728 pixels size\nX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\nX_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\nX_validate = X_validate.reshape((X_validate.shape[0], 28, 28, 1))","c98ba71c":"# check again\nprint (X_test.shape)\nprint (X_train.shape)\nprint (X_validate.shape)","e742cc1f":"model = Sequential()","d56c4322":"img_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)","b7acf38c":"# first CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(32, (3, 3), padding = 'same', input_shape = input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3), padding = 'same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\n\n# second CONV => RELU => CONV => RELU => POOL layer set\nmodel.add(Conv2D(64, (3, 3), padding = 'same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3), padding = 'same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\n\n# first (and only) set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# softmax classifier\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))","7b91be3d":"model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","171ef0c3":"history = model.fit(X_train, y_train, batch_size = 1024, epochs = 50, verbose = 1, validation_data = (X_validate, y_validate))","eb8118af":"# evaluate the model\nevaluate = model.evaluate(X_test, y_test, verbose = 0)\nprint('Test Loss: {}'.format(round(evaluate[0], 3)))\nprint('Test Accuracy: {}'.format(round(evaluate[1], 3)))","31f0c027":"plt.figure(figsize = (12, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='val_Loss')\nplt.legend()\nplt.title('Loss evolution')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.title('Accuracy evolution')","d266c4e2":"plt.figure(figsize = (12, 10))\n\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, accuracy, '-g', label = 'Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label = 'Validation Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.legend()\n\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, loss, '-g', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training vs validation Loss')\nplt.legend()","b1ac20e7":"total_classes = 10\npredicted_classes = model.predict_classes(X_test)\ntarget_classes = ['Class {}'.format(i) for i in range(total_classes)]\nprint(classification_report(y_test, predicted_classes, target_names = target_classes))","3e336333":"fig, axes = plt.subplots(5, 5, figsize = (15, 15))\naxes = axes.ravel()\n\nfor i in np.arange(0, 5*5):  \n    axes[i].axis('off')\n    axes[i].imshow(X_test[i].reshape(28,28), cmap = plt.cm.binary)\n    axes[i].set_title('Predicted Class = {}\\n Actual Class = {}'.format((classes[predicted_classes[i]]), classes[int(y_test[i])]))\n#     axes[i].set_title('Predicted Class = {}\\n Actual Class = {}'.format(round(predicted_classes[i], 2), round(y_test[i], 2)))\n\n# cmap=plt.cm.binary\nplt.subplots_adjust(wspace = 0.5)","b2b6618a":"# Data Explore","a6b4fdef":"Show the training accuracy vs loss to get a better understanding of the model training:","393a65f0":"Here we can see that our network obtained 94.3% accuracy on the testing set.","dfac95f2":"The model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\n\nFor the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\n\nThe first layer is the flatten layer that transforms the format of the images from a 2d-array (28x28) to a 1d-array (784 pixels), this layer has no parameters to learn; it only reformats the data.\n\nThe second (and last) layer is a 10-node softmax layer as the output layer is required to be with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.\n\nBetween the feature extractor and the output layer, we gonna add a fully-connected dense layer to interpret the features, in this case with 512 nodes. All layers will use the ReLU activation function.","2b6874ef":"All images have the same size of a single colour channel, we need to reshape the arrays to have 28\u00d728 pixels size","0e9af29a":"Before traing the model, we need to adjust few more parameters like loss function, optimiser and metrics. The sparse_categorical_crossentropy will be optimised as our classes are mutually and we will monitor the classification accuracy metricexclusive","b496735c":"Next step is to split the training set into 80% training and 20% validation to optimise the classifier. We gonna keep the test set as the same to evaluate the accuracy of the model at the end on the data it has never seen. This helps to see whether the model over-fitting on the training set and whether we should lower the learning rate and train for more epochs if validation accuracy is higher than training accuracy or stop over-training if training accuracy shift higher than the validation.","321db4f1":"# Data Preprocessing","596f96b2":"Next, we gonna train the model by feeding the training data to the model so it learns to associate images and labels. Then we gonna ask the model to make predictions about the test set.","5ab2b5d2":"# Deep Learning CNN for Fashion Clothing Classification","3c76ce06":"Show some images with their predictions. Correct predicted classes are above and actual classes are below:","8aa25a45":"To build a neural network we need to configure the layers of the model, then compile the model.","a4d8a7e1":"As the images of the dataset are unsigned integers in the range between 0 and 255 (black & white), we need to convert this unsigned datatype from integer to float to be allowed for the model","38293b89":"Now we need to normalise the pixeles of these grayscale images and rescale them to the range [0,1] so we can feed them to the neural network. This can be done by divide the values of both dataframes by 255. Then slice both of the datasets into X and y to store images and labels respectively","25721cbf":"<img src = 'https:\/\/raw.githubusercontent.com\/just4data\/CNN-for-Fashion-Classification\/master\/fashion.png'>","05ef20dc":"Doing the same with the testset","92cbe57c":"The above few lines show that there are 60,000 images in the training set, with each image represented in a single colour channel (784 pixels)","2cf5b4d9":"# Load Dataset","48682e06":"# Bulid the Model","e6ceedea":"Since the class names are not included with the dataset, we gonna store them to use later","f19b9108":"Image Classification is one of the most popular tasks in deep learning where we are given a particular image and the model has to predict the class of the image. This notebook trains a Convolutional Neural Network (CNN) with Keras on the Fashion MNIST dataset to classify fashion images and categories.\n\n\n<b>The dataset consists of:<\/b>\n\n- 60,000 training examples\n- 10,000 testing examples\n- 28\u00d728 grayscale images\n- 10 classes\n\n<b>These ten classes are:<\/b>\n- T-shirt\/top\n- Trouser\/pants\n- Pullover shirt\n- Dress\n- Coat\n- Sandal\n- Shirt\n- Sneaker\n- Bag\n- Ankle boot\n\nThe dataset can be downloaded from [here](https:\/\/www.kaggle.com\/zalando-research\/fashionmnist) or you can clone the official Fashion MNIST GitHub [repo](https:\/\/github.com\/zalandoresearch\/fashion-mnist), the dataset appears under data\/fashion. We gonna use the 60,000 images to train the CNN and the 10,000 images to evaluate how accurately the network learned to classify images."}}