{"cell_type":{"d139d4a4":"code","a5e0fbac":"code","ec3d4f2d":"code","003284f5":"code","7e44f18a":"code","377c2bbb":"code","c1dee227":"code","2b8f50cd":"code","d793b73e":"code","f2c1004c":"code","c544e7e7":"code","cbb251ee":"code","a4f12e52":"code","f782e999":"code","9dbbc48c":"code","092f99da":"code","cd6ce6a5":"code","a9aed5e0":"code","026d9597":"code","ba28c1a7":"code","8a3f97cb":"markdown","8d487160":"markdown","3c0637f4":"markdown","3cf9d6b5":"markdown","33ddac69":"markdown","413990f4":"markdown","a373863e":"markdown","9e933a8f":"markdown","52358d0e":"markdown","07988927":"markdown","5257b238":"markdown","c7ce66c0":"markdown","1e71a431":"markdown"},"source":{"d139d4a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a5e0fbac":"import numpy as np\nimport pandas as pd\nimport os\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Bidirectional,CuDNNLSTM, LSTM, BatchNormalization, Dropout, Input, Conv1D, Activation,CuDNNGRU, Reshape, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Flatten\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\nfrom keras import backend as K","ec3d4f2d":"train = pd.read_json('..\/input\/train.json')\ntest = pd.read_json('..\/input\/test.json')\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')","003284f5":"train.head()","7e44f18a":"test.head()","377c2bbb":"sample_submission.head()","c1dee227":"print(train.shape)\nprint(test.shape)","2b8f50cd":"turkey = len(train[train['is_turkey']==1])\nnot_turkey = len(train[train['is_turkey']==0])\nprint(\"Number of turkey sound :\",turkey)\nprint(\"Number of not turkey sound :\",not_turkey)\nprint(\"percentage of turkey sound {0:.2f}\".format(turkey\/train.shape[0]))\nprint(\"percentage of not turkey sound {0:.2f}\".format(not_turkey\/train.shape[0]))","d793b73e":"from IPython.display import YouTubeVideo\nrow = 3\nYouTubeVideo(train['vid_id'][row],start=train['start_time_seconds_youtube_clip'][row],end=train['end_time_seconds_youtube_clip'][row])","f2c1004c":"print(train['audio_embedding'].head())\n\n#see the possible list lengths of the first dimension\nprint(\"train's audio_embedding can have this many frames: \"+ str(train['audio_embedding'].apply(lambda x: len(x)).unique())) \nprint(\"test's audio_embedding can have this many frames: \"+ str(test['audio_embedding'].apply(lambda x: len(x)).unique())) \n\n#see the possible list lengths of the first element\nprint(\"each frame can have this many features: \"+str(train['audio_embedding'].apply(lambda x: len(x[0])).unique()))","c544e7e7":"train_train, train_val = train_test_split(train)\nxtrain = train_train['audio_embedding'].tolist()\nytrain = train_train['is_turkey'].values\n\nxval = train_val['audio_embedding'].tolist()\nyval = train_val['is_turkey'].values\n\nx_train = pad_sequences(xtrain, maxlen=10)\nx_val = pad_sequences(xval, maxlen=10)\n\ny_train = np.asarray(ytrain)\ny_val = np.asarray(yval)","cbb251ee":"def first_model():\n    inp = Input((10, 128))\n    x = Conv1D(512, 10, padding='same')(inp)\n    x = Conv1D(256, 5, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Bidirectional(LSTM(512, return_sequences=True, recurrent_dropout=0.1))(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(256, 10, padding='same')(x)\n    x = Conv1D(128, 5, padding='same')(x)\n    x = Bidirectional(LSTM(512, return_sequences=True, recurrent_dropout=0.1))(x)\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n    print(model.summary())\n    return model","a4f12e52":"def model2():\n    inp = Input(shape=(10, 128))\n    x = Conv1D(128, 1, padding='same')(inp)\n    x = BatchNormalization()(x)\n    x = Bidirectional(CuDNNGRU(256, return_sequences=True))(x)\n    x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    concat = concatenate([avg_pool, max_pool])\n    concat = Dense(64, activation=\"relu\")(concat)\n    concat = Dropout(0.5)(concat)\n    output = Dense(1, activation=\"sigmoid\")(concat)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n    print(model.summary())\n    return model","f782e999":"# https:\/\/www.kaggle.com\/qqgeogor\/keras-lstm-attention-glove840b-lb-0-043\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a \/= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","9dbbc48c":"def model3():\n    model = Sequential()\n    model.add(BatchNormalization(momentum=0.90,input_shape=(10, 128)))\n    model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True)))\n    model.add(Bidirectional(CuDNNLSTM(1, return_sequences = True)))\n    model.add(Attention(10))\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model","092f99da":"batch_size = 100\nepochs = 200\nmodel = first_model()","cd6ce6a5":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=4, \n                                            verbose=1, \n                                            factor=0.5,\n                                            min_lr=0.00001)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=8,\n                              verbose=1,\n                              mode='min',\n                              restore_best_weights=True)\n\ncallback = [learning_rate_reduction,early_stopping]","a9aed5e0":"history = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,validation_data=(x_val, y_val), callbacks=callback, verbose=2)\n\nscore, acc = model.evaluate(x_val, y_val, batch_size=batch_size)\nprint('Test accuracy:', acc)","026d9597":"#plt.figure(figsize=(12,8))\n#plt.plot(range(1, epochs+1), history.history['loss'], label='Train Accuracy')\n#plt.plot(range(1, epochs+1), history.history['val_loss'], label='Validation Accuracy')\n#plt.legend()\n#plt.show()","ba28c1a7":"test_data = test['audio_embedding'].tolist()\nsubmission = model.predict(pad_sequences(test_data))\nsubmission = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':[x for y in submission for x in y]})\nsubmission['is_turkey'] = submission.is_turkey.round(0).astype(int)\nprint(submission.head(20))\nsubmission.to_csv('submission6.csv', index=False)","8a3f97cb":"## Callbacks","8d487160":"Let's check the amount of data we have","3c0637f4":"## Plotting the loss curves\nWe can see the model is converging very fast enough in just 7 or 8 epochs","3cf9d6b5":"Let's check how does the turkey sound","33ddac69":"Thanks to this [Kernel](https:\/\/www.kaggle.com\/michaelapers\/lstm-starter-notebook\/notebook) for easy and understandable approach. Trying different model for the prediction. Feel free to fork the notebook but do upvote it.","413990f4":"## Train the Model\nTill now model2 is performing best with 0.95 accuracy","a373863e":"Let's divide the dataset into training and validation. Padding is required as you can see the embeddings can have uneven number of frames so we need to pad it for making the length of the frames equal","9e933a8f":"## Define Model\n Trying differnet model","52358d0e":"Let's read the data using pandas","07988927":" Let's look at VGGish audio embeddings. You can get more details [here](https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/audioset#input-audio-features)","5257b238":"Let's check the details of the above loaded files","c7ce66c0":"Let's find how many real turkey sound we have in our train dataset","1e71a431":"## Predicting Result "}}