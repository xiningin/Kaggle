{"cell_type":{"42613b6a":"code","b5cafbd7":"code","56dbe7e2":"code","f2c99d70":"code","99a0ba59":"code","739b3744":"code","d7ba2632":"markdown"},"source":{"42613b6a":"import os\nimport math\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nprint('Tensorflow version : {}'.format(tf.__version__))","b5cafbd7":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('flower-classification-with-tpus')\nGCS_PATH = os.path.join(GCS_DS_PATH, 'tfrecords-jpeg-512x512')\nTEST_FNS = tf.io.gfile.glob(os.path.join(GCS_PATH, 'test\/*.tfrec'))\nIMG_DIM = (512, 512)","56dbe7e2":"AugParams = {\n    'd1' : 100,\n    'd2': 160,\n    'rotate' : 45,\n    'ratio' : 0.5\n}","f2c99d70":"def transform(image, inv_mat, image_shape):\n\n    h, w, c = image_shape\n    cx, cy = w\/\/2, h\/\/2\n\n    new_xs = tf.repeat( tf.range(-cx, cx, 1), h)\n    new_ys = tf.tile( tf.range(-cy, cy, 1), [w])\n    new_zs = tf.ones([h*w], dtype=tf.int32)\n\n    old_coords = tf.matmul(inv_mat, tf.cast(tf.stack([new_xs, new_ys, new_zs]), tf.float32))\n    old_coords_x, old_coords_y = tf.round(old_coords[0, :] + w\/\/2), tf.round(old_coords[1, :] + h\/\/2)\n\n    clip_mask_x = tf.logical_or(old_coords_x<0, old_coords_x>w-1)\n    clip_mask_y = tf.logical_or(old_coords_y<0, old_coords_y>h-1)\n    clip_mask = tf.logical_or(clip_mask_x, clip_mask_y)\n\n    old_coords_x = tf.boolean_mask(old_coords_x, tf.logical_not(clip_mask))\n    old_coords_y = tf.boolean_mask(old_coords_y, tf.logical_not(clip_mask))\n    new_coords_x = tf.boolean_mask(new_xs+cx, tf.logical_not(clip_mask))\n    new_coords_y = tf.boolean_mask(new_ys+cy, tf.logical_not(clip_mask))\n\n    old_coords = tf.cast(tf.stack([old_coords_y, old_coords_x]), tf.int32)\n    new_coords = tf.cast(tf.stack([new_coords_y, new_coords_x]), tf.int64)\n    rotated_image_values = tf.gather_nd(image, tf.transpose(old_coords))\n    rotated_image_channel = list()\n    for i in range(c):\n        vals = rotated_image_values[:,i]\n        sparse_channel = tf.SparseTensor(tf.transpose(new_coords), vals, [h, w])\n        rotated_image_channel.append(tf.sparse.to_dense(sparse_channel, default_value=0, validate_indices=False))\n\n    return tf.transpose(tf.stack(rotated_image_channel), [1,2,0])\n\ndef random_rotate(image, angle, image_shape):\n\n    def get_rotation_mat_inv(angle):\n          #transform to radian\n        angle = math.pi * angle \/ 180\n\n        cos_val = tf.math.cos(angle)\n        sin_val = tf.math.sin(angle)\n        one = tf.constant([1], tf.float32)\n        zero = tf.constant([0], tf.float32)\n\n        rot_mat_inv = tf.concat([cos_val, sin_val, zero,\n                                     -sin_val, cos_val, zero,\n                                     zero, zero, one], axis=0)\n        rot_mat_inv = tf.reshape(rot_mat_inv, [3,3])\n\n        return rot_mat_inv\n    angle = float(angle) * tf.random.normal([1],dtype='float32')\n    rot_mat_inv = get_rotation_mat_inv(angle)\n    return transform(image, rot_mat_inv, image_shape)\n\n\ndef GridMask(image_height, image_width, d1, d2, rotate_angle=1, ratio=0.5):\n\n    h, w = image_height, image_width\n    hh = int(np.ceil(np.sqrt(h*h+w*w)))\n    hh = hh+1 if hh%2==1 else hh\n    d = tf.random.uniform(shape=[], minval=d1, maxval=d2, dtype=tf.int32)\n    l = tf.cast(tf.cast(d,tf.float32)*ratio+0.5, tf.int32)\n\n    st_h = tf.random.uniform(shape=[], minval=0, maxval=d, dtype=tf.int32)\n    st_w = tf.random.uniform(shape=[], minval=0, maxval=d, dtype=tf.int32)\n\n    y_ranges = tf.range(-1 * d + st_h, -1 * d + st_h + l)\n    x_ranges = tf.range(-1 * d + st_w, -1 * d + st_w + l)\n\n    for i in range(0, hh\/\/d+1):\n        s1 = i * d + st_h\n        s2 = i * d + st_w\n        y_ranges = tf.concat([y_ranges, tf.range(s1,s1+l)], axis=0)\n        x_ranges = tf.concat([x_ranges, tf.range(s2,s2+l)], axis=0)\n\n    x_clip_mask = tf.logical_or(x_ranges <0 , x_ranges > hh-1)\n    y_clip_mask = tf.logical_or(y_ranges <0 , y_ranges > hh-1)\n    clip_mask = tf.logical_or(x_clip_mask, y_clip_mask)\n\n    x_ranges = tf.boolean_mask(x_ranges, tf.logical_not(clip_mask))\n    y_ranges = tf.boolean_mask(y_ranges, tf.logical_not(clip_mask))\n\n    hh_ranges = tf.tile(tf.range(0,hh), [tf.cast(tf.reduce_sum(tf.ones_like(x_ranges)), tf.int32)])\n    x_ranges = tf.repeat(x_ranges, hh)\n    y_ranges = tf.repeat(y_ranges, hh)\n\n    y_hh_indices = tf.transpose(tf.stack([y_ranges, hh_ranges]))\n    x_hh_indices = tf.transpose(tf.stack([hh_ranges, x_ranges]))\n\n    y_mask_sparse = tf.SparseTensor(tf.cast(y_hh_indices, tf.int64),  tf.zeros_like(y_ranges), [hh, hh])\n    y_mask = tf.sparse.to_dense(y_mask_sparse, 1, False)\n\n    x_mask_sparse = tf.SparseTensor(tf.cast(x_hh_indices, tf.int64), tf.zeros_like(x_ranges), [hh, hh])\n    x_mask = tf.sparse.to_dense(x_mask_sparse, 1, False)\n\n    mask = tf.expand_dims( tf.clip_by_value(x_mask + y_mask, 0, 1), axis=-1)\n\n    mask = random_rotate(mask, rotate_angle, [hh, hh, 1])\n    mask = tf.image.crop_to_bounding_box(mask, (hh-h)\/\/2, (hh-w)\/\/2, image_height, image_width)\n\n    return mask\n\ndef apply_grid_mask(image, image_shape):\n    mask = GridMask(image_shape[0],\n                    image_shape[1],\n                    AugParams['d1'],\n                    AugParams['d2'],\n                    AugParams['rotate'],\n                    AugParams['ratio'])\n    \n    if image_shape[-1] == 3:\n        mask = tf.concat([mask, mask, mask], axis=-1)\n\n    return image * tf.cast(mask, tf.uint8)","99a0ba59":"def augmentation(image):\n    \n    if tf.random.uniform(shape=[], minval=0.0, maxval=1.0) >=0.5:\n        image = apply_grid_mask(image, (*IMG_DIM,3))\n    return tf.cast(image, tf.uint8)\n    \ndef decoded_example(example):\n    example = tf.io.parse_single_example(example, { \"image\" : tf.io.FixedLenFeature([], tf.string) })\n    bits = example['image']\n    image = tf.image.decode_jpeg(bits)\n    return image\n\nds = tf.data.TFRecordDataset(TEST_FNS)\nds = ds.map(decoded_example)\nds = ds.map(augmentation)\nds = ds.batch(25)","739b3744":"images = next(iter(ds))\nimages = images.numpy()\nplt.figure(figsize=(24,24))\ncol = 5\nrow = 5\nfor idx, image in enumerate(images):\n    plt.subplot(row, col, idx+1)\n    plt.imshow(image)\nplt.show()","d7ba2632":"# GridMask data augmentation\nType of image data augmentation can be rougly divided in to 3 categories : \n\n1. Spatial transformation (random-crop, flip, rotation...)\n2. Color distortion (random gamma, brightness, hue, contrast....)\n3. Information dropping (random cutout, random erasing, hide-and-seek..)\n\n\nGridMask is belong to Information dropping method. Information dropping might help improving model generalization through enforcing model to learn on remain information. But keeping the deletion and reservation region in a balance relation is needed. Too much information dropping might result in under-fitting, but too few might result in over-fitting. <br \/>\nThere are also some concerns in old information dropping methods. Since the region they dropped will be randomly. So the information might be totally gone after dropping, which make the data into noise. GridMask deletes the structured regions which are uniformly distributed squares. Since the deleting regions are continuous distributed, so the information missing problem can be improve.\n\n![Information dropping examples](attachment:GridMask_example.png)\n\n\nImage rotation is refer to Chris's great [kernel](https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96) and add some of mine code in it. Which can rotate image with different aspect ratio. I also implemented some data augmentation methods(gaussian blur, random cutout..) in this [kernel](https:\/\/www.kaggle.com\/xiejialun\/customize-data-augmentation-with-tensorflow).\n\n\nMy Github repo : [GridMask_tensorflow(not official)](https:\/\/github.com\/RayXie29\/GridMask_Tensorflow) <br \/>\nOfficial GridMask implementation in pytorch : [GridMask](https:\/\/github.com\/akuxcw\/GridMask) <br \/>\nPaper : [GridMask Data Augmentation](https:\/\/arxiv.org\/abs\/2001.04086) <br \/>"}}