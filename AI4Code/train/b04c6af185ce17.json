{"cell_type":{"b10b1561":"code","9c6e3d43":"code","64d8590a":"code","88827510":"code","ff490167":"code","d3aa8708":"code","c31a894b":"code","b8b057a6":"code","ce6f47a2":"code","5e5ebe10":"code","669686a3":"code","bd6dc04f":"code","5315f30f":"code","fd9ad4db":"code","3a134880":"code","876f93d8":"code","53f832bf":"code","1dd3fd30":"code","6162d50b":"code","6374d8f9":"code","5bd7bc94":"code","614b346d":"code","7b85e8ca":"code","a5192613":"code","2621a352":"code","4242ca3e":"code","3850ebbd":"code","3e8ce22a":"code","a183d6a6":"code","b55882a7":"code","fe525af1":"code","2450b102":"code","7cffd135":"code","d239e190":"code","250879cf":"code","dc447e1b":"code","226a34ff":"code","09945213":"code","3d74df8f":"code","0b6f4e36":"code","26e26968":"markdown","4b60ff1b":"markdown","b07bc23d":"markdown","95c254f1":"markdown","01298f27":"markdown","3531ee55":"markdown","4bdf5c0c":"markdown","450b6a52":"markdown","f90dd7df":"markdown","86c33f8f":"markdown"},"source":{"b10b1561":"import os\nimport sys\nimport math\n\nfrom collections import defaultdict\nfrom multiprocessing.dummy import Pool as ThreadPool\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2","9c6e3d43":"%matplotlib inline\n\nscale = 1.5\nplt.rcParams['figure.figsize'] = [6.4*scale, 4.8*scale]\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'","64d8590a":"os.listdir('..\/input')","88827510":"len(list(open('..\/input\/train_ship_segmentations.csv'))) - 1","ff490167":"len(list(open('..\/input\/sample_submission.csv'))) - 1","d3aa8708":"train_path = '..\/input\/train'\ntest_path = '..\/input\/test'","c31a894b":"train_files = os.listdir(f'{train_path}')\nprint(len(train_files))\n\ntest_files = os.listdir(f'{test_path}')\nprint(len(test_files))","b8b057a6":"im = plt.imread(f'{test_path}\/fec9bf8f4.jpg')\nplt.imshow(im)","ce6f47a2":"im.shape","5e5ebe10":"idx = np.random.permutation(len(train_files))[:9]\n\nfig = plt.figure(figsize=(10, 10))\nfig.subplots_adjust(wspace=0, hspace=0)\nfor i, id in enumerate(idx):\n    fig.add_subplot(3, 3, i + 1)\n\n    im = plt.imread(f'{train_path}\/{train_files[id]}')\n    plt.imshow(im)\n    plt.axis('off')\n\nplt.show()","669686a3":"def get_im_shape(fpath):\n    im = plt.imread(fpath)\n    return im.shape\n\npool = ThreadPool(4)\n\ntrain_fpaths = [os.path.join(train_path, fname) for fname in train_files]\ntrain_im_shapes = pool.map(get_im_shape, train_fpaths)\n\ntest_fpaths = [os.path.join(test_path, fname) for fname in test_files]\ntest_im_shapes = pool.map(get_im_shape, test_fpaths)","bd6dc04f":"counter = defaultdict(int)\nfor shape in train_im_shapes:\n    counter[len(shape)] += 1\nprint(f'All train images have a channel: {counter}')","5315f30f":"# There is one invalid image\ninvalid_idx = [i for i in range(len(train_im_shapes)) if len(train_im_shapes[i]) != 3][0]\ninvalid_idx","fd9ad4db":"os.path.isfile(train_fpaths[invalid_idx])","3a134880":"im = plt.imread(train_fpaths[invalid_idx])\nim.shape","876f93d8":"print(f'Don\\'t use image: {train_fpaths[invalid_idx]}')","53f832bf":"counter = defaultdict(int)\nfor i, shape in enumerate(train_im_shapes):\n    if i == invalid_idx: continue\n    counter[shape[2]] += 1\nprint(f'All train images have 3 channels: {counter}')\n\ncounter = defaultdict(int)\nfor i, shape in enumerate(train_im_shapes):\n    if i == invalid_idx: continue\n    counter[shape[1]] += 1\nprint(f'Train images\\' width: {counter}')\n\ncounter = defaultdict(int)\nfor i, shape in enumerate(train_im_shapes):\n    if i == invalid_idx: continue\n    counter[shape[0]] += 1\nprint(f'Train images\\' height: {counter}')","1dd3fd30":"counter = defaultdict(int)\nfor shape in test_im_shapes:\n    counter[len(shape)] += 1\nprint(f'All test images have a channel: {counter}')\n\ncounter = defaultdict(int)\nfor i, shape in enumerate(test_im_shapes):\n    counter[shape[2]] += 1\nprint(f'All test images have 3 channels: {counter}')\n\ncounter = defaultdict(int)\nfor i, shape in enumerate(test_im_shapes):\n    counter[shape[1]] += 1\nprint(f'Test images\\' width: {counter}')\n\ncounter = defaultdict(int)\nfor i, shape in enumerate(test_im_shapes):\n    counter[shape[0]] += 1\nprint(f'Test images\\' height: {counter}')","6162d50b":"masks = pd.read_csv('..\/input\/train_ship_segmentations.csv')\nprint(masks.shape)\nmasks.head()","6374d8f9":"# How many image ids?\nlen(masks['ImageId'].unique())","5bd7bc94":"# For images without ship, there is only one line per image id\ndf_tmp = masks[masks['EncodedPixels'].isna()]\n\nprint(len(df_tmp['ImageId'].unique()))\nprint(len(df_tmp))","614b346d":"# Number of images with ships and without ships\nn_im_no_ships = len(masks[masks['EncodedPixels'].isna()]['ImageId'].unique())\nn_im_ships = len(masks[~masks['EncodedPixels'].isna()]['ImageId'].unique())\nsns.barplot(x=['Ships', 'No ships'], y=[n_im_ships, n_im_no_ships])","7b85e8ca":"# Distribution of number of ships in images\ndf_tmp = masks[~masks['EncodedPixels'].isna()]\nsns.distplot(df_tmp['ImageId'].value_counts().values, kde=False)","a5192613":"# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    im = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        im[lo:hi] = 1\n    return im.reshape(shape).T\n\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","2621a352":"# One image can have multiple masks so there are multiple rows for the image.\n# Use pandas to find all rows with the same image and put their masks together.\n#fname = masks[~masks['EncodedPixels'].isna()].sample(1)['ImageId'].values[0]\nfname = 'a09398d99.jpg'\nim = plt.imread(f'{train_path}\/{fname}')\nrles = masks.loc[masks['ImageId'] == fname, 'EncodedPixels'].tolist()\n\nall_masks = np.zeros((768, 768))\nfirst_masks = np.zeros((768, 768))\nfor i, rle in enumerate(rles):\n    if i == 0: first_masks += rle_decode(rle)\n    all_masks += rle_decode(rle)\n\nfig, axarr = plt.subplots(1, 3)\naxarr[0].axis('off')\naxarr[1].axis('off')\naxarr[2].axis('off')\naxarr[0].imshow(im)\naxarr[1].imshow(all_masks)\naxarr[2].imshow(im)\naxarr[2].imshow(all_masks, alpha=0.4)\nplt.tight_layout(h_pad=0.1, w_pad=0.1)\nplt.show()","4242ca3e":"rle_encode(first_masks)","3850ebbd":"rles[0] == rle_encode(first_masks)","3e8ce22a":"fpath = f'{test_path}\/fec9bf8f4.jpg'\nim = cv2.imread(fpath)\n\n# (centered x, centered y, width, height, rotation in degree, confidence score)\nlocs = [(305.589397186, 357.82121801, 167.674564232, 31.5170499716, -8.00823881288, 0.999999880791)]\nmask = np.zeros(shape=im.shape[0:2])\n\nfor loc in locs:\n\n    x, y, w, h, d = loc[0:5]\n\n    theta = np.radians(d)\n    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n\n    pts = [(w\/2, h\/2), (-w\/2, h\/2), (-w\/2, -h\/2), (w\/2, -h\/2)]\n    pts = [(p[0] * cos_theta + p[1] * sin_theta,\n           -(p[0] * sin_theta) + p[1] * cos_theta) for p in pts]\n    pts = [(p[0] + x, p[1] + y) for p in pts]\n    pts = [(int(p[0]), int(p[1])) for p in pts]\n    pts = np.array(pts)\n\n    im = cv2.fillPoly(im, pts=[pts], color=(255, 0, 0))\n    mask = cv2.fillPoly(mask, pts=[np.array(pts)], color=(255, 255, 255))\n\nplt.imshow(im[:, :, (2, 1, 0)])\nplt.show()","a183d6a6":"plt.imshow(mask)","b55882a7":"fname = 'a09398d99.jpg'\nrles = masks.loc[masks['ImageId'] == fname, 'EncodedPixels'].tolist()\nim_mask = rle_decode(rles[1])\nplt.imshow(im_mask)","fe525af1":"# https:\/\/stackoverflow.com\/questions\/49957431\/findcontours-of-a-single-channel-image-in-opencv-python\n_, contours, hierarchy = cv2.findContours(im_mask.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\ncv2.minAreaRect(contours[0])","2450b102":"# https:\/\/www.kaggle.com\/raresbarbantan\/f2-metric\/notebook\n# https:\/\/www.kaggle.com\/sgalwan\/airbus-ship-detection-challenge-eda-metrics\/notebook\ndef read_masks(masks, im_name):\n    mask_list = masks.loc[masks['ImageId'] == im_name, 'EncodedPixels'].tolist()\n    all_masks = np.zeros((len(mask_list), 768, 768))\n    for idx, mask in enumerate(mask_list):\n        if isinstance(mask, str):\n            all_masks[idx] = rle_decode(mask)\n    return all_masks\n\ndef read_flat_mask(masks, im_name):\n    all_masks = read_masks(masks, im_name)\n    return np.sum(all_masks, axis=0)\n\ndef iou(mask1, mask2):\n    i = np.sum((mask1 >= 0.5) & (mask2 >= 0.5))\n    u = np.sum((mask1 >= 0.5) | (mask2 >= 0.5))\n    return i \/ (1e-8 + u)","7cffd135":"im_name_with_ships = '00021ddc3.jpg'\nim_name_with_no_ships = '00003e153.jpg'\n\nim_with_ships = plt.imread(f'{train_path}\/00021ddc3.jpg')\nim_with_no_ships = plt.imread(f'{train_path}\/00003e153.jpg')\n\n_, axarr = plt.subplots(1, 2)\naxarr[0].axis('off')\naxarr[1].axis('off')\naxarr[0].imshow(im_with_ships)\naxarr[0].imshow(read_flat_mask(masks, im_name_with_ships), alpha=0.6)\naxarr[1].imshow(im_with_no_ships)\naxarr[1].imshow(read_flat_mask(masks, im_name_with_no_ships), alpha=0.6)","d239e190":"m = read_flat_mask(masks, im_name_with_ships)\nprint(f'{iou(m, m)}, {iou(m, np.zeros((768, 768)))}, {iou(m, np.ones((768, 768)))}')\n\nm = read_flat_mask(masks, im_name_with_no_ships)\nprint(f'{iou(m, m)}, {iou(m, np.zeros((768, 768)))}, {iou(m, np.ones((768, 768)))}')","250879cf":"def f2(true_masks, pred_masks):\n    # a correct prediction on no ships in image would have F2 of zero (according to formula),\n    # but should be rewarded as 1\n    if np.sum(true_masks) == np.sum(pred_masks) == 0:\n        return 1.0\n\n    pred_masks = [m for m in pred_masks if np.any(m >= 0.5)]\n    true_masks = [m for m in true_masks if np.any(m >= 0.5)]\n\n    f2_total = 0\n    thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n\n    for threshold in thresholds:\n        if len(true_masks) == 0:\n            tp, fn, fp = 0.0, 0.0, float(len(pred_masks))\n        else:\n            pred_hits = np.zeros(len(pred_masks), dtype=np.bool)\n            true_hits = np.zeros(len(true_masks), dtype=np.bool)\n\n            for i, pred_mask in enumerate(pred_masks):\n                for j, true_mask in enumerate(true_masks):\n                    if iou(pred_mask, true_mask) > threshold:\n                        pred_hits[i] = True\n                        true_hits[j] = True\n\n            tp = np.sum(pred_hits)\n            fp = len(pred_masks) - tp\n            fn = len(true_masks) - np.sum(true_hits)\n\n        f2 = (5*tp)\/(5*tp + 4*fn + fp)\n        f2_total += f2\n\n    return f2_total \/ len(thresholds)","dc447e1b":"m = read_masks(masks, im_name_with_ships)\nprint(f'{f2(m, m)}, {f2(m, np.zeros((768, 768)))}, {f2(m, np.ones((768, 768)))}')\n\nm = read_masks(masks, im_name_with_no_ships)\nprint(f'{f2(m, m)}, {f2(m, np.zeros((768, 768)))}, {f2(m, np.ones((768, 768)))}')","226a34ff":"# Compute the average F2 on a subset of images with a single blank prediction, images with no ships would get 1 and with ships would get 0. F2 score would be close the ratio of number of images with on ships and number of total images (0.72).\nsubset_images = 2000\nrandom_files = masks['ImageId'].unique()\nnp.random.shuffle(random_files)\n\nf2_sum = 0\nfor fname in random_files[:subset_images]:\n    mask = read_masks(masks, fname)\n    score = f2(mask, [np.zeros((768, 768))])\n    f2_sum += score\n\nprint(f2_sum\/subset_images)","09945213":"len(masks[masks['EncodedPixels'].isna()]['ImageId'].unique()) \/ len(masks['ImageId'].unique())","3d74df8f":"# https:\/\/www.kaggle.com\/ezietsman\/airbus-eda\/notebook\nsample = masks[~masks.EncodedPixels.isna()].sample(9)\nfig, ax = plt.subplots(3, 3, figsize=(10, 10))\nfig.subplots_adjust(wspace=0, hspace=0)\nfor i, im_id in enumerate(sample.ImageId):\n    row, col = i \/\/ 3, i % 3\n\n    im = plt.imread(f'{train_path}\/{im_id}')\n    ax[row, col].imshow(im)\n    ax[row, col].axis('off')\n\nplt.show()","0b6f4e36":"ignore_files = ['13703f040.jpg', '14715c06d.jpg', '33e0ff2d5.jpg', '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', 'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg', 'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg']\n\nfig = plt.figure(figsize=(10, 17))\nfig.subplots_adjust(wspace=0, hspace=0)\nfor i in range(len(ignore_files)):\n    fig.add_subplot(5, 3, i + 1)\n\n    im = plt.imread(f'{test_path}\/{ignore_files[i]}')\n    plt.imshow(im)\n    plt.axis('off')\n\nplt.show()","26e26968":"###### From marked 2-d array to centered rotated rectangle","4b60ff1b":"##### Evaluation","b07bc23d":"###### From run length encoding to masked 2-d array","95c254f1":"##### Ignore images in test","01298f27":"###### From centered rotated rectangle to masked 2-d array","3531ee55":"##### Data","4bdf5c0c":"###### Sample images with ships","450b6a52":"##### Labels","f90dd7df":"##### Images","86c33f8f":"- For each image, one line per one ship\n- If no ship in an image, EncodedPixels is NaN"}}