{"cell_type":{"7c4fbbab":"code","52c16b56":"code","83553cd8":"code","9c54844f":"code","021011ba":"code","af96a753":"code","df47f1e7":"code","be33073c":"code","e945e8a7":"code","2c05b123":"code","56919e94":"code","36f95811":"code","0328f769":"code","15645b35":"code","f9a47b04":"code","f0490802":"code","299d41e8":"code","2bd32003":"code","ef523f2e":"code","b8f41a12":"markdown","5e4061dc":"markdown","eb9e8923":"markdown","7c7c8bfd":"markdown","d112bdaa":"markdown","e7416707":"markdown"},"source":{"7c4fbbab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","52c16b56":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(['dark_background','ggplot'])","83553cd8":"train_df=pd.read_csv('..\/input\/train.csv')\ntest_df=pd.read_csv('..\/input\/test.csv')","9c54844f":"print(train_df.info())\nprint('--'*30+'\\n'+'--'*30)\nprint(test_df.info())\ntrain_df.head(10)","021011ba":"print('Training columns with Null Values \\n',train_df.isna().sum())\nprint('-'*20+'\\n'+'-'*20)\nprint('Test columns with Null or NaN Values \\n',test_df.isnull().sum()) \n#isna(),isnull() does the same thing","af96a753":"df_clean=[train_df,test_df]\n\ndrop_column=['PassengerId','Cabin','Ticket','Name']\n\nfor dataset in df_clean:\n    dataset[\"Age\"].fillna(dataset['Age'].median(), inplace = True)\n    \n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n    dataset.drop(drop_column,axis=1,inplace=True)\n\nprint('Training columns with Null Values \\n',train_df.isna().sum())\nprint('-'*20+'\\n'+'-'*20)\nprint('Test columns with Null or NaN Values \\n',test_df.isnull().sum()) \n    ","df47f1e7":"train_df['Embarked'].value_counts().plot(kind='bar')","be33073c":"train_df['Embarked'].fillna(train_df['Embarked'].mode()[0],inplace=True)","e945e8a7":"print('Training columns with Null Values \\n',train_df.isna().sum())","2c05b123":"train_df = pd.get_dummies(columns=['Embarked','Sex'],data=train_df,drop_first=True)\ntest_df = pd.get_dummies(columns=['Embarked','Sex'],data=test_df,drop_first=True)","56919e94":"train_df.head()","36f95811":"test_df.head()","0328f769":"X=train_df.drop('Survived',axis=1)\ny=train_df['Survived']","15645b35":"import keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nearly_stopping_monitor=EarlyStopping(patience=3)\n#from keras.utils import to_categorical\n#Setting up the model\nmodel_1=Sequential()\nmodel_2=Sequential()\n#Add first layer\nmodel_1.add(Dense(50,activation='relu',input_shape=(X.shape[1],)))\nmodel_2.add(Dense(100,activation='relu',input_shape=(X.shape[1],)))\n#Add second layer\nmodel_1.add(Dense(32,activation='relu'))\nmodel_2.add(Dense(50,activation='relu'))\n#Add output layer\nmodel_1.add(Dense(1,activation='sigmoid'))\nmodel_2.add(Dense(1,activation='sigmoid'))\n#Compile the model\nmodel_1.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\nmodel_2.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])","f9a47b04":"# Fit model_1\nmodel_1_training = model_1.fit(X, y, epochs=30, validation_split=0.2, callbacks=[early_stopping_monitor])\n\n# Fit model_2\nmodel_2_training = model_2.fit(X, y, epochs=30, validation_split=0.2, callbacks=[early_stopping_monitor])\n","f0490802":"plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\nplt.xlabel('Epochs')\nplt.ylabel('Validation score')\nplt.show()","299d41e8":"y_pred = [x[0] for x in model_2.predict(test_df)]\ndf = pd.DataFrame({'PassengerId':pd.read_csv('..\/input\/test.csv')['PassengerId'].values,'Survived':y_pred},dtype=int)\n#df.to_csv('submission.csv', index=False)\n#It gave only around 62% accuracy on test set on submission,","2bd32003":"# Import necessary modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Setup the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space}\n\n# Instantiate a logistic regression classifier: logreg\nlogreg = LogisticRegression()\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\n# Fit it to the data\nlogreg_cv.fit(X,y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \nprint(\"Best score is {}\".format(logreg_cv.best_score_))\n","ef523f2e":"#Now Using 'C'=0.4393970560760795 from above Result\nlogre=LogisticRegression(C=0.4393970560760795)\nlogre.fit(X,y)\ny_pred=logre.predict(test_df)\ndf = pd.DataFrame({'PassengerId':pd.read_csv('..\/input\/test.csv')['PassengerId'].values,'Survived':y_pred},dtype=int)\ndf.to_csv('submission.csv', index=False)","b8f41a12":"### So model_1 is good ","5e4061dc":"### Fitting models ","eb9e8923":"### Now using Regularization along with Hyperparameter Tuning and GridSearchCV ","7c7c8bfd":"### Importing libraries and compiling different models with different units in hidden layer ","d112bdaa":"# Cleaning Data ","e7416707":"### Since 'S' is more Na values be replaced with 'S' in 'Embarked' column"}}