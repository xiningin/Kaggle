{"cell_type":{"f2420a8f":"code","60245326":"code","db32c305":"code","92066a76":"code","f51834bc":"code","3c7c390f":"code","eece2e62":"code","326fd27d":"code","fc6e7a16":"code","954ca34d":"code","2e60b4bf":"code","aa4f31d9":"code","13015a16":"code","73b6c17c":"code","96012b60":"code","13e554cb":"code","710c1641":"code","79b36575":"code","e8ba3190":"code","33902178":"code","1c133e2f":"code","46d9426f":"code","cd25da30":"code","6be81cb1":"code","93a932b0":"code","bc0d2a4b":"markdown","0fc3c335":"markdown","59b4c963":"markdown","e7c39b63":"markdown","03c479a1":"markdown","9b1818be":"markdown","3b77a071":"markdown"},"source":{"f2420a8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60245326":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom pylab import plot, show, subplot, specgram, imshow, savefig\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,f1_score, confusion_matrix, accuracy_score, classification_report\nimport pickle\n%matplotlib inline","db32c305":"FILEPATH = '..\/input\/loan-data-set\/loan_data_set.csv'","92066a76":"df = pd.read_csv(FILEPATH)\ndf.sample(8)","f51834bc":"df.drop(['Loan_ID', 'Gender', 'Dependents', 'Married', 'Property_Area', 'Education'], axis=1, inplace=True) #Using a small set of cols here\ndf.head()","3c7c390f":"df.isnull().sum().any()","eece2e62":"df.isnull().sum()","326fd27d":"df.Credit_History.value_counts()","fc6e7a16":"df.Credit_History.fillna(0.0, inplace=True)\ndf.Loan_Amount_Term.fillna(df.Loan_Amount_Term.mean(), inplace=True)","954ca34d":"df.LoanAmount.fillna(df.LoanAmount.mean(), inplace=True)\ndf.Self_Employed.fillna('No', inplace=True)\n#df.Married.fillna('No', inplace=True)","2e60b4bf":"df.isnull().sum().any()","aa4f31d9":"df['Credit_History'] = df['Credit_History'].astype('int64')\ndf.dtypes","13015a16":"le = LabelEncoder()\ncols = df.columns.tolist()\nfor column in cols:\n    if df[column].dtype == 'object':\n        df[column] = le.fit_transform(df[column])","73b6c17c":"df.dtypes","96012b60":"fig, ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(data=df.corr().round(2), annot=True, linewidths=0.7, cmap='Blues')\nplt.show()","13e554cb":"X = df.drop(\"Loan_Status\", axis=1)\ny = df[\"Loan_Status\"]","710c1641":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=30) ","79b36575":"classifiers = {\n    'Multinomial NB': MultinomialNB(),\n    'Gaussian NB': GaussianNB(),\n    'Linear SVM': SVC(kernel='linear'),\n    'RBF SVM': SVC(kernel='rbf'),\n    'Sigmoid SVM': SVC(kernel='sigmoid'),\n    #FOR SVM USE HYPERPARAMETER TUNING TO BETTER UNDERSTAND WHAT TO TAKE\n    'MLP Classifier': MLPClassifier(),\n    'MLP Hidden Layer': MLPClassifier(hidden_layer_sizes=[100,100]),\n    'Ada Boost': AdaBoostClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'Logistic Regression': LogisticRegression()\n}","e8ba3190":"acc_scores = dict()\n\nfor classifier in classifiers:\n    \n    clf = classifiers[classifier]\n    clf.fit(Xtrain,ytrain)\n    y_pred = clf.predict(Xtest)\n    acc_scores[classifier] = accuracy_score(y_pred, ytest)\n    print(classifier, acc_scores[classifier])","33902178":"model = LogisticRegression()\nmodel.fit(Xtrain, ytrain)\n\ny_pred = model.predict(Xtest)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(y_pred, ytest)))\nprint(confusion_matrix(ytest, y_pred))\nprint(\"Classification Report for Logistic Regression\")\nprint(classification_report(ytest, y_pred))","1c133e2f":"filename = 'logistic_model.p'\npickle.dump(model, open('.\/'+filename, 'wb'))","46d9426f":"filename = 'rand_forest_model.p'\n\nmodel = RandomForestClassifier()\nmodel.fit(Xtrain, ytrain)\n\ny_pred = model.predict(Xtest)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(y_pred, ytest)))\nprint(confusion_matrix(ytest, y_pred))\nprint(\"Classification Report for Random Forest Classifier\")\nprint(classification_report(ytest, y_pred))\n\npickle.dump(model, open('.\/'+filename, 'wb'))","cd25da30":"filename = 'dec_tree_model.p'\n\nmodel = DecisionTreeClassifier()\nmodel.fit(Xtrain, ytrain)\n\ny_pred = model.predict(Xtest)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(y_pred, ytest)))\nprint(confusion_matrix(ytest, y_pred))\nprint(\"Classification Report for Decision Tree Classifier\")\nprint(classification_report(ytest, y_pred))\n\npickle.dump(model, open('.\/'+filename, 'wb'))","6be81cb1":"filename = 'gaussian_nb_model.p'\n\nmodel = GaussianNB()\nmodel.fit(Xtrain, ytrain)\n\ny_pred = model.predict(Xtest)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(y_pred, ytest)))\nprint(confusion_matrix(ytest, y_pred))\nprint(\"Classification Report for Gaussian Na\u00efve Bayes\")\nprint(classification_report(ytest, y_pred))\n\npickle.dump(model, open('.\/'+filename, 'wb'))","93a932b0":"filename = 'linear_svm_model.p'\n\nmodel = SVC(kernel='linear')\nmodel.fit(Xtrain, ytrain)\n\ny_pred = model.predict(Xtest)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(y_pred, ytest)))\nprint(confusion_matrix(ytest, y_pred))\nprint(\"Classification Report for Linear Kernel SVM\")\nprint(classification_report(ytest, y_pred))\n\npickle.dump(model, open('.\/'+filename, 'wb'))","bc0d2a4b":"## Linear Kernel SVM","0fc3c335":"# Saving a model file","59b4c963":"## Logistic Regression","e7c39b63":"## Gaussian Na\u00efve Bayes","03c479a1":"The most popular way of saving a model file is by using pickle.","9b1818be":"## Random Forest Classifier","3b77a071":"## Decision Tree Classifier"}}