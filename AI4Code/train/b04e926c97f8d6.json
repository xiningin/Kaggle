{"cell_type":{"47e53084":"code","582b4494":"code","b14df84a":"code","928e82fe":"code","9ea832c2":"code","d77fc53a":"code","e917b0e8":"code","af9ce15e":"code","4f8d365e":"code","0e47f1dd":"code","c778ae06":"code","f6e05ca0":"code","eaf7667d":"code","e7f2ae4a":"code","4cfccd33":"code","d3c58f39":"code","8b23e854":"code","fd016ecc":"code","7bbadaf8":"code","1c8ae8e6":"code","ad0b115e":"code","dee5391b":"code","f4560868":"code","081c3009":"code","d8dbb97e":"code","4425a837":"code","34e1b6fc":"code","ff008b18":"code","7d12af1c":"code","39fd2fe5":"code","fc7507fb":"code","72ce01f9":"code","acd5613b":"code","464f23b1":"code","97afcdb3":"code","909f077d":"code","c29a3057":"code","6b7bb277":"code","42d970ab":"code","b0e70252":"code","c6918215":"code","3a71e475":"code","849603d5":"code","2942fa2a":"code","dc79ed08":"code","0d3dbf91":"code","9a6b29cc":"code","b2c2930a":"code","a36e8653":"code","0726f1c3":"code","12be353b":"code","89636c8b":"code","356e78e1":"code","e7a5d9ea":"code","3aaa569e":"code","ae10ca24":"code","41b13f9a":"code","4378c8be":"markdown","77f07707":"markdown","2886fc71":"markdown","65da9c32":"markdown","0477bc35":"markdown","9782eab7":"markdown","d4ebbcc6":"markdown","d1bf5f9a":"markdown","ed88fff9":"markdown","bdb6031b":"markdown","c124f983":"markdown","5d8d64f2":"markdown","c28f0b56":"markdown","7f2d7aed":"markdown","eaba7582":"markdown","6bd85893":"markdown","95fb6915":"markdown","994d6f3a":"markdown","e88ec5c2":"markdown","f3b2841d":"markdown","0aa05767":"markdown","10924a5d":"markdown","eaeb932f":"markdown","55b79d8d":"markdown","36a37765":"markdown","b42ec8c8":"markdown","da9444c5":"markdown","100121f7":"markdown","03a2651d":"markdown","5f2130dc":"markdown","a5769b14":"markdown","76122262":"markdown","b31b6f10":"markdown","833cf6b4":"markdown","7ced0fc8":"markdown","b0b1a3f2":"markdown","02650603":"markdown","36ca6f5c":"markdown","8eaa80c8":"markdown","56be03ce":"markdown","4849bb22":"markdown","32a5a64d":"markdown","38bdefd5":"markdown"},"source":{"47e53084":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","582b4494":"# Dateipfad in einer Variable speichern\nvideo_games_path = '..\/input\/Video_Games_Sales_as_at_22_Dec_2016.csv'\n# Daten auslesen\nvgd = pd.read_csv(video_games_path)\n# Zusammenfassung der Daten ausgeben\nvgd.describe()","b14df84a":"vgd.columns","928e82fe":"\ndef missing_values_table(df):\n        # Anzahl der fehlenden Daten\n        mis_val = df.isnull().sum()\n        \n        # Anzahl der fehlenden Daten in %\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Erstellen einer Tabelle mit den Ergebnissen\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Benennung der Spalten\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : \"Missing Values\", 1 : \"% of Total Values\"})\n        \n        # Absteigendes Sortieren der Zeilen\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        \"% of Total Values\", ascending=False).round(1)\n        \n        \n        \n        return mis_val_table_ren_columns","9ea832c2":"#Aufrufen der Tabelle\nmissing_values_table(vgd)","d77fc53a":"vgd_clean = vgd.dropna(axis=0)","e917b0e8":"missing_values_table(vgd_clean)","af9ce15e":"vgd_clean.describe()","4f8d365e":"#Prediction Target\ny = vgd_clean.Global_Sales\n\n# neue Features werden f\u00fcr das Modell genommen\nvgd_features = ['User_Score', 'User_Count', 'Critic_Score', 'Critic_Count']\n\nX = vgd_clean[vgd_features]","0e47f1dd":"y.describe()","c778ae06":"X.describe(include=\"all\")","f6e05ca0":"y.head()","eaf7667d":"X.head()","e7f2ae4a":"from sklearn.tree import DecisionTreeRegressor\n\nvgd_model = DecisionTreeRegressor(random_state=1)\n\nvgd_model.fit(X, y)","4cfccd33":"vgd_model = DecisionTreeRegressor(random_state=1)\n\nvgd_model.fit(X, y)","d3c58f39":"X.head()","8b23e854":"y.head()","fd016ecc":"print(\"Die ersten 5 Spiele:\")\nprint(vgd_model.predict(X.head()))\nprint(\"Die letzen 5 Spiele:\")\nprint(vgd_model.predict(X.tail()))","7bbadaf8":"print(\"Die ersten 5 Spiele:\")\nprint(y.head())\nprint(\"Die letzen 5 Spiele:\")\nprint(y.tail())","1c8ae8e6":"from sklearn.metrics import mean_absolute_error\n\nprediction = vgd_model.predict(X)\nmean_absolute_error(y, prediction)","ad0b115e":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n\nvgd_model = DecisionTreeRegressor()\n\nvgd_model.fit(train_X, train_y)\n\nval_prediction = vgd_model.predict(val_X)","dee5391b":"train_X","f4560868":"val_X","081c3009":"print(mean_absolute_error(val_y, val_prediction))","d8dbb97e":"mean_absolute_error(y, prediction)","4425a837":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","34e1b6fc":"for max_leaf_nodes in [5, 10, 50, 100, 500]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf Nodes: \", max_leaf_nodes, \"\\t\\t\", \"MAE: \", my_mae)","ff008b18":"vgd_model = DecisionTreeRegressor(random_state=1, max_leaf_nodes=50)\n\nvgd_model.fit(train_X, train_y)\nprint(vgd_model.predict(val_X.head()))","7d12af1c":"print(val_y.head())","39fd2fe5":"from sklearn.ensemble import RandomForestRegressor\n\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_X, train_y)\nvgd_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, vgd_preds))","fc7507fb":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()","72ce01f9":"# Modell erstellen\nclf.fit(train_X, train_y)","acd5613b":"# Vorhersage der ersten und letzen 5 Daten\nprint(clf.predict(val_X.head()))\nprint(clf.predict(val_X.tail()))","464f23b1":"# Vergleich mit den urspr\u00fcnglichen Daten\nprint(val_y.head())\nprint(val_y.tail())","97afcdb3":"clf.score(val_X, val_y)","909f077d":"# Get list of categorical variables\ns = (train_X.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","c29a3057":"# Function for comparing different approaches\ndef score_dataset(train_X, val_X, train_y, val_y):\n    model = RandomForestRegressor(n_estimators=50, random_state=0)\n    model.fit(train_X, train_y)\n    preds = model.predict(val_X)\n    return mean_absolute_error(val_y, preds)","6b7bb277":"drop_train_X = train_X.select_dtypes(exclude=['object'])\ndrop_val_X = val_X.select_dtypes(exclude=['object'])\n\nprint(\"MAE from Approach 1 (Drop categorical variables):\")\nprint(score_dataset(drop_train_X, drop_val_X, train_y, val_y))","42d970ab":"from sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabel_X_train = train_X.copy()\nlabel_X_valid = val_X.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    label_X_train[col] = label_encoder.fit_transform(train_X[col])\n    label_X_valid[col] = label_encoder.transform(val_X[col])\n\nprint(\"MAE from Approach 2 (Label Encoding):\") \nprint(score_dataset(label_X_train, label_X_valid, train_y, val_y))","b0e70252":"import matplotlib.pyplot as plt\n%matplotlib inline","c6918215":"import seaborn as sns\nplt.style.use(\"fivethirtyeight\")\n\n# \u00c4nderung der Schrift\nplt.rcParams[\"font.size\"] = 24\nplt.rcParams[\"figure.facecolor\"] = \"white\"\nplt.rcParams[\"axes.facecolor\"] = \"white\"\n\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(15, 12)","3a71e475":"plt.scatter(vgd_clean['User_Count'], vgd_clean['Global_Sales'])","849603d5":"plt.scatter(vgd_clean['User_Score'], vgd_clean['Global_Sales'])","2942fa2a":"plt.scatter(vgd_clean['Critic_Score'], vgd_clean['Global_Sales'])","dc79ed08":"plt.scatter(vgd_clean['Critic_Count'], vgd_clean['Global_Sales'])","0d3dbf91":"def rm_outliers(df, list_of_keys):\n    df_out = df\n    for key in list_of_keys:\n        # Calculate first and third quartile\n        first_quartile = df_out[key].describe()[\"25%\"]\n        third_quartile = df_out[key].describe()[\"75%\"]\n\n        # Interquartile range\n        iqr = third_quartile - first_quartile\n\n        # Remove outliers\n        removed = df_out[(df_out[key] <= (first_quartile - 3 * iqr)) |\n                    (df_out[key] >= (third_quartile + 3 * iqr))] \n        df_out = df_out[(df_out[key] > (first_quartile - 3 * iqr)) &\n                    (df_out[key] < (third_quartile + 3 * iqr))]\n    return df_out, removed","9a6b29cc":"vgd_clean, rmvd_global = rm_outliers(vgd_clean, [\"Global_Sales\"])\nvgd_clean.describe()","b2c2930a":"vgd_clean, rmvd_global = rm_outliers(vgd_clean, [\"User_Count\"])\nvgd_clean.describe()","a36e8653":"vgd_clean, rmvd_global = rm_outliers(vgd_clean, [\"Critic_Score\"])\nvgd_clean.describe()","0726f1c3":"vgd_clean, rmvd_global = rm_outliers(vgd_clean, [\"Critic_Count\"])\nvgd_clean.describe()","12be353b":"y = vgd_clean.Global_Sales\n\nvgd_features = ['User_Score', 'Critic_Score', 'User_Count','User_Score']\n\nX = vgd_clean[vgd_features]","89636c8b":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n\nvgd_model = DecisionTreeRegressor()\n\nvgd_model.fit(train_X, train_y)\n\nval_prediction = vgd_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_prediction))","356e78e1":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()","e7a5d9ea":"clf.fit(train_X, train_y)","3aaa569e":"print(clf.predict(val_X.head()))\nprint(clf.predict(val_X.tail()))","ae10ca24":"print(val_y.head())\nprint(val_y.tail())","41b13f9a":"clf.score(val_X, val_y)","4378c8be":"Doch auch hier konnte der MAE nicht verbessert werden und liegt weiterhin im Bereich von 0.7.","77f07707":"Eine \"Baumtiefe\" von 50 beitet hierbei den besten MAE. Mit 0.691 liegt die Abweichung zwar unter dem Durchschnitt, allerdings ist sie weitergin sehr hoch.\n\nDennoch wird mit dieser Tiefe jetzt erneut eine Vorhersage gemacht.","2886fc71":"\"NaN\" steht f\u00fcr \"Not a Number\". Ob das f\u00fcr die vorhersage vom Nachteil ist, wussten wir zu diesem Zeitpunkt nicht und haben es daher vorerst ignoriert.","65da9c32":"**Modell verfeinern**\n\nEin weg das Modell zu verfeinern ist die tiefe des Entscheidungsbaumes zu ver\u00e4ndern. Ist ein Modell unpr\u00e4zise in den Testdaten, liefert aber gute Ergebnisse in den Trainingsdaten spricht man von 'Overfitting'. Sind auch die Trainingsdaten unpr\u00e4zise, so spricht man von 'Underfitting'. Ziel ist es, die richtige aufteilung des Entscheidungsbaumes zu finden. In unserem Fall sprechen wir von Overfitting, da der MAE der Testdaten deutlich h\u00f6her ist.\n\n![decisiontree](http:\/\/i.imgur.com\/2q85n9s.png)\n\nQuelle: https:\/\/www.kaggle.com\/dansbecker\/underfitting-and-overfitting\n","0477bc35":"**Test- und Trainingsdaten**\n\nDas Problem dieser Abweichung besteht darin, dass nur ein einziges \"Sample\" verwendet wird. Als Beispiel kann hier der \"Publisher\" verwendet werden (auch wenn er als Feature nicht verwendet wurde). Haben Spiele des selben Herstellers immer einen hohen Umsatz, lernt der Algorithmus aus diesem Muster und wird auch f\u00fcr zuk\u00fcnftige Spiele dieses Herstellers einen h\u00f6heren Umsatz vorhersagen. \n\nAus diesem Grund werden Datens\u00e4tze in Tainings- und Testdaten aufgeteilt. Aus dem Datensatz werden einige Daten als Testdaten verwendet, um mit diesen das Trainingsmodell pr\u00e4ziser zu gestalten und auf bisher unbekannte Daten anzuwenden.","9782eab7":"**Modell entwickeln**\n\nDas Modell wird zun\u00e4chst wie in der \u00dcbung mit dem DecisionTreeRegressor erstellt.","d4ebbcc6":"**Aufrufen der ersten 5 Eintr\u00e4ge**","d1bf5f9a":"Der Datensatz wird nun erneut in einer zusammengefassten Darstellung aufzurufen. Jede Spalte hat jetzt die gleiche Anzahl an Daten, wobei diese von \u00fcber 16.000 auf 6825 geschrumpft sind.","ed88fff9":"Die vorherige Funktion ruft erneut die Tabelle auf. Allerdings sind dieses Mal keine Daten enthalten, da alle fehlenden Daten gel\u00f6scht wurden.","bdb6031b":"Wie in der \u00dcbung verfeinern wir in unserem Modell die tiefe des Entscheidungsbaumes und lassen uns den MAE f\u00fcr unterschiedliche \"Leaf Nodes\" ausgeben.","c124f983":"**Daten f\u00fcr das Modell ausw\u00e4hlen**\n\nF\u00fcr diesen Datensatz sollen die Preise der Spiele vorhergesagt werden. Dazu ist es notwendig zu wissen, welche Daten hierf\u00fcr verwendet werden sollen. Zum einen muss das \"Prediction Target\" und zum anderen die \"Features\" bestimmt werden, mit dessen Hilfe die Vorhersage germacht wird.\n","5d8d64f2":"Mit den neuen Features kann der Code ausgef\u00fchrt werden und wir beginnen damit eine Vorhersage f\u00fcr die ersten und letzen f\u00fcnf Spiele zu machen:","c28f0b56":"Von allen 6825 Spielen liegt der h\u00f6chste Wert bei 82.53, wobei hier die Angabe in Millionen gemacht wird. Der niedrigste Wert liegt bei 0.01 und der Durchschnitt bei 0.77.","7f2d7aed":"Die \u00dcbersicht der Daten ist sehr \u00e4hnlich wie die der \u00dcbung. Auch hier ist auf den ersten Blick zu erkennen, dass einige Spalten nicht vollst\u00e4ndig mit Daten bef\u00fcllt sind (z.B. Critic_Score). F\u00fcr ein Seminar an der FH-Wedel k\u00f6nnten bereits zu Anfang einige Fragen gestellt werden, damit sich die Studenten n\u00e4her mit den Daten besch\u00e4ftigen.\n\n- Wie viele Daten sind vorhanden?\n- Wie ist der durchschnittliche Critic Score?\n- Wie alt ist das \u00e4lteste Spiel in dem Datensatz?","eaba7582":"Wie zu erkennen ist, fehlen in diesem Datensatz eine Menge an Daten - teilweise \u00fcber 50%. Um mit einem Modell weiterzuarbeiten, werden diese vorerst entfernt. Daher werden alle fehlenden Daten entfernt und in eine neue Variable gespeichert.","6bd85893":"Insgesamt sind jetzt noch 5811 Daten vorhanden. Auf Basis dieser Daten wird nun erneut der MAE, sowie der Score der logistischen Regression ermittelt.","95fb6915":"und mit den tats\u00e4chlichen Daten verglichen.","994d6f3a":"Zum Vergleich die tats\u00e4chlichen Ums\u00e4tze:","e88ec5c2":"**Grafische Ansichten**\n","f3b2841d":"**Lineare Regression**","0aa05767":"Der Score der logistischen Regression konnte auf fast 12% Ansteigen, aber auch hier zeigt sich, dass unser Modell weiterhin ungenau ist.\n\nDurch das Betrachten der Daten anhand von grafischen Abbildungen konnten weitere Fehlerquellen erkannt werden. Durch die Entfernung von Ausrei\u00dfern konnte der MAE um fast die h\u00e4lfte reduziert werden. F\u00fcr die weitere Verfeinerung des Modells m\u00fcssten weitaus mehr Kenntnisse im Bereich Machine Learning vorhanden sein. Die \u00dcbung an sich beitet einen guten Einstieg, reicht aber f\u00fcr die Bearbeitung einer Competition nicht aus.","10924a5d":"In unserem Notebook haben wir versucht anhand von vier Features die Global Sales vorherzusagen. Um die Daten grafisch zu betrachten haben wir jeweils ein Feature mit unserem Predicted Target gegen\u00fcbergestellt:","eaeb932f":"**Fehlerabwichung**\n\nAuf den ersten Blick sieht es so aus, als w\u00fcrde das Modell in dieser Form immer die korrekten Preise vorhersagen. Mithilfe des MAE (Mean Absolute Error) soll die Fehlerabweichung ermittelt werden.\n\nNOTE: Der MAE wird in diesem Fall nur \"In-Sample\" berechnet. Das Problem dahinter wird im n\u00e4chsten Teil beschrieben","55b79d8d":"Fast 400 der insgesamt 6825 Daten in der Spalte \"Global_Sales\" wurden als Au\u00dfrei\u00dfer identifiziert und entfernt.","36a37765":"Mit train_X und val_X wird die Aufteilung gezeigt. Hier ist zu sehen, dass in etwa 80% der Daten als Testdaten und 20% als Trainingsdaten verwendet werden.","b42ec8c8":"Zum Vergleich noch einmal der MAE ohne Trainingsdaten:","da9444c5":"Beim Aufrufen der ersten f\u00fcnf Eintr\u00e4ge f\u00e4llt auf, dass die Nummerierung in der linken Spalte nicht fortlaufend ist. Das liegt daran, dass wir zu Anfang des Notebook fehlende Eintrage gel\u00f6scht haben. So war zum Beispiel in Zeile 1 ein fehlender Wert enthalten, wodurch diese gel\u00f6scht wurde.","100121f7":"Der Score der Linearen Regression liegt hier bei 10,49%, was bedeutet das unsere Vorhersagen zu fast 90% ungenau sind. Aus diesem Grund werden in den folgenden Code Zeilen einige Methoden aus der \u00dcbung angewendet, um das Modell zu verfeinern.","03a2651d":"Die Prediction ist in der Variable y gespeichert und die Features in der Variable X. Diese werden in den Folgenden Zeilen aufgerufen.","5f2130dc":"Beim Vergleich wird aufgezeigt, wie ungenau die Vorhersage ist. Lediglich ein Wert (4621) kommt dem tats\u00e4chlichen ergebnis nahe. Die Fehlerabweichung bei einer Baumteife von 50 war zwar geringer, aber dennos nicht ausreichend f\u00fcr das Modell. Daher wird nun geguckt, ob der RandomForestDegressor eine bessere alternative bietet.","a5769b14":"**Fehlende Daten erkennen**\n\nWie bereits am Anfang erkannt besitzen die Spalten eine unterschiedliche Anzahl an vorhandenen Daten. Mit der nachfolgenden Funktion werden diese erkannt und anschlie\u00dfend ausgegeben.","76122262":"Hierbei ist zu erkennen, dass einige der Daten als Au\u00dfreiser betrachtet werden k\u00f6nnen, da sie nicht in das allgemeine Muster der grafik passen. Um diese Ausrei\u00dfer zu entfernen benutzen wir die unten aufgef\u00fchrte Funktion. Hier werden alle Daten im Bereich unter 25% bzw. \u00fcber 75% markiert und in den folgenden Codezeilen aus den jeweiligen Spalten entfernt.","b31b6f10":"Die Abweichung der Vorhersagen ist tats\u00e4chlich so gering, das sie nicht weiter beachtet bzw. durch die geringe Gr\u00f6\u00dfe nicht angezeigt wird.","833cf6b4":"Auch durch den RandonForestDegressor konnte der MAE nicht verbessert werden und lag sogar \u00fcber dem vorherigen MAE von 0.691.\n\nF\u00fcr ein Seminar an der FH Wedel ist der MAE ein valider Wert f\u00fcr die Beurteilung und Bewertung der Studenten. Doch auch andere Methoden k\u00f6nnen f\u00fcr eine Vorhersage verwendet werden. Dazu geh\u00f6rt die Lineare Regression. Diese war zwar nicht Teil der \u00dcbung, gibt aber einen weiteren Wert f\u00fcr eine sp\u00e4tere Bewertung der Arbeit.","7ced0fc8":"Zun\u00e4chst werden einige Pakete ben\u00f6tigt. Diese sind allerdings von Anfang an importiert und es musste keine \u00c4nderung vorgenommen werden. Die print-Funktion zeigt lediglich an, welche Dateien sich in dem Pfad befinden. Hier befindet sich unsere csv-Datei, welche im n\u00e4chsten Schritt in die Variable \"vgd\" geladen und aufgerufen wird.","b0b1a3f2":"Wie zu sehen ist, ist die eigentliche Fehlerabweichung deutlich h\u00f6her als gedacht. Sie liegt sogar \u00fcber dem durchschnittlichen Wert der Global_Sales von 0.77. Ein Grund hierf\u00fcr k\u00f6nnte die Wahl unserer Features sein. F\u00fcr ein pr\u00e4zises Modell m\u00fcssten auch andere Spalten wie Rating oder Genre mit einbezogen werden. Wie genau ein String als Feature verwendet werden kann, wird in der \u00dcbung allerdings nicht erw\u00e4hnt.\n\nZudem haben wir auch mehr als die H\u00e4lfte der Daten aufgrund von fehlenden Werten entfernt. Auch hier kann es bessere Methoden geben, welche ein tieferes Verst\u00e4ndnis \u00fcber Machine Learning erfordern.\n","02650603":"Die Spalte \"User_Count\" beinhaltet anschlie\u00dfend sogar fast 600 Ausrei\u00dfer, wohingegen bei den letzten beiden Spalte keine weitere Ver\u00e4nderung auftritt.","36ca6f5c":"**Fazit**\n\nDie \u00dcbung von Kaggle bietet einen guten ersten Einblick in das Thema Machine Learning. Anhand eines Beispiels werden die grundlegenden Prinzipien verdeutlicht. Allerdings konnte die \u00dcbung nicht erfolgreich auf unseren Datensatz angewendet werden. Unser Modell ist sehr ungenau und ohne ein tieferes Verst\u00e4ndnis in die Materie f\u00e4llt es schwer neue L\u00f6sungsans\u00e4tze zu finden. Die M\u00f6glichkeiten im Machine Learning sind so gro\u00df, dass sie kaum durch kleine \u00dcbungen abgebildet werden k\u00f6nnen. \n\nDamit wir besser verstehen wieso unser Modell ungeau ist, haben wir unsere Daten grafisch Dargestellt. Die grafische Darstellung war nicht Teil der von uns durchgef\u00fchrten \u00dcbungen. ","8eaa80c8":"Der MAE konnte von 0.691 auf 0.431 gesenkt werden. Das liegt unter dem Durchschnitt, aber noch immer ist die Fehlerabweichung sehr hoch.","56be03ce":"Die unten stehende Funktion ist ein zusammenfassender Aufruf der Spaltennamen:","4849bb22":"**Prediction Target & Features festlegen**\n\nWie zu Anfang erw\u00e4hnt, sollen die weltweiten Ums\u00e4tze vorhergesagt werden. Wie in der \u00dcbung m\u00fcssen hierf\u00fcr zun\u00e4chst das \"Prediction Target\" und die \"Features\" festgelegt werden. Das Prediction Target ist in diesem Fall die Spalte Global_Sales. Als Features werden folgende Werte genommen:\n\n\nUser Score, Critic Score, Rating, Year of Release, Genre","32a5a64d":"**Seminar Arbeit**\n\nIn diesem Notebook wird zum Einen die von Kaggle bereitgestellte \u00dcbung und zum Anderen selbst erlerntes Wissen verwendet, um einen von uns ausgew\u00e4hlten Datensatz zu bearbeiten. Der Datensatz enth\u00e4lt \u00fcber 16.000 Daten \u00fcber Videospiele und deren Einnahmen am Markt.","38bdefd5":"Auch durch die lineare Regression werden keine pr\u00e4zisen Vorhersagen durchgef\u00fchrt. Das macht deutlich, dass das Modell noch weiter ausgebaut werden muss. \u00c4hnlich wie der MAE kann auch bei der Linearen Regression ein Wert f\u00fcr die Validierung bestimmt werden."}}