{"cell_type":{"5b9f10c4":"code","90e89425":"code","e37b015d":"code","500ac1aa":"code","bac82587":"code","0cbfb727":"code","dd4b0af3":"code","36230373":"code","03822a0d":"markdown","c92fdcca":"markdown","d6b470c8":"markdown","d7641870":"markdown","ccb60604":"markdown","d881d926":"markdown","77837c9c":"markdown"},"source":{"5b9f10c4":"!pip install xlrd","90e89425":"!pip install AutoViz","e37b015d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\nfrom typing import Tuple, List, Dict\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline\n\n\n# read data\nin_kaggle = True\n\ndef get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n    train_path = ''\n    test_path = ''\n    sample_submission_path = ''\n\n    if is_in_kaggle:\n        # running in Kaggle, inside the competition\n        train_path = '..\/input\/tabular-playground-series-mar-2021\/train.csv'\n        test_path = '..\/input\/tabular-playground-series-mar-2021\/test.csv'\n        sample_submission_path = '..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv'\n    else:\n        # running locally\n        train_path = 'data\/train.csv'\n        test_path = 'data\/test.csv'\n        sample_submission_path = 'data\/sample_submission.csv'\n\n    return train_path, test_path, sample_submission_path\n\n","500ac1aa":"# main flow\nstart_time = dt.datetime.now()\nprint(\"Started at \", start_time)","bac82587":"%%time\n# get the training set and labels\ntrain_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n\ndf_train = pd.read_csv(train_set_path)\ndf_test = pd.read_csv(test_set_path)\n\nsubm = pd.read_csv(sample_subm_path)","0cbfb727":"df_train.info()","dd4b0af3":"\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()\ndftc = AV.AutoViz(\n    filename='', \n    sep='' , \n    depVar='target', \n    dfte=df_train, \n    header=0, \n    verbose=1, \n    lowess=False, \n    chart_format='png', \n    max_rows_analyzed=300000, \n    max_cols_analyzed=30\n)\n","36230373":"print('We are done. That is all, folks!')\nfinish_time = dt.datetime.now()\nprint(\"Finished at \", finish_time)\nelapsed = finish_time - start_time\nprint(\"Elapsed time: \", elapsed)","03822a0d":"# Basic Data Overview","c92fdcca":"# Initial Preparations\n\nWe are going to start with the essential pre-requisites as follows\n\n- installing *AutoViz* into this notebook\n- importing the standard Python packages we need to use down the road\n- programming the useful automation routines for repeatable data visualizations we are going to draw in the Advance Analytical EDA trials down the road","d6b470c8":"## Express Analysis Insights\n\nAs we can see, the simple express EDA analysis yielded a lot of useful insights out of the box, in less then 20 minutes of the data crunching. Below are the key finding from the charts generated by *AutoViz* on a generic basis.\n\n### Target Class Labels\n\nIt  is manifested the training dataset has unbalanced class labels for *target* variable. Therefore one of the following techniques has to be adapted in the pre-processing and ML down the road\n\n- oversampling the data using SMOTE or similar technique to balance the class labels in the resulted training set\n- smart undersampling the data to balance the class labels in the resulted training set\n- use adequate class label weights in the modelling with GBDT-style algorithms as well as any other algorithms supporting the class label weights\n\n### Feature-to-Target Relations\n\nWe find that the training set data manifests the following relations between the *target* and feature variables\n\n- all numeric variables except *cont9* demonstrate the good association with the target\n- we may want to try ML experiments with and without *cont9* to see what adds the edge\n- since the dataset seeems to be somewhat similar to the contests in Jan 2021 and Feb 2021\n\n\n### Numeric Feature Findings\n\nIt is demonstrated that\n\n- There is a clear separation of the observations in the training and test sets into well-contained and well separable clusters by the values of *cont4* (2 clusters detected for it, subject to further clustering experiments)\n- *cont5* demonstrates much more clusters in the data, however it is almost sure  to be less productive in ML down the road (similar to what we have observed in Jan 2021 and Feb 2021)\n- Distribution of the continual variables is identic on both the training and testing sets (the details for each variables are provided below)\n- There are certain pairs of highly correlated numeric features with corr >= 0.7 ( cont0-cont01, cont0-cont7, cont1-cont2, cont1-cont8, cont7-cont10)\n- *cont0, cont1, cont2, cont3, cont6, cont7, cont8, cont9*, and *cont10* are highly skewed to the left \n- *cont5* is skewed to the right\n- *cont4* demonstrates the perfrect binomial distribution (and it can be the good feature to use in possible clustering experiments\n\n\n\n### Categorical Feature Findings\n\nFirst of all, unlike the datasets for the tabular playground competitions for Jan and Feb 2021, this dataset proved to have irrelevant (noisy) category variables. *featurewiz*, the secret sauce of *AutoViz*, detected four categories of this sort as follows\n\n- *'cat5'*\n- *'cat7'*\n- *'cat8'*\n- *'cat10'*\n\nIt is suggested to exclude such variables from the ML experiments down the road.\n\nIt has been additionally detected that the rest of the category variables show weak relations with the target and them as well as with the numeric variables (similar to what has been observed in the contests for Jan 2021 and Feb 2021). Therefore the similar ML approaches that worked in the previous playground tabular competitions will be applicable here as well.\n\n\n","d7641870":"# References\n\nSince the dataset in this competition is quite similar to ones for Jan 2021 and Feb 2021 tabular playground competitions, it could be useful to review the EDA findings for the mentioned competitions too\n\n- Feb 2021 Tabular Playground Contest: https:\/\/www.kaggle.com\/gvyshnya\/generic-express-eda-with-comprehensive-insights\n- Jan 2021 Tabular Playground Contest: https:\/\/www.kaggle.com\/gvyshnya\/using-autoviz-to-build-a-comprehensive-eda","ccb60604":"## Express Analysis of Training Set","d881d926":"# Express EDA Analysis \n\nWe are going to invoke *AutoViz*, one of the prominent freeware Pythonic Rapid EDA tools, to quickly draw the basic insights about the data","77837c9c":"# Introduction\n\nThis notebook is intended to extract useful insights for the datasets of \u2018Tabular Playground Series - Mar 2021\u2019 competition in Kaggle. For this competition, it is required to tackle the Regression problem to predict a continuous target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.\n\nWe are going to perform the complete and comprehensive EDA as follows\n-\tAutomate the generic aspects of EDA with AutoViz, one of the leading freeware Rapid EDA tools in Pythonic Data Science world\n-\tDeep into the problem-specific advanced analytical questions\/discoveries with the custom manual EDA routines programmed on top of standard capabilities of Plotly and Matplotlib\n"}}