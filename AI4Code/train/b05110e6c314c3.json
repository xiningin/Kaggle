{"cell_type":{"e319ce41":"code","344bae49":"code","471f016b":"code","c1682673":"code","29716125":"code","794f0a65":"code","fc0a5257":"code","329b7966":"code","7afc8f22":"code","8ab02320":"code","c19f3b06":"code","4313b23f":"code","557db6e1":"code","202fa57c":"code","49c945c9":"code","85957962":"code","724c69fb":"code","633fc189":"code","a03c7504":"code","5ee6f02d":"code","1471ea6d":"code","2c188945":"code","81dfeb50":"code","71c06fee":"code","e4e5a1a3":"code","4914f56b":"code","3671440c":"code","462f8819":"code","766687e8":"code","f81f40b0":"code","5948c3e5":"code","48730cb3":"code","d47461cd":"code","b4310bd7":"code","f01fb605":"code","5eb33bcd":"code","822e07cf":"code","b3b62fbe":"code","1c5819db":"code","b382fbb6":"code","b735adef":"code","9ba667be":"code","e7cc87bb":"code","1e64c3d4":"code","593c3ad8":"code","b6e1983f":"code","aa222841":"code","a56902bf":"code","29356968":"markdown","fcd8244e":"markdown","de8068ac":"markdown","e1a905bf":"markdown","95c8c9e4":"markdown","af681664":"markdown","9f90d7d7":"markdown","c1e561cd":"markdown","a2676492":"markdown","ed2bd5d9":"markdown","f8826a34":"markdown","e958921f":"markdown","c6e15279":"markdown","6fbd40fc":"markdown","800453e4":"markdown","18cc8129":"markdown","e6542dda":"markdown","0b71ec70":"markdown","0e6d2914":"markdown","9eaa5a4a":"markdown","4cfde89a":"markdown","019f17b9":"markdown","a06edac3":"markdown"},"source":{"e319ce41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","344bae49":"# Linear Algebra\nimport numpy as np\n\n# Data Processing\nimport pandas as pd\n\n# Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data Preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\n# Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\n# Support Vector Classifier\nfrom sklearn.svm import SVC\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Cross Validation\nfrom sklearn.model_selection import cross_val_score","471f016b":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","c1682673":"train.head()","29716125":"train.info()","794f0a65":"test.head()","fc0a5257":"test.info()","329b7966":"plt.figure(figsize = (15, 5))\nfor i in range(train[['Age', 'Fare']].shape[1]):\n  plt.subplot(1, 2, i+1)\n  sns.distplot(train[['Age', 'Fare']].iloc[:, i])","7afc8f22":"plt.figure(figsize = (15, 5))\nfor i in range(train[['SibSp', 'Parch']].shape[1]):\n  plt.subplot(1, 2, i+1)\n  sns.countplot(x = train[['SibSp', 'Parch']].iloc[:, i])","8ab02320":"plt.figure(figsize = (8, 5))\nsns.countplot(x = train['SibSp'] +  train['Parch'] + 1, hue = train.Survived)\nplt.xlabel('Family Size')\nplt.show()","c19f3b06":"plt.figure(figsize = (15, 4))\nfor i in range(train[['Sex', 'Pclass', 'Embarked']].shape[1]):\n  plt.subplot(1, 3, i+1)\n  sns.countplot(x = train[['Sex', 'Pclass', 'Embarked']].iloc[:, i], hue = train.Survived)","4313b23f":"train['Title'] = train['Name'].str.extract(pat = '([a-zA-Z]+)\\.', expand = False)\ntrain.Title.value_counts()","557db6e1":"train['Title'] = train['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')\ntrain['Title'] = train['Title'].replace(['Mlle', 'Mme', 'Ms', 'Don', 'Rev', 'Lady', 'Sir', 'Major', 'Col', 'Capt', 'Countess', 'Jonkheer', 'Dr'], 'Other')","202fa57c":"test['Title'] = test['Name'].str.extract(pat = '([a-zA-Z]+)\\.', expand = False)\ntest.Title.value_counts()","49c945c9":"test['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace(['Rev', 'Col', 'Dona', 'Dr'], 'Other')","85957962":"train['Cabin_Code'] = train.Cabin.str[0]\ntrain.Cabin_Code.value_counts()","724c69fb":"plt.figure(figsize = (8, 4))\nsns.countplot(x = train.Cabin_Code, hue = train.Survived)\nplt.show()","633fc189":"test['Cabin_Code'] = test.Cabin.str[0]\ntest.Cabin_Code.value_counts()","a03c7504":"train['Ticket_Numeric'] = train.Ticket.str.isnumeric().astype('uint8')\ntest['Ticket_Numeric'] = test.Ticket.str.isnumeric().astype('uint8')","5ee6f02d":"pd.pivot_table(train,index='Survived',columns='Ticket_Numeric',values='Name', aggfunc='count', fill_value=0)","1471ea6d":"train['Ticket_Alphabets'] = train.Ticket.str.extract('([A-Za-z.\/0-9]+\\ )', expand = False)","2c188945":"train.Ticket_Alphabets.value_counts()","81dfeb50":"train['Ticket_Alphabets'] = train.Ticket_Alphabets.str.lower().str.extract('([a-z.]+)')\ntrain['Ticket_Alphabets'] = train.Ticket_Alphabets.str.replace('.', '', regex = True)","71c06fee":"train.Ticket_Alphabets.value_counts()","e4e5a1a3":"train.loc[(train['Title']=='Mr') & (train['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Mr'), 'Age'].mean(skipna = True)\ntrain.loc[(train['Title']=='Mrs') & (train['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Mrs'), 'Age'].mean(skipna = True)\ntrain.loc[(train['Title']=='Miss') & (train['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Miss'), 'Age'].mean(skipna = True)\ntrain.loc[(train['Title']=='Master') & (train['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Master'), 'Age'].mean(skipna = True)\ntrain.loc[(train['Title']=='Other') & (train['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Other'), 'Age'].mean(skipna = True)","4914f56b":"train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode().iloc[0])","3671440c":"# We use the mean ages of training data only to fill the missing values in the testing data.\ntest.loc[(test['Title']=='Mr') & (test['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Mr'), 'Age'].mean(skipna = True)\ntest.loc[(test['Title']=='Mrs') & (test['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Mrs'), 'Age'].mean(skipna = True)\ntest.loc[(test['Title']=='Miss') & (test['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Miss'), 'Age'].mean(skipna = True)\ntest.loc[(test['Title']=='Master') & (test['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Master'), 'Age'].mean(skipna = True)\ntest.loc[(test['Title']=='Other') & (test['Age'].isna()), 'Age'] = train.loc[(train['Title']=='Other'), 'Age'].mean(skipna = True)","462f8819":"test['Fare'] = test['Fare'].fillna(train['Fare'].median())","766687e8":"train = pd.get_dummies(data = train, columns = ['Sex', 'Embarked'], drop_first = True)\ntrain = pd.get_dummies(data = train, columns=['Cabin_Code'])","f81f40b0":"test = pd.get_dummies(data = test, columns = ['Sex', 'Embarked'], drop_first = True)\ntest = pd.get_dummies(data = test, columns=['Cabin_Code'])\ntest['Cabin_Code_T'] = 0\n# Since there was no one in the test set with Cabin Code T, we create a new column to match the structures of the training and testing datasets.","5948c3e5":"sc = StandardScaler()\ntrain[['Age', 'Fare']] = pd.DataFrame(sc.fit_transform(train[['Age', 'Fare']]))\ntest[['Age', 'Fare']] = pd.DataFrame(sc.transform(test[['Age', 'Fare']]))","48730cb3":"train = train.drop(columns = ['Cabin', 'Ticket', 'PassengerId', 'Name', 'Title', 'Ticket_Alphabets'])","d47461cd":"test = test.drop(columns = ['Cabin', 'Ticket', 'PassengerId', 'Name', 'Title'])","b4310bd7":"X = train.drop(columns = ['Survived'])\ny = train['Survived']","f01fb605":"X.head()","5eb33bcd":"test.head()","822e07cf":"# Logistic Regression\nclassifier_lr = LogisticRegression(penalty = 'l2', random_state=0)","b3b62fbe":"# Naive Bayes\nclassifier_nb = GaussianNB()","1c5819db":"# Support Vector Machine\nclassifier_svm = SVC(C=1, kernel='rbf', gamma = 'auto')","b382fbb6":"# Random Forest\nclassifier_rf = RandomForestClassifier(n_estimators=100, criterion = 'entropy', min_samples_split=10, random_state=0)","b735adef":"lr = cross_val_score(estimator = classifier_lr, X = X, y = y, cv = 10)\nprint(lr)","9ba667be":"nb = cross_val_score(estimator = classifier_nb, X = X, y = y, cv = 10)\nprint(nb)","e7cc87bb":"svm = cross_val_score(estimator = classifier_svm, X = X, y = y, cv = 10)\nprint(svm)","1e64c3d4":"rf = cross_val_score(estimator = classifier_rf, X = X, y = y, cv = 10)\nprint(rf)","593c3ad8":"model = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest']\naccuracy_mean = [np.mean(lr), np.mean(nb), np.mean(svm), np.mean(rf)]\naccuracy_std = [np.std(lr), np.std(nb), np.std(svm), np.std(rf)]","b6e1983f":"K_Fold = pd.DataFrame({'Model' : model, 'Accuracy_Mean' : accuracy_mean, 'Accuracy_Std' : accuracy_std})\nprint(K_Fold)","aa222841":"classifier_svm.fit(X, y)\ny_pred = classifier_svm.predict(test)","a56902bf":"predictions = pd.DataFrame({\"PassengerId\" : list(range(892, 892 + len(y_pred))),\"Survived\" : y_pred})\npredictions.to_csv('predictions.csv', index = False)","29356968":"* We can see that the SVM gives the highest accuracy. So we will use SVM to make the final predictions.","fcd8244e":"# Model Training","de8068ac":"* There are a lot of unique values lets try to group them and see if we can find something useful.","e1a905bf":"Next we take a look at the alphabetic part of the Ticket and try to find some useful information.","95c8c9e4":"* We can see that the passengers with Cabin Code E, D and B are more likely to survive. Cabin Code might be helpful for making the predictions. ","af681664":"# Feature Engineering","9f90d7d7":"### Missing Values:","c1e561cd":"# Predicting the Test Results","a2676492":"### Standardizing the data:","ed2bd5d9":"### Encoding the Categorical Variables:","f8826a34":"We observe that some of the tickets are numeric but some tickets have an alphabetic part as well. So let's see how this affects the survival of a passenger.","e958921f":"* We can see that people who travel alone and those with family size more than 4 are less likely to survive.","c6e15279":"### Ticket:","6fbd40fc":"### Name:\n<p>We will use Name feature to extract the Titles, which will be further used to fill the NA values in the Age column.<\/p>\n\n\n","800453e4":"# Data Visualisation","18cc8129":"### Removing the irrelevant columns:","e6542dda":"* Females have a higher chance of survival.\n* People of lower socioeconomic status are less likely to survive.","0b71ec70":"# Importing Libraries","0e6d2914":"# Cross Validation","9eaa5a4a":"### Cabin:\n<p>Cabin has a lot of NA values, but let's see if we can find something useful.<\/p>","4cfde89a":"# Importing Dataset","019f17b9":"* Still there are a lot of unique values and most of them have very less count. So looking at the Alphabetical part was not very helpful.","a06edac3":"# Data Preprocessing"}}