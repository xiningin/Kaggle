{"cell_type":{"f4e091fe":"code","027d3ea2":"code","691f6569":"code","6f13b6c2":"code","3da58217":"code","29b8e09a":"code","ab2656a1":"code","5aaab203":"code","7fb519a0":"code","896eb4c7":"code","a686bf1d":"code","6d4ae4c0":"code","adcd95a8":"code","b978f525":"code","886d53e6":"code","843f7b88":"code","d823bd22":"code","5f9cecc0":"code","81d06b61":"code","85f986f1":"code","0d850b9e":"code","cfd84aa0":"code","d4bf9877":"code","2abe8787":"code","d28764e1":"code","a19156d1":"code","eccb00c7":"code","580018fd":"code","44149065":"code","555e3531":"code","1ba64ff3":"markdown","01b713eb":"markdown","8798f402":"markdown","4920af29":"markdown","c5bf9ee9":"markdown","064969e7":"markdown","06109fda":"markdown","989ef4ef":"markdown","8593a6d0":"markdown","354919a6":"markdown","4f2db34c":"markdown","5be26c0a":"markdown","6cb1f7bb":"markdown","a33bd1f7":"markdown","7ae145a5":"markdown","0ff6f3ce":"markdown","f45bf125":"markdown","298b6e57":"markdown","2cedfdfa":"markdown","5991bd19":"markdown","c9c9a0bb":"markdown","92f28196":"markdown","5eb0aff4":"markdown","a14b0e0e":"markdown","e9b22a7d":"markdown","93a583d1":"markdown","bb0188d8":"markdown","65fa2db2":"markdown","b1659adb":"markdown","b634e5d8":"markdown","fa6471f3":"markdown","0f085fc7":"markdown","686f30fd":"markdown","24e4fb29":"markdown","21858227":"markdown","13c2392b":"markdown","cba317ce":"markdown","b2a07c7e":"markdown"},"source":{"f4e091fe":"%matplotlib inline\nimport numpy as np                   # advanced math library\n\n# for reproducibility\nfrom numpy.random import seed\nseed(42)\nimport tensorflow as tf\ntf.random.set_seed(42)\n\nimport matplotlib.pyplot as plt      # MATLAB like plotting routines\nimport random                        # for generating random numbers\n\nfrom keras.datasets import mnist     # MNIST dataset is included in Keras\nfrom keras.models import Sequential  # Model type to be used\n\nfrom keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\nfrom keras.utils import np_utils                         # NumPy related tools\n\nfrom sklearn.model_selection import train_test_split # some helper from scikit for data split\n\n#get rid of annoying GPU warnings (and others)\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","027d3ea2":"# The MNIST data is usually split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# Split the train and a majority validation (test) set to emphasize data dependence\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.9, random_state=0)\n\nprint(\"X_train shape\", X_train.shape)\nprint(\"y_train shape\", y_train.shape)\nprint(\"X_val shape\", X_val.shape)\nprint(\"y_val shape\", y_val.shape)\nprint(\"X_test shape\", X_test.shape)\nprint(\"y_test shape\", y_test.shape)","691f6569":"plt.rcParams['figure.figsize'] = (9,9) # Resize figures\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    num = random.randint(0, len(X_train))\n    plt.imshow(X_train[num], cmap='gray')\n    plt.title(\"Class {}\".format(y_train[num]))\n    \nplt.tight_layout()","6f13b6c2":"X_train = X_train.reshape(6000, 784)   # reshape 6,000 28 x 28 matrices into 10,000 784-length vectors.\nX_val = X_val.reshape(54000, 784)   # reshape 54,000 28 x 28 matrices into 10,000 784-length vectors.\nX_test = X_test.reshape(10000, 784) # reshape 10,000 28 x 28 matrices into 60,000 784-length vectors.\n\nX_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\nX_val = X_val.astype('float32')   # change integers to 32-bit floating point numbers\nX_test = X_test.astype('float32')\n\nprint(\"Training matrix shape\", X_train.shape)\nprint(\"Validation matrix shape\", X_val.shape)\nprint(\"Testing matrix shape\", X_test.shape)","3da58217":"# normalize each value for each pixel for the entire vector for each input\nX_train \/= 255\nX_val \/= 255\nX_test \/= 255","29b8e09a":"nb_classes = 10 # number of unique digits\n\ny_train = np_utils.to_categorical(y_train, nb_classes)\ny_val = np_utils.to_categorical(y_val, nb_classes)\ny_test = np_utils.to_categorical(y_test, nb_classes)","ab2656a1":"# Start with a Sequential model, which is a linear stack of layers and common to many architectures.\nmodel = Sequential()","5aaab203":"# The first hidden layer contains 512 neuron nodes\n# Each node receives from an input vector and applies weight and bias to it.\n# The process starts with a random weights (you might see this later during training if you lucky!)\n\nmodel.add(Dense(512, input_shape=(784,))) # a 784 length vector, but where does 784 come from?","7fb519a0":"# An \"activation\" in neural networks is a non-linear function applied to the output of the above layer.\n# Checks the new value of the node, to see if it that artifical neuron has fired (sum of input neurons > threshold).\n# The Rectified Linear Unit (ReLU) converts all negative inputs to nodes in the next layer to be zero, making them \"not fired\"\n# Positive values of a node are okay and therefore unchanged.\n\nmodel.add(Activation('relu'))","896eb4c7":"# Dropout zeroes some random outputs (disables their activation)\n# Dropout regularized the model, i.e. reduces\/prevents overfitting the training data because the goal is not to just memorize but generalize!\nmodel.add(Dropout(0.2))","a686bf1d":"# Identical to the previous layer, but since it is receiving Hidden layer 1's output\n# it receives 512 nodes instead of the 784-inputs from the input image data\n\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))","6d4ae4c0":"# The final layer contains units equal to the number of desired classes (10).\nmodel.add(Dense(10))","adcd95a8":"# Softmax activation function represents a probability distribution over K different possible outcomes.\n# Its values are all non-negative and sum to 1. Also known as the softer version of argmax\n\nmodel.add(Activation('softmax'))","b978f525":"# Visualize the whole network in a crude high-level diagram\n\nmodel.summary()","886d53e6":"# Popular Adam optimizer for quick learning\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","843f7b88":"model.fit(X_train, y_train,\n          batch_size=128, epochs=10, validation_data=(X_val, y_val),\n          verbose=1)","d823bd22":"score = model.evaluate(X_test, y_test)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","5f9cecc0":"# import CNN tools\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n","81d06b61":"# Reload the MNIST data to get the original shape (not the flattened 1D vector)\n(X_train,y_train), (X_test,y_test) = mnist.load_data()\n\n# Split the train and a majority validation set to emphasize data dependence (same as before)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.9, random_state=0)","85f986f1":"# Again, do some formatting\n# Except don't flatten images into a 784-length vector so that 2D convolutions can first be performed\n\nX_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\nX_val = X_val.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255                              # normalize each value for each pixel for the entire vector for each input\nX_val \/= 255\nX_test \/= 255\n\nX_train = X_train.reshape(-1,28,28,1)\nX_val = X_val.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\nprint(\"Training matrix shape\", X_train.shape)\nprint(\"Validation matrix shape\", X_val.shape)\nprint(\"Testing matrix shape\", X_test.shape)","0d850b9e":"# one-hot format classes\n\nnb_classes = 10 # number of unique digits\n\ny_train = np_utils.to_categorical(y_train, nb_classes)\ny_val = np_utils.to_categorical(y_val, nb_classes)\ny_test = np_utils.to_categorical(y_test, nb_classes)","cfd84aa0":"model = Sequential()                                 # Linear stacking of layers\n\n# Convolution Layer 1\nmodel.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\nmodel.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\nmodel.add(Activation('relu'))                        # activation\n# model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n\n# Convolution Layer 2\nmodel.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\nmodel.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\nmodel.add(Activation('relu'))                        # activation\nmodel.add(MaxPooling2D(pool_size=(2,2)))         # Pool the max values over a 2x2 kernel\n# model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n\n# Convolution Layer 3\nmodel.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\nmodel.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\nmodel.add(Activation('relu'))                     # activation\n# model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n\n# Convolution Layer 4\nmodel.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\nmodel.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\nmodel.add(Activation('relu'))                        # activation\nmodel.add(MaxPooling2D(pool_size=(2,2)))          # Pool the max values over a 2x2 kernel\nmodel.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n# model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n\n# Fully Connected Layer 5\nmodel.add(Dense(512))                                # 512 FCN nodes\nmodel.add(BatchNormalization())                      # normalization\nmodel.add(Activation('relu'))                        # activation\n# model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n\n# Fully Connected Layer 6\nmodel.add(Dense(10))                                 # final 10 FCN nodes\nmodel.add(Activation('softmax'))                     # softmax activation","d4bf9877":"model.summary()","2abe8787":"# we'll use the same optimizer\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","d28764e1":"# Besides loss function considerations as before, this method actually results in significant memory savings\n# because we are actually LOADING the data into the network in batches before processing each batch\nbatch_sz = 128\nnum_epochs = 10\n\nmodel.fit(X_train, y_train, batch_size=batch_sz, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)\n\n","a19156d1":"score = model.evaluate(X_test, y_test)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","eccb00c7":"# With data augmentation to prevent overfitting\n\ngen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ngen2 = ImageDataGenerator()\n\ntrain_gen = gen.flow(X_train, y_train, batch_size=batch_sz)\n","580018fd":"# Fit the model\nhistory = model.fit(train_gen, batch_size=batch_sz, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)\n\n# plot history in terms of accuracy per epoch\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n","44149065":"score = model.evaluate(X_test, y_test)\nprint('Test score with Augmentation:', score[0])\nprint('Test accuracy with Augmentation:', score[1])","555e3531":"#!pip install keract\n# from keract import get_activations, display_heatmaps, display_activations\n# keract_inputs = X_test[0:1]\n# keract_targets = y_test[0:1]\n# activations = get_activations(model, keract_inputs)\n# display_activations(activations, cmap=\"gray\", directory='Activations\/', fig_size=(9, 9))\n","1ba64ff3":"## Use Matplotlib to visualize *random* sample images of the *training set* only.","01b713eb":"The image is a 5 x 5 matrix and the kernel going over it is a 3 x 3 matrix.\nA dot product operation between the image and the kernel and the convolved feature is generated.\nEach kernel in a CNN learns a different characteristic of an image.","8798f402":"![gradient_descent.png](attachment:fc8f816e-9ab8-441e-bf2e-f07853ac266e.png)","4920af29":"## Compiling the model and learning rate\n\nKeras needs you to specify a **loss function** and **optimizer** before compiling the model.\n*categorical cross-entropy* is a loss function well-suited to comparing probability distributions (for softmax).\n\nProbability distributions across ten different digits. e.g. 80% confident image is of class 3, 10% confident it's class 8, 5% class 2, etc.\nTarget is a probability distribution with 100% correct category, and 0 for everything else. Cross-entropy thus measures how different the\npredicted distribution is from the target distribution. [More detail at Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Cross_entropy)\n\nThe optimizer determines how quickly the model learns through **gradient descent**. How fast it descends a gradient is the **learning rate**.","c5bf9ee9":"## Final Layer (aka the top-layer before softmax classification)","064969e7":"$$f(x) = max (0,x)$$\n![relu.jpg](attachment:a871228c-c7f5-4dac-a867-9bea011ff998.jpg)","06109fda":"# Please click like (upvote) if you enjoyed this notebook!","989ef4ef":"## The goal\n\nParticipants learn simplified theory and then construct and train two classification models on a limited set of images of handwritten digits, such that it works effectively on unseen data.\n\nDataset: MNIST, which contains 70000 images in total and will be used for this purpose.\nTools: Keras Python API with TensorFlow as the backend.\n\nOutcomes:\n* Fully Connected Neural Networks\n* Intro to Convolutional Neural Networks\n* Data Augmentation to combat inadequate amount of training data","8593a6d0":"## Hidden layer 2","354919a6":"![kernels.png](attachment:e9be70f7-8a23-4b69-8a45-cb4dccb3cde7.png)","4f2db34c":"![convolution.gif](attachment:b2d86248-852b-4ce0-9d01-f0d94b24c9f4.gif)","5be26c0a":"# References\n\n1. https:\/\/keras.io\/models\/sequential\/\n2. https:\/\/keras.io\/layers\/core\/\n3. https:\/\/keras.io\/layers\/convolutional\/\n4. https:\/\/keras.io\/layers\/pooling\/\n5. https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n","6cb1f7bb":"## Results\nResults show the effectiveness of regularization for reducing overfitting","a33bd1f7":"Encode output classes (unique digits 0-9) to one-hot format, i.e.\n\n```\n0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n...\n9 -> [0, 0, 0, 0, 0, 0, 0, 0, 1]\n```\n\nLikely a match if the final output of network is close to one of these classes. e.g. if the final output is:\n\n```\n[0, 0.76, 0, 0, 0, 0, 0.24, 0, 0]\n```\nthen its probably digit `1`.","7ae145a5":"## Loading and splitting the dataset","0ff6f3ce":"### Max Pooling\nKernels in CNNs are similarly used to highlight salient features.\nThis is combined with **max pooling**, where non-highlighted elements are\ndiscarded per feature map, while keeping features of interest.\nThis reduces number of learned parameters and computational cost.\n","f45bf125":"### Convolution\nThis possible through convolution! Convolution applies **kernels** (filters) that traverse through each image and generate **feature maps**.","298b6e57":"The batch size determines the amount of data per step for computing the loss function, gradients, and back propagation. Large batch sizes allow the network to\ntrain faster but there are other factors to consider:\n\nToo large a batch size can cause the optimizer to stop as it prematurely thinks it found a global minima\n\nToo small results in a noisy loss function, and the optimizer may struggle to or never find global minima.\n","2cedfdfa":"![learning_rate.png](attachment:aca79249-f229-4d76-9b97-7fa4d8140a9a.png)","5991bd19":"## Import the following Python modules","c9c9a0bb":"# Introducing Convolutional Neural Networks","92f28196":"![max_pooling.png](attachment:a592ecbb-c792-45c7-b131-d27363c05651.png)","5eb0aff4":"Are smaller learning rates better? Often BUT...\nOverly low can cause optimizer to get stuck in local minima, missing the global minimum of\nthe loss function.\n\nKind of like tunnel vision. A larger learning rate can help jump out of a local minimum.","a14b0e0e":"## Second model: constructing a Convolutional Neural Network (CNN)","e9b22a7d":"# First model: constructing the 3-layer fully connected network\n\n![figure.png](attachment:4c9c222d-f63c-4aa4-b2f5-ff33ea44781a.png)","93a583d1":"![flatten.png](attachment:19e625a7-e711-4d91-bdfd-1cea511752b3.png)","bb0188d8":"## Formatting the input data layer\n\nInstead of a 28 x 28 matrix, build a fully connected network that accepts a 784-length vector, i.e. flattened to 1D vector.\n\nEach image is thus reshaped (flattened) into a vector. Values are normalized to [0-1] range instead of the original [0-255]. This enables any additional dimensions to be on the same scale.","65fa2db2":"## Hidden layer 1","b1659adb":"Before, we built a network that accepts the normalized pixel values of each value and operates soley on those values. What if we could instead feed different features (e.g. **curvature, edges**) of each image into a network, and have the network learn which features are important for classifying an image?","b634e5d8":"### Batch Normalization\nThe last concept is  which does what it says, it scales and centres for faster convergence and stability. You'll notice how\ndropout layers can make training less stable later.","fa6471f3":"### Kernels\nOften used in image processing: blur, edge detection, sharpening, etc.","0f085fc7":"As you can see a pixel is an 8-bit integer from 0-255. 0 is black, while 255 is white.\nThis single-channel pixel is also called greyscale.","686f30fd":"This workshop serves as a one-hour crash course that aims to teach you the basics of implementing Convolutional Neural Networks (CNNs) and the importance of having enough data.\n\nA practical demonstration of this involves building two models for classifying handwritten digits. The first model is a fully-connected neural network, which is first required to understand CNNs. The second is a deeper network that leverages convolutions and pooling to construct a more capable classifier for modern applications.","24e4fb29":"# Introduction to CNNs with Keras (Python)","21858227":"# Trying experimenting with the learning rate and batch size in your own time\n\n#### How does increasing the batch size to 10,000 affect the training time and test accuracy?\n\n#### How about a batch size of 32?\n\n#### Or does it make sense to tune them using a parameter search?\n\n#### Can we add more hidden layers?","13c2392b":"## Bonus\nWouldn't it be nice to visualize the convolutions to see what the model is seeing? Let's visualize the first \"unseen\" image. Uncomment the following","cba317ce":"## Train the first model (finally!)","b2a07c7e":"## Evaluate first model's accuracy on unseen (test set)"}}