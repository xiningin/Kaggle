{"cell_type":{"7526f296":"code","fe2d1acc":"code","5d45fc5e":"code","5d7341e8":"code","ce7876c8":"code","f376b971":"code","96ada06f":"code","91e3ab9a":"code","b9133507":"code","641f39a0":"code","04cf6ad6":"code","c03dfc3d":"code","5cf53fb5":"code","2199c714":"code","56c4d605":"code","2c011a3f":"code","d3680201":"code","0354a0c4":"code","cd9c901d":"code","e442a0d4":"code","b82a7b29":"code","0b8faa05":"code","6ce98c1b":"code","b352260f":"code","0b5012da":"code","184f52c9":"code","c69eddbd":"code","4ebd3dac":"code","054369bd":"code","2a143d63":"code","27ea537a":"code","319ccae1":"code","75bf156c":"code","d1ff1e17":"code","352940e3":"code","decd02f2":"code","e7d823aa":"code","1c362d0c":"code","bf2ae6ba":"code","bda8c441":"code","a02c0e47":"code","6cc661e6":"code","676bc38d":"code","c001d1ab":"code","a109addb":"code","f97534b9":"code","df24ecfd":"code","f42276b1":"code","1686f183":"code","0cc796d2":"markdown","f8343afc":"markdown","9aa385dc":"markdown","315513c9":"markdown","c0758e41":"markdown","30f998f8":"markdown","17b385a6":"markdown","1c9fb6c7":"markdown","d47d6c11":"markdown","bc494b85":"markdown","3f56aa29":"markdown","9a0e19bb":"markdown","59a1cc4b":"markdown","8500842a":"markdown","ce5407a8":"markdown","b660589f":"markdown","d1c449e4":"markdown","1ea6b5eb":"markdown","deb12377":"markdown","a5d71903":"markdown","ff3ef161":"markdown","8d86403f":"markdown","ae968d21":"markdown","fbfa7e35":"markdown","e244aa33":"markdown","54a8a3be":"markdown","6dba1425":"markdown","dbcb5dc3":"markdown","9e057451":"markdown","ec50a436":"markdown","0ea7f4b2":"markdown","7cef89f7":"markdown","be2bdba3":"markdown","7b3cf861":"markdown","ac98caa7":"markdown","de32c0aa":"markdown","434214ff":"markdown","453a5d8c":"markdown","95ba8340":"markdown"},"source":{"7526f296":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nplt.style.use('ggplot')\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,classification_report\n\nfrom IPython.core.interactiveshell import InteractiveShell \nInteractiveShell.ast_node_interactivity = \"all\"\n\nseed = np.random.seed(21)","fe2d1acc":"#Loading Train Data \ndata_train = pd.read_csv(\"..\/input\/costa-rican-household-poverty-prediction\/train.csv\")\ndisplay(data_train.shape, data_train.head())","5d45fc5e":"#Loading Test Data\ndata_test = pd.read_csv(\"..\/input\/costa-rican-household-poverty-prediction\/test.csv\")\ndisplay(data_test.shape, data_test.head())","5d7341e8":"data_train_info = pd.DataFrame(columns=['Name of Col', 'Num of Null', 'Dtype', 'N_Unique'])\n\nfor i in range(0, len(data_train.columns)):\n    data_train_info.loc[i] = [data_train.columns[i],\n                        data_train[data_train.columns[i]].isnull().sum(),\n                        data_train[data_train.columns[i]].dtypes,\n                        data_train[data_train.columns[i]].nunique()] \ndata_train_info\n\n#data_train_info.iloc([\"Num of Null\" != 0])","ce7876c8":"#count of unique rows in Target column\ndata_train[\"Target\"].value_counts()","f376b971":"data_train['Target'].value_counts().plot.bar(width = 0.4, color = 'c', edgecolor = 'k', linewidth = 1)\nplt.xlabel(\"Target Values\")\nplt.ylabel(\"Count of Households\")\nplt.title(\"Target Column Spread\")\nplt.show()","96ada06f":"#households with same poverty level\npoverty_equal = data_train.groupby('idhogar')['Target'].apply(lambda X: X.nunique() == 1) \n#households with un-equal poverty level\npoverty_nequal = poverty_equal[poverty_equal != True] \nprint(\"There are {} households where all the family members of the house do not have same poverty level.\" .format(len(poverty_nequal)))","91e3ab9a":"#households with head\nhousehold_head = data_train.groupby('idhogar')['parentesco1'].sum()","b9133507":"#households without head\nhousehold_without_head = data_train.loc[data_train['idhogar'].isin(household_head[household_head == 0].index), :]\nhousehold_without_head[\"idhogar\"].nunique()","641f39a0":"#Finding the Households without head and poverty level(Target Value) is different\n\nhousehold_without_head_equal = household_without_head.groupby('idhogar')['Target'].apply(lambda X: X.nunique() == 1) \nprint(\"{} households without head have different PovertyLevel\/Target Value.\" .format(sum(household_without_head_equal == False)))","04cf6ad6":"#Now setting poverty level of the members same as the head of the house within a family.\n#Iterating through each household\n\nfor household in poverty_nequal.index:\n    #Finding the correct label(label of house head)\n    head_target = int(data_train[(data_train['idhogar'] == household) & (data_train['parentesco1'] == 1.0)] ['Target'])\n    #Setting the correct label for family members\n    data_train.loc[data_train['idhogar'] == household, 'Target'] = head_target","c03dfc3d":"data_train_info = pd.DataFrame(columns=['Name of Col', 'Num of Null', 'Dtype', 'N_Unique'])\n\nfor i in range(0, len(data_train.columns)):\n    data_train_info.loc[i] = [data_train.columns[i],\n                        data_train[data_train.columns[i]].isnull().sum(),\n                        data_train[data_train.columns[i]].dtypes,\n                        data_train[data_train.columns[i]].nunique()] \ndata_train_info","5cf53fb5":"data_train_info[data_train_info[\"Num of Null\"] > 0]","2199c714":"data_train_info[\"Num of Null\"].sum()","56c4d605":"data_train[data_train[\"Target\"] == 0]","2c011a3f":"# Analysing the top 5 values of dependency, edjefe and dejefa columns \ndata_train.loc[:, [\"dependency\", \"edjefe\", \"edjefa\"]].head()","d3680201":"mapping = {'yes' :1, 'no' :0}\n\nfor data in [data_train, data_test]:\n    data['dependency'] = data['dependency'].replace(mapping).astype(float)\n    data['edjefe']=data['edjefe'].replace(mapping).astype(float)\n    data['edjefa']=data['edjefa'].replace(mapping).astype(float)\n# head output of treated features\ndata_train.loc[:, [\"dependency\", \"edjefe\", \"edjefa\"]].head()","0354a0c4":"data = data_train[data_train['v2a1'].isnull()].head()\ndata.loc[:, [\"v2a1\",\"tipovivi1\",\"tipovivi2\",\"tipovivi3\",\"tipovivi4\",\"tipovivi5\"]]","cd9c901d":"#Features indicating home-ownership\n\nown_feature = [x for x in data_train if x.startswith('tipo')]\n\n#Plotting the home-ownership features for NaN v2a1 rows \n\ndata_train.loc[data_train['v2a1'].isnull(), own_feature].sum().plot.bar(figsize = (5,3), color ='c', edgecolor ='black', linewidth =2)\n\nplt.xticks([0,1,2,3,4],['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],rotation =20, size=8)\nplt.title('Home-ownership status for Households Missing Rent Payments', size=12)","e442a0d4":"for data in [data_train, data_test]:\n    data['v2a1'].fillna(value=0, inplace=True)\n    \ndata_train[['v2a1']].isnull().sum()","b82a7b29":"data_train.loc[data_train['parentesco1'] ==1,[\"v18q\",\"v18q1\"]].head()\n","0b8faa05":"data_train.groupby(by=\"v18q1\")['v18q1'].count()","6ce98c1b":"for df in [data_train, data_test]:\n    df['v18q1'].fillna(value=0, inplace=True)\n    \ndata_train['v18q1'].isnull().sum()","b352260f":"#Checking related features of rez_sec when the value is not Null\ndata_train[data_train['rez_esc'].notnull()]['age'].describe()","0b5012da":"data_train[data_train['rez_esc'].isna() & ((data_train['age'] > 7) & (data_train['age'] < 17))]","184f52c9":"for data in [data_train, data_test]:\n    data['rez_esc'].fillna(value = 0, inplace = True)\n\ndata_train['rez_esc'].isnull().sum()","c69eddbd":"#Lets analyze related features when meaneduc is NaN\ndata_train[data_train['meaneduc'].isnull()].loc[:,['age','meaneduc','edjefe','edjefa','instlevel1','instlevel2','instlevel3','instlevel4','instlevel5','instlevel6','instlevel7','instlevel8','instlevel9']]","4ebd3dac":"#Lets analyze related features when meaneduc is not NaN\ndata_train.loc[:,['Id','meaneduc','edjefe','edjefa','instlevel1','instlevel2','instlevel3','instlevel4','instlevel5','instlevel6','instlevel7','instlevel8','instlevel9']].head()","054369bd":"for data in [data_train,data_test]:\n    data['meaneduc'].fillna(value = data['edjefe'], inplace = True)\n    \ndata_train['meaneduc'].isnull().sum()","2a143d63":"#Related features when SQBmeaned is NaN\ndata_train[data_train['SQBmeaned'].isnull()].loc[:, ['SQBmeaned','meaneduc','edjefe','edjefa','instlevel1','instlevel2']]","27ea537a":"#Related features when SQBmeaned is not NaN\ndata_train.loc[:,['SQBmeaned','meaneduc','edjefe','edjefa','instlevel1','instlevel2']].head()","319ccae1":"for data in [data_train,data_test]:\n    data['SQBmeaned'].fillna(value = data['meaneduc']**2, inplace = True)\n    \ndata_train['SQBmeaned'].isnull().sum()","75bf156c":"#Dropping squared features\ncols = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']\n\nfor df in [data_train, data_test]:\n    df.drop(columns=cols, inplace=True)\n\nprint(data_train.shape, data_test.shape)","d1ff1e17":"#Checking for the household redundant variables \n\nheads = data_train.loc[data_train['parentesco1'] == 1, :]\nheads.shape","352940e3":"corr_matrix = heads.corr()\ncorr_matrix","decd02f2":"#Selecting the upper traingle of corr_matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))","e7d823aa":"#Finding the index of feature columns with correlation greater than 0.95\ncols_to_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\ncols_to_drop","1c362d0c":"#Dropping the cols_to_drop features\nfor df in [data_train, data_test]:\n    df.drop(columns=cols_to_drop, inplace=True)\n\n#Removing the male as well, as this would not be needed in model creation\nfor df in [data_train, data_test]:\n    df.drop(columns = 'male',inplace=True)\n\n\n#dropping 'Id' and 'idhogar' columns \ncols = ['Id','idhogar']\nfor df in [data_train,data_test]:\n    df.drop(columns= cols, inplace=True)\n\nprint(data_train.shape, data_test.shape)","bf2ae6ba":"#Defining features and target variable\nX = data_train.drop('Target', axis=1)\ny = data_train['Target']","bda8c441":"#Checking shape of X and y\nprint(\"Shape of X is {}, and shape of y is {}\".format(X.shape, y.shape))","a02c0e47":"#Splitting train and test data\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.1)","6cc661e6":"#instantiating the Random Forest Classifier with n_estimator as 150\nrfc_model = RandomForestClassifier(n_estimators=150)","676bc38d":"#Fitting the model\nrfc_model.fit(X_train,y_train)","c001d1ab":"#Predicting the y_pred_test\ny_pred_test = rfc_model.predict(X_test)","a109addb":"#Checking accuracy score, confusion matrix and classification report on test data\nprint(\"Accuracy score of RFC model on test dataset is : \")\nprint(accuracy_score(y_test, y_pred_test))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test, y_pred_test))","f97534b9":"#Defining cross validation generator and calculating cross_val_score\nkfold = KFold(n_splits=4,random_state=seed,shuffle=True)\nprint(cross_val_score(rfc_model, X, y, cv=kfold, scoring='accuracy'))","df24ecfd":"#Mean of cross_val_score\nprint(cross_val_score(rfc_model, X, y, cv=kfold, scoring='accuracy').mean())","f42276b1":"feature_labels = list(X)\nfeature_importance = pd.DataFrame({'Feature' : feature_labels, 'Importance' : rfc_model.feature_importances_})","1686f183":"feature_importance[feature_importance['Importance']>0.025]","0cc796d2":"Hence, we need to focus on only the households with head for setting the poverty levels.","f8343afc":"Below listed features have Mixed values-\n\n**dependency**, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)\/(number of member of household between 19 and 64)\n\n**edjefe**, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\n**edjefa**, years of education of female head of household, based on the interaction ofescolari (years of education), head of household and gender, yes=1 and no=0\n\nFor these features, \n\"yes\" = 1\n\"no\" = 0 \n\nLets correct these features using a map and coverting these to float","9aa385dc":"## Check if there are any biases in your dataset","315513c9":"### Treating Mixed Values ","c0758e41":"From the above output, we infer that -\n\nAs the extreme poverty is the smallest count, hence the dataset is not biased.","30f998f8":"Looking at the different datatypes and null values, we infer that -\n\n1. No Null values for integer datatype features.\n2. No Null values for object datatype features.\n3. For float64 datatype below features has Null values -\n   - v2a1 - 6860 values\n   - v18q1 - 7342 values\n   - rez_esc - 7928 values\n   - meaneduc - 5 values\n   - SQBmeaned - 5 values \n\n4. There are total 22140 Null values in the train dataset.\n","17b385a6":"## Check if there is a house without a family head.","1c9fb6c7":"##  Remove null value rows of the target variable.","d47d6c11":"Now, lets fix v18q1 (7342 NaN values) -  number of tablets household owns\n\nLets analyse few rows with v18q1 feature as NaN, to understand the related features. \nSince this is an household level feature,\ntherefore we consider the rows for head of the household.\n","bc494b85":"There is only one value as NaN in age group 7 to 17 years.\nHence, now we can fill the NaN values with 0.","3f56aa29":"As we found out that there are 15 households without a head. \nFirst lets check if members of these households have same Target\/Povertylevel or different.","9a0e19bb":"Note - From the above we infer that features **room, hogar_nin, dependency, edjefe, meaneduc, overcrowding and qmobilephone** \nplay an important role deciding the Income Qualification Level.","59a1cc4b":"The output variable is **Target** column from the dataset.\n\nTest dataset does not have the **Target** column.\n\nIt has zero null values.Datatype is int64.\n\nPossible values of **Target** column -\n1, 2, 3, 4\n\n\n\n\n","8500842a":"## Set poverty level of the members and the head of the house within a family.","ce5407a8":"##  Predict the accuracy using random forest classifier.","b660589f":"From the above, we infer that the **Years behind in school** has some value for age value between 7 and 17 Years.\nLets check if there are any NaN values in 7 to 17 Years of age.","d1c449e4":"###  Loading Train and Test Data","1ea6b5eb":"Now lets treat rez_esc(Years behind in school) feature - 7928 NaN values","deb12377":"Looking at the **Target** column, we observed that there are no null values in Target variable ","a5d71903":"##  Check whether all members of the house have the same poverty level.","ff3ef161":"## Identify the output variable","8d86403f":"As per **SQBmeaned** description and above outputs, it appears that SQBmeaned is square of the **meaneduc**. \nHence, treating the NaN accordingly -","ae968d21":"## End of the Notebook","fbfa7e35":" ##  Check the accuracy using random forest with cross validation.","e244aa33":"There are some Squared Variables and we understand that these would not add any value to the classification model.\nHence dropping these features -\nSQBescolari, SQBage, SQBhogar_total, SQBedjefe, SQBhogar_nin, SQBovercrowding, SQBdependency, SQBmeaned, agesq","54a8a3be":"Now, finally lets treat SQBmeaned - square of the mean years of education of adults (>=18) in the household - 5 values\n\nFirst understand the dependent features to analyze why the 5 values are NaN -","6dba1425":"**---------------------------------------------------------------------------------------------------------------------------**\n\nLets fix v2a1 feature first. Features related to v2a1 (monthly rent payment) -\n\ntipovivi1, =1 own and fully paid house\n\ntipovivi2, =1 own, paying in installments\n\ntipovivi3, =1 rented\n\ntipovivi4, =1 precarious\n\ntipovivi5, =1 other(assigned, borrowed)\n\n","dbcb5dc3":"Looking at above data, we infer that when **owns a tablet** column is 0, then there will be no number of tablets owned by household.\n\nSo, lets add 0 for all the NaN values.","9e057451":"## Data Cleaning\n","ec50a436":"Lets analyze and treat **meaneduc** - average years of education for adults (18+) - 5 values\n\nFew related features -\n- edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n- edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n- instlevel1, =1 no level of education\n- instlevel2, =1 incomplete primary\n","0ea7f4b2":"##  Count how many null values are existing in columns.","7cef89f7":"From above outputs we infer that -\nThere are five datapoints with **meaneduc** as NaN. And all have 18+ age.\nThe value of **meaneduc** feature is same as 'edjefe' if the person is male and 'edjefa' if the person is female for majority of datapoints.\n\nHence, we treat the 5 NaN values in similar way. \n","be2bdba3":"From the above counts we infer that, if the house is owned and paid off, then the house rent should be 0. \nLets add 0 for all the **NaN** values.","7b3cf861":"## Understand the type of data","ac98caa7":"As identified in cell 13, below listed features have NaN values- \n\n - v2a1 - Monthly rent payment - 6860 values\n\n - v18q1 - number of tablets household owns - 7342 values\n\n - rez_esc -Years behind in school - 7928 values\n\n - meaneduc - average years of education for adults (18+) - 5 values\n\n - SQBmeaned - square of the mean years of education of adults (>=18) in the household - 5 values","de32c0aa":"## Checking for the important and impactful features","434214ff":"There are 15 houses without a Family Head","453a5d8c":"### Inferences from the first view of data -\n- There are 142 features and 1 Target field\n- **Id** is the unique identifier for each datapoint\n- **Target** is an ordinal variable indicating the income levels \n        - 1 : Extreme Poverty\n        - 2 : Moderate Poverty\n        - 3 : Vulnerable Households\n        - 4 : Non-vulnerable Households\n            \n- **idhogar** is an unique identifier for each houshold. Hence, for household level analysis this feature should be considered.\n- **parentesco1** indicates if the person is head of the family\n- There are 9556 datapoints in Train Dataset and 23856 datapoints in Test Dataset\n\n","95ba8340":"### Importing Libraries "}}