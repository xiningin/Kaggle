{"cell_type":{"f0f60a6d":"code","a720794a":"code","02b1b468":"code","ec7c1765":"code","4b89f6df":"code","8ca0dfe0":"code","62bdd6eb":"code","fcee4ca6":"code","18276bb2":"code","39a9cb73":"code","4def4794":"code","29bf64b6":"code","c34e7ff2":"code","e7881575":"code","f47eb7fa":"code","faaa0362":"code","0f682f88":"code","6619a1a1":"code","5ba492d8":"code","1d9e1c0d":"code","ecb24661":"code","cdbde2e5":"markdown","fa59932e":"markdown","33025864":"markdown","5e9b5e50":"markdown","bea5348a":"markdown","5cd00f70":"markdown","f0201bd9":"markdown","936f238c":"markdown","0bd2cc93":"markdown","98691ef7":"markdown","3ed975fe":"markdown","fc6de36a":"markdown","86fd2fab":"markdown","ae31a63d":"markdown"},"source":{"f0f60a6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nplt.style.use('fivethirtyeight')\nimport pickle \nimport os \nimport cv2 \n%matplotlib inline\nimport gc\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a720794a":"data_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray'\ntrain_dir = data_dir + '\/train'\nval_dir = data_dir + '\/val'\ntest_dir = data_dir + '\/test'","02b1b468":"labels = ['NORMAL', 'PNEUMONIA']\nimg_size = 200\ndef get_files(file_dir):\n  data = []\n  for label in labels: \n      path = os.path.join(file_dir, label)\n      class_num = labels.index(label)\n      for img in os.listdir(path):\n          try:\n              img_arr = cv2.imread(os.path.join(path, img))\n              img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n              resized_arr = cv2.resize(img_arr, (img_size, img_size))\n              data.append([resized_arr, class_num])\n          except Exception as e:\n              print(e)\n  return np.array(data)","ec7c1765":"train = get_files(train_dir)\nval = get_files(val_dir)\ntest = get_files(test_dir)\n\nprint('Done loading data')","4b89f6df":"plt.imshow(train[1000][0])\nplt.axis('off')\nprint(labels[train[1000][1]])","8ca0dfe0":"Splitting to training, dev, test sets","62bdd6eb":"X = []\ny = []\n\nfor i,j in train:\n  X.append(i)\n  y.append(j)\n\nfor i,j in val:\n  X.append(i)\n  y.append(j)\n  \nfor i,j in test:\n  X.append(i)\n  y.append(j)","fcee4ca6":"X = np.array(X).reshape(-1, 200, 200, 3)\ny = np.array(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=32)\n","18276bb2":"#normalize\n\nX_train = X_train\/255\nX_val = X_val\/255\nX_test = X_test\/255","39a9cb73":"del train\ngc.collect()\ndel val\ngc.collect()\ndel test\ngc.collect()\ndel X\ngc.collect()\ndel y\ngc.collect()","4def4794":"datagen = ImageDataGenerator(rotation_range=90, shear_range=0.1, zoom_range=0.1, width_shift_range=0.1,height_shift_range=0.1)\n\n#no vertical and horizontal flip, because it will cause false real world results.\n\ndatagen.fit(X_train)","29bf64b6":"IMG_SHAPE = (200,200,3)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","c34e7ff2":"base_model.trainable = False\n\nbase_model.summary()","e7881575":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D(activity_regularizer=tf.keras.regularizers.l2(0.05))\nprediction_layer = tf.keras.layers.Dense(1, activity_regularizer=tf.keras.regularizers.l2(0.05), activation= tf.keras.activations.sigmoid)\n\nmodel = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer, \n])\n\nmodel.summary()","f47eb7fa":"base_learning_rate = 0.0005\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","faaa0362":"len(model.trainable_variables)","0f682f88":"initial_epochs = 20","6619a1a1":"early_stop = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\n#history = model.fit(datagen.flow(X_train, y_train, batch_size=30), callbacks=[early_stop], validation_data=(X_val, y_val), epochs=initial_epochs)","5ba492d8":"additional_epochs = 5","1d9e1c0d":"#history = model.fit(datagen.flow(X_train, y_train, batch_size=30), callbacks=[early_stop], validation_data=(X_val, y_val), epochs=additional_epochs)","ecb24661":"#this cannot be run, however I have done it and it ranges around 85 to 90, depending on the epoch num.\n#model.evaluate(X_test, y_test)","cdbde2e5":"Data loading code was borrowed and modified from [therealcyberlord](http:\/\/https:\/\/www.kaggle.com\/therealcyberlord)","fa59932e":" However it is important to note that a machine is not always perfect. Therefore, machine learning must only be used as an adjunct by the medical profesionals instead of relying solely on it (for the time being, that is). Hopefully in the future we will these models being deployed to real world situation in order to reduce the burden of the physician, increase patient-care quality, reduce medical expenditure as well as making healthcare processes such as diagnosing and calculating risks faster. \n   \n   Credits to [deeplearning.ai](http:\/\/deeplearning.ai) team for great courses.","33025864":"Here's the fun part, loading MobileNet v2, note that we set include_top = False to not include the top layers","5e9b5e50":"Getting data directiories,\nthe train, val and test directory has been splitted.","bea5348a":"1. Need to delete these because to optimize RAM usage.","5cd00f70":"Basically we get the files, convert it into RGB (changes 1 channel to 3), and append the file and label to data array","f0201bd9":"Set trainable = False because we want to use the weights from the model.","936f238c":"Here's where the RAM problem start, if you have any suggestions please drop in the comments section below.\n\nThe model stopped after 11 epochs, so I had to run it again another time due to the RAM issues.\n\nMaybe greater accuracy could be achieved if I could run higher number of epochs, also please not that I could include the confusion matrix and the curves as well due to this issue. I will try to update these in future versions.","0bd2cc93":"Datagenerator.","98691ef7":"Adding a few stuffs here.\n1. GlobalAveragePooling2D layer with regularizer.\n2. Dense layer also with regularize.\n3. I have printed the model summary to see the whole layers.","3ed975fe":"Lets see some example of xrays:","fc6de36a":"# **Deep Learning of Xray Images Using Transfer Learning (ImageNetv2) **\n\n   Deep learning in the medical field is a fast growing field. This is an important stepping stone to move to a new era of practising medicine, and that it by the help of machines and computers to increase physician, radiologist or even surgeons' accuracy in areas such as medical prognosis, medical diagnosis, treatment planning and public health intervention. The basic units of machine learning actually closely resemble the long-used biostatistics modelling of medical researches such as logistic regression, linear regression and even Cox time-based regression. \n    \n   Some of the more interesting researches on Deep Learning diagnosing diseases can be read here:\n*     [CheXNet](https:\/\/journals.plos.org\/plosmedicine\/article?id=10.1371\/journal.pmed.1002686) - Chest XRay \n*     [Dermatology](https:\/\/www.nature.com\/articles\/nature21056) - Detecting skin cancers\n*     [Opthamology](https:\/\/www.ncbi.nlm.nih.gov\/pubmed\/27898976) - Fundus image \n*     [Pathology](https:\/\/jamanetwork.com\/journals\/jama\/fullarticle\/2665774) - Microscope images ","86fd2fab":"A little bit more on the model that I have used. I am using pre-trained ImageNet\/MobileNetv2 archictecture that has been trained with millions of images. I am only using the weightage from the earlier layers that learns the simpler parameters of an image, and using those learned weightages\/biases on the Xray images. \n\nHere is the ImageNet model:\n![ImageNet layers](https:\/\/www.researchgate.net\/profile\/Sehla_Loussaief\/publication\/325772980\/figure\/fig2\/AS:673660541079552@1537624597820\/ImageNet-CNN-layers-Fig-2-demonstrates-the-different-network-layers-required-by-the.png)\n\nPlease note that I have removed the last few layers and replaced it with AveragePooling2D and Dense layers with L2 regularization. I needed to use the regularizer because there was too much discrepancy between traning set accuracy and validation\/test set accuracy.\n\nHere are the accuracy I have achieved. (Note that I ran into some RAM issues and had to stop the learning early, if more resources were available, or if there are ways to get pass this\/more tuning of hyperparameters was done,maybe the accuracy can be improved)\n\n**Traning set:** 0.9053 (the higher the epochs, the higher the accuracy - true for all sets - up to 0.9500 \/\/ num epochs limited by ram)\n\n**Validation set:**  0.8356\n\n**Test set:** 0.8500\n\n\nThis is my first Kaggle Notebook! Comment any improvements you might want to see, thank you!\n\n*This is a work in progress, v1.00\n*","ae31a63d":"Lets get to the code:\n\nLoad all the functions needed"}}