{"cell_type":{"816b9ac0":"code","eaa33d17":"code","ba531f50":"code","2fb034d5":"code","3ca5f2f2":"code","23165693":"code","6a8387b6":"code","41bcd81e":"code","6fdd900c":"markdown","d76426c9":"markdown"},"source":{"816b9ac0":"import queue      # for actual implementation of decision tree\n\nclass bt:          # we created class to create the create tree using nodes\n    def __init__(self,entropy,lvl,split_feature,gain):\n        self.split_feature = split_feature \n        self.entropy = entropy\n        self.gain = gain\n        self.lvl = lvl\n        self.right = None\n        self.left = None\n\n\n\ndef printbt1(root,s):    # it prints our actual tree created using rootnode and \n    if root is None:\n         return\n    print(s)\n    print(\"Level :- \" ,root.lvl)\n    print(\"Entropy :- \" ,root.entropy)\n    print(\"Split_Feature :- \",root.split_feature)\n    print(\"Gain :- \",root.gain)\n    print()\n    \n    printbt1(root.left,\"Left Node\")\n    printbt1(root.right,\"Right Node\")","eaa33d17":"import pandas as pd                   \nimport numpy as np\nimport math as ma                              #to perform log() calculations\nfrom sklearn import datasets\niris=datasets.load_iris()\nx=pd.DataFrame(iris.data)                      #x is dataframe of iris.data\nx.columns=['sl','sw','pl','pw']                #proving columns to x dataframe\ny=pd.DataFrame(iris.target)                    #y is dataframe of iris.target\n\nfeatures=['sl','sw','pl','pw']                 # list of features over which spliting will be done\nlevel=0                                        # initializing level variable","ba531f50":"def countSetosa(output):                       # function to count setosa flowers which is also treated as 0\n    # Counts number of setosa\n    output=np.array(output[:])\n    return (output==0).sum()                   #return the number of items whose value is 0(nothing but setosa flower number)\n\ndef countVersicolor(output):                   # function to count versicolor flowers which is also treated as 1\n    # Counts number of versicolor\n    output=np.array(output[:])\n    return (output==1).sum()                #return the number of items whose value is 1(nothing but versicolor  flower number)\n","2fb034d5":"def entropy(lst):                          #funtion to calculate entropy of given node  ====Node data is in lst(list)\n    info=0\n    if sum(lst)==0:                           #to handel zerodivision error\n        return 0\n    for i in range(3):\n        if lst[i]\/sum(lst)==0:             # to handel log(0) which is undefine\n            continue\n        info+=((-1)*lst[i]\/sum(lst))*ma.log(lst[i]\/sum(lst),2)       # info is simply the entropy  # 2 represents log base 2\n    return info","3ca5f2f2":"def gain_ratio(lst,lst1,lst2):          # this funtion finally retun gain ratio\n       \n    info=entropy(lst)                  #info is entropy of head node\n    info1=entropy(lst1)                #info1 is entropy of first splited node\n    info2=entropy(lst2)                 # info1 is entropy of second splited node\n        \n   \n    a=(sum(lst1)\/(sum(lst1)+sum(lst2)))*info1        #info_gain=info-(a+b)  so we need to calculate a and b\n    b=(sum(lst2)\/(sum(lst1)+sum(lst2)))*info2   \n    info_gain=info-(a+b)\n    \n    if sum(lst1)\/(sum(lst1)+sum(lst2))==0:         #to prevent getting log(0)\n        split1=0\n    else:                                          # calculation splitinfo of first splited node\n        split1=((-1)*sum(lst1)\/(sum(lst1)+sum(lst2)))*ma.log(sum(lst1)\/(sum(lst1)+sum(lst2)),2) \n    if sum(lst2)\/(sum(lst1)+sum(lst2))==0:              #to prevent getting log(0)                                           \n        split2=0\n    else:                                          # calculation splitinfo of first splited node\n        split2=((-1)*sum(lst2)\/(sum(lst1)+sum(lst2)))*ma.log(sum(lst2)\/(sum(lst1)+sum(lst2)),2)\n    split_info=split1+split2\n    try:\n        gain_rati=info_gain\/split_info             # to handel zerodivision error\n    except:\n        gain_rati=0\n  \n    return gain_rati\n    ","23165693":"def gain(x,y,f):     \n    \n    data=x[f]                                      #data is the coloumn data of feature f\n    data=np.array(data)\n    \n    maxx=0                                         #maxx will give u max_gain ratio later it is just initialised\n                                                   # we r calculation min and max value to run loop over all values of data\n    feat=0                                         # later feat will return this feature f in df function\n    mid=0                                         # at each time mid will store the value at which spliting is done by feature f\n    \n    \n    for p in range(1,len(data)):\n        #print(len(data))\n        #print(data)\n        m=(data[p-1]+data[p])\/2\n        lst=[0,0,0]                         #it will store number of 0`s , 1`s , 2`s of y on respective indexes 0,1,2\n        lst1=[0,0,0]                      #it will store number of 0`s , 1`s , 2`s of  split_1y on respective indexes 0,1,2\n        lst2=[0,0,0]                     #it will store number of 0`s , 1`s , 2`s of split_2y on respective indexes 0,1,2\n        \n        \n        split_1x=x[data>m]              # it is split of x data whose values are less then m\n        split_1y=y[data>m]              # it is split of y data whose values are less then m\n        \n        split_2x=x[data<=m]           # it is split of x data whose values are greater then m\n        split_2y=y[data<=m]           # it is split of y data whose values are greater then m\n        \n        total_elements=len(x)         # gives total number of elements in x\n        lst[0]=countSetosa(y)          #countSetosa is function which returns number of setosa flowers defines at top\n        lst[1]=countVersicolor(y) \n        lst[2]=total_elements-lst[0]-lst[1]    #lst[2] have value of 3rd type of flowers how many they are\n        \n        total_elements=len(split_1x)                 #this is same for first split\n        lst1[0]=countSetosa(split_1y)\n        lst1[1]=countVersicolor(split_1y) \n        lst1[2]=total_elements-lst1[0]-lst1[1]\n        \n        total_elements=len(split_2x)         #this is same for rnd split\n        lst2[0]=countSetosa(split_2y)\n        lst2[1]=countVersicolor(split_2y) \n        lst2[2]=total_elements-lst2[0]-lst2[1]\n       \n        if lst1.count(0)==3 and lst2.count(0)==3:   #to prevent getting split_info to 0 in gain ratio\n            continue\n        max_gain=gain_ratio(lst,lst1,lst2)    #gain_ratio fun will give u max gain ratio using all 3 list which have all data\n        if max_gain>=maxx:\n            maxx=max_gain\n            feat=f\n            mid=m\n            \n    return maxx,feat,mid","6a8387b6":"def dt(x,y,features,level):\n    lst=[0,0,0]                          #list contains the number of flowers of each type \n    no_of_features_left=len(features)\n    total_elements=len(x)\n    no_of_setosa=countSetosa(y)           #countSetosa is function to count number of setosa flowers in output\n    no_of_versicolor=countVersicolor(y) \n    no_of_virginica=total_elements-no_of_setosa-no_of_versicolor\n    lst[0]=no_of_setosa\n    lst[1]=no_of_versicolor\n    lst[2]=no_of_virginica\n    \n    print('level ',level)\n    print('count of setosa =',no_of_setosa)\n    print('count of versicolor =',no_of_versicolor)\n    print('count of virginica =',no_of_virginica)\n    print('current entropy is =',entropy(lst))\n    \n    if lst.count(0)==2:                 #if lst has only one type of flowers it will reach leaf node\n        root = bt(entropy(lst),level,\"Reached Leaf Node\",0)\n        return root\n    maxx=0                  # maxx will store the maxx gain ratio\n    mid=0                     #mid is the value at which feature splits ang gives max gain ratio\n    feat=None\n    \n    for f in features:\n        max_gain,final_feature,m=gain(x,y,f) # gain fun to get max gainratio # max_gain is maximum gain ratio by final_feature    m is mid\n        if maxx<=max_gain:\n            maxx=max_gain\n            feat=final_feature\n            mid=m\n        \n  \n    print('splitting on feature',feat,'with gain ratio',maxx)         #feat is the feature at which split done\n    root = bt(entropy(lst),level,feat,maxx)\n    new_1x=x[x[feat]>mid]     #spliting main data into two parts according to feat feature\n    new_1y=y[x[feat]>mid]     #spliting main output into two parts according to feat feature\n    new_2x=x[x[feat]<=mid]\n    new_2y=y[x[feat]<=mid]\n   \n   \n    \n    features2=[x for x in features]      # features will remain same bcz a feature can be used any number of times\n    root.left=dt(new_1x,new_1y,features2,level+1)    #calling dt again recursively\n    root.right=dt(new_2x,new_2y,features2,level+1)     #calling dt again recursively\n    return root\n\nroot = dt(x,y,features,level)     #main function call\n\n\n\n    \n  \n    ","41bcd81e":"li=[]\n\nfor i in range(2):\n    li.append(-1)\n#root = create(li)\nprintbt1(root,\"Root Node\")\n   \n","6fdd900c":"# Actual implementation of decision tree","d76426c9":"# Decision Tree Implementation"}}