{"cell_type":{"b76d56ba":"code","58a887d6":"code","5bd36425":"code","2564ebaa":"code","a1fa6774":"code","360b140f":"code","afe92994":"code","ece13ae5":"code","3e8b372d":"code","80a49274":"code","4c31a99a":"code","e246eafb":"code","781cf274":"code","a8d609c2":"code","3ec6acd4":"code","e9abfb9b":"code","23847a8b":"code","c0f8b56a":"code","dac95283":"code","b498d1a9":"markdown","6e3129ac":"markdown","8a5fde08":"markdown","c6e2cdd2":"markdown","ae61c59c":"markdown","2e3b78dd":"markdown","4463f85c":"markdown","b02d068d":"markdown","d854b72c":"markdown","37c34242":"markdown","77b7cb19":"markdown","8c568ab0":"markdown","57d211ba":"markdown","3c20fed9":"markdown","b79cbb2e":"markdown","886bedc5":"markdown"},"source":{"b76d56ba":"!pip install fastai==0.7.0","58a887d6":"from fastai.imports import *\nfrom fastai.structured import *\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\nimport seaborn as sns\nsns.set()\n\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)","5bd36425":"df_raw = pd.read_csv('..\/input\/train.csv')","2564ebaa":"df_raw.head()","a1fa6774":"# check for missing values\nnull = df_raw.isnull().sum().sort_values(ascending=False)[:15]\npd.DataFrame(data=null, columns=['Missing'])","360b140f":"df_raw.SalePrice = np.log(df_raw.SalePrice)","afe92994":"corrmat = df_raw.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True);","ece13ae5":"train_cats(df_raw)","3e8b372d":"df, y, nas = proc_df(df_raw, 'SalePrice')","80a49274":"def split_vals(a,n): return a[:n], a[n:]\nn_valid = 300\nn_trn = len(df)-n_valid\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)","4c31a99a":"def print_score(m):\n    res = [m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","e246eafb":"m = RandomForestRegressor(n_jobs=-1, n_estimators=40, oob_score=True)\nm.fit(X_train, y_train);\nprint_score(m)","781cf274":"# get some insight in feature importance really important.\n# todo, increase in size. change color palette\nfi = pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)[:20]\n\nsns.set(rc={'figure.figsize':(10,9)})\nsns.barplot(data=fi, y='cols', x='imp', palette=\"GnBu_d\");","a8d609c2":"sns.set(rc={'figure.figsize':(5,5)})\nsns.kdeplot(df_raw['OverallQual'] );","3ec6acd4":"# take the whole df and copy it \ndf_temp = df.copy()\n# make an new column on the copy dataframe [is_valid]\ndf_temp['is_valid'] = 1\n# every row in the validation set we will give a zero\ndf_temp.is_valid[:n_trn] = 0\n# we now have a dataset with at target variable if the row is training or a validation set\nx, y, nas = proc_df(df_temp, 'is_valid')","e9abfb9b":"m = RandomForestClassifier(n_estimators=40, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(x, y);\nm.oob_score_","23847a8b":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\nrf_feat_importance(m, x)[:5]","c0f8b56a":"df.drop('Id', axis=1, inplace=True)","dac95283":"X_train, X_valid = split_vals(df, n_trn)\nm = RandomForestRegressor(n_estimators=300, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","b498d1a9":"Thanks to Jeremy Howard from fast.ai.\nFor any questions, please comments and I will try to help.","6e3129ac":"It is not really a suprise it is Id. It is added by Kaggle for the submission, but this is a good way to find features that are time depentend.","8a5fde08":"There are quite a lot of missing values. Mostly found in the pool feature. We will deal with them automatically later when calling prod_df from fastai. This will convert every NaN in 'False'","c6e2cdd2":"We score 98% on the training set and only 84% on the validation set. We are overfitting badly.\nWe can focus on improving the dataset with a baseline in mind. this way we know if we are going in the right direction","ae61c59c":"The goal of this kernel is to show the possibilties of getting insight in your data by using RandomForest. Understanding the important features of a dataset lets us concentrate quickly on what is important. The process can save you some time and early value before diving deep.","2e3b78dd":"## Feature importance","4463f85c":"Distribution is not skewed and is not the cause.","b02d068d":"Understanding the important features of a dataset lets us concentrate on what matters. When there are so many features we can not go through each one of them and visualize it. Some features in the set are more than 100x more important than others!\n","d854b72c":"We are able to predict if a row is in the validation set almost 100%. What this means is that there is a features who clearly shows it.","37c34242":"The score will be validated as RMSLE. We take the log here from the predictor so we can take the R2 later on","77b7cb19":"There are loads of features and I am not an expert in housing. We could see some relations from the matrix above, but I prefer to let the machine show me what is important. To determine feature importance, you would build a RF as fast as you can. You\u2019re aiming for an accuracy score better than random, but not much more than that. Then you would plot the feature importance of the different fields in the analysis\n\nIf you plot all the columns, you\u2019ll find that some columns are important, and some don\u2019t matter at all. For Kaggle scores this is not always an important step, but in a buisness you could show some value by pointing to the most interesting predictors.","8c568ab0":"### Dummies or Label-encode? ","57d211ba":"In case of forecasting the validation set should not be random. You want to make sure you are predicting against the latest timeframe. You dont want to predict against all the years of data.\n\nWe split-test and not crossvalidate, since crossvalidate will shuffle the data and the validation will be random again.","3c20fed9":"Our model is trained on the past, but is validating on the future. This will be the same scenario for when you want to bring it in production. At the moment we are overfitting and cannot predict well on the future. Chances are that we have too much features which are time dependent.","b79cbb2e":"We end here with an R2 score of __87%__ on the validation set.","886bedc5":"We will be using Random forest and are fine with categorical features being label-encoded. You could dummy_encode them. but it gives a lot of extra columns with not much variation in the splits. Since a dummy could only be 1 or 0 the split will always be the same.(If you dont bootstrap ofcourse)\n\nI Would recommend this read about the differences. https:\/\/roamanalytics.com\/2016\/10\/28\/are-categorical-variables-getting-lost-in-your-random-forests\/"}}