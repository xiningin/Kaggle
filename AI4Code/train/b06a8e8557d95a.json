{"cell_type":{"238c6be9":"code","37c0df9a":"code","b5e78f3c":"code","befe3885":"code","6d35fc11":"code","c5fa16a1":"code","683755a2":"code","473f12fd":"code","1387ee9d":"code","4cfafe48":"code","d7a5a7f3":"code","f5bfad4c":"code","56433ea6":"code","4c3f67d2":"code","86b3a0ce":"code","7e5e46ef":"code","46cea968":"code","f8341b5b":"code","eca8aba9":"code","1bdc30d9":"code","df5d4fbc":"code","05f26003":"code","9ff486c7":"code","010197d0":"code","ec100e9a":"code","97035c30":"code","da517551":"code","b8c78934":"code","230ad092":"code","769fef3d":"code","b898330e":"code","614619bf":"code","e248569b":"code","dd155437":"code","bdc6ce5d":"code","62a20511":"code","f13c35ac":"code","3956ebf8":"code","7bc6a9aa":"code","c8264391":"code","4befbe52":"code","1e747882":"code","c0541d70":"code","4eb5c53c":"code","e7634a12":"code","4cc14eb5":"code","70cf4ea7":"code","cf62590d":"code","a1590cca":"code","faa00b09":"code","7eab98f0":"code","37c8a5e9":"code","bc120738":"code","4daa4d01":"code","b43601ac":"code","9db133b2":"markdown"},"source":{"238c6be9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","37c0df9a":"data=pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv')\nstore=pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/store.csv')\ntest= pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/test.csv')\nprint(data.shape)\nprint(store.shape)\nprint(test.shape)","b5e78f3c":"data.head()","befe3885":"store.head()","6d35fc11":"test.head()","c5fa16a1":"data.dtypes","683755a2":"#categorical columns\ndata.describe(include='object')","473f12fd":"#numeric columns\ndata.describe(exclude='object')","1387ee9d":"data.describe()[['Sales','Customers']].loc['mean']","4cfafe48":"data.describe()[['Sales','Customers']].loc['max']","d7a5a7f3":"print(data.Store.nunique())\ndata.Store.value_counts().head(50).plot.bar()","f5bfad4c":"data.Store.value_counts().tail(50).plot.bar()","56433ea6":"data.Store.value_counts() # Store is treated as categorical column although its numeric\n#Hence we cannot compute mean,min,max,etc... for such categorical columns.","4c3f67d2":"data.DayOfWeek.value_counts()","86b3a0ce":"data.Open.value_counts()","7e5e46ef":"data.Promo.value_counts()","46cea968":"data['Date']=pd.to_datetime(data['Date'],format='%Y-%m-%d')\nstore_id=data.Store.unique()[0]  #taking 1st unique storeid and storing in a variable\nprint(store_id)\nstore_rows=data[data['Store']==store_id] #if store_id we got above is present in Store table\nprint(store_rows.shape)\nstore_rows.resample('1D',on='Date')['Sales'].sum().plot.line(figsize=(14,4))\n#ID means 1Day, this shows data day-wise for all the data where store_id[0] which is 1","f8341b5b":"store_rows[store_rows['Sales']==0] #checking storeod of all sales==0","eca8aba9":"test['Date']=pd.to_datetime(test['Date'],format='%Y-%m-%d')\nstore_test_rows=test[test['Store']==store_id]\nstore_test_rows['Date'].min(),store_test_rows['Date'].max()","1bdc30d9":"store_test_rows['Open'].value_counts()","df5d4fbc":"store_rows['Sales'].plot.hist()","05f26003":"store[store['Store']==store_id].T","9ff486c7":"store[~store['Promo2SinceYear'].isna()].iloc[0]","010197d0":"store.isnull().sum()","ec100e9a":"#filling missing values\nstore['Promo2SinceWeek']=store['Promo2SinceWeek'].fillna(0)\nstore['Promo2SinceYear']=store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\nstore['PromoInterval']=store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\nstore['CompetitionDistance']=store['CompetitionDistance'].fillna(store['CompetitionDistance'].max())\nstore['CompetitionOpenSinceMonth']=store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear']=store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])\nstore.isna().sum()","97035c30":"store['Promo2SinceYear'].mode()","da517551":"data_merged=data.merge(store,on='Store',how='left')","b8c78934":"print(data.shape)\nprint(data_merged.shape)","230ad092":"data_merged.isna().sum().sum() #cross checking if there are any missing values","769fef3d":"#Encoding\n#3 categorical column -- StateHoliday,StoreType,Assortment,PromoInterval\n#1 date column\n#rest are numerical\ndata_merged.dtypes","b898330e":"data_merged['day']=data_merged['Date'].dt.day\ndata_merged['month']=data_merged['Date'].dt.month\ndata_merged['year']=data_merged['Date'].dt.year\ndata_merged","614619bf":"data_merged.isnull().sum()","e248569b":"#checking for all categorical columns one by one\ndata_merged['StateHoliday'].unique()\ndata_merged['StateHoliday']=data_merged['StateHoliday'].map({'0':0,0:0,'a':1,'b':2,'c':3})\ndata_merged['StateHoliday']=data_merged['StateHoliday'].astype(float).astype(int)\ndata_merged","dd155437":"data_merged['Assortment'].unique()\ndata_merged['Assortment']=data_merged['Assortment'].map({'0':0,0:0,'a':1,'b':2,'c':3,'d':4})\ndata_merged['Assortment']=data_merged['Assortment'].astype(int)\ndata_merged","bdc6ce5d":"data_merged['StoreType'].unique()\ndata_merged['StoreType']=data_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ndata_merged['StoreType']=data_merged['StoreType'].astype(int)\ndata_merged","62a20511":"data_merged['PromoInterval'].unique()\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ndata_merged['PromoInterval']=data_merged['PromoInterval'].map(map_promo)\ndata_merged","f13c35ac":"# Train and validate Split\nfeatures= data_merged.columns.drop(['Sales','Date'])\nfrom sklearn.model_selection import train_test_split\ntrain_x,validate_x,train_y,validate_y = train_test_split(data_merged[features],np.log(data_merged['Sales']+1),test_size=0.2,random_state=1)\ntrain_x.shape,validate_x.shape,train_y.shape,validate_y.shape","3956ebf8":"from sklearn.tree import DecisionTreeRegressor\nmodel_dt=DecisionTreeRegressor(max_depth=10,random_state=1).fit(train_x,train_y)\nvalidate_y_pred=model_dt.predict(validate_x)","7bc6a9aa":"def draw_tree(model, columns):\n    import pydotplus\n    from sklearn.externals.six import StringIO\n    from IPython.display import Image\n    import os\n    from sklearn import tree\n    \n    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38\/bin\/'\n    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n    dot_data = StringIO()\n    tree.export_graphviz(model,\n                         out_file=dot_data,\n                         feature_names=columns)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","c8264391":"!pip install pydotplus ","4befbe52":"draw_tree(model_dt,features)","1e747882":"pd.Series(np.log(data_merged['Sales']+1)).plot.hist()","c0541d70":"validate_y_pred = model_dt.predict(validate_x)\nfrom sklearn.metrics import mean_squared_error\nvalidate_y_inv=np.exp(validate_y)-1 #becaused we added +1 while log transformation\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\nnp.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))","4eb5c53c":"model_dt.feature_importances_","e7634a12":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nplt.bar(features,model_dt.feature_importances_)\npd.Series(model_dt.feature_importances_,index=features)","4cc14eb5":"#Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\n\nparameters={'max_depth':list(range(5,20))}\nbase_model=DecisionTreeRegressor()\ncv_model=GridSearchCV(base_model,param_grid=parameters,cv=5,return_train_score=True).fit(train_x,train_y)\nparameters\n#by default cv=2","70cf4ea7":"cv_model.best_params_","cf62590d":"pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False) #[['param_max_depth','mean_test_score']]\n#differnt types tried with different max depth","a1590cca":"df_cv_results=pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False)\nimport matplotlib.pyplot as plt\ndf_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\ndf_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\nplt.legend(['Test Scores','Train Scores'])","faa00b09":"stores_avg_cust = data.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest_1 = test.merge(stores_avg_cust,on='Store',how='left')\ntest.shape,test_1.shape\ntest_merged = test_1.merge(store,on='Store',how='inner')\ntest_merged['Open']=test_merged['Open'].fillna(1)\ntest_merged['Date']=pd.to_datetime(test_merged[\"Date\"],format='%Y-%m-%d')\ntest_merged['day']=test_merged['Date'].dt.day\ntest_merged['month']=test_merged['Date'].dt.month\ntest_merged['year']=test_merged['Date'].dt.year\ntest_merged['StateHoliday']=test_merged['StateHoliday'].map({'0':0,'a':1})\ntest_merged['StateHoliday']=test_merged['StateHoliday'].astype(int)\ntest_merged['Assortment']=test_merged['Assortment'].map({'a':1,'b':2,'c':3})\ntest_merged['Assortment']=test_merged['Assortment'].astype(int)\ntest_merged['StoreType']=test_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ntest_merged['StoreType']=test_merged['StoreType'].astype(int)\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ntest_merged['PromoInterval']=test_merged['PromoInterval'].map(map_promo)","7eab98f0":"test_merged","37c8a5e9":"test_pred=model_dt.predict(test_merged[features])\ntest_pred_inv=np.exp(test_pred)-1","bc120738":"submission_predicted=pd.DataFrame({'Id':test['Id'],'Sales':test_pred_inv})","4daa4d01":"submission_predicted.to_csv('submission.csv',index=False)\nsubmission_predicted.head()","b43601ac":"#to calculate RMSPE(Root Mean Square Percentage Error)\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1.\/(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\nvalidate_y_inv=np.exp(validate_y)-1 #becaused we added +1 while log transformation\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\nrmse_val=np.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))\nrmspe_val=rmspe(validate_y_inv,validate_y_pred_inv)\nprint(rmse_val,rmspe_val)","9db133b2":"\n* Train Data : Input and target variable is present\n\n* Test Data: Input is present but there is no target variable here"}}