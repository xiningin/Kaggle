{"cell_type":{"ef667463":"code","9d63010b":"code","032688de":"code","6df4a3f7":"code","d44c863a":"code","82c28cc5":"code","b3cc3533":"code","17834f33":"code","e369a3b2":"code","1a4af150":"code","60861467":"code","71e80776":"code","f95afd62":"code","ec2b685b":"code","a3d8c6d5":"code","ff25a82e":"code","ae2dbdcf":"code","5af96f3c":"code","7e6aa45e":"code","d4eaf252":"code","b63f4999":"code","ca8a62aa":"code","205c7ba7":"code","1fa8e3b5":"code","59402532":"markdown","0ac7c952":"markdown","b5769cf2":"markdown","644d0803":"markdown","238d5627":"markdown","4f332402":"markdown","e0e976e7":"markdown","980e45ed":"markdown","22207945":"markdown","853a55e6":"markdown","5e40f84e":"markdown","d65a562b":"markdown","0f2ec7ed":"markdown","0575f145":"markdown","d4e27583":"markdown","49981f4f":"markdown","8023e01f":"markdown"},"source":{"ef667463":"IMG_SIZE = 300","9d63010b":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\nprint('Tensorflow version:', tf.__version__)","032688de":"train = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/train.csv\")\ntest = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\n#train_x = np.array([cv2.resize(np.array(cv2.imread(\"..\/input\/aptos2019-blindness-detection\/train_images\/\"+i+\".png\")),(IMG_SIZE,IMG_SIZE)) for i in train.id_code])\n#train_y = np.array(train.diagnosis)\n#test_x = np.array([cv2.resize(np.array(cv2.imread(\"..\/input\/aptos2019-blindness-detection\/test_images\/\"+i+\".png\")),(IMG_SIZE,IMG_SIZE)) for i in test.id_code])","6df4a3f7":"\"\"\"\nn = 10\ncols = 5\nrows = np.ceil(n\/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')\n\"\"\"","d44c863a":"\"\"\"\ndef crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\"\"\"\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","82c28cc5":"def load_ben_color(data, img_size, sigmaX=10):\n    if data.ndim == 4:  # array of images\n        for i in range(len(data)):\n            image = cv2.cvtColor(data[i], cv2.COLOR_BGR2RGB)\n            image = crop_image_from_gray(image)\n            image = cv2.resize(image, (img_size, img_size))\n            data[i] = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX), -4 ,128)\n    elif data.ndim == 3:  # just a single image\n        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n        data = crop_image_from_gray(data)\n        data = cv2.resize(data, (img_size, img_size))\n        data = cv2.addWeighted(data, 4, cv2.GaussianBlur(data, (0,0), sigmaX), -4 , 128)\n    else: \n        return 0\n    \n    return data","b3cc3533":"def image_preprocessing(data, img_size, sigmaX=10):\n    # cropping & Ben Graham's preprocessing method\n    data = load_ben_color(data, img_size, sigmaX)\n    \n    # normalization (rescaling between 0 and 1)\n    data = data.astype('float32')\n    for i in range(len(data)):\n        cv2.normalize(data[i],  data[i], 0, 1, cv2.NORM_MINMAX)\n        \n    return data","17834f33":"#train_x = image_preprocessing(train_x, IMG_SIZE, sigmaX=10)\n#test_x = image_preprocessing(test_x, IMG_SIZE, sigmaX=10)","e369a3b2":"\"\"\"\nn = 10\ncols = 5\nrows = np.ceil(n\/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')\n\"\"\"","1a4af150":"import pickle\n\"\"\"\n# pickle out\npickle_out_train_x = open('train_x_aptos2019.pickle', 'wb')\npickle.dump(train_x, pickle_out_train_x)\npickle_out_train_x.close()\n\npickle_out_train_y = open('train_y_aptos2019-blindness-detection.pickle', 'wb')\npickle.dump(train_y, pickle_out_train_y)\npickle_out_train_y.close()\n\npickle_out_test_x = open('test_x_aptos2019-blindness-detection.pickle', 'wb')\npickle.dump(test_x, pickle_out_test_x)\npickle_out_test_x.close()\n\"\"\"\n\n#\"\"\"\n# pickle in\npickle_in_train_x = open('..\/input\/preprocessed-data-aptos2019blindnessdetection\/train_x_aptos2019.pickle', 'rb')\npickle_in_train_y = open('..\/input\/preprocessed-data-aptos2019blindnessdetection\/train_y_aptos2019.pickle', 'rb')\npickle_in_test_x = open('..\/input\/preprocessed-data-aptos2019blindnessdetection\/test_x_aptos2019.pickle', 'rb')\n\ntrain_x = pickle.load(pickle_in_train_x)\ntrain_y = pickle.load(pickle_in_train_y)\ntest_x = pickle.load(pickle_in_test_x)\n\nprint(train_x.shape, train_y.shape, test_x.shape)\n#\"\"\"","60861467":"n = 5\ncols = 5\nrows = np.ceil(n\/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(train_x[i])\n  plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')","71e80776":"n = 5\ncols = 5\nrows = np.ceil(n\/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')","f95afd62":"#\"\"\"\ndef create_model_1():\n    layers_1 = [\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu, input_shape=train_x.shape[1:]),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Flatten(),  \n        tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=len(np.unique(train_y)), activation=tf.nn.softmax),\n    ] \n\n    model_1 = tf.keras.Sequential(layers_1)\n    model_1.compile(optimizer=tf.keras.optimizers.Adam(), #tf.optimizers.Adam(),\n                 loss=tf.keras.losses.sparse_categorical_crossentropy, #tf.losses.SparseCategoricalCrossentropy(),\n                 metrics=['accuracy'])\n    \n    return model_1\n#\"\"\"","ec2b685b":"#\"\"\"\nmodel_1 = create_model_1()\nmodel_1.summary()\n#\"\"\"","a3d8c6d5":"#\"\"\"\n# https:\/\/www.youtube.com\/watch?v=HxtBIwfy0kM\ncheckpoint_path = 'cp_model_1_aptos2019-blindness-detection.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create checkpoint callback\ncp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\nmodel_1 = create_model_1()\n\nmodel_1.fit(train_x, train_y, epochs=5, batch_size=32, \n            callbacks=[cp_callback])  # pass calback to training\n#\"\"\"","ff25a82e":"#\"\"\"\ntrain_predicted = model_1.predict(train_x)\ntrain_predicted = [np.argmax(i) for i in train_predicted]\n\nfrom sklearn.metrics import cohen_kappa_score\ncohen_kappa_score(train_predicted, train_y, weights='quadratic')\n#\"\"\"","ae2dbdcf":"\"\"\" Memory error here\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=30,\n    brightness_range=[0.5, 1.5],\n    zoom_range=[0.8, 1.2],\n    horizontal_flip=True,\n    vertical_flip=False)\n\ndatagen.fit(train_x)\n\ncheckpoint_path = 'cp_model_1_aptos2019-blindness-detection.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n# Create checkpoint callback\ncp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                save_weights_only=True,\n                                                verbose=1)\n\nmodel_1 = create_model_1()\n\n# fits the model on batches with real-time data augmentation:\nmodel_1.fit_generator(datagen.flow(train_x, train_y, batch_size=32),\n                      steps_per_epoch=len(train_x) \/ 32, epochs=5,\n                      callbacks=[cp_callback])\n\"\"\"","5af96f3c":"#model_1 = create_model_1()\n\n#loss, acc = model_1.evaluate(x, y)\n#print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))","7e6aa45e":"#model_1.load_weights('..\/input\/blindness-1\/cp_model_1_aptos2019-blindness-detection.ckpt')\n#loss, acc = model_1.evaluate(x, y)\n#print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))","d4eaf252":"#\"\"\"\ntest_predicted = model_1.predict(test_x)\ntest_predicted = [np.argmax(i) for i in test_predicted]\ntest_result = pd.DataFrame({\"id_code\": test[\"id_code\"].values, \"diagnosis\": test_predicted})\ntest_result.head()\n#\"\"\"","b63f4999":"test_result.to_csv('submission.csv', index=False)","ca8a62aa":"n = 5\ncols = 5\nrows = np.ceil(n\/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n    plt.subplot(rows, cols, i+1)\n    plt.imshow(test_x[i])\n    plt.title(test_predicted[i], fontsize=40)\n    plt.axis('off') ","205c7ba7":"# How to count the occurrence of certain item in an ndarray (from numpy) in Python? \n# https:\/\/stackoverflow.com\/questions\/28663856\/how-to-count-the-occurrence-of-certain-item-in-an-ndarray-in-python\nunique, counts = np.unique(test_predicted, return_counts=True)\nmydict = dict(zip(unique, counts))","1fa8e3b5":"plt.bar(unique, counts)\nplt.show()","59402532":"# Constants","0ac7c952":"Images after preprocessing","b5769cf2":"Images before preprocessing","644d0803":"# Importing libraries","238d5627":"### Train the model","4f332402":"# Loading data","e0e976e7":"## Import model","980e45ed":"## Pickle\nyou don't want to rebuild your dataset everytime!","22207945":"## Resources\n* [Preprocessing & Cropping](https:\/\/www.kaggle.com\/ratthachat\/aptos-updated-preprocessing-ben-s-cropping) ","853a55e6":"# Preprocessing","5e40f84e":"normalization\nhttps:\/\/docs.opencv.org\/2.4\/modules\/core\/doc\/operations_on_arrays.html#cv2.normalize\nhttps:\/\/stackoverflow.com\/questions\/40645985\/opencv-python-normalize-image\/42164670","d65a562b":"Simple_1 with no augmentation","0f2ec7ed":"Auto-cropping","0575f145":"## Predict","d4e27583":"### Model_1 with augmentation","49981f4f":"### Model_1","8023e01f":"Ben Graham's preprocessing method"}}