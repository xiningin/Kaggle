{"cell_type":{"2bcac257":"code","be35d702":"code","accb213f":"code","10bec9c6":"code","b3582680":"code","ed4e15d6":"code","70e319cd":"code","d2e2f1b5":"code","f90c0c36":"code","f6cf8ab7":"code","6575a951":"code","7e52477b":"code","77919f88":"code","4e60a76c":"code","e24bccf7":"code","aee007aa":"code","f8e39615":"code","f38cb7f2":"code","6193263c":"code","af0253ec":"code","9aff7af6":"code","1053fabc":"code","60c3026b":"code","88db537b":"code","46f09153":"code","caee53c3":"code","b93fadc6":"code","8987a2a2":"code","1d2bf044":"code","bdc44ff5":"code","a042c0c8":"markdown","37b43ad5":"markdown","49e01078":"markdown","139ec118":"markdown","01b686e0":"markdown","5376fb9d":"markdown","90d2f1a1":"markdown","dd07effa":"markdown","a78737cd":"markdown","a82ff67d":"markdown","1a913579":"markdown","d7590190":"markdown","895863c7":"markdown","f0ea873a":"markdown","89b31f8c":"markdown","ad57c5fe":"markdown","7e108318":"markdown","531283ad":"markdown","3f52068d":"markdown","f20a85b9":"markdown","8c3de2cd":"markdown","38772c3d":"markdown","2edc6369":"markdown","ea521bf2":"markdown","47c740ca":"markdown","301cb9c6":"markdown"},"source":{"2bcac257":"import numpy as np \nimport pandas as pd \nimport os\nfrom keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\nfrom keras.models import Model\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import regularizers","be35d702":"for dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","accb213f":"!unzip ..\/input\/train.zip -d train\n!unzip ..\/input\/test.zip -d test","10bec9c6":"print(os.listdir('..\/'))","b3582680":"filenames = os.listdir(\"..\/working\/train\/train\")\n\nlabels = []\nfor file in filenames:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append('cat')\n    else:\n        labels.append('dog')","ed4e15d6":"df = pd.DataFrame({\n    'filename': filenames,\n    'label': labels\n})","70e319cd":"df.head(10)","d2e2f1b5":"def get_class_counts(df):\n    grp = df.groupby(['label']).nunique()\n    return {key: grp[key] for key in list(grp.keys())}\n\ndef get_class_proportions(df):\n    class_counts = get_class_counts(df)\n    return {val[0]: round(val[1]\/df.shape[0],4) for val in class_counts.items()}","f90c0c36":"print(\"Dataset class counts\", get_class_counts(df))","f6cf8ab7":"print(\"Dataset class proportions\", get_class_proportions(df))","6575a951":"train_df, validation_df = train_test_split(df, \n                                           test_size=0.1, \n                                           stratify=df['label'],\n                                           random_state = 42)","7e52477b":"print(\"Train data class proportions : \", get_class_proportions(train_df))\nprint(\"Validation data class proportions : \", get_class_proportions(validation_df))","77919f88":"train_df.head(10)","4e60a76c":"train_df = train_df.reset_index(drop=True)\n\nvalidation_df = validation_df.reset_index(drop=True)","e24bccf7":"train_df.head(10)","aee007aa":"batch_size = 64\ntrain_num = len(train_df)\nvalidation_num = len(validation_df)\n\nprint(\"The number of training set is {}\".format(train_num))\nprint(\"The number of validation set is {}\".format(validation_num))","f8e39615":"def two_image_generator(generator, df, directory, batch_size,\n                        x_col = 'filename', y_col = None, model = None, shuffle = False,\n                        img_size1 = (224, 224), img_size2 = (299,299)):\n    gen1 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size1,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    gen2 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size2,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    \n    while True:\n        X1i = gen1.next()\n        X2i = gen2.next()\n        \n        if y_col:\n            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n        else:\n            yield [X1i, X2i]\n        ","f38cb7f2":"ex_df = pd.DataFrame()\nex_df['filename'] = filenames[:5]\nex_df['label'] = labels[:5]\nex_df.head()\n\ntrain_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ne1 = two_image_generator(train_aug_datagen, ex_df, '..\/working\/train\/train\/',\n                                      batch_size = 2, y_col = 'label',\n                                      model = 'binary', shuffle = True)\n\nfig = plt.figure(figsize = (10,10))\nbatches = 0\nrows = 5\ncols = 5\ni = 0\nj = 0\nindices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\nindices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\nfor [x_batch, x_batch2], y_batch in e1:\n    for image in x_batch:\n        fig.add_subplot(rows, cols, indices_a[i])\n        i += 1\n        plt.imshow(image.astype('uint8'))\n        \n    for image in x_batch2:\n        fig.add_subplot(rows, cols, indices_b[j])\n        j += 1\n        plt.imshow(image.astype('uint8'))\n    \n    batches += 1\n    if batches >= 6:\n        break\nplt.show()\n\n","6193263c":"train_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ntrain_generator = two_image_generator(train_aug_datagen, train_df, '..\/working\/train\/train\/',\n                                      batch_size = batch_size, y_col = 'label',\n                                      model = 'binary', shuffle = True)","af0253ec":"validation_datagen = ImageDataGenerator()\n\nvalidation_generator = two_image_generator(validation_datagen, validation_df,\n                                           '..\/working\/train\/train\/', batch_size = batch_size,\n                                           y_col = 'label',model = 'binary', shuffle = True)","9aff7af6":"def create_base_model(MODEL, img_size, lambda_fun = None):\n    inp = Input(shape = (img_size[0], img_size[1], 3))\n    x = inp\n    if lambda_fun:\n        x = Lambda(lambda_fun)(x)\n    \n    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n        \n    model = Model(inp, base_model.output)\n    return model","1053fabc":"#define vgg + resnet50 + densenet\nmodel1 = create_base_model(vgg16.VGG16, (224, 224), vgg16.preprocess_input)\nmodel2 = create_base_model(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)\nmodel3 = create_base_model(inception_v3.InceptionV3, (299, 299), inception_v3.preprocess_input)\nmodel1.trainable = False\nmodel2.trainable = False\nmodel3.trainable = False\n\ninpA = Input(shape = (224, 224, 3))\ninpB = Input(shape = (299, 299, 3))\nout1 = model1(inpA)\nout2 = model2(inpA)\nout3 = model3(inpB)\n\nx = Concatenate()([out1, out2, out3])                \nx = Dropout(0.6)(x)\nx = Dense(1, activation='sigmoid')(x)\nmultiple_pretained_model = Model([inpA, inpB], x)\n\nmultiple_pretained_model.compile(loss = 'binary_crossentropy',\n                          optimizer = 'rmsprop',\n                          metrics = ['accuracy'])\n\nmultiple_pretained_model.summary()","60c3026b":"checkpointer = ModelCheckpoint(filepath='dogcat.weights.best.hdf5', verbose=1, \n                               save_best_only=True, save_weights_only=True)","88db537b":"%%time\nmultiple_pretained_model.fit_generator(\n    train_generator,\n    epochs = 5,\n    steps_per_epoch = train_num \/\/ batch_size,\n    validation_data = validation_generator,\n    validation_steps = validation_num \/\/ batch_size,\n    verbose = 1,\n    callbacks = [checkpointer]\n)","46f09153":"multiple_pretained_model.load_weights('dogcat.weights.best.hdf5')","caee53c3":"test_filenames = os.listdir(\"..\/working\/test\/test\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\n\nnum_test = len(test_df)\n\ntest_datagen = ImageDataGenerator()\n\ntest_generator = two_image_generator(test_datagen, test_df, '..\/working\/test\/test\/', batch_size = batch_size)","b93fadc6":"prediction = multiple_pretained_model.predict_generator(test_generator, \n                                         steps=np.ceil(num_test\/batch_size))","8987a2a2":"prediction = prediction.clip(min = 0.005, max = 0.995)","1d2bf044":"submission_df = pd.read_csv('..\/input\/sample_submission.csv')\n\nfor i, fname in enumerate(test_filenames):\n    index = int(fname[fname.rfind('\/')+1:fname.rfind('.')])\n    submission_df.at[index-1, 'label'] = prediction[i]\nsubmission_df.to_csv('Cats&DogsSubmission.csv', index=False)","bdc44ff5":"submission_df.head()","a042c0c8":"* values smaller than 0.005 become 0.005, and values larger than 0.995 become 0.995.","37b43ad5":"# Prediction","49e01078":"# See which directories have you got","139ec118":"# Modeling\n\n1. Create model architecture\n2. Compile\n3. callbacks\n4. fit_generator","01b686e0":"# Specify DataFrame or Directory ","5376fb9d":"# Check out where my output files reside","90d2f1a1":"# Add data augmentation","dd07effa":"# Manually labelling 2 different datasets and save them into labels\n\nfile.split('.')[0] means - \n* the particular filename is a String separated by dots.\n* line.split(\".\")[0] returns the 1st item of the array. (the actual file looks like \"cat.100.jpg\")","a78737cd":"* In case of train_test_split, allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes. I'm using pandas dataframes. \n* Our dependent variable will be label and filename will act as an independent variable.","a82ff67d":"# Train Test Splitting","1a913579":"* Since we're gonna use two different types of multi input model with flow from directory, I'm using two generator.\n* In case of generator, \"yield\" is used instead of \"return\". Cz, we need to generate image on the fly, which iterates over the loop once.","d7590190":"* best weight will be stored in dogcat.weights.best.hdf5","895863c7":"I'm gonna label the data, so that in train test split I won't have to use stratification.","f0ea873a":"* We can see, there is no need of indexing, so I'm dropping it.","89b31f8c":"# Preprocessing test data","ad57c5fe":"* Confirm that the labels of both training and validation sets are equally divided.","7e108318":"# Import Packages","531283ad":"# Make sure that the labels are proportionately equal before and after the train_test_split","3f52068d":"# Clipping predicted result","f20a85b9":"* Adding augmented data will not improve the accuracy of the validation. Which is why, augmetation on validation dataset is kind of superfluous","8c3de2cd":"* Test if the generator generates same images with two different sizes(225 & 300)","38772c3d":"# Preprocessing\n\n1. Augmentation\n2. Flow_from_dataframe","2edc6369":"# Unzip the zip files","ea521bf2":"# Submission","47c740ca":"* We can see the classes are divided equally into 0.5.","301cb9c6":"* Divide the labels according to \"label\" stratification."}}