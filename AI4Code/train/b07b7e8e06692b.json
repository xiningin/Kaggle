{"cell_type":{"b184bccd":"code","2f50c07f":"code","0be96828":"code","68067ebd":"code","2ca0d8c9":"code","4c8e918e":"code","1ae7853e":"code","bd50bb20":"code","b5deed8b":"code","54a16cbe":"code","c3ccd923":"code","542673c2":"code","2c10a5c7":"code","c30ea32f":"code","04d71e25":"code","374aeeee":"code","d881a0ea":"code","87057ad9":"code","c56f7941":"code","6345096a":"code","ea02817a":"code","e0eecfba":"code","1c433833":"code","233fe7fa":"code","f22eee68":"code","4a5a7419":"code","fcf3b53b":"markdown","3e88f73e":"markdown","b307a287":"markdown","1b0293ff":"markdown","f740b714":"markdown","2951d36f":"markdown","23565916":"markdown","17f0613a":"markdown","fb2d6597":"markdown","2933857e":"markdown","067f4dda":"markdown","569ea5c5":"markdown","cbdae3a1":"markdown","eadc936f":"markdown","67d499da":"markdown"},"source":{"b184bccd":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport glob","2f50c07f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0be96828":"IMAGE_SIZE = 200","68067ebd":"img_dir = \"..\/input\/car-plate-detection\/images\" # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\nfiles.sort() #We sort the images in alphabetical order to match them to the xml files containing the annotations of the bounding boxes\nX=[]\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    X.append(np.array(img))\n    ","2ca0d8c9":"from lxml import etree\ndef resizeannotation(f):\n    tree = etree.parse(f)\n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n    for dim in tree.xpath(\"object\/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)\/(width\/IMAGE_SIZE)\n        ymin = int(dim.xpath(\"ymin\")[0].text)\/(height\/IMAGE_SIZE)\n        xmax = int(dim.xpath(\"xmax\")[0].text)\/(width\/IMAGE_SIZE)\n        ymax = int(dim.xpath(\"ymax\")[0].text)\/(height\/IMAGE_SIZE)\n    return [int(xmax), int(ymax), int(xmin), int(ymin)]\n        ","4c8e918e":"path = '..\/input\/car-plate-detection\/annotations'\ntext_files = ['..\/input\/car-plate-detection\/annotations\/'+f for f in sorted(os.listdir(path))]\ny=[]\nfor i in text_files:\n    y.append(resizeannotation(i))","1ae7853e":"resizeannotation(\"\/kaggle\/input\/car-plate-detection\/annotations\/Cars147.xml\")","bd50bb20":"y[0]","b5deed8b":"np.array(X).shape","54a16cbe":"np.array(y).shape","c3ccd923":"plt.figure(figsize=(10,20))\nfor i in range(0,17) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X[i])","542673c2":"#Example with the first image of the dataset\nimage = cv2.rectangle(X[0],(y[0][0],y[0][1]),(y[0][2],y[0][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","2c10a5c7":"#Example with the second image of the dataset\nimage = cv2.rectangle(X[1],(y[1][0],y[1][1]),(y[1][2],y[1][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","c30ea32f":"#Transforming in array\nX=np.array(X)\ny=np.array(y)","04d71e25":"#Renormalisation\nX = X \/ 255\ny = y \/ 255","374aeeee":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","d881a0ea":"from keras.models import Sequential\n\nfrom keras.layers import Dense, Flatten\n\nfrom keras.applications.vgg16 import VGG16","87057ad9":"# Create the model\nmodel = Sequential()\nmodel.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"sigmoid\"))\n\nmodel.layers[-6].trainable = False\n\nmodel.summary()","c56f7941":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","6345096a":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)","ea02817a":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","e0eecfba":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","1c433833":"plot_scores(train)","233fe7fa":" y_cnn = model.predict(X_test)","f22eee68":"y_cnn.shape","4a5a7419":"plt.figure(figsize=(20,40))\nfor i in range(0,43) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    ny = y_cnn[i]*255\n    image = cv2.rectangle(X_test[i],(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    plt.imshow(image)\n\n","fcf3b53b":"We can see how our model localize license plates on our testing set :","3e88f73e":"We prepare the data for the CNN :","b307a287":"![image.png](attachment:image.png)","1b0293ff":"This dataset contains 433 images with bounding box annotations of the car license plates within the image. Our goal here is to train a convolutional neural network capable of locating licenses plate on new images. ","f740b714":"Import libraries","2951d36f":"## DETECTION ","23565916":"We create the variable X containing all the images of cars by resizing them to 200 * 200.\n\n","17f0613a":"We can draw the rectangle containing the license plate using the OpenCV library","fb2d6597":"And we display the first eighteen image of the dataset : ","2933857e":"We display the files in Kaggle repertoire :","067f4dda":"We check X et y shape","569ea5c5":"We create the variable y containing all the bounding boxe annotations (label). \nBefore that, we will have to resize the annotations so that it fits the new size of the images (200*200). We create a function resizeannotation for that. ","cbdae3a1":"## Convolutionnal Neural Network","eadc936f":"We split our dataset in two : training set\/testing set","67d499da":"## Preparation of the data"}}