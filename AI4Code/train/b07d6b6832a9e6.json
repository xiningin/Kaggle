{"cell_type":{"e770ac1a":"code","f43454cd":"code","f240c31f":"code","9df84775":"code","fd9a1719":"code","b03d652d":"code","03a9dc56":"code","a83fd933":"code","ffb35717":"code","e80960ab":"code","cbbaeedb":"code","6cb54e2a":"code","0b77567c":"code","c1658555":"code","be994912":"code","2ece9940":"code","96dbdbc3":"code","1ff171b4":"code","7f3b5fc7":"code","25a744de":"code","1814a288":"code","98a15bd2":"code","fd03c1a6":"code","bb0818a6":"code","3033f07b":"code","de3afad9":"code","f6019cfa":"code","f95c5fb2":"code","5bc4d215":"code","028969f6":"code","21043b8c":"code","7e763807":"code","a886db44":"code","325d17d4":"code","11e536a1":"code","173091f5":"code","9152289e":"code","a8699f1a":"code","817d2feb":"code","f64cb6ee":"markdown","ab1fc926":"markdown","abebed62":"markdown","e30880d8":"markdown","db11ee77":"markdown","9bc5c31f":"markdown","e5b98b7f":"markdown","a495ea03":"markdown","ff17898b":"markdown","67976a7a":"markdown","efd8edc4":"markdown","bfce534d":"markdown","f0b90f2e":"markdown","f78ae409":"markdown","83355274":"markdown","243ab97e":"markdown","8afeafdc":"markdown","390b9d5f":"markdown","ac7e7c46":"markdown","f5498b45":"markdown","149ab7b5":"markdown","84c8a252":"markdown","43871463":"markdown","490979e9":"markdown","3bc5b7c8":"markdown","02f9f52f":"markdown","8e791a4b":"markdown","6b7e22a6":"markdown","144fd4b4":"markdown","ef1efec3":"markdown","a5363d80":"markdown","d3b40315":"markdown","4b19cdae":"markdown","d2b9c187":"markdown","6161fd2b":"markdown","b43dbe83":"markdown","e42ec6e8":"markdown","eae370cc":"markdown","ff46171c":"markdown","d9ab8671":"markdown","0848e9cc":"markdown","c50e1942":"markdown"},"source":{"e770ac1a":"# Let's gooooooo\n\nimport numpy as np\nimport pandas as pd\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nsurvey20 = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', low_memory = False)\n# ignore first row since it contains description of questions\nsurvey20 = survey20.drop([0])\n\nprint (\"Shape of Kaggle DS Survey Data: \", survey20.shape)","f43454cd":"# Q15 = For how many years have you used machine learning methods?\nprint(\"ML Experience of Kagglers in the year 2020: \", survey20.groupby('Q15').size())","f240c31f":"# Removing participants who have 0 ML experience; We're talking about ML experience right...\nsurvey20 = survey20[survey20.Q15 != 'I do not use machine learning methods']\nprint (\"Number of survey participants who have ML experience: \", survey20.shape[0])","9df84775":"# Put colors to numbers\n\n# Pretty names for the graph & easy access\nexpdict = {\"Under 1 year\": \"< 1 Year\",\n           \"1-2 years\": \"< 2 Years\",\n           \"2-3 years\": \"2-5 Years\",\n           \"3-4 years\": \"2-5 Years\",\n           \"4-5 years\": \"2-5 Years\",\n           \"5-10 years\": \"5-10 Years\",\n           \"10-20 years\": \"10-20 Years\",\n           \"20 or more years\": \"20+ Years\"}\n\n# What we would plot\nnm_cols = ['Experience', 'Count']\nexpname_count_df = pd.DataFrame(columns = nm_cols)\n\n# We use funcs; We is cool;\ndef populate_expname_count(in_df, out_df):\n    enames = in_df.ExpName.unique()\n    for enm in enames:\n        out_df = out_df.append({'Experience': enm,\n                                'Count': len(in_df[in_df['ExpName'] == enm])}, ignore_index = True)\n    return out_df\n\n\ndef set_value(row_number, assigned_value):\n    return assigned_value[row_number] \n\n# focussed columns\ninp_count_df = survey20[['Q15']]\ninp_count_df = inp_count_df.dropna()\ninp_count_df['ExpName'] = inp_count_df['Q15'].apply(set_value, args = (expdict, )) \nexpname_count_df = populate_expname_count(inp_count_df, expname_count_df)\n\nexpname_count_df['color'] = 'rgb(179,179,179)'\nexpname_count_df.loc[expname_count_df['Experience'] == '5-10 Years', \"color\"] = '#FFFFCC'\nexpname_count_df.loc[(expname_count_df['Experience'] == '10-20 Years'), \"color\"] = '#9EB9F3'\nexpname_count_df.loc[(expname_count_df['Experience'] == '20+ Years'), \"color\"] = '#8DD3C7'\n\n# Gimme the pretty picture now!\nfig = px.bar(expname_count_df,\n             x = \"Experience\",\n             y = \"Count\",\n             color = \"color\",\n             hover_name = \"Count\",\n             color_discrete_sequence = expname_count_df.color.unique())\nfig.update_layout(showlegend = False)\nfig.show()\n\n","fd9a1719":"# Smaller label for 20+ years experience\nsurvey20[\"temp\"] = survey20[\"Q15\"].apply(str)\nsurvey20.loc[survey20[\"Q15\"] == '20 or more years', \"temp\"] = '20+ years'\nsurvey20['Q15'] = survey20['temp']\ndel survey20['temp']","b03d652d":"# Checking Inconsistencies\n\n# You can't have an 18-21 year old who has ML experience of 20+ years. Right?\nprint(\"Number of 18-21 year olds who have ML experience of 20+ years: \", len(survey20[(survey20['Q1'] == '18-21') & (survey20['Q15'] == '20+ years')]))\n# Remove these 'child prodigies'\nsurvey20.drop(survey20[(survey20['Q1'] == '18-21') & (survey20['Q15'] == '20+ years')].index, inplace = True) \n\n# Do we have any Kagglers who started ML programming at the age of 8-10 years\nprint(\"Number of 18-21 year olds who have ML experience of 10-20 years: \", len(survey20[(survey20['Q1'] == '18-21') & (survey20['Q15'] == '10-20 years')]))\n# Gotta drop ya kid\nsurvey20.drop(survey20[(survey20['Q1'] == '18-21') & (survey20['Q15'] == '10-20 years')].index, inplace = True) \n","03a9dc56":"# Bursting suns of comparisons ^_^\n# How are age, gender, formal education & job title distributed\n\nsubset_df = survey20[[\"Q1\", \"Q2\", \"Q4\", \"Q5\", \"Q15\"]]\n\nsubset_df = subset_df[(subset_df.Q15 == '5-10 years') | (subset_df.Q15 == '10-20 years') | (subset_df.Q15 == '20+ years')]\n\n# How are ages distributed\nfig_age_exp = px.treemap(subset_df,\n                        path=['Q15', 'Q1'],\n                        color='Q1',\n                        color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig_age_exp.show()\n","a83fd933":"# How are gender distributed\nfig_gndr_exp = px.treemap(subset_df,\n                        path=['Q15', 'Q2'],\n                        color='Q2',\n                        color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig_gndr_exp.show()","ffb35717":"# How is formal education distributed\nfig_deg_exp = px.treemap(subset_df,\n                        path=['Q15', 'Q4'],\n                        color='Q4',\n                        color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig_deg_exp.show()","e80960ab":"# How are job titles distributed\nfig_job_exp = px.treemap(subset_df,\n                         path=['Q15', 'Q5'],\n                         color='Q5',\n                         color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig_job_exp.show()","cbbaeedb":"# Where do our experts live? (Mama raised no stalkers)\n\ncntry_df = survey20[['Q3', 'Q15']]\n\n# We just want country names; not non-specific text\ncntry_df = cntry_df[cntry_df.Q3 != 'Other'] \n\n# 15 Countries with highest 5-10 years ML Experts\nfive_df = (cntry_df.assign(Helper = (cntry_df['Q15'] == '5-10 years'))\n        .groupby(['Q3'])['Helper']\n        .agg([('FiveCount','sum'),('Count','size')])\n        .astype(int)\n        .reset_index()).sort_values('FiveCount', ascending = False).head(15)\nprint (\"Countries with Highest # of 5-10 years ML Experts (in descending order):\\n\", list(five_df['Q3']))\n\n# 15 Countries with highest 10-20 years ML Experts\nten_df = (cntry_df.assign(Helper = (cntry_df['Q15'] == '10-20 years'))\n        .groupby(['Q3'])['Helper']\n        .agg([('TenCount','sum'),('Count','size')])\n        .astype(int)\n        .reset_index()).sort_values('TenCount', ascending = False).head(15)\nprint (\"\\nCountries with Highest # of 10-20 years ML Experts (in descending order):\\n\", list(ten_df['Q3']))\n\n# 15 Countries with highest 20+ years ML Experts\ntwenty_df = (cntry_df.assign(Helper = (cntry_df['Q15'] == '20+ years'))\n        .groupby(['Q3'])['Helper']\n        .agg([('TwentyCount','sum'),('Count','size')])\n        .astype(int)\n        .reset_index()).sort_values('TwentyCount', ascending = False).head(15)\nprint (\"\\nCountries with Highest # of 20+ years ML Experts (in descending order):\\n\", list(twenty_df['Q3']))\n\n# To plot numbers in relevant scale, selecting countries that are common among the above 3 lists\ncommon_countries = list(set(five_df.Q3) & set(ten_df.Q3) & set(twenty_df.Q3))\nprint (\"\\nCommon countries with Highest # of ML Experts (in descending order):\\n\", common_countries)\n\n# Let's create a DF that has counts of all three expert experiences\ncommon_df = five_df[five_df['Q3'].isin(common_countries)]\n\nfrom functools import reduce\n# join bw 5-10 & 10-20\ncommon_df = reduce(lambda x,y: pd.merge(x,y, on = 'Q3', how='outer'), [common_df, ten_df[ten_df['Q3'].isin(common_countries)]])\ncommon_df = common_df.rename(columns = {'Count_x': 'Count'})\ndel common_df['Count_y']\n\n# join bw above & 10-20\ncommon_df = reduce(lambda x,y: pd.merge(x,y, on = 'Q3', how='outer'), [common_df, twenty_df[twenty_df['Q3'].isin(common_countries)]])\ndel common_df['Count_x']\ndel common_df['Count_y']\n\n# Making separate columns into rows for better plotting capability\ncommon_df = common_df.melt(id_vars = [\"Q3\"], var_name = \"Experience\", value_name = \"Count\")\n# Renaming melted columns to experience text again\ncommon_df.loc[(common_df.Experience == 'FiveCount'), 'Experience'] = '5-10 years'\ncommon_df.loc[(common_df.Experience == 'TenCount'), 'Experience'] = '10-20 years'\ncommon_df.loc[(common_df.Experience == 'TwentyCount'), 'Experience'] = '20+ years'\ncommon_df = common_df.rename(columns = {'Q3': 'Country of Residence'})\n\n# And we plot!\nfig = px.bar(common_df,\n             x = \"Country of Residence\",\n             y = \"Count\",\n             color = \"Experience\",\n             #title = \"Experts and Their Countries\",\n             color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig.show()","6cb54e2a":"# The Question \"Select any activities that make up an important part of your role at work\" was multi-choice\n# So a person could've chosen any number of parts of Q23\njobprof_df = survey20[['Q15', 'Q5', 'Q23_Part_1', 'Q23_Part_2', 'Q23_Part_3', 'Q23_Part_4', 'Q23_Part_5', 'Q23_Part_6', 'Q23_Part_7', 'Q23_OTHER']]\n                      \njobprof_df = jobprof_df[(jobprof_df.Q15 == '5-10 years') | (jobprof_df.Q15 == '10-20 years') | (jobprof_df.Q15 == '20+ years')]\n\nprofile_dict = {'Q23_Part_1': 'Analyze Data to Influence Decisions',\n                'Q23_Part_2': 'Build(+,\/Run) Data Infra',\n                'Q23_Part_3': 'Build Prototypes',\n                'Q23_Part_4': 'Build(+,\/Run) ML Service',\n                'Q23_Part_5': 'Improve existing ML models',\n                'Q23_Part_6': 'Research',\n                'Q23_Part_7': 'None of listed',\n                'Q23_OTHER': 'Other'}\n\nprof_plotdf = jobprof_df\n\n# This func creates a new col with name = the job function description & col value = the presence flag(=True\/False)\n# Now why did I make the col name as job function? \n# Because then the DF could be melted to make cols to rows\ndef set_profile_flags(in_df, col_name):\n    in_df[profile_dict[col_name]] = ~in_df[col_name].isnull()\n    # delete the original question col since it is redundant now\n    del in_df[col_name]\n    return in_df\n\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_1')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_2')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_3')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_4')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_5')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_6')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_Part_7')\nprof_plotdf = set_profile_flags(prof_plotdf, 'Q23_OTHER')\n\n# And, we melt the df\nprof_plotdf = prof_plotdf.melt(id_vars = [\"Q15\", \"Q5\"], var_name = \"Function\", value_name = \"Presence\")\n# Dropping all false presence\nprof_plotdf = prof_plotdf[prof_plotdf.Presence == True]\n# Now we don't need the presence col\ndel prof_plotdf['Presence']\n\n# Count functions for a job title and experience category\nprof_plotdf = prof_plotdf.groupby(['Q15','Q5', 'Function']).size().reset_index(name='counts')\nprof_plotdf = prof_plotdf.rename(columns = {'Q5': 'Job Title'})\n\n# Puh-lot!\nfig = px.bar(prof_plotdf,\n             x = \"Function\",\n             y = \"counts\",\n             animation_frame = \"Q15\", # Enjoy the animation :)\n             color = \"Job Title\",\n             color_discrete_sequence = px.colors.sequential.YlGnBu,\n             title=\"How Role-wise Functions vary for the Three Expertise Categories\",\n             range_y=[0, 550],\n             hover_name = \"counts\")\n\nfig.show()","0b77567c":"emp_df = survey20[['Q5', 'Q15', 'Q20', 'Q21', 'Q22', 'Q24', 'Q25']]\n\n# Do our experts work?\n# Yes, Who's paying our experts? What are they like?\n# No, oh k. Bye!\nemp_df = emp_df[(emp_df.Q5 != 'Student') & (emp_df.Q5 != 'Currently not employed')]\n\nemp_df = emp_df[~emp_df.Q20.isnull()]\nemp_df = emp_df[~emp_df.Q21.isnull()]\nemp_df = emp_df[~emp_df.Q22.isnull()]\nemp_df = emp_df[emp_df.Q22 != 'I do not know']\n\nempexp_df = emp_df[(emp_df.Q15 == '5-10 years') | (emp_df.Q15 == '10-20 years') | (emp_df.Q15 == '20+ years')]\nempex_count = empexp_df.groupby(['Q20']).Q20.agg('count').to_frame('Count').reset_index()\n\nemprest_df = emp_df[(emp_df.Q15 != '5-10 years') | (emp_df.Q15 != '10-20 years') | (emp_df.Q15 != '20+ years')]\nemprest_count = emprest_df.groupby(['Q20']).Q20.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 2, specs = specs, subplot_titles=['(DS & ML)-Experts', 'Rest'])\nfig.add_trace(go.Pie(labels = empex_count.Q20,\n                     scalegroup='two',\n                     values = empex_count.Count,\n                     name=\"Experts\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = emprest_count.Q20,\n                     scalegroup='one',\n                     values = emprest_count.Count,\n                     name=\"Rest\",\n                     marker_colors = px.colors.sequential.Greys),\n              1, 2)\n\nfig.update_traces(hole=.4)\nfig.show()","c1658555":"ml_incorporation_txt = {\n    'We are exploring ML methods (and may one day put a model into production)': 'Someday, Maybe',\n    'We use ML methods for generating insights (but do not put working models into production)': 'Internally only',\n    'We recently started using ML methods (i.e., models in production for less than 2 years)': 'Recent Players',\n    'We have well established ML methods (i.e., models in production for more than 2 years)': 'Old Players',\n    'No (we do not use ML methods)': 'No'\n}\n\nemp_df.loc[(emp_df.Q22 == 'We are exploring ML methods (and may one day put a model into production)'), 'Q22'] = ml_incorporation_txt[\"We are exploring ML methods (and may one day put a model into production)\"]\nemp_df.loc[(emp_df.Q22 == 'We use ML methods for generating insights (but do not put working models into production)'), 'Q22'] = ml_incorporation_txt[\"We use ML methods for generating insights (but do not put working models into production)\"]\nemp_df.loc[(emp_df.Q22 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'), 'Q22'] = ml_incorporation_txt[\"We recently started using ML methods (i.e., models in production for less than 2 years)\"]\nemp_df.loc[(emp_df.Q22 == 'We have well established ML methods (i.e., models in production for more than 2 years)'), 'Q22'] = ml_incorporation_txt[\"We have well established ML methods (i.e., models in production for more than 2 years)\"]\nemp_df.loc[(emp_df.Q22 == 'No (we do not use ML methods)'), 'Q22'] = ml_incorporation_txt[\"No (we do not use ML methods)\"]\n\nempexp_df = emp_df[(emp_df.Q15 == '5-10 years') | (emp_df.Q15 == '10-20 years') | (emp_df.Q15 == '20+ years')]\nemprest_df = emp_df[(emp_df.Q15 != '5-10 years') | (emp_df.Q15 != '10-20 years') | (emp_df.Q15 != '20+ years')]\n\nemp_mlex_count = empexp_df.groupby(['Q22']).Q22.agg('count').to_frame('Count').reset_index()\nemp_mlrest_count = emprest_df.groupby(['Q22']).Q22.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 2, specs = specs, subplot_titles=['(DS & ML)-Experts', 'Rest'])\nfig.add_trace(go.Pie(labels = emp_mlex_count.Q22,\n                     scalegroup='two',\n                     values = emp_mlex_count.Count,\n                     name=\"Experts\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = emp_mlrest_count.Q22,\n                     scalegroup='one',\n                     values = emp_mlrest_count.Count,\n                     name=\"Rest\",\n                     marker_colors = px.colors.sequential.Greys),\n              1, 2)\n\nfig.update_traces(hole=.4)\nfig.show()","be994912":"# Who makes small moolah, medium moolah & big moolah\n\n# clubbing together some pay ranges for a neater graph\npay_ranges = {\n    '$0-999': '<= 10K',\n    '1,000-1,999': '<= 10K',\n    '2,000-2,999': '<= 10K',\n    '3,000-3,999': '<= 10K',\n    '4,000-4,999': '<= 10K',\n    '5,000-7,499': '<= 10K',\n    '7,500-9,999': '<= 10K',\n    '10,000-14,999': '10-25K',\n    '15,000-19,999': '10-25K',\n    '20,000-24,999': '10-25K',\n    '25,000-29,999': '25K-50K',\n    '30,000-39,999': '25K-50K',\n    '40,000-49,999': '25K-50K',\n    '50,000-59,999': '50-100K',\n    '60,000-69,999': '50-100K',\n    '70,000-79,999': '50-100K',\n    '80,000-89,999': '50-100K',\n    '90,000-99,999': '50-100K',\n    '100,000-124,999': '100-150K',\n    '125,000-149,999': '100-150K',\n    '150,000-199,999': '150-250K',\n    '200,000-249,999': '150-250K',\n    '250,000-299,999': '250-500K',\n    '300,000-500,000': '250-500K',\n    '> $500,000': '> $500,000'\n}\nempexp_df = empexp_df.dropna()\nempexp_df['Q24'] = empexp_df['Q24'].apply(set_value, args = (pay_ranges, )) \n\n\ncomp_count = empexp_df.groupby(['Q24', 'Q15']).Q24.agg('count').to_frame('Count').reset_index()\ncomp_count = empexp_df.groupby(['Q24', 'Q15']).Q24.agg('count').to_frame('Count').reset_index()\ncomp_count = empexp_df.groupby(['Q24', 'Q15']).Q24.agg('count').to_frame('Count').reset_index()\n\n\n# Puh-lot!\nfig = px.bar(comp_count,\n             x = \"Q24\",\n             y = \"Count\",\n             animation_frame = \"Q15\",\n             color = \"Q24\",\n             color_discrete_sequence = px.colors.sequential.YlGnBu,\n             labels={\"Q24\": \"Compensation($)\"},\n             range_y=[0, 200],\n             hover_name = \"Count\")\n\nfig.show()","2ece9940":"# Frankly I just wanted the apple one  \u00af\\_(\u30c4)_\/\u00af \n\ncomp_5_count = empexp_df[empexp_df.Q15 == '5-10 years'].groupby(['Q24']).Q24.agg('count').to_frame('Count').reset_index()\ncomp_10_count = empexp_df[empexp_df.Q15 == '10-20 years'].groupby(['Q24']).Q24.agg('count').to_frame('Count').reset_index()\ncomp_20_count = empexp_df[empexp_df.Q15 == '20+ years'].groupby(['Q24']).Q24.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 3, specs = specs, subplot_titles=['5-10 Years', '10-20 Years', '20+ Years'])\nfig.add_trace(go.Pie(labels = comp_5_count.Q24,\n                     scalegroup='one',\n                     values = comp_5_count.Count,\n                     name=\"5-10 years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = comp_10_count.Q24,\n                     scalegroup='one',\n                     values = comp_10_count.Count,\n                     name=\"10-20 years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 2)\nfig.add_trace(go.Pie(labels = comp_20_count.Q24,\n                     scalegroup='one',\n                     values = comp_20_count.Count,\n                     name=\"20+ years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 3)\n\nfig.update_traces(hole=.4)\nfig.show()","96dbdbc3":"# Simpler compensation ranges\nempexp_df['Q25'] = empexp_df['Q25'].str.replace(r\"\\(.*\\)\",\"\")\nexpense_dict = {'$0 ': '$0',\n                '$1-$99': '< $100',\n                '100\u2212999': '$100 - $999',\n                '$100-$999': '$100 - $999',\n                '$1000-$9,999': '$1,000 - $9,999',\n                '10,000\u221299,999': '$10,000 - $99,999',\n                '$10,000-$99,999': '$10,000 - $99,999',\n                '$100,000 or more ': '> $100,000'\n}\nempexp_df['Q25'] = empexp_df['Q25'].apply(set_value, args = (expense_dict, )) ","1ff171b4":"# Is there any correlation between Employer size, usage of ML, compensation paid to Kaggler experts & money spent by the employer on ML+cloud services\n# What kinds of firms spend more on ML? Pay more?\n\nfrom sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \n\ncorr_df = empexp_df[['Q20', 'Q22', 'Q24', 'Q25']]\n\ncorr_df['Q20']= label_encoder.fit_transform(corr_df['Q20']) \ncorr_df = corr_df.rename(columns = {'Q20': 'Employer Size'})\ncorr_df['Q22']= label_encoder.fit_transform(corr_df['Q22']) \ncorr_df = corr_df.rename(columns = {'Q22': 'ML Incorporation Extent'})\ncorr_df['Q24']= label_encoder.fit_transform(corr_df['Q24']) \ncorr_df = corr_df.rename(columns = {'Q24': 'Kaggler Compensation'})\ncorr_df['Q25']= label_encoder.fit_transform(corr_df['Q25']) \ncorr_df = corr_df.rename(columns = {'Q25': 'Expenses on ML'})\n\nfig = px.imshow(corr_df.corr(method ='pearson'), color_continuous_scale=\"YlGnBu\")\nfig.show()\n","7f3b5fc7":"# so who's spending big on ML+Cloud?\nsank_df = empexp_df[['Q15', 'Q20', 'Q22', 'Q25']]\n\n# https:\/\/medium.com\/kenlok\/how-to-create-sankey-diagrams-from-dataframes-in-python-e221c1b4d6b0\ndef genSankey(df, cat_cols = [], value_cols = '', title = 'Sankey Diagram'):\n    colorPalette = ['#FFFFCC','#8DD3C7','#B3DE69','#9EB9F3','#87C55F']\n    labelList = []\n    colorNumList = []\n    for catCol in cat_cols:\n        labelListTemp =  list(set(df[catCol].values))\n        colorNumList.append(len(labelListTemp))\n        labelList = labelList + labelListTemp\n        \n    # remove duplicates from labelList\n    labelList = list(dict.fromkeys(labelList))\n    \n    # define colors based on number of levels\n    colorList = []\n    for idx, colorNum in enumerate(colorNumList):\n        colorList = colorList + [colorPalette[idx]]*colorNum\n        \n    # transform df into a source-target pair\n    for i in range(len(cat_cols)-1):\n        if i==0:\n            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            sourceTargetDf.columns = ['source','target','count']\n        else:\n            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            tempDf.columns = ['source','target','count']\n            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n            sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n        \n    # add index for source-target pair\n    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n        \n    return labelList, colorList, sourceTargetDf\n\nsank_df = sank_df[(sank_df.Q22 == 'Old Players') | (sank_df.Q22 == 'Recent Players') | (sank_df.Q22 == 'Internally only')]\n\nemp_sankey = sank_df.groupby(['Q15', 'Q20', 'Q22', 'Q25']).Q15.agg('count').to_frame('count').reset_index()\nelabels, ecolors, sankey_graph = genSankey(emp_sankey,\n                                           cat_cols=['Q15', 'Q20', 'Q22', 'Q25'],\n                                           value_cols='count',\n                                           title='Summary of Employer profile')\n\nfig = go.Figure(data=[go.Sankey(\n    node = dict(pad = 15,\n                thickness = 20,\n                line = dict(color = \"black\", width = 0.5),\n                label = elabels,\n                color = ecolors),\n    link = dict(source = sankey_graph['sourceID'],\n                target = sankey_graph['targetID'],\n                value = sankey_graph['count']))])\nfig.update_layout(title_text=\"Employer Profile of (DS & ML)-Expert Kagglers\", font_size=10)\nfig.show()\n","25a744de":"# Proging Preferences of Prolific Kagglers ^-^\n\nlang_df = survey20[['Q15', 'Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', 'Q7_Part_5', 'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9', 'Q7_Part_10', 'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER']]\n\nlanguage_dict = {'Q7_Part_1': 'Python',\n                 'Q7_Part_2': 'R',\n                 'Q7_Part_3': 'SQL',\n                 'Q7_Part_4': 'C',\n                 'Q7_Part_5': 'C++',\n                 'Q7_Part_6': 'Java',\n                 'Q7_Part_7': 'Javascript',\n                 'Q7_Part_8': 'Julia',\n                 'Q7_Part_9': 'Swift',\n                 'Q7_Part_10': 'Bash',\n                 'Q7_Part_11': 'MATLAB',\n                 'Q7_Part_12': 'None',\n                 'Q7_OTHER': 'Other'}\n\ndef set_profile_flags(in_df, col_name):\n    in_df[language_dict[col_name]] = ~in_df[col_name].isnull()\n    # delete the original question col since it is redundant now\n    del in_df[col_name]\n    return in_df\n\nlang_df = set_profile_flags(lang_df, 'Q7_Part_1')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_2')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_3')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_4')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_5')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_6')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_7')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_8')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_9')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_10')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_11')\nlang_df = set_profile_flags(lang_df, 'Q7_Part_12')\nlang_df = set_profile_flags(lang_df, 'Q7_OTHER')\n\nlang_df = lang_df.melt(id_vars = [\"Q15\"], var_name = \"Language\", value_name = \"Presence\")\n# Dropping all false presence\nlang_df = lang_df[lang_df.Presence == True]\n# Now we don't need the presence col\ndel lang_df['Presence']\n\n\nexp_progdf = lang_df[(lang_df.Q15 == '5-10 years') | (lang_df.Q15 == '10-20 years') | (lang_df.Q15 == '20+ years')]\nprogex_count = exp_progdf.groupby(['Language']).Language.agg('count').to_frame('Count').reset_index()\n\nrest_progdf = lang_df[(lang_df.Q15 != '5-10 years') | (lang_df.Q15 != '10-20 years') | (lang_df.Q15 != '20+ years')]\nprogrest_count = rest_progdf.groupby(['Language']).Language.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 2, specs = specs, subplot_titles=['(DS & ML)-Experts', 'Rest'])\nfig.add_trace(go.Pie(labels = progex_count.Language,\n                     scalegroup='two',\n                     values = progex_count.Count,\n                     name=\"Experts\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = progrest_count.Language,\n                     scalegroup='one',\n                     values = progrest_count.Count,\n                     name=\"Rest\",\n                     marker_colors = px.colors.sequential.Greys),\n              1, 2)\n\nfig.update_traces(hole=.4)\nfig.show()","1814a288":"sugg_df = survey20[['Q15', 'Q8']]\n\nsugg_df = sugg_df[(sugg_df.Q15 == '5-10 years') | (sugg_df.Q15 == '10-20 years') | (sugg_df.Q15 == '20+ years')]\n\nsugg_5_count = sugg_df[sugg_df.Q15 == '5-10 years'].groupby(['Q8']).Q8.agg('count').to_frame('Count').reset_index()\nsugg_10_count = sugg_df[sugg_df.Q15 == '10-20 years'].groupby(['Q8']).Q8.agg('count').to_frame('Count').reset_index()\nsugg_20_count = sugg_df[sugg_df.Q15 == '20+ years'].groupby(['Q8']).Q8.agg('count').to_frame('Count').reset_index()\n\n#subplot_colors = ['rgb(170,13,254)', 'rgb(133,102,13)', 'rgb(86,86,86)', 'rgb(22,255,50)', 'rgb(251,228,38)', 'rgb(196,69,28)', 'rgb(222,160,253)', 'rgb(50,90,155)', 'rgb(254,175,22)', 'rgb(28,255,206)', 'rgb(144,173,28)', 'rgb(218,96,202)', 'rgb(108,69,22)']\n\nspecs = [[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 3, specs = specs, subplot_titles=['5-10 Years', '10-20 Years', '20+ Years'])\nfig.add_trace(go.Pie(labels = sugg_5_count.Q8,\n                     scalegroup='one',\n                     values = sugg_5_count.Count,\n                     name=\"5-10 Years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = sugg_10_count.Q8,\n                     scalegroup='two',\n                     values = sugg_10_count.Count,\n                     name=\"10-20 Years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 2)\nfig.add_trace(go.Pie(labels = sugg_20_count.Q8,\n                     scalegroup='two',\n                     values = sugg_20_count.Count,\n                     name=\"20+ Years\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 3)\n\nfig.update_traces(hole=.4)\n#fig.update_layout(showlegend=False)\nfig.show()","98a15bd2":"ide_df = survey20[['Q15', 'Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5', 'Q9_Part_6',\n                    'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9', 'Q9_Part_10', 'Q9_Part_11', 'Q9_OTHER']]\n\nide_dict = {'Q9_Part_1': 'Jupyter(Lab\/Noteboook)',\n            'Q9_Part_2': 'RStudio',\n            'Q9_Part_3': 'Visual Studio',\n            'Q9_Part_4': 'VSCode',\n            'Q9_Part_5': 'PyCharm',\n            'Q9_Part_6': 'Spyder',\n            'Q9_Part_7': 'Notepad++',\n            'Q9_Part_8': 'Sublime Text',\n            'Q9_Part_9': 'Vim\/Emacs',\n            'Q9_Part_10': 'MATLAB',\n            'Q9_Part_11': 'None',\n            'Q9_OTHER': 'Other'}\n\ndef set_ide_flags(in_df, col_name):\n    in_df[ide_dict[col_name]] = ~in_df[col_name].isnull()\n    # delete the original question col since it is redundant now\n    del in_df[col_name]\n    return in_df\n\nide_df = set_ide_flags(ide_df, 'Q9_Part_1')\nide_df = set_ide_flags(ide_df, 'Q9_Part_2')\nide_df = set_ide_flags(ide_df, 'Q9_Part_3')\nide_df = set_ide_flags(ide_df, 'Q9_Part_4')\nide_df = set_ide_flags(ide_df, 'Q9_Part_5')\nide_df = set_ide_flags(ide_df, 'Q9_Part_6')\nide_df = set_ide_flags(ide_df, 'Q9_Part_7')\nide_df = set_ide_flags(ide_df, 'Q9_Part_8')\nide_df = set_ide_flags(ide_df, 'Q9_Part_9')\nide_df = set_ide_flags(ide_df, 'Q9_Part_10')\nide_df = set_ide_flags(ide_df, 'Q9_Part_11')\nide_df = set_ide_flags(ide_df, 'Q9_OTHER')\n\nide_df = ide_df.melt(id_vars = [\"Q15\"], var_name = \"IDE\", value_name = \"Presence\")\n# Dropping all false presence\nide_df = ide_df[ide_df.Presence == True]\n# Now we don't need the presence col\ndel ide_df['Presence']\n\n\nexp_progdf = ide_df[(ide_df.Q15 == '5-10 years') | (ide_df.Q15 == '10-20 years') | (ide_df.Q15 == '20+ years')]\nprogex_count = exp_progdf.groupby(['IDE']).IDE.agg('count').to_frame('Count').reset_index()\n\nrest_progdf = ide_df[(ide_df.Q15 != '5-10 years') | (ide_df.Q15 != '10-20 years') | (ide_df.Q15 != '20+ years')]\nprogrest_count = rest_progdf.groupby(['IDE']).IDE.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 2, specs = specs, subplot_titles=['(DS & ML)-Experts', 'Rest'])\nfig.add_trace(go.Pie(labels = progex_count.IDE,\n                     scalegroup='two',\n                     values = progex_count.Count,\n                     name=\"Experts\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = progrest_count.IDE,\n                     scalegroup='one',\n                     values = progrest_count.Count,\n                     name=\"Rest\",\n                     marker_colors = px.colors.sequential.Greys),\n              1, 2)\n\nfig.update_traces(hole=.4)\nfig.show()","fd03c1a6":"editor_df = survey20[['Q15', 'Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5', 'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10', 'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13', 'Q10_OTHER']]\n\neditor_dict = {'Q10_Part_1': 'Kaggle',\n            'Q10_Part_2': 'Colab',\n            'Q10_Part_3': 'Azure',\n            'Q10_Part_4': 'Paperspace\/Gradient',\n            'Q10_Part_5': 'Binder\/JupyterHub',\n            'Q10_Part_6': 'Code Ocean',\n            'Q10_Part_7': 'IBM Watson Studio',\n            'Q10_Part_8': 'Amazon Sagemaker Studio',\n            'Q10_Part_9': 'Amazon EMR',\n            'Q10_Part_10': 'Google Cloud AI',\n            'Q10_Part_11': 'Google Cloud Datalab',\n            'Q10_Part_12': 'Databricks Collaborative',\n            'Q10_Part_13': 'None',\n            'Q10_OTHER': 'Other'}\n\ndef set_editor_flags(in_df, col_name):\n    in_df[editor_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\neditor_df\n\neditor_df = set_editor_flags(editor_df, 'Q10_Part_1')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_2')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_3')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_4')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_5')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_6')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_7')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_8')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_9')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_10')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_11')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_12')\neditor_df = set_editor_flags(editor_df, 'Q10_Part_13')\neditor_df = set_editor_flags(editor_df, 'Q10_OTHER')\n\neditor_df = editor_df.melt(id_vars = [\"Q15\"], var_name = \"Editor\", value_name = \"Presence\")\n# Dropping all false presence\neditor_df = editor_df[editor_df.Presence == True]\n# Now we don't need the presence col\ndel editor_df['Presence']\n\n\nexp_progdf = editor_df[(editor_df.Q15 == '5-10 years') | (editor_df.Q15 == '10-20 years') | (editor_df.Q15 == '20+ years')]\nprogex_count = exp_progdf.groupby(['Editor']).Editor.agg('count').to_frame('Count').reset_index()\n\nrest_progdf = editor_df[(editor_df.Q15 != '5-10 years') | (editor_df.Q15 != '10-20 years') | (editor_df.Q15 != '20+ years')]\nprogrest_count = rest_progdf.groupby(['Editor']).Editor.agg('count').to_frame('Count').reset_index()\n\nspecs = [[{'type':'domain'}, {'type':'domain'}]]\n    \nfig = make_subplots(rows = 1, cols = 2, specs = specs, subplot_titles=['(DS & ML)-Experts', 'Rest'])\nfig.add_trace(go.Pie(labels = progex_count.Editor,\n                     scalegroup='two',\n                     values = progex_count.Count,\n                     name=\"Experts\",\n                     marker_colors = px.colors.sequential.YlGnBu),\n              1, 1)\nfig.add_trace(go.Pie(labels = progrest_count.Editor,\n                     scalegroup='one',\n                     values = progrest_count.Count,\n                     name=\"Rest\",\n                     marker_colors = px.colors.sequential.Greys),\n              1, 2)\n\nfig.update_traces(hole=.4)\nfig.show()","bb0818a6":"# Hardware usage\nhw_df = survey20[['Q15', 'Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_OTHER', 'Q13']]\n\nhw_dict = {'Q12_Part_1': 'GPU',\n            'Q12_Part_2': 'TPU',\n            'Q12_Part_3': 'None',\n            'Q12_OTHER': 'Other'}\n\ndef set_hw_flags(in_df, col_name):\n    in_df[hw_dict[col_name]] = ~in_df[col_name].isnull()\n    # delete the original question col since it is redundant now\n    del in_df[col_name]\n    return in_df\n\nhw_df = set_hw_flags(hw_df, 'Q12_Part_1')\nhw_df = set_hw_flags(hw_df, 'Q12_Part_2')\nhw_df = set_hw_flags(hw_df, 'Q12_Part_3')\nhw_df = set_hw_flags(hw_df, 'Q12_OTHER')\n\nhw_df = hw_df.melt(id_vars = [\"Q15\", \"Q13\"], var_name = \"Hardware\", value_name = \"Presence\")\nhw_df = hw_df[hw_df.Presence == True]\ndel hw_df['Presence']\n\nhw_df = hw_df[hw_df.Hardware != 'None']\n\n# Used TPUs? (I've got a feeling that they did!)\n# Too much coffee! Can't wait for answer\nhw_df.loc[(hw_df.Hardware != 'TPU'), 'Q13'] = 'NA'\n\nhw_df = hw_df[(hw_df.Q15 == '5-10 years') | (hw_df.Q15 == '10-20 years') | (hw_df.Q15 == '20+ years')]\nfig_hw_exp = px.treemap(hw_df,\n                        path=['Q15', 'Hardware', 'Q13'],\n                        color='Hardware',\n                        color_discrete_sequence = px.colors.sequential.YlGnBu)\nfig_hw_exp.show()\n","3033f07b":"# Whatchu Got?\n\nvis_df = survey20[['Q15', 'Q14_Part_1', 'Q14_Part_2', 'Q14_Part_3', 'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6', 'Q14_Part_7', 'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11', 'Q14_OTHER']]\n\nvis_dict = {'Q14_Part_1': 'Matplotlib',\n            'Q14_Part_2': 'Seaborn',\n            'Q14_Part_3': 'Plotly \/ Plotly Express',\n            'Q14_Part_4': 'Ggplot \/ ggplot2',\n            'Q14_Part_5': 'Shiny',\n            'Q14_Part_6': 'D3 js',\n            'Q14_Part_7': 'Altair',\n            'Q14_Part_8': 'Bokeh',\n            'Q14_Part_9': 'Geoplotlib',\n            'Q14_Part_10': 'Leaflet \/ Folium',\n            'Q14_Part_11': 'None',\n            'Q14_OTHER': 'Other'}\n\ndef set_vis_flags(in_df, col_name):\n    in_df[vis_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nvis_df = set_vis_flags(vis_df, 'Q14_Part_1')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_2')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_3')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_4')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_5')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_6')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_7')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_8')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_9')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_10')\nvis_df = set_vis_flags(vis_df, 'Q14_Part_11')\nvis_df = set_vis_flags(vis_df, 'Q14_OTHER')\n\nvis_df = vis_df.melt(id_vars = [\"Q15\"], var_name = \"Visualization\", value_name = \"Presence\")\nvis_df = vis_df[vis_df.Presence == True]\ndel vis_df['Presence']\n\nvis_df = vis_df[(vis_df.Q15 == '5-10 years') | (vis_df.Q15 == '10-20 years') | (vis_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(vis_df, x=\"Visualization\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","de3afad9":"fwk_df = survey20[['Q15', 'Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9', 'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13', 'Q16_Part_14', 'Q16_Part_15', 'Q16_OTHER']]\n\nfwk_dict = {'Q16_Part_1': 'Scikit-learn',\n            'Q16_Part_2': 'TensorFlow',\n            'Q16_Part_3': 'Keras',\n            'Q16_Part_4': 'PyTorch',\n            'Q16_Part_5': 'Fast.ai',\n            'Q16_Part_6': 'MXNet',\n            'Q16_Part_7': 'Xgboost',\n            'Q16_Part_8': 'LightGBM',\n            'Q16_Part_9': 'CatBoost',\n            'Q16_Part_10': 'Prophet',\n            'Q16_Part_11': 'H2O 3',\n            'Q16_Part_12': 'Caret',\n            'Q16_Part_13': 'Tidymodels',\n            'Q16_Part_14': 'JAX',\n            'Q16_Part_15': 'None',\n            'Q16_OTHER': 'Other'}\n\ndef set_fwk_flags(in_df, col_name):\n    in_df[fwk_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_1')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_2')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_3')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_4')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_5')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_6')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_7')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_8')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_9')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_10')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_11')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_12')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_13')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_14')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_Part_15')\nfwk_df = set_fwk_flags(fwk_df, 'Q16_OTHER')\n\nfwk_df = fwk_df.melt(id_vars = [\"Q15\"], var_name = \"ML Framework\", value_name = \"Presence\")\nfwk_df = fwk_df[fwk_df.Presence == True]\ndel fwk_df['Presence']\n\nfwk_df = fwk_df[(fwk_df.Q15 == '5-10 years') | (fwk_df.Q15 == '10-20 years') | (fwk_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(fwk_df, x=\"ML Framework\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","f6019cfa":"algo_df = survey20[['Q15', 'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']]\n\nfwk_dict = {'Q17_Part_1': 'Linear or Logistic Regression',\n            'Q17_Part_2': 'Decision Trees\/Random Forests',\n            'Q17_Part_3': 'Gradient Boosting Machines',\n            'Q17_Part_4': 'Bayesian Approaches',\n            'Q17_Part_5': 'Evolutionary Approaches',\n            'Q17_Part_6': 'Dense Neural Networks',\n            'Q17_Part_7': 'Convolutional Neural Networks',\n            'Q17_Part_8': 'Generative Adversarial Networks',\n            'Q17_Part_9': 'Recurrent Neural Networks',\n            'Q17_Part_10': 'Transformer Networks',\n            'Q17_Part_11': 'None',\n            'Q17_OTHER': 'Other'}\n\ndef set_algo_flags(in_df, col_name):\n    in_df[fwk_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_1')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_2')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_3')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_4')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_5')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_6')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_7')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_8')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_9')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_10')\nalgo_df = set_algo_flags(algo_df, 'Q17_Part_11')\nalgo_df = set_algo_flags(algo_df, 'Q17_OTHER')\n\nalgo_df = algo_df.melt(id_vars = [\"Q15\"], var_name = \"ML Algorithm\", value_name = \"Presence\")\nalgo_df = algo_df[algo_df.Presence == True]\ndel algo_df['Presence']\n\nalgo_df = algo_df[(algo_df.Q15 == '5-10 years') | (algo_df.Q15 == '10-20 years') | (algo_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(algo_df, x=\"ML Algorithm\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","f95c5fb2":"algo_df = survey20[['Q15', 'Q18_Part_1', 'Q18_Part_2', 'Q18_Part_3', 'Q18_Part_4', 'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER']]\n\nalg_dict = {'Q18_Part_1': 'General purpose image\/video tools',\n            'Q18_Part_2': 'Image segmentation',\n            'Q18_Part_3': 'Object detection',\n            'Q18_Part_4': 'Image classification',\n            'Q18_Part_5': 'Generative Networks',\n            'Q18_Part_6': 'None',\n            'Q18_OTHER': 'Other'}\n\ndef set_algo_flags(in_df, col_name):\n    in_df[alg_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_1')\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_2')\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_3')\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_4')\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_5')\nalgo_df = set_algo_flags(algo_df, 'Q18_Part_6')\nalgo_df = set_algo_flags(algo_df, 'Q18_OTHER')\n\nalgo_df = algo_df.melt(id_vars = [\"Q15\"], var_name = \"Computer Vision\", value_name = \"Presence\")\nalgo_df = algo_df[algo_df.Presence == True]\ndel algo_df['Presence']\n\nalgo_df = algo_df[(algo_df.Q15 == '5-10 years') | (algo_df.Q15 == '10-20 years') | (algo_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(algo_df, x=\"Computer Vision\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","5bc4d215":"nlp_df = survey20[['Q15', 'Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4', 'Q19_Part_5', 'Q19_OTHER']]\n\nnlp_dict = {'Q19_Part_1': 'Word embeddings\/vectors',\n            'Q19_Part_2': 'Encoder-decoder models',\n            'Q19_Part_3': 'Contextualized embeddings ',\n            'Q19_Part_4': 'Transformer language model',\n            'Q19_Part_5': 'None',\n            'Q19_OTHER': 'Other'}\n\ndef set_nlp_flags(in_df, col_name):\n    in_df[nlp_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nnlp_df = set_nlp_flags(nlp_df, 'Q19_Part_1')\nnlp_df = set_nlp_flags(nlp_df, 'Q19_Part_2')\nnlp_df = set_nlp_flags(nlp_df, 'Q19_Part_3')\nnlp_df = set_nlp_flags(nlp_df, 'Q19_Part_4')\nnlp_df = set_nlp_flags(nlp_df, 'Q19_Part_5')\nnlp_df = set_nlp_flags(nlp_df, 'Q19_OTHER')\n\nnlp_df = nlp_df.melt(id_vars = [\"Q15\"], var_name = \"NLP Methods\", value_name = \"Presence\")\nnlp_df = nlp_df[nlp_df.Presence == True]\ndel nlp_df['Presence']\n\nnlp_df = nlp_df[(nlp_df.Q15 == '5-10 years') | (nlp_df.Q15 == '10-20 years') | (nlp_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(nlp_df, x=\"NLP Methods\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","028969f6":"clhave_df = survey20[['Q15', 'Q26_A_Part_1', 'Q26_A_Part_2', 'Q26_A_Part_3', 'Q26_A_Part_4', 'Q26_A_Part_5', 'Q26_A_Part_6', 'Q26_A_Part_7', 'Q26_A_Part_8', 'Q26_A_Part_9', 'Q26_A_Part_10', 'Q26_A_Part_11', 'Q26_A_OTHER']]\nclwant_df = survey20[['Q15', 'Q26_B_Part_1', 'Q26_B_Part_2', 'Q26_B_Part_3', 'Q26_B_Part_4', 'Q26_B_Part_5', 'Q26_B_Part_6', 'Q26_B_Part_7', 'Q26_B_Part_8', 'Q26_B_Part_9', 'Q26_B_Part_10', 'Q26_B_Part_11', 'Q26_B_OTHER']]\n\nclcomp_dict = {'Q26_A_Part_1': 'AWS',\n               'Q26_B_Part_1': 'AWS',\n               'Q26_A_Part_2': 'Azure',\n               'Q26_B_Part_2': 'Azure',\n               'Q26_A_Part_3': 'GCP',\n               'Q26_B_Part_3': 'GCP',\n               'Q26_A_Part_4': 'IBM Cloud\/Red Hat',\n               'Q26_B_Part_4': 'IBM Cloud\/Red Hat',\n               'Q26_A_Part_5': 'Oracle Cloud',\n               'Q26_B_Part_5': 'Oracle Cloud',\n               'Q26_A_Part_6': 'SAP Cloud',\n               'Q26_B_Part_6': 'SAP Cloud',\n               'Q26_A_Part_7': 'Salesforce Cloud',\n               'Q26_B_Part_7': 'Salesforce Cloud',\n               'Q26_A_Part_8': 'VMware Cloud',\n               'Q26_B_Part_8': 'VMware Cloud',\n               'Q26_A_Part_9': 'Alibaba Cloud ',\n               'Q26_B_Part_9': 'Alibaba Cloud ',\n               'Q26_A_Part_10': 'Tencent Cloud',\n               'Q26_B_Part_10': 'Tencent Cloud',\n               'Q26_A_Part_11': 'None',\n               'Q26_B_Part_11': 'None',\n               'Q26_A_OTHER': 'Other',\n               'Q26_B_OTHER': 'Other'}\n\ndef set_clcomp_flags(in_df, col_name):\n    in_df[clcomp_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_1')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_2')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_3')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_4')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_5')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_6')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_7')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_8')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_9')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_10')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_Part_11')\nclhave_df = set_clcomp_flags(clhave_df, 'Q26_A_OTHER')\n\nclhave_df = clhave_df.melt(id_vars = [\"Q15\"], var_name = \"Cloud Computing Platform\", value_name = \"Presence\")\nclhave_df = clhave_df[clhave_df.Presence == True]\ndel clhave_df['Presence']\nclhave_df = clhave_df[(clhave_df.Q15 == '5-10 years') | (clhave_df.Q15 == '10-20 years') | (clhave_df.Q15 == '20+ years')]\n\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_1')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_2')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_3')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_4')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_5')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_6')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_7')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_8')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_9')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_10')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_Part_11')\nclwant_df = set_clcomp_flags(clwant_df, 'Q26_B_OTHER')\n\nclwant_df = clwant_df.melt(id_vars = [\"Q15\"], var_name = \"Cloud Computing Platform\", value_name = \"Presence\")\nclwant_df = clwant_df[clwant_df.Presence == True]\ndel clwant_df['Presence']\nclwant_df = clwant_df[(clwant_df.Q15 == '5-10 years') | (clwant_df.Q15 == '10-20 years') | (clwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['Cloud Computing Platform- Have', 'Cloud Computing Platform- Want'])\nfig.add_trace(go.Histogram2d(x = clhave_df['Cloud Computing Platform'].values, y = clhave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = clwant_df['Cloud Computing Platform'].values, y = clwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()","21043b8c":"cphave_df = survey20[['Q15', 'Q27_A_Part_1', 'Q27_A_Part_2', 'Q27_A_Part_3', 'Q27_A_Part_4', 'Q27_A_Part_5', 'Q27_A_Part_6', 'Q27_A_Part_7', 'Q27_A_Part_8', 'Q27_A_Part_9', 'Q27_A_Part_10', 'Q27_A_Part_11', 'Q27_A_OTHER']]\ncpwant_df = survey20[['Q15', 'Q27_B_Part_1', 'Q27_B_Part_2', 'Q27_B_Part_3', 'Q27_B_Part_4', 'Q27_B_Part_5', 'Q27_B_Part_6', 'Q27_B_Part_7', 'Q27_B_Part_8', 'Q27_B_Part_9', 'Q27_B_Part_10', 'Q27_B_Part_11', 'Q27_B_OTHER']]\n\nclcomp_dict = {'Q27_A_Part_1': 'Amazon EC2',\n               'Q27_B_Part_1': 'Amazon EC2',\n               'Q27_A_Part_2': 'AWS Lambda',\n               'Q27_B_Part_2': 'AWS Lambda',\n               'Q27_A_Part_3': 'Amazon Elastic',\n               'Q27_B_Part_3': 'Amazon Elastic',\n               'Q27_A_Part_4': 'Azure Cloud Services',\n               'Q27_B_Part_4': 'Azure Cloud Services',\n               'Q27_A_Part_5': 'Microsoft Azure Container Instances',\n               'Q27_B_Part_5': 'Microsoft Azure Container Instances',\n               'Q27_A_Part_6': 'Azure Functions',\n               'Q27_B_Part_6': 'Azure Functions',\n               'Q27_A_Part_7': 'Google Cloud Compute Engine',\n               'Q27_B_Part_7': 'Google Cloud Compute Engine',\n               'Q27_A_Part_8': 'Google Cloud Functions',\n               'Q27_B_Part_8': 'Google Cloud Functions',\n               'Q27_A_Part_9': 'Google Cloud Run',\n               'Q27_B_Part_9': 'Google Cloud Run',\n               'Q27_A_Part_10': 'Google Cloud App Engine',\n               'Q27_B_Part_10': 'Google Cloud App Engine',\n               'Q27_A_Part_11': 'None',\n               'Q27_B_Part_11': 'None',\n               'Q27_A_OTHER': 'Other',\n               'Q27_B_OTHER': 'Other'}\n\ndef set_clprod_flags(in_df, col_name):\n    in_df[clcomp_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_1')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_2')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_3')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_4')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_5')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_6')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_7')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_8')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_9')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_10')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_Part_11')\ncphave_df = set_clprod_flags(cphave_df, 'Q27_A_OTHER')\n\ncphave_df = cphave_df.melt(id_vars = [\"Q15\"], var_name = \"Cloud Computing Product\", value_name = \"Presence\")\ncphave_df = cphave_df[cphave_df.Presence == True]\ndel cphave_df['Presence']\ncphave_df = cphave_df[(cphave_df.Q15 == '5-10 years') | (cphave_df.Q15 == '10-20 years') | (cphave_df.Q15 == '20+ years')]\n\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_1')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_2')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_3')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_4')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_5')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_6')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_7')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_8')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_9')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_10')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_Part_11')\ncpwant_df = set_clprod_flags(cpwant_df, 'Q27_B_OTHER')\n\ncpwant_df = cpwant_df.melt(id_vars = [\"Q15\"], var_name = \"Cloud Computing Product\", value_name = \"Presence\")\ncpwant_df = cpwant_df[cpwant_df.Presence == True]\ndel cpwant_df['Presence']\ncpwant_df = cpwant_df[(cpwant_df.Q15 == '5-10 years') | (cpwant_df.Q15 == '10-20 years') | (cpwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['Cloud Computing Product- Have', 'Cloud Computing Product- Want'])\nfig.add_trace(go.Histogram2d(x = cphave_df['Cloud Computing Product'].values, y = cphave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = cpwant_df['Cloud Computing Product'].values, y = cpwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()\n","7e763807":"mlphave_df = survey20[['Q15', 'Q28_A_Part_1', 'Q28_A_Part_2', 'Q28_A_Part_3', 'Q28_A_Part_4', 'Q28_A_Part_5', 'Q28_A_Part_6', 'Q28_A_Part_7', 'Q28_A_Part_8', 'Q28_A_Part_9', 'Q28_A_Part_10', 'Q28_A_OTHER']]\nmlpwant_df = survey20[['Q15', 'Q28_B_Part_1', 'Q28_B_Part_2', 'Q28_B_Part_3', 'Q28_B_Part_4', 'Q28_B_Part_5', 'Q28_B_Part_6', 'Q28_B_Part_7', 'Q28_B_Part_8', 'Q28_B_Part_9', 'Q28_B_Part_10', 'Q28_B_OTHER']]\n\nmlp_dict = {'Q28_A_Part_1': 'Amazon SageMaker',\n               'Q28_B_Part_1': 'Amazon SageMaker',\n               'Q28_A_Part_2': 'Amazon Forecast',\n               'Q28_B_Part_2': 'Amazon Forecast',\n               'Q28_A_Part_3': 'Amazon Elastic',\n               'Q28_B_Part_3': 'Amazon Elastic',\n               'Q28_A_Part_4': 'Amazon Rekognition',\n               'Q28_B_Part_4': 'Amazon Rekognition',\n               'Q28_A_Part_5': 'Microsoft Azure Container Instances',\n               'Q28_B_Part_5': 'Microsoft Azure Container Instances',\n               'Q28_A_Part_6': 'Google Cloud (AI Platform\/ML Engine)',\n               'Q28_B_Part_6': 'Google Cloud (AI Platform\/ML Engine)',\n               'Q28_A_Part_7': 'Google Cloud Video AI',\n               'Q28_B_Part_7': 'Google Cloud Video AI',\n               'Q28_A_Part_8': 'Google Cloud Natural Language',\n               'Q28_B_Part_8': 'Google Cloud Natural Language',\n               'Q28_A_Part_9': 'Google Cloud Vision AI',\n               'Q28_B_Part_9': 'Google Cloud Vision AI',\n               'Q28_A_Part_10': 'None',\n               'Q28_B_Part_10': 'None',\n               'Q28_A_OTHER': 'Other',\n               'Q28_B_OTHER': 'Other'}\n\ndef set_mlp_flags(in_df, col_name):\n    in_df[mlp_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_1')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_2')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_3')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_4')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_5')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_6')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_7')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_8')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_9')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_Part_10')\nmlphave_df = set_mlp_flags(mlphave_df, 'Q28_A_OTHER')\n\nmlphave_df = mlphave_df.melt(id_vars = [\"Q15\"], var_name = \"ML Product\", value_name = \"Presence\")\nmlphave_df = mlphave_df[mlphave_df.Presence == True]\ndel mlphave_df['Presence']\nmlphave_df = mlphave_df[(mlphave_df.Q15 == '5-10 years') | (mlphave_df.Q15 == '10-20 years') | (mlphave_df.Q15 == '20+ years')]\n\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_1')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_2')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_3')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_4')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_5')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_6')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_7')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_8')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_9')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_Part_10')\nmlpwant_df = set_mlp_flags(mlpwant_df, 'Q28_B_OTHER')\n\nmlpwant_df = mlpwant_df.melt(id_vars = [\"Q15\"], var_name = \"ML Product\", value_name = \"Presence\")\nmlpwant_df = mlpwant_df[mlpwant_df.Presence == True]\ndel mlpwant_df['Presence']\nmlpwant_df = mlpwant_df[(mlpwant_df.Q15 == '5-10 years') | (mlpwant_df.Q15 == '10-20 years') | (mlpwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['ML Product- Have', 'ML Product- Want'])\nfig.add_trace(go.Histogram2d(x = mlphave_df['ML Product'].values, y = mlphave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = mlpwant_df['ML Product'].values, y = mlpwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()\n","a886db44":"bdhave_df = survey20[['Q15', 'Q29_A_Part_1', 'Q29_A_Part_2', 'Q29_A_Part_3', 'Q29_A_Part_4', 'Q29_A_Part_5', 'Q29_A_Part_6', 'Q29_A_Part_7', 'Q29_A_Part_8', 'Q29_A_Part_9', 'Q29_A_Part_10', 'Q29_A_Part_11', 'Q29_A_Part_12', 'Q29_A_Part_13', 'Q29_A_Part_14', 'Q29_A_Part_15', 'Q29_A_Part_16', 'Q29_A_Part_17', 'Q29_A_OTHER']]\nbdwant_df = survey20[['Q15', 'Q29_B_Part_1', 'Q29_B_Part_2', 'Q29_B_Part_3', 'Q29_B_Part_4', 'Q29_B_Part_5', 'Q29_B_Part_6', 'Q29_B_Part_7', 'Q29_B_Part_8', 'Q29_B_Part_9', 'Q29_B_Part_10', 'Q29_B_Part_11', 'Q29_B_Part_12', 'Q29_B_Part_13', 'Q29_B_Part_14', 'Q29_B_Part_15', 'Q29_B_Part_16', 'Q29_B_Part_17', 'Q29_B_OTHER']]\n\nbd_dict = {'Q29_A_Part_1': 'MySQL',\n           'Q29_B_Part_1': 'MySQL',\n           'Q29_A_Part_2': 'PostgresSQL',\n           'Q29_B_Part_2': 'PostgresSQL',\n           'Q29_A_Part_3': 'SQLite',\n           'Q29_B_Part_3': 'SQLite',\n           'Q29_A_Part_4': 'Oracle Database',\n           'Q29_B_Part_4': 'Oracle Database',\n           'Q29_A_Part_5': 'MongoDB',\n           'Q29_B_Part_5': 'MongoDB',\n           'Q29_A_Part_6': 'Snowflake',\n           'Q29_B_Part_6': 'Snowflake',\n           'Q29_A_Part_7': 'IBM Db2',\n           'Q29_B_Part_7': 'IBM Db2',\n           'Q29_A_Part_8': 'Microsoft SQL Server',\n           'Q29_B_Part_8': 'Microsoft SQL Server',\n           'Q29_A_Part_9': 'Microsoft Access',\n           'Q29_B_Part_9': 'Microsoft Access',\n           'Q29_A_Part_10': 'Microsoft Azure Data Lake Storage',\n           'Q29_B_Part_10': 'Microsoft Azure Data Lake Storage',\n           'Q29_A_Part_11': 'Amazon Redshift',\n           'Q29_B_Part_11': 'Amazon Redshift',\n           'Q29_A_Part_12': 'Amazon Athena',\n           'Q29_B_Part_12': 'Amazon Athena',\n           'Q29_A_Part_13': 'Amazon DynamoDB',\n           'Q29_B_Part_13': 'Amazon DynamoDB',\n           'Q29_A_Part_14': 'Google Cloud BigQuery',\n           'Q29_B_Part_14': 'Google Cloud BigQuery',\n           'Q29_A_Part_15': 'Google Cloud SQL',\n           'Q29_B_Part_15': 'Google Cloud SQL',\n           'Q29_A_Part_16': 'Google Cloud Firestore',\n           'Q29_B_Part_16': 'Google Cloud Firestore',\n           'Q29_A_Part_17': 'None',\n           'Q29_B_Part_17': 'None',\n           'Q29_A_OTHER': 'Other',\n           'Q29_B_OTHER': 'Other'}\n\ndef set_mlp_flags(in_df, col_name):\n    in_df[bd_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_1')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_2')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_3')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_4')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_5')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_6')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_7')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_8')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_9')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_Part_10')\nbdhave_df = set_mlp_flags(bdhave_df, 'Q29_A_OTHER')\n\nbdhave_df = bdhave_df.melt(id_vars = [\"Q15\"], var_name = \"Big Data Product\", value_name = \"Presence\")\nbdhave_df = bdhave_df[bdhave_df.Presence == True]\ndel bdhave_df['Presence']\nbdhave_df = bdhave_df[(bdhave_df.Q15 == '5-10 years') | (bdhave_df.Q15 == '10-20 years') | (bdhave_df.Q15 == '20+ years')]\n\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_1')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_2')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_3')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_4')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_5')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_6')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_7')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_8')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_9')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_Part_10')\nbdwant_df = set_mlp_flags(bdwant_df, 'Q29_B_OTHER')\n\nbdwant_df = bdwant_df.melt(id_vars = [\"Q15\"], var_name = \"Big Data Product\", value_name = \"Presence\")\nbdwant_df = bdwant_df[bdwant_df.Presence == True]\ndel bdwant_df['Presence']\nbdwant_df = bdwant_df[(bdwant_df.Q15 == '5-10 years') | (bdwant_df.Q15 == '10-20 years') | (bdwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['Big Data Product- Have', 'Big Data Product- Want'])\nfig.add_trace(go.Histogram2d(x = bdhave_df['Big Data Product'].values, y = bdhave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = bdwant_df['Big Data Product'].values, y = bdwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()\n","325d17d4":"bihave_df = survey20[['Q15', 'Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4', 'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8', 'Q31_A_Part_9', 'Q31_A_Part_10', 'Q31_A_Part_11', 'Q31_A_Part_12', 'Q31_A_Part_13', 'Q31_A_Part_14', 'Q31_A_OTHER']]\nbiwant_df = survey20[['Q15', 'Q31_B_Part_1', 'Q31_B_Part_2', 'Q31_B_Part_3', 'Q31_B_Part_4', 'Q31_B_Part_5', 'Q31_B_Part_6', 'Q31_B_Part_7', 'Q31_B_Part_8', 'Q31_B_Part_9', 'Q31_B_Part_10', 'Q31_B_Part_11', 'Q31_B_Part_12', 'Q31_B_Part_13', 'Q31_B_Part_14', 'Q31_B_OTHER']]\n\nbi_dict = {'Q31_A_Part_1': 'Microsoft Power BI',\n           'Q31_B_Part_1': 'Microsoft Power BI',\n           'Q31_A_Part_2': 'Amazon QuickSight',\n           'Q31_B_Part_2': 'Amazon QuickSight',\n           'Q31_A_Part_3': 'Google Data Studio',\n           'Q31_B_Part_3': 'Google Data Studio',\n           'Q31_A_Part_4': 'Looker',\n           'Q31_B_Part_4': 'Looker',\n           'Q31_A_Part_5': 'Tableau',\n           'Q31_B_Part_5': 'Tableau',\n           'Q31_A_Part_6': 'Salesforce',\n           'Q31_B_Part_6': 'Salesforce',\n           'Q31_A_Part_7': 'Einstein Analytics',\n           'Q31_B_Part_7': 'Einstein Analytics',\n           'Q31_A_Part_8': 'Qlik',\n           'Q31_B_Part_8': 'Qlik',\n           'Q31_A_Part_9': 'Domo',\n           'Q31_B_Part_9': 'Domo',\n           'Q31_A_Part_10': 'TIBCO Spotfire',\n           'Q31_B_Part_10': 'TIBCO Spotfire',\n           'Q31_A_Part_11': 'Alteryx',\n           'Q31_B_Part_11': 'Alteryx',\n           'Q31_A_Part_12': 'Sisense',\n           'Q31_B_Part_12': 'Sisense',\n           'Q31_A_Part_13': 'SAP Analytics Cloud',\n           'Q31_B_Part_13': 'SAP Analytics Cloud',\n           'Q31_A_Part_14': 'None',\n           'Q31_B_Part_14': 'None',\n           'Q31_A_OTHER': 'Other',\n           'Q31_B_OTHER': 'Other'}\n\ndef set_bi_flags(in_df, col_name):\n    in_df[bi_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_1')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_2')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_3')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_4')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_5')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_6')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_7')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_8')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_9')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_Part_10')\nbihave_df = set_bi_flags(bihave_df, 'Q31_A_OTHER')\n\nbihave_df = bihave_df.melt(id_vars = [\"Q15\"], var_name = \"Business Intelligence\", value_name = \"Presence\")\nbihave_df = bihave_df[bihave_df.Presence == True]\ndel bihave_df['Presence']\nbihave_df = bihave_df[(bihave_df.Q15 == '5-10 years') | (bihave_df.Q15 == '10-20 years') | (bihave_df.Q15 == '20+ years')]\n\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_1')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_2')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_3')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_4')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_5')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_6')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_7')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_8')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_9')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_Part_10')\nbiwant_df = set_bi_flags(biwant_df, 'Q31_B_OTHER')\n\nbiwant_df = biwant_df.melt(id_vars = [\"Q15\"], var_name = \"Business Intelligence\", value_name = \"Presence\")\nbiwant_df = biwant_df[biwant_df.Presence == True]\ndel biwant_df['Presence']\nbiwant_df = biwant_df[(biwant_df.Q15 == '5-10 years') | (biwant_df.Q15 == '10-20 years') | (biwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['Business Intelligence- Have', 'Business Intelligence- Want'])\nfig.add_trace(go.Histogram2d(x = bihave_df['Business Intelligence'].values, y = bihave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = biwant_df['Business Intelligence'].values, y = biwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()\n","11e536a1":"autohave_df = survey20[['Q15', 'Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4', 'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8', 'Q34_A_Part_9', 'Q34_A_Part_10', 'Q34_A_Part_11', 'Q34_A_OTHER']]\nautowant_df = survey20[['Q15', 'Q34_B_Part_1', 'Q34_B_Part_2', 'Q34_B_Part_3', 'Q34_B_Part_4', 'Q34_B_Part_5', 'Q34_B_Part_6', 'Q34_B_Part_7', 'Q34_B_Part_8', 'Q34_B_Part_9', 'Q34_B_Part_10', 'Q34_B_Part_11', 'Q34_B_OTHER']]\n\nauto_dict = {'Q34_A_Part_1': 'Google Cloud AutoML',\n             'Q34_B_Part_1': 'Google Cloud AutoML',\n           'Q34_A_Part_2': 'H20 Driverless AI',\n           'Q34_B_Part_2': 'H20 Driverless AI',\n           'Q34_A_Part_3': 'Databricks AutoML',\n           'Q34_B_Part_3': 'Databricks AutoML',\n           'Q34_A_Part_4': 'DataRobot AutoML',\n           'Q34_B_Part_4': 'DataRobot AutoML',\n           'Q34_A_Part_5': 'Tpot',\n           'Q34_B_Part_5': 'Tpot',\n           'Q34_A_Part_6': 'Auto-Keras',\n           'Q34_B_Part_6': 'Auto-Keras',\n           'Q34_A_Part_7': 'Auto-Sklearn',\n           'Q34_B_Part_7': 'Auto-Sklearn',\n           'Q34_A_Part_8': 'Auto_ml',\n           'Q34_B_Part_8': 'Auto_ml',\n           'Q34_A_Part_9': 'Xcessiv',\n           'Q34_B_Part_9': 'Xcessiv',\n           'Q34_A_Part_10': 'MLbox',\n           'Q34_B_Part_10': 'MLbox',\n           'Q34_A_Part_11': 'None',\n           'Q34_B_Part_11': 'None',\n           'Q34_A_OTHER': 'Other',\n           'Q34_B_OTHER': 'Other'}\n\ndef set_auto_flags(in_df, col_name):\n    in_df[auto_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_1')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_2')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_3')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_4')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_5')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_6')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_7')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_8')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_9')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_Part_10')\nautohave_df = set_auto_flags(autohave_df, 'Q34_A_OTHER')\n\nautohave_df = autohave_df.melt(id_vars = [\"Q15\"], var_name = \"Auto ML\", value_name = \"Presence\")\nautohave_df = autohave_df[autohave_df.Presence == True]\ndel autohave_df['Presence']\nautohave_df = autohave_df[(autohave_df.Q15 == '5-10 years') | (autohave_df.Q15 == '10-20 years') | (autohave_df.Q15 == '20+ years')]\n\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_1')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_2')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_3')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_4')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_5')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_6')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_7')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_8')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_9')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_Part_10')\nautowant_df = set_auto_flags(autowant_df, 'Q34_B_OTHER')\n\nautowant_df = autowant_df.melt(id_vars = [\"Q15\"], var_name = \"Auto ML\", value_name = \"Presence\")\nautowant_df = autowant_df[autowant_df.Presence == True]\ndel autowant_df['Presence']\nautowant_df = autowant_df[(autowant_df.Q15 == '5-10 years') | (autowant_df.Q15 == '10-20 years') | (autowant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['Auto ML- Have', 'Auto ML- Want'])\nfig.add_trace(go.Histogram2d(x = autohave_df['Auto ML'].values, y = autohave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = autowant_df['Auto ML'].values, y = autowant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()\n","173091f5":"mgmlhave_df = survey20[['Q15', 'Q35_A_Part_1', 'Q35_A_Part_2', 'Q35_A_Part_3', 'Q35_A_Part_4', 'Q35_A_Part_5', 'Q35_A_Part_6', 'Q35_A_Part_7', 'Q35_A_Part_8', 'Q35_A_Part_9', 'Q35_A_Part_10', 'Q35_A_OTHER']]\nmgmlwant_df = survey20[['Q15', 'Q35_B_Part_1', 'Q35_B_Part_2', 'Q35_B_Part_3', 'Q35_B_Part_4', 'Q35_B_Part_5', 'Q35_B_Part_6', 'Q35_B_Part_7', 'Q35_B_Part_8', 'Q35_B_Part_9', 'Q35_B_Part_10', 'Q35_B_OTHER']]\n\nmgml_dict = {'Q35_A_Part_1': 'Neptune.ai',\n             'Q35_B_Part_1': 'Neptune.ai',\n           'Q35_A_Part_2': 'Weights & Biases',\n           'Q35_B_Part_2': 'Weights & Biases',\n           'Q35_A_Part_3': 'Comet.ml',\n           'Q35_B_Part_3': 'Comet.ml',\n           'Q35_A_Part_4': 'Sacred + Omniboard',\n           'Q35_B_Part_4': 'Sacred + Omniboard',\n           'Q35_A_Part_5': 'TensorBoard',\n           'Q35_B_Part_5': 'TensorBoard',\n           'Q35_A_Part_6': 'Guild.ai',\n           'Q35_B_Part_6': 'Guild.ai',\n           'Q35_A_Part_7': 'Polyaxon',\n           'Q35_B_Part_7': 'Polyaxon',\n           'Q35_A_Part_8': 'Trains',\n           'Q35_B_Part_8': 'Trains',\n           'Q35_A_Part_9': 'Domino Model Monitor',\n           'Q35_B_Part_9': 'Domino Model Monitor',\n           'Q35_A_Part_10': 'None',\n           'Q35_B_Part_10': 'None',\n           'Q35_A_OTHER': 'Other',\n           'Q35_B_OTHER': 'Other'}\n\ndef set_mgml_flags(in_df, col_name):\n    in_df[mgml_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_1')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_2')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_3')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_4')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_5')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_6')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_7')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_8')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_9')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_Part_10')\nmgmlhave_df = set_mgml_flags(mgmlhave_df, 'Q35_A_OTHER')\n\nmgmlhave_df = mgmlhave_df.melt(id_vars = [\"Q15\"], var_name = \"ML Mgmt\", value_name = \"Presence\")\nmgmlhave_df = mgmlhave_df[mgmlhave_df.Presence == True]\ndel mgmlhave_df['Presence']\nmgmlhave_df = mgmlhave_df[(mgmlhave_df.Q15 == '5-10 years') | (mgmlhave_df.Q15 == '10-20 years') | (mgmlhave_df.Q15 == '20+ years')]\n\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_1')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_2')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_3')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_4')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_5')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_6')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_7')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_8')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_9')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_Part_10')\nmgmlwant_df = set_mgml_flags(mgmlwant_df, 'Q35_B_OTHER')\n\nmgmlwant_df = mgmlwant_df.melt(id_vars = [\"Q15\"], var_name = \"ML Mgmt\", value_name = \"Presence\")\nmgmlwant_df = mgmlwant_df[mgmlwant_df.Presence == True]\ndel mgmlwant_df['Presence']\nmgmlwant_df = mgmlwant_df[(mgmlwant_df.Q15 == '5-10 years') | (mgmlwant_df.Q15 == '10-20 years') | (mgmlwant_df.Q15 == '20+ years')]\n\nfig = make_subplots(2,1, subplot_titles=['ML Mgmt- Have', 'ML Mgmt- Want'])\nfig.add_trace(go.Histogram2d(x = mgmlhave_df['ML Mgmt'].values, y = mgmlhave_df['Q15'].values, colorscale = \"YlGnBu\"), 1, 1)\nfig.add_trace(go.Histogram2d(x = mgmlwant_df['ML Mgmt'].values, y = mgmlwant_df['Q15'].values, colorscale = \"YlGnBu\"), 2, 1)\nfig.show()","9152289e":"soc_df = survey20[['Q15', 'Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3', 'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6', 'Q39_Part_7', 'Q39_Part_8', 'Q39_Part_9', 'Q39_Part_10', 'Q39_Part_11', 'Q39_OTHER']]\n\nnlp_dict = {'Q39_Part_1': 'Twitter',\n            'Q39_Part_2': 'Email newsletters',\n            'Q39_Part_3': 'Reddit ',\n            'Q39_Part_4': 'Kaggle',\n            'Q39_Part_5': 'Course Forums',\n            'Q39_Part_6': 'YouTube',\n            'Q39_Part_7': 'Podcasts',\n            'Q39_Part_8': 'Blogs',\n            'Q39_Part_9': 'Journal Publications',\n            'Q39_Part_10': 'Slack Communities',\n            'Q39_Part_11': 'None',\n            'Q39_OTHER': 'Other'}\n\ndef set_soc_flags(in_df, col_name):\n    in_df[nlp_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_1')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_2')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_3')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_4')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_5')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_6')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_7')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_8')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_9')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_10')\nsoc_df = set_soc_flags(soc_df, 'Q39_Part_11')\nsoc_df = set_soc_flags(soc_df, 'Q39_OTHER')\n\nsoc_df = soc_df.melt(id_vars = [\"Q15\"], var_name = \"Social Platforms\", value_name = \"Presence\")\nsoc_df = soc_df[soc_df.Presence == True]\ndel soc_df['Presence']\n\nsoc_df = soc_df[(soc_df.Q15 == '5-10 years') | (soc_df.Q15 == '10-20 years') | (soc_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(soc_df, x=\"Social Platforms\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","a8699f1a":"course_df = survey20[['Q15', 'Q37_Part_1', 'Q37_Part_2', 'Q37_Part_3', 'Q37_Part_4', 'Q37_Part_5', 'Q37_Part_6', 'Q37_Part_7', 'Q37_Part_8', 'Q37_Part_9', 'Q37_Part_10', 'Q37_Part_11', 'Q37_OTHER']]\n\ncourse_dict = {'Q37_Part_1': 'Coursera',\n            'Q37_Part_2': 'edX',\n            'Q37_Part_3': 'Kaggle Learn Courses',\n            'Q37_Part_4': 'DataCamp',\n            'Q37_Part_5': 'Fast.ai',\n            'Q37_Part_6': 'Udacity',\n            'Q37_Part_7': 'Udemy',\n            'Q37_Part_8': 'LinkedIn Learning',\n            'Q37_Part_9': 'Cloud-certification programs',\n            'Q37_Part_10': 'University Courses',\n            'Q37_Part_11': 'None',\n            'Q37_OTHER': 'Other'}\n\ndef set_course_flags(in_df, col_name):\n    in_df[course_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\ncourse_df = set_course_flags(course_df, 'Q37_Part_1')\ncourse_df = set_course_flags(course_df, 'Q37_Part_2')\ncourse_df = set_course_flags(course_df, 'Q37_Part_3')\ncourse_df = set_course_flags(course_df, 'Q37_Part_4')\ncourse_df = set_course_flags(course_df, 'Q37_Part_5')\ncourse_df = set_course_flags(course_df, 'Q37_Part_6')\ncourse_df = set_course_flags(course_df, 'Q37_Part_7')\ncourse_df = set_course_flags(course_df, 'Q37_Part_8')\ncourse_df = set_course_flags(course_df, 'Q37_Part_9')\ncourse_df = set_course_flags(course_df, 'Q37_Part_10')\ncourse_df = set_course_flags(course_df, 'Q37_Part_11')\ncourse_df = set_course_flags(course_df, 'Q37_OTHER')\n\ncourse_df = course_df.melt(id_vars = [\"Q15\"], var_name = \"Social Platforms\", value_name = \"Presence\")\ncourse_df = course_df[course_df.Presence == True]\ndel course_df['Presence']\n\ncourse_df = course_df[(course_df.Q15 == '5-10 years') | (course_df.Q15 == '10-20 years') | (course_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(course_df, x=\"Social Platforms\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","817d2feb":"public_df = survey20[['Q15', 'Q36_Part_1', 'Q36_Part_2', 'Q36_Part_3', 'Q36_Part_4', 'Q36_Part_5', 'Q36_Part_6', 'Q36_Part_7', 'Q36_Part_8', 'Q36_Part_9', 'Q36_OTHER']]\n\ncourse_dict = {'Q36_Part_1': 'Plotly Dash',\n            'Q36_Part_2': 'Streamlit',\n            'Q36_Part_3': 'NBViewer',\n            'Q36_Part_4': 'GitHub',\n            'Q36_Part_5': 'Personal blog',\n            'Q36_Part_6': 'Kaggle',\n            'Q36_Part_7': 'Colab',\n            'Q36_Part_8': 'Shiny',\n            'Q36_Part_9': 'None',\n            'Q36_OTHER': 'Other'}\n\ndef set_public_flags(in_df, col_name):\n    in_df[course_dict[col_name]] = ~in_df[col_name].isnull()\n    del in_df[col_name]\n    return in_df\n\npublic_df = set_public_flags(public_df, 'Q36_Part_1')\npublic_df = set_public_flags(public_df, 'Q36_Part_2')\npublic_df = set_public_flags(public_df, 'Q36_Part_3')\npublic_df = set_public_flags(public_df, 'Q36_Part_4')\npublic_df = set_public_flags(public_df, 'Q36_Part_5')\npublic_df = set_public_flags(public_df, 'Q36_Part_6')\npublic_df = set_public_flags(public_df, 'Q36_Part_7')\npublic_df = set_public_flags(public_df, 'Q36_Part_8')\npublic_df = set_public_flags(public_df, 'Q36_Part_9')\npublic_df = set_public_flags(public_df, 'Q36_OTHER')\n\npublic_df = public_df.melt(id_vars = [\"Q15\"], var_name = \"Public Sharing\", value_name = \"Presence\")\npublic_df = public_df[public_df.Presence == True]\ndel public_df['Presence']\n\npublic_df = public_df[(public_df.Q15 == '5-10 years') | (public_df.Q15 == '10-20 years') | (public_df.Q15 == '20+ years')]\n\nfig = px.density_heatmap(public_df, x=\"Public Sharing\", y=\"Q15\", nbinsx=20, nbinsy=20, labels={\"Q15\": \"(DS & ML) Experience\"}, color_continuous_scale=\"YlGnBu\")\nfig.show()","f64cb6ee":"## The Upgrade Plan\n<i>A goal without a plan is just a wish.<\/i>\n\n<br>Here I have explored the platforms and tools that the experts use <i>( = Have)<\/i>, and those that they want to gain familiarity with in the next two years <i>( = Want)<\/i>.\n<br>It helped in acknowledging the most accepted technologies and the ones that hold promise.\n\n<br>Feel free to open the outputs to see the plots for Cloud Computing Platforms and Products, ML Products, Big data and Business Intelligence tools, and finally tools that enable automation and management of ML models.","ab1fc926":"Newbies i.e. Kagglers who have started to use ML in past one year vastly outnumber all others\n<br>Needless to say, you're using the Rona time wisely!\n\n<br>The other demographic of prominence is the Kagglers who are advanced beginners, in other words, those who have been using ML techniques for just under two years.\n<br>\n\nNow where are the experts?\n<br><span style=\"color:teal;\">The silvers(5-10 years) are definitely more than the golds(10-20 years) and platinums(20+ years); And quite visible in their presence.<\/span>\n","abebed62":"\n***","e30880d8":"### Relativity of Money Matters\nCan we say that companies who have a high number of employees are the ones paying big bucks to our expert Kagglers?\n<br>Or is ML incorporation only for the big boys club?\n<br>More so, is money spent on ML+cloud services only something that big firms can afford?\n<br>Computing correlations to find the answers to above questions.","db11ee77":"On querying the years spent on machine learning practice by Kagglers, we get <span style=\"color:teal;\">nine<\/span> categories.\n<br>So who do we focus on?\n<br>There are <i>Silver<\/i> Kagglers who have used ML methods for 5-10 years \ud83d\ude0e. Then there are <i>Gold<\/i> Kagglers who have practised ML methods for 10-20 years \ud83e\udd29. And then we have the <i>Platinum<\/i> group of Kagglers who have used ML for 20+ years \ud83e\udd2f\n\n<br>Alrighty! Let us meet and greet the Silver, Golden and Platinum Kagglers.","9bc5c31f":"## The ML Kitty\nWhat have the expert Kagglers got in their ML Kitty?\n<br>What libraries and methods do they use most? \n<br>How many of these are you using currently, and which ones you think you should learn now?","e5b98b7f":"<br><span style=\"color:Teal;\">Men rule in numbers in the experienced categories<\/span>.\n<br>Here's to hoping that a decade later, more balanced graphs would be observed.","a495ea03":"## Who's The Boss?\n\nHow does the employer profile change for different experience categories?\n<br>Or does it not change at all?\n\n\n### Employer sizes: Experts vs Rest","ff17898b":"<span style=\"color:teal;\">Coursera is the best destination to learn the tricks of the trade<\/span> as shared by the expert Kagglers.\n<br>While university-offered courses are also a good place to sharpen those knives, <span style=\"color:teal;\"><b>Kaggle Learn Courses<\/b> also have a lot to offer.<\/span>\n<br>Other popular data-science courses can be found at edX, Udemy and Udacity.\n<br><i>Get your game on!<\/i>","67976a7a":"Do pies make things better? Hell yeah!\n<br>Let's look at the above figures in the form of chonky percentages.","efd8edc4":"<b>The Gender Bender<\/b>","bfce534d":"<blockquote><center><span style=\"font-size:20px;\">Life can only be understood <i>backwards<\/i>.\n<br>But it must be lived <i>forwards<\/i><\/span><\/center><\/blockquote>\n<p style=\"text-align:right\"> - Soren Kierkegaard <\/p>\n\n\n***\n\n# A Look into the Habits of (DS & ML)-Experienced Kagglers\n\n\n\n![19197107.jpg](attachment:19197107.jpg)\n<a href=\"https:\/\/www.freepik.com\/vectors\/cartoon\">Cartoon vector created by vectorjuice - www.freepik.com<\/a> \n\nThe <b>Kaggle 2020 DS Survey<\/b> showed maturity in terms of questions and how they explored the preferred tools and practices of the Kagglers.\n<br>Many of us come to Kaggle to learn from the masters (and grandmasters) about their techniques. What stays behind the scene is their profile, what resources they have dedicated to the art, and yes! their weapons of choice.\n\n<br>In this notebook <span style=\"color:teal;\">I have rummaged through the answers of the Kagglers who have been practising Data Science and Machine Learning for a long time<\/span>. Hoping that I can learn some of the habits that they have cultivated over the years of practice.\n\n***","f0b90f2e":"<b>What Degrees do the ML Experts hold?<\/b>","f78ae409":"<span style=\"color:teal;\">GitHub is the place to go when you seek a solution from the masters<\/span>\n<br>The expert Kagglers also like to share their works on <b>Kaggle<\/b> and many of them have personal blogs.\n<br>Google Colab also seems to be popular among the Silver Kagglers.\n\n<br>A large number of experts have also kept their work private probably due to confidentiality demanded by their employers.\n\n***","83355274":"## Let's Talk About Work\n\nLong time back they got a taste of DS-ML. They got hooked. And now they are the elders of the Kaggle clan.\n\n![shad.jpeg](attachment:shad.jpeg)\n\n<br>So just what do they do in the shadows?\n<br>While the scientist profile is common among the three experience categories, what functions comprise their work profile?\n<br>Let's explore the work Kaggle elders do.","243ab97e":"TPUs have gained popularity in the past year, specially since its availability on a platform like Kaggle. <span style=\"color:teal;\">But it seems like it has a lot of catching up to do to gain the kind of acceptance that GPUs command.<\/span>\n<br>Have the experts used TPUs? Yes.\n<br>Are they using TPUs frequently? No, if you are a Silver or Gold Kaggler, but a resounding Yes if you are a Platinum Kaggler.\n<br><span style=\"color:teal;\">A large number of 20+ DS-ML experience holders have used TPUs for more than 25 times.<\/span>","8afeafdc":"## The Social Paradigm\n\n![im-not-anti-social-selectively-social-theresadifference-most-funny-memes-of-53584677.png](attachment:im-not-anti-social-selectively-social-theresadifference-most-funny-memes-of-53584677.png)\n\n<br>What social platforms do the experts prefer to discuss, learn and share their work?\n<br>Peek into the steaming cauldron of graphs with me, and you shall get the answer.","390b9d5f":"<span style=\"color:teal;\">Blogs like Towards Data Science, Analytics Vidhya and others is where the experts go to read up on what's new.\n<br><b>Kaggle<\/b> also figures highly on the preferred source of interesting reads in the field of DS.<\/span>\n<br>Since many expert Kagglers are working in research, they like to read journal publications to stay up-to-date. The other platforms that catch their interest include YouTube, Twitter and those Email newsletters that many of us might not take seriously. Next time, do scour through what they have to offer.\n\n<br>Where do the masters go to sharpen those knives?\n<br>A plot shall answer.","ac7e7c46":"This is it dear reader.\n<br>Your time and patience spent on reading this notebook is greatly appreciated. I hope you could learn something about the habits of (DS & ML)-Expert Kagglers and found things that can enrich your skillset.\n\n![](https:\/\/64.media.tumblr.com\/75b3f2426ecbc015506053d7e08d7dda\/tumblr_pfbnb4O4iV1vd8jsjo2_500.gifv)","f5498b45":"### Where do the (DS & ML)-Experienced Kagglers Live?\n","149ab7b5":"While hosted notebooks are yet to gain popularity as de facto editors,<span style=\"color:teal;\"> Colaboratory and Kaggle notebooks rule the roost.<\/span> \n\n<br>Let's end this section with a peek into hardware preferences of the (DS & ML)-Expert Kagglers.","84c8a252":"<br><span style=\"color:Teal;\">Majority of Kagglers with 20+ years of ML experience started its use in their early thirties or late twenties<\/span>.\nSo it is safe to say that they first got their hands on ML while they were already employed.\n<br>What about the Kagglers who have been using ML techniques for a decade or so?\nAgain a majority of them started out in late twenties to late thirties.\n\n<br>Now we can see that the silver ML programmers (experience = 5-10 years) are present in bigger numbers than the other two categories.\nAgain we can say that about 50% of them started using ML in their early twenties and the thirties.\n<br>But <span style=\"color:Teal;\">the popularity of ML techniques has risen in past 5 years among Kagglers of all ages<\/span>, including late teenagers and programmers past their 50s.\n\n<br>A shout-out to the Kagglers who picked ML practice while their counterparts were enjoying retirement \ud83d\ude47","43871463":"As an experienced data scientist, you can expect to earn in the range of 50k-250k depending on which country you live in.\n<br>With growing expertise, your pay would definitely improve as we see a larger percentage of expert Kagglers earning more than $500,000.","490979e9":"***","3bc5b7c8":"<span style=\"color:teal;\">It's go big or go home for the DS-ML expert Kagglers<\/span>\n<br>A quarter of experts are working at small-sized firms that are most probably start-ups. Moreover, these could include firms owned by the expert themselves. Definitely a high-risk, high-reward situation with a lot of visibility.\n\n![](https:\/\/media.giphy.com\/media\/OPuj7A2SEWnAkBZlQd\/giphy.gif)\n\n\n<br>The other two quarters of them are working in large-sized firms. While the remaining quarter is divided over medium-sized firms.\n\n\n<br>\n\nNow what about the acceptance of ML by the employer?\n\n#### Employer ML practice: Experts vs Rest","02f9f52f":"<span style=\"color:teal;\">So if you are an experienced DS & ML programmer, there's almost half a chance that you're employed at a firm that has incorporated ML models into production.<\/span>\n<br>Or you might be the one who is bringing in the ML game to their firm.\n<br>Almost a similar number of you work on ML methods that are used to gain insights and probably used for decision making.\n<br>And again a similar number of you work on ML applications alongside a mainstream job that does not involve ML use as such. <i>Smells of DS-ML passion again.<\/i>\n\n<br>If we see the Kagglers who have an ML experience of under 5 years, they are somewhat uniformly distributed over the five degrees of ML incorporation.","8e791a4b":"<span style=\"color:teal;\">Expenses on ML+cloud sevices and compensation of ML experts is NOT a function of company size.<\/span>\n<br>This just re-enforces the belief that start-ups primarily focussed on ML\/AI-based products have a major presence. They don't mind paying our experts, or shelling out money to buy tech to support them.\n<br><br>Let's summarize the employer profile of (DS &ML)-Experts on Kaggle.","6b7e22a6":"\n***\n\nIn this survey data, could there be any 'child prodigies' who started ML programming at the age of (-2) or 8 to 10 years?\n<br>Checking for inconsistencies where participants reported an ML experience of 20+ or 10-20 years while specifying their age in 18-21 range.\n","144fd4b4":"<span style=\"color:teal;\">Python is the blue-eyed boy when it comes to practical DS and ML<\/span>\n<br>While choice of programming languages is pretty much on par for the experts and the rest, Bash scripting is more in use by the experienced Kagglers.\n<br>This could be attributed to deployment and test setups that our experts do on a regular basis, as compared to the lesser experienced Kagglers.\n\n<br>While most of the Kagglers are using Python in combination with other languages, <b>what languages do the experts suggest?<\/b> In other words, what language do the experts feel hold promise for a fruitful career in DS & ML field?","ef1efec3":"## Getting to know the (DS & ML)-experienced Kagglers","a5363d80":"<b>What Jobs do the ML Experts do?<\/b>","d3b40315":"#### Money Talk <i>Ka-ching!<\/i>\n\nWho's bringing in the big bucks? Is it a function of expertise?","4b19cdae":"The DS-ML experts of Kaggle community are mostly busy with building prototypes to explore possible application of ML to different areas, or improving on the existing models. So yes, <span style=\"color:teal;\">research is one of their biggest contribution to the field<\/span>\n<br>Another area where their experience is greatly being appreciated is application of their knowledge to business decisions.\n<br>While at the lower side of the expertise spectrum of less than a decade of ML experience, an expert would majorly be working as an analyst or an engineer, and substantially involved with data infrastructure conception and implementation as well.\n<br><br>The job function <i>Other<\/i> is also an interesting observation, since it could mean the work these experts put in enriching the Kaggle community. Or mentoring younger colleagues.\n\n***","d2b9c187":"The heatmaps are self-explanatory. Let's just recap the findings.\n<br><span style=\"color:teal;\">For visualization, the experts prefer Matplotlib<\/span>. It is closely followed by Seaborn. Other favored visualization libraries include Plotly\/Plotly Express, Ggplot\/(2) and Shiny.\n\n<br><span style=\"color:teal;\">Scikit-learn remains the most preferred ML framework<\/span>. The division of ML programmer community over use of TensorFlow or Pytorch is also apparent from the heatmaps, though both command large following among the experts. While Keras, PyTorch, Xgboost are also popular frameworks. A considerable number of experts use LightGBM and Caret too.\n\n<br>Coming down to what ML algorithms are mostly used by expert Kagglers, <span style=\"color:teal;\">classics like Linear\/Logistic Regression and Decision Trees\/Random Forests are the most widely used ones<\/span>. Gradient Boosting Machines are greatly appreciated and have a good following. For deep learning, Convolutional Neural Networks far outnumber application of Recurrent Neural Networks, Dense Neural Networks & Generative Adversarial Networks.\n<br>It should also be noted that depite their recent introduction, Transformer Networks are also being favoured by the experts.\n\n<br>While <span style=\"color:teal;\">majority of Computer Vision problems employ Image classification methods such as VGG, Inception, ResNet, ResNeXt, NASNet and so on<\/span>. A uniform distribution over use of General purpose image\/video tools like PIL, openCV, skimage and something as complex as Generative Networks can also be seen.\n\n<br>The other specialized field of Natural Language Processing<span style=\"color:teal;\">(NLP), relies on classic Word embeddings\/vectors such as GLoVe, fastText, word2vec; and recent techniques like Transformer language models that include GPT-3, BERT, XLnet, etc.<\/span> Encoder-decorder models like seq2seq, vanilla transformers are also pretty much in use right now.\n\n***","6161fd2b":"<span style=\"color:Teal;\">Across the three categories of DS-ML expertise, the US, many European nations and Russia host the majority of them.<\/span>\n<br>Though it should be noted that Asian countries like India and Japan surpassed the UK for the categories of Kagglers who have been practising ML for 5-20 years. Surely, these two nations have emerged as data science hubs and would soon contribute a higher number of experts to the Kaggle community.\n<br>The other two countries that hosted a large number of 5-20 years of ML expertise include Canada and Australia. This observation could also be attributed to the fact that these countries have been migratory destination of techies in the past few years.\n\n***","b43dbe83":"<span style=\"color:Teal;\">Majority of ML experts among Kagglers are Scientists.<\/span> And they are very much a part of research field as well.\n<br>While other ML experts have been designated titles specific to their workplace, many identify themselves as Engineers, Programmers and Statisticians.\nThis shows how Data science is making headways in diverse fields.\n\n<br>A number of Kagglers who have been using ML techniques for 5-10 years also include students.","e42ec6e8":"While majority of Kagglers who have been practising ML techniques for 5-10 years hold a Master's degree.\n<br><span style=\"color:Teal;\">Doctoral degree is very popular amongst the experienced ML programmers<\/span>.\n<br>The abundance of doctorates is more noticeable as we move towards higher ML expertise.\n\n<br>It should also be noted that many Kagglers have gained expertise in ML while formally they hold other professional degrees.\n<br><i>There's no stopping a passion<\/i>. Right?","eae370cc":"<span style=\"color:teal;\">Expert Kagglers obviously favor firms who have been old players of ML incorporation and not shy on spending money to support their work.<\/span>\n<br>They could also be their own bosses or bringing in the ML game to their firms.\n<br>Lastly, Open-source\/In-house technology has a distinguished presence since a large number of experts claimed that not much of big bucks were spent on ML+clouds services by their employers.\n\n***","ff46171c":"***\n\n### Ages, Gender, Formal education & Job titles of (DS & ML)-Experienced Kagglers\nLet us break down the distribution of what ages, gender, degree and jobs that define the profile of our DS-ML experts\n\n<b>So how old are our ML experts?<\/b>","d9ab8671":"<span style=\"color:teal;\">Python and R languages are here to stay.<\/span>\n<br>While the silver and gold Kagglers feel that SQL, MATLAB and a mix of other languages hold promise, surprisingly they do not show much of interest towards Julia.\n<br>On the other hand, the platinum Kagglers feel that DS & ML programming can be furthered by learning C, C++ and Julia.\n\n<br>Now what are the development environments preferred by the experts as compared to lesser experienced Kagglers? \n<br>Let's see.","0848e9cc":"<span style=\"color:teal;\">Python and R languages being the preferred weapons of choice, their primary IDEs are the most popular across all experiences.<\/span>\n<br>While VSCode is more popular among the fresh ML programmers probably due to their familiarity with the IDE, having used it for other programming languages.\n<br>For Python, JupyterLab is slowly overtaking oldies like Spyder and PyCharm as the preferred IDE.\n\n<br>An interesting observation is that Vim\/Emacs editors are still popular among the experienced Kagglers.\n<br>While a part of reason behind this could be the scripting work done by them. The more significant reason could be that when these experts had started to program, the programming world was only divided between Vim users and Emacs users.\n<br><i>Ah! Nostalgia<\/i>","c50e1942":"## Weapons of Choice\n\nDoes the preference of programming language, editor and development environment differ for the experts?\n<br>Or are they on the same boat?\n"}}