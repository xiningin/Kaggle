{"cell_type":{"9d25cc56":"code","0a23fef5":"code","ebb973bb":"code","d02c2750":"code","1f68d0f0":"code","d6a55243":"code","800d73d5":"code","54edae96":"code","c1f197d2":"code","1ad72c7f":"code","ffa254e6":"code","8d82cb20":"code","475a7c6f":"code","33e27002":"code","3f41bd85":"code","751faf90":"code","c097ee31":"code","52b4d4b1":"code","e0882989":"code","0888745b":"code","a8997efc":"code","571fca9d":"code","f96e236d":"code","f6dd023b":"code","7bc973c2":"code","45869763":"code","b89a3fad":"code","365190af":"code","46b1424a":"markdown","4088f688":"markdown","4b9b8c62":"markdown"},"source":{"9d25cc56":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0a23fef5":"import numpy as np\nimport pandas as pd","ebb973bb":"train_data = pd.read_csv(r\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_data = pd.read_csv(r\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","d02c2750":"train_data.head()","1f68d0f0":"train_data.shape","d6a55243":"x_text = train_data[\"text\"]","800d73d5":"import re\n\ndef cleaning(sentence):\n    \n    sentence = re.sub(r\"won't\", \"will not\", sentence)\n    sentence = re.sub(r\"can\\'t\", \"can not\", sentence)\n    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n    sentence = sentence.lower()                 # Converting to lowercase\n    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    sentence = re.sub(r'[.|,|)|(|\\|\/]',r' ',sentence)        #Removing Punctuations\n    return sentence","54edae96":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","c1f197d2":"snow = nltk.stem.SnowballStemmer('english')","1ad72c7f":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer \n\nstop_words = set(stopwords.words('english'))       # set is used as we have to use 'not in' (to iterate) function\n\ntemp = []\n\nfor each_sentence in x_text:\n    each_sentence = cleaning(each_sentence)\n    each_word = [snow.stem(word) for word in each_sentence.split() if word  not in stop_words]\n    temp.append(each_word)   ","ffa254e6":"temp[0:2]","8d82cb20":"# only to remove quotes for each word\n\nfinal_word = []\n\nfor row in temp:\n    seq = ''\n    for word in row:\n        seq = seq + ' ' + word\n    final_word.append(seq)","475a7c6f":"final_word[0:2]","33e27002":"from sklearn.feature_extraction.text import CountVectorizer\n\nconverter = CountVectorizer()\nx = converter.fit_transform(final_word)","3f41bd85":"x = x.toarray()","751faf90":"y = train_data[\"target\"]","c097ee31":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3 , random_state = 0)\n\nprint(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","52b4d4b1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nmodel_lr = LogisticRegression(max_iter = 1000)\n\nhyperparmeter_C = {'C':[0.1]}\n\ngrid_search = GridSearchCV(estimator = model_lr , param_grid = hyperparmeter_C)\n\ngrid_search.fit(x_train,y_train)\n\ngrid_search.best_params_\n\nprint(\"Best C Value is \",grid_search.best_params_)\n\nprint(\"test accuracy \",(grid_search.score(x_test,y_test))*float(100))","e0882989":"test_data.head()","0888745b":"x_test_text = test_data[\"text\"]","a8997efc":"temp_test = []\n\nfor each_sentence in x_test_text:\n    each_sentence = cleaning(each_sentence)\n    each_word = [snow.stem(word) for word in each_sentence.split() if word  not in stop_words]\n    temp_test.append(each_word) ","571fca9d":"temp_test[0:2]","f96e236d":"# only to remove quotes for each word\n\nfinal_word_test = []\n\nfor row in temp_test:\n    seq = ''\n    for word in row:\n        seq = seq + ' ' + word\n    final_word_test.append(seq)","f6dd023b":"final_word_test[0:2]","7bc973c2":"converter.fit(final_word)\ntest_transformed = converter.transform(final_word_test)","45869763":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nmodel_lr = LogisticRegression(max_iter = 1000)\n\nhyperparmeter_C = {'C':[0.1]}\n\ngrid_search = GridSearchCV(estimator = model_lr , param_grid = hyperparmeter_C)\n\ngrid_search.fit(x,y)\n\n\nfinal_prediction = grid_search.predict(test_transformed)","b89a3fad":"final_prediction","365190af":"pred=pd.DataFrame(final_prediction)\n\nsub_df=pd.read_csv(r\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\ndatasets=pd.concat([sub_df['id'],pred],axis=1)\ndatasets.columns=['id','target']\ndatasets.to_csv('submission.csv',index=False)","46b1424a":"# For test data","4088f688":"# Building model","4b9b8c62":"# Preprocessing"}}