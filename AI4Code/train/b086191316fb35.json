{"cell_type":{"ca0a23d6":"code","a2f37c5d":"code","667de626":"code","5f259422":"code","73866b02":"code","2a04efde":"code","f8a6dfe7":"markdown","f1f31b08":"markdown","359e888a":"markdown","8fe8cbcf":"markdown","3f0c1db8":"markdown","b8af54b9":"markdown","2af32342":"markdown","3a950162":"markdown"},"source":{"ca0a23d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2f37c5d":"def add_features(df):\n    #df = pd.get_dummies(df)\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['u_in_lag4'] = df['u_in'].shift(4).fillna(0)\n    df['u_out_lag'] = df['u_out'].shift(1).fillna(0)\n    df['time_lag'] = df['time_step'].shift(2).fillna(0)\n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    df['RC_sum'] = df['R'] + df['C']\n    df['RC_div'] = df['R'] \/ df['C']\n    df['RC_sum'] = df['R'] + df['C']\n    df['RC_div'] = df['R'] \/ df['C']\n    #df['R'] = df['R'].astype(str)\n    #df['C'] = df['C'].astype(str)\n    df['ewm_u_in_mean'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).mean().reset_index(level=0,drop=True)\n    df['ewm_u_in_std'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).std().reset_index(level=0,drop=True)\n    df['ewm_u_in_corr'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).corr().reset_index(level=0,drop=True)\n    df['rolling_10_mean'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    df['rolling_10_max'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).max().reset_index(level=0,drop=True)\n    df['rolling_10_std'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).std().reset_index(level=0,drop=True)\n    df['expand_mean'] = df.groupby('breath_id')['u_in'].expanding(2).mean().reset_index(level=0,drop=True)\n    df['expand_max'] = df.groupby('breath_id')['u_in'].expanding(2).max().reset_index(level=0,drop=True)\n    df['expand_std'] = df.groupby('breath_id')['u_in'].expanding(2).std().reset_index(level=0,drop=True)\n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] \/df['count']\n    df = df.fillna(0)\n    return df\n\ndf = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ndf = add_features(df)","667de626":"# 1 Auto-EDA\n\n# Commented out because dataset is too large for this method.\n\n'''\n!pip install https:\/\/github.com\/pandas-profiling\/pandas-profiling\/archive\/master.zip\nimport pandas_profiling\n#Generating PandasProfiling Report\nreport = pandas_profiling.ProfileReport(df)\nreport\n'''","5f259422":"# 2 Auto-EDA\n!pip install sweetviz\nimport sweetviz as sv\n#Generating Sweetviz report\nreport = sv.analyze(df)\nreport.show_html(\"iris_EDA_report.html\") # specify a name for the report","73866b02":"# 3 Auto-EDA\n!pip install autoviz\n!pip install xlrd\nfrom autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\nfilename = \"\" # empty string (\"\") as filename since no file is being used for the data\nsep = \",\"\ndft = AV.AutoViz(\n    '',\n    sep=\",\",\n    depVar=\"\",\n    dfte=df,\n    header=0,\n    verbose=0,\n    lowess=False,\n    chart_format=\"svg\",\n    max_rows_analyzed=150000,\n    max_cols_analyzed=30,\n     )","2a04efde":"from xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ny = df.pop('pressure')\nX = df\n\nmodel = XGBRegressor(tree_method='gpu_hist')\nmodel.fit(X, y)\n\nplot_importance(model, max_num_features=10)\nplt.show()","f8a6dfe7":"# Third Auto-EDA way (AutoViz)\n***Disadvantages:***\n* A lot of graphs in output\n* Very hard to save it (you need to 'Save Version\" with output and then save .png output)\n* Only plots\n\n***Advantages:***\n* Large amount of different plots, you can find a lot of relations from here\n* Very fast!","f1f31b08":"# Second Auto-EDA way (SweetViz)\n***Disadvantages:***\n* Not a lot of info\n\n***Advantages:***\n* .html output with active buttons (you can click on any feature for more described info and change nbins for plots)","359e888a":"# Introduction\nWhen you see any dataset for the first time you always want to see as many relations as possible. You can do everything by hands, but I want to show libs that can make your life a bit easier.","8fe8cbcf":"Full dataset can be found here: https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/data","3f0c1db8":"# A bit of Feature Engineering","b8af54b9":"# Feature Importance\nIn this example I will use XGBoost with GPU.\n\n*You can (need) to use different models and different scores.*","2af32342":"# Conclusion\nAs student I am more in tradional ways of EDA, where you are doing everything by your hands.\nBut sometimges such libs can be very useful.\nFor example, I can run cell with third Auto-EDA and then just check different plots with some tea for any relations and interesing things, and then check it by hands for more details.\n\nI hope it was useful for new users :)","3a950162":"# First Auto-EDA way (Pandas Profiling)\n***Disadvantages:***\n* Need a lot of RAM (for example this dataset + new features are too large for this memory)\n* Not optimized for big datasets\n\n***Advantages:***\n* Very detailed\n* Different correlations"}}