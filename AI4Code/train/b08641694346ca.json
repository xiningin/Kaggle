{"cell_type":{"67cbfcac":"code","c162b96d":"code","12804903":"code","dd0d68ab":"code","b3f3d24e":"code","598cf866":"code","ffc24284":"code","56f7b893":"code","d921eb57":"code","b0cd2b5f":"code","c75b6036":"code","5f29038e":"code","f4607b18":"code","f0022de2":"code","2896ef45":"code","7d04be53":"code","c3b05aee":"code","e1dfc0f6":"code","d18e8f95":"code","fbd53463":"code","b9b0aa2a":"code","d17687bb":"code","923385b7":"code","a8fcafbe":"code","8b04435a":"code","25d89a54":"code","ad72a038":"code","65d0e2ed":"code","6f5668f0":"code","72fff208":"code","f75c58a4":"code","b8ebc4d7":"code","bdd85da3":"code","5d865689":"code","f87d9acf":"code","697af259":"code","7b7e2d38":"code","79ee24c0":"code","c9c0c568":"code","1b4e0fba":"code","6a1ffe10":"markdown","58788e12":"markdown","1816ddd6":"markdown","f9bb0198":"markdown","67ea1fcf":"markdown","d50cb76d":"markdown","4304c3bf":"markdown","ca60ac51":"markdown","099208bd":"markdown","50f3d0eb":"markdown","3f4f8bfd":"markdown","772895f1":"markdown","2acd02f9":"markdown","2709767c":"markdown","fff3e468":"markdown","5a645d10":"markdown","bff9d70c":"markdown","6e631dc5":"markdown","e91d5430":"markdown","5fd3cc01":"markdown","8d0236db":"markdown","adb3ac35":"markdown","2fabab8d":"markdown","1ca0d4ef":"markdown","de370270":"markdown","a39a6dee":"markdown","7a7c6b35":"markdown","7446f4d7":"markdown","9e8fde42":"markdown","a0c9897c":"markdown","e9c5ce68":"markdown","39177200":"markdown","9ab2655e":"markdown","5d58d3e4":"markdown","65694b29":"markdown","f8f1ba3c":"markdown","12c45a15":"markdown","3dc6256f":"markdown","de54020f":"markdown","02898e17":"markdown"},"source":{"67cbfcac":"import re\nimport sklearn\nimport xgboost as xgb \nimport matplotlib.pyplot as plt\n# Going to use these 5 base models \nfrom sklearn.ensemble import (RandomForestClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom xgboost import XGBClassifier \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nsns.set(style='white', context='notebook', palette='deep')","c162b96d":"# import train and test to play with it\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\nIDtest = df_test[\"PassengerId\"]","12804903":"df_train.head()","dd0d68ab":"df_test.head()","b3f3d24e":"df_train.describe(include=\"all\")","598cf866":"df_test.describe()","ffc24284":"print(df_train.isnull().sum())\nprint(df_test.info())","56f7b893":"data = [df_train, df_test]","d921eb57":"for dataset in data:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n\n    #complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n#delete the cabin feature\/column and others previously stated to exclude in train dataset\ndrop_column = ['PassengerId','Cabin', 'Ticket']\ndf_train.drop(drop_column, axis=1, inplace = True)\ndf_test.drop(drop_column, axis=1, inplace = True)\nprint(df_train.isnull().sum())\nprint(\"-\"*10)\nprint(df_test.isnull().sum())","b0cd2b5f":"print(df_train.isnull().sum())\nprint(df_test.info())","c75b6036":"g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"seagreen\", 0:\"gray\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();","5f29038e":"ax= sns.boxplot(x=\"Pclass\", y=\"Age\", data=df_train)\nax= sns.stripplot(x=\"Pclass\", y=\"Age\", data=df_train, jitter=True, edgecolor=\"gray\")\nplt.show()","f4607b18":"df_train.hist(figsize=(15,20), color = \"orange\")\nplt.figure()","f0022de2":"df_train[\"Age\"].hist();","2896ef45":"f,ax=plt.subplots(1,2,figsize=(20,10))\ndf_train[df_train['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='orange')\nax[0].set_title('Survived= 0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\ndf_train[df_train['Survived']==1].Age.plot.hist(ax=ax[1],color='Lime',bins=20,edgecolor='black')\nax[1].set_title('Survived= 1')\nx2=list(range(0,85,5))\nax[1].set_xticks(x2)\nplt.show()","7d04be53":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf_train['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived',data=df_train,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","c3b05aee":"# scatter plot matrix\npd.plotting.scatter_matrix(df_train,figsize=(15,18))\nplt.figure()","e1dfc0f6":"plt.figure(figsize=(7,4)) \nsns.heatmap(df_train.corr(),annot=True,cmap='BuGn') #draws  heatmap with input as the correlation matrix calculted by(iris.corr())\nplt.show()","d18e8f95":"\npp = sns.pairplot(df_train, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])","fbd53463":"pal = {'male':\"green\", 'female':\"Orange\"}\nplt.subplots(figsize = (15,8))\nax = sns.barplot(x = \"Sex\", \n            y = \"Survived\", \n            data=df_train, \n            palette = pal,\n            linewidth=2 )\nplt.title(\"Survived\/Non-Survived Passenger Gender Distribution\", fontsize = 25)\nplt.ylabel(\"% of passenger survived\", fontsize = 15)\nplt.xlabel(\"Sex\",fontsize = 15);","b9b0aa2a":"pal = {1:\"seagreen\", 0:\"orange\"}\nsns.set(style=\"darkgrid\")\nplt.subplots(figsize = (15,8))\nax = sns.countplot(x = \"Sex\", \n                   hue=\"Survived\",\n                   data = df_train, \n                   linewidth=2, \n                   palette = pal\n)\n\n## Fixing title, xlabel and ylabel\nplt.title(\"Passenger Gender Distribution - Survived vs Not-survived\", fontsize = 25)\nplt.xlabel(\"Sex\", fontsize = 15);\nplt.ylabel(\"# of Passenger Survived\", fontsize = 15)\n\n## Fixing legends\nleg = ax.get_legend()\nleg.set_title(\"Survived\")\nlegs = leg.texts\nlegs[0].set_text(\"No\")\nlegs[1].set_text(\"Yes\")\nplt.show()","d17687bb":"plt.subplots(figsize = (15,10))\nsns.barplot(x = \"Pclass\", \n            y = \"Survived\", \n            data=df_train, \n            linewidth=2)\nplt.title(\"Passenger Class Distribution - Survived vs Non-Survived\", fontsize = 25)\nplt.xlabel(\"Socio-Economic class\", fontsize = 15);\nplt.ylabel(\"% of Passenger Survived\", fontsize = 15);\nlabels = ['Upper', 'Middle', 'Lower']\nval = [0,1,2] ## this is just a temporary trick to get the label right. \nplt.xticks(val, labels);","923385b7":"# Kernel Density Plot\nfig = plt.figure(figsize=(15,8),)\n## I have included to different ways to code a plot below, choose the one that suites you. \nax=sns.kdeplot(df_train.Pclass[df_train.Survived == 0] , \n               color='orange',\n               shade=True,\n               label='not survived')\nax=sns.kdeplot(df_train.loc[(df_train['Survived'] == 1),'Pclass'] , \n               color='g',\n               shade=True, \n               label='survived')\nplt.title('Passenger Class Distribution - Survived vs Non-Survived', fontsize = 25)\nplt.ylabel(\"Frequency of Passenger Survived\", fontsize = 15)\nplt.xlabel(\"Passenger Class\", fontsize = 15)\n## Converting xticks into words for better understanding\nlabels = ['Upper', 'Middle', 'Lower']\nplt.xticks(sorted(df_train.Pclass.unique()), labels);","a8fcafbe":"\nfig = plt.figure(figsize=(15,8),)\nax=sns.kdeplot(df_train.loc[(df_train['Survived'] == 0),'Fare'] , color='orange',shade=True,label='not survived')\nax=sns.kdeplot(df_train.loc[(df_train['Survived'] == 1),'Fare'] , color='g',shade=True, label='survived')\nplt.title('Fare Distribution Survived vs Non Survived', fontsize = 25)\nplt.ylabel(\"Frequency of Passenger Survived\", fontsize = 15)\nplt.xlabel(\"Fare\", fontsize = 15)","8b04435a":"\nfig = plt.figure(figsize=(15,8),)\nax=sns.kdeplot(df_train.loc[(df_train['Survived'] == 0),'Age'] , color='orange',shade=True,label='not survived')\nax=sns.kdeplot(df_train.loc[(df_train['Survived'] == 1),'Age'] , color='g',shade=True, label='survived')\nplt.title('Age Distribution - Surviver V.S. Non Survivors', fontsize = 25)\nplt.xlabel(\"Age\", fontsize = 15)\nplt.ylabel('Frequency', fontsize = 15);","25d89a54":"pal = {1:\"seagreen\", 0:\"orange\"}\ng = sns.FacetGrid(df_train,size=5, col=\"Sex\", row=\"Survived\", margin_titles=True, hue = \"Survived\",\n                  palette=pal)\ng = g.map(plt.hist, \"Age\", edgecolor = 'white');\ng.fig.suptitle(\"Survived by Sex and Age\", size = 25)\nplt.subplots_adjust(top=0.90)","ad72a038":"g = sns.FacetGrid(df_train,size=5, col=\"Sex\", row=\"Embarked\", margin_titles=True, hue = \"Survived\",\n                  palette = pal\n                  )\ng = g.map(plt.hist, \"Age\", edgecolor = 'white').add_legend();\ng.fig.suptitle(\"Survived by Sex and Age\", size = 25)\nplt.subplots_adjust(top=0.90)","65d0e2ed":"sib = pd.crosstab(df_train['SibSp'], df_train['Sex'])\ndummy = sib.div(sib.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\ndummy = plt.xlabel('Siblings')\ndummy = plt.ylabel('Percentage')\n\nparch = pd.crosstab(df_train['Parch'], df_train['Sex'])\ndummy = parch.div(parch.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\ndummy = plt.xlabel('Parent\/Children')\ndummy = plt.ylabel('Percentage')","6f5668f0":"\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=df_train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of SibSp = 0 who survived:\", df_train[\"Survived\"][df_train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 1 who survived:\", df_train[\"Survived\"][df_train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 2 who survived:\", df_train[\"Survived\"][df_train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)","72fff208":"#draw a bar plot for Parch vs. survival\nsns.barplot(x=\"Parch\", y=\"Survived\", data=df_train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of Parch = 0 who survived:\", df_train[\"Survived\"][df_train[\"Parch\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Parch = 1 who survived:\", df_train[\"Survived\"][df_train[\"Parch\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Parch = 2 who survived:\", df_train[\"Survived\"][df_train[\"Parch\"] == 2].value_counts(normalize = True)[1]*100)","f75c58a4":"#sort the ages into logical categories\ndf_train[\"Age\"] = df_train[\"Age\"].fillna(-0.5)\ndf_test[\"Age\"] = df_test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ndf_train['AgeGroup'] = pd.cut(df_train[\"Age\"], bins, labels = labels)\ndf_test['AgeGroup'] = pd.cut(df_test[\"Age\"], bins, labels = labels)\n\n#draw a bar plot of Age vs. survival\n\nplt.figure(figsize=(10,5))\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=df_train, )\n\nplt.show()\n","b8ebc4d7":"# data = [df_train, df_test] declared at the top\nfor dataset in data:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes\/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no\/0 if family size is greater than 1\n\n    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n\n\n    \nstat_min = 10 \n#this will create a true false series with title name as index\ntitle_names = (df_train['Title'].value_counts() < stat_min) \n\n\ndf_train['Title'] = df_train['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n#this will create a true false series with title name as index\ntitle_names = (df_test['Title'].value_counts() < stat_min) \n\n\ndf_test['Title'] = df_test['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n\nprint(df_train['Title'].value_counts())\nprint(df_test['Title'].value_counts())","bdd85da3":"\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\ndf_train.head(1)","5d865689":"Target = ['Survived']\nfeatures = ['Sex_Code','Pclass', 'Embarked_Code', \n               'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code', 'IsAlone']","f87d9acf":"print(df_train[features].shape)\nprint(df_test[features].shape)","697af259":"# Cross validate model with Kfold stratified cross val\n\nkfold = StratifiedKFold(n_splits=10)\n#Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(XGBClassifier(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\ncv_results = []\nfor classifier in classifiers :\n    #print(classifier)\n    cv_results.append(cross_val_score(classifier, df_train[features],\n                y = df_train[Target], scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\n         \"Algorithm\":[\"XGB\", \"DecisionTree\",\"RandomForest\",\n            \"ExtraTrees\",\"GradientBoosting\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\"\n                ,orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","7b7e2d38":"g = sns.scatterplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\")","79ee24c0":"import warnings\nwarnings.filterwarnings(\"ignore\")\nnrows = 5\nncols = 1\nfig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,50),squeeze=False)\nname = [\"XGB\", \"DecisionTree\",\"RandomForest\",\n            \"ExtraTrees\",\"GradientBoosting\"]\nclassifiers = []\nclassifiers.append(XGBClassifier(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nrow=0\ncol=0\nl=[]\nfor classifier in classifiers :\n    classifier.fit(df_train[features],df_train[Target])\n    indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n    try:\n        g = sns.barplot(y=df_train[features].columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n    except:\n        print(\"Dfd\")\n    g.set_xlabel(\"Relative importance\",fontsize=12)\n    g.set_ylabel(\"Features\",fontsize=12)\n    g.tick_params(labelsize=9)\n    g.set_title(name[row] + \" feature importance\")\n    row+=1","c9c0c568":"test_Survived_X = pd.Series(classifiers[0].predict(df_test[features]), name=\"XGB\")\ntest_Survived_B = pd.Series(classifiers[1].predict(df_test[features]), name=\"DecisionTree\")\ntest_Survived_R = pd.Series(classifiers[2].predict(df_test[features]), name=\"RandomFOrest\")\ntest_Survived_E = pd.Series(classifiers[3].predict(df_test[features]), name=\"ExtraTree\")\ntest_Survived_G = pd.Series(classifiers[4].predict(df_test[features]), name=\"GradientBoosting\")\n\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_Survived_X,test_Survived_B,test_Survived_R,test_Survived_E, test_Survived_G],axis=1)\n\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","1b4e0fba":"i = 0\nfor clf in classifiers:\n    test_Survived = pd.Series(clf.predict(df_test[features]), name=\"Survived\")\n    results = pd.concat([IDtest,test_Survived],axis=1)\n    file_name = name[i] + \".csv\"\n    results.to_csv(file_name,index=False)\n    i += 1\n    print(file_name)","6a1ffe10":"The describe() function gives a lot of information about the data","58788e12":"## **Models**","1816ddd6":"### Training models on the entire train dataset and plotting their feature importance","f9bb0198":"### Survived by Sex and Age","67ea1fcf":"### Histograms","d50cb76d":"### Passenger Class Distribution - Survived vs Non-Survived","4304c3bf":"### Survived Distribution","ca60ac51":"Let's now deal wtih the missing values","099208bd":"### Feature Engineering for train and test dataset","50f3d0eb":"### Kernel Density Plot - Age Distribution - Surviver V.S. Non Survivors","3f4f8bfd":"### Bar plot for SibSp vs. survival","772895f1":"### Box Plot of Pclass and Age","2acd02f9":"The data is clean now and we can proceed with EDA(Exploratory Data Analysis)","2709767c":"### Declaring train features and target feature variables","fff3e468":"* Numerical Features: Age (Continuous), Fare (Continuous), SibSp (Discrete), Parch (Discrete)\n* Categorical Features: Survived, Sex, Embarked, Pclass\n* Alphanumeric Features: Ticket, Cabin\n\n***What are the data types for each feature?***\n* Survived: int\n* Pclass: int\n* Name: string\n* Sex: string\n* Age: float\n* SibSp: int\n* Parch: int\n* Ticket: string\n* Fare: float\n* Cabin: string\n* Embarked: string","5a645d10":"## Exploratory Data ","bff9d70c":"### Passenger Gender Distribution - Survived vs Not-survived","6e631dc5":"### Sort the ages into logical categories and draw a bar plot of Age vs. survival","e91d5430":"## **Final Prediction on Test set**","5fd3cc01":"## **Data Cleaning**","8d0236db":"### Scatter plot of all features","adb3ac35":"### Heatmap of feature correlations","2fabab8d":"### Pair plots of entire dataset","1ca0d4ef":"### Convert objects to category using Label Encoder for train and test dataset\n","de370270":"### A scatter plot of the survived people on the features - AGe, Fare, Pclass ","a39a6dee":"Let's see how the data looks like","7a7c6b35":"### Stratified KFold  Cross validation on different models","7446f4d7":"**Some Observations:**\n* There are a total of 891 passengers in our training set.\n* The Age feature is missing approximately 19.8% of its values. I'm guessing that the Age feature is pretty important to survival, so we should probably attempt to fill these gaps.\n* The Cabin feature is missing approximately 77.1% of its values. Since so much of the feature is missing, it would be hard to fill in the missing values. We'll probably drop these values from our dataset.\n* The Embarked feature is missing 0.22% of its values, which should be relatively harmless.","9e8fde42":"### Survived\/Non-Survived Passenger Gender Distribution","a0c9897c":"### Age vs Survived","e9c5ce68":"# **Contents:**\n## ***1. Importing neccessary libraries***\n\n## ***2. Load data***\n\n## ***3. Data Cleaning***\n\n## ***4. Exploratory Data Analysis***\n\n## ***5. Feature Engineering***\n\n## ***6. Models***\n\n## ***7. Final Prediction on test set***","39177200":"### Kernel Density Plot - Fare Distribution Survived vs Non Survived","9ab2655e":"### Passenger Class Distribution - Survived vs Non-Survived","5d58d3e4":"### Bar plot for SibSp vs. Sex","65694b29":"## **Load Data**","f8f1ba3c":"## **Data Cleaning**","12c45a15":"# **Introduction**\nThis notebook is a very basic and simple introductory primer to understand how to go from raw datasets to accurate predictions. It covers all the steps that help in dealing with the data at hand, Efficiently!\n\nThe Titanic dataset is a prime candidate for introducing this as many newcomers to Kaggle start out here. ","3dc6256f":"## **Import Libraries**","de54020f":"### FacetGrid - Survived by Sex and Age","02898e17":"### Correlation among the predictions of different models"}}