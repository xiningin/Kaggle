{"cell_type":{"332eb551":"code","e0e4d4d5":"code","913bda2b":"code","894786f1":"code","3eea4a86":"code","a6deb2ce":"code","1763703a":"code","cca77806":"code","7390aae4":"code","cad499a5":"code","1aa9d09a":"code","525c1484":"code","6e9bad0c":"code","29c89aac":"code","2ec4dba7":"code","b770bd55":"code","28c4d5bb":"code","18b5e62b":"code","4324bacc":"code","75afd5d8":"code","195ee933":"code","ca7aa528":"code","b2fcf8e6":"code","29ea9675":"code","be222748":"code","93c9a613":"code","15a408a1":"code","b2b92211":"code","6cf91196":"code","9f5368c9":"markdown"},"source":{"332eb551":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e0e4d4d5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","913bda2b":"df = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv')","894786f1":"df.head()","3eea4a86":"df.count()","a6deb2ce":"df.info()","1763703a":"df['Province\/State'].value_counts()","cca77806":"sns.set_style('whitegrid')\nsns.heatmap(df.isna(), cmap='viridis')","7390aae4":"df['Country\/Region']","cad499a5":"df['Date']","1aa9d09a":"df['Province\/State'].isna().count()","525c1484":"# Because quantity of null values was greater than quantity of non-null values, \n# I opted to drop the entire column. Not sure if this is the optimal logic path to take.\ndf = df.drop('Province\/State', axis=1)\ndf.head()","6e9bad0c":"df['ConfirmedCases'].value_counts()","29c89aac":"sns.heatmap(df.isna(), cmap='viridis')","2ec4dba7":"df['Country\/Region'].unique()","b770bd55":"countries = pd.get_dummies(df['Country\/Region'], drop_first=True)\ndf.drop('Country\/Region', axis=1, inplace=True)\ndf = df.join(countries)\ndf.head()","28c4d5bb":"df.count()","18b5e62b":"df['Date']","4324bacc":"# Still working on this, perhaps, can also use NLP to get more info from dates\n# from datetime import datetime\n# def Object_To_Int(Date):\n  #  Date.date()\n# df['Date'] = df['Date'].apply(lambda date:Object_To_Int(date))","75afd5d8":"# Current plan is to drop Date column. Seems wrong because\n# date would offer a lot of insight into nature of disease.\ndf.drop('Date', axis=1, inplace=True)\ndf.head()","195ee933":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression","ca7aa528":"df.columns","b2fcf8e6":"X = df.drop(['Fatalities'], axis=1)\ny = df['Fatalities']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","29ea9675":"lm = LinearRegression()","be222748":"lm.fit(X_train, y_train)","93c9a613":"pred = lm.predict(X_test)","15a408a1":"fig = plt.figure(figsize=(12, 6))\nplt.scatter(y_test, pred)","b2b92211":"from sklearn.metrics import mean_squared_error","6cf91196":"print(np.sqrt(mean_squared_error(y_test, pred)))","9f5368c9":"Hello everyone. Hope you are doing well. I am currently learning how to work with different data sets. Don't worry too much about my model choice, however, I was wondering if you have any suggestions regarding how I could improve the data preparation process? Particularly how I dealt with null values seemed iffy here. Any general advice regarding resources I should look into, steps I should take when analyzing data sets, or corrections to certain approaches I chose would also be very helpful. Thank you, and have a great day!"}}