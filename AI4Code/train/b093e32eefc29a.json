{"cell_type":{"fd0aad56":"code","19a6f7ce":"code","60eea448":"code","5a440cd5":"code","8c876521":"code","2c178dc4":"code","b1c24379":"code","8577218f":"code","9845ef69":"code","a58ba74f":"code","c4525012":"code","c8aad7be":"code","5652c075":"code","0e784bee":"code","5eb45d46":"code","d5c6d5ef":"code","81453e34":"code","f7dea4bf":"markdown","cbbefb53":"markdown","caf58887":"markdown","2a5bc17d":"markdown","b221fede":"markdown"},"source":{"fd0aad56":"from pathlib import Path\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torchvision.transforms.functional as TF\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport torch.optim as optim\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2 \nfrom catalyst.contrib.nn import DiceLoss, IoULoss\nfrom catalyst.dl import SupervisedRunner\nfrom catalyst import dl\nfrom torch.nn import BCEWithLogitsLoss\n\nimport numpy as np\nimport os\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nIMAGE_DIR = '..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/images'\nMASK_DIR = '..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/masks'\nIMAGE_HEIGHT = 200\nIMAGE_WIDTH = 200\nBATCH_SIZE = 4","19a6f7ce":"path_img = Path(IMAGE_DIR)\nimg_list = list(path_img.glob('*.png'))\npath_mask = Path(MASK_DIR)\nmask_list = list(path_mask.glob('*.png'))","60eea448":"class FullBodySegmentation(data.Dataset):\n    def __init__(self, inputs: list, targets: list, transform=None):\n        super().__init__() \n        self.inputs = inputs\n        self.targets = targets\n        self.transform = transform\n        \n    def __len__(self,):\n        return len(self.inputs)\n    \n    def __getitem__(self, idx : int):\n        \n        input_image = self.inputs[idx]\n        target_image = self.targets[idx]\n\n        image = np.array(Image.open(input_image).convert(\"RGB\"))\n        mask = np.array(Image.open(target_image).convert(\"L\"), dtype=np.float32)\n        mask = mask \/ 255\n\n        if self.transform is not None:\n            augmentations = self.transform(image=image, mask=mask)\n            image = augmentations[\"image\"]\n            mask = augmentations[\"mask\"]\n        return image, mask\n","5a440cd5":"x_data, x_test ,y_data, y_test = train_test_split(\n                                            img_list,\n                                            mask_list,\n                                            test_size=0.1, \n                                            random_state=42, \n                                            shuffle=True)\n\nx_train, x_val ,y_train, y_val = train_test_split(\n                                            x_data,\n                                            y_data,\n                                            test_size=0.1, \n                                            random_state=42, \n                                            shuffle=True)","8c876521":"def get_loaders(\n    train_dir,\n    train_maskdir,\n    val_dir,\n    val_maskdir,\n    test_dir,\n    test_maskdir,   \n    batch_size,\n    train_transform,\n    val_transform,\n    num_workers=4,\n    pin_memory=True,\n):\n    train_ds = FullBodySegmentation(\n        inputs=train_dir,\n        targets=train_maskdir,\n        transform=train_transform,\n    )\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=True,\n    )\n\n    val_ds = FullBodySegmentation(\n        inputs=val_dir,\n        targets=val_maskdir,\n        transform=val_transform,\n    )\n\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=False,\n    )\n    test_ds = FullBodySegmentation(\n        inputs=test_dir,\n        targets=test_maskdir,\n        transform=val_transform,\n    )\n\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=False,\n    )\n    return train_loader, val_loader, test_loader","2c178dc4":"train_transform = A.Compose(\n    [\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n        A.Rotate(limit=35, p=1.0),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.1),\n        A.Normalize(),\n        ToTensorV2(),\n    ],\n)\n\nval_transform = A.Compose(\n    [\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n        A.Normalize(),\n        ToTensorV2(),\n    ],\n)","b1c24379":" train_loader, val_loader, test_loader = get_loaders(\n                                            x_train,\n                                            y_train,\n                                            x_val,\n                                            y_val,\n                                            x_test,\n                                            y_test,   \n                                            BATCH_SIZE,\n                                            train_transform,\n                                            val_transform,\n                                            num_workers=2,\n                                            pin_memory=True,\n                                        )\nloaders = {\"train\": train_loader, \"valid\": val_loader}","8577218f":"print(f'Length of the train data: {len(train_loader)*BATCH_SIZE} images')\nprint(f'Length of the validation_data: {len(val_loader)*BATCH_SIZE} images')\nprint(f'Length of the test data: {len(test_loader)*BATCH_SIZE} images')","9845ef69":"train_image, train_mask = next(iter(train_loader))\nval_image, val_mask = next(iter(val_loader))\nprint(f'Shape of input images:\\n train -  {train_image.shape},\\n val -  {val_image.shape}')","a58ba74f":"print(\"Check that the mask images in [0,1] range\")\nprint(f'Shape of input masks:\\n train -  {train_mask.shape},\\n val -  {val_mask.shape}')\nprint(f'Train mask values: \\n max - {train_mask.max()} \\n min - {train_mask.min()}')\nprint(f'Validate mask values: \\n max - {val_mask.max()} \\n min - {val_mask.min()}')","c4525012":"fig, axs = plt.subplots(2,4,figsize=(15,15))\n\nfor batch in val_loader:\n    images,mask_target = batch\n    for i in range(len(images)+len(mask_target)):\n        if i <len(images):\n            axs[0,i].imshow(images[i].permute(1,2,0).cpu().numpy())\n        else:\n            axs[1,i%4].imshow(mask_target[i%4].cpu().numpy(),cmap='gray')","c8aad7be":"from catalyst.contrib.models.cv.segmentation.unet import Unet\n\nmodel = Unet()","5652c075":"class CustomRunner(dl.Runner):\n    def predict_batch(self, batch):\n        # model inference step\n        return self.model(batch[0].to(self.device))\n    def handle_batch(self, batch):\n        x, y = batch\n        #logits = self.model(x)['out'].squeeze(1)\n        logits = self.model(x).squeeze(1)\n        binar = torch.sigmoid(logits)\n        num_classes = logits.shape[-1]\n        self.batch = {\n            \"features\": x,\n            \"logits\": logits,\n            \"targets\": y,\n            \"binar\": binar,\n        }","0e784bee":"criterion = {\n    \"dice\": DiceLoss(),\n    \"iou\": IoULoss(),\n    \"bce\": BCEWithLogitsLoss()\n}\noptimizer = torch.optim.Adam(model.parameters())\nscheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n# training\nrunner = CustomRunner()\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=loaders,\n    logdir=\".\/logdir\",\n    valid_loader=\"valid\",\n    valid_metric=\"loss\",\n    minimize_valid_metric=True,\n    num_epochs=10,\n    callbacks=[\n        dl.CriterionCallback(\n            input_key=\"binar\",\n            target_key=\"targets\",\n            metric_key=\"loss_dice\",\n            criterion_key=\"dice\",\n        ),\n        dl.CriterionCallback(\n            input_key=\"binar\",\n            target_key=\"targets\",\n            metric_key=\"loss_iou\",\n            criterion_key=\"iou\",\n        ),\n        dl.CriterionCallback(\n            input_key=\"logits\",\n            target_key=\"targets\",\n            metric_key=\"loss_bce\",\n            criterion_key=\"bce\",\n        ),\n        # loss aggregation\n        dl.MetricAggregationCallback(\n            metric_key=\"loss\",\n            metrics={\"loss_dice\": 1.0, \"loss_iou\": 1.0, \"loss_bce\": 0.8},\n            mode=\"weighted_sum\",\n        ),\n        dl.OptimizerCallback(metric_key=\"loss\"),\n    ],\n)","5eb45d46":"fig, axs = plt.subplots(3,4,figsize=(15,15))\nmodel.eval()\nfor batch in test_loader:\n    images,mask = batch\n    batch_preds = torch.sigmoid(model(images.to(device)) )\n    batch_preds = batch_preds.detach().cpu()  \n    for i in range(len(images)+len(mask)+len(images)):\n        if i <len(images):\n            axs[0,i].imshow(batch_preds[i].squeeze(0).cpu().numpy(),cmap='gray')\n        elif i >=len(images) and i<(len(images)+len(mask)):\n            axs[1,i%4].imshow(images[i%4].permute(1,2,0).cpu().numpy())\n        else:\n            axs[2,i%4].imshow(mask[i%4].cpu().numpy(),cmap='gray')","d5c6d5ef":"model.eval\nwith torch.no_grad():\n    loss = 0\n    criterion_bce = torch.nn.BCEWithLogitsLoss()\n    for batch in val_loader:\n        image, mask = batch[0].cuda(), batch[1].cuda()\n        result = model(image)\n        result = result.squeeze(1)\n        loss_bce = criterion_bce(result, mask) \n        loss +=  loss_bce.item()* image.size(0)\n    epoch_loss = loss \/ len(val_loader)\n    print(\"--------------------\")\n    print(epoch_loss)","81453e34":"model.eval\nwith torch.no_grad():\n    loss = 0\n    criterion_bce = torch.nn.BCEWithLogitsLoss()\n    for batch in test_loader:\n        image, mask = batch[0].cuda(), batch[1].cuda()\n        result = model(image)\n        result = result.squeeze(1)\n        loss_bce = criterion_bce(result, mask) \n        loss +=  loss_bce.item()* image.size(0)\n    epoch_loss = loss \/ len(val_loader)\n    print(\"--------------------\")\n    print(epoch_loss)","f7dea4bf":"# 1) Import libraries and set hyperparameters","cbbefb53":"# Body segmentation with Catalyst\n\n   The purpose of this work is find out how to use Catalyst for the segmentation task.Make a pipeline for this, using only catalyst.\n    Catalyst is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop.","caf58887":"# 2) Prepare data","2a5bc17d":"# 4) Make a training loop\n   Let's take UNET model from catalyst library","b221fede":"# 3) Let's look at the data and check it"}}