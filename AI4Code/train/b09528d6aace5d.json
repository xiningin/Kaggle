{"cell_type":{"a1d94dbb":"code","1255c701":"code","2cb563d1":"code","f9fa1501":"code","eb23134c":"code","118db219":"code","985e989f":"code","4973e389":"code","e32f95fe":"code","c76db370":"code","b44b29fd":"code","2539f926":"code","5d89070f":"code","449cbf13":"code","9bc8f453":"code","62155a2e":"code","71264a69":"code","79001cc4":"code","31bc234d":"code","09c8d419":"code","c01fcfbc":"code","84d002f1":"code","08942674":"code","32bee335":"code","5d25ed65":"code","84088065":"code","d286c2a5":"code","60aa2465":"code","8f87aa8a":"code","1cba3f7d":"code","1134d7f3":"code","74f0ec56":"markdown","0aa3dbea":"markdown","2925c03a":"markdown","35165b43":"markdown","8121b20d":"markdown","4b811612":"markdown","de15a13b":"markdown","5e30b982":"markdown","50803c1b":"markdown","d7745078":"markdown","d7183839":"markdown","fcab2570":"markdown","adbb5e13":"markdown","3a19bff0":"markdown","4abf0629":"markdown","e85246e1":"markdown","22760102":"markdown","bc8f0941":"markdown","cf9b5df7":"markdown","4d03f6ef":"markdown","e550c4d1":"markdown","1a57d138":"markdown"},"source":{"a1d94dbb":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\n\nK.set_image_data_format('channels_last')","1255c701":"print(os.listdir(\"..\/input\"))","2cb563d1":"path = \"..\/input\/train\/\"\nfile_list = os.listdir(path)\nfile_list[:20]","f9fa1501":"reg = re.compile(\"[0-9]+\")\n\ntemp1 = list(map(lambda x: reg.match(x).group(), file_list)) \ntemp1 = list(map(int, temp1))\n\ntemp2 = list(map(lambda x: reg.match(x.split(\"_\")[1]).group(), file_list))\ntemp2 = list(map(int, temp2))\n\nfile_list = [x for _,_,x in sorted(zip(temp1, temp2, file_list))]\nfile_list[:20]","eb23134c":"train_image = []\ntrain_mask = []\nfor idx, item in enumerate(file_list):\n    if idx % 2 == 0:\n        train_image.append(item)\n    else:\n        train_mask.append(item)\n        \nprint(train_image[:10],\"\\n\" ,train_mask[:10])","118db219":"# Display the first image and mask of the first subject.\nimage1 = np.array(Image.open(path+\"1_1.tif\"))\nimage1_mask = np.array(Image.open(path+\"1_1_mask.tif\"))\nimage1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n\nfig, ax = plt.subplots(1,3,figsize = (16,12))\nax[0].imshow(image1, cmap = 'gray')\n\nax[1].imshow(image1_mask, cmap = 'gray')\n\nax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\nax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)","985e989f":"## Storing data\nX = []\ny = []\nfor image, mask in zip(train_image, train_mask):\n    X.append(np.array(Image.open(path+image)))\n    y.append(np.array(Image.open(path+mask)))","4973e389":"X = np.array(X)\ny = np.array(y)\n\nprint(\"X_shape : \", X.shape)\nprint(\"y_shape : \", y.shape)","e32f95fe":"mask_df = pd.read_csv(\"..\/input\/train_masks.csv\")\nmask_df.head()","c76db370":"width = 580\nheight = 420\n\ntemp = mask_df[\"pixels\"][0]\ntemp = temp.split(\" \")","b44b29fd":"mask1 = np.zeros(height * width)\nfor i, num in enumerate(temp):\n    if i % 2 == 0:\n        run = int(num) -1             # very first pixel is 1, not 0\n        length = int(temp[i+1])\n        mask1[run:run+length] = 255 \n\n#Since pixels are numbered from top to bottom, then left to right, we are careful to change the shape\nmask1 = mask1.reshape((width, height))\nmask1 = mask1.T ","2539f926":"(mask1 != y[0]).sum()","5d89070f":"# RLE : run-length-encoding\ndef RLE_to_image(rle):\n    '''\n    rle : array in mask_df[\"pixels\"]\n    '''\n    width, height = 580, 420\n    \n    if rle == 0:\n        return np.zeros((height,width))\n    \n    else:\n        rle = rle.split(\" \")\n        mask = np.zeros(width * height)\n        for i, num in enumerate(rle):\n            if i % 2 == 0:\n                run = int(num) - 1\n                length = int(rle[i+1])\n                mask[run:run+length] = 255\n\n        mask = mask.reshape((width, height))\n        mask = mask.T \n\n        return mask","449cbf13":"print(\"The number of train data : \", X.shape[0])","9bc8f453":"mask_df.head()\nsubject_df = mask_df[['subject', 'img']].groupby(by = 'subject').agg('count').reset_index()\nsubject_df.columns = ['subject', 'N_of_img']\nsubject_df.sample(10)","62155a2e":"pd.value_counts(subject_df['N_of_img']).reset_index()","71264a69":"print(os.listdir(\"..\/input\/test\")[0:15])","79001cc4":"from keras.models import Model, Input, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","31bc234d":"# Randomly choose the indices of data used to train our model.\nindices = np.random.choice(range(len(train_image)), replace = False ,size = 100)\ntrain_image_sample = np.array(train_image)[indices]\ntrain_mask_sample = np.array(train_mask)[indices]","09c8d419":"# Build the dataset.\nIMG_HEIGHT = 96\nIMG_WIDTH = 96\n\nX = np.empty(shape = (len(indices), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\ny = np.empty(shape = (len(indices), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n\nfor i, (image_path, mask_path) in enumerate(zip(train_image_sample, train_mask_sample)):\n    image = cv2.imread(\"..\/input\/train\/\" + image_path, 0)\n    mask = cv2.imread(\"..\/input\/train\/\" + mask_path, 0)\n    \n    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n    mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n    \n    X[i] = image\n    y[i] = mask\n\nX = X[:,:,:,np.newaxis] \/ 255\ny = y[:,:,:,np.newaxis] \/ 255\nprint(\"X shape : \", X.shape)\nprint(\"y shape : \", y.shape)","c01fcfbc":"smooth = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","84d002f1":"inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\nup6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\nup7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\nup8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\nup9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\nconv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])\nmodel.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[dice_coef])","08942674":"results = model.fit(X, y, validation_split=0.1, batch_size=4, epochs=20)","32bee335":"def Generator(X_list, y_list, batch_size = 16):\n    c = 0\n\n    while(True):\n        X = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n        y = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n        \n        for i in range(c,c+batch_size):\n            image = cv2.imread(\"..\/input\/train\/\" + X_list[i], 0)\n            mask = cv2.imread(\"..\/input\/train\/\" + y_list[i], 0)\n    \n            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n            mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n    \n            X[i - c] = image\n            y[i - c] = mask\n        \n        X = X[:,:,:,np.newaxis] \/ 255\n        y = y[:,:,:,np.newaxis] \/ 255\n        \n        c += batch_size\n        if(c+batch_size >= len(X_list)):\n            c = 0\n        yield X, y    ","5d25ed65":"X_train, X_val, y_train, y_val = train_test_split(train_image, train_mask, test_size = 0.3, random_state = 1)\n\nepochs = 10\nbatch_size = 8\nsteps_per_epoch = int(len(X_train) \/ batch_size)\nvalidation_steps = int(len(X_val) \/ batch_size)\n\ntrain_gen = Generator(X_train, y_train, batch_size = batch_size)\nval_gen = Generator(X_val, y_val, batch_size = batch_size)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])\nmodel.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[dice_coef])","84088065":"history = model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch, epochs = epochs,\n                             validation_data = val_gen, validation_steps = validation_steps)","d286c2a5":"sub = pd.read_csv(\"..\/input\/sample_submission.csv\")\ntest_list = os.listdir(\"..\/input\/test\")\n\nprint(\"The number of test data : \", len(test_list))\n\n# Sort the test set in ascending order.\nreg = re.compile(\"[0-9]+\")\n\ntemp1 = list(map(lambda x: reg.match(x).group(), test_list)) \ntemp1 = list(map(int, temp1))\n\ntest_list = [x for _,x in sorted(zip(temp1, test_list))]\n\ntest_list[:15]","60aa2465":"X_test = np.empty((len(test_list), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\nfor i, item in enumerate(test_list):\n    image = cv2.imread(\"..\/input\/test\/\" + item, 0)\n    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n    X_test[i] = image\nX_test = X_test[:,:,:,np.newaxis] \/ 255\n\ny_pred = model.predict(X_test)","8f87aa8a":"def run_length_enc(label):\n    from itertools import chain\n    x = label.transpose().flatten()\n    y = np.where(x > 0)[0]\n    if len(y) < 10:  # consider as empty\n        return ''\n    z = np.where(np.diff(y) > 1)[0]\n    start = np.insert(y[z+1], 0, y[0])\n    end = np.append(y[z], y[-1])\n    length = end - start\n    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n    res = list(chain.from_iterable(res))\n    return ' '.join([str(r) for r in res])","1cba3f7d":"rles = []\nfor i in range(X_test.shape[0]):\n    img = y_pred[i, :, :, 0]\n    img = img > 0.5\n    img = resize(img, (420, 580), preserve_range=True)\n    rle = run_length_enc(img)\n    rles.append(rle)\n    if i % 100 == 0:\n            print('{}\/{}'.format(i, X_test.shape[0]), end = \"\\r\")","1134d7f3":"sub['pixels'] = rles\nsub.to_csv(\"submission.csv\", index = False)","74f0ec56":"It worked !! This was my first semantic segmentation models :)<br\/>\nLet's keep going on !","0aa3dbea":"**Sort the file list in ascending order and seperate it into images and masks**<br\/>\nEach file has the form of either \"subject_imageNum.tif\" or \"subject_imageNum_mask.tif\", so we can extract `subject` and `imageNum` from each file name by using regular expression. `\"[0-9]+\"` means to find the first consecutive number.<br\/>","2925c03a":"## How to deal with train_masks.csv ?","35165b43":"Each test image name is numbered in different way, so we cannot exploit subject information when we predict test data.","8121b20d":"**How to deal with `pixels` column ?**<br\/>\nLet me try to convert the first `pixels` column to the mask image.<br\/>\nActually, this work could be not necessary, since we are provided mask_image. But other competition that I want to join provide only run length encoded data, so I do this to practice. ","4b811612":"Let's build U-net model. I also refered to this [site](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/train.py). ","de15a13b":"## Exploratory data analysis\nFirst of all, let's check how many train data we have.","5e30b982":"## Let's define U-net and train our model by using 100 data\nSince the whole data size is quite big, it may lead to over-memory if we load whole data on X and y as we did earier. <br\/>\nSo our strategy is to use `data generator` that allow us to load a few of data and to use them to train our model.<br\/>\nBefore that, we first use only 100 data to check our model works well","50803c1b":"In order to define data generator, I refer this [site](https:\/\/towardsdatascience.com\/a-keras-pipeline-for-image-segmentation-part-1-6515a421157d)  ","d7745078":"Now we define the dice loss and metrics. I refered to this [site](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/train.py).","d7183839":"If you load images by using cv2.imread(filepath), it gives you image as data type \"np.darray\"<br\/>","fcab2570":"It gives me 0.44690 score.","adbb5e13":"## Define image_generator","3a19bff0":"Hi, I am a semantic segmentation beginner.(I'm sorry for my poor English in advance)<br\/>\n(I refered to many part of this [site](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/submission.py))","4abf0629":"## Let's predict the test data set.","e85246e1":"One can find the number of subjects in train data by `groupby` method on `mask_df`.","22760102":"I refered to the this [site](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/submission.py) to submit my prediction","bc8f0941":"Now, I try to load all image files and store them variables X and y. Afther doing this, I recognize that it takes very much memory.<br\/>\nPlease let me know if there are several efficient ways to store image file","cf9b5df7":"## Building the training dataset.\nLet's look at the train image list","4d03f6ef":"There are total 47 subjects and almost almost all subjects have 120 images except for 5 subjects who have 119 images.<br\/>\nI want to know whether test dataset has similar distribution or not. Let's check this by using the similar way when we listed the train data.","e550c4d1":"Let's check that I did well","1a57d138":"Let's modularize this work."}}