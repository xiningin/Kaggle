{"cell_type":{"27dff754":"code","42389de9":"code","9daeb285":"code","26143580":"code","8668076b":"code","98ae38fe":"code","d3c94035":"code","29c361ca":"code","6e52d89d":"code","f79a9df6":"code","a9b86b53":"code","f48eb4f3":"code","e190277f":"code","35711ab4":"code","f26d5059":"markdown","3cfecf89":"markdown","3e2115a8":"markdown","3221b449":"markdown"},"source":{"27dff754":"import os\nimport zipfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\nimport random\nimport numpy as np\n\nfrom google.colab import files\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","42389de9":"#load premade training model to shorten the time\n!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","9daeb285":"local_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","26143580":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/cats_and_dogs_filtered.zip \\\n    -O \/tmp\/cats_and_dogs_filtered.zip","8668076b":"local_zip = '\/tmp\/cats_and_dogs_filtered.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp')\nzip_ref.close()\n\nbase_dir = '\/tmp\/cats_and_dogs_filtered'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\n\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')","98ae38fe":"print('total training cats images:', len(os.listdir(train_cats_dir)))\nprint('total training dogs images:', len(os.listdir(train_dogs_dir)))\nprint('total validation cats images:', len(os.listdir(validation_cats_dir)))\nprint('total validation dogs images:', len(os.listdir(validation_dogs_dir)))","d3c94035":"train_cat_names = os.listdir( train_cats_dir )\ntrain_dog_names = os.listdir( train_dogs_dir )\nvalidation_dog_names = os.listdir( validation_cats_dir )\nvalidation_dog_names = os.listdir( validation_dogs_dir)\n\nprint(train_cat_names[:10])\nprint(train_dog_names[:10])\nprint(validation_dog_names[:10])\nprint(validation_dog_names[:10])","29c361ca":"nrows = 4\nncols = 4\npic_index = 0\n\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\npic_index += 8\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_names[pic_index-8:pic_index]]\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_names[pic_index-8:pic_index]]\n\nfor i, img_path in enumerate(next_cat_pix + next_dog_pix):\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') \n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","6e52d89d":"# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(\n                                    rescale=1.\/255,\n                                    rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    fill_mode='nearest' \n                                   )\n\ntest_datagen  = ImageDataGenerator(rescale = 1.0\/255.)\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(\n                                                    train_dir,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150)\n                                                    )     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory(\n                                                        validation_dir,\n                                                        batch_size=20,\n                                                        class_mode  = 'binary',\n                                                        target_size = (150, 150)\n                                                         )","f79a9df6":"class myCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if(logs.get('accuracy')>.95):\n                print(\"\\nReached 95 % accuracy so cancelling training!\")\n                self.model.stop_training = True\ncallbacks = myCallback()                ","a9b86b53":"pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x)","f48eb4f3":"optimizer = keras.optimizers.Adam(lr=.0001)\nmodel.compile(\n                loss='binary_crossentropy',\n                optimizer = optimizer,\n                metrics=['accuracy']\n              )","e190277f":"history=model.fit(\n                    train_generator,  \n                    validation_data = validation_generator,\n                    epochs=20,\n                    steps_per_epoch = 100,\n                    validation_steps = 50,\n                    verbose = 2,\n                    callbacks=[callbacks]\n                  )\n","35711ab4":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1 , len(acc) + 1)\n\nplt.plot(epochs , acc , 'b' , label = 'Training accuracy' )\nplt.plot(epochs , val_acc, 'r' , label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\n\nplt.legend()\nplt.rc('font', size = 15)\nplt.rc('figure', figsize=[10,10])\nplt.show()\n","f26d5059":"<a href=\"https:\/\/colab.research.google.com\/github\/mohnabil2020\/machine_learning\/blob\/master\/Cats_%26_Dogs_Classifier.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","3cfecf89":"**This notebook is for classifying  between dogs and cats**\n\n---\n[github link to view better](https:\/\/github.com\/mohnabil2020\/machine_learning\/blob\/master\/9\/Cats_&_Dogs_classifier.ipynb)\n\n\n---\n***My target is :***\n\n\n1.   Increasing accuracy rate and decreasing loss rate as possible\n2.   Prevent overfitting \n\n1.   Reach accuracy >= 95% and stop the training immediately\n2.   Shorten the time of training by using transfer learning \n\n\n\n**hint** maybe you will see errors because I am using collab to store data so use collab to unseen errors\n\n","3e2115a8":"**This chart shows that I stopped overfitting from being occuered**\n\n---\n\n\n\n---\n\n","3221b449":"![](https:\/\/drive.google.com\/file\/d\/1U_1VcN0NM4GfnjemKq72Hh4VnFeMGD5E\/view?usp=sharing)"}}