{"cell_type":{"920ed949":"code","e3502a8d":"code","175df30f":"code","b2f50bc3":"code","cb8e600f":"code","d9d6b3f4":"code","742fd84e":"code","e9dddaaa":"code","6e4bb6d0":"code","7be0723f":"code","4d05af9d":"code","f6a6fad1":"code","578a7e62":"code","74e80438":"code","81528e8c":"code","36efdcc7":"code","849c539b":"code","0304ea39":"code","e81ebc1f":"code","448df236":"code","58cb26a4":"code","827c4867":"code","f346e96b":"code","16b61da7":"code","847098e9":"code","3237c192":"code","8a879b21":"code","80d709a7":"code","224315dc":"code","9d2a2650":"code","6cebc0b0":"code","f500648d":"code","dbc74f5c":"code","60187ff7":"code","9156c0c7":"markdown","cb2f7d7f":"markdown","2fabdbc7":"markdown","fb36c114":"markdown","08dba007":"markdown","06ff12cb":"markdown","431dc818":"markdown","496024ca":"markdown","d98afaf9":"markdown","0acd9de4":"markdown","42795411":"markdown","f9ecd75b":"markdown","5f773aa9":"markdown","e8531f31":"markdown","ced26896":"markdown","dfdc79d4":"markdown","9044e956":"markdown"},"source":{"920ed949":"DATA_PATH = '..\/input\/shopee-product-matching\/'\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook","e3502a8d":"train = pd.read_csv(DATA_PATH + 'train.csv')\ntrain['image'] = DATA_PATH + 'train_images\/' + train['image']\ntrain.head()","175df30f":"train.info()","b2f50bc3":"tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\ntrain.head()","cb8e600f":"len(train.label_group.unique())","d9d6b3f4":"train_label = train.groupby('label_group').posting_id.count().sort_values(ascending=False)\ntrain_label","742fd84e":"pd.cut(train_label, bins=[0, 10, 20, 30, 40, 51]).value_counts()","e9dddaaa":"def findByLabel(label_group_idx, figscale=2):\n    train_a = train[train.label_group == label_group_idx].reset_index()\n    count = len(train_a)\n    showImgNumber = count\n    if count > 5:\n        col = 5\n        row = int(np.ceil(count\/col))  \n    else:\n        row = 1\n        col = count\n    fig, ax = plt.subplots(row, col, figsize=(col*figscale, row*figscale))\n    \n    if row == 1:\n        for j in range(col):\n            if showImgNumber == 0: break\n            ax[j].imshow(cv2.imread(train_a.image[showImgNumber-1]))\n            ax[j].set_xticks([])\n            ax[j].set_yticks([])\n            showImgNumber-=1\n    else:\n        for i in range(row):\n            for j in range(col):\n                if showImgNumber == 0: break\n                ax[i, j].imshow(cv2.imread(train_a.image[showImgNumber-1]))\n                ax[i, j].set_xticks([])\n                ax[i, j].set_yticks([])\n                \n                showImgNumber-=1\n    fig.text(0.1, 0.95, 'label_group: {}'.format(label_group_idx))\n    return train_a","6e4bb6d0":"findByLabel(1163569239)\nplt.show()","7be0723f":"findByLabel(3627744656)\nplt.show()","4d05af9d":"findByLabel(2141883596)\nplt.show()","f6a6fad1":"findByLabel(train.label_group[10])\nplt.show()","578a7e62":"findByLabel(train.label_group[10000])\nplt.show()","74e80438":"train.groupby('image_phash').posting_id.count().sort_values(ascending=False)","81528e8c":"train[train.image_phash == 'fad28daa2ad05595'].label_group.unique()","36efdcc7":"findByLabel(997220911)\nplt.show()","849c539b":"train[train.image_phash == 'd0c0ea37bd9acce0'].label_group.unique()","0304ea39":"image_path = train[train.image_phash == 'd0c0ea37bd9acce0'].image.to_list()\nidx = 20 # len(image_path) = 20\nfig, ax = plt.subplots(2, 10, figsize=(20, 5))\nfor i in range(2):\n    for j in range(10):\n        if idx == 0: break\n        ax[i, j].imshow(cv2.imread(image_path[idx-1]))\n        idx-=1\nplt.show()   ","e81ebc1f":"findByLabel(4198148727)\nplt.show()","448df236":"findByLabel(2403374241)\nplt.show()","58cb26a4":"findByLabel(1960893869)\nplt.show()","827c4867":"def countHashinGroups(train):\n    hash_group = train.image_phash.unique()\n    count = 0\n    hash_li = []\n    count_li = []\n    for each in hash_group:\n        label_count = len(train[train.image_phash == each].label_group.unique())\n        if label_count > 1:\n            count += 1\n            hash_li.append(each) # collect the hash that are labelled wrongly in the dataset\n            count_li.append(label_count) # store the count to get more detail information\n    print('{:.2f}% of the image are labelled in more than 2 groups'.format(100*count\/len(hash_group)))\n    print('{} out of {} are labelled in more than 2 groups'.format(count, len(hash_group)))\n    return hash_li, count_li","f346e96b":"hash_li, count_li = countHashinGroups(train)","16b61da7":"plt.figure(figsize=(20, 5))\nplt.bar(range(len(count_li)), count_li, alpha=0.4)\nplt.show()","847098e9":"def showSameHash(phash):\n    df = train[train.image_phash==phash]\n    label_group = df.label_group.unique()\n    for label in label_group:\n        findByLabel(label)\n    plt.show()","3237c192":"count_li[19], hash_li[19]","8a879b21":"count_li[56], hash_li[56]","80d709a7":"df = train[train.image_phash==hash_li[19]]\ndf","224315dc":"showSameHash(hash_li[19])","9d2a2650":"showSameHash(hash_li[56])","6cebc0b0":"showSameHash(hash_li[-1])","f500648d":"import warnings\nwarnings.filterwarnings('ignore')","dbc74f5c":"def makeOneLabel(train, phash):\n    '''\n    input: dataset, phash\n        find the index of certain phash, and then find out the max count of label in new dataset. In the end, change all\n        label to the max-count label\n    output: dataset\n    '''\n    train_correct = train\n    train_hash = train[train.image_phash == phash]\n    idx = train_hash.index.tolist()\n    allLabels = train_hash.label_group.value_counts(ascending=False).index.tolist()\n    label = train_hash.label_group.value_counts(ascending=False).index[0]\n    train_correct.label_group.iloc[idx] = label\n    print('phash: {}, index: {}, \\n all label: {}, new label: {} \\n'.format(phash, idx, allLabels, label))\n    return train_correct","60187ff7":"for phash in hash_li:\n    train_correct = makeOneLabel(train, phash)","9156c0c7":"hash fad28daa2ad05595 is from one label group (997220911) --> make sense","cb2f7d7f":"## Check whether the pictures are similar in each label_goup","2fabdbc7":"hash d0c0ea37bd9acce0 is from more than one label groups([4198148727, 2403374241, 1960893869]) --> Interesting","fb36c114":"Data preprocessing is quite necessary before we feed our model.","08dba007":"# Preparation\nimport package\nset data_path","06ff12cb":"## Check how many labels in the label_group column","431dc818":"In this notebook, I will try to dive in the dataset to see if I can get some insights.","496024ca":"## groupby image_phash\nTo count pictures having the same image_phash","d98afaf9":"we try to pick one to figure out","0acd9de4":"# Correct the wrong label and re-label them","42795411":"Ok, it makes sense that same hash has same appearance.\nit seems some of the picture are labelled wrongly in the dataset, which could make noise for the later training.","f9ecd75b":"## Check how many images are labelled wrongly","5f773aa9":"## Check how many items in each label group","e8531f31":"# Analyzing","ced26896":"Let's check out!","dfdc79d4":"As we can see here, most of the label group only have less than 10 pictures. It may be a factor that affect the training process becasue of the lack of samples.","9044e956":"As we can see above, pictures from the same label_group may have different RGB, and person\/words included, which could bring obstacles for the classification."}}