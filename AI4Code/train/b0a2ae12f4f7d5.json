{"cell_type":{"43979c2f":"code","0ea1b245":"code","556d1ff8":"code","0f0e8095":"code","5c147e8f":"code","d87e8ccc":"code","43f0b5d5":"code","97d16223":"code","bb246394":"code","8f7a4483":"code","74cfc07e":"code","8fc01eeb":"code","c0f1d18d":"code","42b84650":"code","29404842":"code","3442de4a":"code","3c8afcf2":"code","71a18dd1":"code","b2c5f6a0":"code","c23267c5":"code","9d67e08e":"code","31568c8b":"code","0a6bf342":"code","a92cc903":"code","2a2bbb1a":"code","dee5d2e8":"code","07fb8ec1":"markdown","abc7bc77":"markdown","975b481c":"markdown","f2d40433":"markdown","352514d4":"markdown","33ba43af":"markdown","c24742f6":"markdown","f15a8072":"markdown","78bdd81c":"markdown","07358f4f":"markdown","2d657b51":"markdown"},"source":{"43979c2f":"# define network parameters\nmax_features = 20000\nmaxlen = 100","0ea1b245":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import Conv1D, GlobalMaxPool1D, Dropout, concatenate\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom IPython.display import clear_output","556d1ff8":"train = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\nlist_sentences_train = train[\"comment_text\"].fillna(\"Invalid\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values","0f0e8095":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\n# train data\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nX_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)","5c147e8f":"def build_model(conv_layers = 2, max_dilation_rate = 4):\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Dropout(0.25)(x)\n    x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    prefilt_x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    out_conv = []\n    # dilation rate lets us use ngrams and skip grams to process \n    for dilation_rate in range(max_dilation_rate):\n        x = prefilt_x\n        for i in range(3):\n            x = Conv1D(32*2**(i), \n                       kernel_size = 3, \n                       dilation_rate = 2**dilation_rate)(x)    \n        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n    x = concatenate(out_conv, axis = -1)    \n    x = Dense(64, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['binary_accuracy'])\n\n    return model\n\nmodel = build_model()","d87e8ccc":"batch_size = 512\nepochs = 15\n\nfile_path=\"weights.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n\ncallbacks_list = [checkpoint, early] #early\nmodel.fit(X_t, y, \n          batch_size=batch_size, \n          epochs=epochs, \n          validation_split=0.1, \n          callbacks=callbacks_list)\nmodel.load_weights(file_path)\nclear_output()","43f0b5d5":"eval_results = model.evaluate(X_t, y, batch_size=batch_size)\nfor c_name, c_val in zip(model.metrics_names, eval_results):\n    print(c_name, '%2.3f' % (c_val))","97d16223":"from glob import glob\nimport os\nimport dask.dataframe as ddf\nrustweet_dir = os.path.join('..', 'input', 'russian-troll-tweets')\nall_tweets_ddf = ddf.read_csv(os.path.join(rustweet_dir, '*.csv'), assume_missing=True)\nenglish_tweets_ddf = all_tweets_ddf[all_tweets_ddf['language'].isin(['English'])]\ncontent_cat_ddf = english_tweets_ddf[['content', 'account_category']]\nall_tweets_ddf","bb246394":"%%time\ncontent_cat_df = content_cat_ddf.sample(frac=0.2).compute().drop_duplicates()\nprint(content_cat_df.shape[0], 'tweets loaded')","8f7a4483":"fig, ax1 = plt.subplots(1,1, figsize = (15, 5))\ncontent_cat_df['account_category'].hist(ax=ax1)\ncontent_cat_df.sample(3)","74cfc07e":"# test data\nlist_tweets = content_cat_df[\"content\"].fillna(\"Invalid\").values\nlist_tokenized_tweets = tokenizer.texts_to_sequences(list_tweets)\nX_twe = sequence.pad_sequences(list_tokenized_tweets, maxlen=maxlen)","8fc01eeb":"# run the model on all data\ny_twe = model.predict(X_twe, batch_size=1024, verbose=True)","c0f1d18d":"toxicity_df = pd.DataFrame(y_twe, columns = list_classes)\ntoxicity_df['content_category'] = content_cat_df['account_category'].values.copy()\ntoxicity_df['total_hatefulness'] = np.sum(y_twe, 1)","42b84650":"sns.pairplot(toxicity_df, hue = 'content_category')","29404842":"from IPython.display import Markdown, display\ndisplay_markdown = lambda x: display(Markdown(x))\ndef show_sentence(sent_idx):\n    display_markdown('# Input Sentence:\\n `{}`'.format(list_tweets[sent_idx]))\n    c_pred = model.predict(X_twe[sent_idx:sent_idx+1])[0]\n    display_markdown('## Scores')\n    for k, p in zip(list_classes, c_pred):\n        display_markdown('- {}, Prediction: {:2.2f}%'.format(k, 100*p))\nshow_sentence(50)","3442de4a":"worst_tweets = np.argsort(-1*toxicity_df['total_hatefulness'].values)\nfor _, idx in zip(range(5), \n                  worst_tweets):\n    show_sentence(idx)","3c8afcf2":"toxicity_df.groupby('content_category').agg(lambda x: round(100*np.mean(x))).reset_index().sort_values('total_hatefulness', ascending=False)","71a18dd1":"toxicity_df.groupby('content_category').agg(lambda x: round(100*np.max(x))).reset_index().sort_values('total_hatefulness', ascending=False)","b2c5f6a0":"cat_sample_df = toxicity_df.groupby('content_category').apply(lambda x: x.sample(250, replace=False if x.shape[0]>1000 else True)).reset_index(drop=True)\nsns.factorplot(y='content_category', x='identity_hate', kind='swarm', data=cat_sample_df, size=5)","c23267c5":"# rescale the axes a bit\nclip_tox_df = toxicity_df.copy()\nfor c_class in list_classes:\n    clip_tox_df[c_class] = np.sqrt(np.clip(clip_tox_df[c_class], 0, .025))","9d67e08e":"sns.factorplot(y='content_category', x='identity_hate', kind='violin', data=clip_tox_df)","31568c8b":"sns.factorplot(y='content_category', x='threat', kind='violin', data=clip_tox_df, size=5)","0a6bf342":"from sklearn.model_selection import train_test_split\ntx_train_df, tx_valid_df = train_test_split(toxicity_df, \n                                            test_size = 0.25,\n                                            random_state = 2018,\n                                            stratify=toxicity_df['content_category'])","a92cc903":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.dummy import DummyClassifier\ndmc = DummyClassifier()\ndef fit_and_show(in_skl_model):\n    in_skl_model.fit(tx_train_df[list_classes], tx_train_df['content_category'])\n    out_pred = in_skl_model.predict(tx_valid_df[list_classes])\n    print('%2.2f%%' % (100*accuracy_score(out_pred, tx_valid_df['content_category'])), 'accuracy')\n    print(classification_report(out_pred, tx_valid_df['content_category']))\n    sns.heatmap(confusion_matrix(tx_valid_df['content_category'], out_pred))\nfit_and_show(dmc)","2a2bbb1a":"from sklearn.linear_model import LogisticRegression\nlrm = LogisticRegression()\nfit_and_show(lrm)","dee5d2e8":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nfit_and_show(rfc)","07fb8ec1":"## Show a few random tweets","abc7bc77":"## Which bots are the most ","975b481c":"## Sequence Generation\nHere we take the data and generate sequences from the data","f2d40433":"# Load the tweets of the IRA Bots\nSince it is multiple large CSV files we use dask to handle the loading easier. We then focus on the tweet itself (`content`) and the category (`account_category`) to see if our hate-speech model shows similar results ","352514d4":"# Testing some ideas\nHere we show the average and maximum hatred from the various russian bots based on category and interestingly the LeftTroll is both more hateful on average and in peak than the RightTroll\n","33ba43af":"# Overview\nWe first train a simple Convolutional Neural Network model to recognize various types of hate speech by word patterns using the data from the Kaggle competition from Jigsaw. \nWe then apply it to the tweets associated with the bots of the Internet Research Agency (IRA) of Russia to try and characterize them and see if this matches well and if the hate speech model gives us any insights into the tweets.","c24742f6":"# Can we reclassify bots based on the hate-speech scores?","f15a8072":"## Show the results as reference\nSince we clear out all the training data","78bdd81c":"# Train the Model\nHere we train the model and use model checkpointing and early stopping to keep only the best version of the model","07358f4f":"## Show the worst tweets\nHere we try and find the highest scoring tweets from the model to see how offensive they are (and yikes they are offensive)","2d657b51":"# Load and Preprocessing Steps\nHere we load the data and fill in the misisng values"}}