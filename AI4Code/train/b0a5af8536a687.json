{"cell_type":{"0301ad2f":"code","0501e439":"code","1e78b6f0":"markdown"},"source":{"0301ad2f":"import pandas as pd\nimport numpy as np\nimport os\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import pearsonr\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras import backend as K\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)\nimport ubiquant","0501e439":"def build_model(shape):\n    def fc_block(x, units):\n        x = tf.keras.layers.Dropout(0.35)(x)\n        x = tf.keras.layers.Dense(units, activation = 'relu')(x)\n        return x\n\n    inp = tf.keras.layers.Input((shape))\n    x = fc_block(inp, units = 768)\n    x = fc_block(x, units = 384)\n    x = fc_block(x, units = 192)\n    output = tf.keras.layers.Dense(1, activation = 'linear')(x)\n    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n    return model\n\n# Get our features list\nfeatures = list(np.load('..\/input\/ubiquant-tf-training-baseline-with-tpu\/features.npy'))\ncorr_features = list(np.load('..\/input\/ubiquant-tf-training-baseline-with-tpu\/best_corr.npy'))\n# Build 5 models and load 5 fold weights\nmodel1 = build_model(len(features))\nmodel2 = build_model(len(features))\nmodel3 = build_model(len(features))\nmodel4 = build_model(len(features))\nmodel5 = build_model(len(features))\nmodel1.load_weights('..\/input\/ubiquant-tf-training-baseline-with-tpu\/simple_fc_dnn_1.h5')\nmodel2.load_weights('..\/input\/ubiquant-tf-training-baseline-with-tpu\/simple_fc_dnn_2.h5')\nmodel3.load_weights('..\/input\/ubiquant-tf-training-baseline-with-tpu\/simple_fc_dnn_3.h5')\nmodel4.load_weights('..\/input\/ubiquant-tf-training-baseline-with-tpu\/simple_fc_dnn_4.h5')\nmodel5.load_weights('..\/input\/ubiquant-tf-training-baseline-with-tpu\/simple_fc_dnn_5.h5')\nmodels = [model1, model2, model3, model4, model5]\n# Predict\nenv = ubiquant.make_env()\niter_test = env.iter_test() \nfor (test_df, sample_prediction_df) in iter_test:\n    for col in corr_features:\n        test_df['time_id'] = test_df['row_id'].str[0:4].astype(np.int64)\n        mapper = test_df.groupby(['time_id'])[col].mean().to_dict()\n        test_df[f'time_id_{col}'] = test_df['time_id'].map(mapper)\n    predictions = []\n    for model in models:\n        predictions.append(model.predict(test_df[features]))\n    sample_prediction_df['target'] = np.average(predictions, axis = 0)\n    env.predict(sample_prediction_df)","1e78b6f0":"# Quick Notes\n\nTraining pipeline can be found here: https:\/\/www.kaggle.com\/ragnar123\/ubiquant-tf-training-baseline-with-tpu"}}