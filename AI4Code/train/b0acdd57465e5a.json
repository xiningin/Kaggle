{"cell_type":{"04f0b619":"code","34b47a9d":"code","f2463133":"code","48d82cc7":"code","d7b52491":"code","05dc7597":"code","7b4e8583":"code","7a771419":"code","dc76fd83":"markdown","8154458e":"markdown","00579425":"markdown","96e646fa":"markdown","8689a0f9":"markdown","3d7bf4b2":"markdown","60151876":"markdown","2bc63480":"markdown","bbf3c088":"markdown"},"source":{"04f0b619":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nimport gc\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n","34b47a9d":"def read_dataset():\n    df = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    image_paths = '..\/input\/shopee-product-matching\/test_images\/' + df['image']\n\n    return df, image_paths","f2463133":"def combine_predictions(row):\n    x = np.concatenate([ row['text_predictions'], row['phash']])\n    return ' '.join( np.unique(x) )","48d82cc7":"def get_text_predictions_torch(df, max_features=25_000,th=0.75):\n    model = TfidfVectorizer(stop_words='english', binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df['title'])\n    \n    text_embeddings=text_embeddings.toarray().astype(np.float16)\n    text_embeddings=torch.from_numpy(text_embeddings).to('cuda:0') #.half()\n    CHUNK = 1024 \n    CTS = len(df) \/\/ CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n\n    preds = []\n    indexes=[]\n    for j in tqdm(range( CTS )):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n        for k in range(b-a):\n            IDX = torch.where(cts[k,]>th)[0].cpu().numpy()\n            o = df.iloc[IDX].posting_id.values\n            preds.append(o)\n            indexes.append(IDX)\n\n    del model,text_embeddings\n    gc.collect()\n    return preds","d7b52491":"df,image_paths = read_dataset()\ndf.head()","05dc7597":"text_predictions = get_text_predictions_torch(df, max_features=25_000)","7b4e8583":"phash = df.groupby('image_phash').posting_id.agg('unique').to_dict()\ndf['phash'] = df.image_phash.map(phash)\ndf.head()\n","7a771419":"df['text_predictions'] = text_predictions\ndf['matches'] = df.apply(combine_predictions, axis=1)\ndf[['posting_id', 'matches']].to_csv('submission.csv', index=False)","dc76fd83":"# Preparing Submission","8154458e":"# Import Packages","00579425":"## Phash","96e646fa":"## Text TFIDF","8689a0f9":"# Utils","3d7bf4b2":"# Text Predictions","60151876":"# Calculating Predictions","2bc63480":"# About Notebook\nRapid cupy calculates quite quickly cosine distance, but we can do it faster on Pytorch. \nI love pytorch it flexible and can do many amazing things on it  \nIn this notebook we focus on easy calculation TFIDF","bbf3c088":"# Notes\nCool that we can use **fp16** \n* in this code we just use np.float16 it is same as torch.float16\n* it consumes less memory\n* it is faster  \nFor my experiments (2080ti)  get_text_predictions_torch at CV runs 0.25 rapids 0.34 without TfidfVectorizer.  \nBut not speed is main thing. I dont like extra dependencies and  pytorch code more flexible. (I tell you what kind of flexeble, if I win it)"}}