{"cell_type":{"4bf26f00":"code","b2184677":"code","ecdb24a6":"code","83befd87":"code","b7ab89cf":"code","957974a6":"code","d9872500":"code","c9ca734c":"code","a4c271db":"markdown","f16b0051":"markdown","c8f4836d":"markdown","e896e579":"markdown","fc2ad922":"markdown","1492f208":"markdown","723c3875":"markdown","4f55d142":"markdown","4f7fdd88":"markdown"},"source":{"4bf26f00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2184677":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/rps.zip \\\n    -O \/tmp\/rps.zip\n  \n!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/rps-test-set.zip \\\n    -O \/tmp\/rps-test-set.zip","ecdb24a6":"import zipfile\n\nlocal_zip = '\/tmp\/rps.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp\/')\nzip_ref.close()\n\nlocal_zip = '\/tmp\/rps-test-set.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp\/')\nzip_ref.close()","83befd87":"rock_dir = os.path.join('\/tmp\/rps\/rock')\npaper_dir = os.path.join('\/tmp\/rps\/paper')\nscissors_dir = os.path.join('\/tmp\/rps\/scissors')\n\nprint('total training rock images:', len(os.listdir(rock_dir)))\nprint('total training paper images:', len(os.listdir(paper_dir)))\nprint('total training scissors images:', len(os.listdir(scissors_dir)))\n\nrock_files = os.listdir(rock_dir)\nprint(rock_files[:10])\n\npaper_files = os.listdir(paper_dir)\nprint(paper_files[:10])\n\nscissors_files = os.listdir(scissors_dir)\nprint(scissors_files[:10])","b7ab89cf":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nnext_rock = [os.path.join(rock_dir, fname) \n                for fname in rock_files[:2]]\nnext_paper = [os.path.join(paper_dir, fname) \n                for fname in paper_files[:2]]\nnext_scissors = [os.path.join(scissors_dir, fname) \n                   for fname in scissors_files[:2]]\n\nfor i, img_path in enumerate(next_rock+next_paper+next_scissors):\n  #print(img_path)\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  plt.axis('Off')\n  plt.show()","957974a6":"from keras_preprocessing.image import ImageDataGenerator\n\ntraining_dir = \"\/tmp\/rps\/\"\ntraining_datagen = ImageDataGenerator(\n                   rescale = 1.\/255,\n                   rotation_range = 40,\n                   width_shift_range = 0.2,\n                   height_shift_range = 0.2,\n                   shear_range = 0.2,\n                   zoom_range = 0.2,\n                   horizontal_flip = True)\n\n\ntest_dir = \"\/tmp\/rps-test-set\/\"\ntest_datagen = ImageDataGenerator(\n               rescale = 1.\/255)\n\ntrain_generator = training_datagen.flow_from_directory(\n                  training_dir,\n                  target_size=(150,150),\n                  class_mode='categorical',\n                  batch_size=126)\n\ntest_generator = test_datagen.flow_from_directory(\n                  test_dir,\n                  target_size=(150,150),\n                  class_mode='categorical',\n                  batch_size=126)","d9872500":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\n\nmodel = tf.keras.models.Sequential([\n    # The input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution layer\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    # This is the second convolution layer\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', strides=2),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # This is the third convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # This is the fourth convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = test_generator, verbose = 1, validation_steps=3)\n\nmodel.save(\"rps.h5\")","c9ca734c":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","a4c271db":"**Here I am showing you some images which are part of this dataset.**","f16b0051":"*Hope you liked this notebook and learned something from it and don't forget to hit the upvote button.THANK YOU!!*","c8f4836d":"**The best part about this zipfile library is that it allows us to make directories in which images are already labelled so there is no need to label them.**\n\n**So, there is a \/tmp\/rps\/ directory in which there are three directories called rock, paper and scissors. There is no need to remember these statements; you can just copy paste it wherever you want.**","e896e579":"**Downloading the data using the following code in the form of a zip file**","fc2ad922":"**This plot is used to show the training and testing accuracy over total epochs.**","1492f208":"**Since there are two directories train and test, we have to use ImageDataGenerator. Now, you must be thinking why I have specified so many attributes in the training_datagen but not in test_datagen excpet for rescaling(allows us to get values between 0 and 1). The answer to that is we want to train our model using these attributes and then test it on raw images.**\n\n**If you are having trouble grasping this code, there is no need to except for the path, target_size, and batch_size.**","723c3875":"**Python let us unzip a zipped file using the zipfile library.**","4f55d142":"**Now, here comes the most interesting part. Import tensorflow and keras_preprocessing.**\n\n**Our model type is Sequential with 4 convolution layers(You can experiment with any number of layers with first having the input_shape). The first parameter in the convolution layer is the no. of filters(Filters are nothing but parameters which store information about each pixel in our image. You can try different filters as required by your model) you wanna have and second being the kernel_size. Pooling is nothing but retrieving a selcted value out of the specified size of matrix(MaxPooling2D means taking the largest value amomg all in a 2D matrix).**\n\n**Strides and Dropout are used to reduce overfitting(You can learn more about them in Kaggle DeepLearning microcourse)**\n\n**After adding all the convolution layers, we Flatten them and then add a hidden layer of 512 neurons followed by another Dense layer(This layer is used for prediction) containing 3 classes and softmax function(This function is used to get probabilities about each class e.g how much likely is this image to be an ankle boot)**\n\n**Finally compile and fit the model.**","4f7fdd88":"# Data Retrieving"}}