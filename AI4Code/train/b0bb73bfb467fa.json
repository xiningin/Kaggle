{"cell_type":{"b6404a4c":"code","9cd48395":"code","1d278266":"code","6d9cb65a":"code","fc3a1822":"code","866e22e0":"code","28cf3c2b":"code","10ace7f6":"code","743ffcdf":"code","4c0d9d94":"code","24a35870":"code","b9f4a86f":"code","8c9b5283":"code","0cf35e8d":"code","aaa1c74a":"code","23bcb8a0":"code","49f2ef9c":"code","64f70135":"code","ebbdc83b":"code","4f48e1b5":"code","aba7a075":"code","a3f4cfee":"code","288a1c02":"code","9ae2a8d8":"code","8fa3f335":"code","e49e5dc0":"code","55330a0d":"code","09b87928":"markdown","20b28be8":"markdown","8a308e89":"markdown","de72a581":"markdown","9844b32d":"markdown","eabbaef7":"markdown","90dc3c67":"markdown","ede11c7f":"markdown","f9f903ae":"markdown","dd64c57b":"markdown","24c3c18a":"markdown","8ec107be":"markdown","c8e6e78b":"markdown","4d331d0c":"markdown","64792c79":"markdown","bbf5d37f":"markdown"},"source":{"b6404a4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cd48395":"# Regular EDA (exploratory data analysis)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n# Model Building\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split","1d278266":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_data.head()","6d9cb65a":"test_data.head()","fc3a1822":"# Check if there are missing values in test_data and how many of them in each feature.\n# We can build a function for that.\ndef missing_value_checker(data):\n    list = []\n    for feature, content in data.items():\n        if data[feature].isnull().values.any():\n            \n            sum = data[feature].isna().sum()\n\n            # It would be convinent if we can also know the data type of those features.\n            type = data[feature].dtype\n\n            print (f'{feature}: {sum}, type: {type}')\n            # It would be useful if we can create a list of feature names which has NaN values.\n            \n            list.append(feature)\n    print(list)\n    print(len(list))","866e22e0":"missing_value_checker(test_data)","28cf3c2b":"# drop features with missing value\ntest_edited = test_data.drop(['Alley','FireplaceQu','PoolQC', 'Fence', 'MiscFeature'], axis=1)\n\n# same changes applying to train_data for proper model fitting.\ntrain_edited = train_data.drop(['Alley','FireplaceQu','PoolQC', 'Fence', 'MiscFeature'], axis=1)\n\n# The list above is useful here","10ace7f6":"# Recheck if there are missing values.\nmissing_value_checker(test_edited)","743ffcdf":"missing_value_checker(train_edited)","4c0d9d94":"train_edited.shape, test_edited.shape","24a35870":"def nan_filler(data):\n    for label, content in data.items():\n        if pd.api.types.is_numeric_dtype(content):\n            data[label] = content.fillna(content.median())\n        else:\n            data[label] = content.astype(\"category\").cat.as_ordered()\n            data[label] = pd.Categorical(content).codes+1","b9f4a86f":"nan_filler(test_edited)","8c9b5283":"# Check the missing value\nmissing_value_checker(test_edited)","0cf35e8d":"# Check if the shape is changed\ntest_edited.shape","aaa1c74a":"# Apply same change to the train_edited\nnan_filler(train_edited)","23bcb8a0":"missing_value_checker(train_edited)","49f2ef9c":"train_edited.shape","64f70135":"test_edited.info()","ebbdc83b":"train_edited.info()","4f48e1b5":"X = train_edited.drop('SalePrice', axis=1)\ny = train_edited['SalePrice']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)","aba7a075":"X_train.shape, test_edited.shape","a3f4cfee":"# tf.random.set_seed(42)\n\n# model = tf.keras.Sequential(\n# [\n#     tf.keras.layers.Dense(100),\n#     tf.keras.layers.Dense(1)\n# ])\n\n# model.compile(\n#     # According to evaluation of the data, we use MeanSquaredLogarithmicError for loss evaluation\n#     loss = tf.keras.losses.mean_squared_logarithmic_error,\n#     optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n# )\n\n# model.fit(X_train, y_train, epochs=10)","288a1c02":"tf.random.set_seed(42)\n\nmodel = tf.keras.Sequential(\n[\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(\n    # According to evaluation of the data, we use MeanSquaredLogarithmicError for loss evaluation\n    loss = tf.keras.losses.mean_squared_logarithmic_error,\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002)\n)\n\nhistory = model.fit(X_train, y_train, epochs=200, verbose=0)","9ae2a8d8":"pd.DataFrame(history.history).plot()\nplt.ylabel('accuracy')\nplt.xlabel('epoch')","8fa3f335":"model.evaluate(X_val, y_val)","e49e5dc0":"preds = model.predict(test_edited)\npreds","55330a0d":"output = pd.DataFrame(\n{\n    'Id':test_data['Id'],\n    'SalePrice': np.squeeze(preds)\n})\n\noutput.to_csv('submission.csv', index=False)\n","09b87928":"#### Let's Decide which feature we need to keep and which we can drop.\n\nThere are 3 main ways:\n* If there are too many missing value: delete the whole feature\n        if some features are deleted, same changes need to apply in test_edited dataframe\n* If there are just some missing value: \n        delete samples with these missing values(delete rows)\n* Else: fill missing values with new values we created.\n\n        `mean` or `median` for numbers, new category called `missing` for string objects\n    \n    \n\nApplying in this dataset:\n\n> \u26a0Caution: We cannot delete rows with missing values in the `test_data`, otherwise we cannot make a submission with full length. \n\nI created a notebook before and I had to start all over again because of this issue, so don't make the same mistake as I do. **But if you have better solution for this situation, please let me know.**\n\n\nNearly 40% of the features in `test_data` have missing values, we cannot just delete all of them. (You can if you just want a fast analysis and training, but the accuracy may be low)\n\nAccording to the Data, we will:\n* delete ['Alley','FireplaceQu','PoolQC', 'Fence', 'MiscFeature']\n* fill numerical missing value with mean\n* fill string missing value with 'missing'\n","20b28be8":"\n## 0.5 Prepare the tools needed","8a308e89":"## 2.1 Build a model and evaluate","de72a581":"<a id=\"sec-2\"><\/a>\n# 1. EDA\n* View train and test data\n* Make sure test data has no Nan values\n* Make train data has same features as test data\n* Find out and process the missing value in train data\n* Check if all are numerical\n* Split train data into training and validation data","9844b32d":"## 1.4 Find out and process the missing value in train data\n* Fill missing number with mean\n* Fill missing string with `missing`","eabbaef7":"## 1.6 Split Data","90dc3c67":"## 2.2 Imporve the model\nImproving the model:\n> \ud83d\ude4fI am still new here, so I just tune it by hand. \nIf you have any useful resourses about how to fine tuning tensorflow hyperparameters, please let me know in the comment.","ede11c7f":"## 2.3 Predict and submit","f9f903ae":"\n# Predict House Prices Using Neural Network Regression model from TensorFlow\n\n# 0. Preparations\n## 0.1 Problem Definition\nPredict the final price of each home giving the features about houses.\n## 0.2 Data\nhttps:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/data\n\n**There are 2 main datasets.**\n* train.csv\n* test.csv\n> Since we don't know the label(Price) of the test data, for evaluating the model to get the best model before predicting the test data, we will spilt datas in train.scv into training and validation data, ratio is 20%.\n\n## 0.3 Evaluation\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price.\n\n## 0.4 Features\nThe features are included in data_description.txt","dd64c57b":"# 2. Modeling\n\n* Build a model and evaluate\n* Imporve the model\n* Predict and submit","24c3c18a":"## 1.1 View train and test data","8ec107be":"`train_data` has one more column than `test_data`, which is the label `SalePrice`, for training the model before applying it to predict labels in test_data, we need to split train_data later.","c8e6e78b":"## 1.2 Make sure test data has no Nan values","4d331d0c":"They have same features, which means we can fit the model to test data","64792c79":"## 1.5 Check if all features are numerical","bbf5d37f":"## 1.3 Make train data has same features as test data"}}