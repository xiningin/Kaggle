{"cell_type":{"65dcb628":"code","e49c7b4b":"code","d93bbba0":"code","00e3afa7":"code","02676ebc":"code","01bbf3f6":"code","776e2132":"code","49a39507":"code","f7863457":"code","20c9413c":"code","24c80c2f":"code","52573ec7":"code","1d0a0fa1":"code","737d84af":"code","e3dc0d2c":"code","6b3527d4":"code","fc3bd3fe":"code","044a460a":"code","0b50cd86":"code","52186a17":"code","eb0985e5":"code","5fb26c13":"code","ea4e23b3":"code","127e0646":"code","90d66902":"code","8f6992d0":"code","00ea9ede":"code","9cd67176":"code","31f61f42":"code","46847d73":"code","359060e6":"code","64224ccd":"code","d247ba80":"code","eedfed74":"code","f07fa254":"code","d98e1a43":"markdown","92769285":"markdown","c2b5e227":"markdown","f542e4a1":"markdown","fdf939c1":"markdown","0b75870e":"markdown","de593af9":"markdown","042a0b60":"markdown","a55a9aeb":"markdown","8508d3ba":"markdown","b821c3a4":"markdown","66160c56":"markdown","0d7f9276":"markdown","cf166451":"markdown","48426a76":"markdown","28f20880":"markdown","6cfca170":"markdown","3d197c27":"markdown","ce7602db":"markdown","9ef462b4":"markdown"},"source":{"65dcb628":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nsns.set_palette(sns.color_palette(\"Set2\"))\n\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as tfl\n\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor, DaskLGBMRegressor\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.cluster import KMeans\n\nfrom PIL import Image\nimport os\n\nnp.random.seed(0)\ntf.random.set_seed(0)","e49c7b4b":"train = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntrain['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/train\/' + train['Id'] + '.jpg'\ntrain.head(3)","d93bbba0":"test = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\ntest['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/test\/' + test['Id'] + '.jpg'","00e3afa7":"print(f'shape: {train.shape}')\nprint(train.info())","02676ebc":"train.describe()","01bbf3f6":"plt.figure(figsize=(10,4))\n\nsns.histplot(data=train, x='Pawpularity');","776e2132":"plt.figure(figsize=(20,10))\nplt.tight_layout()\n\nfor i in range(12):\n    plt.subplot(3, 4, i+1)\n    sns.countplot(data=train, x=train.columns[1:13][i])","49a39507":"def size_and_shape(row):\n    img = Image.open(row['path'])\n    return pd.Series([img.size[0], img.size[1], os.path.getsize(row['path'])])","f7863457":"scale = MinMaxScaler()\n\ntrain[['width', 'height', 'size']] = pd.DataFrame(scale.fit_transform(train.apply(size_and_shape, axis=1).values))\ntest[['width', 'height', 'size']] = pd.DataFrame(scale.fit_transform(test.apply(size_and_shape, axis=1).values))","20c9413c":"X = train.drop(['Id', 'Pawpularity', 'path'], axis=1)\ny = train['Pawpularity']","24c80c2f":"k = KMeans(8, random_state=0)\n\nk.fit(X)\n\nX['cluster'] = k.predict(X)\ntest['cluster'] = k.predict(test.drop(['Id', 'path'], axis=1))","52573ec7":"p = PCA()\n\np.fit(X)\n\nX = X.join(pd.DataFrame(p.transform(X)))\ntest = test.join(pd.DataFrame(p.transform(test.drop(['Id', 'path'], axis=1))))","1d0a0fa1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","737d84af":"def eval_model(model):\n    model.fit(X_train, y_train)\n    \n    preds = model.predict(X_test)\n\n    return mean_squared_error(y_test, preds, squared=False)","e3dc0d2c":"xgb = XGBRegressor(seed=0,\n                   learning_rate =0.1,\n                     n_estimators=70,\n                     max_depth=2,\n                     min_child_weight=2,\n                     gamma=0,\n                     subsample=0.9,\n                     colsample_bytree=0.2)\n\nlight = LGBMRegressor(random_state=0,\n                      num_leaves=4,\n                      subsample_for_bin=20, \n                      min_split_gain=0.1,\n                      min_child_samples=25,\n                      reg_lambda=0.4)\n\ncat = CatBoostRegressor(random_seed=0, \n                          verbose=0, \n                          num_trees=11, \n                          learning_rate=0.26,\n                          l2_leaf_reg=2.5, \n                          random_strength=0.9)\n\nextra = ExtraTreesRegressor(random_state=0, \n                            max_depth=4, \n                            min_samples_leaf=2, \n                            max_features=6, \n                            max_leaf_nodes=20)\n\nrf = RandomForestRegressor(random_state=0, \n                              n_estimators=10,\n                              max_depth=5, \n                              max_features=9)\n\ngb = GradientBoostingRegressor(random_state=0, \n                               n_estimators=40, \n                               subsample=0.44)\n\n\nmodels = {'rf': rf, 'gb': gb, 'extra': extra, 'cat': cat, 'light': light, 'xgb': xgb}\n\nfor model in models:\n    print(model, 'RMSE:', eval_model(models[model]))","6b3527d4":"# models = {'cat': cat, 'light': light, 'gb': gb}\n\nmodels_vote = [(model, models[model]) for model in models]\n\nvote = VotingRegressor(estimators=models_vote)\n\nvote.fit(X_train, y_train)\n\neval_model(vote)","fc3bd3fe":"# test['Pawpularity'] = vote.predict(test.drop(['Id', 'path'], axis=1))\n# test[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)","044a460a":"plt.figure(figsize=(20, 7))\n\nfor i in range(12):\n    plt.subplot(2, 6, i+1)\n    img = Image.open(train['path'].iloc[i])\n    plt.imshow(img)\n    title = plt.title(train.Pawpularity[i])\n    plt.setp(title, color='r')  ","0b50cd86":"X_train['path'] = train['path'].iloc[X_train.index]\nX_train['y'] = y_train\n\nX_val = X_test\n\nX_val['path'] = train['path'].iloc[X_val.index]\nX_val['y'] = y_test","52186a17":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 64\n\n@tf.function\ndef process_img(path: str, X_meta: pd.DataFrame, val= False) -> tf.Tensor:\n    img = tf.io.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, dtype=tf.float64)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = keras.applications.efficientnet.preprocess_input(img)\n    img = tf.cast(img, dtype=tf.float64)\n    \n    \n    if not val:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_saturation(img, 0.95, 1.05)\n        img = tf.image.random_contrast(img, 0.95, 1.05)\n        \n    return (img, X_meta)\n\n\n@tf.function\ndef process_img_label(path: str, X_meta, label: int, val=False) -> tuple:\n    img = process_img(path, val)\n    return process_img(path, X_meta, val), label\n\n\n    \n@tf.function\ndef img_meta_data(X, val=False) -> tf.data.Dataset:\n    if 'y' in X.columns==False:\n        data = tf.data.Dataset.from_tensor_slices((X['path'], X.drop('path', axis=1)))\n        return data.map(process_img).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    else:\n        data = tf.data.Dataset.from_tensor_slices((X['path'], X.drop('path', axis=1)))\n        return data.map(lambda x: process_img_label(x['path'], x.drop(['path', 'y'], axis=1), x['y'], val)).batch(BATCH_SIZE).prefetch(AUTOTUNE)","eb0985e5":"train","5fb26c13":"img_meta_data(X_train)","ea4e23b3":"img_meta_data(train['path'].iloc[X_train.index], X_train, y_train)","127e0646":"train_meta = meta_data(X_train, y_train)\nval_meta = meta_data(X_test, y_test)\ntest_meta = meta_data(test.drop(['Id', 'path'], axis=1))","90d66902":"train_imgs = img_data(train['path'].iloc[X_train.index], y_train)\nval_imgs = img_data(train['path'].iloc[X_test.index], y_test, val=True)\ntest_imgs = img_data(test['path'])","8f6992d0":"X_train.shape","00ea9ede":"eff_model = keras.models.load_model('\/kaggle\/input\/keras-applications-models\/EfficientNetB0.h5')\neff_model.trainable = False\n\n\nimg_input = tfl.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nmeta_input = tfl.Input(shape=(32,))\n\nX = eff_model(img_input)\nX = tfl.BatchNormalization()(X)\n\ncon = tfl.concatenate([X, meta_input])\n\nX = tfl.Dense(64, activation='relu')(con)\nX = tfl.Dense(64, activation='relu')(X)\n\nX = tfl.Dropout(0.2)(X)\n\nout = tfl.Dense(1)(X)\n\nmodel = keras.Model(inputs=[img_input, meta_input], outputs=out)","9cd67176":"early_stop = keras.callbacks.EarlyStopping(\n        patience=5,\n        restore_best_weights=True)\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=100,\n    decay_rate=0.96,\n    staircase=True)","31f61f42":"model.compile(keras.optimizers.Adam(learning_rate=lr_schedule), \n            loss='mse', \n            metrics=[keras.metrics.RootMeanSquaredError()])\n\nmodel.summary()","46847d73":"val_meta","359060e6":"train_imgs","64224ccd":"ds = train_imgs.concatenate(train_meta)","d247ba80":"history = model.fit(ds)\n#                 validation_data=np.array([val_imgs, val_meta]),\n#                 epochs = 20)#,\n#                 #callbacks=[early_stop])","eedfed74":"model.predict(test_imgs)*100","f07fa254":"test['Pawpularity'] = model.predict(test_imgs)*100\ntest[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)","d98e1a43":"here I used multiple models (also did manual parameters tuning \ud83d\ude2b)","92769285":"Create our features->traget variables","c2b5e227":"To be Continued...<br>\n**If liked, Please Upvote :D**","f542e4a1":"Simple train+eval function","fdf939c1":"## Submit","0b75870e":"Split our data into train and validate (here named test \ud83d\ude05)","de593af9":"Add Principal Component Analysis features to the data (Also improved performence \ud83e\udd29)","042a0b60":"Add size and shape of images to the data","a55a9aeb":"Add Clusters to the data (improved performence \ud83d\ude04)","8508d3ba":"get data and make `Id` contain the path of image","b821c3a4":"Statistics of the data","66160c56":"## Feature Engineering","0d7f9276":"Some visuals \ud83d\ude01","cf166451":"## Add Images","48426a76":"## Model Training","28f20880":"Normalize the data","6cfca170":"distribution of `Pawpularity`","3d197c27":"## Exploratory Data Analysis (EDA)","ce7602db":"## libraries and data Loading","9ef462b4":"check the shape and NULL values"}}