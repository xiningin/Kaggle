{"cell_type":{"4ffd46e1":"code","136b5764":"code","f9f4cc81":"code","8b96ffa5":"code","a17ad624":"code","f942f640":"code","b0d7c992":"code","b65715eb":"code","1bf0e8be":"code","d96430fe":"code","5fcb0433":"code","49494eb4":"code","254158dc":"code","825b794b":"code","de8fa310":"code","7eb8b26e":"code","adc160e7":"code","9f339a71":"code","1397de6c":"code","8c183e9c":"code","3a1cb548":"code","2a06b21a":"code","396d56a5":"code","1a553e66":"code","0d43dca2":"code","e90a9bc7":"code","4b39da26":"code","fa45bce2":"code","c8e82915":"code","8927b82a":"code","a99957ce":"code","11b8d3dc":"code","19b1bbf9":"code","684d2077":"code","dc516ee8":"code","c5fe51c6":"code","55e8e30b":"code","27d604a8":"code","693ff942":"code","55d71177":"code","282e0ca7":"code","2fa1937b":"code","b79a467a":"code","66214249":"code","caec7030":"code","ff5eaded":"code","42ae1873":"code","6c78b5b0":"code","b4ef0722":"code","f58c444f":"code","49ffb744":"code","ce248aeb":"code","9926042b":"code","9a187b52":"code","315c9370":"code","79d0712f":"code","c6e7586f":"code","c70e25a7":"code","93f31818":"code","aa3aa20b":"code","9b4fc887":"code","9b3f681d":"code","40dc7195":"code","dd225b0d":"code","fb162f18":"code","63647160":"code","74482bbf":"code","e91a8e5e":"code","56aa871d":"code","9d15990b":"code","c02e025b":"code","462e7fa0":"code","3103454b":"code","07577f60":"code","5d9f269b":"code","ed11932d":"code","1d5f3302":"code","e6b9d9c6":"code","d08b0933":"code","9a174123":"code","5fcae445":"code","36818845":"code","c902d6ae":"code","58afc8c4":"code","de7f590d":"code","21224bdf":"code","b55d32dc":"code","d9d98feb":"code","a34dc60d":"code","a1acaa52":"code","dbbd59ef":"code","6beec868":"code","d533a8ab":"code","31bc7862":"code","8648145e":"code","f0087cf8":"code","5d43a3c0":"code","d35d5679":"code","88887983":"code","f8f99da6":"code","2be93b8a":"code","84967554":"code","67e64a00":"markdown","a7d1d58e":"markdown","53a55c83":"markdown","570313ba":"markdown","5d0ed273":"markdown","a74941c4":"markdown","3c9be589":"markdown","fe97597b":"markdown","93c78424":"markdown","2df16c57":"markdown","bf50a704":"markdown","161d6a53":"markdown","fd84c7ac":"markdown","b46c6f66":"markdown","7a7960df":"markdown","2d4d2240":"markdown","3b561436":"markdown","f2ce852d":"markdown","a2cff1e6":"markdown","71e32897":"markdown","7456d8ff":"markdown","aedd5c01":"markdown","aa8c23d6":"markdown","6d506844":"markdown","0d28db09":"markdown","ac2ed6ce":"markdown","92950d90":"markdown","8baf2461":"markdown","48f8d1f1":"markdown","b18b072f":"markdown","a470e231":"markdown","af1346c2":"markdown","e311eeb0":"markdown","77fd26c2":"markdown","29ffdeae":"markdown","8a0ccef9":"markdown","6c58463a":"markdown","8b9005bd":"markdown","b9d5ee91":"markdown","9087de60":"markdown","133ae1e2":"markdown","c3b92f4b":"markdown","8e196223":"markdown","5b2788ff":"markdown","2d6ae080":"markdown","2bea3526":"markdown","38f328aa":"markdown","101fee09":"markdown","b9cb584d":"markdown","ffc7a6b9":"markdown","ca69ee58":"markdown","393431ae":"markdown","69d7dddf":"markdown","6881c2d5":"markdown","cf70be7d":"markdown","c4e7c474":"markdown","cf98ee06":"markdown","87e52aea":"markdown","c7277b7e":"markdown","0b7ce0ed":"markdown","cbe6d515":"markdown","a743ca69":"markdown","8b5a64c3":"markdown","43cd4f19":"markdown","a08a4e90":"markdown","0bdcf74e":"markdown","0cfca599":"markdown","6e611beb":"markdown","09e96077":"markdown","88899aea":"markdown","d96a4803":"markdown","a5b11201":"markdown","8088a879":"markdown","02eb7411":"markdown","2422e857":"markdown","8393cb11":"markdown","53a097cf":"markdown","2e53f0fc":"markdown"},"source":{"4ffd46e1":"import warnings\nwarnings.filterwarnings('ignore')\n\n\nimport scipy as sp\nimport pandas as pd\nimport re\n\nimport matplotlib as mlt\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb","136b5764":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","f9f4cc81":"# Data shape\nprint(train.shape)\nprint(test.shape)\n\n# Check Columns\nprint(train.columns)\nprint(test.columns)\n\n# Column comparison\nprint(set(train.columns)-set(test.columns))\nprint(set(test.columns)-set(train.columns))","8b96ffa5":"train.head(3)","a17ad624":"test.head(3)","f942f640":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    types = [str(data[i].dtype) for i in data.columns]\n    \n    df = pd.DataFrame({'Total':total, 'Precent':percent, 'Types':types})\n    \n    return(sp.transpose(df))","b0d7c992":"missing_data(train)","b65715eb":"missing_data(test)","1bf0e8be":"train.describe()","d96430fe":"test.describe()","5fcb0433":"Survived = train['Survived']\ndata = pd.concat([train.drop(columns='Survived'), test])","49494eb4":"missing_data(data)","254158dc":"data['Age'].fillna(data['Age'].median(), inplace=True)","825b794b":"data['Fare'].fillna(data['Fare'].median(), inplace=True)","de8fa310":"data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)","7eb8b26e":"missing_data(data)","adc160e7":"data['Cabin'].fillna('no value', inplace=True)","9f339a71":"missing_data(data)","1397de6c":"train = data.loc[:train.index[-1]]\ntest = data.loc[train.index[-1]:][1:]\ntrain = pd.concat([Survived, train], axis=1)","8c183e9c":"sns.countplot(x='Survived', data=train).set_title('Survived probablity density function')\nplt.show()","3a1cb548":"features = ['Age', 'Fare']\nnrow=1;ncol=2\nf, axes = plt.subplots(nrow, ncol, figsize=(20, 5))\nfor idx, feature in enumerate(features):\n    plt.subplot(nrow, ncol, idx+1)\n    sns.distplot(data[feature]).set_title('PDF '+str(feature))\nplt.show()","2a06b21a":"features =  ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'] # 'Name', 'Ticket', 'Cabin'\nnrow=2;ncol=3\nf, axes = plt.subplots(nrow, ncol, figsize=(20, 15))\nfor idx, feature in enumerate(features):\n    plt.subplot(nrow, ncol, idx+1)\n    sns.countplot(data[feature])\n    plt.xlabel(feature, fontsize=15)\n#     plt.xticks(rotation=90)\nplt.show()","396d56a5":"data['Title'] = data['Name'].apply(lambda x: x.split(', ')[1].split('.')[0])\nsns.countplot(data['Title'])\nplt.xticks(rotation=-45)\nplt.show()","1a553e66":"nrow=1;ncol=2\nf, axes = plt.subplots(nrow, ncol, figsize=(15, 5))\nplt.subplot(nrow, ncol, 1)\nsns.countplot(data['Ticket'].value_counts())\nplt.subplot(nrow, ncol, 2)\nsns.countplot(data['Cabin'].value_counts())\nplt.show()","0d43dca2":"features = ['Age', 'Fare']\nnrow = 1;ncol=2\nf, axes = plt.subplots(nrow, ncol, figsize=(15, 5))\nfor indx, feature in enumerate(features):\n    plt.subplot(nrow, ncol, indx+1)\n    sns.distplot(train.loc[Survived==0, feature])\n    sns.distplot(train.loc[Survived==1, feature])\nplt.show()","e90a9bc7":"train = data.loc[:train.index[-1]]\ntest = data.loc[train.index[-1]:][1:]\ntrain = pd.concat([Survived, train], axis=1)","4b39da26":"import sklearn","fa45bce2":"le = sklearn.preprocessing.LabelEncoder()\ntrain['Sex_code'] = le.fit_transform(train['Sex'])\ntrain['Ticket_code'] = le.fit_transform(train['Ticket'])\ntrain['Cabin_code'] = le.fit_transform(train['Cabin'])\ntrain['Embarked_code'] = le.fit_transform(train['Embarked'])\ntrain['Title_code'] = le.fit_transform(train['Title'])","c8e82915":"features = ['Survived', 'Pclass', 'Sex_code', 'Age', 'SibSp', 'Parch', 'Ticket_code', 'Fare', 'Cabin_code','Embarked_code', 'Title_code']","8927b82a":"sns.pairplot(train[['Survived', 'Age', 'Fare']], hue='Survived', vars=['Age', 'Fare'])\nplt.title('Pair plot')\nplt.show()","a99957ce":"sns.boxplot(x='Survived', y='Age', data=train)","11b8d3dc":"sns.boxplot(x='Survived', y='Fare', data=train)","19b1bbf9":"sns.countplot(x='Sex', hue='Survived', data=train)","684d2077":"le = sklearn.preprocessing.LabelEncoder()\ndata['Sex_code'] = le.fit_transform(data['Sex'])\ndata['Ticket_code'] = le.fit_transform(data['Ticket'])\ndata['Cabin_code'] = le.fit_transform(data['Cabin'])\ndata['Embarked_code'] = le.fit_transform(data['Embarked'])\ndata['Title_code'] = le.fit_transform(data['Title'])","dc516ee8":"data = data[['Pclass', 'Age', 'SibSp', 'Parch',\n        'Fare', 'Sex_code', 'Ticket_code', 'Cabin_code', 'Embarked_code', 'Title_code']]","c5fe51c6":"train = data.loc[:train.index[-1]]\ntest = data.loc[train.index[-1]:][1:]\ntrain = pd.concat([Survived, train], axis=1)","55e8e30b":"train = train[['Survived', 'Age', 'Fare']]\ntest = test[['Age', 'Fare']]","27d604a8":"# import sklearn.linear_model\n# help(sklearn.linear_model.LogisticRegression)","693ff942":"model = sklearn.linear_model.LogisticRegression()","55d71177":"# dir(sklearn.model_selection.train_test_split)","282e0ca7":"trn, val, trn_y, val_y = sklearn.model_selection.train_test_split(train[['Age', 'Fare']], Survived)","2fa1937b":"model.fit(trn, trn_y)","b79a467a":"# predict = model.predict_proba(val)[:,1]\npredict = model.predict(val)","66214249":"sklearn.metrics.accuracy_score(val_y, predict)","caec7030":"sklearn.metrics.f1_score(val_y, predict)","ff5eaded":"sklearn.metrics.confusion_matrix(val_y, predict)","42ae1873":"fpr, tpr, threshold = sklearn.metrics.roc_curve(val_y, predict)\nroc_auc = sklearn.metrics.auc(fpr, tpr)","6c78b5b0":"plt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = round(roc_auc,2))\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","b4ef0722":"from sklearn.metrics import classification_report\n\nprint(classification_report(val_y, predict, target_names=['Survived', 'Not Survived']))","f58c444f":"neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\nneigh.fit(trn, trn_y)","49ffb744":"predict2 = neigh.predict(val)","ce248aeb":"print(sklearn.metrics.classification_report(val_y, predict2, target_names=['Survived', 'Not Survived']))","9926042b":"predict2 = neigh.predict_proba(val)[:,1]","9a187b52":"fpr, tpr, threshold = sklearn.metrics.roc_curve(val_y, predict2)\nroc_auc = sklearn.metrics.auc(fpr, tpr)","315c9370":"plt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = round(roc_auc,2))\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","79d0712f":"# help(sklearn.svm.SVC)\n\nclf = sklearn.svm.SVC(random_state=1028, probability=True, kernel='linear')\nclf = clf.fit(trn, trn_y)","c6e7586f":"predict3 = clf.predict(val)","c70e25a7":"# help(sklearn.metrics.classification_report)\nprint(sklearn.metrics.classification_report(val_y, predict3, target_names=['O', 'X']))","93f31818":"predict3 = clf.predict_proba(val)[:,1]","aa3aa20b":"fpr, tpr, threshold = sklearn.metrics.roc_curve(val_y, predict3)\nroc_auc = sklearn.metrics.auc(fpr, tpr)","9b4fc887":"plt.title('ROC Curve')\nplt.plot(fpr, tpr, 'b', label=round(roc_auc, 2))\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.xlabel('false positive ratio')\nplt.ylabel('true positive ratio')\nplt.xlim([0,1]);plt.ylim([0,1])\nplt.show()","9b3f681d":"# help(sklearn.ensemble.RandomForestClassifier)\n\nclf = sklearn.ensemble.RandomForestClassifier(max_depth=4,\n random_state=1028).fit(trn, trn_y)","40dc7195":"predict4 = clf.predict(val)","dd225b0d":"print(sklearn.metrics.classification_report(val_y, predict4))","fb162f18":"predict4 = clf.predict_proba(val)[:,1]","63647160":"fpr, tpr, threshold = sklearn.metrics.roc_curve(val_y, predict4)\nroc_auc = sklearn.metrics.auc(fpr, tpr)","74482bbf":"plt.title('Roc curve')\nplt.plot(fpr, tpr, 'b', label=round(roc_auc, 2))\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.xlabel('false positive ratio')\nplt.ylabel('true positive ratio')\nplt.legend(loc='lower right')\nplt.show()","e91a8e5e":"feature_imp = pd.DataFrame(clf.feature_importances_, index=['Age', 'Fare'])","56aa871d":"feature_imp = feature_imp[0].sort_values(ascending=False)","9d15990b":"sns.barplot(x=feature_imp, y=feature_imp.index)","c02e025b":"feature_imp = pd.Series(clf.feature_importances_,index=['A','B']).sort_values(ascending=False)\nfeature_imp","462e7fa0":"corr = train.corr()\nf, axes = plt.subplots(1, 1, figsize=(3, 3))\n\nplt.subplot(1, 1, 1)\nsns.heatmap(corr, cmap='coolwarm', square=True, annot=True, fmt='.2f', annot_kws={\"size\": 12}, linewidths=.05).set_title('heat map_ ')\nplt.show()","3103454b":"help(sns.heatmap)","07577f60":"corr = train.drop(columns='id').corr(method='spearman')\nfig, axes = plt.subplots(1, 1, figsize=(20,12))\n\nhm = sns.heatmap(corr, \n                 ax=axes,           # Axes in which to draw the plot, otherwise use the currently-active Axes.\n                 cmap=\"coolwarm\", # Color Map.\n                 square=True,    # If True, set the Axes aspect to \u201cequal\u201d so each cell will be square-shaped.\n                 annot=True, \n                 fmt='.2f',       # String formatting code to use when adding annotations.\n                 annot_kws={\"size\": 12},\n                 linewidths=.05)\n\nfig.subplots_adjust(top=0.93)\nfig.suptitle('Spearman Correlation Heatmap', \n              fontsize=14, \n              fontweight='bold')\nplt.show()","5d9f269b":"train['Age'] = train['Age'].fillna(round(np.mean(train['Age'])))\ntrain['Cabin'] = train['Cabin'].fillna('no value')\ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].value_counts().index[0])\n\ntest['Age'] = test['Age'].fillna(round(np.mean(test['Age'])))\ntest['Fare'] = test['Fare'].fillna(round(np.mean(test['Fare'])))\ntest['Cabin'] = test['Cabin'].fillna('no value')","ed11932d":"print(train.isnull().sum())\nprint(test.isnull().sum())","1d5f3302":"print(train['Survived'].value_counts())\nsns.countplot(x='Survived', data=train)","e6b9d9c6":"train.columns","d08b0933":"print(train['PassengerId'].value_counts().value_counts())\nprint(test['PassengerId'].value_counts().value_counts())\n\ntrain = train.drop(columns = 'PassengerId')\ntest = test.drop(columns = 'PassengerId')","9a174123":"fig, axes = plt.subplots(1,3, figsize=(12,5), constrained_layout=True)\n\nsns.countplot(x=\"Pclass\", data=train, hue='Survived', ax=axes[0]).set_title('train countplot')\nsns.barplot(x=\"Pclass\", y='Survived', data=train.groupby('Pclass').mean()['Survived'].reset_index(), ax=axes[1]).set_title('train survived_ratio')\nsns.countplot(x=\"Pclass\", data=test, ax=axes[2]).set_title('test Pclass')","5fcae445":"print(len(train['Name'])==len(np.unique(train['Name'])))","36818845":"# Name length column\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)","c902d6ae":"fig, axes = plt.subplots(3,1, figsize=(12,6), constrained_layout=True)\n\nsns.countplot(x=\"Name_length\", data=train[train['Pclass']==1], ax=axes[0]).set_title('1st')\nsns.countplot(x=\"Name_length\", data=train[train['Pclass']==2], ax=axes[1]).set_title('2nd')\nsns.countplot(x=\"Name_length\", data=train[train['Pclass']==3], ax=axes[2]).set_title('3rd')","58afc8c4":"train['name_title'] = train['Name'].apply(lambda x: re.search('([A-Za-z]+)\\.', x).group(1))\ntest['name_title'] = test['Name'].apply(lambda x: re.search('([A-Za-z]+)\\.', x).group(1))","de7f590d":"fig, axes = plt.subplots(1,2, figsize=(15,5), constrained_layout=True)\n\na = sns.countplot(x=\"name_title\", data=train, order=train['name_title'].value_counts().index, ax=axes[0])\na.set_xticklabels(labels=train['name_title'].value_counts().index, rotation=45)\na.set_title('train name_title')\nsns.countplot(x=\"name_title\", data=test, order=test['name_title'].value_counts().index, ax=axes[1]).set_title('test name_title')","21224bdf":"train.loc[~train['name_title'].isin(test['name_title']), 'name_title'] = 'etc'\ntest.loc[~test['name_title'].isin(train['name_title']), 'name_title'] = 'etc'","b55d32dc":"fig, axes = plt.subplots(1,2, figsize=(15,5), constrained_layout=True)\n\nsns.countplot(x=\"name_title\", data=train, order=train['name_title'].value_counts().index, ax=axes[0]).set_title('train name_title')\nsns.countplot(x=\"name_title\", data=test, order=test['name_title'].value_counts().index, ax=axes[1]).set_title('test name_title')","d9d98feb":"fig, axes = plt.subplots(1,3, figsize=(12,5), constrained_layout=True)\n\nsns.countplot(x=\"Sex\", data=train, hue='Survived', ax=axes[0]).set_title('train countplot')\nsns.barplot(x=\"Sex\", y='Survived', data=train.groupby('Sex').mean()['Survived'].reset_index(), order=['male', 'female'], ax=axes[1]).set_title('train Sex_ratio')\nsns.countplot(x=\"Sex\", data=test, ax=axes[2]).set_title('test Pclass')","a34dc60d":"fig, axes = plt.subplots(1,2, figsize=(8,4), constrained_layout=True)\n\nfor val in [0, 1]:\n    sns.kdeplot(train.loc[train['Survived']==val, 'Age'], shade=True, label=val, ax=axes[0])\n\nsns.kdeplot(data=test['Age'], shade=True, ax=axes[1])","a1acaa52":"train['cate_age'] = pd.cut(train['Age'], [0, 15, 25, 40, 60, np.max(train['Age'])], labels=[1, 2, 3, 4, 5])\ntest['cate_age'] = pd.cut(test['Age'], [0, 15, 25, 40, 60, np.max(train['Age'])], labels=[1, 2, 3, 4, 5])","dbbd59ef":"fig, axes = plt.subplots(1,2, figsize=(8,6), constrained_layout=True)\n\nsns.countplot(x='SibSp', data=train, hue='Survived', ax=axes[0])\nsns.countplot(x='SibSp', data=test, ax=axes[1])","6beec868":"fig, axes = plt.subplots(1,2, figsize=(8,6), constrained_layout=True)\n\nsns.countplot(x='Parch', data=train, hue='Survived', ax=axes[0])\nsns.countplot(x='Parch', data=test, ax=axes[1])","d533a8ab":"train['family_size'] = train['SibSp'] + train['Parch']\ntest['family_size'] = test['SibSp'] + test['Parch']","31bc7862":"crosstab_family_size = pd.crosstab(train['Ticket'], train['family_size'])\ncrosstab_family_size.loc[np.count_nonzero(crosstab_family_size==0, axis=1)!=8, ]","8648145e":"fig, axes = plt.subplots(1,2, figsize=(12,4), constrained_layout=True)\n\nsns.countplot(x='family_size', data=train, hue='Survived', ax=axes[0])\nsns.countplot(x='family_size', data=test, ax=axes[1])","f0087cf8":"train.loc[train['family_size'].isin([0, 4, 5, 6, 7, 10]), 'family_size'] = 0\ntrain.loc[train['family_size'].isin([1, 2, 3]), 'family_size'] = 1","5d43a3c0":"test.loc[test['family_size'].isin([0, 4, 5, 6, 7, 10]), 'family_size'] = 0\ntest.loc[test['family_size'].isin([1, 2, 3]), 'family_size'] = 1","d35d5679":"train.groupby('Ticket').mean()['Fare']","88887983":"train[['Ticket', 'Fare']]","f8f99da6":"# Ticket length column\ntrain['Ticket_length'] = train['Ticket'].apply(len)\ntest['Ticket_length'] = test['Ticket'].apply(len)","2be93b8a":"train['Cabin'].value_counts()","84967554":"train['Cabin_first'] = train['Cabin'].apply(lambda x: x[0])\ntest['Cabin_first'] = test['Cabin'].apply(lambda x: x[0])","67e64a00":"Age\uc758 \uacbd\uc6b0 \uc601\uc720\uc544 \ucabd\uc5d0 \ub9ce\uc740 \uc778\uc6d0\uc774 \ubd84\ud3ec\ub41c \uac83\uc744 \ubcfc \uc218 \uc788\ub2e4. \uc774\uac83\uc740 \uc774\uc0c1\uac12\uc73c\ub85c \uc758\uc2ec\ub418\ubbc0\ub85c \ud655\uc778\ud574 \ubcf4\ub294 \uac8c \uc88b\uc744 \uac83 \uac19\ub2e4. 25\uc138 \uc774\ud6c4\ub85c\ub294 \uc644\ub9cc\ud55c \uace1\uc120\ud615\ud0dc\ub85c \ub098\ud0c0\ub098\ubbc0\ub85c \uc815\uc0c1\uc801\uc778 \uace1\uc120\uc744 \ub098\ud0c0\ub0b8\ub2e4.\n\nFare\uc758 \uacbd\uc6b0 \uc55e\ucabd\uc5d0 \ub9e4\uc6b0 \uce58\uc6b0\uccd0\uc838 \uc788\ub294 \uac83\uc744 \ubcfc\uc218 \uc788\uace0, skew\ub418\uc5b4 \uc788\ub2e4. log\uc744 \ucde8\ud574 \uc815\uaddc\uc131\uc744 \ub744\uac8c \ub9cc\ub4e4\uc5b4 \uc694\uae08\ucc28\uc774\uc5d0 \ub300\ud55c \uc0dd\uc874\uc728\uc5d0 \ucc28\uc774\uac00 \uc788\ub294\uc9c0 \uc54c\uc544\ubcf4\ub294 \uac83\ub3c4 \uc88b\uc744 \ub4ef \ud558\ub2e4.\n\n\ub2e4\uc74c\uc740 \ubc94\uc8fc\ud615 \ubcc0\uc218\uc5d0 \ub300\ud574 \uc54c\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\nPassengerId\uc758 \uacbd\uc6b0, \ub2e8\uc21c Id\uac12\uc73c\ub85c \uc0dd\uc874\uc728\uacfc \uad00\ub828\uc774 \uc5c6\uc73c\ubbc0\ub85c \uc0dd\uac01\ud558\uc9c0 \uc54a\uaca0\uc2b5\ub2c8\ub2e4.\n\nName, Ticket, Cabin\uc758 \uacbd\uc6b0\uc5d0\ub294 \ub108\ubb34 \ub9ce\uc740 \ub2e4 \ubc94\uc8fc \uc774\ubbc0\ub85c \ud6c4\uc5d0 Feature engineering\uc744 \ud1b5\ud574 \uc804\ucc98\ub9ac\ud558\uace0 \ubd84\ud3ec\ub97c \ud655\uc778\ud558\uaca0\uc2b5\ub2c8\ub2e4.","a7d1d58e":"- \ud2f0\ucf13\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c \uc0dd\uac01\uc774 \ub354 \ud544\uc694\ud558\ub2e4.","53a55c83":"\uc870\uae08 \ub354 \uc5f0\uad6c\uac00 \ud544\uc694\ud55c \uceec\ub7fc\uc774\ub2e4.","570313ba":"- 20\uc138 \uc774\ud558\uc778 \uacbd\uc6b0 \uc0ac\ub9dd\ud655\ub960\uc774 \ub192\uc740 \uac83\uc744 \ubcfc \uc218 \uc788\ub2e4. \uc774 \uc810\uc744 \uc774\uc6a9\ud558\uae30 \uc704\ud574 \uc5f0\uc18d\ud615 \ubcc0\uc218 \ubcf4\ub2e4\ub294 \uce74\ud14c\uace0\ub9ac\uceec \ubcc0\uc218\uac00 \ub354 \ud6a8\uacfc\uc801\uc778 \uac83\uc73c\ub85c \ubcf4\uc778\ub2e4.","5d0ed273":"\ud2b9\uc815 \ud558\ub098\uc758 \uac12\uc774 \ub9ce\uc740 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uac83\uc774 \uc0dd\uc874\uc728\uacfc \uad00\uacc4\uac00 \uc788\ub294 \uc9c0 \uc720\uc2ec\ud788 \uc0b4\ud3b4\ubcfc \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\n## <a id='33'>Feature Engineering1<\/a>  \n\uc704\uc5d0\uc11c \ub2e4\ubc94\uc8fc\ub85c \uc778\ud574 \ud655\uc778\ud558\uc9c0 \ubabb\ud55c \ubcc0\uc218\ub4e4\uc744 \ud655\uc778\ud574 \ubcf4\uac9f\uc2b5\ub2c8\ub2e4.\n\n\ubc94\uc8fc\ub97c \ucd95\uc18c\ud574\uc11c \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","a74941c4":"def xgb_model(train_val, test_val):\n    \n    gbm = xgb.XGBClassifier(\n    learning_rate = 0.02,\n    n_estimators= 2000,\n    max_depth= 8,\n    min_child_weight= 2,\n    gamma=1,\n#     gamma=0.9,                        \n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic',\n#     nthread= -1,\n    scale_pos_weight=1).fit(train_val.drop(columns=['Survived']), train_val['Survived'])\n    \n    test_val_y = gbm.predict(test_val.drop(columns=['Survived']))\n    \n    true_count = 0\n    for i in test_val_y - test_val['Survived']:\n        if i == 0:\n            true_count+=1\n    \n    return true_count\/len(test_val_y)","3c9be589":"- Interaction effect\ub97c \uc774\uc6a9\ud558\uba74 \uc5b4\ub5a8\uae4c..?","fe97597b":"Taitanic : Machine Learning from Disater\n\n\nSurvived Prediction\n\n\nThe goal : This is a kernel for study. The goal is an accuracy of 0.9","93c78424":"### ensembles","2df16c57":"## Save Submission","bf50a704":"# <a id='1'>Introduction<\/a>  \n#### **Competition background**\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n#### **Evaluation**\n\n\n#### **Timeline**\n\n\n**Data**\n\ntrain.csv, test.csv, sample_submission.csv","161d6a53":"# Modeling","fd84c7ac":"# features","b46c6f66":"Train contains:  \n\n* **PassengerId** (string);  \n* **Survived**;  \n* **2** numerical variables, named **Age** and **Fare**\n* **8** categorical variables, named **Pclass**, **Name**, **Sex**, **SibSp**, **Parch**, **Ticket**, **Cabin**, **Embarked**\n\nTest contains:  \n\n* **PassengerId** (string);  \n* **2** numerical variables, named **Age** and **Fare**\n* **8** categorical variables, named **Pclass**, **Name**, **Sex**, **SibSp**, **Parch**, **Ticket**, **Cabin**, **Embarked**\n\nLet's check if there are any missing data. We will also check the type of data.\n\nWe check first train.","7a7960df":"- family_size\uac00 1, 2, 3\uc778\uacbd\uc6b0\uc5d0 \uc0ac\ub9dd\ub960\uc774 \ub192\ub2e4.\n- \uadf8\ub7ec\ubbc0\ub85c [0, 4, 5, 6, 7, 10]\uacfc [1, 2, 3]\uc744 \uadf8\ub8f9\ud551\ud55c\ub2e4.","2d4d2240":"survived ratio","3b561436":"# 5-fold","f2ce852d":"---","a2cff1e6":"def rf_model(train_val, test_val):\n    regr = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=100).fit(\n    train_val.drop(columns=['Survived']), train_val['Survived'])\n    \n    test_val_y = regr.predict(test_val.drop(columns=['Survived'])) > decision_boundary\n    test_val_y = test_val_y.astype(int)\n    \n    true_count = 0\n    for i in test_val_y - test_val['Survived']:\n        if i == 0:\n            true_count+=1\n    \n    return true_count\/len(test_val_y)","71e32897":"- Pclass\uac00 Ticket class\ub97c \uc758\ubbf8\ud558\ubbc0\ub85c, \uc774\ub984\uc758 \uae38\uc774\uac00 Pclass\uc5d0 \uc601\ud5a5\uc744 \ub07c\uce58\ub294 \uac00?(\ub9ce\uc740 \uc7ac\ub825\uc744 \uac00\uc9c0\uace0 \uc788\ub294\uac00)\n- Fare \ub610\ud55c \uc6b4\uc784\ube44\uc6a9\uc73c\ub85c\uc368 \uc7ac\ub825\uc744 \uc0c1\uc9d5\ud560 \uc218 \ub3c4 \uc788\uc73c\ub098, 3rd\ub97c \ube44\uc2fc\uac12\uc5d0 \uc8fc\uace0 \uc0ac\ub294 \uac83\uc774 \uc7ac\ub825\uac00\uc778\uac00\ub97c \uc0dd\uac01\ud574 \ubcf4\uc558\uc744 \ub54c, \uc544\ub2c8\ub2e4\ub77c\uace0 \uc0dd\uac01\ud588\ub2e4.","7456d8ff":"sibsp and parch","aedd5c01":"# X value","aa8c23d6":"Train data is approximately twice as large as test data.\n\nColumns are the same except for target variables.\n\nLet's glimpse train and test dataset.","6d506844":"cv = KFold(5, shuffle=True, random_state=0)\n\nfor j in range(2, 9):\n    for k in range(30, 51):\n        L = []\n        for i, (idx_train, idx_test) in enumerate(cv.split(train2)):\n            train_val = train2.iloc[idx_train]\n            test_val = train2.iloc[idx_test]\n            \n            max_depth=j\n            decision_boundary=k\/100\n            \n            L.append(rf_model(train_val, test_val))\n            if np.mean(L) > .83:\n                print('accuacy : {}, max_depth : {}, decision boundary : {}'.format(np.mean(L), j, k\/100))\n","0d28db09":"L=[]\nfor i,j in zip(regr.predict(test), submission2['Survived']):\n    if (i+j)\/2 > .5:\n        L.append(1)\n    else:\n        L.append(0)","ac2ed6ce":"\ubcc0\uc218\uc640 \ubcc0\uc218 \uc0ac\uc774\uc758 \uadf8\ub798\ud504\ub294 y\uac00 \ubc94\uc8fc\uc77c \ub54c, \uac4d pair plot\uadf8\ub9ac\uace0 \uc2f6\uc73c\uba74 \uadf8\ub9ac\uace0 box plot\uc774 \uc81c\uc77c \uc815\uc11d\uc778\uac70 \uac19\ub2e4. \uc870\uc815\uc11d \uac19\uc774\n\n\uc774\uac74 y\uac00 \uc5f0\uc18d, x\uac00 \ubc94\uc8fc\uc77c \ub54c\ub3c4 \ud1b5\uc6a9\ub418\ub294 \uc774\uc57c\uae30 \ubcf4\uae30 \ud3b8\ud558\uace0 \uc880 \uc54c \uc218 \uc788\ub294 \uac8c \ub9ce\ub2e4.\n\nvioline\ub3c4 \ub0ab\ubc30\ub4dc\ub2c8 \ucc38\uace0\ubc14\ub78c\n\n\ubc94\uc8fc\uc640 \ubc94\uc8fc\ub294 \uac4d countplot\uc73c\ub85c \ud241\uce58\ub294\uac8c \uc81c\uc77c \ub098\uc740\ub4ef hue\ud558\uac8c\n","92950d90":"## 5-fold CV","8baf2461":"\ubcc0\uc218\ub07c\ub9ac\uc758 \uad00\uacc4\ub97c \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\ny\uac00 \ubc94\uc8fc\ud615 \uc774\ubbc0\ub85c \ubc94\uc8fc-\ubc94\uc8fc, \ubc94\uc8fc-\uc5f0\uc18d\uc744 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ubc94\uc8fc-\uc5f0\uc18d \uba3c\uc800\uc785\ub2c8\ub2e4.","48f8d1f1":"Cabin","b18b072f":"features = ['Name_length', 'est_Survived', 'Pclass', 'Sex', 'Embarked', 'na_count', 'name_title', 'cate_age', 'family_size']","a470e231":"Ticket\n- \ud2f0\ucf13\uc740 \uac00\uc871\uc774\ub77c\uba74 \ub3d9\uc77c\ud55c\uac00?\n- \ud2f0\ucf13\uc774 \uac19\uc744 \ub54c \uc6b4\uc784\ube44\uc6a9\uc774 \uac19\ub2e4\uba74, \uac00\uc871\uc774\ub77c\uace0 \ud310\ub2e8\ud560 \uc218 \uc788\uc744\uae4c","af1346c2":"imbalance \ud55c \ub370\uc774\ud130\uc778 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc124\uba85\ubcc0\uc218\ub97c \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4\uc5d0 \ub300\ud574 \uc2dc\uac01\ud654\ub97c \ud558\uaca0\uc2b5\ub2c8\ub2e4.","e311eeb0":"label = LabelEncoder()\n\ndf = pd.concat([train2, test2])\n\nfor i in ['Sex', 'Embarked', 'name_title']:\n    df[i] = label.fit_transform(df[i])","77fd26c2":"# one hot encoding","29ffdeae":"Name\n\n- \uc774\ub984\uc740 \uc720\ub2c8\ud06c\ud55c \uac12\uc744 \uac00\uc9d0\n- \uc774\ub984\uc758 \uad6c\uc870\ub294 first name, title. last name\uc73c\ub85c \uad6c\uc131\ub418\ub294 \uac83\uc73c\ub85c \ubcf4\uc778\ub2e4.\n- title\uc774 \uc720\uc758\ubbf8\ud55c \uac12\uc744 \uac00\uc9c0\uae30\uc5d0 \uc815\uaddc\ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec tilte\uc744 \ucd94\ucd9c\ud55c\ub2e4.\n- \ub610\ud55c \uc774\ub984\uc758 \uae38\uc774\uac00 \uc720\uc758\ubbf8\ud560\uae4c\ub97c \uc0dd\uac01\ud574 \ubcf4\uc558\ub2e4. \uc774\ub984\uc758 \uae38\uc774\uac00 \uae38 \uc218\ub85d \uadc0\uc871\uc77c \ud655\ub960\uc774 \uc788\ub294 \uac83\uc778\uac00? \ud639\uc740 \ubd80\ud638\uc77c \uac00\ub2a5\uc131\uc774 \uc788\ub294\uc9c0\uc5d0 \ub300\ud55c \uad81\uae08\uc99d","8a0ccef9":"- family_size\uceec\ub7fc\uc758 \uacbd\uc6b0 SibSp\uc640 Parch\uc758 \ud569\uc73c\ub85c \uc368 \uac00\uc871\uc758 \uaddc\ubaa8\ub97c \ub73b\ud55c\ub2e4.","6c58463a":"- sibsp\t# of siblings \/ spouses aboard the Titanic\n- parch\t# of parents \/ children aboard the Titanic\n- \uc774\ubbc0\ub85c \ub450 \uceec\ub7fc\uc740 \uc720\uc0ac\ud55c \uc131\uaca9\uc744 \uac00\uc9c0\uace0 \uc788\ub2e4\uace0 \ubcfc \uc218 \uc788\ub2e4.\n- \ub208\uc5ec\uaca8 \ubcfc \uc218 \uc788\ub294 \ubd80\ubd84\uc740 Parch\uc640 SiSap\uac00 0\uba85\uc77c \ub54c, \uc0dd\uc874\uc728\uc774 \ub192\uc740 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.","8b9005bd":"## Load data   \n\nLet's check what data files are available.","b9d5ee91":"train2 = train[features]\ntest2 = test[features]","9087de60":"fig, axes = plt.subplots(1,3, figsize=(8,6), constrained_layout=True)\n\nsns.countplot(x='Embarked', data=train, hue='Survived', ax=axes[0])\nsns.barplot(x='Embarked', y='Survived', data=train.groupby('Embarked').mean()['Survived'].reset_index(), order=['S', 'C', 'Q'], ax=axes[1])\nsns.countplot(x='Embarked', data=test, order=['S', 'C', 'Q'], ax=axes[2])","133ae1e2":"extract title","c3b92f4b":"# Y value\n","8e196223":"Missing value fill","5b2788ff":"train = pd.merge(train, a, how='left', on=['cate_age', 'Pclass', 'Sex'])\ntest = pd.merge(test, a, how='left', on=['cate_age', 'Pclass', 'Sex'])","2d6ae080":"Pclass\n\n- \uc704\uc758 \uadf8\ub798\ud504\ub97c \ubcf4\uc558\uc744 \ub54c, Pclass\uac00 1st \uc77c\ub54c\uac00 2nd, 3rd\ubcf4\ub2e4 \uc0dd\uc874\ub960\uc774 \ub0ae\uc740 \uac83\uc73c\ub85c \ubcf4\uc778\ub2e4.\n- \ub192\uc740 Pclass\uc77c \ub54c, \uc0dd\uc874\uc728\uc774 \ub0ae\ub2e4. \uc65c \uadf8\ub7f4\uae4c? \uc774\uac83\uc778 Ticket\uc744 \ud655\uc778\ud560 \ud544\uc694\ub3c4 \ubcf4\uc778\ub2e4.","2bea3526":"### Random Forest","38f328aa":"### Xgboost","101fee09":"regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=100).fit(\n    train2[test2.columns], train2['Survived'])\ntest_y = regr.predict(test2)\ntest_y = test_y > .5\npredictions = test_y.astype(int)\ntest_PassengerId = pd.read_csv('..\/input\/gender_submission.csv')['PassengerId']\nsubmission = pd.concat([pd.DataFrame(test_PassengerId), pd.DataFrame({'Survived':predictions})], axis=1)\nsubmission.to_csv(\"submission_rf4.csv\", index=False)","b9cb584d":"test2 = pd.concat([test2.iloc[:, :2], pd.get_dummies(test2.iloc[:, 2:].astype(object))], axis=1)","ffc7a6b9":"# <a id='3'>Data exploration<\/a>  \n\n## <a id='31'>Check the data<\/a>  \n\nLet's check the train and test set.","ca69ee58":"\ubb58 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. skew, std, etc...\n\nmissing data\ub97c \ucc98\ub9ac\ub97c \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ub370\uc774\ud130\uc14b\uc758 \ud1b5\uc77c \uc131\uc744 \uc704\ud574 train\uacfc test\ub97c \ud569\uccd0 \uc9c4\ud589\ud558\uaca0\uc2b5\ub2c8\ub2e4.","393431ae":"gbm = xgb.XGBClassifier(\n    learning_rate = 0.02,\n    n_estimators= 2000,\n    max_depth= 8,\n    min_child_weight= 2,\n    gamma=1,\n#     gamma=0.9,                        \n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic',\n#     nthread= -1,\n    scale_pos_weight=1).fit(train.drop(columns=['Survived', 'Cabin_first_T']), train['Survived'])\n\npredictions = gbm.predict(test)\ntest_PassengerId = pd.read_csv('..\/input\/gender_submission.csv')['PassengerId']\nsubmission2 = pd.concat([pd.DataFrame(test_PassengerId), pd.DataFrame({'Survived':predictions})], axis=1)\nsubmission2.to_csv(\"submission_xgb2.csv\", index=False)","69d7dddf":"train2 = df.iloc[:891, :]\ntest2 = df.iloc[891:, :]","6881c2d5":"a.columns = ['cate_age', 'Pclass', 'Sex', 'est_Survived']","cf70be7d":"\uacb0\uce21\uce58\uac00 \uc815\ub9ac \ub418\uc5c8\ub2e4.\n\n\ub2e4\uc2dc train, test data\ub85c \ubd84\ub9ac\uc2dc\ud0a8\ub2e4.","c4e7c474":"cv = KFold(5, shuffle=True, random_state=0)\nL = []\nfor i, (idx_train, idx_test) in enumerate(cv.split(train)):\n    train_val = train.iloc[idx_train]\n    test_val = train.iloc[idx_test]\n\n    L.append(xgb_model(train_val, test_val))\n    \nprint(np.mean(L)) ","cf98ee06":"a = train.groupby(['cate_age', 'Pclass', 'Sex']).mean()['Survived']","87e52aea":"- target column\uc744 \uc774\uc6a9\ud558\uc5ec, \ud30c\uc0dd\ubcc0\uc218\ub97c \uc0dd\uc131\ud574\ubcf4\uc558\uc744 \ub54c, \uac80\uc99d\uc14b\uc758 \uc815\ud655\ub3c4\ub294 \uc62c\ub77c\uac00\ub098, \ud14c\uc2a4\ud2b8\uc14b\uc758 \uc815\ud655\ub3c4\ub294 \uac10\uc18c\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.","c7277b7e":"- \ud2f0\ucf13\ubc88\ud638\uc5d0 \ub530\ub77c family size\uac00 \uc815\ud574\uc9c0\ub294 \uac83\uc774 \uc544\ub2d8\uc744 \uc54c \uc218 \uc788\ub2e4.\n- \uadf8\ub807\ub2e4\uba74, family size\uc740 \uc0ac\ub9dd\ub960\uc5d0 \uc601\ud5a5\uc744 \uc8fc\ub294\uac00?","0b7ce0ed":"- \ub300\uccb4\uc801\uc73c\ub85c 1st, 2nd\uac00 3rd\ubcf4\ub2e4 \uc6b0\uce21\uaf2c\ub9ac\uac00 \uc880\ub354 \ub450\ud130\uc6b4 \uac83\uc744 \ubcfc \uc218 \uc788\ub2e4.","cbe6d515":"- train data\ub97c \ubcf4\uc558\uc744 \ub54c, \uc57d 4\uac1c\uc758 \ubd09\uc6b0\ub9ac\uac00 \ubcf4\uc774\ub294\ub370, \uadf8 \ubd09\uc6b0\ub9ac\ub97c \uae30\uc900\uc73c\ub85c \uc704\uc758 bins\uae30\uc900\uc744 \uc138\uc6e0\ub2e4.","a743ca69":"# <a id='2'>Prepare for data analysis<\/a>  \n\n\n## Load packages","8b5a64c3":"feature engineering and modeling","43cd4f19":"embarked","a08a4e90":"Age","0bdcf74e":"Sex\n- basemodel\uc744 \ub9cc\ub4e4\uc5b4\ubcf8 \uacb0\uacfc \uac15\ub825\ud55c \ubcc0\uc218 \uc911 \ud558\ub098\uc774\ub2e4.\n- \ub0a8\uc131\uc758 \uacbd\uc6b0 \uc8fd\uc744 \ud655\ub960\uc774 \ub9e4\uc6b0 \ub192\uace0, \uc5ec\uc131\uc758 \uacbd\uc6b0 \uc0dd\uc874\ud655\ub960\uc774 \ub0a8\uc131\ubcf4\ub2e4 \ub192\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4.","0cfca599":"pari plot\uc73c\ub85c \ud241\uccd0\ubc84\ub9ac\uae30~ \ubcc0\uc218\uc5d0 \uad00\ub828\ub41c \ud574\uc11d \uc911\uc694\ud55c \uac83\ub9cc \uc798 \ubd10\ubc14\ub77c","6e611beb":"PassengerId is distinct, so delete","09e96077":"## Random Forest","88899aea":"pd.concat([pd.DataFrame(test_PassengerId), pd.DataFrame({'Survived':L})], axis=1).to_csv(\"submission_ensembles.csv\", index=False)","d96a4803":"\uce74\ube48\uc758 \uacb0\uce21\uce58\uac00 \ub108\ubb34 \ub9ce\uc740 \uac83\uc73c\ub85c \ubcf4\uc778\ub2e4. \uacb0\uce21\uce58\uac00 \uc758\ubbf8\uac00 \uc788\uc744 \uc9c0\ub3c4 \ubaa8\ub974\uae30 \ub54c\ubb38\uc5d0 no value\ub77c\ub294 \uac12\uc744 \ub123\uc5b4\ub454\ub2e4.","a5b11201":"# <a id='0'>Content<\/a>\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the data analysis<\/a>  \n- <a href='#3'>Data exploration<\/a>   \n - <a href='#31'>Check the data<\/a>   \n - <a href='#32'>Density plots of features<\/a>   \n - <a href='#33'>Distribution of mean and std<\/a>   \n - <a href='#34'>Distribution of min and max<\/a>   \n  - <a href='#35'>Distribution of skew and kurtosis<\/a>   \n - <a href='#36'>Features correlations<\/a>   \n - <a href='#37'>Duplicate values<\/a>   \n- <a href='#4'>Feature engineering<\/a>\n- <a href='#5'>Model<\/a>\n- <a href='#6'>Submission<\/a>  \n- <a href='#7'>References<\/a>","8088a879":"train2 = pd.concat([train['Survived'], train2.iloc[:, :2], pd.get_dummies(train2.iloc[:, 2:].astype(object))], axis=1)","02eb7411":"## <a id='32'>Density plots of features<\/a>  \n\ubcc0\uc218\ub4e4\uc5d0 \ub300\ud55c \ubd84\ud3ec\ub97c \ud655\uc778\ud574 \ubd05\uc2dc\ub2e4.\n\n\uba3c\uc800 target variable\uc778 Survived\uc5d0 \ub300\ud574 \ubd05\uc2dc\ub2e4","2422e857":"a = a.fillna(0).reset_index()","8393cb11":"# lebeling","53a097cf":"## Xgboost","2e53f0fc":"- \uacb9\uce58\uc9c0 \uc54a\ub294 \ubd80\ubd84\uc774 \uc788\uc5b4, \uc11c\ub85c \uacf5\ud1b5\uc73c\ub85c \uac00\uc9c0\uc9c0 \uc54a\ub294 \uceec\ub7fc\uc5d0 \ub300\ud574 etc\ub85c \ubcc0\ud658\ud55c\ub2e4."}}