{"cell_type":{"372e7cf7":"code","ba598a74":"code","d63988f2":"code","929dfe02":"code","7b2e74c8":"code","6da31c9e":"code","4f0c2f08":"code","4d25ae7f":"code","8daca8d6":"code","30c2d329":"code","7d1bc054":"code","e848009a":"code","b286cc50":"code","e6495102":"code","aec147af":"code","0117a0dc":"code","479b8778":"code","3b6c0a9a":"markdown","4e0d5584":"markdown","baff9c05":"markdown","4b17f607":"markdown","f6ab1ff8":"markdown","512eafb9":"markdown","0d2eade3":"markdown","a4979c36":"markdown","2edba2e5":"markdown","fcf1374f":"markdown","9faaacfd":"markdown","e8023af6":"markdown","47a70e6d":"markdown","29d32e24":"markdown","34b5af6e":"markdown","f7de097e":"markdown","844a4451":"markdown","6e62b5c9":"markdown","b1af61c5":"markdown","80e028ed":"markdown"},"source":{"372e7cf7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix \nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ba598a74":"df = pd.read_csv(\"..\/input\/textdb3\/fake_or_real_news.csv\")\nprint(df)","d63988f2":"print(df.shape)\ndf.head()","929dfe02":"df.isnull().any()","7b2e74c8":"labels=df.label\nlabels.head()","6da31c9e":"sep=df.label.value_counts()\nsep","4f0c2f08":"sns.countplot(df.label)\nplt.title(\"News published\")","4d25ae7f":"x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=0)","8daca8d6":"tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\ntfidf_train=tfidf_vectorizer.fit_transform(x_train) \ntfidf_trainnb=tfidf_train.toarray()\ntfidf_test=tfidf_vectorizer.transform(x_test)\ntfidf_testnb=tfidf_test.toarray()","30c2d329":"%%time\nlogreg = LogisticRegression()\nlogreg.fit(tfidf_train,y_train)\n","7d1bc054":"y_predlg=logreg.predict(tfidf_test)\nlgscore=accuracy_score(y_test,y_predlg)\nprint(f'Accuracy: {round(lgscore*100,2)}%')","e848009a":"%%time\ngnb = GaussianNB()\ngnb.fit(tfidf_trainnb,y_train)","b286cc50":"y_pred_nb = gnb.predict(tfidf_testnb)\nnbscore=accuracy_score(y_test,y_pred_nb)\nprint(f'Accuracy: {round(nbscore*100,2)}%')","e6495102":"%%time\npac=PassiveAggressiveClassifier(max_iter=50)\npac.fit(tfidf_train,y_train)\n\n","aec147af":"y_pred=pac.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')","0117a0dc":"nbg=round(nbscore*100,2)\npag=round(score*100,2)\nlogg=round(lgscore*100,2)\nx=np.array([\"Gaussian Naive Bayes\",\"Logistic Regression\",\"Passive Agressive\"])\ny=np.array([nbg,logg,pag])\n\n\nblist=plt.bar(x,y)\nblist[0].set_color('r')\nblist[2].set_color('g')\ncolors = {'GNB':'red','LogReg':'blue', 'PA':'green'}         \nlabels = list(colors.keys())\nhandles = [plt.Rectangle((0,0),4,4, color=colors[label]) for label in labels]\nplt.legend(handles, labels)\nfor bar in blist:\n    yval = bar.get_height()\n    plt.text(bar.get_x(), yval + .025, yval)\nplt.ylabel(\"Percent Accuracy\")\nplt.title(\"Classifier Comparison\")\nplt.show()\n#blt=plt.subplots()\n","479b8778":"\ncm = confusion_matrix(y_test,y_pred) # Confusion Matrix of PA Classifier\nls = [0, 1] \ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ls)\ndisp.plot()\nplt.show()","3b6c0a9a":"**11. Deploy Naive Baye's Classifiers** w\/runtime","4e0d5584":"**4. Clean dataframe**","baff9c05":"**10 Logistic Regression** w\/ runtime","4b17f607":"**5.Extract label from df**","f6ab1ff8":"**6.Count number of fake\/real news for plotting**","512eafb9":"**variable storing .toarray() are copies that are used with Gaussian Naive Bayes Classifier**","0d2eade3":"**3.Extract head and shape from df**","a4979c36":"**2.Read CSV File and create DataFrame**\n","2edba2e5":"**1.Imports**  Perform all the necessary imports.","fcf1374f":"**Test and Accuracy of GNB**","9faaacfd":"PA Classifier has better accuracy than NB and LogReg.\nPA Classifier Consumes less than NB and LogReg.","e8023af6":"**Out of all the classifier used here PA Classifier is the most efficient.**","47a70e6d":"**8.Data train,test,split. Create ML model.**","29d32e24":"**12.Calculate and plot Confusion Matrix**","34b5af6e":"**9.NLP with TfidVectorizer using stopwords with frequency max = 0.7 and run vectorizer data on Model created**","f7de097e":"**Visual Representation comparing the classifiers **","844a4451":"**12.Deploy Passive Agressive Classifier and use this for prediction and classification.**","6e62b5c9":"**Test and Accuracy of Logistic Regression**","b1af61c5":"**13.Measure accuracy.**","80e028ed":"**7.Plot graph comparing real and fake news**"}}