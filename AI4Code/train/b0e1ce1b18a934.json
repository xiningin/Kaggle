{"cell_type":{"9eb780e4":"code","70b49999":"code","9588ec2a":"code","ed53db12":"code","7b902aba":"code","287567df":"code","3ffe69cd":"code","9b0f90a1":"code","8c2d077e":"code","6ed022ed":"code","6e5f5e8e":"code","1fd74627":"code","2c936670":"code","e4b82cb2":"code","145c21e8":"code","6a1f9554":"markdown"},"source":{"9eb780e4":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\n\n# Read the file\nds = pd.read_csv(\"..\/input\/parkinson-2018\/pd_speech_features2018.csv\", header = 1)\n\nds.head()","70b49999":"#Data check\n\nds.dtypes","9588ec2a":"#I observed an conflict in the name 'class'. Therefore, I have changed the name from class to category\n\nds= ds.rename(columns={'class': 'Category'})","ed53db12":"# For convinience, divide the dataframe cc based on two labels. \n\ncon_obs = ds.loc[ds.Category==0]    #Data frame with control observation\npark_obs = ds.loc[ds.Category==1]    #Data frame with parkinson observation","7b902aba":"# The given dataframe 'ds' is divided into three sets \n# Training set: train_features\n# Test observations\/features: X_test\n# Test labels: Y_test","287567df":"# Once class SVM is trained with the observations of only one class. In this case, the algorithm is trained with \n# first 2000 observation of normal transactions. The remaining observation is merged with the anomalous observation \n# to create a test set. \n\ntrain_feature = con_obs.loc[0:2000, :]\ntrain_feature = train_feature.drop('Category', 1)","3ffe69cd":"# Creatng test observations\/features\n\nX_test_1 = con_obs.loc[2000:, :].drop('Category',1)\nX_test_2 = park_obs.drop('Category',1)\nX_test = X_test_1.append(X_test_2)","9b0f90a1":"# The remain data set is (after 2000 observations) are appended with anomalous observations\n\nY_1 = con_obs.loc[2000:, 'Category']\nY_2 = park_obs['Category']\n\nY_test= Y_1.append(Y_2)\n\n#Y_test is used to evaluste the model","8c2d077e":"# Setting the hyperparameters for One Class SVM\n\noneclass = svm.OneClassSVM(kernel='linear', gamma=0.001, nu=0.9)\n","6ed022ed":"# Training the algorithm with the features. \n\noneclass.fit(train_feature)","6e5f5e8e":"# Test the algorithm on the test set\n\ndisease_pred = oneclass.predict(X_test)","1fd74627":"# Check the number of outliers predicted by the algorithm\n\nunique, counts = np.unique(disease_pred, return_counts=True)\nprint (np.asarray((unique, counts)).T)","2c936670":"#Convert Y-test and fraud_pred to dataframe for ease of operation\n\nY_test= Y_test.to_frame()\nY_test=Y_test.reset_index()\ndisease_pred = pd.DataFrame(disease_pred)\ndisease_pred= disease_pred.rename(columns={0: 'prediction'})","e4b82cb2":"##Performance check of the model\n\nTP = FN = FP = TN = 0\nfor j in range(len(Y_test)):\n    if Y_test['Category'][j]== 0 and disease_pred['prediction'][j] == 1:\n        TP = TP+1\n    elif Y_test['Category'][j]== 0 and disease_pred['prediction'][j] == -1:\n        FN = FN+1\n    elif Y_test['Category'][j]== 1 and disease_pred['prediction'][j] == 1:\n        FP = FP+1\n    else:\n        TN = TN +1\nprint (TP,  FN,  FP,  TN)\n\n","145c21e8":"# Performance Matrix\n\naccuracy = (TP+TN)\/(TP+FN+FP+TN)\nprint ('acur\u00e1cia: ', accuracy)\nsensitivity = TP\/(TP+FN)\nprint ('sensitividade: ', sensitivity)\nspecificity = TN\/(TN+FP)\nprint ('especificidade: ', specificity)","6a1f9554":"Folks,\n\ncould someone help me in this implementation to classify parkinson in a UCI database http:\/\/archive.ics.uci.edu\/ml\/datasets\/Parkinson%27s+Disease+Classification\nI don't know why it's giving this error division by zero, but I know that there is something to do with True Positives that are zero.\nWhat am I doing wrong?\n\nThanks for the help!"}}