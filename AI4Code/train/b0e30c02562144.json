{"cell_type":{"50e1cd1b":"code","59b57cfc":"code","4dc6175c":"code","c06c4708":"code","a4b34be2":"code","2e93f495":"code","48a95341":"code","cec16eb5":"code","dab85530":"code","f2e3959b":"code","54f84edb":"code","d4f5e038":"code","7bfc94fa":"code","c726027b":"code","c6041bfa":"code","6a4a4906":"code","69aac360":"code","95e8ce29":"code","ad3f9eda":"code","4de9a1db":"code","6499e6e3":"code","25051c23":"code","e0c873b7":"code","c07c1e0b":"code","0599980f":"code","dc0fa393":"code","4ef268f6":"code","677c8bd5":"code","b18bdbb8":"code","5b1505b9":"code","6b3f9be5":"code","3d42e172":"code","d7803235":"code","071ee688":"code","1cb3f815":"code","2b5f35d7":"code","f214c87d":"code","77e96416":"code","69748149":"code","c59718c1":"code","2fd994d8":"code","9e0eb51a":"code","34b3dac8":"code","5f0c161f":"code","f3689083":"markdown","fbeff156":"markdown","8afedca3":"markdown","df8830d0":"markdown","a9e1eb16":"markdown","aef583d2":"markdown","816305f8":"markdown","0e5e98a7":"markdown","e0f1b75a":"markdown","a348e812":"markdown","d800c463":"markdown","b8afe4c4":"markdown","aa7d9acb":"markdown","290a53f9":"markdown","e29f6ab3":"markdown","aaabd1a0":"markdown","d5bf0bae":"markdown","afa53398":"markdown","43afd3a0":"markdown","42ed5309":"markdown","24b92baf":"markdown","0b33aeac":"markdown","bd9cf530":"markdown","ed2614ca":"markdown","46ac8563":"markdown"},"source":{"50e1cd1b":"import os \nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","59b57cfc":"data = pd.read_csv(\"..\/input\/spam.csv\",encoding='latin-1')","4dc6175c":"data.head()","c06c4708":"data['Unnamed: 2'].count()","a4b34be2":"data['Unnamed: 3'].count()","2e93f495":"data['Unnamed: 4'].count()","48a95341":"data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)","cec16eb5":"data.head()","dab85530":"data.rename(columns={'v1':'Label','v2':'Message'},inplace=True)","f2e3959b":"data","54f84edb":"data.dropna(inplace=True)","d4f5e038":"data.shape","7bfc94fa":"words=[]\n\nfor i in range(len(data['Message'])):\n    blob=data['Message'][i]\n    words+=blob.split(\" \")","c726027b":"len(words)","c6041bfa":"for i in range(len(words)):\n    if not words[i].isalpha():\n        words[i]=\"\"","6a4a4906":"word_dict=Counter(words)\nword_dict\nlen(word_dict)","69aac360":"del word_dict[\"\"]","95e8ce29":"word_dict=word_dict.most_common(3000)","ad3f9eda":"features=[]\nlabels=[]\n\nfor i in range(len(data['Label'])):\n\n    blob=data['Message'][i].split(\" \")\n    data1=[]\n    for j in word_dict:\n        data1.append(blob.count(j[0]))\n    features.append(data1)\n    \n    \n   \n    \n    ","4de9a1db":"features=np.array(features)","6499e6e3":"features.shape","25051c23":"labels=data.iloc[:,0]","e0c873b7":"for i in range(len(labels)):\n    if labels[i]=='ham':\n        labels[i]=0\n    else:\n        labels[i]=1","c07c1e0b":"labels.shape","0599980f":"labels=labels.values\nlabels=labels.astype(int)","dc0fa393":"labels","4ef268f6":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(features,labels,test_size=0.2,random_state=9)","677c8bd5":"xtrain.shape","b18bdbb8":"from sklearn.naive_bayes import MultinomialNB\nnbs=MultinomialNB()","5b1505b9":"nbs.fit(xtrain,ytrain)","6b3f9be5":"y_pred=nbs.predict(xtest)","3d42e172":"from sklearn.metrics import accuracy_score\naccuracy_score(y_pred,ytest)","d7803235":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(xtrain,ytrain)","071ee688":"pred = model.predict(xtest)","1cb3f815":"accuracy_score(ytest,pred)","2b5f35d7":"from sklearn.ensemble import RandomForestClassifier\nmodel1= RandomForestClassifier()\nmodel1.fit(xtrain,ytrain)","f214c87d":"prediction = model1.predict(xtest)","77e96416":"accuracy_score(ytest,prediction)","69748149":"from sklearn.metrics import confusion_matrix,classification_report","c59718c1":"print(classification_report(ytest, y_pred, target_names = [\"Ham\", \"Spam\"]))","2fd994d8":"print(classification_report(ytest, pred, target_names = [\"Ham\", \"Spam\"]))\n","9e0eb51a":"conf_mat = confusion_matrix(ytest, y_pred)\nconf_mat_normalized = conf_mat.astype('float') \/ conf_mat.sum(axis=1)[:, np.newaxis]","34b3dac8":"sns.heatmap(conf_mat_normalized)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","5f0c161f":"print(conf_mat)","f3689083":"So we see 3 NaN fields which we drop for our first model as the amount of data in them is very less.In required they can be incorporated later for further analysis","fbeff156":"Now lets clean the data and drop the nan values","8afedca3":"So the accuracy isnt bad as well","df8830d0":"Now lets check it using naive bayes classifier cause it works best in these situations","a9e1eb16":"First we import all the required libraries","aef583d2":"Now for model evaluation","816305f8":"So we have around 8k individual words . We now remove the words which had special charecters in them or were different","0e5e98a7":"So we find out the total number of words to be equal to 86961.\nNow we want to remove those words which have special charecters in them for ease of analysis\n","e0f1b75a":"For our naive bayes model","a348e812":"So thats an accuracy of 97% which isnt bad by any means","d800c463":"Now taking the words which occur very rarely may increase the amount of noise in the data.So we take ony the top 3000","b8afe4c4":"Now for the main thing we will count the total no of words we have in all of the sms combined.This will be the main step in the classifier","aa7d9acb":"Then we import the data ","290a53f9":"Now lets try with logistic regression","e29f6ab3":"Now we have our required output","aaabd1a0":"Now lets form the matrix where we have all the individual words as columns and the message index as rows and the values are filled by the frequency of each word corresponding to the row","d5bf0bae":"Now lets import our output variable","afa53398":"Now we perform train test split on our input and output","43afd3a0":"I am just a newbie in this field and this is my first kaggle submission.Constructive Feedback will be appreciated.I am a second year Graduation Student\n","42ed5309":"As the training models work much better on numeric data we convert labels in numeric data.We change Spam to 1 and Ham to 0.","24b92baf":"Now lets change the column names for better representation.We change v1 to 'Labels' and v2 to 'Message'","0b33aeac":"We now convert features into array","bd9cf530":"For our Logistic Regression Classifier Model","ed2614ca":"Now lets look at our data again\n","46ac8563":"By seeing the above confusion matrix, it is clear that 19 Ham are mis classified as Spam, and 12 Spam are misclassified as Ham. "}}