{"cell_type":{"f03251c2":"code","c297f961":"code","cde9c03d":"code","1a8765c8":"code","d3905186":"code","735363b8":"code","1a69f060":"code","68ac67de":"code","548ae97a":"code","c1e1abbf":"code","fb598e99":"code","19522f00":"code","42929eb1":"code","dfe8bd43":"code","04166ad1":"code","7291f154":"code","122cc9c0":"code","c5aa0700":"code","e812e05e":"code","22223be6":"code","61a4e0e9":"code","9f3b53b8":"code","857d10b3":"code","15f755ac":"code","adc9fe21":"code","fb68b189":"code","2d78a2b8":"code","5812dc2e":"code","7eb215e7":"code","ea0efe57":"code","85341fac":"code","4ddd0b95":"code","84704ee9":"code","ebe59cc0":"code","ed48d905":"code","59083bc5":"code","3d29ab07":"code","ef052827":"code","a745ccdc":"code","8881b49f":"code","a12722e7":"code","d2245ab2":"code","f50ac47f":"code","2768c291":"code","a77be481":"code","37b06cc2":"code","2bf573f5":"code","12a115f9":"code","9bcf5003":"code","45f98652":"code","3b1caf56":"code","45d4e223":"code","01683652":"code","40bf2a46":"code","c1114a42":"code","3e8522a8":"code","d0c900c4":"code","c9201a34":"code","e29d6659":"code","4e4fa8a1":"markdown","fe69c9a5":"markdown","0f1289fd":"markdown","57142bd0":"markdown","97aa7174":"markdown","6811d688":"markdown","c0983dff":"markdown","1420540e":"markdown","d1015420":"markdown","da9c0384":"markdown","587656f0":"markdown","0310204d":"markdown","0e39ed8d":"markdown","a8b38714":"markdown","480c60e0":"markdown","13ba2c9d":"markdown","8c435cb2":"markdown","213deb4b":"markdown","8d4c1723":"markdown","bb760a89":"markdown","c82b3c43":"markdown","6b48748d":"markdown","e1c044b2":"markdown","7d41514f":"markdown","e0f636f8":"markdown","b12ef59e":"markdown","a7d56126":"markdown","c20cb008":"markdown","3af564a9":"markdown","b37b2dfb":"markdown","cb15c7a7":"markdown","2e50c66e":"markdown","50993c4d":"markdown","288fdc1c":"markdown","92cd18cc":"markdown","816b4d6b":"markdown","b3275754":"markdown","1b091115":"markdown","46067ebc":"markdown","46144730":"markdown","13ac0f50":"markdown","5231ca03":"markdown","15d7b169":"markdown","93098c33":"markdown","d2f4424a":"markdown","429d62f3":"markdown","b391e39a":"markdown","1c356242":"markdown","60cbcff2":"markdown","a4fda491":"markdown","8d67cb21":"markdown","1b8338e4":"markdown","90f709c9":"markdown","2044156d":"markdown","03a528e5":"markdown","1c51c55c":"markdown","93d61d10":"markdown","42668324":"markdown","d10c3715":"markdown","877c84a1":"markdown","0b5f5c87":"markdown","456307db":"markdown","5483f6b3":"markdown","81a3ef39":"markdown","ff42fffb":"markdown","d4246946":"markdown","c3035878":"markdown","5e21b177":"markdown","a8736def":"markdown","be338db6":"markdown","4d9db36b":"markdown","5768f293":"markdown","9add029d":"markdown","c776c655":"markdown","f3ec44c5":"markdown","e2e7dfa5":"markdown","c8b54462":"markdown","77c97764":"markdown"},"source":{"f03251c2":"%%HTML\n\n<style type=\"text\/css\">\n\n.output {\n    align-items: center;\n}\n\n.title {\n  text-align: center;\n  font-family: 'Philosopher', sans-serif;\n  font-weight: 400;\n  font-size: 40pt;\n  line-height: 100%;\n  color: #020122;\n  margin-bottom: 0.1em;\n  margin-top: 0.1em;\n  display: block;\n}\n\n   \nblockquote  {\n  font: 27px 'Berkshire Swash', cursive;  \n  color:#d62828;\n  position: relative;\n  margin: 0;\n  padding: 30px 120px;\n  text-align: center;\n  \n}\n\nblockquote:before, blockquote:after {\n  position: absolute;\n  width: 50px;\n  height: 50px;\n  font-size:90px;\n  line-height: 1;\n}\n\nblockquote:before {\n  top: 0;\n  left: 0;\n  content: \"\\201C\";\n}\n\nblockquote:after {\n  top: 100;\n  right: 0;\n  content: \"\\201D\";\n}\n\n\n.h2 {\n    font-family: 'Philosopher', serif;\n    font-weight: 700;\n    font-size: 24pt;\n    line-height: 100%;\n    color: #020122;\n    margin-bottom: 0.1em;\n    margin-top: 0.1em;\n    display: block;\n    }\t\n    \n.multicol--container {\n  max-width: 800px;\n  margin: 0 auto;\n  column-width: 14em;\n  column-gap: 2em;\n  column-rule: 1px solid #ccc;\n}\n\nh3 {\n    font-family: 'Philosopher', serif;\n    font-weight: 400;\n    font-size: 22pt;\n    line-height: 100%;\n    color: #020122;\n    margin-bottom: 0.1em;\n    margin-top: 0.1em;\n    display: block;\n    text-decoration: underline;\n    }\n\n.heading-image{\n    box-shadow: 0px 0px 15px #355070;\n    width:900px;\n    height:600px;\n}\nspan.heading-citation{\n     font-size: 10px;\n     display:table;\n     margin-left: auto;\n     margin-right: auto;\n}\n<\/style>","c297f961":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport calendar\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom IPython.display import HTML\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n\n# Graphics in retina format \n%config InlineBackend.figure_format = 'retina' \n","cde9c03d":"kaggle_2020 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\nkaggle_2020['Time from Start to Finish (seconds)']=kaggle_2020['Time from Start to Finish (seconds)'].apply(pd.to_numeric, errors='coerce')\nkaggle_2020.rename(columns={'Time from Start to Finish (seconds)': 'time_spent_secs'}, inplace=True)\n\n#Qualified responses time spent morethan 2 minutes\nQkaggle_2020 = kaggle_2020.copy()\nQkaggle_2020.drop(Qkaggle_2020[Qkaggle_2020.time_spent_secs < 120.00].index, inplace=True)\n\nkaggle_2019 = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\")\n\nkaggle_2018 = pd.read_csv(\"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\")\n\nkaggle_2017=pd.read_csv(\"..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv\",encoding='ISO-8859-1')\n\nworld_unemp=pd.read_csv(\"..\/input\/oecd-unemployment-rate-2020\/2020 unemployment.csv\")\nind_unemployment=pd.read_csv(\"..\/input\/unemployment-in-india\/Unemployment_Rate_upto_11_2020.csv\")","1a8765c8":"col = ['#e63946','#a8dadc','#457b9d','#1d3557']\n\ndf_all_surveys = pd.DataFrame(data = [len(kaggle_2020),len(kaggle_2019),len(kaggle_2018),len(kaggle_2017)],\n                          columns = ['Number of responses'], index = ['2020','2019','2018','2017'])\ndf_all_surveys.index.names = ['Year of Survey']\n\nx = df_all_surveys['Number of responses'].index\ny = df_all_surveys['Number of responses'].values\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=x,\n        y=y,\n        name=\"line\",\n        line=dict(color='black')\n    \n    ))\n\nfig.add_trace(\n    go.Bar(\n        x=x,\n        y=y,\n        text=y,\n        width=0.4,\n        textposition='auto',\n        name=\"bar\",\n        marker= dict(color=col)\n    ))\n\nfig.data[0].marker.line.width = 1\nfig.data[0].marker.line.color = \"black\"\nfig.update_layout(yaxis=dict(title='Number of Respondents'),width=900,height=450,\n                  title='Figure 1: Total number of respondents over the years',template=\"plotly_white\",\n                  xaxis=dict(title='Years',tickmode = 'array',tickvals = [2017, 2018, 2019, 2020],ticktext = ['2017', '2018', '2019', '2020']))\n\nfig.show()","d3905186":"\nflatui = ['#e63946','#a8dadc','#457b9d','#1d3557','#fb8500','#4f772d','#0f4c5c',\n          '#a35f00','#5d2e46','#b33f62','#f9564f','#a4243b','#7e4931']\nsns.set(style=\"darkgrid\",font_scale=0.8)\ncurrentRole_count  = Qkaggle_2020['Q5'].value_counts(sort=True)\ncurrentRole_count = currentRole_count[:-1,]\nplt.figure(figsize=(15,10))\n\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',\n    fontsize='x-large'  \n)\n\n\nrole_plot = sns.barplot(currentRole_count.index,currentRole_count.values, alpha=1.0,palette=flatui)\n\nfor p in role_plot.patches:\n   role_plot.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nplt.title('Figure 2: Number of Kaggle practioners based on their role',fontsize=18,fontweight='bold', fontfamily='serif')\nplt.ylabel('Number of occurrences', fontsize=16,fontweight='bold', fontfamily='serif')\nplt.xlabel('Roles', fontsize=16, fontweight='bold', fontfamily='serif')\nplt.show()","735363b8":"world_unemp = world_unemp.query('SUBJECT == \"TOT\"')","1a69f060":"world_unemp.head()","68ac67de":"world_unemp['TIME'] = pd.to_datetime(world_unemp['TIME'],dayfirst=True)\nworld_unemp['FREQUENCY']= world_unemp['FREQUENCY'].astype('category')\nworld_unemp['Month'] =  world_unemp['TIME'].dt.month\nworld_unemp['Month_int'] = world_unemp['Month'].apply(lambda x : int(x))\nworld_unemp['Month_name'] = world_unemp['Month_int'].apply(lambda x: calendar.month_abbr[x])\nworld_unemp['LOCATION'] = world_unemp['LOCATION'].astype('category')\nworld_unemp.drop(columns='Month',inplace=True)","548ae97a":"\nfig1 = px.scatter_geo(world_unemp, color=\"Value\",locationmode=\"ISO-3\",locations=\"LOCATION\",opacity=0.9,\n                     hover_name=\"LOCATION\", size=\"Value\",projection='aitoff',animation_group =\"LOCATION\",color_continuous_scale='cividis',\n                     animation_frame=\"Month_name\",scope='world',template=\"plotly_white\",title='Figure 4: Impack of lockdown on employement across world JAN-OCT 2020' )\n\nfig1.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1500\n\n#fig1.update_geos(lataxis_range=[5,35], lonaxis_range=[65, 100])\nfig1.update_geos(\n    landcolor=\"white\",\n    oceancolor=\"#1d3557\",\n    showocean=True,\n    lakecolor=\"LightBlue\"\n)\n\nfig1.show()","c1e1abbf":"ind_unemployment.columns =['States','Date','Frequency','Estimated Unemployment Rate','Estimated Employed','Estimated Labour Participation Rate','Region','longitude','latitude']","fb598e99":"def process_unempdataset(df):\n    df['Date'] = pd.to_datetime(df['Date'],dayfirst=True)\n    df['Frequency']= df['Frequency'].astype('category')\n    df['Month'] =  df['Date'].dt.month\n    df['Month_int'] = df['Month'].apply(lambda x : int(x))\n    df['Month_name'] =  df['Month_int'].apply(lambda x: calendar.month_abbr[x])\n    df['Region'] = df['Region'].astype('category')\n    df.drop(columns='Month',inplace=True)\n    return df","19522f00":"ind_unemployment = process_unempdataset(ind_unemployment)","42929eb1":"fig = px.scatter_geo(ind_unemployment,'longitude', 'latitude', color=\"Region\",opacity=0.9,color_continuous_scale='cividis',\n                     hover_name=\"States\", size=\"Estimated Unemployment Rate\",\n                     animation_frame=\"Month_name\",scope='asia',template=\"plotly_white\",\n                     title='Figure 5: Impack of lockdown on employement across regions JAN-OCT 2020' )\n\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2000\n\nfig.update_geos(lataxis_range=[5,35], lonaxis_range=[65, 100],landcolor=\"white\", oceancolor=\"#1d3557\",\n    showocean=True,\n    lakecolor=\"LightBlue\")\n\nfig.show()","dfe8bd43":"col = ['#e63946','#a8dadc','#457b9d','#1d3557']\n\nunempCount_2020 = Qkaggle_2020['Q5'].value_counts(sort=True)\nunemp2020 = unempCount_2020['Currently not employed']\n\nunempCount_2019 = kaggle_2019['Q5'].value_counts(sort=True)\nunemp2019 = unempCount_2019['Not employed']\n\nunempCount_2018 = kaggle_2018['Q6'].value_counts(sort=True)\nunemp2018 = unempCount_2018['Not employed']\n\nunempCount_2017 = kaggle_2017['EmploymentStatus'].value_counts(sort=True)\nunemp2017 = unempCount_2017['Not employed, but looking for work']\n\ndf_all_unempCount = pd.DataFrame(data = [unemp2020,unemp2019,unemp2018,unemp2017],\n                          columns = ['unemployment Count'], index = ['2020','2019','2018','2017'])\ndf_all_unempCount.index.names = ['Year of Survey']\n\nunemp_x = df_all_unempCount['unemployment Count'].index\nunemp_y = df_all_unempCount['unemployment Count'].values\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=unemp_x,\n        y=unemp_y,\n        name=\"line\",\n       line=dict(color='black')\n    ))\n\nfig.add_trace(\n    go.Bar(\n        x=unemp_x,\n        y=unemp_y,\n        text=unemp_y,\n        width=0.4,\n        textposition='auto',\n        name=\"bar\",\n        #marker=dict(color='#e63946')\n        marker= dict(color=col)\n    ))\n\nfig.data[0].marker.line.width = 1\nfig.data[0].marker.line.color = \"black\"\nfig.update_layout(yaxis=dict(title='Not employed'),width=700,height=500,\n                  title='Figure 6: Total number of unemploument over the years',template=\"plotly_white\",\n                  xaxis=dict(title='Years',tickmode = 'array',tickvals = [2017, 2018, 2019, 2020],ticktext = ['2017', '2018', '2019', '2020']))\n\nfig.show()","04166ad1":"unemp_kaggle_2020=Qkaggle_2020.query('Q5 ==\"Currently not employed\"')\nunemp_kaggle_2019=kaggle_2019.query('Q5 ==\"Not employed\"')\nunemp_kaggle_2018=kaggle_2018.query('Q6 ==\"Not employed\"')\nunemp_kaggle_2017=kaggle_2017.query('EmploymentStatus ==\"Not employed, but looking for work\"')","7291f154":"def count_dataframe(counts,year,col1,col2='counts'):\n    df_value_counts = pd.DataFrame(counts)\n    df_value_counts = df_value_counts.reset_index()\n    df_value_counts.columns = [col1,col2]\n    df_value_counts['year']=year\n    return df_value_counts","122cc9c0":"unemp_expCount_2020 = unemp_kaggle_2020['Q6'].value_counts(sort=True)\nexp2020 = count_dataframe(unemp_expCount_2020,year='2020',col1='coding_experience')\n\nunemp_expCount_2019 = unemp_kaggle_2019['Q15'].value_counts(sort=True)\nexp2019 = count_dataframe(unemp_expCount_2019,year='2019',col1='coding_experience')\n\nunemp_kaggle_2018['Q24'] = unemp_kaggle_2018['Q24'].replace({'I have never written code but I want to learn':'I have never written code','I have never written code but I do not want to learn':'I have never written code'})\nunemp_expCount_2018 = unemp_kaggle_2018['Q24'].value_counts(sort=True)\nexp2018 = count_dataframe(unemp_expCount_2018,year='2018',col1='coding_experience')\n#exp2018=exp2018.drop([7])\ntotal = exp2018.iloc[6:10]['counts'].sum()\ndf2 = {'coding_experience': '20+ years', 'counts': total, 'year': '2018'} \nexp2018 = exp2018.append(df2, ignore_index = True) \nexp2018=exp2018.drop([6,7,8])#9+5+2=16 20+ years\n#exp2018['coding_experience'] = exp2018['coding_experience'].replace({'I have never written code but I want to learn':'I have never written code','I have never written code but I do not want to learn':'I have never written code'})\n\nunemp_expCount_2017 = unemp_kaggle_2017['LearningDataScienceTime'].value_counts(sort=True)\nexp2017 = count_dataframe(unemp_expCount_2017,year='2017',col1='coding_experience')\n\n#Allexp_count=pd.concat([exp2020,exp2019,exp2018,exp2017])\n#Allexp_count","c5aa0700":"  \nx = ['< 1 years', '1-2 years', '3-5 years', 'Never written code',\n       '5-10 years', '10-20 years', '20+ years', '< 1 year', '15+ years',\n       '10-15 years'] \n\ncolors = {'2017':'#1d3557',\n          '2018':'#457b9d',\n          '2019':'#a8dadc',\n          '2020':'#e63946'}\n  \nplot = go.Figure(data=[go.Bar( \n    name = '2017', \n    x = x, \n    marker_color=colors['2017'],\n    y = exp2017['counts'],\n    text=exp2017['counts'],\n    textposition='outside',\n      ), \n                       go.Bar( \n    name = '2018', \n    x = x, \n    marker_color=colors['2018'],\n    y = exp2018['counts'],\n    text=exp2018['counts'],\n    textposition='outside'\n   ) ,\n                       go.Bar( \n    name = '2019', \n    x = x, \n    marker_color=colors['2019'],\n    y = exp2019['counts'],\n    text=exp2019['counts'],\n    textposition='outside'\n    ) ,\n                       go.Bar( \n    name = '2020', \n    x = x, \n    marker_color=colors['2020'],\n    y = exp2020['counts'],\n    text=exp2020['counts'],\n    textposition='outside'\n   ) \n]) \n\nplot.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nplot.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',yaxis=dict(title='Not employed'),width=900,height=550,\n                   title='Figure 7: Total number of unemploument over the years based on coding experience',template=\"plotly_white\",\n                   xaxis=dict(title='coding experience'),\n                   annotations=[go.layout.Annotation(x=1.63, y=0.8, xref=\"x\", yref=\"paper\",\n                                text=\"More % of Unemployemnt <br> with coding experience<br>among all years survey\",\n                                showarrow=True, arrowhead=7, ax=0, ay=-40)])\n\nplot.add_shape(go.layout.Shape(\n                    type=\"rect\",\n                    xref=\"x\",\n                    yref=\"paper\",\n                   \n                    x0=-0.4,\n                    x1=2.4,\n                    y0=0.03,\n                    y1=1,\n                    fillcolor=\"red\",\n                    opacity=0.1,\n                    \n                    layer=\"below\",\n                    line_width=0))\n                               \nplot.show()","e812e05e":"unemp_eduCount_2020 = unemp_kaggle_2020['Q4'].value_counts(sort=True)\nedu2020 = count_dataframe(unemp_eduCount_2020,year='2020',col1='formal_education')\n\nunemp_eduCount_2019 = unemp_kaggle_2019['Q4'].value_counts(sort=True)\nedu2019 = count_dataframe(unemp_eduCount_2019,year='2019',col1='formal_education')\n\nunemp_eduCount_2018 = unemp_kaggle_2018['Q4'].value_counts(sort=True)\nedu2018 = count_dataframe(unemp_eduCount_2018,year='2018',col1='formal_education')\n\nunemp_eduCount_2017 = unemp_kaggle_2017['FormalEducation'].value_counts(sort=True)\nedu2017 = count_dataframe(unemp_eduCount_2017,year='2017',col1='formal_education')\n","22223be6":"  \nx_edu = [\"Bachelor's<br>degree\", \"Master's<br>degree\",\n       \"college\/univ<br>Without<br>bachelor's<br>degree\",\n       'Doctoral<br>degree',\n       'No formal<br>education<br>past high<br>school',\n       'Professional<br>degree', 'I prefer not<br> to answer'] \n\ncolors = {'2017':'#1d3557',\n          '2018':'#457b9d',\n          '2019':'#a8dadc',\n          '2020':'#e63946'}\n\n  \nfig_edu = go.Figure(data=[go.Bar( \n    name = '2017', \n    x = x_edu, \n    y = edu2017['counts'],\n    text=edu2017['counts'],\n    textposition='outside',\n    marker_color=colors['2017']\n   ), \n                       go.Bar( \n    name = '2018', \n    x = x_edu, \n    y = edu2018['counts'],\n    text=edu2018['counts'],\n    textposition='outside',\n    marker_color=colors['2018'],\n   ) ,\n                       go.Bar( \n    name = '2019', \n    x = x_edu, \n    y = edu2019['counts'],\n    text=edu2019['counts'],\n    textposition='outside',\n    marker_color=colors['2019'],\n    ) ,\n                       go.Bar( \n    name = '2020', \n    x = x_edu, \n    y = edu2020['counts'],\n    text=edu2020['counts'],\n    textposition='outside',\n    marker_color=colors['2020'],\n   ) \n]) \n\nfig_edu.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig_edu.update_layout(uniformtext_minsize=2,yaxis=dict(title='Not employed'),width=900,height=690,\n                   title='Figure 8: Total number of unemploument over the years based on Formal Education',barmode='group', xaxis_tickangle=-45,\n                   xaxis=dict(title='Formal Education'),template=\"plotly_white\",\n                   annotations=[go.layout.Annotation(x=1.63, y=0.75, xref=\"x\", yref=\"paper\",\n                                text=\"More % of Unemployemnt <br> in Bachelor's,Master's<br> and college\/university without a<br>bachelor's degree \",\n                                showarrow=True, arrowhead=7, ax=0, ay=-40)])\nfig_edu.add_shape(go.layout.Shape(\n                    type=\"rect\",\n                    xref=\"x\",\n                    yref=\"paper\",\n                   \n                    x0=-0.4,\n                    x1=2.4,\n                    y0=0.03,\n                    y1=1,\n                    fillcolor=\"red\",\n                    opacity=0.1,\n                    \n                    layer=\"below\",\n                    line_width=0))                  \nfig_edu.show()","61a4e0e9":"unemp_counCount_2020 = unemp_kaggle_2020['Q3'].value_counts(sort=True)\ncoun2020 = count_dataframe(unemp_counCount_2020,year='2020',col1='country')\ncoun2020['country'] = coun2020['country'].replace({'United States of America':'U.S.A','United Kingdom of Great Britain and Northern Ireland':'U.K'})\n\nunemp_counCount_2019 = unemp_kaggle_2019['Q3'].value_counts(sort=True)\ncoun2019 = count_dataframe(unemp_counCount_2019,year='2019',col1='country')\ncoun2019['country'] = coun2019['country'].replace({'United States of America':'U.S.A','United Kingdom of Great Britain and Northern Ireland':'U.K'})\n\nunemp_counCount_2018 = unemp_kaggle_2018['Q3'].value_counts(sort=True)\ncoun2018 = count_dataframe(unemp_counCount_2018,year='2018',col1='country')\ncoun2018['country'] = coun2018['country'].replace({'United States of America':'U.S.A','United Kingdom of Great Britain and Northern Ireland':'U.K'})\n\nunemp_counCount_2017 = unemp_kaggle_2017['Country'].value_counts(sort=True)\ncoun2017 = count_dataframe(unemp_counCount_2017,year='2017',col1='country')\ncoun2017['country'] = coun2017['country'].replace({'United States':'U.S.A',\"People 's Republic of China\":'China'})","9f3b53b8":"x_country=['India', 'U.S.A', 'Nigeria', 'Russia', 'Brazil', 'Indonesia','U.K', 'Spain','Japan',\n  'Canada','Taiwan','Germany','China','Turkey','Australia','France']\n\ncolors = {'2017':'#1d3557',\n          '2018':'#457b9d',\n          '2019':'#a8dadc',\n          '2020':'#e63946'}\n \nfig_coun = go.Figure(data=[go.Bar( \n    name = '2017', \n    x = x_country, \n    y = coun2017['counts'],\n    text=coun2017['counts'],\n    textposition='outside',\n    marker_color=colors['2017'],\n   ), \n                       go.Bar( \n    name = '2018', \n    x = x_country, \n    y = coun2018['counts'],\n    text=coun2018['counts'],\n    textposition='outside',\n    marker_color=colors['2018'],\n   ) ,\n                       go.Bar( \n    name = '2019', \n    x = x_country, \n    y = coun2019['counts'],\n    text=coun2019['counts'],\n    textposition='outside',\n    marker_color=colors['2019'],\n    ) ,\n                       go.Bar( \n    name = '2020', \n    x = x_country, \n    y = coun2020['counts'],\n    text=coun2020['counts'],\n    textposition='outside',\n    marker_color=colors['2020'],\n   ) \n]) \n\nfig_coun.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig_coun.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',yaxis=dict(title='Not employed'),width=940,height=650,\n                   title='Figure 9: Total number of unemploument over the years based on over all top 16 countries',barmode='group',\n                   xaxis_tickangle=-45,template=\"plotly_white\",\n                   xaxis=dict(title='Country'),\n                   annotations=[go.layout.Annotation(x=1, y=0.93, xref=\"x\", yref=\"paper\",\n                                text=\"More % of Unemployemnt <br> in india and USA over years  \",\n                                showarrow=True, arrowhead=7, ax=0, ay=-40)])\n\nfig_coun.add_shape(go.layout.Shape(\n                    type=\"rect\",\n                    xref=\"x\",\n                    yref=\"paper\",\n                   \n                    x0=-0.4,\n                    x1=1.4,\n                    y0=0.03,\n                    y1=1,\n                    fillcolor=\"red\",\n                    opacity=0.1,\n                    \n                    layer=\"below\",\n                    line_width=0))  \nfig_coun.show()\n","857d10b3":"unemp_genCount_2020 = unemp_kaggle_2020['Q2'].value_counts(sort=True)\ngender2020 = count_dataframe(unemp_genCount_2020,year='2020',col1='Gender')\ngender2020['Gender'] = gender2020['Gender'].replace({'Man':'Male','Woman':'Female'})\n\nunemp_genCount_2019 = unemp_kaggle_2019['Q2'].value_counts(sort=True)\ngender2019 = count_dataframe(unemp_genCount_2019,year='2019',col1='Gender')\n\nunemp_genCount_2018 = unemp_kaggle_2018['Q1'].value_counts(sort=True)\ngender2018 = count_dataframe(unemp_genCount_2018,year='2018',col1='Gender')\n\nunemp_genCount_2017 = unemp_kaggle_2017['GenderSelect'].value_counts(sort=True)\ngender2017 = count_dataframe(unemp_genCount_2017,year='2017',col1='Gender')\n","15f755ac":"x_gender=['Male','Female']\n\ncolors = {'2017':'#1d3557',\n          '2018':'#457b9d',\n          '2019':'#a8dadc',\n          '2020':'#e63946'}\n \nfig_gender = go.Figure(data=[go.Bar( \n    name = '2017', \n    x = x_gender, \n    y = gender2017['counts'],\n    text=gender2017['counts'],\n    textposition='outside',\n     marker_color=colors['2017']\n   ), \n                       go.Bar( \n    name = '2018', \n    x = x_gender, \n    y = gender2018['counts'],\n    text=gender2018['counts'],\n    textposition='outside',\n    marker_color=colors['2018'],\n   ) ,\n                       go.Bar( \n    name = '2019', \n    x = x_gender, \n    y = gender2019['counts'],\n    text=gender2019['counts'],\n    textposition='outside',\n    marker_color=colors['2019'],\n    ) ,\n                       go.Bar( \n    name = '2020', \n    x = x_gender, \n    y = gender2020['counts'],\n    text=gender2020['counts'],\n    textposition='outside',\n    marker_color=colors['2020'],\n   ) \n]) \n\nfig_gender.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig_gender.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',yaxis=dict(title='Not employed'),\n                   width=750,height=480,template=\"plotly_white\",\n                   title='Figure 10: Gender distribution over years (unemployment)',barmode='group', xaxis_tickangle=-45,\n                   xaxis=dict(title='Gender'))\n                   \nfig_gender.show()\n","adc9fe21":"unemp_ageCount_2020 = unemp_kaggle_2020['Q1'].value_counts(sort=True)\nage2020 = count_dataframe(unemp_ageCount_2020,year='2020',col1='Age')\n\n\nunemp_ageCount_2019 = unemp_kaggle_2019['Q1'].value_counts(sort=True)\nage2019 = count_dataframe(unemp_ageCount_2019,year='2019',col1='Age')\n\nunemp_ageCount_2018 = unemp_kaggle_2018['Q2'].value_counts(sort=True)\nage2018 = count_dataframe(unemp_ageCount_2018,year='2018',col1='Age')\ntot_age = age2018.iloc[10:12]['counts'].sum()\ndf2 = {'Age': '70+', 'counts': tot_age, 'year': '2018'} \nage2018 = age2018.append(df2, ignore_index = True) \nage2018=age2018.drop([10,11])#9+5+2=16 20+ years\n\n\nage_2017=unemp_kaggle_2017[[\"Age\"]]\nbins = [18,22, 25, 30, 35, 40, 45,50,55,60,70,120]\nlabels = [ '18-21','22-24','25-29','30-34', '35-39', '40-44', '45-49',\n       '50-54', '55-59', '60-69', '70+']\nage_2017['agerange'] = pd.cut(age_2017.Age, bins, labels = labels,include_lowest = True)\n\nunemp_ageCount_2017=age_2017['agerange'].value_counts(sort=True)\nage17=count_dataframe(unemp_ageCount_2017,year='2017',col1='Age')\n","fb68b189":"x_age=['25-29', '22-24', '30-34', '35-39', '40-44', '18-21', '55-59',\n       '45-49', '50-54', '60-69', '70+']\n\ncolors = {'2017':'#1d3557',\n          '2018':'#457b9d',\n          '2019':'#a8dadc',\n          '2020':'#e63946'} \n \nfig_age = go.Figure(data=[go.Bar( \n    name = '2017', \n    x = x_age, \n    y = age17['counts'],\n    text=age17['counts'],\n    textposition='outside',\n    marker_color=colors['2017']\n   ), \n                       go.Bar( \n    name = '2018', \n    x = x_age, \n    y = age2018['counts'],\n    text=age2018['counts'],\n    textposition='outside',\n    marker_color=colors['2018'],\n   ) ,\n                       go.Bar( \n    name = '2019', \n    x = x_age, \n    y = age2019['counts'],\n    text=age2019['counts'],\n    textposition='outside',\n    marker_color=colors['2019']\n    ) ,\n                       go.Bar( \n    name = '2020', \n    x = x_age, \n    y = age2020['counts'],\n    text=age2020['counts'],\n    textposition='outside',\n    marker_color=colors['2020'],\n   ) \n]) \n\nfig_age.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig_age.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',yaxis=dict(title='Not employed'),width=900,height=600,\n                   title='Figure 11: Age distribution over years (unemployment)',barmode='group', xaxis_tickangle=-45,\n                   template=\"plotly_white\",\n                   xaxis=dict(title='AGE'))\n                   \nfig_age.show()\n","2d78a2b8":"# Let's do gropuby on coding experience and Gender\nexp_gender=unemp_kaggle_2020.groupby(['Q6','Q2']).agg({'Q6':'count'})\nexp_gender = exp_gender.apply(lambda x: x.sort_values(ascending=False))\nexp_gender","5812dc2e":"# Let's take the values in column Q2(gender) and make it as column using Unstack\n# ref:https:\/\/www.youtube.com\/watch?v=kJsiiPK5sxs\ncode_exp=exp_gender.unstack()\ncode_exp","7eb215e7":"# It will unstack the Q6(coding experience) column values into columns --it is just good to know but i'm not using here\nexp_gender.unstack(0)","ea0efe57":"# the columns is now multi-index let's make it simple\nl=code_exp.copy()\nl.columns=['_'.join(col).strip()for col in l.columns.values]","85341fac":"px.bar(l,title='Figure 12: Gender Distribution along with coding experience(Unemployed) 2020',\n       labels={'value': 'Number of occurrences','Q6':'Coding Expereice','variable':'Gender'},\n       color_discrete_sequence=['#0e4677','#B0E0E6','#87CEFA','#4682B4','#fb5360'], barmode='overlay',\n       template=\"plotly_white\"\n      )","4ddd0b95":"#color palette\nprimary_blue = \"#1d3557\"\nprimary_grey = \"#c8c8c8\"\nTuscan_Red = \"#660033\"\npine_green = \"#157a6e\"","84704ee9":"only_prof_2020=Qkaggle_2020.query('Q5 !=\"Currently not employed\" & Q5 != \"Student\" & Q5 != \"Other\"')\nDS_prof=only_prof_2020[only_prof_2020['Q5'].str.contains('Data Scientist') | only_prof_2020['Q5'].str.contains('Machine Learning Engineer') | only_prof_2020['Q5'].str.contains('Data Analyst')|only_prof_2020['Q5'].str.contains('Data Engineer')]","ebe59cc0":"DS_prof.query('Q6 ==\"< 1 years\" & Q20 == \"10,000 or more employees\" ')['Q24'].unique()#< 1 years 3-5 years 1-2 years'Student'","ed48d905":"questions=Qkaggle_2020.drop(Qkaggle_2020.index[0])\nquestions = questions.columns\nq7 = [question for question in questions if 'Q7' in question]\n\nlanguages = []\nfor qn in q7:\n    for val in DS_prof[qn].unique():\n        languages.append(val)\n        \n        \nlanguages = [lang for lang in languages if str(lang)!='nan']\nprof_langs = (DS_prof.shape[0] - DS_prof[q7].isnull().sum()) \/ DS_prof.shape[0]\nunemp_langs = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q7].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_langs.index = languages\nunemp_langs.index = languages","59083bc5":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace2 = go.Bar(\n    y = languages,\n    x = prof_langs,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = primary_blue),\n    text = np.round(prof_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace2 = go.Bar(\n    y = languages,\n    x = prof_langs,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = primary_blue),\n    text = np.round(prof_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace1 = go.Bar(\n    y = languages,\n    x = unemp_langs,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 13: Programming Languages<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data Science professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_langs.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    #plot_bgcolor = \"#f4f0ea\",# \"#f6f2e8\"\n    template=\"plotly_white\"\n)\n\ndata = [trace1, trace2]\n\nfig = go.Figure(data = data, layout = layout)\n\n\niplot(fig)","3d29ab07":"q9 = [question for question in questions if 'Q9' in question]\n\nide = []\nfor qn in q9:\n    for val in DS_prof[qn].unique():\n        ide.append(val)\n\n\nide = [ides for ides in ide if str(ides)!='nan']\nprof_ide = (DS_prof.shape[0] - DS_prof[q9].isnull().sum()) \/ DS_prof.shape[0]\nunemp_ide = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q9].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_ide.index = ide\nunemp_ide.index = ide","ef052827":"from plotly.subplots import make_subplots\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace2 = go.Bar(\n    y = ide,\n    x = prof_ide,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = Tuscan_Red),\n    text = np.round(prof_ide*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace2 = go.Bar(\n    y = ide,\n    x = prof_ide,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = Tuscan_Red),\n    text = np.round(prof_ide*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace1 = go.Bar(\n    y = ide,\n    x = unemp_ide,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_ide*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 14: IDE<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_ide.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\ndata = [trace1, trace2]\nfig8 = go.Figure(data = data, layout = layout)\nide_fig=iplot(fig8)\n\n#ide_fig=iplot(fig1)","a745ccdc":"q10 = [question for question in questions if 'Q10' in question]\n\nnotebook = []\nfor qn in q10:\n    for val in DS_prof[qn].unique():\n        notebook.append(val)\n\n\nnotebook = [notebooks for notebooks in notebook if str(notebooks)!='nan']\nprof_notebook = (DS_prof.shape[0] - DS_prof[q10].isnull().sum()) \/ DS_prof.shape[0]\nunemp_notebook = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q10].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_notebook.index = notebook\nunemp_notebook.index = notebook","8881b49f":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = notebook,\n    x = prof_notebook,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_notebook*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = notebook,\n    x = prof_notebook,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_notebook*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = notebook,\n    x = unemp_notebook,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_notebook*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 15: Notebooks<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_notebook.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import subplots\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","a12722e7":"q14 = [question for question in questions if 'Q14' in question]\n\nviz_tool = []\nfor qn in q14:\n    for val in DS_prof[qn].unique():\n        viz_tool.append(val)\n\nviz_tool = [viz_tools for viz_tools in viz_tool if str(viz_tools)!='nan']\nprof_viztool = (DS_prof.shape[0] - DS_prof[q14].isnull().sum()) \/ DS_prof.shape[0]\nunemp_viztool = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q14].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_viztool.index = viz_tool\nunemp_viztool.index = viz_tool","d2245ab2":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = viz_tool,\n    x = prof_viztool,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_viztool*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = viz_tool,\n    x = prof_viztool,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_viztool*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = viz_tool,\n    x = unemp_viztool,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_viztool*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 16: Visualisation Tools<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_viztool.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","f50ac47f":"q16 = [question for question in questions if 'Q16' in question]\n\nframework = []\nfor qn in q16:\n    for val in DS_prof[qn].unique():\n        framework.append(val)\n\nframework = [frameworks for frameworks in framework if str(frameworks)!='nan']\nprof_framework = (DS_prof.shape[0] - DS_prof[q16].isnull().sum()) \/ DS_prof.shape[0]\nunemp_framework = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q16].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_framework.index = framework\nunemp_framework.index = framework","2768c291":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = framework,\n    x = prof_framework,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_framework*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = framework,\n    x = prof_framework,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_framework*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = framework,\n    x = unemp_framework,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_framework*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 17: Learning framework<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_framework.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","a77be481":"q17 = [question for question in questions if 'Q17' in question]\n\nalgorithm = []\nfor qn in q17:\n    for val in DS_prof[qn].unique():\n        algorithm.append(val)\n\nalgorithm = [algorithms for algorithms in algorithm if str(algorithms)!='nan']\nprof_algorithm = (DS_prof.shape[0] - DS_prof[q17].isnull().sum()) \/ DS_prof.shape[0]\nunemp_algorithm = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q17].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_algorithm.index = algorithm\nunemp_algorithm.index = algorithm","37b06cc2":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = algorithm,\n    x = prof_algorithm,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_algorithm*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = algorithm,\n    x = prof_algorithm,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_algorithm*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = algorithm,\n    x = unemp_algorithm,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_algorithm*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 18: ML algorithms<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_algorithm.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","2bf573f5":"q37 = [question for question in questions if 'Q37' in question]\n\nDS_course = []\nfor qn in q37:\n    for val in DS_prof[qn].unique():\n        DS_course.append(val)\n\nDS_course = [DS_courses for DS_courses in DS_course if str(DS_courses)!='nan']\nprof_DScourse = (DS_prof.shape[0] - DS_prof[q37].isnull().sum()) \/ DS_prof.shape[0]\nunemp_DScourse = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q37].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_DScourse.index = DS_course\nunemp_DScourse.index = DS_course","12a115f9":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = DS_course,\n    x = prof_DScourse,\n    orientation = \"h\",\n    name = \"Professionals\",\n    \n    marker = dict(color = pine_green),\n    text = np.round(prof_DScourse*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = DS_course,\n    x = prof_DScourse,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_DScourse*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = DS_course,\n    x = unemp_DScourse,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_DScourse*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 19: Data Science Courses<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_DScourse.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 900,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","9bcf5003":"q39 = [question for question in questions if 'Q39' in question]\n\nmedia = []\nfor qn in q39:\n    for val in DS_prof[qn].unique():\n        media.append(val)\n\nmedia = [medias for medias in media if str(medias)!='nan']\nprof_media = (DS_prof.shape[0] - DS_prof[q39].isnull().sum()) \/ DS_prof.shape[0]\nunemp_media = (unemp_kaggle_2020.shape[0] - unemp_kaggle_2020[q39].isnull().sum()) \/ unemp_kaggle_2020.shape[0]\n\nprof_media.index = media\nunemp_media.index = media","45f98652":"texttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = media,\n    x = prof_media,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_media*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% <\/b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% <\/b>\"\n\ntrace3 = go.Bar(\n    y = media,\n    x = prof_media,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = pine_green),\n    text = np.round(prof_media*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\ntrace4 = go.Bar(\n    y = media,\n    x = unemp_media,\n    name = \"unemployed\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(unemp_media*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlayout = dict(\n    title = \"<span style='font-size:26px'>Figure 20: Media<\/span><br><span style='color:#999; font-size: 16px; font-weight:200'>Data professionals vs Unemployed<\/span><br>\",\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend<\/span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_media.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 900,\n    height= 1000,\n    template=\"plotly_white\"\n    #plot_bgcolor = \"#f4f0ea\" #  \"#f6f2e8\"\n)\n\n\ndata = [trace4, trace3]\n#fig.add_trace(go.Figure(data = data, layout = layout), row=1, col=2)\nfig2 = go.Figure(data = data, layout = layout)\n\n#fig = subplots.make_subplots(rows=1, cols=2)\n#fig.append_trace(fig1,1,1)\n#fig.append_trace(fig2,1,2)\n\n\n#fig['layout'].update(layout)\nnote_fig=iplot(fig2)\n#iplot(fig)","3b1caf56":"less_expprof=DS_prof.query('Q6 in [\"< 1 years\", \"1-2 years\", \"3-5 years\"]')\nrole_prof = less_expprof.groupby(['Q1','Q6']).agg({'Q6':'count'})\nrole_prof = role_prof.apply(lambda x: x.sort_values(ascending=False))\nLexp_prof=role_prof.unstack()\n# the columns is now multi-index let's make it simple\nlp=Lexp_prof.copy()\nlp.columns=['_'.join(col).strip()for col in lp.columns.values]","45d4e223":"import plotly.graph_objects as go\n\n# Add data\nAge = lp.index\nexp_less_1 = list(lp['Q6_< 1 years'])\nexp_1_2 = list(lp['Q6_1-2 years'])\nexp_3_5 = list(lp['Q6_3-5 years'])\n\nfigB = go.Figure()\n# Create and style traces\nfigB.add_trace(go.Scatter(x=Age, y=exp_less_1, name='<1 years',\n                         line=dict(color='#d62828', width=4)))\nfigB.add_trace(go.Scatter(x=Age, y=exp_1_2, name = '1-2 years',\n                         line=dict(color='#f77f00', width=4)))\nfigB.add_trace(go.Scatter(x=Age, y=exp_3_5, name='3-5 years',\n                         line=dict(color='#003049', width=4,\n                              dash='dash') # dash options include 'dash', 'dot', and 'dashdot'\n))\n\n# Edit the layout\nfigB.update_layout(title='Figure 21: Data Professional with less coding experience',\n                   xaxis_title='Age',\n                   yaxis_title='Data Professionals count',\n                   width = 700,\n                   height= 590,template=\"plotly_white\")\n\n\nfigB.show()","01683652":"Lexp_Data_Scientist = DS_prof.query('Q6 in [\"< 1 years\", \"1-2 years\", \"3-5 years\"] & Q5==\"Data Scientist\"')\nLexp_Data_Analyst   = DS_prof.query('Q6 in [\"< 1 years\", \"1-2 years\", \"3-5 years\"] & Q5==\"Data Analyst\"')\nLexp_Data_Engineer  = DS_prof.query('Q6 in [\"< 1 years\", \"1-2 years\", \"3-5 years\"] & Q5==\"Data Engineer\"')\nLexp_ML_Engineer    = DS_prof.query('Q6 in [\"< 1 years\", \"1-2 years\", \"3-5 years\"] & Q5==\"Machine Learning Engineer\"')","40bf2a46":"less_exp=less_expprof[['Q1','Q2','Q3','Q4','Q5','Q6','Q20']].copy()\nless_exp.Q20 = less_exp.Q20.fillna('')\n\n\ncompany_size={'':'not specified', '0-49 employees':'small Enterprise', '50-249 employees':'medium Enterprise', '1000-9,999 employees':'10k Large Enterprise',\n       '10,000 or more employees':'10k+ Large Enterprise', '250-999 employees':'Large Enterprise'}\nless_exp['Q20']=less_exp['Q20'].map(company_size)\n\n\ngender={'Man':'Man', 'Woman':'Woman', 'Prefer not to say':'others', 'Nonbinary':'others',\n       'Prefer to self-describe':'others'}\nless_exp['Q2']=less_exp['Q2'].map(gender)\n\n\ncolor_map={'Data Analyst':'#ec7357',\n'Data Engineer':'#06a77d',\n'Data Scientist':'#052f5f',\n'Machine Learning Engineer' : '#ec9a29'\n}\n\n\nfig = px.sunburst(\n    data_frame=less_exp,\n    path=['Q5','Q6','Q20' ],  # Root, branches, leaves\n    color=\"Q5\",\n    color_discrete_map=color_map,\n    #color_discrete_sequence=px.colors.sequential.Tealgrn,\n    maxdepth=-1,                        # set the sectors rendered. -1 will render all levels in the hierarchy\n   # color=\"Q5\",\n    #color_continuous_scale=px.colors.sequential.BuGn,\n    # range_color=[10,100],\n\n    # branchvalues=\"total\",               # or 'remainder'\n    hover_name=\"Q5\",\n    hover_data={'Q5': False},    # remove column name from tooltip  (Plotly version >= 4.8.0)\n    title=\"Figure 22: Company Size based on coding expereince\",\n    template='presentation',         # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n    width=780,\n    height=650                                    # 'plotly_white', 'plotly_dark', 'presentation',\n                                       # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\nfig.update_traces(textinfo='label+percent parent')\n#fig.update_layout(margin=dict(t=0, l=0, r=0, b=0))\nfig.update_layout(template=\"plotly_white\",font_family='monospace')\n\nfig.show()","c1114a42":"lexp_sal=less_expprof[['Q1','Q2','Q3','Q4','Q5','Q6','Q20','Q24']].copy()\nlexp_sal.Q20 = lexp_sal.Q20.fillna('')\nlexp_sal.Q24 = lexp_sal.Q24.fillna('')\nlexp_sal['Q20']=lexp_sal['Q20'].map(company_size)","3e8522a8":"import plotly.io as pio\n# Build the violin\/box plot\n\nviolinfig = px.violin(\n    data_frame=lexp_sal.query('Q5==\"Data Scientist\"'),\n    #data_frame=lexp_sal,\n    x=\"Q20\",\n    y=\"Q24\",\n    category_orders={'Q20':['small Enterprise','medium Enterprise','Large Enterprise','10k Large Enterprise','10k+ Large Enterprise'],\n                     'Q24':[ '> $500,000','300,000-500,000','250,000-299,999','200,000-249,999','150,000-199,999','125,000-149,999','100,000-124,999', \n                             '90,000-99,999','80,000-89,999','70,000-79,999','60,000-69,999','50,000-59,999','40,000-49,999','30,000-39,999','25,000-29,999',\n                             '20,000-24,999','15,000-19,999','10,000-14,999','7,500-9,999','5,000-7,499','4,000-4,999','3,000-3,999','2,000-2,999',\n                             '1,000-1,999','$0-999']\n                    },\n    orientation=\"v\",              # vertical 'v' or horizontal 'h'\n    points='outliers',               # 'outliers','suspectedoutliers', 'all', or False\n    #box=True,                   # draw box inside the violins\n    #color='Q24',              # differentiate markers by color\n    #violinmode=\"group\",       # 'overlay' or 'group'\n    # color_discrete_sequence=[\"limegreen\",\"red\"],\n    # color_discrete_map={\"ALABAMA\": \"blue\" ,\"NEW YORK\":\"magenta\"}, # map your chosen colors\n\n    # hover_name='Year',          # values appear in bold in the hover tooltip\n    # hover_data=['State'],       # values appear as extra data in the hover tooltip\n    # custom_data=['Program'],    # values are extra data to be used in Dash callbacks\n\n    # facet_row='State',          # assign marks to subplots in the vertical direction\n    # facet_col='Period',         # assign marks to subplots in the horizontal direction\n    # facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n\n    # log_x=True,                 # x-axis is log-scaled\n    # log_y=True,                 # y-axis is log-scaled\n\n    labels={'Q20':\"company size\"},     # map the labels\n    title='Figure 23: Salary distribution in Data Scientist',\n    width=900,                   # figure width in pixels\n    height=500,                   # igure height in pixels\n    template='plotly_white',      # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                  # 'plotly_white', 'plotly_dark', 'presentation',\n                                  # 'xgridoff', 'ygridoff', 'gridon', 'none'\n\n    # animation_frame='Year',     # assign marks to animation frames\n    # animation_group='',         # use only when df has multiple rows with same object\n    # range_x=[5,50],             # set range of x-axis\n    # range_y=[-5,100],           # set range of y-axis\n    # category_orders={'Year':[2015,2016,2017,2018,2019]},    # set a specific ordering of values per column\n)\n\n# violinfig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000\n\n# violinfig.update_layout(\n#         yaxis = dict(\n#         tickfont=dict(size=8)))\n\npio.show(violinfig)","d0c900c4":"import plotly.io as pio\n# Build the violin\/box plot\n\nviolinfig = px.violin(\n    data_frame=lexp_sal.query('Q5==\"Data Analyst\"'),\n    #data_frame=lexp_sal,\n    x=\"Q20\",\n    y=\"Q24\",\n    category_orders={'Q20':['small Enterprise','medium Enterprise','Large Enterprise','10k Large Enterprise','10k+ Large Enterprise'],\n                     'Q24':[ '> $500,000','300,000-500,000','250,000-299,999','200,000-249,999','150,000-199,999','125,000-149,999','100,000-124,999', \n                             '90,000-99,999','80,000-89,999','70,000-79,999','60,000-69,999','50,000-59,999','40,000-49,999','30,000-39,999','25,000-29,999',\n                             '20,000-24,999','15,000-19,999','10,000-14,999','7,500-9,999','5,000-7,499','4,000-4,999','3,000-3,999','2,000-2,999',\n                             '1,000-1,999','$0-999']\n                    },\n    orientation=\"v\",              # vertical 'v' or horizontal 'h'\n    points='outliers',               # 'outliers','suspectedoutliers', 'all', or False\n    #box=True,                   # draw box inside the violins\n    #color='Q2',              # differentiate markers by color\n    #violinmode=\"group\",       # 'overlay' or 'group'\n    # color_discrete_sequence=[\"limegreen\",\"red\"],\n    # color_discrete_map={\"ALABAMA\": \"blue\" ,\"NEW YORK\":\"magenta\"}, # map your chosen colors\n\n    # hover_name='Year',          # values appear in bold in the hover tooltip\n    # hover_data=['State'],       # values appear as extra data in the hover tooltip\n    # custom_data=['Program'],    # values are extra data to be used in Dash callbacks\n\n    # facet_row='State',          # assign marks to subplots in the vertical direction\n    # facet_col='Period',         # assign marks to subplots in the horizontal direction\n    # facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n\n    # log_x=True,                 # x-axis is log-scaled\n    # log_y=True,                 # y-axis is log-scaled\n\n    labels={'Q20':\"company size\"},     # map the labels\n    title='Figure 24: Salary distribution in Data Analyst',\n    width=900,                   # figure width in pixels\n    height=500,                   # igure height in pixels\n    template='plotly_white',      # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                  # 'plotly_white', 'plotly_dark', 'presentation',\n                                  # 'xgridoff', 'ygridoff', 'gridon', 'none'\n\n    # animation_frame='Year',     # assign marks to animation frames\n    # animation_group='',         # use only when df has multiple rows with same object\n    # range_x=[5,50],             # set range of x-axis\n    # range_y=[-5,100],           # set range of y-axis\n    # category_orders={'Year':[2015,2016,2017,2018,2019]},    # set a specific ordering of values per column\n)\n\n# violinfig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000\n\n# violinfig.update_layout(\n#         yaxis = dict(\n#         tickfont=dict(size=8)))\n\npio.show(violinfig)","c9201a34":"import plotly.io as pio\n# Build the violin\/box plot\n\nviolinfig = px.violin(\n    data_frame=lexp_sal.query('Q5==\"Data Engineer\"'),\n    #data_frame=lexp_sal,\n    x=\"Q20\",\n    y=\"Q24\",\n    category_orders={'Q20':['small Enterprise','medium Enterprise','Large Enterprise','10k Large Enterprise','10k+ Large Enterprise'],\n                     'Q24':[ '> $500,000','300,000-500,000','250,000-299,999','200,000-249,999','150,000-199,999','125,000-149,999','100,000-124,999', \n                             '90,000-99,999','80,000-89,999','70,000-79,999','60,000-69,999','50,000-59,999','40,000-49,999','30,000-39,999','25,000-29,999',\n                             '20,000-24,999','15,000-19,999','10,000-14,999','7,500-9,999','5,000-7,499','4,000-4,999','3,000-3,999','2,000-2,999',\n                             '1,000-1,999','$0-999']\n                    },\n    orientation=\"v\",              # vertical 'v' or horizontal 'h'\n    points='outliers',               # 'outliers','suspectedoutliers', 'all', or False\n    #box=True,                   # draw box inside the violins\n    #color='Q2',              # differentiate markers by color\n    #violinmode=\"group\",       # 'overlay' or 'group'\n    # color_discrete_sequence=[\"limegreen\",\"red\"],\n    # color_discrete_map={\"ALABAMA\": \"blue\" ,\"NEW YORK\":\"magenta\"}, # map your chosen colors\n\n    # hover_name='Year',          # values appear in bold in the hover tooltip\n    # hover_data=['State'],       # values appear as extra data in the hover tooltip\n    # custom_data=['Program'],    # values are extra data to be used in Dash callbacks\n\n    # facet_row='State',          # assign marks to subplots in the vertical direction\n    # facet_col='Period',         # assign marks to subplots in the horizontal direction\n    # facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n\n    # log_x=True,                 # x-axis is log-scaled\n    # log_y=True,                 # y-axis is log-scaled\n\n    labels={'Q20':\"company size\"},     # map the labels\n    title='Figure 25: Salary distribution in Data Engineer',\n    width=900,                   # figure width in pixels\n    height=500,                   # igure height in pixels\n    template='plotly_white',      # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                  # 'plotly_white', 'plotly_dark', 'presentation',\n                                  # 'xgridoff', 'ygridoff', 'gridon', 'none'\n\n    # animation_frame='Year',     # assign marks to animation frames\n    # animation_group='',         # use only when df has multiple rows with same object\n    # range_x=[5,50],             # set range of x-axis\n    # range_y=[-5,100],           # set range of y-axis\n    # category_orders={'Year':[2015,2016,2017,2018,2019]},    # set a specific ordering of values per column\n)\n\n# violinfig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000\n\n# violinfig.update_layout(\n#         yaxis = dict(\n#         tickfont=dict(size=8)))\n\npio.show(violinfig)","e29d6659":"import plotly.io as pio\n# Build the violin\/box plot\n\nviolinfig = px.violin(\n    data_frame=lexp_sal.query('Q5==\"Machine Learning Engineer\"'),\n    #data_frame=lexp_sal,\n    x=\"Q20\",\n    y=\"Q24\",\n    category_orders={'Q20':['small Enterprise','medium Enterprise','Large Enterprise','10k Large Enterprise','10k+ Large Enterprise'],\n                     'Q24':[ '> $500,000','300,000-500,000','250,000-299,999','200,000-249,999','150,000-199,999','125,000-149,999','100,000-124,999', \n                             '90,000-99,999','80,000-89,999','70,000-79,999','60,000-69,999','50,000-59,999','40,000-49,999','30,000-39,999','25,000-29,999',\n                             '20,000-24,999','15,000-19,999','10,000-14,999','7,500-9,999','5,000-7,499','4,000-4,999','3,000-3,999','2,000-2,999',\n                             '1,000-1,999','$0-999']\n                    },\n    orientation=\"v\",              # vertical 'v' or horizontal 'h'\n    points='outliers',               # 'outliers','suspectedoutliers', 'all', or False\n    #box=True,                   # draw box inside the violins\n    #color='Q2',              # differentiate markers by color\n    #violinmode=\"group\",       # 'overlay' or 'group'\n    # color_discrete_sequence=[\"limegreen\",\"red\"],\n    # color_discrete_map={\"ALABAMA\": \"blue\" ,\"NEW YORK\":\"magenta\"}, # map your chosen colors\n\n    # hover_name='Year',          # values appear in bold in the hover tooltip\n    # hover_data=['State'],       # values appear as extra data in the hover tooltip\n    # custom_data=['Program'],    # values are extra data to be used in Dash callbacks\n\n    # facet_row='State',          # assign marks to subplots in the vertical direction\n    # facet_col='Period',         # assign marks to subplots in the horizontal direction\n    # facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n\n    # log_x=True,                 # x-axis is log-scaled\n    # log_y=True,                 # y-axis is log-scaled\n\n    labels={'Q20':\"company size\"},     # map the labels\n    title='Figure 26: Salary distribution in Machine Learning Engineer',\n    width=900,                   # figure width in pixels\n    height=500,                   # igure height in pixels\n    template='plotly_white',      # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                  # 'plotly_white', 'plotly_dark', 'presentation',\n                                  # 'xgridoff', 'ygridoff', 'gridon', 'none'\n\n    # animation_frame='Year',     # assign marks to animation frames\n    # animation_group='',         # use only when df has multiple rows with same object\n    # range_x=[5,50],             # set range of x-axis\n    # range_y=[-5,100],           # set range of y-axis\n    # category_orders={'Year':[2015,2016,2017,2018,2019]},    # set a specific ordering of values per column\n)\n\n# violinfig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000\n\n# violinfig.update_layout(\n#         yaxis = dict(\n#         tickfont=dict(size=8)))\n\npio.show(violinfig)","4e4fa8a1":"<a id='dataH'><\/a>\n<div class=\"h2\">  Initial Handling of Data<\/div>\n","fe69c9a5":"<div class=\"multicol--container\">\n<p>Analyzing multiple factors of unemployment by Combining two variable.currently not working practioners consists of both expereiced , newbie and expereiced people change in theit domain and carrer and lot other scenarios are there<\/p> \n<\/div>","0f1289fd":"## Key Takeaway:\n<div class=\"multicol--container\">\n    <h3>IDE<\/h3>\n    <p>Due to the rising popularity of open-source software in the industry, along with rapid growth of data science and machine learning the Jupyter Notebook has become ubiquitous among data scientists with 72% working with jupyter,followed by ML Engineer with 64% and by Data Engineer,Data Analyst with 62% and 60% respectively.<\/p>\n    <p>Visual Studio code(VS Code) is mostly used by Data Scientist and Data Analyst with 31% aprox and least used by ML Engineer and Data Engineer with 9% and 16% respectively.Unemployed is behind by 9% if they are trying for Data scientist or Data Analyst they should catch up the gap here.<\/p>\n    <p>PyCharm language specific IDE,so we can see the distribution here for Python and R.It's widely used by Data Engineer and ML Engineer with 15% and 12% and closely followed by Data scientist and Data Analyst by 10%. Unemployed is behind by 8%.<\/p>\n    <p>RStudio language specific IDE for R language. ML Engineer and Data Engineer are on top with 39% and 38%.They are closely followed by Data scientist 32% and Data Analyst with 22%.Unemployed are behind by 8% as the R language users are also less in unemployed when compared to professionals.<\/p>\n    <p>Spyder another language specific IDE it's widely used by ML Engineer with 41% and closely followed by Data Engineer with 35% and Data scientist with 31%. Data Analyst use 21% of this IDE.Unemployed is behind by 4%.<\/p>\n<\/div>    ","57142bd0":"## Now we learnt what we can expect ?\n\n","97aa7174":"\n<a id='cdr'><\/a>\n<div class=\"h2\"> worldwide unemployment 2020(JAN-OCT)<\/div>\n\n\n","6811d688":"Reference notebooks:\n* How is unemployment rate in India during covid-19 by Gokul raj K. : [https:\/\/www.kaggle.com\/gokulrajkmv\/how-is-unemployment-rate-in-india-during-covid-19](http:\/\/)\n* Enthusiast to Data Professional - What changes? by Schubert :[https:\/\/www.kaggle.com\/spitfire2nd\/enthusiast-to-data-professional-what-changes](http:\/\/)\n* Geek Girls Rising : Myth or Reality! by Parul Pandey : [https:\/\/www.kaggle.com\/parulpandey\/geek-girls-rising-myth-or-reality](http:\/\/)","c0983dff":"\n<img class=\"heading-image\" src=\"https:\/\/cdn.pixabay.com\/photo\/2020\/03\/07\/08\/23\/be-unique-4909103_1280.jpg\" alt=\"progress\">\n<span class=\"heading-citation\">Photo by mohamed_hassan on <a href=\"https:\/\/pixabay.com\/users\/mohamed_hassan-5229782\/\">pixabay.com<\/a><\/span>\n<\/img>","1420540e":"<a id='media'><\/a>\n<div class=\"h2\">Media on Data Science Topics<\/div>","d1015420":"<div class=\"multicol--container\">\n<p>Whereas the number of responses in 2018 was considerably higher than in 2017, the year 2019 has seen a decline and year 2020 has seen a slight increase compared to last year.<\/p> \n    \n<p>The data obtained from the survey are useful to know how the community works and where it's lacking<\/p>\n\n<p>The median time spent on the survey for qualified responses was 10.7 minutes,which is up from 9.5 minutes of last year.This is a positive sign that practioners spent more time on survey<\/p>\n<\/div>","da9c0384":"## *Ok we know the problem but how to find the solution???* \n### what we are missing out?\n<div class=\"multicol--container\">\n<p>It's a good thing that unemployed or newbie or wish to change the carrer, the first positive thing is going in right path as they practicipated in survey or they get to know about kaggle and its wonderful community which helps to grow together.they are already in a right place is upto individuals to utilize all the resources<\/p>\n<\/div>","587656f0":"<h3> Considering only the following professional related to ML\/DS :<\/h3>\n<ul>\n    <li>Data Scientist<\/li>\n    <li>Data Analyst<\/li>\n    <li>Data Engineer<\/li>\n    <li>Machine Learning Engineer<\/li>\n <\/ul>\n<p>As the practioners wish to become above one professionals in future :)<\/p>","0310204d":"<a id='sm'><\/a>\n<div class=\"h2\">  Survey methodology<\/div>\n","0e39ed8d":"<a id='cdc8'><\/a>\n<div class=\"h2\">Unemployment over years based on Gender<\/div>\n\n","a8b38714":"\n<a id='cdc5'><\/a>\n<div class=\"h2\"> Unemployment over years based on coding experience<\/div>\n","480c60e0":"<h3>TOP 5 IDE's Based on Importance by ROLE\/JOB:<\/h3>\n<ul>\n    <li>ML Engineer-Jupyter(64%),Spyder(41%),RStudio(39%),Pycharm(12%),VS Code(9%).<\/li>\n    <li> Data Engineer-Jupyter(62%),RStudio(38%),Spyder(35%),VS Code(16%),Pycharm(15%).<\/li>\n    <li>Data scientist-Jupyter(72%),RStudio(32%),Spyder(31%),VS Code(31%),Pycharm(10%).<\/li>\n    <li>Data Analyst-Jupyter(60%),VS Code(31%),RStudio(22%),Spyder(21%),Pycharm(10%).<\/li>\n<ul>","13ba2c9d":"<p><blockquote>If you\u2019re walking down the right path and you\u2019re willing to keep walking, eventually you\u2019ll make progress<\/blockquote><\/p>","8c435cb2":"<div class=\"multicol--container\">\n    <p>According to the OECD report,the OECD area unemployment rate continued to decline in October 2020, to 7.1%, from 7.3% in September, but remained about 2.0 percentage points above the level observed in February, before the COVID-19 pandemic hit the labour market.<\/p>\n    <p>The unemployment rate decreased slightly faster among women (down to 7.2% in October, from 7.5% in September) than among men (down to 6.9%, from 7.1%) in OECD countries, narrowing the gap to 0.3 percentage point, from 0.9 percentage point in April. The OECD area unemployment rate for youth (people aged 15 to 24) fell to 14.4% (from 14.7% in September and well below its peak of 19.0% in April 2020).<\/p>\n  \n    \n   <p>The eurozone, officially called the euro area,[7] is a monetary union of 19 member states of the European Union (EU) that have adopted the euro (\u20ac) as their primary currency and sole legal tender.In the euro area, the unemployment rate decreased marginally to 8.4% in October (remaining 1.2 percentage points above its February level), with decreases of 0.2 percentage point or more in France (to 8.6%), Latvia (to 8.0%), Luxembourg (to 6.5%) and Portugal (to 7.5%). By contrast, the unemployment rate increased by 0.2 percentage point in the Slovak Republic (to 7.0%) and Slovenia (to 4.9%).<\/p>\n    <p>Outside Europe, the unemployment rate decreased by 1.0 percentage point in the United States (to 6.9%), reflecting the decline in the number of people on temporary lay-off. The unemployment rate decreased by 0.3 percentage point in Colombia (to 16.3%), showed little changes in Canada (at 8.9%), Japan (at 3.1%) and Mexico (at 4.6%), but increased by 0.3 percentage point in Korea (to 4.2%). More recent data for November show that the unemployment rate declined further in the United States (to 6.7%) and Canada(to 8.5%).<\/p>\n    \n<\/div>","213deb4b":"<a id='cuct'><\/a>\n<div class=\"h2\">survey responses over the years<\/div>\n","8d4c1723":"<a id='ans'><\/a>\n<div class=\"h2\"> DS\/ML practitioners based on their role 2020<\/div>\n<p>Let's check what information does this year survey reveals about AI\/ML world !! <\/p>\n","bb760a89":"## Data Analyst","c82b3c43":"<div class=\"multicol--container\">\n<p>The media where profesionals sharp their skills and future professionals go to get their skills done is shown in comparison as it helps the course instructor\/professionals here to know where the large group of people goes and how they can focus on this certain group of people to acheive their goals<\/p>\n<p>Podcast also a great place to listen to professionals and entrepreneurs.If you are non-english it also helps to incerase your listening skills and some great podcast channels are available online <\/p>\n<\/div>","6b48748d":"<a id='cdc7'><\/a>\n<div class=\"h2\">Unemployment over years based on country<\/div>\n","e1c044b2":"<div class=\"multicol--container\">\n    <p>This is to inspire and show the point that if you had the required skill you will land in a good job \nhere we could see  irrespective  of the age there are more data professionals are there if you wish and start to improve your skill you could become data professionals  irrespective  of what age or coding experience you have.<\/p>\n<\/div>\n","7d41514f":"<img class=\"heading-image\" src=\"https:\/\/cdn.pixabay.com\/photo\/2016\/11\/15\/21\/29\/illustration-1827583_1280.jpg\" alt=\"boat\">\n<span class=\"heading-citation\">Photo by phtorxp on <a href=\"https:\/\/pixabay.com\/users\/phtorxp-3603324\/\">pixabay.com<\/a><\/span>\n<\/img>\n","e0f636f8":"<a id='cdc9'><\/a>\n<div class=\"h2\">Unemployment over years based on Age<\/div>\n","b12ef59e":"## Data Engineer","a7d56126":"<a id='compsize'><\/a>\n<div class=\"h2\">What to expect in Size of the company<\/div>","c20cb008":"## Key Takeaway:\n<div class=\"multicol--container\">\n       <p> The basic Ml algorithms are the good place to start learning Ml and Deep Learning.one should get to know atleast these top 10 alogorithms to further their studies.<\/p>\n        <ul>\n            <li>Linear or logistic Regression<\/li>\n            <li>Decision Tree or Random Forest<\/li>\n            <li>Gradient Boosting Machines<\/li>\n            <li>CNN<\/li>\n     <\/ul>\n    <p>The sure area of improvement for unemployed are <b>Gradient Boosting Machines,RNN and CNN<\/b> as we lag behid the professionals.<\/p>   \n<\/div>","3af564a9":"<img class=\"heading-image\" src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/06\/27\/18\/10\/company-3502288_1280.jpg\" alt=\"Survey\">\n<span class=\"heading-citation\">Photo by hurca on <a href=\"https:\/\/pixabay.com\/users\/hurca-8968775\/\">pixabay.com<\/a><\/span>\n<\/img>","b37b2dfb":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Data Scientist<\/h3>\n    <p>43% of Data Scientist among Data Professionals with minimum expereienced.The majority of groupy lies with <b>3-5 years experienced with 51%<\/b>,followed by 1-2 years experienced with 32% and Less than 1 year with 17%<\/p>\n    <p>3-5 years experienced Data scientist trends to works more in <b>Small Enterprise<\/b> with 32% and <b>10k+ Large Enterprise<\/b> with 22%<\/p>\n      <p>1-2 years experienced Data scientist trends to works more in <b>Small Enterprise with 51% and medium Enterprise with 13% ,then closely followed by 10k+ Large Enterprise with 12%<\/b><\/p>\n    <p>Less than 1 years experienced Data scientist trends to works more in <b>Small Enterprise with 67% and medium Enterprise with 9% ,then closely followed by 10k Large Enterprise with 7%<\/b><\/p>\n    <h3>Data Analyst<\/h3>\n    <p>31% of Data Analyst among Data Professionals with minimum expereienced.The majority of groupy lies with <b>1-2 years experienced with 39%<\/b>,followed by 3-5 years experienced with 33% and Less than 1 year with 27%<\/p>\n    <p>3-5 years experienced Data Analyst trends to works more in <b>Small Enterprise<\/b> with 28% and <b>10k+ Large Enterprise<\/b> with 19%,closely followed by Medium Enterprise with 18%<\/p>\n    <p>1-2 years experienced Data Analyst trends to works more in <b>Small Enterprise with 41% and 10k+ Large Enterprise with 15% ,then closely followed by 10k Large Enterprise with 13%<\/b><\/p>\n    <p>Less than 1 years experienced Data Analyst trends to works more in <b>Small Enterprise with 40% and medium Enterprise with 17% ,then closely followed by Large Enterprise with 12%<\/b><\/p>\n    \n    \n<\/div>\n","cb15c7a7":"<div class=\"multicol--container\">\n<p>Here to compare between consequtive years i am using grouped bar chart which is easy for human eye to catch the difference quickly and same color code is used for years to give the flow to analysis<\/p>\n<\/div>","2e50c66e":"## Machine Learning Engineer","50993c4d":"<a id='ident'><\/a>\n<div class=\"h2\">What IDE and Notebooks are used by professionals?<\/div>\n","288fdc1c":"<a id='dssal'><\/a>\n<div class=\"h2\">How much salary can be expected based on Size of the company<\/div>","92cd18cc":"## My initial notebook <a href=\"https:\/\/www.kaggle.com\/kavisekar\/trust-the-magic-of-new-beginning\">here<\/a>","816b4d6b":"<div class=\"multicol--container\">\n    <p>In India Unemployment rate is highest among youth with education until diploma (37%), graduate (36%) and post graduate and above (36%), suggesting the lack of opportunities for a higher skilled workforce, based on a report by Kotak Institutional Equities. This has been considered a ticking timebomb with approximately 50% of India\u2019s 1.3 Billion population being below the age of 25 years.<\/p>\n    <p>India and USA shows a drastic unemployment rate as it is likely to be considered that most of the practioners are from these country. But India show higher rate when compared to USA for 2020<\/p>","b3275754":"\n<a id='res'><\/a>\n<div class=\"h2\"> comparison of unemployment over years<\/div>\n ","1b091115":"<a id='dsprofs'><\/a>\n<div class=\"h2\">Data Professionals with minimum experience<\/div>\n<h3>once sailed in same boat!!\u26f5\u26f5\ud83d\udea9<\/h3>","46067ebc":"<a id='cdc6'><\/a>\n<div class=\"h2\"> Unemployment over years based on degree<\/div>\n","46144730":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Small Enterprise<\/h3>\n    <p>we can see that more people earn salaries toward the lower rather than the higher end of the range. This is revealed by the fact that the median at approximately 2,000-2,999 is closer to the bottom of the range than the top.<\/p>\n    <p> 25% professionals get salary above 30,000-39,999 and 75% professionals get below 30,000-39,999.Here max salary is 500,000<\/p>\n    <h3>Medium  Enterprise<\/h3>\n    <p>Upper fences cordon off outliers from the bulk of data in a set, here the max common salary range is             100,000-124,999 <\/p>\n    <p>50% professionals get salary above 7,500-9,999 and 50% professionals get salary below  7,500-9,999<\/p>\n    <p>25% professionals get salary above 30,000-39,999 and 75% professionals get below 30,000-39,999.Here the points in max are outliers greater than 500,000<\/p>\n    <h3>Large Enterprise<\/h3>\n    <p>50% professionals get salary above 15,000-19,999 and 50% professionals get salary below 15,000-19,999<\/p>\n    <p>25% professionals get salary above 90,000-99,999 and 75% professionals get below 90,000-99,999.Max salary is greater than 500,000<\/p>\n    <h3>10k Large Enterprise<\/h3>\n    <p>50% professionals get salary above 30,000-39,999  and 50% professionals get salary below 30,000-39,999<\/p>\n    <p>25% professionals get salary above 90,000-99,999 and 75% professionals get below 90,000-99,999.Max salary is        greater than 500,000<\/p> \n    <h3>10k+ Large Enterprise<\/h3>\n    <p>50% professionals get salary above 30,000-39,999   and 50% professionals get salary below 30,000-39,999<\/p>\n    <p>25% professionals get salary above 50,000-59,999 and 75% professionals get below 50,000-59,999.Max salary is        greater than 500,000<\/p> \n    \n<\/div>\n","13ac0f50":"<a id='learn'><\/a>\n<div class=\"h2\">Learning Framework<\/div>\n","5231ca03":"## Key Takeaway:\n<div class=\"multicol--container\">\n        <p>Visulaization tools are great to have in your skill set,it helps to communication with peoples easily.It's purely depends on individual and organization to use the tools they like and lots of modern visualization tools are also used.Here the top 5 Viz tools are:<\/p>\n        <ul>\n            <li>matplotlib<\/li>\n            <li>seaborn<\/li>\n            <li>plotly<\/li>\n            <li>ggplot<\/li>\n     <\/ul>\n     <p>The sure area of improvement for unemployed are plotly and ggplot as we lag behid the professionals.<\/p>\n    <p>To note that in this notebook i used plotly for almost all graphs and i learnt it completly new at beginning of this notebook.one can easily practice any Viz tools by making a EDA notebook in kaggle<\/p>\n    \n<\/div>","15d7b169":"<h3>TOP Notebooks's Based on Importance by ROLE\/JOB:<\/h3>\n<ul>\n    <li>ML Engineer-colab(50%),kaggle(40%),Binder(11%),Google Cloud AI Platform(11%).<\/li>\n    <li>Data Engineer-colab(33%),kaggle(32%),Binder(14%),Google Cloud AI Platform(7%).<\/li>\n    <li>Data scientist-colab(40%),kaggle(35%),Binder(12%),Google Cloud AI Platform(8%).<\/li>\n    <li>Data Analyst-kaggle(29%),colab(26%),Binder(12%),Google Cloud AI Platform(6%).<\/li>\n <\/ul>","93098c33":"<div class=\"multicol--container\">\n<p>The number of unemployment in 2017 was considerably higher than other subsequent years,In year 2018 and 2019 it has taken a fall which is positive sign but still we can see a little high in 2019.In the current year 2020 has high unemployment rate compared to last two years but it is not bad compared to 2017 and keeping in mind of current trends.<\/p>\n<\/div>","d2f4424a":"<div class=\"multicol--container\">\n<p>Here Bachelor,Masters and some university study gains a high unemployment rate over others.This graph justify that skilled populaiton are most unemployed<\/p>\n<\/div>","429d62f3":"<div  class=\"title\">Trust the Magic of New Beginning<\/div>","b391e39a":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Small Enterprise<\/h3>\n    <p>we can see that more people earn salaries toward the lower rather than the higher end of the range. This is revealed by the fact that the median at approximately 1,000-1,999 is closer to the bottom of the range than the top.<\/p>\n    <p>Upper fences cordon off outliers from the bulk of data in a set, here the max common salary range is             100,000-124,999 <\/p>\n      <p> Here 75th percentile(Q3) is 20,000-24,999.So 25% professionals get salary above 20,000-24,999 and 75% professionals get below 20,000-24,999.Here the points in max are outliers greater than 500,000<\/p>\n    <h3>Medium  Enterprise<\/h3>\n    <p>50% professionals get salary above 7,500-9,999 and 50% professionals get salary below  7,500-9,999<\/p>\n    <p>25% professionals get salary above 40,000-49,999 and 75% professionals get below 40,000-49,999.Max salary is greater than 500,000<\/p>\n    <h3>Large Enterprise<\/h3>\n    <p>50% professionals get salary above 15,000-19,999 and 50% professionals get salary below 15,000-19,999<\/p>\n    <p>25% professionals get salary above 40,000-49,999 and 75% professionals get below 40,000-49,999.Max salary is greater than 500,000<\/p>\n    <h3>10k Large Enterprise<\/h3>\n    <p>50% professionals get salary above 15,000-19,999  and 50% professionals get salary below 15,000-19,999<\/p>\n    <p>25% professionals get salary above 50,000-59,999 and 75% professionals get below 50,000-59,999.Max salary is        greater than 500,000<\/p> \n    <h3>10k+ Large Enterprise<\/h3>\n    <p>50% professionals get salary above 15,000-19,999   and 50% professionals get salary below 15,000-19,999 <\/p>\n    <p>25% professionals get salary above 60,000-69,999 and 75% professionals get below 60,000-69,999.Max salary is        greater than 500,000<\/p> \n    \n<\/div>\n","1c356242":"<div class=\"multicol--container\">\n    <h3>Python<\/h3>\n    <p>Python seems like a clear favourite with more than 80% of respondents using it.<\/p>\n    <h3>SQL<\/h3>\n    <p>Unemployed is behind by 18% so this is the area to improve.Working with databases seems to be a common part of most of our professionals work. Naturally,Data Engineers hasthe top spot here with 72% working with SQL. They  are however,closely followed by  Data  Engineers (72%),DataAnalysts and DataScientist(56%)<\/p>\n    <h3>R<\/h3>\n    <p>While most fields go the Python route,Data  Scientists with 37% of them working with this language followed by Data Analyst with 32% using the language.Unemployed is behind by 12% <\/p>\n    <h3>C,C++,Java<\/h3>\n    <p>These languages form the building blocks of students as they start coding.surprisingly unemployed are in same percent as professionals,however  they  don't  see  as  much  use  with  most data professionals other than Software Engineers.<\/p>\n    <h3>Less Common Languages<\/h3>\n    <p><span style='text-decoration:none'>1. Javascript - Software Engineers (43%)<br>2. MATLAB  -  Research Scientists (27%)<br>3. Bash  -  Database  Engineers   (25%) <br>4. Swift    -   Software  Engineers  (3%) <\/span><\/p>\n<\/div>","60cbcff2":"<a id='wrapup'><\/a>\n<div class=\"h2\">Wrap Up<\/div><br>\n\n<p>I hope you had an interesting time reading about my work and my insights! I also hope to have inspired you to learn Data science irrespective of the age or coding expereience.we also see what to expect from industry and job and salary range available for minimum experienced practioners.If we have necessary skills in our tool set we can acheive whatever we want.Hoping to see the unemployment bars lowers in this year 2021.<\/p>\n <p>To learn any thing new one need to have curiosity, creativity and learn from mistakes and apply the learnt things in real world.<\/p>\n \n <p><blockquote>fell,fast learn and move forward<\/blockquote><\/p>\n \n\n<p>Thanks a lot to the other participants of the competition for their insights, and of course thanks to the Kaggle team for letting us play with this great dataset!Any suggestions and feedback are always welcome.<\/p>\n\n","a4fda491":"![https:\/\/unsplash.com\/photos\/sPt5RIjKfpk](https:\/\/images.unsplash.com\/photo-1553984840-b8cbc34f5215?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80)\n\n<span>Photo by <a href=\"https:\/\/unsplash.com\/@jplenio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Johannes Plenio<\/a> on <a href=\"https:\/\/unsplash.com\/collections\/142433\/light?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash<\/a><\/span>","8d67cb21":"## Data Scientist","1b8338e4":"\n<img class=\"heading-image\" src=\"https:\/\/d12v9rtnomnebu.cloudfront.net\/diveimages\/IT_sector_reaches_2020_unemployment_high_as_national_rate_dips_.svg\"\nalt=\"IT_sector_reaches_2020_unemployment_high_as_national_rate_dips\">\n\n<span class=\"heading-citation\">Reference Article:Why IT services are recouping pandemic lossesby Roberto Torres @TorresLuzardo<a href=\"https:\/\/www.ciodive.com\/news\/IT-unemployment-services-sector-coronavirus\/584819\/\"> Source<\/a>\n<\/span>\n<\/img>","90f709c9":"\n<a id='cu'><\/a>\n<div class=\"h2\"> INDIA unemployment 2020(JAN-OCT) by Region<\/div>\n\n<p>scattermap reference from <a href=\"https:\/\/www.kaggle.com\/gokulrajkmv\/how-is-unemployment-rate-in-india-during-covid-19\">Kaggle notebook<\/a><\/p>","2044156d":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Small Enterprise<\/h3>\n    <p>we can see that more people earn salaries toward the lower rather than the higher end of the range. This is revealed by the fact that the median at approximately 1,000-1,999 is closer to the bottom of the range than the top.<\/p>\n    <p>Upper fences cordon off outliers from the bulk of data in a set, here the max common salary range is             200,000-249,999 <\/p>\n      <p> Here 75th percentile(Q3) is 20,000-24,999.So 25% professionals get salary above 20,000-24,999 and 75% professionals get below 20,000-24,999.Here the points in max are outliers greater than 500,000<\/p>\n    <h3>Medium  Enterprise<\/h3>\n    <p>50% professionals get salary above 15,000-19,999 and 50% professionals get salary below 15,000-19,999<\/p>\n    <p>25% professionals get salary above 50,000-59,999 and 75% professionals get below 50,000-59,999.Max salary is greater than 500,000<\/p>\n    <h3>Large Enterprise<\/h3>\n    <p>50% professionals get salary above 20,000-24,999 and 50% professionals get salary below 20,000-24,999<\/p>\n    <p>25% professionals get salary above 70,000-79,999 and 75% professionals get below 70,000-79,999.Max salary is greater than 500,000<\/p>\n    <h3>10k Large Enterprise<\/h3>\n    <p>50% professionals get salary above 25,000-29,999  and 50% professionals get salary below 25,000-29,999<\/p>\n    <p>25% professionals get salary above 80,000-89,999 and 75% professionals get below 80,000-89,999.Max salary is        greater than 500,000<\/p> \n    <h3>10k+ Large Enterprise<\/h3>\n    <p>50% professionals get salary above 30,000-39,999  and 50% professionals get salary below 30,000-39,999<\/p>\n    <p>25% professionals get salary above 70,000-79,999 and 75% professionals get below 70,000-79,999.Max salary is        greater than 500,000<\/p> \n    \n<\/div>\n","03a528e5":"<a id='pvsu'><\/a>\n<div class=\"h2\">Professionals Vs Unemployed<\/div>\n","1c51c55c":"<div class=\"h2\">Table of Contents<\/div>\n<ul>\n    <li><a href=\"#sm\">Survey methodology<\/a><\/li>\n    <ul>\n        <li><a href=\"#dataH\"> Initial Handling of Data<\/a>\n    <\/ul>\n    <li><a href=\"#cuct\">survey responses over the years<\/a><\/li>\n    <li><a href=\"#ans\">DS\/ML practitioners based on their role 2020<\/a><\/li>\n    <li><a href=\"#motivation\"> Analysis on specific community- Unemployment<\/a><\/li>\n    <li><a href=\"#cdr\">worldwide unemployment 2020(JAN-OCT)<\/a><\/li>\n    <li><a href=\"#cu\">INDIA unemployment 2020(JAN-OCT) by Region<\/a><\/li>\n    <li><a href=\"#res\">comparison of unemployment over the years<\/a><\/li>\n    <li><a href=\"#group\">Let's find where the majarity of the group lies<\/a><\/li>\n    <li><a href=\"#ans\">Data science and machine learning practitioners based on their role 2020<\/a><\/li>\n    <li><a href=\"#dis\">Let's find where the majarity of the group lies<\/a><\/li>\n    <ul>\n        <li><a href=\"#cdc5\">Unemployment over years based on coding experience<\/a><\/li>\n        <li><a href=\"#cdc6\">Unemployment over years based on degree<\/a><\/li>\n        <li><a href=\"#cdc7\">Unemployment over years based on country<\/a><\/li>\n        <li><a href=\"#cdc8\">Unemployment over years based on Gender<\/a><\/li>\n        <li><a href=\"#cdc9\">Unemployment over years based on Age<\/a><\/li>\n    <\/ul>\n    <li><a href=\"#gcex\">Unemployed based on Gender and coding experience 2020<\/a><\/li>\n    <li><a href=\"#pvsu\">Professionals Vs Unemployed<\/a><\/li>\n    <li><a href=\"#ident\">What IDE and Notebooks are used by professionals?<\/a><\/li>\n     <li><a href=\"#viz\">visulaization Tools<\/a><\/li>\n     <li><a href=\"#learn\">Learning Framework<\/a><\/li>\n    <li><a href=\"#mlalgo\">ML algorithms<\/a><\/li>\n    <li><a href=\"#dslearn\">Data Science Course<\/a><\/li>\n     <li><a href=\"#media\">Media on Data Science Topics<\/a><\/li>\n     <li><a href=\"#learn\">Learning Framework<\/a><\/li>\n    <li><a href=\"#dsprofs\">Data Professionals with minimum experience<\/a><\/li>\n    <li><a href=\"#compsize\">What to expect in Size of the company<\/a><\/li>\n    <li><a href=\"#dssal\">How much salary can be expected based on Size of the company<\/a><\/li>\n    <li><a href=\"#wrapup\">Wrap Up<\/a><\/li>   \n<\/ul>","93d61d10":"<a id='gcex'><\/a>\n<div class=\"h2\">Unemployed based on Gender and coding experience 2020<\/div>\n\n### A question is what is the gender ratio on coding experience ?","42668324":"<b>Please Upvote this notebook as it encourages me in doing better.<\/b>","d10c3715":"<div class=\"multicol--container\">\n    <p>It seems that student are very much interested in ML\/AI and other set of practitioners are professional Data Scientist and Software Engineer who actively engage and share the knowledge and all other professional are those make this community active making this place a wonderland to learn.<\/p>\n    <p>Here the 5th palce is not employed this triggered me to look into this closer and find the trends over the year.<\/p>\n    \n<\/div>\n","877c84a1":"<p>It's intersting that the top 5 practitioners are  :<\/p>\n\n* Student\n* Data Scientist\n* Software Engineer\n* Other\n* Currently not employed\n\n","0b5f5c87":"<p>For easy visibilty i changed text in size of company as follows:<\/p>\n<ul>\n    <li>0-49 employees \u27a1 small Enterprise <\/li>\n    <li>50-249 employees \u27a1 medium Enterprise<\/li>\n     <li>250-999 employees \u27a1 Large Enterprise<\/li>\n    <li>1000-9,999 employees \u27a1 10k Large Enterprise<\/li>\n    <li>10,000 or more employees \u27a1 10k+ Large Enterprise<\/li>\n    <li>nan \u27a1 not specified<\/li>\n<\/ul>","456307db":"<div class=\"multicol--container\">\n<h3>a.Kaggle survey 2020 methods<\/h3>\n    \n<p>This year report is based on a survey of 20,037 Kaggle practitioner from 171 different countries and territories around the world.<\/p>\n<p>If a country or territory received less than 50 respondents, Kaggle grouped them into a group named \u201cOther\u201d for anonymity.<\/p>\n\n<p>An invitation to participate in the survey was sent to the entire Kaggle community (anyone opted-in to the Kaggle Email List). The survey was also promoted on the Kaggle website and on the Kaggle Twitter channel.Live from 10\/07\/2020 to 10\/30\/2020.<\/p>\n\n\n<p>Responses to multiple choice questions (only a single choice can be selected) were recorded in individual columns. Responses to multiple selection questions (multiple choices can be selected) were split into multiple columns (with one column per answer choice). <\/p>\n\n   \n<h3>b.OECD Unemployment Rate Worldwide 2020 Data<\/h3>\n    \n<p>A subset of the the Main Economic Indicators (MEI) database, Labour market statistics includes labour force, unemployment level and rate, employment by industry and services.<\/p> \n    \n<p> Data are collected from sample household surveys on a monthly or quarterly basis for OECD countries and non-member economies.<\/p>\n    \n<p>This indicator is measured in numbers of unemployed people as a percentage of the labour force and it is seasonally adjusted.<\/p>\n\n<p>The labour force is defined as the total number of unemployed people plus those in employment.<\/p>\n    \n<h3>c. Unemployment Rate in India 2020 Data<\/h3>\n<p>The survey is planned and executed in a manner that enables the estimation of unemployment at a monthly frequency.The sample size of 43,600 household per month is well distributed over the country to enable the estimation of a monthly unemployment rate.<\/p>\n\n<p> The monthly sample is well-distributed over rural and urban regions to enable a weekly estimation of unemployment at the all-India level. About 10,900 households are surveyed every week.<\/p> \n    \n<p> These yield a sample of about 35,900 individuals for the estimation of weekly unemployment.The rural sample comprises 63,430 households from 3,965 villages.<\/p>\n\n<p>Survey is conducted all over the country, except in the following north eastern states - Arunachal Pradesh, Nagaland, Manipur, Mizoram, Andaman and Nicobar Islands, Lakshadweep, Dadra and Nagar Haveli, Daman and Diu The survey covers all other parts of the country.<\/p>\n\n<\/div>\n","5483f6b3":"<a id='dslearn'><\/a>\n<div class=\"h2\">Data Science Course<\/div>","81a3ef39":"<div>\n<p>Often new beginnings excite us and make us to feel curious and anxious about what would happen, especially taking a new career it beats us in every possible way like fear, self-doubts, finance\u2026. etc. But the magic lies behind the trust we keep and moving forward step by step looking into the possibility\u2019s despite of all hurdles. Due to COVID-19 It is new beginning for all of us whether we are employed or unemployed, Experienced or newbie It is changed our lives, we are virtually connected and work with distributed team worldwide. By looking at positive side we spend more time with our loved ones or learnt a new thing that excite us or even find a new self.<\/p><br> \n\n<p ><blockquote>All you need is trust and a little bit of pixie dust.<\/blockquote>\n\n<p>In this notebook i try to analyse the unemployment in Kaggle 2020 survey.By considereing the current situation we compare it with previous years survey to get a fair point and try to find where the majarity of the group lies and what are common things that stopping from entering into the ML\/AI world<\/p>\n<\/div>","ff42fffb":"<div class=\"multicol--container\">\n\n<p>Here i used 19,092 response data because this is the number of responses i consider \u201cqualified\u201d for analytical      purposes based on time spent on the full, completed survey.Approximately 944 responses were submitted but not included in this analysis because respondents spent less than two minutes on the survey.<\/p>\n\n<p> Kaggle previous survey from 2018 to 2019 along with current 2020 survey are included to compare the repeating Pattern of unemployment and other common factors.<\/p>\n\n<\/div>\n","d4246946":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Small Enterprise<\/h3>\n    <p>we can see that more people earn salaries toward the lower rather than the higher end of the range. This is revealed by the fact that the median at approximately 1,000-1,999 is closer to the bottom of the range than the top.<\/p>\n    <p>Upper fences cordon off outliers from the bulk of data in a set, here the max common salary range is             90,000-99,999 <\/p>\n      <p>25% professionals get salary above 10,000-14,999 and 75% professionals get below 10,000-14,999.Here the points in max are outliers greater than 500,000 , 125,000-149,999 , 100,000-124,999, 300,000-500,000<\/p>\n    <h3>Medium  Enterprise<\/h3>\n    <p>50% professionals get salary above 5,000-7,499 and 50% professionals get salary below  5,000-7,499<\/p>\n    <p>25% professionals get salary above 30,000-39,999 and 75% professionals get below  30,000-39,999.Max salary is greater than 500,000<\/p>\n    <h3>Large Enterprise<\/h3>\n    <p>50% professionals get salary above 20,000-24,999 and 50% professionals get salary below 20,000-24,999<\/p>\n    <p>25% professionals get salary above 40,000-49,999 and 75% professionals get below 40,000-49,999.Max salary is greater than 500,000<\/p>\n    <h3>10k Large Enterprise<\/h3>\n    <p>50% professionals get salary above 10,000-14,999  and 50% professionals get salary below 10,000-14,999<\/p>\n    <p>25% professionals get salary above 40,000-49,999 and 75% professionals get below  40,000-49,999.Max salary is        greater than 500,000<\/p> \n    <h3>10k+ Large Enterprise<\/h3>\n    <p>50% professionals get salary above 7,500-9,999 and 50% professionals get salary below  7,500-9,999 <\/p>\n    <p>25% professionals get salary above 40,000-49,999 and 75% professionals get below 40,000-49,999 .Max salary is        greater than 500,000<\/p> \n    \n<\/div>\n","c3035878":"<div class=\"multicol--container\">\n    <p>Unemployment rate is fairly higher(more than 100 every years) than others for these three groups less than 1 year, 1-2 year, 3-5 years over all years and it states clearly that beginners are struggling a lot and also 3-5 years they can also be a set of people changing their career path and new to ML\/AI\/newbie or intermediate <\/p>\n<\/div>\n","5e21b177":"<h3>Key takeaway:<\/h3>\n<ul>\n    <li>Python is the most popular language among two groups<\/li>\n    <li>both group have more or less similar percent for languages except SQL and R<\/li>\n    <li>Improvement Area- R and SQL are popular among professionals than unemployed so need to improve here<\/li>\n<\/ul>","a8736def":"<img class=\"heading-image\" src=\"https:\/\/cdn.pixabay.com\/photo\/2016\/09\/27\/03\/39\/overcoming-1697546_1280.jpg\" alt=\"leap\">\n<span class=\"heading-citation\">Photo by waldryano on <a href=\"https:\/\/pixabay.com\/users\/waldryano-309781\/\">pixabay.com<\/a><\/span>\n<\/img>\n","be338db6":"<div class=\"multicol--container\">\n<p>Let's look closer look into india unemployment as majority of practioner are from india<\/p>\n    <p>According to a survey conducted by the Centre for Monitoring Indian Economy (CMIE).The report has highlighted that the unemployment rate for the given group was projected at 13.2% during September - December period in 2018. While in 2017, the number stood at 12.1% for the qualified Indians. The highly educated set of individuals \u2014 those with bachelor\u2019s degrees and above \u2014 faced the maximum unemployment while the students who passed high school stood at 10.6%, in terms of unemployment numbers.<\/p>\n    <p>People who have completed a bachelor\u2019s degree or any other higher level of education account for only 10% of the working age population of India. While over 100 million had a bachelor\u2019s degree or higher as of 2018. Out of these, nearly 53 million of those were employed. While eight million were looking for jobs.\nPost graduates (master\u2019s or higher) in India have been facing the biggest challenge to fetch jobs. The unemployment rate among those with a master\u2019s degree is twice the unemployment among the entire labour force, according to the report.<\/p>\n<p>The unemployment rate in India rose to 23.5% in Apr 2020 from 7.2 percent in February 2019, the highest since September 2016<\/p>\n<p>This Scatter map shows monthly unemployment rate across various state and region and it's gradually decerasing<\/p>\n<\/div>","4d9db36b":"<div class=\"multicol--container\">\n<p>In U.S the unemployment rate for IT occupations reached 4.6%, above the previous month's 4.4%, according to CompTIA analysis of the Bureau of Labor Statistics' monthly report.National data in the monthly report showed a recovering economy, with 1.4 million jobs added in August and an overall unemployment rate that fell to 8.4% from 14.7% in April 2020.The employment uptick in the IT services category is one positive sign for the industry.<\/p>\n<\/div>","5768f293":"## Key Takeaway:\n<div class=\"multicol--container\">\n       <p> Various kind of Learning Frameworks are used in projects for ML application development.The framework differs based on company and kind of project. So good to know frameworks are:<\/p>\n        <ul>\n            <li>Scikit-learn<\/li>\n            <li>Tensorflow<\/li>\n            <li>keras<\/li>\n            <li>xgboost<\/li>\n     <\/ul>\n    <p>The sure area of improvement for unemployed are <b>xgboost,pytorch and keras<\/b> as we lag behid the professionals.<\/p>   \n<\/div>","9add029d":"## Key Takeaway\n<div class=\"multicol--container\">\n    <h3>Machine learning Engineers<\/h3>\n    <p>20% of ML Engineers among Data Professionals with minimum expereienced.The majority of groupy lies with <b>3-5 years experienced with 45%<\/b>,followed by 1-2 years experienced with 36% and Less than 1 year with 19%<\/p>\n    <p>3-5 years experienced ML Engineers trends to works more in <b>Small Enterprise<\/b> with 49% and <b>Medium Enterprise<\/b> with 14%,then closely followed by 10k+ Large Enterprise with 12%<\/p>\n    <p>1-2 years experienced ML Engineers trends to works more in <b>Small Enterprise with 64% and medium Enterprise with 11%<\/b><\/p>\n    <p>Less than 1 years experienced ML Engineers trends to works more in <b>Small Enterprise with 61% and 10k+ Large Enterprise with 8%<\/b><\/p>\n    <h3>Data Engineer<\/h3>\n    <p>6% of Data Engineer among Data Professionals with minimum expereienced.The majority of groupy lies with <b>3-5 years experienced with 56%<\/b>,followed by 1-2 years experienced with 29% and Less than 1 year with 15%<\/p>\n    <p>3-5 years experienced Data Engineer trends to works more in <b>10k+ Large Enterprise with 23% and Small Enterprise<\/b> with 21%,closely followed by Medium Enterprise with 19%<\/p>\n    <p>1-2 years experienced Data Engineer trends to works more in <b>Small Enterprise with 31% and 10k+ Large Enterprise with 20% <\/b><\/p>\n    <p>Less than 1 years experienced Data Engineer trends to works more in <b>Medium Enterprise with 27% and Small Enterprise with 23%<\/b><\/p>\n\n    \n    \n<\/div>\n","c776c655":"<a id='motivation'><\/a>\n<div class=\"h2\"> Analysis on specific community- Unemployment<\/div>\n","f3ec44c5":"<a id='viz'><\/a>\n<div class=\"h2\">visulaization Tools<\/div>","e2e7dfa5":"<a id='group'><\/a>\n<div class=\"h2\"> Let's find where the majarity of the group lies<\/div>\n\n","c8b54462":"## Key Takeaway:\n<div class=\"multicol--container\">\n    <h3>Notebook<\/h3>\n    <p>Colab and kaggle are mostly used Notebook by both professionals and unemployed.There is a room to improve for unemployed in colab as they lag by 7%.It seems that ML Engineers love both Kaggle and colab notebooks with 40% and 50% respectively,followed by Data Scientist with 35%(kaggle) and 40%(colab).Data Enginers use 32%(kaggle) and 33%(colab),Data Analyst use them with 29%(kaggle) and 26%(colab)<\/p>\n    <p>surprisingly 25% of profressionals not require hosted notebooks.as not all roles require the hosted notebooks.<\/p>\n    <p>Bottom of Top 5 list are Binder\/JupyterHub and google cloud AI. Binder\/JupyterHub are widely used by Data Engineer with 14% and closely followed by Data Scientist and Data Analyst with 12% and ML Engineer 11%<\/p>\n    <p>Google Cloud AI Platform Notebooks widely used by ML Engineer with 11% and closely followed by Data Scientist with 8% and Data Engineer with 7%. Data Analyst use  6% of this notebook<\/p>\n    <p> Based on the job and project working the other notebooks can also be a great help and it can be learnt while needed.<\/p>\n<\/div>","77c97764":"<a id='mlalgo'><\/a>\n<div class=\"h2\">ML algorithms<\/div>\n "}}