{"cell_type":{"1ad024f1":"code","d11081d2":"code","89c3207e":"code","cf7f182b":"code","d82f5328":"code","7b433d28":"code","2fea50bb":"code","225741fe":"code","fe585e70":"code","23869b1f":"code","3eac9c4e":"code","1910f3e6":"code","9e4c6dd9":"code","f2677a41":"code","829af85e":"code","e273ba83":"code","a892096e":"code","5890f3a8":"code","20b10362":"code","94cde113":"code","3e9a2c57":"markdown","52cd64a8":"markdown","2564c365":"markdown","1b61457c":"markdown","29b1b527":"markdown","0863b000":"markdown","a13fd3cb":"markdown"},"source":{"1ad024f1":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\n        \ninput_path = Path('\/kaggle\/input\/tabular-playground-series-feb-2021\/')","d11081d2":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\ndisplay(train.head())","89c3207e":"test = pd.read_csv(input_path \/ 'test.csv', index_col='id')\ndisplay(test.head())","cf7f182b":"submission = pd.read_csv(input_path \/ 'sample_submission.csv', index_col='id')\ndisplay(submission.head())","d82f5328":"train.dtypes","7b433d28":"train.info()","2fea50bb":"train.describe()","225741fe":"cat_df = train.select_dtypes(include=\"object\")\ncat_cols = cat_df.columns\nnum_df = train.select_dtypes(exclude=\"object\")\nnum_cols = num_df.columns","fe585e70":"fig = plt.figure(figsize=(20, 20))\na, b, c=5, 2, 1\nfor col in cat_cols:\n    plt.subplot(a, b, c)\n    sns.countplot(x=col, data = cat_df)\n    c += 1\nplt.show()","23869b1f":"test_cat_df = test.select_dtypes(include=\"object\")\ntest_cat_cols = test_cat_df.columns\ntest_num_df = test.select_dtypes(exclude=\"object\")\ntest_num_cols = test_num_df.columns","3eac9c4e":"fig = plt.figure(figsize=(20, 20))\na, b, c=5, 2, 1\nfor col in test_cat_cols:\n    plt.subplot(a, b, c)\n    sns.countplot(x=col, data = test_cat_df)\n    c += 1\nplt.show()","1910f3e6":"to_drop = ['cat0', 'cat2', 'cat4', 'cat6', 'cat7']\ntrain = train.drop(to_drop, axis=1)\ntest = test.drop(to_drop, axis=1)","9e4c6dd9":"for c in train.columns:\n    if train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values))\n        train[c] = lbl.transform(train[c].values)\n        test[c] = lbl.transform(test[c].values)\n        \ndisplay(train.head())","f2677a41":"train.describe()","829af85e":"sns.heatmap(train.corr())","e273ba83":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.90)","a892096e":"model = lgb.LGBMRegressor(objective='rmse', n_estimators=100, max_depth=10)","5890f3a8":"scores = cross_val_score(model, train, target, cv=10, scoring='neg_mean_squared_error')\nprint(np.sqrt(-np.mean(scores)))","20b10362":"model.fit(train, target)\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('lgbm.csv')","94cde113":"from sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(target, model.predict(train)))","3e9a2c57":"# Distributions of Columns","52cd64a8":"## We need to encode the categoricals.\n\nThere are different strategies to accomplish this, and different approaches will have different performance when using different algorithms. For this starter notebook, we'll use simple encoding.","2564c365":"## Now you should save your Notebook (blue button in the upper right), and then when that's complete go to the notebook viewer and make a submission to the competition. :-)\n\n## There's lots of room for improvement. What things can you try to get a better score?","1b61457c":"## Pull out the target, and make a validation split","29b1b527":"# Inspecting the Dataset","0863b000":"# Read in the data files","a13fd3cb":"# Checking the datatype of the Columns"}}