{"cell_type":{"dd7eda19":"code","bebb1998":"code","43f30d9a":"code","1bfb34d8":"code","60627e51":"code","090a5871":"code","214b2287":"code","ff4b3fbc":"code","e90850ae":"code","075af3f2":"code","31da5546":"code","bec9ae69":"code","2e54df07":"code","d13b2eb3":"code","8332ed7c":"code","3f6bd286":"code","942db1d8":"code","572d6d05":"markdown","df253233":"markdown","3ba985b8":"markdown","da6b198a":"markdown","84092ed4":"markdown","f634fae4":"markdown","db343878":"markdown","759097c2":"markdown","d53c5313":"markdown"},"source":{"dd7eda19":"# include modules \n# these are the most common ones we have used in the Big Data Class I am taking \nimport math as m\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns  #IMPORTANT - UPGRADE SEABORN TO VERSION 0.9.0 IN ANACONDA ENV\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.tree import DecisionTreeClassifier\n\n","bebb1998":"# loading in packages\n\nimport numpy as np \nimport pandas as pd  #(e.g. pd.read_csv) going to read in the csv so I can actually use it \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","43f30d9a":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","1bfb34d8":"train_data.info() ","60627e51":"train_data.describe()","090a5871":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()\n# want to see the head so I can see the data","214b2287":"print(train_data.columns.values)","ff4b3fbc":"\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()\n\n","e90850ae":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\n# shows me what percentage of women survived which is helpful but I want to add more.","075af3f2":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)\n","31da5546":"import matplotlib.pyplot as plt\n\nsex_pivot = train_data.pivot_table(index=\"Sex\",values=\"Survived\")\nsex_pivot.plot.bar()\nplt.show()","bec9ae69":"class_pivot = train_data.pivot_table(index=\"Pclass\",values=\"Survived\")\nclass_pivot.plot.bar()\nplt.show()","2e54df07":"\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\n","d13b2eb3":"g = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\n","8332ed7c":"\n\n# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\ngrid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();\n\n","3f6bd286":"X_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape\n","942db1d8":"from sklearn.ensemble import RandomForestClassifier \n\n# y is the labels \ny = train_data [\"Survived\"]\n\n# will use these features to train the data\n\nfeatures = [\"Sex\", \"Pclass\"]\n\nX = pd.get_dummies(train_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n\nmodel.fit(X, y)\n\npredictions = model.predict(X_test)\n\noutput_andomF = pd.dataFrame({\"cabin\": test_data.cabin, \"Survived\": predictions})\n\n","572d6d05":"This shows me that people in first class were more likely to survive than those is second or third class. First class was a little over 60%, second class was around 45% and third class was a little over 20%. This proves my thesis above that those in higher class were more likely to survive. ","df253233":"This graph shows me what I learned above that women were more likely to survive on the titanic. Women are a little over 70% and men are a little under 20%","3ba985b8":"I used the column code to see which columns are in my dataset. ","da6b198a":"# DeL \n## Lab 6 - Titanic competition ","84092ed4":"Now that I know women were more likely to survive the titanic I can use that to help me get a higher percentage. What I want to try next is do gender and class because it seems like those who are more wealthy would be first to be saved. ","f634fae4":"This shows me that men were defintley less likely to survive","db343878":"This is lab 6! In this lab, I will be predicting who will survive on the tiatnic and who will not. I will do this by using features and lables to group different people into different groups to try and predict who is going to survive and who is going to die. ","759097c2":"The next graph I got was from this website: https:\/\/www.dataquest.io\/blog\/kaggle-fundamentals\/ . I was unsure of how to make a graph and include class. The next graph looks at class and who was most likely to survive from each class. ","d53c5313":"This shows me that 74% of women survived on the Titanic. This shows me that women are most likely able to survive on the Titanic. "}}