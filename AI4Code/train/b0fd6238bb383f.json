{"cell_type":{"0ff9045e":"code","0f62203a":"code","76aa81fe":"code","b7c6d299":"code","972600ed":"code","2c96ac04":"code","361ebdc5":"code","64da1e80":"code","6fdd350f":"code","3d254414":"code","618d458d":"code","1c6ac4ce":"code","3c98f417":"code","71cfe75c":"code","643d85ff":"code","b906cf72":"code","a882b7d5":"code","4faaf1a4":"code","f3541335":"code","93797756":"code","f793d5dc":"code","9034518a":"code","deb1e333":"code","624a10c3":"code","f2e70945":"code","5e4ce278":"code","2c7684fe":"code","87cc6b69":"markdown","d2ce6d07":"markdown","94250c6d":"markdown","f90a9cd3":"markdown","908a77a2":"markdown","0e284ad3":"markdown","fdde424d":"markdown","6c5a2677":"markdown","6a85df41":"markdown","beef9dd7":"markdown","ea16c275":"markdown","423f88a7":"markdown","f73f98c3":"markdown","6f1fc3b3":"markdown","b42fbd40":"markdown","dd46838e":"markdown","22f2bb05":"markdown","366a22dd":"markdown","940e4a6e":"markdown","904b5a49":"markdown"},"source":{"0ff9045e":"import pandas as pd\nimport numpy as np\nimport os\nimport librosa \nimport tensorflow as tf\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nimport tensorflow.keras.layers as layers\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score","0f62203a":"#train data creator\n\nID=[]\nlabel=[]\n# import required module\nimport os\n# assign directory\ndirectory = '..\/input\/audio-cats-and-dogs\/cats_dogs\/train\/'\n \n# iterate over files in\n# that directory\n\nfor folder in os.listdir(directory):                               #go into the directory\n    for filename in os.listdir(directory+str(folder)):          #go in every class \n        f = os.path.join(directory+str(folder), filename)    #scan through every file in that class\n        if os.path.isfile(f):\n            ID.append(f.split('\/')[-1])\n            label.append(f.split('\/')[-2])","76aa81fe":"train_data=pd.DataFrame()\ntrain_data['ID']=ID\ntrain_data['label']=label","b7c6d299":"train_data","972600ed":"plt.figure(figsize=(8,6),dpi=80)\nsns.set_theme(style=\"darkgrid\")\nsns.countplot('label',data=train_data)\nplt.title('counts: \\n' +'dogs:'+str(train_data.label.value_counts()[1])+\n          '\\n cats:'+str(train_data.label.value_counts()[0]))\nplt.show()","2c96ac04":"ID=[]\nlabel=[]\n# import required module\nimport os\n# assign directory\ndirectory = '..\/input\/audio-cats-and-dogs\/cats_dogs\/test\/'\n \n# iterate over files in\n# that directory\n\nfor folder in os.listdir(directory):\n    for filename in os.listdir(directory+str(folder)):\n        f = os.path.join(directory+str(folder), filename)\n        if os.path.isfile(f):\n            ID.append(f.split('\/')[-1])\n            label.append(f.split('\/')[-2])","361ebdc5":"label[:10]","64da1e80":"for i in range(len(label)):\n    if(label[i]=='test'):\n        label[i]='dogs'\n\nlabel[:10]","6fdd350f":"test_data=pd.DataFrame()\ntest_data['ID']=ID\ntest_data['label']=label\ntest_data","3d254414":"def extract_features(directory):\n    features=[]\n    ID=[]\n    for folder in os.listdir(directory):\n        for filename in os.listdir(directory+str(folder)):\n            f = os.path.join(directory+str(folder), filename)\n            if os.path.isfile(f):\n                x,sr=librosa.load(f, res_type='kaiser_fast',sr=None)\n                mfccs=np.mean(librosa.feature.mfcc(x,sr=sr,n_mfcc=100).T,axis=0)\n                features.append(mfccs)\n                ID.append(f.split('\/')[-1])\n    return [ID, features]","618d458d":"ID, features_train=extract_features('..\/input\/audio-cats-and-dogs\/cats_dogs\/train\/')","1c6ac4ce":"#checking that if they are same, there should be no zero or false value\n\nprint(np.count_nonzero(train_data.ID==ID) )\n\n#the ablove thing should be equal to the original shape of ID's in train_data\n\nlen(train_data.ID)==np.count_nonzero(train_data.ID==ID) \n","3c98f417":"ID,features_test=extract_features('..\/input\/audio-cats-and-dogs\/cats_dogs\/test\/')\n\nlen(test_data.ID)==np.count_nonzero(test_data.ID==ID)   #matched ","71cfe75c":"X_train=np.array(features_train)\nX_test=np.array(features_test)","643d85ff":"Y_train=train_data.label\nY_test=test_data.label","b906cf72":"#label encode Y_train and Y_test\n\nle=LabelEncoder()\n\ntemp=le.fit_transform(Y_train)\nY_train=temp.reshape(-1,1)\n\ntemp=le.fit_transform(Y_test)\nY_test=temp.reshape(-1,1)","a882b7d5":"print(X_train.shape,X_test.shape)\nprint(Y_train.shape,Y_test.shape)   ","4faaf1a4":"model=tf.keras.Sequential()\nmodel.add(layers.Dense(input_shape=(100,), units= 200,activation='relu'))\nmodel.add(layers.Dense(200,activation='relu'))\nmodel.add(layers.Dense(200,activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))","f3541335":"model.summary()","93797756":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","f793d5dc":"hist=model.fit(X_train,Y_train,epochs=100)","9034518a":"plt.title('Train Loss values over 100 epochs:')\nplt.plot(hist.history['loss'],color='red',linewidth=2)\nplt.show()","deb1e333":"plt.title('Train accuracy values over 100 epochs:')\nplt.plot(hist.history['accuracy'],color='purple')\nplt.show()","624a10c3":"Y_pred=model.predict(X_test)","f2e70945":"#since we are using sigmoid activation function at the output layer\nY_pred=(Y_pred>0.5)*1","5e4ce278":"plt.figure(figsize=(10,8),dpi=80)\nsns.heatmap(confusion_matrix(Y_test,Y_pred),annot=True,cmap='Blues')\nplt.title('1 signifies dog sounds and 0 signifies cat sounds \\n'+'Accuracy:'+str(accuracy_score(Y_test,Y_pred)))\nplt.show()","2c7684fe":"print(classification_report(Y_test,Y_pred))","87cc6b69":"## This step is required to check that the ID's that we obtained from extract_features function are matching with the actual ID's in train_data that we created earlier such that there's no mismatch of data rows.","d2ce6d07":"## input shape will be 100 since there are 100 mfccs for each audio file","94250c6d":"# Upvote if you found this useful!","f90a9cd3":"# 6. Build audio classification model","908a77a2":"# 7. Testing the model with test data and metrics","0e284ad3":"## In test set it should be 'dogs' instead of 'test' folder","fdde424d":"# 3. Create test_data","6c5a2677":"## Change the labels to 'dogs'","6a85df41":"## so we have achieved around 90% test accuracy, Not bad given that the dataset is pretty small!","beef9dd7":"# 1. Import required libraries","ea16c275":"# 5. Create X_train, Y_train & X_test, Y_test","423f88a7":"## This function will access the audio files directly from the dataset and automatically store the features for each file in train set","f73f98c3":"## In librosa.load function if we dont write sr=None, it will upsample every audio file to 22Khz which we dont want here.","6f1fc3b3":"# 2. Create train_data","b42fbd40":"# 4. Feature extraction of audio files using MFCCs","dd46838e":"## perfect now lets build the classification model","22f2bb05":"## call on train data set","366a22dd":"## Full classification report","940e4a6e":"## call on test data","904b5a49":"## I have used 100 Mel freq cepstrum coeff. for each audio file."}}