{"cell_type":{"22cc2f63":"code","e80a4762":"code","9fb6e87f":"code","98498912":"code","25a7183c":"code","776bd396":"code","a0b5c70c":"code","5adf545e":"code","55839808":"markdown","918ed22f":"markdown","4b35c778":"markdown","53ae1703":"markdown","72ebf4c9":"markdown"},"source":{"22cc2f63":"import numpy as np \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nimport torch\nfrom torch import device\nimport torch.nn as nn\nimport cv2\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\nimport random\n# from pytorch_fid import fid_score #!!!!!!!!!!\n%matplotlib inline","e80a4762":"class GanModel:\n    def __init__(self, randomSeed = 5, lr = 0.00002, beta1 = 0.9, fileName = None):\n        random.seed(randomSeed)\n        torch.manual_seed(randomSeed)\n        betas = (beta1, 0.999)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.direc = '..\/input\/cats-faces-64x64-for-generative-models\/'\n        self.num_workers = 3\n        self.batch_size = 128\n        self.image_size = 64\n        self.gen_init_arr_size = 128\n        self.lr = lr\n        self.beta1 = beta1\n        self.stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n        self.total_epochs = 0\n        self.savePath = 'model'\n        self.genPath = 'generated'\n        os.makedirs(self.savePath, exist_ok=True)\n        os.makedirs(self.genPath, exist_ok=True)\n        self.std_noise = torch.randn(self.batch_size, self.gen_init_arr_size, 1, 1).to(self.device)\n        \n        \n        if fileName:\n            self.loadModel(fileName)\n        else:\n            self.generator = self.createGen() \n            self.discriminator = self.createDisc() \n            self.opt_d = torch.optim.Adam(self.discriminator.to(self.device).parameters(), lr=lr, betas=betas)\n            self.opt_g = torch.optim.Adam(self.generator.to(self.device).parameters(), lr=lr, betas=betas)\n            \n    def denorm(self,img_tensors):\n        return img_tensors * self.stats[1][0] + self.stats[0][0]\n        \n    def loadData(self):\n        self.data = ImageFolder(self.direc, transform=tt.Compose([ tt.Resize(self.image_size),\n                                                        tt.CenterCrop(self.image_size),\n                                                        tt.ToTensor(),\n                                                        tt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n        self.data_loader = DataLoader(self.data, self.batch_size, shuffle=True, num_workers=self.num_workers, pin_memory=True, drop_last=True) \n\n    def weights_init(self, model):\n\n        classname = model.__class__.__name__\n        if classname.find('Conv') != -1:\n            nn.init.normal_(model.weight.data, 0.0, 0.02)\n        elif classname.find('BatchNorm') != -1:\n            nn.init.normal_(model.weight.data, 1.0, 0.02)\n            nn.init.constant_(model.bias.data, 0)\n            \n    def train_D_G(self, real_images):\n        #discriminator\n        self.opt_d.zero_grad()\n\n        #real batch\n        real_preds = self.discriminator(real_images).to(self.device)\n        real_targets = (torch.rand(real_images.size(0), 1)*0.3 + 0.7).to(self.device)\n        real_D_loss = F.binary_cross_entropy(real_preds, real_targets)\n        real_D_score = torch.mean(real_preds).item()\n        real_D_loss.backward()\n\n        #generated batch\n        start_noise = torch.randn(self.batch_size, self.gen_init_arr_size, 1, 1).to(self.device)\n        fake_images = self.generator(start_noise)\n\n        fake_preds = self.discriminator(fake_images).to(self.device)\n        fake_targets = (torch.rand(fake_images.size(0), 1)*0.3).to(self.device)\n        fake_D_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n        fake_D_score = torch.mean(fake_preds).item()\n        fake_D_loss.backward()\n\n        #total error\n        D_loss = fake_D_loss + real_D_loss\n        self.opt_d.step()\n\n        #generator\n        self.opt_g.zero_grad()\n\n        start_noise = torch.randn(self.batch_size, self.gen_init_arr_size, 1, 1).to(self.device)\n        fake_images = self.generator(start_noise)\n\n        preds = self.discriminator(fake_images).to(self.device) # D(G)\n        targets = (torch.rand(self.batch_size, 1)*0.3+0.7).to(self.device) # did we fool D?\n        G_loss = F.binary_cross_entropy(preds, targets)\n        G_score = torch.mean(preds).item()\n\n        G_loss.backward()\n        self.opt_g.step()\n        \n        return D_loss.item(), G_loss.item(), start_noise, real_D_score, fake_D_score\n    \n    \n            \n    def train(self, num_epochs = 50):\n        torch.cuda.empty_cache()\n        G_losses = []\n        D_losses = []\n        real_scores = []\n        fake_scores = []\n        \n        for epoch in range(num_epochs):\n            for real_images, _ in tqdm(self.data_loader): #via batches\n                real_images = real_images.to(self.device)\n                # train D & G\n                D_loss, G_loss, start_noise, real_score, fake_score = self.train_D_G(real_images)\n\n\n            # Record losses & scores\n            G_losses.append(G_loss)\n            D_losses.append(D_loss)\n            real_scores.append(real_score)\n            fake_scores.append(fake_score)\n\n            # Log losses & scores (last batch)\n            print(\"Epoch [{}\/{}], G_loss: {}, D_loss: {}, real_score: {}, fake_score: {}\".format(\n                self.total_epochs+epoch+1, self.total_epochs+num_epochs, G_loss, D_loss, real_score, fake_score))\n            #self.plotRes(False, epoch)\n        \n        \n        self.total_epochs += num_epochs\n        self.plotLoss(G_losses, D_losses)\n        self.plotRes()\n        return G_losses, D_losses\n    \n    def createGen(self):\n        generator = nn.Sequential(\n        # in: gen_init_arr_size x 1 x 1\n\n        nn.ConvTranspose2d(self.gen_init_arr_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n        nn.BatchNorm2d(512),\n        nn.LeakyReLU(0.25, inplace=True),\n        #nn.ReLU(True),\n        # out: 512 x 4 x 4\n\n        nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(256),\n        nn.LeakyReLU(0.25, inplace=True),\n        #nn.ReLU(True),\n        # out: 256 x 8 x 8\n\n        nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(128),\n        nn.LeakyReLU(0.25, inplace=True),\n        #nn.ReLU(True),\n        # out: 128 x 16 x 16\n\n        nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(64),\n        nn.LeakyReLU(0.25, inplace=True),\n        #nn.ReLU(True),\n        # out: 64 x 32 x 32\n\n        nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.Tanh()).to(self.device)\n        # out: 3 x 64 x 64\n        generator.apply(self.weights_init)\n        return generator\n    \n    \n    def createDisc(self):\n        discriminator = nn.Sequential(\n        # in: 3 x 64 x 64\n\n        nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(64),\n        nn.LeakyReLU(0.25, inplace=True),\n        # out: 64 x 32 x 32\n\n        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(128),\n        nn.LeakyReLU(0.25, inplace=True),\n        # out: 128 x 16 x 16\n\n        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(256),\n        nn.LeakyReLU(0.25, inplace=True),\n        # out: 256 x 8 x 8\n\n        nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(512),\n        nn.LeakyReLU(0.25, inplace=True),\n        # out: 512 x 4 x 4\n\n        nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n        # out: 1 x 1 x 1\n\n        nn.Flatten(),\n        nn.Sigmoid()).to(self.device)\n        discriminator.apply(self.weights_init)\n        return discriminator\n    \n    \n    def saveModel(self, savePath=None, fileName=None):\n        if not savePath:\n            savePath = self.savePath\n        if not fileName:\n            fileName = 'GAN_{}_epochs_{}_lr_{}_beta1.pth'.format(self.total_epochs, self.lr, self.beta1)\n        torch.save({\n            'generator_state_dict': self.generator.state_dict(),\n            'discriminator_state_dict': self.discriminator.state_dict(),\n            'opt_g_state_dict': self.opt_g.state_dict(),\n            'opt_d_state_dict': self.opt_d.state_dict(),\n            'total_epochs': self.total_epochs,\n            'lr' : self.lr,\n            'beta1' : self.beta1,\n        }, os.path.join(savePath, fileName))\n        \n        \n    def loadModel(self, fileName):\n        #if not loadPath:\n        #    loadPath = self.savePath\n        #    dload = torch.load(os.path.join(loadPath, fileName))\n        dload = torch.load(fileName)\n        device = self.device\n        self.lr = dload['lr']\n        self.beta1 = dload['beta1']\n        self.total_epochs = dload['total_epochs']\n        self.generator = self.createGen()\n        self.generator.load_state_dict(dload['generator_state_dict'])\n        self.generator.to(self.device)\n        self.discriminator = self.createDisc()\n        self.discriminator.load_state_dict(dload['discriminator_state_dict'])\n        self.discriminator.to(self.device)\n        self.opt_d = torch.optim.Adam(self.discriminator.to(self.device).parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n        self.opt_g = torch.optim.Adam(self.generator.to(self.device).parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n    \n\n        return self.generator, self.discriminator, self.opt_g, self.opt_d\n\n        \n        \n    def plotLoss(self, G_losses, D_losses, out_file_name=None):\n        plt.figure(figsize=(10, 5))\n        plt.title(\"Generator and Discriminator Loss During Training\")\n        plt.plot(G_losses, label=\"G\")\n        plt.plot(D_losses, label=\"D\")\n        plt.xlabel(\"iterations\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.show()\n        if out_file_name:\n            plt.savefig(os.path.join(self.savePath, out_file_name))\n\n    def plotRes(self):\n        fake_images = self.generator(self.std_noise).to(self.device)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n        #if savef:\n        #    save_image(self.denorm(fake_images), os.path.join(self.sample_dir, fileName), nrow=8)\n        \n    def create_cats(self, num = 10000, path=None):\n        if not path:\n            path = self.genPath\n        else:\n            os.makedirs(path, exist_ok=True)\n        max_num = 1000\n        if num > max_num:\n            k = int(np.ceil(num\/max_num))\n            for i in range(k):\n                with torch.no_grad():\n                    start_noise = torch.randn(max_num, self.gen_init_arr_size, 1, 1).to(self.device)\n                    fake_images = self.generator(start_noise).to(self.device)\n                    for j in range(max_num):\n                        save_image(self.denorm(fake_images[j]), os.path.join(path, 'gen_cat_{}.jpg'.format(i*max_num+j+1)))          \n        else:\n            k = 1\n            with torch.no_grad():\n                start_noise = torch.randn(num, self.gen_init_arr_size, 1, 1).to(self.device)\n                fake_images = self.generator(start_noise).to(self.device)\n                for j in range(num):\n                    save_image(self.denorm(fake_images[j]), os.path.join(path, 'gen_cat_{}.jpg'.format(j+1))) \n        return k*max_num\n        \n        \n    def calc_fid(self):\n        n = self.create_cats(num = 10000, path='gen1')\n        fid_value = fid_score.calculate_fid_given_paths(['..\/input\/cats-faces-64x64-for-generative-models\/cats', 'gen1'],\n                                          self.batch_size,\n                                          'cuda', 2048)\n        return fid_value\n        \n    \n    ","9fb6e87f":"catGan = GanModel(randomSeed = 5, lr = 0.00002, beta1 = 0.9, fileName = '..\/input\/pretrainedmodel\/GAN_200_epochs_2e-05_lr_0.9_beta1.pth')\ncatGan.loadData()\ncatGan.plotRes()\nn = catGan.create_cats(num = 10000, path=None)\n#print(catGan.calc_fid()) #\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0424\u0440\u0435\u0448\u0435  #!!!!!!!!!!\n#\u043f\u0440\u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u0437\u0430\u043f\u0443\u0441\u043a\u0435 \u0432\u044b\u0434\u0430\u043b\u043e 40.61699310870628","98498912":"#\u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u0441\u043e \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u043d\u0430 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u043c \u0448\u0443\u043c\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 \nfake_images = catGan.generator(catGan.std_noise).to(catGan.device)\nfileName = 'res_firstGAN_{}_epochs.jpg'.format(catGan.total_epochs)\nsave_image(catGan.denorm(fake_images), fileName, nrow=8) ","25a7183c":"catGan1 = GanModel(fileName = '..\/input\/pretrainedmodel\/GAN_175_epochs_5e-05_lr_0.9_beta1.pth')\ncatGan1.loadData()\n#print(catGan1.calc_fid()) #\u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0434\u043b\u044f 20 \u0432\u044b\u0437\u043e\u0432\u043e\u0432 22.678623307623095  #!!!!!!!!!!\nn = catGan1.create_cats(num = 10000, path='betterGAN')\n\n# k = []\n# for i in range(20):\n#     k.append(catGan1.calc_fid())\n# print(np.mean(k))","776bd396":"fake_images = catGan1.generator(catGan1.std_noise).to(catGan1.device)\nfileName = 'res_secondGAN_{}_epochs.jpg'.format(catGan1.total_epochs)\nsave_image(catGan1.denorm(fake_images), fileName, nrow=8)\ncatGan1.plotRes()\n#\u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u0441\u043e \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u043d\u0430 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u043c \u0448\u0443\u043c\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438 ","a0b5c70c":"# catGanNew = GanModel(randomSeed = 5, lr = 0.00005, beta1 = 0.95)\n# catGanNew.loadData()\n# catGanNew.train(100)\n# catGanNew.saveModel()\n# print(catGanNew.calc_fid())","5adf545e":"#        \u043a\u043e\u0434 \u0434\u043b\u044f \"\u0434\u043e\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\" \u0432 \u0441\u043b\u0443\u0447\u0430\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n# catGanNew.train(25)\n# catGanNew.saveModel()\n# print(catGanNew.calc_fid())","55839808":"\u041a\u043e\u0434 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u043e\u0432\u043e\u0439 \u0441\u0435\u0442\u0438 \u0441 \u0434\u0440\u0443\u0433\u0438\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438:","918ed22f":"\u041a\u043e\u0434 \u043d\u0438\u0436\u0435 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043d\u0430 200 \u044d\u043f\u043e\u0445\u0430\u0445 \u043c\u043e\u0434\u0435\u043b\u0438 (\u043f\u0430\u0440\u0430\u043c\u0435\u0440\u044b \u0443\u043a\u0430\u0437\u0430\u043d\u044b \u0432 \u0438\u043c\u0435\u043d\u0438 \u0444\u0430\u0439\u043b\u0430) \u0438 \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0432 \u043f\u0430\u043f\u043a\u0435 'generated' 10000 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a. *\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0440\u0430\u0431\u043e\u0442\u044b \u0434\u0430\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u044f \u0438 \u043f\u043e\u0441\u044b\u043b\u0430\u043b\u0430 \u0432 \u043f\u0438\u0441\u044c\u043c\u0435 \u043a \u043f\u0440\u0435\u043f\u043e\u0434\u0430\u0432\u0430\u0442\u0435\u043b\u044f\u043c \u043a\u0443\u0440\u0441\u0430*","4b35c778":"\u041d\u0438\u0436\u0435 \u0432 notebook \u043e\u043f\u0438\u0441\u0430\u043d \u043a\u043b\u0430\u0441\u0441, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0449\u0438\u0439 \u0441\u043e\u0431\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c, \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0441 \u043a\u043e\u0442\u0438\u043a\u0430\u043c\u0438. \n\u041e\u043d \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u044f:\n1. \u043c\u0435\u0442\u043e\u0434 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u043f\u0440\u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0438 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043a\u043b\u0430\u0441\u0441\u0430 __init__(randomSeed, lr, beta1, fileName), \u0433\u0434\u0435 randomSeed \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0444\u0438\u043a\u0441\u0430\u0446\u0438\u0438 randomize, lr, beta1 -- \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043c\u0435\u0442\u043e\u0434\u0430 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 (\u0438 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430,  \u0434\u043b\u044f \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f Adam \u0441 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438), fileName -- \u0438\u043c\u044f \u0444\u0430\u0439\u043b\u0430, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0435\u0433\u043e \u0443\u0436\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c, \u0435\u0441\u043b\u0438 \u043d\u0443\u0436\u043d\u043e \u043d\u0435 \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u043d\u043e\u0432\u0443\u044e, \u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0443\u0436\u0435 \u0438\u043c\u0435\u044e\u0449\u0443\u044e\u0441\u044f;\n2. \u043c\u0435\u0442\u043e\u0434, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u0435\u0440\u0435\u0434 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\u043c\/\u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c denorm(img_tensors);\n3. \u043c\u0435\u0442\u043e\u0434 \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 loadData();\n4. \u043c\u0435\u0442\u043e\u0434 \u0434\u043b\u044f \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0432\u0435\u0441\u043e\u0432 \u0441\u0435\u0442\u0438 weights_init(model);\n5. \u043c\u0435\u0442\u043e\u0434 train_D_G(real_images), \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0439 \u0437\u0430 \u043e\u0434\u0438\u043d \u043f\u0440\u043e\u0445\u043e\u0434 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0431\u0430\u0442\u0447\u0443, \u0432\u043d\u0443\u0442\u0440\u0438 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430;\n6. \u043c\u0435\u0442\u043e\u0434 train(num_epochs), \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0449\u0438\u0439 \u0441\u043e\u0431\u043e\u0439 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0442\u0435\u0447\u0435\u043d\u0438\u0435 num_epochs \u044d\u043f\u043e\u0445. \u041f\u043e \u043e\u043a\u043e\u043d\u0447\u0430\u043d\u0438\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0433\u0440\u0430\u0444\u0438\u043a loss'\u0430 \u0438 \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u0435\u0442\u0438 \u043d\u0430 \u0434\u0430\u043d\u043d\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f;\n7. \u043c\u0435\u0442\u043e\u0434\u044b createGen(), createDisc(), \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0435 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0438 \u0434\u0438\u0441\u043a\u0440\u0438\u043c\u0438\u043d\u0430\u0442\u043e\u0440\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0438 \u0431\u0443\u0434\u0443\u0442 \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f;\n8. \u043c\u0435\u0442\u043e\u0434\u044b saveModel(savePath, fileName) \u0438 loadModel(fileName) \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439;\n9. \u043c\u0435\u0442\u043e\u0434 plotLoss(G_losses, D_losses, out_file_name) \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432 loss;\n10. \u043c\u0435\u0442\u043e\u0434 plotRes() \u0434\u043b\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a, \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u043c \u043f\u0440\u0438 \u0438\u043d\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0448\u0443\u043c\u0435;\n11. \u043c\u0435\u0442\u043e\u0434 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043a\u043e\u0442\u0438\u043a\u043e\u0432 \u0443\u0436\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u044c\u044e createCats(num, path), \u0433\u0434\u0435 num -- \u0442\u0440\u0435\u0431\u0443\u0435\u043c\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a, path -- \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f;\n12. \u043c\u0435\u0442\u043e\u0434 calc_fid() \u0434\u043b\u044f \u0440\u0430\u0441\u0447\u0435\u0442\u0430 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0424\u0440\u0435\u0448\u0435.\n\n\u0421\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044e\u0442\u0441\u044f \u0432 \u043f\u0430\u043f\u043a\u0443 'generated', \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 -- \u0432 \u043f\u0430\u043f\u043a\u0443 'model' (\u0435\u0441\u043b\u0438 \u0438\u043d\u043e\u0435 \u043d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d\u043e \u0432 \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u0430\u0445 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439).","53ae1703":"\u0421\u043b\u0435\u0434\u0443\u044e\u0449\u0430\u044f \u0441\u0435\u0442\u044c \u0438\u043c\u0435\u0435\u0442 \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0438\u0439 fid, \u0445\u043e\u0442\u044f \u0432\u044b\u0445\u043e\u0434 \u044d\u0442\u043e\u0439 \u0436\u0435 \u0441\u0435\u0442\u0438, \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043d\u0430 150 \u044d\u043f\u043e\u0445\u0430\u0445 \u043c\u043d\u0435 \u043d\u0440\u0430\u0432\u0438\u0442\u0441\u044f \u0431\u043e\u043b\u044c\u0448\u0435 :)","72ebf4c9":"\u0414\u0430\u043d\u043d\u044b\u0439 notebook \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u043e-\u0441\u043e\u0441\u0442\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0441 \u043a\u043e\u0442\u0438\u043a\u0430\u043c\u0438, \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u0430\u044f. \u041f\u0440\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0438 \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u043e\u0440\u0438\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043b\u0430\u0441\u044c \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a https:\/\/github.com\/jaingaurav3\/GAN-Hacks\n\n\u0412\u0445\u043e\u0434\u043d\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b \u0432 'input'. \u0414\u043b\u044f \u0441\u0434\u0430\u0447\u0438 \u043f\u043e\u0441\u044b\u043b\u0430\u043b\u0430 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438: # lr = 0.00002, beta1 = 0.9, \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u043d\u0430 200 \u044d\u043f\u043e\u0445\u0430\u0445; \u043d\u043e \u0432\u0447\u0435\u0440\u0430 \u0435\u0449\u0451 \u043f\u043e\u043e\u0431\u0443\u0447\u0430\u043b\u0430 \u0434\u0440\u0443\u0433\u0443\u044e \u0441\u0435\u0442\u044c \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 lr = 0.00005, beta1 = 0.9 \u043d\u0430 175 \u044d\u043f\u043e\u0445\u0430\u0445, \u0443 \u043d\u0435\u0451 \u043b\u0443\u0447\u0448\u0435 fid. \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0435\u0451 \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0432\u044b\u0445\u043e\u0434 \u044d\u0442\u043e\u0433\u043e notebook.\n\n\u0410\u0431\u0440\u0430\u043c\u043e\u0432\u0430 \u0412.\u0412. 515 \u0433\u0440\u0443\u043f\u043f\u0430, \u0412\u041c\u041a \u041c\u0413\u0423\n\nP.s. \u043f\u0435\u0440\u0435\u0434 \u0437\u0430\u043f\u0443\u0441\u043a\u043e\u043c \u043a\u043e\u0434\u0430 \u043d\u0443\u0436\u043d\u043e \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043a\u043e\u043c\u0430\u043d\u0434\u0443 'pip install pytorch-fid', \u0447\u0442\u043e\u0431\u044b \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439 fid_score \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0424\u0440\u0435\u0448\u0435, \u0438 \u0440\u0430\u0441\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0441\u0442\u0440\u043e\u043a\u0438, \u043e\u043a\u0430\u043d\u0447\u0438\u0432\u0430\u044e\u0449\u0438\u0435\u0441\u044f \u043d\u0430  #!!!!!!!!!!"}}