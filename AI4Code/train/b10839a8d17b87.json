{"cell_type":{"321677a2":"code","bb796e4c":"code","485530eb":"code","a18c71ef":"code","0f5a01a3":"code","46227976":"code","7928842e":"code","1b22f821":"code","dc97baca":"code","1dd8d545":"code","00eeeab6":"code","9596c0a4":"code","7e41f6b3":"code","5da6e584":"code","902d9652":"code","a516eec8":"code","f1d676ca":"code","858cb818":"code","c7485147":"code","906652fa":"code","5e58737a":"code","acdd1e8a":"code","71508f78":"code","b37931c8":"code","2e3b82ed":"code","dc1f6cba":"code","ed483d0d":"code","4ef2cc83":"code","1dbcb394":"code","89d45023":"code","ce5f32d7":"code","d9a9dd0b":"code","74c90b8c":"code","f7066cac":"code","7df6e43f":"code","b4d19a67":"code","0347b241":"code","e12bed4d":"code","bd7bf2c4":"code","81329055":"code","4e02ce97":"code","e4484d85":"code","a354e7bf":"code","578b772b":"code","6d3317be":"code","d96a6dab":"code","9966d228":"code","c07ce38d":"code","2b1dde7b":"code","12da17d5":"code","d65ec256":"code","83c1f48b":"code","a05fb0d9":"code","f796956a":"code","934148db":"code","36fb2fb3":"code","6a9f8937":"code","927039e0":"code","1a5d01e5":"code","513c9963":"code","bc3dbb98":"code","bca41e11":"code","c88be065":"code","2e7eeb5b":"code","3ba60a75":"code","cba7c2bd":"markdown","fab83086":"markdown","b0571fce":"markdown","ef563f1c":"markdown","847cfab4":"markdown","f1f8ad63":"markdown","7100d79b":"markdown","c2eb83d5":"markdown","e5f088f4":"markdown","bfa09091":"markdown","4d16ab84":"markdown","0caa9194":"markdown","1d7cc7b0":"markdown","e9ad05ff":"markdown","21b9217d":"markdown","433f2bd0":"markdown","f4a779d2":"markdown","3a4785a1":"markdown","a2ffb532":"markdown","6a9618af":"markdown","688d8271":"markdown","69eb1326":"markdown","4c4ebef9":"markdown","817e47f3":"markdown","1607a005":"markdown","042c14c4":"markdown"},"source":{"321677a2":"#Performing some basic analysis on data,data cleaning\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\n#Reading Tain dataset\n#ion=pd.read_csv('..\/input\/Ion-Switching-knn\/train.csv')\nion=pd.read_csv('..\/input\/train.csv')\ndf=pd.DataFrame(ion)\ndf.info()\ndf.isnull()\ndf.isnull().sum()\ndf.describe()\n\n#Reading Test Dataset\n#Testdata=pd.read_csv(\"..\/input\/Ion-Switching-knn\/test.csv\")\nTestdata=pd.read_csv(\"..\/input\/test.csv\")\ndf2=pd.DataFrame(Testdata)\n\n#Reading sample_submission dataset\n#sample_submission=pd.read_csv('..\/input\/Ion-Switching-knn\/sample_submission.csv')\nsample_submission=pd.read_csv('..\/input\/sample_submission.csv')\n#sample_submission=pd.read_csv('')\ndf3=pd.DataFrame(sample_submission)\n\n\n","bb796e4c":"#Analysing relationship between various coloumn using pairplot\ndf[\"open_channels\"].replace(1,\"Opened\",inplace=True)\ndf[\"open_channels\"].replace(0,\"Closed\",inplace=True)\nimport seaborn as sns\nsns.pairplot(df);","485530eb":"#Plotting scattered plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfig_dims = (10, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.scatterplot(x='time',y='signal',hue='open_channels',ax=ax,data=df)","a18c71ef":"#analysing signal if Monotonic or not\nsr=df['signal']\nprint(sr) \nsr.is_monotonic","0f5a01a3":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nax=sns.boxplot(x='signal',y='open_channels',data=df)\n#ax= sns.swarmplot(x='signal',y='open_channels',data=df, color=\"grey\")","46227976":"#Plotting Boxplot for signal\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nax=sns.boxplot(df['signal'],color=\"b\",linewidth=3)\n#ax=sns.swarmplot(df['signal'],color=\"y\")","7928842e":"print(\"Following Data Is for Signal column: \\n\")\nQ1 = df['signal'].quantile([0.25])\nQ3=df['signal'].quantile([0.75])\nprint(\" \\nQ1\",Q1)\nprint(\" \\nQ3\",Q3)\ntype(Q3)\nIQR=float(Q3)-float(Q1)\nprint(\"\\nIQR for Signal: \",IQR)\nUL=Q3+1.5*IQR\nLL=Q1-1.5*IQR\n\nprint(\"\\nUpper Limit\",UL)\nprint(\"Lower Limit\",LL)\n\nc_2outliers=df[((df[\"signal\"]<=float(LL)) |(df[\"signal\"]>=float(UL)))]\nprint()\nprint(\"\\n\\n\",c_2outliers.info())\nc_2outliers.sort_values(\"signal\",ascending=False)\n","1b22f821":"df_signalclean=df[((df[\"signal\"]>float(LL)) &(df[\"signal\"]<float(UL)))]","dc97baca":"df_signalclean.info()","1dd8d545":"print(\"Following Data Is for ion signal column After cleaning outliers: \\n\")\nQC1 = df_signalclean[\"signal\"].quantile([0.25])\nQC3=df_signalclean[\"signal\"].quantile([0.75])\nQC2=df_signalclean[\"signal\"].quantile([0.50])\nQ2=df_signalclean[\"signal\"].quantile([0.50])\nprint(\" \\nQC1\",QC1)\nprint(\" \\nQC2\",QC2)\nprint(\" \\nQC3\",QC3)\nprint(\" \\nQ1\",Q1)\nprint(\" \\nQ2\",Q2)\nprint(\" \\nQ3\",Q3)\n\ntype(QC3)\nIQRC=float(QC3)-float(QC1)\nprint(\"\\nIQR after cleaning for signal: \",IQRC)\nprint(\"\\nIQR before cleaning for signal: \",IQR)\nULC=QC3+1.67*IQRC\nLLC=QC1-1.67*IQRC\n\nprint(\"\\nUpper Limit after cleaning: \",ULC)\nprint(\"\\nUpper Limit beforer cleaning: \",UL)\nprint(\"\\nLower Limit after cleaning: \",LLC)\nprint(\"\\nLower Limit beforer cleaning: \",LL)\n\nc_2outliers_2nd_pass=df_signalclean[((df_signalclean[\"signal\"]<=float(LLC)) |(df_signalclean[\"signal\"]>=float(ULC)))]\nprint()\nprint(\"\\n\\nOutlayer\",c_2outliers_2nd_pass.info())\nc_2outliers_2nd_pass.sort_values(\"signal\",ascending=False)","00eeeab6":"#Boxplot for signal before removing outliers\nplt.figure(figsize=(16,4))\nsns.boxplot(x=\"signal\",data=df,linewidth=4)\n#sns.swarmplot(x=\"signal\",data=df,color=\"y\")","9596c0a4":"#Boxplot for signal After removing outliers\nplt.figure(figsize=(12,4))\nsns.boxplot(x=\"signal\",data=df_signalclean,color=\"g\",linewidth=4,whis=1.65)\n#sns.swarmplot(x=\"signal\",data=df_signalclean,color=\"r\")","7e41f6b3":"plt.figure(figsize=(16,4))\n\n\n#print(\"Original data is shown with yellow colour\")\nsns.boxplot(x=\"signal\",data=df,color=\"b\",linewidth=4)\n#sns.swarmplot(x=\"signal\",data=df,color=\"y\",size=5)\n\n#print(\"Cleaned Data is shown with red colour\")\nsns.boxplot(x=\"signal\",data=df_signalclean,color=\"w\",linewidth=4,whis=1.65)\n#sns.swarmplot(x=\"signal\",data=df_signalclean,color=\"r\")\n\n\n#plt.legend()\nplt.show()","5da6e584":"plt.figure(figsize=(12,4))\nsns.distplot(df[\"signal\"])","902d9652":"from scipy import stats\ndf_Z_Outliers_clean=df[np.abs((stats.zscore(df[[\"signal\"]])))<3]\nprint(df_Z_Outliers_clean.info())","a516eec8":"plt.figure(figsize=(15,4))\nsns.boxplot(x=\"signal\",data=df_Z_Outliers_clean,color=\"g\",linewidth=4,whis=1.7)\n#sns.swarmplot(x=\"signal\",data=df_Z_Outliers_clean,color=\"r\")","f1d676ca":"#Truncating the time values to floor\ndf[\"open_channels\"].replace(1,\"Opened\",inplace=True)\ndf[\"open_channels\"].replace(0,\"Closed\",inplace=True)\n#floor gets the rounded down (truncated) values of column in dataframe\ndf['time'] = df['time'].apply(np.floor)\ndf['time']\n","858cb818":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x='open_channels', data=df)\nplt.xticks(rotation=90)\ndf[\"open_channels\"].value_counts()\n#df[\"open_channels\"].value_counts(\"Closed\")","c7485147":"#pd.pivot_table(df,index=[\"time\"])\n#df.groupby('time')['open_channels'].value_counts()\ntotal=df.groupby(\"time\")[\"open_channels\"].count()\ntotal\n#df.groupby([\"time\", \"signal\"])[\"open_channels\"].value_counts()\n","906652fa":"openchannels=df.groupby('time')['open_channels'].value_counts()\nopenchannels","5e58737a":"#Plotting graph of time vs no opened and closed channels\nplt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(100,5))\ndf.groupby('time')['open_channels'].value_counts().plot(ax=ax,kind='bar')\n\n\n\n","acdd1e8a":"#Plotting a Signal Distribution\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nax = sns.distplot(df['signal'])","71508f78":"#Plotting bar Graph for time,signal and openchannels showing closed  and opened channels\nimport seaborn as sns\nfig_dims = (15, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x='time',y='signal',hue='open_channels',ax=ax,data=df)\n#sns.barplot(y='signal',hue='open_channels',ax=ax,data=df)","b37931c8":"from sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn import datasets\nimport pandas as pd\nion=pd.read_csv('..\/input\/train.csv')\ndf=pd.DataFrame(ion)\ndf[\"open_channels\"].replace(\"Opened\",1,inplace=True)\ndf[\"open_channels\"].replace(\"Closed\",0,inplace=True)\ny=df['open_channels']\nX=df[['time','signal']]\nXtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.20)\n","2e3b82ed":"from sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=50)#Taking cluster size of 50 for sampling\nclassifier.fit(Xtrain,ytrain)\n","dc1f6cba":"y_pred=classifier.predict(Xtest)\ny_pred\n","ed483d0d":"#Applying model on test dataset\nimport pandas as pd\nTestdata=pd.read_csv(\"..\/input\/test.csv\")\ndf2=pd.DataFrame(Testdata)\nX2=df2[['time','signal']]\n#y_pred2=classifier.predict(X2[2000000,])\ny_pred2=classifier.predict(X2)\ny_pred2\n\n","4ef2cc83":"# Prinnting R square value for Train dataset\nprint('R square:',classifier.score(X,y))","1dbcb394":"# Prinnting R square value for Test dataset\n\nprint('R square:',classifier.score(X2,y_pred2))","89d45023":"#calculating  values for test dataset\nfrom sklearn import metrics\nprint('mean absolute error:',metrics.mean_absolute_error(df3[\"open_channels\"],y_pred2))\nprint('mean squared error:',metrics.mean_squared_error(df3[\"open_channels\"],y_pred2))\nprint('root mean squared error:',np.sqrt(metrics.mean_squared_error(df3[\"open_channels\"],y_pred2)))","ce5f32d7":"#calcuating values for train datset\nprint(\"now\")\n#error estimation\nfrom sklearn import metrics\nprint('mean absolute error:',metrics.mean_absolute_error(ytest,y_pred))\nprint('mean squared error:',metrics.mean_squared_error(ytest,y_pred))\nprint('root mean squared error:',np.sqrt(metrics.mean_squared_error(ytest,y_pred)))\n","d9a9dd0b":"#Calculating Test score i.e accuracy for train dataset\nfrom sklearn.metrics import classification_report\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred==ytest)))\n","74c90b8c":"#Calculating Test score i.e accuracy for test dataset\nfrom sklearn.metrics import classification_report\ndf3[\"open_channels\"].replace(\"Opened\",1,inplace=True)\ndf3[\"open_channels\"].replace(\"Closed\",0,inplace=True)\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred2==df3['open_channels'])))\n","f7066cac":"#verifying test score by confusion_matrix for tain dataset\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix=confusion_matrix(ytest,y_pred)\nprint(confusion_matrix)\n","7df6e43f":"a=195193+144+202+1416\nb=195193+1416\nc=b\/a\nprint(c)","b4d19a67":"#plotting confusion Matrix for train dataset\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(confusion_matrix, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.show()","0347b241":"#calculating error for k  values between 1 and 40 for train dataset\nfrom sklearn.neighbors import KNeighborsClassifier\nerror=[]\nfor i in range (1,50):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(Xtrain,ytrain)\n    pred_i=knn.predict(Xtest)\n    error.append(np.mean(pred_i != ytest))","e12bed4d":"print(error)","bd7bf2c4":"#plotting error for train dataset\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,8))\nplt.plot(range(1,50),error,color='red',linestyle='dashed',marker='o',markerfacecolor='blue',markersize='10')\nplt.title('Error rate k value ')\nplt.xlabel('k value')\nplt.ylabel('mean error')","81329055":"#Using K fold sklearn for train dataset\n# Import required libraries\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport sklearn\n\nion=pd.read_csv('..\/input\/train.csv')\ndf=pd.DataFrame(ion)\n# Import necessary modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import LeavePOut\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold\n# Evaluate using a train and a test set\ny=df['open_channels']\nX=df[['time','signal']]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20,shuffle=True,random_state=50000)\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\nresult = model.score(X_test, y_test)\nprint(\"Accuracy: %.2f%%\" % (result*100.0))\n\ny_pred=model.predict(X_test)\ny_pred_prob=model.predict_proba(X_test)\nprint(\"for Train datset\")\nfrom sklearn import metrics\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred==y_test)))\n\n#for test dataset\nprint(\"for test dataset\")\ny_pred2=model.predict(X2)\nfrom sklearn import metrics\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred2==df3[\"open_channels\"])))\n","4e02ce97":"#K-fold cross validation\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nkfold = model_selection.KFold(n_splits=10,shuffle=True,random_state=50000)\nmodel_kfold = LogisticRegression()\nresults_kfold = model_selection.cross_val_score(model_kfold, X, y, cv=kfold)\nprint(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) \n","e4484d85":"#Performing Ridge  and validation curve \nimport numpy as np\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.linear_model import Ridge\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nion=pd.read_csv('..\/input\/train.csv')\ndf=pd.DataFrame(ion)\n\ny=df['open_channels']\nX=df[['time','signal']]\ntrain_scores, valid_scores = validation_curve(Ridge(), X, y, \"alpha\",\n                                              np.logspace(-7, 3, 3),\n                                              cv=5)\ntrain_scores\n\n\n\n","a354e7bf":"#plotting confusion Matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(train_scores, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.show()","578b772b":"valid_scores\n","6d3317be":"#plotting confusion Matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(valid_scores, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.show()","d96a6dab":"#plotting accuracy\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import linear_model\nfrom scipy.special import expit\n\n# and plot the result\ny=df['open_channels']\nX=df['signal']\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20,shuffle=True,random_state=50000)\nclf = LogisticRegression()\nclf.fit(X_train[:, np.newaxis], y_train)\n#clf.fit(X_train, y_train)\nplt.figure(1, figsize=(6, 4))\nplt.clf()\nplt.scatter(X, y, color='black', zorder=20)\nX_test = np.linspace(-5, 10, 300)\n\nloss = expit(X_test * clf.coef_ + clf.intercept_).ravel()\nplt.plot(X_test, loss, color='red', linewidth=3)\n\nols = linear_model.LinearRegression()\nols.fit(X[:, np.newaxis], y)\n#ols.fit(X, y)\n\n\nplt.plot(X_test, ols.coef_ * X_test + ols.intercept_, linewidth=1)\nplt.axhline(.5, color='.5')\n\nplt.ylabel('y')\nplt.xlabel('X')\nplt.xticks(range(-5, 10))\nplt.yticks([0, 0.5, 1])\nplt.ylim(-.25, 1.25)\nplt.xlim(-4, 10)\nplt.legend(('Logistic Regression Model', 'Linear Regression Model'),\n           loc=\"lower right\", fontsize='medium')\nplt.tight_layout()\nplt.show()","9966d228":"#As the data in open_channels arte not monotonic although we can fit it by using Iostonic regression\n#Plotting linear regression as well as isotonic regression as signals are not monotonic\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import LineCollection\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.utils import check_random_state\n\nX=df['signal']\ny=df['open_channels']  \n\nXtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.20)     \n\n# Fit IsotonicRegression and LinearRegression models\nir = IsotonicRegression()  \ny_ = ir.fit_transform(X, y)\n\n\n","c07ce38d":"#for isotonic regression\ny_pred=ir.predict(Xtest)\ny_pred\n\nimport matplotlib.pyplot as plt\nplt.plot(y_pred)\n\nfrom sklearn.metrics import classification_report\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred==ytest)))\n","2b1dde7b":"#for linear regression\nimport numpy as np\n#X=df['time'].reset_index().values.ravel().view(dtype=[('index', int), ('time', float)])\n#X=df[['time','signal']]\n#converting x to array as x should be two dimensional for linear regression\n#X=df[['signal','time']].to_numpy()\nX=df['signal']\ny=df['open_channels']  \nXtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.20)  \nXtest=Xtest.to_numpy()\n#Xtest.reshape(-1, 1)\nlr = LinearRegression(normalize=True)\nlr.fit(X[:, np.newaxis], y)  # x needs to be 2d for LinearRegression \n\n#lr.fit(X, y)\n\n\n#print(Xtest)\n\n#Xtest.reshape(-1, 1)\n#print(Xtest)","12da17d5":"X[:, np.newaxis]","d65ec256":"y_pred=lr.predict(Xtest[:, np.newaxis])\n#y_pred=lr.predict(Xtest)\ny_pred\n\nimport matplotlib.pyplot as plt\nplt.plot(y_pred)\n\nfrom sklearn.metrics import classification_report\nprint(\"Test Score:{:.6f}\".format(np.mean(y_pred==ytest)))","83c1f48b":"# Plotting linear and Isotonic regression to observe the data\n\nsegments = [[[i, y[i]], [i, y_[i]]] for i in range(len(X))]\nlc = LineCollection(segments, zorder=0)\nlc.set_array(np.ones(len(y)))\nlc.set_linewidths(np.full(len(X), 0.5))\n\nfig = plt.figure()\nplt.plot(X, y, 'r.', markersize=12)\nplt.plot(X, y_, 'b.-', markersize=12)\nplt.plot(X, lr.predict(X[:, np.newaxis]), 'b-')\n#plt.plot(X, lr.predict(X), 'b-')\n\nplt.gca().add_collection(lc)\nplt.legend(('Data', 'Isotonic Fit', 'Linear Fit'), loc='lower right')\nplt.title('Isotonic regression')\nplt.show()","a05fb0d9":"import pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nion=pd.read_csv('..\/input\/sample_submission.csv')\ndf3=pd.DataFrame(ion)\ndf3.info()\n#df3.isnull()\n#df3.isnull().sum()\n#df3.describe()","f796956a":"#Truncating the time values to floor\ndf3[\"open_channels\"].replace(1,\"Opened\",inplace=True)\ndf3[\"open_channels\"].replace(0,\"Closed\",inplace=True)\n#floor gets the rounded down (truncated) values of column in dataframe\ndf3['time'] = df3['time'].apply(np.floor)\ndf3['time']\n","934148db":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x='open_channels', data=df3)\nplt.xticks(rotation=90)\ndf3[\"open_channels\"].value_counts()\n#df3[\"open_channels\"].value_counts(\"Closed\")","36fb2fb3":"#pd.pivot_table(df,index=[\"time\"])\n#df.groupby('time')['open_channels'].value_counts()\ntotal=df3.groupby(\"time\")[\"open_channels\"].count()\ntotal\n#df.groupby([\"time\", \"signal\"])[\"open_channels\"].value_counts()\n","6a9f8937":"openchannels=df3.groupby('time')['open_channels'].value_counts()\nopenchannels","927039e0":"#Plotting graph of time vs no opened and closed channels\nplt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(100,5))\ndf3.groupby('time')['open_channels'].value_counts().plot(ax=ax,kind='bar')\n","1a5d01e5":"#Truncating the time values to floor\ndf2[\"open_channels\"]=y_pred2   #Assigning values of y_pred2 predicted  by model \ndf2[\"open_channels\"].replace(1,\"Opened\",inplace=True)\ndf2[\"open_channels\"].replace(0,\"Closed\",inplace=True)\n#floor gets the rounded down (truncated) values of column in dataframe\ndf2['time'] = df2['time'].apply(np.floor)\ndf2['time']","513c9963":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x='open_channels', data=df2)\nplt.xticks(rotation=90)\ndf2[\"open_channels\"].value_counts()\n#df3[\"open_channels\"].value_counts(\"Closed\")","bc3dbb98":"#pd.pivot_table(df,index=[\"time\"])\n#df.groupby('time')['open_channels'].value_counts()\ntotal=df2.groupby(\"time\")[\"open_channels\"].count()\ntotal\n#df.groupby([\"time\", \"signal\"])[\"open_channels\"].value_counts()\n","bca41e11":"#openchannels=df2.groupby('time')['open_channels'].value_counts()\nopenchannels=df2.groupby('time')['open_channels'].value_counts()\nopenchannels","c88be065":"#Plotting graph of time vs no opened and closed channels for test Dataset i.e df2\nplt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(100,5))\ndf2.groupby('time')['open_channels'].value_counts().plot(ax=ax,kind='bar')","2e7eeb5b":"import pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nion=pd.read_csv('..\/input\/sample_submission.csv')\ndf3=pd.DataFrame(ion)\ndf3.info()","3ba60a75":"\n#generating a Sample csv file for submission\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\ndf4=df3.iloc[:,0:1]\ndf4['open_channels'] = pd.DataFrame(y_pred2)\ndf4['time'] = df4['time'].map(lambda x: '%2.4f' % x)\ndf4['time']\n#df4.info()\n#df4.to_csv(outfile, index=False, header=True, float_format='%11.6f')\ndf4.to_csv (r'sample_submission1.csv', index = False, header=True,float_format='%11.6f')","cba7c2bd":"Hence We conclude that there are only Opened channels in the Test dataset and no closed  channels and Sample_submission dataset should be corrected for the same as the time stamp are same for the testdataset and sample_submission dataset.Hence sample_submission dataset should contain all opened channels i.e all 1.Hence we Calculated Number of open channels and closed channels for each datasat at each point of time.","fab83086":"###### Analysis of signal coloumn after removing outliers","b0571fce":"###### Remove signal outliers","ef563f1c":"###### Hence we conclude that Open_channels are impacted by the signal values with respect to time.the number of open channels are in between signal range -1 to -2.We also finded the Number of Open channels at each point of time and plotted a graph.Thanks!!!","847cfab4":"###### Calculating lower and upper limit of out layers data points as THREE sigma imits.Check if points fall outside this limit and drop them.","f1f8ad63":"###### Analysis of  signal Outliers","7100d79b":"###### Plotting bar graph for Total number of opened channel and closed channels for Train dataset","c2eb83d5":"###### Test score for the isotonic regression is 0.37 means relation between signals and open channels are established it may be zero in case of linear regresssion as signals are non monotonic.","e5f088f4":"###### Hence from K-fold and K-fold cross shuffle validation the accuracy is same that is 93.44","bfa09091":"###### Counting No of open and closed channels at each point of time for train dataset","4d16ab84":"An R-squared of 1 means that all movements of a security (or other dependent variable) are completely explained by movements in the index (or the independent variable(s) we are interested in).","0caa9194":"###### Test Score for linear regression is 0 as signals are non-monotonic","1d7cc7b0":"###### from scattered plot it is observed there are some outliers in data and hence there is some anomaly in data","e9ad05ff":"###### the isotonic regression on generated data. The isotonic regression finds a non-decreasing approximation of a function while minimizing the mean squared error on the training data. The benefit of such a model is that it does not assume any form for the target function such as linearity. For comparison a linear regression is also presented.","21b9217d":"###### Outliers in the signals are completely removed and hence the anomaly in data regarding the open_channels are also removed","433f2bd0":"#  ****It gives me emmense pleasure to introduce the latest version3 for this dataset.I am using some handfull techniques to get out the result required.If you like this please upvote and tell for further enhancement.**************","f4a779d2":"Accuracy for test datset is very less i.e 0.00 hence it contradict to our given data in sample submission and openchannels should be all opened in sample submission dataset","3a4785a1":"Hence we conclude that there are only Closed channels in the Sample_submission dataset and no open channel and it should be all opened as per our model predictions.","a2ffb532":"###### so signals are non monotonic in nature","6a9618af":"###### Hence we conclude that number of opened channels is betwen signal range -1 to -2","688d8271":"Calculating the No of openchaneels and closed channels for test dataset","69eb1326":"###### Applying KNN algorithm for classification\u00b6","4c4ebef9":"###### So our RMSE value is 0.040 which is very less hence we can say that error in our  model is minimum and model is fitted best","817e47f3":"###### Hence Number of open channels are very less as compared to closed channels","1607a005":"###### Counting Number of Total (open+Closed) channels for each point of time for train dataset","042c14c4":"Now Counting Number of open channels in Sample _Submission file\n"}}