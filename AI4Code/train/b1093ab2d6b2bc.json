{"cell_type":{"a6d9a628":"code","db399c41":"code","c6cbfb41":"code","961c1eba":"code","e1c4b25b":"code","ea3ccc5d":"code","2e54f936":"code","491fc688":"code","2766c33e":"code","e9c12233":"code","c23f8597":"code","efb31610":"code","09ac45a6":"code","0b9d92e6":"code","b485a8af":"code","fd8dace2":"code","8c10806a":"code","57336ba1":"code","f4c53210":"markdown","1eee7f31":"markdown","830e8191":"markdown","ae7ffd44":"markdown","1ed25211":"markdown","1cb7c83e":"markdown","d585fae1":"markdown","66b8d429":"markdown","bdfd8aa4":"markdown","abb665d4":"markdown","5cc8cd8a":"markdown","ea5ad944":"markdown","cec5821c":"markdown","92168241":"markdown","9616f8cc":"markdown","eafd11a1":"markdown","68cb081b":"markdown","de7cb0fd":"markdown","094fef75":"markdown","2dda5979":"markdown","aae4e91b":"markdown","9fceff88":"markdown"},"source":{"a6d9a628":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","db399c41":"data=pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","c6cbfb41":"data.head()","961c1eba":"Features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction', 'Age']\nX = data[Features]   \ny = data.Outcome ","e1c4b25b":"data.describe() ","ea3ccc5d":"data.info() ","2e54f936":"data.isnull()","491fc688":"data.isnull().sum()","2766c33e":"plt.rcParams['figure.figsize'] = (40, 41)\nplt.style.use('dark_background')\n\nsns.pairplot(data, hue = 'Outcome', palette = 'husl')\nplt.title('Pair plot for the data', fontsize = 40)\nplt.show()","e9c12233":"plt.rcParams['figure.figsize'] = (15, 15)\n\nsns.heatmap(data.corr(), annot = True)\nplt.title('Correlation Plot')\nplt.show()","c23f8597":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)\nX_scaled","efb31610":"pd.DataFrame(X_scaled)","09ac45a6":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.33,random_state=42) \nx_train.shape","0b9d92e6":"from sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\n\nclf.fit(x_train,y_train)\ny_pred=clf.predict(x_test)","b485a8af":"print(y_pred)","fd8dace2":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(clf.predict(x_train), y_train))\nprint(accuracy_score(y_pred, y_test))","8c10806a":"from sklearn.metrics import confusion_matrix \nconfusion_matrix(y_pred, y_test)","57336ba1":"from sklearn.metrics import classification_report\nclassification_report(y_pred, y_test)","f4c53210":"# 1)Let's import all the required Packages","1eee7f31":"# 8)Trying to fit the model\n# I am using a simple Logistic Regression model for this Binary classification problem!!\nI have tried to hypertune the parameters however there is not much difference in the Accuracy results so using default parameters Only. I have also tried to drop the poorly correlated features however the Accuracy remains the same. I am a newbie to Machine Learning so still learning other algorithms to experiment in future for better accuracy results!!","830e8191":"# 10)Confusion Matrix\nSince this is a medical diagnosis along with Accuracy score always evaluate model results with Confusion Matrix as you surely want to zero out those False Negatives to avoid any misses in diagnosing a patient who Truly has Diabetes for effective identification and treatment","ae7ffd44":"# Pima Indians Diabetes Database\n# Inspiration\n# Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?","1ed25211":"# Pair Plot analysis from above graph :\nThe histograms that appear across the diagonal in the graph is because its Pregnanies vs Pregnancies ..Glucose vs Glucose...BloodPressure vs BloodPressure ..etc\n\nSo, now focus on the actual pairplots above to draw some insights :\n\n# 0 - pink color scatter indicates No Diabetes\n# 1 - blue color scatter indicates Has Diabetes\nSo, look at -\n\n# Age vs Glucose\nwe can see from the plot that when the glucose level is below 100 aprx and check the age in Y axis they are classified as Not having Diabetes but as the glucose level increases beyond 100 to 200 and check the age in Y axis they are classified as having Diabetes\n\nSimilarly look at the pair plot -\n\n# Glucose vs BMI\nfor BMI between 20 and 40 range when the glucose level is above 100 apprx then the people are classified as having Diabetes.\n\nSuch intuitions can be infered using PairPlots","1cb7c83e":"# 4)PLOTS for Visualization and Insights\nLet us Plot a suitable graph to find multicollinearity i.e relationship between independent features in the given dataset.\n\n# Pair Plot is a good idea to represent the relationship between the independant features \neg. Glucose vs Insulin or Age vs BMI\n\nWe have aleady imported matplotlib and seaborn libraries so we are good to go ahead to map the Pair Plot!!","d585fae1":"# 3)Data Munging\nCheck the descriptive information of Dataset using pandas describe and info methods\n# pandas describe - This is an important step to understand the distribution of the data","66b8d429":"# 7)Splitting the data\nTo understand the model performance, we divide the dataset into a training set and a test set. Let's split the dataset by using function train_test_split() from sklearn. The 3 parameters to be passed are Features, outcome, and test_set size. Additionally, you can use random_state to select records randomly.","bdfd8aa4":"There are 32 False Negatives which mean 32 people have Diabetes present but my Model classified them as Not having Diabetes so definitely need to improve model performance!! I have been told Neural Networks will yeild better results in such cases of Binary Classification so I am still coming up that learning curve! ","abb665d4":"# Wondering what is Pima ?\nThe Pima are a group of Native Americans living in an area consisting of what is now central and southern Arizona, as well as northwestern Mexico in the states of Sonora and Chihuahua. The majority population of the surviving two bands of the Akimel O'odham are based in two reservations: the Keli Akimel O\u02bcotham on the Gila River Indian Community and the On'k Akimel O'odham on the Salt River Pima-Maricopa Indian Community.\n\nWikipedia","5cc8cd8a":"# I hope what I have learnt and shared is helpful to someone in someway!\n\n# PASSION FOR TECHNOLOGY","ea5ad944":"# 5)Correlation Matrix for Visualization and Insights between the correlation of Independant Features and Dependant Feature by using Heatmaps.\n\nThe color scale on the right hand side is indicative of the correlation trending towards 1 (max positive correlation value)","cec5821c":"# Check for nulls in the dataset","92168241":"# 9)Evaluating the model\nSince this is a medical diagnosis along with Accuracy score always evaluate model results with Confusion Matrix\/Precision\/Recall\/F1score to really understand the sensitivity and specificity of the predictions as you surely want to zero out those False Negatives to avoid any misses in diagnosing a patient who Truly has Diabetes for effective identification and treatment","9616f8cc":"# The Training Accuracy is 78 %\n...this to me is Okay on the Training set and not going to improve further as it can lead to Overfitting and our focus is more on How our model is going to perform on the Test Data!!\n\n# The Testing Accuracy is 74 %\n..We need to surely improve the Testing Accuray score,though I tried to hypertune the model parameters and tried to drop some of the poorly correlated features however the score did not change much.\n\nI have been told Neural Networks will yeild better results in such cases of Binary Classification","eafd11a1":"# pandas info - This is an important step as it gives you information about the data types","68cb081b":"# 6)Apply Feature scaling to standardize the data columns to common units to avoid biased model.\nAll the Features are in different units of measurements so this is a very important preprocessing step to get good results!\n\nHence we use StandardScaler library to fit the data and then transform to convert the original values to the standardized values hence avoiding bias","de7cb0fd":"# We have No Null values in this dataset so lets get going!!","094fef75":"Below can be the insights from the Correlation Matrix :\n\n# There are No negatively co-related features\n\n# Positively Correlated features :\n\n# Glucose\nIt has a value of .47 which is the highest correlation value in this graph and it is the most important factor determining Diabetes so this is how the machine has found the important feature. Hence Glucose is positively correlated and we can infer as glucose level increases patient is having Diabetes\n\n# BMI, Age, and Pregnancy\nIt has .29 , .24 and .22 values repectively so they can also be important features to predict presence of Diabetes\n\n# Low contributors to the correlation\nPedigree and Insulin are contributing to .17 and .13 correlation only\n\nOn the other hand BP, Skin thickness have low values of .065 and .075 so they are insignificant predictors for Diabetes diagnosis","2dda5979":"# 11)Precision\/Recall\/F1score to really understand the sensitivity and specificity of the predictions","aae4e91b":"# 2)Split the dataset into features and target variable\n\nFeatures are the Independant variables\n\nOutcome is the Class label : 0 - No Diabetes , 1 - Diabetes Present","9fceff88":"Incase you would like to see the transformed standardized data frame do the below step - "}}