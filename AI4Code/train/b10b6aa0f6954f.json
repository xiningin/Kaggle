{"cell_type":{"8f02cd9d":"code","0c7489db":"code","b9edf207":"code","7584a87e":"code","a5c85003":"code","9b082baa":"code","e1778c6a":"code","b9b54955":"code","99ffee81":"code","c83afa06":"code","905e8c0c":"code","d9b9a76a":"code","d36a44b8":"code","68729f18":"markdown"},"source":{"8f02cd9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0c7489db":"import pandas as pd\nfrom datetime import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRFRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV","b9edf207":"filename = '\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv'\ndf = pd.read_csv(filename, parse_dates=[0])\ndf.head()","7584a87e":"def weird_division(n, d):\n    return n \/ d if d else 0","a5c85003":"df['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)\ndf['View\/measurable'] = df.apply(lambda x: weird_division(x['viewable_impressions'],x['measurable_impressions']) , axis=1)","9b082baa":"df.drop(columns=['revenue_share_percent', 'integration_type_id', 'total_impressions'], inplace=True)","e1778c6a":"#Split for train & test\ntrain_df = df[df.date <= datetime(2019, 6, 21)]\ntest_df = df[df.date > datetime(2019, 6, 21)]\ntrain_df = train_df[train_df.CPM <= train_df.CPM.quantile(0.95)]\ntest_df = test_df[test_df.CPM <= test_df.CPM.quantile(0.95)]\ntest_df = test_df[test_df.CPM >= 0]\ntrain_df.reset_index(inplace=True)\ntest_df.reset_index(inplace=True)","b9b54955":"def get_x_y(frame):\n    X = frame[['site_id', 'ad_type_id', 'geo_id', 'device_category_id', \n               'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n               'monetization_channel_id', 'ad_unit_id', 'viewable_impressions',\n               'measurable_impressions', 'View\/measurable']]\n    y = frame['CPM']\n    return X, y","99ffee81":"def fix_preds(X_test, preds):\n    for i in X_test.index:\n        if X_test.iloc[i]['measurable_impressions'] == 0:\n            preds[i] = 0\n    for i in range(len(preds)):\n        if preds[i] < 0:\n            preds[i] = 0\n    return preds","c83afa06":"X_train, y_train = get_x_y(train_df)\nX_test, y_test = get_x_y(test_df)","905e8c0c":"regressors = {'LGBM': LGBMRegressor(objective='mse', n_jobs=-1),\n               'CatBoost': CatBoostRegressor(objective='RMSE', verbose=0),\n               'XGB': XGBRFRegressor(objective='reg:squarederror'),\n               'RandomForest': RandomForestRegressor(criterion='mse', n_jobs=-1)\n              }","d9b9a76a":"for name, regressor in regressors.items():\n    regressor.fit(X_train, y_train)\n    preds = regressor.predict(X_test)\n    print(f'name: {name}, score: {mean_squared_error(y_test, preds)}')","d36a44b8":"#After some experiments with GridSearch\nregr = LGBMRegressor(metric='mse', n_estimators=300, n_jobs=-1, num_leaves=141, objective='mse')\nregr.fit(X_train, y_train)\npreds = regr.predict(X_test)\nprint(mean_squared_error(y_test, preds))\npreds = fix_preds(X_test, preds)\nprint(mean_squared_error(y_test, preds))","68729f18":"### Best Score: 2647\n# Hochu Zachet!"}}