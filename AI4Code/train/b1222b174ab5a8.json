{"cell_type":{"5c21c3e4":"code","deaf3274":"code","258d43dc":"code","06e80b8a":"code","da1f5ce8":"code","1bb1e608":"code","93ab9af3":"code","cf15ded2":"code","09d81024":"code","70308ae5":"code","841981aa":"code","08f01de1":"code","6d6704e8":"code","c423a756":"code","2a5d60a2":"code","6230ea29":"code","415c7259":"code","a9685670":"code","99f37045":"code","5301b740":"code","b5b3e3a4":"code","26d5f542":"code","fe9cdf17":"code","c2b6e033":"code","53e161ac":"code","eeb4267a":"code","a953431c":"code","1f06253b":"code","219ca920":"code","089b0f18":"code","ed48e794":"code","f41fcbcb":"code","387cf8e9":"code","2427d396":"code","95436235":"code","ec8f483a":"code","b5421046":"code","ac48872e":"code","cf514eb0":"code","442bc7fe":"code","e30747f5":"code","82c3977a":"code","3db2bab0":"code","e1f020ea":"code","c30f68a8":"markdown","c10e3d2e":"markdown","45b8665a":"markdown","058caa18":"markdown","8b52bba8":"markdown","a378e12a":"markdown","6c719a7c":"markdown","ef5a28f2":"markdown","3b183c41":"markdown","24e5915b":"markdown","df3968e6":"markdown","e6110775":"markdown","b612536a":"markdown","90b23cea":"markdown","7ad0fe51":"markdown","af17f58a":"markdown","f50e8e34":"markdown","c723ac16":"markdown","002947d9":"markdown","79f9b138":"markdown","4ce86d21":"markdown","72792f83":"markdown","31c07e93":"markdown","96d72e14":"markdown","b1e46af0":"markdown","1bbcecd6":"markdown","7dc22341":"markdown","99c7c09e":"markdown","864fde86":"markdown","f9dec04c":"markdown","378ac56d":"markdown","8689c9ed":"markdown","444356b9":"markdown","021feff1":"markdown","18baffcd":"markdown","ccffd5fb":"markdown","54a04aec":"markdown","92b89cf8":"markdown","d4de8f24":"markdown","6cbb5f5e":"markdown","594dc50e":"markdown","ed53569a":"markdown"},"source":{"5c21c3e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","deaf3274":"stocks_df = pd.read_csv(\"..\/input\/sandp500\/all_stocks_5yr.csv\", index_col = 0, parse_dates= True)","258d43dc":"stocks_df.head()","06e80b8a":"stocks_df.tail()","da1f5ce8":"unique_stocks_names = stocks_df.Name.unique()\nunique_stocks_names","1bb1e608":"def select_and_plot_stock(stock):\n  %matplotlib inline\n  stock_df = stocks_df.loc[stocks_df.Name == stock, :]\n  plt.figure(figsize = (10,10))\n  plt.plot(stock_df.index, stock_df.close)\n  plt.title(f\"Stock Name : {stock}\")\n  plt.xlabel(\"Date\")\n  plt.ylabel(\"Close Price\")\n  plt.grid = True\n  plt.show()\n","93ab9af3":"select_and_plot_stock(\"AAL\")\nselect_and_plot_stock(\"AMZN\")","cf15ded2":"stocks = unique_stocks_names\ndaily_return = pd.DataFrame() #create a DataFrame of daily returns\nfor n in range(len(stocks)):\n        stock_df = stocks_df.loc[stocks_df.Name == stocks[n], :]\n        stock_daily_return = stock_df[\"close\"].pct_change() #usring pct_change function can give us the daily return\n        daily_return[stocks[n]] = stock_daily_return\n        n += 1\ndaily_return = daily_return.drop(daily_return.index[0],axis=0) #drop the first column which doesn't have data in daily return data frame\ndaily_return","09d81024":"def plot_daily_return(stock_names):\n    for n in range(len(stock_names)):\n        plt.figure(figsize = (20,10))\n        plt.subplot(len(stock_names),1,n+1)\n        plt.plot(daily_return.index, daily_return[stock_names[n]])\n        plt.title(f\"Stock Name : {stock_names[n]}\")\n        plt.xlabel(\"Date\")\n        plt.ylabel(\"Daily Return\")\n        plt.grid = True\n        plt.show()\n        plt.grid = True\n        n+=1","70308ae5":"names = [\"AMZN\", \"EBAY\", \"AAL\"]\nplot_daily_return(names)","841981aa":"def dist_plot_return(stock_names):\n    for n in range(len(stock_names)):\n        plt.figure(figsize = (10,10))\n        plt.subplot(len(stock_names),1,n+1)\n        daily_return_stock = daily_return.loc[:, stock_names[n]]\n        daily_return_stock.plot.hist(bins = 50)\n        plt.title(f\"Stock Name : {stock_names[n]}\")\n        plt.xlabel(\"Date\")\n        plt.ylabel(\"Daily Return\")\n        plt.grid = True\n        plt.show()\n        plt.grid = True\n        n+=1","08f01de1":"names = [\"AMZN\", \"EBAY\", \"AAL\"]\ndist_plot_return(names)","6d6704e8":"def annualize_rets(r, periods_per_year):\n  \"\"\"\n  Annulalizes a set of returns\n  \"\"\"\n\n  compounded_grouwth = (1+r).prod()\n  n_periods = r.shape[0]\n  return compounded_grouwth**(periods_per_year\/n_periods)-1","c423a756":"\nannualize_rets(daily_return[\"AMZN\"], 252) #The operational days of the stocks market in a year is 252 days","2a5d60a2":"def drawdown(returns_series: pd.Series):\n  \"\"\"Takes a time series of asset returns. \n     returns a DataFrame with columns for the wealth index,\n     the previous peaks, and\n     the percentage drawdown\n  \"\"\"\n  wealth_index = 1000*(1+returns_series).cumprod()\n  previous_peaks = wealth_index.cummax()\n  drawdowns = (wealth_index - previous_peaks)\/previous_peaks\n  return pd.DataFrame({\"Wealth\" : wealth_index, \"Previous Peak\" : previous_peaks, \"Drawdown\" : drawdowns})\n\n","6230ea29":"drawdown(daily_return[\"AMZN\"])","415c7259":"plt.figure(figsize = (10, 10))\ndrawdown(daily_return[\"AMZN\"])[[\"Wealth\", \"Previous Peak\"]].plot()\nplt.show()","a9685670":"plt.figure(figsize = (10, 5))\ndrawdown(daily_return[\"AMZN\"])[\"Drawdown\"].plot()","99f37045":"def skewness (r):\n  \"\"\"\n  Alternative to scipy.stats.skew()\n  computes the skewness of the supplied series or dataframe\n  returns a float or series\n  \"\"\"\n  demeaned_r = r - r.mean()\n  #use the population standard deviation, so set dof=0\n  sigma_r = r.std(ddof=0)\n  exp = (demeaned_r ** 3).mean()\n  return exp\/sigma_r ** 3","5301b740":"skewness_df = pd.DataFrame(skewness(daily_return))\nskewness_df.columns = [\"Skewness\"]\nskewness_df","b5b3e3a4":"for n in range (0,506, 30):\n    sample_skewness_df = skewness_df[n : n+20].sort_values(by = [\"Skewness\"])\n    %matplotlib inline\n    sample_skewness_df.plot.bar()\n    plt.show()","26d5f542":"def kurtosis(r):\n  demeaned_r = r - r.mean()\n  sigma_r = r.std(ddof=0)\n  exp = (demeaned_r**4).mean()\n  return exp\/sigma_r**4\n","fe9cdf17":"kurtosis_df = pd.DataFrame(kurtosis(daily_return))\nkurtosis_df.columns = [\"Kurtosis\"]\nkurtosis_df","c2b6e033":"for n in range (0,506, 30):\n    sample_kurtosis_df = kurtosis_df[n : n+20].sort_values(by = [\"Kurtosis\"])\n    %matplotlib inline\n    sample_kurtosis_df.plot.bar()\n    plt.show()","53e161ac":"er = annualize_rets(daily_return[:\"2015\"],252) #annualized expected return in the 2013 to 2015 period\ner","eeb4267a":"cov = daily_return.cov()\ncov.head()","a953431c":"def portfolio_return(weights, returns):\n  \"\"\"\n  weights --> Returns\n  \"\"\"\n  return weights.T @ returns # transposing the weights matrix and multiply it by returns\n","1f06253b":"def portfolio_vol(weights, covmat):\n  \"\"\"\n  Weights --> Vol\n  \"\"\"\n  return (weights.T @ covmat @ weights)**0.5","219ca920":"from scipy.optimize import minimize\ndef minimize_vol(target_return, er, cov):\n  \"\"\"\n  target_ret ==> W \n  \"\"\"\n  n = er.shape[0] #number of weights\n  init_guess = np.repeat(1\/n, n) #makes a tuple of n tuples for weights\n  bounds = ((0.0, 1.0),)*n #defines the max and min of our possible weights\n  return_is_target = {\n      \"type\" : \"eq\",\n      \"args\" : (er,),\n      \"fun\" : lambda weights, er :\n       target_return - portfolio_return(weights, er)\n  } \n    \n  weights_sum_to_one = {\n      \"type\" : \"eq\",\n      \"fun\" : lambda weights: np.sum(weights) - 1\n      }\n  results = minimize(\n      portfolio_vol, init_guess,\n                     args = (cov,), method = \"SLSQP\",\n                     options = {\"disp\" : False},\n                     constraints = (return_is_target, weights_sum_to_one),\n                     bounds = bounds\n                    )\n  return results.x","089b0f18":"def optimal_weights(n_points, er, cov):\n  \"\"\"\n  Generates a list of weights to run the optimizer on, to minimize the volatility\n  \"\"\"\n  target_rs = np.linspace(er.min(), er.max(), n_points)\n  weights = [minimize_vol(target_return, er, cov) for target_return in target_rs]\n  return weights","ed48e794":"def msr(riskfree_rate, er, cov):\n  \"\"\"\n  Returns the weights of the portfolio that gives you the maximum sharpe ratio given the riskfree rate and expected returns and a covariancce matrix\n  \"\"\"\n  n = er.shape[0] \n  init_guess = np.repeat(1\/n, n) \n  bounds = ((0.0, 1.0),)*n \n  weights_sum_to_one = {\n      \"type\" : \"eq\",\n      \"fun\" : lambda weights: np.sum(weights) - 1\n  }\n  def neg_sharpe_ratio(weights, riskfree_rate, er, cov):\n    \"\"\"\n    Returns the negative of the sharpe ratio, given weights\n    \"\"\"\n    r = portfolio_return(weights, er) \n    vol = portfolio_vol(weights, cov) \n    return -(r - riskfree_rate)\/vol\n\n  results = minimize(neg_sharpe_ratio, init_guess,\n                     args=(riskfree_rate, er, cov,), method=\"SLSQP\",\n                     options={\"disp\" : False},\n                     constraints = (weights_sum_to_one),\n                     bounds=bounds\n                    )\n  return results.x","f41fcbcb":"def gmv(cov):\n  \"\"\"\n  Returns the weights of the Global Minimum Vol Portfolio given covariance matrix\n  \"\"\"\n  n = cov.shape[0]\n  return msr(0, np.repeat(1,n), cov)","387cf8e9":"def plot_ef(n_points, er, cov, show_cml=False, show_ew=False, show_gmv=False, riskfree_rate=0, style=\".-\"):\n  \"\"\"\n  Plots the efficient frontier curve, msr, gmv, and ew points.\n  \"\"\"\n  weights = optimal_weights(n_points, er, cov)\n  rets = [portfolio_return(w, er) for w in weights]\n  vols = [portfolio_vol(w, cov) for w in weights]\n  ef = pd.DataFrame({\"Returns\" : rets, \"Volatility\" : vols})\n  ax = ef.plot.line(x=\"Volatility\", y = \"Returns\", style = style)\n  if show_gmv:\n    w_gmv = gmv(cov)\n    r_gmv = portfolio_return(w_gmv, er)\n    vol_gmv = portfolio_vol(w_gmv, cov)\n    #displat EW\n    ax.plot([vol_gmv], [r_gmv], color=\"midnightblue\", marker = \"o\", markersize=12)\n  if show_ew:\n    n = er.shape[0]\n    w_ew = np.repeat(1\/n , n)\n    r_ew = portfolio_return(w_ew, er)\n    vol_ew = portfolio_vol(w_ew, cov)\n    #displat EW\n    ax.plot([vol_ew], [r_ew], color=\"red\", marker = \"o\", markersize=10)  \n  if show_cml:\n    ax.set_xlim(left = 0)\n    rf = 0.1\n    w_msr = msr(riskfree_rate, er=er, cov=cov)\n    r_msr = portfolio_return(w_msr, er)\n    vol_msr = portfolio_vol(w_msr, cov)\n    #Add CML\n    cml_x = [0, vol_msr]\n    cml_y = [riskfree_rate, r_msr]\n    ax.plot(cml_x, cml_y, color = \"green\", marker = \"o\", linestyle = \"dashed\", markersize = 12, linewidth =2)\n  return ax\n","2427d396":"plot_ef(20, er, cov, show_cml=True, show_ew=True, show_gmv=True, riskfree_rate=0.03)","95436235":"ew_weights = np.repeat(1\/er.shape[0], er.shape[0])\new_weights[:30] # We can see the firts 30 allocated weights\n","ec8f483a":"portfolio_return(ew_weights, er)","b5421046":"msr_weights = msr(0.03, er, cov)\nmsr_weights[:30]","ac48872e":"portfolio_return(msr_weights, er)","cf514eb0":"gmv_weights = gmv(cov)\ngmv_weights[:30]","442bc7fe":"portfolio_return(gmv_weights, er)","e30747f5":"rets = annualize_rets(daily_return[\"2016\":],252)\nrets","82c3977a":"portfolio_return(ew_weights, rets)","3db2bab0":"portfolio_return(msr_weights, rets)","e1f020ea":"portfolio_return(gmv_weights, rets)","c30f68a8":"### *Stock Names (Symbols)\nLet's look at the unique stock names in the data frame:","c10e3d2e":"## 6. Testing portfolio weights on the test period:\nUsing the calculated weights in each construction method, we can now calculate our actual returns for the unseen data (2016-2018 period):","45b8665a":"For each approach, we need an array representing the weights of the stocks in our portfolio.\nIn the **EW approach**, we only need to allocate weights equally to each stock.\nIn the MSR approach though, we need to calculate the optimized weights that give us a portfolio with the maximum sharpe ratio.\nFinally, in the GMV approach, we need to calculate the weights which give us a portfolio with the minimum volatility.\n\nIn order to find the optimum weights based on each approach, I used the minimizing optimizer method in numpy.","058caa18":"### *Covariance Matrix\nFor the efficient frontier approach, we need the covariance matrix of the stocks. \n\nFortunately, pandas has a method simply builds this matrix:","8b52bba8":"### *Optimizer Function\nThen, the minimizer function which gives the optimum weights for a given return;\nAs we need the minumum volatility for the GMV approach, and the maximum Sharpe Ratio for the MSR approach, we can benefit from this minimizer method in the scipy library. (A trick here is that we can find the  **minimum of the \"negative Sharpe Ratio\"**  instead of the possible maximum Sharpe Ratio)","a378e12a":"Let's see the skewness graphs for all of the stocks:","6c719a7c":"### *Calculating each portfolio returns using allocated weights:\nNow, let's see the weight array of each approach and calculate the annualized return in the training period for each one:","ef5a28f2":"### *Plotting Efficient Frontier Curve, MSR, GMV, and EW points\nNow, let's define a function to plot three spots on the returns-volatility graph using three different approaches (EF, GMV, EW.\n\nI used the **midnight blue** color for the **GMV approach**, the **red** color for the **EW** approach, and the **green** color for the **MSR** approach","3b183c41":"We can also calculate the kurtosis parameter for return distributions:","24e5915b":"### *Calculating Portfolio Returns\nNow, let's define a function to calculate the annualized return of a given portfolio using the weights array of the stocks:","df3968e6":"## 3. Reading Data Set\nNow let's read the csv file from kaggle data set; \n\nIn order to easily divide our data set into two or more time periods, we can parse dates in the data set:","e6110775":"### *Dividing data set into two periods:\nIn order to build this data sets, we simply can benefit from the date parsing capability of pandas library we used while reading our csv file:","b612536a":"### *MSR Approach\nLet's define a function for the MSR Approach; As I mentioned before, we can find the minimum \"negative Sharpe Ratio\" so that we could find the maximum possible Sarpe Ratio and the allocated weights:","90b23cea":"### *Drawdown\nAlso, we can see the drawdown of a given returns set.\n\nHere, we assume that the starting equity is $1000 and will see what will be the fial equity after each day:","7ad0fe51":"> Now let's define a function to be able to plot daily returns for any list of stocks:","af17f58a":"To do this task, we need to define some functions:\n\n\n### *Portfolio Volatility\nFirst of all, a function which calculates the volatility of the portfolio given the weights","f50e8e34":"# **1. Objective:**\n\n### *Comparing  portfolio construction methods using different approaches based on the S&P 500 stocks :*\n\n### The compared approaches are:\n\n   #### 1- Equally Weighted Approach-**EW**, in which each stock gets an equal weight.\n   \n  #### 2- Efficient Frontier Approach == Maximum Sharpe Ration Approach- **MSR** in which the weights are calculated to maximize the sharpe ratio.\n   \n  #### 3- Global Minimum Variance Approach - **GMV** in which the weights are calculated to minimize the volatility of the portfolio.\n   \n   ","c723ac16":"**MSR Approach:**","002947d9":"Now let's plot two instances:","79f9b138":"### *Daily Returns\nNow let's build a data frame of the daily returns of each stock.\n\nWe can benefit from a loop to build the daily return of each stock:","4ce86d21":"**GMV Approach:**","72792f83":"Let's define our annualized return data set for this period","31c07e93":"### ** *EW Approach: **","96d72e14":"We also can see the plot of the drawdown itself:","b1e46af0":"### * Daily Returns Distribution\nWe can also plot the daily return distribution for each stock using histogram plot.\n\nLet's define a function for this application:","1bbcecd6":"**GMV Approach:**","7dc22341":"### *Price Chart\nWe can plot the price changes of the stocks using each day's close price. \nLet's define a function to simplify future plotting tasks:","99c7c09e":"For instance, let's plot daily returns of three randomly selected stocks:","864fde86":"For instance, let's plot the same three stocks:","f9dec04c":"### * Annualized Return\nwe can calculate the annualized return of a given stock returns:","378ac56d":"**MSR Approach:**","8689c9ed":"## 2. Importing Libraries\nFirstly, let's import libraries and os:","444356b9":"### *In order to compare the returns of these approaches in an unseen period, we need to divide our data into two periods:*\n\n  **1- From 2013-2015 - Train Period**\n \n  **2- From 2015 to 2018 - Test Period**\n  \n  It's noteworthy to mention that I haven't used any machine learning solution in this part of the project and the \"taining\" and \"test\" words are used only to define the \"seen\" and \"unseen\" data sets.","021feff1":"Let's build the \"AMZN\" stock drawdown DataFrame.","18baffcd":" ## 5. Portfolio Construction\nFor calculating weights for our desire portfolio and test them on the unseen data, we need to divide our data set into 2 periods.\n\nI chose two periods as training and testing periods :\n\n  1- 2013 to 2015 period as my training data\n  \n  2- 2016 to 2018 period as my testing data","ccffd5fb":"### *Skewness and Kurtosis\nThere are some other parameters that are important for a portfolio analyst such as \nthe Skewness and Kurtosis of the return distribution graph:","54a04aec":"**EW Approach:**","92b89cf8":"## 4. EDA\nLet's run a simple EDA on the data set to take a glance at our data:","d4de8f24":"You can see that our returns are not normally distributed at all (Kurtosis=3 and Skewness =0 represents a Normal (Gaussian) distribution)","6cbb5f5e":"Now let's see what would be our actual return if we used the obtained weights in each approach.\n","594dc50e":"### *Global Minimum Variance (GMV) Approach\nWe can benefit from the same msr function we built for the msr approach. But in this case, our risk free rate is assumed to be zero and our expected return series doesn't have any role:","ed53569a":"Now we can plot the peaks and wealth index of the stock:"}}