{"cell_type":{"a8b29783":"code","78503ace":"code","1d72a9a8":"code","fa11ff89":"code","03260798":"code","a43b6ef9":"code","0a32d661":"code","ed710f0d":"code","a94cd82c":"code","b70c30a0":"code","1a8ca0ec":"code","1ecf5af2":"code","a3474c42":"code","603d7dd4":"code","6d41092d":"code","d61aa71f":"code","0aa15424":"code","3c28e15c":"code","b8d49d3a":"code","9ddf2532":"code","bf93f92d":"code","aec4a0e9":"code","a622aeb8":"code","43e59c16":"code","7a988d53":"code","06d933ad":"code","86ee33a3":"code","f3f9e8bc":"markdown","a446aaf9":"markdown","bce843ef":"markdown","838a1131":"markdown","aec3214e":"markdown","cecb526e":"markdown","92c39fd9":"markdown","2a64aca5":"markdown","03d38d8c":"markdown"},"source":{"a8b29783":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78503ace":"train=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nX=train.drop('label',axis=1)\/255.0\ntestX=test\/255.0\ny=train.label","1d72a9a8":"np.random.seed(42)\ntf.random.set_seed(42)\nk=keras.backend\nk.clear_session()\nfrom sklearn.model_selection import train_test_split\nXtrain,Xval,ytrain,yval=train_test_split(X,y,test_size=0.3,random_state=42)\nXtrain,Xtest,ytrain,ytest=train_test_split(Xtrain,ytrain,test_size=0.1,random_state=42)","fa11ff89":"Xtrain,Xval,Xtest=tf.Variable(Xtrain),tf.Variable(Xval),tf.Variable(Xtest)\nXtrainpp=tf.reshape(Xtrain,[Xtrain.shape[0],28,28,1])\nXvalpp=tf.reshape(Xval,[Xval.shape[0],28,28,1])\nXtestpp=tf.reshape(Xtest,[Xtest.shape[0],28,28,1])","03260798":"testX=tf.reshape(testX,[testX.shape[0],28,28,1])","a43b6ef9":"my_callbacks = [\n    keras.callbacks.EarlyStopping(patience=5),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                              patience=3, min_lr=0.0001),\n]","0a32d661":"from functools import partial\n\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='SAME')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2)\nmodel_vgg=keras.models.Sequential([\n    Default2D(filters=32,kernel_size=5,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=64),\n    MaxPool2D(),\n    Default2D(filters=128),\n    MaxPool2D(),\n    Default2D(filters=256,kernel_size=2),\n    MaxPool2D(),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(50,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(25,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10,activation='softmax')\n])","ed710f0d":"model_vgg.summary()","a94cd82c":"model_vgg.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_vgg=model_vgg.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","b70c30a0":"model_vgg.evaluate(Xtestpp,ytest)","1a8ca0ec":"model_vgg.save('mnist_cnn_vgg_992_007.h5') #99.2% accu and 0.07 % loss","1ecf5af2":"class Inseption2D(keras.layers.Layer):\n    def __init__(self,f11,f311,f333,f511,f555,fMP11,**kwargs):\n        super().__init__(**kwargs)\n        self.f11=f11\n        self.f311=f311\n        self.f333=f333\n        self.f511=f511\n        self.f555=f555\n        self.fMP11=fMP11\n        \n        self.Conv1x1=keras.layers.Conv2D(filters=self.f11,kernel_size=1,activation='relu',padding='same')\n    \n        self.Conv3SL1x1=keras.layers.Conv2D(filters=self.f311,kernel_size=1,activation='relu',padding='same')\n        self.Conv3SL3x3=keras.layers.Conv2D(filters=self.f333,kernel_size=3,activation='relu',padding='same')\n        \n        self.Conv5SL1x1=keras.layers.Conv2D(filters=self.f511,kernel_size=1,activation='relu',padding='same')\n        self.Conv5SL5x5=keras.layers.Conv2D(filters=self.f555,kernel_size=5,activation='relu',padding='same')\n        \n        self.MaxPool=keras.layers.MaxPooling2D(pool_size=3,strides=1,padding='same')\n        self.ConvMP1x1=keras.layers.Conv2D(filters=self.fMP11,kernel_size=1,activation='relu',padding='same')\n        \n    def call(self,inputs):\n        #Input via 1x1\n        out11=self.Conv1x1(inputs)\n        \n        #Input via Smart Layer (1x1,3x3)\n        x=self.Conv1x1(inputs)\n        out33=self.Conv3SL1x1(x)\n        \n        #Input via Smart Layer (1x1,5x5)\n        x=self.Conv1x1(inputs)\n        out55=self.Conv5SL1x1(x)\n        \n        #Input via Max Pool\n        x=self.MaxPool(inputs)\n        outMP11=self.ConvMP1x1(x)\n        \n        #concat the outputs\n        output=keras.layers.Concatenate(axis=-1)([out11,out33,out55,outMP11])\n        \n        return output\n    def get_config(self):\n        base_config=super().get_config()\n        return {**base_config,\n                'f11':self.f11,'f311':self.f311,'f333':self.f333,\n                'f511':self.f511,'f555':self.f555,'fMP11':self.fMP11}","a3474c42":"from functools import partial\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='same')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2,padding='same')\nmodel_gnet=keras.models.Sequential([\n    Default2D(filters=64,kernel_size=7,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=32,kernel_size=1),\n    Default2D(filters=128),\n    MaxPool2D(),\n    Inseption2D(f11=32,f311=16,f333=64,f511=16,f555=32,fMP11=16),\n    Inseption2D(f11=64,f311=32,f333=96,f511=32,f555=64,fMP11=32),\n    MaxPool2D(),\n    Inseption2D(f11=96,f311=64,f333=108,f511=64,f555=96,fMP11=64),\n    Inseption2D(f11=108,f311=96,f333=128,f511=64,f555=108,fMP11=64),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(90,activation='relu'),\n    keras.layers.Dense(45,activation='relu'),\n    keras.layers.Dense(10,activation='softmax')\n])","603d7dd4":"model_gnet.summary()","6d41092d":"model_gnet.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_gnet=model_gnet.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","d61aa71f":"model_gnet.evaluate(Xtestpp,ytest)","0aa15424":"model_gnet.save('mnist_cnn_inseption_988_005.h5') #98.84%  0.05%","3c28e15c":"class ResidualBlock(keras.layers.Layer):\n    def __init__(self,filters,strides=1,activation='relu',**kwargs):\n        super().__init__(**kwargs)\n        self.filters=filters\n        self.strides=strides\n        self.activation=keras.activations.get(activation)\n        self.main_layers=[\n            keras.layers.Conv2D(filters,2,strides=strides,padding='same',use_bias=False),\n            keras.layers.BatchNormalization(),\n            self.activation,\n            keras.layers.Conv2D(filters,2,strides=1,padding='same',use_bias=False),\n            keras.layers.BatchNormalization()\n        ]\n        self.skip_layers=[]\n        if strides>1:\n            self.skip_layers=[\n                keras.layers.Conv2D(filters,1,strides=strides,padding='same',use_bias=False),\n                keras.layers.BatchNormalization()\n            ]\n    def call(self,inputs):\n        Z=inputs\n        for layer in self.main_layers:\n            Z=layer(Z)\n        skip_Z=inputs\n        for layer in self.skip_layers:\n            skip_Z=layer(skip_Z)\n        return self.activation(Z+skip_Z)\n    \n    def get_config(self):\n        base_config=super().get_config()\n        return {**base_config,\"filters\":self.filters,\"strides\":self.strides,\"activation\":keras.activations.serialize(self.activation)}","b8d49d3a":"from functools import partial\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='same')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2,padding='same')\nmodel_rnet=keras.models.Sequential([\n    Default2D(filters=32,kernel_size=5,input_shape=[28,28,1]),\n    MaxPool2D(),\n    ResidualBlock(filters=64,strides=2),\n    ResidualBlock(filters=64),\n    ResidualBlock(filters=128,strides=2),\n    ResidualBlock(filters=128),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(50,activation='relu'),\n    keras.layers.Dense(25,activation='relu'),\n    keras.layers.Dense(10,activation='softmax')\n])","9ddf2532":"model_rnet.summary()","bf93f92d":"model_rnet.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_rnet=model_rnet.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","aec4a0e9":"model_rnet.evaluate(Xtestpp,ytest)","a622aeb8":"model_rnet.save('mnist_cnn_residual_99_003.h5') #99% 0.03%","43e59c16":"ypred=your_model_name.predict_classes(your_prepared_test_data)","7a988d53":"ImageId=pd.Series(range(1,28001))\nLabel=pd.Series(ypred)\nsol=pd.concat([ImageId, Label],axis=1)\nsol=sol.rename(columns={0: \"ImageId\", 1: \"Label\"})\nsol.to_csv('mnist_via_vggnet_sol.csv',index=False)","06d933ad":"\"\"\"\n\nclass DepthMaxPool(keras.layers.Layer):\n    def __init__(self, pool_size, strides=None, padding=\"VALID\", **kwargs):\n        super().__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = pool_size\n        self.strides = strides\n        self.padding = padding\n    def call(self, inputs):\n        return tf.nn.max_pool(inputs,\n                              ksize=(1, 1, 1, self.pool_size),\n                              strides=(1, 1, 1, self.pool_size),\n                              padding=self.padding)\n\n\"\"\"","86ee33a3":"\"\"\"\n\nfrom functools import partial\n\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='SAME')\nMaxPool2D=partial(keras.layers.MaxPooling2D,pool_size=2)\nmodel=keras.models.Sequential([\n    Default2D(filters=90,kernel_size=7,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=180),\n    MaxPool2D(),\n    Default2D(filters=256),\n    DepthMaxPool(16),\n    Default2D(filters=360),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(90,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(45,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10,activation='softmax')\n])\n\n\nmodel.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory=model.fit(Xtrainpp,ytrain,epochs=5,validation_data=(Xvalpp,yval))\nscore=model.evaluate(Xtestpp,ytest)\n\n\"\"\"","f3f9e8bc":"> Splited the train data into train, validation and test (used for evaluation) , **Never touch test data unless predicting**. ","a446aaf9":"# Residual Module (Type-> ResNet)","bce843ef":"# Inseption CNN (Type-> GoogleNet)","838a1131":"# How to Submit Prediction","aec3214e":"* If u reached here, a tip if u need the models they are in output section","cecb526e":"* Now my cnn networks are 2D so they accept 4-dim input so we must reshape our input\n\n> But why this shape only, cause the first dimention is no. of **instances\/batch_size** so i am using shape[0] , then the images in mnist dataset are **28x28** images flattened so lets un-flatten them, duhhh , and last is no. of **channels** which is 1 as our images are **b\/w** not rgb","92c39fd9":"# Simple CNN (Type-> VGG)","2a64aca5":"# Simple CNN with depth Pooling (Not Yet Supported By TF)","03d38d8c":"> Lets read train and test data\n\n* Divided train and test features by **255.0** to normalize it to range **(-1,1)** , generally neural networks perform better in a nomalized range (eg. **MaxMinScaler**) than scaled range (eg. **StandardScaler**)"}}