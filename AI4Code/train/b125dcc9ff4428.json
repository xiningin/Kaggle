{"cell_type":{"2bb41d68":"code","1584b8b9":"code","59974a04":"code","1dc631eb":"code","fccb1eca":"code","e364cd71":"code","ee238fc3":"code","a9f0124b":"code","b0de2b47":"code","5d9a430f":"code","9180d4cf":"code","9bda02e0":"code","c849f5af":"code","66fa4d5b":"code","fbeab7b3":"code","7ee8a2fa":"code","41d99ebf":"code","ed65d6e6":"code","339fc7b3":"code","975d46da":"code","b4304650":"code","666fb89e":"code","f0dd40a8":"code","dd96f176":"code","b00a8c25":"code","815d0eb7":"code","e28738e3":"code","379f2f0f":"code","25cb65d1":"code","f4ad112f":"code","230ff083":"code","347c30a0":"code","13030906":"code","65b89fad":"code","503e67e9":"code","b3bdbea1":"code","135dbc86":"code","a14577fe":"code","c6e6a5df":"code","afdf7db3":"markdown","50aa5e60":"markdown","b7cce8ae":"markdown","b96d1bf3":"markdown"},"source":{"2bb41d68":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1584b8b9":"#Import Ames House Dataset\ndf= pd.read_csv('\/kaggle\/input\/taitanictrain\/datasets_11657_16098_train.csv')","59974a04":"df.info()","1dc631eb":"df.describe()","fccb1eca":"df.head()","e364cd71":"sns.countplot(x='Survived',data=df)","ee238fc3":"sns.countplot(x='Survived',hue='Sex',data=df,palette='winter')","a9f0124b":"sns.countplot(x='Survived',hue='Pclass',data=df)","b0de2b47":"df['Age'].plot.hist()\n","5d9a430f":"sns.scatterplot(data=df, x='Age', y='Sex', hue='Survived')","9180d4cf":"sns.boxplot(data=df, x='Survived', y='Age')","9bda02e0":"sns.boxplot(data=df, x='Sex', y='Age')","c849f5af":"df['Fare'].plot.hist(bins=20,figsize=(10,5))","66fa4d5b":"sns.countplot(x='SibSp',data=df)","fbeab7b3":"df['Parch'].plot.hist()","7ee8a2fa":"sns.countplot(x='Parch',data=df)","41d99ebf":"df.isnull().sum()","ed65d6e6":"df.drop('Cabin',axis=1,inplace=True)","339fc7b3":"df.head()","975d46da":"df.dropna(inplace=True)","b4304650":"df.shape","666fb89e":"df.isnull().sum()","f0dd40a8":"df['Sex'] = df['Sex'].map({'male':1,'female':0})\ndf.head()","dd96f176":"df.drop(['PassengerId','Ticket','Embarked','Name','Fare'],axis=1,inplace=True)","b00a8c25":"df.head()","815d0eb7":"df.info()","e28738e3":"print('max_missing:', df.count().idxmin())","379f2f0f":"sns.pairplot(df, hue='Survived')","25cb65d1":"plt.figure(figsize=(16,10))\nfor i in range (len(df.columns)):\n    plt.subplot(3,5,i+1)\n    sns.boxplot(df[df.columns[i]])","f4ad112f":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score , confusion_matrix , classification_report\nfrom sklearn.neighbors import KNeighborsClassifier","230ff083":"X= df.drop(['Survived'], axis=1)\ny=df['Survived']","347c30a0":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)","13030906":"scaler= StandardScaler()\nscaler.fit(X_train)","65b89fad":"scaled_X_train= scaler.transform(X_train)\nscaled_X_test= scaler.transform(X_test)","503e67e9":"Logistic=LogisticRegression()\nLogistic.fit(scaled_X_train,y_train)","b3bdbea1":"y_pred=Logistic.predict(scaled_X_test)","135dbc86":"accuracy_score(y_test , y_pred)","a14577fe":"confusion_matrix(y_test , y_pred)","c6e6a5df":"print(classification_report(y_test , y_pred))","afdf7db3":"# Data Cleaning","50aa5e60":"# Logistic regression\nLogistic regression, despite its name, is a classification model rather than regression model. Logistic regression is a simple and more efficient method for binary and linear classification problems. \n\nLogistic regression can be binomial, ordinal or multinomial. Binomial or binary logistic regression deals with situations in which the observed outcome for a dependent variable can have only two possible types, \"0\" and \"1\" (which may represent, for example, \"dead\" vs. \"alive\" or \"win\" vs. \"loss\"). Multinomial logistic regression deals with situations where the outcome can have three or more possible types (e.g., \"disease A\" vs. \"disease B\" vs. \"disease C\") that are not ordered. Ordinal logistic regression deals with dependent variables that are ordered.\n\nIn binary logistic regression, the outcome is usually coded as \"0\" or \"1\", as this leads to the most straightforward interpretation.\nIf a particular observed outcome for the dependent variable is the noteworthy possible outcome (referred to as a \"success\" or an \"instance\" or a \"case\") it is usually coded as \"1\" and the contrary outcome (referred to as a \"failure\" or a \"noninstance\" or a \"noncase\") as \"0\". Binary logistic regression is used to predict the odds of being a case based on the values of the independent variables (predictors). The odds are defined as the probability that a particular outcome is a case divided by the probability that it is a noninstance.\n\nLike other forms of regression analysis, logistic regression makes use of one or more predictor variables that may be either continuous or categorical. Unlike ordinary linear regression, however, logistic regression is used for predicting dependent variables that take membership in one of a limited number of categories (treating the dependent variable in the binomial case as the outcome of a Bernoulli trial) rather than a continuous outcome. Given this difference, the assumptions of linear regression are violated. In particular, the residuals cannot be normally distributed. In addition, linear regression may make nonsensical predictions for a binary dependent variable. What is needed is a way to convert a binary variable into a continuous one that can take on any real value (negative or positive). To do that, binomial logistic regression first calculates the odds of the event happening for different levels of each independent variable, and then takes its logarithm to create a continuous criterion as a transformed version of the dependent variable.","b7cce8ae":"# Analysing data\n","b96d1bf3":"# Logistic Regression"}}