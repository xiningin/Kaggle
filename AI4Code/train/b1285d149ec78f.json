{"cell_type":{"57645a9b":"code","5921b0a5":"code","46ed4f01":"code","06d26d86":"code","18e57585":"code","a48e4767":"code","f8e3253e":"markdown"},"source":{"57645a9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndata = pd.read_csv('..\/input\/heart.csv')\n# Any results you write to the current directory are saved as output.","5921b0a5":"data.head()","46ed4f01":"data.target.value_counts()","06d26d86":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data,\n                              test_size = 0.2,\n                              random_state = 100)\ntrain_x = train.drop('target', axis=1)\ntrain_y = train['target']\n\ntest_x = test.drop('target', axis=1)\ntest_y = test['target']\n","18e57585":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","a48e4767":"models = [DecisionTreeClassifier(random_state=100), \n          RandomForestClassifier(random_state=100,n_estimators=300),\n          GradientBoostingClassifier(random_state=100, n_estimators=1000), \n          AdaBoostClassifier(random_state=100),\n          KNeighborsClassifier(n_neighbors=3)]\n\nfor i in models:\n    model = i\n    model.fit(train_x,train_y)\n    pred = model.predict(test_x)\n    acc_score = accuracy_score(pred, test_y)\n    print('The accuracy for',i,'is',acc_score*100)","f8e3253e":"# Random Forest is giving the Highest Accuracy"}}