{"cell_type":{"3831d23d":"code","10779eac":"code","c9cc19bf":"code","1e3ba874":"code","86db255d":"code","9dec7d5b":"code","9032749b":"code","c6f9a1a3":"code","ff8f18e5":"code","e5b2bfa8":"code","c7a0292c":"code","5c8cbf2e":"code","d51e5271":"code","6f5e7e44":"code","3ae48761":"code","12645abe":"code","bdd70c5d":"code","94d4cfe8":"code","2cde6a4a":"code","5e624f02":"code","60b9eb49":"code","f966c344":"code","4ec511e8":"code","ee8b4243":"code","1245180f":"code","fd48a7bc":"code","50936fdb":"code","ad8f8dbb":"code","8c612e39":"code","f0d5c046":"code","c56a3d46":"code","04e3f83c":"code","cf31fdb7":"code","a229c7ae":"code","414b2fbb":"code","98588475":"code","a622405f":"code","c870acb0":"code","b70ca8f4":"code","ecfc3041":"code","b3a129f9":"code","930269cf":"code","b9b0d9eb":"code","eb7d1b20":"code","10948be4":"code","80cf532c":"code","168bcfc4":"code","3ff23bd3":"code","ff47b409":"code","f62450e0":"code","27808f9d":"markdown","1bda9572":"markdown","482d00a4":"markdown","ef59c04c":"markdown","e3a48910":"markdown","23cc932c":"markdown","ad25a013":"markdown","763d1953":"markdown","5118dc03":"markdown","526aa70a":"markdown","a0390957":"markdown","fd206df5":"markdown","20f5b8f2":"markdown","e9f35154":"markdown","932b3bd4":"markdown","14d63eb3":"markdown","ae4f8b02":"markdown","5c045aff":"markdown","bc8b3c71":"markdown","597ab402":"markdown","921e7bee":"markdown"},"source":{"3831d23d":"import numpy as np\nimport pandas as pd\nimport os\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf \nfrom statsmodels.tsa.seasonal import seasonal_decompose \n#from pmdarima import auto_arima                        \nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tools.eval_measures import rmse\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","10779eac":"df = pd.read_csv('..\/input\/monthly-beer-production-in-austr.csv')","c9cc19bf":"df.head()","1e3ba874":"df.info()","86db255d":"df.Month = pd.to_datetime(df.Month)","9dec7d5b":"df = df.set_index(\"Month\")\ndf.head()","9032749b":"df.index.freq = 'MS'","c6f9a1a3":"plt.figure(figsize=(18,9))\nplt.plot(df.index, df[\"Monthly beer production\"], linestyle=\"-\")\nplt.xlabel=('Dates')\nplt.ylabel=('Total Production')\nplt.show();","ff8f18e5":"a = seasonal_decompose(df[\"Monthly beer production\"], model = \"add\")\na.plot();","e5b2bfa8":"import matplotlib.pyplot as plt\nplt.figure(figsize = (16,7))\na.seasonal.plot();","c7a0292c":"#auto_arima(df['Monthly beer production'], seasonal=True, m=12,max_p=7, max_d=5,max_q=7, max_P=4, max_D=4,max_Q=4).summary()","5c8cbf2e":"train_data = df[:len(df)-12]\ntest_data = df[len(df)-12:]","d51e5271":"arima_model = SARIMAX(train_data['Monthly beer production'], order = (2,1,1), seasonal_order = (4,0,3,12))\narima_result = arima_model.fit()\narima_result.summary()","6f5e7e44":"arima_pred = arima_result.predict(start = len(train_data), end = len(df)-1, typ=\"levels\").rename(\"ARIMA Predictions\")\narima_pred","3ae48761":"test_data['Monthly beer production'].plot(figsize = (16,5), legend=True)\narima_pred.plot(legend = True);","12645abe":"arima_rmse_error = rmse(test_data['Monthly beer production'], arima_pred)\narima_mse_error = arima_rmse_error**2\nmean_value = df['Monthly beer production'].mean()\n\nprint(f'MSE Error: {arima_mse_error}\\nRMSE Error: {arima_rmse_error}\\nMean: {mean_value}')","bdd70c5d":"test_data['ARIMA_Predictions'] = arima_pred","94d4cfe8":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","2cde6a4a":"scaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)","5e624f02":"from keras.preprocessing.sequence import TimeseriesGenerator\n\nn_input = 12\nn_features= 1\ngenerator = TimeseriesGenerator(scaled_train_data, scaled_train_data, length=n_input, batch_size=1)","60b9eb49":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\nlstm_model.add(Dense(1))\nlstm_model.compile(optimizer='adam', loss='mse')\n\nlstm_model.summary()","f966c344":"lstm_model.fit_generator(generator,epochs=20)","4ec511e8":"losses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize=(12,4))\nplt.xticks(np.arange(0,21,1))\nplt.plot(range(len(losses_lstm)),losses_lstm);","ee8b4243":"lstm_predictions_scaled = list()\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","1245180f":"lstm_predictions_scaled","fd48a7bc":"lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)","50936fdb":"lstm_predictions","ad8f8dbb":"test_data['LSTM_Predictions'] = lstm_predictions","8c612e39":"test_data","f0d5c046":"test_data['Monthly beer production'].plot(figsize = (16,5), legend=True)\ntest_data['LSTM_Predictions'].plot(legend = True);","c56a3d46":"lstm_rmse_error = rmse(test_data['Monthly beer production'], test_data[\"LSTM_Predictions\"])\nlstm_mse_error = lstm_rmse_error**2\nmean_value = df['Monthly beer production'].mean()\n\nprint(f'MSE Error: {lstm_mse_error}\\nRMSE Error: {lstm_rmse_error}\\nMean: {mean_value}')","04e3f83c":"df.info()","cf31fdb7":"df_pr = df.copy()\ndf_pr = df.reset_index()","a229c7ae":"df_pr.columns = ['ds','y'] # To use prophet column names should be like that","414b2fbb":"train_data_pr = df_pr.iloc[:len(df)-12]\ntest_data_pr = df_pr.iloc[len(df)-12:]","98588475":"from fbprophet import Prophet","a622405f":"m = Prophet()\nm.fit(train_data_pr)\nfuture = m.make_future_dataframe(periods=12,freq='MS')\nprophet_pred = m.predict(future)","c870acb0":"prophet_pred.tail()","b70ca8f4":"prophet_pred = pd.DataFrame({\"Date\" : prophet_pred[-12:]['ds'], \"Pred\" : prophet_pred[-12:][\"yhat\"]})","ecfc3041":"prophet_pred = prophet_pred.set_index(\"Date\")","b3a129f9":"prophet_pred.index.freq = \"MS\"","930269cf":"prophet_pred","b9b0d9eb":"test_data[\"Prophet_Predictions\"] = prophet_pred['Pred'].values","eb7d1b20":"import seaborn as sns","10948be4":"plt.figure(figsize=(16,5))\nax = sns.lineplot(x= test_data.index, y=test_data[\"Monthly beer production\"])\nsns.lineplot(x=test_data.index, y = test_data[\"Prophet_Predictions\"]);","80cf532c":"prophet_rmse_error = rmse(test_data['Monthly beer production'], test_data[\"Prophet_Predictions\"])\nprophet_mse_error = prophet_rmse_error**2\nmean_value = df['Monthly beer production'].mean()\n\nprint(f'MSE Error: {prophet_mse_error}\\nRMSE Error: {prophet_rmse_error}\\nMean: {mean_value}')","168bcfc4":"rmse_errors = [arima_rmse_error, lstm_rmse_error, prophet_rmse_error]\nmse_errors = [arima_mse_error, lstm_mse_error, prophet_mse_error]\nerrors = pd.DataFrame({\"Models\" : [\"ARIMA\", \"LSTM\", \"Prophet\"],\"RMSE Errors\" : rmse_errors, \"MSE Errors\" : mse_errors})","3ff23bd3":"plt.figure(figsize=(16,9))\nplt.plot_date(test_data.index, test_data[\"Monthly beer production\"], linestyle=\"-\")\nplt.plot_date(test_data.index, test_data[\"ARIMA_Predictions\"], linestyle=\"-.\")\nplt.plot_date(test_data.index, test_data[\"LSTM_Predictions\"], linestyle=\"--\")\nplt.plot_date(test_data.index, test_data[\"Prophet_Predictions\"], linestyle=\":\")\nplt.legend()\nplt.show()","ff47b409":"print(f\"Mean: {test_data['Monthly beer production'].mean()}\")\nerrors","f62450e0":"test_data","27808f9d":"# Time Series Forecasting with Python (ARIMA, LSTM, Prophet)","1bda9572":"> Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n\n[Facebook's Prophet Web Page](https:\/\/facebook.github.io\/prophet\/)<br>\n[Forecasting at Scale](https:\/\/peerj.com\/preprints\/3190.pdf)\n","482d00a4":"## ARIMA Forecast","ef59c04c":"> LSTM stands for long short term memory. It is a model or architecture that extends the memory of recurrent neural networks. Typically, recurrent neural networks have \u2018short term memory\u2019 in that they use persistent previous information to be used in the current neural network. Essentially, the previous information is used in the present task. That means we do not have a list of all of the previous information available for the neural node.\n> LSTM introduces long-term memory into recurrent neural networks. It mitigates the vanishing gradient problem, which is where the neural network stops learning because the updates to the various weights within a given neural network become smaller and smaller. It does this by using a series of \u2018gates\u2019. These are contained in memory blocks which are connected through layers, like this:\n\n![](https:\/\/hub.packtpub.com\/wp-content\/uploads\/2018\/04\/LSTM-696x494.png)\n\n> LSTM work\nThere are three types of gates within a unit:\nInput Gate: Scales input to cell (write)\nOutput Gate: Scales output to cell (read)\nForget Gate: Scales old cell value (reset)\nEach gate is like a switch that controls the read\/write, thus incorporating the long-term memory function into the model.\n\nFor more detail:\n<br>\n[What is LSTM?](https:\/\/hub.packtpub.com\/what-is-lstm\/)\n<br>\n[What is LSTM? - Quora](https:\/\/www.quora.com\/What-is-LSTM)\n<br>\n[Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory)","e3a48910":"## Read Dataset","23cc932c":"As you know we scaled our data that's why we have to inverse it to see true predictions.","ad25a013":"When we look at plot we can sey there is a seasonality in data. That's why we will use SARIMA (Seasonal ARIMA) instead of ARIMA.\n\n> Seasonal ARIMA, is an extension of ARIMA that explicitly supports univariate time series data with a seasonal component.\n> It adds three new hyperparameters to specify the autoregression (AR), differencing (I) and moving average (MA) for the seasonal component of the series, as well as an additional parameter for the period of the seasonality.\n\n> There are four seasonal elements that are not part of ARIMA that must be configured; they are:<br>\n**P:** Seasonal autoregressive order.<br>\n**D:** Seasonal difference order.<br>\n**Q:** Seasonal moving average order.<br>\n**m:** The number of time steps for a single seasonal period.<br>","763d1953":"Let's split the data into train and test set","5118dc03":"First we'll scale our train and test data with MinMaxScaler","526aa70a":"## Prophet Forecast","a0390957":"As we can see best arima model chosen by auto_arima() is SARIMAX(2, 1, 1)x(4, 0, 3, 12)\n\n**For some reason \"pmdarima\" wasn't installed at Kaggle. Thats's why I couldn't use \"auto_arima()\" here. But you can see same output below where \"arima_model\" defined.**","fd206df5":"# FORECAST","20f5b8f2":"Don't forget they are just quick and basic predictions so you can improve these models with tuning and according to your data and business knowledge.\n\n<br>\n\nThanks!","e9f35154":"## LSTM Forecast","932b3bd4":"ARIMA is a model which is used for predicting future trends on a time series data. It is model that form of regression analysis. \n* **AR (Autoregression) :** Model that shows a changing variable that regresses on its own lagged\/prior values.\n* **I (Integrated) :**  Differencing of raw observations to allow for the time series to become stationary\n* **MA (Moving average) :** Dependency between an observation and a residual error from a moving average model\n\nFor ARIMA models, a standard notation would be ARIMA with p, d, and q, where integer values substitute for the parameters to indicate the type of ARIMA model used.\n\n* **p:** the number of lag observations in the model; also known as the lag order.\n* **d:** the number of times that the raw observations are differenced; also known as the degree of differencing.\n* **q:** the size of the moving average window; also known as the order of the moving average.\n\nFor more information about ARIMA you can check:\n<br>\n[What is ARIMA](https:\/\/www.quora.com\/What-is-ARIMA)\n<br>\n[Autoregressive Integrated Moving Average (ARIMA)](https:\/\/www.investopedia.com\/terms\/a\/autoregressive-integrated-moving-average-arima.asp)","14d63eb3":"Let's run auto_arima() function to get best p,d,q,P,D,Q values","ae4f8b02":"## Prophet","5c045aff":"## ARIMA (Autoregressive Integrated Moving Average)","bc8b3c71":"Before creating LSTM model we should create a Time Series Generator object.","597ab402":"## LSTM Neural Network","921e7bee":"In this article we will try to forecast a time series data basically. We'll build three different model with Python and inspect their results. Models we will use are ARIMA (Autoregressive Integrated Moving Average), LSTM (Long Short Term Memory Neural Network) and Facebook Prophet. Let's jump in and start with ARIMA."}}