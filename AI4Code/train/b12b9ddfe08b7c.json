{"cell_type":{"45dd5d6e":"code","608b2204":"code","7cca1d48":"code","4afe08ec":"code","7d9548d4":"code","216c18b6":"markdown"},"source":{"45dd5d6e":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv('..\/input\/44352\/training_solutions_rev1.csv')\n\ndf_train, df_test = train_test_split(df, test_size=.2)\ndf_train.shape, df_test.shape","608b2204":"from skimage.transform import resize\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\n          \n\nORIG_SHAPE = (424,424)\nCROP_SIZE = (256,256)\nIMG_SHAPE = (64,64)\n\ndef get_image(path, x1,y1, shape, crop_size):\n    x = plt.imread(path)\n    x = x[x1:x1+crop_size[0], y1:y1+crop_size[1]]\n    x = resize(x, shape)\n    x = x\/255.\n    return x\n    \ndef get_all_images(dataframe, shape=IMG_SHAPE, crop_size=CROP_SIZE):\n    x1 = (ORIG_SHAPE[0]-CROP_SIZE[0])\/\/2\n    y1 = (ORIG_SHAPE[1]-CROP_SIZE[1])\/\/2\n   \n    sel = dataframe.values\n    ids = sel[:,0].astype(int).astype(str)\n    y_batch = sel[:,1:]\n    x_batch = []\n    for i in tqdm(ids):\n        x = get_image('..\/input\/44352\/images_training_rev1\/'+i+'.jpg', x1,y1, shape=shape, crop_size=crop_size)\n        x_batch.append(x)\n    x_batch = np.array(x_batch)\n    return x_batch, y_batch\n        \nX_train, y_train = get_all_images(df_train)\nX_test, y_test = get_all_images(df_test)","7cca1d48":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D\nfrom keras import backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\nmodel = Sequential()\nmodel.add(Conv2D(512, (3, 3), input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\nmodel.add(Conv2D(256, (3, 3)))\n#model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Conv2D(128, (3, 3)))\n#model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Conv2D(128, (3, 3)))\n#model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(GlobalMaxPooling2D())\n\n\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(37))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adamax', metrics=[root_mean_squared_error])\nmodel.summary()","4afe08ec":"batch_size = 128\nmodel.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))","7d9548d4":"import os\nfrom tqdm import tqdm\n\ndef test_image_generator(ids, shape=IMG_SHAPE):\n    x1 = (ORIG_SHAPE[0]-CROP_SIZE[0])\/\/2\n    y1 = (ORIG_SHAPE[1]-CROP_SIZE[1])\/\/2\n    x_batch = []\n    for i in ids:\n        x = get_image('..\/input\/44352\/images_test_rev1\/'+i, x1, y1, shape=IMG_SHAPE, crop_size=CROP_SIZE)\n        x_batch.append(x)\n    x_batch = np.array(x_batch)\n    return x_batch\n\nval_files = os.listdir('..\/input\/44352\/images_test_rev1\/')\nval_predictions = []\nN_val = len(val_files)\nfor i in tqdm(np.arange(0, N_val, batch_size)):\n    if i+batch_size > N_val:\n        upper = N_val\n    else:\n        upper = i+batch_size\n    X = test_image_generator(val_files[i:upper])\n    y_pred = model.predict(X)\n    val_predictions.append(y_pred)\nval_predictions = np.array(val_predictions)\nY_pred = np.vstack(val_predictions)\nids = np.array([v.split('.')[0] for v in val_files]).reshape(len(val_files),1)\nsubmission_df = pd.DataFrame(np.hstack((ids, Y_pred)), columns=df.columns)\nsubmission_df = submission_df.sort_values(by=['GalaxyID'])\nsubmission_df.to_csv('sample_submission.csv', index=False)","216c18b6":"# Test Prediction Submission"}}