{"cell_type":{"671b713d":"code","3d6a101a":"code","0d7f268e":"code","d1dcb729":"code","aa66371b":"code","eef7e80b":"code","d2f1640a":"code","a545e92d":"code","f5c1f4f4":"code","cbd93cb6":"code","5a59c465":"code","e044aaf4":"code","d0115858":"code","ea5911a4":"code","2c6d4790":"code","810e7ffd":"code","0de69f0a":"code","f5ff718a":"code","c1be9840":"code","6a4604d4":"code","1cce731a":"code","8443f756":"code","bf349fc9":"code","5491cb96":"code","7e5a6254":"code","cd8b187c":"code","34510e54":"code","8352ff8f":"code","de8c0a05":"code","02adad53":"code","7c18c320":"code","90b22517":"markdown","0b9bf5d6":"markdown","01465e37":"markdown","1c4a7ea7":"markdown","bb21ad26":"markdown","d4587c87":"markdown","6b1df727":"markdown","f2ebef8d":"markdown","912121ac":"markdown","afba0232":"markdown","69f613ee":"markdown","feba8ce5":"markdown","8fe65f26":"markdown","bd2050a7":"markdown","d75cd042":"markdown","3785f463":"markdown","eebf9d45":"markdown","fbfb5f70":"markdown","9c6f0cdd":"markdown","f8deb756":"markdown","39b0e31c":"markdown","cf714f1b":"markdown","07dcbe34":"markdown","211f312d":"markdown","592a4dd1":"markdown","aed52d49":"markdown","e4567403":"markdown","3b674a0b":"markdown"},"source":{"671b713d":"import psycopg2\nimport sklearn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom itertools import cycle\nfrom sklearn import svm, datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\n\n# Python libraries\n# Classic,data manipulation and linear algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport squarify\n\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport lightgbm as lgbm\n\n# Stats\nimport scipy.stats as ss\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\n# Time\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') ","3d6a101a":"train = pd.read_csv('C:\\\\Users\\\\guillesantillan\\\\Desktop\\\\Train.csv', index_col='PassengerId')\ntest = pd.read_csv('C:\\\\Users\\\\guillesantillan\\\\Desktop\\\\Test.csv', index_col='PassengerId')","0d7f268e":"train.head(5)","d1dcb729":"# Creating variable Title\ntrain['Title'] = train['Name']\n# Cleaning name and extracting Title\nfor name_string in train['Name']:\n    train['Title'] = train['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","aa66371b":"# Creating variable Title\ntest['Title'] = test['Name']\n# Cleaning name and extracting Title\nfor name_string in test['Name']:\n    test['Title'] = test['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","eef7e80b":"# Replacing rare titles \nmapping = {'Mlle': 1,'Ms': 1,'Miss': 1,'Mr': 2,'Mme': 1,'Mrs': 1,'Major': 4,'Col': 4,'Dr' : 4,'Rev' : 4,'Capt': 4,'Other': 3,\n           'Jonkheer': 5,'Sir': 5,'Lady': 500,'Don': 5,'Countess': 5,'Dona': 500,'Royal': 5,'Master': 6}\ntrain.replace({'Title': mapping}, inplace=True)\ntitles = [1,2,3,4,5,6]","d2f1640a":"# Replacing rare titles \nmapping = {'Mlle': 1,'Ms': 1,'Miss': 1,'Mr': 2,'Mme': 1,'Mrs': 1,'Major': 4,'Col': 4,'Dr' : 4,'Rev' : 4,'Capt': 4,'Other': 3,\n           'Jonkheer': 5,'Sir': 5,'Lady': 500,'Don': 5,'Countess': 5,'Dona': 500,'Royal': 5,'Master': 6}\ntest.replace({'Title': mapping}, inplace=True)\ntitles = [1,2,3,4,5,6]","a545e92d":"train['Sexo*Edad'] = round(train.Sex*train.Age, 2)\ntrain['Sexo*Embarked'] = round(train.Sex*train.Embarked, 2)\ntrain['Edad*Embarked'] = round(train.Age*train.Embarked, 2)\ntrain['Fare*Embarked'] = round(train.Age*train.Fare, 2)\ntrain['Age*Parch'] = round(train.Age*train.Parch, 2)\ntrain['SibSp*Parch'] = round(train.SibSp*train.Parch, 2)\ntrain['Embarked*Parch'] = round(train.Embarked*train.Parch, 2)\ntrain['SibSp*Embarked'] = round(train.SibSp*train.Embarked, 2)\ntrain['SibSp*Age'] = round(train.SibSp*train.Age, 2)\ntrain['Title*Age'] = round(train.Title*train.Age, 2)\ntrain['Title*Sex'] = round(train.Title*train.Sex, 2)\ntrain['Title*Fare'] = round(train.Title*train.Fare, 2)\ntrain['Title*Pclass'] = round(train.Title*train.Pclass, 2)\ntrain['Title*Cabin'] = round(train.Title*train.Cabin, 2)\ntrain['Title*SibSp'] = round(train.Title*train.SibSp, 2)\ntrain['Title*Embarked'] = round(train.Title*train.Embarked, 2)\ntrain['Cabin*Fare'] = round(train.Cabin*train.Fare, 2)\n\ntrain['Fare*Embarked*Title*Pclass'] = round(train.Age*train.Fare*train.Title*train.Pclass, 2)\ntrain['Cabin*Fare*train*Embarked'] = round(train.Cabin*train.Fare*train.Title*train.Embarked, 2)\n\ntrain['Edad+Embarked'] = round(train.Age+train.Embarked, 2)\ntrain['Fare+Embarked'] = round(train.Age+train.Fare, 2)\ntrain['Age+Parch'] = round(train.Age+train.Parch, 2)\ntrain['SibSp+Parch'] = round(train.SibSp+train.Parch, 2)\ntrain['SibSp+Age'] = round(train.SibSp+train.Age, 2)\ntrain['Cabin+Fare'] = round(train.Cabin+train.Fare, 2)","f5c1f4f4":"test['Sexo*Edad'] = round(test.Sex*test.Age, 2)\ntest['Sexo*Embarked'] = round(test.Sex*test.Embarked, 2)\ntest['Edad*Embarked'] = round(test.Age*test.Embarked, 2)\ntest['Fare*Embarked'] = round(test.Age*test.Fare, 2)\ntest['Age*Parch'] = round(test.Age*test.Parch, 2)\ntest['SibSp*Parch'] = round(test.SibSp*test.Parch, 2)\ntest['Embarked*Parch'] = round(test.Embarked*test.Parch, 2)\ntest['SibSp*Embarked'] = round(test.SibSp*test.Embarked, 2)\ntest['SibSp*Age'] = round(test.SibSp*test.Age, 2)\ntest['Title*Age'] = round(test.Title*test.Age, 2)\ntest['Title*Sex'] = round(test.Title*test.Sex, 2)\ntest['Title*Sex'] = round(test.Title*test.Sex, 2)\ntest['Title*Fare'] = round(test.Title*test.Fare, 2)\ntest['Title*Pclass'] = round(test.Title*test.Pclass, 2)\ntest['Title*Cabin'] = round(test.Title*test.Cabin, 2)\ntest['Title*SibSp'] = round(test.Title*test.SibSp, 2)\ntest['Title*Embarked'] = round(test.Title*test.Embarked, 2)\ntest['Cabin*Fare'] = round(test.Cabin*test.Fare, 2)\n\ntest['Fare*Embarked*Title*Pclass'] = round(test.Age*test.Fare*test.Title*test.Pclass, 2)\ntest['Cabin*Fare*train*Embarked'] = round(test.Cabin*test.Fare*test.Title*test.Embarked, 2)\n\ntest['Edad+Embarked'] = round(test.Age+test.Embarked, 2)\ntest['Fare+Embarked'] = round(test.Age+test.Fare, 2)\ntest['Age+Parch'] = round(test.Age+test.Parch, 2)\ntest['SibSp+Parch'] = round(test.SibSp+test.Parch, 2)\ntest['SibSp+Age'] = round(test.SibSp+test.Age, 2)\ntest['Cabin+Fare'] = round(test.Cabin+test.Fare, 2)","cbd93cb6":"# Plotting age vs sex vs target\ng = sns.FacetGrid(train, col=\"Sex\", hue=\"Survived\", palette=\"Set1\")\ng.map(sns.distplot, \"Age\")\ng = g.add_legend()\ng.fig.suptitle('Age vs Sex vs Survived', fontsize=16)\ng.fig.set_size_inches(15,8)","5a59c465":"# Plotting title vs age vs sex\ng = sns.FacetGrid(train, col=\"Title\", hue=\"Survived\")\ng.map(sns.distplot, \"Age\")\ng = g.add_legend()\ng.set(ylim=(0, 0.1))\ng.fig.suptitle('Title vs Age', fontsize=16)\ng.fig.set_size_inches(15,8)","e044aaf4":"# Defining missing plot to detect all missing values in dataset\ndef missing_plot(dataset, key) :\n    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])\n    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))\/len(dataset[key])*100, columns = ['Count'])\n    percentage_null = percentage_null.round(2)\n\n    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',\n            line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  \"Missing Values (count & %)\")\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","d0115858":"# Plotting \nmissing_plot(test, 'Age')","ea5911a4":"y = train.Survived","2c6d4790":"features = train.columns.values.tolist()\nfeatures.remove('Name')\nfeatures.remove('Survived')\n\nX = train[features].copy()\nX_test = test[features].copy()","810e7ffd":"# Train_test split\nrandom_state = 0\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.001, random_state = random_state)","0de69f0a":"y_train.mean()","f5ff718a":"plt.hist(y_train)\nplt.show()","c1be9840":"Results = pd.DataFrame({'Model': [],'Accuracy Score': []})","6a4604d4":"model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\nmodel_2 = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\nmodel_4 = RandomForestRegressor(n_estimators=666, min_samples_split=20, random_state=0)\nmodel_5 = DecisionTreeClassifier(max_depth=4)\nmodel_6 = RandomForestClassifier(n_estimators=2500, max_depth=4)\nmodel_7 = LogisticRegression()\nmodel_8 = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n                                max_depth=4, min_child_weight=0,\n                                gamma=0, subsample=0.7,\n                                colsample_bytree=0.7,\n                                scale_pos_weight=1, seed=27,\n                                reg_alpha=0.00006)","1cce731a":"models = {'decission_tree': model_5,\n          'random_forest_class': model_6,\n          'xgboost': model_8}","8443f756":"for model_name, model in models.items():\n    model.fit(X, y)\n    y_pred = model.predict(X_valid)\n    res = pd.DataFrame({\"Model\":[model_name], \"Accuracy Score\": [accuracy_score(y_pred,y_valid)]})\n    Results = Results.append(res)","bf349fc9":"Results","5491cb96":"modelo = model_8","7e5a6254":"plt.figure(figsize=(15,5))\nfeature_names_x, feature_names_ranks = zip(*sorted(zip(features, modelo.feature_importances_), key=lambda x: x[-1]))\nplt.barh(feature_names_x, feature_names_ranks, )\nplt.show()","cd8b187c":"plt.hist(modelo.predict(X_test))\nplt.show()","34510e54":"total = 0\ncount = 0\nfor i in modelo.predict(X_valid):\n    if i == np.asarray(y_valid)[total]:\n        count = count + 1\n    total = total + 1","8352ff8f":"round(count\/total, 4)","de8c0a05":"preds_test = modelo.predict(X_test)","02adad53":"output = pd.DataFrame({'PassengerId': X_test.index, 'Survived': preds_test})\noutput.to_csv('submission.csv', index=False)","7c18c320":"output.head()","90b22517":"\n---\n\n> # <a id='1'>1. Set Up","0b9bf5d6":"* **Analizo cuanto le pegue a la validacion**","01465e37":"> # <a id='3'>3. Machine Learning<\/a> ","1c4a7ea7":"## <a id='3.3'>3.3. Evaluaci\u00f3n de resultados<\/a>","bb21ad26":"## <a id='3.2'>3.2. Aprendizaje<\/a> ","d4587c87":"## <a id='2.1'>2.1. Comparo variables<\/a> ","6b1df727":"*  **Entreno todos los modelos al mismo tiempo**","f2ebef8d":"* **Selecciono un modelo**","912121ac":"* **Creo otras columnas**","afba0232":"* **Creo la columna Title**","69f613ee":"* **La acomodo**","feba8ce5":"> # <a id='2'>2. Analizo el Dataset<\/a> ","8fe65f26":"* **Genero las predicciones en base al dataset que todavia no utilice**","bd2050a7":"* **Analizo si mis predicciones son parecidas a el set de entrenamiento**","d75cd042":"* **Veo las predicciones que genero**","3785f463":"* **Guardo las predicciones en el formato utilizado para la puntuaci\u00f3n de la competencia**","eebf9d45":"## <a id='3.4'>3.4. Predicciones<\/a>","fbfb5f70":"* **Declaraciones de los Algoritmos**","9c6f0cdd":"## <a id='1.2'>1.2. Tomo los csv's<\/a> ","f8deb756":"## <a id='1.3'>1.3. Genero nuevas columnas<\/a>","39b0e31c":"## <a id='3.1'>3.1. Defino (X, y)<\/a> ","cf714f1b":"* **Analizo la importancia de los Features**","07dcbe34":"* **Probabilidad en train**","211f312d":"- <a href='#1'>1. Importando librerias y leyendo el dataset<\/a>  \n    - <a href='#1.1'>1.1. Importando librerias<\/a> \n    - <a href='#1.2'>1.2. Leyendo el Dataset<\/a> \n    - <a href='#1.2'>1.3. Genero nuevas columnas<\/a> \n    \n- <a href='#2'>2. Analizo el Dataset<\/a>  \n    - <a href='#2.1'>2.1. Comparo variables<\/a>\n    \n- <a href='#3'>3. Machine Learning<\/a>  \n    - <a href='#3.1'>3.1. Defino (X, y)<\/a>\n    - <a href='#3.2'>3.2. Aprendizaje<\/a>\n    - <a href='#3.3'>3.3. Evaluaci\u00f3n de resultados<\/a>\n    - <a href='#3.4'>3.4. Predicciones<\/a>\n    \n    \n    \n    \n    ","592a4dd1":"---\n\n> # Mis primeros algoritmos de Machine Learning\n\n---","aed52d49":"## <a id='1.1'>1.1. Importando las Librerias<\/a> ","e4567403":"* **Separo el conjunto de validaci\u00f3n de los datos de entrenamiento**","3b674a0b":"# Indice"}}