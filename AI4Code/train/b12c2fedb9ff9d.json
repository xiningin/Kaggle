{"cell_type":{"4d68329c":"code","dec3d548":"code","8ebf6eac":"code","eb00f2be":"code","9e07cf1d":"code","0b00dc28":"code","9c461610":"code","c8e83e4b":"code","48f26e04":"code","8437da3b":"code","b596106d":"code","f5b32292":"code","5ed2e8f7":"code","42066569":"code","00e26ac2":"code","5fe89263":"code","f8d55d68":"code","4d1de2a7":"code","e99ae1e3":"code","64206c73":"code","58260456":"code","e8de9e29":"code","51da817d":"code","8f2b9cd1":"code","61a05d8b":"code","6237128a":"code","3c92dde6":"code","844e0f02":"code","40a02b5c":"code","eb6514d2":"code","9c65612c":"code","731baa73":"code","b68be3a4":"code","3ca383c0":"code","27a76044":"code","63e40aae":"code","75e57a3d":"code","3d5f3873":"code","7ed4aadd":"code","1589f0e9":"markdown","788f30a3":"markdown","2eb8d5d0":"markdown","6a32e586":"markdown","a69fd9ee":"markdown","d71b12f8":"markdown","cceeebc3":"markdown","29edec05":"markdown","17c98301":"markdown","e7613cfa":"markdown","ff302db9":"markdown","5ab323b5":"markdown","53d14707":"markdown","f0da9dfb":"markdown","5e757ff3":"markdown","62fd0257":"markdown","8afb2406":"markdown","88895818":"markdown","db49d04b":"markdown","f5e46b1c":"markdown","0f37702b":"markdown","68560091":"markdown","84ca2d02":"markdown","668dc5ca":"markdown","75d3d402":"markdown","847a4f8f":"markdown","9a405fc5":"markdown","76183a41":"markdown","4c321e74":"markdown"},"source":{"4d68329c":"import numpy as np \nimport pandas as pd \nimport folium\nfrom folium import plugins\nfrom io import StringIO\nimport geopandas as gpd\nfrom pprint import pprint \nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nfrom plotly import tools\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os \ninit_notebook_mode(connected=True)","dec3d548":"depts = [f for f in os.listdir(\"..\/input\/cpe-data\/\") if f.startswith(\"Dept\")]\npprint(depts)","8ebf6eac":"files = os.listdir(\"..\/input\/cpe-data\/Dept_23-00089\/23-00089_ACS_data\/\")\nfiles","eb00f2be":"basepath = \"..\/input\/cpe-data\/Dept_23-00089\/23-00089_ACS_data\/23-00089_ACS_race-sex-age\/\"\nrca_df = pd.read_csv(basepath + \"ACS_15_5YR_DP05_with_ann.csv\")\nrca_df.head()","9e07cf1d":"a_df = pd.read_csv(basepath + \"ACS_15_5YR_DP05_metadata.csv\")\n\n# for j, y in a_df.iterrows():\n#     if y['Id'].startswith(\"Estimate\"):\n#         print (y['GEO.id'], y['Id'])\n\na_df.head()","0b00dc28":"total_population = rca_df[\"HC01_VC03\"][1:]\n\ntrace = go.Histogram(x=total_population, marker=dict(color='orange', opacity=0.6))\nlayout = dict(title=\"Total Population Distribution - Across the counties\", margin=dict(l=200), width=800, height=400)\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n\nmale_pop = rca_df[\"HC01_VC04\"][1:]\nfemale_pop = rca_df[\"HC01_VC05\"][1:]\n\ntrace1 = go.Histogram(x=male_pop, name=\"male population\", marker=dict(color='blue', opacity=0.6))\ntrace2 = go.Histogram(x=female_pop, name=\"female population\", marker=dict(color='pink', opacity=0.6))\nlayout = dict(title=\"Population Distribution Breakdown - Across the Census Tracts\", margin=dict(l=200), width=800, height=400)\ndata = [trace1, trace2]\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","9c461610":"age_cols = []\nnames = []\nfor i in range(13):\n    if i < 2:\n        i = \"0\"+str(i+8)\n        relcol = \"HC01_VC\" + str(i)\n    else:\n        relcol = \"HC01_VC\" + str(i+8)\n    age_cols.append(relcol)\n    name = a_df[a_df[\"GEO.id\"] == relcol][\"Id\"].iloc(0)[0].replace(\"Estimate; SEX AND AGE - \",\"\")\n    names.append(name)\n\nrca_df['GEO.display-label_cln'] = rca_df[\"GEO.display-label\"].apply(lambda x : x.replace(\", Marion County, Indiana\", \"\").replace(\"Census Tract \", \"CT: \"))\n\ntraces = []\nfor i,agecol in enumerate(age_cols):\n    x = rca_df[\"GEO.display-label_cln\"][1:]\n    y = rca_df[agecol][1:]\n    trace = go.Bar(y=y, x=x, name=names[i])\n    traces.append(trace)\n\ntmp = pd.DataFrame()\nvals = []\nGeo = []\nCol = []\nfor i,age_col in enumerate(age_cols):\n    Geo += list(rca_df[\"GEO.display-label_cln\"][1:].values)\n    Col += list([names[i]]*len(rca_df[1:]))\n    vals += list(rca_df[age_col][1:].values)\n\ntmp['Geo'] = Geo\ntmp['Col'] = Col\ntmp['Val'] = vals\ntmp['Val'] = tmp['Val'].astype(int)  * 0.01\n\ndata = [go.Scatter(x = tmp[\"Geo\"], y = tmp[\"Col\"], mode=\"markers\", marker=dict(size=list(tmp[\"Val\"].values)))]\nlayout = dict(title=\"Age Distribution by Census Tract - Marion County, Indiana\", legend=dict(x=-0.1, y=1, orientation=\"h\"), \n              margin=dict(l=150, b=100), height=600, barmode=\"stack\")\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","c8e83e4b":"trace1 = go.Histogram(x = rca_df[\"HC01_VC26\"][1:], name=\"18+\", marker=dict(opacity=0.4)) \ntrace2 = go.Histogram(x = rca_df[\"HC01_VC27\"][1:], name=\"21+\", marker=dict(opacity=0.3)) \ntrace3 = go.Histogram(x = rca_df[\"HC01_VC28\"][1:], name=\"62+\", marker=dict(opacity=0.4)) \ntrace4 = go.Histogram(x = rca_df[\"HC01_VC29\"][1:], name=\"65+\", marker=dict(opacity=0.3)) \n\ntitles = [\"Age : 18+\",\"Age : 21+\",\"Age : 62+\",\"Age : 65+\",]\nfig = tools.make_subplots(rows=2, cols=2, print_grid=False, subplot_titles=titles)\nfig.append_trace(trace1, 1, 1);\nfig.append_trace(trace2, 1, 2);\nfig.append_trace(trace3, 2, 1);\nfig.append_trace(trace4, 2, 2);\nfig['layout'].update(height=600, title=\"Distribution of Age across the Census Tracts\", showlegend=False);\niplot(fig, filename='simple-subplot');","48f26e04":"single_race_df = rca_df[[\"HC01_VC49\", \"HC01_VC50\", \"HC01_VC51\", \"HC01_VC56\", \"HC01_VC64\", \"HC01_VC69\"]][1:]\nops = [1, 0.85, 0.75, 0.65, 0.55, 0.45]\ntraces = []\nfor i, col in enumerate(single_race_df.columns):\n    nm = a_df[a_df[\"GEO.id\"] == col][\"Id\"].iloc(0)[0].replace(\"Estimate; RACE - One race - \", \"\")\n    trace = go.Bar(x=rca_df[\"GEO.display-label_cln\"][1:], y=single_race_df[col], name=nm, marker=dict(opacity=0.6))\n    traces.append(trace)\nlayout = dict(barmode=\"stack\", title=\"Population Breakdown by Race (Single)\", margin=dict(b=100), height=600, legend=dict(x=-0.1, y=1, orientation=\"h\"))\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","8437da3b":"traces = []\nfor i, col in enumerate(single_race_df.columns):\n    nm = a_df[a_df[\"GEO.id\"] == col][\"Id\"].iloc(0)[0].replace(\"Estimate; RACE - One race - \", \"\")\n    if nm in [\"White\", \"Black or African American\"]:\n        continue\n    trace = go.Bar(x=rca_df[\"GEO.display-label_cln\"][1:], y=single_race_df[col], name=nm, marker=dict(opacity=0.6))\n    traces.append(trace)\nlayout = dict(barmode=\"stack\", title=\"Population Breakdown by Race (Single)\", margin=dict(b=100), height=400, legend=dict(x=-0.1, y=1, orientation=\"h\"))\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","b596106d":"basepath2 = \"..\/input\/cpe-data\/Dept_23-00089\/23-00089_ACS_data\/23-00089_ACS_poverty\/\"\na_df = pd.read_csv(basepath2 + \"ACS_15_5YR_S1701_metadata.csv\")\n# for j, y in a_df.iterrows():\n#     if \"Below poverty level; Estimate\" in y['Id']:\n#         print (y['GEO.id'], y['Id'])        \n        \na_df.T.head()","f5b32292":"pov_df = pd.read_csv(basepath2 + \"ACS_15_5YR_S1701_with_ann.csv\")[1:]\npov_df.head()\n\n# pov_df[[\"HC02_EST_VC66\", \"\"]]\n# pov_df[\"HC02_EST_VC01\"] = pov_df[\"HC02_EST_VC01\"].astype(float)\n# pov_df.sort_values(\"HC02_EST_VC01\", ascending = False)[\"HC02_EST_VC01\"]","5ed2e8f7":"age_bp = [\"HC02_EST_VC04\", \"HC02_EST_VC05\", \"HC02_EST_VC08\", \"HC02_EST_VC09\", \"HC02_EST_VC11\"]\npov_df[age_bp]\n\npov_df['GEO.display-label_cln'] = pov_df[\"GEO.display-label\"].apply(lambda x : x.replace(\", Marion County, Indiana\", \"\").replace(\"Census Tract \", \"CT: \"))\n\nnames = [\"Below 5\", \"5-17\", \"18-34\", \"34-64\", \"65+\"]\n\nvals = []\nGeo = []\nCol = []\ntmp = pd.DataFrame()\nfor i,age_col in enumerate(age_bp):\n    Geo += list(pov_df[\"GEO.display-label_cln\"][1:].values)\n    Col += list([names[i]]*len(pov_df[1:]))\n    vals += list(pov_df[age_col][1:].values)\n\ntmp['Geo'] = Geo\ntmp['Col'] = Col\ntmp['Val'] = vals\ntmp['Val'] = tmp['Val'].astype(int)  * 0.025\n\ngeos = tmp.groupby(\"Geo\").agg({\"Val\" : \"sum\"}).sort_values(\"Val\", ascending = False)[:75].reset_index()['Geo']\ntmp1 = tmp[tmp[\"Geo\"].isin(geos)]\ndata = [go.Scatter(x = tmp1[\"Geo\"], y = tmp1[\"Col\"], mode=\"markers\", marker=dict(color=\"red\", size=list(tmp1[\"Val\"].values)))]\nlayout = dict(title=\"Age Distribution by Census Tract - Marion County, Indiana\", legend=dict(x=-0.1, y=1, orientation=\"h\"), \n              margin=dict(l=150, b=100), height=600, barmode=\"stack\")\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","42066569":"basepath = \"..\/input\/cpe-data\/Dept_23-00089\/23-00089_ACS_data\/23-00089_ACS_owner-occupied-housing\/\"\na_df = pd.read_csv(basepath + \"ACS_15_5YR_S2502_metadata.csv\")\n# for i,val in a_df.iterrows():\n#     if \"Estimate\" in val['Id']:\n#         if \"Owner-occupied\" in val[\"Id\"]:\n#             print (val['GEO.id'], val[\"Id\"])\na_df.T.head()    ","00e26ac2":"basepath = \"..\/input\/cpe-data\/Dept_23-00089\/23-00089_ACS_data\/23-00089_ACS_education-attainment\/\"\na_df = pd.read_csv(basepath + \"ACS_15_5YR_S1501_metadata.csv\")\na_df.T.head()","5fe89263":"a_df = pd.read_csv(basepath + \"ACS_15_5YR_S1501_with_ann.csv\")\na_df.head()","f8d55d68":"path = \"..\/input\/cpe-data\/Dept_35-00103\/35-00103_UOF-OIS-P_prepped.csv\"\nincidents = pd.read_csv(path)\nincidents.head()","4d1de2a7":"incidents[\"SUBJECT_INJURY_TYPE\"].value_counts()","e99ae1e3":"incidents.shape[0]","64206c73":"kmap = folium.Map([35.22, -80.89], height=400, zoom_start=10, tiles='CartoDB dark_matter')\nfor j, rown in incidents[1:].iterrows():\n    if str(rown[\"LOCATION_LONGITUDE\"]) != \"nan\":\n        lon = float(rown[\"LOCATION_LATITUDE\"])\n        lat = float(rown[\"LOCATION_LONGITUDE\"])\n        folium.CircleMarker([lon, lat], radius=5, color='red', fill=True).add_to(kmap)\nkmap","58260456":"imap = folium.Map([35.22, -80.89], height=400, zoom_start=10, tiles='CartoDB positron')\nfor j, rown in incidents[1:].iterrows():\n    if str(rown[\"LOCATION_LONGITUDE\"]) != \"nan\":\n        lon = float(rown[\"LOCATION_LATITUDE\"])\n        lat = float(rown[\"LOCATION_LONGITUDE\"])\n        \n        if rown[\"SUBJECT_RACE\"] == \"Black\":\n            col = \"black\"\n        elif rown[\"SUBJECT_RACE\"]== \"White\":\n            col = \"green\"\n        elif rown[\"SUBJECT_RACE\"]== \"Hispanic\":\n            col = \"yellow\"\n        else:\n            col = \"red\"\n                \n        folium.CircleMarker([lon, lat], radius=5, color=col, fill=True).add_to(imap)    \nimap","e8de9e29":"imap = folium.Map([35.22, -80.89], height=400, zoom_start=10, tiles='CartoDB positron')\nfor j, rown in incidents[1:].iterrows():\n    if str(rown[\"LOCATION_LONGITUDE\"]) != \"nan\":\n        lon = float(rown[\"LOCATION_LATITUDE\"])\n        lat = float(rown[\"LOCATION_LONGITUDE\"])\n        \n        if rown[\"SUBJECT_GENDER\"] == \"Male\":\n            col = \"blue\"\n        else:\n            col = \"red\"\n                \n        folium.CircleMarker([lon, lat], radius=5, color=col, fill=True).add_to(imap)        \nimap","51da817d":"imap = folium.Map([35.22, -80.89], height=400, zoom_start=10, tiles='CartoDB positron')\nfor j, rown in incidents[1:].iterrows():\n    if str(rown[\"LOCATION_LONGITUDE\"]) != \"nan\":\n        lon = float(rown[\"LOCATION_LATITUDE\"])\n        lat = float(rown[\"LOCATION_LONGITUDE\"])\n        \n        if rown[\"SUBJECT_INJURY_TYPE\"] == \"Non-Fatal Injury\":\n            col = \"red\"\n        elif rown[\"SUBJECT_INJURY_TYPE\"] == \"Fatal Injury\":\n            col = \"green\"\n        else:\n            col = \"blue\"                \n        folium.CircleMarker([lon, lat], radius=5, color=col, fill=True).add_to(imap)        \nimap","8f2b9cd1":"p2 = \"\"\"..\/input\/cpe-data\/Dept_35-00103\/35-00103_Shapefiles\/CMPD_Police_Division_Offices.shp\"\"\"\nOne = gpd.read_file(p2) \nfor j, rown in One.iterrows():\n    lon = float(str(rown[\"geometry\"]).split()[1].replace(\"(\",\"\"))\n    lat = float(str(rown[\"geometry\"]).split()[2].replace(\")\",\"\"))\n    folium.CircleMarker([lat, lon], radius=5, color='blue', fill=True).add_to(kmap)\nkmap","61a05d8b":"p1 = \"\"\"..\/input\/cpe-data\/Dept_23-00089\/23-00089_Shapefiles\/Indianapolis_Police_Zones.shp\"\"\"\nOne = gpd.read_file(p1)  \nOne.head()","6237128a":"mapa = folium.Map([39.81, -86.26060805912148], height=400, zoom_start=10, tiles='CartoDB dark_matter',API_key='wrobstory.map-12345678')\nfolium.GeoJson(One).add_to(mapa)\nmapa ","3c92dde6":"f, ax = plt.subplots(1, figsize=(10, 8))\nOne.plot(column=\"DISTRICT\", ax=ax, cmap='Accent',legend=True);\nplt.title(\"Districts : Indianapolis Police Zones\")\nplt.show()","844e0f02":"f, ax = plt.subplots(1, figsize=(10, 8))\nOne.plot(column=\"JURISDCTN\", ax=ax, cmap='Accent', legend=True);\nplt.title(\"JuriDiction : Indianapolis Police Zones\")\nplt.show()","40a02b5c":"p3 = \"\"\"..\/input\/cpe-data\/Dept_11-00091\/11-00091_Shapefiles\/boston_police_districts_f55.shp\"\"\"\nOne = gpd.read_file(p3)  \nmapa = folium.Map([42.3, -71.0], height=400, zoom_start=10,  tiles='CartoDB dark_matter',API_key='wrobstory.map-12345678')\nfolium.GeoJson(One).add_to(mapa)\nmapa ","eb6514d2":"p4 = \"\"\"..\/input\/cpe-data\/Dept_37-00049\/37-00049_Shapefiles\/EPIC.shp\"\"\"\nOne = gpd.read_file(p4)  \nmapa = folium.Map([32.7, -96.7],zoom_start=10, height=400, tiles='CartoDB dark_matter',API_key='wrobstory.map-12345678')\nfolium.GeoJson(One).add_to(mapa)\nmapa ","9c65612c":"p5 = \"..\/input\/cpe-data\/Dept_37-00027\/37-00027_UOF-P_2014-2016_prepped.csv\"\ndept_37_27_df = pd.read_csv(p5)[1:]\ndept_37_27_df[\"INCIDENT_DATE\"] = pd.to_datetime(dept_37_27_df[\"INCIDENT_DATE\"]).astype(str)\ndept_37_27_df[\"MonthDate\"] = dept_37_27_df[\"INCIDENT_DATE\"].apply(lambda x : x.split(\"-\")[0] +'-'+ x.split(\"-\")[1] + \"-01\")\n\ntmp = dept_37_27_df.groupby(\"MonthDate\").agg({\"INCIDENT_REASON\" : \"count\"}).reset_index()\ntmp\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\n\ntrace1 = go.Scatter(x=tmp[\"MonthDate\"], y=tmp.INCIDENT_REASON, name=\"Month wise Incidents\")\n# trace2 = go.Scatter(x=tmp[\"MonthDate\"], y=tmp.INCIDENT_REASON)\n\ndata = [trace1]\nlayout = go.Layout(height=400, title=\"Incidents in Austin Texas\")\nfig = go.Figure(data, layout)\niplot(fig)","731baa73":"a = dept_37_27_df[\"SUBJECT_GENDER\"].value_counts()\ntr1 = go.Bar(x = a.index, y = a.values, name=\"Gender\")\n\na = dept_37_27_df[\"INCIDENT_REASON\"].value_counts()\ntr2 = go.Bar(x = a.index, y = a.values, name=\"INCIDENT_REASON\")\n\na = dept_37_27_df[\"SUBJECT_RACE\"].value_counts()\ntr3 = go.Bar(x = a.index, y = a.values, name=\"SUBJECT_RACE\")\n\n\nfig = tools.make_subplots(rows=1, cols=3, print_grid=False, subplot_titles=[\"Gender\", \"Incident Reason\", \"Subject Race\"])\nfig.append_trace(tr1, 1, 1);\nfig.append_trace(tr2, 1, 2);\nfig.append_trace(tr3, 1, 3);\nfig['layout'].update(height=400, title=\"Austin Incidents Distribution\", showlegend=False);\niplot(fig, filename='simple-subplot');","b68be3a4":"a = dept_37_27_df[\"REASON_FOR_FORCE\"].value_counts()[:6]\ntr1 = go.Bar(x = a.index, y = a.values, name=\"Gender\")\n\na = dept_37_27_df[\"TYPE_OF_FORCE_USED1\"].value_counts()[:8]\ntr2 = go.Bar(x = a.index, y = a.values, name=\"INCIDENT_REASON\")\n\nfig = tools.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles=[\"REASON_FOR_FORCE\", \"TYPE_OF_FORCE_USED1\"])\nfig.append_trace(tr1, 1, 1);\nfig.append_trace(tr2, 1, 2);\nfig['layout'].update(height=400, margin=dict(b=140), title=\"Austin Incidents Distribution\", showlegend=False);\niplot(fig, filename='simple-subplot');","3ca383c0":"p5 = \"..\/input\/cpe-data\/Dept_37-00027\/37-00027_Shapefiles\/APD_DIST.shp\"\ndept_37_27_shp = gpd.read_file(p5)\ndept_37_27_shp.head()","27a76044":"f, ax = plt.subplots(1, figsize=(10, 12))\ndept_37_27_shp.plot(column=\"SECTOR\", ax=ax, cmap='Accent',legend=True);\nplt.title(\"Sectors \")\nplt.show()","63e40aae":"f, ax = plt.subplots(1, figsize=(10, 12))\ndept_37_27_shp.plot(column=\"PATROL_ARE\", ax=ax, cmap='coolwarm',legend=True);\nplt.title(\"Patrol Areas \")\nplt.show()","75e57a3d":"from shapely.geometry import Point\n\n## remove na\nnotna = dept_37_27_df[['LOCATION_LATITUDE','LOCATION_LONGITUDE']].dropna().index\ndept_37_27_df = dept_37_27_df.iloc[notna].reset_index(drop=True)\ndept_37_27_df['coordinates'] = (dept_37_27_df.apply(lambda x: Point(float(x['LOCATION_LONGITUDE']), float(x['LOCATION_LATITUDE'])), axis=1))\ndept_37_27_gdf = gpd.GeoDataFrame(dept_37_27_df, geometry='coordinates')\n\n# ## make the corrdinate system same\ndept_37_27_gdf.crs = {'init' :'epsg:4326'}\ndept_37_27_shp.crs = {'init' :'esri:102739'}\ndept_37_27_shp = dept_37_27_shp.to_crs(epsg='4326')","3d5f3873":"## plot\nf, ax = plt.subplots(1, figsize=(10, 12))\ndept_37_27_shp.plot(ax=ax, column='PATROL_ARE', cmap = \"gray\", legend=True)\ndept_37_27_gdf.plot(ax=ax, marker='*', color='red', markersize=10)\nplt.title(\"Incident Locations and Patrol Areas \")\nplt.show()","7ed4aadd":"## plot\nf, ax = plt.subplots(1, figsize=(10, 12))\ndept_37_27_shp.plot(ax=ax, column='SECTOR', cmap = \"Oranges\", legend=True)\ndept_37_27_gdf.plot(ax=ax, marker='*', color='Black', markersize=10)\nplt.title(\"Incident Locations and Sectors \")\nplt.show()","1589f0e9":"### Bostan Police Districts","788f30a3":"The above plot gives a view about which age groups are located in which areas. Lets look at an other view of age group distributions. ","2eb8d5d0":"Lets explore other metrics of the same district\n\n### Dept_23-00089, Metric : Poverty\n","6a32e586":"The shape file is also given:","a69fd9ee":"### Dallas Districts","d71b12f8":"### About Dataset : Department Files\n\nThe dataset consists of different data files for different police deparments. Lets quickly look at those department names. ","cceeebc3":"We can see that majority wise White or Black American population exists. It will be interesting to look at which ones are the dominating other races. Lets remove white and black population and plot again","29edec05":"### Dept_23-00089, Metric : Owner Occupied Housing\n","17c98301":"### Department : Dept_23-00089 | Metric : Education\n","e7613cfa":"Lets plot the districts and juridiction realted with this shapefile data","ff302db9":"### Austin City \n\nLets plot the incidents of Austin, Tx","5ab323b5":"Similar files are shared for other departments as well. Lets look at an other department. \n\n### Department : Dept_35-00103\n\nLets explore the prepped file which contains information about the incidents that occured in that area","53d14707":"Lets try to map the multiple shape files \/ data together.  Taking the notes from @Chris [kernel](https:\/\/www.kaggle.com\/crawford\/another-world-famous-starter-kernel-by-chris) and @dsholes [kernel](https:\/\/www.kaggle.com\/dsholes\/confused-start-here), First we can create the GeoPandas dataframe from the normal dataframe, by converting the latlongs to POINTS. ","f0da9dfb":"Total Incidents reported : ","5e757ff3":"Let's plot the population distribution by different Race. First, lets consider only the single Race variables","62fd0257":"# <font color=\"#703bdb\">Part 0. Getting Familier with the Dataset - CPE <\/font> <hr>\n\n<a href=\"http:\/\/policingequity.org\/\">Center of Policing Equity<\/a> is a research and action think tank that works collaboratively with law enforcement, communities, and political stakeholders to identify ways to strengthen relationships with the communities they serve. CPE is also the home of the nation\u2019s first and largest <a href=\"http:\/\/policingequity.org\/national-justice-database\/\">database<\/a> tracking national statistics on police behavior. \n\nThe main aim of CPE is to bridge the divide created by communication problems, suffering and generational mistrust, and forge a path towards public safety, community trust, and racial equity. This kernel series is my contribution to the <a href=\"https:\/\/www.kaggle.com\/center-for-policing-equity\/data-science-for-good\">Data Science for Good: Center for Policing Equity<\/a>. The contribution is focused on providing a generic, robust, and automated approach to integrate, standardize the data and further diagnose disparities in policing, shed light on police behavior, and provide actionable recommendations. \n\n### <font color=\"#703bdb\">Main Submission: <\/font>\n\n<ul>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/1-solution-workflow-science-of-policing-equity\/\">Part 1: Solution Workflow - The Science of Policing Equity <\/a>  <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/2-automation-pipeline-integration-processing\">Part 2: Data Integration and Processing : Automation Pipeline<\/a>  <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/3-example-runs-of-automation-pipeline\">Part 3: Example Runs of Automation Pipeline <\/a>  <\/li> \n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-1-analysis-report-minneapolis-24-00013\">Part 4.1: Analysis Report - Measuring Equity - Minneapolis Police Department <\/a>   <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-2-analysis-report-lapd-49-00033\">Part 4.2: Analysis Report - Los Angles Police Department (49-00033) <\/a>   <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-3-analysis-report-officer-level-analysis\">Part 4.3: Analysis Report - Indianapolis Officer Level Analysis (23-00089) <\/a>   <\/li><\/ul>\n\nThe complete overview of the solution is shared in the *first kernel*. It explains the process and flow of automation, standardization, processing, and analysis of data. In the *second kernel*, the first component of the solution pipeline : data integration and processing is implemented. It processes both core level data as well as department level data. In the *third kernel*, this pipeline is executed and run for several departments. After all the standardized and clean data is produced, it is analysed with different formats of the Analysis Framework in 4.1, 4.2 and 4.3 kernels. In *kernel 4.1*, core analysis is done along with link with crime rate and poverty data. In *kernel 4.2*, core analysis is done along with statistical analysis. In *kernel 4.3*, officer level analysis is done. \n\n<hr>\n\n## About this Kernel : \n\nThis kernel is just a starter kernel that aims to provide understanding of the data and unearth the hidden insights from the data shared. First part is a quick exploration of the shared data and the next part is the complete GIS analysis. Lets Load the required libraries first. ","8afb2406":"### Location of Incidents ","88895818":"### About Dataset : Different Data Files for Police Departments\n\nAmong different departments, different files are shared corresponding to different data files, such as Education, Race, Poverty etc. Lets have a look","db49d04b":"\n### Indianapolis Police Zones\n\nLets plot the shape file and related data ","f5e46b1c":"Incidents by Race : Legend - \n\nBlack : Black Person   \nGreen : White Person  \nYellow : Hispanic  \nRed : All Others  \n","0f37702b":"Great, now we have understanding about what kinds of dataset we have.  I have now shared my complete solution : \n\n### <font color=\"#703bdb\">Main Submission: <\/font>\n\n<ul>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/1-solution-workflow-science-of-policing-equity\/\">Part 1: Solution Workflow - The Science of Policing Equity <\/a>  <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/2-automation-pipeline-integration-processing\">Part 2: Data Integration and Processing : Automation Pipeline<\/a>  <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/3-example-runs-of-automation-pipeline\">Part 3: Example Runs of Automation Pipeline <\/a>  <\/li> \n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-1-analysis-report-minneapolis-24-00013\">Part 4.1: Analysis Report - Measuring Equity - Minneapolis Police Department <\/a>   <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-2-analysis-report-lapd-49-00033\">Part 4.2: Analysis Report - Los Angles Police Department (49-00033) <\/a>   <\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/shivamb\/4-3-analysis-report-officer-level-analysis\">Part 4.3: Analysis Report - Indianapolis Officer Level Analysis (23-00089) <\/a>   <\/li><\/ul>\n","68560091":"The meanings of columns is given in an another file. Here is the description of all the columns used in the avove dataset. ","84ca2d02":"Lets plot these incidents by gender","668dc5ca":"Lets locate the location of Police Offices as well","75d3d402":"Plot incidents by patrol areas, sectors etc","847a4f8f":"Now, lets start exploring these data files. \n\n### Department : Dept_23-00089, Metric : Race, Sex, Age\n\nLets load the dataset","9a405fc5":"So about 50 census tracts have population around 3000 - 4000. One Census tract has very high population. Female gender percentage is higher in only two of the census tracts. \n\n### Distribution of Age Groups\n\nLets plot the census tract wise different agegroup's population count ","76183a41":"Only one incident involves female, rest all others were males. \n\nIncidents by Subject Injury Types","4c321e74":"So there are coluns about Estimate, Margin of Error, Percent related to Sex, Age, Race, and Total Population. Lets start exploring these variables. \n\n### Distribution of Total Population across Census Tracts\n\n<br>\n\n**Census Tracts:** \nCensus tracts (CTs) are small, relatively stable geographic areas that usually have a population between 2,500 and 8,000 persons. They are located in census metropolitan areas and in census agglomerations that had a core population of 50,000 or more in the previous census.\n\n"}}