{"cell_type":{"cdd4a3fe":"code","63fcee59":"code","cdd9332f":"code","d61fe768":"code","9fde3cad":"code","57972535":"code","b3112a6e":"code","fad2e074":"code","d73ddbb7":"code","5a1a7154":"code","bb4aea1c":"code","35f57b7b":"markdown","d09bbcfc":"markdown","0194416a":"markdown","39eaf76c":"markdown","67c4951e":"markdown","4dc2c8ee":"markdown","93f179e0":"markdown","094f213a":"markdown"},"source":{"cdd4a3fe":"!pip install snownlp\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom snownlp import SnowNLP\nimport jieba\nfrom gensim import corpora, models\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","63fcee59":"data={}\ndata['comment'] = pd.read_csv('\/kaggle\/input\/mengniutieba\/comment.csv',header=None)\ndata['post'] = pd.read_csv('\/kaggle\/input\/mengniutieba\/post.csv',header=None,usecols=list(range(7)))\n\npart1 = data['comment'][[2,3]]\npart1.columns = ['text','time']\npart2 = data['post'][[3,4]]\npart2.columns = ['text','time']\n\ntext = pd.concat((part1,part2),axis=0, ignore_index=True)\ndel part1,part2,data","cdd9332f":"import re\nreplace_url = lambda s : re.sub(r'http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',s)\nreplace_digit = lambda s : re.sub(r'[0-9a-zA-Z\\t\\n\ufffd]','',s)\n\ntext = text.drop_duplicates()\n\ntext = text.dropna()\n\ntext = text.sort_values(by='time')\ntext['time'] = text['time'].apply(lambda x:x[:7])\ntext = text.set_index('time').iloc[1:-2]\n\ntext['text'] = text['text'].apply(replace_url).apply(replace_digit)\ntext['len'] = text['text'].apply(lambda x:len(x))\ntext=text[text['len']>1]\nTXT = text\ndel text","d61fe768":"sentiment = TXT.iloc[:, 0].apply(lambda x: SnowNLP(x).sentiments)\nserise = sentiment.groupby('time').agg(np.mean)","9fde3cad":"import matplotlib.pyplot as plt\nimport seaborn as sns     #more beautiful more simple but lack plasticity with seaborn\n#seaborn depend on matplotlib\n\n%matplotlib inline \n%pylab inline\n\nplt.rcParams['font.sans-serif'] = ['SimHei'] #to show CH tag\nplt.rcParams['axes.unicode_minus'] = False # to show signal\npylab.rcParams['figure.figsize'] = (10, 6)   #set scale of img\nsns.set(color_codes=True) #seaborn set background\n\nserise.plot()","57972535":"from statsmodels.graphics.tsaplots import plot_acf  \nfrom statsmodels.tsa.stattools import adfuller as ADF \nfrom statsmodels.graphics.tsaplots import plot_pacf    \nfrom statsmodels.stats.diagnostic import acorr_ljungbox \nfrom statsmodels.tsa.arima_model import ARIMA\nplot_acf(serise).show()\nplot_pacf(serise).show()\nprint(u'ADF-test\uff1a', ADF(serise))\n# print(u'Ljung-Box-test\uff1a',acorr_ljungbox(serise) )\nmodel = ARIMA(serise, (1,0,1)).fit() #try model of ARIMA(1, 0, 1)\nmodel.summary2()","b3112a6e":"T_ser = pd.Series(TXT['text'])\njieba.enable_parallel(4)\ncut = lambda s: ' '.join(jieba.cut(s))\nT_cut = T_ser.apply(cut)","fad2e074":"stopword=[word.strip() for word in open(\"..\/input\/stopwordch\/stopwordCh.txt\",'r').readlines()]\nT_sep = T_cut.apply(lambda s: s.split(' ')).apply(lambda x: [i for i in x if i.encode('utf-8') not in stopword])","d73ddbb7":"w_lst = T_sep['2018-11':].to_list()\nwords=[]\nfor lst in w_lst:\n    words.extend(lst)\n    \nimport wordcloud\nw = wordcloud.WordCloud(font_path = '..\/input\/chinesefonts\/simkai.ttf')\nw.generate(' '.join(words))\n# s=' '.join(list(TXT['2018-11':]['text']))\n# w.generate(s)\nw.to_image()\n# w.to_file('output1.png')","5a1a7154":"import jieba.posseg as jp\nflags = ('n', 'nr', 'ns', 'nt', 'eng', 'v', 'd')#word type\nseg_word = lambda s : [w.word for w in jp.cut(s) if w.flag in flags and w.word not in stopword]\nText = pd.concat((T_ser,sentiment),axis=1)\nText.columns=['text','index']\nText['seg'] = Text['text'].apply(seg_word)\n# Text['index'>0.9]['text']","bb4aea1c":"def LDA(word_list):\n    words_ls=word_list\n    dictionary = corpora.Dictionary(words_ls)\n\n    corpus = [dictionary.doc2bow(words) for words in words_ls]\n\n    lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=2)\n    print('topics')\n    for topic in lda.print_topics(num_words=5):\n        print(topic)\n    return topic\n# positive part \n_ = LDA(Text[Text['index']>0.8]['seg'])\n# negtive part \n_ = LDA(Text[Text['index']<0.2]['seg'])","35f57b7b":"## Chinese Text Segmentation","d09bbcfc":"# Preprocess\n* Drop duplicates\n* Drop NA\n* Accurate by month\n* Drop nosense charactors\n* Drop single word","0194416a":"# Word Frequency Analysis","39eaf76c":"# Latent Dirichlet Allocation(LDA)","67c4951e":"## Time Serise Analysis\nwith sentiment data","4dc2c8ee":"# Sentiment Analysis\n\nUse package `snownlp`\n\nand try time serise analysis(TSA) model","93f179e0":"# Plot Words Cloud","094f213a":"# Read Data & Reshape"}}