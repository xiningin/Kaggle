{"cell_type":{"d9dcdde2":"code","26fe6fb0":"code","f0a1c11e":"code","024ea2ad":"code","c3281547":"code","300dd552":"code","8167c3ad":"code","67e0aa53":"markdown","845127d6":"markdown","88ef5b5f":"markdown","377aa8a7":"markdown","c69df22b":"markdown","e391dbc7":"markdown"},"source":{"d9dcdde2":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom pathlib import Path\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# List all fruit classes\ntraining_data_dir = Path(\"..\/input\/fruits-360_dataset\/fruits-360\/Training\")\ntest_data_dir = Path(\"..\/input\/fruits-360_dataset\/fruits-360\/Test\")\nfruit_classes = [str(d.name) for d in training_data_dir.iterdir()]\nprint(\"Fruit types: {}\".format(\", \".join(fruit_classes)))\nprint(\"Number of fruits: {}\".format(len(fruit_classes)))\n\n# Reading one example image to get the size of the data\nimage_path = training_data_dir \/ 'Cocos' \/ 'r_33_100.jpg'\ntest_img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\nprint(\"Image shape: {}\".format(test_img.shape))\n\n# Set up the ImageDataGenerator and read data using flow_from_directory\nselected_fruits = fruit_classes[0:4]\nbatch_size=128\nexample_generator = ImageDataGenerator(rescale=1.\/255).flow_from_directory(\n        str(training_data_dir),\n        classes=selected_fruits,\n        class_mode='categorical',\n        color_mode='rgb',\n        batch_size=batch_size,\n        target_size=test_img.shape[0:2])\n\n# Show a sample from the training data by extracting a batch\nbatch_data = next(example_generator)\nimages = batch_data[0]\nclasses = batch_data[1]\nprint(\"Batch images shape: {}\".format(images.shape))\nprint(\"Batch classes shape: {}\".format(classes.shape))\nindex = random.randint(0, batch_size-1)\nimage = images[index, :, :, :]\nclass_index = np.where(classes[index, :] == 1)[0][0]\nclass_str = selected_fruits[class_index]\nprint(\"Below fruit class: {}\".format(class_str))\nplt.imshow(image)","26fe6fb0":"import keras\n\n# Useful constants\nINPUT_SHAPE = test_img.shape\nTRAINING_DIR = training_data_dir\nTEST_DIR = test_data_dir\nFRUIT_CLASSES = fruit_classes\nEXAMPLES_PER_CLASS = 500 # This is an approximate number\nVALIDATION_RATIO = 0.25\nNUM_CLASSES = len(FRUIT_CLASSES)\n\nDEFAULT_DATAGEN_ARGS = dict(rescale=1.\/255)\n\ndef get_data_generators(data_gen_args=DEFAULT_DATAGEN_ARGS,\n                        selected_fruits=None,\n                        color_mode='rgb',\n                        target_size=INPUT_SHAPE[0:2],\n                        batch_size=32):\n    training_generator = ImageDataGenerator(**data_gen_args).flow_from_directory(\n        str(TRAINING_DIR),\n        classes=selected_fruits,\n        class_mode='categorical',\n        color_mode=color_mode,\n        batch_size=batch_size,\n        target_size=target_size)\n    # No augmentation applied for the validation data\n    validation_generator = ImageDataGenerator(**DEFAULT_DATAGEN_ARGS).flow_from_directory(\n        str(TEST_DIR),\n        classes=selected_fruits,\n        class_mode='categorical',\n        color_mode=color_mode,\n        batch_size=batch_size,\n        target_size=target_size)\n    return training_generator, validation_generator\n\n\ndef plot_history(history):\n    # Plot training and validation accuracy values\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    # Plot training and validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\ndef train_fruit_classifier(model, data_gen_args=DEFAULT_DATAGEN_ARGS, epochs=10, batch_size=128, selected_fruits=FRUIT_CLASSES):\n    num_fruits = len(selected_fruits)\n\n    # Approximately the size of the training set\n    steps_per_epoch = (EXAMPLES_PER_CLASS * num_fruits) \/\/ batch_size\n\n    train_generator, val_generator = get_data_generators(\n        data_gen_args=data_gen_args, selected_fruits=selected_fruits, batch_size=batch_size)\n\n    training_history = model.fit_generator(\n            train_generator,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_generator,\n            validation_steps=int(steps_per_epoch * VALIDATION_RATIO),\n            epochs=epochs)\n\n    return training_history\n","f0a1c11e":"# Define a simple model\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import Conv2D\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import MaxPooling2D\n\ndef create_simple_model(num_classes=NUM_CLASSES):\n    model = Sequential()\n\n    # Convolutional\/downsampling layers\n    model.add(Conv2D(32, (3, 3), padding='same', input_shape=INPUT_SHAPE))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))  # Output shape (50, 50, 32)\n\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))  # Output shape (25, 25, 32)\n\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))  # Output shape (12, 12, 64)\n\n    # Flatten data to be able to apply dense layers\n    model.add(Flatten()) # Output size = 12 * 12 * 64 = 9216\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model\n","024ea2ad":"# Select some fruits\nnum_fruits = 4\nselected_fruits = FRUIT_CLASSES[0:num_fruits]\nprint(\"Selected fruits: {}\".format(\", \".join(selected_fruits)))\n\n# Create the model\nmodel = create_simple_model(num_fruits)\nmodel.compile(optimizer='adam',\n              loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\nmodel.summary()\n\n# Train\ntraining_history = train_fruit_classifier(\n    model, epochs=10, batch_size=128, selected_fruits=selected_fruits)\n\n# Display result\nplot_history(training_history)\n\nmodel.save_weights('simple_model_v1_fruits_4.h5')","c3281547":"# Use all fruit classes (default)\nmodel = create_simple_model()\nmodel.compile(optimizer='adam',\n              loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\nmodel.summary()\n\n# Train\ntraining_history = train_fruit_classifier(model, epochs=20, batch_size=128)\n\n# Display results\nplot_history(training_history)\n\nmodel.save_weights('simple_model_v1_fruits_95.h5')","300dd552":"from keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Conv2D\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import MaxPooling2D\n\n\ndef add_relu_bottleneck_layer(model, num_filters, filter_size, \n                              dropout_rate=0.0, use_batch_norm=False, first_layer=True):\n    if first_layer:\n        model.add(Conv2D(num_filters, (filter_size, filter_size), padding='same', input_shape=INPUT_SHAPE))\n    else:\n        model.add(Conv2D(num_filters, (filter_size, filter_size), padding='same'))\n    if use_batch_norm:\n        model.add(BatchNormalization())\n    model.add(Activation('relu')) # Uncertain if this should be before or after batch norm\n    if dropout_rate > 0.0:\n        model.add(Dropout(dropout_rate))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n\ndef create_extended_model(num_classes=NUM_CLASSES,\n                          fc_units=128,\n                          use_batch_norm=False,\n                          conv_dropout_rate=0.0,\n                          fc_dropout_rate=0.5):\n    model = Sequential()\n\n    # Bottleneck layers\n    add_relu_bottleneck_layer(model, 32, 3, dropout_rate=conv_dropout_rate, use_batch_norm=use_batch_norm,\n                              first_layer=True)\n    add_relu_bottleneck_layer(model, 64, 3, dropout_rate=conv_dropout_rate, use_batch_norm=use_batch_norm)\n    add_relu_bottleneck_layer(model, 64, 3, dropout_rate=conv_dropout_rate, use_batch_norm=use_batch_norm)\n\n    # Flatten data to be able to apply dense layers\n    model.add(Flatten())\n    model.add(Dense(fc_units))\n    if use_batch_norm:\n        model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(fc_dropout_rate))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model\n","8167c3ad":"# Train extended model\n# Use batch normalization and dropout on convolutional layers\nmodel = create_extended_model(num_classes=NUM_CLASSES,\n                              fc_units=128,\n                              use_batch_norm=True,\n                              conv_dropout_rate=0.2,\n                              fc_dropout_rate=0.5)\nmodel.compile(optimizer='adam',\n              loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\nmodel.summary()\n\n# Train\ntraining_history = train_fruit_classifier(model, epochs=20, batch_size=128)\n\n# Display results\nplot_history(training_history)\n\nmodel.save_weights('extended_model_v1_fruits_95.h5')","67e0aa53":"# Utility functions\nHave do be defined here so they can be used below.","845127d6":"# More fruits\nThe model easily achieves (near) perfect accuracy only after a few epochs. Let's try with more classes.\nA curious result is that the validation set achieves better performance than the training set. This is likely due to the high dropout rate in the fully connected layer since this introduces noise during training but not during validation.","88ef5b5f":"# Defining a model\nDefine some simple model. Inspiration came from here, only changing from binary classification to categorical:\n\nhttps:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html\n","377aa8a7":"# Train the model\nTry training on only four types of fruit for simplicity.","c69df22b":"# Loading the data\nFirst step is always to figure out how to load the data. Below is an example of how this data can be loaded using ImageDataGenerator from keras. \nhttps:\/\/keras.io\/preprocessing\/image\/","e391dbc7":"# Extended model\nA slightly more advanced model"}}