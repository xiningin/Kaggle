{"cell_type":{"f7120e7c":"code","7945e255":"code","b6cca28a":"code","d14e430c":"code","fb2f40ab":"code","bd7c6044":"code","8cad2332":"code","c1c7722e":"code","3443c06e":"code","5abcdf16":"code","e68eefa7":"code","f20a236e":"code","c052ae20":"code","c1099ec1":"code","4105ae1c":"code","cfdc82be":"code","f859c3fc":"code","74193d05":"code","31356321":"code","bd1e33b8":"code","eac73f84":"code","c9bbf009":"markdown","7dd050a3":"markdown","0d041223":"markdown","93600360":"markdown","04821551":"markdown","43b5129e":"markdown","b89fbc4b":"markdown","2cd0af35":"markdown","27c30031":"markdown"},"source":{"f7120e7c":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","7945e255":"data = pd.read_csv('..\/input\/cvdcvd-vd\/Social_Network_Ads.csv')","b6cca28a":"data = data.set_index('User ID')","d14e430c":"data.info()","fb2f40ab":"data.groupby(['Purchased','Gender']).median()","bd7c6044":"sns.countplot(data=data,x='Purchased')","8cad2332":"sns.countplot(data=data,x='Purchased',hue='Gender')","c1c7722e":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.histplot(data=data,hue='Purchased',x='Age',bins=20,element='poly')\nplt.subplot(1,2,2)\nsns.histplot(data=data,hue='Purchased',x='EstimatedSalary',bins=20,element='poly')","3443c06e":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.boxplot(data=data,x='Purchased',y='Age',)\nplt.subplot(1,2,2)\nsns.boxplot(data=data,x='Purchased',y='EstimatedSalary')","5abcdf16":"plt.figure(figsize=(15,7))\nsns.scatterplot(data=data,x='Age',y='EstimatedSalary',hue='Purchased',style='Gender')","e68eefa7":"from sklearn.preprocessing import LabelEncoder\nto_be_encoded = ['Gender']\nlabel_encoder = LabelEncoder()\ndfs = []\nfor i in to_be_encoded:\n    temp = pd.DataFrame({'Before Encoding':data[i].unique(),'After Encoding':label_encoder.fit_transform(data[i].unique())})\n    dfs.append([temp.sort_values(by=['After Encoding'],),i])\n    data[i] = label_encoder.fit_transform(data[i])\nprint(dfs[0][1])\ndfs[0][0]","f20a236e":"X = data.drop('Purchased',axis=1)\n\nY = data['Purchased']","c052ae20":"X['nf']=X['EstimatedSalary']*X['Age']\nX['nf2']=X['EstimatedSalary']*X['EstimatedSalary']","c1099ec1":"from sklearn.feature_selection import SelectKBest, chi2\nfs = SelectKBest(score_func=chi2, k='all')\nfs.fit(X, Y)\nper = []\nfor i in fs.scores_:\n    per.append(round(((i\/sum(fs.scores_))*100),3))\n\nfeatures_data = pd.DataFrame({'Feature':X.columns,'Scores':fs.scores_,'Importance (%)':per}).sort_values(by=['Scores'],ascending=False)\n\nplt.figure(figsize=(9,3))\nsns.barplot( 'Importance (%)','Feature',orient='h',data=features_data)\ninsignificant = features_data.loc[features_data['Importance (%)']<0.005]['Feature'].unique()\nfeatures_data","4105ae1c":"X = X.drop(insignificant,axis=1)","cfdc82be":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","f859c3fc":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=100)","74193d05":"from sklearn.metrics import accuracy_score,classification_report\n\n#XGB\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier() \n\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n\n#RFC\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\n\n#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\naccuracy = []\nfor i in range(1,40):    \n    kn = KNeighborsClassifier(n_neighbors=i)\n    kn.fit(X_train,Y_train)\n    predK = kn.predict(X_test)\n    accuracy.append([accuracy_score(Y_test,predK),i])\n    #print('Tested for k =',i)\ntemp = accuracy[0]\nfor m in accuracy:\n    if temp[0] < m[0]:\n        temp=m\nknn = KNeighborsClassifier(n_neighbors=temp[1])\n\n#SVM\nfrom sklearn.svm import SVC\nsvc = SVC()\n\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.1,1, 10, 100, 1000,2000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n\nprint('Models Imported')","31356321":"model_acc = []\nmodels = [xgb,lr,rfc,knn,svc,grid]\n#model_name = ['xgb','lr','rfc','kno','svc','grid']\nfor i in models:\n    i.fit(X_train,Y_train)\n    model_acc.append(accuracy_score(Y_test,i.predict(X_test)))\n                      \nmodels = pd.DataFrame({'Models':models,'Accuracy':model_acc})","bd1e33b8":"models = models.sort_values(by=['Accuracy'],ascending=False).reset_index().drop('index',axis=1)\nbest = models['Models'][0]\nmodels['Models']=models['Models'].astype(str).str.split(\"(\", n = 2, expand = True)[0]\nmodels","eac73f84":"print('Hence the best model is',models['Models'][0],'with an accuracy of',round((models['Accuracy'][0]*100),2),'%')\nprint('\\nThe classification report is:')\nprint(classification_report(Y_test,best.predict(X_test)))","c9bbf009":"# <center> Customer Purchase","7dd050a3":"# Test Train Split","0d041223":"# Scaling","93600360":"# EDA","04821551":"# Model Selection and Estimation","43b5129e":"# Importing Data","b89fbc4b":"# Feature Importance","2cd0af35":"# One Hot Encoding","27c30031":"# Importing Libraries"}}