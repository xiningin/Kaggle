{"cell_type":{"46ab2041":"code","1ef9d70e":"code","09c726b9":"code","4d45f455":"code","29238a8d":"code","b9e645e8":"code","caccaa82":"code","4d5a0d15":"code","7e97b164":"code","290b2651":"code","b8ff7551":"code","1fedcbaf":"code","6fe91f5f":"code","98d1dbcf":"code","63451325":"code","6cb271a4":"code","aa912c0c":"code","37ac9a3a":"markdown","4ddd15ae":"markdown","9ab62e25":"markdown","b2b3f58c":"markdown","65514def":"markdown","af8add42":"markdown","73f2c41e":"markdown","171cc4b7":"markdown","afbf14b1":"markdown","5c7acffe":"markdown"},"source":{"46ab2041":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","1ef9d70e":"#display full output of cell not only last one\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","09c726b9":"# 2. Load data \n\nPATH = \"..\/input\/chest-xray-pneumonia\/chest_xray\"\ntrain_dir = os.path.join(PATH, \"train\")\nvalidation_dir = os.path.join(PATH, \"val\")\ntest_dir = os.path.join(PATH, \"test\")\n\ntrain_dir\nvalidation_dir\ntest_dir","4d45f455":"train_norm_dir = os.path.join(train_dir, \"NORMAL\")  #train directory containing normal(non pneumonia images) \ntrain_pne_dir = os.path.join(train_dir, \"PNEUMONIA\") #train directory containing pneumonia images\n\nval_norm_dir = os.path.join(validation_dir, \"NORMAL\") # validation directory\nval_pne_dir = os.path.join(validation_dir, \"PNEUMONIA\")\n\ntest_norm_dir = os.path.join(test_dir, \"NORMAL\") # validation directory\ntest_pne_dir = os.path.join(test_dir, \"PNEUMONIA\")\n\ntotal_train = len(os.listdir(train_norm_dir)) + len(os.listdir(train_pne_dir)) #total no of training images\ntotal_val = len(os.listdir(val_norm_dir)) + len(os.listdir(val_pne_dir)) #total no of validation images\ntotal_test = len(os.listdir(test_norm_dir)) + len(os.listdir(test_pne_dir)) #total no of validation images\n\n#total no of training and validation images\ntotal_train\ntotal_val\ntotal_test","29238a8d":"len(os.listdir(train_norm_dir))\nlen(os.listdir(train_pne_dir))","b9e645e8":"sample_img = os.path.join(train_norm_dir, \"IM-0149-0001.jpeg\")\nshow_img = load_img(sample_img)\nplt.imshow(show_img)\nplt.show;","caccaa82":"# 3. preprocessing data\n\n#setting some variables we will be requiring in training\nbatch_size=32\nepochs = 20\nimg_width = 150\nimg_height = 150","4d5a0d15":"train_img_generator = ImageDataGenerator(rescale= 1.0\/255,\n                                        shear_range=0.2,\n                                        zoom_range=0.2,)\nval_img_generator = ImageDataGenerator(rescale = 1.0\/255)\ntest_img_generator = ImageDataGenerator(rescale = 1.0\/255)","7e97b164":"train_data_gen = train_img_generator.flow_from_directory(batch_size = batch_size,\n                                                        directory = train_dir,\n                                                        shuffle=True,\n                                                        target_size = (img_height,img_width),\n                                                        class_mode = 'binary')\n\nval_data_gen = val_img_generator.flow_from_directory(batch_size = batch_size,\n                                                    directory = validation_dir,\n                                                    shuffle = True,\n                                                    target_size = (img_height,img_width),\n                                                    class_mode = 'binary')\ntest_data_gen = test_img_generator.flow_from_directory(batch_size = batch_size,\n                                                    directory = test_dir,\n                                                    shuffle = True,\n                                                    target_size = (img_height,img_width),\n                                                    class_mode = 'binary')","290b2651":"sample_train_imgs , label=  next(train_data_gen) \nplt.imshow(sample_train_imgs[1])\nplt.show();\n\n#training input size (batch_size , width, height, channels)\n\nsample_train_imgs.shape\nlen(label)","b8ff7551":"with tf.device(\"\/GPU:0\"):\n    model = tf.keras.models.Sequential([\n                                     tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150,150,3),padding='same'),\n                                     tf.keras.layers.Conv2D(16, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.MaxPooling2D((2,2)),\n                                     \n                                     tf.keras.layers.Conv2D(16, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.Conv2D(16, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.MaxPooling2D((2,2)),\n                                     \n                                     tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.MaxPooling2D((2,2)),\n\n                                     tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',padding='same'),\n                                     tf.keras.layers.MaxPooling2D((2,2)),\n\n                                     tf.keras.layers.Flatten(),\n                                     tf.keras.layers.Dense(512, activation='relu'),\n                                     tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(optimizer= tf.keras.optimizers.Adam(lr = 1e-5),\n              loss='binary_crossentropy',\n              metrics=['acc','AUC']\n               )\n\nmodel.summary()","1fedcbaf":"%mkdir \".\/cpkt\"\nCPKT = \".\/cpkt\/\"","6fe91f5f":"callback_1 = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=False\n)\n\ncallback_2 = tf.keras.callbacks.ModelCheckpoint(\n    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n)","98d1dbcf":"with tf.device(\"\/GPU:0\"):\n    history = model.fit_generator(train_data_gen,\n                             epochs= epochs,\n                             validation_data = val_data_gen,                        \n                             callbacks = [callback_1, callback_2])","63451325":"auc = history.history['auc']\nval_auc = history.history['val_auc']\n\nplt.figure(figsize=(5, 5))\nplt.plot(auc, label='Training AUC')\nplt.plot(val_auc, label='Validation AUC')\nplt.legend(loc='lower right')\nplt.ylabel('AUC')\nplt.ylim([min(plt.ylim()),1])\nplt.title('AUC')\n\nplt.show();","6cb271a4":"result = model.evaluate(test_data_gen)\nprint(\"loss, accuracy, AUC:\", result)","aa912c0c":"model.save_weights('first_train.h5')","37ac9a3a":"* the below code will set labels from directory name(eg. all images in train\/NORMAL directory will be labeled 0:Normal and images from train\/PNEUMONIA will be labeled 1:PNEUMONIA)\n* similarly labels will be set in test and validation directory\n* output shows images found belonging to 2 classes(normal and pneumonic)","4ddd15ae":"# Training model ","9ab62e25":"* the images are xray-ed images so are grayscale","b2b3f58c":"#  Saving Weights","65514def":"# Inspecting the images","af8add42":"* the following model contains pair of two Conv layer followed by Maxpooling.\n* the fully connected layer have 2 dense layer, final output layer is activated by Sigmoid.\n\n* Also, there is callback funtion defined and it will callback when accuracy is reached 95%. \n* this callback function helps in preventing overfitting.","73f2c41e":"* our tensorflow model will take RGB image with 3 channels, but we have grayscale images so, ImageDataGenerator will rescale,reshape and do some other augmentation.\n* after augmentation and reshaping our input data size will be (img_height, img_width, 3)\n* set image width and height to some low to mid range value so computation will be easy. here I am using width and height 150","171cc4b7":"# Importing required libraries","afbf14b1":"# Model","5c7acffe":"# Data Loading"}}