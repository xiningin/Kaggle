{"cell_type":{"e30a8e48":"code","ebc599fe":"code","d80852f0":"code","3a4d1116":"code","9de0ca2d":"code","d80bd183":"code","3f6b069d":"code","88654a6b":"code","874e5689":"code","7d36b453":"code","4b87775a":"code","2bdfe895":"code","e5303426":"code","b1e99ada":"code","a9922b5d":"markdown","56589119":"markdown","b2e803e4":"markdown"},"source":{"e30a8e48":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ebc599fe":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.svm import SVC\nfrom collections import Counter\nfrom sklearn.metrics import plot_confusion_matrix, f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans","d80852f0":"train = pd.read_csv('..\/input\/dry-beans-classification-iti-ai-pro-intake01\/train.csv')\ntest = pd.read_csv('..\/input\/dry-beans-classification-iti-ai-pro-intake01\/test.csv')","3a4d1116":"# Check data types and missing values\ntrain.info()\ntest.info()","9de0ca2d":"train['y'].value_counts()","d80bd183":"X = train.drop(['ID', 'y'], axis=1)\ny = train['y']\nX_test = test.drop(['ID'], axis=1)","3f6b069d":"sns.displot(data=train, x = 'Area' ,hue='y')","88654a6b":"sns.displot(data=train, x = X['Eccentricity'] ** 3 ,hue='y')","874e5689":"X['Area'] = np.log(X['Area'])\nX_test['Area'] = np.log(X_test['Area'])\n\n\nX['Eccentricity'] = (X['Eccentricity']) ** 3\nX_test['Eccentricity'] = (X_test['Eccentricity']) **3","7d36b453":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(X.corr(), vmin=-1, vmax=1, annot=True)","4b87775a":"ss = StandardScaler()\nX = pd.DataFrame(ss.fit_transform(X))\nX_test = pd.DataFrame(ss.transform(X_test))","2bdfe895":"pca = PCA(random_state=22)\npca.fit(X)\nloadings = pca.components_\nnum_pc = pca.n_features_\npc_list = [\"PC\" + str(i) for i in list(range(1, num_pc + 1))]\nf, ax = plt.subplots(figsize=(15,5))\nplt.bar(x=pc_list, height=pca.explained_variance_ratio_)","e5303426":"#Choose n_components=7\npca = PCA(n_components=7, random_state=22)\nX_pca = pca.fit_transform(X)\nX_test_pca = pca.transform(X_test)\n\ngmm = GaussianMixture(n_components=7, random_state=22).fit(X_pca)\nproba = gmm.predict_proba(X_pca)\nX_new = pd.concat([pd.DataFrame(X_pca), pd.DataFrame(proba)], axis=1)\n\nsvm = SVC(C=34.5,gamma=0.092,tol=0.091).fit(X_new, y)\n\nproba_test = gmm.predict_proba(X_test_pca)\nX_test_new = pd.concat([pd.DataFrame(X_test_pca), pd.DataFrame(proba_test)], axis=1)\n\npred_svc = svm.predict(X_test_new)","b1e99ada":"test['y'] = pred_svc\ntest[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)","a9922b5d":"# 1. Load the Dataset","56589119":"# 2. Exploratory Data Analysis","b2e803e4":"# 3. Modeling"}}