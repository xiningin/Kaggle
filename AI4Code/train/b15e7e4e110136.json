{"cell_type":{"2bf77c3b":"code","d069c035":"code","e6c53d65":"code","9a0d5b39":"code","2d8b3cfe":"code","c714a895":"code","6372e57f":"code","a4cc2e29":"code","b661cdd6":"code","fdb70aa3":"code","c51d24f1":"code","4f574b20":"code","2525fd9c":"markdown"},"source":{"2bf77c3b":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","d069c035":"# Importing the dataset\ndataset = pd.read_csv('..\/input\/Wine.csv')\nX = dataset.iloc[:, 0:13].values\ny = dataset.iloc[:, 13].values","e6c53d65":"dataset.head()","9a0d5b39":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","2d8b3cfe":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","c714a895":"# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nexplained_variance","6372e57f":"# Fitting Logistic Regression to the training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)","a4cc2e29":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred","b661cdd6":"# Making the confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","fdb70aa3":"from sklearn.metrics import classification_report\nCR=classification_report(y_test, y_pred)\nprint(CR)","c51d24f1":"# Visualizing the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.01),\n                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.01))\n\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha=0.75, cmap=ListedColormap(('red', 'green', 'blue')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c=ListedColormap(('red', 'green', 'blue'))(i), label=j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()","4f574b20":"# Visualizing the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.01),\n                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.01))\n\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha=0.75, cmap=ListedColormap(('red', 'green', 'blue')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c=ListedColormap(('red', 'green', 'blue'))(i), label=j)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()","2525fd9c":"**IF YOU LIKE MY WORK PLS UPVOTE**"}}