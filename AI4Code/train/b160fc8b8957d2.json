{"cell_type":{"6e3df6db":"code","8794ae6d":"code","d9a34440":"code","05dbf1ac":"code","8d226e29":"code","f91d0545":"code","4222148b":"code","047411fb":"code","6483bccb":"code","1f72be92":"code","28977a04":"code","9d589de3":"code","805fa611":"code","e54c62b3":"code","8de745ff":"code","a9056072":"code","95973be9":"code","a47d1e04":"code","5251ddc1":"code","9facdb8a":"code","69adbbc0":"code","9ea41473":"code","e28b8cfc":"code","c7d8c164":"code","db8a8319":"code","536d7383":"code","8af8617d":"code","17adbf5e":"code","f5db1a87":"code","669e0d61":"code","59dc48cb":"code","ff926a89":"code","e32e5dff":"code","649063d1":"code","8845d207":"markdown","894d643d":"markdown","61808b28":"markdown","4a2acd19":"markdown","4d1bd0a2":"markdown"},"source":{"6e3df6db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport plotly.express as px \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2 as cv\nfrom warnings import filterwarnings as filt \n\nplt.style.use('fivethirtyeight')\nfilt('ignore')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8794ae6d":"def get_df(base_path):\n    images = []\n    labels = []\n    for cls in ['no', 'yes']:\n        path = os.path.join(base_path, cls)\n        imgs = [os.path.join(cls, i) for i in os.listdir(path)]\n        images += imgs \n        labels += [cls] * len(imgs)\n        \n    return pd.DataFrame({\n        'img_path' : images,\n        'target'   : labels\n    })\n\nbase_path = '..\/input\/brain-mri-images-for-brain-tumor-detection'\n\n\ndf = get_df(base_path)\ndf.head()","d9a34440":"target_count = df.target.value_counts()\npx.bar(x = target_count.index, y = target_count, color = target_count.index, title = 'brain tumor target count')","05dbf1ac":"def get_row_num(num, col = 5):\n    if num % col == 0:\n        return num \/\/ col\n    return (num \/\/ col) + 1\n\ndef hardmax(ohe):\n    return np.argmax(ohe, axis = 1)\n\ndef show_imgs(df, base_path, num = 10, col = 5):\n    df = df.sample(num)\n    ind = 1\n    row = get_row_num(num, col)\n    plt.figure(figsize = (22, row * 3))\n    for i, rdf in df.iterrows():\n        plt.subplot(row, col, ind)\n        path = os.path.join(base_path, rdf.img_path)\n        image = plt.imread(path)\n        label = rdf.target\n        plt.imshow(image)\n        plt.title(f'Tumor : {label} | {image.shape}')\n        plt.axis('off')\n        ind += 1\n        \n        \ndef show_img_gen(generator, num = 10, col = 5, ohe = False, cmap = None):\n    batches = (generator.samples \/\/ generator.batch_size) \n    n = np.random.randint(0, batches)\n    row = get_row_num(num, col)\n    images, labels = generator[n]\n    plt.figure(figsize = (22, row * 3))\n    for i in range(num):\n        img = images[i]\n        cls = labels[i]\n        cls = cls if ohe == False else hardmax(cls)\n        \n        plt.subplot(row, col, i + 1)\n        plt.imshow(img, cmap = cmap)\n        plt.title(f'Tumor : {cls} | {img.shape}')\n        plt.axis('off')","8d226e29":"show_imgs(df, base_path, 15, 5)","f91d0545":"from sklearn.model_selection import train_test_split","4222148b":"def samples(x, y, frac = 0.2):\n    x, xt, y, yt = train_test_split(x, y, stratify = y, test_size = frac)\n    print(f'Total samples  :==> {x.shape[0]}')\n    print(f'Splitting frac :==> {frac}')\n    print(f'Train split    :==> {x.shape[0]}')\n    print(f'Test split     :==> {xt.shape[0]}')\n    return x, xt, y, yt\n\nx = df.drop(['target'], axis = 1)\ny = df.target\nx_train, x_dev, y_train, y_dev = samples(x, y, 0.25)","047411fb":"import albumentations as A\nfrom keras.preprocessing.image import ImageDataGenerator","6483bccb":"def alb_transformation(x):\n    transform = A.Compose([\n        A.CoarseDropout(max_holes = 12, min_holes = 8),\n        A.GaussianBlur(p = 0.3),\n    ])\n    \n    x_aug = transform(image = x)['image']\n    return x_aug\n\ndef create_img_generator(df, base_path, \n                         target_size, batch_size = 16, \n                         color_mode = 'rgb', \n                         datagen_args = {'rescale' : 1.\/255}, shuffle = False):\n    generator = ImageDataGenerator(**datagen_args)\n    return generator.flow_from_dataframe(df, base_path, \n                                         x_col = 'img_path', y_col = 'target', \n                                         classes = ['no', 'yes'], color_mode = color_mode, \n                                         target_size = target_size, class_mode = 'binary',\n                                         shuffle = shuffle, batch_size = batch_size\n                                        )\n\ndef print_mean_shape(df, base_path):\n    heights = []\n    widths  = []\n    for i, rdf in df.iterrows():\n        path = os.path.join(base_path, rdf.img_path)\n        img = plt.imread(path).shape\n        heights.append(img[0])\n        widths.append(img[1])\n    \n    \n    mh = np.mean(heights)\n    mw = np.mean(widths)\n    print(f'Mean height : {mh}')\n    print(f'Mean width  : {mw}')\n    \n    plt.figure(figsize = (15, 5))\n\n    plt.subplot(1, 2, 1)\n    sns.distplot(heights)\n    plt.axvline(mh, linestyle = 'dashed', linewidth = 2.5, color = 'k')\n    plt.title('Image height distribution')\n    \n    plt.subplot(1, 2, 2)\n    sns.distplot(widths)\n    plt.axvline(mw, linestyle = 'dashed', linewidth = 2.5, color = 'k')\n    plt.title('Image width distribution')","1f72be92":"print_mean_shape(df, base_path)","28977a04":"## args\ntrain_gen_args = {\n    'rescale'         : 1.\/255,\n    'horizontal_flip' : True ,\n    'vertical_flip'   : True,\n    'zoom_range'      : .15,\n    'rotation_range'  : .15,\n    'preprocessing_function' : alb_transformation\n}\n\ndev_gen_args = {\n    'rescale' : 1.\/255\n}\n\nIMG_SIZE   = 380\nIMG_SHAPE  = (IMG_SIZE, IMG_SIZE, 1) \nBATCH_SIZE = 16\n\n## generators\ntrain_df = pd.concat([x_train, y_train], axis = 1)\ntrain_gen = create_img_generator(train_df, base_path, \n                                 IMG_SHAPE[:-1], BATCH_SIZE, \n                                 color_mode = 'grayscale', \n                                 datagen_args = train_gen_args, \n                                 shuffle = True)\n\ndev_df = pd.concat([x_dev, y_dev], axis = 1)\ndev_gen = create_img_generator(dev_df, base_path, \n                                 IMG_SHAPE[:-1], BATCH_SIZE, \n                                 color_mode = 'grayscale', \n                                 datagen_args = dev_gen_args, \n                                 shuffle = False)","9d589de3":"show_img_gen(train_gen, 15, 5, cmap = 'gray')","805fa611":"show_img_gen(dev_gen, 5, 5, cmap = 'gray')","e54c62b3":"from keras.layers import Conv2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Flatten, Input, MaxPool2D\nfrom keras import Sequential\nfrom keras.models import Model\nimport tensorflow as tf\nimport keras \n\ndef CNN_seq(ip, op, layer_activation):\n    output_activation = 'sigmoid' if op == 1 else 'softmax'\n    model = Sequential([\n        Input(shape = ip),\n        Conv2D(filters = 32, kernel_size = (3,3), strides = 1, padding = 'same', activation = layer_activation),\n        MaxPool2D(pool_size = (2,2), strides = (2,2)),\n        \n        Conv2D(filters = 32, kernel_size = (3,3), strides = 1, padding = 'same', activation = layer_activation),\n        MaxPool2D(pool_size = (2,2), strides = (2,2)),\n        \n        Conv2D(filters = 64, kernel_size = (3,3), strides = 1, padding = 'same', activation = layer_activation),\n        BatchNormalization(),\n        \n        Flatten(),\n        Dropout(.3),\n        \n        Dense(512, activation = layer_activation),\n        Dense(256, activation = layer_activation),\n        Dense(64,  activation = layer_activation),\n        \n        Dense(op,   activation = output_activation)  \n    ])\n    \n    print(f'Layer Activation  : {layer_activation}')\n    print(f'Output Activation : {output_activation}')\n    return model\n\n\ndef plot_dots(ax, arr, color, best_epoch = False, mode = None):\n    plt.grid(False)\n    ax.scatter(list(range(1, len(arr) + 1)), arr, color = color)\n    ax.plot(list(range(1, len(arr) + 1)), arr, linewidth = 2.55, )\n    if best_epoch and mode is not None:\n        n = np.min(arr) if mode == 'min' else np.max(arr)\n        plt.axhline(n, linestyle = 'dashed', linewidth = 1.5, color = 'white')\n    \ndef plot(his):\n    his = pd.DataFrame(his.history)\n    \n    plt.figure(figsize = (15, 5))\n    plt.style.use('dark_background')\n    \n    \n    plt.subplot(1, 2, 1)\n    plot_dots(plt, his.loss, 'red')\n    plot_dots(plt, his.val_loss, 'yellow', True, 'min')\n    plt.title('Loss')\n    plt.xlabel('epoch')\n    plt.ylabel('Loss')\n    plt.legend([None,'loss', None, 'val_loss'])\n    \n    plt.subplot(1, 2, 2)\n    plot_dots(plt, his.accuracy, 'red')\n    plot_dots(plt, his.val_accuracy, 'yellow', True, 'max')\n    plt.title('Accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('Acc')\n    plt.legend([None, 'acc', None, 'val_acc'])\n    \n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, f1_score, roc_auc_score\n\ndef report(yt, pred):\n    print(f'Accuracy score :==> {accuracy_score(yt, pred)}')\n    print()\n    print(classification_report(yt, pred))\n    print()\n    sns.heatmap(confusion_matrix(yt, pred), fmt = '.2f', annot = True, cmap = 'plasma')\n    \n    \ndef best_pred_thresh(yt, pred, thresh = [i\/10 for i in range(2,10)], return_bt = False):\n    bt = 0\n    bfscore = 0\n    bascore = 0\n    for t in thresh:\n        pp = (pred >= t).astype(int)\n        ass = round(accuracy_score(yt, pp), 2)\n        f1s = round(f1_score(yt, pp), 2)\n        print(f'threshold : {t} | accuracy score : {ass}  |  f1 score : {f1s}')\n        if (ass > bascore) and (f1s > bfscore):\n            bt = t\n            bascore = ass\n            bfscore = f1s\n            \n    print('''\n    \n    =======================================================================================\n    \n    ''')\n    print(f'Best Threshold :====>   {bt}')\n    print(f'Best accuracy  :====>   {bascore}')\n    print(f'Best f1 score  :====>   {bfscore}')\n    \n    if return_bt:\n        return bt\n    \n    \ndef roc_plot(yt, preds_prob):\n    auc_scores, fprs, tprs = [], [], []\n    for ind, pred in enumerate(preds_prob):\n        auc = roc_auc_score(yt, pred)\n        fpr, tpr, _ = roc_curve(yt, pred)\n        auc_scores.append(auc)\n        fprs.append(fpr)\n        tprs.append(tpr)\n        \n    plt.style.use('dark_background')\n    \n    for i in range(ind + 1):\n        plt.figure(1, figsize = (12, 6))\n        plt.grid(False)\n        plt.plot(fprs[i], tprs[i], label = f'model {i + 1} - auc score : {auc_scores[i]}')\n    \n    plt.title('AU-ROC Curve')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    ","8de745ff":"model = CNN_seq(IMG_SHAPE, 1, 'tanh')\nmodel.summary()","a9056072":"model.compile(\n    loss ='binary_crossentropy',\n    optimizer = tf.keras.optimizers.SGD(learning_rate = .0015),\n    metrics = ['accuracy']\n)\n\nhis = model.fit_generator(generator = train_gen, validation_data= dev_gen, \n                          steps_per_epoch = train_gen.samples \/\/ train_gen.batch_size , \n                          epochs = 50\n                         )","95973be9":"plot(his)","a47d1e04":"pred = model.predict_generator(dev_gen) \nyt   = dev_gen.classes\n\nthresh1 = best_pred_thresh(yt, pred, return_bt= True)","5251ddc1":"ppred = (pred >= thresh1).astype(int)\nreport(yt, ppred)","9facdb8a":"model2 = CNN_seq(IMG_SHAPE, 1, 'leaky_relu')\nmodel2.summary()","69adbbc0":"model2.compile(\n    loss ='binary_crossentropy',\n    optimizer = tf.keras.optimizers.Adam(learning_rate = .0015),\n    metrics = ['accuracy']\n)\n\nhis2 = model2.fit_generator(generator = train_gen, validation_data= dev_gen, \n                          steps_per_epoch = train_gen.samples \/\/ train_gen.batch_size , \n                          epochs = 50\n                         )","9ea41473":"plot(his2)","e28b8cfc":"pred = model2.predict_generator(dev_gen) \nyt   = dev_gen.classes\n\nthresh2 = best_pred_thresh(yt, pred, return_bt= True)","c7d8c164":"ppred = (pred >= thresh2).astype(int)\nreport(yt, ppred)","db8a8319":"model3 = CNN_seq(IMG_SHAPE, 1, 'relu')\nmodel3.summary()","536d7383":"model3.compile(\n    loss ='binary_crossentropy',\n    optimizer = tf.keras.optimizers.Adam(learning_rate = .0015),\n    metrics = ['accuracy']\n)\n\nhis3 = model3.fit_generator(generator = train_gen, validation_data= dev_gen, \n                          steps_per_epoch = train_gen.samples \/\/ train_gen.batch_size , \n                          epochs = 50\n                         )","8af8617d":"plot(his3)","17adbf5e":"pred = model3.predict_generator(dev_gen) \nyt   = dev_gen.classes\n\nthresh3 = best_pred_thresh(yt, pred, return_bt= True)","f5db1a87":"ppred = (pred >= thresh3).astype(int)\nreport(yt, ppred)","669e0d61":"preds =  [\n    model.predict_generator(dev_gen),\n    model2.predict_generator(dev_gen),\n    model3.predict_generator(dev_gen),\n]\n\nroc_plot(yt, preds)","59dc48cb":"from PIL import Image\nimport requests as req\nfrom io import BytesIO\nimport cv2 as cv\n\nurl = 'https:\/\/i.ibb.co\/pWS4v31\/unnamed.jpg'\nimg = req.get(url).content\nimage = Image.open(BytesIO(img))\nimage","ff926a89":"img = np.array(image)\nimg = cv.resize(img, (380,380))\n# img = img.reshape((380, 380, 1))\nimg = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\nimg.shape","e32e5dff":"plt.axis('off')\nplt.imshow(img.reshape((380, 380, 1)), cmap = 'gray')","649063d1":"m1p = model.predict(img.reshape((1,380, 380, 1))) \nm2p = model2.predict(img.reshape((1,380, 380, 1)))\nm3p = model3.predict(img.reshape((1,380, 380, 1))) \n\nprint(f'Model 1 predicted :==> {m1p}')\nprint(f'Model 2 predicted :==> {m2p}')\nprint(f'Model 3 predicted :==> {m3p}')","8845d207":"**Prediction with my own mri scan**","894d643d":"### model 2","61808b28":"ok thats too bad, i dont have any tumor but all models detected that i have one","4a2acd19":"### Augmented Images","4d1bd0a2":"### model 3"}}