{"cell_type":{"3b4a3f9b":"code","d61928cd":"code","49b2aaac":"code","d9eb9b6c":"code","c9c4239f":"code","e724e1c4":"code","484e1508":"code","bfe39229":"code","3f03219f":"code","4aac2de1":"code","80678eaa":"code","f91a6121":"code","626d9377":"code","5e3c0152":"code","300ca39e":"code","28ceebf5":"code","bb0738ac":"code","ac5d0719":"code","16dd1634":"code","4330f955":"code","c0aaf416":"code","18a7d582":"code","0a7a15d5":"code","8a04b28f":"code","392ee5b5":"code","85d8a4dc":"code","2181cc12":"code","4906f6ee":"code","3af3d399":"code","6795fb38":"code","a2cba8a0":"code","17bb7a7a":"code","c830d7ef":"markdown"},"source":{"3b4a3f9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sbn\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.\n%matplotlib inline","d61928cd":"import pandas as pd\nimport numpy as np\nimport glob\nimport theano.tensor as T\nimport theano\nfrom sklearn.metrics import mean_squared_error","49b2aaac":"print (\"Helpful guide: https:\/\/github.com\/parsing-science\/pymc3_quickstart_guide\")\ndf=pd.concat([pd.read_csv(f) for f in glob.glob('..\/input\/*.csv')], ignore_index = True)\ndf.count()[0]","d9eb9b6c":"df=df.dropna()\ndf.head()","c9c4239f":"df[\"duration_hrs\"]=df[\"duration_sec\"]\/3600.\ndf[\"age\"]=2019-df[\"member_birth_year\"]\ndf[\"start_day\"]=pd.to_datetime(df[\"start_time\"], errors='ignore')\ndf[\"start_day\"]= df['start_day'].dt.floor(\"d\")","e724e1c4":"df=pd.get_dummies(columns=[\"member_gender\",\"user_type\"],data=df)\ndf.head()","484e1508":"aggregations = {\n    'duration_hrs':'mean',\n    \"age\" :\"mean\",\n    \"member_gender_Female\":\"sum\",\n    \"member_gender_Male\":\"sum\",\n    \"member_gender_Other\":\"sum\",\n    \"user_type_Customer\":\"sum\",\n    \"user_type_Subscriber\":\"sum\",  \n}\nday=df.groupby(\"start_day\").agg(aggregations)\nday.head()","bfe39229":"dayList = day.index.day_name()\ndayList","3f03219f":"day[\"total_riders\"]=day[\"user_type_Customer\"]+day[\"user_type_Subscriber\"]","4aac2de1":"print (len(day[\"total_riders\"]))\nnextDay=list(day[\"total_riders\"])\nnextDay.pop(0)#Don't need this value anymore\nnextDay.append(0.0)#Add a zero to the next one as a test","80678eaa":"from sklearn.preprocessing import RobustScaler\nscaledDF = RobustScaler().fit_transform(day)\nscaledDF = pd.DataFrame(data=scaledDF, columns = [\"scaled_\"+str(x) for x in day.columns])","f91a6121":"scaledDF['day'] = dayList\ndayLookup = pd.DataFrame({\"day\": scaledDF.day.unique(), \"dayIndex\": range(7)})","626d9377":"scaledDF[\"nextDay\"]=nextDay\nscaledDF=scaledDF[:len(nextDay)-1]\nscaledDF.tail(5)","5e3c0152":"scaledDF = pd.merge(scaledDF, dayLookup, on=[\"day\"], how='left')\nscaledDF.tail(5)","300ca39e":"import seaborn as sns\ncorr = scaledDF.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","28ceebf5":"\"\"\"\nIf we plot the distributions of these variables, we see \nsignificant co-linearity among some variables with respect \nto the next day predictions. Predictably, categorical features\nthat exist in the majority (male ridership and subscription riders)\nhave strong relationships.\n\"\"\"\n\ng = sbn.pairplot(scaledDF[scaledDF['day']=='Saturday']);","bb0738ac":"\"\"\"\nWhen we plotted the entirety of distributions together (all days of the week),\nwe could see multiple, linear relationships in the data. Now we observe what \nlook to be very tight correlations.\n\"\"\"\n\ng = sbn.pairplot(scaledDF[scaledDF['day']=='Wednesday']);","ac5d0719":"print (\"Let us try some baseline predictions: Naive Average of all ridership\")\n\nnaivePreds=np.ones(len(scaledDF['nextDay']))+np.mean(day['total_riders'])\nnp.sqrt(mean_squared_error(scaledDF[\"nextDay\"], naivePreds))","16dd1634":"print (\"What if we simply look back one day and see if that is a good predictor?\")\nnp.sqrt(mean_squared_error(scaledDF[\"nextDay\"], day[\"total_riders\"][:len(scaledDF[\"nextDay\"])]))","4330f955":"import theano.tensor as T\n\ny = scaledDF[\"nextDay\"]\nX = scaledDF.drop(['day','nextDay','dayIndex'],axis=1)\nindex = scaledDF.dayIndex\n\n#Let's test our model on the last 30 days of data\nmonth_split = len(y)-30\nX_train , Y_train, Index_train =  X[:month_split], y[:month_split], index[:month_split]\nX_test , Y_test, Index_test = X[month_split:], y[month_split:], index[month_split:]\n\n\"\"\"\nWe need to build a shared tensor for the input, output, and now\nthe index value that corresponds to which day we are referencing.\n\"\"\"\nmodel_index = theano.shared(np.array(Index_train))\nmodel_input = theano.shared(np.array(X_train))\nmodel_output = theano.shared(np.array(Y_train))\nprint (X_train.shape,Y_train.shape,Index_train.shape)\nprint (X_test.shape,Y_test.shape,Index_test.shape)","c0aaf416":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,Y_train)\npreds = lr.predict(X_test)\nnp.sqrt(mean_squared_error(Y_test, preds)) #1298.350508812364","18a7d582":"np.sqrt(mean_squared_error(Y_test, naivePreds[:len(Y_test)]))#2117.4783114031584","0a7a15d5":"import pymc3 as pm\n\nprint('Running on PyMC3 v{}'.format(pm.__version__))","8a04b28f":"hierarchical_big_model = pm.Model()\n\nnDays, nFeatures = len(scaledDF.dayIndex.unique()), X.shape[1]\nwith hierarchical_big_model:\n\n    \"\"\"\n    Meta Priors: For each day of the week, we \n    should have a different set of distributions. Potentially\n    we could have different priors even for the season,\n    weather, etc.\n    \"\"\"\n    day_alpha = pm.Normal('day_alpha', mu=0, sd=100)\n    day_beta = pm.Normal('day_beta', mu=0, sd=100)\n    \n    \"\"\"\n    Model the uncertainty of our parent distributions \n    with a HalfCauchy with beta = 4.\n    \"\"\"\n    sigma_day_alpha = pm.HalfCauchy('sigma_day_alpha', 4)\n    sigma_day_beta = pm.HalfCauchy('sigma_day_beta', 4)\n    \n    \"\"\"\n    Now we draw distributions depending on the day from\n    the above values. We now have to grab betas from an array\n    of shape 7,8 as we have 7 days and 8 weights to learn.\n    \"\"\" \n    alpha = pm.Normal('alpha', mu = day_alpha, sd = sigma_day_alpha, shape = nDays )\n    beta = pm.Normal('beta', mu = day_beta, sd = sigma_day_beta, shape = (nDays,nFeatures) )\n    \"\"\"\n     We can do the dot product as long as we index the day using the model_index and\n     then the 8 weights via beta[model_index,:].T .\n    \"\"\"\n    values = np.exp(alpha[model_index] + T.dot(model_input, beta[model_index,:].T) )\n    \n    # Likelihood (samplYeah does noting distribution) of observations\n    Y_obs = pm.Poisson('Y_obs', mu=values, observed=model_output)","392ee5b5":"#Set to training again\nwith hierarchical_big_model:\n    inference = pm.ADVI()\n    approx = pm.fit(n=100000, method=inference)","85d8a4dc":"advi_trace = approx.sample(10000)","2181cc12":"import pickle\nfileObject = open(\"models\/advi_tracehierarchical_big.pickle\",'wb')  \npickle.dump(advi_trace, fileObject)\nfileObject.close()","4906f6ee":"pm.traceplot(advi_trace[-1000:]);","3af3d399":"def scoreModel(trace,y,model_name):\n    ppc = pm.sample_ppc(trace[1000:], model=model_name, samples=1000)\n    #We have to change the scoring model to grab the first element\n    pred = ppc['Y_obs'][0].mean(axis=0)\n    return np.sqrt(mean_squared_error(y, pred))\n\nscoreModel(advi_trace,Y_train,hierarchical_big_model)","6795fb38":"model_input.set_value(np.array(X_test))\nmodel_index.set_value(np.array(Index_test))\nmodel_output.set_value(np.array(Y_test))\nscoreModel(advi_trace,Y_test,hierarchical_big_model)","a2cba8a0":"ppc = pm.sample_ppc(advi_trace[1000:], model=hierarchical_big_model, samples=1000)","17bb7a7a":"print (ppc['Y_obs'][0].mean(axis=0))","c830d7ef":"In this hierarchical example, we are including all of the features we had in our previous example,\nbut allowing them to vary based on the day we are referencing."}}