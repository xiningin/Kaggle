{"cell_type":{"eb5fdc51":"code","e0d83161":"code","19da90b1":"code","f941cbbc":"code","81f15f8a":"code","971cc6b2":"code","69fa991c":"code","7b3a7821":"code","17e862ba":"code","776a605a":"code","5a9f3402":"code","87a11a94":"code","872aa12e":"code","5ba8844d":"code","b391cd31":"code","c2705f42":"code","24cc465e":"code","0d3fe2ec":"code","d264feae":"code","a1825ec9":"code","b25386fa":"code","1c2e0e0a":"code","6b5f0bb3":"code","45c02c5d":"code","fcee7bc5":"code","391afccd":"code","517b4db7":"code","0ab405c5":"code","60dc9121":"markdown","88851b78":"markdown","9a17908e":"markdown"},"source":{"eb5fdc51":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport os\nimport sys\n\nimport pandas as pd\nimport math\nimport csv\n\nfrom timeit import default_timer as timer\n\nfrom datetime import datetime","e0d83161":"# madgrad\n# https:\/\/github.com\/facebookresearch\/madgrad\n\n#!pip install madgrad\n\n#from madgrad import MADGRAD","19da90b1":"!pip install timm","f941cbbc":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim\nfrom torch.optim import AdamW\n\nfrom torch.nn.parallel.data_parallel import data_parallel\n\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import *\n\nimport collections\nfrom collections import defaultdict\n\nimport timm\nfrom timm.models.swin_transformer import *\n\nimport torch.cuda.amp as amp","81f15f8a":"from timm.scheduler.cosine_lr import CosineLRScheduler","971cc6b2":"num_label = 6\nimage_size = 224\ndata_dir = f\"\/kaggle\/input\/stratified-k-fold\/{image_size}\/train\/\"\ntrain_df = pd.read_csv(\"..\/input\/stratified-k-fold\/train_df.csv\")","69fa991c":"train_df.head()","7b3a7821":"def make_fold(mode='train-0'):\n    if 'train' in mode:\n        fold = int(mode[-1])\n        df_train = train_df[train_df.fold != fold].reset_index(drop=True)\n        df_valid = train_df[train_df.fold == fold].reset_index(drop=True)\n        return df_train, df_valid","17e862ba":"class YogaDataset(Dataset):\n    def __init__(self, df, augment=None):\n        super().__init__()\n        self.df = df\n        self.augment = augment\n        self.length = len(df)\n\n    def __str__(self):\n        string  = ''\n        string += '\\tlen = %d\\n'%len(self)\n        string += '\\tdf  = %s\\n'%str(self.df.shape)\n        return string\n\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, index):\n        d = self.df.iloc[index]\n        image_file = data_dir + '\/%s' % (d.image_id)\n        #image = cv2.imread(image_file,cv2.IMREAD_GRAYSCALE)\n        image = cv2.imread(image_file)\n        onehot = np.zeros(6)\n        onehot[d[\"class_6\"]] = 1\n        \n        r = {\n            'index' : index,\n            'd' : d,\n            'image' : image,\n            'onehot' : onehot,\n        }\n        if self.augment is not None: r = self.augment(r)\n        return r\n\n\ndef null_collate(batch):\n    collate = defaultdict(list)\n\n    for r in batch:\n        for k, v in r.items():\n            collate[k].append(v)\n\n    # ---\n    batch_size = len(batch)\n    onehot = np.ascontiguousarray(np.stack(collate['onehot'])).astype(np.float32)\n    collate['onehot'] = torch.from_numpy(onehot)\n\n    image = np.stack(collate['image'])\n    #image = image.reshape(batch_size, 1, image_size,image_size).repeat(3,1)\n    image = image.transpose((0, 3, 1, 2))\n    image = np.ascontiguousarray(image)\n    image = image.astype(np.float32) \/ 255\n    collate['image'] = torch.from_numpy(image)\n\n    return collate","776a605a":"\"\"\"\ndf_train, df_valid = make_fold(mode='train-0')\n\ndataset = YogaDataset(df_valid) #null_augment\nprint(dataset)\n\n\nfor i in range(3):\n    i = np.random.choice(len(dataset))\n    r = dataset[i]\n    print('index ' , i)\n    print(r['d'])\n    print(r['onehot'])\n    print('')\n    plt.figure()\n    plt.imshow(r['image'])\n\"\"\"","5a9f3402":"\"\"\"\nloader = DataLoader(\n    dataset,\n    sampler = RandomSampler(dataset),\n    batch_size  = 8,\n    drop_last   = True,\n    num_workers = 0,\n    pin_memory  = True,\n    collate_fn  = null_collate,\n)\nfor t,batch in enumerate(loader):\n    if t>5: break\n\n    print(t, '-----------')\n    print('index : ', batch['index'])\n    print('image : ')\n    print('\\t', batch['image'].shape, batch['image'].is_contiguous())   \n    print('onehot : ')\n    print('\\t', batch['onehot'])\n    print('\\t', batch['onehot'].shape, batch['onehot'].is_contiguous())\n    print('')\n\"\"\"","87a11a94":"#e = swin_tiny_patch4_window7_224(pretrained=True)\n#print(e)","872aa12e":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        #self.swin = swin_base_patch4_window12_384_in22k(pretrained=True)\n        #e = swin_base_patch4_window12_384(pretrained=True, drop_path=0.2)\n        e = swin_tiny_patch4_window7_224(pretrained=True, drop_path=0.2)\n        self.patch_embed = e.patch_embed\n        self.pos_drop = e.pos_drop\n        self.layers = e.layers\n        self.norm = e.norm\n        self.avgpool = e.avgpool\n        \n        self.logit = nn.Linear(768, num_label)\n        #self.logit = nn.Linear(1024, num_label)\n\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2*image-1     ; #print('input ',   x.shape)\n\n        x = self.patch_embed(x)\n        x = self.pos_drop(x)\n        x = self.layers(x)\n        x = self.norm(x)  # B L C\n        # TODO \uff1f\uff1f\uff1f\uff1f\n        x = self.avgpool(x.transpose(1, 2))  # B C 1\n        x = torch.flatten(x, 1)\n        x = F.dropout(x, 0.5, training=self.training)\n        logit = self.logit(x)\n        return logit","5ba8844d":"\"\"\"\n\nbatch_size = 2\nC, H, W = 3, image_size, image_size\nimage = torch.randn(batch_size, C, H, W).cuda()\n\nnet = Net().cuda()\nlogit = net(image)\n \nprint(image.shape)\nprint(logit.size())\n\n\"\"\"","b391cd31":"class Logger(object):\n    def __init__(self):\n        self.terminal = sys.stdout  #stdout\n        self.file = None\n\n    def open(self, file, mode=None):\n        if mode is None: mode ='w'\n        self.file = open(file, mode)\n\n    def write(self, message, is_terminal=1, is_file=1 ):\n        if '\\r' in message: is_file=0\n\n        if is_terminal == 1:\n            self.terminal.write(message)\n            self.terminal.flush()\n            #time.sleep(1)\n\n        if is_file == 1:\n            self.file.write(message)\n            self.file.flush()\n\n    def flush(self):\n        # this flush method is needed for python 3 compatibility.\n        # this handles the flush command by doing nothing.\n        # you might want to specify some extra behavior here.\n        pass","c2705f42":"def time_to_str(t, mode='min'):\n    if mode=='min':\n        t  = int(t)\/60\n        hr = t\/\/60\n        min = t%60\n        return '%2d hr %02d min'%(hr,min)\n\n    elif mode=='sec':\n        t   = int(t)\n        min = t\/\/60\n        sec = t%60\n        return '%2d min %02d sec'%(min,sec)\n\n    else:\n        raise NotImplementedError","24cc465e":"def get_learning_rate(optimizer):\n    lr=[]\n    for param_group in optimizer.param_groups:\n        lr +=[ param_group['lr'] ]\n\n    assert(len(lr)==1) #we support only one param_group\n    lr = lr[0]\n\n    return lr","0d3fe2ec":"class AmpNet(Net):\n    @torch.cuda.amp.autocast()\n    def forward(self,*args):\n        return super(AmpNet, self).forward(*args)\n\nis_mixed_precision = True  #True #False","d264feae":"from sklearn.metrics import f1_score","a1825ec9":"def np_loss_cross_entropy(probability, truth):\n    batch_size = len(probability)\n    truth = truth.reshape(-1)\n    p = probability[np.arange(batch_size),truth]\n    loss = -np.log(np.clip(p,1e-6,1))\n    loss = loss.mean()\n    return loss","b25386fa":"def do_valid(net, valid_loader):\n\n    valid_probability = []\n    valid_truth = []\n    valid_num = 0\n\n    net.eval()\n    start_timer = timer()\n    for t, batch in enumerate(valid_loader):\n        batch_size = len(batch['index'])\n        image = batch['image'].cuda()\n        onehot = batch['onehot']\n        label = onehot.argmax(-1)\n\n        with torch.no_grad():\n            #with amp.autocast():\n                logit = data_parallel(net,image)\n                probability = F.softmax(logit,-1)\n\n        valid_num += batch_size\n        valid_probability.append(probability.data.cpu().numpy())\n        valid_truth.append(label.data.cpu().numpy())\n        print('\\r %8d \/ %d  %s'%(valid_num, len(valid_loader.dataset),time_to_str(timer() - start_timer,'sec')),end='',flush=True)\n\n    assert(valid_num == len(valid_loader.dataset))\n    #print('')\n    #----------------------\n    truth = np.concatenate(valid_truth)\n    probability = np.concatenate(valid_probability)\n    predict = probability.argsort(-1)[:, ::-1]\n\n    loss = np_loss_cross_entropy(probability,truth)\n    topk = (predict==truth.reshape(-1,1))\n    #acc  = topk[:, 0]\n    topk = topk.mean(0).cumsum()\n    #acc = [acc[truth==i].mean() for i in range(num_study_label)]\n\n    #---\n    f1score  = f1_score(truth, predict[:, 0], average=\"macro\")\n    #map  = np_metric_map_curve_by_class(probability, truth)\n    return [loss, f1score, topk[0], topk[1]]","1c2e0e0a":"\"\"\"\ndf_train, df_valid = make_fold('train-1')\nvalid_dataset = YogaDataset(df_valid, )\nvalid_loader  = DataLoader(\n            valid_dataset,\n            sampler = SequentialSampler(valid_dataset),\n            batch_size  = 16,\n            drop_last   = False,\n            num_workers = 4,\n            pin_memory  = True,\n            collate_fn  = null_collate,\n        )\nnet = AmpNet().cuda()\nvalid_loss = do_valid(net, valid_loader)\nvalid_loss\n\"\"\"","6b5f0bb3":"!pip install albumentations -U\nimport albumentations as alb","45c02c5d":"#\"\"\"\nsize = image_size\ntransform = alb.Compose([\n        #\u4f4d\u7f6e\n        alb.OneOf([\n            alb.HorizontalFlip(p=0.5),\n        #    alb.VerticalFlip(p=0.5),\n        ], p=0.5),\n\n        #alb.RandomRotate90(p=.5),\n\n        #\u771f\u5b9e\u6742\u97f3\n        alb.OneOf([\n            #alb.RandomShadow(p=0.1),  # \u7070\u9636\u65e0\u6cd5\u4f7f\u7528\n            alb.CoarseDropout(p=0.5), \n            #alb.MaskDropout(p=0.02),\n        ], p=0.25),\n\n        #\u6a21\u7cca\n        alb.OneOf([\n            alb.MedianBlur(blur_limit=(3, 7),p=0.5),\n            #alb.GlassBlur(sigma=0.9, max_delta=200, iterations=1, always_apply=False, mode='fast',p=0.05),\n            alb.GaussianBlur(p=0.5),\n        ], p=0.2),\n\n        #\u5f62\u72b6\n        alb.OneOf([\n            alb.OpticalDistortion(p=0.3),\n            alb.GridDistortion(p=0.3),\n            alb.IAAPiecewiseAffine(p=0.1),\n            alb.ElasticTransform (alpha=1, sigma=50,alpha_affine=40,\n                              interpolation=1, border_mode=4, #value=None, mask_value=None, \n                              always_apply=False, approximate=False, p=0.3)\n        ], p=0.5),\n\n        #\u989c\u8272\n        alb.OneOf([\n            # alb.HueSaturationValue(10,25,10, p= 0.4),  # \u7070\u9636\u4e0d\u517c\u5bb9\n            alb.CLAHE(clip_limit=4, p=0.1),\n            alb.OneOf([\n                #normal\n                alb.RandomBrightnessContrast(brightness_limit=[-0.4,0.4], \n                                         contrast_limit=[-0.4,0.4], brightness_by_max=False, \n                                         always_apply=False, p=0.8),\n                #lighting\n                alb.RandomBrightnessContrast(brightness_limit=[0.4,0.6], \n                                         contrast_limit=[0.4,0.6], \n                                         brightness_by_max=False, \n                                         always_apply=False, p=0.05),\n                alb.RandomBrightnessContrast(brightness_limit=[0.4,0.6], \n                                         contrast_limit=[-0.6,-0.4], brightness_by_max=False, \n                                         always_apply=False, p=0.05),\n                #darking\n                alb.RandomBrightnessContrast(brightness_limit=[-0.6,-0.4], \n                                         contrast_limit=[0.4,0.6], brightness_by_max=False, \n                                         always_apply=False, p=0.05),\n                alb.RandomBrightnessContrast(brightness_limit=[-0.6,-0.4], \n                                         contrast_limit=[-0.5,-0.3], brightness_by_max=False, \n                                         always_apply=False, p=0.05),\n            ],p=0.6)             \n        ], p=0.4),\n\n        #\u6574\u4f53\u5931\u771f\u5316\n        alb.OneOf([\n            alb.GaussNoise(p= 0.1),\n            alb.RandomGamma(gamma_limit=(70, 110), #eps=None, \n                             always_apply=False, p=0.3),           \n        ], p=0.1),\n\n        #\u504f\u79fb\n        alb.OneOf([\n            alb.ShiftScaleRotate(shift_limit=[-0.1,0.1], scale_limit=[-0.15,0.15], \n                                 #rotate_limit=15, \n                                 rotate_limit=0,\n                                 p=0.98, \n                         border_mode=cv2.BORDER_REFLECT),\n            alb.ShiftScaleRotate(shift_limit=[0.1,0.3], scale_limit=[-0.15,0.15], \n                                 #rotate_limit=15, \n                                 rotate_limit=0,\n                                 p=0.005, \n                         border_mode=0),\n            alb.ShiftScaleRotate(shift_limit=[-0.3,0.1], scale_limit=[-0.15,0.15], \n                                 #rotate_limit=15, \n                                 rotate_limit=0,\n                                 p=0.005, \n                         border_mode=0),\n            alb.ShiftScaleRotate(shift_limit=0.1, scale_limit=[0.5,0.6], \n                                 #rotate_limit=30, \n                                 rotate_limit=0,\n                                 p=0.01, \n                         border_mode=cv2.BORDER_REFLECT),\n        ], p=0.9),\n              \n        alb.Cutout(num_holes=10, \n                    max_h_size=int(.1 * size), max_w_size=int(.1 * size), \n                    p=.5),\n    ])\n#random.seed(42)\n#\"\"\"","fcee7bc5":"def train_augment(r):\n    image = r['image']\n\n    aug = transform(image=image)\n\n    r['image'] = aug[\"image\"]\n    return r","391afccd":"config = {\n    \"image_size\":image_size,\n    \"start_lr\":5e-4,\n    #fold = [0, 1, 2, 3, 4]\n    \"foldlist\":[0],\n    \"batchsize\": 64,\n    \"num_iteration\": 900,\n    \"iter_log\": 30,\n    \"iter_valid\": 30\n}","517b4db7":"IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ndef run_train():\n    \n    #wandb.watch(Net, criterion, log=\"all\", log_freq=10)\n    \n    #for fold in [0,1,2,3,4]:\n    for fold in config[\"foldlist\"]:\n        \n        #wandb.init(project=\"covid19-siim-classify\", config=config)\n        \n        out_dir = \".\/\"\n        initial_checkpoint = None\n            \n\n        #start_lr   = 0.0001#1\n        start_lr = config[\"start_lr\"]\n        batch_size = config[\"batchsize\"]\n\n        #num_iteration = 12000\n        num_iteration = config[\"num_iteration\"]\n        iter_log    = config[\"iter_log\"]\n        iter_valid  = config[\"iter_valid\"]\n        iter_save   = list(range(0, num_iteration+1, iter_valid))        \n\n        ## setup  ----------------------------------------\n        for f in ['checkpoint', 'train', 'valid', 'backup']: os.makedirs(out_dir + '\/' + f, exist_ok=True)\n        # backup_project_as_zip(PROJECT_PATH, out_dir +'\/backup\/code.train.%s.zip'%IDENTIFIER)\n\n        log = Logger()\n        log.open(out_dir + '\/log.train.txt', mode='a')\n        log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n        #log.write('\\t%s\\n' % COMMON_STRING)\n        #log.write('\\t__file__ = %s\\n' % __file__)\n        log.write('\\tout_dir  = %s\\n' % out_dir)\n        log.write('\\n')\n\n        ## dataset ------------------------------------\n        df_train, df_valid = make_fold('train-%d'%fold)\n        \n        train_dataset = YogaDataset(df_train, train_augment)\n        #train_dataset = SiimDataset(df_train, )\n        valid_dataset = YogaDataset(df_valid, )\n\n        train_loader = DataLoader(\n            train_dataset,\n            sampler = RandomSampler(train_dataset),\n            batch_size = batch_size,\n            drop_last   = False,\n            num_workers = 2,\n            pin_memory  = True,\n            worker_init_fn=lambda id: np.random.seed(torch.initial_seed() \/\/ 2 ** 32 + id),\n            collate_fn  = null_collate,\n        )\n        valid_loader  = DataLoader(\n            valid_dataset,\n            sampler = SequentialSampler(valid_dataset),\n            batch_size  = 64,\n            drop_last   = False,\n            num_workers = 2,\n            pin_memory  = True,\n            collate_fn  = null_collate,\n        )\n\n        log.write('train_dataset : \\n%s\\n'%(train_dataset))\n        log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n        log.write('\\n')\n\n\n        ## net ----------------------------------------\n        log.write('** net setting **\\n')\n        if is_mixed_precision:\n            scaler = amp.GradScaler()\n            net = AmpNet().cuda()\n        else:\n            net = Net().cuda()\n\n\n        if initial_checkpoint is not None:\n            f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n            start_iteration = f['iteration']\n            start_epoch = f['epoch']\n            state_dict  = f['state_dict']\n            net.load_state_dict(state_dict,strict=True)  #True\n        else:\n            start_iteration = 0\n            start_epoch = 0\n\n\n        log.write('net=%s\\n'%(type(net)))\n        log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n        log.write('\\n')\n\n        # -----------------------------------------------\n        if 0: ##freeze\n            for p in net.block0.backbone.parameters(): p.requires_grad = False\n\n\n        #optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n        #optimizer = RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n        #optimizer = MADGRAD( filter(lambda p: p.requires_grad, net.parameters()), lr=start_lr, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n        optimizer = AdamW(net.parameters(), lr=start_lr)\n        #optimizer = Adam(net.parameters(), lr=start_lr)\n        # TODO adamw\n        #optimizer = MADGRAD(filter(lambda p: p.requires_grad, net.parameters()), lr=start_lr, momentum= 0.9, weight_decay= 0, eps= 1e-06)\n        \n        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n        scheduler = lr_scheduler = CosineLRScheduler(\n            optimizer,\n            t_initial=num_iteration,\n            t_mul=1.,\n            lr_min=start_lr*1e-2,\n            warmup_lr_init=start_lr*1e-3,\n            warmup_t=len(train_loader),\n            cycle_limit=1,\n            t_in_epochs=False,\n        )        \n\n        log.write('optimizer\\n  %s\\n'%(optimizer))\n        log.write('\\n')\n\n\n        ## start training here! ##############################################\n        log.write('** start training here! **\\n')\n        log.write('   fold = %d\\n'%(fold))\n        log.write('   is_mixed_precision = %s \\n'%str(is_mixed_precision))\n        log.write('   batch_size = %d\\n'%(batch_size))\n        #log.write('   experiment = %s\\n' % str(__file__.split('\/')[-2:]))\n        log.write('                      |----- VALID ---|---- TRAIN\/BATCH --------------\\n')\n        log.write('rate     iter   epoch | loss    f1score  topk_0 topk_1  | loss0  loss1 loss2 | time          \\n')\n        log.write('----------------------------------------------------------------------\\n')\n                  #0.00000   0.00* 0.00  | 0.000  0.000  0.000  0.000  | 0.000  0.000  0.000 |  0 hr 00 min\n\n        def message(mode='print'):\n            if mode==('print'):\n                asterisk = ' '\n                loss = batch_loss\n            if mode==('log'):\n                asterisk = '*' if iteration in iter_save else ' '\n                loss = train_loss\n\n            text = \\\n                '%0.7f  %5.5f%s %4.2f  | '%(rate, iteration\/10000, asterisk, epoch,) +\\\n                '%4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n                '%4.3f  | '%(*loss,) +\\\n                '%s' % (time_to_str(timer() - start_timer,'min'))\n\n            return text\n\n        #----\n        valid_loss = np.zeros(4,np.float32)\n        train_loss = np.zeros(1,np.float32)\n        batch_loss = np.zeros_like(train_loss)\n        sum_train_loss = np.zeros_like(train_loss)\n        sum_train = 0\n        loss0 = torch.FloatTensor([0]).cuda().sum()\n\n\n        start_timer = timer()\n        iteration = start_iteration\n        epoch = start_epoch\n        rate = 0\n        while  iteration < num_iteration:\n\n            for t, batch in enumerate(train_loader):\n\n                if iteration in iter_save:\n                    if iteration != start_iteration:\n                        torch.save({\n                            'state_dict': net.state_dict(),\n                            'iteration': iteration,\n                            'epoch': epoch,\n                        }, out_dir + '\/checkpoint\/%08d_model.pth' % (iteration))\n                        pass\n\n                if (iteration % iter_valid == 0):\n                    #if iteration!=start_iteration:\n                        valid_loss = do_valid(net, valid_loader)  #\n                        #scheduler.step(valid_loss[0])\n                        pass\n\n                if (iteration % iter_log == 0):\n                    print('\\r', end='', flush=True)\n                    log.write(message(mode='log') + '\\n')\n                   \n\n                # learning rate schduler ------------\n                rate = get_learning_rate(optimizer)\n\n                # one iteration update  -------------\n                batch_size = len(batch['index'])\n                image = batch['image'].cuda()\n                onehot = batch['onehot'].cuda()\n                label = onehot.argmax(-1)\n\n                #----\n                net.train()\n                optimizer.zero_grad()\n\n                if is_mixed_precision:\n                    with amp.autocast():\n                        logit = data_parallel(net, image)\n                        loss0 = F.cross_entropy(logit, label)\n                        \n                    scaler.scale(loss0).backward()\n                  \n                    scaler.unscale_(optimizer)\n                    scaler.step(optimizer)                           # Now we can do an optimizer step\n                    scaler.update()\n                    optimizer.zero_grad()\n                    scheduler.step_update(iteration)\n\n                # print statistics  --------\n                epoch += 1 \/ len(train_loader)\n                iteration += 1\n\n                batch_loss = np.array([loss0.item()])\n                sum_train_loss += batch_loss\n                sum_train += 1\n                if iteration % iter_log == 0:\n                    train_loss = sum_train_loss \/ (sum_train + 1e-12)\n                    sum_train_loss[...] = 0\n                    sum_train = 0\n\n                print('\\r', end='', flush=True)\n                print(message(mode='print'), end='', flush=True)\n\n        log.write('\\n')\n        #wandb.finish()","0ab405c5":"run_train()","60dc9121":"# Refference \n1. original https:\/\/github.com\/microsoft\/Swin-Transformer\/blob\/main\/config.py\n2. timm https:\/\/github.com\/rwightman\/pytorch-image-models\n3. some bug fix with test https:\/\/github.com\/mrzhuzhe\/pepper\/tree\/master\/colabNote","88851b78":"# Utils","9a17908e":"# Training"}}