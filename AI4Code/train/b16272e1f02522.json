{"cell_type":{"777dd84b":"code","4de444bf":"code","02a762a8":"code","df047a11":"code","cf2b228d":"code","9ace6714":"code","fbb7d16d":"code","88e7227c":"code","03dda6b4":"code","cb41f740":"code","35d83fa8":"code","c96cde4e":"code","d4196229":"code","e8b017e6":"code","90990295":"code","bf13052c":"code","824c443f":"code","4ecce4d2":"code","f8f7880e":"code","3eed9343":"code","0413038f":"code","015616e8":"code","4bcd89ff":"code","933a8657":"code","ac336a94":"code","7b6d8868":"code","223bc9cf":"code","bb9086b7":"code","8f0c06e5":"markdown","cd7d7dd5":"markdown","18fd0752":"markdown","9bf49d1f":"markdown","b5032808":"markdown","dc320d15":"markdown","4a88411d":"markdown","4276de85":"markdown","a42aca97":"markdown","56eb6f67":"markdown","dc6ebbf3":"markdown","69d767cd":"markdown","fb3006f9":"markdown"},"source":{"777dd84b":"import os\nfrom copy import deepcopy\nfrom glob import glob\nfrom dataclasses import dataclass\nfrom typing import List, Tuple, Any, Optional, Callable\nfrom functools import partial\n\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split, sampler\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torchvision.utils import make_grid, draw_segmentation_masks\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nfrom tqdm.notebook import tqdm\n\n","4de444bf":"\n@dataclass\nclass Config:\n    train_path: str\n    test_path: str\n    seed: int        \n\n    image_size: Tuple[int]\n    validation_size: float\n    train_on_all_data: bool\n    \n    model_name: str\n    \n\n    epochs: int\n    batch_size: int\n    loss: str\n    lr: float\n    save_model_period: int\n    \n    \nconf = Config(\n    train_path='..\/input\/journey-springfield\/journey-springfield\/train\/simpsons_dataset',\n    test_path='..\/input\/journey-springfield\/journey-springfield\/testset\/testset',\n    seed = 42,\n\n    image_size = (224,224), \n\n    validation_size = 0.3,\n    train_on_all_data = False,\n    \n    model_name = 'mobilenet_v3_small',\n\n    epochs = 10,\n    batch_size = 32,\n    loss = 'CEL',\n    lr = 1e-4,\n    save_model_period = 1,\n    )\n\nMODEL_COLLECTION = {\n    'resnet18': models.resnet18(pretrained=True),\n    'mobilenet_v3_small': models.mobilenet_v3_small(pretrained=True),\n    'mobilenet_v3_large': models.mobilenet_v3_large(pretrained=True),\n}\nassert conf.model_name in MODEL_COLLECTION, 'invalid model_name!'\n\nLOSS_FUNCTION_COLLECTION = {\n    'CEL': torch.nn.CrossEntropyLoss,\n}\nassert conf.loss in LOSS_FUNCTION_COLLECTION, 'incorrect loss function is configured'\n\nEXPLORING = False\nIMAGE_TO_SHOW = min(8, conf.batch_size)\n\ndef set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.'''\n    # acknowledgment:\n    # https:\/\/www.kaggle.com\/rluethy\/efficientnet3d-with-one-mri-type\n    np.random.seed(seed)\n#     random.seed(seed)\n    torch.manual_seed(seed)\n    \n    if torch.cuda.is_available():\n#         torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n        # When running on the CuDNN backend, two further options must be set\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(conf.seed)\n\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","02a762a8":"# template to version name\nf'RUN{\" AD\" if conf.train_on_all_data else \"\"} ep{conf.epochs} {conf.model_name} lr{np.floor(np.log10(conf.lr))}'","df047a11":"# We  use pretrained  models. \n# So we need to use ImageNet mean and std. \ncolor_mean = np.array([0.485, 0.456, 0.406])\ncolor_std = np.array([0.229, 0.224, 0.225])","cf2b228d":"labels = [path.split('\/')[-1] for path in glob(conf.train_path + '\/*')]\nlabel_to_target = {label: target for target, label in enumerate(labels)}\ntarget_to_label = {target: label for target, label in enumerate(labels)}","9ace6714":"all_train_paths = sorted(glob(conf.train_path + '\/**\/*.jpg', recursive=True))\ntest_paths = sorted(glob(conf.test_path + '\/*.jpg'))","fbb7d16d":"train_paths, val_paths = train_test_split(all_train_paths, test_size=conf.validation_size, random_state=conf.seed)\nlen(train_paths), len(val_paths)","88e7227c":"class SpringfieldDataset(Dataset):\n    def __init__(self, paths:List[str], is_train=False, transforms=None):\n        self.paths = paths\n        self.transforms = transforms\n        self.is_train = is_train\n    \n    def __len__(self):\n        return len(self.paths)\n                   \n    def __getitem__(self, i):\n        path = self.paths[i]\n        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n        if self.is_train:\n            label, image_name = path.split('\/')[-2:]\n            target = label_to_target[label]\n        else:\n            image_name = path.split('\/')[-1]\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        result = {'image': image, 'image_name': image_name}\n        if self.is_train:\n            result.update({'label': label, 'target': target})\n            \n        return result","03dda6b4":"aug_transforms = [\n        albu.HorizontalFlip(),\n        albu.GaussNoise(p=0.3),\n        albu.OneOf([\n            albu.MotionBlur(p=0.2),\n            albu.MedianBlur(blur_limit=3, p=0.3),\n            albu.Blur(blur_limit=3, p=0.3),\n        ], p=0.2),\n        albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=25, p=0.2),\n        albu.OneOf([\n            albu.OpticalDistortion(p=0.3),\n            albu.GridDistortion(p=0.1),\n            albu.PiecewiseAffine(p=0.3),\n        ], p=0.2),\n        albu.OneOf([\n            albu.CLAHE(clip_limit=2),\n            albu.Sharpen(),\n            albu.Emboss(),\n            albu.RandomBrightnessContrast(),            \n        ], p=0.3),\n        albu.HueSaturationValue(p=0.3),\n    ]\n\nresize_transforms = [albu.Resize(*conf.image_size),]\n\nconvert_transforms = [\n        albu.Normalize(mean=color_mean, std=color_std),\n        ToTensorV2(),\n    ]\n\n\ntrain_transforms = albu.Compose(aug_transforms + resize_transforms + convert_transforms)\nval_transforms = albu.Compose(resize_transforms + convert_transforms)\ntest_transforms = albu.Compose(resize_transforms + convert_transforms)\n\n# def transform_func(transforms):\n    \n#     def applying_function(image): \n#         image = np.array(image)\n#         return transforms(image=image)['image']\n    \n#     return applying_function\n\n\ndef inverse_transforms(image_tensor):\n    \n    inv_normalize = transforms.Normalize(\n            mean= [-m\/s for m, s in zip(color_mean, color_std)],\n            std= [1\/s for s in color_std]\n        )\n    \n    image_tensor = inv_normalize(image_tensor)\n    \n    image = image_tensor.permute(1,2,0)\n    \n    return image\n    \n","cb41f740":"train_dataset = SpringfieldDataset(train_paths, is_train=True, transforms=train_transforms)\nval_dataset = SpringfieldDataset(val_paths, is_train=True, transforms=val_transforms)\ntest_dataset = SpringfieldDataset(test_paths, is_train=False, transforms=test_transforms)","35d83fa8":"plt.imshow(inverse_transforms(train_dataset[0]['image']));","c96cde4e":"plt.imshow(inverse_transforms(val_dataset[0]['image']));","d4196229":"train_dataloader = DataLoader(train_dataset, batch_size=conf.batch_size, shuffle=True,\n                              num_workers=os.cpu_count(), prefetch_factor=4, pin_memory=DEVICE.type=='cuda')\nval_dataloader = DataLoader(val_dataset, batch_size=conf.batch_size, shuffle=True,\n                              num_workers=os.cpu_count(), prefetch_factor=4, pin_memory=DEVICE.type=='cuda')\ntest_dataloader = DataLoader(test_dataset, batch_size=conf.batch_size, shuffle=False,\n                              num_workers=os.cpu_count(), prefetch_factor=4, pin_memory=DEVICE.type=='cuda')","e8b017e6":"class_number = len(labels)\n\nmodel = MODEL_COLLECTION[conf.model_name]\n\n# change classifier to actual class_number\nif 'mobilenet' in conf.model_name:\n    model.classifier[3] = torch.nn.Linear(in_features=model.classifier[3].in_features, out_features=class_number)\nelse:\n    raise NotImplementedError\n    \nmodel.to(DEVICE);","90990295":"def save_model(path, model_state, optimizer, scheduler, description:str, config:Optional[Config]=None):\n    torch.save({\n            'model_state_dict': model_state,\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'description': description,\n            'config': config,\n            }, path)\n    print('successfully saved')\n\ndef load_model(path, model, optimizer=None, scheduler=None):\n    checkpoint = torch.load(path, map_location=DEVICE)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    if optimizer is not None:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    if scheduler is not None:\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    description = checkpoint['description']\n    try:\n        config = checkpoint['config']\n    except KeyError:\n        config = None\n        print('no config to load!')\n    print('successfully loaded')\n    return description, config","bf13052c":"def do_epoch(model, optimizer, loss_func, dataloader,\n             mode='T', metric_func=None, title=None):\n    \"\"\"\n    Compute one epoch\n    :param model: (nn.Module) model\n    :param optimizer: (torch.optim) optimization method. Ignored if mode='V'\n    :param loss_func: (func) loss functions\n    :param dataloader: (MyDataLoader) val batches generator (X, y). Default None\n    :param mode: (str) 'T' - Train or 'V' - Validate. Default 'T'\n    :param metric_func: (func) target metric\n    :param title: (str) description in progress bar\n    :return:\n        epoch_loss: mean loss\n        epoch_metric: mean metric\n    \"\"\"\n    if mode not in ['V', 'T']:\n        raise ValueError('mode should be \"T\" or \"V\"')\n        \n    # History\n    epoch_loss = []\n    epoch_metric = []\n\n#     predictions = torch.Tensor()\n#     ground_truth = torch.Tensor()\n#     predictions_df = pd.DataFrame(columns=['patient', 'mri_type', 'predict_proba', 'target']).astype({'predict_proba':float, 'target':int})\n    \n    with tqdm(total=len(dataloader)) as progress_bar:\n        for ind, batch in enumerate(dataloader, 1):\n            description = ''\n            if title is not None:\n                description += title\n            description += f'Mode: {mode} |'\n            \n            X_tens = batch['image'].to(DEVICE)\n            y_tens = batch['target'].to(DEVICE)\n            \n            prediction = model(X_tens)\n#             prediction = torch.clip(prediction, min=0, max=1)\n            \n            loss = loss_func(prediction, y_tens)            \n            epoch_loss.append(loss.item())\n            description += f'Loss: {np.mean(epoch_loss): 7.3} |'\n            \n            # backward\n            if mode == 'T':\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                \n            progress_bar.set_description(description)\n            progress_bar.update()\n\n        #  metric calculate\n#             if metric_func is not None:\n        # apply treshold to prediction and convert it to int\n#         tresholded_prediction = (prediction.detach()> 0.5).type(torch.int)\n        metric = metric_func(\n            prediction.detach().cpu().argmax(dim=1),\n            y_tens.detach().cpu()\n        )\n        epoch_metric.append(metric)\n        description += f'Metric: {np.mean(epoch_metric): 7.3} |'\n\n        progress_bar.set_description(description)\n        progress_bar.update()\n        \n    return epoch_loss, epoch_metric\n\n\ndef train(model, train_loader, loss_func, optimizer, epoch_count=1,\n          metric_func=None, val_loader=None, scheduler=None):\n    \"\"\"\n    Training model\n    :param model: (torch.nn.Module) model for train\n    :param train_loader: (MyDataLoader) train batches generator (X, y)\n    :param loss_func: (func) loss functions\n    :param optimizer: (torch.optim) optimization method\n    :param epoch_count: (int) epochs count. Default 10\n    :param metric_func: (func) target metric\n    :param val_loader: (MyDataLoader) val batches generator (X, y). Default None\n    :param scheduler: (torch.utils)\n    :return:\n        history_info: dict of training history consist \"Tloss\", \"Tmetric\",\n                    \"Vloss\", \"Vmetric\"\n        best_model_param: model parameters at the highest Vmetric value\n    \"\"\"\n    \n    torch.cuda.empty_cache()\n    \n    # Train history and loader\n    history_info = {'Tloss': [], 'Tmetric': []}\n    dataloaders = {'T': train_loader}\n    \n    # Validation history and loader\n    if val_loader is not None:\n        dataloaders.update({'V': val_loader})\n        history_info.update({'Vloss': [], 'Vmetric': []})\n\n    # best Val_score and model params\n    best_metric = - np.inf # start from worst value\n    best_loss = np.inf\n    best_metric_model = {}\n    best_loss_model = {}\n    \n    for epoch in range(epoch_count):\n        for mode, data in dataloaders.items():\n            # title for progress bar\n            title = f'[{epoch+1: 3}\/{epoch_count}]|'\n            model.train(mode == 'T')\n            \n            epoch_loss, epoch_metric = \\\n                do_epoch(model, optimizer, loss_func, data,\n                         mode, metric_func, title)\n            history_info[mode + 'loss'].extend(epoch_loss)\n            history_info[mode + 'metric'].extend(epoch_metric)\n            mean_epoch_loss = np.mean(epoch_loss)\n            mean_epoch_metric = np.mean(epoch_metric)\n            \n\n        # scheduler step\n        if scheduler is not None:\n            scheduler.step(mean_epoch_metric)\n            \n        # save best metric model parameters\n        if metric_func is not None:            \n            if mean_epoch_metric > best_metric:\n                best_metric = mean_epoch_metric\n                best_metric_model = {'params': deepcopy(model.state_dict()),\n                                     'epoch': epoch+1,\n                                     'metric': mean_epoch_metric,\n                                     'loss': mean_epoch_loss}\n\n        # save best loss model parameters\n        if mean_epoch_loss < best_loss:\n            best_loss = mean_epoch_loss\n            best_loss_model = {'params': deepcopy(model.state_dict()),\n                                 'epoch': epoch+1,\n                                 'metric': mean_epoch_metric,\n                                 'loss': mean_epoch_loss}\n\n        \n        # save model every conf.save_model_period epochs. set conf.save_model_period to 0 to disable this.\n        if conf.save_model_period != 0 and (epoch + 1) % conf.save_model_period == 0:\n            file_name = (\n                            f\"{conf.model_name} \"\\\n                            f\"PS \"\\\n                            f\"ep_{epoch+1} \"\\\n                            f\"VL_{best_loss_model['loss']: >6.3f} \"\\\n                            f\"VM_{best_loss_model['metric']: >6.3f}\"\n                        )\n            print(f'saving model {file_name}')\n            save_model(file_name+'.model', deepcopy(model.state_dict()), optimizer, scheduler, description=f'{file_name}; loss {conf.loss};', config=conf)\n\n    return history_info, best_metric_model, best_loss_model","824c443f":"# optimizer parameters\nOPTIM_MOMENTUM = 0.9\nWEIGHT_DECAY = 1e-5  # l2 weight decay\n\noptimizer = torch.optim.Adam(model.parameters(),\n                            lr=conf.lr,\n#                             weight_decay = WEIGHT_DECAY\n                            )\n\nloss_func = LOSS_FUNCTION_COLLECTION[conf.loss]().to(DEVICE)\nmetric_func = partial(f1_score, average= 'macro')\n\n# scheduler parameters\nfactor = 0.5\npatience = 2\nthreshold = 0.001\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='max', factor=factor, patience=patience,\n    verbose=True, threshold=threshold\n)","4ecce4d2":"torch.cuda.empty_cache()\ntrain_history,  best_metric_model, best_loss_model= \\\n    train(model, train_dataloader, loss_func, optimizer,\n          conf.epochs, metric_func, val_dataloader, scheduler)","f8f7880e":"# save model with best metric\nfile_name = (\n            f\"{conf.model_name} \"\\\n            f\"BM \"\\\n            f\"ep_{best_loss_model['epoch']} \"\\\n            f\"VL_{best_loss_model['loss']:.3f} \"\\\n            f\"VM_{best_loss_model['metric']:.3f}\"\n            )\n\nsave_model(file_name+'.model', best_metric_model['params'], optimizer, scheduler, description=f'{file_name}; loss {conf.loss};', config=conf)\nfile_name","3eed9343":"# save model with best loss\nfile_name = (\n            f\"{conf.model_name} \"\\\n            f\"BL \"\n            f\"ep_{best_loss_model['epoch']} \"\\\n            f\"VL_{best_loss_model['loss']:.3f} \"\\\n            f\"VM_{best_loss_model['metric']:.3f}\"\n            )\n\nsave_model(file_name+'.model', best_loss_model['params'], optimizer, scheduler, description=f'{file_name}; loss {conf.loss};', config=conf)\nfile_name","0413038f":"plt.subplots(4,figsize=(15, 6))\n\nplt.subplot(411)\nplt.plot(train_history['Tloss'], label='Train Loss', color='blue')\nplt.legend()\n\nplt.subplot(412)\nplt.plot(train_history['Vloss'], label='Validation Loss', color='red')\nplt.legend()\n\nplt.subplot(413)\nplt.plot(train_history['Tmetric'], label='Train Metric', color='blue')\nplt.legend()\n\nplt.subplot(414)\nplt.plot(train_history['Vmetric'], label='Validation Metric', color='red')\nplt.legend()\n\nplt.show()","015616e8":"model.eval()\nbatch=next(iter(val_dataloader))\nprediction = model(batch['image'].to(DEVICE)).cpu()\nprint(batch['target'])\nprint(prediction.argmax(dim=1))","4bcd89ff":"def make_submition(model, dataloader):\n    torch.cuda.empty_cache()\n    model.eval()\n    \n    submission = {\"Id\": [], \"Expected\": []}\n    for batch in tqdm(dataloader):\n        \n        submission['Id'].extend(batch['image_name'])\n        \n        X_tens = batch['image'].to(DEVICE)        \n        prediction = model(X_tens).cpu().argmax(dim=1)\n        labels = [target_to_label[p.item()] for p in prediction]\n        submission['Expected'].extend(labels)   \n        \n    return pd.DataFrame(submission)","933a8657":"submission = make_submition(model, test_dataloader)","ac336a94":"submission.to_csv(\"submission.csv\", index=False)","7b6d8868":"submission_mobnet01 = pd.read_csv('..\/input\/journeyspringfield-cache\/submission_mobnet_01.csv')\nsubmission_phash = pd.read_csv('..\/input\/journeyspringfield-cache\/submission_phash.csv')","223bc9cf":"df_compare = pd.merge(left=submission_phash, right=submission, left_on='Id', right_on='Id', suffixes=('_phash', '_mobnet'), how='outer')\ndf_compare.iloc[723]","bb9086b7":"(df_compare['Expected_phash'] == df_compare['Expected_mobnet']).sum() \/ df_compare.shape[0]","8f0c06e5":"### Collect file paths into dataframe","cd7d7dd5":"# Dataset","18fd0752":"# Model","9bf49d1f":"# Check training results","b5032808":"### The percentage of matches between the predictions of the two models. ","dc320d15":"# \n\n\n\n","4a88411d":"# Configuration","4276de85":"### Train-validation split","a42aca97":"# Compare with prediction by perceptual hash base algorithm","56eb6f67":"# Training","dc6ebbf3":"# Train loop","69d767cd":"### Augmentations","fb3006f9":"### Save best models"}}