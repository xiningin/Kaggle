{"cell_type":{"28b91e5f":"code","2900d621":"code","59c4a91f":"code","e8d57204":"code","18ed6865":"code","520aab25":"code","703cecd2":"code","7e2cd53a":"code","99f994cf":"code","54050879":"code","723b1e89":"code","9fb7e0cb":"code","6531169a":"code","c2bb592c":"code","baae3ed6":"code","af704657":"code","92c2acbe":"code","844c2221":"code","89c0ff1b":"code","62c17814":"code","dec41d83":"code","65a81a5f":"code","f42f046f":"code","cbd89ec8":"code","56d78cc3":"code","580e585e":"code","b26d8ed9":"markdown","5dc72e7e":"markdown","a19e1aaa":"markdown","da408cb8":"markdown","4f849ea9":"markdown"},"source":{"28b91e5f":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import ToTensor\nimport torchvision.transforms as tt\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","2900d621":"TRAIN_PATH = '..\/input\/intel-image-classification\/seg_train\/seg_train'\nTEST_PATH = '..\/input\/intel-image-classification\/seg_test\/seg_test'\nPRED_PATH = '..\/input\/intel-image-classification\/seg_pred\/seg_pred'","59c4a91f":"transform = tt.Compose([\n    tt.ToTensor(),\n    tt.Resize((64, 64))\n])","e8d57204":"train_ds = ImageFolder(TRAIN_PATH, transform=transform)\ntest_ds = ImageFolder(TEST_PATH, transform=transform)","18ed6865":"image, label = train_ds[0]\nprint(f\"Image Size: {image.shape}\")\nprint(f\"Label: {label}\")\nprint(image)","520aab25":"classes = train_ds.classes","703cecd2":"train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True, num_workers=8)\ntest_dl = DataLoader(test_ds, batch_size=32, shuffle=True, pin_memory=True, num_workers=8)","7e2cd53a":"for batch in train_dl:\n    plt.figure(figsize=(16, 8))\n    image, _ = batch\n    plt.imshow(make_grid(image, nrow=16).permute(1, 2, 0))\n    plt.axis(\"off\")\n    plt.show()\n    break","99f994cf":"class IntelCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Flatten(),\n            nn.Linear(1024*8*8, 512),\n            nn.ReLU(),\n            nn.Linear(512, 64),\n            nn.ReLU(),\n            nn.Linear(64, 6)\n        )\n    \n    def forward(self, image):\n        output = self.model(image)\n        return output","54050879":"model = IntelCNN()\nmodel","723b1e89":"def accuracy(pred, label):\n    _, out = torch.max(pred, dim=1)\n    return torch.tensor(torch.sum(out == label).item()\/len(pred))\n\ndef validation_step(valid_dl, model, loss_fn):\n    for image, label in valid_dl:\n        out = model(image)\n        loss = loss_fn(out, label)\n        acc = accuracy(out, label)\n        return {\"val_loss\": loss, \"val_acc\": acc}\n\ndef fit(train_dl, valid_dl, epochs, optimizer, loss_fn, model):\n    history = []\n    for epoch in range(epochs):\n        for image, label in train_dl:\n            out = model(image)\n            loss = loss_fn(out, label)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        val = validation_step(valid_dl, model, loss_fn)\n        print(f\"Epoch [{epoch}\/{epochs}] => loss: {loss}, val_loss: {val['val_loss']}, val_acc: {val['val_acc']}\")\n        history.append({\"loss\": loss, \n                        \"val_loss\": val['val_loss'], \n                        \"val_acc\": val['val_acc']\n                       })\n    return history","9fb7e0cb":"def to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)","6531169a":"device='cuda'\nmodel = model.to(device)\ntrain_dl = DeviceDataLoader(train_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","c2bb592c":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nepochs = 10\nhistory = fit(train_dl, test_dl, epochs, optimizer, loss_fn, model)","baae3ed6":"history","af704657":"train_loss = [x['loss'] for x in history]\nval_loss = [x['val_loss'] for x in history]\nval_acc = [x['val_acc'] for x in history]","92c2acbe":"train_loss = [x.item() for x in train_loss]\nval_loss = [x.item() for x in val_loss]\nval_acc = [x.item() for x in val_acc]","844c2221":"epoch = np.arange(10)\nplt.plot(epoch, train_loss)\nplt.plot(epoch, val_loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend(['train', 'val']);","89c0ff1b":"epoch = np.arange(10)\nplt.plot(epoch, val_acc)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy');","62c17814":"def evaluate(image):\n    out = model(image)\n    _, pred = torch.max(out, dim=1)\n    return pred","dec41d83":"import os\nds = []\nfor i in os.listdir(PRED_PATH):\n    img = plt.imread(PRED_PATH + \"\/\" + i)\n    ds.append(transform(img))","65a81a5f":"pred_dl = DataLoader(ds, batch_size=32, pin_memory=True, num_workers=8)","f42f046f":"pred_dl = DeviceDataLoader(pred_dl, device)","cbd89ec8":"preds = []\nfor img in pred_dl:\n    out = model(img)\n    _, pred = torch.max(out, dim=1)\n    preds.append(pred.to('cpu').numpy())\n    break","56d78cc3":"classes_pred = [classes[x] for x in preds[0]] ","580e585e":"for img in pred_dl:\n    for i in range(0, 10):\n        plt.imshow(img[i].to('cpu').permute(1, 2, 0))\n        plt.title(classes_pred[i])\n        plt.show()\n    break","b26d8ed9":"Combine the directory into the single one and shuffle it for making the training more better.","5dc72e7e":"# Visualize the Image\nIn this section, we visualize the image using the `matplotlib.pyplot` library.","a19e1aaa":"# Intel Image Classification\nIn this notebook, we create a neural network for predicting the natural scenes around the world. We use the tensorflow library for creating the neural network. Size of the image is 150 x 150 with around 25k images. We have 6 different classes with buildings, forest, glacier, mountain, sea, street.","da408cb8":"# Train the Model\nIn this section, we train the model and load the `train_dl` and `test_dl` to GPU for fast processing.","4f849ea9":"# Create a Model\nIn this section, we create a neural network using the different layers"}}