{"cell_type":{"917c18aa":"code","66f64b9e":"code","19188239":"code","2e06936d":"code","887d90c6":"code","c19eba96":"code","e5051e4c":"code","2f84e43a":"code","ba168765":"code","4b611627":"code","3871e15d":"code","d8a1d570":"code","47ce6054":"code","9715ddb5":"code","6227141f":"code","e7e01618":"code","1329c2a5":"code","86c7c891":"code","b509e662":"code","3a2364aa":"code","8f1223bb":"code","e09270a3":"code","aa7b4dce":"code","cb89fbd5":"code","9113d9d7":"code","4de41df0":"code","c117b0b4":"code","b8006cf4":"code","47e4ab8c":"code","e0402ad7":"code","cb83e122":"code","d552ac09":"code","8942363e":"code","ea2fd862":"code","d0448a12":"code","81a759eb":"markdown","08d04047":"markdown","c181c7ad":"markdown","4e15ac5b":"markdown","b0360adb":"markdown","42c545e4":"markdown","31470f7e":"markdown","797814b2":"markdown","36b120fb":"markdown","95ff865d":"markdown","987c3c81":"markdown"},"source":{"917c18aa":"try:\n    !pip install scikit-image\n    !pip install pydotplus\n    !pip install openpyxl\nexcept:\n    None\n\nfrom sklearn.metrics import silhouette_score, mean_absolute_error, mean_squared_error, confusion_matrix, accuracy_score, classification_report, f1_score, roc_curve, roc_auc_score\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split,GridSearchCV,cross_val_score, cross_val_predict\nfrom sklearn.ensemble import BaggingClassifier,RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import LinearRegression,  SGDClassifier, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom sklearn.cluster import AgglomerativeClustering, KMeans\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.feature_selection import RFE, SelectKBest, chi2\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom sklearn.preprocessing import StandardScaler\nfrom xml.etree import cElementTree as ElementTree\nimport openpyxl\nfrom keras_preprocessing.image import ImageDataGenerator\n# from sklearn.externals.six import StringIO  \nfrom six import StringIO\nfrom sklearn.naive_bayes import GaussianNB\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.decomposition import NMF, TruncatedSVD\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom IPython.display import Image  \nimport matplotlib.pyplot as plt\nfrom sklearn import metrics \nfrom joblib import dump, load\nimport requests, zipfile, io\nfrom sklearn import svm\nimport numpy as np\nfrom numpy import mean, std\nimport seaborn as sns\nimport cv2\nimport scipy.io\nimport pandas as pd\nimport pydotplus\nimport os\nfrom glob import glob\nfrom PIL import Image\nfrom math import sqrt\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nimport skimage\nfrom skimage import segmentation\n\n","66f64b9e":"#%% functionfor extract the image's mask from xml extensi\u00f3n file. \ndef fun2(pathxml,pathimg, img_path, label_path,img_path_nerve, label_path_nerve):\n  tree = ElementTree.parse(pathxml)\n  root = tree.getroot()\n  xy=[]\n  d={}\n  i=0\n  for element in root:\n    if len(element)==0:\n      d[str(element.tag)]=str(element.text)\n    else: \n      d[str(element.tag)]={}\n    for sub in element:\n      if len(sub)==0:\n        d[str(element.tag)][str(sub.tag)]=str(sub.text)\n      else:\n        d[str(element.tag)][str(sub.tag)]={}\n      for sub2 in sub:\n        if len(sub2)==0:\n          d[str(element.tag)][str(sub.tag)][str(sub2.tag)]=str(sub2.text)\n        else:\n          if str(sub2.tag)==\"pt\":\n            i+=1\n            d[str(element.tag)][str(sub.tag)][str(sub2.tag)+str(i)]={\"x\":sub2[0].text,\"y\":sub2[1].text}\n            xy.append((sub2[0].text,sub2[1].text))\n  pts = np.asarray(xy,np.int32)\n  img=plt.imread(pathimg)\n  img_poly = plt.imread(pathimg)\n  img_labels = np.zeros((img[:,:,0].shape),dtype=np.uint8)\n  cv2.fillPoly(img_poly,[pts], (255,0,0));  \n  indices=np.where(np.all(img_poly== (255,0,0),axis=-1)) \n  img_labels[indices[0],indices[1]] = 1#255#255#1\n  \n  cv2.imwrite(img_path, img)\n  cv2.imwrite(label_path, img_labels)\n\n  cv2.imwrite(img_path_nerve, img)\n  cv2.imwrite(label_path_nerve, img_labels)","19188239":"FILEID = \"1GewZspflKFgN7Clut5Xqr3E3CQLSfoYU\"\n!wget --load-cookies \/tmp\/cookies.txt \"https:\/\/docs.google.com\/uc?export=download&confirm=$(wget --quiet --save-cookies \/tmp\/cookies.txt --keep-session-cookies --no-check-certificate 'https:\/\/docs.google.com\/uc?export=download&id='$FILEID -O- | sed -rn 's\/.*confirm=([0-9A-Za-z_]+).*\/\\1\\n\/p')&id=\"$FILEID -O ImagenesNervios.zip && rm -rf \/tmp\/cookies.txt","2e06936d":"from zipfile import ZipFile\nfile_name = \".\/ImagenesNervios.zip\"\n\nwith ZipFile(file_name, 'r') as zipF:\n  zipF.extractall()\n  print('Done')\n","887d90c6":"# r = requests.get('https:\/\/github.com\/HaroldMDiazVargas\/NerveProject\/blob\/main\/ImagenesNervios.zip?raw=true') \n# z = zipfile.ZipFile(io.BytesIO(r.content))\n# z.extractall()","c19eba96":"# !mkdir ImagenesNervios\/data\n# !mkdir ImagenesNervios\/ciatico\n# !mkdir ImagenesNervios\/cubital\n# !mkdir ImagenesNervios\/mediano\n# !mkdir ImagenesNervios\/femoral\n\n# nerve = {0:'ciatico',9:'cubital',14:'mediano',17:'femoral'}\n\n# total_img = 0\n# nerve_img = 0\n# j = 0\n# for i in range(22):\n  \n#   if i == 0 or i == 9 or i == 14 or i == 17:\n#     nerve_img = 0\n#     act_nerv = nerve[i]\n#     j = j+1\n#   # path = \"P\"+str(i+1)+\"_\"+act_nerv\n#   path = \".\/ImagenesNervios\/\"+\"P\"+str(i+1)+\"_\"+act_nerv+\"\/\"\n#   xml_name = [pos_xml for pos_xml in os.listdir(path) if pos_xml.endswith('.xml')]\n  \n#   for xml_file in xml_name:\n#     nerve_img = nerve_img + 1\n#     total_img = total_img + 1\n#     img_path = \".\/ImagenesNervios\/data\/\"+act_nerv+'_'+str(total_img)+'.png'\n#     label_path = \".\/ImagenesNervios\/data\/\"+act_nerv+'_'+str(total_img)+'_mask.png'\n#     img_path_nerve = \".\/ImagenesNervios\/\"+act_nerv+\"\/\"+str(nerve_img)+'.png'\n#     label_path_nerve = \".\/ImagenesNervios\/\"+act_nerv+\"\/\"+str(nerve_img)+'_mask.png'\n#     path_xml = path+xml_file\n#     path_img = path+xml_file[0:-4]+\".jpg\"\n#     fun2(path_xml,path_img, img_path, label_path,img_path_nerve, label_path_nerve)","e5051e4c":"# !mkdir Images\n# !mv .\/ImagenesNervios\/data\/ .\/Images\/data","2f84e43a":"# file_images = glob('.\/Images\/data\/*.png')\nfile_images = glob('.\/ImagenesNervios_\/*.png')\n# file_images","ba168765":"# file_images.sort()\n# filepath_image = [] # s\u00f3lo imagenes\n# filepath_mask = [] # mascaras\n# nerve_name = []\n# for filepath in [filepath_ for filepath_ in file_images if 'mask' not in filepath_]:\n#   mask = filepath[:-4]+'_mask.png'\n#   if mask in file_images:\n#     filepath_image.append(filepath)\n#     filepath_mask.append(mask)\n\n#     if 'ciatico' in filepath:\n#       nerve_name.append('ciatico')\n#     elif 'cubital' in filepath:\n#       nerve_name.append('cubital')\n#     elif 'femoral' in filepath:\n#       nerve_name.append('femoral')\n#     elif 'mediano' in filepath:\n#       nerve_name.append('mediano')\n\n# df = pd.DataFrame({'filepath':filepath_image,'nerve_name':nerve_name,'mask':filepath_mask})\n# t = df['nerve_name']\n# df.head()","4b611627":"file_images.sort()\nfilepath_image = [] # s\u00f3lo imagenes\nfilepath_mask = [] # mascaras\nnerve_name = []\nfor filepath in [filepath_ for filepath_ in file_images if 'mask' not in filepath_]:\n  mask = filepath[:-4]+'_mask.png'\n  if mask in file_images:\n    filepath_image.append(filepath)\n    filepath_mask.append(mask)\n\n    if 'ciatico' in filepath:\n      nerve_name.append(1)\n    elif 'cubital' in filepath:\n      nerve_name.append(2)\n    elif 'femoral' in filepath:\n      nerve_name.append(3)\n    elif 'mediano' in filepath:\n      nerve_name.append(4)\n\ndf = pd.DataFrame({'filepath':filepath_image,'nerve_name':nerve_name,'mask':filepath_mask})\nt = df['nerve_name']\ndf.head()","3871e15d":"df","d8a1d570":"df_train_images,df_test_images,t_train,_ = train_test_split(df,t, test_size=0.2,stratify = t)\ndf_train_images,df_val_images,_,_ = train_test_split(df_train_images,t_train, test_size=0.2,stratify = t_train)","47ce6054":"img = cv2.imread(filepath_image[0])\nmask = cv2.imread(filepath_mask[0])\nheight,width,_ = img.shape\nprint(height,'x',width)\nplt.subplot(1,2,1)\nplt.imshow(img)\nplt.subplot(1,2,2)\nplt.imshow(mask*255,cmap='gray')\nplt.show()","9715ddb5":"df_train_images","6227141f":"def train_generator(data_frame, batch_size, train_path, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = 'filepath',\n        y_col = 'nerve_name',\n        classes = [1,2,3,4],\n        class_mode = 'raw',\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    # for (img, mask) in train_gen:\n    #     img, mask = adjust_data(img, mask)\n    #     yield (img,mask)\n\n# def adjust_data(img,mask):\n#     img = img \/ 255\n#     #mask = mask \/ 255\n#     mask[mask > 0.5] = 1\n#     mask[mask <= 0.5] = 0\n    \n#     return (img, mask)\n\n\n\n    for (img, mask) in train_gen:\n        img, input_mtrx,mask = adjust_data(img, mask)\n        yield ((img,input_mtrx),mask)\n\ndef adjust_data(img_t,mask):\n    img = img_t[0] \/ 255\n    #mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    tipo_nervio = img_t[1]\n\n    input_mtrx = np.zeros((len(tipo_nervio),8,8,120))\n    for i in range(4):\n        index = np.where(tipo_nervio == i+1)\n        for j in range(len(index[0])):\n            input_mtrx[index[0][j],:,:,:] = i+1\n    # print(input_mtrx.shape)\n    return (img,input_mtrx, mask)","e7e01618":"def preprocessing_mask(mask):\n  mask[mask > 0.5] = 255\n  mask[mask <= 0.5] = 0\n  return mask\n\n# def adjust_data(img_t,mask):\n#   img = img_t[0] \/ 255\n#   #mask = mask \/ 255\n#   mask[mask > 0.5] = 1\n#   mask[mask <= 0.5] = 0\n#   tipo_nervio = img_t[1]\n\n#   input_mtrx = np.zeros((len(tipo_nervio),8,8,4))\n#   for i in range(4):\n#     index = np.where(tipo_nervio == i)\n#     for j in range(len(index[0])):\n#       input_mtrx[index[0][j],:,:,i] = 1\n#   # print(input_mtrx.shape)\n#   return (img,input_mtrx, mask)","1329c2a5":"seed = 1993\nbatch_size = 32\nheight,width = 128,128\ntrain_generator_args = dict(rotation_range=10,\n                            horizontal_flip =True,\n                            vertical_flip=True)\n                            # fill_mode='nearest')\n\n\ntrain_gen = train_generator(df_train_images, batch_size,\n                            None,\n                            train_generator_args,\n                            target_size=(height, width))\n\nval_gen = train_generator(df_val_images, batch_size,\n                            None,\n                            # dict(),\n                            train_generator_args,\n                            target_size=(height, width))\n\ntest_gen = train_generator(df_test_images, batch_size,\n                            None,\n                            dict(),\n                            target_size=(height, width))","86c7c891":"# seed = 1993\n# batch_size = 32\n# height,width = 256,256\n# image_datagen = ImageDataGenerator(rotation_range=10,\n#                                    horizontal_flip =True,\n#                                    vertical_flip=True,\n#                                    rescale=1.\/255)\n\n# image_datagen_mask = ImageDataGenerator(rotation_range=10,\n#                                    horizontal_flip =True,\n#                                    vertical_flip=True,\n#                                    rescale=1.\/255,\n#                                    preprocessing_function = preprocessing_mask)\n\n# generator_train_img = image_datagen.flow_from_dataframe(df_train_images,\n#                                                         x_col = 'filepath',\n#                                                         y_col = 'nerve_name',\n#                                                         classes = [0,1,2,3],\n#                                                         color_mode = \"rgb\",\n#                                                         batch_size = batch_size,\n#                                                         class_mode = None, #raw?\n#                                                         directory = None,\n#                                                         target_size = (height,width),\n#                                                         seed = seed)\n\n# generator_train_mask = image_datagen_mask.flow_from_dataframe(df_train_images,\n#                                                          x_col='mask',\n#                                                          class_mode = None,\n#                                                          directory = None,\n#                                                          color_mode=\"grayscale\", \n#                                                          batch_size = batch_size,\n#                                                          target_size = (height,width),\n#                                                          seed = seed)\n\n# train_gen = zip(generator_train_img,generator_train_mask)\n\n# for (img, mask) in train_gen:\n#   img, input_mtrx,mask = adjust_data(img, mask)\n#   yield ((img,input_mtrx),mask)\n# generator_val_img = image_datagen.flow_from_dataframe(df_val_images,\n#                                                         x_col='filepath',\n#                                                         y_col = 'nerve_name',\n#                                                         classes = [0,1,2,3],\n#                                                         color_mode = \"rgb\",\n#                                                         class_mode = None,\n#                                                         directory = None,\n#                                                         target_size = (height,width),\n#                                                         batch_size = batch_size,\n#                                                         seed = seed)\n\n# generator_val_mask = image_datagen_mask.flow_from_dataframe(df_val_images,\n#                                                          x_col='mask',\n#                                                          class_mode = None,\n#                                                          directory = None,\n#                                                          color_mode=\"grayscale\",\n#                                                          target_size = (height,width),\n#                                                          batch_size = batch_size,\n#                                                          seed = seed)\n\n# val_gen = zip(generator_val_img,generator_val_mask)\n\n# for (img, mask) in val_gen:\n#   img, input_mtrx,mask = adjust_data(img, mask)\n#   yield ((img,input_mtrx),mask)\n\n# generator_test_img = image_datagen.flow_from_dataframe(df_test_images,\n#                                                         x_col='filepath',\n#                                                         y_col = 'nerve_name',\n#                                                         classes = [0,1,2,3],\n#                                                         color_mode = \"rgb\",\n#                                                         class_mode = None,\n#                                                         directory = None,\n#                                                         target_size = (height,width),\n#                                                         batch_size = batch_size,\n#                                                         seed = seed)\n\n# generator_test_mask = image_datagen_mask.flow_from_dataframe(df_test_images,\n#                                                          x_col='mask',\n#                                                          class_mode = None,\n#                                                          directory = None,\n#                                                          color_mode=\"grayscale\",\n#                                                          target_size = (height,width),\n#                                                          batch_size = batch_size,\n#                                                          seed = seed)\n\n# test_gen = zip(generator_test_img,generator_test_mask)\n\n# for (img, mask) in test_gen:\n#   img, input_mtrx,mask = adjust_data(img, mask)\n#   yield ((img,input_mtrx),mask)\n","b509e662":"i,j = next(train_gen)\n\nplt.imshow(i[0][0])\nedges_est = segmentation.clear_border(j[0,:,:,0])\nplt.contour(edges_est,[0.5])\nplt.show()","3a2364aa":"i[0][0].shape","8f1223bb":"def dice_coef(y_true, y_pred, smooth = 1.):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef renny_entropy(ytrue,ypred):\n    Ke = tf.matmul(ypred,ypred,transpose_b=True)\n    Ke = Ke\/tf.linalg.trace(Ke)\n    #entropy_renny  = (1\/(1-2))*tf.math.log((1\/tf.constant(32*32,dtype=ypred.dtype))*tf.linalg.trace(tf.matmul(Ke,Ke,transpose_a=True)))\n    entropy_renny = tf.constant(1\/(1-2))*tf.linalg.trace(tf.matmul(Ke,Ke,transpose_a=True))\n    return entropy_renny\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred, smooth = 1.):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true) + K.sum(y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef iou_np(mask,mask_est,smooth=1):\n  inter = np.sum(mask*mask_est)\n  sum__ = np.sum(mask) + np.sum(mask_est)\n  return (inter + smooth)\/(sum__ - inter + smooth)\n\ndef sensitivity(y_true, y_pred):\n    s = K.sum(y_true, axis=(1,2,3))\n    y_true_c = s \/ (s + K.epsilon())\n    s_ = K.sum(y_pred, axis=(1,2,3))\n    y_pred_c = s_ \/ (s_ + K.epsilon())\n   \n    true_positives = K.sum(K.round(K.clip(y_true_c * y_pred_c, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true_c, 0, 1)))\n    return true_positives \/ (possible_positives + K.epsilon())\n\ndef specificity(y_true, y_pred):\n    s = K.sum(y_true, axis=(1,2,3))\n    y_true_c = s \/ (s + K.epsilon())\n    s_ = K.sum(y_pred, axis=(1,2,3))\n    y_pred_c = s_ \/ (s_ + K.epsilon())\n    \n    true_negatives = K.sum(K.round(K.clip((1-y_true_c) * (1-y_pred_c), 0, 1)))#123456789\n# path = \".\/ImagenesNervios\/data\/\"data_image = [] data_mask = glob(path + '*_mask*') for i in data_mask:  data_image.append(i.replace('_mask', '')) print(\"Cantidad total de datos:\",len(data_image))\n\n    possible_negatives = K.sum(K.round(K.clip(1-y_true_c, 0, 1)))\n    return true_negatives \/ (possible_negatives + K.epsilon())","e09270a3":"514*8","aa7b4dce":"50*25","cb89fbd5":"UPSAMPLE_MODE = 'SIMPLE' # SIMPLE'\nNET_SCALING = None\nGAUSSIAN_NOISE = 0.1\nEDGE_CROP = 16\nACTIVATION = 'relu'\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.layers.experimental import RandomFourierFeatures\n# Build U-Net model\ndef upsample_conv(filters, kernel_size, strides, padding):\n    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\ndef upsample_simple(filters, kernel_size, strides, padding):\n    return layers.UpSampling2D(strides)\n\nif UPSAMPLE_MODE=='DECONV':\n    upsample=upsample_conv\nelse:\n    upsample=upsample_simple\n\ndef create_model(phi_units = 2):\n  input_img = layers.Input((width,height,3), name = 'RGB_Input')\n  cond_input = layers.Input(shape=[8,8,120], name = 'Cond_Input')\n  pp_in_layer = input_img\n\n  if NET_SCALING is not None:\n      pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n      \n  # pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n  pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n\n  c1 = layers.Conv2D(8, (3, 3), activation=ACTIVATION, padding='same') (pp_in_layer)\n  c1 = layers.BatchNormalization()(c1)\n  c1 = layers.Conv2D(8, (3, 3), padding='same') (c1)\n  c1 = layers.BatchNormalization()(c1)\n  p1 = layers.MaxPooling2D((2, 2)) (c1)\n\n  c2 = layers.Conv2D(16, (3, 3), activation=ACTIVATION, padding='same') (p1)\n  c2 = layers.BatchNormalization()(c2)\n  c2 = layers.Conv2D(16, (3, 3), padding='same') (c2)\n  c2 = layers.BatchNormalization()(c2)\n  p2 = layers.MaxPooling2D((2, 2)) (c2)\n\n  c3 = layers.Conv2D(32, (3, 3), activation=ACTIVATION, padding='same') (p2)\n  c3 = layers.BatchNormalization()(c3)\n  c3 = layers.Conv2D(32, (3, 3), padding='same') (c3)\n  c3 = layers.BatchNormalization()(c3)\n  p3 = layers.MaxPooling2D((2, 2)) (c3)\n\n  c4 = layers.Conv2D(64, (3, 3), activation=ACTIVATION, padding='same') (p3)\n  c4 = layers.BatchNormalization()(c4)\n  c4 = layers.Conv2D(64, (3, 3), padding='same') (c4)\n  c4 = layers.BatchNormalization()(c4)\n  p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n    \n#   combined = layers.concatenate([p4,cond_input],axis=3)\n  #%% Modified by CAJ\n  flatten = layers.Flatten()(p4)\n  rff = RandomFourierFeatures(output_dim=int(height\/16)*int(width\/16)*phi_units,trainable=True,name = 'Phi')(flatten)\n  resha = layers.Reshape((int(height\/16),int(width\/16),-1))(rff)\n  #%% End modify\n  c5 = layers.Conv2D(128, (3, 3), activation=ACTIVATION, padding='same') (resha)#(p4)\n  c5 = layers.BatchNormalization()(c5)\n  c5 = layers.Conv2D(128, (3, 3), activation=ACTIVATION, padding='same') (c5)\n  c5 = layers.BatchNormalization()(c5)\n\n  combined = layers.concatenate([c5,cond_input],axis=3)\n\n  u6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (combined)#combined\n  u6 = layers.concatenate([u6, c4])\n  c6 = layers.Conv2D(64, (3, 3), activation=ACTIVATION, padding='same') (u6)\n  c6 = layers.BatchNormalization()(c6)\n  c6 = layers.Conv2D(64, (3, 3), activation=ACTIVATION, padding='same') (c6)\n  c6 = layers.BatchNormalization()(c6)\n    \n#   combined = layers.concatenate([c6,cond_input],axis=3)\n\n  u7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\n  u7 = layers.concatenate([u7, c3])\n  c7 = layers.Conv2D(32, (3, 3), activation=ACTIVATION, padding='same') (u7)\n  c7 = layers.BatchNormalization()(c7)\n  c7 = layers.Conv2D(32, (3, 3), activation=ACTIVATION, padding='same') (c7)\n  c7 = layers.BatchNormalization()(c7)\n\n#   combined = layers.concatenate([c7,cond_input],axis=3)\n\n  u8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)#c7\n  u8 = layers.concatenate([u8, c2])\n  c8 = layers.Conv2D(16, (3, 3), activation=ACTIVATION, padding='same') (u8)\n  c8 = layers.BatchNormalization()(c8)\n  c8 = layers.Conv2D(16, (3, 3), activation=ACTIVATION, padding='same') (c8)\n  c8 = layers.BatchNormalization()(c8)\n\n#   combined = layers.concatenate([c8,cond_input],axis=3)\n\n  u9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)#c8\n  u9 = layers.concatenate([u9, c1], axis=3)\n  c9 = layers.Conv2D(8, (3, 3), activation=ACTIVATION, padding='same') (u9)\n  c9 = layers.BatchNormalization()(c9)\n  c9 = layers.Conv2D(8, (3, 3), activation=ACTIVATION, padding='same') (c9)\n  c9 = layers.BatchNormalization()(c9)\n\n  d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n  d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n  d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP),name='output')(d)\n  if NET_SCALING is not None:\n      d = layers.UpSampling2D(NET_SCALING)(d)\n\n  seg_model = models.Model(inputs=[input_img,cond_input], outputs=[d])\n  # inputs=[inputs,vector_input]\n  return seg_model\n\nseg_model = create_model(64)\n\nseg_model.summary()","9113d9d7":"tf.keras.utils.plot_model(seg_model,show_shapes=True)","4de41df0":"# tf.keras.utils.plot_model(seg_model,show_shapes=True)","c117b0b4":"# for path_file,mask_file,class_file in zip(filesname,masks_files,test_t):\n#     print(path_file,\" \",class_file)","b8006cf4":"from sklearn.metrics import accuracy_score,balanced_accuracy_score,f1_score,roc_auc_score,confusion_matrix,recall_score\nfrom joblib import dump\nimport pandas as pd\nimport os\n\n\ndict_nerve = {0:'ciatico',1:'cubital',2:'mediano',3:'femoral'}\nEPOCHS = 200\nBATCH_SIZE = batch_size\n\na = 1\nphi_units = 2\nmetrics = [iou, dice_coef, sensitivity, specificity, 'binary_accuracy']\n\nexcel_write = pd.ExcelWriter('results.xlsx')\n\nfor phi_units in [64]:\n  pass_b = False\n  results_template = 'results_a-{}_phi-units-{}' # string template\n  basepath = results_template.format(a,phi_units)\n  try:\n    os.mkdir(basepath)\n  except:\n    pass\n\n\n  try:\n    tf.keras.backend.clear_session()\n    seg_model = create_model(phi_units)\n  except:\n    pass_b = True\n  \n  if pass_b:\n    pass\n  else:\n    seg_model.compile(optimizer=Adam(lr=1e-3),\n                      loss=dice_coef_loss,\n                      metrics = metrics)\n\n    callbacks = [tf.keras.callbacks.ModelCheckpoint(basepath+'\/Model_Checkpoint',\n                                                    monitor='val_loss',\n                                                    verbose=0,\n                                                    mode = 'min')]\n\n    history = seg_model.fit(train_gen,\n                            steps_per_epoch=len(df_train_images) \/\/ BATCH_SIZE, \n                            epochs=EPOCHS, \n                            callbacks=callbacks,\n                            validation_data = val_gen,\n                            validation_steps=len(df_val_images) \/\/ BATCH_SIZE)\n\n    seg_model = tf.keras.Model(inputs = [seg_model.input],outputs=[seg_model.output[0]])\n\n\n    plt.plot(history.history['loss'],label = '-Dice')\n    plt.plot(history.history['val_loss'],label = 'Val -Dice')\n    plt.legend()\n    plt.savefig(basepath+'\/LearningCurve.png')\n    plt.show()\n\n\n    seg_model.save(basepath+'\/model.h5')\n    ## Calculo de metricas de rendimiento. \n\n\n    filesname = df_test_images['filepath'].to_list()\n    masks_files = df_test_images['mask'].to_list()\n    test_t = df_test_images['nerve_name'].to_list()\n\n    Acc = []\n    Dice = []\n    GM = []\n    Sen = []\n    Spe = []\n    AUC = []\n    CM = []\n    IOU = []\n#     for path_file,mask_file in zip(filesname,masks_files):\n    for path_file,mask_file,class_file in zip(filesname,masks_files,test_t):\n      image1 = np.array(Image.open(path_file).resize((height,width)))\n      mask = np.array(Image.open(mask_file).resize((height,width))).reshape(-1,)\n      inp2 = class_file\n      input_mtrx = np.zeros((8,8,120))\n      input_mtrx[:,:,:] = inp2\n      input_mtrx= input_mtrx[np.newaxis, :, :, :]\n#       mask_est = np.squeeze(seg_model.predict(np.expand_dims(image1,0)\/255).astype(np.uint8)).reshape(-1,)4\n      mask_est = np.squeeze(seg_model.predict([np.expand_dims(image1,0)\/255,input_mtrx]).astype(np.uint8)).reshape(-1,)\n# model_cond.predict([img,input_mtrx])\n      CM.append(confusion_matrix(mask,mask_est,labels=[0,1]))\n      Acc.append(accuracy_score(mask,mask_est))\n      sen = recall_score(mask,mask_est,pos_label=1)\n      spe = recall_score(mask,mask_est,pos_label=0)\n      Sen.append(sen)\n      Spe.append(spe)\n      GM.append(sqrt(sen*spe))\n      Dice.append(f1_score(mask,mask_est,pos_label=1))\n      AUC.append(roc_auc_score(mask,mask_est))\n      IOU.append(iou_np(mask,mask_est))\n\n    mdict = {'Acc':Acc,\n            'GM': GM,\n            'IOU':IOU,\n            'Dice':Dice,\n            'AUC':AUC,\n            'Sen':Sen,\n            'Spe':Spe,\n            'nerve_name':test_t}\n\n    pd.DataFrame(mdict).to_excel(excel_write,sheet_name='a-{}__phi-{}'.format(a,phi_units))\n\n    plt.boxplot([Acc,GM,Dice,IOU,Sen,Spe,AUC])\n    plt.xticks([1,2,3,4,5,6,7],['Acc','GM','Dice','IOU','Sen','Spe','AUC'])\n    plt.savefig(basepath+'\/Boxplot_all')\n    plt.show()\n\n    # for name_nerve in ['ciatico','cubital','femoral','mediano']:\n    for name_nerve in [0,1,2,3]:\n      Acc_aux = [Acc[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      Sen_aux = [Sen[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      Spe_aux = [Spe[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      Dice_aux = [Dice[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      GM_aux = [GM[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      AUC_aux = [AUC[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      IOU_aux = [IOU[i] for i in range(len(Acc)) if test_t[i]==name_nerve]\n      plt.boxplot([Acc_aux,GM_aux,Dice_aux,IOU_aux,Sen_aux,Spe_aux,AUC_aux])\n      plt.xticks([1,2,3,4,5,6,7],['Acc','GM','Dice','IOU','Sen','Spe','AUC'])\n      plt.title(dict_nerve[name_nerve])\n      plt.savefig(basepath+'\/Boxplot_{}'.format(dict_nerve[name_nerve]))\n      plt.show()\n\n    savedata = {'Acc':Acc,\n                'GM':GM,\n                'Dice':Dice,\n                'Sen':Sen,\n                'Spe':Spe,\n                'AUC':AUC,\n                'IOU':IOU,\n                'CM':CM,\n                'train':df_train_images.to_dict(),\n                'test':df_test_images.to_dict(),\n                'val':df_val_images.to_dict()}\n    dump(savedata,basepath+'\/results.joblib')\n  \n  \n\nexcel_write.save()\n","47e4ab8c":"# plt.title(dict_nerve(name_nerve))","e0402ad7":"# dict_nerve(name_nerve)","cb83e122":"# import openpyxl","d552ac09":"!zip -r results_RFF_UNET-Cond .\/results* model.png\n# !zip -r results_UNET-Cond .\/results* model.png","8942363e":"import shutil \nshutil.rmtree('.\/ImagenesNervios_')\n!rm .\/ImagenesNervios.zip\n# !rm \n# shutil.rmtree('.\/Test')","ea2fd862":"# from google.colab import files\n# files.download('.\/results.xlsx')","d0448a12":"# files.download('results.zip')","81a759eb":"## Download Dataset","08d04047":"# Build Model ","c181c7ad":"## Relocate images and mask","4e15ac5b":"<a href=\"https:\/\/colab.research.google.com\/github\/cralji\/RFF-Nerve-UTP\/blob\/main\/RFF-UNET_Nerve-UTP.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","b0360adb":"### original","42c545e4":"# Import Packages","31470f7e":"### Split sets","797814b2":"# Functions ","36b120fb":"## need functions","95ff865d":"### Data generator. ","987c3c81":"# Load Data"}}