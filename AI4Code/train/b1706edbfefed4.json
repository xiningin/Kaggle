{"cell_type":{"eb48b8ee":"code","d026297d":"code","e4734c4d":"code","2c0b0da0":"code","53e27f48":"code","6e28cdfc":"code","74634719":"code","5a168ef9":"code","b7720940":"code","4b173237":"code","b46b82c4":"code","45626e7b":"code","e90b1d87":"code","c2b10d9a":"code","8c20dda4":"code","e4a63082":"code","3ac6767b":"code","ec7adeb6":"code","2cca9ed6":"code","8d3016b3":"code","ae5e716e":"code","682e10b6":"code","e3b404b4":"code","5b66ca71":"code","84a91996":"code","23c2f19c":"code","599b0ff0":"code","9cdae078":"code","4ca50b93":"code","fc961dfb":"code","662c28d1":"code","51837a1c":"code","76ad73a3":"code","2626262f":"code","078bb222":"code","c9ab60dc":"code","9ad64bde":"code","e99aa4c4":"code","61e3b0ea":"code","2018447c":"code","fb7b3ec5":"code","640dd72a":"code","b36af662":"code","dde2787a":"code","1e60f16c":"code","e240e8b5":"code","2232db31":"code","b302989e":"code","3bee9af6":"code","a7d01b00":"code","bb03895f":"code","ceb7b6f8":"code","d45fe0ab":"code","f2346654":"code","f672c1ef":"code","de685674":"code","66181c86":"code","1902c61c":"code","2624b21c":"code","9ed1a7cd":"code","b5267e86":"code","dccc6ca9":"code","84df7780":"code","86788895":"code","71c4c2c4":"code","98551bdc":"code","f5dfbfed":"code","ef3cf7d6":"code","99db2792":"code","d31b5527":"code","67552555":"markdown","a5cda11d":"markdown","a0452601":"markdown","147979d9":"markdown","41c95b70":"markdown","aeeb26b7":"markdown","abdda6ae":"markdown","d36808e5":"markdown","8b7b9d0c":"markdown","e1c6036a":"markdown","0a59e67e":"markdown","1901a9b9":"markdown","012faf22":"markdown","623ed206":"markdown","3f3701f8":"markdown","54e461f3":"markdown","18455bc7":"markdown","fb5b5e54":"markdown","59021c8f":"markdown","f52851f3":"markdown","2393390f":"markdown","b3e69687":"markdown","c3ea2368":"markdown","59e3a09a":"markdown","1472c4a1":"markdown","9fe02f0a":"markdown","9c666900":"markdown","e56c2c38":"markdown","4e553738":"markdown","7e082400":"markdown","bcf7ccf8":"markdown","2a8427cf":"markdown","3d35bf12":"markdown","6122151b":"markdown","8841956d":"markdown","6f09789a":"markdown","0fafc2da":"markdown","0ae4d654":"markdown","a23b3fbd":"markdown","16690742":"markdown","e7bd299a":"markdown","c18e7709":"markdown","6342cc7d":"markdown","2a1cd08f":"markdown","6c084ef5":"markdown","65d6e986":"markdown","846b7638":"markdown","080a1c40":"markdown","b965fda1":"markdown","58849a80":"markdown","54b81453":"markdown","566a0b17":"markdown","48c06500":"markdown","e08fa237":"markdown","2c70ba7d":"markdown","5d0ed88d":"markdown","29fcdce4":"markdown","a6ad576b":"markdown"},"source":{"eb48b8ee":"#import libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split,GridSearchCV,learning_curve,ShuffleSplit\nfrom sklearn.metrics import confusion_matrix,classification_report,roc_curve,roc_auc_score,auc,accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n","d026297d":"df=pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","e4734c4d":"df.isnull().sum()","2c0b0da0":"df.dtypes","53e27f48":"sns.set_style(\"whitegrid\")\nsns.boxplot(x=\"age\",data=df)\nplt.title(\"Box plot showing distribution of age in the dataset\")\nplt.xlabel(\"Age in years\")\n","6e28cdfc":"#lets see the descriptive stats for this box-plot\nIQR=stats.iqr(df[\"age\"],interpolation=\"midpoint\")\nIQR","74634719":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"sex\",data=df)\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"Frequency\",fontsize=14)\n","5a168ef9":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"thal\",data=df)\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"Frequency\",fontsize=14)\nplt.show()","b7720940":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"cp\",data=df,palette=\"Accent\")\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"Frequency\",fontsize=14)\nplt.show()","4b173237":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"exang\",data=df,palette=\"Set2\")\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"Frequency\",fontsize=14)\nplt.show()","b46b82c4":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"fbs\",data=df,palette=\"Set1\")\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"Frequency\",fontsize=14)\nplt.show()","45626e7b":"copy_df=df.copy()\n","e90b1d87":"copy_df['restecg'][copy_df['restecg']==0]='normal'\ncopy_df['restecg'][copy_df['restecg']==1]=\"ST-T wave abnormality\"\ncopy_df['restecg'][copy_df['restecg']==2]=\"left ventricular hypertrophy\"\ncopy_df['slope'].value_counts()","c2b10d9a":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"restecg\",data=copy_df)\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"frequency\",fontsize=14)\nplt.show()","8c20dda4":"copy_df['slope'][copy_df['slope']==0]='downsloping'\ncopy_df['slope'][copy_df['slope']==2]=\"flat\"\ncopy_df['slope'][copy_df['slope']==1]=\"upsloping\"\n","e4a63082":"plt.figure(figsize=(9,9))\nsns.countplot(x=\"target\",hue=\"slope\",data=copy_df,palette=\"Paired_r\")\nplt.xlabel(\"Heart Disease\",fontsize=14)\nplt.ylabel(\"frequency\",fontsize=14)\nplt.show()","3ac6767b":"df.head()","ec7adeb6":"copy_df['sex'][copy_df['sex']==0]=\"female\"\ncopy_df['sex'][copy_df[\"sex\"]==1]=\"male\"","2cca9ed6":"\nplt.figure(figsize=(9,9))\nsns.regplot(x=\"age\",y=\"chol\",data=copy_df)\nsns.scatterplot(x=\"age\",y=\"chol\",data=copy_df,hue=\"sex\",palette=\"flare\")\nplt.xlabel(\"Age\",fontsize=14)\nplt.ylabel(\"Cholestrol\",fontsize=14)\nplt.show()","8d3016b3":"figure,axs=plt.subplots(1,2,figsize=(8,8))\nsns.boxplot(x=\"sex\",y=\"chol\",data=copy_df,palette=\"Set1\",ax=axs[0])\nsns.boxplot(x=\"sex\",y=\"age\",data=copy_df,palette=\"flare_r\",ax=axs[1])\naxs[0].set_xlabel(\"Sex\",fontsize=14)\naxs[0].set_xlabel(\"Cholestrol\",fontsize=14)\naxs[1].set_xlabel(\"Sex\",fontsize=14)\naxs[1].set_xlabel(\"Age\",fontsize=14)\nplt.show()","ae5e716e":"figure,axs=plt.subplots(2,2,figsize=(10,10))\ny_labels=['trestbps','age','thalach','oldpeak']\nindex=0\nfor i,j in zip([0,0,1,1],[0,1,0,1]):\n    sns.stripplot(x=\"target\",y=y_labels[index],hue=\"sex\",data=copy_df,ax=axs[i][j])\n    axs[i][j].set_xlabel(\"heart disease\",fontsize=14)\n    axs[i][j].set_ylabel(y_labels[index],fontsize=14)\n    index+=1\n    \n\nplt.show()","682e10b6":"figure,axs=plt.subplots(2,2,figsize=(10,10))\ny_labels=['trestbps','thalach','oldpeak',\"chol\"]\nindex=0\nfor i,j in zip([0,0,1,1],[0,1,0,1]):\n    sns.scatterplot(x=\"age\",y=y_labels[index],hue=\"target\",data=copy_df,ax=axs[i][j],palette=\"Set1\")\n    axs[i][j].set_xlabel(\"age\",fontsize=14)\n    axs[i][j].set_ylabel(y_labels[index],fontsize=14)\n    index+=1\n    \n\nplt.show()\n","e3b404b4":"numeric_variables=['trestbps','thalach','oldpeak',\"chol\",\"age\",\"target\"]\nsns.pairplot(copy_df[numeric_variables],hue=\"target\",palette=\"Accent\")","5b66ca71":"#converting categorical to dummy\nhot_encoder=OneHotEncoder()\ndummy_columns=[\"cp\",\"restecg\",\"slope\",\"ca\",\"thal\"]\ndummy_df=df[dummy_columns]\nencoded=hot_encoder.fit_transform(dummy_df).toarray()\nfeatures=hot_encoder.get_feature_names(dummy_columns)\n\ndummy_df=pd.DataFrame(encoded,columns=features)\ndummy_df.head()\n\ndf_new=df.drop(dummy_columns,axis=1)\ndf_new=pd.concat((dummy_df,df_new),axis=1)\ndf_new.head()","84a91996":"plt.figure(figsize=(12,12))\nsns.heatmap(data=df_new.corr())\nplt.show()","23c2f19c":"#using pandas to get out of dummy variable trap\ndummy_df=pd.get_dummies(df[dummy_columns].astype(str),drop_first=True)\ndummy_df.head()","599b0ff0":"#constructing a new dataframe\ndf_new =df.drop(dummy_columns,axis=1)\ndf_new=pd.concat((dummy_df,df_new),axis=1)\nplt.figure(figsize=(12,12))\nsns.heatmap(data=df_new.corr())\nplt.show()\n","9cdae078":"# #we will choose best feature from thal_2,thal_3 and slope_2, slope_1\n# features=[\"thal_2\",\"thal_3\",\"slope_2\",\"slope_1\"]\n# for feat in features:\n#     print(df_new[[feat,\"target\"]].corr())\n    \n# #so, thal_2 and slope_2 has higher correlation between target features\n# #dropping thal_3 and slope_1\n# df_new.drop(labels=[\"thal_3\",\"slope_1\"],inplace=True,axis=1)\n# df_new.head()","4ca50b93":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\ny=df_new['target']\nX=df_new.drop(labels='target',axis=1)\nprint(X.shape,y.shape)\n\n#normalizing the data\ncolumns=X.columns\nX=pd.DataFrame(scaler.fit_transform(X),columns=columns)\n\n\n#splitting the data into train and test set\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\nprint(y_train.value_counts())\nprint(y_test.value_counts())","fc961dfb":"X_train.describe().apply(lambda s:s.apply('{0:.5f}'.format))","662c28d1":"C=[0.01,0.03,0.1,0.3,1,3,10,30,100]\ngamma=[0.01,0.03,0.1,0.3,1,3,10,30,100]\nkernel=['rbf','poly','sigmoid']\nparams={'C':C,'gamma':gamma,'kernel':kernel}","51837a1c":"\ngrid_s=GridSearchCV(SVC(),params,verbose=0)\ngrid_s.fit(X_train,y_train)\nprint(grid_s.best_estimator_)\nprint(grid_s.best_params_)","76ad73a3":"#fit the model\nmodel=SVC(C=30,gamma=0.03,kernel=\"sigmoid\")\nmodel.fit(X_train,y_train)\n","2626262f":"#learning curve plotter function\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes,\n                       return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n                         fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt","078bb222":"\nfig, axes = plt.subplots(3, 1, figsize=(10, 15))\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\nplot_learning_curve(model, \"SVC(C=100, gamma=0.01, kernel='sigmoid')\", X_train, y_train, axes=axes, ylim=(0.7, 1.01),\n                    cv=cv, n_jobs=4)","c9ab60dc":"#some helper functions\n#accuracy score\ndef score(y_test,predictions):\n    print(classification_report(y_test,predictions))\n    print(pd.DataFrame(predictions).value_counts())\n    print(\"Accuracy score ={score}\".format(score=accuracy_score(y_test,predictions)))\n\n#confusion matrix plotter\ndef plot_matrix(y_test,predictions):\n    matrix=confusion_matrix(y_test,predictions)\n    matrix=matrix.transpose()\n    cm_df=pd.DataFrame(matrix,index=[\"Healthy\",\"Heart Disease\"],columns=[\"Healthy\",\"Heart Disease\"])\n    sns.heatmap(cm_df,annot_kws={\"size\":16},annot=True,fmt=\"d\")\n\n#roc curve plotter\ndef plot_roc(y_test,predictions):\n    actual_vals=pd.DataFrame(pd.get_dummies(y_test))\n    predictions=pd.DataFrame(pd.get_dummies(predictions))\n    print('0: {}'.format(predictions[predictions[0]==1][0].sum()))\n    print('1 :{}'.format(predictions[predictions[1]==1][1].sum()))\n    predictions.head()\n    #compute roc curve and roc area for each curve\n    fpr=dict()\n    tpr=dict()\n    roc_auc=dict()\n    n_classes=2\n\n    #loop for each class\n    for i in range(n_classes):\n        fpr[i],tpr[i],_=roc_curve(actual_vals.iloc[:,i],predictions.iloc[:,i])\n        roc_auc[i]=auc(fpr[i],tpr[i])\n    #micro-average roc curve\n    fpr[\"micro\"],tpr[\"micro\"],_=roc_curve(actual_vals.to_numpy().ravel(),predictions.to_numpy().ravel())\n    roc_auc[\"micro\"]=auc(fpr[\"micro\"],tpr[\"micro\"])\n    \n    colors = [ 'darkorange', 'cornflowerblue']\n    #main plotter\n    lw=2\n    plt.figure(figsize=(10,8))\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n    labels=['Healthy','Heart Disease']\n    for i,color in zip(range(n_classes),colors):\n         plt.plot(fpr[i], tpr[i], color=color,lw=lw,label='ROC curve of class {0} {name} (area = {area:0.2f})'\n                 ''.format(i, name=labels[i],area=roc_auc[i]))\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve for heart disease prediction')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    ","9ad64bde":"predictions=model.predict(X_test)\nscore(y_test,predictions)","e99aa4c4":"#confusion matrix\nplot_matrix(y_test,predictions)","61e3b0ea":"#roc curve\nplot_roc(y_test,predictions)","2018447c":"model=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\npredictions=model.predict(X_test)\nscore(y_test,predictions)","fb7b3ec5":"params = {\n    'max_depth': [2, 3, 5, 10, 20],\n    'min_samples_leaf': [5, 10, 20, 50, 100],\n    'criterion': [\"gini\", \"entropy\"]\n}\n\n\n#hyper parameter tuning using grid search\ngrid_s=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=params,cv=4,n_jobs=-1,verbose=1,scoring=\"accuracy\")\ngrid_s.fit(X_train,y_train)","640dd72a":"print(grid_s.best_params_)\nprint(grid_s.best_estimator_)","b36af662":"model=DecisionTreeClassifier(max_depth=10, min_samples_leaf=5,criterion=\"gini\")\nmodel.fit(X_train,y_train)","dde2787a":"from sklearn import tree\nfig = plt.figure(figsize=(20,20))\nout= tree.plot_tree(model,\n                   feature_names=X_train.columns,\n                   class_names=['Healthy', \"Heart Disease\"],\n                   filled=True)\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor('red')\n        arrow.set_linewidth(3)\n","1e60f16c":"predictions=model.predict(X_test)\nscore(y_test,predictions)","e240e8b5":"plot_matrix(y_test,predictions)","2232db31":"plot_roc(y_test,predictions)","b302989e":"model=LogisticRegression()\nmodel.fit(X_train,y_train)\npredictions=model.predict(X_test)\nscore(y_test,predictions)","3bee9af6":"C=[0.01,0.03,0.1,0.3,1,3,10,30,100]\npenalty=[\"l1\", \"l2\", \"elasticnet\"]\n\nparams={'C':C,'penalty':penalty}\n\n#hyper parameter tuning using grid search\ngrid_s=GridSearchCV(estimator=LogisticRegression(),param_grid=params,cv=4,n_jobs=-1,verbose=1,scoring=\"accuracy\")\ngrid_s.fit(X_train,y_train)","a7d01b00":"print(grid_s.best_estimator_)\nprint(grid_s.best_params_)\n","bb03895f":"model=LogisticRegression(C=1,penalty='l2')\nmodel.fit(X_train,y_train)","ceb7b6f8":"fig, axes = plt.subplots(3, 1, figsize=(10, 15))\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\nplot_learning_curve(model, \"LogisticRegression(C=1, penalty=l2)\", X_train, y_train, axes=axes, ylim=(0.7, 1.01),\n                    cv=cv, n_jobs=4)","d45fe0ab":"predictions=model.predict(X_test)\nscore(y_test,predictions)","f2346654":"plot_matrix(y_test,predictions)","f672c1ef":"plot_roc(y_test,predictions)","de685674":"from sklearn.ensemble import RandomForestClassifier","66181c86":"model=RandomForestClassifier()\nmodel.fit(X_train,y_train)\npredictions=model.predict(X_test)\nscore(y_test,predictions)","1902c61c":"# parameters_dict = {'n_estimators':[3,5,10,20,25,30,40,60,70,100],'max_features':[\"auto\",\"sqrt\",\"log2\"]\n#                   ,\"max_depth\": [2,5,6,10,None],\"criterion\":[\"gini\",\"entropy\"], \"min_samples_split\" : [0.1, 0.2, 0.3, 0.4,0.9,2],\n#                   \"min_samples_leaf\" :[0.1, 0.2, 0.3, 0.4,1]}\n# grid_s=GridSearchCV(RandomForestClassifier(n_jobs=-1,random_state=1),param_grid=parameters_dict,verbose=0)\n# grid_s.fit(X_train,y_train)\n","2624b21c":"print(grid_s.best_estimator_)","9ed1a7cd":"model=RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=20,\n                       n_jobs=-1, random_state=1)\nmodel.fit(X_train,y_train)","b5267e86":"predictions=model.predict(X_test)\nscore(y_test,predictions)","dccc6ca9":"plot_matrix(y_test,predictions)","84df7780":"plot_roc(y_test,predictions)","86788895":"import tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","71c4c2c4":"ann=Sequential()\nann.add(Dense(activation=\"relu\",input_dim=22,units=4,kernel_initializer=\"uniform\"))\nann.add(Dense(activation=\"relu\",units=18,kernel_initializer=\"uniform\"))\nann.add(Dense(activation=\"sigmoid\",units=1,kernel_initializer=\"uniform\"))\nann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])","98551bdc":"ann.fit(X_train,y_train,batch_size=8,epochs=100)","f5dfbfed":"preds=ann.predict(X_test)\npreds=(preds>0.5)\npreds=[int(ele[0])for ele in preds.tolist()]\npreds=np.array(preds)\n","ef3cf7d6":"score(y_test,preds)","99db2792":"plot_matrix(y_test,preds)","d31b5527":"plot_roc(y_test,preds)","67552555":"<p>So, now we are done with basic categorical understanding. Let's get started with the quantitative variable analysis<\/p>","a5cda11d":"<h2>SVM<\/h2>","a0452601":"<h2>Predictions and accuracy <\/h2>","147979d9":"<h2>Roc Curve<\/h2>","41c95b70":"<p> Well, I found some important points regarding the so called thal variable in this dataset. Check it out so that we can infer better from the graph.\n    <ul>\n        <li>0 maps to null in the original dataset.<\/li>\n        <li>1 maps to 6 in the original dataset. This means that a fixed defect was found.<\/li>\n        <li> 2 maps to 3 in the original dataset. This means that the blood flow was normal.<\/li>\n        <li> 3 maps to 7 in the original dataset. This means that a reversible defect was found.<\/li>\n<\/ul>\n        <\/p>","aeeb26b7":"<p>We will use hyper-parameter tuning to find the best params for the svc classifier<\/p>","abdda6ae":"<h2>ROC Curve<\/h2>","d36808e5":"<p> Observations that can be made from the figure :<br\/>\n<ul>\n    <li>The median age is close to 55 years.<\/li>\n    <li>25 % of the people are less than 48 years of age.<\/li>\n    <li>25% of the people are above 63 years of age.<\/li>\n    <li>There are no visible outliers in the dataset, although 1.5*IQR may beg to differ.<\/li>\n    <li>Interquartile range is about 13.5<\/li>\n    <li>Looks like about 50 percent of the data is about upper medium to early old age.It's kinda true as generally that's the average life expectancy for most of the adults.<\/li>\n<\/ul>\n<\/p>","8b7b9d0c":"<h2>Default Model Test<\/h2>","e1c6036a":"<p>Time to look at the trend for restecg.<br\/><b>restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)<\/b><\/p>","0a59e67e":"<h2>Predictions and accuracy<\/h2>","1901a9b9":"<p>Well! We were right. Some outliers are present<\/p>\n<p>From the distribution, it is evident that on an average, females have higher cholestrol levels than male.<\/p>\n<p> 50% females in the dataset have cholestrol between 220-300. While half the male people in the dataset have have cholestrol levels between 210-260<\/p>\n<p>50 % of the males in the dataset are between 48-60 years of age whilst on the other hand 50% of the females are between 49-65 years of age<\/p>","012faf22":"<p>still some of the variables are highly correlated<\/p>","623ed206":"<h2>Logistic Regression<\/h2>","3f3701f8":"<h2>Feature Engineering for Model Selection<\/h2>","54e461f3":"<p>First of all let's visualize the age distribution in our data<\/p>","18455bc7":"<h2>Confusion Matrix<\/h2>","fb5b5e54":"### **Let's visualize if a particular gender is more prone to getting a heart disease**","59021c8f":"<p><b>Conclusions:<\/b>\n    <ul>\n        <li>Upsloping in st segment means normal electrocardiographic changes during exercise. Which is good. And from the plot, healthy people generally have upsloping st segments.<\/li>\n        <li>Downsloping means abnormal electrocardiographic changes, which is bad. And people suffering from heart diseases generally give such readings.<\/li>\n<\/ul>\n    <\/p>","f52851f3":"<h2>Random Forest Classifier<\/h2>","2393390f":"<p>Now, let's see how much is this thalassemia reponsible for heart disease <\/p>\n<p>According to google <i>\"Thalassemia is an inherited blood disorder characterised by less oxygen-carrying protein (haemoglobin) and fewer red blood cells in the body than normal.\"<\/i>. Or in layman terms, with thalassemia rbc's are destroyed at a rapid rate, which leads to fatigue and maybe heart disease. Who knows? Let's find out.<\/p>","b3e69687":"<p>High precision is necessary for heart disease prediction and we do achieve it.<\/h2>","c3ea2368":"<p>So, we have no null values in our dataset. Thats promising<\/p>","59e3a09a":"<p> Now let's understand what slope is.In this dataset it is the slope of the peak exercise ST segment.Exercise tolerance testing is an important diagnostic and prognostic tool for assessing patients with suspected or known ischaemic heart disease. During exercise, coronary blood flow must increase to meet the higher metabolic demands of the myocardium. Limiting the coronary blood flow may result in electrocardiographic changes.ST segment depression (horizontal or downsloping) is the most reliable indicator of exercise-induced ischaemia.  <\/p>\n<p>Value 1: upsloping, Value 2: flat, Value 3: downsloping)<\/p>","1472c4a1":"<p>So, there is a weak positive correlation between age and cholestrol.(essentially no correlation)<\/p>\n<p>Some old women have unusually high cholestrol levels<\/p>","9fe02f0a":"<p> Not that good. Performing hyperparameter tuning<\/p>","9c666900":"<p> the best params that I got for svm were<\/p>\n<p>SVC(C=100, gamma=0.01, kernel='sigmoid')<\/p>","e56c2c38":"<h2>Learning Curve<\/h2>","4e553738":"<h2><b>Exploratory data analysis and Visualization<\/b><\/h2>","7e082400":"<h2>Pairplot for numeric variables<\/h2>","bcf7ccf8":"<p>So what do they even mean ??\n<ul>\n    <li>Fixed Defect(1) means that no blood flows in some part of the heart.<\/li>\n    <li>Reversible Defect(2) means that an abnormal blood flow pattern is observed.<\/li>\n<\/ul>\n<\/p>","2a8427cf":"<h2> Confusion Matrix<\/h2>","3d35bf12":"<p><b>Conclusions:<\/b><br\/>\n    <ul>\n        <li>1: typical angina:more in people with heart disease.<\/li>\n        <li>2: atypical angina : more in people with heart disease.<\/li>\n        <li>3: non-anginal pain : not conclusive<\/li>\n        <li>0: asymptomatic : people with type 0 cp are not that likely to have a heart disease.<\/li>\n\n  <\/ul>\n<\/p>","6122151b":"<p>\n<b>Conclusions:<\/b><ul>\n    <li>\n    So, most people who had a heart disease, didn't have exercise induced angina\/pain.\n    <\/li>\n    <li>\n        People who didn't suffer from heart disease had approximately the same probability of suffering from exang and not suffering from it.\n    <\/li>\n    <\/ul>\n<\/p>","8841956d":"<p>1. Lower tbs means heart disease. <\/p>\n<p>2. High thalach means heart disease.<\/p>\n<p>3. Low oldpeak indicates heart disease. <\/p>\n<p>4. Having even small amounts of cholestrol can lead to a heart disease.<\/p>\n<p>5. Age alone doesn't determine heart disease probability.<\/p>","6f09789a":"<p>looks like we fell into the dummy variable trap.<\/p>","0fafc2da":"<h2>Confusion Matrix<\/h2>","0ae4d654":"<p>It's possible that the model performs better by removing some features, which i'll do in the  future<\/p>","a23b3fbd":"<h2><b>Let's see which age group and gender have more cholestrol levels<\/b><\/h2>","16690742":"<p>1. People below 50 years of age and having low trestbps generally suffer from heart disease. <\/p>\n<p>2. People with lower age and high maximum possible heart rates(thalach) suffer from heart disease.<\/p>\n<p>3. People with lower oldpeak irrespective of the age have heart disease<\/p>\n<p>4. Young people with cholestrol generally have heart disease. Cholestrol increases with age so having high cholestrol levels during young age is bad<\/p>","e7bd299a":"<p><b>Conclusions:<\/b>\n<ul>\n    <li>People suffering from heart disease generally have a type-2 thalassemia. i.e abnormal blood flow pattern is observed.<\/li>\n    <li>Healthy people generally have a normal blood flow.<\/li>\n    <li>Fixed Defect thalassemia is present in both. But there aren't enough samples to make an absolute decision.<\/li>\n    <li>Looks like fixed defect thalassemia is not such a good indicator of whether a person is likely to suffer from a heart disease or not. Will be removed during one hot encoding<\/li>\n    <b> Well abnormal blood flow in heart can cause a shock or..... an attack !!<\/b>\n<\/ul> \n    <\/p>","c18e7709":"<h2>Confusion Matrix<\/h2>","6342cc7d":"<h2>Artifical Neural Network<\/h2>","2a1cd08f":"<p> <b>Now , lets see how the chestpain affects the chances of getting a heart disease<\/b><\/p>","6c084ef5":"<h2>Decision Tree<\/h2>","65d6e986":"<p><b>Conclusions:<\/b>\n    <ul>\n    <li>ST-T wave abnormality is predominant in people with heart disease.Which is true considering that, ST-T wave abnormality is predominant in people with heart disease. <\/li>\n        <li>Not enough samples for left ventricular hypertrophy. So it cannot be deciding factor to predict heart disease as sample size won't allow it to be a major predictor in classification algorithm.<\/li>\n        <li>Normal ecg test scores are higher in people who not suffering from heart disease, but not by a very satisfactory margin.<\/li>\n    <\/ul>\n    <\/p>","846b7638":"<h2>Roc curve<\/h2>","080a1c40":"<h2>Hyperparameter tuning<\/h2>","b965fda1":"<h2><b>Load the data<\/b><\/h2>","58849a80":"<p> Nothing conclusive can be said. The number of high fbs and low fbs are looking very close in both the cases<\/p>","54b81453":"<h2>ROC curve<\/h2>","566a0b17":"<p><b>FBS<\/b><\/p>\n<\/p>It signifies The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\nGreater than 120mg\/dl means suffering from diabetes.<\/p>","48c06500":"<h2>Hyperparameter tuning<\/h2>","e08fa237":"<p> <b>Understanding the pattern for exercise induced angina<\/b><\/p>","2c70ba7d":"<h2>Model Training<\/h2>","5d0ed88d":"<p>1. So, people with higher resting blood pressure don't necessarily have heart disease<\/p>\n<p>2. People with maximum possible heart rates(thalach) above 140 generally suffer from a heart disease<\/p>\n<p>3. People with lower old peaks are prone to heart diseases.<\/p>\n<p>4. Looks like age doesn't  tell alone if a person suffers from heart disease or not.<\/p>","29fcdce4":"<h2>Swarm plot for various categorical data and heart disease<\/h2>","a6ad576b":"<p>So,on an average females are more prone to heart diseases<\/p>\n<p>So, gender might be a good predictor for heart disease. We need to dive deeper in order to reach a valid conclusion.<\/p>"}}