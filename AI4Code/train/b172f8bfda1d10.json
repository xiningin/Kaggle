{"cell_type":{"a844eb76":"code","40969413":"code","a1ddc06f":"code","3e01b332":"code","39b48642":"code","0c19a407":"code","839c257f":"code","d6cbaec7":"code","427d2ae5":"code","6088891e":"code","42ebba24":"code","d7f6026a":"code","92be95fe":"code","8f51605c":"code","5af47cd5":"code","2b9aa04a":"code","32633bce":"code","a12111a3":"code","8074f388":"code","501b955d":"code","0075ccb3":"code","9e2c7f13":"markdown","4c95fe3c":"markdown"},"source":{"a844eb76":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n \ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","40969413":"#GOAL: Predict Housing Sales Prices (SalePrice)\n\ntrain.info()\n","a1ddc06f":"train.head()","3e01b332":"####DROP FEAUTURES WITH MAJORITY OF ELEMENTS MISSING\nmajority_missing = []\nfor col in train.columns:\n    if train[col].isnull().sum() >(train.shape[0])\/2:\n        majority_missing.append(col)\n    \nreduced_train = train.drop(majority_missing, axis=1)\nreduced_test = test.drop(majority_missing, axis=1)\n\n","39b48642":"test_nan = reduced_test.isnull().sum().sort_values(ascending = False) \nlen(test_nan[test_nan>=1])\n","0c19a407":"#lets merge test and train to handle nan values at same time\n\ndf_all = pd.concat([reduced_train,reduced_test ],ignore_index=True)\ndf_all.shape, reduced_train.shape, reduced_test.shape #NOTE: first 1460 rows from training data last 1459 from test ","839c257f":"# replace all the categorical variable with their mode value and numerical variables with their median\ndf_all[\"Electrical\"].dtype, df_all[\"SalePrice\"].dtype # so categorical variables would have a data type of \"dtype(0)\" and integers \"dtype('float64')\"","d6cbaec7":"has_null = df_all.isnull().sum()\nhas_null[has_null>0]","427d2ae5":"# to find categorical variable with missing features\nstr_missing = []\nfor col in df_all:\n    if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n        if df_all[col].isnull().sum() >0:\n            str_missing.append(col)\nstr_missing","6088891e":"#in the data description for FireplaceQu Na means it does not have that feature\ndf_all['FireplaceQu'] = df_all['FireplaceQu'].fillna('None')","42ebba24":" # this will give us a list of all the columns that non nan inputs are a string since \n\nfor col in df_all:\n    if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n        if df_all[col].isnull().sum() >0:\n            df_all[col] = df_all[col].fillna(df_all[col].mode()[0])\n            \n","d7f6026a":"\nfor col in df_all:\n    if df_all[col].dtype == df_all['GarageArea'].dtype and col != 'SalePrice':\n        if df_all[col].isnull().sum() >0:\n            mean = df_all[col].mean()\n            df_all[col] = df_all[col].fillna(mean)\n            ","92be95fe":"def categorical(data):\n    cat_var = []\n    for col in data:\n        if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n            cat_var.append(col)\n    return cat_var        ","8f51605c":"#now we need to hand categorical variables\ncat_var = categorical(df_all)\ndf_all = pd.get_dummies(df_all, columns = cat_var, drop_first = True)\n        ","5af47cd5":"#As noted previously first 1460 columns (inclusive) are from the training data and rest are from test data\ntrain_final = df_all.iloc[:1460,:]\ntest_final = df_all.iloc[1460:,:]\ntest_final = test_final.drop('SalePrice',axis=1) #since test data originally did not have the SalePrice feature, this is what we are estimating\n","2b9aa04a":"#Check that no more columns with missing values\ntrain_final.isnull().sum().sort_values(ascending = True), test_final.isnull().sum().sort_values(ascending = True)","32633bce":"#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n","a12111a3":"model_xgb = xgb.XGBRegressor(learning_rate = 0.11)\nY= train_final['SalePrice']\nX= train_final.drop('SalePrice', axis = 1)\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state = 0)\nmodel_xgb.fit(X_train,Y_train)\n","8074f388":"xgb_pred = model_xgb.predict(X_test)\nr2_score(Y_test, xgb_pred)","501b955d":"\n# Use the model to make predictions\npredicted_prices = model_xgb.predict(test_final)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)","0075ccb3":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","9e2c7f13":"**Part 1: Feature Engineering**","4c95fe3c":"**Part 2: Fit the model** "}}