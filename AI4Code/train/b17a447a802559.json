{"cell_type":{"8aa204fd":"code","cfd58091":"code","ce77e91c":"code","b9541ab6":"code","a4fc2789":"code","414865f6":"code","5aecc31f":"code","d8aa03ad":"code","a765f523":"code","61328fd0":"code","b9e1f99a":"code","8b6afd76":"code","46691052":"code","501d79de":"code","dfb9777a":"code","ad9199d3":"code","54730165":"code","942afc36":"code","ec3b649d":"code","adc8954d":"code","be7ad388":"code","7612461a":"code","a0b9b88f":"code","b1dc6b8d":"code","ec0b81ce":"code","30e1d617":"code","537c02d8":"code","eafa31e4":"code","6124fa3b":"code","66a81e55":"code","38025bde":"code","06aa1a60":"code","afa8cc7e":"code","004ca04b":"code","a166d4ec":"code","0e0278a4":"code","d9f44159":"code","c3a0746b":"code","34da7af9":"code","0bfba443":"code","3b8b06ef":"code","4df32bc5":"code","226466e9":"code","4ca1f2fc":"code","68d4a500":"code","9aa676b6":"code","ef2a4296":"code","0ab2755f":"code","5b9b1a6a":"code","307f9263":"code","c4f8fd5a":"code","d2ac0976":"code","ff59fa5f":"code","52c29140":"code","2103127e":"code","741e026f":"code","3f8dad87":"code","8b4054c2":"code","4aabc03b":"code","8620f363":"code","6caf79ac":"code","68f8172d":"code","43433630":"code","48956d98":"code","d9f380d6":"code","8e012592":"code","0a91ea38":"code","cabd59dc":"code","be4a37e7":"code","82e43b5e":"code","0173a88b":"code","e07f2c4e":"code","3b6eb065":"markdown","25531041":"markdown","3444a7dd":"markdown","f65acc01":"markdown","e6dd59cc":"markdown","3ad14551":"markdown","689ad443":"markdown","dcc8c154":"markdown","2572a5d6":"markdown","0254ede1":"markdown","83562e95":"markdown","2cde6172":"markdown","e16cbf20":"markdown","c5bcc47f":"markdown","699d920f":"markdown","da78501e":"markdown","c487b163":"markdown","55291e0c":"markdown","3b638b9b":"markdown","8bf8f2f3":"markdown","33b81eab":"markdown","2ec9595c":"markdown","7d21d440":"markdown","932ffe0e":"markdown","78d5ee10":"markdown","6c9bd905":"markdown","ea6f1a6f":"markdown","8d403fd9":"markdown","870a06c5":"markdown"},"source":{"8aa204fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n#%matplotlib inline\n#sns.set_style(\"whitegrid\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ndataset_dir = os.path.join('..', 'input', 'titanic')\nprint(os.listdir(dataset_dir))\n\n# Any results you write to the current directory are saved as output.\noutput_dir = '\/kaggle\/working\/output'\nos.makedirs(output_dir, exist_ok=True)","cfd58091":"df_train = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(dataset_dir, 'test.csv'))\nprint('[INFO] DataFrame (train.csv)')\nprint(df_train.info())\nprint('[INFO] DataFrame (test.csv)')\nprint(df_test.info())","ce77e91c":"df_train.sample(10)","b9541ab6":"def null_count():\n    print(\"<< null count: Training Data >>\")\n    print(pd.isnull(df_train).sum()) \n    print(\" \")\n    print(\"<< null count: Testing Data >>\")\n    print(pd.isnull(df_test).sum())\n    \nnull_count()","a4fc2789":"df_train.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\ndf_test.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\n\ndf_train.sample(10)","414865f6":"print('<< Age: Training Data (median) >>\\n{}'.format(df_train['Age'].median()))\ndf_train.plot(y='Age', bins=20, kind='hist')","5aecc31f":"print('<< Age: Testing Data (median) >>\\n{}'.format(df_test['Age'].median()))\ndf_test.plot(y='Age', bins=20, kind='hist')","d8aa03ad":"# It will not be a problem by compensating with the average value.\ndf_train['Age'].fillna(df_train['Age'].median(), inplace = True)\ndf_test['Age'].fillna(df_test['Age'].median(), inplace = True) \n\nnull_count()","a765f523":"print('<< Kind of \"Sex\" : Training Data >> \\n{}'.format(set(df_train['Sex'])))\nprint('<< Kind of \"Embarked\" : Training Data >> \\n{}'.format(set(df_train['Embarked'])))\n#print('<< Kind of \"Name\" >> \\n{}'.format(set(df_train['Name'])))\n# \u2192Too many kinds. It is needed to convert Title.\n\nprint('<< Kind of \"Sex\" : Testing Data >> \\n{}'.format(set(df_test['Sex'])))\nprint('<< Kind of \"Embarked\" : Testing Data >> \\n{}'.format(set(df_test['Embarked'])))\n#print('<< Kind of \"Name\" >> \\n{}'.format(set(df_train['Name'])))\n# \u2192Too many kinds. It is needed to convert Title.","61328fd0":"df_train.loc[df_train['Sex'] == 'male', 'Sex'] = 0\ndf_train.loc[df_train['Sex'] == 'female', 'Sex'] = 1\n\ndf_train.loc[df_train['Embarked'] == 'C', 'Embarked'] = 0\ndf_train.loc[df_train['Embarked'] == 'Q', 'Embarked'] = 1\ndf_train.loc[df_train['Embarked'] == 'S', 'Embarked'] = 2\n\ndf_test.loc[df_test['Sex'] == 'male', 'Sex'] = 0\ndf_test.loc[df_test['Sex'] == 'female', 'Sex'] = 1\n\ndf_test.loc[df_test['Embarked'] == 'C', 'Embarked'] = 0\ndf_test.loc[df_test['Embarked'] == 'Q', 'Embarked'] = 1\ndf_test.loc[df_test['Embarked'] == 'S', 'Embarked'] = 2","b9e1f99a":"for name in df_train['Name']:\n    df_train['Title'] = df_train['Name'].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nfor name in df_test['Name']:\n    df_test['Title'] = df_test['Name'].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nprint('<< Title: Training Data >>')\ntitles_training = list(set(df_train['Title']))\nprint(titles_training)\n\nprint('<< Title: Testing Data >>')\ntitles_testing = list(set(df_test['Title']))\nprint(titles_testing)","8b6afd76":"for title in titles_training:\n    print('{} in titles_testing: {}'.format(title, title in titles_testing))","46691052":"other_list_titles_training = [title for title in titles_training if not (title in titles_testing)]\nprint(other_list_titles_training)","501d79de":"df_train.loc[[_title in other_list_titles_training for _title in df_train['Title']], 'Title'] = 'Other'\nprint('<< Title: Training Data >>')\ntitles_training = list(set(df_train['Title']))\nprint(titles_training)","dfb9777a":"for title in titles_testing:\n    print('{} in titles_training: {}'.format(title, title in titles_training))","ad9199d3":"other_list_titles_testing = [title for title in titles_testing if not (title in titles_training)]\nprint(other_list_titles_testing)","54730165":"df_test.loc[[_title in other_list_titles_testing for _title in df_test['Title']], 'Title'] = 'Other'\nprint('<< Title: Testing Data >>')\ntitles_testing = list(set(df_test['Title']))\nprint(titles_testing)","942afc36":"for title in titles_training:\n    print('{} in titles_testing: {}'.format(title, title in titles_testing))","ec3b649d":"for title in titles_testing:\n    print('{} in titles_training: {}'.format(title, title in titles_training))","adc8954d":"idx_titles_training = np.arange(len(titles_training))\n\nhist_idx_titles_training = df_train['Title'].copy()\nfor i, title in enumerate(titles_training):\n    hist_idx_titles_training[hist_idx_titles_training == title] = i\nhist, bins = np.histogram(hist_idx_titles_training, bins = len(titles_training))\n\nplt.bar(bins[0:len(titles_training)], hist, tick_label = list(titles_training), align = 'center')","be7ad388":"idx_titles_testing = np.arange(len(titles_testing))\n\nhist_idx_titles_testing = df_test['Title'].copy()\nfor i, title in enumerate(titles_testing):\n    hist_idx_titles_testing[hist_idx_titles_testing == title] = i\nhist, bins = np.histogram(hist_idx_titles_testing, bins = len(titles_testing))\n\nplt.bar(bins[0:len(titles_testing)], hist, tick_label = list(titles_testing), align = 'center')","7612461a":"df_train.sample(10)","a0b9b88f":"new_titles = titles_training    # same as training data and testing data\ndf_train['Title'] = [new_titles.index(title) for title in df_train['Title']]\ndf_test['Title'] = [new_titles.index(title) for title in df_test['Title']]\nprint(new_titles)\nprint(np.arange(len(new_titles)))\n#print(df_train['Title'])","b1dc6b8d":"df_train.sample(10)","ec0b81ce":"print('<< Embarked: Training Data (median) >>\\n{}'.format(df_train['Embarked'].median()))\ndf_train.plot(y='Embarked', bins=3, kind='hist')\nprint('<< Embarked: Testing Data (median) >>\\n{}'.format(df_test['Embarked'].median()))\ndf_test.plot(y='Embarked', bins=3, kind='hist')","30e1d617":"df_train['Embarked'].fillna(2, inplace = True)\ndf_test['Embarked'].fillna(2, inplace = True) \n\nnull_count()","537c02d8":"df_train.sample(10)","eafa31e4":"df_train.describe()","6124fa3b":"null_count()","66a81e55":"print('<< Fare: Training Data (median) >>\\n{}'.format(df_train['Fare'].median()))\ndf_train.plot(y='Fare', kind='hist')\nprint('<< Fare: Testing Data (median) >>\\n{}'.format(df_test['Fare'].median()))\ndf_test.plot(y='Fare', kind='hist')","38025bde":"df_test['Fare'].fillna(df_test['Fare'].median(), inplace = True) \n\nnull_count()","06aa1a60":"df_train['IsFamily'] = df_train['SibSp'] + df_train['Parch'] > 0\ndf_train.loc[df_train['IsFamily'] == True, 'IsFamily'] = 1\ndf_train.loc[df_train['IsFamily'] == False, 'IsFamily'] = 0\n\ndf_test['IsFamily'] = df_test['SibSp'] + df_test['Parch'] > 0\ndf_test.loc[df_test['IsFamily'] == True, 'IsFamily'] = 1\ndf_test.loc[df_test['IsFamily'] == False, 'IsFamily'] = 0\n#print(df_test['IsFamily'])","afa8cc7e":"df_train.sample(10)","004ca04b":"hist_age, bins_age = np.histogram(df_train['Age'], bins=10)\nplt.bar(bins_age[0:10], hist_age, width=7, align = 'center')","a166d4ec":"df_train.loc[df_train['Age'] <= bins_age[1], 'Age'] = 0\nfor i in range(1, len(hist_age)-1):\n    df_train.loc[(df_train['Age'] > bins_age[i]) & (df_train['Age'] <= bins_age[i+1]), 'Age'] = i\ndf_train.loc[df_train['Age'] > bins_age[len(hist_age)-1], 'Age'] = len(hist_age)-1\n_hist_age, _bins_age = np.histogram(df_train['Age'], bins=len(hist_age))\nplt.bar(_bins_age[0:10], _hist_age, align = 'center')","0e0278a4":"_hist_age, _bins_age = np.histogram(df_test['Age'], bins=10)\nplt.bar(_bins_age[0:10], _hist_age, width=7, align = 'center')","d9f44159":"df_test.loc[df_test['Age'] <= bins_age[1], 'Age'] = 0\nfor i in range(1, len(hist_age)-1):\n    df_test.loc[(df_test['Age'] > bins_age[i]) & (df_test['Age'] <= bins_age[i+1]), 'Age'] = i\ndf_test.loc[df_test['Age'] > bins_age[len(hist_age)-1], 'Age'] = len(hist_age)-1\nhist_age, bins_age = np.histogram(df_test['Age'], bins=len(hist_age))\n\nplt.bar(bins_age[0:10], hist_age, align = 'center')","c3a0746b":"df_train.sample(10)","34da7af9":"hist_fare, bins_fare = np.histogram(df_train['Fare'], bins=10)\nplt.bar(bins_fare[0:10], hist_fare, width=40, align = 'center')","0bfba443":"df_train.loc[df_train['Fare'] >= 100, 'Fare'] = 100\nhist_fare, bins_fare = np.histogram(df_train['Fare'], bins=10)\nplt.bar(bins_fare[0:10], hist_fare, width=7, align = 'center')","3b8b06ef":"df_train.loc[df_train['Fare'] <= bins_fare[1], 'Fare'] = 0\nfor i in range(1, len(hist_fare)-1):\n    df_train.loc[(df_train['Fare'] > bins_fare[i]) & (df_train['Fare'] <= bins_fare[i+1]), 'Fare'] = i\ndf_train.loc[df_train['Fare'] > bins_fare[len(hist_fare)-1], 'Fare'] = len(hist_fare)-1\n_hist_fare, _bins_fare = np.histogram(df_train['Fare'], bins=len(hist_fare))\nplt.bar(_bins_fare[0:10], _hist_fare, align = 'center')","4df32bc5":"_hist_fare, _bins_fare = np.histogram(df_test['Fare'], bins=10)\nplt.bar(_bins_fare[0:10], _hist_fare, width=40, align = 'center')","226466e9":"df_test.loc[df_test['Fare'] >= 100, 'Fare'] = 100\n_hist_fare, _bins_fare = np.histogram(df_test['Fare'], bins=10)\nplt.bar(_bins_fare[0:10], _hist_fare, width = 7, align = 'center')","4ca1f2fc":"df_test.loc[df_test['Fare'] <= bins_fare[1], 'Fare'] = 0\nfor i in range(1, len(hist_fare)-1):\n    df_test.loc[(df_test['Fare'] > bins_fare[i]) & (df_test['Fare'] <= bins_fare[i+1]), 'Fare'] = i\ndf_test.loc[df_test['Fare'] > bins_fare[len(hist_fare)-1], 'Fare'] = len(hist_fare)-1\nhist_fare, bins_fare = np.histogram(df_test['Fare'], bins=len(hist_fare))\nplt.bar(bins_fare[0:10], hist_fare, align = 'center')","68d4a500":"df_train.sample(10)","9aa676b6":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Pclass vs Survived\")\nplt.show()","ef2a4296":"sns.barplot(x=\"Sex\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Sex vs Survived\")\nplt.show()","0ab2755f":"sns.barplot(x=\"Age\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Age vs Survived\")\nplt.show()","5b9b1a6a":"sns.barplot(x=\"Fare\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Fare vs Survived\")\nplt.show()","307f9263":"sns.barplot(x=\"Embarked\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Embarked vs Survived\")\nplt.show()","c4f8fd5a":"sns.barplot(x=\"Title\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"Title vs Survived\")\nplt.show()","d2ac0976":"sns.barplot(x=\"IsFamily\", y=\"Survived\", data=df_train)\nplt.ylabel(\"Survived Rate\")\nplt.title(\"IsFamily vs Survived\")\nplt.show()","ff59fa5f":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, make_scorer\n\nfrom sklearn.model_selection import GridSearchCV","52c29140":"#features = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"Fare\", \"Title\", \"IsFamily\"]  # feat_00\nfeatures = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"IsFamily\"]  # feat_01\nx_train = df_train[features]\ny_train = df_train[\"Survived\"]\nx_test = df_test[features]","2103127e":"K_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)","741e026f":"svc_models = []\nsvc_accuracy = []\nfor i, (train_index, val_index) in enumerate(K_fold.split(x_train, y_train)):\n    x_train_ = x_train.iloc[train_index]\n    y_train_ = y_train.iloc[train_index]\n    x_valid_ = x_train.iloc[val_index]\n    y_valid_ = y_train.iloc[val_index]\n    \n    svc_clf = SVC(gamma='auto')\n    svc_clf.fit(x_train_, y_train_)\n    svc_predict = svc_clf.predict(x_valid_)\n    svc_accuracy.append(accuracy_score(y_valid_, svc_predict))\n    print('[ITER {}] validation accuracy={}'.format(i, svc_accuracy[-1]))\n    \n    svc_models.append(svc_clf)\n\nsvc_accuracy = np.array(svc_accuracy).mean(axis=0)\nprint('[MEAN] validation accuracy={}'.format(svc_accuracy))","3f8dad87":"svc_predictions = []\nfor i, _model in enumerate(svc_models):\n    prediction = _model.predict(x_test)\n    svc_predictions.append(prediction)\nsvc_prediction = np.array(svc_predictions).mean(axis=0)\nprint(svc_prediction.shape)\npd.DataFrame(svc_prediction).to_csv(os.path.join(output_dir, 'svc_prediction.csv'), index=False)","8b4054c2":"linsvc_models = []\nlinsvc_accuracy = []\nfor i, (train_index, val_index) in enumerate(K_fold.split(x_train, y_train)):\n    x_train_ = x_train.iloc[train_index]\n    y_train_ = y_train.iloc[train_index]\n    x_valid_ = x_train.iloc[val_index]\n    y_valid_ = y_train.iloc[val_index]\n\n    linsvc_clf = LinearSVC(max_iter=10000)\n    linsvc_clf.fit(x_train_, y_train_)\n    linsvc_predict = linsvc_clf.predict(x_valid_)\n    linsvc_accuracy.append(accuracy_score(y_valid_, linsvc_predict))\n    print('[ITER {}] validation accuracy={}'.format(i, linsvc_accuracy[-1]))\n    \n    linsvc_models.append(linsvc_clf)\n\nlinsvc_accuracy = np.array(linsvc_accuracy).mean(axis=0)\nprint('[MEAN] validation accuracy={}'.format(linsvc_accuracy))","4aabc03b":"linsvc_predictions = []\nfor i, _model in enumerate(linsvc_models):\n    prediction = _model.predict(x_test)\n    linsvc_predictions.append(prediction)\nlinsvc_prediction = np.array(linsvc_predictions).mean(axis=0)\nprint(linsvc_prediction.shape)\npd.DataFrame(linsvc_prediction).to_csv(os.path.join(output_dir, 'linsvc_prediction.csv'), index=False)","8620f363":"rf_models = []\nrf_accuracy = []\nfor i, (train_index, val_index) in enumerate(K_fold.split(x_train, y_train)):\n    x_train_ = x_train.iloc[train_index]\n    y_train_ = y_train.iloc[train_index]\n    x_valid_ = x_train.iloc[val_index]\n    y_valid_ = y_train.iloc[val_index]\n\n    rf_clf = RandomForestClassifier(n_estimators=100)\n    rf_clf.fit(x_train_, y_train_)\n    rf_predict = rf_clf.predict(x_valid_)\n    rf_accuracy.append(accuracy_score(y_valid_, rf_predict))\n    print('[ITER {}] validation accuracy={}'.format(i, rf_accuracy[-1]))\n    \n    rf_models.append(rf_clf)\n    \nrf_accuracy = np.array(rf_accuracy).mean(axis=0)\nprint('[MEAN] validation accuracy={}'.format(rf_accuracy))","6caf79ac":"rf_predictions = []\nfor i, _model in enumerate(rf_models):\n    prediction = _model.predict(x_test)\n    rf_predictions.append(prediction)\nrf_prediction = np.array(rf_predictions).mean(axis=0)\nprint(rf_prediction.shape)\npd.DataFrame(rf_prediction).to_csv(os.path.join(output_dir, 'rf_prediction.csv'), index=False)","68f8172d":"x_train_, x_valid_, y_train_, y_valid_ = train_test_split(x_train, y_train, test_size=0.2, random_state=1234)\n\nensemble_predictions = []\nfor i, _model in enumerate(svc_models):\n    prediction = _model.predict(x_valid_)\n    ensemble_predictions.append(prediction)\n\nfor i, _model in enumerate(rf_models):\n    prediction = _model.predict(x_valid_)\n    ensemble_predictions.append(prediction)\n\nensemble_prediction = np.array(ensemble_predictions).mean(axis=0).round()\nensemble_accuracy = accuracy_score(y_valid_, ensemble_prediction)\nprint('validation accuracy={}'.format(ensemble_accuracy))","43433630":"ensemble_prediction = np.array([svc_prediction, rf_prediction]).mean(axis=0)\nprint(ensemble_prediction.shape)\npd.DataFrame(ensemble_prediction).to_csv(os.path.join(output_dir, 'ensemble_prediction.csv'), index=False)","48956d98":"x_train_gs, x_valid_gs, y_train_gs, y_valid_gs = train_test_split(x_train, y_train, test_size=0.2, random_state=1234)\n\ntuned_parameters = [\n    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]},\n    {'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': [0.001, 0.0001]},\n    {'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.001, 0.0001]}\n    ]\n#score = 'f1'\n#svc_clf_gs = GridSearchCV(SVC(), tuned_parameters, scoring='%s_weighted' % score)\nsvc_clf_gs = GridSearchCV(SVC(), tuned_parameters, scoring = make_scorer(accuracy_score))\n\nsvc_clf_gs.fit(x_train, y_train)\nprint(svc_clf_gs.best_estimator_)","d9f380d6":"svc_clf_gs_best = svc_clf_gs.best_estimator_\nsvc_clf_gs_best.fit(x_train_gs, y_train_gs)\n\nsvc_clf_gs_best_predict = svc_clf_gs_best.predict(x_valid_gs)\nsvc_clf_gs_best_accuracy = accuracy_score(y_valid_gs, svc_clf_gs_best_predict)\n\nprint('validation accuracy={}'.format(svc_clf_gs_best_accuracy))","8e012592":"x_train_gs, x_valid_gs, y_train_gs, y_valid_gs = train_test_split(x_train, y_train, test_size=0.2, random_state=1234)\n\ntuned_parameters = {\n        'n_estimators'      : [5, 10, 20, 30, 50],\n        'criterion'         : ['gini', 'entropy'],\n        'max_features'      : ['auto', 'sqrt', 'log2'], \n        'min_samples_split' : [3, 5, 10, 15, 20],\n        'max_depth'         : [3, 5, 10, 15, 20]\n}\nrf_clf_gs = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring = make_scorer(accuracy_score))\nrf_clf_gs.fit(x_train_gs, y_train_gs)\n\nprint(rf_clf_gs.best_estimator_)","0a91ea38":"rf_clf_gs_best = rf_clf_gs.best_estimator_\nrf_clf_gs_best.fit(x_train_gs, y_train_gs)\n\nrf_clf_gs_best_predict = rf_clf_gs_best.predict(x_valid_gs)\nrf_clf_gs_best_accuracy = accuracy_score(y_valid_gs, rf_clf_gs_best_predict)\n\nprint('validation accuracy={}'.format(rf_clf_gs_best_accuracy))","cabd59dc":"ensemble_gs_best_prediction = np.array([svc_clf_gs_best_predict, rf_clf_gs_best_predict]).mean(axis=0).round()\nensemble_gs_best_accuracy = accuracy_score(y_valid_gs, ensemble_gs_best_prediction)\nprint('validation accuracy={}'.format(ensemble_gs_best_accuracy))","be4a37e7":"svc_clf_gs_predict = svc_clf_gs_best.predict(x_test)\nrf_clf_gs_predict = rf_clf_gs_best.predict(x_test)\nensemble_gs_prediction = np.array([svc_clf_gs_predict, rf_clf_gs_predict]).mean(axis=0)\nprint(ensemble_gs_prediction.shape)\npd.DataFrame(ensemble_gs_prediction).to_csv(os.path.join(output_dir, 'ensemble_gs_prediction.csv'), index=False)","82e43b5e":"print('[Confirm validation accuracy]')\nprint('SVC: {}'.format(svc_accuracy))\nprint('Linear SVC: {}'.format(linsvc_accuracy))\nprint('RandomForest: {}'.format(rf_accuracy))\nprint('Ensemble(SVC and RandomForest): {}'.format(ensemble_accuracy))\nprint('SVC with GridSearch: {}'.format(svc_clf_gs_best_accuracy))\nprint('RandomForest with GridSearch: {}'.format(rf_clf_gs_best_accuracy))\nprint('Ensemble(SVC and RandomForest with GridSearch): {}'.format(ensemble_gs_best_accuracy))","0173a88b":"submission_predictions = []\nfor i, _model in enumerate(svc_models):\n    prediction = _model.predict(x_test)\n    submission_predictions.append(prediction)\n\nfor i, _model in enumerate(rf_models):\n    prediction = _model.predict(x_test)\n    submission_predictions.append(prediction)\n    \nprint(np.array(submission_predictions).shape)","e07f2c4e":"submission_prediction = np.array(submission_predictions).mean(axis=0).round().astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": submission_prediction\n    })\n\nsubmission.to_csv(os.path.join(output_dir, 'submission.csv'), index=False)\nprint(submission.shape)","3b6eb065":"# 11.Fitting and Predicting","25531041":"## Pclass vs Survived","3444a7dd":"## 7.Add \"IsFamily\"\n\n* SibSp + Parch > 0 \u2192 1\n* SibSp + Parch == 0 \u2192 0","f65acc01":"## Age vs Survived","e6dd59cc":"## GridSearch RandomForest model","3ad14551":"## 3.Complement \"Age\"","689ad443":"## 6.Complement \"Fare\"","dcc8c154":"## 0.Template","2572a5d6":"## Sex vs Survived","0254ede1":"## Title vs Survived","83562e95":"## Ensemble(SVC and RandomForest GridSearch)","2cde6172":"## SVC model","e16cbf20":"## Embarked vs Survived","c5bcc47f":"## Ensemble(SVC and RandomForest)","699d920f":"# 10. Check the Relationship with Survived","da78501e":"## Prepare Training","c487b163":"# 12.Submission","55291e0c":"## 5.Complement \"Embarked\"","3b638b9b":"## RandomForest model","8bf8f2f3":"# 8. Convert \"Age\" to Index","33b81eab":"## Fare vs Survived","2ec9595c":"## IsFamily vs Survived","7d21d440":"## 2.Drop Labels\n\n* Cabin : Too many lost data\n* Ticket : Value is complex","932ffe0e":"# Example of Kernel Using Titanic Dataset","78d5ee10":"## 1.Load CSV","6c9bd905":"## GridSearch SVC model","ea6f1a6f":"## Linear SVC model","8d403fd9":"# 9. Convert \"Fare\" to Index","870a06c5":"## 4.Make it Numeric\n\n* Sex : male\u21920, female\u21921\n* Embarked : C\u21920, Q \u21921, S \u2192 2\n* Title :\n * Ms \u2192 0\n * Miss \u2192 1\n * Dr \u2192 2\n * Mr \u2192 3\n * Master \u2192 4\n * Rev \u2192 5\n * Other \u2192 6\n * Col \u2192 7\n * Mrs \u2192 8"}}