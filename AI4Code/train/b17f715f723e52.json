{"cell_type":{"67c17090":"code","a94c9206":"code","ed6ac022":"code","00f65e9a":"code","a37c5d33":"code","63f67c7e":"code","99f9ec47":"code","ed468136":"code","f84be2b3":"code","b57ff6cd":"code","5e174e1e":"code","7427c87c":"code","330324a7":"code","f6d35d76":"code","37cf85f5":"markdown","535e969d":"markdown","48a96d3b":"markdown","1262d67a":"markdown","16ed54a5":"markdown","23c421a3":"markdown","928eaf7a":"markdown"},"source":{"67c17090":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom scipy import sparse\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm","a94c9206":"class ProprecessingData:\n  def load_data(self) -> pd.DataFrame:\n    \"\"\"\n    Read file csv withd pandas\n    \"\"\"\n    name = [\"URL\", \"category\"]\n    path_file = '..\/input\/url-classification-dataset-dmoz\/URL Classification.csv'\n    df = pd.read_csv(path_file, names=name, na_filter=False)\n    X = df[\"URL\"]\n    y = df[\"category\"]\n    \n    return X, y\n  def split_data(self, test_size) -> pd.DataFrame:\n    \"\"\"\n    Spilit data into train set and test set\n    \"\"\"\n    X, y = self.load_data()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    \n    return X_train, X_test, y_train, y_test\n  def tfidf_train(self, X_train: pd.DataFrame) -> sparse.csr.csr_matrix:\n    \"\"\"\n    Fit X for TFIDF\n    Output : Vector TIFIDF type csr_matrix\n    \"\"\"\n    self.vectorizer = CountVectorizer(stop_words = ['http', 'www', 'com', 'net',\n                                                    'org', 'jp', 'bc', \n                                                    'html', 'htm', 'index'])\n    word_count_vector = self.vectorizer.fit_transform(X_train)\n    self.tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True) \n    tf_idf_vector = self.tfidf_transformer.fit_transform(word_count_vector)\n    \n    return tf_idf_vector\n  def tfidf_test(self, X_test: pd.DataFrame) -> sparse.csr.csr_matrix:\n    \"\"\"\n    Fit X for TFIDF\n    Output : Vector TIFIDF type csr_matrix\n    \"\"\"\n    word_count_vector_test = self.vectorizer.transform(X_test)\n    tf_idf_vector_test = self.tfidf_transformer.transform(word_count_vector_test)\n    return tf_idf_vector_test","ed6ac022":"propre_data = ProprecessingData()\nX_train, X_test, y_train, y_test = propre_data.split_data(0.2)","00f65e9a":"tf_idf_vector = propre_data.tfidf_train(X_train)","a37c5d33":"tf_idf_vector_test = propre_data.tfidf_test(X_test)","63f67c7e":"labels = ['Adult', 'Arts', 'Business', 'Computers', 'Games', 'Health', 'Home', 'Kids',\n          'News', 'Recreation', 'Reference', 'Science', 'Shopping', 'Society', 'Sports']\nlabels_count = np.unique(y_train, return_counts=True)\nfig, ax = plt.subplots(figsize=(20, 8))\nax.bar(labels_count[0], labels_count[1], 0.5, tick_label=labels, color='green')\nplt.show()","99f9ec47":"labels = ['Adult', 'Arts', 'Business', 'Computers', 'Games', 'Health', 'Home', 'Kids',\n          'News', 'Recreation', 'Reference', 'Science', 'Shopping', 'Society', 'Sports']\nlabels_count = np.unique(y_test, return_counts=True)\nfig, ax = plt.subplots(figsize=(20, 8))\nax.bar(labels_count[0], labels_count[1], 0.5, tick_label=labels, color='green')\nplt.show()","ed468136":"print(tf_idf_vector_test.shape)\nprint(type(tf_idf_vector_test))","f84be2b3":"class MultinomialNB:\n  def __init__(self, alpha: float=1.0):\n    self.alpha = alpha\n  def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame):\n    \"\"\"\n    Fit data training to Naive Bayes\n    Input: X_train: type csr_matrix \n    y_train: list\n    \"\"\"\n    m, n = X_train.shape\n    self._classes = np.unique(y_train)\n    # Count class\n    n_classes = len(self._classes)\n    # Init matrix prior,likelihood\n    self._priors = np.zeros(n_classes)\n    self._likelihood = np.zeros((n_classes, n))\n    for idx, c in enumerate(self._classes):\n      bool_c = np.array(c==y_train)\n      # Data of class c\n      X_train_c = X_train[bool_c]\n      # Caculate prior and likelihood\n      self._priors[idx] = (X_train_c.shape[0] \/ m)\n      self._likelihood[idx,:] =  np.log((X_train_c.sum(axis=0) + self.alpha) \/ np.sum((X_train_c.sum(axis=0) + self.alpha)))\n  def cal_c_likelihood(self, c_likeli, x_test):\n    \"\"\"\n    Calculate multi likelihood of class c with x test\n    \"\"\"\n    return x_test * np.log(c_likeli)[:, np.newaxis]\n  def _predict(self, x_test) -> list:\n    \"\"\"\n    Calculate sum likelihood and prior of class c.\n    Argmax class c have posteriors.\n    \"\"\"\n    posteriors = []\n    for idx, c in enumerate(self._classes):\n      prior_c = np.log(self._priors[idx])\n      likelihood_c = x_test * self._likelihood[idx, :]\n      posteriors_c = np.sum(likelihood_c) + prior_c\n      posteriors.append(posteriors_c)\n    return self._classes[np.argmax(posteriors)]\n  def predict(self, X_test) -> list:\n    \"\"\"\n    predict output for X test\n    Input: csr_matrix\n    Output: list\n    \"\"\"\n    return [self._predict(x_test) for x_test in tqdm(X_test)]","b57ff6cd":"clf = MultinomialNB()","5e174e1e":"clf.fit(tf_idf_vector, y_train)","7427c87c":"y_pred = clf.predict(tf_idf_vector_test)","330324a7":"from sklearn.metrics import classification_report\ntarget_names = np.unique(y_test)\nprint(classification_report(y_test, y_pred, target_names=target_names))","f6d35d76":"array = confusion_matrix(y_test, y_pred)\ncm=np.array(array)\ncm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\ndf_cm = pd.DataFrame(cm, index = [i for i in \"0123456789ABCDE\"],\n                  columns = [i for i in \"0123456789ABCDE\"])\nplt.figure(figsize = (20,15))\nsns.heatmap(df_cm, annot=True)","37cf85f5":"# Import","535e969d":"# Build Model","48a96d3b":"# Visualize Data","1262d67a":"We notice here that the data is unbalanced, uneven between the class labels.","16ed54a5":"The method is straight forward. Just take the average of the precision and recall of the system on different sets.\nA weighted average is the average of a data set that recognizes certain numbers as more important than others.\n","23c421a3":"The model's Accuracy is: 0.38 but the f1-score of some very low classes is like News=0.0 and shopping=0.02. That the model has not predicted the classes with little data","928eaf7a":"The shape and data type of data when converted to tf_idf is csr_matrix."}}