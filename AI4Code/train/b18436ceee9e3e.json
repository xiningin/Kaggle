{"cell_type":{"76946ca7":"code","bcdb2445":"code","d0cb9c32":"code","be4b9ad4":"code","23fdaa57":"code","8a8460cf":"code","1ddaf56f":"code","ca244d8d":"code","3cd5750a":"code","4acb6783":"code","201e57c2":"code","a6c3be15":"code","2ea62785":"code","da57cde7":"code","a35b580e":"code","39a55a45":"code","62efa889":"code","4437cb31":"code","d484d72a":"code","19adb5c1":"code","7cda8359":"code","6e0644a7":"code","836cc936":"markdown"},"source":{"76946ca7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom yellowbrick.text import FreqDistVisualizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import LinearSVC\n","bcdb2445":"# Dataset: https:\/\/www.kaggle.com\/edqian\/twitter-climate-change-sentiment-dataset","d0cb9c32":"#This notebook is just for my quick interest in multiclass classification of sentiments on climate change\n# I know, the accuracy can be improved via preprocessing or stronger models ","be4b9ad4":"dataset = pd.read_csv(\"..\/input\/twitter-climate-change-sentiment-dataset\/twitter_sentiment_data.csv\")","23fdaa57":"dataset.head()","8a8460cf":"#missing values\nlen(dataset[dataset.message == None])","1ddaf56f":"#length of whole dataset\nlen(dataset)","ca244d8d":"#I am using 70% of the data for training\ntrain_data_length = int(len(dataset) * 0.7)\nprint(\"Train data length: \"+str(train_data_length))\nprint(\"Test data length: \"+str(len(dataset)-train_data_length))\n\n#defining training and test set\ntrain_data = dataset.iloc[:train_data_length]\ntest_data = dataset.iloc[train_data_length:]","3cd5750a":"#Initializing Vectorization of Climate posts\nvectorizer = TfidfVectorizer()\nvectorised_train_documents = vectorizer.fit_transform(train_data[\"message\"])\nvectorised_test_documents = vectorizer.transform(test_data[\"message\"])\nvectorised_train_documents","4acb6783":"#Distribution of most common words\nfeatures = vectorizer.get_feature_names()\nvisualizer = FreqDistVisualizer(features=features, orient='v')\nvisualizer.fit(vectorised_train_documents)\nvisualizer.show()","201e57c2":"#Using the One vs All concept, I am changing the labels to vectors (4 x 1) each\nmlb = MultiLabelBinarizer()\ntrain_labels = mlb.fit_transform(map(str,train_data.sentiment))\ntest_labels = mlb.transform(map(str,test_data.sentiment))","a6c3be15":"ModelsPerformance = {}\n#Creating method for model evaluation\ndef metricsReport(modelName, test_labels, predictions):\n    macro_f1 = f1_score(test_labels, predictions, average='macro')\n\n    micro_f1 = f1_score(test_labels, predictions, average='micro')\n    \n    hamLoss = hamming_loss(test_labels, predictions)\n    ModelsPerformance[modelName] = micro_f1","2ea62785":"#first weak classifier \nbagClassifier = OneVsRestClassifier(BaggingClassifier(n_jobs=-1))\nbagClassifier.fit(vectorised_train_documents, train_labels)\nbagPreds = bagClassifier.predict(vectorised_test_documents)\nmetricsReport(bagClassifier, test_labels, bagPreds)","da57cde7":"#Model: K-nearest-Neighbors \nknnClf = KNeighborsClassifier()\n\nknnClf.fit(vectorised_train_documents, train_labels)\nknnPredictions = knnClf.predict(vectorised_test_documents)\nmetricsReport(knnClf, test_labels, knnPredictions)","a35b580e":"#Model: Decision Tree\ndtClassifier = DecisionTreeClassifier()\ndtClassifier.fit(vectorised_train_documents, train_labels)\ndtPreds = dtClassifier.predict(vectorised_test_documents)\nmetricsReport(dtClassifier, test_labels, dtPreds)","39a55a45":"#Model: Random Forest\nrfClassifier = RandomForestClassifier(n_jobs=-1)\nrfClassifier.fit(vectorised_train_documents, train_labels)\nrfPreds = rfClassifier.predict(vectorised_test_documents)\nmetricsReport(rfClassifier, test_labels, rfPreds)","62efa889":"#Model: Gradient Boosting\nboostClassifier = OneVsRestClassifier(GradientBoostingClassifier())\nboostClassifier.fit(vectorised_train_documents, train_labels)\nboostPreds = boostClassifier.predict(vectorised_test_documents)\nmetricsReport(boostClassifier, test_labels, boostPreds)","4437cb31":"#Model: Multinominal Naive Bayes\nnbClassifier = OneVsRestClassifier(MultinomialNB())\nnbClassifier.fit(vectorised_train_documents, train_labels)\nnbPreds = nbClassifier.predict(vectorised_test_documents)\nmetricsReport(nbClassifier, test_labels, nbPreds)","d484d72a":"#Model: Linear Support Vector Machine\nsvmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\nsvmClassifier.fit(vectorised_train_documents, train_labels)\n\nsvmPreds = svmClassifier.predict(vectorised_test_documents)\nmetricsReport(svmClassifier, test_labels, svmPreds)","19adb5c1":"#Model performance\nModelsPerformance","7cda8359":"#As we can see, the Linear Support Vector Machine performs the best.","6e0644a7":"#These results can be highly improved via Preprocessing, Tokening and stronger models","836cc936":"Dataset: https:\/\/www.kaggle.com\/edqian\/twitter-climate-change-sentiment-dataset\n\nThis notebook is just for my quick interest in multiclass classification of sentiments on climate change\nThe accuracy can be improved via preprocessing or stronger models \n\nAs I wanted to get an overview of the accuracy \n\nlength of dataset: 43943\nmissing values: 0\n"}}