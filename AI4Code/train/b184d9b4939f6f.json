{"cell_type":{"14fd074a":"code","f29c0fad":"code","50070370":"code","66653075":"code","91c743d4":"code","92f24ab0":"code","6b39a1e4":"code","409c45fb":"code","97516272":"code","7812046e":"code","81db912d":"code","c6577e98":"code","7dadf219":"code","65e83f7b":"markdown","160718c0":"markdown","be544263":"markdown","b4cad85d":"markdown","2337c3f2":"markdown","c049eeb0":"markdown","ba726eff":"markdown","2430c1d1":"markdown","9fcaa759":"markdown","d9b72456":"markdown","83dfaf65":"markdown","2e3d8053":"markdown","b23cf533":"markdown"},"source":{"14fd074a":"import pandas as pd\nimport numpy as np\n\nresults = pd.DataFrame(columns = ['Tactic', 'Tactic name', 'Model', 'Description', 'Result', 'Score'])","f29c0fad":"results = results.append({\n    'Tactic': 0,\n    'Tactic name': 'Baseline',\n    'Model': 'rf',\n    'Description': 'Random Forest',\n    'Result': 0.6648148148148149,\n    'Score': 0.54789\n}, ignore_index = True)\n\nresults","50070370":"results = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'bg',\n    'Description': 'Bagging',\n    'Result': 0.784126984126984,\n    'Score': 0.73833\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'gb',\n    'Description': 'Gradient Boosting',\n    'Result': 0.7630291005291,\n    'Score': 0.72271\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'lg',\n    'Description': 'LightGBM',\n    'Result': 0.7979497354497355,\n    'Score': 0.77311\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'xg',\n    'Description': 'XGBoost',\n    'Result': 0.6996031746031746,\n    'Score': 0.58578\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'knn',    \n    'Description': 'k-Nearest Neighbors',\n    'Result': 0.691005291005291,\n    'Score': 0.63779\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'rf',    \n    'Description': 'Random Forests',\n    'Result': 0.6648148148148149,\n    'Score': 0.54789\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'lr',\n    'Description': 'Logistic Regression',\n    'Result': 0.6129629629629629,\n    'Score': 0.55308\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'xt',\n    'Description': 'eXtra-Trees',\n    'Result': 0.6128968253968254,\n    'Score': 0.53823\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'lda',\n    'Description': 'Linear Discriminant Analysis',\n    'Result': 0.6032407407407407,\n    'Score': 0.58154\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 1,\n    'Tactic name': 'Test classifiers',\n    'Model': 'gnb',\n    'Description': 'Gaussian Naive Bayes',\n    'Result': 0.5685185185185185,\n    'Score': 0.42161\n}, ignore_index = True)\n\nresults.query('Tactic == 1')","66653075":"results = results.append({\n    'Tactic': 2,\n    'Tactic name': 'Stack classifiers',\n    'Model': '[lg]',\n    'Description': 'Stack of models: LightGBM',\n    'Result': 0.7979497354497355,\n    'Score': 0.77311\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 2,\n    'Tactic name': 'Stack classifiers',\n    'Model': '[lg, gb, knn]',\n    'Description': 'Stack of models: LightGBM, Gradient Boosting, k-Nearest Neighbors',\n    'Result': 0.7979497354497355,\n    'Score': 0.77303\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 2,\n    'Tactic name': 'Stack classifiers',\n    'Model': '[lg, knn]',\n    'Description': 'Stack of models: LightGBM, k-Nearest Neighbors',\n    'Result': 0.7979497354497355,\n    'Score': 0.77311\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 2,\n    'Tactic name': 'Stack classifiers',\n    'Model': '[lg, lr, xt]',\n    'Description': 'Stack of models: LightGBM, Logistic Regression, eXtra-Trees',\n    'Result': 0.7978835978835979,\n    'Score': 0.77311\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 2,\n    'Tactic name': 'Stack classifiers',\n    'Model': '[lg, lda, xt]',\n    'Description': 'Stack of models: LightGBM, Linear Discriminant Analysis, eXtra-trees',\n    'Result': 0.7978835978835979,\n    'Score': 0.77311\n}, ignore_index = True)\n\nresults.query('Tactic == 2')","91c743d4":"results = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'lg',\n    'Description': 'Optimized LightGBM',\n    'Result': 0.8067460317460318,\n    'Score': 0.78236\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'xt',\n    'Description': 'Optimized eXtra-Trees',\n    'Result': 0.8049603174603175,\n    'Score': 0.78149\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'gb',\n    'Description': 'Optimized Gradient Boosting',\n    'Result': 0.8013227513227513,\n    'Score': 0.77732\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'rf',\n    'Description': 'Optimized Random Forest',\n    'Result': 0.8007936507936508,\n    'Score': 0.77521\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'bg',\n    'Description': 'Optimized Bagging',\n    'Result': 0.7933201058201058,\n    'Score': 0.75800\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'xg',\n    'Description': 'Optimized XGBoost',\n    'Result': 0.7694444444444445,\n    'Score': 0.73749\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'knn',\n    'Description': 'Optimized k-Nearest Neighbors',\n    'Result': 0.756547619047619,\n    'Score': 0.71808\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 3,\n    'Tactic name': 'Hyperparameter optimization',\n    'Model': 'lr',\n    'Description': 'Optimized Logistic Regression',\n    'Result': 0.6446428571428572,\n    'Score': 0.58974\n}, ignore_index = True)\n\nresults.query('Tactic == 3')","92f24ab0":"results = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, gb, bg, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Gradient Boosting, Bagging, k-Nearest Neighbors',\n    'Result': 0.8103174603174602,\n    'Score': 0.78889\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, gb, rf, bg, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Gradient Boosting, Randrom Forest, Bagging, k-Nearest Neighbors',\n    'Result': 0.8101190476190476,\n    'Score': 0.78955\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, gb, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Gradient Boosting, k-Nearest Neighbors',\n    'Result': 0.8098544973544973,\n    'Score': 0.78940\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, k-Nearest Neighbors',\n    'Result': 0.8097883597883597,\n    'Score': 0.78563\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, bg, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Bagging, k-Nearest Neighbors',\n    'Result': 0.8097222222222222,\n    'Score': 0.78382\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, rf, bg, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Random Forest, Bagging, k-Nearest Neighbors',\n    'Result': 0.8090608465608465,\n    'Score': 0.78994\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 4,\n    'Tactic name': 'Stack optimized classifiers',\n    'Model': '[lg, xt, rf, knn]',\n    'Description': 'Stack of models: LightGBM, eXtra-Trees, Random Forest, k-Nearest Neighbors',\n    'Result': 0.8089285714285714,\n    'Score': 0.79018\n}, ignore_index = True)\n\nresults.query('Tactic == 4')","6b39a1e4":"results = results.append({\n    'Tactic': 5,\n    'Tactic name': 'Class weight',\n    'Model': 'xt',\n    'Description': 'Weighted eXtra-Trees',\n    'Result': 0.803042328042328,\n    'Score': 0.78081\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 5,\n    'Tactic name': 'Class weight',\n    'Model': 'rf',\n    'Description': 'Weighted Random Forest',\n    'Result': 0.7955687830687831,\n    'Score': 0.76507\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 5,\n    'Tactic name': 'Class weight',\n    'Model': 'lg',\n    'Description': 'Weighted LightGBM',\n    'Result': 0.6341269841269841,\n    'Score': 0.53320\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 5,\n    'Tactic name': 'Class weight',\n    'Model': 'lr',\n    'Description': 'Weighted Logistic Regression',\n    'Result': 0.5964285714285714,\n    'Score': 0.31908\n}, ignore_index = True)\n\nresults.query('Tactic == 5')","409c45fb":"results = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'xt',\n    'Description': 'eXtra-Trees',\n    'Result': 0.8222883597883598,\n    'Score': 0.80142\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'lg',\n    'Description': 'LightGBM',\n    'Result': 0.8196428571428571,\n    'Score': 0.79496\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'gb',\n    'Description': 'Gradient Boosting',\n    'Result': 0.8175925925925925,\n    'Score': 0.79778\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'rf',\n    'Description': 'Random Forests',\n    'Result': 0.817063492063492,\n    'Score': 0.79113\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'xg',\n    'Description': 'XGBoost',\n    'Result': 0.8039021164021164,\n    'Score': 0.78067\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'bg',\n    'Description': 'Bagging',\n    'Result': 0.8037037037037037,\n    'Score': 0.77487\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'knn',\n    'Description': 'k-Nearest Neighbors',\n    'Result': 0.7116402116402116,\n    'Score': 0.65645\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 6,\n    'Tactic name': 'Feature engineering',\n    'Model': 'lr',\n    'Description': 'Logistic Regression',\n    'Result': 0.6223544973544973,\n    'Score': 0.56301\n}, ignore_index = True)\n\n# results = results.append({\n#     'Tactic': 6,\n#     'Tactic name': 'Feature engineering',\n#     'Model': 'lda',\n#     'Description': 'Linear Discriminant Analysis',\n#     'Result': 0.5973544973544973,\n#     'Score': 0.56452\n# }, ignore_index = True)\n\n# results = results.append({\n#     'Tactic': 6,\n#     'Tactic name': 'Feature engineering',\n#     'Model': 'gnb',\n#     'Description': 'Gaussian Naive Bayes',\n#     'Result': 0.5212962962962963,\n#     'Score': 0.42493\n# }, ignore_index = True)\n\n# results = results.append({\n#     'Tactic': 6,\n#     'Tactic name': 'Feature engineering',\n#     'Model': 'ab',\n#     'Description': 'AdaBoost',\n#     'Result': 0.41064814814814815,\n#     'Score': 0.15887\n# }, ignore_index = True)\n\nresults.query('Tactic == 6')","97516272":"results = results.append({\n    'Tactic': 7,\n    'Tactic name': 'Outlier detection',\n    'Model': 'lg',\n    'Description': 'LightGBM. Contamination 0.01',\n    'Result': 0.8020443613041155,\n    'Score': 0.78039\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 7,\n    'Tactic name': 'Outlier detection',\n    'Model': 'lg',\n    'Description': 'LightGBM. Contamination 0.05',\n    'Result': 0.8041631857421331,\n    'Score': 0.77526\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 7,\n    'Tactic name': 'Outlier detection',\n    'Model': 'lg',\n    'Description': 'LightGBM. Contamination 0.1',\n    'Result': 0.8026161081716637,\n    'Score': 0.76304\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 7,\n    'Tactic name': 'Outlier detection',\n    'Model': 'lg',\n    'Description': 'LightGBM. Contamination 0.2',\n    'Result': 0.7978670634920635,\n    'Score': 0.74398\n}, ignore_index = True)\n\nresults.query('Tactic == 7')","7812046e":"results = results.append({\n    'Tactic': 8,\n    'Tactic name': 'Feature selection: optimal importance',\n    'Model': 'lg',\n    'Description': 'LightGBM',\n    'Result': 0.8232142857142858,\n    'Score': 0.79681\n}, ignore_index = True)\n\nresults = results.append({\n    'Tactic': 8,\n    'Tactic name': 'Feature selection: optimal importance',\n    'Model': 'lg',\n    'Description': 'LightGBM. Only positive',\n    'Result': 0.8163,\n    'Score': 0.79507\n}, ignore_index = True)\n\nresults.query('Tactic == 8')","81db912d":"results = results.append({\n    'Tactic': 9,\n    'Tactic name': 'Feature selection: backward elimination',\n    'Model': 'lg',\n    'Description': 'LightGBM',\n    'Result': 0.7986111111111112,\n    'Score': 0.79529\n}, ignore_index = True)\n\nresults.query('Tactic == 9')","c6577e98":"results = results.append({\n    'Tactic': 10,\n    'Tactic name': 'Feature selection: forward selection',\n    'Model': 'lg',\n    'Description': 'LightGBM',\n    'Result': 0.8046957671957673,\n    'Score': 0.79155\n}, ignore_index = True)\n\nresults.query('Tactic == 10')","7dadf219":"## Export Tactic00 + Tactic01 results ordered by score\ntactic_01_results = results.query('Tactic == 1 or Tactic == 0').sort_values('Score', ascending=False).reset_index(drop=True)\ntactic_01_results.to_csv('tactic_01_results.csv', index=True, index_label='Id')\n\n## Export Tactic03 results ordered by score\ntactic_03_results = results.query('Tactic == 3').sort_values('Score', ascending=False).reset_index(drop=True)\ntactic_03_results.to_csv('tactic_03_results.csv', index=True, index_label='Id')\n\n## Calculate ratio\nresults['Ratio'] = round(results['Score'] \/ results['Result'] * 100, 2)\n\nresults.to_csv('results.csv', index=True, index_label='Id')\nresults","65e83f7b":"# Tactic 10 results","160718c0":"# Export","be544263":"# Tactic 06 results","b4cad85d":"# Tactic 00 results","2337c3f2":"# Tactic 01 results","c049eeb0":"# Tactic 02 results ","ba726eff":"# Tactic 03 results ","2430c1d1":"# Tactic 05 results","9fcaa759":"# Tactic 07 results","d9b72456":"# Tactic 09 results","83dfaf65":"# Tactic 04 results ","2e3d8053":"# Introduction\n\nThe aim of this notebook is to collect the results of each of the different tactics tested.\n\nThere are a huge collection of notebooks, each one with a tactic or part of a tactic.\nThe objective of each tactic is to study, analyse, and get conclusions of an very specific concept.\n\n- [Tactic 00. Baseline](https:\/\/www.kaggle.com\/juanmah\/tactic-00-baseline)\n- [Tactic 01. Test classifiers](https:\/\/www.kaggle.com\/juanmah\/tactic-01-test-classifiers)\n- [Tactic 02. Stack classifiers](https:\/\/www.kaggle.com\/juanmah\/tactic-02-stack-classifiers)\n- [Tactic 03. Hyperparameter optimization](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization):\n - [Tactic 03. Hyperparameter optimization. LR](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-lr)\n - [Tactic 03. Hyperparameter optimization. LDA](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-lda)\n - [Tactic 03. Hyperparameter optimization. KNN](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-knn)\n - [Tactic 03. Hyperparameter optimization. GNB](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-gnb)\n - [Tactic 03. Hyperparameter optimization. SVC](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-svc)\n - [Tactic 03. Hyperparameter optimization. Bagging](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-bagging)\n - [Tactic 03. Hyperparameter optimization. Xtra-trees](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-xtra-trees)\n - [Tactic 03. Hyperparameter optimization. Adaboost](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-adaboost)\n - [Tactic 03. Hyperparameter optimization. GB](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-gb)\n - [Tactic 03. Hyperparameter optimization. LightGBM](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-lightgbm)\n - [Tactic 03. Hyperparameter optimization. XGBoost](https:\/\/www.kaggle.com\/juanmah\/tactic-03-hyperparameter-optimization-xgboost)\n- [Tactic 04. Stack optimized classifiers](https:\/\/www.kaggle.com\/juanmah\/tactic-04-stack-optimized-classifiers)\n- [Tactic 05. Class weight](https:\/\/www.kaggle.com\/juanmah\/tactic-05-class-weight)\n- [Tactic 06. Feature engineering](https:\/\/www.kaggle.com\/juanmah\/tactic-06-feature-engineering)\n- [Tactic 07. Outlier detection](https:\/\/www.kaggle.com\/juanmah\/tactic-07-outlier-detection)\n- [Tactic 08. Feature selection: optimal importance](https:\/\/www.kaggle.com\/juanmah\/tactic-08-feature-selection-optimal-importance)\n- [Tactic 09. Feature selection: backward elimination](https:\/\/www.kaggle.com\/juanmah\/tactic-09-feature-selection-backward-elimination)\n- [Tactic 10. Feature selection: forward selection](https:\/\/www.kaggle.com\/juanmah\/tactic-10-feature-selection-forward-selection)\n\nThe result table is the collection of all the individual results in each tactic.\n\nThere are two main numbers in this table: result and score.\n**Result** is the internal score (i.e. the score on the train set),\nand **score** is the public score returned by Kaggle (i.e. the score in the test set).","b23cf533":"# Tactic 08 results"}}