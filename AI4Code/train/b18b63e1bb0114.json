{"cell_type":{"d56a3f93":"code","9b3de819":"code","a9995b5f":"code","ccff7a86":"code","2ef4148a":"code","86f32816":"code","b358d6c5":"code","cd59ff35":"code","85e49ea5":"code","0c4a983d":"code","838838cc":"code","7c02c187":"code","0e2b439f":"code","b3d90adf":"code","fb2e6671":"code","1643a88e":"code","d9687b49":"code","ff929925":"code","48ac9bff":"code","b154453d":"code","1247a3ff":"code","a5a90860":"code","cbedb685":"code","f10e6db2":"code","e58e474c":"code","f99623cb":"code","4bed4ac3":"markdown","9a688daa":"markdown","506e8a22":"markdown","3209e452":"markdown","0d822d5b":"markdown","860a7a70":"markdown","b94f205b":"markdown","e317306a":"markdown","565d390a":"markdown"},"source":{"d56a3f93":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","9b3de819":"from tensorflow.data import Dataset\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense\nfrom tensorflow.keras.activations import relu\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy, sparse_categorical_accuracy, SparseCategoricalAccuracy, CategoricalAccuracy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","a9995b5f":"def get_shallow_cnn():\n  model = Sequential()\n  model.add(Conv2D(16, 3, activation=relu, input_shape=(28, 28, 1)))\n  model.add(MaxPool2D())\n  model.add(Conv2D(32, 3, activation=relu))\n  model.add(MaxPool2D())\n  model.add(Flatten())\n  model.add(Dense(128, activation=relu))\n  model.add(Dense(10))\n  return model","ccff7a86":"(x_data, y_data), (x_test, y_test) = mnist.load_data()\nx_data = x_data[..., np.newaxis]\nx_test = x_test[..., np.newaxis]","2ef4148a":"x_data.shape, y_data.shape, x_test.shape, y_test.shape","86f32816":"(x_train, x_valid, y_train, y_valid) = train_test_split(\n    x_data, y_data, test_size=0.15, random_state=42)","b358d6c5":"print(x_train.shape, y_train.shape)\nprint(x_valid.shape, y_valid.shape)\nprint(x_test.shape, y_test.shape)","cd59ff35":"train_dataset = Dataset.from_tensor_slices((x_train, y_train))\nvalid_dataset = Dataset.from_tensor_slices((x_valid, y_valid))\ntest_dataset = Dataset.from_tensor_slices((x_test, y_test))","85e49ea5":"train_dataset = train_dataset.batch(64, True)\nvalid_dataset = valid_dataset.batch(64, True)\ntest_dataset = test_dataset.batch(64, True)","0c4a983d":"steps_per_epoch = x_train.shape[0]\/\/64\nvalidation_steps = x_valid.shape[0]\/\/64","838838cc":"model1 = get_shallow_cnn()\n\nmodel1.compile(optimizer=Adam(),\n              loss=SparseCategoricalCrossentropy(True),\n              metrics=['accuracy'])\n\nhistory1 = model1.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n              validation_data=valid_dataset,\n              epochs=10, validation_steps=validation_steps)","7c02c187":"model2 = get_shallow_cnn()\n\nmodel2.compile(optimizer=Adam(),\n              loss=SparseCategoricalCrossentropy(True),\n              metrics=[SparseCategoricalAccuracy()])\n\nhistory2 = model2.fit(\n    train_dataset, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_dataset,\n    epochs=10, validation_steps=validation_steps)","0e2b439f":"y_train = to_categorical(y_train)\ny_valid = to_categorical(y_valid)\ny_test = to_categorical(y_test)\nprint(y_train.shape, y_valid.shape, y_test.shape)\ntrain_dataset3 = Dataset.from_tensor_slices((x_train, y_train))\nvalid_dataset3 = Dataset.from_tensor_slices((x_valid, y_valid))\ntest_dataset3 = Dataset.from_tensor_slices((x_test, y_test))","b3d90adf":"train_dataset3.element_spec","fb2e6671":"train_dataset3 = train_dataset3.batch(64, True)\nvalid_dataset3 = valid_dataset3.batch(64, True)\ntest_dataset3 = test_dataset3.batch(64, True)","1643a88e":"train_dataset3.element_spec","d9687b49":"model3 = get_shallow_cnn()\n\nmodel3.compile(optimizer=Adam(),\n              loss=CategoricalCrossentropy(True),\n              metrics=[CategoricalAccuracy()])\n\nhistory3 = model3.fit(\n    train_dataset3, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_dataset3,\n    epochs=10, validation_steps=validation_steps)","ff929925":"history2.history.keys()","48ac9bff":"plt.style.use('ggplot')\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(12, 5))\n\naxes[0].set_xlabel(\"Epochs\", fontsize=14)\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].set_title('Loss vs epochs')\naxes[0].plot(history1.history[\"loss\"])\naxes[0].plot(history2.history[\"loss\"])\naxes[0].plot(history3.history[\"loss\"])\n\naxes[1].set_title('Accuracy vs epochs')\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epochs\", fontsize=14)\naxes[1].plot(history1.history[\"accuracy\"])\naxes[1].plot(history2.history[\"sparse_categorical_accuracy\"])\naxes[1].plot(history3.history[\"categorical_accuracy\"])\n\nplt.show()","b154453d":"(x_data, y_data), (x_test, y_test) = mnist.load_data()\nx_data = x_data[..., np.newaxis]\nx_test = x_test[..., np.newaxis]","1247a3ff":"x_data.shape, y_data.shape, x_test.shape, y_test.shape","a5a90860":"(x_train, x_valid, y_train, y_valid) = train_test_split(\n    x_data, y_data, test_size=0.15, random_state=42)","cbedb685":"img_generator = ImageDataGenerator(rescale=1\/255.0)","f10e6db2":"train_dataset = img_generator.flow(x_train, y_train, batch_size=64)\nvalid_dataset = img_generator.flow(x_valid, y_valid, batch_size=64)\ntest_dataset = img_generator.flow(x_test, y_test, batch_size=64)","e58e474c":"model5 = get_shallow_cnn()\n\nmodel5.compile(optimizer=Adam(),\n              loss=SparseCategoricalCrossentropy(True),\n              metrics=['accuracy'])\n\nhistory5 = model5.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n              validation_data=valid_dataset,\n              epochs=10, validation_steps=validation_steps)","f99623cb":"plt.style.use('ggplot')\nfig, axes = plt.subplots(1, 2, sharex=True, figsize=(12, 5))\n\naxes[0].set_xlabel(\"Epochs\", fontsize=14)\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].set_title('Loss vs epochs')\naxes[0].plot(history5.history[\"loss\"])\n\naxes[1].set_title('Accuracy vs epochs')\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epochs\", fontsize=14)\naxes[1].plot(history5.history[\"accuracy\"])\n\nplt.show()","4bed4ac3":"#### using model compiled with 'Accuracy':","9a688daa":"\n\n```\nmodel3 = get_shallow_cnn()\n\nmodel3.compile(optimizer=Adam(),\n              loss=SparseCategoricalCrossentropy(True),\n              metrics=[Accuracy()])\n\nhistory3 = model3.fit(\n    train_dataset, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_dataset,\n    epochs=10, validation_steps=validation_steps)\n\n# Results in an error:\n    ValueError: Shapes (64, 10) and (64, 1) are incompatible\n\n```\n\n","506e8a22":"### ImageDataGenerator\n\ntf.keras image data generator object is specifically designed for images","3209e452":"Why are they exactly not the same??\n\nFrom which places did the randomness creep in.","0d822d5b":"## mnist","860a7a70":"### Dataset\n\nIn this section we will use the tensorflow Dataset object to create a generator for train, test, valid data and use it it to train the network.","b94f205b":"## networks","e317306a":"#### using model compiled with 'accuracy':","565d390a":"#### using model compiled with 'sparse categorical accuracy':"}}