{"cell_type":{"e8b143cf":"code","eb1457ab":"code","39b6bba4":"code","360395e9":"code","7d34c0d7":"code","a7497787":"code","033bceb9":"code","010c66f2":"code","717d77dd":"code","555e6c23":"code","443dac3f":"code","2246d989":"code","0f6aa98a":"code","87bf45b7":"code","d383a99b":"code","11c6ce51":"code","551ffd7f":"code","91fc90d1":"code","b019dc54":"code","60fbcc80":"code","52292492":"code","de0cda01":"code","06e557b3":"code","28c132ba":"code","22c968a2":"markdown","767c620a":"markdown","566760db":"markdown","749d96a7":"markdown","075181e1":"markdown","8409818e":"markdown","540ef096":"markdown","ddab0883":"markdown","8df77c98":"markdown","6ad43c6e":"markdown","6c6483cc":"markdown","e693c620":"markdown"},"source":{"e8b143cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info\n\nimport os\nimport xgboost as xgb\n\n# Any results you write to the current directory are saved as output.","eb1457ab":"items = pd.read_csv('..\/input\/items.csv')\nshops = pd.read_csv('..\/input\/shops.csv')\ncats = pd.read_csv('..\/input\/item_categories.csv')\ntrain = pd.read_csv('..\/input\/sales_train.csv')\n# set index to ID to avoid droping it later\ntest  = pd.read_csv('..\/input\/test.csv').set_index('ID')","39b6bba4":"def eda(data):\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n    \ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)","360395e9":"eda(train)\ngraph_insight(train)","7d34c0d7":"# Drop Duplicate Data\nsubset = ['date', 'date_block_num', 'shop_id', 'item_id','item_cnt_day']\ndrop_duplicate(train, subset = subset)","a7497787":"# There are items with strange prices and sales.\n# After detailed exploration I decided to remove items with price > 100000 and sales > 1001 (1000 is ok).\n# for q in set(train.item_price):\n#     if q < 100000:\n#         train['color_item_price'] = 'black'\n#     else:\n#         train['color_item_price'] = 'red'\n\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","033bceb9":"train = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1001]","010c66f2":"print(train[train.item_price < 0])","717d77dd":"median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\ntrain.loc[train.item_price<0, 'item_price'] = median","555e6c23":"eda(test)\ngraph_insight(test)","443dac3f":"eda(items)\ngraph_insight(items)","2246d989":"# shops.loc[shops.shop_name == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"', 'shop_name'] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"'\n# shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n# shops.loc[shops.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\n# shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n# shops = shops[['shop_id','city_code']]\n\n# cats['split'] = cats['item_category_name'].str.split('-')\n# cats['type'] = cats['split'].map(lambda x: x[0].strip())\n# cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n# # if subtype is nan then type\n# cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n# cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n# cats = cats[['item_category_id','type_code', 'subtype_code']]\n\n# items.drop(['item_name'], axis=1, inplace=True)","0f6aa98a":"cats.head()","87bf45b7":"ts = time.time()\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in range(34):\n    sales = train[train.date_block_num==i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\ntime.time() - ts","d383a99b":"matrix.head(20)","11c6ce51":"train['revenue'] = train['item_price'] *  train['item_cnt_day']","551ffd7f":"l = list(cats.item_category_name)\nl_cat = l\n\nfor ind in range(1,8):\n    l_cat[ind] = 'Access'\n\nfor ind in range(10,18):\n    l_cat[ind] = 'Consoles'\n\nfor ind in range(18,25):\n    l_cat[ind] = 'Consoles Games'\n\nfor ind in range(26,28):\n    l_cat[ind] = 'phone games'\n\nfor ind in range(28,32):\n    l_cat[ind] = 'CD games'\n\nfor ind in range(32,37):\n    l_cat[ind] = 'Card'\n\nfor ind in range(37,43):\n    l_cat[ind] = 'Movie'\n\nfor ind in range(43,55):\n    l_cat[ind] = 'Books'\n\nfor ind in range(55,61):\n    l_cat[ind] = 'Music'\n\nfor ind in range(61,73):\n    l_cat[ind] = 'Gifts'\n\nfor ind in range(73,79):\n    l_cat[ind] = 'Soft'\n\n\ncats['cats'] = l_cat\ncats.head()","91fc90d1":"ts = time.time()\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0)\n                                .clip(0,20) # NB clip target here\n                                .astype(np.float16))\ntime.time() - ts","b019dc54":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)","60fbcc80":"train['date'] = pd.to_datetime(train.date,format=\"%d.%m.%Y\")\ntrain.head()","52292492":"p_df = train.pivot_table(index=['shop_id','item_id'], columns='date_block_num', values='item_cnt_day',aggfunc='sum').fillna(0.0)\np_df.head()","de0cda01":"train_cleaned_df = p_df.reset_index()\ntrain_cleaned_df['shop_id']= train_cleaned_df.shop_id.astype('str')\ntrain_cleaned_df['item_id']= train_cleaned_df.item_id.astype('str')\n\nitem_to_cat_df = items.merge(cats[['item_category_id','cats']], how=\"inner\", on=\"item_category_id\")[['item_id','cats']]\nitem_to_cat_df[['item_id']] = item_to_cat_df.item_id.astype('str')\n\ntrain_cleaned_df = train_cleaned_df.merge(item_to_cat_df, how=\"inner\", on=\"item_id\")\n\n# Encode Categories\nfrom sklearn import preprocessing\n\nnumber = preprocessing.LabelEncoder()\ntrain_cleaned_df[['cats']] = number.fit_transform(train_cleaned_df.cats)\ntrain_cleaned_df = train_cleaned_df[['shop_id', 'item_id', 'cats'] + list(range(34))]\ntrain_cleaned_df.head()","06e557b3":"ts = time.time()\ncache = {}\nmatrix['item_shop_last_sale'] = -1\nmatrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\nfor idx, row in matrix.iterrows():    \n    key = str(row.item_id)+' '+str(row.shop_id)\n    if key not in cache:\n        if row.item_cnt_month!=0:\n            cache[key] = row.date_block_num\n    else:\n        last_date_block_num = cache[key]\n        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n        cache[key] = row.date_block_num         \ntime.time() - ts\n","28c132ba":"param = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\n\n# param = {\n#      'max_depth'=8,\n#     'n_estimators'=1000,\n#     'min_child_weight'=300, \n#     'colsample_bytree'=0.8, \n#     'subsample'=0.8, \n#     'eta'=0.3,    \n#     'seed'=42\n# }\n\nprogress = dict()\nxgbtrain = xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values, train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values)\nwatchlist  = [(xgbtrain,'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values))\nfrom sklearn.metrics import mean_squared_error \nrmse = np.sqrt(mean_squared_error(preds,train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values))","22c968a2":"### Observations:\n\n* Each shop_name starts with the city name.\n* Each category contains type and subtype in its name.","767c620a":"## Overview of train dataset","566760db":"### mapping the categories","749d96a7":"For each month (date_block_num) it is agreggated a unique pair shop_id, item_id","075181e1":"## Auxiliar Functions","8409818e":"Imput median in the only price below zero","540ef096":"## Overview of item dataset","ddab0883":"agreggate train set by show\/item pais to calculate target, so the target will be similar to the test prediction","8df77c98":"## XGBOOST","6ad43c6e":"## Overview of test dataset","6c6483cc":"### Check if there is any price below zero","e693c620":"### generate revenue feature"}}