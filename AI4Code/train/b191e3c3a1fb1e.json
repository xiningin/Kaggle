{"cell_type":{"e45f231c":"code","1c9d5fb5":"markdown"},"source":{"e45f231c":"import numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import LocalOutlierFactor\n\nnp.random.seed(42)\n\nxx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n\n# Generate normal (not abnormal) training observations\nX = 0.3 * np.random.randn(100, 2)\nX_train = np.r_[X + 2, X - 2]\n\n# Generate new normal (not abnormal) observations\nX = 0.3 * np.random.randn(20, 2)\nX_test = np.r_[X + 2, X - 2]\n\n# Generate some abnormal novel observations\nX_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n\n# fit the model for novelty detection (novelty=True)\nclf = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\nclf.fit(X_train)\n\n# DO NOT use predict, decision_function and score_samples on X_train as this\n# would give wrong results but only on new unseen data (not used in X_train),\n# e.g. X_test, X_outliers or the meshgrid\ny_pred_test = clf.predict(X_test)\ny_pred_outliers = clf.predict(X_outliers)\nn_error_test = y_pred_test[y_pred_test == -1].size\nn_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n\n# plot the learned frontier, the points, and the nearest vectors to the plane\nZ = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.title(\"Novelty Detection with LOF\")\nplt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\na = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='darkred')\nplt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n\n\ns = 40\nb1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white', s=s, edgecolors='k')\nb2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='blueviolet', s=s,\n                 edgecolors='k')\nc = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='gold', s=s,\n                edgecolors='k')\n\nplt.axis('tight')\nplt.xlim((-5, 5))\nplt.ylim((-5, 5))\nplt.legend([a.collections[0], b1, b2, c],\n           [\"learned frontier\", \"training observations\",\n            \"new regular observations\", \"new abnormal observations\"],\n           loc=\"upper left\",\n           prop=matplotlib.font_manager.FontProperties(size=11))\nplt.xlabel(\n    \"errors novel regular: %d\/40 ; errors novel abnormal: %d\/40\"\n    % (n_error_test, n_error_outliers))\nplt.show()\n","1c9d5fb5":"## Novelty detection with Local Outlier Factor (LOF)\n\nThe Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for novelty detection. Note that when LOF is used for novelty detection you MUST not use predict, decision_function and score_samples on the training set as this would lead to wrong results. You must only use these methods on new unseen data (which are not in the training set). See User Guide <outlier_detection>: for details on the difference between outlier detection and novelty detection and how to use LOF for outlier detection.\n\nThe number of neighbors considered, (parameter n_neighbors) is typically set 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by samples that can potentially be local outliers. In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general."}}