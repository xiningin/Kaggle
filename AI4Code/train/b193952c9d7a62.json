{"cell_type":{"564222c8":"code","91c67d82":"code","1f9eff70":"code","62be402c":"code","84b9ad09":"code","17f70ce3":"code","7d29a7fa":"code","3b481732":"code","66be155c":"code","fbce6a89":"code","f87c1647":"code","0ef8be84":"code","8660c7af":"code","23e452cb":"code","6ccedce3":"code","a152cdeb":"code","423aa20c":"code","e8266690":"code","92edaee9":"code","4dfca7cf":"code","4da263b1":"code","6ebf49ac":"code","5f0773be":"code","711ad78d":"code","b509bd36":"code","f6447d6f":"code","9eeb3465":"code","09e03fb5":"code","14b9f5b1":"code","739a1d00":"code","252fe7d8":"code","79679632":"code","842d3e30":"code","88c01cd6":"code","18557427":"code","1a829105":"code","1bbeb97c":"code","c05d6688":"code","18225ace":"code","e024cf4d":"code","22066879":"code","a5ea4918":"code","1c57554d":"code","26780780":"code","cbe8c9d0":"code","2fd63796":"code","84a44bd0":"code","06370e33":"code","c08c696e":"code","65c7ad99":"code","251839bc":"code","dead3a12":"code","8bfa6c20":"markdown","80fc146a":"markdown","84550395":"markdown","c27b8d3b":"markdown","7a47a0b1":"markdown","e380df3a":"markdown","82fa2da5":"markdown","ca303170":"markdown","39ba309b":"markdown","c00dd610":"markdown","dc3c7e73":"markdown","3e1ccfe6":"markdown","4c4ef228":"markdown","b52ffe0d":"markdown","8fd9b650":"markdown","a6978e08":"markdown","80e69d16":"markdown","e345862f":"markdown","deaeb168":"markdown","877b0304":"markdown","b9a6020e":"markdown","b8596890":"markdown","13621e1e":"markdown","439a72bb":"markdown","ffb97d28":"markdown","476d141f":"markdown","9069f89b":"markdown","be4b04bb":"markdown"},"source":{"564222c8":"%load_ext autoreload\n%autoreload 2\n\n\n%matplotlib inline","91c67d82":"import numpy as np\nimport pandas as pd\n\nfrom fastai.imports import *\n#from fastai.structured import *\n#from structured import *\nfrom fastai.tabular import *\nfrom fastai import *\n#from fastai_structured import *\n\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nfrom scipy.cluster import hierarchy as hc\n\nfrom fastai_structured import *","1f9eff70":"!ls ..\/input\/","62be402c":"PATH = \"..\/input\/\"\n!ls {PATH}","84b9ad09":"## Training dataset\ndf_raw = pd.read_csv(f'{PATH}diamonds.csv', low_memory=False,\n                    index_col = 'Unnamed: 0')","17f70ce3":"df_raw.head()","7d29a7fa":"df_raw.describe()","3b481732":"plt.hist(list(df_raw.carat), bins=10, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Carats\")\nplt.title(\"Occurance of varying carats\")","66be155c":"new_index = ['Ideal', 'Premium', 'Very Good', 'Good', 'Fair']\nplt.bar(df_raw.groupby('cut').count().iloc[:,0].reindex(new_index).index,\n       df_raw.groupby('cut').count().iloc[:,0].reindex(new_index)\/len(df_raw.cut))\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Cuts\")\nplt.title(\"Occurance of varying cuts\")","fbce6a89":"df_raw.color.unique()","f87c1647":"new_index = ['E', 'F', 'G', 'H', 'I', 'J']\nplt.bar(df_raw.groupby('color').count().iloc[:,0].reindex(new_index).index,\n       df_raw.groupby('color').count().iloc[:,0].reindex(new_index)\/len(df_raw.cut))\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Color\")\nplt.title(\"Occurance of varying color\")","0ef8be84":"plt.hist(list(df_raw.depth), bins=100, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Depth\")\nplt.xlim(55,70)\nplt.title(\"Occurance of varying depth\")","8660c7af":"plt.hist(list(df_raw.table), bins=30, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Table\")\nplt.xlim(50,70)\nplt.title(\"Occurance of varying table\")","23e452cb":"plt.hist(list(df_raw.x), bins=30, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"X\")\nplt.xlim(3,10)\nplt.title(\"Occurance of varying x\")","6ccedce3":"plt.hist(list(df_raw.y), bins=100, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Y\")\nplt.xlim(3,10)\nplt.title(\"Occurance of varying y\")","a152cdeb":"plt.hist(list(df_raw.z), bins=100, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Z\")\nplt.xlim(2,6)\nplt.title(\"Occurance of varying z\")","423aa20c":"plt.hist(list(df_raw.price), bins=100, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Price\")\nplt.title(\"Occurance of varying price\")","e8266690":"df_raw['price'] = np.log(df_raw['price']); df_raw['price'].head()","92edaee9":"plt.hist(list(df_raw.price), bins=100, edgecolor='white')\nplt.ylabel(\"Occurance\")\nplt.xlabel(\"Price\")\nplt.title(\"Occurance of varying price\")","4dfca7cf":"train_cats(df_raw)\n#apply_cats(df_test_raw,df_raw)","4da263b1":"(df_raw.isnull().sum().sort_values(ascending=False)\/len(df_raw)).head(10)","6ebf49ac":"df, y, nas = proc_df(df_raw, 'price')","5f0773be":"X_train,X_valid,y_train,y_valid = train_test_split(df,y,test_size=0.25, random_state=42)","711ad78d":"def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","b509bd36":"m = RandomForestRegressor(n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","f6447d6f":"m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","9eeb3465":"import IPython\nimport graphviz\n\ndef mydraw_tree(t, df, size=10, ratio=0.6, precision=0):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))","09e03fb5":"## Draw tree is fastai\nmydraw_tree(m.estimators_[0], X_train, precision=3)","14b9f5b1":"df_nosize = df.copy()","739a1d00":"df_nosize.columns","252fe7d8":"df_nosize = df_nosize.drop(['carat','depth','table','x','y','z'],axis=1)","79679632":"df_nosize.head()","842d3e30":"X_train,X_valid,y_train,y_valid = train_test_split(df_nosize,y,test_size=0.25, random_state=42)","88c01cd6":"m = RandomForestRegressor(n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","18557427":"X_train","1a829105":"m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","1bbeb97c":"import IPython\nimport graphviz\n\ndef mydraw_tree(t, df, size=10, ratio=0.6, precision=0):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))","c05d6688":"## Draw tree is fastai\nmydraw_tree(m.estimators_[0], X_train, precision=3)","18225ace":"X_train,X_valid,y_train,y_valid = train_test_split(df,y,test_size=0.25, random_state=42)","e024cf4d":"m = RandomForestRegressor(n_estimators=100,n_jobs=-1,oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","22066879":"## Each tree is found in m.estimators_\n\npreds = np.stack([t.predict(X_valid) for t in m.estimators_])\npreds[:,0], np.mean(preds[:,0]), y_valid[0]","a5ea4918":"plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(100)]);","1c57554d":"param_grid = {\n    'min_samples_leaf': [1, 5, 10],\n    'max_features': [0.5, 1],\n    'n_estimators': [20],\n    'n_jobs': [-1],\n    'random_state': [42]\n}\n\nm = RandomForestRegressor(n_estimators=20)\n\ngrid_search = GridSearchCV(m, param_grid=param_grid, cv=5, iid=False,\n                           verbose=1, scoring='neg_mean_squared_error');\ngrid_search.fit(X_train, y_train);\n#print(grid_search.cv_results_)","26780780":"print(grid_search.best_score_)","cbe8c9d0":"print(grid_search.best_params_)","2fd63796":"myscoredf = pd.DataFrame(grid_search.cv_results_)[['param_min_samples_leaf','param_max_features','mean_test_score']]; myscoredf.head(10)","84a44bd0":"myscoredf = myscoredf.pivot('param_min_samples_leaf','param_max_features','mean_test_score')","06370e33":"ax = sns.heatmap(myscoredf, annot=True, fmt=\".5g\", cmap=cm.coolwarm)","c08c696e":"m = RandomForestRegressor(n_estimators=20,\n                          min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n                          max_features=grid_search.best_params_['max_features'],\n                          n_jobs=-1)\nm.fit(X_train, y_train);\nprint_score(m)","65c7ad99":"fi = rf_feat_importance(m, df); fi[:10]","251839bc":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","dead3a12":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nplot_fi(fi[:30]);","8bfa6c20":"## Looking at feature importance","80fc146a":"****R2 = 0.99****","84550395":"1. Size is the most important: especially carat and y. However, probably high colinearity (have not checked yet)\n2. Random forest can be used to predict this well. (although simpler linear models may also be alright)","c27b8d3b":"only marginal improvement after 20 estimators","7a47a0b1":"## Data preprocessing","e380df3a":"## Looking at feature importance","82fa2da5":"## Importing libraries","ca303170":"only R2=0.1","39ba309b":"## Running a basic untuned RF ","c00dd610":"1. Check how model fares with high carat diamonds (may have less samples)\n2. Given the R2 and how everything is based on size, a linear model with transformed (logged) price may also work well\n3. The interaction between x, y, z and carat may be interesting to explore","dc3c7e73":"Seems like carat and y are most important. Lets drop size dimensions to have a look:","3e1ccfe6":"Note that y, x, z and carat are correlated which a dendrogram would probably show!","4c4ef228":"Still not normally distributed but much better!","b52ffe0d":"# Predicting diamond prices","8fd9b650":"Packages required to run this piece of code:\n\n1. Numpy\n2. Pandas\n3. Matplotlib\n4. Sklearn\n5. graphviz\n6. Fastai0.7","a6978e08":"#### Checking data","80e69d16":"Automatic reloading and inline plotting","e345862f":"Note that this is very skewed, not normal distribution","deaeb168":"## Key findings","877b0304":"The aim of this project is to create a model that accurately predicts diamond prices","b9a6020e":"No NaNs! Happy days!","b8596890":"#### Reading in data","13621e1e":"## Future work","439a72bb":"Check for NaNs","ffb97d28":"## Tuning RF","476d141f":"Clarity and color seems to be the most important non size feature","9069f89b":"Obviously more people buy low carat diamonds than high carat diamond. This means the data may be inbalanced for prediction of high carat diamonds. While I may not have time to do this, I would recommend repeating the ****under-represented samples**** or using K fold cross validation cleverly to always include all of the rare samples","be4b04bb":"Dealing with categorical data:"}}