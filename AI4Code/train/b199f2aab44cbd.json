{"cell_type":{"68fe6f12":"code","99b17611":"code","2777d1d5":"code","a0af9ccf":"code","343586ca":"code","03f79507":"code","11ab0050":"code","3781c484":"code","2275f166":"code","142f47c4":"code","7163784e":"code","c6f071d5":"code","bb8b6c22":"code","b76ef58b":"code","17da233c":"code","b19aa35e":"code","26e5c180":"code","e3082ea0":"code","023c6c0e":"code","7acbbf87":"code","42bf5741":"code","2da99d92":"code","84d3bc04":"code","cc261b13":"code","41c857f2":"code","d062c452":"code","4278ce32":"code","ef79d475":"code","7ad7b63d":"code","b7aaaf89":"code","32b15aa6":"code","5c1220fd":"code","18d17b83":"code","f2448098":"code","94d3a7be":"code","161020e5":"code","4e44809f":"code","6be36688":"code","39536319":"code","337e6920":"code","5861996c":"code","3a1ed287":"code","34825b4f":"code","041b57c7":"code","5d6c6868":"code","442f03cc":"code","2385ee1f":"code","1a168e8a":"code","dfc00df3":"code","0a1445c4":"code","f7403472":"code","6f0ec0c8":"code","b1b4b9bd":"code","2842f261":"code","15dab9cb":"code","2c8d7f38":"code","d008e536":"code","f22cf840":"code","4ef6250b":"code","8aa90d3d":"code","f04ceb72":"markdown","efb496c1":"markdown","40e1ac5a":"markdown","bd3c30aa":"markdown","d6d15674":"markdown","5b6da10d":"markdown","3808bce7":"markdown","bee693ec":"markdown","219c9129":"markdown","e831305e":"markdown","e4a217e2":"markdown","d0dc0deb":"markdown","90bd439e":"markdown","15110a6f":"markdown","b989a402":"markdown","06191a85":"markdown","61f8f7f6":"markdown","eedf1bdc":"markdown","a798bcdc":"markdown","90be689b":"markdown","79279aec":"markdown","cd8ccaed":"markdown","234d63b6":"markdown","4fa8b662":"markdown","86eb6156":"markdown","940d8386":"markdown","8b4417f4":"markdown","b5e96f95":"markdown","55472aa5":"markdown","9584da1b":"markdown","a2be8d31":"markdown","0f444e01":"markdown","5aa2cce6":"markdown","de620ebc":"markdown","2aac043f":"markdown","d144c7ce":"markdown","8fbff097":"markdown","8c08421d":"markdown"},"source":{"68fe6f12":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default='notebook'","99b17611":"df_demographic=pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/demographic.csv')","2777d1d5":"df_demographic.head()","a0af9ccf":"df_diet=pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/diet.csv')","343586ca":"df_diet.head()","03f79507":"df_examination=pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/examination.csv')","11ab0050":"df_examination.head()","3781c484":"df_labs=pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/labs.csv')","2275f166":"df_labs.head()","142f47c4":"df_questionnaire=pd.read_csv('..\/input\/national-health-and-nutrition-examination-survey\/questionnaire.csv')","7163784e":"df_questionnaire.head(5)","c6f071d5":"df=pd.concat([df_demographic, df_diet, df_examination, df_labs, df_questionnaire], axis=1)","bb8b6c22":"df.shape","b76ef58b":"null=100*(df.isnull().sum())\/(df.shape[0])","17da233c":"df_null=pd.DataFrame({'percentage':null})","b19aa35e":"df_null.head()","26e5c180":"df_high=df_null[df_null['percentage']>70]","e3082ea0":"df_high.head()","023c6c0e":"df.drop(list(df_high.index),axis=1, inplace=True)","7acbbf87":"print(df.dtypes.unique())","42bf5741":"df_type=pd.DataFrame({'type':df.dtypes})","2da99d92":"df_object=df_type[df_type['type']=='object']","84d3bc04":"df_object.head()","cc261b13":"df_object.shape","41c857f2":"df.drop(list(df_object.index), axis=1,inplace=True)","d062c452":"null=100*(df.isnull().sum())\/(df.shape[0])","4278ce32":"df_null=pd.DataFrame({'percentage':null})","ef79d475":"df_medium=df_null[(df_null['percentage']<70) & (df_null['percentage']>0.5)]","7ad7b63d":"for x in list(df_medium.index):\n    df[x]=df[x].fillna(df[x].mean())","b7aaaf89":"df.dropna(axis=0, inplace=True)","32b15aa6":"df.shape","5c1220fd":"new=[]\nfor x in list(df.isnull().sum().values):\n    if x!=0:\n        print(x)\n    else:\n        new.append(x)\nprint(new)","18d17b83":"print(df.dtypes.unique())","f2448098":"ss=StandardScaler()","94d3a7be":"ss.fit(df)","161020e5":"scaled_df=ss.transform(df)","4e44809f":"scaled_df","6be36688":"scaled_df.shape","39536319":"pca=PCA()\npca.fit(scaled_df)","337e6920":"plt.figure(figsize=(12,8))\nplt.bar(x=list(range(1,754)), height=pca.explained_variance_ratio_,color='black')\nplt.xlabel('Components',fontsize=12)\nplt.ylim(0,0.06)\nplt.xlim(0,100)\nplt.ylabel('Variance%',fontsize=12)\nplt.title('Variance of Components',fontsize=15)\nplt.show()","5861996c":"pca=PCA(n_components=3)","3a1ed287":"pca.fit(scaled_df)","34825b4f":"X_pca=pca.transform(scaled_df)","041b57c7":"X_pca","5d6c6868":"fig=px.scatter_3d(x=X_pca[:,0],y=X_pca[:,1],z=X_pca[:,2])\nfig.update_layout(\n    title={\n        'text': 'First vs. Second vs. Third Principal Components',\n        'y':0.92,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","442f03cc":"X=X_pca\ninertia=[]\nfor n in range (1,11):\n    model=KMeans( n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=111,algorithm='elkan')\n    model.fit(X)\n    inertia.append(model.inertia_)\nprint(inertia)","2385ee1f":"plt.figure(figsize=(8,6))\nsns.set_style('whitegrid')\nplt.plot(list(range(1,11)), inertia, linewidth=2, markersize=12, color='royalblue', marker='o',markerfacecolor='m', markeredgecolor='m')\nplt.xlabel('Number of Clusters',fontsize=15)\nplt.ylabel('Inertia',fontsize=15)\nplt.title('Inertia vs. Number of Clusters',fontsize=18)\nplt.show()","1a168e8a":"model=KMeans(n_clusters=4, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=111,algorithm='elkan')\nmodel.fit(X)\nlabels=model.labels_\ncenters=model.cluster_centers_","dfc00df3":"centers","0a1445c4":"fig=px.scatter_3d(data_frame=df,x=X_pca[:,0],y=X_pca[:,1],z=X_pca[:,2], color=labels, color_continuous_scale='emrld')\n\nfig.update_layout(\n    title={\n        'text': 'Clustering the Principal Components',\n        'y':0.92,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","f7403472":"df.head(2)","6f0ec0c8":"df.reset_index(inplace=True, drop=True)","b1b4b9bd":"df_components= pd.DataFrame(data=X_pca, columns=['Principal Component 1', 'Principal Component 2', 'Principal Component 3'])","2842f261":"df_components.shape","15dab9cb":"df.shape","2c8d7f38":"df_new= pd.concat([df,df_components],axis=1)","d008e536":"df_new['Cluster Label']=labels ","f22cf840":"df_new.head(2)","4ef6250b":"df_new['Cluster Label']=df_new['Cluster Label'].apply(lambda x:'first' if x==0  else 'second' if x==1 else 'third' if x==2 else 'fourth')","8aa90d3d":"df_new.head()","f04ceb72":"### Adding PCA and K-means Results to DataFrame ","efb496c1":"# ![11.jpg](attachment:11.jpg)","40e1ac5a":"## Introduction","bd3c30aa":"## Dimensionality Reduction by Principal Component Analysis (PCA)","d6d15674":"## Importing Libraries","5b6da10d":"### Finding the Optimal Number of Clusters ","3808bce7":"<div align=\"justify\">\n\nThe National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States.The NHANES interview includes demographic, socioeconomic, dietary, and health-related datasets. \n\nIn this notebook, the main goal is to determine the types of diseases affecting patients. For this purpose, first we will perform data cleaning and transform the data into a uniform format. Afterwards, we will sandardize the clean data and perform dimensionality reduction by Principal Component Analysis (PCA) as a preprocessing step prior to data segmentation. Finally, we  will find the main clusters or types of the diseases by KMeans Clustering.\n\n<\/div>\n","bee693ec":"We can see that all the null values are removed and the data is clean.","219c9129":"Now we create a new data frame. It allows us to add in the values of the three principal components to our data set. In addition, we also append the clusters labels to this new data frame.","e831305e":"## Finding the Clusters by KMeans Clustering","e4a217e2":"# <center> National Health Dataset Dimensionality Reduction and Clustering <center>","d0dc0deb":"### Standardizing the Data","90bd439e":"### Performing PCA with the Chosen number of components","15110a6f":"We concatenate five dataframes including df_demographic, df_diet, df_examination, df_labs and df_questionnaire.","b989a402":"## Conclusion","06191a85":"## Loading Dataset","61f8f7f6":"Finally, we should add the names of the clusters to the labels.","eedf1bdc":"We try to find the optimal number of components which capture the greatest amount of variance in the data.","a798bcdc":"In this figure, x, y and z axes are the first, second and third Principal Components, respectively. We can now clearly observe the segmentation of separate clusters.","90be689b":"First, we find the optimal number of clusters by elbow method.","79279aec":"Fianlly the columns that contain less than 0.5% null values are remained, and we drop the rows of df that contain these null values.","cd8ccaed":"The number of columns is 753, therefore, we will use Principal Component Analysis (PCA) as a dimensionality-reduction technique.","234d63b6":"We can see that if the number of clusters is smaller than 4, the inertia has a high value but if the number of clusters is larger than 4, the inertia is relatively constant. So we chose 4 as the optimal number of clusters.","4fa8b662":"Now we select the columns that contain more than 70% null values and remove them from df.","86eb6156":"We create a dataframe that shows the percentage of null values in each column of df.","940d8386":"## Data Cleaning ","8b4417f4":"Then we select the columns that contain between 0.5% and 70% null values, and replace the null values with the mean of each column.","b5e96f95":"Now we check whether the dataframe still contains null values.","55472aa5":"### Finding the Optimal Number of Principal Components ","9584da1b":"Now we perform PCA with the with the chosen number of components, 3.","a2be8d31":"### Visualizing the Clusters by Components","0f444e01":"There is a variance drop off at Number of components=3, and the first three components explain the majority of the variance in our data. So, we reduce the dimensionality by PCA using only 3 components.","5aa2cce6":"### Performing Clustering with the Optimal Number of Clusters ","de620ebc":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importing Libraries<\/a><\/span><\/li><li><span><a href=\"#Loading-Dataset\" data-toc-modified-id=\"Loading-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Loading Dataset<\/a><\/span><\/li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Data Cleaning<\/a><\/span><\/li><li><span><a href=\"#Dimensionality-Reduction-by-Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"Dimensionality-Reduction-by-Principal-Component-Analysis-(PCA)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Dimensionality Reduction by Principal Component Analysis (PCA)<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Standardizing-the-Data\" data-toc-modified-id=\"Standardizing-the-Data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Standardizing the Data<\/a><\/span><\/li><li><span><a href=\"#Finding-the-Optimal-Number-of-Principal-Components\" data-toc-modified-id=\"Finding-the-Optimal-Number-of-Principal-Components-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Finding the Optimal Number of Principal Components<\/a><\/span><\/li><li><span><a href=\"#Performing-PCA-with-the-Chosen-number-of-components\" data-toc-modified-id=\"Performing-PCA-with-the-Chosen-number-of-components-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Performing PCA with the Chosen number of components<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Finding-the-Clusters-by-KMeans-Clustering\" data-toc-modified-id=\"Finding-the-Clusters-by-KMeans-Clustering-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Finding the Clusters by KMeans Clustering<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Finding-the-Optimal-Number-of-Clusters\" data-toc-modified-id=\"Finding-the-Optimal-Number-of-Clusters-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Finding the Optimal Number of Clusters<\/a><\/span><\/li><li><span><a href=\"#Performing-Clustering-with-the-Optimal-Number-of-Clusters\" data-toc-modified-id=\"Performing-Clustering-with-the-Optimal-Number-of-Clusters-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>Performing Clustering with the Optimal Number of Clusters<\/a><\/span><\/li><li><span><a href=\"#Visualizing-the-Clusters-by-Components\" data-toc-modified-id=\"Visualizing-the-Clusters-by-Components-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>Visualizing the Clusters by Components<\/a><\/span><\/li><li><span><a href=\"#Adding-PCA-and-K-means-Results-to-DataFrame\" data-toc-modified-id=\"Adding-PCA-and-K-means-Results-to-DataFrame-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;<\/span>Adding PCA and K-means Results to DataFrame<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","2aac043f":"Now we select the columns that contain object datatypes and remove them from df.","d144c7ce":"So, when we further reduced the dimensionality by PCA, found out that we only need 3 components, and then we clustered the data to four seperate groups which represent types of diseases that affect patients.","8fbff097":"In order to increase the resolution, we limit the x axis between 0 and 100.","8c08421d":"In this notebook, we used  National Health and Nutrition Examination Survey (NHANES) datasets including demographic, socioeconomic, dietary, and health-related datasets. We performed the following steps:\n-  Conducted data cleaning, imputed missing values, created new features and transformed the data into a uniform format.\n\n-  Standardized the clean data, identified three components that explained the majority of variance in data, and performed dimensionality reduction by PCA as a preprocessing step prior to data segmentation. \n\n-  Determined four separate clusters as the most representative types of diseases affecting sample patients by K-means algorithm. Implemented K-means clustering and visualized clusters by principal components.\n"}}