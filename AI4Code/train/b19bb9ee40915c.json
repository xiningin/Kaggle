{"cell_type":{"d7c42e9e":"code","c2b9314f":"code","7fea9692":"code","f2581db6":"code","78ff7ed6":"code","d3ccee0d":"code","8c929af9":"code","2d9ed4d2":"code","5744720f":"code","e952e06d":"code","db116669":"code","6bcafc6d":"code","e212f898":"code","673bc93f":"code","41ae3029":"code","7a9784cd":"code","0641fc03":"code","f5f7c412":"code","81e6abd3":"code","81606fb5":"code","23fb515f":"code","48e68e34":"code","a07f1a41":"code","1a9596f1":"code","63dbefcf":"code","b2493e60":"code","e9c08c99":"code","5c7e725d":"code","00e59ebc":"code","cc3c14a7":"code","bd8fb7cd":"code","4b6ddcfd":"code","ab530c6e":"code","7be076df":"code","f3ddfe96":"code","763b7fff":"code","f19d00da":"code","3e833a6a":"code","3fba71f0":"code","eb15bc12":"code","418daf37":"code","fbba5933":"code","cf9bda0d":"code","c499e2c8":"code","deb35cf5":"code","81aaee7e":"code","36a3c71d":"code","8d937521":"code","b913583c":"code","50c4bbd7":"code","2fe125f0":"code","3459e11a":"code","a7e139f4":"code","f29f9c0d":"code","575b2649":"code","d557663d":"code","83993346":"code","c5e36795":"code","c7302afc":"code","1ba5a7d8":"code","8a5c6bd0":"code","af8cf869":"code","7bb3e184":"code","4cec4ad6":"code","1a272c2c":"code","fe2fff0c":"code","d8bfed50":"code","a84b6fbc":"code","3b88e7fc":"code","35215384":"code","13d82ac7":"code","96166761":"code","c5ca8663":"code","187e861f":"code","6d0b77ad":"code","31f35b94":"code","1463ccfa":"code","026ec6b9":"code","e091fda3":"code","4dfd83b5":"code","133cc88b":"code","5b0cde4f":"code","c9dac965":"code","1c80a4e2":"code","c6ac8265":"code","98c35a46":"code","389c8c5e":"code","3bc2a698":"code","d384491b":"code","ddc33e60":"markdown","8a71fbda":"markdown","34625a14":"markdown","b666aaef":"markdown","10b524aa":"markdown","15a8c162":"markdown","7e9c8db5":"markdown","30277d4f":"markdown","d5f6633a":"markdown","4b898289":"markdown","a980d78d":"markdown"},"source":{"d7c42e9e":"import pandas as pd\nimport numpy as np # importing np since you will have to use it at one point or the other with pandas!","c2b9314f":"# check pandas versions - NOTE THAT ALL PANDAS OPERATIONS ARE DEPENDANT ON THE VERSION YOU USE.\nprint(pd.__version__)\nprint(np.__version__)","7fea9692":"# create empty dataframe, specifying column names\ndf = pd.DataFrame(columns=['X', 'Y', 'Z'])\ndf","f2581db6":"# create dataframe from csv-formatted string\nfrom io import StringIO\ndfFromString = pd.read_csv(StringIO(\"Employee ID,Name,Age,Grade,Marital Status,Number of kids\\r\\n1,Chris,M,38,B,Married,1\\r\\n2,Mira,F,33,A,Single,0\"))\n\n# pd.head() returns the first few rows of a df, 5 by default ( tail() will return the last few )\nprint(\"Head:\")\nprint(dfFromString.head())\n\n# pd.shape returns the number of rows by columns\nprint(\"\\nShape:\")\nprint(dfFromString.shape)      \n\n# pd.size returns number of rows * number of columns\nprint(\"\\nSize:\")\nprint(dfFromString.size)\n\n# pd.dtypes returns types of each column\nprint(\"\\ndtypes:\")\nprint(dfFromString.dtypes)","78ff7ed6":"# create dataframe from list of lists, specifying column names\ndf = pd.DataFrame.from_records([[100,200,300,], [312,412,512], [689,789,889]], columns=['Col0', 'Col1', 'Col2'])\ndf.head()","d3ccee0d":"# create dataframe from dictionary, specifying column names\ndictData =  {'Harry': 38, 'Mary': 30,'Ben': 12,}\ndfDateVal = pd.DataFrame(list(dictData.items()), columns=['Name', 'Age'])\ndfDateVal","8c929af9":"# read CSV file online\/ using weblink\ndata1 = pd.read_csv(\"https:\/\/people.sc.fsu.edu\/~jburkardt\/data\/csv\/hw_200.csv\")\ndata1.head()","2d9ed4d2":"# read in data specifying seperator\/delimiter\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_2.csv', sep='|')\nemployeeData.head()","5744720f":"# read in a file not having a header\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_3.csv', header=None)\nemployeeData.head()","e952e06d":"# read in file specifying column types\ndata1 = pd.read_csv(\"\/kaggle\/input\/all-pandas-operations-reference\/Games.csv\", dtype={'Game Number':float})\ndata1.dtypes","db116669":"# read in file skipping some lines\napartmentData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Apartments.csv', skiprows=3)\napartmentData","6bcafc6d":"# specify column names while reading in CSV\ncol_names = ['Country_Name', 'Num_of_people', 'Language_Spoken']\ncountryDF = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv', names=col_names, header=0)\ncountryDF.head()","e212f898":"# read only a few of many columns\nempData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv', usecols=['ID', 'Name', 'Gender'])\nempData.head()","673bc93f":"# for using less memory, read in a column of repeating strings as type 'category;\nempData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv', dtype={'Marital Status':'category'})\nempData.dtypes","41ae3029":"# specify missing value labels while reading in data\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nemployeeData.tail(10) # print last few rows","7a9784cd":"# read in data having column of date time strings, parsing the column\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv', parse_dates=['Joining Datetime'])\nprint(\"dtypes:\\n\", employee_joining.dtypes)\n\nprint(\"\\nDF:\\n\", employee_joining.head())","0641fc03":"# filter DF by a particular string in a string-type column\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData[employeeData.Name.str.contains('ba')].head()","f5f7c412":"# basic info about a df\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData.info()","81e6abd3":"# statistical info about df\nemployeeData.describe()","81606fb5":"# see types of columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\ndtype_df = employeeData.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","23fb515f":"# print unique values in a column\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData.Grade.unique()","48e68e34":"# print number of unique values in a column\nemployeeData.Grade.nunique()","a07f1a41":"# print counts for each unique value in a column, including NA\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nemployeeData['Kids'].value_counts(dropna=False)","1a9596f1":"# percentage of each unique value in a column, including NA\nemployeeData['Kids'].value_counts(dropna=False, normalize=True) * 100","63dbefcf":"# crosstable of 2 columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\npd.crosstab(employeeData.Gender, employeeData.Grade)","b2493e60":"# get a single statistic for a column\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nemployeeData.groupby('Grade').Kids.mean()","e9c08c99":"# get multiple statistics for a column\nemployeeData.groupby('Grade').Kids.agg(['min', 'max', 'mean'])","5c7e725d":"# count how many rows have no missing values\nemployeeData.dropna().shape[0]","00e59ebc":"# location\/index\/position of all null values\nemployeeData.isnull().head(20)","cc3c14a7":"# number of null values by columns\nemployeeData.isnull().sum()","bd8fb7cd":"# print proportion of missing values per column, sorted\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\n\npercent_missing = employeeData.isnull().sum() * 100 \/ len(employeeData)\nmissing_value_df = pd.DataFrame({'column_name': employeeData.columns, 'percent_missing': percent_missing}).sort_values('percent_missing').set_index('column_name')\nmissing_value_df","4b6ddcfd":"# select using loc & \":\" \n# loc is inclusive on both sides\nemployeeData = pd.read_csv(\"\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv\")\nemployeeData.loc[0:3] # if columns location not specified, implicit mode used - all columns","ab530c6e":"# select using loc\n# 'loc' does not accept integers for columns; column names have to be used.\nemployeeData.loc[0:3, ['Name','Marital Status']]","7be076df":"# select using iloc\n# unlike 'loc', 'iloc' accepts integers for columns\n# iloc is exclusive on right side, so 1:4 means 1,2,3\nemployeeData.iloc[0:3, 2:4]","f3ddfe96":"# select columns from a list of strings\nemployeeData[['Name','Kids']].head()","763b7fff":"# select string-type single column using column name, on a single value\ndata2 = employeeData[employeeData.Name=='Henry']\ndata2.head()","f19d00da":"# select string-type single column on multiple values\ndata2 = employeeData.copy()\ndata2 = data2[data2[\"Name\"].isin([\"Henry\", \"Ava\"])]\ndata2.head()","3e833a6a":"# select rows NOT containing a particular string\ndata2 = employeeData.copy()\ndata2 = data2[~data2[\"Name\"].str.contains(\"o\")] # exclude names containing 'o'\ndata2.head()","3fba71f0":"# select on multiple columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData[(employeeData[\"Kids\"] == 3) & (employeeData[\"Marital Status\"] == 'Single')].head()","eb15bc12":"# select rows having missing values in a column\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nemployeeData[employeeData.Kids.isnull()].head()","418daf37":"# use a column as index, and then as a row-label for filtering\n# this column needs to have non-missing unique values\ncountryInfo1 = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint('\\n------- Before setting index ---------- \\n', countryInfo1.head())\n\ncountryInfo1.set_index('Country', inplace=True)\nprint('\\n------- After setting index ---------- \\n', countryInfo1.head())\n\nprint(\"\\nCanada's population: {}\".format(countryInfo1.loc['Canada', 'Population']))","fbba5933":"# sort by index\ncountryInfo1.sort_index()","cf9bda0d":"# selecting rows on timestamps\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv', parse_dates=['Joining Datetime'])\nemployee_joining.loc[employee_joining['Joining Datetime'] >= pd.to_datetime('1\/1\/1933'), :]","c499e2c8":"# add a new column having constant values\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo before:\\n\", countryInfo.head())\n\ncountryInfo[\"Population density\"] = 20000\nprint(\"\\ncountryInfo after:\\n\", countryInfo.head())","deb35cf5":"# create a new column based on conditions of existing column(s)\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nprint(\"employeeData before:\\n\", employeeData.head())\n\nemployeeData['isMale'] = np.where(employeeData['Gender']=='M', 'yes', 'no')\nprint(\"\\nemployeeData after:\\n\", employeeData.head())","81aaee7e":"# rename columns - using dictionary to specify old & new names\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo before:\\n\", countryInfo.head())\n\ncountryInfo.rename(columns={'Population':'Pop.'}, inplace=True)\n\nprint(\"\\ncountryInfo after:\\n\", countryInfo.head())","36a3c71d":"# rename columns - using a list to rename all columns\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo before:\\n\", countryInfo.head())\n\ncountryInfo.columns = ['Cntry', 'Pop.', 'LANG.']\n\nprint(\"\\ncountryInfo after:\\n\", countryInfo.head())","8d937521":"# rename multiple column names using single operation\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\ncountryInfo.columns = ['Country_Name', 'Country_Population', 'Country_Language']\nprint(\"countryInfo before:\\n\", countryInfo.head())\n\n# replace th string \"Country_\" with \"C_\"\ncountryInfo.columns = countryInfo.columns.str.replace('Country_', 'C_')\n\nprint(\"\\ncountryInfo after:\\n\", countryInfo.head())","b913583c":"# remove a single column\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo before:\\n\", countryInfo.head())\n\ncountryInfo.drop('Population', axis=1, inplace=True)\n\nprint(\"\\ncountryInfo after:\\n\", countryInfo.head())","50c4bbd7":"# remove multiple columns -  using a list of names of columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nprint(\"employeeData before:\\n\", employeeData.head())\n\nemployeeData.drop(['Hobbies', 'Kids'], axis=1, inplace=True)\n\nprint(\"\\nemployeeData after:\\n\", employeeData.head())","2fe125f0":"# remove multiple columns - using positions of columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nprint(\"employeeData before:\\n\", employeeData.head())\n\nemployeeData.drop(data2.columns[3:], axis=1, inplace=True)\n\nprint(\"\\nemployeeData after:\\n\", employeeData.head())","3459e11a":"# change a column type\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo.dtypes before:\\n\", countryInfo.dtypes)\n\ncountryInfo.Population = countryInfo.Population.astype(float)\n\nprint(\"\\ncountryInfo.dtypes after:\\n\", countryInfo.dtypes)","a7e139f4":"# convert all object-type columns to categorical\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\nprint(\"countryInfo.dtypes before:\\n\", countryInfo.dtypes)\n\nlisCatCols = ['Country', 'Main Language']\ncountryInfo[lisCatCols] = countryInfo[lisCatCols].astype('category')\n\nprint(\"\\ncountryInfo.dtypes after:\\n\", countryInfo.dtypes)","f29f9c0d":"# change a column type, making misformatted data NaN\ncountryInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language_with_errors.csv')\nprint(\"countryInfo before:\\n\", countryInfo.head())\nprint(\"\\ncountryInfo.dtypes before:\\n\", countryInfo.dtypes)\n\ncountryInfo.Population = pd.to_numeric(countryInfo.Population, errors='coerce')\n\nprint(\"\\n\\ncountryInfo after:\\n\", countryInfo.head())\nprint(\"\\ncountryInfo.dtypes after:\\n\", countryInfo.dtypes)","575b2649":"# add a new column for rows having similar column value(s)\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nprint(\"employeeData before:\\n\", employeeData.head())\n\n# for each row, add a column of total people having the same number of kids\nemployeeData['other'] = employeeData.groupby('Kids')['Kids'].transform('count')\n\nprint(\"\\nemployeeData after:\\n\", employeeData.head())","d557663d":"# drop rows having missing data in any col\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nprint(\"Df Shape before: \", employeeData.shape)\nemployeeData.dropna(how='any', inplace=True) # use 'all' for checking all columns\nprint(\"Df Shape after: \", employeeData.shape)","83993346":"# drop NAs in any of specified columns\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nprint(\"Df Shape before: \", employeeData.shape)\nemployeeData.dropna(subset=['Kids', 'Hobbies'], how='any', inplace=True)\nprint(\"Df Shape after: \", employeeData.shape)","c5e36795":"# replace NAs in a column with a value\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nemployeeData['Hobbies'].fillna(value='Not reported', inplace=True)\n\n# check that substitution took place\nemployeeData[employeeData['Hobbies'] == 'Not reported'].head()","c7302afc":"# replace NAs in all columns of dataframe by median of corresponding column\n## df = pd.read_csv(.........)\n## df = df.fillna(df.median())","1ba5a7d8":"# drop columns having percentage of missing values greater than 80\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_4_with_NAs.csv', na_values=['', \"NA\", \"--\"])\nprint(\"Df Shape before: \", employeeData.shape)\n\n# drop columns having more than 5% data missing\nemployeeData = employeeData.loc[:, employeeData.isnull().mean() < .05]\n\nprint(\"Df Shape after: \", employeeData.shape)","8a5c6bd0":"# capitalise all entries of string column\nemployeeData.Name = employeeData.Name.str.upper()\nemployeeData.Name.head()","af8cf869":"# replace a particular string\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData.Name = employeeData.Name.str.replace('ba', 'za') # this will affect the name 'Sebastian'\n\n# check for names containing 'za' now\nemployeeData[employeeData.Name.str.contains('za')]","7bb3e184":"# get mean of columns using 'axis' parameter, this will work on ONLY numeric columns\/rows\nemployeeData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nemployeeData.mean() # axis = 0, if unspecified","4cec4ad6":"# convert column of timestamp strings to datetime\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv')\nemployee_joining['Joining Datetime'] = pd.to_datetime(employee_joining['Joining Datetime'])\nprint(\"dtypes:\\n\", employee_joining.dtypes)","1a272c2c":"# convert a column of timestamp strings to datetime, specifying format\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv')\nemployee_joining['Joining Datetime'] = pd.to_datetime(employee_joining['Joining Datetime'],\n                                                      format=\"%m\/%d\/%Y %H:%M\")\nemployee_joining.dtypes","fe2fff0c":"# to see time difference between consecutive rows of a datetime column\nemployee_joining['Joining Datetime'].diff()","d8bfed50":"# extract year, month, day, day of year, week, hour, minute\nemployee_joining['Joining Datetime'].dt.hour","a84b6fbc":"# difference between timestamps, extract days\n(employee_joining['Joining Datetime'].max() - employee_joining['Joining Datetime'].min()).days","3b88e7fc":"# add a new column for seconds since 1st Jan 1900 (For Epoch i.e. 1970, change appropriately)\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv', parse_dates=['Joining Datetime'])\n\nemployee_joining['EpochTime'] = (employee_joining['Joining Datetime'] - pd.Timestamp(\"1900-01-01\")) \/\/ pd.Timedelta('1s')\nemployee_joining.head()","35215384":"# set datetime column as index, filter rows between string timestamps\nemployee_joining = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Joining.csv', parse_dates=['Joining Datetime'])\n\ntemp_emp = employee_joining.copy()\ntemp_emp.set_index('Joining Datetime', inplace=True)\n\ntemp_emp.loc['1930-06-01 22:00:00':'1931-12-31 19:00:00']","13d82ac7":"# find any duplicated rows\norgData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/OrgData.csv')\norgData.duplicated() # returns a Series of booleans","96166761":"# get number of duplicates\norgData.duplicated().sum()","c5ca8663":"# to see rows which are duplicated\norgData.loc[orgData.duplicated(keep='first'), :] # show first occurence of dup","187e861f":"# drop duplicate rows\nprint('size of OrgData before dropping: {}'.format(orgData.shape))\n\norgData.drop_duplicates(inplace=True)\n\nprint('size of OrgData after dropping: {}'.format(orgData.shape))","6d0b77ad":"# use only certain columns when checking for duplication\norgData.duplicated(subset=['Name', 'Gender'])","31f35b94":"# check whether duplicate columns exist, keep only the first, delete the rest\ncompanyInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/CompanyInfo.csv')\nprint('size of companyInfo before dropping dup. columns: {}'.format(companyInfo.shape))\n\ncompanyInfo = companyInfo.loc[:,~companyInfo.T.duplicated(keep='first')]\nprint('size of companyInfo after dropping dup. columns: {}'.format(companyInfo.shape))","1463ccfa":"# drop columns with constant values( only 1 value) throughout\n\norgData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/OrgData.csv')\n\n# make a column having constant\/same value\norgData[\"const_col\"] = 23\n\nprint(\"Dataframe before:\\n\", orgData.head())\n\norgData = orgData.loc[:, orgData.apply(pd.Series.nunique) != 1]\nprint(\"\\n\\nDataframe after:\\n\", orgData.head())","026ec6b9":"# create a copy of a dataframe to work on\ncompanyInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/CompanyInfo.csv')\ncompanyInfo_copy = companyInfo.copy()\n\ncompanyInfo_copy.head()","e091fda3":"# sort pandas df by column\ncompanyInfo.sort_values('People', ascending=False, inplace=True) # for multiple columns, pass in list of columns\ncompanyInfo","4dfd83b5":"# remove single row by index\ncompanyInfo.drop(1, axis=0, inplace=True)\ncompanyInfo","133cc88b":"# get numpy values of entire DF\nnumpy_values = companyInfo.values\nnumpy_values","5b0cde4f":"# extract 80% random rows from a column\ncompanyInfo.Business.sample(frac=0.8)","c9dac965":"# shuffle pandas rows randomly\ncompanyInfo = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/CompanyInfo.csv')\nsample = companyInfo.sample(frac=1)\nsample","1c80a4e2":"# save CSV to disk as a file, without saving index column\nsample.to_csv('sample.csv', index=False)","c6ac8265":"'''\nPowerful function to reduce RAM usgae, definitely use this for serious model building\nreference: https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65\n\nparameters: \nprops: DF to reduce\nverbose: optional, default True\n    Whether to print compression stats or not\n\nreturns:\ndf with reduced size\nlist of columns with NA filled in\n\nusage: \ndf, NAlist = reduce_mem_usage(df) # compression stats printed\ndf, _ = reduce_mem_usage(df, False) # compression stats NOT printed, ignore NA list\n\n'''\ndef reduce_mem_usage(props, verbose):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2\n    \n    if verbose:\n        print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            if verbose:\n                print(\"******************************\")\n                print(\"Column: \",col)\n                print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            if verbose:\n                print(\"dtype after: \",props[col].dtype)\n                print(\"******************************\")\n    \n    if verbose:\n        # Print final result\n        print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n        mem_usg = props.memory_usage().sum() \/ 1024**2 \n        print(\"Memory usage is: \",mem_usg,\" MB\")\n        print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n        \n    return props, NAlist","98c35a46":"empData = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Employee_Data_1.csv')\nempData, _ = reduce_mem_usage(empData, verbose=False)","389c8c5e":"# reset index of dataframe\ncountryInfo.reset_index(inplace=True)\ncountryInfo.head()","3bc2a698":"# use multiple datasets for slicing\/dicing\/further EDA\n\n# read in one datafile of some countries\ncountryInfo1 = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Population_Language.csv')\ncountryInfo1.set_index('Country', inplace=True)\n\n# read in one more datafile containing areas of above countries\ncountryInfo2 = pd.read_csv('\/kaggle\/input\/all-pandas-operations-reference\/Country_Area.csv')\ncountryInfo2.set_index('Country', inplace=True)\n\n# calculate population density of all countries\ncountryInfo = countryInfo1.Population \/ countryInfo2.Area_in_million_sq_km\ncountryInfo","d384491b":"# merge\/join\/concatenate side by side dataframes. Dataframes should have the same indices\ncountryInfo = pd.concat([countryInfo1, countryInfo2], axis=1)\ncountryInfo.head()","ddc33e60":"## Operations regarding Duplication","8a71fbda":"## Tired of Googling for syntax each time you want to run a pandas operation? Well, I was. Remembering all the syntax may not be possible.\n\n## The aim of this notebook is to be your go-to resource for any & all pandas operations. Please comment for feature additions\/improvements\/errors","34625a14":"## Pandas Dataframes: Creating \/ Reading in data files","b666aaef":"## Indexing\/ Filtering \/ Selecting","10b524aa":"## MISC operations","15a8c162":"## Summary functions","7e9c8db5":"## Handling missing values","30277d4f":"## Column operations","d5f6633a":"## String operations on a column","4b898289":"## Operations on two or more dataframes","a980d78d":"## Date Time operations"}}