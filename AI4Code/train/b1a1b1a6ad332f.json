{"cell_type":{"2ecc5bb9":"code","d44aa504":"code","cd9af3a7":"code","025c0c76":"code","c366e962":"code","ea68f103":"code","667ec4fa":"markdown","6a1cd6c0":"markdown","6de9efb7":"markdown","7ff55bd0":"markdown","424b82cc":"markdown","15277bc2":"markdown","42f8e490":"markdown"},"source":{"2ecc5bb9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression","d44aa504":"lista = []\nX = np.arange(1,21) \nfor x in X:\n    lista.append(x+np.random.randint(6))\nY = np.array(lista)\ndf = pd.DataFrame({'X':X,'Y':Y[:20]})","cd9af3a7":"m,b = np.polyfit(X,Y[:20],1) #Define the coeficients of the equation as m and b\neq = m*X+b #Here define the equation\nplt.plot(df['X'],df['Y'], 'o') #Plot the points\nplt.plot(df['X'], eq, color='red');","025c0c76":"lr = LinearRegression() #Define the regression model\nlr.fit(df['X'].values.reshape(-1,1), df['Y'].values) #Fit the regression model\npredict = lr.predict(df['X'].values.reshape(-1,1)) #Make the prediction\nplt.scatter(df['X'].values, df['Y'].values) #Plot the points\nplt.plot(df['X'].values, predict, color='red'); #Plot the regression line","c366e962":"#Run to generate new datas\nlista = []\nX = np.arange(-25,60) \nfor x in X:\n    lista.append(x+np.random.randint(30))\nY = np.array(lista)\ndf = pd.DataFrame({'X':X,'Y':Y[:85]})","ea68f103":"m,b = np.polyfit(X,Y[:85],1)\neq = m*X+b\nfig = plt.figure(figsize=(12,6))\nplt.plot(df['X'],df['Y'], 'o')\nplt.plot(df['X'], eq, color='red')\nplt.box(False)\nplt.title('Linear regression\\n\\n',fontsize=22, fontweight='bold', fontfamily='serif')\nplt.text (df['X'].max()+1, df['Y'].max(), f'Y = {m:.3f}X + {b:.3f}',fontsize=12,fontfamily='serif')\nplt.vlines(x=0, ymin=df['Y'].min(), ymax=df['Y'].max())\nplt.hlines(y=0, xmin=df['X'].min(), xmax=df['X'].max())\nplt.xlabel('X axis', fontsize=16)\nplt.ylabel('Y axis', fontsize=16);","667ec4fa":"## Linear regression with Numpy\n\nIt is very simple using np.polyfit","6a1cd6c0":"## Now, we make a beautiful chart with new data\n\nI choose the Numpy, but the result is the same","6de9efb7":"## Linear regression with Scikit-learn\n\nIt is simple using LinearRegression()","7ff55bd0":"Linear regression is a technique used to model the relationships between observed variables. The idea behind simple linear regression is to \"fit\" the observations of two variables into a linear relationship between them. Graphically, the task is to draw the line that is \"best-fitting\" or \"closest\" to the points (x_i,y_i), where x_i an y_i are observations of the two variables which are expected to depend linearly on each other.\n![lr.png](attachment:lr.png)\n\nRegression is a common process used in many applications of statistics in the real world. There are two main types of applications:\n\nPredictions: After a series of observations of variables, regression analysis gives a statistical model for the relationship between the variables. This model can be used to generate predictions: given two variables xx and y,y, the model can predict values of yy given future observations of x.x. This idea is used to predict variables in countless situations, e.g. the outcome of political elections, the behavior of the stock market, or the performance of a professional athlete.\n\nCorrelation: The model given by a regression analysis will often fit some kinds of data better than others. This can be used to analyze correlations between variables and to refine a statistical model to incorporate further inputs: if the model describes certain subsets of the data points very well, but is a poor predictor for other data points, it can be instructive to examine the differences between the different types of data points for a possible explanation. This type of application is common in scientific tests, e.g. of the effects of a proposed drug on the patients in a controlled study.\n\nAlthough many measures of best fit are possible, for most applications the best-fitting line is found using the method of least squares. That is, viewing yy as a linear function of x,x, the method finds the linear function LL which minimizes the sum of the squares of the errors in the approximations of the y_i\tby L(x_i).\n\n**Font**: https:\/\/brilliant.org\/wiki\/linear-regression\/\n\n![lineareq.png](attachment:lineareq.png)\n\n","424b82cc":"## Import libraries\n\n**Pandas** and **Numpy** to create the data;\n\n**Numpy** to fit the linear regression;\n\n**Sklearn** to fit linear regression;\n\n**Matplotlib** to plot the points and the line.","15277bc2":"## Creating our data\n\n1. Create a empty list\n2. Create a variable X containing the values of the X label\n3. A **for loop** to add each element of the X label sum random values\n4. Crate an array with this list (that no more is empty) as variable Y\n5. Transform this array in a DataFrame using Pandas","42f8e490":"## A little bit of theory"}}