{"cell_type":{"c07855c1":"code","163a5e33":"code","539bc406":"code","3d5d55f8":"code","153b5897":"code","3035c23e":"code","4c5dbc28":"code","19fe9071":"code","b003edca":"code","6642b70f":"code","9c1c8a25":"code","85fbcff4":"code","e42090c3":"markdown","4b59c47f":"markdown","9a44b957":"markdown","ef9970eb":"markdown","24f6ecad":"markdown","193ac308":"markdown","44ace806":"markdown","e26d8bf6":"markdown","d385757c":"markdown","1ef69e95":"markdown"},"source":{"c07855c1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","163a5e33":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('\/kaggle\/input\/restaurant-reviews\/Restaurant_Reviews.tsv' , sep='\\t', quoting=3) #quoting removes '' \ndata.head()\n","539bc406":"import re # Regular expression operations\nimport nltk \n# library of natural language processing  to  download the symbols of stop words, which we don't want to include\n# like the or an (anything that is not helpful)\nnltk.download(\"stopwords\") # download all stopwords\nfrom nltk.corpus import stopwords # import to the notebook\nfrom nltk.stem.porter import PorterStemmer #to apply stemming on our reviews\n\n#stemming consist of taking only the root of a word that indicates enough about what this word means.\n# stemming the word 'love' etc\n\ncorpus = [] ## will contain all cleaned reviews\n#We will iterate through all reviews and we will clean each review (remove punctuations)\n\nfor i in range(0,1000):\n    # 1.. remove all punctuation\n    review = re.sub(\"[^a-zA-Z]\", \" \", data[\"Review\"][i])# can replace anything in a text, replace by spaces\n    #\u02c6-means no letters \"not\"- \n    #  not all the letters from a to z in lowercase nor the capital letters from a to z  by spaces\n    # The question: is where shall we replace: reviews\n    #[\"Review\"][i] - review of the loop\n    \n    #2.. to transform all the capital letters into lowercase.\n    review=review.lower()\n    \n    #3.. to split the different elements of the reviews in different words\n    # then we can apply stemming to each\n    \n    review=review.split()\n    \n    # 4.. Applying Stemming\n    # Need to not include Not in the stopwords\n\n    ps=PorterStemmer()\n    \n    all_stopwords=stopwords.words('english')\n    all_stopwords.remove('not')\n    review=[ps.stem(word) for word in review if not word in set(all_stopwords)] \n    \n    # we want not to include stopwords\n     #if the word of the review is not in the set of all the English stop word then we will consider for stemming\n    \n    #5.. Join all them together (as a strng format)\n    review= \" \".join(review) ## joining reviews and adding the space\n    \n    #6..add all cleaned reviews to the corpus\n    corpus.append(review)","3d5d55f8":"#print(corpus)","153b5897":"#the reviews in different rows and all the words from all the reviews in the different columns where\n#the sales will get a one if the word is in the review and a zero otherwise.","3035c23e":"#tokenazation\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features = 1500) #  the maximum size of sparse matrix. but before find the len of X\n\n#Reviews\nx=cv.fit_transform(corpus).toarray()\n# it will take all the words from all the reviews in the corpus and then using this\n#transform part of the method it will put all these words in different columns.\n#shall be a 2D array\n\n#Liked\ny=data.iloc[:,-1].values #taking the last column of the file","4c5dbc28":"len(x[0]) # words of tokenazation","19fe9071":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=0)","b003edca":"from sklearn.naive_bayes import GaussianNB\nclassifier=GaussianNB()\nclassifier.fit(x_train, y_train)\n\n# We can try different classification models","6642b70f":"y_pred=classifier.predict(x_test)\n#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","9c1c8a25":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm=confusion_matrix(y_test, y_pred)\nprint(cm)\n","85fbcff4":"accuracy_score(y_test, y_pred)","e42090c3":"## Predicting the Test set results","4b59c47f":"## Cleaning the texts","9a44b957":"## Importing the dataset","ef9970eb":"Basically we have 1566 words that were taken from all the reviews and for each of the reviews we\n\nhave either one in the columns corresponding to the words that are in the review and zero to all the\n\nother columns corresponding to the words that are not in the review.","24f6ecad":"## Training the Naive Bayes model on the Training set","193ac308":"# Natural Language Processing","44ace806":"## Creating the Bag of Words model","e26d8bf6":"## Making the Confusion Matrix","d385757c":"## Importing the libraries","1ef69e95":"## Splitting the dataset into the Training set and Test set"}}