{"cell_type":{"385751c5":"code","5d589787":"code","3ca6b87e":"code","d39f9b6f":"code","678075a7":"code","58d054bc":"code","0c0a5df2":"code","34da8d33":"code","9474663a":"code","21e7d821":"code","1be33e65":"code","3b93c308":"code","16213811":"code","951a4f1a":"code","19e5b40b":"code","445ee077":"code","3efcdf7b":"code","ca60c390":"code","5adaeb98":"code","bcfbeaff":"code","9911418f":"code","7aa1f904":"code","b60374a8":"code","e5f746c9":"code","35071220":"code","1677af6f":"code","3b93521f":"code","1a67b46f":"code","9a6053b7":"markdown","e34d646d":"markdown","512c13b8":"markdown","64458ffe":"markdown","7cc087cb":"markdown","249d41d5":"markdown","2f19aca4":"markdown","408b3ce9":"markdown","b146dc23":"markdown"},"source":{"385751c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d589787":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","3ca6b87e":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","d39f9b6f":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","678075a7":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","58d054bc":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Look at page 5\npdf = os.path.join(outputFolder,'mand.pdf[5]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg') # intro page to preview later","0c0a5df2":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/mand.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","34da8d33":"# Code by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook\n\n# Plot WordCloud of page 5\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 5 of Mandibular Recovering with AI\")","9474663a":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/mand.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","21e7d821":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p10\npdf = os.path.join(outputFolder,'mand.pdf[10]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage1 = Image.open('\/kaggle\/working\/mand.jpg')","1be33e65":"# PDF to JPG for p5\npdf = os.path.join(outputFolder,'mand.pdf[5]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage5 = Image.open('\/kaggle\/working\/mand.jpg')\n\n# PDF to JPG for p10\npdf = os.path.join(outputFolder,'mand.pdf[10]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage10 = Image.open('\/kaggle\/working\/mand.jpg')","3b93c308":"# Parse a PDF file and convert it to CSV using PyTesseract (p1)\ntext = pytesseract.image_to_string(pdfimage1)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","16213811":"# Parse a PDF file and convert it to CSV using Tika-Python (p5-10)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/mand.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/mand.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 5-10","951a4f1a":"#Explore page 10 -   Here we have 31 pages  \nw, h = pdfimage10.size # crop image\npdfimage10.crop((0, 300, w, h-900)) # display exerpt of PDF","19e5b40b":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p18\npdf = os.path.join(outputFolder,'mand.pdf[18]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage18 = Image.open('\/kaggle\/working\/mand.jpg')","445ee077":"#Explore page 18 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage18.size # crop image\npdfimage18.crop((0, 300, w, h-900)) # display exerpt of PDF","3efcdf7b":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p16\npdf = os.path.join(outputFolder,'mand.pdf[16]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage16 = Image.open('\/kaggle\/working\/mand.jpg')","ca60c390":"#Explore page 16 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage16.size # crop image\npdfimage16.crop((0, 300, w, h-900)) # display exerpt of PDF","5adaeb98":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p9\npdf = os.path.join(outputFolder,'mand.pdf[9]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage9 = Image.open('\/kaggle\/working\/mand.jpg')","bcfbeaff":"#Explore page 9 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage9.size # crop image\npdfimage9.crop((0, 300, w, h-900)) # display exerpt of PDF","9911418f":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p8\npdf = os.path.join(outputFolder,'mand.pdf[8]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage8 = Image.open('\/kaggle\/working\/mand.jpg')","7aa1f904":"#Explore page 8 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage8.size # crop image\npdfimage8.crop((0, 300, w, h-900)) # display exerpt of PDF","b60374a8":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p4\npdf = os.path.join(outputFolder,'mand.pdf[4]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage4 = Image.open('\/kaggle\/working\/mand.jpg')","e5f746c9":"#Explore page 4 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage4.size # crop image\npdfimage4.crop((0, 300, w, h-900)) # display exerpt of PDF","35071220":"# Convert PDF to JPG and then convert JPG to CSV\n\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p7\npdf = os.path.join(outputFolder,'mand.pdf[7]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/mand.jpg')\npdfimage7 = Image.open('\/kaggle\/working\/mand.jpg')","1677af6f":"#Explore page 7 - Mueller Report. Here, there are 31 pages \nw, h = pdfimage7.size # crop image\npdfimage7.crop((0, 300, w, h-900)) # display exerpt of PDF","3b93521f":"# Pages 5, 10, 8, 7 \ndfcombined.head() # preview csv of 5-11","1a67b46f":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","9a6053b7":"<iframe width=\"1214\" height=\"1280\" src=\"https:\/\/www.youtube.com\/embed\/5nUI0gnLzM0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>\n","e34d646d":"#Again I chose pg 18, but it's 19.","512c13b8":"![](https:\/\/i1.rgstatic.net\/publication\/339506901_Recovering_Mandibular_Morphology_after_Disease_with_Artificial_Intelligence\/links\/5e56657e4585152ce8f0330d\/largepreview.png)researchgate.net","64458ffe":"#With page 5, it didn't work. I never know why it happen that kind of issue. Though I chose pg 10, below it's 11. \n\nThe original crop values were 1240 and 1300. Changing to 300 (upper) and 900 (bottom) I got better perspective of the page.","7cc087cb":"#<font color=\"#EC7063\">Are you ready to 45 hours training the model?<\/font>\n\nTraining of the mandibular generator (page 16)\n\n\"The generation and completion models of this study were completed on the graphics processing unit (GPU) server of the high-performance computing platform of Central South University.\" ","249d41d5":"#Cropping Original was 1240. Changing to 300, got the upper of the page. H was 1300 with 900 got more bottom of the page.","2f19aca4":"http:\/\/ctgans.kuye.cn\/   \n\n<h1><span class=\"label label-default\" style=\"background-color:#DC143C;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:white; padding:10px\">Only 45 hours to train the model<\/span><\/h1><br>","408b3ce9":"#Acknowledgements\n\nAuthors: Ye Liang, JingJing Huan, Jia-Da Li, CanHua Jiang, ChangYun Fang, YongGang Liu\n\nDepartment of Stomatology, Xiangya Hospital, Central South University, Changsha, China\n\nSchool of Life Sciences, Central South University, Changsha, Hunan Province, China\n\nXiangya Application Institute, Engineering Research Center of Hunan Province of Material\n\nIncreasing Manufacturing, Central South University, Changsha, China\n\nhttps:\/\/www.medrxiv.org\/content\/10.1101\/2020.02.24.20027193v1.full.pdf\n\n\nScript by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook","b146dc23":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #DC143C;\"><b style=\"color:white;\">Recovering Mandibular Morphology with AI<\/b><\/h1><\/center>\n\n#Authors: Ye Liang, JingJing Huan, Jia-Da Li, CanHua Jiang, ChangYun Fang, YongGang Liu\n\nDepartment of Stomatology, Xiangya Hospital, Central South University, Changsha, China\n\nSchool of Life Sciences, Central South University, Changsha, Hunan Province, China\n\nXiangya Application Institute, Engineering Research Center of Hunan Province of Material\n\nIncreasing Manufacturing, Central South University, Changsha, China\n\n\"Mandibular tumors and radical oral cancer surgery often cause bone dysmorphia and defects. Most patients present with noticeable mandibular deformations, and doctors often have difficulty determining their exact mandibular morphology. In this study, a deep convolutional generative adversarial network (DCGAN) called CTGAN is proposed to complete 3D   mandibular cone beam computed tomography (CBCT) data from CT data.\"\n\n\"After extensive training CTGAN was tested on 6 mandibular tumor cases, resulting in 3D virtual mandibular completion. The authors found that CTGAN can generate mandibles with different levels and rich morphology, including positional and angular changes and local patterns. The completion results are shown as tomographic images combining generated and natural areas. The 3D generated mandibles have the anatomical morphology of the real mandibles and transition smoothly to the portions without disease, showing that CTGAN constructs mandibles with the expected patient characteristics and is suitable for mandibular morphological completion. The presented modeling principles can be applied to other areas for 3D morphological completion from medical images.\"\n\nhttps:\/\/www.medrxiv.org\/content\/10.1101\/2020.02.24.20027193v1.full.pdf"}}