{"cell_type":{"36e1cb9a":"code","58d1b46b":"code","64bdde13":"code","7cb8ffeb":"code","bf48f5b2":"code","ab5129d3":"code","1f6ba8ff":"code","519936cb":"code","fe821545":"code","94edaeb0":"code","b83feb53":"code","83ee29fa":"code","63a437ab":"code","70f50da4":"code","0e5d6206":"code","c58a1579":"code","3e0e2101":"code","7cfbc52a":"markdown","461c12c7":"markdown","cb156149":"markdown","a1bce76a":"markdown","40b9530a":"markdown","ce2e7067":"markdown","a64254b0":"markdown","607cc01d":"markdown","033778fd":"markdown","ee681eb2":"markdown","b466636b":"markdown","1b901ccc":"markdown"},"source":{"36e1cb9a":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","58d1b46b":"data = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","64bdde13":"data.info()","7cb8ffeb":"data.head()","bf48f5b2":"data.tail()","ab5129d3":"data.shape","1f6ba8ff":"data.corr()","519936cb":"import matplotlib.pyplot as plt\nimport plotly as py\nimport seaborn as sns\n","fe821545":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,fmt='.1f')\nplt.show()","94edaeb0":"sns.pairplot(data)\nplt.show()","b83feb53":"y = data.target.values\nx = data.drop([\"target\"],axis =1)","83ee29fa":"x_normalized = (x-np.min(x))\/(np.max(x)-np.min(x))","63a437ab":"from sklearn.model_selection import train_test_split","70f50da4":"x_train, x_test, y_train, y_test = train_test_split(x_normalized,y,test_size=0.17,random_state=42)","0e5d6206":"from sklearn.tree import DecisionTreeClassifier\n","c58a1579":"dt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)","3e0e2101":"dt.score(x_test,y_test)","7cfbc52a":"Variable Description:\n1. age       : Age of patient\n1. sex       : Gender of patient (1 = male; 0 = female)\n1. cp        : Chest pain type\n1. trestbps  : Resting blood pressure (in mm Hg on admission to the hospital)\n1. chol      : Serum cholestoral in mg\/dl\n1. fbs       : Fasting blood sugar > 120 mg\/dl (1 = true; 0 = false)\n1. restecg   : Resting electrocardiographic results\n1. thalach   : Maximum heart rate achieved\n1. exang     : Exercise induced angina (1 = yes; 0 = no)\n1. oldpeak   : ST depression induced by exercise relative to rest\n1. slope     : The slope of the peak exercise ST segment\n1. ca        : Number of major vessels (0-3) colored by flourosopy\n1. thal      : 3 = normal; 6 = fixed defect; 7 = reversable defect\n1. target    : Has disease (1 = yes; 0= no)\n\nfloat(1): oldpeak\n\nint(13):age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, slope, ca, thal and target   ","461c12c7":"* Normalization","cb156149":"<a id=2>\n# Virtualization","a1bce76a":"<a id = 4>\n# Conclusion","40b9530a":"We have a simple binary classification problem in here. I will use sklearn to develop a model.","ce2e7067":"* Training","a64254b0":"All possible graphs.","607cc01d":"* Spliting data to train and test subdatas","033778fd":"# Analysis and Modelling of Heart Disease Dataset\n<br>\n## Introduction\n    \n    This Kernel includes analysis data of Heart Diseases and Modeling an Machine Learning model.\n![](https:\/\/cdn.mos.cms.futurecdn.net\/FkvoCPACZCJaFKUEqDhB79-970-80.jpg)    \n    Content:\n1. [Analysis of Data](#1)\n    * Variable Description\n2. [Virtualization](#2)\n3. [Modelling](#3)\n4. [Conclusion](#4)","ee681eb2":"<a id = 3>\n# Modelling\n","b466636b":"<a id=1>\n# Analysis of Data","1b901ccc":"Speaking throghly we have 86.53 percent succes rated machine learning classification model. May be there are some diffirent classification models that work best."}}