{"cell_type":{"61c3e5d4":"code","de8c41d9":"code","a12d6a61":"code","8f83e399":"code","e45a12eb":"code","02ad4301":"code","6b65c3d3":"code","8a6b902a":"code","8b0551b0":"markdown","26460b30":"markdown","696dfd09":"markdown"},"source":{"61c3e5d4":"# Set-up code partially from \"Deep Neural Network Keras Way\" notebook\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow import keras\nfrom keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n# read train and test sets\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\n\n# set up training and testing data\nX_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])","de8c41d9":"# Data Preprocessing (from the aforementioned notebook)\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px\n\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","a12d6a61":"# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","8f83e399":"# Function for the model\ndef my_model():\n# Building the model\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=[28,28,1]),\n        preprocessing.RandomContrast(0.2),\n        preprocessing.RandomTranslation(height_factor=0.1,width_factor=0.1),\n        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n        layers.MaxPool2D(),\n        layers.BatchNormalization(axis=1),\n        layers.Flatten(),\n        layers.Dense(units=1024,activation='relu'),\n        layers.Dense(units=10, activation='softmax')\n    ])\n\n    # Compiling the model with 'adam' optimizer,\n    # \"categorical_crossentropy\" loss, and \"accuracy\" metric\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","e45a12eb":"# prepares data for training\nfrom sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1)","02ad4301":"# Fitting the model with Early Stopping\ncallback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\nmodel = my_model()\nhistory=model.fit(\n    X_train, y_train,\n    validation_data = (X_val, y_val),\n    epochs=50,\n    callbacks=[callback]\n)","6b65c3d3":"# train final model with all of the training data\ncallback_final = keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\nfinal_model= my_model()\nhistory=final_model.fit(X, y, epochs=50, callbacks=[callback_final])","8a6b902a":"# Final submission\npredictions = model.predict(X_test, verbose=0)\npredictions_final = predictions.argmax(axis=1)\nprint(predictions_final)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions_final)+1)),\n                         \"Label\": predictions_final})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)\nprint(\"Finished uploading submission file to csv\")","8b0551b0":"# The Model\nI am using a convolutional neural network with the following architecture:\n\n1. InputLayer(28, 28, 1)\n2. Preprocessing\n3. Conv2D(kernel_size=3, filters=32, activation='relu')\n4. BatchNormalization\n5. Conv2D(kernel_size=3, filters=64, activation='relu')\n6. BatchNormalization\n7. Conv2D(kernel_size=5, filters=128, activation='relu')\n8. BatchNormalization\n9. Conv2D(kernel_size=5, filters=128, activation='relu')\n10. MaxPool2D\n11. BatchNormalization\n12. Flatten\n13. Dense(units=1024,activation='relu')\n14. Dense(units=10, activation='softmax')","26460b30":"# Digit Recognizer Submission\nThe code starts with the imports and data handling\/preprocessing.","696dfd09":"This model trains to a maximum validation accuracy of about 97%.\n\nNow the model will be trained on the whole training data for final submission."}}