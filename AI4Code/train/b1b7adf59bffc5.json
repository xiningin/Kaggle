{"cell_type":{"b60e07c5":"code","22fc7491":"code","58d367a7":"code","4e8e540c":"code","c015fa6c":"code","d099434d":"code","f2609f4c":"code","d181ccd3":"code","ca34db14":"code","d4238316":"code","7d1fb199":"code","0ff0e458":"code","434112be":"code","a36587bb":"code","21c06925":"code","3ff4f6d1":"code","7275500b":"code","c452ce81":"code","e3a7764e":"markdown","80914c3f":"markdown","62b90512":"markdown","1ff1f48c":"markdown"},"source":{"b60e07c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)4\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22fc7491":"import tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model \nimport matplotlib.pyplot as plt\nimport cv2\nimport sklearn\nimport random\nfrom keras.callbacks import ModelCheckpoint\n\naugm = \".\/\"\ntrain_images_path = \"..\/input\/classification-with-limited-data\/food\/train\/images\"\ntrain_labels_path = \"..\/input\/classification-with-limited-data\/food\/train\/train.csv\" # direct path to the csv-file\n\ntest_images_path = \"..\/input\/classification-with-limited-data\/food\/test\/images\"\n\nimg_height = 224\nimg_width = 224\nimg_channels = 3\n\nnum_classes = 107","58d367a7":"df = pd.read_csv(train_labels_path)\ndf.head()","4e8e540c":"# Adapted from Niklas Dettmer's Notebook\n\naugment_factor = 8\nseed = 69\n\n\naugment_path = os.path.join(augm, 'augmented')\naug_images_path = os.path.join(augment_path, 'images')\n\nif not os.path.exists(augm):\n    os.mkdir(augm)\n    os.mkdir()\nif not os.path.exists(augment_path):\n    os.mkdir(augment_path)\nif not os.path.exists(aug_images_path):\n    os.mkdir(aug_images_path)\n    \ndef augment_image(image):\n    threshold = .5\n    aug = tf.convert_to_tensor(np.copy(image), dtype=tf.float32)\n    \n    if np.random.rand() < threshold:\n        aug = tf.image.random_flip_left_right(aug, seed)\n    if np.random.rand() < threshold:\n        aug = tf.image.random_flip_up_down(aug, seed)\n    if np.random.rand() < threshold:\n        aug = tf.image.resize(tf.image.random_crop(aug, [int(aug.shape[0] * 6\/10), int(aug.shape[1] * 6\/10), aug.shape[2]], seed), aug.shape[:-1])\n    if np.random.rand() < threshold:\n        noise = tf.random.normal(shape=aug.shape, mean=0.0, stddev=.15, dtype=tf.float32)\n        aug = tf.clip_by_value(tf.add(aug, noise), 0., 1.)\n\n    return aug.numpy()\n\nfor filename in os.listdir(train_images_path):\n    for i in range(augment_factor):\n        aug_image_path = os.path.join(aug_images_path, str(i) + \"-\" + filename)\n        if not os.path.exists(aug_image_path):\n            image = cv2.imread(os.path.join(train_images_path, filename)) \/ 255.\n\n            image = (augment_image(image) * 255.).astype(np.uint8)\n\n            cv2.imwrite(aug_image_path, image)\n            df.loc[len(df)] = [os.path.basename(aug_image_path), df.loc[df['Id'] == filename, 'Expected'].values[0]]\n            \n","c015fa6c":"\n\ndef get_augmented_fn(train_image_name):\n    augm_images_filenames = []\n    for fn in os.listdir(aug_images_path): \n        if train_image_name in fn:\n            augm_images_filenames.append(fn)\n    return augm_images_filenames\n    \ndef show_augmented(train_image_name):\n    rnd_aug = get_augmented_fn(train_image_name)\n    plt.figure()\n    \n    f, axarr = plt.subplots(1,len(rnd_aug)+1, figsize=(15,20))\n    axarr[0].axis(\"off\")\n    axarr[0].imshow((cv2.imread(os.path.join(train_images_path, org))\/255)[...,::-1])\n    i = 1\n    for img in rnd_aug:\n        axarr[i].imshow((cv2.imread(os.path.join(aug_images_path,img))\/255)[...,::-1])\n        axarr[i].axis(\"off\")\n        i = i + 1\n    \nfor i in range(10):    \n    org = np.random.choice(os.listdir(train_images_path))\n    show_augmented(org)","d099434d":"# source: https:\/\/medium.com\/@mrgarg.rajat\/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n\nfrom keras.utils import Sequence\nfrom skimage import util\n\nclass LabeledDataGenerator(Sequence):\n    \n    def __init__(self, image_filepaths, batch_size, augment_factor=4, seed=69):\n        self.image_filepaths = image_filepaths\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return (np.ceil(len(self.image_filepaths) \/ float(self.batch_size))).astype(np.int)\n    \n    def __getitem__(self, idx):\n        batch_x = self.image_filepaths[idx * self.batch_size: (idx+1) * self.batch_size]\n        \n        if os.path.basename(filename.split(\"-\")[-1]) not in df['Id'].values:\n            print(\"Entry for\", os.path.basename(filename.split(\"-\")[-1]), \"does not exist!\")\n        \n        images = np.array([\n            (cv2.imread(filename) \/ 255.)[...,::-1] for filename in batch_x\n        ], dtype=np.float32)\n        \n        labels = np.array([df.loc[df['Id'] == os.path.basename(filename), 'Expected'].values[0] for filename in batch_x], dtype=np.float32)\n        \n        labels = tf.one_hot(labels, depth=num_classes)\n        \n        return images, labels","f2609f4c":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nbatch_size = 32\ntrain_size_max = len(os.listdir(train_images_path)) * (augment_factor + 1)\ntrain_size = train_size_max\n\ntrain_images_filenames = os.listdir(train_images_path)\ntrain_images_filepaths = [os.path.join(train_images_path, filename) for filename in train_images_filenames]\ntrain_images_filepaths_shuffled = shuffle(train_images_filepaths)\n\ntrain_images_filepaths_t, train_images_filepaths_v = train_test_split(\n    train_images_filepaths_shuffled, test_size=.2, random_state=69)\n\naug_images_filepaths = [os.path.join(aug_images_path, filename) for filename in os.listdir(aug_images_path)]\ntrain_images_filepaths_t += aug_images_filepaths\ntrain_images_filepaths_t_shuffled = shuffle(train_images_filepaths)\n\ntrain_batch_gen_t = LabeledDataGenerator(train_images_filepaths_t, batch_size, seed=69)\ntrain_batch_gen_v = LabeledDataGenerator(train_images_filepaths_v, batch_size)\n","d181ccd3":"example_img = train_batch_gen_t[10][0][13]\nplt.figure()\nplt.subplot(1, 1, 1)\nplt.imshow(example_img)\nplt.show()","ca34db14":"from tensorflow.keras.applications import EfficientNetB3\nbase_model = EfficientNetB3(input_shape = example_img.shape, include_top = False, weights = 'imagenet')\n\n# add new classifier layers\ninputs = tf.keras.Input(shape=(img_height, img_width, 3))\nx = base_model(inputs)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.25)(x)\nx = layers.Dense(128, activation=\"sigmoid\")(x)\noutputs = layers.Dense(107, activation='softmax')(x)\n# define new model\nmodel = tf.keras.models.Model(inputs=inputs, outputs=outputs, name = \"classifier\")","d4238316":"checkpoint = ModelCheckpoint('.\/model.{epoch:02d}-{val_loss:.4f}.h5',\n                             monitor='val_loss',\n                             verbose=1,\n                             save_weights_only = True,\n                             save_best_only=True,\n                             mode=\"min\")\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),  # Optimizer\n    # Loss function to minimize\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    # List of metrics to monitor\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n)\nmodel.summary()\nmodel.load_weights(\"..\/input\/weights\/model.15-0.0049.h5\")","7d1fb199":"import time\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom datetime import datetime\n\nn_epochs = 15\n\ntf.keras.backend.clear_session()\n\ntrain_start = time.time()\n\ndef scheduler(epoch, lr):\n  if epoch < n_epochs * 1\/2:\n    return lr\n  else:\n    return lr * tf.math.exp(-0.1)\n\nclass_history = model.fit(\n    x = train_batch_gen_t,\n    epochs = n_epochs,\n    verbose = 1,\n    validation_data = train_batch_gen_v,\n    callbacks=[LearningRateScheduler(scheduler), checkpoint]\n)\n\nprint(\"Training finished.\")\nprint(\"Needed training time:*\", time.time() - train_start, \"s\")\n\nmodel.save_weights(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '_classifier.h5')","0ff0e458":"model.load_weights(\".\/model.15-0.0167.h5\")","434112be":"def get_predictions(img):\n    return model(img).numpy().reshape(-1)\n\ndef get_prediction(img):\n    return np.argmax(get_predictions(img))","a36587bb":"org_labels = pd.read_csv(train_labels_path)","21c06925":"\ndef show_others(file):\n    l = org_labels.loc[org_labels[\"Id\"] == file][\"Expected\"]\n    other_imgs = org_labels.loc[org_labels[\"Expected\"] == l.values[0]][\"Id\"]\n    img = (cv2.imread(os.path.join(train_images_path, file))\/255)[...,::-1]   \n    img = np.array([img])\n    prediction = np.argmax(get_predictions(img))\n    plt.figure()\n    \n    f, axarr = plt.subplots(1,len(other_imgs)+1, figsize=(30,50))\n    axarr[0].axis(\"off\")\n    axarr[0].set_title(f\"Model output: {prediction}\")\n    axarr[0].imshow((cv2.imread(os.path.join(train_images_path, file))\/255)[...,::-1])\n    i = 1\n    for img in other_imgs:\n        axarr[i].set_title(f\"Actual label: {l.values}\")\n        axarr[i].imshow((cv2.imread(os.path.join(train_images_path, img))\/255)[...,::-1])\n        axarr[i].axis(\"off\")\n        i = i + 1\n\n        \nfile = np.random.choice(os.listdir(train_images_path))  \nshow_others(file)","3ff4f6d1":"def show_wrong():\n    wrong_files = []\n    for img in os.listdir(train_images_path):\n        real_label = org_labels.loc[org_labels[\"Id\"] == img][\"Expected\"]\n        prediction = get_prediction(np.array([(cv2.imread(os.path.join(train_images_path, img))\/255)[...,::-1]]))\n        if not real_label.values == prediction:\n            print(f\"{real_label.values}  || {prediction}\")\n            wrong_files.add(img)\n    return wrong_files\nfor f in show_wrong():\n    show_others(f)","7275500b":"test_eval_df = pd.DataFrame(columns=[\"Id\", \"Expected\"])\n\nnumClasses = 107\nfor file in os.listdir(test_images_path):\n    \n    img = (cv2.imread(os.path.join(test_images_path, file))\/255)[...,::-1]\n    img = np.array([img])\n    \n    predictedClass = get_prediction(img)\n    test_eval_df.loc[len(test_eval_df)] = [file, predictedClass]","c452ce81":"test_eval_df.to_csv(datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\") + '_predictions.csv', index = False)","e3a7764e":"Train\/Validation split is applied before the augmented images are inserted into the train set. Otherwise, the validation accuracy might be artificially high. ","80914c3f":"The following functions are used to inspect some of the augmented images in relation to the original. ","62b90512":"## Data Augmentation\n\nThe following handles the creation of augmented images based on our test data set. Crop, rotation and noise are randomly applied.  ","1ff1f48c":"## Dataset generation and augmentation\n\n"}}