{"cell_type":{"0f225223":"code","54f1db28":"code","3925a945":"code","43035b16":"code","16ea1c79":"code","1952e845":"code","c6ded659":"code","8fb36b09":"code","712d230f":"code","c61d4ac0":"code","1758f605":"code","15d81ff1":"code","cf203646":"code","8d9aa705":"code","5ad5117f":"code","5f1d98b9":"code","04538c30":"code","8bb4f0ae":"code","b25f6c70":"code","de7b2c3a":"code","7f0b66d5":"code","0ffd6a87":"code","f8f541d5":"code","5ce80a72":"code","10f44fe8":"code","3bf5cb80":"code","ce2b6d7b":"code","0c1ec8fb":"code","4ac41d8e":"code","edbafe33":"code","f4a14397":"code","d1aff3ab":"code","33c89a01":"code","e485905a":"code","395a5e66":"code","27921936":"code","730d025b":"code","7accb27d":"markdown","25571209":"markdown","d16eb1d0":"markdown","6a59971c":"markdown","dccbd3a8":"markdown","32b42cdc":"markdown","3d43a7d7":"markdown","0e0ce998":"markdown","91772ae0":"markdown"},"source":{"0f225223":"# Packages for Data Wrangling\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nfrom collections import Counter\n\n# For graphs\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","54f1db28":"# Use cleaner absolute path to find file\npath = os.path.abspath('..\/input\/truth-detectiondeception-detectionlie-detection\/politifact.csv')\ndf = pd.read_csv(path, index_col=0)","3925a945":"# Check for null values and total number of rows\ndf.info()\ndf.shape","43035b16":"# to see statement in full\npd.set_option('display.max_colwidth', 200) \n\n# See sample of data\ndf.head(3)","16ea1c79":"# check groups that exist in veracity column\ndf.veracity.value_counts()","1952e845":"# Full Flop, Half Flip, & No Flip have nothing to do with veracity; remove them\n# Half-True doesn't help as it contains equal parts lie and truth\n\nver_df = df[~df.isin(['Full Flop',\n                    'Half Flip',\n                     'No Flip',\n                     'Half-True']).any(axis=1)]\n\nver_df.head(3)","c6ded659":"ver_df.veracity.value_counts()","8fb36b09":"# Transform variables into binary True\/False\nver_df = ver_df.replace({\"False\" : 0,\n                \"Mostly True\" : 1,\n                \"Mostly False\" : 0,\n                \"True\" : 1,\n                \"Pants on Fire!\" : 0\n               })\n\nver_df.head(3)","712d230f":"ver_df.info()","c61d4ac0":"# check imbalance\nver_df.veracity.value_counts()","1758f605":"# randomly sample 10 rows\nver_df.iloc[0:100:10]","15d81ff1":"# how many unique items per category?\nver_df.describe(include='all')","cf203646":"# top 10 sources\nver_df.source.value_counts()[:10]","8d9aa705":"chop = \"\/web\/20180705082623\"\nlen(chop)","5ad5117f":"link_chop_df = ver_df\nlink_chop_df.head()","5f1d98b9":"link_chop_df['link'] = link_chop_df['link'].apply(lambda x: x[len(chop):])","04538c30":"link_chop_df.head()","8bb4f0ae":"ver_df = link_chop_df\nver_df.head()","b25f6c70":"# extracting the date from the link column\n# r() = first group to extract; you can use multiple ()\n# ?P<column_name> = column name for convenience\n# \\d = digit\n# {n} = number of digits to include\n# . = wildcard\n# + = greedy search\n# ? = but not too greedy\nver_df[\"date\"] = ver_df.link.str.extract(r'(\\d{4}\/.+?\\d{2})')","de7b2c3a":"ver_df.head(3)","7f0b66d5":"# change the date column to a datetime column for convenience\nver_df.date = pd.to_datetime(ver_df.date,infer_datetime_format=True)","0ffd6a87":"ver_df.info()","f8f541d5":"ver_df[:90:30]","5ce80a72":"#by year\nax = ver_df.groupby(ver_df.date.dt.year).count().plot(kind=\"bar\")\nax.legend_ = None\nplt.title(\"Distribution by Year\")\nplt.show()","10f44fe8":"#by month\nax = ver_df.groupby(ver_df.date.dt.month).count().plot(kind=\"bar\")\nax.legend_ = None\nplt.title(\"Distribution by Month\")\nplt.show()","3bf5cb80":"ver_df = ver_df.drop(columns='link')\ncleaned_df = ver_df\ncleaned_df.head()\n# ver_df.columns","ce2b6d7b":"cleaned_df[:100:10]","0c1ec8fb":"cleaned_df.to_csv('politifact_ner_cleaned_data.csv', index=True)","4ac41d8e":"df = pd.read_csv('politifact_ner_cleaned_data.csv')\ndf.head()","edbafe33":"import spacy\nfrom spacy import displacy\nimport pandas as pd","f4a14397":"df = pd.read_csv('politifact_ner_cleaned_data.csv')","d1aff3ab":"# Load up spacy large language model for NER (named entity recognition) and POS (part of speech) detection\nnlp = spacy.load('en_core_web_lg')","33c89a01":"# First sample\nnobj = nlp(df.statement[0])\npos = [(token.text, token.pos_) for token in nobj]\nprint(pos)","e485905a":"# Intuitive vizualization of how the POS tagger works\ndisplacy.render(nobj, \n                options = {\n                          \"distance\" : 100,\n                          \"arrow_stroke\" : 3, # thickness of arrow line\n                          \"arrow_width\" : 8, # thickness of arrow head\n                          \"font\" : \"Helvetica\", # font\n                          \"bg\" : \"#FFFFF\" # background color\n                         })","395a5e66":"# First sample\nnobj = nlp(df.statement[50])\npos = [(token.text, token.pos_) for token in nobj]\nprint(pos)","27921936":"# Intuitive vizualization of how the POS tagger works\ndisplacy.render(nobj,\n                style='ent',\n                options = {\n                          \"distance\" : 100,\n                          \"arrow_stroke\" : 3, # thickness of arrow line\n                          \"arrow_width\" : 8, # thickness of arrow head\n                          \"font\" : \"Helvetica\", # font\n                          \"bg\" : \"#FFFFF\" # background color\n                         })","730d025b":"## End of notebook","7accb27d":"# Verify the dates of the data","25571209":"# Take every link and remove the beginning part up until HTTP(S)","d16eb1d0":"## Named Entity Recognition Tags","6a59971c":"# Vizualize POS and NER","dccbd3a8":"# Reindex Dataset for ease of use","32b42cdc":"# Initially 14209 rows of non-null data","3d43a7d7":"## Vizualize NER POS SD","0e0ce998":"# By removing irrelevant statements, 11118 rows survive","91772ae0":"## Dependency Parse & POS Tags"}}