{"cell_type":{"c8284b1c":"code","3fad59c0":"code","4b72a5d4":"code","4ef887e6":"code","f605e9ad":"code","6f858e8d":"code","cac20a07":"code","01188814":"code","8f8b4ca7":"markdown","e34722e6":"markdown","542f38ea":"markdown"},"source":{"c8284b1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fad59c0":"import warnings \nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns',None)\nfrom itertools import product\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nimport lightgbm as lgb","4b72a5d4":"train=pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv')\n\n\ny=train['target']\ntrain.drop(['id','target'],axis=1,inplace=True)\ntest.drop(['id'],axis=1,inplace=True)\n\ntotal=pd.concat([train,test],axis=0,ignore_index=True)\n\ncol_cat=total.select_dtypes('object').columns.to_list()\ncol_num=total.select_dtypes('number').columns.to_list()\n\ntrain.shape,total.shape,len(col_cat),len(col_num)","4ef887e6":"class SeparateEncoder():\n    def cat_transform(self,df,cat_cols,encoding_list):\n        df_mod=pd.DataFrame()\n        for idx,cat in zip(encoding_list,cat_cols):\n            if idx==0:#One Hot\n                df_oh=pd.get_dummies(df[cat],prefix=cat,prefix_sep='_')\n                df_mod=pd.concat([df_mod,df_oh],axis=1)\n            elif idx==1:#LabelEncoder\n                le=LabelEncoder()\n                df_le=pd.DataFrame(le.fit_transform(df[cat]),columns=[cat])\n                df_mod=pd.concat([df_mod,df_le],axis=1)\n        (_,cat_feature_count)=df_mod.shape\n        return df_mod,cat_feature_count\n    \n    def num_transform(self,df,num_cols,add_pca=True,n_components=5):\n        df_num=df[num_cols]\n        SS=StandardScaler()\n        df_num=pd.DataFrame(SS.fit_transform(df_num),columns=num_cols)\n        if add_pca:\n            pca=PCA(n_components=n_components,random_state=0)\n            df_pca=pd.DataFrame(pca.fit_transform(df_num))\n            df_num=pd.concat([df_num,df_pca],axis=1)\n        else:\n            pass\n        return df_num  \n    \n    def merge_transform(self,df,cat_cols,num_cols,encoding_list,add_pca=True,n_components=5):\n        df_cat,cat_feature_count=self.cat_transform(df,cat_cols,encoding_list)\n        df_num=self.num_transform(df,num_cols,add_pca=add_pca,n_components=n_components)\n        df_merge=pd.concat([df_cat,df_num],axis=1)\n        return df_merge,cat_feature_count","f605e9ad":"#parameters after optuna\nlgbm_params = {\n    'objective':'binary',\n    'metric': 'auc', \n    'n_jobs':-1,\n    'verbosity':-2,\n    'n_estimators': 20000,\n    'reg_alpha': 0.000721024661208569,\n    'reg_lambda': 47.79748127808107,\n    'colsample_bytree': 0.24493010466517195,\n    'subsample': 0.12246675404710294,\n    'learning_rate': 0.013933182980403087,\n    'max_depth': 21,\n    'num_leaves': 90,\n    'min_child_samples': 144,\n    'cat_smooth': 63\n}","6f858e8d":"n_splits=10\nskf=StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=0)\nse=SeparateEncoder()","cac20a07":"%%time\nencoding_list=np.ones(len(col_cat))\ne_list=[0,0,0]\nfor l,m in zip([1,5,10],list(range(3))):\n    encoding_list[l]=e_list[m]\n\ndf_merge_total,cat_feature_count=se.merge_transform(total,col_cat,col_num,encoding_list,add_pca=False)\ndf_merge_train,df_merge_test=df_merge_total.iloc[:len(train),:],df_merge_total.iloc[len(train):,:]\nscore=0\npreds=pd.DataFrame(columns=[f'pred{c}'for c in range(n_splits)])\n\nfor k,(train_idx,val_idx) in enumerate(skf.split(df_merge_train,y)):\n    print(f'------Fold{k+1}')\n    X_train,y_train=df_merge_train.iloc[train_idx,:],y[train_idx]\n    X_val,y_val=df_merge_train.iloc[val_idx,:],y[val_idx]\n\n    l_train=lgb.Dataset(X_train,y_train)\n    l_val=lgb.Dataset(X_val,y_val)\n    model = lgb.train(params=lgbm_params,\n                    num_boost_round=1000,\n                    early_stopping_rounds=400,\n                    train_set=l_train,\n                    valid_sets=[l_val,l_train],\n                    verbose_eval=500)         \n    val_pred=model.predict(X_val)\n    score+=roc_auc_score(y_val,val_pred)\/n_splits\n    preds[f'pred{k}']=model.predict(df_merge_test)\/n_splits\n\nprint('\\n')\nprint('='*50)\nprint(score)\nprint('='*50)","01188814":"submission=pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsubmission['target']=preds.sum(axis=1)\nsubmission.to_csv('submission_lgbm.csv',index=False)\nsubmission","8f8b4ca7":"**Thanks for reading!**\n\n**Please let me know if you have any questions and advice.**","e34722e6":"# Summary\n\nSimple LightGBM model without Tuning.\n\nFor more details about encoding, please visit here --> [TPS Mar 21| LabelEncoder vs. OneHotEncoder](https:\/\/www.kaggle.com\/mayasakaguchi\/tps-mar-21-labelencoder-vs-onehotencoder)\n\nLightGBM parameter from [https:\/\/www.kaggle.com\/svyatoslavsokolov\/tps-mar-2021-lgbm](https:\/\/www.kaggle.com\/svyatoslavsokolov\/tps-mar-2021-lgbm)","542f38ea":"# Submission Files"}}