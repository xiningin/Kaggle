{"cell_type":{"93592f4a":"code","9bae203e":"code","955b07a5":"code","4d5ddc2c":"code","08e8a478":"code","0c26dcbd":"code","6b85f606":"code","929df07c":"code","b64229a5":"code","7e17ab2e":"code","27e9d9c4":"code","a93588ec":"code","9d8bb366":"code","fab36101":"code","5fbd4b3e":"code","09490cce":"code","89f63369":"code","aa25a754":"code","9660f9a6":"code","df411a01":"code","6c616867":"code","a2b33020":"code","19929b5c":"code","961fbbe0":"code","7fed7de4":"code","aae59b1c":"code","8e8f60cf":"code","86c0ea49":"code","682e0b49":"code","5b3be2bd":"code","79c2e98a":"code","214d0da7":"code","0b3a1ec1":"code","56f9c712":"markdown"},"source":{"93592f4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9bae203e":"df = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')","955b07a5":"df.head(10)","4d5ddc2c":"df.info()","08e8a478":"print(np.unique(df['price_range']))","0c26dcbd":"df.describe()","6b85f606":"# Lets Divide the data to input and target\nX = df.iloc[:,0:20]\ny = df.iloc[:,-1]","929df07c":"# Lets do some Feature Selection for better results and accuracy\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest","b64229a5":"kbest = SelectKBest(chi2,k=10)","7e17ab2e":"best_feaures = kbest.fit(X,y)","27e9d9c4":"best_feaures.scores_","a93588ec":"df_features = pd.DataFrame(best_feaures.scores_)\ndf_columns = pd.DataFrame(X.columns)","9d8bb366":"featureScores = pd.concat([df_columns,df_features],axis=1)","fab36101":"featureScores.columns = ['Features','Score']","5fbd4b3e":"featureScores.sort_values(by='Score',ascending=False)","09490cce":"X = df[['ram','px_height','battery_power','px_width','mobile_wt','int_memory','sc_w','talk_time','fc','sc_h']]","89f63369":"X","aa25a754":"X = X.values\ny = y.values","9660f9a6":"print(X.shape,y.shape)","df411a01":"# lets do some normalisation and scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","6c616867":"y = y.reshape(-1,1)","a2b33020":"# now convert y labels to one hot encoder\nfrom sklearn.preprocessing import OneHotEncoder\nohot = OneHotEncoder()\ny = ohot.fit_transform(y)","19929b5c":"y = y.toarray()","961fbbe0":"# Train Test Split\nfrom sklearn.model_selection import train_test_split","7fed7de4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)","aae59b1c":"# Neural network Model\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import *\nimport matplotlib.pyplot as plt\n%matplotlib inline","8e8f60cf":"model = Sequential()\nmodel.add(Dense(8,activation='relu',input_dim = 10))\nmodel.add(Dense(6,activation='relu'))\nmodel.add(Dense(4,activation='softmax'))\nmodel.summary()","86c0ea49":"model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","682e0b49":"history = model.fit(X_train,y_train,epochs=105,validation_data=(X_test,y_test),batch_size=64)","5b3be2bd":"y_pred = model.predict(X_test)\n\n#lets do the inverse one hot encoding\npred = []\nfor i in range(len(y_pred)):\n    pred.append(np.argmax(y_pred[i]))\n    \n# also inverse encoding for y_test labels\n\ntest = []\nfor i in range(len(y_test)):\n    test.append(np.argmax(y_test[i]))","79c2e98a":"# accuracy of the model\nfrom sklearn.metrics import accuracy_score\nacc = accuracy_score(pred,test)\nprint(\"Accuracy of Your Model is = \" + str(acc*100))","214d0da7":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Features','Price_Weight'],loc='upper left')\nplt.show()","0b3a1ec1":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Features','Price_Weight'],loc='upper left')\nplt.show()","56f9c712":"### Please Upvote if you like the Notebook!\n### ThankYou!"}}