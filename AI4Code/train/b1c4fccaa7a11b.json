{"cell_type":{"8ed6c7d2":"code","9e4e2688":"code","a101f1b6":"code","788d53d7":"code","2b3b1ba5":"code","6b215f6d":"code","6f228e84":"code","3a99f9d8":"code","475b94ff":"code","6dbd48e0":"code","35c3a7b4":"code","7fc264ab":"code","4747fefc":"code","301ebbf4":"code","55f135a5":"code","2c8743c0":"code","69265862":"code","6878a9f6":"code","ea746186":"code","b6ce855c":"code","2f9cef11":"code","2484b127":"code","95705373":"code","4e185d2a":"code","f0541f2d":"code","ac59cf69":"code","eb407626":"code","12723f1c":"code","9552c8a7":"code","d1bd79b0":"code","65fa5eb6":"code","db969dab":"code","1d887f00":"code","feebe949":"code","ec687183":"code","7e7b8af3":"code","ce3c491c":"code","99660a97":"code","6b80d95a":"code","df51a8ba":"code","21815ffd":"code","da3ee950":"code","af484fdf":"code","b3ec9066":"code","6d4e9310":"code","853f45eb":"code","549ed36f":"code","4ae9a38f":"code","20051b0c":"code","9135181c":"code","6178637b":"code","be8912c5":"code","502be63f":"code","ccc3b637":"code","c9949d1e":"code","d0c2fb80":"code","3bfece04":"code","fdda049b":"code","d15976de":"code","b6fbeece":"code","dced430c":"code","12432af8":"code","2cfba2f9":"code","bf25e42e":"code","1a69ca1d":"code","ce20d0b1":"code","3181957d":"code","135e7f19":"code","938684ff":"code","2c7911f8":"code","e29f8fac":"code","5562d353":"code","2f6c39ac":"code","a4205baf":"code","dd8276c1":"code","97fdad81":"code","33ab295e":"code","69ee2b88":"code","e605965a":"code","2492155f":"code","580a799e":"code","ac53c01e":"code","064e8837":"code","715f8145":"code","0555a28b":"code","ed0a04da":"code","0b3ed1f4":"code","ab47c20e":"markdown","4fb7a303":"markdown","4c718eb5":"markdown","b2fb1790":"markdown","5484fa1b":"markdown","fe74fadc":"markdown","a1aaefa6":"markdown","a47a7c50":"markdown","1e248249":"markdown","8223c63f":"markdown","b7abc728":"markdown","174a030b":"markdown","73cd44df":"markdown","c121d163":"markdown","2c4d755f":"markdown","2fa482fb":"markdown","9217e7d1":"markdown","fc4626b7":"markdown","a79a8e35":"markdown","1635be74":"markdown","b0802b46":"markdown","5cac2a3c":"markdown","d3220db4":"markdown","2482ce07":"markdown","d8f41a58":"markdown","78f85bd4":"markdown","2ae739ad":"markdown","37bc4cbe":"markdown","1c7633b4":"markdown","e8162e1c":"markdown","e32d7d6b":"markdown","b64c1d8a":"markdown","a2c68071":"markdown","0f1be3f0":"markdown","fd068599":"markdown","faaa405a":"markdown","5f7a39da":"markdown","fd3f84b9":"markdown","c13f785e":"markdown","617deeb7":"markdown","33084eb5":"markdown","f4464f39":"markdown","bdb6fd77":"markdown","9bbd2cc5":"markdown","ce618321":"markdown","26da72d7":"markdown","d32b9aff":"markdown","053ecc7d":"markdown","17302528":"markdown","ba371061":"markdown","4d0d377c":"markdown","8ad0b34d":"markdown","4ede04a5":"markdown","977a143e":"markdown","0ad0c373":"markdown","079f0015":"markdown","091a9774":"markdown","29842a99":"markdown","141601c1":"markdown","8ff87b82":"markdown","82bd0c1a":"markdown","40a9897c":"markdown","4f6fb5d9":"markdown","df5b3c5c":"markdown","47ea2267":"markdown","44a1aa1d":"markdown","702746b9":"markdown","53915872":"markdown","5296459d":"markdown","c9b53f46":"markdown","9eb20fc1":"markdown","8f6f4f0b":"markdown","adeec6ef":"markdown","1339d588":"markdown","ec551d99":"markdown","3e318766":"markdown","47f0ff3b":"markdown","e72719d8":"markdown","940acb45":"markdown","ccc9cf57":"markdown","46ceff82":"markdown","bbdf25f2":"markdown","e27fc696":"markdown","59d20ea9":"markdown","244e49ef":"markdown","5b2e2967":"markdown","dc71ece4":"markdown","5e8fab47":"markdown","9e6e0993":"markdown","8c93b9b3":"markdown","d3e15f9b":"markdown","920d26d2":"markdown"},"source":{"8ed6c7d2":"import pandas as pd\n# Some sklearn tools for preprocessing and building a pipeline. \n# ColumnTransformer was introduced in 0.20 so make sure you have this version\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Our algorithms, by from the easiest to the hardest to intepret.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier","9e4e2688":"df = pd.read_csv('..\/input\/bank-marketing\/bank-additional-full.csv', sep = ';')\n\ndf.y.value_counts()","a101f1b6":"# Get X, y\ny = df[\"y\"].map({\"no\":0, \"yes\":1})\nX = df.drop(\"y\", axis=1)","788d53d7":"X.drop(\"duration\", inplace=True, axis=1)","2b3b1ba5":"X.dtypes","6b215f6d":"# Some such as default would be binary features, but since\n# they have a third class \"unknown\" we'll process them as non binary categorical\nnum_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n\ncat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]","6f228e84":"preprocessor = ColumnTransformer([(\"numerical\", \"passthrough\", num_features), \n                                  (\"categorical\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n                                   cat_features)])","3a99f9d8":"# Logistic Regression\nlr_model = Pipeline([(\"preprocessor\", preprocessor), \n                     (\"model\", LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\", random_state=42))])\n\n# Decision Tree\ndt_model = Pipeline([(\"preprocessor\", preprocessor), \n                     (\"model\", DecisionTreeClassifier(class_weight=\"balanced\"))])\n\n# Random Forest\nrf_model = Pipeline([(\"preprocessor\", preprocessor), \n                     (\"model\", RandomForestClassifier(class_weight=\"balanced\", n_estimators=100, n_jobs=-1))])\n\n# XGBoost\nxgb_model = Pipeline([(\"preprocessor\", preprocessor), \n                      # Add a scale_pos_weight to make it balanced\n                      (\"model\", XGBClassifier(scale_pos_weight=(1 - y.mean()), n_jobs=-1))])","475b94ff":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.3, random_state=42)","6dbd48e0":"gs = GridSearchCV(lr_model, {\"model__C\": [1, 1.3, 1.5]}, n_jobs=-1, cv=5, scoring=\"accuracy\")\ngs.fit(X_train, y_train)","35c3a7b4":"print(gs.best_params_)\nprint(gs.best_score_)","7fc264ab":"lr_model.set_params(**gs.best_params_)","4747fefc":"lr_model.get_params(\"model\")","301ebbf4":"lr_model.fit(X_train, y_train)","55f135a5":"y_pred = lr_model.predict(X_test)","2c8743c0":"accuracy_score(y_test, y_pred)","69265862":"print(classification_report(y_test, y_pred))","6878a9f6":"import eli5\neli5.show_weights(lr_model.named_steps[\"model\"])","ea746186":"preprocessor = lr_model.named_steps[\"preprocessor\"]","b6ce855c":"ohe_categories = preprocessor.named_transformers_[\"categorical\"].categories_","2f9cef11":"new_ohe_features = [f\"{col}__{val}\" for col, vals in zip(cat_features, ohe_categories) for val in vals]","2484b127":"all_features = num_features + new_ohe_features","95705373":"pd.DataFrame(lr_model.named_steps[\"preprocessor\"].transform(X_train), columns=all_features).head()","4e185d2a":"eli5.show_weights(lr_model.named_steps[\"model\"], feature_names=all_features)","f0541f2d":"i = 4\nX_test.iloc[[i]]","ac59cf69":"y_test.iloc[i]","eb407626":"eli5.show_prediction(lr_model.named_steps[\"model\"], \n                     lr_model.named_steps[\"preprocessor\"].transform(X_test)[i],\n                     feature_names=all_features, show_feature_values=True)","12723f1c":"gs = GridSearchCV(dt_model, {\"model__max_depth\": [3, 5, 7], \n                             \"model__min_samples_split\": [2, 5]}, \n                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n\ngs.fit(X_train, y_train)","9552c8a7":"print(gs.best_params_)\nprint(gs.best_score_)","d1bd79b0":"dt_model.set_params(**gs.best_params_)","65fa5eb6":"dt_model.fit(X_train, y_train)\ny_pred = dt_model.predict(X_test)","db969dab":"accuracy_score(y_test, y_pred)","1d887f00":"print(classification_report(y_test, y_pred))","feebe949":"eli5.show_weights(dt_model.named_steps[\"model\"], feature_names=all_features)","ec687183":"eli5.show_prediction(dt_model.named_steps[\"model\"], \n                     dt_model.named_steps[\"preprocessor\"].transform(X_test)[i],\n                     feature_names=all_features, show_feature_values=True)","7e7b8af3":"gs = GridSearchCV(rf_model, {\"model__max_depth\": [10, 15], \n                             \"model__min_samples_split\": [5, 10]}, \n                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n\ngs.fit(X_train, y_train)","ce3c491c":"print(gs.best_params_)\nprint(gs.best_score_)","99660a97":"rf_model.set_params(**gs.best_params_)","6b80d95a":"rf_model.fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)","df51a8ba":"accuracy_score(y_test, y_pred)","21815ffd":"print(classification_report(y_test, y_pred))","da3ee950":"eli5.show_weights(rf_model.named_steps[\"model\"], \n                  feature_names=all_features)","af484fdf":"gs = GridSearchCV(xgb_model, {\"model__max_depth\": [5, 10],\n                              \"model__min_child_weight\": [5, 10],\n                              \"model__n_estimators\": [25]},\n                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n\ngs.fit(X_train, y_train)","b3ec9066":"print(gs.best_params_)\nprint(gs.best_score_)\nxgb_model.set_params(**gs.best_params_)\nxgb_model.fit(X_train, y_train)","6d4e9310":"y_pred = xgb_model.predict(X_test)","853f45eb":"accuracy_score(y_test, y_pred)","549ed36f":"print(classification_report(y_test, y_pred))","4ae9a38f":"from lime.lime_tabular import LimeTabularExplainer","20051b0c":"categorical_names = {}\nfor col in cat_features:\n    categorical_names[X_train.columns.get_loc(col)] = [new_col.split(\"__\")[1] \n                                                       for new_col in new_ohe_features \n                                                       if new_col.split(\"__\")[0] == col]","9135181c":"categorical_names","6178637b":"def convert_to_lime_format(X, categorical_names, col_names=None, invert=False):\n    \"\"\"Converts data with categorical values as string into the right format \n    for LIME, with categorical values as integers labels.\n\n    It takes categorical_names, the same dictionary that has to be passed\n    to LIME to ensure consistency. \n\n    col_names and invert allow to rebuild the original dataFrame from\n    a numpy array in LIME format to be passed to a Pipeline or sklearn\n    OneHotEncoder\n    \"\"\"\n\n    # If the data isn't a dataframe, we need to be able to build it\n    if not isinstance(X, pd.DataFrame):\n        X_lime = pd.DataFrame(X, columns=col_names)\n    else:\n        X_lime = X.copy()\n\n    for k, v in categorical_names.items():\n        if not invert:\n            label_map = {\n                str_label: int_label for int_label, str_label in enumerate(v)\n            }\n        else:\n            label_map = {\n                int_label: str_label for int_label, str_label in enumerate(v)\n            }\n\n        X_lime.iloc[:, k] = X_lime.iloc[:, k].map(label_map)\n\n    return X_lime\n","be8912c5":"convert_to_lime_format(X_train, categorical_names).head()","502be63f":"explainer = LimeTabularExplainer(convert_to_lime_format(X_train, categorical_names).values,\n                                 mode=\"classification\",\n                                 feature_names=X_train.columns.tolist(),\n                                 categorical_names=categorical_names,\n                                 categorical_features=categorical_names.keys(),\n                                 discretize_continuous=True,\n                                 random_state=42)","ccc3b637":"i = 2\nX_observation = X_test.iloc[[i], :]\nX_observation","c9949d1e":"print(f\"\"\"\\\n* True label: {y_test.iloc[i]}\n* LR: {lr_model.predict_proba(X_observation)[0]}\n* DT: {dt_model.predict_proba(X_observation)[0]}\n* RF: {rf_model.predict_proba(X_observation)[0]}\n* XGB: {xgb_model.predict_proba(X_observation)[0]}\"\"\")","d0c2fb80":"observation = convert_to_lime_format(X_test.iloc[[i], :],categorical_names).values[0]\nobservation","3bfece04":"# Let write a custom predict_proba functions for our models:\nfrom functools import partial\n\ndef custom_predict_proba(X, model):\n    X_str = convert_to_lime_format(X, categorical_names, col_names=X_train.columns, invert=True)\n    return model.predict_proba(X_str)","fdda049b":"lr_predict_proba = partial(custom_predict_proba, model=lr_model)\ndt_predict_proba = partial(custom_predict_proba, model=dt_model)\nrf_predict_proba = partial(custom_predict_proba, model=rf_model)\nxgb_predict_proba = partial(custom_predict_proba, model=xgb_model)","d15976de":"explanation = explainer.explain_instance(observation, lr_predict_proba, num_features=5)","b6fbeece":"explanation.show_in_notebook(show_table=True, show_all=False)","dced430c":"explanation.save_to_file(\"explanation.html\")","12432af8":"print(explanation.local_exp)\nprint(explanation.intercept)\nprint(explanation.score)","2cfba2f9":"# dt_predict_proba","bf25e42e":"explanation = explainer.explain_instance(observation, dt_predict_proba, num_features=5)\nexplanation.show_in_notebook(show_table=True, show_all=False)\nprint(explanation.score)","1a69ca1d":"explanation = explainer.explain_instance(observation, rf_predict_proba, num_features=5)\nexplanation.show_in_notebook(show_table=True, show_all=False)\nprint(explanation.score)","ce20d0b1":"explanation = explainer.explain_instance(observation, xgb_predict_proba, num_features=5)\nexplanation.show_in_notebook(show_table=True, show_all=False)\nprint(explanation.score)","3181957d":"import shap\n# Need to load JS vis in the notebook\nshap.initjs() ","135e7f19":"explainer = shap.TreeExplainer(xgb_model.named_steps[\"model\"])","938684ff":"observations = xgb_model.named_steps[\"preprocessor\"].transform(X_train.sample(1000, random_state=42))\nshap_values = explainer.shap_values(observations)","2c7911f8":"i = 0\nshap.force_plot(explainer.expected_value, shap_values[i], \n                features=observations[i], feature_names=all_features)","e29f8fac":"shap.force_plot(explainer.expected_value, shap_values,\n                features=observations, feature_names=all_features)","5562d353":"shap.summary_plot(shap_values, features=observations, feature_names=all_features)","2f6c39ac":"shap.dependence_plot(\"nr.employed\", shap_values, \n                     pd.DataFrame(observations, columns=all_features))","a4205baf":"from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\nfrom keras.preprocessing.image import load_img, img_to_array","dd8276c1":"model = InceptionV3()","97fdad81":"image_raw = load_img(\"..\/input\/toucan-for-xai\/toucan.jpeg\", target_size=(299,299))\nimage_raw","33ab295e":"# Convert to numpy array, reshape and preprocess\nimage = img_to_array(image_raw)\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\nimage = preprocess_input(image)","69ee2b88":"predictions = model.predict(image)","e605965a":"decode_predictions(predictions)","2492155f":"model.predict(image).argsort()[0, -5:][::-1]","580a799e":"from lime.lime_image import LimeImageExplainer","ac53c01e":"explainer = LimeImageExplainer()","064e8837":"explanation = explainer.explain_instance(image[0], model.predict, \n                                         top_labels=2, num_samples=100,\n                                         random_seed=42)","715f8145":"from skimage.segmentation import mark_boundaries\nfrom matplotlib import pyplot as plt","0555a28b":"temp, mask = explanation.get_image_and_mask(96, positive_only=True, num_features=5, hide_rest=True)\n# plot image and mask together\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))","ed0a04da":"temp, mask = explanation.get_image_and_mask(96, positive_only=True, num_features=1, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))","0b3ed1f4":"temp, mask = explanation.get_image_and_mask(779, positive_only=False, num_features=8, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))","ab47c20e":"Let's convert our observation to lime format and convert it to a numpy array.","4fb7a303":"Let's see our best parameters and score","4c718eb5":"<h1> Importing the libraries <\/h1>","b2fb1790":"Now we can define our 4 models as sklearn `Pipeline` object, containing our preprocessing step and training of one given algorithm.","5484fa1b":"Lime can also be used to explain decisions made for image classification. \n\nIn this example we will use the pretrained `InceptionV3` model available with Keras. Lime is quite slow with images, so it's wiser to stick to a \"shallow\" deep learning model.","fe74fadc":"Let's test our custom function to make sure it generates propabilities properly","a1aaefa6":"Another interesting plot that we can generate with SHAP is the `summary_plot`, it can be seen as a feature importance plot with more meaningful insights. Below we're plotting the summary plot for class 1 on the whole subset.\nThe colour corresponds to the value of the feature and the x axis corresponds to the SHAP value, meaning the impact on the probability. ","a47a7c50":"The dataset can be downloaded [here](https:\/\/archive.ics.uci.edu\/ml\/datasets\/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build classifiers that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`).","1e248249":"Now that we have generated our explanation, we have access to several representations. The most useful one when working in a notebook is `show_in_notebook`.\n\n\nOn the left it shows the list of probabilities for each class, here the model classified our observation as 0 (non subsribed) with a high probability.\n* If you set `show_table=True`, you will see the table with the most important features for this observation on the right.","8223c63f":"## More local interpretation with SHAP","b7abc728":"### with a Random Forest","174a030b":"Note: This notebook uses features introduced in Python 3.6 and sklearn 0.20.","73cd44df":"<h1>Data dictionary<\/h1>","c121d163":"We can also visualise all points in our dataset at once with a given class by passing all explanations for that class to `force_plot`","2c4d755f":"### Let's train our XGB model as well","2fa482fb":"In order to explain why the model classifies invidividual observations as class 0 or 1, we are going to use the `LimeTabularExplainer` from the library `lime`, this is the main explainer to use for tabular data. Lime also provides an explainer for text data, for images and for time-series.\n\nWhen using the tabular explainer, we need to provide our training set as parameter so that `lime` can compute statistics on each feature, either `mean` and `std` for numerical features, or frequency of values for categorical features. Those statistics are used to scale the data and generate new perturbated data to train our local linear models on.","9217e7d1":"The second class predicted by our model was a bus (label 779), set `positive_only=False` in order to see what features contributed positively and negatively to that decision. What do you see?","fc4626b7":"First let's fine tune our logistic regression and evaluate its performance.","a79a8e35":"<h1> Creating model training pipelines <\/h1>","1635be74":"`eli5` can also be used to explain black box models, but we will use `Lime` and `SHAP` for our two last models instead.","b0802b46":"This explanation shows how each feature contributes to shifting the prediction from the base value to the output value of the model either by decreasing or increasing the probability of our class.","5cac2a3c":"Our client subsribed to the term deposit after the campaign! Let's see what our model would have predicted and how it would explain it.\n\nWe'll need to first transform our row into the format expected by our model as `eli5` cannot work directly with our pipeline.\n\nNote: `eli5` actually does support pipeline, but with a limited number of transformations only. In our pipeline it does not support the `passthrough` transformation (which, funny enough, doesn't do anything...)","d3220db4":"<h2> LIME(Local Interpretable Model-agnostic Explanation) to generate local intepretations of black box models<\/h2>","2482ce07":"### With a Decision Tree","d8f41a58":"Looks like it's picking principally on whether the month is march or not, the marketting campaign seem to have been more efficient in march?","78f85bd4":"Great, so now we have a nice list of columns after processing. Let's visualise the data in a dataframe just for sanity check:","2ae739ad":"<img src=https:\/\/www.logikk.com\/wp-content\/uploads\/2019\/01\/AI_Ethics_Graphic.png>","37bc4cbe":"1. We'll define a new `ColumnTransformer` object (new in sklearn 0.20) that keeps our numerical features and apply one hot encoding on our categorical features. That will allow us to create a clean pipeline that includes both features engineering (one hot encoding here) and training the model (a nice way to avoid data leakage)","1c7633b4":"# Intepreting models with non tabular data","e8162e1c":"Now we'll load a picture of a toucan, we need to make sure we load it at the good size for inception, here 229*229","e32d7d6b":"### Create an explainer","b64c1d8a":"SHAP has a generic explainer that works for any model and a TreeExplainer optimised for tree based models. Here we will focus on the `TreeExplainer` with our XGB model (the hardest to intepret)","a2c68071":"LIME is fitting a linear model on a local perturbated dataset. You can access the coefficients, the intercept and the R squared of the linear model by calling respectively `.local_exp`, `.intercept` and `.score` on your explanation.","0f1be3f0":"We can also use `eli5` to explain a specific prediction, let's pick a row in the test data:","fd068599":"Let's see our best parameters and score","faaa405a":"**That gives us the weights associated to each feature, that can be seen as the contribution of each feature into predicting that the class will be y=1 (the client will subscribe after the campaign).**\n\nThe names for each features aren't really helping though, we can pass a list of column names to `eli5` but we'll need to do a little gymnastics first to extract names from our preprocessor in the pipeline (since we've generated new features on the fly with the one hot encoder)","5f7a39da":"Generate predictions","fd3f84b9":"Let's use `eli5` to visualise the weights associated to each feature:","c13f785e":"#### Explain new observations","617deeb7":"For Decision Trees, `eli5` only gives feature importance, which does not say in what direction a feature impact the predicted outcome.","33084eb5":"You can also save the explanation to an html file with `save_to_file` to share it.","f4464f39":"We're good to go!","bdb6fd77":"`eli5` can also be used to intepret decision trees:","9bbd2cc5":"## Interpreting image classifiers","ce618321":"Here the toucan corresponds to index 96, the school bus to index 779, etc..","26da72d7":"What feature do you expect to be the most important in that decision? Plot the image with only the main feature (`num_features=1`)","d32b9aff":"Let's get started. First import the `LimeImageExplainer` and instantiate a new explainer","053ecc7d":"If your R-squared is low, the linear model that LIME fitted isn't a great approximation to your model, which means you should not rely too much on the explanation it provides.","17302528":"Great, our explainer is ready. Now let's pick an observation we want to explain.","ba371061":"`Lime` needs the dataset that is passed to have categorical values converted to integer labels that maps to the values in `categorical_names`. For instance, label `0` for the column `2` will map to `divorced`. We will use a custom helper function to do so, that converts data from original to LIME and from LIME to original format.\n\nThat function is going over all categorical features and replacing strings by the correct integer labels, feel free to check `helpers.py`.","4d0d377c":"First, in order to get the `categorical_names` parameter we need to build a dictionary with indexes of categorical values in original dataset as keys and lists of possible categories as values:","8ad0b34d":"<h1>References<\/h1>\n\n**Open the Black Box: an Introduction to Model Interpretability with LIME and SHAP - Kevin Lemagnen\n[Source](https:\/\/github.com\/klemag\/pydata_nyc2018-intro-to-model-interpretability)\n","4ede04a5":"Generate predictions","977a143e":"The tools we have seen above also work with text data and images. There are plenty of examples available online for text-data. Here we will just demonstrate how to use `Lime` to explain an image classifier.","0ad0c373":"<h1>Splitting the data<\/h1>","079f0015":"That's better than the built-in feature importance on RandomForest because not only we can see what features are important but also how they affect our predictions.","091a9774":"The dataset is imbalanced, we will need to keep that in mind when building our models!","29842a99":"<div class=\"alert alert-block alert-info\">\nHave you been rejected from a job by an ATS? Chances are, it was a poorly trained one.\nDo you now someone who was denied a loan without any reason?\nHow do you ensure you algorithm doesn't discriminate? You hold it accountable.\nThis notebook lists a few Pythonian ways to do so, using libraries that explain the way predictions are made. \n    \n<b> Please upvote this if you find it useful <\/b>\n    \n<\/div>","141601c1":"Note the comment about `duration` feature. We will exclude it from our analysis.","8ff87b82":"Let's split the data into training and test sets.","82bd0c1a":"You can check what labels your predictions correspond to by calling the function `decode_predictions` on your predictions. By default it returns the 5 more likely predictions","40a9897c":"The parameters passed to the explainer are:\n- our training set, we need to make sure we use the training set *without* one hot encoding\n- `mode`: the explainer can be used for classification or regression\n- `feature_names`: list of labels for our features\n- `categorical_features`: list of indexes of categorical features\n- `categorical_names`: dict mapping each index of categorical feature to a list of corresponding labels\n- `dicretize_continuous`: will discretize numerical values into buckets that can be used for explanation. For instance it can tell us that the decision was made because distance is in bucket [5km, 10km] instead of telling us distance is an importante feature.","4f6fb5d9":"In order to compute the shapley values with the tree explainer, we need to call the `shap_values` methods passing a dataset. That can be quite computationally expensive, so we will only pass 1000 samples picked at random.","df5b3c5c":"Remember that LIME needs the indices of the class we are interested in. Execute the cell bellow to get the indices corresponding to the 5 most probably classes we predicted above. Those indices correspond to the classes used in the ImageNet dataset that was used to train our model.","47ea2267":"Let's look at the features in the X matrix:","44a1aa1d":"<h2> The Dataset <\/h2>","702746b9":"Great, we predicted a toucan with a probability of 99%, that's promising!","53915872":"LIME stands for `Local Interpretable Model-Agnostic Explanations`. We can use it with any model we've built in order to explain why it took a specific decision for a given observation. To do so, LIME creates a dataset in the locality of our observation by perturbating the different features. Then it fits a local linear model on this data and uses the weights on each feature to provide an explanation.","5296459d":"We can look at the features importance with Eli5 first:","c9b53f46":"Looks good!","9eb20fc1":"### With Logistic Regression","8f6f4f0b":"<!-- Text to HTML Code from http:\/\/snapbuilder.com Code Snippet Generators -->\n<p style=\"text-align:inherit;\"><span style=\"font-family:Helvetica, sans-serif;;font-size:34px;font-style:normal;font-weight:bold;text-decoration:inherit;text-transform:capitalize;color:#E81818;background-color:#F5F5F5;\">Responsible AI: Interpretability and Explainability in AI systems<\/span>\n<\/p>","adeec6ef":"We need to process the image to get a numpy array compatible with our model. Here we simply loads it to an array, reshape it and use the preprocess_input method provided by Keras that ensures all the preprocessing steps are made for us.","1339d588":"Now we can fit the model on the whole training set and calculate accuracy on the test set.","ec551d99":"Now we can start visualising our explanations using the `force_plot` function from the shap package passing our first shap_value (we also need to pass `explainer.expected_value` which is the base value).","3e318766":"The explainer is the same as before, we call `explain_instance` to generate a new explanation. We need to provide:\n- our observation: here the first row of our numpy matrix (that has only one row since we only have one image)\n- our predict function, we can simply use the one from our model here\n- `top_labels` the number of classes to explain. Here our model generate probabilities for more than a 1000 classes (and we looked at the five first). We do not want LIME to generate local models to explain each of those classes. As lime is pretty slow with images, let's only ask for the explanation to our two main classes, toucan and school bus\n- `num_samples`: the number of new datapoints to create to fit a linear model, let's set it to 1000\n\n*WARNING*: that will be slow. ","47f0ff3b":"Now that our image is ready, generate predictions by using `.predict` as usual.","e72719d8":"Here the most important feature seems to be `nr.employed`. We can also get an explanation for a given prediction, this will calculate the contribution of each feature in the prediction:","940acb45":"We'll create a variable called `observation` that contains our ith observation in the test dataset.","ccc9cf57":"<h1> Libraries for Explainable AI <\/h1>\n<h2> The Eli5 Library: Intepreting \"white box\" models <\/h2>","46ceff82":"Here the explanation for a single prediction is calculated by following the decision path in the tree, and adding up contribution of each feature from each node crossed into the overall probability predicted.","bbdf25f2":"Let's see our best parameters and score","e27fc696":"1. age (numeric)\n2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n5. default: has credit in default? (categorical: 'no','yes','unknown')\n6. housing: has housing loan? (categorical: 'no','yes','unknown')\n7. loan: has personal loan? (categorical: 'no','yes','unknown')\n8. contact: contact communication type (categorical: 'cellular','telephone') \n9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n14. previous: number of contacts performed before this campaign and for this client (numeric)\n15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n17. cons.price.idx: consumer price index - monthly indicator (numeric) \n18. cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n20. nr.employed: number of employees - quarterly indicator (numeric)","59d20ea9":"We can see our 1000 samples on the x axis. The y-axis corresponds to the same scale we were looking at before, where blue values corresponds to the probability decreasing, red increasing. Hover with your mouse on a point to see the main features impacting a given observation. You can also use the drop down on the left to visualise the impact of specific features, for example duration only.","244e49ef":"We can explain roughly what our model seems to focus on mostly. We also get the standard deviation of feature importance accross the multiple trees in our ensemble.","5b2e2967":"In order to explain a prediction, we use the `explain_instance` method on our explainer. This will generate new data with perturbated features around the observation and learn a local linear model. It needs to take:\n- our observation as a numpy array\n- a function that uses our model to predict probabilities given the data (in same format we've passed in our explainer). That means we cannot pass directly our `rf_model.predict_proba` because our pipeline expects string labels for categorical values. We will need to create a custom function `rf_predict_proba` that first converts back integer labels to strings and then calls `rf_model.predict_proba`.\n- `num_features`: number of features to consider in explanation","dc71ece4":"Let's check that it worked:","5e8fab47":"First let's check the explanation for the predicted class `toucan`. That corresponds to label 96 in the ImageNet classes. We need to use the method `get_image_and_mask` on our explanation object with the following parameters:\n- index of the class to explain. We'll start with the index of the main class predicted, that was 96\n- positive_only: in order to show the part of the image that contribute positively to this class being selected\n- num_features: number of superpixels to use. LIME breaks down our image into a set of superpixels, each containing several pixels. Those superpixels are equivalent to `features` in tabular data.\n- hide_rest: to hide the rest of the image\n\nThat returns a new image and a mask as numpy arrays. You can then use `mark_boundaries` to show the image together with the mask.","9e6e0993":"Great, now you can try to change the number of features you're looking at and deactivate `positive_only` in order to see features that contribute negatively to the class. You can also look at other classes or try other pictures.","8c93b9b3":"# Introduction to Model Interpretability\n\nThis kernel was used for a presentation at ODSC New Delhi Meetup, which can be accessed [here](https:\/\/app.aiplus.training\/courses\/explainable-ai-and-interpret-ability-of-ai-solutions-strategic-overview-challenges-and-caveats)","d3e15f9b":"Let's see our best parameters and score.","920d26d2":"Let's create a new instance of InceptionV3"}}