{"cell_type":{"be17530b":"code","4887a9b1":"code","472ce8a4":"code","5c2a47aa":"code","14161d4f":"code","fc1aac65":"code","8037b4b9":"code","f2e7a3e0":"code","8a30c24d":"code","5992f4ed":"code","4ea24866":"code","3168f55f":"code","38caac90":"code","8aecc17d":"code","b6292380":"code","73abbc9c":"code","31fbab19":"code","1253ec81":"code","451f100c":"code","a49581fe":"code","d4dea0bf":"code","35e16745":"code","4b4bb275":"code","3c656002":"code","80cd9054":"markdown","3f654bf6":"markdown","d502080a":"markdown","7bc42134":"markdown","57866fe4":"markdown"},"source":{"be17530b":"!tar xf \/kaggle\/input\/files-ships-2020\/ships.tgz  # les images dans des r\u00e9pertoires!tar vxf \/kaggle\/input\/files-ships-2020\/ships.tgz  # les images dans des r\u00e9pertoires","4887a9b1":"types = ['coastguard', 'containership', 'corvette', 'cruiser', 'cv', 'destroyer', 'methanier', 'smallfish', 'submarine', 'tug']\ntypes_id = {t:i for (i,t) in enumerate(types)}\n\nbatch_size = 64","472ce8a4":"from keras.preprocessing.image import ImageDataGenerator \n\n#After trying different experiments, i just realized that the training data plays the most important role.\n#Data Augmentation\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        horizontal_flip=True,\n        validation_split=0.1,\n        rotation_range=6,\n        shear_range=8,\n        zoom_range=[0.9, 1.5],  \n        brightness_range=[0.7, 1.2],\n        width_shift_range=0.2,\n        height_shift_range=0.3,\n        channel_shift_range = 50,\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n        'ships_scaled',\n        target_size=(128, 192 ),\n        batch_size=batch_size,\n        subset=\"training\")\n\nvalidation_generator = train_datagen.flow_from_directory(\n        'ships_scaled',\n        target_size=(128, 192 ),\n        batch_size=batch_size,\n        subset=\"validation\")","5c2a47aa":"# from matplotlib import pyplot as plt\n# #128, 192, 3\n# X_batch, y_batch = next(train_generator)\n# plt.figure(figsize=(20, 15))\n# for i in range(9):\n#     print(y_batch[i])\n#     plt.subplot(331 + i)\n#     plt.imshow(X_batch[i])\n# plt.show()","14161d4f":"from keras.models import Model\nfrom keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation, concatenate\nfrom keras.regularizers import l1_l2\n\ninputs = Input(shape=(128, 192, 3), name='cnn_input')\n#... pleins de lignes\n\n#with 2 stacked convolutional (two feature maps are stacked along the depth), the model is able to detect the details of the ships. \n\n#block 1\n#feature maps: extracting edges\nx = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x) #downsampling\n\n#block 2: 2 stacked convolutional layers\nx = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)  #downsampling\n\n#block 3: 2 stacked convolutional layers\n\nx = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\nx = BatchNormalization()(x)\nx = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)  #downsampling\n\nx = Flatten()(x)\n\n#Fully connected layers\n\nx = Dense(256, activation='relu')(x)  \nx = BatchNormalization()(x)\nx = Dropout(0.3)(x) #avoid overfitting\n\nx = Dense(256, activation='relu')(x) \nx = BatchNormalization()(x)\nx = Dropout(0.4)(x) #avoid overfitting\n\noutputs = Dense(10, activation=\"softmax\")(x)\n\nmodel = Model(inputs, outputs)\n\nmodel.compile(optimizer='rmsprop',   # pas obligatoirement le meilleur algo pour converger\n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n              )","fc1aac65":"model.summary()","8037b4b9":"from sklearn.utils import class_weight\nimport numpy as np\n#The current dataset is imbalanced => too few data for cv, corvette, submarine (the 3 lowest accuracies in previous experiments)\n#generate class weights for dataset\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\nprint(class_weights)","f2e7a3e0":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = train_generator.samples \/\/ batch_size,\n        validation_data = validation_generator, \n        validation_steps = validation_generator.samples \/\/ batch_size,\n        callbacks = [\n#             EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10),\n            ModelCheckpoint(\"best_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True),\n        ],\n        class_weight = class_weights,\n        epochs = 90)   # 10 permet d'avoir une id\u00e9e mais probablement pas suffisant pour un beau r\u00e9sultat ","8a30c24d":"# une autre cellule de fit_generator est possible pour continuer","5992f4ed":"from matplotlib import pyplot as plt\nplt.figure(figsize=(8, 6))\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","4ea24866":"import numpy as np\nimport pandas as pd\nfrom keras.utils import np_utils\n\nships = np.load('\/kaggle\/input\/files-ships-2020\/ships_test.npz', allow_pickle=True)\nX_test = ships['X']\nY_test = ships['Y']\n\nX_test = X_test.astype('float32') \/ 255\nY_test_cat = np_utils.to_categorical(Y_test).astype('bool')","3168f55f":"score = model.evaluate(X_test, Y_test_cat, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nres = model.predict(X_test).argmax(axis=1)\nconfu = confusion_matrix(Y_test, res)\npd.DataFrame({types[i][:3]:confu[:,i] for i in range(len(types))}, index=types)","38caac90":"print(classification_report(Y_test, res, target_names=types))","8aecc17d":"from keras.models import load_model\nbest_model = load_model('\/kaggle\/working\/best_model.hdf5')\nscore = best_model.evaluate(X_test, Y_test_cat, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\nres = best_model.predict(X_test).argmax(axis=1)\nconfu = confusion_matrix(Y_test, res)\npd.DataFrame({types[i][:3]:confu[:,i] for i in range(len(types))}, index=types)","b6292380":"print(classification_report(Y_test, res, target_names=types))","73abbc9c":"ships = np.load('\/kaggle\/input\/files-ships-2020\/ships_competition.npz', allow_pickle=True)\nX_test = ships['X']\nX_test = X_test.astype('float32') \/ 255","31fbab19":"# predict results\nres = model.predict(X_test).argmax(axis=1)\ndf = pd.DataFrame({\"Category\":res})\ndf.to_csv(\"reco_nav.csv\", index_label=\"Id\")","1253ec81":"!head reco_nav.csv","451f100c":"from IPython.display import HTML\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(title=\"Download reco_nav.csv\", filename='reco_nav.csv')","a49581fe":"res = best_model.predict(X_test).argmax(axis=1)\ndf = pd.DataFrame({\"Category\":res})\ndf.to_csv(\"reco_nav_best_model.csv\", index_label=\"Id\")\ncreate_download_link(title=\"Download reco_nav_best_model.csv\", filename='reco_nav_best_model.csv')","d4dea0bf":"!head reco_nav_best_model.csv","35e16745":"create_download_link(title=\"Download best_model.hdf5\", filename='best_model.hdf5')","4b4bb275":"!rm ships_scaled -rf","3c656002":"!ls \/kaggle\/working","80cd9054":"## Soumission des r\u00e9sultats\n\nLe fichier suivant sert \u00e0 soumettre son r\u00e9sultat \u00e0 la comp\u00e9tition. Pour cela vous devez regarder les Output de votre Kernel (pour cela il semble qu'il faille avoir commit\u00e9 sa feuille sinon le r\u00e9sultat est \u00e0 chercher dans le r\u00e9pertoire courant) et cliquer sur le bouton Submit to competition.","3f654bf6":"### **Load from ModelCheckPoint**","d502080a":"## Analyse des r\u00e9sultats","7bc42134":"## Mon r\u00e9seau\n\nC'est un exemple minimaliste qui ne classera rien. A vous d'ajouter des couches pour en faire quelque chose qui marche.","57866fe4":"Un g\u00e9n\u00e9rateur de donn\u00e9es \u00e0 la vol\u00e9e, c'est plus lent que d'avoir tout en m\u00e9moire mais cela ne consomme rien en m\u00e9moire (donc plus le probl\u00e8me avec la normalisation).\n\nhttps:\/\/keras.io\/preprocessing\/image\/"}}