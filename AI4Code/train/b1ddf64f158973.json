{"cell_type":{"210b55e3":"code","50056a10":"code","7c4c9a82":"code","0b369e2b":"code","059fb198":"code","fd02a246":"code","e8735351":"code","dea9bfda":"code","d664e1d9":"code","d0af7ff0":"code","647bb16d":"code","633c83c6":"markdown","885277aa":"markdown","01276942":"markdown","242ec1b5":"markdown","e79b5514":"markdown","c16ea705":"markdown","db1822c0":"markdown","236631cf":"markdown","090e5362":"markdown","cd412b04":"markdown","bc91d0a2":"markdown"},"source":{"210b55e3":"# Code you have previously used to load data\nimport pandas as pd\n\n# Path of the file to read\niowa_file_path = '..\/input\/house-prices-advanced-regression-techniques\/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)","50056a10":"# print the list of columns in the dataset to find the name of the prediction target\nhome_data.columns","7c4c9a82":"y = home_data['SalePrice']","0b369e2b":"# Create the list of features \nfeature_names = ['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\n\n# select data corresponding to features in feature_names\nX =home_data[feature_names]","059fb198":"# print description or statistics from X\nprint(X.describe())","fd02a246":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","e8735351":"from sklearn.tree import DecisionTreeRegressor\n#specify the model. \n#For model reproducibility, set a numeric value for random_state when specifying the model\nmodel = DecisionTreeRegressor(random_state=1)\n\n# Fit the model\nmodel.fit(X_train,y_train)","dea9bfda":"predictions = model.predict(X_test)\nprint(predictions)","d664e1d9":"import seaborn as sns \nimport matplotlib.pyplot as plt ","d0af7ff0":"fig, ax = plt.subplots()\nax.scatter(predictions, y_test, edgecolors=(0, 0, 1))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nplt.show()","647bb16d":"# model evaluation for testing set\n\nfrom sklearn import metrics\n\nmae = metrics.mean_absolute_error(y_test, predictions)\nmse = metrics.mean_squared_error(y_test, predictions)\nr2 = metrics.r2_score(y_test, predictions)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('MAE is {}'.format(mae))\nprint('MSE is {}'.format(mse))\nprint('R2 score is {}'.format(r2))","633c83c6":"## Step 7:Actual vs Predicted graph","885277aa":"Here, we did not use the test data. Rather the train data has been splitted to show how to perform splitting when the data is not already splitted. However, we could use test data directly instead of splitting the training data into train and test data","01276942":"\n\n## Step 2: Specify the Target Variable\nSelect the target variable which here is the sales price. Save this to a new variable called `y`. \n","242ec1b5":"On this plot, we can check out where the points lie. We can see that some points are far away from the diagonal line and we can conclude that the R2  score will be low. This shows us that the model doesn\u2019t fit the data very well. Now, we will make the same conclusion by solely observing magnitudes of regression metrics.","e79b5514":"## Step 6: Make Predictions\nMake predictions with the model's `predict` command using `X` as the data. Save the results to a variable called `predictions`.","c16ea705":"## Step 1: Load the data","db1822c0":"![](http:\/\/)## Step 5: Define and Fit the Model\nCreate a `DecisionTreeRegressor` model and fit the model using `X` and `y` ","236631cf":"* ## Step 5: Split the Data into Train and Test Set","090e5362":"## Step 4: Review Independent Variables\nBefore building a model, take a quick look at **X** ","cd412b04":"## Step 3: Define the Features\nCreate a DataFrame called `X` holding the predictive features.\n\nWe select only a few columns as the features","bc91d0a2":"## Step 8: Evaluation of the Model"}}