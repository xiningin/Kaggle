{"cell_type":{"b51309d4":"code","b599d36e":"code","16dff045":"code","119cf8b5":"code","826fa4d3":"code","20a8677f":"code","d4de666b":"code","74ffb967":"code","70d7ac8c":"code","53906c06":"code","9aea4c8b":"code","0a2f50d3":"code","c105fe76":"code","6df2ef32":"code","86f3fc8a":"code","494df356":"code","c7546487":"code","0408e833":"code","ca352cf9":"code","de2fa3dc":"code","8b37597c":"code","263313ba":"code","46705660":"code","34b0c709":"code","954045ed":"code","2a10c41c":"code","d38d0c26":"code","0e7a2532":"markdown","2f874f49":"markdown","8db91d2a":"markdown","6b015078":"markdown","e9e55c69":"markdown","8e1ed8f2":"markdown","98223dd0":"markdown","a13df646":"markdown","05bc46de":"markdown","30c44efe":"markdown","1facdde9":"markdown"},"source":{"b51309d4":"# data processing\nimport numpy as np \nimport pandas as pd\n\n# for extracting holidays\nimport dateutil.easter as easter\n\n# sklearn baseline models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\n# scale numerical features\nfrom sklearn.preprocessing import MinMaxScaler\n\n# for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# for visualizing decission tree\nfrom sklearn import tree\n\n# for reproducibility\nRANDOM_SEED = 42\n\nplt.style.use('ggplot')","b599d36e":"# Read basic data\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\n\n# convert dates to datetimes\nfor _df in [df_train, df_test]:\n    _df.date = pd.to_datetime(_df.date)\n    \n# create features from datetime object\nfor _df in [df_train, df_test]:\n    _df['year'] = _df['date'].apply(lambda x: x.year)\n    _df['month'] = _df['date'].apply(lambda x: x.month)\n    _df['quarter'] = _df.date.dt.quarter\n    _df['day'] = _df['date'].apply(lambda x: x.day)\n    _df['wd'] = _df['date'].apply(lambda x: x.weekday())\n    _df['weekend'] = _df['wd'].isin([5, 6]).astype(int)\n    _df['day_of_year'] = _df.date.dt.dayofyear  \n    _df['week_of_year'] = _df.date.dt.isocalendar().week\n    _df['is_friday'] = np.where((_df['wd'] == 4), 1, 0)","16dff045":"def holiday_features(holiday_df, df):\n    \"\"\"\n    This function taken from:\n    https:\/\/www.kaggle.com\/maxencefzr\/tps-jan22-catboost-using-pycaret\n    \"\"\"\n    fin_holiday = holiday_df.loc[holiday_df.country == 'Finland']\n    swe_holiday = holiday_df.loc[holiday_df.country == 'Sweden']\n    nor_holiday = holiday_df.loc[holiday_df.country == 'Norway']\n    \n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    \n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    \n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    \n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df['days_from_easter'] = (df.date - easter_date).dt.days.clip(-5, 65)\n    \n    # Last Sunday of May (Mother's Day)\n    sun_may_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-5-31')),\n        2016: pd.Timestamp(('2016-5-29')),\n        2017: pd.Timestamp(('2017-5-28')),\n        2018: pd.Timestamp(('2018-5-27')),\n        2019: pd.Timestamp(('2019-5-26'))\n    })\n    #new_df['days_from_sun_may'] = (df.date - sun_may_date).dt.days.clip(-1, 9)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-06-24')),\n        2016: pd.Timestamp(('2016-06-29')),\n        2017: pd.Timestamp(('2017-06-28')),\n        2018: pd.Timestamp(('2018-06-27')),\n        2019: pd.Timestamp(('2019-06-26'))\n    })\n    df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n    \n    # First Sunday of November (second Sunday is Father's Day)\n    sun_nov_date = df.date.dt.year.map({\n        2015: pd.Timestamp(('2015-11-1')),\n        2016: pd.Timestamp(('2016-11-6')),\n        2017: pd.Timestamp(('2017-11-5')),\n        2018: pd.Timestamp(('2018-11-4')),\n        2019: pd.Timestamp(('2019-11-3'))\n    })\n    df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n    \n    return df","119cf8b5":"# read outsourced data\nfestivities = pd.read_csv(\"..\/input\/festivities-in-finland-norway-sweden-tsp-0122\/nordic_holidays.csv\",\n                          parse_dates=['date'],\n                          usecols=['date', 'country', 'holiday'])\n\n# add holiday information\ndf_train = holiday_features(festivities, df_train)\ndf_test = holiday_features(festivities, df_test)","826fa4d3":"# process GDP\ngdp = pd.read_csv(\"..\/input\/gdp-20152019-finland-norway-and-sweden\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv\")\ngdp = np.concatenate([gdp[['year', 'GDP_Finland']].values, \n                      gdp[['year', 'GDP_Norway']].values, \n                      gdp[['year', 'GDP_Sweden']].values])\ngdp = pd.DataFrame(gdp, columns=['year', 'gdp'])\ngdp['country'] = ['Finland']*5 + ['Norway']*5 +['Sweden']*5\n\n# add data\nfor _df in [df_train, df_test]:\n    gdp_countries = _df.merge(gdp, on=['country', 'year'], how='left')['gdp'].values\n    for country in ['Finland', 'Norway', 'Sweden']:\n        _df['gdp_'+ country] = gdp_countries * (_df['country']==country).astype(int)","20a8677f":"# aggregate data\ndf_g = df_train.groupby(['year', 'product', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(2, 2, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _year in enumerate(range(2015, 2019)):\n    _df =  df_g[_year].reset_index()\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='product', linewidth=2.5, ax=axes[i])\n    \nplt.tight_layout()","d4de666b":"# aggregate data\ndf_g = df_train.groupby(['product', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(3, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _product in enumerate(df_train['product'].unique()):\n    _df =  df_g[_product].reset_index()\n    axes[i].set_title(_product)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","74ffb967":"# aggregate data\ndf_g = df_train.groupby(['store', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(2, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _store in enumerate(df_train['store'].unique()):\n    _df =  df_g[_store].reset_index()\n    axes[i].set_title(_store)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","70d7ac8c":"# aggregate data\ndf_g = df_train.groupby(['country', 'year', 'date'])['num_sold'].sum()\n\n# greate plotting function\nfig, axes = plt.subplots(3, 1, figsize=(24, 8), sharey=True)\n\naxes = axes.flatten() \n\nfor i, _country in enumerate(df_train['country'].unique()):\n    _df =  df_g[_country].reset_index()\n    axes[i].set_title(_country)\n    sns.lineplot(data=_df, x='date', y='num_sold', hue='year', linewidth=2.5, ax=axes[i], palette=\"tab10\")\n    \nplt.tight_layout()","53906c06":"# create new DataFrames for transformed features\nX_train = df_train.copy()\nX_test = df_test.copy()\n\n# extract targets\ny_train = X_train.pop('num_sold')","9aea4c8b":"# calculate days per month\nDAYS_PER_MONTH = pd.concat([df_train, df_test])\nDAYS_PER_MONTH = DAYS_PER_MONTH.groupby(['year','month']).agg({'day': ['max']})\nDAYS_PER_MONTH = DAYS_PER_MONTH.reset_index()\nDAYS_PER_MONTH.columns = ['year', 'month', 'max_days']\nDAYS_PER_MONTH.head()","0a2f50d3":"# get max days for both train and test datasets\nX_train = pd.merge(X_train, DAYS_PER_MONTH, on=['year', 'month'], how='left')\nX_train['day'] = X_train['day'] \/ X_train['max_days']\ndel X_train['max_days']\n\nX_test = pd.merge(X_test, DAYS_PER_MONTH, on=['year', 'month'], how='left')\nX_test['day'] = X_test['day'] \/ X_test['max_days']\ndel X_test['max_days']","c105fe76":"# scale other numerical features\nfor col in ['day_of_year', 'days_from_easter', 'days_from_wed_jun', 'days_from_sun_nov']:\n    scaler = MinMaxScaler()\n    scaler.fit(X_train[col].values.reshape(-1, 1))\n    # transform\n    X_train[col] = scaler.transform(X_train[col].values.reshape(-1, 1))\n    X_test[col] = scaler.transform(X_test[col].values.reshape(-1, 1))","6df2ef32":"# one-hot encode categorical features\nX_train = pd.get_dummies(X_train, columns=['country', 'store', 'product', 'month'])\nX_test = pd.get_dummies(X_test, columns=['country', 'store', 'product', 'month'])","86f3fc8a":"# split train data into train and validation sections\n_X_train = X_train.loc[X_train.year != 2018].copy()\n_X_valid = X_train.loc[X_train.year == 2018].copy()","494df356":"# https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting\/discussion\/36414\n# https:\/\/www.kaggle.com\/teckmengwong\/tps2201-hybrid-time-series\ndef smape_loss(y_true, y_pred):\n    \"\"\"\n    SMAPE Loss\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Ground truth (correct) target values.\n    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Estimated target values.\n    Returns\n    -------\n    loss : float or ndarray of floats\n        If multioutput is 'raw_values', then mean absolute error is returned\n        for each output separately.\n        If multioutput is 'uniform_average' or an ndarray of weights, then the\n        weighted average of all output errors is returned.\n        SMAPE output is non-negative floating point. The best value is 0.0.\n\n    \"\"\"\n    denominator = (np.abs(y_true) + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","c7546487":"# create simple lin. Regression\nmodel_lin_reg = LinearRegression()\n\n# train model\nmodel_lin_reg.fit(_X_train.iloc[:, 3:], y_train.loc[_X_train.index])\n\n# make predictions on validation data\n_pred_lin_reg = model_lin_reg.predict(_X_valid.iloc[:, 3:])\n\n# calcualte SMAPE\nsmape_loss_lin_reg = smape_loss(y_train.loc[_X_valid.index], _pred_lin_reg)\nprint(f'Vadidation data SMAPE:')\nprint(f'Lin. reg.: {smape_loss_lin_reg:.2f}')","0408e833":"# create new DataFrame for comparing predictions on validation dataset\nvalid_res = _X_valid.copy()\n# add predictions for proting\nvalid_res['observed'] = y_train.loc[_X_valid.index]\nvalid_res['Linear regression'] = _pred_lin_reg\nvalid_res.head()","ca352cf9":"def plot_predictions(df_val, model_name='Linear regression'):\n    \"\"\"\n    This function plots predictions on validation Dataset.\n    \"\"\"\n    # get data for ploting\n    df_plot = df_val.groupby('date')[['observed', model_name]].sum()\n    \n    # greate plotting function\n    fig, axes = plt.subplots(2, 1, figsize=(24, 8))\n\n    # temporal visualization\n    axes[0].scatter(df_plot.index, df_plot['observed'], label='Observed', color='#348ABD')\n    axes[0].plot(df_plot.index, df_plot[model_name], label='Model', linewidth=2.5)\n\n    # add legend\n    legend = axes[0].legend(frameon=1)\n    frame = legend.get_frame()\n    frame.set_facecolor('w')\n\n    axes[0].set_xlabel('Date')\n    axes[0].set_title(f'{model_name} model.')\n\n    # histograms\n    axes[1].hist([y_train.loc[_X_valid.index], _pred_lin_reg], bins=np.linspace(0, 3000, 201),\n                 label=['Observed', 'Model'], color=[ '#348ABD', '#E24A33'])\n\n    # add legends with white backgrounds\n    for i in range(2):\n        legend = axes[i].legend(frameon=1)\n        frame = legend.get_frame()\n        frame.set_facecolor('w')\n\n    plt.tight_layout()","de2fa3dc":"plot_predictions(valid_res, 'Linear regression')","8b37597c":"# create simple lin. Regression\nmodel_des_tree = DecisionTreeRegressor(random_state=RANDOM_SEED)\n\n# train model\nmodel_des_tree.fit(_X_train.iloc[:, 3:], y_train.loc[_X_train.index])\n\n# make predictions on validation data\n_pred_des_tree = model_des_tree.predict(_X_valid.iloc[:, 3:])\n\n# calcualte SMAPE\nsmape_loss_des_tree = smape_loss(y_train.loc[_X_valid.index], _pred_des_tree)\nprint(f'Vadidation data SMAPE:')\nprint(f'Des. tree: {smape_loss_des_tree:.2f}')","263313ba":"# add predictions on validation data\nvalid_res['Decision Tree'] = _pred_des_tree\nvalid_res.head()","46705660":"plot_predictions(valid_res, 'Decision Tree')","34b0c709":"def plot_predictions_2(df_val, model_name='Linear regression'):\n    \"\"\"\n    This function plots predictions on validation Dataset.\n    \"\"\"\n    # select data for proting\n    df_plot = df_train.loc[df_val.index].copy()\n    # add predictions data\n    df_plot['model'] = df_val[model_name]\n    # agregate data\n    df_plot = df_plot.groupby(['date', 'country', 'store'])[['num_sold', 'model']].sum().reset_index()\n    \n    # greate plotting function\n    fig, axes = plt.subplots(3, 2, figsize=(24, 10))\n    \n    for i, country in enumerate(df_plot.country.unique()):\n        for ii, store in enumerate(df_plot.store.unique()):\n            # select data\n            _df = df_plot.loc[(df_plot.store == store) & (df_plot.country == country)]\n            axes[i, ii].scatter(_df.date, _df.num_sold, label='Observed', color='#348ABD')\n            axes[i, ii].plot(_df.date, _df.model, label='Model', linewidth=2.5)\n            \n            # calculate smape for subsection\n            _smape = smape_loss(_df.num_sold, _df.model)\n            \n            # add labels and legend\n            axes[i, ii].set_title(f'{country.title()} - {store}. SMAPE: {_smape:.1f}')\n            axes[i, ii].set_ylabel('num. sold')\n            legend = axes[i, ii].legend(frameon=1)\n            frame = legend.get_frame()\n            frame.set_facecolor('w')\n            \n\n    plt.tight_layout()","954045ed":"plot_predictions_2(valid_res, model_name='Decision Tree')","2a10c41c":"# create simple lin. Regression\nfinal_model = DecisionTreeRegressor(random_state=RANDOM_SEED)\n\n# train model\nfinal_model.fit(X_train.iloc[:, 3:], y_train);\n\n# make predictions on test data\npred_test = final_model.predict(X_test.iloc[:, 3:])","d38d0c26":"# make submission\nsubmission = X_test[['row_id']].copy()\nsubmission['num_sold'] = pred_test\n# round results\nsubmission['num_sold'] = submission['num_sold'].round()\nsubmission.to_csv('submission.csv', index=False)","0e7a2532":"## My scores on public leaderboad\n\n* **linear regression:** 25.46780,\n* **decision tree:** 9.56904 (basic data).\n* **decision tree:** 9.77822 (added holiday data).\n* **decision tree:** 6.45971 (added GDP data).\n\n## 1. Load data","2f874f49":"### 4.1 `linear regression` baseline model","8db91d2a":"### 4.2 Decision Tree Regressor\n\n* baseline features.","6b015078":"## 5. Submission","e9e55c69":"## 3. Feature engineering\n\n### 3.1 `min`-`max` scale days.\n\nIn 2015 Februrary had 28 days and in 2016 29. `days` feature will be `min-max` scaled based on the number of days durring specific year, i.e. 28th of Febuary will be equal to the 31-st of January.","8e1ed8f2":"### 2.2 sales by product group","98223dd0":"### 3.2 one-hot-encoding","a13df646":"### 2.3 sales by store","05bc46de":"## 2. Data visualizations\n\n### 2.1 Yearly results","30c44efe":"### 2.4 sales by country","1facdde9":"## 4. Modeling\n\n### Helper functions"}}