{"cell_type":{"a7927ac3":"code","1c3c4556":"code","76bd0f4a":"code","44b9cb06":"code","debfdb04":"code","a862a2f6":"code","6168f651":"code","a48f4cbe":"code","a44bb3e1":"markdown","68b343c2":"markdown","8b20571a":"markdown","9bb09021":"markdown","5adac887":"markdown","c6fa0a25":"markdown","37d52b37":"markdown","2147d96f":"markdown","1d1c5f65":"markdown","c3425967":"markdown","e33b81a4":"markdown","08402f3f":"markdown","b47f0813":"markdown"},"source":{"a7927ac3":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\nfrom sklearn import svm","1c3c4556":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\n# Remove rows with missing target values\ntrain_data.dropna(axis=0, subset=['Survived'], inplace=True)\ny = train_data.Survived # Target variable             \ntrain_data.drop(['Survived'], axis=1, inplace=True) # Removing target variable from training data\n\ntrain_data.drop(['Age'], axis=1, inplace=True) # Remove columns with null values\n\n# Select numeric columns only\nnumeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\nX = train_data[numeric_cols].copy()\n\nprint(\"Shape of input data: {} and shape of target variable: {}\".format(X.shape, y.shape))\n\n# X.head() \npd.concat([X,y], axis=1).head()# Show first 5 training examples","76bd0f4a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)\nprint('X_train dimension= ', X_train.shape)\nprint('X_test dimension= ', X_test.shape)\nprint('y_train dimension= ', y_train.shape)\nprint('y_train dimension= ', y_test.shape)","44b9cb06":"clf= svm.SVC()\nclf.fit(X_train, y_train)\nprint('Model score using default parameters is = ', clf.score(X_test, y_test))","debfdb04":"# Let create parameter grid for GridSearchCV\nparameters = {  'C':[0.01, 1, 5],\n                'kernel':('linear', 'rbf'),\n                'gamma' :('scale', 'auto')\n             }\ngsc = GridSearchCV(estimator = svm.SVC(), param_grid= parameters,cv= 5,verbose =1)\n\n# Fitting the model for grid search. It will first find the best parameter combination using cross validation. \n# Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), \n# to built a single new model using the best parameter setting.\ngsc.fit(X_train, y_train) ","a862a2f6":"print(f'Best hyperparameters: {gsc.best_params_}') \nprint(f'Best score: {gsc.best_score_}')\nprint('Detailed GridSearchCV result is as below')\ngsc_result = pd.DataFrame(gsc.cv_results_).sort_values('mean_test_score',ascending= False)\ngsc_result[['param_C','param_kernel','param_gamma','mean_test_score']]","6168f651":"# n_iter=5 > Number of parameter settings that are sampled. \n# So instaed of 12 it will randomly search for only 5 combinations for each fold\nrsc = RandomizedSearchCV(estimator = svm.SVC(), param_distributions= parameters,cv=5,n_iter = 5,verbose =1)\nrsc.fit(X_train, y_train)","a48f4cbe":"print(f'Best hyperparameters: {rsc.best_params_}') \nprint(f'Best score: {rsc.best_score_}')\nprint('Detailed RandomizedSearchCV result is as below')\nrsc_result = pd.DataFrame(rsc.cv_results_).sort_values('mean_test_score',ascending= False)\nrsc_result[['param_C','param_kernel','param_gamma','mean_test_score']]","a44bb3e1":"# Random Search Example <a id =\"15\"><\/a>\nWe will use same dataset and same parameter grid for hyperparameter tuning.","68b343c2":"# Grid Search Example <a id =\"9\"><\/a>\n\nWe are going to use [Titanic: Machine Learning from Disaster](https:\/\/www.kaggle.com\/c\/titanic\/overview) competition data. We will to convert this dataset into toy dataset so that we can straightaway jump into hyperparameter tuning\n\n![Titanic_Machine_Learning_from_Disaster](https:\/\/raw.githubusercontent.com\/satishgunjal\/images\/master\/Titanic_Machine_Learning_from_Disaster.png)\n\n## Import Libraries <a id =\"10\"><\/a>\n\n* pandas: Used for data manipulation and analysis\n* train_test_split: Sklearn library to split arrays or matrices into random train and test subsets\n* GridSearchCV: Sklearn library to perform exhaustive search over specified parameter values for an estimator\n* RandomizedSearchCV: Sklearn library to perform randomized search on hyper parameters \n* svm: Sklearn Support Vector Machines library","8b20571a":"## Load Dataset <a id =\"11\"><\/a>\nWe will load the dataset into pandas dataframe and convert it into a toy dataset by removing categorical columns and rows and columns with null values.","9bb09021":"![Hyperparameter_Tuning_Header_1000x690](https:\/\/raw.githubusercontent.com\/satishgunjal\/images\/master\/Hyperparameter_Tuning_Header_1000x690.png)","5adac887":"# References:\n* [What is the Difference Between a Parameter and a Hyperparameter?](https:\/\/machinelearningmastery.com\/difference-between-a-parameter-and-a-hyperparameter\/)\n* [sklearn.model_selection.GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html)\n* [sklearn.model_selection.RandomizedSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html)\n* [SVM Hyperparameter Tuning using GridSearchCV | ML](https:\/\/www.geeksforgeeks.org\/svm-hyperparameter-tuning-using-gridsearchcv-ml\/)","c6fa0a25":"# Index\n* [Introduction](#1)\n* [Parameter vs Hyperparameter](#2)\n  - [Parameter](#3)\n  - [Hyperparameter](#4)\n* [Hypertuning Steps](#5)\n* [Tuning Strategy](#6)\n  - [Grid Search](#7)\n  - [Random Search](#8)\n* [Grid Search Example](#9)\n  - [Import Libraries](#10)\n  - [Load Dataset](#11)\n  - [Understanding the Data](#12)\n  - [Model Score Without Hyperparameter Tuning](#13)\n  - [Model Score Using Hyperparameter Tuning](#14)  \n* [Random Search Example](#15)\n* [Conclusion](#16)","37d52b37":"# Introduction <a id =\"1\"><\/a>\nAs of now we have covered most of the basic machine learning algorithms and you must have noticed that in case of [K-Means Clustering](https:\/\/www.kaggle.com\/satishgunjal\/tutorial-k-means-clustering\/notebook) we have to provide the value of 'K', similarly in case of [Support Vector Machines](https:\/\/www.kaggle.com\/satishgunjal\/tutorial-support-vector-machines) we have to choose gamma and Regularization parameter(C). Such parameters which needs to be specified before fitting the model are called as Hyperparameter. Since parameters can't be estimated from data, getting their value correct have the biggest impact on the model performance. Only way to find the best possible value of hyperparameters is to try them and choose the best performing one, this process is knows as hyperparameter tuning. \n\n# Parameter vs Hyperparameter <a id =\"2\"><\/a>\n\n## Parameter <a id =\"3\"><\/a>\n\n* Parameter also known as model parameter is a configuration variable which is internal to model and whose value can be estimated from the data\n* They are required by the model when making predictions\n* They are estimated or learned from data\n* They are often not set manually by the practitioner\n* They are often saved as part of the learned model\n* Some examples of model parameters include:\n  * The weights in an artificial neural network\n  * The support vectors in a support vector machine\n  * The coefficients in a linear regression or logistic regression\n\n## Hyperparameter <a id =\"4\"><\/a>\n\n* Hyperparameter are external to the model and whose values cannot be estimated based on the data\n* They are often specified by the practitioner (By testing the model with test data)\n* They are often tuned for a given predictive modeling problem\n* They can often be set using heuristics\n* Some examples of model hyperparameters include:\n  * The learning rate for training a neural network\n  * The gamma and Regularization parameter(C) hyperparameters for support vector machines\n  * The K in K-nearest neighbors\n  * No of trees (n_estimators) in Random Forest Algorithm\n  \n![Hyperparameter_Tuning](https:\/\/raw.githubusercontent.com\/satishgunjal\/images\/master\/Hyperparameter_Tuning1.png)\n  \n# Hypertuning Steps <a id =\"5\"><\/a>\n\n* Make a list of different hyperparameters based on the problem in hand. If there are more than one hyperparameter then make grid with different combination of parameters\n* Fit all of them separately to the model. If you have large number of hyperparameters then training time and computational cost will be very high. To reduce it you may try few random combination of hyperparameters, instead of going for every possible permutation.\n* Note down the model performance\n* Choose the best performing one\n\nAlways use cross validation technique for hyperparameter tuning to avoid the model overfitting on test data.\n\n# Tuning Strategy <a id =\"6\"><\/a>\n\nModels can have many hyperparameters and to try every permutation of it can be treated as a search problem. Below are the two most common ways to perform the hyperparameter tuning.\n\n## Grid Search <a id =\"7\"><\/a>\n\n* Grid search exhaustively considers all parameter combinations for an estimator.\n* GridSearchCV implements a \u201cfit\u201d and a \u201cscore\u201d method. It also implements \u201cpredict\u201d, \u201cpredict_proba\u201d, \u201cdecision_function\u201d, \u201ctransform\u201d and \u201cinverse_transform\u201d if they are implemented in the estimator used.\n* The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n* Since grid search goes through every possible combination of hyperparameters, it is computationally expensive and takes longer time to complete.\n\n## Random Search <a id =\"8\"><\/a>\n\n* Unlike grid search, random search perform randomized search on hyper parameters and selects few parameter combinations for an estimator.\n* RandomizedSearchCV implements a \u201cfit\u201d and a \u201cscore\u201d method. It also implements \u201cpredict\u201d, \u201cpredict_proba\u201d, \u201cdecision_function\u201d, \u201ctransform\u201d and \u201cinverse_transform\u201d if they are implemented in the estimator used.\n* The parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.\n* Since random search goes through selective combination of hyperparameters, it is computationally less expensive and takes less time to complete.","2147d96f":"## Model Score Without Hyperparameter Tuning <a id =\"13\"><\/a>\n\nWe will split the dataset using **train_test_split()** method and use training set for model training and test set for model testing. Later we will use hyperparameter tuning to improve the model performance.","1d1c5f65":"## Understanding the Data <a id =\"12\"><\/a>\nFinal dataset contains 5 features and 891 training examples. We have to predict which passengers survived the Titanic shipwreck based on available training data. Features that we are going to use in this example are passenger id, ticket class, sibling\/spouse aboard, parent\/children aboard and ticket fare.","c3425967":"Now lets train using SVM classifier. Note that we are using default parameters.","e33b81a4":"That took long time to complete!!\nNow lets review the results from GridSearchCV.","08402f3f":"# Conclusion <a id =\"16\"><\/a>\nAs you can see from above results hyperparameter tuning helps to find the best parameters which can improve the model performance. Since grid search takes more time and is computationally more heavy, it's not suitable for big datasets. Random search is obvious choice for big datasets, but it doesn't guarantee to find the best parameters as it uses only selected samples of the parameters.","b47f0813":"## Model Score Using Hyperparameter Tuning <a id =\"14\"><\/a>\nSo without hyperparameter tuning we get only 60% accuracy, lets see the model performance using hyperparameter tuning"}}