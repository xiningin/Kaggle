{"cell_type":{"a405cd68":"code","e14e66fd":"code","2c8bc625":"code","077d1503":"code","bc381172":"code","34b32fc0":"code","92a9c611":"code","2a3b338e":"code","f41f6870":"code","ec870a9a":"code","73ff013a":"code","51ba6086":"code","c9130983":"code","30ed5215":"code","64b0b72c":"code","9374e081":"code","8386d196":"code","4df82e23":"code","d45af09d":"code","427e097f":"code","8167c67d":"code","0b7cfa51":"code","e8ad303d":"code","84b736e1":"code","32be7abe":"code","a017c261":"code","873deab3":"code","ab50c1d9":"code","c249b796":"code","29804aea":"code","ca12b876":"code","92e828a4":"code","8736171e":"code","3cccf5f1":"code","e58e370e":"code","ae0d3eb1":"code","c603ddae":"code","a78bb334":"code","fe046d98":"code","11d4869d":"code","577e6d7f":"code","b7a20b8e":"code","eef84422":"code","5cb8e181":"code","7a1bc157":"code","e3cc3a18":"code","fceaf128":"code","d2f735b0":"code","6f194240":"code","8931e6fc":"code","405a2175":"code","77a3b534":"code","ecc830fe":"code","ac57c575":"code","b6b94240":"code","3483a38a":"code","beb27463":"markdown","ca412e14":"markdown","5c048c43":"markdown","e76f3fe9":"markdown","21d4f908":"markdown","3eb62eb2":"markdown","064b2279":"markdown","07c0be5d":"markdown","1db9b728":"markdown"},"source":{"a405cd68":"\nimport numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e14e66fd":"dataset = pd.read_csv(\"..\/input\/szeged-weather\/weatherHistory.csv\")","2c8bc625":"dataset.head()","077d1503":"dataset.info()","bc381172":"dataset.isnull().sum() #there are 517 null values which should be replaced","34b32fc0":"#checking what\u00b4s the most often item\ndataset[\"Precip Type\"].mode()[0] ","92a9c611":"#replacing null values by most often item, in this case it\u00b4s \"rain\"\ndataset[\"Precip Type\"] = dataset[\"Precip Type\"].fillna(dataset[\"Precip Type\"].mode()[0]) \n","2a3b338e":"dataset.isna().sum() ","f41f6870":"#formating column to date format\ndataset[\"Formatted Date\"] = pd.to_datetime(dataset[\"Formatted Date\"], format = \"%Y-%m-%d %H:%M:%S.%f %z\") ","ec870a9a":"#checking dataset\ndataset","73ff013a":"#checking unigue values in columns\n{column: len(dataset[column].unique()) for column in dataset.columns} ","51ba6086":"#\"loud cover\" has only one unique value\ndataset = dataset.drop([\"Loud Cover\",\"Daily Summary\"], axis=1) ","c9130983":"#checking correlations\ndataset.corr() ","30ed5215":"#apparent temperature is highly correlated to temperature and should be removed\ndataset = dataset.drop([\"Apparent Temperature (C)\"], axis=1) ","64b0b72c":"dataset","9374e081":"{column: len(dataset) for column in dataset.columns}","8386d196":"len((dataset.columns))","4df82e23":"X = dataset","d45af09d":"{column: len(X[column].unique()) for column in X.columns}","427e097f":"dataset[\"year\"] = dataset[\"Formatted Date\"].apply(lambda x: x.year)\ndataset[\"month\"] = dataset[\"Formatted Date\"].apply(lambda x: x.month)\ndataset[\"day\"] = dataset[\"Formatted Date\"].apply(lambda x: x.day)","8167c67d":"dataset","0b7cfa51":"dataset.info()","e8ad303d":"dataset = dataset.drop([\"Formatted Date\"], axis=1)","84b736e1":"dataset","32be7abe":"le = preprocessing.LabelEncoder()","a017c261":"le.fit(dataset[\"Summary\"])\n","873deab3":"list(le.classes_)","ab50c1d9":"dataset[\"Summary\"] = le.transform(dataset[\"Summary\"])","c249b796":"dataset","29804aea":"le.fit(dataset[\"Precip Type\"])","ca12b876":"dataset[\"Precip Type\"] = le.transform(dataset[\"Precip Type\"])","92e828a4":"#all columns are numeric and scaled\ndataset.info()","8736171e":"y = dataset[\"Temperature (C)\"]","3cccf5f1":"X = dataset.drop([\"Temperature (C)\"], axis = 1)","e58e370e":"X","ae0d3eb1":"sc = StandardScaler()\nsc.fit(X)\nX = pd.DataFrame(sc.transform(X), columns=X.columns)","c603ddae":"X","a78bb334":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)","fe046d98":"#new dictionary for models and names\nmodels = { \n    \n                \"Linear regression\": LinearRegression(),\n                 \"Ridge regression\": Ridge(),\n                 \"Lasso regression\": Lasso(),\n           \"Elastic Net regression\": ElasticNet(),\n   \"K-nearest Neighbors regression\": KNeighborsRegressor(),\n         \"Decision Tree regression\": DecisionTreeRegressor(),\n'Support Vector Machine regression': SVR(),\n         \"Random Forest Regression\": RandomForestRegressor()\n    \n            \n\n}","11d4869d":"models","577e6d7f":"#training models\nfor name, model in models.items():\n    y_pred = model.fit(X_train, y_train)\n    print(name + \" Trained\")\n    ","b7a20b8e":"#printing R^2 results\nfor name, model in models.items():\n    y_pred = model.predict(X_test)  \n    print(name  + \" R^2: {:.8f}\".format(r2_score(y_test, y_pred)))","eef84422":"#printing RMSE results\nfor name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(name  + \" RMSE: {:.8f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))","5cb8e181":"lr = LinearRegression()\nlr.fit(X_train,y_train)\n\ny_pred_lr = lr.predict(X_test)","7a1bc157":"rr = Ridge()\nrr.fit(X_train,y_train)\n\ny_pred_rr = rr.predict(X_test)","e3cc3a18":"lsr = Lasso()\nlsr.fit(X_train,y_train)\ny_pred_lsr = lsr.predict(X_test)","fceaf128":"enr = ElasticNet()\nenr.fit(X_train,y_train)\ny_pred_enr = enr.predict(X_test)","d2f735b0":"knr = KNeighborsRegressor()\nknr.fit(X_train,y_train)\ny_pred_knr = knr.predict(X_test)","6f194240":"dtr = DecisionTreeRegressor()\ndtr.fit(X_train,y_train)\ny_pred_dtr = dtr.predict(X_test)","8931e6fc":"svr = SVR()\nsvr.fit(X_train,y_train)\ny_pred_svr = svr.predict(X_test)","405a2175":"rfr = RandomForestRegressor()\nrfr.fit(X_train,y_train)\n  \ny_pred_rfr = rfr.predict(X_test)","77a3b534":"r2_score(y_test, y_pred_rfr)","ecc830fe":"np.sqrt(mean_squared_error(y_test,y_pred_rfr))","ac57c575":"model_eval = pd.DataFrame(index=[\"Linear Regression\"], columns=[\"r2 score\", \"RMSE\"])","b6b94240":"model_eval.loc[\"Linear Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_lr))\nmodel_eval.loc[\"Linear Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_lr)))\nmodel_eval.loc[\"Ridge Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_rr))\nmodel_eval.loc[\"Ridge Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_rr)))\nmodel_eval.loc[\"Lasso Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_lsr))\nmodel_eval.loc[\"Lasso Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_lsr)))\nmodel_eval.loc[\"Elastic Net Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_enr))\nmodel_eval.loc[\"Elastic Net Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_enr)))\nmodel_eval.loc[\"K-nearest Neighbors Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_knr))\nmodel_eval.loc[\"K-nearest Neighbors Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_knr)))\nmodel_eval.loc[\"Decision Tree Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_dtr))\nmodel_eval.loc[\"Decision Tree Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_dtr)))\nmodel_eval.loc[\"Support Vector Machine Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_svr))\nmodel_eval.loc[\"Support Vector Machine Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_svr)))\nmodel_eval.loc[\"Random Forest Regression\", \"r2 score\"] = \"{:.8f}\".format(r2_score(y_test, y_pred_rfr))\nmodel_eval.loc[\"Random Forest Regression\", \"RMSE\"] = \"{:.8f}\".format(np.sqrt(mean_squared_error(y_test,y_pred_rfr)))\n\nmodel_eval.reset_index(inplace = True)","3483a38a":"#checking results in dataframe ready to pipe to PowerBI \nmodel_eval","beb27463":"# 3. **Preprocessing**","ca412e14":"# 6. Preparing predicted results r2 score and RMSE for PowerBI dataframe ","5c048c43":"# 7. Conclusion\n\nAs we can see, best results were delivered by Random Forest. Since best R^2 score is 1, i\u00b4ve managed to get 0,96 without much tuning, so score can be even better.\n\nRMSE score is 1,85 which means Random Forest predicts by 1,85 C\u00b0 accuracy.\n\nBig disadvantage of Random Forest and also Decision Tree is slow training, training of all models took about 20 mins and 90% of this time was spent on these two. ","e76f3fe9":"Preparing dataframe from PowerBI dashboard","21d4f908":"# 2. **Checking data if there are some nulls and NaNs**","3eb62eb2":"For this project I did pick weather data from Szeged and i\u00b4ll try various regression models to see which perform best. \n\nMy task is predict temperature, make interactive dashboard in PowerBI to understand data and show dataframe with results in the end.\n\nThere is link to public PowerBI Dashboard: \n\nhttps:\/\/app.powerbi.com\/view?r=eyJrIjoiOTJiMWVjMWUtOTlhMS00YzljLTg5MjItZTM4NmUxNzBjZDNhIiwidCI6ImQyZjljZjBlLTc0ZDEtNGNiMi1hZTk5LWRmZTYyMjkxOGQ1MCIsImMiOjl9\n\n","064b2279":"# 5. **Test, train split and fitting to models**","07c0be5d":"# 1. **Importing data**","1db9b728":"# 4. **Label encoding text values**"}}