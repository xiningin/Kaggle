{"cell_type":{"ba3ec20a":"code","4eb43315":"code","4eb8cb5e":"code","f11c5f44":"code","9b371645":"code","02b94f08":"code","f071726d":"code","25f22c62":"code","8b381867":"code","ba6a44b1":"code","ab2946e6":"code","555e34f7":"code","5ebdc2be":"code","c01c46d5":"code","ebe62a80":"code","de3b1c81":"code","3389fc3d":"code","5edb7ff6":"code","fc630233":"code","c5495408":"code","3711b410":"code","e9b764bb":"code","69dd07c7":"code","0d2caaf1":"code","62292f79":"code","696d0f05":"code","193d1c1e":"code","85820356":"code","ae7d8619":"code","07c81f6a":"code","fa692f82":"code","49e30a3e":"code","cf28644d":"code","007e3699":"code","5ac3b260":"code","7baf8418":"code","d841a9bc":"code","0eaf63c5":"code","b53d267f":"code","913553aa":"code","8e4f27a0":"code","749c4fdc":"code","6afa8150":"code","a3863c1b":"code","ca8fc598":"code","5c87e272":"code","9b07368d":"code","aa621bcd":"code","02cc8878":"markdown","a083f126":"markdown","5fac66bb":"markdown","93ab8392":"markdown","c51bef41":"markdown","fa9fb57a":"markdown","2d36ca02":"markdown","bcd2a6e6":"markdown","73c18303":"markdown","7e2bda25":"markdown","e814e658":"markdown","8c6c3ba7":"markdown","c07bcf37":"markdown","217ed413":"markdown","bbdf3844":"markdown","bdd2cf77":"markdown","38c535b7":"markdown","9c635a2f":"markdown","649c5036":"markdown","b06ecb1d":"markdown","14b4368a":"markdown","100b3b16":"markdown","cf1a9203":"markdown","ec0ebc0d":"markdown","50b376f2":"markdown","d26c6384":"markdown","519d63a0":"markdown","cf3cf91e":"markdown","9b0b28b5":"markdown","3e21aea0":"markdown","5cf660b7":"markdown"},"source":{"ba3ec20a":"import pandas as pd \nimport numpy as np \nimport numpy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport ipywidgets \nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom pandas_profiling import ProfileReport\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier","4eb43315":"train= pd.read_csv('..\/input\/titanic\/train.csv')\ntest= pd.read_csv('..\/input\/titanic\/test.csv')","4eb8cb5e":"train.head()","f11c5f44":"train.columns","9b371645":"train.info()","02b94f08":"train.describe()","f071726d":"### Check for missing values\ntrain.isna().sum()","25f22c62":"# define imputer\nimputer = KNNImputer()\n# fit on the dataset\nimputer.fit(train['Age'].values.reshape(-1,1))\n# transform the dataset\ntraintrans = imputer.transform(train['Age'].values.reshape(-1,1))\ntesttrans = imputer.transform(test['Age'].values.reshape(-1,1))","8b381867":"train['Age_new']=traintrans\ntest['Age_new']=testtrans","ba6a44b1":"train['Age_new']=train['Age_new'].astype(int)\ntest['Age_new']=test['Age_new'].astype(int)","ab2946e6":"display(train['Age_new'].isna().sum())\ndisplay(test['Age_new'].isna().sum())","555e34f7":"train['Embarked'].value_counts()","5ebdc2be":"#repalce the missing values 'Embarked' column with the highest occuring frequency.\ntrain['Embarked'] = train['Embarked'].fillna('S') \ntest['Embarked'] = test['Embarked'].fillna('S') ","c01c46d5":"### Check for missing values\n# train.isna().sum()\n## all the required columns are imputed, drop the previous Age column\ntrain.drop('Age',axis=1,inplace=True)\ntest.drop('Age',axis=1,inplace=True)","ebe62a80":"file = ProfileReport(train)\nfile.to_file(output_file='output.html')","de3b1c81":"file","3389fc3d":"fig = make_subplots(rows=2, cols=2)\nfig.add_trace(go.Histogram(x=train['Age_new'],\n                           histnorm='probability',\n                           marker_color='#EB89B5',name=\"Age:Histogram\"),row=1,col=1) \nfig.add_trace(go.Violin(y=train['Age_new'],\n                        box_visible=True,\n                        meanline_visible=True,\n                        points='all',\n                        jitter=0.05,\n                        marker_color='yellow',name=\"Age:Violin\"),row=1,col=2)\nfig.add_trace(go.Histogram(x=train['Fare'],\n                           histnorm='probability',\n                           marker_color='#EB89B5',name=\"Fare:Histogram\"),row=2,col=1) \nfig.add_trace(go.Violin(y=train['Fare'],\n                        box_visible=True,\n                        meanline_visible=True,\n                        points='all',\n                        jitter=0.05,\n                        marker_color='yellow',name=\"Fare:Violin\"),row=2,col=2)\n\nfig.update_xaxes(title_text=\"Age : Histogram Distribution\", row=1, col=1)\nfig.update_xaxes(title_text=\"Age : Violin Distribution\", row=1, col=2)\nfig.update_xaxes(title_text=\"Fare : Histogram Distribution\", row=2, col=1)\nfig.update_xaxes(title_text=\"Fare : Violin Distribution\", row=2, col=2)\n\nfig.update_layout(title={'text':\"Distribution Plots:Age and Fare\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.97},\n                  template='plotly_dark',\n                  height=900,\n                  legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )),\n                  annotations=[dict(showarrow=True,\n                                x=50,\n                                y=0.04,\n                                ax=30,\n                                ay=-50,\n                                xref='x1',\n                                yref='y1',\n                                text=\"Right Skewed\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.7,\n                                font=dict(color=\"red\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowhead=4),\n                               dict(showarrow=True,\n                                x=80,\n                                y=0.06,\n                                ax=30,\n                                ay=-50,\n                                xref='x3',\n                                yref='y3',\n                                text=\"Slight right <br>skewed\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.7,\n                                font=dict(color=\"red\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowhead=4)\n                          ])\nfig.show() ","5edb7ff6":"col_y = 'Survived'\ntargets = [train.loc[train[col_y] == val] for val in train[col_y].unique()]\nfig=go.Figure()\nfig.add_trace(go.Histogram(x=targets[0]['Age_new'],\n                               histnorm='probability',\n                               marker_color='yellow',name=\"Survived:0\"))\nfig.add_trace(go.Histogram(x=targets[1]['Age_new'],\n                               histnorm='probability',\n                               marker_color='red',name=\"Survived:1\"))\nfig.update_xaxes(title_text=\"Age : Histogram Distribution\")\nfig.update_layout(title={'text':\"Distribution :Age Hue on Survived\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.97},\n                      template='plotly_dark',\n                      legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )),\n                        annotations=[dict(showarrow=True,\n                                x=23,\n                                y=0.28,\n                                text=\" Survived Distribution <br> for 0\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.9,\n                                font=dict(color=\"lightgoldenrodyellow\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowhead=4),\n                                    dict(showarrow=True,\n                                x=40,\n                                y=0.14,\n                                ax=10,\n                                ay=-50,\n                                text=\" Survived Distribution <br> for 1\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.9,\n                                font=dict(color=\"lightgoldenrodyellow\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowside=\"end\",\n                                arrowhead=4)],\n                      barmode='overlay')\nfig.update_traces(opacity=0.5)\nfig.show();","fc630233":"col_y = 'Survived'\ntargets = [train.loc[train[col_y] == val] for val in train[col_y].unique()]\nfig=go.Figure()\nfig.add_trace(go.Histogram(x=targets[0]['Fare'],\n                               histnorm='probability',\n                               marker_color='yellow',name=\"Survived:0\"))\nfig.add_trace(go.Histogram(x=targets[1]['Fare'],\n                               histnorm='probability',\n                               marker_color='red',name=\"Survived:1\"))\nfig.update_xaxes(title_text=\"Fare : Histogram Distribution\")\nfig.update_layout(title={'text':\"Distribution :Fare Hue on Survived\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.97},\n                      template='plotly_dark',\n                      legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )),\n                        annotations=[dict(showarrow=True,\n                                x=-4,\n                                y=0.65,\n                                text=\" Survived Distribution <br> for 0\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.9,\n                                font=dict(color=\"lightgoldenrodyellow\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowhead=4),\n                                    dict(showarrow=True,\n                                x=40,\n                                y=0.14,\n                                ax=10,\n                                ay=-50,\n                                text=\" Survived Distribution <br> for 1\",\n                                xanchor=\"center\",\n                                xshift=10,\n                                opacity=0.9,\n                                font=dict(color=\"lightgoldenrodyellow\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowside=\"end\",\n                                arrowhead=4)],\n                      barmode='overlay')\nfig.update_traces(opacity=0.5)\nfig.show();","c5495408":"fig=go.Figure()\nfig.add_trace(go.Box(x=train['Pclass'],\n                     y=train['Age_new'],\n                     marker=dict(\n                                color='limegreen',\n                                outliercolor='red',\n                                line=dict(\n                                    outliercolor='red',\n                                    outlierwidth=2)),\n                     name=\"pclass\",\n                     jitter=0.5,\n                     boxmean='sd',\n                     boxpoints='suspectedoutliers'))\nfig.update_xaxes(title_text=\"Pclass : Boxplot\")\nfig.update_layout(title={'text':\"Boxplot :Age Hue on Pclass\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.97},\n                      template='plotly_dark',\n                      legend=dict(yanchor=\"bottom\",\n                                  y=0.5,\n                                  xanchor=\"center\",\n                                  x=1.2),\n                      barmode='overlay',\n                      annotations=[dict(showarrow=True,\n                                x=2,\n                                y=72,\n                                text=\" Outlier\",\n                                xanchor=\"right\",\n                                xshift=0,\n                                opacity=0.9,\n                                font=dict(color=\"lightgoldenrodyellow\",\n                                          size=12),\n                                arrowcolor=\"lightgoldenrodyellow\",\n                                arrowsize=5,\n                                arrowwidth=0.5,\n                                arrowhead=4)],)\nfig.update_traces(opacity=0.5)\nfig.show();","3711b410":"fig=ex.violin(train,\n              y='Survived',\n              x='Fare', \n              color='Survived',\n              orientation='h').update_traces(side='positive',width=2)\nfig.update_xaxes(title_text=\"Fare : Violin Side Positive Hue on Surbvived \")\nfig.update_layout(template=\"plotly_dark\",\n                  legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )\n                          ))","e9b764bb":"fig = ex.pie(train,values=\"Survived\",names=\"Sex\",template=\"plotly_dark\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Sex composition of Survive Passengers',\n           layout_showlegend=False)","69dd07c7":"fig = ex.pie(train,values=\"Fare\",names=\"Pclass\",template=\"plotly_dark\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update_layout(title=\"Fare composition of Pclass Passengers\",\n          legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=-0.2,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )))","0d2caaf1":"fig=ex.histogram(train, x='Survived', color=\"Sex\", barmode='group',template=\"plotly_dark\")\nfig.update_xaxes(title_text=\"Sex composition of Survived\")\nfig.update_layout(\n           legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )))","62292f79":"fig=ex.histogram(train, x='Survived', color=\"SibSp\",barmode='group',template=\"plotly_dark\")\nfig.update_xaxes(title_text=\"SibSp composition of Survived\")\nfig.update_layout(\n           legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )))","696d0f05":"train.columns","193d1c1e":"from plotly.graph_objs import *\ncols=['Survived', 'Pclass','Sex', 'SibSp', 'Parch','Fare','Embarked', 'Age_new']\ntrace1 = {\n  \"type\": \"heatmap\", \n  \"x\": train[cols].corr().columns.tolist(), \n  \"y\": train[cols].corr().columns.tolist(), \n  \"z\": train[cols].corr().values.tolist()\n}\ndf = Data([trace1])\nfig = Figure(data=df)\nfig.update_layout(template='plotly_dark',\n                  title={'text':\"Features Correlation Matrix\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.9})\nfig.show()","85820356":"train['age_bucket']=np.where(train['Age_new']<=30,\"0-30\",\n                           np.where((train['Age_new']>30)&(train['Age_new']<=40),\"30-40\",\n                                   np.where((train['Age_new']>40)&(train['Age_new']<=50),\"40-50\",\n                                           np.where((train['Age_new']>50)&(train['Age_new']<=60),\"50-60\",\"60+\"))))","ae7d8619":"fig = ex.parallel_categories(train, dimensions=['age_bucket', 'Survived'],\n                labels={'age_bucket':'Age Bucket', 'Survived':'Survived'},\n                template='ggplot2',\n                title=\"Parallely Corordinates : Distribution of Age bucket v\u00eds-a-v\u00eda Diabetes\")\nfig.update_layout()\nfig.show()","07c81f6a":"train = train.drop(['PassengerId','Name','Ticket','Cabin'],axis = 1)\ntest = test.drop(['PassengerId','Name','Ticket','Cabin'],axis = 1)\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)","fa692f82":"train.columns","49e30a3e":"train['Survived']=train['Survived'].astype(int)","cf28644d":"col=['Pclass', 'SibSp', 'Parch', 'Fare', 'Age_new', 'Sex_female',\n       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\nX = train\nY = X['Survived'].values\nX = X.drop('Survived', axis = 1)\nX = X[col]","007e3699":"X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)","5ac3b260":"# Function to create model, required for KerasClassifier\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","7baf8418":"# fix random seed for reproducibility\nseed = 123\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0)\n# define the grid search parameters\nbatch_size = [10, 20, 40, 60, 80, 100]\nepochs = [10, 50, 100]\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","d841a9bc":"# Function to create model, required for KerasClassifier\ndef create_model(optimizer='adam'):\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model","0eaf63c5":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\noptimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\nparam_grid = dict(optimizer=optimizer)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","b53d267f":"from keras.optimizers import SGD\n# Function to create model, required for KerasClassifier\ndef create_model(learn_rate=0.01, momentum=0):\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    # Compile model\n    optimizer = SGD(lr=learn_rate, momentum=momentum)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model","913553aa":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\nlearn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\nmomentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\nparam_grid = dict(learn_rate=learn_rate, momentum=momentum)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","8e4f27a0":"# Function to create model, required for KerasClassifier\ndef create_model(init_mode='uniform'):\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, kernel_initializer=init_mode, activation='relu'))\n    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","749c4fdc":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\ninit_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\nparam_grid = dict(init_mode=init_mode)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","6afa8150":"# Function to create model, required for KerasClassifier\ndef create_model(activation='relu'):\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, kernel_initializer='uniform', activation=activation))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","a3863c1b":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\nactivation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\nparam_grid = dict(activation=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","ca8fc598":"from keras.constraints import maxnorm\nfrom keras.layers import Dropout\n# Function to create model, required for KerasClassifier\ndef create_model(dropout_rate=0.0, weight_constraint=0):\n    # create model\n    model = Sequential()\n    model.add(Dense(15, input_dim=10, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(weight_constraint)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","5c87e272":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\nweight_constraint = [1, 2, 3, 4, 5]\ndropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\nparam_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","9b07368d":"# Function to create model, required for KerasClassifier\ndef create_model(neurons=1):\n    # create model\n    model = Sequential()\n    model.add(Dense(neurons, input_dim=10, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","aa621bcd":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n# define the grid search parameters\nneurons = [1, 5, 10, 15, 20, 25, 30]\nparam_grid = dict(neurons=neurons)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","02cc8878":"<br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #EEE8AA ; color : #808000; text-align: center; border-radius: 100px 100px;\">Titanic- EDA and Model building <\/h1>\n<br>\n    \n<center><img src=\"https:\/\/hips.hearstapps.com\/hmg-prod.s3.amazonaws.com\/images\/the-white-star-line-passenger-liner-r-m-s-titanic-embarking-news-photo-1608252641.\"><\/center>\n","a083f126":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune the Training Optimization Algorithm&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","5fac66bb":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Bucketing Age and Parallel Categories Plot&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","93ab8392":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the activation=tanh achieved the best result of about 80.58% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","c51bef41":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune the Number of Neurons in the Hidden Layer&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","fa9fb57a":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune Network Weight Initialization&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","2d36ca02":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Features and Information&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","bcd2a6e6":"<a id = \"results\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EEE8AA; border-radius:6px; font-weight: bold; font-family:Garamond; font-size:26px; color:#808080; \">Conclusion and Further Improvement<\/span><\/h1>\n\n* The objective o fhtis notebook was to give the understanding on how to use hyperparameters for NN in keras.\n* There are amny other algorithms that can be used to acheive better accuracy.\n* Further improvements can be done using some fine tuning on the base classifiers with additional classifiers.\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">PLEASE UPVOTE IF IT IS USEFUL&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","73c18303":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the batch size of 10 and 100 epochs achieved the best result of about 78.33% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","7e2bda25":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Train Test Split&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","e814e658":"Only about 38.38 % (342) of the total passengers (891) survived.","8c6c3ba7":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Pandas Profiling&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","c07bcf37":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the optimizer=RMSProp achieved the best result of about 79.01% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","217ed413":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Bivariate Analysis&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> \n\nThe target variable is a categorical variable. We can just add the target variable as the hue layer to show the distribution by each target class. If the variable is predictive, we shall see significant distribution across classes of the target variable","bbdf3844":"\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune the Neuron Activation Function&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","bdd2cf77":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune Learning Rate and Momentum&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","38c535b7":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune Dropout Regularization&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","9c635a2f":"#### We can see few nulls in Age, Cabin and Embarkerd column. Cabin is of no use as for the perdiction purpose we will impute Age and Embarked.","649c5036":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Install Libraries&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","b06ecb1d":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Read Data&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","14b4368a":"<a id = \"model\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EEE8AA; border-radius:6px; font-weight: bold; font-family:Garamond; font-size:26px; color:#808080; \">Model Building<\/span><\/h1>","100b3b16":"<center><br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #EEE8AA ; color : #808000; text-align: center; border-radius: 100px 100px;\">Content <\/h1>\n<br><\/center>\n    \n<p id=\"toc\"><\/p>\n    \n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#OV\">&nbsp;&nbsp;&nbsp;&nbsp;1.Overview<\/a><\/h3>\n\n---\n    \n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#eda\">&nbsp;&nbsp;&nbsp;&nbsp;2.EDA<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#model\">&nbsp;&nbsp;&nbsp;&nbsp;3.Model Building<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#results\">&nbsp;&nbsp;&nbsp;&nbsp;4.Conclusion and Take Away<\/a><\/h3>\n\n---","cf1a9203":"<a id = \"OV\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EEE8AA; border-radius:6px; font-weight: bold; font-family:Garamond; font-size:26px; color:#808080; \">Overview<\/span><\/h1>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">About Dataset&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> \n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nThere are 2 similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\nThe `test.csv` dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">List of Attributes&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>\n\n* `survival`\n* `pclass`\n* `sex`\n* `Age`\n* `sibsp`\n* `parch`\n* `ticket`\n* `fare`\n* `cabin`\n* `embarked`","ec0ebc0d":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the learning rate =0.01 and momentum=0.8 achieved the best result of about 76.6% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","50b376f2":"<a id = \"eda\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EEE8AA; border-radius:6px; font-weight: bold; font-family:Garamond; font-size:26px; color:#808080; \">EDA<\/span><\/h1>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Univariate Analysis&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> \n\n\nWe will use countplot to create the univariate count distribution plot of all categorical variables and numerical variables.\n","d26c6384":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Imputation usimg KNN Imputer&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","519d63a0":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the weight init=lecun_uniform achieved the best result of about 80.35% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","cf3cf91e":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Tune Batch Size and Number of Epochs&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","9b0b28b5":"<h1>KNN Imputer Data Transform<\/h1>\n\nKNNImputer is a data transform that is first configured based on the method used to estimate the missing values.\n\nThe default distance measure is a Euclidean distance measure that is NaN aware, e.g. will not include NaN values when calculating the distance between members of the training dataset. This is set via the \u201cmetric\u201d argument.\n\nThe number of neighbors is set to five by default and can be configured by the \u201cn_neighbors\u201d argument.\n\nFinally, the distance measure can be weighed proportional to the distance between instances (rows), although this is set to a uniform weighting by default, controlled via the \u201cweights\u201d argument.","3e21aea0":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the number of neurons=5 achieved the best result of about 79.12% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>","5cf660b7":"<h4 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: green;\">We can see that the drop_out=0.1 and weight_constraint=1 achieved the best result of about 79.5% accuracy.&nbsp;&nbsp;&nbsp;&nbsp;<\/h4>"}}