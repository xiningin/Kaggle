{"cell_type":{"8044fc13":"code","5df44848":"code","d4830d82":"code","d3eec137":"code","8ad819d7":"code","72796bf8":"code","1360ce41":"code","c243e108":"code","a7dc0e9c":"code","7c0d46c6":"code","5aeadd09":"code","d6855ae9":"code","4d9dbf0c":"code","ee0991d2":"code","a600de25":"code","9cd2461c":"code","62ea79a5":"code","970376ad":"code","0a4aec00":"code","f7dd2b2d":"code","943ecc86":"code","aca4332a":"code","eb2d415e":"code","e77c1f51":"code","6f3dbe07":"code","043c479f":"code","c364a837":"code","6683d1cb":"code","93f9a524":"code","9b975d75":"markdown","9eade9e8":"markdown","36612604":"markdown","0cc2c628":"markdown","d0d3c164":"markdown","742a83dc":"markdown","8217c07b":"markdown","4d8f5e22":"markdown","b6145dd6":"markdown","4c2b0ce8":"markdown","283b1271":"markdown","772ed0bf":"markdown","30436d6b":"markdown","a710586b":"markdown","92e99df7":"markdown","4f713773":"markdown","0c10bb60":"markdown"},"source":{"8044fc13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5df44848":"path = '\/kaggle\/input\/landmark-recognition-2021\/'\nos.listdir(path)","d4830d82":"train_data = pd.read_csv(path+'train.csv')\ntrain_data.head()","d3eec137":"len(train_data['landmark_id'].unique())","8ad819d7":"def plot_examples(landmark_id=1):\n    \"\"\" Plot 5 examples of images with the same landmark_id \"\"\"\n    \n    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = train_data[train_data['landmark_id']==landmark_id].index[i]\n        image_id = train_data.loc[idx, 'id']\n        file = image_id+'.jpg'\n        subpath = '\/'.join([char for char in image_id[0:3]])\n        img = cv2.imread(path+'train\/'+subpath+'\/'+file)\n        axs[i].imshow(img)\n        axs[i].set_title('landmark_id: '+str(landmark_id))\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        print(path+'train\/'+subpath+'\/'+file)","72796bf8":"plot_examples(landmark_id=7)","1360ce41":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.layers import Flatten, Input\nfrom tensorflow.keras.preprocessing import image","c243e108":"new_path = '..\/input\/resnet50' \nos.listdir(new_path)","a7dc0e9c":"base_model = ResNet50(weights='..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', pooling=max, include_top = False)\ninput = Input(shape=(100,100,3),name = 'image_input')\nx = base_model(input)\nx = Flatten()(x)\nmodel = Model(inputs=input, outputs=x)","7c0d46c6":"img_path = '\/kaggle\/input\/landmark-recognition-2021\/train\/5\/9\/7\/597353dfbb3df649.jpg'\nimg = image.load_img(img_path, target_size=(100, 100))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)\nfeatures_reduce =  features.squeeze()\nprint(features_reduce.size)","5aeadd09":"def obtain_features(landmark_id=1):\n    \"\"\" Obtain features of 5 examples of images with the same landmark_id \"\"\"\n    \n    feature_vals = []\n    for i in range(5):\n        try:\n            idx = train_data[train_data['landmark_id']==landmark_id].index[i]\n            image_id = train_data.loc[idx, 'id']\n            file = image_id+'.jpg'\n            subpath = '\/'.join([char for char in image_id[0:3]])\n            img = cv2.imread(path+'train\/'+subpath+'\/'+file)\n            #print(path+'train\/'+subpath+'\/'+file)\n            img_path = path+'train\/'+subpath+'\/'+file\n            img = image.load_img(img_path, target_size=(100, 100))\n            x = image.img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            x = preprocess_input(x)\n            features = model.predict(x)\n            features_reduce =  features.squeeze()\n            feature_vals.append(features_reduce)\n        except:\n            pass\n    try:\n        return sum(feature_vals)\/len(feature_vals)\n    except:\n        return None\n    ","d6855ae9":"feature_vals = obtain_features(landmark_id=1)\nprint(feature_vals)","4d9dbf0c":"no_of_landmarks = 100\nlandmark_ids = train_data['landmark_id'].unique()\nprint(landmark_ids[:no_of_landmarks])","ee0991d2":"features_landmarks = []\nfor i in range(no_of_landmarks):\n    if i%10 == 0:\n        print(i, end=',')\n    landmark = landmark_ids[i]\n    features_landmarks.append(obtain_features(landmark_id=landmark))\n    ","a600de25":"print(features_landmarks[0].shape)","9cd2461c":"features_landmarks = np.array(features_landmarks)\nprint(features_landmarks.shape)","62ea79a5":"from tensorflow.keras import Input, Model, layers\n\nlatent_dim = 10\n\nencoder_inputs = Input(shape=(32768,))\nx = layers.Dense(4000, activation=\"relu\")(encoder_inputs)\nx = layers.Dense(100, activation=\"relu\")(x)\nz = layers.Dense(latent_dim, name=\"z_mean\")(x)\nencoder = Model(encoder_inputs, z, name=\"encoder\")\nencoder.summary()","970376ad":"latent_inputs = Input(shape=(latent_dim,))\nx = layers.Dense(100, activation=\"relu\")(latent_inputs)\nx = layers.Dense(400, activation=\"relu\")(x)\ndecoder_outputs = layers.Dense(32768, activation=\"relu\")(x)\ndecoder = Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","0a4aec00":"latent_dim = 10\n\nclass Autoencoder(Model):\n  def __init__(self, latent_dim):\n    super(Autoencoder, self).__init__()\n    self.latent_dim = latent_dim   \n    self.encoder = encoder\n    self.decoder = decoder\n\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded\n\nautoencoder = Autoencoder(latent_dim)","f7dd2b2d":"from tensorflow.keras import metrics, losses\n\nautoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","943ecc86":"autoencoder.fit(features_landmarks, features_landmarks,\n                epochs=30,\n                shuffle=True)","aca4332a":"'''test_landmark = 36\ntest_index = 2\nidx = train_data[train_data['landmark_id']==test_landmark].index[test_index]\nimage_id = train_data.loc[idx, 'id']\nfile = image_id+'.jpg'\nsubpath = '\/'.join([char for char in image_id[0:3]])\nimg = cv2.imread(path+'train\/'+subpath+'\/'+file)\n#print(path+'train\/'+subpath+'\/'+file)\nimg_path = path+'train\/'+subpath+'\/'+file\nimg = image.load_img(img_path, target_size=(100, 100))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nfeatures = model.predict(x)\nfeatures_reduce =  np.array(features.squeeze())\nfeatures_reduce =  np.reshape(features_reduce, (1,32768))\nencoded_img = autoencoder.encoder(features_reduce).numpy()\nprint(encoded_img)'''","eb2d415e":"encoded_features = []\ni = 0\nfor elem in features_landmarks:\n    if i % 100 == 0:\n        print(i, end=',')\n    elem =  np.reshape(elem, (1,32768))\n    encoded_val = autoencoder.encoder(elem).numpy()\n    encoded_features.append(encoded_val[0])\n    i += 1","e77c1f51":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier(random_state=1)\n\n# Fit the model\ndecision_tree.fit(encoded_features, landmark_ids[:no_of_landmarks])","6f3dbe07":"'''test_landmark = 36\ntest_index = 2\nidx = train_data[train_data['landmark_id']==test_landmark].index[test_index]\nimage_id = train_data.loc[idx, 'id']\nfile = image_id+'.jpg'\nsubpath = '\/'.join([char for char in image_id[0:3]])\nimg = cv2.imread(path+'train\/'+subpath+'\/'+file)\n#print(path+'train\/'+subpath+'\/'+file)\nimg_path = path+'train\/'+subpath+'\/'+file\nimg = image.load_img(img_path, target_size=(100, 100))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nfeatures = model.predict(x)\nfeatures_reduce =  features.squeeze()\nfeatures_reduce =  np.reshape(features_reduce, (1,32768))\nencoded_img = autoencoder.encoder(features_reduce).numpy()\npredictions = decision_tree.predict([encoded_img[0]])\nprint(predictions)'''","043c479f":"'''test_img = '..\/input\/landmark-recognition-2021\/test\/9\/0\/0\/900bb54db718a992.jpg'\nimg = image.load_img(img_path, target_size=(100, 100))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)\nfeatures_reduce =  features.squeeze()\n\nfeatures_reduce =  np.reshape(features_reduce, (1,32768))\nencoded_img = autoencoder.encoder(features_reduce).numpy()\npredictions = decision_tree.predict([encoded_img[0]])\nprint(predictions)'''","c364a837":"test_data = pd.read_csv(path+'sample_submission.csv')\ntest_data.head()","6683d1cb":"    predictions = []\n    for i in range(len(test_data)):\n        try:\n            if i%100==0:\n                print(i, end=',')\n            image_id = test_data.loc[i, 'id']\n            file = image_id+'.jpg'\n            subpath = '\/'.join([char for char in image_id[0:3]])\n            img = cv2.imread(path+'test\/'+subpath+'\/'+file)\n            #print(path+'test\/'+subpath+'\/'+file)\n            img_path = path+'test\/'+subpath+'\/'+file\n            img = image.load_img(img_path, target_size=(100, 100))\n            x = image.img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            x = preprocess_input(x)\n            features = model.predict(x)\n            features_reduce =  features.squeeze()\n            features_reduce =  np.reshape(features_reduce, (1,32768))\n            encoded_img = autoencoder.encoder(features_reduce).numpy()\n        except:\n            pass\n        pred = decision_tree.predict([encoded_img[0]])\n        #print(prediction)\n        predictions.append(str(pred[0]) + ' 1.00000000')","93f9a524":"output = pd.DataFrame({'id': test_data.id,\n                       'landmarks': predictions})\n\noutput.head()\noutput.to_csv('submission.csv', index=False)","9b975d75":"## Function to obtain ResNet50 image features for each landmark label\n\nTake average feature value of first 5 (if present) images","9eade9e8":"## Load test data in submission format","36612604":"## Convert to submission format","0cc2c628":"# Landmark recognition with few-shot learning + ResNet50 + Decision tree\n## Loading essential packages","d0d3c164":"## Code to check prediction for individual predicted labels\n\n### Check within training data (sanity check)","742a83dc":"## Obtain predictions of test data","8217c07b":"## Autoencoder to compress feature vector","4d8f5e22":"## Fitting a decision tree on the landmark labels and corresponding average features","b6145dd6":"### Looking at the number of unique landmarks","4c2b0ce8":"## Loading data","283b1271":"### Seeing the labels of the first N landmarks","772ed0bf":"### Props to https:\/\/www.kaggle.com\/michaelscheinfeilda\/landmark-recognition-2021-starter for the plot function","30436d6b":"Example of extracting ResNet50 features from a sample image","a710586b":"## Loading ResNet50 model\n\nSelecting 100x100x3 as the dimension for the images to be used","92e99df7":"### Obtaining features for the first N landmarks","4f713773":"### Check within test data","0c10bb60":"## Loading necessary modules"}}