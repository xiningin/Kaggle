{"cell_type":{"5d41c120":"code","b403c94a":"code","691206ad":"code","b8dd53fa":"code","a1f082d7":"code","4b1fadaf":"code","69093558":"code","272bd78f":"code","9722a3ef":"code","14a4fcc9":"code","8f25e5cf":"code","3db7dd96":"code","5bf4eec4":"code","66948e3d":"code","3d5b6443":"code","02c142ae":"code","aa68dc53":"code","7092f7cc":"code","e5b8dcc8":"code","644b3d44":"code","b8dc8457":"code","b6f9f9ee":"code","3dc573ab":"code","6cb7d715":"code","da424a3e":"code","a0002712":"code","f48e0e0a":"code","37e5f278":"code","6e6c77e1":"code","99e51356":"code","5e5457db":"code","96c84ff0":"code","253972f9":"code","b86b7667":"code","64796077":"code","e1fd2feb":"code","e068eced":"code","c3f8cda7":"code","032dfea6":"code","17c880ac":"code","74df5a47":"code","e561a235":"code","13e5b600":"code","2ad910b9":"code","57e1233e":"code","cf0e4f79":"code","c57f22e2":"code","f1bdbe0d":"code","312f91ca":"code","64130def":"code","d0d0ed5a":"code","9627d704":"code","d227eb7a":"code","c5394ef0":"code","7fdce2f1":"code","e0a993c7":"code","1cfc2cae":"code","5a21d244":"code","a7c07b06":"code","5ef07287":"code","c029cbf2":"code","83eb98c1":"code","b0b51b80":"code","2a55cdba":"code","316b140d":"code","cf8f9892":"code","6af04d5c":"code","75ba35e1":"code","57a9f61d":"code","c1871839":"code","4b1138e6":"code","b12e6d53":"code","ebdc4640":"code","00daba1e":"markdown"},"source":{"5d41c120":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn import preprocessing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn.metrics import r2_score\nfrom random import seed\nfrom random import randrange\nimport timeit\nimport tensorflow as tf\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score","b403c94a":"%load_ext autoreload\n%autoreload \n%reload_ext autoreload\nimport utility_script_multi_sklearn as us","691206ad":"SNOMED_scored=pd.read_csv(\"..\/input\/featurized-physionet-challenge-2020-data\/SNOMED_mappings_scored.csv\", sep=\";\")\nSNOMED_unscored=pd.read_csv(\"..\/input\/featurized-physionet-challenge-2020-data\/SNOMED_mappings_unscored.csv\", sep=\";\")","b8dd53fa":"data = pd.read_csv('..\/input\/featurized-physionet-challenge-2020-data\/ecg_data_with_labels.csv')","a1f082d7":"conf_weights = pd.read_csv(\"..\/input\/featurized-physionet-challenge-2020-data\/weights.csv\", sep=\",\", header= 0, index_col=0 )","4b1fadaf":"data.head()","69093558":"print(np.where(data.iloc[:,:-1].isna()))\nprint(data.index[np.isinf(data.iloc[:,:-1]).any(1)])\n#print(data.columns.to_series()[np.isinf(data.iloc[:,:-1]).any()])","272bd78f":"data.shape","9722a3ef":"data = data.dropna()","14a4fcc9":"#data = data.replace([np.inf, -np.inf], 0)","8f25e5cf":"data.shape","3db7dd96":"print(np.where(data.iloc[:,1:-1].isna()))\nprint(data.index[np.isinf(data.iloc[:,1:-1]).any(1)])\n#print(data.columns.to_series()[np.isinf(data.iloc[:,1:-1]).any()])","5bf4eec4":"y_data = data['labels']","66948e3d":"X_data = data.iloc[:,1:-1]","3d5b6443":"data.iloc[:,1:]","02c142ae":"import seaborn as sns\nplt.figure(figsize=(30,30))\ncor = data.iloc[:,1:].corr()\nsns.heatmap(cor, cmap=\"rocket_r\", annot=True,cbar=False, annot_kws={\"size\": 3})\nplt.show()","aa68dc53":"def making_undef_class(labels):\n    df_labels = pd.DataFrame(labels)\n    for i in range(len(SNOMED_unscored.iloc[0:,1])):\n        df_labels.replace(to_replace=str(SNOMED_unscored.iloc[i,1]), inplace=True ,value=\"undefined class\", regex=True)\n    return df_labels\n\n  \ndf_y = making_undef_class(y_data)","7092f7cc":"y_data.unique()","e5b8dcc8":"from sklearn.preprocessing import MultiLabelBinarizer\none_hot = MultiLabelBinarizer()\ny=one_hot.fit_transform(df_y['labels'].str.split(pat=','))\nprint(one_hot.classes_)\nprint(\"classes: {}\".format(y.shape[1]))","644b3d44":"y = np.delete(y, -1, axis=1)","b8dc8457":"norsk_liste = ['pacing-rytme', 'forlenget qt-intervall', 'atrieflimmer','atrieflutter','venstre grenblokk','unormal Q-b\u00f8lge','unormal T-b\u00f8lge','forlenget PR-intervall', 'ventrikul\u00e6re premature slag','lav QRS-spenning','1.grads AV-blokk','prematur atriell kontraksjon',\n               'venstre akse avvik','sinusbradykardi','bradykardi','sinus rytme', 'sinus takykardi', 'prematur ventrikul\u00e6r kontraksjon','sinusarytmi','venstre fremre fascikul\u00e6rblokk','h\u00f8yre akse avvik','h\u00f8yre grenblokk','invertert T-b\u00f8lge','supraventrikul\u00e6re premature slag',\n               'uspesifikk intraventrikul\u00e6r ledningsforstyrrelse','ufullstendig h\u00f8yre grenblokk','komplett h\u00f8yre grenblokk']","b6f9f9ee":"us.plot_classes(one_hot.classes_[0:-1],SNOMED_scored, y)","3dc573ab":"#@title Transform our One Hot encoded multilabel output to a new type of label where all can be represented by a number:\nfrom sklearn.preprocessing import LabelEncoder\n\ndef get_new_labels(y):\n    y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y])\n    return y_new\n\ny_temp_new = get_new_labels(y)\nprint(\"Total number of unique combinations of diagnosis: {}\".format(len(np.unique(y_temp_new))))","6cb7d715":"us.plot_classes_2(one_hot.classes_[0:-1],y,SNOMED_scored,norsk_liste)","da424a3e":"one_hot.classes_[0:-1][26]","a0002712":"#test_index = []\n#for i in range(len(y.T)):\n#    test_index.append(np.random.choice(np.where(y.T[i] == 1)[0],size = 110, replace=False))\n#test_index = np.unique(np.array(test_index).ravel())","f48e0e0a":"#X_train_val = X_data.drop(X_data.iloc[test_index].index)\n#y_train_val = np.delete(y,test_index,axis=0)\n#X_test = X_data.iloc[test_index]\n#y_test = y[test_index]","37e5f278":"#print(X_train_val.shape)\n#print(y_train_val.shape)\n#print(X_test.shape)\n#print(y_test.shape)","6e6c77e1":"#us.plot_classes_2(one_hot.classes_[0:-1],y_test,SNOMED_scored,norsk_liste)","99e51356":"#us.plot_classes_2(one_hot.classes_[0:-1],y_train_val,SNOMED_scored,norsk_liste)","5e5457db":"#@title Transform our One Hot encoded multilabel output to a new type of label where all can be represented by a number:\nfrom sklearn.preprocessing import LabelEncoder\n\ndef get_new_labels(y):\n    y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y])\n    return y_new\n\ny_new = get_new_labels(y)\nprint(\"Total number of unique combinations of diagnosis in train set: {}\".format(len(np.unique(y_new))))","96c84ff0":"#@title K-fold, 10 splits, Shuffle=True and random_state = 42. The distribution of Training and Val data in each fold is now:\nfrom sklearn.model_selection import StratifiedKFold\nfolds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(y,y_new))\nprint(\"Training split: {}\".format(len(folds[0][0])))\nprint(\"Validation split: {}\".format(len(folds[0][1])))","253972f9":"#@title The distribution of diagnosis in each Fold:\nX_axis_labels=one_hot.classes_[0:-1]\nplt.figure(figsize=(20,100))\nh=1\nfor i in range(len(folds)):\n    plt.subplot(10,2,h)\n    plt.subplots_adjust(hspace=1.0)\n    plt.bar(x= X_axis_labels, height=y[folds[i][0]].sum(axis=0))\n    plt.title(\"Distribution of Diagnosis - Training set - Fold {}\".format(i+1) ,fontsize=\"20\", color = \"black\")\n    plt.tick_params(axis=\"both\", colors = \"black\")\n    plt.xticks(rotation=90, fontsize=10)\n    plt.yticks(fontsize = 10)\n    #plt.xlabel(\"Diagnosis\", color = \"white\")\n    plt.ylabel(\"Count\", color = \"black\")\n    h=h+1\n    plt.subplot(10,2,h)\n    plt.subplots_adjust(hspace=1.0)\n    plt.bar(x= X_axis_labels, height=y[folds[i][1]].sum(axis=0))\n    plt.title(\"Distribution of Diagnosis - Validation set - Fold {}\".format(i+1) ,fontsize=\"20\", color = \"black\")\n    plt.tick_params(axis=\"both\", colors = \"black\")\n    #plt.xlabel(\"Diagnosis\", color = \"white\")\n    plt.ylabel(\"Count\", color = \"black\")\n    plt.xticks(rotation=90, fontsize=10)\n    plt.yticks(fontsize = 10)\n    h=h+1","b86b7667":"!pip install scikit-multilearn","64796077":"import seaborn as sns\nconf_weights.columns = SNOMED_scored.iloc[:,0]\nconf_weights.index = SNOMED_scored.iloc[:,0]\n\nconf_weights = pd.DataFrame(conf_weights, columns=SNOMED_scored.iloc[:,0], index = SNOMED_scored.iloc[:,0])\n\nconf_weights.columns=SNOMED_scored.iloc[:,2]\nconf_weights.index = SNOMED_scored.iloc[:,2]\nconf_weights.index.name = 'Virkelig'\nconf_weights.columns.name = 'Predikert'\n\nplt.figure(figsize = (12,10))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(conf_weights, cmap=\"rocket_r\", annot=True,cbar=False, annot_kws={\"size\": 10})# font size\nplt.savefig(\".\/confmatrix_weights.png\",dpi=200)","e1fd2feb":"!pip install arff","e068eced":"my_cluster = []\nfor i in range(len(y.T)):\n    my_cluster.append(np.unique(np.where(y[np.where(y.T[i]==1)])[1]))","c3f8cda7":"from skmultilearn.ensemble import LabelSpacePartitioningClassifier\nfrom skmultilearn.cluster import FixedLabelSpaceClusterer\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nclassifier_MLP = LabelSpacePartitioningClassifier(\n    classifier = LabelPowerset(\n        classifier= MLPClassifier(solver='adam', alpha=0.0001, hidden_layer_sizes=(100,100,100,100,100), verbose=1, max_iter=10, batch_size=100, learning_rate='adaptive', activation='relu',learning_rate_init=0.0001),\n        require_dense = [False, True]\n    ),\n    require_dense = [True, True],\n    clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n)","032dfea6":"from skmultilearn.problem_transform import ClassifierChain\nfrom skmultilearn.ensemble import LabelSpacePartitioningClassifier\nfrom skmultilearn.cluster import FixedLabelSpaceClusterer\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skmultilearn.ensemble import MajorityVotingClassifier\n\nclassifier_cluster_chain = LabelSpacePartitioningClassifier(\n    classifier = ClassifierChain(\n        classifier= RandomForestClassifier(n_jobs=-1,n_estimators=3, verbose=1,class_weight=None),\n        require_dense = [False, True]\n    ),\n    require_dense = [True, True],\n    clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n)","17c880ac":"from skmultilearn.ensemble import LabelSpacePartitioningClassifier\nfrom skmultilearn.cluster import FixedLabelSpaceClusterer\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skmultilearn.ensemble import MajorityVotingClassifier\n\nclassifier_rf_lb_cluster = LabelSpacePartitioningClassifier(\n    classifier = LabelPowerset(\n        classifier= RandomForestClassifier(n_jobs=-1,n_estimators=5, verbose=1),\n        require_dense = [False, True]\n    ),\n    require_dense = [True, True],\n    clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n)","74df5a47":"from skmultilearn.ensemble import LabelSpacePartitioningClassifier\nfrom skmultilearn.cluster import FixedLabelSpaceClusterer\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skmultilearn.ensemble import MajorityVotingClassifier\n\nclassifier_rf_lb_cluster_bal = LabelSpacePartitioningClassifier(\n    classifier = LabelPowerset(\n        classifier= RandomForestClassifier(n_jobs=-1,n_estimators=3, verbose=1, class_weight=\"balanced\"),\n        require_dense = [False, True]\n    ),\n    require_dense = [True, True],\n    clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n)\n# Score : 0.4961250109543675","e561a235":"from sklearn.neural_network import MLPClassifier\nclf_mlp = MLPClassifier(solver='adam', alpha=0.0001, hidden_layer_sizes=(200,200,200,200,200), verbose=1, max_iter=10, batch_size=100, learning_rate='adaptive', activation='relu',learning_rate_init=0.0001)","13e5b600":"val_res = np.zeros(shape=(5,10))\ntraining_res = np.zeros(shape=(5,10))\nj = 0\n\nfor train_index, val_index in folds:\n    \n    X_train, X_val = np.asarray(X_data)[train_index], np.asarray(X_data)[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n\n\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train_scaled = scaler.transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    print(\"Making a cluster\")\n    my_cluster = []\n    for i in range(len(y_train.T)):\n        my_cluster.append(np.unique(np.where(y_train[np.where(y_train.T[i]==1)])[1]))\n    print(\"Making the model\")\n    classifier = LabelSpacePartitioningClassifier(\n        classifier = ClassifierChain(\n            classifier= RandomForestClassifier(n_jobs=-1,n_estimators=3, verbose=1),\n            require_dense = [False, True]\n        ),\n        require_dense = [True, True],\n        clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n    )\n\n    classifier.fit(X_train_scaled,y_train)\n    y_pred_val = classifier.predict(X_val_scaled)\n    y_pred_train = classifier.predict(X_train_scaled)\n\n    y_pred_val = y_pred_val.todense()\n    y_pred_val = np.asarray(y_pred_val)\n\n    y_pred_train = y_pred_train.todense()\n    y_pred_train = np.asarray(y_pred_train)\n\n    val_res[0,j] = us.compute_beta_measures(y_val,y_pred_val,2)[0]\n    val_res[1,j] = us.compute_beta_measures(y_val,y_pred_val,2)[1]\n    val_res[2,j] = us.compute_f_measure(y_val,y_pred_val)\n    val_res[3,j] = us.compute_accuracy(y_val,y_pred_val)\n    val_res[4,j] = us.compute_challenge_metric_for_opt(y_val,y_pred_val)\n    training_res[0,j] = us.compute_beta_measures(y_train,y_pred_train,2)[0]\n    training_res[1,j] = us.compute_beta_measures(y_train,y_pred_train,2)[1]\n    training_res[2,j] = us.compute_f_measure(y_train,y_pred_train)\n    training_res[3,j] = us.compute_accuracy(y_train,y_pred_train)\n    training_res[4,j] = us.compute_challenge_metric_for_opt(y_train,y_pred_train)\n    j = j+1\n\n\n\n    print(\"{}-fold cross val:\".format(j))\n    print(\"F2-score:\",us.compute_beta_measures(y_val,y_pred_val,2)[0])\n    print(\"G2-score:\",us.compute_beta_measures(y_val,y_pred_val,2)[1])\n    print(\"F-measure:\",us.compute_f_measure(y_val,y_pred_val))\n    print(\"Accuracy:\",us.compute_accuracy(y_val,y_pred_val))\n    print(\"Challenge prediction:\", us.compute_challenge_metric_for_opt(y_val,y_pred_val))\n    print(\"Challenge prediction (train data):\", us.compute_challenge_metric_for_opt(y_train,y_pred_train))\n    \nvaliderings_resultat = pd.DataFrame(val_res)\ntrenings_resultat = pd.DataFrame(training_res)\nvaliderings_resultat.to_csv(\"valideringsresultat_forest_chain_cluster.csv\")\ntrenings_resultat.to_csv(\"treningsresultat_forest_chain_cluster.csv\")","2ad910b9":"'''\ntest_res = np.zeros(shape=(10,5))\ntraining_res = np.zeros(shape=(10,5))\n\nn_bootstraps = 10\n\nfor j in range(n_bootstraps):\n    test_index = []\n    for i in range(len(y.T)):\n        test_index.append(np.random.choice(np.where(y.T[i] == 1)[0],size = 100, replace=False))\n    test_index = np.unique(np.array(test_index).ravel())\n\n    X_train_val = X_data.drop(X_data.iloc[test_index].index)\n    y_train_val = np.delete(y,test_index,axis=0)\n    X_test = X_data.iloc[test_index]\n    y_test = y[test_index]\n\n    scaler = StandardScaler()\n    scaler.fit(X_train_val)\n    X_train_val_scaled = scaler.transform(X_train_val)\n    X_test_scaled = scaler.transform(X_test)\n    print(\"Making a cluster\")\n    my_cluster = []\n    for i in range(len(y_train_val.T)):\n        my_cluster.append(np.unique(np.where(y_train_val[np.where(y_train_val.T[i]==1)])[1]))\n    print(\"Making the model\")\n    classifier = LabelSpacePartitioningClassifier(\n        classifier = ClassifierChain(\n            classifier= RandomForestClassifier(n_jobs=-1,n_estimators=5, verbose=1,class_weight=None),\n            require_dense = [False, True]\n            ),\n        require_dense = [True, True],\n        clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n        )\n\n    classifier.fit(X_train_val_scaled,y_train_val)\n    y_pred_test = classifier.predict(X_test_scaled)\n    y_pred_train = classifier.predict(X_train_val_scaled)\n\n    y_pred_test = y_pred_test.todense()\n    y_pred_test = np.asarray(y_pred_test)\n\n    y_pred_train = y_pred_train.todense()\n    y_pred_train = np.asarray(y_pred_train)\n\n    test_res[0:j] = compute_beta_measures(y_test,y_pred_test,2)[0]\n    test_res[1:j] = compute_beta_measures(y_test,y_pred_test,2)[1]\n    test_res[2:j] = compute_f_measure(y_test,y_pred_test)\n    test_res[3:j] = compute_accuracy(y_test,y_pred_test)\n    test_res[4:j] = compute_challenge_metric_for_opt(y_test,y_pred_test)\n    training_res[0:j] = compute_beta_measures(y_train_val,y_pred_train,2)[0]\n    training_res[1:j] = compute_beta_measures(y_train_val,y_pred_train,2)[1]\n    training_res[2:j] = compute_f_measure(y_train_val,y_pred_train)\n    training_res[3:j] = compute_accuracy(y_train_val,y_pred_train)\n    training_res[4:j] = compute_challenge_metric_for_opt(y_train_val,y_pred_train)\n\n\n\n    print(\"{} bootstrap:\".format(j))\n    print(\"F2-score:\",compute_beta_measures(y_test,y_pred_test,2)[0])\n    print(\"G2-score:\",compute_beta_measures(y_test,y_pred_test,2)[1])\n    print(\"F-measure:\",compute_f_measure(y_test,y_pred_test))\n    print(\"Accuracy:\",compute_accuracy(y_test,y_pred_test))\n    print(\"Challenge prediction:\", compute_challenge_metric_for_opt(y_test,y_pred_test))\n    print(\"Challenge prediction (train data):\", compute_challenge_metric_for_opt(y_train_val,y_pred_train))\n\n'''","57e1233e":"\nclassifier = LabelSpacePartitioningClassifier(\n    classifier = ClassifierChain(\n        classifier= RandomForestClassifier(n_jobs=-1,n_estimators=3, verbose=1,class_weight=None),\n        require_dense = [False, True]\n        ),\n    require_dense = [True, True],\n    clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n    )","cf0e4f79":"'''\nwith tpu_strategy.scope():\n    classifier = LabelSpacePartitioningClassifier(\n        classifier = ClassifierChain(\n            classifier= RandomForestClassifier(n_jobs=-1,n_estimators=5, verbose=1,class_weight=None),\n            require_dense = [False, True]\n            ),\n        require_dense = [True, True],\n        clusterer = FixedLabelSpaceClusterer(clusters=my_cluster)\n        )\n'''","c57f22e2":"scaler = StandardScaler()\nscaler.fit(X_data.iloc[folds[0][0]])\nX_train_scaled = scaler.transform(X_data.iloc[folds[0][0]])\nX_test_scaled = scaler.transform(X_data.iloc[folds[0][1]])\n\nclassifier.fit(X_train_scaled,y[folds[0][0]])","f1bdbe0d":"y_pred = classifier.predict(X_test_scaled)","312f91ca":"y_pred = y_pred.todense()\ny_pred = np.asarray(y_pred)","64130def":"y_test = y[folds[0][1]]","d0d0ed5a":"print(np.argmax(y_pred, axis=1)[0:20])\nprint(np.argmax(y_test,axis=1)[0:20])","9627d704":"us.compute_challenge_metric_for_opt(y_test,y_pred)","d227eb7a":"print(\"F2-score:\",us.compute_beta_measures(y_test,y_pred,2)[0])\nprint(\"G2-score:\",us.compute_beta_measures(y_test,y_pred,2)[1])\nprint(\"F2-score (SKLearn):\",fbeta_score(y_test,y_pred, average='macro', beta=2.0))\nprint(\"F-measure:\",us.compute_f_measure(y_test,y_pred))\nprint(\"F1-score (SKlearn):\",f1_score(y_test, y_pred, average='macro'))\nprint(\"Challenge prediction:\", us.compute_challenge_metric_for_opt(y_test,y_pred))\nprint(\"Accuracy:\",us.compute_accuracy(y_test,y_pred))\nprint(\"Accuracy (SKlearn):\",accuracy_score(y_test,y_pred))","c5394ef0":"fbeta_score(y_test,y_pred, average='macro', beta=2.0)","7fdce2f1":"conf_matrix = us.compute_modified_confusion_matrix_nonorm(y_test,y_pred)\n\nnorm_conf_matrix = np.zeros((conf_matrix.shape[0], conf_matrix.shape[1]))\n\nfor i in range(conf_matrix.shape[0]):\n    norm_conf_matrix[i]=conf_matrix[i]\/conf_matrix[i].sum()\n\ndf_conf_matrix = pd.DataFrame(norm_conf_matrix, columns=one_hot.classes_[:-1], index = one_hot.classes_[:-1])\ndf_conf_matrix.index.name = 'y_true'\ndf_conf_matrix.columns.name = 'y_pred'\n\n\nimport seaborn as sns\nplt.figure(figsize = (16,10))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_conf_matrix, cmap=\"rocket_r\", annot=True,annot_kws={\"size\": 10}, fmt=\".2f\", cbar=False)\nplt.title(\"ECG data\", fontsize = 40, color= \"black\")\nplt.xlabel(\"y predicted\",fontsize=30, color= \"black\")\nplt.ylabel(\"y true\",fontsize = 30, color= \"black\")\nplt.yticks(fontsize=20, rotation=0, color= \"black\")\nplt.xticks(fontsize=20, rotation=90, color= \"black\")\nplt.savefig(\"ensemble_model_conf_matrix.png\", dpi=300)\nplt.show()","e0a993c7":"from joblib import dump\ndump(classifier, 'balanced_rand_forest_cluster.joblib') ","1cfc2cae":"'''\nfrom joblib import load\nclf_new = load('\/content\/drive\/My Drive\/logs\/clf_Chain_rand_forest.joblib') \n'''","5a21d244":"#y_pred = clf_new.predict(X_test_scaled)","a7c07b06":"!pip install lime","5ef07287":"import lime\nimport lime.lime_tabular\n","c029cbf2":"FeatureNames = ['gender','age','R HR STD','R HR median','R HR min', 'R HR max','R HR mean','RMSSD','R amp II std','R amp II min','R amp II min_2', 'R amp leads I', 'R amp leads II', 'R amp lead III', \n                'R amp lead aVR','R amp lead aVL','R amp lead aVF', 'R amp V1','R amp V2','R amp V3','R amp V4','R amp V5','R amp V6','p_offset_std','p_offset_median','p_offset_min','p_offset_max',\n                'mean_p_offset','p_onsets_std','p_onsets_median','p_onsets_min','p_onsets_max','mean_p_onsets','ECG_baseline','p_rate_std','p_rate_median','p_rate_min','p_rate_max','mean_p_rate', \n                'P amp leads I', 'P amp leads II', 'P amp lead III', 'P amp lead aVR','P amp lead aVL','P amp lead aVF', 'P amp V1','P amp V2','P amp V3','P amp V4','P amp V5','P amp V6','q_rate_std',\n                'q_rate_median','q_rate_min','q_rate_max','mean_q_rate','Q amp leads I', 'Q amp leads II', 'Q amp lead III', 'Q amp lead aVR','Q amp lead aVL','Q amp lead aVF', 'Q amp V1','Q amp V2',\n                'Q amp V3','Q amp V4','Q amp V5','Q amp V6','s_rate_std','s_rate_median','s_rate_min','s_rate_max','mean_s_rate','S amp leads I', 'S amp leads II', 'S amp lead III', 'S amp lead aVR',\n                'S amp lead aVL','S amp lead aVF', 'S amp V1','S amp V2','S amp V3','S amp V4','S amp V5','S amp V6','t_rate_std','t_rate_median','t_rate_min','t_rate_max','mean_t_rate',\n                'T amp leads I', 'T amp leads II', 'T amp lead III', 'T amp lead aVR','T amp lead aVL','T amp lead aVF', 'T amp V1','T amp V2','T amp V3','T amp V4','T amp V5','T amp V6','t_offset_std',\n                't_offset_median','t_offset_min','t_offset_max','mean_t_offset','t_onsets_std','t_onsets_median','t_onsets_min','t_onsets_max','mean_t_onsets']","83eb98c1":"explainer = lime.lime_tabular.LimeTabularExplainer(X_train_scaled,mode='classification',feature_names=FeatureNames,class_names=one_hot.classes_[:-1])","b0b51b80":"#explainer = lime.lime_tabular.LimeTabularExplainer(X_train_val_scaled,  discretize_continuous=True)","2a55cdba":"class model_wrapper:\n    # drf is the h2o distributed random forest object, the column_names is the\n    # labels of the X values\n    def __init__(self,model,column_names):\n            \n            self.model = model\n            self.column_names = column_names\n \n    def predict_proba(self,this_array):        \n        # If we have just 1 row of data we need to reshape it\n        shape_tuple = np.shape(this_array)        \n        if len(shape_tuple) == 1:\n            this_array = this_array.reshape(1, -1)\n            \n        # We convert the numpy array that Lime sends to a pandas dataframe and\n        # convert the pandas dataframe to an h2o frame\n        self.pandas_df = pd.DataFrame(data = this_array,columns = self.column_names)\n\n        # Predict with the h2o drf\n        self.predictions = self.model.predict(self.pandas_df).todense()\n        # the first column is the class labels, the rest are probabilities for\n        # each class\n        self.predictions =  np.asarray(self.predictions)\n        return self.predictions","316b140d":"#clf_wrapped_ = model_wrapper(clf_new,FeatureNames) ","cf8f9892":"classifier_wrapped_ =  model_wrapper(classifier,FeatureNames) ","6af04d5c":"one_hot.classes_[np.where(y_test[5]==1)]","75ba35e1":"#i = np.random.randint(0, X_test_scaled.shape[0])\nexp = explainer.explain_instance(X_test_scaled[5], classifier_wrapped_.predict_proba, num_features=10, top_labels=2,num_samples=5000, distance_metric='euclidean',)","57a9f61d":"print(exp.available_labels())","c1871839":"%matplotlib inline","4b1138e6":"exp.show_in_notebook(show_table=True, show_all=True)","b12e6d53":"exp.save_to_file(\"explaination.html\")","ebdc4640":"one_hot.classes_[:-1][np.argmax(y_test[1])]","00daba1e":"About 150 ECG-recordings removed"}}