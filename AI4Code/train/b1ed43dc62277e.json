{"cell_type":{"9a4ec31e":"code","531df489":"code","806d59f5":"code","886dfd8b":"code","1ba4f068":"code","6f68e9c3":"code","ca5dcd4f":"code","ab1a8f38":"code","c53de3cc":"code","0b706fb1":"code","fb482a88":"code","14aec9d7":"code","d822ec84":"code","a958f7b5":"code","db95bebf":"code","c58ba3cc":"code","012a14c8":"code","c5cc032a":"code","58343b21":"code","ebcf9de1":"code","b95f4a79":"code","33040f49":"code","ab801f9f":"markdown","9f996eb8":"markdown","f194392c":"markdown","c3471e36":"markdown","c8781596":"markdown","0ddac472":"markdown","5b9769d1":"markdown","0cb82616":"markdown","fd3dc154":"markdown","789dbc64":"markdown","e608c9c8":"markdown","af618e7e":"markdown","60ed59ff":"markdown","177e45dd":"markdown","a6a3a614":"markdown","8b58a7d1":"markdown","738d8b0a":"markdown","6ecd2074":"markdown","69aae148":"markdown","25fc3078":"markdown","abe6c891":"markdown","dc5025ac":"markdown","b8e894d0":"markdown","39fb71df":"markdown","dc75bab9":"markdown","b05751eb":"markdown","fe2a51a2":"markdown","4f0a6e50":"markdown","5f449bb8":"markdown","2facfdd4":"markdown","33f32a29":"markdown","e6308bea":"markdown","09a85283":"markdown","19cbb0b5":"markdown","8bd0a493":"markdown","58b5d542":"markdown","c72f3c7d":"markdown","dd70cef3":"markdown"},"source":{"9a4ec31e":"from IPython.display import Image\nImage(filename='\/kaggle\/input\/graph-of-model\/plot.png', width=800) ","531df489":"# import the necessary packages\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nimport numpy as np\nimport argparse\nimport cv2\nimport os\nfrom imutils import paths\n","806d59f5":"# construct the argument parser and parse the arguments\nap = argparse.ArgumentParser()\nap.add_argument(\"-d\", \"--dataset\", required=True,\n\thelp=\"path to input dataset\")\nap.add_argument(\"-o\", \"--output\", required=True,\n\thelp=\"path to output directory to store augmentation examples\")\nap.add_argument(\"-t\", \"--total\", type=int, default=100,\n\thelp=\"# of training samples to generate\")\nargs = vars(ap.parse_args())","886dfd8b":"imagePaths = list(paths.list_images(args[\"dataset\"]))\ndata = []","1ba4f068":"# loop over the image paths\nfor imagePath in imagePaths:\n\t# extract the class label from the filename\n\tlabel = imagePath.split(os.path.sep)[-2]\n\n\t# load the image, swap color channels, and resize it to be a fixed\n\t# 224x224 pixels while ignoring aspect ratio\n\timage = cv2.imread(imagePath)\n\t# update the data and labels lists, respectively\n\tdata.append(image)","6f68e9c3":"for image in data:\n\t# load the input image, convert it to a NumPy array, and then\n\t# reshape it to have an extra dimension\n\tprint(\"[INFO] loading example image...\")\n\timage = img_to_array(image)\n\timage = np.expand_dims(image, axis=0)","ca5dcd4f":"aug = ImageDataGenerator(\n\t\trotation_range=30,\n\t\tzoom_range=0.15,\n\t\twidth_shift_range=0.2,\n\t\theight_shift_range=0.2,\n\t\tshear_range=0.15,\n\t\thorizontal_flip=True,\n\t\tfill_mode=\"nearest\")\n\ttotal = 0","ab1a8f38":"# construct the actual Python generator\n\tprint(\"[INFO] generating images...\")\n\timageGen = aug.flow(image, batch_size=1, save_to_dir=args[\"output\"],\n\t\tsave_prefix=\"image\", save_format=\"jpg\")\n\t# loop over examples from our image data augmentation generator\n\tfor image in imageGen:\n\t\t# increment our counter\n\t\ttotal += 1\n\n\t\t# if we have reached the specified number of examples, break\n\t\t# from the loop\n\t\tif total == args[\"total\"]:\n\t\t\tbreak","c53de3cc":"$ python generate_images.py --dataset dataset\/covid --output generated_dataset\/covid\n$ python generate_images.py --dataset dataset\/normal --output generated_dataset\/normal","0b706fb1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport cv2\nimport os","fb482a88":"ap = argparse.ArgumentParser()\nap.add_argument(\"-d\", \"--dataset\", required=True,\n\thelp=\"path to input dataset\")\nap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n\thelp=\"path to output loss\/accuracy plot\")\nap.add_argument(\"-m\", \"--model\", type=str, default=\"covid19.model\",\n\thelp=\"path to output loss\/accuracy plot\")\nargs = vars(ap.parse_args())","14aec9d7":"INIT_LR = 1e-3\nEPOCHS = 100\nBS = 128","d822ec84":"for imagePath in imagePaths:\n\t# extract the class label from the filename\n\tlabel = imagePath.split(os.path.sep)[-2]\n\n\t# load the image, swap color channels, and resize it to be a fixed\n\t# 224x224 pixels while ignoring aspect ratio\n\timage = cv2.imread(imagePath)\n\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\timage = cv2.resize(image, (128, 128))\n\n\t# update the data and labels lists, respectively\n\tdata.append(image)\n\tlabels.append(label)","a958f7b5":"data = np.array(data) \/ 255.0\nlabels = np.array(labels)\n\n# perform one-hot encoding on the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)","db95bebf":"(trainX, testX, trainY, testY) = train_test_split(data, labels,\n\ttest_size=0.20, stratify=labels, random_state=42)\n\n# initialize the training data augmentation object\ntrainAug = ImageDataGenerator(\n\trotation_range=15,\n\tfill_mode=\"nearest\")\n\n# load the VGG16 network, ensuring the head FC layer sets are left\n# off\nbaseModel = VGG16(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(128, 128, 3)))\n","c58ba3cc":"headModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(4, 4))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False","012a14c8":"print(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n\ttrainAug.flow(trainX, trainY, batch_size=BS),\n\tsteps_per_epoch=len(trainX) \/\/ BS,\n\tvalidation_data=(testX, testY),\n\tvalidation_steps=len(testX) \/\/ BS,\n\tepochs=EPOCHS)\n\n","c5cc032a":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs,\n\ttarget_names=lb.classes_))\n\n# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(testY.argmax(axis=1), predIdxs)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) \/ total\nsensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n\n# show the confusion matrix, accuracy, sensitivity, and specificity\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","58343b21":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(args[\"plot\"])\n\n# serialize the model to disk\nprint(\"[INFO] saving COVID-19 detector model...\")\nmodel.save(args[\"model\"], save_format=\"h5\")","ebcf9de1":"$ python train_covid19.py --dataset generated_dataset","b95f4a79":"Train for 79 steps, validate on 102 samples\nEpoch 1\/100\n11\/11 [==============================] - 219s 20s\/step - loss: 0.8125 - accuracy: 0.4706 - val_loss: 0.4332 - val_accuracy: 0.7500\nEpoch 2\/100\n11\/11 [==============================] - 255s 23s\/step - loss: 0.6254 - accuracy: 0.6765 - val_loss: 0.3841 - val_accuracy: 0.7500\nEpoch 3\/100\n11\/11 [==============================] - 399s 36s\/step - loss: 0.5812 - accuracy: 0.6569 - val_loss: 0.3528 - val_accuracy: 0.9000\nEpoch 4\/100\n11\/11 [==============================] - 398s 36s\/step - loss: 0.5092 - accuracy: 0.7353 - val_loss: 0.3150 - val_accuracy: 0.8500\nEpoch 5\/100\n11\/11 [==============================] - 395s 36s\/step - loss: 0.4465 - accuracy: 0.8137 - val_loss: 0.2848 - val_accuracy: 0.9000\nEpoch 6\/100\n11\/11 [==============================] - 397s 36s\/step - loss: 0.3994 - accuracy: 0.8824 - val_loss: 0.2566 - val_accuracy: 0.9000\nEpoch 7\/100\n11\/11 [==============================] - 403s 37s\/step - loss: 0.3739 - accuracy: 0.8529 - val_loss: 0.2346 - val_accuracy: 0.9000\nEpoch 8\/100\n.\n.\n.\n11\/11 [==============================] - 221s 20s\/step - loss: 0.0959 - accuracy: 0.9804 - val_loss: 0.0429 - val_accuracy: 1.0000\nEpoch 99\/100\n11\/11 [==============================] - 204s 19s\/step - loss: 0.0893 - accuracy: 0.9706 - val_loss: 0.0228 - val_accuracy: 1.0000\nEpoch 100\/100\n11\/11 [==============================] - 202s 18s\/step - loss: 0.0723 - accuracy: 0.9706 - val_loss: 0.0278 - val_accuracy: 1.0000\n[INFO] evaluating network...\n              precision    recall  f1-score   support\n\n       covid       1.00      0.93      0.96        14\n      normal       0.93      1.00      0.97        14\n\n    accuracy                           0.96        28\n   macro avg       0.97      0.96      0.96        28\nweighted avg       0.97      0.96      0.96        28\n\n[[13  1]\n [ 0 14]]","33040f49":"from IPython.display import Image\nImage(filename='\/kaggle\/input\/graph-of-model\/plot.png', width=800) ","ab801f9f":"Now you will be able to see the images dataset in the \"generated-data\" folder(containing 2 folders covid & normal) which we are gonna use in this whole process.","9f996eb8":"* From line 54-57 we are passing each image on by one to our data augmentation object and saving it in \"jpg\"format. and rest code loop over all images and check if we reached a specifies number of examples which is 100 by default.","f194392c":"You can find the dataset used in training of this Deep Learning Model from [Open Source Kaggle Dataset of 5000 Lungs X Ray Images +ve COVID and 5000 Healthy Persons Lungs Images](https:\/\/www.kaggle.com\/nabeelsajid917\/covid-19-x-ray-10000-images)","c3471e36":"* From line 75-76 we setting training data, test data and 79-81 we doing data augmentation and finaly from line 85-86 we are loading VGG16 network whome we will trai. ","c8781596":"* From line 4-24 we are importing necessary packages need for this file","0ddac472":"* from line 12-19 we are setting the command line arguments.","5b9769d1":"* Now Open \"generate_images.py\" file of directory","0cb82616":"# Lets Train the Deep Learning Model ","fd3dc154":"* and run the following command","789dbc64":"**Specificity**\n100% Specificity means we could accurately identify them as \u201cCOVID-19 negative\u201d 100.00% of the time using our model.","e608c9c8":"# Lets dive into train_covid19.py","af618e7e":"**Accuracy**\nHere we have 100% accuracy means we can use this model for detection of COVID from X Rays.","60ed59ff":"Download the source code and dataset [here](https:\/\/www.kaggle.com\/nabeelsajid917\/covid-19-x-ray-10000-images).","177e45dd":"# Lets dive into generate_images.py","a6a3a614":"* This will create a Deep Learning model \"covid19.model\" in the same directory","8b58a7d1":"* In line 22 we are taking all the image paths in a list\n* In line 23 we are initializing an array to store all the images ","738d8b0a":"* From line 39-61 we are taking each image from the path, changing it to RGB, resizing it, adding its lable to label and adding image to data.","6ecd2074":"* From line 44-52 we are doing data augmentation","69aae148":"**Sensitivity**\n92.86% Sensitivity means we could accurately identify them as \u201cCOVID-19 positive\u201d 92.86% of the time using our model.","25fc3078":"# Accuracy Graph of DL Model","abe6c891":"# COVID-19 Detection from X Ray Images of Lungs","dc5025ac":"* and finally we are poling the graph of accuracy from 148-163 ","b8e894d0":"* from line 65-71 we are creating np array and encoding images lables ","39fb71df":"Lets discuss the accuracy of our created model from the graph ploted","dc75bab9":"* From line 26-33 we are setting command line arguments","b05751eb":"* and these commands one by one.","fe2a51a2":"* From line 35-40 we are converting image to array so that we can apply data augmentation on it.","4f0a6e50":"# Accessing dataset from the Kaggle\nDownload the whole directory available [here](https:\/\/www.kaggle.com\/nabeelsajid917\/covid-19-x-ray-10000-images).\n* Create a New Python Local Environment and paste all th files in main directory of local environment.\n* Check the file named \"requirements.txt\". This file contains the information about all the libraries we gonna use in this process.\n* run the command ***pip install -r requirements.txt*** this will install all the required libraries we needed.","5f449bb8":"* Now open the file in \"train_covid19.py\" in editor","2facfdd4":"* from line 121-145 we are evaluating our model. Priniting reports and confusion matrix.","33f32a29":"* From line 90-99 we are setting some training parameters and than from 103-104 we are freezing base layers so that they might not update during first training process.","e6308bea":"**NOTE**: Through this model is almost 100% accurate but still there is a lot of work need to be done as I didn't used other parameters like geo-location, travel history etc to detect COVID-19. Using only X Rays images is not enough. If you want to use this for further research kindly contact me for further studies and research. ","09a85283":"* Accuracy: 100.00%\n* Sensitivity: 92.86%\n* Specificity: 100.00%","19cbb0b5":"* from line 107-10 we are compiling our model and from 113-119 we are traing the head of our network ","8bd0a493":"* from line 2-9 we are importing necessary packages needed.","58b5d542":"* From line 26-34 we are opening all the paths of images one by one and than appending images into data array.","c72f3c7d":"* from line 37-39 we are setting innitial learning rate, no or epochs and batch size.","dd70cef3":"**NOTE**: *Wait for some time because these commands will create data augmentation and will create around 10000 images. On a good GPU it will take a few minutes*.   "}}