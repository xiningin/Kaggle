{"cell_type":{"bdb5dd05":"code","21573601":"code","0e226ec2":"code","1f12ee8e":"code","e7cd3d52":"code","220a05f2":"code","57f8d378":"code","49453e25":"code","4aa006f7":"code","f18a24aa":"code","119db890":"code","eb9a15b5":"code","738189ab":"code","546bf30a":"code","3cb1f52a":"code","34d8186f":"code","3bcde4e6":"code","81ac57b3":"code","f1d50826":"markdown","cb25c279":"markdown","a7d0b7a7":"markdown","0ee11b86":"markdown","b16b3ba9":"markdown","f509e955":"markdown","560cb200":"markdown"},"source":{"bdb5dd05":"from keras import Model, Input\nfrom keras import models\nfrom keras import layers\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import ModelCheckpoint\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","21573601":"data = pd.read_csv(\"\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\",\n                   names=['review', '\u0441lass'],\n                   header=0,\n                   encoding='utf-8')","0e226ec2":"x_train = data['review']\ny_train = data['\u0441lass']\ndel data","1f12ee8e":"print(x_train[0])\nprint(y_train[0])\nprint(len(x_train))","e7cd3d52":"max_words = 20_000","220a05f2":"tokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(x_train)\nx_train = tokenizer.texts_to_sequences(x_train)\ndel tokenizer","57f8d378":"def vectorize(sequences, dimension):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        for j in sequence:\n            results[i, j] += 1\n    return results\/np.amax(results)","49453e25":"x_train = vectorize(x_train, max_words)","4aa006f7":"y_train = [1 if i == 'positive' else 0 for i in y_train]","f18a24aa":"x_test = x_train[:10_000]\ny_test = y_train[:10_000]\n\nx_train = x_train[10_000:]\ny_train = y_train[10_000:]","119db890":"x_test = np.array(x_test)\ny_test = np.array(y_test)\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)","eb9a15b5":"branch = 256\n\ndropout = 0.4\n\nepochs = 500\n\nonehot_input = Input(shape=(max_words,), name='onehot') \n\nfeatures = layers.Dropout(dropout)(onehot_input)\n\nfeatures = layers.Dense(128, activation='sigmoid')(features)\nfeatures = layers.Dropout(dropout)(features)\n\nfeatures = layers.Dense(64, activation='sigmoid')(features)\nfeatures = layers.Dropout(dropout)(features)\n\noutput = layers.Dense(1, activation = \"sigmoid\", name=\"ispositive\")(features)\n\nmodel = Model(\n    inputs=[onehot_input],\n    outputs=[output],\n)\n\nmodel.compile(\n    optimizer = 'rmsprop',\n    loss = \"binary_crossentropy\",\n    metrics = [\"accuracy\"]\n)\n\nprint(model.summary())","738189ab":"model_save_path = 'best_model.h5'\ncheckpoint_callback = ModelCheckpoint(model_save_path, \n                                      monitor='val_accuracy',\n                                      save_best_only=True,\n                                      verbose=1)","546bf30a":"results = model.fit(\n    {\"onehot\": x_train},\n    {\"ispositive\": y_train},\n    epochs=epochs,\n    batch_size=branch,\n    validation_data=({\"onehot\": x_test},\n                     {\"ispositive\": y_test}),\n    callbacks=[checkpoint_callback],\n)","3cb1f52a":"model.load_weights(model_save_path)","34d8186f":"plt.plot(results.history['accuracy'], label='Train')\nplt.plot(results.history['val_accuracy'], label='Test')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","3bcde4e6":"scores = model.evaluate(x_test, y_test, verbose=1)","81ac57b3":"scores","f1d50826":"# **Test model**","cb25c279":"# **Split data**","a7d0b7a7":"# **Build model**","0ee11b86":"# **Prepare Y data**","b16b3ba9":"# **Prepare X data**","f509e955":"# **Train model**","560cb200":"# **Load data**"}}