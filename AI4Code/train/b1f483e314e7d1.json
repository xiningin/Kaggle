{"cell_type":{"81089eb7":"code","cb62c7fa":"code","bf01d9e6":"code","9eeb01f2":"code","2ed1921f":"code","6d098f5a":"code","399d3be3":"code","55092f91":"code","ac32f5e0":"code","032f9574":"code","2a6015b2":"code","dc954a32":"code","84a78407":"code","9ea2fd3f":"code","5f6d31b6":"code","6c4b1965":"code","63aee93e":"code","669dd3e0":"code","ee03789f":"code","afa1a5ee":"markdown"},"source":{"81089eb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb62c7fa":"import matplotlib.pyplot as plt\nimport re\nimport csv\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dropout","bf01d9e6":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","9eeb01f2":"train.head()","2ed1921f":"test.head()","6d098f5a":"def preprocess(data):\n    \n    data.Cabin.fillna(\"0\", inplace = True)\n    \n    data.loc[data.Cabin.str[0] == \"A\",\"Cabin\"] = 1\n    data.loc[data.Cabin.str[0] == \"B\",\"Cabin\"] = 2\n    data.loc[data.Cabin.str[0] == \"C\",\"Cabin\"] = 3\n    data.loc[data.Cabin.str[0] == \"D\",\"Cabin\"] = 4\n    data.loc[data.Cabin.str[0] == \"E\",\"Cabin\"] = 5\n    data.loc[data.Cabin.str[0] == \"F\",\"Cabin\"] = 6\n    data.loc[data.Cabin.str[0] == \"G\",\"Cabin\"] = 7\n    data.loc[data.Cabin.str[0] == \"T\",\"Cabin\"] = 8\n    \n    data['Sex'].replace('female', 1, inplace=True)\n    data['Sex'].replace('male', 2, inplace=True)\n    \n    data[\"Embarked\"].replace(\"S\",1,inplace = True)\n    data[\"Embarked\"].replace(\"C\",2,inplace = True)\n    data[\"Embarked\"].replace(\"Q\",3,inplace = True)\n    \n    data[\"Age\"].fillna(data.Age.median(),inplace = True)\n    \n    data[\"Fare\"].fillna(data.Fare.median(),inplace = True)\n    \n    data[\"Embarked\"].fillna(data.Embarked.median(),inplace = True)\n    \n    data.drop([\"PassengerId\",\"Ticket\"], axis = 1,inplace = True)\n    \n    return data","399d3be3":"preprocess(train).head()","55092f91":"preprocess(test).head()","ac32f5e0":"def group_titles(data):\n    \n    data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n    \n    data['Title'].replace('Master.', 0, inplace=True)\n    data['Title'].replace('Mr.', 1, inplace=True)\n    data['Title'].replace(['Ms.','Mlle.', 'Miss.'], 2, inplace=True)\n    data['Title'].replace(['Mme.', 'Mrs.'], 3, inplace=True)\n    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 4, inplace=True)\n    \n    data.drop([\"Name\"],axis = 1 , inplace = True)\n    return data","032f9574":"group_titles(train).head()","2a6015b2":"train.shape","dc954a32":"train.Cabin = train.Cabin.astype('int64') ","84a78407":"X_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.20, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","9ea2fd3f":"y_train.shape","5f6d31b6":"model = Sequential()\nmodel.add(Dense(16, input_shape=X_train.shape, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(X_train,y_train, epochs =300, validation_split=0.2,verbose = 1)","6c4b1965":"#model = Sequential()\n#model.add(Dense(1024, input_shape=X_train.shape, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(1024, activation='relu'))\n#model.add(Dropout(0.1))\n#model.add(Dense(1024, activation='relu'))\n#model.add(Dense(1, activation='sigmoid'))\n#model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n#history = model.fit(X_train,y_train,batch_size = 700, epochs =10, validation_split=0.2,verbose = 1)","63aee93e":"print(history.history.keys())","669dd3e0":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()\n\nplt.figure()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","ee03789f":"print(\"accuracy: \",history.history['accuracy'][-1])\nprint(\"val_accuracy: \",history.history['val_accuracy'][-1])\nprint(\"loss: \",history.history['loss'][-1])\nprint(\"val_loss: \",history.history['val_loss'][-1])","afa1a5ee":"imamhatiplerkapat\u0131ls\u0131nxd"}}