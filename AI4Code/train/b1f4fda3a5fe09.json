{"cell_type":{"8f01656e":"code","137d9c72":"code","756b5752":"code","1a247716":"code","95e40d2f":"code","1891f96e":"code","f84acf78":"code","5e40dbc4":"code","776867cb":"code","ee6093ee":"code","efd34bf0":"code","915553bf":"code","a11024e4":"code","300ae541":"code","b4852799":"code","176279fa":"code","0e915487":"code","ab780a9c":"code","1797d72d":"code","871f8a77":"code","cfe7c102":"code","17c31c05":"code","3f70dbca":"code","9881a929":"code","b625b9cd":"code","15a9a7de":"code","113513d3":"code","193b03dc":"code","b9863c3a":"code","3682852d":"code","cd9dcb41":"code","a14a23ca":"code","e7ec393c":"code","ef88da76":"code","357ed996":"code","45f5c4b4":"code","033f5770":"code","ec405055":"code","5af45ae6":"code","7802afe7":"code","6bed067d":"code","25465d3d":"code","da195a51":"code","45f2ba78":"code","69b22b95":"code","54570941":"code","5b337e8d":"code","0b8685d3":"code","82c8c0ea":"code","62d76b12":"code","87dd9de7":"code","1a846f45":"code","8123686a":"code","5e133a37":"code","67500b99":"code","9722ddb4":"code","676a7498":"code","992e8c34":"code","6bc62f43":"code","52c568eb":"code","f4fb9c0b":"code","43333ed7":"code","80ad333f":"code","575f0c9c":"code","56122bf7":"code","4439039b":"code","bce38607":"code","fd662e58":"code","1726ae7b":"code","068f06cb":"code","793ec59e":"code","db9ef1fc":"code","672e60e7":"code","ac19e108":"code","83929f7e":"markdown","b5b0b8c0":"markdown","bda0f971":"markdown","c5566508":"markdown","67e473c5":"markdown","2e1e8970":"markdown","73e7b674":"markdown","dc5cb858":"markdown","24a74d59":"markdown","69d94e61":"markdown","ab8b91c9":"markdown","b5a612c1":"markdown","c718ea3e":"markdown","66004099":"markdown","b22da21a":"markdown","89966809":"markdown","8ffec079":"markdown","b3739efb":"markdown","fffa926e":"markdown","b72c149a":"markdown","56255b99":"markdown","20be7daf":"markdown","b7b4bbf0":"markdown","7d7d2650":"markdown","fe55ed89":"markdown","6bb99286":"markdown","7f29dac2":"markdown","83497795":"markdown","7fb413e7":"markdown","46ff6256":"markdown","61831d09":"markdown","41e0fc2f":"markdown","fb1fd0e0":"markdown","70e5cdb6":"markdown","66923189":"markdown","ccbedafc":"markdown","641e701d":"markdown","a37e97d7":"markdown","d3760e23":"markdown","32494845":"markdown","38f9f741":"markdown","fb38296d":"markdown","c922d9d4":"markdown","c2e140fd":"markdown","519046af":"markdown","8b5f543c":"markdown","ee5f160a":"markdown","7ba76915":"markdown","c7959108":"markdown","53da61c0":"markdown","fc3d1bd7":"markdown","88202ab3":"markdown","32688bc4":"markdown","930bcf4e":"markdown","965f02e7":"markdown","5c84cb80":"markdown","2741f33f":"markdown","3b5ed666":"markdown","59865179":"markdown","e61c1f19":"markdown","6b1eb983":"markdown","aaa5030e":"markdown","af2dd061":"markdown","7cda3a28":"markdown","0a941194":"markdown","85704225":"markdown","32f32a9e":"markdown","db93c77c":"markdown","a38dd8cc":"markdown","2e3d8b6b":"markdown","5ff71dbd":"markdown","af3df45c":"markdown","5ca14eaf":"markdown","f5b38a4f":"markdown","ac73aba6":"markdown","d87a9fd7":"markdown","f500888c":"markdown","3b4f5e7d":"markdown","fbe46361":"markdown"},"source":{"8f01656e":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","137d9c72":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","756b5752":"# Lecture des donn\u00e9es d'apprentissage et de test\nt = pd.read_csv(\"..\/input\/titanic\/train.csv\")","1a247716":"t.head().T","95e40d2f":"t.Sex.value_counts()      # nombre d'hommes et de femmes","1891f96e":"t.Sex.count()              # nombre total hommes+femmes","f84acf78":"t.Cabin.count()","5e40dbc4":"t.count()                  # Comptage par colonnes","776867cb":"t[np.isnan(t.Age)].Survived.value_counts()","ee6093ee":"hommes = (t.Sex==\"male\")","efd34bf0":"t[hommes].head()        # t[hommes] est le tableau o\u00f9 on ne retient que lignes pour lesquelles hommes est True","915553bf":"t[hommes].Survived.value_counts()","a11024e4":"femmes = t.Sex==\"female\"\nclasse1 = t.Pclass == 1\nclasse2 = t.Pclass == 2\nclasse3 = t.Pclass == 3\nsurvivant = t.Survived == 1\nmort = ~ survivant","300ae541":"jack = hommes & classe3\nrose = femmes & classe1","b4852799":"p_jack = t[jack & survivant].Sex.count()\/t[jack].Sex.count()\nprint(p_jack)","176279fa":"p_rose = t[rose & survivant].Sex.count()\/t[rose].Sex.count()\nprint(p_rose)","0e915487":"t.columns","ab780a9c":"# On \u00e9limine les colonnes non pertinentes pour la pr\u00e9diction\ntitanic = t.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)","1797d72d":"titanic.count()","871f8a77":"titanic[np.isnan(titanic.Age)]","cfe7c102":"titanic1 = titanic.fillna(value = {'Age':titanic.Age.mean()})","17c31c05":"plt.hist(titanic1.Age, bins=80)","3f70dbca":"titanic = titanic.fillna(method='pad')","9881a929":"titanic = titanic.fillna(method='pad')","b625b9cd":"titanic.count()","15a9a7de":"plt.hist(titanic.Age, bins=80)","113513d3":"sns.distplot(titanic.Fare, color='blue')","193b03dc":"titanic['log_fare'] = np.log(titanic.Fare+1)","b9863c3a":"sns.kdeplot(titanic.log_fare, color='blue')","3682852d":"titanic = titanic.drop(['Fare'], axis=1)","cd9dcb41":"titanic[['Age','log_fare']].describe()","a14a23ca":"sns.kdeplot(titanic.log_fare, color='blue')\nsns.kdeplot(titanic.Age, color='red')","e7ec393c":"from sklearn import preprocessing","ef88da76":"minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\ntitanic[['Age', 'log_fare']] = minmax.fit_transform(titanic[['Age', 'log_fare']])","357ed996":"sns.distplot(titanic.log_fare, color='blue')\nsns.distplot(titanic.Age, color='red')","45f5c4b4":"scaler = preprocessing.StandardScaler()\ntitanic[['Age', 'log_fare']] = scaler.fit_transform(titanic[['Age', 'log_fare']])","033f5770":"sns.kdeplot(titanic.log_fare, color='blue')\nsns.kdeplot(titanic.Age, color='red')","ec405055":"titanic.info()","5af45ae6":"titanic.Sex = titanic.Sex.map({\"male\":0, \"female\":1})","7802afe7":"titanic = pd.get_dummies(data=titanic, columns=['Pclass', 'Embarked'])","6bed067d":"titanic.head()","25465d3d":"X = titanic.drop(['Survived'], axis=1)\ny = titanic.Survived","da195a51":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","45f2ba78":"print(X_train.shape)\nprint(X_test.shape)","69b22b95":"from sklearn.linear_model import LogisticRegression","54570941":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","5b337e8d":"y_lr = lr.predict(X_test)","0b8685d3":"# Importation des m\u00e9thodes de mesure de performances\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","82c8c0ea":"print(confusion_matrix(y_test,y_lr))","62d76b12":"print(accuracy_score(y_test,y_lr))","87dd9de7":"print(classification_report(y_test, y_lr))","1a846f45":"probas = lr.predict_proba(X_test)","8123686a":"print(probas)","5e133a37":"dfprobas = pd.DataFrame(probas,columns=['proba_0','proba_1'])\ndfprobas['y'] = np.array(y_test)","67500b99":"dfprobas","9722ddb4":"plt.figure(figsize=(10,10))\nsns.distplot(1-dfprobas.proba_0[dfprobas.y==0], bins=50)\nsns.distplot(dfprobas.proba_1[dfprobas.y==1], bins=50)","676a7498":"false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","992e8c34":"plt.figure(figsize=(12,12))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\nplt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","6bc62f43":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","52c568eb":"print(classification_report(y_test, y_rf))","f4fb9c0b":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","43333ed7":"rf1 = ensemble.RandomForestClassifier(n_estimators=10, min_samples_leaf=10, max_features=3)\nrf1.fit(X_train, y_train)\ny_rf1 = rf.predict(X_test)\nprint(classification_report(y_test, y_rf1))","80ad333f":"from sklearn.model_selection import validation_curve\nparams = np.arange(1, 300,step=30)\ntrain_score, val_score = validation_curve(rf, X, y, 'n_estimators', params, cv=7)\nplt.figure(figsize=(12,12))\nplt.plot(params, np.median(train_score, 1), color='blue', label='training score')\nplt.plot(params, np.median(val_score, 1), color='red', label='validation score')\nplt.legend(loc='best')\nplt.ylim(0, 1)\nplt.xlabel('n_estimators')\nplt.ylabel('score');","575f0c9c":"from sklearn import model_selection","56122bf7":"param_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)","4439039b":"rf_gs.fit(X_train, y_train)","bce38607":"print(rf_gs.best_params_)","fd662e58":"rf2 = rf_gs.best_estimator_","1726ae7b":"y_rf2 = rf2.predict(X_test)","068f06cb":"print(classification_report(y_test, y_rf2))","793ec59e":"importances = rf2.feature_importances_\nindices = np.argsort(importances)","db9ef1fc":"plt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","672e60e7":"# Sous Jupyter, si xgboost n'est pas d\u00e9j\u00e0 install\u00e9\n!pip install xgboost","ac19e108":"import xgboost as XGB\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\nprint(classification_report(y_test, y_xgb))","83929f7e":"### Encodage binaire des donn\u00e9es qualitatives (*one hot encoding*)","b5b0b8c0":"On voit qu'il y a une forte diff\u00e9rente de distribution entre les deux s\u00e9ries.  \nCertains algorithmes demandent une distribution normalis\u00e9e. Pour une discussion d\u00e9taill\u00e9e sur ce sujet, cf par exemple :  \nhttp:\/\/www.faqs.org\/faqs\/ai-faq\/neural-nets\/part2\/section-16.html  \nhttp:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html","bda0f971":"N\u00e9anmoins cette mesure peut \u00eatre fauss\u00e9e dans certains cas, en particulier si le nombre de 0 et de 1 est d\u00e9s\u00e9quilibr\u00e9.\nOn a donc d'autres estimateurs :\n- la **pr\u00e9cision** est le nombre de pr\u00e9dictions positives correctes sur le nombre total de pr\u00e9dictions positives : *precision = VP\/(VP+FP)*\n- la **sensibilit\u00e9** (*recall*) est le nombre de pr\u00e9dictions positives sur le nombre effectif de \"oui\" : *recall = VP:(VP+FN)*\n- le **score F1** est la moyenne pond\u00e9r\u00e9e de la pr\u00e9cision et de la sensibilit\u00e9 : *f1-score = 2xprecisionxrecall\/(precision+recall)*","c5566508":"Certaines distributions sont d\u00e9s\u00e9quilibr\u00e9es, et \u00e9loign\u00e9es d'une loi normale :","67e473c5":"L'attribut *feature_importances_* renvoie un tableau du poids de chaque caract\u00e9ristique dans la d\u00e9cision :","2e1e8970":"On affiche la distribution des probabilit\u00e9s de pr\u00e9diction de 1, et celle des non probabilit\u00e9s de pr\u00e9diction de 0 :","73e7b674":"## Lecture des donn\u00e9es","dc5cb858":"Parmi les hyperparam\u00e8tres de l'algorithme qui peuvent avoir un impact sur les performances, on a :\n- **n_estimators** : le nombre d'arbres de d\u00e9cision de la for\u00eat al\u00e9atoire\n- **min_samples_leaf** : le nombre d'\u00e9chantillons minimum dans une feuille de chaque arbre\n- **max_features** : le nombre de caract\u00e9ristiques \u00e0 prendre en compte lors de chaque split\n\nPour chaque algorithme de *sklearn*, on peut trouver la liste des param\u00e8tres dans la documentation, avec des exemples :  \nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html  ","24a74d59":"La distribution des \u00e2ges n'est pas significativement modifi\u00e9e ...","69d94e61":"On peut visualiser ces degr\u00e9s d'importance avec un graphique \u00e0 barres par exemple :","ab8b91c9":"<img src = \"http:\/\/scikit-learn.org\/0.16\/_static\/ml_map.png\">","b5a612c1":"## Exercice : tester diff\u00e9rentes visualisations sur le dataset","c718ea3e":"On remarque qu'il manque des valeurs pour 'age' et 'embarked' (pr\u00e9sence de valeurs ind\u00e9finies 'NaN')","66004099":"### Importance des caract\u00e9ristiques","b22da21a":"La **matrice de confusion** permet de compter les vrais positifs, faux positifs, ...","89966809":"L'option *method='pad'* permet d'utiliser la pr\u00e9c\u00e9dente valeur non manquante :","8ffec079":"# Le Titanic","b3739efb":"On peut compter les hommes survivants ou non :","fffa926e":"Tracer l'histogramme pour *age* :","b72c149a":"On met les probabilit\u00e9s de pr\u00e9diction de la valeur 1 dans un dataframe, avec les valeurs effectives, pour faciliter la visualisation :","56255b99":"Afficher la matrice de confusion :","20be7daf":"La plupart des algorithmes ont besoin de donn\u00e9es num\u00e9riques, et n'acceptent pas les cha\u00eenes de caract\u00e8res :","b7b4bbf0":"En comparant les valeurs pr\u00e9dites et les valeurs r\u00e9elles, on a plusieurs possibilit\u00e9s :\n- *Vrais positifs* (VP ou TP) : on pr\u00e9dit \"oui\" et la valeur attendue est \"oui\"\n- *Vrais n\u00e9gatifs* (VN ou TN) : on pr\u00e9dit \"non\" et la valeur attendue est \"non\"\n- *Faux positifs* (FP) : on pr\u00e9dit \"oui\" et la valeur attendue est \"non\"\n- *Faux n\u00e9gatifs* (FN) : on pr\u00e9dit \"non\" et la valeur attendue est \"oui\"\n\nPar exemple, si veut pr\u00e9dire le d\u00e9c\u00e8s, le nombre de vrais positifs est le nombre de fois o\u00f9 on a pr\u00e9dit 0 pour des passagers effectivement morts sur le Titanic (*survived = 0*)","7d7d2650":"Les valeurs inconnues sont affich\u00e9es comme **NaN** (*Not a Number*).  \nOn peut tester si une valeur est **NaN** avec la fonction *np.isnan(valeur)*  \nAfficher les lignes pour lesquelles l'\u00e2ge est inconnu :","fe55ed89":"## D\u00e9s\u00e9quilibre des distributions","6bb99286":"## Interpr\u00e9tation des param\u00e8tres","7f29dac2":"La fonction *fillna* permet de compl\u00e9ter simplement les param\u00e8tres manquants. ","83497795":"Appliquer une r\u00e9gression logistique pour classifier sur l'ensemble de test","7fb413e7":"### Mise \u00e0 l'\u00e9chelle des donn\u00e9es quantitatives","46ff6256":"On utilise la fonction *get_dummies* de Pandas pour transformer les colonnes multimodales (par exemple 'embarked') en plusieurs colonnes binaires (par exemple 'embarked_C' dont les valeurs sont 1 si le passager a embarqu\u00e9 \u00e0 Cherbourg et 0 sinon) :","61831d09":"Calculer la probabilit\u00e9 de survie de Jack :","41e0fc2f":"## Mesures de performance","fb1fd0e0":"## Exercice : explorer d'autres m\u00e9thodes de classification","70e5cdb6":"## Exercice : quelle est la probabilit\u00e9 de survie de Rose et Jack ?","66923189":"## Ajustement des hyperparam\u00e8tres (Random Forests)","ccbedafc":"## Cr\u00e9ation des jeux d'apprentissage et de test","641e701d":"## Exercice : appliquer les m\u00e9thodes sur le dataset *Indian Diabete*","a37e97d7":"La distribution id\u00e9ale permet de s\u00e9parer totalement la pr\u00e9diction des positifs et n\u00e9gatifs :  \n<img src=\"https:\/\/miro.medium.com\/max\/660\/1*Uu-t4pOotRQFoyrfqEvIEg.png\">\nLe cas le plus d\u00e9favorable consiste en une distribution \u00e9quivalente pour les positifs et les n\u00e9gatifs :  \n<img src=\"https:\/\/miro.medium.com\/max\/538\/1*iLW_BrJZRI0UZSflfMrmZQ.png\">","d3760e23":"Tracer les courbes de distribution de l'\u00e2ge selon la classe (utiliser *FacetGrid*)","32494845":"Que peut-on dire des voyageurs de 1ere, 2eme et 3eme classe ?","38f9f741":"On s\u00e9pare le dataset en deux parties :\n- un ensemble d'apprentissage (entre 70% et 90% des donn\u00e9es), qui va permettre d'entra\u00eener le mod\u00e8le\n- un ensemble de test (entre 10% et 30% des donn\u00e9es), qui va permettre d'estimer la pertinence de la pr\u00e9diction","fb38296d":"On voit qu'il manque des donn\u00e9es, en particulier pour la colonne *'age'*  \nIl existe plusieurs approches pour compl\u00e9ter les donn\u00e9es manquantes :  \n- **suppression** des donn\u00e9es manquantes (par exemple avec la fonction *dropna*). C'est une m\u00e9thode simple, mais qui \u00e9limine de l'information\n- **remplacement** des donn\u00e9es manquantes. Par exemple, on pourrait remplacer les informations manquantes pour l'\u00e2ge par la moyenne de la colonne (mais on introduit un biais sur cette valeur), ou par un nombre al\u00e9atoire g\u00e9n\u00e9r\u00e9 par une loi normale de m\u00eame moyenne et variance ...\n- **estimation** des param\u00e8tres manquants avec une m\u00e9thode de pr\u00e9diction (par exemple avec une r\u00e9gression)","c922d9d4":"Jack est un homme en 3\u00e8me classe, et Rose une femme en 1\u00e8re (d\u00e9finir les bool\u00e9ens *jack* et *rose*) :","c2e140fd":"On teste les for\u00eats al\u00e9atoires :","519046af":"On lance l'entrainement :","8b5f543c":"<img src=\"https:\/\/i.stack.imgur.com\/gKyb9.png\">","ee5f160a":"D\u00e9finir les bool\u00e9ens pour *femmes, classe1, classe2, classe3, survivant, ...*","7ba76915":"### Donn\u00e9es manquantes","c7959108":"On peut voir les param\u00e8tres s\u00e9lectionn\u00e9s et le score :","53da61c0":"On utilise ces distributions pour construire la **courbe ROC** (Receiving Operator Characteristic) qui repr\u00e9sente le taux de vrais positifs par rapport aux taux de faux positifs.  \nLa mesure de l'aire sous la courbe **AUC** (Area Under Curve) est un bon indicateur de performance  \nPour plus de d\u00e9tails : http:\/\/www.xavierdupre.fr\/app\/mlstatpy\/helpsphinx\/c_metric\/roc.html","fc3d1bd7":"*validation_curve* permet de tracer la courbe du score sur un ensemble d'apprentissage et sur un ensemble de test (*cross validation*), en faisant varier un param\u00e8tre, par exemple *n_estimators* :","88202ab3":"La pertinence (ou *accuracy*) mesure le nombre de bonnes pr\u00e9dictions sur le nombre total d'observations","32688bc4":"Cr\u00e9er les jeux d'apprentissage et de test","930bcf4e":"Calculer la probabilit\u00e9 de survie de Rose :","965f02e7":"La m\u00e9thode *GridSearchCV* permet de tester plusieurs combinaisons de param\u00e8tres (list\u00e9s dans une grille de param\u00e8tres) et de s\u00e9lectionner celle qui donne la meilleure pertinence","5c84cb80":"Eliminer les colonnes non pertinentes pour la pr\u00e9diction (on peut utiliser une liste de colonnes dans *drop*), et placer le r\u00e9sultat dans la variable *titanic* :","2741f33f":"On peut d\u00e9finir un bool\u00e9en pour abr\u00e9ger une caract\u00e9ristique :","3b5ed666":"Il manque des valeurs, par exemple pour la colonne *age*","59865179":"*predict_proba* donne un tableau de couples de probabilit\u00e9s : *[probabilit\u00e9 de pr\u00e9diction 0, probabilit\u00e9 de pr\u00e9diction 1]*","e61c1f19":"On s\u00e9lectionne le meilleur estimateur :","6b1eb983":"<img src=\"https:\/\/www.scienceabc.com\/wp-content\/uploads\/2016\/04\/titanic-jack-and-rose-plank-scene.webp\">","aaa5030e":"## XGBoost","af2dd061":"La m\u00e9thode XGBoost est d\u00e9riv\u00e9e des arbres de d\u00e9cision, et tr\u00e8s efficace, en particulier pour de grandes quantit\u00e9s de donn\u00e9es.","7cda3a28":"On peut normaliser les valeurs min et \u00e0 max (valeurs ramen\u00e9es entre 0 et 1) :","0a941194":"Ici on a choisi des valeurs pour le nombres d'arbres dans la for\u00eat al\u00e9atoire (*'n_estimators'*) et le nombre minimum d'\u00e9chantillons pour une feuille. On pourrait tester d'autres valeurs, et d'autres param\u00e8tres, cf :  \nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html","85704225":"- survived - Survival (0 = No; 1 = Yes)\n- pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n- name - Name\n- sex - Sex\n- age - Age\n- sibsp - Number of Siblings\/Spouses Aboard\n- parch - Number of Parents\/Children Aboard\n- ticket - Ticket Number\n- fare - Passenger Fare\n- cabin - Cabin\n- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n","32f32a9e":"## Conditionnement des donn\u00e9es","db93c77c":"La librairie *sklearn* comporte une librairie de pr\u00e9traitement des donn\u00e9es","a38dd8cc":"http:\/\/scikit-learn.org\/0.16\/tutorial\/machine_learning_map\/index.html","2e3d8b6b":"# Rose & Jack","5ff71dbd":"**Exercice** : tracer les courbes de validation pour les param\u00e8tres *min_samples_leaf* et *max_features* (attention pour ce dernier, le nombre max est le nombre de caract\u00e9ristiques \/ colonnes du tableau)","af3df45c":"*value_counts* permet de compter le nombre d'\u00e9l\u00e9ments par cat\u00e9gorie d'une s\u00e9rie","5ca14eaf":"## R\u00e9gression logistique","f5b38a4f":"Dans ce cas, une transformation log peut am\u00e9liorer l'\u00e9quilibre :","ac73aba6":"On peut \u00e9galement utiliser le *StandardScaler* pour ramener la moyenne \u00e0 0 et l'\u00e9cart type \u00e0 1 :","d87a9fd7":"Tracer l'histogramme des \u00e2ges. Qu'observez-vous ?","f500888c":"On a am\u00e9lior\u00e9 la performance du mod\u00e8le","3b4f5e7d":"Sous Anaconda prompt :\n*pip install xgboost*  \n(d\u00e9j\u00e0 disponible sous Kaggle)","fbe46361":"Tracer diff\u00e9rentes repr\u00e9sentations du dataset"}}