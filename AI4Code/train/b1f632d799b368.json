{"cell_type":{"c13bcd91":"code","11070da6":"code","b9bf5fc8":"code","17565a93":"code","dc3c0b59":"code","4335d008":"code","ae5d3ac6":"code","1a1a649e":"markdown","95bbc5a3":"markdown","f17167f4":"markdown"},"source":{"c13bcd91":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder","11070da6":"train_data = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\n\ntrain_data.drop(['id', 'target'], axis = 1, inplace = True)\n\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\n\ntest_data.drop(['id'], axis = 1, inplace = True)","b9bf5fc8":"train_data['istrain'] = 1\n\ntest_data['istrain'] = 0\n\ncombined_data = pd.concat([train_data, test_data], axis = 0)","17565a93":"df_numeric = combined_data.select_dtypes(exclude=['object'])\n\ndf_obj = combined_data.select_dtypes(include=['object']).copy()\n    \nfor c in df_obj:\n    df_obj[c] = pd.factorize(df_obj[c])[0]\n    \ncombined_data = pd.concat([df_numeric, df_obj], axis=1)\n\ny = combined_data['istrain']\n\ncombined_data.drop('istrain', axis = 1, inplace = True)","dc3c0b59":"combined_data.head()","4335d008":"skf = StratifiedShuffleSplit(n_splits = 5, random_state = 44,test_size =0.4)\nxgb_params = {\n        'learning_rate': 0.1, 'max_depth': 6,'subsample': 0.9,\n        'colsample_bytree': 0.9,'objective': 'binary:logistic',\n        'n_estimators':100, 'gamma':1,\n        'min_child_weight':4,'use_label_encoder' :False\n        }   \nclf = xgb.XGBClassifier(**xgb_params, seed = 10)    ","ae5d3ac6":"scores = []\n\navg_loss = []\n\nfor train_index, test_index in skf.split(combined_data, y):\n       \n        x0, x1 = combined_data.iloc[train_index], combined_data.iloc[test_index]\n        \n        y0, y1 = y.iloc[train_index], y.iloc[test_index]        \n        \n        print(x0.shape)\n        \n        clf.fit(x0, y0, eval_set=[(x1, y1)],\n               eval_metric=['logloss','auc'], verbose=True,early_stopping_rounds=50)\n                \n        prval = clf.predict_proba(x1)[:,1]\n        \n        roc = roc_auc_score(y1,prval)\n\n        scores.append(roc)\n        \n        avg_loss.append(clf.best_score)\n\n        print ('XGB Val OOF AUC=',roc)\n    \nprint(\"Log Loss Stats {0:.8f},{1:.8f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))","1a1a649e":"**As we can see the AUC socre is close to 0.5,whic implies train and test data are almost indistiguishable. Both train and test set must come from similar distribution and normal validation techniques should work**","95bbc5a3":"Though this was not needed since the data is artificially generated, it is a good practice to perform a check","f17167f4":"# Adversarial Validation\n\n**Adversarial validation is a technique applied to the data to help reduce overfitting. The idea behind this is to identify the degree of similarity between the training and test data by analysing feature distribution. To do this, we build a classifier to predict which data is from the training set and which is from the test set. This model will assign 1 for rows from the train set and 0 for rows of data from the test set. If there are differences between the distributions of train and test set then this classifier will be able to identify these. The better a model you can learn to distinguish them, the bigger the problem you have.**"}}