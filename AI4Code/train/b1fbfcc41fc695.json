{"cell_type":{"f0d00e82":"code","0587719c":"code","43db6493":"code","1f81e5e3":"code","e1f94314":"code","0c3e2428":"code","93595e53":"code","6a1cba93":"code","4370d775":"code","936abf55":"code","c67714d5":"code","53898a25":"code","5f06d6ca":"code","ae522e24":"code","ec25c03c":"code","5e1b3ffc":"code","9b829ba4":"code","3e7f6321":"code","bbfb88a4":"code","aa0f5151":"code","c7aeda71":"code","f22b4f1c":"code","ffb49d05":"code","f8c7c856":"code","446e7254":"markdown","de583d8c":"markdown","57be4094":"markdown","3bd98678":"markdown","a48a80ab":"markdown"},"source":{"f0d00e82":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfiles=[]\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n        print(files[-1])\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0587719c":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport datetime as dt\nimport lightgbm as lgb\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","43db6493":"df = pd.read_csv(files[-1])\ndf[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\ndf[\"day_from_date\"] = pd.to_datetime(df[\"date\"]).dt.day\ndf['month_from_date'] = pd.to_datetime(df[\"date\"]).dt.month\nprint(df.shape)\ndf.head(1)","1f81e5e3":"df.info()","e1f94314":"df.describe()","0c3e2428":"%%time\ndf[\"CPM\"] = np.where(df[\"measurable_impressions\"] != 0, \n                    (df[\"total_revenue\"] * 100) \/ (df['measurable_impressions']) * 1000,\n                     0,\n                    )\nsns.distplot(df[\"CPM\"])","93595e53":"sns.heatmap(df.drop(\"CPM\", axis=1).corr())","6a1cba93":"## drop high correlate features\ncorr_matrix = df.drop(\"CPM\", axis=1).corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\nprint(\"before remove:\", df.shape)\ndf.drop(to_drop, axis=1, inplace=True)\nprint(\"after remove:\", df.shape)","4370d775":"df.info()","936abf55":"df[[\"date\", \"CPM\"]].groupby([\"date\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","c67714d5":"df[[\"site_id\", \"CPM\"]].groupby([\"site_id\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","53898a25":"df[[\"ad_type_id\", \"CPM\"]].groupby([\"ad_type_id\"]).agg({\"CPM\":\"median\"}).unstack().plot.bar()","5f06d6ca":"df[[\"device_category_id\", \"CPM\"]].groupby([\"device_category_id\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","ae522e24":"df[[\"os_id\", \"CPM\"]].groupby([\"os_id\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","ec25c03c":"df[[\"monetization_channel_id\", \"CPM\"]].groupby([\"monetization_channel_id\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","5e1b3ffc":"df[[\"day_from_date\", \"CPM\"]].groupby([\"day_from_date\"]).agg({\"CPM\":\"mean\"}).unstack().plot.bar()","9b829ba4":"df.nunique(axis=0)","3e7f6321":"df.drop([\"integration_type_id\", \"revenue_share_percent\", \"total_revenue\", \"ad_type_id\"], axis=1, inplace=True)","bbfb88a4":"cpm_quan_95 = df[\"CPM\"].quantile(0.95)\ndf = df[(df['CPM'] >= 0 ) & (df['CPM'] < cpm_quan_95)]","aa0f5151":"mid_date = dt.date(2019, 6, 22)\ntrain = df.loc[df[\"date\"] < mid_date, :]\ntest = df.loc[df[\"date\"] >= mid_date, :]\n\ntrain.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)\n\nprint(train.shape, test.shape)","c7aeda71":"X_train = train.drop(\"CPM\", axis=1)\ny_train = train[\"CPM\"]","f22b4f1c":"X_test = test.drop(\"CPM\", axis=1)\ny_test = test[\"CPM\"]","ffb49d05":"params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'mse',\n    'max_depth': 10, \n    'learning_rate': 0.1,\n    'verbose': 0, \n    'early_stopping_round': 50}\n\nn_estimators = 1000\nn_iters = 10\nmse_errors = []\n\nfor i in range(n_iters): \n    X_train = train.drop(\"CPM\", axis=1)\n    y_train = train[\"CPM\"]\n    x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=i)\n    d_train = lgb.Dataset(x_train, label=y_train)\n    d_valid = lgb.Dataset(x_valid, label=y_valid)\n    watchlist = [d_valid]\n    model = lgb.train(params, d_train, n_estimators, watchlist, verbose_eval=0)\n\n    preds = model.predict(x_valid)\n    err = mean_squared_error(y_valid, preds)\n    mse_errors.append(err)\n    print('MSE = ' + str(err))\n\nprint(f\"Mean MSE = {np.mean(mse_errors)} +\/- {np.std(mse_errors)}\")","f8c7c856":"pred = model.predict(X_test)\nprint(\"MSE: \", round(mean_squared_error(pred, y_test), 4))","446e7254":"## Features","de583d8c":"## Preprocessing","57be4094":"## Answer","3bd98678":"## Import Libraries and Data","a48a80ab":"## Modeling"}}