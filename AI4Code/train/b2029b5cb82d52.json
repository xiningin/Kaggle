{"cell_type":{"e7c5c591":"code","fa5ba92b":"code","c4928b4f":"code","22c3b3eb":"code","f8b8a8a2":"code","a8a4f234":"code","29f691a5":"code","2ac8d2c3":"code","9910e904":"code","6c4430c0":"code","a58f6e67":"code","8128a95b":"code","43412e02":"code","03f3d5f4":"code","011376ab":"code","a1f9917e":"code","2a706625":"code","82e576aa":"code","6e20861d":"code","7fe5d642":"code","b745dc04":"code","23be8eba":"markdown","a907cb76":"markdown","423d7c0f":"markdown","ffe4245a":"markdown","2fb1eb8b":"markdown","8259dcc7":"markdown","9db1fa90":"markdown","4e835751":"markdown","5698bc83":"markdown","4cde973f":"markdown","6b07bef2":"markdown","693ac626":"markdown","378a78b5":"markdown","3d480055":"markdown","4a25c01d":"markdown","11095f22":"markdown","cc9893d4":"markdown","a4ef0b47":"markdown","5eace54e":"markdown"},"source":{"e7c5c591":"import time\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom pytz import all_timezones\n\n# # helper functions\n# from cozie_functions import *","fa5ba92b":"\ndef normalise_total_cozie(dataframe, group, threshold):\n    cluster_df = dataframe.copy(deep=True)\n    # remapping\n    cluster_df['prefer_cooler'] = cluster_df['thermal_cozie'][cluster_df.thermal_cozie == 11.0] #Too Hot\n    cluster_df['prefer_warmer'] = cluster_df['thermal_cozie'][cluster_df.thermal_cozie == 9.0] # Too COld\n    cluster_df['thermaly_comfy'] = cluster_df['thermal_cozie'][cluster_df.thermal_cozie == 10.0] #_cOmfy\n\n    \n    cluster_df['prefer_dimmer'] = cluster_df['light_cozie'][cluster_df.light_cozie == 11.0] # Too bright\n    cluster_df['prefer_brighter'] = cluster_df['light_cozie'][cluster_df.light_cozie == 9.0] # Too Dark\n    cluster_df['visually_comfy'] = cluster_df['light_cozie'][cluster_df.light_cozie == 10.0] #_comfy\n    \n    cluster_df['prefer_quieter'] = cluster_df['noise_cozie'][cluster_df.noise_cozie == 11.0] # Too Loud\n    cluster_df['prefer_louder'] = cluster_df['noise_cozie'][cluster_df.noise_cozie == 9.0] # Too Quiet\n    cluster_df['aurally_comfy'] = cluster_df['noise_cozie'][cluster_df.noise_cozie == 10.0] #_comfy\n\n    \n\n    # group\n    group_df=cluster_df.groupby(group).count()\n    group_df = group_df[group_df.thermal_cozie >= threshold]\n\n    group_df[['prefer_cooler', 'prefer_warmer', 'thermaly_comfy']] = group_df[['prefer_cooler', 'prefer_warmer', 'thermaly_comfy']].div(group_df.thermal_cozie, axis=0)\n    group_df[['prefer_dimmer', 'prefer_brighter', 'visually_comfy']] = group_df[['prefer_dimmer', 'prefer_brighter','visually_comfy']].div(group_df.light_cozie, axis=0) \n    group_df[['prefer_quieter', 'prefer_louder', 'aurally_comfy']] = group_df[['prefer_quieter', 'prefer_louder', 'aurally_comfy']].div(group_df.noise_cozie, axis=0)\n\n\n\n    return (group_df)\n\ndef find_optimal_tree_depth(clf, train_vectors, train_labels, plot=True):\n    \"\"\"Choose the optimal depth of a tree model \n    \"\"\"\n    \n    DEFAULT_K = 10\n    \n    # generate a list of potential depths to calculate the optimal\n    depths = list(range(1, 25))\n\n    # empty list that will hold cv scores\n    cv_scores = []\n\n    print(\"Finding optimal tree depth\")\n    # find optimal tree depth    \n    for d in depths: # TODO: try using chooseK(train_labels) instead of jus DEFAULT_K\n        clf_depth = clf.set_params(max_depth = d) # use previous parameters while changing depth\n\n        scores = cross_val_score(clf_depth, train_vectors, \n                                 train_labels, cv = choose_k(train_labels),\n                                 scoring = 'accuracy') # accuracy here is f1 micro\n        cv_scores.append(scores.mean())\n\n    # changing to misclassification error and determining best depth\n    MSE = [1 - x for x in cv_scores] # MSE = 1 - f1_micro\n    optimal_depth = depths[MSE.index(min(MSE))]\n    \n    print(\"The optimal depth is: {}\".format(optimal_depth))\n    print(\"Expected accuracy (f1 micro) based on Cross-Validation: {}\".format(cv_scores[depths.index(optimal_depth)]))\n    \n    if plot:\n        # plot misclassification error vs depths\n        fig = plt.figure(figsize=(12, 10))\n        plt.plot(depths, MSE)\n        plt.xlabel('Tree Depth', fontsize = 20)\n        plt.ylabel('Misclassification Error', fontsize = 20)\n#         plt.legend(fontsize = 15)\n        plt.show()\n\n    return optimal_depth","c4928b4f":"raw_data_date = \"2019-11-15\"\ndf_raw = pd.read_csv(\"..\/input\/longitudinal-personal-thermal-comfort-preferences\/cresh_tabular_merged.csv\")\nraw_features = df_raw.columns.values\nprint(\"Raw dataset dimension: {}\".format(df_raw.shape))\nprint(raw_features)\ndf_raw.head(10)\n","22c3b3eb":"df_processed = df_raw.copy()","f8b8a8a2":"# list of columns which won't be used on this experiment\n# co2_sensing: some sensing sensors don't have that feature in some rooms\n# clothing was only used for PMV\nlist_drop_columns = ['Unnamed: 0', 'index', 'clothing','comfort_cozie', 'responseSpeed_cozie', 'co2_sensing', 'voc_sensing', 'lat_cozie', \n                     'lon_cozie', 'Floor', 'Latitude', 'Longitude', 'Space_id']\n","a8a4f234":"# drop first two columns of indices\ndf_processed.drop(list_drop_columns, axis=1, inplace=True)\ndf_processed.head(10)\n","29f691a5":"# we prioritize thermal comfort votes in the instances\ndf_processed = df_processed[df_processed['thermal_cozie'].notnull()]\ndf_processed.head(10)\n","2ac8d2c3":"df_processed = df_processed[df_processed['temperature_mbient'].notnull()]\nprint(\"First Batch within building (COMPLETE AMBIENT) dataset dimension: {}\".format(df_processed.shape))\ndf_processed.head(10)\n","9910e904":"print(\"All participants in file:\")\nprint(df_processed['user_id'].unique())\ndf_processed = df_processed[pd.to_numeric(df_processed['user_id'].str[5:]) <= 30]\nprint(\"Only Cresh participants:\")\nprint(df_processed['user_id'].unique())\n","6c4430c0":"df_processed_indoor = df_processed.copy()\ndf_processed_indoor = df_processed_indoor[df_processed_indoor['room'].notnull()]\n# all sensing features will be missing but it's enough to check one\ndf_processed_indoor = df_processed_indoor[df_processed_indoor['humidity_sensing'].notnull()]\nprint(\"First Batch within building dataset dimension: {}\".format(df_processed_indoor.shape))\ndf_processed_indoor.head(10)\n","a58f6e67":"df_processed_indoor_time = df_processed_indoor.copy()\n\n# convert to Singapore time\ndf_processed_indoor_time['time'] = df_processed_indoor_time['time'].apply(pd.Timestamp).dt.tz_convert('Asia\/Singapore')\n\n# get minute of the day and day of the week\ndf_processed_indoor_time['time_minute'] = df_processed_indoor_time['time'].dt.hour * 60 + df_processed_indoor_time['time'].dt.minute\ndf_processed_indoor_time['day_of_week'] = df_processed_indoor_time['time'].dt.dayofweek\n\n# Create cyclical features for the time and day of the week\ndf_processed_indoor_time['hour_sin'] = np.sin(df_processed_indoor_time.time_minute * (2. * np.pi\/1440)) #24*60 = 1440\ndf_processed_indoor_time['hour_cos'] = np.cos(df_processed_indoor_time.time_minute * (2. * np.pi\/1440))\ndf_processed_indoor_time['day_of_week_sin'] = np.sin(df_processed_indoor_time.day_of_week * (2. * np.pi\/7))\ndf_processed_indoor_time['day_of_week_cos'] = np.cos(df_processed_indoor_time.day_of_week * (2. * np.pi\/7))\n\n# delete auxiliary columns\ndf_processed_indoor_time.drop(['time', 'time_minute', 'day_of_week'], axis=1, inplace=True)\n\nprint(df_processed_indoor_time.head(10))\n","8128a95b":"df_processed_indoor_time.dropna(inplace=True)\nprint(df_processed_indoor_time.shape)\nprint(df_processed_indoor_time.head(10))\n","43412e02":"df_fs1 = df_processed_indoor_time.copy()\ndf_fs1.drop(['heartRate_cozie', 'room', 'temperature_mbient'], axis=1, inplace=True)\nfeature_set1 = df_fs1.columns.values\n\nprint(\"Feature Set1: {} \\n Size: {}\".format(feature_set1, df_fs1.shape))","03f3d5f4":"df_fs2 = df_processed_indoor_time.copy()\ndf_fs2.drop(['room'], axis=1, inplace=True)\nfeature_set2 = df_fs2.columns.values\n\nprint(\"Feature Set2: {} \\n Size: {}\".format(feature_set2, df_fs2.shape))","011376ab":"df_fs3 = df_processed_indoor_time.copy()\n\n# remap and calculate preference history for the user and for the room\n\n# for Users\ngrouped_user_df = normalise_total_cozie(df_fs3, 'user_id', 0)\ngrouped_user_df.drop([\"thermaly_comfy\", 'aurally_comfy', 'visually_comfy'], axis=1, inplace=True)\n\n# for Rooms\ngrouped_room_df = normalise_total_cozie(df_fs3, 'room', 0)\ngrouped_room_df.drop([\"thermaly_comfy\", 'aurally_comfy', 'visually_comfy'], axis=1, inplace=True)\n\n# take average results and map it back to the feature_set\npreferences = ['prefer_cooler', 'prefer_warmer', 'prefer_dimmer', 'prefer_brighter','prefer_quieter', 'prefer_louder']\nfor preference in preferences:\n    map_dict = grouped_user_df[preference].to_dict()\n    label = \"user_grouped_\" + preference.split(\"_\")[1]\n    df_fs3[label] = df_fs3['user_id'].map(map_dict)\nfor preference in preferences:\n    map_dict = grouped_room_df[preference].to_dict()\n    label = \"room_grouped_\" + preference.split(\"_\")[1]\n    df_fs3[label] = df_fs3['room'].map(map_dict)\n    \n# do this by first creating a dictionary, and then running the .map method\ndf_fs3.dropna(subset=[\"user_grouped_cooler\", \"user_grouped_warmer\", \"room_grouped_cooler\", \"room_grouped_warmer\"], inplace=True)\n\nfeature_set3 = df_fs3.columns.values\n\nprint(\"Feature Set3: {} \\n Size: {}\".format(feature_set3, df_fs3.shape))\n","a1f9917e":"df_fs4 = df_fs3.copy()\n\ndf_fs4.drop(['humidity_sensing', 'light_sensing', 'noise_sensing', 'temperature_sensing'], axis=1, inplace=True)\nfeature_set4 = df_fs4.columns.values\n\nprint(\"Feature Set4: {} \\n Size: {}\".format(feature_set4, df_fs4.shape))","2a706625":"df_fs5 = df_fs4.copy()\ndf_fs5.drop(['temperature_mbient'], axis=1, inplace=True)\nfeature_set5 = df_fs5.columns.values\n\nprint(\"Feature Set5: {} \\n Size: {}\".format(feature_set5, df_fs5.shape))","82e576aa":"df_fs6 = df_fs5.copy()\ndf_fs6.drop(['heartRate_cozie'], axis=1, inplace=True)\nfeature_set6 = df_fs6.columns.values\n\nprint(\"Feature Set5: {} \\n Size: {}\".format(feature_set6, df_fs6.shape))","6e20861d":"def save_df(dataframe, file_name):\n#     new_name = str(datetime.date(datetime.now())) + \"_\" + file_name + \".csv\" raw_data_date\n    new_name = raw_data_date + \"_\" + file_name + \".csv\"\n    dataframe.to_csv(\"data-processed-preferences\/\" + new_name, index=False)\n    ","7fe5d642":"dataframes = [df_fs1, df_fs2, df_fs3, df_fs4, df_fs5, df_fs6]\ndataframes_names = ['fs1', 'fs2', 'fs3', 'fs4', 'fs5', 'fs6']\nfor df, df_name in zip(dataframes, dataframes_names):\n    save_df(df, df_name)\n    ","b745dc04":"# rows 1474","23be8eba":"### Feature Set5: Time + Heart Rate + room + preference history","a907cb76":"### Feature Set3: Time + Sensing + Heart Rate + mbient + room + preference history","423d7c0f":"# Remove NaNs","ffe4245a":"### Feature Set4: Time + Heart Rate + mbient + room + preference history","2fb1eb8b":"## Measured variables are features","8259dcc7":"### Feature Set2: Time + Sensing + Heart Rate + mbient","9db1fa90":"### Feature Set1: Time + Sensing","4e835751":"This notebook is from the Github repository: https:\/\/github.com\/buds-lab\/humans-as-a-sensor-for-buildings\/blob\/master\/data\/datasets_generation_room_preference.ipynb\n\n# Summary of Dataframes\n- `df_raw` original dataframe, exactly the same as the original `.csv` file\n- `df_processed` dataframe without certain columns that are not used for future experiments\n- `df_processed_indoor` filtered only within SDE\n- `df_processed_indoor_time` `time` was processed as an `hour.minute` numerical feature\n","5698bc83":"# Convert `time` into a feature\n\nRef: http:\/\/blog.davidkaleko.com\/feature-engineering-cyclical-features.html","4cde973f":"<img src=\"..\/img\/tiers.png\">","6b07bef2":"## Drop rows with collection errors","693ac626":"# Create Feature Sets","378a78b5":"## Filter only Cresh participants","3d480055":"# Save Dataframes","4a25c01d":"# Load raw file and preprocess features","11095f22":"# Remove rows with missing data on mbient","cc9893d4":"### Feature Set6: Time + room + preference history","a4ef0b47":"# Only votes indoor","5eace54e":"## Drop features not needed for experiments"}}