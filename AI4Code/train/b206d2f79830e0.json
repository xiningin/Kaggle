{"cell_type":{"5bb3e050":"code","2fad94f1":"code","59aa2efe":"code","8eac6550":"code","8b8604b1":"code","a10f6f00":"code","9cbc2e6e":"code","90b781c0":"code","db2ca6c1":"code","1955764d":"code","1e1027d9":"code","84fdf174":"code","4c1b1e58":"code","f2c3830f":"code","240cc358":"code","2313a07a":"code","017496f5":"code","37af68ad":"code","c1069bc5":"code","bd476b72":"code","b8e1552d":"code","435f28ad":"code","89d29f46":"code","56d5c196":"code","371046f6":"code","04761bf3":"code","cbd87e7f":"code","a73fa76d":"code","491c867b":"code","2078f1ee":"code","519b6324":"code","7ca1a329":"code","786cf17a":"code","eb308043":"code","96ba61e4":"code","995e029c":"code","c165b288":"code","0af60b33":"code","e0597d8d":"code","26d7d9ee":"code","1c73d218":"code","1d12cc41":"code","7df564a4":"code","2f8bdb8b":"code","2586cf40":"code","5202adad":"code","fb0a0b2a":"code","b4c25a33":"code","5750a512":"code","41b559cb":"code","90046ae9":"code","d2f33c79":"markdown","a7af5a87":"markdown","27eb0ff2":"markdown","e4b240d2":"markdown","f472f8f4":"markdown","afbc32e0":"markdown","3f647bc9":"markdown","35f1f692":"markdown","64f71b6f":"markdown","415c08cb":"markdown","5e4c5790":"markdown","4a632f32":"markdown","f957d1f9":"markdown","16ffa1f2":"markdown","9262c9cd":"markdown","2cf0d6b3":"markdown","24191349":"markdown","466dbe40":"markdown","52c34cd5":"markdown","9cf4218d":"markdown","432f93db":"markdown","c97c004a":"markdown","84500461":"markdown","148c3744":"markdown","71e60bfd":"markdown","1058f542":"markdown","92b4611b":"markdown","9b84eb61":"markdown","cc75ed4c":"markdown"},"source":{"5bb3e050":"# Import required libraries\nimport os\nimport gc\nimport sys\nimport json\nimport random\nfrom pathlib import Path\n\nimport cv2 # CV2 for image manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tqdm import tqdm\n\nfrom imgaug import augmenters as iaa\n\nimport seaborn as sns\nimport matplotlib.image as mpimg\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold, KFold","2fad94f1":"!pip install tensorflow==1.5\n!pip install keras==2.1.5\n\nimport tensorflow\nprint(tensorflow.__version__)\nimport keras\nprint(keras.__version__)","59aa2efe":"!ls \/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/","8eac6550":"%%time\nwith open('\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/label_descriptions.json', 'r') as file:\n    label_desc = json.load(file)\nsample_sub_df = pd.read_csv('\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/sample_submission.csv')\ntrain_df = pd.read_csv('\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train.csv')","8b8604b1":"train_df.head()","a10f6f00":"sample_sub_df.head()","9cbc2e6e":"print(f'Shape of training dataset: {train_df.shape}')","90b781c0":"print(f'# of images in training set: {train_df[\"ImageId\"].nunique()}')\nprint(f'# of images in test set: {sample_sub_df[\"ImageId\"].nunique()}')","db2ca6c1":"pd.DataFrame([train_df['Height'].describe(), train_df['Width'].describe()]).T.loc[['max', 'min', 'mean']]","1955764d":"image_shape_df = train_df.groupby(\"ImageId\")[\"Height\", \"Width\"].first()","1e1027d9":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\nax1.hist(image_shape_df['Height'], bins=100)\nax1.set_title(\"Height distribution\")\nax2.hist(image_shape_df['Width'], bins=100)\nax2.set_title(\"Width distribution\")\nplt.show()","84fdf174":"plt.figure(figsize = (70,7))\nmin_height = list(set(train_df[train_df['Height'] == train_df['Height'].min()]['ImageId']))[0]\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{min_height}.jpg'))\nplt.grid(False)\nplt.show()","4c1b1e58":"plt.figure(figsize = (70,7))\nmax_height = list(set(train_df[train_df['Height'] == train_df['Height'].max()]['ImageId']))[0]\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{max_height}.jpg'))\nplt.grid(False)\nplt.show()","f2c3830f":"plt.figure(figsize = (70,7))\nmin_width = list(set(train_df[train_df['Width'] == train_df['Width'].min()]['ImageId']))[0]\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{min_width}.jpg'))\nplt.grid(False)\nplt.show()","240cc358":"plt.figure(figsize = (70,7))\nmax_width = list(set(train_df[train_df['Width'] == train_df['Width'].max()]['ImageId']))[0]\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{max_width}.jpg'))\nplt.grid(False)\nplt.show()","2313a07a":"area_df = pd.DataFrame()\narea_df['ImageId'] = train_df['ImageId']\narea_df['area'] = train_df['Height'] * train_df['Width']\nmin_area = list(set(area_df[area_df['area'] == area_df['area'].min()]['ImageId']))[0]\nmax_area = list(set(area_df[area_df['area'] == area_df['area'].max()]['ImageId']))[0]","017496f5":"plt.figure(figsize = (70,7))\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{min_area}.jpg'))\nplt.grid(False)\nplt.show()","37af68ad":"plt.figure(figsize = (70,7))\nplt.imshow(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{max_area}.jpg'))\nplt.grid(False)\nplt.show()","c1069bc5":"num_classes = len(label_desc['categories'])\nnum_attributes = len(label_desc['attributes'])\nprint(f'Total # of classes: {num_classes}')\nprint(f'Total # of attributes: {num_attributes}')","bd476b72":"categories_df = pd.DataFrame(label_desc['categories'])\nattributes_df = pd.DataFrame(label_desc['attributes'])\ncategories_df","b8e1552d":"pd.set_option('display.max_rows', 300)\nattributes_df","435f28ad":"def plot_images(size=12, figsize=(12, 12)):\n    # First get some images to be plotted\n    image_ids = train_df['ImageId'].unique()[:12]\n    images=[]\n    \n    for image in image_ids:\n        images.append(mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{image}.jpg'))\n    \n    # Plot images in groups of 4 images\n    n_groups = 4\n    \n    count = 0\n    for index in range(size \/\/ 4):\n        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=figsize)\n        for row in ax:\n            for col in row:\n                col.imshow(images[count])\n                col.axis('off')\n                count += 1\n        plt.show()\n    gc.collect()","89d29f46":"plot_images()","56d5c196":"def create_mask(size):\n    image_ids = train_df['ImageId'].unique()[:size]\n    images_meta=[]\n\n    for image_id in image_ids:\n        img = mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{image_id}.jpg')\n        images_meta.append({\n            'image': img,\n            'shape': img.shape,\n            'encoded_pixels': train_df[train_df['ImageId'] == image_id]['EncodedPixels'],\n            'class_ids':  train_df[train_df['ImageId'] == image_id]['ClassId']\n        })\n\n    masks = []\n    for image in images_meta:\n        shape = image.get('shape')\n        encoded_pixels = list(image.get('encoded_pixels'))\n        class_ids = list(image.get('class_ids'))\n        \n        # Initialize numpy array with shape same as image size\n        height, width = shape[:2]\n        mask = np.zeros((height, width)).reshape(-1)\n        \n        # Iterate over encoded pixels and create mask\n        for segment, (pixel_str, class_id) in enumerate(zip(encoded_pixels, class_ids)):\n            splitted_pixels = list(map(int, pixel_str.split()))\n            pixel_starts = splitted_pixels[::2]\n            run_lengths = splitted_pixels[1::2]\n            assert max(pixel_starts) < mask.shape[0]\n            for pixel_start, run_length in zip(pixel_starts, run_lengths):\n                pixel_start = int(pixel_start) - 1\n                run_length = int(run_length)\n                mask[pixel_start:pixel_start+run_length] = 255 - class_id * 4\n        masks.append(mask.reshape((height, width), order='F'))  # https:\/\/stackoverflow.com\/questions\/45973722\/how-does-numpy-reshape-with-order-f-work\n    return masks, images_meta","371046f6":"def plot_segmented_images(size=12, figsize=(14, 14)):\n    # First create masks from given segments\n    masks, images_meta = create_mask(size)\n    \n    # Plot images in groups of 4 images\n    n_groups = 4\n    \n    count = 0\n    for index in range(size \/\/ 4):\n        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=figsize)\n        for row in ax:\n            for col in row:\n                col.imshow(images_meta[count]['image'])\n                col.imshow(masks[count], alpha=0.75)\n                col.axis('off')\n                count += 1\n        plt.show()\n    gc.collect()","04761bf3":"plot_segmented_images()","cbd87e7f":"categories_df = pd.DataFrame(label_desc.get('categories'))\nattributes_df = pd.DataFrame(label_desc.get('attributes'))","a73fa76d":"print(f'# of categories: {len(categories_df)}')\nprint(f'# of attributes: {len(attributes_df)}')","491c867b":"categories_df.head()","2078f1ee":"attributes_df.head()","519b6324":"category_map, attribute_map = {}, {}\nfor cat in label_desc.get('categories'):\n    category_map[cat.get('id')] = cat.get('name')\nfor attr in label_desc.get('attributes'):\n    attribute_map[attr.get('id')] = attr.get('name')","7ca1a329":"train_df['ClassId'] = train_df['ClassId'].map(category_map)\ntrain_df['ClassId'] = train_df['ClassId'].astype('category')","786cf17a":"sns.set(style='darkgrid')\nfig, ax = plt.subplots(figsize = (10,10))\nsns.countplot(y='ClassId',data=train_df , ax=ax, order = train_df['ClassId'].value_counts().index)\nfig.show()","eb308043":"IMAGE_ID = '000b3ec2c6eaffb491a5abb72c2e3e26'","96ba61e4":"# Get the an image id given in the training set for visualization\nvis_df = train_df[train_df['ImageId'] == IMAGE_ID]\nvis_df['ClassId'] = vis_df['ClassId'].cat.codes\nvis_df = vis_df.reset_index(drop=True)\nvis_df","995e029c":"plt.figure(figsize = (110,11))\nimage = mpimg.imread(f'\/kaggle\/input\/imaterialist-fashion-2020-fgvc7\/train\/{IMAGE_ID}.jpg')\nplt.grid(False)\nplt.imshow(image)\nplt.plot()","c165b288":"train_df[train_df['ImageId'] == IMAGE_ID]","0af60b33":"segments = list(vis_df['EncodedPixels'])\nclass_ids = list(vis_df['ClassId'])\nmasks = []\nfor segment, class_id in zip(segments, class_ids):\n    \n    height = vis_df['Height'][0]\n    width = vis_df['Width'][0]\n    # Initialize empty mask\n    mask = np.zeros((height, width)).reshape(-1)\n    \n    # Iterate over encoded pixels and create mask\n    splitted_pixels = list(map(int, segment.split()))\n    pixel_starts = splitted_pixels[::2]\n    run_lengths = splitted_pixels[1::2]\n    assert max(pixel_starts) < mask.shape[0]\n    for pixel_start, run_length in zip(pixel_starts, run_lengths):\n        pixel_start = int(pixel_start) - 1\n        run_length = int(run_length)\n        mask[pixel_start:pixel_start+run_length] = 255 - class_id * 4\n\n    mask = mask.reshape((height, width), order='F')\n    masks.append(mask)","e0597d8d":"def plot_individual_segment(*masks, image, figsize=(110, 11)):\n    plt.figure(figsize = figsize)\n    plt.imshow(image)\n    for mask in masks:\n        plt.imshow(mask, alpha=0.6)\n    plt.axis('off')\n    plt.show()","26d7d9ee":"plot_individual_segment(masks[0], image=image)","1c73d218":"plot_individual_segment(masks[1], image=image)","1d12cc41":"plot_individual_segment(masks[2], image=image)","7df564a4":"plot_individual_segment(masks[3], image=image)","2f8bdb8b":"plot_individual_segment(masks[4], image=image)","2586cf40":"plot_individual_segment(masks[5], image=image)","5202adad":"plot_individual_segment(masks[6], image=image)","fb0a0b2a":"plot_individual_segment(masks[6], image=image)","b4c25a33":"train_df[['ImageId', 'EncodedPixels', 'Height', 'Width', 'ClassId']].isna().sum()","5750a512":"train_df.head()","41b559cb":"train_df['ClassId'] = train_df['ClassId'].cat.codes","90046ae9":"train_df","d2f33c79":"## Plotting 7th Segment with ClassId: \"sleeve\"","a7af5a87":"## Plotting 8th segment with Class \"neckline\"","27eb0ff2":"## Plotting 1st Segment: ClassId: \"Shoe\" and no attributes ","e4b240d2":"Let's check of missing values in training dataset for columns other than \"AttributeIds\"","f472f8f4":"### Image with maximum width","afbc32e0":"## Plotting 2nd Segment: ClassId: \"shoe\"","3f647bc9":"## Data Preparation and modeling","35f1f692":"## Plotting 3rd Segment with ClassId: \"pants\"","64f71b6f":"From above table, this image has 8 segmentes and a few attributes. Let's visualize all of them!","415c08cb":"### Image with minimum area","5e4c5790":"## Plotting 4th Segment with ClassId: \"top, t-shirt, sweatshirt\"","4a632f32":"### Height and Width destribution of training images","f957d1f9":"### Image with minimum height","16ffa1f2":"## Plotting a few training images without any masks","9262c9cd":"### Now let's visualize an image with all its classes and attributes","2cf0d6b3":"Some of the segments have no attributes. Let's check how many such segment exists in training dataset.","24191349":"## Plotting a few images with given segments","466dbe40":"### Image size analysis in training dataset","52c34cd5":"### Image with minimum width","9cf4218d":"### Let's see the class wise distribution of segments in training dataset","432f93db":"## Plotting 6th Segment with ClassId: \"sleeve\"","c97c004a":"### Image with maximum area","84500461":"## Details about Classes and Attributes","148c3744":"So there are 46 categories (classes) and 294 attributes. Let's see some of the categories and attributes","71e60bfd":"## Plotting 5th Segment with ClassId: \"pocket\"","1058f542":"## Analysing Categories and Attributes","92b4611b":"## Now let's plot each segment in a separate image","9b84eb61":"### Image with maximum height","cc75ed4c":"## Let's first the plot the plain image"}}