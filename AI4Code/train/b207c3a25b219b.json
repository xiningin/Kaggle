{"cell_type":{"a9f9e2c0":"code","2e0bb1e1":"code","1184adc1":"code","f12bf181":"code","042a9354":"code","7391612f":"code","c16875f6":"code","1bcb1f6a":"code","157009d1":"code","15ae548f":"code","9607ca08":"code","fabc2037":"code","69b638ff":"code","0a38e622":"code","d4b18703":"code","a6803cdf":"code","9d29ae3d":"code","6cf90f2d":"code","b78645dd":"code","5bc63489":"code","d138aa02":"code","e9cc76e7":"code","7ef6911e":"code","f72684c7":"code","d619e88c":"code","13e428e1":"code","5e3fbb72":"code","1d103cb1":"code","50bbdfbf":"markdown","aa91a3d9":"markdown","9ace8fce":"markdown","6ac7de39":"markdown","53b5357b":"markdown","e27c9d5a":"markdown","7cf591ad":"markdown","d435fbcd":"markdown","02a06c71":"markdown","ceb0f3f7":"markdown","98873141":"markdown","7cdae348":"markdown","08324306":"markdown","01d88ae0":"markdown","ec15ac57":"markdown","ede6820d":"markdown","f4f4a6b7":"markdown","e822b16f":"markdown","464a64ab":"markdown","bf49b371":"markdown","c072f5bd":"markdown","ed9b1cd2":"markdown","bc33155f":"markdown","37cebe4a":"markdown"},"source":{"a9f9e2c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport sys\nimport csv\nimport os\nimport math\nimport json, codecs\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom zipfile import ZipFile\nimport shutil\nfrom glob import glob\nfrom PIL import Image\nfrom PIL import ImageFilter\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras.models import Sequential, load_model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport time\nimport cv2\nimport h5py\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","2e0bb1e1":"train_path = \"\/kaggle\/input\/signature\/signature\/Train\/\"\ntest_path = \"\/kaggle\/input\/signature\/signature\/Test\/\"","1184adc1":"train_g = ['\/kaggle\/input\/signature\/signature\/Train\/genuine\/g40.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g128.PNG',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g3.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g42.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g81.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g120.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g83.png',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g131.PNG',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g145.PNG',\n'\/kaggle\/input\/signature\/signature\/Train\/genuine\/g56.png']\n\ntrain_f = ['\/kaggle\/input\/signature\/signature\/Train\/forged\/f27.PNG',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f55.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f140.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f68.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f26.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f135.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f33.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f80.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f117.png',\n'\/kaggle\/input\/signature\/signature\/Train\/forged\/f114.png']\n\ntest_g = ['\/kaggle\/input\/signature\/signature\/Test\/genuine\/g4.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g59.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g12.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g35.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g13.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g21.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g24.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g25.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g19.png',\n'\/kaggle\/input\/signature\/signature\/Test\/genuine\/g14.png']\n\ntest_f = ['\/kaggle\/input\/signature\/signature\/Test\/forge\/f55.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f26.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f12.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f33.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f4.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f53.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f17.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f48.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f10.png',\n'\/kaggle\/input\/signature\/signature\/Test\/forge\/f44.png']","f12bf181":"plt.figure(figsize = (35,5))\nplt.suptitle('Train Real Signatures', fontsize = 18)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    plt.imshow(cv2.resize(cv2.imread(train_g[i], 1), (224,224)))\nplt.savefig('train_g')\nplt.show()    ","042a9354":"plt.figure(figsize = (35,5))\nplt.suptitle('Train Fake Signatures', fontsize = 18)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    plt.imshow(cv2.resize(cv2.imread(train_f[i], 1), (224,224)))\nplt.savefig('train_f')\nplt.show()","7391612f":"plt.figure(figsize = (35,5))\nplt.suptitle('Test Real Signatures', fontsize = 18)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    plt.imshow(cv2.resize(cv2.imread(test_g[i], 1), (224,224)))\nplt.savefig('test_g')\nplt.show()    ","c16875f6":"plt.figure(figsize = (35,5))\nplt.suptitle('Test Fake Signatures', fontsize = 18)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    plt.imshow(cv2.resize(cv2.imread(test_f[i], 1), (224,224)))\nplt.savefig('test_f')\nplt.show()    ","1bcb1f6a":"numberOfClass = len(glob(train_path+\"\/*\"))\ntrain_data = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), class_mode='binary')\ntest_data = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), class_mode='binary')","157009d1":"# Data replication\n\ntrain_datagen = ImageDataGenerator(\n    shear_range=10,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    preprocessing_function=preprocess_input)\n \ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    batch_size=32,\n    class_mode='binary',\n    target_size=(224,224))\n \ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input)\n \ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    shuffle=False,\n    class_mode='binary',\n    target_size=(224,224))","15ae548f":"epochs = [5,10,15]\noptimizers = ['SGD', 'Adam', 'RMSprop']","9607ca08":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.50))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.50))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.50))\nmodel.add(Dense(numberOfClass, activation='softmax'))\n\n\nprint(model.summary())","fabc2037":"from keras.utils import plot_model\nplot_model(model)","69b638ff":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n        \n        \n        print(\"Optimizer:\",optimizer)\n        history = model.fit_generator(\n            generator=train_data,\n            epochs=epoch,\n            validation_data=test_data,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        val_loss, val_acc = model.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model.save('cnn_0_num_reader.model')\n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:CNN Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: False'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n        save = \"cnn_0_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()","0a38e622":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n               \n        print(\"Optimizer:\",optimizer)\n        history = model.fit_generator(\n            generator=train_generator,\n            epochs=epoch,\n            validation_data=test_generator,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        val_loss, val_acc = model.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model.save('cnn_1_num_reader.model')\n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:CNN Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: True'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n        save = \"cnn_1_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()","d4b18703":"vgg = VGG16()\nvgg_layer_list = vgg.layers\n\nmodel_vgg = Sequential()\nfor i in range(len(vgg_layer_list)-1):\n    model_vgg.add(vgg_layer_list[i])\n\nfor layers in model_vgg.layers:\n    layers.trainable = False    \nmodel_vgg.add(Dense(numberOfClass, activation=\"softmax\"))\nprint(model_vgg.summary())","a6803cdf":"from keras.utils import plot_model\nplot_model(model_vgg)","9d29ae3d":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model_vgg.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n        \n        \n        print(\"Optimizer:\",optimizer)\n        history = model_vgg.fit_generator(\n            generator=train_data,\n            epochs=epoch,\n            validation_data=test_data,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        \n        val_loss, val_acc = model_vgg.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model_vgg.save('vgg_0_num_reader.model')\n        \n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:VGG16 Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: False'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        save = \"vgg_0_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()       ","6cf90f2d":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model_vgg.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n        \n             \n        print(\"Optimizer:\",optimizer)\n        history = model_vgg.fit_generator(\n            generator=train_generator,\n            epochs=epoch,\n            validation_data=test_generator,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        val_loss, val_acc = model_vgg.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model_vgg.save('vgg_1_num_reader.model')\n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:VGG16 Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: True'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n        save = \"vgg_1_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()","b78645dd":"model_resnet = Sequential()\nmodel_resnet.add(ResNet50(include_top=False, weights='imagenet', pooling = 'avg'))\nmodel_resnet.add(Dense(numberOfClass, activation=\"softmax\"))\nmodel_resnet.layers[0].trainable = False\nmodel_resnet.summary()","5bc63489":"from keras.utils import plot_model\nplot_model(model_resnet)","d138aa02":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model_resnet.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n        \n        \n        print(\"Optimizer:\",optimizer)\n        history = model_resnet.fit_generator(\n            generator=train_data,\n            epochs=epoch,\n            validation_data=test_data,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        val_loss, val_acc = model_resnet.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model_resnet.save('resnet_0_num_reader.model')\n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:ResNet50 Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: False'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        save = \"resnet_0_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()","e9cc76e7":"for epoch in epochs:\n    print(\"Epoch:\", epoch)\n    for optimizer in optimizers:\n        model_resnet.compile(loss='sparse_categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n        \n        print(\"Optimizer:\",optimizer)\n        history = model_resnet.fit_generator(\n            generator=train_generator,\n            epochs=epoch,\n            validation_data=test_generator,\n            steps_per_epoch=40,\n            validation_steps=20)\n        \n        val_loss, val_acc = model_resnet.evaluate(test_data)\n        print(val_loss)\n        print(val_acc)\n        model_resnet.save('resnet_1_num_reader.model')\n        \n        plt.figure(figsize=(30,5))\n        plt.subplot(121)\n        title = 'Model:ResNet50 Epoch:'+str(epoch)+' Optimizer:'+optimizer+' Data Replication: True'\n        plt.suptitle(title, fontsize=15)\n\n\n        plt.plot(history.history['accuracy'])\n        plt.plot(history.history['val_accuracy'])\n        plt.title('Model Accuracy', fontsize=10)\n        plt.ylabel('Accuracy', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        plt.subplot(122)\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss', fontsize=10)\n        plt.ylabel('Loss', fontsize=10)\n        plt.xlabel('Epoch', fontsize=10)\n        plt.legend(['Train', 'Test'], loc='upper left')\n\n\n        save = \"resnet_1_\"+optimizer+\"_\"+str(epoch)\n        plt.savefig(save)\n        plt.show()","7ef6911e":"model.compile(loss='sparse_categorical_crossentropy',\n      optimizer='Adam',\n      metrics=['accuracy'])\n\nhistory = model.fit_generator(\n    generator=train_generator,\n    epochs=5,\n    validation_data=test_generator,\n    steps_per_epoch=40,\n    validation_steps=20)","f72684c7":"plt.figure(figsize = (35,5))\nplt.suptitle('Real signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_g[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_g_cnn')\nplt.show()\n\n\nplt.figure(figsize = (35,5))\nplt.suptitle('Fake signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_f[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_f_cnn')\nplt.show()","d619e88c":"model_vgg.compile(loss='sparse_categorical_crossentropy',\n      optimizer='RMSprop',\n      metrics=['accuracy'])\n\nhistory = model_vgg.fit_generator(\n    generator=train_generator,\n    epochs=10,\n    validation_data=test_generator,\n    steps_per_epoch=40,\n    validation_steps=20)","13e428e1":"plt.figure(figsize = (35,5))\nplt.suptitle('Real signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_g[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model_vgg.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_g_vgg')\nplt.show()\n\n\nplt.figure(figsize = (35,5))\nplt.suptitle('Fake signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_f[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model_vgg.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_f_vgg')\nplt.show()","5e3fbb72":"model_resnet.compile(loss='sparse_categorical_crossentropy',\n      optimizer='RMSprop',\n      metrics=['accuracy'])\n\nhistory = model_resnet.fit_generator(\n    generator=train_generator,\n    epochs=15,\n    validation_data=test_generator,\n    steps_per_epoch=40,\n    validation_steps=20)","1d103cb1":"plt.figure(figsize = (35,5))\nplt.suptitle('Real signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_g[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model_resnet.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_g_resnet')\nplt.show()\n\n\nplt.figure(figsize = (35,5))\nplt.suptitle('Fake signatures Test', fontsize=20)\nx, y = 1, 10\nfor i in range(10):\n    plt.subplot(x, y, i+1)\n    plt.axis('off')\n    img = cv2.resize(cv2.imread(test_f[i], 1), (224,224))\n    plt.imshow(img)\n    img = img_to_array(img)\n    img = img.reshape(1,224,224,3)\n    pre = model_resnet.predict_classes(img, batch_size=1)\n    plt.title(pre, fontsize=20)\nplt.savefig('test_f_resnet')\nplt.show()","50bbdfbf":"### Data Replication: False","aa91a3d9":"# Conclusion","9ace8fce":"### Data Replication: False","6ac7de39":"![vgg.PNG](attachment:vgg.PNG)","53b5357b":"## Hyperparameter selection\n\n* Epoch: 5 \n* Optimezer: Adam \n* Data Replication: True","e27c9d5a":"### Data Replication: False","7cf591ad":"# Models Evaluation","d435fbcd":"![resnet.PNG](attachment:resnet.PNG)","02a06c71":"# Data Visualization","ceb0f3f7":"## Hyperparameter selection\n\n* Epoch: 15 \n* Optimezer: RMSprop \n* Data Replication: True","98873141":"## VGG16","7cdae348":"The model that gives the best results after the experiments is VGG16.","08324306":"### Data Replication: True","01d88ae0":"## ResNet","ec15ac57":"### Data Replication: True","ede6820d":"## CNN","f4f4a6b7":"## Hyperparameter selection\n\n* Epoch: 10 \n* Optimezer: RMSprop \n* Data Replication: True","e822b16f":"# ResNet50","464a64ab":"### Train and Test Split","bf49b371":"![cnn.PNG](attachment:cnn.PNG)","c072f5bd":"# CNN","ed9b1cd2":"### Hyperparameters","bc33155f":"### Data Replication: False","37cebe4a":"# VGG16\n"}}