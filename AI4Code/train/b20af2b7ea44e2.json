{"cell_type":{"50b96127":"code","3ebb09a6":"code","13c959e0":"code","335f075c":"code","e021d205":"code","ed356b7c":"code","5683a431":"code","4ce10ecc":"code","f29edfeb":"code","ed0c9069":"code","491832a5":"code","3e54f66c":"code","48cbe6dd":"code","469039ce":"code","c3936735":"code","04cb831e":"code","f4895bcd":"code","c737f5bc":"code","d2f0209d":"code","ecee7a36":"code","c717e671":"code","c1f85eef":"code","338ef8a9":"code","6d5eceea":"code","6aea756d":"code","e14c6105":"code","03e27a22":"code","9932ddad":"code","e1f011e5":"code","c3809288":"code","3bada19b":"code","182316f3":"code","a4b34e1d":"code","abc6699b":"code","706e8cec":"code","f0a9a913":"code","954a7459":"code","d83e7e9c":"code","c99bcaec":"code","f3a6da9a":"code","3af38246":"code","72458ee2":"code","be6c62b4":"code","a41a6142":"code","b3815c5f":"markdown","2e4b4186":"markdown","4244876e":"markdown","ca1daa98":"markdown","2d1ceec9":"markdown","fda33925":"markdown","2a4dbabe":"markdown","65be4818":"markdown","f60321b6":"markdown","5373fe0c":"markdown","0fe6edd3":"markdown","c016cf03":"markdown","ba81afb7":"markdown","2a6ad878":"markdown","3e801f2f":"markdown","8ad149fb":"markdown","4cbb9e8c":"markdown","4830a8eb":"markdown","f4971e55":"markdown","23dbad4d":"markdown","484f968e":"markdown","74b10163":"markdown","7eb94ffd":"markdown"},"source":{"50b96127":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","3ebb09a6":"SBP = pd.read_csv('..\/input\/heightpulse\/SBP.csv')\nSBP.head()","13c959e0":"SBP.info()","335f075c":"SBP.describe()","e021d205":"SBP.columns","ed356b7c":"sns.pairplot(SBP)","5683a431":"sns.displot(SBP)","4ce10ecc":"sns.heatmap(SBP.corr(), annot=True)","f29edfeb":"X = SBP[['pulserate', 'height']]\ny = SBP['SBP']","ed0c9069":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=27)","491832a5":"X_test","3e54f66c":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val(model):\n    pred = cross_val_score(model, X, y, cv=8)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","48cbe6dd":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","469039ce":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,y_train)","c3936735":"lin_reg.intercept_","04cb831e":"lin_reg.coef_","f4895bcd":"# print the intercept\nprint(lin_reg.intercept_)","c737f5bc":"coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","d2f0209d":"pred = lin_reg.predict(X_test)","ecee7a36":"plt.scatter(y_test, pred)","c717e671":"sns.distplot((y_test - pred), bins=50);","c1f85eef":"test_pred = lin_reg.predict(X_test)\ntrain_pred = lin_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","338ef8a9":"results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_train, train_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df","6d5eceea":"from sklearn.linear_model import RANSACRegressor\n\nmodel = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","6aea756d":"results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","e14c6105":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","03e27a22":"results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","9932ddad":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.1, \n              precompute=True, \n#               warm_start=True, \n              positive=True, \n              selection='random',\n              random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","e1f011e5":"results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","c3809288":"from sklearn.linear_model import ElasticNet\n\nmodel = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","3bada19b":"results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","182316f3":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree=2)\n\nX_train_2_d = poly_reg.fit_transform(X_train)\nX_test_2_d = poly_reg.transform(X_test)\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train_2_d,y_train)\n\ntest_pred = lin_reg.predict(X_test_2_d)\ntrain_pred = lin_reg.predict(X_train_2_d)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","a4b34e1d":"results_df_2 = pd.DataFrame(data=[[\"Polynomial Regression\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","abc6699b":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\nsgd_reg.fit(X_train, y_train)\n\ntest_pred = sgd_reg.predict(X_test)\ntrain_pred = sgd_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","706e8cec":"results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","f0a9a913":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nmodel = Sequential()\n\nmodel.add(Dense(X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=Adam(0.00001), loss='mse')\n\nr = model.fit(X_train, y_train,\n              validation_data=(X_test,y_test),\n              batch_size=1,\n              epochs=10)","954a7459":"plt.figure(figsize=(10, 6))\n\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()","d83e7e9c":"test_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","c99bcaec":"results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","f3a6da9a":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=1000)\nrf_reg.fit(X_train, y_train)\n\ntest_pred = rf_reg.predict(X_test)\ntrain_pred = rf_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","3af38246":"results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","72458ee2":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm_reg.fit(X_train, y_train)\n\ntest_pred = svm_reg.predict(X_test)\ntrain_pred = svm_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","be6c62b4":"results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","a41a6142":"results_df.set_index('Model', inplace=True)\nresults_df['R2 Square'].plot(kind='barh', figsize=(12, 8))","b3815c5f":"### Regression Evaluation Metrics","2e4b4186":"### Predictions from Model","4244876e":"## Residual Histogram","ca1daa98":"## 2. Check out the Data","2d1ceec9":"## 1.4 Lasso Regression","fda33925":"### Model Evaluation","2a4dbabe":"## 5. Preparing Data For Linear Regression","65be4818":"## 1.3 Ridge Regression","f60321b6":"## 1.8 Artificial Neural Network","5373fe0c":"## 1.10 Support Vector Machine","0fe6edd3":"## 1.11 Models Comparison","c016cf03":"## 1.1Linear Regression","ba81afb7":"## 4. Training a Linear Regression Model","2a6ad878":"### Train Test Split","3e801f2f":"## 1. Import Libraries","8ad149fb":"## 1.5 Elastic Net","4cbb9e8c":"### Random Sample Consensus - RANSAC","4830a8eb":"## 1.2 Robust Regression","f4971e55":"## 1.7. Stochastic Gradient Descent","23dbad4d":"## 3. Exploratory Data Analysis (EDA)","484f968e":"## 1.6 Polynomial Regression","74b10163":"### X and y arrays","7eb94ffd":"## 1.9 Random Forest Regressor"}}