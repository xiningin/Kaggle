{"cell_type":{"115dfe46":"code","e76da0d0":"code","fcd92d7f":"code","b880f644":"code","5456fd26":"code","ec4f41a1":"code","5ca7fb18":"code","e5f03ff5":"code","d7fbc5e9":"code","b625c72e":"code","40050d6a":"code","a1de4715":"code","b68dea28":"code","4b2b31f4":"code","a61d5f1a":"code","35d6704b":"code","aacd2c72":"code","0e0bdfbb":"code","86799d89":"code","3967c5f1":"code","bb7fb9df":"code","3d3bd2d8":"code","03ee17d3":"markdown","875f9fec":"markdown","451ec8fa":"markdown","c3515ef5":"markdown","eb7480fd":"markdown","74827edd":"markdown","0dd607f2":"markdown","4c4ce7c2":"markdown","ceedbcb4":"markdown","9c551a42":"markdown","0696a070":"markdown","ded40238":"markdown","46c4087e":"markdown","d1b8d330":"markdown"},"source":{"115dfe46":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.\n!unzip ..\/input\/test.zip\n!unzip ..\/input\/train.zip","e76da0d0":"!mkdir has_cactus has_no_cactus ","fcd92d7f":"df = pd.read_csv('..\/input\/train.csv')","b880f644":"df.head()\n","5456fd26":"import shutil\nimages_having_cactus = []\nimages_having_no_cactus = []\n\nfor i in df[df['has_cactus'] == 1]['id']:\n    p = os.path.join('.\/train\/', i)\n    images_having_cactus.append(p)\n\nfor i in df[df['has_cactus'] == 0]['id']:\n    p = os.path.join('.\/train\/', i)\n    images_having_no_cactus.append(p)\n\n# Copying the images actually\nfor i in images_having_cactus:\n    shutil.copy(i, '.\/has_cactus\/')\nfor i in images_having_no_cactus:\n    shutil.copy(i, '.\/has_no_cactus\/')","ec4f41a1":"print('Has Cactus: {}'.format(df[df['has_cactus'] == 1]['id'].count()))\nprint('Has No Cactus: {}'.format(df[df['has_cactus'] == 0]['id'].count()))","5ca7fb18":"def augument_data(\n    directory,              # Directory where augumentation is needed. Same dir will have sample images\n    number_of_images_to_add # Image count to add \n):\n    print('Images to add: {}'.format(number_of_images_to_add))\n    import cv2\n    from glob import glob\n    l = glob(directory + '\/*.jpg')\n    for image in l:\n        if number_of_images_to_add == 0:\n            break\n        img = cv2.imread(image)\n        h_img = cv2.flip(img, 0)\n        v_img = cv2.flip(img, 1)\n        cv2.imwrite(directory + '\/h_img_{}.jpg'.format(number_of_images_to_add), h_img)\n        number_of_images_to_add -= 1\n        cv2.imwrite(directory + '\/v_img_{}.jpg'.format(number_of_images_to_add), v_img)\n        number_of_images_to_add -= 1","e5f03ff5":"augument_data('.\/has_no_cactus\/', df[df['has_cactus'] == 1]['id'].count() - df[df['has_cactus'] == 0]['id'].count())","d7fbc5e9":"!mkdir -p curated_data\/train_data curated_data\/validation_data\/has_cactus\n!mkdir -p curated_data\/validation_data\/has_no_cactus\n!mv has_cactus has_no_cactus curated_data\/train_data","b625c72e":"from glob import glob\nimport shutil\nl = glob('curated_data\/train_data\/has_cactus\/*.jpg')\nfor i in range(300):\n    shutil.move(l[i], 'curated_data\/validation_data\/has_cactus')\n\nl = glob('curated_data\/train_data\/has_no_cactus\/*.jpg')\nfor i in range(300):\n    shutil.move(l[i], 'curated_data\/validation_data\/has_no_cactus')","40050d6a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping","a1de4715":"datagen = ImageDataGenerator(\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True,\n    horizontal_flip=True,\n    vertical_flip=True\n)","b68dea28":"train_data = datagen.flow_from_directory(\n    'curated_data\/train_data\/',\n    class_mode='categorical'\n)\n\nvalidation_data = datagen.flow_from_directory(\n    'curated_data\/validation_data\/',\n    class_mode='categorical'\n)","4b2b31f4":"vgg16_model = VGG16(\n    include_top=False,\n    weights='imagenet',\n    input_shape=(256, 256, 3)\n)","a61d5f1a":"vgg16_model.summary()","35d6704b":"for layer in vgg16_model.layers[:5]:\n    layer.trainable = False","aacd2c72":"x = vgg16_model.output\nx = Flatten()(x)\nx = Dense(1024)(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)\n\n# creating the final model \nmodel = Model(inputs= vgg16_model.input, outputs= predictions)\n\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n\n# compile the model \nmodel.compile(loss = \"binary_crossentropy\", optimizer = SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])","0e0bdfbb":"model.fit_generator(\n    train_data,\n    epochs=20,\n    validation_data=validation_data,\n    callbacks=[early_stop]\n)","86799d89":"hist = pd.DataFrame(model.history.history)\nhist.plot()","3967c5f1":"import cv2\nfrom glob import glob\ntest_images = glob('..\/input\/test\/test\/*.jpg')\ndf = pd.DataFrame(columns=['id', 'has_cactus'])\ndf.index.name = 'id'\nfor img in test_images:\n    i = cv2.imread(img)\n    i.resize(256, 256, 3)\n    pred = model.predict(i.reshape(1, 256, 256, 3))\n    tempDf = pd.DataFrame({\n        'id': [img.split('\/')[-1]],\n        'has_cactus': [pred[0][0]]\n    })\n    df = df.append(tempDf)","bb7fb9df":"# # Removing the new directories created locally\n!rm -rf curated_data\/","3d3bd2d8":"df = df.set_index('id')\ndf.to_csv('submission.csv')","03ee17d3":"## Data preparation","875f9fec":"## Model Definition","451ec8fa":"This means, we need `8772` more samples in training for `has_no_cactus` category.\nThe solution is [Data Augumentation](https:\/\/towardsdatascience.com\/data-augmentation-experimentation-3e274504f04b)","c3515ef5":"Now, let's see how many training images are present per class","eb7480fd":"### Making directories\n1. `has_cactus`: Positive samples\n2. `has_no_cactus`: Negative samples","74827edd":"* Moved the curated data to `curated_data` directory\n* Created `validation_data` and `test_data` under curated data along with `train_data`","0dd607f2":"### Download `submission.csv` from here\n<a href='submission.csv'>Download Submission<\/a>","4c4ce7c2":"We'll try to use pre-trained model named `VGG16` with `imagenet` weights.","ceedbcb4":"## Analysis","9c551a42":"To curate the data and make it easier for training, will follow below steps.\n1. Read the `train.csv` file\n2. Read the labels from `train.csv` which are the `positive` (containing cactus) and `negative` (not containing cactus) images\n3. Create two different directories for positive and negative images\n4. Move positive images to positive dir and negative images to negative dir\n5. Train with `ImageDataGenerator`","0696a070":"## Data Augumentation\n1. We'll be adding the more images to the existing dataset\n2. After iterating over the images under no_cactus, we'll\n* Flip the image horizontally and save\n* Flip the image vertically and save\n3. We won't add it to the data frame since we are going to use ImageDataGenerator from keras","ded40238":"## Creating Data Generator","46c4087e":"Now, the number of images in both the directories is equal.\n\n\n| Class  | Number of images   |\n|---|---|\n|  `has_cactus` | 13136  |\n|  `has_no_cactus` | 13136  |","d1b8d330":"## Loading the `train.csv`"}}