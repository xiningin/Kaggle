{"cell_type":{"f519f34a":"code","65e197c6":"code","b25714c3":"code","4cbfd8f5":"code","ccf57698":"code","451eec11":"code","d119860c":"code","07bb6d50":"code","f01c426f":"code","eaa522a6":"code","6d7b4d0b":"code","1836c8be":"code","7db7167b":"code","f497bb35":"code","84281a10":"code","39e82a20":"code","531acb2a":"code","3fa3ecc6":"code","58614bbd":"code","bdcc66a0":"code","a1853da3":"code","4fd92b15":"code","0b535d0a":"code","b9ee4306":"code","eab59059":"code","561d01c0":"code","929195ef":"code","0fe99331":"code","e8791bc5":"code","a55e6f86":"code","d1df4b51":"code","7e11fd8d":"code","49e199d6":"code","858a224b":"code","d47c3348":"code","19c52be7":"code","11a55bfc":"code","de30ef72":"code","cb4299a7":"code","99a39035":"code","9accc576":"code","d202a419":"code","506fa3b2":"code","eee36c80":"code","fd17f9c3":"markdown","860c4068":"markdown","06ca3454":"markdown","51aace52":"markdown","cc79334c":"markdown","e1e94c78":"markdown","3f15aaa0":"markdown","b3600a3b":"markdown","051f6d1d":"markdown","3da10aaf":"markdown","4adbd323":"markdown","808576cb":"markdown","11d57f27":"markdown","b0ff6337":"markdown","2ef0242a":"markdown"},"source":{"f519f34a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65e197c6":"df=pd.read_csv(\"..\/input\/fake-news\/train.csv\")","b25714c3":"df.head()","4cbfd8f5":"x=df.drop('label',axis=1)","ccf57698":"x.head()","451eec11":"y=df['label']","d119860c":"y.head()","07bb6d50":"x.shape","f01c426f":"df=df.dropna()","eaa522a6":"df.shape","6d7b4d0b":"df.head(10)","1836c8be":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer","7db7167b":"message=df.copy()","f497bb35":"message.head(10)","84281a10":"message.reset_index(inplace=True)","39e82a20":"message.head(10)","531acb2a":"from nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nimport re\nps=PorterStemmer()\ncorpus=[]\n\nfor i in range(0,len(message)):\n    review=re.sub('[^a-zA-Z]',' ',message['title'][i])\n    review=review.lower()\n    review=review.split()\n    review=[word for word in review if not word in stopwords.words('english')]\n    review=' '.join(review)\n    corpus.append(review)","3fa3ecc6":"corpus","58614bbd":"cv=CountVectorizer(max_features=5000,ngram_range=(1,3))\nx=cv.fit_transform(corpus).toarray()","bdcc66a0":"x","a1853da3":"x.shape","4fd92b15":"y=message['label']","0b535d0a":"from sklearn.model_selection import train_test_split","b9ee4306":"xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=1)","eab59059":"cv.get_feature_names()[50:75]","561d01c0":"cv.get_params()","929195ef":"a_df=pd.DataFrame(xtrain,columns=cv.get_feature_names())","0fe99331":"a_df.head()","e8791bc5":"import matplotlib.pyplot as plt\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","a55e6f86":"from sklearn.naive_bayes import MultinomialNB","d1df4b51":"model=MultinomialNB()\nmodel.fit(xtrain,ytrain)","7e11fd8d":"from sklearn.metrics import accuracy_score\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\nypred=model.predict(xtest)\nscore=accuracy_score(ypred,ytest)\nscore*100","49e199d6":"con=confusion_matrix(ytest,ypred)\nplot_confusion_matrix(con,classes=['Fake','Real'])","858a224b":"from sklearn.linear_model import PassiveAggressiveClassifier","d47c3348":"mod=PassiveAggressiveClassifier(n_iter_no_change=50)\nmod.fit(xtrain,ytrain)","19c52be7":"from sklearn.metrics import accuracy_score\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\nypred=mod.predict(xtest)\nscore=accuracy_score(ypred,ytest)\nscore*100","11a55bfc":"con=confusion_matrix(ytest,ypred)\nplot_confusion_matrix(con,classes=['Fake','Real'])","de30ef72":"classifier=MultinomialNB(alpha=0.1)","cb4299a7":"from sklearn.metrics import accuracy_score\nprevious_score=0\nfor alpha in np.arange(0,1,0.1):\n    sub_classifier=MultinomialNB(alpha=alpha)\n    sub_classifier.fit(xtrain,ytrain)\n    y_pred=sub_classifier.predict(xtest)\n    score = accuracy_score(ytest, y_pred)\n    if score>previous_score:\n        classifier=sub_classifier\n    print(\"Alpha: {}, Score : {}\".format(alpha,score))","99a39035":"features=cv.get_feature_names()","9accc576":"features[:20]","d202a419":"classifier.coef_[0]","506fa3b2":"sorted(zip(classifier.coef_[0],features),reverse=True)[:20]","eee36c80":"sorted(zip(classifier.coef_[0],features))[:20]","fd17f9c3":"**This algorithm works well with text data**","860c4068":"# Passive agressive classifier","06ca3454":"**The 6th and 8th record is missing due to the deletion NaN records, we will try to re index that, so that will be useful for looping while processing the text**","51aace52":"# Hyperparameter tuning with MultinomialNB","cc79334c":"**Rows represent the sentences and columns represents the feature(words of high value(first 5000 feature) taken from the sentences)**","e1e94c78":"**Now x is having 5000 feature**","3f15aaa0":"**Get dependent feature**","b3600a3b":"**Most real words**","051f6d1d":"# Multinominal Naive Bayes algorithm","3da10aaf":"**Bag of words model using CountVectorizer**","4adbd323":"**we will see the top most real and fake words**","808576cb":"**Now all the indexes are in proper incremental order**","11d57f27":"# Train test split","b0ff6337":"# Text preprocessing","2ef0242a":"**Get independent feature**"}}