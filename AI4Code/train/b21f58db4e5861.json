{"cell_type":{"b0e5d42c":"code","29325ef8":"code","b27a490a":"code","10ce7e81":"code","4d434956":"code","460ccc3d":"code","cf0237cb":"code","d33d955b":"code","590facfa":"code","8526a626":"code","9774c392":"code","b5771e49":"code","0ace8564":"code","c9bce374":"code","0c24de15":"code","015ba864":"code","06e099c0":"code","a25ce283":"code","ec509171":"code","7b5ee220":"code","5e224ad4":"code","9a6991b6":"code","5e8186b8":"code","40e60fe6":"code","8a460dce":"markdown","af80e51f":"markdown","47c8aa26":"markdown","5f68fe0d":"markdown","38c207a1":"markdown","2cbbdfe5":"markdown","848edfaa":"markdown","173e7220":"markdown"},"source":{"b0e5d42c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nplt.style.use('ggplot') \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","29325ef8":"import os\nprint(os.listdir(\"..\/input\"))","b27a490a":"data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","10ce7e81":"data.head(10)","4d434956":"data.info()","460ccc3d":"data.describe()","cf0237cb":"#get correlations of each features in dataset\ndata.corr()","d33d955b":"# heatmap\nsns.heatmap(data.corr(), cmap=\"YlGnBu\" )","590facfa":"sns.countplot(x='Outcome', data=data)\nplt.title(\"Count plot for Target Variable\")","8526a626":"sns.pairplot(data=data,hue=\"Outcome\")","9774c392":"sns.catplot(x=\"Outcome\", y=\"Pregnancies\", \n            kind=\"violin\", split=True, \n            palette=\"ch:r=-.5,l=.75\",\n            inner=\"stick\", \n            data=data)","b5771e49":"sns.scatterplot(x='Age',  y='Pregnancies', hue='Outcome',\n                data= data, \n                legend = 'full',\n                palette=\"ch:r=-.7,l=.87\")","0ace8564":"# histograms\ndata.hist(figsize=(15,10))\nplt.figure();","c9bce374":"plt.boxplot([data['Age'], data['BMI']])","0c24de15":"def evaluation(y, y_pred):\n    print(\"MSE: {}\".format(mean_squared_error(y, y_pred)))\n    print(\"Accuracy Score:\", accuracy_score(y, y_pred))\n    print(\"Precision:\", precision_score(y, y_pred))\n    print(\"Recall:\", recall_score(y, y_pred))\n    print(\"F1 Score:\", f1_score(y, y_pred))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n    cm = pd.crosstab(y, y_pred)\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\")","015ba864":"y = np.array(data['Outcome'])\nX = np.array(data.drop(columns=['Outcome'], axis=1))","06e099c0":"# split dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","a25ce283":"# W\/O Scaling or Normalization\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\n\ny_pred = lr.predict(X_test)\nprint(\"Logistic regressin Report:\")\nevaluation(y_test,y_pred)","ec509171":"# With Standard Scaling \nSS = StandardScaler()\n\nX_train_scaled = SS.fit_transform(X_train)\nX_test_scaled = SS.transform(X_test)\n\nlr = LogisticRegression(max_iter=150)\nlr.fit(X_train_scaled,y_train)\n\ny_pred = lr.predict(X_test_scaled)\nprint(\"Logistic regressin Report (Standard Scaling):\")\nevaluation(y_test,y_pred)","7b5ee220":"# Normalize the data \nmeans = np.mean(X, axis=0)\nstds = np.std(X, axis=0)\n\nX_train_norm = (X_train - means)\/stds\nX_test_norm = (X_test- means)\/stds\n\nlr = LogisticRegression()\nlr.fit(X_train_norm,y_train)\n\ny_pred = lr.predict(X_test_norm)\nprint(\"Logistic regressin Report (Normalized Data):\")\nevaluation(y_test,y_pred)","5e224ad4":"# With MinMax Scaling \nMMS = MinMaxScaler()\n\nX_train_scaled = MMS.fit_transform(X_train)\nX_test_scaled = MMS.transform(X_test)\n\nlr = LogisticRegression()\nlr.fit(X_train_scaled,y_train)\n\ny_pred = lr.predict(X_test_scaled)\nprint(\"Logistic regressin Report (MinMax Scaling):\")\nevaluation(y_test,y_pred)","9a6991b6":"# Features: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age\n# get importance \nimportance = lr.coef_[0]\n# summarize feature importance for normalized model\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show();","5e8186b8":"penalty = ['l1', 'l2']\nC = [0.0001,0.001,0.01,0.1, 1, 10, 100, 1000]\nsolver = ['liblinear', 'saga']\n\nparam_grid = dict(penalty=penalty, C=C, solver=solver)\n\ngrid = GridSearchCV(estimator=lr, param_grid=param_grid, \n                    verbose=1, cv=10)\n\nbest_model = grid.fit(X_train_norm, y_train)","40e60fe6":"y_pred = best_model.predict(X_test_norm)\nevaluation(y_test, y_pred)","8a460dce":"**Data Scaling and Normalization perform the same so, I will try parameter tuning to see if it will perform better**\n","af80e51f":"#### **From the above figure, we can draw the following:**\n\n*   Glucose, BMI, Age, diabetes pedigree function and pregnancies have significant positive influence on the model, specially glucose level and BMI.\n\n*   Blood pressure and Insulin rate have a negative influence on the prediction","47c8aa26":"## **Predicting Diabetes using Logistic Regression**\n","5f68fe0d":"### **1. Import Libraries**","38c207a1":"#### **3. Data Exploration and Visualization**","2cbbdfe5":"#### **4. Data Modeling** ","848edfaa":"#### **5. Hyperparameter Tuning**","173e7220":"### **2. Load Dataset**\n\n#### **Dataset information**:\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n##### **Columns**:\n1. Pregnancies: Number of times pregnant\n2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n3. BloodPressure: Diastolic blood pressure (mm Hg)\n4. SkinThickness: Triceps skin fold thickness (mm)\n5. Insulin: 2-Hour serum insulin (\n6. BMI: Body mass index (Weight (kg)\/(Height (m)^2))\n7. DiabetesPedigreeFunction: Diabetes pedigree function\n8. Age: Age (years)\n9. Outcome: Class variable (0 or 1)\n\n##### Data Source: \n\n[pima-indians-diabetes-database](https:\/\/www.kaggle.com\/uciml\/pima-indians-diabetes-database)\n\n\n"}}