{"cell_type":{"f7ab4740":"code","372cfffd":"code","f73e36ce":"code","129ea27c":"code","bf92a800":"code","4b102ed6":"code","7048bad1":"code","c88a0dcf":"code","97d5911d":"code","c4b8a939":"code","74c5078c":"code","2426416c":"code","bd76ddd5":"code","c24d5c31":"code","42b274f0":"code","b2dec6bd":"code","9bc54105":"code","4cfdf97c":"code","5da0b438":"code","1663cc00":"code","7ae0f997":"code","b85566b8":"code","c4e4e6a6":"code","95bdf164":"code","77470e0e":"code","e461686d":"code","21f57d5a":"code","59a5c04d":"code","a4f7f10f":"code","c2282cdd":"code","1b581df9":"code","8519b2dc":"code","45e7e413":"code","75ef711a":"code","605e84af":"code","9fcda7eb":"code","9161a9cb":"code","332a5d4d":"code","4701d23a":"code","05be9b15":"code","848556a0":"code","e1d7bb73":"code","93406861":"code","7714c802":"code","4a428206":"code","c31f1352":"code","b06b29ba":"markdown","ab4cb77a":"markdown","fae3a55b":"markdown","a8bd5f37":"markdown","940f830e":"markdown","60b720d1":"markdown","69eec32d":"markdown","5ea6e4b5":"markdown","f3a7a7bf":"markdown","59077d59":"markdown","59b9452f":"markdown","97cd92b3":"markdown","e14cc57b":"markdown","bf2afcf2":"markdown","dfcfc961":"markdown","fe95561e":"markdown","06330760":"markdown","abd7839d":"markdown","ce2c5324":"markdown","450c3fa1":"markdown","77c9c3e2":"markdown","4f76d756":"markdown","2201efd5":"markdown","d09b7da2":"markdown","189ff743":"markdown","485ba31f":"markdown","05b14f02":"markdown","70b7a143":"markdown","24fd428a":"markdown","73c891a4":"markdown","53394b96":"markdown","ab608496":"markdown","c75983ff":"markdown","767e4164":"markdown","34ab314e":"markdown","be99a459":"markdown","4cae96db":"markdown"},"source":{"f7ab4740":"## Plotting Libaray\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n## Train and Test Split\nfrom sklearn.model_selection import train_test_split\n## Evaluation Matrics\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import MinMaxScaler\n# Oversample with SMOTE and random undersample for imbalanced dataset\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n## Models\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB","372cfffd":"## Load Data\nhdf = pd.read_csv (r'\/content\/healthcare-dataset-stroke-data.csv')\nhdf","f73e36ce":"print(\"Number of Rows:\", hdf.shape[0])\nprint(\"Number of Columns:\", hdf.shape[1])","129ea27c":"hdf.columns","bf92a800":"## Numerical Description\nhdf.describe()","4b102ed6":"## Object Description\nhdf.describe(include=['object'])","7048bad1":"hdf.isnull().sum()  ","c88a0dcf":"## Drop Null values\nhdf = hdf.dropna()","97d5911d":"## Stoke Cases\nstroke= hdf['stroke'].value_counts()\nstroke","c4b8a939":"sns.countplot(x = hdf['stroke'])","74c5078c":"## Total Genders\ngender= hdf['gender'].value_counts()\ngender","2426416c":"hdf = hdf[(hdf.gender != 'Other')]","bd76ddd5":"sns.countplot(x = hdf['gender'])","c24d5c31":"## Plot work type\nfig = px.pie(hdf, values=hdf['work_type'].value_counts().values, names=hdf['work_type'].value_counts().index,\n             title='Work type' ,\n             color_discrete_sequence=px.colors.sequential.Cividis_r\n            )\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","42b274f0":"## Plot Heart diesase w.r.t gender\nfig = px.pie(hdf, values='heart_disease', names='gender',\n             title='heart_disease Chart with respect to Gender' ,\n             color_discrete_sequence=px.colors.sequential.Aggrnyl\n            )\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","b2dec6bd":"## Plot Hyper tension w.r.t gender\nsns.catplot(x=\"hypertension\", col = 'stroke', data=hdf, kind = 'count', palette='rainbow')","9bc54105":"pd.crosstab([hdf[\"Residence_type\"]], hdf[\"stroke\"], margins = True).style.background_gradient(cmap = \"rainbow\")","4cfdf97c":"## Plot Residence_type w.r.t Stroke\nsns.catplot(x=\"Residence_type\", col = 'stroke', data=hdf, kind = 'count', palette='rainbow')","5da0b438":"## fetching only people with stoke\nhdfs = hdf[(hdf.stroke == 1)]","1663cc00":"## Ploting Graph of stroke w.r.t to gender and stoke\nfig = px.histogram(hdfs, x=\"age\", y=\"stroke\", color=\"gender\",\n                   hover_data=hdf.columns ,\n                   title = 'Sum Of Deaths With Respect to Specific Age and Gender' , \n                   color_discrete_sequence=px.colors.sequential.Blackbody,\n                   width=900 ,\n                   height=600)\nfig.show()","7ae0f997":"## categorical encoder\nhdf['gender'] =hdf['gender'].astype('category').cat.codes  \nhdf['ever_married'] =hdf['ever_married'].astype('category').cat.codes  \nhdf['work_type'] =hdf['work_type'].astype('category').cat.codes  \nhdf['Residence_type'] =hdf['Residence_type'].astype('category').cat.codes  \nhdf['smoking_status'] =hdf['smoking_status'].astype('category').cat.codes","b85566b8":"## Split dataset\nx = hdf.drop(['id','stroke'],axis=1)\ny = hdf[[ 'stroke']]","c4e4e6a6":"## Normalization\nsc = MinMaxScaler()\nx = sc.fit_transform(x)","95bdf164":"## Class Balancing\nover = SMOTE()\nunder = RandomUnderSampler()\nsteps = [('o', over), ('u', under)]\npipeline = Pipeline(steps=steps)\nx, y = pipeline.fit_resample(x, y)","77470e0e":"## Splitting into train and test data\nx_train , x_test , y_train , y_test = train_test_split (x , y , test_size = 0.3 , train_size = 0.7 , random_state = 12)\nprint (\"Train Data x Shape: \" , x_train.shape)\nprint (\"Test Data x Shape: \" , x_test.shape)\nprint (\"Train Data y Shape: \" , y_train.shape)\nprint (\"Test Data y Shape: \" , y_test.shape)","e461686d":"## Model Train\nrfc = RandomForestClassifier()\nrfc.fit(x_train , y_train)","21f57d5a":"## Model Prediction\nrfc_pred = rfc.predict(x_test)","59a5c04d":"print( \"Test Accuracy : \" , accuracy_score( y_test,rfc_pred)*100 , \"%\" )","a4f7f10f":"# Creating the confusion matrix:\nrf_cm = confusion_matrix(y_test, rfc_pred)\n\n# Visualization:\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(rf_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax, cmap='BrBG')\nplt.title('RF Classification Confusion Matrix')\nplt.xlabel('y_pred')\nplt.ylabel('y_test')\nplt.show()","c2282cdd":"## CLassification Report\nprint(classification_report(y_test, rfc_pred))","1b581df9":"lrc = LogisticRegression( n_jobs = -1 , C = 0.1 , penalty = 'l2' )\nlrc.fit(x_train , y_train)","8519b2dc":"lrc_pred = lrc.predict(x_test)","45e7e413":"print( \"Test Accuracy : \" , accuracy_score( y_test,lrc_pred)*100 , \"%\" )","75ef711a":"# Creating the confusion matrix:\nlrc_cm = confusion_matrix(y_test, lrc_pred)\n\n# Visualization:\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(lrc_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax, cmap='BrBG')\nplt.title('LR Classification Confusion Matrix')\nplt.xlabel('y_pred')\nplt.ylabel('y_test')\nplt.show()","605e84af":"print(classification_report(y_test, lrc_pred))","9fcda7eb":"svc = SVC()\nsvc.fit(x_train , y_train)","9161a9cb":"svc_pred = svc.predict(x_test)","332a5d4d":"print( \"Test Accuracy : \" , accuracy_score( y_test,svc_pred)*100 , \"%\" )","4701d23a":"# Creating the confusion matrix:\nsvc_cm = confusion_matrix(y_test, lrc_pred)\n\n# Visualization:\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(svc_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax, cmap='BrBG')\nplt.title('svc Classification Confusion Matrix')\nplt.xlabel('y_pred')\nplt.ylabel('y_test')\nplt.show()","05be9b15":"print(classification_report(y_test, svc_pred))","848556a0":"NB = GaussianNB()\nNB.fit(x_train , y_train)","e1d7bb73":"NB_pred = NB.predict(x_test)","93406861":"print( \"Accuracy : \" , accuracy_score(y_test,NB_pred)*100 , \"%\" )","7714c802":"# Creating the confusion matrix:\nNB_cm = confusion_matrix(y_test, lrc_pred)\n\n# Visualization:\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(NB_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax, cmap='BrBG')\nplt.title('NB Classification Confusion Matrix')\nplt.xlabel('y_pred')\nplt.ylabel('y_test')\nplt.show()","4a428206":"print(classification_report(y_test, NB_pred))","c31f1352":"Accuracy = pd.DataFrame({'RandomForestClassifier': accuracy_score(y_test,rfc_pred)*100,\n             'LogisticRegression':accuracy_score(y_test,lrc_pred)*100 ,\n             'SupportVectorMachine' : accuracy_score(y_test,svc_pred)*100,\n             'NaiveBayes': accuracy_score(y_test,NB_pred)*100} , index=[0])\nAccuracy","b06b29ba":"## This Shows Random Foest has the highest accuracy\n","ab4cb77a":"## Classification Report","fae3a55b":"## Visualizing either people from Urban or Rural People have stroke issues\n","a8bd5f37":"## Confusion Matrix","940f830e":"## Confusion Matrix","60b720d1":"## Summary of data","69eec32d":"## CLass Balancing\n\n### From the Pie chart of Stoke label we can see that class are very much Imbalance with with people having stroke is only while 4700 have no stroke. this causes problem in training model and can cause over fitting So for that class imbalancing technique are used i.e oversampling and undersampling\n\n\n\n*   SOMTE (OverSampling)\n*   RandomUnderSampler (Undersampling)\n\n","5ea6e4b5":"## Confusion Matrix","f3a7a7bf":"## Stroke w.r.t Age","59077d59":"## Description for Categorical Columns","59b9452f":"## Classification Report","97cd92b3":"## this Show at people after 70 has more strokes and espacially in females","e14cc57b":"## Convert Categoical values using cat labelencoder","bf2afcf2":"## Split Dataset","dfcfc961":"## Removing Other as it could as casue overfitting issue","fe95561e":"## Total Number of Storke Case","06330760":"## Logistic Regression","abd7839d":"### Applying Different Models on the Datasets","ce2c5324":"## Stroke Preditction\n\nThis is Classification Problem as we gonna classifiy either the person had stroke or not","450c3fa1":"## Scale the values\n\n### Normalization of Dataset is done through Minmax","77c9c3e2":"## Importing dataset\n","4f76d756":"## Total Accuracy","2201efd5":"## Classification Report","d09b7da2":"## Libariries","189ff743":"## Number of Male and Female in Dataset","485ba31f":"## Confusion Matrix","05b14f02":"## Visualizing Males and Females heart disease By Pie Plot\n","70b7a143":"## Exploratory Analysis","24fd428a":"## RandomForest","73c891a4":"## Number of Rows and Columns","53394b96":"## Work Type of People","ab608496":"## Visualizing Hyper tension and Non Hyper Tension having stroke\n","c75983ff":"## Classification Report","767e4164":"## Naive Bayes","34ab314e":"## Data Info Checking any Null Value","be99a459":"## Columns","4cae96db":"## SVC"}}