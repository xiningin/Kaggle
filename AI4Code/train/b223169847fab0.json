{"cell_type":{"d46c93f7":"code","787a28d8":"code","100b0014":"code","0ae48e9d":"code","b3c00847":"code","21f20d8c":"code","34249c0a":"code","a50b865b":"code","b3dbe8d0":"code","e76d74f6":"code","a6119de8":"code","b88c46ce":"code","8e6ae8d4":"code","fc98aa13":"code","c3224b21":"code","ab33290c":"code","c1810a63":"code","a0d74bb6":"code","bcd06b8f":"code","68b266aa":"code","7248d3f6":"code","622b8ebf":"code","7d6263a7":"code","aabcdeb4":"code","2f727c54":"code","6dafab91":"code","45fa8942":"code","35d16036":"code","90e823ab":"code","3ffbafd2":"code","f0d9ba41":"code","591566dd":"code","559fe05c":"code","12f8995b":"code","4879bbfa":"code","0c9c47de":"code","7f499c1b":"code","7b669c3a":"code","d4f8aca4":"code","161f9a52":"code","454e61cc":"code","5a16505b":"code","fa3f6fd9":"markdown","62ca63bf":"markdown","c829b3cd":"markdown","269245e4":"markdown"},"source":{"d46c93f7":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\ntf.__version__","787a28d8":"network = tf.keras.applications.VGG19(include_top=False, weights='imagenet')","100b0014":"network.summary()","0ae48e9d":"len(network.layers)","b3c00847":"import cv2 \nimport pandas as pd\ncontent_image = cv2.imread('..\/input\/style-transfer-and-object-detection\/crystal-kpop-girl-bw-wallpaper-preview.jpg')  \nplt.imshow(content_image)\nplt.show()","21f20d8c":"type(content_image), content_image.shape, content_image.min(), content_image.max()","34249c0a":"content_image = content_image \/ 255\ncontent_image.min(), content_image.max()","a50b865b":"content_image","b3dbe8d0":"content_image = content_image[tf.newaxis, :]\ncontent_image.shape","e76d74f6":"style_image = cv2.imread('..\/input\/style-transfer-and-object-detection\/Wallpapers-famous-painting-artist-painter-brush-oil-on-.jpg')\nplt.imshow(style_image)\nplt.show()","a6119de8":"style_image = style_image \/ 255\nstyle_image = style_image[tf.newaxis, :]\nstyle_image.shape","b88c46ce":"content_layers = ['block4_conv2']\nstyle_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']","8e6ae8d4":"num_content_layers = len(content_layers)\nnum_style_layers = len(style_layers)\nprint(num_content_layers, num_style_layers)","fc98aa13":"[network.get_layer(name).output for name in style_layers]","c3224b21":"network.input","ab33290c":"def vgg_layers(layer_names):\n    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n    vgg.trainable = False\n\n    outputs = [vgg.get_layer(name).output for name in layer_names]\n    network = tf.keras.Model(inputs = [vgg.input], outputs = outputs)\n\n    return network","c1810a63":"style_extractor = vgg_layers(style_layers)\nstyle_extractor.summary()","a0d74bb6":"style_extractor.outputs","bcd06b8f":"style_outputs = style_extractor(style_image)\nlen(style_outputs)","68b266aa":"style_outputs[1]","7248d3f6":"style_outputs[0].shape, style_outputs[1].shape, style_outputs[2].shape, style_outputs[3].shape, style_outputs[4].shape","622b8ebf":"def gram_matrix(layer_activation):\n    result = tf.linalg.einsum('bijc,bijd->bcd', layer_activation, layer_activation)\n    input_shape = tf.shape(layer_activation)\n    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n\n    return result \/ num_locations","7d6263a7":"style_outputs[0]","aabcdeb4":"gram_matrix(style_outputs[0])","2f727c54":"class StyleContentModel(tf.keras.models.Model):\n  def __init__(self, style_layers, content_layers):\n    super().__init__()\n    self.vgg = vgg_layers(style_layers + content_layers)\n    self.style_layers = style_layers\n    self.content_layers = content_layers\n    self.num_style_layers = len(style_layers)\n    self.vgg.trainable = False\n\n  def call(self, inputs):\n    inputs = inputs * 255.0\n    # 0 - 1\n    # -127.50 - 127.50\n    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n    outputs = self.vgg(preprocessed_input)\n    style_outputs = outputs[:self.num_style_layers]\n    content_outputs = outputs[self.num_style_layers:]\n\n    style_outputs = [gram_matrix(style_output) for style_output in style_outputs]\n\n    content_dict = {content_name: value for content_name, value in zip(self.content_layers, content_outputs)}\n    style_dict = {style_name: value for style_name, value in zip(self.style_layers, style_outputs)}\n\n    return {'content': content_dict, 'style': style_dict}","6dafab91":"style_layers, content_layers","45fa8942":"extractor = StyleContentModel(style_layers, content_layers)","35d16036":"results = extractor(content_image)\nresults","90e823ab":"for key, value in results.items():\n    print(key, value.keys())","3ffbafd2":"style_targets = extractor(style_image)['style']\ncontent_targets = extractor(content_image)['content']","f0d9ba41":"len(style_targets), len(content_targets)","591566dd":"new_image = tf.Variable(content_image)","559fe05c":"content_weight = 1\nstyle_weight = 100","12f8995b":"optimizer = tf.optimizers.Adam(learning_rate=0.001)","4879bbfa":"expected_output = np.array([10000, 15000])\npredictions = np.array([8000, 15900])","0c9c47de":"np.sum(abs(expected_output - predictions)) \/ 2","7f499c1b":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nmean_absolute_error(expected_output, predictions)","7b669c3a":"mean_squared_error(expected_output, predictions)","d4f8aca4":"((expected_output - predictions) ** 2).mean()","161f9a52":"plt.imshow(tf.squeeze(content_image, axis = 0));","454e61cc":"epochs = 3000\nprint_every = 250\n\nfor epoch in range(epochs):\n  with tf.GradientTape() as tape:\n    outputs = extractor(new_image)\n\n    content_outputs = outputs['content']\n    style_outputs = outputs['style']\n\n    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name] - content_targets[name]) ** 2) for name in content_outputs.keys()])\n    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name] - style_targets[name]) ** 2) for name in style_outputs.keys()])\n\n    total_loss = content_loss * content_weight \/ num_content_layers + style_loss * style_weight \/ num_style_layers\n\n  gradient = tape.gradient(total_loss, new_image)\n  optimizer.apply_gradients([(gradient, new_image)])\n\n  new_image.assign(tf.clip_by_value(new_image, 0.0, 1.0))\n\n  if (epoch + 1) % print_every == 0:\n    print('Epoch {} | content loss: {} | style loss: {} | total loss {}'.format(epoch + 1, content_loss, style_loss, total_loss))\n    plt.imshow(tf.squeeze(new_image, axis = 0))\n    plt.show()","5a16505b":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30,8))\nax1.axis('off')\nax1.imshow(tf.squeeze(content_image, axis = 0))\nax1.set_title('Content image')\nax2.axis('off')\nax2.imshow(tf.squeeze(new_image, axis = 0))\nax2.set_title('New image')\nax3.axis('off')\nax3.imshow(tf.squeeze(style_image, axis = 0))\nax3.set_title('Style image');","fa3f6fd9":"# Building the neural network","62ca63bf":"# Loading and pre-processing the images","c829b3cd":"## Style image","269245e4":"## Content image"}}