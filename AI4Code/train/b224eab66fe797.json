{"cell_type":{"eae94003":"code","c359ed78":"code","850e3d65":"code","691ddae7":"code","7aa77538":"code","f25fb449":"code","6197e799":"code","d6e9a3a1":"code","74464b85":"code","59f65de7":"code","17c4e7fe":"code","1dcb16b3":"code","d2dc252d":"code","36114488":"code","2bf361c5":"code","6c9ea1b0":"code","d311de9d":"code","14aee336":"code","7d451a9b":"code","9685851d":"code","7dfe36c1":"code","513dfa8f":"code","006151bc":"code","b172355a":"code","2c4a9bc5":"code","b2e2f1a6":"code","2b1df981":"code","d1dc2618":"code","d8c87ecb":"code","8c57a1e5":"code","5293484b":"code","ce754c87":"code","1293751c":"code","d6273798":"code","9a3a0625":"code","e41f8561":"code","0b068922":"code","7a21fc48":"code","6fd68a37":"code","92c1434a":"code","5cec420f":"code","07bc522d":"code","6da817b5":"code","baa937ec":"code","ca649116":"code","2a86f927":"code","a96e5e5e":"code","d07ff70d":"code","b528e2a9":"code","829d9c17":"code","7cefa16e":"code","b435b568":"code","8ab2bdf2":"code","de2688a5":"code","09a06054":"code","904131ec":"code","587aa076":"code","3c97ab71":"code","ab2cac93":"code","a1d35224":"code","7147ab75":"markdown","14924261":"markdown","488fbff4":"markdown","80230f32":"markdown","0228f61b":"markdown","0aadd028":"markdown","7d178e7d":"markdown","4b769365":"markdown","ea295787":"markdown","49bfb30f":"markdown","9a8b4f2b":"markdown","0718b63c":"markdown","8ec95b2a":"markdown","f08c43ed":"markdown","afefb52d":"markdown","c7cf2da1":"markdown","0e22a558":"markdown","0514e2e2":"markdown","25c827e7":"markdown"},"source":{"eae94003":"# suppress display of warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 'Pandas' is used for data manipulation and analysis\nimport pandas as pd \n\n# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\nimport numpy as np\n\n# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\nimport matplotlib.pyplot as plt\n\n# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\nimport seaborn as sns\n\n# import various functions to perform regression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesRegressor\n\n#importing metrics for tabulating the result\nfrom sklearn.metrics import mean_squared_log_error\n\n#setting the plot size using rcParams\nplt.rcParams['figure.figsize'] = [15,8]","c359ed78":"df = pd.read_csv('..\/input\/car-prices-dataset\/train.csv')\ndf_test = pd.read_csv('..\/input\/car-prices-dataset\/test.csv')","850e3d65":"df.head()","691ddae7":"df_test.head()","7aa77538":"#Understanding the shape of the data\ndf.shape","f25fb449":"#assigning the target variable\ny=df['Price']","6197e799":"#Concatenting both the test and train datasets together so that we can perform all the rectification tasks on both the data together\ndf = df.drop(['Price'],axis=1)\ndf_test=df_test.drop(['Price'],axis=1)\ndf_merge = df.append(df_test)\ndf_merge.reset_index(inplace=True)\ndf_merge= df_merge.drop(['index'],axis=1)","d6e9a3a1":"#checking the shape of the merged dataset\ndf_merge.shape","74464b85":"#checking the dtypes and Unique values\ninfo = pd.DataFrame()\ninfo['DataTypes'] = df_merge.dtypes\ninfo['Unique_values'] = df_merge.nunique()\ninfo","59f65de7":"df_merge.describe(include='object')","17c4e7fe":"df_merge.describe(include=np.number)","1dcb16b3":"#removing the 'km' from the mileage column and converting it to float\ndf_merge['Mileage'] = pd.to_numeric(df_merge.Mileage.str.split(' ').str[0], downcast='float')","d2dc252d":"#replacing all the '0' values with the mean values of the 'Mileage' column\ndf_merge['Mileage'] = np.where(df_merge['Mileage'] == 0.0,df_merge['Mileage'].mean(),df_merge['Mileage'])","36114488":"#checking the unique values of 'Doors' column\ndf_merge['Doors'].unique()","2bf361c5":"#cleaning the Doors column\ndf_merge['Doors'] = np.where((df_merge['Doors'] == '04-May') | (df_merge['Doors'] == '02-Mar'), df_merge['Doors'].str.split('-').str[0],df_merge['Doors'])","6c9ea1b0":"#checking the unique values of 'Doors' column after cleaning\ndf_merge['Doors'].unique()","d311de9d":"#checking the unique values of 'Levy' column after cleaning\ndf_merge['Levy'].unique()","14aee336":"#converting the Levy column to float as it is the Tax \ndf_merge['Levy'] = pd.to_numeric(df_merge['Levy'].replace('-', '0'), downcast='float')","7d451a9b":"#Replacing the 0 in the 'Levy' column with mean of that column\ndf_merge['Levy'] = np.where(df_merge['Levy'] == 0.0,df_merge['Levy'].mean(),df_merge['Levy'])","9685851d":"#checking the unique values in the 'Engine volume' column\ndf_merge['Engine volume'].unique()","7dfe36c1":"#We can see that there are some values with 'Turbo' and some values without 'Turbo'\n#So we remove the word 'Turbo' from all records that have it\ndf_merge['Engine volume'] = pd.to_numeric(df_merge['Engine volume'].str.split(' ').str[0], downcast='float')","513dfa8f":"#Replacing the '0' in the 'Engine volume' column with the mean value of that column\ndf_merge['Engine volume']=np.where(df_merge['Engine volume'] == 0.0,df_merge['Engine volume'].mean(),df_merge['Engine volume'])","006151bc":"#Feature engineering the production year column\nimport datetime as dt\ncurrt_time = dt.datetime.now()\ndf_merge['Prod. year'] = currt_time.year - df_merge['Prod. year'] ","b172355a":"#Checking the dataset after all the retification\ndf_merge.head()","2c4a9bc5":"sns.heatmap(df_merge.isnull(),cbar=False)\nplt.show","b2e2f1a6":"sns.heatmap(df_merge.corr(), cbar=True, annot=True)\n","2b1df981":"#distribution of numeric variables\ndf_merge.hist()\nplt.tight_layout()\nplt.show()","d1dc2618":"#shapiro test to check the skewness of the target variable\nfrom scipy.stats import shapiro\nx = shapiro(y)\nif x[1] <= 0:\n    print('Negatively skewed')\nelse:\n    print('Positively Skewed')\n  ","d8c87ecb":"#As from the shapiro test we can see that 'Price' column is negatively skewed we need to normlize it\ny = np.log(y)","8c57a1e5":"categ = df_merge.select_dtypes(include='object')\nnum = df_merge.select_dtypes(include = np.number)","5293484b":"#getting dummies for the categorical variables\ncat_dummies = pd.get_dummies(categ,drop_first=True)","ce754c87":"#creating the final dataset\ndf_final = pd.concat([num,cat_dummies], axis=1)","1293751c":"#checking the shape of the final dataset\ndf_final.shape","d6273798":"#segregating the training and test data before model building\ntrain_data = df_final.iloc[:19237]\ntrain_data.shape","9a3a0625":"test_data = df_final.iloc[19237:]\ntest_data.shape","e41f8561":"#splitting the data into test and train\nX = train_data\nY=y\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=10)\n","0b068922":"#Randomized Search CV for searching the best parameters\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","7a21fc48":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","6fd68a37":"rf_model = RandomForestRegressor()","92c1434a":"rf_random_model = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","5cec420f":"rf_random_model.fit(X_train,y_train)","07bc522d":"#getting the best parameters\nrf_random_model.best_params_","6da817b5":"reg= ExtraTreesRegressor()\nreg.fit(X_train,y_train)\nExtraTreesRegressor()","baa937ec":"#finding important features\nfeat_importances = pd.Series(reg.feature_importances_, index=X_train.columns)","ca649116":"pd.DataFrame(feat_importances.nlargest(30)).index","2a86f927":"#instantiating the randomforest regressor using the best parameters\nmod4 = RandomForestRegressor(n_estimators= 1000, max_depth= 25,\n max_features= 'sqrt',\n min_samples_leaf=1,\n min_samples_split = 2\n )","a96e5e5e":"X1 = train_data[['Airbags', 'Mileage', 'Prod. year', 'ID', 'Gear box type_Tiptronic',\n       'Leather interior_Yes', 'Levy', 'Fuel type_Diesel', 'Engine volume',\n       'Manufacturer_HYUNDAI', 'Fuel type_Hybrid', 'Color_White',\n       'Color_Black', 'Drive wheels_Front', 'Model_FIT', 'Color_Grey',\n       'Color_Silver', 'Cylinders', 'Wheel_Right-hand drive', 'Category_Sedan',\n       'Manufacturer_TOYOTA', 'Category_Jeep', 'Gear box type_Variator',\n       'Manufacturer_SSANGYONG', 'Fuel type_Petrol', 'Drive wheels_Rear',\n       'Model_Prius']]\ny1=y\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1,y1, test_size=0.3, random_state=10)","d07ff70d":"#fitting the model\nmodel = mod4.fit(X1_train, y1_train)","b528e2a9":"#predicting the data\ny_predict=model.predict(X1_test)","829d9c17":"#calculating the RMLSE score\nRMLSE=np.sqrt(mean_squared_log_error(np.exp(y1_test),np.exp(y_predict)))","7cefa16e":"#Printing the RMLSE score\nRMLSE","b435b568":"mod3 = RandomForestRegressor(n_estimators= 1000, max_depth= 25,\n max_features= 'sqrt',\n min_samples_leaf=1,\n min_samples_split = 2\n )","8ab2bdf2":"model_random = mod3.fit(X_train, y_train)","de2688a5":"feat_importances = pd.Series(model_random.feature_importances_, index=X_train.columns)","09a06054":"pd.DataFrame(feat_importances.nlargest(50)).index","904131ec":"X2=train_data[['Airbags', 'Mileage', 'Prod. year', 'ID', 'Gear box type_Tiptronic',\n       'Leather interior_Yes', 'Levy', 'Fuel type_Diesel', 'Engine volume',\n       'Manufacturer_HYUNDAI', 'Fuel type_Hybrid', 'Color_White',\n       'Color_Black', 'Drive wheels_Front', 'Model_FIT', 'Color_Grey',\n       'Color_Silver', 'Cylinders', 'Wheel_Right-hand drive', 'Category_Sedan',\n       'Manufacturer_TOYOTA', 'Category_Jeep', 'Gear box type_Variator',\n       'Manufacturer_SSANGYONG', 'Fuel type_Petrol', 'Drive wheels_Rear',\n       'Model_Prius', 'Color_Blue', 'Category_Hatchback']]\nY2=y\n\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2,Y2, test_size=0.3, random_state=10)","587aa076":"model1 = mod4.fit(X2_train, y2_train)","3c97ab71":"y_pred=model1.predict(X2_test)","ab2cac93":"RMLSE1=np.sqrt(mean_squared_log_error(np.exp(y2_test),np.exp(y_pred)))","a1d35224":"RMLSE1","7147ab75":"#  Feature selection using  extra tree regressor","14924261":"We need to convert 'Mileage' column into float as we know that it is of float\/integer datatype.","488fbff4":"# Importing Librabries","80230f32":"# Rectifying the data","0228f61b":"# Approach\n","0aadd028":"We can see that 'Engine volume' is having high correlation with 'Cylinders' and 'Levy' columns. ","7d178e7d":"Importing the data","4b769365":"# Finding best features using random forest regressor","ea295787":"Since we need to find features to train the model so that it neither gets underfitted or overfitted, we use feature selection technique.The best feature selection technique that worked for this problem statement is using extra tree regressor.","49bfb30f":"We can see that there are no missing values","9a8b4f2b":"From the above display we can see that:\n\n1)The 'Levy' column contains '-' symbol.We need to look into this column.\n\n2)In the 'Doors' column there are month names which we need to remove.\n\n3)In the 'Mileage' column there is 'km' written, we need to seperate this 'km' for model building purpose.\n\n4)We need to delete the 'Price' column as we need to predict it.","0718b63c":"# Understanding the data","8ec95b2a":"# Building the model","f08c43ed":"From the above display we can see that:\n\n1)The 'Levy' column contains '-' symbol.We need to look into this column.\n\n2)In the 'Doors' column there are month names which we need to remove.\n\n3)In the 'MIleage' column there is 'km' written, we need to seperate this 'km' for model building purpose.","afefb52d":"We can see that 'Prod. year','Levy' and 'Engine volume' columns are right skewed.","c7cf2da1":"# Extrapolatory Data Analysis ","0e22a558":"We can see that there are 19237 records and 18 rows","0514e2e2":"From the describe() function we can get the mean,count and quantiles values for numeric data and count,frequency of object type data. From the above displays it can be seen that there are no missing values.","25c827e7":"1)Each column of the datasets were checked for any data inconsistency.\n\n2)Required actions were taken for specific columns where data inconsistencies were found.\n\n3)Different regression algorithms were used to build different models.\n\n4) __RandomForestRegressor__ gave us the best model.So the .ipynb file contains only the random forest models.\n\n5)Tuning of hyperparameters were required for random forest regressor to optimize the RMSLE value.\n\n6)Best features were selected using VIF,RFE,forward elimnation,backward elimination,random forest and extra trees techniques. Features extracted using extra trees technique gave us the best model."}}