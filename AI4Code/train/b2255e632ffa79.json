{"cell_type":{"2571aa0c":"code","52ea231a":"code","27f550a7":"code","817d2843":"code","9d18316f":"code","0131d78b":"code","bd6c1f34":"code","fbb18530":"code","75bc30bc":"code","ab96f00c":"code","1dfc1b08":"code","2c76c140":"code","a38b8210":"code","4cec753c":"code","ae5d0e8f":"code","7c8080dd":"code","05bf694f":"markdown","b7828e98":"markdown"},"source":{"2571aa0c":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","52ea231a":"# Hyperparameters\nnum_epochs = 6\nnum_classes = 10\nbatch_size = 100\nlearning_rate = 0.01","27f550a7":"train_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\", dtype=np.float32)\ntest_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\", dtype=np.float32)\nsample_sub = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")","817d2843":"train_df.shape","9d18316f":"y = train_df.label.values\nX0 = train_df.loc[:, train_df.columns != 'label'].values\/255\n\nX0.shape, y.shape","0131d78b":"X = X0.reshape((-1, 1, 28, 28))\n\nX.shape","bd6c1f34":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nX_train.shape, X_test.shape","fbb18530":"XTrain = torch.from_numpy(X_train)\nyTrain = torch.from_numpy(y_train).type(torch.LongTensor)\n\nXTest = torch.from_numpy(X_test)\nyTest = torch.from_numpy(y_test).type(torch.LongTensor)","75bc30bc":"train = TensorDataset(XTrain, yTrain)\ntest = TensorDataset(XTest, yTest)\n\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)","ab96f00c":"class ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.drop_out = nn.Dropout()\n        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.drop_out(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out\n\n\nmodel = ConvNet()","1dfc1b08":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","2c76c140":"total_step = len(train_loader)\nloss_list = []\nacc_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        # Run the forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss_list.append(loss.item())\n\n        # Backprop and perform Adam optimisation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Track the accuracy\n        total = labels.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        correct = (predicted == labels).sum().item()\n        acc_list.append(correct \/ total)\n\n        if (i + 1) % 100 == 0:\n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))","a38b8210":"# Test the model\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the model on test images: {} %'.format((correct \/ total) * 100))","4cec753c":"Xt = (test_df.values\/255).reshape((-1, 1, 28, 28))\nXt.shape","ae5d0e8f":"model.eval()\nwith torch.no_grad():\n    sample_sub['Label'] = model(torch.from_numpy(Xt)).argmax(dim=1)\n    \nsample_sub.head()","7c8080dd":"sample_sub.to_csv(\"submission.csv\", index=False)","05bf694f":"#### Prediction","b7828e98":"#### Create Model"}}