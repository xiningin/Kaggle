{"cell_type":{"da458839":"code","2fa30d90":"code","d340bcc9":"code","9fdec6cd":"code","05d7d214":"code","458dc395":"code","5f6af4e3":"code","538310b0":"code","49c34c3f":"code","8aeafcc7":"code","f69512df":"code","8ea35651":"code","f88d33ba":"code","a7d30870":"code","1bc5abd5":"code","aeefdd7f":"code","f393fc51":"code","82f0eb4c":"code","bb3fbaf3":"code","51928c1c":"code","66204572":"code","346a89c1":"code","6f093b59":"code","b3701693":"code","d4b51f8d":"code","56a3aeb4":"code","bbd6b95c":"code","348fda66":"code","bf1d07bc":"markdown","a4174540":"markdown","2da1f7ee":"markdown","34b9da75":"markdown"},"source":{"da458839":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fa30d90":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB,MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nimport numpy as np\nimport matplotlib.pyplot as plt","d340bcc9":"df=pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","9fdec6cd":"df.head()","05d7d214":"df.info()","458dc395":"df.describe()","5f6af4e3":"df.drop([\"time\"],axis=1,inplace=True)","538310b0":"df.head()","49c34c3f":"y=df['DEATH_EVENT']\nx=df.iloc[0:,:11]","8aeafcc7":"x.head()","f69512df":"y.head()","8ea35651":"x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=2,test_size=.20)","f88d33ba":"scale=StandardScaler()\nx_train_scale=scale.fit_transform(x_train)\nx_test_scale=scale.transform(x_test)","a7d30870":"rn=RandomForestClassifier()\nrn.fit(x_train_scale,y_train)\nrn.score(x_test_scale,y_test)","1bc5abd5":"for i in range(2,11):\n    kn=KNeighborsClassifier()\n    kn.fit(x_train_scale,y_train)\n    print(i,kn.score(x_test_scale,y_test))","aeefdd7f":"lg=LogisticRegression()\nlg.fit(x_train_scale,y_train)\nlg.score(x_test_scale,y_test)","f393fc51":"sv=SVC(kernel=\"poly\")\nsv.fit(x_train_scale,y_train)\nsv.score(x_test_scale,y_test)","82f0eb4c":"sv=SVC()\nsv.fit(x_train_scale,y_train)\nsv.score(x_test_scale,y_test)","bb3fbaf3":"sv=SVC(kernel=\"linear\")\nsv.fit(x_train_scale,y_train)\nsv.score(x_test_scale,y_test)","51928c1c":"nv=BernoulliNB()\nnv.fit(x_train_scale,y_train)\nnv.score(x_test_scale,y_test)","66204572":"dt=DecisionTreeClassifier()\ndt.fit(x_train_scale,y_train)\ndt.score(x_test_scale,y_test)","346a89c1":"from keras.models import Sequential\nfrom keras.layers import Dense","6f093b59":"model=Sequential()\nhidden1=Dense(units=32,activation='relu')\nhidden2=Dense(units=56,activation='relu')\nhidden3=Dense(units=26,activation='relu')\nhidden4=Dense(units=46,activation='relu')\nout=Dense(units=1,activation='relu')\nmodel.add(hidden1)\nmodel.add(hidden2)\nmodel.add(hidden3)\nmodel.add(hidden4)\nmodel.add(out)","b3701693":"model.compile(optimizer='adam',loss='mean_absolute_error',metrics=['accuracy'])","d4b51f8d":"history=model.fit(np.asarray(x_train_scale),np.asarray(y_train),epochs=100,batch_size=10, \n          validation_data=(np.asarray(x_test_scale),np.asarray(y_test)))","56a3aeb4":"model.evaluate(np.asarray(x_test_scale),np.asarray(y_test))","bbd6b95c":"model.summary()","348fda66":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","bf1d07bc":"# Spliting and Scaling the data","a4174540":"# Applying ML algos","2da1f7ee":"# Creating Neural Network","34b9da75":"# **Data Describing**"}}