{"cell_type":{"aaff4e42":"code","28074b0b":"code","79d2d4b9":"code","c7d10444":"code","53faacbd":"code","1b077418":"code","27f6f13e":"code","cf011d50":"code","607203d2":"code","bffd623d":"code","f36f0197":"code","abd945a8":"code","317c6efa":"code","284d831e":"code","343176c6":"code","17ba2eb6":"code","56447b81":"code","75c2d34b":"code","705f4aa5":"code","58bdd2c9":"code","299d9e76":"code","bda9ac46":"code","d2e56fa5":"code","d25fcbd1":"code","59372c1c":"code","fd45e57b":"code","a4911230":"code","00db335b":"code","2af74ebb":"code","cb0e3ad9":"code","39abe4ce":"code","c0a25b78":"code","557e46d0":"code","12a34cae":"code","48f8fd98":"code","de1cf901":"code","4bd55444":"code","3480b4d6":"code","8953b99c":"code","e52c67e5":"code","5390c278":"code","45592fd0":"code","926bbd9c":"code","c037680d":"code","75ba7d58":"code","054db6ad":"code","3c7b6742":"code","23d40864":"code","15b1de5d":"code","f5b9d44e":"code","233f2645":"code","b97c543b":"code","3975a64a":"code","29c0c32c":"code","78b347f5":"code","adc021f2":"code","4601fafc":"code","eb82aa61":"code","5d6af732":"code","4b79f9f5":"code","7bc7ca70":"code","1cb3ece6":"markdown","c13d81af":"markdown","1352618b":"markdown","785cf175":"markdown","740aa084":"markdown","9abc9c80":"markdown","b3ae1054":"markdown","8131434c":"markdown","bf0fdf91":"markdown","afdb7f7c":"markdown","484cdfee":"markdown","7e039104":"markdown"},"source":{"aaff4e42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","28074b0b":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_orig = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","79d2d4b9":"train.head()","c7d10444":"train.corr()","53faacbd":"train.isnull().any()","1b077418":"from pandas_profiling import ProfileReport\nprof = ProfileReport(train)\nprof.to_file(output_file='output.html')","27f6f13e":"train[train[\"Age\"].isnull()]","cf011d50":"import seaborn as sns\n\nsns.distplot(train[\"Age\"])","607203d2":"train[\"Age\"].max()","bffd623d":"train[\"Age\"].min()","f36f0197":"train[\"Age\"].median()","abd945a8":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())","317c6efa":"sns.distplot(train[\"Age\"])","284d831e":"train_orig[\"Age\"].mean()","343176c6":"train_orig[\"Age\"] = train_orig[\"Age\"].fillna(train[\"Age\"].mean())","17ba2eb6":"sns.distplot(train_orig[\"Age\"])","56447b81":"train[train[\"Embarked\"].isnull()]","75c2d34b":"train[\"Embarked\"][train[\"Embarked\"].isnull()] =\"S\"","705f4aa5":"train.isnull().any()","58bdd2c9":"train=train.drop(\"Cabin\", axis=1)","299d9e76":"train=train.drop(\"Name\", axis=1)","bda9ac46":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_orig = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","d2e56fa5":"test.isnull().any()","d25fcbd1":"sns.distplot(test[\"Age\"])","59372c1c":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())","fd45e57b":"sns.distplot(test[\"Age\"])","a4911230":"test[test[\"Fare\"].isnull()]","00db335b":"test[\"Fare\"][test[\"Pclass\"]==3].median()","2af74ebb":"test[\"Fare\"][test[\"Fare\"].isnull()]=test[\"Fare\"][test[\"Pclass\"]==3].median()","cb0e3ad9":"test= test.drop(\"Cabin\",axis=1)","39abe4ce":"test= test.drop(\"Name\",axis=1)","c0a25b78":"train.columns","557e46d0":"test.columns","12a34cae":"train[\"Sex\"].unique()","48f8fd98":"test[\"Sex\"].unique()","de1cf901":"train.dtypes","4bd55444":"columns_to_onehot = [\"Sex\", \"Embarked\"]\ncolumns_to_label=[\"Ticket\"]","3480b4d6":"train[\"Ticket\"]","8953b99c":"train=pd.get_dummies(train, columns=columns_to_onehot)","e52c67e5":"train","5390c278":"test=pd.get_dummies(test, columns=columns_to_onehot)","45592fd0":"test","926bbd9c":"test.dtypes","c037680d":"from sklearn.preprocessing import LabelEncoder\n\nle= LabelEncoder()\n","75ba7d58":"train[\"Ticket\"]=le.fit_transform(train[\"Ticket\"])\ntest[\"Ticket\"]=le.fit_transform(test[\"Ticket\"])","054db6ad":"pi = test[\"PassengerId\"]","3c7b6742":"train = train.drop(\"PassengerId\", axis=1)","23d40864":"test = test.drop(\"PassengerId\", axis=1)","15b1de5d":"X_train = train.drop(\"Survived\", axis=1)\ny_train = train[\"Survived\"]\nX_test = test","f5b9d44e":"X_train","233f2645":"y_train","b97c543b":"X_test","3975a64a":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L","29c0c32c":"model = Sequential(name='titanic_model')\n\nmodel.add(L.InputLayer(input_shape=(11,))) # necessary to use model.summary()\n\nmodel.add(L.Dense(2048, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(1024, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(512, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(128, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(64, activation='relu'))\n\nmodel.add(L.Dense(32, activation='relu'))\nmodel.add(L.Dense(1, activation='sigmoid')) # output layer, use sigmoid for binary\n\nmodel.summary()","78b347f5":"model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['accuracy'])","adc021f2":"history = model.fit(X_train, y_train,\n                    batch_size=16, \n                    epochs=500)","4601fafc":"import matplotlib.pyplot as plt\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['loss'])\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'acc'], loc='upper left')\nplt.show()\n","eb82aa61":"preds = model.predict(test)","5d6af732":"preds","4b79f9f5":"submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\nsubmission['Survived'] = [0 if pred < 0.5 else 1 for pred in preds]\nsubmission.head(20)","7bc7ca70":"from IPython.display import FileLink\n\n\nsubmission.to_csv('submission.csv',index=False)\nFileLink(r'submission.csv')","1cb3ece6":"We build our neural network model. Going from high neuron count to low usually increases our performance.\n\nWe use droput because we try to avoid overfitting.","c13d81af":"We have 3 missing features. Let's use the \"pandas_profilling\" library for a closer look. (It didn't work on my personal computer due to version problems, but I will share the file with you.)","1352618b":"We fill the Age's missing values with median. But otherway we can fill with mean. It is a matter of distribution, but below you can see that the distribution does not matter much when changed either way.","785cf175":"We are looking at correlations. The important thing for us is the \"Survived\" column that we will predict.\n\nThe correlation increases as it approaches 1. This shows that there is a linear link between the two variables. (It doesn't matter if it is negative, only the direction of linearity is changing.)","740aa084":"We are looking at the first five lines in our data. This way we can recognize features.","9abc9c80":"We're deleting the Cabin column because there are too many minus values.","b3ae1054":"We fill  the Embarked's missing values with \"S\" I prefer it because it is the most frequently used.","8131434c":"In order for our model to work and perform better, we have to deal with missing data.","bf0fdf91":"We will keep Passenger_Id separate and use it for Submission.","afdb7f7c":"We want to give numerical values to our model, we convert the object type values to numeric values.\nWe use one_hot for those with lesser values.\nWe use one_hot for those with many different values","484cdfee":"# We do the same for test data as we do on train data.","7e039104":"First of all, we import to the train data as \"train\" and \"train_orig\". \"train_orig\" same as \"train\" for if we do something wrong, we can access the original train data."}}