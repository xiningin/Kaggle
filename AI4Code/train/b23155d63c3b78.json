{"cell_type":{"71fb731e":"code","aa136627":"code","378254bc":"code","497c1d7c":"code","d58533e1":"code","597e926c":"code","2ee07a64":"code","ed7f8fc8":"code","72069c3d":"code","bda61dc3":"code","5cec0a55":"code","7979b1c4":"code","28dda93a":"code","b39a5cfb":"code","f1615f2a":"code","b19c0e1e":"code","7de011c4":"code","e270d2d7":"code","ce4e08f8":"code","08698e32":"code","b4526ea9":"code","54a89137":"code","fec40e7d":"code","d6a201ca":"code","45bf74fb":"code","68e82802":"code","6b2e01dc":"code","4899c522":"code","efff7ca0":"code","e1eefedc":"code","1626c037":"markdown","e6020ae3":"markdown","00262210":"markdown","a35e73d1":"markdown","e0f60aec":"markdown","a0f2e3e8":"markdown","c938de21":"markdown","8dcae2fb":"markdown","b082f77a":"markdown","6c04b2c4":"markdown","68feae8f":"markdown","101a9dca":"markdown","fe3eaa65":"markdown","f7a37873":"markdown","173e79e1":"markdown","349c5fe1":"markdown","f52fe84f":"markdown","f7f3a01e":"markdown","d2a0db8d":"markdown","3582d084":"markdown","de11ed38":"markdown","e08b75cd":"markdown","367996c3":"markdown","c38c2633":"markdown","10bb5e53":"markdown"},"source":{"71fb731e":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom matplotlib impoty pyplot as plt\nimport seaborn as sns\n\nfrom category_encoders.ordinal import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aa136627":"train_df = pd.read_csv('..\/input\/kakr-4th-competition\/train.csv')\ntest_df = pd.read_csv('..\/input\/kakr-4th-competition\/test.csv')","378254bc":"train_df.drop(['id'], axis=1, inplace=True)\ntest_df.drop(['id'], axis=1, inplace=True)","497c1d7c":"y = train_df['income'] != '<=50K'\nX = train_df.drop(['income'], axis=1)","d58533e1":"LE_encoder = OrdinalEncoder(list(X.columns))\n\nX = LE_encoder.fit_transform(X, y)\ntest_df = LE_encoder.transform(test_df)","597e926c":"X['income'] = y\nX.head(5)","2ee07a64":"test_df['native_country'] = test_df['native_country'].astype(np.int64)","ed7f8fc8":"y_train = X['income'].values\nX_train = X.drop(['income'], axis=1).values\nX_test = test_df.values","72069c3d":"class Model_Creation(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n        \n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n        \n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self, x, y):\n        return self.clf.fit(x, y)\n    \n    def feature_importances(self, x, y):\n        print(self.clf.fit(x, y).feature_importances_)","bda61dc3":"train_size = train_df.shape[0]\ntest_size = test_df.shape[0]\nSEED = 0\nNFOLDS = 5\nkf = KFold(n_splits=NFOLDS, random_state=SEED)\n\ndef get_scores(clf, x_train_get, y_train_get, x_test_get):\n    pred_train = np.zeros((train_size,))\n    pred_test = np.zeros((test_size,))\n    pred_test_kfold = np.empty((NFOLDS, test_size))\n        \n    for i, (train_index, val_index) in enumerate(kf.split(x_train_get)):\n        x_train = x_train_get[train_index]\n        y_train = y_train_get[train_index]\n        x_val = x_train_get[val_index]\n        \n        clf.train(x_train, y_train)\n        \n        pred_train[val_index] = clf.predict(x_val)\n        pred_test_kfold[i, :] = clf.predict(x_test_get)\n        \n    pred_test[:] = pred_test_kfold.mean(axis=0)\n    \n    pred_train = pred_train.astype(int)\n    pred_test = pred_test.astype(int)\n    \n    clf_acc_score = accuracy_score(y_train_get, pred_train)\n    clf_f1_score = f1_score(y_train_get, pred_train)\n    \n    return pred_train.reshape(-1, 1), pred_test.reshape(-1, 1), clf_acc_score, clf_f1_score","5cec0a55":"dt_params = {\n    'max_depth' : 3,\n    'min_samples_split' : 2\n}\n\nada_params = {\n    'n_estimators': 100,\n    'learning_rate' : 0.75\n}\n\nrf_params = {\n    'n_estimators' : 100,\n    'min_samples_split' : 2\n}\n\net_params = {\n    'n_estimators': 100,\n    'min_samples_leaf': 2,\n}\n\ngb_params = {\n    'n_estimators': 100,\n    'min_samples_leaf': 2,\n}","7979b1c4":"dt_model = Model_Creation(clf=DecisionTreeClassifier, seed=SEED, params=dt_params)\nrf_model = Model_Creation(clf = RandomForestClassifier, seed = SEED, params = rf_params)\net_model = Model_Creation(clf = ExtraTreesClassifier, seed = SEED, params = et_params)\nada_model = Model_Creation(clf = AdaBoostClassifier, seed = SEED, params = ada_params)\ngb_model = Model_Creation(clf = GradientBoostingClassifier, seed = SEED, params = gb_params)","28dda93a":"dt_train_result, dt_test_result, dt_acc_score, dt_f1_score = get_scores(clf=dt_model, x_train_get=X_train, y_train_get=y_train, x_test_get=X_test)\nrf_train_result, rf_test_result, rf_acc_score, rf_f1_score = get_scores(clf=rf_model, x_train_get=X_train, y_train_get=y_train, x_test_get=X_test)\net_train_result, et_test_result, et_acc_score, et_f1_score = get_scores(clf=et_model, x_train_get=X_train, y_train_get=y_train, x_test_get=X_test)\nada_train_result, ada_test_result, ada_acc_score, ada_f1_score = get_scores(clf=ada_model, x_train_get=X_train, y_train_get=y_train, x_test_get=X_test)\ngb_train_result, gb_test_result, gb_acc_score, gb_f1_score = get_scores(clf=gb_model, x_train_get=X_train, y_train_get=y_train, x_test_get=X_test)","b39a5cfb":"print('Accuracy score of DecisionTreeClassifier :', round(dt_acc_score, 4) * 100, '%')\nprint('F1-Score of DecisionTreeClassifier :', round(dt_f1_score, 4) * 100)\n\nprint('Accuracy score of RandomForestClassifer :', round(rf_acc_score, 4) * 100, '%')\nprint('F1-Score of ExtraTreesClassifier :', round(rf_f1_score, 4) * 100)\n\nprint('Accuracy score of ExtraTreesClassifier :', round(et_acc_score, 4) * 100, '%')\nprint('F1-Score of ExtraTreesClassifier :', round(et_f1_score, 4) * 100)\n\nprint('Accuracy score of AdaBoost :', round(ada_acc_score, 4) * 100, '%')\nprint('F1-Score of AdaBoost :', round(ada_f1_score, 4) * 100)\n\nprint('Accuracy score of Gradient Boosting Machine :', round(gb_acc_score, 4) * 100, '%')\nprint('F1-Score of Gradient Boosting Machine :', round(gb_f1_score, 4) * 100)","f1615f2a":"dt_features = dt_model.feature_importances(X_train, y_train)\nrf_features = rf_model.feature_importances(X_train, y_train)\net_features = et_model.feature_importances(X_train, y_train)\nada_features = ada_model.feature_importances(X_train, y_train)\ngb_features = gb_model.feature_importances(X_train, y_train)","b19c0e1e":"dt_features = [0.00158387, 0, 0, 0, 0.21968882, 0.52720064, 0, 0, 0, 0, 0.25152667, 0, 0, 0]\n\nrf_features = [0.14884607, 0.03715319, 0.1672759,  0.0335612, 0.08463101, 0.09981356,\n 0.07028089, 0.07831672, 0.0139579, 0.01390901, 0.11619356, 0.03545653,\n 0.08397304, 0.01663142]\n\net_features = [0.09821158, 0.03551721, 0.03277514, 0.05533726, 0.14090152, 0.13328737,\n 0.05471377, 0.14526666, 0.01215226, 0.04887652, 0.13526527, 0.0378438,\n 0.06095664, 0.00889499]\n\nada_features = [0.11, 0.02, 0.02, 0.01, 0.07, 0.06, 0.17, 0.08, 0.01, 0.04, 0.21, 0.17, 0.03, 0]\n\ngb_features = [0.06090052, 0.00509677, 0.00435494, 0.00256431, 0.19704072, 0.38849472,\n 0.02393962, 0.00597061, 0.00107229, 0.00193148, 0.20452907, 0.06179946,\n 0.04085863, 0.00144688]","7de011c4":"X_tmp = X.drop(['income'], axis=1)\nX_tmp.head(5)","e270d2d7":"feature_df = pd.DataFrame({\n    'Features' : X_tmp.columns.values,\n    'DT_feat_importances_' : dt_features,\n    'RF_feat_importances_' : rf_features,\n    'ET_feat_importances_' : et_features,\n    'ADA_feat_importances_' : ada_features,\n    'GB_feat_importances_' : gb_features\n})","ce4e08f8":"feature_df.head(5)","08698e32":"def plot_feature_importance(clf_features):\n    plt.figure(figsize = (20, 12))\n    feat_plot = sns.barplot(data=feature_df, x='Features', y=clf_features)\n    feat_plot.set_title(clf_features, fontdict={'fontsize' : 20})\n    for p in feat_plot.patches:\n        feat_plot.annotate(format(p.get_height(), '.2f'),\n                        (p.get_x() + p.get_width() \/ 2., p.get_height()),\n                         ha = 'center', va = 'center',\n                         textcoords = 'offset points')","b4526ea9":"plot_feature_importance('DT_feat_importances_')","54a89137":"plot_feature_importance('RF_feat_importances_')","fec40e7d":"plot_feature_importance('ET_feat_importances_')","d6a201ca":"plot_feature_importance('ADA_feat_importances_')","45bf74fb":"plot_feature_importance('GB_feat_importances_')","68e82802":"first_level_pred = pd.DataFrame({\n    'DecisionTree' : dt_train_result.ravel(),\n    'RandomForest' : rf_train_result.ravel(),\n    'ExtraTrees' : et_train_result.ravel(),\n    'AdaBoost' : ada_train_result.ravel(),\n    'GBM' : gb_train_result.ravel()\n    \n})\nfirst_level_pred.head()","6b2e01dc":"first_level_pred.value_counts()","4899c522":"X_train_secondlevel = np.concatenate((dt_train_result, rf_train_result, et_train_result,\n                                     ada_train_result, gb_train_result), axis=1)\nX_test_secondlevel = np.concatenate((dt_test_result, rf_test_result, et_test_result,\n                                     ada_test_result, gb_test_result), axis=1)","efff7ca0":"xgb_model = xgb.XGBClassifier(\n    n_estimators = 100,\n    max_depth = 4,\n    min_child_weight = 2,\n    objective = 'binary:logistic').fit(X_train_secondlevel, y_train)\nfinal_pred = xgb_model.predict(X_test_secondlevel)","e1eefedc":"sample_submission = pd.read_csv('\/kaggle\/input\/kakr-4th-competition\/sample_submission.csv')\nsample_submission['prediction'] = final_pred.astype(int)\nsample_submission.to_csv('submission.csv', index=False)","1626c037":"\uc548\ub155\ud558\uc138\uc694. \ucde8\ubbf8\ub85c \uce90\uae00\uc744 \uc2dc\uc791\ud55c \uc9c0 \uc5bc\ub9c8 \uc548 \ub418\uc5b4\uc11c \ub9ce\uc774 \ubd80\uc871\ud55c \ucee4\ub110\uc774\uc9c0\ub9cc  \n\uc990\uac81\uac8c \ub9cc\ub4e4\uc5b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4! \uc790\uc720\ub85c\uc6b4 \ud53c\ub4dc\ubc31\uc740 \ub298 \ud658\uc601\uc785\ub2c8\ub2e4!","e6020ae3":"Model_Creation\uc774\ub77c\ub294 \ud074\ub798\uc2a4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.  \n5\uac1c\uc758 Classifier\ub97c \ud6a8\uc728\uc801\uc774\uace0 \ube60\ub974\uac8c \uc0dd\uc131\ud558\uae30 \uc704\ud574 \ub9cc\ub4dc\ub294 \ud074\ub798\uc2a4\uc785\ub2c8\ub2e4.","00262210":"# 3. Second-Level Classifier \ub9cc\ub4e4\uae30","a35e73d1":"\uc544\ub798\ub294 5\uac1c Classifier\ub4e4\uc758 Consensus\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uac12\uc785\ub2c8\ub2e4.","e0f60aec":"\uc774\uc81c \ub9c8\uc9c0\ub9c9\uc73c\ub85c X_train, y_train, X_test\ub97c \ub098\ub204\uc5b4 \uc800\uc7a5\ud574\ub461\ub2c8\ub2e4.","a0f2e3e8":"\uc774\ubc88\uc5d0\ub294 get_scores \ud568\uc218\ub97c \uc815\uc758\ud569\ub2c8\ub2e4.\nReturn\uac12\uc73c\ub85c 4\uac00\uc9c0\ub97c \ubc1b\uc2b5\ub2c8\ub2e4.  \n\n1. Training Prediction : X_train, y_train\uc744 \ub123\uc5b4\uc92c\uc744 \ub54c\uc758 0, 1 \uc608\uce21\uac12\ub4e4\uc785\ub2c8\ub2e4. \uc774 \uacb0\uacfc\uac12\uc740 \ucd94\ud6c4\uc5d0 \ud569\uccd0\uc9c4 \ub4a4, Second-Level Classifier\uc758 Input\uc774 \ub429\ub2c8\ub2e4.  \n2. Test Prediction : X_test\uc744 \ub123\uc5b4\uc92c\uc744 \ub54c\uc758 \uc608\uce21\uac12\uc785\ub2c8\ub2e4. First-Level Classifier\ub4e4\uc758 \uc131\ub2a5\uc774 \uc5b4\ub5a0\ud55c\uc9c0 \uccb4\ud06c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n3. First-level Accuracy Score : X_train, y_train\uc758 Accuracy Score\uc785\ub2c8\ub2e4.\n4. First-level F1 Score : X_train, y_train\uc758 F1-Score\uc785\ub2c8\ub2e4.","c938de21":"\uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \ubc29\uc2dd\uc73c\ub85c Parameter\ub4e4\uc744 \uc815\uc758\ud588\uc2b5\ub2c8\ub2e4.  \n\ucd94\ud6c4 \uc774 \uac12\ub4e4\uc740 Tuning\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.","8dcae2fb":"First-level Classifier\ub4e4\uc758 \uc131\ub2a5\uc744 \uccb4\ud06c\ud574\ubd05\uc2dc\ub2e4.","b082f77a":"'native_country' \uc5f4\ub9cc float \ud615\ud0dc\uc5ec\uc11c, \ub2e4\ub978 \uc5f4\uacfc \ub3d9\uc77c\ud558\uac8c \ud615\ubcc0\ud658\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4.","6c04b2c4":"feature_df\uc5d0 \uac01 Classifier\ub4e4\uc758 importance\ub97c \ubaa8\uc544\ub193\uc558\uc2b5\ub2c8\ub2e4.","68feae8f":"# Stacking\uc744 \uc774\uc6a9\ud55c Second-Level Learning Model","101a9dca":"5\uac1c\uc758 \ubaa8\ub378\uc744 \uc544\ub798\uc640 \uac19\uc774 \uc0dd\uc131\ud55c \ub4a4, \uacb0\uacfc\uac12\uc744 \ubcc0\uc218\uc5d0 \uc800\uc7a5\ud569\ub2c8\ub2e4.","fe3eaa65":"# 2. First-Level Classifier \ub9cc\ub4e4\uae30","f7a37873":"# 4. Reference","173e79e1":"\uc774\uc81c \uc774 \uc608\uce21\uac12\ub4e4\uc744 \ud558\ub098\ub85c \ubb36\uc5b4\uc11c Second-level Classifier\uc5d0 \ub123\uc2b5\ub2c8\ub2e4.","349c5fe1":"## 2) Performance & Feature Importance","f52fe84f":"\uc774\ub97c Seaborn\uc744 \uc774\uc6a9\ud574\uc11c \uadf8\ub9bc\uc73c\ub85c \ud655\uc778\ud574\ubd05\uc2dc\ub2e4.","f7f3a01e":"Stacking\uc744 \uc774\uc6a9\ud55c \ub2e4\uc74c \ubaa8\ub378\uc740 \uc774\ub7f0 \uc2dd\uc73c\ub85c \uad6c\ud604\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n1. 5\uac1c\uc758 First Level Classifier\ub4e4\uc774 (DecisionTree, RandomForest, ExtraTrees, AdaBoost, GBM) \uac01\uc790 \uc608\uce21\uac12\uc744 0, 1\uc758 \ud615\ud0dc\ub85c \ub3c4\ucd9c\ud55c\ub2e4.\n2. \uc774 \uc608\uce21\uac12\uc744 \ubaa8\uc544\uc11c Second Level Classifier(XGBoost)\uc5d0 \ub123\uc5b4 \ucd5c\uc885 \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud55c\ub2e4.\n\n**\uc774 \ucee4\ub110\uc740 Baseline\uc774\uba70, \ud5a5\ud6c4 Feature Engineering, Parameter Tuning \ub4f1\uc744 \ud1b5\ud574 \uc131\ub2a5\uc744 \uac1c\uc120\ud560 \uc608\uc815\uc785\ub2c8\ub2e4.  \n\ud53c\ub4dc\ubc31 \ubc0f \uc131\ub2a5 \uac1c\uc120\uc5d0 \ub300\ud55c \uc544\uc774\ub514\uc5b4\ub294 \ubb34\uc5c7\uc774\ub4e0 \uac10\uc0ac\ud558\uac8c \ub4e3\uaca0\uc2b5\ub2c8\ub2e4!**","d2a0db8d":"## 1) Model Creation","3582d084":"\uc6b0\uc120 \uc608\uce21\ud558\uace0\uc790 \ud558\ub294 'income' \uc744 True\/False \ud615\ud0dc\ub85c \ubcc0\ud658\ud574\uc900 \ub4a4, X\uc640 y\ub97c \ubd84\ub9ac\ud588\uc2b5\ub2c8\ub2e4.","de11ed38":"\ub77c\ubca8\ub9c1\uc744 \ub9c8\uce58\uace0 \ub098\uba74 \uc544\ub798\uc640 \uac19\uc740 \ub370\uc774\ud130\ub85c \uc815\ub9ac\ub429\ub2c8\ub2e4.","e08b75cd":"1. [[KaKr] \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d(EDA) \uc124\uba85 + \uc608\uc2dc](https:\/\/www.kaggle.com\/subinium\/kakr-eda)  \n2. [\uce90\ud558~ EDA + LightGBM + PyCaret](https:\/\/www.kaggle.com\/teddylee777\/eda-lightgbm-pycaret)  \n3. [Introduction to Ensembling\/Stacking in Python](https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python)","367996c3":"# 1. \ud559\uc2b5 \uac00\ub2a5\ud55c \ud615\ud0dc\ub85c \ub370\uc774\ud130 \ubcc0\ud658","c38c2633":"First-level Classifier\ub4e4\uc740 \uc5b4\ub5a4 Feature\uc5d0 \uac00\uc911\uce58\ub97c \ub450\uace0 \ud559\uc2b5\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud574\ubd05\uc2dc\ub2e4.","10bb5e53":"Ordinal Encoder\ub97c \uc774\uc6a9\ud55c \ub77c\ubca8\ub9c1\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4."}}