{"cell_type":{"ed4fc8e5":"code","19b2fb8f":"code","9e3e40a7":"code","692b1acf":"code","890b5d72":"code","6eec55e7":"code","2cdd47ef":"code","7dfb8f2a":"code","8f5703e0":"code","5ca46ee6":"code","546030a8":"code","118fd111":"code","42697447":"code","f0bf38ce":"code","8b6d557d":"code","78fd0098":"code","58e77aaf":"code","c214ec7a":"code","1a235524":"code","31509490":"code","6de8371f":"code","6980e85c":"code","945b9baa":"code","175fd091":"code","e6a14076":"code","7f91f947":"code","05ff87f8":"code","1e2dee61":"code","ccbf8a39":"code","bb055546":"markdown","c3862527":"markdown","b8c3b409":"markdown","a38d4604":"markdown","444ab171":"markdown","dcdefa1b":"markdown","9aaaa36b":"markdown","bb7f84f0":"markdown","42a663f2":"markdown","014614fa":"markdown","c3fcadc0":"markdown","c0f032aa":"markdown","2146c6ab":"markdown","846c582e":"markdown","9d0e18d1":"markdown","c07b6842":"markdown","858cad16":"markdown","57da468c":"markdown","6d7bf07b":"markdown","03647ba7":"markdown","7986f6db":"markdown","c2e5d00a":"markdown","1c2357ce":"markdown","4761cfb8":"markdown"},"source":{"ed4fc8e5":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","19b2fb8f":"!pip install pandas_flavor","9e3e40a7":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n\n            length = len(df[i])\n            tmp = np.round((length - df[i].between(lower_range,upper_range).sum())\/length * 100, 2)\n            if tmp != 0:\n                features[i] = tmp\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())","692b1acf":"import itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","890b5d72":"\n\nimport matplotlib as mpl\n\nsns.set(style=\"darkgrid\",font_scale=1.1)\n# plt.rcParams['figure.dpi']=200\n\nmpl.rcParams['figure.dpi'] = 200\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['font.family'] = 'sans-serif'\nmpl.rcParams['font.sans-serif'] = [\"SF UI Display\",\"Inter\", \"Helvetica\"]\nmpl.rcParams['font.weight'] = 500\nmpl.rcParams['axes.titleweight'] = 800\nmpl.rcParams['axes.labelsize'] = \"large\"\nmpl.rcParams['axes.titlesize'] = \"x-large\"\nmpl.rcParams['xtick.labelsize'] = \"medium\"\nmpl.rcParams['ytick.labelsize'] = \"medium\"\n\n# mpl.rcParams['patch.antialiased'] = True \n# mpl.rcParams['patch.linewidth'] = 1.5\n# sns.set_context(rc = {'patch.linewidth': 5.0})\n\n# \u2018xx-small\u2019, \u2018x-small\u2019, \u2018small\u2019, \u2018medium\u2019, \u2018large\u2019, \u2018x-large\u2019, \u2018xx-large\u2019.\n\n\n\nfrom matplotlib.ticker import MaxNLocator\n\ndef srt_reg(y, df,x_size=20,y_size=20,*args,**kwargs):\n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sns.regplot(x=i,\n                    y=y,\n                    data=df,\n                    ax=j,\n                    order=3,\n                    ci=None,\n                    color='#e74c3c',\n                    line_kws={'color': 'black'},\n                    scatter_kws={'alpha':0.4},\n                   *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n        plt.tight_layout()\n\ndef srt_box(y, df,*args,**kwargs):\n    fig, axes = plt.subplots(19, 3, figsize=(30,30))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sortd = df.groupby([i])[y].median().sort_values(ascending=False)\n        sns.boxplot(x=i,\n                    y=y,\n                    data=df,\n                    palette='plasma',\n                    order=sortd.index,\n                    ax=j,\n                    *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\n\n        \ndef histplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.histplot(x=df,ax=ax,*args,**kwargs)\n        [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.histplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n            [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n\ndef countplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.countplot(x=df,ax=ax,*args,**kwargs)\n        [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.countplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n            [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\n    \n    \ndef barplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n        \n        if i == y:\n            continue\n\n        sns.barplot(data=df,\n                    x=i,\n                    y=y,\n                    ax=j,*args,**kwargs)\n\n        j.tick_params(labelrotation=45)\n        [ j.bar_label(tmp) for tmp in j.containers]\n#         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n    \n    \ndef violinplt(df,y,ncols=3,x_size=30,y_size=30,x_scale = \"linear\", y_scale = \"linear\", *args,**kwargs):\n    \n    \n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.violinplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n            \n            lower_range, upper_range = df[i].IQR_range()\n            outliers = df[(df[i] > upper_range) | (df[i] < lower_range)][i]\n            sns.scatterplot(y=outliers, x=0, marker='D', color='crimson', ax=j)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            g = sns.violinplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n            g.set_xscale(x_scale)\n            g.set_yscale(y_scale)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \ndef boxplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\nimport scipy.stats as stats\n\ndef qqplt(df,x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        stats.probplot(df,plot=ax, *args,**kwargs)\n        \n#         ax.set_title(label=df.columns)\n        ax.tick_params(labelrotation=45)\n        ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n#         plt.tight_layout()\n        \n    \n    else:\n        ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            stats.probplot(df[i],plot=j, *args,**kwargs)\n            j.set_title(label=i)\n            j.tick_params(labelrotation=45)\n            j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n            plt.tight_layout()\n\n","6eec55e7":"df = pd.read_csv(\"..\/input\/employee-future-prediction\/Employee.csv\")\ndf.about()","2cdd47ef":"thresold = 50","7dfb8f2a":"df.describe_discrete_cols(thresold)","8f5703e0":"df.get_continuous_cols(thresold)\n# df.describe_continuous_cols(thresold=thresold)","5ca46ee6":"countplt(df, y_size=50, ncols=2)","546030a8":"countplt(df, y_size=50, ncols=2, hue=df[\"LeaveOrNot\"])","118fd111":"countplt( pd.qcut(df[\"Age\"], q=7), y_size=10 )","42697447":"df[\"Age\"] = pd.qcut(df[\"Age\"], q=7)","f0bf38ce":"countplt( df[\"Age\"], y_size=10, hue=df[\"LeaveOrNot\"] )","8b6d557d":"countplt(pd.qcut(df[\"ExperienceInCurrentDomain\"], q=3 ), y_size=10)","78fd0098":"df[\"exp\"] = pd.qcut(df[\"ExperienceInCurrentDomain\"], q=3 )\ndf.drop(\"ExperienceInCurrentDomain\",axis=1,inplace=True)","58e77aaf":"countplt(df[\"exp\"], y_size=10, hue=df[\"LeaveOrNot\"])","c214ec7a":"df.columns","1a235524":"display_multiple_tables(\n[compare_cols(df, l_feat=[feat, \"LeaveOrNot\"], r_feat={\"LeaveOrNot\":\"count\"}, percent=True, percent_of_total=True) for feat in ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age', 'Gender','EverBenched', 'exp'] ]\n)","31509490":"display_multiple_tables(\n[compare_cols(df[df[\"Gender\"]==\"Male\"], l_feat=[feat, \"Gender\", \"LeaveOrNot\"], r_feat={\"LeaveOrNot\":\"count\"}, percent=True, percent_of_total=True) for feat in ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age','EverBenched', 'exp'] ]\n)","6de8371f":"display_multiple_tables(\n[compare_cols(df[df[\"Gender\"]==\"Female\"], l_feat=[feat, \"Gender\", \"LeaveOrNot\"], r_feat={\"LeaveOrNot\":\"count\"}, percent=True, percent_of_total=True) for feat in ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age','EverBenched', 'exp'] ]\n)","6980e85c":"display_multiple_tables(\n[compare_cols(df, l_feat=[feat, \"Gender\",], r_feat={\"Education\":\"count\"}, percent=True, percent_of_total=True) for feat in ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age','EverBenched', 'exp'] ]\n)","945b9baa":"from sklearn.preprocessing import OrdinalEncoder","175fd091":"encoder = OrdinalEncoder(dtype=np.int64)\n\nx = df.drop(\"LeaveOrNot\",axis=1)\ny = df[\"LeaveOrNot\"]\n\nx[x.columns.to_list()] = encoder.fit_transform(x)\nx.head()","e6a14076":"x.describe_discrete_cols(thresold)","7f91f947":"from sklearn.linear_model import LogisticRegression,SGDClassifier,ElasticNet\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,HistGradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm  import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import cross_val_score","05ff87f8":"lr = LogisticRegression()\nsgd = SGDClassifier()\ngb = GradientBoostingClassifier()\nadb = AdaBoostClassifier()\nxg = XGBClassifier(use_label_encoder=False,eval_metric='mlogloss')\nlgb = LGBMClassifier()\nhgb=HistGradientBoostingClassifier()\nsvc = SVC()\ncb = CatBoostClassifier(verbose=False)\n\n# define dict of models \nclfs={\n    \"Logistic\":lr,\n    \"SVC\":svc,\n    \"Stocastic Grad\":sgd,\n    \"Grad boost\":gb,\n    \"AdaBoost\":adb,\n    \"Hist Grad Boost\":hgb,\n#     XG boost took too long to train, so Ill not use it\n#     \"XG Boost\":xg,\n    \"Light GBM\":lgb,\n    \"Catboost\":cb\n}","1e2dee61":"perf = {}\n\nfor name,model in zip(clfs, clfs.values()):\n    print(f\"Training {name}\")\n    tmp = cross_val_score(model, X=x, y =y,cv=10,n_jobs=-1, scoring=\"precision\")\n    print(f\"{name} got average of {tmp.mean()} and {tmp.std()}\")\n    perf[name] =  tmp\n\nmodel = []\nvalue = []\nstd = []\nfor name,arr in zip(perf, perf.values()):\n    model.append(name)\n    value.append(np.round(arr.mean()*100,2))\n    std.append(np.round(arr.std()*100,2))\n\nperf_df = pd.DataFrame({\"model\":model, \"mean\":value, \"std dev\":std})\ndisplay(perf_df.sort_values(\"mean\", ascending=False))","ccbf8a39":"score = \"precision\"\nparams = {'learning_rate': 0.001, 'n_estimators': 275, 'num_leaves': 100}\narr = cross_val_score(LGBMClassifier(**params), X=x, y =y,cv=10,n_jobs=-1, scoring=score, )\nprint(f\"{score} mean: {np.round(arr.mean()*100, 2)} std: {np.round(arr.std()*100, 2)}\")","bb055546":"<h1 id =\"Introduction\" style=\"color:#E36149;\">Introduction<\/h1>\n\n<h2 id =\"Problem Statement\" style=\"color:#E36149;\">Problem Statement<\/h2>\nA company's HR department wants to predict whether some employees would leave the company in next 2 years. Your job is to build a predictive model that predicts the prospects of future and present employee.\nPerform EDA and bring out insights A company's HR department wants to predict whether some customers would leave the company in next 2 years. Your job is to build a predictive model that predicts the prospects of future and present employee.\nPerform EDA and bring out insights\n\n<h2 id =\"Tasks\" style=\"color:#E36149;\">Tasks<\/h2>\n\n- Perform EDA\n- Build model to predict if Employee leaves\n\n### If you found this notebook insightful or helpful please Upvote, Suggestions are always welcome","c3862527":"**lets use bins = 7 for age since the distribution looks good**","b8c3b409":"<h2 id =\"Lets bin for ExperienceInCurrentDomain\" style=\"color:#E36149;\">Lets bin for ExperienceInCurrentDomain<\/h2>","a38d4604":"**I really got lucky to find best Hyper Parameters while I was corse searching**","444ab171":"**lets save performance of each model into dict and create a dataframe with it to see the performance**\n\n**here I am going to use `precision` as a metric, since here it represents \"how many of the predicted employees actually left**","dcdefa1b":"<h1 id =\"Encode values\" style=\"color:#E36149;\">Encode values<\/h1>","9aaaa36b":"<h1 id =\"Importing data and initial impressions\" style=\"color:#E36149;\">Importing data and initial impressions<\/h1>","bb7f84f0":"**Looks like all columns are discrete in nature**\n\n**it would be better if we bin the `Age` and `ExperienceInCurrentDomain` and just encode the others**","42a663f2":"<h1 id =\"Imports\" style=\"color:#E36149;\">Imports<\/h1>","014614fa":"<h1 id =\"EDA\" style=\"color:#E36149;\">EDA<\/h1>","c3fcadc0":"```\nfrom tune_sklearn import TuneGridSearchCV\n\n# trying wider range first, then we narrow down\ntuned_parameters = [{\n    \"num_leaves\": np.linspace(100,500,5, endpoint=True, dtype=int),\n    \"n_estimators\":np.linspace(50,500,5, endpoint=True, dtype=int),\n    \"learning_rate\":np.linspace(0.001, 1,10, endpoint=True),\n}]\n                          \n\nlgbm = LGBMClassifier(\n    boosting_type=\"gbdt\",\n    n_jobs=-1\n)\n\nscores = [\"precision\",\n         ]\n\nfor score in scores:\n    print(f\"# Tuning hyper-parameters for {score}\")\n    print()\n\n    clf = TuneGridSearchCV(lgbm, tuned_parameters,early_stopping=False, cv=3,\n                       scoring=score, n_jobs=-1)\n    clf.fit(x,y)\n\n    print(\"Best parameters set found on development set:\")\n    print()\n    print(clf.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    print()\n    print(score)\n    cross_val_score(LGBMClassifier(clf.best_params_), X=x, y =y,cv=10,n_jobs=-1, scoring=score, ).mean()\n    print()\n    \n  ```","c0f032aa":"<h1 id =\"Tune\" style=\"color:#E36149;\">Tune<\/h1>","2146c6ab":"**Key Observations**\n- 49% of master degree holders left\n- 99% of people joined in 2018 left\n- 50% of people who live in Pune left\n- 60% of people with PaymentTier as 2 left\n- 40% of people with age between 22 and 25 left\n- 47% of female employees left\n- 45% of people who were ever Benched left\n","846c582e":"**lets train on all the below models and select from the best one**","9d0e18d1":"<h2 id =\"Lets add some numbers to the stats\" style=\"color:#E36149;\">Lets add some numbers to the stats<\/h2>","c07b6842":"<h2 id =\"Lets now bin Age\" style=\"color:#E36149;\">Lets now bin Age<\/h2>","858cad16":"<h1 id =\"Custom Code for pandas\" style=\"color:#E36149;\">Custom Code for pandas<\/h1>","57da468c":"**First lets just plot the data and see what can be done**","6d7bf07b":"**Lets use bins=3 since it looks good and lets rename the column to `exp`**","03647ba7":"<h1 id =\"Custom Code for plotting\" style=\"color:#E36149;\">Custom Code for plotting<\/h1>","7986f6db":"**huhh! thats interesting to see roughly 50% of each bin leave**","c2e5d00a":"**Although SVC has the highest accuracy, I would go with LGBM for the following reasons**\n- the difference is not huge\n- LGBM takes faster to train","1c2357ce":"**lets tune LGBM**\n\n**I referred [this](https:\/\/www.kaggle.com\/prashant111\/lightgbm-classifier-in-python?cellIds=52&kernelSessionId=39196115) notebook on which parameters to focus on**","4761cfb8":"<h1 id =\"Train Models\" style=\"color:#E36149;\">Train Models<\/h1>"}}