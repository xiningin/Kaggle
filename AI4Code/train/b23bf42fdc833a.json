{"cell_type":{"7c567ce5":"code","f17a37f8":"code","2c2e9bdc":"code","3f481318":"code","afbbd4fc":"code","f4e323eb":"code","557d3c4b":"code","c539014f":"code","0ebf8708":"code","4b83d23b":"code","110b1ecf":"code","979abd4b":"code","e417aade":"code","b6ee8035":"code","46c12b5a":"code","67c83d5e":"code","83c466bf":"markdown"},"source":{"7c567ce5":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport time, logging, gc\nfrom sklearn.preprocessing import RobustScaler\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import *\nfrom tensorflow.keras.callbacks import *","f17a37f8":"train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\npressure_unique = np.array(sorted(train['pressure'].unique()))","2c2e9bdc":"train","3f481318":"test","afbbd4fc":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] \/df['count']\n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['u_in_lag'] = df['u_in_lag']*df['breath_id_lagsame']\n    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['u_in_lag2'] = df['u_in_lag2']*df['breath_id_lag2same']\n    df['u_out_lag2'] = df['u_out'].shift(2).fillna(0)\n    df['u_out_lag2'] = df['u_out_lag2']*df['breath_id_lag2same']\n    #df['u_in_lag'] = df['u_in'].shift(2).fillna(0)\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['RC'] = df['R']+df['C']\n    #df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","f4e323eb":"y = train['pressure'].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1)","557d3c4b":"train","c539014f":"rb = RobustScaler()\n\nrb.fit(train)\ntrain = rb.transform(train)\ntest = rb.transform(test)","0ebf8708":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\ngc.collect","4b83d23b":"# Detect hardware, return appropriate distribution strategy\nprint(tf.version.VERSION)\ntf.get_logger().setLevel(logging.ERROR)\ntry: # detect TPU\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError: # detect GPU(s) and enable mixed precision\n    strategy = tf.distribute.MirroredStrategy() # works on GPU and multi-GPU\n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    tf.config.optimizer.set_jit(True) # XLA compilation\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print('Mixed precision enabled')\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","110b1ecf":"def plot_hist(hist):\n    plt.plot(hist.history[\"loss\"])\n    plt.plot(hist.history[\"val_loss\"])\n    plt.title(\"model performance\")\n    plt.ylabel(\"mean_absolute_error\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","979abd4b":"def create_model():   \n    with strategy.scope():\n    \n        model = Sequential([\n            \n            Input(shape=(80, 13)),\n            Bidirectional(LSTM(700, return_sequences=True)),\n            Bidirectional(LSTM(512, return_sequences=True)),\n            Bidirectional(LSTM(256, return_sequences=True)),\n            Bidirectional(LSTM(128, return_sequences=True)),\n            Dense(128, activation='selu'),\n            Dense(1)\n        ])\n\n        model.compile(optimizer=\"adam\",loss = \"mae\")\n    return(model)","e417aade":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\n\ntest_preds = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train, y)):\n    print(f\"****** fold: {fold+1} *******\")\n    X_train, X_valid = train[train_idx], train[test_idx]\n    y_train, y_valid = y[train_idx], y[test_idx]\n    \n    scheduler = tf.keras.optimizers.schedules.ExponentialDecay(1e-3, 200*((len(train)*0.8)\/512), 1e-5)\n    es = EarlyStopping(monitor='val_loss',mode='min', patience=35, verbose=1,restore_best_weights=True)\n    \n    model = create_model()\n        \n    history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, batch_size = 256, callbacks = [es,tf.keras.callbacks.LearningRateScheduler(scheduler)])\n    test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n    plot_hist(history)\n    del X_train, X_valid, y_train, y_valid, model\n    gc.collect()   ","b6ee8035":"submission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\nsubmission[\"pressure\"] = sum(test_preds)\/5  #test_preds[1]\nsubmission.to_csv('submission_mean.csv', index=False)\nsubmission    ","46c12b5a":"# ENSEMBLE FOLDS WITH MEDIAN\nsubmission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\nsubmission","67c83d5e":"# ROUND PREDICTIONS (Post Preprocessing)\nsubmission['pressure'] = submission['pressure'].map(lambda x: pressure_unique[np.abs(pressure_unique-x).argmin()])\nsubmission.to_csv('submission_post_preprocessing.csv', index=False)\nsubmission","83c466bf":"<h4>References:<\/h4>\n\n1. https:\/\/www.kaggle.com\/tolgadincer\/tensorflow-bidirectional-lstm-0-234 <br>\n2. https:\/\/www.kaggle.com\/junhyeok99\/tensorflow <br>\n3. https:\/\/www.kaggle.com\/kensit\/improvement-base-on-tensor-bidirect-lstm-0-173\n4. Using ensemble folds with median instead of mean from this [kernel](https:\/\/www.kaggle.com\/cdeotte\/ensemble-folds-with-median-0-153\/notebook) \n5. Post preprocessing from the [kernel](https:\/\/www.kaggle.com\/snnclsr\/a-dummy-approach-to-improve-your-score-postprocess\/notebook) using the method of [columbia2131](https:\/\/www.kaggle.com\/columbia2131) (He made a comment in the notebook contains the code with better way)"}}