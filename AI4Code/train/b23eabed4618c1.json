{"cell_type":{"5201ef01":"code","b5d1e407":"code","5f40de86":"code","379d1032":"code","b5f6a6a0":"code","ec2e1596":"code","bff6b4c5":"code","aed991c7":"code","6a798313":"code","ef7af305":"code","361bcc89":"code","50040b30":"code","be88b2fb":"code","872737d3":"code","59614a90":"code","0318bfbd":"code","bdbcb2e6":"code","20691743":"code","79d48de3":"code","31959c4b":"code","0d058adc":"code","dcbce66e":"code","e3594a55":"markdown","ac5e737f":"markdown","275db45a":"markdown","92cd16f8":"markdown","536bd8a6":"markdown","e06170e9":"markdown","fb9b01c1":"markdown","97b2e196":"markdown","df00d769":"markdown","804f778e":"markdown","c133b8e9":"markdown","dbbd2759":"markdown","e84977e5":"markdown","711a2a55":"markdown","a80c78b7":"markdown","22ee1ed8":"markdown","1f57c522":"markdown","8bb85aea":"markdown"},"source":{"5201ef01":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt","b5d1e407":"df = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","5f40de86":"df.info()","379d1032":"df.head()","b5f6a6a0":"df.describe().transpose()","ec2e1596":"df.isnull().sum()","bff6b4c5":"sns.countplot(data=df, x = 'quality')","aed991c7":"fig = plt.figure(figsize=(7,4), dpi=150)\nsns.heatmap(data= df.corr(), annot=True)\n","6a798313":"sns.scatterplot(data=df, x = 'quality', y='alcohol')","ef7af305":"sns.scatterplot(data=df, x = 'alcohol', y='density')","361bcc89":"sns.barplot(data=df, x = 'quality',y = 'citric acid')","50040b30":"bins = (2, 5.5, 8)\ngroup_names = ['bad', 'good']\ndf['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)","be88b2fb":"df['quality'].value_counts()","872737d3":"from sklearn.model_selection import train_test_split\nX = df.drop('quality', axis = 1)\ny = df['quality']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)","59614a90":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","0318bfbd":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nsvc = SVC()\nparam_grid = {'C' : [0.001,0.01,0.1,0.4,0.5,1]}\ngrid = GridSearchCV(svc, param_grid)\ngrid.fit(X_train,y_train)","bdbcb2e6":"grid.best_params_","20691743":"from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\ngrid_pred = grid.predict(X_test)\nplot_confusion_matrix(grid, X_test, y_test)","79d48de3":"print(classification_report(y_test,grid_pred))","31959c4b":"from sklearn.ensemble  import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","0d058adc":"plot_confusion_matrix(rfc, X_test, y_test)","dcbce66e":"print(classification_report(y_test,pred_rfc))","e3594a55":"## Note: We could actually use those multi class label and balance them. There is a hyperparameter in svc called class wight. If we equall class wight to balace our model will dedicate more weight to our imbalance data.","ac5e737f":"### 1. Data Preview\n### 2. EDA\n### 3. Data Preprocessing\n### 4. Model training\n### 5. Model Evaluation","275db45a":"### It looks there is no missing data, let's check!","92cd16f8":"# 3. Data preprocessing","536bd8a6":"# 1. Data Preview ","e06170e9":"According to above count plot our data is obviouly imbalanced. Since 8 is best quality we have a lot of 5 quality in our dataset.","fb9b01c1":"<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/11\/Ch%C3%A2teau_P%C3%A9trus.jpg\" width=\"700\" style=\"display: block;\n  margin-left: auto;\n  margin-right: auto;\n  width: 50%;\" >","97b2e196":"## Random Forest performed better.","df00d769":"## SVC","804f778e":"## Feature Scaling","c133b8e9":"### well that's a balance set. Let's move on to our models.","dbbd2759":"# 2. EDA","e84977e5":"Heat map plot shows us that there isn't any string relationship between our features or our label. The corrolation between pH and fixed acidity is -0.68 which makes sense since pH is in indirect rellation with acidity. For our label alcohol feature has the highest corrolation which is 0.48.\n### Now let plot some more plots to see the rellations more clear.","711a2a55":"## Random Forest","a80c78b7":"## Train|Test Split","22ee1ed8":"## If my notebook was helpfull for, make sure to give it an upvote. \n## Thank you!","1f57c522":"# 4. Model Training","8bb85aea":"### Since our dataset is imbalance, It's reasonable to convert our label to binary. We can divide it to good and bad. 3 to 5 is good wine and 6 to 8 is bad wine."}}