{"cell_type":{"3f3f1f9f":"code","7232aeb3":"code","ac9d9a73":"code","6eb2216e":"code","2dbe7f2a":"code","03af312f":"code","bdf0db86":"code","0c56cb07":"code","04e57995":"code","57a6105c":"code","19bebe10":"code","9446501e":"code","f057fea0":"code","0ec50be8":"markdown","31c451c1":"markdown","1c409ee8":"markdown","bd1d267a":"markdown"},"source":{"3f3f1f9f":"%matplotlib inline\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport tensorflow as tf","7232aeb3":"AUTO = tf.data.experimental.AUTOTUNE\nDATASET_DIR = Path('\/kaggle\/input\/flowers-tta')\nPATH = Path('\/kaggle\/input\/flower-classification-with-tpus')\nSIZES = {s: f'{s}x{s}' for s in [192, 224, 331, 512]}\nTFRECORD_DIR = KaggleDatasets().get_gcs_path(PATH.parts[-1])","ac9d9a73":"classes_filename = DATASET_DIR\/'classes.csv' \nCLASSES = tf.constant(pd.read_csv(classes_filename).values.squeeze(), tf.string)\n\ndef get_parse_fn(split):\n    def parse_fn(example):\n        features = {\"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n                    \"id\": tf.io.FixedLenFeature([], tf.string),\n                    \"class\": tf.io.FixedLenFeature([], tf.int64)}\n        \n        if split == 'test':\n            del features['class']\n            \n        example = tf.io.parse_single_example(example, features)\n            \n        example['image'] = tf.image.decode_jpeg(example['image'])\n        example['label'] = tf.cast(example['class'], tf.int32)\n        example['class'] = CLASSES[example['label']]\n        \n        return example\n\n    return parse_fn\n\ndef get_ds(split, img_size=224, batch_size=128, shuffle=False):\n    file_pat = f'{TFRECORD_DIR}\/tfrecords-jpeg-{SIZES[img_size]}\/{split}\/*.tfrec'\n    \n    options = tf.data.Options()\n    options.experimental_deterministic = not shuffle\n    \n    ds = (tf.data.Dataset.list_files(file_pat, shuffle=shuffle)\n          .with_options(options)\n          .interleave(tf.data.TFRecordDataset, num_parallel_calls=AUTO)\n          .map(get_parse_fn(split), num_parallel_calls=AUTO)\n         )\n    \n    if shuffle:\n        ds = ds.shuffle(2048)\n            \n    return ds.repeat().batch(batch_size).prefetch(AUTO)\n\ndef show_images(imgs, titles=None, hw=(3,3), rc=(4,4)):\n    \"\"\"Show list of images with optional list of titles.\"\"\"\n    h, w = hw\n    r, c = rc\n    fig=plt.figure(figsize=(w*c, h*r))\n    gs1 = gridspec.GridSpec(r, c, fig, hspace=0.2, wspace=0.05)\n    for i in range(r*c):\n        img = imgs[i].squeeze()\n        ax = fig.add_subplot(gs1[i])\n        if titles != None:\n            ax.set_title(titles[i], {'fontsize': 10})\n        plt.imshow(img)\n        plt.axis('off')\n    plt.show()","6eb2216e":"ds_val = get_ds('val', shuffle=False)\nds_val_iter = ds_val.unbatch().batch(16).as_numpy_iterator()","2dbe7f2a":"b_val = next(ds_val_iter)\nshow_images(b_val['image'], b_val['class'].tolist(), hw=(2,2), rc=(2,8))","03af312f":"ds_trn = get_ds('train', shuffle=False)\nds_trn_iter = ds_trn.unbatch().batch(16).as_numpy_iterator()","bdf0db86":"b_trn = next(ds_trn_iter)\nshow_images(b_trn['image'], b_trn['class'].tolist(), hw=(2,2), rc=(2,8))","0c56cb07":"ds_sample = tf.data.experimental.sample_from_datasets([ds_trn.unbatch(), ds_val.unbatch()], [1., 1.])\nds_sample_iter = ds_sample.batch(16).as_numpy_iterator()","04e57995":"b_smp = next(ds_sample_iter)\nshow_images(b_smp['image'], b_smp['class'].tolist(), hw=(2,2), rc=(2,8))","57a6105c":"choices = tf.data.Dataset.range(2).repeat()\nds_choose = tf.data.experimental.choose_from_datasets([ds_trn.unbatch(), ds_val.unbatch()], choices)\nds_choose_iter = ds_choose.batch(16).as_numpy_iterator()","19bebe10":"b_ch = next(ds_choose_iter)\nshow_images(b_ch['image'], b_ch['class'].tolist(), hw=(2,2), rc=(2,8))","9446501e":"ds_zip = tf.data.Dataset.zip((ds_val.unbatch(), ds_trn.unbatch()))\nds_zip_iter = ds_zip.batch(8).as_numpy_iterator()","f057fea0":"b_zip = next(ds_zip_iter)\nshow_images(b_zip[0]['image'], b_zip[0]['class'].tolist(), hw=(2,2), rc=(1,8))\nshow_images(b_zip[1]['image'], b_zip[1]['class'].tolist(), hw=(2,2), rc=(1,8))","0ec50be8":"# Create Datasets","31c451c1":"# Zip ","1c409ee8":"# Choose","bd1d267a":"# Sample"}}