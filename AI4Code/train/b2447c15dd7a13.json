{"cell_type":{"a8e5ea53":"code","3511fa1d":"code","1c27e0fc":"code","3bf0685e":"code","4ad9800a":"code","db49d014":"code","a0c00857":"code","83af1672":"code","25c1997d":"code","36fcb58a":"code","b98408fd":"code","6e3eab32":"code","c05d2990":"code","3ccadbd1":"code","1acc241a":"code","4605e9c9":"code","b01a0148":"code","2a4ef988":"code","2a93876f":"code","e1b02b17":"code","fa3c5e0c":"code","87aeef2c":"code","cfe6fbf8":"code","c7fe75e9":"code","ae4a8198":"code","9b1b0fb2":"code","a19f87e0":"code","5ef89043":"code","8956c342":"code","bf0710b9":"code","57254abb":"code","ef1496ad":"code","85dd9723":"code","c7460376":"code","b1181a4b":"code","2cbbd1ad":"code","cfd1904b":"code","36278fc4":"code","5f34bb34":"code","697e3aeb":"code","5ed140b3":"code","103d00a1":"code","20f21d8d":"code","7fa91d1d":"code","249ca8c6":"code","d8ed8e52":"code","43288470":"code","ddcdadf9":"code","9974f0fd":"markdown","470156ed":"markdown","dc97075a":"markdown","c944edb1":"markdown","e95656d8":"markdown","23c4ccf3":"markdown","a6c1d67e":"markdown","93dc0c7c":"markdown","f0f75d83":"markdown","02a6cbb9":"markdown","eca43767":"markdown","6b8fffea":"markdown","63f2227d":"markdown","a927587f":"markdown","f1c4a009":"markdown","bc47fbac":"markdown","6dee2103":"markdown","f5df006a":"markdown","5335529d":"markdown","bc736d28":"markdown"},"source":{"a8e5ea53":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/myimage\/DShacks.jpg\")","3511fa1d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","1c27e0fc":"#Import dataset\nloan = pd.read_csv('..\/input\/hackdataset1\/loan_traindata.csv', index_col = 'Loan_ID')","3bf0685e":"# Define function\ndef missing(x):\n    return sum(x.isnull())","4ad9800a":"# Apply per column\nprint('Missing values per column')\nloan.apply(missing, axis = 0).head()","db49d014":"# Apply per row\nprint('Missing values per column')\nloan.apply(missing, axis = 1).head()","a0c00857":"text = \"\"\"The E-Book looks amazing and I would like a copy of it, here is my e-mail id - :xyz@gmail.com | \n        Hi, I am looking for a job in data science field, ramesh4u@yahoo.in please send me the E-book and kindly suggest\n        how to move forward, thanks - ab_c@gmail.com\"\"\"","83af1672":"import re \nre.findall(r\"([\\w.-]+@[\\w.-]+)\", text)","25c1997d":"text= \"Hi \ud83d\ude02! Have a nice weekend \ud83d\udc95\ud83d\udc6d\"\npreprocessed_text=text.encode('ascii', 'ignore').decode('ascii')\n\nprint(\"Raw tweet:\",text)  #with emoji\nprint(\"Preprocessed tweet:\",preprocessed_text) # no emoji\n\n","36fcb58a":"\n\n# create a dataframe\ndf = pd.DataFrame({'name':['Ramesh Babu', 'Virat Kotari', 'Narendra Sharma']})\ndf.head()\n\n","b98408fd":"# extract first name and last name\ndf['first_name'] = df['name'].str.split(' ', expand = True)[0]\ndf['last_name'] = df['name'].str.split(' ', expand = True)[1]\n\ndf","6e3eab32":"#Exponential distribution\nX = np.random.exponential(2, (5000,1))\n\n#Log Normal distribution\nY = np.random.weibull(a = 2, size = (5000,1))\n\nplt.figure(figsize = (10,4), dpi = 120)\n\n#Plotting exponential distribution\nplt.subplot(121)\nplt.hist(X, bins = 100)\nplt.title(\"exponential distribution\")\n\n#plotting weibull distribution\nplt.subplot(122)\nplt.hist(Y, bins = 100)\nplt.title(\"weibull distribution\");","c05d2990":"\n\nfrom sklearn.preprocessing import QuantileTransformer\nqt = QuantileTransformer(n_quantiles = len(X), output_distribution = 'normal')\n\n## transforming above distributions to Normal distribution ##\nX = qt.fit_transform(X)\nY = qt.fit_transform(Y)\nprint('distributions transformed')\n\nplt.figure(figsize = (10,4), dpi = 120)\n\n#Plotting transformed exponential\nplt.subplot(121)\nplt.hist(X, bins = 100)\nplt.title(\"transformed exponential\")\n\n#plotting transformed weibull\nplt.subplot(122)\nplt.hist(Y, bins = 100)\nplt.title(\"transformed weibull\");","3ccadbd1":"\n# importing all the required libraries\nimport skimage.io as io\nfrom skimage.transform import rotate","1acc241a":"# reading the image using its path\nimage = io.imread('..\/input\/benzimage\/benz.jpg')\ndef image_augment(image):\n    fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(20,10))\n    ax[0].imshow(image)\n    ax[0].axis('off')\n    ax[1].imshow(rotate(image, angle=45, mode = 'wrap'))\n    ax[1].axis('off')\n    ax[2].imshow(np.fliplr(image))\n    ax[2].axis('off')\n    \nimage_augment(image)\n","4605e9c9":"#import dataset\ndata = pd.read_csv('..\/input\/hackdataset\/CleanData.csv')\ndata.shape","b01a0148":"\n# Seperate dependent and independent variable\nx = data.drop(['Survived'], axis = 1)\ny = data['Survived']\n\n# import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n\n","2a4ef988":"train_x, test_x, train_y, test_y = train_test_split(x, y, random_state = 45)\nprint(train_y.value_counts(normalize=True))\nprint(test_y.value_counts(normalize=True))\n\n","2a93876f":"# With Statify\ntrain_X, test_X, train_Y, test_Y = train_test_split(x, y, random_state = 56, stratify = y)\nprint(train_Y.value_counts(normalize = True))\nprint(test_Y.value_counts(normalize = True))\n\n\n","e1b02b17":"#import the dataset\ndata = pd.read_csv('..\/input\/hackdataset1\/loan_traindata.csv')\ndata.shape\n\n","fa3c5e0c":"#check data types of column\ndata.dtypes\n","87aeef2c":"# Dataframe containing only categorical variable\ncategorical_var = data.select_dtypes(\"object\").head()\ndisplay(categorical_var.head(2))\n","cfe6fbf8":"# Dataframe containing only numeric variable\nnumeric_var = data.select_dtypes(\"number\")\ndisplay(numeric_var.head(2))","c7fe75e9":"# Create a test dataframe\n# Untidy dataframe\n# x : Subjects\n# y : Student names\nmarks = pd.DataFrame(np.random.randint(0, 25, size = (30,5)), \n                     columns = ['Maths', 'Physics','Chemistry', 'Biology', 'Computer_Science'])\nmarks.head(5)","ae4a8198":"# Add student column to dataset\nmarks['Student'] = ['Student ' + str(i) for i in range(1,31)]\ndisplay(marks.head(5))","9b1b0fb2":"# Bring last column to first position\ncols = marks.columns.tolist()\nmarks = marks[['Student','Chemistry', 'Biology', 'Computer_Science', 'Maths', 'Physics']]\n","a19f87e0":"#Data in wide format\nmarks.head(5)","5ef89043":"#Data in long format\ntidy = pd.melt(marks,\n               id_vars = 'Student',\n               value_name = 'Frequency')\ntidy.head(5)","8956c342":"from sklearn.datasets import load_iris\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier(random_state=0)\niris = load_iris()\n\nclf = clf.fit(iris.data, iris.target)\n\n#Plot tree\nplt.figure(figsize = [8,8])\ntree.plot_tree(clf)\nplt.show();\n\n\n\n\n","bf0710b9":"!pip install chart_studio","57254abb":"from chart_studio.plotly import plot, iplot\nimport cufflinks as cf","ef1496ad":"cf.set_config_file(theme='ggplot',sharing='public',offline=True)\n# import data\ndata = pd.read_csv('..\/input\/hackdataset1\/loan_traindata.csv')\ndata.head(1)\n\n\n","85dd9723":"#histogram\ndata.Property_Area.iplot(kind = 'histogram');\n","c7460376":"#Box plot\ndata[['ApplicantIncome', 'CoapplicantIncome']].iplot(kind = 'box')","b1181a4b":"#scatter plot\ndata.iplot(x = 'Loan_ID', y = ['ApplicantIncome','CoapplicantIncome'], kind = 'scatter', mode = 'markers')\n","2cbbd1ad":"text='Hi! Welcome to Data Science'\ncharacters=list(text)\nprint(characters)","cfd1904b":"!pip install pandarallel","36278fc4":"%load_ext autoreload\n%autoreload 2\nimport time\nfrom pandarallel import pandarallel\nimport math\nimport random\nfrom tqdm._tqdm_notebook import tqdm_notebook\ntqdm_notebook.pandas()","5f34bb34":"pandarallel.initialize(progress_bar=True)","697e3aeb":"df = pd.DataFrame({\n    'A' : [random.randint(5,10) for i in range(1,500000) ],\n    'B' : [random.randint(5,10) for i in range(1,500000) ]\n})","5ed140b3":"def func(x):\n    return math.sin(x.A**2) + math.sin(x.B**2) + math.tan(x.A**2)","103d00a1":"#Without Parellelization\n%time\nres = df.progress_apply(func, axis=1)","20f21d8d":"#With Parellelization\n%time\nres_parallel = df.parallel_apply(func, axis=1)","7fa91d1d":"#Import dataset\nloan = pd.read_csv('..\/input\/hackdataset1\/loan_traindata.csv', index_col = 'Loan_ID')\npivot = loan.pivot_table(values = ['LoanAmount'], index = ['Gender', 'Married', 'Self_Employed'], aggfunc = np.mean)\npivot","249ca8c6":"data = pd.read_csv('..\/input\/hackdataset\/AirQuality.csv')\ndata.head(2)\n\n","d8ed8e52":"data.dtypes\n","43288470":"data['date_time'] = data['Date'] + ' ' + data['Time']\ndata['date_time'] = pd.to_datetime(data['date_time'],format='%d\/%m\/%Y %H.%M.%S')","ddcdadf9":"new_df = pd.DataFrame({\"date_time\": data['date_time'],\n              \"year\": data['date_time'].dt.year,\n              \"month\": data['date_time'].dt.month,\n              \"dayofweek\": data['date_time'].dt.dayofweek,\n              \"quarter\": data['date_time'].dt.quarter,\n              \"hour\": data['date_time'].dt.hour,\n              \"CO(GT)\": data['CO(GT)'],\n              \"PT08.S1(CO)\": data['PT08.S1(CO)'],\n              \"NMHC(GT)\": data['NMHC(GT)']\n             })\nnew_df.head(2)","9974f0fd":"* [Table of Contents](#Tableofcontents)\n<a id=\"Pandas in Parellel\"><\/a>\n#### Hack 13: Pandas in Parellel","470156ed":"# Introduction:\nDuring learning phase, I've came across with some of the DataScience hacks, Tips & Tricks and thought to bring it under this notebook and share with you for easy reference.\n\nI've provided references link in References topic. Happy Learning!!!!","dc97075a":"* [Table of Contents](#Tableofcontents)\n<a id=\"Convertstringsintocharacters\"><\/a>\n#### Hack 12: Convert strings into characters","c944edb1":"* [Table of Contents](#Tableofcontents)\n<a id=\"ExtractE-mailsfromtext\"><\/a>\n#### Hack 2: Extract E-mails from text","e95656d8":"* [Table of Contents](#Tableofcontents)\n<a id=\"TransformingDistributionstoNormalDistributions\"><\/a>\n#### Hack 5: Transforming Distributions to Normal Distributions","23c4ccf3":"* [Table of Contents](#Tableofcontents)\n<a id=\"Extractdifferentdatatypesintodifferentdataframes\"><\/a>\n#### Hack 8: Extract different datatypes into different dataframes","a6c1d67e":"* [Table of Contents](#Tableofcontents)\n<a id=\"ImageAugmentation\"><\/a>\n#### Hack 6: Image Augmentation","93dc0c7c":"With Stratify","f0f75d83":"* [Table of Contents](#Tableofcontents)\n<a id=\"PivotTable\"><\/a>\n#### Hack 14: Pivot Table","02a6cbb9":"* [Table of Contents](#Tableofcontents)\n<a id=\"Splittingastringinpython\"><\/a>\n#### Hack 4: Splitting a string in python","eca43767":"* [Table of Contents](#Tableofcontents)\n<a id=\"References\"><\/a>\n### References\n#### https:\/\/courses.analyticsvidhya.com\/courses\/take\/data-science-hacks-tips-and-tricks\/texts\/10742305-about-the-data-science-hacks-tips-and-tricks-course\n    \n#### Special thanks to Author: Kunal jain for wonderful course on Analytics Vidhya\n    ","6b8fffea":"* [Table of Contents](#Tableofcontents)\n<a id=\"InteractivePlotusingcufflinks\"><\/a>\n#### Hack 11: Interactive Plot using cufflinks","63f2227d":"* [Table of Contents](#Tableofcontents)\n<a id=\"VisualizeDecisionTree\"><\/a>\n#### Hack 10: Visualize Decision Tree","a927587f":"* [Table of Contents](#Tableofcontents)\n<a id=\"SplitingDataintoStratify\"><\/a>\n#### Hack 7: Spliting Data into Stratify\n","f1c4a009":"* [Table of Contents](#Tableofcontents)\n<a id=\"RemoveEmoji'sfromtext\"><\/a>\n#### Hack 3: Remove Emoji's from text","bc47fbac":"* [Table of Contents](#Tableofcontents)\n<a id=\"unmeltdataconvertwideformdataframeintolongform\"><\/a>\n#### Hack 9: unmelt data convert wide form dataframe into long form dataframe","6dee2103":"<a id=\"Tableofcontents\"><\/a>\n# Table of Contents\n* [Hack 1: Pandas Apply to find Missing Values](#PandasApplytofindMissingValues)\n* [Hack 2: Extract E-mails from text](#ExtractE-mailsfromtext)\n* [Hack 3: Remove Emoji's from text](#RemoveEmoji'sfromtext)\n* [Hack 4: Splitting a string in python](#Splittingastringinpython)\n* [Hack 5: Transforming Distributions to Normal Distributions](#TransformingDistributionstoNormalDistributions)\n* [Hack 6: Image Augmentation](#ImageAugmentation)\n* [Hack 7: Spliting Data into Stratify](#SplitingDataintoStratify)\n* [Hack 8: Extract different datatypes into different dataframes](#Extractdifferentdatatypesintodifferentdataframes)\n* [Hack 9: unmelt data convert wide form dataframe into long form dataframe](#unmeltdataconvertwideformdataframeintolongform)\n* [Hack 10: Visualize Decision Tree](#VisualizeDecisionTree)\n* [Hack 11: Interactive Plot using cufflinks](#InteractivePlotusingcufflinks)\n* [Hack 12: Convert strings into characters](#Convertstringsintocharacters)\n* [Hack 13: Pandas in Parellel](#PandasinParellel)\n* [Hack 14: Pivot Table](#PivotTable)\n* [Hack 15: Feature Engineering for TimeSeries Data](#FeatureEngineeringforTimeSeriesData)\n* [References](#References)","f5df006a":"* [Table of Contents](#Tableofcontents)\n<a id=\"FeatureEngineeringforTimeSeriesData\"><\/a>\n#### Hack 15: Feature Engineering for TimeSeries Data","5335529d":"* [Table of Contents](#Tableofcontents)\n<a id=\"PandasApplytofindMissingValues\"><\/a>\n### Hack 1: Pandas Apply to find Missing Values","bc736d28":"Without Stratify"}}