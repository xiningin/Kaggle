{"cell_type":{"796a0efa":"code","04d77004":"code","216d92ae":"code","b0e4b9a7":"code","05cf8f5e":"code","6bff326e":"code","24f97857":"code","3eb389c6":"code","c80210bd":"code","71f8230c":"code","4d9822d2":"code","640621fd":"code","d2aa8518":"code","1184ba0f":"code","9c7b6814":"code","da513d10":"code","b6413209":"code","113723f5":"code","35057ecc":"code","1419601a":"code","3bbbc3ba":"code","eb03c61c":"code","91833056":"code","996da961":"code","de0643d4":"code","c67002b9":"code","8dac1c71":"code","5a66ed67":"code","fc4472d9":"code","66df6c7d":"code","bb1e24b7":"code","ab7ac770":"code","0a03c4eb":"code","0381d9d0":"code","7bf9ab0e":"code","d03c5479":"code","d278ecf5":"code","d0e80893":"code","1b00e280":"code","66104dde":"code","46877b5d":"markdown","13add7bd":"markdown","6acd2c16":"markdown","32539b64":"markdown","ce238ae5":"markdown","174b420b":"markdown","087727de":"markdown","b09921c9":"markdown","7b708e7a":"markdown","3c4fdb94":"markdown","9d14530f":"markdown","9ba5ac1b":"markdown","0d5ac32c":"markdown","ded96cc0":"markdown","3641af5a":"markdown","f81f4d02":"markdown","13b51d48":"markdown","339bd718":"markdown","628b3986":"markdown","4d5b50d3":"markdown","363f5ad5":"markdown","eb9156c7":"markdown","29fc5608":"markdown","bc7612dc":"markdown","3789121c":"markdown","8b7f4146":"markdown","5bab72fd":"markdown","e5043960":"markdown","46324765":"markdown","2e1c9418":"markdown","bca77687":"markdown","94670bd3":"markdown","9d88857a":"markdown","7979761f":"markdown","08c54513":"markdown","d9de7d90":"markdown","c21a2ca5":"markdown","7945e102":"markdown","cd781e51":"markdown","9d5fea5f":"markdown","386d8df2":"markdown","d2580c4c":"markdown","93bd7e44":"markdown","e4faa774":"markdown","f010a36e":"markdown"},"source":{"796a0efa":"# Importation de la librairie warnings et d\u00e9sactivation des avertissements (pour rendre les sorties code plus lisible et \u00e9viter les avertissements de version de librairies)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Importation des librairies pandas et numpy permettant la manipulation des donn\u00e9es et des tableaux multidimensionnels \nimport pandas as pd\nimport numpy as np\n\n# Librairies de visualisation permettant de tracer diff\u00e9rents graphes.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Param\u00e8trage des visualisations\nsns.set(style='darkgrid')\nplt.rcParams[\"patch.force_edgecolor\"] = True","04d77004":"# Nous devons dans un premier temps charger les donn\u00e9es depuis notre dataset. Le dataset contient 2 fichiers 'train.csv'\n# et 'test'.csv' contenant respectivement plus de 550 000 entr\u00e9es et plus de 234 000 entr\u00e9es.\n\n# Nous chargons donc les donn\u00e9es dans un tableau de donn\u00e9es.\n\n# Train set\ntrain = pd.read_csv('..\/input\/train.csv')\n# Test set\ntest = pd.read_csv('..\/input\/test.csv')","216d92ae":"# Regardons les 5 premi\u00e8res entr\u00e9es ainsi que les 5 derni\u00e8res pour se donner une id\u00e9e de la forme que prenne les entr\u00e9es.\n\n# Ensemble d'entrainement:\n\n# 5 premi\u00e8res lignes pour l'ensemble d'entrainement:\ntrain.head(5)","b0e4b9a7":"# 5 derni\u00e8res lignes pour l'ensemble d'entrainement:\ntrain.tail(5)","05cf8f5e":"# Visualisons \u00e9galement les types des donn\u00e9es d'entr\u00e9e ainsi que la taille exacte de l'ensemble de donn\u00e9es.\nprint(train.info())\nprint('Shape: ',train.shape)","6bff326e":"# Explication ici: tailles des ensembles de donn\u00e9es.\n# Nombre de colonnes pour l'ensemble train: 12 => target(price) est dans l'ensemble; nous nous en servirons pour entrainer l'algorithme\n# A l'inverse, 11 colomnes pour l'ensemble train (pas la target). Nous nous en servirons pour tester les performances de l'algorithme sur plusieurs mod\u00e8les de r\u00e9gression\n# Parler \u00e9galement du type des variables et de la signification de chacune des colomnes","24f97857":"# Ensemble de test:\n\n# 5 premi\u00e8res lignes pour l'ensemble de test:\ntest.head(5)","3eb389c6":"# 5 derni\u00e8res lignes pour l'ensemble de test:\ntest.tail(5)","c80210bd":"# Visualisons \u00e9galement les types des donn\u00e9es d'entr\u00e9e ainsi que la taille exacte.\nprint(test.info())\nprint('Shape: ',test.shape)","71f8230c":"# Examinons de plus pr\u00e8s les valeurs manquantes des ensemble des donn\u00e9es\n\n# Ensemble d'apprentissage\n\ntotal_miss = train.isnull().sum()\nperc_miss = total_miss\/train.isnull().count()*100\n\nmissing_data = pd.DataFrame({'Total missing':total_miss,\n                            '% missing':perc_miss})\n\nmissing_data.sort_values(by='Total missing',\n                         ascending=False).head(3)","4d9822d2":"# Ensemble de test\n\ntotal_miss = test.isnull().sum()\nperc_miss = total_miss\/test.isnull().count()*100\n\nmissing_data = pd.DataFrame({'Total missing':total_miss,\n                            '% missing':perc_miss})\n\nmissing_data.sort_values(by='Total missing',\n                         ascending=False).head(3)","640621fd":"# Nous devons maintenant nous occuper de ces donn\u00e9es manquantes.\n# Plusieurs choix s'offrent \u00e0 nous. Nous pourrions simplement supprimer les lignes poss\u00e8dant une valeur manquante.\n# Cependant, ce choix apparait ici tr\u00e8s mauvais car pr\u00e8s de 70% des donnn\u00e9es sont manquantes pour la colomne 'Product_Category_3'.\n# Compte tenu du fort pourcentage de donn\u00e9es manquante pour cette colomne, nous choisissons de la supprimer de l'ensemble d'apprentissage et de l'ensemble de test.\nhalf_count_train = len(train) \/ 2 # Cette ligne est un seuil\nhalf_count_test = len(test) \/ 2 # Cette ligne est un seuil\n\ntrain = train.dropna(thresh=half_count_train,axis=1) # Cette ligne supprime les colomne comportant plus de 50% de donn\u00e9es manquantes\ntest = test.dropna(thresh=half_count_test,axis=1) # Cette ligne supprime les colomne comportant plus de 50% de donn\u00e9es manquantes","d2aa8518":"# Regardons de nouveau un \u00e9chantillon de nos ensembles.\ntrain.head()","1184ba0f":"test.head()","9c7b6814":"print(train.Product_Category_2)","da513d10":"print(train.Product_Category_2.min())\nprint(train.Product_Category_2.max())","b6413209":"print(test.Product_Category_2.min())\nprint(test.Product_Category_2.max())","113723f5":"# Commencons par calculer cette moyenne\navg_train = train.Product_Category_2.mean()\navg_test = test.Product_Category_2.mean()\n\nprint(avg_train)\nprint(avg_test)","35057ecc":"# Remplacons les valeurs manquantes de l'ensemble d'apprentissage et de l'ensemble de test par les moyennes repectives \ntrain['Product_Category_2'].fillna(avg_train, inplace=True)\ntest['Product_Category_2'].fillna(avg_test, inplace=True)","1419601a":"print(train.Product_Category_2)","3bbbc3ba":"print(test.Product_Category_2)","eb03c61c":"# Train set\nunique_users = len(train.User_ID.unique())\nunique_products = len(train.Product_ID.unique())\nprint('There are {} unique users and {} unique products in the train set'.format(unique_users, unique_products))","91833056":"# Test set\nunique_users = len(test.User_ID.unique())\nunique_products = len(test.Product_ID.unique())\nprint('There are {} unique users and {} unique products in the test set'.format(unique_users, unique_products))","996da961":"# Drop the columns Product_Id and User_Id in the train and test set\ntrain = train.drop(columns=\"User_ID\")\ntrain = train.drop(columns=\"Product_ID\")\ntest = test.drop(columns=\"User_ID\")\ntest = test.drop(columns=\"Product_ID\")","de0643d4":"for col_name in ['Gender', 'Age', 'Occupation', 'City_Category']:\n    print(sorted(train[col_name].unique()))\n    print(sorted(test[col_name].unique()))","c67002b9":"train['Marital_Status'].unique()","8dac1c71":"train['Stay_In_Current_City_Years'].unique()","5a66ed67":"# Train set\n# We first need to convert the '4+' value to simply '4'\ntrain['Stay_In_Current_City_Years'] = [x.strip().replace('4+', '4') for x in train['Stay_In_Current_City_Years']]\n# Then we need to replace the object type values by integers                                                                                       \ntrain['Stay_In_Current_City_Years'] = train['Stay_In_Current_City_Years'].astype(str).astype(int)\nprint(train['Stay_In_Current_City_Years'])\n\n# Test set\ntest['Stay_In_Current_City_Years'] = [x.strip().replace('4+', '4') for x in test['Stay_In_Current_City_Years']]\n# Then we need to replace the object type values by integers                                                                                       \ntest['Stay_In_Current_City_Years'] = test['Stay_In_Current_City_Years'].astype(str).astype(int)\nprint(test['Stay_In_Current_City_Years'])","fc4472d9":"# Drop the columns Product_Category_1 and Product_Category_2 in the train and test set\ntrain = train.drop(columns=\"Product_Category_1\")\ntrain = train.drop(columns=\"Product_Category_2\")\ntest = test.drop(columns=\"Product_Category_1\")\ntest = test.drop(columns=\"Product_Category_2\")","66df6c7d":"for col_name in train.columns:\n    print(col_name, len(train[col_name].unique()))","bb1e24b7":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=[15, 15])\n\ntrain['Gender'].value_counts().plot(kind='barh', ax=axes[0,0], title='Gender')\ntrain['Age'].value_counts().plot(kind='barh', ax=axes[0,1], title='Age')\ntrain['City_Category'].value_counts().plot(kind='barh', ax=axes[1,0], title='City_Category')\ntrain['Marital_Status'].value_counts().plot(kind='barh', ax=axes[1,1], title='Marital_Status')\ntrain['Occupation'].value_counts().plot(kind='barh', ax=axes[2,0], title='Occupation')\ntrain['Stay_In_Current_City_Years'].value_counts().plot(kind='barh', ax=axes[2,1], title='Stay_In_Current_City_Years')","ab7ac770":"for col_name in test.columns:\n    print(col_name, len(test[col_name].unique()))","0a03c4eb":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=[15, 15])\n\ntest['Gender'].value_counts().plot(kind='barh', ax=axes[0,0], title='Gender')\ntest['Age'].value_counts().plot(kind='barh', ax=axes[0,1], title='Age')\ntest['City_Category'].value_counts().plot(kind='barh', ax=axes[1,0], title='City_Category')\ntest['Marital_Status'].value_counts().plot(kind='barh', ax=axes[1,1], title='Marital_Status')\ntest['Occupation'].value_counts().plot(kind='barh', ax=axes[2,0], title='Occupation')\ntest['Stay_In_Current_City_Years'].value_counts().plot(kind='barh', ax=axes[2,1], title='Stay_In_Current_City_Years')","0381d9d0":"# Rappelons que les variables cat\u00e9goriques sont les suivantes: Age, Gender, Occupation, Ciy_Category, Marital_Status, Product Category 1, \u00a8Product Category 2\ntrain.dtypes","7bf9ab0e":"# Train set\n# Nous remplacons tout d'abord les valeurs de la colonne 'Gender' initialement \u00e9gales \u00e0 'F' par 0 et 'M' par 1\n# Cette op\u00e9ration n'est pas n\u00e9cessaire pour la colonne 'Marital_Status' puisque ces valeurs sont d\u00e9j\u00e0 sous cette forme\ntrain.Gender = np.where(str(train.Gender)=='M',1,0) # Femelle: 0, Male: 1\ntest.Gender = np.where(str(test.Gender)=='M',1,0) # Femelle: 0, Male: 1\n\n# Nous encodons ensuites les variables cat\u00e9goriques (Age, City_Category, Occupation)\ntrain_Age = pd.get_dummies(train.Age)\ntrain_CC = pd.get_dummies(train.City_Category)\ntrain_Occup = pd.get_dummies(train.Occupation)\ntest_Age = pd.get_dummies(test.Age)\ntest_CC = pd.get_dummies(test.City_Category)\ntest_Occup = pd.get_dummies(test.Occupation)\n\n# Et nous remplacons les variables cat\u00e9goriques initiales par les variables encod\u00e9es\ntrain_encoded = pd.concat([train_Age,train_CC,train_Occup,train],axis=1)\ntrain_encoded.drop(['Age','City_Category','Occupation'],axis=1,inplace=True)\ntest_encoded = pd.concat([test_Age,test_CC,test_Occup,test],axis=1)\ntest_encoded.drop(['Age','City_Category','Occupation'],axis=1,inplace=True)\nprint(train_encoded)\nprint(test_encoded)","d03c5479":"X_train = train_encoded.iloc[:, :-1].values # Prend toutes les colonnes sauf la derni\u00e8re (variable cible)\ny_train = train_encoded.iloc[:,-1].values # Prend la derni\u00e8re colonne (variable cible)\n\n# Pour pr\u00e9sire les nouveaux r\u00e9sultats\nX_test = test_encoded # Prend toutes les colonnes sauf la derni\u00e8re (variable cible)","d278ecf5":"# Fitting Random Forest Regression to the dataset\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 10, random_state = 0) # nous utilisons une foret de 10 arbres d\u00e9cisionnels, random_state supprime la variabilit\u00e9 des r\u00e9sultats\nregressor.fit(X_train, y_train)","d0e80893":"# Predict new results on the test set\nprediction = np.round(regressor.predict(X_test))\nprint(prediction)\n# Reshape prediction vector into a 2D matrix\nprediction = prediction.reshape(len(prediction), 1)\n\n# concatenate X_test with prediction \ndataTest = np.concatenate((X_test, prediction), axis = 1)\nprint(dataTest)","1b00e280":"# Feature importance \nf_im = regressor.feature_importances_.round(3)\nser_rank = pd.Series(f_im,index=test_encoded.columns).sort_values(ascending=False)\n\nplt.figure()\nsns.barplot(y=ser_rank.index,x=ser_rank.values,palette='deep')\nplt.xlabel('relative importance')","66104dde":"# Options pour afficher davantage de colonnes en sortie\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n# Option pour avoir des r\u00e9sultats consistants\nnp.random.seed(0)\n\n# Pour faciliter la manipulation des donn\u00e9es, repartons de l'ensemble de test duquel nous avons supprim\u00e9 les colonnes\n# inutiles \u00e0 notre analyse. Ajoutons simplement une colonne prediction \u00e0 cet ensemble.\ntest['prediction'] = prediction\n# Nous prenons 10 lignes de l'ensemble de test et les ordonnons selon la valeur de la colonne pr\u00e9diction \n# (par ordre d\u00e9croissant)\nprint(test.sample(10).sort_values(by='prediction',ascending=False))\n","46877b5d":"#### Gender, Age, Occupation, and City_Category","13add7bd":"Seulement 2 colomnes: 'Product_Category_3'  et 'Product_Category_2' poss\u00e8dent des valeurs manquantes. La colonne 'Product_Category_3' poss\u00e8de pr\u00e8s de 70% de valeurs manquantes et  la colomne 'Product_Category_2' plus de 30% de donn\u00e9es manquantes.","6acd2c16":"Il semble que les valeurs de cette colonnes sont comprises entre 2 et 18. Nous pouvons remplacer les valeurs manquantes par la moyenne des valeurs non nulles de la colonne","32539b64":"Ces 4 colonnes sont relativement simples dans une optique de pr\u00e9traitement. \n\nCommencons par visualiser le d\u00e9tail des cat\u00e9gories pour chacune des 4 colonnes.","ce238ae5":"### Visualisation pr\u00e9liminaire","174b420b":"Dans cette partie, nous allons analyser graphiquement les donn\u00e9es pour avoir une meilleure vue d'ensemble de celles-ci et pour d\u00e9gager les variables les plus importantes pour la d\u00e9termination du montant du panier d'achat d'un consommateur.","087727de":"V\u00e9rifions que les donn\u00e9es manquantes ont bien \u00e9t\u00e9 remplac\u00e9es comme d\u00e9sir\u00e9.","b09921c9":"Les cat\u00e9gories de chaque colonne sont identiques pour l'ensemble d'apprentissage et l'ensemble de test. Le nombre de cat\u00e9gories est plutot faible (maximum 21 pour la colonne 'Occupation')  \nCes colonnes sont toutes des cat\u00e9gories qui peuvent \u00eatre encod\u00e9es via des vecteurs one-hot encoded. Cette partie d'encodage sera effectu\u00e9e dans la partie suivante. ","7b708e7a":"Ces donn\u00e9es sont des identifiants et doivent ainsi \u00eatre trait\u00e9es comme donn\u00e9es cat\u00e9gorie.\nNous devons connaitre un peu mieux la distribution de ces donn\u00e9es pour d\u00e9terminer le nombre de cat\u00e9gories pr\u00e9sentes.","3c4fdb94":"> ##  Conclusion","9d14530f":"Nous avons supprimer la colonne 'Product_Category_3' de nos 2 tableaux de donn\u00e9es 'train' et 'test'. Cependant, nous l'avons vu, la colone 'Product_Category_2' poss\u00e8de plus de 30% de donn\u00e9es manquantes; pourcentage important mais qui reste inf\u00e9rieur au seuil fix\u00e9 de 50%.\nAinsi cette colonne demeure dans les 2 tableaux de donn\u00e9es. Les donn\u00e9es manquantes de cette colonne ne peuvent cependant pas rester inchang\u00e9es dans les tableaux. ","9ba5ac1b":"Rappelons que notre ensemble de donn\u00e9es contenait plus d'un demi million d'entr\u00e9es . Ainsi il y'a environ 100 lignes pour chaque utilisateur et 160 lignes pour chaque produit. Ces colonnes sont donc importantes et ne doivent  pas \u00eatre supprimer dans le cadre d'une analyse cibl\u00e9e sur un \u00e9chantillon de consommateurs.\nEn effet, nous avons suffisament d'informations dans notre ensemble de donn\u00e9es pour apprendre des identifiants consommateurs et des identifiants produits.\nCependant, le nombre de cat\u00e9gories est tr\u00e8s important et il serait compliqu\u00e9 de simplement encoder chacune des cat\u00e9gories  par des vecteurs type one-hot encoder. (remplacement de chaque cat\u00e9gorie par un vecteur de taille n o\u00f9 n est le nombre de cat\u00e9gories et o\u00f9 chaque entr\u00e9e du vecteur est repr\u00e9sent\u00e9e par un 1 ou un 0 en fonction de la pr\u00e9sence ou non de la cat\u00e9gorie consid\u00e9ree.)\n\nDe plus, ces colonnes ne permettent pas d'avoir une g\u00e9n\u00e9ralisation permettant de cibler globalement un large \u00e9ventail de consommateurs (au contraire de l'age, du statut marital, ...) puisque chaque entr\u00e9e est sp\u00e9cifique \u00e0 un consommateur dans le cadre de l'identifiant consommateur et sp\u00e9cifique \u00e0 un seul produit pour l'identifiant produit.\n\nNous d\u00e9cidons ainsi de supprimer ces colonnes de notre analyse.","0d5ac32c":"### Traitement de valeurs manquantes","ded96cc0":"### Visualisation","3641af5a":"#### Ensemble de test","f81f4d02":"Cette colonne est \u00e9galement cat\u00e9gorique. En effet, la valeur de chacune des entr\u00e9es pour cette colonne peut \u00eatre soit 0 (individu non mari\u00e9) soit 1 (individu mari\u00e9).  ","13b51d48":"### Etude et repr\u00e9sentation des colonnes","339bd718":"Les variables 'Marital_Status' et 'Gender' peuvent \u00eatre repr\u00e9sent\u00e9es simplement par des donn\u00e9es binaires (0 ou 1) et ne n\u00e9cessitent donc pas d'\u00eatre one-hot-encoded. Cependant, les autres variables doivent subir ce traitement pour ne pas biaiser l'apprentissage de l'algorithme.","628b3986":"### Encodage","4d5b50d3":"Nos colonnes sont maintenant bien encod\u00e9es. Les donn\u00e9es sont ainsi pr\u00eates pour \u00eatre analys\u00e9es et utilis\u00e9es pour l'apprentissage de notre algorithme.","363f5ad5":"#### Marital_Status","eb9156c7":"Nous pouvons observer que le type des valeurs de cette colonne sont des chaines de caract\u00e8res et non des entiers comme nous pourrions le penser.\nCeci s'explique par le fait qu'une de ces valeurs repr\u00e9sente en fait une cat\u00e9gorie (\u00e0 savoir 4+). Pour \u00e9viter la cr\u00e9ation de nouvelles cat\u00e9gories, nous faisons le  choix de transformer le type de cette variable en entier.  Cette op\u00e9ration permettra de lin\u00e9ariser les donn\u00e9es de cette colonne de fa\u00e7on \u00e0 ce qu'il y'ait une relation d'ordre entre celles-ci.","29fc5608":"Nous avons pr\u00e9alablement supprimer la colonne Product_Category_3 car celle-ci contenait un nombre de donn\u00e9es manquantes supp\u00e9rieur au seuil que nous avons fix\u00e9 \u00e0 50%. Les cat\u00e9gories de produit 1 et 2 quant \u00e0 elles demeurent dans notre ensemble de donn\u00e9es. Cependant au m\u00eame titre que l'identifiant produit ou l'identifiant consommateur, ces informations ne permettent pas une bonne g\u00e9n\u00e9ralisation et s'inscrivent davantage dans le cadre d'une analyse cibl\u00e9e o\u00f9 une analyse r\u00e9trospective (une fois que nous connaissons la valeur du montant du panier des consommateurs, ces donn\u00e9es sont particulierement utiles pour une analyse de suivi client.) \nDans le cadre de notre \u00e9tude, nous cherchons \u00e0 utiliser les indicateurs bas niveaux comme l'age, le sexe, le statut marital, l'occupation ou encore le nombre d'ann\u00e9es pass\u00e9es dans la ville de r\u00e9sidence actuelle des  consommateurs  pour d\u00e9gager des tendances et faire un ciblage global de types de consommateurs.\n\nNous d\u00e9cidons ainsi de supprimer \u00e9galement les colonnes Product_Category_1 et Product_Category_2.","bc7612dc":"Nous pouvons clairement voir que le temps pass\u00e9 dans la ville de r\u00e9sidence actuelle est le crit\u00e8re majeur dans l'apprentissage de l'algorithme (pr\u00e8s de 25% de l'apprentissage est du \u00e0 ce crit\u00e8re) suivi par le statut marital ( ~11 % de l'apprentissage total) puis l'age du consommateur ainsi que la cat\u00e9gorie social de sa ville de r\u00e9sidence.","3789121c":"Diff\u00e9rents algorithmes de r\u00e9gression permettent de donner de bons r\u00e9sultats (Seulement si la phase de pr\u00e9traitement a bien \u00e9t\u00e9 op\u00e9ree).\nNous impl\u00e9menterons l'algorithme 'for\u00eat d'arbres d\u00e9cisionnels' plus connu en anglais sous le nom de 'Random Forest'","8b7f4146":"## New part","5bab72fd":"Les donn\u00e9es manquantes ont bien \u00e9t\u00e9 remplac\u00e9es. Il nous faut maintenant continuer le processus de pr\u00e9traitement des donn\u00e9es en analysant davantage les colonnes.","e5043960":"Testons maintenant la performance de notre algorithme en comparant les r\u00e9sultats obtenus \u00e0 la visualisation effectu\u00e9e pr\u00e9c\u00e9demment. \nPour cela, nous pouvons afficher les donn\u00e9es d'entr\u00e9es pour diff\u00e9rentes valeurs de sortie de l'algorithme (prix du panier consommateur) et les comparer  aux conclusions faites post visualisation.\n\n","46324765":"## Partie 1: Pr\u00e9traitement des donn\u00e9es","2e1c9418":"#### Product_Category","bca77687":"**Le consommateur parfait**\n![](http:\/\/1.bp.blogspot.com\/-a1RLc8TDlYc\/UcrD6y7jD2I\/AAAAAAAABXc\/tmtZDOwyckg\/s1600\/blond+barbe.jpg)","94670bd3":"Pour commencer, nous pouvons separer les variables ind\u00e9pendantes de la variable d\u00e9pendante (variable cible).","9d88857a":"#### Stay_In_Current_City_Years","7979761f":"#### Ensemble d'apprentissage","08c54513":"La distribution des donn\u00e9es de l'ensemble de test est assez similaire \u00e0 celle de l'ensemble d'apprentissage. Ceci laisse supposer de bons r\u00e9sultats lors de la phase d'analyse pr\u00e9dictive.\nSur la base de la visualisation effectu\u00e9e, nous sommes en mesure de d\u00e9gager les resultats suivants:\n\n* Les Hommes consomment plus que les Femmes\n* Les C\u00e9libataires consomment davantage que les personnes mari\u00e9es\n* Les Clients r\u00e9sidant dans une ville de niveau social interm\u00e9diaire d\u00e9pensent plus\n* Les Clients ayant v\u00e9cu 1 an dans leur ville de r\u00e9sidence actuelle d\u00e9pensent plus\n* Les Clients de 29 \u00e0 36 ans sont les plus d\u00e9pensiers\n\n\nCes simples relations permettent de d\u00e9gager des tendances et d'\u00e9tablie un profil consommateur \u00e0 cibler en priorit\u00e9 lors de campagnes marketing.\nIci, compte tenu des r\u00e9sultats \u00e9tablis, le consommateur parfait serait un homme c\u00e9libataire d'une trentaine d'ann\u00e9es vivant dans une ville de niveau social interm\u00e9diaire depuis 1 an.","d9de7d90":"Nous avons impl\u00e9menter un algorithme nous permettant de pr\u00e9dire le montant du panier d'un consommateur connaissant son sexe, statut marital, age, occupation et nombre d'ann\u00e9es pass\u00e9es dans la ville de r\u00e9sidence actuelle.\nCet algorithme se base sur des indicateurs bas niveaux facilement identifiables et pourra permettre d'estimer la potentialit\u00e9 \u00e0 l'achat d'un consommateur. \nDans la partie visualisation, nous avons \u00e9galement pu dresser le profil du consommateur parfait \u00e0 cibler en priorit\u00e9 lors de campagnes marketing notamment (Black Friday ou autres).\nUne analyse cibl\u00e9e ou r\u00e9trospective qui prendrait en compte l'ensemble des indicateurs de l'ensemble de donn\u00e9es utilis\u00e9 pourrait venir compl\u00e9ter cette \u00e9tude et d\u00e9terminer notamment les produits g\u00e9n\u00e9rant le plus de ventes.","c21a2ca5":"## Partie 3: Algorithme","7945e102":"#### User_ID et Product_ID","cd781e51":"Image du proc\u00e9d\u00e9 d'encodage \n![](https:\/\/cdn-images-1.medium.com\/max\/1368\/0*T5jaa2othYfXZX9W.)\n","9d5fea5f":"Cette colonne repr\u00e9sente le nombre d'ann\u00e9es pass\u00e9s par un consommateur dans la m\u00eame ville. Nous pouvons imaginer une corr\u00e9lation entre le nombre d'ann\u00e9es pass\u00e9es dans la m\u00eame vilel et le prix du panier d'un consommateur lors du black Friday. Un consommateur ayant longuement v\u00e9cu dans la m\u00eame ville peut poss\u00e9der davantage de ressources financi\u00e8res qu'un nouvel habitant.","386d8df2":"Pour que l'algorithme que nous r\u00e9aliserons dans la section suivante n'apprenne pas des relations d'ordre inexisante entre les variables cat\u00e9goriques (genre, statut marital, tranche d'age...), il nous faut encoder ces variables d'apr\u00e8s la m\u00e9thode de one hot encoding explicit\u00e9e pr\u00e9cedemment.","d2580c4c":"Affichons le minimum et le maximum de cette colonne pour l'ensemble de donn\u00e9es d'entrainement et de test.","93bd7e44":"Nous avons impl\u00e9m\u00e9ment\u00e9 un algorithme nous permettant de pr\u00e9voir le montant du panier d'un consommateurs connaissant son age, son sexe, son statut marital et autres indicateurs utilis\u00e9s.\nNous pouvons maintenant nous pencher sur ces r\u00e9sultats et d\u00e9terminer notamment les crit\u00e8res qui influencent le plus le montant d'un panier consommateur lors du Black Friday.","e4faa774":"## Partie 2: Visualisation et encodage","f010a36e":"Int\u00e9ressons nous donc \u00e0 cette colonne plus en d\u00e9tail pour d\u00e9terminer une technique de remplacement des donn\u00e9es manquantes."}}