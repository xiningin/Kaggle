{"cell_type":{"2685fe56":"code","16eb9111":"code","7b911903":"code","ce6759eb":"code","dee7c08f":"code","f5301cf2":"code","627a1e16":"code","7a264790":"code","815be258":"code","6a5feb31":"code","6cd0723e":"code","c4676001":"code","378c728e":"code","b6a9c050":"code","47dde1dc":"code","ecf3ffe7":"code","b238db7d":"code","de05219d":"code","488e69ad":"code","3d0dc28d":"markdown","7eabd577":"markdown","0d1ff1ca":"markdown","d185a2d3":"markdown","5484e27e":"markdown","a92eadf3":"markdown","07c9d152":"markdown","1ddca853":"markdown","7f1765e8":"markdown","9d7d3bfb":"markdown","e19cd5b7":"markdown","37ec9e7a":"markdown","cb0e87a9":"markdown","c0d7c3a4":"markdown","2a1e38c3":"markdown"},"source":{"2685fe56":"!pip install -U pip\n!pip install drdigit-brezniczky==0.0.12","16eb9111":"from collections import OrderedDict\nimport numpy.random as rnd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport drdigit as drd\nimport poland_2019_ep_preprocessing as pp\n\n# I keep this commented out and uncomment it before committing\ndrd.set_option(physical_cache_path=\"\")  # as IMHO Kaggle dislikes joblib","7b911903":"df, info = pp.get_preprocessed_data()","ce6759eb":"print(df.columns)","dee7c08f":"print(info)","f5301cf2":"df[\"ld_\" + info.get_lista_column(4)].iloc[:5]","627a1e16":"df[info.get_lista_column(4)].iloc[:5]","7a264790":"# to fix the smooth filtering\nrnd.seed(1234)\n\ntests = OrderedDict()\n\n# p-values for Lista 4 filtered per ward, MIN_N_WARDS = 0\n# 100: 0.0746\n# 200: 0.0172\n# 300: 0.0426\n\n# minimum number of party-specific votes to require \n# per each row\/each ward in a municipality\nMIN_VOTE_LIMIT = 100\n# minimum electoral wards to require per municipality\nMIN_N_WARDS = 0\n# number of simulation iterations - increase to get smoother CDFs\nLL_ITERATIONS = 5000\n\nfor feasibility in [\"municipality\", \"ward\"]:\n    for lista in [3, 4]:\n        if feasibility == \"ward\":\n            feasible_df = drd.get_feasible_rows(\n                df, MIN_VOTE_LIMIT,\n                [list(df.columns).index(\n                    info.get_lista_column(lista))]\n            )\n        else:\n            # I promise this filter will change :)\n            groups = drd.get_feasible_groups(\n                df, min_n_wards=MIN_N_WARDS,\n                min_votes=MIN_VOTE_LIMIT,\n                value_colname=info.get_lista_column(lista),\n                group_colname=info.area_column,\n            )\n            feasible_df = df[df[info.area_column].isin(groups)]\n        \n        print(\"Lista %d, by %s, nr of municipalities: %d\" % \n              (lista, feasibility, len(feasible_df)))\n\n        tests[(lista, feasibility)] = \\\n            drd.LodigeTest(\n                digits=feasible_df[\"ld_\" + info.get_lista_column(lista)],\n                group_ids=feasible_df[info.area_column],\n                bottom_n=20,\n                avoid_inf=True,\n                quiet=True,\n                ll_iterations=LL_ITERATIONS,\n            )","815be258":"p_values = [tests[test_id].p for test_id in sorted(tests.keys())]\n\ntest_results = pd.DataFrame(dict(Lista=[x for x, _ in tests.keys()], \n                                 Filtered_by=[x for _, x in tests.keys()],\n                                 p_value=p_values))\n# column order\ntest_results = test_results[[\"Lista\", \"Filtered_by\", \"p_value\"]]\n\ntest_results","6a5feb31":"for lista, filtered_by in sorted(tests.keys()):\n    test = tests[(lista, filtered_by)]\n    drd.plot_entropy_distribution(\n        actual_total_ent=test.likelihood,\n        p=test.p,\n        entropies=test.cdf.sample,\n        title=\"Lista %d filtered on the %s level\" % (lista, filtered_by)\n    )","6cd0723e":"def check_ranking(merged, info):\n    feasible_df = drd.get_feasible_rows(\n        merged,\n        100,\n        [list(merged.columns).index(info.get_lista_column(4))]\n    )\n\n    scores = drd.get_group_scores(feasible_df[info.area_column],\n                                  feasible_df[info.get_lista_column(4)].values % 10,\n                                  overhearing_base_columns=[\n                                      feasible_df[info.valid_votes_column].values % 10,\n                                      feasible_df[info.get_lista_column(4)].values % 10,\n                                  ],\n                                  overhearing_indep_columns=[\n                                      feasible_df[info.get_lista_column(3)].values % 10,\n                                  ],\n                                  quiet=True  # this many messages would ruin the notebook\n                                  )\n\n    scores.sort_values(inplace=True)\n    return scores\n\nranking = check_ranking(df, info)","c4676001":"ranking.head()","378c728e":"plt.hist(ranking, bins=20)\nplt.title(\"Distribution of scores by area code\")\nplt.show()","b6a9c050":"old_figsize = plt.rcParams[\"figure.figsize\"]\ntry:\n    plt.rcParams[\"figure.figsize\"] = [9, 7]\n    drd.plot_explanatory_fingerprint_responses(fontsize=16)\nfinally:\n    plt.rcParams[\"figure.figsize\"] = old_figsize","47dde1dc":"def plot_PL_fingerprint(merged, info, areas, group_desc, lista_index):\n    act_df = merged[merged[info.area_column].isin(areas)]\n    drd.plot_fingerprint(\n        party_votes=act_df[info.get_lista_column(lista_index)],\n        valid_votes=act_df[info.valid_votes_column],\n        registered_voters=act_df[info.nr_of_registered_voters_column],\n        title=\"Poland %s, 2019 EP, lista %d\" %\n              (group_desc, lista_index),\n        quiet=False,\n    )\n\nn = len(ranking)","ecf3ffe7":"plot_PL_fingerprint(df, info, ranking.index[:int(n \/ 2)], \"top 50%\", 4)","b238db7d":"plot_PL_fingerprint(df, info, ranking.index[int(n \/ 2):], \"bottom 50%\", 4)","de05219d":"plot_PL_fingerprint(df, info, ranking.index[:int(n \/ 2)], \"top 50%\", 3)","488e69ad":"plot_PL_fingerprint(df, info, ranking.index[int(n \/ 2):], \"bottom 50%\", 3)","3d0dc28d":"# 2. Scoring and ranking\n\nWe can score and rank the area codes based on the irregularity score of the last digit sequences in the constituent groups.\n\nIt's only the Lista 4 results which are under examination here.\n\n(This takes a while, say 3 minutes on the first run.)","7eabd577":"# 1. Initial exploration\n\nThe two major Listas in Poland are Lista 3 and 4.\n\nLista 4 digits were found to be more problematic on overall assessments.\n\nThese can be played with via the (hyper)parameters, below is one way to come to considering raising the eyebrows for the Lista 4 results.","0d1ff1ca":"# Origins (\"very optional reading\")\n\nI have primarily went on to analyse Hungarian data, which definitely looks very suspicious in some cases (esp. in my home town), and anomalies then seem to favour the notoriously winning populist party, although it's pretty unobvious at the first look.\n\nI then tried my luck with other data sets, to see how things go elsewhere. For now, let's just say I expected to find something in Poland as well, and it does seem to look interesting.\nI took the opporunity to utilize the re-applicatoion of the methods to start extracting the core of the techniques into (my first) Python package (expect cats and dogs therefore...), but it's really just the start.\nThere are loads of other methods and actually scientific and quality work out there (e.g. that of Peter Klimek), which could also be put into code, perhaps into the package.\n\nIf you are interested, have a look at [my summary slides of the Hungarian findings](https:\/\/docs.google.com\/presentation\/d\/e\/2PACX-1vTH7yhMRkwkEknyj2EyKBOluytggyHz0l3UlHxLxr58ao8Oy5UcsrvnVu4m_Nt--3VlxFoJ9EkvCyBs\/pub?start=false&loop=false&delayms=3000) (so far).","d185a2d3":"Trivia: Lista 4 is spearheaded by PiS, the governing party. In 2014, PiS was organizing a protest due to the huge number of invalid votes (20%) experienced then.\n\nApparently, in the more suspicious areas they did less well than in the less suspicious half (versus bottom chart), as the bright patch, the majority of votes is in the bottom, \"lower percentage of votes won\"  half of the chart.","5484e27e":"# Conclusion\n\nIt is partly an appetizer, probably Polish data enthusiasts could do a way better job at looking at their own data. I hope some will have a look!\n\nLikely [this very interesting map](https:\/\/www.reddit.com\/r\/europe\/comments\/7fwq02\/polish_election_results_overlaid_on_a_map_of_the\/) can explain a lot of the two-faced nature of the above plots, perhaps not all of it though.\n\nThen if the above gave you no motivation, only doubt about the correctness of the approach - of course fine!\n\nBut if the above makes you already doubt the election results - also great, one practical option is to go and count votes yourself (in Hungary it is possible to apply, though can be tiresome to get there), as well as to incentivize others to do so. Or do something, you know :) Take things in your hands ...\n\nI guess it's just generally good practice to be a bit skeptical.","a92eadf3":"## Lista 4 (PiS)","07c9d152":"Now we adapt the plotting utilities to the Polish data processing, then plot electoral fingerprints - of course, a ranking is unlikely to provide a 100% perfect separation:","1ddca853":"# 3. Can there be a strategy? - Plots...\n\nPlotting the results is the next step.\n\nBelow is a rough explanation of how the - typically singular - patch on the fingerprint charts gets smeared in a handful of scenarios (the smear could be an aggregate of such a[](http:\/\/) change carried out to different degrees).\n\nNote that the diagonal directions coincide with a \"nothing else\" scenario.","7f1765e8":"# Poland 2019 EP elections doctoring quick check \n\nThis is a brief adaptation of the notebook hosted at https:\/\/github.com\/brezniczky\/ep_elections_2019_hun\/\n(rendered version: [Poland 2019 EP Elections](https:\/\/htmlpreview.github.io\/?https:\/\/github.com\/brezniczky\/ep_elections_2019_hun\/blob\/master\/Poland%202019%20EP%20Elections.html)) partly to demonstrate the use of the DrDigit package (see https:\/\/github.com\/brezniczky\/drdigit\/), in expectation of the coincident 13 October 2019 elections in Hungary as well as in Poland.\n\nThe author is much more an enthusiast than an analyst, it's a best effort.\n\n[Contributions](https:\/\/github.com\/brezniczky\/drdigit\/issues\/1) are welcome.\nI probably do not have a good intuition of what fits the bill politically in today's Poland - opinions as well as more data might come useful!\n\nThere might be some relatively simple explanation of why there seems to be a systematic change in the results for the more suspicious areas. I have reasons to believe that socio-economic status of the vote counters is ruled out more than not, but you never know, that could be just the most plausible option.","9d7d3bfb":"There is apparently plenty of low score areas (these scores are derived from probabilities - so we could think of something like a proxy metric to low probability).\n\nLet's take a look at whether there can be any systematic looking relation between irregular digit distributions and vote shares!\n\nNote that these fingerprints are weighted by the votes received, so that we rather observe the distribution of actual votes than just what ratios were typical.\nObviously, similar silhouettes and shapes and hotpoints could still embody very different, but identically looking effects without this.","e19cd5b7":"Now that the package is available, it is time for some processing.\n\n# Preprocessing","37ec9e7a":"Trivia: Lista 3 is spearheaded by PO, the strongest contender party. In 2014, PiS was organizing the protest due to PO's involvement in the alleged electoral fraud.\n\nApparently, in the more suspicious areas they did better than in the less suspicious half (= bottom chart), as the bright patch, the majority of votes shifts towards the top right, \"higher turnout, higher vote share\"  quarter of the top chart.","cb0e87a9":"If there's any oddball behaviour, likely that could be relatively easily extracted from the rows defined by Lista 4's sufficiently big vote counts, compared to the other options that were considered.","c0d7c3a4":"## Lista 3 (PO)","2a1e38c3":"We can also plot these together with the distribution of the simulated samples that the tests are based on, so we see gain some understanding of how hectic the situation is."}}