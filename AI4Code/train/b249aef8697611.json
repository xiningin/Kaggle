{"cell_type":{"bd65d4d6":"code","dfe1e950":"code","a9d06293":"code","b98b5024":"code","9be1f672":"code","ae37bb6d":"code","fff80347":"code","2392f149":"code","961f71d3":"code","ffa1d116":"code","ff6f85f4":"code","96075a84":"code","116093f9":"code","d03f21eb":"code","0cc4d4aa":"code","2e5b783a":"code","f692c43b":"code","fd2bc1f8":"code","a0ab1e43":"code","1d694754":"code","95746ca7":"code","cf416ca8":"code","464df369":"code","4bd2feb6":"code","fcacd068":"markdown","9a0ee99d":"markdown"},"source":{"bd65d4d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n#Importing Models\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,AdaBoostRegressor\n#importing Preprocess \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n#importing Evaluation Metrics\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import accuracy_score\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dfe1e950":"train_data=pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv',parse_dates=['datetime'])\ntest_data=pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv',parse_dates=['datetime'])","a9d06293":"train_data.head()","b98b5024":"train_data.dtypes","9be1f672":"train_data.isnull().sum()","ae37bb6d":"print('unique values for {} column:\\n {}'.format('season',train_data['season'].unique()))\nprint('unique values for {} column:\\n {}'.format('holiday',train_data['holiday'].unique()))\nprint('unique values for {} column:\\n {}'.format('weather',train_data['weather'].unique()))\nprint('unique values for {} column:\\n {}'.format('workingday',train_data['workingday'].unique()))","fff80347":"sns.relplot(x='humidity',y='count',data=train_data,kind='line',ci=None)\nplt.show()","2392f149":"sns.countplot(train_data['holiday'])\nplt.show()","961f71d3":"sns.catplot(x='weather',data=train_data,kind='count')\n# 1-> spring\n# 2-> summer\n# 3-> fall\n# 4-> winter","ffa1d116":"sns.catplot(data=train_data[['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n               'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']],kind='box')\nfig=plt.gcf()\nplt.xticks(rotation=45)\nfig.set_size_inches(10,10)","ff6f85f4":"#corelation matrix.\ncor_mat= train_data[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False # to get the lower triangular shape only\nfig=plt.gcf()\nfig.set_size_inches(30,12)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)","96075a84":"sum(train_data['humidity']==0)","116093f9":"print('Data has {} rows and {} columns'.format(train_data.shape[0],train_data.shape[1]))","d03f21eb":"# getting dummies for weather and season columns\ntrain_data=pd.get_dummies(data=train_data,columns=['weather','season'],prefix=['weather','season'])\ntest_data=pd.get_dummies(data=test_data,columns=['weather','season'],prefix=['weather','season'])","0cc4d4aa":"# modifing datetime column\ntrain_data['hour']=[t.hour for t in train_data['datetime']]\ntrain_data['year']=[t.year for t in train_data['datetime']]\ntrain_data['month']=[t.month for t in train_data['datetime']]\ntrain_data['day']=[t.weekday() for t in train_data['datetime']]\n#---------------------------------------------------------------\ntest_data['hour']=[t.hour for t in test_data['datetime']]\ntest_data['year']=[t.year for t in test_data['datetime']]\ntest_data['month']=[t.month for t in test_data['datetime']]\ntest_data['day']=[t.weekday() for t in test_data['datetime']]","2e5b783a":"train_data['year']=train_data['year'].map({2011:0,2012:1})\n#---------------------------------------------------------\ntest_data['year']=test_data['year'].map({2011:0,2012:1})","f692c43b":"#Dropping datetime column for both train and test data\ntrain_data.drop('datetime',axis=1,inplace=True)\n","fd2bc1f8":"train_data.columns","a0ab1e43":"X=train_data.drop(columns=['casual', 'registered', 'count'],axis=1)\ny=train_data['count']","1d694754":"train_X,val_X,train_y,val_y=train_test_split(X,y,random_state=1)","95746ca7":"# Trying 3 models RandomForrest , Adaboost ,Bagging\nmodels=[RandomForestRegressor(),AdaBoostRegressor(),BaggingRegressor()]\nmodels_names=['RandomForestRegressor','AdaBoostRegressor','BaggingRegressor']\nrmsle=[]\nfor model in models:\n    model.fit(train_X,train_y)\n    y_pred=model.predict(val_X)\n    rmsle.append(np.sqrt(mean_squared_log_error(y_pred,val_y)))\ndic={'Models': models_names,'Rmsle':rmsle}\nmodel_df=pd.DataFrame(dic)\nmodel_df\n\n    \n","cf416ca8":"rf_clf=RandomForestRegressor(n_estimators=450,max_depth=20,n_jobs=-1)\nrf_clf.fit(train_X,train_y)\npreds=rf_clf.predict(val_X)\nprint(np.sqrt(mean_squared_log_error(preds,val_y)))","464df369":"# as we see no noticable tunning,we will see the predictions of the model to the test data,fitting to whole data\nmy_model=RandomForestRegressor(n_estimators=450,max_depth=20,n_jobs=-1)\nmy_model.fit(X,y)\n\nfinal_preds=my_model.predict(test_data.drop('datetime',axis=1))\n","4bd2feb6":"output=pd.DataFrame({'datetime':test_data.datetime,'count':final_preds})\noutput.to_csv('submission.csv',index=False)","fcacd068":"# Splitting Data to X and y","9a0ee99d":"# Preprocess for Train and Test data"}}