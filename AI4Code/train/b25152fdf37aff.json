{"cell_type":{"ce42b057":"code","d39a6523":"code","c9b249b1":"code","4b2b15cf":"code","ba4c3f58":"code","8ffbd0f1":"code","ccdd23cf":"code","1f1e4e6c":"code","b4ce74ea":"code","f9b8236e":"code","c9d63196":"code","841e92db":"code","e3f5c882":"code","907336ec":"code","b31895d1":"code","cc7f7a9d":"code","6668a945":"code","5f0fd66b":"code","7b1612d6":"code","7488e550":"code","422093cf":"code","35b13adb":"code","6145466a":"code","6f9d7f42":"code","ad6d998c":"code","6a227c57":"code","5b9e42e7":"markdown","f14199c0":"markdown","f9e3b1d4":"markdown","865858ef":"markdown","53a8fa03":"markdown","5d49fe7e":"markdown","aa0ad836":"markdown","828637bc":"markdown","922e5cfc":"markdown","b768ebff":"markdown"},"source":{"ce42b057":"import sys\nsys.path = [\n    '..\/input\/geffnet-20200820'  \n] + sys.path\n\nimport numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport albumentations\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport geffnet\nfrom transformers import *","d39a6523":"import re\nimport string\n\ndef cleanReview(title):\n    # \u5229\u7528\u6b63\u5219\u5339\u914d\\x\u5f00\u5934\u7684\u7279\u6b8a\u5b57\u7b26\n    result = re.findall(r'\\\\x[a-f0-9]{2}', title)\n    for x in result:\n        title = title.replace(x, '')\n    title = title.lower()\n    # \u66ff\u6362\u6240\u6709\u6807\u70b9\u7b26\u53f7\n    for c in string.punctuation:\n        title = title.replace(c, \" \")\n    # \u5229\u7528\u6b63\u5219\u5339\u914dml\u6216\u8005cm\u6216\u8005mm\u7b49\u7ed3\u675f\u7684\u7279\u6b8a\u5b57\u7b26\n    unitlist = ['mm', 'cm', 'm', 'ml', 'l', 'gr', 'kg', '%', 'w']\n    maplist = {'mm':'millimeter', 'cm':'centimeter', 'm':'meter', 'ml':'millilitre', 'l':'litre', 'gr':'gram', 'kg':'kilogram', '%':'percentage', 'w':'watt'}\n    for u in unitlist:\n        result = re.findall(r'[0-9\\s]'+u+'[\\s]', title) + re.findall(r'[0-9\\s]'+u+'\\Z', title)\n        for x in result:\n            title = title.replace(x, x.strip()[:-len(u)]+' '+ maplist[u] +' ')\n    title = ' '.join(title.split())\n    return title","c9b249b1":"test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\ntest['title'] = test['title'].apply(cleanReview)\ntest.to_csv('test.csv',index=False)\n\ntrain = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntrain['title'] = train['title'].apply(cleanReview)\ntrain.to_csv('train.csv',index=False)\n\ntrain_fold = pd.read_csv('..\/input\/shopee-folds\/train_fold.csv')\ntrain_fold['title'] = train_fold['title'].apply(cleanReview)\ntrain_fold.to_csv('train_fold.csv',index=False)","4b2b15cf":"COMPUTE_CV = True\n\ntest = pd.read_csv('test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","ba4c3f58":"train = pd.read_csv('train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","8ffbd0f1":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","ccdd23cf":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","1f1e4e6c":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","b4ce74ea":"if COMPUTE_CV:\n    test = pd.read_csv('train_fold.csv')\n#     test = test[test.fold==0]\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('test.csv')\n    test_gf = cudf.read_csv('test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","f9b8236e":"import os\n\ndef get_transforms(img_size=256):\n    return  albumentations.Compose([\n                albumentations.Resize(300, 300),\n                albumentations.CenterCrop(img_size,img_size, p=1.0),\n#                 albumentations.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n                albumentations.Normalize()\n            ])\n\n\nclass LandmarkDataset(Dataset):\n    def __init__(self, csv, split, mode, transforms=get_transforms(img_size=256), tokenizer=None):\n\n        self.csv = csv.reset_index()\n        self.split = split\n        self.mode = mode\n        self.transform = transforms\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        text = row.title\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n        \n        res0 = self.transform(image=image)\n        image0 = res0['image'].astype(np.float32)\n        image = image0.transpose(2, 0, 1)        \n\n        text = self.tokenizer(text, padding='max_length', truncation=True, max_length=16, return_tensors=\"pt\")\n        input_ids = text['input_ids'][0]\n        attention_mask = text['attention_mask'][0]\n\n        if self.mode == 'test':\n            return torch.tensor(image), input_ids, attention_mask\n        else:\n            return torch.tensor(image), input_ids, attention_mask, torch.tensor(row.label_group)","c9d63196":"tokenizer = AutoTokenizer.from_pretrained('..\/input\/bert-base-uncased')","841e92db":"if not COMPUTE_CV: \n    df_sub = pd.read_csv('test.csv')\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('..\/input\/shopee-product-matching\/', 'test_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])\nelse:\n    df_sub = test\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('..\/input\/shopee-product-matching\/', 'train_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])","e3f5c882":"class ArcMarginProduct_subcenter(nn.Module):\n    def __init__(self, in_features, out_features, k=3):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n        self.reset_parameters()\n        self.k = k\n        self.out_features = out_features\n        \n    def reset_parameters(self):\n        stdv = 1. \/ math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        \n    def forward(self, features):\n        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n        cosine, _ = torch.max(cosine_all, dim=2)\n        return cosine \n    \nsigmoid = torch.nn.Sigmoid()\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\nclass Swish_module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n\n    \n \n    \nclass enet_arcface_FINAL(nn.Module):\n\n    def __init__(self, enet_type, out_dim):\n        super(enet_arcface_FINAL, self).__init__()\n        self.bert = AutoModel.from_pretrained('..\/input\/bert-base-uncased')\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=None)\n        self.feat = nn.Linear(self.enet.classifier.in_features+self.bert.config.hidden_size, 512)\n        self.swish = Swish_module()\n        self.dropout = nn.Dropout(0.5)\n        self.metric_classify = ArcMarginProduct_subcenter(512, out_dim)\n        self.enet.classifier = nn.Identity()\n \n    def forward(self, x,input_ids, attention_mask):\n        x = self.enet(x)\n        text = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]\n        x = torch.cat([x, text], 1)\n        x = self.swish(self.feat(x))\n        return F.normalize(x), self.metric_classify(x)\n    \ndef load_model(model, model_file):\n    state_dict = torch.load(model_file)\n    if \"model_state_dict\" in state_dict.keys():\n        state_dict = state_dict[\"model_state_dict\"]\n    state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n#     del state_dict['metric_classify.weight']\n    model.load_state_dict(state_dict, strict=True)\n    print(f\"loaded {model_file}\")\n    model.eval()    \n    return model","907336ec":"import math\nfrom tqdm import tqdm\n\nWGT = '..\/input\/shopee-b0-bert\/b0ns_256_bert_20ep_fold0_epoch27.pth'\n\nmodel = enet_arcface_FINAL('tf_efficientnet_b0_ns', out_dim=11014).cuda()\nmodel = load_model(model, WGT)\n\n\nembeds = []\n\nwith torch.no_grad():\n    for img, input_ids, attention_mask in tqdm(test_loader): \n        img, input_ids, attention_mask = img.cuda(), input_ids.cuda(), attention_mask.cuda()\n        feat, _ = model(img, input_ids, attention_mask)\n        image_embeddings = feat.detach().cpu().numpy()\n        embeds.append(image_embeddings)\n\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","b31895d1":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","cc7f7a9d":"image_embeddings = cupy.array(image_embeddings)\npreds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)\/\/CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n   \n    cts = cupy.matmul(image_embeddings, image_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n#         print(sorted(cts[k,], reverse=True))\n        IDX = cupy.where(cts[k,]>0.5)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","6668a945":"test['preds2'] = preds\ntest.head()","5f0fd66b":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words=None, \n                        binary=True, \n                        max_features=25000)\ntext_embeddings = model.fit_transform(test_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","7b1612d6":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    #COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.75)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","7488e550":"test['preds'] = preds\ntest.head()","422093cf":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","35b13adb":"def combine_for_sub(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return np.unique(x)","6145466a":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', test.f1.mean() )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","6f9d7f42":"print(\"CV for image :\", round(test.apply(getMetric('preds2'),axis=1).mean(), 3))\nprint(\"CV for text  :\", round(test.apply(getMetric('preds'),axis=1).mean(), 3))\nprint(\"CV for phash :\", round(test.apply(getMetric('preds3'),axis=1).mean(), 3))","ad6d998c":"test","6a227c57":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","5b9e42e7":"# Use Phash Feature\nWe will predict all items with the same phash as duplicates","f14199c0":"# Use Text Embeddings\nTo prevent memory errors, we will find similar titles in chunks. To faciliate this, we will use cosine similarity between text embeddings instead of KNN.","f9e3b1d4":"# Compute Baseline CV Score\nA baseline is to predict all items with the same `image_phash` as being duplicate. Let's calcuate the CV score for this submission.","865858ef":"# Load Train Data\nFirst we load the train data and create a target column of ground truths to help us compute CV score. Note how the variable `COMPUTE_CV` will change to `False` when we **submit** this notebook but it is `True` now because you are reading a **commit** notebook.","53a8fa03":"# Load Libraries","5d49fe7e":"# Write Submission CSV\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of `test.csv` dataframe will be longer than 3 rows and the variable `COMPUTE_CV` will subsequently set to `False`. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok.","aa0ad836":"# Compute RAPIDS Model CV and Infer Submission\nWe will now use image embeddings, text embeddings, and phash to create a better model with better CV. We will also infer submission csv.\n\nNote how the variable `COMPUTE_CV` is only `True` when we **commit** this notebook. Right now you are reading a **commit** notebook, so we see test replaced with train and computed CV score. When we **submit** this notebook, the variable `COMPUTE_CV` will be `False` and the **submit** notebook will **not** compute CV. Instead it will load the real test dataset with 70,000 rows and find duplicates in the real test dataset.","828637bc":"# Compute CV Score\nThis simple model scores a high CV of 0.700+!","922e5cfc":"thanks to https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700","b768ebff":"# Use Image Embeddings\nTo prevent memory errors, we will compute image embeddings in chunks. And we will find similar images with RAPIDS cuML KNN in chunks."}}