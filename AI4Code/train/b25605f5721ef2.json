{"cell_type":{"7a88a892":"code","259ef826":"code","b3cf3cf5":"code","e9777710":"code","dd1a69a2":"code","943c0694":"code","0286b49a":"code","9748b74e":"code","5da9da28":"code","e777f100":"code","f2c2775f":"code","c0045e0b":"code","a7dc095e":"code","0d250031":"code","94ea79ec":"markdown","7ea61bd2":"markdown"},"source":{"7a88a892":"#importing required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","259ef826":"#reading csv file into data frame\ndf = pd.read_csv('..\/input\/KNN_Project_Data')\ndf.head()","b3cf3cf5":"#performing exploratory data analysis\nsns.set_style('darkgrid')\nsns.pairplot(df, hue='TARGET CLASS', palette='colorblind').fig.set_size_inches(15,15)","e9777710":"#standardizing numerical variables\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df.drop('TARGET CLASS', axis=1))\nscaled_features = scaler.transform(df.drop('TARGET CLASS', axis=1))\ndf_scaled = pd.DataFrame(scaled_features, columns=df.columns[:-1])\ndf_scaled.head()","dd1a69a2":"#splitting dataframe into train and test\nX = df.drop('TARGET CLASS', axis=1)\ny = df['TARGET CLASS']","943c0694":"X.head()","0286b49a":"y.head()","9748b74e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=101)","5da9da28":"#Using KNN for this prediction\nfrom sklearn.neighbors import KNeighborsClassifier\n#trying with k=1\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\n","e777f100":"#evaluating model performance\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test, prediction))\nconfusion_matrix(y_test, prediction)","f2c2775f":"#Using elbow method to find optimal k\nerror_rate=[]\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    prediction_i = knn.predict(X_test)\n    error_rate.append(np.mean(prediction_i != y_test))\nsns.set_style('darkgrid')\nplt.figure(figsize=(15,8))\nplt.plot(range(1,40), error_rate, marker='o', markerfacecolor='red', linestyle='dashed', color='green', markersize=10)\nplt.title('Error Rate VS K')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","c0045e0b":"#Good values for k appear to be 24, 32, 36\n#trying k = 24\nknn = KNeighborsClassifier(n_neighbors=24)\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\nprint(classification_report(y_test, prediction))\nconfusion_matrix(y_test, prediction)\n#The score improves significantly from 74 to 82%.","a7dc095e":"#trying k = 32\nknn = KNeighborsClassifier(n_neighbors=24)\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\nprint(classification_report(y_test, prediction))\nconfusion_matrix(y_test, prediction)","0d250031":"#trying k = 36\nknn = KNeighborsClassifier(n_neighbors=36)\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\nprint(classification_report(y_test, prediction))\nconfusion_matrix(y_test, prediction)","94ea79ec":"Given a classified data set, the aim is to predict the TARGET CLASS.","7ea61bd2":"Therefore, the optimal k is 24 with 83% precision."}}