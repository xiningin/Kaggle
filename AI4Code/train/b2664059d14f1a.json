{"cell_type":{"55cbcb57":"code","e195655d":"code","373cb9f9":"code","4377a228":"code","e0dcf727":"code","9f383c69":"code","0e1d0a03":"code","f5d8a486":"code","6857efb1":"code","6b096b70":"code","c04c516e":"code","d1c7962c":"code","79eb9aec":"code","a43d43f8":"code","505e3d7d":"code","8bbec897":"code","42b7e9f8":"code","59ffe911":"code","5c87f5db":"code","c5ad073c":"code","a57fbf2b":"code","cd6f4db0":"code","dc71e7d3":"code","6b2b057e":"code","e4fdcfcd":"code","f9263b53":"code","b48e6736":"code","c21e7456":"code","4b6f1df3":"code","6a8964e3":"code","8b55db81":"code","cbc323a2":"code","0d5d553d":"code","f460b569":"code","ded48081":"code","2035ca2e":"code","40032e27":"code","992b0072":"code","8ab6ebfd":"code","d9a510c5":"code","12f8ca41":"code","82f76afd":"code","adedbe7b":"code","6529cb53":"code","e4fc6c20":"code","090fc268":"code","126b39a2":"code","5e74410f":"code","cbfb47e0":"code","3d883bfe":"code","17a08f90":"code","4d7f3407":"code","50d2c313":"code","a897dc7c":"code","ed5fd149":"code","3dd4a155":"code","6e12907d":"code","a9b516eb":"code","3c2f783f":"code","99b4fdb0":"code","0351d79a":"code","b7fa2adb":"code","b5cae210":"code","be041f88":"code","87aba6ce":"code","e8353134":"markdown","a52462ba":"markdown","29c913f2":"markdown","08e0fe25":"markdown","19c5bf8e":"markdown","0f43cc7d":"markdown","f8ac3cd4":"markdown","b4ae4752":"markdown","3442bd53":"markdown","b98fdfb7":"markdown","94a465f1":"markdown","85e9ef7f":"markdown","1b2ea1ca":"markdown","36dc0e83":"markdown","6c22f12e":"markdown","0f671fff":"markdown","b7fb555a":"markdown","d96446b4":"markdown","ca0abe63":"markdown","49315215":"markdown","d6fab467":"markdown","4ea9e2fc":"markdown","a1ae34e0":"markdown","e157d63f":"markdown","9af2a79e":"markdown","c5ad725a":"markdown","e667f7a6":"markdown","f0ce540f":"markdown","62ba50b6":"markdown","b5658f89":"markdown","753d2084":"markdown","2882638a":"markdown","1b5ae351":"markdown","73ff74dd":"markdown"},"source":{"55cbcb57":"# load some default Python modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\nplt.style.use('seaborn-whitegrid')","e195655d":"# read data in pandas dataframe\ndf_train =  pd.read_csv('..\/input\/train.csv', parse_dates=[\"pickup_datetime\"],nrows=2000000)\ndf_test =  pd.read_csv('..\/input\/test.csv')\n\n# list first few rows (datapoints)\ndf_train.head()","373cb9f9":"# check datatypes\ndf_train.dtypes","4377a228":"# check statistics of the features\ndf_train.describe()\ndf_test['key'] = pd.to_datetime(df_test['key'])\ndf_test['pickup_datetime']  = pd.to_datetime(df_test['pickup_datetime'])\ndf_train['key'] = pd.to_datetime(df_train['key'])\ndf_train['pickup_datetime']  = pd.to_datetime(df_train['pickup_datetime'])\ndata = [df_train,df_test]\nfor i in data:\n    i['Month'] = i['pickup_datetime'].dt.month\n    i['Date'] = i['pickup_datetime'].dt.day\n    i['Day of Week'] = i['pickup_datetime'].dt.dayofweek\n    i['Hour'] = i['pickup_datetime'].dt.hour\n\n","e0dcf727":"print('Old size: %d' % len(df_train))\ndf_train = df_train[df_train.fare_amount>=0]\nprint('New size: %d' % len(df_train))","9f383c69":"# plot histogram of fare\ndf_train[df_train.fare_amount<100].fare_amount.hist(bins=100, figsize=(14,3))\nplt.xlabel('fare $USD')\nplt.title('Histogram');","0e1d0a03":"print(df_train.isnull().sum())","f5d8a486":"print('Old size: %d' % len(df_train))\ndf_train = df_train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(df_train))","6857efb1":"# define bounding box\nBB = (-75, -73, 40, 41.5)\n\n# this function will be used with the test set below\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[select_within_boundingbox(df_train, BB)]\nprint('New size: %d' % len(df_train))","6b096b70":"# load image of NYC map\nnyc_map = plt.imread('https:\/\/aiblog.nl\/download\/nyc_-75_40_-73_41.5.png')\n\n# this function will be used more often to plot data on the NYC map\ndef plot_on_map(df, BB, nyc_map, figsize=(20, 16)):\n    fig, axs = plt.subplots(1,2, figsize=figsize)\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=0.4, c='r', s=2)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=[-75, -73, 40, 41.5]);\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=0.4, c='r', s=2)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=[-75, -73, 40, 41.5]);\n    \nplot_on_map(df_train, BB, nyc_map)","c04c516e":"# For this plot and further analysis, we need a function to calculate the distance in miles between locations in lon,lat coordinates.\n# This function is based on https:\/\/stackoverflow.com\/questions\/27928\/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi\/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)\/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) \/ 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n\n# First calculate two arrays with datapoint density per sq mile\nn_lon, n_lat = 200, 200 # number of grid bins per longitude, latitude dimension\ndensity_pickup, density_dropoff = np.zeros((n_lat, n_lon)), np.zeros((n_lat, n_lon)) # prepare arrays\n\n# To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n# This function needs an array with the (location) bins for counting the number of datapoints\n# per bin.\nbins_lon = np.zeros(n_lon+1) # bin\nbins_lat = np.zeros(n_lat+1) # bin\ndelta_lon = (BB[1]-BB[0]) \/ n_lon # bin longutide width\ndelta_lat = (BB[3]-BB[2]) \/ n_lat # bin latitude height\nbin_width_miles = distance(BB[2], BB[1], BB[2], BB[0]) \/ n_lon # bin width in miles\nbin_height_miles = distance(BB[3], BB[0], BB[2], BB[0]) \/ n_lat # bin height in miles\nfor i in range(n_lon+1):\n    bins_lon[i] = BB[0] + i * delta_lon\nfor j in range(n_lat+1):\n    bins_lat[j] = BB[2] + j * delta_lat\n    \n# Digitize per longitude, latitude dimension\ninds_pickup_lon = np.digitize(df_train.pickup_longitude, bins_lon)\ninds_pickup_lat = np.digitize(df_train.pickup_latitude, bins_lat)\ninds_dropoff_lon = np.digitize(df_train.dropoff_longitude, bins_lon)\ninds_dropoff_lat = np.digitize(df_train.dropoff_latitude, bins_lat)\n\n# Count per grid bin\n# note: as the density_pickup will be displayed as image, the first index is the y-direction, \n#       the second index is the x-direction. Also, the y-direction needs to be reversed for\n#       properly displaying (therefore the (n_lat-j) term)\nfor i in range(n_lon):\n    for j in range(n_lat):\n        density_pickup[j, i] = np.sum((inds_pickup_lon==i+1) & (inds_pickup_lat==(n_lat-j))) \/ bin_width_miles\n        density_dropoff[j, i] = np.sum((inds_dropoff_lon==i+1) & (inds_dropoff_lat==(n_lat-j))) \/ bin_height_miles","d1c7962c":"# Plot the density arrays\nfig, axs = plt.subplots(2, 1, figsize=(18, 24))\naxs[0].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[0].imshow(np.log1p(density_pickup), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[0].set_title('Pickup density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)\n\naxs[1].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[1].imshow(np.log1p(density_dropoff), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[1].set_title('Dropoff density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)","79eb9aec":"# add new column to dataframe with distance in miles\ndf_train['distance_miles'] = distance(df_train.pickup_latitude, df_train.pickup_longitude, \\\n                                      df_train.dropoff_latitude, df_train.dropoff_longitude)\n\ndf_train.distance_miles.hist(bins=50, figsize=(12,4))\nplt.xlabel('distance miles')\nplt.title('Histogram ride distances in miles')","a43d43f8":"df_train.groupby('passenger_count')['distance_miles', 'fare_amount'].mean()","505e3d7d":"print(\"Average $USD\/Mile : {:0.2f}\".format(df_train.fare_amount.sum()\/df_train.distance_miles.sum()))","8bbec897":"# scatter plot distance - fare\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\naxs[0].scatter(df_train.distance_miles, df_train.fare_amount, alpha=0.2)\naxs[0].set_xlabel('distance mile')\naxs[0].set_ylabel('fare $USD')\naxs[0].set_title('All data')\n\n# zoom in on part of data\nidx = (df_train.distance_miles < 15) & (df_train.fare_amount < 100)\naxs[1].scatter(df_train[idx].distance_miles, df_train[idx].fare_amount, alpha=0.2)\naxs[1].set_xlabel('distance mile')\naxs[1].set_ylabel('fare $USD')\naxs[1].set_title('Zoom in on distance < 15 mile, fare < $100');\n","42b7e9f8":"# remove datapoints with distance <0.05 miles\nidx = (df_train.distance_miles >= 0.05)\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[idx]\nprint('New size: %d' % len(df_train))","59ffe911":"# JFK airport coordinates, see https:\/\/www.travelmath.com\/airport\/JFK\njfk = (-73.7822222222, 40.6441666667)\nnyc = (-74.0063889, 40.7141667)\n\ndef plot_location_fare(loc, name, range=1.5):\n    # select all datapoints with dropoff location within range of airport\n    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n    idx = (distance(df_train.pickup_latitude, df_train.pickup_longitude, loc[1], loc[0]) < range)\n    df_train[idx].fare_amount.hist(bins=100, ax=axs[0])\n    axs[0].set_xlabel('fare $USD')\n    axs[0].set_title('Histogram pickup location within {} miles of {}'.format(range, name))\n\n    idx = (distance(df_train.dropoff_latitude, df_train.dropoff_longitude, loc[1], loc[0]) < range)\n    df_train[idx].fare_amount.hist(bins=100, ax=axs[1])\n    axs[1].set_xlabel('fare $USD')\n    axs[1].set_title('Histogram dropoff location within {} miles of {}'.format(range, name));\n    \nplot_location_fare(jfk, 'JFK Airport')","5c87f5db":"ewr = (-74.175, 40.69) # Newark Liberty International Airport, see https:\/\/www.travelmath.com\/airport\/EWR\nlgr = (-73.87, 40.77) # LaGuardia Airport, see https:\/\/www.travelmath.com\/airport\/LGA\nplot_location_fare(ewr, 'Newark Airport')\nplot_location_fare(lgr, 'LaGuardia Airport')","c5ad073c":"df_train['hour'] = df_train.pickup_datetime.apply(lambda t: t.hour)\ndf_train['year'] = df_train.pickup_datetime.apply(lambda t: t.year)","a57fbf2b":"df_train['fare_per_mile'] = df_train.fare_amount \/ df_train.distance_miles\ndf_train.fare_per_mile.describe()","cd6f4db0":"idx = (df_train.distance_miles < 3) & (df_train.fare_amount < 100)\nplt.scatter(df_train[idx].distance_miles, df_train[idx].fare_per_mile)\nplt.xlabel('distance mile')\nplt.ylabel('fare per distance mile')\n\n# theta here is estimated by hand\ntheta = (16, 4.0)\nx = np.linspace(0.1, 3, 50)\nplt.plot(x, theta[0]\/x + theta[1], '--', c='r', lw=2);","dc71e7d3":"# display pivot table\ndf_train.pivot_table('fare_per_mile', index='hour', columns='year').plot(figsize=(14,6))\nplt.ylabel('Fare $USD \/ mile');","6b2b057e":"hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \\\n         13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\n# minimum & maximum duration in minutes\ntrip1_min = [10, 10, 10, 10, 10, 10, 10, 12, 14, 14, 14, 14, \\\n             14, 14, 14, 14, 14, 12, 12, 12, 12, 12, 10, 10]\ntrip1_max = [20, 18, 16, 16, 16, 18, 22, 26, 40, 35, 35, 35, \\\n             35, 35, 35, 40, 35, 30, 28, 28, 26, 26, 24, 24]\n\ntrip2_min = [18, 18, 18, 18, 18, 18, 20, 24, 28, 30, 30, 30, \\\n             28, 28, 26, 28, 30, 28, 26, 22, 22, 22, 20, 20]\ntrip2_max = [35, 35, 30, 28, 28, 30, 40, 55, 75, 75, 70, 70, \\\n             60, 60, 60, 60, 60, 65, 55, 45, 45, 50, 45, 40]\n\nplt.figure(figsize=(12, 5))\nplt.plot(hours, trip1_min, '--', c='b', label=\"trip1 (2.7 mile) - minimum duration\")\nplt.plot(hours, trip1_max, '-', c='b', label=\"trip1 (2.7 mile) - maximum duration\")\nplt.plot(hours, trip2_min, '--', c='r', label=\"trip2 (7.2 mile) - minimum duration\")\nplt.plot(hours, trip2_max, '-', c='r', label=\"trip2 (7.2 mile) - maximum duration\")\nplt.xlabel('hour of the day')\nplt.ylabel('driving time (min)')\nplt.title('Estimated driving time for two trips using Google Map traffic info')\nplt.legend();","e4fdcfcd":"from sklearn.linear_model import LinearRegression\n\n# plot all years\nfor year in df_train.year.unique():\n    # create figure\n    fig, axs = plt.subplots(4, 6, figsize=(18, 10))\n    axs = axs.ravel()\n    \n    # plot for all hours\n    for h in range(24):\n        idx = (df_train.distance_miles < 15) & (df_train.fare_amount < 100) & (df_train.hour == h) & \\\n              (df_train.year == year)\n        axs[h].scatter(df_train[idx].distance_miles, df_train[idx].fare_amount, alpha=0.2, s=1)\n        axs[h].set_xlabel('distance miles')\n        axs[h].set_ylabel('fare $USD')\n        axs[h].set_xlim((0, 15))\n        axs[h].set_ylim((0, 70))\n\n        model = LinearRegression(fit_intercept=False)\n        x, y = df_train[idx].distance_miles.values.reshape(-1,1), df_train[idx].fare_amount.values.reshape(-1,1)\n        X = np.concatenate((np.ones(x.shape), x), axis=1)\n        model.fit(X, y)\n        xx = np.linspace(0.1, 25, 100)\n        axs[h].plot(xx, model.coef_[0][0] + xx * model.coef_[0][1], '--', c='r', lw=2)\n        axs[h].set_title('hour = {}, theta=({:0.2f},{:0.2f})'.format(h, model.coef_[0][0], model.coef_[0][1]))\n\n    plt.suptitle(\"Year = {}\".format(year))\n    plt.tight_layout(rect=[0, 0, 1, 0.95]);","f9263b53":"# add new column to dataframe with distance in mile\ndf_train['distance_to_center'] = distance(nyc[1], nyc[0], df_train.pickup_latitude, df_train.pickup_longitude)","b48e6736":"fig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train.distance_to_center, df_train.distance_miles, c=np.clip(df_train.fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx = (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                     c=np.clip(df_train[idx].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);","c21e7456":"df_train['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0], df_train.dropoff_latitude, df_train.dropoff_longitude)\ndf_test['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0], df_test.pickup_latitude, df_test.pickup_longitude)\ndf_test['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0], df_test.dropoff_latitude, df_test.dropoff_longitude)","4b6f1df3":"# remove all to\/from JFK trips\nidx = ~((df_train.pickup_distance_to_jfk < 1) | (df_train.dropoff_distance_to_jfk < 1))\n\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                    c=np.clip(df_train[idx].fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx1 = idx & (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx1].distance_to_center, df_train[idx1].distance_miles, \n                     c=np.clip(df_train[idx1].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);","6a8964e3":"idx = (df_train.fare_amount>80) & (df_train.distance_miles<35) \nplot_on_map(df_train[idx], BB, nyc_map)","8b55db81":"df_train['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0], df_train.dropoff_latitude, df_train.dropoff_longitude)\ndf_train['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0], df_train.dropoff_latitude, df_train.dropoff_longitude)\ndf_test['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], df_test.pickup_latitude, df_test.pickup_longitude)\ndf_test['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0], df_test.dropoff_latitude, df_test.dropoff_longitude)\ndf_test['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0], df_test.pickup_latitude, df_test.pickup_longitude)\ndf_test['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0], df_test.dropoff_latitude, df_test.dropoff_longitude)","cbc323a2":"# remove all to\/from airport trips\nidx = ~((df_train.pickup_distance_to_jfk < 1) | (df_train.dropoff_distance_to_jfk < 1) |\n        (df_train.pickup_distance_to_ewr < 1) | (df_train.dropoff_distance_to_ewr < 1) |\n        (df_train.pickup_distance_to_lgr < 1) | (df_train.dropoff_distance_to_lgr < 1))\n\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                    c=np.clip(df_train[idx].fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx1 = idx & (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx1].distance_to_center, df_train[idx1].distance_miles, \n                     c=np.clip(df_train[idx1].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);","0d5d553d":"plot_on_map(df_test, BB, nyc_map)","f460b569":"df_test.passenger_count.hist();","ded48081":"# add new column to dataframe with distance in km\ndf_test['distance_miles'] = distance(df_test.pickup_latitude, df_test.pickup_longitude, \\\n                                     df_test.dropoff_latitude, df_test.dropoff_longitude)\ndf_test['distance_to_center'] = distance(nyc[1], nyc[0], \\\n                                          df_test.dropoff_latitude, df_test.dropoff_longitude)\ndf_test['hour'] = df_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).hour)\ndf_test['year'] = df_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).year)\n#df_train['distance_to_center'] = distance(nyc[1], nyc[0], \\\n #                                         df_train.dropoff_latitude, df_train.dropoff_longitude)\n","2035ca2e":"df_test[~select_within_boundingbox(df_test, BB)]","40032e27":"idx = (df_train.distance_to_center<15) & (df_train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count','Month','Date','Day of Week']\nX_ = df_train[idx][features].values\ny_= df_train[idx]['fare_amount'].values\ndf_test=df_test[features].values","992b0072":"# define dataset\n# select points 15 miles near NYC center and remove zero passenger datapoint\n\n","8ab6ebfd":"X.shape, y.shape","d9a510c5":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom bayes_opt import BayesianOptimization\nX_train, X_test, y_train, y_test = train_test_split(X_,\n                                                    y_, test_size=0.25)\ndel(X_)\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndel(X_train)\ndtest = xgb.DMatrix(X_test)\ndel(X_test)","12f8ca41":"def xgb_evaluate(max_depth, gamma, colsample_bytree):\n    params = {'eval_metric': 'rmse',\n              'max_depth': int(max_depth),\n              'subsample': 0.8,\n              'eta': 0.1,\n              'gamma': gamma,\n              'colsample_bytree': colsample_bytree}\n    # Used around 1000 boosting rounds in the full model\n    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n    \n    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]","82f76afd":"xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 7), \n                                             'gamma': (0, 1),\n                                             'colsample_bytree': (0.3, 0.9)})\n# Use the expected improvement acquisition function to handle negative numbers\n# Optimally needs quite a few more initiation points and number of iterations\nxgb_bo.maximize(init_points=3, n_iter=5, acq='ei')","adedbe7b":"params = xgb_bo.res['max']['max_params']\nparams['max_depth'] = int(params['max_depth'])","6529cb53":"# Train a new model with the best parameters from the search\nmodel2 = xgb.train(params, dtrain, num_boost_round=250)\n\n# Predict on testing and training set\ny_pred = model2.predict(dtest)\ny_train_pred = model2.predict(dtrain)\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# Report testing and training RMSE\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))\nprint(np.sqrt(mean_squared_error(y_train, y_train_pred)))","e4fc6c20":"import matplotlib.pyplot as plt\nfscores = pd.DataFrame({'X': list(model2.get_fscore().keys()), 'Y': list(model2.get_fscore().values())})\nfscores.sort_values(by='Y').plot.bar(x='X')","090fc268":"test = df_test\n#test['pickup_datetime'] = test['pickup_datetime'].str.slice(0, 16)\n#test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n \n# Predict on holdout set\n\ndtest = xgb.DMatrix(test)\ny_pred_test = model2.predict(dtest)\ndf_test","126b39a2":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['fare_amount'] = y_pred_test\nsubmission.to_csv('submission_1.csv', index=False)\nsubmission.head(20)","5e74410f":"idx = (df_train.distance_to_center<15) & (df_train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count','Month','Date','Day of Week']\nX_ = df_train[idx][features].values\ny_= df_train[idx]['fare_amount'].values","cbfb47e0":"import lightgbm as lgbm","3d883bfe":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'nthread': -1,\n        'verbose': 0,\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'subsample_freq': 1,\n        'colsample_bytree': 0.6,\n        'reg_aplha': 1,\n        'reg_lambda': 0.001,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1     \n    }","17a08f90":"pred_test_y = np.zeros(df_test.shape[0])\npred_test_y.shape","4d7f3407":"train_set = lgbm.Dataset(X_, y_, silent=True)\ntrain_set","50d2c313":"model = lgbm.train(params, train_set = train_set, num_boost_round=300)","a897dc7c":"print(model)","ed5fd149":"pred_test_y = model.predict(df_test, num_iteration = model.best_iteration)","3dd4a155":"print(pred_test_y)","6e12907d":"submission['fare_amount'] = y_pred_test\nsubmission.to_csv('submission_LGB1.csv', index=False)\nsubmission.head(20)","a9b516eb":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom bayes_opt import BayesianOptimization","3c2f783f":"idx = (df_train.distance_to_center<15) & (df_train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count','Month','Date','Day of Week']\nX_ = df_train[idx][features].values\ny_= df_train[idx]['fare_amount'].values\n","99b4fdb0":"x_train,x_test,y_train,y_test = train_test_split(X_,y_,random_state=0,test_size=0.01)","0351d79a":"#Cross-validation\nparams = {\n    # Parameters that we are going to tune.\n    'max_depth': 8, #Result of tuning with CV\n    'eta':.03, #Result of tuning with CV\n    'subsample': 1, #Result of tuning with CV\n    'colsample_bytree': 0.8, #Result of tuning with CV\n    # Other parameters\n    'objective':'reg:linear',\n    'eval_metric':'rmse',\n    'silent': 1\n}\n\n#Block of code used for hypertuning parameters. Adapt to each round of parameter tuning.\n#Turn off CV in submission\nCV=False\nif CV:\n    dtrain = xgb.DMatrix(X_,label=y_)\n    gridsearch_params = [\n        (eta)\n        for eta in np.arange(.04, 0.12, .02)\n    ]\n\n    # Define initial best params and RMSE\n    min_rmse = float(\"Inf\")\n    best_params = None\n    for (eta) in gridsearch_params:\n        print(\"CV with eta={} \".format(\n                                 eta))\n\n        # Update our parameters\n        params['eta'] = eta\n\n        # Run CV\n        cv_results = xgb.cv(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            nfold=3,\n            metrics={'rmse'},\n            early_stopping_rounds=10\n        )\n\n        # Update best RMSE\n        mean_rmse = cv_results['test-rmse-mean'].min()\n        boost_rounds = cv_results['test-rmse-mean'].argmin()\n        print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n        if mean_rmse < min_rmse:\n            min_rmse = mean_rmse\n            best_params = (eta)\n\n    print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))\nelse:\n    #Print final params to use for the model\n    params['silent'] = 0 #Turn on output\n    print(params)","b7fa2adb":"\ndef XGBmodel(x_train,x_test,y_train,y_test,params):\n    matrix_train = xgb.DMatrix(x_train,label=y_train)\n    matrix_test = xgb.DMatrix(x_test,label=y_test)\n    model=xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=10,evals=[(matrix_test,'test')])\n    return model\n\nmodel = XGBmodel(x_train,x_test,y_train,y_test,params)","b5cae210":"prediction = model.predict(xgb.DMatrix(df_test), ntree_limit = model.best_ntree_limit)","be041f88":"submission['fare_amount'] = prediction.round(2)\nsubmission.to_csv('submission_LGB2.csv', index=False)\nsubmission.head(20)","87aba6ce":"idx = (df_train.distance_to_center<15) & (df_train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count','Month','Date','Day of Week']\nX_ = df_train[idx][features].values\ny_= df_train[idx]['fare_amount'].values","e8353134":"## Generate Kaggle submission\n\nThe code below can be used to generate a Kaggle submission file.","a52462ba":"This model gives a kaggle score of about 5. Certainly not the best model on the leaderboard, but what could we expect from a linear regression model? \n\nFrom now on we need to improve the model. Considering the analysis above, I would search for a model that is able to:\n\n- model the non-linear time (`hour`) dependency\n- model different pricings (e.g. fixed fee to an airport vs metered ride)\n- model location dependencies and avoid the direct point-to-point distance measure.\n","29c913f2":"Note that the fare per distance has more spread for smaller distances (<0.5 mile) than larger distances. This could be explained as follows:  we measure the distance from point to point and not by road. For smaller distances the difference between these two measurement methods is expected to be larger. This is one aspect I would guess a more advanced model (deep learning NN) would improve upon compared to a linear model.\n\n[30\/07\/2018] An other reason why the spread for smaller distances is larger could be due to slow traffic at rush hours. Short drives at rush hours vary more in duration.","08e0fe25":"From the scatterplot on the map we see that some locations are in the water. Either these are considered as noise, or we drop them from the dataset. This depends on the model and training method used later.\n\n### Datapoint density per sq mile\n\n\nA scatterplot of the pickup and dropoff locations gives a quick impression of the density. However, it is more accurate to count the number of datapoints per area to visualize the density. The code below counts pickup and dropoff datapoints per sq miles. This gives a better view on the 'hot spots'.","19c5bf8e":"As this dataset is huge reading all data would require a lot of memory. Therefore I read a limited number of rows while exploring the data. When my exploration code (e.g. this notebook) is ready I re-run the notebook while reading more rows.","0f43cc7d":"It can be clearly seen that the fare $USD\/mile varies over the years and over the hours. \n\nTo investigate this further I used Google map to calculate the expected duration of two trips:\n\n- Trip 1 : from Museum of the City of New York to Beacon Theatre, 4.5km, not leaving Manhatten\n- Trip 2 : from Times Squared to Maria Hermandez Park, 12km, leaving Times Squared via Queens Midtown Tunnel (Toll road)\n\nBelow are the data and graphs. I do see the same type of graph. So, amount of traffic determines the duration of the trip and thus the fare. While the amount of traffic depends on the hour of the day.","f8ac3cd4":"## Fare at night is different from day time\n\nTo visualize the relation between time and fare\/km three more columns are added to the data: the year, the hour of the day and the fare $USD per KM.","b4ae4752":"# Generate Kaggle baseline model and submission\n\nAlso explore the test set, e.g. to see if the data has the same properties.","3442bd53":"There is a lot of 'green' dots, which is about \\$50 to \\$60 fare amount near 13 miles distance of NYC center of distrance of trip. This could be due to trips from\/to JFK airport. Let's remove them to see what we're left with.","b98fdfb7":"# New York City Taxi Fare Prediction Playground Competition\n\nThis is my notebook I used to explore the NYC Taxi Fare dataset. Use this yourself to explore the dataset. If you have question, sent me a message!\n\nHave fun!\n\nAlbert van Breemen\n27\/7\/2018\n\n**Update**\n\n2018\/07\/30\n- Corrected 'ewr'\/'lgr' typo [Thanks to Lu Mingming]\n- Small update `plot_on_map` function\n- Converted distances to miles [Thanks to sandy1112]\n- Add Taxi pricing rules [Thanks to sandy1112]\n- Added density plots (datapoints per sq mile)\n\n2018\/07\/28 \n- Added a graph with estimated drive time for two trips using Google Map Traffic info. This could explain how fare depends on hour of the day.\n\n\n## Reading data and first exploration\n\n\nFirst thing I like to do with a new dataset is to explore the data. This means investigating the number of features, their datatype, their meaning and statistics.","94a465f1":"Now there are some 'yellow' dots (fare amount > \\$80) left. To understand these datapoints we plot them on the map.","85e9ef7f":"The maximum fare \\$USD\/mile seem to be very high. This could be due to wrong distance or fare data. On the other hand, let's analyse this somewhat further. In general taxi fare is calculate by\n\n$$\ny_{fare} = \\theta_0 + \\theta_1 \\cdot x_{distance} + \\theta_2 \\cdot x_{duration}\n$$\n\nwith $\\theta_0$ the starting tariff, $x_{distance}$ the distance travelled and $x_{duration}$ the duration of the trip. If we rewrite this we get an expression for the fare per distance:\n\n$$\n\\frac{y_{fare}}{x_{distance}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1 + \\theta_2 \\cdot \\frac{x_{duration}}{ x_{distance}}\n$$\n\nLet's further assume for the shorter trips that $x_{distance} = c \\cdot x_{duration}$ with $c$ the average speed, then we get\n\n$$\n\\frac{y_{fare}}{x_{distance}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1 + \\frac{\\theta_2}{c} \\cdot \\frac{x_{duration}}{x_{duration}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1'\n$$\n\nwith $\\theta_1' = \\theta_1 + \\theta_2 \/ c$.\n\nConclusion: the fare per distance is proportional to $1\/\\text{distance_mile}$. Let's plot the data and a graph.\n","1b2ea1ca":"There seem to be a concentration of datapoints near dropoff (-74.2, 40.65). After looking these coordinates up on Google map I learned NYC has a second airport: Newark Liberty International Airport. The fare from\/to the airport from NYC center is around $80-$100 USD. \n\nLet's remove also these datapoints to see if my findings are right. As there is also a third airport, LaGuardia Airport, I remove them too.","36dc0e83":"## Fare varies with pickup location\n\nTo visualize whether the fare per km varies with the location the distance to the center of New York is calculated. ","6c22f12e":"## Remove missing data\n\nAlways check to see if there is missing data. As this dataset is huge, removing datapoints with missing data probably has no effect on the models beings trained.","0f671fff":"It seems that most rides are just short rides, with a small peak at ~13 miles. This peak could be due to airport drives.\n\nLet's also see the influence of `passenger_count`.","b7fb555a":"Let's continue with the time vs fare per distance analysis. Next we use a pandas pivot table to calculate a summary and to plot them.","d96446b4":"A `passenger_count` of zero seems odd. Perhaps a taxi transporting some goods or an administration error? The latter seems not the case as the `fare_amount` is also significantly lower.\n\nInstead of looking to the `fare_amount` using the 'fare per mile' also provides some insights.","ca0abe63":"\nA more in-depth analysis of the fare \/ time dependency is illustrated below. Here, I calculate per year and per hour the fare and do a linear regression. When investigating the plots, you clearly see the price increase over the years.","49315215":"The following things I notice (while using 500k datapoints):\n\n- The minimal `fare_amount` is negative. As this does not seem to be realistic I will drop them from the dataset.\n- Some of the minimum and maximum longitude\/lattitude coordinates are way off. These I will also remove from the dataset (I will define a bounding box for the coordinates, see further).\n- The average `fare_amount` is about \\$11.4 USD with a standard deviation of \\$9.9 USD. When building a predictive model we want to be better than $9.9 USD :)","d6fab467":"From this plot we notice:\n\n- There are trips with zero distance but with a non-zero fare. Could this be trips from and to the same location? Predicting these fares will be difficult as there is likely not sufficient information in the dataset.\n- There are some trips with >50 miles travel distance but low fare. Perhaps these are discounted trips? Or the previously mentioned hotspot near Seymour (see density plots above)?\n- The horizontal lines in the right plot might indicate again the fixed fare trips to\/from JFK airport.\n- Overall there seems to be a (linear) relation between distance and fare with an average rate of +\/- 100\/20 = 5 \\$USD\/mile.\n\nConsidering the last point, when I google for NYC taxi fare prices I find:\n\n- \\$4.00 \u2013 \\$10.00 for 3km trip (https:\/\/www.priceoftravel.com\/555\/world-taxi-prices-what-a-3-kilometer-ride-costs-in-72-big-cities\/)\n- Start range: \\$2.50 - \\$3.30, 1km range: \\$1.55 - \\$2.98 (https:\/\/www.numbeo.com\/taxi-fare\/in\/New-York)\n- A detailed description of the taxi prices: http:\/\/home.nyc.gov\/html\/tlc\/html\/passenger\/taxicab_rate.shtml\n    - Initial charge for most rides (excluding from JFK and other airports) is \\$2.50 upon entry. After that there \\$0.5 every unit where the unit is defined as 1\/5th of a mile or when the Taxicab is travelling 12 Miles an hour or more...since we can't decipher the velocity of the car, I would take 1\/5th of a mile as the unit and convert the distance into this unit.\n    - \\$0.5 of additional surcharge between 8PM - 6AM.\n    - Peak hour weekday surcharge of \\$1 Monday-Friday between 4PM-8PM.\n    - There is a \\$0.5 MTA State Surcharge for all trips that end in New York City or Nassau, Suffolk, Westchester, Rockland, Dutchess, Orange or Putnam Counties.\n    - There is a \\$0.3 Improvement surcharge\n\nNote: the calculated distance in the dataset is from point to point. In reality, the distance measured by road is larger.","4ea9e2fc":"\nOne datapoint in the testset seems to fall outside the defined boundingbox. For this notebook I assume the linear model will generalize sufficiently to deal with this unseen datapoint. For training a more advanced model (other notebook) I will redefine the BB and make it somewhat larger.","a1ae34e0":"$$\n\\text{fare} \\text{ ~ } \\text{year}, \\text{hour}, \\text{distance}, \\text{passenger_count}\n$$","e157d63f":"Plotting the distance to NYC center vs distance of the trip vs the fare amount gives some insight in this complex relation. ","9af2a79e":"For a baseline model I use a linear regression model.","c5ad725a":"In the histogram of the `fare_amount` there are some small spikes between \\$40 and \\$60. This could indicate some fixed fare price (e.g. to\/from airport). This will be explored further below.","e667f7a6":"### The longer the distance between pickup and dropoff location, the higher the fare\n\nTo visualize the distance - fare relation we need to calculate the distance of a trip first. ","f0ce540f":"These plots clearly show that the datapoints concentrate around Manhatten and the three airports (JFK, EWS, LGR). There is also a hotspot near Seymour (upper right corner). As I'm not from the US, does somebody has an idea what's so special about this location?\n","62ba50b6":"\n## Location data\n\nAs we're dealing with location data, I want to plot the coordinates on a map. This gives a better view of the data. For this, I use the following website:\n\n- Easy to use map and GPS tool: https:\/\/www.gps-coordinates.net\/ \n- Calculate distance between locations: https:\/\/www.travelmath.com\/flying-distance\/\n- Open street map to grab using bouding box a map: https:\/\/www.openstreetmap.org\/export#map=8\/52.154\/5.295\n\nNew York city coordinates are (https:\/\/www.travelmath.com\/cities\/New+York,+NY):\n\n- longitude = -74.0063889\n- lattitude = 40.7141667\n\nI define a bounding box of interest by `[long_min, long_max, latt_min, latt_max] = [-75, -73, 40, 41.5]`. From Open Street Map I grab a map and I drop any datapoint outside this box.","b5658f89":"## Some trips, like to\/from an airport, are fixed fee\n\nAnother way to explore this data is to check trips to\/from well known places. E.g. a trip to JFK airport. Depending on the distance, a trip to an airport is often a fixed price. Let's see.","753d2084":"It seems that there are some fixed prices to\/from the airport. Also, somebody might have paid way too much ($250??)!\n\nLet's do the same for the other two airports.","2882638a":"\nRemoving the to\/from airport trips seems to give a more 'linear' view of the data. Fare amount depends on distance travelled and not so much on starting position.","1b5ae351":"# Model\n\nBased on the analysis above, I would start with the following model:","73ff74dd":"## Distance and time visualisations\n\nBefore building a model I want to test some basic 'intuition':\n\n- The longer the distance between pickup and dropoff location, the higher the fare.\n- Some trips, like to\/from an airport, are fixed fee. \n- Fare at night is different from day time.\n\nSo, let's check."}}