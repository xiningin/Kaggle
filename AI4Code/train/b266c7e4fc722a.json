{"cell_type":{"d81c0c9c":"code","71e78f75":"code","578fafd1":"code","e78cd900":"code","748c0bd3":"code","9779ed79":"code","0e7013d0":"code","c71ee6b7":"code","102dd20d":"code","df192033":"code","55c6ba2f":"code","86405cee":"code","52bfed05":"code","f73d4cea":"code","df8c155d":"code","4b69335b":"code","37770689":"code","9a5c452b":"code","9ef80255":"code","8918cea5":"code","ed901410":"code","041af61e":"code","b6ad8c09":"code","62f5edda":"code","46fd9499":"code","4d98193e":"code","8dccdbb3":"code","8cca0a91":"code","0c4c24e0":"code","45ec29b6":"code","229f834a":"code","5be215f3":"code","48b69817":"code","0bc10c35":"markdown","1df5d617":"markdown","30562dab":"markdown","9068c35a":"markdown","118b605e":"markdown","2444e937":"markdown","24d18580":"markdown","16c9ab63":"markdown","53bea039":"markdown","6b133aaa":"markdown","57d67a2b":"markdown","b7f20adf":"markdown","3d0252e5":"markdown","fd16c191":"markdown","740b5cce":"markdown","816b546a":"markdown","2179232d":"markdown","df13b44a":"markdown","881cfefb":"markdown","5ebb4d83":"markdown","da00a048":"markdown","03ac046f":"markdown","d31c4b5b":"markdown","31bcfc3b":"markdown","3c7e83c9":"markdown","c8226b68":"markdown","2a637f84":"markdown","e1dcd0c6":"markdown","b817749b":"markdown","815c4c50":"markdown","e0fc3b26":"markdown"},"source":{"d81c0c9c":"import tensorflow as tf\nimport skimage.io ","71e78f75":"Xi = skimage.io.imread(\"https:\/\/www.data-imaginist.com\/assets\/images\/kitten.jpg\") #link for image to be read","578fafd1":"image = tf.cast(Xi, tf.float32)\nimage = tf.image.resize(image, (224, 224))\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage = image[None, ...]","e78cd900":"pretrained_model = tf.keras.applications.MobileNetV2(include_top=True, weights='imagenet')\npretrained_model.trainable = False","748c0bd3":"image_probs = pretrained_model.predict(image)","9779ed79":"decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\nprint(decode_predictions(image_probs))","0e7013d0":"def get_imagenet_label(probs):\n  return decode_predictions(probs, top=1)[0][0]","c71ee6b7":"import matplotlib.pyplot as plt","102dd20d":"plt.figure()\nplt.imshow(image[0]*0.5+0.5) \n_, image_class, class_confidence = get_imagenet_label(image_probs)\nplt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\nplt.show()","df192033":"# Get the input label of the image.\nindex = 200\nlabel = tf.one_hot(index, image_probs.shape[-1]) #one hot encoded array with only index 200 as 1\nlabel = tf.reshape(label, (1, image_probs.shape[-1])) # reshaping the array to (1,1000) which is the shape of image probabilities","55c6ba2f":"loss_object = tf.keras.losses.CategoricalCrossentropy()\n#function to create the perturbations.\ndef create_adversarial_pattern(input_image, input_label):\n  with tf.GradientTape() as tape:\n    tape.watch(input_image) #recording operations on tensor\n    prediction = pretrained_model(input_image)\n    loss = loss_object(input_label, prediction)\n\n  # Get the gradients of the loss w.r.t to the input image.\n  gradient = tape.gradient(loss, input_image)\n  print(loss)\n  # Get the sign of the gradients to create the perturbation\n  signed_grad = tf.sign(gradient)\n  return signed_grad","86405cee":"perturbations = create_adversarial_pattern(image, label)\nplt.imshow(perturbations[0]*0.5+0.5); ","52bfed05":"epsilons = [0, 0.01, 0.1, 0.15] #error\ndescriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n                for eps in epsilons]\n\nfor i, eps in enumerate(epsilons):\n  adv_x = image + eps*perturbations\n  adv_x = tf.clip_by_value(adv_x, -1, 1)\n  _, label, confidence = get_imagenet_label(pretrained_model.predict(adv_x))\n  plt.figure()\n  plt.imshow(adv_x[0]*0.5+0.5)\n  plt.title('{} \\n {} : {:.2f}% Confidence'.format(descriptions[i],\n                                                   label, confidence*100))\n  plt.show()","f73d4cea":"from sklearn.datasets import load_iris\nimport pandas as pd\n# Load the dataset\ndata = load_iris()\niris = pd.DataFrame(data.data)\niris.columns=['sepal_length','sepal_width','petal_length','petal_width']\niris['Class']=data.target\niris.head()","df8c155d":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","4b69335b":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\nx = iris.iloc[:, [1, 2, 3, 4]].values\ny_kmeans = kmeans.fit_predict(x)","37770689":"plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'virginica')\n\n#Plotting the prototypes of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'centroids')\n\nplt.legend()","9a5c452b":"from sklearn.metrics import silhouette_score\nsilhouette_score(data.data, kmeans.labels_)","9ef80255":"#MANUALLY PLOTTING THE CRITICISMS\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'virginica')\n\n#Plotting the prototypes of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'centroids')\nplt.scatter(3.8, 6.5,marker='x',s=250, c = 'brown', label='Criticism')\nplt.scatter(2.2, 4,marker='x',s=250, c = 'brown')\nplt.scatter(2.7, 6.7,marker='x',s=250, c = 'brown')\nplt.scatter(4.2, 1.2,marker='x',s=250, c = 'brown')\nplt.scatter(2.2, 1.2,marker='x',s=250, c = 'brown')\nplt.legend()","8918cea5":"from statsmodels.formula.api import ols\n\nm = ols('Class ~ petal_width',data=iris).fit()\nprint(m.params)","ed901410":"import scipy.stats as stats\nimport statsmodels.api as sm","041af61e":"fig = sm.graphics.qqplot(m.resid, dist=stats.norm, line='45', fit=True)","b6ad8c09":"fig = plt.figure(figsize=(15,10))\nfig = sm.graphics.plot_regress_exog(m, \"petal_width\", fig=fig)","62f5edda":"infl = m.get_influence()\nsm_fr = infl.summary_frame()\nsm_fr[:10]","46fd9499":"import matplotlib.pyplot as plt\nplt.figure(figsize=(25,10))\nplt.title(\"Cooks Distance\")\nplt.xlabel(\"Petal width\")\nplt.ylabel(\"Influence\")\nsm_fr.cooks_d.plot.bar()","4d98193e":"print(\"1. Observations with a cooks distance greater than \",iris['petal_width'].mean()  * 3,\"are possible outliers.\")\n# Here n=no. of observations =150\nn=150\nprint(\"2. Any point over \",4\/n,\" should be investigated.\")\nprint(\"3. Any value that sticks out from the other should also be investigated.\")","8dccdbb3":"iris[(sm_fr.cooks_d>0.0267)].nunique","8cca0a91":"iris_new1 = iris[(sm_fr.cooks_d)<=0.0267]\niris_new1","0c4c24e0":"plt.figure(figsize=(25,10))\nplt.title(\"Cooks Distance\")\nplt.xlabel(\"Petal width\")\nplt.ylabel(\"DFFITS\")\nsm_fr.dffits.plot.bar()","45ec29b6":"import math\nn=150\n# Here n=no. of observations =150\nk=1\n# Here k=no. of predictor terms =1\nprint(\"An observation is deemed influential if the absolute value of its DFFITS value > \", 2 * math.sqrt((k+2)\/(n-k-2)))","229f834a":"iris[(abs(sm_fr.dffits)>0.2857)].nunique","5be215f3":"iris_new2 = iris[(abs(sm_fr.dffits)<=0.2857)]\niris_new2","48b69817":"import seaborn as sns\nsns.boxplot(iris_new1['petal_width'])","0bc10c35":"Step 3: Mobilenet v2 initialisation. The predicted output(preds) is a vector of 1000 probabilities for each class available.","1df5d617":"\nRemoving the outliers and producing a new dataframe -","30562dab":"# Prototypes and Criticisms","9068c35a":"INTERPRETATION -\n\nHere, the brown points are manually plotted in orer to show the criticisms.\nCriticismns are selected from the data points of regions that are not well explained by the prototypes.","118b605e":"On combining the results of Cooks distance and DFFITS, it is clear that there were total 7 outliers(134 instance is common in both). The final dataframe without outliers is as follows -","2444e937":"\nRemoving the outliers and producing a new dataframe -","24d18580":"# Adversarial Examples","16c9ab63":"INTERPRETATION -\nThe new dataframe contains 143 rows which means that the 7 outliers which were present are now removed.","53bea039":"INTERPRETATION -\n\nThe DFFITS gives us an idea of the effect of deleting a value on model parameters. The values on x axis are instances of petal width and on the y axis is the corresponding influence when the particular instance is removed.\n\nOn the basis of the thumb rules printed above, there is one value with absolute value > 0.286. \n\n\n","6b133aaa":"# Influential Instances","57d67a2b":"Step 5: Extracting labels","b7f20adf":"Step 2: Preprocessing the images. The image is converted to tensor, resized and preprocessed for mobilenet_v2 .","3d0252e5":"Step 7: Using FGSM(Fast Gradient Signed Method) for adversarial images","fd16c191":"INTERPRETATION -\n\nThe prototypes are selected to cover the centers of the data distribution and the criticisms are points in a cluster without a prototype. Thus,the clusters of the red, blue and green points where the centroids lie can be considered as the Prototypes.\n\nThe small group of points where the density of points is low (which are not a part of any cluster but are important samples) are the Criticisms.","740b5cce":"INTERPRETATION -\n\nThe Cooks distance gives us an idea of the effect of deleting a value on model predictions. The values on x axis are instances of petal width and on the y axis is the corresponding influence when the particular instance is removed.\n\nOn the basis of the thumb rules printed above, there is no value above 3.59 but there are a number of values over 0.027. \n\n\n","816b546a":"INTERPRETATION -\n\nThis is the Q-Q plot of residuals where plot comes very close to a straight line, except possibly for the upper tail, where we find a couple of residuals somewhat larger than expected.","2179232d":"The description of these classes is shown and it can be seen that the \"tiger cat\" is the top class for the given image with the max probability of 0.339.","df13b44a":"## 2. DFFITS","881cfefb":"Ordinary least squares (OLS) is a method that defines the relationship between one or more independent variables and a dependent variable. It minimizes the sum of the squares in the difference between the observed and predicted values of the dependent variable.\n\nFor example, let us consider the target variable 'class' and the independent variable 'petal width' for analysis.","5ebb4d83":"Step 8: Displaying adversarial images (with decoded label and confidence level)","da00a048":"##Deletion diagnostics","03ac046f":"There are many approaches to find prototypes in the data. One of these is k-means, a clustering algorithm. Any clustering algorithm that returns actual data points as cluster centers would qualify for selecting prototypes. ","d31c4b5b":"## 1. COOK'S DISTANCE","31bcfc3b":"Step 6: Displaying the image with the image label and confidence level(i.e. the probability that it contains the label)","3c7e83c9":"Step 4: Predict class of input image using Mobilenet v2 model.","c8226b68":"Adversarial pattern is created by recording the loss using the label, then finding the gradient wrt. image and obtaining the sign of the gradient.","2a637f84":"The above table contains the data for first 10 samples.","e1dcd0c6":"INTERPRETATION -\nThe new dataframe contains 149 rows which means that the 1 outlier which was present is now removed.","b817749b":"Step 1: Storing the image to be read. tensorflow is used for the whole process.","815c4c50":"INTERPRETATION -\n\nIn an adversarial example, a small feature perturbations (error) is added  intentionally that cause a machine learning model to make a false prediction. \nAdversarial image = Input image + Epsilon * Perturbations\n\nHere, it can be seen that -\n\nThe first image is the original image with 0 error. On adding a small amount of error (epsilon = 0.01) , the model is fooled to predict the image with more probability. If the epsilon is increased to 0.05 and 0.1, the prediction has changed from tiger cat to egyptian cat(with more confidence level) and tabby respectively.\n\nThus, the same image with different levels of error is used for prediction multiple times using the same model but the results are different as the model is deceived by the error introduced.","e0fc3b26":"INTERPRETATION -\n\nTo analyse the global model behaviour and individual predictions, we have drawn the above plots. The etailed explanation is as follows -\n\nWhen performing a linear classification with only one independent variable, a scatter plot of the target against the independent variable provides a good indication of the nature of the relationship. Since there is more than one variable, this will not work as it does not take into account the effect of the other independent variables in the model.\n\nThus, Partial residual plots and CCPR plots are used to show the relationship between a given independent variable and the response variable given that other independent variables are also in the model.  \n\nIn partial regression plot-\nY = residuals from regressing Y (class of iris) against all the independent variables except petal width\nXi = residuals from regressing petal width against the remaining indpependent variables.\n\nIn CCPR plot -\nThe x axis shows the independent variable(petal width) whereas y axis shows the residuals of model + (regression_coefficient * the independent variable) to show where the fitted line would lie.\n\nThe residuals(a measure of how much a regression line vertically misses a data point) are also shown in separate plot."}}