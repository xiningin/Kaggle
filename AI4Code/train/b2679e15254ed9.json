{"cell_type":{"4f60d21a":"code","2d5a1257":"code","5b5c355c":"code","1878bc8c":"code","8beeab34":"code","ca79cac8":"code","b42d8477":"code","8d7880ef":"code","1b184216":"code","e3fc7f6a":"code","528a811c":"code","ce3570a0":"code","11031c1b":"code","a586046f":"code","c9a85cf2":"code","a2d7ff58":"code","ce656aee":"code","b3554e86":"code","f13af420":"code","d2f3ad44":"code","e00ae357":"code","6e24c767":"code","5591e574":"code","0e7f3dd9":"code","18032fbe":"code","7ee769c2":"code","5c2ce800":"code","5c873fdc":"code","fccef475":"code","1a9e6d55":"code","0049c9e5":"code","3b134c87":"code","e0d69034":"code","ace2f519":"code","bbf75692":"code","a0b5b558":"code","bf302909":"code","8f2af4c2":"code","fb9ed922":"code","bc286184":"code","17620264":"code","2812f604":"code","fcdaa728":"code","3789d802":"code","8173d35a":"code","377136ec":"code","4b2fa703":"code","3e7b9063":"code","b7079130":"code","be09e7f9":"code","2938928d":"code","1ca1d996":"code","7e3c0ebc":"code","eeea15e5":"code","82932b91":"code","d75882dc":"code","5ffb2d4f":"code","c89cd4cb":"code","2287e677":"code","d7d4c835":"code","00e2fe8d":"code","24a02f73":"code","b0d84cce":"code","532c4273":"code","35ce0ee0":"code","958a9a6c":"code","bde1dfb6":"code","3dc6bbb8":"code","ccf00073":"code","dad35a50":"code","79c09d25":"code","1af03e6f":"code","92545d77":"markdown","583f0eee":"markdown","7478fee1":"markdown","9468d446":"markdown","8034cb0e":"markdown","a53280f7":"markdown","4b4f5df4":"markdown","5121c28a":"markdown","4938b110":"markdown"},"source":{"4f60d21a":"import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns","2d5a1257":"gender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')","5b5c355c":"gender_submission.head()","1878bc8c":"gender_submission.shape","8beeab34":"test.head()","ca79cac8":"test.shape","b42d8477":"train.head()","8d7880ef":"train.shape","1b184216":"y_train = train['Survived']\ntrain.drop('Survived', axis=1, inplace=True)","e3fc7f6a":"y_train.shape","528a811c":"X_train = train\nX_train.shape","ce3570a0":"X_test = test","11031c1b":"X_train.head()","a586046f":"X_test.head()","c9a85cf2":"X_train.drop(['Cabin', 'Ticket'], axis=1, inplace=True)\nX_test.drop(['Cabin', 'Ticket'], axis=1, inplace=True)","a2d7ff58":"X_train.head()","ce656aee":"one_hot_encoded_data = pd.get_dummies(X_train, columns = ['Embarked'])","b3554e86":"X_train = one_hot_encoded_data","f13af420":"X_train.head()","d2f3ad44":"X_train.shape","e00ae357":"X_train['Sex'].replace(['male', 'female'], [1, 0], inplace=True)","6e24c767":"X_train.head()","5591e574":"X_train.shape","0e7f3dd9":"X_test.head()","18032fbe":"one_hot_encoded_data = pd.get_dummies(X_test, columns = ['Embarked'])","7ee769c2":"X_test = one_hot_encoded_data","5c2ce800":"X_test['Sex'].replace(['male', 'female'], [1, 0], inplace=True)","5c873fdc":"X_test.head()","fccef475":"X_test.head()","1a9e6d55":"X_train.drop('Name', axis=1, inplace=True)\nX_test.drop('Name', axis=1, inplace=True)","0049c9e5":"X_train.isnull().sum()","3b134c87":"X_test.isnull().sum()","e0d69034":"for col in X_train.columns:\n    print(col, '  -->  ', X_train[col].isnull().values.any())","ace2f519":"X_train['Age'].fillna(int(X_train['Age'].mean()), inplace=True)","bbf75692":"for col in X_train.columns:\n    print(col, '  -->  ', X_train[col].isnull().values.any())","a0b5b558":"X_train['Age'] = X_train['Age'].apply(pd.to_numeric, downcast='integer')","bf302909":"X_train.shape","8f2af4c2":"X_test['Age'].fillna(int(X_test['Age'].mean()), inplace=True)","fb9ed922":"X_test['Age'] = X_test['Age'].apply(pd.to_numeric, downcast='integer')","bc286184":"X_test['Fare'].fillna(X_test['Fare'].mean(), inplace=True)","17620264":"X_test.head()","2812f604":"X_test.isnull().sum()","fcdaa728":"X_test.shape","3789d802":"X_train.shape","8173d35a":"y_train.shape","377136ec":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","4b2fa703":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","3e7b9063":"accuracyDetails = {}","b7079130":"cv = KFold(n_splits=10, random_state=1, shuffle=True)","be09e7f9":"model = RandomForestClassifier(n_estimators = 40)\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","2938928d":"print(scores*100)","1ca1d996":"print(\"Mean Accuracy for the Model using Random Forest = {}\".format(np.round(scores.mean()*100, 2)))","7e3c0ebc":"accuracyDetails['Random Forest'] = np.round(scores.mean()*100, 2)","eeea15e5":"model = SVC()\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","82932b91":"print(scores*100)","d75882dc":"print(\"Mean Accuracy for the Model using SVM = {}\".format(np.round(scores.mean()*100, 2)))","5ffb2d4f":"accuracyDetails['SVM'] = np.round(scores.mean()*100, 2)","c89cd4cb":"model = KNeighborsClassifier(n_neighbors=7)\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","2287e677":"print(scores*100)","d7d4c835":"print(\"Mean Accuracy for the Model using KNN = {}\".format(np.round(scores.mean()*100, 2)))","00e2fe8d":"accuracyDetails['KNN'] = np.round(scores.mean()*100, 2)","24a02f73":"model = LogisticRegression(solver='liblinear')\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)","b0d84cce":"print(scores*100)","532c4273":"print(\"Mean Accuracy for the Model using Logistic Regression = {}\".format(np.round(scores.mean()*100, 2)))","35ce0ee0":"accuracyDetails['Logistic Regression'] = np.round(scores.mean()*100, 2)","958a9a6c":"print(accuracyDetails)","bde1dfb6":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\n","3dc6bbb8":"rfMain = RandomForestClassifier(n_estimators=40)\nrfMain.fit(X_train, y_train)\ny_pred = rfMain.predict(X_test)","ccf00073":"y_pred","dad35a50":"y_pred_df = pd.DataFrame([gender_submission['PassengerId'] ,y_pred], index=['PassengerId', 'Survived'])","79c09d25":"y_pred_df = y_pred_df.T","1af03e6f":"y_pred_df.to_csv('My_Predictions.csv', index=False)","92545d77":"## Using Random Forest","583f0eee":"### Logistic Regression's Cross validation","7478fee1":"Problem:\n> The sinking of the Titanic is one of the most infamous shipwrecks in history.\n> While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. \n> In this challenge, we are asked to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\nSolution: \n> Firstly for this classification the target test data is not given so what I did is first k-fold cross-validated with 10 fold to the algorithms KNN, SVM, Logistic Regression & Random Forest and selected the best one among them.\n> Mean of Accuracy readings of KNN, SVM, Logistic regression & Random forest are 62.18%, 65.1%, 79.69% & 81.6% respectively.\n> Random Forest worked best in this case so I used it for my predictions.","9468d446":"### KNN's Cross validation","8034cb0e":"## Conclusion: Random Forest works best for cross validation sets so we are using Random Forest classifier for the classification","a53280f7":"## Cross Valdiation Set","4b4f5df4":"### SVM's Cross validation","5121c28a":"## Titanic Survival Prediction","4938b110":"### Random Forest's Cross validation"}}