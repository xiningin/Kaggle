{"cell_type":{"df3d0260":"code","7aa2bf8b":"code","5466f06d":"code","62bf7ca2":"code","ebe6f257":"code","34a3cf1d":"code","036fc4e9":"code","300d6a81":"code","1c3607fe":"code","4f5acfe2":"code","71e1f3d4":"code","8736af75":"code","47235026":"code","c766df46":"code","84dbfb74":"code","f26b903e":"code","e1f19223":"code","b1841c83":"code","2572c13b":"code","d2c9b01b":"code","a561071d":"code","8856df9e":"code","2df5e2dd":"code","f76e2165":"code","1c2c41bc":"code","30ee1f31":"code","82a914cc":"code","1305b8ce":"code","108645b6":"code","88bfaf4c":"code","fbe191ca":"code","00de48d3":"code","7f0cea33":"code","5684e7ae":"code","281f8e85":"code","4445a661":"code","10bb75f8":"code","28369933":"code","0e1f741f":"code","19b3c5a5":"code","3f02dd2d":"code","28b49584":"code","de02d23d":"code","d1291de5":"code","3e1975e4":"code","eea2c874":"code","4b19451b":"code","5d9d638d":"code","00a92961":"code","14bdeb7d":"code","2eed9a5f":"code","c45a0a24":"code","5b12e59e":"code","f9ca44da":"code","2a5305a9":"code","08ddc50b":"code","8952e3e7":"code","e54cc8b9":"code","b53d8178":"code","e0aa3498":"code","5bed5570":"code","1ab5ec47":"markdown","f337d323":"markdown","1091e6a0":"markdown","286ec023":"markdown","c8ada632":"markdown","2c299f11":"markdown","9a8061be":"markdown","c31a5621":"markdown","8fff9a2c":"markdown","d0509c94":"markdown","43210481":"markdown","fa6267cf":"markdown","dc485533":"markdown","309eaf71":"markdown","f352e777":"markdown","7a154196":"markdown"},"source":{"df3d0260":"# Library\n\n# Firstly used libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Warnings\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\npd.set_option('display.max_rows', None)\n\n# Data Preprocessing\n\nfrom sklearn.neighbors import LocalOutlierFactor \nfrom sklearn import preprocessing\n\n# Modeling\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost\nfrom xgboost import XGBRegressor\n!pip install lightgbm\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\n# Model Tuning\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","7aa2bf8b":"# read the data\nhitters=pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\nhitters.head()","5466f06d":"df=hitters.copy()\nprint(df.shape)\ndf.info()","62bf7ca2":"#drop NA values\n\ndf1=df.dropna()\ndf1.shape","ebe6f257":"y=df1[\"Salary\"]\nX=df1.drop(\"Salary\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\nprint(X_train.shape)\nX_train.head()","34a3cf1d":"df1=X_train.copy()","036fc4e9":"# understanding skewness of the features ( It is acceptable if the skewness is btween -1 and 1)\n# When the value of the skewness is negative, the tail of the distribution is longer towards the left hand side of the curve.\n# When the value of the skewness is positive, the tail of the distribution is longer towards the right hand side of the curve.\ndf1.skew(axis = 0, skipna = True) ","300d6a81":"# The features which will be transformed\n\ndf1.skew(axis = 0, skipna = True)[(df1.skew(axis = 0, skipna = True) >1) | (df1.skew(axis = 0, skipna = True)< -1)]","1c3607fe":"df1.isin([0]).any()==True   #( HmRun, CHmRun, PutOuts, Assists, Errors features have zero values.)","4f5acfe2":"# numpy.log1p will be used to deal with these zeros (because of CHmRun, PutOuts, Assists features' zero values)\n\ndf1[df1.isin([0]).any(axis=1)==True].loc[:, \"CHmRun\":\"Assists\"]","71e1f3d4":"# Applying log1p transformation for right skewed features and applying exponential for left skewed features\nsns.distplot(df1[\"CHmRun\"], hist=False);","8736af75":"df1[\"CHmRun\"]=np.log1p(df1[\"CHmRun\"])","47235026":"sns.distplot(df1[\"CRuns\"], hist=False);","c766df46":"df1[\"CRuns\"]= np.log(df1[\"CRuns\"])","84dbfb74":"sns.distplot(df1[\"CRBI\"], hist=False);","f26b903e":"df1[\"CRBI\"]= np.log(df1[\"CRBI\"])","e1f19223":"sns.distplot(df1[\"CWalks\"], hist=False);","b1841c83":"df1[\"CWalks\"]= np.log(df1[\"CWalks\"])","2572c13b":"sns.distplot(df1[\"PutOuts\"], hist=False);","d2c9b01b":"df1[\"PutOuts\"]= np.log1p(df1[\"PutOuts\"])","a561071d":"sns.distplot(df1[\"Assists\"], hist=False);","8856df9e":"df1[\"Assists\"]= np.log1p(df1[\"Assists\"])","2df5e2dd":"# Salary has skewness\nprint(y_train.skew(axis = 0, skipna = True))\nsns.distplot(y_train, hist=False);","f76e2165":"# y_train= np.log(y_train)","1c2c41bc":"df1.head(3)","30ee1f31":"# get dummies\n\ndf1 =pd.get_dummies(df1,columns= [\"League\",\"Division\",\"NewLeague\"], drop_first=True)\ndf1.head(2)","82a914cc":"numeric_df1=df1.loc[:, \"AtBat\":\"Errors\"]\ncat_df1=df1.loc[:, \"League_N\":\"NewLeague_N\"]","1305b8ce":"df2=numeric_df1.copy()\n\n# LOF  Outlier Detection\n\nclf= LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\nclf.fit_predict(df2)\n\ndf2_scores=clf.negative_outlier_factor_\nnp.sort(df2_scores)[0:10]","108645b6":"sns.boxplot(df2_scores);","88bfaf4c":"outlier_indexes=df2.loc[df2_scores< -2]\noutlier_indexes","fbe191ca":"# Throw away outliers from df1 and Salary feature also according to these indexes .","00de48d3":"df1=df1.drop(index=[249])\ndf1=df1.reset_index(drop=True)\n\ny_train=pd.DataFrame(y_train).drop(index=[249])\ny_train=y_train.reset_index(drop=True)\nprint(df1.shape )\nprint(y_train.shape )","7f0cea33":"df1.head(2)","5684e7ae":"df3=pd.concat([df1,y_train], axis=1)\nprint(df3.shape)\ndf3.head()","281f8e85":"# df3 is our final data frame. df1 means X train data,  y_train means y train data","4445a661":"y_train[0:5]","10bb75f8":"X_test.head()","28369933":"X_test =pd.get_dummies(X_test,columns= [\"League\",\"Division\",\"NewLeague\"], drop_first=True)\nX_test.head(2)","0e1f741f":"y_test[0:5]","19b3c5a5":"df1.head(2)","3f02dd2d":"# df1a (all numeric features are transformed)","28b49584":"df1a=df1.copy()\ndf1a[\"AtBat\"]=np.log1p(df1a[\"AtBat\"])\ndf1a[\"Hits\"]=np.log1p(df1a[\"Hits\"])\ndf1a[\"HmRun\"]=np.log1p(df1a[\"HmRun\"])\ndf1a[\"Runs\"]=np.log1p(df1a[\"Runs\"])\ndf1a[\"RBI\"]=np.log1p(df1a[\"RBI\"])\ndf1a[\"Walks\"]=np.log1p(df1a[\"Walks\"])\ndf1a[\"Years\"]=np.log1p(df1a[\"Years\"])\ndf1a[\"CAtBat\"]=np.log1p(df1a[\"CAtBat\"])\ndf1a[\"CHits\"]=np.log1p(df1a[\"CHits\"])\ndf1a[\"Errors\"]=np.log1p(df1a[\"Errors\"])\ndf1a.head(2)","de02d23d":"df1.head(3)","d1291de5":"cat_df4= df1.loc[:, \"League_N\":\"NewLeague_N\"]","3e1975e4":"numeric_df4=df1.loc[:, \"AtBat\":\"Errors\"]\nnumeric_df4.head()","eea2c874":"numeric_df4_columns=numeric_df4.columns\nstandardized_numeric_df4=preprocessing.scale(numeric_df4)\nstandardized_numeric_df4=pd.DataFrame(standardized_numeric_df4, columns=numeric_df4_columns)\nprint(standardized_numeric_df4.shape)\nstandardized_numeric_df4.head(2)","4b19451b":"y_train.shape","5d9d638d":"df4= pd.concat([standardized_numeric_df4,cat_df4], axis=1)\ndf4","00a92961":"# Here X_train is df4","14bdeb7d":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","2eed9a5f":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1a,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","c45a0a24":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df4,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","5b12e59e":"#the best model is knn for df3: 442 RMSE\n\n","f9ca44da":"sns.distplot(y_test, hist=False);","2a5305a9":"y_test.skew()","08ddc50b":"y_train= np.log(y_train)\n\n\n\nmodels = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","8952e3e7":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1a,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","e54cc8b9":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df4,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","b53d8178":"y_test= np.log(y_test)\n\nmodels = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","e0aa3498":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df1a,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","5bed5570":"models = []\n\nmodels.append(('Regression', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Lasso', Lasso()))\nmodels.append(('ElasticNet', ElasticNet()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('GBM', GradientBoostingRegressor()))\nmodels.append((\"XGBoost\", XGBRegressor()))\nmodels.append((\"LightGBM\", LGBMRegressor()))\nmodels.append((\"CatBoost\", CatBoostRegressor(verbose = False)))\n\n\nfor name, model in models:\n    model.fit(df4,y_train)\n    y_pred=model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(name,rmse)","1ab5ec47":"## df3 modeling","f337d323":"## df4 modeling","1091e6a0":"# DATA UNDERSTANDING","286ec023":"## df4 modeling","c8ada632":"## df3 modeling","2c299f11":"## df3 modeling","9a8061be":"# These are the version of log transformed Salary(y_train and y_test) for df3-df1a-df4","c31a5621":"## df4 modeling","8fff9a2c":"# df1a (all numeric features are transformed) modeling","d0509c94":"# MODELING","43210481":"# DATA PREPROCESSING","fa6267cf":"# These are the version of log transformed Salary(y_train) for df3-df1a-df4","dc485533":"## 2nd Trial : df4\n\n* **df1-->df4**\n\n* drop NA values\n* train-test split\n* log and log(1+x) transformation on train data\n* detect outliers and drop them on train data\n* standardization","309eaf71":"## 1st Trial : df3\n\n* **df1-->df2-->df3**\n\n* drop NA values\n* train-test split\n* log and log(1+x) transformation on train data\n* detect outliers and drop them on train data","f352e777":"## df1a (all numeric features are transformed) modeling","7a154196":"## df1a (all numeric features are transformed) modeling"}}