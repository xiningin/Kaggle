{"cell_type":{"7fd235d7":"code","50e16ac0":"code","90b927cb":"code","1bdbc4b4":"code","9ce5b796":"code","1b97b17a":"code","ef6af32a":"markdown","34da6561":"markdown","935e6072":"markdown","0294e6ee":"markdown","01c2db52":"markdown","ae58aac7":"markdown"},"source":{"7fd235d7":"import torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","50e16ac0":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\ny = train_data.label\nX = train_data.drop(['label'], axis=1)\n\nX = X\/255.0\ntest_data = test_data\/255.0\n\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nprint('shape of x_train ', x_train.shape)\nprint('shape of x_val ', x_val.shape)\nprint('shape of y_val ', y_val.shape)\nprint('shape of y_train ', y_train.shape)\n\n\nclass Digits(torch.utils.data.Dataset):\n    def __init__(self, pixel, label):\n        self.x = pixel\n        self.y = label.values\n        \n    def __len__(self):\n        return len(self.x)\n        \n    def __getitem__(self, index):\n        x = self.x.values[index]\n        y = self.y[index]\n        return x, y\n    \ntrain_ds = Digits(x_train, y_train)\nval_ds = Digits(x_val, y_val)\ntest_ds = Digits(test_data, pd.Series(np.zeros(784)))\n\n# dataloader\nbatch_size = 64\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size)","90b927cb":"plt.figure(figsize=(10,10))\nfor i in range(12):\n    plt.subplot(4, 3, i+1)\n    plt.imshow(train_ds[i][0].reshape(28, 28))\nplt.show()","1bdbc4b4":"from sklearn.decomposition import PCA\n\npca = PCA(n_components= 2)\ndata_reduced = pca.fit_transform(X)\n\nlabels = np.unique(y)\ncolors = ['cornflowerblue','darkturquoise','teal','red','mediumpurple','goldenrod','yellowgreen','grey','palevioletred','darkorange']\nplt.figure(figsize=(20,12))\nplt.rc('font', size=14)\nfor label in labels:\n    subset = data_reduced[train_data.label==label]\n    pca_1 = [row[0] for row in subset]\n    pca_2 = [row[1] for row in subset]\n    plt.scatter(pca_1,pca_2, c=colors[label], label= labels[label])\n    \n\nplt.legend()\nplt.show()","9ce5b796":"class my_model(torch.nn.Module):\n    def __init__(self):\n        super(my_model, self).__init__()\n        self.layer = torch.nn.Linear(784, 500)\n        self.output_layer = torch.nn.Linear(500, 10)\n        \n    def forward(self, x):\n        y = self.layer(x)\n        y = torch.nn.functional.relu(y)\n        y = self.output_layer(y)\n        y = torch.nn.functional.softmax(y, dim=1)\n        return y\n\ndef train_model(model, optimizer, train_dl, val_dl, epochs):\n    for i in range(epochs):\n        total = 0\n        sum_loss = 0\n        for x, y in train_dl:\n            batch = y.shape[0]\n            x = x.cuda().float()\n            y = y.cuda()\n            # forward pass \n            predict_class = model(x)\n            # calculate loss\n            loss = torch.nn.functional.cross_entropy(predict_class, y)\n\n            # initialise the gradients\n            optimizer.zero_grad()\n            # backpropagate\n            loss.backward()\n            # update weights\n            optimizer.step()\n\n            total += batch\n            sum_loss += loss.item()\n\n        train_loss = sum_loss \/ total\n        val_loss, val_acc = val_model(model, val_dl)\n\n        print(\"epoch {} train_loss {:.3f} val_loss {:.3f} val_acc {:.3f}\".format(i, train_loss, val_loss, val_acc))\n        \n    return sum_loss\/total\n\ndef val_model(model, val_dl):\n    sum_loss = 0\n    total =0\n    correct = 0\n    \n    for x, y in val_dl:\n        batch = y.shape[0]\n        x = x.cuda().float()\n        y = y.cuda()\n        y_pred = model(x)\n        loss = torch.nn.functional.cross_entropy(y_pred, y)\n        _, index = torch.max(y_pred, 1)\n        correct += index.eq(y).sum().item()\n        total += batch\n        sum_loss += loss.item()\n        val_loss = sum_loss\/total\n        val_acc = correct\/total\n        \n    return val_loss, val_acc\n\n\nmodel = my_model().cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_model(model, optimizer, train_dl, val_dl, 50)","1b97b17a":"rows, cols = 5, 5\n\nplt.figure(figsize=(20,20))\n\nfor i in range(rows*cols):   \n    test_x, _ = test_ds[i]\n    test_x = torch.FloatTensor(test_x.reshape(-1, 784))\n    y_class = model(test_x.cuda())\n    y = y_class.cpu().data.numpy().argmax()\n    confidence = y_class.cpu().data.numpy()[0][y]\n    plt.subplot(rows, cols, i+1)\n    plt.imshow(test_ds[i][0].reshape(28, 28))\n    plt.xlabel('predicted class : {}'.format(y))\n    \nplt.tight_layout()\nplt.show()","ef6af32a":"### TRAIN THE MODEL","34da6561":"### EVALUATE THE MODEL","935e6072":"##  THIS NOTEBOOK IS FOR PYTORCH BEGINNERS ","0294e6ee":"### IMPORT LIBRARIES","01c2db52":"### VISUALIZE THE DATA IN 2D PLOT","ae58aac7":"### CREATE DATASET"}}