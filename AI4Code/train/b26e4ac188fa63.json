{"cell_type":{"2ced6dad":"code","b45d9326":"code","e82badb9":"code","ab542b41":"code","66ebf00a":"code","6d86c616":"code","dfed0888":"code","9fa7f7ff":"code","f7cf6b24":"code","1fd62490":"code","985adc7a":"code","b58e5b6a":"code","d985790a":"code","bd999622":"code","9b1a387b":"code","ed66e31c":"markdown","07d002b3":"markdown","b2bc21ee":"markdown","1f939379":"markdown","562895e7":"markdown"},"source":{"2ced6dad":"import os\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets","b45d9326":"tf.test.is_gpu_available()","e82badb9":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","ab542b41":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\ndataset_base_path = GCS_DS_PATH+\"\/tfrecords-jpeg-224x224\"\ndef get_records(split_name):\n    filenames = tf.io.gfile.glob(dataset_base_path+\"\/\"+ split_name+\"\/\"+ \"*.tfrec\")\n    return tf.data.TFRecordDataset(filenames)","66ebf00a":"train_records = get_records(\"train\")\nval_records = get_records(\"val\")\n\noptions = tf.data.Options()\noptions.experimental_deterministic = False\n\ntest_records = get_records(\"test\").with_options(options)","6d86c616":"image_feature_description = {\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'class': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef decode_image(image):\n    image = tf.io.decode_image(image)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, (image_size, image_size, 3))\n    image \/= 255\n    return image\n\ndef parse_image_function(example_proto):\n    example = tf.io.parse_single_example(example_proto, image_feature_description)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int64)\n    id = example['id']\n    return image, label, id\n","dfed0888":"image_size = 224\n\ntraining_size = sum(1 for record in train_records.map(parse_image_function))\nprint(\"Training Size:\", training_size)\n\ntrain_records\n\nfor image, label, id in train_records.map(parse_image_function):\n    plt.imshow(image)\n    plt.title(label.numpy())\n    break","9fa7f7ff":"batch_size = 32\n\ndef label_data_map(image, label, id):\n    return image, label\n\ndef unlabel_data_map(image, label, id):\n    return image\n\ntraining_batch = train_records.map(parse_image_function).shuffle(training_size\/\/4).map(label_data_map).batch(batch_size).prefetch(1)\nvalidation_batch = val_records.map(parse_image_function).map(label_data_map).batch(batch_size).prefetch(1)\ntest_batch = test_records.map(parse_image_function).map(unlabel_data_map).batch(batch_size).prefetch(1)","f7cf6b24":"num_classes = 104\n\nwith strategy.scope():\n    feature_extractor = tf.keras.applications.MobileNetV2(input_shape=(image_size, image_size, 3), weights='imagenet')\n    feature_extractor.trainable = False\n    \n    model = tf.keras.Sequential([\n        feature_extractor,\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n","1fd62490":"EPOCHS = 50\n\nhistory = model.fit(training_batch, epochs=EPOCHS, validation_data=validation_batch)","985adc7a":"model.evaluate(validation_batch)","b58e5b6a":"ids = []\nfor img, label, id in test_records.map(parse_image_function):\n    ids.append(id.numpy().decode(\"utf-8\"))","d985790a":"probs = model.predict(test_batch)","bd999622":"preds = np.argmax(probs, axis=1)","9b1a387b":"np.savetxt('submission.csv', np.rec.fromarrays([ids, preds]), fmt=['%s', '%d'], header='id,label', delimiter=',', comments='')","ed66e31c":"# Reading TFRecord Files","07d002b3":"# Model","b2bc21ee":"## Validation","1f939379":"## Input Pipeline","562895e7":"## Prediction"}}