{"cell_type":{"7b79cb52":"code","5bf00fea":"code","d7e56381":"code","e2bb307f":"code","0b015659":"code","0b586f68":"code","a7b0900c":"code","31d28548":"code","c97ec910":"code","e9fd070e":"code","dcb8a956":"code","e404c63b":"code","07e9454e":"code","19767488":"code","c483df78":"code","490615ee":"code","745e8bce":"code","48a02cc7":"code","e1a7c173":"code","8882e38c":"code","2e66b677":"code","82d4e5dc":"code","74df3aba":"code","1e89b090":"code","d7540bb9":"code","960eeec3":"code","b4851dbd":"code","b51789a6":"code","38600d4d":"code","12c0068f":"code","0cf53dbe":"code","2b29cf16":"code","70895378":"markdown","28ce4568":"markdown","38a5c01f":"markdown","c76303e3":"markdown","de50a2fe":"markdown","38181134":"markdown","42ab5638":"markdown","5539b145":"markdown","41a0bc3b":"markdown","03906d8c":"markdown","6a09c08a":"markdown","a92bb523":"markdown","a1c18a1f":"markdown","7ba064db":"markdown","98b02259":"markdown","1051bcf1":"markdown","f61e7ab5":"markdown","8469ccb2":"markdown","ed64b14e":"markdown","e8eb0e05":"markdown"},"source":{"7b79cb52":"from glob import glob\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.datasets import load_files \nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\n\nfrom keras.utils import np_utils\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/flowers\/flowers\"))\n\n# Any results you write to the current directory are saved as output.","5bf00fea":"# Make a parent directory `data` and three sub directories `train`, `valid` and 'test'\n%rm -rf data # Remove if already present\n\n%mkdir -p data\/train\/daisy\n%mkdir -p data\/train\/tulip\n%mkdir -p data\/train\/sunflower\n%mkdir -p data\/train\/rose\n%mkdir -p data\/train\/dandelion\n\n%mkdir -p data\/valid\/daisy\n%mkdir -p data\/valid\/tulip\n%mkdir -p data\/valid\/sunflower\n%mkdir -p data\/valid\/rose\n%mkdir -p data\/valid\/dandelion\n\n%mkdir -p data\/test\/daisy\n%mkdir -p data\/test\/tulip\n%mkdir -p data\/test\/sunflower\n%mkdir -p data\/test\/rose\n%mkdir -p data\/test\/dandelion\n\n\n%ls data\/train\n%ls data\/valid\n%ls data\/test","d7e56381":"base_dir = \"..\/input\/flowers\/flowers\"\ncategories = os.listdir(base_dir)","e2bb307f":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom shutil import copyfile\n\nplt.rcParams[\"figure.figsize\"] = (20,3)","0b015659":"def train_valid_test(files):\n    \"\"\"This function splits the files in training, validation and testing sets with 60%, 20%\n    and 20% of data in each respectively\"\"\"\n    train_fles = files[:int(len(files)*0.6)]\n    valid_files = files[int(len(files)*0.6):int(len(files)*0.8)]\n    test_files = files[int(len(files)*0.8):]\n    return train_fles, valid_files, test_files","0b586f68":"def copy_files(files, src, dest):\n    \"\"\"This function copy files from src to dest\"\"\"\n    for file in files:\n        copyfile(\"{}\/{}\".format(src, file), \"{}\/{}\".format(dest, file))","a7b0900c":"def plot_images(category, images):\n    \"\"\"This method plots five images from a category\"\"\"\n    for i in range(len(images)):\n        plt.subplot(1,5,i+1)\n        plt.title(category)\n        image = mpimg.imread(\"{}\/{}\/{}\".format(base_dir, category, images[i]))\n        plt.imshow(image)\n    plt.show()","31d28548":"total_images = []\nfor category in categories:\n    images = os.listdir(\"{}\/{}\".format(base_dir, category))\n    random.shuffle(images)\n    filtered_images = [image for image in images if image not in ['flickr.py', 'flickr.pyc', 'run_me.py']]\n    \n    total_images.append(len(filtered_images))\n    \n    \n    train_images, valid_images, test_images = train_valid_test(filtered_images)\n    \n    copy_files(train_images, \"{}\/{}\".format(base_dir, category), \".\/data\/train\/{}\".format(category))\n    copy_files(valid_images, \"{}\/{}\".format(base_dir, category), \".\/data\/valid\/{}\".format(category))\n    copy_files(test_images, \"{}\/{}\".format(base_dir, category), \".\/data\/test\/{}\".format(category))\n    plot_images(category, images[:5])\n    \n        ","c97ec910":"print(\"Total images: {}\".format(np.sum(total_images)))\nfor i in range(len(categories)):\n    print(\"{}: {}\".format(categories[i], total_images[i]))","e9fd070e":"y_pos = np.arange(len(categories))\nplt.bar(y_pos, total_images, width=0.2,color='b',align='center')\nplt.xticks(y_pos, categories)\nplt.ylabel(\"Image count\")\nplt.title(\"Image count in different categories\")\nplt.show()","dcb8a956":"# define function to load train, valid and test datasets\ndef load_dataset(path):\n    data = load_files(path)\n    flower_files = np.array(data['filenames'])\n    print(data['target_names'])\n    flower_targets = np_utils.to_categorical(np.array(data['target']), 5)\n    return flower_files, flower_targets\n\n# load train, test, and validation datasets\ntrain_files, train_targets = load_dataset('data\/train')\nvalid_files, valid_targets = load_dataset('data\/valid')\ntest_files, test_targets = load_dataset('data\/test')\n\nprint('There are %d total flower categories.' % len(categories))\nprint('There are %s total flower images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\nprint('There are %d training flower images.' % len(train_files))\nprint('There are %d validation flower images.' % len(valid_files))\nprint('There are %d test flower images.' % len(test_files))\n","e404c63b":"from keras.preprocessing import image                  \nfrom tqdm import tqdm","07e9454e":"def path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(224, 224))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)","19767488":"def paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","c483df78":"from PIL import ImageFile                            \nImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\n# pre-process the data for Keras\ntrain_tensors = paths_to_tensor(train_files).astype('float32')\/255\nvalid_tensors = paths_to_tensor(valid_files).astype('float32')\/255\ntest_tensors = paths_to_tensor(test_files).astype('float32')\/255","490615ee":"simple_model = Sequential()\nprint(train_tensors.shape)\n\n### Define the architecture of the simple model.\nsimple_model.add(Conv2D(filters=16, kernel_size=2, strides=1, activation='relu', input_shape=(224,224,3)))\nsimple_model.add(GlobalAveragePooling2D())\nsimple_model.add(Dense(5, activation='softmax'))\nsimple_model.summary()","745e8bce":"simple_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","48a02cc7":"# Create a `saved_models` directory for saving best model\n%mkdir -p saved_models","e1a7c173":"from keras.callbacks import ModelCheckpoint  \n\n### number of epochs\nepochs = 50\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.simple.hdf5', \n                               verbose=1, save_best_only=True)\n\nsimple_model.fit(train_tensors, train_targets, \n          validation_data=(valid_tensors, valid_targets),\n          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)","8882e38c":"simple_model.load_weights('saved_models\/weights.best.simple.hdf5')","2e66b677":"# get index of predicted flower category for each image in test set\nflower_predictions = [np.argmax(simple_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(flower_predictions)==np.argmax(test_targets, axis=1))\/len(flower_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","82d4e5dc":"model = Sequential()\nprint(train_tensors.shape)\n### Define architecture.\nmodel.add(Conv2D(filters=16, kernel_size=2, strides=1, activation='relu', input_shape=(224,224,3)))\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=32, kernel_size=2, strides=1, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=64, kernel_size=2, strides=1, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(5, activation='softmax'))\nmodel.summary()","74df3aba":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","1e89b090":"from keras.callbacks import ModelCheckpoint  \n\n### number of epochs\nepochs = 50\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.from_scratch.hdf5', \n                               verbose=1, save_best_only=True)\n\nmodel.fit(train_tensors, train_targets, \n          validation_data=(valid_tensors, valid_targets),\n          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)","d7540bb9":"model.load_weights('saved_models\/weights.best.from_scratch.hdf5')","960eeec3":"# get index of predicted flower category for each image in test set\nflower_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(flower_predictions)==np.argmax(test_targets, axis=1))\/len(flower_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","b4851dbd":"from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.models import Model\n\ninception_resnet = InceptionResNetV2(weights=\"imagenet\",include_top=False, input_shape=(224,224,3))\nfor layer in inception_resnet.layers[:5]:\n    layer.trainable = False\n\noutput_model = inception_resnet.output\noutput_model = Flatten()(output_model)\noutput_model = Dense(200, activation='relu')(output_model)\noutput_model = Dropout(0.5)(output_model)\noutput_model = Dense(200, activation='relu')(output_model)\noutput_model = Dense(5, activation='softmax')(output_model)\n\nmodel = Model(inputs=inception_resnet.input, outputs=output_model)\nmodel.summary()","b51789a6":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","38600d4d":"from keras.callbacks import ModelCheckpoint  \n\n### number of epochs\nepochs = 50\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.inception_resnetv2.hdf5', \n                               verbose=1, save_best_only=True)\n\nmodel.fit(train_tensors, train_targets, \n          validation_data=(valid_tensors, valid_targets),\n          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)","12c0068f":"### load best weights\nmodel.load_weights('saved_models\/weights.best.inception_resnetv2.hdf5')","0cf53dbe":"# get index of predicted flower category for each image in test set \nflower_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(flower_predictions)==np.argmax(test_targets, axis=1))\/len(flower_predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","2b29cf16":"for i in range(5):\n    predicted = np.argmax(model.predict(np.expand_dims(test_tensors[i], axis=0)))\n    actual = np.argmax(test_targets[i])\n    print(\"Predicted: {}, Actual: {}, Name: {}\".format(predicted, actual, test_files[i].split(\"\/\")[2]))\n    image = mpimg.imread(test_files[i])\n    plt.imshow(image)\n    plt.show()","70895378":"---\n<a id='step1'><\/a>\n## Step 1: Data Preprocessing\n\n### Import Libraries\nHere we import a set of useful libraries","28ce4568":"The flowers are represented in dataset as follows: \n\n```\n                                                       flowers\n\nDaisy                     Dandelion                     Rose                     Sunflower                     Tulip\n\n```\nWe can split dataset in order to produce training, validation and testing sets that would easily utilize `load_files` from `sklearn`\n\n```\n                                                                                                                          data\n                                                        training                                                        validation                                                        test\n                                  Daisy  |  Dandelion  |  Rose  |  Sunflower  |  Tulip      &&     Daisy  |  Dandelion  |  Rose  |  Sunflower  |  Tulip     &&    Daisy  |  Dandelion  |  Rose  |  Sunflower  |  Tulip\n\n```","38a5c01f":"### Data Transformation\n\nKeras' CNNs require a 4D tensor as input with the shape as `(nb_samples, rows, columns, channels)` where\n- `nb_samples`: total number of samples or images\n- `rows`: number of rows of each image\n- `columns`: number of columns of each image\n- `channels`: number of channels of each image\n","c76303e3":"#### Load best weight of the model","de50a2fe":"#### Get the accuracy on test set","38181134":"<a id=\"step4\"><\/a>\n## Step 4: Develop a CNN using Transfer Learning","42ab5638":"# Introduction\nThe model is designed to classify flowers by species.\n\nOur EDA is structured in the following way:\n\n**[First](#step1)**: Data analysis.\n\n**[Second](#step2)**:  Model training.\n\n**[Third](#step3)**: CNN Model training.\n\n**[Fourth](#step4)**: CNN using transfer learning.\n","5539b145":"### Making Predictions with the simple model","41a0bc3b":"#### Load the best weight of the model","03906d8c":"The `ptahs_to_tensor` applies `path_to_tensor` to all images and returns a list of tensors.","6a09c08a":"### Observations\n- There are 4323 total images with approximately similar distribution in each category.\n- The dataset does not seem  to be imbalanced.\n- Accuracy can be used as a metric for model evaulation.","a92bb523":"### Benchmark model's performance\nThe accuracy obtained from the benchmark model is 41.57%.","a1c18a1f":"### Create a 4D tensor\nThe `path_to_tensor` function below takes a color image as input and returns a 4D tensor suitable for supplying to Keras CNN. The function first loads the image and then resizes it 224x224 pixels. The image then, is converted to an array and resized to a 4D tensor. The returned tensor will always have a shape of `(1, 224, 224, 3)` as we are dealing with a single image only in this function.","7ba064db":"### Pre-process the Data\nRescale the images by dividing every pixel in every image by 255.","98b02259":"#### Get the accuracy of the model","1051bcf1":"Find all the categories of the flowers","f61e7ab5":"### Analyze the data\nData is stored in a directory named \"flower\", in seperate sub-directories based on the species.","8469ccb2":"---\n<a id=\"step3\"><\/a>\n## Step 3: Develop a CNN architecture from scratch","ed64b14e":"<a id=\"step2\"><\/a>\n## Step 2: Develop a Benchmark model\nUse a simple CNN to create a benchmark model.","e8eb0e05":"### Statistics of flowers"}}