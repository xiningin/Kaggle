{"cell_type":{"31e546f7":"code","50ad55d3":"code","f2fcc9f7":"code","b3dc9c89":"code","c902a967":"code","206c264d":"code","9ddc6c46":"code","2994edf8":"code","bba2cba4":"code","ef0f5a32":"code","4110a4cf":"code","1ae19fa1":"code","2b9fcc1b":"code","27781d33":"code","34ae5728":"code","908def7f":"code","38f81ea7":"code","1d7c4a2d":"code","4d1306fa":"code","9b0dc9f8":"code","c95db5ed":"code","0f8f4d2f":"code","b5fa6eac":"code","9a6fad2b":"code","9d72cf51":"code","81586de5":"code","ce1885ce":"code","b96cd2c8":"code","83cca0c9":"code","4d96ed7e":"code","854341a6":"code","64524056":"code","ee1fad03":"code","e19a886b":"code","8902bbcf":"code","a2932a05":"code","35478c3d":"code","e7c4d0be":"code","9c5072b2":"code","f475f6be":"code","7d297fe7":"code","287b7604":"code","c1a798f5":"markdown","26000924":"markdown","5806f80c":"markdown","7ef752e0":"markdown","b6dcabf2":"markdown","f6966f74":"markdown","b56366bf":"markdown","fc324f16":"markdown","55c4585a":"markdown","a82e4487":"markdown","c0b953e2":"markdown","d59140d8":"markdown","173cf57e":"markdown","251cb1a0":"markdown","f83e94a1":"markdown","ea1f8197":"markdown"},"source":{"31e546f7":"import numpy as np\nimport pandas as pd\n\nimport keras\nfrom keras.preprocessing import image\nfrom keras.utils import to_categorical\n\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\n\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.python.keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport cv2","50ad55d3":"# Directory Listings for train and test images\n\ntrain_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'","f2fcc9f7":"# Reading the csv files\n\ntrain = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv')\nsubmission=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","b3dc9c89":"# Exploring the content of train file\ntrain.head()","c902a967":"# Comparing the number of records in both categories\ntrain['target'].value_counts()","206c264d":"train_benign = train[train['target']==0].sample(3000)\ntrain_malign = train[train['target']==1]\ntrain_samples = pd.concat([train_benign,train_malign])\ntrain_samples.reset_index()","9ddc6c46":"# Training data\ntrain_labels = []\ntrain_images =[]\n\nfor i in range(train_samples.shape[0]):\n    train_images.append(train_dir+train_samples['image_name'].iloc[i]+'.jpg')\n    train_labels.append(train_samples['target'].iloc[i])\n\ndf_train = pd.DataFrame(train_images)\ndf_train.columns =['images']\ndf_train['target'] = train_labels","2994edf8":"# Test data\ntest_images =[]\nfor i in range(test.shape[0]):\n    test_images.append(test_dir+test['image_name'].iloc[i]+'.jpg')\n\ndf_test = pd.DataFrame(test_images)\ndf_test.columns = ['images']","bba2cba4":"# Splitting the train data further into train and validation sets\nX_train, X_val, y_train,y_val = train_test_split(df_train['images'],df_train['target'],test_size=0.2,random_state=0)\n\ntrain = pd.DataFrame(X_train)\ntrain.columns = ['images']\ntrain['target']=y_train\n\nvalidation = pd.DataFrame(X_val)\nvalidation.columns = ['images']\nvalidation['target']=y_val","ef0f5a32":"def get_predictions(model,sub_df):\n    target=[]\n    for path in df_test['images']:\n        img=cv2.imread(str(path))\n        img = cv2.resize(img, (224,224))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32)\/255.\n        img=np.reshape(img,(1,224,224,3))\n        prediction=model.predict(img)\n        target.append(prediction[0][0])\n    \n    sub_df['target']=target\n    return sub_df","4110a4cf":"train_datagen = ImageDataGenerator(preprocess_input,rescale=1.\/255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(preprocess_input,rescale=1.\/255)\n\nimage_size = 224\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                    train,\n                    x_col='images',\n                    y_col ='target',\n                    target_size=(image_size,image_size),\n                    batch_size=8,\n                    shuffle=True,\n                    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n                    validation,\n                    x_col='images',\n                    y_col ='target',\n                    target_size=(image_size,image_size),\n                    batch_size=8,\n                    shuffle=False,\n                    class_mode='raw')","1ae19fa1":"def vgg16_model(num_classes=None):\n    model = VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n    x = Flatten()(model.output)\n    output = Dense(1,activation='sigmoid')(x)\n    model = Model(model.input,output)\n    \n    return model","2b9fcc1b":"vgg_conv = vgg16_model(1)","27781d33":"def focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","34ae5728":"# Defining the optimizer and compiling the model\nopt = Adam(lr=1e-5)\nvgg_conv.compile(loss=focal_loss(),optimizer=opt,metrics=[keras.metrics.AUC()])","908def7f":"# Denining the num of epochs, batch_size and steps for training and validation\nnb_epochs = 2\nbatch_size=8\nnb_train_steps = train.shape[0]\/\/batch_size  # \/\/ rounds off the result of division\nnb_validation_steps = validation.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps are {} and {}\".format(nb_train_steps,nb_validation_steps))","38f81ea7":"# Fitting the model\nvgg_conv.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_steps)","1d7c4a2d":"# Getting the predictions for test data\n\nsub_dfs = []\n\nsub_vgg16 = submission.copy()\nsub_vgg16 = get_predictions(vgg_conv,sub_vgg16)\nsub_vgg16.head()","4d1306fa":"sub_vgg16.to_csv('submission_vgg16.csv',index=False)","9b0dc9f8":"df_vgg16 = pd.read_csv('..\/input\/subvgg16csv\/submission_vgg16.csv')\ndf_vgg16.head()","c95db5ed":"sub_dfs = []\nsub_dfs.append(df_vgg16)","0f8f4d2f":"def resnet50_model(num_classes=None):\n    model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3),pooling='avg')\n    x = Flatten()(model.output)\n    output = Dense(1,activation='sigmoid')(x)\n    model = Model(model.input,output)\n    \n    return model","b5fa6eac":"resnet_conv = resnet50_model(1)","9a6fad2b":"# Denining the optimizer and compiling the model\nopt = Adam(lr=1e-5)\nresnet_conv.compile(loss=focal_loss(),optimizer=opt,metrics=[keras.metrics.AUC()])","9d72cf51":"# Denining the num of epochs, batch_size and steps for training and validation\nnb_epochs = 2\nbatch_size=8\nnb_train_steps = train.shape[0]\/\/batch_size  # \/\/ rounds off the result of division\nnb_validation_steps = validation.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps are {} and {}\".format(nb_train_steps,nb_validation_steps))","81586de5":"# Fitting the model\nresnet_conv.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_steps)","ce1885ce":"# Getting the predictions for test data\n\n\nsub_resnet = submission.copy()\nsub_resnet = get_predictions(resnet_conv,sub_resnet)\nsub_resnet.head()","b96cd2c8":"sub_resnet.to_csv('submission_resnet.csv',index=False)","83cca0c9":"df_resnet = pd.read_csv('..\/input\/subresnetcsv\/submission_resnet.csv')\nsub_dfs.append(df_resnet)","4d96ed7e":"!pip install -q efficientnet\nimport efficientnet.tfkeras as efn","854341a6":"def efficientnet_model(num_classes=None):\n    \n    model = keras.Sequential([\n        \n            efn.EfficientNetB7(\n            weights='imagenet',\n            include_top=False,\n            input_shape=(224,224,3)),\n        keras.layers.GlobalAveragePooling2D(), #Works like flatten layer but adds pooling to it to optimize data before feeding to FC layer\n        keras.layers.Dense(1024,activation='relu'),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(512,activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(256,activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128,activation='relu'),\n        keras.layers.Dropout(0.1),\n        keras.layers.Dense(1,activation='sigmoid')\n        \n    ])\n    return model","64524056":"efficientnet_conv = efficientnet_model(1)","ee1fad03":"# Defining the optimizer and compiling the model\nopt = Adam(lr=1e-5)\nefficientnet_conv.compile(loss=focal_loss(),optimizer=opt,metrics=[keras.metrics.AUC()])","e19a886b":"# Defining the num of epochs, batch_size and steps for training and validation\nnb_epochs = 2\nbatch_size=8\nnb_train_steps = train.shape[0]\/\/batch_size  # \/\/ rounds off the result of division\nnb_validation_steps = validation.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps are {} and {}\".format(nb_train_steps,nb_validation_steps))","8902bbcf":"# Fitting the model\nefficientnet_conv.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_steps)","a2932a05":"# Getting the predictions for test data\n\n\nsub_efficientnet = submission.copy()\nsub_efficientnet = get_predictions(efficientnet_conv,sub_efficientnet)\nsub_efficientnet.head()","35478c3d":"sub_efficientnet.to_csv('submission_efficientnet.csv',index=False)","e7c4d0be":"df_efficient = pd.read_csv('..\/input\/subefficientnetcsv\/submission_efficientnet.csv')\nsub_dfs.append(df_efficient)","9c5072b2":"from scipy.stats import rankdata","f475f6be":"#Ranking results from all models\nfor i in range(3) :\n    sub_dfs[i]['target'] = rankdata(sub_dfs[i]['target'], method='min')","7d297fe7":"sub_dfs[0]['target'] = sub_dfs[0]['target']*0.8 + sub_dfs[1]['target']*0.1 + sub_dfs[2]['target']*0.1\nsub_dfs[0].head()","287b7604":"sub_dfs[0].to_csv('submission_blending.csv' , index = False)","c1a798f5":"# Helper Functions","26000924":"# Preparing the train and test data","5806f80c":"# Blending Scores from All Models","7ef752e0":"This is a baseline model to detect Melanoma in the images given in the dataset. Here I have used subset of training data (3500 images). I used 3 pre-trained models which are VGG16, Resnet50 and Efficientnet B7, and ensembled the results using weighted average.\n\nThe process will be consisting of below steps.\n\n1. Importing the required libraries\n2. Loading and preparng the images\n3. Preprocessing\n4. Defining and training the model8\n5. Getting predictions for the model\n6. Repeating step 4,5 for other models\n7. Blending the scores from all 3 models\n8. Submission","b6dcabf2":"# Exploring the data","f6966f74":"**1. VGG16 Pre-trained Model**","b56366bf":"# Modeling","fc324f16":"# Submitting Final Predictions","55c4585a":"**2. EfficientNet B7 Pretrained Model**","a82e4487":"# Data Preprocessing","c0b953e2":"Using focal loss instead of binary_cropssentory because of class imbalance","d59140d8":"The data is highly imbalanced as only 584 records belong to class 1 (Malignant).\nHence we will be taking a sample of 3000 images from benign cases, along with all 584 malignant cases","173cf57e":"#  Importing Libraries","251cb1a0":"Data Processing will include following tasks\n\n1. Normalization of pixel values to range of 0 to 1\n2. Reshaping of the images\n3. Data augumentation for training images","f83e94a1":"**2. Resnet50 Pretrained Model**","ea1f8197":"Giving more weightage to VGG16 since it gave better score on validation data"}}