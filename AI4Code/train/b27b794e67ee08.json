{"cell_type":{"7973ca8a":"code","e7538e90":"code","b7c36ece":"code","954495a0":"code","541fad52":"code","030fc55f":"code","d7a97eeb":"code","d4dea449":"code","c6b0dfcd":"code","e57a123d":"code","d1a0c781":"code","2db27218":"code","f7f8a4c2":"code","1583be13":"code","a88f24e7":"code","b8c4d7c7":"code","02a255f7":"code","0c6fde64":"code","86ab1972":"code","4b3f8cd8":"code","40e27b59":"code","45bbefad":"code","362f9bbb":"code","e0ed4e64":"code","e89bbea7":"code","261d3943":"code","d3d36be8":"code","16a925ce":"code","2eb0f0c3":"code","26510e4f":"code","98a9d686":"code","55c81803":"code","b0eecb76":"code","259608f8":"code","bbcc9ca2":"code","7fb9c241":"code","83e4ca67":"code","decfd30a":"code","15534a5a":"code","a905ebb3":"code","2cf16d02":"code","36eff751":"code","a61da782":"code","3eae2e52":"code","0f9a9d3e":"code","3b75cfec":"code","3801fcc3":"code","62c63772":"code","c8aca5d0":"code","7826f16f":"code","b306978e":"code","b174a8cf":"code","9886f2ca":"code","c32a9414":"code","17a741b0":"markdown","a22f13ab":"markdown","b6273e82":"markdown","49ce97fa":"markdown","714bc4c1":"markdown","f971fe9e":"markdown","84af548a":"markdown","f8a2aa61":"markdown","ce03cc8b":"markdown","cd38bc9c":"markdown","9644a8e2":"markdown","71acc073":"markdown","be6a6f38":"markdown","9a7c323f":"markdown","411f1ede":"markdown","4fa446d6":"markdown","4c40b256":"markdown","4cfefe12":"markdown","ff49f5bb":"markdown"},"source":{"7973ca8a":"%matplotlib inline","e7538e90":"!git clone https:\/\/github.com\/nachiket273\/pytorch_resnet_rs","b7c36ece":"!cp -r pytorch_resnet_rs\/* .","954495a0":"!pip install wandb --upgrade","541fad52":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport math\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport random\nimport seaborn as sns\nfrom sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.models as models\n\nfrom tqdm.notebook import tqdm\n\nfrom model import ResnetRS\nfrom model.ema import EMA","030fc55f":"import wandb\nwandb.login()","d7a97eeb":"print(\"Torch version: \", torch.__version__)\nprint(\"Torchvision version: \", torchvision.__version__)","d4dea449":"DIR = '..\/input\/seti-breakthrough-listen\/'\nTRAIN_CSV = os.path.join(DIR, 'train_labels.csv')\nTEST_CSV = os.path.join(DIR, 'sample_submission.csv')","c6b0dfcd":"train_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)","e57a123d":"train_df.head()","d1a0c781":"def get_img_path(img_id, train=True):\n    if train:\n        dir_path = os.path.join(DIR, 'train')\n    else:\n        dir_path = os.path.join(DIR, 'test')\n    file_name = os.path.join(img_id[0], img_id + '.npy')\n    dir_path = os.path.join(dir_path, file_name)\n    return dir_path","2db27218":"train_df['img_path'] = train_df['id'].apply(lambda k : get_img_path(k))\ntrain_df.head()","f7f8a4c2":"test_df['img_path'] = test_df['id'].apply(lambda k: get_img_path(k, False))\ntest_df.head()","1583be13":"CFG = {\n    'seed' : 37,\n    'epochs' : 20,\n    'img_size' : 320,\n    'bs' : 32,\n    'num_classes' : 2,\n    'base_lr' : 1e-4,\n    'weight_decay' : 1e-3,\n    'test_size' : 0.1,\n    'drop_rate'  : 0.1,\n    'min_lr' : 1e-7\n}","a88f24e7":"def seed_everything(seed=17):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","b8c4d7c7":"seed_everything(CFG['seed'])","02a255f7":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","0c6fde64":"sns.countplot(x= train_df['target'])","86ab1972":"train_df['target'].value_counts(normalize=True)","4b3f8cd8":"def show_images(path, label):\n    _id = path.split('\/')[-1].split('.')[0]\n    cadence = np.load(path).astype(np.float32)\n    fig, ax = plt.subplots(nrows = 6, ncols = 1, figsize = (16, 10))\n    fig.suptitle(f'ID:{_id}   TARGET:{label}', fontsize = 18)\n    for i in range(6):\n        ax[i].imshow(cadence[i], interpolation = 'nearest', aspect = 'auto')\n        ax[i].text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n    \n    plt.show()","40e27b59":"show_images(train_df[train_df['target'] == 0]['img_path'].values[0], 0)","45bbefad":"show_images(train_df[train_df['target'] == 1]['img_path'].values[0], 1)","362f9bbb":"test_sample = test_df.sample(3)\ntest_sample.head()","e0ed4e64":"for path in test_sample['img_path'].values:\n    show_images(path, None)","e89bbea7":"class SetiDS(Dataset):\n    def __init__(self, img_paths, labels, test=False, transform=None):\n        self.test = test\n        self.img_paths = img_paths \n        if not self.test:\n            self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        file_path = self.img_paths[idx]\n        \n        image = np.load(file_path)\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n            #image = self.transform(image)\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n            \n        if not self.test:\n            label = torch.tensor(self.labels[idx]).long()\n            return image, label\n        else:\n            return image","261d3943":"def get_transforms(train=True):\n    if train:\n        transform = A.Compose([\n            A.Resize(CFG['img_size'], CFG['img_size']),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            ToTensorV2(),\n        ])\n    else:\n        transform = A.Compose([\n            A.Resize(CFG['img_size'], CFG['img_size']),\n            ToTensorV2()\n        ])\n    return transform","d3d36be8":"train_tf = get_transforms()\nval_tf = get_transforms(False)\ntest_tf = get_transforms(False)","16a925ce":"X_train, X_val, y_train, y_val = train_test_split(train_df['img_path'], train_df['target'],\n                                                  test_size=CFG['test_size'],\n                                                  random_state=CFG['seed'],\n                                                  stratify=train_df['target'])","2eb0f0c3":"train_ds = SetiDS(X_train.values, y_train.values, transform=train_tf)\nval_ds = SetiDS(X_val.values, y_val.values, transform=val_tf)\ntest_ds = SetiDS(test_df['img_path'].values, None, test=True, transform=test_tf)","26510e4f":"train_dl = DataLoader(train_ds, batch_size=CFG['bs'], num_workers=4,\n                      drop_last=False, shuffle=True, pin_memory=True)\nvalid_dl = DataLoader(val_ds, batch_size=CFG['bs'], num_workers=4,\n                      drop_last=False, shuffle=False, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size=CFG['bs'], num_workers=4,\n                     drop_last=False, shuffle=False, pin_memory=True)","98a9d686":"def save_checkpoint(model, filename='data\/checkpoint.pth'):\n    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n    torch.save(model.state_dict(), filename)","55c81803":"def load_checkpoint(model, filename = 'data\/checkpoint.pth'):\n    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n    names = set(model.state_dict().keys())\n    for n in list(sd.keys()):\n        if n not in names and n+'_raw' in names:\n            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n            del sd[n]\n    model.load_state_dict(sd)","b0eecb76":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.losses =[]\n        self.acc = []\n        self.prec = []\n        self.rec = []\n        self.F1 =[]\n        self.roc_auc = []\n        self.its = []\n        \n    def append(self, loss, acc, prec, rec, F1, roc_auc, it):\n        self.losses.append(loss)\n        self.acc.append(acc)\n        self.prec.append(prec)\n        self.rec.append(rec)\n        self.F1.append(F1)\n        self.roc_auc.append(roc_auc)\n        self.its.append(it)","259608f8":"def train(loader, model, optimizer, criterion, ema, device):\n    model.train()\n    running_loss = 0.\n    correct = 0\n    start_time = time.time()\n    t = tqdm(loader, leave=False, total=len(loader))\n    preds, tgts = list(), list()\n\n    for i, (ip, tgt) in enumerate(t):\n        ip, tgt = ip.to(device), tgt.to(device)\n        output = model(ip)\n        loss = criterion(output, tgt)\n        running_loss += loss.item()\n        _, pred = output.max(dim=1)\n        correct += torch.sum(pred == tgt.data)\n        tgt = tgt.cpu().detach().numpy()\n        pred = pred.cpu().detach().numpy()\n        tgts.extend(list(tgt))\n        preds.extend(list(pred))\n        \n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        ema.update(model.parameters())\n        \n    trn_time = time.time() - start_time        \n    trn_losses = running_loss \/len(loader)\n    trn_acc = correct * 100\/ len(loader.dataset)\n    trn_F1 = f1_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n    trn_prec = precision_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n    trn_rec = recall_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n    trn_roc_auc = roc_auc_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n    \n    return trn_time, trn_F1, trn_losses, trn_acc, trn_prec, trn_rec, trn_roc_auc","bbcc9ca2":"def test(loader, model, criterion, ema, device):\n    with torch.no_grad():\n        model.eval()\n        running_loss = 0.\n        correct = 0\n        start_time = time.time()\n        t = tqdm(loader, leave=False, total=len(loader))\n        preds, tgts = list(), list()\n        \n        for i, (ip, tgt) in enumerate(t):\n            ip, tgt = ip.to(device), tgt.to(device)\n            ema.store(model.parameters())\n            ema.copy(model.parameters())\n            output = model(ip)\n            loss = criterion(output, tgt)\n            ema.copy_back(model.parameters())\n            running_loss += loss.item()\n            _, pred = output.max(dim=1)\n            correct += torch.sum(pred == tgt.data)\n            tgt = tgt.cpu().detach().numpy()\n            pred = pred.cpu().detach().numpy()\n            tgts.extend(list(tgt))\n            preds.extend(list(pred))\n            \n        val_time = time.time() - start_time\n        val_losses = running_loss\/len(loader)\n        val_acc = correct * 100 \/ len(loader.dataset)\n        val_F1 = f1_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n        val_prec = precision_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n        val_rec = recall_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n        val_roc_auc = roc_auc_score(tgts, preds, average='weighted', labels=np.unique(tgts)) * 100\n        \n        return val_time, val_F1, val_losses, val_acc, val_prec, val_rec, val_roc_auc","7fb9c241":"def fit(model, epochs, optimizer, criterion, ema, device, wandb, sched=None):\n    best_roc_auc = 0.\n    print(\"Epoch\\tTrn_loss\\tVal_loss\\tTrn_roc_auc\\tVal_roc_auc\\tTrn_Acc\\t\\tVal_Acc\")\n    limit = 0\n    for j in range(epochs):\n        trn_time, trn_F1, trn_losses, trn_acc, trn_prec, trn_rec, trn_roc_auc = train(train_dl, model, optimizer, criterion, ema, device)\n        train_stats.append(trn_losses, trn_acc, trn_prec, trn_rec, trn_F1, trn_roc_auc, trn_time)\n        val_time, val_F1, val_losses, val_acc, val_prec, val_rec, val_roc_auc = test(valid_dl, model, criterion, ema, device)\n        test_stats.append(val_losses, val_acc, val_prec, val_rec, val_F1, val_roc_auc, val_time)\n        wandb.log({\n            \"Train Loss\": trn_losses,\n            \"Valid Loss\": val_losses,\n            \"Train Acc\": trn_acc,\n            \"Valid Acc\": val_acc,\n            \"Train Roc Auc Score\": trn_roc_auc,\n            \"Valid Roc Auc Score\": val_roc_auc,\n            \"Train Precision Score\": trn_prec,\n            \"Valid Precision Score\": val_prec,\n            \"Train Recall Score\": trn_rec,\n            \"Valid Recall Score\": val_rec,\n            \"Train F1 Score\": trn_F1,\n            \"Valid F1 Score\": val_F1\n        })\n        if(val_roc_auc > best_roc_auc):\n            limit = 0\n            best_roc_auc = val_roc_auc\n            save_checkpoint(model, '.\/best_model.pth')\n        else:\n            limit += 1\n            if limit == 5:\n                break\n        if sched:\n            sched.step()\n        print(\"{}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\"\n              .format(j+1, trn_losses, val_losses, trn_roc_auc, val_roc_auc, trn_acc, val_acc))\n    wandb.run.summary[\"Best Roc Auc Score\"] = best_roc_auc","83e4ca67":"def get_model():\n    model = ResnetRS.create_pretrained('resnetrs50', in_ch=1, num_classes=2,\n                                       drop_rate=CFG['drop_rate'])\n    for param in model.parameters():\n        param.require_grad = True\n    model = model.to(device)\n    return model","decfd30a":"model = get_model() ","15534a5a":"save_checkpoint(model, '.\/init.pth')","a905ebb3":"weights = torch.tensor([0.9, 0.1]).to(device)\n\ncriterion = nn.CrossEntropyLoss(weights).to(device)","2cf16d02":"optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['base_lr'],\n                              weight_decay=CFG['weight_decay'])","36eff751":"sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, CFG['epochs'],\n                                                   eta_min=CFG['min_lr'])","a61da782":"ema = EMA(model.parameters(), decay_rate=0.995, num_updates=0)","3eae2e52":"train_stats = AvgStats()\ntest_stats = AvgStats()","0f9a9d3e":"run = wandb.init(project='Seti-ResNetRS', config=CFG,\n                 group = 'resnetrs', job_type='train',\n                 name = 'resnetrs50_ema_wandb')","3b75cfec":"wandb.watch(model)","3801fcc3":"print(f\"{'='*25} Fit {'='*25}\")\nfit(model, CFG['epochs'], optimizer, criterion, ema, device, wandb, sched=sched)","62c63772":"def plot(train_stats, test_stats):\n    nrows, ncols = 3, 2\n    fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize = (16, 10))\n\n    # Accuracy\n    ax[0, 0].plot(train_stats.acc, label='train')\n    ax[0, 0].plot(test_stats.acc, label='val')\n    ax[0, 0].set_title(\"Accuracy\")\n    ax[0, 0].legend(loc='upper left')\n\n    # Roc_Auc_Score\n    ax[0, 1].plot(train_stats.roc_auc, label='train')\n    ax[0, 1].plot(test_stats.roc_auc, label='val')\n    ax[0, 1].set_title(\"Roc Auc Score\")\n    ax[0, 1].legend(loc='upper left')\n\n    # Precision score\n    ax[1, 0].plot(train_stats.prec, label='train')\n    ax[1, 0].plot(test_stats.prec, label='val')\n    ax[1, 0].set_title(\"Precision Score\")\n    ax[1, 0].legend(loc='upper left')\n\n    # Recall score\n    ax[1, 1].plot(train_stats.rec, label='train')\n    ax[1, 1].plot(test_stats.rec, label='val')\n    ax[1, 1].set_title(\"Recall Score\")\n    ax[1, 1].legend(loc='upper left')\n\n    # F1 score\n    ax[2, 0].plot(train_stats.F1, label='train')\n    ax[2, 0].plot(test_stats.F1, label='val')\n    ax[2, 0].set_title(\"F1 Score\")\n    ax[2, 0].legend(loc='upper left')\n\n    # Loss\n    ax[2, 1].plot(train_stats.losses, label='train')\n    ax[2, 1].plot(test_stats.losses, label='val')\n    ax[2, 1].set_title(\"Losses\")\n    ax[2, 1].legend(loc='upper left')\n\n\n    plt.show()","c8aca5d0":"plot(train_stats, test_stats)","7826f16f":"load_checkpoint(model, '.\/best_model.pth')","b306978e":"def get_predicts(loader, model, device):\n    preds = list()\n    t = tqdm(loader, leave=False, total=len(loader))\n    with torch.no_grad():\n        model.eval()\n        for i, ip in enumerate(t):\n            ip = ip.to(device)\n            output = model(ip)\n            _, pred = output.max(dim=1)\n            pred = pred.cpu().detach().numpy()\n            preds.extend(list(pred))\n    return preds","b174a8cf":"preds = get_predicts(test_dl, model, device)","9886f2ca":"test_df['target'] = preds\ntest_df.drop(['img_path'], axis=1, inplace=True)\ntest_df.to_csv('submission.csv', index=False)","c32a9414":"run.finish()","17a741b0":"# Config","a22f13ab":"# Pytorch + resnetrs + wandb\n\nBasic pytorch resnetrs notebook\n\nCurrent parameters\n---------------------\n1) Augmentation:\n- Train:\n    - resize\n    - verticle flip\n    - horizontal flip\n    - tensorize\n    \n- Val\/ Test\n    - resize\n    - tensorize\n\n2) Model:\n- resnetrs50(pretrained) (https:\/\/github.com\/nachiket273\/pytorch_resnet_rs)\n- drop_rate = 0.1\n\n3) Other parameters:\n- image size = 320\n- base lr = 1e-4\n- minimum lr = 1e-7\n- batch size = 32\n- weight decay = 1e-3\n- optimizer = AdamW\n- loss = CrossEntropyLoss with class weights\n- schedular = CosineAnnealingLr\n\n4) Metrics:\n- roc auc score\n- F1 score\n- accuracy\n\n5) We use Exponential moving average of model parameters with decay rate of 0.995\n\n6) we use weights and biases to track the runs.","b6273e82":"# Train data","49ce97fa":"# Model and Training","714bc4c1":"### Show Cadence ","f971fe9e":"## Fit and wandb tracking","84af548a":"# Custom Dataset","f8a2aa61":"## Criterion, optimizer and scheduler","ce03cc8b":"# Load Data","cd38bc9c":"# Seed","9644a8e2":"### Test Data ","71acc073":"# Load Best saved parameters","be6a6f38":"### Training Data: Target = 1","9a7c323f":"# Train and Test","411f1ede":"### Training Data: Target = 0","4fa446d6":"# Helper Functions","4c40b256":"# Predict","4cfefe12":"Using my implementation of resnetrs.<br>\nThe repository is available @ https:\/\/github.com\/nachiket273\/pytorch_resnet_rs<br>","ff49f5bb":"### Datasets and Dataloader"}}