{"cell_type":{"3a7c13c7":"code","15850f75":"code","b123a472":"code","56d71a98":"code","b4baa309":"code","7893f71f":"code","434285e1":"code","bd5fa74f":"code","f464f1de":"code","494e496a":"code","97dea026":"code","bf159441":"code","c7770f33":"code","ab03af46":"code","d6232f0b":"code","f2a4e026":"code","a14e13e9":"code","0df66af1":"code","b250afc9":"code","f29a4bca":"code","7e1544e9":"code","1459b17f":"markdown","52e5fcaf":"markdown","14d58a8b":"markdown","1a585365":"markdown","5fbd97eb":"markdown","a190d1c3":"markdown","1db121df":"markdown","c60bd976":"markdown","6d8588c9":"markdown","ce5e7936":"markdown","b4447fe0":"markdown","f4ebbc33":"markdown","03526e55":"markdown","d54354aa":"markdown","448f896a":"markdown","c57ab6f9":"markdown","1e950066":"markdown","d8b46bf9":"markdown","9f9d5f54":"markdown","5f10d77d":"markdown","7e0647a5":"markdown","6ed12aa2":"markdown","95e7315a":"markdown","f3583927":"markdown","bb62d6fd":"markdown","5737df25":"markdown","406f41d7":"markdown","ff30ecc4":"markdown","603c7dbd":"markdown","25057732":"markdown","2317f8be":"markdown"},"source":{"3a7c13c7":"!pip install -U tensorflow==2.4\n\n!pip install cloud-tpu-client\nimport tensorflow as tf \nfrom cloud_tpu_client import Client\nprint(tf.__version__)\nClient().configure_tpu_version(tf.__version__, restart_type='ifNeeded')\n\n#!pip install efficientnet\n\nprint(tf.__version__)","15850f75":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OneHotEncoder","b123a472":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\n\n#Seperating features from label\nX = train_df.copy()\ny = X.pop('label')\n\ntrain_df.head()","56d71a98":"mlb = OneHotEncoder()\ny_d = mlb.fit_transform(y.to_frame().values)\ny_df = pd.DataFrame.sparse.from_spmatrix(y_d)","b4baa309":"from keras.layers import LeakyReLU\n    \n#Kernel regularizer has a weight of 0 so it's not being used, did not give good results\nclass ResModule(keras.layers.Layer):\n    def __init__(self, input_dim, bottleneck_size):\n        super(ResModule, self).__init__()\n        self.input_dim = input_dim\n        self.bottleneck_size = bottleneck_size\n        self.conv1_height = layers.Conv2D(self.input_dim, kernel_size=(1, 3), kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.conv1_width = layers.Conv2D(self.input_dim, kernel_size=(3, 1), kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.conv2_height = layers.Conv2D(self.input_dim, kernel_size=(1, 3), kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.conv2_width = layers.Conv2D(self.input_dim, kernel_size=(3, 1), kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n\n        self.bottleneck1 = layers.Conv2D(self.bottleneck_size, kernel_size=1, kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.bottleneck2 = layers.Conv2D(self.bottleneck_size, kernel_size=1, kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.bottleneck3 = layers.Conv2D(self.bottleneck_size, kernel_size=1, kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n        self.bottleneck4 = layers.Conv2D(self.bottleneck_size, kernel_size=1, kernel_regularizer=tf.keras.regularizers.L1L2(.0), padding=\"same\", activation=LeakyReLU())\n\n        self.norm1 = layers.BatchNormalization()\n        self.norm2 = layers.BatchNormalization()\n        self.norm3 = layers.BatchNormalization()\n        self.norm4 = layers.BatchNormalization()\n        self.norm5 = layers.BatchNormalization()\n        self.norm6 = layers.BatchNormalization()\n        self.norm7 = layers.BatchNormalization()\n        self.norm8 = layers.BatchNormalization()\n        self.norm9 = layers.BatchNormalization()\n        self.norm10 = layers.BatchNormalization()\n        self.norm11 = layers.BatchNormalization()\n        \n        self.dropout1 = layers.Dropout(.1)\n        self.dropout2 = layers.Dropout(.1)\n        self.dropout3 = layers.Dropout(.1)\n        self.dropout4 = layers.Dropout(.1)\n        self.dropout5 = layers.Dropout(.1)\n        self.dropout6 = layers.Dropout(.1)\n        self.dropout7 = layers.Dropout(.1)\n        self.dropout8 = layers.Dropout(.1)\n        \n\n    def call(self, inputs):\n        x = self.bottleneck1(inputs)\n        x = self.norm1(x)\n        x = self.dropout1(x)\n        \n        x = self.conv1_height(x)\n        x = self.norm2(x)\n        x = self.dropout2(x)\n        \n        x = self.bottleneck2(x)\n        x = self.norm3(x)\n        x = self.dropout3(x)\n        \n        x = self.conv1_width(x)\n        x = self.norm4(x)\n        x = self.dropout4(x)\n        \n\n        xMiddle = layers.add([inputs, x])\n        xMiddle = self.norm5(xMiddle)\n        \n        x = self.bottleneck3(xMiddle)\n        x = self.norm6(x)\n        x = self.dropout5(x)\n        \n        x = self.conv2_height(x)\n        x = self.norm7(x)\n        x = self.dropout6(x)\n        \n        x = self.bottleneck4(x)\n        x = self.norm8(x)\n        x = self.dropout7(x)\n        \n        x = self.conv2_width(x)\n        x = self.norm9(x)\n        x = self.dropout8(x)\n\n        x = layers.add([xMiddle, x])\n        x = self.norm10(x)\n        \n        x = layers.add([inputs, x])\n        x = self.norm11(x)\n        \n        return x\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'bottleneck_size': self.bottleneck_size,\n            'input_dim': self.input_dim\n        })\n        return config\n","7893f71f":"cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n    tpu=os.environ[\"TPU_NAME\"])\ntf.config.experimental_connect_to_cluster(cluster_resolver)\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\ntpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)","434285e1":"input_shape = [28, 28, 1]\nunit_size = 1024\nbottleneck_size = 64\n\nwith tpu_strategy.scope():\n    model = keras.Sequential([\n        \n        #tf.keras.layers.experimental.preprocessing.Rescaling(1\/127.5, offset=-1, input_shape=input_shape),\n        # rescales but not MEAN CENTERED! \n        # No longer using\n        \n        \n        # An outside convolution is applied before each new ResModule with a new Depth, to \n        # ensure depth is equal throughout the module\n        layers.Conv2D(unit_size, kernel_regularizer=tf.keras.regularizers.L1L2(.0), input_shape=input_shape, kernel_size=(1, 3), padding=\"same\", activation=LeakyReLU()),\n        layers.BatchNormalization(),\n        layers.Dropout(.1),\n        \n    \n        ResModule(unit_size, bottleneck_size),\n        ResModule(unit_size, bottleneck_size),\n    \n        layers.MaxPooling2D(2),\n    \n        layers.Conv2D(unit_size*2, kernel_regularizer=tf.keras.regularizers.L1L2(.0), kernel_size=(1, 3), padding=\"same\", activation=LeakyReLU()),\n        layers.BatchNormalization(),\n        layers.Dropout(.1),\n        ResModule(unit_size*2, bottleneck_size),\n        ResModule(unit_size*2, bottleneck_size),\n    \n        layers.MaxPooling2D(2),\n    \n        ResModule(unit_size*2, bottleneck_size),\n        ResModule(unit_size*2, bottleneck_size),\n    \n        layers.MaxPooling2D(2),\n    \n        layers.Conv2D(unit_size*4, kernel_regularizer=tf.keras.regularizers.L1L2(.0), kernel_size=(1, 3), padding=\"same\", activation=LeakyReLU()),\n        layers.BatchNormalization(),\n        layers.Dropout(.1),\n        ResModule(unit_size*4, bottleneck_size*2),\n        ResModule(unit_size*4, bottleneck_size*2),\n        \n        layers.Conv2D(unit_size*8, kernel_regularizer=tf.keras.regularizers.L1L2(.0), kernel_size=(1, 3), padding=\"same\", activation=LeakyReLU()),\n        layers.BatchNormalization(),\n        layers.Dropout(.1),\n        ResModule(unit_size*8, bottleneck_size*4),\n        ResModule(unit_size*8, bottleneck_size*4),\n    \n        layers.MaxPooling2D(2),\n              \n        layers.Dense(units=unit_size*16, activation=LeakyReLU(), kernel_regularizer=tf.keras.regularizers.L1L2(.0)),\n        layers.BatchNormalization(),\n        layers.Dropout(.3),\n        \n        layers.Dense(10) #USING LOGITS\n    ])\n    \n    #Removed: kernel_regularizer=tf.keras.regularizers.L1L2(.001)","bd5fa74f":"model.summary()","f464f1de":"#Need to pass in the custom objects to work!\nif os.path.isdir('.\/mymodel'):\n    model = keras.models.load_model(\".\/mymodel.h5\", custom_objects={'LeakyReLU': layers.LeakyReLU, 'ResModule':ResModule})","494e496a":"X_train_tensor = np.reshape(X.values, (-1, 28, 28, 1))\nY_train_tensor = np.reshape(y_df.values, (-1, 1, 1, 10))\nX_train_tensor = tf.dtypes.cast(X_train_tensor, tf.float64)\nY_train_tensor = tf.dtypes.cast(Y_train_tensor, tf.float64)\n                     \n\ndef train_input_fn(x, y, batch_size=512):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    \n    dataset = dataset.cache()\n    dataset = dataset.shuffle(42000)#, reshuffle_each_iteration=True)\n    \n    #Take 20% to the validation set\n    validation_set = dataset.take(tf.cast(X_train_tensor.shape[0]*.2, tf.int64))\n    dataset = dataset.skip(tf.cast(X_train_tensor.shape[0]*.2, tf.int64))\n    \n    dataset = dataset.repeat()\n    dataset = dataset.batch(batch_size)\n    \n    validation_set = validation_set.repeat()\n    validation_set = validation_set.batch(batch_size)\n    \n    \n    return dataset, validation_set\n    \nbig_dataset, val_dataset = train_input_fn(X_train_tensor, Y_train_tensor)","97dea026":"data_augmentation = keras.Sequential(\n    [\n        # I don't think flipping is unlikely\n        #layers.experimental.preprocessing.RandomFlip(\"horizontal\"), Unlikely numbers would be flipped\n        #layers.experimental.preprocessing.RandomFlip(\"vertical\"), Unlikely upside down number\n        layers.experimental.preprocessing.RandomRotation(factor=0.1),\n        \n        #upper and lower bounds\n        #Zoomed out\n        layers.experimental.preprocessing.RandomZoom(\n            height_factor=(.1, .3), width_factor=(.1, .3)\n        ),\n        #Zoomed In\n        layers.experimental.preprocessing.RandomZoom(\n            height_factor=(-.3, -.1), width_factor=(-.3, -.1)\n        ),\n        layers.experimental.preprocessing.RandomTranslation(\n            height_factor=(-.2, .2), width_factor=(-.2, .2)\n        )\n    ],\n    name=\"data_augmentation\"\n)","bf159441":"data_normalization = keras.Sequential(\n    [\n        layers.experimental.preprocessing.Normalization(input_shape=input_shape)\n    ],\n    name=\"data_normalization\"\n)","c7770f33":"# Apply to the training and validation datasets\naug_ds = big_dataset.map(\n  lambda x, y: (data_augmentation(x, training=True), y))\naug_ds = aug_ds.map(\n  lambda x, y: (data_normalization(x, training=True), y))\n\naug_valid_ds = val_dataset.map(\n  lambda x, y: (data_augmentation(x, training=False), y))\naug_valid_ds = aug_valid_ds.map(\n  lambda x, y: (data_normalization(x, training=False), y))","ab03af46":"model.compile(\n    optimizer=keras.optimizers.SGD(learning_rate=0.1),\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), #'categorical_crossentropy' #normal categorical is for one-hot\n    steps_per_execution=64,\n    metrics=['accuracy']\n)","d6232f0b":"#This is what was recommended for batch size but I ignored it:\n#BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n\ndef scheduler(epoch, lr):\n    if epoch < 3:  #10 before!\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\n    \n    \nhistory = model.fit(\n    aug_ds,\n    validation_data=aug_valid_ds,\n    steps_per_epoch = 2048,\n    validation_steps = 256,\n    validation_freq = 2,\n    epochs=30,\n    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler), ]\n)","f2a4e026":"#My Notes:\n\n#l1 punishes insignificant weights\n#l2 punishes weights that are too high\n\n#Regularization Weights:\n#For convolution, these values should be more lower (.001, dropout=.5)\n#For FC (.1) also dropout\n\n\n#Recent Changes: \n#smaller batch size, \n#learning rate scheduler, \n#smaller learning rate, & SGD!!!\n#steps per execution","a14e13e9":"model.save('mymodel64.h5', save_format='h5')","0df66af1":"test_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","b250afc9":"predictions = model.predict(\n    data_normalization(\n        np.reshape(test_df.values, (-1, 28, 28, 1)\n    ), training=False)\n)","f29a4bca":"predictions.shape","7e1544e9":"str_csv = \"ImageId,Label\\n\"\nimage_id = 1\nfor p in predictions:\n    str_csv = str_csv + \"{},{}\\n\".format(image_id, np.argmax(p[0][0]))\n    image_id += 1\n    \nwith open('submission.csv', \"w\") as fh:\n    fh.write(str_csv)","1459b17f":"> Note: For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required. (Taken from tensorflow website)","52e5fcaf":"> Note: To run this you'll need to set the accelerator to tpu","14d58a8b":"Why use augmentation?\n\nI believed my training set might be missing some images the test set may have, so these augmentations will mess up the training set to prepare my model for the upcoming test set.\n\n\nI used these augmentations:\n1. Rotated Digits\n2. Zooming Out on Digits\n3. Zooming In on Digits (the negative width and height factor)\n4. Shifting Image in any direction","1a585365":"### Load the model","5fbd97eb":"The label \"0-9\" is a number but we don't want our model to consider it as an ordinal value but like a categorical value. So we'll use one hot encoding on our labels.","a190d1c3":"## Saving the Model:","1db121df":"#### I'll try to include everything I learned as well as good practices I found","c60bd976":"When training models on the tpu you should apply these to your tf dataset:\n1. Cache\n2. Shuffle\n3. Repeat (For most cases)\n4. Batch ","6d8588c9":"### Quick One Hot Encoding","ce5e7936":"## Create Predictions:","b4447fe0":"![image.png](attachment:image.png)\n\nImage from here: https:\/\/towardsdatascience.com\/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec","f4ebbc33":"### Compile the model","03526e55":"#### Note: ONLY IF YOU PREVIOUSLY SAVED THE MODEL","d54354aa":"### Data Augmentation","448f896a":"This will apply the loss and optimizer for our model.\n\nI found better results using SGD with a learning rate scheduler rather than an adaptive optimizer like adam. I've read that it's because the former generalizes better.","c57ab6f9":"### Keras Subclassing, Residual Module","1e950066":"A lot of these tips I learned from the Stanford Course CSE 231n.\n\nHere is a good link to lecture 2: https:\/\/www.youtube.com\/watch?v=8inugqHkfvE&ab_channel=AndrejKarpathy","d8b46bf9":"## Goal: Make Residual Network For Digit Recognizer Competition","9f9d5f54":"### Data Normalization","5f10d77d":"Why use normalization?\n\nTwo reasons:\n1. The model will have trouble learning if values have a very high scalar value or a low scalar value.\n2. The model learns faster when it's normalized from -1 to 1 (balances along positive and negative sides).\n\nA mistake I made previously was to use batch normalization instead of normalization all my data. It's bad because the same data will change depending on the batch it's with and that doesn't make sense because the image hasn't changed. So I removed this because it was confusing my model.","7e0647a5":"Now you can look at the model for a more detailed look:","6ed12aa2":"### And Now to Train the Model","95e7315a":"#### The default kaggle environment didn't have tensorflow 2.4 installed which you need to have this: *tf.distribute.TPUStrategy*","f3583927":"### Retrieve training set","bb62d6fd":"### Import packages","5737df25":"Here is the residual module. \n\nExplanation: The idea behind skip connections is that you add the current layer with it's previous layer. When you go back and do backpropgation the previous layers receive the same updates as the later layer. This is good because as more layers get added to the top of a neural network (it starts on the bottom) the bottom layers receive less updates. \n\nA downside to this method is that you can't downsample the image until you add the layers together","406f41d7":"### Update Tensorflow Version on Kaggle","ff30ecc4":"### Creating the Tensorflow Dataset","603c7dbd":"### In this notebook, I wanted to do the following:\n1. Create a neural network that used a ResNet's residuals\/skip connections idea\n2. Employ the best practices when designing the model\n3. Train the model on a tpu\n4. Increase the complexity of the dataset with data augmentation","25057732":"Now here is a list of good practices I used:\n\n1. **Bottlenecking:** A technique to reduce depth. When two layers with a large depth size are next to each other the model gets huge. Instead introduce an intermediate layer with smaller depth. This intermediate layer should be a 1x1 convolutional layer. I believe this was used by the Google Inception model.\n\n\n2. **Batchnorm after Activation:** Normalize values after non linear activation so during backprop they don't get too high (exploding gradient, goes to infinity\/nan) or too low (vanishing gradient, model barely updates). I have seen case where people do activation first then batchnorm afterwards, I'm not entirely sure which is better.\n\n\n3. **Dropout:** To prevent the model's from adapting to each other (bad if one neuron is reliant on another) Two tips I read: Apply after batch normalization and use .1 for convolution layers, .3-.5 for Dense layers.\n\n\n4. **Splitting kernels:** Instead of having one convolutional layer with a 3x3 kernel instead have two layers with 3x1 and 1x3. The latter has less learnable parameters (9 vs 6) and this helps the model train faster but still learn information from the same 3x3 area of the image.\n\n\n5. **Small Kernels:** Instead of having one big 28x28 kernel in one convolutional layer, we instead break it down for each subsequent layer. This has less learnable parameters and if we have enough layers it will have the same effect. The first layer will learn lines, the second can learn curves, the third can learn shapes, until finally the last layer will learn digit shapes.\n\n\n6. **Decrease Width\/Height, Increase Depth:** As the network goes deeper, we'll need to downsample to get closer to our output shape (one hot encoding of the digit, [28, 28, 1] into [1, 1, 10]). Now that the image gets smaller we can increase the depth with cost in terms of extra training time.\n\n\n7. **No Flatten Layers:** Keras has a flatten layer where you take the width and height dimension and flatten them to one dimension. They do this to use a Fully Connected layer at the end, which can't take values with a width or height > 1. But if you flatten, the model will likely lose the ability to seperate the x and y dimensions. For images this is important so flattening is generally a bad idea. The work around is to downsample enough times with convolution and pooling so that you end up with a 1x1 feature map (with a large depth) and then you can send it to a Dense layer.\n\n\n8. **Use Depths to the Power of 2:** I heard there was some keras speedups that happens if you do this because of matrices. I don't know if it's true but I consider it a good practice.\n\n\n9. **Using Same Padding for Convolutions:** The idea of padding is to zero pad an input before convolution so the input size is the same as the output size (for that layer). It was used by the VGG model.\n\n\n10. **Almost Always Use LeakyRelu:** Activations generally have two problems. Their values are bounded or they are not evenly distributed along the positive and negative sides (For more information check out the course below). Relu is a good solution to the first but not the second because of the dying relu problem. LeakyRelu fixes this, it doesn't just zero out negative values but instead scales them down.","2317f8be":"> Note: I defined the tpu_strategy here and created the model under it's scope, now when I train the model it'll go on the tpu."}}