{"cell_type":{"47522d49":"code","3e43a56d":"code","6474f226":"code","a7ef386b":"code","5a69bf69":"code","3385951d":"code","f762a5e8":"code","649ec46e":"code","7e5efa74":"code","2c50edf2":"code","a6057cb3":"code","dba22502":"code","6b0e2662":"code","9e047986":"code","03fb5e3d":"code","f9d82106":"code","4b58e111":"code","1ba3eb42":"code","76316e7b":"markdown","15f30036":"markdown","7ff3d8e9":"markdown","7cbc7221":"markdown","3e28b3f9":"markdown","96fe2f1c":"markdown","71abf88a":"markdown","6c3a0b2f":"markdown","5067264c":"markdown","256a604a":"markdown","b0d0d6f8":"markdown","341849b1":"markdown","5af70e3d":"markdown","94fa0504":"markdown","ec87b70f":"markdown","5a90094e":"markdown","78f73a0e":"markdown","c91579a9":"markdown","3aede9a2":"markdown","addd89b1":"markdown","158f24c8":"markdown","9b8f63c0":"markdown","b8fc7cdd":"markdown","32ae5546":"markdown","67448e1c":"markdown","18344395":"markdown","44eb7c8a":"markdown","bdb70622":"markdown","ee17a8c4":"markdown","930cef52":"markdown","a47a0e25":"markdown","80806a75":"markdown","7cf50698":"markdown","24b3e31e":"markdown","dfe95d8e":"markdown","59a00242":"markdown"},"source":{"47522d49":"# Install Pycocotools\n!pip install 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n# Install detectron 2\n!python -m pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu102\/torch1.7\/index.html","3e43a56d":"%matplotlib inline\nfrom pycocotools.coco import COCO\nimport numpy as np\nimport skimage.io as io\nimport matplotlib.pyplot as plt\nimport pylab\nimport random\npylab.rcParams['figure.figsize'] = (8.0, 10.0)# Import Libraries\n\n# For visualization\nimport os\nimport seaborn as sns\nfrom matplotlib import colors\nfrom tensorboard.backend.event_processing import event_accumulator as ea\nfrom PIL import Image\n\n# Scipy for calculating distance\nfrom scipy.spatial import distance","6474f226":"# I am visualizing some images in the 'val\/' directory\n\ndataDir='..\/input\/coco-car-damage-detection-dataset\/val'\ndataType='COCO_val_annos'\nmul_dataType='COCO_mul_val_annos'\nannFile='{}\/{}.json'.format(dataDir,dataType)\nmul_annFile='{}\/{}.json'.format(dataDir,mul_dataType)\nimg_dir = \"..\/input\/coco-car-damage-detection-dataset\/img\"","a7ef386b":"# initialize coco api for instance annotations\ncoco=COCO(annFile)\nmul_coco=COCO(mul_annFile)","5a69bf69":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","3385951d":"assert torch.__version__.startswith(\"1.7\")","f762a5e8":"import detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\nimport skimage.io as io\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Set base params\nplt.rcParams[\"figure.figsize\"] = [16,9]","649ec46e":"# To find out inconsistent CUDA versions, if there is no \"failed\" word in this output then things are fine.\n!python -m detectron2.utils.collect_env","7e5efa74":"\ndataset_dir = \"..\/input\/coco-car-damage-detection-dataset\"\nimg_dir = \"img\/\"\ntrain_dir = \"train\/\"\nval_dir = \"val\/\"","2c50edf2":"from detectron2.data.datasets import register_coco_instances\nregister_coco_instances(\"car_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_val_annos.json\"), os.path.join(dataset_dir,img_dir))\nregister_coco_instances(\"car_mul_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_mul_val_annos.json\"), os.path.join(dataset_dir,img_dir))","a6057cb3":"#get configuration\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (damage) + 1\ncfg.MODEL.RETINANET.NUM_CLASSES = 2 # only has one class (damage) + 1\ncfg.MODEL.WEIGHTS = os.path.join(\"..\/input\/coco-damage-detection-trained-models\/damage_segmentation_model.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \ncfg['MODEL']['DEVICE']='cuda'#or cpu\ndamage_predictor = DefaultPredictor(cfg)","dba22502":"cfg_mul = get_cfg()\ncfg_mul.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg_mul.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\ncfg_mul.MODEL.RETINANET.NUM_CLASSES = 6 # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\ncfg_mul.MODEL.WEIGHTS = os.path.join(\"..\/input\/coco-damage-detection-trained-models\/part_segmentation_model.pth\")\ncfg_mul.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \ncfg_mul['MODEL']['DEVICE']='cuda' #or cpu\npart_predictor = DefaultPredictor(cfg_mul)","6b0e2662":"def detect_damage_part(damage_dict, parts_dict):\n  \"\"\"\n  Returns the most plausible damaged part for the list of damages by checking the distance \n  between centers centers of damage_polygons and parts_polygons\n\n  Parameters\n  -------------\n   damage_dict: dict\n                Dictionary that maps damages to damage polygon centers.\n   parts_dict: dict\n                Dictionary that maps part labels to parts polygon centers.\n  Return\n  ----------\n  part_name: str\n            The most plausible damaged part name.\n  \"\"\"\n  try:\n    max_distance = 10e9\n    assert len(damage_dict)>0, \"AssertError: damage_dict should have atleast one damage\"\n    assert len(parts_dict)>0, \"AssertError: parts_dict should have atleast one part\"\n    max_distance_dict = dict(zip(damage_dict.keys(),[max_distance]*len(damage_dict)))\n    part_name = dict(zip(damage_dict.keys(),['']*len(damage_dict)))\n\n    for y in parts_dict.keys():\n        for x in damage_dict.keys():\n          dis = distance.euclidean(damage_dict[x], parts_dict[y])\n          if dis < max_distance_dict[x]:\n            part_name[x] = y.rsplit('_',1)[0]\n\n    return list(set(part_name.values()))\n  except Exception as e:\n    print(e)","9e047986":"\ndamage_class_map= {0:'damage'}\nparts_class_map={0:'headlamp',1:'rear_bumper', 2:'door', 3:'hood', 4: 'front_bumper'}","03fb5e3d":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(16,12))\nim = io.imread(\"..\/input\/coco-car-damage-detection-dataset\/val\/32.jpg\")\n\n#damage inference\ndamage_outputs = damage_predictor(im)\ndamage_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\ndamage_out = damage_v.draw_instance_predictions(damage_outputs[\"instances\"].to(\"cpu\"))\n\n#part inference\nparts_outputs = part_predictor(im)\nparts_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_mul_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\nparts_out = parts_v.draw_instance_predictions(parts_outputs[\"instances\"].to(\"cpu\"))\n\n#plot\nax1.imshow(damage_out.get_image()[:, :, ::-1],)\nax2.imshow(parts_out.get_image()[:, :, ::-1])","f9d82106":"damage_prediction_classes = [ damage_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(damage_outputs[\"instances\"].pred_classes.tolist())]\ndamage_polygon_centers = damage_outputs[\"instances\"].pred_boxes.get_centers().tolist()\ndamage_dict = dict(zip(damage_prediction_classes,damage_polygon_centers))","4b58e111":"\nparts_prediction_classes = [ parts_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(parts_outputs[\"instances\"].pred_classes.tolist())]\nparts_polygon_centers =  parts_outputs[\"instances\"].pred_boxes.get_centers().tolist()\n\n\n\n#Remove centers which lie in beyond 800 units\nparts_polygon_centers_filtered = list(filter(lambda x: x[0] < 800 and x[1] < 800, parts_polygon_centers))\nparts_dict = dict(zip(parts_prediction_classes,parts_polygon_centers_filtered))","1ba3eb42":"print(\"Damaged Parts: \",detect_damage_part(damage_dict,parts_dict))","76316e7b":"#### I will load two pretained models:\n\n* Damage Segmentation model weights -  This can be easily created using this notebook [\nDetectron2 Car Damage Detection](https:\/\/www.kaggle.com\/lplenka\/detectron2-car-damage-detection). The model is stored in default output directory.\n\n* Parts Segmentation Model weights - This can be also created just changing the dataset from damage annotions to parts annotation in [cell 22](https:\/\/www.kaggle.com\/lplenka\/detectron2-car-damage-detection?scriptVersionId=52171508&cellId=37)\n","15f30036":"# <center><img src=\"https:\/\/raw.githubusercontent.com\/facebookresearch\/detectron2\/master\/.github\/Detectron2-Logo-Horz.svg\"><center\/>","7ff3d8e9":"### Do give this notebook an upvote if you liked my work, thanks!","7cbc7221":"For now allowing multiple polygons of same class label","3e28b3f9":"#### Register Train Dataset, so that we can use its Metadata","96fe2f1c":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Create damage polygons <\/center><\/h2>","71abf88a":"<h2><center> <a href=\"https:\/\/github.com\/facebookresearch\/detectron2\">Detectron2<\/a> is a PyTorch based modular object detection library<\/center><\/h2>\n\n<h4 style=\"text-align: right, line-height: 3.5em;\"> Detectron 2 is a next-generation open-source object detection system from Facebook AI Research. It can be used to train various state-of-the-art models like <a href=\"http:\/\/densepose.org\/\">Densepose <\/a> and <a href=\"https:\/\/ai.facebook.com\/blog\/improving-scene-understanding-through-panoptic-segmentation\/\">panoptic feature pyramid networks<\/a> for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection. With a modular design, Detectron2 is flexible and extensible, and able to provide fast training on single or multiple GPU servers. <\/h4>\n    \n    \n<h4> I hope that releasing Detectron2 will continue to accelerate progress in the area of object detection and segmentation. This Kernel is my attempt of contributing to the progress. <\/h4>   ","6c3a0b2f":"I couldn't think of any way where we can train a image segmentation model that can directly detect the damaged parts. So I decided to build two image segmentation models. One model to segment the damages which returns the \"damage\" polygon(s). One model to segment the parts of the car which returns the \"parts\" polygon(s). \n\nI had two approaches on how to move forward after getting the output from two models:\n*  After getting the predicted bounding boxes (polygons) from two models then I can check which damage polygons lie inside which \"part\" polygon and can detect the damaged part. \n*  After getting the predicted bounding boxes (polygons) from two models then I can check how far the damage is from different parts and return the part nearest to a damage.\n\n\nNote: There should be some way to train a single model that does both the tasks, but it can be in next versions. Feel free to suggest new approaches and implement your own approach.\n\nIn this notebook I have implemented the second approach for now. I will add the first approach soon.","5067264c":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>  Register Car Damage Dataset <\/center><\/h3>","256a604a":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px' > Import Libraries required for training<\/center><\/h3>","b0d0d6f8":"The left image shows the damages and right image shows the parts, both of these can be plotted using this notebook [https:\/\/www.kaggle.com\/lplenka\/coco-data-visualization](https:\/\/www.kaggle.com\/lplenka\/coco-data-visualization)","341849b1":"* Model confuses between front and rear bumper.\n* Center of polygon was mostly different from center of bbox.","5af70e3d":"#### The challenge here is to detect that the **hood ** has damages and not other parts of car.","94fa0504":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Model Inference <\/center><\/h2>","ec87b70f":"\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Damage Detection Model <\/center><\/h2>","5a90094e":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Detecting Damaged Parts - Idea<\/center><\/h3>","78f73a0e":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Conclusion <\/center><\/h2>\n","c91579a9":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Problem Statement<\/center><\/h3>","3aede9a2":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Some insights from the performance of model <\/center><\/h2>","addd89b1":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Set constant variables<\/center><\/h3>","158f24c8":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Source Dataset<\/center><\/h3>","9b8f63c0":"**Since we will train two models, first for only damages and second for only parts, you can find annotation for both in the dataset I have published here. [Coco Car Damage Dataset](https:\/\/www.kaggle.com\/lplenka\/coco-car-damage-detection-dataset)**","b8fc7cdd":"\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Parts Segmentation Model <\/center><\/h2>","32ae5546":"For now allowing multiple polygons of same class label","67448e1c":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Create parts polygons <\/center><\/h2>","18344395":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; border:0' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Initialize the COCO API<\/center><\/h3>","44eb7c8a":"##### Since I have already shown the installation steps, here I will directly start with all installations","bdb70622":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Import Libraries<\/center><\/h3>","ee17a8c4":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white; ' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Load trained model <\/center><\/h2>","930cef52":"#### I have created another notebook [Detectron2 Car Damage Detection](https:\/\/www.kaggle.com\/lplenka\/detectron2-car-damage-detection) where I have shown step by step installation Dectectron 2 and other supporting libraries. There I have also shown how to use Detectron 2 for detecting damage in cars using Image Segmentation.","a47a0e25":"<a ><img src=\"https:\/\/i.ibb.co\/dP12V6R\/damages.jpg\" alt=\"damages\" border=\"0\"><\/a>\n<a ><img src=\"https:\/\/i.ibb.co\/0QhJGSd\/parts.jpg\" alt=\"parts\" border=\"0\"><\/a>","80806a75":"* There is definitely a lot of scope for improvement. But this notebook can be a good begining for other complex approaches.\n* Data augmentation and training on larger data can significantly improve the results.","7cf50698":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Installation<\/center><\/h3>","24b3e31e":"The ouput looks correct \ud83d\ude03","dfe95d8e":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'> Damaged Parts <\/center><\/h2>","59a00242":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; color:white;' role=\"tab\" aria-controls=\"home\"><center style='padding-top: 15px'>Let's begin!<\/center><\/h3>"}}