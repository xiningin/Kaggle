{"cell_type":{"38ce4167":"code","9b1bd4d1":"code","97e872a9":"code","28af85fb":"code","b5467593":"code","c07dee8e":"code","fba62731":"code","d60c47a0":"code","28d49f14":"code","e69019a1":"code","c47f5d93":"code","c6ef46a6":"code","1d4a4859":"code","7911dc43":"markdown","f912b1d7":"markdown","8507cfa3":"markdown","34b41d2b":"markdown","97c060e8":"markdown","28451767":"markdown","a123b9d5":"markdown","e2bc0b9d":"markdown"},"source":{"38ce4167":"import os\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9b1bd4d1":"BASE_DIR = '..\/input\/landmark-recognition-2020'","97e872a9":"!ls {BASE_DIR}","28af85fb":"train_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'))\ntrain_df.head(10)","b5467593":"print(f'Total number of training images: {len(train_df)}')","c07dee8e":"print(f'Total number of landmarks in training dataset: {train_df[\"landmark_id\"].nunique()}')","fba62731":"target_dist = train_df.groupby('landmark_id', as_index=False)['id'].count().sort_values('id', ascending=False).reset_index(drop=True)\ntarget_dist = target_dist.rename(columns={'id':'count'})\ntarget_dist","d60c47a0":"sns.set(rc={'figure.figsize':(11,8)})\nsns.set(style=\"whitegrid\")","28d49f14":"ax = sns.distplot(train_df['landmark_id'].value_counts()[:50])\nax.set(xlabel='Landmark Counts', ylabel='Probability Density', title='Distribution of top 50 landmarks')\nplt.show()","e69019a1":"ax = sns.distplot(train_df['landmark_id'].value_counts()[51:])\nax.set(xlabel='Landmark Counts', ylabel='Probability Density')\nplt.show()","c47f5d93":"def get_image(image_id):\n    img = cv2.imread(os.path.join(os.path.join(BASE_DIR, 'train'), image_id[0], image_id[1], image_id[2], image_id + '.jpg'))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\ndef get_image_id(landmark_id):\n    return train_df[train_df['landmark_id'] == landmark_id]['id'][:1].values[0]","c6ef46a6":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(30, 15))\nax = ax.flatten()\nlandmark_ids = target_dist['landmark_id'][:6].values\n\nfor i in range(6):\n    ax[i].imshow(get_image(get_image_id(landmark_ids[i])))\n    ax[i].grid(False)\nplt.show()","1d4a4859":"fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(30, 15))\nax = ax.flatten()\nlandmark_ids = target_dist['landmark_id'][-6:].values\n\nfor i in range(6):\n    ax[i].imshow(get_image(get_image_id(landmark_ids[i])))\n    ax[i].grid(False)\nplt.show()","7911dc43":"Now let's plot the PDF of rest of the landmarks","f912b1d7":"There are some landmarks having only ~2 training images!","8507cfa3":"## Bottom 6 Landmarks (by count)","34b41d2b":"The distribution of labels is highly imbalanced. Let's first see the distribution of top 50 landmarks (which occurs the most)","97c060e8":"There are 81313 landmarks and 1580470 images, therefore only ~19 images per landmark (average) for training data. Let's see actual distribution of landmarks.","28451767":"## Distribution of Landmarks","a123b9d5":"## Top 6 Landmarks (by count)","e2bc0b9d":"There are ~1.58 million training images. That's huge!"}}