{"cell_type":{"38a26bfa":"code","4bfff4d2":"code","009c548c":"code","59b489d8":"code","15e7c034":"code","25ecc8d9":"code","7cfda8dd":"code","ac332dcd":"code","2cf85efe":"code","121d9ce5":"code","ef5db94c":"markdown","a5168861":"markdown","bfce1355":"markdown","1a885051":"markdown","0cf41d3d":"markdown","cac38f8e":"markdown","8f4b018c":"markdown","2f2456c5":"markdown","76565bd8":"markdown"},"source":{"38a26bfa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4bfff4d2":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D\nfrom tensorflow.keras.layers import Input, Dense\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport pandas as pd\nimport numpy as np\nimport os\nfrom numpy import argmax\n","009c548c":"PATH = \"\/kaggle\/input\/eye-disease-dataset\/Eye_diseases\"\ndata_dir_list = os.listdir(PATH)\ndata_dir_list","59b489d8":"img_rows=224\nimg_cols=224\nnum_channel=3\n\nnum_epoch = 50\nbatch_size = 32\n\nimg_data_list=[]\nclasses_names_list=[]\ntarget_column=[]\nfor dataset in data_dir_list:\n    classes_names_list.append(dataset)\n    print(\"Getting image from {} folder\".format(dataset))\n    img_list= os.listdir(PATH +\"\/\"+ dataset)\n    for img in img_list:\n        input_img = cv2.imread(PATH +\"\/\"+dataset+\"\/\"+img)\n        input_img_resize=cv2.resize(input_img,(img_rows,img_cols))\n        img_data_list.append(input_img_resize)\n        target_column.append(dataset)","15e7c034":"num_classes = len(classes_names_list)\nprint(\"num_classes\",num_classes)\nimg_data = np.array(img_data_list) # convert images in numpy array \nimg_data = img_data.astype('float32')\nimg_data \/= 255\nprint(\"Shape of image data\",img_data.shape)\nnum_of_samples = img_data.shape[0]\ninput_shape = img_data[0].shape \nprint(\"number of samples\",num_of_samples)\nprint(\"target column before encoding\",target_column)","25ecc8d9":"Labelencoder = LabelEncoder()\ntarget_column = Labelencoder.fit_transform(target_column)\nnp.unique(target_column)","7cfda8dd":"target_column","ac332dcd":"target_column_hotcoded = to_categorical(target_column,num_classes)\nX,Y = shuffle(img_data,target_column_hotcoded,random_state=2)\nX_train,X_temp,y_train,y_temp = train_test_split(X,Y,test_size=0.3,random_state=2)\nX_test,X_val,y_test,y_val = train_test_split(X_temp,y_temp,test_size=0.3,random_state=2)","2cf85efe":"first_Mod = Sequential()\n\nfirst_Mod.add(Conv2D(64,(3,3),activation='relu',input_shape=input_shape))\nfirst_Mod.add(Conv2D(64,(3,3),activation='relu'))\nfirst_Mod.add(MaxPool2D(pool_size=(2,2)))\nfirst_Mod.add(Dropout(0.2))\n\nfirst_Mod.add(Conv2D(128,(3,3),activation='relu'))\nfirst_Mod.add(Conv2D(128,(3,3),activation='relu'))\nfirst_Mod.add(MaxPool2D(pool_size=(2,2)))\nfirst_Mod.add(Dropout(0.2))\n\nfirst_Mod.add(Flatten())\nfirst_Mod.add(Dense(128,activation='relu'))\nfirst_Mod.add(Dropout(0.2))\nfirst_Mod.add(Dense(num_classes,activation='softmax'))\nfirst_Mod.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nfirst_Mod.summary()","121d9ce5":"hist = first_Mod.fit(X_train,y_train,batch_size=batch_size,epochs=num_epoch,verbose=1,validation_data=(X_test,y_test))\nscore = first_Mod.evaluate(X_test,y_test,batch_size=batch_size)\nprint('Test Loss',score[0])\nprint(\"Test Accuracy\",score[1])","ef5db94c":"Hi everyone,\n\nHere i have used Tensorflow keras CNN model in this kernal to predict 5 class label in dataset for eye disease classification.","a5168861":"Now here we'll prepare data to feed into the model. first read all the images from the dataset and resize it with specific size and prepare all the image data list for multiple folder with  target column.","bfce1355":"Now here read all the directories available in eye disease folder","1a885051":"Now fit the data in the model and evaluate the model accuracy and Loss.","0cf41d3d":"Create CNN Model to predict class label for eye disease","cac38f8e":"Now check the target column value after the encoding","8f4b018c":"Here encode the target column becuase we can't use string in model. so here we are using label encoder to encode target column.","2f2456c5":"Now lets split data with validation split equal to 30% from training data. Validation split is used to determine that our model is not geting over-fitted.","76565bd8":"First of all import all the necessary libraries "}}