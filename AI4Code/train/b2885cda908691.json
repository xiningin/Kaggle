{"cell_type":{"b34d6852":"code","92e8f939":"code","8ac55939":"code","574d6164":"code","3c519f79":"code","7f2cfa4d":"code","4ef6fde1":"code","78f88471":"code","d3756a38":"code","d9ea8678":"code","5821498e":"code","aa5bea0d":"code","4b91bd19":"code","271eb924":"markdown","bd4e44a2":"markdown","ffc8cbd7":"markdown"},"source":{"b34d6852":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92e8f939":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)","8ac55939":"train.head()","574d6164":"test.head()","3c519f79":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","7f2cfa4d":"# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split","4ef6fde1":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","78f88471":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","d3756a38":"# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","d9ea8678":"# Define the model \nmodel = RandomForestRegressor(random_state=0)\n\n# Train the model (will take about 10 minutes to run)\nmodel.fit(X_train, y_train)\npreds_valid = model.predict(X_valid)\nprint(mean_squared_error(y_valid, preds_valid, squared=False))","5821498e":"from xgboost import XGBRegressor\n\nmy_model = XGBRegressor()\nmy_model.fit(X_train, y_train)","aa5bea0d":"from sklearn.metrics import mean_absolute_error\n\npredictions = my_model.predict(X_valid)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","4b91bd19":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","271eb924":"training the model","bd4e44a2":"preparing the data","ffc8cbd7":"separating a validation from train set"}}