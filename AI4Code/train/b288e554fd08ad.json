{"cell_type":{"2c3ab3cc":"code","75b3a79c":"code","2728cb1b":"code","2610e805":"code","219405fa":"code","d0799340":"code","bd55b3da":"code","4e598cc8":"code","dc4115fd":"code","e9c207e1":"code","31aa73f0":"code","82cd9414":"code","3c4c7453":"code","b9e5ba2d":"code","3bfe8899":"code","e40e1372":"code","c47ce898":"code","c5c76829":"code","c01cc7dc":"code","642542f8":"code","05ba73f0":"code","b0793859":"markdown","a97fe25c":"markdown","048cb124":"markdown","85e7d76d":"markdown","763f6dc0":"markdown","2a07ff0e":"markdown","017889ef":"markdown"},"source":{"2c3ab3cc":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom functools import partial, wraps, reduce\nfrom tensorflow.keras.layers import (Conv2D, MaxPool2D, BatchNormalization, InputLayer, LeakyReLU, Dense, \nFlatten, Dropout, ReLU, SeparableConv2D, GlobalAveragePooling2D)\nfrom tensorflow.keras.regularizers import l2\n\ntf.__version__","75b3a79c":"# path and label file creation\n\npath_dict = {'val_normal':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/',\n            'val_pneumonia':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA',\n            'train_normal':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/',\n            'train_pneumonia':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/',\n            'test_normal':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/',\n            'test_pneumonia':'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'\n            }\n\ndata_paths = {}\n\nfor key, value in path_dict.items():\n\tpaths_list = []\n\tfor dirname, _, filenames in os.walk(value):\n\t\tfor filename in filenames:\n\t\t\tpaths_list.append(os.path.join(dirname, filename))\n\tdata_paths[key] = paths_list\n\nfor key in data_paths:\n    print(key,\" : \",len(data_paths[key]))\n\n\na = data_paths\nn = 'val_normal'\np = 'val_pneumonia'\n\nval_data = np.concatenate((\n    np.concatenate((a[n], a[p]), axis=0).reshape(-1, 1),\n    np.concatenate((\n        np.zeros(len(a[n])),\n        np.ones(len(a[p]))\n    ), axis=0).reshape(-1, 1)\n), axis=1)\n\nn = 'train_normal'\np = 'train_pneumonia'\n\ntrain_data = np.concatenate((\n    np.concatenate((a[n], a[p]), axis=0).reshape(-1, 1),\n    np.concatenate((\n        np.zeros(len(a[n])),\n        np.ones(len(a[p]))\n    ), axis=0).reshape(-1, 1)\n), axis=1)\n\nn = 'test_normal'\np = 'test_pneumonia'\n\ntest_data = np.concatenate((\n    np.concatenate((a[n], a[p]), axis=0).reshape(-1, 1),\n    np.concatenate((\n        np.zeros(len(a[n])),\n        np.ones(len(a[p]))\n    ), axis=0).reshape(-1, 1)\n), axis=1)\n\n\n# remove unwanted files\n\nremove_train = []\nremove_val = []\nremove_test = []\n\nfor index, i in enumerate(train_data[:,0]):\n    if (i.split('.')[1]) != 'jpeg':\n        print(i, index)\n        remove_train.append(index)\n\nfor index, i in enumerate(val_data[:,0]):\n    if (i.split('.')[1]) != 'jpeg':\n        print(i, index)\n        remove_val.append(index)\n\nfor index, i in enumerate(test_data[:,0]):\n    if (i.split('.')[1]) != 'jpeg':\n        print(i, index)\n        remove_test.append(index)\n\ntrain_data = np.delete(train_data, remove_train, axis=0)\nval_data = np.delete(val_data, remove_val, axis=0)\ntest_data = np.delete(test_data, remove_test, axis=0)","2728cb1b":"# adding more data to validation dataset from train\nnp.random.seed(10)\n\ndata = np.append(train_data, val_data, axis=0)\nnp.random.shuffle(data)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(data[:,0], data[:,1], test_size=0.10, random_state=42)\n\nprint('Data shape after split: ', X_train.shape, X_val.shape)\n\nunique_elements, counts_elements = np.unique(y_val, return_counts=True)\nprint('0 and 1 in val data :', counts_elements)\n\nunique_elements, counts_elements = np.unique(y_train, return_counts=True)\nprint('0 and 1 in train data :', counts_elements)","2610e805":"@tf.function()\ndef read_decode_resize_img(path, label):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    original = img\n    img = tf.image.random_flip_left_right(img)\n    if tf.random.uniform(()) > 0.67:\n        img = tf.image.random_contrast(img, 1, 2)\n    if tf.random.uniform(()) > 0.67:\n        tf.image.central_crop(img, 0.5)\n    if tf.random.uniform(()) > 0.67:\n        img = original\n    return tf.image.resize(img, [224, 224]), label","219405fa":"@tf.function()\ndef read_decode_resize_img_no_aug(path, label):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    return tf.image.resize(img, [224, 224]), label","d0799340":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds_original = tf.data.Dataset.from_tensor_slices(\n    (X_train, y_train.astype(float)))\n\ntrain_ds = (train_ds_original\n            .shuffle(len(X_train))\n            .map(read_decode_resize_img, num_parallel_calls=AUTOTUNE)\n            .batch(128)\n            .prefetch(buffer_size=AUTOTUNE)\n            .repeat(2))\n\n\nval_ds = tf.data.Dataset.from_tensor_slices(\n    (X_val, y_val.astype(float)))\n\nval_ds = (val_ds\n            .shuffle(len(X_val))\n            .map(read_decode_resize_img_no_aug, num_parallel_calls=AUTOTUNE)\n            .batch(128)\n            .prefetch(buffer_size=AUTOTUNE))\n\ntest_ds = tf.data.Dataset.from_tensor_slices(\n    (test_data[:, 0], test_data[:, 1].astype(float)))\n\ntest_ds = (test_ds\n            .shuffle(len(test_data))\n            .map(read_decode_resize_img_no_aug, num_parallel_calls=AUTOTUNE)\n            .batch(32)\n            .prefetch(buffer_size=AUTOTUNE))","bd55b3da":"import matplotlib.pyplot as plt\nimg_collection = next(iter(train_ds))\nplt.figure(figsize=(10,10))\nfor i in range(10):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(tf.squeeze(img_collection[0][i,:,:,:]), cmap='binary')\n    plt.xlabel(img_collection[1][i].numpy())\nplt.show()","4e598cc8":"# Init\n\ndef compose(*funcs):\n    if funcs:\n        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n    else:\n        raise ValueError('Composition of empty sequence not supported.')\n\n        \n_MeNetConv2D = partial(SeparableConv2D,\n                       kernel_size=3,\n                       strides=1,\n                       kernel_regularizer=l2(1e-3),\n                       bias_regularizer=l2(1e-3),\n                       padding='same')\n\n\n@wraps(SeparableConv2D)\ndef MeNetConv2D(*args, **kwargs):\n    return _MeNetConv2D(*args, **kwargs)\n\n\ndef MeNetConv2D_BN_Leaky(*args, **kwargs):\n    return compose(\n        MeNetConv2D(*args, **kwargs),\n        BatchNormalization(),\n         LeakyReLU(alpha=0.1))\n\n_MeNetDense = partial(Dense,\n                      activation='relu',\n                      kernel_regularizer=l2(1e-3)\n                      )\n\n\n@wraps(Dense)\ndef MeNetDense(*args, **kwargs):\n    return _MeNetDense(*args, **kwargs)\n\n\ndef MeNetDense_Dropout(*args, **kwargs):\n    return compose(\n        MeNetDense(*args, **kwargs),\n        Dropout(0.4)\n    )\n\n# model\n\ninputs = keras.Input(shape=(224, 224, 3))\n\nconv1 = MeNetConv2D_BN_Leaky(filters=8, name='conv1')(inputs)\nmaxpool1 = MaxPool2D(name='maxpool1')(conv1)\n\nconv2 = MeNetConv2D_BN_Leaky(filters=16, name='conv2')(maxpool1)\nmaxpool2 = MaxPool2D(name='maxpool2')(conv2)\n\nconv3 = MeNetConv2D_BN_Leaky(filters=32, name='conv3')(maxpool2)\nmaxpool3 = MaxPool2D(name='maxpool3')(conv3)\n\nconv4 = MeNetConv2D_BN_Leaky(filters=64, name='conv4')(maxpool3)\nmaxpool4 = MaxPool2D(name='maxpool4')(conv4)\n\nconv5 = MeNetConv2D_BN_Leaky(filters=128, name='conv5')(maxpool4)\nmaxpool5 = MaxPool2D(name='maxpool5')(conv5)\n\nconv6 = MeNetConv2D_BN_Leaky(filters=256, name='conv6')(maxpool5)\nmaxpool6 = MaxPool2D(name='maxpool6')(conv6)\n\nflatten = Flatten()(maxpool6)\ndropout = Dropout(0.3)(flatten)\ndense1 = MeNetDense_Dropout(512)(dropout)\ndense2 = MeNetDense_Dropout(128)(dense1)\noutputs = Dense(1)(dense2)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs, name='MeNet_Model')","dc4115fd":"model.summary()","e9c207e1":"class WeightedBinaryCrossEntropy(keras.losses.Loss):\n    \n    def __init__(self, neg_weight=1.25, from_logits=True,\n                 reduction=keras.losses.Reduction.AUTO,\n                 name='weighted_binary_crossentropy'):\n        super().__init__(reduction=reduction, name=name)\n        self.neg_weight = neg_weight\n        self.from_logits = from_logits\n    \n    @tf.function\n    def call(self, y_true, y_pred):\n        ce = tf.losses.binary_crossentropy(\n            y_true, y_pred, from_logits=self.from_logits)[:,None]\n        ce = ce*(y_true) + self.neg_weight*ce*(1-y_true)\n        return ce","31aa73f0":"model.compile(optimizer='adam',\n              loss=WeightedBinaryCrossEntropy(),\n              metrics=['accuracy'])","82cd9414":"def scheduler(epoch):\n  if epoch <= 25:\n    return 0.001\n  if epoch > 25:\n    return 0.0005\n\nlearning_rate_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n\n# pre_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n#                                            min_delta = 0.01, patience = 5, verbose = 1,mode = 'min',\n#                                            baseline = 0.09, restore_best_weights=False)","3c4c7453":"with tf.device('\/device:GPU:0'):\n    history = model.fit(train_ds,validation_data=val_ds, epochs=35,\n                       callbacks=[learning_rate_callback])","b9e5ba2d":"from matplotlib import pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","3bfe8899":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.grid()\nplt.show()","e40e1372":"model.evaluate(test_ds)","c47ce898":"X = []\ny = []\nfor val in test_ds:\n    X.append(val[0])\n    y.append(val[1])\n\nprint(len(X), len(y))","c5c76829":"recall = []\nprecision = []\nconfusion_matrix = []\n\nfor x, y_true in zip(X, y):\n    y_pred = tf.math.sigmoid(model.predict(tf.squeeze(x)))\n    y_pred = np.where(y_pred > 0.8, 1, 0)\n    y_true = y_true.numpy().reshape(-1,1)\n    \n    m = tf.metrics.Recall()\n    m.update_state(y_true, y_pred)\n    recall.append(m.result().numpy())\n\n    m = tf.metrics.Precision()\n    m.update_state(y_true, y_pred)\n    precision.append(m.result().numpy())\n    \n    m = tf.math.confusion_matrix(tf.squeeze(y_true), tf.squeeze(y_pred))\n    confusion_matrix.append(m)","c01cc7dc":"print('Recall :', np.mean(np.array(recall)),'Precision :', np.mean(np.array(precision)))\n\na = np.array(confusion_matrix)\nresult = np.zeros((2,2))\nfor i in range(20):\n    result += confusion_matrix[i]\n\nimport seaborn as sn\nclasses = ['Normal','Pneumonia']\nresult = result.numpy()\nf, ax = plt.subplots(figsize=(9, 6))\nsn.heatmap(result, annot=True, ax=ax, cmap='viridis',\n          xticklabels=classes, yticklabels=classes, fmt='d')\nax.set_ylim(len(result)-0.01, -0.01)","642542f8":"model.save('my_model') ","05ba73f0":"import shutil\nshutil.make_archive('model', 'zip', '\/kaggle\/working\/my_model')","b0793859":"**Total model parameters are 0.6 M, which enables fast training and faster prediction**","a97fe25c":"### Importing Libraries","048cb124":"Validation data is very small to find the best model. <br>\nAdding data to it from train","85e7d76d":"Using Weighted binary cross entropy loss, to penalize prediction of the \"normal\" as \"pneumonia\" <br>\nnegative weight is 1.25","763f6dc0":"Creating train, test and val dataset, with path and label. <br>\nImageFolder from Pytorch is the better way than the below, so i recommend you using it","2a07ff0e":"### Data preparation","017889ef":"Implementing a learning rate scheduler based on the epoch"}}