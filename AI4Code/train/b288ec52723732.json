{"cell_type":{"3275d420":"code","4d683ec5":"code","aa71b96f":"code","3ed5ccdf":"code","7a9374af":"code","62856161":"code","73bdd11c":"code","48628392":"code","bead5c6b":"code","48568b06":"code","6e8a4ec8":"code","faeadb49":"code","35e61ece":"code","81d2191d":"code","d6989886":"code","cf461900":"code","caa61bc1":"code","88d54ec5":"code","f9784f70":"code","dbb8fe73":"code","7f08cd0a":"code","bb046748":"code","b82a5dec":"code","01a3abbe":"code","b9c1092f":"code","47246f4a":"code","45b48e8a":"code","20806358":"code","90b983bb":"markdown","6522a801":"markdown","b9b6e32e":"markdown","ddcfe47c":"markdown","db3a750a":"markdown","fcf52aee":"markdown","b832fb1e":"markdown","0ad2b273":"markdown","db141cba":"markdown","e1fdacaa":"markdown","ba053b2c":"markdown","f254506c":"markdown","db9c48de":"markdown","c72a5e6c":"markdown","01345513":"markdown","6cdaa81b":"markdown","61f9b91c":"markdown","0547f558":"markdown","d77621ab":"markdown","88e62362":"markdown","804fc440":"markdown","a34a9404":"markdown","2c8126cc":"markdown","db933cbb":"markdown","0c4d1371":"markdown","16ba7960":"markdown","95161781":"markdown","fa1b34e0":"markdown","a650f3e9":"markdown","cbef420e":"markdown","0619927c":"markdown","1e05ac76":"markdown","63d0768c":"markdown","d33b8ff0":"markdown"},"source":{"3275d420":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\nsns.set_palette(\"pastel\")\nimport plotly.express as px\nfrom IPython.display import Image\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4d683ec5":"df = pd.read_csv(\"\/kaggle\/input\/hr-analytics-classification\/train_LZdllcl.csv\")\ntest_full = pd.read_csv(\"\/kaggle\/input\/hr-analytics-classification\/test_2umaH9m.csv\")\ndf.head()","aa71b96f":"len(df)","3ed5ccdf":"df.info()","7a9374af":"df = df.dropna()\nlen(df)","62856161":"df['previous_year_rating'] = df['previous_year_rating'].astype(np.int64)","73bdd11c":"promo = pd.DataFrame(df.is_promoted.value_counts())\npromo.columns = [\"Promoted\"]\npromo[\"Valores\"] = promo.index\npromo[\"Valores\"] = promo[\"Valores\"].map({0:\"No Promovido\", 1:\"Promovido\"})\nfig = px.pie(promo, values= \"Promoted\", names = \"Valores\", title = \"Empleados Promovidos\", color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=500)\nfig.show()","48628392":"depart = pd.DataFrame(df.department.value_counts())\ndepart.columns = [\"Valores\"]\ndepart[\"Departamentos\"] = depart.index\nfig = px.bar(depart, x = \"Departamentos\", y= \"Valores\", title = \"Cantidad de Empleados por Departamento\", color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(\n    autosize=False,\n    width=850,\n    height=650)\nfig.show()","bead5c6b":"depart = pd.DataFrame(df.groupby(\"is_promoted\").department.value_counts().reset_index(name='Valores'))\nfor i in range(0,9):\n    value = round(depart[depart[\"is_promoted\"] == 1].iloc[i,2] \/ depart[depart[\"is_promoted\"] == 0].iloc[i,2] * 100, 2)\n    nombre = depart.iloc[i,1]\n    print(f\"Porcentaje de Empleados Promovidos en Departamento \"+ str(nombre) + \": \" + str(value) + \"%\")\ndepart[\"is_promoted\"] = depart[\"is_promoted\"].map({0:\"No Promovido\", 1:\"Promovido\"})\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='department', y='Valores', data=depart, hue='is_promoted')\nplt.legend(title='Promoci\u00f3n', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlabel('Empleados Promovidos y no Promovidos por Departamento')\nplt.show()","48568b06":"region = pd.DataFrame(df.region.value_counts())\nregion.columns = [\"Regiones\"]\nregion[\"Valores\"] = region.index\nfig = px.pie(region, values= \"Regiones\", names = \"Valores\", title = \"Cantidad de Empleados por Regiones\",color_discrete_sequence=px.colors.qualitative.Set2)\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=500)\nfig.show()\nprint(\"Los empleados de la organizaci\u00f3n provienen de \" + str(df.region.nunique()) + \" regiones diferentes.\")","6e8a4ec8":"educ = pd.DataFrame(df.groupby(\"is_promoted\").education.value_counts().reset_index(name='Valores'))\nfor i in range(0,3):\n    value = round(educ[educ[\"is_promoted\"] == 1].iloc[i,2] \/ educ[educ[\"is_promoted\"] == 0].iloc[i,2] * 100, 2)\n    nombre = educ.iloc[i,1]\n    print(f\"Porcentaje de Empleados Promovidos en Departamento \"+ str(nombre) + \": \" + str(value) + \"%\")\n\neduc[\"is_promoted\"] = educ[\"is_promoted\"].map({0:\"No Promovido\", 1:\"Promovido\"})\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='education', y='Valores', data=educ, hue='is_promoted')\nplt.legend(title='Promoci\u00f3n', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlabel('Empleados Promovidos y no Promovidos por Departamento')\nplt.show()","faeadb49":"genero = pd.DataFrame(df.groupby(\"is_promoted\").gender.value_counts().reset_index(name='Valores'))\n\nplt.figure(figsize=(13, 8))\nsns.barplot(x='gender', y='Valores', data=genero, hue='is_promoted')\nplt.title(\"Empleados Promovidos y no Promovidos por G\u00e9nero\")\nplt.legend(title='Promovido', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlabel('G\u00e9nero')\nplt.show()","35e61ece":"canal = pd.DataFrame(df.groupby(\"is_promoted\").recruitment_channel.value_counts().reset_index(name='Valores'))\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='recruitment_channel', y='Valores', data=canal, hue='is_promoted')\nplt.title(\"Empleados Promovidos y no Promovidos por Canal de Reclutamiento\")\nplt.legend(title='Promovido', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlabel('Canal de Reclutamiento')\nplt.show()","81d2191d":"entrenamientos = pd.DataFrame(df.groupby(\"is_promoted\").no_of_trainings.value_counts().reset_index(name='Valores'))\npromo_entrenamientos = entrenamientos[entrenamientos[\"is_promoted\"]==1]\nplt.figure(figsize=(12, 8))\nsns.barplot(data=promo_entrenamientos, x=\"no_of_trainings\", y=\"Valores\")\nplt.title(\"Empleados Promovidos por Cantidad de Capacitaciones Previos\")\nplt.xlabel('Cantidad de Capacitaciones')","d6989886":"numericas = [\"age\", \"previous_year_rating\", \"length_of_service\",\"KPIs_met >80%\",\"awards_won?\",\"avg_training_score\"]\ndf[numericas].hist(figsize=(16,8),layout=(2,3), density=True)\nplt.show()","cf461900":"fig = px.histogram(df, x=\"age\", title = \"Distribuci\u00f3n de Edades de los Empleados\", color = \"is_promoted\", labels= {\"age\":\"Edad\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=650)\nfig.show()\nprint(\"La media de edad de los empleados es \" + str(round(np.mean(df.age),0)))\nprint(\"Le mediana de edad de los empleados es \" + str(np.median(df.age)))","caa61bc1":"fig = px.histogram(df, x=\"previous_year_rating\", title = \"Distribuci\u00f3n de Puntajes del A\u00f1o Previo de los Empleados\", color = \"is_promoted\", labels= {\"previous_year_rating\":\"Puntajes\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=650)\nfig.show()\nprint(\"La media de edad de los empleados no promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==0].previous_year_rating),2)))\nprint(\"La media de edad de los empleados promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==1].previous_year_rating),2)))","88d54ec5":"fig = px.histogram(df, x=\"length_of_service\", title = \"Distribuci\u00f3n de Cantidad de a\u00f1os de Servicio de los Empleados\", color = \"is_promoted\", labels= {\"length_of_service\":\"A\u00f1os de Servicio\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=650)\nfig.show()\nprint(\"La media de a\u00f1os de servicio de los empleados no promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==0].length_of_service),2)))\nprint(\"La media de a\u00f1os de servicio de los empleados promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==1].length_of_service),2)))","f9784f70":"fig = px.histogram(df, x=\"KPIs_met >80%\", title = \"Distribuci\u00f3n de Cantidad de Empleados que superaron el 80 de sus KPI\", color = \"is_promoted\", labels= {\"KPIs_met >80%\":\"KPI > 80\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=700,\n    height=650)\nfig.show()\n\nkpi_no = round(len(df[(df[\"is_promoted\"]==1) & (df[\"KPIs_met >80%\"] == 0)]) \/ len(df[df[\"KPIs_met >80%\"] == 0]) *100, 2)\nkpi_si = round(len(df[(df[\"is_promoted\"]==1) & (df[\"KPIs_met >80%\"] == 1)]) \/ len(df[df[\"KPIs_met >80%\"] == 1]) *100, 2)\n\nprint(\"El \" + str(kpi_no) + \"% de empleados que no super\u00f3 el 80% de sus KPI fue promovido\")\nprint(\"El \" + str(kpi_si) + \"% de empleados que s\u00ed super\u00f3 el 80% de sus KPI fue promovido\")","dbb8fe73":"fig = px.histogram(df, x=\"awards_won?\", title = \"Distribuci\u00f3n de Cantidad de Empleados por Premios Obtenidos\", color = \"is_promoted\", labels= {\"awards_won?\":\"Premios Obtenidos\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=700,\n    height=650)\nfig.show()\n\nkpi_no = round(len(df[(df[\"is_promoted\"]==1) & (df[\"awards_won?\"] == 0)]) \/ len(df[df[\"awards_won?\"] == 0]) *100, 2)\nkpi_si = round(len(df[(df[\"is_promoted\"]==1) & (df[\"awards_won?\"] == 1)]) \/ len(df[df[\"awards_won?\"] == 1]) * 100, 2)\n\nprint(\"El \" + str(kpi_no) + \"% de empleados que no obtuvo premios fue promovido\")\nprint(\"El \" + str(kpi_si) + \"% de empleados que s\u00ed obtuvo permios fue promovido\")","7f08cd0a":"fig = px.histogram(df, x=\"avg_training_score\", title = \"Distribuci\u00f3n de Cantidad de a\u00f1os de Servicio de los Empleados\", color = \"is_promoted\", labels= {\"avg_training_score\":\"Promedio de Puntaje de Capacitaci\u00f3n\",\"is_promoted\": \"Promoci\u00f3n\"},nbins=35, color_discrete_sequence=px.colors.qualitative.Pastel2)\nfig.update_layout(yaxis_title=\" \")\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=650)\nfig.show()\nprint(\"La media de a\u00f1os de servicio de los empleados no promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==0].avg_training_score),2)))\nprint(\"La media de a\u00f1os de servicio de los empleados promovidos es \" + str(round(np.mean(df[df[\"is_promoted\"]==1].avg_training_score),2)))","bb046748":"df.drop([\"employee_id\", \"region\"], axis=1, inplace=True)","b82a5dec":"df.department = df.department.map({\"Sales & Marketing\":0,\n                 \"Operations\":1,\n                 \"Technology\":2,\n                 \"Analytics\":3,\n                 \"R&D\":4,\n                 \"Procurement\":5,\n                 \"Finance\":6,\n                 \"HR\":7,\n                 \"Legal\":8})\ndf.education = df.education.map({\"Master's & above\":0,\n                                \"Bachelor's\":1,\n                                \"Below Secondary\":2})\ndf.gender = df.gender.map({\"f\":0,\n                          \"m\":1})\ndf.recruitment_channel = df.recruitment_channel.map({\"sourcing\":0,\n                                                    \"other\":1,\n                                                    \"referred\":2})\ndf.head()","01a3abbe":"from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import cross_validate, StratifiedKFold, RandomizedSearchCV\n\nscoring = {'accuracy':make_scorer(accuracy_score), \n           'precision':make_scorer(precision_score),\n           'recall':make_scorer(recall_score), \n           'f1_score':make_scorer(f1_score),\n            'roc_auc':make_scorer(roc_auc_score)}\n\nlog_model = LogisticRegression(max_iter=10000)\nsvc_model = LinearSVC(dual=False)\ndtr_model = DecisionTreeClassifier()\nrfc_model = RandomForestClassifier()\ngnb_model = GaussianNB()\nxgb_model = xgb.XGBClassifier()\n\ndef models_evaluation(X, y, folds):\n    log = cross_validate(log_model, X, y, cv=folds, scoring=scoring)\n    svc = cross_validate(svc_model, X, y, cv=folds, scoring=scoring)\n    dtr = cross_validate(dtr_model, X, y, cv=folds, scoring=scoring)\n    rfc = cross_validate(rfc_model, X, y, cv=folds, scoring=scoring)\n    gnb = cross_validate(gnb_model, X, y, cv=folds, scoring=scoring)\n    xgb = cross_validate(xgb_model, X, y, cv=folds, scoring=scoring)\n\n\n    models_scores_table = pd.DataFrame({'Logistic Regression':[log['test_accuracy'].mean(),\n                                                               log['test_precision'].mean(),\n                                                               log['test_recall'].mean(),\n                                                               log['test_f1_score'].mean(),\n                                                              log['test_roc_auc'].mean()],\n                                       \n                                      'Support Vector Classifier':[svc['test_accuracy'].mean(),\n                                                                   svc['test_precision'].mean(),\n                                                                   svc['test_recall'].mean(),\n                                                                   svc['test_f1_score'].mean(),\n                                                                  svc['test_roc_auc'].mean()],\n                                       \n                                      'Decision Tree':[dtr['test_accuracy'].mean(),\n                                                       dtr['test_precision'].mean(),\n                                                       dtr['test_recall'].mean(),\n                                                       dtr['test_f1_score'].mean(),\n                                                      dtr['test_roc_auc'].mean()],\n                                       \n                                      'Random Forest':[rfc['test_accuracy'].mean(),\n                                                       rfc['test_precision'].mean(),\n                                                       rfc['test_recall'].mean(),\n                                                       rfc['test_f1_score'].mean(),\n                                                      rfc['test_roc_auc'].mean()],\n                                       \n                                      'Gaussian Naive Bayes':[gnb['test_accuracy'].mean(),\n                                                              gnb['test_precision'].mean(),\n                                                              gnb['test_recall'].mean(),\n                                                              gnb['test_f1_score'].mean(),\n                                                             gnb['test_roc_auc'].mean()],\n                                        \n                                       'Extreme Gradient Boosting':[xgb['test_accuracy'].mean(),\n                                                              xgb['test_precision'].mean(),\n                                                              xgb['test_recall'].mean(),\n                                                              xgb['test_f1_score'].mean(),\n                                                            xgb['test_roc_auc'].mean()]},\n                                      \n                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', \"AUC ROC\"])\n    \n\n    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n\n    return(models_scores_table)\n  \nmodels_evaluation(features, target, 5)","b9c1092f":"from datetime import datetime\n\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n\n        \nparams = {\n        'min_child_weight': [1,3, 5, 7, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n        'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0],\n        'max_depth': [2, 3, 4, 5, 7,9]\n        }\n\nfolds = 5\nparam_comb = 20\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 7)\n\nrandom_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=param_comb, scoring='f1',verbose = 3, n_jobs=4, cv=skf.split(features,target), random_state=7)\n\n\nstart_time = timer(None) \nrandom_search.fit(features, target)\ntimer(start_time)\n","47246f4a":"print('Par\u00e1metros \u00d3ptimos:')\nprint(random_search.best_params_)\nprint(\"\\n Mejor Puntaje F1 Obtenido\")\nprint(random_search.best_score_)","45b48e8a":"test = test_full.copy() \n\ntest.drop([\"employee_id\",\"region\"],axis=1, inplace=True)\n\ntest.department = test.department.map({\"Sales & Marketing\":0,\n                 \"Operations\":1,\n                 \"Technology\":2,\n                 \"Analytics\":3,\n                 \"R&D\":4,\n                 \"Procurement\":5,\n                 \"Finance\":6,\n                 \"HR\":7,\n                 \"Legal\":8})\ntest.education = test.education.map({\"Master's & above\":0,\n                                \"Bachelor's\":1,\n                                \"Below Secondary\":2})\ntest.gender = test.gender.map({\"f\":0,\n                          \"m\":1})\ntest.recruitment_channel = test.recruitment_channel.map({\"sourcing\":0,\n                                                    \"other\":1,\n                                                    \"referred\":2})\n\ntest.head()","20806358":"y_test = random_search.predict(test)\ny_test_prob = random_search.predict_proba(test)\nresultados = pd.DataFrame(data={'id':test_full['employee_id'], 'Promovido':y_test, \"Probabilidad\":y_test_prob[:,1]})\nprint(resultados.head())\nprint(\"La cantidad de Empleados Promovidos es de: \" + str(len(resultados[resultados[\"Promovido\"]==1])))","90b983bb":"Podemos ver que hay algunos valores Nulos para las variables de educaci\u00f3n y rating del a\u00f1o anterior. En estas situaciones, tenemos dos caminos: eliminar las filas enteras que contienen datos inv\u00e1lidos, o imputarles alg\u00fan valor. En este caso en particular, ya que solo vamos a utilizar estos datos para entrenar nuestro algoritmo, vamos a proceder a eliminar las filas.","6522a801":"En primer lugar, vamos a eliminar la fila de ID de empleados porque no nos es \u00fatil para el modelo predictivo y las regiones por la gran cantidad que tenemos, lo que puede llevar a menor precisi\u00f3n","b9b6e32e":"Tambi\u00e9n observamos que esta variable tiene bastante peso para la promoci\u00f3n de empleados. Adem\u00e1s de la diferencia en la media, podemos ver que son pocos empleados promovidos en los puntajes m\u00e1s bajos (alrededor del 50%) si lo ponemos en relaci\u00f3n a la cantidad de empleados totales que obtuvieron ese puntaje promedio. Sin embargo, para los puntajes m\u00e1s altos (superiores al 90%), casi todos los empleados que obtienen estos puntajes son promovidos.","ddcfe47c":"## An\u00e1lisis de Datos y Visualizaci\u00f3n","db3a750a":"## G\u00e9nero","fcf52aee":"Como supon\u00edamos, esta variable de rendimiento tambi\u00e9n se muestra como un criterio para la promoci\u00f3n de empleados.","b832fb1e":"## Canal de Reclutamiento","0ad2b273":"Ahora vamos a entrenar y comparar los puntajes de m\u00faltiples algoritmos de clasificaci\u00f3n. Decid\u00ed ir por los m\u00e1s comunes, que son: Regresi\u00f3n Log\u00edstica, M\u00e1quinas de Vector Soporte, \u00c1rboles de Decisi\u00f3n, Bosques Aleatorios de Clasificaci\u00f3n, Clasificador Bayesiano Ingenuo y Potenciaci\u00f3n Extrema de Gradiente (Extreme Gradient Boosting)\n\nComo base, utilic\u00e9 el [c\u00f3digo de Roberto Salazar](http:\/\/https:\/\/towardsdatascience.com\/machine-learning-classifiers-comparison-with-python-33149aecdbca) para esta tarea","db141cba":"## Regi\u00f3n ","e1fdacaa":"## Predicciones","ba053b2c":"Naturalmente, la variable est\u00e1 muy desbalanceada: tenemos pocos casos de promociones comparados con los empleados que no son promovidos, como es de esperar en cualquier organizaci\u00f3n.","f254506c":"## Modelo de Predicci\u00f3n","db9c48de":"Ahora necesitamos convertir las variables categ\u00f3ricas en num\u00e9ricas, para esto vamos a convertir cada una de las categor\u00edas de estas variables en valores numerales como 0-1-2, etc. De acuerdo a la cantidad de categor\u00edas que tenga cada variable.","c72a5e6c":"### Limpieza de datos para entrenar el modelo","01345513":"## Educaci\u00f3n","6cdaa81b":"## Variables Num\u00e9ricas","61f9b91c":"Como es de esperar, la distribuci\u00f3n de edad de los empleados es similar a la de la poblaci\u00f3n activa. Adem\u00e1s de los estad\u00edsticos descriptivos, a simple vista podemos ver que la mayor\u00eda de los empleados tienen entre 26 y 43 a\u00f1os y que la distribuci\u00f3n de edades de los empleados promovidos es relativa a la distribuci\u00f3n total de edades de empleados.","0547f558":"Observamos que las promociones son relativas a la cantidad de empleados de cada departamento. A simple vista no hay ning\u00fan departamento que llame la atenci\u00f3n. Quiz\u00e1s promover un n\u00famero equitativo de empleados por departamento incluso sea una pol\u00edtica de la empresa. Conocer esta informaci\u00f3ns nos ser\u00eda \u00fatil para nuestra tarea.","d77621ab":"Ahora que tenemos el algoritmo de clasificaci\u00f3n optimizado, podemos utilizarlo para realizar predicciones sobre nuevos datos y saber cu\u00e1l empleado ser\u00e1 promovido con anticipaci\u00f3n, siempre teniendo en cuenta la falibilidad del modelo y el puntaje obtenido en la prueba.","88e62362":"## Cantidad de Entrenamientos","804fc440":"# Predicci\u00f3n de Promociones de Empleados","a34a9404":"El resultado final, es una base de datos que mostrar\u00e1 cu\u00e1l empleado ser\u00e1 promovido (1) y cu\u00e1l no (0), y la probabilidad de que estos empleados tengan de ser promovidos de acuerdo a este modelo.","2c8126cc":"Debido a que este projecto es una simple demostraci\u00f3n, no vamos a realizar una optimizaci\u00f3n de hiperpar\u00e1metros a fuerza bruta porque llevar\u00eda mucho tiempo. Decid\u00ed realizar una optimizaci\u00f3n mediante una b\u00fasqueda aleatoria de hiperpar\u00e1metros.","db933cbb":"## Departamentos","0c4d1371":"Al interpretar estos resultados, debemos tener en cuenta lo siguiente:\n1. El desbalance de nuestra variable objetivo: Como vimos al principio, la cantidad de empleados no promovidos es mayor al 90%. Esto significa que, si un modelo predictivo diera como 100% de toda la muestra como \"no promovido\", estar\u00eda acertando en el 90% de los casos. Por esta raz\u00f3n, el puntaje de \"Accuracy\" (Exactitud) de un modelo predictivo en esta situaci\u00f3n no es el mejor a utilizar.\n2. El problema que buscamos resolver: la principal demanda de la organizaci\u00f3n es la de detectar con anticipaci\u00f3n aquellos empleados que pueden llegar a ser promovidos para poder prepararlos con mayor tiempo. Haremos la suposici\u00f3n de que tanto la tasa de \"Precisi\u00f3n\" como la de \"Recuperaci\u00f3n\" tienen el mismo costo para la empresa, y por esta raz\u00f3n utilizaremos el puntaje F1 que es un equilibrio de ambos puntajes. El algoritmo que mejor se desempe\u00f1a sobre este puntaje es el Extreme Gradient Boosting.","16ba7960":"## Ajuste de hiperpar\u00e1metros","95161781":"Al observar cuidadosamente, vemos que una variable num\u00e9rica es de tipo \"float64\", lo que nos puede dificultar hacer algunas operaciones en el futuro, as\u00ed que vamos a cambiar su formato a \"integer\".","fa1b34e0":"![Empleados](https:\/\/www.groupe.io\/wp-content\/uploads\/2019\/04\/Best-Employee.jpg)","a650f3e9":"Se puede observar que la cantidad de empleados promovidos en relaci\u00f3n a la educaci\u00f3n alcanzada es relativa a la cantidad absoluta de los empleados en cada una de estas categor\u00edas.","cbef420e":"## En este projecto vamos a visualiar y analizar los datos referidos a empleados de una organizaci\u00f3n masiva, para luego poder entrenar un algoritmo de clasificaci\u00f3n que pueda predecir cu\u00e1l empleado ser\u00e1 promovido","0619927c":"Observamos que la mayor\u00eda de los empleados promovidos solo ha tenido 1 capacitaci\u00f3n. El mayor n\u00famero de capacitaciones ha sido 6 para los empleados promovidos. La cantidad de capacitaciones no parece ser un determinante muy fuerte para la promoci\u00f3n en esta organizaci\u00f3n.","1e05ac76":"En esta variable podemos empezar a ver una diferencia entre los empleados promovidos y los no promovidos. Probablemente esta variable, como las otras basadas en el rendimiento s\u00ed sean buenos predictores para conocer qui\u00e9n ser\u00e1 promovido.","63d0768c":"## Edad","d33b8ff0":"1. Al leer la nueva base de datos, debemos recordar que tenemos que hacer la misma limpieza de datos que hicimos para entrenar al algoritmo, es decir, eliminar las columnas de \"ID\" de los empleados y las regiones, adem\u00e1s de imputar los mismos valores num\u00e9ricos a las variables categ\u00f3ricas que utilizamos."}}