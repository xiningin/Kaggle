{"cell_type":{"3e8571c5":"code","25796158":"code","f27d2ef9":"code","d96c12f5":"code","c6214226":"code","ea0883a2":"code","0770c50b":"code","a7a5bdc9":"code","65d27b6e":"code","17a7dd72":"code","165dc737":"code","5256d17b":"code","152243e0":"code","046bea2f":"code","32e0f0a4":"code","62444c99":"code","ee2a5c06":"markdown","d4e51df5":"markdown"},"source":{"3e8571c5":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgbm\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport cv2\nimport missingno as msno","25796158":"train=pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest=pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","f27d2ef9":"train.head()","d96c12f5":"train_meta = train.copy()\ntest_meta = test.copy()\ntrain_meta = train_meta.drop([\"Id\", \"Pawpularity\"], axis=1)\ntest_meta = test_meta.drop([\"Id\"], axis=1)","c6214226":"train_image = train.copy()\ntest_image = test.copy()\n\ntrain_image[\"file_path\"] = train[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/train\/\" + x + \".jpg\")\ntest_image[\"file_path\"] = test[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/test\/\" + x + \".jpg\")","ea0883a2":"%%time\n\ndef preprocess(image_url):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (128, 128))\n    return image\n\nx_train_image=[]\nfor i in train_image['file_path']:\n    x1=preprocess(i)\n    x_train_image.append(x1)","0770c50b":"plt.figure(figsize=(20, 20))\nrow, col = 5, 4\nfor i in range(row * col):\n    plt.subplot(row, col, i+1)\n    image = cv2.imread(train_image.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train_image.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"No: {i}\" f\"   Pawpularity: {target}\")\nplt.show()","a7a5bdc9":"test1_image=[]\n\nfor i in test_image['file_path']:\n    x1=preprocess(i)\n    test1_image.append(x1)\n\ntest1_image=np.array(test1_image)","65d27b6e":"def get_model() :\n\n    # model for Photo image\n    image_inputs = tf.keras.Input((128, 128 , 3))\n    x_image = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),strides=2,activation='relu', padding='same')(image_inputs)\n    x_image = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides=2,activation='relu', padding='same')(x_image)\n    x_image = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),strides=2,activation='relu', padding='same')(x_image)   \n    x_image = tf.keras.layers.Flatten()(x_image)\n    x_image = tf.keras.layers.Dense(128,activation='relu')(x_image)\n    x_image = tf.keras.layers.Dropout(0.25)(x_image)\n    \n    # model for Meta data\n    meta_inputs = tf.keras.Input(shape=((12,)))\n    x_meta = tf.keras.layers.Dense(12,activation='relu')(meta_inputs)    \n    x_meta = tf.keras.layers.Dense(24,activation='relu')(x_meta)    \n    x_meta = tf.keras.layers.Dense(12,activation='relu')(x_meta)      \n\n    x = tf.keras.layers.Concatenate(axis=1)([x_image, x_meta])\n    output = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs=[image_inputs, meta_inputs], outputs=output)\n    \n    return model","17a7dd72":"model =  get_model()\ntf.keras.utils.plot_model(model, show_shapes=True)","165dc737":"x_train_image = np.array(x_train_image)\ny_train=train['Pawpularity']\n\nfrom sklearn.model_selection import train_test_split\n\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback\n\n#x_meta_train,x_meta_test,y_train,y_test=train_test_split(train_meta,y_train,test_size=0.2)","5256d17b":"def preprocess1(image_url, tabular):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (128, 128))\n    return (image, tabular[1:]), tabular[0]","152243e0":"%%time\ntf.keras.backend.clear_session()\n\nmodels = []\nhistorys = []\ntabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', \n                   'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nkf = KFold(n_splits=3, shuffle=True)\n\nfor train_index, val_index in kf.split(train_meta):      \n    \n    x_path = train_image.loc[train_index, \"file_path\"]    \n    x_val= train_image.loc[val_index, \"file_path\"]\n    \n    tabular_train = train.loc[train_index, [\"Pawpularity\"] + tabular_columns]\n    tabular_val = train.loc[val_index, [\"Pawpularity\"] + tabular_columns]\n\n    def step_decay(epoch):\n        initial_lrate = 0.001\n        drop = 0.5\n        epochs_drop = 10.0\n        lrate = initial_lrate * math.pow(drop, math.floor((epoch)\/epochs_drop)\n        )\n        return lrate\n\n    lrate = LearningRateScheduler(step_decay)\n\n    earstop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5)\n    \n    model = get_model()\n    model.compile(\n        loss = tf.keras.losses.MeanSquaredError(),    \n        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"],\n        optimizer = tf.keras.optimizers.Adam(1e-3)\n        )\n    \n    train_ds = tf.data.Dataset.from_tensor_slices((x_path, tabular_train)).map(preprocess1).shuffle(512).batch(100).cache().prefetch(2)\n    val_ds = tf.data.Dataset.from_tensor_slices((x_val, tabular_val)).map(preprocess1).batch(100).cache().prefetch(2)\n    \n    history = model.fit(\n        train_ds,\n        epochs = 25,\n        batch_size=100,\n        validation_data = val_ds,\n        verbose = 1,\n        callbacks = [lrate, earstop]\n        )\n        \n    historys.append(history)\n    models.append(model)","046bea2f":"def preprocess_test_data(image_url, tabular):    \n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (128, 128))    \n    return (image, tabular), 0\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test_image[\"file_path\"], test[tabular_columns])).map(preprocess_test_data).batch(100).cache().prefetch(2)","32e0f0a4":"preds = []\n\nfor model in models:\n    nn_pred=model.predict(test_ds)\n    preds.append(nn_pred)\n\npreds_array = np.array(preds)\npreds_mean = np.mean(preds_array, axis =0)","62444c99":"sub=pd.DataFrame()\nsub['Id']=test['Id']\nsub['Pawpularity']=preds_mean\nsub.to_csv('submission.csv',index=False)\nsub","ee2a5c06":"**(P.S.)**  \nBelow discussion thread was also helpful for me as a knowledge, but I was not able to utilize the method (Option1) very well.. (When I simply throw the Image+Meta into CNN, the Public score showed 22.19051...) I have to study more and retry :-)\n\n\u306a\u304a\u3001\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u3082\u975e\u5e38\u306b\u8208\u5473\u6df1\u304b\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u3053\u3053\u3067\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308bOption1\u306f\u3001\u3069\u3046\u3082\u3046\u307e\u304f\u4f7f\u3044\u3053\u306a\u305b\u307e\u305b\u3093\u3067\u3057\u305f\uff08\u5358\u7d14\u306bImage+Meta\u3092CNN\u306b\u6295\u5165\u3059\u308b\u3068\u3001\u30b9\u30b3\u30a2\u306f22.19051\u3067\u3057\u305f\u3002\u3002\uff09\u3082\u3063\u3068\u7814\u7a76\u3057\u3066\u30ea\u30c8\u30e9\u30a4\u305b\u306d\u3070\u3002\n\nhttps:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/277164","d4e51df5":"# Beginner's Experiment for Multi-input (Photo image + Meta data)\n\nThanks to Lonnie's notebook below. \nhttps:\/\/www.kaggle.com\/lonnieqin\/tensorflow-multi-input-pet-pawpularity-model\n\nI tried to process simple Convolutional Neural Network (CNN) at first, but it didn't show good score. Then, I came to be interested in processing Multi-input using Photo image data and Meta data together, how good score it shows?  \n\u6700\u521d\u306f\u30b7\u30f3\u30d7\u30eb\u306b\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u753b\u50cf\u8a8d\u8b58\u3092\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u3042\u307e\u308a\u30b9\u30b3\u30a2\u3082\u826f\u304f\u306a\u3044\u306e\u3067\u3001Meta Data\u3068\u4e00\u7dd2\u306b\u51e6\u7406\u3057\u305f\u3089\u3069\u306e\u7a0b\u5ea6\u306e\u30b9\u30b3\u30a2\u6539\u5584\u306b\u7e4b\u304c\u308b\u306e\u304b\u8208\u5473\u3092\u6301\u3061\u3001Multi-input\u306e\u5b9f\u9a13\u3092\u3057\u3066\u307f\u305f\u3082\u306e\u3067\u3059\u3002\n\n**(1) Simple CNN using Photo-image data only**  \n First, I tried simple CNN using Photo-image data only. Public score was 20.73773.\n \n**(2) Simple MLP using Meta-data only**  \n Then, tried simple MLP using Meta-data only. Public score was 20.61303.\n \n**(3) Multi-input using both (1) and (2)**\n Tried Multi-input using both, then Public score was 20.53512.\n \nMulti-input seems effective rather than processing each of them independently :-)\n\n![image.png](attachment:c8569b6f-3ae1-401d-a285-bea9f57767e0.png)\n\n\n"}}