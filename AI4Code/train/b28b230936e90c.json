{"cell_type":{"4914213e":"code","c32da107":"code","3077a0d6":"code","744c4f1e":"code","53c7135f":"code","b05a41e9":"code","877e216f":"code","fc5ef730":"code","9dc2659a":"code","98b5b118":"code","81f953c3":"code","2d87b7e8":"code","3b3818d8":"code","e70f120d":"code","2f8d07e1":"code","403b02ca":"code","3c63e93d":"code","33e56769":"code","187c8447":"code","6eb33ed7":"code","b5bd8f50":"code","607dcc04":"code","21b8fd42":"code","fb791d26":"code","bfcddb9d":"code","d1e26477":"code","686d6f33":"markdown","09a2ed4f":"markdown","c4968e27":"markdown","ca22e143":"markdown"},"source":{"4914213e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn import preprocessing\nfrom scipy.spatial import ConvexHull\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c32da107":"\ndf = pd.read_csv(r'\/kaggle\/input\/customer-order-data\/SampleAssessment.csv')\ndf.head()","3077a0d6":"df.columns","744c4f1e":"## num of customers\nprint ('Number of Customers:',df.customer_id.nunique())","53c7135f":"df.describe()\n#Observations: \n# Amount in last 7 days,Amount in last 4 weeks have missing values (as min=0), \n# Avg_DistanceFromResturant is negative in few cases","b05a41e9":"df.dtypes\n# convert dates to date format","877e216f":"# format date\ndf['First_Order_Time'] = pd.to_datetime(df['First Time'])\ndf['Recent_Order_Time'] = pd.to_datetime(df['Recent Time'])\n\ndf['First_Order_Time'] = df['First_Order_Time'].dt.strftime('%m\/%d\/%Y')\ndf['Recent_Order_Time'] = df['Recent_Order_Time'].dt.strftime('%m\/%d\/%Y')\n\ndf['First_Order_Time'] = pd.to_datetime(df['First_Order_Time'])\ndf['Recent_Order_Time'] = pd.to_datetime(df['Recent_Order_Time'])","fc5ef730":"df.head()","9dc2659a":"# drop redundant columns\ndf.drop(['First Time','Recent Time'], axis = 1, inplace=True)\n\n# assume current date to be just the next day after latest transaction\ndf['current_date'] = max(df['Recent_Order_Time'])+ datetime.timedelta(days=1)","98b5b118":"# extract num_days_since_last_order, num_days_since_first_order\ndf['num_days_since_last_order'] = df['current_date'] - df['Recent_Order_Time']\ndf['num_days_since_first_order'] = df['current_date'] - df['First_Order_Time']","81f953c3":"\n## rename columns\n\ndf.columns = ['customer_id', 'num_of_Orders', 'num_of_Orders_in_last_7_days',\n       'num_of_Orders_in_last_4_weeks', 'Amount', 'Amount_in_last_7_days',\n       'Amount_in_last_4_weeks', 'Avg_DistanceFromResturant',\n       'Avg_DeliveryTime', 'First_Order_Time', 'Recent_Order_Time',\n       'current_date', 'num_days_since_last_order',\n       'num_days_since_first_order']","2d87b7e8":"df.head()","3b3818d8":"# check for cases where order value is null for last 7 days and 4 Weeks\nnull_orders_in_last_7_days = df[df.num_of_Orders_in_last_7_days.isna()]\nnull_orders_in_last_4_weeks = df[df.num_of_Orders_in_last_4_weeks.isna()]\n\nprint (null_orders_in_last_7_days.num_days_since_last_order.min())\nprint (null_orders_in_last_4_weeks.num_days_since_last_order.min())\n# it means it these are actually null not missing  so replace them by 0\n\ndf.num_of_Orders_in_last_7_days.fillna(0, inplace = True)\ndf.num_of_Orders_in_last_4_weeks.fillna(0, inplace = True)","e70f120d":"# replace neagtive values with 0\ndf['Avg_DistanceFromResturant'] = np.where(df['Avg_DistanceFromResturant']<0, 0,df['Avg_DistanceFromResturant'])","2f8d07e1":"# check\ndf.describe()","403b02ca":"# avg of one order for a customer\ndf['AOV'] = round(df['Amount']\/df['num_of_Orders'],0)\n\n# avg of one order for a customer in last 7 days\ndf['AOV_last_7_days'] = np.where(df['num_of_Orders_in_last_7_days']==0, 0,\n                                 round(df['Amount_in_last_7_days']\/df['num_of_Orders_in_last_7_days'],0))\n\n# avg of one order for a customer in last 4 weeks\ndf['AOV_last_4_weeks'] = np.where(df['num_of_Orders_in_last_4_weeks']==0, 0,\n                                  round(df['Amount_in_last_4_weeks']\/df['num_of_Orders_in_last_4_weeks'],0))","3c63e93d":"# % of users transacted in last 7 days\nprint ('% of users transacted in last 7 days:',df[df['num_of_Orders_in_last_7_days']!=0].shape[0]\/df.shape[0])\n\n# % of users transacted in last 4 weeks \nprint ('% of users transacted in last 4 weeks:',df[df['num_of_Orders_in_last_4_weeks']!=0].shape[0]\/df.shape[0])","33e56769":"# filtering for only relevant columns\ndf_mod = df[['customer_id','num_of_Orders', 'AOV','AOV_last_7_days','AOV_last_4_weeks', 'Avg_DistanceFromResturant', 'Avg_DeliveryTime', 'num_days_since_last_order', 'num_days_since_first_order']]\n\n# extract days\ndf_mod['num_days_since_last_order'] = df_mod['num_days_since_last_order'].dt.days\ndf_mod['num_days_since_last_order'] = df_mod['num_days_since_last_order'].astype(int)\n\ndf_mod['num_days_since_first_order'] = df_mod['num_days_since_first_order'].dt.days\ndf_mod['num_days_since_first_order'] = df_mod['num_days_since_first_order'].astype(int)","187c8447":"# l2-normalize  \nX_normalized = preprocessing.normalize(df_mod[df_mod.columns[1:]], norm='l2')","6eb33ed7":"for i in range(7):\n    pca = PCA(n_components=i)\n    pca_result = pca.fit_transform(X_normalized)\n    print (i,\"explained variance : \",sum(pca.explained_variance_.round(2)), \"|\",\"explained variance ratio : \",sum(pca.explained_variance_ratio_.round(2)))\n    print ('')","b5bd8f50":"pca = PCA(n_components = 4)\npca_result = pca.fit_transform(X_normalized)","607dcc04":"distortions = []\nsilhouette_avg_list = []\nlabels_temp = [2,3,4,5]\nfor k in labels_temp:\n    kmeanModel = KMeans(n_clusters=k,random_state=100)\n    kmeanModel.fit(pca_result)\n    cluster_labels = kmeanModel.fit_predict(pca_result)\n    silhouette_avg = silhouette_score(pca_result, cluster_labels)\n    print(\"For n_clusters =\", k,\n          \"The average silhouette_score is :\", silhouette_avg)\n    distortions.append(kmeanModel.inertia_)\n    silhouette_avg_list.append(silhouette_avg)","21b8fd42":"# plotting elbow curve for optimal k value (inertia vs no. of clusters)\nplt.plot(labels_temp, distortions)\nplt.xlabel('number of clusters(k)')\nplt.ylabel('Distortions')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","fb791d26":"'''Make Clusters'''\n\ncluster_size = 4\nk = int(cluster_size)\nkmeans = KMeans(n_clusters=k, random_state=100).fit(pca_result)\ncluster_labels = list(kmeans.predict(pca_result))","bfcddb9d":"print (\"cluster distribution\")\nprojected = pca.fit_transform(X_normalized.data)\nprojected = pd.concat([pd.DataFrame(projected),pd.DataFrame(cluster_labels).rename(columns ={0:'Labels'})],axis = 1)","d1e26477":"fig, ax = plt.subplots(1, figsize=(20,10))\ncolors = ['#DF2020', '#81DF20', '#2095DF','#ffff99']\n# plot data\nplt.scatter(projected[0].values, projected[1].values, c=list(kmeans.labels_), alpha = 0.6, s=10)\n# plot centers\ncentroids = kmeans.cluster_centers_\ncen_x = [i[0] for i in centroids] \ncen_y = [i[1] for i in centroids]\n\nplt.scatter(cen_x, cen_y, marker='^', c=colors, s=70)\n# draw enclosure\nfor i in projected['Labels'].unique():\n    points = projected[projected.Labels == i][[0,1]].values\n    # get convex hull\n    hull = ConvexHull(points)\n    # get x and y coordinates\n    # repeat last point to close the polygon\n    x_hull = np.append(points[hull.vertices,0],\n                       points[hull.vertices,0][0])\n    y_hull = np.append(points[hull.vertices,1],\n                       points[hull.vertices,1][0])\n    # plot shape\n    plt.fill(x_hull, y_hull, alpha=0.3, c=colors[i])\n    \n# plt.xlim(0,200)\n# plt.ylim(0,200)","686d6f33":"**EDA**","09a2ed4f":"**Feature Creation**","c4968e27":"**PCA and K-means Clustering**","ca22e143":"**Following code is for Customer Segmentation  using food delivery data. In the code you will find the following:**\n\n* EDA and Feature Creation\n* PCA for dimensionality reduction\n* Elbow method to select optimal cluster"}}