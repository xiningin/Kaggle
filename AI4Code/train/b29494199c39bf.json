{"cell_type":{"50f1e4fe":"code","0a13bf90":"code","908ef7a0":"code","d34d6cc5":"code","7b1e70dd":"code","95ca0051":"code","e58f6c4e":"code","a4580032":"code","48816e92":"code","171e4318":"code","1af0ab9a":"code","3e5f6ebf":"code","a50f69c9":"code","dab8a36b":"code","f3c8e11c":"code","906b8675":"code","53cc3106":"code","f829d73e":"code","75b2e9c5":"code","e8070e5e":"code","fa457ee0":"code","d51b274c":"code","b4ba14ec":"code","33fda6c7":"code","c6bc099f":"code","4d1b0755":"code","d6311df8":"code","29367946":"code","e2a3a4be":"code","b3da3db2":"code","f059f570":"markdown","aad86869":"markdown","76552a54":"markdown","10bcf78c":"markdown","9b6cbb14":"markdown","dcf67bd9":"markdown","4ca51f81":"markdown","5783707d":"markdown"},"source":{"50f1e4fe":"import matplotlib.pyplot as plt\nimport IPython.display as ipd\nimport librosa\nimport librosa.display as disp\nimport pandas as pd\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom pickle import load\nfrom pickle import dump\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nimport warnings\nwarnings.filterwarnings('ignore')","0a13bf90":"df = pd.read_csv('..\/input\/hindi-speech-classification\/dataset\/train.csv')","908ef7a0":"df.head()","d34d6cc5":"df['gender'] = LabelEncoder().fit_transform(df['gender'])","7b1e70dd":"df.head()","95ca0051":"df['gender'].value_counts(normalize=True)","e58f6c4e":"filename = '\/kaggle\/input\/hindi-speech-classification\/dataset\/train\/common_voice_hi_26204093.mp3'\nplt.figure(figsize=(14,6))\ndata,sample_rate = librosa.load(filename)\ndisp.waveplot(data, sr=sample_rate)","a4580032":"ipd.Audio(filename)","48816e92":"# Source for this cell : https:\/\/github.com\/jurgenarias\/Portfolio\/blob\/master\/Voice%20Classification\/Code\/Gender_Classifier\/Gender_Classifier_NN.ipynb\ndef extract_features(files):\n    \n    # Sets the name to be the path to where the file is in my computer\n    file_name = os.path.join(os.path.abspath('..\/input\/hindi-speech-classification\/dataset\/train')+'\/'+str(files.file_id)+'.mp3')\n\n    # Loads the audio file as a floating point time series and assigns the default sample rate\n    # Sample rate is set to 22050 by default\n    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n\n    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n\n    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n    stft = np.abs(librosa.stft(X))\n\n    # Computes a chromagram from a waveform or power spectrogram.\n    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n\n    # Computes a mel-scaled spectrogram.\n    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n\n    # Computes spectral contrast\n    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n\n    # Computes the tonal centroid features (tonnetz)\n    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n    sr=sample_rate).T,axis=0)\n        \n    \n    # We add also the classes of each file as a label at the end\n    label = files.gender\n\n    return mfccs, chroma, mel, contrast, tonnetz, label","171e4318":"startTime = datetime.now()\nfeatures_label = df.apply(extract_features, axis=1)\nprint(datetime.now() - startTime)","1af0ab9a":"dump(features_label, open('features_label.pkl', 'wb'))","3e5f6ebf":"features_label = load(open('.\/features_label.pkl', 'rb'))","a50f69c9":"features_label","dab8a36b":"# We create an empty list where we will concatenate all the features into one long feature\n# for each file to feed into our neural network \n\nfeatures = []\nfor i in range(0, len(features_label)):\n    features.append(np.concatenate((features_label[i][0], features_label[i][1], \n                features_label[i][2], features_label[i][3],\n                features_label[i][4]), axis=0))","f3c8e11c":"features[1]","906b8675":"# Similarly, we create a list where we will store all the labels\n\nlabels = []\nfor i in range(0, len(features_label)):\n    labels.append(features_label[i][5])","53cc3106":"labels[1]","f829d73e":"# Setting our X and y as a numpy array to feed into the neural network\nX = np.array(features)\ny = np.array(labels)","75b2e9c5":"X_train, X_testval, Y_train, Y_testval = train_test_split(X, y , test_size=0.3, random_state=48, stratify=y)\nX_val, X_test, Y_val, Y_test = train_test_split(X_testval, Y_testval, test_size=0.3, random_state=46, stratify=Y_testval)","e8070e5e":"# Scaling data\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_val = ss.transform(X_val)\nX_test = ss.transform(X_test)","fa457ee0":"X_val[2].shape","d51b274c":"model = Sequential()\n\nmodel.add(Dense(193, input_shape=(193,), activation = 'relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.25))  \n\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.5))    \n\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')","b4ba14ec":"model.summary()","33fda6c7":"# fitting the model with the train data and validation with the validation data\n# we used early stop with patience 15\nhistory = model.fit(X_train, Y_train, batch_size=16, epochs=100, \n                    validation_data=(X_val, Y_val),\n                    callbacks=[early_stop]\n                   )","c6bc099f":"model.evaluate(X_test,Y_test)","4d1b0755":"pred=model.predict(X_test)\ny_pred = []\nfor a in pred:\n  if a > 0.5:\n    y_pred.append(1)\n  else:\n    y_pred.append(0)\n\ncm = confusion_matrix(Y_test, y_pred)\nprint(cm)","d6311df8":"test_df = pd.read_csv('..\/input\/hindi-speech-classification\/dataset\/train.csv')","29367946":"test_file = test_df[test_df['gender']=='female'].sample(1)","e2a3a4be":"def extract_features_test(files):\n    file_name = os.path.join(os.path.abspath('..\/input\/hindi-speech-classification\/dataset\/train')+'\/'+str(files.file_id.tolist()[0])+'.mp3')\n    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n    stft = np.abs(librosa.stft(X))\n    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n    sr=sample_rate).T,axis=0)\n    label = files.gender.tolist()[0]\n\n    return mfccs, chroma, mel, contrast, tonnetz, label","b3da3db2":"test_file_extract = extract_features_test(test_file)\ntest_file_extract1 = np.concatenate((test_file_extract[0], test_file_extract[1], \n                                    test_file_extract[2], test_file_extract[3],\n                                    test_file_extract[4]))\ntest_file_extract1 = test_file_extract1.reshape(1,-1)\ntest_file_extract1 = ss.transform(np.array(test_file_extract1))\nresult = model.predict(test_file_extract1)\nprint(f\"Predict Class = {'Male' if result > 0.5 else 'Female'}\")\nprint(f\"Real Class = {test_file_extract[5]}\")","f059f570":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Evaluate <\/center><\/h1> ","aad86869":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Importing Libraries <\/center><\/h1> ","76552a54":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Split Data <\/center><\/h1> ","10bcf78c":"<h1 style='background:#CCE2CB; border:0; color:black'><center> EDA & Simple Feature Engineering <\/center><\/h1> ","9b6cbb14":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Modelling <\/center><\/h1> ","dcf67bd9":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Load Data <\/center><\/h1> ","4ca51f81":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Preprocessing <\/center><\/h1> ","5783707d":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Train <\/center><\/h1> "}}