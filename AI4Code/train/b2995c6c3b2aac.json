{"cell_type":{"11fd160e":"code","c5765ad4":"code","63d573dc":"code","3b4c27d6":"code","a0eed2fc":"code","917dc3cd":"code","eb3fb6d2":"code","72b3536d":"code","ae896dd8":"code","bd5e3563":"code","6aa8c88c":"code","660495f2":"code","aa294da2":"code","55ca248c":"code","88c9740a":"code","911ecd54":"code","05e6a1ae":"code","97953667":"code","35ee3746":"code","ed335fe9":"code","eafdaec5":"code","c65b7065":"code","f440b5ee":"code","3b0bd034":"code","b1fad5c9":"code","e174a3ed":"markdown","2c5fd288":"markdown","cc2bde06":"markdown","6c3aec49":"markdown","24c3a41e":"markdown","1c2c9117":"markdown","e9e6a236":"markdown","175fea21":"markdown","fc7f2c27":"markdown","d874db1c":"markdown","f6e669fa":"markdown","6908dcd2":"markdown","3f4de370":"markdown","a0ad21f1":"markdown","a2b8cd50":"markdown","cdcae5fa":"markdown","714cb2a7":"markdown","35abb7f5":"markdown","7459200c":"markdown"},"source":{"11fd160e":"import os\nprint(\"There are following directories and files in this dataset\")\nprint(*list(os.listdir(\"..\/input\/dogs-vs-cats-redux-kernels-edition\")),sep = \"\\n\")","c5765ad4":"import glob\nimport numpy as np\nimport pandas as pd\nimport fastai\nfrom fastai.vision.all import *","63d573dc":"path = Path('..\/input\/dogs-vs-cats-redux-kernels-edition')\nimage_path = Path('.\/train')\n\nsample_submission_file = Path('..\/input\/dogs-vs-cats-redux-kernels-edition\/sample_submission.csv')","3b4c27d6":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip\",\"r\") as x:\n    x.extractall(\".\/\")","a0eed2fc":"print(\"Number of images present in train folder are: \")\nlen(glob.glob('.\/train\/*.jpg'))","917dc3cd":"print(\"First few samples of training data is as follows: \\n\")\nPath('.\/train').ls(5)","eb3fb6d2":"train_img_files = get_image_files('.\/train')","72b3536d":"img_file_names = np.array([f'{x}' for x in sorted(train_img_files)])\nimg_file_names","ae896dd8":"label_names = np.array([(1 if 'dog' in file_name else 0) for file_name in img_file_names])\nlabel_names","bd5e3563":"train_df = pd.DataFrame(img_file_names, columns=['id'])\ntrain_df['label'] = label_names\nprint(\"Size of Training data \\n\", train_df.shape)\nprint(\"----------------------------------------------------------\")\nprint(\"\\nFirst few samples of data are \\n\",train_df.head())","6aa8c88c":"dls = ImageDataLoaders.from_df(train_df, path='.', \n                         valid_pct=0.2, seed=42, \n                         fn_col='id', \n                         label_col='label', \n                         label_delim=None, \n                          \n                         item_tfms=Resize(128), batch_tfms=None, \n                         bs=64, \n                         )","660495f2":"image_data_loader.device","aa294da2":"dls.show_batch()","55ca248c":"len(dls.train_ds), len(dls.valid_ds)","88c9740a":"learn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(4,freeze_epochs = 4)","911ecd54":"learn.fit_one_cycle(6,lr_max=slice(1e-6,1e-4))","05e6a1ae":"!rm -r '.\/train'\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip\",\"r\") as y:\n    y.extractall(\".\/\")","97953667":"print(\"Number of images present in test folder are: \")\nlen(glob.glob('.\/test\/*.jpg'))","35ee3746":"print(\"First few samples of test data is as follows: \\n\")\nPath('.\/test').ls(5)","ed335fe9":"test_image_files = get_image_files('.\/test')","eafdaec5":"fnames = [f.name for f in test_image_files]\ntst_dl = dls.test_dl(test_image_files)","c65b7065":"_,_,preds = learn.get_preds(dl=tst_dl, with_decoded=True)\n\nsub = pd.DataFrame(fnames, columns=['id'])\nsub['label'] = preds","f440b5ee":"!rm -r '.\/test'\nsub = pd.DataFrame(fnames, columns=['id'])\nsub['label'] = preds","3b0bd034":"sample_sub = pd.read_csv(sample_submission_file)","b1fad5c9":"sub.to_csv('submission.csv', index=False)","e174a3ed":"**Let us check the device type of our \"ImageDataLoader\" to make sure that we are using \"GPU\"**","2c5fd288":"**Thanks for checking out this notebook.\n**\nIf you find this helpful, please show your love and support by upvoting it too.","cc2bde06":"**Defining the variables and assigning the paths for test dataset**","6c3aec49":"# 3. Test.zip\n**This zip file contains the training data which will be used for training our model**","24c3a41e":"# Creating the image data loader","1c2c9117":"# 1. sample_submission.csv\n**This csv file is an example of csv file(of the predictions by your model) to be uploaded for this competition's evaluation.****","e9e6a236":"Make the predictions using our trained model called \"learn\".\n\nIgnoring the first two outputs from the model, let us take our final result stored in variable \"preds\"\n","175fea21":"# Understanding the dataset\n**Let us print the dataset**","fc7f2c27":"# Bring it on - Test data !!","d874db1c":"# Checking the data for model training\n**We will now check the images availabe to us:**","f6e669fa":"# Creating the Pandas Dataframe to be used for creating an ImageDataLoader","6908dcd2":"# Training data\n**Let us see the training data present in \"train.zip\" file and available in train folder **","3f4de370":"# 2. Train.zip\n**This zip file contains the training data which will be used for training our model**","a0ad21f1":"# Defining the variables and assigning the paths for this notebook\n","a2b8cd50":"# Test data\n**Let us see the test data present in \"test.zip\" file and available in test folder **","cdcae5fa":"**Let us check few random images from our ImageDataLoader's batch to make sure that images and labels appears correctly in it.\n**\n","714cb2a7":"# Importing necessary libraries\n**Import Pandas - For data analysis Import Fastai - For training of deep learning model and predictions.\n\n\nNote: We are using Fastai2 (course version 4) which is the latest version. (Not previous version of Fastai- which is version 1)**","35abb7f5":"# Trainnig the image recognizer model\n\n#We create a CNN (convolutional neural network) with the following specific details:\n\nWhat data we want to train it on? <\/br> Our data to be used for training is \"dls\"\n\nWhich architecture to use? <\/br> We are using Resnet34\n\nwhat metric to use for our training evaluation? <\/br> We have specified it as \"error_rate\"\n\n","7459200c":"**Let us create a ImageDataLoader of our test data set**"}}