{"cell_type":{"4ba979f5":"code","b989f829":"code","519c9e8c":"code","f55cbe76":"code","742b92d9":"code","74a97574":"code","a2dd5708":"code","cbfd132e":"code","df0d9b0a":"code","8d51ee78":"code","84195d4d":"code","f5364b48":"code","e820ab57":"code","483c954d":"code","6f5437e6":"code","d89f7ec8":"code","295b03b2":"code","05b82b8f":"code","cb48069f":"code","579fc05b":"code","50fd63db":"code","e959bf71":"code","53cc793c":"code","7663b22c":"code","8d8fd4c8":"code","c714707d":"code","9594d4b5":"code","0c7a154d":"code","9b919a79":"code","c5eb646a":"code","adcde2cb":"code","8f7e68c8":"code","4cc9cfcb":"markdown","7eb2c156":"markdown","42d83569":"markdown","9a6d4fff":"markdown","52a37432":"markdown","4d520631":"markdown","e7e94feb":"markdown","1d8adad7":"markdown","c448be70":"markdown","c83d5720":"markdown","fa04892a":"markdown","0d62ee78":"markdown","09f28758":"markdown","8cea04a3":"markdown","794b9476":"markdown","bc60bd49":"markdown","a2225623":"markdown","209c82c3":"markdown","5e1e56ed":"markdown"},"source":{"4ba979f5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b989f829":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier,NeighborhoodComponentsAnalysis,LocalOutlierFactor\nfrom sklearn.decomposition import PCA\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","519c9e8c":"data = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndata.head()","f55cbe76":"data = data.rename(columns= {'diagnosis':'target'})#I want to change the diagnosis variable name to target.\ndata.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)","742b92d9":"data.head()","74a97574":"data['target'] = [1 if i.strip() == 'M'else 0 for i in data.target] # I need to convert the M and B in the target variable to 0 and 1.\n# .strip () removes spaces in string expressions.","a2dd5708":"# How many M and how many B's are we examining them.\npalette=[\"#FBC00E\",\"#29B3FF\"]\nsns.countplot(data['target'],palette=palette);\nprint(data.target.value_counts())","cbfd132e":"# 1 malignant so M\n# 0 benign so B\ndata.head()","df0d9b0a":"data.info()","8d51ee78":"data.describe()\n# strictly standardization process is required for this data","84195d4d":"# Since all variables we have are numeric, we look at corr ().\nax = plt.figure(figsize=(15,8))\nax = sns.heatmap(data.corr());","f5364b48":"# Since this is so confusing, I'll set a Threshold and cover those above it.\ncor_mat = data.corr()\nthreshold = 0.75\nfilters = np.abs(cor_mat['target']) > threshold\ncorr_features = cor_mat.columns[filters].tolist()\nax = plt.figure(figsize=(15,8))\nax = sns.heatmap(data[corr_features].corr(),annot=True,linewidths=.3)\nplt.title('Correlation Between Features w Corr Threshold 0.75');","e820ab57":"data_melted = pd.melt(data,id_vars='target',var_name='features',value_name='value')\nax = plt.figure(figsize=(15,8))\nax = sns.boxplot(x='features',y='value',hue='target',data=data_melted,palette=palette)\nplt.xticks(rotation=90);\n# Because the data is not standardized here, it becomes a strange table, we will use it later.","483c954d":"# Pair plot is one of the most effective methods used in numerical data.\n# This will not look nice either, because the data needs to be standardized.\nsns.pairplot(data[corr_features],diag_kind='kde',markers='+',hue='target',palette=palette);\n# But I just used corr_features for images.","6f5437e6":"y = data['target']\nx = data.drop(['target'],axis=1)\ncolumns = x.columns.tolist()","d89f7ec8":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)\nx_score = clf.negative_outlier_factor_\noutlier_score = pd.DataFrame()\noutlier_score['score'] = x_score\noutlier_score.head()","295b03b2":"plt.figure(figsize=(8,5))\nplt.scatter(x.iloc[:,0],x.iloc[:,1],color='#29B3FF',s=3,label='Data Points')\nplt.legend();","05b82b8f":"radius = (x_score.max() - x_score) \/ (x_score.max() - x_score.min())","cb48069f":"plt.figure(figsize=(8,5))\nplt.scatter(x.iloc[:,0],x.iloc[:,1],color='#FBC00E',s=3,label='Data Points')\nplt.scatter(x.iloc[:,0],x.iloc[:,1],s=1000*radius,edgecolors='#29B3FF',facecolors='none',label='Outlier Scores')\nplt.legend()\nplt.show()","579fc05b":"# We are looking at contradictory observations.\nthreshold = -2.5\nfiltre = outlier_score['score'] < threshold\noutlier_index = outlier_score[filtre].index.tolist()\nplt.figure(figsize=(8,5))\nplt.scatter(x.iloc[outlier_index,0],x.iloc[outlier_index,1],color='#D55250',s=50,label='Outlier')\nplt.scatter(x.iloc[:,0],x.iloc[:,1],color='#FBC00E',s=3,label='Data Points')\nplt.scatter(x.iloc[:,0],x.iloc[:,1],s=1000*radius,edgecolors='#29B3FF',facecolors='none',label='Outlier Scores')\nplt.legend()\nplt.show()","50fd63db":"# Drop outliers\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values\n# All of these, there are a lot of other variables waiting for outlier observations for columns 0 and 1.","e959bf71":"# Train Test seperation\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)","53cc793c":"# Standart\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","7663b22c":"# Let's visualize boxplot that was not visualized before.\nx_train_df = pd.DataFrame(x_train,columns=columns)\nx_train_df['target'] = y_train\ndata_melted = pd.melt(x_train_df,id_vars='target',var_name='features',value_name='value')\nplt.figure(figsize=(15,8))\nsns.boxplot(x='features',y='value',hue='target',data=data_melted,palette=palette)\nplt.xticks(rotation=90)\nplt.show()","8d8fd4c8":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(x_train,y_train)\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nacc = accuracy_score(y_test,y_pred)\nscore = knn.score(x_test,y_test)\nprint('Score:',score)\nprint('Confusion Matrix:',cm)\nprint('Basic Accuracy Score:',acc)","c714707d":"def knn_best_params(x_train,x_test,y_train,y_test):\n    k_range = list(range(1,31))\n    weight_options = ['uniform','distance']\n    print()\n    param_grid = dict(n_neighbors = k_range,weights=weight_options)\n    knn = KNeighborsClassifier()\n    grid = GridSearchCV(knn,param_grid,cv=10,scoring='accuracy')\n    grid.fit(x_train,y_train)\n    print('Best Training Score {} with parameters: {}'.format(grid.best_score_,grid.best_params_))\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(x_train,y_train)\n    \n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n    cm_test = confusion_matrix(y_test,y_pred_test)\n    cm_train = confusion_matrix(y_train,y_pred_train)\n    acc_test = accuracy_score(y_test,y_pred_test)\n    acc_train = accuracy_score(y_train,y_pred_train)\n    print('Test Score: {},Train Score: {}'.format(acc_test,acc_train))\n    print()\n    print('Confusion Matrix Test: {}'.format(cm_test))\n    print('Confusion Matrix Train: {}'.format(cm_train))\n    \n    return grid","9594d4b5":"grid = knn_best_params(x_train,x_test,y_train,y_test)","0c7a154d":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)\npca = PCA(n_components=2)\npca.fit(x_scaled)\nx_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(x_reduced_pca,columns=['p1','p2'])\npca_data['target'] = y\nplt.figure(figsize=(8,5))\nsns.scatterplot(x='p1',y='p2',hue='target',data=pca_data,palette=palette)\nplt.title('PCA: p1 vs p2')\nplt.show()\n# We reduced 30 dimensional data to 2 dimensions with PCA.","9b919a79":"# Now we will do a chnn using 2 dimensional data.\nx_train_pca,x_test_pca,y_train_pca,y_test_pca = train_test_split(x_reduced_pca,y,test_size=0.3,random_state=42)\ngrid_pca = knn_best_params(x_train_pca,x_test_pca,y_train_pca,y_test_pca)","c5eb646a":"# We use a visualization to see how the split is decided.\ncmap_light = ListedColormap(['#FBC00E','#29B3FF'])\ncmap_bold = ListedColormap(['darkorange','darkblue'])\nh = .05\nX = x_reduced_pca\nx_min,x_max = X[:,0].min() -1,X[:,0].max() + 1\ny_min,y_max = X[:,1].min() -1 ,X[:,1].max() + 1\nxx,yy = np.meshgrid(np.arange(x_min,x_max,h),\n                   np.arange(y_min,y_max,h))\nZ = grid_pca.predict(np.c_[xx.ravel(),yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(10,8))\nplt.pcolormesh(xx,yy,Z,cmap=cmap_light)\nplt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,\n           edgecolors='k',s=20)\nplt.xlim(xx.min(),xx.max())\nplt.ylim(yy.min(),yy.max())\nplt.title(\"%i-Class Classification (k= %i,weights = '%s')\"%(len(np.unique(y)),grid_pca.best_estimator_.n_neighbors,grid_pca.best_estimator_.weights))","adcde2cb":"nca = NeighborhoodComponentsAnalysis(n_components=2,random_state=42)\nnca.fit(x_scaled,y)\nx_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(x_reduced_nca,columns=['p1','p2'])\nnca_data['target'] = y\nplt.figure(figsize=(10,8))\nsns.scatterplot(x='p1',y='p2',hue='target',data=nca_data,palette=palette)\nplt.title('NCA : p1 vs p2')\nplt.show()","8f7e68c8":"x_train_nca,x_test_nca,y_train_nca,y_test_nca = train_test_split(x_reduced_nca,y,test_size=0.3,random_state=42)\ngrid_nca = knn_best_params(x_train_nca,x_test_nca,y_train_nca,y_test_nca)","4cc9cfcb":"<center><h4 style=\"color:#4E5130;\">Our data consists of very different numbers, which affects our correct classification rate, so we need to standardize the data.<\/h4><\/center>","7eb2c156":"<center><h2 style=\"color:#4E5130;\">There is a distortion, we need to fix it.<\/h2><\/center>","42d83569":"<a id=\"10\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Status Summary\ud83d\udccc<\/h1><\/center>\n\n<center><h4 style=\"color:#4E5130;\">Yes we got a very high score as you can see.In real life problems these methods and algorithms work more or less like this.Here we just covered a problem for KNN, but I showed you a lot of algorithms, you can use them all.You just need to understand the problem correctly and make the right decisions.I did not explain too much while addressing the problem because I explained everything in detail in the tutorial.I hope this real life problem works for you too<\/h4><\/center>","9a6d4fff":"<a id=\"9\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">NCA\ud83d\ude80<\/h1><\/center>","52a37432":"<center><h4 style=\"color:#4E5130;\">Missing observations here and I will fix a few problems<\/h4><\/center>","4d520631":"<center><h4 style=\"color:#4E5130;\">In this section I will classify the data set we cleared.<\/h4><\/center>","e7e94feb":"<a id=\"3\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Cleaning Data And EDA\ud83e\uddf9<\/h1><\/center>","1d8adad7":"<a id=\"5\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Standardization And Seperation\ud83d\udd28<\/h1><\/center>","c448be70":"<a id=\"8\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Principal Component Analysis\ud83d\udd2c<\/h1><\/center>","c83d5720":"<a id=\"4\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Outliers\ud83e\uddfa<\/h1><\/center>","fa04892a":"<center><h1 style=\"color:#D55250;\">Breast Cancer Classification\ud83e\uddec<\/h1><\/center>\n<p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n    <p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n\n    \n\n\n<center><img src=\"https:\/\/image.flaticon.com\/icons\/png\/512\/2659\/2659980.png\" width=500><\/center>\n        <p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n            <p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n        \n        \n<center><h2 style=\"color:#E77A80;\">What is the Cancer?<\/h2><\/center>\n        <center><h4 style=\"color:#4E5130;\">Cancer is the name given to all associated diseases. In all types of cancer, some of the body cells begin to divide and spread to surrounding tissues. Cancer can start almost anywhere in the human body, made up of trillions of cells. Normally, human cells grow and multiply to form new cells when the body needs it. When cells become old or damaged, they die and new cells replace the dying cells.<\/h4><\/center>\n                <p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n                \n<center><h2 style=\"color:#E77A70;\">Cancer Treatment<\/h2><\/center>\n                \n<center><h4 style=\"color:#4E5130;\">Common treatment methods used in cancer are surgery, radiotherapy and chemotherapy. Less frequently, hormone therapies, biological therapies, and targeted therapies are used. These treatment methods are applied alone or together. The first treatment is generally known as first line treatment. Treatment given after first-line therapy is called adjuvant therapy. Chemotherapy applied after surgical treatment is an adjuvant treatment. Neoadjuvant therapy is the treatment applied before the first step treatment.<\/h4><\/center>\n                    <p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n                    \n                    \n<center><h2 style=\"color:#E77A80;\">Content<\/h2><\/center>\n\n[<center>Libarys\ud83d\udcda<\/center>](#1)\n\n[<center>Load Dataset\ud83d\udc68\u200d\ud83d\udd2c<\/center>](#2)\n\n[<center>Cleaning Data And EDA\ud83e\uddf9<\/center>](#3)\n                        \n[<center>Outliers\ud83e\uddfa<\/center>](#4)\n\n[<center>Standardization And Seperation\ud83d\udd28<\/center>](#5)\n\n[<center>Classification With K-Nearest Neighbors\ud83c\udf0c<\/center>](#6)\n                        \n[<center>K-Nearest Neighbors Optimization\ud83c\udfcb<\/center>](#7)\n                        \n[<center>Principal Component Analysis\ud83d\udd2c<\/center>](#8)\n                        \n[<center>NCA\ud83d\ude80<\/center>](#9)\n                        \n[<center>Status Summary\ud83d\udccc<\/center>](#10)\n                        \n<p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n<p>&#160;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p>\n                                \n                                \n                        \n<center><h2 style=\"color:#D55250;\">Important Note\u2757\ufe0f<\/h2><\/center>\n\n<center><h4 style=\"color:#4E5130;\">I posted all the processes I have done on the notebook called What is machine learning, you can access it in more detail from there.<\/h4><\/center>\n<center><h4 style=\"color:#4E5130;\">That's why I did not explain much while trading here. Good reading<\/h4><\/center>\n\n[<center>\u2699\ufe0fMachine Learning Tutorial For Beginners<\/center>](https:\/\/www.kaggle.com\/omercansvgn\/machine-learning-tutorial-for-beginners\/)","0d62ee78":"<a id=\"6\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Classification With K-Nearest Neighbors\ud83c\udf0c<\/h1><\/center>","09f28758":"<center><h4 style=\"color:#4E5130;\">We will perform the hyperparameter optimization process of our algorithm.<\/h4><\/center>","8cea04a3":"<center><h4 style=\"color:#4E5130;\">We will try to explain our results with fewer variables.<\/h4><\/center>","794b9476":"<a id=\"7\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">K-Nearest Neighbors Optimization\ud83c\udfcb\ud83c\udffb<\/h1><\/center>","bc60bd49":"<center><h3 style=\"color:#E77A80;\">Thank you for reading, don't forget to give upvote if you find it really useful, I wish you a pleasant day<\/h3><\/center>\n\n<center><img src=\"https:\/\/images.vexels.com\/media\/users\/3\/161144\/isolated\/preview\/8a71d12a40321402455aa974b63c44c1-thank-you-thanks-badge-sticker-by-vexels.png\" width=250><\/center>\n","a2225623":"<a id=\"2\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Load Dataset\ud83d\udc68\u200d\ud83d\udd2c<\/h1><\/center>","209c82c3":"<center><h4 style=\"color:#4E5130;\">Here we will examine outlier observations and deal with them.<\/h4><\/center>","5e1e56ed":"<a id=\"1\"><\/a> <br>\n<center><h1 style=\"color:#D55250;\">Libarys\ud83d\udcda<\/h1><\/center>"}}