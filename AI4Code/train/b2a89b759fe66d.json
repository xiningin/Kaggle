{"cell_type":{"538badf3":"code","4f42f495":"code","9e10cab1":"code","5ce97a61":"code","48073e90":"code","3921a6c6":"code","fd9089d8":"code","b047a19b":"code","2375a014":"code","31823bf8":"code","2fe666db":"code","f69b3574":"code","7d64b74a":"code","b6fb6331":"code","83ebd973":"code","3b54bd5c":"code","6a2935b6":"code","3a964d90":"code","55c577c1":"code","25ed5302":"code","28f2303e":"code","d377b71a":"code","3947bccb":"code","997fb7f9":"code","103d26af":"code","b1f439c4":"code","4af9f2ed":"code","b8b2d602":"code","312f9a7e":"code","1cc657a5":"markdown","a6494b52":"markdown","aadd6779":"markdown","e9e66117":"markdown"},"source":{"538badf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom fastai import *\nfrom fastai.vision import *\n\nimport torchvision\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom time import time\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom IPython.display import HTML\nimport base64\n\nimport PIL\n\n# Any results you write to the current directory are saved as output.","4f42f495":"# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","9e10cab1":"def imagify(tensor):\n    reshaped = tensor.reshape(-1, 28, 28)\n    print(reshaped.shape)\n    reshaped = np.stack((reshaped,) *3, axis = 1)\n    print(reshaped.shape)\n    image_arr = []\n\n    for idx, current_image in enumerate(reshaped):\n        img = torch.tensor(current_image, dtype=torch.float) \/ 255.\n        img = vision.image.Image(img)\n        image_arr.append(img)\n    return image_arr\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# Unused. Old implementation\ndef save_images(pathBase, images, labels=None, is_test=False):\n    for idx in range(len(images)):\n        fPathBase = f'\/tmp\/{pathBase}'\n        label = None\n        base = None\n        if not is_test:\n            label = labels[idx]\n            fPathBase = f'{fPathBase}\/{label}'\n            base = time() * 1000\n        else:\n            base = '{0:05d}'.format(idx + 1)\n        image = images[idx]\n        image = torch.tensor(image)\n        image = vision.image.Image(image)\n        #image.show()\n        if not os.path.exists(fPathBase):\n            os.makedirs(fPathBase)\n        image.save(f'{fPathBase}\/{base}.png')\n\n    Path(fPathBase).ls()\n\ndef split_data(data, labels, pct=0.8):\n    train_xl = []\n    train_yl = []\n    valid_xl = []\n    valid_yl = []\n\n    for img, label in zip(data, labels):\n        if random.random() >= pct:\n            valid_xl.append(img)\n            valid_yl.append(label)\n        else:\n            train_xl.append(img)\n            train_yl.append(label)\n    \n    return train_xl, train_yl, valid_xl, valid_yl\n\ndef create_label_lists(train_xl, train_yl, valid_xl, valid_yl):\n    train_xl = TensorImageList(train_xl)\n    train_yl = CategoryList(train_yl, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n    valid_xl = TensorImageList(valid_xl)\n    valid_yl = CategoryList(valid_yl, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n    \n    train_ll = LabelList(train_xl, train_yl)\n    valid_ll = LabelList(valid_xl, valid_yl)\n    \n    return LabelLists(Path('.'), train_ll, valid_ll)\n\nclass TensorImageList(ImageList):\n    def get(self, i):\n        img = self.items[i]\n        self.sizes[i] = img.size\n        return img","5ce97a61":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","48073e90":"labels = df_train.iloc[:,0].values.flatten()\nimages = imagify(df_train.iloc[:,1:].values)","3921a6c6":"train_xl, train_yl, valid_xl, valid_yl = split_data(images, labels, 0.9)","fd9089d8":"test_xl = imagify(df_test.values)\ntest_xl = TensorImageList(test_xl)","b047a19b":"lls = create_label_lists(train_xl, train_yl, valid_xl, valid_yl)","2375a014":"#tfms = get_transforms(do_flip=False, max_rotate=20, xtra_tfms=rand_pad(2, 28))","31823bf8":"#tfms = (tfms[0], [])\ntfms = (rand_pad(2, 28), [])","2fe666db":"mnist_data = ImageDataBunch.create_from_ll(lls, ds_tfms=tfms)","f69b3574":"mnist_data.add_test(test_xl)","7d64b74a":"mnist_data.show_batch()","b6fb6331":"arch = models.resnet50 # because why not?\nlearner = cnn_learner(mnist_data, arch, metrics=[accuracy])","83ebd973":"learner.lr_find()\nlearner.recorder.plot()","3b54bd5c":"lr = 1e-3","6a2935b6":"learner.fit_one_cycle(10, lr)","3a964d90":"# Accuracy Plot:\nlearner.recorder.plot_metrics()","55c577c1":"# Losses Plot\nlearner.recorder.plot_losses()","25ed5302":"learner.save('mnist-1') #0.994268","28f2303e":"learner.lr_find()\nlearner.recorder.plot()","d377b71a":"learner.unfreeze()","3947bccb":"learner.fit_one_cycle(10, slice(1e-6, lr\/5))","997fb7f9":"learner.save('mnist-2') #0.995119","103d26af":"c_interpret = ClassificationInterpretation.from_learner(learner)\nc_interpret.plot_top_losses(12)","b1f439c4":"preds = learner.get_preds(ds_type=DatasetType.Test)","4af9f2ed":"pred_values = preds[0].argmax(1).numpy()","b8b2d602":"submission = DataFrame({'ImageId': list(range(1, len(pred_values) + 1)), 'Label': pred_values})\nsubmission.head()","312f9a7e":"#create_download_link(submission)","1cc657a5":"It turns out, even a human would have quite a hard time recognizing some of the numbers above.","a6494b52":"We're looking for the good `lr` which is where the loss appears to go down the most","aadd6779":"Now that we're done training, let's see which of the training data constitutes our biggest losses.","e9e66117":"# Digit Recognizer with fast.ai v3\n\n## Introduction\nThis is just the regular MNIST done using fast.ai V3\n\nSince the library doesn't have an easy way to deal with the input format here (arrays in CSV), we'll have to go through a roundabout route and create the images so that fast.ai will have an easier time reading it through it's Data Block API\n\n## Process\n1. Convert the CSV to vision.image.Image\n2. Create a Databunch using the custom list, TensorImageList\n3. Train the model\n4. Predict the outcome\n\n## Note\nPlease forgive me if this notebook isn't optimized. This is my first one ever in Kaggle and I'm only starting to get used to the environment."}}