{"cell_type":{"1e89c63b":"code","924ed367":"code","efe4727a":"code","f2c4cae5":"code","ea2c8c59":"code","57320d95":"code","35c0dad7":"code","c0f28b46":"code","aa630e06":"code","f004b2f4":"code","f24f2926":"code","ed77c95a":"code","6edd1efe":"code","101d2277":"markdown","30d0ac90":"markdown","895a7016":"markdown","bf122386":"markdown","3ad71452":"markdown","00164a6c":"markdown","c50c8ca2":"markdown","2b969a9a":"markdown","b2dd4593":"markdown","3ec35cf9":"markdown","59c3720b":"markdown","db822153":"markdown","09b15219":"markdown"},"source":{"1e89c63b":"import os\nimport numpy as np\nimport cv2 as cv # pip install opencv-python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.layers import Input, Reshape, Dense, Flatten, Activation, Conv2D, UpSampling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\n\n%matplotlib inline","924ed367":"# Image data directory path \u691c\u8a3c\u7528\u753b\u50cf\u30c7\u30fc\u30bf\u30d5\u30a1\u30a4\u30eb\u306e\u683c\u7d0d\u30d1\u30b9\nimage_path = '..\/input'\n# Print data category (Only \"pokemon\" will be printed) \u30ab\u30c6\u30b4\u30ea\u540d\u3092\u53d6\u5f97\uff08 \"pokemon\" \u306e\u307f\u3068\u306a\u308b\u60f3\u5b9a\uff09\nclasses = os.listdir(image_path)\n#print(classes)\n\nprint(f'Total number of categories: {len(classes)}')\n\nX_train = [] # List for images\n\n# Image size \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u30b5\u30a4\u30ba\nimage_size = 64\nimage_width = image_size\nimage_height = image_size\n\n# Image plot limit \u8868\u793a\u3059\u308b\u753b\u50cf\u30b5\u30f3\u30d7\u30eb\u6570\nplot_limit = 20\n# \u753b\u50cf\u8868\u793a\u9818\u57df\u306e\u30b5\u30a4\u30ba\u3001\u30b0\u30ea\u30c3\u30c9\ndim=(4,5)\nfigsize=(16,8)\n\nplt.figure(figsize=figsize)\n\n# A dictionary which contains class and number of images in that class\ncounts = {}\nfor c in classes:\n    if c == \".DS_Store\": # Only on Mac environment\n        continue\n\n    image_class_path = os.path.join(image_path, c)\n\n    # Count image files\n    image_files = os.listdir(image_class_path)\n    #print(image_files)\n    counts[c] = len(image_files)\n    \n    count = 0\n    for image_file in image_files:\n        image = cv.imread(os.path.join(image_class_path, image_file))\n\n        try:\n            resized = cv.resize(image, (image_width, image_height)) # Resizing images to (image_width, image_height)\n            X_train.append(resized) # Adds resized image data to list\n            \n            # Print image data sample\n            if count < plot_limit:\n                plt.subplot(dim[0],dim[1],count+1)\n                plt.imshow(resized)\n                plt.axis('off')\n\n            image = None\n            count = count + 1\n            \n        # If we can't read image - we skip it\n        except:\n            print(os.path.join(image_class_path, image_file), '[ERROR] can\\'t read the file')\n            image = None\n            continue\n\nplt.tight_layout()\nplt.show()","efe4727a":"# Number of images in each clsss plot\nfig = plt.figure(figsize = (25, 5))\nsns.barplot(x = list(counts.keys()), y = list(counts.values())).set_title('Number of images in each class')\nplt.xticks(rotation = 90)\nplt.margins(x=0)\nplt.show()\n\nprint(f'Total number of images in dataset: {sum(list(counts.values()))}')","f2c4cae5":"# Convert list with images to numpy array and reshape it \nX_train = np.array(X_train).reshape(-1, image_width, image_height, 3)\nprint(X_train.shape)\n\n# Scaling data in array\nX_train = X_train \/ 255.0","ea2c8c59":"# @param width: int(image_width \/ 2)\n# @param height: int(image_height) \/ 2)\ndef Generator(width, height):\n    nch = 200\n    model_input = Input(shape=[100])\n    #x = Dense(nch*14*14, kernel_initializer='glorot_normal')(model_input) # 100 -> 200*14*14\n    x = Dense(nch*width*height, kernel_initializer='glorot_normal')(model_input) # 100 -> 200*64*64\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    #x = Reshape( [14, 14, nch] )(x) # 200*14*14 -> 14x14x200 (width)x(height)x(channel)\n    x = Reshape( [width, height, nch] )(x) # 200*64*64 -> 64x64x200 (width)x(height)x(channel)\n    x = UpSampling2D(size=(2, 2))(x) # 64x64x200 -> 128x128x200 \/\/ # 14x14x200 -> 28x28x200\n    x = Conv2D(int(nch\/2), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 128x128x200 -> 128x128x100 \/\/ # 28x28x200 -> 28x28x100\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(int(nch\/4), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 128x128x100 -> 128x128x50 \/\/ # 28x28x100 -> 28x28x50\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    #x = Conv2D(1, (1, 1), padding='same', kernel_initializer='glorot_uniform')(x) # 28x28x50 -> 28x28x1\n    x = Conv2D(3, (1, 1), padding='same', kernel_initializer='glorot_uniform')(x) # 128x128x50 -> 128x128x3\n    model_output = Activation('sigmoid')(x)\n    model = Model(model_input, model_output)\n    \n    print(\"#### Generator: \")\n    model.summary()\n    \n    return model","57320d95":"def Discriminator(shape, dropout_rate=0.25, opt=Adam(lr=1e-4)):\n    model_input = Input(shape=shape) # 128x128x3 \/\/ # 28x28x1\n    x = Conv2D(256, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(model_input) # 128x128x3 -> 64x64x256 \/\/ # 28x28x1 -> 14x14x256\n    x = LeakyReLU(0.2)(x)\n    x = Dropout(dropout_rate)(x)\n    x = Conv2D(512, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(x) # 64x64x256 -> 32x32x512 \/\/ # 14x14x256 -> 7x7x512\n    x = LeakyReLU(0.2)(x)\n    x = Dropout(dropout_rate)(x)\n    x = Flatten()(x) # 32x32x512 -> 32*32*512 \/\/ # 7x7x512 -> 7*7*512\n    x = Dense(256)(x) # 32*32*512 -> 256 \/\/ # 7*7*512 -> 256\n    x = LeakyReLU(0.2)(x)\n    x = Dropout(dropout_rate)(x)\n    model_output = Dense(2,activation='softmax')(x) # 256 -> 2\n    model = Model(model_input, model_output)\n    model.compile(loss='categorical_crossentropy', optimizer=opt)\n    \n    print(\"#### Discriminator: \")\n    model.summary()\n    \n    return model","35c0dad7":"generator = Generator(int(image_width \/ 2), int(image_height \/ 2))\n#print(X_train.shape[1:])\ndiscriminator = Discriminator(X_train.shape[1:])","c0f28b46":"def combined_network(generator, discriminator, opt=Adam(lr=1e-3)):\n    gan_input = Input(shape=[100])\n    x = generator(gan_input)\n    gan_output = discriminator(x)\n    model = Model(gan_input, gan_output)\n    model.compile(loss='categorical_crossentropy', optimizer=opt)\n    # model.summary()\n    \n    return model","aa630e06":"def make_trainable(net, val):\n    net.trainable = val\n    for l in net.layers:\n        l.trainable = val","f004b2f4":"def train(step=3000, BATCH_SIZE=128):\n    for e in tqdm(range(step)):\n        # 1. \u30d0\u30c3\u30c1\u306e\u5b66\u7fd2\u3067\u5229\u7528\u3059\u308b\u753b\u50cf\u306e\u9078\u629e \n        # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306e\u5206\u3060\u3051\u30e9\u30f3\u30c0\u30e0\u306b\u753b\u50cf\u3092\u9078\u629e\n        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]\n        \n        # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306e\u5206\u3060\u3051\u30e9\u30f3\u30c0\u30e0\u306b\u30ce\u30a4\u30ba\u3092\u751f\u6210\u3057\u3001generator\u306b\u3088\u308a\u753b\u50cf\u3092\u751f\u6210\n        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n        generated_images = generator.predict(noise_gen)\n        \n        # 2. Discriminator\u306e\u5b66\u7fd2\u3092on\u306b\u5207\u308a\u66ff\u3048\u308b\n        # Discriminator\u304c\u5b66\u7fd2\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\n        make_trainable(discriminator,True)\n        \n        # 3. Generator\u306b\u3088\u308b\u751f\u6210\u753b\u50cf\u3092\u7528\u3044\u3066Discriminator\u306e\u5b66\u7fd2\n        # X = (\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u5206\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u753b\u50cf, \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u5206\u306e\u751f\u6210\u753b\u50cf)\n        X = np.concatenate((image_batch, generated_images))\n        \n        # y = (\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u5206\u306eTrue(\u672c\u7269), \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u5206\u306eFalse(\u507d\u7269))\n        y = np.zeros([2*BATCH_SIZE,2])\n        y[:BATCH_SIZE,1] = 1\n        y[BATCH_SIZE:,0] = 1      \n        \n        # Discriminator\u306etrain\n        discriminator.train_on_batch(X,y)\n        \n        # 4. Discriminator\u306e\u5b66\u7fd2\u3092off\u306b\u5207\u308a\u66ff\u3048\u308b\n        # Discriminator\u304c\u5b66\u7fd2\u3057\u306a\u3044\u3088\u3046\u306b\u5909\u66f4\n        make_trainable(discriminator,False)\n    \n        # 5. Generator\u306e\u5b66\u7fd2\n        # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306e\u5206\u3060\u3051\u30e9\u30f3\u30c0\u30e0\u306b\u30ce\u30a4\u30ba\u3092\u751f\u6210\n        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n        \n        # y = (\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u5206\u306eTrue(\u672c\u7269))\n        # \u5b9f\u969b\u306b\u306f\u751f\u6210\u3057\u305f\u753b\u50cf\u306a\u306e\u3067Discriminator\u3068\u3057\u3066\u306f\u507d\u7269\u3068\u5224\u65ad\u3059\u3079\u304d\u3060\u304c\u3001Genarator\u306e\u5b66\u7fd2\u306a\u306e\u3067\u751f\u6210\u3057\u305f\u753b\u50cf\u3092\u672c\u7269\u3068\u5224\u65ad\u3059\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3055\u305b\u308b\n        y2 = np.zeros([BATCH_SIZE,2])\n        y2[:,1] = 1\n        \n        # Generator\u306etrain\n        GAN.train_on_batch(noise_gen, y2 )","f24f2926":"make_trainable(discriminator, False)\nGAN = combined_network(generator, discriminator)","ed77c95a":"train(step=2000)","6edd1efe":"n_ex=plot_limit\n\nnoise = np.random.uniform(0,1,size=[n_ex,100])\ngenerated_images = generator.predict(noise)\n\nplt.figure(figsize=figsize)\nfor i in range(generated_images.shape[0]):\n    plt.subplot(dim[0],dim[1],i+1)\n    img = generated_images[i,:,:, 0]\n    plt.imshow(img)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","101d2277":"# Prepare","30d0ac90":"# Generator\n\nGenerator \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u95a2\u6570\u3092\u5b9a\u7fa9\u3059\u308b  \nGenerator \u306f\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u751f\u6210\u3057\u305f\u30ce\u30a4\u30ba\u304b\u3089\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u3042\u308b\u3088\u3046\u306a\u672c\u7269\u3089\u3057\u3044\u753b\u50cf\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u76ee\u7684  \nGenerator \u304c\u51fa\u529b\u3057\u305f\u753b\u50cf\u3092\u3001Descriminator \u304c\u672c\u7269\u3068\u52d8\u9055\u3044\u3059\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3055\u305b\u308b\n","895a7016":"# Load \/ Plot data\n\n\u5b66\u7fd2\u30fb\u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u3001\u8868\u793a","bf122386":"# Generate and plot data\n\n\u753b\u50cf\u3092\u751f\u6210\u3057\u3066\u8868\u793a","3ad71452":"# Count data\n\n\u753b\u50cf\u30c7\u30fc\u30bf\u6570\u3092\u30ab\u30a6\u30f3\u30c8","00164a6c":"# Train function\n\n\u5b66\u7fd2\u3092\u5b9f\u969b\u306b\u5b9f\u884c\u3059\u308b\u95a2\u6570","c50c8ca2":"# Controll GAN training function\n\ncombined_network \u95a2\u6570\u3067 Generator \u306e\u5b66\u7fd2\u3092\u76ee\u7684\u3068\u3059\u308b\u5834\u5408\u3001Discriminator \u304c\u4e00\u7dd2\u306b\u5b66\u7fd2\u3057\u3066\u3057\u307e\u308f\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b","2b969a9a":"# Adjust \/ Convert data\n\n\u5b66\u7fd2\u306e\u51e6\u7406\u7528\u306b\u30c7\u30fc\u30bf\u3092\u8abf\u6574","b2dd4593":"# Discriminator\n\nDiscriminator \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u95a2\u6570\u3092\u5b9a\u7fa9\u3059\u308b  \n\u5143\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u753b\u50cf\u304c\u5165\u529b\u3055\u308c\u308c\u3070\u3001\u672c\u7269\u3067\u3042\u308b\u3001Generator \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u753b\u50cf\u306f\u507d\u7269\u3067\u3042\u308b\u3001\u3068\u5224\u5b9a\u3059\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3055\u305b\u308b","3ec35cf9":"# Load libraries\n\n\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u8aad\u307f\u8fbc\u3080","59c3720b":"# Initialize Generator, Discriminator\n\nGenerator\u3001Discriminator \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210","db822153":"# Train GAN function\n\nGenerator \u306e\u5b66\u7fd2\u6642\u306b\u5229\u7528\u3059\u308b\u95a2\u6570  \nGenerator \u3068 Discriminator \u3092\u3064\u306a\u3052\u305f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u5b66\u7fd2\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b","09b15219":"# Train\n\n\u5b66\u7fd2\u3092\u5b9f\u884c"}}