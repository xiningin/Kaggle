{"cell_type":{"4ba2e370":"code","b0541ea4":"code","17c2a1d7":"code","3bcb5b22":"code","59f0b607":"code","cb452298":"code","9b150f57":"code","2b22d50e":"code","fca8bdcf":"code","f27bde8d":"code","0584b526":"code","9773dcb2":"code","63ddb5c0":"code","ae965913":"markdown","410ab4db":"markdown","0d24e8ef":"markdown","5c0ced13":"markdown","20e11141":"markdown","6b8ef212":"markdown","5051c491":"markdown","d90bdbf4":"markdown","90ac0deb":"markdown","a3f0f3bb":"markdown","109abc90":"markdown","9eb68351":"markdown"},"source":{"4ba2e370":"import numpy as np # MATRIX OPERATIONS\nimport pandas as pd # EFFICIENT DATA STRUCTURES\nimport matplotlib.pyplot as plt # GRAPHING AND VISUALIZATIONS\nimport math # MATHEMATICAL OPERATIONS\nimport cv2 # IMAGE PROCESSING - OPENCV\nfrom glob import glob # FILE OPERATIONS\nimport itertools # Efficient looping\n\n# KERAS AND SKLEARN MODULES\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# GLOBAL VARIABLES\nscale = 70 # px to scale\nseed = 7 # fixing random","b0541ea4":"path_to_images = '..\/input\/plant-seedlings-classification\/train\/*\/*.png'\nimages = glob(path_to_images)\ntrainingset = []\ntraininglabels = []\nnum = len(images)\ncount = 1\n#READING IMAGES AND RESIZING THEM\nfor i in images:\n    print(str(count)+'\/'+str(num),end='\\r')\n    # Get image (with resizing)\n    trainingset.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    # Get image label (folder name)\n    traininglabels.append(i.split('\/')[-2])\n    count=count+1\ntrainingset = np.asarray(trainingset) # Train images set\ntraininglabels = pd.DataFrame(traininglabels) # Train labels set","17c2a1d7":"# Show some example images\nfor i in range(8):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(trainingset[i])","3bcb5b22":"new_train = []\nsets = []; getEx = True\nfor i in trainingset:\n        # Use gaussian blur\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n        # Convert to HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    \n    # Create mask (parameters - green color range)\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n       # Create bool mask\n    boolean = mask>0\n    \n        # Apply the mask\n    new = np.zeros_like(i,np.uint8) # Create empty image\n    new[boolean] = i[boolean] # Apply boolean mask to the origin image\n    \n    new_train.append(new) # Append image without backgroung\n    \n     # Show examples\n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE without background\n        plt.show()\n        getEx = False\nnew_train = np.asarray(new_train)\n\n\nprint('Most of the background removed:')\n    \n# Show sample result\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    plt.imshow(new_train[i])","59f0b607":"# Encode labels and create classes\nlabels = preprocessing.LabelEncoder()\nlabels.fit(traininglabels[0])\nprint('Classes: '+str(labels.classes_))\nencodedlabels = labels.transform(traininglabels[0])\n\n# Make labels categorical\nclearalllabels = np_utils.to_categorical(encodedlabels)\nclasses = clearalllabels.shape[1]\nprint(\"Number of classes: \" + str(classes))\n    \n# Plot of label types numbers\ntraininglabels[0].value_counts().plot(kind='pie')","cb452298":"new_train = new_train\/255 # Normalize input [0...255] to [0...1]\n\nx_train,x_test,y_train,y_test = train_test_split(new_train,clearalllabels,test_size=0.1,random_state=seed,stratify=clearalllabels)\nprint('Train Shape: {}'.format(x_train.shape))","9b150f57":"generator = ImageDataGenerator(\n    rotation_range = 180, # randomly rotate images in the range\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range = 0.1, # randomly shift images horizontally\n    height_shift_range = 0.1, # randomly shift images vertically \n    horizontal_flip = True, # randomly flip images horizontally\n    vertical_flip = True # randomly flip images vertically\n)\ngenerator.fit(x_train)","2b22d50e":"np.random.seed(seed) # Fix seed\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(scale, scale, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(classes, activation='softmax'))\n\n# compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()\n\n","fca8bdcf":"# learning rate reduction\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                        patience=3, \n                        verbose=1, \n                        factor=0.4, \n                        min_lr=0.00001)\n\n# checkpoints\nfilepath='weights.best_{epoch:02d}-{val_acc:.2f}.h5'\ncheckpoints = ModelCheckpoint(filepath, monitor='val_acc', \n                              verbose=1, save_best_only=True, mode='max')\nfilepath='weights.last_auto4.h5'\ncheckpoints_full = ModelCheckpoint(filepath, monitor='val_acc', \n                                 verbose=1, save_best_only=False, mode='max')\n\n# all callbacks\ncallbacks_list = [checkpoints, lrr, checkpoints_full]\n\n# fit model\n#hist = model.fit_generator(generator.flow(x_train, y_train, batch_size=75),\n#                            epochs=35,\n#                            validation_data=(x_test, y_test),\n#                            steps_per_epoch=x_train.shape[0],\n#                            callbacks=callbacks_list\n#                           )\n\n# Evaluate model\n# LOADING MODEL\nmodel.load_weights(\"..\/input\/weights\/weights.best_17-0.96.hdf5\") # best fitting model\ndataset = np.load(\"..\/input\/plantrecomodels\/Data.npz\") # Training and validation datasets\ndata = dict(zip((\"x_train\",\"x_test\",\"y_train\", \"y_test\"), (dataset[k] for k in dataset)))\nx_train = data['x_train']\nx_test = data['x_test']\ny_train = data['y_train']\ny_test = data['y_test']\n\nprint(model.evaluate(x_train, y_train))  # Evaluate on train set\nprint(model.evaluate(x_test, y_test))  # Evaluate on test set","f27bde8d":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\npredY = model.predict(x_test)\npredYClasses = np.argmax(predY, axis = 1) \ntrueY = np.argmax(y_test, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, predYClasses) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_)","0584b526":"path_to_test = '..\/input\/plant-seedlings-classification\/test\/*.png'\npics = glob(path_to_test)\n\ntestimages = []\ntests = []\ncount=1\nnum = len(pics)\n\n# Obtain images and resizing, obtain labels\nfor i in pics:\n    print(str(count)+'\/'+str(num),end='\\r')\n    tests.append(i.split('\/')[-1]) # Images id's\n    testimages.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    count = count + 1\n\ntestimages = np.asarray(testimages) # Train images set \n\nfor i in range(8):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(testimages[i])","9773dcb2":"newtestimages = []\nsets = []\ngetEx = True\nfor i in testimages:\n        # Use gaussian blur\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n        # Convert to HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    \n        # Create mask (parameters - green color range)\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n        # Create bool mask\n    boolean = mask>0\n    \n        # Apply the mask\n    masking = np.zeros_like(i,np.uint8) # Create empty image\n    masking[boolean] = i[boolean] # Apply boolean mask to the origin image\n    \n    # Append image without backgroung\n    newtestimages.append(masking)\n    \n        # Show examples\n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # Show the original image\n        plt.subplot(2,3,2);plt.imshow(blurr) # Blur image\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV image\n        plt.subplot(2,3,4);plt.imshow(mask) # Mask\n        plt.subplot(2,3,5);plt.imshow(boolean) # Boolean mask\n        plt.subplot(2,3,6);plt.imshow(masking) # Image without background\n        plt.show()\n        getEx=False\n\nnewtestimages = np.asarray(newtestimages)\n\n# OTHER MASKED IMAGES\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(newtestimages[i])","63ddb5c0":"newtestimages=newtestimages\/255\nprediction = model.predict(newtestimages)\n\n# Write prediction result to a file\npred = np.argmax(prediction,axis=1)\npredStr = labels.classes_[pred]\n\nresult = {'file':tests,'species':predStr}\nresult = pd.DataFrame(result)\nresult.to_csv(\"Prediction.csv\",index=False)\nprint('Prediction result saved as Prediction.csv')","ae965913":"**4. \u062a\u0628\u062f\u06cc\u0644 \u0628\u0631\u0686\u0633\u0628 \u0647\u0627 \u0628\u0647 \u0622\u0631\u0627\u06cc\u0647 \u0647\u0627\u06cc \u0639\u062f\u062f\u06cc**\n* \u0628\u0631\u0686\u0633\u0628 \u0647\u0627 \u0628\u0647 \u0635\u0648\u0631\u062a \u0631\u0634\u062a\u0647 \u0647\u0633\u062a\u0646\u062f \u0648 \u067e\u0631\u062f\u0627\u0632\u0634 \u06a9\u0627\u0631\u0627\u06a9\u062a\u0631\u0647\u0627 \u0633\u062e\u062a \u0627\u0633\u062a\u060c \u0628\u0646\u0627\u0628\u0631\u06cc\u0646 \u0631\u0634\u062a\u0647 \u0647\u0627 \u0631\u0627 \u0628\u0647 \u062f\u0633\u062a\u0647 \u0647\u0627\u06cc \u062f\u0648\u062f\u0648\u06cc\u06cc \u062a\u0628\u062f\u06cc\u0644 \u0645\u06cc\u06a9\u0646\u06cc\u0645.\n* \u062f\u0633\u062a\u0647 \u0628\u0646\u062f\u06cc \u0645\u06cc\u062a\u0648\u0627\u0646\u062f \u062f\u0631 \u0642\u0627\u0644\u0628 \u0622\u0631\u0627\u06cc\u0647 \u0627\u06cc 12 \u0631\u0642\u0645\u06cc \u0628\u0627 \u0634\u0631\u0627\u06cc\u0637 \u0632\u06cc\u0631 \u0627\u0639\u0645\u0627\u0644 \u0634\u0648\u062f:\n    * 0 - \u0627\u06af\u0631 \u06af\u0648\u0646\u0647 \u0634\u0646\u0627\u0633\u0627\u06cc\u06cc \u0646\u0634\u062f.\n    * 1 - \u0627\u06af\u0631 \u06af\u0648\u0646\u0647 \u0634\u0646\u0627\u0633\u0627\u06cc\u06cc \u0634\u062f.\n* \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062b\u0627\u0644: \u0627\u06af\u0631 \u06af\u0648\u0646\u0647 \u06cc \u0627\u0648\u0644 \u06cc\u0627 \u0628\u0644\u06a9 \u06af\u0631\u0633 \u062a\u0634\u062e\u06cc\u0635 \u062f\u0627\u062f\u0647 \u0634\u062f \u0628\u0631\u0686\u0633\u0628 \u0628\u0647 \u0635\u0648\u0631\u062a \u0645\u0642\u0627\u0628\u0644 \u062e\u0648\u0627\u0647\u062f \u0628\u0648\u062f = [1,0,0,0,0,0,0,0,0,0,0,0]","410ab4db":"**6. \u062c\u0644\u0648\u06af\u06cc\u0631\u06cc \u0627\u0632 \u0628\u06cc\u0634 \u0628\u0631\u0627\u0632\u0634**\n* \u062c\u0647\u062a \u062c\u0644\u0648\u06af\u06cc\u0631\u06cc \u0627\u0632 \u0628\u06cc\u0634 \u0628\u0631\u0627\u0632\u0634 \u06cc\u0627 \u0622\u0648\u0631\u0641\u06cc\u062a\u06cc\u0646\u06af \u062a\u0627\u0628\u0639\u06cc \u0637\u0631\u0627\u062d\u06cc \u0645\u06cc\u06a9\u0646\u06cc\u0645 \u06a9\u0647 \u0628\u0647 \u0635\u0648\u0631\u062a \u062a\u0635\u0627\u062f\u0641\u06cc \u062a\u063a\u06cc\u06cc\u0631\u0627\u062a\u06cc \u0627\u0632 \u0642\u0628\u06cc\u0644 \u0686\u0631\u062e\u0634\u060c \u0628\u0632\u0631\u06af\u0646\u0645\u0627\u06cc\u06cc\u060c \u0634\u06cc\u0641\u062a \u0648 \u0628\u0631\u06af\u0631\u062f\u0627\u0646\u062f\u0646 \u0631\u0648\u06cc \u062a\u0635\u0627\u0648\u06cc\u0631 \u0627\u0639\u0645\u0627\u0644 \u06a9\u0646\u062f \u0648 \u0645\u0634\u062e\u0635\u0627\u062a \u062a\u0635\u0648\u06cc\u0631 \u062d\u06cc\u0646 \u0628\u0631\u0627\u0632\u0634 \u062a\u063a\u06cc\u06cc\u0631 \u06cc\u0627\u0628\u062f.\n\n   * \u062a\u0646\u0638\u06cc\u0645 \u0686\u0631\u062e\u0634 \u062a\u0635\u0627\u062f\u0641\u06cc \u0627\u0632 0 \u062a\u0627 180 \u062f\u0631\u062c\u0647\n   * \u062a\u0646\u0638\u06cc\u0645 \u0628\u0632\u0631\u06af\u0646\u0645\u0627\u06cc\u06cc \u062a\u0635\u0627\u062f\u0641\u06cc \u0628\u0647 \u0645\u06cc\u0632\u0627\u0646 0.1\n   * \u062a\u0646\u0638\u06cc\u0645 \u062c\u0627\u0628\u062c\u0627\u06cc\u06cc \u062a\u0635\u0627\u062f\u0641\u06cc \u0628\u0647 \u0645\u06cc\u0632\u0627\u0646 0.1\n   * \u062a\u0646\u0638\u06cc\u0645 \u062d\u0627\u0644\u062a \u0622\u06cc\u0646\u0647 \u06cc \u0627\u0641\u0642\u06cc \u0648 \u0639\u0645\u0648\u062f\u06cc","0d24e8ef":"**5. \u062a\u0639\u0631\u06cc\u0641 \u0645\u062f\u0644 \u0648 \u062c\u062f\u0627\u0633\u0627\u0632\u06cc \u062f\u06cc\u062a\u0627\u0633\u062a:**\n* \u0645\u06cc \u062e\u0648\u0627\u0647\u06cc\u0645 \u0628\u062e\u0634\u06cc \u0627\u0632 \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc \u0622\u0645\u0648\u0632\u0634 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0627\u0639\u062a\u0628\u0627\u0631\u0633\u0646\u062c\u06cc \u06cc\u0627 \u0648\u0644\u06cc\u062f\u06cc\u0634\u0646 \u0627\u062e\u062a\u0635\u0627\u0635 \u062f\u0647\u06cc\u0645.\n\n\u062f\u0647 \u062f\u0631\u0635\u062f \u0627\u0632 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062c\u0645\u0648\u0639\u0647 \u06cc \u0627\u0639\u062a\u0628\u0627\u0631\u0633\u0646\u062c\u06cc \u062a\u062e\u0635\u06cc\u0635 \u0645\u06cc\u0627\u0628\u062f.\n\u062f\u0627\u062f\u0647 \u0647\u0627 \u0628\u0647 \u0635\u0648\u0631\u062a \u0646\u0627\u0645\u062a\u0648\u0627\u0632\u0646 \u0627\u0646\u062f\u060c \u0628\u0631\u0627\u06cc \u062c\u0644\u0648\u06af\u06cc\u0631\u06cc \u0627\u0632 \u06a9\u0627\u0647\u0634 \u062f\u0642\u062a \u0627\u0631\u0632\u06cc\u0627\u0628\u06cc:","5c0ced13":"**9. \u0645\u0627\u062a\u0631\u06cc\u0633 \u067e\u0631\u0627\u06a9\u0646\u062f\u06af\u06cc**\n* \u0645\u0627\u062a\u0631\u06cc\u0633 \u067e\u0631\u0627\u06a9\u0646\u062f\u06af\u06cc \u0631\u0627\u0647 \u0645\u0646\u0627\u0633\u0628\u06cc \u0628\u0631\u0627\u06cc \u062a\u0634\u062e\u06cc\u0635 \u062e\u0637\u0627\u0647\u0627\u06cc \u0645\u062f\u0644 \u0627\u0633\u062a.\n* \u0628\u0647 \u0637\u0648\u0631\u06cc \u06a9\u0647 \u0645\u0642\u062f\u0627\u0631 \u062f\u0642\u06cc\u0642 \u067e\u06cc\u0634 \u0628\u06cc\u0646\u06cc \u0647\u0627\u06cc \u062f\u0631\u0633\u062a \u0648 \u0646\u0627\u062f\u0631\u0633\u062a \u0631\u0627 \u0645\u0634\u062e\u0635 \u0645\u06cc\u06a9\u0646\u062f.","20e11141":"**7. \u0633\u0627\u062e\u062a \u0634\u0628\u06a9\u0647 \u06cc \u0639\u0635\u0628\u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0648\u0646\u0627\u0644**\n* \u0627\u06cc\u0646 \u0645\u062f\u0644 6 \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0644\u0648\u0648\u0634\u0648\u0646\u0627\u0644 \u062f\u0627\u0631\u062f\n* \u0627\u06cc\u0646 \u0645\u062f\u0644 \u062f\u0627\u0631\u0627\u06cc 3 \u0644\u0627\u06cc\u0647 \u06cc \u0686\u06af\u0627\u0644 \u0627\u0633\u062a\n\n\u0628\u0631\u0627\u06cc \u0627\u06cc\u062c\u0627\u062f \u0627\u06cc\u0646 \u0645\u062f\u0644 \u0627\u0632 \u06a9\u0631\u0627\u0633 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0634\u062f\u0647 \u0627\u0633\u062a.\n\u062f\u0631 \u0633\u0627\u062e\u062a \u0634\u0628\u06a9\u0647 \u0627\u0628\u062a\u062f\u0627 \u0627\u0632 \u0634\u0628\u06a9\u0647 \u0647\u0627\u06cc \u0627\u0632 \u067e\u06cc\u0634 \u0622\u0645\u0648\u0632\u0634 \u062f\u06cc\u062f\u0647 \u0627\u06cc \u0686\u0648\u0646 \u0648\u06cc \u062c\u06cc \u062c\u06cc 16 \u060c 19 \u0648 \u0627\u06a9\u0633\u067e\u0634\u0646 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0634\u062f \u0627\u0645\u0627 \u062f\u0642\u062a \u0646\u0647\u0627\u06cc\u06cc \u0627\u0632 \u0686\u06cc\u0632\u06cc \u062f\u0631 \u062d\u062f\u0648\u062f 85 \u062a\u0627 90 \u062f\u0631\u0635\u062f \u0628\u0627\u0644\u0627\u062a\u0631 \u0646\u0631\u0641\u062a. \u0633\u067e\u0633 \u0627\u0632 4 \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0648 \u0646\u0647\u0627\u06cc\u062a\u0627 \u0627\u0632 6 \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u06cc\u0645 \u0648 \u062f\u0631 \u0627\u062f\u0627\u0645\u0647 3 \u0644\u0627\u06cc\u0647 \u06cc \u0686\u06af\u0627\u0644 \u0641\u0648\u0644\u06cc \u06a9\u0627\u0646\u06a9\u062a\u062f \u0628\u0647 \u0645\u062f\u0644 \u0627\u0636\u0627\u0641\u0647 \u0634\u062f. \u062f\u0648 \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0627\u0648\u0644 64 \u0641\u06cc\u0644\u062a\u0631 \u0648 \u0645\u0627\u0628\u0642\u06cc \u062f\u0627\u0631\u0627\u06cc 128 \u0641\u06cc\u0644\u062a\u0631 \u0647\u0633\u062a\u0646\u062f \u0648 \u062f\u0648 \u0644\u0627\u06cc\u0647 \u06cc \u0622\u062e\u0631 256 \u0641\u06cc\u0644\u062a\u0631 \u062f\u0627\u0631\u0646\u062f. \u0628\u0639\u062f \u0627\u0632 \u0647\u0631 \u062c\u0641\u062a \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0645\u062f\u0644 \u062f\u0627\u0631\u0627\u06cc \u06cc\u06a9 \u0644\u0627\u06cc\u0647 \u06cc \u0645\u06a9\u0633 \u067e\u0648\u0644\u06cc\u0646\u06af \u0627\u0633\u062a\u061b \u0647\u0645\u0686\u0646\u06cc\u0646 \u0628\u0647 \u0645\u0646\u0638\u0648\u0631 \u06a9\u0627\u0647\u0634 \u0628\u06cc\u0634 \u0628\u0631\u0627\u0632\u0634 \u067e\u0633 \u0627\u0632 \u0647\u0631 \u062c\u0641\u062a \u0644\u0627\u06cc\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0627\u0632 \u06cc\u06a9 \u0644\u0627\u06cc\u0647 \u06cc \u062f\u0631\u0627\u067e \u0622\u0648\u062a \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0634\u062f\u0647 \u0627\u0633\u062a. (10\u062f\u0631\u0635\u062f \u0628\u06cc\u0646 \u0644\u0627\u06cc\u0647 \u0647\u0627\u06cc \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646\u0627\u0644 \u0648 50\u062f\u0631\u0635\u062f \u0628\u06cc\u0646 \u0644\u0627\u06cc\u0647 \u0647\u0627\u06cc \u0686\u06af\u0627\u0644) \u0647\u0645\u0686\u0646\u06cc\u0646 \u0645\u0627\u0628\u06cc\u0646 \u0647\u0631 \u0644\u0627\u06cc\u0647 \u0627\u0632 \u06cc\u06a9 \u0644\u0627\u06cc\u0647 \u06cc \u0646\u0631\u0645\u0627\u0644 \u0633\u0627\u0632\u06cc \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u0647 \u0627\u06cc\u0645.","6b8ef212":"* http:\/\/www.mehradaria.com\/\n*  http:\/\/www.mehrnevesht.com\/","5051c491":"# \u062f\u0633\u062a\u0647 \u0628\u0646\u062f\u06cc \u0646\u0647\u0627\u0644 \u06af\u06cc\u0627\u0647\u0627\u0646 \u0628\u0627 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u06cc\u0627\u062f\u06af\u06cc\u0631\u06cc \u0639\u0645\u06cc\u0642\n### \u0645\u0647\u0631\u0627\u062f \u0622\u0631\u06cc\u0627 \n\u062f\u06cc\u062a\u0627\u0633\u062a \u0645\u0648\u0631\u062f \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0647 \u0627\u0632 \u06cc\u06a9\u06cc \u0627\u0632 \u0645\u0633\u0627\u0628\u0642\u0627\u062a \u06a9\u06af\u0644 \u0628\u0627 \u0647\u0645\u06cc\u0646 \u0639\u0646\u0648\u0627\u0646 \u062f\u0631\u06cc\u0627\u0641\u062a \u0634\u062f\u0647 \u0627\u0633\u062a\u060c \u0645\u062a\u0634\u06a9\u0644 \u0627\u0632 \u06cc\u06a9 \u0645\u062c\u0645\u0648\u0639\u0647 \u062f\u0627\u062f\u0647 \u06cc \u0622\u0645\u0648\u0632\u0634 \u0648 \u0645\u062c\u0645\u0648\u0639\u0647 \u062a\u0635\u0627\u0648\u06cc\u0631 \u0622\u0632\u0645\u0648\u0646 \u0627\u0632 \u0645\u0631\u0627\u062d\u0644 \u0645\u062e\u062a\u0644\u0641 \u0631\u0634\u062f \u0646\u0647\u0627\u0644 \u06af\u06cc\u0627\u0647\u0627\u0646 \u0627\u0633\u062a. \u0647\u0631 \u062a\u0635\u0648\u06cc\u0631 \u0634\u0646\u0627\u0633\u0647 \u06cc \u06cc\u06a9\u062a\u0627 \u0648 \u0645\u0646\u062d\u0635\u0631 \u0628\u0647 \u0641\u0631\u062f\u06cc \u062f\u0627\u0631\u062f. \u0627\u06cc\u0646 \u062f\u06cc\u062a\u0627\u0633\u062a \u0634\u0627\u0645\u0644 12 \u06af\u0648\u0646\u0647 \u06cc \u0645\u062e\u062a\u0644\u0641 \u0627\u0632 \u06af\u06cc\u0627\u0647\u0627\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0647\u062f\u0641 \u0646\u0647\u0627\u06cc\u06cc \u062f\u0633\u062a\u0647 \u0628\u0646\u062f\u06cc \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc \u0622\u0632\u0645\u0648\u0646 \u062f\u0631 \u0647\u0631 \u06cc\u06a9 \u0627\u0632 \u0627\u06cc\u0646 \u06af\u0648\u0646\u0647 \u0647\u0627\u0633\u062a. \u0628\u062f\u06cc\u0646 \u0645\u0646\u0638\u0648\u0631 \u0627\u0628\u062a\u062f\u0627 \u0628\u0627 \u0645\u062a\u062f\u0647\u0627\u06cc \u067e\u0631\u062f\u0627\u0632\u0634 \u062a\u0635\u0648\u06cc\u0631 \u0628\u0647 \u067e\u06cc\u0634 \u067e\u0631\u062f\u0627\u0632\u0634 \u0648 \u0622\u0645\u0627\u062f\u0647 \u0633\u0627\u0632\u06cc \u062f\u0627\u062f\u0647 \u0647\u0627 \u067e\u0631\u062f\u0627\u062e\u062a\u0647 \u0633\u067e\u0633 \u0645\u062f\u0644 \u0645\u0648\u0631\u062f \u0646\u0638\u0631 \u0631\u0627 \u0645\u06cc \u0633\u0627\u0632\u06cc\u0645 \u0648 \u062f\u0631 \u0646\u0647\u0627\u06cc\u062a \u06a9\u0627\u0631\u0627\u06cc\u06cc \u0622\u0646 \u0645\u0648\u0631\u062f \u0628\u0631\u0631\u0633\u06cc \u0642\u0631\u0627\u0631 \u0645\u06cc \u06af\u06cc\u0631\u062f.","d90bdbf4":"**3. \u067e\u0627\u06a9\u0633\u0627\u0632\u06cc \u062a\u0635\u0627\u0648\u06cc\u0631 \u0648 \u062d\u0630\u0641 \u067e\u0633 \u0632\u0645\u06cc\u0646\u0647:**\n* \u0628\u0631\u0627\u06cc \u067e\u06cc\u0634 \u067e\u0631\u062f\u0627\u0632\u0634 \u062a\u0635\u0627\u0648\u06cc\u0631:\n    * \u062a\u0628\u062f\u06cc\u0644 \u062a\u0635\u0648\u06cc\u0631 \u0622\u0631 \u062c\u06cc \u0628\u06cc \u0628\u0647 \u0627\u0686 \u0627\u0633 \u0648\u06cc\n    * \u062d\u0630\u0641 \u0646\u0648\u06cc\u0632 \u062a\u0635\u0627\u0648\u06cc\u0631\n    * \u0627\u06cc\u062c\u0627\u062f \u06cc\u06a9 \u0645\u0627\u0633\u06a9 \u0628\u0631\u0627\u06cc \u062d\u0630\u0641 \u067e\u0633 \u0632\u0645\u06cc\u0646\u0647\n    \n    \n\u0628\u0631\u0627\u06cc \u0627\u0641\u0632\u0627\u06cc\u0634 \u062f\u0642\u062a\u060c \u067e\u0633 \u0632\u0645\u06cc\u0646\u0647 \u06cc \u062a\u0635\u0627\u0648\u06cc\u0631 \u0631\u0627 \u062d\u0630\u0641 \u0645\u06cc\u06a9\u0646\u06cc\u0645\u060c \u0628\u062f\u06cc\u0646 \u0645\u0646\u0638\u0648\u0631 \u0627\u0632 \u0622\u0646\u062c\u0627\u06cc\u06cc \u06a9\u0647 \u0646\u0647\u0627\u0644 \u0647\u0627 \u063a\u0627\u0644\u0628\u0627 \u0628\u0647 \u0631\u0646\u06af \u0633\u0628\u0632 \u06cc\u0627 \u062a\u0648\u0646\u0627\u0644\u06cc\u062a\u0647 \u0627\u06cc \u0627\u0632 \u0633\u0628\u0632 \u0647\u0633\u062a\u0646\u062f \u0645\u0627\u0633\u06a9\u06cc \u0627\u06cc\u062c\u0627\u062f \u0645\u06cc\u0634\u0648\u062f \u06a9\u0647 \u0628\u0627 \u0639\u0645\u0644 \u06a9\u0627\u0646\u0648\u0648\u0644\u0648\u0634\u0646 \u0628\u0647 \u062c\u0632 \u0628\u0627\u0632\u0647 \u0627\u06cc \u0627\u0632 \u0631\u0646\u06af \u0633\u0628\u0632 \u0645\u0627\u0628\u0642\u06cc \u062a\u0635\u0648\u06cc\u0631 \u0631\u0627 \u062d\u0630\u0641 \u06a9\u0646\u062f.","90ac0deb":"**2. \u062f\u0631\u06cc\u0627\u0641\u062a \u062f\u0627\u062f\u0647 \u0647\u0627 \u0648 \u062a\u063a\u06cc\u06cc\u0631 \u0633\u0627\u06cc\u0632 \u062a\u0635\u0627\u0648\u06cc\u0631:**","a3f0f3bb":" **10. \u067e\u0631\u062f\u0627\u0632\u0634 \u0645\u062c\u0645\u0648\u0639\u0647 \u0622\u0632\u0645\u0648\u0646 \u0648 \u067e\u06cc\u0634 \u0628\u06cc\u0646\u06cc:**","109abc90":"**8. \u0628\u0631\u0627\u0632\u0634 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0628\u0627 CNN:**\n* \u062a\u0639\u062f\u0627\u062f\u06cc \u06a9\u0627\u0644 \u0628\u06a9 \u0637\u0631\u0627\u062d\u06cc \u0645\u06cc\u06a9\u0646\u06cc\u0645:\n    * \u062c\u0647\u062a \u0647\u0645\u06af\u0631\u0627\u06cc\u06cc \u0633\u0631\u06cc\u0639 \u062a\u0631 \u0646\u0631\u062e \u06cc\u0627\u062f\u06af\u06cc\u0631\u06cc \u0628\u0627\u06cc\u062f \u06a9\u0627\u0647\u0634 \u06cc\u0627\u0628\u062f.\n    * \u0628\u0647\u062a\u0631\u06cc\u0646 \u0648\u0632\u0646 \u0647\u0627\u06cc \u0645\u062f\u0644 \u0631\u0627 \u0630\u062e\u06cc\u0631\u0647 \u0645\u06cc\u06a9\u0646\u06cc\u0645.\n    * \u0622\u062e\u0631\u06cc\u0646 \u0648\u0632\u0646 \u0647\u0627\u06cc \u0645\u062f\u0644 \u0631\u0627 \u0630\u062e\u06cc\u0631\u0647 \u0645\u06cc\u06a9\u0646\u06cc\u0645.  \n    \n\u0627\u06a9\u0646\u0648\u0646 \u0645\u062f\u0644 \u062e\u0648\u062f \u0631\u0627 \u0622\u0645\u0648\u0632\u0634 \u0645\u06cc\u062f\u0647\u06cc\u0645\u061b \u0627\u0628\u062a\u062f\u0627 \u0686\u0646\u062f \u06a9\u0627\u0644 \u0628\u06a9 \u062a\u0646\u0638\u06cc\u0645 \u0645\u06cc\u06a9\u0646\u06cc\u0645\u060c \u0627\u0648\u0644\u06cc \u0646\u0631\u062e \u06cc\u0627\u062f\u06af\u06cc\u0631\u06cc \u0645\u062f\u0644 \u0631\u0627 \u06a9\u0627\u0647\u0634 \u0645\u06cc\u062f\u0647\u062f\u061b \u0646\u0631\u062e \u06cc\u0627\u062f\u06af\u06cc\u0631\u06cc \u0628\u0627\u0644\u0627 \u0633\u0631\u0639\u062a \u0647\u0645\u06af\u0631\u0627\u06cc\u06cc \u0631\u0627 \u0627\u0641\u0632\u0627\u06cc\u0634 \u0645\u06cc\u062f\u0647\u062f \u0627\u0645\u0627 \u0628\u0627 \u0627\u06cc\u0646 \u0646\u0631\u062e \u0628\u0627\u0644\u0627  \u0645\u0645\u06a9\u0646 \u0627\u0633\u062a \u0645\u062f\u0644 \u062f\u0631 \u0645\u06cc\u0646\u06cc\u0645\u0645 \u0645\u062d\u0644\u06cc \u06af\u06cc\u0631 \u06a9\u0646\u062f \u0628\u0646\u0627\u0628\u0631\u06cc\u0646 \u062f\u0631 \u067e\u0631\u0648\u0633\u0647 \u06cc \u0628\u0631\u0627\u0632\u0634 \u0646\u0631\u062e \u06cc\u0627\u062f\u06af\u06cc\u0631\u06cc \u0631\u0627 \u06a9\u0627\u0647\u0634 \u0645\u06cc\u062f\u0647\u06cc\u0645. \u0646\u0631\u062e \u06a9\u0627\u0647\u0634 \u0645\u06cc\u0627\u0628\u062f \u0627\u06af\u0631 \u062f\u0642\u062a \u067e\u0633 \u0627\u0632 \u0633\u0647 \u0627\u067e\u0648\u06a9 \u0628\u0647\u0628\u0648\u062f \u0646\u06cc\u0627\u0628\u062f. \u062f\u0648 \u06a9\u0627\u0644 \u0628\u06a9 \u062f\u06cc\u06af\u0631 \u0628\u0647\u062a\u0631\u06cc\u0646 \u0648 \u0622\u062e\u0631\u06cc\u0646 \u0648\u0632\u0646 \u0647\u0627\u06cc \u0645\u062f\u0644 \u0631\u0627 \u0630\u062e\u06cc\u0631\u0647 \u0645\u06cc\u06a9\u0646\u0646\u062f.","9eb68351":"**1. \u0641\u0631\u0627\u062e\u0648\u0627\u0646\u06cc \u0645\u0627\u0698\u0648\u0644 \u0647\u0627\u06cc \u0645\u0648\u0631\u062f \u0646\u06cc\u0627\u0632:**"}}