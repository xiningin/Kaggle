{"cell_type":{"14727dff":"code","e9b46378":"code","cd7805fa":"code","dcab2409":"code","a6ff7488":"code","9829c985":"code","1641cf38":"code","aff2c456":"code","f6ed0822":"code","cea06502":"code","d4ec9c79":"code","337686ae":"code","55624d9a":"code","2d4df184":"code","942ef14c":"code","ca989bf2":"code","afa10fd7":"code","c73835b9":"code","4ffd0989":"code","d8319154":"code","2f65ed40":"code","38558f3b":"code","3f751e01":"code","bc990d17":"code","d365ebc4":"code","59404d7d":"code","7c168cf7":"code","327cd742":"code","b1514061":"code","94e0d55c":"code","85a575b8":"code","f5d2619a":"code","e9ff7ac0":"code","579a30e1":"code","a1097147":"code","2440d582":"code","7aa8e96a":"code","c9700144":"code","8f2a7e39":"code","53dbc12e":"code","a2256316":"code","d5e39821":"code","5be92fe4":"code","d5bd8b50":"code","b80fd667":"code","cbb90e5d":"code","24180627":"code","e1670bf9":"code","56ce347e":"code","611b74af":"code","5954c703":"code","70f62f98":"code","f21d9363":"code","a2affe00":"code","0c2aad77":"code","4c30fa38":"code","14c2d2ff":"code","fd49e45e":"code","0ab885b5":"code","1dd58af1":"code","d0b4c366":"code","24979715":"code","85b4be97":"code","a1e1d8c0":"code","b361818d":"code","bf7533e7":"code","0cd60f65":"code","745478e9":"code","c50c47de":"code","e98ecb5f":"code","9a0840f9":"code","adb8db78":"code","ea781ae3":"code","be6730cb":"code","bf081ea9":"code","e1a1319e":"code","8100d189":"code","ceb41f6e":"code","1bfadca5":"code","a44f76c5":"code","2b8bca6c":"code","bc7cfff4":"code","d49a1146":"code","1e939955":"code","4f4d7837":"code","c065cdf6":"code","55702cdc":"code","3505dd28":"code","ef8087cc":"code","33959d59":"code","9065523d":"code","9a06ed32":"code","9ae1e4bf":"code","8d29b1ab":"markdown","d1c4871f":"markdown","0bb9ea64":"markdown","0f003601":"markdown","d8ed0730":"markdown","1d5c15b0":"markdown","59eee5d9":"markdown","3ca1fc87":"markdown","9203f76c":"markdown","f32b1796":"markdown","5f25024e":"markdown","dfe176e4":"markdown","f37edc52":"markdown","58e31f8e":"markdown","1e59ae97":"markdown","e4ac84a6":"markdown","1ac680cd":"markdown","6c4182f9":"markdown","f787f4b3":"markdown","a38181a1":"markdown","7071ae20":"markdown","9a4be95e":"markdown","28e27af4":"markdown","d217d022":"markdown","07045581":"markdown","8551f96b":"markdown","40413837":"markdown","9893e30b":"markdown","00b9272a":"markdown","96010714":"markdown","72d469b2":"markdown","c6fbecce":"markdown","0b3dd8a7":"markdown","941afa7e":"markdown","225e7931":"markdown","dc8e9f84":"markdown","d16287cd":"markdown","684aaea2":"markdown","ebcb3df5":"markdown","56e1a0db":"markdown","f7b1f2b5":"markdown","7da0ba76":"markdown","abce761e":"markdown","dc539d9d":"markdown","7fb5fa6b":"markdown"},"source":{"14727dff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e9b46378":"import pandas as pd \nimport numpy as np \nfrom scipy import stats  \nimport matplotlib.pyplot as plt  \nimport seaborn as sns \n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nprint('.....setup complete')","cd7805fa":"# reading csv file \ndf = pd.read_csv('..\/input\/Churn_Modelling.csv')\ndf.head()","dcab2409":"print('shape of Dataframe is',df.shape)","a6ff7488":"sns.boxplot(y=\"CreditScore\", x=\"Exited\", data=df)","9829c985":"sns.boxplot(y=\"Age\", x=\"Exited\", data=df)","1641cf38":"sns.boxplot(y=\"Tenure\", x=\"Exited\", data=df)","aff2c456":"sns.boxplot(y=\"Balance\", x=\"Exited\", data=df)","f6ed0822":"sns.boxplot(y=\"EstimatedSalary\", x=\"Exited\", data=df)","cea06502":"sns.distplot(df['Exited'], kde=False, rug=True)","d4ec9c79":"df.describe().T","337686ae":"df.nunique()","55624d9a":"duplicateDFRow = df[df.duplicated()]\nprint(duplicateDFRow)","2d4df184":"#correlation heat map\n\nfig_dims = (14, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.heatmap(df.corr(), annot = True,ax=ax)","942ef14c":"sns.regplot(y=\"CreditScore\", x=\"Exited\", data=df)\nplt.ylim(0,)\ndf[[\"CreditScore\", \"Exited\"]].corr()","ca989bf2":"sns.regplot(y=\"Age\", x=\"Exited\", data=df)\nplt.ylim(0,)\ndf[[\"Age\", \"Exited\"]].corr()","afa10fd7":"sns.regplot(y=\"Balance\", x=\"Exited\", data=df)\nplt.ylim(0,)\ndf[[\"Balance\", \"Exited\"]].corr()","c73835b9":"sns.regplot(y=\"EstimatedSalary\", x=\"Exited\", data=df)\nplt.ylim(0,)\ndf[[\"EstimatedSalary\", \"Exited\"]].corr()","4ffd0989":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"CreditScore\", x=\"Exited\", data=df)","d8319154":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Geography\", x=\"Exited\", data=df)","2f65ed40":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Gender\", x=\"Exited\", data=df)","38558f3b":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Age\", x=\"Exited\", data=df)","3f751e01":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Tenure\", x=\"Exited\", data=df)","bc990d17":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Balance\", x=\"Exited\", data=df)","d365ebc4":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"NumOfProducts\", x=\"Exited\", data=df)","59404d7d":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"EstimatedSalary\", x=\"Exited\", data=df)","7c168cf7":"sns.set(style=\"ticks\", color_codes=True)\ng = sns.pairplot(df)","327cd742":"df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1,inplace=True)","b1514061":"df.isnull().sum()","94e0d55c":"z = np.abs(stats.zscore(df['Age']))\nz1 = np.abs(stats.zscore(df['EstimatedSalary']))\nz,z1","85a575b8":"print(np.where (z>3))\nprint(np.where (z1>3))","f5d2619a":"c_df= pd.get_dummies(df,columns=[\"Gender\",\"Geography\"])","e9ff7ac0":"c_df.head()","579a30e1":"from sklearn.model_selection import train_test_split\n\nX= c_df.loc[:,c_df.columns != 'Exited']\ny= c_df.loc[:,c_df.columns == 'Exited']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)","a1097147":"from sklearn.preprocessing import StandardScaler\n\nsc= StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","2440d582":"from sklearn.ensemble import RandomForestClassifier","7aa8e96a":"rfc = RandomForestClassifier(random_state=10)\nrfc.fit(X_train,y_train)","c9700144":"s_rfc =rfc.score(X_test, y_test)\nprint('RF=',s_rfc)","8f2a7e39":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nimport time","53dbc12e":"# checking for best parameter values of bootstrap, max_depth, max_features,min_samples_leaf,\n# min_samples_split and n_estimators.\n\n\nmax_depth= [1,2,3,4,5,6,7,8,9,10,11,12]\nn_estimators= [50,100,200,300,400,500]\n\nparam_grid = dict( max_depth=max_depth,  n_estimators=n_estimators)","a2256316":"random = RandomizedSearchCV(estimator=rfc, param_distributions=param_grid, cv = 3, n_jobs=-1,random_state=10)\n\nstart_time = time.time()\nrandom_result = random.fit(X, y)\n\n# Summarize results\nprint(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')","d5e39821":"# n_estimators=400,max_depth=12\nrfc = RandomForestClassifier(random_state=10,n_estimators=400,max_depth=12 )\nrfc.fit(X_train,y_train)","5be92fe4":"score1_rfc =rfc.score(X_test, y_test)\nscore1_rfc","d5bd8b50":"yhat = rfc.predict(X_test)\nyhat_prob = rfc.predict_proba(X_test)","b80fd667":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools","cbb90e5d":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, yhat, labels=[1,0]))","24180627":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['response=1','response=0'],normalize= False,  title='Confusion matrix')","e1670bf9":"rf_score= (classification_report(y_test, yhat))\nprint(rf_score)","56ce347e":"from sklearn.metrics import plot_roc_curve\ndisp=plot_roc_curve(rfc,X_test, y_test)","611b74af":"from sklearn import metrics","5954c703":"mae_rf = metrics.mean_absolute_error(y_test, yhat)\nprint('Mean Absolute Error : ',mae_rf)\nmse_rf = metrics.mean_squared_error(y_test, yhat)\nprint('Mean Squared Error : ',mse_rf)","70f62f98":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn import model_selection","f21d9363":"# here k = 5\nresults=[]\nkfold=model_selection.KFold(n_splits=5)\ncv_results = model_selection.cross_val_score(rfc,X_train,y_train,cv=kfold, scoring='accuracy')\nresults.append(cv_results)\nprint('Random Forest : ',cv_results.mean())","a2affe00":"from sklearn.linear_model import LogisticRegression","0c2aad77":"lr= LogisticRegression()\nlr.fit(X_train,y_train)","4c30fa38":"score_lr =lr.score(X_test, y_test)\nprint('LR=',score_lr)","14c2d2ff":"max_iter=[100,110,120,130,140]\nC = [0.01,0.1,1,10]\nparam_grid = dict(max_iter=max_iter,C=C)","fd49e45e":"random = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv = 3, n_jobs=-1,random_state=10)\n\nstart_time = time.time()\nrandom_result = random.fit(X, y)\n# Summarize results\nprint(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')","0ab885b5":"lr= LogisticRegression(C=0.1,max_iter=120)\nlr.fit(X_train,y_train)","1dd58af1":"score1_lr =lr.score(X_test, y_test)\nprint('LR=',score1_lr)","d0b4c366":"y1hat = lr.predict(X_test)","24979715":"results1=[]\nkfold1=model_selection.KFold(n_splits=5)\ncv_results1 = model_selection.cross_val_score(lr,X_train,y_train,cv=kfold1, scoring='accuracy')\nresults1.append(cv_results1)\nprint('Logistic Regression : ',cv_results1.mean())","85b4be97":"lr_score=(classification_report(y_test, y1hat))\nprint (lr_score)","a1e1d8c0":"disp=plot_roc_curve(lr,X_test, y_test)","b361818d":"mae_lr = metrics.mean_absolute_error(y_test, y1hat)\nprint('Mean Absolute Error : ',mae_lr)\nmse_lr = metrics.mean_squared_error(y_test, y1hat)\nprint('Mean Squared Error : ',mse_lr)","bf7533e7":"from sklearn import svm","0cd60f65":"svmc = svm.SVC(kernel='rbf')\nsvmc.fit(X_train, y_train)","745478e9":"score_svmc =svmc.score(X_test, y_test)\nprint('SVM = ',score_svmc)","c50c47de":"C=[1,2,3,4,5,6,7,8,9,10,11,12]\ndegree=[1,2,3,4,5,6,7,8,9,10]\nparam_grid = dict(C=C,degree=degree)","e98ecb5f":"random = RandomizedSearchCV(estimator=svmc, param_distributions=param_grid, cv = 3, n_jobs=-1,random_state=10)\n\nstart_time = time.time()\nrandom_result = random.fit(X, y)\n# Summarize results\nprint(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')","9a0840f9":"svmc = svm.SVC(kernel='rbf',degree= 6,C=5)\nsvmc.fit(X_train, y_train)","adb8db78":"score1_svmc =svmc.score(X_test, y_test)\nprint('SVM = ',score1_svmc)","ea781ae3":"y2hat = svmc.predict(X_test)","be6730cb":"results2=[]\nkfold2=model_selection.KFold(n_splits=5)\ncv_results2 = model_selection.cross_val_score(svmc,X_train,y_train,cv=kfold2, scoring='accuracy')\nresults2.append(cv_results2)\nprint('SVM : ',cv_results2.mean())","bf081ea9":"svm_score= (classification_report(y_test, y2hat))\nprint(svm_score)","e1a1319e":"disp=plot_roc_curve(svmc,X_test, y_test);","8100d189":"mae_svm = metrics.mean_absolute_error(y_test, y2hat)\nprint('Mean Absolute Error : ',mae_svm)\nmse_svm = metrics.mean_squared_error(y_test, y2hat)\nprint('Mean Squared Error : ',mse_svm)","ceb41f6e":"from sklearn.neighbors import KNeighborsClassifier","1bfadca5":"knn = KNeighborsClassifier(n_neighbors = 18)\nknn.fit(X_train,y_train)","a44f76c5":"s_knn =knn.score(X_test, y_test)\nprint('KNN=',s_knn)","2b8bca6c":"algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\nn_neighbors=range(1,20)\nweights=['uniform', 'distance']\nparam_grid = dict(algorithm=algorithm,n_neighbors=n_neighbors,weights=weights)","bc7cfff4":"random = RandomizedSearchCV(estimator=knn, param_distributions=param_grid, cv = 3, n_jobs=-1,random_state=42)\n\nstart_time = time.time()\nrandom_result = random.fit(X, y)\n# Summarize results\nprint(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\nprint(\"Execution time: \" + str((time.time() - start_time)) + ' ms')","d49a1146":"knn = KNeighborsClassifier(algorithm='ball_tree',n_neighbors = 16)\nknn.fit(X_train,y_train)","1e939955":"s1_knn =knn.score(X_test, y_test)\nprint('KNN=',s1_knn)","4f4d7837":"y3hat = knn.predict(X_test)","c065cdf6":"results3=[]\nkfold3=model_selection.KFold(n_splits=5)\ncv_results3 = model_selection.cross_val_score(knn,X_train,y_train,cv=kfold3, scoring='accuracy')\nresults3.append(cv_results3)\nprint('KNN : ',cv_results3.mean())","55702cdc":"knn_score=classification_report(y_test, y3hat)\nprint(knn_score)","3505dd28":"disp=plot_roc_curve(knn,X_test, y_test)","ef8087cc":"mae_knn = metrics.mean_absolute_error(y_test, y3hat)\nprint('Mean Absolute Error : ',mae_knn)\nmse_knn = metrics.mean_squared_error(y_test, y3hat)\nprint('Mean Squared Error : ',mse_knn)","33959d59":"print('01. RANDOM FOREST : \\n',rf_score)\nprint('02. LOGISTIC REGRESSION : \\n',lr_score)\nprint('03. SUPPORT VECTOR MACHINE : \\n',svm_score)\nprint('04. K-NEAREST NEIGHBORS : \\n',knn_score)","9065523d":"disp=plot_roc_curve(rfc,X_test, y_test)\nplot_roc_curve(lr,X_test, y_test,ax=disp.ax_);\nplot_roc_curve(svmc,X_test, y_test,ax=disp.ax_);\nplot_roc_curve(knn,X_test, y_test,ax=disp.ax_);","9a06ed32":"compare_models = pd.DataFrame( \n    {  'Model' : ['RANDOM FOREST','LOGISTIC REGRESSION', 'SUPPORT VECTOR MACHINE','K-NEAREST NEIGHBORS'], \n       'Score after CV' : [cv_results.mean(), cv_results1.mean(),cv_results2.mean(),cv_results3.mean()],\n       'AUC' : ['0.87','0.77','0.84','0.81'],\n        'Mean Absolute Error'  : [mae_rf, mae_lr, mae_svm, mae_knn], \n        'Mean Squared Error'  : [mse_rf, mse_lr, mse_svm, mse_knn] \n    })  ","9ae1e4bf":"compare_models.T","8d29b1ab":"### Hyperparameter Tuning in SVM","d1c4871f":"###  Validating using k fold cross validation ","0bb9ea64":"# K-Nearest Neighbors","0f003601":"### Mean Squared Error & Mean Absolute Error","d8ed0730":"## Aggregation for all numerical Columns","1d5c15b0":"### So the model with the highest  Accuracy=86,  Precision=87,  AUC=87 and lowest  MAE=12.72,  MSE=12.72  is  RANDOM FOREST CLASSIFIER","59eee5d9":"<h4>Made By : Yogender Kushwaha<\/h4>\n<h4>LinkedIn: click <a href=\"https:\/\/www.linkedin.com\/in\/yogender-kushwaha\/\">HERE<\/a><\/h4>","3ca1fc87":"## Duplicate values across all columns","9203f76c":"### Mean Squared Error & Mean Absolute Error","f32b1796":"# Random Forest Classifier","5f25024e":"### Validating using 5 fold cross validation","dfe176e4":"## Bar Plot ","f37edc52":"1. Here the outliers are not removed because according to the Telecom customers these outliers looks the genuine values. \n2. So if we remove the outliers it may increase the accuracy of the model for this dataset but we will loose huge amount of data and for the real world datset it will not perform much better.","58e31f8e":"### Validating using 5 fold cross validation","1e59ae97":"## Z score for checking Outliers","e4ac84a6":"## Converting the Catogorical Data into Dummy Values","1ac680cd":" ###  F1 Score, Precision, Recall, Accuracy and AUC for LR","6c4182f9":"## Normalising the data using skelarn\u2019s StandardScaler","f787f4b3":"# Support Vector Machine","a38181a1":"### New LR model with updated parametrs ","7071ae20":"### New KNN model with updated parametrs ","9a4be95e":"### Mean Squared Error & Mean Absolute Error","28e27af4":"## Histogram \u2013 Distribution of Target Variable","d217d022":"# LogisticRegression","07045581":"###  Validating using 5 fold cross validation LR","8551f96b":"### New RF model with updated parametrs ","40413837":"### Hyperparameter Tuning in Random Forest","9893e30b":"## Unique Values across all columns ","00b9272a":" ###  F1 Score, Precision, Recall, Accuracy and AUC for SVM","96010714":"## Train and Test Split","72d469b2":"### Hyperparameter Tuning in KNN","c6fbecce":"### Confusion matrix RF","0b3dd8a7":"## Droping all non-essential features","941afa7e":"### New SVM model with updated parametrs ","225e7931":"## Boxplot","dc8e9f84":"## Correlation \u2013 Heatmap","d16287cd":"### Hyperparameter Tuning in Logistic Regression","684aaea2":"### Mean Squared Error & Mean Absolute Error","ebcb3df5":"# Conclusion","56e1a0db":"## Regression Plot ","f7b1f2b5":"## Pair plot ","7da0ba76":" ### AUC, F1 Score, Precision, Recall and Accuracy RF","abce761e":"## Checking for Null values","dc539d9d":" ###  F1 Score, Precision, Recall, Accuracy and AUC for KNN","7fb5fa6b":"# Basic EDA "}}