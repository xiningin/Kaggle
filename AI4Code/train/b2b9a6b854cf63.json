{"cell_type":{"2aaf8c36":"code","2fdd1d96":"code","25deeb12":"code","161151a7":"code","dc91d71d":"code","14fea2d2":"code","960d660f":"code","21916a90":"code","3f17fa20":"code","f418c0bb":"code","78ba5c77":"code","fd9a7b4e":"code","751f78e0":"code","819bb3a4":"code","d1a420e7":"code","97a7d8a6":"code","d4297bdf":"code","647a5e9f":"code","326a2558":"code","6b9bf428":"code","2e4a0684":"code","3bdb425b":"code","af6efce0":"code","2927d26d":"code","c3abebe2":"code","a5acd0f1":"code","221fee86":"code","65f4bb67":"code","d22a2af5":"code","5b313094":"code","a95bec62":"code","1c908d4a":"code","e42ddc87":"code","bb10d4d6":"code","67f80e23":"code","c72b9294":"code","abf5a601":"code","d314c9d2":"code","8b9516c4":"code","ca829c8f":"code","5e96f63e":"code","5e0db9b9":"markdown","fa03f335":"markdown","dfa66c78":"markdown","923789db":"markdown","fa93ae65":"markdown","194af359":"markdown","98980e58":"markdown","f3f5ea10":"markdown","0f11a090":"markdown","4a1ddffa":"markdown","ccb6a749":"markdown","35e182fc":"markdown","66354ffc":"markdown","5fb5b152":"markdown"},"source":{"2aaf8c36":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n\nfrom sklearn.decomposition import PCA, KernelPCA\n\nfrom scipy import stats\n\nimport warnings\nwarnings.filterwarnings('ignore')","2fdd1d96":"df = pd.read_csv(\"..\/input\/forest-fire-area\/forestfires.csv\")\ndf.head()","25deeb12":"df.shape","161151a7":"# check null values if any\n\ndf.isna().sum()","dc91d71d":"df.info()","14fea2d2":"#describe numerical features\n\ndf.describe().T","960d660f":"# describe categorical features\n\ndf.describe(include=\"O\")","21916a90":"# visualize distribution of all numerical columns\n\nnum_cols = df.select_dtypes(include='number').columns\n\nfig, axs =  plt.subplots(nrows=5, ncols=2, figsize=(15,20))\naxs = np.ravel(axs)\n\nfor i, col in enumerate(num_cols[2:]):\n    plt.sca(axs[i])\n    sns.histplot(data=df, x=col, kde=True, line_kws={'linewidth':2, 'linestyle':'--'}, color='orange')\n    \nplt.tight_layout()\nplt.show()","3f17fa20":"## removing outliers\n\nmask = (df.FFMC<80)|(df.ISI>25)\n\ndf = df.loc[~mask]\ndf.shape","f418c0bb":"# visualize distribution of all numerical columns again\n\nnum_cols = df.select_dtypes(include='number').columns\n\nfig, axs =  plt.subplots(nrows=5, ncols=2, figsize=(15,20))\naxs = np.ravel(axs)\n\nfor i, col in enumerate(num_cols[2:]):\n    plt.sca(axs[i])\n    sns.histplot(data=df, x=col, kde=True, line_kws={'linewidth':2, 'linestyle':'--'}, color='orange')\n    \nplt.tight_layout()\nplt.show()","78ba5c77":"df.month.value_counts()","fd9a7b4e":"df.day.value_counts()","751f78e0":"## Data mapping of categorical features\n\nmonth_map = {'jan':1, 'feb':2, 'mar':3, \n             'apr':4, 'may':5, 'jun':6, \n             'jul':7, 'aug':8, 'sep':9, \n             'oct':10, 'nov':11, 'dec':12}\n\nday_map = {'mon':1, 'tue':2, 'wed':3,\n          'thu':4, 'fri':5, 'sat':6, 'sun':7}\n\ndf.month = df.month.map(month_map)\ndf.day = df.day.map(day_map)","819bb3a4":"df.info()","d1a420e7":"X, y = df.drop('area', 1).values, df['area'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","97a7d8a6":"scaler = StandardScaler()\nscaler.fit(X_train)","d4297bdf":"X_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\ny_train_log = np.log1p(y_train)\ny_test_log = np.log1p(y_test)","647a5e9f":"def model_results(model, X_train, y_train):\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_train)\n    mse = mean_squared_error(y_train, predictions)\n    rmse = np.sqrt(mse)\n    print(f\"RMSE: {rmse:.3f}\\n\")\n    \n    print(\"*****Shapiro-Wilks test for Normality*****\")\n    residuals = y_train - predictions\n    test_results = stats.shapiro(residuals)\n    if test_results[1]>0.5:\n        print(\"\\nResiduals follow normal distribution!\")\n    else:\n        print(\"\\nResiduals do no follow normal distribution!\")\n    \n    plt.scatter(np.arange(len(residuals)), residuals)\n    plt.title(\"Residual Plot\")\n    plt.show()\n    ","326a2558":"linear_reg = LinearRegression()\n\nmodel_results(linear_reg, X_train_scaled, y_train_log)","6b9bf428":"lasso = Lasso(alpha=0.2, random_state=101)\n\nmodel_results(lasso, X_train_scaled, y_train_log)","2e4a0684":"ridge = Ridge(alpha=0.1, random_state=101)\n\nmodel_results(ridge, X_train_scaled, y_train_log)","3bdb425b":"elastic_net = ElasticNet(alpha=0.1)\nmodel_results(elastic_net, X_train_scaled, y_train_log)","af6efce0":"elastic_net.coef_","2927d26d":"## get important features only\n\nindexes = np.where(elastic_net.coef_!=0)[0].tolist()\nindexes","c3abebe2":"elastic_net_2 = ElasticNet(alpha=0.1)\nmodel_results(elastic_net_2, X_train_scaled[:, indexes], y_train_log)","a5acd0f1":"def train_test_error(model, X_train=X_train_scaled, \n                     X_test=X_test_scaled, y_train=y_train_log, \n                     y_test=y_test_log):\n    \n    train_rmse = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n    test_rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n    \n    print(f\"Train RMSE: {train_rmse:.3f}\")\n    print(f\"Test RMSE:  {test_rmse:.3f}\")","221fee86":"svr_reg = SVR(kernel='rbf', degree=2, C=1)\nsvr_reg.fit(X_train_scaled, y_train_log)\n\ntrain_test_error(svr_reg)","65f4bb67":"forest = RandomForestRegressor(n_estimators=10, random_state=101)\nforest.fit(X_train_scaled, y_train_log)\n\ntrain_test_error(forest)","d22a2af5":"forest.feature_importances_","5b313094":"correlation_matrix = pd.DataFrame(X_train_scaled).corr()\n\n\ncorrelation_matrix = pd.DataFrame(np.tril(correlation_matrix, -1))","a95bec62":"correlation_matrix.style.highlight_max(axis=1, color='orange')#.highlight_min(axis=1, color='red')","1c908d4a":"rfe = RFE(elastic_net, n_features_to_select=5, verbose=1)\nrfe.fit(X_train_scaled,y_train_log)\n\nindexes = np.where(rfe.support_==True)[0]\n\n\nelastic_net.fit(X_train_scaled[:, indexes.tolist()], y_train_log)\n\ntrain_test_error(elastic_net, X_train=X_train_scaled[:, indexes.tolist()], \n                 X_test=X_test_scaled[:, indexes.tolist()])","e42ddc87":"## RFE of Random forest\n\nrfe = RFE(forest, n_features_to_select=5, verbose=1)\nrfe.fit(X_train_scaled,y_train_log)\n\nindexes = np.where(rfe.support_==True)[0]\n\nforest.fit(X_train_scaled[:, indexes.tolist()], y_train_log)\n\ntrain_test_error(forest, X_train=X_train_scaled[:, indexes.tolist()], \n                 X_test=X_test_scaled[:, indexes.tolist()])","bb10d4d6":"gradient_boost = GradientBoostingRegressor(learning_rate=0.01, random_state=101)\n\n## RFE of Gradient Boosting \n\nrfe = RFE(gradient_boost, n_features_to_select=5, verbose=1)\nrfe.fit(X_train_scaled,y_train_log)\n\nindexes = np.where(rfe.support_==True)[0]\n\ngradient_boost.fit(X_train_scaled[:, indexes.tolist()], y_train_log)\n\ntrain_test_error(gradient_boost, X_train=X_train_scaled[:, indexes.tolist()], \n                 X_test=X_test_scaled[:, indexes.tolist()])","67f80e23":"pca = PCA(n_components=2, random_state=101)","c72b9294":"rfe = RFE(elastic_net, n_features_to_select=5, verbose=1)\nrfe.fit(X_train_scaled,y_train_log)\n\nindexes = np.where(rfe.support_==True)[0].tolist()\n\n## dimensionality reduction\ntrain_data = X_train_scaled[:, indexes]\ntest_data = X_test_scaled[:, indexes]\n\ntrain_data = pca.fit_transform(train_data)\ntest_data = pca.transform(test_data)\n\nelastic_net.fit(train_data, y_train_log)\n\ntrain_test_error(elastic_net, X_train=train_data, X_test=test_data)","abf5a601":"indexes ## important features X, month, DMC, ISI, wind","d314c9d2":"df.info()","8b9516c4":"predictions = np.round(np.expm1(elastic_net.predict(test_data)),2)\npredictions","ca829c8f":"squared_errors = (y_test - predictions)**2\n\ninterval = np.sqrt(stats.t.interval(0.95, \n                                    df=len(squared_errors)-1, \n                                    loc=squared_errors.mean(), \n                                    scale=stats.sem(squared_errors)))\ninterval","5e96f63e":"import joblib\n\njoblib.dump(scaler, \"scaler_forest_fire_v1.pkl\")\njoblib.dump(pca, \"pca_forest_fire_v1.pkl\")\njoblib.dump(elastic_net, \"forest_fire_elastic_net_model_v1.pkl\")","5e0db9b9":"### Linear Regression model","fa03f335":"### SVR","dfa66c78":"### Gardient Boosting Regressor with RFE","923789db":"### Lasso","fa93ae65":"## Dimensionality Reduction and RFE together","194af359":"## Data Loading and Preprocessing","98980e58":"### Random Forest with RFE","f3f5ea10":"### Prepare Train - Test dataset","0f11a090":"### Elastic Net","4a1ddffa":"## Recursive Feature Elimination (RFE) for feature selection","ccb6a749":"### Random Forest","35e182fc":"## Models","66354ffc":"### Ridge","5fb5b152":"### Elastic Net with RFE"}}