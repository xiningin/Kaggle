{"cell_type":{"8083a562":"code","c741361f":"code","33431a0f":"code","fc2df93b":"code","a4a23df9":"code","1160ab1e":"code","8c2b2916":"code","12bec5a0":"code","dd506f73":"code","e309d8c8":"code","434c42b4":"code","a42b284a":"code","3613cfb3":"code","35da0f5c":"code","ddeb38dd":"code","8961d9ea":"code","ed65058d":"code","ffa9bfa1":"code","47f15324":"code","dd6b9128":"code","32fe5a62":"code","6517fc2e":"code","e1a05a03":"code","6645744f":"code","90cda584":"code","5634da6f":"code","a54a091d":"code","8730bdb2":"code","cf3c2160":"markdown","a3e483d3":"markdown","56198b84":"markdown","706c0a90":"markdown","e5616118":"markdown","bc458c35":"markdown","070fff43":"markdown","6c6a8888":"markdown","cf0d1361":"markdown","183b851d":"markdown","c6c2e062":"markdown"},"source":{"8083a562":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c741361f":"train_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","33431a0f":"train_data.head()","fc2df93b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (14,8)\nsns.set()","a4a23df9":"train_data.info()","1160ab1e":"# proportion of missing values\nmissing_values = train_data.isna().sum()\/len(train_data)\nmissing_values = missing_values.sort_values(ascending=False)\nmissing_values[missing_values != 0]","8c2b2916":"fig, ax =  plt.subplots()\n\nsns.heatmap(train_data.isnull(), cbar=False, ax=ax)\nax.set_title('Heatmap of missing values')\nplt.show()","12bec5a0":"numeric_cols = [col for col in train_data.columns \n                if train_data[col].dtype in ['int64', 'float64']]\ncategorical_cols = [col for col in train_data.columns \n                    if train_data[col].dtype == 'object']\n\nassert len(train_data.columns) == len(numeric_cols + categorical_cols)","dd506f73":"import math\n\nslide = 10\n\nfor i in range(math.ceil(len(numeric_cols)\/slide)):\n    cols = numeric_cols[slide * i: slide * (i+1)]\n    display(train_data[cols].describe())","e309d8c8":"cols = 2\nrows = math.ceil(len(numeric_cols)\/cols)\nfig, axes = plt.subplots(rows, cols, figsize=(14, 8\/\/cols*rows))\nplt.tight_layout()\n\nfor i, col in enumerate(numeric_cols):\n    ax = axes[i\/\/cols, i%cols]\n    sns.histplot(data=train_data, x=col, element='step', ax=ax)\n    ax.set_title(f'Histogram of {col}', y=0.88)\n\nplt.show()","434c42b4":"fig, ax =  plt.subplots(figsize=(18,14))\n\ncorrelation_matrix = train_data[numeric_cols].corr()\nmask = np.triu(np.ones_like(correlation_matrix))\n\nsns.heatmap(correlation_matrix, cmap='RdBu',\n            vmin=-1, vmax=1, mask=mask, ax=ax)\nax.set_title('Heatmap of numeric columns')\nplt.show()","a42b284a":"# choose columns with absolute correlation greater than threshold\nthreshold = 0.5\ncondition = correlation_matrix['SalePrice'].abs() > threshold\nhigh_correlation = correlation_matrix.loc[condition, condition]\nhigh_correlation","3613cfb3":"fig, ax =  plt.subplots()\n\nmask = np.triu(np.ones_like(high_correlation))\n\nsns.heatmap(high_correlation, cmap='RdBu',\n            vmin=-1, vmax=1, annot=True, square=True,\n            mask=mask, ax=ax)\nax.set_title('Heatmap of numeric columns highly correlated with price')\nplt.show()","35da0f5c":"cols = list(high_correlation.columns)\ng = sns.pairplot(data=train_data[cols])\nprint(f\"Pairplot of {' vs '.join(cols)}\")\nplt.show()","ddeb38dd":"# choose columns with absolute correlation less than threshold\n# low correlation may be due to non-linear relationships\nthreshold = 0.05\ncondition = correlation_matrix['SalePrice'].abs() < threshold\nlow_correlation = correlation_matrix.loc[condition, condition]\nlow_correlation","8961d9ea":"cols = list(low_correlation.columns)\ncols.append('SalePrice')\ng = sns.pairplot(data=train_data[cols])\nprint(f\"Pairplot of {' vs '.join(cols)}\")\nplt.show()","ed65058d":"for i in range(math.ceil(len(categorical_cols)\/slide)):\n    cols = categorical_cols[slide * i: slide * (i+1)]\n    display(train_data[cols].describe())","ffa9bfa1":"# check the cardinality of categorical columns\ncardinality = train_data[categorical_cols].nunique()\ncardinality = cardinality.sort_values(ascending=False)\ncardinality","47f15324":"cardinality.value_counts().sort_index()","dd6b9128":"# choose columns with cardinality lower than threshold\nthreshold = 10\ncondition = cardinality < threshold\nlow_cardinality_cols = list(cardinality[condition].index)\nlow_cardinality_cols","32fe5a62":"cols = 2\nrows = math.ceil(len(low_cardinality_cols)\/cols)\nfig, axes = plt.subplots(rows, cols, figsize=(14, 8\/\/cols*rows))\nplt.tight_layout()\n\nfor i, col in enumerate(low_cardinality_cols):\n    ax = axes[i\/\/cols, i%cols]\n    sns.histplot(data=train_data, x='SalePrice',\n                 hue=col, element='step', ax=ax)\n    ax.set_title(f'Histogram of SalePrice by {col}', y=0.88)\n\nplt.show()","6517fc2e":"# one-way ANOVA\nfrom scipy.stats import f_oneway\n\nanova_results = []\nfor col in categorical_cols:\n    groupby = train_data.groupby(col)['SalePrice']\n    categories = train_data[col].dropna().unique()\n    anova_data = [\n        groupby.get_group(category) for category in categories\n    ]\n\n    F, p = f_oneway(*anova_data)\n    anova_results.append([col, F, p])\n\ncolumns = ['feature', 'F-statistic', 'p-value']\nanova_df = pd.DataFrame(anova_results, columns=columns)\nanova_df = anova_df.sort_values('p-value')\nanova_df","e1a05a03":"# get the columns whose p-value is statistically significant\nthreshold = 0.01\nsignificant_anova = anova_df[anova_df['p-value'] < threshold]\nsignificant_anova","6645744f":"print(f'Categorical columns: {len(categorical_cols)}')\nprint(f'Low cardinality columns: {len(low_cardinality_cols)}')\n\nsignificant_anova_cols = significant_anova['feature'].values\nprint('Columns with statistically significant ANOVA p-value: {}'.format(\n    len(significant_anova_cols)\n))\n\nanova_low_cardinality =  set(significant_anova_cols) & set(low_cardinality_cols)\nprint('Columns with statistically significant ANOVA p-value and low cardinality: {}'.format(\n    len(anova_low_cardinality)\n))","90cda584":"print('Columns with low cardinality but statistically insignificant ANOVA p-value:')\nprint(set(low_cardinality_cols) - set(significant_anova_cols))\n\nprint('Columns with statistically significant ANOVA p-value but high cardinality:')\nprint(set(significant_anova_cols) - set(low_cardinality_cols))","5634da6f":"list(anova_low_cardinality)","a54a091d":"cardinality[anova_low_cardinality].value_counts()","8730bdb2":"cols = 2\nrows = math.ceil(len(anova_low_cardinality)\/cols)\nfig, axes = plt.subplots(rows, cols, figsize=(14, 8\/\/cols*rows))\nplt.tight_layout()\n\nfor i, col in enumerate(anova_low_cardinality):\n    ax = axes[i\/\/cols, i%cols]\n    sns.boxplot(data=train_data, x=col, y='SalePrice', ax=ax)\n    ax.set_title(f'Box plot of {col}', y=0.88)\n\nplt.show()","cf3c2160":"# Housing Prices EDA\n## Loading the data","a3e483d3":"### Categorical features","56198b84":"We have effectively removed the low cardinality columns that had little relationship with `SalePrice` from our list of categorical variables.","706c0a90":"### Numeric features","e5616118":"## Exploratory Data Analysis","bc458c35":"The missing values seem to be normally distributed within the data.","070fff43":"From pairplot above, we can observe that the relationship between`OverallQual` and `SalePrice` is quite non-linear.","6c6a8888":"### Missing values","cf0d1361":"From the pairplot above, we can see that features with low correlation actually have very little influence on `SalePrice`.","183b851d":"From the histograms above, we can see that some categorical variables seem to have an impact on price. Is there a relationship between the categorical variables and `SalePrice`?\n\nLet's perform a one-way ANOVA test for each categorical variable to find out.","c6c2e062":"From heatmap plot above, we can see that `OverallQual` has the strongest correlation with `SalePrice`, followed by `GrLivArea`, `GarageCars`, `GarageArea`, `1stFlrSF`, `TotalBsmtSF` and so on.\n\nHowever, the following features are **very** strongly correlated\n- `GarageCars` and `GarageArea`\n- `GrLivArea` and `TotRomsAbvGrd`\n- `TotalBsmtSF` and `1stFlrSF`\n\nwhich means that including both elements of each pair above results in some features being redundant."}}