{"cell_type":{"0dc9cfea":"code","1844613d":"code","15a9f8ae":"code","996f4a69":"code","1982ddd5":"code","a8bade4f":"code","c326a1b8":"code","9baab9e7":"code","5731ff0a":"code","3c623ef6":"code","46f021d3":"code","85c93f2a":"code","2d6f5151":"code","0c067acb":"code","053a4811":"code","3859514d":"code","0d010cfb":"code","c5049fa7":"code","0a11e1c1":"code","4a47c5d6":"code","65c862d0":"code","f7b9e791":"code","fb929a27":"code","7b31984b":"code","8fa95a8f":"markdown","d593fd0c":"markdown","9cbdb0fb":"markdown","2e59a9bc":"markdown","8cff2d28":"markdown","8212be46":"markdown","fdd4e00f":"markdown","87b9b342":"markdown","43374a0d":"markdown","f05aa1a2":"markdown","26cf7b7e":"markdown","9a4a7d85":"markdown","144db222":"markdown","ca0cfed2":"markdown","44205eb8":"markdown","1d050d85":"markdown","220b1573":"markdown","187c0ae8":"markdown","8003bb1a":"markdown","08a5b03e":"markdown","105fac0b":"markdown"},"source":{"0dc9cfea":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom mlxtend.plotting import plot_decision_regions","1844613d":"df = pd.read_csv('..\/input\/unsupervised-learning-on-country-data\/Country-data.csv')","15a9f8ae":"df.head()","996f4a69":"plt.figure(figsize = (16, 8))\nplt.scatter(df['country'], df['gdpp'])\nplt.ylabel(\"GDP\")\nplt.xlabel(\"Country\")\nplt.xticks([])\nplt.show()","1982ddd5":"# removing outliers\ndf = df.loc[df['gdpp'] <= 50000]\n# calculating mean GDP\nmean_gdp = np.mean(df['gdpp'])\ndf['Class'] = 1\n# dividing classes\nfor i in df.index:\n    if df.loc[i, 'gdpp'] < mean_gdp:\n        df.loc[i, 'Class'] = 0\n    elif df.loc[i, 'gdpp'] > 2*mean_gdp:\n        df.loc[i, 'Class'] = 2\nplt.figure(figsize = (16, 8))\nplt.scatter(df['country'], df['gdpp'])\nplt.ylabel(\"GDP\")\nplt.xlabel(\"Country\")\nplt.xticks([])\nplt.show()","a8bade4f":"gdp_above_twoavg = df.loc[df['Class'] == 2]\ngdp_above_avg = df.loc[df['Class'] == 1]\ngdp_below_avg = df.loc[df['Class'] == 0]\nplt.figure(figsize = (16, 8))\nplt.scatter(gdp_above_twoavg['country'], gdp_above_twoavg['gdpp'], label = \"GDP above 2*avg\")\nplt.scatter(gdp_above_avg['country'], gdp_above_avg['gdpp'], label = \"GDP btw avg-2*avg\")\nplt.scatter(gdp_below_avg['country'], gdp_below_avg['gdpp'], label = \"GDP below avg\")\nplt.xlabel(\"Country\")\nplt.ylabel(\"GDP\")\nplt.xticks([])\nplt.legend()\nplt.show()","c326a1b8":"y = df['Class']\nX = df.drop(['Class', 'country'], axis = 1)\nX.head()","9baab9e7":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)","5731ff0a":"X_train.head()","3c623ef6":"def plot_classes(X, y, clf, title):\n    values = {}\n    ranges = {}\n    for i in range(0, 8):\n        if i == 4:\n            pass\n        else:\n            values[i] = 50\n            ranges[i] = 500\n    plot_decision_regions(X, y, clf=clf,\n                          legend=2, feature_index = [4, 8],\n                          filler_feature_values = values,\n                          filler_feature_ranges = ranges)\n    plt.xlabel(\"Income per capita\")\n    plt.ylabel(\"Country GDP\")\n    plt.title(title)\n    plt.show()","46f021d3":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","85c93f2a":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train, y_train)\nprint(f\"Train Score: {logreg.score(X_train, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, logreg, 'Logistic Regression on train set')\nplot_classes(X_test.values, y_test.values, logreg, 'Logistic Regression on test set')","2d6f5151":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train_scaled, y_train)\nprint(f\"Train Score: {logreg.score(X_train, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 1\n        ranges[i] = 5\nplot_decision_regions(X_train_scaled, y_train.values, clf=logreg,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"Logistic Regression on train set with Feature Normalization\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=logreg,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"Logistic Regression on test set with Feature Normalization\")\nplt.show()","0c067acb":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nprint(f\"Train Score: {knn.score(X_train, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, knn, 'kNN on train set with k=3')\nplot_classes(X_test.values, y_test.values, knn, 'kNN on test set with k=3')","053a4811":"knn.fit(X_train_scaled, y_train)\nprint(f\"Train Score: {knn.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test_scaled, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 0.5\n        ranges[i] = 5\nplot_decision_regions(X_train_scaled, y_train.values, clf=knn,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"kNN on train set with Feature Normalization & k=3\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=knn,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"kNN on test set with Feature Normalization & k=3\")\nplt.show()","3859514d":"svm = SVC(gamma = 'auto', C = 10).fit(X_train, y_train)\nprint(f\"Train Score: {svm.score(X_train, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 100\n        ranges[i] = 500\nplot_decision_regions(X_train.values, y_train.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on train set\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test.values, y_test.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on test set\")\nplt.show()","0d010cfb":"svm = SVC(gamma = 'auto', C = 10).fit(X_train_scaled, y_train)\nprint(f\"Train Score: {svm.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test_scaled, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 0.8\n        ranges[i] = 4\nplot_decision_regions(X_train_scaled, y_train.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on train set with Feature Normalization\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on test set with Feature Normalization\")\nplt.show()","c5049fa7":"tree = DecisionTreeClassifier().fit(X_train, y_train)\nprint(f\"Train Score: {tree.score(X_train, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, tree, 'Decision Tree on train set')\nplot_classes(X_test.values, y_test.values, tree, 'Decision Tree on test set')","0a11e1c1":"tree = DecisionTreeClassifier().fit(X_train_scaled, y_train)\nprint(f\"Train Score: {tree.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test_scaled, y_test)}\")\nplot_classes(X_train_scaled, y_train.values, tree, 'Decision Tree on train set with Feature Normalization')\nplot_classes(X_test_scaled, y_test.values, tree, 'Decision Tree on test set with Feature Normalization')","4a47c5d6":"poly = PolynomialFeatures(degree = 2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)","65c862d0":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train_poly, y_train)\nprint(f\"Train Score: {logreg.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test_poly, y_test)}\")","f7b9e791":"knn.fit(X_train_poly, y_train)\nprint(f\"Train Score: {knn.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test_poly, y_test)}\")","fb929a27":"svm = SVC(gamma = 5, C = 10).fit(X_train_poly, y_train)\nprint(f\"Train Score: {svm.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test_poly, y_test)}\")","7b31984b":"tree = DecisionTreeClassifier().fit(X_train_poly, y_train)\nprint(f\"Train Score: {tree.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test_poly, y_test)}\")","8fa95a8f":"## kNN with Feature Normalization","d593fd0c":"## SVM","9cbdb0fb":"# Logistic Regression","2e59a9bc":"**According to results of all various algorithms, the performances are in the following order(best to worst(comaratively)):**\n1. Decision Tree\n2. kNN Classification\n3. Logistic Regression\n4. SVM","8cff2d28":"## Removing Outliers & visualzing data distribution","8212be46":"# Polynomial Features","fdd4e00f":"## Decision Tree with Feature Normalization","87b9b342":"# k Neighbors Classifier","43374a0d":"## kNN","f05aa1a2":"# Decision Tree","26cf7b7e":"## Making labels and features from the data","9a4a7d85":"## SVM with Feature Normalization","144db222":"## Splitting the data into train & test sets","ca0cfed2":"# Plotting Function","44205eb8":"# Support Vector Machine(SVM)","1d050d85":"# Feature Normalization","220b1573":"**Note that results of Decision Tree are same with simple features & normalized features, which should be as decision tree does not bother whether features are normalized or not, it simply classify based on values. So no matter what the scales are for various features, decision tree would always give the same result**","187c0ae8":"## Kernelized Support Vector Machine","8003bb1a":"## Decision Tree","08a5b03e":"## Logistic","105fac0b":"## Logistic Regression with Feature Normalization"}}