{"cell_type":{"4c79ff36":"code","01dbf211":"code","ab8b4504":"code","1ae6b81b":"code","3dc88899":"code","7e284441":"code","e2031b22":"code","8da73c5c":"code","3f7de6a1":"code","5a6945a2":"code","01b61275":"code","1994c5e8":"code","d6b9a3ee":"code","00bbf096":"code","1bd14f85":"code","3a30d6bf":"code","0bef2df8":"code","a52fb602":"code","68915152":"code","c7c0d4fe":"code","f0675077":"code","82d14a97":"code","6f43678e":"code","0a30ba7f":"code","42688851":"code","2c74f507":"code","b694cb44":"code","c7883550":"code","24e1d6ed":"code","d151a204":"code","0809c06f":"code","e90d98e0":"code","2f31546d":"code","f479754d":"code","51675589":"code","ce0ca037":"code","b863388a":"code","0f22f708":"code","86b94c09":"code","805cfb8a":"code","3e349ae8":"code","ef184d7f":"code","41529f51":"code","2171a0f1":"code","c23c3ca3":"code","81fd557e":"code","7933fde9":"code","89933949":"code","17c7d709":"code","aa97148e":"code","4dd81763":"code","0f4c728c":"code","937e167c":"code","b3854e9d":"code","8ef42151":"code","745570e5":"code","bbef904e":"code","0067621c":"code","8014cc0f":"code","2318ec80":"code","4dc368c3":"code","87b1f052":"code","dcce867f":"code","057bd88a":"code","49e11b98":"code","e01ee10e":"code","ae95a4a8":"code","3ea90a01":"code","4e2eedec":"code","3e964a8c":"markdown","7ee539ee":"markdown","f50110db":"markdown","edf8778a":"markdown","d014d4ca":"markdown","bc5f323b":"markdown","ae45f61f":"markdown","60b80ddc":"markdown","38d43ab2":"markdown","a53961f9":"markdown","db6ac0bb":"markdown","ccda71b2":"markdown","e9689898":"markdown","807d2afe":"markdown","f839f5e1":"markdown","4f96d2d2":"markdown","e83f7546":"markdown","8d3e2830":"markdown","0ae4a406":"markdown","d7501a22":"markdown","360caf2c":"markdown","c9212edc":"markdown","25919767":"markdown","8b5db733":"markdown","df7eb7df":"markdown","bd3ce16e":"markdown","39aad505":"markdown","80cbb14f":"markdown","a467e6e8":"markdown","84c125a7":"markdown","e07df6c0":"markdown","bf8f04aa":"markdown","8371b6ff":"markdown","c360d480":"markdown","ffcaf932":"markdown","8c1b970e":"markdown","9ec21fa8":"markdown","700ca99e":"markdown","2a19b767":"markdown","c6f587fa":"markdown","e4712d60":"markdown","b57307ac":"markdown","6c7afbfd":"markdown","77b8967e":"markdown","2015ce3a":"markdown","49dfb026":"markdown","e67818a8":"markdown","781b7ac3":"markdown","92e58c4d":"markdown"},"source":{"4c79ff36":"import pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","01dbf211":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data  = pd.read_csv(\"..\/input\/titanic\/test.csv\")","ab8b4504":"train_data.info()","1ae6b81b":"train_data.head()","3dc88899":"x = DataFrame(train_data['Survived'].value_counts()).reset_index()\nx.columns = ['Survived', 'Count']\nprint(x)\n\nsrviv_pct = 100 * x.iloc[1, 1]\/(x.iloc[0, 1] + x.iloc[1, 1])\nprint(\"Survival Percentage in Train Data:\", srviv_pct)","7e284441":"sns.barplot(x='Survived', y='Count', data=x)","e2031b22":"x = DataFrame(train_data['Pclass'].value_counts()).reset_index()\nx.columns = ['Pclass', 'Count']\nprint(x)\nprint('----------------')\n\nx = DataFrame(train_data['Sex'].value_counts()).reset_index()\nx.columns = ['Sex', 'Count']\nprint(x)\nprint('----------------')\n\nx = DataFrame(train_data['SibSp'].value_counts()).reset_index()\nx.columns = ['SibSp', 'Count']\nprint(x)\nprint('----------------')\n\nx = DataFrame(train_data['Parch'].value_counts()).reset_index()\nx.columns = ['Parch', 'Count']\nprint(x)\nprint('----------------')\n\nx = DataFrame(train_data['Embarked'].value_counts()).reset_index()\nx.columns = ['Embarked', 'Count']\nprint(x)","8da73c5c":"train_data[train_data['Fare'] == 0]","3f7de6a1":"train_data[train_data['Fare'] == 0].shape","5a6945a2":"train_data[train_data['Age'] == 0]","01b61275":"fig, (axis1, axis2) = plt.subplots(1, 2, sharey=True)\n\nsns.kdeplot(data=train_data['Age'], ax=axis1)\nsns.kdeplot(data=train_data['Fare'], ax=axis2)","1994c5e8":"sns.violinplot(data=train_data['Age']).set_title('Age')","d6b9a3ee":"sns.violinplot(data=train_data['Fare']).set_title(\"Fare\")","00bbf096":"sns.distplot(train_data['Age'], bins=50,\n            kde_kws ={'color': 'darkgreen', 'alpha': 0.9, 'label': 'KDE Plot'},\n            hist_kws={'color': 'red', 'alpha': 0.6, 'label': 'Histogram'})","1bd14f85":"sns.distplot(train_data['Fare'], bins=50,\n            kde_kws ={'color': 'darkgreen', 'alpha': 0.6, 'label': 'KDE Plot'},\n            hist_kws={'color': 'red', 'alpha': 0.6, 'label': 'Histogram'})","3a30d6bf":"g = sns.FacetGrid(train_data, col=\"Survived\", col_wrap=3,height=4)\ng = (g.map(plt.hist, \"Pclass\"))","0bef2df8":"g = sns.FacetGrid(train_data, col=\"Survived\", col_wrap=3,height=4)\ng = (g.map(plt.hist, \"SibSp\"))","a52fb602":"g = sns.FacetGrid(train_data, col=\"Survived\", col_wrap=3,height=4)\ng = (g.map(plt.hist, \"Parch\"))","68915152":"grid = sns.FacetGrid(train_data, row='Embarked')\ngrid.map(plt.hist, 'Survived')","c7c0d4fe":"grid = sns.FacetGrid(train_data, row='Sex')\ngrid.map(plt.hist, 'Survived')","f0675077":"grid = sns.FacetGrid(train_data, row='Embarked', col='Sex')\ngrid.map(plt.hist, 'Survived')","82d14a97":"grid = sns.FacetGrid(train_data, row='Embarked')\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', order=None, hue_order=None)\ngrid.add_legend()","6f43678e":"grid = sns.FacetGrid(train_data, row='Sex', col='Survived')\ngrid.map(plt.hist, 'Age', bins=20)","0a30ba7f":"grid = sns.FacetGrid(train_data, row='Sex')\ngrid.map(sns.pointplot, 'Pclass', 'Survived', order=None, hue_order=None)\ngrid.add_legend()","42688851":"from sklearn.impute import SimpleImputer\nchar_imputer = SimpleImputer(strategy=\"most_frequent\")\nx = DataFrame(char_imputer.fit_transform(train_data[[\"Embarked\"]]))\nx.columns= ['Imputed_Embarked']\n\ntrain_data = pd.concat([train_data, x], axis=1)\ntrain_data = train_data.drop(['Cabin', 'Embarked'], axis=1)","2c74f507":"train_data[['Sex', 'Age']].groupby(['Sex']).mean().sort_values('Age', ascending=False)","b694cb44":"train_data[['Pclass', 'Sex', 'Age']].groupby(['Pclass', 'Sex']).mean().sort_values('Age', ascending=False)","c7883550":"x = DataFrame(train_data[['Pclass', 'Sex', 'Age']].groupby(['Pclass', 'Sex']).mean().reset_index())\n\nfor i in range(train_data.shape[0]):\n    if np.isnan(train_data.loc[i, 'Age']):\n        for j in range(0, 6):\n            if train_data.loc[i, 'Sex'] == x.loc[j, 'Sex'] and train_data.loc[i, 'Pclass'] == x.loc[j, 'Pclass']:\n                train_data.loc[i, 'Age'] = x.loc[j, 'Age']","24e1d6ed":"train_data.info()","d151a204":"train_data['Family'] = train_data['SibSp'] + train_data['Parch']\n\ngrid = sns.FacetGrid(train_data, col='Survived')\ngrid.map(plt.hist, 'Family', bins=20)","0809c06f":"train_data['Age_Bin'] = pd.qcut(train_data['Age'], 10, labels=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"])\ntrain_data['Age_Bin'] = train_data['Age_Bin'].astype(int)","e90d98e0":"train_data[['Sex', 'Age_Bin', 'Survived']].groupby(['Sex', 'Age_Bin']).mean().sort_values('Survived', ascending=False)","2f31546d":"train_data[['Age_Bin', 'Survived']].groupby(['Age_Bin']).mean().sort_values('Survived', ascending=False)","f479754d":"train_data['Sex'] = train_data['Sex'].map({'male': 0, 'female': 1}).astype(int)\ntrain_data['Imputed_Embarked'] = train_data['Imputed_Embarked'].map({'S': 0, 'Q': 1, 'C': 2}).astype(int)","51675589":"train_data['Pclass_Sex'] = train_data['Pclass'] * train_data['Pclass'] + train_data['Sex']\ntrain_data[['Pclass_Sex', 'Survived']].groupby('Pclass_Sex').mean().sort_values('Survived', ascending=False)","ce0ca037":"from sklearn.preprocessing import StandardScaler\nstd_scaler_Fare = StandardScaler()\nstd_scaler_Age = StandardScaler()\ntrain_data['Fare'] = std_scaler_Fare.fit_transform(train_data[['Fare']])\ntrain_data['Age']  = std_scaler_Age.fit_transform(train_data[['Age']])","b863388a":"train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntrain_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n\ntrain_data['Title'] = train_data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).astype(int)\n\ntrain_data['Title'] = train_data['Title'].fillna(0)","0f22f708":"train_data.head()","86b94c09":"train_data_model = train_data.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\ntrain_data_label = train_data['Survived']\n\ntrain_data_model.info()","805cfb8a":"from sklearn.svm import SVC, LinearSVC\nfrom sklearn.linear_model import SGDClassifier, Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","3e349ae8":"svc = SVC(random_state=42)\nsvc.fit(train_data_model, train_data_label)\nacc_svc = round(svc.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_svc)","ef184d7f":"perceptron = Perceptron(random_state=42)\nperceptron.fit(train_data_model, train_data_label)\nacc_perceptron = round(perceptron.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_perceptron)","41529f51":"linear_svc = LinearSVC(random_state=42, max_iter=10000)\nlinear_svc.fit(train_data_model, train_data_label)\nacc_linear_svc = round(linear_svc.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_linear_svc)","2171a0f1":"sgd = SGDClassifier(random_state=42)\nsgd.fit(train_data_model, train_data_label)\nacc_sgd = round(sgd.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_sgd)","c23c3ca3":"decision_tree = DecisionTreeClassifier(random_state=42)\ndecision_tree.fit(train_data_model, train_data_label)\nacc_decision_tree = round(decision_tree.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_decision_tree)","81fd557e":"random_forest = RandomForestClassifier(random_state=42, n_estimators=100)\nrandom_forest.fit(train_data_model, train_data_label)\nacc_random_forest = round(random_forest.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_random_forest)","7933fde9":"from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\ncv_score = cross_val_score(random_forest, train_data_model, train_data_label, cv=10, scoring='accuracy')\n\nprint(\"Mean Score     :\", cv_score.mean())\nprint(\"Std Dev Score  :\", cv_score.std())","89933949":"importances = pd.DataFrame({'Feature':train_data_model.columns,'Importance':np.round(random_forest.feature_importances_,3)})\nimportances = importances.sort_values('Importance',ascending=False).set_index('Feature')\nimportances.head(15)","17c7d709":"train_data_model = train_data_model.drop(['SibSp', 'Parch'], axis=1)\n\nrandom_forest.fit(train_data_model, train_data_label)\nacc_random_forest = round(random_forest.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_random_forest)","aa97148e":"cv_score = cross_val_score(random_forest, train_data_model, train_data_label, cv=10, scoring='accuracy')\n\nprint(\"Mean Score     :\", cv_score.mean())\nprint(\"Std Dev Score  :\", cv_score.std())\n\nimportances = pd.DataFrame({'Feature':train_data_model.columns,'Importance':np.round(random_forest.feature_importances_,3)})\nimportances = importances.sort_values('Importance',ascending=False).set_index('Feature')\nimportances.head(15)","4dd81763":"param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25], \"min_samples_split\" : [10, 12, 16, 18], \"n_estimators\": [100, 700, 1500]}\nrf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n\ngrid_search.fit(train_data_model, train_data_label)\n\ngrid_search.best_params_","0f4c728c":"random_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 16,   \n                                       n_estimators=1500, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\nrandom_forest.fit(train_data_model, train_data_label)\nacc_random_forest = round(random_forest.score(train_data_model, train_data_label) * 100, 2)\nprint(acc_random_forest)\nprint(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")","937e167c":"cv_score = cross_val_score(random_forest, train_data_model, train_data_label, cv=10, scoring='accuracy')\n\nprint(\"Mean Score     :\", cv_score.mean())\nprint(\"Std Dev Score  :\", cv_score.std())","b3854e9d":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, classification_report\n\ntrain_label_predict = random_forest.predict(train_data_model)\nprint(\"Confusion Matrix: \\n\", confusion_matrix(train_data_label, train_label_predict))\n\nprint(\"Precision: \", precision_score(train_data_label, train_label_predict))\nprint(\"Recall   : \", recall_score(train_data_label, train_label_predict))\nprint(\"f1 Score : \", f1_score(train_data_label, train_label_predict))","8ef42151":"print(classification_report(train_data_label, train_label_predict, target_names=['Not-Survived', 'Survived']))","745570e5":"train_data_label_scores = random_forest.predict_proba(train_data_model)\ntrain_data_label_scores = train_data_label_scores[:,1]\n\nprecision, recall, threshold = precision_recall_curve(train_data_label, train_data_label_scores)\ndef plot_precision_and_recall(precision, recall, threshold):\n    plt.plot(threshold, precision[:-1], \"r-\", label=\"Precision\", linewidth=5)\n    plt.plot(threshold, recall[:-1], \"b\", label=\"Recall\", linewidth=5)\n    plt.xlabel(\"Threshold\", fontsize=19)\n    plt.legend(loc=\"upper right\", fontsize=19)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(14, 7))\nplot_precision_and_recall(precision, recall, threshold)\nplt.show()","bbef904e":"def plot_precision_vs_recall(precision, recall):\n    plt.plot(recall, precision, \"g--\", linewidth=2.5)\n    plt.ylabel(\"Recall\", fontsize=19)\n    plt.xlabel(\"Precision\", fontsize=19)\n    plt.axis([0, 1.5, 0, 1.5])\n\nplt.figure(figsize=(14, 7))\nplot_precision_vs_recall(precision, recall)\nplt.show()","0067621c":"false_positive_rate, true_positive_rate, thresholds = roc_curve(train_data_label, train_data_label_scores)\n\ndef plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n\nplt.figure(figsize=(14, 7))\nplot_roc_curve(false_positive_rate, true_positive_rate)\nplt.show()\nprint(roc_auc_score(train_data_label, train_data_label_scores))","8014cc0f":"test_data.info()","2318ec80":"test_data[np.isnan(test_data['Fare'])]","4dc368c3":"min_fare = np.min(test_data['Fare'])\n\nfor i in range(test_data.shape[0]):\n    if np.isnan(test_data.loc[i, 'Fare']):\n        test_data.loc[i, 'Fare'] = min_fare","87b1f052":"test_data[np.isnan(test_data['Fare'])]","dcce867f":"test_data.info()","057bd88a":"x = DataFrame(char_imputer.transform(test_data[[\"Embarked\"]]))\nx.columns= ['Imputed_Embarked']\n\ntest_data = pd.concat([test_data, x], axis=1)\n\ntest_data = test_data.drop(['Cabin', 'Embarked'], axis=1)\n\nx = DataFrame(test_data[['Pclass', 'Sex', 'Age']].groupby(['Pclass', 'Sex']).mean().reset_index())\n\nfor i in range(test_data.shape[0]):\n    if np.isnan(test_data.loc[i, 'Age']):\n        for j in range(0, 6):\n            if test_data.loc[i, 'Sex'] == x.loc[j, 'Sex'] and test_data.loc[i, 'Pclass'] == x.loc[j, 'Pclass']:\n                test_data.loc[i, 'Age'] = x.loc[j, 'Age']\n\ntest_data['Family'] = test_data['SibSp'] + test_data['Parch']\n\ntest_data['Age_Bin'] = pd.qcut(test_data['Age'], 10, labels=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"])\ntest_data['Age_Bin'] = test_data['Age_Bin'].astype(int)\n\ntest_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1}).astype(int)\ntest_data['Imputed_Embarked'] = test_data['Imputed_Embarked'].map({'S': 0, 'Q': 1, 'C': 2}).astype(int)\n\ntest_data['Pclass_Sex'] = test_data['Pclass'] * test_data['Pclass'] + test_data['Sex']\n\ntest_data['Fare'] = std_scaler_Fare.transform(test_data[['Fare']])\ntest_data['Age']  = std_scaler_Age.transform(test_data[['Age']])\n\ntest_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntest_data['Title'] = test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\n\ntest_data['Title'] = test_data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).astype(int)\n\ntest_data['Title'] = test_data['Title'].fillna(0)\n\n## Prepare final data for model\ntest_data_model = test_data.drop(['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch'], axis=1)","49e11b98":"test_data_model.info()","e01ee10e":"test_data_predictions = random_forest.predict(test_data_model)\npred = DataFrame(test_data_predictions)\npred.columns = ['Survived']\npredictions = pd.concat([test_data['PassengerId'], pred], axis=1)\npredictions.to_csv(\"Submission_RF.csv\", index=False)","ae95a4a8":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout","3ea90a01":"classifier = Sequential([Dense(128, activation='relu', input_shape=(train_data_model.shape[1], )),\n                         Dropout(rate=0.1),\n                         Dense(64, activation='relu'),\n                         Dropout(rate=0.1),\n                         Dense(1, activation='sigmoid')])\n\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Accuracy'])\nclassifier.fit(train_data_model, train_data_label,\n                    batch_size=20,\n                    epochs=20)","4e2eedec":"test_data_predictions = classifier.predict(test_data_model)\npred = DataFrame(test_data_predictions)\npred.columns = ['Survived']\npredictions = pd.concat([test_data['PassengerId'], pred], axis=1)\npredictions.to_csv(\"Submission_ANN.csv\", index=False)","3e964a8c":"#### Check if there is any row with Age as Zero","7ee539ee":"#### OBSERVATION: Age range 20-40 Female has high survival rate and Male has low survival rate","f50110db":"#### Check if there is any row with Fare as Zero","edf8778a":"#### OBSERVATION: Sex is evidently the dominant factor of Survival","d014d4ca":"#### OBSERVATION: Pclass=3 has lowest survival rate.","bc5f323b":"#### OBSERVATION: Sibsp does not provide any definite conclusion","ae45f61f":"#### Use this best_params to train Random Forest.","60b80ddc":"#### So we can see there is no missing value in the train data.","38d43ab2":"#### Fit data to the model","a53961f9":"#### Since SibSp and Parch have less importance we will remove and train Random Forest again.","db6ac0bb":"#### OBSERVATION: Passengers embarked from S has lowest survival rate","ccda71b2":"#### Understand different Metrics of the Model.","e9689898":"#### Variable Importance.","807d2afe":"#### OBSERVATION: Females have high survival rate","f839f5e1":"#### Import the libraries","4f96d2d2":"#### Next action item is to identify survival trend for different attribute and try to explore meaningful insights from the data.","e83f7546":"#### OBSERVATION: Embarked from Q Pclass 3 Male have high survival rate","8d3e2830":"#### Feature Engineering - Try to create some feature\n\n#### Create a new column Family = SibSp + Parch","0ae4a406":"#### Since we can see there is some relation between mean age of passengers with their Pclass and Sex combination we will impute missing Ages using mean values of Pclass-Sex combination.","d7501a22":"#### Create a new column Pclass_Sex as Pclass ** 2 + Sex","360caf2c":"#### Precision-Recall Curve","c9212edc":"#### We can see there is missing value in 'Fare' column unlike train data; so for this we don't have any imputation strategy. Ideally we should have a strategy but for simplicity we will replace the missing value with minimum fare.","25919767":"#### Precision Vs Recall","8b5db733":"#### Load the dataset","df7eb7df":"#### Let's see the first few lines of the train data","bd3ce16e":"#### Since this is a Classification problem I am using 'Accuracy' as my Metric and Area-Under-Curve is also good. So I will now proceed towards applying this model on test dataset.\n\n#### Apply data pre-processing on test data.","39aad505":"#### Now let's try to apply Artificial Neural Network to see how it goes.","80cbb14f":"#### Let's see the distribution of 2 Numerical predictors - Age and Fare","a467e6e8":"#### Create a new column Age_Bin with Pandas qcut() method.","84c125a7":"#### Missing Value Imputation","e07df6c0":"#### OBSERVATION: There is a sharp dip in Survival rate of Pclass 3 females","bf8f04aa":"#### So we can see train data has slighty less representation of Survived passengers but it is not highly skewed.","8371b6ff":"#### ROC Curve","c360d480":"#### Let's see whether the train data is balanced i.e it has equal representation of Survived vs Not-Survived","ffcaf932":"#### Prepare final data for model","8c1b970e":"#### OBSERVATION: Parch does not provide any definite conclusion","9ec21fa8":"#### Scale Fare and Age","700ca99e":"#### For 'Embarked' we will replace missing values by most frequent character of this column andwe will remove 'Cabin' because it has too many Null values.","2a19b767":"#### Explore the distribution of different categorical predictor variables","c6f587fa":"#### So we can conclude that -\n1. Distribution of Age is somewhat Normal and most people has age between 20 to 40.\n2. Fare is highly skewed with Fare for most people is less than 10.","e4712d60":"#### So there are 15 rows with Fare as Zero which we need to impute.","b57307ac":"#### This is one of the basic dataset that almost all the people in the field of Machine Learning have used to practice their skill and I am of no exception.\n\n#### As Jack in this movie said \"I figure life's a gift and I don't intend on wasting it.\" I too intended to understand this problem but as a novice I took help from different solutions in Kaggle and in other forums.\n\n#### So let's proceed...","6c7afbfd":"#### 'Survived' is the target column which we need to learn and predict from the test data and based on the problem description we can easily understand it is a Classification problem where Survived=1 means Survived but Survived=0 means Not-Survived.\n\n#### We can see 'Age', 'Cabin' and 'Embarked' columns have Null values which we need to impute.","77b8967e":"#### Convert Categorical variable to Numeric","2015ce3a":"#### Create a new column 'Title' and converted it to Numeric.","49dfb026":"#### Exploration of train data","e67818a8":"#### Since Random Forest is giving maximum accuracy we will do a grid search on Random Forest.","781b7ac3":"#### Since Random Forest is giving maximum accurancy we will use this model.\n\n#### Cross Validation.","92e58c4d":"#### So we can clearly see -\n\n1. Maximum people are travelling in Pclass 3.\n2. Maximum people are male.\n3. Maximum people are travelling alone.\n4. Maximum people have embarked from S."}}