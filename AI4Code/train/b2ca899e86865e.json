{"cell_type":{"433e352d":"code","6bb4d8f3":"code","a56573d2":"code","27b3fb48":"code","c96f11d2":"code","db4cf6e2":"code","77a31ab7":"code","0634f3dd":"code","0c9cf2bc":"code","3d60f3b4":"markdown","e826b9bc":"markdown","5a45ce2d":"markdown","6f094079":"markdown","c05401ba":"markdown","0d02237f":"markdown"},"source":{"433e352d":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython import display\nimport time","6bb4d8f3":"X = np.arange(100, dtype=float)\ny = np.concatenate((np.zeros(50, dtype=float), np.ones(50, dtype=float)), axis=0)","a56573d2":"plt.scatter(X, y)","27b3fb48":"def mse(y, y_pred): ##mean squared error\n  return np.sum((y - y_pred)**2)\/y.shape[0]","c96f11d2":"epoch_loss = []\n\nslope = 0.\nbias = 0.\nlearning_rate = 1e-6 \nn = X.shape[0]\n\nfor epoch in range(10): \n  y_pred = slope*X + bias\n  loss = mse(y, y_pred)\n  epoch_loss.append(loss)\n\n  ######plotting#####\n  display.display(plt.gcf())\n  display.clear_output(wait=True)\n  fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n  ax0.scatter(X, y)\n  ax0.plot(X, y_pred, 'r')\n  ax0.set_title('slope = {0:.5f}, bias = {1:.5f}'.format(slope, bias))\n  ax1.set_title('mse = {0:.2f}'.format(loss))\n  ax1.plot(epoch_loss)\n  plt.show()\n  time.sleep(1)\n  ###################\n  \n  ###slope and bias derivatives with respect to mse###\n  D_mse_wrt_slope = -np.sum(X * (y - y_pred)) \n  D_mse_wrt_bias = -np.sum(y - y_pred) \n  \n  \n  slope = (slope - learning_rate * D_mse_wrt_slope)\n  bias = (bias - learning_rate * D_mse_wrt_bias)","db4cf6e2":"X = np.concatenate((X, np.array([200])))\ny = np.concatenate((y, np.array([1])))","77a31ab7":"epoch_loss = []\n\nslope = 0.\nbias = 0.\nlearning_rate = 1e-6 \nn = X.shape[0]\n\nfor epoch in range(10):\n  y_pred = slope*X + bias\n  loss = mse(y, y_pred)\n  epoch_loss.append(loss)\n\n  ######plotting#####\n  display.display(plt.gcf())\n  display.clear_output(wait=True)\n  fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n  ax0.scatter(X, y)\n  ax0.plot(X, y_pred, 'r')\n  ax0.set_title('slope = {0:.5f}, bias = {1:.5f}'.format(slope, bias))\n  ax1.set_title('mse = {0:.2f}'.format(loss))\n  ax1.plot(epoch_loss)\n  plt.show()\n  time.sleep(1)\n  ###################\n  \n  \n  ###slope and bias derivatives with respect to mse###\n  D_mse_wrt_slope = -np.sum(X * (y - y_pred))\n  D_mse_wrt_bias = -np.sum(y - y_pred)\n\n  slope = (slope - learning_rate * D_mse_wrt_slope)\n  bias = (bias - learning_rate * D_mse_wrt_bias)","0634f3dd":"def log_loss(y, y_pred): ##log loss error (binary cross entropy)\n  return -np.sum((y*np.log(y_pred) + (1-y)*np.log(1-y_pred)))\/y.shape[0]","0c9cf2bc":"epoch_loss = []\n\nslope = 0.\nbias = 0.\nlearning_rate = 1e-5\nn = X.shape[0]\n\nfor epoch in range(700000+1):\n  linear = slope*X + bias\n  y_pred = 1\/(1+np.exp(-linear)) ##logistic\n  loss = log_loss(y, y_pred)\n  epoch_loss.append(loss)\n\n\n  if(epoch%50000 == 0):\n    ######plotting#####\n    display.display(plt.gcf())\n    display.clear_output(wait=True)\n    fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n    fig.suptitle('epoch = {0}'.format(epoch))\n    ax0.scatter(X, y)\n    ax0.plot(X, y_pred, 'r')\n    ax0.set_title('slope = {0:.5f}, bias = {1:.5f}'.format(slope, bias))\n    ax1.set_title('loss = {0:.2f}'.format(loss))\n    ax1.plot(epoch_loss)\n    plt.show()\n    time.sleep(1)\n    ###################\n    \n  ###slope and bias derivatives with respect to loss###\n  dLoss_dLogistic = (-y\/y_pred) + ((1-y)\/(1-y_pred))\n  dLogistic_dLinear = y_pred*(1-y_pred)\n  dLinear_dSlope = X\n  ##computational graph\n  dLoss_dSlope = np.sum(dLoss_dLogistic * dLogistic_dLinear * dLinear_dSlope) \n  dLoss_dBias = np.sum(dLoss_dLogistic * dLogistic_dLinear)\n  \n  slope = slope - learning_rate * dLoss_dSlope\n  bias = bias - learning_rate * dLoss_dBias","3d60f3b4":"<h1>Putting It All Together<\/h1>","e826b9bc":"<h1>The Problem with Linear Regression<\/h1>","5a45ce2d":"<h1>Logistic Regressions Loss Function<\/h1>","6f094079":"<h1>Logistic Regression's Computation Graph<\/h1>","c05401ba":"![image.png](attachment:image.png)","0d02237f":"<h1>Applying Linear Regression to Binary Data<\/h1>"}}