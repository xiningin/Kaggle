{"cell_type":{"c2aedbf6":"code","650e82ae":"code","2ad35b84":"code","55d6cdf6":"code","34c8e60a":"code","0a391b58":"code","ce184076":"code","06abeff1":"code","9ed6b4a4":"code","1ad76547":"code","3f516f51":"code","0817fb88":"code","9b5fdd77":"code","a4cb0caa":"code","2f2bd994":"code","2af41abb":"code","a374bd8f":"code","303ac068":"code","5d732229":"code","59d84d3e":"code","3d1dd8fb":"code","4b13d538":"code","50a3feff":"code","7c11a4fc":"code","81c9d911":"code","64710c5a":"code","660f82d7":"code","97ac517a":"code","4d61a891":"code","4eba29ca":"code","f574d035":"code","9af9b87a":"code","f5e8e484":"code","007bd37f":"code","ae0d7cfb":"code","ca9dcdf1":"code","71b57960":"code","b35bc18d":"code","02189418":"code","b5dc83f3":"code","2829553d":"code","559d05ca":"code","c45930da":"code","4078b981":"code","07624b86":"code","da58b4ee":"code","cb784fd4":"code","304fc026":"code","868f23fe":"code","1b3c6d16":"code","3247ac85":"code","d27838cf":"code","34b78840":"code","ebfbaa0c":"code","c3c83857":"code","c0ef7d44":"code","cd85ca52":"code","afd467aa":"code","bb12c449":"code","7e31d73c":"code","c7642781":"code","82180992":"code","a64fa7a4":"code","ac96394f":"code","57f6c39a":"code","183d974c":"code","7f3585d2":"code","29f82d87":"markdown","c5b4a11d":"markdown","9adc6695":"markdown","b8d2b5e9":"markdown","a3fcc0dc":"markdown","37cf5d19":"markdown","e1158616":"markdown","cc44cc13":"markdown"},"source":{"c2aedbf6":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom pandas.plotting import register_matplotlib_converters\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 22, 10\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","650e82ae":"df=pd.read_csv('..\/input\/pgcb-power-demand-data\/PGCB_Demand_Data_2021.csv')\ndf[\"DateTime\"] = pd.to_datetime(df.date.astype(str) + ' ' + df.hour.astype(str), format='%m\/%d\/%Y %H')\ndf[\"DateTime\"]=pd.to_datetime(df[\"DateTime\"])\ndf.set_index(\"DateTime\",inplace=True)\ndf","2ad35b84":"df.shape","55d6cdf6":"sns.lineplot(x=df.index, y=\"demand\", data=df);","34c8e60a":"sns.lineplot(x='month', y=\"demand\", data=df);","0a391b58":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposed=seasonal_decompose(df[\"demand\"],\n                             model='additive'\n                             )","ce184076":"trend=decomposed.trend\nsesonal=decomposed.seasonal\nresidual=decomposed.resid","06abeff1":"plt.figure(figsize=(20,16))\nplt.subplot(411)\nplt.plot(df[\"demand\"],label=\"Orginal\",color='red')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(trend,label=\"Trend\",color='red')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(sesonal,label=\"Sesonal\",color='red')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(residual,label=\"Residual\",color='red')\nplt.legend(loc='upper left')\nplt.show()","9ed6b4a4":"# from sklearn.preprocessing import MinMaxScaler\n# scaler=MinMaxScaler(feature_range=(0,1))\n# X=scaler.fit_transform(df.demand.values.reshape(-1,1))\nD_max_daily = df.groupby(df.index).demand.max().to_numpy()\ndf.demand= df.demand\/max(D_max_daily)\nD_max=max(D_max_daily)","1ad76547":"##splitting dataset into train and test split\ntraining_size=int(len(df)*0.65)\ntest_size=len(df)-training_size\ntrain_data,test_data=df.demand[0:training_size],df.demand[training_size:len(df)]","3f516f51":"train=train_data.values.reshape(-1,1)\ntest=test_data.values.reshape(-1,1)","0817fb88":"train.shape","9b5fdd77":"test.shape","a4cb0caa":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-time_step-1):\n\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + time_step, 0])\n\treturn np.array(dataX), np.array(dataY)","2f2bd994":"# reshape into X=t,t+1,t+2,t+3 and Y=t+4\ntime_step = 24*7 # take time laps for 7 days\nX_train, y_train = create_dataset(train, time_step)\nX_test, ytest = create_dataset(test, time_step)","2af41abb":"print(X_train.shape)\nprint(y_train.shape)","a374bd8f":"print(X_test.shape)\nprint(ytest.shape)","303ac068":"# reshape input to be [samples, time steps, features] which is required for LSTM\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","5d732229":"#print(X_train[:3])\n#print(y_train[:3])\n#print(X_test.shape)\n#print(len(X_train[1]))\nprint(X_train[0])","59d84d3e":"X_train","3d1dd8fb":"from keras.models import Sequential\nfrom keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional,GRU\nfrom tensorflow.keras.optimizers import Adam \nfrom keras.callbacks import EarlyStopping, TensorBoard\n\nfrom keras.layers import TimeDistributed\n\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\n","4b13d538":"model=Sequential()\nmodel.add(LSTM(50,input_shape=(X_train.shape[1],X_train.shape[2])))\nmodel.add(RepeatVector(168))\n\nmodel.add(LSTM(50,return_sequences=True))\n\nmodel.add(TimeDistributed(Dense(100, activation='relu')))\nmodel.add(LSTM(50))\n\nmodel.add(Dense(1))\n\nmodel.compile(loss='mean_absolute_percentage_error',optimizer='adam')","50a3feff":"model.summary()","7c11a4fc":"import time\nstart_time = time.time()\nhistory=model.fit(X_train,y_train,epochs = 40, batch_size=64,validation_split=0.1)\nfinish_time = time.time()\nprint(\"--- %s seconds ---\" % (finish_time - start_time))","81c9d911":"print((finish_time - start_time)\/60,'minutes')\nscores = model.evaluate(X_test, ytest)\nprint(\"TEST MAPE :\",scores)","64710c5a":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], linewidth =4)\nplt.plot(history.history['val_loss'], linewidth =4)\nplt.grid(False)\na =  plt.legend(['train loss','validation loss'])\n\n\n\nplt.show()","660f82d7":"### Lets Do the prediction and check performance metrics\ntrain_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","97ac517a":"test_predict","4d61a891":"### Calculate RMSE performance metrics\nimport math\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train*D_max,train_predict*D_max))","4eba29ca":"### Test Data RMSE\nmath.sqrt(mean_squared_error(ytest*D_max,test_predict*D_max))","f574d035":"train_predict.shape","9af9b87a":"y_train_rs=y_train.reshape(-1,1)\ny_train_rs.shape","f5e8e484":"df.demand.shape","007bd37f":"train_predict.shape","ae0d7cfb":"test_predict.shape","ca9dcdf1":"plt.plot(test_predict*D_max)\nplt.plot(ytest*D_max)\nplt.legend(['PREDICTED','ACTUAL'])","71b57960":"plt.plot(test_predict[:24]*D_max, linewidth = 4)\nplt.plot(ytest[:24]*D_max, linewidth = 4)\nplt.grid(False)\nplt.legend(['PREDICTED','ACTUAL'])\n","b35bc18d":"nsamples, nx, ny = X_train.shape\nd2_train_dataset = X_train.reshape((nsamples,nx*ny))","02189418":"from sklearn.ensemble import RandomForestRegressor\ncls = RandomForestRegressor(n_estimators=1,min_samples_leaf=100)\ncls.fit(d2_train_dataset,y_train)","b5dc83f3":"nsamples, nx, ny = X_test.shape\nd2_test_dataset = X_test.reshape((nsamples,nx*ny))","2829553d":"sk_pred=cls.predict(d2_test_dataset)","559d05ca":"plt.plot(sk_pred[0:24]*D_max, linewidth = 4)\nplt.plot(ytest[0:24]*D_max, linewidth = 4)\nplt.grid(False)\n\nplt.legend(['PREDICTED(RF)','ACTUAL'])","c45930da":"import sklearn.metrics\nfrom sklearn.metrics import mean_squared_error","4078b981":"def percentage_error(actual, predicted):\n    res = np.empty(actual.shape)\n    for j in range(actual.shape[0]):\n        if actual[j] != 0:\n            res[j] = (actual[j] - predicted[j]) \/ actual[j]\n        else:\n            res[j] = predicted[j] \/ np.mean(actual)\n    return res\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100","07624b86":"MAPE_RF=mean_absolute_percentage_error(ytest,sk_pred)\nMAPE_RF","da58b4ee":"cls.score(d2_test_dataset,ytest)","cb784fd4":"# Main function for calculating Mean Absolute Percentage Error\nimport sklearn.metrics\ndef percentage_error(actual, predicted):\n    res = np.empty(actual.shape)\n    for j in range(actual.shape[0]):\n        if actual[j] != 0:\n            res[j] = (actual[j] - predicted[j]) \/ actual[j]\n        else:\n            res[j] = predicted[j] \/ np.mean(actual)\n    return res\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100","304fc026":"MAPE_RF=mean_absolute_percentage_error(ytest,sk_pred)\nMAPE_RF","868f23fe":"cls.score(d2_test_dataset,ytest)","1b3c6d16":"train.shape","3247ac85":"gData=df.demand.values.reshape(-1,1)","d27838cf":"gData[:10]","34b78840":"gX, gY = create_dataset(gData, time_step)","ebfbaa0c":"gX.shape","c3c83857":"gY.shape","c0ef7d44":"gX =gX.reshape(gX.shape[0],gX.shape[1] , 1)\ngX.shape\npred_gX=model.predict(gX)","cd85ca52":"#Function for calculating LSTM model MAPE value\ndef LSTM_MAEP_RMSE(month,year):\n  year_dict = {2018: 1, 2019: 2, 2020: 3}\n\n  month_seq = {\n      \"jan\": 1,\n      \"feb\": 2,\n      \"mar\": 3,\n      \"apr\": 4,\n      \"may\": 5,\n      \"jun\": 6,\n      \"jul\": 7,\n      \"aug\": 8,\n      \"sep\": 9,\n      \"oct\": 10,\n      \"nov\": 11,\n      \"dec\": 12,\n  }\n\n  month_dict = {\n      \"jan\": (0, 31),\n      \"feb\": (31, 59),\n      \"mar\": (59, 90),\n      \"apr\": (90, 120),\n      \"may\": (120, 151),\n      \"jun\": (151, 181),\n      \"jul\": (181, 212),\n      \"aug\": (212, 243),\n      \"sep\": (243, 273),\n      \"oct\": (273, 304),\n      \"nov\": (304, 334),\n      \"dec\": (334, 365)\n  } \n\n  st = year_dict[year]*365+(month_dict[month][0] + (1 if year == 2020 and month_seq[month] > 2 else 0))*24\n  en = year_dict[year]*365+(month_dict[month][1] + (1 if year == 2020 and month_seq[month] >= 2 else 0))*24\n  test_y_jan = []\n  true_y_jan = []\n  for i in range(st, en):\n    test_y_jan.append(pred_gX[i])\n    true_y_jan.append(gY[i])\n      \n  return mean_absolute_percentage_error(true_y_jan,test_y_jan)","afd467aa":"pred_gX.shape","bb12c449":"gY.shape","7e31d73c":"JANUARY_LSTM_MAPE=LSTM_MAEP_RMSE(\"jan\",2020)\nMARCH_LSTM_MAPE=LSTM_MAEP_RMSE(\"mar\",2020)\nJUNE_LSTM_MAPE=LSTM_MAEP_RMSE(\"jun\",2020)\nSEPTEMBER_LSTM_MAPE=LSTM_MAEP_RMSE(\"sep\",2020)\nDECEMBER_LSTM_MAPE=LSTM_MAEP_RMSE(\"dec\",2020)","c7642781":"print(JANUARY_LSTM_MAPE)\nprint(JUNE_LSTM_MAPE)\nprint(DECEMBER_LSTM_MAPE)\nprint(SEPTEMBER_LSTM_MAPE)\nprint(DECEMBER_LSTM_MAPE)","82180992":"\ndef LSTM_MONTH_PLOT(month,year):\n\n  year_dict = {2018: 1, 2019: 2, 2020: 3}\n\n  month_seq = {\n      \"jan\": 1,\n      \"feb\": 2,\n      \"mar\": 3,\n      \"apr\": 4,\n      \"may\": 5,\n      \"jun\": 6,\n      \"jul\": 7,\n      \"aug\": 8,\n      \"sep\": 9,\n      \"oct\": 10,\n      \"nov\": 11,\n      \"dec\": 12,\n  }\n\n  month_dict = {\n      \"jan\": (0, 31),\n      \"feb\": (31, 59),\n      \"mar\": (59, 90),\n      \"apr\": (90, 120),\n      \"may\": (120, 151),\n      \"jun\": (151, 181),\n      \"jul\": (181, 212),\n      \"aug\": (212, 243),\n      \"sep\": (243, 273),\n      \"oct\": (273, 304),\n      \"nov\": (304, 334),\n      \"dec\": (334, 365)\n  } \n\n  st = year_dict[year]*365+(month_dict[month][0] + (1 if year == 2020 and month_seq[month] > 2 else 0))*24\n  en = year_dict[year]*365+(month_dict[month][1] + (1 if year == 2020 and month_seq[month] >= 2 else 0))*24\n  test_y = []\n  true_y = []\n  for i in range(st, en,24):\n    test_y.append(pred_gX[i]*D_max)\n    true_y.append(gY[i]*D_max)\n  \n  plt.plot(test_y,linewidth = 4)\n  plt.plot(true_y,linewidth = 4) \n  #plt.suptitle(f\"{month.upper()} Month prediction comparison\")\n  plt.legend([\"PREDICTED\", \"ACTUAL\"])","a64fa7a4":"LSTM_MONTH_PLOT('jan',2020)\n\n","ac96394f":"LSTM_MONTH_PLOT('mar',2020)","57f6c39a":"LSTM_MONTH_PLOT('jun',2020)\n","183d974c":"LSTM_MONTH_PLOT('sep',2020)\n","7f3585d2":"LSTM_MONTH_PLOT('dec',2020)\n","29f82d87":"# Check Model Score","c5b4a11d":"# Create LSTM & Autoencoder Model","9adc6695":"# Training Model with Randomfroste","b8d2b5e9":"# Creating Timestep","a3fcc0dc":"# Visulize result forecasting","37cf5d19":"# Load Dataset","e1158616":"# Ploting Losses","cc44cc13":"# EDA"}}