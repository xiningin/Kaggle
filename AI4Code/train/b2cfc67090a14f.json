{"cell_type":{"dee69817":"code","bdc2c909":"code","a7166950":"code","410a1f80":"code","3dad248f":"code","9d5475b9":"code","3dc767af":"code","5a6a430c":"code","d52fa500":"code","398900b9":"code","dea71e9d":"code","a58dc253":"code","9bd39107":"code","18a2aad9":"code","e559d296":"code","a16e9d81":"code","146e6dab":"code","08498f88":"code","ae292223":"code","cefb5c37":"code","2d0c8944":"code","c560222b":"code","6adfc433":"code","ed55227c":"code","1b306082":"code","b8b67ee8":"code","634ca1d2":"code","d50db2eb":"code","394fcee7":"code","aca3dcd2":"code","0dd13e78":"code","aa3f3149":"code","bfe08f13":"code","d981b0df":"code","53d0da99":"code","b4eb7811":"code","fcc77a21":"markdown"},"source":{"dee69817":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.graph_objs as go\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bdc2c909":"data = pd.read_csv(\"..\/input\/wholesale-customers-data\/Wholesale customers data.csv\")","a7166950":"data.columns","410a1f80":"data.drop(['Channel', 'Region'], axis = 1, inplace = True)","3dad248f":"display(data.describe())","9d5475b9":"data.head(10)","3dc767af":"data.shape","5a6a430c":"## Feature relevance\n\nnew_data = data.drop('Grocery', axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(new_data, data.Grocery, test_size = 0.25, random_state = 20)\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\nregressor = model.fit(X_train, y_train)\nprediction = regressor.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nscore = r2_score(y_test, prediction)\nprint(\"the score is\", score)","d52fa500":"data.isnull().any()","398900b9":"sns.pairplot(data)","dea71e9d":"import seaborn as sns\n\nsns.heatmap(data.corr(), annot = True)","a58dc253":"np","9bd39107":"sns.scatterplot(x = data['Fresh'], y = data['Frozen'])","18a2aad9":"sns.scatterplot(x = data['Milk'], y = data['Detergents_Paper'])","e559d296":"sns.countplot(data['Fresh'])","a16e9d81":"data_sub = data.iloc[:,2:8]\ndata_sub.head(5)","146e6dab":"data_sub.describe()","08498f88":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(data_sub)\ndata_sub = scaler.transform(data_sub)","ae292223":"data_sub = pd.DataFrame(data_sub, columns=data_sub.columns)","cefb5c37":"from sklearn.decomposition import PCA\npca_data = PCA(n_components = 6)\nprincipalComponenets_data = pca_data.fit_transform(data)\nprincipalComponenets_data","2d0c8944":"pca_data.components_","c560222b":"pca_data.explained_variance_ratio_","6adfc433":"np.cumsum(pca_data.explained_variance_ratio_)","ed55227c":"sns.lineplot(x = ['1', '2', '3', '4', '5', '6'], y = np.cumsum(pca_data.explained_variance_ratio_))\n\nplt.xlabel('Principal components')\nplt.ylabel('Explained Variance ratio')","1b306082":"x = data.iloc[:,2:8]\nx","b8b67ee8":"from sklearn.cluster import KMeans\n\nwcss = []\n\nfor i in range(1,11):\n    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    \n    km.fit(x)\n    \n    wcss.append(km.inertia_)\n    \nplt.plot(range(1,11), wcss)\n\nplt.show()","634ca1d2":"km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n\ny_means = km.fit_predict(x)","d50db2eb":"plt.scatter(x.iloc[:,3], x.iloc[:,4])\n\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s = 300, c = 'red')","394fcee7":"principal_Df = pd.DataFrame(data = principalComponenets_data, \n                            columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4', 'principal component 5', 'principal component 6'])","aca3dcd2":"wcss = []\n\nfor i in range(1,11):\n    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    \n    km.fit(principal_Df)\n    \n    wcss.append(km.inertia_)\n    \nplt.plot(range(1,11), wcss)\n\nplt.show()","0dd13e78":"km = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n\ny_means = km.fit_predict(principal_Df)","aa3f3149":"plt.scatter(principal_Df.iloc[:,0], principal_Df.iloc[:,1])\n\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s = 300, c = 'red')","bfe08f13":"from sklearn.preprocessing import normalize\ndata_scaled = normalize(data)\ndata_scaled = pd.DataFrame(data_scaled, columns=data.columns)\ndata_scaled.head()","d981b0df":"import scipy.cluster.hierarchy as shc\nplt.figure(figsize=(10, 7))  \nplt.title(\"Dendrograms\")  \ndend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))\nplt.axhline(y=6, color='r', linestyle='--')","53d0da99":"from sklearn.cluster import AgglomerativeClustering\ncluster = AgglomerativeClustering(n_clusters = 2, affinity = \"euclidean\", linkage = \"ward\")\ncluster.fit_predict(data_scaled)","b4eb7811":"plt.figure(figsize = (10, 7))\nplt.scatter(data_scaled['Milk'], data_scaled['Grocery'], c = cluster.labels_)","fcc77a21":"Hierarchial Clustering\nStandardScaler() standardizes features (such as the features of the person data i.e height, weight)by removing the mean and scaling to unit variance.\n\n(unit variance: Unit variance means that the standard deviation of a sample as well as the variance will tend towards 1 as the sample size tends towards infinity.)\n\nNormalizer() rescales each sample. For example rescaling each company's stock price independently of the other.\n\nSome stocks are more expensive than others. To account for this, we normalize it. The Normalizer will separately transform each company's stock price to a relative scale.\n\nrom the Normalizer docs:\n\nEach sample (i.e. each row of the data matrix) with at least one non zero component is rescaled independently of other samples so that its norm (l1 or l2) equals one.\n\nAnd StandardScaler\n\nStandardize features by removing the mean and scaling to unit variance\n\nIn other words Normalizer acts row-wise and StandardScaler column-wise. Normalizer does not remove the mean and scale by deviation but scales the whole row to unit norm."}}