{"cell_type":{"b224fa0a":"code","1d2c9f55":"code","87f22757":"code","efe35030":"code","5e41fd85":"code","0e00e661":"code","8983557c":"code","db3bf762":"code","6cbcd1de":"code","4fb2afa6":"code","fe19fdda":"code","2195f59f":"code","ea732784":"code","21697d27":"code","d28d6174":"code","8fc5e8d8":"code","eb92dec3":"code","c631529c":"code","f5375fb3":"code","5654863b":"markdown","e92d1c86":"markdown","98e00a1e":"markdown","65d04f9d":"markdown","fb98e306":"markdown","acb1e5d3":"markdown","2eac74b1":"markdown","cc2523e9":"markdown","49319a4f":"markdown"},"source":{"b224fa0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))","1d2c9f55":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Number of rows and columns in train set : \",train.shape)\nprint(\"Number of rows and columns in test set : \",test.shape)","87f22757":"pd.set_option('max_columns',258)\ntrain.head()","efe35030":"test.head()","5e41fd85":"sns.countplot(train['target'], palette='Set3')","0e00e661":"train.target.value_counts()","8983557c":"pd.set_option('max_rows',258)\ntrain.describe()","db3bf762":"test.describe()","6cbcd1de":"train.isnull().sum()","4fb2afa6":"test.isnull().sum()","fe19fdda":"feats = [f for f in train.columns if f not in ['id','target']]\nfor i in feats:\n    print ('==' + str(i) + '==')\n    print ('train:' + str(train[i].nunique()\/train.shape[0]))\n    print ('test:' + str(test[i].nunique()\/test.shape[0]))","2195f59f":"def plot_feature_distribution(df1, df2, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(26,10,figsize=(18,22))\n\n    for feature in features:\n        i += 1\n        plt.subplot(26,10,i)\n        sns.distplot(df1[feature], hist=False,label=label1)\n        sns.distplot(df2[feature], hist=False,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    plt.show();\n    \nt0 = train[feats].loc[train['target'] == 0]\nt1 = train[feats].loc[train['target'] == 1]\nfeatures = train[feats].columns.values\nplot_feature_distribution(t0, t1, '0', '1', features)    ","ea732784":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","21697d27":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train[features].mean(axis=0),color=\"yellow\",kde=True,bins=50, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"red\", kde=True,bins=50, label='test')\nplt.legend()\nplt.show()","d28d6174":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","8fc5e8d8":"plt.figure(figsize=(16,6))\nfeatures = train[feats].columns.values\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=0),color=\"red\", kde=True,bins=50, label='train')\nsns.distplot(test[features].std(axis=0),color=\"yellow\", kde=True,bins=50, label='test')\nplt.legend()\nplt.show()","eb92dec3":"correlations = train[features].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorrelations.head(10)","c631529c":"correlations.tail(10)","f5375fb3":"feats_target = [f for f in train.columns if f not in ['id']]\ncorrelations = train[feats_target].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorr = correlations[correlations['level_0']=='target']\ncorr.head(300)","5654863b":"# Instant Gratification Exploration Data Analysis\nThis is an anonymized, binary classification dataset.","e92d1c86":"# Target and Feature Correlation","98e00a1e":"# Basic describtion","65d04f9d":"# Target Exploration","fb98e306":"# Uniqule Count Check","acb1e5d3":"# Feature Correlation","2eac74b1":"# Distribution of mean and std","cc2523e9":"# Missing Value Check","49319a4f":"# Density plots of features"}}