{"cell_type":{"15184ef8":"code","b33fc1ac":"code","163b79bd":"code","7d66aacd":"code","92b3fdd9":"code","74d5e836":"code","427e89be":"code","f06dfb10":"code","ec952bee":"code","42301fb4":"code","65721265":"code","f6d53065":"code","e0f3af9f":"code","d869b084":"code","7bce7e9c":"code","b5f5a4e3":"code","454f9e1b":"code","9b3ce893":"code","e5a866a4":"code","5e381e88":"code","ee86ff54":"code","92d534d0":"code","84c0e754":"code","5b1e0640":"markdown","6aad5184":"markdown","2b8e434b":"markdown","8046ed41":"markdown","b1d0107e":"markdown","5f31f06b":"markdown","4f24f0b0":"markdown","fed228ad":"markdown","2e2f69b8":"markdown","d476e956":"markdown","e57cf6c9":"markdown","5832aeef":"markdown","28a9058a":"markdown"},"source":{"15184ef8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b33fc1ac":"df= pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndf.head()","163b79bd":"df.describe()","7d66aacd":"f,ax = plt.subplots()\ndf.training_hours.hist(ax=ax)\nf,ax = plt.subplots()\ndf[['training_hours', 'target']].boxplot(by='target', ax=ax)","92b3fdd9":"df.groupby(['target']).training_hours.describe()[['mean', '50%']].T.plot(kind='barh')","74d5e836":"f,ax = plt.subplots()\ndf.city_development_index.hist(ax=ax)\nf,ax = plt.subplots()\ndf[['city_development_index', 'target']].boxplot(by='target', ax=ax)","427e89be":"df.groupby(['target']).city_development_index.describe()[['mean', '50%']].T.plot(kind='barh')","f06dfb10":"for name, group in df.groupby(['target']):\n    f,ax = plt.subplots()\n    group.city_development_index.hist(ax=ax)","ec952bee":"categorical_columns = [\n    'gender', 'relevent_experience', 'enrolled_university',\n    'education_level', 'major_discipline', 'experience',\n    'company_size', 'company_type', 'last_new_job',\n]","42301fb4":"# First lets see how many categories are in each categorical feature.\ndf[categorical_columns].nunique()","65721265":"# Casting to an int.\ndf['experience_int'] = np.where(\n    df.experience.str.contains('>20'),\n    21,\n    np.where(\n        df.experience.str.contains('<1'),\n        0,\n        df.experience\n    )\n).astype('int')","f6d53065":"def plot_cat_comp(category):\n    f, ax = plt.subplots()\n    ax = (\n        df\n        .fillna('nan')\n        .groupby(['target',category])\n        .agg({'enrollee_id':'nunique'})\n        .join(df.groupby('target').agg(total=('enrollee_id', 'nunique')))\n        .assign(\n            percentage = lambda x: x['enrollee_id']\/x['total']\n        )\n        .reset_index()\n        .pivot(\n            index=category,\n            columns='target',\n            values='percentage'\n        )\n        .plot(\n            kind='barh',\n            ax=ax\n        )\n    )\n\n    return ax","e0f3af9f":"plot_cat_comp('experience_int')","d869b084":"for cat in categorical_columns:\n    ax = plot_cat_comp(cat)\n    ax.set_title(cat,x=0, ha='left')","7bce7e9c":"df_process = df.copy()\ndf_process[categorical_columns] = df_process[categorical_columns].fillna('nan')\ndf_process = pd.get_dummies(df, columns = ['company_size', 'relevent_experience', 'company_type' , 'education_level'])","b5f5a4e3":"features = [\n       'city_development_index',\n       'training_hours', 'experience_int', 'company_size_10\/49',\n       'company_size_100-500', 'company_size_1000-4999', 'company_size_10000+',\n       'company_size_50-99', 'company_size_500-999', 'company_size_5000-9999',\n       'company_size_<10', 'relevent_experience_Has relevent experience',\n       'relevent_experience_No relevent experience',\n       'company_type_Early Stage Startup', 'company_type_Funded Startup',\n       'company_type_NGO', 'company_type_Other', 'company_type_Public Sector',\n       'company_type_Pvt Ltd', 'education_level_Graduate',\n       'education_level_High School', 'education_level_Masters',\n       'education_level_Phd', 'education_level_Primary School'\n]\n","454f9e1b":"from sklearn.model_selection import train_test_split","9b3ce893":"X = df_process[features]\ny = df_process['target']","e5a866a4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","5e381e88":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.metrics import roc_auc_score","ee86ff54":"rf_pipe = Pipeline(steps =[ (\"RF\",RandomForestClassifier(random_state=42)) ])\nada_pipe = Pipeline(steps =[ (\"RF\",AdaBoostClassifier(random_state=42,learning_rate=0.7)) ])\nsvm_pipe = Pipeline(steps =[ (\"RF\",SVC(random_state=42,kernel='rbf')) ])\ndt_pipe = Pipeline(steps = [('RF', DecisionTreeClassifier(max_depth=10))])","92d534d0":"rf_cross_val_scores = cross_val_score(rf_pipe,X_train,y_train,cv=5,scoring='f1')\nada_f1_cross_val_scores=cross_val_score(ada_pipe,X_train,y_train,cv=5,scoring='f1')\ndt_f1_cross_val_scores=cross_val_score(dt_pipe,X_train,y_train,cv=5,scoring='f1')\n","84c0e754":"rf_pipe.fit(X_train,y_train)\nrf_prediction = rf_pipe.predict(X_test)\n\nada_pipe.fit(X_train,y_train)\nada_prediction = ada_pipe.predict(X_test)\n\ndt_pipe.fit(X_train,y_train)\ndt_prediction = dt_pipe.predict(X_test)\n\nprint('Area under ROC Score of Random Forest Model On Test Set - {:,.2%}'.format(roc_auc_score(rf_prediction,y_test)))\nprint('Area under ROC Score of AdaBoost Model On Test Set - {:,.2%}'.format(roc_auc_score(ada_prediction,y_test)))\nprint('Area under ROC Score of Decision Tree Model On Test Set - {:,.2%}'.format(roc_auc_score(dt_prediction,y_test)))\n","5b1e0640":"# Understanding the categorical data","6aad5184":"## Investigating numeric feautres\n\n- It appears that the training hours are slightly longer for target == 0\n- We also see that the mean and median city development index is slightly higher for target == 0.\n\nIn the city development index there appears to be two distributions layered on top of one another. Possibly clustering the two distributions could create a useful feature.\n","2b8e434b":"# Prepare the data for ML","8046ed41":"## Exploring Experience\n\nIt appears there is some correlation between the experience level and the target, higher experience are more likely to have target == 0. Lower experience are more likely to have target ==1.","b1d0107e":"### training hours","5f31f06b":"# HR analytics job change of data sciencetists\n\nExploring what features are good predictors of people changing jobs and building some models to predict.","4f24f0b0":"## Exploring other categoricals","fed228ad":"Just describing the data so we can see what we have on our hands. Observations\n\n- 25% of users are looking to change jobs, this is low and we will need to consider this when training models - a model could predict everyting 0 and still have 75% accuracy.\n- 19,158 samples\n- Training hours and city development index appear to be the only numeric features.","2e2f69b8":"Thats an ok baseline. Will start a new notebook to try and improve upon these scores.","d476e956":"# Model Selection","e57cf6c9":"# import and data loading","5832aeef":"# Exploring the data","28a9058a":"### City Development Index"}}