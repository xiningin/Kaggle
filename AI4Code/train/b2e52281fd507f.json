{"cell_type":{"7e5e19a7":"code","b825d77d":"code","ac51c286":"code","718ff886":"code","4de3a81c":"code","a2e89c14":"code","aa056aeb":"code","84ae5973":"code","f8fe0579":"code","fdf5832f":"code","a56d30f5":"code","a4e146b4":"code","ea73f398":"code","af76da51":"code","27b5bebe":"code","92bf1ccb":"code","8d9a7d2e":"code","404902f3":"code","1cd1a6fb":"code","2ae4adee":"code","146bef18":"code","6eab91af":"code","f177a0a2":"code","5c47ce70":"code","65b257e3":"code","32ff3f1b":"code","3cf5ed7a":"code","fd932471":"markdown","0364d3bc":"markdown","b01e02da":"markdown","87cbc3fc":"markdown","6c3a344d":"markdown","076c657a":"markdown","c02c1c9e":"markdown","88167964":"markdown","5f748702":"markdown","14f974f7":"markdown","6da915a4":"markdown","ae5806d8":"markdown","9de70160":"markdown","10685b9f":"markdown","f86d7186":"markdown","e2943204":"markdown","2a1fff5b":"markdown"},"source":{"7e5e19a7":"import json\nimport math\nimport os\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\nIMG_SIZE = 224\n\n%matplotlib inline","b825d77d":"\n\nnp.random.seed(2019)\ntf.random.set_random_seed(2019)\n","ac51c286":"train_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntest_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.head()","718ff886":"train_df['diagnosis'].hist()\ntrain_df['diagnosis'].value_counts()","4de3a81c":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(4*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_df)","a2e89c14":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n    \n    \ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","aa056aeb":"def preprocess_image(image_path, desired_size=IMG_SIZE):\n    im = load_ben_color(image_path,sigmaX = 30)\n    return im","84ae5973":"N = train_df.shape[0]\nx_train = np.empty((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(train_df['id_code'])):\n    x_train[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_id}.png'\n    )","f8fe0579":"N = test_df.shape[0]\nx_test = np.empty((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(test_df['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/test_images\/{image_id}.png'\n    )","fdf5832f":"y_train = pd.get_dummies(train_df['diagnosis']).values\n\nprint(\"NO of train images in x\",x_train.shape)\nprint(\"NO of train images in y\",y_train.shape)\nprint(\"NO of test images\",x_test.shape)","a56d30f5":"x_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train, \n    test_size=0.15, \n    random_state=2019\n)","a4e146b4":"BATCH_SIZE = 32\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)\n# Using Mixup\n#mixup_generator = MixupGenerator(x_train, y_train, batch_size=BATCH_SIZE, alpha=0.2, datagen=create_datagen())()","ea73f398":"plt.imshow(x_train[5], interpolation='nearest')\n\n","af76da51":"densenet = DenseNet121(\n    weights='..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(IMG_SIZE,IMG_SIZE,3)\n)","27b5bebe":"def build_model():\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(lr=0.00005),\n    metrics=['accuracy']\n        )\n    \n    return model","92bf1ccb":"model = build_model()\nmodel.summary()","8d9a7d2e":"#appa_metrics = Metrics()\n\nhistory = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n    epochs=15,\n    validation_data=(x_val, y_val),\n    \n)","404902f3":"model.save_weights(\"model.h5\")\nmodel.save('CNNmodel.h5')\nprint(\"model saved to disk\")\n","1cd1a6fb":"import joblib\njoblib.dump(model,'JOBmodel.sav')\n","2ae4adee":"Jmodel = joblib.load('JOBmodel.sav')","146bef18":"import pickle\nfilename = 'pickel_model.pkl'\nloadedModel = pickle.dump(model,open(filename,'wb'))\nprint(\"model saved\")\n","6eab91af":"from IPython.display import FileLink\nFileLink(r'JOBmodel.sav')\n","f177a0a2":"print(history.history.keys())\nplt.figure(1)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')","5c47ce70":"image_path=f'..\/input\/aptos2019-blindness-detection\/train_images\/02358b47ea89.png'\nimg = image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\nplt.imshow(img)\nimg = preprocess_image(image_path)\nimg = np.expand_dims(img, axis=0)\nresult=Jmodel.predict_classes(img)\nplt.title(label = result[0])\nplt.show()\nprint(\"the diabetic retinopathy level of this eye is {}\".format(result))","65b257e3":"sample_test_images = []\nim_names = []\nfor i in range(0,20):\n    img_path = train_df.loc[i,'id_code']\n    im_names.append(img_path)\n    img = preprocess_image(f'..\/input\/aptos2019-blindness-detection\/train_images\/{img_path}.png')\n    sample_test_images.append(img)\n\nprint(len(sample_test_images),\"images are stored in a list\")\n    \n    ","32ff3f1b":"print(im_names)","3cf5ed7a":"def predict_multiple(li, columns=5, rows=4):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n    for i in range(columns*rows):\n        im = li[i]\n        img = np.expand_dims(im, axis=0)\n        result=Jmodel.predict_classes(img)\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(result[0])\n        plt.imshow(im, interpolation='nearest')\n        \n    plt.tight_layout()\n    \npredict_multiple(sample_test_images)    ","fd932471":"# Shapes of data","0364d3bc":"# Splitting into train and validations","b01e02da":"# Saving the model as joblib file","87cbc3fc":"# Saving the model as CNN.model","6c3a344d":"# Building the model","076c657a":"# Predicting a single image","c02c1c9e":"# Converting Preprocessed images to Numpy arrays ","88167964":"# Displaying some Sample Images","5f748702":"# Model: DenseNet-121","14f974f7":"# Saving the model as Pickle file","6da915a4":"# Loading & Exploration","ae5806d8":"# Plotting accuracy curves of both train & validation","9de70160":"# Predicting multiple images:","10685b9f":"# Image Preprocessing using ben's idea\n\n\nWe will resize the images to 224x224, then create a single numpy array to hold the data.","f86d7186":"# Data Augmentation ","e2943204":"# Training & Evaluation","2a1fff5b":"# Set random seed for reproducibility."}}