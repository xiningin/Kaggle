{"cell_type":{"8741df9e":"code","447112d4":"code","75ebc3cc":"code","e7c3b21c":"code","0b87d303":"code","c6f61b47":"code","9a94c4cc":"code","7c0ed45e":"code","4d455492":"code","d445aed9":"code","03770d78":"code","d5a2a0d0":"code","de67470d":"code","ce7addcf":"code","0d179b5b":"code","437cc3d0":"code","0ca53daf":"code","bfe9fd08":"code","2be93dab":"code","18b7ad31":"code","b2bf1bbf":"code","ba252195":"code","213666ab":"code","b9060c4e":"code","da212217":"code","20f631c1":"markdown","98c98f38":"markdown","e4856fe1":"markdown","47b2aa92":"markdown","cca95e8c":"markdown","05bc94e2":"markdown","96eda951":"markdown","d2f09fbc":"markdown","5d3de77e":"markdown","57ea405e":"markdown","041b0214":"markdown"},"source":{"8741df9e":"import cv2\nimport numpy as np\nimport os\nimport glob\nimport pandas as pd\nfrom skimage import io\nfrom PIL import Image \nimport matplotlib.pylab as plt\n\n# biblioteca para extra\u00e7\u00e3o de descritores de haralick\n!pip install mahotas==1.4.11\nimport mahotas as mt","447112d4":"!pip install gdown\n!gdown --id 1ZIcOVraxDcCN7jV-LLmidbaSnOSA0BJV","75ebc3cc":"!unzip -q dataset_covid_atividade.zip","e7c3b21c":"from os import listdir\nfrom os.path import isfile, join\nmypath = 'dataset_covid_atividade\/covid'\ncovid_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ncovid_files[:20]","0b87d303":"from os import listdir\nfrom os.path import isfile, join\nmypath = 'dataset_covid_atividade\/non-covid'\nnon_covid_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\nnon_covid_files[:20]","c6f61b47":"dataset = []\nfor img_url in non_covid_files:\n  try:\n    image = io.imread('dataset_covid_atividade\/non-covid\/'+img_url) \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    dataset.append(image)\n  except:\n    print('Warning: ',img_url)","9a94c4cc":"for img_url in covid_files:\n  try:\n    image = io.imread('dataset_covid_atividade\/covid\/'+img_url) \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    dataset.append(image)\n  except:\n    print('Warning: ',img_url)","7c0ed45e":"img = cv2.imread('dataset_covid_atividade\/covid\/COVID-10.png')\nplt.imshow(img)","4d455492":"img = cv2.imread('dataset_covid_atividade\/non-covid\/Normal-10.png')\nplt.imshow(img)","d445aed9":"def extract_features(image):\n        # calculate haralick texture features for 4 types of adjacency\n        textures = mt.features.haralick(image)\n        ht_mean = textures.mean(axis=0)\n        return ht_mean","03770d78":"from tqdm.notebook import tqdm\nX = []\nfor image in tqdm(dataset):\n  textures = extract_features(image)\n  X.append(textures)","d5a2a0d0":"Y = ['non_covid']*500 + ['covid']*500","de67470d":"df_data = pd.DataFrame(X)\ndf_data['labels'] = Y\n\ndf_data","ce7addcf":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","0d179b5b":"df_data_scaled = pd.DataFrame(X_scaled)\ndf_data_scaled['labels'] = Y\n\ndf_data_scaled","437cc3d0":"import seaborn as sns\n\n\nsns.pairplot(df_data, hue=\"labels\");","0ca53daf":"sns.pairplot(df_data_scaled, hue=\"labels\");","bfe9fd08":"from sklearn.model_selection import train_test_split\n\ndf_selected = df_data_scaled.iloc[:, [5, 10]]","2be93dab":"y = np.where(df_data.iloc[:, -1] == 'non_covid', 0, 1)\nX_train, X_test, y_train, y_test = train_test_split(df_selected, y, train_size=.8, random_state=42)","18b7ad31":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nmodels = [LogisticRegression(),\n          SVC(),\n          ExtraTreeClassifier(),\n          DecisionTreeClassifier(),\n          ExtraTreesClassifier(),\n          GradientBoostingClassifier(),\n          RandomForestClassifier(),\n          KNeighborsClassifier(),\n          MLPClassifier()]","b2bf1bbf":"from sklearn.metrics import accuracy_score\n\ntrain_accuracies = []\ntest_accuracies = []\n\nfor model in models:\n    model.fit(X_train, y_train)\n    train_accuracies.append(accuracy_score(y_train, model.predict(X_train)))\n    test_accuracies.append(accuracy_score(y_test, model.predict(X_test)))\n\nprint(f'Train accuracies {train_accuracies}')\nprint(f'Test accuracies {test_accuracies}')","ba252195":"# Defining some parameters that will be the same for every model\nrandom_state = 42\nn_jobs = -1\n\n# Defining the lists we'll use on the tuning function\nmodels = []\nlist_search_params = []\nrandomized = []\n\n# *** Logistic Regression Classifier ***\nlr = LogisticRegression()\n\nlr_param = {'random_state' : [random_state], \n            'penalty' : ['l2'], \n            'C' : np.geomspace(1e-4, 1e4, 9)\n}\n\nmodels.append(lr)\nlist_search_params.append(lr_param)\nrandomized.append(False)\n\n# *** Decision Tree Classifier ***\ndt = DecisionTreeClassifier()\n\ndt_param = {'random_state' : [random_state],\n             'criterion' : ['gini', 'entropy'],\n             'splitter' : ['best', 'random'],\n             'max_depth' : [None, 3, 5, 7, 10],\n             'min_samples_leaf' : np.linspace(1, 10, 5).astype(int), \n             'min_samples_split' : np.linspace(2, 10, 5).astype(int), \n             'max_features': [0.25, 0.50, 0.75, 1.00]\n} \n\nmodels.append(dt)\nlist_search_params.append(dt_param)\nrandomized.append(True)\n\n\n# *** ExtraTree Classifier ***\net = ExtraTreeClassifier()\n\net_param = {'random_state' : [random_state],\n            'criterion' : ['gini', 'entropy'],\n            'splitter' : ['best', 'random'],\n            'max_depth' : [None, 3, 5, 7, 10],\n            'min_samples_leaf' : np.linspace(1, 10, 5).astype(int), \n            'min_samples_split' : np.linspace(2, 10, 5).astype(int), \n            'max_features': [0.25, 0.50, 0.75, 1.00]\n}\n\nmodels.append(et)\nlist_search_params.append(et_param)\nrandomized.append(True)\n\n# *** Random Forest Classifier ***\nrf = RandomForestClassifier()\n\nrf_param = {'random_state' : [random_state],\n            'n_jobs' : [n_jobs],\n            'criterion' : ['gini', 'entropy'],\n            'max_depth' : [None, 3, 5, 7, 10],\n            'min_samples_leaf' : np.linspace(1, 10, 5).astype(int), \n            'min_samples_split' : np.linspace(2, 10, 5).astype(int), \n            'max_features': [0.25, 0.50, 0.75, 1.00],\n            'n_estimators': np.geomspace(10, 1000, 7).astype(int)\n}\n\nmodels.append(rf)\nlist_search_params.append(rf_param)\nrandomized.append(True)\n\n# *** SVC Classifier ***\nsvc = SVC()\n\nsvc_param = {'random_state' : [random_state],\n             'C' : [0.25, 0.5, 1.0, 2.0, 4.0],\n             'gamma' : ['auto'],\n             'kernel' : ['rbf', 'linear', 'poly', 'sigmoid'],\n             'shrinking' : [True, False]\n}\n\nmodels.append(svc)\nlist_search_params.append(svc_param)\nrandomized.append(False)\n\n# *** K-Nearest Neighbors Classifier ***\nknn = KNeighborsClassifier()\n\nknn_param = {'n_jobs' : [n_jobs],\n             'n_neighbors' : np.linspace(3, 7, 5).astype(int),\n             'weights' : ['uniform', 'distance'],\n             'metric' : ['euclidean', 'manhattan', 'chebyshev']\n}\n\nmodels.append(knn)\nlist_search_params.append(knn_param)\nrandomized.append(False)\n\n# *** Gradient Boosting Classifier ***\ngb = GradientBoostingClassifier()\n\ngb_param = {'random_state' : [random_state], \n             'loss' : ['deviance', 'exponential'],\n             'learning_rate': [0.01, 0.05, 0.1, 0.25],\n             'n_estimators' : [100, 250, 500],\n             'max_depth': [None, 3, 6, 9],\n             'min_samples_leaf': [1, 5],\n             'max_features': [0.25, 0.50, 0.75, 1.0]  \n}\nmodels.append(gb)\nlist_search_params.append(gb_param)\nrandomized.append(False)\n\n# *** Extra Trees Classifier ***\nets = ExtraTreesClassifier()\n\nets_param = {'random_state' : [random_state],\n             'n_jobs' : [n_jobs],\n             'n_estimators' : [100, 500, 1000],\n             'criterion' : ['gini', 'entropy'],\n             'max_depth' : [None, 3, 5, 7, 10],\n             'min_samples_leaf' : np.linspace(1, 10, 5).astype(int), \n             'min_samples_split' : np.linspace(2, 10, 5).astype(int), \n             'max_features': [0.25, 0.50, 0.75, 1.00]\n}\nmodels.append(ets)\nlist_search_params.append(ets_param)\nrandomized.append(True)","213666ab":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n\ns_objs = []\n\nfor model, params, random in zip(models, list_search_params, randomized):\n    kfold = StratifiedKFold(n_splits=5)\n    print(f'Searching for model: {model}') \n    if random:\n        s_obj = RandomizedSearchCV(model, params, cv=5, scoring='accuracy', n_iter=100,\n                                   n_jobs=-1)\n    else:\n        s_obj = GridSearchCV(model, params, cv=5, scoring='accuracy', n_jobs=-1)\n    \n    s_obj.fit(X_train, y_train)\n    s_objs.append(s_obj)\n\n\nbest_estimators = list(map(lambda x : x.best_estimator_, s_objs))\nbest_params = list(map(lambda x : x.best_params_, s_objs))\nbest_scores = list(map(lambda x : x.best_score_, s_objs))\nbest_estimators","b9060c4e":"best_params","da212217":"best_scores","20f631c1":"### Exemplo - Raio-X Non-Covid","98c98f38":"Observamos que, apesar de visualmente parecer dif\u00edcil de separar, os modelos conseguem uma acur\u00e1cia bastante alta. Podemos tentar procurar por hiperpar\u00e2metros melhores.","e4856fe1":"Como vamos selecionar dois descritores, na pr\u00e1tica estamos selecionando em qual dos gr\u00e1ficos acima n\u00f3s vamos tentar dividir os pontos. Portanto, para selecionar os dois descritores, vamos selecionar o gr\u00e1fico em que os pontos parecem o mais separ\u00e1veis poss\u00edvel.\n\nNenhum dos gr\u00e1ficos parece particarmente f\u00e1cil de se dividir os pontos, ent\u00e3o vamos selecionar os atributos 5 e 10.","47b2aa92":"# Gerando o dataset","cca95e8c":"_Esse notebook foi originalmente minha **Atividade 2 da mat\u00e9ria de Minera\u00e7\u00e3o de Dados N\u00e3o Estruturados** - SCC0287 - no ano de 2021, segundo semestre com o Professor Ricardo Marcondes Marcacini._\n\n_O objetivo dela era explorar a classifica\u00e7\u00e3o de imagens de Raio-X de pulm\u00f5es de pessoas com e sem COVID-19. Para fazer a classifica\u00e7\u00e3o, aplicamos o conceito de Descritores de Textura de Haralick._","05bc94e2":"# Pr\u00e9-processando via Descritores de Texturas","96eda951":"### Exemplo - Raio-X Covid","d2f09fbc":"# Atividade\n\n* 1. Escolher dois descritores de textura de Haralick (cada coluna \u00e9 um descritor).\n* 2. Dividir o conjunto de dados com 80% de treinamento e 20% de teste.\n* 3. Avaliar a classifica\u00e7\u00e3o a partir dos dois descritores utilizados.","5d3de77e":"Podemos observar que todos os modelos possuem resultados pr\u00f3ximos de 90%. Aparentemente, poder\u00edamos utilizar os par\u00e2metros padr\u00f5es, pois eles parecem ser at\u00e9 melhores do que os par\u00e2metros que encontraram.","57ea405e":"# Instalando Bibliotecas","041b0214":"# Dataset"}}