{"cell_type":{"bd13d4f2":"code","e49cdfbf":"code","52fec85e":"code","a3014f36":"code","6704a162":"code","c48d11c4":"code","fc9176a1":"code","356f66b4":"code","ca9efb49":"code","ef40650c":"code","c1082100":"code","01ab3d91":"markdown","127b639d":"markdown","2f88df87":"markdown","c1761ff2":"markdown","a62fb08b":"markdown","b4de33c6":"markdown","a9d0888d":"markdown","8d8daada":"markdown","5fbbda33":"markdown","6b482e63":"markdown"},"source":{"bd13d4f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","e49cdfbf":"df = pd.read_csv('..\/input\/Mall_Customers.csv')\ndf.head()","52fec85e":"df.isnull().sum()","a3014f36":"df.dtypes","6704a162":"fig, axes = plt.subplots(1, 2, figsize=(12,8))\n\nsns.boxplot(x=\"Gender\", y=\"Annual Income (k$)\", data=df, orient='v' , ax=axes[0])\nsns.boxplot(x=\"Gender\", y=\"Spending Score (1-100)\", data=df, orient='v' , ax=axes[1])","c48d11c4":"df_group_one = df[['Gender','Annual Income (k$)','Spending Score (1-100)']]\ndf_group_one.groupby(['Gender'],as_index=False).mean()","fc9176a1":"df_female = df[df['Gender'] == \"Female\"]\nprint(df_female.shape)\ndf_female.head()","356f66b4":"Percentage = (df_female.shape[0]\/df.shape[0])*100\nprint('Female Percentage: ', round(Percentage), '%')","ca9efb49":"from sklearn.cluster import DBSCAN\nimport sklearn.utils\nfrom sklearn.preprocessing import StandardScaler\n\nClus_dataSet = df_female[['Age','Annual Income (k$)','Spending Score (1-100)']]\nClus_dataSet = np.nan_to_num(Clus_dataSet)\nClus_dataSet = np.array(Clus_dataSet, dtype=np.float64)\nClus_dataSet = StandardScaler().fit_transform(Clus_dataSet)\n\n# Compute DBSCAN\ndb = DBSCAN(eps=0.5, min_samples=4).fit(Clus_dataSet)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\ndf_female['Clus_Db']=labels\n\nrealClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\nclusterNum = len(set(labels)) \n\n# A sample of clusters\nprint(df_female[['Age','Annual Income (k$)','Spending Score (1-100)','Clus_Db']].head())\n\n# number of labels\nprint(\"number of labels: \", set(labels))","ef40650c":"# Black removed and is used for noise instead.\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each)\n          for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = Clus_dataSet[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = Clus_dataSet[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % realClusterNum)\nplt.show()\n\nn_noise_ = list(labels).count(-1)\nprint('number of noise(s): ', n_noise_)","c1082100":"#Visualization\nfor clust_number in set(labels):\n    clust_set = df_female[df_female.Clus_Db == clust_number]\n    if clust_number != -1:\n        print (\"Cluster \"+str(clust_number)+', Avg Age: '+ str(round(np.mean(clust_set.Age)))+\\\n               ', Avg Income: '+ str(round(np.mean(clust_set['Annual Income (k$)'])))+\\\n               ', Avg Spending: '+ str(round(np.mean(clust_set['Spending Score (1-100)'])))+', Count: '+ str(np.count_nonzero(clust_set.index)))","01ab3d91":"## Explore the data","127b639d":"**About \"DBSCAN\" **   \nDBSCAN is density-based clustering algorithm that robust to outliers (noises).","2f88df87":"## Find insight between Male and Female","c1761ff2":"Hi, everyone. I'm Chatchaphon (Aey) from Thailand.  \nThis is my first kaggle kernel.  \nIf you like, please upvote and share it.  \nThank you!","a62fb08b":"## Conclusion\nWith tightly setting, we found that \"Cluster 3 (average age: 32)\" which highest average income and spending is the most potential customer group. The second candidate is \"Cluster 0 (average age: 22)\" which lowest average income but spending a lot. For some countries, \"Cluster 3\" will represent people who are being settled down (have a family) which spending most for their children. And \"Cluster 0\" will represent people who are starting a new work-life after graduated that spending most for their new society life.  \n  \nThis analysis is only focus on women. Maybe men have a little difference insight.   \nPlease try to find it, and share with me!","b4de33c6":"## Data Visualization","a9d0888d":"Women look spend more than men. Let's focus on \"Female\"!","8d8daada":"## Grouping Data with \"Female\"","5fbbda33":"## Compute DBSCAN\nI am setting with a little so densy. Thus more noises will appear, but we can find a lot more insight with very sensitive result.  \n> eps=0.5, min_samples=4","6b482e63":"## Problem Statement\nCan we find more deeply and sensitive insight about potential customer, when we're clustering customer segmentation with \"DBSCAN\" algorithm?"}}