{"cell_type":{"3c62d7fd":"code","a4d1b917":"code","e8688eb2":"code","5e6a13c5":"code","a53a5281":"code","dbaf7605":"code","6e36df90":"code","8d65df62":"code","59ce8641":"code","251991e4":"code","05ca63b4":"code","254430cb":"code","5c238954":"code","7b19c4b1":"code","ed91d2e9":"code","3d44e9ad":"code","c43aa4b2":"code","f3b4ca92":"code","7be78fe7":"code","612c2cfb":"code","13d7a422":"code","2f90b81f":"code","b2cc6d4c":"code","d918c405":"code","1e4c3d5a":"markdown","ebc55803":"markdown","1c7770c6":"markdown","4af7fe77":"markdown","e79aced3":"markdown","4eeb80af":"markdown","3d766791":"markdown","0ebc35bf":"markdown","fdf4647b":"markdown","29e7ccff":"markdown","0fe1cf5c":"markdown","201d9c33":"markdown","1982fe32":"markdown"},"source":{"3c62d7fd":"import os\nimport sys\nimport time\nimport random\nimport logging\nimport typing as tp\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n\n\n%matplotlib inline\n\n#Load more packages\nfrom scipy.stats import ks_2samp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')","a4d1b917":"ROOT = Path.cwd().parent\nINPUT = ROOT \/ \"input\"\nDATA = INPUT \/ \"house-prices-advanced-regression-techniques\"\nWORK = ROOT \/ \"working\"\n\nfor path in DATA.iterdir():\n    print(path.name)","e8688eb2":"train = pd.read_csv(DATA \/ \"train.csv\")\ntest = pd.read_csv(DATA \/ \"test.csv\")\nsample_sub= pd.read_csv(DATA \/ \"sample_submission.csv\")\nprint(\"train: {}, test: {}, sample sub: {}\".format(\n    train.shape, test.shape, sample_sub.shape\n))","5e6a13c5":"train.head().T","a53a5281":"labels = {}\nfor col in train.select_dtypes(exclude = np.number).columns.tolist():\n    le = LabelEncoder().fit(pd.concat([train[col].astype(str),test[col].astype(str)]))   \n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))\n    labels [col] = le\nprint('Categorical columns:', list(labels.keys()))","dbaf7605":"print(f'Percent of Nans in Train Data : {round(train.isna().sum().sum()\/len(train), 2)}')\nprint(f'Percent of Nans in Test  Data : {round(test.isna().sum().sum()\/len(test), 2)}')","6e36df90":"train = train.replace([np.inf, -np.inf], np.nan)\ntrain= train.fillna(0)\ntrain","8d65df62":"test = test.replace([np.inf, -np.inf], np.nan)\ntest= test.fillna(0)\ntest","59ce8641":"#barplots showing the frequency of each category separated by label\nplt.figure(figsize=[15,17])\nfft=['Street',\n          'Alley',\n          'LotShape',\n          'LandContour',\n          'Utilities',\n          'LotConfig',\n          'LandSlope',\n        'Neighborhood',\n          ]\nn=1\nfor f in fft:\n    plt.subplot(4,2,n)\n    sns.countplot(x=f, hue='BldgType', edgecolor=\"black\", alpha=0.7, data=train)\n    sns.despine()\n    plt.title(\"Countplot of {}  by SalePrice\".format(f))\n    n=n+1\nplt.tight_layout()\nplt.show()","251991e4":"#barplots showing the frequency of each category separated by label\nplt.figure(figsize=[15,17])\nfft1=[    'Condition1',\n          'Condition2',\n          'BldgType',\n          'HouseStyle',\n          'OverallQual',\n          'OverallCond',\n          'YearBuilt',\n          'YearRemodAdd',\n          ]\nn=1\nfor f in fft1:\n    plt.subplot(4,2,n)\n    sns.countplot(x=f, hue='BldgType', edgecolor=\"black\", alpha=0.7, data=train)\n    sns.despine()\n    plt.title(\"Countplot of {}  by SalePrice\".format(f))\n    n=n+1\nplt.tight_layout()\nplt.show()","05ca63b4":"#barplots showing the frequency of each category separated by label\nplt.figure(figsize=[15,17])\nfft2=[ 'RoofStyle',\n          'RoofMatl',\n          'Exterior1st',\n          'Exterior2nd',\n          'MasVnrType',\n         'MasVnrArea',\n           'ExterQual',\n          'ExterCond',\n          ]\nn=1\nfor f in fft2:\n    plt.subplot(4,2,n)\n    sns.countplot(x=f, hue='BldgType', edgecolor=\"black\", alpha=0.7, data=train)\n    sns.despine()\n    plt.title(\"Countplot of {}  by SalePrice\".format(f))\n    n=n+1\nplt.tight_layout()\nplt.show()","254430cb":"#barplots showing the frequency of each category separated by label\nplt.figure(figsize=[15,17])\nfft3=[ 'Foundation',\n          'BsmtQual',\n          'BsmtCond',\n          'BsmtExposure',\n          'BsmtFinType1',\n          'BsmtFinSF1',\n          'BsmtFinType2',\n          'BsmtFinSF2',\n          ]\nn=1\nfor f in fft3:\n    plt.subplot(4,2,n)\n    sns.countplot(x=f, hue='BldgType', edgecolor=\"black\", alpha=0.7, data=train)\n    sns.despine()\n    plt.title(\"Countplot of {}  by SalePrice\".format(f))\n    n=n+1\nplt.tight_layout()\nplt.show()","5c238954":"#barplots showing the frequency of each category separated by label\nplt.figure(figsize=[15,17])\nfft4=[  'PoolQC',\n          'Fence',\n          'MiscFeature',\n          'MiscVal',\n          'MoSold',\n          'YrSold',\n          'SaleType',\n          'SaleCondition'\n          ]\nn=1\nfor f in fft4:\n    plt.subplot(4,2,n)\n    sns.countplot(x=f, hue='BldgType', edgecolor=\"black\", alpha=0.7, data=train)\n    sns.despine()\n    plt.title(\"Countplot of {}  by SalePrice\".format(f))\n    n=n+1\nplt.tight_layout()\nplt.show()","7b19c4b1":"#Select feature column names and target variable we are going to use for training\nfeatures=['Id',\n          'MSSubClass',\n          'MSZoning',\n          'LotFrontage',\n          'LotArea',\n          'Street',\n          'Alley',\n          'LotShape',\n          'LandContour',\n          'Utilities',\n          'LotConfig',\n          'LandSlope',\n          'Neighborhood',\n          'Condition1',\n          'Condition2',\n          'BldgType',\n          'HouseStyle',\n          'OverallQual',\n          'OverallCond',\n          'YearBuilt',\n          'YearRemodAdd',\n          'RoofStyle',\n          'RoofMatl',\n          'Exterior1st',\n          'Exterior2nd',\n          'MasVnrType',\n          'MasVnrArea',\n          'ExterQual',\n          'ExterCond',\n          'Foundation',\n          'BsmtQual',\n          'BsmtCond',\n          'BsmtExposure',\n          'BsmtFinType1',\n          'BsmtFinSF1',\n          'BsmtFinType2',\n          'BsmtFinSF2',\n          'BsmtUnfSF',\n          'TotalBsmtSF',\n          'Heating',\n          'HeatingQC',\n          'CentralAir',\n          'Electrical',\n          '1stFlrSF',\n          '2ndFlrSF',\n          'LowQualFinSF',\n          'GrLivArea',\n          'BsmtFullBath',\n          'BsmtHalfBath',\n          'FullBath',\n          'HalfBath',\n          'BedroomAbvGr',\n          'KitchenAbvGr',\n          'KitchenQual',\n          'TotRmsAbvGrd',\n          'Functional',\n          'Fireplaces',\n          'FireplaceQu',\n          'GarageType',\n          'GarageYrBlt',\n          'GarageFinish',\n          'GarageCars',\n          'GarageArea',\n          'GarageQual',\n          'GarageCond',\n          'PavedDrive',\n          'WoodDeckSF',\n          'OpenPorchSF',\n          'EnclosedPorch',\n          '3SsnPorch',\n          'ScreenPorch',\n          'PoolArea',\n          'PoolQC',\n          'Fence',\n          'MiscFeature',\n          'MiscVal',\n          'MoSold',\n          'YrSold',\n          'SaleType',\n          'SaleCondition']\n\ntarget = 'SalePrice'","ed91d2e9":"#This is input which our classifier will use as an input.\ntrain[features].head(10)","3d44e9ad":"params = {\n    'objective': 'reg:squarederror',\n    'n_estimators': 1000,\n    'lambda': 7.610705234008646, \n    'alpha': 0.0019377246932580476, \n    'colsample_bytree': 0.5, \n    'subsample': 0.7, \n    'learning_rate': 0.012, \n    'max_depth': 20, \n    'random_state': 24, \n    'min_child_weight': 229,\n    'random_state':42,\n\n}\n\n\nmodel = XGBRegressor(**params)\nmodel.fit(train[features],train[target])\n","c43aa4b2":"#Make predictions using the features from the test data set\npredictions = model.predict(test[features])\n\npredictions","f3b4ca92":"#Create a  DataFrame\nsubmission = pd.DataFrame({'Id':test['Id'],'SalePrice':predictions})\n                        \n\n#Visualize the first 10 rows\nsubmission.head(10)","7be78fe7":"#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'submission.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","612c2cfb":"train.drop(train[['Id', 'SalePrice']], axis=1, inplace=True)\ntest.drop(test[['Id']], axis=1, inplace=True)","13d7a422":"\nhypothesisnotrejected = []\nhypothesisrejected = []\n\nfor col in train.columns:\n    statistic, pvalue = ks_2samp(train[col], test[col])\n    if pvalue>=statistic:\n        hypothesisnotrejected.append(col)\n    if pvalue<statistic:\n        hypothesisrejected.append(col)\n        \n    plt.figure(figsize=(8,4))\n    plt.title(\"Kolmogorov-Smirnov test for train\/test\\n\"\n              \"feature: {}, statistics: {:.5f}, pvalue: {:5f}\".format(col, statistic, pvalue))\n    sns.kdeplot(train[col], color='blue', shade=True, label='Train')\n    sns.kdeplot(test[col], color='green', shade=True, label='Test')\n\n    plt.show()","2f90b81f":"len(hypothesisnotrejected), len(hypothesisrejected)\n","b2cc6d4c":"print(hypothesisrejected)\n","d918c405":"print(hypothesisnotrejected)\n","1e4c3d5a":"# Prediction","ebc55803":"# Prepocessing","1c7770c6":"# Visualisation","4af7fe77":"# Hypothesis rejected","e79aced3":"# Hypothesis not rejected","4eeb80af":"\n## References: \n* https:\/\/www.statisticshowto.com\/kolmogorov-smirnov-test\/\n* https:\/\/www.kaggle.com\/bearstrikesback\/adversarial-validation-plus-ks-test\/notebook\n* Chakravarti, Laha, and Roy, (1967). Handbook of Methods of Applied Statistics, Volume I, John Wiley and Sons, pp. 392-394.\n* Ruppert, D. (2004). Statistics and Finance: An Introduction. Springer Science and Business Media.\n* Stephens M.A. (1992) Introduction to Kolmogorov (1933) On the Empirical Determination of a Distribution. In: Kotz S., Johnson N.L. (eds) Breakthroughs in Statistics. Springer Series in Statistics (Perspectives in Statistics). Springer, New York, NY","3d766791":"Perform KS-Test for each feature from train\/test. Draw its distribution. Count features based on statistics.\n","0ebc35bf":"# Xgboost","fdf4647b":"# Check Missing Data\n\n","29e7ccff":"### The purpose of using Kolmogorov-Smirnov Test  to check whether train and test sets are significantly different.","0fe1cf5c":"#      House Prices Prediction\n![https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTdDMRs8OdF9DcJGPxxn8pNohVvLMGipNlzaQ&usqp=CAU](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTdDMRs8OdF9DcJGPxxn8pNohVvLMGipNlzaQ&usqp=CAU)\n\n\n","201d9c33":"# Model","1982fe32":"# Kolmogorov-Smirnov Test\n\n\nThe Kolmogorov-Smirnov Goodness of Fit Test (K-S test) compares your data with a known distribution and lets you know if they have the same distribution. Although the test is nonparametric \u2014 it doesn\u2019t assume any particular underlying distribution \u2014 it is commonly used as a test for normality to see if your data is normally distributed.It\u2019s also used to check the assumption of normality in Analysis of Variance.\n\n\n\n\n<img src='https:\/\/i.stack.imgur.com\/4nNN2.png' width='700'>\n\n\n\n\n\n\n\n"}}