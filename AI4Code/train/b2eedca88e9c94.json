{"cell_type":{"6a8164bc":"code","4b7b9a54":"code","908fc352":"code","bef6ecce":"code","dbae4dc9":"code","c429dce7":"code","aba0f87d":"code","ae5be4a7":"code","12d0ae9e":"code","b9a52a10":"code","da626ea7":"code","a894fa7f":"code","c2e60d85":"code","17a6b37d":"code","8150c533":"code","f0563b25":"code","b430cea6":"code","1f8d5aa6":"code","d5ae9f9a":"code","b937da06":"code","69aaa174":"code","8f4842b1":"code","b8eaacbc":"code","89995169":"code","be19b9e6":"code","58a58d90":"code","90bc2125":"code","95dae01e":"code","d153a6b8":"code","60a82a41":"code","b1f9a543":"code","d4d283ed":"code","5787607e":"code","bfd7e13c":"code","ad37e9d5":"code","e0c1ecc3":"code","432ebffb":"code","381cd218":"code","c9e91b9f":"code","2575a875":"code","57929652":"code","b6cf7697":"code","8cbf30d4":"code","f06b327a":"code","ee0b20b8":"code","8a29b176":"code","d1dae142":"code","1ae9e34e":"code","6e7fb39e":"code","3806366a":"code","392f595d":"code","1a8476be":"code","446f6d99":"code","15266550":"code","1ecfaa0b":"code","56395413":"code","9684d624":"code","594e7769":"code","d93725f9":"code","a492702e":"code","379056ea":"code","1391bb33":"code","9fd8e117":"code","5156357d":"code","c6530c91":"code","8fe3e44b":"markdown","ef575fe5":"markdown","20c31325":"markdown","cc2d6bbd":"markdown","b739e38f":"markdown","c265e6dd":"markdown","b1972289":"markdown","b3a525de":"markdown","ed239385":"markdown","f86a5194":"markdown","16796ef9":"markdown","8ce00609":"markdown","157a868a":"markdown","623413e7":"markdown","b17932b2":"markdown","c355d094":"markdown","a6be52fd":"markdown","5473a407":"markdown","08b7126d":"markdown","b0938f4f":"markdown","0af5e27c":"markdown","12882cc5":"markdown","c487405f":"markdown","fa0f9ee9":"markdown","50327c31":"markdown","61f3d62e":"markdown","d71b2b21":"markdown","0ad19eab":"markdown","c48f2b77":"markdown","86bbb880":"markdown","166bd639":"markdown","b1505c2f":"markdown","8d2934a3":"markdown","d210a1e1":"markdown"},"source":{"6a8164bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b7b9a54":"import torch\n#Torchvision has inbuilt Dataset where FashionMnist dataset is available, Lets import data\n# It has all functionality to work with Image data\nimport torchvision\nimport torchvision.transforms as transforms","908fc352":"# Checking availability of Cuda (NVIDEA GPU)\ntorch.cuda.is_available()","bef6ecce":"train_set = torchvision.datasets.FashionMNIST(\nroot = '.\/data',\ntrain = True,\ndownload = True,\ntransform = transforms.Compose([transforms.ToTensor()])\n)","dbae4dc9":"# Checking dataset length\nlen(train_set)","c429dce7":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","aba0f87d":"len(train_set)","ae5be4a7":"img, label = train_set[0]\nimg.shape, label","12d0ae9e":"# let's view some images","b9a52a10":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","da626ea7":"import matplotlib.pyplot as plt","a894fa7f":"show_img(*train_set[5999])","c2e60d85":"show_img(*train_set[9])","17a6b37d":"loader = DataLoader(train_set, batch_size = 1000, num_workers = 1)\nnum_pixels = len(train_set) * 28 * 28\n\ntotal_sum = 0\nfor batch in loader:\n    total_sum += batch[0].sum()\n    \nmean = total_sum \/ num_pixels\n\nsum_squared_error = 0\n\nfor batch in loader:\n    sum_squared_error += ((batch[0] - mean).pow(2)).sum()\n    \nstd = torch.sqrt(sum_squared_error \/ total_sum)\n\nmean.item(), std.item()","8150c533":"transform1 = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomAffine(0, shear = 10, scale = (0.8, 1.2)),\n    transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(0.286, 0.6601),\n    #transforms.Pad(2),\n    transforms.RandomHorizontalFlip(p=1)\n])","f0563b25":"train_set1 = torchvision.datasets.FashionMNIST(\nroot = '.\/data',\ntrain = True,\ndownload = True,\ntransform = transform1\n)","b430cea6":"test_set = torchvision.datasets.FashionMNIST(\nroot = '.\/data',\ntrain = False,\ndownload = True,\ntransform = transform1\n)","1f8d5aa6":"img1, label = train_set1[0]","d5ae9f9a":"# this is New Image set\nshow_img(*train_set1[1109])","b937da06":"# This is Original image\nshow_img(*train_set[1109])","69aaa174":"img, label = train_set1[0]\nimg.shape, label","8f4842b1":"img, label = test_set[0]\nimg.shape, label","b8eaacbc":"import numpy as np","89995169":"def split_indices(n, val_per, seed = 0):\n    n_val = int(n * val_per)\n    np.random.seed(seed)\n    idx = np.random.permutation(n)\n    return idx[n_val : ], idx[: n_val]","be19b9e6":"val_per = 0.2\nrand_seed = 42\n\ntrain_indices, val_indices = split_indices(len(train_set1), val_per, rand_seed)\n\nprint(len(train_indices), len(val_indices))","58a58d90":"print(\"Validation Indices: \", val_indices[:20])\nprint(\"Training Indices: \", train_indices[:20])","90bc2125":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","95dae01e":"# this is one of Hyper parameter, but let's select given below value\nbatch_size = 512","d153a6b8":"# training data loader\ntrain_sampler = SubsetRandomSampler(train_indices)\ntrain_dl = DataLoader(train_set1, batch_size, sampler = train_sampler)","60a82a41":"# validation dataloader\nval_sampler = SubsetRandomSampler(val_indices)\nval_dl = DataLoader(train_set1, batch_size, sampler = val_sampler)","b1f9a543":"from torchvision.utils import make_grid\n# this will help us to create Grid of images","d4d283ed":"# We will select first 110 image from first batch of size = 512\ndef show_batch(dl):\n    for img, label in dl:\n        fig, ax = plt.subplots(figsize = (12,8))\n        ax.imshow(make_grid(img[:110], 10).permute(1,2,0))\n        break","5787607e":"show_batch(val_dl)","bfd7e13c":"show_batch(train_dl)","ad37e9d5":"sample = next(iter(train_set1))\nimg = sample[0]\nimg.shape","e0c1ecc3":"import torch.nn as nn\nimport torch.nn.functional as F","432ebffb":"class ResidualBlock(nn.Module):\n    \n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        \n        self.block = nn.Sequential(\n                nn.Conv2d(in_channels = channels[0], out_channels = channels[1], kernel_size = (3,3), stride = (2,2), padding = 1),\n                nn.BatchNorm2d(channels[1]),\n                nn.ReLU(inplace = True),\n                \n                nn.Conv2d(in_channels = channels[1], out_channels = channels[2], kernel_size = (1,1), stride = (1,1), padding = 0)\n            )\n        \n        self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels = channels[0], out_channels = channels[2], kernel_size = (1,1), stride = (2,2), padding = 0),\n                nn.BatchNorm2d(channels[2])\n            )\n        \n    def forward(self, x):\n        shortcut = x\n        \n        block = self.block(x)\n        shortcut = self.shortcut(x)\n        x = F.relu(block + shortcut)\n        \n        return x","381cd218":"### MODEL ###\n\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNet, self).__init__()\n        \n        self.residual_block1 = ResidualBlock(channels = [1,4,8])\n        self.residual_block2 = ResidualBlock(channels = [8,16,32])\n        \n        self.linear_1 = nn.Linear(7*7*32, num_classes)\n        \n    def forward(self, x):\n        \n        out = self.residual_block1(x)\n        out = self.residual_block2(out)\n        \n        logit = self.linear_1(out.view(-1, 7*7*32))\n        \n        return logit","c9e91b9f":"model = ConvNet(num_classes = 10)","2575a875":"sample = next(iter(train_set1))\nimg = sample[0]\nimg.shape","57929652":"img.unsqueeze(1).shape","b6cf7697":"out = model(img.unsqueeze(0))","8cbf30d4":"out","f06b327a":"# Output In terms of Probability\nF.softmax(out)","ee0b20b8":" # Demo function to test result\n\nfor images, labels in train_dl:\n    print('Image Shape', images.shape)\n    out = model(images)\n    print('output shape', out.shape)\n    print('out[0]', out[0])\n    break","8a29b176":"probs = F.softmax(out[0], dim = 0)\nprobs","d1dae142":"m = torch.argmax(probs)\nm","1ae9e34e":"# Lets plot\nplt.imshow(img.permute(1,2,0))","6e7fb39e":"sample[1]","3806366a":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","392f595d":"device = get_default_device()\ndevice","1a8476be":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)","446f6d99":"def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n    \n    pred = model(x)\n    \n    loss = loss_func(pred, y)\n    \n    if opt is not None:\n        \n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    \n    if metric is not None:\n        \n        metric_result = metric(pred, y)\n        \n    return loss.item(), len(x), metric_result","15266550":"def evaluate(model, loss_fn, val_dl, metric = None):\n    \n    with torch.no_grad():\n        \n        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n        \n        losses, nums, metrics = zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses, nums)) \/ total\n        \n        avg_metric = None\n        \n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums)) \/ total\n            \n    return avg_loss, total, avg_metric","1ecfaa0b":"def fit(epochs, model, loss_fn, train_dl, val_dl, opt_fn = None, lr = None, metric = None):\n    \n    train_losses, val_losses, val_metrics = [], [], []\n    history = []\n    \n    if opt_fn is None: opt_fn = torch.optim.Adam\n        \n    opt = opt_fn(model.parameters(), lr = lr)\n    \n    for epoch in range(epochs):\n        \n        model.train()\n        for x, y in train_dl:\n            train_loss, _, _ = loss_batch(model, loss_fn, x, y, opt)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, val_dl, metric)\n        val_loss, total, val_metric = result\n        history.append(result)\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_losses)\n        val_metrics.append(val_metric)\n        \n        if metric is None:\n            print('Epoch{}\/{}, train_loss: {:.4f}, val_loss: {:.4f}' \n                 .format(epoch+1, epochs, train_loss, val_loss))\n            \n        else:\n            print('Epoch {}\/{}, train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric))\n            \n    return train_losses, val_losses, val_metrics","56395413":"# Define accuracy as measure of perfomance\ndef accuracy(output, labels):\n    _, preds = torch.max(output, dim = 1)\n    \n    return torch.sum(preds == labels).item() \/ len(preds)","9684d624":"# let's check how initial guess work on Validation set\nval_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric = accuracy)\n\nprint(val_loss, val_acc)","594e7769":"num_epochs = 15\nopt_fn = torch.optim.Adam\nlr = 1e-5","d93725f9":"history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, opt_fn, lr, accuracy)","a492702e":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","379056ea":"img, label = test_set[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","1391bb33":"img, label = test_set[1839]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","9fd8e117":"img, label = test_set[193]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","5156357d":"img, label = test_set[10]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","c6530c91":"test_loader = DeviceDataLoader(DataLoader(test_set, batch_size=256), device)\nresult = evaluate(model, F.cross_entropy, test_loader, metric = accuracy)\nresult\nAccuracy = result[2] * 100\nAccuracy\nloss = result[0]\nprint(\"Total Losses: {}, Accuracy: {}\".format(loss, Accuracy))","8fe3e44b":"Main aim is to reduce Overfitting, lets see below code","ef575fe5":"We will be performing Data Normalization.\nData Normalization is technique where we normalize data using Formula (x - mu) \/ std. By performing Standrdization, we will reduce importance of any feature that gives equal opportunity all variables.\n\n\nWe can assume this value as 0.5 mean and 0.5 standard deviation, but its always best practice to find for each Dataset","20c31325":"As a final step, let's also look at the overall loss and accuracy of the model on the test set.\n\n","cc2d6bbd":"# Define Fit Function","b739e38f":"So Mean = 0.286, Std = 0.66","c265e6dd":"Let's Train Model\n\n","b1972289":"Let's Import libraries to generate Random Subset & dataLoader to feed Batch of data to model, as feeding whole dataset may lead to System failure or Hang","b3a525de":"# Test dataloading & Model Evaluation","ed239385":"Following code will help us to find Mean and Standard Deviation, let's calculate","f86a5194":"# Device selection","16796ef9":"We can depict change in image clearly","8ce00609":"# Import Required Library & Load data","157a868a":"We need to import one extra dimension as Model need shape as [batch_size COlor Channel heigh * Width]\n\n.unsqueeze() from torch help to add extra dimension","623413e7":"Thats it for this Notebook...\n\nIf you like this kindly Consider Upvoting!! Happy learning!!","b17932b2":"So highest 17% probability that this image belong to label index 1\nLet's Verify","c355d094":"So, model suggest, this image belong to index 2, Let's observe\n\n","a6be52fd":"So images now are of size ","5473a407":"# Helper Function to Get Best Fit","08b7126d":"Now we have [1, 1, 28, 28] shape of image","b0938f4f":"Well, around 10% accuracy, well it was initial guess, dont worry !!\n\n","0af5e27c":"# Training & Validation set Generation","12882cc5":"As we are using GPU, so below code will help us to access GPU at different stage of Processing\n\n","c487405f":"# Regularization","fa0f9ee9":"Let's find out original data size and shape","50327c31":"Lets verify how transformation has been carried out and its effect","61f3d62e":"Let's test model based on initial Guesses by Pytorch\n\n","d71b2b21":"Let's download Train & Test images","0ad19eab":"Let's verify where we have all class from output columns in both train and validation set\n\n","c48f2b77":"Initial guess from model suggest, probability of class index 9, is our final answer","86bbb880":"Well, initial prediction was Class 5, it was class 9 actually :(,\n\nNo worry, it was just random guess by model","166bd639":"So we have 60000 train data and each image is 28*28 pixel and all are gray scale as only 1 color channel exist","b1505c2f":"# Model Building using Torch.nn","8d2934a3":"# Data Study and Stadardization","d210a1e1":"Let's Import libraries to generate Random Subset & dataLoader to feed Batch of data to model, as feeding whole dataset may lead to System failure or Hang"}}