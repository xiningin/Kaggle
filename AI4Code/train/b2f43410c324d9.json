{"cell_type":{"74040b41":"code","0605fcb5":"code","6162bea7":"code","1613120e":"code","4ee19986":"code","679fffb3":"code","8ab2ff8c":"code","ae192a72":"code","15707b9a":"code","a181d867":"code","7f9ea2d6":"code","7815efd9":"code","552c96a9":"code","1303368b":"code","da6c3592":"code","8c309c07":"code","2dbfb114":"code","ae01f822":"code","8571147f":"code","08b638b4":"code","11134463":"markdown","2830f8f8":"markdown","aa600d36":"markdown","4f7ea51f":"markdown","16a583fb":"markdown","b12c3305":"markdown","1fcf773f":"markdown","fb8dc675":"markdown","550dcd2b":"markdown","21c656dd":"markdown","f68388a7":"markdown","7b9dab0a":"markdown"},"source":{"74040b41":"pip install beautifulsoup4","0605fcb5":"#we import the libraries\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport sys\n","6162bea7":"result=requests.get('https:\/\/www.talabat.com\/egypt\/restaurants') #we make a requests to get the link info \n    \nwebsite=BeautifulSoup(result.content,'lxml') #we turn the url contant to readable HTML ","1613120e":"name=website.find_all('p',{'class':'h5 f-14 m-0 text-nowrap'}) \n\n#the name variable will return every restaurant HTML that has the name in the page but in the list type\n\n\nname[1].text #we can check if it works , by specify which element in the list we want to turn into a text\n\n","4ee19986":"#to get turn all the HTML into text we use FOR loop\n\nres_name=[]   #create an empty list to store the output inside it \nfor i in range(len(name)):\n    res_name.append(name[i].text)\n    \n    \nres_name #as you can see we get all restaurant names","679fffb3":"name=website.find_all('p',{'class':'h5 f-14 m-0 text-nowrap'}) \ntypee=website.find_all('p',{'class':'h5 f-14 muted m-0 text-nowrap'}) \n\nres_name=[] #create an empty list to store the output inside it \nres_type=[]\nfor i in range(len(name)):\n    res_name.append(name[i].text)\n    res_type.append(typee[i].text)\n\n","8ab2ff8c":"res_type","ae192a72":"#function to return the resturnt name in a shape to be readable as a link\n\ndef remove(name):\n    string=(\"[@_!#.$%^&*()<>?\/'\\|}{~:]\") \n    \n    for i in string:\n        name=name.replace(i, \"\") #remove the spical chracters\n        \n    return name.replace(\" \",\"-\") #replace the space with a -","15707b9a":"#we create the links from the res_name list:\nlinks=[]\n\nfor a in res_name:\n    links.append('https:\/\/www.talabat.com\/egypt\/'+remove(a))\n    links=list(dict.fromkeys(links))","a181d867":"links #we have now the links","7f9ea2d6":"rate=[]\n\nfor linkk in links: \n    \n    result=requests.get(linkk)\n    src=result.content\n    soup=BeautifulSoup(result.content,'lxml')\n    rates=soup.find('div',{'class':'rating-number text-center mr-1'})\n    \n    try:                    #we use the try and excpt in order if we get an invaild link,we don't have to stop all the for loop.\n        rate.append(rates.text)\n        \n    except:\n        rate.append(0) #we append a 0 with invailed links , in order to keep the order \n        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n        print(\"Next entry.\")\n        print()","7815efd9":"rate #now we have the rate, notice that the 0 as an int means invaild link,and '0.0' as str is a rate","552c96a9":"#creating the lists\nres_name=[]\nres_type=[]\nlinks=[]\nrate=[]\nnumber=0","1303368b":"# create the while loop for 13 pages\nwhile number < 13 : #we will do the same as we did previously\n    \n    result=requests.get(f'https:\/\/www.talabat.com\/egypt\/restaurants?page={number}') #we here change the page number to the number variable\n    website=BeautifulSoup(result.content,'lxml')\n    \n    name=website.find_all('p',{'class':'h5 f-14 m-0 text-nowrap'}) \n    typ=website.find_all('p',{'class':'h5 f-14 muted m-0 text-nowrap'})\n    \n    \n    for i in range(len(name)):\n        res_name.append(name[i].text)\n        res_name=list(dict.fromkeys(res_name))\n        \n        res_type.append(typ[i].text)\n\n        \n    #creating the links    \n    for a in res_name:\n        links.append('https:\/\/www.talabat.com\/egypt\/'+remove(a))\n        links=list(dict.fromkeys(links))\n        \n        \n        \n    number += 1\n    print('pag is done',number) #to keep track with the page number","da6c3592":"rate=[]\n","8c309c07":"#this may take a while \nfor linkk in links:\n    \n    result=requests.get(linkk)\n    src=result.content\n    soup=BeautifulSoup(result.content,'lxml')\n    rates=soup.find('div',{'class':'rating-number text-center mr-1'})\n    \n    try:\n        rate.append(rates.text)\n        \n    except:\n        rate.append(0)\n        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n        print(\"Next entry.\")\n        print()","2dbfb114":"#creating a dataframe that has all the lists\n\na ={'res_name':res_name,'res_type':res_type,'links':links,'rate':rate}\ndf = pd.DataFrame.from_dict(a, orient='index').transpose() #we did that as if we have an empty cell\ndf=df.dropna()\n","ae01f822":"df #here you have the data ","8571147f":"stop","08b638b4":"df.to_csv('talabt.csv', index=False) #saving the df into your local","11134463":"#### but we did this for only one page , how to make it to all pages ?\n\nwe use a while loop","2830f8f8":"![3.jpg](attachment:d0038630-c8db-4775-95ef-6d74deb75fab.jpg)","aa600d36":"### we can do the same as we did with the name , in order to get the restaurant type","4f7ea51f":"#### this only for the this page it will take forever to do this for the whole pages","16a583fb":"![1.jpg](attachment:d564f954-d9d9-4d24-85c1-d640204f931f.jpg)","b12c3305":"#### we want to extract the restaurant name we :\n\n1-right click on the name \n\n2- choice inspect\n\n3-we only interested on two parts of the HTML , first is the first letter or word after the '<' sign , second the attribute and here we have the class arrtibute","1fcf773f":"as we can see in the Screenshot from  (https:\/\/www.talabat.com\/egypt\/restaurants), we want to extract data from the website.","fb8dc675":"#### after creating the funcation we do the same as we did with name and type ","550dcd2b":"![4.jpg](attachment:60386d71-4aa8-41c1-9a4a-d71ea39da75e.jpg)","21c656dd":"### how to get info from the inner page?\n\nin order to get the restaurant rate , we do as following","f68388a7":"as we can see The variable part is the last part and it's the restaurant name \n\n\n##### note : there are no spaces or speical letters in the link so we have to make sure we remove it all ","7b9dab0a":"![2.jpg](attachment:ce68a220-f592-435a-9d4d-a7f48f7d4097.jpg)"}}