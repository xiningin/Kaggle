{"cell_type":{"752ef589":"code","3fb732f2":"code","c4305dbd":"code","1ac4d185":"code","dc30a8e2":"code","011b0728":"code","bbdc4e31":"code","367ab8f8":"code","068bba60":"code","02609fcf":"code","a36d71a5":"code","f0953fd1":"code","65efb05d":"code","622dc4af":"code","cc1fa2e1":"code","a83c025f":"code","e39d73ac":"code","f3aea5fe":"code","34956985":"code","7ed2668e":"code","6418292c":"code","6c9ef03d":"code","1329ac6c":"code","c65073ca":"code","bce7b034":"markdown","c1f08b71":"markdown","15f9676e":"markdown","3846c9a1":"markdown","c25e59f0":"markdown","bca807eb":"markdown","debfc587":"markdown","bf126351":"markdown","c0e811a4":"markdown"},"source":{"752ef589":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fb732f2":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2 as cv\nfrom pprint import pprint\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom numpy import expand_dims\nimport tensorflow.keras.layers as Layers\n# model\nfrom tensorflow.keras.models import Sequential\n\n# layers\nfrom tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Activation, Dropout\n\n# categorical\nfrom tensorflow.keras.utils import to_categorical\nimport os\nimport glob","c4305dbd":"def dataset_create(path):\n    \"\"\"reading images in each folder and creating our data so the model \n    to be trained on\"\"\"\n    images = []\n    labels = []\n    for folder in os.listdir(path):\n        image_path = os.path.join(path, folder)\n        for filename in glob.glob(image_path + '\/*.jpg'):\n            image = cv.imread(filename)\n            image = cv.resize(image,(150,150))\n            images.append(image)\n            labels.append(folder)\n    return np.array(images), np.array(labels)","1ac4d185":"path_train = '\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train'\n\nx_train, y_train = dataset_create(path_train)\nx_train.shape, y_train.shape","dc30a8e2":"\nimport seaborn as sns\nsns.set(rc = {'figure.figsize':(12,7)})\np = sns.countplot( x = y_train, palette = 'Set3')\n\n#I think we can consider our training dataset as balanced dataset\n\n","011b0728":"#converting the lables to the categorical number they should have:\ndef y_label(y):\n    label_categories = {'buildings': 0,\n            'forest': 1,\n            'glacier': 2,\n            'mountain': 3,\n            'sea': 4,\n            'street': 5}\n\n#y_train_cat = map(label_categories.get, y_train_array)\n    y = [label_categories[k] for k in y]\n    return y\n\ny_train = y_label(y_train)\n","bbdc4e31":"import random\ndef shuffle_data(x,y):\n    c = list(zip(x, y))\n    random.shuffle(c)\n    x, y = zip(*c)\n    x= np.asarray(x)\n    y= np.asarray(y)\n    return x, y\n\nx_train, y_train = shuffle_data(x_train,y_train)","367ab8f8":"type(y_train)","068bba60":"y_train = to_categorical(y_train)","02609fcf":"# define the model\nmodel = Sequential([\n    # First convolutional layer\n    Conv2D(filters= 64, kernel_size=(3, 3), input_shape=(150, 150, 3)),\n    MaxPool2D(pool_size=(2, 2), strides=2),\n    Activation('relu'),\n    # Second convolutional layer\n    #Conv2D(filters= 16, kernel_size=(3, 3),input_shape=(150, 150, 3)),\n    #MaxPool2D(pool_size=(2, 2), strides=2),\n    #Activation('relu'),\n    # Fully connected layers\n    Flatten(),#before that we need to flatten our inputs\n    #Dense(units =128, activation = 'relu'),\n    #Dropout(0.5),\n    Dense(units =64, activation = 'relu'),\n    #Dropout(0.2),\n    Dense(units =32, activation = 'relu'),\n    #Dropout(0.2),\n    Dense(units=6, activation='softmax') # like binary Logistic Regression classifier, Softmax classifier is its generalization to multiple classes (here we have 6).\n])","a36d71a5":"model.summary()","f0953fd1":"# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy']\n)","65efb05d":"history = model.fit(x=x_train, y=y_train, batch_size=128, epochs=20, validation_split=0.2)","622dc4af":"\n\n#from tensorflow.keras import backend as K\n\n#K.clear_session()\n\n","cc1fa2e1":"\n\n# plot the accuracy\nplt.figure(figsize=(12,4))\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.show()\n\n","a83c025f":"# now lets test it on our test data\n# firts we need to prepare our test data\npath_test = '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'\n\nx_test, y_test = dataset_create(path_test)\ny_test = y_label(y_test)\nx_test, y_test = shuffle_data(x_test,y_test)\ny_test = to_categorical(y_test)","e39d73ac":"score = model.evaluate(x_test, y_test)\nprint(score)","f3aea5fe":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications.vgg16 import decode_predictions","34956985":"model_2 = VGG16(weights='imagenet')","7ed2668e":"\nmodel_2 = VGG16(input_shape=(150, 150, 3), weights='imagenet', include_top=False)","6418292c":"# freeze the layers in Convolutional part so that do not retrain them\nfor layer in model_2.layers:\n    layer.trainable = False\n    print(layer.trainable)\n\n","6c9ef03d":"# Now lets add the fully connected part as we like to our model_2\nedited_model = Sequential([\n    model_2,\n    Flatten(),\n    Dense(16, activation='relu'),\n    Dense(6, activation='softmax')\n])\n\n","1329ac6c":"# compile the model\nedited_model.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy']\n)","c65073ca":"history_2 = edited_model.fit(x=x_train, y=y_train, batch_size=32, epochs=20, validation_split=0.2)","bce7b034":"To have a correct and reliable model, we need to check if our collected data is ballenced, thus we count how much each category do we have in training dataset","c1f08b71":"Now its time to shuffle our training data, so that we have random input into our CNN model.\nWe want to shuffle two list at once with same order. That is why we need to use zip","15f9676e":"VGG16 models takes images input as with 244* 244 * 3 but we can change it to our desired dimension","3846c9a1":"In order to train our models we need to creat a dataset including images, and labels of those images.\nThus with the help of OpenCV we read images from each folder, cv.imread, reads images and returns their array.\nThen we define the size of our target so that we can have the correct shape for our CNN model\n","c25e59f0":"In the explanation of dataset, it is asked us to give specific number to each category, therefore we change our y_train list into numbers.\ndefine a dictionary and then with a simple list comprehension we convert our y_train to what we wanted.","bca807eb":"like what we were expecting from our validation result","debfc587":"In order to feed the lables to CNN we need to categorise label values so 'to_categorical' is our function","bf126351":"Obviously we have over fitting, and our validation model is not learning like our training model.","c0e811a4":"## Now lets try transfer learning\n#### we can strat by VGG16\nI would like to fisrt fine tune the fully connected layers thus when I am loading the VGG16 model I have to specify \"include_top=False\""}}