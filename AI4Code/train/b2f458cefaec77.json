{"cell_type":{"54de89b9":"code","d074e965":"code","327baddd":"code","759504b0":"code","371e5d4c":"code","a5391fd3":"code","e74190db":"code","4cbe01a9":"code","4b5b1489":"code","05f55c3d":"code","a9a2f3e5":"code","f47f6424":"code","117e987d":"code","75bdb90e":"code","d79401f2":"code","4eda7fd2":"code","d9823e83":"code","e0c8c1f2":"code","9aca0f1c":"code","8e962cae":"code","0f1832f8":"code","a11f8d89":"code","72e5012f":"code","b9423cc7":"code","c5b731bc":"code","1fea14a4":"code","d8b648c0":"code","01e05c2e":"code","a50deb25":"code","6ce773c5":"code","ef8d4150":"code","4f7973b6":"code","997d06b5":"code","b861daec":"code","9fa37b06":"code","490a03b3":"code","4fadc325":"code","1513cef5":"code","a3efd6a1":"code","a1d8f67a":"code","ad78ab2b":"code","7ae290bd":"code","9270821d":"code","4d33d8d3":"code","e2ced841":"code","aa34e5a0":"code","ff40b707":"code","a8a205d9":"code","bd38de9d":"code","1ff6b580":"code","fd670fe9":"code","3ebdee3c":"code","bc5379f9":"code","1094268c":"code","6fccbae3":"code","2f08ea9f":"code","d4577001":"markdown","7f204f8c":"markdown","4dbc3531":"markdown","a2c656e1":"markdown","b57b613f":"markdown","454138c0":"markdown","596fab6b":"markdown","9ee92b2e":"markdown","ff950dac":"markdown","3440234e":"markdown","e093bcd2":"markdown","669b2fcd":"markdown","3d13a719":"markdown","370230ff":"markdown","998dab1c":"markdown","4696f91e":"markdown","58c1c0d6":"markdown","ee103ca4":"markdown","66dd33bd":"markdown","3c1902cc":"markdown","49156f85":"markdown","e19a958d":"markdown","664d94b8":"markdown","55768b1b":"markdown","b5d2c0fa":"markdown","fe6269a9":"markdown","f1504a95":"markdown","3fc9533b":"markdown","3cca022f":"markdown","14376e69":"markdown","1cdc63ab":"markdown","445b9ebf":"markdown","d606ee48":"markdown","06701178":"markdown","90195714":"markdown","9b80f547":"markdown","63d4ce20":"markdown","1b80b8b3":"markdown","3ed23b26":"markdown","ec7edbdb":"markdown","71006737":"markdown","ee70440a":"markdown","c7980fd4":"markdown","d717686d":"markdown","1ba8c803":"markdown","03a240df":"markdown","ec4a9bd5":"markdown","0073ab4e":"markdown","26a9446b":"markdown","0c8898ca":"markdown","ac61e900":"markdown","df96457a":"markdown","7e437c7d":"markdown","716035c9":"markdown","3c102e2c":"markdown","a353b329":"markdown","13fb7baf":"markdown","2951e40a":"markdown"},"source":{"54de89b9":"import csv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport geopandas as gpd\nimport geoplot as gplt\n\n# data = []\n# with open('\/kaggle\/input\/jobs-on-naukricom\/home\/sdf\/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv', newline='', encoding=\"utf8\") as csvfile:\n#     spamreader = csv.reader(csvfile)\n#     for row in spamreader:\n#         sub = np.array(row)\n#         if sub[2] == \"\":\n#             continue\n#         data.append(sub)\npd.set_option('display.max_columns',15)\npd.set_option('display.max_rows',None)\ndata_df=pd.read_csv('\/kaggle\/input\/jobs-on-naukricom\/home\/sdf\/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv')\n# data = np.array(data)\ndata_df.head()","d074e965":"data_df.dtypes","327baddd":"data_df.isna().any()","759504b0":"sns.heatmap(data_df.isnull(),cbar=True,cmap='gnuplot')","371e5d4c":"selected_col = ['Job Title', 'Job Salary', 'Job Experience Required', 'Key Skills', 'Role Category', 'Location', 'Functional Area', 'Industry', 'Role']\nmissing = []\nfor col in selected_col:\n    print('Number of missing data in', col,':', data_df[col].isna().value_counts()[1])\n    missing.append((col, data_df[col].isna().value_counts()[1]))\nprint('Total number of missing data :', len(data_df))","a5391fd3":"missing.sort(key=lambda x: x[1], reverse = True)\nx_pos = [i for i in range(len(missing))]\nnums = [words[1] for words in missing]\nx = [words[0] for words in missing]\nsns.set(rc={'figure.figsize':(19,9)})\nsns.barplot(x=x, y=nums)","e74190db":"data_df.dropna(axis=0,inplace=True)\ndata_df.isna().any()","4cbe01a9":"fp = '..\/input\/data-ana-for-jobs-on-naukri-supplements\/india-polygon.shp'\nmap_df = gpd.read_file(fp)\nmap_df.head()","4b5b1489":"map_df[\"st_nm\"]","05f55c3d":"# ind will pass the industry into the function, if ind == '', this means that we are looking at all industries\ndef get_ind_city_cnt(ind):\n    cityCnt = {}\n    sub_data = data_df[data_df['Industry'].str.contains(ind)]\n    for i in range(len(sub_data)):\n        cities = sub_data.iloc[i, 7]\n        if \"(\" in cities:\n            index = cities.find(\"(\")\n            cities = cities[:index]\n        cities = cities.split(\",\")\n        uniqueCities = set()\n        for city in cities:\n            tmp = city\n            # cleaning data\n            if \")\" in tmp:\n                print(city)\n            if \"\/\" in tmp:\n                sameName = city.split(\"\/\")\n                sameName.sort()\n                tmp = sameName[0]\n            tmp = tmp.strip()\n            uniqueCities.add(tmp.lower())\n        for city in uniqueCities:\n            cityCnt[city] = cityCnt.get(city, 0) + 1\n\n    # some location information need to be deleted\n    cleanSet = [\"electronics city\", \"1700000\", \"300000\", \"400000\", \"500000\", \"700000\"]\n    for i in cleanSet:\n        if i in cityCnt:\n            del cityCnt[i]\n    return cityCnt\ncityCnt = get_ind_city_cnt(\"\")\nprint(\"Number of unique locations in dataset is\", len(cityCnt))","a9a2f3e5":"cityData = pd.ExcelFile(\"..\/input\/data-ana-for-jobs-on-naukri-supplements\/Town_Codes_2001.xls\")\ncity_df = cityData.parse(\"Sheet1\")\ncity_df.head()","f47f6424":"notFound = set([])\nfor name in city_df[\"State\/Union territory\"]:\n    if map_df[map_df[\"st_nm\"].isin([name])].empty:\n        notFound.add(name)\nnotFound","117e987d":"stateTran = {'Andaman & Nicobar Islands *':'Andaman and Nicobar Islands' ,\n             \"Chandigarh *\":'Chandigarh' ,\n             \"Dadra & Nagar Haveli *\":'Dadra and Nagar Haveli',\n             \"Daman & Diu *\":'Daman and Diu',\n             \"Lakshadweep *\":'Lakshadweep',\n             \"Delhi *\":'Delhi',\n             \"Pondicherry *\":'Puducherry',\n             \"Uttaranchal\": 'Uttarakhand',\n             \"Orissa\":'Odisha',\n             \"Jammu & Kashmir\": 'Jammu and Kashmir'\n            }","75bdb90e":"notFoundCities = []\ncityToState = {}\nfor name in cityCnt.keys():\n    if name == \"\":\n        continue\n    tmp = name[0].upper()+name[1:]\n    if city_df[city_df[\"City\/Town\"].isin([tmp])].empty:\n        if city_df[city_df[\"State\/Union territory\"].isin([tmp])].empty:\n            sub = tmp.split()\n            add = False\n            for i in sub:\n                i = i[0].upper()+i[1:]\n                if city_df[city_df[\"City\/Town\"].isin([i])].empty and city_df[city_df[\"State\/Union territory\"].isin([i])].empty:\n                    add = True\n                else:\n                    add = False\n            if add:\n                notFoundCities.append(name)\nprint(\"Number of location that is no matched in either cities or states\",len(notFoundCities))","d79401f2":"# # Save\n# np.save('unmatchedLocations.npy', cityTran) \n\n# Load\ncityTran = np.load('..\/input\/data-ana-for-jobs-on-naukri-supplements\/unmatchedLocations.npy',allow_pickle='TRUE').item()","4eda7fd2":"# retrieve state according to its location\ndef getState(city):\n    if city == \"\":\n        return \"\"\n    tmp = city[0].upper()+city[1:]\n    if city_df[city_df[\"City\/Town\"].isin([tmp])].empty:\n        if city_df[city_df[\"State\/Union territory\"].isin([tmp])].empty:\n            sub = tmp.split()\n            add = False\n            for i in sub:\n                i = i[0].upper()+i[1:]\n                if city_df[city_df[\"City\/Town\"].isin([i])].empty:\n                    if city_df[city_df[\"State\/Union territory\"].isin([i])].empty:\n                        add = True\n                    else:\n                        return city_df.loc[city_df[\"State\/Union territory\"]==i][\"State\/Union territory\"].values[0]\n                else:\n                    return city_df.loc[city_df[\"City\/Town\"]==i][\"State\/Union territory\"].values[0]\n                    \n            if add:\n                return \"\"\n    else:\n        return city_df.loc[city_df[\"City\/Town\"]==tmp][\"State\/Union territory\"].values[0]\n\n# translate the state\ndef validState(state):\n    if state in stateTran:\n        return stateTran[state]\n    else:\n        return state\n\n# get the number of jobs with respect to its state\ndef get_state_cnt(cityCnt):\n    stateCnt = {}\n    missing = []\n    for city, num in cityCnt.items():\n        state = getState(city)\n        if state == \"\" or state is None:\n            if city in cityTran:\n                state = validState(cityTran[city])\n                stateCnt[state] = stateCnt.get(state, 0) + num\n            else:\n                missing.append(city)\n\n        else:\n            state = validState(state)\n            stateCnt[state] = stateCnt.get(state, 0) + num\n    return stateCnt, missing\n\nstateCnt, missing = get_state_cnt(cityCnt)\nprint(\"The number of locations that is still not mapped to states\", len(missing))","d9823e83":"missing","e0c8c1f2":"def plot_geo(stateCnt, ind):\n    stateData = []\n    for key, val in stateCnt.items():\n        stateData.append((key, val))\n    for state in map_df[\"st_nm\"]:\n        if state not in stateCnt:\n            stateData.append((state, 0))\n    \n    jobNum = [0 for _ in range(len(DATA_df))]\n    new_col = ind+\" Number of Jobs\"\n    DATA_df[new_col] = jobNum\n    \n    for state, num in stateData:\n        DATA_df.loc[DATA_df[\"st_nm\"] == state, new_col] = num\n    merged= map_df.merge(DATA_df, on = \"st_nm\", how = \"left\")\n    \n    fig, ax = plt.subplots(1, figsize=(10, 10))\n    ax.axis(\"off\")\n    ax.set_title(ind+\" Job data\", fontdict={\"fontsize\": \"25\", \"fontweight\" : \"10\"})\n    merged.plot(column=new_col,cmap=\"YlGnBu\", linewidth=0.8, ax=ax, edgecolor=\"0\", legend=True,markersize=[39.739192*2, -104.990337*2])\n    plt.show()\n    merged = merged.sort_values(new_col, ascending=False)\n    sns.barplot(x=merged['st_nm'][:10], y=merged[new_col][:10])\n    \ndef ind_geo_dist(ind):\n    city_cnt = get_ind_city_cnt(ind)\n    state_cnt, missing = get_state_cnt(city_cnt)\n    plot_geo(state_cnt, ind)\n\nDATA_df = pd.read_excel(\"..\/input\/data-ana-for-jobs-on-naukri-supplements\/data_ecxel.xlsx\")\nDATA_df.rename(columns={\"Name of State \/ UT\": \"st_nm\"},inplace=True)\nind_geo_dist(\"\")","9aca0f1c":"data_df['Industry'].value_counts()[:10]","8e962cae":"data_df.loc[data_df['Industry'].str.contains('IT-Software \/ Software Services',case=False)]='IT-Software, Software Services'\ndata_df.loc[data_df['Industry'].str.contains('Recruitment \/ Staffing',case=False)]='Recruitment , Staffing'\ndata_df['Industry'].value_counts()[:10]","0f1832f8":"print(\"We will focus on the top 10 industries because they compose\", '{:.1%}'.format(sum(data_df['Industry'].value_counts()[:10])\/len(data_df)), 'of all data')","a11f8d89":"top_ten_state = data_df['Industry'].value_counts()[:10].index\nfor ind in top_ten_state:\n    ind_geo_dist(ind)","72e5012f":"data_df['Job Salary'].value_counts()[:10]","b9423cc7":"data_df['Job Experience Required'].value_counts()[:10]","c5b731bc":"exp_cat = ['' for _ in range(len(data_df))]\ndata_df['Experience Categories'] = exp_cat\ndata_df.head()","1fea14a4":"CAT = {(0, 1):\"Newbie\", (1, 5):\"Semiprofessional\", (5, 10):\"Professional\", (10, 100):\"Expert\"}\ndef get_cat(yrs):\n    if len(yrs) != 2:\n        return \"\"\n    start, end = str(yrs[0]), str(yrs[1])\n    start, end = start.strip(), end.strip()\n    if not start.isnumeric():\n        return \"\"\n    start, end = int(start), int(end)\n    res = ''\n    for key, val in CAT.items():\n        if start <= key[1] and end > key[0]:\n            res += ' ' + val\n    if start >= 10:\n        res += ' Expert'\n    res = res.strip()\n    return res\n\nfor i in range(len(data_df)):\n    job_req = data_df.iloc[i, 4].lower()\n    #print(job_req)\n    index = job_req.find('y')\n    job_req = job_req[:index]\n    yrs = job_req.split('-')\n    cat = get_cat(yrs)\n    data_df.iloc[i, -1] = cat\n\ndata_df.head()","d8b648c0":"value_cnt = {\"Newbie\":0, \"Semiprofessional\":0, \"Professional\":0, \"Expert\":0}\nfor i in range(len(data_df)):\n    sub_cat = data_df.iloc[i, -1]\n    sub_cat = sub_cat.split()\n    for key in value_cnt.keys():\n        if key in sub_cat:\n            value_cnt[key] += 1\nfor key, val in value_cnt.items():\n    print(key, \":\", val)\nplt.pie(x=[val for val in value_cnt.values()], labels=[key for key in value_cnt.keys()], autopct='%1.1f%%')","01e05c2e":"new_df = data_df[data_df['Experience Categories'].str.contains('Newbie', case=True)]\nnew_cnt = new_df['Industry'].value_counts()\nplot = new_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","a50deb25":"semipro_df = data_df[data_df['Experience Categories'].str.contains('Semiprofessional', case=True)]\nsemipro_cnt = semipro_df['Industry'].value_counts()\nplot = semipro_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","6ce773c5":"pro_df = data_df[data_df['Experience Categories'].str.contains('Professional', case=True)]\npro_cnt = pro_df['Industry'].value_counts()[:10]\nplot = pro_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","ef8d4150":"exp_df = data_df[data_df['Experience Categories'].str.contains('Expert', case=True)]\nexp_cnt = exp_df['Industry'].value_counts()[:10]\nplot = exp_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","4f7973b6":"pro_cnt = pd.DataFrame(pro_cnt)\npro_cnt.reset_index(inplace=True)\npro_cnt.rename(columns={'Industry':'Professional'},inplace=True)\nsemipro_cnt = pd.DataFrame(semipro_cnt)\nsemipro_cnt.reset_index(inplace=True)\nsemipro_cnt.rename(columns={'Industry':'Semiprofessional'},inplace=True)\nnew_cnt = pd.DataFrame(new_cnt)\nnew_cnt.reset_index(inplace=True)\nnew_cnt.rename(columns={'Industry':'Newbie'},inplace=True)\nexp_cnt = pd.DataFrame(exp_cnt)\nexp_cnt.reset_index(inplace=True)\nexp_cnt.rename(columns={'Industry':'Expert'},inplace=True)\nmerged = new_cnt.merge(semipro_cnt, on = \"index\", how = \"left\")\nmerged = merged.merge(pro_cnt, on = \"index\", how = \"left\")\nmerged = merged.merge(exp_cnt, on = \"index\", how = \"left\")\nmerged.head()","997d06b5":"merged = merged.fillna(0)\nmerged.isnull().values.any()","b861daec":"total, per_semi, per_pro, per_new, per_exp= [], [], [], [], []\n\nfor i in range(len(merged)):\n    sub_t = merged[\"Semiprofessional\"][i] + merged[\"Professional\"][i] + merged[\"Newbie\"][i]+merged['Expert'][i]\n    total.append(sub_t)\n    per_semi.append(merged['Semiprofessional'][i] \/ sub_t)\n    per_pro.append(merged['Professional'][i] \/ sub_t)\n    per_new.append(merged['Newbie'][i] \/ sub_t)\n    per_exp.append(merged['Expert'][i] \/ sub_t)\nmerged[\"Total Number of Jobs\"] = total\nmerged[\"Percent of Semipro\"] = per_semi\nmerged[\"Percent of Pro\"] = per_pro\nmerged[\"Percent of New\"] = per_new\nmerged[\"Percent of Exp\"] = per_exp\nmerged.head()","9fa37b06":"fig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor i in range(5):\n    for j in range(2):\n        val = [merged.iloc[i*2+j, k] for k in range(6, 10)]\n        index = ['Percent of Semipro', 'Percent of Pro', 'Percent of New', 'Percent of Exp']\n        tmp = pd.DataFrame({\"Val\":val}, index = index)\n        axs[i, j].pie(tmp, autopct='%.0f%%', labels=tmp.index)\n        axs[i, j].set_title(merged.iloc[i*2+j,0] + ' Recruitment Pattern')","490a03b3":"merged = merged.sort_values(\"Percent of New\", ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Newbies','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][8]))\nmerged = merged.sort_values(\"Percent of Semipro\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Semiprofessionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][6]))\nmerged = merged.sort_values(\"Percent of Pro\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Professionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][7]))\nmerged = merged.sort_values(\"Percent of Exp\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Experts','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][9]))","4fadc325":"print('<', merged.iloc[0][0], '> is The industry that recruits least Newbies','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][8]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Semiprofessionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][6]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Professionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][7]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Experts','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][9]))","1513cef5":"from wordcloud import WordCloud, STOPWORDS\ndef topSkills(Industry):\n    ind = data_df[data_df['Industry'] == Industry]\n    keySkill = ind['Key Skills'].value_counts()\n    keySkill.head()\n    skillCnt = {}\n    wcloud = []\n    for row, cnt in keySkill.iteritems():\n        skill_arr = row.split('|')\n        for skill in skill_arr:\n            skill = skill.strip().lower()\n            skillCnt[skill] = skillCnt.get(skill, 0) + cnt\n            for i in range(cnt):\n                wcloud.append(skill)\n    skillCnt = pd.Series(skillCnt).to_frame('Count')\n    skillCnt.reset_index(inplace=True)\n    skillCnt.rename(columns={'index':'Skill'},inplace=True)\n    skillCnt.head()\n    #print(skillCnt)\n    skillCnt = skillCnt.sort_values(\"Count\",ascending=False)\n    skillRange = 10 if len(skillCnt) >= 10 else len(skillCnt)\n    ax = skillCnt.head(skillRange).plot(kind='bar', figsize=(9, 5))\n    plt.xticks(range(skillRange), skillCnt.head(skillRange)['Skill'])\n    ax.set_ylabel(\"Total Number of Skill\")\n    ax.set_xlabel(\"Skill\")\n    t = Industry+\" Industry Top Skills\"\n    plt.title(t)\n    wordcloud = WordCloud(width = 500, height = 500, \n                    background_color ='white', \n                    min_font_size = 10).generate(str(wcloud))\n    plt.figure(figsize = (8, 8), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.show()","a3efd6a1":"topSkills('IT-Software, Software Services')","a1d8f67a":"topSkills('Recruitment, Staffing')","ad78ab2b":"topSkills('BPO, Call Centre, ITeS')","7ae290bd":"topSkills('Banking, Financial Services, Broking')","9270821d":"topSkills('Education, Teaching, Training')","4d33d8d3":"topSkills('Medical, Healthcare, Hospitals')","e2ced841":"topSkills(\"Strategy, Management Consulting Firms\")","aa34e5a0":"topSkills(\"Internet, Ecommerce\")","ff40b707":"topSkills(\"Media, Entertainment, Internet\")","a8a205d9":"topSkills(\"Travel , Hotels , Restaurants , Airlines , Railways\")","bd38de9d":"jobTitle = data_df['Job Title']\ndic = {}\nfor job in jobTitle:\n    dic[job] = dic.get(job, 0) + 1","1ff6b580":"def findTop(arr, key, val, num):\n    arr.append((val, key))\n    arr.sort(reverse=True)\n    if len(arr) > num:\n        arr.pop()\n    \nuniequeJobTitle = []\ntopTenJobTitle = []\nfor key, val in dic.items():\n    findTop(topTenJobTitle, key, val, 10)\n    if val == 1:\n        uniequeJobTitle.append(key)\nprint(len(uniequeJobTitle), \"number of unique Job Title\")","fd670fe9":"x_pos = [i for i in range(len(topTenJobTitle))]\nnums = [words[0] for words in topTenJobTitle]\nx = [words[1] for words in topTenJobTitle]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 10 Job Title\", ylabel = \"Occurence of the Top 10 Job Title\")","3ebdee3c":"uniequeJobTitle = []\ntopTenJobTitle = []\nfor key, val in dic.items():\n    findTop(topTenJobTitle, key, val, 11)\n    if val == 1:\n        uniequeJobTitle.append(key)\nx_pos = [i for i in range(10)]\nnums = [words[0] for words in topTenJobTitle[1:11]]\nx = [words[1] for words in topTenJobTitle[1:11]]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 10 Job Title\", ylabel = \"Occurence of the Top 10 Job Title\")","bc5379f9":"keywords = {}\nwordFilter = [\"for\", \"in\", \"opening\", \"\"]\nfor key, val in dic.items():\n    for sub in key.split():\n        if sub in \"~!@#$%^&*()-=+~\\|]}[{';: \/?.>,<.\" or sub.lower() in wordFilter:\n            continue\n        keywords[sub] = keywords.get(sub, 0) + val\nprint(\"Number of keywords\", len(keywords))","1094268c":"topTwentyKeywords = []\nfor key, val in keywords.items():\n    findTop(topTwentyKeywords, key, val, 20)\nx_pos = [i for i in range(len(topTwentyKeywords))]\nnums = [words[0] for words in topTwentyKeywords]\nx = [words[1] for words in topTwentyKeywords]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 20 Keywords\", ylabel = \"Occurence of the top 20 keywords in Job Title\")","6fccbae3":"jobTypeInUrgent = {}\ncounter = 0\nfor index, job in data_df.iterrows():\n    if job['Job Title'].lower().find(\"urgent\") >= 0 and job['Role Category']:\n        jobTypeInUrgent[job['Role Category']] = jobTypeInUrgent.get(job['Role Category'], 0) + 1\n        \ntopTwentyJobInUrgent = []\nfor key, val in jobTypeInUrgent.items():\n    findTop(topTwentyJobInUrgent, key, val, 10)\n\nx_pos = [i for i in range(len(topTwentyJobInUrgent))]\nnums = [words[0] for words in topTwentyJobInUrgent]\nx = [words[1] for words in topTwentyJobInUrgent]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 20 Urgent Roles\", ylabel = \"Occurence of the top 20 Urgent Role\")","2f08ea9f":"x","d4577001":"## Industry & Geo Distribution\n### 1. How does job distribution vary according to each industry?","7f204f8c":"### 2. Map locations to states\nMapping strategy: map locations to state -> sum up jobs for each state -> plot on the map\n#### 1). map loations to state\nIn order to map locations that includes, cities, towns, and states, we a dataset that tell us which state these locations belong to.","4dbc3531":"### 8. Let's see what are the top 10 key skills in Internet, Ecommerce industry\u00b6","a2c656e1":"#### 2). Location Information Cleaning \nAfter inspecting the location data in data frame, I decide to delete everything in the \"()\" because they are location included in the preceding term (Ex:Delhi (Bhikaji Cama) )","b57b613f":"## Job Experience","454138c0":"### 3. Let's see what are the top 10 key skills in BPO Call Center industry","596fab6b":"> #### 2). Is there any missing data?","9ee92b2e":"### 1. Load Data","ff950dac":"## Industry & Experience\n### 1. How do different industries relate to experience requirement?\n#### 1). Newbie Recruitment","3440234e":"#### 3). Let's check the pattern and frequency of the missing","e093bcd2":"#### We see that there're many entry is overlapped with one another. I'd like to set them into 4 categories<br>0-1 -> Newbie <br>1-5 -> Semiprofessional<br> 5-10 -> Professional<br>10-?  Expert\n### 1. Create a new column for \"Experience Categories\"","669b2fcd":"#### 4). How many data are missing in each column?","3d13a719":"## Job Salary","370230ff":"## Skills for Top 10 Industries","998dab1c":"We can see that Programming & Design has the highest demands and there's still a lot of needs on voice people.\nI was suprised that teacher is also in top twenty urgent roles.","4696f91e":"Job seekers may take these as a reference when thinking of moving from one place to another to pursue a career in specific industires\nOf course, it is clear that Maharashtra the most opportunities. Other factors, such as living costs, living environment and salary should also be considered.","58c1c0d6":"### 6. Let's see what are the top 10 key skills in Medical, Healthcare, Hospitals industry\u00b6","ee103ca4":"#### 4). Find unmatched cities between naukri job data and city_state data and create another mapping relation","66dd33bd":"# Overview","3c1902cc":"### 7. Let's see what are the top 10 key skills in Strategy, Management Consulting Firms industry\u00b6","49156f85":"### 2. Sum up location for each state","e19a958d":"I have saved all unmatched locations into a file so that it looks cleaner and compact in the code","664d94b8":"### 2. Let's see what are the top 10 key skills in Recuitment industry","55768b1b":"Pie charts tell us that jobs opportunites provided by each industry at 4 experience levels. As IT industry provides more job opportunities, it is not quite useful if we want to know whether some industries prefer semiprofessal over others or reverse.\n### 2. Let's look at recruitment patterns in each industry\n#### 1). Merge data","b5d2c0fa":"#### 2). Convert Nan to 0 and label correct name for columns and check dataset","fe6269a9":"### 3. Plot the job info on the india map","f1504a95":"### 2. Data wrangling","3fc9533b":"As the \"IT-Software \/ Software Services\" is the same as \"IT-Software, Software Services\" and \"Recruitment \/ Staffing\" is the same as \"Recruitment , Staffing\" , let's first merge two data","3cca022f":"### 2. Let's map the \"Job Experience Required\" to \"Experience Categories\" according to the categories I created above\nNote that 1-7 will be classified as both semiprofessional and professional","14376e69":"Note: there're multiple industries whose recruitment percent may be the same","1cdc63ab":"### 1. Let's see what are the top 10 key skills in IT industry\u00b6","445b9ebf":"Great! Now, let's see how many jobs are in each category","d606ee48":"# Visualize Jobs Market on India Map\u00b6","06701178":"We can see that our cleaning is successful. These location information can not be mapped to states on india map\u00b6","90195714":"### 9. Let's see what are the top 10 key skills in Meida, Intertainment, Internet industry","9b80f547":"#### 4). Expert Recruitment","63d4ce20":"#### 2). Find unmatched states between two dataset","1b80b8b3":"#### 3). Professional Recruitment","3ed23b26":"Job searching is one of the biggest concern for many people. It is important to know job market in general and understand the industry and role that you are interested in so that you can better prepare for entering an new industry or job-hopping. In this project, I will first investigate job market geographically, second experience requirement and last key skills requirement, industry wise.","ec7edbdb":"#### 2). Semiprofessional Recruitment","71006737":"### IT industry is definitely the most popular and needed jobs in India. I hope this analysis provides sufficient information on location, skill set requirements, experience requirements, etc, that may help job seekers to pursue professional interests.","ee70440a":"## Preparation","c7980fd4":"### 2. Keywords in job title","d717686d":"As most of the information is not disclosed, we will not further investigate on these","1ba8c803":"### 4. Let's see what are the top 10 key skills in Banking, Finanacial Services, Broking industry\u00b6","03a240df":"#### 5). Drop missing data","ec4a9bd5":"> ### 1. Get a india map! We will visualize the number of jobs in the India Map.\nThere are 4000 cities and towns in India and it would be too messy to visualize each of them on the map. Therefore, I choose to visualize job market in 28 states and 8 union territories in India\u00b6","0073ab4e":"## Job Title\n### 1. Let's see the number of different type of Job Title","26a9446b":"Note: As some jobs is available for two or more experience categories, total number of jobs may increase for each industry\n#### 4). Let's plot the recruitment pattern for top ten industries\u00b6","0c8898ca":"OK\uff0csome recruiters put the industry into the job. Let's take IT industry out.","ac61e900":"#### 3). Convert number to percentage in order to find out which industry prefer professional, semiprofessional or newbie. ","df96457a":"We can see that India job opportunities was not evenly dstributed. Some areas have way more jobs than other areas. Maharashtra,  Karnataka, Uttar Pradesh are the top 3 states that provide job opportunities","7e437c7d":"#### 3). Let's creat a mapping between unmatched names in two datasets","716035c9":"#### 1). What's the data type in each column?","3c102e2c":"### 10. Let's see what are the top 10 key skills in Travel , Hotels , Restuarants , Airlines , Railways industry","a353b329":"### 5. Let's see what are the top 10 key skills in Education, Teaching, Training industry","13fb7baf":"### 3. \"Urgent\" stands for job that needs people immediately. Let's find out what kind of job is urgent and where these jobs are.","2951e40a":"Many company needs semiprofessional and professional. Meanwhile, newbie is also welcome. However, experts is not in urgent for many company."}}