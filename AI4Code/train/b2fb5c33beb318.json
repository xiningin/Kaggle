{"cell_type":{"2c29022b":"code","1956742c":"code","adcfb1c1":"code","c86259d6":"code","27e15695":"code","70e15ead":"code","7d4256c2":"code","1899c883":"code","82f9bd2b":"code","5c60751a":"code","f000c92f":"markdown","87807e83":"markdown"},"source":{"2c29022b":"import numpy as np # linear algebra\nimport os # accessing directory structure","1956742c":"x = []\ny = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        if 'x_data' in file:\n            # load data as text and reshape\n            x = np.loadtxt(file).reshape(2480, 20, 100)\n            print('successfully loaded: {}'.format(file))\n        elif 'y_data' in file:\n            # load data as text and reshape\n            y = np.loadtxt(file).reshape(2480, 20)\n            print('successfully loaded: {}'.format(file))\n            ","adcfb1c1":"print(x.shape)\nprint(y.shape)","c86259d6":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)","27e15695":"from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","70e15ead":"model = Sequential()\nmodel.add(BatchNormalization(input_shape=x.shape[1:]))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(20, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])\nmodel.summary()","7d4256c2":"model.fit(x_train, y_train, epochs=200, validation_split=0.2)","1899c883":"def self_test(model, x, y):\n    p = model.predict(x)\n    right = 0\n    wrong = 0\n    for i in range(len(p)):\n        m = p[i].max()\n        pred_winner = 1\n        real_winner = 1\n        for ii in p[i]:\n            if ii == m:\n                break\n            pred_winner+=1  \n        for ii in y[i]:\n            if ii == 1:\n                break\n            real_winner+=1\n        if real_winner == pred_winner:\n            right+=1\n        else:\n            wrong+=1\n    print('correct inferences: {}'.format(right))\n    print('incorrect inferences: {}'.format(wrong))\n    print('accuracy: {}'.format(right \/ (right + wrong)))","82f9bd2b":"model.evaluate(x_test, y_test)","5c60751a":"self_test(model, x_test, y_test)","f000c92f":"## Conclusion\nfrom this data and model we can achieve 51% accuracy meaning for every 2 races we will correctly predict 1 and incorrectly predict 1.\n\nlets see what you can do.. hopefully better :)","87807e83":"## Introduction\nthis dataset contains 2480 greyhound races scraped from the web, the x data should be reshaped to (2480, 20, 100) when loaded and y data should be reshaped to (2480, 20)\n\ny data is the one-hot encoded representation of the winner of the race and there is no placing data ( who came second, third and fourth)\n\nUsing the example below you can get an idea on how to read and work with the data contained in this set. I have made this data public in an attempt to get a higher precision accuracy."}}