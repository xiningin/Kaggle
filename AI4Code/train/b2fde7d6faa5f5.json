{"cell_type":{"42db0cf9":"code","b967fbb5":"code","ea2c6df6":"code","dfa79995":"code","3afbfc4a":"code","669a7967":"code","47380bf4":"code","74e8f35a":"code","b4c067a3":"code","44c49581":"code","27021e56":"code","b35be0cc":"code","baf96067":"code","4eb9e1af":"code","9271756c":"code","f8f893c5":"code","f20a2f01":"code","10c08cef":"code","dad8c239":"code","65173fc3":"code","a86b1bd7":"code","d790859f":"code","9c5e818c":"code","df188f66":"code","8ef4fbe6":"code","546354b9":"code","aba05946":"code","bf58bbea":"code","1046c42c":"code","0c1eb6e0":"code","1b76cf89":"markdown","3989c18d":"markdown","e41e8472":"markdown","3ee56762":"markdown","f2edd356":"markdown","ab26022d":"markdown"},"source":{"42db0cf9":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b967fbb5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go","ea2c6df6":"df_train = pd.read_csv('\/kaggle\/input\/train.csv')\ndf_sample = pd.read_csv('\/kaggle\/input\/submission.csv')","dfa79995":"df_train.columns","3afbfc4a":"df_train.isnull().sum()","669a7967":"# Replacing all the Province_State that are null by the Country_Region values\ndf_train.Province_State.fillna(df_train.Country_Region, inplace=True)\n\ndf_train.County.fillna(df_train.Province_State, inplace=True)\n\ndf_train.isnull().sum()\ndf_train.columns\n\n# taking care of categorical values from train set\n# we can also use labelencoder for date column\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf_train['County'] = labelencoder.fit_transform(df_train['County'])\ndf_train['Province_State'] = labelencoder.fit_transform(df_train['Province_State'])\ndf_train['Country_Region'] = labelencoder.fit_transform(df_train['Country_Region'])\ndf_train['Target'] = labelencoder.fit_transform(df_train['Target'])\n# df_train['Date'] = labelencoder.fit_transform(df_train['Date'])","47380bf4":"#taking care of the date column\ndf_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)\n\ndf_train.loc[:, 'Date'] = df_train.Date.dt.strftime(\"%Y%m%d\")\ndf_train.loc[:, 'Date'] = df_train['Date'].astype(int)","74e8f35a":"df_train.columns","b4c067a3":"# splitting the dataset for training and testing\nfrom sklearn.model_selection import train_test_split\n\nX = df_train.iloc[:, [7, 8]].values\ny = df_train.iloc[:, [8]].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=0)\n\ny_train = np.ravel(y_train)","44c49581":"# Fitting Random Forest Regression to the dataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_jobs=-1)\nestimators = 100\nmodel.set_params(n_estimators=estimators)\n\nscores = []\n\npipeline = Pipeline([('scaler2' , StandardScaler()),\n                        ('RandomForestRegressor: ', model)])\npipeline.fit(X_train , y_train)\ny_pred = pipeline.predict(X_test)\n\npipeline.fit(X_train, y_train)\nscores.append(pipeline.score(X_test, y_test))","27021e56":"y_pred","b35be0cc":"from sklearn.metrics import explained_variance_score , max_error ,mean_absolute_error , mean_squared_error\nfrom math import sqrt\nprint('variance_score:',explained_variance_score(y_test, y_pred))\nprint('max_error:',max_error(y_test, y_pred))\nprint('mean_absolute_error score:',mean_absolute_error(y_test, y_pred))\nprint('mean_squared_error score:',mean_squared_error(y_test, y_pred))\nprint('root mean_squared_error:',sqrt(mean_squared_error(y_test,y_pred)))\n ","baf96067":"#fitting the decision tree regression to the dataset\n\nfrom sklearn.tree import DecisionTreeRegressor\nregressor_new = DecisionTreeRegressor(random_state=0)\nregressor_new.fit(X_train,y_train)","4eb9e1af":"y_pred = regressor_new.predict(X_test)","9271756c":"from sklearn.metrics import explained_variance_score , max_error ,mean_absolute_error , mean_squared_error\nfrom math import sqrt\nprint('variance_score:',explained_variance_score(y_test, y_pred))\nprint('max_error:',max_error(y_test, y_pred))\nprint('mean_absolute_error score:',mean_absolute_error(y_test, y_pred))\nprint('mean_squared_error score:',mean_squared_error(y_test, y_pred))\nprint('root mean_squared_error:',sqrt(mean_squared_error(y_test,y_pred)))","f8f893c5":"df_test = pd.read_csv('\/kaggle\/input\/test.csv')","f20a2f01":"df_test.isnull().sum()","10c08cef":"df_test.columns","dad8c239":"# Replacing all the Province_State that are null by the Country_Region values\ndf_test.Province_State.fillna(df_test.Country_Region, inplace=True)\ndf_test.County.fillna(df_test.Province_State, inplace=True)\n\n# taking care of categorical values from train set\n# we can also use labelencoder for date column\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf_test['County'] = labelencoder.fit_transform(df_test['County'])\ndf_test['Province_State'] = labelencoder.fit_transform(df_test['Province_State'])\ndf_test['Country_Region'] = labelencoder.fit_transform(df_test['Country_Region'])\ndf_test['Target'] = labelencoder.fit_transform(df_test['Target'])\n","65173fc3":"#taking care of the date column\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)\n\ndf_test.loc[:, 'Date'] = df_test.Date.dt.strftime(\"%Y%m%d\")\ndf_test.loc[:, 'Date'] = df_test['Date'].astype(int)\n","a86b1bd7":"df_test","d790859f":"df_test.columns","9c5e818c":"df_test.drop(['ForecastId', 'County', 'Province_State', 'Country_Region','Target','Date'], axis = 1 , inplace = True)","df188f66":"df_test.index.name = 'Id'\ndf_test","8ef4fbe6":"y_pred2 = pipeline.predict(df_test)","546354b9":"pred_list = [int(x) for x in y_pred2]\n\noutput = pd.DataFrame({'Id': df_test.index, 'TargetValue': pred_list})\nprint(output)","aba05946":"a=output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['Id'])['TargetValue'].quantile(q=0.95).reset_index()","bf58bbea":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\na","1046c42c":"a['Id'] =a['Id']+ 1\na","0c1eb6e0":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","1b76cf89":"**hii everyone i don't know much about data science but this is my first project where train and test dataset have different column size so if there is any mistake kindly tell me.**","3989c18d":"# **applying decision tree**","e41e8472":"# **if you like it please do upvote and if you find mistake then please inform me**","3ee56762":"# **applying random forest**","f2edd356":"# **preprocessing the dataset**","ab26022d":"# **testing on whole new dataset**"}}