{"cell_type":{"02aaed76":"code","d062f94f":"code","1a07171d":"code","883e31c7":"code","b3b8a97a":"code","d9d22eaa":"code","17b3e6cb":"code","95b735fc":"code","4bdde2ca":"code","6eeb45e2":"code","4fcb3e70":"code","cf1828d1":"code","cb8dc134":"code","d4781dd2":"code","b9040e45":"code","6baec615":"code","00705716":"code","4b0d7d98":"code","f934f140":"code","8581df5b":"code","27ae0857":"code","9daacb75":"code","fcf1efef":"code","d59181e9":"code","b8d7cd50":"code","525aa2ec":"code","e3ecc9c9":"code","4862b666":"code","439e7800":"code","50840e0d":"code","32d8406d":"code","eff43894":"code","8004b25c":"code","c511a6df":"code","2c6ca240":"code","7a7d58ae":"code","ce277eef":"code","91c5afa1":"code","274e31e1":"code","f32c9106":"code","2d446f37":"code","b7902fad":"code","cecd3a89":"code","3aa0cb04":"code","c55b9410":"code","d99d1e5d":"code","fd7d30f8":"code","7f2299b0":"code","ecbb0cec":"code","0c77e028":"code","c513801c":"code","4d45cacf":"code","aac1736e":"code","b9aa1e6c":"code","e4214261":"code","46c2ae2f":"code","e54f82af":"code","22a5536f":"code","9e26299d":"code","27bdd163":"code","5b979f72":"code","ad1e2852":"code","59db09a9":"code","0ff22bb0":"code","cb536a31":"code","6c2a95b5":"code","a526a2df":"code","45917f95":"code","6db0e4ec":"code","18cdaee7":"code","6db7e76a":"code","ca6ec6a9":"code","8277b110":"code","401be990":"code","4738e3ee":"code","579078e6":"code","9794f867":"code","3f9cce84":"code","5651040b":"code","e5eee03a":"code","6aacae79":"code","d70d01b8":"code","de7c505c":"code","d7f246c8":"code","13a8d57e":"code","3b8a2562":"code","8c7b6653":"code","52106fde":"code","fc9b996d":"markdown","9823c467":"markdown","0d130311":"markdown","fe44ef10":"markdown","add597b3":"markdown","400bb0b2":"markdown","f8f50cd6":"markdown","e32950ba":"markdown","f6078c38":"markdown","0d2b2c29":"markdown","728283a5":"markdown","3ee2114e":"markdown","cfd082e7":"markdown","c6a06681":"markdown","b3712a92":"markdown","de56e2e1":"markdown","353f28ee":"markdown","8c11c8ca":"markdown","f48461c2":"markdown","16a3326e":"markdown","ae17ec77":"markdown","d7c4b7fb":"markdown","17929d24":"markdown","463028a3":"markdown","8311974f":"markdown"},"source":{"02aaed76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d062f94f":"data = pd.read_csv('..\/input\/master.csv')","1a07171d":"data.info()","883e31c7":"data.corr()","b3b8a97a":"f,ax = plt.subplots(figsize=(13, 13))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","d9d22eaa":"data.head(10)","17b3e6cb":"data.columns","95b735fc":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.year.plot(kind = 'line', color = 'r',label = 'year',linewidth=1,alpha = 0.5,grid = True,linestyle = '-.')\ndata.suicides_no.plot(color = 'g',label = 'suicides_no',linewidth=1, alpha = 0.5,grid = True,linestyle = ':')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","4bdde2ca":"# Line Plot \n# x = year, y = suicides_no\ndata.plot(kind='line', x='year', y='suicides_no',alpha = 0.5,color = 'blue', grid = True,linestyle = ':', figsize = (10,8))\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year, suicides_no Scatter Plot')            # title = title of plot","6eeb45e2":"# Scatter Plot \n# x = year, y = suicides_no\ndata.plot(kind='scatter', x='year', y='suicides_no',alpha = 0.5,color = 'red', figsize = (8,6))\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year suicides_no Scatter Plot')            # title = title of plot","4fcb3e70":"plt.scatter(data.year, data.suicides_no, color = \"red\", alpha = 0.5) # other notation\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year suicides_no Scatter Plot')            # title = title of plot","cf1828d1":"# Histogram\n# bins = number of bar in figure\ndata.year.plot(kind = 'hist',bins = 40,figsize = (6,6))\nplt.show()","cb8dc134":"# clf() = cleans it up again you can start a fresh\ndata.year.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","d4781dd2":"data = pd.read_csv('..\/input\/master.csv') # data import ","b9040e45":"series = data['year']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['suicides_no']]  # data[['Defense']] = data frame\nprint(type(data_frame))","6baec615":"# 1 - Filtering Pandas data frame\nx = data['year']>2014     # There are only 3 pokemons who have higher defense value than 200\ndata[x]","00705716":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['year']>2014, data['suicides_no']>5000 )]","4b0d7d98":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['year']>2014) & (data['suicides_no']>5000)] # other notation","f934f140":"# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value \n# select specific indexes in a column\nfor index,value in data[['year']][47:49].iterrows(): # 47 include, 49 exclude\n    print(index,\" : \",value)","8581df5b":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.suicides_no)\/len(data.suicides_no)\nprint(\"threshold: \", threshold)\ndata[\"suicides_no_level\"] = [\"High\" if i > threshold else \"Low\" for i in data.suicides_no]  # list comprehension\ndata.loc[1450:1460,[\"suicides_no_level\",\"suicides_no\"]] # we will learn loc more detailed later","27ae0857":"data = pd.read_csv('..\/input\/master.csv')\ndata.head()  # head shows first 5 rows","9daacb75":"# tail shows last 5 rows\ndata.tail()","fcf1efef":"# columns gives column names of features\ndata.columns","d59181e9":"# shape gives number of rows and columns in a tuble\ndata.shape","b8d7cd50":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","525aa2ec":"# For example lets look frequency of sex types\nprint(data['sex'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 13910 male, 13910 female  ","e3ecc9c9":"data.describe() #ignore null entries","4862b666":"# For example: comparison of generation by year\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n# outlier data is not seen in this analysis\ndata.boxplot(column='year',by = 'generation', figsize = (10,8)) ","439e7800":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","50840e0d":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'country', value_vars= ['year','suicides_no'])\nmelted","32d8406d":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","eff43894":"data1 = data['country'].head()\ndata2= data['year'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in row\nconc_data_col","8004b25c":"data.dtypes","c511a6df":"# lets convert object(str) to categorical\ndata['sex'] = data['sex'].astype('category')","2c6ca240":"data.dtypes","7a7d58ae":"# Lets look at does master data have nan value\ndata.info()","ce277eef":"# Lets chech HDI for year\ndata[\"HDI for year\"].value_counts(dropna =False)\n# As you can see, there are 19456 NAN value","91c5afa1":"# Lets drop NaN values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"HDI for year\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","274e31e1":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","f32c9106":"assert  data['HDI for year'].notnull().all() # returns nothing because we drop NaN values","2d446f37":"data[\"HDI for year\"].fillna('empty',inplace = True)","b7902fad":"assert  data['HDI for year'].notnull().all() # returns nothing because we do not have nan values","cecd3a89":"country = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","3aa0cb04":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","c55b9410":"df[\"income\"] = 0 #Broadcasting entire column\ndf","d99d1e5d":"# Plotting all data \ndata1 = data.loc[:,[\"suicides_no\",\"population\",\"gdp_per_capita ($)\"]]\ndata1.plot()\n# it is confusing","fd7d30f8":"data1.plot(subplots = True, figsize=(10,8))\nplt.show()","7f2299b0":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"suicides_no\",y = \"gdp_per_capita ($)\", figsize=(10,8))\nplt.show()","ecbb0cec":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True)","0c77e028":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","c513801c":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","4d45cacf":"data.head() # index of our data is 012345","aac1736e":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\") # index of our data is date\ndata2 ","b9aa1e6c":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","e4214261":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","46c2ae2f":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","e54f82af":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","22a5536f":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","9e26299d":"# read data\ndata = pd.read_csv('..\/input\/master.csv')\ndata.head()","27bdd163":"# indexing using square brackets\ndata[\"generation\"][0]","5b979f72":"# using column attribute and row label\ndata.generation[0] # a different method","ad1e2852":"# using loc accessor\ndata.loc[0,[\"generation\"]]","59db09a9":"# Selecting only some columns\ndata[[\"age\",\"generation\"]]","0ff22bb0":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"generation\"]))     # series\nprint(type(data[[\"generation\"]]))   # data frames","cb536a31":"# Slicing and indexing series\ndata.loc[1:10,\"age\":\"population\"]   # 10 and \"Defense\" are inclusive","6c2a95b5":"# Reverse slicing \ndata.loc[10:1:-1,\"age\":\"population\"] ","a526a2df":"# From something to end\ndata.loc[0:10,\"country-year\":] ","45917f95":"boolean = data.year > 2000\ndata[boolean]","6db0e4ec":"# Combining filters\nfirst_filter = data.year > 2014\nsecond_filter = data.suicides_no > 5000\ndata[first_filter & second_filter]","18cdaee7":"# Filtering column based others\ndata.year[data.suicides_no>20000]","6db7e76a":"# Plain python functions\ndef div(n):\n    return n\/2\ndata.suicides_no.apply(div)","ca6ec6a9":"# Or we can use lambda function\ndata.suicides_no.apply(lambda n : n\/2)","8277b110":"# Defining column using other columns\ndata[\"total_power\"] = data.population + data.suicides_no\ndata.head()","401be990":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","4738e3ee":"# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,27920,1)\ndata3.head()","579078e6":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/master.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","9794f867":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"year\",\"generation\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","3f9cce84":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","5651040b":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","e5eee03a":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","6aacae79":"# level determines indexes\ndf1.unstack(level=0)","d70d01b8":"df1.unstack(level=1)","de7c505c":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","d7f246c8":"df","13a8d57e":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","3b8a2562":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","8c7b6653":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","52106fde":"df.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","fc9b996d":"**INDEXING PANDAS TIME SERIES**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","9823c467":"### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n\n**outliers: the value that is considerably higher or lower from rest of the data**\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n\n**We will use describe() method. Describe method includes:**\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n**What is quantile?**\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","0d130311":"**BUILDING DATA FRAMES FROM SCRATCH**\n\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","fe44ef10":"**MELTING DATA FRAMES**\n\n* Reverse of pivoting","add597b3":"**RESAMPLING PANDAS TIME SERIES**\n\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","400bb0b2":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklearn(we will learn later)","f8f50cd6":"**INDEX OBJECTS AND LABELED DATA**\n\nindex: sequence of label","e32950ba":"**PYTHON DATA SCIENCE TOOLBOX**\n\n**In this part, you learn:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","f6078c38":"** CONCATENATING DATA**\n \nWe can concatenate two dataframe ","0d2b2c29":"**MANIPULATING DATA FRAMES WITH PANDAS**\n\nINDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","728283a5":"**CATEGORICALS AND GROUPBY**","3ee2114e":"**PANDAS**\nWhat we need to know about pandas?\n* CSV: comma - separated values","cfd082e7":"**PIVOTING DATA FRAMES**\n\n* pivoting: reshape tool","c6a06681":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","b3712a92":"**PANDAS FOUNDATION **\n\n**REV\u0130EW of PANDAS**\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy","de56e2e1":"**IN THIS PART YOU LEARN:**\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n*  basic pandas features like filtering that is actually something always used and main for being data scientist\n*  for loops","353f28ee":"**MATPLOTLIB**\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle  ","8c11c8ca":"**STACKING and UNSTACKING DATAFRAME**\n\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","f48461c2":"**FILTERING DATA FRAMES**\n\nCreating boolean series\nCombining filters\nFiltering column based others","16a3326e":"**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","ae17ec77":"**VISUAL EXPLORATORY DATA ANALYSIS**\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","d7c4b7fb":"**HIERARCHICAL INDEXING**\n\n* Setting indexing","17929d24":"**TIDY DATA**\n\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.","463028a3":"**TRANSFORMING DATA**\n\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","8311974f":"**DIAGNOSE DATA for CLEANING**\n\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data"}}