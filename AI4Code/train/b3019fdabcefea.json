{"cell_type":{"6513aa0a":"code","38ea24ee":"code","78e732a3":"code","fdff0521":"code","d5ca44ba":"code","ae57daff":"code","83d06006":"code","3eb99479":"code","608aa299":"code","fa9d1c56":"code","d1e9edbf":"code","eb14065e":"code","ce7fb190":"code","bab4228e":"code","d8eb1b93":"code","6a21346b":"code","735d96d7":"code","c51fe7f2":"code","f25385b5":"code","4b3296f7":"code","328b17dd":"code","2f3811cc":"code","d0602bb9":"code","e984d143":"code","ddc4a423":"code","6269bccd":"code","32fb9462":"code","07aa3e50":"code","03b404b0":"code","cf0697fe":"code","9457bee7":"code","0fb76665":"code","e1275e93":"code","9848736a":"code","9ee10ba1":"code","42241cbe":"code","d32053b9":"code","0db735aa":"code","91656c8b":"code","8f5ccdf6":"code","3a69a058":"code","65dff9fe":"code","9aaf0d76":"code","84e4e0e8":"code","cb18b95e":"code","93a67a37":"code","c0b90739":"code","ae502d83":"code","c6ddb256":"code","b35d8156":"code","b64e5f55":"code","cb105edb":"code","2c6fd478":"code","69eba522":"code","c147f41f":"code","32a96669":"code","d8d3a30d":"code","bf8a8268":"code","b0f115df":"code","c12406b3":"code","cff240b2":"code","f7a621be":"code","ed25a322":"code","d7d7eab1":"code","d78029cd":"code","ad4b037f":"code","a3b679d6":"code","510b02d8":"code","27b6c557":"code","2ca24f1d":"code","f18b24c3":"code","fca21d46":"code","897050c0":"code","901431eb":"code","9b789a6a":"code","1a0615ff":"code","60a278c5":"code","f9b3d8e3":"code","653ccc51":"code","6cb227f1":"code","b7613da0":"code","7217d1b5":"code","4859112d":"code","5c02dde8":"code","e9faef15":"code","923fb49a":"code","e67b81fe":"code","96482dd2":"code","1d879695":"code","a911c940":"code","148a35f9":"code","0449d438":"code","516eefc2":"code","9c889e4a":"code","c482af39":"code","4182e2a5":"code","4293345a":"code","0c704209":"code","3bb0d76c":"code","0cecac53":"code","45cc81f8":"code","8e1435b8":"code","83fe4922":"code","f3277877":"code","8d486b75":"code","ff0b1ec1":"code","7aa257fb":"code","fd780c6f":"code","21abc7d9":"code","ea185198":"code","06424925":"code","083aeede":"code","d744e5ed":"code","0f1a0eb3":"code","5e10ceeb":"code","cde1694e":"code","07bf44c2":"code","ce5ecb8e":"code","b99e40ab":"code","30121bd8":"code","979ef0dc":"code","c18cbd8c":"code","3a18505a":"code","f8cef653":"code","6c04ccd7":"code","cca2a0b6":"code","18093d04":"code","1ac0e608":"code","987ea91e":"code","6b93fa68":"code","2e8b8e06":"markdown","97e24deb":"markdown","c55f9e9a":"markdown","e7b1622f":"markdown","01ab9332":"markdown","f5f24ab4":"markdown","eeb44331":"markdown","9b37a734":"markdown","0af90f33":"markdown","a98bb0ab":"markdown","dfe5fc42":"markdown","f57353e6":"markdown","15e8dd37":"markdown","5666c48b":"markdown","604b7b0d":"markdown","290d9b45":"markdown","c4844d5f":"markdown","e7effa45":"markdown","63c0ad57":"markdown","559b0780":"markdown","87a72c6a":"markdown","c8f7f282":"markdown","bd4f05a4":"markdown","742c5b9c":"markdown"},"source":{"6513aa0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option(\"display.max_columns\",None)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n              \n              \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38ea24ee":"train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","78e732a3":"a=train.shape\nprint(a)","fdff0521":"train.info()","d5ca44ba":"train.describe()","ae57daff":"x=round(100*(train.isnull().sum()\/len(train)),2)\nx=x.sort_values(ascending=False)\nprint(x)","83d06006":"list(100*(train.isnull().sum()\/len(train)))","3eb99479":"train.drop(train.loc[:,list(round(100*(train.isnull().sum()\/len(train)), 2)>70)].columns, 1,inplace=True)\ntrain.head()","608aa299":"round(100*(train.isnull().sum()\/len(train)),2).sort_values(ascending=False)\n","fa9d1c56":"import matplotlib.pyplot as plt, seaborn as sns\n%matplotlib inline","d1e9edbf":"sns.distplot(train.Age)\nplt.show()","eb14065e":"train[\"Age\"]=train.Age.replace(np.nan,train.Age.mean())","ce7fb190":"round(100*(train.isnull().sum()\/len(train)),2).sort_values(ascending=False)","bab4228e":"train=train.dropna()\nround(100*(train.isnull().sum()\/len(train)),2).sort_values(ascending=False)","d8eb1b93":"f=round(((a[0]-train.shape[0])\/a[0])*100,2)\nprint(\"{} percent of data is removed to clean the dataset\".format(f))","6a21346b":"train.info()","735d96d7":"tr_data=train[[\"Survived\",\"Age\",\"Fare\"]]\nsns.pairplot(tr_data,diag_kind=\"kde\")\nplt.show()\n","c51fe7f2":"sns.countplot(x=\"Sex\",hue=\"Survived\",data=train)\nplt.show()","f25385b5":"sns.countplot(x=\"Pclass\",hue=\"Survived\",data=train)\nplt.show()","4b3296f7":"sns.countplot(x=\"SibSp\",hue=\"Survived\",data=train)\nplt.xticks(rotation=90)\nplt.show()","328b17dd":"sns.countplot(x=\"Parch\",hue=\"Survived\",data=train)\nplt.xticks(rotation=0)\nplt.show()","2f3811cc":"sns.distplot(train[\"Fare\"])\nplt.xticks(rotation=90)\nplt.show()","d0602bb9":"sns.countplot(x=\"Embarked\",hue=\"Survived\",data=train)\nplt.xticks(rotation=0)\nplt.show()","e984d143":"sns.heatmap(train.corr(),annot=True)","ddc4a423":"train.head()","6269bccd":"train.drop([\"PassengerId\",\"Ticket\",\"Name\"],1,inplace=True)","32fb9462":"train.head()","07aa3e50":"train_dum=pd.get_dummies(train.Pclass)\ntrain_dum.head()","03b404b0":"train=pd.concat([train,train_dum],axis=1)\ntrain.head()","cf0697fe":"train_dum=pd.get_dummies(train.Sex)\ntrain_dum.head()","9457bee7":"train=pd.concat([train,train_dum],axis=1)\ntrain.head()","0fb76665":"train_dum=pd.get_dummies(train.Embarked)\ntrain_dum.head()","e1275e93":"train=pd.concat([train,train_dum],axis=1)\ntrain.head()","9848736a":"train.drop([\"Pclass\",\"Sex\",\"Embarked\",3,\"male\",\"S\"],axis=1,inplace=True)","9ee10ba1":"train.head()","42241cbe":"from sklearn.model_selection import train_test_split","d32053b9":"y=train.pop(\"Survived\")\ny.head()","0db735aa":"X=train\nX.head()","91656c8b":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=None)","8f5ccdf6":"from sklearn.preprocessing import StandardScaler","3a69a058":"scaler=StandardScaler()\nX_train[[\"Age\",\"Fare\"]]=scaler.fit_transform(X_train[[\"Age\",\"Fare\"]])\nX_train.head()","65dff9fe":"import statsmodels.api as sm","9aaf0d76":"X_train_sm=sm.add_constant(X_train)\nlogm1=sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nlogm1.fit().summary()","84e4e0e8":"from sklearn.linear_model import LogisticRegression","cb18b95e":"lr=LogisticRegression()\nfrom sklearn.feature_selection import RFE","93a67a37":"rfe=RFE(lr,7)\nrfe=rfe.fit(X_train,y_train)\nrfe.support_","c0b90739":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","ae502d83":"col=X_train.columns[rfe.support_]","c6ddb256":"col","b35d8156":"X_train[col].head()","b64e5f55":"X_train.columns[~rfe.support_]","cb105edb":"X_train_sm=sm.add_constant(X_train[col])\nlogm2=sm.GLM(y_train,X_train_sm,family=sm.families.Binomial())\nres=logm2.fit()\nres.summary()","2c6fd478":"from statsmodels.stats.outliers_influence import variance_inflation_factor","69eba522":"vif=pd.DataFrame()\nvif[\"Features\"]=X_train.columns\nvif[\"VIF\"]=[variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\nvif[\"VIF\"]=round(vif[\"VIF\"],2)\nvif=vif.sort_values(by = \"VIF\", ascending = False)\nvif","c147f41f":"col1=col.drop([\"Q\"])\ncol1","32a96669":"X_train[col1].head()","d8d3a30d":"X_train_sm=sm.add_constant(X_train[col1])\nlogm3=sm.GLM(y_train,X_train_sm, family=sm.families.Binomial())\nres1=logm3.fit()\nres1.summary()","bf8a8268":"vif=pd.DataFrame()\nvif[\"Features\"]=X_train[col1].columns\nvif[\"VIF\"]=[variance_inflation_factor(X_train.values,i) for i in range(X_train[col1].shape[1])]\nvif[\"VIF\"]=round(vif[\"VIF\"],2)\nvif=vif.sort_values(by = \"VIF\", ascending = False)\nvif","b0f115df":"col2=col1.drop([\"C\"])","c12406b3":"col2","cff240b2":"X_train_sm=sm.add_constant(X_train[col2])\nlogm4=sm.GLM(y_train,X_train_sm, family=sm.families.Binomial())\nres2=logm4.fit()\nres2.summary()","f7a621be":"vif=pd.DataFrame()\nvif[\"Features\"]=X_train[col2].columns\nvif[\"VIF\"]=[variance_inflation_factor(X_train.values,i) for i in range(X_train[col2].shape[1])]\nvif[\"VIF\"]=round(vif[\"VIF\"],2)\nvif=vif.sort_values(by=\"VIF\",ascending=False)\nvif","ed25a322":"X_train_sm.columns","d7d7eab1":"p=X_train_sm.iloc[:,1:]\np.head()","d78029cd":"sns.heatmap(p.corr(),annot=True)","ad4b037f":"# Getting the predicted values on the train set\ny_train_pred = res2.predict(X_train_sm)\ny_train_pred[:10]","a3b679d6":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","510b02d8":"y_train_pred_final = pd.DataFrame({'survived':y_train.values, 'survived_Prob':y_train_pred})\ny_train_pred_final['Passanger ID'] = y_train.index\ny_train_pred_final.head()","27b6c557":"# Creating new column 'predicted' with 1 if survived_Prob > 0.5 else 0\ny_train_pred_final['predicted'] = y_train_pred_final.survived_Prob.map(lambda x: 1 if x > 0.5 else 0)","2ca24f1d":"y_train_pred_final.head()","f18b24c3":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.feature_selection import SelectFromModel","fca21d46":"confusion = metrics.confusion_matrix(y_train_pred_final.survived, y_train_pred_final.predicted )\nprint(confusion)","897050c0":"print(metrics.accuracy_score(y_train_pred_final.survived, y_train_pred_final.predicted))","901431eb":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","9b789a6a":"# Sensitivity\nTP \/ float(TP+FN)","1a0615ff":"# specificity\nTN \/ float(TN+FP)","60a278c5":"# false postive rate - predicting conversion when lead actually have not converted\nprint(FP\/ float(TN+FP))","f9b3d8e3":"# positive predictive value \nprint (TP \/ float(TP+FP))","653ccc51":"# Negative predictive value\nprint (TN \/ float(TN+ FN))","6cb227f1":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","b7613da0":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.survived, y_train_pred_final.survived_Prob, drop_intermediate = False )","7217d1b5":"draw_roc(y_train_pred_final.survived, y_train_pred_final.survived_Prob)","4859112d":"# create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.survived_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","5c02dde8":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.survived, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","e9faef15":"# plotting accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","923fb49a":"# 0.4 is the optimum point to take it as a cutoff probability.\ny_train_pred_final['final_predicted'] = y_train_pred_final.survived_Prob.map( lambda x: 1 if x > 0.4 else 0)\ny_train_pred_final.head()","e67b81fe":"# Assigning the scores\ny_train_pred_final['Lead_Score'] = y_train_pred_final.survived_Prob.map( lambda x: round(x*100))\ny_train_pred_final.head()","96482dd2":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_train_pred_final.survived, y_train_pred_final.final_predicted)","1d879695":"confusion2 = metrics.confusion_matrix(y_train_pred_final.survived, y_train_pred_final.final_predicted )\nconfusion2","a911c940":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","148a35f9":"# sensitivity of the logistic regression model\nTP \/ float(TP+FN)","0449d438":"# specificity\nTN \/ float(TN+FP)","516eefc2":"# false postive rate - predicting conversion when lead does not have churned\nprint(FP\/ float(TN+FP))","9c889e4a":"# Positive predictive value \nprint (TP \/ float(TP+FP))","c482af39":"# Negative predictive value\nprint (TN \/ float(TN+ FN))","4182e2a5":"#Looking at the confusion matrix again\nconfusion = metrics.confusion_matrix(y_train_pred_final.survived, y_train_pred_final.predicted )\nprint(confusion)","4293345a":"#Precision\n# TP \/ TP + FP\nconfusion[1,1]\/(confusion[0,1]+confusion[1,1])","0c704209":"#Recall\n#TP \/ TP + FN\nconfusion[1,1]\/(confusion[1,0]+confusion[1,1])","3bb0d76c":"# verifying precision and recall score by using sklearn\nprecision_score(y_train_pred_final.survived, y_train_pred_final.predicted)","0cecac53":"recall_score(y_train_pred_final.survived, y_train_pred_final.predicted)","45cc81f8":"y_train_pred_final.survived, y_train_pred_final.predicted","8e1435b8":"p, r, thresholds = precision_recall_curve(y_train_pred_final.survived, y_train_pred_final.survived_Prob)","83fe4922":"plt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","f3277877":"X_test.head()","8d486b75":"X_test[[\"Age\",\"Fare\"]]=scaler.transform(X_test[[\"Age\",\"Fare\"]])\nX_test.head()","ff0b1ec1":"X_test = X_test[col2]\nX_test.head()","7aa257fb":"X_test_sm = sm.add_constant(X_test)","fd780c6f":"y_test_pred = res2.predict(X_test_sm)","21abc7d9":"y_test_pred[:10]","ea185198":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)","06424925":"y_pred_1.head()","083aeede":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)","d744e5ed":"# Putting Prospect ID to index\ny_test_df['Passanger ID'] = y_test_df.index","0f1a0eb3":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)","5e10ceeb":"# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)","cde1694e":"y_pred_final.head()","07bf44c2":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Conversion_Prob'})","ce5ecb8e":"y_pred_final.head()","b99e40ab":"# Rearranging the columns\ny_pred_final = y_pred_final.reindex(['Passanger ID','Survived','Conversion_Prob'], axis=1)","30121bd8":"y_pred_final.head()","979ef0dc":"y_pred_final['Predicted_Conversion'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.42 else 0)","c18cbd8c":"y_pred_final.head()","3a18505a":"# accuracy.\nmetrics.accuracy_score(y_pred_final.Survived, y_pred_final.Predicted_Conversion)","f8cef653":"confusion2 = metrics.confusion_matrix(y_pred_final.Survived, y_pred_final.Predicted_Conversion)\nconfusion2","6c04ccd7":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","cca2a0b6":"# sensitivity\nTP \/ float(TP+FN)","18093d04":"# specificity\nTN \/ float(TN+FP)","1ac0e608":"# precision_score\nprecision_score(y_pred_final.Survived , y_pred_final.Predicted_Conversion)","987ea91e":"#recall score\nrecall_score(y_pred_final.Survived, y_pred_final.Predicted_Conversion)","6b93fa68":"#Top 3 most important features\nsmf=SelectFromModel(LogisticRegression(), threshold=-np.inf,max_features=3)\nsmf.fit(X_train,y_train)\nfeature_idx=smf.get_support()\nfeature_name=X_train.columns[feature_idx]\nfeature_name","2e8b8e06":"# Train Test Split","97e24deb":"*importing train,test and gender_submission datasets***","c55f9e9a":"> using RFE","e7b1622f":"# Precision and Recall","01ab9332":"> highest peoples were on board from low Fare and very less peoples wew from fare more then 200","f5f24ab4":"# Data Preparation","eeb44331":"**Running Training model**","9b37a734":"# Confusion Metrix","0af90f33":"**Introducing Dummy and using one hot encoding******","a98bb0ab":"> Feature Scaling**","dfe5fc42":"# Model Building","f57353e6":"# Finding Optimal Point","15e8dd37":"from Pclass 3 highest people were dead followed by class 2 and 1 ","5666c48b":"### we will drop the values having greater then 70% of null values","604b7b0d":"# Making predictions on the test set","290d9b45":"Servived peoples are decreasing with a downward slope arranged by SibSp number","c4844d5f":"# ****Importing Dataset****","e7effa45":"# Exploratory Data Analytics","63c0ad57":"# Feature Selection","559b0780":"> more Male peoples are died compared to female","87a72c6a":"> highest people were dead from Parch 0 ","c8f7f282":"# Precision and recall tradeoff","bd4f05a4":"> there were more people of age between 20 to 40 ","742c5b9c":"# > Data Cleaning"}}