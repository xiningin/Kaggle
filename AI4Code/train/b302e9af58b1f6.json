{"cell_type":{"e1e28683":"code","7a636cbc":"code","cab42959":"code","8ac6b902":"code","91442e19":"code","2788cd9f":"code","0c903022":"code","a72a2c1f":"code","70596d00":"code","af26ac04":"code","b6785646":"code","72522354":"markdown","65422fca":"markdown","c090b73e":"markdown","6abff3d8":"markdown","febab709":"markdown"},"source":{"e1e28683":"# In case you didn't know, this code here basically\n# enables pandas to be used via the keyword pd\n# (simple terms for explanation!)\nimport pandas as pd","7a636cbc":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","cab42959":"# First, a quick overview of our data:\ntrain_data.head()","8ac6b902":"# Then, we check the size of our data: (891 rows and 12 columns)\ntrain_data.shape","91442e19":"# Now, a quick statistic summary of the data:\n# For obvious reasons, it won't include data for non-numeric features.\ntrain_data.describe()","2788cd9f":"# We can do the same thing to our test data:\n# Note that it will contain one less feature - since we're using it to predict, it won't contain the Survived column.\nprint(test_data.shape)\ntest_data.head()","0c903022":"y = train_data.Survived\nX = train_data.drop(['Survived'], axis=1)\nX_test = test_data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","a72a2c1f":"from sklearn.svm import SVC\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\n\nnum_cols = [cname for cname in X_train if X_train[cname].dtype in ['int64', 'float64']]\ncat_cols = [cname for cname in X_train if X_train[cname].dtype == \"object\"]\n\nnumerical_transformer = SimpleImputer(strategy='constant')\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')) \n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('cat', categorical_transformer, cat_cols)\n    ])\n\nmodel = SVC(kernel='linear', random_state=0)\n","70596d00":"def compareMAE(model):\n    my_pipeline = Pipeline(steps=[(),())])\n","af26ac04":"# add multiple models and comparison between them\n# add GridSearchCV stuff as well\nfrom sklearn.metrics import mean_absolute_error\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\nmy_pipeline.fit(X_train, y_train)\npredictions = my_pipeline.predict(X_valid)\nmean_absolute_error(y_valid, predictions)\nfinal_submission = my_pipeline.predict(X_test)","b6785646":"# basics on submissions\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': final_submission})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","72522354":"# Using Titanic Dataset to Learn Stuff!\n#### A quick intro to Machine Learning: Python and Mathematics included!\n---\n\n*by Ricardo Prins*\n\n### Work in Progress! ETA a couple weeks\n\nThe idea of this Notebook is to use the Titanic Dataset to explain certain concepts and tools etc.\n\nThis will be the first in a series of notebooks.\n\n### Contents\n- What is Machine Learning?\n- Types of ML Problems\n- Pandas - Extracting Data 101\n  - Getting data from a file\n  - Training, Validating, Testing\n- Dealing with problems in data\n- Imputers, Encoders, etc.\n- Pipelines\n- It's time to model! Will we be able to save Jack?\n- Next steps (and next notebook as well)\n\nAny suggestions, please reach out to me: prins@tesseractcoding.com\n  ","65422fca":"So, all that was done up there was to allow the notebook to _evoke_ all _pandas_' functionalities. Now, it is time to put that to use.\n\nMost data you'll find on Kaggle is in the .csv(comma separated values) format. What _pandas_ will allow us to do is to get that data and put it in a way that we can read. In other words, it will get that file and _load_ it within something we call a Dataset - the place we use to store data.\n\n_Add section with a brief explanation about splitting data between training, validation and testing_\n\nWith that being said, here's how we use the _read_csv()_ function to obtain data from the .csv files:","c090b73e":"Was it too hard? Now, at this point, what we have are our two files: one, that will contain the data we'll use to train our model, and the test data, to verify our model's accuracy. Let's take a look at what these two files contain:\n\nIf you have problems with statistical concepts, [check this Youtube channel](https:\/\/www.youtube.com\/channel\/UCFrjdcImgcQVyFbK04MBEhA) - this guy is awesome.","6abff3d8":"# Pandas - Extracting Data 101\n\nWell, we have to start from some place, right? Since I don't intend to teach everything related to the Python language in a single notebook (I'd be REALLY presumptuous if I thought I could do it), I'll just assume you know how to Google some of the stuff you end up finding confusing in here (or even send me an email and I'll be more than glad to clarify things).\n\nAhem, I believe if we have to set a beginning, it definitely has to be _pandas_. Why? If we want to analyze data, we must first learn how to have it ready to be analyzed. \n\nSo, one of the initial things you'll have to do in almost any project is to have Pandas ready for use. If you're wondering what is _pandas_, (from the [webpage](https:\/\/pandas.pydata.org\/)): _it is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language._\n\nHands on - this is how we start using it:","febab709":"# What is Machine Learning?\n\nI still remember when I was hired to a company to oversee their operations desk. It was quite a bizarre experience: the person before me was practically *ragequitting* the company, and there was no structure whatsoever. It was a call center, and all I had at my disposal was MS Excel, access to raw data via a very limited SQL tool and an underpaid, underqualified team... My job? To analyze the entire company's operations, and to determine whether they were efficient or not...\n\nThat was nearly ten years ago, and a lot has changed. Looking back, I could've done a lot of different things that would've impacted positively both in that company as well as in my great team. (they were really great, I miss them!) What was my greatest lesson learned from that experience? Data is power.\n\nData is everywhere. It is the rational description of everything around us. It allows us to face decision-making, analytical processes with much more maturity and without the tainting effect of emotions. Of course, it should be carefully extracted and treated in order to allow us to enjoy these amazing benefits...but it is out there.\n\nThe term *Machine Learning* dates back from the late 50s, and it was used in relation to what we call nowadays *pattern classification*. It is closely related to Artificial Intelligence - a greatly misunderstood field of knowledge, mainly because of irrational fears and Hollywoodian paranoia. Ultimately, it can be defined as the process of *reading* data and obtaining conclusions from it, in a guided, but automated way. It aims to \"tackle solvable problems of a practical nature\" - and it is even considered, by some, an entirely different field - and not a branch of AI.\n\nSince this isn't a textbook, and I have literally zero concern whether this definition is perfect and entirely comprehensive or not, I'd rather stick to the ***how*** rather than the ***what***. In that sense, Machine Learning it the *thing* that *learns* from historical data in order to *predict* future data. So, it deals with patterns, behaviors, and it *infers* things from them.\n\nAll these keywords are important here, because they help us to understand the *what* of Machine Learning through its *how*. It also helps us to understand its difference from other data analytical approaches, such as Data Science, for example. It also helps us to understand its strong link to Statistics and Mathematics - and its fundamental differences, which will be more visible once we get our hands dirty.\n\nAs it is probably obvious, this notebook uses Python in order to attain its objective, and it also considers that the necessary prerequisites from Mathematics and Statistics are well established. If they aren't, the reader can look for many online sources, such the amazing *Mathematics for Machine Learning* online course from Coursera."}}