{"cell_type":{"66bfd81d":"code","8dddba2b":"code","f6eed845":"code","e6e785ec":"code","290e066c":"code","794baf4f":"code","56e242b2":"code","015f78f8":"code","31d2f680":"code","30a00b0e":"code","9c5c241c":"code","8420d20a":"code","b70aa882":"code","384d33e1":"code","55bcb584":"code","db96d32d":"code","78b2512b":"code","58768f8a":"code","5cf4b759":"code","b04c9f71":"code","616eb090":"code","a3137267":"code","0e90bfc7":"code","2fa95620":"markdown","62d7555e":"markdown"},"source":{"66bfd81d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","8dddba2b":"# Imports\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler","f6eed845":"!wget https:\/\/raw.githubusercontent.com\/Iamsdt\/DLProjects\/master\/utils\/Helper.py","e6e785ec":"import Helper\nimport torch\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import DataLoader\n\ndata_dir = '..\/input\/labelledrice\/Labelled\/'\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n                                transforms.RandomRotation(30),\n                                transforms.Resize(255),\n                                #transforms.RandomResizedCrop(224),\n                                transforms.RandomHorizontalFlip(),\n                                #transforms.ColorJitter(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\ntest_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                #transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntrain_data = datasets.ImageFolder(data_dir, transform=train_transform)\ntest_data = datasets.ImageFolder(data_dir, transform=test_transform)\nprint(len(train_data))\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n\nlen(trainloader)","290e066c":"classes = train_data.classes","794baf4f":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndata_iter = iter(trainloader)\nimages, labels = data_iter.next() #this line\n\nfig = plt.figure(figsize=(25, 5))\nfor idx in range(2):\n    ax = fig.add_subplot(1, 5, idx + 1, xticks=[], yticks=[])\n    # unnormolaize first\n    img = images[idx] \/ 2 + 0.5\n    npimg = img.numpy()\n    img = np.transpose(npimg, (1, 2, 0)) #transpose\n    ax.imshow(img, cmap='gray')\n    ax.set_title(classes[labels[idx]])","56e242b2":"model = models.resnet152(pretrained=True)\nmodel.fc","015f78f8":"model = Helper.freeze_parameters(model)","31d2f680":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1536),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=1536, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.3),\n  nn.Linear(in_features=1024, out_features=4),\n  nn.LogSoftmax(dim=1) \n)\n    \nmodel.fc = classifier\nmodel.fc","30a00b0e":"import torch.optim as optim\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)","9c5c241c":"epoch = 1","8420d20a":"model, train_loss, test_loss = Helper.train(model, trainloader, testloader, epoch, optimizer, criterion)","b70aa882":"new_model = models.resnet50(pretrained=True)","384d33e1":"m = nn.Sequential(*list(new_model.children())[:-1])\nm","55bcb584":"trainloader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=16)","db96d32d":"from tqdm import tqdm\n# move to gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nm.to(device)\n\n#For training data\n\n# Stores the labels of the train data\ntrn_labels = [] \n\n# Stores the pre convoluted features of the train data\ntrn_features = []\n\nprint(\"For training........\")\n\n#Iterate through the train data and store the calculated features and the labels\nfor data,label in tqdm(trainloader):\n    o = m(Variable(data.to(device)))\n    o = o.view(o.size(0),-1)\n    trn_labels.extend(label)\n    trn_features.extend(o.cpu().data)\n\n#For test data\nprint(\"For testing........\")\n\n#Iterate through the validation data and store the calculated features and the labels\nval_labels = []\nval_features = []\nfor data,label in tqdm(testloader):\n    o = m(Variable(data.to(device)))\n    o = o.view(o.size(0),-1)\n    val_labels.extend(label)\n    val_features.extend(o.cpu().data)\n\nprint(\"Done\")","78b2512b":"from torch.utils.data import Dataset\nclass FeaturesDataset(Dataset):\n    \n    def __init__(self,featlst,labellst):\n        self.featlst = featlst\n        self.labellst = labellst\n        \n    def __getitem__(self,index):\n        return (self.featlst[index],self.labellst[index])\n    \n    def __len__(self):\n        return len(self.labellst)","58768f8a":"#Creating dataset for train and validation\ntrn_feat_dset = FeaturesDataset(trn_features,trn_labels)\nval_feat_dset = FeaturesDataset(val_features,val_labels)\n\n#Creating data loader for train and validation\ntrn_feat_loader = DataLoader(trn_feat_dset,batch_size=1,shuffle=True)\nval_feat_loader = DataLoader(val_feat_dset,batch_size=1)","5cf4b759":"\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1536),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=1536, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.3),\n  nn.Linear(in_features=1024, out_features=4),\n  nn.LogSoftmax(dim=1) \n)\n\nnet = classifier\nprint(net)","b04c9f71":"net.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.03)","616eb090":"epoch = 10","a3137267":"model, train_loss, test_loss = Helper.train(net, trn_feat_loader, val_feat_loader, epoch, optimizer, criterion)","0e90bfc7":"Helper.test(model, val_feat_loader, criterion)","2fa95620":"# Extract conv features","62d7555e":"# With previous data loader"}}