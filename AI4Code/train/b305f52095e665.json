{"cell_type":{"fb5fb44e":"code","ea62b74d":"code","4bfb3e9a":"code","0454860d":"code","9d2c3be0":"code","adc6afad":"code","68334609":"code","98501d50":"code","04bf5320":"code","97cbe12d":"code","4ea2b030":"code","dd90d7ca":"code","582513cd":"code","ead946d8":"code","e5f8150a":"markdown","54026ca2":"markdown","060f7172":"markdown","d96e8fe9":"markdown"},"source":{"fb5fb44e":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import Image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, Activation, BatchNormalization\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import mean_absolute_error","ea62b74d":"Image(\"..\/input\/lanlimages\/images\/images\/training_set\/val_0\/3828-2.913799.jpg\") # The time to failure of this segment is at the file name (2.913799)","4bfb3e9a":"img_width = 72\nimg_height = 72\nTRAIN_DIR = '..\/input\/lanlimages\/images\/images\/training_set\/val_'\nTEST_DIR = '..\/input\/lanlimages\/images\/images\/test_set\/'\ntest_images = [TEST_DIR+i for i in os.listdir(TEST_DIR)]","0454860d":"folds = 5\ntrain_images = [[],[],[],[],[]]\nfor fold in range(folds):\n    train_images[fold] = []\n    for i in os.listdir(TRAIN_DIR + str(fold)):\n        train_images[fold].append(TRAIN_DIR + str(fold) + '\/' + i)","9d2c3be0":"val_X_cnn = []\nval_y_cnn = []\ntrain_X_cnn = []\ntrain_y_cnn = []\nseg_id_val_cnn = [[],[],[],[],[]]\nseg_id_train_cnn = [[],[],[],[],[]]\nseg_id_test_cnn = []\n\nval_X_cnn.append(train_images[0])\nval_y_cnn.append(np.zeros(len(val_X_cnn[0])))\ntrain_X_cnn.append(train_images[1]+train_images[2]+train_images[3]+train_images[4])\ntrain_y_cnn.append(np.zeros(len(train_X_cnn[0])))\n\nval_X_cnn.append(train_images[1])\nval_y_cnn.append(np.zeros(len(val_X_cnn[1])))\ntrain_X_cnn.append(train_images[0]+train_images[2]+train_images[3]+train_images[4])\ntrain_y_cnn.append(np.zeros(len(train_X_cnn[1])))\n\nval_X_cnn.append(train_images[2])\nval_y_cnn.append(np.zeros(len(val_X_cnn[2])))\ntrain_X_cnn.append(train_images[0]+train_images[1]+train_images[3]+train_images[4])\ntrain_y_cnn.append(np.zeros(len(train_X_cnn[2])))\n\nval_X_cnn.append(train_images[3])\nval_y_cnn.append(np.zeros(len(val_X_cnn[3])))\ntrain_X_cnn.append(train_images[0]+train_images[1]+train_images[2]+train_images[4])\ntrain_y_cnn.append(np.zeros(len(train_X_cnn[3])))\n\nval_X_cnn.append(train_images[4])\nval_y_cnn.append(np.zeros(len(val_X_cnn[4])))\ntrain_X_cnn.append(train_images[0]+train_images[1]+train_images[2]+train_images[3])\ntrain_y_cnn.append(np.zeros(len(train_X_cnn[4])))","adc6afad":"def prepare_data(list_of_images, dataset):\n    \"\"\"\n    Returns two arrays:\n        x is an array of images\n        y is an array of labels\n    \"\"\"\n    x = [] # images as arrays\n    y = [] # labels\n    seg_id = []\n    \n    for image in list_of_images:\n        x.append(cv2.imread(image,cv2.IMREAD_GRAYSCALE))\n        if dataset != 'test':\n            y.append(float(image.split('-')[-1][:-4])) # [:-4] is to remove the file extension\n        \n        if dataset == 'validation':\n            seg_id.append(image.split('\/')[-1].split('-')[0])\n        \n        if dataset == 'test':\n            seg_id.append(image.split('\/')[-1].split('.')[0])\n            \n    return x, y, seg_id","68334609":"for fold in range(folds):\n    train_X_cnn[fold], train_y_cnn[fold], seg_id_train_cnn[fold] = prepare_data(train_X_cnn[fold], 'training') #seg_id_train will be []\n    val_X_cnn[fold], val_y_cnn[fold], seg_id_val_cnn[fold] = prepare_data(val_X_cnn[fold], 'validation')\ntest_X_cnn, test_y_cnn, seg_id_test_cnn = prepare_data(test_images, 'test')  #test_y will be []","98501d50":"train_X_cnn = np.array(train_X_cnn)\nval_X_cnn = np.array(val_X_cnn)\ntest_X_cnn = np.array(test_X_cnn)","04bf5320":"train_X_cnn = train_X_cnn.reshape(train_X_cnn.shape[0], train_X_cnn.shape[1], train_X_cnn.shape[2], train_X_cnn.shape[3], 1)\nval_X_cnn = val_X_cnn.reshape(val_X_cnn.shape[0], val_X_cnn.shape[1], val_X_cnn.shape[2], val_X_cnn.shape[3], 1)\ntest_X_cnn = test_X_cnn.reshape(test_X_cnn.shape[0], test_X_cnn.shape[1], test_X_cnn.shape[2], 1)","97cbe12d":"train_X_cnn[0].shape, val_X_cnn[0].shape, test_X_cnn.shape","4ea2b030":"nb_train_samples = train_X_cnn[0].shape[0]\nnb_validation_samples = val_X_cnn[0].shape[0]\nbatch_size = 64","dd90d7ca":"oof_cnn = np.zeros(len(train_X_cnn[0])+len(val_X_cnn[0]))\nall_y_cnn = np.zeros(len(oof_cnn))\npredictions_cnn = np.zeros(len(test_X_cnn))\n\nfor fold in range (folds):\n    print('fold: ', fold)\n    print('----------')\n    # Initialising the CNN\n    model = Sequential()\n    # Step 1 - Convolution\n    model.add(Conv2D(32, (5, 5), input_shape = (72, 72, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    # Step 2 - Pooling\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    # Adding a second convolutional layer\n    model.add(Conv2D(64, (3, 3), use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    # Step 3 - Flattening\n    model.add(Flatten())\n    # Step 4 - Full connection\n    model.add(Dense(units = 2056, kernel_regularizer=regularizers.l2(0.001)))\n    model.add(Dropout(rate=0.3))\n    model.add(Activation('relu'))\n    # Step 5 - Output Layer\n    model.add(Dense(units = 1, activation = 'linear'))\n    # Compiling the CNN\n    model.compile(optimizer = 'Adam', loss = 'mean_absolute_error')\n    train_datagen = ImageDataGenerator(rescale=1.\/255)\n    val_datagen = ImageDataGenerator(rescale=1.\/255)\n    test_datagen = ImageDataGenerator(rescale=1.\/255)\n    train_generator = train_datagen.flow(train_X_cnn[fold], train_y_cnn[fold], batch_size=batch_size, shuffle=False)\n    validation_generator = val_datagen.flow(val_X_cnn[fold], val_y_cnn[fold], batch_size=batch_size, shuffle=False)\n    test_generator = test_datagen.flow(test_X_cnn, batch_size=batch_size, shuffle=False)\n    # EarlyStopping\n    es = EarlyStopping(monitor='val_loss', patience=8, mode='auto', restore_best_weights=True)\n    # Fitting\n    model.fit_generator(train_generator, steps_per_epoch=nb_train_samples \/\/ batch_size, callbacks=[es],\n                        epochs=40, validation_data=validation_generator, validation_steps=nb_validation_samples \/\/ batch_size)\n    # Predicting\n    index_start = len(val_X_cnn[0])*fold\n    index_end = index_start + len(val_X_cnn[0])\n    oof_cnn[index_start:index_end] = model.predict_generator(generator=validation_generator, steps=len(validation_generator), verbose=1).reshape(1,-1)\n    all_y_cnn[index_start:index_end] = val_y_cnn[fold]\n    predictions_cnn += model.predict_generator(generator=test_generator, steps=len(test_generator), verbose=1)[:,0] \/ folds\n\noof_cnn = np.where(oof_cnn < 0, 0, oof_cnn) # Removing negative predictions\npredictions_cnn = np.where(predictions_cnn < 0, 0, predictions_cnn) # Removing negative predictions\nprint('CV MAE: {}'.format(mean_absolute_error(all_y_cnn, oof_cnn)))","582513cd":"g = sns.jointplot(x=all_y_cnn,y=oof_cnn,kind='hex')\nlims = [18,0]\ng.ax_joint.plot(lims, lims)","ead946d8":"submission = pd.read_csv('..\/input\/LANL-Earthquake-Prediction\/sample_submission.csv', index_col='seg_id')\nsubmission.time_to_failure = predictions_cnn\nsubmission.to_csv('submission.csv',index=True)","e5f8150a":"### This kernel was created to the <a target=\"_blank\" href=\"https:\/\/www.kaggle.com\/c\/LANL-Earthquake-Prediction\">LANL Earthquake Prediction<\/a> competition.\n### Here we plot the raw data and then aplly a Convolution Neural Network on the images.","54026ca2":"### Here is an example of image that will be the input of the CNN:","060f7172":"## Conclusion\n#### This technique give us a reasonable result, considering that we are not using any numerical features. Besides, we can create a more complex neural network combining a MLP (numerical features) with a CNN (images), this can be done with the Keras functional API.","d96e8fe9":"## Submission"}}