{"cell_type":{"b634faae":"code","1937fdb3":"code","8dbdc46a":"code","3f5dbfc4":"code","f6add852":"code","8a85e784":"code","f07dbcd3":"code","22afbb7a":"code","f7bc701a":"code","98ebbe70":"code","e42e2515":"code","8e97b042":"code","714b775f":"code","056fc4c3":"code","65b44501":"code","6e239c5b":"code","fda2aef8":"code","9f6e965c":"code","ff853344":"code","78437091":"code","293d8476":"code","ab22dcb1":"code","58afac8e":"code","f7fb2046":"code","37939b68":"code","274e1b27":"code","b1a207f2":"code","2b0b39ba":"code","22f9f1d3":"code","fb8679b8":"code","17be26bd":"code","fe1f8dc7":"code","1d2fcfcf":"code","778df441":"code","5b347f75":"code","7d54e6f7":"code","4ad5d5e8":"code","7356eeae":"code","1d27c53a":"code","a2326b14":"code","85dd674b":"code","4e919ac3":"code","b28855a3":"code","e5ae562a":"code","5c9993ea":"code","3a374019":"code","0d6ab032":"code","798521af":"code","165cc6ed":"code","91ace70d":"code","5aea88dd":"code","39d26d3f":"code","249583b1":"code","347f8ed0":"code","7b5b955f":"code","b90a433d":"code","57227c40":"code","5d80a44e":"code","48bc250d":"code","1e4f442f":"code","7b9f6fed":"code","cb97ad4d":"code","7cb57356":"code","6aebead7":"code","af2a476a":"code","54022a0a":"code","3832ebfb":"code","16f6d93c":"code","d1034f5a":"code","aadb1687":"code","f421b6e8":"code","47728db8":"markdown","0d37e93d":"markdown","079680e9":"markdown","1bcffb5d":"markdown","dfb8cc55":"markdown","71ac61bc":"markdown","374efa50":"markdown","fd60342f":"markdown","1d3cb514":"markdown","3c09b2b4":"markdown"},"source":{"b634faae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1937fdb3":"#import all the necessary libraries here\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.offline as pyoff\nimport plotly.figure_factory as ff\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.graph_objs as go\n%matplotlib inline\nimport math\n","8dbdc46a":"def generate_layout_bar(col_name):\n    layout_bar = go.Layout(\n        autosize=False, # auto size the graph? use False if you are specifying the height and width\n        width=800, # height of the figure in pixels\n        height=600, # height of the figure in pixels\n        title = \"Distribution of {} column\".format(col_name), # title of the figure\n        # more granular control on the title font \n        titlefont=dict( \n            family='Courier New, monospace', # font family\n            size=14, # size of the font\n            color='black' # color of the font\n        ),\n        # granular control on the axes objects \n        xaxis=dict( \n        tickfont=dict(\n            family='Courier New, monospace', # font family\n            size=14, # size of ticks displayed on the x axis\n            color='black'  # color of the font\n            )\n        ),\n        yaxis=dict(\n#         range=[0,100],\n            title='Percentage',\n            titlefont=dict(\n                size=14,\n                color='black'\n            ),\n        tickfont=dict(\n            family='Courier New, monospace', # font family\n            size=14, # size of ticks displayed on the y axis\n            color='black' # color of the font\n            )\n        ),\n        font = dict(\n            family='Courier New, monospace', # font family\n            color = \"white\",# color of the font\n            size = 12 # size of the font displayed on the bar\n                )  \n        )\n    return layout_bar","3f5dbfc4":"init_notebook_mode(connected=True)","f6add852":"data=pd.read_excel(\"..\/input\/Train.xlsx\")","8a85e784":"datacopy_master=data","f07dbcd3":"data.head()","22afbb7a":"Records=data.shape[0]\nAttributes=data.shape[1]\nprint(\"Number of Records in dataset = \",Records)\nprint(\"Number of Attributes in dataset = \",Attributes)\n","f7bc701a":"data['Suspicious'].describe()","98ebbe70":"value,count=np.unique(data['Suspicious'],return_counts=True)\npercent=(count\/Records)*100\nprint(np.asarray([value,count,percent]).T)","e42e2515":"count","8e97b042":"labels = 'No', 'Yes', 'Indeterminate'\nexplode = (0, 0.1, 0)  # only \"explode\" the 2nd slice (i.e. 'Yes')\n\nfig1, ax1 = plt.subplots()\nax1.pie(count, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()\n","714b775f":"count[0]","056fc4c3":"data1 = [\n    go.Bar(\n        x=value, # assign x as the dataframe column 'x'\n        y=count,\n        text=count,\n        textposition='auto'\n    )\n]\n\nlayout = go.Layout(\n    barmode='stack',\n    title='Stacked Bar with Pandas'\n)\n\nfig = go.Figure(data=data1, layout=layout)\n\n# IPython notebook\niplot(fig)","65b44501":"plt.bar(np.unique(data['SalesPersonID']),data.groupby(['SalesPersonID']).mean()['Quantity'])\n\nplt.ylim([0,120000])\nplt.show()","6e239c5b":"datacopy=data","fda2aef8":"datacopy.head()","9f6e965c":"datacopy['new_Column']=0","ff853344":"temp=data.groupby(['SalesPersonID','ProductID']).mean()['Quantity']","78437091":"temp = (pd.DataFrame(temp))","293d8476":"temp = temp.reset_index()","ab22dcb1":"temp.columns","58afac8e":"result=pd.merge(data,temp,on=['SalesPersonID','ProductID'],how='left')","f7fb2046":"result=result.drop(['new_Column'],axis=1)","37939b68":"data=data.drop(['new_Column'],axis=1)","274e1b27":"result.head()","b1a207f2":"datacopy.head()","2b0b39ba":"datacopy['new_Column']=datacopy.TotalSalesValue\/datacopy.Quantity","22f9f1d3":"datacopy.head()","fb8679b8":"data['price_Per_Unit']=data.TotalSalesValue\/data.Quantity","17be26bd":"data=pd.merge(data,temp,on=['SalesPersonID','ProductID'],how='left')","fe1f8dc7":"data=data.rename(index=str, columns={\"Quantity_y\": \"Average_qty_\/guy_\/prdID\"})\n","1d2fcfcf":"data.head()","778df441":"temp=data.groupby(['SalesPersonID','ProductID']).mean()['TotalSalesValue']","5b347f75":"temp = (pd.DataFrame(temp))","7d54e6f7":"temp = temp.reset_index()","4ad5d5e8":"data=pd.merge(data,temp,on=['SalesPersonID','ProductID'],how='left')","7356eeae":"data.head()","1d27c53a":"data=data.rename(index=str, columns={\"TotalSalesValue_y\": \"Average_TotalSales_\/guy_\/prdID\"})\n","a2326b14":"data.head()","85dd674b":"temp=data.groupby(['SalesPersonID']).mean()['TotalSalesValue_x']","4e919ac3":"temp=pd.DataFrame(temp)","b28855a3":"data=pd.merge(data,temp,on=['SalesPersonID'],how='left')","e5ae562a":"data=data.rename(index=str, columns={\"TotalSalesValue_x_y\": \"Average_TotalSales_\/guy\"})\n","5c9993ea":"temp=data.groupby(['SalesPersonID']).mean()['Quantity_x']\ntemp=pd.DataFrame(temp)","3a374019":"data=pd.merge(data,temp,on=['SalesPersonID'],how='left')","0d6ab032":"data=data.rename(index=str, columns={\"Quantity_x_y\": \"Average_Quantity_\/guy\"})\n","798521af":"temp=data.groupby(['ProductID']).mean()['Quantity_x_x']\ntemp=pd.DataFrame(temp)","165cc6ed":"data=pd.merge(data,temp,on=['ProductID'],how='left')","91ace70d":"data=data.rename(index=str, columns={\"Quantity_x_x_y\": \"Average_Quantity_\/Product\"})\n","5aea88dd":"temp=data.groupby(['ProductID']).mean()['TotalSalesValue_x_x']\ntemp=pd.DataFrame(temp)","39d26d3f":"data=pd.merge(data,temp,on=['ProductID'],how='left')","249583b1":"data=data.rename(index=str, columns={\"TotalSalesValue_x_x_y\": \"Average_TotalSales_\/ProductID\"})\n","347f8ed0":"data.describe()","7b5b955f":"data.columns","b90a433d":"data=data.rename(index=str, columns={'Average_qty_\/guy_\/prdID':'Average_qty_guy_prdID',\n                                     'Average_TotalSales_\/guy_\/prdID':'Average_TotalSales_guy_prdID',\n                                     'Average_TotalSales_\/guy':'Average_TotalSales_guy',\n                                     'Average_Quantity_\/guy':'Average_Quantity_guy',\n                                     'Average_Quantity_\/Product':'Average_Quantity_Product',\n                                     'Average_TotalSales_\/ProductID':'Average_TotalSales_ProductID',\n                                     'Quantity_x_x_x':'Quantity',\n                                     'TotalSalesValue_x_x_x':'TotalSalesValue'})\n","57227c40":"data.head()","5d80a44e":"data.to_csv('feature_engineering.csv',index=False)","48bc250d":"data.groupby('ProductID').mean()","1e4f442f":"ax = sns.scatterplot(x=\"SalesPersonID\", y=\"price_Per_Unit\", hue=\"Suspicious\",data=data)","7b9f6fed":"data_for_Yes=datacopy_master[datacopy_master.Suspicious=='Yes']","cb97ad4d":"data_for_No=datacopy_master[datacopy_master.Suspicious=='No']","7cb57356":"data_for_indeterminate=datacopy_master[datacopy_master.Suspicious=='indeterminate']","6aebead7":"data_for_Yes.head()","af2a476a":"temp=data_for_Yes.groupby(['SalesPersonID']).sum()\ntemp=pd.DataFrame(temp)\ndataframe_with_Yes = temp.reset_index()\n","54022a0a":"temp=data_for_No.groupby(['SalesPersonID']).sum()\ntemp=pd.DataFrame(temp)\ndataframe_with_No = temp.reset_index()\n","3832ebfb":"temp=data_for_indeterminate.groupby(['SalesPersonID']).sum()\ntemp=pd.DataFrame(temp)\ndataframe_with_indeterminate = temp.reset_index()\n","16f6d93c":"temp1=dataframe_with_Yes.sort_values('Quantity',ascending=False).head(10)\ntemp2=dataframe_with_No.sort_values('Quantity',ascending=False).head(10)\ntemp3=dataframe_with_indeterminate.sort_values('Quantity',ascending=False).head(10)\n","d1034f5a":"temp4=pd.merge(temp1,temp2,on=['SalesPersonID'],how='left')","aadb1687":"temp4","f421b6e8":"data.groupby('Suspicious').count()","47728db8":"* well it seems that there are 3 unique values in this column\n* the top most occuring value is **'indeterminate'** with a Frequency of **39846**.\n* let's check the frequency of the other two values too.","0d37e93d":"### **Buisness case: ** \n* A large U.S. Electrical appliance's retailer has many branches. There is no Fixed Price for a product(for various reasons),the SalesPerson has the freedom to choose the price at which they sell the product. There is no cap on the minimum and maximum quantity of sales on the Salesperson.Due to these reasons the average sale size and average quantity for a transaction varies.The company wants to do a **'Sales and Productivity'** analysis.\n* It is for this reason the company wants to implement a system to classify the reports into one of the Three categories,\n  **Suspicious\/Not Suspicious\/Indeterminate**.                       \n* The company also wants the Salespersons to be grouped into **HighRisk** or **MediumRisk** or **LowRisk** categories based on the report info provided by them. \n","079680e9":"*let us start to group the records based on salesperson and  find the distribution of each salesperson","1bcffb5d":"## Part-0 : Importing all the necessary Libraries and Loading the Data","dfb8cc55":"## Overview of this notebook\n-**Understand the problem.** We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n\n-**Univariable study.** We'll just focus on the dependent variable and try to know a little bit more about it.\n\n-**Multivariate study.** We'll try to understand how the dependent variable and independent variables relate.","71ac61bc":"snapshot of  the data","374efa50":"* the above calculation show's that the dataset has 93.57% of the records with indeterminate level,06.00% of the records with No level,00.42% of the records with Yes level.","fd60342f":"### **Part-2 : Univariate Analysis**\n*First things first*:Analysing **'Suspicious'** column ","1d3cb514":"### **ML Problem Statement:**\n1. Build and Develop a Machine Learning Model to **Classify** the Reports submitted by the Salesperson into one of three categories Yes\/NO\/Indeterminate.\n   The dependent column is **'Suspicious'**.\n2. **Segment** the Salesperson into one of the three categories HighRisk or MediumRisk or LowRisk categories.","3c09b2b4":"## Part-1 : Understanding the problem statement\n"}}