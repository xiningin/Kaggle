{"cell_type":{"0bade07e":"code","467a3969":"code","3502ea84":"code","788e1d2e":"code","32b0dbe2":"code","c78c95de":"code","11239961":"code","d309be19":"code","88da8d34":"code","4871c668":"code","886ca7d1":"code","73da8c73":"code","75a1dddd":"code","dacb3a73":"code","d5dae2fc":"code","126954d3":"code","760eb818":"code","9f7d2558":"code","efd40d67":"code","eae81c32":"code","73e38183":"code","e40d8573":"code","abd1af3c":"code","72d9d4d3":"code","37764810":"code","3f9173be":"code","78daa889":"code","16f4b526":"code","47e94b1e":"code","bd666492":"code","f6a95402":"code","c42a393c":"code","6bd62ea8":"code","65e3bc8b":"code","17dba29a":"code","02bb0ae8":"code","5cf72d28":"code","6f148a3f":"code","625e7974":"code","10bfbe5f":"code","b22ac031":"markdown","8322e8dc":"markdown","c50411cf":"markdown","233a552e":"markdown","53547dff":"markdown","d82b2286":"markdown","ba0f21b6":"markdown"},"source":{"0bade07e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","467a3969":"import math\nimport glob\nimport os\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.graph_objs as go \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n%matplotlib inline","3502ea84":"products_df = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\nproducts_df.head()","788e1d2e":"products_df.info()","32b0dbe2":"district_df = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\n","c78c95de":"district_df.head()","11239961":"district_df.info()","d309be19":"path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\nall_files = glob.glob(path+ \"\/*.csv\")\n\nli=[]\n\nfor file in all_files:\n    df=pd.read_csv(file,index_col=None,header=0)\n    district_id = file.split('\/')[4].split(\".\")[0]\n    df['district_id']=district_id\n    li.append(df)\n    \nengagement_df=pd.concat(li)\nengagement_df=engagement_df.reset_index(drop=True)\n","88da8d34":"engagement_df.head()","4871c668":"engagement_df.info()","886ca7d1":"#Function to find the percent of missing values \ndef missing_values(df):\n    #Missing Values in dataframe\n    mis_val = df.isnull().sum()\n    #Missing value Percent :\n    mis_val_percent = 100* df.isnull().sum() \/ len(df)\n    #Missing Values Table\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_ren = mis_val_table.rename(\n            columns = {0 : 'Missing Values', 1 : '% of Missing Values'})\n    mis_val_final=mis_val_ren.sort_values('% of Missing Values',ascending=False)\n    \n    return mis_val_final","73da8c73":"#Product table missing values\nmsno.bar(products_df,color='green', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()\n\nmissing_values(products_df)","75a1dddd":"#District table missing values\nmsno.bar(district_df,color='red', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()\nmissing_values(district_df)","dacb3a73":"#Engagement data missing values\nmsno.bar(engagement_df,color='blue', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()\n\nmissing_values(engagement_df)","d5dae2fc":"#Missisng values imputation:\n#In district dataframe we have certain rows where all the columns are missing values except district id . So we shall remove such rows\ndistricts_df=district_df.copy()","126954d3":"districts_df = districts_df.dropna(thresh=2)","760eb818":"#Check if there are any duplicates in dataframes\nprint(\"Number of Duplicate value in Districts Dataframe:\",districts_df.duplicated().sum())\nprint(\"Number of Duplicate value in Engagement Dataframe:\",engagement_df.duplicated().sum())\nprint(\"Number of Duplicate value in Products Dataframe:\",products_df.duplicated().sum())\n","9f7d2558":"#Lets drop the duplicate values in Products_df\nproducts_df= products_df.dropna()\n\n#Now we have droppped all the rows with missing values. \nmissing_values(products_df)\n","efd40d67":"#In the description it is given PrimaryEssentialFunction has 2 layers. So now lets split those 2 layers\nproducts_df['PEF L1'] = products_df['Primary Essential Function'].apply(lambda pef:pef.split('-')[0].strip())\nproducts_df['PEF L2'] = products_df['Primary Essential Function'].apply(lambda pef:pef.split('-')[1].strip())\nproducts_df = products_df[['LP ID','URL','Product Name','Provider\/Company Name','Sector(s)','PEF L1','PEF L2']]\nproducts_df.info()","eae81c32":"products_df.head()","73e38183":"#Companies selling more than 1 product\nprovider_group = products_df.groupby('Provider\/Company Name')[['LP ID']].count().sort_values(by='LP ID')\nprovider_group = provider_group[provider_group['LP ID']>1]\nprovider_group\n","e40d8573":"plt.figure(figsize=(12,6))\nplt.title(\"Number of product by Provider\/Company Name'\")\nplt.ylabel('Provider Name')\nplt.xlabel('Number of product')\nsns.barplot(x=list(provider_group['LP ID']),y=provider_group.index)\n","abd1af3c":"#Number of products by Primary Essential function L1\npef_group = products_df.groupby('PEF L1')[['LP ID']].count().sort_values(by='LP ID')\npef_group","72d9d4d3":"plt.figure(figsize=(12,6))\nplt.title(\"Number of product by PEF L1'\")\nplt.ylabel('PEF L1')\nplt.xlabel('Number of product')\nsns.barplot(x=list(pef_group['LP ID']),y=pef_group.index)\n","37764810":"plt.figure(figsize=(16, 20))\nsns.countplot(y='PEF L2', data=products_df, order=products_df[\"PEF L2\"].value_counts().index)\nplt.title(\"Primary Essential Function L2\",font=\"Serif\", size=20)\nplt.show()\n","3f9173be":"#Number of products by sector\nsector_group = products_df.groupby('Sector(s)')[['LP ID']].count().sort_values(by='LP ID')\nsector_group","78daa889":"plt.figure(figsize=(12,6))\nplt.title(\"Number of product by Sector\")\nplt.ylabel('Sector Name')\nplt.xlabel('Number of product')\nsns.barplot(x=list(sector_group['LP ID']),y=sector_group.index)\n","16f4b526":"# Only one  company each is dealing with Higher ed and corporate sector. So lets find what are they \nproducts_df[products_df['Sector(s)']=='Higher Ed; Corporate']['Product Name'],products_df[products_df['Sector(s)']=='Corporate']['Product Name']","47e94b1e":"#Sector Distribution\nsec_colors = ['gold', 'mediumturquoise', 'darkorange','red','green']\nlabels = list(products_df['Sector(s)'].value_counts().index)\nvalues = products_df['Sector(s)'].value_counts()\n# colors = ['mediumslateblue', 'darkorange']\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values)])\nfig.update_traces(hoverinfo='label+percent', textinfo='label+percent', textfont_size=10,\n                  marker=dict(colors=sec_colors, line=dict(color='#000000', width=3)))\nfig.update_layout(title=\"Sector Distribution \",\n                  titlefont={'size': 20},      \n                  )\nfig.show()","bd666492":"# State Level Data\nplt.figure(figsize=(16, 10))\nsns.countplot(y=\"state\",data=districts_df,order=districts_df.state.value_counts().index,palette=\"Blues\",linewidth=3)\nplt.title(\"State level data\",font=\"Serif\", size=20,pad=20)\nplt.show()\n\n\nstates = districts_df.groupby(by ='state').count()[['district_id']]\n#abbreviations of all the US States\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ncodes = []\nfor i in states.index:\n    codes.append(us_state_abbrev[i])\n# print(codes)\ndata = dict(\n        type = 'choropleth',\n        colorscale = 'blues',\n        locations = codes,\n        locationmode = 'USA-states',\n        z = list(states['district_id']),\n        text = states.index,\n        colorbar = {'title':'States'},\n      )\nlayout = dict(title = 'States',\n              geo = dict(projection = {'type':'mercator'})\n             )\nlayout = dict(title= 'States with most districts mentioned',\n              geo = {'scope':'usa'})\n\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)\n","f6a95402":"# State Distribution\nlabels = list(districts_df.state.value_counts().index)\nvalues = districts_df['state'].value_counts()\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values,hole=.2)])\nfig.update_traces(hoverinfo='label+percent', textinfo='percent', textfont_size=15,\n                  marker=dict( line=dict(color='#000000', width=3)))\nfig.update_layout(title=\"State Distribution \",\n                  titlefont={'size': 30},      \n                  )\nfig.show()","c42a393c":"#Locale Distribution\ncolors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\nlabels = list(districts_df.locale.value_counts().index)\nvalues = districts_df['locale'].value_counts()\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values)])\nfig.update_traces(hoverinfo='label+percent', textinfo='label+percent', textfont_size=20,\n                  marker=dict(colors=colors,line=dict(color='#000000', width=2)))\nfig.update_layout(title=\"Locale Distribution \",\n                  titlefont={'size': 20},      \n                  )\nfig.show()","6bd62ea8":"district_df['pp_total_raw'].value_counts()","65e3bc8b":"district_df[\"pp_total_raw\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%',figsize=(10, 10)).legend()","17dba29a":"districts_df['pct_free\/reduced'].value_counts()","02bb0ae8":"plt.figure(figsize=(16,7))\nsns.countplot(x='pct_free\/reduced',data=district_df,hue='locale')\nplt.title('pct_free\/reduced by the locale')","5cf72d28":"# Engagement Data \nengagement_df['date'] = pd.to_datetime(engagement_df['time']).dt.date\nengagement_df['month']= pd.to_datetime(engagement_df['time']).dt.month_name()\nengagement_df['weekday']= pd.to_datetime(engagement_df['time']).dt.day_name()","6f148a3f":"engagement_df","625e7974":"#Monthly percentage access\nplt.figure(figsize=(15,12))\nsns.set_style('whitegrid')\nsns.stripplot(x=\"month\", y=\"pct_access\", data=engagement_df)\nplt.show()","10bfbe5f":"#Weekly percentage access\norder = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\nplt.figure(figsize=(15,12))\nsns.set_style('whitegrid')\nsns.stripplot(x=\"weekday\", y=\"pct_access\", data=engagement_df,order=order)\nplt.show()","b22ac031":"**Problem Statement**\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.\n\n\n","8322e8dc":"**Introduction:**\n\nAs the world becomes increasingly interconnected, so do \nthe risks we face. The COVID-19 pandemic has not stopped \nat national borders. It has affected people regardless of \nnationality, level of education, income or gender. But the same \nhas not been true for its consequences, which have hit the \nmost vulnerable hardest.\nEducation is no exception. Students from privileged \nbackgrounds, supported by their parents and eager and able to \nlearn, could find their way past closed school doors to alternative \nlearning opportunities. Those from disadvantaged backgrounds \noften remained shut out when their schools shut down. \nThis crisis has exposed the many inadequacies and inequities \nin our education systems \u2013 from access to the broadband and \ncomputers needed for online education, and the supportive \nenvironments needed to focus on learning, up to the \nmisalignment between resources and needs. \n\nIn this kernel let's analyse 3 different datasets product_info , districts_info and engagement_data and find insights on the state of digital learning in 2020","c50411cf":"**** DISTRICT INFORMATION DATA****\n\n**Understanding the data**\nThe district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set, we removed the identifiable information about the school districts. We also used an open source tool ARX (Prasser et al. 2020) to transform several data fields and reduce the risks of re-identification. For data generalization purposes some data points are released with a range where the actual value falls under. Additionally, there are many missing data marked as 'NaN' indicating that the data was suppressed to maximize anonymization of the dataset.\n\n**district_id** : The unique identifier of the school district\n\n**state** : The state where the district resides in\n\n**locale** : NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\n\n**pct_black\/hispanic **: Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n\n**pct_free\/reduced :** Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\n**countyconnectionsratio** : ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\n\n**pptotalraw** : Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.","233a552e":"# Reading data files \n\n**Product information data**\n\nThe product file products_info.csv includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy.\n\n**LPID** : The unique identifier of the product\n\n**URL** : Web Link to the specific product\n\n**ProductName** : Name of the specific product\n\n**Provider\/CompanyName** : Name of the product provider\n\n**Sector(s)** : Sector of education where the product is used\n\n**PrimaryEssentialFunction** : The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled","53547dff":"# Engagement data\nThe engagement data are aggregated at school district level, and each file in the folder engagement_data represents data from one school district*.\n\n\ud83d\udcddThe 4-digit file name represents district_id which can be used to link to district information in district_info.csv.\n\n\ud83d\udcddThe lp_id can be used to link to product information in product_info.csv.\n\n\n**time**\tdate in \"YYYY-MM-DD\"\n\n**lp_id**\tThe unique identifier of the product\n\n**pct_access**\tPercentage of students in the district have at least one page-load event of a given product and on a given day\n\n**engagement_index**\tTotal page-load events per one thousand students of a given product and on a given day\n","d82b2286":"# Missing Values Identification and Imputation:","ba0f21b6":"**Objective:**\n\n        Our objective is to find answers to the below questions\n\n\u2022\tWhat is the picture of digital connectivity and engagement in 2020?\n\n\u2022\tWhat is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n\n\u2022\tHow does student engagement with different types of education technology change over the course of the pandemic?\n\n\u2022\tHow does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n\n\u2022\tDo certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\n\n"}}