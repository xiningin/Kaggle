{"cell_type":{"d8dba389":"code","c617aaec":"code","e4bf0d12":"code","cf3d1ad7":"code","8b739e92":"code","9a4cbb18":"code","6be5618a":"code","d72fb600":"code","18c096b5":"code","c94ea610":"code","e99ae932":"code","bae47228":"code","dbbf9335":"code","09d1767f":"code","4d577581":"code","0e197bd6":"code","a8b6a491":"code","c08eb46d":"code","39379b41":"code","320507ba":"code","e0d6ccc6":"code","2520d314":"code","8c9f5d56":"code","2fde2342":"code","5a02e7b9":"code","ba6f4584":"code","e6e40de6":"code","b2d88fee":"code","83172f76":"code","17186d0c":"code","37433f8c":"code","589b2dd3":"code","6ba75a88":"code","82972b6e":"code","1fb946b2":"code","0a7de929":"code","d3fbada8":"code","9fe11b26":"code","6f3a0756":"code","59046ef8":"code","eca6617a":"code","81dfd9d1":"code","0c2ddeae":"code","cad4f200":"code","41d5c657":"code","adf7afd3":"code","a3533b97":"code","69e53cdb":"code","a95e6011":"code","66b31dae":"code","a0f744e6":"code","d8c42d9b":"code","6af343a8":"code","2192afef":"code","1be2e9c4":"code","07d21b1e":"code","cb5aceac":"code","4936c309":"code","7e46fbe9":"code","fdc30dc6":"code","57d380e4":"code","ff166458":"code","fda7a4b7":"code","9af39ece":"code","438b620f":"code","17ace377":"code","68cd8494":"code","d85f2fed":"code","45d7f1d1":"code","0db82e19":"code","a1c1208a":"code","7f9e2faf":"code","04d8f8d4":"code","91e39c1d":"code","19e29217":"code","245baf77":"code","60450cac":"code","cf965104":"code","8d701b6d":"code","7f110457":"code","39355507":"markdown","02c8ec37":"markdown","d1006f9e":"markdown","6107be78":"markdown","97ee861e":"markdown","6d2c006a":"markdown","525995b7":"markdown","41a5c295":"markdown","35804fd2":"markdown","eb674b58":"markdown","793ac56e":"markdown","53702a96":"markdown","fcf6fc93":"markdown","b05002ca":"markdown","c1eacf8f":"markdown","31e3c8bb":"markdown","15263420":"markdown","6ac7378f":"markdown","0a2c84df":"markdown","fc61652e":"markdown","bdd605be":"markdown","75efddb1":"markdown","5eb06879":"markdown","b5d14b45":"markdown","ca8885be":"markdown","dfad4d12":"markdown","b40b22c2":"markdown","6da32d48":"markdown","6b758176":"markdown","60d01436":"markdown","b6e739a4":"markdown","c5cfd5a2":"markdown","f7d16316":"markdown","06b65c7d":"markdown"},"source":{"d8dba389":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","c617aaec":"df = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')","e4bf0d12":"df.head()","cf3d1ad7":"df.shape","8b739e92":"df.info()","9a4cbb18":"df.drop(['PatientId','AppointmentID'],axis=1, inplace = True)\n\ndf.head()","6be5618a":"df['No-show'].value_counts()","d72fb600":"(22319 \/ 110527) * 100, (88208 \/ 110527) * 100, (22319 \/ 110527) * 100 + (88208 \/ 110527) * 100, 88208+22319","18c096b5":"# Convert Features ScheduledDay and AppointmentDay to DateTime\n\ndf['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\ndf['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n\n# df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay']).dt.date.astype('datetime64[ns]')\n# df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay']).dt.date.astype('datetime64[ns]')","c94ea610":"df.info()","e99ae932":"df.head()","bae47228":"df['ScheduledMonth'] = df['ScheduledDay'].dt.month\ndf['ScheduledDayofWeek'] = df['ScheduledDay'].dt.day_name()\n# df['ScheduledHour'] = df['ScheduledDay'].dt.hour","dbbf9335":"# df.drop(['ScheduledDay'],axis=1, inplace = True)","09d1767f":"df.head()","4d577581":"df['AppointmentMonth'] = df['AppointmentDay'].dt.month\ndf['AppointmentDayofWeek'] = df['AppointmentDay'].dt.day_name()\n# df['AppointmentHour'] = df['AppointmentDay'].dt.hour\n\ndf.head()","0e197bd6":"# df.drop(['AppointmentDay'],axis=1, inplace = True)\n# df.head()","a8b6a491":"sorted(df['Gender'].unique())","c08eb46d":"sorted(df['Neighbourhood'].unique())","39379b41":"sorted(df['No-show'].unique())","320507ba":"sorted(df['Age'].unique())","e0d6ccc6":"df[(df['Age'] == -1) | (df['Age'] == 115)]","2520d314":"# df = df[(df['Age'] == -1) | (df['Age'] == 115)]\n\n# THe above can also we re-written as \ndf = df[(df['Age'] < 115) & (df['Age'] > 0)]","8c9f5d56":"df.head()","2fde2342":"sorted(df['Handcap'].unique())","5a02e7b9":"sns.countplot(x='Gender', hue='No-show', data=df)","ba6f4584":"plt.figure(figsize=(30,12))\nfig = sns.countplot(x='Neighbourhood',hue='No-show',data=df)\nfig.set_xticklabels(fig.get_xticklabels(), rotation=90);","e6e40de6":"sns.heatmap(df.corr(), cmap='coolwarm')","b2d88fee":"df['No-show'].value_counts()","83172f76":"pd.get_dummies(df['No-show'],drop_first = True) ","17186d0c":"df['No-show'] = pd.get_dummies(df['No-show'],drop_first = True)","37433f8c":"df.head()","589b2dd3":"df['Gender'] = pd.get_dummies(df['Gender'],drop_first = True)\ndf.head()","6ba75a88":"pd.get_dummies(df['Neighbourhood'])","82972b6e":"nb = pd.get_dummies(df['Neighbourhood'])\ndf = df.join(nb)\ndf.head()","1fb946b2":"df.drop(['Neighbourhood'],axis=1, inplace = True)","0a7de929":"del nb","d3fbada8":"df.head()","9fe11b26":"df.shape","6f3a0756":"df.describe()","59046ef8":"df.info()","eca6617a":"df['ScheduledDayofWeek'].unique() \n# 'AppointmentDayofWeek']","81dfd9d1":"sd = pd.get_dummies(df['ScheduledDayofWeek'], prefix='Sch')\ndf = df.join(sd)\ndf.drop(['ScheduledDayofWeek'],axis=1, inplace = True)\ndel sd\ndf.head()","0c2ddeae":"df['AppointmentDayofWeek'].unique() ","cad4f200":"pd.get_dummies(df['AppointmentDayofWeek'], prefix='App')","41d5c657":"sd = pd.get_dummies(df['AppointmentDayofWeek'], prefix='App')\ndf = df.join(sd)\ndf.drop(['AppointmentDayofWeek'],axis=1, inplace = True)\ndel sd\ndf.head()","adf7afd3":"df.info()","a3533b97":"df.describe()","69e53cdb":"# Check the Features Vs Target\nfeatures = ['Gender','Hipertension','Alcoholism','Diabetes', 'SMS_received']\nfor r in features :\n    print(df.groupby(r)['No-show'].mean())\n    print()","a95e6011":"from sklearn.model_selection import train_test_split","66b31dae":"# training_features = df.columns\ndf.columns","a0f744e6":"X = df.drop(['No-show','ScheduledDay', 'AppointmentDay'],axis=1) # Features\ny = df['No-show']  # Labels\n\nX.head()","d8c42d9b":"y.head()","6af343a8":"# Split dataset into train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test","2192afef":"unique, counts = np.unique(y_train, return_counts=True)\nplt.bar(unique, counts)\n\nunique, counts = np.unique(y_test, return_counts=True)\nplt.bar(unique, counts)\n\nplt.title('Class Frequency')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\n\nplt.show()","1be2e9c4":"from sklearn.linear_model import LogisticRegression\n\n# Instantiate model\nmodel_lr = LogisticRegression(max_iter=1000)","07d21b1e":"# Train model\nmodel_lr.fit(X_train,y_train)","cb5aceac":"# Get predictions\npred_lr = model_lr.predict(X_test)","4936c309":"roc_auc_score(y_test, pred_lr)","7e46fbe9":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report,confusion_matrix, precision_score, recall_score","fdc30dc6":"print(classification_report(y_test,pred_lr))\n\nprint('*'*30)\n\nprint(\"Confusion matrix:\\n\",confusion_matrix(y_test, pred_lr))","57d380e4":"perf = pd.DataFrame()","ff166458":"perf['Model'] = ['LogisticRegression']\nperf['ROC AUC'] = [roc_auc_score(y_test, pred_lr)]\nperf['F1-Score'] = [f1_score(y_test, pred_lr, average='weighted')]\nperf['Accuracy'] = [accuracy_score(y_test, pred_lr)]\nperf['Precision'] = [precision_score(y_test, pred_lr)]\nperf['Recall'] = [recall_score(y_test, pred_lr)]\n \nperf","fda7a4b7":"from sklearn.tree import DecisionTreeClassifier\n\nmodel_dt = DecisionTreeClassifier()","9af39ece":"# fit to data\nmodel_dt.fit(X_train,y_train)\n\n# get predictions\npred_dt = model_dt.predict(X_test)","438b620f":"new_row = {\n    'Model': 'DecisionTreeClassifier', \n    'ROC AUC': roc_auc_score(y_test, pred_dt), \n    'F1-Score':f1_score(y_test, pred_dt, average='weighted'), \n    'Accuracy': accuracy_score(y_test, pred_dt),\n    'Precision': precision_score(y_test, pred_dt),\n    'Recall' : recall_score(y_test, pred_dt)\n}\nperf = perf.append(new_row,ignore_index=True)\n\nperf","17ace377":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_rfc = RandomForestClassifier(n_estimators=100,verbose=0)\n\nmodel_rfc.fit(X_train,y_train)\n\npred_rfc = model_rfc.predict(X_test)","68cd8494":"new_row = {\n    'Model': 'RandomForestClassifier', \n    'ROC AUC': roc_auc_score(y_test, pred_rfc), \n    'F1-Score':f1_score(y_test, pred_rfc, average='weighted'), \n    'Accuracy': accuracy_score(y_test, pred_rfc),\n    'Precision': precision_score(y_test, pred_rfc),\n    'Recall' : recall_score(y_test, pred_rfc)\n}\nperf = perf.append(new_row,ignore_index=True)\n\nperf","d85f2fed":"n_features = X_train.shape[1]\nplt.barh(range(n_features), model_dt.feature_importances_, )\nplt.yticks(np.arange(n_features), X_train)\nplt.xlabel('Feature Importance')\nplt.ylabel('Feature')\nplt.show()","45d7f1d1":"model_dt.feature_importances_.argsort()","0db82e19":"importances = model_dt.feature_importances_\n\n# Sort feature importances in descending order\nindices = np.argsort(importances)[::-1]\n\n# Rearrange feature names so they match the sorted feature importances\nfeat = [X_train.columns[i] for i in indices]\n\nprint(indices , feat)\n\ntop_n_indx = indices[:10]\ntop_n_feat = feat[:10]\nprint(top_n_indx, top_n_feat)","a1c1208a":"# X_train.shape[1], len(X_train.columns[top_5])","7f9e2faf":"# Create plot\nplt.figure()\n\n# Create plot title\nplt.title(\"Feature Importance\")\n\n# Add bars\n# plt.bar(range(X_train.shape[1]), importances[indices])\n# plt.bar(range(X_train.columns[top_n]), importances[top_n])\nplt.bar(range(len(top_n_feat)), importances[top_n_indx])\n\n# Add feature names as x-axis labels\n# plt.xticks(range(X_train.shape[1]), feat, rotation=90)\n# plt.xticks(range(X_train.columns[top_n]), feat[top_n], rotation=90)\nplt.xticks(range(len(top_n_feat)), top_n_feat, rotation=90)\n\n# Show plot\nplt.show()\n\n\n# plt.barh(boston.feature_names[sorted_idx], perm_importance.importances_mean[sorted_idx])\n# plt.xlabel(\"Permutation Importance\")\n\n# plt.barh(range(n_features), model_dt.feature_importances_, )\n# plt.yticks(np.arange(n_features), X_train)\n# plt.xlabel('Feature Importance')\n# plt.ylabel('Feature')\n# plt.show()","04d8f8d4":"df[['ScheduledDay', 'AppointmentDay']].head()","91e39c1d":"df['wait_time'] = df[\"AppointmentDay\"].sub(df[\"ScheduledDay\"], axis=0)","19e29217":"df[['ScheduledDay', 'AppointmentDay', 'wait_time']].head()","245baf77":"df[\"wait_time\"] = (df[\"wait_time\"] \/ np.timedelta64(1, 'D')).abs()\ndf[['ScheduledDay', 'AppointmentDay', 'wait_time']].head()","60450cac":"X = df.drop(['No-show','ScheduledDay', 'AppointmentDay'],axis=1) # Features\ny = df['No-show']  # Labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test","cf965104":"X_train.head()","8d701b6d":"# Instantiate model\nmodel_lr = LogisticRegression(max_iter=1000)\nmodel_dt = DecisionTreeClassifier()\nmodel_rfc = RandomForestClassifier(n_estimators=100,verbose=0)\n\n# Train model\nmodel_lr.fit(X_train,y_train)\nmodel_dt.fit(X_train,y_train)\nmodel_rfc.fit(X_train,y_train)\n\n# Get predictions\npred_lr = model_lr.predict(X_test)\npred_dt = model_dt.predict(X_test)\npred_rfc = model_rfc.predict(X_test)\n","7f110457":"new_row = {\n    'Model': 'LogisticRegression with WaitTime', \n    'ROC AUC': roc_auc_score(y_test, pred_lr), \n    'F1-Score':f1_score(y_test, pred_lr, average='weighted'), \n    'Accuracy': accuracy_score(y_test, pred_lr),\n    'Precision': precision_score(y_test, pred_lr),\n    'Recall' : recall_score(y_test, pred_lr)\n}\nperf = perf.append(new_row,ignore_index=True)\n\nnew_row = {\n    'Model': 'DecisionTreeClassifier with WaitTime', \n    'ROC AUC': roc_auc_score(y_test, pred_dt), \n    'F1-Score':f1_score(y_test, pred_dt, average='weighted'), \n    'Accuracy': accuracy_score(y_test, pred_dt),\n    'Precision': precision_score(y_test, pred_dt),\n    'Recall' : recall_score(y_test, pred_dt)\n}\nperf = perf.append(new_row,ignore_index=True)\n\nnew_row = {\n    'Model': 'RandomForestClassifier with WaitTime', \n    'ROC AUC': roc_auc_score(y_test, pred_rfc), \n    'F1-Score':f1_score(y_test, pred_rfc, average='weighted'), \n    'Accuracy': accuracy_score(y_test, pred_rfc),\n    'Precision': precision_score(y_test, pred_rfc),\n    'Recall' : recall_score(y_test, pred_rfc)\n}\nperf = perf.append(new_row,ignore_index=True)\n\n\nperf","39355507":"## 3. Random Forest","02c8ec37":"As shown above, \n1. Gender does not seem to affect whether a person shows up to an appointment or not, as both males and females don't show up to approximately 20 percent of their appointments. \n\n2. Alcoholism don't seem to affect no-shows as well.\n\n3. Hypertension and Diabetes seems to have a small affect, as a patient who has hypertension is 3% more likely to show up than a patient who doesn't have hyper tension.\n4. Patients who received a text reminder did not show up to 27% person of their appointments, where as patients who did not receive a text reminder did not show up to ~17% of their appointments.","d1006f9e":"There are various evaluation metric for Classification Problem, such as classification_report,confusion_matrix, roc auc curve etc.\n\nFor now i am going with ROC AUR Curve.","6107be78":"# Evaluation ","97ee861e":"Just to have a feel of other evaluation metrics","6d2c006a":"## 1. Logistic Regression","525995b7":"# Important Feature","41a5c295":"## 2. Decsion Tree","35804fd2":"# Split the data into Train and Set","eb674b58":"The model is 74 % accuracate on the test set, which is an improvement of 2% better than a DT model.\n\nRecall: Out of the ones that did not show up, how many did we predict correctly? x %\n\nPrecision: Out of the ones our model said will not show up, how many didn't ? x %","793ac56e":"Though I did not understand all these neighbourhood, but they sems to be correct and no duplicate except for 'SANTA LU\u00cdZA' and 'SANTA L\u00daCIA'. Not sure if they are different or typo. For now considering it as different and proceeding.","53702a96":"# Medical Appointment No Shows\nRefer to link for details on the dataset.\n\nhttps:\/\/www.kaggle.com\/joniarroba\/noshowappointments \n\nA person makes a doctor appointment, receives all the instructions and no-show. Who to blame?\nIf this help you studying or working, please don\u00b4t forget to upvote :). Reference to Joni Hoppen and Aquarela Advanced Analytics Aquarela\n\nGreetings!\n\nContent\n110.527 medical appointments its 14 associated variables (characteristics). The most important one if the patient show-up or no-show to the appointment. Variable names are self-explanatory.\n\n","fcf6fc93":"## Class DIstribution","b05002ca":"Till now all categorical features looks good. Lets check for `Age`.","c1eacf8f":"Cool Gender feature has two values.","31e3c8bb":"# Encoding\n\n## Encoding the Categorical Features\n1. Target (No-show)\n2. Gender\n3. Neighbourhood\n4. AppointmentDayofWeek\n5. ScheduledDayofWeek","15263420":"# EDA - Exploratory Data Analysis","6ac7378f":"# Visualize","0a2c84df":"There are 6 records, so we should be good to drop the data poits for now. They might be genuine, but for now dropping them. ","fc61652e":"The model is 73 % accuracate on the test set, which is an not good and decrement of 6% down than a LR model.\n\nRecall: Out of the ones that did not show up, how many did we predict correctly? 10 %\n\nPrecision: Out of the ones our model said will not show up, how many didn't ? 31 %","bdd605be":"## Gender Vs No-show","75efddb1":"Observation : \n1. Some of the column \/ feature name has typo. Like feature `Handcap` i think it meant to say `Handicap`, feature `Hipertension` should be `Hypertension`. But it will not matters a lot, however we should be knwoing about this.\n2. Feature `PatientId` is of float type, ideally ID should be of Integer type. Again this should not matter a lot as Patient ID is unique and will not be using it for training.\n3. Feature `AppointmentID` is again Unique and an randomly generated number for a patient while making an appointment. Will not be using it for training.\n4. Features such as `ScheduledDay` and `AppointmentDay` are DateTime, but showing as Object, so we may have to convert it to DateTime. Also will split this into Month; Day and Hour to work on it better.","5eb06879":"# Create Model ","b5d14b45":"## Neighbourhood Vs No-show","ca8885be":"oops we do have min age as -1 and max as 115. Which looks fishy.","dfad4d12":"## Class distribution of Train and Test","b40b22c2":"Other features can work on are Age, by considering the group of ages.\netc.","6da32d48":"There are many categorical features... lets check them one by one.","6b758176":"So out of 110527, 22319 (which is 20%) patients didn't show up to their appointment, and 80% of patient do show up.","60d01436":"As mentioned total data observation are 110527, and from above we could see that there are no missing values.","b6e739a4":"# Load DataSet","c5cfd5a2":"# Import Libraries.","f7d16316":"The Logistic Regression model is 79% accuracate on the test set.\n\nRecall: Out of the ones that did not show up, how many did we predict correctly? 10 %\n\nPrecision: Out of the ones our model said will not show up, how many didn't ? 35 %","06b65c7d":"We have to do more feature engineering.\n\nOne of the another thing to consider is **Wait Time**.\nUsually or in my opnion, if I schedule an appointment far in advance and no one reminds me, I tend to forget about it. Or by the time my appointment day arrives, I feel better and don't bother showing up. \n\nIn this section, I will create a variable called \"wait_time\" to see if the time between the date an appointment was scheduled and the date was the appointment is, has an affect on no-shows."}}