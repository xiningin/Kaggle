{"cell_type":{"84c288f9":"code","a3613b28":"code","1e4dd7c6":"code","ac0a8ffd":"code","42e367f4":"code","6a5fc28f":"code","f154be08":"code","7448cb9b":"code","7804de08":"code","6d5366bf":"code","2e4c2f21":"code","6706ea53":"code","805954fd":"code","12d28635":"code","fb222904":"code","7f361d72":"code","828a5c65":"code","b70913d6":"code","2816ddbc":"code","0a1a2e02":"code","15782598":"code","0e819e4a":"code","2f21ff85":"code","e17d77a3":"code","2d18547d":"code","d4533360":"code","fb06cb07":"code","db06e827":"code","4619b2bd":"code","2180d8cf":"code","775c0208":"code","4a75347f":"code","b056aca0":"code","f96e9354":"code","4897d1a0":"code","93a25311":"code","3e60663d":"code","c8ec7c7f":"code","1d4195ec":"code","e0ffa507":"code","d3b85b54":"code","f024ec77":"code","6fedd6e0":"code","6790d8f3":"code","689a3b29":"code","9ee9e15e":"code","eb1e9fba":"code","a9fd282e":"code","e5ecd9e4":"code","90e0d0fb":"code","ed2ce4bc":"code","3991f882":"code","511b85aa":"markdown","9f94f627":"markdown","334d0790":"markdown","c629c7a1":"markdown","df3a7087":"markdown","fb8312f5":"markdown","6feb3a6a":"markdown","aa014631":"markdown","88f12732":"markdown","22351611":"markdown","aff43dfd":"markdown","eeb09197":"markdown","702b8f3e":"markdown","d438ebab":"markdown","d89f2dff":"markdown"},"source":{"84c288f9":"import numpy as np \nimport pandas as pd \nfile_dirs = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file_dirs.append((os.path.join(dirname, filename)))\n","a3613b28":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv',index_col = 'PassengerId')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv',index_col = 'PassengerId')\ncmp_data = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntrain_data.describe()","1e4dd7c6":"train_data.head()","ac0a8ffd":"import matplotlib.pyplot as plt\nimport seaborn as sns","42e367f4":"train_data.isna().sum()","6a5fc28f":"train_data.drop('Cabin',inplace=True,axis=1)\ntest_data.drop('Cabin',inplace=True,axis=1)","f154be08":"sns.set_style('darkgrid')\nplt.figure(figsize=(15,9))\nax = sns.distplot(train_data.Age)\nax.set_title(\"Age Distribution\",fontsize=15)\nplt.legend(['Skew: {:.2} , Kurt:{:.2} '.format(train_data.Age.skew(),train_data.Age.kurt())])\nplt.show()","7448cb9b":"plt.figure(figsize=(15,9))\nsns.regplot(train_data['Age'],train_data['Fare'])\nplt.show()","7804de08":"plt.figure(figsize=(15,9))\nsns.scatterplot(train_data['Age'],train_data['Fare'],hue=train_data['Parch'])\nplt.show()","6d5366bf":"plt.figure(figsize=(15,9))\nsns.barplot(y=train_data['Age'],x=train_data['Parch'],hue=train_data['Sex'])\nplt.show()","2e4c2f21":"plt.figure(figsize=(15,9))\nax = sns.scatterplot(y=train_data['Fare'],x=train_data['Age'],hue=train_data['Survived'])\nax.set_title('Survival Depending On Fare Amount And Age')\nplt.show()","6706ea53":"from sklearn.linear_model import LinearRegression","805954fd":"#for our train_data\nmissing_age_samepls = train_data[train_data.Age.isna()].copy()\nnot_missing_age = train_data[~train_data.Age.isna()].copy()\n\nnot_missing_age.Sex.replace({'female':0,'male':1},inplace=True)\nmissing_age_samepls.Sex.replace({'female':0,'male':1},inplace=True)\n\nmodel = LinearRegression()\n\nmodel.fit(not_missing_age[['Sex','Fare','Parch']],not_missing_age['Age'])\nage_predictions = model.predict(missing_age_samepls[['Sex','Fare','Parch']])\nmissing_age_samepls['Age'] = age_predictions\n\ntrain_data.loc[train_data.Age.isna(),'Age'] = age_predictions\ntrain_data.Embarked.fillna('S',inplace=True)","12d28635":"#for out test data \ntest_data.Fare.fillna(test_data.Fare.mean(),inplace=True)\nmissing_age_samepls = test_data[test_data.Age.isna()].copy()\nnot_missing_age = test_data[~test_data.Age.isna()].copy()\n\nnot_missing_age.Sex.replace({'female':0,'male':1},inplace=True)\nmissing_age_samepls.Sex.replace({'female':0,'male':1},inplace=True)\n\nmodel = LinearRegression()\n\nmodel.fit(not_missing_age[['Sex','Fare','Parch']],not_missing_age['Age'])\nage_predictions = model.predict(missing_age_samepls[['Sex','Fare','Parch']])\nmissing_age_samepls['Age'] = age_predictions\n\ntest_data.loc[test_data.Age.isna(),'Age'] = age_predictions\n","fb222904":"train_data.isna().sum()","7f361d72":"test_data.isna().sum()","828a5c65":"train_data.replace({'male':1,'female':0},inplace=True)\ntest_data.replace({'male':1,'female':0},inplace=True)","b70913d6":"correlation = train_data.corr()\nplt.figure(figsize=(15,9))\nax = sns.heatmap(correlation,cmap='PiYG_r',annot=True)","2816ddbc":"plt.figure(figsize=(14,8))\nax =sns.countplot(x=train_data['Sex'],hue=train_data['Survived'])\nax.set_title('Survival Rate Depending On Gendder',fontsize=15)\nplt.show()","0a1a2e02":"plt.figure(figsize=(14,8))\nax =sns.countplot(train_data['Parch'],palette='GnBu',alpha=1)\nax2 =sns.countplot(train_data['SibSp'],alpha=1)\nplt.show()","15782598":"plt.figure(figsize=(14,8))\nax =sns.countplot(train_data['Embarked'],palette='GnBu',alpha=1)","0e819e4a":"train_data.replace({'S':2,'C':1,'Q':0},inplace=True)\ntest_data.replace({'S':2,'C':1,'Q':0},inplace=True)","2f21ff85":"age_groups = pd.cut(train_data.Age,6,labels=['0-13','14-26','27-40','41-53','54-66','67-80'])\ntrain_data['Age Group'] = age_groups\nage_groups_2 = pd.cut(test_data.Age,6,labels=['0-13','14-26','27-40','41-53','54-66','67-80'])\ntest_data['Age Group'] = age_groups_2\ntest_data","e17d77a3":"plt.figure(figsize=(14,8))\nax = sns.countplot(x=train_data['Survived'],hue=train_data['Age Group'])\nax.set_title('Amount Of Survivers And Not Survivers Per Age Group',fontsize=15)\nax.set_xticklabels(['Did Not Survive','Survived'])\nplt.show()","2d18547d":"train_data['Age Group'] = train_data['Age Group'].astype('category').cat.codes\ntest_data['Age Group'] = test_data['Age Group'].astype('category').cat.codes\ntrain_data","d4533360":"plt.figure(figsize=(20,11))\nax = sns.boxplot(x=train_data['Pclass'],y=train_data['Fare'],hue = train_data['Survived'])","fb06cb07":"train_data = train_data[train_data['Fare'] < 120]\ntrain_data = train_data[train_data['Age'] < 55]\n","db06e827":"pclass_d = pd.get_dummies(train_data.Pclass,prefix='Pclass_')\nage_g_d = pd.get_dummies(train_data['Age Group'],prefix='Age_Group_')\nparch_d = pd.get_dummies(train_data['Parch'],prefix='Parch_')\n\npclass_d = pclass_d[pclass_d.columns[:2]]\nage_g_d = age_g_d[age_g_d.columns[:4]]\nparch_d = parch_d[parch_d.columns[:5]]\n\ntrain_data = pd.concat([train_data,pclass_d,age_g_d,parch_d],axis=1)\n\npclass_d = pd.get_dummies(test_data.Pclass,prefix='Pclass_')\nage_g_d = pd.get_dummies(test_data['Age Group'],prefix='Age_Group_')\nparch_d = pd.get_dummies(test_data['Parch'],prefix='Parch_')\n\npclass_d = pclass_d[pclass_d.columns[:2]]\nage_g_d = age_g_d[age_g_d.columns[:4]]\nparch_d = parch_d[parch_d.columns[:5]]\n\ntest_data = pd.concat([test_data,pclass_d,age_g_d,parch_d],axis=1)\ntest_data\n\n","4619b2bd":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC","2180d8cf":"correlation = train_data.corr()\nplt.figure(figsize=(30,14))\nax = sns.heatmap(correlation,cmap='PiYG_r',annot=True)\n","775c0208":"#The Features will use for prediction \nfrom sklearn.feature_selection import SelectKBest,chi2\nn_fets = 5\nfets = [fet for fet in train_data.columns[3:] if fet  != 'Ticket']\n#features = ['Fare','Age Group','SibSp','Pclass','Parch','Sex','Age']\nselector = SelectKBest(chi2,k=n_fets)\nX = selector.fit_transform(train_data[fets],train_data['Survived'])\ny = train_data['Survived']\n\nselected_feaures = train_data[fets].iloc[:,list(selector.get_support(indices=True))].columns.to_list()\nselected_feaures","4a75347f":"train_x,test_x,train_y,test_y = train_test_split(X,y)","b056aca0":"#scaler = StandardScaler()\n#train_x = scaler.fit_transform(train_x)\n#test_x = scaler.fit_transform(test_x)","f96e9354":"def RandomForest_Optimal_n(train_x,test_x,train_y,test_y,n_list):\n    result = []\n    for n in n_list:\n        model = RandomForestClassifier(random_state=42,n_estimators=n,max_leaf_nodes=25)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        result.append(f1(pred,test_y))\n    return result","4897d1a0":"RF_results = RandomForest_Optimal_n(train_x,test_x,train_y,test_y,[5,10,30,50,100,130,150,200,350])\nRF_results\nplt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(9),y=RF_results)\nax.set_xlabel('Number Of Estimators',fontsize=13)\nax.set_ylabel('Accuracy Score',fontsize=13)\ny_pos = RF_results.index(max(RF_results))\nx_pos = np.arange(9)[y_pos]\nax.plot(np.arange(9)[x_pos],RF_results[x_pos],'r*',label='Best Score',ms=15)\nax.set_xticklabels([-1,5,10,30,50,100,130,150,200,350])\nax.legend()\nplt.show()","93a25311":"def KNN_Optimal_n(train_x,test_x,train_y,test_y,n_list):\n    result = []\n    for n in n_list:\n        model = KNeighborsClassifier(n_neighbors=n)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        result.append(f1(pred,test_y))\n    return result","3e60663d":"KNN_results = KNN_Optimal_n(train_x,test_x,train_y,test_y,[1,2,5,8,10,20,35,42,50])\nKNN_results\nplt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(9),y=KNN_results)\nax.set_xlabel('Number Of Estimators',fontsize=13)\nax.set_ylabel('Accuracy Score',fontsize=13)\ny_pos = KNN_results.index(max(KNN_results))\nx_pos = np.arange(9)[y_pos]\nax.plot(np.arange(9)[x_pos],KNN_results[x_pos],'r*',label='Best Score',ms=15)\nax.set_xticklabels([-1,1,2,5,8,10,20,35,42,50])\nax.legend()\nplt.show()","c8ec7c7f":"def SVM_Optimal_C(train_x,test_x,train_y,test_y,n_list):\n    result = []\n    for n in n_list:\n        model = SVC(C=n,kernel='poly')\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        result.append(f1(pred,test_y))\n    return result","1d4195ec":"SVM_results = SVM_Optimal_C(train_x,test_x,train_y,test_y,[1,2,5,20,35,42,50])\nSVM_results\nplt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(7),y=SVM_results)\nax.set_xlabel('Number Of Estimators',fontsize=13)\nax.set_ylabel('Accuracy Score',fontsize=13)\ny_pos = SVM_results.index(max(SVM_results))\nx_pos = np.arange(7)[y_pos]\nax.plot(np.arange(7)[x_pos],SVM_results[x_pos],'r*',label='Best Score',ms=15)\nax.set_xticklabels([-1,1,2,5,20,35,42,50])\nax.legend()\nplt.show()","e0ffa507":"def ADA_Optimal_n(train_x,test_x,train_y,test_y,n_list):\n    result = []\n    for n in n_list:\n        model = AdaBoostClassifier(n_estimators=n,learning_rate=0.6)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        result.append(f1(pred,test_y))\n    return result","d3b85b54":"ADA_results = ADA_Optimal_n(train_x,test_x,train_y,test_y,[1,2,5,20,35,42,50])\nADA_results\nplt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(7),y=ADA_results)\nax.set_xlabel('Number Of Estimators',fontsize=13)\nax.set_ylabel('Accuracy Score',fontsize=13)\ny_pos = ADA_results.index(max(ADA_results))\nx_pos = np.arange(7)[y_pos]\nax.plot(np.arange(7)[x_pos],ADA_results[x_pos],'r*',label='Best Score',ms=15)\nax.set_xticklabels([-1,1,2,5,20,35,42,50])\nax.legend()\nplt.show()","f024ec77":"def DT_Optimal_n(train_x,test_x,train_y,test_y,n_list):\n    result = []\n    for n in n_list:\n        model = DecisionTreeClassifier(criterion='entropy',max_leaf_nodes=n,splitter='random',\n                                      random_state=42)\n        model.fit(train_x,train_y)\n        pred = model.predict(test_x)\n        result.append(model.score(test_x,test_y))\n    return result","6fedd6e0":"DT_results = DT_Optimal_n(train_x,test_x,train_y,test_y,[2,3,5,7,20,35,42,50])\nDT_results\nplt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(8),y=DT_results)\nax.set_xlabel('Number Of Estimators',fontsize=13)\nax.set_ylabel('Accuracy Score',fontsize=13)\ny_pos = DT_results.index(max(DT_results))\nx_pos = np.arange(8)[y_pos]\nax.plot(np.arange(8)[x_pos],DT_results[x_pos],'r*',label='Best Score',ms=15)\nax.set_xticklabels([-1,2,3,5,7,20,35,42,50])\nax.legend()\nplt.show()","6790d8f3":"from keras.layers import Dense\nfrom keras.models import Sequential\n","689a3b29":"model = Sequential()\nmodel.add(Dense(64,activation='sigmoid',input_dim=n_fets))\nmodel.add(Dense(36,activation='sigmoid'))\nmodel.add(Dense(64,activation='sigmoid'))\nmodel.add(Dense(8,activation='sigmoid'))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')","9ee9e15e":"pred = model.predict(test_x)\nprint(classification_report(np.round(pred),test_y))","eb1e9fba":"plt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(350\/15),y=history.history['accuracy'][::15],color='g',label='Accuracy Growth')\nax.set_title('Neural Network Learning Process On Train\/Test Data',fontsize=15)\nax.set_xlabel=('# Epoch \/ 15')\nax.set_ylabel=('Accuracy')\nax.legend(loc =2 ,prop={'size':16})\nplt.show()","a9fd282e":"all_data_fit = model.fit(X,y,epochs=350)","e5ecd9e4":"plt.figure(figsize=(15,8))\nax = sns.lineplot(x=np.arange(350\/15),y=all_data_fit.history['accuracy'][::15],color='g',label='Accuracy Growth')\nax.set_title('Neural Network Learning Process On The Entire DataSet',fontsize=15)\nax.set_xlabel=('# Epoch \/ 15')\nax.set_ylabel=('Accuracy')\nax.legend(loc =2 ,prop={'size':16})\nplt.show()","90e0d0fb":"from sklearn.ensemble import VotingClassifier\n","ed2ce4bc":"final_prediction = model.predict(test_data[selected_feaures])\ndt_model = DecisionTreeClassifier(criterion='entropy',max_leaf_nodes=20,splitter='random',random_state=42)\nada_model = AdaBoostClassifier(n_estimators=5,learning_rate=0.6)\nRF_model = RandomForestClassifier(random_state=42,n_estimators=300,max_leaf_nodes=25)\n\n","3991f882":"fcnn_prediction = np.round(final_prediction)\nvc = VotingClassifier(estimators = [('RF',RF_model),('ada',ada_model),('dt',dt_model)],voting='hard',weights=[0.2,0.1,0.7])\nvc.fit(X,y)\n\nfinal_prediction = vc.predict(test_data[selected_feaures])\n\nfinal_prediction = final_prediction.astype(np.int16)\n\n\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = final_prediction\nsubmission.to_csv('submission.csv', index=False)\n\n","511b85aa":"## We will use LinearRegression to fill in the missing ages","9f94f627":"## Here we see that older males and females have higher parch value it can help us estimate the right age for a sample that has a missing age, we will use the sex features together with the fare feature and the parch to get an approximation for the age","334d0790":"### We See that females are more likley to survive so it can be a good indicator in our model","c629c7a1":"## Removal Of Outliers","df3a7087":"## Now that we took care of the missing ages and other missing data we can continue our EDA and try and get feel for some patterns of correlations in our data","fb8312f5":"# Model Selection And Evaluation","6feb3a6a":"## The features that have the higher correlation in our data when looking at the correlation against Survived are 'Embarked' , 'Fare','Pclass' also we saw in our EDA that Sex is an fair indicator of survival as more females survived then males.","aa014631":"## Let Start With An EDA","88f12732":"## We see that we have some fair correlation that we can work with in our classification\nlets see if we can create some feature to boost our classification","22351611":"# So we tested a few classification models and saw that surprisingly\u200b the more 'simple' decision tree algorithm did the best job with an average accuracy score of 0.8 , before creating our production model lets see if we can create a neural network that will overscore the decision tree model ","aff43dfd":"## Here we see that as for survivors there is an increase in survival rate up to age 40 and the probability of survival drops as the individual gets older towards  80","eeb09197":"## Most passengers embarked at Southampton","702b8f3e":"### So we see we have 177 samples with missing age ,and 687 almost 3\/4 of our samepls missing there Cabin information. as for the cabin information it will be no use to us and this feature will be droped but lets see the distribution of our ages and find out whats the best cource of action to tackle the missing values","d438ebab":"### Categorical Encoding","d89f2dff":"# Finaly lets stack our best models in order to form our final prediciton"}}