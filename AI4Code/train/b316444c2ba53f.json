{"cell_type":{"c34e3f58":"code","87f8fec7":"code","9366e82f":"code","65d2ebf1":"code","4e6a88ef":"code","0d23a08a":"code","70c679f5":"code","7ca76532":"code","e99feb50":"code","ceae38f8":"code","a9c90c6d":"code","044b83fb":"markdown","45166655":"markdown","b80b4a73":"markdown","cfc17527":"markdown"},"source":{"c34e3f58":"import os\nfrom glob import glob\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nVIDEO_DIR = os.path.join('..', 'input', 'highway-traffic-videos-dataset', 'video' )","87f8fec7":"from PIL import Image\nfrom IPython.display import display","9366e82f":"def read_video_segment(in_path, vid_seg = None):\n    cap = cv.VideoCapture(in_path)\n    video_length = int(cap.get(cv.CAP_PROP_FRAME_COUNT)) - 1\n    frames = []\n    if cap.isOpened() and video_length > 0:\n        frame_ids = [0]\n        if vid_seg is None:\n            vid_seg = np.array([0, 0.25, 0.5, 0.75, 1])\n        else:\n            vid_seg = np.clip(vid_seg, 0, 1)\n            \n        frame_ids = np.clip(video_length*vid_seg, 0, video_length-1).astype(int)\n        count = 0\n        success, image = cap.read()\n        print('Loaded', video_length, 'frames at', image.shape, 'resolution')\n        while success:\n            if count in frame_ids:\n                frames.append(image)\n            success, image = cap.read()\n            count += 1\n    return frames","65d2ebf1":"vpath= os.path.join( VIDEO_DIR, 'cctv052x2004080516x01638.avi' )\nframes = read_video_segment( vpath )","4e6a88ef":"print( len(frames) )\nprint( frames[0].shape )\nimg_0 = frames[2]\nimg_1 = frames[3]\nout_image = cv.cvtColor( img_0, cv.COLOR_BGR2RGB)\ndisplay(Image.fromarray(img_0))\nout_image = cv.cvtColor( img_1, cv.COLOR_BGR2RGB)\ndisplay(Image.fromarray(img_1))","0d23a08a":"def cart_and_polar_flow( image_0, image_1, tuner ):\n    flow = cv.calcOpticalFlowFarneback( image_0[..., 0], image_1[..., 0], *tuner )\n    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n    hsv         = np.zeros( flow[..., 0].shape + (3,) )\n    hsv [..., 0] = ang*180\/np.pi\/2\n    hsv [..., 1] = 255\n    hsv [..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n    \n    # normalizing of displacement\n    mx = max( flow.max(), -flow.min() )\n    n_flow = np.uint8((flow +mx) \/ mx *127 )\n    \n    polar  = cv.cvtColor( np.uint8(hsv ), cv.COLOR_HSV2BGR)\n    return n_flow, polar\n\nprint(img_0.shape)","70c679f5":"config_smooth = (None, 0.5, 3,  25,  3, 5, 1.0, cv.OPTFLOW_FARNEBACK_GAUSSIAN )\n(flow_1, bgr_1) = cart_and_polar_flow( img_0, img_1, config_smooth )\n\nflow_1 = np.concatenate( (flow_1, flow_1[...,0:1]), axis=2 )\nflow_1 = cv.cvtColor( flow_1, cv.COLOR_BGR2RGB)\nbgr_1  = cv.cvtColor( bgr_1,  cv.COLOR_BGR2RGB)\n\ndisplay(Image.fromarray(flow_1))","7ca76532":"display(Image.fromarray(bgr_1))","e99feb50":"import random\n# OpenCV magic\ndef sparse_flow( old_frame, frame ):\n    # params for ShiTomasi corner detection\n    feature_params = dict( maxCorners = 100,\n                           qualityLevel = 0.3,\n                           minDistance = 7,\n                           blockSize = 7 )\n    # Parameters for lucas kanade optical flow\n    lk_params = dict( winSize  = (15, 15),\n                      maxLevel = 2,\n                      criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    \n    old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n\n    p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n    print ( \"good features found: \", p0.shape)\n    #print (p0)\n    # Create a mask image for drawing purposes\n    mask = np.zeros_like(old_frame)\n    \n    p1, st, err =  cv.calcOpticalFlowPyrLK( old_frame, frame, p0, None, **lk_params  )\n    # Select good points\n    if p1 is not None:\n        good_new = p1[st==1]\n        good_old = p0[st==1]\n    # draw the tracks\n    for i, (new, old) in enumerate(zip(good_new, good_old)):\n        a, b = new.ravel()\n        c, d = old.ravel()\n        mask = cv.line(np.zeros_like(frame), \n                       (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n        frame = cv.circle(frame, (int(a), int(b)), 1, color[i].tolist(), -1)\n        frame = cv.add(frame, mask)\n    return np.uint8(frame)","ceae38f8":"img_painted = sparse_flow( img_0, img_1 )\ndisplay(Image.fromarray(  img_painted  ))\nprint(\"Ugh!\")","a9c90c6d":"img_painted = sparse_flow( img_0[50:220], img_1[50:220] )\ndisplay(Image.fromarray(  img_painted  ))\nimg_painted = sparse_flow( img_1[50:220], img_0[50:220] )\ndisplay(Image.fromarray(  img_painted  ))\nprint(\"That's better.\")","044b83fb":"Now sparse optical flow with Lucas-Kanade algorithm","45166655":"Some dense optical flow with OpenCV implementation of Farneback algorithm. Based on\nhttps:\/\/docs.opencv.org\/3.4\/d4\/dee\/tutorial_optical_flow.html","b80b4a73":"That was unexpected, 'goodFeaturesToTrack' totally sticks to synthetic text in frame. Below I just cut frame parts with text.","cfc17527":"dataset provided with\nA. B. Chan and N. Vasconcelos, \"Probabilistic Kernels for the Classification of Auto-Regressive Visual Processes\".  Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, San Diego, 2005.\n\nNow I'm trying it for optical flow expirements\n\nVideo reading adopted from here: https:\/\/www.kaggle.com\/kmader\/drone-flight-path\/notebook"}}