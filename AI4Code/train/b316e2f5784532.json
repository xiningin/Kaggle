{"cell_type":{"aefe6586":"code","4033400e":"code","58fb84ae":"code","f935f1a3":"code","6cefc77d":"code","7703485b":"code","f843ff56":"code","db910926":"code","6ff953c8":"code","4b9d41b3":"code","b08fec68":"code","cc4ea793":"code","bb9de030":"code","5eb025e1":"code","a9750feb":"code","ffd340eb":"markdown"},"source":{"aefe6586":"FAST_RUN = False #False#True ## if true, run with 223k rows for faster debugging\n\nif FAST_RUN:\n    n_splits = 3\nelse:\n    n_splits = 5","4033400e":"%%time\nimport pandas as pd\nimport numpy as np\nif FAST_RUN:\n    train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\",nrows=223456)\nelse:\n    train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/sample_submission.csv\")\ntrain\n\nfeatures = [\"R\", \"C\", \"time_step\", \"u_in\", \"u_out\"]\ntarget = train[\"pressure\"]","58fb84ae":"train","f935f1a3":"train.head(200000).describe().round(2)","6cefc77d":"train.head(100000)[\"breath_id\"].value_counts().describe() ## ~Most all series have 80 time steps","7703485b":"### we see that R,C are fixed for a given breath id - no point in making TS feats from them\ntrain.head(100000).groupby(\"breath_id\").std().describe()","f843ff56":"train.dtypes","db910926":"def add_feats(train):\n    # # rewritten calculation of lag features from this notebook: https:\/\/www.kaggle.com\/patrick0302\/add-lag-u-in-as-new-feat\n# # some of ideas from this notebook: https:\/\/www.kaggle.com\/mst8823\/google-brain-lightgbm-baseline\n    # train[[\"15_out_mean\"]] = train.groupby('breath_id')['u_out'].rolling(window=15,min_periods=1).agg({\"15_out_mean\":\"mean\"}).reset_index(level=0,drop=True)\n    train['last_value_u_in'] = train.groupby('breath_id')['u_in'].transform('last')\n    train['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1)\n    train['u_out_lag1'] = train.groupby('breath_id')['u_out'].shift(1)\n    train['u_in_lag_back1'] = train.groupby('breath_id')['u_in'].shift(-1)\n    train['u_out_lag_back1'] = train.groupby('breath_id')['u_out'].shift(-1)\n    train['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\n    train['u_out_lag2'] = train.groupby('breath_id')['u_out'].shift(2)\n    train['u_in_lag3'] = train.groupby('breath_id')['u_in'].shift(3)\n    train['u_out_lag3'] = train.groupby('breath_id')['u_out'].shift(3)\n    train['u_in_lag_back2'] = train.groupby('breath_id')['u_in'].shift(-2)\n    train['u_out_lag_back2'] = train.groupby('breath_id')['u_out'].shift(-2)\n    train['u_in_lag_back3'] = train.groupby('breath_id')['u_in'].shift(-3)\n    train['u_out_lag_back3'] = train.groupby('breath_id')['u_out'].shift(-3)\n    train['u_in_lag_back10'] = train.groupby('breath_id')['u_in'].shift(-10)\n    train['u_out_lag_back10'] = train.groupby('breath_id')['u_out'].shift(-10)\n\n    train['u_in_first'] = train.groupby('breath_id')['u_in'].first()\n    train['u_out_first'] = train.groupby('breath_id')['u_out'].first()\n\n    ## time since last step\n    train['time_step_diff'] = train.groupby('breath_id')['time_step'].diff().fillna(0)\n    ### rolling window ts feats\n    train['ewm_u_in_mean'] = train.groupby('breath_id')['u_in'].ewm(halflife=9).mean().reset_index(level=0,drop=True)\n    train['ewm_u_in_std'] = train.groupby('breath_id')['u_in'].ewm(halflife=10).std().reset_index(level=0,drop=True) ## could add covar?\n    train['ewm_u_in_corr'] = train.groupby('breath_id')['u_in'].ewm(halflife=15).corr().reset_index(level=0,drop=True) # self umin corr\n    # train['ewm_u_in_corr'] = train.groupby('breath_id')['u_in'].ewm(halflife=6).corr(train.groupby('breath_id')[\"u_out\"]).reset_index(level=0,drop=True) # corr with u_out # error\n    ## rolling window of 15 periods\n    train[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\",\"15_out_std\"]] = train.groupby('breath_id')['u_in'].rolling(window=15,min_periods=1).agg({\"15_in_sum\":\"sum\",\"15_in_min\":\"min\",\"15_in_max\":\"max\",\"15_in_mean\":\"mean\",\"15_in_std\":\"std\"}).reset_index(level=0,drop=True)\n#     train[[\"45_in_sum\",\"45_in_min\",\"45_in_max\",\"45_in_mean\",\"45_out_std\"]] = train.groupby('breath_id')['u_in'].rolling(window=45,min_periods=1).agg({\"45_in_sum\":\"sum\",\"45_in_min\":\"min\",\"45_in_max\":\"max\",\"45_in_mean\":\"mean\",\"45_in_std\":\"std\"}).reset_index(level=0,drop=True)\n    train[[\"45_in_sum\",\"45_in_min\",\"45_in_max\",\"45_in_mean\",\"45_out_std\"]] = train.groupby('breath_id')['u_in'].rolling(window=45,min_periods=1).agg({\"45_in_sum\":\"sum\",\"45_in_min\":\"min\",\"45_in_max\":\"max\",\"45_in_mean\":\"mean\",\"45_in_std\":\"std\"}).reset_index(level=0,drop=True)\n\n    train[[\"15_out_mean\"]] = train.groupby('breath_id')['u_out'].rolling(window=15,min_periods=1).agg({\"15_out_mean\":\"mean\"}).reset_index(level=0,drop=True)\n\n    print(train.shape[0])\n    display(train)\n    train = train.fillna(0) # ORIG\n\n    # max, min, mean value of u_in and u_out for each breath\n    train['breath_id__u_in__max'] = train.groupby(['breath_id'])['u_in'].transform('max')\n    train['breath_id__u_out__max'] = train.groupby(['breath_id'])['u_out'].transform('max')\n\n    train['breath_id__u_out__mean'] =train.groupby(['breath_id'])['u_out'].mean()\n    train['breath_id__u_in__mean'] =train.groupby(['breath_id'])['u_in'].mean()\n\n    train['breath_id__u_in__min'] = train.groupby(['breath_id'])['u_in'].transform('min')\n    train['breath_id__u_out__min'] = train.groupby(['breath_id'])['u_out'].transform('min')\n\n    train['R_div_C'] = train[\"R\"].div(train[\"C\"])\n\n    # difference between consequitive values\n    train['R__C'] = train[\"R\"].astype(str) + '__' + train[\"C\"].astype(str)\n    train['u_in_diff1'] = train['u_in'] - train['u_in_lag1']\n    train['u_out_diff1'] = train['u_out'] - train['u_out_lag1']\n    train['u_in_diff2'] = train['u_in'] - train['u_in_lag2']\n    train['u_out_diff2'] = train['u_out'] - train['u_out_lag2']\n    train['u_in_diff3'] = train['u_in'] - train['u_in_lag3']\n    train['u_out_diff3'] = train['u_out'] - train['u_out_lag3']\n    ## diff between last 2 steps\n    train['u_in_diff_1_2'] = train['u_in_lag1'] - train['u_in_lag2']\n    train['u_out_diff_1_2'] = train['u_out_lag1'] - train['u_out_lag2']\n    train['u_in_lagback_diff_1_2'] = train['u_in_lag_back1'] - train['u_in_lag_back2']\n    train['u_out_lagback_diff_1_2'] = train['u_out_lag_back1'] - train['u_out_lag_back2']\n\n    train['u_in_lagback_diff1'] = train['u_in'] - train['u_in_lag_back1']\n    train['u_out_lagback_diff1'] = train['u_out'] - train['u_out_lag_back1']\n    train['u_in_lagback_diff2'] = train['u_in'] - train['u_in_lag_back2']\n    train['u_out_lagback_diff2'] = train['u_out'] - train['u_out_lag_back2']\n\n    # from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\n    train.loc[train['time_step'] == 0, 'u_in_diff'] = 0\n    train.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n\n    # difference between the current value of u_in and the max value within the breath\n    train['breath_id__u_in__diffmax'] = train.groupby(['breath_id'])['u_in'].transform('max') - train['u_in']\n    train['breath_id__u_in__diffmean'] = train.groupby(['breath_id'])['u_in'].transform('mean') - train['u_in']\n\n    print(\"before OHE\")\n    display(train)\n\n    # OHE\n    train = train.merge(pd.get_dummies(train['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\n    train = train.merge(pd.get_dummies(train['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\n    train = train.merge(pd.get_dummies(train['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n    # https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\n    train['u_in_cumsum'] = train.groupby(['breath_id'])['u_in'].cumsum()\n    train['time_step_cumsum'] = train.groupby(['breath_id'])['time_step'].cumsum()\n\n    # feature by u in or out (ideally - make 2 sep columns for each state) # dan\n    train['u_in_partition_out_sum'] = train.groupby(['breath_id',\"u_out\"])['u_in'].transform(\"sum\")\n\n    train = train.fillna(0) # add for consistency with how test is done - dan\n\n    return train","6ff953c8":"%%time\ntrain = add_feats(train)","4b9d41b3":"%%time\ntest = add_feats(test)","b08fec68":"from sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import GroupKFold \nfrom sklearn.model_selection import  KFold\nfrom sklearn import metrics","cc4ea793":"#remove expiratory phase from training #dan\nprint(train.shape[0])\ntrain = train.loc[train[\"u_out\"] != 1]\nprint(train.shape[0])","bb9de030":"scores = []\nfeature_importance = pd.DataFrame()\nmodels = []\ncolumns = [col for col in train.columns if col not in ['id', 'breath_id', 'pressure']]\nX = train[columns]\ny = train['pressure']\nparams = {'objective': 'regression',\n          'learning_rate': 0.25,\n          \"boosting_type\": \"gbdt\",\n          'min_data_in_leaf': 120,#600,\n          'max_bin': 210, #196,\n#           'device':'gpu',\n          'feature_fraction': 0.5, #0.4,\n          'lambda_l1':36, 'lambda_l2':80,\n          'max_depth':16,\n          'num_leaves':1000,\n          \"metric\": 'mae',\n          'n_jobs': -1\n         }\nfolds = GroupKFold(n_splits=n_splits)\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params, n_estimators=6000) # 8000\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=100, early_stopping_rounds=15)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = columns\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","5eb025e1":"feature_importance","a9750feb":"for model in models:\n    submission['pressure'] += model.predict(test[columns])\nsubmission['pressure'] \/= n_splits\n\nsubmission.to_csv('first_sub.csv', index=False)","ffd340eb":"## Actual time-series and window features + some more original feature engineering. \n* Big boost compared to merely aggregate features\n* 3X speedup and better results by modelling  without the expiratory phase\n* Features applied in a modular fashion for easier, safer changes.\n* Many base features based on the notebook: https:\/\/www.kaggle.com\/shivansh002\/lgbm-lover-s"}}