{"cell_type":{"e3a327cd":"code","93fb3553":"code","c6896aad":"code","d44d2f9e":"code","609c6a69":"code","124cdf4f":"code","a67b0f91":"markdown","9af0931b":"markdown","4aa1acf2":"markdown","7add17c4":"markdown","d2992cb0":"markdown","ba167821":"markdown","45436f39":"markdown","b25e31ae":"markdown"},"source":{"e3a327cd":"import numpy as np \nimport pandas as pd ","93fb3553":"data = pd.read_csv('\/kaggle\/input\/supermarket\/GroceryStoreDataSet.csv', header=None)\ndata.head()\ntransactions = []\nfor i in range(len(data)):\n    transactions.append(data.values[i, 0].split(','))\nprint(transactions)","c6896aad":"class Apriori:\n    \n    def __init__(self, transactions, min_support, min_confidence):\n        self.transactions = transactions\n        self.min_support = min_support # The minimum support.\n        self.min_confidence = min_confidence # The minimum confidence.\n        self.support_data = {} # A dictionary. The key is frequent itemset and the value is support.      \n        \n    def create_C1(self):\n        \"\"\"\n        create frequent candidate 1-itemset C1 by scaning data set.\n        Input:\n            None\n        Output:\n            C1: A set which contains all frequent candidate 1-itemsets\n        \"\"\"\n        C1 = set()\n        for transaction in self.transactions:\n            for item in transaction:\n                C1.add(frozenset([item]))\n        return C1\n    \n    def create_Ck(self, Lksub1, k):\n        \"\"\"\n        Create Ck.\n        Input:\n            Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.\n            k: the item number of a frequent itemset.\n        Output:\n            Ck: A set which contains all all frequent candidate k-itemsets.\n        \"\"\"\n        \n        Ck = set()\n        len_Lksub1 = len(Lksub1)\n        list_Lksub1 = list(Lksub1)\n        for i in range(len_Lksub1):\n            for j in range(1, len_Lksub1):\n                l1 = list(list_Lksub1[i])\n                l2 = list(list_Lksub1[j])\n                l1.sort()\n                l2.sort()\n                if l1[0:k-2] == l2[0:k-2]:\n                    # TODO: self joining Lk-1\n                    pass\n                \n                    # TODO: pruning\n                    pass\n\n        return Ck\n    \n    def generate_Lk_from_Ck(self, Ck):\n        \"\"\"\n        Generate Lk by executing a delete policy from Ck.\n        Input:\n            Ck: A set which contains all all frequent candidate k-itemsets.\n        Output:\n            Lk: A set which contains all all frequent k-itemsets.\n        \"\"\"\n        \n        Lk = set()\n        item_count = {}\n        for transaction in self.transactions:\n            for item in Ck:\n                if item.issubset(transaction):\n                    if item not in item_count:\n                        item_count[item] = 1\n                    else:\n                        item_count[item] += 1\n        t_num = float(len(self.transactions))\n        for item in item_count:\n            support = item_count[item] \/ t_num\n            if support >= self.min_support:\n                Lk.add(item)\n                self.support_data[item] = support\n        return Lk\n        \n    def generate_L(self):\n        \"\"\"\n        Generate all frequent item sets..\n        Input:\n            None\n        Output:\n            L: The list of Lk.\n        \"\"\"        \n        self.support_data = {}\n        \n        C1 = self.create_C1()\n        L1 = self.generate_Lk_from_Ck(C1)\n        Lksub1 = L1.copy()\n        L = []\n        L.append(Lksub1)\n        i = 2\n        while True:\n            Ci = self.create_Ck(Lksub1, i)\n            Li = self.generate_Lk_from_Ck(Ci)\n            if Li:\n                Lksub1 = Li.copy()\n                L.append(Lksub1)\n                i += 1\n            else:\n                break\n        return L\n        \n        \n    def generate_rules(self):\n        \"\"\"\n        Generate association rules from frequent itemsets.\n        Input:\n            None\n        Output:\n            big_rule_list: A list which contains all big rules. Each big rule is represented\n                       as a 3-tuple.\n        \"\"\"\n        L = self.generate_L()\n        \n        big_rule_list = []\n        sub_set_list = []\n        for i in range(0, len(L)):\n            for freq_set in L[i]:\n                for sub_set in sub_set_list:\n                    if sub_set.issubset(freq_set):\n                        # TODO : compute the confidence\n                        conf = pass\n                        big_rule = (freq_set - sub_set, sub_set, conf)\n                        if conf >= self.min_confidence and big_rule not in big_rule_list:\n                            big_rule_list.append(big_rule)\n                sub_set_list.append(freq_set)\n        return big_rule_list\n        ","d44d2f9e":"model = Apriori(transactions, min_support=0.1, min_confidence=0.75)","609c6a69":"L = model.generate_L()\n\nfor Lk in L:\n    print('frequent {}-itemsets\uff1a\\n'.format(len(list(Lk)[0])))\n\n    for freq_set in Lk:\n        print(freq_set, 'support:', model.support_data[freq_set])\n    \n    print()","124cdf4f":"rule_list = model.generate_rules()\n\nfor item in rule_list:\n    print(item[0], \"=>\", item[1], \"confidence: \", item[2])","a67b0f91":"**Step 3\uff1a Test Algorithm**","9af0931b":"# Apriori Algorithm\n\nThis is the first homework of EE448. In this work, you should be familiar with the Apriori algorithm and complete its implementation.\n\nThe specific points involved are, \n* candidate generation : self-joining\n* candidate generation : pruning\n* association rule mining: calculation of confidence","4aa1acf2":"**Step 2: Inplementation of Apriori algorithm**","7add17c4":"    3. Association rule mining","d2992cb0":"** Step 0\uff1aEnvironment Setup**","ba167821":"    1. Model construction","45436f39":"**Step 1: Data Preparation**","b25e31ae":"    2. Frequent item set mining"}}