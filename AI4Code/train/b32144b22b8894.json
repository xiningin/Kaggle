{"cell_type":{"94f38752":"code","9c3d55e3":"code","37e36fee":"code","ea8747a6":"code","dae14d2e":"code","305a59e1":"code","703c5e75":"code","61720250":"code","594164c5":"code","b86975a3":"code","b5027791":"markdown","edf3bbe9":"markdown","e4d0fe8b":"markdown","8a6f2fbc":"markdown","46f8c576":"markdown","b3e16666":"markdown","ab8d3da4":"markdown","31e3196f":"markdown","92a17aeb":"markdown","d46b0068":"markdown","44246b8f":"markdown","5367e078":"markdown","dc280322":"markdown","adeb51ff":"markdown","5cd941b8":"markdown","c9ead370":"markdown","f7bff7a5":"markdown"},"source":{"94f38752":"import os, sys\nsys.path.append('..\/usr\/lib\/visualization')\nfrom visualization import *","9c3d55e3":"slay_play_data = get_play_data(week=14, gameId=2018120911, playId=1584)\nprint(slay_play_data)","37e36fee":"comp_prob, incomp_prob = run_model(slay_play_data)\nprint_probabilities(comp_prob, incomp_prob)","ea8747a6":"slay_play_data[\"WR-DB proximity\"] = 2.40 # median WR-DB separation for HITCH routes\ncomp_prob, incomp_prob = run_model(slay_play_data)\nprint_probabilities(comp_prob, incomp_prob)","dae14d2e":"scores_df = pd.read_csv('..\/input\/nfl-bdb-data\/cb_scores.csv')\nplot_playmaking_skills(scores_df)","305a59e1":"plot_coverage_skills(scores_df)","703c5e75":"plot_ball_skills(scores_df)","61720250":"rankings = get_final_cb_rankings_table(n_players=30)\nrankings","594164c5":"rankings = get_final_saf_rankings_table(n_players=30)\nrankings","b86975a3":"rankings = get_final_lb_rankings_table(n_players=30)\nrankings","b5027791":"In the table below, we rank the top 30 Cornerbacks who were targeted at least 45 times throughout the 2018 season. The table shows each players' rating in each of the six key categories (with their rank for each category in parenthesis). The Raw Score is the sum of the player's rankings for the six metrics. Finally, the Overall Score is a normalized version of the Raw Score that is then put on a scale from 0-100. Players who were selected to the Pro Bowl that year are marked with an asterisk.","edf3bbe9":"# AI-Based Evaluation of NFL Pass Defenders\n ***NOTE: This is the full version of our [2021 NFL Big Data Bowl competition report](https:\/\/www.kaggle.com\/chipkajb\/ai-based-evaluation-of-nfl-pass-defenders). The additional information that was cut from the condensed competition version can be found in the Appendix of this report. Also, see our [GitHub repo](https:\/\/github.com\/chipkajb\/nfl_big_data_bowl_2021) to access the code used in our analysis.***","e4d0fe8b":"# 7. Appendix\n    \n### 7.1 Comments on input parameters to AI model\nWe found that parameter #4 (the proximity of the ball to the target receiver when the ball arrives) was not always accurate in the player tracking data. Presumably because the ball moves so quickly, the data sometimes indicates that the ball reaches the target receiver while the position of the ball is still in mid-flight. Furthermore, our motivation behind parameter #5 (the proximity of the passer to the nearest blitzer when the ball is thrown) is to capture the amount of pressure that is on the passer because this often has a great impact on the success of the pass. However, the player tracking data does not include linemen, so we are not able to take all pass rushers in consideration; hence, we only look at blitzing players. Although parameters #4 and #5 still prove to be useful, we must consider these points in order to truly understand their role in our analysis.\n\n### 7.2 Training the AI model\n\nWe encountered a couple notable obstacles during the training process. First, we curated the player tracking data, as some data was found to be irregular (e.g. plays with missing player data, missing ball data, etc.). All irregular data was discarded to avoid unnecessarily hindering the training process. The second, and primary, obstacle to overcome in the training process was to ensure that the model does not overfit the training data. If the model does overfit the training data, then it will not accurately predict the pass completion probability for new data, and therefore, not be useful outside of the training dataset. Our training approach used many techniques to avoid overfitting. First, as mentioned previously, we split the data into a training set and validation set. After each training epoch, the model was tested on the validation set. The model that performed best on the validation set is the final model that we selected. Furthermore, our neural network includes dropout layers and our training process uses L2 regularization to avoid overfitting.\n\n### 7.3 Remarks on AI model testing exercise\n\nBeyond the WR-DB separation input parameter, the second greatest factor to determining a pass completion according to our model is the pass distance across the field. This makes intuitive sense, as passes that travel a larger distance are less likely to be completed. Interestingly, the third most significant factor is the receiver's distance to the sideline. This may seem surprising at first, but when we consider the fact that the receiver's distance to the sideline is strongly correlated to the pass distance across the field, then we can understand why this parameter's contribution is so high. Finally, as mentioned previously, parameter #4 (WR-ball proximity) is not always accurate in the data and parameter #5 (QB-blitzer proximity) does not consider linemen rushing the passer. Therefore, these parameters proved to be less predictive than otherwise expected.\n\n\n### 7.4 Top coverage Safeties\n\nIn the table below, we rank the top 30 coverage Safeties and Defensive Backs who were targeted at least 25 times throughout the 2018 season. These players have the position of \"S,\" \"FS,\" \"SS,\" or \"DB\" in the player tracking dataset. Players who were selected to the Pro Bowl that year are marked with an asterisk.","8a6f2fbc":"### 3.4 Testing\nTo better understand our model, we examine the amount that each input parameter contributes to the model's output. To do this, we find the average value ($\\mu$) and standard deviation ($\\sigma$) of all eight input parameters. Then, while holding all other parameters constant at their average value, we vary one parameter by one standard deviation. We do this for all input parameters and compare the resulting completion probabilities to determine the amount each parameter contributes to the model's output. The results of this exercise are summarized below.\n\n1. Longitudinal pass distance: $\\mu=14.6$, $\\sigma=10.4$, contribution: $6.1\\%$\n2. Lateral pass distance: $\\mu=11.1$, $\\sigma=7.1$, contribution: $27.6\\%$\n3. WR-DB separation: $\\mu=3.8$, $\\sigma=3.1$, contribution: $32.3\\%$\n4. WR-ball proximity: $\\mu=1.4$, $\\sigma=1.3$, contribution: $3.7\\%$\n5. QB-blitzer proximity: $\\mu=6.4$, $\\sigma=3.3$, contribution: $1.0\\%$\n6. WR-sideline proximity: $\\mu=13.8$, $\\sigma=7.5$, contribution: $21.6\\%$\n7. QB speed: $\\mu=1.8$, $\\sigma=1.7$, contribution: $2.8\\%$\n8. Time to throw: $\\mu=2.8$, $\\sigma=1.0$, contribution: $5.0\\%$\n\nFrom these results, we see that the greatest factor in determining the result of a pass is the WR-DB separation, therefore, emphasizing the importance of a defender's tracking ability and reinforcing the significance of our analysis. For additional remarks regarding this exercise, see section 7.3 in the Appendix.","46f8c576":"When this data is fed into our model, we see that the predicted pass incompletion probability is $84.4\\%$.","b3e16666":"### 7.6 Limitations of analysis\n\nThe main limitation of our analysis is that we only evaluate defenders on plays where they were targeted. Therefore, our player evaluation is not all-encompassing because, as an example, it will not consider a defender's great coverage if it results in a sack. Likewise, it will also not consider a defender's poor coverage if the QB ends up throwing to a different receiver. Therefore, the reliability of our analysis decreases for defenders that were scarcely targeted. For this reason, we only include players with at least a specific number of targets in our final ranking. However, this can cause certain slot cornerbacks to be overlooked, as they may not be targeted frequently enough to be included in our final rankings. Additionally, defenders that are targeted infrequently due to stellar coverage may be disadvantaged in our analysis. For instance, Patrick Peterson was targeted less than any other Cornerback in our final ranking. This may indicate that his coverage ability is actually better than our analysis may suggest.\n\nOn the other hand, another limitation of our analysis could be that it does not examine fine-grained situations, but rather collectively looks at all plays where a given defender was targeted. It can be helpful to know how a defender fares in specific situations (e.g. when positioned outside the numbers, on deep routes, on slot receivers, etc.), as this can provide fine-grained knowledge for deciding matchups and scheme fits.\n\nFinally, sometimes multiple players contribute in defending a specific pass, as more than one defender may be in the proximity of the target receiver. This raises another limitation, as our analysis only considers the closest defender to the target receiver, and entirely attributes the play's metrics to that single defender.","ab8d3da4":"# 4. Key Metrics\n\nOur analysis uses six key metrics to evaluate a player's pass coverage ability. Each of these metrics measures a specific aspect of pass defense. When considered in combination, these metrics give a more detailed view of a player's true pass defense ability. The first three metrics are existing measures commonly used for player evaluation. The last three metrics are new, innovative measures that we pioneer using our AI model.\n\n### 4.1 Definitions\n\n1. Incompletion Rate (INC Rate) is the percentage of passes that result in an incompletion when targeting a given defender. This metric measures a player's \"shutdown\" ability.\n\n2. Interception Rate (INT Rate) is the percentage of passes that result in an interception when targeting a given defender. This metric measures a player's \"takeaway\" ability.\n\n3. Expected Points Added (EPA) is the expected points (EP) that a given play contributes. In other words, it is a way to measure the value of an individual play in terms of points. Since our analysis focuses on pass defense, we award the play's EPA to the targeted pass defender. In our analysis, we use this metric to measure a defender's \"playmaking\" ability.\n\n4. Expected Incompletion Rate (EIR) is the percentage of passes that our AI model predicts will result in an incompletion when targeting a given defender. Since the only input parameter of our AI model that the pass defender can control is the WR-DB separation, this metric measures the player's \"tracking\" ability.\n\n5. Incompletion Rate Above Expectation (IRAE) is the difference between the actual incompletion rate (INC Rate) and the expected incompletion rate (EIR). Since EIR is produced by our validated AI model and takes into consideration the conditions of each individual pass, we can expect it to be an accurate estimate of the actual incompletion rate. Although discrepancies between INC Rate and EIR may be attributed to things such as inaccuracies in the AI model and unforeseen events like drops or spectacular catches, this likely will not occur consistently, as our AI model has been shown to accurately predict pass completion probability overall. Therefore, consistent discrepancies between INC Rate and EIR for a given defender indicates that the main contributing factor must be the way the defender plays once the ball reaches the receiver. Therefore, this metric is used to measure a player's \"pass breakup\" ability.\n\n6. Incompletion Probability Added (IPA) is the incompletion probability that a defender contributes on a given play above the \"average defender\" according to our AI model. This value is computed by first using the AI model to calculate the completion probability for a given pass, then the WR-DB separation value is replaced with the median WR-DB separation value for all plays in the dataset with the same route, and a new completion probability is computed. The difference between these two values is the defender's IPA for that play. In other words, it is the additional probability of an incompletion that a defender contributes above a defender with median tracking performance, while all other aspects of the play are held constant. This metric is inspired by the Wins Above Replacement (WAR) metric in baseball, which attempts to measure how many more wins a player is worth above a replacement-level player. It is also inspired by True Shooting Percentage (TS%) in basketball, which attempts to measure a player's shooting efficiency considering not all shots are of equal difficulty, and therefore should not be weighted equally. Similarly, IPA captures the fact that not all passes are equally difficult to defend, but rather, the specific conditions of the pass ought to be considered. Therefore, IPA is used to measure a player's \"true coverage\" ability.\n\n### 4.2 Example\n\nTo better understand these new metrics, let's look at an example. Shown below is a sample from our dataset for the previous play involving Darius Slay. On this play, there was just $0.32$ yards of separation between the receiver and Darius Slay.","31e3196f":"However, when we use the data from the same play but replace Darius Slay's WR-DB separation with the median value for all HITCH routes ran in 2018, we see that the predicted pass incompletion probability drops to $30.9\\%$. Therefore, Darius Slay's Incompletion Probability Added (IPA) for that specific play is $84.4\\% - 30.9\\% = 53.5\\%$. In other words, that specific pass is $53.5\\%$ more likely to fall incomplete, compared to the median NFL defender, because of Darius Slay's performance.","92a17aeb":"# 1. Summary\n\nThis report presents a novel approach to evaluating NFL pass defenders by leveraging AI-based techniques. Current evaluation techniques fail to take many aspects of pass defense into account. Our evaluation methodology seeks to resolve this difficulty by taking all relevant skills into consideration, including tracking, pass breakup, true coverage, shutdown, takeaway, and playmaking abilities.\n\nWe design and train a deep neural network using player tracking data to estimate pass completion probability. We develop three new advanced metrics using our AI model to more accurately evaluate a player's pass coverage ability. Using these three metrics, as well as three other existing metrics, we evaluate all pass defenders in the 2018 NFL regular season. Finally, we discuss possible applications of our work.","d46b0068":"In this report, we address the challenge of evaluating a pass defender's ability by first quantifying the difficulty of defending a given pass, and then quantifying the player's performance given the specific play's conditions. In the following sections, we go into the details of our methodology.","44246b8f":"# 3. AI Model\n\nOur analysis centers around the use of an AI model to estimate pass completion probability. This model is a deep neural network that we design, train, calibrate, and validate from scratch.\n\nThe first step to developing this model is to understand the data that is available to us. We use player tracking data from the 2018 NFL regular season to perform our analysis. Below is an animation showing the player tracking data for the previous play involving Darius Slay.\n\n<img src=\"https:\/\/raw.githubusercontent.com\/chipkajb\/miscellaneous\/master\/nfl_big_data_bowl_2021\/slay_animation.gif\">","5367e078":"# 2. Motivation\n\nThe game of football presents a unique difficulty to accurately quantify a player's contribution to their team's overall success. For instance, the play shown below demonstrates the elite quickness and agility of Darius Slay. However, on the score sheet, this play is simply marked as an incompletion. The difficulty of the play, or the raw ability required to make the play, is never quantified.\n\n<img src=\"https:\/\/raw.githubusercontent.com\/chipkajb\/miscellaneous\/master\/nfl_big_data_bowl_2021\/slay_video.gif\">","dc280322":"From this animation, we can see several factors that contribute to the pass result. Using this insight, we decide to use the following parameters to develop our AI model.\n\n1. Pass distance down field (longitudinal)\n2. Pass distance across field (lateral)\n3. Proximity of target receiver to nearest defender when ball arrives\n4. Proximity of ball to target receiver when ball arrives\n5. Proximity of passer to nearest blitzer when ball is thrown\n6. Proximity of target receiver to sideline when ball arrives\n7. Passer's running speed when ball is thrown\n8. Time it takes from when ball is snapped to when ball is thrown\n\nFor additional comments on these input parameters, see section 7.1 in the Appendix.\n\n### 3.1 Data collection\n\nIn order to train the AI model, we first sifted through the player tracking data to generate a new dataset which includes the eight parameters listed above, as well as other metadata such as play result and route. The dataset comprises of nearly 18,000 passes and was split into a training set and validation set. For additional details regarding the training process, see section 7.2 in the Appendix.\n\n### 3.2 Calibration\n\nA common issue in deep learning is that neural networks tend to be over-confident in their estimation of probabilities. Therefore, in order for our AI model to more accurately reflect realistic probabilities, we calibrated our model using [temperature scaling](https:\/\/arxiv.org\/pdf\/1706.04599.pdf). This calibration process involved tuning our AI model to most accurately reflect the actual pass completion percentages seen in the validation dataset.\n\n### 3.3 Validation\n\nThe final stage of development for the AI model is to evaluate its performance. Our model correctly predicts the outcome of 80% of all passes in the dataset. More importantly, however, our model accurately predicts the pass completion probability, as shown in the figure below. This figure is generated by using our model to predict the completion probability for all passes in the dataset. These predictions are then grouped by predicted pass completion probability (e.g. 0-10%, 10-20%, etc.). Then, for each group, the actual completion percentage for those passes is calculated based on the plays' results. Finally, the actual completion percentage is plotted against the model's predicted completion probability. A model that matches reality will form a diagonal line. As shown in the figure below, our AI model predicts the actual pass completion probability with a high degree of accuracy.","adeb51ff":"<img src=\"https:\/\/github.com\/chipkajb\/miscellaneous\/raw\/master\/nfl_big_data_bowl_2021\/calibration_graph.png\">","5cd941b8":"# 5. Player Evaluation\n\nUsing our AI model to predict pass completion probabilities, we gain a more detailed view of a player's pass defense ability. The following three figures explore how specific players measure with respect to our metrics. In each figure, we highlight the players that excel in each aspect of pass defense.","c9ead370":"### 7.5 Top coverage Linebackers\n\nIn the table below, we rank the top 30 coverage Linebackers who were targeted at least 25 times throughout the 2018 season. Players who were selected to the Pro Bowl that year are marked with an asterisk.","f7bff7a5":"# 6. Application\n\nOur analysis provides a detailed look at a player's ability to defend the pass by leveraging AI. Although we focused this report on evaluating Cornerbacks, our analysis can be applied to any player in pass coverage (see sections 7.4 and 7.5 in the Appendix for Safety and Linebacker coverage rankings). This is especially valuable considering the lack of useful evaluation techniques for Linebackers in pass coverage. Overall, our analysis is valuable for many reasons. The most obvious application is for player evaluation. Using our methodology, we get a detailed and accurate measure of a player's pass coverage performance, which can be used as a tool for grading players and selecting All-Pro teams. Additionally, our analysis could be used by Front Office members when it comes to making decisions regarding contract negotiations, free agency, and trades. It is also useful for player development, as our analysis shows the specific aspects of pass defense in which a player requires the most improvement. Finally, our analysis could also be used to bolster coaching. If a coach understands the specific aspects in which a player excels or underperforms in pass coverage, then that can inform the coach's decisions regarding practice drills, player matchups, game situations, and even play-calling. For a discussion on the limitations of our analysis, see section 7.6 in the Appendix."}}