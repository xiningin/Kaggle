{"cell_type":{"9b31e4d8":"code","a06263eb":"code","12986a4c":"code","1c6ba1af":"code","4d1b2b84":"code","7be84aba":"code","486ff6c0":"code","72a833c8":"code","dd2a39d7":"code","9ec43fd2":"code","fcd191ce":"code","0c20abc4":"code","bc2f6af1":"code","21c02a5b":"code","cad8adfb":"code","2f8868b8":"code","fff63375":"code","79754fbc":"code","f21b6dac":"code","ca7bbf98":"code","c9732dbd":"code","e7220ef5":"code","32228bda":"code","da8650f3":"code","3048bcb5":"code","fd7e348c":"code","91077fc7":"code","248c337a":"code","966ae923":"code","1eabcea1":"code","272e9557":"code","30a27c2b":"code","a47dc9bc":"code","2df3fa70":"code","87c9b041":"code","dbd376ef":"code","468d70a4":"code","2dfeda06":"code","ec1a2439":"code","387aa345":"code","2f008a8c":"code","f58215fe":"code","b2ac3398":"code","66240301":"markdown","180e31ee":"markdown","a22a0ab9":"markdown"},"source":{"9b31e4d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Any results you write to the current directory are saved as output.","a06263eb":"train=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain.head()","12986a4c":"#remove outliers\ntrain=train.drop(index=[523,1298],axis=0)","1c6ba1af":"test=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest.head()","4d1b2b84":"print('the train data has {} rows and {} features'.format(train.shape[0],train.shape[1]))\nprint('the test data has {} rows and {} features'.format(test.shape[0],test.shape[1]))","7be84aba":"data=pd.concat([train.iloc[:,:-1],test],axis=0)\nprint('the data has {} rows and {} features'.format(data.shape[0],data.shape[1]))","486ff6c0":"data.info()","72a833c8":"num_features=data.select_dtypes(include=['int64','float64'])\ncategorical_features=data.select_dtypes(include='object')","dd2a39d7":"num_features.describe()","9ec43fd2":"categorical_features.describe()","fcd191ce":"data.isnull().sum().sort_values(ascending=False)[:34]","0c20abc4":"data = data.drop(columns=['Id','Street','PoolQC','Utilities'],axis=1)","bc2f6af1":"data['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","21c02a5b":"data['LotFrontage'].isnull().sum()","cad8adfb":"#create a new class 'other'\nfeatures=['Electrical','KitchenQual','SaleType','Exterior2nd','Exterior1st','Alley','Fence', 'MiscFeature','FireplaceQu','GarageCond','GarageQual','GarageFinish','GarageType','BsmtCond','BsmtExposure','BsmtQual','BsmtFinType2','BsmtFinType1','MasVnrType']\nfor name in features:\n    data[name].fillna('Other',inplace=True)","2f8868b8":"data[features].isnull().sum()","fff63375":"data['MSZoning'] = data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","79754fbc":"data['Functional']=data['Functional'].fillna('typ')","f21b6dac":"zero=['GarageArea','GarageYrBlt','MasVnrArea','BsmtHalfBath','BsmtHalfBath','BsmtFullBath','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','GarageCars']\nfor name in zero:\n    data[name].fillna(0,inplace=True)","ca7bbf98":"data.isnull().sum()","c9732dbd":"data.loc[data['MSSubClass']==60, 'MSSubClass']=0\ndata.loc[(data['MSSubClass']==20)|(data['MSSubClass']==120), 'MSSubClass']=1\ndata.loc[data['MSSubClass']==75, 'MSSubClass']=2\ndata.loc[(data['MSSubClass']==40)|(data['MSSubClass']==70)|(data['MSSubClass']==80), 'MSSubClass']=3\ndata.loc[(data['MSSubClass']==50)|(data['MSSubClass']==85)|(data['MSSubClass']==90)|(data['MSSubClass']==160)|(data['MSSubClass']==190), 'MSSubClass']=4\ndata.loc[(data['MSSubClass']==30)|(data['MSSubClass']==45)|(data['MSSubClass']==180), 'MSSubClass']=5\ndata.loc[(data['MSSubClass']==150), 'MSSubClass']=6","e7220ef5":"object_features = data.select_dtypes(include='object').columns\nobject_features","32228bda":"def dummies(d):\n    dummies_df=pd.DataFrame()\n    object_features = d.select_dtypes(include='object').columns\n    for name in object_features:\n        dummies = pd.get_dummies(d[name], drop_first=False)\n        dummies = dummies.add_prefix(\"{}_\".format(name))\n        dummies_df=pd.concat([dummies_df,dummies],axis=1)\n    return dummies_df","da8650f3":"dummies_data=dummies(data)\ndummies_data.shape","3048bcb5":"data=data.drop(columns=object_features,axis=1)\ndata.columns","fd7e348c":"final_data=pd.concat([data,dummies_data],axis=1)\nfinal_data.shape","91077fc7":"#Re-spliting the data into train and test datasets\ntrain_data=final_data.iloc[:1458,:]\ntest_data=final_data.iloc[1458:,:]\nprint(train_data.shape)\ntest_data.shape","248c337a":"# X: independent variables and y: target variable\nX=train_data\ny=train.loc[:,'SalePrice']","966ae923":"from sklearn.linear_model import Ridge, RidgeCV, LassoCV, ElasticNet","1eabcea1":"model_las_cv = LassoCV(alphas=(0.0001, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nmodel_las_cv.fit(X,y)\nlas_cv_preds=model_las_cv.predict(test_data)","272e9557":"model_ridge_cv = RidgeCV(alphas=(0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nmodel_ridge_cv.fit(X, y)\nridge_cv_preds=model_ridge_cv.predict(test_data)","30a27c2b":"model_ridge = Ridge(alpha=10, solver='auto')\nmodel_ridge.fit(X, y)\nridge_preds=model_ridge.predict(test_data)","a47dc9bc":"model_en = ElasticNet(random_state=1, alpha=0.00065, max_iter=3000)\nmodel_en.fit(X, y)\nen_preds=model_en.predict(test_data)","2df3fa70":"import xgboost as xgb","87c9b041":"model_xgb = xgb.XGBRegressor(learning_rate=0.01,n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)\nmodel_xgb.fit(X, y)\nxgb_preds=model_xgb.predict(test_data)","dbd376ef":"from sklearn.ensemble import GradientBoostingRegressor","468d70a4":"model_gbr = GradientBoostingRegressor(n_estimators=3000, \n                                learning_rate=0.05, \n                                max_depth=4, \n                                max_features='sqrt', \n                                min_samples_leaf=15, \n                                min_samples_split=10, \n                                loss='huber', \n                                random_state =42)\nmodel_gbr.fit(X, y)\ngbr_preds=model_gbr.predict(test_data)","2dfeda06":"from lightgbm import LGBMRegressor","ec1a2439":"model_lgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       #min_data_in_leaf=2,\n                                       #min_sum_hessian_in_leaf=11\n                                       )\nmodel_lgbm.fit(X, y)\nlgbm_preds=model_lgbm.predict(test_data)","387aa345":"final_predictions = 0.3 * lgbm_preds + 0.3 * gbr_preds + 0.1 * xgb_preds + 0.3 * ridge_cv_preds","2f008a8c":"#display the first 5 predictions of sale price\nfinal_predictions[:5]","f58215fe":"#make the submission data frame\nsubmission = {\n    'Id': test.Id.values,\n    'SalePrice': final_predictions + 0.007 * final_predictions\n}\nsolution = pd.DataFrame(submission)\nsolution.head()","b2ac3398":"#make the submission file\nsolution.to_csv('submission.csv',index=False)","66240301":"Our dataset has no missing values.\n\nAnother pre-processing step is to transform categorical features into numerical features","180e31ee":"We'll divide the data into numerical and categorical data and verify their descriptive statistics","a22a0ab9":"We'll combine these two data sets using the concat attribute"}}