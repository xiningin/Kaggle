{"cell_type":{"3a3b0601":"code","cef24a00":"code","25dc4600":"code","c98b4298":"code","f3a27bee":"code","4898caa1":"code","f080bea9":"code","f4190e45":"code","97634aed":"code","ec8a9d3a":"code","2a563c1a":"code","f130dc20":"code","ca94c54c":"code","d350d568":"code","40788358":"code","a38af9e6":"code","4dc8f112":"code","3898495c":"code","f31237c7":"code","a6a81b04":"code","d530d190":"code","251a6740":"code","8473d83d":"code","5ed4be93":"code","8a3753ad":"code","02204ef7":"code","6d6615d6":"code","fe1bd413":"code","9d4d065b":"code","14c1a2f4":"code","d0ab7099":"code","674a954d":"code","352bd47b":"code","b8d21819":"code","0950830a":"markdown","140635ef":"markdown","317f6c61":"markdown","79a5f920":"markdown"},"source":{"3a3b0601":"!pip install rake-nltk\n\nimport pandas as pd\nimport numpy as np\nfrom rake_nltk import Rake\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer","cef24a00":"#Import dataset with sypnopsis \nsypnopsis = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime_with_synopsis.csv')\n\n#Import dataset with anime type\nusecols =['MAL_ID','Type']\nanime_type = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime.csv', usecols=usecols)","25dc4600":"display(sypnopsis.shape)\ndisplay(anime_type.shape)\n\n#Merge the two dataset\ndf = sypnopsis.merge(anime_type, how='left', on='MAL_ID')\n\ndisplay(df.shape)","c98b4298":"#Check the first 5 row of merged dataset\ndf.head()","f3a27bee":"#Check the types of the anime \ndf['Type'].value_counts()","4898caa1":"#Filter out the 'Music', 'Unknown', 'OVA' or 'ONA' type\ndf.drop(df[df['Type']=='Music'].index, inplace=True)\ndf.drop(df[df['Type']=='Unknown'].index, inplace=True)\ndf['Type'].value_counts()","f080bea9":"#Check the dataset\ndf.describe(include='all')","f4190e45":"#Drop duplicates anime \ndf.drop_duplicates(subset='Name', inplace=True)\ndf.shape","97634aed":"#Define content with no sypnopsis \nno_sypnopsis = df['sypnopsis'].mode()[0]\nno_sypnopsis","ec8a9d3a":"#Subset the dataframe to a cleaner and usable dataframe\ndf = df[(df['sypnopsis'].isnull()==False) & (df['sypnopsis'] != no_sypnopsis)]\ndf.shape","2a563c1a":"df.describe(include='all')","f130dc20":"#define and drop content with no sypnopsis \nno_sypnopsis = df['sypnopsis'].mode()[0]\ndf = df[df['sypnopsis'] != no_sypnopsis]\ndf.shape","ca94c54c":"#drop anime with duplicate sypnopsis \ndf.drop_duplicates(subset='sypnopsis', inplace=True)\ndf.describe(include='all')","d350d568":"df['sypnopsis'] = df['sypnopsis'].astype(str)\nprint(df['sypnopsis'].head())","40788358":"# Initialize empty column\ndf['Keywords'] = ''\n\n# function to get keywords from a text\ndef get_keywords(x):\n    plot = x\n    \n    # initialize Rake using english stopwords from NLTK, and all punctuation characters\n    r = Rake()\n    \n    # extract keywords from text\n    r.extract_keywords_from_text(plot)\n    \n    # get dictionary with keywords and scores\n    scores = r.get_word_degrees()\n    \n    # return new keywords as list, ignoring scores\n    return(list(scores.keys()))\n\n# Apply function to generate keywords\ndf['Keywords'] = df['sypnopsis'].apply(get_keywords)\ndf.head()","a38af9e6":"# Split the features into list \ndef tokenize(x):\n    if isinstance(x, list):\n        return [i.lower().split(\", \") for i in x]\n    else:\n        if isinstance(x, str):\n            return x.lower().split(\", \")\n        else:\n            return ''   \n\ndf['Genres'] = df['Genders'].apply(tokenize)\ndf.head()","4dc8f112":"df_keys = pd.DataFrame() \n\ndf_keys['title'] = df['Name']\ndf_keys['bag_of_words'] = ''\n\ndef bag_words(x):\n    return(' '.join(x['Genres'])+ ' ' + ' '.join(x['Keywords']) + ' ' )\ndf_keys['bag_of_words'] = df.apply(bag_words, axis = 1)\n\ndf_keys.head()","3898495c":"cv = CountVectorizer()\nbow = cv.fit_transform(df_keys['bag_of_words'])","f31237c7":"cosine_sim = cosine_similarity(bow, bow)","a6a81b04":"# create list of indices for later matching\nindices = pd.Series(df_keys.index, index = df_keys['title'])\n\ndef recommend_anime(title, n = 10, cosine_sim = cosine_sim):\n    movies = []\n    \n    # retrieve matching movie title index\n    if title not in indices.index:\n        print(\"Movie not in database.\")\n        return\n    else:\n        idx = indices[title]\n    \n    # cosine similarity scores of movies in descending order\n    scores = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n    \n    # top n most similar movies indexes\n    # use 1:n because 0 is the same movie entered\n    top_n_idx = list(scores.iloc[1:n].index)\n        \n    return pd.DataFrame(df_keys['title'].iloc[top_n_idx])","d530d190":"recommend_anime('InuYasha')","251a6740":"recommend_anime('Kaguya-sama wa Kokurasetai: Tensai-tachi no Renai Zunousen')","8473d83d":"recommend_anime('Detective Conan')","5ed4be93":"from sklearn.neighbors import NearestNeighbors\nfrom scipy.sparse import csr_matrix","8a3753ad":"#Import anime_name dataset\nanime_name = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime.csv', usecols=['MAL_ID','Name'])\ndisplay(anime_name.shape)\nanime_name.head()","02204ef7":"#Import rating dataset\nrating_data =pd.read_csv('..\/input\/anime-recommendation-database-2020\/rating_complete.csv')\ndisplay(rating_data.shape)\nrating_data.head()","6d6615d6":"#Count number of unique users\nusers_count = rating_data.groupby(\"user_id\").size().reset_index()\nusers_count.columns = [\"user_id\", \"anime_count\"]\nprint('Numbers of unique users : ', users_count.shape[0])\n\n#Filter the users\nfiltered_users = users_count[users_count.anime_count >= 500]\nusers = list(filtered_users.user_id)\nprint('Numbers of unique users with 500 or more anime ratings : ', len(users))","fe1bd413":"#Filter the rating data with users who had rated 500 or more anime \nrating_data = rating_data[rating_data['user_id'].isin(users)]\nprint (\"rating shape:\", rating_data.shape)\nprint (rating_data.info())","9d4d065b":"#vectorization\nunique_users = {int(x): i for i,x in enumerate(rating_data.user_id.unique())}\nunique_animes = {int(x): i for i,x in enumerate(anime_name.MAL_ID.unique())}\n\nprint(len(unique_animes), len(unique_users))\nanime_collaborative_filter = np.zeros((len(unique_animes), len(unique_users)))\n\nfor user_id, MAL_ID, rating in rating_data.values:\n    anime_collaborative_filter[unique_animes[MAL_ID], unique_users[user_id]] = rating","14c1a2f4":"def get_recommended(title, n_neighbors=10):\n    model_knn = NearestNeighbors(metric='cosine', n_neighbors=n_neighbors)\n    model_knn.fit(csr_matrix(anime_collaborative_filter))\n    \n    query_index = anime_name[anime_name['Name']==title].index[0]\n\n    distances, indices = model_knn.kneighbors(anime_collaborative_filter[query_index,:].reshape(1, -1), n_neighbors = n_neighbors)\n    result = []\n    for i in range(0, len(distances.flatten())):\n        index = indices.flatten()[i]\n        if index == query_index:\n            continue\n        result.append(anime_name.iloc[index])\n        \n    return pd.DataFrame(result)","d0ab7099":"get_recommended('Fullmetal Alchemist: Brotherhood')","674a954d":"get_recommended('InuYasha')","352bd47b":"get_recommended('Kaguya-sama wa Kokurasetai: Tensai-tachi no Renai Zunousen')","b8d21819":"get_recommended('Steins;Gate')","0950830a":"# ANIME RECOMMENDER SYSTEM\n\nIn this notebook, I will try to build anime recommender system based on the scrapped data from myanimelist.net that is available <a href=\"https:\/\/www.kaggle.com\/hernan4444\/anime-recommendation-database-2020\">here<\/a>","140635ef":"## References\n\nThis notebook is created based on several references below :\n* <a href=\"https:\/\/www.kaggle.com\/hernan4444\/anime-content-collaborative-knn\">Anime Recommended System - Content Based & Collaborative Filtering<\/a>\n* <a href=\"https:\/\/towardsdatascience.com\/machine-learning-for-building-recommender-system-in-python-9e4922dd7e97\">Machine Learning for Building Recommender System in Python<\/a>\n* <a href=\"https:\/\/www.datacamp.com\/community\/tutorials\/recommender-systems-python\">Beginner Tutorial: Recommender Systems in Python<\/a>\n* <a href=\"https:\/\/towardsdatascience.com\/techniques-for-content-based-recommender-systems-64f812d2b5a0\">Techniques for Content-based Recommender Systems<\/a>\n* <a href=\"https:\/\/towardsdatascience.com\/how-to-build-from-scratch-a-content-based-movie-recommender-with-natural-language-processing-25ad400eb243\">How to build a content-based movie recommender system with Natural Language Processing<\/a>","317f6c61":"## Collaborative Filtering\n\nIn the collaborative filtering recommender system, we will only consider the rating given by user to give recommendation. This recommendation will return preferred anime by previous users who rated highly on the input anime.\n\nAdvantages : \n* Result are often better than content-based, because it can give recommendation without the machine analyzing complex object such as anime from its metadata.\n\nDisadvantages : \n* Will face 'cold start' problem when new item that didn't have enough rating will not be recommended.\n* Requires big amount of rating data before it can generate satisfying result.","79a5f920":"## Content-Based Recommender System\n\nIn the content-based recommender system, we will only consider the synopsis and metadata of the anime. This recommendation will return the most similar items based of the input anime we gave.\n\nAdvantages : \n* Can overcome 'cold start' problem when we're using the collaborative filtering where new item that didn't have enough rating will not be recommended.\n\nDisadvantages : \n* Result may not be satisfying as it's difficult to rate a complex item by its metadata only.\n* Tend to return on similar items such as the sequel or the 2nd season of that anime."}}