{"cell_type":{"516118c0":"code","0985370b":"code","80863c29":"code","e97b98d9":"code","6441d68c":"code","d2ef46af":"code","b62fbfae":"code","60b3a5b1":"code","d7fdcf62":"code","0b966dd1":"code","aa4d3c3b":"code","7e5393a6":"code","dea12735":"code","450b755e":"code","f449ec8e":"code","d6f2618f":"markdown","33aded2a":"markdown","63e99268":"markdown","dd42ba47":"markdown","289a47a5":"markdown","556aca82":"markdown","d99e2d58":"markdown"},"source":{"516118c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0985370b":"train_images = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntest_images = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","80863c29":"Y_train = train_images['label'].values\nY_test = test_images['label'].values\n\nX_train = train_images.drop([\"label\"],axis=1).values\nX_test = test_images.drop([\"label\"],axis=1).values","e97b98d9":"X_train = X_train.reshape(-1,28,28)\nX_test = X_test.reshape(-1,28,28)\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i],cmap=plt.get_cmap('gray'))\n    plt.xlabel(Y_train[i])\nplt.show()","6441d68c":"X_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)","d2ef46af":"X_train = X_train\/255.0\nX_test = X_test\/255.0","b62fbfae":"X_train.shape","60b3a5b1":"label_binrizer = LabelBinarizer()\nY_train = label_binrizer.fit_transform(Y_train)\nY_test = label_binrizer.fit_transform(Y_test)","d7fdcf62":"train_datagen = ImageDataGenerator(rotation_range=30, zoom_range=0.2, horizontal_flip = True,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n                                   fill_mode='nearest')","0b966dd1":"validation_datagen = ImageDataGenerator()","aa4d3c3b":"model = Sequential()\nmodel.add(Conv2D(filters= 32 , kernel_size=(3,3), padding = 'same', activation = 'relu' , input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides = 2, padding = 'same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3) , padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides = 2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding = 'valid', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2) , strides = 2))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(24, activation = 'softmax'))","7e5393a6":"model.compile(optimizer= 'adam' ,loss = 'categorical_crossentropy',metrics = ['accuracy'])\nmodel.summary()","dea12735":"history = model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=32),\n                              steps_per_epoch=len(X_train) \/\/ 32,\n                              epochs=10,\n                              validation_data=validation_datagen.flow(X_test, Y_test, batch_size=32),\n                              validation_steps=len(X_test) \/\/ 32)","450b755e":"model.evaluate(X_test, Y_test, verbose=0)","f449ec8e":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","d6f2618f":"Don't forget to upvote, if you found my notebook useful.","33aded2a":"## Image augmentation","63e99268":"# CNN Sign Language Classifier","dd42ba47":"## Importing Libraries and dataset","289a47a5":"## Model","556aca82":"## Reshaping, Normalisation and Encoding","d99e2d58":"## Evaluate"}}