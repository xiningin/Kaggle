{"cell_type":{"1e6379f6":"code","5cb33ad8":"code","7912cfb5":"code","cc5ecd5d":"code","fc5b79b1":"code","27c5352b":"code","183068ac":"code","7912a1cc":"code","d7a0c0cd":"code","d0ecf1e9":"code","b3bf8311":"code","ce0672f8":"code","775992ba":"code","baaf656b":"code","f1b5de02":"code","85f32ecc":"code","a4825224":"code","7bd4fe3e":"code","3a9ec8b6":"code","3180934d":"code","a80fedcc":"code","69a77974":"code","17820dd3":"code","8c56ff9b":"code","845e4869":"code","58a756d4":"code","d39f98c5":"code","c2f5829b":"code","c00b29a2":"code","9bffd32d":"code","8719c767":"code","1d443636":"code","b1286a76":"code","33011b7e":"code","7dc8e13f":"code","5078866d":"code","017deeca":"code","cb96e61f":"code","35e77cf1":"code","939bf98e":"code","904c3245":"code","779f1625":"code","f5d1da70":"code","018a17d4":"code","28027eb4":"code","dee7bf31":"code","923c6c81":"code","c6d845aa":"code","12bb6e65":"code","cdb0a74f":"code","9345fd1b":"code","bdaa7a21":"code","a3591870":"code","0c73475f":"code","d3e3c1a7":"code","804bdd2d":"markdown","22ba3853":"markdown","0f226cc6":"markdown","a4e27527":"markdown","562fb18d":"markdown","74057ade":"markdown","d32a2695":"markdown","e7eebadd":"markdown","940688df":"markdown","03cd8068":"markdown","c04226ee":"markdown"},"source":{"1e6379f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5cb33ad8":"from os import listdir","7912cfb5":"train_path ='..\/input\/train\/'\nlistdir(train_path)[:10]","cc5ecd5d":"len(listdir(train_path))","fc5b79b1":"test_path = '..\/input\/test_stg1\/'","27c5352b":"listdir(test_path)[:10]","183068ac":"len(listdir(test_path))","7912a1cc":"submission = pd.read_csv('..\/input\/sample_submission_stg1.csv')","d7a0c0cd":"submission.head()","d0ecf1e9":"from tqdm import tqdm\ndef loadBatchImages(path):\n    catList = listdir(path)\n    loadedImages = []\n    loadedLabels = []\n    for cat in catList:\n        if not cat.startswith('.'):\n            deepPath = path+cat+\"\/\"\n            imageList = listdir(deepPath)\n            for images in tqdm(imageList):\n                img = deepPath + images\n                loadedLabels.append(cat)\n                loadedImages.append(img)\n            \n    return loadedImages, loadedLabels","b3bf8311":"loadedImages, loadedLabels = loadBatchImages(train_path)","ce0672f8":"num_classes = len(np.unique(loadedLabels))","775992ba":"num_classes","baaf656b":"#Encode labels with value between 0 and n_classes-1.\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nloadedLabels = np.asarray(loadedLabels)\nencoder.fit(loadedLabels)\nencoded_loadedLabels = encoder.transform(loadedLabels)","f1b5de02":"# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\nlabels_Hot = to_categorical(encoded_loadedLabels, num_classes = num_classes)","85f32ecc":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","a4825224":"df= pd.DataFrame()","7bd4fe3e":"df['path']=loadedImages\ndf['labels'] = list(labels_Hot)","3a9ec8b6":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","3180934d":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(df, \n                                   test_size = 0.25, \n                                   random_state = 2018)\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","a80fedcc":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 128)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 1024)) # one big batch","69a77974":"t_x, t_y = next(train_gen)","17820dd3":"t_x.shape[1:]","8c56ff9b":"img_dim = t_x.shape[1:]","845e4869":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Flatten, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom sklearn.metrics import fbeta_score","58a756d4":"num_classes = len(labels_Hot[0])","d39f98c5":"num_classes","c2f5829b":"input_tensor = Input(shape=img_dim)\nbase_model = VGG16(include_top=False,input_shape=img_dim)\n    \nbn = BatchNormalization()(input_tensor)\nx = base_model(bn)\nx = Flatten()(x)\noutput = Dense(num_classes, activation='softmax')(x)\nmodel = Model(input_tensor, output)\nmodel.summary()","c00b29a2":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nfrom keras.optimizers import Adam","9bffd32d":"history = History()\ncallbacks = [history, \n             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-7, verbose=1),\n             ModelCheckpoint(filepath='weights.best.hdf5', verbose=1, save_best_only=True, \n                             save_weights_only=True, mode='auto')]","8719c767":"model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])","1d443636":"batch_size = 128\nsteps_per_epoch = len(train_df)\/batch_size","b1286a76":"steps_per_epoch","33011b7e":"model.fit_generator(train_gen,steps_per_epoch=steps_per_epoch,validation_data = (test_X, test_Y), \n                                  epochs = 25,callbacks = callbacks)","7dc8e13f":"model.load_weights('weights.best.hdf5')","5078866d":"import glob\nfrom glob import glob\ntest_image_paths = glob(test_path +'*.jpg', recursive=True)","017deeca":"test_image_paths[:10]","cb96e61f":"X_test = pd.DataFrame()","35e77cf1":"X_test['path'] = test_image_paths","939bf98e":"X_test['image'] = X_test['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])","904c3245":"X_test.head()","779f1625":"test_gen = flow_from_dataframe(core_idg, X_test, \n                             path_col = 'path',\n                            y_col = 'image', \n                            target_size = IMG_SIZE,\n                            batch_size = 256) # we can use much larger batches for evaluation","f5d1da70":"pred_Y =  model.predict_generator(test_gen,verbose = 1)","018a17d4":"len(pred_Y)","28027eb4":"pred_Y[0]","dee7bf31":"submission = pd.DataFrame()","923c6c81":"X_test['image'].head()","c6d845aa":"submission['image'] = X_test['image']","12bb6e65":"unique_labels = np.unique(loadedLabels)","cdb0a74f":"unique_labels","9345fd1b":"encoder.fit(unique_labels)\nencoder.transform(unique_labels)","bdaa7a21":"for i,label in enumerate(list(unique_labels)):\n    print(i,label)","a3591870":"for i,label in enumerate(list(unique_labels)):\n    submission[label] = pred_Y[:,i]","0c73475f":"submission.head()","d3e3c1a7":"submission.to_csv('predictions.csv',index = False)","804bdd2d":"# Vgg16","22ba3853":"# Flow from DataFrame","0f226cc6":"# Test Data Preparation","a4e27527":"*  **Xplore the files**           \nExaminations of the files present in the Dataset is done in this section                \n*  **Labels analysis**\nLabels analysis of the labels found in the Train dataset            \n*  **Creating the One Hot Encoding of the labels**  \nThis is a `Multilabel Classification` problem , hence a One Hot Encoding of the labels need to be done          \n*   **Create the Data Generators**                   \nCreate the Train , Test Data Generators             \n* **Flow from DataFrame**     \nThis section defines the functions so that the paths \n* **Model Creation**\nThis is the section where the Actual Model is built\n* **Test Data Preparation**     \nThe Test Data is prepared so that it can be sent to the Model\n* **Map Predictions**\nThe predictions are mapped for the Submission File\n","562fb18d":"# Xplore the files","74057ade":"# Finetune Vgg16","d32a2695":"# Plan","e7eebadd":"# Create Data Generators","940688df":"# Labels analysis","03cd8068":"# Create the Dataframe for the Datagenerators","c04226ee":"# Creating the OHE vector for the labels"}}