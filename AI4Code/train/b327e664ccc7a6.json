{"cell_type":{"36105143":"code","89b9c638":"code","6e9698ba":"code","d3eff7c4":"code","839b313a":"code","7fa8dfd2":"code","9c79ec3e":"code","037ff6be":"code","fe15c1db":"code","268d017f":"code","a907d71a":"code","f3c68871":"code","bb6848f1":"code","28415d6a":"code","ba4a1f69":"code","92e69c5f":"code","b032b27b":"markdown","4feeca7c":"markdown","2247d2f0":"markdown","59a82d63":"markdown","705f08b4":"markdown","96c80a45":"markdown","53a3f9d6":"markdown","3f808a09":"markdown","836f14ac":"markdown","967ebd7f":"markdown","bb2de794":"markdown","4c04fc4f":"markdown","cf2d7cbe":"markdown","f6990d79":"markdown","d97621f7":"markdown","466dd51d":"markdown","86dbab8b":"markdown","2bba3079":"markdown","b55aa8cd":"markdown","d78cdfa9":"markdown","e428a949":"markdown"},"source":{"36105143":"import pandas as pd # Para manipular dataframes\nimport numpy as np # Para hacer cuentas con arrays\nimport itertools # Para iterar sobre combinaciones de hiperpar\u00e1metros\nimport torch # Para implementar algoritmos de deep learning\nimport pickle # Para guardar estados parciales del loop de tuneo de hiperpar\u00e1metros\nfrom sklearn.impute import SimpleImputer # Para llenar missings num\u00e9ricos\nfrom sklearn.model_selection import train_test_split, StratifiedKFold # Para dividir los datos de entrenamiento en train y validation sets, y para hacer cross-validation\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder # Para ajustar la escala de los atributos num\u00e9ricos y definir dummy variables\nfrom sklearn.compose import make_column_transformer # Para generar un algoritmo de procesamiento para cada atributo\nfrom sklearn.pipeline import Pipeline # Para crear pipelines de transformaciones, esto lo saqu\u00e9 de la documentaci\u00f3n de sklearn\nfrom sklearn.metrics import balanced_accuracy_score # Para medir la weighted accuracy\n\nrand_state = 42 # Semilla para que todos los shuffles sean iguales y poder comparar los resultados de forma correcta","89b9c638":"def init_params(m): # Funci\u00f3n para inicializar los par\u00e1metros de la red (siguiendo los consejos del libro en el cap\u00edtulo 4)\n  if(type(m) == torch.nn.Linear): # S\u00f3lo modifico los m\u00f3dulos que son capas lineales\n    torch.nn.init.xavier_normal_(m.weight) # Aplico la inicializaci\u00f3n de Xavier para los pesos\n    torch.nn.init.zeros_(m.bias) # Inicializo con ceros los bias\n\ndef add_dropout(layers,dp_max = 0.5): # Agrega dropout a las capas\n  N = len(layers) # N\u00famero de capas para dropoutear\n  dp = dp_max\/N # Agrego una probabilidad de dropout linealmente incremental desde la primera capa oculta (dp_1 = 0) \n                # hasta la \u00faltima (dp_N = dp_max)\n    \n  for i in range(N): # Itero sobre todas las capas\n    layers[i] += (torch.nn.Dropout((i + 1)*dp),) # Ac\u00e1 ten\u00eda la tupla (Linear,ReLU) y le agrego el m\u00f3dulo Dropout.\n                                                 # Es una concatenaci\u00f3n de tuplas, estoy re loco\n\n  return layers\n\ndef get_weights(net): # Devuelve los par\u00e1metros de la red \"net\" separados en dos conjuntos: wd_params (pesos) para aplicarles weight decay y no_wd_params (biases) para no hacerles nada\n  wd_params = [] # Par\u00e1metros que voy a afectar por weight decay\n  no_wd_params = [] # Par\u00e1metros sin weight decay\n  for name, param in net.named_parameters(): # Itero sobre (nombe,par\u00e1metro) en toda la red\n    if('weight' in name):\n      wd_params.append(param)\n    else:\n      no_wd_params.append(param)\n  return wd_params, no_wd_params\n\ndef train_test_mlp(train_dataset,val_dataset,num_extra_hidden_layers,num_hidden_nodes,\n                   batch_size,num_epochs,lr,optim_alg,wd,dp_max,progress = False,val_data = True): # Entrena y valida un MLP configurable\n\n  # Genero iteradores de entrenamiento (multibatch) y validaci\u00f3n (batch \u00fanico)\n  train_iter = torch.utils.data.DataLoader(train_dataset,batch_size,shuffle = True,num_workers = 4) # Iterador para cargar los minibatches del training set\n\n  if(val_data): # Si estoy usando datos de validaci\u00f3n\n    val_iter = torch.utils.data.DataLoader(val_dataset,val_dataset.__dict__['tensors'][0].shape[0]) # Iterador para cargar el validation set (un solo batch)\n\n  num_features = train_dataset.__dict__['tensors'][0].shape[1] # N\u00famero de atributos (me cost\u00f3 ubicarlo en el TensorDataSet)\n  num_labels = len(train_dataset.__dict__['tensors'][1].unique()) # N\u00famero de categor\u00edas (me cost\u00f3 ubicarlo en el TensorDataSet)\n    \n  # DEFINO LA RED (MODELO) --> La arquitectura es s\u00f3lo parcialmente configurable. \n  #                        --> Todas las capas son lineales y tienen una funci\u00f3n de activaci\u00f3n no lineal (excepto la capa de salida)\n  #                        --> Las capas ocultas interiores tienen todas el mismo n\u00famero de nodos de entrada y salida (son cuadradas), \n  #                            para reducir la cantidad de hiperpar\u00e1metros y simplificar\n  #                        --> Usamos s\u00f3lo ReLU como funci\u00f3n de activaci\u00f3n en todas las capas\n  #                        --> El dropout tambi\u00e9n es s\u00f3lo parcialmente conifigurable. El hiperpar\u00e1metro es el valor m\u00e1ximo de probabilidad\n  #                            de dropout (dp_max), y el valor que se configura en cada capa crece linealmente desde 0 hasta dp_max\n  #                        --> El weight decay tambi\u00e9n... ponemos el mismo en todos los par\u00e1metros de peso de la red (los biases no decaen)\n  #                        \n  extra_hidden_layers = [(torch.nn.Linear(num_hidden_nodes,num_hidden_nodes),\n                          torch.nn.ReLU()) for _ in range(num_extra_hidden_layers)] # Capas ocultas (cuadradas) extra. Las guardo como tuplas (linear,f_act)\n\n  extra_hidden_layers = add_dropout(extra_hidden_layers,dp_max = dp_max) # Agrego dropout a las capas ocultas intermedias\n\n  net = torch.nn.Sequential(torch.nn.Linear(num_features,num_hidden_nodes), # Primera capa oculta, lineal\n                            torch.nn.ReLU(), # Primera funci\u00f3n de activaci\u00f3n\n                            *[layer for layer_tuple in extra_hidden_layers for layer in layer_tuple], # Capas ocultas y funciones de activaci\u00f3n extra\n                            torch.nn.Linear(num_hidden_nodes,num_labels)) # Capa externa, lineal\n\n  weights,biases = get_weights(net) # Separo los par\u00e1metros en weights y biases (para todas las capas) \n\n  net.apply(init_params) # Inicializo los par\u00e1metros de la red\n            \n  L = torch.nn.CrossEntropyLoss() # Defino la funci\u00f3n de p\u00e9rdida (entrop\u00eda cruzada)\n\n  # AC\u00c1 NOS MANDAMOS UNA MACANA. LO DEJO COMO EST\u00c1 PARA QUE QUEDE LA EVIDENCIA DEL ERROR.\n  # En la siguiente l\u00ednea, definimos el algoritmo de optimizaci\u00f3n agregando el weight decay.\n  # Sin embargo, en la l\u00ednea que le sigue, VOLVEMOS A DEFINIR EL OPTIMIZADOR PERO SIN WEIGHT DECAY\n  # Esto pas\u00f3 porque la primera versi\u00f3n era sin weight decay, y cuando lo agregamos no borramos la vieja.\n  # Y, desafortunadamente, en el orden de las cosas qued\u00f3 la l\u00ednea SIN decay m\u00e1s abajo.\n  # Por lo tanto, no entrenamos ninguna red con weigth decay...\n  trainer = optim_alg([{\"params\":weights,'weight_decay': wd},\n                       {\"params\":biases}],lr = lr) # Defino el algoritmo de optimizaci\u00f3n\n  trainer = optim_alg(net.parameters(),lr = lr) # Defino el algoritmo de optimizaci\u00f3n\n  \n  # ENTRENO Y EVAL\u00daO LA RED\n  net.train() # Activo el modo de entrenamiento\n  for e in range(num_epochs): # Itero sobre todas las \u00e9pocas\n    # ENTRENAMIENTO  \n    for X,y in train_iter: # Itero sobre todos los minibatches de entrenamiento\n      loss = L(net(X),y) # Calculo la funci\u00f3n de p\u00e9rdida\n      trainer.zero_grad() # Reseteo los gradientes de todos los par\u00e1metros (esto es necesario porque por defecto autograd los acumula)\n      loss.backward() # Calculo el gradiente de la funci\u00f3n de p\u00e9rdida\n      trainer.step() # Actualizo los par\u00e1metros seg\u00fan el optimizador\n  \n    train_loss = 0 # Reseteo la p\u00e9rdida para calcular la nueva p\u00e9rdida con los valores actualizados de los par\u00e1metros\n    for X,y in train_iter: # Itero sobre todos los minibatches de entrenamiento\n      train_loss += L(net(X),y) # Calculo la funci\u00f3n de p\u00e9rdida TOTAL (usando todos los datos) al final de la \u00e9poca  \n    \n    # EVALUACI\u00d3N  \n    if(val_data): # Si estoy usando datos de validaci\u00f3n\n      net.eval() # Activo el modo de evaluaci\u00f3n\n      with torch.no_grad(): # Desactivo el c\u00e1lculo de gradientes cuando forwardeo a trav\u00e9s de la red (y para que funque balanced_accuracy_score)\n        for X,y in val_iter: # Accedo al \u00fanico batch de validaci\u00f3n en el iterador\n          val_pred = net(X).argmax(dim = 1) # Predicciones para el validation set (como son labels categ\u00f3ricos, elijo el de mayor probabilidark)\n        balanced_accuracy = balanced_accuracy_score(y,val_pred) # Weighted accuracy para el validation set      \n      if(progress):\n        print('\u00c9poca {}: L = {}; balanced_accuracy = {}'.format(e,train_loss,balanced_accuracy)) # Imprimo la p\u00e9rdida total y el balanced accuracy al final de la \u00e9poca\n    else:\n      if(progress):\n        print('\u00c9poca {}: L = {}'.format(e,train_loss)) # Imprimo la p\u00e9rdida total al final de la \u00e9poca\n\n  if(val_data): # Si estoy usando datos de validaci\u00f3n\n    return net,balanced_accuracy\n  else:\n    return net\n  \ndef cross_validation(train_data,train_data_labels,k_folds,transf_feat,transf_labels,hyperparam): # Realiza una cross-validation para un modelo\n  balanced_accuracy = [] # Lista vac\u00eda para guardar la performance de cada pliegue\n  \n  # Dado que las diferentes posiciones (_labels_) tienen probabilidades _prior_ diferentes, tiene m\u00e1s sentido usar\n  # un muestreo estratificado para mantener la distribuci\u00f3n de posiciones en el conjunto de entrenamiento y el de validaci\u00f3n.\n  \n  cross_val = StratifiedKFold(n_splits = k_folds,shuffle = True,random_state = rand_state) # Defino el objeto StratifiedKFold para la cross-validation\n  \n  fold = 0 # Inicializo el n\u00famero de fold\n  for train_idx,val_idx in cross_val.split(train_data,train_data_labels): # Itero sobre todos los \"pliegues\" (folds) de validaci\u00f3n\n    print('Fold: {}'.format(fold))\n    #--------------------------------------------\n    # Separo un _validation set_ \n    #--------------------------------------------\n    train_feat = train_data.iloc[train_idx] # Atributos de entrenamiento\n    train_labels = train_data_labels.iloc[train_idx] # Etiquetas de entrenamiento\n    val_feat = train_data.iloc[val_idx] # Atributos de validaci\u00f3n\n    val_labels = train_data_labels.iloc[val_idx] # Etiquetas de validaci\u00f3n\n    \n    #--------------------------------------------\n    # Entreno los _pipelines_ de transformaciones\n    #--------------------------------------------\n    transf_feat.fit(train_feat) # Utilizo \u00fanicamente los atributos del conjunto de entrenamiento \n    transf_labels.fit(train_labels); # Utilizo \u00fanicamente los labels del conjunto de entrenamiento \n    \n    #--------------------------------------------\n    # Aplico las transformaciones a todos los datos\n    #--------------------------------------------\n    train_feat_transf = torch.tensor(transf_feat.transform(train_feat),dtype = torch.float32) # Atributos del conjunto de entrenamiento (PyTorch quiere Float32s)\n    val_feat_transf = torch.tensor(transf_feat.transform(val_feat),dtype = torch.float32) # Atributos del conjunto de validaci\u00f3n (PyTorch quiere Float32s)\n    \n    train_labels_transf = torch.tensor(transf_labels.transform(train_labels),dtype = torch.long) # Labels del conjunto de entrenamiento (PyTorch quiere Longs)\n    val_labels_transf = torch.tensor(transf_labels.transform(val_labels),dtype = torch.long) # Labels del conjunto de entrenamiento (PyTorch quiere Longs)\n    \n    #--------------------------------------------\n    # Genero los datasets de entrenamiento y validaci\u00f3n para meterlos en el DataLoader\n    #--------------------------------------------\n    train_dataset = torch.utils.data.TensorDataset(train_feat_transf,train_labels_transf) # Creo un objeto de clase TensorDataset para usarlo en el framework Pytorch\n    val_dataset = torch.utils.data.TensorDataset(val_feat_transf,val_labels_transf) # Creo un objeto de clase TensorDataset para usarlo en el framework Pytorch\n    \n    #--------------------------------------------\n    #--------------------------------------------\n    # ENTRENAMIENTO DEL MODELO Y VALIDACI\u00d3N\n    #--------------------------------------------\n    #--------------------------------------------\n    net,bal_acc = train_test_mlp(train_dataset,val_dataset,*hyperparams.values()) # Entreno y valido este MLP con los datos de este fold\n    \n    balanced_accuracy.append(bal_acc) # Guardo la balanced accuracy de este fold\n    fold += 1 # Incremento el fold\n    \n  return balanced_accuracy\n\ndef train_full_dataset(train_feat,train_labels,transf_feat,transf_labels,hyperparams): # Entreno el modelo con todos los datos\n  #--------------------------------------------\n  # Entreno los _pipelines_ de transformaciones\n  #--------------------------------------------\n  transf_feat.fit(train_feat) # Utilizo \u00fanicamente los atributos del conjunto de entrenamiento \n  transf_labels.fit(train_labels); # Utilizo \u00fanicamente los labels del conjunto de entrenamiento \n    \n  #--------------------------------------------\n  # Aplico las transformaciones a todos los datos\n  #--------------------------------------------\n  train_feat_transf = torch.tensor(transf_feat.transform(train_feat),dtype = torch.float32) # Atributos del conjunto de entrenamiento (PyTorch quiere Float32s)\n  test_feat_transf = torch.tensor(transf_feat.transform(test_data),dtype = torch.float32) # Atributos del conjunto de prueba (PyTorch quiere Float32s)    \n\n  train_labels_transf = torch.tensor(transf_labels.transform(train_labels),dtype = torch.long) # Labels del conjunto de entrenamiento (PyTorch quiere Longs)\n   \n  #--------------------------------------------\n  # Genero el dataset de entrenamiento para meterlo en el DataLoader\n  #--------------------------------------------\n  train_dataset = torch.utils.data.TensorDataset(train_feat_transf,train_labels_transf) # Creo un objeto de clase TensorDataset para usarlo en el framework Pytorch\n   \n  #--------------------------------------------\n  #--------------------------------------------\n  # ENTRENAMIENTO DEL MODELO Y VALIDACI\u00d3N\n  #--------------------------------------------\n  #--------------------------------------------\n  net = train_test_mlp(train_dataset,None,*hyperparams.values(),progress = True,val_data = False) # Entreno este MLP con todos los datos\n    \n  return net,transf_feat,transf_labels","6e9698ba":"train_data = pd.read_csv('data\/fifa2021_training.csv') # Leo el archivo con los datos de entrenamiento\ntest_data = pd.read_csv('data\/fifa2021_test.csv') # Leo el archivo con los datos de prueba\n\ntrain_data_labels = train_data.pop('Position') # Saco las etiquetas del conjunto de entrenamiento y las guardo en un objeto separado","d3eff7c4":"print('N\u00famero de datos en el training set: {} \\nN\u00famero de datos en el test set: {}'.format(len(train_data),len(test_data)))\ntrain_data.head(4) # Imprimo las primeras 4 filas de test_data","839b313a":"num_feat_train = train_data.select_dtypes(np.number).columns # Atributos num\u00e9ricos\ncat_feat_train = train_data.select_dtypes(np.object).columns # Atributos categ\u00f3ricos, que incluyen a los booleanos con missings\n\nnum_feat_test = test_data.select_dtypes(np.number).columns # Atributos num\u00e9ricos\ncat_feat_test = test_data.select_dtypes(np.object).columns # Atributos categ\u00f3ricos, que incluyen a los booleanos con missings\n\nprint('Atributos num\u00e9ricos: {} \\n {} \\n'.format(len(num_feat_train),num_feat_train))\nprint('Atributos categ\u00f3ricos: {} \\n {} \\n'.format(len(cat_feat_train),cat_feat_train))\n\nprint('\u00bfCoinciden los atributos del training set con los del test set?: {}'.format(\n    (num_feat_train == num_feat_test).all() and (cat_feat_train == cat_feat_test).all()))","7fa8dfd2":"print('Training set:')\ntrain_nan_cols = train_data.isna().sum(axis = 0) # Cuento cu\u00e1ntos NaN hay en cada columna y guardo esos valores en un vector\nprint(train_nan_cols[np.where(train_nan_cols != 0)[0]]) # Imprimo s\u00f3lo los atributos que tienen missings\n\nprint('\\nTest set:')\ntest_nan_cols = test_data.isna().sum(axis = 0) # Cuento cu\u00e1ntos NaN hay en cada columna y guardo esos valores en un vector\nprint(test_nan_cols[np.where(test_nan_cols != 0)[0]]) # Imprimo s\u00f3lo los atributos que tienen missings","9c79ec3e":"bad_features = ['ID','Club','Club_KitNumber','Club_JoinedClub','Club_ContractLength',\n                'Name','Natinality','BirthDate','Value','Wage'] # Atributos que voy a descartar de manera cuasi ad hoc\n\nnum_feat = train_data.drop(columns = bad_features).select_dtypes(np.number).columns # Atributos num\u00e9ricos\ncat_feat = train_data.drop(columns = bad_features).select_dtypes(np.object).columns # Atributos categ\u00f3ricos, que incluyen a los booleanos con missings\n\nprint('Atributos num\u00e9ricos: {} \\n {} \\n'.format(len(num_feat),num_feat))\nprint('Atributos categ\u00f3ricos: {} \\n {} \\n'.format(len(cat_feat),cat_feat))","037ff6be":"#------ ATRIBUTOS ----------\n# Atributos num\u00e9ricos: (1) Llenado de missings con la mediana, (2) Escalado (estandarizaci\u00f3n; output con media 0 y varianza 1)\nnum_pipeline = Pipeline([('imputer', SimpleImputer(strategy = \"median\")), # Pipeline con transformaciones para los atributos num\u00e9ricos\n                         ('std_scaler', StandardScaler())])\n\n# Pipeline completo (ambos tipos de variables) para los atributos\ntransf_feat = make_column_transformer((num_pipeline,num_feat), # Pipeline para atributos num\u00e9ricos (ver m\u00e1s arriba)\n                                      (OneHotEncoder(),cat_feat), # A las variables categ\u00f3ricas s\u00f3lo las uanjotencodeo\n                                      remainder = 'drop') # Tiro todos los atributos que no est\u00e9n incluidos en num_feat y cat_feat\n\n\n#------ LABELS ----------\ntransf_labels = LabelEncoder() # Le asigna un valor entero a cada categor\u00eda, entre 0 y (N_class - 1)","fe15c1db":"# Hiperpar\u00e1metros y otras cuestiones\n# Ac\u00e1 va una lista de todos los hiperpar\u00e1metros y dem\u00e1s cosas configurables para cada modelo que voy a probar. \n# Mis modelos van a ser todos perceptrones multicapa con capas lineales. Todas las capas, excepto la primera, ser\u00e1n cuadradas \n# (el n\u00famero de entradas coincide con el n\u00famero de salidas), lineales y con funci\u00f3n de activaci\u00f3n `ReLU` a su salida.\n  \n# CONFIGURABLES (los voy a tunear)\nbatch_size = [32,64,256] # Tama\u00f1o del minibatch \nlearning_rate = [0.0001,0.001,0.01] # Learning rate\nnum_extra_hidden_layers = [1,2,3] # N\u00famero de capas ocultas extra (si vale 0, el modelo tiene una \u00fanica capa)\nweight_decay = [0,1,2] # Weight decay\ndropout_max = [0,0.3,0.6] # M\u00e1xima probabilidad de dropout\n\n# FIJOS (no los cambio)\nnum_epochs = 10 # N\u00famero de \u00e9pocas\nnum_hidden_nodes = 128 # N\u00famero de nodos en cada capa oculta\noptim_alg = torch.optim.Adam # Algoritmo de optimizaci\u00f3n\nk_folds = 10 # N\u00famero de pliegues en la cross-validation","268d017f":"#-----------------------------------------------------------------------------------------\n#-----------------------------------------------------------------------------------------\n#------------ WARNING, WARNING, \u00a1LA PC VA A EXPLOTAR! ------------------------------------\n#-----------------------------------------------------------------------------------------\n#-----------------------------------------------------------------------------------------\n# ESTO QUE VOY A HACER ES UNA ASQUEROSIDAD, PERO ESTOY MUY CANSADO Y QUIERO TERMINAR EL TP\n\n# results = [] # Lista vac\u00eda para guardar los resultados (cuando voy a empezar el loop)\n# m_idx = 0 # Inicializo un contador de modelos\nresults = pickle.load(open(\"results.pickle\",\"rb\")) # Cargo la lista de resultados (cuando quiero seguir el loop)\nm_idx = len(results) # Contin\u00fao un contador de modelos\n\nall_models = itertools.product(batch_size,learning_rate,num_extra_hidden_layers,weight_decay,dropout_max) # Defino todas las combinaciones de hiperpar\u00e1metros\ntest_models = itertools.islice(all_models,m_idx,None) # Testeo s\u00f3lo modelos nuevos (no vuelvo a testear algo que ya teste\u00e9)\n\nfor bs,lr,num_ex_hl,wd,dp_max in test_models: # Empiezo desde el \u00faltimo modelo ya entrenado\n  # Agrupo todo en un diccionario para que sea m\u00e1s legible el c\u00f3digo\n  hyperparams = {'num_extra_hidden_layers':num_ex_hl,'num_hidden_nodes':num_hidden_nodes,'batch_size':bs,\n                 'num_epochs':num_epochs,'lr':lr,'optim_alg':optim_alg,'wd':wd,'dp_max':dp_max} # Hiperpar\u00e1metros\n    \n  balanced_accuracy = cross_validation(train_data,train_data_labels,k_folds,transf_feat,transf_labels,hyperparams) # Realizo una cross-validation para este modelo\n\n  results.append([hyperparams,balanced_accuracy]) # Guardo la configuraci\u00f3n del modelo y su score\n  pickle.dump(results,open(\"results.pickle\",\"wb\")) # Guardo los datos en el disco\n                                                              \n  print('Modelo {}, mean_balanced_accuracy = {:.4f}'.format(m_idx,sum(balanced_accuracy)\/k_folds)) # Imprimo los resultados a medida que van saliendo, para matar la ansiedark\n  m_idx +=1 # Incremento el contador de modelos","a907d71a":"results = pickle.load(open(\"results.pickle\",\"rb\")) # Cargo la lista de resultados (cuando quiero seguir el loop)\n\nN_models = len(results) # N\u00famero de modelos\nmodel_performances = [] # Lista para guardar las mean_balanced_accuracies\n\nfor i in range(N_models): # Itero sobre todos los modelos\n  model = results[i] # Lista con los resultados de este modelo\n  mean_balanced_acc = 0 # Inicio el acumulador para calcular la mean balanced accuracy de este modelo\n\n  for bal_acc in model[1]: # Itero sobre las performances de cada pliegue\n    mean_balanced_acc += bal_acc\n\n  model_performances.append(mean_balanced_acc\/k_folds) # Guardo la parformance de este modelo","f3c68871":"best_things = [it_val for it_val in sorted(enumerate(model_performances),\n               key = lambda x:x[1],reverse = True)] # Un poco de magia pyth\u00f3nica para ordenar los modelos de mejor a peor\n\nfor i in range(10): # Muestro los mejores 10 modelos\n  print('Modelo {}, mean_balanced_accuracy = {:.4f}'.format(best_things[i][0],best_things[i][1]))","bb6848f1":"for i,bal_acc in enumerate(results[int(best_things[0][0])][1]): # Itero sobre todos los folds\n  print('Fold {}, bal_acc = {:.4f}'.format(i,bal_acc))","28415d6a":"# Hiperpar\u00e1metros del modelo ganador\nhyperparams = results[int(best_things[0][0])][0]\n\n# Entreno la red\nnet,transf_feat_final,transf_label_final = train_full_dataset(train_data,train_data_labels,transf_feat,transf_labels,hyperparams)","ba4a1f69":"test_feat_transf = torch.tensor(transf_feat_final.transform(test_data),dtype = torch.float32) # Atributos del conjunto de prueba (PyTorch quiere Float32s)\n\nnet.eval() # Activo el modo de evaluaci\u00f3n\n\nwith torch.no_grad(): # Desactivo el c\u00e1lculo de gradientes cuando forwardeo a trav\u00e9s de la red\n  test_labels_transf = net(test_feat_transf).argmax(dim = 1) # Determino los labels (transformados) del test set\n\ntest_labels = transf_label_final.inverse_transform(test_labels_transf) # Labels del test set, con el formato original (categor\u00edas)\ndata_out = pd.DataFrame({'Id':test_data['ID'],'Category':test_labels}) # DataFrame formateado para subirlo a Kaggle\ndata_out.to_csv('predicciones_hache_barra.csv',index = False) # Exporto el archivo .csv","92e69c5f":"submit_data = pd.read_csv('predicciones_hache_barra.csv') # Leo mis predicciones\nsubmit_example = pd.read_csv('sample_submission.csv') # Leo las predicciones del ejemplo que subieron los profes\n\nprint('my_submission_shape = {}'.format(submit_data.shape)) # Chequeo el n\u00famero de filas y columnas en mi archivo\nprint(submit_data.head(3)) # Reviso algunos datos de mis predicciones\nprint(submit_example.head(3)) # Reviso algunos datos del ejemplo\n\nprint('Fracci\u00f3n de coincidencias con el random guessing: {:.3f}'.format((submit_data['Category'] == submit_example['Category']).sum()\/submit_data.shape[0])) # Chequeo cu\u00e1ntas predicciones de mi modelo coinciden con el random guessing del ejemplo","b032b27b":"### Chequeo el formato del archivo que acabo de crear","4feeca7c":"### Selecci\u00f3n de atributos\nDecido _ad hoc_ que los atributos `ID', 'Name`, `Natinality` (que, por cierto, est\u00e1 mal escrito) y `BirthDate` no me van a servir para predecir la posici\u00f3n del jugador. Adem\u00e1s, en otro _notebook_ analic\u00e9 por separado todos los atributos y verifiqu\u00e9 que `Value` y `Wage` tienen poca capacidad predictiva usando un modelo lineal, y como tienen tantos _missings_ me parece que redundarlos con su valor medio va a meter ruido nom\u00e1s. Entonces, combinando esto con lo que analic\u00e9 antes, voy a descartar los siguientes atributos: `Value`, `Wage`, `Club`, `Club_KitNumber`, `Club_JoinedClub`, `Club_ContractLength`, `Name`, `Natinality` y `BirthDate`. El atributo `Sex` podr\u00eda ser un buen predictor dado que hay muchos menos datos de mujeres que de hombres y posiblemente la proporci\u00f3n de posiciones no sea la misma en ambas subpoblaciones. Adem\u00e1s, por ejemplo, si la altura predice la posici\u00f3n, sabemos que la distribuci\u00f3n de alturas depende del sexo as\u00ed que puede tener una influencia.","2247d2f0":"### Selecci\u00f3n del modelo final y entrenamiento\nDe todos los modelos que prob\u00e9, el que tenga mejor _mean_balanced_accuracy_ va a ser mi decisi\u00f3n final. Ac\u00e1 lo voy a entrenar con todos los datos del _training_set_ original, para luego hacer las predicciones con el _test_set_ y subirlas a Kaggle.","59a82d63":"### Funciones para automatizar el proceso","705f08b4":"Si est\u00e1 todo ok, procedo a entrenar el modelo ganador con todos los datos","96c80a45":"# Trabajo Pr\u00e1ctico N\u00b02:\n## Estudiantes: \n### Fabi\u00e1n Giana, Javier V\u00e9lez y Mauro Gentile","53a3f9d6":"Casi arbitrariamente, me llam\u00f3 la atenci\u00f3n el atributo `PlayerWorkRate`, que [seg\u00fan la FIFA](https:\/\/www.fifplay.com\/encyclopedia\/work-rate\/) mide cu\u00e1nto participa el jugador en el ataque y en la defensa. Sospecho que va a ser uno de los mejores predictores. **EDIT:** con el diario del lunes, mi sospecha era incorrecta.","3f808a09":"### Valores faltantes\nMe fijo cu\u00e1ntos _missings_ hay en cada atributo:","836f14ac":"### Transformaciones\nAc\u00e1 voy a definir todas las transformaciones que tengo que hacer sobre los datos antes de ingresarlos al MLP. Estas transformaciones incluyen:\n\n1. Llenado de _missings_. **EDIT**: finalmente saqu\u00e9 todos los atributos con missings en el training set, pero los datos nuevos podr\u00edan tenerlos as\u00ed que defino un transformador igual.  **EDIT 2**: me olvid\u00e9 de definir un imputador de _missings_ categ\u00f3ricos.  \n2. Codificaci\u00f3n de los atributos categ\u00f3ricos (incluyendo el _target_, `Position`).  \n3. Escalado de los atributos num\u00e9ricos.  ","967ebd7f":"# NOTA FINAL","bb2de794":"Este proceso de selecci\u00f3n del mejor modelo lo hicimos cada uno por separado, as\u00ed que las tres _submissions_ son diferentes en t\u00e9rminos de la exploraci\u00f3n de hiperpar\u00e1metros. Por otro lado, por cuestiones de tiempo (y seguramente de sentido com\u00fan) no alcanzamos a probar todas las combinaciones de hiperpar\u00e1metros, as\u00ed que el modelo cuyas predicciones subimos no necesariamente es el mejor de los que pens\u00e1bamos probar. ","4c04fc4f":"Reviso que el _balanced_accuracy_ sea relativamente similar entre los diferentes _folds_ para el modelo ganador. Deber\u00eda implementar algo como calcular la varianza o el error est\u00e1ndar, pero ya a esta altura no hay energ\u00eda as\u00ed que vamos a mirarlos a ojo.","cf2d7cbe":"### Entrenamiento y evaluaci\u00f3n de modelos\nAc\u00e1 voy a definir un conjunto de modelos, donde cada uno tiene diferentes hiperpar\u00e1metros, y voy a calcular la _cross-validation_ para cada uno. El que tenga mejor _mean_balanced_accuracy_ va a ser mi decisi\u00f3n final.","f6990d79":"Los atributos `Value`, `Wage`, `Club`, `Club_KitNumber`, `Club_JoinedClub`, y `Club_ContractLength` tienen _missings_ tanto en el training set como en el test set. Si bien los atributos `Value` (que asumo es el \"valor econ\u00f3mico de le jugador\", hablando de objetivizaci\u00f3n...) y `Wage` (que asumo es el sueldo de le jugador) podr\u00edan tener capacidad predictiva (capaz los delanteros ganen m\u00e1s que los defensores, o capaz los mediocampistas \"valgan m\u00e1s\" que los arqueros), los otros atributos con _missings_ no deber\u00edan presentar poder predictivo, as\u00ed que los voy a descartar.","d97621f7":"# Aprendizaje Profundo | Oto\u00f1o 2021 by Datitos\n![71335171.png](data:image\/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACwElEQVR4nOzdMY7iQBBA0WU197\/FnJNNJ\/FqWvLHZfd7McIGfVVQos3X+\/3+A2f7e\/UN8EzCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBJfV9\/A\/7xer6XX3\/1\/gZ70eU0sEsIiISwSwiIhLBLCIiEsEiP2WEf7m9U9zVnvU9vh85pYJIRFQlgkhEVCWCSERUJYJEbssc5ytL+5at8zec9UM7FICIuEsEgIi4SwSAiLhLBIPGqPdWR1v1VfdwcmFglhkRAWCWGREBYJYZEQFokt9lhHdt4z1UwsEsIiISwSwiIhLBLCIiEsEh\/dY+18zq4w7RzlTyYWCWGREBYJYZEQFglhkRAWiS1+jzVhr\/Mbd7nP3zCxSAiLhLBICIuEsEgIi4SwSDxqj1U\/72r1ulc9l2sCE4uEsEgIi4SwSAiLhLBICIvE7D3W9\/fSy6\/63dLqdZfvc\/F7mMDEIiEsEsIiISwSwiIhLBLCIjF7j3WSs87rTXufyUwsEsIiISwSwiIhLBLCIiEsEq8Ju5N6r3OXc3xP2oeZWCSERUJYJIRFQlgkhEVCWCRG7LGOTN7TfNIdvwcTi4SwSAiLhLBICIuEsEgIi8Toc4U7Pyf9p8n7qiMmFglhkRAWCWGREBYJYZEQFonRe6wjd9zr7MbEIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi8S8AAP\/\/HtRtH09JwIEAAAAASUVORK5CYII=)","466dd51d":"### M\u00f3dulos que voy a usar","86dbab8b":"### Carga de datos\nPrimero cargo los datos y miro las primeras filas para verificar que son los datos correctos:","2bba3079":"### Separaci\u00f3n de los atributos por tipo\nAhora voy a separar los atributos seg\u00fan tipo (num\u00e9ricos y categ\u00f3ricos) y ver cu\u00e1ntos hay de cada uno. Tambi\u00e9n voy a chequear que los atributos del _training set_ coincidan con los del _test set_:","b55aa8cd":"# PREDICCIONES SOBRE EL TEST SET","d78cdfa9":"# PREPROCESAMIENTO DE LOS DATOS","e428a949":"Veo que el n\u00famero de instancias en el _test set_ no coincide con el n\u00famero que se solicita en la competencia de Kaggle. **Consultar a los profes.**"}}