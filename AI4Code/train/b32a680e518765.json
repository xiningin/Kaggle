{"cell_type":{"f4b7c6cd":"code","d4e7b101":"code","a2700637":"code","040fe148":"code","36b4258c":"code","0e6b7841":"code","96c771a2":"markdown","83b4044c":"markdown","e59c75d6":"markdown","5bb5da82":"markdown"},"source":{"f4b7c6cd":"!pip install mtcnn","d4e7b101":"from mtcnn import MTCNN\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom tensorflow.keras.models import Model, load_model\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\npd.set_option('display.max_columns', 80)","a2700637":"def crop(img):\n    # x, y, width, height = result['box']\n    s=1.2\n    height=img.shape[0]\n    width=img.shape[1]    \n    detector = MTCNN()\n    data=detector.detect_faces(img) \n    if data==[]:\n        return False, None\n    else:\n        for i, faces in enumerate(data): # iterate through all the faces found\n            box=faces['box']  # get the box for each face\n            biggest=0                    \n            area = box[2] * box[3]\n            if area>biggest:\n                biggest=area\n                bbox=box\n            x,y,w,h=bbox  \n            xn=int(x +w\/2)-int(w * s\/2)\n            yn=int(y+h\/2)- int(h * s\/2)\n            xen=int(x +w\/2) + int(w * s\/2)\n            yen=int(y+h\/2) + int(h * s\/2)\n            bbox[0]= 0 if bbox[0]<0 else bbox[0]\n            xn=0 if xn<0 else xn\n            yn=0 if yn<0 else yn\n            xen= width if xen>width else xen\n            yen= height if yen>height else yen\n            img=img[yn:yen, xn:xen]            \n            return True, img","040fe148":"def classify(sdir, csv_path,  model_path, name, crop_image = False):    \n    # read in the csv file\n    e=1.2\n    class_df=pd.read_csv(csv_path)    \n    img_height=int(class_df['height'].iloc[0])\n    img_width =int(class_df['width'].iloc[0])\n    img_size=(img_height, img_width)    \n    scale=class_df['scale by'].iloc[0]     \n    try: \n        s=int(scale)\n        s2=s\n        s1=0\n    except:\n        split=scale.split('-')\n        s1=float(split[1])\n        s2=float(split[0].split('*')[1]) \n    \n    path_list=[]\n    paths=os.listdir(sdir)\n    for f in paths:\n        path_list.append(os.path.join(sdir,f))\n    print (' Model is being loaded- this will take about 10 seconds')\n    model=load_model(model_path)\n    image_count=len(path_list) \n    index_list=[] \n    prob_list=[]\n    cropped_image_list=[]\n    good_image_count=0\n    for i in range (image_count):       \n        img=plt.imread(path_list[i])        \n        if crop_image == True:\n            status, img=crop(img)            \n        else:\n            status=True\n        if status== True:\n            good_image_count +=1\n            img=cv2.resize(img, img_size)             \n            cropped_image_list.append(img)\n            img=img*s2 - s1\n            img=np.expand_dims(img, axis=0)\n            p= np.squeeze (model.predict(img))           \n            index=np.argmax(p)             \n            prob=p[index]\n            index_list.append(index)\n            prob_list.append(prob)\n    if good_image_count==1:        \n        class_name= class_df['class'].iloc[index_list[0]]\n        probability= prob_list[0]\n        img=cropped_image_list [0]\/255 \n        plt.title(class_name, color='blue', fontsize=16)\n        plt.axis('off')\n        plt.imshow(img)\n        return class_name, probability\n    elif good_image_count == 0:\n        return None, None\n    most=0\n    for i in range (len(index_list)-1):\n        key= index_list[i]\n        keycount=0\n        for j in range (i+1, len(index_list)):\n            nkey= index_list[j]            \n            if nkey == key:\n                keycount +=1                \n        if keycount> most:\n            most=keycount\n            isave=i             \n    best_index=index_list[isave]    \n    psum=0\n    bestsum=0\n    for i in range (len(index_list)):\n        psum += prob_list[i]\n        if index_list[i]==best_index:\n            bestsum += prob_list[i]\n        else:\n            bestsum += 1-prob_list[i]\n    img= cropped_image_list[isave]\/255    \n    class_name=class_df['class'].iloc[best_index]\n    plt.title(class_name, color='blue', fontsize=16)\n    plt.axis('off')\n    plt.imshow(img)\n    return class_name, bestsum\/image_count","36b4258c":"predict_dir=r'..\/input\/autistic-children-data-set-traintestvalidate\/autism-rev2\/images to predict'  \nname='summary diagnosis average for all images'\nmloc=r'..\/input\/autistic-children-data-set-traintestvalidate\/autism-rev2\/EfficientNetB4-Autism-92.00.h5'\ncsvloc=r'..\/input\/autistic-children-data-set-traintestvalidate\/autism-rev2\/class_dict.csv'\nresult, probability=classify(predict_dir, csvloc,mloc, name, crop_image=True)\nprint (f' {name} is predicted as being {result} with a probability of {probability * 100:5.2f} %')","0e6b7841":"predict_dir=r'..\/input\/autistic-children-data-set-traintestvalidate\/autism-rev2\/single image to predict'\nname='diagnosis'\nresult, probability=classify(predict_dir, csvloc,mloc, name, crop_image=True)\nprint (f' {name} is predicted as being {result} with a probability of {probability * 100:5.2f} %')","96c771a2":"### define a function that takes in an image and detects the faces in the image\n### if there are multiple faces in the image it selects the faces having the most\n### pixels in it and returns that as the cropped facial image","83b4044c":"### This code use a trained model EfficientNetB4-Autism-92.00.h5 with an F1 score on the test set of 92% to make predictions on either a single image or on multiple images. When multiple images are used they should be of the SAME child. The kernel has a function crop which will crop the image to be just that of the face. See directory images to predict for the types of images to use. If the images you have are already cropped to the face then set crop=False in the kernels parameter list.\n## NOTE this code should NOT be considered a medical diagnosis.\n### The dataset used to train the model is of insufficient quality to produce results with a satisfactorly high confidence level.To achieve that level a much larger data set is need and the images of all children used for training would require a complete medical diagnosis prior to using the childs image as part of the dataset. I have tried to solict help to produce said dataset but have achieved no assistance to date.","e59c75d6":"### code below process the images in the images to predict directory. Ideally these\n### images would be different images of the same child so an averaged prediction for\n### the single child would result. However I was not able to gather mltiples images of\n### the same child so I included images of other children with autism for demonstration\n### purposes.","5bb5da82":"### code below demonstrates use with a single image"}}