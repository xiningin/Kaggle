{"cell_type":{"1745877d":"code","5152842d":"code","c20f4881":"code","4eb09e84":"code","629c2817":"code","4c253059":"code","ee763fa8":"code","50442313":"code","a72e88f7":"code","c0b59d38":"code","b300978f":"code","75ab048b":"code","43531a4c":"code","e7bf7bd7":"code","31c02c27":"code","3d91f051":"code","89b3123b":"markdown","eb744a95":"markdown"},"source":{"1745877d":"# import necessary libraries\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras import preprocessing, layers\nfrom keras.models import Model\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport os\nimport cv2\nfrom PIL import Image\nimport pickle\nfrom pathlib import Path\n\nimport imageio\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport os\n","5152842d":"# read in data \/ paths\n\ntest_img = ('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/test\/')\ntrain_img = ('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/')\ntrain_data = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv')\nss = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/sample_submission.csv')","c20f4881":"train_data.fillna(0, inplace=True)","4eb09e84":"files = np.load('..\/input\/unique-image-arrays\/arrays.npz')\n\narrays = [files[key] for key in files]","629c2817":"nps=[]\n\nfor x in arrays:\n    new = np.resize(x,(256,256))\n    new = np.asarray(new)\n    new = keras.preprocessing.image.img_to_array(new)\n    nps.append(new)","4c253059":"class_labels = np.stack(labels)\nbbox_bound = np.stack(boxes)\ndata = np.stack(nps)","ee763fa8":"X_train, X_test, y_lab_train, y_lab_test, y_box_train, y_box_test =train_test_split(data, \n                                                                                     class_labels, \n                                                                                     bbox_bound.astype(int), \n                                                                                     test_size=0.2, \n                                                                                     shuffle=True, \n                                                                                     random_state=34)","50442313":"model2 = tf.keras.models.load_model('..\/input\/cnn-model\/model')","a72e88f7":"model2.fit(X_train, [y_lab_train, y_box_train], epochs=5, batch_size=50, validation_split=0.2)","c0b59d38":"model2.summary()","b300978f":"cls, b = model2.predict(X_test)","75ab048b":"model2.evaluate(X_test, [y_lab_test, y_box_test])","43531a4c":"pred_labels = []\n\nfor lab in cls:\n    lab = np.argmax(lab)\n    pred_labels.append(lab)","e7bf7bd7":"# for lab, box in zip(labels, b):\n    ","31c02c27":"tf.keras.utils.plot_model(model2)","3d91f051":"ss.to_csv('submission.csv', index=False)","89b3123b":"# Basic CNN implementation\n\n## Dicoms\n### Reading and pulling information from .dicom files requires nuance, and is a computationally exhaustive. Thanks to a wonderful notebook by @raddar, (http:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way), I used this formatting along with a couple other functions to properly resize and compile the image data. \n\n##### update 1\/15:\n#### functioning model, will link data preprocessing notebook once it's organized and cleaned","eb744a95":"## Next Steps...\n\n##### for modeling notebook: \n### 1) implement KFold splitting to train & validate data \n### 2) create or manipulate sample_submission dataframe to efficiently read in output data\n### 3) create IoU def to find mAP (evaluation metric)\n##### current version_1.31"}}