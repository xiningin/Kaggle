{"cell_type":{"c496f005":"code","9a1c8044":"code","2b61c267":"code","9bef4f4a":"code","2e3f04db":"code","89422786":"code","c550ca3e":"code","c04af674":"code","4db5eb01":"code","e3d7495e":"code","43ea1886":"code","03f17668":"code","80daf060":"code","9acdd6f2":"code","48442c3c":"code","bdfd18f5":"code","1d1cc586":"code","68dd0bf5":"code","eb62936c":"code","b068cde1":"code","208023a9":"code","1b73b135":"code","45702ddb":"code","adffe51a":"code","adffe5a3":"code","dc301552":"code","08bc693d":"code","724353fd":"code","843f00f3":"code","fe31bcf0":"code","6bb6289d":"code","5d81458b":"code","57984e15":"code","7e127090":"code","741110bb":"code","977f0b53":"code","a6fde1e7":"code","591782e4":"code","2100dcd3":"code","2840fab1":"code","a8c8a892":"code","eba10f47":"code","825769d0":"code","f97327b3":"code","70dc3fc3":"code","a85f9090":"code","4775380f":"code","d69e5eba":"code","44d78357":"code","ee51f1f2":"code","4cafb2dc":"code","5020221e":"code","95bd8b35":"code","a743815c":"code","f05b64cf":"code","270f7d5e":"code","34d46dee":"code","b7514194":"code","831789c1":"code","f59a3185":"code","6d6f0dd7":"code","b5061d44":"code","4e0d2e8b":"code","583b36f1":"code","f14340c4":"code","8646e1ff":"code","068fd312":"code","2dfa6cdc":"code","000c58f1":"code","8e6699b9":"code","698341dd":"code","df8697e0":"code","2c81a4ce":"code","b11cf1b2":"code","ae148de2":"code","7eef86af":"code","5e8cec90":"code","69124e5a":"code","5c40a7fb":"code","fe5eda7e":"code","5884f94d":"code","576c03e9":"code","1a5f3172":"code","db940b8e":"code","665d0325":"code","f5927f81":"code","d8e0e9d8":"code","d002516c":"code","d36f1b31":"code","1ad5c627":"code","d3950a35":"code","f7bea52c":"code","210eaa32":"code","e7178aec":"code","e62672a9":"code","133d6378":"code","c3ff3228":"code","0b17606a":"code","671b225f":"code","70b121f9":"code","791c6a96":"code","6b3b5e6e":"code","3eaa3358":"code","aac220a7":"code","e650d7eb":"code","72a9bea3":"code","68a0fb42":"code","eef6f6c1":"code","c64eef3e":"code","e274deba":"code","6a4aabeb":"code","e4e82026":"code","0090733b":"code","93eb414f":"code","44e6e533":"code","789b5568":"code","4c124b71":"code","beaf6364":"code","a04e2032":"code","72b86fa5":"code","2fcb58b8":"code","6bc7cfe3":"code","3d5d538a":"code","81491596":"code","93a1b510":"code","c5117f4c":"code","d81a8bc2":"code","8bed6e47":"code","c092454f":"code","461e4756":"code","8f94309a":"code","a044b33e":"code","4a8a18ac":"code","82bdfd25":"code","f03ed47f":"code","badb0401":"code","1ee38cc0":"code","46494d27":"code","a025e627":"code","49f9fa55":"code","e8cb998f":"code","262573a5":"code","1242a839":"code","345c533d":"code","b90b70fc":"code","b70044ae":"code","7845c05a":"code","cbbf4ff6":"code","fa52bbd9":"code","1f168274":"code","dca4bd4a":"code","204d640a":"code","e78527f5":"code","37b76494":"code","bea69201":"code","50913eb0":"code","f9cddb2d":"code","3c4b8ec0":"code","13601b55":"code","5524713d":"code","a1d84d3a":"code","cae19b86":"code","08334d01":"code","0c0efcb1":"code","a68fa77c":"code","b1fac86f":"code","ce61b27b":"code","dcebbc38":"code","0b772155":"code","a839c8a8":"code","fa650160":"code","549919c3":"code","3c6eff4f":"code","84a19f62":"code","b97d4595":"code","d5003f2b":"code","c8456db2":"code","9fce8e25":"code","492b2d90":"code","48f3b849":"code","123eb6d6":"code","e07d4d12":"code","ea67d8d3":"code","ec3ca57b":"code","019e11a7":"code","55e1a3e8":"code","d9ed885e":"code","2e6e4144":"code","9b5b24a7":"code","7927fdc5":"code","afad9401":"markdown","4f0cb85b":"markdown"},"source":{"c496f005":"from IPython.display import HTML\n\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n<\/script>\n<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on\/off the raw code.\"><\/form>''')","9a1c8044":"%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(40,8))\n\nimg=mpimg.imread('\/kaggle\/input\/images1\/CT UNET3D.png')\nimgplot = plt.imshow(img)\nplt.show()","2b61c267":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9bef4f4a":"# %pylab inline\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n\n# plt.figure(figsize=(40,8))\n\n# img=mpimg.imread('\/kaggle\/input\/images1\/CT UNET3D.png')\n# imgplot = plt.imshow(img)\n# plt.show()","2e3f04db":"from nibabel.testing import data_path\nimport os","89422786":"example_filename = os.path.join(data_path, '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/coronacases_org_001.nii')","c550ca3e":"example_filename ","c04af674":"import matplotlib.pyplot as plt\n\ndef multi_slice_viewer(volume):\n    #remove_keymap_conflicts({'j', 'k'})\n    fig, ax = plt.subplots()\n    ax.volume = volume\n    ax.index = volume.shape[0] \/\/ 2\n    ax.imshow(volume[ax.index])\n    fig.canvas.mpl_connect('key_press_event', process_key)\n\ndef process_key(event):\n    fig = event.canvas.figure\n    ax = fig.axes[0]\n    if event.key == 'j':\n        previous_slice(ax)\n    elif event.key == 'k':\n        next_slice(ax)\n    fig.canvas.draw()\n\ndef previous_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n    ax.images[0].set_array(volume[ax.index])\n\ndef next_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index + 1) % volume.shape[0]\n    ax.images[0].set_array(volume[ax.index])","4db5eb01":"import nibabel as nib","e3d7495e":"img = nib.load(example_filename)","43ea1886":"img.shape","03f17668":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[:,:,i])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","80daf060":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","9acdd6f2":"def show_images(images):\n\n    n_ = min(images.shape[0], 20) \n    rows = 4\n    cols = (n_ \/\/ 4) + (1 if (n_ % 4) != 0 else 0)\n    figure = plt.figure(figsize=(2*rows, 2*cols))\n    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n    for i in range(n_):\n        plt.subplot(cols, rows, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        if images.shape[1] == 3:\n           \n            vol = images[i].detach().numpy()\n            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n                            for y in range(vol.shape[2])] \\\n                            for x in range(vol.shape[1])]\n            plt.imshow(img)\n        else: \n            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n\n    return figure","48442c3c":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","bdfd18f5":"def reshape(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cv2.resize(image[:,:,i], ( 64, 64))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","1d1cc586":"# out=LoadLungData(64, 64,100)\n# print(out.shape)","68dd0bf5":"# out.shape","eb62936c":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","b068cde1":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     value=out[0]['seg'][i,:,:]>0\n#     print(value)\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","208023a9":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","1b73b135":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(10,35):\n#     plt.subplot(5, 5, i + 1-10)\n\n#     plt.imshow(out[0]['seg'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","45702ddb":"# keys = range(len(out))\n# split = dict()\n# size=len(out)\n# split_1=int(size*0.7)\n# split_2=int(size*0.7)+int(size*0.2)\n# split['train']=range(0,split_1)\n# split['test']=range(split_1,split_2)\n# split['val']=range(split_2,size)\n# print('len val',len(split['val']))","adffe51a":"import os\nimport time\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","adffe5a3":"n_epochs =10\ntime_start = \"\"\ntime_end = \"\"\nepoch = 0\n ","dc301552":"# import torch\n# from torch.utils.data import Dataset\n\n\n# class SlicesDataset(Dataset):\n\n#     def __init__(self, data):\n#         self.data = data\n\n#         self.slices = []\n\n#         for i, d in enumerate(data):\n#             print(d[\"image\"].shape[0])\n#             for j in range(d[\"image\"].shape[0]):\n#                 self.slices.append((i, j))\n#         print('Len slices ',len(self.slices))\n\n#     def __getitem__(self, idx):\n\n#         slc = self.slices[idx]\n#         sample = dict()\n#         sample[\"id\"] = idx\n\n\n#         i,j=slc\n        \n#         #print('i ',i)\n#         #print('j ',j)\n    \n#         import numpy as np\n\n#         image_=self.data[i]['image']\n#         label_=self.data[i]['seg']\n#         image=image_[j,:,:]\n#         #print('Slice shape ',image.shape)\n#         print('1',image.shape)\n#         image=image.reshape(1,image.shape[0],image.shape[1])\n#         print('2',image.shape)\n#         label=label_[j,:,:]\n#         label=label.reshape(1,label.shape[0],label.shape[1])\n   \n#         sample['image']=torch.tensor(image)#\n#         sample['seg']=torch.tensor(label)#\n\n#         return sample\n\n#     def __len__(self):\n   \n#         return len(self.slices)","08bc693d":"import numpy as np\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom nilearn.surface import surface\nfrom nilearn.plotting import show","724353fd":"# train_loader = DataLoader(SlicesDataset(out[split[\"train\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)\n# val_loader = DataLoader(SlicesDataset(out[split[\"val\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)","843f00f3":"# test_data = out[split[\"test\"]]","fe31bcf0":"def build_model(inp_shape, k_size=3):\n    merge_axis = -1 # Feature maps are concatenated along last axis (for tf backend)\n    data = Input(shape=inp_shape)\n    conv1 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(data)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv2 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(conv1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n    conv3 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool1)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv4 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n\n    conv5 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool2)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv6 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv5)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv6)\n\n    conv7 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool3)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n    conv8 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv7)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv8)\n\n    conv9 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool4)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n\n    up1 = UpSampling3D(size=(2, 2, 2))(conv9)\n    conv10 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(up1)\n    conv10 = BatchNormalization()(conv10)\n    conv10 = Activation('relu')(conv10)\n    conv11 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv10)\n    conv11 = BatchNormalization()(conv11)\n    conv11 = Activation('relu')(conv11)\n    merged1 = concatenate([conv11, conv8], axis=merge_axis)\n    conv12 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(merged1)\n    conv12 = BatchNormalization()(conv12)\n    conv12 = Activation('relu')(conv12)\n\n    up2 = UpSampling3D(size=(2, 2, 2))(conv12)\n    conv13 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up2)\n    conv13 = BatchNormalization()(conv13)\n    conv13 = Activation('relu')(conv13)\n    conv14 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv13)\n    conv14 = BatchNormalization()(conv14)\n    conv14 = Activation('relu')(conv14)\n    merged2 = concatenate([conv14, conv6], axis=merge_axis)\n    conv15 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged2)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Activation('relu')(conv15)\n\n    up3 = UpSampling3D(size=(2, 2, 2))(conv15)\n    conv16 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up3)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Activation('relu')(conv16)\n    conv17 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv16)\n    conv17 = BatchNormalization()(conv17)\n    conv17 = Activation('relu')(conv17)\n    merged3 = concatenate([conv17, conv4], axis=merge_axis)\n    conv18 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged3)\n    conv18 = BatchNormalization()(conv18)\n    conv18 = Activation('relu')(conv18)\n\n    up4 = UpSampling3D(size=(2, 2, 2))(conv18)\n    conv19 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up4)\n    conv19 = BatchNormalization()(conv19)\n    conv19 = Activation('relu')(conv19)\n    conv20 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv19)\n    conv20 = BatchNormalization()(conv20)\n    conv20 = Activation('relu')(conv20)\n    merged4 = concatenate([conv20, conv2], axis=merge_axis)\n    conv21 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged4)\n    conv21 = BatchNormalization()(conv21)\n    conv21 = Activation('relu')(conv21)\n\n    conv22 = Convolution3D(padding='same', filters=2, kernel_size=k_size)(conv21)\n    output = Reshape([-1, 2])(conv22)\n    output = Activation('softmax')(output)\n    output = Reshape(inp_shape[:-1] + (2,))(output)\n\n    model = Model(data, output)\n    return model","6bb6289d":"# out[0]['image'].shape","5d81458b":"# len(out)","57984e15":"# # X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","7e127090":"# X=np.array(X)\n# # y=np.array(y)","741110bb":"# X.shape","977f0b53":"# X.shape","a6fde1e7":"# y.shape","591782e4":"# X.shape[1:]","2100dcd3":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv3D, Input, MaxPooling3D, Dropout, concatenate, UpSampling3D\nimport tensorflow as tf\n\ndef Unet3D(inputs,num_classes):\n    x=inputs\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n    merge6 = concatenate([drop4,up6],axis=-1)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n\n    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n    merge7 = concatenate([conv3,up7],axis=-1)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n\n    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n    merge8 = concatenate([conv2,up8],axis=-1)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n\n    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n    merge9 = concatenate([conv1,up9],axis=-1)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n    conv10 = Conv3D(1,1, activation = 'sigmoid')(conv9)\n    model = Model(inputs=inputs, outputs = conv10)\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","2840fab1":"def dice_loss(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.cast(tf.reshape(y_true,[-1]),tf.float32)\n    y_pred_f =tf.cast(tf.reshape(y_pred,[-1]),tf.float32)\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (1-(2. * intersection + smooth) \/ (union + smooth))","a8c8a892":"def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (2. * intersection + smooth) \/ (union + smooth)","eba10f47":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","825769d0":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","f97327b3":"def my_generator(x_train, y_train, batch_size):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size)\n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","70dc3fc3":"!pip install nilearn","a85f9090":"from nilearn.plotting import view_img, glass_brain, plot_anat, plot_epi","4775380f":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# image_batch, mask_batch = next(my_generator(X, y, 8))\n# fix, ax = plt.subplots(8,2, figsize=(8,20))\n# for i in range(8):\n    \n    \n#     ax[i,0].imshow(image_batch[i,:,:,0])\n#     ax[i,1].imshow(mask_batch[i,:,:,0])\n# plt.show()\n","d69e5eba":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","44d78357":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nweight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)","ee51f1f2":"# X.shape","4cafb2dc":"# y.shape","5020221e":"# hist = Model_3D.fit(X, y,\n#                            steps_per_epoch = 20,\n                           \n#                            epochs=10, verbose=2,\n#                            )","95bd8b35":"# np.array([X[0]]).shape","a743815c":"# segmented=Model_3D.predict(np.array([X[0]]))","f05b64cf":"# segmented_=segmented[0,:,:,:,0]","270f7d5e":"# segmented_.shape","34d46dee":"# import SimpleITK as sitk\n# filtered_image = sitk.GetImageFromArray(segmented_)","b7514194":"# filtered_image ","831789c1":"# import nibabel as nib\n# import numpy as np\n\n# data = np.arange(4*4*3).reshape(4,4,3)\n\n# new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n\n# new_image_ = nib.Nifti1Image(np.array(X[0]), affine=np.eye(4))\n\n\n","f59a3185":"# plot_anat(new_image)\n  \n","6d6f0dd7":"# view_img(new_image , new_image_)","b5061d44":"# nib.save(new_image , '\/kaggle\/working\/segmented.nii')","4e0d2e8b":"# nib.save(new_image_ , '\/kaggle\/working\/original.nii')","583b36f1":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","f14340c4":"# out=LoadLungData(64, 64,200)\n# print(out.shape)","8646e1ff":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(30):\n#     plt.subplot(5, 6, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","068fd312":"# X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","2dfa6cdc":"# X=np.array(X)\n# y=np.array(y)\n\n# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","000c58f1":"# len(X_train)","8e6699b9":"# len(X_test)","698341dd":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","df8697e0":"# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(X_test,y_test),\n#                            epochs=50, verbose=2,\n#                            )\n# auc=max(history.history['dice_coe'])\n\n","2c81a4ce":"\n\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('\/kaggle\/working\/singleinput'+'.csv')\n\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score single input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n# plt.savefig('\/kaggle\/working\/singleinput.png')\n# plt.show()\n","b11cf1b2":"def cluster(img):\n            vectorized = img.reshape((-1,4))\n            vectorized = np.float32(vectorized)\n            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n            K = 4\n            attempts=10\n            ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n            center = np.uint8(center)\n            res = center[label.flatten()]\n            result_image = res.reshape((img.shape))\n            return result_image","ae148de2":"from scipy import ndimage\nfrom skimage import filters","7eef86af":"from skimage.morphology import disk\n\ndef reshape_cluster2(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=filters.median(cv2.resize(image[:,:,i], ( 64, 64)),disk(1))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=filters.median(reshaped_image[:,i,:],disk(1))\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=filters.median(reshaped_image[i,:,:],disk(1))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","5e8cec90":"from skimage.morphology import disk\n\ndef reshape_cluster(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cluster(cv2.resize(image[:,:,i], ( 64, 64)))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=cluster(reshaped_image[:,i,:])\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=cluster(reshaped_image[i,:,:])\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","69124e5a":"from skimage.morphology import disk\n\ndef reshape_cluster_spectral(image, new_shape):\n    \n    \n    import skimage.segmentation as seg\n\n\n\n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]= seg.slic(cv2.resize(image[:,:,i], ( 64, 64)),n_segments=30)\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]= seg.slic(reshaped_image[:,i,:],n_segments=30)\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]= seg.slic(reshaped_image[i,:,:],n_segments=30)\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","5c40a7fb":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungMaskData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","fe5eda7e":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungDataClusterData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape_cluster(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","5884f94d":"out=LoadLungData(64, 64,100)","576c03e9":"out_=LoadLungDataClusterData(64, 64,100)\n","1a5f3172":"out__=LoadLungMaskData(64, 64,100)","db940b8e":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[0]['seg'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","665d0325":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(40,70,1):\n    plt.subplot(5, 6, i + 1-40)\n\n    plt.imshow(out_[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","f5927f81":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out__[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","d8e0e9d8":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[1]['image'][i,:,:]-out_[1]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","d002516c":"\nX=np.array([out[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\n","d36f1b31":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(y[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","1ad5c627":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","d3950a35":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","f7bea52c":"print(X_train.shape)\nprint(y_train.shape)","210eaa32":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D.summary()","e7178aec":"\n# history = Model_3D.fit(X, y,\n#                            batch_size=2,\n#                            #validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=150, verbose=2,\n#                            callbacks=[ tf.keras.callbacks.EarlyStopping(patience=3)]\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('\/kaggle\/working\/withoutsoby.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","e62672a9":"#Model_3D.save_weights('\/kaggle\/working\/single.h5')\nModel_3D.load_weights('..\/input\/ctlungseg\/single (1).h5')","133d6378":"%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}","c3ff3228":"\n# for j in range(20):\n\n#     segmented=Model_3D.predict(np.array([X[j]]))\n#     segmented_=segmented[0,:,:,:,0]\n#     print(len(segmented_[segmented_>0]))\n\n#     import matplotlib.pyplot as plt\n#     im_fdata=img.get_fdata()\n\n\n\n\n#     plt.figure(figsize=(10,8))\n\n#     # Iterate and plot random images\n#     for i in range(0,60):\n#         plt.subplot(10, 6, i + 1)\n\n#         plt.imshow(segmented_[i,:,:])\n#         plt.axis('off')\n\n#     # Adjust subplot parameters to give specified padding\n#     plt.tight_layout()  \n#     plt.show()\n    \n#     import nibabel as nib\n#     import numpy as np\n\n#     data = np.arange(4*4*3).reshape(4,4,3)\n\n#     new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n#     nib.save(new_image , '\/kaggle\/working\/infection'+str(j)+'.nii')","0b17606a":"X=np.array([out[i]['image'] for i in range(len(out))]+[out_[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\n\n\n","671b225f":"len(y)","70b121f9":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D_filter=Unet3D(inputs,num_classes=3)\n    Model_3D_filter.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D_filter.summary()","791c6a96":"\n# history = Model_3D.fit(X, y,\n#                            batch_size=2,\n#                            #validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=150, verbose=2,\n#                            callbacks=[ tf.keras.callbacks.EarlyStopping(patience=3)]\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('\/kaggle\/working\/fusion.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","6b3b5e6e":"#Model_3D.save_weights('\/kaggle\/working\/multi.h5')\nModel_3D_filter.load_weights('..\/input\/ctlungseg1\/multi.h5')","3eaa3358":"X=np.array([out[i]['image'] for i in range(len(out))]+[out_[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])","aac220a7":"from skimage.morphology import disk\n\ndef clean(image):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(image[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","e650d7eb":"from skimage.morphology import disk\n\ndef lung(image,lung):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(lung[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","72a9bea3":"diffv=[]\nfor j in range(20):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    segmented_=clean(segmented_)\n    lung_=lung(segmented_,X[j])\n    print(len(segmented_[segmented_>0.5]))\n    print(len(y[j][y[j]>0.5]))\n    diffv.append(len(segmented_[segmented_>0.5])- len(y[j][y[j]>0.5]))\n    print(diffv)\n   \n    size=len(segmented_[segmented_>0])\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n    if size>200:\n\n        plt.figure(figsize=(10,8))\n\n        # Iterate and plot random images\n        for i in range(0,9):\n            plt.subplot(3, 3, i + 1)\n\n            plt.imshow(segmented_[i,:,:])\n            plt.axis('off')\n\n        # Adjust subplot parameters to give specified padding\n        plt.tight_layout()  \n        plt.show()\n        \n        \n        \n        plt.figure(figsize=(10,8))\n\n        # Iterate and plot random images\n        for i in range(0,9):\n            plt.subplot(3, 3, i + 1)\n\n            plt.imshow(y[j][i,:,:])\n            plt.axis('off')\n\n        # Adjust subplot parameters to give specified padding\n        plt.tight_layout()  \n        plt.show()\n\n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n    \n    if j==0:\n\n        new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n        nib.save(new_image , '\/kaggle\/working\/infection'+str(j)+'.nii')\n        new_image_1 = nib.Nifti1Image(lung_, affine=np.eye(4))\n        nib.save(new_image_1 , '\/kaggle\/working\/lung'+str(j)+'.nii')\nimport csv\n\npd.DataFrame(diffv).to_csv('\/kaggle\/working\/difffusion.csv')","68a0fb42":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungTestData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/mosmed-covid19-ct-scans\/CT-2\/'\n\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            covid, _ = load(os.path.join(image_dir, f))\n\n\n            \n\n            #image=image\/255\n\n            try:\n\n                covid = reshape(covid, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n               \n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": covid, \"filename\": f})\n        else:\n            break\n   \n    #print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","eef6f6c1":"out=LoadLungTestData(64, 64,100)","c64eef3e":"Model_3D.load_weights('..\/input\/ctlungseg\/single (1).h5')","e274deba":"X=np.array([out[i]['image'] for i in range(len(out))])","6a4aabeb":"\nfor j in range(4):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    segmented_=clean(segmented_)\n    print(len(segmented_[segmented_>0]))\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n\n\n    plt.figure(figsize=(10,8))\n\n    # Iterate and plot random images\n    for i in range(0,4):\n        plt.subplot(3, 2, i + 1)\n\n        plt.imshow(segmented_[i,:,:])\n        plt.axis('off')\n\n    # Adjust subplot parameters to give specified padding\n    plt.tight_layout()  \n    plt.show()\n    \n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n\n    new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n    nib.save(new_image , '\/kaggle\/working\/infection'+str(j)+'.nii')","e4e82026":"Model_3D_filter.load_weights('..\/input\/ctlungseg1\/multi.h5')","0090733b":"from skimage.morphology import disk\n\ndef clean(image):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(image[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","93eb414f":"\n# for j in range(99):\n\n#     segmented=Model_3D.predict(np.array([X[j]]))\n    \n    \n    \n    \n#     segmented_=segmented[0,:,:,:,0]\n#     segmented_=clean(segmented_)\n    \n#     print(len(segmented_[segmented_>0]))\n\n#     import matplotlib.pyplot as plt\n#     im_fdata=img.get_fdata()\n\n\n\n\n#     plt.figure(figsize=(10,8))\n\n#     # Iterate and plot random images\n#     for i in range(0,60):\n#         plt.subplot(10, 6, i + 1)\n\n#         plt.imshow(segmented_[i,:,:])\n#         plt.axis('off')\n\n#     # Adjust subplot parameters to give specified padding\n#     plt.tight_layout()  \n#     plt.show()\n    \n#     import nibabel as nib\n#     import numpy as np\n\n#     data = np.arange(4*4*3).reshape(4,4,3)\n\n#     new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n#     nib.save(new_image , '\/kaggle\/working\/infection'+str(j)+'.nii')","44e6e533":"out=LoadLungData(64, 64,100)\n#out_=LoadLungDataClusterData(64, 64,100)","789b5568":"def dice_coe_sorense(y_true,y_pred, smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    \n    return (2. * intersection + smooth) \/ (union + smooth)","4c124b71":"# import pywt\n# import cv2\n# import numpy as np\n\n# # This function does the coefficient fusing according to the fusion method\n# def fuseCoeff(cooef1, cooef2, method):\n\n#     if (method == 'mean'):\n#         cooef = (cooef1 + cooef2) \/ 2\n#     elif (method == 'min'):\n#         cooef = np.minimum(cooef1,cooef2)\n#     elif (method == 'max'):\n#         cooef = np.maximum(cooef1,cooef2)\n#     else:\n#         cooef = []\n\n#     return cooef\n\n# def fuse(I1,I2):\n\n\n#     # Params\n#     FUSION_METHOD = 'mean' # Can be 'min' || 'max || anything you choose according theory\n\n#     # We need to have both images the same size\n#     #I2 = cv2.resize(I2,I1.shape) # I do this just because i used two random images\n\n#     ## Fusion algo\n\n#     # First: Do wavelet transform on each image\n#     wavelet = 'db1'\n#     cooef1 = pywt.wavedec2(I1[:,:], wavelet)\n#     cooef2 = pywt.wavedec2(I2[:,:], wavelet)\n\n#     # Second: for each level in both image do the fusion according to the desire option\n#     fusedCooef = []\n#     for i in range(len(cooef1)-1):\n\n#         # The first values in each decomposition is the apprximation values of the top level\n#         if(i == 0):\n\n#             fusedCooef.append(fuseCoeff(cooef1[0],cooef2[0],FUSION_METHOD))\n\n#         else:\n\n#             # For the rest of the levels we have tupels with 3 coeeficents\n#             c1 = fuseCoeff(cooef1[i][0],cooef2[i][0],FUSION_METHOD)\n#             c2 = fuseCoeff(cooef1[i][1], cooef2[i][1], FUSION_METHOD)\n#             c3 = fuseCoeff(cooef1[i][2], cooef2[i][2], FUSION_METHOD)\n\n#             fusedCooef.append((c1,c2,c3))\n\n#     # Third: After we fused the cooefficent we nned to transfor back to get the image\n#     fusedImage = pywt.waverec2(fusedCooef, wavelet)\n\n#     # Forth: normmalize values to be in uint8\n#     fusedImage = np.multiply(np.divide(fusedImage - np.min(fusedImage),(np.max(fusedImage) - np.min(fusedImage))),255)\n#     #fusedImage = fusedImage.astype(np.uint8)\n#     return  cv2.resize(fusedImage,(64,64))\n# # Fith: Show image\n\n# !pip install imutils\n# # import the necessary packages\n# from imutils import paths\n# import argparse\n# import cv2\n\n# def variance_of_laplacian(image):\n# \t# compute the Laplacian of the image and then return the focus\n# \t# measure, which is simply the variance of the Laplacian\n# \treturn cv2.Laplacian(image, cv2.CV_64F).var()\n\n# def fuse_(I1,I2):\n#     IMAGE=[]\n#     #print('teste')\n#     for i in range(I1.shape[0]):\n#         IMAGE.append(fuse(I1[i,:,:], cv2.Laplacian(I2[i,:,:],cv2.CV_64F)))\n#     return np.array(IMAGE)","beaf6364":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\nX=np.array([(out[i]['image']-cv2.Laplacian(out[i]['image'],cv2.CV_64F))\/2 for i in range(len(out))]+[cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))]+[out[i]['image'] for i in range(len(out))])","a04e2032":"print(X.shape)\nprint(y.shape)","72b86fa5":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","2fcb58b8":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\nX=np.array([(out[i]['image']+cv2.Laplacian(out[i]['image'],cv2.CV_64F))\/2 for i in range(len(out))]+[cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","6bc7cfe3":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","3d5d538a":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","81491596":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","93a1b510":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","c5117f4c":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","d81a8bc2":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionhistoryminus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","8bed6e47":"\n# #X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\n# y=np.array([out[i]['seg'] for i in range(len(out))])\n# X=np.array([out[i]['image'] for i in range(len(out))])","c092454f":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","461e4756":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","8f94309a":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/nofusionhistoryminus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","a044b33e":"\n# #X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\n# y=np.array([out[i]['seg'] for i in range(len(out))])\n# X=np.array([(out[i]['image']+cv2.Laplacian(out[i]['image'],cv2.CV_64F))\/2 for i in range(len(out))])","4a8a18ac":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","82bdfd25":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","f03ed47f":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionhistoryplus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","badb0401":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","1ee38cc0":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","46494d27":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","a025e627":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionlaplacian.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","49f9fa55":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F)+out[i]['image'] for i in range(len(out))])","e8cb998f":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","262573a5":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","1242a839":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","345c533d":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionsoma.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","b90b70fc":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+out[i]['image'] for i in range(len(out))])","b70044ae":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","7845c05a":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","cbbf4ff6":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n# # \n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","fa52bbd9":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionsobelsoma.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","1f168274":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+out[i]['image'])\/2 for i in range(len(out))])","dca4bd4a":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","204d640a":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","e78527f5":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","37b76494":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionsobelsomadiv2.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","bea69201":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)-out[i]['image'] for i in range(len(out))])","50913eb0":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","f9cddb2d":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","3c4b8ec0":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","13601b55":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionsobeldiffdiv2.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","5524713d":"import pandas as pd\ndivminus2laplacian=pd.read_csv('..\/input\/papersegmentctresults\/fusion-div2laplacian.csv')\ndfnofusion=pd.read_csv('..\/input\/papersegmentctresults\/nofusion.csv')\ndivplus2laplacian=pd.read_csv('..\/input\/papersegmentctresults\/fusiondiv2laplacian.csv')\naddlaplacian=pd.read_csv('..\/input\/papersegmentctresults\/fusionlaplacian.csv')\ndivminus2sobel=pd.read_csv('..\/input\/papersegmentctresults\/fusion-div2sobel.csv')\ndivplus2sobel=pd.read_csv('..\/input\/papersegmentctresults\/fusiondiv2sobel.csv')","a1d84d3a":"\ndivminus2laplacian","cae19b86":"import altair as alt\ndfaltair=pd.DataFrame(columns=['x','y','class'])","08334d01":"for i,r in divminus2laplacian.iterrows():\n    dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion diff\/2'},ignore_index=True)\nfor i,r in dfnofusion.iterrows():\n    dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'No fusion'},ignore_index=True)\n\nfor i,r in  divplus2laplacian.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion add\/2'},ignore_index=True)\n\nfor i,r in  addlaplacian.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion add'},ignore_index=True)\n\n\nfor i,r in  divminus2sobel.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Sobel fusion diff\/2'},ignore_index=True)\nfor i,r in  divplus2sobel.iterrows():\n    \n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Sobel fusion add\/2'},ignore_index=True)\n","0c0efcb1":"alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.2, 0.88])),color='class')","a68fa77c":"#alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.2, 0.3])),color='class')","b1fac86f":"#alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.874, 0.88])),color='class')","ce61b27b":"out=LoadLungData(64, 64,100)\n# out__=LoadLungMaskData(64, 64,100)","dcebbc38":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([out__[i]['image'] for i in range(len(out))])","0b772155":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","a839c8a8":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=20, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","fa650160":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([out[i]['image'] for i in range(len(out))])","549919c3":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadClusterData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape_cluster_spectral(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster_spectral(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","3c6eff4f":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+cv2.Laplacian(out[i]['image'],cv2.CV_64F))\/2 for i in range(len(out))])","84a19f62":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","b97d4595":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","d5003f2b":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=20, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","c8456db2":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('\/kaggle\/working\/fusionlaplaciansobel.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","9fce8e25":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cluster(out[i]['image'])+cv2.Laplacian(out[i]['image'],cv2.CV_64F))\/2 for i in range(len(out))])","492b2d90":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","48f3b849":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-2\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n                              patience=1, min_lr=0.001)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    #Model_3D.summary()","123eb6d6":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\nhist = Model_3D.fit(X_train, y_train,\n                           \n                           batch_size=1,\n                           validation_data=(X_test,y_test),\n                           epochs=20, verbose=2,\n                           callbacks=[reduce_lr]\n                           )","e07d4d12":"import pandas as pd\ndf_history=pd.DataFrame.from_dict(hist.history)\ndf_history.to_csv('\/kaggle\/working\/fusionlaplaciankmeans.csv')\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\nplt.plot(hist.history['dice_coe'])\n#plt.plot(history.history['val_dice_coe'])\nplt.title('Dice score multi input')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['dice', 'val_dice'], loc='upper left')","ea67d8d3":"!pip install scikit-fuzzy\nimport skfuzzy as fuzz","ec3ca57b":"from skimage import transform,io\nimport cv2\n\ndef fuzzy(image):\n    \n    \n    \n    mfx = fuzz.trapmf(image.flatten(),  [0.4, 0.6,200,200])\n    \n \n    \n    return mfx.reshape(64,64)","019e11a7":"print(X.shape)","55e1a3e8":"print(out[0]['image'].shape)\n#plt.imshow(out[0]['image'])","d9ed885e":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cluster(out[i]['image'])+out[i]['image'])\/2 for i in range(len(out))])","2e6e4144":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","9b5b24a7":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-2\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n                              patience=1, min_lr=0.001)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    #Model_3D.summary()","7927fdc5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\nhist = Model_3D.fit(X_train, y_train,\n                           \n                           batch_size=1,\n                           validation_data=(X_test,y_test),\n                           epochs=20, verbose=2,\n                           callbacks=[reduce_lr]\n                           )","afad9401":"## Load Sample Files","4f0cb85b":"## Lung CT Segmentation"}}