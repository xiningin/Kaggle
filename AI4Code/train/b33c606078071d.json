{"cell_type":{"415f113e":"code","8e5fe07c":"code","3bc1e44d":"code","ca36776c":"code","e60aab7c":"code","9afaa9fd":"code","cd741d77":"code","2ce2f8aa":"code","c47c1131":"code","6cd353f9":"code","e3318024":"code","25f18d43":"code","b65fd15b":"code","fe44995f":"code","6b2a1a62":"code","1c47be36":"code","9267dfab":"code","789e543b":"code","1af0d952":"code","1722c4d1":"code","4971b091":"code","e8e79007":"code","4d658d6e":"code","f0cb6714":"code","83fb0bf5":"code","ff9a61e0":"code","7abb91d7":"code","a3cf79ca":"code","c7ad1f99":"code","5373c59a":"code","e8019c28":"code","ce150197":"code","482da677":"code","600f13c5":"code","d5674db0":"code","09987890":"code","105e3b93":"code","c733f5df":"code","671bd671":"code","7f637a26":"code","d91b6a8e":"code","93a9df0b":"code","c3acee0a":"code","e5c4bb60":"code","209b4d9a":"code","3454ec85":"code","7373e3da":"code","7958d0b7":"code","2b9076b5":"code","b1417552":"code","de22c950":"code","59ab68ea":"code","d0589a52":"code","f5dab8e3":"markdown","b8634197":"markdown","e641441f":"markdown","0d87fb76":"markdown","0ee339d4":"markdown","aa1815a1":"markdown","132b0176":"markdown","e8d62587":"markdown","0de75ec2":"markdown","4be216a3":"markdown","2c968c99":"markdown","703a604c":"markdown","8c7d5ae1":"markdown","d161aa4c":"markdown","1a1e701a":"markdown","05f96fa4":"markdown","bdbaa668":"markdown","e3ad22e9":"markdown","02f68f9b":"markdown","c9bedb67":"markdown","f0d0912b":"markdown","c9985232":"markdown","b35772b7":"markdown","10c70f37":"markdown","2b97ade6":"markdown","04cb41fa":"markdown","5f66cae8":"markdown","2a3edb8b":"markdown","37047144":"markdown","fab7e8be":"markdown","bfe69beb":"markdown","c8e57373":"markdown","15c77541":"markdown","60beb70e":"markdown","dbac47c4":"markdown","05ed3377":"markdown","965b86aa":"markdown","5e37fc1b":"markdown","c7c666c2":"markdown","c582107f":"markdown","8ec4990d":"markdown","e900ec91":"markdown","2608709b":"markdown","742b7779":"markdown","44a71783":"markdown","d51e186b":"markdown","225ffb6e":"markdown","bcf1137a":"markdown","824e987f":"markdown"},"source":{"415f113e":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter","8e5fe07c":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3bc1e44d":"df=pd.read_csv('..\/input\/glass.csv')\ndf.head()","ca36776c":"df.info()","e60aab7c":"df.isnull().sum()","9afaa9fd":"## Let us check for five point summary of our data\ndf.describe()","cd741d77":"features=df.columns[:-1]\ncols=list(features)","2ce2f8aa":"for i in cols:\n    skewness=df[i].skew()\n    print('Skewness for ',i,'= ',skewness)","c47c1131":"plt.figure(figsize=(10,10))\ndf.boxplot()","6cd353f9":"Feat=[]\nU_C_L=[]\nL_C_L=[]\nfor i in cols:\n    q_25=np.percentile(df[i],25)\n    q_75=np.percentile(df[i],75)\n    IQR=q_75-q_25\n    const=1.5*IQR\n    UCL=round((q_75+const),4)\n    LCL=round((q_25+const),4)\n    Feat.append(i)\n    U_C_L.append(UCL)\n    L_C_L.append(LCL)","e3318024":"limits=pd.DataFrame({'Features':Feat,'Upper Limit':U_C_L,'Lower Limit':L_C_L})\nlimits","25f18d43":"def outliers(df):\n    outlier_indices=[]\n    \n    # iterate over features(columns)\n    for col in df.columns.tolist():\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        \n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        \n        # Interquartile rrange (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n    print(multiple_outliers)\n    return multiple_outliers\nprint('The dataset contains %d observations with more than 2 outliers' %(len(outlier_indices)))  ","b65fd15b":"outlier_indices = outliers(df[cols])\noutlier_indices","fe44995f":"plt.figure(figsize=(8,8))\ncor_mat=df[cols].corr()\ncor_mat\nsns.heatmap(cor_mat,annot=True)","6b2a1a62":"plt.figure(figsize=(50,50))\nprint(df.groupby(['Type'])['RI'].mean())","1c47be36":"(df.groupby(['Type'])['Na'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Na\" content')\nplt.title('Sodium Content in various types of glass')","9267dfab":"(df.groupby(['Type'])['Mg'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Mg\" content')\nplt.title('Magnesium Content in various types of glass')","789e543b":"(df.groupby(['Type'])['Al'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Al\" content')\nplt.title('Aluminum Content in various types of glass')","1af0d952":"(df.groupby(['Type'])['Si'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Si\" content')\nplt.title('Silicon Content in various types of glass')","1722c4d1":"(df.groupby(['Type'])['K'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"K\" content')\nplt.title('Potassium Content in various types of glass')","4971b091":"(df.groupby(['Type'])['Ca'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Ca\" content')\nplt.title('Calcium Content in various types of glass')","e8e79007":"(df.groupby(['Type'])['Ba'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Ba\" content')\nplt.title('Barium Content in various types of glass')","4d658d6e":"(df.groupby(['Type'])['Fe'].mean()).plot(kind='bar')\nplt.xlabel('Type of glass')\nplt.ylabel('\"Fe\" content')\nplt.title('Iron Content in various types of glass')","f0cb6714":"df1=df.drop(outlier_indices).reset_index(drop=True)","83fb0bf5":"df1.shape","ff9a61e0":"for i in cols:\n    skewness=df1[i].skew()\n    print('Skewness for ',i,'= ',skewness)","7abb91d7":"y=df1['Type']\nx=df1.drop('Type',axis=1)\nfrom sklearn.model_selection import train_test_split","a3cf79ca":"from scipy import stats as st","c7ad1f99":"for i in x.columns:\n    x[i],lambda_val=st.boxcox(x[i]+1.0)","5373c59a":"for i in x.columns:\n    skewness=x[i].skew()\n    print('Skewness for ',i,'= ',skewness)","e8019c28":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nxs=ss.fit_transform(x)","ce150197":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30)","482da677":"x_train=ss.fit_transform(x_train)\nx_test=ss.transform(x_test)","600f13c5":"x_test.shape,y_test.shape","d5674db0":"def model_eval(algo,xtrain,ytrain,xtest,ytest):\n    algo.fit(xtrain,ytrain)\n    ytrain_pred=algo.predict(xtrain)\n\n    from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,classification_report\n\n    print('Confusion matrix for train:','\\n',confusion_matrix(ytrain,ytrain_pred))\n\n    print('Overall accuracy of train dataset:',accuracy_score(ytrain,ytrain_pred))\n    \n    print('Classification matrix for train data','\\n',classification_report(ytrain,ytrain_pred))\n\n    ytest_pred=algo.predict(xtest)\n\n    print('Test data accuracy:',accuracy_score(ytest,ytest_pred))\n\n    print('Confusion matrix for test data','\\n',confusion_matrix(ytest,ytest_pred))\n    \n    print('Classification matrix for train data','\\n',classification_report(ytest,ytest_pred))","09987890":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nmodel_eval(rfc,x_train,y_train,x_test,y_test)","105e3b93":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\nrfc=RandomForestClassifier(random_state=3)\nparams={'n_estimators':sp_randint(50,200),'max_features':sp_randint(1,24),'max_depth':sp_randint(2,10),\n       'min_samples_split':sp_randint(2,20),'min_samples_leaf':sp_randint(1,20),'criterion':['gini','entropy']}\nrs=RandomizedSearchCV(rfc,param_distributions=params,n_iter=500,cv=3,scoring='accuracy',random_state=3,\n                      return_train_score=True)\nrs.fit(xs,y)","c733f5df":"rfc_best_parameters=rs.best_params_\nprint(rfc_best_parameters)","671bd671":"rfc1=RandomForestClassifier(**rfc_best_parameters)\nmodel_eval(rfc1,x_train,y_train,x_test,y_test)","7f637a26":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\nmodel_eval(knn,x_train,y_train,x_test,y_test)","d91b6a8e":"knn_rs=KNeighborsClassifier()\n\nparams={'n_neighbors':sp_randint(1,30),'p':sp_randint(1,6)}\n\nrs1=RandomizedSearchCV(knn_rs,param_distributions=params,cv=3,return_train_score=True,random_state=3,n_iter=500)\n\nrs1.fit(xs,y)","93a9df0b":"knn_best_parameters=rs1.best_params_\nprint(knn_best_parameters)","c3acee0a":"knn1=KNeighborsClassifier(**knn_best_parameters)\nmodel_eval(knn1,x_train,y_train,x_test,y_test)","e5c4bb60":"import lightgbm as lgb\nlgbm=lgb.LGBMClassifier()\nmodel_eval(lgbm,x_train,y_train,x_test,y_test)","209b4d9a":"from scipy.stats import uniform as sp_uniform\nparams={'n_estimator':sp_randint(50,200),'max_depth':sp_randint(2,15),'learning_rate':sp_uniform(0.001,0.5),\n       'num_leaves':sp_randint(20,50)}\nlgbm_rs=lgb.LGBMClassifier()\nrs_lgbm=RandomizedSearchCV(lgbm_rs,param_distributions=params,cv=3,random_state=3,n_iter=500,n_jobs=-1)\nrs_lgbm.fit(xs,y)","3454ec85":"lgbm_best_parameters=rs_lgbm.best_params_\nprint(lgbm_best_parameters)","7373e3da":"lgbm_1=lgb.LGBMClassifier(**lgbm_best_parameters)\nmodel_eval(lgbm_1,x_train,y_train,x_test,y_test)","7958d0b7":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(solver='liblinear')\nmodel_eval(lr,x_train,y_train,x_test,y_test)","2b9076b5":"from sklearn.ensemble import VotingClassifier\nlr=LogisticRegression(solver='liblinear')\nrfc1=RandomForestClassifier(**rfc_best_parameters)\nknn1=KNeighborsClassifier(**knn_best_parameters)\nlgbm_1=lgb.LGBMClassifier(**lgbm_best_parameters)","b1417552":"clf=VotingClassifier(estimators=[('lr',lr),('knn',knn1),('rfc',rfc1),('lgbm',lgbm_1)],voting='hard')\nmodel_eval(clf,x_train,y_train,x_test,y_test)","de22c950":"clf_sv=VotingClassifier(estimators=[('lr',lr),('knn',knn1),('rfc',rfc1),('lgbm',lgbm_1)],voting='soft')\nmodel_eval(clf_sv,x_train,y_train,x_test,y_test)","59ab68ea":"clf_sv1=VotingClassifier(estimators=[('lr',lr),('knn',knn1),('rfc',rfc1),('lgbm',lgbm_1)],voting='soft',weights=[5,5,1,1])\nmodel_eval(clf_sv1,x_train,y_train,x_test,y_test)","d0589a52":"clf_sv2=VotingClassifier(estimators=[('lr',lr),('knn',knn1)],voting='soft',weights=[5,4])\nmodel_eval(clf_sv2,x_train,y_train,x_test,y_test)","f5dab8e3":"##### All types of glasses have calcium content inthe range 9 to 10. Calcium content is highest in glass used in containers (Type 5)","b8634197":"1. From box plot it is evident that there are outliers in the data.\n2. Mean of 'Si' is way more than mean of other parameters. It is not surprising, since 'Si' is major content in glass","e641441f":"We can see that there are no null values in the data set","0d87fb76":"Results look better than previous after transformation as we can see that skew values have come down. Lets split the data for training and testing","0ee339d4":"The data has 214 observations and 9 features which can be used to predict 10th feature.","aa1815a1":"##### From the skewness data we can see that none of the features are normally distributed. Let us check with box plots to find the outliers. 'Ba' and 'K' have very high skewness in data","132b0176":"## Hard-Voting","e8d62587":"# Logistic Regression","0de75ec2":"# Data Information\n\nThis is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n\nAttribute information: -\n1.\tId number: 1 to 214 (removed from CSV file)\n2.\tRI: refractive index\n3.\tNa: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n4.\tMg: Magnesium\n5.\tAl: Aluminum\n6.\tSi: Silicon\n7.\tK: Potassium\n8.\tCa: Calcium\n9.\tBa: Barium\n10.\tFe: Iron\n11.\tType of glass: (class attribute) -- 1 building_windows_float_processed -- 2 building_windows_non_float_processed -- 3 vehicle_windows_float_processed -- 4 vehicle_windows_non_float_processed (none in this database) -- 5 containers -- 6 tableware -- 7 headlamps\n\nIn this note book, I have made small attempt to understand and use various classification algorithms to predict the best algorithm for this data.\n\nNotebook by: [Akshay Sb](https:\/\/www.linkedin.com\/in\/akshaybidarkundi\/)\n\n\"\"Please do upvote, if you find this as useful.\"\"","4be216a3":"#### Here we can see that  odel is over-fitting, let us try hyper-parameter tuning for the random forest","2c968c99":"##### Let us try to see whether there is any correlation between the features","703a604c":"#####  Float and non-float processed building glasses, float-processed window glasses and head-lamp glasses (Type 1,2,3 and 7) have almost same quantity of potassium.\n#####  Glasses used in containers (Type 5) have very high content of potassium compared to other types\n##### Table ware glasses have no potassium content in them.","8c7d5ae1":"### There is slight difference in the accuracy. We will check with soft voting\n\n#### Soft Voting with equal weightages","d161aa4c":"# Model Building","1a1e701a":"##### Magnesium (Mg) content varies from around 0.5 to 3.5. It is highest in float processed building windows and vehicle windows (Type 1 and Type3) glasses","05f96fa4":"#### Let us find the outliers.","bdbaa668":"##### Glass used in tablewares have no iron content in them\n##### Glass used in headlamps have iron content of around 0.01.\n##### Glass used in non-float processed building window glasses have highest content of iron compared other types of glasses.","e3ad22e9":"### Let us check for any null values","02f68f9b":"##### 1. Aluminum (Al) content varies from 1.15 to around 2.20. It is highest in glass used in headlamps (Type7).\n##### 2. Glass used in containers also have almost same Aluminum content as that of headlamps. ","c9bedb67":"#### We can observe that, all the types of glass have similar refractive index.","f0d0912b":"#### Lets plot distribution plots after removing outlier columns","c9985232":"Now, it is better to remove these rows, instead of removing entries based on LCL and UCL. ","b35772b7":"#### Let us try soft voting by giving weightages","10c70f37":"#### From above results, it can be seen that the model with combinations of Logistic Regression, KNN, Random Forest and Light gbm performs better compared to other models.","2b97ade6":"## Random Forest","04cb41fa":"# Stacking","5f66cae8":"##### Model seems to over-fit. Let us tune the hyper-parameters to check whether we can resolve over-fitting issues","2a3edb8b":"#### Even after hyperparameter tuning, there is no improvement in performance of model. Let us try building other models","37047144":"### Let us define a function to evaluate a model, which can be used to evaluate the model of all algorithms","fab7e8be":"#### Let us see what are the best parameters and we will build model as per best parameters","bfe69beb":"# Since KNN and Logistic Regression models are performing better. Lets try and build stacking model with only KNN and Logistic Regression","c8e57373":"#### There is acceptable difference between train and test accuracy.","15c77541":"##### Sodium (Na) content varies from 12.5 to 14. It is highest in type-6 glass which is tableware glass","60beb70e":"#### From train and test accuracy, we can observe that the accuracy scores are closer to each other. Hence we can see that KNeighbours performs better in this case. Let us try with other models before final conclusion","dbac47c4":"# KNN Algorithm","05ed3377":"Here we can see that Upper limit and lower limit are very close to each other. If we remove the outliers there will be huge loss in information. Hence we will remove those rows which have more than two outliers","965b86aa":"### Let us look at the content of Na,Mg,Al,Si,K,Ca,Ba and Fe in different types of glass","5e37fc1b":"#### There is around 10% difference between train and test data. Let us try to hyper-tune the parameters.","c7c666c2":"##### Glass used in float processed building and vehicle window glasses and  tableware glasses (Type 1,3,6) almost have no Barium content in them.\n##### Glass used in non-float processed building window walls and container glass have Barium content in the range 0.05 - 0.2\n##### Glass used in headlamps have highest Barium content.","c582107f":"### Let us check for any outliers using uni variate analysis","8ec4990d":"## Reading the data","e900ec91":"Still there is no appreciable change in skewness. Let us go for transformations\nHere we cannot use Log transformation, since it keeps on reducing the value and there are some features with negetive skew and it will becone further negetive.\nWe can try for box-cox transformation","2608709b":"### Let us use Boosting method (Lightbgm)","742b7779":"## Here we can observe,model is performing better comparing to equal weightages.","44a71783":"#### Even after hyperparameter tuning, there is considerable amount of over-fitting","d51e186b":"## Importing Libraries","225ffb6e":"There is good correlation between 'Ca' and 'RI'.\nThere is moderate correlation between ('Si' and 'RI'),('Ba' and 'Mg') and ('Al' and 'Mg')","bcf1137a":"##### Every type of glass have almost same SIlicon content","824e987f":"## Exploratory Data Analysis"}}