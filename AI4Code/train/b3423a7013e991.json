{"cell_type":{"32c7f0ac":"code","88eab0a2":"code","4161f42f":"code","a37af10c":"code","0503dbe5":"code","b2dd696f":"code","cddb1d3c":"code","f545b779":"code","8c11cb8b":"code","3afd5e44":"code","2852b1c4":"code","70f9d024":"code","af75d42f":"code","bd358a43":"code","fd3f9650":"code","572823c3":"code","c17057d9":"code","4add1e19":"code","af5fb673":"code","98fdbea9":"code","dbacab8a":"code","274ecff6":"markdown"},"source":{"32c7f0ac":"import os\nimport re\n\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage, misc\nfrom matplotlib import pyplot\nimport cv2 as cv\nimport numpy as np\nnp.random.seed(0)\n\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf\nprint(tf.__version__)\nprint(ndimage.__version__)","88eab0a2":"input_img = Input(shape=(256, 256, 3))\nl1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\nl2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\nl3 = MaxPooling2D(padding='same')(l2)\nl4 = Dropout(0.3)(l3)\nl5 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\nl6 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l5)\nl7 = MaxPooling2D(padding='same')(l6)\nl8 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l7)\nl9 = UpSampling2D()(l8)\nl10 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\nl11 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l10)\nl12 = add([l6,l11])\nl13 = UpSampling2D()(l12)\nl14 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\nl15 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l14)\nl16 = add([l15,l2])\ndecoded = Conv2D(3, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l16)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.summary()","4161f42f":"from tensorflow.keras.optimizers import Adam\ndef get_optimizer():\n \n    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n    return adam","a37af10c":"optimizer=get_optimizer()\nautoencoder.compile(optimizer=optimizer, loss='mean_squared_error',metrics=['acc'])","0503dbe5":"TRAIN_HR_DIR='..\/input\/cars-train-img\/cars_train'","b2dd696f":"import os\nimport re\nfrom scipy import ndimage, misc\nfrom skimage import data, color\nfrom skimage.transform import resize, rescale\nfrom matplotlib import pyplot\nimport numpy as np\nimport gc\n","cddb1d3c":"broken_file=[]\nepoch=1\nscale_percent = 50\nfor epoch in range(epoch):\n    # 1 is only for demo I use 10 for my training\n    for i in range(1):\n        x_train_n2=[]\n        x_train_down2=[]\n        x_train_n=[]\n        x_train_down=[]\n        for a in range(800):\n            broken_file=[]\n             #a=a+301 #loop 301-350\n              #a=a+401 #loop(401-600)\n            counter=(i+7)*800\n            a=a+1+counter \n            b = (lambda a: '{0:0>5}'.format(a))(a)\n                \n            filename = str(b)+'.jpg'\n            #print(filename)\n            image=0\n            image_resized=0\n            \n            image_path=os.path.join(TRAIN_HR_DIR,filename)\n            image = pyplot.imread(image_path)\n        \n            image_resized = resize(image, (256,256))\n            broken_file.append(image_resized)\n            dim_test=np.array(broken_file)\n            if(dim_test.ndim==4):\n                x_train_n.append(image_resized)\n            \n                low_res_image=resize(resize(image, (128, 128)),(256,256))\n            \n                x_train_down.append(low_res_image)\n                            \n                \n                \n                x_train_n2=np.array(x_train_n).reshape(-1, 256,256, 3)\n                \n                x_train_down2=np.array(x_train_down).reshape(-1, 256,256, 3)\n            else:\n                error=\"file error in file no.\"+filename\n                print(error)\n                \n        hist=autoencoder.fit(x_train_down2, x_train_n2,\n                        epochs=2,\n                        batch_size=10,\n                        shuffle=True,\n                        validation_split=0.15)\n        del x_train_n2\n        del x_train_down2\n        del x_train_n\n        del x_train_down\n        # Somehow when I add gc.collect() it even saves more spaces for training\n        gc.collect()\nautoencoder.save('car_sr_8000.hdf5') \n","f545b779":"def get_dataset():\n    broken_file=[]\n    epoch=1\n    scale_percent = 50\n    x_train_n=[]\n    x_train_down=[]\n    x_train_n2=[]\n    x_train_down2=[]\n    for a in range(100):\n        broken_file=[]\n        #a=a+301 #loop 301-350\n        #a=a+401 #loop(401-600)\n        \n        a=a+1\n        b = (lambda a: '{0:0>5}'.format(a))(a)\n        filename = str(b)+'.jpg'\n        #print(filename)\n        image=0\n        image_resized=0\n        \n        image_path=os.path.join(TRAIN_HR_DIR,filename)\n        image = pyplot.imread(image_path)\n        \n        image_resized = resize(image, (256,256))\n        broken_file.append(image_resized)\n        dim_test=np.array(broken_file)\n        if(dim_test.ndim==4):\n            x_train_n.append(image_resized)\n            \n            low_res_image=resize(resize(image, (128, 128)),(256,256))\n            # rescale somehow didn't work in Kaggle it transform my (256,256,3)to(256,256,4)\n            #x_train_down.append(rescale(rescale(image_resized, 0.5), 2.0))\n            x_train_down.append(low_res_image)\n                    \n                \n                \n            x_train_n2=np.array(x_train_n).reshape(-1, 256,256, 3)\n            #print(x_train_n2.shape)\n            x_train_down2=np.array(x_train_down).reshape(-1, 256,256, 3)\n        else:\n            error=\"file error in file no.\"+filename\n            print(error)\n        \n    return x_train_n2,x_train_down2\n\nx_train_n,x_train_down = get_dataset()","8c11cb8b":"encoded_imgs = autoencoder.predict(x_train_down)","3afd5e44":"image_index = np.random.randint(0,100)","2852b1c4":"plt.figure(figsize=(128, 128))\ni = 1\nax = plt.subplot(10, 10, i)\n# The model low_resolution input\nplt.imshow(x_train_down[image_index])\n\n\n#ax = plt.subplot(10, 10, i)\n#plt.imshow(encoded_imgs[image_index].reshape((64*64, 256)))\ni += 1\nax = plt.subplot(10, 10, i)\n# My model prediction\nplt.imshow(encoded_imgs[image_index])\ni += 1\nax = plt.subplot(10, 10, i)\nplt.imshow(x_train_n[image_index])\nplt.show()","70f9d024":"# The Zoomed vesion of these images can be accessed here\n# https:\/\/drive.google.com\/drive\/folders\/1ZLMjXPxqQf8vzwD6F23eJM3Yi7g3ImCf?usp=sharing\n# picture name : 1st_prediction.png","af75d42f":"# We can see that my model sharpends the blurry images\n# Note that my 1st model are trained from images that are processed by scikit transform library\n\n# Now Let me pre-load my 2nd model that are trained from images that are processed by cv2 rescale library","bd358a43":"input_img = Input(shape=(256, 256, 3))\nl1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\nl2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\nl3 = MaxPooling2D(padding='same')(l2)\nl4 = Dropout(0.3)(l3)\nl5 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\nl6 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l5)\nl7 = MaxPooling2D(padding='same')(l6)\nl8 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l7)\n\nl9 = Conv2DTranspose(256, (3,3), strides=(2,2), padding='same')(l8)\n\nl10 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\nl11 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l10)\nl12 = add([l6,l11])\n\nl13 = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same')(l12)\n\nl14 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\nl15 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l14)\nl16 = add([l15,l2])\ndecoded = Conv2D(3, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l16)\n\nautoencoder2 = Model(input_img, decoded)\nautoencoder2.summary()","fd3f9650":"autoencoder2.compile(optimizer=optimizer, loss='mean_squared_error')","572823c3":"def get_dataset_2():\n    # Using Cv2 for creating pixelated images\n    broken_file=[]\n    epoch=1\n    scale_percent = 25\n    x_train_n=[]\n    x_train_down=[]\n    x_train_n2=[]\n    x_train_down2=[]\n    for a in range(100):\n        broken_file=[]\n        #a=a+301 #loop 301-350\n        #a=a+401 #loop(401-600)\n        \n        a=a+1\n        b = (lambda a: '{0:0>5}'.format(a))(a)\n        filename = str(b)+'.jpg'\n        #print(filename)\n        image=0\n        image_resized=0\n        \n        image_path=os.path.join(TRAIN_HR_DIR,filename)\n        image = pyplot.imread(image_path)\n        \n        image_resized = resize(image, (256,256))\n        broken_file.append(image_resized)\n        dim_test=np.array(broken_file)\n        if(dim_test.ndim==4):\n            x_train_n.append(image_resized)\n            \n            width = int(image_resized.shape[1] * scale_percent \/ 100)\n            height = int(image_resized.shape[0] * scale_percent \/ 100)\n            dim = (width, height)\n            small_image = cv.resize(image_resized, dim, interpolation = cv.INTER_AREA)\n\n            # scale back to original size\n            width = int(small_image.shape[1] * 100 \/ scale_percent)\n            height = int(small_image.shape[0] * 100 \/ scale_percent)\n            dim = (width, height)\n            low_res_image = cv.resize(small_image, dim, interpolation =  cv.INTER_AREA)\n            \n            x_train_down.append(low_res_image)\n                    \n                \n                \n            x_train_n2=np.array(x_train_n).reshape(-1, 256,256, 3)\n            #print(x_train_n2.shape)\n            x_train_down2=np.array(x_train_down).reshape(-1, 256,256, 3)\n        else:\n            error=\"file error in file no.\"+filename\n            print(error)\n        \n    return x_train_n2,x_train_down2\n\nx_train_n_cv,x_train_down_cv = get_dataset_2()","c17057d9":"autoencoder2.load_weights('..\/input\/my-other-pretrained-model\/ResNet_Super_Resolution_7epoch_900data_convTranspose.hdf5')","4add1e19":"SR_cv = autoencoder2.predict(x_train_down_cv)\n# Trying to see the performance differences\nSR = autoencoder.predict(x_train_down_cv)","af5fb673":"plt.figure(figsize=(128, 128))\ni = 1\nax = plt.subplot(10, 10, i)\n# The model low_resolution input\nplt.imshow(x_train_down_cv[39])\n\n\n#ax = plt.subplot(10, 10, i)\n#plt.imshow(encoded_imgs[image_index].reshape((64*64, 256)))\ni += 1\nax = plt.subplot(10, 10, i)\n# My 2nd model prediction (trained on cv2 processed images)\nplt.imshow(SR_cv[39])\ni += 1\nax = plt.subplot(10, 10, i)\n# My 1st model prediction (trained on scikit transform images)\nplt.imshow(SR[39])\ni += 1\nax = plt.subplot(10, 10, i)\nplt.imshow(x_train_n_cv[39])\nplt.show()","98fdbea9":"# The Zoomed vesion of these images can be accessed here\n# https:\/\/drive.google.com\/drive\/folders\/1ZLMjXPxqQf8vzwD6F23eJM3Yi7g3ImCf?usp=sharing\n# picture name : 2nd_prediction.png","dbacab8a":"# My 1st model works well for enhancing blurry images (prepared by skitransform tools)\n# While my 2nd model outperforms my 1st model for enhancing pixelated images (prepared by CV2)\n# Super Resolution models performs differently based on how we prepare their training data.\n\n# Notes to self : try to combine dataset that are processed both from cv2 and scikit transform\n# Changing loss function to perceptional loss function\n# Use dynamic regularization and Callbacks(maybe?)","274ecff6":"# Loading my other pre-trained model"}}