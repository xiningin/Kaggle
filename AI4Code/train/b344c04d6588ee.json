{"cell_type":{"315002c8":"code","5a394245":"code","708c6ba1":"code","01cabc7f":"code","aeabd16a":"code","0a48525c":"code","e41b47a9":"code","e79ccf40":"code","bebb7355":"code","2f6d79fb":"code","6d6e6aa3":"code","1b4a2022":"code","257d4155":"code","31f20a3a":"code","fb5058dd":"code","661edee6":"code","aecfebc4":"markdown","1405093d":"markdown","de2cfe9b":"markdown","940ff1d7":"markdown","c7e5453e":"markdown","e64edd75":"markdown"},"source":{"315002c8":"import pandas as pd","5a394245":"df_train = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ndf_train.head()","708c6ba1":"for col in df_train.columns:\n    if col not in [\"id\",\"claim\"]:\n        print(col,\"=\",df_train[col].isnull().sum())","01cabc7f":"df_train = df_train.fillna(df_train.mean())","aeabd16a":"X = df_train.drop([\"id\",\"claim\"],axis =1)\ny = df_train.claim","0a48525c":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","e41b47a9":"X = df_train.drop([\"id\",\"claim\"],axis = 1)\ny = df_train.claim","e79ccf40":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)","bebb7355":"y_pred = clf.predict(X_val)","2f6d79fb":"score = accuracy_score(y_val, y_pred)\nprint(score)","6d6e6aa3":"df_test = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\ndf_test.head()","1b4a2022":"for col in df_test.columns:\n    if col not in [\"id\",\"claim\"]:\n        print(col,\"=\",df_test[col].isnull().sum())","257d4155":"df_test = df_test.fillna(df_test.mean())","31f20a3a":"df_test = df_test.drop(\"id\",axis =1)","fb5058dd":"pred = clf.predict(df_test)","661edee6":"sub  = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsub.claim = pred\nsub.to_csv(\"submission.csv\",index = False)","aecfebc4":"**Step 4:**\n- Import RandomForestClassifier, accuracy_score\n- Fit training data\n- Predict on validation data\n- Find accuracy score on validation data","1405093d":"**Step 3:**\n- Drop id and claim columns\n- Set Features to X and Target to y\n- Split data into 80% for training and 20% for validation","de2cfe9b":"**step 5:**\n- Read Test Data\n- Check for missing values\n- Fill with mean value\n- Predict using model","940ff1d7":"**Step 1:**\n- Import required libraries  for the this Notebook.","c7e5453e":"**Step 6:**\n- Read sample solution\n- Replace claim with column with prediction from test data\n- Write to csv and submit.","e64edd75":"**Step 2:**\n- Read Training data\n- Check For missing values\n- Fill missing values with mean"}}