{"cell_type":{"c1312dbb":"code","1ee4dc51":"code","7ebcdbc2":"code","c486b97c":"code","c4e7454f":"code","a081fbaa":"code","23caccda":"code","3a9c1f01":"code","e1eab099":"code","b2a35285":"code","d22aa865":"code","436aadcb":"code","8b151bdc":"code","f2e24851":"code","36047ac8":"code","7c505c6d":"code","d605d620":"code","8731be41":"code","bdcbf59a":"code","bef1761a":"code","56ca1afb":"code","1870f85e":"code","0c0a974f":"code","917b9660":"code","54ccc96d":"code","d1334dbd":"code","29586984":"code","5c7f8a0c":"code","65f427b0":"code","5eaf8343":"code","567dbada":"code","2ea376e3":"code","81e8092b":"code","fff18e6a":"code","57b565bb":"code","b513af94":"code","5c869585":"code","5eed1c64":"code","44832d5c":"code","7509a7f8":"code","55d2a737":"code","a1b6aed7":"code","89b82e47":"code","1ab90e12":"code","42b2a7d4":"code","0f1fafb7":"code","f93d07bb":"code","e4a19886":"code","f4024f49":"code","12d147ab":"code","17efd80b":"code","5c821fca":"code","d63fc525":"code","58432436":"code","453c6301":"code","a7752d49":"code","bbcd4f08":"code","fb049a50":"code","17510115":"code","b1ebd454":"code","b5d5fa13":"code","47ea24c2":"code","4122aef4":"code","b65dcca8":"code","58e3175e":"code","f53f9764":"code","9c7ba017":"code","cd55d92e":"code","f12f2d27":"code","4e903c27":"code","faad5251":"code","2d7fc632":"code","492ebe9f":"code","1293b5ca":"code","55b386f3":"code","4802febf":"code","f5c9bb06":"code","2fa6bd3c":"code","da578393":"code","d9699017":"code","78b788e1":"code","99fd9e0d":"code","aee31e36":"code","5260e2f7":"code","33299961":"code","469bf53c":"code","c2b73f0f":"code","e0a3f993":"code","8625211b":"code","1e0223ce":"code","09e579ac":"code","a0ff9f39":"code","4c197e6b":"markdown","7838b22a":"markdown","b3c8f66f":"markdown","c3bbbe67":"markdown","b450ca51":"markdown","ef065dcf":"markdown","43869af5":"markdown","74f19ec7":"markdown","676016e7":"markdown","c5fff9ca":"markdown","a3347840":"markdown"},"source":{"c1312dbb":"#! pip list\n\n ","1ee4dc51":"!pip install \/kaggle\/input\/iterative-stratification\/iterative-stratification-master\/","7ebcdbc2":"#!pip install git+https:\/\/github.com\/fastai\/fastcore > \/dev\/null\n#!pip install git+https:\/\/github.com\/fastai\/fastai2 > \/dev\/null\n#!pip install iterative-stratification > \/dev\/null","c486b97c":"import sys\npackage_path = '..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\n\n","c4e7454f":"!ls ..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch","a081fbaa":"%cd \/kaggle\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\nfrom efficientnet_pytorch import EfficientNet\n%cd -","23caccda":"import pandas as pd\nimport numpy as np\nfrom fastai.vision.all import *\nimport pickle\nimport os","3a9c1f01":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'\n!cp '..\/input\/resnet101\/resnet101.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet101-5d3b4d8f.pth'\n\n## cp efficientnet pretrained weights\n!cp '..\/input\/efficientnet-pytorch-pretrained\/adv-efficientnet-b7-4652b6dd.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n!cp '..\/input\/efficientnet-pytorch-pretrained\/adv-efficientnet-b6-ac80338e.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n \n!cp '..\/input\/efficientnet-pytorch-pretrained\/adv-efficientnet-b5-86493f6b.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n!cp '..\/input\/efficientnet-pytorch-pretrained\/adv-efficientnet-b4-44fb3a87.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n\n\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b2-27687264.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b3-c8376fa2.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b4-e116e8b3.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b6-c76e70fd.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n!cp '..\/input\/efficientnet-pytorch\/efficientnet-b7-dcc49843.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n!cp '..\/input\/vgg16weight\/vgg16_bn-6c64b313.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n#!cp '..\/input\/vgg19-bnmodels\/vgg19_bn-c79401a0.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n#!cp '..\/input\/squeezenet\/squeezenet1_0-a815701f.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n#!cp '..\/input\/squeezenet\/squeezenet1_0-a815701f.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n#!cp '..\/input\/pytorch-model-zoo\/alexnet-owt-4df8aa71.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/'\n\n# !cp '..\/input\/resnet34\/resnet34.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet34-333f7ec4.pth'","e1eab099":"'''\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet101\/resnet101.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet101-5d3b4d8f.pth'\n\n'''","b2a35285":"path = Path('..\/input\/hpa-cell-tiles-sample-balanced-dataset')","d22aa865":"df = pd.read_csv(path\/'cell_df.csv')","436aadcb":"df.head()","8b151bdc":"len(df)","f2e24851":"labels = [str(i) for i in range(19)]\nfor x in labels: df[x] = df['image_labels'].apply(lambda r: int(x in r.split('|')))","36047ac8":"#dfs = df.sample(frac=0.1, random_state=42)\n\n#dfs = df.sample(frac=1, random_state=42)\n\n#let try less data for efficientnetb5\n\n#b5 is fine. over b5 out of memory.\n\ndfs = df.sample(frac=1, random_state=42)\n\n\ndfs = dfs.reset_index(drop=True)\nlen(dfs)","7c505c6d":"unique_counts = {}\nfor lbl in labels:\n    unique_counts[lbl] = len(dfs[dfs.image_labels == lbl])\n\nfull_counts = {}\nfor lbl in labels:\n    count = 0\n    for row_label in dfs['image_labels']:\n        if lbl in row_label.split('|'): count += 1\n    full_counts[lbl] = count\n    \ncounts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\ncounts = np.array(sorted(counts, key=lambda x:-x[1]))\ncounts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\ncounts.set_index('label').T\n","d605d620":"len(dfs)","8731be41":"nfold = 5\nseed = 42\n\ny = dfs[labels].values\nX = dfs[['image_id', 'cell_id']].values\n\ndfs['fold'] = np.nan\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    dfs.iloc[test_index, -1] = i\n    \ndfs['fold'] = dfs['fold'].astype('int')","bdcbf59a":"dfs['is_valid'] = False\ndfs['is_valid'][dfs['fold'] == 0] = True","bef1761a":"dfs.is_valid.value_counts()","56ca1afb":"def get_x(r): return path\/'cells'\/(r['image_id']+'_'+str(r['cell_id'])+'.jpg')\nimg = get_x(dfs.loc[12])\nimg = PILImage.create(img)\nimg.show();","1870f85e":"def get_y(r): return r['image_labels'].split('|')\nget_y(dfs.loc[12])","0c0a974f":"sample_stats = ([0.07237246, 0.04476176, 0.07661699], [0.17179589, 0.10284516, 0.14199627])","917b9660":"item_tfms = RandomResizedCrop(224, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(flip_vert=True, size=128, max_warp=0), Normalize.from_stats(*sample_stats)]\nbs=256","54ccc96d":"dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(vocab=labels)),\n                splitter=ColSplitter(col='is_valid'),\n                get_x=get_x,\n                get_y=get_y,\n                item_tfms=item_tfms,\n                batch_tfms=batch_tfms\n                )\ndls = dblock.dataloaders(dfs, bs=bs)","d1334dbd":"# dblock.summary(dfs)","29586984":"dls.show_batch(nrows=3, ncols=3)","5c7f8a0c":"#learn = cnn_learner(dls, resnet50, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()","65f427b0":"#learn = cnn_learner(dls, resnet101, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()","5eaf8343":"#learn = cnn_learner(dls, vgg16_bn, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()#","567dbada":"#learn = cnn_learner(dls, vgg19_bn, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()","2ea376e3":"#learn = cnn_learner(dls,squeezenet1_0, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()#","81e8092b":"#learn = cnn_learner(dls,alexnet, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()#","fff18e6a":"'''\ndef get_learner(fold_num, lr=1e-3):\n    opt_func = partial(Adam, lr=lr, wd=0.01, eps=1e-8)\n\n    data = get_data(fold_num)\n    \n    model = EfficientNet.from_pretrained(\"efficientnet-b7\", advprop=True)\n    #model = EfficientNet.from_name(\"efficientnet-b7\")\n    #model = EfficientNet.from_pretrained(\"efficientnet-b8\", advprop=True) # weights run to NaN\n    #model = EfficientNet.from_name('efficientnet-b4') \n    #model._fc = nn.Linear(1280, data.c)# the last layer... # works for b0,b1\n    #model._fc = nn.Linear(1536, data.c)# the last layer... B3\n    #model._fc = nn.Linear(1792, data.c)# the last layer... B4\n    #model._fc = nn.Linear(2048, data.c)# the last layer... B5\n    #model._fc = nn.Linear(2304, data.c)# the last layer... B6\n    model._fc = nn.Linear(2560, data.c)# the last layer... B7\n    #model._fc = nn.Linear(2816, data.c)# the last layer... B8\n\n    learn = Learner(\n        dls, model, opt_func=opt_func,\n        loss_func=LabelSmoothingCrossEntropy(),\n        #callback_fns = [partial(OverSamplingCallback)],  \n        metrics=[\n            AccumMetric(healthy_roc_auc, flatten=False),\n            AccumMetric(multiple_diseases_roc_auc, flatten=False),\n            AccumMetric(rust_roc_auc, flatten=False),\n            AccumMetric(scab_roc_auc, flatten=False),\n            AccumMetric(comp_metric, flatten=False)]\n        ).to_fp16()\n    return learn\n'''","57b565bb":"def get_learner(lr=1e-3):\n    opt_func = partial(Adam, lr=lr, wd=0.01, eps=1e-8)\n\n    #data = get_data(fold_num)\n    \n    #model = EfficientNet.from_pretrained(\"efficientnet-b5\", advprop=True) #0.364\n    \n    #let try add some epochs\n    \n    model = EfficientNet.from_pretrained(\"efficientnet-b5\", advprop=True)  \n    \n    #model = EfficientNet.from_pretrained(\"efficientnet-b6\", advprop=False) outof memory\n    # b7 out of memory , try small model \n    \n    #model = EfficientNet.from_name(\"efficientnet-b7\")\n    #model = EfficientNet.from_pretrained(\"efficientnet-b8\", advprop=True) # weights run to NaN\n    #model = EfficientNet.from_name('efficientnet-b4') \n    #model._fc = nn.Linear(1280, data.c)# the last layer... # works for b0,b1\n    #model._fc = nn.Linear(1536, data.c)# the last layer... B3\n    #model._fc = nn.Linear(1792, data.c)# the last layer... B4\n    model._fc = nn.Linear(2048, dls.c)# the last layer... B5\n    #model._fc = nn.Linear(2304, dls.c)# the last layer... B6\n    #model._fc = nn.Linear(2560, dls.c)# the last layer... B7\n    #model._fc = nn.Linear(2816, data.c)# the last layer... B8\n\n    learn = Learner(\n        dls, model, opt_func=opt_func,\n        #loss_func=LabelSmoothingCrossEntropy(),\n        #callback_fns = [partial(OverSamplingCallback)],  \n        metrics=[accuracy_multi, PrecisionMulti()]\n        ).to_fp16()\n    return learn\n","b513af94":"learn=get_learner()","5c869585":"learn.lr_find()","5eed1c64":"#SuggestedLRs(lr_min=0.017378008365631102, lr_steep=0.001737800776027143)","44832d5c":"#learn.lr_find()#\n# SuggestedLRs(lr_min=0.03630780577659607, lr_steep=0.02754228748381138)","7509a7f8":"#learn.fit(16)\n#each epoch around 20minuts","55d2a737":"lr=3e-2","a1b6aed7":"#learn.fine_tune(2,base_lr=lr)","89b82e47":"#learn.fine_tune(4,base_lr=lr)","1ab90e12":"learn.fine_tune(6,base_lr=lr)","42b2a7d4":"learn.recorder.plot_loss()","0f1fafb7":"from sklearn.metrics import multilabel_confusion_matrix as cm","f93d07bb":"# val_targ = torch.stack([x[1] for x in learn.dls.valid_ds], dim=0).numpy()\n# val_targ.shape","e4a19886":"val_targ = dfs[labels][dfs.is_valid == True].values","f4024f49":"val_targ.shape","12d147ab":"val_preds_all = learn.get_preds(dl=learn.dls.valid)","17efd80b":"val_preds = val_preds_all[0].numpy()","5c821fca":"val_preds = val_preds > 0.5","d63fc525":"full_preds = val_preds_all[0].numpy()","58432436":"vis_arr = cm(val_targ, val_preds)","453c6301":"# i = 60\n# print(learn.dls.valid.dataset[i][1])\n# print(val_preds[i])\n# print(full_preds[i])\n# learn.dls.valid.dataset[i][0]","a7752d49":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndef print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names,\n    )\n\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    axes.set_ylabel('True label')\n    axes.set_xlabel('Predicted label')\n    axes.set_title(\"Confusion Matrix for the class - \" + class_label)","bbcd4f08":"fig, ax = plt.subplots(5, 4, figsize=(12, 16))\n    \nfor axes, cfs_matrix, label in zip(ax.flatten(), vis_arr, labels):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"0\", \"1\"])\n\nfig.tight_layout()\nplt.show()","fb049a50":"val = dfs[dfs.is_valid==True]\nlen(val[val['16'] == 1])","17510115":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(val_targ, val_preds)\naverage_precision","b1ebd454":"from sklearn.metrics import precision_recall_curve\n\nprecision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(19):\n    precision[i], recall[i], _ = precision_recall_curve(val_targ[:, i], val_preds[:, i])\n    average_precision[i] = average_precision_score(val_targ[:, i], val_preds[:, i])\n\n# A \"micro-average\": quantifying score on all classes jointly\nprecision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(val_targ.ravel(), val_preds.ravel())\naverage_precision[\"micro\"] = average_precision_score(val_targ, val_preds, average=\"micro\")\nprint('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))","b5d5fa13":"average_precision","47ea24c2":"path = Path('..\/input\/hpa-cell-tiles-test-with-enc-dataset')","4122aef4":"df = pd.read_csv(path\/'cell_df.csv')","b65dcca8":"df.to_csv('cell_df.csv', index=False)","58e3175e":"test_dl = learn.dls.test_dl(df)","f53f9764":"test_dl.show_batch()","9c7ba017":"preds, _ = learn.get_preds(dl=test_dl)","cd55d92e":"preds.shape","f12f2d27":"with open('preds.pickle', 'wb') as handle:\n    pickle.dump(preds, handle)","4e903c27":"tta, _ = learn.tta(dl=test_dl)","faad5251":"tta.shape","2d7fc632":"with open('tta.pickle', 'wb') as handle:\n    pickle.dump(tta, handle)","492ebe9f":"cls_prds = torch.argmax(preds, dim=-1)\nlen(cls_prds), cls_prds","1293b5ca":"sample_submission = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')\nsample_submission.head()","55b386f3":"df['cls'] = cls_prds\ndf['pred'] = df[['cls', 'enc']].apply(lambda r: str(r[0]) + ' 1 ' + r[1], axis=1)\ndf.head()","4802febf":"subm = df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n# subm = subm.loc[3:]\nsubm.head()","f5c9bb06":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)","2fa6bd3c":"sub.head()","da578393":"def isNaN(num):\n    return num != num","d9699017":"for i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","78b788e1":"sub = sub[sample_submission.columns]\nsub.head()","99fd9e0d":"sub.to_csv('submission_1.csv', index=False)","aee31e36":"cell_df = pd.read_csv('cell_df.csv')\ncell_df.head()\ncell_df['cls'] = ''","5260e2f7":"threshold = 0.0\n\nfor i in range(preds.shape[0]): \n    p = torch.nonzero(preds[i] > threshold).squeeze().numpy().tolist()\n    if type(p) != list: p = [p]\n    if len(p) == 0: cls = [(preds[i].argmax().item(), preds[i].max().item())]\n    else: cls = [(x, preds[i][x].item()) for x in p]\n    cell_df['cls'].loc[i] = cls","33299961":"def combine(r):\n    cls = r[0]\n    enc = r[1]\n    classes = [str(c[0]) + ' ' + str(c[1]) + ' ' + enc for c in cls]\n    return ' '.join(classes)\n\ncombine(cell_df[['cls', 'enc']].loc[24])","469bf53c":"cell_df['pred'] = cell_df[['cls', 'enc']].apply(combine, axis=1)\ncell_df.head()","c2b73f0f":"subm = cell_df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n# subm = subm.loc[3:]\nsubm.head()","e0a3f993":"sample_submission = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')\nsample_submission.head()","8625211b":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)\nsub.head()","1e0223ce":"def isNaN(num):\n    return num != num\n\nfor i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","09e579ac":"sub = sub[sample_submission.columns]\nsub.head()","a0ff9f39":"sub.to_csv('submission.csv', index=False)","4c197e6b":"## Where are the mistakes? ","7838b22a":"submission ","b3c8f66f":"## Using fastai data block API with item and batch transforms\n\nRead more: https:\/\/docs.fast.ai\/tutorial.datablock.html","c3bbbe67":"Thank you for your attention! Looking forward to questions and comments!","b450ca51":"## Change below to `frac=1` to run on the whole training sample","ef065dcf":"I trained for 10 epochs in the 0.342 leaderboard submission. ","43869af5":"Forded from \"fastai cell tile prototyping [training]\". credits due to author of It.","74f19ec7":"# fastai training with the data-block API\nfastai is a great tool to create a strong baseline quickly. I use pretty much out of the box approach for multilabel classification, with resnet50 backbone, one cycle training, lr finder etc. The data block API is a great way to prepare the data, and comes with a default set of augmentations that I use as well.\n\nSolution overview: https:\/\/www.kaggle.com\/c\/hpa-single-cell-image-classification\/discussion\/221550\n\n### I will smile for every upvote :) ","676016e7":"# Inference\nThis is running on the public test data preprocessed in the same way as train. We will save both regular preds and preds with TTA so that we can use them later in a separate submission notebook. ","c5fff9ca":"## Using multilabel stratification for the train-validation split.\n\nThere is some leakage in the code below (cells belonging to the same image should be in the same split). However, when I fixed that, I got a lower score... coincidence? ","a3347840":"## Let's train!"}}