{"cell_type":{"827f993a":"code","ad7584e5":"code","105167e4":"code","836d7d86":"code","ac871abd":"code","c4aa3818":"code","0827e7b9":"code","6190959a":"markdown","d88d0ea8":"markdown","aac7e748":"markdown","5f19d6e2":"markdown","bd46cc22":"markdown","525b68c5":"markdown"},"source":{"827f993a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad7584e5":"import pandas as pd\nimport numpy as np\n\n## Data Load\nX_train_csv = pd.read_csv(\"..\/input\/hr-data-predict-change-jobscompetition-form\/X_train.csv\")\nX_test_csv  = pd.read_csv(\"..\/input\/hr-data-predict-change-jobscompetition-form\/X_test.csv\")\ny_train_csv = pd.read_csv(\"..\/input\/hr-data-predict-change-jobscompetition-form\/y_train.csv\")\ny_test_csv  = pd.read_csv(\"..\/input\/hr-data-predict-change-jobscompetition-form\/test_label\/y_test.csv\")\n\n## EDA\ndef EDA(name, df):\n    print(\"== ===================================================\")\n    print(\"== EDA : \", name)\n    print(\"== ===================================================\")\n    \n    print(\">>> all column info\")\n    print(df.columns)\n    \n    print(\">>> include object column info\")\n    print(df.select_dtypes(include=object).columns)\n    for col in df.select_dtypes(include=object).columns :\n        print(\"-- ---------------------------------------------------\")\n        print(col, \"-\", df[col].nunique(), \" : \", df[col].unique())\n        print(df[col].value_counts())\n        print(\"null check : \", df[col].isnull().sum())\n        \n    print(\">>> exclude object column info\")\n    print(df.select_dtypes(exclude=object).columns)\n    for col in df.select_dtypes(exclude=object).columns :\n        print(\"-- ---------------------------------------------------\")\n        print(col, \"-\", df[col].unique()[:10])\n        print(df[col].describe())\n        print(\"null check : \", df[col].isnull().sum())\n        \n    print(\"== ===================================================\")\n    print(df.isnull().sum())\n    print(df.info())\n    print(df.describe())\n    print(\"== ===================================================\\n\\n\")\n    \n## \ub370\uc774\ud130 \ud655\uc778\uc6a9\nEDA(\"X_train_csv\", X_train_csv)\nEDA(\"y_train_csv\", y_train_csv)\nEDA(\"X_test_csv\", X_test_csv)","105167e4":"## User Defined Variable\ntarget_col = \"target\"\ndrop_col = [\"city\", \"enrollee_id\"]\nis_scaled = True\n\ngender_na = \"Other\"\nenrolled_university_na = \"Other\" # \"no_enrollment\"\neducation_level_na = \"Other\" # \"Primary School\"\nexperience_na = \"<1\"\nlast_new_job_na = \"never\"\n\ndef data_preprocessing(df_train, df_test) :\n#     print(\" > NA Data before check ---------------------\")\n#     print(df_train.isnull().sum())\n#     print(df_test.isnull().sum())\n    \n#     df_train['gender'].fillna( gender_na, inplace=True)\n#     df_train['enrolled_university'].fillna( enrolled_university_na, inplace=True)\n#     df_train['education_level'].fillna( education_level_na, inplace=True)\n#     df_train['experience'].fillna( experience_na, inplace=True)\n#     df_train['last_new_job'].fillna( last_new_job_na, inplace=True)    \n    \n#     df_test['gender'].fillna( gender_na, inplace=True)\n#     df_test['enrolled_university'].fillna( enrolled_university_na, inplace=True)\n#     df_test['education_level'].fillna( education_level_na, inplace=True)\n#     df_test['experience'].fillna( experience_na, inplace=True)\n#     df_test['last_new_job'].fillna( last_new_job_na, inplace=True)  \n    \n#     print(\" > NA Data check ---------------------\")\n#     print(df_train.isnull().sum())\n#     print(df_test.isnull().sum())\n    \n    split_len = df_train.shape[0]\n    \n    print(\" > One-Hot encoding pre count check -------------------\")\n    print(df_train.shape)\n    print(df_test.shape)\n    df_dum = pd.get_dummies(pd.concat([df_train, df_test], axis=0))\n    \n    df_train = df_dum[:split_len]\n    df_test  = df_dum[split_len:]\n    \n    print(\" > One-Hot encoding split count check -----------------\")\n    print(df_train.shape)\n    print(df_test.shape)\n    \n    print(\" > One-Hot encoding type check ---------------------\")\n    print(df_train.info())\n    print(df_test.info())\n    \n    return df_train, df_test\n\nX = X_train_csv.drop(drop_col, axis=1)\ny = y_train_csv[target_col]\nX_sub = X_test_csv.drop(drop_col, axis=1)\n\nX, X_sub = data_preprocessing(X, X_sub)","836d7d86":"## HoldOut\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n\n## Regulation\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_scaled_train = X_train\nX_scaled_test = X_test\nX_scaled_sub = X_sub\n\nif is_scaled :\n    X_scaled_train = scaler.transform(X_train)\n    X_scaled_test = scaler.transform(X_test)\n    X_scaled_sub = scaler.transform(X_sub)","ac871abd":"## model - RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_scaled_train, y_train)\n\n## train predict\npred_train = model.predict(X_scaled_train)\nprob_train = model.predict_proba(X_scaled_train)\n## test predict\npred_test = model.predict(X_scaled_test)\nprob_test = model.predict_proba(X_scaled_test)\n## submission predict\npred_sub = model.predict(X_scaled_sub)\nprob_sub = model.predict_proba(X_scaled_sub)\n\n## evaluation\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score, accuracy_score\nprint(\"\\n\\n>>> train -----------------------------------------------\")\nprint(\"accuracy_score : \", accuracy_score(y_train, pred_train))\nprint(\"f1_score       : \", f1_score(y_train, pred_train))\nprint(\"roc_auc_score  : \", roc_auc_score(y_train, prob_train[:,1]))\nprint(confusion_matrix(y_train, pred_train))\nprint(classification_report(y_train, pred_train))\n\nprint(\"\\n\\n>>> test ------------------------------------------------\")\nprint(\"accuracy_score : \", accuracy_score(y_test, pred_test))\nprint(\"f1_score       : \", f1_score(y_test, pred_test))\nprint(\"roc_auc_score  : \", roc_auc_score(y_test, prob_test[:,1]))\nprint(confusion_matrix(y_test, pred_test))\nprint(classification_report(y_test, pred_test))\n\nprint(\"\\n\\n>>> sub creation ----------------------------------------\")\ndf_sub = pd.DataFrame({\"enrollee_id\":X_test_csv['enrollee_id'], \"target\":prob_sub[:,1], \"target.pred\":pred_sub})\ndf_sub.to_csv(\"y_submission.csv\", index=False)\n\ndf_subr = pd.read_csv(\".\/y_submission.csv\")\ndisplay(df_subr.head())\n\ny_sub = y_test_csv[\"target\"]\nprob_subr = df_subr[\"target\"]\npred_subr = df_subr[\"target.pred\"]\n\nprint(\"\\n\\n>>> sub -------------------------------------------------\")\nprint(\"accuracy_score : \", accuracy_score(y_sub, pred_subr))\nprint(\"f1_score       : \", f1_score(y_sub, pred_subr))\nprint(\"roc_auc_score  : \", roc_auc_score(y_sub, prob_subr))\nprint(confusion_matrix(y_sub, pred_subr))\nprint(classification_report(y_sub, pred_subr))","c4aa3818":"## Enclosure.01 Cross_val\n## cross valid \nfrom sklearn.model_selection import GridSearchCV, cross_val_score, KFold\nkfold = KFold(n_splits=10)\nscore = cross_val_score(RandomForestClassifier(random_state=42), X_scaled_train, y_train, cv=kfold, scoring=\"roc_auc\")\nprint(score.mean())\nprint(score)\n# help(GridSearchCV)","0827e7b9":"## Enclosure.02 GridSearchCV\n## GridSearchCV\n\"\"\"\ngrid_param = {\"n_estimators\":range(100, 1000, 100), \"min_samples_split\":range(1, 10, 1), \"min_samples_leaf\":range(1,5,1), \"max_features\":[\"log2\", \"sqrt\", \"auto\"]}\ngrid_search = GridSearchCV(model, grid_param)\ngrid_search.fit(X_scaled_train, y_train)\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)\nprint(grid_search.score(X_scaled_test, y_test))\n\"\"\"","6190959a":"## Part.02 Data Preprocessing","d88d0ea8":"## Part.04 Data Modeling & Evaluation","aac7e748":"## Part.01 Data Load & EDA","5f19d6e2":"## Enclosure.01 Cross_val","bd46cc22":"## Enclosure.02 GridSearchCV","525b68c5":"## Part.03 Data Holdout & Data Normalization"}}