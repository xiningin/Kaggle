{"cell_type":{"8ba0e2fe":"code","346dbcf6":"code","87fca010":"code","b8773e9f":"code","6fcb651b":"code","532a943f":"code","70a6c994":"code","84a13160":"code","4e943ae3":"code","f9ffd867":"code","280db2c1":"code","cec58e3a":"code","d0eb5114":"code","8f25c564":"code","5b1ea349":"code","4e578213":"code","fd99a4ab":"code","2c76c418":"code","d48db301":"code","f7d89073":"code","2e3d95de":"code","6125d53f":"code","f60848df":"code","08bad5d0":"code","5fced6ba":"code","7bfb0702":"code","bfad9569":"code","50ae1bca":"code","00994c8f":"code","7ef98de1":"code","9fdb9cf3":"code","ac0d059d":"code","e7ce19a6":"code","b2744beb":"code","501f4e72":"code","bfee7796":"code","24e4097e":"code","8c63bdd7":"code","b7938ed5":"code","515d1fc0":"code","ec6e35f9":"code","f492aad3":"code","fbbaa678":"code","5611b96a":"code","fe1af704":"code","142a1f17":"code","aefbe472":"code","a1adf241":"code","93ba980d":"code","9723f00e":"code","762649d1":"code","2bc671b7":"code","eee77858":"code","6cbaa75a":"code","7ff71bb9":"code","aba0dff4":"code","c961b85a":"code","66277ce3":"code","dc434629":"code","99b8e408":"code","0cc625c1":"code","5f482432":"code","2f9a1b59":"code","033d3df0":"code","dd56bbb5":"code","efdc1632":"code","a8cf7e85":"code","5c58f1ea":"code","afe06be7":"code","442d9d89":"code","116131e5":"code","dbd04d92":"code","816f1e54":"code","8185bc18":"code","aa54cf89":"code","9cc2cb50":"code","ba31b40a":"code","3333908d":"code","d7ad8d64":"code","6c0be133":"code","73f535b4":"markdown","0d6eb137":"markdown","527e162b":"markdown","c99afb4d":"markdown","f74bc9ec":"markdown","d7cfe03e":"markdown","987a9ce2":"markdown","44e0d33c":"markdown","0fe967a7":"markdown","422355ba":"markdown","1251644f":"markdown","047c7460":"markdown","d1de80d6":"markdown","64eaddaf":"markdown","49a7ad8b":"markdown","8bf9eb69":"markdown","1b642d74":"markdown","36823137":"markdown","488f5670":"markdown","44bfcc93":"markdown","65477933":"markdown"},"source":{"8ba0e2fe":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport missingno as msno\nimport yaml\nfrom collections import Counter\nimport plotly.graph_objects as go\nimport plotly.express as xp\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.manifold import TSNE\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.metrics import accuracy_score\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ncolormap = ['#78ED02', '#66A725', '#638146', '#546247', '#40443C']\nsns.palplot(colormap)","346dbcf6":"# Let's read the files and check the info\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain_data = pd.read_csv(f\"{PATH}train.csv\")\ntest_data = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\n\n# We merge train- and test-data for now\ndf = pd.concat([train_data,test_data], axis = 0, ignore_index = True)\ntrain_mask = ~df.Category.isna()\ndf.info()","87fca010":"df","b8773e9f":"df.describe()","6fcb651b":"# Plot missing values\nmsno.bar(df, color=colormap)","532a943f":"df.columns","70a6c994":"# Rename some features\n\n# Remove the space after 'Vocal '\ndf = df.rename(columns = {'Vocal ':'Vocal'})\n\n# (Optional) Remove '_'\ndf = df.rename(columns = {'Artists_Genres':'ArtistsGenres', 'Release_year':'ReleaseYear', 'Album_type':'AlbumType'})\n\n# (Optional) Correct spelling mistakes\ndf = df.rename(columns = {'Dancebility':'Danceability'})\ndf.columns","84a13160":"# Let's see the categorical and numerical features\n\ncategorical_features = {\"Artists\",\"Track\",\"Version\",\"ArtistsGenres\",\"Album\",\"AlbumType\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\nnumerical_features = {\"Duration\",\"ReleaseYear\",\"BPM\",\"Energy\",\"Danceability\",\"Happiness\"}\ndisplay(df[categorical_features].head())\ndisplay(df[numerical_features].head())","4e943ae3":"# Let's check for some dependencies visually\nsns.pairplot(df[list(numerical_features)+[\"Category\"]],palette=colormap[2:4], hue=\"Category\")","f9ffd867":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","280db2c1":"# Let's check the missing value(s) in 'Artists'\ndf.loc[df['Artists'].isna()==True]","cec58e3a":"# We can drop this record as it has the least amount of parameters\ndf = df.drop([661])\ndf = df.reset_index(drop=True)\ndf.loc[df['Artists'].isna()==True]","d0eb5114":"# Let's check the missing value(s) in 'Album'\ndf.loc[df['Album'].isna()==True]","8f25c564":"# We replace it with 'none'\ndf[\"Album\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Album'].isna()==True]","5b1ea349":"# Let's check the missing value(s) in 'Vocal'\ndf.loc[df['Vocal'].isna()==True]","4e578213":"# We replace it with 'none'\ndf[\"Vocal\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Vocal'].isna()==True]","fd99a4ab":"# Let's check the missing value(s) in 'Country'\ndf.loc[df['Country'].isna()==True]","2c76c418":"# We replace it with 'none'\ndf[\"Country\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Country'].isna()==True]","d48db301":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Labels'].isna()]","f7d89073":"# We replace it with 'none'\ndf[\"Labels\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Labels'].isna()==True]","2e3d95de":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Version'].isna()]","6125d53f":"# We replace it with 'none'\ndf[\"Version\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Version'].isna()==True]","f60848df":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['AlbumType'].isna()]","08bad5d0":"# We replace it with 'none'\ndf[\"AlbumType\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['AlbumType'].isna()==True]","5fced6ba":"msno.bar(df, color=colormap)","7bfb0702":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which are only present in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique genre values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimensionality of the dataset.\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    \n    return embedded\n\ndef plot_cumulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation.\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=colormap[i+1])))\n    fig.show()","bfad9569":"# Let's see how the description\nprint(description[\"Country\"])","50ae1bca":"# We split to onehot vector and plot the countries\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_cumulative_onehot(country_onehot)","00994c8f":"# We drop the old column and replace it by the new onehot vector\ncountry_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop([\"Country\", \"none\"], axis=1)\ndf.head()","7ef98de1":"# Let's check what is in 'Vocal'\nprint(description[\"Vocal\"])","9fdb9cf3":"# Create a new array and split the vocal types\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\n        \n# We drop the old column and replace it by the new onehot vector\ndf[[\"FemaleVocal\",\"MaleVocal\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)\ndf.head()","ac0d059d":"# Let's check the key feature\ndescription[\"Key\"]","e7ce19a6":"# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","b2744beb":"# We correct some keys and replace them with the same value (C# = D\u266d, etc)\ndf[\"Major\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\n# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","501f4e72":"# We put the Major\/Minor part into new feature, to make it more easy for our model in the fitting process\ndf.loc[:,\"Major\"] = (df[\"Major\"]==\"Major\").astype(int)\n_df = df.groupby([\"Major\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"Major\", y=\"Track\",color=\"Category\", height=400, color_discrete_sequence=colormap[1:4])","bfee7796":"# Let's plot a full overview (key + major\/minor)\n_df = df.copy(deep=True)\n_df[\"Key_precise\"] = _df[\"Key\"] +\"_major:\"+ _df[\"Major\"].astype(str)\n_df = _df.groupby([\"Key_precise\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df, x=\"Key_precise\", y=\"Track\", color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","24e4097e":"# Replace the old column with our onehot vector\ndf[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)\ndf.head()","8c63bdd7":"# Check the description\nfor k in [\"Energy\",\"Happiness\",\"Dancebility\"]:\n    print(f\"{k}:{description[k]}\")","b7938ed5":"# Let's scale energy, happiness and danceabilty down proportionally\ndf[['Energy%', 'Happiness%', 'Danceability%']] = df[['Energy', 'Happiness', 'Danceability']].apply(lambda x: x\/sum(x), axis=1)\ndf = df.drop([\"Energy\", \"Danceability\", \"Happiness\"], axis=1)\ndf.head()","515d1fc0":"# Let's see how the feature is structured\nprint(description[\"Artists\"])","ec6e35f9":"# How many artists are there\nall_artists = []\nfor i in df.index:\n    all_artists.extend(df.loc[i, \"Artists\"].split(\"|\"))\nlen(set(all_artists))","f492aad3":"# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nrare_artists = Counter(all_artists)\nrare_artists = [k for k in rare_artists if rare_artists[k]<=threshold]\nlen(rare_artists)","fbbaa678":"# Drop all artists who are only in the test-set or the train-set\nin_train, in_test = [], []\nfor i in df.loc[train_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~train_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","5611b96a":"all_artists = list(set(all_artists) - set(rare_artists) - only_test - only_train)\nprint(len(all_artists))\nrare_artists = set(rare_artists) | only_test | only_train\nprint(len(rare_artists))","fe1af704":"# Create onehot vector for artists\nresult = []\ndef prune(x):\n    vector = np.zeros(len(all_artists)+1) # for rare artists\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_artists)):\n        vector[i]=1 if all_artists[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    result.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(result, columns = all_artists + [\"Others\"], index=df.index)\n\nonehot_artists","142a1f17":"# We drop the rare artists (Others) column, it's not really relevant.\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\n\n# Let's plot the artists\nonehot_artists[\"Category\"] = df[\"Category\"]\nplot_cumulative_onehot(onehot_artists)","aefbe472":"# Since there are too many features in the onehot vector, we will apply tsne (dimensionality reduction)\nartists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\n\n# Create scatterplot to visualize artists, now reduced to 2 tsne values\nxp.scatter(_df,x=\"Artists_tsne1\",y=\"Artists_tsne2\",color=\"Category\", hover_data=[\"Artists\"], height=500, color_discrete_sequence=colormap[1:4])","a1adf241":"# Replace the old artists column\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)\ndf.head()","93ba980d":"# Check what's in the feature\ndescription[\"Release year\"]","9723f00e":"# Let's create a scatterplot\nxp.scatter(df, x=\"ReleaseYear\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","762649d1":"# Let's create a decade feature, to detect some music of 80s, 90s etc. as a specific genre\ndf.loc[:,\"ReleaseDecade\"] = (df.loc[:,\"ReleaseYear\"]\/\/10 * 10)\n# Because of the small number of values, we will put all <80s values in the 80s genre\ndf.loc[df.loc[:,\"ReleaseDecade\"]<1990,\"ReleaseDecade\"] = 1980 \n_df = df.groupby([\"ReleaseDecade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"ReleaseDecade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=colormap[1:4])","2bc671b7":"# Create onehot vector with the decades\ndf[list(set(df[\"ReleaseDecade\"].values))] = OneHotEncoder().fit_transform(df[[\"ReleaseDecade\"]]).toarray()\ndf = df.drop([\"ReleaseDecade\", \"ReleaseYear\"], axis=1)\ndf.head()","eee77858":"# Let's see the description\nprint(description[\"Labels\"])","6cbaa75a":"# Split the lables into onehot vector\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_cumulative_onehot(labels_onehot)","7ff71bb9":"# Use tsne function to reduce dimensionality\nlabels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Labels_tsne1\",y=\"Labels_tsne2\",color=\"Category\", hover_data=[\"Labels\"], height=500, color_discrete_sequence=colormap)","aba0dff4":"# Replace old column\ndf = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)\ndf.head()","c961b85a":"# Read the description\ndescription[\"Artists Genres\"]","66277ce3":"# To onehot vector\ngenres_onehot = split_to_onehot(df, \"ArtistsGenres\")\nplot_cumulative_onehot(genres_onehot)","dc434629":"# We have too much values, so we reduce the dimensionality\ngenres_embedded = onehot_to_tsne2(genres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"ArtistsGenres\"]] = df[[\"Category\",\"ArtistsGenres\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Genres_tsne1\",y=\"Genres_tsne2\",color=\"Category\", hover_data=[\"ArtistsGenres\"], height=500, color_discrete_sequence=colormap)","99b8e408":"# Replace the old column\ndf = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"ArtistsGenres\", axis=1)\ndf.head()","0cc625c1":"# See description\nprint(description[\"Album\"])","5f482432":"# To onehot vector\nalbum_onehot = split_to_onehot(df, \"Album\")\nplot_cumulative_onehot(album_onehot)","2f9a1b59":"# Again, too much values, so reduce to 2 tsne values\nalbum_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\n_df = album_embedded.copy(deep=True)\n_df[[\"Category\",\"Album\"]] = df[[\"Category\",\"Album\"]]\n\n# Scatterplot\nxp.scatter(_df,x=\"Album_tsne1\",y=\"Album_tsne2\",color=\"Category\", hover_data=[\"Album\"], height=500, color_discrete_sequence=colormap)","033d3df0":"# Replace column\ndf = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)\ndf.head()","dd56bbb5":"# Check the description\nfor i in [\"Track\", \"Version\", \"Album_type\"]:\n    print(description[i])","efdc1632":"# We do not have features, so we use label encoder\ntrack_encoder = LabelEncoder()\ndf[\"Track\"] = track_encoder.fit_transform(df[\"Track\"])\ndf.head()","a8cf7e85":"# Let's see if there is a dependency\n_df = df.groupby([\"Version\",\"Category\"], as_index=False).count()\n\n# Plot a bar chart\nxp.bar(_df,x=\"Version\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","5c58f1ea":"# To onehot vector and replace column\nversions = set(df[\"Version\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop([\"Version\",\"none\"], axis=1)\ndf.head()","afe06be7":"# Let's see for any relevance\n_df = df.groupby([\"AlbumType\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"AlbumType\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","442d9d89":"# Create onehot vector and replace old column\nalbumTypes = set(df[\"AlbumType\"])\ndf[list(albumTypes)] = OneHotEncoder().fit_transform(df[[\"AlbumType\"]]).toarray()\ndf = df.drop([\"AlbumType\",\"none\"], axis=1)\ndf.head()","116131e5":"# Check the description\nfor k in [\"Duration\",\"BPM\"]:\n    print(f\"{k}:{description[k]}\")","dbd04d92":"# Let's see if there is a dependency\n_df = df.groupby([\"Duration\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"Duration\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","816f1e54":"# No dependency really, so we leave duration as it is\n# We drop the column\ndf.drop('Duration', axis=1, inplace=True)","8185bc18":"# Let's see if there is a dependency between BPM and (no) likes\n_df = df.groupby([\"BPM\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"BPM\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","aa54cf89":"# No dependency I guess, so we leave BPM as it is\n# We drop the column\ndf.drop('BPM', axis=1, inplace=True)","9cc2cb50":"df","ba31b40a":"df.info()","3333908d":"# Let's select our features\nfeatures = df.columns[2:]\ndummies = pd.get_dummies(df[features])\nx = dummies[:-370]\nx_acc = dummies[-370:-300]\nx_test = dummies[-300:]\n\ntrain_data = df[:-370]\ny = train_data['Category']\ntrain_data_acc = df[-370:-300]\ny_test = train_data_acc[\"Category\"]","d7ad8d64":"# Try different models\nmodel = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with RandomForest is: ', accuracy)\n\nmodel = AdaBoostClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with AdaBoost is: ', accuracy)\n\nmodel = GradientBoostingClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GradientBoosting is: ', accuracy)\n\nmodel = DecisionTreeClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with DecisionTree is: ', accuracy)\n\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with LinearDiscriminant is: ', accuracy)\n\nmodel = SVC()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with SupportVectorMachine: ', accuracy)\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with ExtraTrees: ', accuracy)\n\nmodel = MLPClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with MLPClassifier: ', accuracy)\n\nmodel = GaussianProcessClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GaussianProcess: ', accuracy)\n\nmodel = KNeighborsClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with KNeighbors: ', accuracy)\n\nmodel = CatBoostClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with CatBoost: ', accuracy)","6c0be133":"# RandomForest gives the best accuracy\n\nfinal_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nfinal_model.fit(x, y)\n\nsample = pd.read_csv(\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = final_model.predict(x_test)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample.to_csv(\".\/submission.csv\", index=False)","73f535b4":"**3.1 COUNTRY**","0d6eb137":"AlbumType","527e162b":"**3.4 ENERGY, HAPPINESS, DANCEABILITY**","c99afb4d":"Duration","f74bc9ec":"BPM","d7cfe03e":"**3.9 ALBUM**","987a9ce2":"**3.11 DURATION, BPM**","44e0d33c":"# **1. DATA ANALYSIS**","0fe967a7":"**3.2 VOCAL**","422355ba":"**3.7 LABELS**","1251644f":"Track","047c7460":"# **3. FEATURE ENGINEERING**","d1de80d6":"Version","64eaddaf":"**3.5 ARTISTS**  ","49a7ad8b":"**3.8 ARTISTS GENRES**","8bf9eb69":"**3.6 RELEASE YEAR**","1b642d74":"**3.3 KEY**","36823137":"***SOME USEFUL FUNCTIONS***","488f5670":"# **2. DATA PREPARATION**","44bfcc93":"# **4. MODEL SELECTION**","65477933":"**3.10 TRACK, VERSION, ALBUM TYPE**"}}