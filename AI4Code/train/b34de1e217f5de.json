{"cell_type":{"526af595":"code","abf349d1":"code","837b94dc":"code","0844c822":"code","df854cfc":"code","23acf0ae":"code","ef4249ff":"code","77057abb":"code","b64c8be1":"code","ca4e7f3a":"code","69c95ebc":"code","4b0a3e75":"code","fd503315":"code","d7cb6b6d":"code","a19cfb71":"code","a1145722":"code","769351d2":"markdown","39943dce":"markdown"},"source":{"526af595":"\nimport os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\nfrom pathlib import Path\n\n\nimport cv2\nfrom PIL import Image\nimport pdb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os \nfrom glob import glob\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","abf349d1":"data=pd.read_csv('..\/input\/train_ship_segmentations_v2.csv')","837b94dc":"data.head()","0844c822":"PATH='..\/input\/'","df854cfc":"train_imgs=os.listdir(PATH+'train_v2')\ntest_imgs=os.listdir(PATH+'test_v2')","23acf0ae":"masks = pd.read_csv(os.path.join('..\/input\/',\n                                 'train_ship_segmentations_v2.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks.head()","ef4249ff":"from sklearn.model_selection import train_test_split\nunique_img_ids = masks.groupby('ImageId').size().reset_index(name='counts')\ntrain_ids, valid_ids = train_test_split(unique_img_ids, \n                 test_size = 0.3, \n                 stratify = unique_img_ids['counts'])\ntrain_df = pd.merge(masks, train_ids)\nvalid_df = pd.merge(masks, valid_ids)\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')","77057abb":"train_imgs[:5]","b64c8be1":"test_imgs[:5]","ca4e7f3a":"data = data.reset_index()\ndata['ship_count'] = data.groupby('ImageId')['ImageId'].transform('count')\n","69c95ebc":"print(data['ship_count'].describe())","4b0a3e75":"df = df.ImageId()","fd503315":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        data_path = train_imgs\n    elif \"mask\" in image_type:\n        data_path = masks\n    elif \"Test\" in image_type:\n        data_path = test_imgs\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}\".format(image_id))\n\ndef get_image_data(image_id, image_type, **kwargs):\n    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    img = img.astype('uint8')\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n   \n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T ","d7cb6b6d":"sample = masks[~masks.EncodedPixels.isna()].sample(9)\n\nfig, ax = plt.subplots(3, 3, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 3\n    row = i \/\/ 3\n    \n    path = Path('..\/input\/train_v2') \/ '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","a19cfb71":"from skimage.filters import gaussian,laplace","a1145722":"ImageId = '0005d01c8.jpg'\n\nimg = imread('..\/input\/train_v2\/' + ImageId)\nimg_masks = masks.loc[masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n\n# Take the individual ship masks and create a single mask array for all ships\nall_masks = np.zeros((768, 768))\nfor mask in img_masks:\n    all_masks += rle_decode(mask)\n\nfig, axarr = plt.subplots(1, 3, figsize=(15, 40))\naxarr[0].axis('off')\naxarr[1].axis('off')\naxarr[2].axis('off')\naxarr[0].imshow(img)\naxarr[1].imshow(all_masks)\naxarr[2].imshow(img)\naxarr[2].imshow(all_masks, alpha=0.4)\nplt.tight_layout(h_pad=0.1, w_pad=0.1)\nplt.show()","769351d2":"**IMAGE TRANSFORMATION**\nLet's try to give contrast in a way to differentiate between ship and background.","39943dce":"Let's have a sneek peek into 9 images."}}