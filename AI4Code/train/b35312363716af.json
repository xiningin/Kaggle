{"cell_type":{"a3c14996":"code","5d0e8946":"code","c8af9624":"code","bf4717cf":"code","c4f28d04":"code","5c61137c":"code","3fe9e231":"code","30a27112":"code","ade512cf":"code","fde7acd1":"code","4d8c594e":"code","04e9c89e":"code","d8748475":"code","75a41163":"code","c7fa2eac":"code","b1c91e99":"code","d4d55081":"code","1e3950cf":"code","8e4d1012":"code","56e55736":"code","17e13101":"code","8ad15166":"code","960e8967":"code","44f1ae05":"code","0097655e":"code","d2a7a987":"code","fab941a9":"code","f926ef2f":"code","d4e17915":"code","6c3426d9":"code","8fc056a0":"code","92bac9cc":"code","1eab1f59":"code","6df9bafd":"code","c0224259":"code","f8c7a473":"code","ea837b9f":"code","472f2753":"code","d7451395":"code","04fc83c7":"code","94c1dfc9":"code","667c24d6":"code","e067c2d5":"code","82e5c7f2":"code","6875d4b7":"code","b3fe1d3b":"code","11195589":"code","e95388de":"code","a51afa95":"code","6bf35536":"code","d50648a5":"code","bd794ca6":"code","0c0b1da0":"code","32c519be":"code","99db5c68":"code","283e9aec":"code","ce8408d5":"code","718d2655":"code","d7449d81":"code","7ebe46d3":"code","e01c427b":"code","cea1146e":"code","c15a77f0":"code","0e0a017f":"code","5d301b16":"code","2f3b5af6":"code","f83abcb3":"code","85dc1ea9":"code","80bbb052":"code","4628772b":"code","258149d0":"code","0c8c1381":"code","8c3cdabe":"code","bb4c7189":"code","7970d84d":"code","a3d64268":"code","7b52ce83":"code","7d1943d3":"code","0047d1ee":"code","4ee34b46":"code","7c2a9608":"code","1f2e3b00":"code","437a57b0":"code","28a72eb1":"code","950cb847":"code","4a44f9ab":"code","34afd6b2":"code","44b560aa":"code","d8edffd5":"code","e7a52a4d":"code","865d42d9":"code","61b527c0":"code","ee6af27d":"code","4b9e0f65":"code","6a3968f7":"code","43c8770f":"code","55dc091f":"code","44e939a4":"code","cddded8e":"code","c38b1aff":"code","683edbc0":"code","f1cabd5d":"code","3af1582d":"code","1833543e":"code","da116a10":"code","d45dec91":"code","bb804780":"code","29a7fadf":"code","0a5b0d6e":"code","67d96e3b":"code","85403c6b":"code","039e8120":"markdown","55268855":"markdown","ec249994":"markdown","52ec77e2":"markdown","f142e386":"markdown","0e34c341":"markdown","ca8ed313":"markdown","ef7ad096":"markdown","a44e2e0d":"markdown","dcd7b4a2":"markdown","4c392c9c":"markdown","fd237646":"markdown","5646da48":"markdown","fc37675e":"markdown","6475329d":"markdown","67b3186c":"markdown","27e9dba6":"markdown","a4d2de95":"markdown","44901485":"markdown","8650a974":"markdown","6e0104db":"markdown","69a57906":"markdown","1de42665":"markdown","228f5a5a":"markdown","179a27f9":"markdown","2553d955":"markdown","994d7cb4":"markdown","36927570":"markdown","0bf2ad1c":"markdown","b5e58e6d":"markdown","d3e853a4":"markdown","5d2cad06":"markdown","71ea20b5":"markdown","5fa55f71":"markdown","a2f421cb":"markdown","20166a86":"markdown","12cb110c":"markdown","e3f4a79b":"markdown","1bd889fb":"markdown","2bb209ef":"markdown","7d6d14d7":"markdown","8d2ef242":"markdown","90207902":"markdown","c283da89":"markdown","227d201a":"markdown","266311f0":"markdown","0b2fc924":"markdown","ca441bd0":"markdown","02ee954c":"markdown","f5246534":"markdown","f2141b72":"markdown","893507a9":"markdown","1641d921":"markdown","38da8e96":"markdown","8b50e33e":"markdown","4e44cbbd":"markdown","22682918":"markdown","c5a01ed3":"markdown"},"source":{"a3c14996":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, PassiveAggressiveClassifier, RidgeClassifierCV, SGDClassifier, Perceptron\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import BernoulliNB, GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\n\nfrom bayes_opt import BayesianOptimization\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore') \n\n%matplotlib inline","5d0e8946":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head()","c8af9624":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","bf4717cf":"print(\"Train Dataset\")\nprint(\"Lines: {}\".format(train.shape[0]))\nprint(\"Columns: {}\".format(\", \".join(train.columns)))\n\nprint(\"\\n\\nTest Dataset\")\nprint(\"Lines: {}\".format(test.shape[0]))\nprint(\"Columns: {}\".format(\", \".join(test.columns)))","c4f28d04":"train.dtypes","5c61137c":"test.dtypes","3fe9e231":"train.describe()","30a27112":"test.describe()","ade512cf":"(train.isna().sum() \/ train.shape[0]) * 100","fde7acd1":"(test.isna().sum() \/ test.shape[0]) * 100","4d8c594e":"f, ax = plt.subplots(figsize = (14, 14))\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(\n    train[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr('pearson'), \n    cmap=colormap,\n    square=True, \n    cbar_kws={'shrink': .9}, \n    ax=ax,\n    annot=True, \n    linewidths=0.1, vmax=1.0, linecolor='white',\n    annot_kws={'fontsize': 10}\n)\n\nplt.title('Pearson Correlation of Train Dataset', y=1.05, size=15)","04e9c89e":"f, ax = plt.subplots(figsize = (14, 14))\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(\n    test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr('pearson'), \n    cmap=colormap,\n    square=True, \n    cbar_kws={'shrink': .9}, \n    ax=ax,\n    annot=True, \n    linewidths=0.1, vmax=1.0, linecolor='white',\n    annot_kws={'fontsize': 10}\n)\n\nplt.title('Pearson Correlation of Test Dataset', y=1.05, size=15)","d8748475":"data = [train, test]","75a41163":"train.drop('PassengerId', axis=1, inplace=True)\ntrain.head()","c7fa2eac":"fig, ax = plt.subplots()\n\nlabels = ['1', '2', '3']\n\nx = np.arange(len(labels))\nwidth = 0.35\n\nax.bar(x - width\/2, train.Pclass.value_counts().sort_index() \/ train.Pclass.count(), width, label='Train', color=\"green\")\nax.bar(x + width\/2, test.Pclass.value_counts().sort_index() \/ test.Pclass.count(), width, label='Test', color=\"green\", alpha=0.5)\n\nax.set_ylabel('% Ticket Class')\nax.set_title('Ticket Class Normalized')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nplt.show()","b1c91e99":"fig, ax = plt.subplots()\n\nlabels = ['1', '2', '3']\n\nx = np.arange(len(labels))\nwidth = 0.35\n\nax.bar(x - width\/2, train[train.Survived == 1].Pclass.value_counts().sort_index(), width, label='Survived')\nax.bar(x + width\/2, train[train.Survived == 0].Pclass.value_counts().sort_index(), width, label='Died')\n\nax.set_ylabel('Number of Ticket Class')\nax.set_title('Ticket Class vs Survived')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nplt.show()","d4d55081":"le = LabelEncoder()\nle.fit(train.Pclass)\n\nfor dataset in data:\n    dataset.Pclass = le.transform(dataset.Pclass)","1e3950cf":"train.Pclass.value_counts()","8e4d1012":"train.head()","56e55736":"train.Name.head(10)","17e13101":"for dataset in data:\n    dataset['Title'] = dataset.Name.str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]","8ad15166":"pd.crosstab(train.Title, train.Sex)","960e8967":"pd.crosstab(test.Title, test.Sex)","44f1ae05":"titles = [\"Master\", \"Miss\", \"Mr\", \"Royals\", \"Professionals\"]\n\nfor dataset in data:\n    dataset.Title = dataset.Title.replace(['Lady', 'the Countess', 'Countess', 'Don', 'Jonkheer', 'Dona', 'Sir'], 'Royals')\n    dataset.Title = dataset.Title.replace(['Col', 'Dr', 'Major', 'Capt'], 'Professionals')\n    dataset.Title = dataset.Title.replace([\"Ms\", \"Mme\", \"Mlle\", \"Mrs\"], 'Miss')\n    dataset.Title = dataset.Title.replace(['Master', 'Rev'], 'Mas\/Rev')\n    dataset.Title = dataset.Title.map({\"Mas\/Rev\": 0, \"Miss\": 1, \"Mr\": 2, \"Royals\": 3, \"Professionals\": 4})","0097655e":"train.Title.value_counts()","d2a7a987":"sns.factorplot(x=\"Title\", y=\"Survived\", data=train, kind=\"bar\").set_xticklabels(titles).set_ylabels(\"Survival Probability\")","fab941a9":"for dataset in data:\n    dataset.drop('Name', axis=1, inplace=True)","f926ef2f":"h = sns.FacetGrid(train, row=\"Title\", hue=\"Survived\")\nh.map(plt.hist, 'Age', alpha=.75)\nh.add_legend()","d4e17915":"train.head()","6c3426d9":"fig, ax = plt.subplots()\n\nlabels = ['female', 'male']\n\nx = np.arange(len(labels))\nwidth = 0.35\n\nax.bar(x - width\/2, train.Sex.value_counts().sort_index() \/ train.Sex.count(), width, label='Train', color=\"green\")\nax.bar(x + width\/2, test.Sex.value_counts().sort_index() \/ test.Sex.count(), width, label='Test', color=\"green\", alpha=0.5)\n\nax.set_ylabel('% Sex')\nax.set_title('Sex Normalized')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nplt.show()","8fc056a0":"sns.factorplot(x=\"Sex\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","92bac9cc":"h = sns.FacetGrid(train, row='Sex', col='Pclass', hue='Survived')\nh.map(plt.hist, 'Age', alpha=.75)\nh.add_legend()","1eab1f59":"for dataset in data:\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1})","6df9bafd":"train.head()","c0224259":"train.Age.isna().sum() \/ train.shape[0]","f8c7a473":"test.Age.isna().sum() \/ test.shape[0]","ea837b9f":"min(train.Age), max(train.Age)","472f2753":"min(test.Age), max(test.Age)","d7451395":"a = sns.FacetGrid(train, hue='Survived', aspect=4)\na.map(sns.kdeplot, 'Age', shade=True)\na.set(xlim=(0, train['Age'].max()))\na.add_legend()","04fc83c7":"g = sns.factorplot(y=\"Age\",x=\"Sex\",data=train, kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Pclass\", data=train, kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Parch\", data=train, kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"SibSp\", data=train, kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Title\", data=train, kind=\"box\")","94c1dfc9":"train[train.Age.isna()].Title.value_counts()","667c24d6":"def fill_age_missing_values(df):\n    age_null = list(df[df[\"Age\"].isnull()].index)\n\n    for index in age_null:\n        temp_Pclass = df.iloc[index][\"Pclass\"]\n        temp_SibSp = df.iloc[index][\"SibSp\"]\n        temp_Parch = df.iloc[index][\"Parch\"]\n        temp_Title = df.iloc[index][\"Title\"]\n        \n        age_median = df[\"Age\"][(\n            (df[\"Pclass\"] == temp_Pclass) & \n            (df[\"Pclass\"] == temp_Pclass) & \n            (df[\"SibSp\"] == temp_SibSp) & \n            (df[\"Parch\"] == temp_Parch) & \n            (df[\"Title\"] == temp_Title)\n        )].median()\n        \n        df[\"Age\"].iloc[index] = age_median if (df.iloc[index][\"Age\"] == True) and (np.isnan(age_median) == False) else df[\"Age\"].median()\n    return df","e067c2d5":"for dataset in data:\n    dataset = fill_age_missing_values(dataset)","82e5c7f2":"train.Age.isna().sum(), test.Age.isna().sum()","6875d4b7":"train[train.Age < 1].Survived.mean()","b3fe1d3b":"age_groups = ['Baby',  'Child', 'Young Adult', 'Adult', 'Senior']\n\nfor dataset in data:\n    dataset.loc[(dataset['Age'] <= 2), 'Age Group'] = 0\n    dataset.loc[((dataset[\"Age\"] > 2) & (dataset['Age'] <= 10)), 'Age Group'] = 1 \n    dataset.loc[((dataset[\"Age\"] > 10) & (dataset['Age'] <= 19)), 'Age Group'] = 2\n    dataset.loc[((dataset[\"Age\"] > 19) & (dataset['Age'] <= 60)), 'Age Group'] = 3\n    dataset.loc[(dataset[\"Age\"] > 60), 'Age Group'] = 4\n    \n    dataset[\"Age\"] = dataset[\"Age\"].astype(int)\n    dataset[\"Age Group\"] = dataset[\"Age Group\"].astype(int)","11195589":"sns.factorplot(x=\"Age Group\", y=\"Survived\", data=train, kind=\"bar\").set_xticklabels(age_groups).set_ylabels(\"Survival Probability\")","e95388de":"train.head()","a51afa95":"sns.factorplot(x=\"SibSp\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","6bf35536":"train[train.SibSp > 4].Survived.mean()","d50648a5":"train[train.SibSp > 4]","bd794ca6":"sns.factorplot(x=\"Parch\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","0c0b1da0":"train[train.Parch > 5].Survived.mean()","32c519be":"train[train.Parch > 5]","99db5c68":"for dataset in data:\n    dataset['Family'] = dataset.SibSp + dataset.Parch","283e9aec":"sns.factorplot(x=\"Family\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","ce8408d5":"train.head()","718d2655":"test.head()","d7449d81":"test.Fare.isna().sum()","7ebe46d3":"test[test.Fare.isna()]","e01c427b":"test.loc[test.Fare.isna(), 'Fare'] = test[test.Pclass == 3].Fare.mean()","cea1146e":"sns.distplot(train[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(train[\"Fare\"].skew())).legend(loc=\"best\")","c15a77f0":"sns.distplot(test[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(test[\"Fare\"].skew())).legend(loc=\"best\")","0e0a017f":"min(train.Fare), min(test.Fare)","5d301b16":"for dataset in data:\n    dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda x: np.log(x) if x > 0 else 0)","2f3b5af6":"sns.distplot(train[\"Fare\"], color=\"g\", label=\"Skewness : %.2f\"%(train[\"Fare\"].skew())).legend(loc=\"best\")","f83abcb3":"sns.distplot(test[\"Fare\"], color=\"g\", label=\"Skewness : %.2f\"%(test[\"Fare\"].skew())).legend(loc=\"best\")","85dc1ea9":"train.head()","80bbb052":"train.Cabin.isna().sum() \/ train.shape[0]","4628772b":"for dataset in data:\n    dataset.Cabin.fillna(\"U\", inplace=True)\n    dataset.Cabin = dataset.Cabin.apply(lambda x: x.split(\" \")[-1][0] if len(x) > 0 else \"U\")","258149d0":"train.Cabin.value_counts()","0c8c1381":"test.Cabin.value_counts()","8c3cdabe":"print(\"Survival rate (%)\")\nprint(\"With Cabin: {:.2f}\".format(train[train.Cabin != \"U\"].Survived.sum() \/ train[train.Cabin != \"U\"].shape[0]))\nprint(\"Without Cabin: {:.2f}\".format(train[train.Cabin == \"U\"].Survived.sum() \/ train[train.Cabin == \"U\"].shape[0]))","bb4c7189":"h = sns.FacetGrid(train[train.Cabin != \"U\"])\nh.map(plt.hist, \"Pclass\", alpha=0.75)","7970d84d":"sns.factorplot(x=\"Cabin\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","a3d64268":"for dataset in data:\n    dataset.Cabin = dataset.Cabin.map({'U': 0, 'T': 0, 'G': 1, 'A': 2, 'C': 3, 'B': 4, 'D': 5, 'E': 6, 'F': 7})","7b52ce83":"sns.factorplot(x=\"Cabin\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","7d1943d3":"train.head()","0047d1ee":"train.Embarked.isna().sum()","4ee34b46":"train[train.Embarked.isna()]","7c2a9608":"train.loc[train.Embarked.isna(), 'Embarked'] = train.Embarked.mode()[0]","1f2e3b00":"sns.factorplot(x=\"Embarked\", y=\"Survived\", data=train, kind=\"bar\").set_ylabels(\"Survival Probability\")","437a57b0":"sns.factorplot(\"Pclass\", col=\"Embarked\",  data=train, size=6, kind=\"count\")","28a72eb1":"for dataset in data:\n    dataset.Embarked = dataset.Embarked.map({\"C\": 2, \"Q\": 1, \"S\": 0})","950cb847":"train.head()","4a44f9ab":"for dataset in data:\n    dataset.drop(columns=['Parch', 'SibSp', 'Ticket', 'Age'], inplace=True)","34afd6b2":"train.head()","44b560aa":"train.Survived.value_counts()","d8edffd5":"train.Survived.mean()","e7a52a4d":"f, ax = plt.subplots(figsize = (15, 15))\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(\n    train.corr('pearson'), \n    cmap=colormap,\n    square=True, \n    cbar_kws={'shrink': .8}, \n    ax=ax,\n    annot=True, \n    linewidths=0.1, vmax=1.0, linecolor='white',\n    annot_kws={'fontsize': 9}\n)\n\nplt.title('Pearson Correlation of Features', y=1.05, size=15)","865d42d9":"train = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"])\ntrain = pd.get_dummies(train, columns = [\"Pclass\"])\ntrain = pd.get_dummies(train, columns = [\"Age Group\"])","61b527c0":"train.head()","ee6af27d":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"])\ntest = pd.get_dummies(test, columns = [\"Pclass\"])\ntest = pd.get_dummies(test, columns = [\"Age Group\"])","4b9e0f65":"test.head()","6a3968f7":"preds = list(train.columns)\npreds.remove('Survived')\npreds.remove('Cabin')\npreds","43c8770f":"X_train = train[preds]\ny_train = train.Survived\n\nX_test = test[preds]","55dc091f":"scaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n\n# X_train_scaled = X_train\n# X_test_scaled = X_test","44e939a4":"importances = []\nfor i in range(10):\n    rf = RandomForestClassifier()\n    rf.fit(X_train_scaled, y_train)\n    if len(importances) > 0:\n        importances = [x + y for x, y in zip(importances, rf.feature_importances_)]\n    else:\n        importances = rf.feature_importances_\n\nimportances = [x \/ 10 for x in importances]","cddded8e":"importances = pd.DataFrame({'feature': preds, 'importance':importances})\nimportances","c38b1aff":"importances.sort_values('importance', ascending=False, inplace=True)","683edbc0":"acc = []\nfor i in importances.importance.values:\n    acc.append(i + acc[-1] if len(acc) > 0 else i)\nimportances['acc'] = acc\nimportances","f1cabd5d":"importances.set_index('feature', drop=True, inplace=True)","3af1582d":"fig, ax = plt.subplots()\n\nax.bar(importances.index, importances.importance)\nax.plot(importances.index, importances.acc, '--', color=\"red\")\nax.set_ylabel('Importance')\nax.set_title('Feature Importances')\nplt.xticks(rotation=90)\n\nplt.show()","1833543e":"MODELS = [\n    #Ensemble Methods\n    AdaBoostClassifier(),\n    BaggingClassifier(),\n    ExtraTreesClassifier(),\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n\n    #Gaussian Processes\n    GaussianProcessClassifier(),\n    \n    #GLM\n    LogisticRegressionCV(),\n    PassiveAggressiveClassifier(),\n    RidgeClassifierCV(),\n    SGDClassifier(),\n    Perceptron(),\n    \n    #Navies Bayes\n    BernoulliNB(),\n    GaussianNB(),\n    \n    #Nearest Neighbor\n    KNeighborsClassifier(),\n    \n    #SVM\n    SVC(probability=True),\n    NuSVC(probability=True),\n    LinearSVC(),\n    \n    #Trees    \n    DecisionTreeClassifier(),\n    ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n\n    #xgboost\n    XGBClassifier()    \n]\n\nk_fold = StratifiedKFold(n_splits=5)\n\ncolumns = ['Model Name', 'Parameters','Train Accuracy Mean', 'Test Accuracy Mean', 'Test Accuracy STD * 3', 'Model', 'Time']\nmodels = pd.DataFrame(columns=columns)\n\nrow_index = 0\nfor ml in MODELS:\n    model_name = ml.__class__.__name__\n    models.loc[row_index, 'Model Name'] = model_name\n    models.loc[row_index, 'Parameters'] = str(ml.get_params())\n    \n    cv_results = cross_validate(ml, X_train_scaled, y_train, n_jobs=4, cv=k_fold, return_train_score=True, return_estimator=True)\n\n    models.loc[row_index, 'Time'] = cv_results['fit_time'].mean()\n    models.loc[row_index, 'Train Accuracy Mean'] = cv_results['train_score'].mean()\n    models.loc[row_index, 'Test Accuracy Mean'] = cv_results['test_score'].mean()\n    models.loc[row_index, 'Test Accuracy STD * 3'] = cv_results['test_score'].std() * 3\n    models.loc[row_index, 'Model'] = cv_results['estimator']\n    \n    row_index+=1\n\nmodels.sort_values(by=['Test Accuracy Mean'], ascending=False, inplace=True)\nmodels.reset_index(drop=True, inplace=True)\nmodels","da116a10":"sns.barplot(x='Test Accuracy Mean', y='Model Name', data=models, color='m')\n\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","d45dec91":"# 77% accuracy\ntop_k_models = 5\n\ny_test = []\nfor i in range(top_k_models):\n    preds = []\n    for ml in models.loc[i, 'Model']:\n        preds = [x + y for x, y in zip(ml.predict(X_test_scaled), preds)] if len(preds) > 0 else ml.predict(X_test_scaled)\n    \n    preds = [x\/len(models.loc[i, 'Model']) for x in preds]\n    y_test = [x + y for x, y in zip(preds, y_test)] if len(y_test) > 0 else preds\n\ny_test = [x\/top_k_models for x in y_test]\ny_test = [1 if x >= .5 else 0 for x in y_test]\n\ntest['Survived'] = y_test\nprint('Survival rate: {}'.format(test['Survived'].mean()))\n\n# test[['PassengerId', 'Survived']].to_csv('submission.csv', index=None)","bb804780":"gbc = GradientBoostingClassifier()\n\nparam_grid = {\n    \"max_depth\": [1, 3, 5, 7, None],\n    \"min_samples_split\": [2, 3, 10],\n    \"min_samples_leaf\": [1, 3, 10],\n    \"n_estimators\" :[100, 200, 300]\n}\n\ngridcv = GridSearchCV(gbc, param_grid = param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n\ngridcv.fit(X_train, y_train)\n\ngbc_best = gridcv.best_estimator_\n\n# Best Accuracy Score\ngridcv.best_score_","29a7fadf":"xgb = XGBClassifier()\n\nparam_grid = {\n    'gamma': [i\/10.0 for i in range(0,5)],\n    'subsample': [i\/10.0 for i in range(6,10)],\n    'colsample_bytree': [i\/10.0 for i in range(6,10)],\n    'reg_alpha': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1]\n}\n\ngridcv = GridSearchCV(xgb, param_grid = param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n\ngridcv.fit(X_train, y_train)\n\nxgb_best = gridcv.best_estimator_\n\n# Best Accuracy Score\ngridcv.best_score_","0a5b0d6e":"rfc = RandomForestClassifier()\n\nparam_grid = {\n    \"max_depth\": [None],\n    \"max_features\": [1, 3, 10],\n    \"min_samples_split\": [2, 3, 10],\n    \"min_samples_leaf\": [1, 3, 10],\n    \"bootstrap\": [False],\n    \"n_estimators\" :[100, 200, 300],\n    \"criterion\": [\"entropy\"]\n}\n\ngridcv = GridSearchCV(rfc, param_grid = param_grid, cv=k_fold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n\ngridcv.fit(X_train, y_train)\n\nrfc_best = gridcv.best_estimator_\n\n# Best Accuracy Score\ngridcv.best_score_","67d96e3b":"best_estimator = rfc_best\nbest_estimator.fit(X_train, y_train)\n\ntest['Survived'] = best_estimator.predict(X_test)\ntest[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)","85403c6b":"test.Survived.mean()","039e8120":"### 3.2 Ticket class","55268855":"Getting predictions for the 5 best models.","ec249994":"The test set has 1 row with null Fare.","52ec77e2":"### 6.3 Submitting","f142e386":"Let's fill this null value with the mean of 3rd class tickets.","0e34c341":"Split the Fare in four groups","ca8ed313":"#### Siblings and spouses aboard.","ef7ad096":"We can see a drop in the survival rate for passenger alone in the ship.","a44e2e0d":"#### Defining Final Features","dcd7b4a2":"### 3.3 Name","4c392c9c":"Nobody with more than 5 parents aboard has survived, but we only have one observation, so we can't conclude anything.","fd237646":"#### Creating Family Size","5646da48":"77,51% of accuracy in Kaggle test set.","fc37675e":"The distributions of cabin id seems to be the same among the both datasets","6475329d":"The two dataset has the same data types.","67b3186c":"#### Scaling","27e9dba6":"#### Fare distribution","a4d2de95":"Nobody with more than 4 number of sibling and\/or spouses aboard has survided","44901485":"All the babies has survived.","8650a974":"## 6. Modelling","6e0104db":"#### Random Forest","69a57906":"### 3.9 Embarked","1de42665":"## 4. Target","228f5a5a":"## 3. Data Analysis and Feature Engineering","179a27f9":"### 3.6 Family Size","2553d955":"The age has 19% of null values in the training set and 20% in the test set.","994d7cb4":"These null values can mean two things:\n1. Problem with the data, lost fields.\n2. Not everyone got a seperated cabin, thus the cabins that got registreds belong to higher socio economic class.\n\nLet's investigate the second assumption by correlation the cabin with the pclass.","36927570":"#### Importances","0bf2ad1c":"### 2.2 Data Types","b5e58e6d":"Queenstown(Q) has almost exclusively Pclass = 3 passengers  \nSouthampton(S) has a majority of Pclass = 3 passengers  \nCherbourg(C) has a majority of Pclass = 1 passengers  ","d3e853a4":"### 3.10 Removing non-essential features","5d2cad06":"### 2.3 Data Info\n\n**Describe**","71ea20b5":"#### Description\n**PassengerId**  \nUnique per passenger.\n\n**Survived (Target)**  \nIf a passenger has survived or not.\n\n**Pclass**  \nOrdinal datatype for the ticket class, a proxy for socio-economic status.  \n1 = upper class.  \n2 = middle class.  \n3 = lower class.\n\n**Name**  \nPassenger name. This variable is a nominal datatype. \nIt could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like master, makes a difference.\n\n**Sex**  \nIf the passenger is male or female.\n\n**Age**  \nHow old are the passengers. Perhaps childreen has a higher chance of survival.\n\n**SibSp**  \nNumber of related siblings or spouse aboard.\n\n**Parch**   \nNumber of related parents or children aboard. \n\n**Ticket**  \nIt's supposed to be unique per passenger. Perhaps we can use the ticket to fill some null values in others features.\n\n**Fare**  \nThe price of the ticket. Like the pclass, we can use this feature for socio-economic relationships.\nThe test set has null values.\n\n**Cabin**  \nThe cabin where the passenger were. \nThe cabin is composed by a letter followed by a number sequence.\nThe letters represent the deck. Even though this column has the higher number of null values, we can extract the letter and see if there is some correlations.\n\n**Embarked**  \nThe port where the passenger has embarked.\nThe train set has null values.","5fa55f71":"## 1. Importing Libraries","a2f421cb":"**Correlation**","20166a86":"### 3.1 Passanger ID\n\nThe passenger ids are of no use for us, because is a unique value for each passenger.\nWe're not gonna drop from the test set because we need to submit the predictions.","12cb110c":"### 3.4 Sex","e3f4a79b":"Passengers that embarked from Cherbourg(C), have the highest survival rate at almost 55%.  \nPassengers that embarked from Queenstown(Q), have a 40% survical rate.  \nPassengers that embarked from Southampton(S), have the lowest survival rate at just over 30%.  \n\nLet's check the correlation between the Pclass and the Embarked","1bd889fb":"## 5. Final Features","2bb209ef":"### 6.2 Hyper Parameter Tunning","7d6d14d7":"The Fare is highly skewed, let's apply a log function to tackle reduce the skewness.","8d2ef242":"### 3.8 Cabin","90207902":"#### Correlations","c283da89":"**Null Values**","227d201a":"### 3.7 Passenger Fare","266311f0":"77,03% of accuracy in Kaggle test set.","0b2fc924":"# Titanic: Machine Learning from Disaster\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).","ca441bd0":"#### Gradient Boosting","02ee954c":"### 6.1 Model Exploration","f5246534":"#### Parents and childreen aboard","f2141b72":"80,86% of accuracy in Kaggle test set.","893507a9":"One approach is to fill the null values with the median per title.","1641d921":"#### XGBoost","38da8e96":"#### One Hot Encoding","8b50e33e":"Brendalf,\n#StayHome.","4e44cbbd":"### 3.5 Age","22682918":"## 2. Data\n\n### 2.1 Importing Data","c5a01ed3":"The name of the passenger is not important to us. But we can derived the socio-economic status from the passenger's title."}}