{"cell_type":{"df78cf2c":"code","fefbe9aa":"code","ca9b8279":"code","7414cb60":"code","096eff89":"code","866f96cf":"code","d0f07a77":"code","1ceb76a4":"code","ced1e4d8":"code","283f2276":"code","d764e3e5":"code","c0c16c07":"code","841a4103":"code","3572f468":"code","5f7d4d33":"code","b215ee3d":"code","7c4482ce":"code","8b41c346":"code","4e9d9f6f":"code","d7c0cde9":"code","7594bb3d":"code","51c7681f":"code","4bc1481d":"code","a57b88d0":"code","b7999586":"code","703cedea":"code","bc07a013":"code","6cab12fd":"code","b3e79c7c":"code","86eafced":"code","742f95ec":"code","edb92f08":"code","eb316af2":"code","f0401689":"code","2a1f75ce":"code","2b039397":"code","41e00694":"code","04b935d0":"code","0623c85d":"code","07de7aec":"code","8ab4a33e":"markdown","daedcbc0":"markdown","5dad936b":"markdown","d733e97f":"markdown","2669166a":"markdown","376577ef":"markdown","7d633f4f":"markdown","54c9dbaf":"markdown","6f33a15b":"markdown","debbbdbe":"markdown","e2070671":"markdown","790538fc":"markdown","42581bb1":"markdown","cdf02419":"markdown","c56b27a3":"markdown","d5ca2567":"markdown","7e29e704":"markdown","198ffcbc":"markdown","4631a0af":"markdown","9d5a40ed":"markdown","a170ce5a":"markdown","4df34345":"markdown","d887a418":"markdown","69c7796b":"markdown","a7ddc603":"markdown","a4f48879":"markdown","d4e0ee0f":"markdown","b77158c2":"markdown","a0bcb7be":"markdown","6c53ef4a":"markdown"},"source":{"df78cf2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fefbe9aa":"df = pd.read_csv('\/kaggle\/input\/fifa19\/data.csv', index_col=0)\ndf","ca9b8279":"# removing unwanted columns\ncol_remove = ['Photo', 'Flag', 'Club Logo', 'Special', 'Real Face', 'Jersey Number', 'Joined', 'Loaned From', 'Contract Valid Until']\ndf.drop(columns=col_remove, inplace=True)\n# converting Values and Wages into floats\ndf['Value'].replace({'[\u20ac]':'', '.5M':'500000', 'M':'000000', 'K':'000'}, regex=True, inplace=True)\ndf['Wage'].replace({'[\u20ac]':'', 'K':'000'}, regex=True, inplace=True)\ndf['Value'] = df['Value'].astype('float64')\/1000000\ndf['Wage'] = df['Wage'].astype('float64')\/1000\ndf = df.rename(columns={'Value':'Value(\u20acM)', 'Wage':'Wage(\u20acK)'})\ndf","7414cb60":"df.describe()","096eff89":"sns.set_style('whitegrid', {'axes.facecolor':'darkgrey', 'patch.edgecolor': 'black'})\nsns.set_context('talk', font_scale=1.9)\nplt.figure(figsize=(32,10))\npos_count = sns.countplot(data=df, x='Position', hue='Preferred Foot', order=df['Position'].value_counts().index, \n                          palette={'Left':'red', 'Right':'aquamarine'}, saturation=1)\nplt.legend(markerscale=2, fontsize=20)\npos_count.set_title('Number of Players by Position and Preferred Foot')\nsns.despine(top=True, right=True)","866f96cf":"sns.set_context('paper', font_scale=2.8)\nplt.figure(figsize=(32,18))\nnat_count = sns.countplot(data=df, y='Nationality', order=df['Nationality'].value_counts()[:20].index, palette='hsv')\nnat_count.set_title('Top 20 Nationalities with the Highest Number of Players')\nplt.show()","d0f07a77":"club_gdf = df.groupby(['Club'], sort=True)\nwage_gdf = club_gdf['Wage(\u20acK)'].sum().sort_values(ascending=False)[:20]\nsns.set_style({'figure.facecolor':'white', 'axes.facecolor':'darkgrey'})\nplt.figure(figsize=(30,18))\npalette = {'Real Madrid':'w', 'FC Barcelona':'darkblue', 'Manchester City':'aquamarine', 'Manchester United':'r', 'Juventus':'black', 'Chelsea':'b', 'Liverpool':'firebrick', 'Tottenham Hotspur':'w', \n           'Arsenal':'r', 'Paris Saint-Germain':'darkblue', 'FC Bayern M\u00fcnchen':'darkred', 'Everton':'b', 'Milan':'darkred', 'Napoli':'c', 'West Ham United':'indigo', 'Inter':'navy', 'Atl\u00e9tico Madrid':'w', \n           'Leicester City':'b', 'Roma':'orange','Borussia Dortmund':'yellow'}\nwage_plt = sns.barplot(y=wage_gdf.index, x=wage_gdf, palette=palette)\nwage_plt.set_title('Top 20 Clubs with Highest Wages')\nplt.show()","1ceb76a4":"value_gdf = club_gdf['Value(\u20acM)'].sum().sort_values(ascending=False)[:20]\nplt.figure(figsize=(30,18))\npalette = {'Real Madrid':'w', 'FC Barcelona':'darkblue', 'Manchester City':'aquamarine', 'Manchester United':'r', 'Juventus':'black', 'Chelsea':'b', 'Liverpool':'firebrick', 'Tottenham Hotspur':'w', \n           'Arsenal':'r', 'Paris Saint-Germain':'darkblue', 'FC Bayern M\u00fcnchen':'darkred', 'Valencia CF':'orange', 'Milan':'darkred', 'Napoli':'c', 'Lazio':'lightblue', 'Inter':'navy', 'Atl\u00e9tico Madrid':'crimson', \n           'FC Porto':'b', 'Bayer 04 Leverkusen':'orange','Borussia Dortmund':'yellow'}\nvalue_plt = sns.barplot(y=value_gdf.index, x=value_gdf, palette=palette)\nvalue_plt.set_title('Top 20 Clubs with Most Expensive Squad')\nplt.show()","ced1e4d8":"ovl_gdf = club_gdf['Overall'].median().sort_values(ascending=False)[:20]\nplt.figure(figsize=(30,18))\npalette = {'Real Madrid':'w', 'FC Barcelona':'darkblue', 'Manchester City':'aquamarine', 'Manchester United':'r', 'Juventus':'black', 'Chelsea':'b', 'Liverpool':'firebrick', 'Tottenham Hotspur':'w', \n           'Arsenal':'r', 'Paris Saint-Germain':'darkblue', 'FC Bayern M\u00fcnchen':'darkred', 'Roma':'orange', 'Milan':'darkred', 'Napoli':'c', 'FC Porto':'lightblue', 'Inter':'navy', 'Atl\u00e9tico Madrid':'crimson', \n           'Sevilla FC':'b', 'Real Betis':'orange','Borussia Dortmund':'yellow', 'SL Benfica':'salmon', 'Sporting CP':'green', 'Bayer 04 Leverkusen':'orange', 'Lazio':'lightblue'}\nax = plt.gca(xlim=(75,85)) # for setting the axes limits\novl_plt = sns.barplot(y=ovl_gdf.index, x=ovl_gdf, palette=palette, ax=ax)\novl_plt.set_title('Top 20 Clubs with Median Squad Overall')\nplt.show()","283f2276":"pot_gdf = club_gdf['Potential'].mean().sort_values(ascending=False)[:20]\nplt.figure(figsize=(30,18))\npalette = {'Real Madrid':'w', 'FC Barcelona':'darkblue', 'Manchester City':'aquamarine', 'Manchester United':'r', 'Juventus':'black', 'Chelsea':'b', 'Liverpool':'firebrick', 'Tottenham Hotspur':'w', \n           'Arsenal':'r', 'Paris Saint-Germain':'darkblue', 'FC Bayern M\u00fcnchen':'darkred', 'Roma':'orange', 'Milan':'darkred', 'Napoli':'c', 'FC Porto':'lightblue', 'Inter':'navy', 'Atl\u00e9tico Madrid':'crimson', \n           'Sevilla FC':'b', 'Real Betis':'orange','Borussia Dortmund':'yellow', 'SL Benfica':'salmon', 'Sporting CP':'green', 'Bayer 04 Leverkusen':'orange', 'Lazio':'lightblue', 'Olympique Lyonnais':'blue',\n           'Valencia CF':'yellow'}\nax = plt.gca(xlim=(80,86)) # for setting the axes limits\npot_plt = sns.barplot(y=pot_gdf.index, x=pot_gdf, palette=palette, ax=ax)\npot_plt.set_title('Top 20 Clubs with Mean Potential Rating')\nplt.show()","d764e3e5":"plt.figure(figsize=(30,18))\nage_ovrl_viol = sns.violinplot(data=df, x='Age', y='Overall', scatter=False, palette='cool', scale='count', linewidth=1.5)\nage_ovrl_viol.set_title('Violin Plot - Age vs Overall - with Relative Sample Size (thickness)')\nplt.show()","c0c16c07":"ovl_pot_df = pd.concat([df['Overall'], df['Potential']], axis=1)\novl_pot_df.index = df['Age']\nsns.set_style('whitegrid', {'figure.facecolor':'white', 'axes.facecolor': 'darkgrey'})\nplt.figure(figsize=(30,18))\nax = plt.gca(xlim=(20,35), ylim=(60,75)) # for setting the axes limits\nregplt = sns.lineplot(data=ovl_pot_df, ax=ax, palette='afmhot_r')\nregplt.set_title('Convergence of Potential and Overall Rating')\nplt.show()","841a4103":"valuation_df = pd.concat([df['Overall'], df['Value(\u20acM)']], axis=1)\nfree_agents = valuation_df['Value(\u20acM)'] == 0\nvaluation_df.drop(index=valuation_df[free_agents].index, inplace=True)","3572f468":"plt.figure(figsize=(30,18))\nreg_plot = sns.regplot(data=valuation_df, x='Overall', y='Value(\u20acM)', order=3, scatter_kws={'s':80, 'color':(1,0,0)})\nreg_plot.set_title('Value vs Overall Regression Plot')\nplt.show()","5f7d4d33":"plt.figure(figsize=(30,18))\nreg_plot = sns.regplot(data=df, x='Overall', y='Wage(\u20acK)', order=3, scatter_kws={'s':80, 'color':(1,1,0)})\nreg_plot.set_title('Wage vs Overall Regression Plot')\nplt.show()","b215ee3d":"# cleaning missing values\ndf.dropna(axis='index', how='any', subset=df.columns[44:-1], inplace=True)","7c4482ce":"plt.figure(figsize=(28,25))\nsns.set_style('darkgrid', {'figure.facecolor':'grey'})\nht_map_attr = sns.heatmap(data=df[df.columns[1:]].corr(method='spearman'), linewidth=1, linecolor='w', cmap='hot_r')\nht_map_attr.set_title('Spearman Correlation Heatmap between Attributes')\nplt.show()","8b41c346":"# merging pos and attributes\nheatmap_row = pd.DataFrame(df['Position']) \nheatmap_col = df[df.columns[44:-1]] \nheatmap_df = heatmap_row.join(heatmap_col)\n# removing missing rows\nheatmap_df.replace(\"\", np.nan, inplace=True)\nheatmap_df.dropna(axis='index', inplace=True) \n# simplifying position mapping\npos_map = {'LS':'ST', 'RS':'ST', 'CF':'ST', 'RF':'ST', 'LF':'ST', 'LAM':'CAM', 'RAM':'CAM', 'LCM':'CM', 'RCM':'CM', \n           'LDM':'CDM', 'RDM':'CDM', 'RCB':'CB', 'LCB':'CB', 'RWB':'RB', 'LWB':'LB'}\nheatmap_df['Position'].replace(pos_map, inplace=True)\n# finding the median values for every pos\ngb_pos = heatmap_df.groupby(['Position'], sort=True)\n# plotting the heatmap\nplt.figure(figsize=(35,12))\nhtmap_pos_attr = sns.heatmap(data=gb_pos.median(), annot=gb_pos.median().values, cmap='magma_r')\nhtmap_pos_attr.set_title('Heatmap of Attributes (Median) for Every Position')\nplt.show()","4e9d9f6f":"heatmap_df","d7c0cde9":"plt.figure(figsize=(28,18))\nfor i in heatmap_df.columns[1:10]:\n    sns.distplot(df[i], hist=False, label=i, kde_kws={'linewidth':4}, axlabel='Rating')","7594bb3d":"plt.figure(figsize=(28,18))\nfor i in heatmap_df.columns[10:20]:\n    sns.distplot(df[i], hist=False, label=i, kde_kws={'linewidth':4}, axlabel='Rating')","51c7681f":"plt.figure(figsize=(28,18))\nfor i in heatmap_df.columns[20:-5]:\n    sns.distplot(df[i], hist=False, label=i, kde_kws={'linewidth':4}, axlabel='Rating')","4bc1481d":"plt.figure(figsize=(28,18))\nfor i in heatmap_df.columns[-5:]:\n    sns.distplot(df[i], hist=False, label=i, kde_kws={'linewidth':4}, axlabel='Rating')","a57b88d0":"from sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb","b7999586":"# further reducing data granularity into broader classifications of positions\npos_df = heatmap_df\npos_grp = {'CB':'Centre Half', 'CDM':'CDM', \"LB\":'Fullback', \"RB\":'Fullback', \n           'LM':'Winger', 'RM':'Winger', 'LW':'Winger', 'RW':'Winger', \n           'CM':'Central Midfielder', 'GK':'Goalkeeper', 'ST':'Striker', 'Full back':'Fullback'}\npos_df['Position'].replace(pos_grp, inplace=True)","703cedea":"pos_df['Position'].value_counts()","bc07a013":"# train test splitting dataset\nx = pos_df[pos_df.columns[1:]]\ny = pos_df[pos_df.columns[0]]\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)","6cab12fd":"# creating models\nmodel1 = RandomForestClassifier()\nmodel2 = LogisticRegression(solver='lbfgs', max_iter=150)\nmodel3 = GaussianNB()\nmodel4 = MultinomialNB()\nmodel5 = KNeighborsClassifier(n_neighbors=15)\nmodel6 = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\nmodels = [model1, model2, model3, model4, model5, model6]","b3e79c7c":"# training models\nmodel_scores = {}\nfor model in models:\n    model.fit(train_x, train_y)\n    score = model.score(test_x, test_y)\n    model_scores[model] = score","86eafced":"model_scores_df = pd.DataFrame({\n    'Model' : ['RandomForestClassifier','LogisticRegression', \n               'GaussianNB', 'MultinomialNB', 'KNeighborsClassifier', \n               'XGBClassifier'],\n    'Score' : list(model_scores.values())\n})\nmodel_scores_df.sort_values('Score', ascending=False, inplace=True)\nmodel_scores_df","742f95ec":"df2 = pd.DataFrame({\n    'Actual Position': test_y,\n    'LogisticRegression' : model2.predict(test_x),\n    'RandomForest': model1.predict(test_x),\n    'XGBClassifier' : model6.predict(test_x),\n    'KNeighborsClassifier' : model5.predict(test_x),\n    'MultinomialNB' : model4.predict(test_x),\n    'GaussianNB' : model3.predict(test_x)\n})\ndf2","edb92f08":"heatmap_serial = ['RandomForestClassifier', 'LogisticRegression', 'GaussianNB', 'MultinomialNB', 'KNeighborsClassifier', 'XGBClassifier', ]\nlabels = ['Goalkeeper', 'Centre Half', 'Fullback', 'CDM', 'Central Midfielder', 'CAM', 'Winger', 'Striker']\nfor i in range(len(models)):    \n    cm = confusion_matrix(models[i].predict(test_x), test_y, labels=labels)\n    cm = pd.DataFrame(cm)\n    cm.index, cm.columns = labels, labels \n    plt.figure(figsize=(20,15))\n    sns.heatmap(cm, cmap='Blues', annot=True, linecolor='grey', linewidth=3).set_title(heatmap_serial[i])\n","eb316af2":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.linear_model import LinearRegression","f0401689":"reg_df = pd.concat([df['Overall'], df[df.columns[15]], df[df.columns[44:-1]]], axis=1)\nreg_df.dropna(axis='index', subset=['Position'], inplace=True)\npos_dict = {'LS':'Striker', 'RS':'Striker', 'CF':'Striker', 'RF':'Striker', 'LF':'Striker', 'LAM':'CAM', 'RAM':'CAM', 'LCM':'Central Midfielder', \n            'RCM':'Central Midfielder', 'LDM':'Centre Half', 'RDM':'Centre Half', 'RCB':'Centre Half', 'LCB':'Centre Half', 'RWB':'Fullback', 'LWB':'Fullback',\n            'CB':'Centre Half', 'CDM':'CDM', \"LB\":'Fullback', \"RB\":'Fullback', \n            'LM':'Winger', 'RM':'Winger', 'LW':'Winger', 'RW':'Winger', \n            'CM':'Central Midfielder', 'GK':'Goalkeeper', 'ST':'Striker'}\nreg_df['Position'].replace(pos_dict, inplace=True)","2a1f75ce":"# OneHot Encoding for Position\nx = reg_df[reg_df.columns[1:]]\ny = reg_df['Overall']\ncol_trans = make_column_transformer((OneHotEncoder(), ['Position']),\n                                    remainder='passthrough')\nx = col_trans.fit_transform(x)\n# train test split\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=100)","2b039397":"# creating and training model\nreg_model = LinearRegression()\nreg_model.fit(train_x, train_y)\n# model evaluation\nacc = reg_model.score(test_x, test_y)\nprint(\"Model has an accuracy of {}%\".format(acc*100))","41e00694":"preds_df = pd.DataFrame({\n    'Predicted Overall':reg_model.predict(test_x),\n    'Real Overall':test_y\n})\npreds_df['Difference'] = preds_df['Real Overall'] - preds_df['Predicted Overall']\npreds_df","04b935d0":"plt.figure(figsize=(25,12))\nsns.lineplot(data=preds_df, x='Real Overall', y='Predicted Overall').set_title('Correlation between Predicted and Real Overall')\nplt.show()","0623c85d":"plt.figure(figsize=(25,12))\nfor i in range(2):\n    a = sns.distplot(preds_df[preds_df.columns[i]], hist=True, label=preds_df.columns[i], kde_kws={'linewidth':'4'}, axlabel='Overall')\n    a.set_title('Distribution of Predicted and Real Overall')\n    a.legend()\nplt.show()","07de7aec":"plt.figure(figsize=(25,12))\nsns.distplot(preds_df['Difference'], bins=50, kde_kws={'linewidth':'4'}, color=\"r\").set_title('Distribution of Differences in Predicted and Real Overall')\nplt.show()","8ab4a33e":"### Key Points\n- To determine current Overal rating of a team, I used the median as mean is not resistant to outliers. Football is a team game so one or two outlying players is not enough. However, to determine the Potential rating, I used mean as having a two or three players who are out of the ordinary could in the long run, affect the whole team. \n- Juventus turns out to be the strongest team on paper. ","daedcbc0":"model1 = RandomForestClassifier()\nmodel2 = LogisticRegression(solver='lbfgs', max_iter=150)\nmodel3 = GaussianNB()[](http:\/\/)\nmodel4 = MultinomialNB()\nmodel5 = KNeighborsClassifier(n_neighbors=15)\nmodel6 = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)","5dad936b":"## How does the Overall rating affect a player's valuation?\nFirst I will remove all the free agents as their overall rating may not be an ideal representation against their valuation.","d733e97f":"## Data Exploration","2669166a":"## Predicting Position Based on Attributes","376577ef":"## Machine Learning Applications\n- regression model for predicting Overall based on attributes\n- classification of player position based on attributes","7d633f4f":"### Key Points: \n- The model is mostly accurate between 60 and 85 Overall.\n- Much of the inaccuracy is outside of this range, suggesting possible non-linearity throughout the overall range of all Overall rates. ","54c9dbaf":"## When do players reach their full potential?","6f33a15b":"### Nationality of Players","debbbdbe":"### Key Points\n- Better players generally cost more and are paid more\n- But some of the best players may not be as expensive and could be obtained for relatively cheaper transfer fees\n- The variabilities of Value and Wage increase as the Overall increases, suggesting other factors such as marketability may be more important when determing their valuation ","e2070671":"> ## Initial Data Cleaning","790538fc":"### Key Points\n- Violin thickness represents the sample size\n- Sample size gets smaller over the age of 30, resulting in less representative samples\n- Hence, players probably tend to retire after the age of 30\n- Overall generally increases with age upto the age of 31, and then starts to drop","42581bb1":"### Key Points\n- Most successful classification model is Multi-class Logistic Regression, followed closely by RandomForest and KNN models. Naive Bayes models were least successful models.  ","cdf02419":"### Key Points\n- Models have been quite satisfactory in their prediction. \n- A lot of the confusions were between positions that have overlaps in the requirements of their attributes. For instance, CDM and CB, CDM and CM, Full back and Winger, Winger is Striker. \n- These confusions are to some extent acceptable as players in modern football need to be versatile. For instance, modern wingers are also often good as Strikers, CDMs often need to play as Center Halves, and the whole of central midfield (CAM, CM and CAM) are very similar, with slight differences in offensive and defensive attributes. ","c56b27a3":"### Highest Spending Clubs","d5ca2567":"### What is the nature of the change in Overall rating for a players as they mature?\n","7e29e704":"Based on the previous analysis, it is clear that the Overall rating relies on the other attributes and are weighted differently for different positions. Therefore, I will convert the position feature into a one-hot encoded variable. ","198ffcbc":"## Distribution of Attributes","4631a0af":"### Key Points\n- We can see the key attributes players needs or does not need to have for playing in each position.\n- For instance; STs have the highest finishing while CBs have the lowest. Strength is important for both CBs and STs.\n- Acceleration, SprintSpeed, Agility, and Balance are all key attributes for RW, RM, RB, LW, LM, and LB.\n- CM, CDM, RB and LB are positions with the highest stamina requirement","9d5a40ed":"### Strongest Squads on paper","a170ce5a":"## Predicting Overall Using Linear Regression\n","4df34345":"### Key Points\n- Spearman correlation is more robust than Pearson when dealing with outliers.\n- We can see clusters of attributes that are highly correlated to each other. For instance, GK attributes form one cluster, Marking, Interception, Standing and Sliding tackles form another, Shot Power to Penalties form another one, and Skill Moves to Ball Control form a further one. These clusters perhaps pertain to specific set of roles of a player on the field. \n- We can also see that the Overall attribute correlates disproportionately high with Reactions and Composure. That means these two important for all players regardless of their position (except maybe GKs).\n- Wage correlates strongest with Overall, Potential, Composure, Reaction, and Ball Control.\n- Strength and Balance have strong negative correlation, similar to Strength with Acceleration, SprintSpeed and Agility. ","d887a418":"## Median of Attributes by Position","69c7796b":"**Let's Predict Some Positions**","a7ddc603":"### Key Points\n- The distributions that are normal are probably not good discriminators of which position a player should play in given their set of attributes.\n- For instance, the Sliding Tackle rating is bimodally distributed. It is plausible that the first bell shape is due to the ratings for players who are not defensively sound, while the second one is probably for players who are actually defensively sound like CBs, or CDMs or Fullbacks. ","a4f48879":"### Key Points: \n- Left footed players are rare, compared to right footed players.\n- Most LBs and LWBs are left footed.\n- Most RBs and RWBs are right footed. \n- LCBs and LMs have higher than average proportion of left footed players.","d4e0ee0f":"## Correlation b\/w Attributes","b77158c2":"### Further Ideas: \n- Future models could seperate the total dataset into two or three tiers of players, as much of the Wages, Values and even the attribute weights for predicting Overall vary between the suggested ranges (<60, between 60 and 85, and >85). \n- Same could be done for analysing positon classifyer models. \n- Feature importance and Principal Component Analysis for each of the positions could be implemented to render a more accurate mdoel for position prediction. ","a0bcb7be":"### Key Points\n- Players tend to reach their full potential between Age 28 and 30","6c53ef4a":"### Distribution of Positions and Preferred Feet Among Players"}}