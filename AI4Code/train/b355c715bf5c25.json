{"cell_type":{"00e4c9f5":"code","c79b36c3":"code","785d752b":"code","9c46b08d":"code","dd28cb3c":"code","da45eaef":"code","3bcd6749":"code","67c6a6e8":"code","005b06cc":"code","86afb0aa":"code","b1ce7249":"code","2a2e1266":"code","8c988254":"code","6fcf0902":"code","3bc8d1ba":"code","dc443690":"code","2f67378c":"code","b42ac157":"code","f9e611ac":"markdown","796e60a7":"markdown","21347163":"markdown","b7d63eee":"markdown","9d33f0e3":"markdown","b313496d":"markdown","21c1a6d4":"markdown","8ebc97e5":"markdown","5f0cd430":"markdown","46a48abe":"markdown","4fee0a83":"markdown","dbae387b":"markdown","f15b1051":"markdown","d0122ea1":"markdown","cde8c101":"markdown","9ca70ecf":"markdown","29b101bb":"markdown","13d5ee6b":"markdown"},"source":{"00e4c9f5":"import os\nprint((os.listdir('..\/input\/')))\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn.feature_selection import SelectFromModel\nimport xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler","c79b36c3":"#import keras\n#from keras.layers import Dense\n#from keras.models import Sequential\n#from keras import regularizers\n#from keras.utils import to_categorical\n#from sklearn.preprocessing import StandardScaler\n#model = Sequential()","785d752b":"df_train = pd.read_csv('..\/input\/webclubrecruitment2019\/TRAIN_DATA.csv')\ndf_test = pd.read_csv('..\/input\/webclubrecruitment2019\/TEST_DATA.csv')\nX_train, X_dev, y_train, y_dev = train_test_split( df_train.loc[:, 'V1':'V16'], df_train.loc[:, 'Class'], test_size=0.15, random_state=42)","9c46b08d":"test_index=df_test['Unnamed: 0'] #copying test index for later","dd28cb3c":"X_train['V6'] = StandardScaler().fit_transform(X_train['V6'].values.reshape(-1, 1))\n\nX_dev['V6'] = StandardScaler().fit_transform(X_dev['V6'].values.reshape(-1, 1))\n\ndf_test['V6'] = StandardScaler().fit_transform(df_test['V6'].values.reshape(-1, 1))\n\nfeatures = ['V2','V3', 'V4', 'V7','V8','V16']\nfor feature in features:\n    for column in range(pd.get_dummies(X_train[feature]).columns.size):\n        X_train[feature + '_' + str(column + 1)] = pd.get_dummies(X_train[feature])[column]\n        \nfor feature in features:\n    for column in range(pd.get_dummies(X_dev[feature]).columns.size):\n        X_dev[feature + '_' + str(column + 1)] = pd.get_dummies(X_dev[feature])[column]\n\nfor feature in features:\n    for column in range(pd.get_dummies(df_test[feature]).columns.size):\n        df_test[feature + '_' + str(column + 1)] = pd.get_dummies(df_test[feature])[column]\n\n\nX_train.drop(columns=features, axis = 1, inplace = True)\nX_dev.drop(columns=features, axis = 1, inplace = True)\ndf_test.drop(columns=features, axis = 1, inplace = True)\n\ndf_test = df_test.loc[:, 'V1':'V16_4']\n","da45eaef":"train_X = df_train.loc[:, 'V1':'V16']\ntrain_y = df_train.loc[:, 'Class']\n","3bcd6749":"model = xgb.XGBClassifier(learning_rate = 0.12, max_depth = 2, min_child_weight = 1, subsample = 0.8, colsample_bytree = 1, n_estimators = 300)\nmodel.fit(X_train, y_train)","67c6a6e8":"#from sklearn.model_selection import GridSearchCV\n\n#xgb_model = xgb.XGBClassifier()\n#optimization_dict = {\n#                      'learning_rate': [0.10, 0.12, 0.04, 0.06, 0.08, 0.14, 0.16],\n#                        'max_depth': [1, 2,4,6, 8, 10],\n#                     'n_estimators': [50,100,200, 300, 400]}\n\n#model = GridSearchCV(xgb_model, optimization_dict, \n#                     scoring='accuracy', verbose=1)\n\n#model.fit(X_train,y_train)\n#print(model.best_score_)\n#print(model.best_params_)","005b06cc":"#df_test = df_test.loc[:, 'V1':'V16']\npred = model.predict_proba(df_test)\npred","86afb0aa":"pred_dev = model.predict(X_dev) \npred_dev = pd.DataFrame(pred_dev)\nscore = roc_auc_score(y_dev, pred_dev)\nscore","b1ce7249":"result=pd.DataFrame()\nresult['Id'] = test_index\nresult['PredictedValue'] = pd.DataFrame(pred[:, 1])\nresult.to_csv('output.csv', index=False)\nresult","2a2e1266":"#import keras\n#from keras.layers import Dense\n#from keras.models import Sequential\n#from keras import regularizers\n#from keras.utils import to_categorical\n#from sklearn.preprocessing import StandardScaler\n#model = Sequential()\n","8c988254":"#from sklearn.feature_selection import SelectKBest\n#from sklearn.feature_selection import chi2\n#bestfeatures = SelectKBest(score_func=chi2, k='all')\n#fit = bestfeatures.fit(df_train.loc[:, 'V1':'V16'].abs() ,df_train.loc[:, 'Class'])\n#dfscores = pd.DataFrame(fit.scores_)\n#dfcolumns = pd.DataFrame(df_train.loc[:, 'V1':'V16'].columns)\n#concat two dataframes for better visualization \n#featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n#featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n#print(featureScores.nlargest(10,'Score'))","6fcf0902":"#X_train['V13'] = StandardScaler().fit_transform(X_train['V13'].values.reshape(-1, 1))\n#X_train['V15'] = StandardScaler().fit_transform(X_train['V15'].values.reshape(-1, 1))\n#X_train['V6'] = StandardScaler().fit_transform(X_train['V6'].values.reshape(-1, 1))\n#X_train['V12'] = StandardScaler().fit_transform(X_train['V12'].values.reshape(-1, 1))\n#X_train['V14'] = StandardScaler().fit_transform(X_train['V14'].values.reshape(-1, 1))\n\n#X_dev['V15'] = StandardScaler().fit_transform(X_dev['V15'].values.reshape(-1, 1))\n#X_dev['V13'] = StandardScaler().fit_transform(X_dev['V13'].values.reshape(-1, 1))\n#X_dev['V6'] = StandardScaler().fit_transform(X_dev['V6'].values.reshape(-1, 1))\n#X_dev['V12'] = StandardScaler().fit_transform(X_dev['V12'].values.reshape(-1, 1))\n#X_dev['V14'] = StandardScaler().fit_transform(X_dev['V14'].values.reshape(-1, 1))\n\n\n#X_train['V3_1'] = pd.get_dummies(X_train['V3'])[0]\n#X_train['V3_2'] = pd.get_dummies(X_train['V3'])[1]\n#X_train['V3_3'] = pd.get_dummies(X_train['V3'])[2]\n\n#X_train['V7_1'] = pd.get_dummies(X_train['V7'])[0]\n#X_train['V7_2'] = pd.get_dummies(X_train['V7'])[1]\n\n#X_train['V8_1'] = pd.get_dummies(X_train['V8'])[0]\n#X_train['V8_2'] = pd.get_dummies(X_train['V8'])[1]\n\n#X_train['V9_1'] = pd.get_dummies(X_train['V9'])[0]\n#X_train['V9_2'] = pd.get_dummies(X_train['V9'])[1]\n#X_train['V9_3'] = pd.get_dummies(X_train['V9'])[2]\n\n#X_dev['V3_1'] = pd.get_dummies(X_dev['V3'])[0]\n#X_dev['V3_2'] = pd.get_dummies(X_dev['V3'])[1]\n#X_dev['V3_3'] = pd.get_dummies(X_dev['V3'])[2]\n\n#X_dev['V7_1'] = pd.get_dummies(X_dev['V7'])[0]\n#X_dev['V7_2'] = pd.get_dummies(X_dev['V7'])[1]\n\n#X_dev['V8_1'] = pd.get_dummies(X_dev['V8'])[0]\n#X_dev['V8_2'] = pd.get_dummies(X_dev['V8'])[1]\n\n#X_dev['V9_1'] = pd.get_dummies(X_dev['V9'])[0]\n#X_dev['V9_2'] = pd.get_dummies(X_dev['V9'])[1]\n#X_dev['V9_3'] = pd.get_dummies(X_dev['V9'])[2]\n\n#X_train.drop(columns=['V3', 'V7', 'V8', 'V9'],axis = 1, inplace = True)\n#X_dev.drop(columns=['V3', 'V7', 'V8', 'V9'], axis = 1, inplace = True)","3bc8d1ba":"#lam = 0.1\n#model.add(Dense(X_train.columns.size, activation='relu', input_dim=X_train.columns.size))\n#model.add(Dense(24, activation='relu'))\n#model.add(Dense(32, activation='relu'))\n#model.add(Dense(36, activation='relu'))\n#model.add(Dense(40, activation='relu'))\n#model.add(Dense(34, activation='relu'))\n#model.add(Dense(30, activation='relu'))\n#model.add(Dense(20, activation='relu'))\n#model.add(Dense(10, activation='relu'))\n#model.add(Dense(4, activation='relu'))\n#model.add(Dense(1, activation='sigmoid'))\n\n#model.compile(optimizer='adam', loss='binary_crossentropy')\n","dc443690":"#model.fit(X_train, y_train, epochs=70, batch_size=256)\n#pred = model.predict(X_dev)","2f67378c":"#pred_dev = pd.DataFrame(pred[:])\n#score = roc_auc_score(y_dev, pred_dev)\n","b42ac157":"#df_test['V1'] = StandardScaler().fit_transform(X_dev['V1'].values.reshape(-1, 1))\n#df_test['V13'] = StandardScaler().fit_transform(df_test['V13'].values.reshape(-1, 1))\n#df_test['V15'] = StandardScaler().fit_transform(df_test['V15'].values.reshape(-1, 1))\n\n#df_test['V6'] = StandardScaler().fit_transform(df_test['V6'].values.reshape(-1, 1))\n#df_test['V12'] = StandardScaler().fit_transform(df_test['V12'].values.reshape(-1, 1))\n#df_test['V14'] = StandardScaler().fit_transform(df_test['V14'].values.reshape(-1, 1))\n\n#df_test['V3_1'] = pd.get_dummies(df_test['V3'])[0]\n#df_test['V3_2'] = pd.get_dummies(df_test['V3'])[1]\n#df_test['V3_3'] = pd.get_dummies(df_test['V3'])[2]\n\n#df_test['V7_1'] = pd.get_dummies(df_test['V7'])[0]\n#df_test['V7_1'] = pd.get_dummies(df_test['V7'])[0]\n#df_test['V7_2'] = pd.get_dummies(df_test['V7'])[1]\n#df_test['V7_2'] = pd.get_dummies(df_test['V7'])[1]\n\n#df_test['V8_1'] = pd.get_dummies(df_test['V8'])[0]\n#df_test['V8_2'] = pd.get_dummies(df_test['V8'])[1]\n\n#df_test['V9_1'] = pd.get_dummies(df_test['V9'])[0]\n#df_test['V9_2'] = pd.get_dummies(df_test['V9'])[1]\n#df_test['V9_3'] = pd.get_dummies(df_test['V9'])[2]\n\n#df_test.drop(columns=['V3', 'V7', 'V8', 'V9'], axis = 1, inplace = True)\n\n#df_test = df_test.loc[:, 'V1':'V9_3']\n#pred = model.predict(df_test)\n\n#result=pd.DataFrame()\n#result['Id'] = test_index\n#result['PredictedValue'] = pd.DataFrame(pred)\n#result['PredictedValue'] = ['%.4f' % elem for elem in result['PredictedValue']]\n#result.to_csv('output.csv', index=False)\n#result","f9e611ac":"## Baseline Kernel for WebClub Recruitment Test 2019","796e60a7":"### Preparing the results and converting ton .csv file","21347163":"### Predicting the probabilities for the test data","b7d63eee":"### Importing required packages neural network(Code after xgboost)","9d33f0e3":"### Running the dataset through the model","b313496d":"### Feature selections ","21c1a6d4":"### Building the neural network","8ebc97e5":"### Initializing Classifier","5f0cd430":"### Importing required packages for xgboost","46a48abe":"### Data Preprocessing : Standardising and Encoding the important features","4fee0a83":"### Preparing the test set accordingly(Standardizing and one-hot encoding) and predicting probabilities for the test set","dbae387b":"# Neural Network","f15b1051":"### Predicting ROC AUC Score for the dev set","d0122ea1":"### Separating the features and the labels","cde8c101":"### Predicting output for dev set to check accuracy","9ca70ecf":"### Parameter Standardisation and One-hot Encoding","29b101bb":"### Reading the Train and Test Set","13d5ee6b":"### Converting the results to .csv"}}