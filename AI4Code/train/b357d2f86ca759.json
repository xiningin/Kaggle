{"cell_type":{"a85a284e":"code","d44f3c25":"code","2c596835":"code","c8d2f1de":"code","aa86365d":"code","77e10cbf":"code","dd51eba0":"code","d0863ac6":"code","77166a10":"code","e5948ebc":"code","909e26f0":"code","e399e85b":"code","09b015b6":"code","dc4f3df8":"code","1733575c":"code","9522433d":"markdown","ea308282":"markdown","bd996ada":"markdown","13c8603a":"markdown","fb66f6ee":"markdown","25ac01b7":"markdown","04563fd2":"markdown"},"source":{"a85a284e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\/yelp-dataset\"))\nfrom pyspark import SparkContext, SparkConf, StorageLevel, SQLContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import functions as F\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import Row","d44f3c25":"# initialize spark session\nspark = SparkSession.builder \\\n        .appName(\"Big Data Project\") \\\n        .master(\"local[4]\") \\\n        .config(\"spark.logConf\", True) \\\n        .getOrCreate()\nsc = spark.sparkContext\nsc\nsqlContext = SQLContext(sc)","2c596835":"\n# review_df = sqlContext.read.json(\"yelp_dataset\/yelp_review.json\")\nreview_df = spark.read.csv('..\/input\/remove-text-column-of-review\/output.csv', header=True)\nbusiness_df = sqlContext.read.json(\"..\/input\/yelp-dataset\/yelp_academic_dataset_business.json\")","c8d2f1de":"# Filter Restaurant businesses\nbusiness_df = business_df.filter(\"categories like '%Restaurant%'\").select(col(\"business_id\"))\n\n# Filter out shops\/users that have very few (<10) reviews to forcefully restrict sparsity.\nbusiness_review_count = review_df.groupBy('business_id').\\\n                agg(F.count(review_df.stars).alias(\"biz_count\"))\n\nbiz_with_10_ratings_or_more = business_review_count.filter(\"biz_count>=10\")\n\nuser_review_count = review_df.groupBy('user_id').\\\n                agg(F.count(review_df.stars).alias(\"user_count\"))\n\nuser_with_10_ratings_or_more = user_review_count.filter(\"user_count>=10\")\n\n# merge with review_df\nreview_df = business_df.join(review_df, \"business_id\", \"inner\")\nreview_df = biz_with_10_ratings_or_more.join(review_df, \"business_id\", \"inner\")\nreview_df = user_with_10_ratings_or_more.join(review_df, \"user_id\", \"inner\")","aa86365d":"# assert schema for feeding into ALS\nreview_df = review_df.select(col(\"user_id\"), col(\"business_id\"), col(\"stars\"))\nprint(review_df.schema)","77e10cbf":"user_num_df = review_df.select('user_id').distinct()\nbiz_num_df = review_df.select('business_id').distinct()","dd51eba0":"# converting business id and user id with to numerical index, as required by ALS\nfrom pyspark.sql.window import Window as W\n# user index\nuser_num_df = user_num_df.withColumn(\"idx\", monotonically_increasing_id())\nw = W.orderBy(\"idx\")\nuser_num_df = user_num_df.withColumn(\"user_index\", F.row_number().over(w))\nuser_num_df = user_num_df.drop(\"idx\")\n# business index\nbiz_num_df = biz_num_df.withColumn(\"idx1\", monotonically_increasing_id())\nw = W.orderBy(\"idx1\")\nbiz_num_df = biz_num_df.withColumn(\"business_index\", F.row_number().over(w))\nbiz_num_df = biz_num_df.drop(\"idx1\")","d0863ac6":"review_df = review_df.withColumn(\"stars\", review_df[\"stars\"].cast(IntegerType()))\nreview_df = review_df.join(biz_num_df, \"business_id\")\nreview_df = review_df.join(user_num_df, \"user_id\")\nprint(review_df.schema)","77166a10":"# split dataset into train, validation and test\n(training, validation, test) = review_df.randomSplit([0.6,0.2,0.2], seed=42)\n# cache these datasets for performance\ntraining.cache()\nvalidation.cache()\ntest.cache()\n\nreview_df.unpersist()\nbusiness_df.unpersist()\nbiz_num_df.unpersist()\nuser_num_df.unpersist()\nbiz_with_10_ratings_or_more.unpersist()\nuser_with_10_ratings_or_more.unpersist()\n\nreview_df = None\nbusiness_df = None\nbiz_num_df = None\nuser_num_df = None\nbiz_with_10_ratings_or_more = None\nuser_with_10_ratings_or_more = None","e5948ebc":"# Baseline model 1 - average rating overall\ntraining_avg_rating = training.agg(avg(training.stars)).collect()[0][0]\n# add a column with the average rating\ntest_for_avg_df = test.withColumn('prediction', F.lit(training_avg_rating))\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n# get RMSE\ntest_avg_RMSE_1 = evaluator.evaluate(test_for_avg_df)\nprint(\"The baseline 1 RMSE is {0}\".format(test_avg_RMSE_1))\n#training_avg_rating.unpersist()\ntest_for_avg_df.unpersist()\ntraining_avg_rating = None\ntest_for_avg_df = None\nevaluator = None","909e26f0":"# Baseline model 2 - average rating per business\ntraining_avg_rating = training.groupBy('business_id').agg(avg(training.stars).alias(\"prediction\"))\n# add a column with the average rating\ntest_for_avg_df = test.join(training_avg_rating, \"business_id\")\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n# get RMSE\ntest_avg_RMSE_2 = evaluator.evaluate(test_for_avg_df)\nprint(\"The baseline 2 RMSE is {0}\".format(test_avg_RMSE_2))\ntraining_avg_rating.unpersist()\ntest_for_avg_df.unpersist()\ntraining_avg_rating = None\ntest_for_avg_df = None\nevaluator = None","e399e85b":"# Baseline model 3 - average rating per user\ntraining_avg_rating = training.groupBy('user_id').agg(avg(training.stars).alias(\"prediction\"))\n# add a column with the average rating\ntest_for_avg_df = test.join(training_avg_rating, \"user_id\")\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n# get RMSE\ntest_avg_RMSE_3 = evaluator.evaluate(test_for_avg_df)\nprint(\"The baseline 3 RMSE is {0}\".format(test_avg_RMSE_3))\ntraining_avg_rating.unpersist()\ntest_for_avg_df.unpersist()\ntraining_avg_rating = None\ntest_for_avg_df = None\nevaluator = None","09b015b6":"def train_ALS(rank, maxit, reg, train_df, test_df, seed = 42):\n    als = ALS(maxIter = maxit,\n              regParam = reg,\n              rank = rank,\n              userCol=\"user_index\", \n              itemCol=\"business_index\", \n              ratingCol=\"stars\",\n              coldStartStrategy=\"drop\")\n\n    # set the parameters for the method\n    als.setSeed(seed)\n    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n    # Create the model with these parameters.\n    model = als.fit(train_df)\n    # Run the model to create a prediction. Predict against the validation_df.\n    predict_df = model.transform(test_df)\n    error = evaluator.evaluate(predict_df)\n    als = None\n    model = None\n    predict_df.unpersist()\n    predict_df = None\n    evaluator = None\n    return(error)\n\nnumIterations = [5, 10, 15, 20]\nranks = [2, 4, 6, 8]\nregs = list(np.arange(0.05, 0.4, 0.05))\n\nRMSE_results = []\nbest_RMSE = 20\nfor rank in ranks:\n    for maxit in numIterations:\n        for reg in regs:\n            error = train_ALS(rank = rank, maxit = maxit, reg = reg,train_df = training, test_df = validation)\n            RMSE_results.append(error)\n#             print(error)\n#             print(maxit)\n#             print(reg)\n#             print(rank)\n            if best_RMSE > error:\n                best_RMSE = error\n                best_maxit = maxit\n                best_reg = reg\n                best_rank = rank\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.plot(range(112),RMSE_results, 'bs', range(112),np.full((112), test_avg_RMSE_1), 'r--',range(112),np.full((112), test_avg_RMSE_2), 'g--',range(112),np.full((112), test_avg_RMSE_3), 'y--')\nRMSE_results.to_csv('RMSE_results.csv')","dc4f3df8":"# Build the recommendation model using ALS on the training data\n# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nals = ALS(maxIter = best_maxit,\n          regParam = best_reg,\n          rank = best_rank,\n          userCol=\"user_index\", itemCol=\"business_index\", ratingCol=\"stars\",\n          coldStartStrategy=\"drop\", seed = 42)\nmodel = als.fit(training)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test)\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))","1733575c":"# Generate top 10 business recommendations for each user\nuserRecs = model.recommendForAllUsers(10)\n# Generate top 10 user recommendations for each business\nbizRecs = model.recommendForAllItems(10)\n# Generate top 10 business recommendations for a specified set of users\nusers = review_df.select(als.getUserCol()).distinct().limit(3)\nuserSubsetRecs = model.recommendForUserSubset(users, 10)\n# Generate top 10 user recommendations for a specified set of businesses\nbizs = review_df.select(als.getItemCol()).distinct().limit(3)\nbizSubSetRecs = model.recommendForItemSubset(bizs, 10)\n# $example off$\nuserRecs.show()\nbizRecs.show()\nuserSubsetRecs.show()\nbizSubSetRecs.show()","9522433d":"# ID Transformation for Feeding into ALS","ea308282":"# Prediction","bd996ada":"# Baseline Models","13c8603a":"# Imports","fb66f6ee":"# Data - Reduce Sparsity","25ac01b7":"# Training","04563fd2":"# Data Loading"}}