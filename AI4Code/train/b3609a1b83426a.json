{"cell_type":{"76e1af25":"code","9cb2a9e0":"code","dae88b34":"code","9af3c916":"code","951dd07a":"code","3240553e":"code","c50c12c3":"code","8d93453c":"code","38219bf7":"code","5e3a6cc8":"code","28493a79":"markdown","1ee4c1f2":"markdown","3c2ada87":"markdown","a14c7389":"markdown","7e7499fe":"markdown","ef84f9e4":"markdown","be0f125b":"markdown","18c72904":"markdown","ce56ce0f":"markdown","00ca73b6":"markdown","03a36dea":"markdown","29c51ef2":"markdown"},"source":{"76e1af25":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom torch.optim import Adam\nfrom torchvision import datasets\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom sklearn.metrics import accuracy_score\n\n\n\nif torch.cuda.is_available():        \n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(\"device:\", device)","9cb2a9e0":"def extract_path(tup):\n    return tup[0]\n\ntrain = datasets.ImageFolder(\"..\/input\/cat-and-dog\/training_set\/training_set\")\ntrain_imgs = pd.Series(train.imgs, name=\"path\").apply(func=extract_path)\ntrain_targets = pd.Series(train.targets, name=\"label\")\ntrain_merged = pd.concat([train_imgs, train_targets], axis=1)\ntrain, val = train_test_split(train_merged, test_size=0.3, random_state=0)\n\ntest = datasets.ImageFolder(\"..\/input\/cat-and-dog\/test_set\/test_set\")\ntest_imgs = pd.Series(test.imgs, name=\"path\").apply(func=extract_path)\ntest_targets = pd.Series(test.targets, name=\"label\")\ntest_merged = pd.concat([test_imgs, test_targets], axis=1)","dae88b34":"train[\"label\"].value_counts()\/len(train)","9af3c916":"val[\"label\"].value_counts()\/len(val)","951dd07a":"class CustomDataset(Dataset):\n    \"\"\"\n    A custom image dataset.\n    \"\"\"\n    def __init__(self, data, transform_pipe, device):\n        self.data = data\n        self.transform_pipe = transform_pipe\n        self.device = device\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        observation = self.data.iloc[index, :]\n        image = Image.open(observation[\"path\"]).convert(\"RGB\")\n        image = self.transform_pipe(image).to(self.device)\n        if observation[\"label\"] == 0:\n            label = torch.zeros(size=(1,1)).to(self.device)\n        else:\n            label = torch.ones(size=(1,1)).to(self.device)\n        return [image, label]","3240553e":"class CNNClassifier(nn.Module):\n    \"\"\"\n    A CNN-based classifier.\n    \"\"\"\n\n    def __init__(self, conv_ch1, conv_ch2, linear_size, kernel_size, pooling_size, linear_input_size=None):\n        \"\"\"\n        Constructor.\n\n        :param int conv_ch1: number of output channels of the first convolutional layer\n        :param int conv_ch2: number of output channels of the second convolutional layer\n        :param int linear_size: number of outputs the second linear layer expects from the first linear layer\n        :param int kernel_size: width and height of each convolutional kernel in the model\n        :param int pooling_size: size of the pooling window\n        :param int linear_input_size: number of outputs the first linear layer expects from the convolutional\n        part.\n        \"\"\"\n        super(CNNClassifier, self).__init__()\n        self.linear_input_size = linear_input_size\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(pooling_size)\n\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=conv_ch1, kernel_size=kernel_size)\n        \n        self.batch_norm1 = nn.BatchNorm2d(num_features=conv_ch1)\n        self.conv2 = nn.Conv2d(in_channels=conv_ch1, out_channels=conv_ch2, kernel_size=kernel_size)\n        \n        if linear_input_size:  # evaluates as False if linear_input_size is None\n            self.batch_norm2 = nn.BatchNorm1d(num_features=linear_input_size)\n            self.linear1 = nn.Linear(in_features=linear_input_size, out_features=linear_size)\n            self.batch_norm3 = nn.BatchNorm1d(num_features=linear_size)\n            self.linear2 = nn.Linear(in_features=linear_size, out_features=1)\n            self.batch_norm4 = nn.BatchNorm1d(num_features=1)\n            self.sigmoid = nn.Sigmoid()\n\n    def conv_part(self, x):\n        \"\"\"\n        Calculates the convolutional part of the forward pass.\n\n        :param torch.Tensor x: input data\n        :return: input representations after the convolutional part.\n        \"\"\"\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        \n        x = self.batch_norm1(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        return x\n\n    def scalars_after_conv(self, x):\n        \"\"\"\n        Calculates how many scalars, i.e. tensors of rank 0 are in the output of the convolutional component.\n\n        :param torch.Tensor x: one batch of input\/observations\n        :return: the number of rank 0 tensors in the output of the convolutional component\n        \"\"\"\n        x = self.conv_part(x)\n        size = x.size()  # batch_size x channel_size x width x height\n        n_channels = size[1]\n        width = size[2]\n        height = size[3]\n        return n_channels * width * height\n\n    def forward(self, x):\n        \"\"\"\n        performs the forward pass.\n\n        :param  torch.Tensor x: the input\/observations per batch\n        :return: the prediction of the whole batch\n        \"\"\"\n        x = self.conv_part(x)\n\n        if self.linear_input_size:\n            x = x.view(-1, self.linear_input_size)  # flatten out for the linear layers\n            \n            x = self.batch_norm2(x)\n            x = self.linear1(x)\n            \n            x = self.batch_norm3(x)\n            x = self.linear2(x)\n            \n            x = self.batch_norm4(x)\n        return self.sigmoid(x)","c50c12c3":"def find_mean_std(loader):\n    \"\"\"\n    Calculates the averaged mean and std for all channels \n    of a given RGB-image dataset.\n    \"\"\"\n    mean_ch1 = 0\n    mean_ch2 = 0\n    mean_ch3 = 0\n    std_ch1 = 0\n    std_ch2 = 0\n    std_ch3 = 0\n\n\n    for image in loader:\n        means = torch.mean(input=image[0], dim=[2, 3])[0] # mean for each channel\n        mean_ch1 += means[0].item()\n        mean_ch2 += means[1].item()\n        mean_ch3 += means[2].item()\n\n        stds = torch.std(input=image[0], dim=[2, 3])[0] # std for each channel\n        std_ch1 += stds[0].item()\n        std_ch2 += stds[1].item()\n        std_ch3 += stds[2].item()\n        \n    mean_ch1 \/= len(loader)\n    mean_ch2 \/= len(loader)\n    mean_ch3 \/= len(loader)\n    std_ch1 \/= len(loader)\n    std_ch2 \/= len(loader)\n    std_ch3 \/= len(loader)\n    return {\"mean\": [mean_ch1, mean_ch2, mean_ch3], \"std\": [std_ch1, std_ch2, std_ch3]}","8d93453c":"# determine mean and std of the training data\nexample_pipe = transforms.Compose([transforms.RandomCrop(size=[256, 256], pad_if_needed=True),\n                                   transforms.ToTensor()])\n\nexample_dataset = CustomDataset(data=train, transform_pipe=example_pipe, device=device)\nexample_loader = DataLoader(example_dataset, \n                            batch_size=1, \n                            sampler=RandomSampler(data_source=example_dataset))\n\nstats = find_mean_std(loader=example_loader)\n\n# define the datasets accordingly\ntransform_pipe = transforms.Compose([transforms.RandomCrop(size=[256, 256], pad_if_needed=True),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize(mean=stats[\"mean\"], std=stats[\"std\"])])\n\ntrain_dataset = CustomDataset(data=train, transform_pipe=transform_pipe, device=device)\nval_dataset = CustomDataset(data=val, transform_pipe=transform_pipe, device=device)\ntest_dataset = CustomDataset(data=test, transform_pipe=transform_pipe, device=device)","38219bf7":"# Parameters\n# accumulate 4 4-batches to one 16-pseudo-batch\ncombine = 4\nbatch_size = 4\n\nn_epochs = 5\nlr = 0.01  # note: large learning rate\nconv_ch1 = 8\nconv_ch2 = 4\nlinear_size = 16\nkernel_size = 3\npooling_size = 4\ntrain_loader = DataLoader(train_dataset, \n                          batch_size=batch_size, \n                          sampler=RandomSampler(data_source=train_dataset))\nval_loader = DataLoader(val_dataset, \n                        batch_size=batch_size, \n                        sampler=RandomSampler(data_source=val_dataset))\n\n# to automatically determine the first linear size:\nexample_batch = next(iter(train_loader))\nexample_x = example_batch[0]\nexample_model = CNNClassifier(conv_ch1=conv_ch1, \n                              conv_ch2=conv_ch2, \n                              linear_size=linear_size, \n                              kernel_size=kernel_size, \n                              pooling_size=pooling_size).to(device)\nlinear_input_size = example_model.scalars_after_conv(x=example_x)\n\nmodel = CNNClassifier(conv_ch1=conv_ch1, \n                      conv_ch2=conv_ch2, \n                      linear_size=linear_size, \n                      kernel_size=kernel_size, \n                      pooling_size=pooling_size, \n                      linear_input_size=linear_input_size).to(device)\noptimizer = Adam(model.parameters())\nloss_func = nn.BCELoss()","5e3a6cc8":"for epoch in range(n_epochs):\n    print(\"=== Epoch\", epoch+1, \"===\")\n    acc_train = 0\n    acc_val = 0\n    # train\n    model.train()  # train mode\n    for i, batch in enumerate(train_loader):\n        x = batch[0]\n        y = batch[1].view(-1, 1).cuda(non_blocking=True)\n        \n        probas = model(x) # perform forward\n        loss = loss_func(probas, y) # calculate the loss\n        loss \/= combine\n        loss.backward() # calculate gradients\n        \n        if ((i+1) % combine == 0):\n            optimizer.step() # update weights\n            optimizer.zero_grad() # clear the gradient\n            \n    model.eval()  # evaluation mode\n    # acc on train, interesting if you want to\n    # check for overfitting\n    for batch in train_loader:\n        x = batch[0]\n        y = batch[1].view(-1, 1)\n        with torch.no_grad():\n            probas = model(x)\n        pred = np.round(probas.cpu().numpy())\n        acc_train += accuracy_score(y_true=y.cpu().numpy(), y_pred=pred)\n    acc_train \/= len(train_loader)\n    print(\"Train Accuracy:\", acc_train)\n    \n    # acc on val\n    for batch in val_loader:\n        x = batch[0]\n        y = batch[1].view(-1, 1)\n        with torch.no_grad():\n            probas = model(x)\n        pred = np.round(probas.cpu().numpy())\n        acc_val += accuracy_score(y_true=y.cpu().numpy(), y_pred=pred)\n        \n    \n    acc_val \/= len(val_loader)\n    print(\"Val Accuracy:\", acc_val, \"\\n\")","28493a79":"## Training\nUsing Gradient Accumulation as mentioned in the last part of this series.\nConsider we have a GPU capable to load 8 images at a time only, but we want to calculate gradients based on a pseudo batch of 16 images per step:","1ee4c1f2":"note: these results are fram from optimal but I don't have enough time to find optimal hyperparameters. However, the distribution of the target (all the way in the beginning) shows that these models actually learn the patterns of the data =)","3c2ada87":"<a id=\"sec4\"><\/a>\n***\n<h1 style=\"background-color:SteelBlue; color:white\" >-> 4. Implementing Batch Normalization<\/h1>\n\nNote: Batcch Normalization can be applied to image data as well. Therefore we solely have to use `BatchNorm2d` and provide the number of image channels.","a14c7389":"<a id=\"sec3\"><\/a>\n***\n<h1 style=\"background-color:SteelBlue; color:white\" >-> 3. Benefits of Batch Normalization<\/h1>\n\nThe [Batch Normalization Paper](http:\/\/proceedings.mlr.press\/v37\/ioffe15.pdf) lists a number of practical beneftis. \n\n* Batch Normalization allows layers to learn slightly more independently from other layers.\n\n* Batch Normalization reduces the impact of the data scale on the gradients, making them more dependend on the actual patterns in the input and less on single large values.\n\n* Each layer can assume its input to be equally distributed on train and test\n\n* The model will be less sensitive to parameter initialization.\n\n* The resulting gradients are more balanced and thus less likely to explode or vanish. Exploding and vanishing gradients are caused by backpropagation itself. To reach weights in the early layers of our model, we need to apply the chain rule all the way down to the respective weights. Let me give you an extreme example for each case: If the values in the chain rule are all bigger than 1, the respective gradient might be really big (explode). If the values in the chain rule are all smaller than 1, the respective gradient might be very small. Since the gradients are directly used in the parameter updates, they might lead to way too big (exploding), or way too small updates during the training process. The earlier the weights are used in the neural network, the more are they at risk to suffer from the aforementioned issues.\n\n* The model can handle higher learning rates (because Batch Normalization evades vanishing and exploding gradient).\n\n* Batch Normalization prevents saturable nonlinearity functions to saturate (not that important for us but beneficial in very complex architectures that rely on specific nonlinearities)","7e7499fe":"Take a look at the target distribution:","ef84f9e4":"<a id=\"sec1\"><\/a>\n***\n<h1 style=\"background-color:SteelBlue; color:white\" >-> 1. Prepare The Image Data (As Before)<\/h1>","be0f125b":"## Image Normalization\nNow that we created a batch-normalized neural network, we should normalize the image data itself as well. We could either do this by aplying batch normalization before the first hidden layer, or use `transforms.Normalize` in our data preprocessing pipeline. I will stick to the latter in order to normalize over the whole dataset. ","18c72904":"<a id=\"sec2\"><\/a>\n***\n<h1 style=\"background-color:SteelBlue; color:white\" >-> 2. Batch Normalization Introduction<\/h1>\n\nTo understand the concept of [Batch Normalization](http:\/\/proceedings.mlr.press\/v37\/ioffe15.pdf), we should step back and think about Normalization (often referred to as Standardization) itself.\nNormalization...\n\n* ...refers to adjusting numerical values to be on a common scale.\n\n* ...allows our model to be more generalizing\n\nBatch Normalization utilizes a Normalization technique similar to [Standardization](https:\/\/www.kaggle.com\/milankalkenings\/comprehensive-tutorial-feature-engineering).\nStandardization subtracts the mean of the data and devides it by its standard deviation. The normalization technique used by Batch Normalization subtracts the mean of the data and devides it by the variance of the data\n\n## How does Batch Normalization work?\n\nWhenever we train a deep learning model, the parameters in each layer are adapted over the training iterations. In iteration $\\mathscr{i}$, the parameters of layer $\\mathscr{l}$ will be adapted to generate optimal outputs for the given input. However, training the model will change the input of layer $\\mathscr{l}$, since the parameters of layer $\\mathscr{l-1}$ will be changed as well. Thus, the parameters of layer $\\mathscr{l}$ are already slightly outdated in iteration $\\mathscr{i}+1$. The aforementioned change in the input distribution is reffered to as [Internal Covariance Shift](http:\/\/proceedings.mlr.press\/v37\/ioffe15.pdf) (note: the more general term [Covariance Shift](https:\/\/www.youtube.com\/watch?v=nUUqwaxLnWs&t=64s) refers to changes in our data that require retraining the model).\nBatch Normalization evades this issue by performing Standardization per batch at the given position in the network using the following formulas using $N$ many inputs:\n\n$\\mu_{batch}=\\frac{1}{N}\\sum^N_nx_n$\n\n$\\sigma_{batch}^2=\\frac{1}{N}\\sum^N_n(x_n-\\mu_{batch})^2$\n\n$\\hat x_n=\\frac{x_n-\\mu_{batch}}{\\sqrt{\\sigma^2 + \\epsilon}}$\n\nreturn: $\\gamma \\hat x_n + \\beta$\n\nNote: $\\gamma \\hat x_n + \\beta$ is solely used to allow the network to learn its optimal mean $\\beta$ and deviation $\\gamma$ on its own. Both parameters are learned during the training process.\n\n\n\n\n***\nFor those of you who already made some experiences with Machine Learning Ensembles:\n\nInterpreting each node in our neural network as an **isolated** weak learner in a stacking ensemble, we can easily derive the idea of batch normalization.\nThe nodes (weak learners) at layer $\\mathscr{l}$ don't know wether the outputs of layer $\\mathscr{l-1}$ are the actual input data (in case $\\mathscr{l-1} = 0$) or already processed data from any hidden layer. \nSince we know that normalization in many cases improves the performance of machine learning models by allowing them to be more generalizing, we should enable all of these weak learners to benefit from that. \nThus, normalizing the data for each (or at least for some to have less time complexity) non-input layer seems to be a good idea. \nSince we only feed batches into our neural network, we have no idea about the actual normalization parameters across the whole dataset and instead can only predict them on the given batch - we arrived at the idea of batch normalization.","ce56ce0f":"* [Part 1](https:\/\/www.kaggle.com\/milankalkenings\/explained-tensor-fundamentals-fnn-pytorch)\n* [Part 2](https:\/\/www.kaggle.com\/milankalkenings\/gradient-accumulation-enhance-gpu-capabilities)\n\nThis is the third part of my PyTorch-Series. Make sure to take a look at the earlier episodes of this series if you lack any of the concpets mentioned in this notebook!","00ca73b6":"# PyTorch Journey Part 3\n* [Part 1: Tensor Fundamentals & FNN](https:\/\/www.kaggle.com\/milankalkenings\/pytorch-1-tensor-fundamentals-fnn)\n* [Part 2: CNN & Gradient Accumulation](https:\/\/www.kaggle.com\/milankalkenings\/pytorch-2-cnn-gradient-accumulation)\n\nThis is the third part of my PyTorch-Series. Make sure to take a look at the earlier episodes of this series if you lack any of the concpets mentioned in this notebook!","03a36dea":"<h1 style=\"background-color:SteelBlue; color:white\" >-> Content<\/h1>\n\n## 1. [Prepare The Image Data (As Before)](#sec1)\n## 2. [Batch Normalization Introduction](#sec2)\n## 3. [Benefits of Batch Normalization](#sec3)\n## 4. [Implementing Batch Normalization](#sec4)","29c51ef2":"<div class=\"alert alert-danger\" role=\"alert\">\n    <h3>Feel free to <span style=\"color:red\">comment<\/span> if you have any suggestions   |   motivate me with an <span style=\"color:red\">upvote<\/span> if you like this project.<\/h3>\n<\/div>"}}