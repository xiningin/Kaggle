{"cell_type":{"d80de8a7":"code","147b99a2":"code","45f511e1":"code","bf401f67":"code","d3ac88eb":"code","3a6d9cc1":"code","2e5ec875":"code","3ae37214":"code","3b49b0ca":"code","82d2020e":"code","a0d35fef":"code","d008e31a":"code","5da485c9":"code","aa981f3c":"code","c5f9b0da":"code","4c801a58":"code","4df231df":"code","1cc8c16a":"code","f461547f":"code","e27605f2":"code","d2c9021d":"code","87a75799":"code","90fc4052":"code","4db20772":"code","75e0bc69":"code","9dfe1a16":"code","f00d149f":"code","b66c0c54":"code","7756826b":"markdown","ff7e3f62":"markdown"},"source":{"d80de8a7":"import os\nimport cv2\nimport shutil\nimport random\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D,BatchNormalization,AvgPool2D,Flatten,Dense,Concatenate,Input,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix","147b99a2":"input_data_path='\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images'\nlabels=os.listdir(input_data_path)\nprint(labels)","45f511e1":"labels.pop()\nprint(labels)","bf401f67":"def get_image_path():\n    image_path_list,name_list=[],[]\n    for label in labels:\n        folder_path=os.path.join(input_data_path,label)\n        image_set=random.sample(os.listdir(folder_path),1)\n        for file in image_set:\n            file_path=os.path.join(folder_path,file)\n            image_path_list.append(file_path)\n            name_list.append(label)\n    return image_path_list,name_list\nimage_path_list,name_list=get_image_path()","d3ac88eb":"def plot_classes(image_path_list,name_list):\n    fig=plt.figure(figsize=(16,16))\n    row=1\n    col=2\n    for i in range(len(name_list)):\n        fig.add_subplot(row,col,i+1)\n        plt.axis('off')\n        plt.title(name_list[i])\n        plt.imshow(cv2.imread(image_path_list[i]))\n    plt.show()\nplot_classes(image_path_list,name_list)","3a6d9cc1":"data_dir='\/kaggle\/data'\ntrain_path=os.path.join(data_dir,'train')\nvalid_path=os.path.join(data_dir,'valid')\ntest_path=os.path.join(data_dir,'test')","2e5ec875":"def make_dir():\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n        os.mkdir(train_path)\n        os.mkdir(valid_path)\n        os.mkdir(test_path)\n        for label in labels:\n            os.mkdir(os.path.join(train_path,label))\n            os.mkdir(os.path.join(valid_path,label))\n            os.mkdir(os.path.join(test_path,label))\nmake_dir()","3ae37214":"def check_dir():\n    print(f'{data_dir}: {os.path.isdir(data_dir)}')\n    print(f'{train_path}: {os.path.isdir(train_path)}')\n    print(f'{valid_path}: {os.path.isdir(valid_path)}')\n    print(f'{test_path}: {os.path.isdir(test_path)}')\n    for label in labels:\n        print(f'{os.path.join(train_path,label)}: {os.path.isdir(os.path.join(train_path,label))}')\n        print(f'{os.path.join(valid_path,label)}: {os.path.isdir(os.path.join(valid_path,label))}')\n        print(f'{os.path.join(test_path,label)}: {os.path.isdir(os.path.join(test_path,label))}')\ncheck_dir()","3b49b0ca":"def load_train_images(n=7000):\n    for label in labels:\n        folder_path=os.path.join(input_data_path,label)\n        dest_path=os.path.join(train_path,label)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading the training images from {folder_path} to {dest_path}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\nload_train_images()","82d2020e":"def load_valid_images(n=2000):\n    for label in labels:\n        folder_path=os.path.join(input_data_path,label)\n        dest_path=os.path.join(valid_path,label)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading the validation images from {folder_path} to {dest_path}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\nload_valid_images()","a0d35fef":"def load_test_images(n=1000):\n    for label in labels:\n        folder_path=os.path.join(input_data_path,label)\n        dest_path=os.path.join(test_path,label)\n        image_set=random.sample(os.listdir(folder_path),n)\n        print(f'Loading the validation images from {folder_path} to {dest_path}')\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\nload_test_images()","d008e31a":"target_size=(64,64)\nbatch_size=30\nepochs=35","5da485c9":"datagen=ImageDataGenerator(rescale=1.\/255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\ntrain_data=ImageDataGenerator(rescale=1.\/255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input,horizontal_flip=True).flow_from_directory(directory=train_path,target_size=target_size,classes=labels,batch_size=batch_size)\nvalid_data=datagen.flow_from_directory(directory=valid_path,target_size=target_size,batch_size=batch_size,classes=labels)\ntest_data=datagen.flow_from_directory(directory=test_path,target_size=target_size,batch_size=batch_size,classes=labels,shuffle=False)","aa981f3c":"class MCDropout(tf.keras.layers.Dropout):\n    def call(self,inputs):\n        return super().call(inputs,training=True)","c5f9b0da":"class ResnetUnit(keras.models.Model):\n    def __init__(self,filters,n_conv=4,kernel_size=3,strides=1):\n        super().__init__()\n        self.model=[]\n        for _ in range(n_conv):\n            self.model.append(Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,activation='relu',padding='same'))\n            self.model.append(BatchNormalization())\n        self.model=Sequential(self.model)\n    def call(self,inputs):\n        out=self.model(inputs)\n        out=Concatenate()([out,inputs])\n        return tf.keras.activations.elu(out)","4c801a58":"rate=0.45","4df231df":"def build_resnet(target_size,n_conv=4):\n    steps=int(np.log2(target_size[0]))\n    model=[]\n    model.append(Input(shape=(*target_size,3)))\n    filters=8\n    for i in range(steps):\n        model.append(ResnetUnit(filters=filters,n_conv=n_conv))\n        model.append(AvgPool2D(pool_size=(2,2),strides=2))\n        filters*=2\n    model+=[\n        Flatten(),\n        Dense(units=4096,activation='relu'),\n        MCDropout(rate),\n        Dense(units=4096,activation='relu'),\n        MCDropout(rate),\n        Dense(units=len(labels),activation='softmax'),\n    ]\n    return Sequential(model)","1cc8c16a":"model=build_resnet(target_size=target_size)","f461547f":"model.summary()","e27605f2":"ckpt_path='\/kaggle\/model_checkpoint'\nif not os.path.isdir(ckpt_path):\n    os.mkdir(ckpt_path)","d2c9021d":"model_checkpoint=ModelCheckpoint(filepath=ckpt_path,monitor='val_accuracy',save_best_only=True,save_weights_only=True,mode='max')","87a75799":"model.compile(optimizer=Adam(lr=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","90fc4052":"history=model.fit(x=train_data,epochs=epochs,verbose=2,callbacks=[model_checkpoint],validation_data=valid_data,batch_size=batch_size)","4db20772":"model.load_weights(ckpt_path)","75e0bc69":"def predict(data,num=20):\n    y_prob=np.stack(np.array(model.predict(x=data)) for _ in range(num))\n    y_prob=np.mean(y_prob,axis=0)\n    cm=confusion_matrix(y_true=data.classes,y_pred=np.argmax(y_prob,axis=-1))\n    acc=cm.trace()\/cm.sum()\n    print(f'Accuracy: {acc*100}')","9dfe1a16":"predict(test_data)","f00d149f":"val_loss=history.history['val_loss']\ntrain_loss=history.history['loss']","b66c0c54":"plt.figure()\nplt.plot(train_loss,'bo--')\nplt.plot(val_loss,'ro--')\nplt.title('Loss vs Epochs')\nplt.legend(['Train','Valid'])\nplt.show()","7756826b":"![Resnet.png](attachment:156fec47-f6f8-4413-b707-bdd0556096e2.png)","ff7e3f62":"### Resnet unit architecture"}}