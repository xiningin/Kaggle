{"cell_type":{"41b1c3be":"code","b3492bb7":"code","88f42a9d":"code","9ea084ff":"code","039f7d40":"code","95d85cc2":"code","74c00b9f":"code","9c31cfb7":"code","5bef5159":"markdown","1a7c0331":"markdown","3329abc4":"markdown","57a9fc4f":"markdown","67798cc0":"markdown","3600374c":"markdown","fc3e8d9b":"markdown","e739d6db":"markdown","c59a0959":"markdown"},"source":{"41b1c3be":"import logging\nlogging.getLogger().setLevel(logging.ERROR)\n\nimport os, os.path\nfrom os import listdir\nfrom skimage.io import imread, imsave\nfrom skimage.transform import resize\nfrom skimage import exposure\nimport shutil\nimport numpy as np\nimport cv2\n\nTRAIN_DATA_DIR=\"..\/input\/chest_xray\/chest_xray\/train\/\"\nVALIDATION_DATA_DIR=\"..\/input\/chest_xray\/chest_xray\/val\/\"\nTEST_DATA_DIR=\"..\/input\/chest_xray\/chest_xray\/test\/\"\n\ndir_to_transform = ['train', 'val', 'test']\nclasses = ['NORMAL', 'PNEUMONIA']\n\nif os.path.isdir('..\/transformed'):\n    shutil.rmtree('..\/transformed')\nos.mkdir('..\/transformed')\n\nfor f in dir_to_transform:\n    os.mkdir('..\/transformed\/' + f)\n    for c in classes:\n        input_path = \"..\/input\/chest_xray\/chest_xray\/\" + f + '\/' + c\n        output_path = '..\/transformed\/' + f + '\/' + c\n        os.mkdir(output_path)\n        for image_file in listdir(input_path):\n            if image_file.endswith('.jpeg'):\n                full_input_path = input_path + '\/' + image_file\n                full_output_path = output_path + '\/' + image_file\n                image = imread(full_input_path)\n                image = resize(image, (256, 256), anti_aliasing=False)\n                image = image[32:224,32:224]                \n                image = image\/255.\n                image = exposure.equalize_adapthist(image)\n                imsave(full_output_path, image)              ","b3492bb7":"import matplotlib.pyplot as plt\n\nimage_file = \"IM-0031-0001.jpeg\"\nraw_image = imread(\"..\/input\/chest_xray\/chest_xray\/test\/NORMAL\/\" + image_file)\nraw_image = resize(raw_image, (288, 288), anti_aliasing=False)\ntransformed_image = imread(\"..\/transformed\/test\/NORMAL\/\" +  image_file)\n\nfig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10,10))\naxs[0].imshow(raw_image, cmap='gray')\naxs[0].set_title('Raw image')\naxs[0].axis('off')\naxs[1].imshow(transformed_image, cmap='gray')\naxs[1].set_title('CLAHE image')\naxs[1].axis('off')\nplt.show()","88f42a9d":"from keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPool2D, Add, Concatenate, Subtract, Dot, Average, Lambda, SeparableConv2D, DepthwiseConv2D\nfrom keras import regularizers\n\nfrom keras import backend as K\n\ninput_shape = (192, 192, 3)\ninput_layer = Input(shape=input_shape, name='input_layer')\n\noutput = Conv2D(48, (1,1), activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01))(input_layer)\noutput = MaxPool2D(pool_size=(2, 2))(output)\noutput = BatchNormalization()(output)\noutput = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01))(output)\noutput = MaxPool2D(pool_size=(2, 2))(output)\noutput = BatchNormalization()(output)\noutput = Conv2D(16, (5,5), activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01))(output)\noutput = BatchNormalization()(output)\noutput = Flatten()(output)\noutput = Dense(units=256, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01))(output)\noutput = BatchNormalization()(output)\noutput = Dropout(rate=0.2)(output)\noutput = Dense(units=256, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.01))(output)\noutput = BatchNormalization()(output)\noutput = Dropout(rate=0.2)(output)\noutput = Dense(units=1, activation='sigmoid')(output)\n\nmodel = Model(inputs=input_layer, outputs=output)\nmodel.summary()","9ea084ff":"from keras.preprocessing.image import ImageDataGenerator\n\nclass Generators():\n    train_dir = None\n    validation_dir = None\n    test_dir = None\n\n    def __init__(self, train_dir, validation_dir, test_dir):\n        self.train_dir = train_dir\n        self.validation_dir = validation_dir\n        self.test_dir = test_dir\n\n    def train_generator(self, image_size, batch_size=32):\n        datagen = ImageDataGenerator(rescale=1.\/255,\n                                     rotation_range=8,\n                                     width_shift_range=25,\n                                     height_shift_range=25,\n                                     zoom_range=(0.95, 1.1),\n                                     brightness_range=(0.8,1.2),\n                                     shear_range=10,\n                                     fill_mode = \"constant\",\n                                     horizontal_flip=True,\n                                     vertical_flip=False,\n                                     cval=0\n                                    )\n        data_generator = datagen.flow_from_directory(\n            self.train_dir,\n            target_size=(image_size, image_size),\n            batch_size=batch_size,\n            class_mode='binary')\n        return data_generator\n\n    def validation_generator(self, image_size, batch_size=32):\n        datagen = ImageDataGenerator(rescale=1.\/255)\n        data_generator = datagen.flow_from_directory(\n            self.validation_dir,\n            target_size=(image_size, image_size),\n            batch_size=batch_size,\n            class_mode='binary')\n        return data_generator     \n\n    def test_generator(self, image_size, batch_size=1, shuffle=False):\n        datagen = ImageDataGenerator(rescale=1.\/255)\n        data_generator = datagen.flow_from_directory(\n            self.test_dir,\n            target_size=(image_size, image_size),\n            batch_size=batch_size,\n            shuffle=shuffle,\n            class_mode='binary')\n        return data_generator","039f7d40":"from keras.optimizers import Adam, Nadam, SGD\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\noptimizer = Adam()\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\nmodelCheckpoint = ModelCheckpoint(monitor='val_loss', filepath=\"simple_cnn_model\", save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.000001, verbose=1)\nearlyStopping = EarlyStopping(patience=11, restore_best_weights=True)\n\nTRAIN_DATA_DIR=\"..\/transformed\/train\/\"\nVALIDATION_DATA_DIR=\"..\/transformed\/val\/\"\nTEST_DATA_DIR=\"..\/transformed\/test\/\"\n\ngenerators = Generators(TRAIN_DATA_DIR, VALIDATION_DATA_DIR, TEST_DATA_DIR)\ntrain_generator = generators.train_generator(192, batch_size=32)\nvalidation_generator = generators.validation_generator(192, batch_size=16)\n\nmodel.fit_generator(train_generator, \n                    epochs=100,\n                    steps_per_epoch=100, \n                    validation_data=validation_generator, \n                    validation_steps=1, \n                    callbacks=[reduce_lr, modelCheckpoint, earlyStopping], \n                    verbose=1, \n                    class_weight={0:1.0, 1:0.33})","95d85cc2":"\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve\n\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\n\n\nclass ResultUtils():\n    def plot_confusion_matrix(self, predicted_classes, true_classes):\n        cf_matrix = confusion_matrix(true_classes, predicted_classes)\n        plot_confusion_matrix(conf_mat=cf_matrix, figsize=(5, 5))\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.show()\n\n        acc = accuracy_score(true_classes, predicted_classes)*100\n        tn, fp, fn, tp = confusion_matrix(true_classes, predicted_classes).ravel()\n\n        print('Accuracy: {0:.2f}%'.format(acc))\n        print('Precision: {0:.2f}%'.format(tp\/(tp+fp)*100))\n        print('Recall: {0:.2f}%'.format(tp\/(tp+fn)*100))\n        \n    def find_ratio_of_normal_class(self, true_classes):\n        total = len(true_classes)\n        normal = np.count_nonzero(true_classes != 1)\n        return float(normal)\/total\n\nresultUtils = ResultUtils()\n\ntest_generator = generators.test_generator(192, batch_size=1)\ntrue_classes = test_generator.classes\n\npredicted_classes = model.predict_generator(test_generator, 624, verbose=1)\n\npercentage_of_normal = resultUtils.find_ratio_of_normal_class(true_classes)\npredicted_classes_after_threshold = predicted_classes  > np.percentile(predicted_classes, percentage_of_normal*100)\n\nresultUtils.plot_confusion_matrix(true_classes, predicted_classes_after_threshold)","74c00b9f":"TEST_DATA_DIR=\"..\/transformed\/test\/\"\n\ntta_steps = 7\npredictions = []\n\ndatagen = ImageDataGenerator(rescale=1.\/255,\n                                     rotation_range=12,\n                                     width_shift_range=15,\n                                     height_shift_range=15,\n                                     zoom_range=(0.95, 1.05),\n                                     brightness_range=(0.8,1.2),\n                                     shear_range=10,\n                                     fill_mode = \"constant\",\n                                     horizontal_flip=True,\n                                     vertical_flip=False,\n                                     cval=0\n                                    )\ndata_generator = datagen.flow_from_directory(\n    TEST_DATA_DIR,\n    target_size=(192, 192),\n    batch_size=1,\n    class_mode='binary',\n    shuffle=False)\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(data_generator, 624, verbose=1)\n    predictions.append(preds)\n\npredicted_classes = np.mean(predictions, axis=0)\n\nresultUtils = ResultUtils()\ntrue_classes = test_generator.classes\n\npercentage_of_normal = resultUtils.find_ratio_of_normal_class(true_classes)\npredicted_classes_after_threshold = predicted_classes  > 0.85\n\nresultUtils.plot_confusion_matrix(true_classes, predicted_classes_after_threshold)","9c31cfb7":"import shap\n\nTRAIN_DATA_DIR=\"..\/transformed\/train\/\"\nVALIDATION_DATA_DIR=\"..\/transformed\/val\/\"\nTEST_DATA_DIR=\"..\/transformed\/test\/\"\n\ngenerators = Generators(TRAIN_DATA_DIR, VALIDATION_DATA_DIR, TEST_DATA_DIR)\n\ntrain_generator = generators.train_generator(192, batch_size=100)\ntest_generator = generators.test_generator(192, batch_size=5, shuffle=True)\n\ntrain_images = next(train_generator)[0]\n\ntest_set = next(test_generator)\ntest_images = test_set[0]\ntest_images_labels = test_set[1]\n\ntest_images_labels = np.reshape(test_images_labels, (5,1))\ntest_images_labels = np.where(test_images_labels > 0.5, 'PNEUMONIA', 'NORMAL')\n\ne = shap.DeepExplainer(model, train_images)\nshap_values = e.shap_values(test_images)\nshap.image_plot(shap_values, test_images, labels=test_images_labels)","5bef5159":"**2. Neural network model**\n\n* We don't want to recognize whole image as a 'chest with pneumonia'. We rather want to discover some patterns which would indicate that there's pneumonia on the image. So we don't need to build long conv structures. \n* The dataset is small and unbalanced. We will use L1+L2 regularization and droput to prevent overfitting.","1a7c0331":"* We can increase Precision and Recall using Test Time Augmentation.","3329abc4":"* In the predicted set we can calculate a percentile of normal classes percentage, it will be the threshold. Everything above this value should be predicted as PNEUMONIA. \n* Achieved score is quite good, Precision and Recall is around 92%.","57a9fc4f":"* The difference between raw and normalized image:","67798cc0":"**1. Preparing dataset**\n\n* The images come from different distributions so before training they will be normalized by [CLAHE](https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.exposure.html#equalize-adapthist).\n* All images will be zoomed a bit.\n* Simple data augmentation techniques will be used which are available in ImageDataGenerator class.","3600374c":"**3. Traning**\n\n* We will use callbacks for reducing learning rate and save the best model, also early stopping is added so we can set number of epoch to 100 (it will end ealier anyway).\n* The ratio between normal and pneumonia dataset is 1:3","fc3e8d9b":"** 4. Results **","e739d6db":"When we browse kernels which use Chest X-Ray Images dataset we can see that the most of solutions are based on transfer learning. It is the simplest approach to the problem and not very innovating. These models reach Recall on > 95% level, but mostly predict everyhing as PNEUMONIA.\n\nIn this kernel I checked what result we can achive with simple network 3xConv + 2xFC with some techniques which prevent overfitting.","c59a0959":"**5. Explaing the model using shap**\n\n* We will use [SHAP](https:\/\/github.com\/slundberg\/shap) to check what exactly this model is predicting."}}