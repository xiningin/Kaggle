{"cell_type":{"91e7f7d6":"code","a341eb67":"code","78609d3e":"code","168a572c":"code","d14d5193":"code","c61cfda1":"code","62a579fb":"code","8eebffa7":"code","202f785e":"code","e985f3a8":"code","6239f592":"code","b6d26c89":"code","7aa89ce2":"code","cf1151e0":"code","be0f64cc":"markdown","8e751512":"markdown","d254528e":"markdown","99455529":"markdown","6eaa7e34":"markdown"},"source":{"91e7f7d6":"!pip install imageai","a341eb67":"!wget \"https:\/\/github.com\/OlafenwaMoses\/ImageAI\/releases\/download\/essential-v4\/pretrained-yolov3.h5\"","78609d3e":"!wget 'https:\/\/github.com\/OlafenwaMoses\/ImageAI\/releases\/download\/essentials-v5\/resnet50_coco_best_v2.1.0.h5'","168a572c":"import numpy as np\nimport os\nimport shutil\nfrom pathlib import Path\nfrom PIL import Image","d14d5193":"root_annots_path = '..\/input\/hard-hat-detection\/annotations\/'\nroot_images_path = '..\/input\/hard-hat-detection\/images\/'\n\nannots_path = sorted([i for i in Path(root_annots_path).glob('*.xml')])\nimages_path = sorted([i for i in Path(root_images_path).glob('*.png')])\n\nn_imgs = len(images_path)\n\nclasses = np.array([\"helmet\",\"head\",\"person\"])","c61cfda1":"with open(annots_path[500], 'r') as f:\n    print(f.read())","62a579fb":"os.makedirs('imageai\/data\/train\/images', exist_ok=True)\nos.makedirs('imageai\/data\/train\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/validation\/images', exist_ok=True)\nos.makedirs('imageai\/data\/validation\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/test\/images', exist_ok=True)\nos.makedirs('imageai\/data\/test\/annotations', exist_ok=True)","8eebffa7":"n_imgs = 300\nn_split = n_imgs \/\/ 20\n\n\nfor i, (annot_path, img_path) in enumerate(zip(annots_path, images_path)):    \n    if i > n_imgs:\n        break\n    # train-val-test split\n    if i < n_split:\n        shutil.copy(img_path, 'imageai\/data\/test\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/test\/annotations\/' + annot_path.parts[-1])\n    elif n_split <= i < n_split*5:\n        shutil.copy(img_path, 'imageai\/data\/validation\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/validation\/annotations\/' + annot_path.parts[-1])\n    else:\n        shutil.copy(img_path, 'imageai\/data\/train\/images\/' + img_path.parts[-1])\n        shutil.copy(annot_path, 'imageai\/data\/train\/annotations\/' + annot_path.parts[-1])","202f785e":"print(len(list(Path('imageai\/data\/train\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/validation\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/test\/annotations\/').glob('*.xml'))))","e985f3a8":"from imageai.Detection.Custom import DetectionModelTrainer\n\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\/\")\ntrainer.setTrainConfig(object_names_array=[\"helmet\",\"head\",\"person\"],\n                       batch_size=8,\n                       num_experiments=10,\n                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n\ntrainer.trainModel()","6239f592":"from imageai.Detection.Custom import DetectionModelTrainer\n\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\/\")\nmetrics = trainer.evaluateModel(model_path=\"imageai\/data\/models\/\",\n                                json_path=\"imageai\/data\/json\/detection_config.json\",\n                                iou_threshold=0.2,\n                                object_threshold=0.3,\n                                nms_threshold=0.5)","b6d26c89":"!wget \"https:\/\/www.lemoniteur.fr\/mediatheque\/9\/1\/1\/002134119_620x393_c.jpeg\"","7aa89ce2":"from imageai.Detection.Custom import CustomObjectDetection\n\ndetector = CustomObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"imageai\/data\/models\/detection_model-ex-010--loss-0040.896.h5\")\ndetector.setJsonPath(\"imageai\/data\/json\/detection_config.json\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(minimum_percentage_probability=50,\n                                             input_image=\"002134119_620x393_c.jpeg\",\n                                             output_image_path=\"detected.jpg\")\nfor detection in detections:\n    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])","cf1151e0":"Image.open('detected.jpg')","be0f64cc":"On g\u00e9n\u00e8re un certain nombre de mod\u00e8les qu'on peut \u00e9valuer :","8e751512":"On t\u00e9l\u00e9charge une image :","d254528e":"Notre mod\u00e8le a su apprendre et d\u00e9tecte bien les casques.","99455529":"# D\u00e9tection du port du masque dans des images","6eaa7e34":"Et on va d\u00e9tecter la pr\u00e9sence de casques sur l'image :"}}