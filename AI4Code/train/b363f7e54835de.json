{"cell_type":{"af331e9e":"code","8073cf64":"code","6211d5e5":"code","8fdbb446":"code","4eaa2546":"code","a1a5dc6e":"code","2f5986e4":"code","892f1706":"code","ad6d8616":"code","c66e158e":"code","5dc4faf2":"code","05b48cbb":"code","e47dfa3d":"code","f49cac7c":"code","1aaea380":"code","6e736eef":"code","3ab3aa26":"markdown","72f931f1":"markdown","c4a3accc":"markdown","8f880c04":"markdown","f80a8580":"markdown","41a24751":"markdown","a0349e24":"markdown","50d7e4c0":"markdown","2cd41577":"markdown","f9eb51f9":"markdown","0ff4074b":"markdown"},"source":{"af331e9e":"import torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets,transforms\nfrom torch import nn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.models as models","8073cf64":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","6211d5e5":"IMGSIZE = 90\ntransform1 = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(0.2),\n                                transforms.ToTensor(),\n                                transforms.Resize((IMGSIZE,IMGSIZE))\n                               ])","8fdbb446":"full_data = torchvision.datasets.ImageFolder(root = '..\/input\/flowers-recognition\/flowers\/flowers', transform = transform1)","4eaa2546":"classes = full_data.classes\nprint(\"Classes:\",classes)\nnum_classes = len(full_data.classes)\nprint(\"Number of Classes:\",num_classes)","a1a5dc6e":"train_data, test_data = torch.utils.data.random_split(full_data, [3458, 865])  # In 80% & 20% ratio","2f5986e4":"train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 46, shuffle = True)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 46, shuffle = True)","892f1706":"def normalize_image(image):\n    image_min = image.min()\n    image_max = image.max()\n    image.clamp_(min = image_min, max = image_max)\n    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n    return image\n\ndef plot_images(images, labels, classes, normalize = True):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize = (10, 10))\n\n    for i in range(rows*cols):\n\n        ax = fig.add_subplot(rows, cols, i+1)\n        \n        image = images[i]\n\n        if normalize:\n            image = normalize_image(image)\n\n        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n        ax.set_title(classes[labels[i]])\n        ax.axis('off')","ad6d8616":"N_IMAGES = 9\n\nimages, labels = zip(*[(image, label) for image, label in [train_data[i] for i in range(N_IMAGES)]])\n\nclasses = full_data.classes\n\nplot_images(images, labels, classes)","c66e158e":"class ModConvNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super(ModConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer5 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.layer6 = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.fc1 = nn.Linear(1024, 256)\n        self.fc2 = nn.Linear(256, 512)\n        self.fc3 = nn.Linear(512, num_classes)\n\n        \n    def forward(self, x):\n        o = self.layer1(x)\n        o = self.layer2(o)\n        o = self.layer3(o)\n        o = self.layer4(o)\n        o = self.layer5(o)\n        o = self.layer6(o)\n        o = o.reshape(o.size(0), -1)\n        o = self.fc1(o)\n        o = F.dropout(o, training=self.training)\n        o = self.fc2(o)\n        o = F.dropout(o, training=self.training)\n        o = self.fc3(o)\n        return F.log_softmax(o,dim=1)\n\nmodel = ModConvNet(num_classes).to(device)","5dc4faf2":"# Custom model\ndef Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model):\n    \n    TrainLoss = []\n    TrainAcc = []\n    TestLoss = []\n    TestAcc = []\n    \n    total_step = len(train_loader)\n\n    for epoch in range(epochs):\n        trainAcc = 0\n        testAcc = 0\n        for i, (images, labels) in enumerate(train_loader):\n            model.train()\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            trainloss = criteria(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            trainloss.backward()\n            optimizer.step()\n\n            # Checking accuracy\n            preds = outputs.data.max(dim=1,keepdim=True)[1]\n            trainAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n\n        trainAcc = trainAcc\/len(train_loader.dataset) * 100\n\n        for i, (images, labels) in enumerate(test_loader):\n            model.eval()\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            testloss = criteria(outputs, labels)\n\n            # Checking accuracy\n            preds = outputs.data.max(dim=1,keepdim=True)[1]\n            testAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n\n        testAcc = testAcc\/len(test_loader.dataset) * 100\n\n        print(\"Epoch {} =>  Train Loss : {trainloss:.2f};   Train Accuracy : {trainAcc:.2f}%;   Test Loss : {testloss:.2f};   Test Accuracy : {testAcc:.2f}%\".format(epoch+1, trainloss=trainloss.item(), trainAcc=trainAcc, testloss=testloss.item(), testAcc=testAcc))\n\n        TrainLoss.append(trainloss)\n        TrainAcc.append(trainAcc)\n\n        TestLoss.append(testloss)\n        TestAcc.append(testAcc)\n        \n    plt.plot(range(epochs),TrainAcc)\n    plt.plot(range(epochs),TestAcc)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.title(\"Accuracy of Modified CNN\")\n    plt.legend([\"Training Accuracy\", \"Testing Accuracy\"])\n    plt.show()\n    \n    plt.plot(range(epochs),TrainAcc)\n    plt.plot(range(epochs),TestAcc)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.title(\"Loss of Modified CNN\")\n    plt.legend([\"Training Loss\", \"Testing Loss\"])\n    plt.show()\n    \n    return TrainAcc, TestAcc, TrainLoss, TestLoss","05b48cbb":"model = ModConvNet(num_classes).to(device)\ncriteria = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-5,weight_decay=1e-5)\nepochs = 10\n\nTrainAcc, TestAcc, TrainLoss, TestLoss = Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model)","e47dfa3d":"alexnet = torchvision.models.alexnet(pretrained=True)\nalexnet.classifier[6].out_features = 5\n\nfor param in alexnet.features.parameters(): \n    param.requires_grad = False\n\nalexnet = alexnet.cuda()\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(alexnet.parameters(),lr=1e-5,weight_decay=1e-5)\nepochs = 10\n\nTrainAcc, TestAcc, TrainLoss, TestLoss = Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model=alexnet)","f49cac7c":"vgg16 = torchvision.models.vgg16(pretrained=True)\nvgg16.classifier[6].out_features = 5\n\nfor param in vgg16.features.parameters(): \n    param.requires_grad = False\n\nvgg16 = vgg16.cuda()\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg16.parameters(),lr=1e-5,weight_decay=1e-5)\nepochs = 10\n\nTrainAcc, TestAcc, TrainLoss, TestLoss = Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model=vgg16)","1aaea380":"resnet18 = models.resnet18(pretrained=True)\n\nq = resnet18.fc.in_features\nresnet18.fc = nn.Linear(in_features=q, out_features = 5)\n\nresnet18 = resnet18.cuda()\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(),lr=1e-5,weight_decay=1e-5)\nepochs=10\n\nTrainAcc, TestAcc, TrainLoss, TestLoss = Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model=resnet18)","6e736eef":"resnet34 = models.resnet34(pretrained=True)\n\nq = resnet34.fc.in_features\nresnet34.fc = nn.Linear(in_features=q, out_features = 5)\n\nresnet34 = resnet34.cuda()\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet34.parameters(),lr=1e-5,weight_decay=1e-5)\nepochs=10\n\nTrainAcc, TestAcc, TrainLoss, TestLoss = Train_and_Test(criteria, optimizer, epochs, train_loader, test_loader, model=resnet34)","3ab3aa26":"# **Modified CNN**","72f931f1":"# VGG16","c4a3accc":"**Models Used :**\n*   **Modified CNN**\n*   **alexnet**\n*   **vgg16**\n*   **resnet18**\n*   **resnet34**","8f880c04":"# **Importing Some Basic Libraries**","f80a8580":"# ResNet18","41a24751":"# **Function for training and testing Models**","a0349e24":"# By seeing the trends in the graphs and the accuracies and loss, we can say that ResNet34 is performing best under 10 epochs.","50d7e4c0":"# AlexNet","2cd41577":"# **Importing Data**","f9eb51f9":"# Custom CNN","0ff4074b":"# **Initializing GPU Usage**"}}