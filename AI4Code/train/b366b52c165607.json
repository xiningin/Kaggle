{"cell_type":{"99e2feb8":"code","4ad83e18":"code","0a729550":"code","d076f9ef":"code","6831a935":"markdown","b4a54c26":"markdown","2cb19431":"markdown","55c9a0f2":"markdown"},"source":{"99e2feb8":"from os import listdir\nfrom os.path import join\n\nimport numpy as np\n\n\ndef compute_det_curve(target_scores, nontarget_scores):\n\n    n_scores = target_scores.size + nontarget_scores.size\n    all_scores = np.concatenate((target_scores, nontarget_scores))\n    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n\n    # Sort labels based on scores\n    indices = np.argsort(all_scores, kind='mergesort')\n    labels = labels[indices]\n\n    # Compute false rejection and false acceptance rates\n    tar_trial_sums = np.cumsum(labels)\n    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n\n    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums \/ target_scores.size))  # false rejection rates\n    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums \/ nontarget_scores.size))  # false acceptance rates\n    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n\n    return frr, far, thresholds\n\n\ndef compute_eer(target_scores, nontarget_scores):\n    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n    abs_diffs = np.abs(frr - far)\n    min_index = np.argmin(abs_diffs)\n    eer = np.mean((frr[min_index], far[min_index]))\n    return eer, thresholds[min_index]\n\n\ndef log_loss(y_true, y_pred, eps=1e-15):\n\n    y_true = y_true[:, np.newaxis]\n    y_pred = y_pred[:, np.newaxis]\n\n    y_true = np.append(1 - y_true, y_true, axis=1)\n    y_pred = np.append(1 - y_pred, y_pred, axis=1)\n\n    y_pred = np.clip(y_pred, eps, 1 - eps)\n\n    y_pred \/= y_pred.sum(axis=1)[:, np.newaxis]\n    loss = -(y_true * np.log(y_pred)).sum(axis=1)\n\n    return np.average(loss)","4ad83e18":"methods_name = ['Deepfakes', 'FaceSwap', 'Face2Face', 'NeuralTextures']\nmethods_size = []\nsubmission = []\n\nvideos = '\/kaggle\/input\/faceforensics\/original_sequences\/youtube\/c23\/videos'\nfiles = [join(videos, filename) for filename in listdir(videos)]\nmethods_size.append(len(files))\nsubmission.extend(sorted(files))\nprint(len(files), 'Original')\n\nfor method in methods_name:\n    videos = f'\/kaggle\/input\/faceforensics\/manipulated_sequences\/{method}\/c23\/videos'\n    files = [join(videos, filename) for filename in listdir(videos)]\n    methods_size.append(len(files))\n    submission.extend(sorted(files))\n    print(len(files), method)","0a729550":"labels = np.ones(len(submission), dtype=np.float32) \/ 2","d076f9ef":"offset = methods_size[0]\noriginal_labels = labels[:offset]\nfor method, size in zip(methods_name, methods_size[1:]):\n    fake_labels = labels[offset:offset + size]\n    eer, _ = compute_eer(fake_labels, original_labels)\n    ll = log_loss(np.concatenate([np.zeros_like(original_labels), np.ones_like(fake_labels)]),\n                  np.concatenate([original_labels, fake_labels]))\n    print(f'{method:15s} EER {eer:.4f} LL {ll:.4f}')\n    offset += size","6831a935":"# Result","b4a54c26":"# Introduction\n\nThis kernel demonstrates how to compute Equal Error Rate (EER) and Log Loss (LL) for the [FaceForensics++](https:\/\/www.kaggle.com\/sorokin\/faceforensics) dataset.","2cb19431":"# Prediction","55c9a0f2":"# Inputs"}}