{"cell_type":{"4e4bb2dc":"code","ede8f999":"code","fa79eb4f":"code","d1a38dfe":"code","6306321a":"code","8cf7c0e8":"code","109c270f":"code","dde7e264":"code","81139cdc":"code","169ac461":"code","4a9db4a1":"code","233fdd20":"code","e2d3a0db":"code","11a749e8":"code","8d55a3c3":"code","7bea5be1":"code","15e36ece":"code","a3be9ee6":"code","811af8bb":"code","45989fd6":"code","8e7748d8":"code","bc5185ef":"code","24e1f2ab":"code","400cda82":"code","8f782e88":"code","64b13497":"code","c4994339":"code","e2c43533":"code","03dc70b8":"code","9b13f924":"code","558b1958":"code","5dc56ec1":"code","0d788a1b":"code","fcd130a8":"code","4dd359d9":"code","c59e968d":"code","390235d9":"code","4ec30e29":"code","e04e0327":"code","b8c06d33":"code","2c0adebb":"code","ff729156":"code","0cb2ba9b":"code","b6bdad8e":"code","26a53ed7":"code","148196be":"code","7f4c7e2f":"code","a2c35272":"code","615a1181":"code","8eba61c7":"code","a3c15d53":"code","3b4e11bd":"code","6d87b50d":"code","00249b08":"code","2c6825c7":"code","58ae4177":"code","a58c272a":"code","5e07af42":"code","690ff773":"code","9e4c908b":"code","07a0cd27":"code","4eaeadca":"code","24536a1d":"code","fe726572":"code","2700a976":"code","6f9c0f4f":"code","94679c72":"code","5e27f469":"code","a8e84f45":"code","5499ee00":"code","258dbf34":"code","4f90a6e6":"code","942185d7":"code","9275c30a":"code","af70b90f":"code","90aa8e3e":"code","cc55a337":"code","5377cec2":"code","aec75cbc":"markdown","4b769e95":"markdown","70aff414":"markdown","9cc99eaf":"markdown","c7ab4c2a":"markdown","eae5aa7d":"markdown","f784f124":"markdown","17e24e6f":"markdown","565206cc":"markdown","ba2b99bf":"markdown","3eed5c05":"markdown","e8e96e5e":"markdown","bec3fc06":"markdown","50e07efc":"markdown","2ff46ad7":"markdown","521fb59f":"markdown","29c08dd7":"markdown","8859042f":"markdown","0c056085":"markdown","a706af30":"markdown","6e4003a3":"markdown","aa58e3cd":"markdown","dc83c760":"markdown","1222aa2e":"markdown","84dfe2d1":"markdown","10a81318":"markdown","6a50838c":"markdown","583ccaca":"markdown","357c45cf":"markdown","3fcae9c0":"markdown","c48bba5a":"markdown","b56cfbe4":"markdown","3d4d951d":"markdown","0de4104c":"markdown","45968016":"markdown","fae693b5":"markdown","177cbb1e":"markdown","3259de48":"markdown","5c867399":"markdown","8640abb7":"markdown","f8789e05":"markdown","e0988d1c":"markdown","2d6ef695":"markdown","1f07a5ce":"markdown"},"source":{"4e4bb2dc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport math\nimport gc\nimport datetime as dt\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n### Modelling:\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\n","ede8f999":"dtypes = {'Id':'int64',\n         'MSSubClass':'category',\n         'MSZoning':'category',\n         'LotFrontage':'object',\n         'LotArea':'float64',\n         'Street':'category',\n         'Alley':'category',\n         'LotShape':'category',\n         'LandContour':'category',\n         'Utilities':'category',\n         'LotConfig':'category',\n         'LandSlope':'category',\n         'Neighborhood':'category',\n         'Condition1':'category',\n         'Condition2':'category',\n         'BldgType':'category',\n         'HouseStyle':'category',\n         'OverallQual':'category',\n         'OverallCond':'category',\n         'YearBuilt':'int64',\n         'YearRemodAdd':'int64',\n         'RoofStyle':'category',\n         'RoofMatl':'category',\n         'Exterior1st':'category',\n         'Exterior2nd':'category',\n         'MasVnrType':'category',\n         'MasVnrArea':'object',\n         'ExterQual':'category',\n         'ExterCond':'category',\n         'Foundation':'category',\n         'BsmtQual':'category',\n         'BsmtCond':'category',\n         'BsmtExposure':'category',\n         'BsmtFinType1':'category',\n         'BsmtFinSF1':'float32',\n         'BsmtFinType2':'category',\n         'BsmtFinSF2':'float32',\n         'BsmtUnfSF':'float32',\n         'TotalBsmtSF':'float32',\n         'Heating':'category',\n         'HeatingQC':'category',\n         'CentralAir':'category',\n         'Electrical':'category',\n         '1stFlrSF':'int64',\n         '2ndFlrSF':'int64',\n         'LowQualFinSF':'float32',\n         'GrLivArea':'float32',\n         'BsmtFullBath':'float32',\n         'BsmtHalfBath':'float32',\n         'FullBath':'int64',\n         'HalfBath':'int64',\n         'BedroomAbvGr':'int64',\n         'KitchenAbvGr':'int64',\n         'KitchenQual':'category',\n         'TotRmsAbvGrd':'int64',\n         'Functional':'category',\n         'Fireplaces':'int8',\n         'FireplaceQu':'category',\n         'GarageType':'category',\n         'GarageYrBlt':'object',\n         'GarageFinish':'category',\n         'GarageCars':'float32',\n         'GarageArea':'float32',\n         'GarageQual':'category',\n         'GarageCond':'category',\n         'PavedDrive':'category',\n         'WoodDeckSF':'float32',\n         'OpenPorchSF':'float32',\n         'EnclosedPorch':'float32',\n         '3SsnPorch':'float32',\n         'ScreenPorch':'float16',\n         'PoolArea':'float16',\n         'PoolQC':'category',\n         'Fence':'category',\n         'MiscFeature':'category',\n         'MiscVal':'float16',\n         'MoSold':'float16',\n         'YrSold':'float16',\n         'SaleType':'category',\n         'SaleCondition':'category',\n         'SalePrice':'int64'}","fa79eb4f":"kaggle=1\nif kaggle==0:\n    train=pd.read_csv('train.csv',dtype=dtypes)\n    test=pd.read_csv('test.csv',dtype=dtypes)\nelse:\n    train=pd.read_csv('..\/input\/train.csv',dtype=dtypes)\n    test=pd.read_csv('..\/input\/test.csv',dtype=dtypes)\n","d1a38dfe":"print(\"Train dataset has {} rows and {} columns\".format(train.shape[0],train.shape[1]))","6306321a":"print(\"Test dataset has {} rows and {} columns\".format(test.shape[0],test.shape[1]))","8cf7c0e8":"train.info()","109c270f":"plt.figure(figsize=(8,8))\nax=sns.distplot(train['SalePrice'],color='red')\nax.set_xlabel('SalePrice')\nax.set_title('Distribution of SalePrice')","dde7e264":"print(\"Train data has sale price from staring year {} to ending year {}\".format(min(train['YearBuilt']),max(train['YearBuilt'])))","81139cdc":"print(\"Test data has sale price from staring year {} to ending year {}\".format(min(test['YearBuilt']),max(test['YearBuilt'])))","169ac461":"year_sale=train.groupby('YearBuilt')['SalePrice'].median()\nyear_sale.plot()","4a9db4a1":"train.isnull().values.any()","233fdd20":"test.isnull().values.any()","e2d3a0db":"def check_null(df):\n    null=df.isnull().sum()\n    focus_columns=null[null>0]\n    \n    return(focus_columns)","11a749e8":"focus_columns_train=check_null(train)\nfocus_columns_test=check_null(test)\nprint(\"Columns to focus in train dataset:\\n {} \\nColumns to focus in test dataset:\\n {}\".format(focus_columns_train,focus_columns_test))","8d55a3c3":"train_clean=train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1)\ntest_clean=test.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1)","7bea5be1":"impute_columns_train=focus_columns_train[focus_columns_train<500]\nprint(\"There are {} columns to be imputed \\n The columns are \\n{}\".format(len(impute_columns_train),impute_columns_train.index))","15e36ece":"train_clean[['LotFrontage', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical',\n       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual',\n       'GarageCond']].info()","a3be9ee6":"### Inspited from https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n###https:\/\/www.kaggle.com\/tunguz\/more-effective-ridge-lgbm-script-lb-0-44341-2\nfor col in ['LotFrontage','MasVnrArea','GarageYrBlt']:\n    train_clean[col]=train_clean[col].fillna(train_clean[col].median()).astype('float16')","811af8bb":"for col in ['GarageType','GarageFinish','GarageQual','GarageCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MasVnrType']:\n    train_clean[col]=train_clean[col].cat.add_categories('NA')\n    train_clean[col]=train_clean[col].fillna('NA')","45989fd6":"train_clean['Electrical'].value_counts()","8e7748d8":"train_clean['Electrical']=train_clean['Electrical'].fillna('SBrkr')","bc5185ef":"del impute_columns_train\ndel focus_columns_train\ntrain_clean.isnull().values.any()","24e1f2ab":"impute_columns_test=focus_columns_test[focus_columns_test<500]\nprint(\"There are {} columns to be imputed \\n The columns are \\n{}\".format(len(impute_columns_test),impute_columns_test.index))","400cda82":"test_clean[['MSZoning', 'LotFrontage', 'Utilities', 'Exterior1st', 'Exterior2nd',\n       'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',\n       'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual',\n       'Functional', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars',\n       'GarageArea', 'GarageQual', 'GarageCond', 'SaleType']].info()","8f782e88":"for col in ['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageCars','GarageArea','LotFrontage','MasVnrArea','GarageYrBlt']:\n    test_clean[col]=test_clean[col].fillna(test_clean[col].median()).astype('float16')","64b13497":"for col in ['GarageType','GarageFinish','GarageQual','GarageCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MasVnrType']:\n    test_clean[col]=test_clean[col].cat.add_categories('NA')\n    test_clean[col]=test_clean[col].fillna('NA')","c4994339":"## https:\/\/stackoverflow.com\/questions\/25239958\/impute-categorical-missing-values-in-scikit-learn\n\nfor col in ['Exterior1st','Exterior2nd','Utilities','MSZoning','SaleType','Functional','KitchenQual']:\n    print(f'Imputing col {col} with {test_clean[col].value_counts().index[0]}')\n    test_clean[col]=test_clean[col].fillna(test_clean[col].value_counts().index[0])","e2c43533":"test_clean.isnull().values.any()","03dc70b8":"#test_clean.info()","9b13f924":"del train\ndel test","558b1958":"\nntrain=train_clean.shape[0]\nall_df=pd.concat([train_clean,test_clean])","5dc56ec1":"for col in ['Condition2', 'Electrical', 'Exterior1st', 'Exterior2nd', 'GarageQual','Heating', 'HouseStyle', 'RoofMatl', 'Utilities']:\n    print(f'Converting {col} from object to category datatype')\n    all_df[col]=all_df[col].astype('category')","0d788a1b":"categories = all_df.select_dtypes('category')","fcd130a8":"for  cat in categories:\n    print(f'\\n{cat} has {all_df[cat].nunique()} categories')","4dd359d9":"def one_hot_encoder(df, nan_as_category = True):\n    original_columns = list(df.columns)\n    categorical_columns = [col for col in df.columns if df[col].dtype.name == 'category']\n    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n    new_columns = [c for c in df.columns if c not in original_columns]\n    return df, new_columns","c59e968d":"all_df,oh_new_cols=one_hot_encoder(all_df)","390235d9":"all_df.info()","4ec30e29":"all_df.head()","e04e0327":"train=all_df[:ntrain]\ntrain.shape","b8c06d33":"train.isnull().values.any()","2c0adebb":"test=all_df[ntrain:]\ntest.shape","ff729156":"test=test.drop(['SalePrice'],axis=1)","0cb2ba9b":"test.isnull().values.any()","b6bdad8e":"test.head()","26a53ed7":"def rmsle(x,y): return math.sqrt(((np.log1p(x)-np.log1p(y))**2).mean())","148196be":"train.sort_values('YearBuilt',inplace=True)","7f4c7e2f":"X=train.drop(['SalePrice'],axis=1)\ny=train['SalePrice']","a2c35272":"from sklearn.model_selection import KFold, StratifiedKFold","615a1181":"num_folds=5","8eba61c7":"folds = KFold(n_splits= num_folds, shuffle=True, random_state=1054)","a3c15d53":"oof_preds = np.zeros(train.shape[0])\nfeature_importance_df = pd.DataFrame()\nsub_preds = np.zeros(test.shape[0])","3b4e11bd":"feat=[f for f in X.columns if f in test.columns]","6d87b50d":"##https:\/\/www.kaggle.com\/tunguz\/xgb-simple-features\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(X,y)):\n        \n            train_x, train_y = X[feat].iloc[train_idx], y.iloc[train_idx]\n            valid_x, valid_y = X[feat].iloc[valid_idx], y.iloc[valid_idx]\n            rfm = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True,random_state=100)\n            rfm.fit(train_x, train_y)\n            \n\n            oof_preds[valid_idx] = rfm.predict(valid_x)[:1]\n            sub_preds += rfm.predict(test[feat]) \/ folds.n_splits # - Uncomment for K-fold \n\n            fold_importance_df = pd.DataFrame()\n            fold_importance_df[\"cols\"] = X.columns\n            fold_importance_df[\"importance\"] = rfm.feature_importances_\n            fold_importance_df[\"fold\"] = n_fold + 1\n            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n            print('Fold %2d RMSE : %.6f' % (n_fold + 1, rmsle(valid_y, oof_preds[valid_idx])))\n            del rfm, train_x, train_y, valid_x, valid_y\n            gc.collect()","00249b08":"pred_df = pd.DataFrame(sub_preds, index=test[\"Id\"], columns=[\"SalePrice\"])\npred_df.to_csv('output_RF1.csv', header=True, index_label='Id')","2c6825c7":"from sklearn.model_selection import train_test_split\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport lightgbm as lgb","58ae4177":"## From fast.ai library,\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","a58c272a":"train_x,valid_x,train_y,valid_y=train_test_split(X,y,test_size=0.2,random_state=100)","5e07af42":"print(f'Shape of train_x is {train_x.shape} Shape of train_y is {train_y.shape} Shape of valid_x is {valid_x.shape} Shape of valid_y is {valid_y.shape}')","690ff773":" rfm = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True,random_state=100)","9e4c908b":"rfm.fit(train_x,train_y)","07a0cd27":"print(f\"RMSLE of the training model {rmsle(train_y,rfm.predict(train_x))} \\n RMSLE of the validation model {rmsle(valid_y,rfm.predict(valid_x))}\")","4eaeadca":"perm = PermutationImportance(rfm, random_state=100).fit(valid_x,valid_y)\neli5.show_weights(perm, feature_names = valid_x.columns.tolist())","24536a1d":"to_keep=['GrLivArea','GarageArea','YearBuilt','TotalBsmtSF','GarageCars']","fe726572":"X_keep=X[to_keep].copy()","2700a976":"train_x,valid_x,train_y,valid_y=train_test_split(X_keep,y,test_size=0.2)","6f9c0f4f":"print(f'Shape of train_x is {train_x.shape} Shape of train_y is {train_y.shape} Shape of valid_x is {valid_x.shape} Shape of valid_y is {valid_y.shape}')","94679c72":"rfm = RandomForestRegressor(n_estimators=30, min_samples_leaf=2, max_features=0.5, n_jobs=-1, oob_score=True,random_state=100)","5e27f469":"rfm.fit(train_x,train_y)","a8e84f45":"oof_rfm=rfm.predict(valid_x)","5499ee00":"print(f\"RMSLE of the training model {rmsle(train_y,rfm.predict(train_x))} \\n RMSLE of the validation model {rmsle(valid_y,oof_rfm)}\")","258dbf34":"param = {'num_leaves': 120,\n         'min_data_in_leaf': 3, \n         'objective':'regression',\n         'max_depth': -1,\n         'learning_rate': 0.008,\n         \"min_child_samples\": 5,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 2,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1}","4f90a6e6":"train_lgb=lgb.Dataset(train_x,label=train_y)\nvalid_lgb=lgb.Dataset(valid_x,label=valid_y)","942185d7":"num_round=5000\nclf = lgb.train(param, train_lgb, num_round,valid_sets=[train_lgb,valid_lgb], verbose_eval=100,early_stopping_rounds=200)\noof_lgb= clf.predict(valid_x, num_iteration=clf.best_iteration)","9275c30a":"print(f\"RMSLE of the model {rmsle(valid_y,oof_lgb)}\")","af70b90f":"predictions=clf.predict(test[to_keep])","90aa8e3e":"pred_df = pd.DataFrame(predictions, index=test[\"Id\"], columns=[\"SalePrice\"])","cc55a337":"pred_df.head()","5377cec2":"pred_df.to_csv('output_lgb.csv', header=True, index_label='Id')","aec75cbc":"We notice that the train data has features of houses built between 1872 to 2010 whereas the test data has houses built between 1879 till 2010. Therefore an effective train-valid-test split would be to split based on this time based feature since it is a common fact that the house prices tend to depreciate as the house gets older and older.We take  1000 rows as train data and 460 rows as validation set.","4b769e95":"We can now split the train and validation data without a time based split as we did earlier.","70aff414":"Going by the description of the dataset I see that most of the columns should be of categorical datatype . I create a custom dictionary to define the datatypes and read the dataset assigning this datatype.","9cc99eaf":"### Basic Modelling ","c7ab4c2a":"# House Price Prediction","eae5aa7d":"The distribution is a perfect normal curve with some outliers in the extremes.Lets check the median value of the sale price with respect to the year built.","f784f124":"### Exploratory Data Analysis","17e24e6f":"The predictor variable here is the saleprice . Lets check the distribution of the saleprice in the training dataset.","565206cc":"From the permutation importance we see that GrLivArea (Above grade (ground) living area square feet) seems to be most important in predicting the sale price followed by garage cars and TotalBsmtSF . It is interesting to note that Fireplaces is also noted as important feature.The external material quality of average\/typical is also rated as important factor.Lets take the weights till 0.0115 and build our model .Lets check if there is any improvement in our predictions.","ba2b99bf":"Now lets take the test dataset and impute the missing values.","3eed5c05":"We build a random forest model with the dataset and check the baseline accuracy.","e8e96e5e":"The sale price seem to be showing a fluctuating trend over the year.","bec3fc06":"Before building our model , it is necessary to encode the categorical variables. Lets concatenate the train and test set for encoding.","50e07efc":"### Dealing with Null Values","2ff46ad7":"Thus we see that there are columns both in train and test data having null values . The total number of rows present is 1460 . Therefore we consider a threashold of 500 and check the columns having more than 500 null values and remove them.","521fb59f":"Thus we see that there are 5 columns in train and test having null values in more than 500 rows . Lets remove them.","29c08dd7":"The other columns - Exterior1st,Exterior2nd,Utilities,MSZoning,saletype,functional and Kitchen Qual do have have inherent NA value and hence they will be imputed with maximum value.","8859042f":"Now lets check if there are any more null values.","0c056085":"Standard Circuit Breakers & Romex is the type most used for the electrical system and hence we impute that value.","a706af30":"Now we encode the columns,","6e4003a3":"From the RMSLE scores , we understand that the model has been overfit since the training and validation scores difference is more.","aa58e3cd":"Defining a function for encoding the categorical columns,","dc83c760":"Lets check the cardinality of each column,","1222aa2e":"As a precaution , lets check if there are any more null values,","84dfe2d1":"Lets check if there are any null values in the dataset.","10a81318":"Lets submit our model,","6a50838c":"Only 3 variables are numerical variables while others are categorical.We try to impute the numeric missing values with median values in that column.","583ccaca":"One reason we are getting a high RMSLE error is due to presence of all the features .Lets build a RF model and check the permutation importance to know which features are useful in predicting the sale price.","357c45cf":"### Introduction","3fcae9c0":"Other columns having null values need to be imputed before we build a basic model.Lets check the train dataset first.","c48bba5a":"### Reference","b56cfbe4":"The model scored 0.15915 on LB . Lets try to improve our model.","3d4d951d":"The RMSLE is quite high .Lets try the lightgbm and see if there is any improvement in our validation scores.","0de4104c":"All the other categorical variables except electrical can be imputed with NA since in the data description there is a separate category 'NA'.","45968016":"Now for electrical , lets check the cardinals and impute the missing value with most frequent cardinality","fae693b5":"Lets check the description of these columns to decide on the imputing criteria.","177cbb1e":"The dataset provided contains a set of variables that could determine the housing prices in a locality . The challenge here is to build a model which could predict the prices accurately . Its a classic regression problem and the metric to be used here is RMSE score as per the competition page . We have been provided with the train and test dataset to play with . Lets get started.\n\n**This is my first compeition kernel .The kernel has been created based on my learnings from various top GM's in kaggle .If you have any suggestions for improvement they are welcome .**","3259de48":"Check if there are any more missing values,","5c867399":"### Improving our model","8640abb7":"1.https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-zillow-prize\n2.https:\/\/www.kaggle.com\/humananalog\/xgboost-lasso\n3.https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n4.https:\/\/www.kaggle.com\/tunguz\/xgb-simple-features\n5.https:\/\/www.kaggle.com\/tunguz\/more-effective-ridge-lgbm-script-lb-0-44341-2","f8789e05":"Lets try random forest model without cv again.","e0988d1c":"Thus all the columns have been encoded.Lets split the train and test back.","2d6ef695":"The metric used for modelling is RMSLE score .Lets create a function to calculate the score.","1f07a5ce":"### Loading the required libraries and dataset "}}