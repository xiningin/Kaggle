{"cell_type":{"5edcb027":"code","d4a97eb0":"code","a480e086":"code","6be546e3":"code","92410d92":"code","ec1b09d4":"code","6686150b":"code","90bb57c6":"code","888b0c0a":"code","b63d7a11":"code","7b56809a":"code","5df93f2f":"code","0016741e":"code","97d81010":"markdown","a9bb1858":"markdown","cf1464fe":"markdown","4ee2e8ce":"markdown","f5c2f6a5":"markdown","5459d05b":"markdown","5b5b9083":"markdown"},"source":{"5edcb027":"from typing import Any, Dict\nimport umap\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom sklearn.decomposition import PCA\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nimport tensorflow as tf\nfrom sklearn.decomposition import PCA\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import Reshape, LayerNormalization, PReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import AveragePooling1D\nfrom tensorflow.keras.layers import Dropout\n\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import regularizers\nimport os\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb","d4a97eb0":"train = pd.read_csv(\"\/kaggle\/input\/otto-group-product-classification-challenge\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/otto-group-product-classification-challenge\/test.csv\")\nss = pd.read_csv(\"\/kaggle\/input\/otto-group-product-classification-challenge\/sampleSubmission.csv\")","a480e086":"train.head()","6be546e3":"def docking(train: pd.DataFrame, test: pd.DataFrame) -> [pd.DataFrame, pd.Series]:\n    print(\"docking\")\n    dict_a: Dict\n    dict_a = {\"Class_1\": 0,\n              \"Class_2\": 1,\n              \"Class_3\": 2,\n              \"Class_4\": 3,\n              \"Class_5\": 4,\n              \"Class_6\": 5,\n              \"Class_7\": 6,\n              \"Class_8\": 7,\n              \"Class_9\": 8,\n              }\n    target = train[\"target\"].map(dict_a)\n    con_df = pd.concat([train, test], sort=False)\n    \"\"\"\n    target\u306f Class_n\u3000\u2192 n-1\u3000\u306b\u3057\u305f\uff081-9\u3060\u3063\u305f\u306e\u3067\uff09\n    train\u306ecolumns\u306f feat_n \u2192 n \u306b\u3059\u308b\n    \"\"\"\n    con_df = con_df.drop([\"id\", \"target\"], axis=1)\n    con_df.columns = con_df.columns.map(lambda x: int(x[5:]))\n    con_df = np.log1p(con_df)\n\n    return con_df, target\n\n\ndef split_data(df, df_pca, df_features, target, join_pca: bool):\n    # df = np.log1p(df)\n    # df = pd.concat([df, df_pca], axis=1, join=\"inner\")\n    if join_pca:\n        # df = pd.concat([df, df_pca], axis=1, join_axes=[df.index])\n        df = pd.concat([df.reset_index(drop=True), df_pca.reset_index(drop=True)], axis=1)\n    # df = df_pca.copy()\n\n    # df = pd.concat([df, df_features], axis=1, join_axes=[df.index])\n    df = pd.concat([df.reset_index(drop=True), df_features.reset_index(drop=True)], axis=1)\n    train_df = df[:len(target)]\n    test_df = df[len(target):]\n    return train_df, test_df\n\n\ndef make_features(df: pd.DataFrame):\n    memo = pd.DataFrame()\n    memo[\"count_zero\"] = df[df == 0].count(axis=1)\n    # memo[\"count_one\"] = df[df == 1].count(axis=1)\n    return memo\n","92410d92":"def do_pca(df: pd.DataFrame, target: pd.Series):\n    n = 10\n    pca = PCA(n_components=n)\n    pca.fit(df[:len(target)])\n    # df_pca = pca.fit_transform(df)\n    df_pca = pca.transform(df)\n    n_name = [f\"pca{i}\" for i in range(n)]\n    df_pca = pd.DataFrame(df_pca, columns=n_name)\n    return df_pca","ec1b09d4":"df, target = docking(train, test)\ndf_pca = do_pca(df, target)\ndf_features = make_features(df)\ndf_train, df_test = split_data(df, df_pca, df_features, target, join_pca=True)","6686150b":"train.head()","90bb57c6":"df_train.head()","888b0c0a":"df_test.head()","b63d7a11":"def nn_train_model(\n        df: pd.DataFrame, target: pd.DataFrame, test: pd.DataFrame\n):\n    n_splits = 5\n    num_class = 9\n    epochs = 10\n    lr_init = 0.01\n    bs = 256\n    num_features = df.shape[1]\n    folds = KFold(n_splits=n_splits, random_state=71, shuffle=True)\n\n    model = tf.keras.models.Sequential([\n        Input(shape=(num_features,)),\n        Dense(128, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(128, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(64, kernel_initializer='glorot_uniform', activation=\"relu\"),\n        BatchNormalization(),\n        Dropout(0.25),\n\n        Dense(num_class, activation=\"softmax\")\n    ])\n    \n    # print(model.summary())\n    optimizer = tf.keras.optimizers.Adam(lr=lr_init, decay=0.0001)\n\n    \"\"\"callbacks\"\"\"\n    callbacks = []\n    # callbacks.append(tf.keras.callbacks.LearningRateScheduler(lr_scheduler))\n    # log_dir = \"logs\/fit\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    # callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1))\n\n    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n    preds = np.zeros((test.shape[0], num_class))\n    for trn_idx, val_idx in folds.split(df, target):\n        train_x = df.iloc[trn_idx, :].values\n        val_x = df.iloc[val_idx, :].values\n        train_y = target[trn_idx].values\n        val_y = target[val_idx].values\n\n        # train_x = np.reshape(train_x, (-1, num_features, 1))\n        # val_x = np.reshape(val_x, (-1, num_features, 1))\n        model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=epochs, verbose=2, batch_size=bs,\n                  callbacks=callbacks)\n        preds += model.predict(test.values) \/ n_splits\n\n    return preds","7b56809a":"pred1 = nn_train_model(df_train, target, df_test)","5df93f2f":"def make_submit_file(pred: np.ndarray, ss: pd.DataFrame) -> None:\n    save_path = \"submission.csv\"\n    ss.iloc[:, 1:] = pred\n    ss.to_csv(save_path, index=None)","0016741e":"make_submit_file(pred1, ss)","97d81010":"Import","a9bb1858":"# Submit","cf1464fe":"\u88dc\u8db3\uff1a head\u3067\u3088\u304f\u898b\u308b\u3068\u3001pca\u306e\u5024\u304cdf_train\u3068df_test\u3067\u4e00\u81f4\u3057\u3066\u305f\uff01  \nindex\u306b\u3088\u308b\u30de\u30fc\u30b8\u30df\u30b9\u3068\u601d\u308f\u308c\u308b","4ee2e8ce":"# Training data\u3092fit\u3057\u3001transform\u3067\u5168\u4f53\u306e\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3059\u308b\n","f5c2f6a5":"# Define Simple NN Model","5459d05b":"\u88dc\u8db3\uff1a Fold\u3054\u3068\u306btrain-val\u306eloss\u304c\u6975\u7aef\u306b\u9055\u3046\u306e\u3067\u6c17\u3065\u3044\u305f\u3002  \nKFold\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068shuffle\u3057\u306a\u3044 & \u30e9\u30d9\u30eb\u3068id\u304c\u660e\u78ba\u306b\u76f8\u95a2\u3057\u3066\u308b\u306e\u3067\u30b7\u30e3\u30c3\u30d5\u30eb\u3057\u3088\u3046","5b5b9083":"Sorry I use Japanese.  \n\nPCA\u3092\u4f7f\u3063\u305f\u6642\u306b\u3060\u3051LB\u30b9\u30b3\u30a2\u304c\u4e0b\u304c\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\uff08\u306a\u305c\u304bCV\u30b9\u30b3\u30a2\u306f\u305d\u3053\u307e\u3067\u5909\u308f\u308a\u306a\u3044\uff09  \n\u30ea\u30fc\u30af\u3057\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3069\u3046\u3057\u305f\u3089\u3053\u306e\u30d0\u30b0\u304c\u6cbb\u308b\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u3002  \n\u30a2\u30a4\u30c7\u30a2\u304c\u3042\u3063\u305f\u3089\u305c\u3072\u30b3\u30e1\u30f3\u30c8\u3067\u6559\u3048\u3066\u304f\u3060\u3055\u3044\uff01\n\n\u79c1\u304c\u66f8\u3044\u305f\u30b3\u30fc\u30c9\u306f\n\u30fbTraining data\u3092fit\u3057\u3001transform\u3067\u5168\u4f53\u306e\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3059\u308b\n\u30fbCV\u306e\u4e2d\u306eTraining data\u3092fit\u3057\u3001transform\u3067\u5168\u4f53\u306e\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3059\u308b\n\n\u3068\u3044\u30462\u3064\u306e\u3082\u306e\u3067\u3059\u3002\n\u5f8c\u308d\u306e\u51e6\u7406\u306f\u6700\u5f8c\u306b\u8f09\u305b\u307e\u3059\u3002"}}