{"cell_type":{"6c1e0880":"code","f41df50d":"code","343b23c1":"code","0df15e18":"code","602cbba7":"code","b8dddd4d":"code","243c13ba":"code","60a4219e":"code","193eb8cc":"code","9c50d083":"code","f03671d0":"code","4f7cf95c":"code","dab36bc8":"code","48f7ad92":"code","e3794b4d":"code","6f3efab7":"code","fedd0452":"markdown","88140228":"markdown","ea23873a":"markdown","a090f551":"markdown","21755782":"markdown","2a3ec765":"markdown","e751cedd":"markdown","991870a4":"markdown","730250ab":"markdown","4518f102":"markdown","1aefe77b":"markdown","8efba297":"markdown","9ebe6669":"markdown","a89c5890":"markdown","28639ba3":"markdown","a2922be9":"markdown"},"source":{"6c1e0880":"!pip install dabl","f41df50d":"import numpy as np \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport dabl\nfrom pandas_profiling import ProfileReport\nfrom catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\n\nfrom sklearn.metrics import mean_squared_error, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\n\n       \nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\npd.set_option('max_rows', 300)\nimport re\n\n\npd.set_option('display.max_columns', 300)\nnp.random.seed(566)\npd.set_option('display.max_rows', 200)\npd.set_option('display.width', 1000)\npd.set_option('display.float_format', '{:20,.2f}'.format)\npd.set_option('display.max_colwidth', -1)","343b23c1":"TARGET_COL = \"diabetes_mellitus\"\ndf = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nprint(test.shape)\n","0df15e18":"dabl.clean(df)","602cbba7":"dabl.plot(df, \"diabetes_mellitus\")","b8dddd4d":"trainprofile = ProfileReport(df,'EDA')","243c13ba":"trainprofile","60a4219e":"## Print the categorical columns\nprint([c for c in df.columns if (1<df[c].nunique()) & (df[c].dtype != np.number)& (df[c].dtype != int) ])","193eb8cc":"categorical_cols =  ['hospital_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type']\n\n","9c50d083":"## Handle na values\ndf[categorical_cols] = df[categorical_cols].fillna(\"\")\ntest[categorical_cols] = test[categorical_cols].fillna(\"\")\n\ndf[categorical_cols].isna().sum()","f03671d0":"## Train Test split and remove Target values\nX_train = df.drop([TARGET_COL],axis=1)\ny_train = df[TARGET_COL]","4f7cf95c":"## catBoost Pool object\ntrain_pool = Pool(data=X_train,label = y_train,cat_features=categorical_cols)","dab36bc8":"model_basic = CatBoostClassifier(verbose=False,iterations=50)#,learning_rate=0.1, task_type=\"GPU\",)\nmodel_basic.fit(train_pool, plot=True,silent=True)\nprint(model_basic.get_best_score())","48f7ad92":"### hyperparameter tuning example grid for catboost : \n#grid = {'learning_rate': [0.04, 0.1],\n#        'depth': [7, 11],\n#         'l2_leaf_reg': [1, 3,9],\n#        \"iterations\": [500],\n#       \"custom_metric\":['Logloss', 'AUC']}\n\n#model = CatBoostClassifier()\n\n## can also do randomized search - more efficient typically, especially for large search space - `randomized_search`\n#grid_search_result = model.grid_search(grid, \n#                                      train_pool,\n#                                      plot=True,\n#                                      refit = True, #  refit best model on all data\n#                                      partition_random_seed=42)\n\n#print(model.get_best_score())\n","e3794b4d":"test[TARGET_COL] = model_basic.predict(test,prediction_type='Probability')[:,1]","6f3efab7":"test[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission.csv\",index=False)","fedd0452":"\ud83c\udfaf **Video Tutorials for the notebook and also walkthrough of Kaggle platform can be found in this discussion thread**\n\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209141\n\n**Also check out the following discussion threads if you are new to Kaggle or Machine Learning**\n\n\ud83c\udfaf **Looking for a Team Megathread**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209054\n\n\ud83c\udfaf **New to Kaggle or Machine Learning? Come Say Hi!**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209055\n\n\ud83c\udfaf **Questions about competition setup, rules, submissions, etc**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209058\n","88140228":"### dabl, the Data Analysis Baseline Library\n\n**dabl has several tools that make it easy to clean and inspect your data, and create strong baseline models.**\n\nOfficial Documentation : https:\/\/amueller.github.io\/dabl\/dev\/quick_start.html\n\n### Data Cleaning","ea23873a":"### Import the Libraries","a090f551":"**Credit:** All images are taken from internet . The notebook is adapted from from Dan Ofer's Kernel \n[here](https:\/\/www.kaggle.com\/danofer\/wids-2020-starter-catboost-0-9045-lb). \n\n**Note:** If you like this kernel and\/or choose to fork it, please appreciate the hard work by up-voting the kernel with the ^ button above.\n\nFollow me on Twitter @Urengaraju\n","21755782":"### Submission File","2a3ec765":"### Exploratory Data analysis\n","e751cedd":"![](https:\/\/drive.google.com\/uc?id=1KUPBkdldYARjDAdfF79ezcBpq4Nwg0IL)","991870a4":"### EDA using Pandas Profiling\n\npandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\nGithub Repo : https:\/\/github.com\/pandas-profiling\/pandas-profiling\n\n\n![](https:\/\/drive.google.com\/uc?id=1QEEcCjfj5cnA_9vRfj2nZLRK0QlQGuBV)\n","730250ab":"### Exploratory Data Analysis\n\nCheck out the following discussion threads to understand the data \n\n\ud83c\udfaf **Understanding all Features in the dataset**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/210219\n\n\ud83c\udfaf **Apache 2 Calculation**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/210221\n\n\ud83c\udfaf **ANZACS : APACHE III ICU Diagnosis codes Dataset**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/210218\n\n\ud83c\udfaf **Questions about the dataset and data structure**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209059\n\n\nReference Notebook : \n\nhttps:\/\/www.kaggle.com\/thedatabeast\/wids-2021-tutorial\n\nhttps:\/\/www.kaggle.com\/iamleonie\/wids-datathon-2021-diabetes-detection\n\nhttps:\/\/www.kaggle.com\/yubiabia98\/visualization-exploratory-data-analysis-light","4518f102":"### Feature Engineering\n\n\ud83c\udfaf**For Feature engineering approaches , you can refer to WiDS Datathon 2020 Solution Thread**\n\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209053\n\n**Check out the following threads for experimentation**\n\n\ud83c\udfaf**Awesome Gradient Boosting Research Papers.**\nhttps:\/\/www.kaggle.com\/discussion\/207264\n\n\ud83c\udfaf**Research Papers related to Diabetes Prediction**\nhttps:\/\/www.kaggle.com\/c\/widsdatathon2021\/discussion\/209064\n\n\n**3 rd Place Solution :** https:\/\/www.kaggle.com\/jayjay75\/3rd-place-nn-wids2020\n","1aefe77b":"### HyperParameter Tuning\n\nCode Commented because it takes more than 1 hour to run","8efba297":"## Data Description\n\n<div class=\"alert alert-block alert-info\">\nMIT\u2019s GOSSIS community initiative, with privacy certification from the Harvard Privacy Lab, has provided a dataset of more than 130,000 hospital Intensive Care Unit (ICU) visits from patients, spanning a one-year timeframe. This data is part of a growing global effort and consortium spanning Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than 200 hospitals in the United States.\n<\/div>\n\nThe data includes:\n\n\ud83d\udccc**TrainingWiDS2021.csv** - the training data. You should see 130,157 encounters represented here. Please view the Data Dictionary file for more information about the columns.\n\n\ud83d\udccc**UnlabeledWiDS2021.csv** - the unlabeled data (data without diabetes_mellitus provided). You are being asked to predict the diabetes_mellitus variable for these encounters.\n\n\ud83d\udccc**SampleSubmissionWiDS2021.csv** - a sample submission file in the correct format.\n\n\ud83d\udccc**SolutionTemplateWiDS2021.csv** - a list of all the rows (and encounters) that should be in your submissions.\n\n\ud83d\udccc**DataDictionaryWiDS2021.csv** - supplemental information about the data.","9ebe6669":"### Catboost\n\n<div class=\"alert alert-block alert-info\">\nCatBoost is an algorithm for gradient boosting on decision trees. It is developed by Yandex researchers and engineers, and is used for search, recommendation systems, personal assistant, self-driving cars, weather prediction and many other tasks at Yandex and in other companies, including CERN, Cloudflare, Careem taxi. It is an open-source library\n<\/div>\n\nOfficial Documentation and Video Tutorials https:\/\/catboost.ai\/\n\n![](https:\/\/drive.google.com\/uc?id=172aE-E6J3-QAxZ5RI9kN0XOxX7Shq-MB)","a89c5890":"### Load the Data","28639ba3":"## Objective\n\n<div class=\"alert alert-block alert-info\">\nThe challenge is to create a model that uses data from the first 24 hours of intensive care to to determine whether a patient has been diagnosed with a particular type of diabetes, Diabetes Mellitus.\n\n<\/div>\n","a2922be9":"### Metric AUC \u2014 ROC Curve :\n\n<div class=\"alert alert-block alert-info\">\nAUC \u2014 ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. Higher the AUC, better the model is at distinguishing between patients with disease and no disease. The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis.\n<\/div>\n\nLearn more about AUC [here](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc)\n\n![](https:\/\/drive.google.com\/uc?id=1blwyxTGjR13darmbW7-MrUIUnix-lmnE)"}}