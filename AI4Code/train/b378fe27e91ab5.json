{"cell_type":{"3ee78757":"code","8d4355ec":"code","d7e7d3d2":"code","5beb5b2a":"code","12b2e83d":"code","074e8a6e":"code","76756fb6":"code","bee8e24b":"code","126ad2d5":"code","06a75ca7":"code","da9c4345":"code","c127a3bc":"code","17a89a6c":"code","f76edf1f":"code","32092421":"code","e97628ec":"code","9bb442a8":"code","ade7b1fd":"code","c49f29cf":"code","7b37c2e4":"code","f90fba74":"markdown","9ae394f5":"markdown","86fca1dd":"markdown","97214b28":"markdown","1c485c66":"markdown","37a1f663":"markdown","4b78b06e":"markdown","7d4ac08f":"markdown"},"source":{"3ee78757":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","8d4355ec":"from fastai.imports import *\nfrom fastai.structured import *\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\nfrom sklearn import metrics","d7e7d3d2":"df_raw = pd.read_feather('..\/input\/bulldozersraw\/bulldozers-raw')\ndf_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')","5beb5b2a":"print (\"SHAPES!!!\")\nprint (\"df_raw => \" + str(df_raw.shape))\nprint (\"df_trn => \" + str(df_trn.shape))\nprint (\"y_trn ==> \" + str(y_trn.shape))","12b2e83d":"# Criando uma fun\u00e7\u00e3o para fazer o split do DataFrame 'a' na posi\u00e7\u00e3o 'n'\ndef split_vals(a,n):\n    return a[:n], a[n:]\n\n# Qtde de registros que ficar\u00e3o nos DataFrame's de valida\u00e7\u00e3o\nn_valid = 12000\n\n# Ponto de corte do DataFrame\nn_trn = len(df_trn)-n_valid\n\n# Dividindo os DataFrame's iniciais em 2\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nraw_train, raw_valid = split_vals(df_raw, n_trn)","074e8a6e":"print (\"SHAPES!!!\")\nprint (\"X_train => \" + str(X_train.shape))\nprint (\"X_valid => \" + str(X_valid.shape))\nprint (\"y_train => \" + str(y_train.shape))\nprint (\"y_valid => \" + str(y_valid.shape))\nprint (\"raw_train => \" + str(raw_train.shape))\nprint (\"raw_valid => \" + str(raw_valid.shape))","76756fb6":"### Gerando um DataFrame com apenas duas colunas\nx_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]\nprint (\"x_sub => \" + str(x_sub.shape))\nx_sub.head().T","bee8e24b":"# 'class' declara uma classe \/ objeto, neste caso chamado 'TreeEnsemble'\nclass TreeEnsemble():\n    \n    # Os m\u00e9todos \/ fun\u00e7\u00f5es em Python s\u00e3o declarados utilizando o 'def', o '__init__' \u00e9 um M\u00c9TODO M\u00c1GICO\n    # do Python (ele \u00e9 o construtor da classe \/ objeto), existem muitos outros m\u00e9todos m\u00e1gicos\n\n    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):       \n        \n        # Todo m\u00e9todo dentro de uma classe deve ter um primeiro parametro obrigat\u00f3rio, que convencionou-se \n        # chamar de 'self'\n        \n        # Gerando uma semente aleat\u00f3ria\n        np.random.seed(42)\n        \n        # Atribuindo os valores recebidos aos atribudos correspondentes do objeto 'TreeEnsemble'\n        # O Python permite a atribui\u00e7\u00e3o de v\u00e1rios valores em uma \u00fanica linha\n        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n        \n        # Chama um m\u00e9todo da pr\u00f3pria classe 'TreeEnsemble' para criar uma lista '[]' chamada 'trees'\n        # com as 'n_trees' (Observe que n\u00e3o foi efetuado um tratamento caso este valor n\u00e3o tenha sido informado) \n        self.trees = [self.create_tree() for i in range(n_trees)]\n        \n        \n    def create_tree(self):\n        \n        # Cria uma vari\u00e1vel local chamada 'rnd_idxs' contendo os 'sample_sz' indices das linhas (j\u00e1 embaralhados)\n        # Veja um exemplo na pr\u00f3xima celula\n        rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n        \n        # O retorno deste m\u00e9todo \u00e9 o resultado da execu\u00e7\u00e3o da classe 'DecisionTree', passando como parametro\n        # os atributos 'self.x' e 'self.y', MAS APENAS com as linhas (\u00edndices) que foram selecionados aleatoriamente.\n        #\n        # self.x.iloc[rnd_idxs] => Como 'self.x' \u00e9 uma matriz \u00e9 necess\u00e1rio utilizar o m\u00e9todo 'iloc' para\n        # referenciar as linhas informadas na lista 'rnd_idxs'\n        #\n        # self.y[rnd_idxs] => Como 'self.y' \u00e9 um array (tem apenas uma coluna) n\u00e3o foi necess\u00e1rio utilizar o\n        # 'iloc', bastando apenas referenciar as linhas informando a lista 'rnd_idxs'\n        #\n        # Portanto para cada arvore gerada teremos uma amostra diferente de registros\n        return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)\n        \n        \n    def predict(self, x):\n        \n        # O m\u00e9todo 'predict' retorna a m\u00e9dia ..\n        \n        return np.mean([t.predict(x) for t in self.trees], axis=0)","126ad2d5":"# Demonstra\u00e7\u00e3o do m\u00e9todo 'numpy.random.permutation' \nprint (\"Tamanho do 'y_train' ==> \" + str(len(y_train)))\nprint (\"Exibindo os 5 primeiros indices entre '0' e 'len(y_train)' de forma aleat\u00f3ria.\")\nnp.random.permutation(len(y_train))[:5]","06a75ca7":"class DecisionTree():\n    \n    def __init__(self, x, y, idxs=None, min_leaf=5):\n        \n        # Simplesmente est\u00e1 inicializando a classe 'DecisionTree' atribuindo os parametros recebidos aos \n        # atribudos da classe, sem qualquer tipo de tratamento adicional\n        # ser\u00e1 reimplementada logo abaixo\n        \n        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf","da9c4345":"# Criando um objeto 'TreeEnsemble'\nm = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=1000, min_leaf=3)","c127a3bc":"# Exibindo uma representa\u00e7\u00e3o da 1\u00aa arvore do objeto 'TreeEnsemble' \nm.trees[0]","17a89a6c":"class DecisionTree():\n    \n    def __init__(self, x, y, idxs=None, min_leaf=5):\n        \n        # Trata o atributo 'idxs'\n        if idxs is None:\n            # Se 'idxs' n\u00e3o for definido, atribui um Array de inteiros de '0' at\u00e9 'len(y)'\n            idxs = np.arange(len(y))\n            \n        # Atribui os parametros recebidos \/ tratados aos atributos da classe 'DecisionTree'\n        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n        \n        # Atribui \u00e0 'self.n' o tamanho do array 'idxs'\n        # Atribui \u00e0 'self.c' o n\u00famero de colunas da matriz 'x'\n        self.n,self.c = len(idxs), x.shape[1]\n        \n        # Atribui \u00e0 'self.val' a m\u00e9dia dos valores de 'y'\n        self.val = np.mean(y[idxs])\n        \n        # Atribui \u00e0 'self.score' um float infinito positivo\n        self.score = float('inf')\n        \n        # Executa o m\u00e9todo interno 'self.find_varsplit()'\n        self.find_varsplit()\n        \n    # Isso apenas faz uma decis\u00e3o; n\u00f3s vamos fazer isso recursivo depois\n    def find_varsplit(self):\n        for i in range(self.c):\n            self.find_better_split(i)\n            \n    # N\u00f3s vamos escrever isso mais tarde!\n    def find_better_split(self, var_idx):\n        pass\n    \n    # Devolve o nome da coluna na posi\u00e7\u00e3o passada como parametro\n    # Equivalente a um m\u00e9todo 'get_split_name(var_idx)'\n    @property\n    def split_name(self):\n        return self.x.columns[self.var_idx]\n    \n    # Retorna o conte\u00fado da coluna 'self.var_idx' de todas as linhas contidas no array 'self.idxs'\n    @property\n    def split_col(self):\n        return self.x.values[self.idxs,self.var_idx]\n    \n    # Retorna 'True' ou 'False' para a compara\u00e7\u00e3o \n    @property\n    def is_leaf(self):\n        return self.score == float('inf')\n    \n    # Implementa outro m\u00e9todo m\u00e1gico do Python, agora respons\u00e1vel pela representa\u00e7\u00e3o da classe \/ objeto\n    # O objetivo do '__repr__' \u00e9 ser inequ\u00edvoco\n    def __repr__(self):\n        s = f'n: {self.n}; val:{self.val}'\n        if not self.is_leaf:\n            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n        return s","f76edf1f":"# Demonstra\u00e7\u00e3o do que acontece no m\u00e9todo 'split_name'\n#     return self.x.columns[self.var_idx]\nprint(\"Todas as colunas de 'X_train' => \" + str(X_train.columns))\nprint(\"Nome da 3\u00aa coluna de 'X_train' => \" + str(X_train.columns[2]))","32092421":"# Demonstra\u00e7\u00e3o do que acontece no m\u00e9todo 'split_col'\n#     return self.x.values[self.idxs,self.var_idx]\nprint (\"Todos os valores das 3\u00aa e 4\u00aa linhas de 'X_train'\\n\" + str(X_train.values[[2,3]]))\nprint (\"Todos os valores da 3\u00aa coluna, das 3\u00aa e 4\u00aa linhas de X_train\\n\" + str(X_train.values[[2,3],2]))","e97628ec":"# Refazendo o objeto 'TreeEnsemble' com apenas 30 registros\nm = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=30, min_leaf=3)","9bb442a8":"# Exibindo os valores 'target' da 2\u00aa arvore\nm.trees[1].y","ade7b1fd":"# Exibindo a representa\u00e7\u00e3o da 2\u00aa arvore (agora usando o m\u00e9todo __repr__)\nm.trees[1]","c49f29cf":"# Exibindo os valores 'target' da 3\u00aa arvore\nm.trees[2].y","7b37c2e4":"# Exibindo a representa\u00e7\u00e3o da 3\u00aa arvore (agora usando o m\u00e9todo __repr__)\nm.trees[2]","f90fba74":"### Importando bibliotecas","9ae394f5":"# Caderno de apoio para o v\u00eddeo 5 do curso de Machine Learning da Fast.ai\n[V\u00eddeo completo da Li\u00e7\u00e3o 5](https:\/\/www.youtube.com\/watch?v=3jl2h9hSRvc&feature=youtu.be)","86fca1dd":"# C\u00f3digo comentado do notebook 'lesson3-rf_foundations' do curso de Machine Learning do Fast.ai utilizado na parte final do v\u00eddeo 5","97214b28":"### Reimplementando a classe 'DecisionTree'\n* [Python **@property**](https:\/\/www.programiz.com\/python-programming\/property)\n* [Python Course - Properties vs. Getters and Setters](https:\/\/www.python-course.eu\/python3_properties.php)\n* [Qual \u00e9 a diferen\u00e7a entre '**\\_\\_str\\_\\_**' e '**\\_\\_repr\\_\\_**' ?](https:\/\/pt.stackoverflow.com\/questions\/176464\/qual-%C3%A9-a-diferen%C3%A7a-entre-str-e-repr)\n* [How to Work with Infinity in Python](https:\/\/medium.com\/@sanatinia\/how-to-work-with-infinity-in-python-337fb3987f06)","1c485c66":"### Lendo os dados","37a1f663":"## Dataset's de treinamento \/ teste e valida\u00e7\u00e3o\n---\n***Observa\u00e7\u00f5es***\n* *Em Machine Learning a nossa preocupa\u00e7\u00e3o deve estar na 'precis\u00e3o da generaliza\u00e7\u00e3o' ou no 'erro da generaliza\u00e7\u00e3o;*\n* *Volume dos dataset's, quanto maior melhor?*\n* *Aleatoriedade dos dados;*\n\n[V\u00eddeo (at\u00e9 7m18s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=0&end=438)\n\n## OOB (Out-Of-Bag)\n---\n***Defini\u00e7\u00e3o***\nEstimativas out-of-bag ajudam a evitar a necessidade de um conjunto de dados de valida\u00e7\u00e3o independente, mas frequentemente subestimam a melhoria real do desempenho e o n\u00famero ideal de itera\u00e7\u00f5es.\n*Fonte.: [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Out-of-bag_error)*\n\n***Link's interessantes***\n* *[Random Forests - Leo Breiman and Adele Cutler](https:\/\/www.stat.berkeley.edu\/~breiman\/RandomForests\/cc_home.htm)*\n    * *Cada \u00e1rvore \u00e9 constru\u00edda usando uma amostra de bootstrap diferente dos dados originais. Cerca de um ter\u00e7o dos casos s\u00e3o deixados de fora da amostra de bootstrap e n\u00e3o s\u00e3o usados na constru\u00e7\u00e3o da k-\u00e1rvore.*\n* *[scikit-learn - OOB Errors for Random Forests](http:\/\/scikit-learn.org\/stable\/auto_examples\/ensemble\/plot_ensemble_oob.html)*\n\n[V\u00eddeo (7m19s at\u00e9 11m38s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=439&end=698)\n\n## Modo Kaggle de avaliar as competi\u00e7\u00f5es\n---\nDados disponibilizados para a competi\u00e7\u00e3o\n\n| P\u00fablicos  | Privados  |\n|:-:|:-:|\n| 30% | 70% |\n| aleat\u00f3rios |  |\n\n[V\u00eddeo (11m40s at\u00e9 12m55s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=700&end=775)\n\n## Em que situa\u00e7\u00e3o n\u00e3o \u00e9 aconselh\u00e1vel utilizar o OOB? \n---\n[V\u00eddeo (12m55s at\u00e9 16m05s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=775&end=965)\n\n## 'Ent\u00e3o, o mundo muda...' \n---\nEste \u00e9 um problema para n\u00f3s e para o machine learning, prever o futuro, trabalhar com s\u00e9ries temporais e afins, ***por exemplo: Previs\u00e3o do tempo. Ela tem melhorado ao longo dos anos?***\n\n[V\u00eddeo (16m05s at\u00e9 20m25s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=965&end=1225)\n\n## Usando pesos al\u00e9m de uma proposta de 'modus operandi'\n---\n[V\u00eddeo (20m25s at\u00e9 24m00s)](http:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=1225&end=1440)\n\n## Se\u00e7\u00e3o de perguntas\n---\n[V\u00eddeo (24m00s at\u00e9 30m00s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=1441&end=1800)\n\n## Cross-Validation\n---\n[V\u00eddeo (30m05s at\u00e9 37m53s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=1805&end=2273)\n\n***Link's interessantes***\n* *[Cross-Validation in Machine Learning](https:\/\/towardsdatascience.com\/cross-validation-in-machine-learning-72924a69872f)*\n* *[scikit-learn - Cross-validation: evaluating estimator performance](http:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)*\n* *[A Gentle Introduction to k-fold Cross-Validation](https:\/\/machinelearningmastery.com\/k-fold-cross-validation\/)*\n* *[Wikipedia - Valida\u00e7\u00e3o cruzada](https:\/\/pt.wikipedia.org\/wiki\/Valida%C3%A7%C3%A3o_cruzada)*\n* **Exemplo do esquema de particionamento e execu\u00e7\u00e3o do m\u00e9todo k-fold com k = 3**\n![image.png](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/b\/b0\/Kfold.pdf\/page1-507px-Kfold.pdf.jpg)\n\n## Tree interpreter \n---\n* *O que um interpretador de arvore faz? e como faz?*\n* *Gr\u00e1fico 'Cascata', quem se habilita a desenvolver?*\n* **Acabou a caixa preta?!?**\n\n[V\u00eddeo (38m10s at\u00e9 44m25s )](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=2290&end=2965)\n\n## Extrapolation\n---\n1. *Score de valida\u00e7\u00e3o X score do Out-Of-Bag*\n2. *Criada uma nova coluna 'is_valid' e aplicado o RandomForestClassifier*\n    1. *Precis\u00e3o de 99,999% ?!? Muito bom... Indica que n\u00e3o deve existir aleatoriedade nos dados...*\n    2. *SalesID, saleElapsed, MachineID (sequenciais)*\n    3. *Remove estas colunas*\n3. *Executa novamente RandomForestClassifier*\n    1. *Agora uma precis\u00e3o de 97,89% ?!? Bom? Ser\u00e1? ...*\n    2. age, YearMade, saleDayofyear estes tamb\u00e9m s\u00e3o vari\u00e1veis dependentes do 'tempo'\n    \nEnt\u00e3o vamos remover todas estas vari\u00e1veis que s\u00e3o 'temporais', correto???\n\n[V\u00eddeo (44m26s at\u00e9 57m01s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=2666&end=3421)\n\n## Extrapolation ...\n---\n* ***Aplica novamente a RandomForestRegressor, s\u00f3 que agora removendo uma das colunas acima por vez, para ver qual o impacto na predi\u00e7\u00e3o***\n* *Removendo as colunas SalesID, MachineID e saleDayofyear e aplicando novamente a RandomForestRegressor, qual deve ser o resultado?*\n\n[V\u00eddeo (57m02s at\u00e9 1h02m31s)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=3421&end=3751)\n\n## O modo Jeremy de escrever um c\u00f3digo\n---\n* ***Vamos construir um algoritmo de RandomForest***\n\n* O modo Jeremy de construir aplicativos:\n    * Abordagem Top-Down (Assuminos que a base j\u00e1 est\u00e1 pronta)\n    * Atribui\u00e7\u00f5es em tuplas\n* O porque de usar uma semente aleat\u00f3ria, como funciona, etc.\n\nLink's\n\n\n\n[V\u00eddeo (1h04m49s at\u00e9 o final)](https:\/\/www.youtube.com\/embed\/3jl2h9hSRvc?start=3752)","4b78b06e":"* [%load_ext autoreload; %autoreload 2](https:\/\/ipython.org\/ipython-doc\/3\/config\/extensions\/autoreload.html) ==> Recarrega os m\u00f3dulos automaticamente antes de entrar na execu\u00e7\u00e3o do c\u00f3digo digitado no prompt do IPython.\n* [%matplotlib inline](https:\/\/ipython.readthedocs.io\/en\/stable\/interactive\/plotting.html) ==> Faz com que a sa\u00edda dos comandos de plotagem seja exibida nos frontends, como o notebook Jupyter, diretamente abaixo da c\u00e9lula de c\u00f3digo que o produziu. Os gr\u00e1ficos resultantes ser\u00e3o tamb\u00e9m armazenados no documento do bloco de notas.","7d4ac08f":"## Estruturas de dados b\u00e1sica\n\n* [Wikip\u00e9dia - Ensemble Learning](https:\/\/en.wikipedia.org\/wiki\/Ensemble_learning)\n* [Introdu\u00e7\u00e3o a Classes e M\u00e9todos em Python (b\u00e1sico)](http:\/\/pythonclub.com.br\/introducao-classes-metodos-python-basico.html)\n* [Os m\u00e9todos m\u00e1gicos do Python](https:\/\/pythonhelp.wordpress.com\/2013\/03\/11\/os-metodos-magicos-de-python\/)\n* [O porqu\u00ea do **self** expl\u00edcito em Python](http:\/\/archive.is\/cX2mq)"}}