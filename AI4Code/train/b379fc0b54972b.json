{"cell_type":{"e7575d1c":"code","175f6371":"code","faaf570d":"code","71504ce9":"code","bdbe3315":"code","b79ec476":"code","84314fe2":"code","f85e3ae7":"code","1b5d5c2f":"code","3ee9fd22":"code","df799d03":"code","e8aab54c":"code","72817ffe":"code","68cacb28":"code","66c4ef96":"code","9899c58f":"code","7f3c1708":"code","e17bfe88":"code","04df507b":"code","cc84a4dd":"code","e1e9aa14":"code","a075b052":"code","a14af9b5":"code","b5f0681f":"code","4206b435":"code","f1838066":"code","d9b16422":"markdown","97ec3b2e":"markdown","16e0975b":"markdown","f0ff61f5":"markdown","07c7e4b4":"markdown","dda27557":"markdown","017de45a":"markdown","1b1c97a3":"markdown","eb56fdf2":"markdown","8b9a341f":"markdown","cf350616":"markdown","887cd109":"markdown","47240d0d":"markdown"},"source":{"e7575d1c":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport wandb","175f6371":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_key = user_secrets.get_secret(\"wandb_key\")","faaf570d":"wandb.login(key=wandb_key)","71504ce9":"wandb.init(project=\"Anomaly Detection Using Autoencoders MNIST-digit\")","bdbe3315":"np.random.seed(42)\ntf.random.set_seed(42)","b79ec476":"train_file = '..\/input\/digit-recognizer\/train.csv'\ntest_file = '..\/input\/digit-recognizer\/test.csv'","84314fe2":"test_df = pd.read_csv(test_file)","f85e3ae7":"df = pd.read_csv(train_file)\ndf.head()","1b5d5c2f":"df.shape","3ee9fd22":"df['label'].value_counts()","df799d03":"train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42, stratify=df['label'])","e8aab54c":"class encoder(keras.Model):\n    def __init__(self):\n        super(encoder, self).__init__()\n        self.cnn1 = keras.layers.Conv2D(32, 3, strides=2, activation='relu', padding='same')\n        self.cnn2 = keras.layers.Conv2D(64, 3, strides=2, activation='relu', padding='same')\n        self.cnn3 = keras.layers.Conv2D(128, 3, strides=2, activation='relu')\n    \n    def call(self, x):\n        x = self.cnn1(x)\n        x = self.cnn2(x)     \n        x = self.cnn3(x)        \n        return x","72817ffe":"class decoder(keras.Model):\n    def __init__(self):\n        super(decoder, self).__init__()\n        self.cnnT1 = keras.layers.Conv2DTranspose(64, 3, strides=2, activation='relu')\n        self.cnnT2 = keras.layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')\n        self.cnnT3 = keras.layers.Conv2DTranspose(1, 3, strides=2, activation='relu', padding='same')\n    \n    def call(self, x):\n        x = self.cnnT1(x)\n        x = self.cnnT2(x)     \n        x = self.cnnT3(x)          \n        return x","68cacb28":"class autoEncoder(keras.Model):\n    def __init__(self):\n        super(autoEncoder, self).__init__()\n        self.encoder = encoder()\n        self.decoder = decoder()\n    \n    def call(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","66c4ef96":"@tf.function\ndef make_2d(row):\n    image = tf.reshape(row, (28, 28))\n    image = tf.cast(image, tf.float64)\/255.\n    image = tf.expand_dims(image, axis=-1)\n    return image","9899c58f":"train_ds = tf.data.Dataset.from_tensor_slices(train_df.drop(columns='label')).map(make_2d).shuffle(5).batch(32)\nval_ds = tf.data.Dataset.from_tensor_slices(val_df.drop(columns='label')).map(make_2d).batch(1)","7f3c1708":"def ssim(input_img, output_img):\n    return 1 - tf.reduce_mean(tf.image.ssim(input_img, tf.cast(output_img, tf.float64), max_val=1))","e17bfe88":"optimizer = keras.optimizers.Adam(learning_rate=0.001)\nmodel = autoEncoder()","04df507b":"EPOCHS = 5\n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for step, (image) in enumerate(train_ds):\n        with tf.GradientTape() as tape:\n            output = model(image, training=True)\n            loss = ssim(image, output)\n        grads = tape.gradient(loss, model.trainable_weights)\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n        total_loss += loss.numpy()\n\n    print(f\"Epoch {epoch+1}: loss: {total_loss\/(step+1)}\")\n    wandb.log({\"loss\": total_loss\/(step+1), \"epoch\": epoch+1})\n    \n    fig, ax = plt.subplots(2, 5)\n    for step, (image) in enumerate(val_ds.take(5)):\n        output = model(image, training=False)\n        loss = ssim(image, output)\n        ax[0][step].imshow(image.numpy()[0], cmap=\"gray\")\n        ax[1][step].imshow(output.numpy()[0], cmap=\"gray\")\n        fig.suptitle(f\"Epoch: {epoch+1}\")\n    \n    wandb.log({\"validation examples over training period\": wandb.Image(fig)})\n        ","cc84a4dd":"all_loss = []\nfor step, (image) in enumerate(val_ds):\n    output = model(image, training=False)\n    loss = ssim(image, output)\n    wandb.log({\"val_loss_for_threshold\": loss.numpy()})\n    all_loss.append(loss.numpy())","e1e9aa14":"plt.figure(figsize=(15,10))\nplt.plot(range(1, len(all_loss)+1), all_loss);","a075b052":"_99th_percentile = np.percentile(all_loss,q=99)\nprint(_99th_percentile)","a14af9b5":"THRESH_LOSS = _99th_percentile","b5f0681f":"test_ds = tf.data.Dataset.from_tensor_slices(test_df.values).map(make_2d).batch(1)","4206b435":"outliers = []\nextreme_outliers = []\nall_loss = []\nfor image in test_ds:\n    output = model(image, training=False)\n    loss = ssim(image, output)\n    all_loss.append(loss.numpy())\n    wandb.log({\"test_loss\":loss.numpy()})\n    if loss.numpy() > THRESH_LOSS:\n        fig, ax = plt.subplots(1, 2)\n        ax[0].imshow(image.numpy()[0], cmap=\"gray\")\n        ax[0].title.set_text(\"Original\")\n        ax[1].imshow(output.numpy()[0], cmap=\"gray\")\n        ax[1].title.set_text(\"Reconstructed\")\n        wandb_img = wandb.Image(fig, caption=f\"Loss: {loss.numpy():.5f}\")\n        if loss.numpy() < THRESH_LOSS+0.003:\n            wandb.log({\"test_outlier_loss\":loss.numpy()})\n            outliers.append(wandb_img)\n            continue\n        wandb.log({\"extreme_test_outliers_loss\":loss.numpy()})\n        extreme_outliers.append(wandb_img)\nwandb.log({\"test_outliers\":outliers})\nwandb.log({\"extreme_test_outliers\":extreme_outliers})","f1838066":"plt.figure(figsize=(15,10))\nplt.plot(range(1, len(all_loss)+1), all_loss);","d9b16422":"# Training Loop using `tf.GradientTape()`","97ec3b2e":"## Creating training and validation dataset\/dataloader using tf.data for better performance","16e0975b":"## AutoEncoder class\n\n> Combining encoder and decoder.","f0ff61f5":"## Decoder Class","07c7e4b4":"## Defining loss function and optimizer before the trianing loop\n- loss funtion: MSE\n- optimizer: Adam\n- Learning Rate: 0.001","dda27557":"## Using validation data to find the threshold for finding the outliers.","017de45a":"### Defining Test Dataset","1b1c97a3":"# Using tf.Keras.Model for creating encoder, decoder classes.","eb56fdf2":"## Function to convert a row to 2D Image\n> @tf.function improves the performance.","8b9a341f":"## Encoder Class","cf350616":"Every class has almost equal number of examples","887cd109":"## Finding Outliers in Test Dataset","47240d0d":"### 99th percentile seems a appropriate threshold for outliers"}}