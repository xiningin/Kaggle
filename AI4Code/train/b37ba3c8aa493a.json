{"cell_type":{"aadde8ec":"code","b8c67157":"code","37892155":"code","889aca03":"code","eb34c090":"code","e3247649":"code","99a67870":"code","0de3d74d":"code","6ec7d304":"code","7d056545":"code","cf276b9b":"code","07ff5581":"code","8f9f33e4":"code","f3aa859b":"code","d038727c":"code","e9447600":"code","e28cc444":"code","9a1903be":"code","75f73287":"code","91003056":"code","83718cca":"code","649ed93d":"code","77c1efb4":"code","ec811874":"code","43687467":"code","65f9004f":"code","2b5eb8a7":"markdown","73911720":"markdown","e955aa3a":"markdown","8bc4567a":"markdown","47e43c4b":"markdown","af207818":"markdown","b22f398f":"markdown","6bdbf9f6":"markdown","eafb4ce9":"markdown","ece71ccb":"markdown","45605220":"markdown","6bdbef43":"markdown","fb80f4a4":"markdown"},"source":{"aadde8ec":"import glob\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T\nimport albumentations as A\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nROOT_PATH = '..\/input\/lgg-mri-segmentation\/kaggle_3m\/'","b8c67157":"mask_files = glob.glob(ROOT_PATH + '*\/*_mask*')\nimage_files = [file.replace('_mask', '') for file in mask_files]","37892155":"def diagnosis(mask_path):\n    return 1 if np.max(cv2.imread(mask_path)) > 0 else 0\n\ndf = pd.DataFrame({\"image_path\": image_files,\n                  \"mask_path\": mask_files,\n                  \"diagnosis\": [diagnosis(x) for x in mask_files]})\ndf.head()","889aca03":"ax = df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(10,6), color=['blue', 'red'])\nax.set_title('Data Distribution', fontsize=15)\nax.set_ylabel('Total Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=15)","eb34c090":"train_df, val_df = train_test_split(df, stratify=df['diagnosis'], test_size=0.1)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15)\ntrain_df = train_df.reset_index(drop=True)\n\nprint(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))","e3247649":"IMG_SIZE = 521\nimages = []\nmasks = []\ndf_positive = df[df['diagnosis']==1].sample(5).values\nfor data in df_positive:\n    img = cv2.resize(cv2.imread(data[0]), (IMG_SIZE, IMG_SIZE))\n    mask = cv2.resize(cv2.imread(data[1]), (IMG_SIZE, IMG_SIZE))\n    images.append(img)\n    masks.append(mask)\nimages = np.hstack(np.array(images))\nmasks = np.hstack(np.array(masks))\n\nfig = plt.figure(figsize=(25,25))\ngrid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images', fontsize=15)\ngrid[0].axis('off')\ngrid[1].imshow(masks)\ngrid[1].set_title('Masks', fontsize=15)\ngrid[1].axis('off')\ngrid[2].imshow(images)\ngrid[2].imshow(masks, alpha=0.4)\ngrid[2].set_title('Brain MRI with mask', fontsize=15)\ngrid[2].axis('off')","99a67870":"def show_aug(inputs, nrows=5, ncols=5, image=True):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i = 0\n    if len(inputs) > 25:\n        inputs = inputs[:25]\n        \n    for idx in range(len(inputs)):\n        if image is True:           \n            img = inputs[idx].numpy().transpose(1,2,0)\n            mean = [0.485, 0.456, 0.406]\n            std = [0.229, 0.224, 0.225] \n            img = (img * std + mean).astype(np.float32)\n        else:\n            img = inputs[idx].numpy().astype(np.float32)\n            img = img[0,:,:]\n        plt.subplot(nrows, ncols, i+1)\n        plt.imshow(img); \n        plt.axis('off')\n        i += 1\n    return plt.show()","0de3d74d":"class BrainDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 0])\n        image = np.array(image)\/255.\n        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n        mask = np.array(mask)\/255.\n        \n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask = aug['mask']\n            \n        image = image.transpose((2,0,1))\n        image = torch.from_numpy(image).type(torch.float32)\n        image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n        mask = torch.from_numpy(mask).type(torch.float32)\n        \n        return image, mask\n    \ntrain_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])\nval_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n])\ntest_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0)\n])","6ec7d304":"train_dataset = BrainDataset(train_df, train_transform)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=26, shuffle=True, num_workers=2)\n\nval_dataset = BrainDataset(val_df, val_transform)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=26, shuffle=True, num_workers=2)\n\ntest_dataset = BrainDataset(test_df, test_transform)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=26, shuffle=True, num_workers=2)","7d056545":"images, masks = next(iter(train_dataloader))\nprint(images.shape)\nprint(masks.shape)\nshow_aug(images)\nshow_aug(masks, image=False)","cf276b9b":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True))\n    def forward(self, x):\n        return self.double_conv(x)\n    \nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels))\n    def forward(self, x):\n        return self.maxpool_conv(x)\n    \nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels\/\/2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels\/\/2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX\/\/2, diffX-diffX\/\/2,\n                        diffY\/\/2, diffY-diffY\/\/2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid())\n    def forward(self, x):\n        return self.conv(x)","07ff5581":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024\/\/factor)\n        self.up1 = Up(1024, 512\/\/factor, bilinear)\n        self.up2 = Up(512, 256\/\/factor, bilinear)        \n        self.up3 = Up(256, 128\/\/factor, bilinear)        \n        self.up4 = Up(128, 64, bilinear)        \n        self.outc = OutConv(64, n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","8f9f33e4":"model = UNet(3, 1).to(device)\nout = model(torch.randn(1, 3, 256, 256).to(device))\nprint(out.shape)","f3aa859b":"def dice_coef_metric(pred, label):\n    intersection = 2.0 * (pred * label).sum()\n    union = pred.sum() + label.sum()\n    if pred.sum() == 0 and label.sum() == 0:\n        return 1.\n    return intersection \/ union\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection \/ union)\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss","d038727c":"def compute_iou(model, loader, threshold=0.3):\n    valloss = 0\n    with torch.no_grad():\n        for step, (data, target) in enumerate(loader):\n            data = data.to(device)\n            target = target.to(device)\n\n            outputs = model(data)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            loss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += loss\n\n    return valloss \/ step","e9447600":"def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n    loss_history = []\n    train_history = []\n    val_history = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        \n        losses = []\n        train_iou = []\n        \n        for i, (image, mask) in enumerate(tqdm(train_loader)):\n            image = image.to(device)\n            mask = mask.to(device)\n            outputs = model(image)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n            \n            train_dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n            loss = loss_func(outputs, mask)\n            losses.append(loss.item())\n            train_iou.append(train_dice)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n                \n        val_mean_iou = compute_iou(model, val_loader)\n        scheduler.step(val_mean_iou)\n        loss_history.append(np.array(losses).mean())\n        train_history.append(np.array(train_iou).mean())\n        val_history.append(val_mean_iou)\n        \n        print('Epoch : {}\/{}'.format(epoch+1, num_epochs))\n        print('loss: {:.3f} - dice_coef: {:.3f} - val_dice_coef: {:.3f}'.format(np.array(losses).mean(),\n                                                                               np.array(train_iou).mean(),\n                                                                               val_mean_iou))\n    return loss_history, train_history, val_history","e28cc444":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\nnum_epochs = 100\nloss_history, train_history, val_history = train_model(train_dataloader, val_dataloader, bce_dice_loss, optimizer, scheduler, num_epochs)","9a1903be":"def plot_model_history(model_name, train_history, val_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_history, label='train dice', lw=3, c=\"b\")\n    plt.plot(x, val_history, label='validation dice', lw=3, c=\"r\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"Dice\", fontsize=15)\n\n    plt.show()\n    \nplot_model_history('UNet', train_history, val_history, num_epochs)","75f73287":"test_iou = compute_iou(model, test_dataloader)\nprint(\"Mean IoU: {:.3f}%\".format(100*test_iou))","91003056":"test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(1).values[0]\nimage = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\nmask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n\n# pred\npred = torch.tensor(image.astype(np.float32) \/ 255.).unsqueeze(0).permute(0,3,1,2)\npred = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\npred = model(pred.to(device))\npred = pred.detach().cpu().numpy()[0,0,:,:]\n\npred_t = np.copy(pred)\npred_t[np.nonzero(pred_t < 0.3)] = 0.0\npred_t[np.nonzero(pred_t >= 0.3)] = 255.\npred_t = pred_t.astype(\"uint8\")\n\n# plot\nfig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n\nax[0, 0].imshow(image)\nax[0, 0].set_title(\"image\")\nax[0, 1].imshow(mask)\nax[0, 1].set_title(\"mask\")\nax[1, 0].imshow(pred)\nax[1, 0].set_title(\"prediction\")\nax[1, 1].imshow(pred_t)\nax[1, 1].set_title(\"prediction with threshold\")\nplt.show()","83718cca":"test_samples = test_df[test_df[\"diagnosis\"] == 1].sample(105).values\n\ndef batch_preds_overlap(model, samples):\n    \"\"\"\n    Computes prediction on the dataset\n    \n    Returns: list with images overlapping with predictions\n    \n    \"\"\"\n    prediction_overlap = []\n    for test_sample in samples:\n\n         # sample\n        image = cv2.resize(cv2.imread(test_sample[0]),(128, 128))\n        image =  image \/ 255.\n        ground_truth = cv2.resize(cv2.imread(test_sample[1], 0), (128, 128)).astype(\"uint8\")\n\n        # pred\n        prediction = torch.tensor(image).unsqueeze(0).permute(0,3,1,2)\n        prediction = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(prediction)\n        prediction = model(prediction.to(device).float())\n        prediction = prediction.detach().cpu().numpy()[0,0,:,:]\n\n        prediction[np.nonzero(prediction < 0.3)] = 0.0\n        prediction[np.nonzero(prediction >= 0.3)] = 255.\n        prediction = prediction.astype(\"uint8\")\n\n        # overlap \n        original_img = cv2.resize(cv2.imread(test_sample[0]),(128, 128))\n\n        _, thresh_gt = cv2.threshold(ground_truth, 127, 255, 0)\n        _, thresh_p = cv2.threshold(prediction, 127, 255, 0)\n        contours_gt, _ = cv2.findContours(thresh_gt, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        contours_p, _ = cv2.findContours(thresh_p, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        overlap_img = cv2.drawContours(original_img, contours_gt, 0, (0, 255, 0), 1)\n        overlap_img = cv2.drawContours(overlap_img, contours_p, 0, (255,36,0), 1)#255,0,0\n        prediction_overlap.append(overlap_img)\n\n    return prediction_overlap\n    \nprediction_overlap_r = batch_preds_overlap(model, test_samples)","649ed93d":"pred_overlap_5x1_r = []\npred_overlap_5x3_r = []\n\nfor i in range(5, 105+5, 5):\n    pred_overlap_5x1_r.append(np.hstack(np.array(prediction_overlap_r[i-5:i])))\n\nfor i in range(3, 21+3, 3):\n    pred_overlap_5x3_r.append(np.vstack(pred_overlap_5x1_r[i-3:i]))","77c1efb4":"def plot_plate_overlap(batch_preds, title, num):\n    plt.figure(figsize=(15, 15))\n    plt.imshow(batch_preds)\n    plt.axis(\"off\")\n\n    plt.figtext(0.76,0.75,\"Green - Ground Truth\", va=\"center\", ha=\"center\", size=20,color=\"lime\");\n    plt.figtext(0.26,0.75,\"Red - Prediction\", va=\"center\", ha=\"center\", size=20, color=\"#ff0d00\");\n    plt.suptitle(title, y=.80, fontsize=20, weight=\"bold\", color=\"#00FFDE\");\n\n    fn = \"_\".join((title+str(num)).lower().split()) + \".png\"\n    plt.savefig(fn, bbox_inches='tight', pad_inches=0.2, transparent=False, facecolor='black')\n    plt.close()\n\ntitle = \"Predictions of UNet\"\n\nfor num, batch in enumerate(pred_overlap_5x3_r):\n    plot_plate_overlap(batch,title, num)","ec811874":"from PIL import Image\n\ndef make_gif(title):\n    base_name = \"_\".join(title.lower().split())\n\n    base_len = len(base_name) \n    end_len = len(\".png\")\n    fp_in = f\"{base_name}*.png\"\n    fp_out = f\"{base_name}.gif\"\n\n    img, *imgs = [Image.open(f) \n                  for f in sorted(glob.glob(fp_in), key=lambda x : int(x[base_len:-end_len]))]\n\n    img.save(fp=fp_out, format='GIF', append_images=imgs,\n             save_all=True, duration=1000, loop=0)\n    \n    return fp_out\n\nfn = make_gif(title)","43687467":"from IPython.display import Image as Image_display\nwith open(fn,'rb') as f:\n    display(Image_display(data=f.read(), format='png'))","65f9004f":"torch.save(model.state_dict(), 'unet-model.ckpt')","2b5eb8a7":"### Create dataset","73911720":"## 2. Explore Data","e955aa3a":"### References\n1: https:\/\/www.kaggle.com\/bonhart\/brain-mri-data-visualization-unet-fpn<br>\n2: https:\/\/github.com\/milesial\/Pytorch-UNet<br>\n3: https:\/\/arxiv.org\/pdf\/1505.04597v1.pdf","8bc4567a":"## 1. Import packages","47e43c4b":"## 7. Train History","af207818":"## 5. Metric and Loss Function","b22f398f":"## 6. Train Model","6bdbf9f6":"### Split data into `train`\/`validation`\/`test` set","eafb4ce9":"## 3. Data Generator and Augmentation","ece71ccb":"## 8. Prediction","45605220":"### Visualize Image with Mask","6bdbef43":"### Creating DataFrame","fb80f4a4":"## 4. Create Model"}}