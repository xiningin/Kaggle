{"cell_type":{"3ed0f7a5":"code","28d8111c":"code","c3849e74":"code","cc2a779d":"code","a6250a18":"code","87eca25a":"code","cebd593b":"code","2c7ccccf":"code","149a8d85":"code","0415b93f":"code","2ff553b8":"code","244352ff":"code","394c9fbf":"code","93755774":"markdown","9debf9a6":"markdown","b5177f14":"markdown","3e43a70d":"markdown","e6667574":"markdown","1605d247":"markdown","11fa9b62":"markdown","cb42d7ec":"markdown","791d6f0a":"markdown","1bb4a420":"markdown","b380d096":"markdown","b6e2efd2":"markdown","4480435c":"markdown","325428de":"markdown","74d8edc2":"markdown"},"source":{"3ed0f7a5":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nfrom sklearn.preprocessing import StandardScaler","28d8111c":"dataset = pd.read_csv('..\/input\/predicting-a-pulsar-star\/pulsar_stars.csv')\ndataset.head(5)","c3849e74":"dataset.isnull().sum()","cc2a779d":"dataset.describe().T","a6250a18":"plt.figure(figsize = (12, 8))\nplot = sns.countplot(dataset['target_class'])\nplot.set_title(\"Target Class count\")\nfor p in plot.patches:\n    plot.annotate('{}'.format(p.get_height()), xy = (p.get_x() + 0.35, p.get_height() + 40))","87eca25a":"plt.figure(figsize = (12, 8))\nsns.heatmap(dataset.corr(), annot = True, fmt = \".2f\")","cebd593b":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(dataset.iloc[:, :-1])\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['Principal component 1', 'Principal component 2'])\nprincipalDf = pd.concat([principalDf, dataset.iloc[:, -1]], axis = 1)","2c7ccccf":"plt.figure(figsize = (20, 12))\nsns.scatterplot(x = 'Principal component 1', \n                y = 'Principal component 2', \n                data = principalDf,\n               hue = 'target_class')","149a8d85":"X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], random_state = 0, test_size = 0.3)","0415b93f":"def metrics(model, y_true, y_pred):\n    print(\"The accuracy of the model {} is: {:.2f}%\".format(model, accuracy_score(y_true, y_pred)*100))\n    print(\"Confusion matrix for {}\".format(model))\n    print(confusion_matrix(y_true, y_pred))\n    print(\"-\"*40)","2ff553b8":"standardScaler = StandardScaler()\nX_train = standardScaler.fit_transform(X_train)\nX_test = standardScaler.transform(X_test)","244352ff":"# Support Vector Classifier\nsupportVectorClassifier = SVC(kernel = 'rbf')\nsupportVectorClassifier.fit(X_train, y_train)\n\n# Random Forest Classifier\nrandomForestClassifier = RandomForestClassifier(n_estimators = 100)\nrandomForestClassifier.fit(X_train, y_train)\n\n# Artificial Neural Network\nartificialNeuralNetwork = Sequential()\nartificialNeuralNetwork.add(Dense(units = 32, activation = 'relu', input_dim = 8))\nartificialNeuralNetwork.add(Dropout(0.5))\nartificialNeuralNetwork.add(Dense(units = 64, activation = 'relu'))\nartificialNeuralNetwork.add(Dropout(0.5))\nartificialNeuralNetwork.add(Dense(units = 128, activation = 'relu'))\nartificialNeuralNetwork.add(Dropout(0.5))\nartificialNeuralNetwork.add(Dense(units = 1, activation = 'sigmoid'))\nartificialNeuralNetwork.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nartificialNeuralNetwork.fit(X_train, y_train, epochs = 50, shuffle = False, validation_split = 0.1, verbose = 0)","394c9fbf":"# Support Vector Classifier\nmetrics(\"Support Vector Classifier\", y_test, supportVectorClassifier.predict(X_test)) \n\n# Random Forest Classifier\nmetrics(\"Random Forest Classifier\", y_test, randomForestClassifier.predict(X_test)) \n\n# Artificial Neural Network\nmetrics(\"Artificial Neural Network\", y_test, (artificialNeuralNetwork.predict(X_test) > 0.5))","93755774":"There are no null values in the dataset, thus I can proceed with direcly working with the complete dataset.","9debf9a6":"Given the size and range of each column is varied, it's always a good practice to scale the data.","b5177f14":"## Machine and Deep Learning\n\nI'll now explore two machine learning models and one Artificial Neural Network to classify between the stars. But first, I'll split the data into training (70%) and testing (30%) data.","3e43a70d":"## Import libraries","e6667574":"The dataset is highly imbalanced. The number of non-pulsar data points is approcimately 10 times the number of pulsar data points.","1605d247":"# Using ML\/DL to predict Pulsar Star\n\nIn this notebook, I'll explore the dataset of pulsar stars and use multiple Machine and Deep learning models to classify between pulsar and other stars.","11fa9b62":"From the heatmap, we can see that `Mean of the integrated profile`, `Excess kurtosis of the integrated profile` and `Skewness of the integrated profile` are highly correlated features to the target class.","cb42d7ec":"## Exploratory Data Analysis\n\nI'll next take a look at the dataset and its various features.","791d6f0a":"## Import dataset\n\nI'll import the dataset and take a quick view about the details of the dataset.","1bb4a420":"Taking a look at the results above we can see that **Random Forest Classifier** performs the best classification. It's amazing how it's able to classify both pulsar and non-pulsar stars with greater accuracy as can be seen from the confusion matrix.","b380d096":"### Model creation and training\n\nI'll create a Support Vector Classifier, Random Forest Classifier and an Artificial Neural Network.","b6e2efd2":"### Training and results\n\nLet's now test the models and see the accuracy and confusion matrices.","4480435c":"I'll define a `metrics` method which would allow us to easily get the accuracy and confusion matrix.","325428de":"As is clear from the table above, the values in each column vary across different ranges and thus, using scaling on the dataset would really help in model training and prediction without bias towards any specific feature.","74d8edc2":"barring a few outliers, the PCA analysis reveals that the data is quite separable when we consider just two principal features."}}