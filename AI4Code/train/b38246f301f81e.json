{"cell_type":{"5cd03260":"code","06f74e1d":"code","d17962d2":"code","ca9d05e3":"code","34d636b0":"code","591d3a06":"code","f6a11cd1":"code","e19597f1":"code","0ed8d7a6":"code","dcfc6be7":"code","169c31a1":"code","8e523751":"code","7c6a7a9b":"code","65297eb9":"code","cfa59dac":"code","b5b8988d":"code","b2f9709b":"code","fdecbaa9":"code","c8a52da6":"code","807d4f73":"code","434868fc":"code","8d48d092":"code","0c230336":"code","9de3d5a3":"code","25172249":"code","5fa972db":"markdown","fba97eba":"markdown","418c7e34":"markdown","7650b07e":"markdown","d0db4f8f":"markdown","b4428c91":"markdown","0b6b81c1":"markdown","14677db6":"markdown","cc2a6b81":"markdown","c8d8d74f":"markdown","914cccfe":"markdown","bf7be5fe":"markdown","698fee29":"markdown","fb894eda":"markdown","b26457ce":"markdown","450dce8b":"markdown","5015122a":"markdown","773b7da5":"markdown","99597215":"markdown","f5b07269":"markdown","3d034b98":"markdown","c4465393":"markdown","cd3e2aed":"markdown","e30d5878":"markdown","11504394":"markdown","ab29e313":"markdown","7cbbc3dd":"markdown","c5477597":"markdown","ec62a2f5":"markdown","11b1c8f7":"markdown","0e1a8882":"markdown","5e5d2110":"markdown","0ccdc558":"markdown","9e3b4a6e":"markdown","f613155f":"markdown","1f9e0f24":"markdown","3f4fa37f":"markdown","2247758b":"markdown","d3c06130":"markdown","db1cc4c0":"markdown","fa4353ef":"markdown","744994d2":"markdown","5baae3f9":"markdown","9101485d":"markdown","8d721f93":"markdown","949f2ca0":"markdown","8d62cc0b":"markdown"},"source":{"5cd03260":"housing_data_path: str = \"..\/input\/california-housing-prices-data-extra-features\/California_Houses.csv\"","06f74e1d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot as plt\nfrom typing import Dict, List\n%matplotlib inline\nsns.set_style(\"darkgrid\")\npd.options.mode.chained_assignment = None","d17962d2":"housing_df: pd.DataFrame = pd.read_csv(housing_data_path)","ca9d05e3":"housing_df.head()","34d636b0":"housing_df.info()","591d3a06":"housing_df.describe()","f6a11cd1":"fig, ax = plt.subplots(4, 3, figsize=[15,15])\nsns.histplot(data=housing_df, x=\"Median_House_Value\", ax=ax[0, 0])\nsns.histplot(data=housing_df, x=\"Median_Income\", ax=ax[0, 1])\nsns.histplot(data=housing_df, x=\"Median_Age\", ax=ax[0, 2])\nsns.histplot(data=housing_df, x=\"Tot_Rooms\", ax=ax[1, 0])\nsns.histplot(data=housing_df, x=\"Tot_Bedrooms\", ax=ax[1, 1])\nsns.histplot(data=housing_df, x=\"Population\", ax=ax[1, 2])\nsns.histplot(data=housing_df, x=\"Households\", ax=ax[2, 0])\nsns.histplot(data=housing_df, x=\"Distance_to_coast\", ax=ax[2, 1])\nsns.histplot(data=housing_df, x=\"Distance_to_LA\", ax=ax[2, 2])\nsns.histplot(data=housing_df, x=\"Distance_to_SanDiego\", ax=ax[3, 0])\nsns.histplot(data=housing_df, x=\"Distance_to_SanJose\", ax=ax[3, 1])\nsns.histplot(data=housing_df, x=\"Distance_to_SanFrancisco\", ax=ax[3, 2])\nfig.tight_layout()\nplt.show()","e19597f1":"housing_df_train: pd.DataFrame = None\nhousing_df_test: pd.DataFrame = None\nhousing_df_train, housing_df_test = train_test_split(\n    housing_df, test_size=0.3, random_state=0)","0ed8d7a6":"plt.figure(figsize=(10, 5))\nsns.scatterplot(data=housing_df_train, x=\"Longitude\", y=\"Latitude\")\nplt.show()","dcfc6be7":"plt.figure(figsize=(10, 5))\nsns.scatterplot(data=housing_df_train, x=\"Longitude\", y=\"Latitude\", alpha=0.1)\nplt.show()","169c31a1":"plt.figure(figsize=(10, 5))\ng = sns.scatterplot(data=housing_df_train, x=\"Longitude\", y=\"Latitude\",\n                    hue=\"Median_House_Value\", size=\"Population\",\n                    alpha=0.1, palette=\"terrain_r\")\ng.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\nplt.show()","8e523751":"corr: pd.DataFrame = housing_df_train.corr(method=\"pearson\")","7c6a7a9b":"corr[\"Median_House_Value\"].sort_values(ascending=False)","65297eb9":"fig, ax = plt.subplots(1, 2, figsize=[10, 5])\nsns.regplot(data=housing_df_train, x=\"Median_Income\", y=\"Median_House_Value\",\n            line_kws={\"color\": \"red\"}, scatter_kws={\"alpha\":0.1}, ax=ax[0])\nsns.regplot(data=housing_df_train, x=\"Distance_to_coast\",\n            y=\"Median_House_Value\", line_kws={\"color\": \"red\"},\n            scatter_kws={\"alpha\":0.1}, ax=ax[1])\nax[0].set(ylim=(0, 550000))\nax[1].set(ylim=(0, 550000))\nfig.tight_layout()\nplt.show()","cfa59dac":"housing_df_train['rooms_per_household'] = (\n    housing_df_train['Tot_Rooms'] \/ housing_df_train['Households'])\nhousing_df_train['bedrooms_per_household'] = (\n    housing_df_train['Tot_Bedrooms'] \/ housing_df_train['Households'])\nhousing_df_train['bedrooms_per_room'] = (\n    housing_df_train['Tot_Bedrooms'] \/ housing_df_train['Tot_Rooms'])\nhousing_df_train['population_per_household'] = (\n    housing_df_train['Population'] \/ housing_df_train['Households'])","b5b8988d":"corr: pd.DataFrame = housing_df_train.corr(method=\"pearson\")","b2f9709b":"corr[\"Median_House_Value\"].sort_values(ascending=False)","fdecbaa9":"x_train: pd.DataFrame = housing_df_train.drop(\"Median_House_Value\", axis=1)\ny_train: pd.DataFrame = housing_df_train[\"Median_House_Value\"].copy()","c8a52da6":"scaler: StandardScaler = StandardScaler()\nx_train_processed: np.ndarray = scaler.fit_transform(x_train)","807d4f73":"linear_reg: LinearRegression = LinearRegression()\nscores: np.ndarray = cross_val_score(\n    linear_reg, x_train_processed, y_train, cv=5, \n    scoring=\"neg_root_mean_squared_error\")\nprint((f\"{round(abs(scores.mean()), 2)} RMSE with a standard\"\n    f\"deviation of {round(scores.std(), 2)}\"))","434868fc":"# define parameters\nparam: Dict[str, List] = {\n    \"max_features\": [4, 6, 8, 10],\n    \"max_depth\": [10, 20, 30],\n    \"max_leaf_nodes\": [100, 300, 600]\n}\n\n# define model\ntree_reg: DecisionTreeRegressor = DecisionTreeRegressor()\n\n# define search\nsearch: GridSearchCV = GridSearchCV(\n    tree_reg, param, scoring=\"neg_root_mean_squared_error\", cv=5)\n\n# fit the search \nsearch.fit(x_train_processed, y_train)\n\n# get mean score\nmean_score: float = abs(\n    search.cv_results_[\"mean_test_score\"][search.best_index_])\n\n# get standard deviation score\nstd_score: float = abs(\n    search.cv_results_[\"std_test_score\"][search.best_index_])\n\n# print the results \nprint((f\"{round(mean_score, 2)} RMSE with a standard \"\n    f\"deviation of {round(std_score, 2)}\"))\n\n# print best parameters \nprint((f\"Best parameters: {search.best_params_}\"))","8d48d092":"# define parameters\nparam: Dict[str, List] = {\n    \"n_estimators\": [3, 10, 30], \n    \"max_features\": [2, 4, 6, 8],\n}\n\n# define model\nforest_reg: RandomForestRegressor = RandomForestRegressor()\n\n# define search\nsearch: GridSearchCV = GridSearchCV(\n    forest_reg, param, scoring=\"neg_root_mean_squared_error\", cv=5)\n\n# fit the search \nsearch.fit(x_train_processed, y_train)\n\n# get mean score\nmean_score: float = abs(\n    search.cv_results_[\"mean_test_score\"][search.best_index_])\n\n# get standard deviation score\nstd_score: float = abs(\n    search.cv_results_[\"std_test_score\"][search.best_index_])\n\n# print the results \nprint((f\"{round(mean_score, 2)} RMSE with a standard \"\n    f\"deviation of {round(std_score, 2)}\"))\n\n# print best parameters \nprint((f\"Best parameters: {search.best_params_}\"))","0c230336":"# create attribute combinations on test set\nhousing_df_test[\"rooms_per_household\"] = (\n    housing_df_test[\"Tot_Rooms\"] \/ housing_df_test[\"Households\"])\nhousing_df_test[\"bedrooms_per_household\"] = (\n    housing_df_test[\"Tot_Bedrooms\"] \/ housing_df_test[\"Households\"])\nhousing_df_test[\"bedrooms_per_room\"] = (\n    housing_df_test[\"Tot_Bedrooms\"] \/ housing_df_test[\"Tot_Rooms\"])\nhousing_df_test[\"population_per_household\"] = (\n    housing_df_test[\"Population\"] \/ housing_df_test[\"Households\"])\n\n# create labels and features\nx_test: pd.DataFrame = housing_df_test.drop(\"Median_House_Value\", axis=1)\ny_test: pd.DataFrame = housing_df_test[\"Median_House_Value\"].copy()\n\n# apply feature scaling\nx_test_processed: np.ndarray = scaler.fit_transform(x_test)","9de3d5a3":"# define model\nforest_reg = RandomForestRegressor(\n    max_features=4, n_estimators=30)\n\n# fit the model \nforest_reg.fit(x_train_processed, y_train)\n\n# predict \ny_pred = forest_reg.predict(x_test_processed)\n\n# get mean score\nrmse = abs(mean_squared_error(y_test, y_pred, squared=False))\n\n# print the results \nprint(f\"{round(rmse, 2)} RMSE on test set\")","25172249":"sorted(zip(forest_reg.feature_importances_, x_train.columns), reverse=True)","5fa972db":"Let\"s divide our feature and labels in the test set after adding the attribute combinations and apply feature scaling:","fba97eba":"Let\"s create some reasonable attribute combinations:","418c7e34":"Let\"s try a decision tree regression:","7650b07e":"This is better!","d0db4f8f":"### ***Evaluate Model on the Test Set***","b4428c91":"### ***Import Packages***","0b6b81c1":"et\"s compute the standard correlation coefficient (Pearson\u2019s r):","14677db6":"This plot reveals a few things. First, the correlation For Median_House_Value and Median_Income is very strong, we can clearly see the upward trend and the points are not too dispersed. Second there is a little weaker correlation For Median_House_Value and Distance_to_coast we can clearly see the downward trend.\n","cc2a6b81":"Now let\u2019s look at how much each attribute correlates with the median house value:","c8d8d74f":"As we can see the housing prices are very much related to the location\n(e.g., close to the ocean) and to the population density.","914cccfe":"Let\"s compute the standard correlation coefficient (Pearson\u2019s r):","bf7be5fe":"Let\"s divide our feature and labels:","698fee29":"Before we perform an EDA and gain some knowledge from our data we should create a test set. We create a test set before the eda in order to ensure no \"peeking ahead\".","fb894eda":"Let\u2019s take a look at the top five rows:","b26457ce":"Let\u2019s load the data set using Pandas:","450dce8b":"### ***Decision Tree Regressor***","5015122a":"### ***Data Cleaning***","773b7da5":"This looks like California all right, but other than that it is hard to see any particular pattern. let\"s visualize the places where there is a high density of data points:","99597215":"### ***Splitting Data - Train and Test Sets***","f5b07269":"A few things in these histograms we should notice:\n\n2. The attributes have very different scales - we should perform feature scaling.\n\n3. Many histograms are tail heavy - they extend much farther to the right of\nthe median than to the left. This may make it a bit harder for some Machine\nLearning algorithms to detect patterns. We need to transform these to have more bell-shaped distributions.","3d034b98":"### ***Looking for Correlations on Attribute Combinations***","c4465393":"Let\"s train our model and evaluate on the test set:","cd3e2aed":"### ***Linear Regression***","e30d5878":"### ***Random Forest Regressor***","11504394":"First model we will try is a simple linear regression:","ab29e313":"Since there is geographical information (latitude and longitude), let\"s\ncreate a scatterplot of all districts to visualize the data:","7cbbc3dd":"Lets load all the needed packages for this notebook:","c5477597":"### ***Visualizing Geographical Data***","ec62a2f5":"### ***The Dataset***","11b1c8f7":"We can see that:\n\n1. There are 20,640 instances in the dataset.\n\n2. There are no missing values.\n\n3. All the values are numeric (float or int).\n\nNext, let\"s display some statistical summaries of the numerical columns:","0e1a8882":"We can see that each row represents one district and has 14 attributes:\n- Median_House_Value - Median house value for households within a block (measured in US Dollars).\n- Median_Income - Median income for households within a block of houses (measured in tens of thousands of US Dollars).\n- Median_Age - Median age of a house within a block; a lower number is a newer building.\n- Tot_Rooms - Total number of rooms within a block.\n- Tot_Bedrooms - Total number of bedrooms within a block.\n- Population - Total number of people residing within a block.\n- Households - Total number of households, a group of people residing within a home unit, for a block.\n- Latitude - A measure of how far north a house is; a higher value is farther north.\n- Longitude - A measure of how far west a house is; a higher value is farther west.\n- Distance_to_coast - Distance to the nearest coast point. \n- Distance_to_LA - Distance to the centre of Los Angeles.\n- Distance_to_SanDiego - Distance to the centre of San Diego.\n- Distance_to_SanJose - Distance to the centre of San Jose. \n- Distance_to_SanFrancisco - Distance to the centre of San Francisco.","5e5d2110":"Clearly this is not a great score. The Median_House_Value ranges between 14999 to 500000 so a typical prediction error of 67886 is not very satisfying.","0ccdc558":"### ***Looking for Correlations***","9e3b4a6e":"### ***Quick Look at the Data***","f613155f":"We can see our model overfits a little bit but still our RMSE result is not bad.\n\nLastly let\u2019s display the importance scores for each attribute:","1f9e0f24":"Now we can clearly see the high-density areas, namely the Bay\nArea and around Los Angeles and San Diego, plus a long line of fairly high density in the Central Valley, in particular around Sacramento and Fresno.\n\nLastly let\"s add the housing prices and district population to the scatter plot:","3f4fa37f":"As we saw above we need to apply feature scaling:","2247758b":"We can see that Median_Income and Distance_to_coast are the most correlated to Median_House_Value, let\"s plot their correlation:","d3c06130":"# ***California Housing Prices Prediction***\n\nThis notebook shows the process and orientation in building a model to predict housing prices in California.\n\nThis notebook was created by: ***Leor Ariel Rose***","db1cc4c0":"For this notebook we will use the [California Housing Prices Data (5 new features!)](https:\/\/www.kaggle.com\/fedesoriano\/california-housing-prices-data-extra-features).\nThis dataset is based on data from the 1990 California cen\u2010sus.\n\nPlease download the data set, upload it to the notebook environment and define the path to the dataset:","fa4353ef":"Now let\u2019s look at how much each attribute correlates with the median house value:","744994d2":"This is better from linear regression but it\"s not a great score. The Median_House_Value ranges between 14999 to 500000 so a typical prediction error of 59518 is not very satisfying.","5baae3f9":"Let\"s try a random forest regression:","9101485d":"Next, let\"s get a quick overview of the dataset (total number of rows, each attribute\u2019s type and number of non-null values):","8d721f93":"We can see that rooms_per_household and bedrooms_per_room are much more correlated with the Median_House_Value than the total number of rooms,bedrooms and households.","949f2ca0":"Lastly, let\"s display a histogram for each value except Latitude and Longitude (no knowledge will be gained from plotting a histogram of these attributes):","8d62cc0b":"### ***Load Data***"}}