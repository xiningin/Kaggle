{"cell_type":{"1c7324fa":"code","5fbdcdfe":"code","29a49376":"code","efd101b8":"code","3c024a52":"code","497deb33":"code","650737ab":"code","73c48515":"code","9a6af617":"code","ba91753b":"code","ac69e3db":"code","ccda6e48":"code","fc34c619":"code","f803f1a7":"code","6aca70ca":"code","4a5cc05f":"code","9067b6d0":"code","bfb92647":"code","921df996":"code","c4758c71":"code","5e673f2f":"code","8b2f7635":"markdown"},"source":{"1c7324fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import r2_score,accuracy_score,mean_squared_error\nimport tensorflow as tf \nfrom tensorflow.keras.callbacks import EarlyStopping\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","5fbdcdfe":"prediction_data=pd.read_csv(\"..\/input\/titanic\/test.csv\")\nprediction_data.set_index('PassengerId', inplace=True)\nprediction_data_copy=prediction_data","29a49376":"df=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf.set_index('PassengerId', inplace=True)\ndf","efd101b8":"df.drop(\"Name\",axis=1,inplace=True)\nprediction_data.drop(\"Name\",axis=1,inplace=True)\ndf","3c024a52":"df.info()","497deb33":"df.describe()","650737ab":"df.isna().sum()\nprediction_data.isna().sum()","73c48515":"df.duplicated().sum()","9a6af617":"df.drop([\"Cabin\",\"Ticket\"],axis=1,inplace=True)#cabin missing too many values, hence it's best to be removed; name is irrelevant to the model\nprediction_data.drop([\"Cabin\",\"Ticket\"],axis=1,inplace=True)","ba91753b":"y=pd.get_dummies(df[\"Pclass\"]) #One hot encoding the  passenger class\ny.columns = ['1st class','2nd class', '3rd class']\ndf.drop(\"Pclass\",axis=1,inplace=True)\ndf=df.join(y)\nprint(df.columns)\ny=pd.get_dummies(df[\"Embarked\"]) #One hot encoding the  passenger class\ndf.drop(\"Embarked\",axis=1,inplace=True)\ny.columns = ['Cherbourg','Queenstown', 'Southampton']\ndf=df.join(y)\ny=pd.get_dummies(df[\"Sex\"]) #One hot encoding the  passenger class\ndf.drop(\"Sex\",axis=1,inplace=True)\n\ndf=df.join(y)\nprint(df)\n\ny=pd.get_dummies(prediction_data[\"Pclass\"]) #One hot encoding the  passenger class\ny.columns = ['1st class','2nd class', '3rd class']\nprediction_data.drop(\"Pclass\",axis=1,inplace=True)\nprediction_data=prediction_data.join(y)\nprint(prediction_data.columns)\ny=pd.get_dummies(prediction_data[\"Embarked\"]) #One hot encoding the  passenger class\nprediction_data.drop(\"Embarked\",axis=1,inplace=True)\ny.columns = ['Cherbourg','Queenstown', 'Southampton']\nprediction_data=prediction_data.join(y)\ny=pd.get_dummies(prediction_data[\"Sex\"]) #One hot encoding the  passenger class\nprediction_data.drop(\"Sex\",axis=1,inplace=True)\nprediction_data=prediction_data.join(y)","ac69e3db":"df['Age'].fillna((df['Age'].mean()), inplace=True)\nprediction_data['Age'].fillna((prediction_data['Age'].mean()), inplace=True)\nprediction_data['Fare'].fillna((prediction_data['Age'].mean()), inplace=True)\nprint(prediction_data.isna().sum())","ccda6e48":"#checking for highly collinear variables\nplt.figure(figsize=(12,4))\nsns.heatmap(data=df.corr(), cmap='coolwarm', annot=True)","fc34c619":"X=df.drop(\"Survived\",axis=1)\ny=df[[\"Survived\"]]\nprint(df,prediction_data)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n\nscaler=StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\ncopy_prediction_data=prediction_data\nprediction_data=scaler.transform(prediction_data)","f803f1a7":"print(X_train)\nprint(prediction_data)\n","6aca70ca":"#RandomForestClassifier\nrandomforest_classifier=RandomForestClassifier()\nrandomforest_classifier.fit(X_train,y_train)\npred=randomforest_classifier.predict(X_test)\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_randomforest = model_selection.cross_validate(estimator=randomforest_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_randomforest = model_selection.cross_validate(estimator=randomforest_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_randomforest['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_randomforest['test_score'].mean()*100)","4a5cc05f":"#LogisticRegressor\nlogistic_regressor = LogisticRegression() #initialising logistic regression\nlogistic_regressor.fit(X_train,y_train) #fitting the data\ny_pred = logistic_regressor.predict(X_test) #predict the result\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_logistic_regressor = model_selection.cross_validate(estimator=logistic_regressor , X=X_train , y= y_train , cv = 10)\ntest_accuracy_logistic_regressor = model_selection.cross_validate(estimator=logistic_regressor , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_logistic_regressor['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_logistic_regressor['test_score'].mean()*100)","9067b6d0":"#KNeighborsClassifier\nkneighbors_classifier = KNeighborsClassifier() #initialising the kneighbors algorithm\nkneighbors_classifier.fit(X_train, y_train) #fitting the data\n\nprint(\"Accuracy with cross validation\")\ntrain_accuracy_kneighbors = model_selection.cross_validate(estimator=kneighbors_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_kneighbors = model_selection.cross_validate(estimator=kneighbors_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_kneighbors['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_kneighbors['test_score'].mean()*100)","bfb92647":"#XGB Classifier\nxgb_classifier = XGBClassifier()\nxgb_classifier.fit(X_train , y_train)\n\nprint(\"Accuracy with cross validation\")\n\ntrain_accuracy_xgb = model_selection.cross_validate(estimator=xgb_classifier , X=X_train , y= y_train , cv = 10)\ntest_accuracy_xgb = model_selection.cross_validate(estimator=xgb_classifier , X=X_test , y= y_test , cv = 10)\nprint(\"Training accuracy:\",train_accuracy_xgb['test_score'].mean()*100) \nprint(\"Testing accuracy:\",test_accuracy_xgb['test_score'].mean()*100)","921df996":"ann_classifier=tf.keras.models.Sequential()\nann_classifier.add(tf.keras.layers.Dense(units = 16 , activation='relu')) \nann_classifier.add(tf.keras.layers.Dense(units = 1 , activation='sigmoid'))\nann_classifier.compile(optimizer='adam', loss='binary_crossentropy' , metrics= ['accuracy'] )\n\nearly_stopping = EarlyStopping(\n  monitor='accuracy', min_delta=0.0001,\n  patience=20)\nann_classifier.fit(X_train , y_train, batch_size= 32 , epochs= 2000,callbacks=[early_stopping])\n","c4758c71":"prediction1=randomforest_classifier.predict(prediction_data)\nprediction2=logistic_regressor.predict(prediction_data)\nprediction3=kneighbors_classifier.predict(prediction_data)\nprediction4=ann_classifier.predict(prediction_data)\nprint(prediction4.size)\nprint(prediction4)\nprediction4 = (prediction4 > 0.5).astype(int).reshape(prediction_data.shape[0])\nprint(prediction4.size)\n# predictions_df=pd.DataFrame(data={\"ID\":prediction_data_copy[\"PassengerId\"],\"Predictions\":prediction1})\n# predictions_df.to_csv(\"predictions1_df.csv\",index=False,quoting=3,sep=',')\n# predictions_df=pd.DataFrame(data={\"ID\":prediction_data_copy[\"PassengerId\"],\"Predictions\":prediction2})\n# predictions_df.to_csv(\"predictions2_df.csv\",index=False,quoting=3,sep=',')\n# predictions_df=pd.DataFrame(data={\"ID\":prediction_data_copy[\"PassengerId\"],\"Predictions\":prediction2})\n# predictions_df.to_csv(\"predictions3_df.csv\",index=False,quoting=3,sep=',')","5e673f2f":"print(prediction4.size)\nprint(prediction_data_copy.index)\npredictionsdf = pd.DataFrame(prediction_data_copy.index)\npredictionsdf[\"Survived\"]=prediction4\npredictionsdf\npredictionsdf\npredictionsdf.to_csv(\"submission.csv\",index=False,sep=',')","8b2f7635":"<h3><center>We have some missing values<\/center><\/h3>"}}