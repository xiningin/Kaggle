{"cell_type":{"4eb3fdca":"code","bd5ee21b":"code","404f5458":"code","0fcc836e":"code","30d9cc70":"code","6ea1a029":"code","6e3f7128":"code","6c87bc0f":"code","441c31ca":"code","51fdeac4":"code","58d36ea9":"code","262027e4":"code","ff254ec3":"code","d255eaf6":"code","2422e2ac":"code","e742f88b":"code","67f2c2cd":"code","40e99144":"code","85220085":"code","8fccc8f1":"code","0130534f":"code","62fb45df":"code","b13f5b9d":"code","561b0ba6":"code","4cdeeb41":"code","05df0e00":"markdown","54574a41":"markdown","9d19c484":"markdown","adc47889":"markdown","bd66c1df":"markdown","159f8ac2":"markdown","56c1b547":"markdown","24bfc7bd":"markdown","0305fe70":"markdown"},"source":{"4eb3fdca":"import numpy as np\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras import regularizers\nimport pandas as pd\nfrom IPython.display import HTML","bd5ee21b":"#Generating Data\n\nimage_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255,validation_split=0.2)\n\nimg_data_train=image_generator.flow_from_directory('..\/input\/MLChallenge\/ML\/Train',target_size=(224,224),subset='training')\n\nimg_data_val=image_generator.flow_from_directory('..\/input\/MLChallenge\/ML\/Train',target_size=(224,224),subset='validation')\n\n","404f5458":"#Display Different Classes\nimg_data_train.class_indices","0fcc836e":"class_names=['Bakery','Battery','Cleanser','Confectional products','Dairy Products','Frozen Food','Fruits','Ice Cream','Instant',\n            'Personal care','Poultry products','Snacks','beverages','canned','care','cereals','chips','chocolates','vegetables']\nprint(len(class_names))","30d9cc70":"#Funcn to view and analayze data\n\ndef display(img_batch,label_batch):\n    plt.figure(figsize=(10,9))\n    plt.subplots_adjust(wspace=0.7,hspace=0.7)\n    for i in range(30):\n        plt.subplot(6,5,i+1)\n        plt.imshow(img_batch[i])\n        plt.title(class_names[np.argmax(label_batch[i])])","6ea1a029":"for sample_batch,sample_label in img_data_train:\n    print(sample_batch.shape)\n    print(sample_label.shape)\n    break","6e3f7128":"display(sample_batch,sample_label)","6c87bc0f":"feature_extract_url=\"https:\/\/tfhub.dev\/tensorflow\/resnet_50\/feature_vector\/1\"\n\n    \nfeature_extraction_layer=hub.KerasLayer(str(feature_extract_url),input_shape=(224,224,3))\n\nfeature_extraction_layer.trainable=False\n\nsteps_per_epoch=np.ceil(img_data_train.samples\/img_data_train.batch_size)","441c31ca":"#EARLY STOPPING\n\nearly_stop=keras.callbacks.EarlyStopping(monitor='val_loss',patience=15)\n\n\n#LEARNING RATE DECAY\nlr_schedule=tf.keras.optimizers.schedules.InverseTimeDecay(\n  0.0001,\n  decay_steps=steps_per_epoch*500,\n  decay_rate=1,\n  staircase=True)\n\ndef get_optimizer():\n    return tf.keras.optimizers.Adam(lr_schedule)","51fdeac4":"model=tf.keras.Sequential([\nfeature_extraction_layer,\nkeras.layers.Dropout(0.5),\n# keras.layers.Dense(800,activation='relu',kernel_regularizer=regularizers.l2(0.009)),\n# # keras.layers.Dropout(0.6),  \n# keras.layers.Dense(800,activation='relu',kernel_regularizer=regularizers.l2(0.00001)),\n\n\ntf.keras.layers.Dense(img_data_train.num_classes,activation='softmax')\n])\n\nmodel.compile(optimizer=get_optimizer(),loss='categorical_crossentropy',metrics=['accuracy'])","58d36ea9":"steps=np.ceil(img_data_train.samples\/img_data_train.batch_size)\n\nhistory=model.fit(img_data_train,epochs=102,validation_data=img_data_val,steps_per_epoch=steps,verbose=0)","262027e4":"feature_extract_url2=\"https:\/\/tfhub.dev\/google\/efficientnet\/b1\/feature-vector\/1\"\n\n    \nfeature_extraction_layer2=hub.KerasLayer(str(feature_extract_url2),input_shape=(224,224,3))\n\nfeature_extraction_layer2.trainable=False\n\nmodel2=tf.keras.Sequential([\nfeature_extraction_layer2,\nkeras.layers.Dropout(0.3),\n# keras.layers.Dense(19,activation='relu',kernel_regularizer=regularizers.l2(0.009)),\n# # keras.layers.Dropout(0.6),  \n# keras.layers.Dense(800,activation='relu',kernel_regularizer=regularizers.l2(0.00001)),\n\n\ntf.keras.layers.Dense(img_data_train.num_classes,activation='softmax',kernel_regularizer=regularizers.l2(0.009))\n])\n\nmodel2.compile(optimizer=get_optimizer(),loss='categorical_crossentropy',metrics=['accuracy'])\n\n\n\nhistory2=model2.fit(img_data_train,epochs=105,validation_data=img_data_val,steps_per_epoch=steps,verbose=0)\n","ff254ec3":"feature_extract_url3=\"https:\/\/tfhub.dev\/tensorflow\/resnet_50\/feature_vector\/1\"\n\n    \nfeature_extraction_layer3=hub.KerasLayer(str(feature_extract_url3),input_shape=(224,224,3))\n\nfeature_extraction_layer3.trainable=False\n\nmodel3=tf.keras.Sequential([\nfeature_extraction_layer3,\nkeras.layers.Dropout(0.5),\n    \n\ntf.keras.layers.Dense(img_data_train.num_classes,activation='softmax')\n])\n\nmodel3.compile(optimizer=get_optimizer(),loss='categorical_crossentropy',metrics=['accuracy'])\n\n\n\nhistory3=model3.fit(img_data_train,epochs=150,validation_data=img_data_val,steps_per_epoch=steps,verbose=0)\n","d255eaf6":"feature_extract_url4=\"https:\/\/tfhub.dev\/tensorflow\/resnet_50\/feature_vector\/1\"\n\n    \nfeature_extraction_layer4=hub.KerasLayer(str(feature_extract_url4),input_shape=(224,224,3))\n\nfeature_extraction_layer4.trainable=False\n\nmodel4=tf.keras.Sequential([\nfeature_extraction_layer4,\nkeras.layers.Dropout(0.5),\n\n\ntf.keras.layers.Dense(img_data_train.num_classes,activation='softmax')\n])\n\nmodel4.compile(optimizer=get_optimizer(),loss='categorical_crossentropy',metrics=['accuracy'])\n\n\n\nhistory4=model4.fit(img_data_train,epochs=200,validation_data=img_data_val,steps_per_epoch=steps,verbose=0)\n","2422e2ac":"plt.plot(history.history['accuracy'],label='Train Accuracy')\nplt.plot(history.history['val_accuracy'],label='Val Accuracy')\nplt.xlabel('Epcoh')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.5,1.1])","e742f88b":"plt.plot(history.history['loss'],label='Train loss')\nplt.plot(history.history['val_loss'],label='Val loss')\nplt.xlabel('Epcoh')\nplt.ylabel('loss')\nplt.legend(loc='lower right')\nplt.ylim([0,5])","67f2c2cd":"model.evaluate(img_data_val)\nmodel2.evaluate(img_data_val)\nmodel3.evaluate(img_data_val)\nmodel4.evaluate(img_data_val)","40e99144":"#Generating test data to get predictions\n\ntest_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255)\n\ntest_data=test_generator.flow_from_directory('..\/input\/MLChallenge\/ML',classes=['Test'],class_mode=None,shuffle=False,target_size=(224,224))","85220085":"predictions1=model.predict(test_data)\npredictions2=model2.predict(test_data)\npredictions3=model3.predict(test_data)\npredictions4=model4.predict(test_data)\n\npredictions=(predictions1+predictions2+predictions3+predictions4)\/4\n\n\n","8fccc8f1":"#Making sure predictions stored as per need.\npredictions.shape","0130534f":"prediction_class_index=np.argmax(predictions,axis=-1)\n","62fb45df":"#Storing Predicted class name in a list\n\npredicted_class_name=[]\nfor i in prediction_class_index:\n    predicted_class_name.append(class_names[i])\n    ","b13f5b9d":"#Storing predictins in DataFrame to generate csv\n\nimg_ids=test_data.filenames\ndf=pd.DataFrame(data=img_ids,columns=['ID'])\ndf['Class']=predicted_class_name\n\ndf=df.replace('Test\/','',regex=True)\ndf=df.replace('.jpg','',regex=True)","561b0ba6":"df.to_csv('submission.csv',index=False)\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename='submission.csv')\n","4cdeeb41":"df","05df0e00":"# Plotting Accuracy and Loss helps better visualize and analyize Training.\n\nHelps make better hyperparameter tuning decisions.","54574a41":"# Further 2 models are also built on ResNet50..\n\nResNet200 and Inception Net were also tested but due to limited data they lead to heavy overfitting and dont generalize well over validation set.\n","9d19c484":"First Model is ResNet50....feature vector obtained from tensorflow hub.","adc47889":"# Training Data is less...Model may overfit \n\nSo can use early stopping ...to get good accuracy on Validation set.\n\nUsing Learning rate decay helps optimization and also helps generalize result.\n\nWill also use Dropout.","bd66c1df":"# ****Making Predictions Human Friendly :D****","159f8ac2":"# Displaying a sample of the Training Data.","56c1b547":"# Models shows accuracy near 93%\n\nAveraging their predictions on test images should result in better predictions.","24bfc7bd":"Second Model is Efficientnet","0305fe70":"# **Classifying Grocery Items into 19 Categories!!**\n\nImporting neeeded libraries."}}