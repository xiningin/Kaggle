{"cell_type":{"4d2f157c":"code","f4461d6c":"code","a9d254d5":"code","a50cad35":"code","20abcfd3":"code","c45232f4":"code","e4e2fc21":"code","4beebd18":"code","52da4970":"code","9994a909":"code","0e030581":"code","ad62a3dd":"code","b1b4d762":"code","618b67bc":"code","71652023":"code","69c2df86":"code","3abac485":"code","3939944a":"code","14e2188d":"code","f54a1d54":"code","978550f0":"code","687273f0":"code","d4fb3ad7":"code","4549b5e2":"markdown","01e261e6":"markdown","87c1ae31":"markdown","040f3e0a":"markdown","06d71eba":"markdown","4aeb87bb":"markdown","ecebdfc5":"markdown","4fc2de63":"markdown","23c52fc0":"markdown","8339374f":"markdown","7f51181c":"markdown"},"source":{"4d2f157c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f4461d6c":"#Baixei a Biblioteca que quero usar para a an\u00e1lise \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n#ENTENDER AS BIBLIOTECAS QUE N\u00c3O CONHE\u00c7O \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.cm as cm\nimport sklearn as sk\nfrom random import seed,sample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_curve, auc,\\\nprecision_score\nimport seaborn as sns\nsns.set()\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier","a9d254d5":"#Leio os dados\ndata = pd.read_csv (\"..\/input\/paysim1\/PS_20174392719_1491204439457_log.csv\") \ndata.info()","a50cad35":"#Descri\u00e7\u00e3o dos dados \n#Generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values.\n#Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types. The output will vary depending on what is provided.\ndata.describe().T","20abcfd3":"data.shape","c45232f4":"data.head (20)\n#observa\u00e7\u00e3o - nos dois casos que aparecem como isFraud o valor de transferencia\/saque \u00e9 de 181,00\n#para as analises seguintes eu n\u00e3o possi tirar o nome de origem e nome de destino, seguindo a Lei de Benford eu preciso buscar em todas as informa\u00e7\u00f5es que possuam\n#numero uma propor\u00e7\u00e3o que caracterize uma sequencia criada ","e4e2fc21":"# verificando as classes da vari\u00e1vel alvo\ndata.isFraud.unique()","4beebd18":"#Saber a propor\u00e7\u00e3o de transa\u00e7\u00f5es realizadas \nprint(\"Quantidades de transa\u00e7\u00f5es por tipo: \\n\",data.type.value_counts())","52da4970":"print('\\n The types of fraudulent transactions are {}'.format(\n    list(data.loc[data.isFraud == 1].type.drop_duplicates().values)\n))\n\ndfFraudTransfer = data.loc[(data.isFraud == 1) & (data.type == 'TRANSFER')]\ndfFraudCashout = data.loc[(data.isFraud == 1) & (data.type == 'CASH_OUT')]\ndfFraudCashin = data.loc[(data.isFraud == 1) & (data.type == 'CASH_IN')]\ndfFraudDebit = data.loc[(data.isFraud == 1) & (data.type == 'DEBIT')]\n\nprint('The number of fraudulent TRANFERs = {}'.format(len(dfFraudTransfer)))\nprint('The number of fraudulent CASH_OUTs = {}'.format(len(dfFraudCashout)))\nprint('The number of fraudulent CASH_INs = {}'.format(len(dfFraudCashin)))\nprint('The number of fraudulent DEBITs = {}'.format(len(dfFraudDebit)))","9994a909":"print('\\n The types of flagged fraudulent transactions are {}'.format(\n    list(data.loc[data.isFlaggedFraud == 1].type.drop_duplicates().values)\n))\n\ndfFraudTransfer = data.loc[(data.isFlaggedFraud == 1) & (data.type == 'TRANSFER')]\ndfFraudCashout = data.loc[(data.isFlaggedFraud == 1) & (data.type == 'CASH_OUT')]\ndfFraudCashin = data.loc[(data.isFlaggedFraud == 1) & (data.type == 'CASH_IN')]\ndfFraudDebit = data.loc[(data.isFlaggedFraud == 1) & (data.type == 'DEBIT')]\n\nprint('The number of flagged fraudulent TRANFERs = {}'.format(len(dfFraudTransfer)))\nprint('The number of flagged fraudulent CASH_OUTs = {}'.format(len(dfFraudCashout)))\nprint('The number of flagged fraudulent CASH_INs = {}'.format(len(dfFraudCashin)))\nprint('The number of flagged fraudulent DEBITs = {}'.format(len(dfFraudDebit)))\n\n","0e030581":"#Estat\u00edsticas simples das opera\u00e7\u00f5es fraudulentas \n#Duvida - como fazer - quero saber nos casos de fraude qual a estatistica basica das opera\u00e7\u00f5es destadas fraude e suspeitas de fraude \n#Teoricamente tenho que criar uma nova planilha somente com os casos de numero 1 \n#criar uma nova planilha somente com os casos de fraude \n#isolar somente as linhas em que isfraud seja 1","ad62a3dd":"#Duvida: como transformo isso em um arquivo? \ndata[data['isFraud'] == 1]","b1b4d762":"#Excluindo as linhas que tem 0 em isfraud mas posso fazer essa exclus\u00e3o das linhas que contem cash_out e debit que deram zeradas para fraude e possivel fraude\n#desta forma eu mantenho as transa\u00e7\u00f5es de transferencia e cash_out para analise de predi\u00e7\u00e3o.\nT = data.loc[(data['type'] == 'TRANSFER') | (data['type'] == 'CASH_OUT')]\n\nY = T['isFraud']\n# Also we can drop the isFlaggedFraud coulmn as it has no siginificant impact on the dataset as observerd above.\n# Also the names of the accounts can also be dropped as they are also irrelevant in this case.\nT = T.drop(['step', 'isFlaggedFraud'], axis = 1)\n\nT.head(100)\n\n#data = data[data.isFraud != 0]\n","618b67bc":"#incluir o calculo do desvio padr\u00e3o \nprint('A m\u00e9dia do valor da Fraude \u00e9:',round(T['amount'].mean(),2))\nprint('O Menor Valor de Fraude \u00e9:',round(T['amount'].min(),2))\nprint('O Maior Valor de Fraude \u00e9:',round(T['amount'].max(),2))\nprint('A Mediana do Valor nas Fraudes \u00e9:',round(T['amount'].median(),2))\nprint('A Moda do Valor de Fraude \u00e9:',round(T['amount'].mode(),2))\n\nprint()\n\n#print('A Vari\u00e2ncia do valor de Fraude \u00e9:',round(dados['Sal\u00e1rio Mensal'].var(),2))\n\n\n#print('O Desvio Padr\u00e3o do valor de Fraude \u00e9:',round(data['Sal\u00e1rio Mensal'].std(),2))","71652023":"# imprimindo a m\u00e9dia e o desvio-padr\u00e3o do valor dos casos de isFraud para cada classe\nprint('Mean and Standard Dev for Amount by Outcome')\nprint('Mean:')\nprint(T.groupby('isFraud')['amount'].mean())\nprint('Standard Dev:')\nprint(T.groupby('isFraud')['amount'].std())","69c2df86":"data.head = (10)","3abac485":"#Quero procurar padr\u00f5es nos casos de fraude e possiveis fraudes no novo valor de \nmedia = (data['newbalanceDest'].groupby(data['isFraud']).mean())\nmedia.round(2)\n#print (\"A m\u00e9dia do novo valor na conta do destinat\u00e1rio nos casos de possivel fraude \u00e9 de:\") \n#media.mean()","3939944a":"# plotando um Pairplot\nsns.pairplot(T.sample (500), hue = 'isFraud')\n#p=sns.pairplot(T, hue = 'amount')","14e2188d":"# plotando um Heatmap de correla\u00e7\u00e3o\nplt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(T.corr(), annot=True,cmap ='RdYlGn')","f54a1d54":"#USE O SMOTE PARA BALANCEAR","978550f0":"numeric = T.dtypes[T.dtypes != \"object\"].index\nT = T[numeric]\nX = T\n\ny = T['isFraud']\ndel X['isFraud']","687273f0":"# dividindo os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","d4fb3ad7":"# importando as bibliotecas dos modelos classificadores\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\n\n# definindo uma lista com todos os modelos\nclassifiers = [\n    KNeighborsClassifier(3),\n    GaussianNB(),\n    LogisticRegression(),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier()]\n\n# rotina para instanciar, predizer e medir os rasultados de todos os modelos\nfor clf in classifiers:\n    # instanciando o modelo\n    clf.fit(X_train, y_train)\n    # armazenando o nome do modelo na vari\u00e1vel name\n    name = clf.__class__.__name__\n    # imprimindo o nome do modelo\n    print(\"=\"*30)\n    print(name)\n    # imprimindo os resultados do modelo\n    print('****Results****')\n    y_pred = clf.predict(X_test)\n    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n    print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n","4549b5e2":"Quais tipos de transa\u00e7\u00f5es s\u00e3o fraudulentas? \n\nQuantas transa\u00e7\u00f5es fraudulentas existem em cada tipo de transa\u00e7\u00e3o (transferencias - saques - dep\u00f3sito ou d\u00e9bito)? \n\nEsses s\u00e3o os tipos de transa\u00e7\u00f5es que ocorrem no Dataset - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER","01e261e6":"4. Exploro os dados ","87c1ae31":"TEMOS 16 TRANSA\u00c7\u00d5ES DE TRANSFERENCIA COM FLAG DE FRAUDULENTA - TRATA-SE DE TRANSA\u00c7\u00d5ES QUE ENVOLVEM TRASFERENCIA DE MAIS DE 200.000 EM MOEDA LOCAL","040f3e0a":"AP\u00d3S ESTA SEPARA\u00c7\u00c3O DOS DADOS AGORA QUERO SABER DELES - NOS CASOS DE ISFRAUD = 1 QUAL O % DE CASOS EM QUE O NEWBALANCEORIG E NEWBALANCEDEST \u00c9 0 AO MESMO TEMPO","06d71eba":"1. Objetivo do projeto \n\n1 - Classificar com a maior acuracia possivel as transa\u00e7\u00f5es fraudulentas? \n2 - Avaliar qual a melhor m\u00e9trica para identificar fraudes? \n3 - Como cheguei neste conclus\u00e3o? \n4 - Como as pessoas est\u00e3o realizando essas fraudes? ","4aeb87bb":"Pontos Chaves da an\u00e1lise dos dados \n\nMais de 6 milhoes de transa\u00e7\u00f5es para an\u00e1lise \n\n11 colunas no dataset \n\n\n","ecebdfc5":"2. Descri\u00e7\u00e3o do Dataset:\n\nInformation about dataset, paysim1:\n\nURL of Kaggle Dataset page: https:\/\/www.kaggle.com\/ntnu-testimon\/paysim1\n\nThis dataset was a sample of a much larger dataset (not available on Kaggle) generated from a simulation that closely resembles the normal day-to-day transactions including the occurrence of fraudulent transactions.\n\nThe dataset was made for performing research on fraud detection methods.\n\nHere are the variables in the datasets as well as their descriptions:\n\nstep - integer - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n\ntype - string\/categorical - type of transaction: CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n\namount - float - amount of the transaction in local currency.\n\nnameOrig - string - customer who initiated the transaction\n\noldbalanceOrg - float initial balance before the transaction\n\nnewbalanceOrig - float - new balance after the transaction\n\nnameDest - string - customer who is the recipient of the transaction\n\noldbalanceDest - float - initial balance of recipient before the transaction.\n\nnewbalanceDest - float - new balance of recipient after the transaction.\n\nisFraud - boolean\/binary - determines if transaction is fraudulent (encoded as 1) or valid (encoded as 0)\n\nisFlaggedFraud - boolean\/binary - determines if transaction is flagged as fraudulent (encoded as 1) or not flagged at all (encoded as 0). An observation is flagged if the transaction is fraudulent and it involved a transfer of over 200,000 in the local currency.\n","4fc2de63":"3. Leitura dos dados ","23c52fc0":"Identificar na analise de nos casos de isfraud os valores da conta de origem e destino ficam zeradas em maior percentual ","8339374f":"Duvida: pra buscar qual informa\u00e7\u00e3o eu calcularia a m\u00e9dia e desvio padr\u00e3o neste dataset?","7f51181c":"AS UNICAS TRASA\u00c7\u00d5ES QUE EU PRECISO PROCURAR FRAUDES S\u00c3O NAS **TRANSFERENCIAS E CASHOUTS** NELA IREI FOCAR AS ANALISES E COMPARATIVOS\nTEMOS 4097 TRANSA\u00c7\u00d5ES FRAUDULENTAS EM TRANSFERENCIAS E 4116 TRANSA\u00c7\u00d5ES FRAUDULENTAS EM CASHOUTS"}}