{"cell_type":{"343186f5":"code","ee401f01":"code","1fd5100a":"code","6dc88dab":"code","b1251a78":"code","e414a45a":"code","fbdf3155":"code","2e96c667":"code","7b97afe5":"code","647ee406":"code","930aff30":"code","57d31db2":"code","3d0aec66":"code","2725108c":"code","815fca8b":"code","1f3f2182":"code","546a9602":"code","fe4704b9":"code","90bc9423":"markdown","5dc9b8c1":"markdown","962be91e":"markdown","ea6bc775":"markdown","cd7ad9ec":"markdown","6dfeeae3":"markdown","fbcbbc0f":"markdown","b6901201":"markdown","3717b123":"markdown","5ab3d55a":"markdown","e87afb7b":"markdown","42c807d3":"markdown"},"source":{"343186f5":"# Import all the necessary Library \nimport torchvision\nimport torch.utils.data as utils\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader,Dataset\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport torchvision.utils\nimport numpy as np\nimport time\nimport copy\nfrom torch.optim import lr_scheduler\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.autograd import Variable\nimport PIL.ImageOps    \nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport pandas as pd \n","ee401f01":"def imshow(img,text=None,should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(75, 8, text, style='italic',fontweight='bold',\n            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","1fd5100a":"# First, look at everything.\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/sign_data\/sign_data\"]).decode(\"utf8\"))\n\n","6dc88dab":"class Config():\n    training_dir = \"..\/input\/sign_data\/sign_data\/train\"\n    testing_dir = \"..\/input\/sign_data\/sign_data\/test\"\n    train_batch_size = 32\n    train_number_epochs = 20","b1251a78":"training_dir=\"..\/input\/sign_data\/sign_data\/train\"\ntraining_csv=\"..\/input\/sign_data\/sign_data\/train_data.csv\"\ntesting_csv=\"..\/input\/sign_data\/sign_data\/test_data.csv\"\ntesting_dir=\"..\/input\/sign_data\/sign_data\/test\"","e414a45a":"class SiameseNetworkDataset():\n    \n    def __init__(self,training_csv=None,training_dir=None,transform=None):\n        # used to prepare the labels and images path\n        self.training_df=pd.read_csv(training_csv)\n        self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n        self.training_dir = training_dir    \n        self.transform = transform\n\n    def __getitem__(self,index):\n        \n        # getting the image path\n        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n        \n        \n        # Loading the image\n        img0 = Image.open(image1_path)\n        img1 = Image.open(image2_path)\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n        \n        # Apply image transformations\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n        \n        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n    \n    def __len__(self):\n        return len(self.training_df)","fbdf3155":"# Load the the dataset from raw image folders\nsiamese_dataset = SiameseNetworkDataset(training_csv,training_dir,\n                                        transform=transforms.Compose([transforms.Resize((105,105)),\n                                                                      transforms.ToTensor()\n                                                                      ])\n                                       )","2e96c667":"# Viewing the sample of images and to check whether its loading properly\nvis_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        batch_size=8)\ndataiter = iter(vis_dataloader)\n\n\nexample_batch = next(dataiter)\nconcatenated = torch.cat((example_batch[0],example_batch[1]),0)\nimshow(torchvision.utils.make_grid(concatenated))\nprint(example_batch[2].numpy())","7b97afe5":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        \n        # Setting up the Sequential of CNN Layers\n        self.cnn1 = nn.Sequential(\n            \n            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n            nn.ReLU(inplace=True),\n            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n            nn.MaxPool2d(3, stride=2),\n            \n            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n            nn.ReLU(inplace=True),\n            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n\n            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n\n        )\n        \n        # Defining the fully connected layers\n        self.fc1 = nn.Sequential(\n            nn.Linear(30976, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p=0.5),\n            \n            nn.Linear(1024, 128),\n            nn.ReLU(inplace=True),\n            \n            nn.Linear(128,2))\n        \n  \n  \n    def forward_once(self, x):\n        # Forward pass \n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        # forward pass of input 1\n        output1 = self.forward_once(input1)\n        # forward pass of input 2\n        output2 = self.forward_once(input2)\n        return output1, output2\n","647ee406":"class ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n\n        return loss_contrastive","930aff30":"# Load the dataset as pytorch tensors using dataloader\ntrain_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=Config.train_batch_size)","57d31db2":"# Check whether you have GPU is loaded or not\nif torch.cuda.is_available():\n    print('Yes')","3d0aec66":"# Declare Siamese Network\nnet = SiameseNetwork().cuda()\n# Decalre Loss Function\ncriterion = ContrastiveLoss()\n# Declare Optimizer\noptimizer = optim.RMSprop(net.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)","2725108c":"def train():\n    counter = []\n    loss_history = [] \n    iteration_number= 0\n    \n    for epoch in range(0,Config.train_number_epochs):\n        for i, data in enumerate(train_dataloader,0):\n            img0, img1 , label = data\n            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n            optimizer.zero_grad()\n            output1,output2 = net(img0,img1)\n            loss_contrastive = criterion(output1,output2,label)\n            loss_contrastive.backward()\n            optimizer.step()\n            if i %50 == 0 :\n                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n                iteration_number +=10\n                counter.append(iteration_number)\n                loss_history.append(loss_contrastive.item())\n    return net","815fca8b":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# Train the model\nmodel = train()\ntorch.save(model.state_dict(), \"model.pt\")\nprint(\"Model Saved Successfully\")","1f3f2182":"# Load the saved model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SiameseNetwork().to(device)\nmodel.load_state_dict(torch.load(\"model.pt\"))","546a9602":"# Load the test dataset\ntest_dataset = SiameseNetworkDataset(training_csv=testing_csv,training_dir=testing_dir,\n                                        transform=transforms.Compose([transforms.Resize((105,105)),\n                                                                      transforms.ToTensor()\n                                                                      ])\n                                       )\n\ntest_dataloader = DataLoader(test_dataset,num_workers=6,batch_size=1,shuffle=True)","fe4704b9":"# Print the sample outputs to view its dissimilarity\ncounter=0\nlist_0 = torch.FloatTensor([[0]])\nlist_1 = torch.FloatTensor([[1]])\nfor i, data in enumerate(test_dataloader,0): \n  x0, x1 , label = data\n  concatenated = torch.cat((x0,x1),0)\n  output1,output2 = model(x0.to(device),x1.to(device))\n  eucledian_distance = F.pairwise_distance(output1, output2)\n  if label==list_0:\n    label=\"Orginial\"\n  else:\n    label=\"Forged\"\n  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f} Label: {}'.format(eucledian_distance.item(),label))\n  counter=counter+1\n  if counter ==20:\n     break","90bc9423":"## Import and Install all the necessary packages","5dc9b8c1":"### Loss Function","962be91e":"## Siamese Network Definition","ea6bc775":"Let's  go step wise ","cd7ad9ec":"## Steps to create classifier using Siamese Neural Network \n\n\n1.   **Data Preprocessing**\n2.   **Define the Siamese Network**\n3.   **Feature Vector Extraction**\n4.   **Similarity Score Calculation**\n5.   **Defininf Loss Function**\n6.   **Optimizer**\n7.   **Testing using One-Shot Learnig**\n8.   **Making Predictions**\n\n","6dfeeae3":"Thats it guys ! I am limited by time , computational power and knowledge .to get standard accuracy . But anyway this is the working code of Siamese Neural Network and you can try it for your own applications and dataset.\n\nPaper Reference: https:\/\/arxiv.org\/pdf\/1707.02131.pdf\n\nThanks to Gupta Blog : https:\/\/hackernoon.com\/one-shot-learning-with-siamese-networks-in-pytorch-8ddaab10340e","fbcbbc0f":"## Load Dataset :\n\nDatasets can be downloaded from this Link:  https:\/\/drive.google.com\/file\/d\/1q03FLpaolm6Jq5vM0a_AEnjJoqjtxgP8\/view?usp=sharing\n\n**Copy the dataset directly to your drive and load it from there**","b6901201":"# Siamese Neural Network\n\nSiamese neural network is a class of neural network architectures that contain two or more identical sub networks. identical here means they have the same configuration with the same parameters and weights. Parameter updating is mirrored across both sub networks.It is used find the similarity of the inputs by comparing its feature vectors.\n\nFor more details check this blog : https:\/\/innovationincubator.com\/siamese-neural-network-with-code-example\/","3717b123":"### Preprocessing and Loading Dataset\n\nWe preprocessed all the images and loaded them as .npy files which is easy to transfer . You can follow your own preprocessing steps .\n","5ab3d55a":"## Final Touch ","e87afb7b":"### Train the Model","42c807d3":"### Additional Utility Functions "}}