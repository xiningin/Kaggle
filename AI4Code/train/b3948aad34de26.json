{"cell_type":{"7a083a24":"code","5eb7170f":"code","364ca1fc":"code","34d4396d":"code","fd318b1c":"code","6739110c":"code","48397d36":"code","1d7e5bd9":"code","3faed423":"code","d596b954":"code","eb6ae45f":"code","9882c927":"code","2e9830a6":"code","74004a3c":"code","6ea8d600":"code","aafc21a0":"code","c3bf742d":"code","1b120bd6":"code","e839d007":"code","84627c82":"code","f508b8f8":"code","387ca212":"code","3a62443f":"code","e4c9ca3d":"code","523b2d3b":"code","3a229b65":"code","620fa3f0":"code","6f4446b5":"code","68daa6a4":"code","8d420e74":"code","c5566b70":"code","241ac553":"code","32e9a84b":"code","63efbb4e":"code","f591b811":"code","13ce1381":"code","161f425c":"code","a85e68fe":"code","6ba0a29c":"code","102111c2":"code","453e9da7":"code","0f3abde3":"code","c98ea06b":"code","5732baea":"code","83cd532b":"code","429d8d98":"code","2cdf77f0":"code","eeaecf8e":"code","1b5770b7":"code","c383e15f":"code","82d84cdc":"code","dc3abdfa":"code","5de5a83d":"code","d66bea14":"code","e0d28396":"code","25835958":"code","bcaded4d":"code","601aa296":"code","029bc081":"code","fe547d58":"code","0cc50912":"code","b2c648b4":"code","201a1f7a":"code","c1e58d0b":"code","07c8b5f2":"code","b66235e7":"code","dedb811d":"code","3dc19b41":"code","3d61a800":"markdown","08669b9e":"markdown","4636230d":"markdown","533cff56":"markdown","a0ab7e8e":"markdown","fd1856d7":"markdown","2e61d801":"markdown","7fa76f2b":"markdown","e159ccc6":"markdown","14f29873":"markdown","d5dfa34e":"markdown","a970ab0b":"markdown","00b754ae":"markdown","1d76f132":"markdown","1f65fe92":"markdown","db42c4b0":"markdown","ac803061":"markdown","557f4b01":"markdown","dd9f9d3b":"markdown","67664323":"markdown","e7993533":"markdown","22e3110e":"markdown","3a08657e":"markdown","354f28dd":"markdown","e4fdf13b":"markdown"},"source":{"7a083a24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5eb7170f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom plotly.offline import plot, iplot, init_notebook_mode\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom statsmodels.formula.api import ols","364ca1fc":"data = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","34d4396d":"data.head()","fd318b1c":"data.shape","6739110c":"data.info()","48397d36":"data.describe()","1d7e5bd9":"data.isnull().sum()","3faed423":"sns.set_style('darkgrid')\nsns.set_palette('coolwarm')","d596b954":"sns.distplot(data['age'])","eb6ae45f":"for i in data.columns:\n    plt.figure()\n    plt.hist(data[i],density=True)","9882c927":"data_corr = data.corr()","2e9830a6":"data_corr","74004a3c":"plt.figure(figsize=(10,6))\nsns.heatmap(data_corr,annot = True, cmap = 'coolwarm' ,vmin=-1)","6ea8d600":"data_corr[np.absolute(data_corr['DEATH_EVENT']) > 0.1]['DEATH_EVENT']","aafc21a0":"data.age.value_counts(ascending=False)","c3bf742d":"x = data[(data['age'] > 45)\n          & (data['DEATH_EVENT'] == 1)]","1b120bd6":"len(x)","e839d007":"data[data['DEATH_EVENT'] == 1]","84627c82":"male = data[data['sex'] == 1]\nmale_death = male[male['DEATH_EVENT']==1]\nmale_alive = male[male['DEATH_EVENT']==0]\nmale_death.head()","f508b8f8":"male_alive.head()","387ca212":"female = data[data['sex'] == 0]\nfemale_death = female[female['DEATH_EVENT']==1]\nfemale_alive = female[female['DEATH_EVENT']==0]\nfemale_death.head()\n","3a62443f":"female_alive.head()","e4c9ca3d":"labels = ['Male' ,'Female']\n\nvalues = [len(data[data['sex']==1]) , len(data[data['sex']==0])]\n\nfig = go.Figure(data=[go.Pie(labels=labels,values=values , hole =.4)])\n\nfig.update_layout(\n    title_text = \"Gender Distribution\")\n\nfig.show()","523b2d3b":"labels = ['Male - Survived','Male - Not Survived', \"Female -  Survived\", \"Female - Not Survived\"]\nvalues = [len(male[data[\"DEATH_EVENT\"]==0]),len(male[data[\"DEATH_EVENT\"]==1]),\n         len(female[data[\"DEATH_EVENT\"]==0]),len(female[data[\"DEATH_EVENT\"]==1])]\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\nfig.update_layout(\n    title_text=\"Survival Analysis- Gender\")\nfig.show()","3a229b65":"labels = ['No','Yes']\ndiabetes_yes = data[data['diabetes']==1]\ndiabetes_no = data[data['diabetes']==0]\nvalues = [len(diabetes_no), len(diabetes_yes)]\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\nfig.update_layout(\n    title_text=\"Analysis on Diabetes\")\nfig.show()","620fa3f0":"diabetes_yes_survi = diabetes_yes[data[\"DEATH_EVENT\"]==0]\ndiabetes_yes_not_survi = diabetes_yes[data[\"DEATH_EVENT\"]==1]\ndiabetes_no_survi = diabetes_no[data[\"DEATH_EVENT\"]==0]\ndiabetes__no_not_survi = diabetes_no[data[\"DEATH_EVENT\"]==1]","6f4446b5":"labels = ['Diabetes Yes - Survived','Diabetes Yes - Not Survived', 'Diabetes NO - Survived', 'Diabetes NO - Not Survived']\nvalues = [len(diabetes_yes[data[\"DEATH_EVENT\"]==0]),len(diabetes_yes[data[\"DEATH_EVENT\"]==1]),\n         len(diabetes_no[data[\"DEATH_EVENT\"]==0]),len(diabetes_no[data[\"DEATH_EVENT\"]==1])]\ncolors = ['gold', 'mediumturquoise', 'fuchsia', 'lightgreen']\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\nfig.update_layout(\n    title_text=\"Analysis on Survival - Diabetes\")\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.show()","68daa6a4":"anaemia_yes = data[data['anaemia']==1]\nanaemia_no = data[data['anaemia']==0]","8d420e74":"labels = ['Yes' , 'No']\nvalues = [len(anaemia_yes) , len(anaemia_no)]\n\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'Anaemia Analysis',\n    )\nfig.show()","c5566b70":"anaemia_yes_survived = anaemia_yes[anaemia_yes['DEATH_EVENT']==0]\nanaemia_yes_not_survived = anaemia_yes[anaemia_yes['DEATH_EVENT']==1]\n\nanaemia_no_survived = anaemia_no[anaemia_no['DEATH_EVENT']==0]\nanaemia_no_not_survived = anaemia_no[anaemia_no['DEATH_EVENT']==1]","241ac553":"labels = ['Anaemia Yes - Survived','Anaemia Yes - Not Survived', 'Anaemia No - Survived', 'Anaemia NO - Not Survived']\nvalues = [len(anaemia_yes_survived), len(anaemia_yes_not_survived), len(anaemia_no_survived), len(anaemia_no_not_survived)]\n\ncolors = ['cyan','midnightblue','magenta','yellow']\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'Survival Analysis - Anaemia')\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.show()","32e9a84b":"hbp_yes = data[data['high_blood_pressure']==1]\nhbp_not = data[data['high_blood_pressure']==0]","63efbb4e":"labels = ['High Blood Pressure' ,'Not High Blood Pressure']\nvalues = [len(hbp_yes) , len(hbp_not)]\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'High Blood Pressure Analysis')\nfig.show()","f591b811":"high_bp_survived = hbp_yes[hbp_yes['DEATH_EVENT']==0]\nhigh_bp_survived_not = hbp_yes[hbp_yes['DEATH_EVENT']==1]\nnot_high_bp_survived = hbp_not[hbp_not['DEATH_EVENT']==0]\nnot_high_bp_not_survived = hbp_not[hbp_not['DEATH_EVENT']==1]","13ce1381":"labels = ['High BP - Survived' , 'High BP - Not Survived' , 'Not High BP - Survived' , 'Not High BP - Not Survived']\nvalues = [len(high_bp_survived) , len(high_bp_survived_not) ,len(not_high_bp_survived) ,len(not_high_bp_not_survived)]\n\ncolors=['aqua','mistyrose']\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'Survival Analysis - High Blood Pressure')\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.show()","161f425c":"smoking_yes = data[data['smoking']==1] \nsmoking_no  = data[data['smoking']==0]","a85e68fe":"label = ['Yes' ,'No']\nvalues = [len(smoking_yes),len(smoking_no)]\n\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'Smoking Analysis')\nfig.show()","6ba0a29c":"smoking_yes_surv = smoking_yes[smoking_yes['DEATH_EVENT']==0]\nsmoking_yes_not_surv = smoking_yes[smoking_yes['DEATH_EVENT']==1]\nsmoking_no_surv = smoking_no[smoking_no['DEATH_EVENT']==0]\nsmoking_no_not_surv = smoking_no[smoking_no['DEATH_EVENT']==1]","102111c2":"labels = ['Smoking Yes - Survived','Smoking Yes - Not Survived', 'Smoking No - Survived', 'Smoking NO- Not Survived']\nvalues = [len(smoking_yes_surv), len(smoking_yes_not_surv), len(smoking_no_surv), len(smoking_no_not_surv)]\n\nfig = go.Figure(data =[go.Pie(labels=labels, values=values ,hole=.4)])\nfig.update_layout(\n    title_text = 'Survival Analysis - Smoking')\nfig.show()","453e9da7":"X = data.drop('DEATH_EVENT',axis=1)\ny = data['DEATH_EVENT']","0f3abde3":"from sklearn.model_selection import train_test_split\nX_train , X_test ,y_train ,y_test = train_test_split(X,y,test_size=0.2 , random_state=101)","c98ea06b":"X_train.shape , X_test.shape , y_train.shape , y_test.shape","5732baea":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler","83cd532b":"from sklearn.pipeline import Pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),   #Step1 - normalize data\n    ('clf', LogisticRegression())       #Step2 - classifier\n])\npipeline.steps","429d8d98":"from sklearn.model_selection import cross_validate\n\nscores = cross_validate(pipeline, X_train, y_train)\nscores\n","2cdf77f0":"scores['test_score'].mean()","eeaecf8e":"from sklearn.neighbors import KNeighborsClassifier","1b5770b7":"k = range(1,30)\nerror_rate = []\n\nfor i in k:\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    y_pred = knn.predict(X_test)\n    error_rate.append(np.mean(y_pred != y_test))","c383e15f":"plt.figure(figsize=(10,6))\nplt.plot(k,error_rate,color='b',ls='--',marker='o',markerfacecolor='red',markersize=10)\nplt.xticks(k)\nplt.xlabel('K-Value')\nplt.ylabel('Error Rate')\nplt.title('Error Rate vs K')","82d84cdc":"from sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nclfs = []\nclfs.append(LogisticRegression())\nclfs.append(SVC())\nclfs.append(KNeighborsClassifier(n_neighbors=13))\nclfs.append(DecisionTreeClassifier())\nclfs.append(RandomForestClassifier())\nclfs.append(GradientBoostingClassifier())\n\nfor classifier in clfs:\n    pipeline.set_params(clf = classifier)\n    scores = cross_validate(pipeline, X_train, y_train)\n    print('---------------------------------')\n    print(str(classifier))\n    print('-----------------------------------')\n    for k, v in scores.items():\n            print(k,' mean ', v.mean())\n          \n","dc3abdfa":"from sklearn.metrics import accuracy_score , f1_score , roc_auc_score","5de5a83d":"from xgboost import XGBClassifier\nxgb = XGBClassifier(learning_rate = 0.005)\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\n\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,y_pred))","d66bea14":"from lightgbm import LGBMClassifier\nlgb = LGBMClassifier()\nlgb.fit(X_train,y_train)\ny_pred = lgb.predict(X_test)","e0d28396":"print(accuracy_score(y_test,y_pred))\nprint('F1-score: ',f1_score(y_test,y_pred))\nprint('Roc_Auc_Score: ',roc_auc_score(y_test,y_pred))","25835958":"from sklearn.model_selection import GridSearchCV","bcaded4d":"rfc = RandomForestClassifier()","601aa296":"rfc.fit(X_train,y_train)\ny_pred = rfc.predict(X_test)\nprint(accuracy_score(y_test,y_pred))\nprint(f1_score(y_test,y_pred))\nprint(roc_auc_score(y_test,y_pred))","029bc081":"X_train.head()","fe547d58":"features_imp = pd.DataFrame({'feature': X_train.columns, 'importance': rfc.feature_importances_}).sort_values(by='importance', ascending=False)\nfeatures_imp = features_imp.reset_index()\nfeatures_imp","0cc50912":"X = data[['time','serum_creatinine','ejection_fraction','age']]\ny = data['DEATH_EVENT']","b2c648b4":"from sklearn.model_selection import train_test_split\nX_train , X_test ,y_train ,y_test = train_test_split(X,y,test_size=0.2 , random_state=2698)","201a1f7a":"rfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\ny_pred = rfc.predict(X_test)\nprint(accuracy_score(y_test,y_pred))\nprint(f1_score(y_test,y_pred))\nprint(roc_auc_score(y_test,y_pred))","c1e58d0b":"from sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'max_depth': [80, 90, 100, 110],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\n# Instantiate the grid search model\ngrid = GridSearchCV(estimator = rfc, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\ngrid.fit(X,y)","07c8b5f2":"rfc_tuned = RandomForestClassifier(max_depth=100,min_samples_leaf=3,\n                       min_samples_split=12 , random_state=108)","b66235e7":"rfc_tuned.fit(X_train,y_train)\n\ny_pred = rfc.predict(X_test)\n\nprint(\"\"\"\n------------------------\nRandom Forest Classifier\n------------------------\"\"\")\n\nprint('Accuracy score: ',accuracy_score(y_test,y_pred))\nprint('F1 - Score: ',f1_score(y_test,y_pred))\nprint('ROC_AUC Score: ',roc_auc_score(y_test,y_pred))","dedb811d":"gbt = GradientBoostingClassifier()\ngbt.fit(X_train,y_train)\ny_pred = gbt.predict(X_test)\nprint(\"\"\"\n---------------------------\nGradient Boosted Classifier\n---------------------------\"\"\")\nprint('Accuracy score: ',accuracy_score(y_test,y_pred))\nprint('F1 - Score: ',f1_score(y_test,y_pred))\nprint('ROC_AUC Score: ',roc_auc_score(y_test,y_pred))","3dc19b41":"xgb = XGBClassifier()\nxgb.fit(X_train,y_train)\n\ny_pred = xgb.predict(X_test)\nprint(\"\"\"\n------------------\nXgBoost Classifier\n------------------\"\"\")\nprint('Accuracy score: ',accuracy_score(y_test,y_pred))\nprint('F1 - Score: ',f1_score(y_test,y_pred))\nprint('ROC_AUC Score: ',roc_auc_score(y_test,y_pred))","3d61a800":"***Lets have a look on if sex(gender) & a few other attributes of an individual has something to say***","08669b9e":"## High Blood Pressure ","4636230d":"***Pipelines***","533cff56":"# Pipelining Multiple Classifiers","a0ab7e8e":"## Anaemia ","fd1856d7":"## Diabetes","2e61d801":"# It's my first notebook on kaggle and i would like to contribute more ,I am open to any and all criticisms and suggestions . If you ever get around this notebook and have some suggestions for me , please drop it in the comments.\n","7fa76f2b":"grid.best_estimator_","e159ccc6":"# Checking out a few other classifiers , just out of curiosity\u200b","14f29873":"***Lets try to use only the features that has some significance***","d5dfa34e":"# LGBM , cuz why not ? xD","a970ab0b":"## Gender","00b754ae":"**Quite an improvement , lets see if we can stretch it even more**","1d76f132":"### Importing Libraries","1f65fe92":"# Baseline Logistic Regression","db42c4b0":"# If you like this notebook , Please upvote it .","ac803061":"### EDA","557f4b01":"***Finding an \"optimal\" 'k' for K-Means ***","dd9f9d3b":"# XgBoost Classifier has the best F1-Score and ROC_AUC_Score among all other classifiers,Since the data was quite imbalanced accuracy wouldn't really be the right measure to evaluate the models . Moreover with tuning XgBoost idk what astonishing results you'd be able to get ","67664323":" \n***Out of 96 positive death events 89 of these were the cases where the age of the deceased was greater than 45 .***","e7993533":"***Train Test Split***","22e3110e":"# **Random Forest Classifier**","3a08657e":"## Smoking","354f28dd":"## Data Modelling","e4fdf13b":" #  XgBoost "}}