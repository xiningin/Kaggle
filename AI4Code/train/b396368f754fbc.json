{"cell_type":{"3a69613a":"code","1f6fecbe":"markdown","38626aef":"markdown","2b286a40":"markdown","9580e631":"markdown","3a7d5fba":"markdown","3114d22c":"markdown","043cb287":"markdown","5257b500":"markdown","897cad15":"markdown","6b35f69a":"markdown","f1a6ad6a":"markdown"},"source":{"3a69613a":"import random\nfrom pandas import DataFrame\nfrom sklearn.ensemble import BaggingClassifier\n\nnumTurnsPredictors = 5 #number of previous turns to use as predictors\nminTrainSetRows = 10 #only start predicting moves after we have enough data\nnumRandomStartTurns = 200\nmyLastMove = None\nmySecondLastMove = None\nopponentLastMove = None\nnumDummies = 3 #how many dummy vars we need to represent a move\npredictors = DataFrame(columns=[str(x) for x in range(numTurnsPredictors * 2 * numDummies)])\npredictors = predictors.astype(\"int\")\nopponentsMoves = []\nroundHistory = [] #moves made by both players in each round\nclf = BaggingClassifier()\n\ndef randomMove():\n    return random.randint(0,2)\n\n#converts my and opponents moves into dummy variables i.e. [1,2] into [0,1,1,0]\ndef convertToDummies(moves):\n    newMoves = []\n    dummies = [[0,0,1], [0,1,0], [1,0,0]]\n\n    for move in moves:\n        newMoves.extend(dummies[move])\n\n    return newMoves\n\ndef updateRoundHistory(myMove, opponentMove):\n    global roundHistory\n    roundHistory.append(convertToDummies([myMove, opponentMove]))\n\ndef flattenData(data):\n    return sum(data, [])\n\ndef updateFeatures(rounds):\n    global predictors\n    flattenedRounds = flattenData(rounds)\n    predictors.loc[len(predictors)] = flattenedRounds\n\n#returns index of biggest value\ndef getIndexMax(probs):\n    return probs.index(max(probs))\n\n#is the largest probabilty class above the threshold\ndef isStrongPrediction(probs):\n    largestProb = probs[getIndexMax(probs)]\n    \n    #more than 70%\n    if largestProb > 0.7:\n        return True\n    else:\n        return False\n\ndef fitAndPredict(clf, x, y, newX):\n    df = DataFrame.from_records([newX], columns=[str(i) for i in range(numTurnsPredictors * 2 * numDummies)])\n    clf.fit(x, y)\n    probs = clf.predict_proba(df)[0].tolist()\n    print(probs)\n    \n    #only play non-random move if classifier is confident enough\n    if isStrongPrediction(probs):\n        print(\"PLAYING!\")\n        return getIndexMax(probs)\n    else:\n        return randomMove()\n\ndef makeMove(observation, configuration):\n    global myLastMove\n    global mySecondLastMove\n    global opponentLastMove\n    global predictors\n    global opponentsMoves\n    global roundHistory\n\n    if observation.step == 0:\n        myLastMove = randomMove()\n        return myLastMove\n\n    if observation.step == 1:\n        updateRoundHistory(myLastMove, observation.lastOpponentAction)\n        myLastMove = randomMove()\n        return myLastMove\n\n    else:\n        updateRoundHistory(myLastMove, observation.lastOpponentAction)\n        opponentsMoves.append(observation.lastOpponentAction)\n\n        if observation.step > numTurnsPredictors and observation.step > numRandomStartTurns:\n            updateFeatures(roundHistory[-numTurnsPredictors - 1: -1])\n\n        if len(predictors) > minTrainSetRows:\n            print(\"PREDICTING\")\n            clf = BaggingClassifier(n_estimators=max(int(observation.step\/50), 1))\n            predictX = flattenData(roundHistory[-numTurnsPredictors:]) #data to predict next move\n            predictedMove = fitAndPredict(clf, predictors,\n                              opponentsMoves[-len(predictors):], predictX)\n            myLastMove = (predictedMove + 1) % 3\n            return myLastMove\n        else:\n            myLastMove = randomMove()\n            return myLastMove","1f6fecbe":"### That's It!","38626aef":"The agent also plays randomly at the beginning of each match, to help obfuscate its strategy. It also doesn't collect any of the opponent's moves as training data during this period in case the opponent also has a random warm-up period.","2b286a40":"## Agent Code","9580e631":"### Hit-And-Run","3a7d5fba":"# Hit-And-Run With Sliding Trees - Top 3% (Silver) Finish","3114d22c":"### Bagging Classifier With Sliding Number Of Trees","043cb287":"Many of the top RPS agents use relatively complex strategies and meta-strategies to select each move. It is possible, however, to use a single, basic model (i.e. no selection strategies) with a couple of other techniques and achieve a respectable score on the leaderboard, as demonstrated below.","5257b500":"Each turn, the agent attempts to predict the opponent's next move (and then plays the move which beats that move) using a standard bagging classifier trained using the history of the match. The only difference with this classifier is that the number of trees used in the model increases (hence \"sliding\" trees) as each match progresses and therefore more training data becomes available. In this case the number of trees starts at just 1 at the beginning of each match and increases by 1 every 50 turns. This ensures that the size of the subset of training data each tree uses remains fairly constant throughout the entire match.","897cad15":"The bagging classifier produces a probability estimate for each of the opponent's moves and using these, we can see how confident the classifier is that the opponent will play the predicted move. The agent only plays the move which beats the predicted opponent's move when the predicted probability of the opponent making that move is over 70%. The rest of the time the agent simply plays a random move. This means when it is unsure, neither the agent nor its opponent has the edge as a random move will win\/draw\/lose in equal amounts. It also helps to cloak the agent's strategy as it adds a lot of noise to its moves. In this sense it's a rather cowardly agent as it only \"attacks\" (and potentially exposes its strategy) when it thinks the odds are in its favour!","6b35f69a":"### Random Start","f1a6ad6a":"I wasn't going to do a write-up as there are certainly stronger agents out there. However, in the end I thought it may be worth it as many of the best ones are likely to feature relatively advanced strategy selection techniques and large ensemble methods, and I thought it would be good to show that you can create a decent contender with a fairly simple and compact agent without having to write too much code.\n\nThanks for reading!"}}