{"cell_type":{"c72c52c2":"code","5e553cef":"code","930ba6fa":"code","0f4f7eb7":"code","272331a4":"code","c84c3aff":"code","05c2fb4f":"code","aaaae4cd":"code","b9376cd7":"code","a51e6163":"markdown"},"source":{"c72c52c2":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","5e553cef":"model_builder = keras.applications.xception.Xception\npreprocess_input = keras.applications.xception.preprocess_input\ndecode_predictions = keras.applications.xception.decode_predictions\n\n# The local path to our target image\nimg_path = keras.utils.get_file(\n    \"african_elephant.jpg\", \" https:\/\/i.imgur.com\/Bvro0YD.png\"\n)\n\ndisplay(Image(img_path))\n\n# from PIL import Image as PilImage\n# Pretrained model uses 299x299 input size\n# img_size = PilImage.open(img_path).size\nimg_size = (299, 299)","930ba6fa":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(\n    img_array, model, last_conv_layer_name, classifier_layer_names\n):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","0f4f7eb7":"# Prepare image\nimg_array = preprocess_input(get_img_array(img_path, size=img_size))\n\n# Make model\nmodel = model_builder(weights=\"imagenet\")","272331a4":"model.summary()","c84c3aff":"last_conv_layer_name = \"block14_sepconv2_act\"\nclassifier_layer_names = [\"avg_pool\", \"predictions\"]","05c2fb4f":"# Print what the top predicted class is\npreds = model.predict(img_array)\nprint(\"Predicted:\", decode_predictions(preds, top=1)[0])","aaaae4cd":"# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(\n    img_array, model, last_conv_layer_name, classifier_layer_names\n)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","b9376cd7":"# We load the original image\nimg = keras.preprocessing.image.load_img(img_path)\nimg = keras.preprocessing.image.img_to_array(img)\n\n# We rescale heatmap to a range 0-255\nheatmap = np.uint8(255 * heatmap)\n\n# We use jet colormap to colorize heatmap\njet = cm.get_cmap(\"jet\")\n\n# We use RGB values of the colormap\njet_colors = jet(np.arange(256))[:, :3]\njet_heatmap = jet_colors[heatmap]\n\n# We create an image with RGB colorized heatmap\njet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\njet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\njet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n# Superimpose the heatmap on original image\nsuperimposed_img = jet_heatmap * 0.3 + img\nsuperimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n# Save the superimposed image\nsave_path = \"elephant_cam.jpg\"\nsuperimposed_img.save(save_path)\n\n# Display Grad CAM\ndisplay(Image(save_path))","a51e6163":"# Explaining a Neural Network image classification result using **Grad-CAM** (*Gradient-weighted Class Activation Mapping*)\nExample obtained at [Keras](https:\/\/keras.io\/examples\/vision\/grad_cam\/) website. Another good example can be found [here](https:\/\/fairyonice.github.io\/Grad-CAM-with-keras-vis.html)."}}