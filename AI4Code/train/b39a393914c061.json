{"cell_type":{"5d2d55f3":"code","fec185eb":"code","4cb87458":"code","93eefdc2":"code","9d724f37":"code","06618fe3":"code","23228d85":"code","e07482ae":"code","362f6eda":"code","16582eb2":"markdown"},"source":{"5d2d55f3":"!pip install tez\n!pip install timm\n!pip install nnaudio","fec185eb":"import os\nimport albumentations\nimport tez\nimport torch\nimport random\nimport timm\n\nimport pandas as pd\nimport torch.nn as nn\nimport numpy as np\n\nfrom nnAudio.Spectrogram import CQT1992v2\nfrom scipy import signal\nfrom sklearn import metrics\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm","4cb87458":"def seed_everything(seed: int) -> None:\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","93eefdc2":"class G2NetDataset:\n    def __init__(self, ids, targets, base_path, augmentation):\n        self.ids = ids\n        self.targets = targets\n        self.augmentation = augmentation\n        self.base_path = base_path\n        self.qtransform_params = {\n            \"sr\": 2048,\n            \"fmin\": 20,\n            \"fmax\": 1024,\n            \"hop_length\": 32,\n            \"bins_per_octave\": 8,\n        }\n        self.wave_transform = CQT1992v2(**self.qtransform_params)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def apply_qtransform(self, waves, transform):\n        return_data = []\n        for wave in waves:\n            wave = torch.from_numpy(wave).float()\n            return_data.append(transform(wave))\n        return_data = torch.stack(return_data, dim=1)\n        return_data = return_data.squeeze().numpy()\n        return return_data\n\n    def __getitem__(self, idx):\n        sample = self.ids[idx]\n        path = self.base_path.format(sample[0], sample[1], sample[2], sample)\n\n        data = np.load(path)\n        data = self.apply_qtransform(data, self.wave_transform)\n        data = np.transpose(data, (1, 2, 0)).astype(np.float32)\n\n        targets = self.targets[idx]\n\n        if self.augmentation is not None:\n            augmented = self.augmentation(image=data)\n            data = augmented[\"image\"]\n\n        data = np.transpose(data, (2, 0, 1)).astype(np.float32)\n        return {\n            \"x\": torch.tensor(data, dtype=torch.float32),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","9d724f37":"class G2NetModel(tez.Model):\n    def __init__(self, learning_rate):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.model = timm.create_model(\"tf_efficientnet_b7_ns\", in_chans=3)\n        self.model.classifier = nn.Linear(2560, 1)\n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        try:\n            auc = metrics.roc_auc_score(targets, outputs)\n        except ValueError:\n            auc = 0\n        return {\"auc\": auc}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return opt\n\n    def forward(self, x, targets=None):\n        outputs = self.model(x)\n\n        if targets is not None:\n            loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n            metrics = self.monitor_metrics(outputs, targets)\n            return outputs, loss, metrics\n        return outputs, 0, {}","06618fe3":"# change fold here\nclass args:\n    fold = 0\n    learning_rate = 1e-5\n    batch_size = 32\n    epochs = 10\n    accumulation_steps = 1","23228d85":"seed_everything(42)\n\nmeans = (6.90108482e-26, 5.11772679e-26, -1.38312479e-26)\nstds = (7.42028294e-21, 7.41993950e-21, 1.83832928e-21)\n\ntrain_aug = albumentations.Compose(\n    [\n        albumentations.Normalize(\n            mean=means,\n            std=stds,\n            max_pixel_value=1,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Normalize(\n            mean=means,\n            std=stds,\n            max_pixel_value=1,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\ndf = pd.read_csv(\"..\/input\/g2netfolds\/train_folds.csv\")\ndf_train = df[df.kfold != args.fold].reset_index(drop=True)\ndf_valid = df[df.kfold == args.fold].reset_index(drop=True)","e07482ae":"train_dataset = G2NetDataset(\n    ids=df_train[\"id\"].values,\n    targets=df_train[\"target\"].values,\n    augmentation=train_aug,\n    base_path=\"..\/input\/g2net-gravitational-wave-detection\/train\/{}\/{}\/{}\/{}.npy\",\n)\n\nvalid_dataset = G2NetDataset(\n    ids=df_valid[\"id\"].values,\n    targets=df_valid[\"target\"].values,\n    augmentation=valid_aug,\n    base_path=\"..\/input\/g2net-gravitational-wave-detection\/train\/{}\/{}\/{}\/{}.npy\",\n)\n\nmodel = G2NetModel(learning_rate=args.learning_rate)\n\nes = EarlyStopping(\n    monitor=\"valid_auc\",\n    model_path=f\"model_f{args.fold}.bin\",\n    patience=3,\n    mode=\"max\",\n    save_weights_only=True,\n)\n\nmodel.fit(\n    train_dataset,\n    valid_dataset=valid_dataset,\n    train_bs=args.batch_size,\n    valid_bs=4 * args.batch_size,\n    device=\"cuda\",\n    epochs=args.epochs,\n    callbacks=[es],\n    fp16=True,\n    accumulation_steps=args.accumulation_steps,\n)","362f6eda":"# generate test and valid predictions\nmodel.load(f\"model_f{args.fold}.bin\", device=\"cuda\", weights_only=True)\n\nvalid_predictions = model.predict(valid_dataset, batch_size=args.batch_size, n_jobs=-1)\nfinal_valid_predictions = []\nfor preds in tqdm(valid_predictions):\n    final_valid_predictions.extend(preds.ravel().tolist())\n\ndf_valid = df_valid[[\"id\", \"target\"]]\ndf_valid[\"target\"] = final_valid_predictions\ndf_valid.to_csv(f\"valid_predictions_f{args.fold}.csv\", index=False)\n\ndf_test = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Normalize(\n            mean=means,\n            std=stds,\n            max_pixel_value=1,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\ntest_dataset = G2NetDataset(\n    ids=df_test[\"id\"].values,\n    targets=np.zeros(len(df_test)),\n    augmentation=valid_aug,\n    base_path=\"..\/input\/g2net-gravitational-wave-detection\/test\/{}\/{}\/{}\/{}.npy\",\n)\n\ntest_predictions = model.predict(test_dataset, batch_size=args.batch_size, n_jobs=-1)\nfinal_test_predictions = []\nfor preds in tqdm(test_predictions):\n    final_test_predictions.extend(preds.ravel().tolist())\n\ndf_test[\"target\"] = final_test_predictions\ndf_test.to_csv(f\"test_predictions_f{args.fold}.csv\", index=False)","16582eb2":"# "}}