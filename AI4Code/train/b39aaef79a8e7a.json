{"cell_type":{"47e11507":"code","b6116452":"code","a71ac69a":"code","a4ec5ddf":"code","d8604cc8":"code","3d709caa":"code","c33fb429":"code","29ba5861":"code","3f5bd19a":"code","0017d067":"code","27c7cb4e":"code","7ce662ac":"code","15df6259":"markdown","700e146b":"markdown","7624c0db":"markdown"},"source":{"47e11507":"!pip install ..\/input\/keras-applications\/Keras_Applications-1.0.8\/ -f .\/ --no-index\n!pip install ..\/input\/image-classifiers\/image_classifiers-1.0.0\/ -f .\/ --no-index\n!pip install ..\/input\/efficientnet-1-0-0\/efficientnet-1.0.0\/ -f .\/ --no-index\n!pip install ..\/input\/segmentation-models\/segmentation_models-1.0.1\/ -f .\/ --no-index","b6116452":"%env SM_FRAMEWORK=tf.keras","a71ac69a":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport gc\nimport cv2\nimport sys\nimport json\nimport time\nimport pickle\nimport shutil\nimport numba\nimport numpy as np\nimport pandas as pd \nimport tifffile as tiff\nimport rasterio\nfrom rasterio.windows import Window\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import *\nimport segmentation_models as sm\nfrom segmentation_models import Unet, FPN, Linknet\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom tqdm import tqdm\nprint('tensorflow version:', tf.__version__)\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\ngpu_devices = tf.config.experimental.list_physical_devices('GPU')\nif gpu_devices:\n    for gpu_device in gpu_devices:\n        print('device available:', gpu_device)\npd.set_option('display.max_columns', None)","a4ec5ddf":"TEST = True\nKAGGLE = True\nMDLS_FOLDS = {'v39': [0, 2, 3, 4]}\nif KAGGLE:\n    DATA_PATH = '..\/input\/hubmap-kidney-segmentation'\n    MDLS_PATHS = {ver: f'..\/input\/kidney-models-{ver}' \n                  for ver, _ in MDLS_FOLDS.items()}\nelse:\n    DATA_PATH = '.\/data2'\n    MDLS_PATHS = {ver: f'.\/models_{ver}' \n                  for ver, _ in MDLS_FOLDS.items()}\nTHRESHOLD = .35\nVOTERS = 1\nTTAS = [0, 1]\nEXPAND = 4\nMIN_OVERLAP = 1 \/ 16\nIDNT = rasterio.Affine(1, 0, 0, 0, 1, 0)\nSTRATEGY = tf.distribute.get_strategy() \nSUB_PATH = f'{DATA_PATH}\/test' if TEST else f'{DATA_PATH}\/train'\n\nstart_time = time.time()","d8604cc8":"params_dict = {}\nfor ver, _ in MDLS_FOLDS.items():\n    with open(f'{MDLS_PATHS[ver]}\/params.json') as file:\n        params_dict[ver] = json.load(file)\nfor ver, params in params_dict.items():\n    print('version:', ver, '| loaded params:', params, '\\n')","3d709caa":"def enc2mask(encs, shape):\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for m, enc in enumerate(encs):\n        if isinstance(enc, np.float) and np.isnan(enc): continue\n        s = enc.split()\n        for i in range(len(s) \/\/ 2):\n            start = int(s[2 * i]) - 1\n            length = int(s[2 * i + 1])\n            img[start : start + length] = 1 + m\n    return img.reshape(shape).T\n\ndef rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","c33fb429":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2 * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred, smooth=1):\n    return (1 - dice_coef(y_true, y_pred, smooth))\n\ndef bce_dice_loss(y_true, y_pred):\n    return params['bce_weight'] * binary_crossentropy(y_true, y_pred) + \\\n        (1 - params['bce_weight']) * dice_loss(y_true, y_pred)\n\ndef get_model(backbone, input_shape, path, \n              loss_type='bce_dice', umodel='unet', \n              classes=1, lr=.001):\n    if backbone == 'efficientnetb0':\n        weights = f'{path}\/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n    elif backbone == 'efficientnetb1':\n        weights = f'{path}\/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n    elif backbone == 'efficientnetb2':\n        weights = f'{path}\/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n    elif backbone == 'efficientnetb3':\n        weights = f'{path}\/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n    elif backbone == 'resnet34':\n        weights = f'{path}\/resnet34_imagenet_1000_no_top.h5'\n    else:\n        raise AttributeError('mode parameter error')\n    with STRATEGY.scope():\n        if loss_type == 'bce_dice': \n            loss = bce_dice_loss\n        elif loss_type == 'bce_jaccard_loss':\n            loss = bce_jaccard_loss\n        else:\n            raise AttributeError('loss mode parameter error')\n        if umodel == 'unet':\n            model = Unet(backbone_name=backbone, encoder_weights=weights,\n                         input_shape=input_shape,\n                         classes=classes, activation='sigmoid')\n        elif umodel == 'fpn':\n            model = FPN(backbone_name=backbone, encoder_weights=weights,\n                        input_shape=input_shape,\n                        classes=classes, activation='sigmoid')\n        elif umodel == 'link':\n            model = Linknet(backbone_name=backbone, encoder_weights=weights,\n                            input_shape=input_shape,\n                            classes=classes, activation='sigmoid')\n        else:\n            raise AttributeError('umodel mode parameter error')\n        model.compile(\n            optimizer=tfa.optimizers.Lookahead(\n                tf.keras.optimizers.Adam(learning_rate=lr)\n            ),\n            loss=loss, \n            metrics=[dice_coef]\n        )\n    return model","29ba5861":"def make_grid(shape, window=256, min_overlap=32):\n    x, y = shape\n    nx = x \/\/ (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    ny = y \/\/ (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    slices = np.zeros((nx, ny, 4), dtype=np.int64) \n    for i in range(nx):\n        for j in range(ny):\n            slices[i, j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx * ny, 4)\n\ndef flip(img, axis=0):\n    if axis == 1:\n        return img[::-1, :, ]\n    elif axis == 2:\n        return img[:, ::-1, ]\n    elif axis == 3:\n        return img[::-1, ::-1, ]\n    else:\n        return img","3f5bd19a":"img_files = [x for x in os.listdir(SUB_PATH) if '.tiff' in x]\nprint('images idxs:', img_files)","0017d067":"subm = {}\nfor i_img, img_file in enumerate(img_files):\n    print('-' * 20, img_file, '-' * 20)\n    img_data = rasterio.open(os.path.join(SUB_PATH, img_file), transform=IDNT)\n    print('img shape:', img_data.shape)\n    if img_data.count != 3:\n        print('img file with subdatasets as channels')\n        layers = [rasterio.open(subd) for subd in img_data.subdatasets]\n    img_preds = np.zeros(img_data.shape, dtype=np.uint8)\n    tile_size = int(params['img_size'] * EXPAND)\n    tile_resized = int(tile_size * params['resize'])\n    slices = make_grid(\n        img_data.shape, \n        window=tile_resized, \n        min_overlap=int(tile_resized * MIN_OVERLAP)\n    )\n    models = []\n    for ver, folds in MDLS_FOLDS.items():\n        for n_fold in folds:\n            checkpoint_path = f'{MDLS_PATHS[ver]}\/model_{n_fold}.hdf5'\n            model = get_model(\n                params_dict[ver]['backbone'], \n                input_shape=(tile_size, tile_size, 3),\n                path=MDLS_PATHS[ver],\n                loss_type=params_dict[ver]['loss'],\n                umodel=params_dict[ver]['umodel']\n            )\n            model.load_weights(checkpoint_path)\n            models.append(model)\n            print('ver:', ver, '| model loaded:', checkpoint_path)\n    for (x1, x2, y1, y2) in tqdm(slices, desc=f'{img_file}'):\n        if img_data.count == 3: # normal\n            img = img_data.read(\n                [1, 2, 3], \n                window=Window.from_slices((x1, x2), (y1, y2))\n            )\n            img = np.moveaxis(img, 0, -1)\n        else: # with subdatasets\/layers\n            img = np.zeros((tile_resized, tile_resized, 3), dtype=np.uint8)\n            for fl in range(3):\n                img[:, :, fl] = layers[fl].read(\n                    window=Window.from_slices((x1, x2), (y1, y2))\n                )\n        img = cv2.resize(img, (tile_size, tile_size))\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        pred = np.zeros((tile_size, tile_size), dtype=np.float32)\n        for tta_mode in TTAS:\n            img_aug = flip(img, axis=tta_mode)\n            img_aug = np.expand_dims(img_aug, 0)\n            img_aug = img_aug.astype(np.float32) \/ 255\n            for model in models:\n                pred_aug = np.squeeze(model.predict(img_aug))\n                pred += flip(pred_aug, axis=tta_mode)\n        pred \/= (len(models) * len(TTAS))\n        pred = cv2.resize(pred, (tile_resized, tile_resized))\n        img_preds[x1:x2, y1:y2] = img_preds[x1:x2, y1:y2] + \\\n            (pred > THRESHOLD).astype(np.uint8)\n    del model, models, img, pred, img_aug, pred_aug; gc.collect()\n    print('img max:', np.max(img_preds), '| voters:', VOTERS)\n    img_preds = (img_preds >= VOTERS).astype(np.uint8)\n    rle_pred = rle_encode_less_memory(img_preds)\n    subm[i_img] = {'id':img_file.replace('.tiff', ''), 'predicted': rle_pred}\n    del img_preds, img_data, rle_pred; gc.collect()\n\nelapsed_time = time.time() - start_time\nprint(f'time elapsed: {elapsed_time \/\/ 60:.0f} min {elapsed_time % 60:.0f} sec')","27c7cb4e":"df_sub = pd.DataFrame(subm).T\ndf_sub","7ce662ac":"df_sub.to_csv('submission.csv', index=False)","15df6259":"References:\n\n- [256x256 images](https:\/\/www.kaggle.com\/iafoss\/256x256-images)\n\n- [Making a successful submission](https:\/\/www.kaggle.com\/igor14497\/making-a-successful-submission])\n\n- [HuBMAP: TF with TPU EfficientUNet 512x512[subm]](https:\/\/www.kaggle.com\/wrrosa\/hubmap-tf-with-tpu-efficientunet-512x512-subm)\n\n- [Global Mask Shift](https:\/\/www.kaggle.com\/tivfrvqhs5\/global-mask-shift)\n\nMany thanks to that notebooks' authors.","700e146b":"This notebook makes an inference for Unet model with EfficientNet backbone based on [this library](https:\/\/github.com\/qubvel\/segmentation_models). The code for training models is [here](https:\/\/github.com\/vgarshin\/kaggle_kidney\/blob\/master\/kidney_train.ipynb).","7624c0db":"# Hacking the Kidney: Inference of Unet model"}}