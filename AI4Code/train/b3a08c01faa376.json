{"cell_type":{"efb90a2a":"code","5cd61537":"code","9a2c3f2a":"code","fddf1daa":"code","e3c5e998":"code","62fcfae5":"code","a7dd31f9":"code","e07393db":"code","1369ecc7":"code","c56bee78":"code","ea558181":"code","6df67cc2":"code","674ba321":"code","293867ba":"code","e786a9da":"code","c6fc9558":"code","bd3fe801":"code","816fd55a":"code","4fd57707":"code","044405b7":"code","8838d690":"markdown","8f727ff4":"markdown","e00dfad8":"markdown"},"source":{"efb90a2a":"from tensorflow import keras\nfrom keras.utils.vis_utils import plot_model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom glob import glob\nfrom keras.layers import Flatten,Dense\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img","5cd61537":"IMAGE_SIZE = [224,224]","9a2c3f2a":"# Create InceptionV3 Layer\ninception = InceptionV3(include_top=False,weights='imagenet',input_shape=IMAGE_SIZE + [3])","fddf1daa":"for layer in inception.layers:\n  layer.trainable = False","e3c5e998":"# we will use the glob to see how many outputs \/ labels there are\nfolders = glob('..\/input\/tomatoleaf\/tomato\/train\/*')","62fcfae5":"folders","a7dd31f9":"# Add Flatten and Dense in last layers\nx = Flatten()(inception.output)\nprediction = Dense(len(folders),activation='softmax')(x)","e07393db":"# create a model with additional flatten and dense layers and then we plot it\nmodel = Model(inputs=inception.input,outputs = prediction)\nplot_model(model)","1369ecc7":"# Check Summary Model\nmodel.summary()","c56bee78":"# Compile the model that we have created with adam and the loss is categorical_crossentropy because the classification is more than 2 classes\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","ea558181":"# Image Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2)\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255)","6df67cc2":"# Apply Image Augmentation to Train and Test Images\ntraining_set = train_datagen.flow_from_directory('..\/input\/tomatoleaf\/tomato\/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\n\ntest_set = train_datagen.flow_from_directory('..\/input\/tomatoleaf\/tomato\/val',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","674ba321":"import tensorflow as tf\n# CallBack EarlyStop\nearly = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)","293867ba":"# Train data\nhistory = model.fit_generator(\n    training_set,\n    validation_data=test_set,\n    epochs=30,\n    steps_per_epoch=len(training_set),\n    validation_steps=len(test_set),\n    callbacks=[early]\n)","e786a9da":"# Model Evaluation\nmodel.evaluate(test_set)","c6fc9558":"import matplotlib.pyplot as plt\nimport seaborn as sns","bd3fe801":"# Visualize the Accuracy and Loss to check whether our model is overfitting or not\nsns.set()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n# Accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n# Loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","816fd55a":"# Visualize train data val accuracy and val loss\nplt.plot(history.history['val_loss'], label = 'training loss')\nplt.plot(history.history['val_accuracy'], label = 'training accuracy')\nplt.legend()","4fd57707":"# Visualize test data accuracy and loss\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['accuracy'], label = 'training accuracy')\nplt.legend()","044405b7":"# Save Weight model\nmodel.save_weights(\"modelInceptionV3.h5\")","8838d690":"# Using Pre-trained Model InceptionV3","8f727ff4":"# Data Prep","e00dfad8":"# Import Library"}}