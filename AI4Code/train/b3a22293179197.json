{"cell_type":{"60d0639b":"code","62247048":"code","fab3fd2e":"code","a62786b2":"code","983145f0":"code","fba64a70":"code","f08671dc":"code","e8901ed2":"code","291c82d0":"code","4aae0aa5":"code","af9a46ef":"code","5cc75118":"code","e60d284e":"code","2fdde6b4":"code","17eb11de":"code","acf02ea4":"code","e6c3a7ad":"code","43214ed2":"code","6ae0cc27":"code","50a923ef":"code","824a5e17":"code","ecf68293":"code","cde40368":"code","662c20c0":"markdown","c39ddb0d":"markdown","6af8f6c9":"markdown","c0a77a3c":"markdown","a3e7dc1c":"markdown","a60eebe0":"markdown","675df026":"markdown","827e2d4a":"markdown","d86cf2f1":"markdown","fff4de66":"markdown","f014a062":"markdown"},"source":{"60d0639b":"import os\nimport sys\nfrom collections import Counter\nimport json\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical","62247048":"# What is inside the labels.csv\nDATA_PATH = \"..\/input\/flower-classification-dataset\/\"\ndf = pd.read_csv(os.path.join(DATA_PATH, 'labels.csv'))\ndf.tail()","fab3fd2e":"X = []\ny = []\nfor image, label in tqdm(zip(df.image_id.values, df.category.values), total=len(df)):\n    try:\n        xt = np.array(Image.open(os.path.join(DATA_PATH, f\"files\/{image}.jpg\")).resize((128,128)))\n        yt = label\n        X.append(xt)\n        y.append(yt)\n    except:\n        print(os.path.join(DATA_PATH, f\"files\/{image}.jpg\"))\n    \nX = np.array(X)\ny = np.array(y)\n\nprint(X.shape, y.shape)","a62786b2":"files = os.listdir(os.path.join(DATA_PATH, 'files'))\nprint(f\"The total number of files in the dataset are {len(files)}\")","983145f0":"# Lets see that the number of images in the dataset equals to the provided labels\nprint(f\"The total number of points in the labels.csv are {len(df)}\")","fba64a70":"train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)","f08671dc":"train_y = to_categorical(train_y)\ntest_y = to_categorical(test_y)\n\nprint(train_y.shape, test_y.shape)","e8901ed2":"num_classes = 103","291c82d0":"print(train_X.shape, train_y.shape)","4aae0aa5":"# plot first few images\nplt.figure(figsize=(12,12))\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # plot raw pixel data\n    plt.imshow(train_X[i])\n# show the figure\nplt.show()","af9a46ef":"plt.figure(figsize=(18,6))\ndf[\"category\"].value_counts().plot(kind='bar')","5cc75118":"!rm -rf preview\n!mkdir preview","e60d284e":"datagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nimg = load_img(os.path.join(DATA_PATH, f\"files\/0.jpg\"))  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview\/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,\n                          save_to_dir=\"preview\", save_prefix='f', save_format='jpg'):\n    i += 1\n    if i > 20:\n        break  # otherwise the generator would loop indefinitely","2fdde6b4":"!ls preview","17eb11de":"x=[]\nfor image in os.listdir('preview'):\n    xt = np.array(Image.open(os.path.join(\"preview\", image)).resize((128,128)))\n    x.append(xt)    \n    \n# plot first few images\nplt.figure(figsize=(12,12))\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # plot raw pixel data\n    plt.imshow(x[i])\n# show the figure\nplt.show()","acf02ea4":"model = Sequential()\nmodel.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(128, 128, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","e6c3a7ad":"model.summary()","43214ed2":"batch_size = 16\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","6ae0cc27":"train_generator = train_datagen.flow(\n        train_X,\n        train_y,\n        batch_size=batch_size,\n        shuffle=True\n        )  # since we use binary_crossentropy loss, we need binary labels\n\n# this is a similar generator, for validation data\nvalidation_generator = test_datagen.flow(\n        test_X,\n        test_y,\n        shuffle=False,\n        )","50a923ef":"history = model.fit_generator(\n        train_generator,\n        epochs=50,\n        validation_data=validation_generator)","824a5e17":"print(history.history.keys())","ecf68293":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","cde40368":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","662c20c0":"## Prepare Data","c39ddb0d":"## Train Model","6af8f6c9":"### Spliting the dataset","c0a77a3c":"## Understanding Image transformations","a3e7dc1c":"### Exploring images in the dataset","a60eebe0":"### Let's explore the class distributions for now","675df026":"### Loading the dataset","827e2d4a":"## Plot Training History","d86cf2f1":"## Build Model","fff4de66":"## Data Augmentation","f014a062":"### Exploring the dataset images"}}