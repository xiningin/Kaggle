{"cell_type":{"c4de2add":"code","4b989277":"code","688ad08a":"code","51ac0331":"code","83d2e2da":"code","618e1d47":"code","6f557baa":"code","c53b86e9":"code","daeafb04":"code","ebe05a13":"code","c17431c3":"code","e3ca1473":"code","04545717":"code","7f2d2ddb":"code","71c889e1":"code","cc7d24a9":"code","f6240ddd":"code","7bf69eb2":"code","07ad4b9e":"code","0883c2e7":"markdown","d1fd79b1":"markdown","02ba26f6":"markdown","89b75eb4":"markdown","d8ea71ae":"markdown","b5e57df5":"markdown","966ceb0f":"markdown","3da99fa3":"markdown","def5f9c7":"markdown","501aaf5a":"markdown","cea3d68e":"markdown","11e3a6da":"markdown","684678ea":"markdown","fc9302e0":"markdown","30878e13":"markdown","3c81d4c4":"markdown","07a06f0b":"markdown","9c429c95":"markdown","805dad57":"markdown","5217839b":"markdown","bf8cbf8f":"markdown","f0b1a736":"markdown","3379a169":"markdown","e3d08ed4":"markdown","478422c5":"markdown","d80ff69b":"markdown","1cc83e7e":"markdown","d4fe8cd9":"markdown","2ef0e060":"markdown","476053f3":"markdown","ab512a15":"markdown","747607b6":"markdown","1f486d45":"markdown","04febb55":"markdown","25f68fc8":"markdown","d0663c25":"markdown","481b826f":"markdown","772da042":"markdown","9b28a779":"markdown","96cfcfe7":"markdown","95ea3840":"markdown","9211bb45":"markdown"},"source":{"c4de2add":"#Imports\n\n#Import linear algebra and data manipulation\nimport numpy as np\nimport pandas as pd\n\n#Import plotting packages\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#Import machine learning\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost\n\nfrom sklearn.model_selection import train_test_split #split\nfrom sklearn.metrics import r2_score, mean_squared_error #metrics","4b989277":"#read the dataset\nlistings_df = pd.read_csv('..\/input\/listings.csv')\n\n#find number of listings and number of hosts\nlistings_number = listings_df['id'].count()\nhosts_number = len(listings_df['host_id'].unique())\n\nprint('listings.csv dataset contains information on %d listings provided by %d hosts.' % (listings_number, \n                                                                                          hosts_number))","688ad08a":"#find percentage of missing values for each column\nlistings_missing_df = listings_df.isnull().mean()*100\n\n#filter out only columns, which have missing values\nlistings_columns_with_nan = listings_missing_df[listings_missing_df > 0]\n\n#plot the results\nlistings_columns_with_nan.plot.bar(title='Missing values per column, %')","51ac0331":"#read the dataset\ncalendar_df = pd.read_csv('..\/input\/calendar.csv')\n\n#find number of rows in dataset\nrows_num = calendar_df.shape[0]\n\n#find first and last date of the calendar\nmin_date = calendar_df['date'].min()\nmax_date = calendar_df['date'].max()\n\nprint('calendar.csv dataset contains %d rows.' % (rows_num))\nprint('The first date of observation is %s and the last date is %s.' % (min_date, max_date))","83d2e2da":"#get percentage of missing values for each column in dataset\ncalendar_missing_df = pd.DataFrame([calendar_df.isnull().mean()*100])\n\n#plot the results\ncalendar_missing_df.plot.bar(title='Missing values per column, %')","618e1d47":"#Helper functions for dataset cleaning\n\ndef get_month_from_date(row):\n    ''' Get month from date represented as a string '''\n    return int(row['date'].split('-')[1])\n\ndef get_year_from_date(row):\n    ''' Get year from date represented as a string '''\n    return int(row['date'].split('-')[0])\n\ndef get_host_since_year(row):\n    ''' Get year from a date represented as a string '''\n    try:\n        host_since = int(row['host_since'].split('-')[0])\n    except:\n        host_since = np.nan\n    return host_since\n\ndef get_val_from_list(row, column_name, value):\n    ''' Fill in dummy column for values '''\n    val = 0.0\n    try:\n        vals = row[column_name].replace('[', '').replace(\"'\", '').replace(\"]\", '').replace('\"', '').replace('{', '').replace('}', '').split(',')\n        if value in vals:\n            val = 1.0\n    except:\n        val = 0.0\n    return val\n\ndef split_list_into_columns(df, column_name, max_dummies_num = 10):\n    ''' Split values in columns, which contain lists (for example, amenities) '''\n    \n    # get dictionary of unique values in lists across dataset rows\n    values_dict = {}\n\n    for unique_value in df[column_name].unique(): \n        for value in unique_value.replace('[', '').replace(\"'\", '').replace(\"]\", '').replace('\"', '').replace('{', '').replace('}', '').split(','):\n            if value in values_dict:\n                values_dict[value] = values_dict[value] + 1\n            else:\n                values_dict[value] = 0\n                \n    values_sorted = sorted(values_dict.items(), key=lambda kv: kv[1], reverse = True)\n      \n    # split into columns\n    for value in values_sorted[: max_dummies_num]:\n        df[column_name + '_' + value[0]] = df.apply(lambda row: get_val_from_list(row, column_name, value[0]),axis=1)\n        \n    return\n\ndef get_extra_people_fee(row):\n    ''' Return 1 when the is fee for exatra people '''\n    if row['extra_people'] == '$0.00':\n        return 0.0\n    else:\n        return 1.0\n\n#Main dataset cleaning function\ndef clean_dataset(listings_df, calendar_df):\n    '''\n    INPUT\n    listings_df - pandas dataframe containing listings data \n    calendar_df - pandas dataframe containing calendar data\n    \n    OUTPUT\n    df - cleaned dataset, which contains merged tables:\n    1. irrelevant columns are dropped;\n    2. string containing dates are converted into numbers;\n    3. columns, containing lists, are split into several columns (for example, amenities)\n    4. missing values are imputed with mean or mode.\n    '''\n    #merge datasets\n    listings_df = listings_df.rename(index=str, columns={\"id\": \"listing_id\"})\n    df = pd.merge(calendar_df, listings_df, on = 'listing_id')\n    \n    #drop the irrelevant columns\n    columns_to_drop = ['available', 'host_id','host_location','host_acceptance_rate','host_neighbourhood',\n                   'host_total_listings_count', 'weekly_price', 'monthly_price',\n                   'security_deposit', 'cleaning_fee', 'calendar_updated',\n                   'listing_url','last_scraped' ,'scrape_id', 'name', 'summary', 'space', 'description',\n                   'experiences_offered', 'street', 'neighbourhood', 'neighbourhood_cleansed', 'zipcode',\n                   'neighborhood_overview', 'notes', 'transit', 'thumbnail_url', 'medium_url', 'picture_url',\n                   'xl_picture_url', 'host_url', 'host_name', 'host_about', 'host_thumbnail_url', 'host_picture_url',\n                   'city', 'state', 'market', 'smart_location', 'country_code', 'country', 'latitude', 'longitude',\n                   'is_location_exact', 'square_feet', 'has_availability', 'availability_30',\n                   'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped',\n                  'first_review', 'last_review', 'requires_license', 'license', 'jurisdiction_names', 'price_y',\n                  'reviews_per_month']\n    df = df.drop(columns = columns_to_drop)\n    \n    #convert date from the calendar into month and drop the date colum\n    df['month'] = df.apply(lambda row: get_month_from_date(row),axis=1)\n    df['year'] = df.apply(lambda row: get_year_from_date(row),axis=1)\n    df = df.drop(columns = ['date'])\n    \n    #remove rows where price_x == nan, because price will be used as response column\n    df = df.dropna(subset=['price_x'])\n    \n    #convert price to number and drop the price_x column\n    df['price'] = df['price_x'].astype(str)\n    df['price'] = df['price'].str.replace(\"[$, ]\", \"\").astype(\"float\")\n    df = df.drop(columns = ['price_x'])\n    \n    #convert host_since date into number and fill in missing values, drop the original column\n    df['host_since_year'] = df.apply(lambda row: get_host_since_year(row),axis=1)\n    df['host_since_year'].fillna(df['host_since_year'].mean(), inplace = True)\n    df = df.drop(columns = ['host_since'])\n    \n    #convert host_response_rate into number and fill in missing values, drop the original column\n    df['host_response_rate_num'] = df['host_response_rate'].astype(str)\n    df['host_response_rate_num'] = df['host_response_rate_num'].str.replace(\"%\", \"\").astype(\"float\")\n    df['host_response_rate_num'].fillna(df['host_response_rate_num'].mean(), inplace = True)\n    \n    df['host_response_rate_buckets'] = pd.qcut(df['host_response_rate_num'], 5, labels=False, duplicates = 'drop')\n    \n    df = df.drop(columns = ['host_response_rate', 'host_response_rate_num'])\n    \n    #fill missing values with mean value for host_listings_count\n    df['host_listings_count'].fillna(df['host_listings_count'].mean(), inplace = True)\n    \n    #split host_verifications into dummy columns and drop the original column\n    split_list_into_columns(df, 'host_verifications')\n    df = df.drop(columns = ['host_verifications'])\n    \n    #fill in missing values for bathrooms, bedrooms and beds with mode\n    df['bathrooms'] = df['bathrooms'].fillna(df['bathrooms'].mode()[0])\n    df['bedrooms'] = df['bedrooms'].fillna(df['bedrooms'].mode()[0])\n    df['beds'] = df['beds'].fillna(df['beds'].mode()[0])\n    \n    #split amenities into dummy columns and drop the original column\n    split_list_into_columns(df, 'amenities')\n    df = df.drop(columns = ['amenities'])\n    \n    #turn extra people fee into binary column (1 - if fee for extra people is charged, 0 - otherwise)\n    df['extra_people_fee'] = df.apply(lambda row: get_extra_people_fee(row),axis=1)\n    df = df.drop(columns = ['extra_people'])\n    \n    #fill missing values for review scores columns\n    review_scores_columns = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n                         'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n                        'review_scores_value']\n    for column in review_scores_columns:\n        df[column].fillna(df[column].mean(), inplace = True)\n    \n    return df","6f557baa":"# apply functions above to clean dataset\ndf = clean_dataset(listings_df, calendar_df)","c53b86e9":"#find minimum, maximum and average price for listing\nmin_price = df['price'].min()\nmax_price = df['price'].max()\nmean_price = df['price'].mean()\n\nprint('Minimum price per listing is %d$.' % (min_price))\nprint('Maximum price per listing is %d$' % (max_price))\nprint('Average price per listing is %d$.' % (mean_price))","daeafb04":"#get the average price for each listing\nmean_price_for_listing = df.groupby('listing_id').mean()['price']\n\n#plot\nplt.figure(figsize=(15,5))\nplt.hist(mean_price_for_listing, bins=20)\nplt.xticks(np.arange(0, 1700, step=100))\nplt.ylabel('Number of listings')\nplt.xlabel('Price, $')\nplt.title('Number of listings depending on price')\n\n\nplt.savefig('Price distrubution.png')\n\nplt.show()","ebe05a13":"#find number of total number of listings for each month in 2016\nnumber_of_listings_by_month = pd.Series([12])\nfor i in range(1, 13):\n    number_of_listings_by_month[i] = len(df[(df['month'] == i) & (df['year'] == 2016)]['listing_id'].unique())\n    \nnumber_of_listings_by_month = number_of_listings_by_month.drop(0)\n\n#plot\nplt.figure(figsize=(10,5))\nplt.plot(number_of_listings_by_month)\nplt.xticks(np.arange(1, 13, step=1))\nplt.ylabel('Number of listings')\nplt.xlabel('Month')\nplt.title('Number of listings per month, 2016')\n\nplt.savefig('number of available listings.png')\n\nplt.show()","c17431c3":"#find average price by month\naverage_price_by_month = df.groupby(['month'])['price'].mean()\n\n#plot\nplt.figure(figsize=(10,5))\nplt.plot(average_price_by_month)\nplt.ylabel('Average price, $')\nplt.xlabel('Month')\nplt.title('Average price')\n\nplt.savefig('average price for month')\n\nplt.show()","e3ca1473":"#get list of neighbourhoods\nneighbourhoods = df['neighbourhood_group_cleansed'].unique()\n\n#get prices by month and neighbourhood\nprice_by_month_neighbourhood = df.groupby(['month','neighbourhood_group_cleansed']).mean().reset_index()\n\n#plot prices for each neighbourhood\nfig = plt.figure(figsize=(20,10))\nax = plt.subplot(111)\n\nfor neighbourhood in neighbourhoods:\n    ax.plot(price_by_month_neighbourhood[price_by_month_neighbourhood['neighbourhood_group_cleansed'] == neighbourhood]['month'],\n             price_by_month_neighbourhood[price_by_month_neighbourhood['neighbourhood_group_cleansed'] == neighbourhood]['price'],\n             label = neighbourhood)\n    \nbox = ax.get_position()\nax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nplt.ylabel('Average price, $')\nplt.xlabel('Month')\nplt.title('Average price for neighbourhood, $')\n\nplt.savefig('average price for neighbourhood')\n\nplt.show()","04545717":"#Numerical columns to find out correlation\ncols = ['accommodates','bathrooms','bedrooms','beds','host_since_year',\n        'host_listings_count', 'extra_people_fee',\n        'review_scores_rating', 'price']\n\n#Find out correlation between columns and plot\ncorrs = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1)\nsns.set(rc={'figure.figsize':(7,7)})\nhm=sns.heatmap(corrs, cbar = True, annot=True, square = True, fmt = '.2f',\n              yticklabels = cols, xticklabels = cols).set_title('Correlations heatmap')\n\nfig = hm.get_figure()\nfig.savefig('correlations.png')","7f2d2ddb":"#turn categorical columns into dummies\ncat_columns = list(df.select_dtypes(include=['object']).columns)\n    \nfor col in  cat_columns:\n    df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_',\n\n                                                         drop_first=True, dummy_na=True)], axis=1)\n#drop listing_id and year columns\ndf = df.drop(columns = ['listing_id', 'year'])","71c889e1":"#prepare train and test datasets for modelling\nTEST_SIZE = 0.3\nRAND_STATE = 42\n\nX = df.drop(columns = 'price')\ny = df[['price']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state=RAND_STATE)","cc7d24a9":"#train RF regressor model\nforest = RandomForestRegressor(n_estimators=100, \n                               criterion='mse', \n                               random_state=RAND_STATE, \n                               n_jobs=-1)\nforest.fit(X_train, y_train.squeeze())\n\n#calculate scores for the model\ny_train_preds = forest.predict(X_train)\ny_test_preds = forest.predict(X_test)\n\nprint('Random Forest MSE train: %.3f, test: %.3f' % (\n        mean_squared_error(y_train, y_train_preds),\n        mean_squared_error(y_test, y_test_preds)))\nprint('Random Forest R^2 train: %.3f, test: %.3f' % (\n        r2_score(y_train, y_train_preds),\n        r2_score(y_test, y_test_preds)))","f6240ddd":"#get feature importances from the model\nheaders = [\"name\", \"score\"]\nvalues = sorted(zip(X_train.columns, forest.feature_importances_), key=lambda x: x[1] * -1)\nforest_feature_importances = pd.DataFrame(values, columns = headers)\nforest_feature_importances = forest_feature_importances.sort_values(by = ['score'], ascending = False)\n\nfeatures = forest_feature_importances['name'][:15]\ny_pos = np.arange(len(features))\nscores = forest_feature_importances['score'][:15]\n\n#plot feature importances\nplt.figure(figsize=(10,5))\nplt.bar(y_pos, scores, align='center', alpha=0.5)\nplt.xticks(y_pos, features, rotation='vertical')\nplt.ylabel('Score')\nplt.xlabel('Features')\nplt.title('Feature importances (Random Forest)')\n\nplt.savefig('feature importances RF.png')\n \nplt.show()","7bf69eb2":"#train XGBoost model\nxgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)\nxgb.fit(X_train,y_train)\n\n#calculate and print scores for the model for top 15 features\ny_train_preds = xgb.predict(X_train)\ny_test_preds = xgb.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (\n        mean_squared_error(y_train, y_train_preds),\n        mean_squared_error(y_test, y_test_preds)))\nprint('R^2 train: %.3f, test: %.3f' % (\n        r2_score(y_train, y_train_preds),\n        r2_score(y_test, y_test_preds)))","07ad4b9e":"#get feature importances from the model\nheaders = [\"name\", \"score\"]\nvalues = sorted(zip(X_train.columns, xgb.feature_importances_), key=lambda x: x[1] * -1)\nxgb_feature_importances = pd.DataFrame(values, columns = headers)\n\n#plot feature importances for top 15 features\nfeatures = xgb_feature_importances['name'][:15]\ny_pos = np.arange(len(features))\nscores = xgb_feature_importances['score'][:15]\n \nplt.figure(figsize=(10,5))\nplt.bar(y_pos, scores, align='center', alpha=0.5)\nplt.xticks(y_pos, features, rotation='vertical')\nplt.ylabel('Score')\nplt.xlabel('Features')\nplt.title('Feature importances (XGBoost)')\n\nplt.savefig('feature importances XGB.png')\n \nplt.show()","0883c2e7":"## Approach","d1fd79b1":"It is useful to look on correlations between price and other features from the dataset to find factors, which influence the price.","02ba26f6":"## The First Look at the Data","89b75eb4":"As we see on the diagram above, we don't have information on each listing license and on amount of square feets for each listing. We can also see that there are more than 40% of missing values for weekly price, monthly price and security deposit, but we are not going to use these data in our analysis anyway, because it will obviously lead to overfitting our machine learning model.","d8ea71ae":"According to the diagram above listing prices raise significantly in summer, probably, because of the fact that there are less listings available for reservation. There is also a raise in December. This tells us that summer and winter holidays should be the busiest times to visit Seattle.","b5e57df5":"## Conclusion","966ceb0f":"## Initial Insights","3da99fa3":"The diagram above shows us number of listings depending on month. We can see that number of available listings for reservation is tends to be the lowest in summer.","def5f9c7":"We already mentioned above that neighbourhood might have great influence on the listing price. Let's take a look at listing prices depending on neighbourhood.","501aaf5a":"### Prices Depending on Neighbourhood","cea3d68e":"The main takeaways of the Seattle data analysis include:\n<br> Basic characteristics of the place (number of bedrooms, bathrooms, beds and accomodates) affect the reservation price.\n<br> The reservation price varies depending on the time of the year. For example, the busiest time to visit Seattle is summer.\n<br> The host qualities and the number of reviews and review scores might also affect the reservation price. That is why if you want to save money, you may, for example, look for places which have fewer reviews. This will help to find the places with same characteristics (bathrooms, bedrooms, location etc.), and lower reservation price.","11e3a6da":"AirBnB reservation price is based on following costs (according to __[AirBnB official website information](https:\/\/www.airbnb.com\/help\/article\/125\/how-is-the-price-determined-for-my-reservation?locale=en)__):\n- Costs determined by the host:\n    - Nightly price: Nightly rate decided by the host;\n    - Cleaning fee: One-time fee charged by some hosts to cover the cost of cleaning their space;\n    - Extra guest fees: One-time fee charged by some hosts to cover other costs related to using their space;\n- Costs determined by Airbnb: Airbnb service fee;\n- Other costs that may be included: currency exchange fees, VAT, other local taxes etc.","684678ea":"### What Are the Busiest Times of the Year to Visit Seattle?","fc9302e0":"## Introduction","30878e13":"### Correlation between Price and Other Features","3c81d4c4":"AirBnB provided us with 3 datasets for Seattle:\n* listings.csv - summary information on listing in Seattle such as: location, host information, cleaning and guest fees, amenities etc.\n* calendar.csv - calendar data for the listings: availability dates, price for each date.\n* reviews.csv - summary review data for the listings. This dataset won't be used in further analysis.","07a06f0b":"Statistics for calendar.csv dataset:","9c429c95":"Train XGBoost Regressor model to predict price:","805dad57":"In our analysis we will concentrate on the factors, which influence the nightly price, determined by the host. Actually, AirBnB already has an algorithm, which suggests hosts the price. The approach for the algorithm and challenges are described in the article __[here](https:\/\/www.vrmintel.com\/inside-airbnbs-algorithm\/)__.\nWe can also use the information from the article in our analysis:\n\n- Time of the year, when reservation is made, affects the price;\n- Amenities offered like Wi-Fi and TV should be considered in the analysis, as they also might have great influence on price;\n- It is better to use neighbourhood information rather then exact coordinates to describe the listing location, because sometimes even close locations might have huge difference in listing prices, if they belong to different neighbourhoods or are located different sides of the river. ","5217839b":"listings.csv dataset missing values statistics (only columns with any missing data are represented on the diagram):","bf8cbf8f":"Statistics for listings.csv dataset:","f0b1a736":"Additionally we are able to apply machine learning methods to see which features in dataset influence the price the most. In order to do this we will train two popular models (__[Random Forest regressor](https:\/\/en.wikipedia.org\/wiki\/Random_forest)__ and __[XGBoost regressor)](https:\/\/en.wikipedia.org\/wiki\/XGBoost)__ based on decision trees and look at resulting feature importances.","3379a169":"As we see on digram, there are only 32% percent of missing values for price column for dates, when the listing was unavailable.","e3d08ed4":"Before diving deep into data, let's find out some general information on how the reservation price is determined and search for some useful facts for the future analysis.","478422c5":"Before trying to get the first outcomes, the data should be pre-processed: \n* datasets should be merged into one using the listing identifier;\n* irrelevant columns and columns, which contain missing data should be removed from the analysis;\n* dates and prices should be converted from text into numbers.","d80ff69b":"calendar.csv dataset missing values statistics","1cc83e7e":"## Initial Data Preparation","d4fe8cd9":"### Listing Prices Overview","2ef0e060":"To answer this question we should look at:\n* how the number of listings change depending on time of the year?\n* how prices change depending on time of time of the year?","476053f3":"Let's take a look at the results of the modelling:\n* The modelling also shows us that factors already mentioned above have influence on price: time of the year, location, number of bedrooms, bathrooms, beds and accomodates;\n* The host qualities are important: number of host's listings, number of years since being the host, time in which the host responds to the inquiries;\n* The pricing might depend on reviews: number of reviews and review scores.","ab512a15":"Train Random Forest Regressor model to predict price:","747607b6":"First of all let's have a high level overview of the prices:","1f486d45":"Now we see the distribution of average listing prices. The majority of listings is concentrated around 50 - 150 USD.","04febb55":"On the diagram above we can see that prices differ depending on the location (neighbourhood). The highest average prices are in Downtown, which is not surprising. But for each neighbourhood prices tend to raise in summer.","25f68fc8":"## High Level Analysis","d0663c25":"Finding an accomodation is the most typical problem to be solved, when travelling to other city or country. And one of the most important things in choosing an accomodation is the reservation price. What are the main factors, which affect the reservation prices? Does time of the year influence prices and what are the busiest times of the year to visit particular city? How can we save money on the reservation?\n\nFortunately, we can try to answer these questions by analysing publicly accessible __[AirBnB](https:\/\/www.airbnb.com)__ data, available on __[Inside AirBnB](http:\/\/insideairbnb.com\/get-the-data.html)__ and on __[Kaggle](https:\/\/www.kaggle.com\/airbnb\/seattle)__.","481b826f":"## Machine Learning","772da042":"From the correlations heatmap diagram we can see that price is correlated with number of accomodates, bathrooms, bedrooms and beds. We also see that these features are correlated themselves. In fact, these results are quite obvious, because the price really depends on how large is the place.","9b28a779":"Now when we have clean data, we can look closer and try to find answers to our questions.","96cfcfe7":"In this analysis we tried to understand what influences the reservation prices with the help of AirBnB data for Seattle. Of course, the results may be different for each city, but current approach still can be used for other cities' data.","95ea3840":"First of all, I chose Seattle dataset, and it will take me the following steps to come into conclusions about factors, affecting reservation prices:\n\n1. The first look at the data: \n    * what information we have?\n    * what information is missing?\n    * discover general facts: time period, total number of listings in the dataset, \n2. Initial data preparation:\n    * remove the irrelevant information;\n    * reformat the information and imputing missing values;   \n3. High level analysis:\n    * find out high level trends and correlations;  \n4. Use machine learning for further analysis.","9211bb45":"So now when we know how to choose between places offered by AirBnB and save money it is time to travel and test it on practice!"}}