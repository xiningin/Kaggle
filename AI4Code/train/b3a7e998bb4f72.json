{"cell_type":{"c12f12e6":"code","102ee29e":"code","d6bb1d2a":"code","43ac33d5":"code","69fa9d1e":"code","1badc500":"code","287506ff":"code","0dd43616":"code","6f1292ad":"code","525d8669":"code","0233080a":"code","9bae045d":"code","c48dfe29":"code","65bcfda3":"code","8801ebcb":"code","81fc61d8":"code","023a534a":"code","29a0f857":"code","3ca8a5dc":"code","48a97e30":"code","2efa4279":"code","4124bd0b":"code","10cd7765":"code","5201b4f0":"code","bad8d8fc":"code","d95b5cc9":"code","815f9765":"code","907ac91c":"code","67f2bad4":"code","1d8c94ec":"code","7eb7c25c":"code","5537d9df":"code","a6869aa0":"code","d4d8f745":"code","8a280098":"markdown"},"source":{"c12f12e6":"import os, json, random, cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pathlib\nimport tensorflow as tf\nimport re\nimport math\nfrom tqdm import tqdm","102ee29e":"class BASE_CFG:\n    comp_path = \"\/kaggle\/input\/landmark-retrieval-2021\"\n    n_labels = 81313\n    NUMBER_OF_CLASSES = 81313\n    BATCH_SIZE = 256\n    EPOCHS = 10\n    LEARNING_RATE=0.0001\n    OBJ_HEIGHT = 256\n    OBJ_WIDTH = 256\n    IMAGE_SIZE = 256\n    CHANNELS = 0\n    NET = 0\n    dtype = 'float32'\n    VAL_CLASS_NUM = 1000\n    FOLD = 3","d6bb1d2a":"CFG = BASE_CFG()\ncomp_path = pathlib.Path(CFG.comp_path)\nprint(comp_path)","43ac33d5":"DATASET_NAME = f'landmark-retrieval-2021-stratify-fold{CFG.FOLD}'","69fa9d1e":"!rm -r \/tmp\/{DATASET_NAME}\nos.makedirs(f'\/tmp\/{DATASET_NAME}', exist_ok=True)","1badc500":"with open('..\/input\/statking-kaggle-api\/kaggle.json') as f:\n    kaggle_creds = json.load(f)\nos.environ['KAGGLE_USERNAME'] = kaggle_creds['username']\nos.environ['KAGGLE_KEY'] = kaggle_creds['key']","287506ff":"!kaggle datasets init -p \/tmp\/{DATASET_NAME}\nwith open(f'\/tmp\/{DATASET_NAME}\/dataset-metadata.json') as f:\n    dataset_meta = json.load(f)\ndataset_meta['id'] = f'deepkim\/{DATASET_NAME}'\ndataset_meta['title'] = DATASET_NAME\nwith open(f'\/tmp\/{DATASET_NAME}\/dataset-metadata.json', \"w\") as outfile:\n    json.dump(dataset_meta, outfile)\nprint(dataset_meta)\n\n!cp \/tmp\/{DATASET_NAME}\/dataset-metadata.json \/tmp\/{DATASET_NAME}\/meta.json\n!ls \/tmp\/{DATASET_NAME}\n\n!kaggle datasets create -u -p \/tmp\/{DATASET_NAME}","0dd43616":"#os.listdir(\"\/tmp\/landmark-retrieval-2021-tfrecords-size256\")","6f1292ad":"!ls \/tmp\/{DATASET_NAME}\n","525d8669":"train = pd.read_csv(comp_path \/ \"train.csv\")","0233080a":"landmark_id_count_dict = train['landmark_id'].value_counts().to_dict()","9bae045d":"#class_pair_dict = {}\nclass_pair_dict_keys = train.groupby('landmark_id').count().reset_index().index.tolist()\nclass_pair_dict_values = train.groupby('landmark_id').count().reset_index()['landmark_id'].tolist()","c48dfe29":"class_pair_dict = {key:value for key, value in zip(class_pair_dict_keys, class_pair_dict_values)}\nreverse_class_pair_dict = {value:key for key, value in zip(class_pair_dict_keys, class_pair_dict_values)}","65bcfda3":"train['fixed_landmark_id'] = train['landmark_id'].map(reverse_class_pair_dict)","8801ebcb":"train['landmark_id_count'] = train['landmark_id'].map(landmark_id_count_dict)","81fc61d8":"train.id.nunique()","023a534a":"train","29a0f857":"from sklearn.model_selection import StratifiedKFold\ntrain['fold'] = -1\nskf = StratifiedKFold(n_splits=40)\nfor fold,(tr_idx, val_idx) in enumerate(skf.split(train, y = train['fixed_landmark_id'])):\n    train.loc[val_idx,'fold'] = fold","3ca8a5dc":"tqdm.pandas()","48a97e30":"#image_path = \"..\/input\/landmark-recognition-2020\/train\/{}\/{}\/{}\/{}.jpg\".format(image_id[0],image_id[1],image_id[2],image_id) \ntrain['file_path'] = train['id'].map(lambda x: \"train\/{}\/{}\/{}\/{}.jpg\".format(x[0],x[1],x[2],x))","2efa4279":"train['kaggle_file_path'] = train['id'].map(lambda x: \"..\/input\/landmark-retrieval-2021\/train\/{}\/{}\/{}\/{}.jpg\".format(x[0],x[1],x[2],x))","4124bd0b":"train.head()","10cd7765":"for fold in range(40):\n    print(train.loc[train['fold']==fold]['fixed_landmark_id'].value_counts().sort_values())","5201b4f0":"import gc\ngc.collect()","bad8d8fc":"train","d95b5cc9":"import pickle\ntrain.to_csv(\"startified_train.csv\", index=False)\n","815f9765":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(image,image_name,label):\n    feature = {\n        'image': _bytes_feature(image),\n        'image_id': _bytes_feature(image_name),\n        'target': _int64_feature(label),\n      }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","907ac91c":"def create_real_train_tf_records(fold  = 0):\n    df = train.loc[train['fold']==fold].reset_index(drop=True)\n    tfr_filename = f'\/tmp\/{DATASET_NAME}\/landmark-2021-train-{fold}-{df.shape[0]}.tfrec'\n    with tf.io.TFRecordWriter(tfr_filename) as writer:\n        for i,row in df.iterrows():\n            image_id = row.id\n            target = row.fixed_landmark_id\n            image_path = \"..\/input\/landmark-retrieval-2021\/train\/{}\/{}\/{}\/{}.jpg\".format(image_id[0],image_id[1],image_id[2],image_id) \n            image_encoded = tf.io.read_file(image_path)\n            image_name = str.encode(image_id)\n            example = serialize_example(image_encoded,image_name,target)\n            writer.write(example)","67f2bad4":"if CFG.FOLD == 0:\n    foldrange=range(0,10)\nelif CFG.FOLD==1:\n    foldrange = range(10,20)\nelif CFG.FOLD==2:\n    foldrange = range(20,30)\nelif CFG.FOLD==3:\n    foldrange = range(30,40)","1d8c94ec":"import joblib\n_ = joblib.Parallel(n_jobs=8)(\n        joblib.delayed(create_real_train_tf_records)(fold) for fold in tqdm(foldrange))","7eb7c25c":"from datetime import datetime\nversion_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nprint(version_name)","5537d9df":"!cp \/kaggle\/working\/train.csv \/tmp\/{DATASET_NAME}\/train.csv\n","a6869aa0":"!ls \/tmp\/{DATASET_NAME}","d4d8f745":"!kaggle datasets version -m {version_name} -p \/tmp\/{DATASET_NAME} -r zip -q","8a280098":"# DATASET MAKING"}}