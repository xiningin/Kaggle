{"cell_type":{"42e04876":"code","0e4d61c0":"code","db29a765":"code","32c34410":"code","80f48862":"code","b3ada356":"code","ab927bf5":"code","1e9f1d2d":"code","799d7859":"code","168c4f5b":"code","0c37b4f1":"code","e3e9973a":"code","48f85c21":"code","dadf8c1c":"code","0d047c14":"code","3d2313cc":"code","0bfcd134":"code","200d7b93":"code","853b7db9":"code","f1d88f60":"code","f8783e9c":"code","8694e7c6":"code","215054eb":"code","a638a6c1":"code","8e6857de":"code","1a4ef8fb":"code","817daab6":"code","66fab640":"code","a8180bca":"code","e7e9eade":"markdown"},"source":{"42e04876":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy.stats import norm\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0e4d61c0":"PATH = '..\/input'\ntraining_set = pd.read_csv(os.path.join(PATH, 'training_set.csv'))\ntesting_set = pd.read_csv(os.path.join(PATH, 'test_set.csv'), nrows=100)\ncomplete_set = training_set.append(testing_set)\n#training_set = training_set.set_index(training_set['object_id'])\n#training_set = training_set.drop(columns=['object_id'])","db29a765":"FEATURES = list(complete_set)\nFEATURES","32c34410":"complete_set.head()","80f48862":"pd.set_option('display.float_format', lambda x : '%.0f' % x)","b3ada356":"complete_set.describe()","ab927bf5":"PREDICTORS = ['mjd_a59k', 'passband', 'flux']\nOUTCOME = ['detected']","1e9f1d2d":"def preprocessing(df):\n    '''\n    return a preprocessed df\n    '''\n    df_new = df.copy()\n    ### SAND BOX\n    df_new['mjd_a59k'] = df_new['mjd'] - df_new['mjd'].min()\n#     MJD to Unix time conversion: (MJD - 40587) * 86400 + seconds past UTC midnight\n#     https:\/\/wiki.polaire.nl\/doku.php?id=mjd_convert_modified_julian_date\n    df_new['unix'] = (df_new['mjd'] - 40587) * 86400\n    df_new['unix'] = df_new['unix'] - df_new['unix'].min()\n    ### SAND BOX END\n    return df_new","799d7859":"df_current = preprocessing(training_set)\n#### SAND BOX ####","168c4f5b":"sns.distplot(df_current[df_current.detected == 0]['flux'] , fit=norm)","0c37b4f1":"df_current.describe()","e3e9973a":"# df_current[df_current.detected == 1].describe() - df_current[df_current.detected == 0].describe()","48f85c21":"df_current[df_current.detected == 0].isna().sum()","dadf8c1c":"df_current[df_current.detected == 0].describe()","0d047c14":"# df_current[df_current.detected == 1].describe()[]","3d2313cc":"#### SAND BOX ENDED ####","0bfcd134":"def x_y(df):\n    '''\n    determine the x and y by global variable predictors and outcome\n    '''\n    X = df[PREDICTORS]\n    y = df[OUTCOME]\n    return (X, y)","200d7b93":"training_final = preprocessing(training_set)\ntesting_final = preprocessing(pd.read_csv(os.path.join(PATH, 'test_set_sample.csv')))","853b7db9":"X_tr, y_tr = x_y(training_final)\nX_te, y_te = x_y(testing_final)","f1d88f60":"from sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier","f8783e9c":"models = []\n### SAND BOX ####\n# models.append(('Logistic Regression', LogisticRegression()))\n# models.append(('Extreme Gradient Booster', XGBClassifier()))\nmodels.append(('Extreme Gradient Booster', XGBClassifier(learning_rate=0.05)))\nmodels.append(('Extreme Gradient Booster', XGBClassifier(learning_rate=0.02)))\nmodels.append(('Extreme Gradient Booster', XGBClassifier(learning_rate=0.01)))\nmodels.append(('Extreme Gradient Booster', XGBClassifier(learning_rate=0.2)))\nmodels.append(('Extreme Gradient Booster', XGBClassifier(learning_rate=0.25)))\n","8694e7c6":"class ModelResult():\n    def __init__(self, name, model) :\n        self.name = name\n        self.model = model\n        self.metrics = []\n    def set_metric(self, name, metric):\n        self.metrics.append((name, metric))\n    def __str__(self):\n        returner = \"###### \" + self.name + \" ######\\n\"\n        for met_name, metric in self.metrics :\n            returner += met_name + \":\\n\"\n            returner += str(metric) + \"\\n\"\n        return returner\n    ","215054eb":"# mres = ModelResult('lr', LogisticRegression())\n# print(mres)","a638a6c1":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve\nimport time","8e6857de":"def run_models(models):\n    results = []\n    for name, model in models :\n        start = time.time()\n        model.fit(X_tr, y_tr)\n        y_pred = model.predict(X_te)\n        mr = ModelResult(name, model)\n        mr.set_metric(('accuracy'), accuracy_score(y_te, y_pred))        \n        mr.set_metric(('confusion_matrix'), confusion_matrix(y_te, y_pred))        \n        mr.set_metric(('roc_curve'), roc_curve(y_te, y_pred))\n        mr.set_metric(('time_elapsed'), time.time() - start)\n        results.append(mr)\n    return results\n#uncomment this if ready\nresults = run_models(models)","1a4ef8fb":"for res in results :\n    print(res)","817daab6":"for res in results :\n    print(res)","66fab640":"results_3 = run_models(models_3)","a8180bca":"for r in results_3 :\n    print(r)","e7e9eade":"PREDICTORS = ['mjd_a59k', 'passband', 'flux']\n\n###### Logistic Regression ######\naccuracy:\n0.948817\nconfusion_matrix:\n[[948817      0]\n [ 51183      0]]\nroc_curve:\n(array([0., 1.]), array([0., 1.]), array([1, 0]))\n\n###### Extreme Gradient Booster 0.1 LR ######\naccuracy:\n0.964415\nconfusion_matrix:\n[[948511    306]\n [ 35279  15904]]\nroc_curve:\n(array([0.00000000e+00, 3.22506869e-04, 1.00000000e+00]), array([0.        , 0.31072817, 1.        ]), array([2, 1, 0]))\n\n###### Extreme Gradient Booster 0.05 LR ######\naccuracy:\n0.962487\nconfusion_matrix:\n[[948635    182]\n [ 37331  13852]]\nroc_curve:\n(array([0.00000000e+00, 1.91817811e-04, 1.00000000e+00]), array([0.        , 0.27063673, 1.        ]), array([2, 1, 0]))\ntime_elapsed:\n49.75889468193054\n\n###### Extreme Gradient Booster 0.02 LR ######\naccuracy:\n0.960895\nconfusion_matrix:\n[[948691    126]\n [ 38979  12204]]\nroc_curve:\n(array([0.00000000e+00, 1.32796946e-04, 1.00000000e+00]), array([0.        , 0.23843854, 1.        ]), array([2, 1, 0]))\ntime_elapsed:\n49.226396322250366\n\n###### Extreme Gradient Booster 0.01 LR ######\naccuracy:\n0.959617\nconfusion_matrix:\n[[948680    137]\n [ 40246  10937]]\nroc_curve:\n(array([0.0000000e+00, 1.4439033e-04, 1.0000000e+00]), array([0.        , 0.21368423, 1.        ]), array([2, 1, 0]))\ntime_elapsed:\n49.153637170791626\n\n###### Extreme Gradient Booster 0.20 LR ######\naccuracy:\n0.965446\nconfusion_matrix:\n[[948454    363]\n [ 34191  16992]]\nroc_curve:\n(array([0.00000000e+00, 3.82581678e-04, 1.00000000e+00]), array([0.        , 0.33198523, 1.        ]), array([2, 1, 0]))\ntime_elapsed:\n49.09350323677063\n\n###### Extreme Gradient Booster 0.25 LR######\naccuracy:\n0.965306\nconfusion_matrix:\n[[948430    387]\n [ 34307  16876]]\nroc_curve:\n(array([0.00000000e+00, 4.07876334e-04, 1.00000000e+00]), array([0.        , 0.32971885, 1.        ]), array([2, 1, 0]))\ntime_elapsed:\n49.166661739349365\n"}}