{"cell_type":{"b780218f":"code","511289d4":"code","46de9a60":"code","25195742":"code","fb090125":"code","4d5d6e77":"code","00c038f8":"code","2023de95":"code","da357bc4":"code","901e4a2b":"code","ba601444":"code","00f24c0f":"code","2c6cccb4":"code","c3f4124f":"code","cbcae53e":"code","e19857d7":"code","2a77f575":"code","b4af1694":"code","52d66bff":"code","a7058ae1":"code","4430d049":"code","db9677d1":"code","135b4f0c":"code","5bfe8eb7":"code","7b5acf20":"code","a8f6b67a":"code","949b13c6":"code","a6bbb49b":"code","a691eb65":"code","3b78f03c":"code","a0727389":"code","55a9f738":"code","028c5888":"code","4fe271c6":"code","00475cd8":"code","69c44ae5":"code","271528ff":"code","db7ca4df":"code","099581f3":"code","fe00e4c4":"code","96c09ef3":"code","b8607c7c":"code","befbfff5":"code","0a857886":"code","afbd0508":"code","8a168a63":"code","6e5c6553":"code","083bdbbc":"code","f548c8b7":"code","bfd7aad7":"code","53a10c29":"markdown","00646935":"markdown","972465ec":"markdown","d17c8118":"markdown","71a628be":"markdown","7f12a820":"markdown","7516352e":"markdown","582fe931":"markdown","077afd53":"markdown","ecd873fc":"markdown","914ea0a8":"markdown","02b6b0b5":"markdown","9e7b1b8e":"markdown","5165028b":"markdown","272b2749":"markdown","d88b0b06":"markdown","a24be3ca":"markdown","914f307f":"markdown","dfa228af":"markdown","32b4565b":"markdown","86617be9":"markdown","1283b9be":"markdown","fdbfafb5":"markdown","428af552":"markdown","08dfa7a0":"markdown","d0dda2b9":"markdown","4d909697":"markdown","8010c291":"markdown"},"source":{"b780218f":"# Allow several prints in one cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport pandas as pd","511289d4":"# Input\nimport numpy as np\na_list = list(\"abcdefg\")\nnumpy_array = np.arange(1, 10)\ndictionary = {\"A\":  0, \"B\":1, \"C\":2, \"D\":3, \"E\":5}","46de9a60":"series1 = pd.Series(a_list)\nprint(series1)\nseries2 = pd.Series(numpy_array)\nprint(series2)\nseries3 = pd.Series(dictionary)\nprint(series3)","25195742":"# input\nser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\nser2 = pd.Series(np.arange(26))","fb090125":"# using pandas DataFrame\nser_df = pd.DataFrame(ser1, ser2).reset_index()\nser_df.head()\n# using pandas DataFrame with a dictionary, gives a specific name to the column\nser_df = pd.DataFrame({\"col1\":ser1, \"col2\":ser2})\nser_df.head(5)\n# using pandas concat\nser_df = pd.concat([ser1, ser2], axis = 1)\nser_df.head()","4d5d6e77":"# input\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])","00c038f8":"ser1[~ser1.isin(ser2)]","2023de95":"# input\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])","da357bc4":"# using pandas\na_not_b = ser1[~ser1.isin(ser2)]\nb_not_a = ser2[~ser2.isin(ser1)]\n                          \na_not_b.append(b_not_a, ignore_index = True)\n\n# using numpy union and intersection\nser_u = pd.Series(np.union1d(ser1, ser2))\nser_i = pd.Series(np.intersect1d(ser1, ser2))\nser_u[~ser_u.isin(ser_i)]","901e4a2b":"# input\nstate = np.random.RandomState(100)\nser = pd.Series(state.normal(10, 5, 25))\n","ba601444":"# using pandas\nser.describe()","00f24c0f":"# input\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))","2c6cccb4":"ser.value_counts()","c3f4124f":"# input\nser = pd.Series(np.random.randint(1, 10, 35))\nser","cbcae53e":"# using numpy\npd.DataFrame(np.array(ser).reshape(7, 5))\n\n# using only pandas\npd.DataFrame(ser.values.reshape(7, 5))","e19857d7":"# input\n\nnp.random.RandomState(100)\nser = pd.Series(np.random.randint(1, 5, 10))\nser","2a77f575":"# using the where clause\nser.where(lambda x: x%3 == 0).dropna()\n\n# using numpy and reshape to get a pandas series\n#pd.Series(np.argwhere(ser%3 == 0).reshape(4))\nnp.argwhere(ser%3 == 0)","b4af1694":"# input\n\nser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\npos = [0, 4, 8, 14, 20]","52d66bff":"# using loc\nser.loc[pos]\n\n# using series take\nser.take(pos)","a7058ae1":"# input\nser1 = pd.Series(range(5))\nser2 = pd.Series(list('abcde'))","4430d049":"# vertical\nser1.append(ser2)\n# or using pandas concat and axis = 0\npd.concat([ser1, ser2], axis = 0)\n\n# horizontal\npd.concat([ser1, ser2], axis = 1)","db9677d1":"# input\nser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\nser2 = pd.Series([1, 3, 10, 13])","135b4f0c":"# get's the index, but it's sorts the index\nlist(ser1[ser1.isin(ser2)].index)\n\n# using numpy where\n[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n\n# using pandas Index and get location\n[pd.Index(ser1).get_loc(i) for i in ser2]","5bfe8eb7":"# input\nser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n\n# Desired Output\n# [nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n# [nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]","7b5acf20":"# using pandas diff()\nser.diff(periods = 1).tolist()\nser.diff(periods = 1).diff(periods = 1).tolist()","a8f6b67a":"# input\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013\/04\/04', '2014-05-05', '2015-06-06T12:20'])\n\n\n'''\nDesired Output\n\n0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\n'''\n\n","949b13c6":"# using pands to_datetime\npd.to_datetime(ser)\n\n# using dateutil parse\nfrom dateutil.parser import parse\nser.map(lambda x: parse(x))","a6bbb49b":"# input\nser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n\n'''\nDesired Output\n\n\n0     Apple\n1    Orange\n4     Money\ndtype: object\n'''","a691eb65":"# using nested loops\nvowels = list(\"aeiou\")\nlist_ = []\nfor w in ser:\n    c = 0\n    for l in list(w.lower()):\n        if l in vowels:\n            c += 1\n    if c >= 2:\n        print(w)\n        list_.append(w)\n\nser[ser.isin(list_)]\n\n# another solution using counter\n\nfrom collections import Counter\nmask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\nser[mask]","3b78f03c":"# input\nmy_str = 'dbc deb abed ggade'\n\n'''\nDesired Output\n\n'dbccdebcabedcggade'  # least frequent is 'c'\n'''","a0727389":"# using Counter\nfrom collections import Counter\nmy_str_ = my_str\nCounter_ = Counter(list(my_str_.replace(\" \", \"\")))\nCounter_\nminimum = min(Counter_, key = Counter_.get)\n\nprint(my_str.replace(\" \", minimum))\n\n# using pandas\nser = pd.Series(list(my_str.replace(\" \", \"\")))\nser.value_counts()\nminimum = list(ser.value_counts().index)[-1]\nminimum\nprint(my_str.replace(\" \", minimum))","55a9f738":"# input\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","028c5888":"# first let's import using the previuos code and save as a normal csv\n\nnames = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\nwith open(\"\/kaggle\/input\/boston-house-prices\/housing.csv\") as f:\n    data = f.read()\n    nth_rows = []\n    for i, rows in enumerate(data.split(\"\\n\")):\n        nth_rows.append(rows)\n\ndata_ = [nth_rows[i].split() for i in range(len(nth_rows))]\n\ndf = pd.DataFrame(data_, columns=names)\ndf.head()\ndf.to_csv(\"housing_preprocessed.csv\")\ndel df","4fe271c6":"# now let's start importing as normal and use converters to convert the values\n# skipfooter because we had the last rows with nan values and index_col to specify that the first column is the index\ndf = pd.read_csv(\"housing_preprocessed.csv\",  index_col = 0, skipfooter=1,  converters = {\"MEDV\": lambda x: \"HIGH\" if float(x) >= 25 else \"LOW\"})\ndf","00475cd8":"# input\n        \n# code that generates the housing_preprocessed.csv file\nnames = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\nwith open(\"\/kaggle\/input\/boston-house-prices\/housing.csv\") as f:\n    data = f.read()\n    nth_rows = []\n    for i, rows in enumerate(data.split(\"\\n\")):\n        nth_rows.append(rows)\n\ndata_ = [nth_rows[i].split() for i in range(len(nth_rows))]\n\ndf = pd.DataFrame(data_, columns=names)\ndf.to_csv(\"housing_preprocessed.csv\")\ndel df\n\n# use the \/kaggle\/input\/boston-house-prices\/housing_preprocessed.csv file\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","69c44ae5":"file = \"housing_preprocessed.csv\"\n# using index\ndf = pd.read_csv(file, usecols = [1, 2, 4], skipfooter=1)\ndf.head()\n# using column names\ndf = pd.read_csv(file, usecols = [\"CRIM\", \"ZN\", \"CHAS\"])\ndf.head()","271528ff":"# input\ndf = pd.read_csv(\"..\/input\/cars93\/Cars93.csv\")\ndf","db7ca4df":"# Solution 1\nprint(\"Our df has a total of {} null values\".format(df.isnull().sum().sum()))\nprint()\n\n# Solution 2\ndf.isnull().values.any()\nprint()\n\n# Solution 3\n# A more detailed one\ndef report_nulls(df):\n    '''\n    Show a fast report of the DF.\n    '''\n    rows = df.shape[0]\n    columns = df.shape[1]\n    null_cols = 0\n    list_of_nulls_cols = []\n    for col in list(df.columns):\n        null_values_rows = df[col].isnull().sum()\n        null_rows_pcn = round(((null_values_rows)\/rows)*100, 2)\n        col_type = df[col].dtype\n        if null_values_rows > 0:\n            print(\"The column {} has {} null values. It is {}% of total rows.\".format(col, null_values_rows, null_rows_pcn))\n            print(\"The column {} is of type {}.\\n\".format(col, col_type))\n            null_cols += 1\n            list_of_nulls_cols.append(col)\n    null_cols_pcn = round((null_cols\/columns)*100, 2)\n    print(\"The DataFrame has {} columns with null values. It is {}% of total columns.\".format(null_cols, null_cols_pcn))\n    return list_of_nulls_cols\n\nreport_nulls(df)","099581f3":"# input\ndf = pd.read_csv(\"..\/input\/cars93\/Cars93.csv\")","fe00e4c4":"# Solution 1\nbeg_null = df.isnull().sum().sum()\nprint(beg_null)\n# notice that we have filtering the columns  as a list.\ndf[[\"Luggage.room\"]] = df[[\"Luggage.room\"]].apply(lambda x: x.fillna(x.mean()))\nend_null = df.isnull().sum().sum()\nprint(end_null)\n\nprint(\"We have got rid of {} null values, filling them with the mean.\".format(beg_null - end_null))","96c09ef3":"# input\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))","b8607c7c":"# Solution to question 1\n# we pass a list with the custom names BUT THIS DOESN'T change in place\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\ndf[[\"c\", \"b\", \"a\", \"d\", \"e\"]]\ndf\n\n# if we reasing that this will work\ndf = df[[\"c\", \"b\", \"a\", \"d\", \"e\"]]\ndf\n\n# Solution to question 2\ndef change_cols(df, col1, col2):\n    df_columns = df.columns.to_list()\n    index1 = df_columns.index(col1)\n    index2 = df_columns.index(col2)\n    # swaping values\n    df_columns[index1], df_columns[index2] = col1, col2\n    \n    return df[df_columns]\n\n\ndf = change_cols(df, \"b\", \"e\")\ndf\n    \n\n# Solution to question 3\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\ncol_list = list(df.columns)\ncol_list_reversed = col_list[::-1]\ncol_list\ncol_list_reversed\n# using the trick from solution 1\ndf = df[col_list_reversed]\ndf\n\n\nprint(\"Solution from the website\")\nprint(\"-------------------------\")\n# Others solution from the website\n\n# Input\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\n# Solution Q1\ndf[list('cbade')]\n\n# Solution Q2 - No hard coding\ndef switch_columns(df, col1=None, col2=None):\n    colnames = df.columns.tolist()\n    i1, i2 = colnames.index(col1), colnames.index(col2)\n    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n    return df[colnames]\n\ndf1 = switch_columns(df, 'a', 'c')\n\n# Solution Q3\ndf[sorted(df.columns)]\n# or\ndf.sort_index(axis=1, ascending=False, inplace=True)","befbfff5":"# input\ndf = pd.read_csv(\"..\/input\/cars93\/Cars93.csv\")\ndf","0a857886":"# First let's import only the columns we need\ndf = pd.read_csv(\"..\/input\/cars93\/Cars93.csv\", usecols=[\"Manufacturer\", \"Model\", \"Type\"])\n\n# Solution 1\n# Using normal python slicing\ndf[::20]\n\ndf = pd.read_csv(\"..\/input\/cars93\/Cars93.csv\", usecols=[\"Manufacturer\", \"Model\", \"Type\"])\n\n# Solution 2\n# Using iloc\ndf.iloc[::20, :][['Manufacturer', 'Model', 'Type']]\n","afbd0508":"# input\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\ndf1 = df.copy(deep = True)","8a168a63":"# Solution 1\ndf[\"sum\"] = df.sum(axis = 1)\ndf\n\nprint(\"The index of the rows that are greater than 100 are {}\".format((df[df[\"sum\"] > 100].index).to_list()[-2:]))\n\n# Solution 2 using numpy\nrowsums = df1.apply(np.sum, axis=1)\n\n# last two rows with row sum greater than 100\nlast_two_rows = df1.iloc[np.where(rowsums > 100)[0][-2:], :]\nlast_two_rows","6e5c6553":"# input\nser = pd.Series(np.logspace(-2, 2, 30))\nser1 = ser.copy(deep = True)\nser2 = ser.copy(deep = True)","083bdbbc":"# Solution 1\n# get the quantiles values\nquantiles = np.quantile(ser, [0.05, 0.95])\nser\n\n# filter ser using numpy to know where the values are below or greater than 5% or 95% and replace the values\nser.iloc[np.where(ser < quantiles[0])] = quantiles[0]\nser.iloc[np.where(ser > quantiles[1])] = quantiles[1]\n    \n# or we can just do\nser1[ser1 < quantiles[0]] = quantiles[0]\nser1[ser1 > quantiles[1]] = quantiles[1]\n\nser1\n\n# Solution from the webpage\ndef cap_outliers(ser, low_perc, high_perc):\n    low, high = ser.quantile([low_perc, high_perc])\n    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n    ser[ser < low] = low\n    ser[ser > high] = high\n    return(ser)\n\ncapped_ser = cap_outliers(ser2, .05, .95)\nser2\ncapped_ser","f548c8b7":"# input\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))","bfd7aad7":"# Solution 1\ndf\ndf.iloc[df.index.to_list()[::-1]]\n\n# Solutions from the webpage\n# Solution 2\ndf.iloc[::-1, :]\n\n# Solution 3\nprint(df.loc[df.index[::-1], :])","53a10c29":"<a id = 'q3'><\/a>\n**3. How to get the items of series A not present in series B?**\n\nGet all items of ser1 and ser2 not common to both.\n\n[Go back to the table of contents](#table_of_contents)","00646935":"<a id = 'q5'><\/a>\n**5. How to get useful infos**\n\nCompute the minimum, 25th percentile, median, 75th, and maximum of ser.\n\n[Go back to the table of contents](#table_of_contents)","972465ec":"<a id = 'q9'><\/a>\n**9. How to extract items at given positions from a series**\n\nFrom ser, extract the items at positions in list pos.\n\n[Go back to the table of contents](#table_of_contents)","d17c8118":"<a id = 'q14'><\/a>\n\n**14. How to filter words that contain atleast 2 vowels from a series?**\n\nFrom ser, extract words that contain atleast 2 vowels.\n\n[Go back to the table of contents](#table_of_contents)","71a628be":"<a id = 'q20'><\/a>\n\n**20. How to change the order of columns of a dataframe?**\n\nActually 3 questions.\n\n1. In df, interchange columns 'a' and 'c'.\n\n2. Create a generic function to interchange two columns, without hardcoding column names.\n\n3. Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last.\n\n[Go back to the table of contents](#table_of_contents)\n","7f12a820":"<a id = 'q15'><\/a>\n\n**15. How to replace missing spaces in a string with the least frequent character?**\n\nReplace the spaces in my_str with the least frequent character.\n\n[Go back to the table of contents](#table_of_contents)","7516352e":"# Welcome to this Kernel\n\n* This kernel is a compilation of 24 exercises with solutions from this webpage:\n\nhttps:\/\/www.machinelearningplus.com\/python\/101-pandas-exercises-python\/\n\n\n# Upvote if you found it useful\n","582fe931":"<a id = 'q13'><\/a>\n\n**13. How to convert a series of date-strings to a timeseries?**\n\n[Go back to the table of contents](#table_of_contents)","077afd53":"<a id = 'q1'><\/a>\n\n**1. How to create a series from a list, numpy array and dict?**\n\nCreate a pandas series from each of the items below: a list, numpy and a dictionary\n\n[Go back to the table of contents](#table_of_contents)","ecd873fc":"# Pandas exercise","914ea0a8":"### The End","02b6b0b5":"<a id='table_of_contents'><\/a>\n# Table of contents\n\n[1. How to create a series from a list, numpy array and dict?](#q1)\n\n[2. How to combine many series to form a dataframe?](#q2)\n\n[3. How to get the items of series A not present in series B?](#q3)\n\n[4. How to get the items not common to both series A and series B?](#q4)\n\n[5. How to get useful infos](#q5)\n\n[6. How to get frequency counts of unique items of a series?](#q6)\n\n[7. How to convert a numpy array to a dataframe of given shape? (L1)](#q7)\n\n[8. How to find the positions of numbers that are multiples of 3 from a series?](#q8)\n\n[9. How to extract items at given positions from a series?](#q9)\n\n[10. How to stack two series vertically and horizontally ?](#q10)\n\n[11. How to get the positions of items of series A in another series B?](#q11)\n\n[12. How to compute difference of differences between consequtive numbers of a series?](#q12)\n\n[13. How to convert a series of date-strings to a timeseries?](#q13)\n\n[14. How to filter words that contain atleast 2 vowels from a series?](#q14)\n\n[15. How to replace missing spaces in a string with the least frequent character?](#q15)\n\n[16. How to change column values when importing csv to a dataframe?](#q16)\n\n[17. How to import only specified columns from a csv file?](#q17)\n\n[18. How to check if a dataframe has any missing values?](#q18)\n\n[19. How to replace missing values of multiple numeric columns with the mean?](#q19)\n\n[20. How to change the order of columns of a dataframe?](#q20)\n\n[21. How to filter every nth row in a dataframe?](#q21)\n\n[22. How to get the last n rows of a dataframe with row sum > 100?](#q22)\n\n[23. How to find and cap outliers from a series or dataframe column?](#q23)\n\n[24. How to reverse the rows of a dataframe?](#q24)\n","9e7b1b8e":"<a id = 'q19'><\/a>\n\n**19. How to replace missing values of multiple numeric columns with the mean?**\n\nReplace missing values in Luggage.room columns with their respective mean.\n\n[Go back to the table of contents](#table_of_contents)\n","5165028b":"<a id = 'q6'><\/a>\n**6. How to get frequency counts of unique items of a series?**\n\nCalculate the frequency counts of each unique value ser.\n\n[Go back to the table of contents](#table_of_contents)","272b2749":"<a id = 'q12'><\/a>\n**12. How to compute difference of differences between consequtive numbers of a series?**\n\nDifference of differences between the consequtive numbers of ser.\n\n[Go back to the table of contents](#table_of_contents)","d88b0b06":"<a id = 'q11'><\/a>\n**11. How to get the positions of items of series A in another series B?**\n\nGet the positions of items of ser2 in ser1 as a list.\n\n[Go back to the table of contents](#table_of_contents)","a24be3ca":"\n<a id = 'q23'><\/a>\n\n**23. How to find and cap outliers from a series or dataframe column?**\n\nReplace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value.\n\n[Go back to the table of contents](#table_of_contents)\n\n\n\n","914f307f":"<a id = 'q18'><\/a>\n\n**18. How to check if a dataframe has any missing values?**\n\n[Go back to the table of contents](#table_of_contents)\n","dfa228af":"<a id = 'q4'><\/a>\n**4. How to get the items not common to both series A and series B?**\n\nGet all items of ser1 and ser2 not common to both.\n\n[Go back to the table of contents](#table_of_contents)","32b4565b":"****\n<a id = 'q24'><\/a>\n\n**24. How to reverse the rows of a dataframe?**\n\nReverse all the rows of dataframe df.\n\n[Go back to the table of contents](#table_of_contents)\n\n","86617be9":"<a id = 'q16'><\/a>\n\n**16. How to change column values when importing csv to a dataframe?**\n\nImport the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes \u2018Low\u2019 and > 25 becomes \u2018High\u2019.\n\n[Go back to the table of contents](#table_of_contents)","1283b9be":"\n<a id = 'q22'><\/a>\n\n**22. How to get the last n rows of a dataframe with row sum > 100?**\n\nGet the last two rows of df whose row sum is greater than 100.\n\n[Go back to the table of contents](#table_of_contents)\n\n\n\n","fdbfafb5":"<a id = 'q21'><\/a>\n\n**21. How to filter every nth row in a dataframe?**\n\nFrom df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n\n[Go back to the table of contents](#table_of_contents)\n","428af552":"<a id = 'q10'><\/a>\n\n**10. How to stack two series vertically and horizontally ?**\n\nStack ser1 and ser2 vertically and horizontally (to form a dataframe).\n\n[Go back to the table of contents](#table_of_contents)","08dfa7a0":"<a id = 'q7'><\/a>\n**7. How to convert a numpy array to a dataframe of given shape? (L1)**\n\nReshape the series ser into a dataframe with 7 rows and 5 columns\n\n[Go back to the table of contents](#table_of_contents)","d0dda2b9":"<a id = 'q8'><\/a>\n**8. How to find the positions of numbers that are multiples of 3 from a series?**\n\nFind the positions of numbers that are multiples of 3 from ser.\n\n[Go back to the table of contents](#table_of_contents)","4d909697":"<a id = 'q2'><\/a>\n**2. How to combine many series to form a dataframe?**\n\nCombine ser1 and ser2 to form a dataframe.\n\n[Go back to the table of contents](#table_of_contents)","8010c291":"<a id = 'q17'><\/a>\n\n**17. How to import only specified columns from a csv file?**\n\n[Go back to the table of contents](#table_of_contents)"}}