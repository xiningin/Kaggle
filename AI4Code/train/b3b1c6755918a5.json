{"cell_type":{"5b4378b3":"code","0b1491f1":"code","9bc96a64":"code","c5b05049":"code","35474f7a":"code","84f5f375":"code","9eed032e":"code","510ee7de":"code","90fbc444":"code","e63a5c0d":"code","3ba38c9c":"code","2686624c":"code","697ddb2b":"code","c1982119":"code","1e308b27":"code","238e6865":"code","e04fe2b9":"code","71d5fa3f":"code","87a82f1f":"code","e2978000":"code","ba6a8d0d":"code","e3b0e5cb":"code","e38636f2":"code","8f84ef7c":"code","a26b02db":"code","fa5f7365":"code","c6e97c24":"code","c7b3029f":"code","7ac1a9f9":"code","d6b96cad":"markdown","053faa94":"markdown","f7f3ecdb":"markdown","a0a51d31":"markdown","e6442a03":"markdown","29638ca3":"markdown","185ff894":"markdown"},"source":{"5b4378b3":"#import necessary package\n#for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# for EDA visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom matplotlib import gridspec\n\nimport warnings\nwarnings.filterwarnings('ignore')","0b1491f1":"# read data\ndf = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","9bc96a64":"#preview data\ndf.head()","c5b05049":"df.describe()","35474f7a":"#I will not use cabin feature. so I willdrop the column\ndf = df.drop(columns=['Cabin'])","84f5f375":"df.isnull().sum()","9eed032e":"# So I will use iterpolate for handling the null value\ndf = df.interpolate(method='nearest', limit_direction='forward')\ndf.isnull().sum().sum()","510ee7de":"#still got null value. But since only 2 data. I will drop it\ndf = df.dropna()\ndf.isnull().sum().sum()","90fbc444":"# Styling:\n''' Use Pallete > 2 for jointplot or pair plot '''\ncustom_palet1 = ['#111d5e', '#1E6262', '#E50058', '#FF740F', '#F64662']\ncustom_palet2 = ['#11364A', '#E84545', '#3F7B70', '#ffbd69', '#ffc93c']\ncustom_palet3 = ['#11364A', '#E84545']\ncustom_palet4 = ['#3F7B70', '#F64662']\ncustom_palet5 = [\"#868686\", \"#477ccd\"]\n\nplt.style.use('ggplot')","e63a5c0d":"#Check the unique value for each columns\ndf.nunique()","3ba38c9c":"#renaming columns for better understanding\ndf.columns = [\n    'Passenger_ID', 'Survival_Status','Sosio_Class',\n    'Name','Gender','Age','Sibling_Spouse_Relation',\n    'Parent_Child_Relation','Ticket_Number','Fare','Port_Embarked']","2686624c":"# map data also kinda for better visualization understanding\ndf['Survival_Status'] = df['Survival_Status'].map({0: 'Not_Survived', 1: 'Survived'})\n\ndf['Sosio_Class'] = df['Sosio_Class'].map({1: 'Upper_Class', 2: 'Middle_Class', 3: 'Lower_Class'})\n\ndf['Port_Embarked'] = df['Port_Embarked'].map({'C': 'Cherboug', 'Q': 'Queesntown', 'S':'Southhampton'})","697ddb2b":"# Group data by continuous or categorical dataset for better selection\ncategorical = [i for i in df.loc[:, df.nunique()<= 10]]\ncontinuous = [i for i in df.loc[:, df.nunique()>=10]]","c1982119":"def categorical_distribution(data, cols, hue=None, rows=3, columns=2, palette=custom_palet1):\n\n    '''Function for displaying categorical Distribution'''\n\n    fig, axes = plt.subplots(rows, columns, figsize=(15, 12))\n    fig.patch.set_facecolor('#e8e8e6')\n    axes = axes.flatten()\n\n    for i, j in zip(data[cols].columns, axes):\n        sns.countplot(x=i,\n        data=data,\n        palette=palette,\n        hue=hue,\n        ax=j,\n        order=data[i].value_counts().index)\n\n        total = float(len(data[i]))\n        j.set_title(f'Distribution of {str(i)}')\n\n        for p in j.patches:\n            height = p.get_height()\n            j.text(p.get_x() + p.get_width() \/ 2. , height+2, '{:1.2f}%'. format((height\/ total)*100), ha = 'center')\n\n        plt.style.use('seaborn-dark-palette')\n        plt.tight_layout()","1e308b27":"categorical_distribution(df, categorical)","238e6865":"categorical_distribution(df, categorical[1:], 'Survival_Status', palette=custom_palet2 )","e04fe2b9":"# Displaying continuous Data distributions:\nfig = plt.figure(constrained_layout= True, figsize = (15,4))\ngrid = gridspec.GridSpec(ncols=6, nrows=1, figure=fig)\n\nax1 = fig.add_subplot(grid[0, :2])\nax1.set_title(' Passenger Age Distribution')\nsns.distplot(\n    df['Age'],\n    hist_kws ={\n        'rwidth':1,\n        'edgecolor': '#11364A',\n        'alpha': 0.9},\n    kde_kws={\n        \"linestyle\":'solid',\n        'color':custom_palet2[3]},\n    color = custom_palet2[1]\n        )\nax11 = fig.add_subplot(grid[0, 2:3])\nax11.set_title('Passenger Age')\nsns.boxplot(df['Age'], orient='v', color= custom_palet2[1])\n\nax2 = fig.add_subplot(grid[0, 3:5])\nax2.set_title(' Passenger Fare Distribution')\nsns.distplot(\n    df['Fare'],\n    hist_kws ={\n        'rwidth':1,\n        'edgecolor': '#11364A',\n        'alpha': 1},\n    kde_kws={\n        \"linestyle\":'solid',\n        'color':custom_palet2[1]},\n    color = custom_palet2[3]\n        )\nax22 = fig.add_subplot(grid[0, 5:])\nax22.set_title('Passenger Fare')\nsns.boxplot(df['Fare'], orient='any', color= custom_palet2[3])","71d5fa3f":"sns.jointplot(data=df, x=\"Age\", y=\"Fare\", hue=\"Survival_Status\", palette=custom_palet4)","87a82f1f":"# import necesssary packages\n# data preprocessing- splitting\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# model build\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#result evaluation\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import mean_absolute_error","e2978000":"model_list = [\n    SVC(),\n    GaussianNB(),\n    LinearRegression(),\n    LogisticRegression(),\n    DecisionTreeClassifier(class_weight='balanced'),\n    RandomForestClassifier(n_estimators=45)\n]","ba6a8d0d":"newTrainData = pd.DataFrame( df, columns=['Age','Gender','Sosio_Class','Fare','Survival_Status'])\nnewTrainData.head()","e3b0e5cb":"# re-map data also for processing\nnewTrainData['Gender'] = newTrainData['Gender'].map({'male': 0, 'female': 1})\n\nnewTrainData['Survival_Status'] = newTrainData['Survival_Status'].map({'Not_Survived': 0, 'Survived': 1})\n\nnewTrainData['Sosio_Class'] = newTrainData['Sosio_Class'].map({'Upper_Class': 1, 'Middle_Class': 2, 'Lower_Class': 3})","e38636f2":"# splitting them\ndataset = newTrainData.values\nfeature, target = dataset[:,:-1], dataset [:, -1]\n","8f84ef7c":"x_train,x_test, y_train, y_test = train_test_split(feature, target, random_state=48, test_size=0.3)","a26b02db":"def thresholding(y_pred):\n        \n    ''' This method will transform The continuous list into discrete 0 and 1 based on the mean value '''\n\n    data = np.array(y_pred)\n    mean = data.mean()\n    new_pred = []\n    for y in data:\n        if y >= mean:\n            y = 1\n            new_pred.append(y)\n        elif y < mean:\n            y = 0\n            new_pred.append(y)\n            \n    return new_pred\n\n\ndef get_Score(model_list, x_train, x_test, y_train, y_test):\n    result = []\n    for model in model_list:\n        model.fit(x_train,y_train)\n        gen_score = model.score(x_test,y_test)\n        y_pred = thresholding(model.predict(x_test))\n        \n        score_r2 = r2_score(y_test,y_pred)\n        mae_score = mean_absolute_error(y_test,y_pred)\n        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n        auc_score = auc(fpr,tpr)\n        score_f1 = f1_score(y_test, y_pred)\n        score_jaccard = jaccard_score(y_test, y_pred)\n        \n        result.append([str(model),gen_score,score_r2,mae_score, auc_score, score_f1,score_jaccard])\n        \n    return result","fa5f7365":"evaluationTable =pd.DataFrame(get_Score(model_list, x_train, x_test, y_train, y_test), \\\n columns=['Model', 'Score', 'R2_Score','MAE_Score','AUC_Score','F1_Score','Jaccard Similarity'])\nevaluationTable","c6e97c24":"# initialize K-Fold\nNSPLIT = 5\nkf = KFold(n_splits=NSPLIT, random_state=48, shuffle=True)","c7b3029f":"def get_Score(model, x_train, x_test, y_train, y_test):\n    model.fit(x_train, y_train)\n    return model.score(x_test, y_test)\n\n\ndef get_KFold_Score(model_list, feature):\n    output = [[model] + [get_Score(model, feature[train_index], feature[test_index], target[train_index], target[test_index]) for train_index, test_index in kf.split(feature)] for model in model_list]\n\n    return output","7ac1a9f9":"KFold_Score = pd.DataFrame(get_KFold_Score(model_list,feature), columns= ['Model', 'iter1', 'iter2', 'iter3', 'iter4', 'iter5'])\n\nfor i, row in KFold_Score.iterrows():\n    KFold_Score.loc[i, 'Average Score'] = (row['iter1']+row['iter2']+row['iter3']+row['iter4']+row['iter5'])\/NSPLIT\n\nKFold_Score.head()","d6b96cad":"Okay, finished with the EDA. Now lets proceed with ML prediction Analysis\n\n---\n# ML Prediction Analysis\n---","053faa94":"---\n## Simple Exploratory Data Analysis- EDA\n---","f7f3ecdb":"since the feature that I will be using is 'Age', 'Gender', 'Sosio_Class','Fare'  and 'Survival Status'. So I will make new dataset","a0a51d31":"#### Then, Now I will be using simple K-Fold","e6442a03":"---\n### This is it for now","29638ca3":"## This notebook was for my Machine Learning practice\n---\n\n I refer a lot from his notebooks. --> https:\/\/www.kaggle.com\/datafan07 ","185ff894":"#### 1st I will be using simple train_test_split"}}