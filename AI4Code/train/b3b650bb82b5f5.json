{"cell_type":{"9bd562f8":"code","189feaeb":"code","686aa71a":"code","49893e22":"code","87c0facf":"code","67c308ff":"markdown","bbf40154":"markdown","3f5fce3f":"markdown","e801a993":"markdown","5d97e8b5":"markdown","730db043":"markdown","9acd1b74":"markdown"},"source":{"9bd562f8":"from google.cloud import bigquery\nfrom bq_helper import BigQueryHelper\nimport pandas as pd\n\nbq_assistant = BigQueryHelper(\"bigquery-public-data\", \"ethereum_blockchain\")\nclient = bigquery.Client()\n\nmin_block_number = 5100000\nmax_block_number = 6400000\n\n# find average values and sort\nquery = \"\"\"\nSELECT\n  address, SUM(n_updates) AS updates\nFROM\n(\n  SELECT\n      address, COUNT(*) AS n_updates\n  FROM\n  (\n  SELECT DISTINCT\n    from_address AS address, block_number AS block_number\n  FROM\n    `bigquery-public-data.ethereum_blockchain.transactions`\n  WHERE\n    block_number > %d\n    AND\n    block_number < %d\n  )\n  GROUP BY \n    address\n\n  UNION ALL\n\n  SELECT \n      address AS address, COUNT(*) AS n_updates\n  FROM\n  (\n  SELECT DISTINCT\n    to_address AS address, block_number AS block_number\n  FROM\n    `bigquery-public-data.ethereum_blockchain.transactions`\n  WHERE\n    block_number > %d\n    AND\n    block_number < %d\n  )\n  GROUP BY \n    address\n)\nWHERE\n  n_updates >= 5\n  AND\n  address IS NOT NULL\nGROUP BY \n  address\nORDER BY \n  updates DESC\n\"\"\"\n\nmost_populars = bq_assistant.query_to_pandas_safe(query % (min_block_number, max_block_number, min_block_number, max_block_number), max_gb_scanned=40)\nprint(\"Retrieved \" + str(len(most_populars)) + \" accounts.\")\nblocks_int = max_block_number - min_block_number\nmost_populars = most_populars.sort_values(by='updates', ascending=False)\nmost_populars[\"probability\"] = most_populars[\"updates\"] \/ (blocks_int*1.0)\nprint(most_populars.head(10))","189feaeb":"from scipy.optimize import curve_fit\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef func_powerlaw(x, m, c, c0):\n    return c0 + x**m * c\n\nblocks_int = max_block_number - min_block_number\n\n# Compute probabilities\nmost_populars[\"probability\"] = most_populars[\"updates\"] \/ (blocks_int*1.0)\nmost_populars[\"idxs\"] = range(1, len(most_populars) + 1)\n\n# Fit curve\nsol = curve_fit(func_powerlaw, most_populars[\"idxs\"], most_populars[\"probability\"], p0 = np.asarray([float(-1),float(10**5),0]))\nfitted_func = func_powerlaw(most_populars[\"idxs\"], sol[0][0], sol[0][1], sol[0][2])\nprint(\"Fit with values {} {} {}\".format(sol[0][0], sol[0][1], sol[0][2]))\n\n# Plot fit vs samples (only for the first 2000)\nplt.rcParams.update({'font.size': 20})\nplt.figure(figsize=(10,5))\nplt.loglog(most_populars[\"probability\"].tolist()[1:10000],'o')\nplt.loglog(fitted_func.tolist()[1:10000])\nplt.xlabel(\"Account index (by descending popularity)\")\nplt.ylabel(\"Relative frequency [1\/block]\")\nplt.show()","686aa71a":"query = \"\"\"\nSELECT \n      timestamp, number\n    FROM\n      `bigquery-public-data.ethereum_blockchain.blocks`\nINNER JOIN \n(\n    SELECT DISTINCT\n              from_address AS address, block_number AS block_number\n            FROM\n              `bigquery-public-data.ethereum_blockchain.transactions`\n            WHERE\n              from_address = '%s'\n              AND\n              block_number > %d\n              AND\n              block_number < %d\n\n    UNION DISTINCT\n\n    SELECT DISTINCT\n              to_address AS address, block_number AS block_number\n            FROM\n              `bigquery-public-data.ethereum_blockchain.transactions`\n            WHERE\n              to_address = '%s'\n              AND\n              block_number > %d\n              AND\n              block_number < %d\n) as InnerTable\nON \n    `bigquery-public-data.ethereum_blockchain.blocks`.number = InnerTable.block_number;\n\"\"\"\n\n# CryptoKitties address\nadx_1 = most_populars.iloc[4].address \ntransax_1 = bq_assistant.query_to_pandas_safe(query % (adx_1, min_block_number, max_block_number, adx_1, min_block_number, max_block_number), max_gb_scanned=40)\nprint(\"Retrieved \" + str(len(transax_1)) + \" blocks for account %s.\" % (adx_1) )\ntransax_1.sort_values(by=\"number\", ascending=True, inplace=True)\n    \n# Bittrex address    \nadx_2 = most_populars.iloc[3].address \ntransax_2 = bq_assistant.query_to_pandas_safe(query % (adx_2, min_block_number, max_block_number, adx_2, min_block_number, max_block_number), max_gb_scanned=40)\nprint(\"Retrieved \" + str(len(transax_2)) + \" blocks for account %s.\" % (adx_2) )\ntransax_2.sort_values(by=\"number\", ascending=True, inplace=True)\n    \ntransax = list()\ntransax.append(transax_1)\ntransax.append(transax_2)","49893e22":"# plot the Empirical CDF\nplt.figure(figsize=(15,5))\nfor t in transax:\n    t.sort_values(by=\"number\", inplace=True)\n    tx_d = t.diff()\n    tx_d = tx_d.iloc[1:]\n    count = np.sort(tx_d[\"number\"].values)\n    cdf = np.arange(len(count)+1)\/float(len(count))\n    plt.plot(count, cdf[:-1])\n\nplt.axis([0, 20, 0, 1])\nplt.xlabel(\"Number of blocks without updates [n]\")\nplt.ylabel(\"Empirical CDF ( Pr[x <= n] )\")\nplt.show()","87c0facf":"# activity during time\ntxp_1 = transax_1[\"timestamp\"].groupby(transax_1[\"timestamp\"].dt.floor('d')).size().reset_index(name='CryptoKitties')\ntxp_2 = transax_2[\"timestamp\"].groupby(transax_2[\"timestamp\"].dt.floor('d')).size().reset_index(name='Bittrex')\ntxp_1 = txp_1[10:-10]\ntxp_2 = txp_2[10:-10]\n\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 8))\nax = txp_1.plot(x=\"timestamp\", y=\"CryptoKitties\", ax=ax)\nax = txp_2.plot(x=\"timestamp\", y=\"Bittrex\", ax=ax)\nplt.ylabel(\"Active blocks\/day\")\n\n# patterns\nf = plt.figure(figsize=(15,5))\nax = f.add_subplot(121)\nax2 = f.add_subplot(122)\n\nplt.subplot(1, 2, 1)\ntxp_1 = transax_1[\"timestamp\"].groupby(transax_1[\"timestamp\"].dt.day_name()).count().sort_values()\ntxp_1 \/= sum(txp_1)\ntxp_1.plot(kind=\"bar\", ax=ax)\nplt.xlabel(\"Day of the week\")\nplt.ylabel(\"Normalized count\")\nplt.title(\"CryptoKitties\")\n\nplt.subplot(1, 2, 2)\ntxp_2 = transax_2[\"timestamp\"].groupby(transax_2[\"timestamp\"].dt.day_name()).count().sort_values()\ntxp_2 \/= sum(txp_2)\ntxp_2.plot(kind=\"bar\", ax=ax2)\nplt.xlabel(\"Day of the week\")\nplt.ylabel(\"Normalized count\")\nplt.title(\"Bittrex\")","67c308ff":"**Conclusion**\n\n* We have introduced some basic tools that can be used for the statistical characterization of blockchain updates. \n* Besides the study of economic\/human interactions that happen on chain, the characterization allows to model the data flow generated by blockchain software. This is a valuable information for the management of the IT infrastructures.\n* We have extracted one feature (\"an account is modified (or not) in a block\"), because it was the simplest approach, but we can extend this kernel by distinguishing between transactions from\/to the account, and their cardinality.","bbf40154":"From the results, it is possible to extract several interesting statistics. For example, the cumulative density function (CDF) of number of blocks between two consecutive updates to the account. The knowledge of the CDF is important to design and evaluate the performances of blockchain lightweight protocols. For example, we can decide to sync our blockchain client periodically, and tune the period based on the statistics of the account that we are interested in.","3f5fce3f":"Ok, we obtained the list of most popular addresses and printed the **top ten**. A quick check of the addresses on a blockchain explorer (https:\/\/etherscan.io\/) tells us that they are all associated with currency exchanges or popular decentralized applications (**dApps**). We might expect that the accounts follow a power-law, where the most \"active\" accounts are owned by centralized exchanges. Is it true?","e801a993":"We can also look for specific activity patterns. For example, in the figure below we show that, even if the two accounts show the same relative frequency *on average*, their activity is not stationary.\n\nOther question: on which **day of the week** are the two accounts more active? The bar figures show that CryptoKitties, that is a game, is particularly used during the weekends. On the other hand, Bittrex is active on Mondays and Tuesdays and on Friday, that is quite expected for a trading platform.","5d97e8b5":"**Statistics of specific accounts**\n\nWe can also observe the activity of specific accounts. For example, the following query returns the block numbers (and their timestamp) at which an account has been modified. We apply it to two addresses: one associated with [CryptoKitties](https:\/\/www.cryptokitties.co\/) dApp, and one with [Bittrex](https:\/\/bittrex.com\/) exchange, that are characterized by similar relative frequency of updates.","730db043":"We plot the relative frequency of accounts that are modified at least once per hour (there are approximately 10k of them in the main network).\nTheir relative frequency doesn't follow a \"simple\" power-law, because the 20 most popular accounts have \"equal power\", i.e. they show similar activity. A *broken* power-law would be more appropriate, as we have observed in a [recent paper](https:\/\/arxiv.org\/pdf\/1807.07422.pdf). In that document, you can find more insights about how to use the statistics of accounts to design better protocols.","9acd1b74":"We show how to extract meaningful statistics of accounts of the Ethereum main network, from the data set hosted by Google BigQuery. \n\n**Active accounts**\n\nFirst, we find which accounts are more active, by searching for the probability that an account is modified in a generic block (we don't distinguish between transactions from\/to its address). This is an index of the accounts' **activity**.\n\nTo find the most popular accounts, I wrote the following query (1).  The number of addresses in Ethereum main network is becoming quite large, hence we filter out those that are rarely updated (they have been part of less than 5 transactions). Moreover, we limit the study to a range of blocks after the \"explosion\" of the **crypto bubble** (blocks between min_block_number and max_block_number).\n\nAs suggested [here](https:\/\/www.kaggle.com\/mrisdal\/visualizing-average-ether-costs-over-time?utm_medium=partner&utm_source=cloud&utm_campaign=big+data+blog+ethereum), we set a safety limit to control the quota of free queries provided by Kaggle. For this kernel, you will read a maximim of 120 GB from BigQuery. As the database size is constantly increasing, in the future you will incur in a error, if the amount of scanned data is greater than max_gb_scanned=40."}}