{"cell_type":{"19c0564d":"code","e22807ac":"code","5f7689fb":"code","a483fd4f":"code","fdca40b6":"code","1e3a7d43":"code","f5d4d9c6":"code","d1c91f7e":"code","cea8d4dc":"code","f7a654b5":"code","3531ce99":"code","a8db8997":"code","facde03f":"code","5ce12443":"code","ca313719":"code","877f8cf7":"code","a0b14db1":"markdown","41de7c31":"markdown","7241ea9f":"markdown","b258d92e":"markdown","8d887e2d":"markdown","dc199484":"markdown"},"source":{"19c0564d":"# TensorFlow and tf.keras\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image, ImageDraw\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Image Selection\nimport os,cv2\n\nimport math","e22807ac":"train_dir = '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_long\/train_images'\ntest_dir = '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_long\/test_images'\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(36, 36),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=42,\n    subset='training'\n)","5f7689fb":"validation_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(36, 36),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","a483fd4f":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_dir,\n    target_size=(36, 36),\n    class_mode=\"binary\",\n    color_mode=\"grayscale\",\n)","fdca40b6":"model = models.Sequential()\n#model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(36, 36, 1)))\n#model.add(layers.MaxPooling2D((2, 2)))\n#model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n#model.add(layers.MaxPooling2D((2, 2)))\n#model.add(layers.Flatten())\n#model.add(layers.Dense(120, activation='relu'))\n#model.add(layers.Dense(60, activation='relu'))\n#model.add(layers.Dense(10))\n\nmodel.add(keras.layers.Conv2D(6, (5, 5), activation='relu', input_shape=(36, 36, 1)))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\nmodel.add(keras.layers.Conv2D(16, (5, 5), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(16, activation='relu'))\nmodel.add(keras.layers.Dense(2, activation='softmax'))\nmodel.compile(optimizer=keras.optimizers.Adam(),\n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\nmodel.summary()","1e3a7d43":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                    validation_data=validation_generator,\n                    epochs=10\n)","f5d4d9c6":"model.evaluate(test_generator)","d1c91f7e":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","cea8d4dc":"image2 = '\/kaggle\/input\/testpredict\/TestPredict2.png'\n\ntest_image= image.load_img(image2, color_mode=\"grayscale\", target_size=(36,36)) \ntest_image = image.img_to_array(test_image)\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = model.predict_classes(test_image)  \nprint(result)","f7a654b5":"result2 = model.predict(test_image)  \nprint(result2)","3531ce99":"close_dist = 20","a8db8997":"def calc_dist(box1, box2):\n    return math.sqrt(((box1[0]-box2[0])**2) + ((box1[1]-box2[1])**2) )\n\n# common version\ndef should_merge(box1, box2):\n    if(calc_dist(box1,box2) <= close_dist):\n        return True, [min(box1[0], box2[0]), min(box1[1], box2[1]), max(box1[2], box2[2]),\n                                  max(box1[3], box2[3])]\n    return False, None","facde03f":"def proba (x, y, img, model):\n    img_crop = img.crop((x, y, x+36, y+36))\n    \n    img_crop = image.img_to_array(img_crop)\/255\n    img_crop = np.expand_dims(img_crop, axis = 0)\n\n    proba=model.predict(img_crop)\n    \n    return proba[0][1]\n    ","5ce12443":"#fill proba table\nimg = '\/kaggle\/input\/testpredict\/237px-SmallFaces1966_SmallVersion.png'\nim = image.load_img(img, color_mode=\"grayscale\")\nisize=im.size\nboxes = []\nprint('Boxes', len(boxes))\n\nfor x in range (isize [0]-36 ):\n    print(x)\n    for y in range (isize [1]-36 ):\n        probas= proba (x, y, im, model)\n        \n        if (probas>0.9):\n            new_box= [x, y, x+36, y+36]\n            is_merge= False\n            box_merge = None\n            i=0\n            while ((not is_merge) & (i<len(boxes))):\n                is_merge, box_merge = should_merge(boxes[i], new_box)\n                if is_merge:\n                    boxes[i]= box_merge\n                i=i+1    \n            if not is_merge:\n                boxes.append(new_box)\n                print('Boxes', len(boxes))    ","ca313719":"draw = ImageDraw.Draw (im)\nfor i in range(len(boxes)):\n    draw.rectangle ( boxes[i] , outline = 'red')\nim.save ('out_smallfaces.png')","877f8cf7":"model.save_weights('my_checkpoint')","a0b14db1":"**EVALUATION**","41de7c31":"**LIBRARY**","7241ea9f":"**TRAINING**","b258d92e":"**LOAD DATA**","8d887e2d":"**AMELIORATION**\nAmelioration de la performance du classifieur : cela se fait en cherchant une architecture plus\nefficace et plus performant du CNN, et en augmentant la base d\u2019apprentissage. Il y a beaucoup de\nressources sur Internet avec des images de visages. Par exemple :\n\n\u2014 https:\/\/facedetection.com\/datasets\n\n\u2014 http:\/\/www.face-rec.org\/databases\/\n\n\u2014 http:\/\/www.cbsr.ia.ac.cn\/english\/CASIA-WebFace-Database.html\n\n\u2014 http:\/\/www.vision.caltech.edu\/Image Datasets\/Caltech 10K WebFaces\/\n\n\u2014 http:\/\/lrs.icg.tugraz.at\/research\/aflw\/\n\nNous disposons de certaines bases que nous pouvons vous fournir directement.\n\n***Ameliorations algorithmiques*** : vous pouvez travailler sur l\u2019optimisation du d\u00b4etecteur en terme\nde temps de calcul. La suppression de la redondance mentionne dans la section 6 est une premiere\npiste. Et un certain nombre de choses pourraient etre parallelisees (avec l\u2019utilisation de GPU et\/ou\nplusieurs c\u0153urs de CPU). Faites des mesures de temps et\/ou du \u226a profiling \u226b pour comparer.\n\n***Extension multi-vues*** : vous pouvez apprendre un CNN qui estime non seulement la pr\u00b4esence ou\nnon d\u2019un visage mais aussi son orientation. Par exemple, il peut y avoir six classes : non-visage, profil\ngauche, semi-profil gauche, frontal, semi-profil droit, profil droit. Ou deux modeles, le premier qui\ndetecte le visage, et le deuxieme son orientation. Il faut des images annotees, bien entendu.\n\n***Extension multi-modale*** : jusqu\u2019ici nous avons seulement traite des images en niveaux de gris.\nRien nous empeche d\u2019utiliser les images en couleur. Il faut donc cr\u00b4eer un ensemble d\u2019apprentissage\nen couleur et modifier l\u2019architecture du CNN pour prendre les 3 canaux en entree. Une autre idee et\nd\u2019utiliser des videos, donc des sequences d\u2019images.\n\n***Extraction d\u2019autres informations*** : l\u2019estimation de la pose de la tete mentionn\u00b4e ci-dessus est une\ninformation qui peut etre interessante. Mais on peut aussi s\u2019interesser au genre, par exemple, aux\ncaracteristiques du visage (pr\u00b4esence de lunettes, barbes etc.), ou reconna\u0131tre des expressions faciales\n(par exemple le sourire). Enfin, on peut apprendre l\u2019identite de la personne et ainsi creer un systeme\nde reconnaissance faciale avec un nombre limite de personnes (monde ferme).","dc199484":"**MODEL**\n\n*Simple CNN Model*"}}