{"cell_type":{"c15d077d":"code","73624fe1":"code","e71d7573":"code","fe02eb7c":"code","50722025":"code","22088df7":"code","042bff12":"code","c37d7338":"code","304be3cf":"code","86edf22e":"code","e857c89c":"code","ea70344c":"code","a9c59c83":"code","e4ad78c1":"code","6fa2175e":"code","5c3d5e5f":"code","f07a39ee":"code","ced22d50":"markdown","2ac4cfea":"markdown","63465658":"markdown","5689cf8f":"markdown","343112c8":"markdown","b5afbd17":"markdown","70236b37":"markdown","f8812d99":"markdown","621386f6":"markdown","1987301b":"markdown","adfd47c6":"markdown"},"source":{"c15d077d":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\nimport copy \n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n\n\nimport pytorch_lightning as pl \nfrom pytorch_lightning import seed_everything\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import roc_auc_score","73624fe1":"os.environ['CUDA_LAUNCH_BLOCKING'] = '1'","e71d7573":"class config:\n        TRAIN_FILE = '..\/input\/assist-preprocess\/skillbuilder12clean.csv'\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n        NROWS = 3000000\n        MAX_SEQ = 100 \n        \n        # Configuration Training\n        MAX_EPOCHS = 100\n        BATCH_SIZE = 128\n        \n        # Dropout of final FFN\n        DROPOUT = 0.1\n        \n        # Configuration Multihead\n        EMBED_DIMS = 512 \n        ENC_HEADS = DEC_HEADS = 8\n        NUM_ENCODER = NUM_DECODER = 4\n        \n        # Number of exercises and categories of exercise to encode\n        TOTAL_EXE = 179999\n        TOTAL_CAT = 267\n        \n        \n        # Configuration Optimiser\n        LEARNING_RATE = 0.001\n        \n        # Configuration EarlyStop\n        EARLY_STOP_MIN_DELTA = 0.0\n        EARLY_STOP_PATIENCE = 10\n        ","fe02eb7c":"class DKTDataset(Dataset):\n    def __init__(self,samples,max_seq,start_token=0): \n        super().__init__()\n        self.samples = samples\n        self.max_seq = max_seq\n        self.start_token = start_token\n        self.data = []\n        for id in self.samples.index:\n            exe_ids,answers,categories = self.samples[id]\n            if len(exe_ids)>max_seq:\n                for l in range((len(exe_ids)+max_seq-1)\/\/max_seq):\n                    self.data.append((exe_ids[l:l+max_seq],answers[l:l+max_seq],categories[l:l+max_seq]))\n            elif len(exe_ids)<self.max_seq and len(exe_ids)>10:\n                self.data.append((exe_ids,answers,categories))\n            else :\n                continue\n\n    def __len__(self):\n        return len(self.data)\n  \n    def __getitem__(self,idx):\n        question_ids,answers,exe_category = self.data[idx]\n        seq_len = len(question_ids)\n\n        exe_ids = np.zeros(self.max_seq,dtype=int)\n        ans = np.zeros(self.max_seq,dtype=int)\n        exe_cat = np.zeros(self.max_seq,dtype=int)\n        if seq_len<self.max_seq:\n            exe_ids[-seq_len:] = question_ids\n            ans[-seq_len:] = answers\n            exe_cat[-seq_len:] = exe_category\n        else:\n            exe_ids[:] = question_ids[-self.max_seq:]\n            ans[:] = answers[-self.max_seq:]\n            exe_cat[:] = exe_category[-self.max_seq:]\n\n        input = {\"input_ids\":exe_ids,\"input_cat\":exe_cat}\n        answers = np.append([0],ans[:-1]) #start token\n        assert ans.shape[0]==answers.shape[0] #\"both ans and label should be same len with start-token\"\n        return input,answers,ans\n","50722025":"class FFN(nn.Module):\n    def __init__(self,in_feat):\n        super(FFN,self).__init__()\n        self.linear1 = nn.Linear(in_feat,in_feat)\n        self.linear2 = nn.Linear(in_feat,in_feat)\n        self.drop = nn.Dropout(config.DROPOUT)\n  \n    def forward(self,x):\n        out = F.relu(self.drop(self.linear1(x)))\n        out = self.linear2(out)\n        return out \n\n\nclass EncoderEmbedding(nn.Module):\n    def __init__(self,n_exercises,n_categories,n_dims,seq_len):\n        super(EncoderEmbedding,self).__init__()\n        self.n_dims = n_dims\n        self.seq_len = seq_len\n        self.exercise_embed = nn.Embedding(n_exercises,n_dims)\n        self.category_embed = nn.Embedding(n_categories,n_dims)\n        self.position_embed = nn.Embedding(seq_len,n_dims)\n\n    def forward(self,exercises,categories):\n        e = self.exercise_embed(exercises)\n        c = self.category_embed(categories)\n        seq = torch.arange(self.seq_len,device=config.device).unsqueeze(0)\n        p = self.position_embed(seq)\n        return p + c + e\n\nclass DecoderEmbedding(nn.Module):\n    def __init__(self,n_responses,n_dims,seq_len):\n        super(DecoderEmbedding,self).__init__()\n        self.n_dims = n_dims\n        self.seq_len = seq_len\n        self.response_embed = nn.Embedding(n_responses,n_dims)\n        self.position_embed = nn.Embedding(seq_len,n_dims)\n\n    def forward(self,responses):\n        e = self.response_embed(responses)\n        seq = torch.arange(self.seq_len,device=config.device).unsqueeze(0)\n        p = self.position_embed(seq)\n        return p + e \n\n\n# layers of encoders stacked onver, multiheads-block in each encoder is n.\n# Stacked N MultiheadAttentions \nclass StackedNMultiHeadAttention(nn.Module):\n    def __init__(self,n_stacks,n_dims,n_heads,seq_len,n_multihead=1,dropout=0.2):\n        super(StackedNMultiHeadAttention,self).__init__()\n        self.n_stacks = n_stacks\n        self.n_multihead = n_multihead\n        self.n_dims = n_dims \n        self.norm_layers = nn.LayerNorm(n_dims)\n        \n        #n_stacks has n_multiheads each\n        self.multihead_layers = nn.ModuleList(n_stacks*[nn.ModuleList(n_multihead*[nn.MultiheadAttention(embed_dim = n_dims,\n                                                          num_heads = n_heads,\n                                                            dropout = dropout),]),])\n        self.ffn = nn.ModuleList(n_stacks*[FFN(n_dims)])\n        self.mask = torch.triu(torch.ones(seq_len,seq_len),diagonal=1).to(dtype=torch.bool)\n  \n    def forward(self,input_q,input_k,input_v,encoder_output=None,break_layer=None):\n        for stack in range(self.n_stacks):\n            for multihead in range(self.n_multihead):\n                norm_q = self.norm_layers(input_q)\n                norm_k = self.norm_layers(input_k)\n                norm_v = self.norm_layers(input_v) \n                heads_output,_ = self.multihead_layers[stack][multihead](query=norm_q.permute(1,0,2),\n                                                                        key=norm_k.permute(1,0,2),\n                                                                        value=norm_v.permute(1,0,2),\n                                                                        attn_mask=self.mask.to(config.device))\n                heads_output = heads_output.permute(1,0,2)\n                #assert encoder_output != None and break_layer is not None     \n                if encoder_output != None and multihead == break_layer:\n                    assert break_layer <= multihead, \" break layer should be less than multihead layers and postive integer\"\n                    input_k = input_v = encoder_output\n                    input_q = input_q + heads_output\n                else:\n                    input_q = input_q + heads_output\n                    input_k = input_k + heads_output\n                    input_v = input_v + heads_output\n            last_norm = self.norm_layers(heads_output)\n            ffn_output = self.ffn[stack](last_norm)\n            ffn_output = ffn_output + heads_output # Skip connection?\n        return ffn_output\n","22088df7":"# Main model for training \nclass PlusSAINTModule(pl.LightningModule):\n    def __init__(self):\n        super(PlusSAINTModule,self).__init__()\n        self.loss = nn.BCEWithLogitsLoss()\n        self.encoder_layer = StackedNMultiHeadAttention(n_stacks=config.NUM_DECODER,\n                                                        n_dims=config.EMBED_DIMS,\n                                                        n_heads=config.DEC_HEADS,\n                                                        seq_len=config.MAX_SEQ,\n                                                        n_multihead=1,dropout=0.1)\n        self.decoder_layer = StackedNMultiHeadAttention(n_stacks=config.NUM_ENCODER,\n                                                        n_dims=config.EMBED_DIMS,\n                                                        n_heads=config.ENC_HEADS,\n                                                        seq_len=config.MAX_SEQ,\n                                                        n_multihead=2,dropout=0.1)\n        self.encoder_embedding = EncoderEmbedding(n_exercises=config.TOTAL_EXE,\n                                                  n_categories=config.TOTAL_CAT,\n                                                  n_dims=config.EMBED_DIMS,seq_len=config.MAX_SEQ)\n        self.decoder_embedding = DecoderEmbedding(n_responses=3,n_dims=config.EMBED_DIMS,seq_len=config.MAX_SEQ)\n        self.fc = nn.Linear(config.EMBED_DIMS,1)\n        self.hparams.learning_rate=config.LEARNING_RATE\n\n    #TODO: implement embdding layer and its output\n    def forward(self,x,y): \n        enc = self.encoder_embedding(exercises=x[\"input_ids\"].long().to(config.device),categories=x['input_cat'].long().to(config.device))\n        dec = self.decoder_embedding(responses=y.long().to(config.device))\n        \n        # this encoder \n        encoder_output = self.encoder_layer(input_k=enc,\n                                            input_q=enc,\n                                            input_v=enc)\n        #this is decoder\n        decoder_output = self.decoder_layer(input_k=dec,\n                                            input_q=dec,\n                                            input_v=dec,\n                                            encoder_output = encoder_output,\n                                            break_layer=1)\n        #fully connected layer\n        out = self.fc(decoder_output)\n        return out.squeeze()\n\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(),lr=self.hparams.learning_rate)\n        scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=2, verbose=True)\n        return  {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_auc\"}\n    \n#     # learning rate warm-up\n#     def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_idx, second_order_closure=None, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n#         # warm up lr\n#         if self.trainer.global_step < 4000:\n#             lr_scale = min(1., float(self.trainer.global_step + 1) \/ 4000.)\n#             for pg in optimizer.param_groups:\n#                 pg['lr'] = lr_scale * self.hparams.learning_rate\n\n#         # update params\n#         optimizer.step()\n#         optimizer.zero_grad()\n  \n    def training_step(self,batch,batch_ids):\n        input,ans,labels = batch\n        target_mask = (input[\"input_ids\"]!=0)\n        out = self(input,ans)\n        loss = self.loss(out.view(-1).float(),labels.view(-1).float()) \n        out = torch.masked_select(out,target_mask)\n        out = torch.sigmoid(out) \n        labels = torch.masked_select(labels,target_mask)    \n        self.log(\"train_loss\",loss, on_step=False, on_epoch=True, logger=True)\n        return {\"loss\":loss,\"outs\":out,\"labels\":labels}\n    \n    def training_epoch_end(self,training_ouput): \n        out = torch.cat([i[\"outs\"] for i in training_ouput]).view(-1) \n        labels = torch.cat([i[\"labels\"] for i in training_ouput]).view(-1)\n        auc = roc_auc_score(labels.cpu().detach().numpy(),out.cpu().detach().numpy())\n        self.print(\"Epoch {} - Training AUC: \".format(self.current_epoch),auc) # Mettre epoch avant\n        self.log('train_auc', auc, on_step=False, on_epoch=True, logger=True)\n  \n    def validation_step(self,batch,batch_ids):\n        input,ans,labels = batch\n        target_mask = (input[\"input_ids\"]!=0)\n        out = self(input,ans)\n        loss = self.loss(out.view(-1).float(),labels.view(-1).float())\n        out = torch.masked_select(out,target_mask)\n        out = torch.sigmoid(out) \n        labels = torch.masked_select(labels,target_mask) \n        self.log(\"val_loss\",loss, on_step=False, on_epoch=True, logger=True)\n        output = {\"outs\":out,\"labels\":labels}\n        return output\n  \n    def validation_epoch_end(self,validation_ouput): \n        out = torch.cat([i[\"outs\"] for i in validation_ouput]).view(-1) \n        labels = torch.cat([i[\"labels\"] for i in validation_ouput]).view(-1)\n        auc = roc_auc_score(labels.cpu().detach().numpy(),out.cpu().detach().numpy())\n        self.print(\"Epoch {} - Validation AUC: \".format(self.current_epoch),auc)\n        self.log('val_auc', auc, on_step=False, on_epoch=True, logger=True)","042bff12":"def get_dataloaders():              \n    dtypes = {'timestamp': 'int64', \n              'user_id': 'int32' ,\n              'problem_id': 'int32',\n              'correct':'int8',\n#               'template_id': 'uint16', \n              'skill_id': 'uint16'}\n    print(\"Loading csv.....\")\n    train_df = pd.read_csv(config.TRAIN_FILE,usecols=[1,2,3,5,7],dtype=dtypes, \n                           nrows=config.NROWS\n                          )\n    print(\"Shape of dataframe :\",train_df.shape)\n    # Add dtype optimisation here\n\n    n_skills = train_df.problem_id.nunique() \n    print(\"No. of skills :\",n_skills)\n    print(\"Shape after exlusion:\",train_df.shape)\n\n    #grouping based on user_id to get the data supplu\n    print(\"Grouping users...\") \n    group = train_df[['user_id','problem_id','correct','skill_id']]\\\n                    .groupby(\"user_id\")\\\n                    .apply(lambda r: (r.problem_id.values,r.correct.values,\\\n                                      r.skill_id.values))\n    del train_df\n    gc.collect() \n    print(\"splitting\") \n    train,val = train_test_split(group,test_size=0.2) \n    print(\"Train size: \",train.shape,\"Validation size: \",val.shape)\n    train_dataset = DKTDataset(train,max_seq = config.MAX_SEQ)\n    val_dataset = DKTDataset(val,max_seq = config.MAX_SEQ)\n    train_loader = DataLoader(train_dataset,\n                          batch_size=config.BATCH_SIZE,\n                          num_workers=8,\n                          shuffle=True) \n    val_loader = DataLoader(val_dataset,\n                          batch_size=config.BATCH_SIZE,\n                          num_workers=8,\n                          shuffle=False)\n    del train_dataset,val_dataset \n    gc.collect() \n    return train_loader, val_loader","c37d7338":"%%time\ntrain_loader, val_loader = get_dataloaders() \nprint('----------------------------------------------')","304be3cf":"%system rm -rf '.\/logs'\n%system rm -rf '.\/bestmodel'","86edf22e":"seed_everything(42)","e857c89c":"logger = CSVLogger(\"logs\", name=\"my_exp_name\")","ea70344c":"%%time\n\ncheckpoint = ModelCheckpoint(dirpath=\"bestmodel\",\n                             filename=\"best_model\",\n                             verbose=True,\n                             save_top_k=1,\n                             monitor=\"val_auc\",\n                             mode='max',\n                             save_weights_only=True,\n                             period=1\n                            )\n\nearly_stop_callback = EarlyStopping(monitor='val_auc',\n                                    min_delta=config.EARLY_STOP_MIN_DELTA,\n                                    patience=config.EARLY_STOP_PATIENCE,\n                                    verbose=False,\n                                    mode='max'\n                                   )\n\nsaint_plus = PlusSAINTModule()\ntrainer = pl.Trainer(gpus=-1,\n                     max_epochs=config.MAX_EPOCHS, \n                     progress_bar_refresh_rate=21, \n                     callbacks=[#checkpoint, \n                                early_stop_callback], \n                     logger=logger) \ntrainer.fit(model=saint_plus,\n            train_dataloader=train_loader, \n            val_dataloaders=[val_loader,]) \n# trainer.save_checkpoint(\"model.pt\")\n\nprint('----------------------------------------------')","a9c59c83":"metrics = pd.read_csv('.\/logs\/my_exp_name\/version_0\/metrics.csv')","e4ad78c1":"val_metrics = metrics[['epoch','val_loss', 'val_auc']].dropna()\ntrain_metrics = metrics[['epoch', 'train_loss', 'train_auc']].dropna()","6fa2175e":"new_metrics = train_metrics.merge(val_metrics, on='epoch')","5c3d5e5f":"import matplotlib.pyplot as plt","f07a39ee":"plt.figure(figsize=(24,8))\n\nplt.subplot(1, 2, 1)\nplt.title('Training and test auc')\nplt.plot(new_metrics.epoch, new_metrics['train_auc'], label='Training AUC')\nplt.plot(new_metrics.epoch, new_metrics['val_auc'], label='Test AUC')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.title('Training and test loss')\nplt.plot(new_metrics.epoch, new_metrics['train_loss'], label='Training loss')\nplt.plot(new_metrics.epoch, new_metrics['val_loss'], label='Test loss')\nplt.legend()\n\nplt.show()\n\n","ced22d50":"# Dataset","2ac4cfea":"# SAINT model","63465658":"## About Knowledge Tracing and SAINT  \n\n**Knowledge Tracing** is the modelling of student knowledge over time. As far as I know, one of the earliest attempt was in [Knowledge Tracing: Modelling the acquisition of procedural Knowledge](https:\/\/link.springer.com\/article\/10.1007%252FBF01099821) (CORBETT A.T. and ANDERSON J.T., 1995).\nAnd after, a lot of different model were produced like:\n- BKT (Bayesian Knowledge Tracing) which is a Hidden Markov Model\n- LFA (Learning Factors Analysis)\n- LPA (Learning Perfomance Analysis)\n- And probabbly a lot more that I missed...\n\nAfter this first wave, the research switch from those models to Deep Learning models. Recurrent Neural Network and Attention mechanism became the common block for Knowledge Tracing models like SAKT (Self-Attentive Knowledge Tracing). \n\n**SAINT** (Separeted Self-AttentIve Neural knowledge Tracing) is a one of those models and it's based on a **Transformer Architecture** (See [Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing](https:\/\/arxiv.org\/pdf\/2002.07033v4.pdf) for more information). In the original paper, SAINT was used on the EdNet database. And in the implementation that I forked, it was used on the Riid data set from the recent competition (which is also a data set from EdNet). Here I tried to use SAINT on the ASSISment Data Set to see if it would still perform well (see [here](https:\/\/www.kaggle.com\/nicolaswattiez\/skillbuilder-data-2009-2010) more information on the dataset).","5689cf8f":"# Dataloader","343112c8":"# Training","b5afbd17":"## About transformers\n\nTransformers are a Deep Learning architecture initialy used in NLP and for sequential problem (ie: predicting the next word knowing a sequence of words). The two main advantages of Transformers are:\n- They allows for significantly more parallelization\n- They can retain long-term dependencies\n\nIf you want to know more about transformers, you can check those references:\n- https:\/\/towardsdatascience.com\/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0\n- https:\/\/towardsdatascience.com\/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452\n- https:\/\/www.kaggle.com\/abhinand05\/vision-transformer-vit-tutorial-baseline\n\nYou can also check the original paper if you are really motivated: [Attention is All you Need](https:\/\/arxiv.org\/pdf\/1706.03762.pdf)","70236b37":"# Import everything now...","f8812d99":"# Introduction\n\n\nThis notebook was fork from https:\/\/www.kaggle.com\/shivanandmn\/saint-training-using-pytorch-success-run (Huge thanks to the author!)","621386f6":"# Final Model with Trainer","1987301b":"# Configure constants","adfd47c6":"If you want to fork and play a bit with the parameters, don't use all the data set. It will just throw a \"CUDA error: device-side assert triggered\".  \nI think it's a memory error since it work correctly with 3 000 000 rows but I'm not sure."}}