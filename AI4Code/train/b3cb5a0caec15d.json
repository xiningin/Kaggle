{"cell_type":{"c862ab62":"code","e0840834":"code","23937c74":"code","199cc57d":"code","7cf6aa5c":"code","46f9a0e3":"code","1a5b7b9c":"code","999e9e61":"code","f5fb8fc9":"code","1ab111ae":"code","aec59451":"code","009a9225":"code","bf7308f8":"code","ed384775":"code","01191365":"code","581eb9d6":"code","8243e252":"code","c0261e21":"code","75a9d4d0":"code","03627fb9":"code","636c65c9":"code","b6e792e6":"code","789d990c":"code","1f62338f":"code","2be28276":"code","d9ad8790":"code","c48ef1a7":"code","1c3f4608":"code","27acda87":"code","e20737ae":"code","01b12802":"code","45aeb3db":"code","c94bf540":"code","29e187b5":"code","e6136c93":"code","3869b519":"code","7e6fbe8a":"code","7fdc4064":"code","abd1347e":"code","2f00f710":"code","d351c4b7":"code","93bea38b":"code","3ba6c605":"code","a181abf8":"code","f90bd785":"code","3b624462":"code","aa1417f0":"code","7f4842fe":"code","a0b87dcf":"code","4b7f9940":"code","7a94472e":"code","92bd69ce":"code","2897f604":"code","a58e2d3c":"code","e6fae35e":"code","d978db5d":"code","004afc31":"code","0865112e":"code","259e9fce":"code","7d83c743":"code","6a80ad20":"code","23e09c9f":"code","fe464790":"code","21189673":"code","74c89ecf":"code","862d9e93":"code","6249a7a0":"code","58859021":"code","c35b476e":"code","a255cd7b":"code","d14d05bc":"code","9883fa7e":"code","bcb5c290":"code","21236c05":"code","09e8a12e":"code","b21a5959":"code","5e90c234":"code","387b0539":"code","8fc7cf32":"code","9c452b62":"code","de2efe9e":"code","0df50634":"code","fb228fb6":"code","e2e73440":"code","29104f74":"code","f370eb83":"code","1ebbb268":"code","bb3b2a80":"code","dfef8b42":"code","45d99c93":"code","c3bc2bfc":"code","b9dee939":"code","5a264b39":"code","e2282a68":"code","9f44e3de":"code","f0e3692f":"code","74d1207f":"code","3e7f9102":"code","7199559d":"code","19eb42b1":"markdown","f0e5fe39":"markdown","c832a6ff":"markdown","6020f02d":"markdown","dce248f4":"markdown","0b7f941e":"markdown","098927a5":"markdown","d7795ed9":"markdown","76115c2f":"markdown","df07392b":"markdown","71dca854":"markdown","efc88637":"markdown","44980e32":"markdown","22861fbf":"markdown","d157d325":"markdown","37b34925":"markdown","f2aa6224":"markdown","ccb6d986":"markdown","28428598":"markdown","b9c63598":"markdown","200b50b7":"markdown","89653ce5":"markdown","0d84658a":"markdown","18024138":"markdown","e15e85f5":"markdown","655e472b":"markdown","33a4acab":"markdown","264ea7c5":"markdown","a5888aab":"markdown","7c79890b":"markdown","2aa0debf":"markdown","1cd431fa":"markdown","362c03ff":"markdown","243e6c26":"markdown","0bd3de31":"markdown","036b19ae":"markdown","f267eff5":"markdown","d6b14252":"markdown","158e0c42":"markdown"},"source":{"c862ab62":"#Set the libraries\n#Dataset\nimport pandas as pd #for data manipulation\nimport numpy as np  #for calculation\nfrom sklearn.impute import SimpleImputer #for fulfilling the missing values\nfrom sklearn.preprocessing import LabelEncoder #for turning categorical to numeric\n#Model\nfrom sklearn.model_selection import train_test_split     #for training the model\nfrom sklearn.metrics import accuracy_score #for calculating the accuracy\nfrom sklearn.ensemble import RandomForestClassifier #the ML tool\nfrom sklearn.tree import DecisionTreeClassifier #the ML tool\n\n#Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n","e0840834":"test_valid_file = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\",index_col = \"PassengerId\")\ntrain_file = pd.read_csv(\"..\/input\/titanic\/train.csv\", index_col=\"PassengerId\")\ntest_file = pd.read_csv(\"..\/input\/titanic\/test.csv\", index_col = \"PassengerId\")","23937c74":"#Dataset\ntest_valid = pd.DataFrame(test_valid_file) #Test Validation \ntest_d = pd.DataFrame(test_file) #Test\n\ntrain_d = pd.DataFrame(train_file)#Training \ntrain_valid = train_d['Survived'].copy() #Training Validation\n\ntrain_d.head()","199cc57d":"train_d.info()","7cf6aa5c":"display(train_d.isnull().sum())\ndisplay(test_d.isnull().sum())","46f9a0e3":"train_imputed = train_d.copy()\ntest_imputed = test_d.copy()\nsi = SimpleImputer(missing_values=np.nan, strategy='mean') # Tool\n#Train dataset\nimputed_age = np.array(train_imputed['Age']) # Adjust dataset for an imputation\nimputed_age = imputed_age.reshape(-1,1)\nimputed_age = pd.DataFrame(si.fit_transform(imputed_age),index = train_d.index)\ntrain_imputed['Age'] = imputed_age\n#Test dataset\ntes_age = np.array(test_imputed['Age'])\ntes_age = tes_age.reshape(-1,1)\ntes_age = pd.DataFrame(si.transform(tes_age),index = test_d.index) #Use previously calculated value(Train_imputed)\ntest_imputed['Age'] = tes_age\nprint(\"This is the mean of Age (train):\", train_d['Age'].mean())","1a5b7b9c":"def missing_value_index(dataset,Columns_Name): \n    nan = dataset.isnull() #Set the dataset to find null values\n    for i in range(len(dataset.index)): \n        value=nan[Columns_Name].iloc[i]\n        if value == True: #Test whether the value is missing (True: Missing, False: Not missing)\n            display(dataset.iloc[i]) #Print the row\nmissing_value_index(train_imputed,'Embarked')","999e9e61":"si = SimpleImputer(missing_values = np.nan, strategy= 'most_frequent' ) #Adjust the tool\n#Train Dataset\nemb = np.array(train_imputed['Embarked']) #Adjust dataset for an imputation\nemb = emb.reshape(-1,1)\nemb = pd.DataFrame(si.fit_transform(emb),index = train_imputed.index)\ntrain_imputed['Embarked'] = emb\n#Test Dataset\ntes_emb = np.array(test_imputed['Embarked'])\ntes_emb = tes_emb.reshape(-1,1)\ntes_emb = pd.DataFrame(si.transform(tes_emb), index= test_imputed.index)\ntest_imputed['Embarked'] = tes_emb\n","f5fb8fc9":"#To check\ndisplay(train_imputed.isnull().sum())\ndisplay(test_imputed.isnull().sum())","1ab111ae":"enco = LabelEncoder()\ncat_col = ['Sex',  'Embarked'] #Set the columns for encoding\ntrain_encoded = train_imputed.copy() #Create another dataset for encoding\ntest_encoded =  test_imputed.copy() #Create another dataset for encoding \nfor sliced_col in cat_col:\n    train_encoded[sliced_col] = pd.DataFrame(enco.fit_transform(train_encoded[sliced_col]), index = train_imputed.index)\n    test_encoded[sliced_col] = pd.DataFrame(enco.transform(test_encoded[sliced_col]), index = test_imputed.index)\n    print(enco.classes_)\n\ndisplay(train_encoded.head())\ndisplay(test_encoded.head())","aec59451":"display(train_encoded.describe())\ncorr = train_encoded.corr()\ndisplay(corr)\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, cmap='GnBu', annot = True, mask=mask)\nplt.title('Correlation between Variables')","009a9225":"female = train_imputed[train_imputed['Sex'] == 'female']\nmale = train_imputed[train_imputed['Sex'] == 'male']\nsns.distplot(train_imputed['Age'])\nplt.title('Age Distribution')\n#gender basis\nplt.figure()\nsns.distplot(male['Age'],color='r', hist = False, label= 'Male')\nsns.distplot(female['Age'],color='g', hist = False, label='Female')\nplt.title('Age Distribution Divided by Sex')","bf7308f8":"#understand the distribution\n\nplt.figure()\nsns.boxplot(x='Pclass', y='Age', data=  train_imputed)\nplt.title('Class Distribution1')\nplt.figure()\nsns.countplot(x='Pclass', data = train_imputed)\nplt.title('Class Distribution2')\nplt.figure()\nsns.countplot(x='Sex', data= train_imputed)\nplt.title('Sex Distribution')","ed384775":"#Undestand the Pclass distribution\nsns.swarmplot(x='Pclass', y = 'Age', hue = 'Survived', data = train_imputed)\nplt.title('Class Distribution based on the Survivor and Class')\nplt.figure()\nsns.swarmplot(x='Pclass', y='Age',hue = 'Sex',data = train_imputed)\nplt.title('Class Distribution based on Sex and Class')","01191365":"#Understand the dataset (distribution)\nclass_count = train_imputed.groupby(['Pclass']).Pclass.agg(['count']) #Pclass\nclass_count['Distribution %'] = (class_count['count'] \/ class_count['count'].sum()) * 100","581eb9d6":"#calculate the rate of survival based on class\ndef dist_calcualtor():\n    \n    i = [1,2,3]\n    for i in i:\n        #Divide the class\n        pclass = train_imputed[train_imputed['Pclass']== i ] #Create a pclass based DF\n        suv = pclass[pclass['Survived']==1]\n        dead =pclass[pclass['Survived']==0]\n        suv_rate = len(suv.index) \/ len(pclass)\n        death_rate = len(dead.index)\/ len(pclass)\n        display([death_rate,suv_rate])\ndist_calcualtor()","8243e252":"#Survival distribution\nclass_survived = train_imputed.groupby(['Pclass', 'Survived']).Survived.agg(['count']) #Survived\nclass_survived['Survival Dist (%) to Total pop'] = (class_survived['count'] \/ class_survived['count'].sum()) * 100\ndist_list = np.array([0.37037037037037035, 0.6296296296296297,0.5271739130434783, \n                      0.47282608695652173,0.7576374745417516, 0.24236252545824846])\nclass_survived['Survival Dist(%) to Class pop'] = dist_list *100","c0261e21":"#Display All the data\n\n\ndisplay(\"# of passengers at each class\",class_count)\ndisplay(\"Distribution of Survival at each class\", class_survived)","75a9d4d0":"#Pclass Vizualizations \n#Survival Distribution based on the class\nclass_survived['Survival Dist(%) to Class pop'].plot.bar(color= 'g',width=0.75)\nplt.title('Survivor Distribution based on Class')\nplt.ylabel('Dist (%)')","03627fb9":"#divide age based on class and count the age \ndef class_age_counter():\n    i = [1,2,3]\n    age_dist = pd.DataFrame({}, index=[0,0,0])\n    for i in i:\n        #Divide the class\n        pclass = train_imputed[train_imputed['Pclass']== i ] #Create a pclass based DF\n        #Divide the age based on the class\n        kids_teen = pclass[pclass['Age'] < 20] #Create a DF of younger than 20 (0-19)\n        exc_pc = pclass[pclass['Age']>19]#Exclude the 0-19 from pclass DF\n        _20_39 = exc_pc[exc_pc['Age']<40] #DF of 20-39\n        exc_pc = exc_pc[exc_pc['Age']> 39] #Exclude 20-39 from pclass df\n        _40_59 =  exc_pc[exc_pc['Age']< 60]\n        exc_pc = exc_pc[exc_pc['Age'] > 59]\n        _60_80 =  exc_pc[exc_pc['Age']<101]\n        #Count the # of passengers in a certain class\n        class_age_dis = pd.DataFrame({'0-19': len(kids_teen.index), '20-39': len(_20_39.index), '40-59':len(_40_59.index),\n                                     '60-100': len(_60_80.index)}, index = [i])\n        \n        age_dist = pd.concat([age_dist, class_age_dis], axis=0)\n    age_dist = age_dist.drop([0,0,0])\n    display(age_dist)","636c65c9":"class_age_counter()","b6e792e6":"#Divide Survived based on age\n#First, sort based on whether a passenger is survived\ndef age_survivors():\n    a_s = pd.DataFrame({},index=[0,0,0])\n    i = [1,2,3]\n    for i in i:\n        #Divide DataSet based on Class\n        pclass = train_imputed[train_imputed['Pclass']== i ] #Create a pclass based DF\n        #Divide class anchored data based on a passenger's age\n        sv = pclass[pclass['Survived']==1]\n        kids_teen = sv[sv['Age'] < 20] #Create a DF of younger than 20 (0-19)\n        pdf = sv[sv['Age']>19]#Exclude the 0-19 from pclass DF\n        _20_39 = pdf[pdf['Age']<40] #DF of 20-39\n        pdf = pdf[pdf['Age']> 39] #Exclude 20-39 from pclass df\n        _40_59 =  pdf[pdf['Age']< 60]\n        pdf = pdf[pdf['Age'] > 59]\n        _60_100 =  pdf[pdf['Age']<101]\n        #Create the dataset for counting purposes\n        sa = pd.DataFrame({'0-19': len(kids_teen.index), '20-39': len(_20_39.index), '40-59':len(_40_59.index),\n                                        '60-100': len(_60_100.index)}, index = [i])\n        a_s = pd.concat([a_s, sa], axis=0)\n    a_s = a_s.drop([0,0,0])\n    display(a_s)\n","789d990c":"age_survivors()","1f62338f":"# Age Distribiton\nclass_age_max_min = train_imputed.groupby(['Pclass']).Age.agg([max,min])\nage_pop = pd.DataFrame({'0-19': [21,35,108], '20-39': [114,112,338], '40-59':[64,33,40],\n                                     '60-100': [17,4,5]}, index = ['1st','2nd','3rd'])\nage_suv = pd.DataFrame({'0-19': [17,26,36], '20-39': [77,45,80], '40-59':[37,15,2],\n                                     '60-100': [5,1,1]}, index = ['1st','2nd','3rd'])\n","2be28276":"age_pop_ratio = age_pop.copy()\nfor i in range(len(age_pop.index)):\n    total = age_pop.iloc[i].sum()\n    age_pop_ratio.iloc[i] = (age_pop.iloc[i] \/ total) * 100\n","d9ad8790":"\n#rate_surviving: How much % passenger from a certain age range at a certain class is survived. \nrate_surviving = (age_suv \/ age_pop) * 100\ndisplay(\"Passenger Distribution\u2193\",age_pop)\ndisplay(\"Survivor Distribution \u2193\", age_suv)\ndisplay(\"Passenger Distribution Ratio\", age_pop_ratio)\ndisplay(\"Surviving rate based on age\", rate_surviving)\ndisplay(\"Max\/Min Age\", class_age_max_min)","c48ef1a7":"#Age distribution based on the class\nage_pop_ratio.plot.bar(width=0.75,stacked=True)\nplt.title('Age Distribution by the Class')\nplt.ylabel('Count')\n\nplt.figure()\nsns.heatmap(rate_surviving, cmap='RdBu', annot=True)\nplt.title('Survival Rate (%) by the Age')\n","1c3f4608":"#Understand the Sex dataset\ngender = train_imputed.groupby(['Sex','Survived']).Survived.agg(['count'])\ngender","27acda87":"def female_count():\n    i = [1,2,3]\n    female = pd.DataFrame({},index= [0,0,0])\n    for i in i:\n        #Divide the dataset based on Class\n        pclass = train_imputed[train_imputed['Pclass']== i ] #Create a pclass based DF\n        #Based on Female and Survived\n        pclass_sex = pclass[pclass['Sex'] == 'female']\n        #Age classification\n        kt_s = pclass_sex[pclass_sex['Age']< 20]\n        no_kt = pclass_sex[pclass_sex['Age']>19]\n        young = no_kt[no_kt['Age']< 40]\n        no_y = no_kt[no_kt['Age']>39]\n        mid = no_y[no_y['Age']<60]\n        no_m = no_y[no_y['Age']>59]\n        old = no_m[no_m['Age']<101]\n        age_sex_counter = pd.DataFrame({'0-19':len(kt_s.index), '20-39':len(young.index), '40-59':len(mid.index),\n                                       '60-100':len(old.index)},index=[i])\n        female = pd.concat([female, age_sex_counter], axis=0)\n    female= female.drop([0,0,0])\n    display(female)","e20737ae":"female_count()","01b12802":"#Undersatnding the distribution of passenger classified by sex\nfemale_pop = pd.DataFrame({'0-19': [14,16,45], '20-39': [52,44,89], '40-59':[24,16,9],\n                                    '60-100':[3,0,1]},index = ['1st','2nd','3rd'])\nmale_pop = age_pop - female_pop\ndisplay('Female Distribution', female_pop,\n       'Male Distribution', male_pop)","45aeb3db":"#Classify Sex based on age and survival\ndef female_survivor():\n    i = [1,2,3]\n    female = pd.DataFrame({},index= [0,0,0])\n    for i in i:\n        #Divide the dataset based on Class\n        pclass = train_imputed[train_imputed['Pclass']== i ] #Create a pclass based DF\n        #Based on Female and Survived\n        pclass_sex = pclass[pclass['Sex'] == 'female']\n        survived = pclass_sex[pclass_sex['Survived'] == 1]\n        #Age classification\n        kt_s = survived[survived['Age']< 20]\n        no_kt = survived[survived['Age']>19]\n        young = no_kt[no_kt['Age']< 40]\n        no_y = no_kt[no_kt['Age']>39]\n        mid = no_y[no_y['Age']<60]\n        no_m = no_y[no_y['Age']>59]\n        old = no_m[no_m['Age']<101]\n        age_sex_counter = pd.DataFrame({'0-19':len(kt_s.index), '20-39':len(young.index), '40-59':len(mid.index),\n                                       '60-100':len(old.index)},index=[i])\n        female = pd.concat([female, age_sex_counter], axis=0)\n    female= female.drop([0,0,0])\n    display(female)\n        \n","c94bf540":"female_survivor()","29e187b5":"#Group survivors based on sex\nsurvived_female = pd.DataFrame({'0-19': [13,16,24], '20-39': [51,40,47], '40-59':[24,14,0],\n                                    '60-100':[3,0,1]},index = ['1st','2nd','3rd'])\n\nsurvived_male = age_suv - survived_female\ndisplay('Female Dist', female_pop,\n        'Female Survivors',survived_female,\n       'Male Dist', male_pop,\n       'Male Survivors', survived_male)","e6136c93":"#Rate Calculation\n\n#female_rate: How much % female passenger from a certain age range at a certain class is survived.\n#male_rate: How much % male passenger from a certain age range at a certain class is survived.\n#Surviving_rate = female_rate + male_rate\nfemale_rate = (survived_female \/ female_pop) * 100\nmale_rate = (survived_male \/ male_pop) * 100\n\n#combine gender surviving rate\nsex_rate = pd.concat([female_rate,male_rate], axis=1)\nsex_rate = sex_rate.fillna(0)\nsex_rate.columns = ['0-19 F',   '20-39 F','40-59 F', '60-100 F','0-19 M', '20-39 M', '40-59 M','60-100 M' ]\n\ndisplay('This is a survival rate', rate_surviving,\n        'This is the rate based on gender', sex_rate)\n","3869b519":"plt.figure(figsize=[10,6])\nsns.heatmap(sex_rate,cmap='RdBu',annot= True)\nplt.title('Survival Rate (%) by the Gender and Age')","7e6fbe8a":"n_suv = train_imputed[train_imputed['Survived']==1]\n#Understand the overall of distribution\nsib_unique = train_imputed['SibSp'].unique()\npch_unique = train_imputed['Parch'].unique()\ndisplay('SibSp:{}'.format(sib_unique),\n       'Parchi:{}'.format(pch_unique))","7fdc4064":"#SibSp: Undestanding the data\nsib_dist = train_imputed.groupby('SibSp').SibSp.agg(['count'])\n\nsib_dist['Survivors'] = n_suv.groupby(['SibSp']).Survived.agg(['count'])\nsib_dist = sib_dist.fillna(0)\n#Surviving rate = # of survivors \/ # of passengers for each in a SibSp attribute\nsib_dist['Survival Rate %'] = (sib_dist['Survivors']\/sib_dist['count'] )*100\ndisplay(sib_dist)","abd1347e":"#SibSp: Class & Sex Distribution\nsib_pc_dist  = train_imputed.groupby(['SibSp', 'Pclass']).SibSp.agg(['count'])\nsib_sex_dist = train_imputed.groupby(['SibSp', 'Pclass','Sex']).SibSp.agg(['count'])\ndisplay(sib_pc_dist,sib_sex_dist)","2f00f710":"pch = train_imputed.groupby(['Parch']).Parch.agg(['count'])\npch['Survived'] = n_suv.groupby(['Parch']).Survived.agg(['count'])\npch = pch.fillna(0)\npch['Survival Rate (%)'] = (pch['Survived']\/ pch['count']) * 100\ndisplay(pch)\ndisplay(sib_dist)","d351c4b7":"\npch_v1 = train_imputed.groupby(['Parch']).Parch.agg(['count'])\ndisplay(pch_v1)\npch_v2 = train_imputed.groupby(['Parch', 'Pclass']).Parch.agg(['count'])\ndisplay(pch_v2)\npch_v3 = train_imputed.groupby(['Parch', 'Pclass','Sex']).Parch.agg(['count'])\ndisplay(pch_v3)\npch_v4 = train_imputed.groupby(['Parch', 'Pclass','Sex', 'Survived']).Parch.agg(['count'])\ndisplay(pch_v4)","93bea38b":"#Visualize the relation\nsib_dist['Survival Rate %'].plot.bar()\nplt.title('% of Survival (SibSp)')\nplt.ylabel('Dist')\nplt.figure()\npch['Survival Rate (%)'].plot.bar()\nplt.title('% of Survival (Parch)')\nplt.ylabel('Dist')","3ba6c605":"\nsns.swarmplot(x='SibSp', y='Age', hue = 'Survived', data = train_imputed)\nplt.title('Distribution of passenger classified by Survived and SibSp')\n\nplt.figure()\nsns.swarmplot(x='Parch', y='Age', hue = 'Survived', data = train_imputed)\nplt.title('Distribution of passenger classified by Survived and Parch')","a181abf8":"sns.swarmplot(x='SibSp', y='Age',hue = 'Pclass', data =n_suv)\nplt.title('Distirbution of Survivors measured by Pclass and SibSp')\nplt.figure()\nsns.swarmplot(x='Parch', y='Age',hue = 'Pclass', data =n_suv)\nplt.title('Distirbution of Survivors measured by Pclass and Parch')","f90bd785":"sns.swarmplot(x='SibSp', y='Age',hue = 'Sex', data =n_suv)\nplt.title('Distirbution of Survivors measured by Sex and SibSp')\nplt.figure()\nsns.swarmplot(x='Parch', y='Age',hue = 'Sex', data =n_suv)\nplt.title('Distirbution of Survivors measured by Sex and Parch')","3b624462":"#First let's look at easier one\np6 = train_imputed[train_imputed['Parch']==6]\ndisplay(p6)\ngoodwin = train_imputed[train_imputed['Name'].str.contains('Goodwin')]\ngoodwin = goodwin.sort_values('Age')\ndisplay(goodwin)\np5 = train_imputed[train_imputed['Parch'] == 5]\ndisplay(p5)\nasplund = train_imputed[train_imputed['Name'].str.contains('Asplund')]\ndisplay(asplund)\n","aa1417f0":"family = train_encoded.copy()\nfamily['SurName'] = family['Name'].str.extract(pat = '(.+),.' ,expand = True)\ndisplay(family.isnull().sum())","7f4842fe":"def family_classifier(df):\n    \n    ind = np.arange(len(df)) #Easy manipulation\n    df.index = ind\n    df['Family'] = np.nan #Create a new column\n    for i in df.index:\n        if df['SibSp'].iloc[i] > 0 or df['Parch'].iloc[i] > 0:\n            df['Family'].iloc[i] = 'F'\n        else:\n            df['Family'].iloc[i] = 'S'\n","a0b87dcf":"family_classifier(family)\ndisplay(family.head(), family['Family'].unique())","4b7f9940":"family.isnull().sum()","7a94472e":"#Family Distribution\nfam_dist = family.groupby(['Family']).Family.agg(['count'])\nfam_suv = family[family['Survived'] == 1]\nfam_dist['Survived'] = fam_suv.groupby(['Family']).Family.agg(['count'])\nfam_dist['Survival Rate (%)'] = (fam_dist['Survived']\/ fam_dist['count']) * 100\ndisplay('This is the rate compared with the total family classified population',fam_dist)","92bd69ce":"#for a calculation purpose\nn_sv = train_d[train_d['Survived'] == 1]\na = n_sv.groupby(['Pclass']).Survived.agg(['count'])\n\nfan_suv_dist = fam_suv.groupby(['Family', 'Pclass']).Pclass.agg(['count'])\nfan_suv_dist['Survival Rate(%)'] = (fan_suv_dist['count'] \/ a['count']) * 100\ndisplay('This is the survival rate compared with the class survived population', fan_suv_dist)","2897f604":"#Vizualize the family and survival\n\nsns.swarmplot(x= 'Family', y='Age', hue='Survived', data= family)\nplt.title('Passenger Distribution based on Survived and Family Structures')\n\nplt.figure()\nsns.swarmplot(x='Pclass', y = 'Age', hue='Family', data =fam_suv  )\nplt.title('Survivor Distribution based on Pclass and Family Structures')\nplt.figure()\nsns.swarmplot(x='Sex', y='Age', hue='Family', data= fam_suv)\nplt.title('Survivor Distribution based on Family and Sex')\n\nplt.figure()\nfan_suv_dist['Survival Rate(%)'].plot.bar()\nplt.title('Survial Rate based on Family Condition')","a58e2d3c":"family['Title'] = family['Name'].str.extract(',(.+)\\.')\ntitle = family['Title'].unique()\ndisplay(family,title)","e6fae35e":"a = family[family['Name'].str.contains(' Mrs. Martin') ]\na['Name'] = 'Rothschild, Mrs. Martin'\nfamily[family['Name'].str.contains(' Mrs. Martin') ] = a","d978db5d":"family[family['Name'].str.contains(' Mrs. Martin') ]","004afc31":"family['Title'] = family['Name'].str.extract(',(.+)\\.')\ntitle = family['Title'].unique()\n\ndisplay(family,title)","0865112e":"fa = family.groupby(['Family' ]).Family.agg(['count'])\nfa","259e9fce":"a = family.groupby(['Family', 'Title','Survived']).Title.agg(['count'])\na","7d83c743":"#First create a df for group each family in order to see their family composition \nfam = family[family['Family'] == 'F']\nfam\nfam2 = fam.copy()\nind = np.arange(len(fam2))\nfam2 = fam2.sort_values('Age',ascending = False)\nfam2.index = ind\n\n","6a80ad20":"def family_comp(df):\n    family_sorted = df.sort_values('SurName')\n    surname_sorted = family_sorted['SurName'].unique()\n    for i in surname_sorted: #Defined it above\n        family_sn = family_sorted[family_sorted['SurName']==i]\n        family_sn = family_sn.sort_values('Age')\n        display(family_sn)\n        \nsv = train_d[train_d['Survived'] == 1]\ndf = sv.groupby('Survived').Survived.agg(['count'])\ndf['count']","23e09c9f":"#copy the dataset\ntrain_d2 = train_d.copy()\ntest_d2 = test_d.copy()","fe464790":"print(train_d2.info(), test_d2.info())\nfamily_classifier(train_d2)\nfamily_classifier(test_d2)\ndisplay(train_d2.head(), test_d2.head())","21189673":"train_d3 = train_d2.fillna({'Age': 0})\nno_age = train_d3[train_d3['Age']==0]\nno_age","74c89ecf":"na_dist = no_age.groupby(['Family']).Age.agg(['count'])\nna_dist","862d9e93":"na_dist_2 = no_age.groupby(['Family','Sex']).Age.agg(['count'])\nna_dist_2","6249a7a0":"sing = train_d2[train_d2['Age'] > 0]\nsing = sing[sing['Family']=='S']\nsing_dist = sing.groupby(['Family']).Age.agg([max, min])\nsing.groupby(['Sex']).Sex.agg(['count'])","58859021":"sns.boxplot(x= 'Age', y= 'Sex', data = sing)\nplt.title('Singles Distribution based on Sex')\nplt.figure()\nsns.swarmplot(x='Sex', y = 'Age', hue = 'Pclass', data = sing )\nplt.title('Singles Distribution based on Class and Sex')","c35b476e":"female_sig = sing[sing['Sex'] == 'female']\nfemale_sigle_age_mean = female_sig['Age'].mean()\nfemale_sigle_age_mean","a255cd7b":"male_sing = sing[sing['Sex'] == 'male']\nmeale_sigle_age_mean = male_sing['Age'].mean()\nmeale_sigle_age_mean","d14d05bc":"f_age = train_d2[train_d2['Age'] > 0]\nf_age = f_age[f_age['Family'] == 'F']\nf_dist = f_age.groupby('Family').Age.agg([min,max])\nf_dist","9883fa7e":"sns.boxplot(x = 'Age', y= 'Sex', data= f_age)\nplt.title('Family Distribution based on Sex')\nplt.figure()\nsns.swarmplot(x = 'Sex' , y = 'Age', hue = 'Pclass', data =  f_age)\nplt.title('Family Distribution based on Sex and Pclass')","bcb5c290":"male_f = f_age[f_age['Sex'] == 'male']\nmeale_f_age_mean = male_f['Age'].mean()\nmeale_f_age_mean","21236c05":"female_f = f_age[f_age['Sex'] == 'female']\nfemale_f_age_mean = female_f['Age'].mean()\nfemale_f_age_mean","09e8a12e":"fam_stru = f_age.copy()\nfam_stru['SurName'] = fam_stru['Name'].str.extract('(.+),.')\nfam_stru.index = np.arange(len(fam_stru))\nfam_stru","b21a5959":"def fam_slicer(df):\n    df_copy = df.copy()\n    df_copy = df_copy.sort_values('SurName')\n    sn = df_copy['SurName'].unique()\n    kids_teen = df_copy[df['Age'] < 20]\n    older = df_copy[df['Age']>20]\n    older['Family'] = 'F'\n    kids_teen['Family'] = 'C'\n    df_copy = pd.concat([kids_teen, older], axis=0)\n    df_copy_ind = df_copy.sort_index()\n    df['Family'] = df_copy['Family']\n            ","5e90c234":"fam_slicer(fam_stru)","387b0539":"family_comp(fam_stru)","8fc7cf32":"child = fam_stru[fam_stru['Family'] == 'C']\nchild['Age'].mean()","9c452b62":"sns.swarmplot(x = 'Sex', y='Age', hue='Parch',data = child)\nplt.title('Kids Distribution based on Sex and Parch')","de2efe9e":"c_suv = child[child['Survived'] == 1]\nsns.swarmplot(x='Sex', y='Age',hue='Parch', data=c_suv)\nplt.title('Survived Kids Dist based on Parch and Sex')\nf = fam_stru[fam_stru['Family'] == 'F']\nf_suv = f[f['Survived']==1]\nf_suv = f_suv[f_suv['Parch'] > 0]\nplt.figure()\nsns.swarmplot(x='Sex', y='Age',hue='Parch', data=f_suv)\nplt.title('Survived Parents Dist based on Parch and Sex')","0df50634":"features = ['Pclass', 'Sex', 'Age']\nx = train_encoded[features].copy()\ny = pd.DataFrame({'Survived':train_encoded['Survived']})\nx_train,x_test, y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=1)","fb228fb6":"i = [50,100,150,200,250,300]\nfor i in i:\n    model = RandomForestClassifier(n_estimators = i, random_state=1)\n    model = model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    print(\"Accuracy with {}: {}\".format(i, accuracy_score(y_test,y_pred)))","e2e73440":"model = RandomForestClassifier(n_estimators = 300, random_state=1)\nmodel.fit(x_train,y_train)\ny_pred = model.predict(x_test)\nprint(\"Accuracy with {}: {}\".format(i, accuracy_score(y_test,y_pred)))","29104f74":"comp_pred = model.predict(test_encoded[features])\nprint(\"Accuracy\", accuracy_score(test_valid, comp_pred))\ndf = pd.DataFrame({'Survived': comp_pred},index =test_valid.index)\ndf2 = pd.concat([test_valid,df],axis=1)\ndisplay(test_valid, df)","f370eb83":"enco = LabelEncoder()\n#Train dataset\nfam_encoded = family.copy()\nfam_encoded['Family'] = pd.DataFrame(enco.fit_transform(fam_encoded['Family']))\ndisplay(enco.classes_, fam_encoded)\n\n\n#Test dataset\ntes_fam = test_encoded.copy()\nfamily_classifier(tes_fam)\ntes_fam['SurName'] = test_encoded['Name'].str.extract(pat = '(.+),.' ,expand = True)\nsurname = tes_fam['SurName'].unique()\n\ntest_encoded2 = tes_fam.copy()\ntest_encoded2['Family'] = pd.DataFrame(enco.transform(tes_fam['Family']))\ndisplay(test_encoded2)","1ebbb268":"features = ['Pclass', 'Sex', 'Age', 'Family']","bb3b2a80":"x = fam_encoded[features].copy()\ny = fam_encoded['Survived'].copy()\n#create training set\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25,random_state=1)","dfef8b42":"ind = [5, 10, 25, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n","45d99c93":"for i in ind:\n    model = RandomForestClassifier(n_estimators = i, random_state=2)\n    model.fit(xtrain,ytrain)\n    pred = model.predict(xtest)\n    accu_sco = accuracy_score(ytest, pred)\n    print(i, accu_sco)\n","c3bc2bfc":"model = RandomForestClassifier(n_estimators=5,random_state=2)\nmodel.fit(xtrain,ytrain)\npred2 = model.predict(test_encoded2[features])\nprint(accuracy_score(test_valid, pred2))\n\n\nmy_submission = pd.DataFrame({'Survived': pred2},index=test_valid.index)\nmy_submission.to_csv('submission2.csv',index=True)","b9dee939":"#Encode: Sex\nfrom sklearn.preprocessing import OneHotEncoder as ohe\n#Creat a copy for onehotencoding\ntrain_ohe = train_imputed.copy()\ntest_ohe= test_imputed.copy()\n\n#Generate a new column\nfamily_classifier(train_ohe)\nfamily_classifier(test_ohe)","5a264b39":"oh = ohe(handle_unknown='ignore', sparse = False)\n\n#Sex\ntrain_sex  =np.array(train_ohe['Sex'])\ntrain_sex = np.reshape(train_sex, [-1,1])\ntest_sex = np.array(test_ohe['Sex'])\ntest_sex =np.reshape(test_sex,[-1,1])\ntrain_e = pd.DataFrame(oh.fit_transform(train_sex),index = train_ohe.index)\ntest_e  = pd.DataFrame(oh.transform(test_sex), index = test_ohe.index)\ndisplay(oh.categories_)","e2282a68":"test_e.columns = ['female', 'male']\ntrain_e.columns = ['female', 'male']\n\ntrain_ohe = pd.concat([train_ohe, train_e], axis=1)\ntest_ohe= pd.concat([test_ohe, test_e], axis=1)","9f44e3de":"#Building ML model \nfrom xgboost import XGBClassifier\n\n#list the potential variables\nfeatures = ['Pclass', 'Age', 'female', 'male']\n#Slice the dataset for training\nx = train_ohe[features]\ny = train_ohe['Survived']\nxtrain, xtest,ytrain, ytest = train_test_split(x, y, test_size = 0.25, random_state = 5)\ni = [0.2, 0.1,0.05,0.001, 0.0005,0.0001]\nfor i in i:\n    print(i)\n    model5 = XGBClassifier(n_estimators=500, learning_rate=i, random_state = 5)\n    model5.fit(xtrain, ytrain, early_stopping_rounds = 10,\n              eval_set=[(xtest,ytest)])","f0e3692f":"model5 = XGBClassifier(n_estimators=500, learning_rate = 0.05, random_sate= 5)\nmodel5.fit(xtrain, ytrain, early_stopping_rounds = 6, eval_set=[(xtest, ytest)])\npred = model5.predict(xtest)\naccuracy_score(ytest, pred)","74d1207f":"pred5 = model5.predict(test_ohe[features])\naccuracy_score(test_valid,pred5)","3e7f9102":"sub = pd.DataFrame({'Survived': pred5}, index = test_valid.index)\nsub.to_csv('submission5.csv', index = True)","7199559d":"#Set the df\n\ntrain = train_d2.copy()\ntest = test_d2.copy()\n\ntrain_sing = train[train['Family'] == 'S']\ntrain_sing_m = train_sing[train_sing['Sex'] == 'male']\ntrain_sing_f = train_sing[train_sing['Sex'] == 'female']\n\n\ntrain_f = train[train['Family'] == 'F']\ntrain_f_m = train_f[train_f['Sex'] =='male']\ntrain_f_f = train_f[train_f['Sex'] =='female']\n\n\ntest_sing = test[test['Family'] == 'S']\ntest_sing_m = test_sing[test_sing['Sex'] == 'male']\ntest_sing_f= test_sing[test_sing['Sex'] == 'female']\n\n\ntest_f = test[test['Family'] == 'F']\ntest_f_m = test_f[test_f['Sex'] =='male']\ntest_f_f = test_f[test_f['Sex'] == 'female']\n\n\nsi = SimpleImputer()\n\n#Impute: Single male\ntrain_s = np.array(train_sing_m['Age'])\ntrain_s = np.reshape(train_s,[-1,1])\n\ntest_s = np.array(test_sing_m['Age'])\ntest_s = np.reshape(test_s, [-1,1])\n\ntrain_imputed_s = pd.DataFrame(si.fit_transform(train_s), index = train_sing_m.index)\ntrain_imputed_s.columns = ['Age_imputed']\ntest_imputed_s = pd.DataFrame(si.transform(test_s),index = test_sing_m.index)\ntest_imputed_s.columns= ['Age_imputed']\n\ntrain_imputed2_m = pd.concat([train_sing_m, train_imputed_s], axis=1)\ntest_imputed2_m = pd.concat([test_sing_m, test_imputed_s], axis = 1)\n\n#Impute: Single Female\n\ntrain_s = np.array(train_sing_f['Age'])\ntrain_s = np.reshape(train_s ,[-1,1])\ntest_s = np.array(test_sing_f['Age'])\ntest_s = np.reshape(test_s,[-1,1])\n\ntrain_imputed_s = pd.DataFrame(si.fit_transform(train_s),index = train_sing_f.index)\ntest_imputed_s = pd.DataFrame(si.transform(test_s), index = test_sing_f.index)\n\ntrain_imputed_s.columns= ['Age_imputed']\ntest_imputed_s.columns=['Age_imputed']\n\ntrain_imputed2_f = pd.concat([train_sing_f, train_imputed_s], axis=1)\ntest_imputed2_f = pd.concat([test_sing_f, test_imputed_s], axis=1)\n#Impute: Family Male\n\ntrain_s = np.array(train_f_m['Age'])\ntrain_s = np.reshape(train_s,[-1,1])\ntest_s = np.array(test_f_m['Age'])\ntest_s = np.reshape(test_s,[-1,1])\n\ntrain_imputed_s = pd.DataFrame(si.fit_transform(train_s),index = train_f_m.index)\ntest_imputed_s = pd.DataFrame(si.transform(test_s), index = test_f_m.index)\n\ntrain_imputed_s.columns = ['Age_imputed']\ntest_imputed_s.columns = ['Age_imputed']\n\ntrain_imputed2_f_m = pd.concat([train_f_m, train_imputed_s], axis=1)\ntest_imputed2_f_m = pd.concat([test_f_m, test_imputed_s], axis= 1)\n\n\n\n#Impute: Family Female\n\ntrain_s = np.array(train_f_f['Age'])\ntrain_s = np.reshape(train_s,[-1,1])\ntest_s = np.array(test_f_f['Age'])\ntest_s = np.reshape(test_s,[-1,1])\n\ntrain_imputed_s = pd.DataFrame(si.fit_transform(train_s),index = train_f_f.index)\ntest_imputed_s = pd.DataFrame(si.transform(test_s),index = test_f_f.index)\ntrain_imputed_s.columns = ['Age_imputed']\ntest_imputed_s.columns = ['Age_imputed']\n\ntrain_imputed2_ff = pd.concat([train_f_f,train_imputed_s],axis=1)\ntest_ff = pd.concat([test_f_f,test_imputed_s], axis=1)\ntrain_imputed2 = pd.concat([train_imputed2_m, train_imputed2_f,\n                            train_imputed2_f_m,train_imputed2_ff],axis=0)\ntrain_imputed2 = train_imputed2.sort_index()\ntrain_imputed2 = train_imputed2.drop(['Age', 'Cabin'],axis=1)\ntest_imputed2 = pd.concat([test_imputed2_m,test_imputed2_f,\n                           test_imputed2_f_m,test_ff],axis=0)\ntest_imputed2 = test_imputed2.sort_index()\ntest_imputed2 = test_imputed2.drop(['Age','Cabin'],axis=1)\n#Encoding\ntrain_enco = train_imputed2.copy()\ntest_enco = test_imputed2.copy()\noh = ohe(handle_unknown='ignore',sparse=False)\n#Sex\nfeatures=['Sex']\n\no_train1 = pd.DataFrame(oh.fit_transform(train_enco[features]),index = train_enco.index)\no_test1 = pd.DataFrame(oh.transform(test_enco[features]),index = test_enco.index)\ndisplay(oh.categories_)\n#Family\nfeatures=['Family']\n\no_train2= pd.DataFrame(oh.fit_transform(train_enco[features]),index = train_enco.index)\no_test2 = pd.DataFrame(oh.transform(test_enco[features]),index = test_enco.index)\ndisplay(oh.categories_)\n\n#merging\no_train = pd.concat([o_train1,o_train2],axis=1)\no_test = pd.concat([o_test1,o_test2],axis=1)\no_train.columns=(['female', 'male','F', 'S'])\no_test.columns=(['female', 'male','F', 'S'])\ntrain_enco = pd.concat([train_enco,o_train], axis=1)\ntest_enco = pd.concat([test_enco, o_test], axis=1)\n\n#Building mdoel\n\nfeatures = ['Pclass', 'Age_imputed', 'female', 'male','F', 'S']\np = [0.2, 0.1, 0.05, 0.01, 0.005, 0.001]\ny = train_enco['Survived']\nx = train_enco[features]\nxtrain,xtest,ytrain,ytest = train_test_split(x,y , test_size = 0.25, random_state = 5)\nfor i in p:\n    print(i)\n    model6 = XGBClassifier(n_estimators=500, learning_rate = i, random_state = 6)\n    model6.fit(xtrain, ytrain, early_stopping_rounds = 10,\n              eval_set=[(xtest,ytest)])\nmodel6 = XGBClassifier(n_estimators = 500, learning_rate=0.05, random_state=6)\nmodel6.fit(xtrain,ytrain, early_stopping_rounds = 10, eval_set=[(xtest,ytest)])\npred = model6.predict(xtest)\naccuracy_score(ytest,pred)\npred6 = model6.predict(test_enco[features])\naccuracy_score(test_valid, pred6)\nsb = pd.DataFrame({'Survived': pred6},index = test_valid.index)\nsb.to_csv('submission6.csv', index = True)","19eb42b1":"# **Interpretation (Age \/ Sex)**\n\nBased on surviving rate calculations above, a striking but expected result is revealed. Kids and Teens is the highest across the class. For the 1st class, the survivng rate of kids & teens is 81%, 74% and 33% for 2nd and 3rd class respectively. In the 1st class, the rate declies as the age goes up, but it is not applicable to other two classes. In the 2nd class, after the teenagers, mid working age has the sencond highest rate of 45%, while it is the lowest in the 3rd class at 5%. In addition to the surviving rate,the gender also does matter in survival.The female passengers are more likely to survive regardless of the passenger classes with rate of more than half (53%) in any age ranges accross the classes. Overall, there is an important pattern for explaning the survival which female and younger age passengers were more likely to be rescued. \n\nWith having these findings, it is clear that kids and teens had a privilege in the evacuation. After kids & teens, the 1st class passengers were allowed to evacuate. The female passengers were also priotized first in the evacuation. I am not sure the order of evacuation, but it is very logical to claim kids & teens first, female passengers and other 1st class passengers followed by just looking at data. \n\nThe greater insights are drawn so far, however, one problme arises which is there is no clear pattern behind the survivors. In other words, it is puzzling that the 1st class's trend does not apply to other classes. If this applys to all classes, it is very logical to conclude that the surviving rate decreases as a passenger's age gets old. Yet, this is not true in this dataset, thus a further investigation is required to build the ML and the narrative that can capture the whole stroy behind the data. \n\nNext Question: What is the relationship between Survival and familiy structural data?","f0e5fe39":"# Imputation 2nd","c832a6ff":"# ML2","6020f02d":"# Interpretation\n   \nThe more passengers were borded on 3rd class. Male population is twice larger. The age 20-30 is the largest population in both male and female. Importantly, the survivors are concentrated in the 1st class. However, when you consider the age, survivors are randomly distributed.\n\nThose graphs are very powerful and revealing, yet i need more precious insights. Thus, I try to make that vizualizations into numerical form in order to further extract insights.","dce248f4":"# Sibsp \/ Parchi\/ Name","0b7f941e":"# **Next**\n   \n   The dataset for ML is ready!! For next, I will figure out any relations and attributions of data. \n   Since the encoded variabels are small, OneHotEncoding might bring a higer accuracy.\n","098927a5":"# Pclass","d7795ed9":"* Age","76115c2f":"# Prepare the dataset\n* Explore the dataset\n* Finding Missing Values\n* Replacing it","df07392b":"Parch","71dca854":"Imputation is Done!!\nNext step will be encoding!","efc88637":"# Thank you\n\n\nThank you taking a look at my work. If you have any comments \/ advices, please leave the comment in this notebook!!","44980e32":"In terms of family this is totally different distribution. Since the family indicates that both siblings and the family, it might be misleading that parents with around early 20 has kids of 20. Thus if I can furhter classify the family strucutures into C(kids) and F (family) at first. This might be tedious but I will slice the Dataset based on the Surname. ","22861fbf":"# #2 Discussion\n\n\n\nUnfortunately, I could not find any clear patterns of the family strucutures and survival. This is due to a lack of skill. For a further improvment, I should use another algorithms other than the RandomForestClassifier or XGBClassifier. By using differnt algorithms, it might be a good idea to test a family survival pattern and other variables (Fare, Cabin).","d157d325":"# ****Interpretation (Pclass)****\n\nMore than half of passengers were borded on 3rd class which is a half of the total population. More specifically, 55% of total passengers were borded on 3rd class, 21% of passengers on 2nd, and 24% on the 1st class. Though, the survivors distribution is totally different. Although the 3rd class is the most populated class, a 3rd class passenger's surviving rate is just 24.2%. The 1st class passeger's survival rate is 2.6 greater than the 3rd class rate.\n\nThe key take away is that the surviving rate significantly varies depending on the passenger class. One possible narrative is that the 1st class passengers were privileged to evacuate first, it pushes up the surviving rate much higher than other two classes. Based on these take aways, Pclass is the influential variable in predicting surivers. ","37b34925":"# Interpretation (SibSp\/Parch)[1\/2]\n\nBased on the graphs above which show the relationship between # of siblings or spouses and survival, less the SibSp are, higher the survival rate is. For the parch, there is a similar trend in survial, but one thing is diffenrent which is Parch of 3 is the highest. However, I am not sure this is becuase of gender influence since the survivors of Parch[3] is all females. I cannot distinguish the effect of internal factors (Age,Sex), I conclude SibSp and Parch seems no direct relation with the survival. \n\n\nThis is rather unexpected. I was excpeting something like as the number of siblings goes up, more likey they survive. It was just an assumption and wrong, but I will try to further dig family strucutures down for getting further insights by increasing the complexity. \n","f2aa6224":"Family\n* F: With Family\n* S: Single","ccb6d986":"# Key Findings\n\nAfter reviewing data, several key findings have been revealed.\n* Kids \/ Teens are more likely rescued\n* Female passengers regardless of a passenger class also have a higher survivial rate\n* 3rd class is the most neglected class\n* Family Passenger is also more likely to survive\n\nBased on those key findings, the decision making process during this accident is revealed. Since the life-boat is not enough for all passengers, potential survivors are also accordingly limited. Thus, passengers needed to choose who are on the boat first. People (I guess the staff) priotized females, kids and Teens first in the evacuation. After that, they allowed 1st class and family passengers to borad. As a result, even though the 3rd class is most populated class, this decision led many people from 3rd class to death. Overall, many passengers were died as a result of this tragidic event, but I assume that passengers were rather rational at the evacuation becuase they save many vulnerable passengers (females and kids passengers) lives while they were facing the risk of death. ","28428598":"# Encoding of Categorical Valuables\n# \n1st: Use Label Encoding method (Simple and Easy to apply)\n    \nJust to remind. These are Categorical Variables(Name,Sex, Ticket, Cabin, Embarked). I will foucs on Sex and Embarked data for encoding because there is theoritically a correlation with Survival. \n  \n       \n","b9c63598":"# Questions\n\n* Do any variables have critical relation with Surivial?\n* Is there any trends and patterns among data?","200b50b7":"* Encoding2\n\n\n\n","89653ce5":"* Gender","0d84658a":"# #1 Discussion\n    \nJust looking at the heatmap,  Sex, Pclass, and Fare have a high correlation with values of -0.54, -0.34, and 0.26 respectively. It captures how strong the effect on the dependent variable (Survival) is. So, these data are certainly appeared as the most influencial variables in a prediction of Survival. \n\nThe age perhaps is deemed to be an important variable as well, although it is weakly correlated. Because the age itself has many associations with another data. It is rather unthinkable to decide the current mean (30) is the best estimation for missing values since this dataset has more information about the familiy strucures. Breaking age and  its associations down to a small pices might be able to reveal an unexpected useful insight which can be then utilized for improvements of the accuracy.\n\n\nThese are yet still assumptions. In later EDA section, I will investigate those data to prove that they are a great predictor. ","18024138":"# Dealing with the Missing Values","e15e85f5":"# Missing Values\n \nAge and Cabin are lacking a tremendous amount of data. Thus,it might be a good idea to drop especially Cabin. For age,on the other hand, we can make some calculations and find a potential value. Just for now, use mean for the imputation. For Embarked, since this is categrocial data, the mean can not be used. Thus, I will substitute nan values with most frequent data becuase it is more likely to appear. ","655e472b":"# ML5\n\nReduce the variable","33a4acab":"# WorkFlow\n\n\n\n1. Data Preparations\n\n    Since there is both numerical and categorical variables, I need to adjust all data  into numbers in order for comupters to understand\n    \n2. Explornatory Data Analysis (EDA)\n\n    After making adjustments of data, I will begin looking at data deeply in order to extract insights (correlation, and disributions)\n     \n3. Review of the process \/ Feature Selection\n\n    Once I could draw useful insights for a model, I will review the process for readjusting data based on EDA results. (Hopefully it improves the model accuracy)\n    \n4. Build the model","264ea7c5":"* Embarked","a5888aab":"Okay... A very similar distribution","7c79890b":"# Data Discription\nFrom the Titanic competiton page \n* Survived: (0 = dead, 1 = Survived)\n* Pclass: Ticket Class\n* Ticket: Ticket number\n* Sibsp: # of siblings \/ spouses aboard the Titanic\n* Parch: # of parents \/ children aboard the Titanic\n* Fare: Passenger fare\n* Embarked : Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\n* Categorical Variables: Name, Sex, Ticket, Cabin, Embarked\n* Numerical Variables  : Survived,PClass, Age, SibSp, Parch, Fare\n\nSo now, We understand a characteristic of Dataset. Next step will be finding and dealing with missing values\n","2aa0debf":"# ML Building","1cd431fa":"# **The Notebook for the 1st competition**\n\nSince I joined Kaggle, I learned several basic but very useful skills in Kaggle's courses. I found that the best way to bring those skills to next level is to participate competitions. In order to get used to the kaggle notebook system and to improve skills, I will first work on the Titanic competition.\n\n\n# The Goal of this competition\n - To predict the survivors from passengers by using the machine learning\n ","362c03ff":"# Data Exploration\n * Data Search\n * Distribution\n * Correlation\n \n \nFor now, I will use the train_imputed dataset","243e6c26":"Let's try to classify the family structures","0bd3de31":"Import the dataset","036b19ae":"* ML2","f267eff5":"# Interpretation (SibSp\/Parch)[2\/2]\n\nBased on what we have gotten from analyses, the passenger who has a family contains a higher survival rate. Passengers with family could survive in a 51% chance while singles were only a 30% chance in survial. Breaking survival rate deeper, one interesting insight has been able to take: almost half of survived family passengers were borded on the 1st class while the 3rd class family passengers were again neglected but the 3rd class is the most survived class among single passengers. \n\nFor a further exploration, find if I can cut down the family into his\/her title. I might be able to further extract insights from this dataset since the title can explain his\/her socio-economic status, this can furhter break family structure down to smaller pices.\n","d6b14252":"Just simplify the process of grouping. I will classify the passenger based on age. If the age is less than 20, a passenger is assigned C (Kids \/ Teen), and others as F. Kids and Teens have a high survival rate than other segments. But this does not solve any problem since I classify passengers based on age. So I will use this data to find any patterns. ","158e0c42":"# Further Exploration"}}