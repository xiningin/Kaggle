{"cell_type":{"6d235956":"code","d6511bae":"code","3ae2c83b":"code","063a9b2e":"code","46e99584":"code","43ae68be":"code","8feacbbd":"code","4e913bc2":"code","32201e99":"code","84941c6b":"code","09f16ba4":"code","b8e6e038":"code","bb98f412":"code","1ebdb725":"code","e43b76ed":"code","8aae7e34":"code","8a462377":"markdown","5f83c3de":"markdown","5bc3841b":"markdown","50f094d9":"markdown","9d56a4c9":"markdown"},"source":{"6d235956":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6511bae":"# Import Pandas\nimport pandas as pd\n\n# Loading Data sets\nfull_url='\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv'\n\nfull_url1='\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv'\n\ncredits = pd.read_csv(full_url)\nmovies=pd.read_csv(full_url1)","3ae2c83b":"# Printing 1st 5 elements of credits dataset\ncredits.head()","063a9b2e":"# Printing 1st 5 elements of movies dataset\nmovies.head(2)","46e99584":"# Printing the shapes of both the datasets\nprint(\"Credits:\",credits.shape)\nprint(\"Movies:\",movies.shape)","43ae68be":"# Renaming the column of credits data set\ncredits_renamed=credits.rename(index=str,columns={'movie_id':'id'})\ncredits_renamed.head()","8feacbbd":"# Merging both data sets\nmerge=movies.merge(credits_renamed,on='id')\nmerge.head()","4e913bc2":"# Dropping unnecessary columns \ncleaned=merge.drop(columns=['homepage','title_x','title_y','status','production_countries'])\ncleaned.head()","32201e99":"cleaned['overview'].head()","84941c6b":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,3),min_df=3,analyzer='word')\n\n#Replace NaN with an empty string\ncleaned['overview'] = cleaned['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(cleaned['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","09f16ba4":"from sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","b8e6e038":"print(cosine_sim.shape)\nprint(cosine_sim[1])","bb98f412":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(cleaned.index, index=cleaned['original_title']).drop_duplicates()\n","1ebdb725":"def get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return cleaned['original_title'].iloc[movie_indices]","e43b76ed":"# Getting the recommendation\nget_recommendations('Avatar')","8aae7e34":"get_recommendations('The Dark Knight Rises')","8a462377":" Myself [Kartik Gaglani](https:\/\/www.linkedin.com\/in\/kartik-gaglani-63bb2a186\/) along with [Amar Patel](https:\/\/www.linkedin.com\/in\/amarpatel69\/) are creating an ML based Recommendation Engine in collaboration with [Mr. Rocky Jagtiani](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/)\n \n> This is a simple Data Science project on Movies Recommendation System which recommends you the movie based on the Review of previous movie.\n\n> Dataset: tmdb_5000_credits.csv,tmdb_5000_movies.csv from kaggle itself\n\n> Tech Stack used: pandas, Scikit-learn,Python\n\n> Recommended links : \n\n> https:\/\/datascience.suvenconsultants.com  ( For DS \/ AI \/ ML )\n\n> https:\/\/monster.suvenconsultants.com  ( For Web development )","5f83c3de":"Recommender systems are among the most popular applications of data science today. They are used to predict the \"rating\" or \"preference\" that a user would give to an item. Almost every major tech company has applied them in some form. Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow.\n\nRecommender systems have also been developed to explore research articles and experts, collaborators, and financial services. ","5bc3841b":"I would like to humbly and sincerely thank my mentor [Rocky Jagtiani](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/). He is more of a friend to me then mentor. The Machine Learning course taught by him and various projects we did and are still doing is the best way to learn and skill in Data Science field. See https:\/\/datascience.suvenconsultants.com once for more.","50f094d9":"Here we are going to implement **Content Based Filtering**","9d56a4c9":"Recommender systems can be classified into Two types:\n\n> **Content-based recommenders**: suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person likes a particular item, he or she will also like an item that is similar to it. And to recommend that, it will make use of the user's past item metadata. A good example could be YouTube, where based on your history, it suggests you new videos that you could potentially watch.\n\n> **Collaborative filtering engines**: these systems are widely used, and they try to predict the rating or preference that a user would give an item-based on past ratings and preferences of other users. Collaborative filters do not require item metadata like its content-based counterparts."}}