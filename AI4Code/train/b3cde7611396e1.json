{"cell_type":{"cdce206f":"code","33b87a09":"code","38e493e1":"code","720b6d0b":"code","23aeb1a1":"code","7d42940a":"code","18e2ea43":"code","fee4f5bd":"code","2c956757":"code","a6dddf60":"code","bd6ca54c":"code","33627be0":"markdown","376f04b5":"markdown","9df0f2af":"markdown","0d69ad2a":"markdown","4bc1c30b":"markdown"},"source":{"cdce206f":"import os\nprint(os.listdir(\"..\/input\"))","33b87a09":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm","38e493e1":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","720b6d0b":"cols = list(train.columns)[2:]","23aeb1a1":"from sklearn.preprocessing import StandardScaler\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, BatchNormalization, Dropout, Flatten, Input\nfrom keras import backend as K\nimport keras\nfrom matplotlib.colors import LogNorm","7d42940a":"%%time\nss = StandardScaler(copy=False)\ndata_ss = ss.fit_transform(np.nan_to_num(train[cols].apply(lambda x: round(x, 2)).values))","18e2ea43":"n_features = data_ss.shape[1]\n\ndim = 15\n\ndef build_model(dropout_rate=0.15, activation='tanh'):\n    main_input = Input(shape=(n_features, ), name='main_input')\n    \n    x = Dense(dim*2, activation=activation)(main_input)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout_rate)(x)\n    \n    x = Dense(dim*2, activation=activation)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout_rate\/2)(x)\n    \n    x = Dense(dim, activation=activation)(x)\n    x = Dropout(dropout_rate\/4)(x)\n\n    encoded = Dense(2, activation='tanh')(x)\n\n    input_encoded = Input(shape=(2, ))\n    \n    x = Dense(dim, activation=activation)(input_encoded)\n    x = Dense(dim, activation=activation)(x)\n    x = Dense(dim*2, activation=activation)(x)\n    \n    decoded = x = Dense(n_features, activation='linear')(x)\n\n    encoder = Model(main_input, encoded, name=\"encoder\")\n    decoder = Model(input_encoded, decoded, name=\"decoder\")\n    autoencoder = Model(main_input, decoder(encoder(main_input)), name=\"autoencoder\")\n    return encoder, decoder, autoencoder\n\nK.clear_session()\nc_encoder, c_decoder, c_autoencoder = build_model()\nc_autoencoder.compile(optimizer='nadam', loss='mse')\n\nc_autoencoder.summary()","fee4f5bd":"%%time\nloss_history = []\nfor i in tqdm(range(20)):\n    epochs = 20\n    batch_size = 2048\n    history = c_autoencoder.fit(data_ss + np.random.normal(scale=0.01, size=data_ss.shape), data_ss,\n                        epochs=epochs,\n                        batch_size=batch_size,\n                            shuffle=True,\n                            verbose=0)\n    \n    loss_history += history.history['loss']\nplt.figure(figsize=(10, 5))\nplt.plot(loss_history);","2c956757":"%%time\nemb = c_encoder.predict(data_ss)","a6dddf60":"plt.figure(figsize=(10, 10))\nplt.hist2d(emb[:, 0], emb[:, 1], bins=256, norm=LogNorm());","bd6ca54c":"plt.figure(figsize=(10, 10))\nplt.scatter(emb[:, 0], emb[:, 1], marker='.', c=train['target'].values, alpha=0.1);","33627be0":"Hmmm...","376f04b5":"# Draw result\n## Density","9df0f2af":"# Make NN and train it","0d69ad2a":"It seems like here is small number of original variables, that combines into this dense rectangles. Wide empty lines can be interpreted like suffisient difference in some of original variable values, maybe categorical features.","4bc1c30b":"## Scatter plot colored by target"}}