{"cell_type":{"5e1c42f7":"code","1cecdad0":"code","f0471cc7":"code","819592b5":"code","db142930":"code","ac8666ec":"code","b5536d71":"code","50358cf4":"code","b0cc5b41":"code","6affa395":"code","e7b14169":"code","d1dee5b1":"code","76e9bbb0":"code","783b671b":"code","79949805":"code","39c4c928":"code","f0b41f14":"code","a058247f":"code","891625ad":"code","8c2d7ade":"code","7a43a1eb":"markdown","b9b17229":"markdown","1afb5459":"markdown","cb1a1253":"markdown","a8cd1f9f":"markdown","0ac5e29e":"markdown","63fc8dcb":"markdown","b9053582":"markdown","159df4ab":"markdown","22c8222a":"markdown","a404db49":"markdown","eddf65dc":"markdown","6ab516f2":"markdown","992ca4cd":"markdown"},"source":{"5e1c42f7":"# import required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n# import logistic regression model and accuracy_score metric\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, cohen_kappa_score\nfrom imblearn.over_sampling import SMOTE, SVMSMOTE","1cecdad0":"# Helper functions to compute and print metrics for classifier\ndef confusion_mat(y_true,y_pred, label='Confusion Matrix - Training Dataset'):\n    print(label)\n    cm = pd.crosstab(y_true, y_pred, rownames = ['True'],\n                  colnames = ['Predicted'], margins = True)\n    print(pd.crosstab(y_true, y_pred, rownames = ['True'],\n                  colnames = ['Predicted'], margins = True))\n    return cm\n\ndef metrics_clf(y_pred,y_true, print_metrics=True):\n    acc=accuracy_score(y_true, y_pred)\n    bal_acc=balanced_accuracy_score(y_true, y_pred)\n    f1 =f1_score(y_true, y_pred)\n    kappa = cohen_kappa_score(y_true, y_pred)\n    if print_metrics:\n        print(f'Accuracy score = {acc:.3f}\\n')\n        print(f'Balanced Accuracy score = {bal_acc:.3f}\\n')\n        print(f'F1 Accuracy score = {f1:.3f}\\n')\n        print(f'Cohen Kappa score = {kappa:.3f}\\n')\n    return (acc,bal_acc,f1, kappa)","f0471cc7":"# Show full output in cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity='all'","819592b5":"# Load data\ndata = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","db142930":"# Show five sampled records\ndata.sample(5)","ac8666ec":"# Show proportion of Classes\n# 1 means Fraud, 0 Normal\n_= data['Class'].value_counts().plot.bar(color=['coral', 'deepskyblue'])\ndata['Class'].value_counts()\nprint('Proportion of the classes in the data:\\n')\nprint(data['Class'].value_counts() \/ len(data))","b5536d71":"# Remove Time from data\ndata = data.drop(['Time'], axis = 1)\n# create X and y array for model split\nX = np.array(data[data.columns.difference(['Class'])])\ny = np.array(data['Class']).reshape(-1, 1)\nX\ny\n","50358cf4":"# split into training and testing datasets using stratify, i.e. same proportion class labels (0\/1) in training and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 2, shuffle = True, stratify = y)","b0cc5b41":"print('Proportion of the classes in training data:\\n')\nunique, counts = np.unique(y_train, return_counts=True)\nprint(f'\"{unique[0]}\": {counts[0]\/len(y_train):.3f}')\nprint(f'\"{unique[1]}\": {counts[1]\/len(y_train):.3f}')","6affa395":"print('Proportion of the classes in test data:\\n')\nunique, counts = np.unique(y_test, return_counts=True)\nprint(f'\"{unique[0]}\": {counts[0]\/len(y_test):.3f}')\nprint(f'\"{unique[1]}\": {counts[1]\/len(y_test):.3f}')","e7b14169":"# standardize the data\n# fit only on training data (to avoid data leakage)\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train=scaler.transform(X_train)\nX_test=scaler.transform(X_test)","d1dee5b1":"# Fit a simple Logistic regression model\nmodel_LR = LogisticRegression(solver = 'lbfgs')","76e9bbb0":"# fit the model\nmodel_LR.fit(X_train, y_train.ravel())\n\n# prediction for training dataset\ntrain_pred = model_LR .predict(X_train)\n\n# prediction for testing dataset\ntest_pred = model_LR.predict(X_test)","783b671b":"(acc_train, b_acc_train, f1_train, k_train)=metrics_clf(y_train,train_pred)\ncm_train=confusion_mat(y_train.ravel(),train_pred,'Confusion Matrix - Train Dataset (NO SMOTE)')","79949805":"(acc_test_sm, b_acc_test_sm, f1_test_sm, k_test_sm)=metrics_clf(y_test,test_pred)\ncm_test=confusion_mat(y_test.ravel(),test_pred,'Confusion Matrix - Test Dataset (NO SMOTE)')","39c4c928":"sm = SMOTE(random_state = 42, n_jobs=-1, sampling_strategy='minority')\n#sm= SVMSMOTE(random_state=42, k_neighbors=20, n_jobs=-1)","f0b41f14":"# generate balanced training data\n# test data is left untouched\nX_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())\n\n# observe that data has been balanced\nax = pd.Series(y_train_new).value_counts().plot.bar(title='Class distribution', y='Count',color=['coral', 'deepskyblue'])\n_= ax.set_ylabel('Count')","a058247f":"# fit the model on balanced training data\n_= model_LR.fit(X_train_new, y_train_new)\n\n# prediction for Training data\ntrain_pred_sm = model_LR.predict(X_train_new)\n\n# prediction for Testing data\ntest_pred_sm = model_LR.predict(X_test, )","891625ad":"(acc_test_sm, b_acc_test_sm, f1_test_sm, k_test_sm)=metrics_clf(y_train_new,train_pred_sm)\ncm_test=confusion_mat(y_train_new.ravel(),train_pred_sm,'Confusion Matrix - Train Dataset (SMOTE)')","8c2d7ade":"(acc_test_sm, b_acc_test_sm, f1_test_sm, k_test_sm)=metrics_clf(y_test,test_pred_sm)\ncm_test_sm=confusion_mat(y_test.ravel(),test_pred_sm,'Confusion Matrix - Test Dataset')","7a43a1eb":"## Logistic regression model","b9b17229":"* ## Metrics on Test (SMOTE)\n> ### On Test set metrics have worsen !!","1afb5459":"> Split data into Training and Test using stratify = Class return arrays with the same proportion of classes   \nalthough these are highly imbalanced (0.998 for \"0\" class and 0.002 for \"1\" class)!!","cb1a1253":"## Scale data","a8cd1f9f":"## Model with SMOTE (Synthetic Minority Oversampling Technique)\n[SMOTE parameters](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE)","0ac5e29e":"## Metrics on Training","63fc8dcb":"# Investigate SMOTE for a simple classifier for Fraud Detection   \n### This kernel is higly inspired from [Khyati Mahendru post on Medium](https:\/\/medium.com\/analytics-vidhya\/balance-your-data-using-smote-98e4d79fcddb)","b9053582":"## Metrics on Training (SMOTE)\n> ### NOTE how Accuracy is now almost equal to Balanced Accuracy, F1 and Cohen Kappa both improved","159df4ab":"# Load data","22c8222a":"## Metrics on Test","a404db49":"# SMOTE   \n**S**ynthetic **M**inority **O**versampling **TE**chnique   \n >This technique generates synthetic data for the minority class.\n SMOTE proceeds by joining the points of the minority class with line segments and then places artificial points on these lines.\n \nThe SMOTE algorithm works in 4 simple steps:\n\n1. Choose a minority class input vector\n2. Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n3. Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n4. Repeat the steps until data is balanced\n\nSMOTE is implemented in Python using the [imblearn](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/install.html) library   \n(to install use: `pip install -U imbalanced-learn`).   \n\nAdditional resources on SMOTE and related tasks:   \n\n[SMOTE oversampling](https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/)   \n\n[SMOTE docs & examples](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/auto_examples\/index.html)   \n\n[Tips for advanced feature engineering](https:\/\/towardsdatascience.com\/4-tips-for-advanced-feature-engineering-and-preprocessing-ec11575c09ea)\n","eddf65dc":"## Model without SMOTE","6ab516f2":"# Metrics analysis\nThis simple classifier show very high accuracy but this is not due to correct classification. \nThe model has predicted the majority class for almost all the examples (see confusion matrix),and being the majority class (\"0\" i.e. not fraud transaction) about 99.8% of total samples this leads to such high accuracy scores.\nMore significative metrics for imbalanced dataset are:\n1. F1 score\n2. Cohen Kappa\n3. Balanced accuracy\n\nFor a detailed article\/discussion to this metrics refer to [Which Evaluation Metric Should You Choose](https:\/\/neptune.ai\/blog\/f1-score-accuracy-roc-auc-pr-auc)","992ca4cd":"**Fraud Detection** is a dataset higly imbalanced as the vast majority of samples refer to non-fraud transactions.\n"}}