{"cell_type":{"3d61c2e2":"code","fdb722cd":"code","86c7097a":"code","99758727":"code","19a3a0c1":"code","efeab2cd":"code","44b0c3de":"code","95bcb3df":"code","91a18179":"code","ce77ead3":"code","fbf595cc":"code","ad5b5bfb":"code","2161e050":"code","4a728182":"code","c4f6bc73":"code","39020ac2":"code","28ba79e7":"markdown","2294596c":"markdown","ad74c71c":"markdown","097a2589":"markdown","9134126e":"markdown","b5262054":"markdown","78efd857":"markdown","98089a38":"markdown","3104f62d":"markdown","a59b46e1":"markdown","c0608126":"markdown","27900ba4":"markdown","fa65d93d":"markdown","9a11dabf":"markdown","8573278b":"markdown"},"source":{"3d61c2e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdb722cd":"mata_data1_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\"\nmata_data2_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\"\n","86c7097a":"meta_data1 = pd.read_csv(mata_data1_path)\nmeta_data2 = pd.read_csv(mata_data2_path)\n","99758727":"engagement_Path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \n\ntemp = []\n\nfor district in meta_data1.district_id.unique():\n    df = pd.read_csv(f'{engagement_Path}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \n    \nengagement_df = pd.concat(temp)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df","19a3a0c1":"engagement_df.isna()","efeab2cd":"missing_value=engagement_df.isna().sum()\nmissing_value","44b0c3de":"# Function to calculate missing values by column\ndef missing_values_table(df):\n    # Total missing values\n    mis_val = engagement_df.isnull().sum()\n\n    # Percentage of missing values\n    mis_val_percent = 100 * engagement_df.isnull().sum() \/ len(df)\n\n    # dtype of missing values\n    mis_val_dtype = engagement_df.dtypes\n\n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent, mis_val_dtype], axis=1)\n\n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values', 2: 'Dtype'})\n\n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n\n    # Print some summary information\n    print (\"Your selected dataframe has \" + str(engagement_df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) + \" columns that have missing values.\")\n\n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns\n\nprint(missing_values_table(engagement_df))","95bcb3df":"import pandas as pd\n\nclass Clean_data:\n    \n    def __init__(self, df:pd.DataFrame):\n        self.df = df\n        \n    def Fiil_value(self, df: pd.DataFrame) -> pd.DataFrame:\n\n        try:\n            #df.dropna()\n            df.fillna(0,inplace = True)\n            #df.replace(to_replace = np.nan, value = 0 )\n        except:\n            pass\n        \n        return df\n\n    def drop_value(self, df:pd.DataFrame)->pd.DataFrame:\n\n\n        try:\n            df = df[df.state.notna()].reset_index(drop=True)\n            for column in df.columns:\n                df[column].fillna(df[column].mode()[0], inplace=True)\n            #df.dropna()\n        except:\n            pass\n\n        return df\n    def duplicates(self, df:pd.DataFrame)->pd.DataFrame:\n        try:\n            df.drop_duplicates(inplace=True)\n            \n        except:\n            pass\n        \n        return df","91a18179":"clean_meta_data1= Clean_data(engagement_df)\ndf = clean_meta_data1.Fiil_value(engagement_df)\ndf.head()","ce77ead3":"mata_data1_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\"","fbf595cc":"district_data = pd.read_csv(mata_data1_path)\ndistrict_data","ad5b5bfb":"clean_meta_data1= Clean_data(district_data)\ndf = clean_meta_data1.drop_value(district_data)\ndf","2161e050":"mata_data2_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\"","4a728182":"product_df = pd.read_csv(mata_data2_path)\n#rename column to merge\nproduct_data1 = product_df.rename({'LP ID':'lp_id'}, axis=1)\n# product_df\nproduct_data1","c4f6bc73":"print(missing_values_table(product_data1))","39020ac2":"eng_dist_df = pd.merge(engagement_df,district_data, on = \"district_id\" )\neng_dist_pro_df = pd.merge(eng_dist_df,product_data1, on = \"lp_id\" )\neng_dist_pro_df ","28ba79e7":"**Fill Missing Values**","2294596c":"filing missing values with mode of the cloumn","ad74c71c":"**Processing Districts Data**","097a2589":"**Data Reading**","9134126e":"**Concatinating Engagement Data**","b5262054":"**Missing Values**","78efd857":"**Missing value treatment**","98089a38":"the District data contains the folowing columns \n* district_id\n* state\tlocale\n* pct_black\/hispanic\n* pct_free\/reduced\n* county_connections_ratio\n* pp_total_raw","3104f62d":"columns in Engagement Dataframe\n* time\n* lp_id\n* pct_access\n* engagement_index\n* district_id","a59b46e1":"**Processing Product Data**","c0608126":"**Missing Values With in the column**","27900ba4":"**Joining District_info and engagement datasets**","fa65d93d":"we have 0 missing value in product_info dataframe","9a11dabf":"**Processing Engegement Data**","8573278b":"**filling missing values with 0**"}}