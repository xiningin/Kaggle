{"cell_type":{"a4283963":"code","8aba53dd":"code","a0e7bfc4":"code","e328898c":"code","69e3eaef":"code","39cf1d4d":"code","fe722de1":"code","ae9ae308":"code","5b08707a":"code","d49cae33":"code","c4a1aa59":"code","67aa0615":"markdown","59ddef9c":"markdown","099f0d3d":"markdown","5c78f23f":"markdown","f4c42535":"markdown","a3d7ce2a":"markdown"},"source":{"a4283963":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport seaborn as sns\ncmap = sns.color_palette()\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8aba53dd":"assets = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/asset_details.csv\")\nassets.sort_values(\"Weight\", ascending=False)","a0e7bfc4":"assets[\"weight_percent\"] = (assets[\"Weight\"] \/ assets[\"Weight\"].sum()) * 100\nassets.sort_values(\"Weight\", ascending=False)","e328898c":"fig = px.pie(assets, values='weight_percent', names='Asset_Name', title='Weights assigned to each cryptocurrency')\nfig.show()","69e3eaef":"assets.columns","39cf1d4d":"asset_names_dict = {row[\"Asset_Name\"]:row[\"Asset_ID\"] for ind, row in assets.iterrows()}","fe722de1":"asset_names_dict","ae9ae308":"train = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/train.csv\")\ntrain.head()","5b08707a":"asset_names = [\n    'Bitcoin',\n    'Ethereum',\n    'Cardano',\n    'Binance Coin',\n    'Dogecoin',\n    'Bitcoin Cash',\n    'Litecoin',\n    'Ethereum Classic',\n    'Stellar',\n    'TRON',\n    'Monero',\n    'EOS.IO',\n    'IOTA',\n    'Maker'\n]\n\ntime_frame = []\nfor asset in asset_names:\n    #fetching the asset whose id is similar to any particular asset in that dataframe and gather into one dataframe\n#     print(coin_df)\n    coin_df = train[train[\"Asset_ID\"]==asset_names_dict[asset]].set_index(\"timestamp\")\n    start_time = coin_df.index[0].astype('datetime64[s]')\n#     print(start_time)\n    end_time = coin_df.index[-1].astype('datetime64[s]')\n#     print(end_time)\n    time_frame.append([asset, start_time, end_time])\ntime_df = pd.DataFrame(time_frame)\ntime_df.columns = [\"Asset_Name\", \"Start_Time\", \"End_Time\"]\ntime_df","d49cae33":"missing_list = []\nfor asset in asset_names:\n    coin_df =train[train[\"Asset_ID\"]==asset_names_dict[asset]].set_index(\"timestamp\")\n    missing_list.append([asset, coin_df.shape[0]] + coin_df.isna().sum().tolist())\nmissing_df = pd.DataFrame(missing_list)\nmissing_df.columns = [\"Asset_Name\", \"TotalRows\", 'Missing_Asset_ID', 'Missing_Count', 'Missing_Open', \n                      'Missing_High', 'Missing_Low', 'Missing_Close', 'Missing_Volume', 'Missing_VWAP', 'Missing_Target']\nmissing_df","c4a1aa59":"import gresearch_crypto\nenv = gresearch_crypto.make_env()\niter_test = env.iter_test()\n\ntrain_df = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/train.csv',usecols=['Target', 'Asset_ID','timestamp'], dtype={'Asset_ID': 'int8'})\ntrain_df['datetime'] = pd.to_datetime(train_df['timestamp'], unit='s')\ntrain_df = train_df.set_index('datetime').drop('timestamp', axis=1)\ntrain_df = train_df[(train_df.index.year == 2021) & (train_df.index.month > 5)]\ndfs = {asset_id: train_df[train_df['Asset_ID'] == asset_id].resample('1min').interpolate().copy() for asset_id in train_df['Asset_ID'].unique()}\ndel train_df\nfor df_test, df_pred in iter_test:\n    df_test['datetime'] = pd.to_datetime(df_test['timestamp'], unit='s')\n    for _, row in df_test.iterrows():\n        try:\n            df = dfs[row['Asset_ID']]\n            closest_train_sample = df.iloc[df.index.get_loc(row['datetime'], method='nearest')]\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = closest_train_sample['Target']\n        except:\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = 0\n    df_pred['Target'] = df_pred['Target'].fillna(0)\n    env.predict(df_pred)","67aa0615":"Get The Pie chart for above weight_percentage feature","59ddef9c":"Inference from above missing data Information:\n\n* There is a lot of missing data in the Target column\n* All the other columns do not have missing data\n* Bitcoin has the least number of missing target values and Monero the most.\n","099f0d3d":"Whole Distribution of weights of different assets into pie chart","5c78f23f":"Inference from above Observation:\n\n* The earliest start date in the data is Jan 1, 2018 and most coins have that start datetime.\n* The data is available till Sep 21, 2021 and all the coins have the same end datetime.\n* Dogecoin has the least historical information available of the given coins in the given data and it is captured only from April 2019 instead of others assets.","f4c42535":"Missing data\n","a3d7ce2a":"we can see here that weights column in assets_details will be used to get the weighted pearson correlation coefficient evaluation metric."}}