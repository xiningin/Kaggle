{"cell_type":{"5dec26b2":"code","afbf9a16":"code","7103f3c7":"code","8b36a640":"code","dfd99c61":"code","685e39d5":"code","eea44805":"code","c380b191":"code","8bebe36c":"code","15b6a4e2":"code","b3eb5488":"code","985c493d":"code","ed909204":"code","cbc5f6bb":"code","40978287":"code","6d8c875e":"code","50327da9":"code","1d209654":"code","1be1028e":"code","abe28b5c":"markdown","b815df32":"markdown","0895f322":"markdown","e18b9dab":"markdown","37661870":"markdown","f6b4c6c3":"markdown","d07a6fe9":"markdown"},"source":{"5dec26b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","afbf9a16":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder,OrdinalEncoder,PowerTransformer,StandardScaler,MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import IterativeImputer,SimpleImputer,KNNImputer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.feature_selection import SelectKBest,mutual_info_classif,RFECV\nfrom sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score ","7103f3c7":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv',index_col='PassengerId')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n\nx=train.drop('Survived',axis=1)\ny=train['Survived']\n\nsubmit=pd.DataFrame(test['PassengerId'])\ntest=test.set_index('PassengerId')","8b36a640":"print('Shape of train dataset-',train.shape)\nprint('Shape of valid dataset-',test.shape)\n\nprint('------------------------------------------------------------------------------>')\n\nprint(train.info())\n\nprint('------------------------------------------------------------------------------>')\n\nprint('Description of dataset->')\ntrain.describe()","dfd99c61":"sns.countplot(x='Sex',data=train,hue='Survived')\n\nprint('Just by observing the graph, it can be approximated that the survival rate of men is around 20% and that of women is around 75%.\\nTherefore, whether a passenger is a male or a female plays an important role in determining if one is going to survive.')","685e39d5":"group=train.groupby(['Pclass','Survived'])\npclass_survived = group.size().unstack()\nsns.heatmap(pclass_survived,annot=True,fmt='d')\n\nprint('\\nIt helps in determining if higher-class passengers had more survival rate than the lower class ones or vice versa. \\nClass 1 passengers have a higher survival chance compared to classes 2 and 3. \\nIt implies that Pclass contributes a lot to a passenger\u2019s survival rate.\\n')\n","eea44805":"sns.violinplot(y=train['Age'],x=train['Sex'],hue=train['Survived'],split=True)\n\nprint('\\nThis graph gives a summary of the age range of men, women and children who were saved.\\nThe survival rate is \u2013\\n')\nprint('-> Good for children\\n-> High for women in the age range 20-50.\\n-> Less for men as the age increases.')\n","c380b191":"train['family_group']=train['SibSp']+train['Parch']\ntest['family_group']=test['SibSp']+test['Parch']\n\ntrain['Alone']=0\ntrain.loc[train['family_group']==1,'Alone']=1\ntest['Alone']=0\ntest.loc[test['family_group']==1,'Alone']=1\n\nsns.factorplot(x='family_group',y='Survived',data=train)\nsns.factorplot(x='Alone',y='Survived',data=train)\n\n\nprint('\\n->Chance of survival is more with family member of less than 4\\n->And if a person is alone it has more chance to survive')","8bebe36c":"train['Fare_range']=pd.qcut(train['Fare'],4)\nsns.barplot(x=train['Fare_range'],y=train['Survived'])\nprint('People have higher chance of survival if fare is high\\n')","15b6a4e2":"train.drop(['Fare_range','Alone','family_group'],axis=1,inplace=True)","b3eb5488":"a=[]\nfor i in range(len(train['Name'])):\n    a.append(train['Name'].iloc[i].split(',')[1].split('.')[0])\ntrain['title']=a","985c493d":"train['title']=train['title'].replace([' Dr',' Rev',' Col',' Mlle',' Major',' Jonkheer',' Ms',' Capt',' Mme',' Lady',' Don',' the Countess',' Sir'],'Rare')\ntrain['title']=train['title'].replace({' Mr':1,' Mrs':2,' Miss':3,'Rare':4,' Master':5})","ed909204":"for i in range(len(train['Age'])):\n    if(pd.isnull(train['Age'].iloc[i])):\n        if(train['title'].iloc[i]==5):\n            train['Age'].iloc[i]=5\n        elif(train['title'].iloc[i]==4):\n            train['Age'].iloc[i]=44\n        elif(train['title'].iloc[i]==3):\n            train['Age'].iloc[i]=21\n        elif(train['title'].iloc[i]==2):\n            train['Age'].iloc[i]=35\n        else:\n            train['Age'].iloc[i]=30\n            ","cbc5f6bb":"for i in range(len(train['Fare'])):\n    if(pd.isnull(train['Cabin'].iloc[i])):\n        train['Cabin'].iloc[i]=0\n    else:\n        train['Cabin'].iloc[i]=train['Cabin'].iloc[i][0]\ntrain['Cabin']=train['Cabin'].replace({0:np.nan})","40978287":"for i in range(len(train)):\n    if(pd.isnull(train['Cabin'].iloc[i])):\n        if((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='C') and (train['Age'].iloc[i]>30 and train['Age'].iloc[i]<59)):\n            train['Cabin'].iloc[i]='A'\n        elif((train['Pclass'].iloc[i]==3) and (train['Embarked'].iloc[i]=='S') and (train['Age'].iloc[i]>1 and train['Age'].iloc[i]<45)):\n            train['Cabin'].iloc[i]='G'\n        elif((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='S') and (train['Age'].iloc[i]<59)):\n            train['Cabin'].iloc[i]='T'\n        elif((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='A') and (train['Fare'].iloc[i]>26 and train['Age'].iloc[i]<40)):\n            train['Cabin'].iloc[i]='A'\n        elif((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='S') and (train['Fare'].iloc[i]>42 and train['Age'].iloc[i]<170)):\n            train['Cabin'].iloc[i]='T'\n        elif((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='C') and (train['Fare'].iloc[i]>40 and train['Age'].iloc[i]<47)):\n            train['Cabin'].iloc[i]='A'\n        elif((train['Pclass'].iloc[i]==1) and (train['Embarked'].iloc[i]=='A') and (train['Fare'].iloc[i]>26 and train['Age'].iloc[i]<40)):\n            train['Cabin'].iloc[i]='A'","6d8c875e":"train=train.drop(['Ticket','Name'],axis=1)","50327da9":"train['Sex']=train['Sex'].replace({'male':0,'female':1})\ntrain['Cabin']=train['Cabin'].replace({'G':1,'C':2,'B':3,'E':4,'A':5,'T':5,'F':5,'D':5})\ntrain=pd.get_dummies(train,columns=['Embarked'],drop_first=True)\n\ntrain['Fare']=np.sqrt(train['Fare'])","1d209654":"x=train.drop('Survived',axis=1)\ny=train['Survived']","1be1028e":"for i in range(1,2):\n    pipeline=Pipeline(steps=[('impute',KNNImputer(n_neighbors=6)),('encode',StandardScaler()),('model',GradientBoostingClassifier())])\n    cv=RepeatedStratifiedKFold(n_repeats=10,n_splits=3,random_state=3)\n    score=cross_val_score(pipeline,x,y,cv=cv,scoring='accuracy',n_jobs=-1)\n    print(np.mean(score),i)","abe28b5c":"# Data Modelling","b815df32":"**1.Importing Modules using sklearn**","0895f322":"# 2.Data Visualization","e18b9dab":"# 1.Introduction","37661870":"# 3.Data Cleaning and Feature extraction","f6b4c6c3":"**3.Basic data description**","d07a6fe9":"\n\n----------------------------------------------------------------------------------------------------------------------------------------------\n**2.Dividing the dataset into train and validation**"}}