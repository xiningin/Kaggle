{"cell_type":{"fbfdb5b0":"code","4fe64090":"code","a729a9d7":"code","7787d68c":"code","bec3e9f9":"code","03ba56fa":"code","469e8510":"code","a0cfa145":"code","0f29ef59":"code","61b2b106":"code","a1104094":"code","2277998c":"code","e1ae40cc":"code","e0ded260":"code","c203969b":"code","e73532a1":"code","981a4cba":"code","258d30f9":"code","1a080c09":"code","dac32752":"code","840210c8":"code","9a6e40eb":"code","b9c653b3":"code","fc23bf8c":"code","7e52fc99":"code","f7f6ec4c":"code","6571329c":"code","301abb66":"code","f24b3f28":"code","8f521201":"code","28c5312c":"code","8d7eab97":"code","5f295188":"code","5664fa32":"code","f68a146a":"code","04e66439":"code","b13f9766":"code","14b57b91":"code","514e3322":"code","5c8bd0cf":"code","82b3052a":"code","d0eef19f":"code","2c9a9ede":"code","178265dc":"code","e709ce9a":"code","53b257c4":"code","43b3a10f":"code","d95b891b":"code","c558abe3":"code","f34387fe":"code","e62dadd8":"code","c007bfb0":"code","075f6de5":"code","db3b0d5f":"code","6c1a0e26":"code","82d2eddc":"code","d9382f39":"code","733cf6d7":"code","44c66a28":"code","1bd4a783":"code","ed07b02a":"code","753c66e2":"code","44cdfaf7":"code","9cb43ec6":"code","acdb8e36":"code","0b9e33cb":"code","c5b80257":"code","5cf21550":"code","7ba55e35":"code","d7d6ac71":"code","901f924e":"code","9c88d3ba":"code","bd6d15b0":"code","1ef4b606":"code","814f2119":"code","25657044":"code","5ed6e920":"code","d92f8ec7":"code","e18d3791":"code","b282cb7f":"code","39e8cdf4":"code","c1ab2f95":"code","4d18485e":"code","2766e041":"code","b2bde71c":"code","b865831d":"markdown","706955af":"markdown"},"source":{"fbfdb5b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport gc\ngc.collect()\n\n# Any results you write to the current directory are saved as output.","4fe64090":"!pip install pretrainedmodels\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n!pip install fastai==1.0.52\nimport fastai\nfastai.__version__\n\nfrom fastai import *\nfrom fastai.vision import *\n\nfrom torchvision.models import *\nimport pretrainedmodels\n\nfrom utils import *\nimport sys\n\nfrom fastai.callbacks.tracker import EarlyStoppingCallback\nfrom fastai.callbacks.tracker import SaveModelCallback\n\npath = Path('..\/input\/wiki-face-data\/wiki_crop\/wiki_crop\/')\npath.ls()","a729a9d7":"import fastai; fastai.__version__","7787d68c":"import scipy.io\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta","bec3e9f9":"mat = scipy.io.loadmat('..\/input\/wiki-face-data\/wiki_crop\/wiki_crop\/wiki.mat')\nmat","03ba56fa":"columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \n           \"face_score\", \"second_face_score\", 'celeb_names', 'celeb_id']","469e8510":"instances = mat['wiki'][0][0][0].shape[1]\n\ndf = pd.DataFrame(index = range(0,instances), columns = columns)","a0cfa145":"for i in mat:\n    if i == \"wiki\":\n        current_array = mat[i][0][0]\n        for j in range(len(current_array)):\n            #print(columns[j],\": \",current_array[j])\n            df[columns[j]] = pd.DataFrame(current_array[j][0])","0f29ef59":"df.head()","61b2b106":"df.shape","a1104094":"def datenum_to_datetime(datenum):\n    \n    try:\n        days = datenum % 1\n        hours = days % 1 * 24\n        minutes = hours % 1 * 60\n        seconds = minutes % 1 * 60\n        exact_date = datetime.fromordinal(int(datenum)) \\\n           + timedelta(days=int(days)) \\\n           + timedelta(hours=int(hours)) \\\n           + timedelta(minutes=int(minutes)) \\\n           + timedelta(seconds=round(seconds)) \\\n           - timedelta(days=366)\n    \n        return exact_date.year\n    \n    except(ValueError, TypeError, OverflowError):\n        \n        return np.nan  ","2277998c":"df['date_of_birth'] = df['dob'].apply(datenum_to_datetime) ","e1ae40cc":"df['date_of_birth'].value_counts()","e0ded260":"df['age'] = df['photo_taken'] - df['date_of_birth']\n\n#remove pictures does not include face\ndf = df[df['face_score'] != -np.inf]\n\n#some pictures include more than one face, remove them\ndf = df[df['second_face_score'].isna()]\n\n#check threshold\ndf = df[df['face_score'] >= 3.5]\n\ndf = df.drop(columns = ['name','face_score','second_face_score','date_of_birth','face_location'])\n\n#some guys seem to be greater than 100. some of these are paintings. remove these old guys\ndf = df[df['age'] <= 100]\n\n#some guys seem to be unborn in the data set\ndf = df[df['age'] > 0]","c203969b":"df.head()","e73532a1":"df.shape","981a4cba":"df['age'] = df['age'].apply(lambda x: int(x))","258d30f9":"print(type(df['age']))\ndf['age'].value_counts()","1a080c09":"df = df.drop(columns=['dob', 'photo_taken'])\ndf.head()","dac32752":"df_gender = df.drop(columns=['age', 'celeb_names', 'celeb_id'])\ndf_gender.head()","840210c8":"df_gender['gender'].value_counts()","9a6e40eb":"df_gender['full_path'] = df_gender['full_path'].str.get(0)","b9c653b3":"df_gender.dropna(axis=0, inplace=True)\ndf_gender.shape","fc23bf8c":"df_gender.head()","7e52fc99":"df_gender['gender'] = df_gender['gender'].map({0:'female', 1:'male'})","f7f6ec4c":"df_gender.head()","6571329c":"tfms = get_transforms(max_rotate= 10.,max_zoom=1., max_lighting=0.20, do_flip=False,\n                      max_warp=0., xtra_tfms=[flip_lr(), brightness(change=(0.3, 0.60), p=0.7), contrast(scale=(0.5, 2), p=0.7),\n                                              crop_pad(size=600, padding_mode='border', row_pct=0.,col_pct=0.),\n                                              rand_zoom(scale=(1.,1.5)), rand_crop(),\n                                              perspective_warp(magnitude=(-0.1,0.1)),\n                                              #jitter(magnitude=(-0.05,0.05), p=0.5),\n                                              symmetric_warp(magnitude=(-0.1,0.1)) ])\n\npath = Path('..\/input\/wiki-face-data\/wiki_crop\/wiki_crop\/')\n\nsrc = (ImageList.from_df(df_gender, path, cols=['full_path'], folder = '.')\n        .split_by_rand_pct(0.2)\n        .label_from_df())","301abb66":"data = (src.transform(tfms, resize_method=ResizeMethod.CROP, padding_mode='border', size=128)\n        .databunch(bs=64).normalize(imagenet_stats))","f24b3f28":"data.show_batch(6, figsize=(12,12))","8f521201":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pathlib import Path\nimport random","28c5312c":"def resnet50(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.resnet50(pretrained=pretrained)\n    return model","8d7eab97":"opt_func = partial(optim.Adam, betas=(0.9,0.99), eps=1e-5)","5f295188":"learn = cnn_learner(data, models.resnet50, \n                    metrics = accuracy, model_dir = \"\/temp\/model\/\", \n                    opt_func=opt_func, bn_wd=False,callback_fns=[ShowGraph]).mixup()","5664fa32":"learn.freeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion = True)","f68a146a":"lr = 5e-4","04e66439":"learn.fit_one_cycle(2, max_lr=slice(lr), wd=(1e-6, 1e-4, 1e-2), pct_start=0.5, callbacks=[SaveModelCallback(learn)])","b13f9766":"learn.save('first_head_resnet')\nlearn.load('first_head_resnet')","14b57b91":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion = True)","514e3322":"learn.fit_one_cycle(5, max_lr=slice(1e-5, lr\/5), wd=(1e-6, 1e-4, 1e-2), \n                    callbacks=[SaveModelCallback(learn)], pct_start=0.5)","5c8bd0cf":"learn.save('first_body_resnet')\nlearn.load('first_body_resnet')","82b3052a":"learn.show_results()","d0eef19f":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","2c9a9ede":"interp.plot_top_losses(9, figsize=(15,11))","178265dc":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","e709ce9a":"img = open_image('..\/input\/picture-1\/55632758_1035600193317551_7808214316078858240_n.jpg')\nimg","53b257c4":"learn.predict(img)","43b3a10f":"learn.summary","d95b891b":"print(learn.summary())","c558abe3":"data_big = (src.transform(tfms, size=256)\n        .databunch(num_workers=0).normalize(imagenet_stats))\n\nlearn.data = data_big\ndata_big.train_ds[0][0].shape","f34387fe":"learn.freeze_to(-1)\nlearn.lr_find()\nlearn.recorder.plot(suggestion = True)","e62dadd8":"lr=1e-3","c007bfb0":"learn.fit_one_cycle(2, max_lr=slice(lr), wd=(1e-6, 1e-4, 1e-2), pct_start=0.5, callbacks=[SaveModelCallback(learn)])","075f6de5":"learn.save('second_head_resnet')\nlearn.load('second_head_resnet')","db3b0d5f":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion = True)","6c1a0e26":"learn.fit_one_cycle(5, max_lr=slice(1e-6,1e-4), wd=(1e-6, 1e-4, 1e-2), callbacks=[SaveModelCallback(learn)], pct_start=0.5)","82d2eddc":"learn.save('second_body_resnet')\nlearn.load('second_body_resnet')","d9382f39":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","733cf6d7":"learn.show_results()","44c66a28":"interp.plot_top_losses(9, figsize=(15,11))","1bd4a783":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","ed07b02a":"class SaveFeatures():\n    features=None\n    def __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n        self.features = None\n    def hook_fn(self, module, input, output): \n        out = output.detach().cpu().numpy()\n        if isinstance(self.features, type(None)):\n            self.features = out\n        else:\n            self.features = np.row_stack((self.features, out))\n    def remove(self): \n        self.hook.remove()","753c66e2":"learn.model","44cdfaf7":"# Second last layer of the model\nlearn.model[1][4]","9cb43ec6":"len(data_big.train_ds.items), len(data_big.valid_ds.items)","acdb8e36":"sf = SaveFeatures(learn.model[1][4])","0b9e33cb":"_= learn.get_preds(data_big.train_ds)\n_= learn.get_preds(DatasetType.Valid)","c5b80257":"len(sf.features)","5cf21550":"type(sf.features)","7ba55e35":"img_path = [str(x) for x in (list(data_big.train_ds.items) +list(data_big.valid_ds.items))]\nlabel = [data_big.classes[x] for x in (list(data_big.train_ds.y.items) +list(data_big.valid_ds.y.items))]\nlabel_id = [x for x in (list(data_big.train_ds.y.items) +list(data_big.valid_ds.y.items))]","d7d6ac71":"df_new = pd.DataFrame({'img_path': img_path, 'label': label, 'label_id': label_id})\ndf_new","901f924e":"array = np.array(sf.features)","9c88d3ba":"x=array.tolist()","bd6d15b0":"df_new['img_repr'] = x","1ef4b606":"df_new","814f2119":"df_new.shape","25657044":"df_new","5ed6e920":"from annoy import AnnoyIndex\n\nf = len(df_new['img_repr'][0])\nt = AnnoyIndex(f, metric='euclidean')","d92f8ec7":"ntree = 100\n\nfor i, vector in enumerate(df_new['img_repr']):\n    t.add_item(i, vector)\n_  = t.build(ntree)","e18d3791":"import time\ndef get_similar_images_annoy(img_index):\n    start = time.time()\n    base_img_id, base_vector, base_label  = df_new.iloc[img_index, [0,3,1]]\n    similar_img_ids = t.get_nns_by_item(img_index, 8)\n    end = time.time()\n    print(f'{(end - start) * 1000} ms')\n    return base_img_id, base_label, df_new.iloc[similar_img_ids]","b282cb7f":"base_image, base_label, similar_images_df = get_similar_images_annoy(500)","39e8cdf4":"print(base_label)\nopen_image(base_image)","c1ab2f95":"similar_images_df","4d18485e":"def show_similar_images(similar_images_df):\n    images = [open_image(img_id) for img_id in similar_images_df['img_path']]\n    categories = [learn.data.train_ds.y.reconstruct(y) for y in similar_images_df['label_id']]\n    return learn.data.show_xys(images, categories)","2766e041":"show_similar_images(similar_images_df)","b2bde71c":"learn.save(\"\/kaggle\/working\/gender-pred-wiki\")\nfrom IPython.display import FileLinks\nFileLinks('.')","b865831d":"# Using Annoy","706955af":"# Fastai Hooks - Image Similarity Search"}}