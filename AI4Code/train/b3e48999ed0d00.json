{"cell_type":{"6dff9dfe":"code","d60523fe":"code","360f8eba":"code","454e385a":"code","cc7b6bce":"code","ed20f439":"code","636195aa":"code","8ce4d27f":"code","3438383b":"code","766e139a":"code","d4016cca":"code","9d7ba229":"code","f429f9c1":"code","0efb7cac":"code","e1042391":"code","7b6a78bb":"code","1190fcde":"code","cdf116be":"code","cf0b5eee":"code","c46ac013":"code","e23015ff":"code","47b23923":"code","6dc1e303":"code","1111f461":"code","3922bdfa":"code","013f8c2f":"code","95343643":"markdown","b7515ca6":"markdown","05a439d0":"markdown","1226aeda":"markdown","531d98c4":"markdown","f77fada8":"markdown","d76eeb2d":"markdown","c7df6d00":"markdown","99d3c27a":"markdown"},"source":{"6dff9dfe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nimport seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.model_selection import StratifiedKFold","d60523fe":"train = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsample_sub = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")","360f8eba":"# looking at the shape of dataset\ntrain.shape , test.shape , sample_sub.shape","454e385a":"train.head()","cc7b6bce":"train.describe()","ed20f439":"train.info()","636195aa":"# Finding null values \/ Missing values\ntrain.isnull().sum().sum()","8ce4d27f":"# Compute the correlation matrix\ncorr = train.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","3438383b":"cols = ['f'+str(i) for i in range(100)]","766e139a":"# plot the first 32 features \ni = 1\nplt.figure()\nfig, ax = plt.subplots(8, 4,figsize=(20, 22))\nfor feature in cols[:32]:\n    plt.subplot(8, 4,i)\n    sns.histplot(train[feature],color=\"blue\", kde=True,bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True,bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","d4016cca":"sns.catplot(x=\"target\", kind=\"count\", palette=\"ch:.25\", data=train)","9d7ba229":"## Target distibution\npie, ax = plt.subplots(figsize=[18,8])\ntrain.groupby('target').size().plot(kind='pie',autopct='%.1f',ax=ax,title='Target distibution')","f429f9c1":"# Train test split\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.2\ntrain,validation = train_test_split(train, test_size  = test_size_val, random_state = random_state_val)","0efb7cac":"y_nm = 'target'\n\ndf_train_x = train.drop(y_nm, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(y_nm, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\n\ndf_test_x = test","e1042391":"num_cols = [col for col in df_train_x.columns if df_train_x[col].dtype in [\"float16\",\"float32\",\"float64\"]]\ncat_cols = [col for col in df_train_x.columns if df_train_x[col].dtype not in [\"float16\",\"float32\",\"float64\"]]","7b6a78bb":"y = train[\"target\"].copy()\n\nfor cols in cat_cols:\n    enc = TargetEncoder(cols=[cols])\n    df_train_x = enc.fit_transform(df_train_x, y)\n    df_val_x = enc.transform(df_val_x)\n    df_test_x = enc.transform(df_test_x)","1190fcde":"scaler = QuantileTransformer()\nscaler.fit(df_train_x)\ndf_train_x = pd.DataFrame(scaler.transform(df_train_x))\ndf_val_x = pd.DataFrame(scaler.transform(df_val_x))\ndf_test_x = pd.DataFrame(scaler.transform(df_test_x))","cdf116be":"XGBClassifier = xgb.XGBClassifier(max_depth = 8,\n                                 learning_rate = 0.005,\n                                 n_estimators = 10000,\n                                 objective = 'binary:logistic',\n                                 tree_method = 'gpu_hist',\n                                 booster = 'gbtree',\n                                 gamma = 0.64,\n                                 max_delta_step = 3,\n                                 min_child_weight = 7,\n                                 subsample = 0.7,\n                                 colsample_bytree = 0.8,\n                                 n_jobs = -1\n                                 )","cf0b5eee":"start = datetime.datetime.now()\nxgb = XGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)], \n                       eval_metric = 'auc',\n                       early_stopping_rounds = 15,\n                       verbose = True)\nend = datetime.datetime.now()\nend-start","c46ac013":"fi_vals = xgb.get_booster().get_score(importance_type = 'weight')\nfi_dict = {df_train_x.columns[i]:float(fi_vals.get('f'+str(i),0.)) for i in range(len(df_train_x.columns))}\nfeature_importance_ = sorted(fi_dict.items(), key=operator.itemgetter(1), reverse=True)\nfeature_importance_result = OrderedDict(feature_importance_)\n\nimportance = pd.DataFrame(feature_importance_)\nimportance.columns = ['feature','weight']\nimportance.head(10)","e23015ff":"importance_ten = importance[:10]\nimportance_ten.set_index('feature').sort_values(by='weight').plot(kind='barh', figsize=(5, 5))","47b23923":"fpr, tpr, _ = roc_curve(df_val_y, xgb.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_roc_auc =0.\nopt_threshold =0.\nval_y_prob = xgb.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,50):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_roc_auc <= roc_auc:\n        max_roc_auc = roc_auc\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max roc_auc =%f, optimized_threshold=%f'%(max_roc_auc, opt_threshold))\nprint('Complete')","6dc1e303":"predict_xgb = xgb.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_xgb > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","1111f461":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_xgb)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","3922bdfa":"pred_test = xgb.predict_proba(df_test_x.values)[:,1]\n\ntest_result= pd.DataFrame(pred_test)\ntest_result.columns = ['target']\npredict = test_result['target']\nId_No = test['id']\nsubmission = pd.DataFrame({'id': Id_No, 'target': predict})\nsubmission['target'] = submission['target'].astype('float32')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","013f8c2f":"print(\"Up Vote if you like the Code\")","95343643":"## Model XGB Classifier","b7515ca6":"## Trellis plots","05a439d0":"## ROC Curve","1226aeda":"## Target Feature Distribution","531d98c4":"## Corelation matrix","f77fada8":"## Loading datasets","d76eeb2d":"## 10 Most important features","c7df6d00":"## Normalize data","99d3c27a":"### Transformation of Data"}}