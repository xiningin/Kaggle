{"cell_type":{"61415461":"code","3cc25966":"code","04a84b59":"code","638b3d3e":"code","64e56e74":"code","a43f1681":"code","ea99fa80":"code","b40362a6":"code","6322e9aa":"code","5608a938":"code","6708f87b":"code","d621a196":"code","aa1f4451":"code","52e7c67e":"code","958d63ed":"code","7c73637e":"code","8b2ec126":"code","40ff8813":"code","86feb72f":"code","8fea7314":"code","8f1ec1d9":"code","b60763a2":"code","fa5420ce":"code","cfcaabbc":"code","19928c2b":"code","9738c3e7":"code","ecbf6cf9":"code","aec2343e":"code","86121e9e":"code","e5f34c9e":"code","e9187d6f":"code","b8074573":"code","82437925":"markdown","b22d854d":"markdown","d006fff1":"markdown","0b40067b":"markdown","8420d7de":"markdown","44e2d647":"markdown","e28bdefc":"markdown","39faabd9":"markdown","0d4b7e42":"markdown","e9d00728":"markdown","cbe77db3":"markdown","cd4f337d":"markdown","b7a5c0ca":"markdown","61998c76":"markdown","c3a9c660":"markdown","9321ad53":"markdown","0f30c500":"markdown","71139a98":"markdown","fb4afc28":"markdown","46b13587":"markdown","25a2d97b":"markdown","0df08cdb":"markdown","9adffd8e":"markdown","61323b78":"markdown","17653075":"markdown","080b8ca3":"markdown","5dc5b38d":"markdown","3570e763":"markdown","ed90bde7":"markdown"},"source":{"61415461":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Libraries\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline","3cc25966":"data = pd.read_csv('..\/input\/credit-card-customers\/BankChurners.csv')\ndata.head()","04a84b59":"# print the shape of the data\nprint('Data has {} samples and {} features.'.format(data.shape[0], data.shape[1]))","638b3d3e":"data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n          'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n          'CLIENTNUM'], axis = 1, inplace = True)","64e56e74":"print('Number of missing values by column:')\ndata.isna().sum()","a43f1681":"#  Remove rows with Unknown data\ndata = data.mask(data.eq('Unknown')).dropna()\nprint('After filtration {} remains for anlysis'.format(data.shape[0]))","ea99fa80":"data.rename(columns = {'Attrition_Flag': 'Status', 'Customer_Age': 'Age', 'Education_Level' : 'Education'}, inplace = True)\ndata.head()","b40362a6":"# Review categories in Income_Category\ndisplay('Categories of incomes:',data['Income_Category'].value_counts())","6322e9aa":"# Replace the categories with labels which describes the level of income\nincome_categories_labels = {'Less than $40K' : 'low', '$40K - $60K' : 'medium',\n                            '$60K - $80K': 'above medium', '$80K - $120K':'high', '$120K +' : 'very high'}\ndata['Income_Category'] = data['Income_Category'].replace(income_categories_labels)\n# Display the counts of the the new income labels\ndata['Income_Category'].value_counts()","5608a938":"encoder = LabelEncoder()\ndata['Status'] = encoder.fit_transform(data['Status'])\ndata.head()","6708f87b":"# Get the median value for the aveage utilization rate\nutilization_ratio_median = data['Avg_Utilization_Ratio'].median()\n# Get mean value for both above and below median utilization ratio\nhigh_utilization_ratios_mean = data.query('Avg_Utilization_Ratio >= {}'.format(utilization_ratio_median))['Status'].mean()\nlow_utilization_ratios_mean = data.query('Avg_Utilization_Ratio < {}'.format(utilization_ratio_median))['Status'].mean()","d621a196":"plt.title('Comparing customers who continue to use service in realtion to average utilization rate')\nplt.bar(x = [1,2], height = [high_utilization_ratios_mean, low_utilization_ratios_mean],\n        tick_label = ['High average utilization', 'Low average utilization']);\nplt.ylabel('Number of existing customers')\nplt.show()","aa1f4451":"# Get categorical columns from dataframe\n\n# Categorical boolean mask\ncategorical_feature_mask = data.dtypes==object\n# filter categorical columns using mask and turn it into a list\ncategorical_cols = data.columns[categorical_feature_mask].tolist()","52e7c67e":"le = LabelEncoder()\ndata[categorical_cols] = data[categorical_cols].apply(lambda col: le.fit_transform(col))\ndata.head(10)","958d63ed":"num_subscribed, num_churned = data['Status'].value_counts()\n\n# Visualize the data set balance\nplt.title('Dataset balance')\nplt.bar(x = [1,2],\n        height = [num_subscribed, num_churned],\n        tick_label = ['Subscribed customers', 'Churned cusomers']);\nplt.ylabel('Customers')\nplt.show()","7c73637e":"# Drop target for data frame and assign results to x which will contain the feautres\nx = data.drop('Status', axis = 1)\n# Set the target values to new variable\ny = data['Status']","8b2ec126":"from imblearn.over_sampling import SMOTE\n# ovesmapling\nstrategy = {0:7000, 1:7000}\noversample = SMOTE(sampling_strategy=strategy)\nx, y = oversample.fit_resample(x, y)","40ff8813":"# Data splitting\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","86feb72f":"y_train_cat = tf.keras.utils.to_categorical(y_train, 2)\ny_test_cat = tf.keras.utils.to_categorical(y_test, 2)","8fea7314":"from sklearn.preprocessing import MinMaxScaler\ndef data_normalization(train_df, test_df):\n    scaler = MinMaxScaler()\n    # fitting the scaler to training data\n    scaler = scaler.fit(train_df)\n    # Transforming training and test data using scaler\n    train_df = scaler.transform(train_df)\n    test_df = scaler.transform(test_df)\n    return train_df, test_df\n\n# Applying normalization to data\nx_train, x_test = data_normalization(x_train, x_test)","8f1ec1d9":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators = 50) # Setting the number of estimators to 50 (After trial and error)\nclf.fit(x_train, y_train_cat) # Fitting the model using the training data\ny_pred = clf.predict(x_test) # Predicting whether the customer will leave the service or not using the model","b60763a2":"from sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test_cat, y_pred))","fa5420ce":"features = x.columns\nimportances = clf.feature_importances_\nindices = np.argsort(importances)[:]\nf, ax = plt.subplots(figsize=(7,5))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","cfcaabbc":"x = x.drop(['Card_Category', 'Gender', 'Marital_Status', 'Income_Category', 'Education'], axis = 1)","19928c2b":"# Resplitting the data \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n# Transforming y to categorical format \ny_train_cat = tf.keras.utils.to_categorical(y_train, 2)\ny_test_cat = tf.keras.utils.to_categorical(y_test, 2)","9738c3e7":"x_train, x_test = data_normalization(x_train, x_test)","ecbf6cf9":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', # Monitor the validation loss\n    patience=5) # Stop training if the monitored metric hasn't improved in 5 epochs.\n]","aec2343e":"classifier = tf.keras.models.Sequential(layers = None , name = None)\n# Input layer\nclassifier.add(tf.keras.layers.Input(shape = x_train.shape[1],))\n# Hidden layers\nclassifier.add(tf.keras.layers.Dense(units = 64 , activation = \"relu\" ))\nclassifier.add(tf.keras.layers.Dense(units = 32 , activation = \"relu\" ))\nclassifier.add(tf.keras.layers.Dense(units = 8 , activation = \"relu\" ))\n# Output layer\nclassifier.add(tf.keras.layers.Dense(units = 2 , activation = \"sigmoid\"))\nclassifier.summary()","86121e9e":"classifier.compile(optimizer = tf.keras.optimizers.Adam(1e-3),\n                   loss = 'categorical_crossentropy',\n                   metrics= ['accuracy'])","e5f34c9e":"history = classifier.fit(x_train, y_train_cat,\n                         batch_size= 16,\n                         epochs = 100,\n                         callbacks = callbacks,\n                         validation_data = (x_test,y_test_cat))","e9187d6f":"plt.plot(history.history['loss'], label='Traing loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.legend()\nplt.title('Loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.show()","b8074573":"plt.plot(history.history['accuracy'], label='Training accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuraccy')\nplt.legend()\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.show()","82437925":"### Rename colums\nReanming colums to be more insightful and shorter","b22d854d":"### Data cleaning\n#### Remove uncessary columns","d006fff1":"## Imports","0b40067b":"# Predict churning customers-Models comparison + EDA\n\nDisclamer: Still work in progress and all constructive feedback is much appreciated.","8420d7de":"## Explaratory data analysis\nExplore the data and provid insightful analysis\n\n### Does the credit card utilization ratio lower in churning customers?","44e2d647":"## Data warngling\n### Data importing","e28bdefc":"### Random forrest","39faabd9":"#### Encode <b>Status<\/b> column \nUse scikit's label encoder to encode the status (This project target value)","0d4b7e42":"#### Data normalization ","e9d00728":"## Machine learning models","cbe77db3":"#### Data normalization","cd4f337d":"No missing values were found but after using the data Unkown values were found.","b7a5c0ca":"#### Data oversampling","61998c76":"#### Transforming quality to categorical data","c3a9c660":"From this graph the ratio of people who continued using the services after having a lower average utilization is lower than those with higher ones. This could be a start to a statistical test to confirm these results.","9321ad53":"### Feature engineering\nTransform the feauture 'Income_Category' to represent diffrent income ranges in a more useful categorical format.","0f30c500":"From the visualization presented above the dataset is inbalancd which can lead the models to be biased towards the majority class, data oversamplying usinf SMOTE will be used to reduce the huge diffrence between the two classes.","71139a98":"Dropping the user Id and the Naive Bayes colums because they are not relevant to this analysis.","fb4afc28":"#### Feature importance analysis using the Random forrest model ","46b13587":"### Data preprocessing\nData prepartion includes using LabelEncoder to encode categorical data and values normalization.\n#### label encoding","25a2d97b":"#### Data splitting","0df08cdb":"#### Dropping five least important feature to improve performance","9adffd8e":"### Checking for missing values","61323b78":"#### Splitting the data","17653075":"#### Callbacks\nCallbacks help to best monitor the model and taking actions during training.<br>\nThe example which used in this small project is **EarlyStopping** which helps stop the training if a certain metric or the loss hasn't imropved or sevral epochs.<br>\nCallbacks are added to the model in the fit function.","080b8ca3":"## Intoduction\nIn this notebook contains a data analysis on the credit card customers data to draw infrences on the churning customers behaviors before they cancel thier credit cards. Then random forrest algorithm and a neural network will be used to classify the customers as Current customers (Customers who did not cancel there credit cards) and churning customers (Customers who cancelled their credit cards). \nThe random forrest will be used to analyse the importance of each feature and the fie least important features will be removed before trining neural network.\nA datasampling technique using SMOTE was introduced in version three to reduce gape between two classes\n\n<u>Data source:<\/u> https:\/\/www.kaggle.com\/sakshigoyal7\/credit-card-customers\n\n### Questions in the data analysis:\n1. Does the credit card utilization ratio lower in churning customers?\n2. What is the influence of the income category on people with a cetrain martial status for leaving the service?\n3. What card category customers needs most attention from the service providers?","5dc5b38d":"#### Get the accuracy of Rnadom forrest model based on testng data","3570e763":"### Neural netwok","ed90bde7":"The model will be tuned in the next versions and feature extraction will be added to the preprocessing phase. Also, more work on the data analysis will be added."}}