{"cell_type":{"81cf7302":"code","7c69fe33":"code","8c8d1a78":"code","e3f3eafc":"code","d624efaf":"code","46c09bb2":"code","8e17f946":"code","c757b071":"code","915f1b31":"code","aff83d95":"code","cc81e36a":"code","4130c1d6":"markdown","3e84e519":"markdown","8889238f":"markdown","ce655dae":"markdown","be325001":"markdown","f91108b9":"markdown","e7be7e37":"markdown","22dc6f65":"markdown","e0c33749":"markdown","3e796d55":"markdown","7a94401e":"markdown","10305c1e":"markdown","7accbffe":"markdown","4950c715":"markdown","972e9c6e":"markdown","5549f63b":"markdown","21a2f0be":"markdown","59d7e9eb":"markdown","cd3716cb":"markdown","0b1c963d":"markdown"},"source":{"81cf7302":"#Importing necessary library\nimport pandas as pd\nimport numpy as np\nimport requests\nfrom pandas_profiling import ProfileReport\n\nimport urllib.request\n\n#import the beatiful soup functions to parse the data\nfrom bs4 import BeautifulSoup\n\n# Any results you write to the current directory are saved as output.\nfrom IPython.display import display, Image\n\nimport math\n\ndisplay(Image(filename='\/kaggle\/input\/web-scraping-technique.jpg'))","7c69fe33":"URL = \"https:\/\/coronanepal.live\/\"\n#query the website\npage = requests.get(url = URL)\n\n#parse the html and store in Beautiful soup format\nsoup = BeautifulSoup(page.text)\n\n#find all links\nall_links = soup.find_all(\"a\")\nfor link in all_links:\n    pass\n    #print(link.get(\"href\"))\n    \n\n#find all tables\nall_tables = soup.find('table')\n\n#Uncomment Below line to get more sense of data\n#all_tables","8c8d1a78":"#Generate lists\nA = []\nB = []\nC = []\nD = []\nE = []\nF = []\n\nfor row in all_tables.findAll(\"tr\"):\n    cells = row.findAll('td')\n    \n    #Only extract table body\n    if(len(cells) == 6):\n        A.append(cells[0].find(text = True))\n        B.append(cells[1].find(text = True))\n        C.append(cells[2].find(text = True))\n        D.append(cells[3].find(text = True))\n        E.append(cells[4].find(text = True))\n        F.append(cells[5].find(text = True))","e3f3eafc":"#Creating Empty DataFrame\ndf = pd.DataFrame()\n\n#Creating columns and stroing value\ndf['\u091c\u093f\u0932\u094d\u0932\u093e'] = A\ndf['District'] = B\ndf['Confirmed Cases'] = C\ndf['\u0915\u0941\u0932 \u0938\u0902\u0915\u094d\u0930\u092e\u093f\u0924'] = D\ndf['\u091c\u092e\u094d\u092e\u093e \u092e\u0943\u0924\u094d\u092f\u0941'] = E\ndf['\u0928\u093f\u0915\u094b \u092d\u090f\u0915\u094b'] = F\n\n#Defining datatype for each column\ndf = df.astype({'\u091c\u093f\u0932\u094d\u0932\u093e':str,'District':str,'\u0915\u0941\u0932 \u0938\u0902\u0915\u094d\u0930\u092e\u093f\u0924':int,'\u091c\u092e\u094d\u092e\u093e \u092e\u0943\u0924\u094d\u092f\u0941':int, '\u0928\u093f\u0915\u094b \u092d\u090f\u0915\u094b':int})\n\n#Displaying the data\nfrom IPython.display import display, HTML\ndisplay(HTML(df.to_html()))","d624efaf":"URL = \"https:\/\/pomber.github.io\/covid19\/timeseries.json\"\n\n# sending get request and saving the response as response object \nr = requests.get(url = URL) \n\n# extracting data in json format \ndata = r.json() \n\n#It contains all countries data.Extracting data of only Nepal\nnepal_data = data['Nepal']\n\n#Uncomment below line to get more sense of Data\n#print(nepal_data)","46c09bb2":"date_list = []\nconfirmed_list = []\nrecovered_list = []\ndeath_list = []\n\nfor i in range(len(nepal_data)):\n    date_list.append(nepal_data[i]['date'])\n    confirmed_list.append(nepal_data[i]['confirmed'])\n    recovered_list.append(nepal_data[i]['recovered'])\n    death_list.append(nepal_data[i]['deaths'])","8e17f946":"#Creating empty DataFrame\nnepal_data_frame = pd.DataFrame()  \n\n#Putting data in column from list\nnepal_data_frame['Date'] = date_list\nnepal_data_frame['Confirmed'] = confirmed_list\nnepal_data_frame['Recovered'] = recovered_list\nnepal_data_frame['Death'] = death_list\n\n\n\nnepal_data_frame = nepal_data_frame.astype({'Confirmed':int, \"Recovered\":int})\n\n#Displaying the data\nfrom IPython.display import display, HTML\ndisplay(HTML(nepal_data_frame.to_html()))","c757b071":"#install library\n!pip install COVID19Py","915f1b31":"import COVID19Py\n\ncovid19 = COVID19Py.COVID19()","aff83d95":"data = covid19.getAll()\n\n#Uncomment below line to get sense of data\n#print(data)","cc81e36a":"latest = covid19.getLatest()\nprint(latest)","4130c1d6":"# Data Scraping\n\n**Data scraping, also known as web scraping, is the process of importing information from a website into a spreadsheet or local file saved on your computer. It's one of the most efficient ways to get data from the web, and in some cases to channel that data to another website.**","3e84e519":"**Making DataFrame from list**","8889238f":"# Extractind data from endpoint","ce655dae":"**Putting Extracted data in a list**","be325001":"**Check this notebook for Visualization part: https:\/\/www.kaggle.com\/milan400\/nepal-coronavirus-real-time-data-analysis**","f91108b9":"* We are going to use Library: 'COVID19Py'. It contains alot information regarding coronavirus of almost all countires.\n* Two data sources can be choosen: JHU and CSBS.\n* From my viewpoint it contains less accurate data and it is not updated timely like others.","e7be7e37":"**Installing Library**","22dc6f65":"**Getting all data at once**","e0c33749":"# Using Dedicated library","3e796d55":"* Another way to extract is through extracting data from Excel,CSV file. \n 1. Download the data \n 1. Read data using pandas(read_csv, read_excel)\n* Many other datas are in PDF file which can be extracted using \"tabula-py\".But it out of scope of this tutorial","7a94401e":"# Extracting data using Beautiful Soup","10305c1e":"**Extracting Table Data**","7accbffe":"Get more information using this library here: https:\/\/github.com\/Kamaropoulos\/COVID19Py","4950c715":"# 3 Ways of extracting data:\n1. Extracting data using Beautiful Soup\n1. Extractind data from endpoint\n1. Using dedicated library","972e9c6e":"**Extracting required data from JSON**","5549f63b":"* We are going to extract data from \"\"https:\/\/pomber.github.io\/covid19\/timeseries.json\". \n* It contains timeseries data. It contains confirmed, deaths, recovered cases of countries. Starting from \"2020-1-22\".\n* Data is in JSON format","21a2f0be":"We are going to scraping data from \"https:\/\/coronanepal.live\/\". It contains realtime data of Nepal regrading CoronaVirus. We are going to scrape \u091c\u093f\u0932\u094d\u0932\u093e, \u091c\u093f\u0932\u094d\u0932\u093e(in english), \u0915\u0941\u0932 \u0938\u0902\u0915\u094d\u0930\u092e\u093f\u0924,\u0915\u0941\u0932 \u0938\u0902\u0915\u094d\u0930\u092e\u093f\u0924(in English),\u091c\u092e\u094d\u092e\u093e \u092e\u0943\u0924\u094d\u092f\u0941, \u0928\u093f\u0915\u094b \u092d\u090f\u0915\u094b\n\n**For Non-Nepali Speakers:**\n\n* \u091c\u093f\u0932\u094d\u0932\u093e---------->District\n* \u0915\u0941\u0932 \u0938\u0902\u0915\u094d\u0930\u092e\u093f\u0924-----> Confirmed Cases\n* \u091c\u092e\u094d\u092e\u093e \u092e\u0943\u0924\u094d\u092f\u0941-------> Dead Case\n* \u0928\u093f\u0915\u094b \u092d\u090f\u0915\u094b------> Recovered Case","59d7e9eb":"**Getting latest amount of total confirmed cases, deaths, and recoveries**","cd3716cb":"**Putting Extracted Data in List**","0b1c963d":"**Creating DataFrame From List**"}}