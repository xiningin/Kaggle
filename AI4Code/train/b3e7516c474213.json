{"cell_type":{"7e5c1a01":"code","157a0606":"code","e605159a":"code","e0cfe65c":"code","a5a859af":"code","e23fa2e0":"code","3a43eeca":"code","d1376840":"code","7ac37507":"code","ab57ebb0":"code","5a00de85":"code","44d01ae8":"code","dc5cfbf8":"code","41ace297":"code","2556d37a":"code","e3a4a542":"code","0ecf50cf":"code","7aa61617":"code","cb55f1d5":"code","d39d92cd":"code","a469cfce":"code","847fd39b":"code","d5800352":"code","78ff2454":"code","e0a03aac":"code","cccb4a7b":"code","0a8c2a84":"code","24d8651f":"markdown","7231caf5":"markdown","4ca8e2d8":"markdown","9fbf8e4d":"markdown","7aa48389":"markdown","de20667d":"markdown","437581e1":"markdown","879fdf29":"markdown","a95b0a43":"markdown","6f4c49e8":"markdown","94033fb6":"markdown","2d089662":"markdown","b610d665":"markdown","47cd08c6":"markdown","ec6d2396":"markdown","1379cb17":"markdown","4efc7f00":"markdown","dbafaf8a":"markdown","6553bc1f":"markdown","011144fb":"markdown","4f7de086":"markdown","30a8cb06":"markdown","cd6fd7e9":"markdown","1f371082":"markdown","c2f755fc":"markdown","58a53f1b":"markdown","59387dd4":"markdown","4133649e":"markdown","831c74a5":"markdown","c7d4be2b":"markdown","cac6ddaa":"markdown","2beaa96b":"markdown","8a5ada2d":"markdown","6f869ccf":"markdown","ccfd32a3":"markdown","6360ccbb":"markdown"},"source":{"7e5c1a01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","157a0606":"clas = pd.read_csv('..\/input\/titanic\/data_cleaned.csv')\nclas.head()","e605159a":"clas.shape","e0cfe65c":"clas.info()","a5a859af":"x = clas.drop(['Survived'],axis=1)\ny = clas['Survived']\nx.shape,y.shape","e23fa2e0":"#Importing MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaled = scaler.fit_transform(x)","3a43eeca":"#Importing train_test_split function\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=12,stratify=y)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","d1376840":"#Importing the classifier and accuracy metrics\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.metrics import f1_score","7ac37507":"#Creating instance of KNN\nins = KNN(n_neighbors=9)\n\n#Fit model\nins.fit(x_train,y_train)\n\n#Predict model over test data\npredict= ins.predict(x_test)\nf1 = f1_score(predict,y_test)\nprint(\"The accuracy of f1_score = \",f1)","ab57ebb0":"def elbow(K):\n    #initialize an empty list\n    error=[]\n    \n    #train model for every K\n    for i in K:\n        #Instance of KNN\n        ins = KNN(n_neighbors=i)\n        ins.fit(x_train,y_train)\n        \n        #Appending the f1_scores to the empty list\n        predict= ins.predict(x_test)\n        f1 = f1_score(predict,y_test)\n        z = 1-f1\n        error.append(z)\n        \n    return error","5a00de85":"#Define the range of K after intervals\nk = range(5,30,2)","44d01ae8":"#Calling the elbow function\ntest = elbow(k)","dc5cfbf8":"plt.plot(k,test)\nplt.title(\"Elbow curve\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Test Error\")","41ace297":"#Creating instance of KNN\nins = KNN(n_neighbors = 5)\n\n#Fit model\nins.fit(x_train,y_train)\n\n#Predict model over test data\npredict= ins.predict(x_test)\nf1 = f1_score(predict,y_test)\nprint(\"Test f1_score = \",f1)","2556d37a":"reg = pd.read_csv('..\/input\/titanic\/train_cleaned.csv')\nreg.head()","e3a4a542":"reg.shape","0ecf50cf":"reg.info()","7aa61617":"X = reg.drop(['Item_Outlet_Sales'],axis=1)\nY = reg['Item_Outlet_Sales']\nX.shape,Y.shape","cb55f1d5":"scale = MinMaxScaler()\nx_scaled = scale.fit_transform(X)","d39d92cd":"X = pd.DataFrame(x_scaled)","a469cfce":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=32)\nX_train.shape,X_test.shape,Y_train.shape,Y_test.shape","847fd39b":"#Importing the regressor and accuracy metrics\nfrom sklearn.neighbors import KNeighborsRegressor as KNN\nfrom sklearn.metrics import mean_squared_error as mse\n#Creating instance of KNN\ns = KNN(n_neighbors=7)\n\n#Fit model\ns.fit(X_train,Y_train)\n\n#Predict model over test data\npred= s.predict(X_test)\ner = mse(pred,Y_test)\nprint(\"The accuracy of MSE score = \",er)","d5800352":"def elbow(p):\n    #initialize an empty list\n    errornew=[]\n    \n    #train model for every p\n    for i in p:\n        #Instance of KNN\n        s = KNN(n_neighbors=i)\n        s.fit(X_train,Y_train)\n        \n        #Appending the f1_scores to the empty list\n        pred= s.predict(X_test)\n        mean = mse(pred,Y_test)\n        mseer = 1-mean\n        errornew.append(mseer)\n        \n    return errornew","78ff2454":"#Define the range of K after intervals\np = range(5,20,2)","e0a03aac":"#Calling the elbow function\ntestnew = elbow(p)","cccb4a7b":"#Plotting the curves\nplt.plot(p,testnew)\nplt.title(\"Elbow curve\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Test Error\")","0a8c2a84":"#Creating instance of KNN\ns = KNN(n_neighbors=20)\n\n#Fit model\ns.fit(X_train,Y_train)\n\n#Predict model over test data\npred= s.predict(X_test)\ner = mse(pred,Y_test)\nprint(\"The MSE score = \",er)","24d8651f":"**Seperating the dependent anf independent variables**","7231caf5":"# Scaling the Data using MinMax Scaler","4ca8e2d8":"The stratify set to y determines the test labels are equally distributed in y as they are in x.","9fbf8e4d":"Reading the data from a dataframe.","7aa48389":"**Split the data into train and test data**","de20667d":"# Creating an elbow for least error regressor\n","437581e1":"The Mean Squared Error has considerably increased from 1514907.7 to 1589531.4.","879fdf29":"The data has no null values as such. ","a95b0a43":"The Titanic survivial dataset is used over here.","6f4c49e8":"Both x and y have the same number of observations and target column in the y dataframe.","94033fb6":"The range is set from 5 to 30 after alternate intervals.","2d089662":"# Scaling the Data using MinMax Scaler","b610d665":"# This notebook deals with KNN by classification technique on Titanic disaster dataset & KNN by Regression on Big Mart Sales Dataset with elbow method for obtaining the least test error in each case.","47cd08c6":"**Seperating target variable from the dataset.**","ec6d2396":"# Importing the KNN classifier\n\n\n\n\n\n","1379cb17":"Both x and y have the same number of observations and target column in the y dataframe.","4efc7f00":"We have 8523 observations with 46 features overall.","dbafaf8a":"For our random K = 9 neighbors , we observe f1_score = 0.56. Our objective is to get the lowest test error (1- f1_score) which can be done by the elbow curve.","6553bc1f":"The dataset has no column with null values.","011144fb":"Here we are using the Big Mart Sales Dataset.","4f7de086":"Importing the necessary libraries and warnings.","30a8cb06":"# Classification KNN","cd6fd7e9":"The minimum error is observed at K = 5.","1f371082":"We find the error is down to 0.4 as observed from the elbow curve as well.","c2f755fc":"The range is set from 5 to 20 at alternate intervals.","58a53f1b":"The data has 891 observations and 25 columns.","59387dd4":"The categorical columns have been preprocessed into continuous columns as per dummy coding.","4133649e":"# KNN Regression","831c74a5":"**Split the data into train and test data**","c7d4be2b":"**Convert into a dataframe**","cac6ddaa":"The minimum error is observed at K = 20.","2beaa96b":"# Creating an elbow for least error classifier","8a5ada2d":"Reading the data.","6f869ccf":"Plotting the curves","ccfd32a3":"# Importing the KNN classifier","6360ccbb":"Setting the classifier for K = 5."}}