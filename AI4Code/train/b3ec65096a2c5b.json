{"cell_type":{"2fcb9271":"code","69224354":"code","0947b5f7":"code","68128699":"code","0eb4e45c":"code","e43b858d":"code","fae1162d":"code","463781eb":"code","82d31a06":"code","f110a127":"code","8f613479":"code","eb79b94d":"code","5d6d5341":"code","f0143243":"code","b1dcb978":"code","2b2b76f7":"code","ceb46f28":"code","0fb40fd7":"code","8709739b":"code","37cb66a3":"code","2ee93511":"code","43dad05d":"code","9fd1bfca":"code","02c6a832":"code","d292a231":"code","c581a16e":"code","bd1f630b":"code","efc71a9a":"code","32aaa510":"code","9750dab0":"code","1dd5f4b1":"code","0394d00c":"code","b5f04140":"code","a3a36528":"code","3374a3fa":"markdown","70301035":"markdown","4fbec9e0":"markdown","d16621a2":"markdown","5cdadb7a":"markdown","e5784fe6":"markdown","23c60cd8":"markdown","018cfbfe":"markdown","46896c42":"markdown"},"source":{"2fcb9271":"# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","69224354":"%%time\n\nimport sys\n!cp ..\/input\/rapids\/rapids.0.12.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","0947b5f7":"import numpy as np\nimport pandas as pd\nimport pickle\nfrom datetime import datetime\nimport pytz\nimport feather\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nfrom pathlib import Path\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom hmmlearn.hmm import GaussianHMM\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nimport lightgbm as lgb\nfrom tqdm.notebook import tqdm\nfrom scipy.stats import mode\nfrom sklearn.metrics import accuracy_score\n# from cuml.neighbors import KNeighborsClassifier, NearestNeighbors\n# import cuml; cuml.__version__","68128699":"from cuml.neighbors import KNeighborsClassifier, NearestNeighbors\nimport cuml; cuml.__version__","0eb4e45c":"%%time\n\nNAME='KNN'\n\nNMINUS=3\nNPLUS=3\n\nweights=[4, 1, 0.5, 0.25, 1, 0.5, 0.25] # original, negative, positive\n\nNFOLDS=5\nRS=42\n\nPATH=Path('\/kaggle\/input\/is-eda-sine-50hz-exp')\n\nprint(f'Loading data for model {NAME}\\n')\n\ntrain=feather.read_dataframe(PATH\/'train.feather')\ntest=feather.read_dataframe(PATH\/'test.feather')\n\nwith open(PATH\/'folds_train.pickle', 'rb') as infile:\n    folds_train = pickle.load(infile)\n    \nwith open(PATH\/'folds_val.pickle', 'rb') as infile:\n    folds_val = pickle.load(infile)","e43b858d":"models=np.sort(train['model'].unique())\nmodels","fae1162d":"cols=['signal_no_drift']\ntarget=['open_channels']\n\nfor shift in range(1, NMINUS+1):\n    feature='signal_shift_-' + str(shift)\n    cols.append(feature)\n    \nfor shift in range(1, NPLUS+1):\n    feature='signal_shift_+' + str(shift)\n    cols.append(feature)\n    \nprint(f\"The list of features included in the {NAME} model:\\n\")\nprint(cols)","463781eb":"train=train[cols+target+['model', 'batch', 'time']]\ntest=test[cols+['model', 'batch', 'segment', 'time']]","82d31a06":"print(train.shape)\nprint(test.shape)","f110a127":"classes=np.array(['class_'+str(i) for i in range(11)])\noof=pd.DataFrame(data=np.zeros((len(train), 11)), index=train.index, columns=classes)\noof_preds=np.zeros(len(train))\npreds_proba=pd.DataFrame(data=np.zeros((len(test), 11)), index=test.index, columns=classes)\n\nf1_folds=[]","8f613479":"for c, w in zip(cols, weights):\n    train[c]=w*train[c]\n    test[c]=w*test[c]","eb79b94d":"%%time\n\nKNN=100\nbatch = 1024\n\nfor fold_num in range(1, NFOLDS+1):\n    \n    print('-'*50)\n    print(f'Fold {fold_num}:')\n    \n    train_index=folds_train[fold_num]\n    val_index=folds_val[fold_num]\n\n    X_train, Y_train = train.iloc[train_index, :], train.loc[train_index, target]\n    X_val, Y_val = train.iloc[val_index, :], train.loc[val_index, target]\n    \n    for m in models:   \n        \n#         if fold_num !=1:\n#             continue\n\n        mask_model_train=(X_train['model']==m)\n        mask_model_val=(X_val['model']==m)\n        mask_model_test=(test['model']==m)\n\n        X_mod=X_train.loc[mask_model_train, cols].values\n        Y_mod=Y_train[mask_model_train].values.reshape(-1,)\n        \n        X_val_mod=X_val.loc[mask_model_val, cols].values\n        Y_val_mod=Y_val[mask_model_val].values.reshape(-1,)\n        \n        X_test=test.loc[mask_model_test, cols].copy()\n        \n#         clf = KNeighborsClassifier(n_neighbors=KNN)\n        \n#         clf.fit(X_mod, Y_mod)\n            \n        #Y_val_pred=clf.predict_proba(X_val_mod)#.reshape(-1, 1))     \n        #Y_test_pred=clf.predict_proba(X_test.values)#.reshape(-1, 1))\n        \n        if m=='M4':\n            shift=1 # recall that we removed zero open channel from model 4\n        else:\n            shift=0\n        ##############################################\n        #KNN = 99\n        #batch = 1024\n        #print('Training...')\n        clf = NearestNeighbors(n_neighbors=KNN)\n        clf.fit(X_mod)\n        distances, indices = clf.kneighbors(X_val_mod)\n        #print('Processing validation set...')\n        ct = indices.shape[0]\n        pred = np.zeros((ct,KNN),dtype=np.int8)\n        Y_val_pred = np.zeros((ct,len(np.unique(Y_mod))),dtype=np.float32)\n        it = ct\/\/batch + int(ct%batch!=0)\n        for k in range(it):\n            a = batch*k; b = batch*(k+1); b = min(ct,b)\n            pred[a:b,:] = Y_mod[ indices[a:b].astype(int) ]\n            for j in np.unique(Y_mod):\n                Y_val_pred[a:b,j-shift] = np.sum(pred[a:b,]==j,axis=1)\/KNN\n        \n        ##############################################\n        #print('Processing test set...')\n        \n        distances, indices = clf.kneighbors(X_test.values)\n\n        ct = indices.shape[0]\n        pred = np.zeros((ct,KNN),dtype=np.int8)\n        Y_test_pred = np.zeros((ct,len(np.unique(Y_mod))),dtype=np.float32)\n        it = ct\/\/batch + int(ct%batch!=0)\n        for k in range(it):\n            a = batch*k; b = batch*(k+1); b = min(ct,b)\n            pred[a:b,:] = Y_mod[ indices[a:b].astype(int) ]\n            for j in np.unique(Y_mod):\n                Y_test_pred[a:b,j-shift] = np.sum(pred[a:b,]==j,axis=1)\/KNN\n        \n        ##############################################\n\n        classes_mod=classes[np.unique(Y_mod)]           \n        #print('oofs...')\n        oof.loc[val_index[mask_model_val], classes_mod]=Y_val_pred\n        #print('preds_probas...')\n        preds_proba.loc[mask_model_test, classes_mod]+=Y_test_pred\n        \n        # Compute Macro F1 score for the model:\n        \n        #print('Y_val_pred...')\n        Y_val_pred=np.argmax(Y_val_pred, axis=1).astype(int).reshape(-1, ) + int(shift)\n        #print('f1...')\n        f1_model=f1_score(Y_val_mod, Y_val_pred, average='macro')\n        print(f'Model {m}: done! Macro F1 score = {f1_model:.5f}')\n    \n    oof_preds[val_index]=np.argmax(oof.iloc[val_index, :].values, axis=1).astype(int).reshape(-1, )\n    Y_val_OC=train.loc[val_index, 'open_channels'].values.astype(np.uint8).reshape(-1, )\n    \n    f1_fold=f1_score(Y_val_OC, oof_preds[val_index], average='macro')\n    f1_folds.append(f1_fold)\n    \n    print(f'\\nFold {fold_num} is done! Macro F1 score = {f1_fold:.5f}')\n\npreds_proba\/=NFOLDS\npreds=np.argmax(preds_proba.values, axis=1).astype(int).reshape(-1, )\n\nprint('-'*50)\nprint('Summary:')\n\nfor m in models:\n    print(f\"\\nModel {m}:\")\n    mask_model=train['model']==m\n    f1_model=f1_score(train.loc[mask_model, 'open_channels'].values.reshape(-1,), \n                      oof_preds[mask_model], average='macro')\n    print(classification_report(train.loc[mask_model, 'open_channels'].values.reshape(-1,), \n                                oof_preds[mask_model], digits=5))\n    print(f'Macro F1 score for model {m}    = {f1_model:.5f}')\n\nf1_av=np.array(f1_folds).mean()\nf1_std=np.std(f1_folds)\nprint(f'Macro F1 score = {f1_av:.5f} (average across the folds); std = {f1_std:.5f}')\n\nf1=f1_score(train['open_channels'].values.reshape(-1,), oof_preds, average='macro')\n\nprint(f'Macro F1 score = {f1:.5f} (out-of-folds)')","5d6d5341":"for c, w in zip(cols, weights):\n    train[c]=train[c]\/w\n    test[c]=test[c]\/w","f0143243":"%%time\nprint(classification_report(train['open_channels'].values.reshape(-1,), oof_preds, digits=5))","b1dcb978":"%%time\n\n# hidden states vs open channels\nfig, ax = plt.subplots(5, 1, figsize=(10, 10*5))\nax = ax.flatten()\n\nfor i, m in enumerate(models): \n    mask=train['model']==m\n    cm = confusion_matrix(train.loc[mask, 'open_channels'].values, oof_preds[mask])\n    sns.heatmap(cm, annot=True, lw=1, ax=ax[i])\n    ax[i].set_xlabel(\"Predicted open channels\")\n    ax[i].set_ylabel(\"Actual open channels\")\n    ax[i].set_title(f\"Model {m}\")\nplt.tight_layout()\nplt.show()","2b2b76f7":"%%time\nPATH=Path('\/kaggle\/input\/is-gmm-cv5-b7-repl-seq-folds\/sub_GMM_110.csv')\npreds_GMM=pd.read_csv(PATH)\n\nmask_M1_GMM=(test['model']=='M1')&(preds_GMM['open_channels']>1)\npreds[mask_M1_GMM]=preds_GMM.loc[mask_M1_GMM, 'open_channels']","ceb46f28":"PATH=Path('\/kaggle\/input\/liverpool-ion-switching\/')\nsub=pd.read_csv(PATH\/'sample_submission.csv')","0fb40fd7":"sub['open_channels']=preds\nsub['open_channels'].value_counts().sort_index()","8709739b":"sub.shape","37cb66a3":"time_zone = pytz.timezone('America\/Chicago')\ncurrent_datetime = datetime.now(time_zone)\nts=current_datetime.strftime(\"%m%d%H%M%S\")\n\nsub_file_name='sub_'+NAME+'_'+ts+'.csv'\noof_file_name='oof_'+NAME+'.feather'#'_'+ts+'.csv'\npreds_file_name='preds_'+NAME+'.feather'#'_'+ts+'.csv'\n\nts, sub_file_name, oof_file_name, preds_file_name","2ee93511":"%%time\n\noof.to_feather(oof_file_name)\npreds_proba.to_feather(preds_file_name)\nsub.to_csv(sub_file_name, index=False, float_format='%.4f')","43dad05d":"%%time\n\npalette = sns.color_palette()\npalette=[(0, 0, 0)]+palette\nsns.palplot(palette)\nplt.xlabel('Open channels', fontsize=15)\nticks=np.arange(0, 11)\nplt.xticks(ticks, ticks, fontsize=12)\nplt.show()","9fd1bfca":"def plot_signal_vs_shifted_one(df, mod, target='open_channels', batch=None, segment=None, \n                               col1='signal_no_drift', col2='signal_shift_-1', s=0.05, mk_scale=60,\n                               low=math.floor(train['signal_no_drift'].min()),\n                               high=math.ceil(train['signal_no_drift'].max())):\n    \n    mask_model=df['model']==mod\n        \n    if batch is not None:\n        mask_batch=df['batch']==batch\n        mask_model=np.logical_and(mask_model, mask_batch)\n\n    if segment is not None:\n        if 'segment' not in df.columns:\n            print(\"There is no 'segment' column in the data frame! Can't continue!\")\n            return\n        else:           \n            mask_segment=df['segment']==segment\n            mask_model=np.logical_and(mask_model, mask_segment)               \n            \n    if target in df.columns:\n        mod_chans=np.unique(df.loc[mask_model, target].values)\n        for ch in mod_chans:\n            mask_channel=df[target]==ch\n            mask=np.logical_and(mask_model, mask_channel)\n            x=df.loc[mask, col1].values\n            y=df.loc[mask, col2].values\n            plt.plot(x, y, 'o', markersize=s, label=ch, c=palette[ch])\n            plt.legend(markerscale=mk_scale)\n    else:\n        x=df.loc[mask_model, col1].values\n        y=df.loc[mask_model, col2].values\n        plt.plot(x, y, 'o', markersize=s)        \n    \n    plt.xlim((low, high))\n    plt.ylim((low, high))\n    \n    plt.xlabel('Current now, pA')\n    plt.ylabel('Current next, pA')\n    \n    plot_title=f'Model {mod}'\n    if batch is not None:\n        plot_title+=f', batch {batch}'\n    if segment is not None:\n        plot_title+=f', {segment}'\n    plt.title(plot_title)","02c6a832":"def plot_signal_vs_shifted_all(df, mod, target='open_channels', hsize_one=5, \n                               s=0.05, mk_scale=60, n_cols=2, style='seaborn-whitegrid',\n                               col1='signal_no_drift', col2='signal_shift_-1',\n                               low=math.floor(train['signal_no_drift'].min()),\n                               high=math.ceil(train['signal_no_drift'].max()),):\n    \n    mask=df['model']==mod\n    \n    if 'segment' in df.columns:\n        segments=np.sort(df.loc[mask, 'segment'].unique())\n        batches=[None for i in range(len(segments))]\n    else:\n        batches=np.sort(df.loc[mask, 'batch'].unique())\n        segments=[None for i in range(len(batches))]\n    \n    hsize=n_cols*hsize_one\n    n_rows=math.ceil(len(batches) \/ n_cols)\n    vsize= n_rows*hsize_one\n    \n    plt.figure(figsize=(hsize, vsize))\n    plt.style.use(style)\n    \n    for i , (batch, segment) in enumerate(zip(batches, segments), 1):\n        plt.subplot(n_rows, n_cols, i)\n        plot_signal_vs_shifted_one(df, target=target, batch=batch, \n                                   segment=segment, mod=mod, s=s, \n                                   mk_scale=mk_scale,\n                                   low=low, high=high)\n        \n    plt.tight_layout()","d292a231":"low={'M1':-4, 'M2':-4, 'M3':-5, 'M4':-5, 'M5':-5}\nhigh={'M1':2, 'M2':0, 'M3':6, 'M4':10, 'M5':5}","c581a16e":"def show_results(preds, mod='M1', lag=-1, df=train, s=0.3, mk_scale=10):\n    df_new=df[['model', 'batch', 'signal_no_drift', 'signal_shift_'+str(lag)]].copy()\n    df_new['open_channels']=preds.astype(np.uint8)\n    if 'segment' in df.columns:\n        df_new['segment']=df['segment'].copy()\n    plot_signal_vs_shifted_all(df_new, mod, low=low[mod], high=high[mod], s=s, mk_scale=mk_scale)","bd1f630b":"for m in models:\n    show_results(oof_preds, mod=m, lag=-1, df=train, s=0.7, mk_scale=5)","efc71a9a":"y_true=train['open_channels'].values\n\nmask=np.equal(y_true, oof_preds)\nfor m in models:\n    show_results(y_true[~mask], mod=m, lag=-1, df=train[~mask], s=0.7, mk_scale=5)","32aaa510":"high['M1']=4","9750dab0":"for m in models:\n    show_results(preds, mod=m, lag=-1, df=test, s=0.7, mk_scale=5)","1dd5f4b1":"batches_order=np.array([0, 1, 2, 6, 3, 7, 4, 9, 5, 8])","0394d00c":"def signal_scatter_plots(df, col='signal', order=batches_order):\n    \n    n_batches=df['batch'].nunique()\n    \n    if n_batches==4:  # if test\n        vsize = 2\n        hsize = 2\n        fig_vsize=20\n        fig_hsize=40\n        name='test'\n        order=np.arange(4)\n    else:             # if train\n        vsize = 5\n        hsize = 2\n        fig_vsize=60\n        fig_hsize=40\n        name='train'\n    \n    plt.figure(figsize=(fig_hsize, fig_vsize), facecolor='white')\n    sns.set(font_scale=3.5)\n    \n    for i, b in enumerate(order):\n\n        ax = plt.subplot(vsize, hsize, i+1)\n        mask_batch=(df['batch'] == b)\n        \n        if np.isin(df.columns, 'open_channels').any():   \n            channels=np.unique(df.loc[mask_batch, 'open_channels'].values)\n            for ch in channels:\n                mask_channel=(df['open_channels']==ch)\n                mask=np.logical_and(mask_batch, mask_channel)\n                plt.plot(df.loc[mask, 'time'].values, df.loc[mask, col].values, \n                         'o', color=palette[ch], ms=0.6, label=ch)      \n            title_string='Signal vs time per batch in '\n            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n                       fontsize='36', markerscale=30)\n        else:\n            title_string='Signal vs time per batch in '\n            plt.plot(df.loc[mask_batch, 'time'].values, df.loc[mask_batch, col].values, \n                     'o', ms=0.1)\n\n        ax.set(xlabel='Time, s', ylabel='Current, pA', title= f'Batch {b}')\n\n    plt.suptitle(title_string + f'{name}', y=1.02)\n    plt.tight_layout()\n    plt.show()","b5f04140":"%%time\ntrain['open_channels']=oof_preds\ntrain['open_channels']=train['open_channels'].astype(np.uint8)\nsignal_scatter_plots(train, col='signal_no_drift')","a3a36528":"%%time\ntest['open_channels']=preds\ntest['open_channels']=test['open_channels'].astype(np.uint8)\nsignal_scatter_plots(test, col='signal_no_drift')","3374a3fa":"## Generating a submission file and saving oof's and predicted probabilities","70301035":"## Fixing Model 1\n\nModel 1 data in the train set contain only two possible open_channels values: 0 and 1. Graphical analysis of the test set has shown that there might be an additional channel present in Model 1 test set data. To identify the channels that are not in train earlier we used the Gaussian Mixture Model algorithm. Now, for `open_channels` of model M1 greater than 1, we will overwrite the our predictions with those of GMM.","4fbec9e0":"## Setting things up for training","d16621a2":"Multiply the original and shifted signal columns by their weights. ","5cdadb7a":"## Loading libraries","e5784fe6":"Reinstate the original values of the signals:","23c60cd8":"To get an idea about the accuracy of our results let's print a full classification report and also take a look at the confusion matricies for different models.","018cfbfe":"## Visualizing the results","46896c42":"## Training a KNN model"}}