{"cell_type":{"018ee08c":"code","0d2ec480":"code","d2ac0fff":"code","60214a46":"code","e1b165e7":"code","d1e1ff70":"code","9aa302a3":"code","f5692217":"code","224f72c9":"code","5a123c18":"code","d1200c78":"code","e211099c":"code","71e623e9":"code","88cc8949":"code","971c7719":"code","c0d71045":"code","a5ff245f":"code","e8750e07":"code","c2dae716":"code","4075007b":"code","6480d84a":"code","a74e4397":"code","c219b82b":"code","eca3732c":"code","acf196b4":"code","8c428127":"code","35804aad":"code","a64170b9":"code","e7aecacb":"code","37494482":"code","569fe181":"code","2f0db110":"code","0189162b":"code","55ccd26a":"code","de036473":"code","bead9f62":"code","1139c920":"code","284d02a0":"markdown","00c707e0":"markdown","6727799e":"markdown","a7bec66a":"markdown"},"source":{"018ee08c":"#Let's start with importing necessary libraries\n\nimport pandas as pd \nimport numpy as np \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nimport scikitplot as skl\nsns.set()\n%matplotlib inline\n","0d2ec480":"df = pd.read_csv('Dataset\/UCI_Credit_Card.csv')\ndf.rename(columns={'PAY_0':'PAY_1'},inplace=True)\ndf.rename(columns={'default.payment.next.month':'Defpay'},inplace=True)\n#train_set = df.iloc[0: , :]\ndf.head()","d2ac0fff":"df.info()","60214a46":"df.columns","e1b165e7":"x = df.drop(\"Defpay\",axis=1)   #Feature Matrix\ny = df[\"Defpay\"]","d1e1ff70":"df.head()","9aa302a3":"x.head()","f5692217":"y.head()","224f72c9":"def onehot_encode(df, column_dict):\n    df = df.copy()\n    for column, prefix in column_dict.items():\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","5a123c18":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop ID\n    df = df.drop('ID', axis=1)\n    \n    df = onehot_encode(\n        df,\n        {\n            'EDUCATION': 'EDU',\n            'MARRIAGE': 'MAR'\n        }\n    )\n    \n    # Split df into X and y\n    y = df['Defpay'].copy()\n    x = df.drop('Defpay', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    x = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n    \n    return x, y","d1200c78":"x, y = preprocess_inputs(df)","e211099c":"# separate dataset into train and test\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(\n    x,\n    y,\n    test_size=0.2,\n    random_state=0)\n\nx_train.shape, x_test.shape","71e623e9":"x_train.corr()","88cc8949":"import seaborn as sns\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = x_train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\nplt.show()","971c7719":"# with the following function we can select highly correlated features\n# it will remove the first feature that is correlated with anything other feature\n\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","c0d71045":"corr_features = correlation(x_train, 0.8)\nlen(set(corr_features))","a5ff245f":"corr_features","e8750e07":"x_train.drop(corr_features,axis=1)\nx_test.drop(corr_features,axis=1)","c2dae716":"x_test.to_excel(\"Test.xlsx\")","4075007b":"\n#-------------- \n# Logistic Regression \n#--------------\n#x_train,x_test,y_train,y_test = train_test_split(x_scaled,y, test_size= 0.25, random_state = 355)\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train)\ny_pred = log_reg.predict(x_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy on Test Set for Logistic Regression  = %.2f\" %(accuracy))\n\n#-------------- \n# Random Forest \n#--------------\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=10)\nclassifier.fit( x_train, y_train )\ny_pred = classifier.predict( x_test )\n\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for RandomForest = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresRF = cross_val_score( classifier, x_train, y_train, cv=10)\nprint(\"Mean RandomForest CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresRF.mean(), scoresRF.std() ))\n\n#-------------- \n# kernel SVM \n#--------------\n\nclassifier1 = SVC(kernel=\"rbf\")\nclassifier1.fit( x_train, y_train )\ny_pred = classifier1.predict( x_test )\n\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for kernel-SVM = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresSVC = cross_val_score( classifier1, x_train, y_train, cv=10)\nprint(\"Mean kernel-SVM CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresSVC.mean(), scoresSVC.std() ))\n      \n#-------------- \n# Naive Bayes \n#--------------\n\nclassifier3 = GaussianNB()\nclassifier3.fit( x_train, y_train )\ny_pred = classifier3.predict( x_test )\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for NBClassifier = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresNB = cross_val_score( classifier3, x_train, y_train, cv=10)\nprint(\"Mean NaiveBayes CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresNB.mean(), scoresNB.std() ))\n      \n#-------------- \n# K-NEIGHBOURS \n#--------------\n\nclassifier4 = KNeighborsClassifier(n_neighbors=5)\nclassifier4.fit( x_train, y_train )\ny_pred = classifier4.predict( x_test )\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for KNeighborsClassifier = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresKN = cross_val_score( classifier4, x_train, y_train, cv=10)\nprint(\"Mean KN CrossVal Accuracy on Train Set Set %.2f, with std=%.2f\" % (scoresKN.mean(), scoresKN.std() ))\n      \n\n#-------------- \n# DecisionTree \n#--------------\n\nclassifier5 = DecisionTreeClassifier(max_depth=6,max_leaf_nodes=6)\nclassifier5\nclassifier5.fit( x_train, y_train )\ny_pred = classifier5.predict( x_test )\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for DecisionTreeClassifier = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\n\n#-------------- \n# BernoulliNB Naive Bayes \n#--------------\n\nclassifier6 = BernoulliNB()\nclassifier6.fit( x_train, y_train )\ny_pred = classifier6.predict( x_test )\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for BernoulliNB = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresNB = cross_val_score( classifier6, x_train, y_train, cv=10)\nprint(\"Mean BernoulliNB CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresNB.mean(), scoresNB.std() ))\n\n\n      ","6480d84a":"#-------------- \n# MPC Classifier Neural Network \n#--------------\n\nclassifier7 = MLPClassifier()\nclassifier7.fit( x_train, y_train )\ny_pred = classifier7.predict( x_test )\nprint(\"Accuracy on Test Set for MPC Classifier Neural Network = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresMLP = cross_val_score( classifier7, x_train, y_train, cv=10)\nprint(\"Mean MPC Classifier Neural Network CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresMLP.mean(), scoresMLP.std() ))","a74e4397":"#-------------- \n# kernel SVM \n#--------------\n\nclassifier1 = SVC(kernel=\"rbf\")\nclassifier1.fit( x_train, y_train )\ny_pred = classifier1.predict( x_test )\n\ncm = confusion_matrix( y_test, y_pred )\nprint(\"Accuracy on Test Set for kernel-SVM = %.2f\" % ((cm[0,0] + cm[1,1] )\/len(x_test)))\nscoresSVC = cross_val_score( classifier1, x_train, y_train, cv=10)\nprint(\"Mean kernel-SVM CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresSVC.mean(), scoresSVC.std() ))\n","c219b82b":"# Confusion Matrix\nconf_mat = confusion_matrix(y_test,y_pred)\nconf_mat","eca3732c":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","acf196b4":"# Breaking down the formula for Accuracy\nAccuracy = (true_positive + true_negative) \/ (true_positive +false_positive + false_negative + true_negative)\nAccuracy","8c428127":"# Precison\nPrecision = true_positive\/(true_positive+false_positive)\nPrecision","35804aad":"# Recall\nRecall = true_positive\/(true_positive+false_negative)\nRecall","a64170b9":"# F1 Score\nF1_Score = 2*(Recall * Precision) \/ (Recall + Precision)\nF1_Score","e7aecacb":"# Area Under Curve\nauc = roc_auc_score(y_test, y_pred)\nauc","37494482":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, color='orange', label='ROC')\nplt.plot([0, 1], [0, 1], color='darkblue', linestyle='--',label='ROC curve (area = %0.2f)' % auc)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()\nplt.show()","569fe181":"import pickle\n\nfilename = 'finalized_model_final_v3'\nwith open(filename, 'wb') as f:\n    # save the model to disk\n    pickle.dump(classifier1,f)\n \n\n \n# load the model from disk\nwith open(filename, 'rb') as f:\n    mp = pickle.load(f)","2f0db110":"mp.predict([[-1.136720146,-1.234322957,-0.269642796,0.904712193,1.782348172,1.809921299,1.899435735,1.999879066,1.992315513,-0.451585476,-0.446521315,-0.403127148,-0.385656163,-0.338120153,-0.328845274,-0.341941619,-0.158901311,-0.296801274,-0.205929895,-0.314136117,-0.257155818,-0.021607511,1.354326157,-0.937295167,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,0.937671725,-0.104325689]])","0189162b":"mp.predict([[2.562830153,0.81016074,0.055816221,-0.874991148,-0.72356993,-0.696663456,-0.666598731,-0.64756476,-0.61645169,-0.547138338,-0.633672034,-0.621070701,-0.620610009,-0.642925675,-0.13181108,-0.095549121,-0.071099345,-0.107214011,-0.229931072,1.716358474,-0.232179964,-0.021607511,1.354326157,-0.937295167,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,0.937671725,-0.104325689]])","55ccd26a":"mp.predict([[0.250611216,-1.234322957,-0.920560831,0.904712193,1.782348172,1.809921299,1.899435735,1.999879066,1.992315513,0.826060596,0.929767088,0.93853648,1.173619733,1.323580671,1.424581059,0.050559638,-0.256989518,0.271165362,-0.052667063,0.013130756,-0.293382058,-0.021607511,-0.738374575,1.066899773,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,0.937671725,-0.104325689]])","de036473":"mp.predict([[2.177460331,-1.234322957,-0.161156457,0.014860523,0.111736104,0.138864795,0.188746091,0.234916515,0.253137378,2.845259896,2.51973328,2.678494331,2.560818945,2.537934032,2.723152932,0.880964542,1.920525277,0.106227851,0.113490019,0.341183071,0.26913719,-0.021607511,1.354326157,-0.937295167,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,0.937671725,-0.104325689]])","bead9f62":"mp.predict([[-0.905498252,-1.234322957,1.900083987,0.014860523,0.111736104,0.138864795,0.188746091,0.234916515,-0.61645169,-0.027885396,0.003750388,-0.152392564,-0.287182289,-0.252391029,-0.171607487,-0.220647199,-0.148484865,-0.240004611,-0.212313187,1.580019094,-0.225879748,-0.021607511,-0.738374575,1.066899773,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,-1.066471318,9.585366814]])","1139c920":"mp.predict([[-1.136720146,-1.234322957,-1.246019848,1.794563864,1.782348172,1.809921299,1.899435735,1.999879066,1.992315513,-0.475107016,-0.462299863,-0.436898737,-0.38761476,-0.371345945,-0.32619218,-0.305716307,-0.213587657,-0.171848614,-0.308062562,-0.183229368,-0.293382058,-0.021607511,-0.738374575,1.066899773,-0.44275183,-0.064162911,-0.097063202,-0.041266147,-0.042464642,-0.91426088,0.937671725,-0.104325689]])","284d02a0":"## Selected kernel-SVM","00c707e0":"## Exporting a model","6727799e":"### ML Algorithms","a7bec66a":"## Using x_test for Retesting test results"}}