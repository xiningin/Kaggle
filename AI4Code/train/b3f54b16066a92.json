{"cell_type":{"b6752838":"code","179f5ff9":"code","0aa62cd8":"code","4fd7e047":"code","33bc406c":"code","0d6a50b2":"code","75079082":"code","a2125b99":"code","0b80f02c":"code","60840880":"code","e45ba792":"code","3bb49b91":"code","d7818d52":"code","2bbd9e6b":"markdown","886518f9":"markdown","99720dc1":"markdown","5c9663a7":"markdown"},"source":{"b6752838":"# install this or efficientNet will failed to load\n!pip install --quiet \/kaggle\/input\/kerasapplications\n!pip install --quiet \/kaggle\/input\/efficientnet-git","179f5ff9":"import math, re, os, random, warnings\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nimport efficientnet.tfkeras as efn\n\nprint(\"Tensorflow version \" + tf.__version__)","0aa62cd8":"strategy = tf.distribute.get_strategy()\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = \"..\/input\/cassava-leaf-disease-classification\"\nIMAGE_SIZE = [512, 512]\nRESIZE_IMAGE_SIZE = [512, 512]  #  \u56fe\u50cf\u589e\u5f3a\u538b\u7f29\u540e\u7684\u5927\u5c0f TPU 512,  GPU 300(\u592a\u5927\u7206\u5185\u5b58)\nCLASSES = ['0', '1', '2', '3', '4']\nWEIGHTS_PATH = \"..\/input\/cassava-leaf-disease-resnet-weights\/EfficientNetB4-best-08-0.8890.h5\"\nBATCH_SIZE = 16","4fd7e047":"# seed everything\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","33bc406c":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) # model zoo \u7684\u8bad\u7ec3\u811a\u672c\u4e0d\u7528\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","0d6a50b2":"TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/test_tfrecords\/*.tfrec')\n\nprint(TEST_FILENAMES)","75079082":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    return dataset\n\n\ndef data_val_augment(image, label):\n    # val\u9a8c\u8bc1\u96c6\u56fe\u7247\u9884\u5904\u7406\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])  # \u8fd9\u91cc\u53bb\u6389\u4e86\u6a21\u578b\u91cc\u7684\u524d\u5904\u7406\u5c42, \u76f4\u63a5\u5728\u8fd9\u91ccreshape\n    if not IMAGE_SIZE == RESIZE_IMAGE_SIZE:\n        image = tf.image.resize(image, RESIZE_IMAGE_SIZE)  \n    return image, label\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.map(data_val_augment, num_parallel_calls=AUTOTUNE)  \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","a2125b99":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","0b80f02c":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    return image, idnum","60840880":"# def to_float32(image, label):\n#     return tf.cast(image, tf.float32), label","e45ba792":"# \u52a0\u8f7d\u6a21\u578b\ntrained_model = tf.keras.models.load_model(WEIGHTS_PATH)\ntrained_model.summary()","3bb49b91":"test_ds = get_test_dataset(ordered=True) \n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = trained_model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","d7818d52":"print('Generating submission.csv file...')\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='image_id,label', comments='')\n!head submission.csv","2bbd9e6b":"# \u5404\u6a21\u578b\u7684\u9884\u6d4b\u63d0\u4ea4Kernel\n\n* [\u8bad\u7ec3Kernel](https:\/\/www.kaggle.com\/tianyu5\/tpus-cassava-leaf-disease)","886518f9":"## \u8fdb\u884c\u9884\u6d4b","99720dc1":"\u6d4b\u8bd5\u96c6\u7684\u5904\u7406\u548c\u9a8c\u8bc1\u96c6\u4e00\u6837. \u7528val_augment\u8fc7\u4e00\u4e0b","5c9663a7":"## Set up variables"}}