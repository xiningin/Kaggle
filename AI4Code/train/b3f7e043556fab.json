{"cell_type":{"c884d08f":"code","e3905cb7":"code","14559f02":"code","39df758f":"code","dda7612f":"code","502772af":"code","7512c327":"code","014e9ea6":"code","b173dc84":"code","8ddc65bf":"code","99c394a7":"code","c8f9c06f":"code","611a0ee6":"code","99eb7b56":"code","2cdcfbcd":"code","290a1f86":"code","a0870f7a":"code","1b2c2770":"code","a3e67787":"code","e334bc9d":"code","e95c19c7":"code","1d6836d0":"code","606314af":"code","75c090cd":"code","db8a0b40":"code","5f675ff1":"code","7fcb376c":"code","0b298e1a":"code","3511db25":"code","b406dede":"code","4cbddc48":"code","a98350ff":"code","1c243900":"code","ff8cc219":"code","7aaa9bf8":"code","b8b8550f":"code","6de69ec9":"code","72e726e0":"code","3e890b8a":"code","a095fbb6":"code","bf061d2c":"code","37f2fca1":"code","d9c58404":"code","ca7d95ad":"code","a2b6a104":"code","895ba9a4":"code","1019b3da":"code","5be81654":"code","e638f87a":"code","9f74f51b":"code","35b1be57":"code","147bf055":"code","9371b253":"code","61b6f9c7":"code","b48a7e84":"code","4fdf912e":"code","54b76366":"code","e9d128e8":"code","35f75b5e":"code","4a372477":"code","8db62fb4":"code","0a81e1a0":"code","996cc65b":"code","9a16ac1e":"code","f77aceb0":"code","554b8b06":"code","e54e13c3":"code","3beb43be":"code","ee4c875d":"code","66f2aded":"code","6815f976":"code","ad2266de":"code","c1239775":"code","e5e96e4a":"code","0a56b65b":"code","51c356bc":"code","11b61e35":"code","f3e9067c":"code","ae22dfa4":"code","a361f92d":"code","49e1867b":"code","028db67d":"code","6208569e":"code","89cfa432":"code","088ef322":"code","4999838f":"code","b41ded2c":"code","459f5231":"code","4ab0f7ac":"code","44bd6f70":"code","7aecb25c":"code","a415f31a":"code","44b835e6":"code","ee29f9dd":"code","dbc024ec":"code","1b2f15f8":"code","dc0717ba":"code","6c0f6600":"code","b2f763a9":"code","dbb4072a":"code","98a71858":"code","758aecba":"code","be08b396":"code","9408ed50":"code","a0f15c04":"code","81582777":"markdown","af8025a3":"markdown","081cda16":"markdown","03946a8f":"markdown"},"source":{"c884d08f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","e3905cb7":"movie=pd.read_csv(r'\/kaggle\/input\/cinema-movie\/Movie_regression.csv')\nmovie.head()","14559f02":"moviecbr=movie.copy()","39df758f":"movie.info()","dda7612f":"movie.shape","502772af":"movie.describe()","7512c327":"round((movie.isnull().sum() * 100 \/ len(movie)),2)","014e9ea6":"\nsns.distplot(movie['Time_taken'])\nplt.show()","b173dc84":"#Encode categorical data\ndummy = pd.get_dummies(movie[[\"Genre\",\"3D_available\"]]).iloc[:,:-1]\nmovie = pd.concat([movie,dummy], axis=1)\nmovie = movie.drop([\"Genre\",\"3D_available\"], axis=1)\nmovie.shape","8ddc65bf":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nit = IterativeImputer(estimator=LinearRegression())\nnewdata_lr = pd.DataFrame(it.fit_transform(movie))\nnewdata_lr.columns = movie.columns\nnewdata_lr.head()","99c394a7":"import scipy.stats as stats\nstats.ttest_ind(newdata_lr.Time_taken,movie.Time_taken,nan_policy='omit')","c8f9c06f":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nit = IterativeImputer(estimator=RandomForestRegressor(random_state=42))\nnewdata_rfr = pd.DataFrame(it.fit_transform(movie))\nnewdata_rfr.columns = movie.columns\nnewdata_rfr.head()","611a0ee6":"import scipy.stats as stats\nstats.ttest_ind(newdata_rfr.Time_taken,movie.Time_taken,nan_policy='omit')","99eb7b56":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=tree.DecisionTreeRegressor(random_state=42))\nnewdata_bg = pd.DataFrame(it.fit_transform(movie))\nnewdata_bg.columns = movie.columns\nnewdata_bg.head()","2cdcfbcd":"import scipy.stats as stats\nstats.ttest_ind(newdata_bg.Time_taken,movie.Time_taken,nan_policy='omit')","290a1f86":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=AdaBoostRegressor(random_state=42))\nnewdata_abc = pd.DataFrame(it.fit_transform(movie))\nnewdata_abc.columns = movie.columns\nnewdata_abc.head()","a0870f7a":"import scipy.stats as stats\nstats.ttest_ind(newdata_abc.Time_taken,movie.Time_taken,nan_policy='omit')","1b2c2770":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import tree\nit = IterativeImputer(estimator=GradientBoostingRegressor(random_state=42))\nnewdata_gbr = pd.DataFrame(it.fit_transform(movie))\nnewdata_gbr.columns = movie.columns\nnewdata_gbr.head()","a3e67787":"import scipy.stats as stats\nstats.ttest_ind(newdata_gbr.Time_taken,movie.Time_taken,nan_policy='omit')","e334bc9d":"from sklearn.experimental import enable_iterative_imputer\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\nfrom sklearn import tree\nit = IterativeImputer(estimator=xgb.XGBRegressor(random_state=42))\nnewdata_xgb = pd.DataFrame(it.fit_transform(movie))\nnewdata_xgb.columns = movie.columns\nnewdata_xgb.head()","e95c19c7":"import scipy.stats as stats\nstats.ttest_ind(newdata_xgb.Time_taken,movie.Time_taken,nan_policy='omit')","1d6836d0":"# Compare with original v\/s modified ","606314af":"movie.Time_taken.describe(),newdata_lr.Time_taken.describe()","75c090cd":"movie.Time_taken.describe(),newdata_rfr.Time_taken.describe()","db8a0b40":"movie.Time_taken.describe(),newdata_bg.Time_taken.describe()","5f675ff1":"movie.Time_taken.describe(),newdata_abc.Time_taken.describe()","7fcb376c":"movie.Time_taken.describe(),newdata_gbr.Time_taken.describe()","0b298e1a":"movie.Time_taken.describe(),newdata_xgb.Time_taken.describe()","3511db25":"movie=newdata_abc","b406dede":"moviecbr = moviecbr.assign(Time_taken=movie['Time_taken'])","4cbddc48":"movie.info()","a98350ff":"import pandas_profiling as pp \nprofile = pp.ProfileReport(movie) \nprofile","1c243900":"movie.hist(figsize=(32,20),bins=50)\nplt.xticks(rotation=90)\nplt.show()","ff8cc219":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(movie, train_size = 0.7, random_state = 42)","7aaa9bf8":"df_train.shape, df_test.shape","b8b8550f":"X_train=df_train.drop('Collection',axis=1)\ny_train=df_train['Collection']\nX_test=df_test.drop('Collection',axis=1)\ny_test=df_test['Collection']","6de69ec9":"X_train.info()","72e726e0":"X_train.columns","3e890b8a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.fit_transform(X_train[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nX_train.head()","a095fbb6":"X_test[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.transform(X_test[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nX_test.head()","bf061d2c":"X_test.shape,X_train.shape","37f2fca1":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","d9c58404":"X_train = X_train.drop([\"Lead_Actress_rating\"], axis = 1)\nX_test = X_test.drop([\"Lead_Actress_rating\"], axis = 1)","ca7d95ad":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a2b6a104":"X_train = X_train.drop([\"Lead_ Actor_Rating\"], axis = 1)\nX_test = X_test.drop([\"Lead_ Actor_Rating\"], axis = 1)","895ba9a4":"# Calculate the VIFs for the new model\nimport statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","1019b3da":"X_train = X_train.drop([\"Producer_rating\"], axis = 1)\nX_test = X_test.drop([\"Producer_rating\"], axis = 1)","5be81654":"import statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","e638f87a":"X_train = X_train.drop([\"Multiplex coverage\"], axis = 1)\nX_test = X_test.drop([\"Multiplex coverage\"], axis = 1)","9f74f51b":"import statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","35b1be57":"import xgboost as xgb\nmodel=xgb.XGBRegressor()\nmodel.fit(X_train, y_train)\nscore_xgb=model.score(X_test,y_test)\nprint(\"Score XGBRegressor :\", score_xgb)","147bf055":"from sklearn.metrics import mean_squared_error\nrmse_xgb=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE XGBRegressor :',rmse_xgb)","9371b253":"from sklearn.metrics import mean_squared_log_error\nRMSLE_xgb=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for XGBRegressor :\",RMSLE_xgb)","61b6f9c7":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nX_trainlr=X_train.copy()\nimport statsmodels.api as sm\nX_train_lm = sm.add_constant(X_trainlr)\nlr = sm.OLS(y_train, X_trainlr).fit()\nlr.summary()","b48a7e84":"X_train1 = X_trainlr.drop([\"Avg_age_actors\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","4fdf912e":"X_train1 = X_train1.drop([\"Num_multiplex\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","54b76366":"X_train1 = X_train1.drop([\"Time_taken\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","e9d128e8":"X_train1 = X_train1.drop([\"Twitter_hastags\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","35f75b5e":"X_train1 = X_train1.drop([\"Production expense\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","4a372477":"X_train1 = X_train1.drop([\"Movie_length\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","8db62fb4":"X_train1 = X_train1.drop([\"3D_available_NO\"], axis = 1)\nX_train_lm = sm.add_constant(X_train1)\nlr= sm.OLS(y_train, X_train_lm).fit()\nlr.summary()","0a81e1a0":"X_testlr=X_test.copy()\ncol1=X_train1.columns\nX_testlr=X_test[col1]\n# Adding constant variable to test dataframe\nX_testlr= sm.add_constant(X_testlr)","996cc65b":"from sklearn.metrics import mean_squared_error\nrmse_lr=mean_squared_error(lr.predict(X_testlr),y_test)**0.5\nprint('RMSE Linear Regression:',rmse_lr)\n","9a16ac1e":"from sklearn.metrics import mean_squared_log_error\nRMSLE_lr=np.sqrt(mean_squared_log_error( y_test, abs(lr.predict(X_testlr))))\nprint(\"RMSLE for Linear Regression:\",RMSLE_lr)","f77aceb0":"from sklearn.ensemble import GradientBoostingRegressor\nmodel= GradientBoostingRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_gbc=model.score(X_test,y_test)\nprint(\"Score GradientBoostingRegressor:\", score_gbc)","554b8b06":"from sklearn.metrics import mean_squared_error\nrmse_gbc=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE GradientBoostingRegressor :',rmse_gbc)","e54e13c3":"from sklearn.metrics import mean_squared_log_error\nRMSLE_gbc=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for GradientBoostingRegressor :\",RMSLE_gbc)","3beb43be":"from sklearn.ensemble import AdaBoostRegressor\nmodel = AdaBoostRegressor()\nmodel.fit(X_train, y_train)\nscore_abr=model.score(X_test,y_test)\nprint(\"Score AdaBoostRegressor:\", score_abr)","ee4c875d":"from sklearn.metrics import mean_squared_error\nrmse_abr=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE AdaBoostRegressor :',rmse_abr)","66f2aded":"from sklearn.metrics import mean_squared_log_error\nRMSLE_abr=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for AdaBoostRegressor :\",RMSLE_abr)","6815f976":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\nscore_rfr=model.score(X_test,y_test)\nprint(\"Score RandomForestRegressor:\", score_rfr)","ad2266de":"from sklearn.metrics import mean_squared_error\nrmse_rfr=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE RandomForestRegressor :',rmse_rfr)","c1239775":"from sklearn.metrics import mean_squared_log_error\nRMSLE_rfr=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for RandomForestRegressor :\",RMSLE_rfr)","e5e96e4a":"from sklearn.ensemble import BaggingRegressor\nmodel = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1))\nmodel.fit(X_train, y_train)\nscore_br=model.score(X_test,y_test)\nprint(\"Score BaggingRegressor:\", score_br)","0a56b65b":"from sklearn.metrics import mean_squared_error\nrmse_br=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE  BaggingRegressor :',rmse_br)","51c356bc":"from sklearn.metrics import mean_squared_log_error\nRMSLE_br=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for BaggingRegressor :\",RMSLE_br)","11b61e35":"from sklearn.metrics import mean_squared_log_error\nRMSLE_br=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for BaggingRegressor :\",RMSLE_br)","f3e9067c":"moviecbr['Collection']=moviecbr['Collection'].astype('float')\nmoviecbr['Num_multiplex']=moviecbr['Num_multiplex'].astype('float')\nmoviecbr['Avg_age_actors']=moviecbr['Avg_age_actors'].astype('float')\nmoviecbr['Trailer_views']=moviecbr['Trailer_views'].astype('float')","ae22dfa4":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndftrain, dftest = train_test_split(moviecbr, train_size = 0.7, random_state = 42)","a361f92d":"dftrain.shape, dftest.shape","49e1867b":"Xtrain=dftrain.drop('Collection',axis=1)\nytrain=dftrain['Collection']\nXtest=dftest.drop('Collection',axis=1)\nytest=dftest['Collection']","028db67d":"Xtrain.info()","6208569e":"Xtrain.columns","89cfa432":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nXtrain[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.fit_transform(Xtrain[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nXtrain.head()","088ef322":"Xtest[['Marketing expense', 'Production expense', 'Multiplex coverage',\n         'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n         'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n         'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']]= scaler.transform(Xtest[['Marketing expense', 'Production expense', 'Multiplex coverage',\n                                                        'Budget', 'Movie_length', 'Lead_ Actor_Rating', 'Lead_Actress_rating',\n                                                        'Director_rating', 'Producer_rating', 'Critic_rating', 'Trailer_views',\n                                                        'Time_taken', 'Twitter_hastags', 'Avg_age_actors', 'Num_multiplex']])\nXtest.head()","4999838f":"Xtest.shape,Xtrain.shape","b41ded2c":"from catboost import CatBoostRegressor\nmodel=CatBoostRegressor()\ncategorical_features_indices = np.where(Xtrain.dtypes != np.float)[0]\nmodel.fit(Xtrain,ytrain,cat_features=([11, 14]),eval_set=(Xtest, ytest))\nscore_cbr=model.score(Xtest,ytest)\nprint(\"Score CatBoostRegressor:\", score_cbr)","459f5231":"from sklearn.metrics import mean_squared_error\nrmse_cbr=mean_squared_error(model.predict(Xtest),ytest)**0.5\nprint('RMSE CatBoostRegressor :',rmse_cbr)","4ab0f7ac":"from sklearn.metrics import mean_squared_log_error\nRMSLE_cbr=np.sqrt(mean_squared_log_error( ytest, model.predict(Xtest) ))\nprint(\"RMSLE for CatBoostRegressor :\",RMSLE_cbr)","44bd6f70":"import lightgbm as lgb\ntrain_data=lgb.Dataset(X_train,label=y_train)\nparams = {'learning_rate':0.001}\nmodel= lgb.train(params, train_data)\n","7aecb25c":"from sklearn.metrics import mean_squared_error\nrmse_lgb=mean_squared_error(model.predict(X_test),y_test)**0.5\nprint('RMSE Light GBM :',rmse_lgb)","a415f31a":"from sklearn.metrics import mean_squared_log_error\nRMSLE_lgb=np.sqrt(mean_squared_log_error( y_test, model.predict(X_test) ))\nprint(\"RMSLE for Light GBM:\",RMSLE_lgb)","44b835e6":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(random_state=42)\nrf.fit(X_train, y_train)","ee29f9dd":"from sklearn.model_selection import GridSearchCV","dbc024ec":"params = {\n    'max_depth': [25,30,35],\n    'min_samples_leaf': [2,3,5],\n    'max_samples': [50,75,100]\n    \n}","1b2f15f8":"grid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv=5,\n                           n_jobs=-1, verbose=1)","dc0717ba":"%%time\ngrid_search.fit(X_train, y_train)","6c0f6600":"grid_search.best_score_","b2f763a9":"rf_best = grid_search.best_estimator_\nrf_best","dbb4072a":"from sklearn.metrics import mean_squared_error\nrmse_rfr_ht=mean_squared_error(rf_best.predict(X_test),y_test)**0.5\nprint('RMSE RandomForestRegressor With Hypertuning :',rmse_rfr_ht)","98a71858":"from sklearn.metrics import mean_squared_log_error\nRMSLE_rfr_ht=np.sqrt(mean_squared_log_error( rf_best.predict(X_test),y_test ))\nprint(\"RMSLE for RandomForestRegressor With Hypertuning :\",RMSLE_rfr_ht)","758aecba":"score_rfr_ht=rf_best.score(X_test,y_test)\nprint(\"Score RandomForestRegressor With Hypertuning :\", score_rfr_ht)","be08b396":"print('RMSE Light GBM                                 :',rmse_lgb)\nprint('RMSE XGBRegressor                              :',rmse_xgb)\nprint('RMSE GradientBoostingRegressor                 :',rmse_gbc)\nprint('RMSE AdaBoostRegressor                         :',rmse_abr)\nprint('RMSE  BaggingRegressor                         :',rmse_br)\nprint('RMSE CatBoostRegressor                         :',rmse_cbr)\nprint(\"RMSE RandomForestRegressor Without Hypertuning :\",rmse_rfr)\nprint('RMSE RandomForestRegressor With Hypertuning    :',rmse_rfr_ht)\nprint(\"RMSE for Linear Regression                     :\",rmse_lr)","9408ed50":"print(\"Score RandomForestRegressor Without Hypertuning :\", score_rfr)\nprint(\"Score RandomForestRegressor With Hypertuning    :\",score_rfr_ht)\nprint('Score XGBRegressor                              :',score_xgb)\nprint('Score GradientBoostingRegressor                 :',score_gbc)\nprint('Score AdaBoostRegressor                         :',score_abr)\nprint('Score  BaggingRegressor                         :',score_br)\nprint('Score CatBoostRegressor                         :',score_cbr)","a0f15c04":"print('RMSLE for Light GBM                                 :',RMSLE_lgb)\nprint('RMSLE for XGBRegressor                              :',RMSLE_xgb)\nprint('RMSLE for GradientBoostingRegressor                 :',RMSLE_gbc)\nprint('RMSLE for AdaBoostRegressor                         :',RMSLE_abr)\nprint('RMSLE for  BaggingRegressor                         :',RMSLE_br)\nprint('RMSLE for CatBoostRegressor                         :',RMSLE_cbr)\nprint(\"RMSLE for RandomForestRegressor Without Hypertuning :\",RMSLE_rfr)\nprint(\"RMSLE for RandomForestRegressor With Hypertuning    :\",RMSLE_rfr_ht)\nprint(\"RMSLE for Linear Regression                         :\",RMSLE_lr)","81582777":"**CatBoostRegressor is best algorithm for this regression problem for following factors**\n- RMSLE for CatBoostRegressor is lowerest compared to others \n- Score for CatBoostRegressor is higherest compared to others\n- RMSE for CatBoostRegressor is lowerest compared to others","af8025a3":"# Missing Value Treatment ","081cda16":"But we found, AdaBoost Regressor to be best work with p value & t Value ","03946a8f":"We will use Machine learning Algorithm to compute the missing value "}}