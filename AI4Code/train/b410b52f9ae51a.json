{"cell_type":{"89c4e44a":"code","3dc3618a":"code","2694aa91":"code","e4f67e32":"code","35e79e68":"code","d317160a":"code","4573fa37":"code","12771651":"code","7e7b875a":"code","5ec08309":"code","e1c34825":"code","75181095":"code","983af938":"code","5c83b00c":"code","1636cd5d":"code","c2446f3d":"code","ae162cdf":"code","58b46b28":"code","179f8ea4":"code","063156e6":"code","191d51d8":"code","16c0f7a5":"markdown","9670ba25":"markdown","e926ce1f":"markdown","3bcd1baf":"markdown"},"source":{"89c4e44a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3dc3618a":"#importing libraries which we required further\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","2694aa91":"#lets read the salary data and store it in dataframe using pandas\ndata = pd.read_csv('\/kaggle\/input\/sf-salaries\/Salaries.csv')\ndata.head()","e4f67e32":"#lets see overview of dataset using describe()\ndata.describe()","35e79e68":"data['Benefits'].value_counts()","d317160a":"data['BasePay'].value_counts()","4573fa37":"data['Status'].value_counts()","12771651":"#since there are lot of missing values in status and notes variable in datsaet so lets drop it \ndata.drop(columns=[\"Status\",\"Notes\"],inplace=True,axis=1)","7e7b875a":"data.head()","5ec08309":"#lets identify categorical columns in dataset\n# Get list of categorical variables\ns = (data.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","e1c34825":"data.info()","75181095":"data.isnull().sum()","983af938":"for col in ['BasePay','OvertimePay','OtherPay','Benefits']:\n    data[col]=pd.to_numeric(data[col],errors='coerce')","5c83b00c":"#data.fillna(value='BasePay')\n\"\"\"data['BasePay']=data.BasePay.fillna(data['BasePay'].mean(),inplace=True)\ndata['Benefits']=data.Benefits.fillna(data['Benefits'].mean(),inplace=True)\"\"\"","1636cd5d":"data.isnull().sum()","c2446f3d":"data['JobTitle'].value_counts()","ae162cdf":"print(data.JobTitle.unique())","58b46b28":"data['EmployeeName'] = data['EmployeeName'].apply(str.upper)\ndata.head()","179f8ea4":"data['JobTitle'] = data['JobTitle'].apply(str.upper)\ndata['JobTitle'].value_counts()","063156e6":"d_hsp={\"1\":\"I\",\"2\":\"II\",\"3\":\"III\",\"4\":\"IV\",\"5\":\"V\",\"6\":\"VI\",\"7\":\"VII\",\"8\":\"VIII\",\n       \"9\":\"IX\",\"10\":\"X\",\"11\":\"XI\",\"12\":\"XII\",\"13\":\"XIII\",\"14\":\"XIV\",\"15\":\"XV\",\n       \"16\":\"XVI\",\"17\":\"XVII\",\"18\":\"XVIII\",\"19\":\"XIX\",\"20\":\"XX\",\"21\":\"XXI\",\n       \"22\":\"XXII\",\"23\":\"XXIII\",\"24\":\"XXIV\",\"25\":\"XXV\"}\ndata['JobTitle'] = data['JobTitle'].replace(d_hsp, regex=True)","191d51d8":"data['JobTitle'].value_counts()","16c0f7a5":"Now final check for null or missing values ","9670ba25":"**Lets do exploratory data analysis for this dataset**","e926ce1f":"Now we have to deal with missing values in column BasePay and Benifits\nLets fill them by there mean value for simplicity further we will modify for model improvement.\n","3bcd1baf":"1. Check few records from both dataset \n1. Check how many categorical variables are present in dataset\n1. Handle Missing values in dataset\n1. Visualize distribution of data along with each group \n"}}