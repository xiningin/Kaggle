{"cell_type":{"8d6abccb":"code","8a82bf5a":"code","1d189ff2":"code","24c59e81":"code","f7fdadc4":"code","ef1ab138":"code","3e582e73":"code","7cfb0413":"markdown","670b6b27":"markdown"},"source":{"8d6abccb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import KMeans, k_means\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom sklearn.metrics import calinski_harabasz_score\nfrom time import time\n","8a82bf5a":"# generate random spots\nx,y = make_blobs(n_samples = 500, n_features =2, centers = 3, random_state = 0)","1d189ff2":"colors = ['red','blue','pink','green']\n\nplt.figure(figsize = (500,10))\nfig,ax1 = plt.subplots(1)\n\nfor i in range(4):\n    ax1.scatter(x[y==i,0], x[y==i,1], marker = 'o', s = 8, c = colors[i])\n    \nplt.show()","24c59e81":"# Hard to tell if this is a good clustering, let's find the best K use silhouette_score\n\nresult = []\nfor i in [2,3,4,5,6,7]:\n    cluster = KMeans(n_clusters = i,random_state = 42). fit(x)\n    y_pred = cluster.labels_\n    score = silhouette_score(x,y_pred)\n    result.append(score)\nprint(max(result))\nprint(result.index(max(result)))\n","f7fdadc4":"# # Best K = 3,use k_means to get more information in a simple way\n\nk_means(x,3,return_n_iter = True)\n\n# 1, the center value(seeds) for 3 unique clusters\n# 2, y value corresponding to the 3 clusters\n# 3, inertia\n# 4, n_iter = 6","ef1ab138":"t0 = time()\ncalinski_harabasz_score(x,y_pred)\ntime() - t0","3e582e73":"t1 = time()\nsilhouette_score(x,y_pred)\ntime() -t1","7cfb0413":"CHi score doesn't have lower and upper limit, hard to tell the clustering is good or  \nbad just based on the value, but CHi score works good on large datasets, more stable and save \ncalculation time. Let's compare the time difference between CHi score and silhouette score use the same \nrandom plots","670b6b27":"Get CHi score is 10 times faster then get silhouette score, when it comes to big datasets,CHi is very helpful"}}