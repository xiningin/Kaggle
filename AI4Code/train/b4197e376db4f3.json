{"cell_type":{"f5a71e8d":"code","461d6379":"code","eb5d91e1":"code","c84cf626":"code","c9bfe775":"code","cff89e57":"code","e5ade369":"code","1f0c44a7":"code","6564836e":"code","4301c7ee":"code","06ccf13f":"code","b6acda3e":"code","123bb514":"code","b6617ec9":"code","ea9faa5f":"code","68ddfc61":"code","8338b1d5":"code","00038a30":"code","bfe4e169":"code","39162654":"code","fb2fced6":"markdown","36a133ce":"markdown","f51c0d5f":"markdown","f3b81ff7":"markdown"},"source":{"f5a71e8d":"#Dummy \n\nl2=[]","461d6379":"#Reading the Lab Files\nimport math\nimport pandas as pd\nimport numpy as np\n#df = pd.read_csv('~\/thoreau-backend\/frontend\/static\/water\/LabData\/LAB_DATA_with_SENSOR_data_MAIN_for_ANALYSIS.csv')\ndf = pd.read_csv('\/kaggle\/input\/codtestin\/For_val_input.csv',error_bad_lines=False)\n#df=df[df['Location']=='DELH']\nprint(df.keys())\n","eb5d91e1":"print(len(df))","c84cf626":"df2=df[['(SEN) pH ', '(SEN) Turbidity NTU', '(SEN) DO ppm',\n       'NO3 ppm','(SEN) CHLA RFU', '(SEN) CDOM RFU', '(SEN) Conductivity',\n       '(SEN) TRPN RFU', 'COD ppm','(SEN) Temperature']]\ndf2=df2.apply(pd.to_numeric, errors='coerce').dropna()\n#df2['BOD_QF']=df2.apply(lambda x: NSF_BOD(x['BOD ppm']), axis=1)\n#df2['BOD_QF']=df2.apply(lambda x: x['BOD ppm']\/x['COD ppm'], axis=1)\n\"\"\"df2['(SEN) pH '] = df2['(SEN) pH '].apply(lambda x: NSF_pH(x))\ndf2['(SEN) DO ppm'] = df2.apply(lambda x: NSF_DO(x['(SEN) DO ppm'],x['(SEN) Temperature']), axis=1)\"\"\"\n#df2['(SEN) Turbidity NTU'] = df2['(SEN) Turbidity NTU'].apply(lambda x: -96.31*(1-math.exp(-1.1513*x))+105.56)\n#corr = df2.corr()\n\"\"\"df_t = pd.read_csv('\/kaggle\/input\/codtest\/For_val.csv',error_bad_lines=False)\n#df_t=df_t[df_t['Location']=='DELH']\ndf2_t=df_t[['(SEN) pH ', '(SEN) Turbidity NTU', '(SEN) DO ppm',\n       'NO3 ppm', '(SEN) CHLA RFU','(SEN) CDOM RFU', '(SEN) Conductivity',\n       '(SEN) TRPN RFU', 'COD ppm', '(SEN) Temperature']]\ndf2_t=df2_t.apply(pd.to_numeric, errors='coerce').dropna()\n#df2_t['BOD_QF']=df2_t.apply(lambda x: NSF_BOD(x['BOD ppm']), axis=1)\ndf2['(SEN) pH '] = df2['(SEN) pH '].apply(lambda x: NSF_pH(x))\ndf2['(SEN) DO ppm'] = df2.apply(lambda x: NSF_DO(x['(SEN) DO ppm'],x['(SEN) Temperature']), axis=1)\"\"\"\n#df2['(SEN) Turbidity NTU'] = df2['(SEN) Turbidity NTU'].apply(lambda x: -96.31*(1-math.exp(-1.1513*x))+105.56)\n\"\"\"df2_t=df2_t.drop(columns=['FC cfu\/100ml', 'BOD ppm'])\ndf2=df2.drop(columns=['FC cfu\/100ml', 'BOD ppm'])\ndf3=df2.append(df2_t, ignore_index=True)\nmini=df3['BOD_QF'].min()\nfactor=df3['BOD_QF'].max()-df3['WQI_CPCB'].min()\ns=df2['BOD_QF']\ndf2=((df2-df3.min())\/(df3.max()-df3.min()))\ndf2['BOD_QF']=s\ns2=df2_t['BOD_QF']\ndf2_t=((df2_t-df3.min())\/(df3.max()-df3.min()))\ndf2_t['BOD_QF']=s2\ndf2=df2.drop(columns=['(SEN) Turbidity NTU','(SEN) Temperature'])\ndf2_t=df2_t.drop(columns=['(SEN) Turbidity NTU','(SEN) Temperature'])\n_t\n\ndf3=df2.append(df2_t, ignore_index=True)\"\"\"\nfrom sklearn.model_selection import train_test_split\n\n#df2=df3.copy()\n\n\n\n#df2_t=((df2_t-df2.min())\/(df2.max()-df2.min()))*0.6+0.2\n\ndf2=((df2-df2.min())\/(df2.max()-df2.min()))*0.6+0.2\ndf2, df2_t = train_test_split(df2, test_size=0.1)\n#df2['COD ppm']=s","c9bfe775":"l2=[]\n#df2=df2.drop(df2.index[l2])\ndf2.keys()","cff89e57":"\"\"\"l2=[14,19,33,39,51,53,56,58,73,103,110,122,127,158,168,173,180,184,195,200]\n\ndf2_t=df2.iloc[l2]\ndf2=df2.drop(df2.index[l2])\"\"\"","e5ade369":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr = df2.corr()\n\nfig, ax = plt.subplots(figsize=(10,10))\nax.xaxis.set_tick_params(labelsize=12)\nax.yaxis.set_tick_params(labelsize=12)\n\nsns.heatmap(corr,xticklabels=['pH ', 'Turbidity', 'DO','NO3 ppm','Chlorophyll-a', 'CDOM', 'Conductivity','Tryptophan', 'COD ppm', 'Temperature',],yticklabels=['pH ', 'Turbidity', 'DO','NO3 ppm','Chlorophyll-a', 'CDOM', 'Conductivity','Tryptophan', 'COD ppm', 'Temperature'], mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True,),\nsquare=True, ax=ax, annot = True)","1f0c44a7":"from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(df2.drop(columns=['WQI_CPCB',]), df2['WQI_CPCB'],  train_size=0.85)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport keras\nfrom keras.callbacks import Callback\nfrom numpy import array\nfrom sklearn.model_selection import KFold\nimport sklearn.metrics as metrics","6564836e":"#make changes here\nno_of_neurons=[63,63,63]\n\n\n\n#Do not touch this\nno_of_neurons.append(1)\nnumber_of_additional_layers=len(no_of_neurons)-2","4301c7ee":"n_fold=10\n\n#Smaller batch takes longer per epoch, larger batch gives a wholesome picture\nbatch=2\nepoch_count=1000\n\n\nloss_fn='mse'  # choose from mae or mse\n\nlr=0.0001\n\n#We really need to figure this out\nearly_stop_at=0.004","06ccf13f":"print(df2.keys())","b6acda3e":"#Add parameters you wish to remove\ntrain_removal=[]\n\n\n#Don't touch this\ntrain_removal.append('COD ppm')","123bb514":"def regression_results(y_true, y_pred):\n\n    # Regression metrics\n    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n    mse=metrics.mean_squared_error(y_true, y_pred) \n    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n    r2=metrics.r2_score(y_true, y_pred)\n    \n    print('explained_variance: ', round(explained_variance,4))    \n    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n    print('r2: ', round(r2,4))\n    print('MAE: ', round(mean_absolute_error,4))\n    print('MSE: ', round(mse,4))\n    print('RMSE: ', round(np.sqrt(mse),4))\n    return [r2,mean_absolute_error,mse]\n\nclass EarlyStoppingByLossVal(Callback):\n    def __init__(self, monitor='loss', value=5, verbose=0):\n        super(Callback, self).__init__()\n        self.monitor = monitor\n        self.value = value\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs={}):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n            \n        if epoch>=4999:\n            print(\"Training Loss : \"+str(current))\n\n        if current < early_stop_at:\n            if self.verbose > 0:\n                print(\"Epoch %05d: early stopping THR\" % epoch)\n                print(\"Train actual loss : \"+str(current))\n            self.model.stop_training = True\n\n","b6617ec9":"\n\n        \nkfold = KFold(n_fold, True, 1)\n# enumerate splits\nfold_no=1\nr2_train=[]\nr2_test=[]\nmae_train=[]\nmae_test=[]\nmse_train=[]\nmse_test=[]\nfor train_index, test_index in kfold.split(df2):\n    #X_train, X_test = df2.loc[train_index, \"(SEN) pH\"], df2.loc[test_index, \"(SEN) pH\"]\n    #y_train, y_test = df2.loc[train_index, \"WQI_CPCB\"], df2.loc[test_index, \"WQI_CPCB\"]\n    #print(X_train)\n    X_train=df2.iloc[train_index].drop(columns=train_removal)\n    y_train=df2.iloc[train_index]['COD ppm']\n    X_test=df2.iloc[test_index].drop(columns=train_removal)\n    y_test=df2.iloc[test_index]['COD ppm']\n    \n    model = Sequential()\n    model.add(Dense(no_of_neurons[0], kernel_initializer='normal',input_dim = len(df2.columns)-len(train_removal), activation='relu'))\n    for i in range(number_of_additional_layers):\n        model.add(Dense(no_of_neurons[i+1], kernel_initializer='normal',activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=lr))\n    callbacks = [EarlyStoppingByLossVal(monitor='loss', value=5, verbose=1)]\n    print('------------------------------------------------------------------------')\n    \n    print(f'Validation index number {test_index} ...')\n    print(f'Training for fold {fold_no} ...')\n    model.fit(X_train, y_train,batch_size=batch,epochs=epoch_count,callbacks=callbacks,verbose=0)\n    p_train=model.predict(X_train)\n    p_test=model.predict(X_test)\n    print()\n    print(\"Train Metrics\")\n    l_train=regression_results(y_train,p_train)\n    r2_train.append(l_train[0])\n    mae_train.append(l_train[1])\n    mse_train.append(l_train[2])\n    print()\n    print(\"Validation metrics\")\n    l_test=regression_results(y_test,p_test)\n    r2_test.append(l_test[0])\n    mae_test.append(l_test[1])\n    mse_test.append(l_test[2])\n    \n    print()\n    # Increase fold number\n    fold_no = fold_no + 1","ea9faa5f":"import statistics\nprint(\"\\nTrain Mean Performance\")\nprint(statistics.mean(r2_train))\n\nprint(statistics.mean(mae_train))\nprint(statistics.mean(mse_train))\nprint(\"\\nValidation Mean Performance\")\nprint(statistics.mean(r2_test))\nprint(statistics.mean(mae_test))\nprint(statistics.mean(mse_test))","68ddfc61":"X=df2.drop(columns=train_removal)\nY=df2['COD ppm']\nmodel = Sequential()\nmodel.add(Dense(no_of_neurons[0], kernel_initializer='normal',input_dim = len(df2.columns)-len(train_removal), activation='relu'))\nfor i in range(number_of_additional_layers):\n    model.add(Dense(no_of_neurons[i+1], kernel_initializer='normal',activation='relu'))\nmodel.add(Dense(1, kernel_initializer='normal'))\nmodel.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=lr))\ncallbacks = [EarlyStoppingByLossVal(monitor='loss', value=early_stop_at, verbose=1)]\nhistory=model.fit(X, Y,batch_size=batch,epochs=epoch_count,callbacks=callbacks,verbose=0,validation_data=(df2_t.drop(columns=train_removal),df2_t['COD ppm']))\np=model.predict(X)\nl=regression_results(Y,p)","8338b1d5":"#l=regression_results(df2['COD ppm'],model.predict(df2.drop(columns=['BOD ppm', 'COD ppm','FC cfu\/100ml'])))","00038a30":"p_t=model.predict(df2_t.drop(columns=train_removal))\nl=regression_results(df2_t['COD ppm'],p_t)","bfe4e169":"plt.scatter(df2_t['COD ppm'],p_t)","39162654":"\"\"\"plt.scatter(df2.index,df2['COD ppm'])\nplt.scatter(df2.index,model.predict(df2.drop(columns=['BOD ppm', 'COD ppm','FC cfu\/100ml'])))\"\"\"","fb2fced6":"Layers and Neurons","36a133ce":"KFOLD levers\n","f51c0d5f":"## ","f3b81ff7":"Coulmn Removal"}}