{"cell_type":{"796c8e2f":"code","3ed348e2":"code","0ab56d8c":"code","d081ea59":"code","0f2ab35a":"code","ebd1cd13":"code","3f9bbc37":"code","d70e1708":"code","066e9911":"code","39d931e5":"code","b9c1440f":"code","00d40a55":"code","effb5b03":"code","46186e2c":"code","e8165526":"code","46162cbf":"code","72da78c6":"code","98852436":"code","904bc0d9":"code","e370d35e":"code","7c64142d":"code","b179cad3":"code","10dc295a":"code","a8017b35":"code","94fa3a9d":"code","91a699bf":"code","713de088":"code","0a95d93f":"code","3b05678c":"code","801c34c2":"code","93ba35d2":"code","8ef46569":"code","8d187a27":"code","6b518884":"code","a4ca9cb2":"code","ced0740c":"code","83733706":"code","63e79242":"code","96757279":"code","9a1940e2":"code","5534ce9e":"code","8e86a204":"code","8b7c353c":"code","f3e987c4":"code","17028960":"code","0209bf70":"code","02f0a9de":"code","03debf92":"code","e81092c4":"code","804c5970":"code","f1d41fdd":"code","ae422779":"code","c93e083a":"code","dd352ddd":"code","05ed24f7":"code","37e561e1":"code","1d7f5647":"code","972a06b1":"code","b8f5f067":"code","eb3bf1ec":"code","e9671e1d":"code","2fe0b865":"code","ca8bb4ce":"code","549d6418":"code","3172c411":"code","ef8475fb":"code","6f467be9":"code","64f90636":"code","a9dda264":"code","35702e87":"code","42d4f81b":"code","6144363c":"code","149495a2":"code","1dafc00f":"code","da4922c5":"code","d44d94f7":"code","1edb9b93":"code","a9b54d77":"code","39e082a7":"code","048233f7":"code","9ac10ace":"code","950efc3c":"code","9710a93b":"code","e54a387d":"code","1086b211":"code","e374134f":"code","70f12228":"code","0d1a677e":"markdown","af1d16f5":"markdown","2c990890":"markdown","7a8d29db":"markdown","e211a7ef":"markdown","8f9864f7":"markdown","01ee0d21":"markdown","e083ba1f":"markdown","10604e0c":"markdown","24bd0585":"markdown","a55d6dd2":"markdown","4cf401f4":"markdown","dfbbff1f":"markdown","5a81458c":"markdown","8fa2eeec":"markdown","0d833288":"markdown","e7f85712":"markdown","111498bd":"markdown","cda0b234":"markdown","aa2b2e28":"markdown","5d872a65":"markdown","59ebe22a":"markdown","0c3efc70":"markdown"},"source":{"796c8e2f":"# Importing all necessary tools\n\n# Importing the data analysis libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Matplotlib inline makes our plots appear inside the notebook\n%matplotlib inline\n\n# Importing the Evaluation tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve\n\n# Importing our machine learning models\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n","3ed348e2":"# 1. Importing the data\ndf = pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\ndf.head()","0ab56d8c":"df.head().T","d081ea59":"df.info()","0f2ab35a":"len(df)","ebd1cd13":"df[\"RainTomorrow\"].value_counts().plot(kind=\"bar\", color=[\"lightblue\", \"salmon\"]);","3f9bbc37":"# We have a class imbalance in our problem","d70e1708":"pd.crosstab(df.Rainfall, df.Location)","066e9911":"fig, ax = plt.subplots(figsize=(10,7))\n\nax.scatter(df.MaxTemp,\n            df.Rainfall,\n            color=[\"salmon\"])\nplt.title(\"MaxTemp vs Rainfall\")\nplt.ylabel(\"Rainfall\")\nplt.xlabel(\"MaxTemp\");","39d931e5":"fig, ax = plt.subplots(figsize=(10,7))\n\nax.scatter(df.MinTemp,\n            df.Rainfall,\n            color=[\"lightblue\"])\nplt.title(\"MinTemp vs Rainfall\")\nplt.ylabel(\"Rainfall\")\nplt.xlabel(\"MainTemp\");","b9c1440f":"df.head()","00d40a55":"fig, ax = plt.subplots(figsize=(10,10))\n\nax.scatter(df.Date[:1000],\n           df.Rainfall[:1000],\n           color=[\"blue\"])\nplt.title(\"Date vs Rainfall\")\nplt.ylabel(\"Rainfall\")\nplt.xlabel(\"Date\");","effb5b03":"# Import the data again but this time parse the dates \ndf = pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\",\n                 parse_dates=[\"Date\"])","46186e2c":"df.Date.dtype","e8165526":"df.Date[:1000]","46162cbf":"fig, ax = plt.subplots(figsize=(8,7))\n\nax.scatter(df.Date[:1000],\n           df.Rainfall[:1000],\n           color=[\"darkred\"])\nplt.title(\"Rainfall by Date\")\nplt.ylabel(\"Rainfall\")\nplt.xlabel(\"Date\");","72da78c6":"plt.style.use(\"default\")\nfig, ax = plt.subplots(figsize=(8,7))\n\nax.scatter(df.Date[:1000],\n           df.WindGustSpeed[:1000],\n           color=[\"blue\"])\nplt.title(\"WindGustSpeed by Date\")\nplt.ylabel(\"WindGustSpeed\")\nplt.xlabel(\"Date\");","98852436":"fig,(ax0,ax1) = plt.subplots(nrows=2,\n                             ncols=1,\n                             figsize=(10,8),\n                             sharex=True)\n\n# Scatter plot with WindSpeed9am\nax0.scatter(df.Date[:1000],\n            df.WindSpeed9am[:1000],\n            color=\"teal\");\n\nax0.set(title=\"WindSpeed9am vs Date\",\n        xlabel=\"date\",\n        ylabel=\"WindSpeed9am\")\n\n# Scatter plot with WindSpeed3pm\nax1.scatter(df.Date[:1000],\n            df.WindSpeed3pm[:1000],\n            color=\"pink\")\n\nax1.set(title=\"WindSpeed3pm vs Date\",\n        xlabel=\"date\",\n        ylabel=\"WindSpeed3pm\");","904bc0d9":"fig,(ax0,ax1) = plt.subplots(nrows=2,\n                             ncols=1,\n                             figsize=(10,8),\n                             sharex=True)\n\n# Scatter plot with Humidity9am\nax0.scatter(df.Date[:1000],\n            df.Humidity9am[:1000],\n            color=\"teal\");\n\nax0.set(title=\"Humidity9am vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Humidity9am\")\n\n# Scatter plot with Humidity3pm\nax1.scatter(df.Date[:1000],\n            df.Humidity3pm[:1000],\n            color=\"blue\")\n\nax1.set(title=\"Humidity3pm vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Humidity3pm\");","e370d35e":"fig,(ax0,ax1) = plt.subplots(nrows=2,\n                             ncols=1,\n                             figsize=(10,8),\n                             sharex=True)\n\n# Scatter plot with Pressure9am\nax0.scatter(df.Date[:1000],\n            df.Pressure9am[:1000],\n            color=\"red\");\n\nax0.set(title=\"Pressure9am vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Pressure9am\")\n\n# Scatter plot with Pressure3pm\nax1.scatter(df.Date[:1000],\n            df.Pressure3pm[:1000],\n            color=\"blue\")\n\nax1.set(title=\"Pressure3pm vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Pressure3pm\");","7c64142d":"fig,(ax0,ax1) = plt.subplots(nrows=2,\n                             ncols=1,\n                             figsize=(10,8),\n                             sharex=True)\n\n# Scatter plot with Temp9am\nax0.scatter(df.Date[:1000],\n            df.Temp9am[:1000],\n            color=\"navy\");\n\nax0.set(title=\"Temp9am vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Temp9am\")\n\n# Scatter plot with Temp3pm\nax1.scatter(df.Date[:1000],\n            df.Temp3pm[:1000],\n            color=\"firebrick\")\n\nax1.set(title=\"Temp3pm vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Temp3pm\");","b179cad3":"fig,(ax0,ax1) = plt.subplots(nrows=2,\n                             ncols=1,\n                             figsize=(10,8),\n                             sharex=True)\n\n# Scatter plot with Maxtemp\nax0.scatter(df.Date[:1000],\n            df.MaxTemp[:1000],\n            color=\"teal\");\n\nax0.set(title=\"Maxtemp vs Date\",\n        xlabel=\"date\",\n        ylabel=\"Maxtemp\")\n\n# Scatter plot with MinTemp\nax1.scatter(df.Date[:1000],\n            df.MinTemp[:1000],\n            color=\"navy\")\n\nax1.set(title=\"MinTemp vs Date\",\n        xlabel=\"date\",\n        ylabel=\"MinTemp\");","10dc295a":"df_tmp = df","a8017b35":"df_tmp.head().T","94fa3a9d":"df_tmp.Date.head(20)","91a699bf":"# Sort the DataFrame in Date order\ndf_tmp.sort_values(by=[\"Date\"], inplace=True, ascending=True)\ndf_tmp.Date.head(20)","713de088":"df_tmp.head()","0a95d93f":"# make a copy of the original dataset\ndf_temp = df.copy()","3b05678c":"df_temp[\"Year\"] = df_temp.Date.dt.year\ndf_temp[\"Month\"] = df_temp.Date.dt.month\ndf_temp[\"Day\"] = df_temp.Date.dt.day\ndf_temp[\"DayOfWeek\"] = df_temp.Date.dt.dayofweek\ndf_temp[\"DayOfYear\"] = df_temp.Date.dt.dayofyear","801c34c2":"df_temp.head().T","93ba35d2":"# Since we've enriched our DataFrame with datetime features we can now remove the Date column\ndf_temp.drop(\"Date\", axis=1,inplace=True)","8ef46569":"df_temp.Location.value_counts()","8d187a27":"df_temp.tail().T","6b518884":"df_temp.info()","a4ca9cb2":"pd.api.types.is_string_dtype(df_temp.Location)","ced0740c":"# Find the columns which contains strings\nfor label, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","83733706":"# This will turn all the string values into categorical values\nfor label, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_temp[label] = content.astype(\"category\").cat.as_ordered()","63e79242":"df_temp.info()","96757279":"df_temp.RainTomorrow.cat.categories","9a1940e2":"df_temp.Location.cat.codes","5534ce9e":"df_temp.isna().sum()","8e86a204":"### Saving preprocessed data\n# df_temp.to_csv(\"datasets\/temp.csv\",\n#                index=False)","8b7c353c":"df_temp.RainTomorrow.cat.codes","f3e987c4":"# Check for numerical values \nfor label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","17028960":"df_temp.Pressure9am","0209bf70":"# Check for which numeric columns have null values\nfor label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","02f0a9de":"# Filling numeric rows with the mean\nfor label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Fill missing numeric values with the mean\n            df_temp[label] = content.fillna(content.mean())","03debf92":"# Check for missing values now if any\nfor label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","e81092c4":"df_temp.isna().sum()","804c5970":"df_temp.head().T","f1d41fdd":"# Check to see how many examples were missing in MinTemp\n#df_temp.MinTemp_is_missing.value_counts()","ae422779":"df_temp.isna().sum()","c93e083a":"# Check for columns which arent numeric\nfor label,content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","dd352ddd":"pd.Categorical(df_temp.RainTomorrow).codes","05ed24f7":"df_temp.RainTomorrow.value_counts()","37e561e1":"# Filling categorical rows with the mode\nfor label, content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Turn Categories into numbers\n            df_temp[label] = pd.Categorical(content).codes\n            # Fill missing categorical values with the mode\n            df_temp[label] = content.fillna(content.mode()[0])","1d7f5647":"df_temp[\"Location\"] = df_temp[\"Location\"].cat.codes\ndf_temp[\"WindGustDir\"] = df_temp[\"WindGustDir\"].cat.codes\ndf_temp[\"WindDir9am\"] = df_temp[\"WindDir9am\"].cat.codes\ndf_temp[\"WindDir3pm\"] = df_temp[\"WindDir3pm\"].cat.codes\ndf_temp[\"RainToday\"] = df_temp[\"RainToday\"].cat.codes\ndf_temp[\"RainTomorrow\"] = df_temp[\"RainTomorrow\"].cat.codes","972a06b1":"df_temp.head().T","b8f5f067":"df_temp.isna().sum()","eb3bf1ec":"df_temp.RainTomorrow.value_counts()","e9671e1d":"df_temp.RainTomorrow.value_counts().plot(kind=\"bar\", \n                                         color=[\"lightblue\", \"salmon\"]);\n                       ","2fe0b865":"# Splitting the data\nX = df_temp.drop([\"RainTomorrow\"], axis=1)\ny = df_temp[\"RainTomorrow\"]\n\n# Splitting the data into train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","ca8bb4ce":"df_temp.info()","549d6418":"# We actually don't need these columns\ndf_temp = df_temp.drop([\"DayOfWeek\",\"DayOfYear\"], axis=1)","3172c411":"df_temp.Location.dtype","ef8475fb":"# %%time\n# # Instantiate the model\n# clf1 = LogisticRegression(n_jobs=-1,\n#                           random_state=12)\n# # fit the model\n# clf1.fit(X_train, y_train)","6f467be9":"#clf1.score(X_test, y_test)","64f90636":"%%time\n# Instantiate the 2nd model\nclf2 = RandomForestClassifier(n_jobs=-1,\n                              random_state=12)\n\n# fit the model\nclf2.fit(X_train, y_train)","a9dda264":"clf2.score(X_test, y_test)","35702e87":"# make a confusion matrix for randomForest Classifier\ny_preds = clf2.predict(X_test)","42d4f81b":"print(confusion_matrix(y_test, y_preds))","6144363c":"# Print the classification report \nprint(classification_report(y_test, y_preds))","149495a2":"# Visualize the confusion matrix\nsns.set(font_scale=1.5)\n\ndef plot_conf_mat(y_test, y_preds):\n    fig,ax = plt.subplots(figsize=(4,4))\n    ax = sns.heatmap(confusion_matrix(y_test, y_preds),\n                     annot=True,\n                     cbar=False)\n    plt.xlabel(\"true label\")\n    plt.ylabel(\"predicted label\")\n    \nplot_conf_mat(y_test,y_preds)","1dafc00f":"# plotting a correlation matrix \nplt.figure(figsize=(28,15))\nsns.heatmap(df_temp.corr(),\n            annot=True)\nplt.xticks(rotation=90)\nplt.show","da4922c5":"# Let's drop the highly correlated columns\ndf_temp = df_temp.drop([\"Temp9am\", \"Temp3pm\", \"Pressure3pm\",\"MaxTemp\"], axis=1)\ndf_temp.columns","d44d94f7":"# df_temp = df_temp.drop([\"Humidity9am\"], axis=1)\n# df_temp.columns","1edb9b93":"df_temp.head().T","a9b54d77":"# Split the data into X and y\nX = df_temp.drop([\"RainTomorrow\"], axis=1)\ny = df_temp[\"RainTomorrow\"]\n\n\n# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=12)","39e082a7":"%%time\n# Let's fit our model again\n# Instantiate the 2nd model\nclf2 = RandomForestClassifier(n_jobs=-1,\n                              random_state=12)\n\n# fit the model\nclf2.fit(X_train, y_train)","048233f7":"clf2.score(X_test, y_test)","9ac10ace":"y_preds = clf2.predict(X_test)","950efc3c":"print(confusion_matrix(y_test, y_preds))","9710a93b":"print(classification_report(y_test, y_preds))","e54a387d":"%%time\n# Instantiate the model\nclf1 = LogisticRegression(n_jobs=-1,\n                          random_state=12)\n\n# Fit the model\nclf1.fit(X_train, y_train)","1086b211":"# score the model\nclf1.score(X_test, y_test)","e374134f":"# make a confusion matrix and classification report\ny_preds = clf1.predict(X_test)\nprint(confusion_matrix(y_test, y_preds))","70f12228":"print(classification_report(y_test, y_preds))","0d1a677e":"## 2. EDA (Exploratory Data Analysis)\n\nThe goal here is to find out more about the data and become a \nsubject matter export on the dataset you're working with \n\n1. What question are you trying to solve?\n2. What kind of data do we have and how do we treat different types?\n3. What's missing from the data and how do you deal with it?\n4. What are the outliers and why should care about them?\n5. How can you add , change or remove features to get more from your data?\n","af1d16f5":"### Filling and turning categorical features into numbers","2c990890":"Thanks to Pandas Categories we now have a way to access all our data in form of numbers\nBut we still have to fill the missing data...","7a8d29db":"### First we will try the RandomForestClassifier\n\nThis model is without dropping the highly correlated columns from our dataset","e211a7ef":"So we got 85% accuracy on the baseline randomforestclassifier","8f9864f7":"## Machine learning modelling\n\nHere we're done with the data preprocessing and now we will proceed to building and fitting the machine learning models\n\nwe are going to experiment with 3 different models on our dataset and see which one performs the best \nwe will use the baseline models in the begining \n","01ee0d21":"### Sort the DataFrame by the Date \n\nwhen working with time series data, it's a good idea to sort it by the date","e083ba1f":"## 1. Importing the data","10604e0c":"From this we can infer that Humdity is lowest at January and starts increasing from February till August it is at it's peak on July \nand then from September to December it starts falling","24bd0585":"So After training and Evaluating 2 models we can see that RandomForestClassifier is giving us better results than LogisticRegression\nhence next we are going to tune our RandomForestClassifier to improve it \nwe can also try other models to see if they do a better job than these two but for the time being we will try tuning the randomforestclassifier","a55d6dd2":"## Filling missing values \n### Filling numeric missing values first\n","4cf401f4":"As we can see that our model is having troubles predicting the true negative values (yes rainfall) because of a class imbalance \nas we have more number of no rainfall samples in our dataset\n\n","dfbbff1f":"## Data Preprocessing","5a81458c":"From the correlation matrix we can infer that \n\n* Temp9am and MaxTemp are highly correlated\n* Temp9am and MinTemp are highly correlated\n* Temp3pm and MaxTemp are highly correlated \n* Temp3pm and MinTemp are highly correlated\n* Pressure9am and Pressure3pm are highly correlated\n* MinTemp and MaxTemp are highly correlated","8fa2eeec":"As Australia lies in the Southern Hemisphere the Summer Season is from December to February and Winter is from June to August so we can see high temps during summer and low during winter ","0d833288":"### Converting string to categories\none way we can turn all of our data into numbers is by converting them into pandas categories","e7f85712":"### Let's try the LogisticRegression model\n","111498bd":"There are no missing values since we have filled the missing values with the median of the data","cda0b234":"### Parsing dates \nwhen we are working with time series data we want to enrich time and date as much as possible \n\nwe can do that by telling pandas which column has dates in it using the `parse_dates` parameter","aa2b2e28":"### Adding datetime parameters for the `Date` column","5d872a65":"from this we can infer that \nDuring Summer \n\n* maximum MaxTemp is over 45 degrees\n* maximum MinTemp is over 25 degrees\n* minimum MaxTemp is between 20-30 degrees\n* minimum MinTemp is between 5-15 degrees\n\nDuring Winter \n* maximum MaxTemp is between 20-25 degrees\n* maximum MinTemp is between 5-10 degrees\n* minimum MaxTemp is just under 10 degrees\n* minimum MinTemp is under 0 degrees\n\n","59ebe22a":"## Data dictionary for the project\n\n1. Date - The date of observation\n2. Location - The common name of the location of the weather station\n3. MinTemp - The minimum temperature in degrees celsius\n4. MaxTemp - The maximum temperature in degrees celsius\n5. Rainfall - The amount of rainfall recorded for the day in mm\n6. Evaporation - The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n7. Sunshine - The number of hours of bright sunshine in the day.\n8. WindGustDir - The direction of the strongest wind gust in the 24 hours to midnight\n9. WindGustSpeed - The speed (km\/h) of the strongest wind gust in the 24 hours to midnight\n10. WindDir9am - Direction of the wind at 9am\n11. WindDir3pm - Direction of the wind at 3pm\n12. WindSpeed9am - Wind speed (km\/hr) averaged over 10 minutes prior to 9am\n13. WindSpeed3pm - Wind speed (km\/hr) averaged over 10 minutes prior to 3pm\n14. Humidity9am - Humidity (percent) at 9am\n15. Humidity3pm - Humidity (percent) at 3pm\n16. Pressure9am - Atmospheric pressure (hpa) reduced to mean sea level at 9am\n17. Pressure3pm - Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n18. Cloud9am - Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a         unit of eigths.It records how many\n19. Cloud3pm - Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a         description of the values\n20. Temp9am - Temperature (degrees C) at 9am\n21. Temp3pm - Temperature (degrees C) at 3pm\n22. RainToday - Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n23. RainTommorow - The amount of next day rain in mm. Used to create response variable RainTomorrow.     A kind of measure of the \"risk\".","0c3efc70":"# Rainfall prediction project (Classification)\n\n\nPredict next-day rain by training classification models on the target variable RainTomorrow\nThis dataset contains about 10 years of daily weather observations from many locations across Australia.\n\nRainTomorrow is the target variable to predict. It means -- did it rain the next day, Yes or No? This column is Yes if the rain for that day was 1mm or more.\n\n\n## Framework For the project\n\n\n* Step 1 - Download the data from kaggle- https:\/\/www.kaggle.com\/jsphyg\/weather-dataset-rattle-package\n\n* Step 2 - Import the data\n\n* Step 3 - EDA (Exploratory Data Analysis)\n\n* Step 4 - Data preparation (Converting the data into numeric form and filling the missing values)\n\n* Step 5 - Fit a Machine Learning model and Evaluate the model on the data \n\n* Step 6 - Improving the model (hyperparameter tuning)\n\n* Step 7 - Evaluating the final model (Confusion matrix, ROC curve, Precision, Recall, F1score)\n\n* Step 8 - Feature importance \n\n"}}