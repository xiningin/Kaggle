{"cell_type":{"a33b5276":"code","ee6c88d2":"code","51996489":"code","0bc5e4fa":"code","9710e7b2":"code","3543f3db":"code","0fc8a974":"code","a1c4dc82":"code","620c2118":"code","b07adda0":"code","13bc55e4":"code","62a09ae9":"code","65d244b9":"code","d530e747":"code","68e6e743":"code","cd4cf717":"code","3ee6fdf5":"code","080718ae":"code","bc4d6501":"code","408b9f76":"code","aec6e5a7":"code","f95cccdd":"code","c1ccc17c":"code","aa28c6e4":"code","179531a7":"code","b19817f0":"code","0f145bd2":"code","90325dfd":"code","6a744c38":"code","642dd72f":"code","ea13caa8":"code","fe91145f":"code","610fc7ce":"code","f38c7945":"code","c3e84d2d":"code","5d62e4ed":"code","bccdaed3":"code","b44d9f4b":"code","c038f1da":"code","8d2e7f23":"code","9ae89d0d":"code","981599b3":"code","aca12a0b":"code","d71955d2":"code","af0814b0":"code","ff8f7cfe":"code","64b96d5d":"code","58250c73":"code","75fb2bdc":"code","0c5000a2":"code","65752ca9":"code","0bd773ed":"code","92430611":"code","3b16d822":"code","6b44a2d3":"code","7a8d6b4e":"code","e05fcd35":"code","57af6814":"code","d2728a82":"code","54a7b660":"code","1878751a":"code","996f9941":"code","78a9957e":"code","14eb065e":"code","a9f661de":"code","98cda681":"code","881870f2":"code","8b4401c5":"code","81d00fe5":"code","8d53507d":"code","1a95f663":"code","3a7e96c6":"code","dd45ea27":"code","22473074":"code","4ee86ffa":"code","37b5cf23":"code","f5114d35":"code","ea1aaa89":"code","f219f2d7":"code","0f20774a":"code","c2f088b2":"code","78264997":"code","d8c39d77":"code","bfe8b50c":"markdown","41e4d71b":"markdown","b86f00f7":"markdown","6b84e5c4":"markdown","cb0cbcd8":"markdown","88ccf74a":"markdown","2651b719":"markdown","c5ea6c74":"markdown","7c3aa76f":"markdown","5dc09466":"markdown","7b200efb":"markdown","a79e6a90":"markdown","6f329865":"markdown","be98ce4b":"markdown","9528dd5a":"markdown","fda2a085":"markdown","efc9687a":"markdown","5f60cbef":"markdown","8a9c1ef6":"markdown","2154e499":"markdown","47d5b26d":"markdown","4ba4a19c":"markdown","c6307793":"markdown","a4329030":"markdown","85eabe7e":"markdown","da0cb191":"markdown","eac36685":"markdown","32c9d3ff":"markdown","64b689a1":"markdown","570be7ad":"markdown","9a5682d1":"markdown","8c2f8502":"markdown","5f3eea94":"markdown","05d7f8e7":"markdown","6c88faa8":"markdown","dd0aae79":"markdown","127e3995":"markdown","4df94e92":"markdown","568147f6":"markdown","f9814efa":"markdown","a0818c1e":"markdown","6b15f4e5":"markdown","9bbc12db":"markdown","6da008a0":"markdown","d9039f72":"markdown","d5e9eacd":"markdown","a500f40b":"markdown","fa0decfa":"markdown","f49cd79f":"markdown","d479a4ad":"markdown","19fa800c":"markdown","d566738d":"markdown","08084cb4":"markdown","062c4e0f":"markdown","9c87150c":"markdown","61afc3f0":"markdown","ee5e1a16":"markdown","dcb711a4":"markdown","ab3cd311":"markdown","9b9f710f":"markdown","7207c851":"markdown","779c1883":"markdown","c50b7192":"markdown","abad48ee":"markdown","6a1184ba":"markdown","59003ea1":"markdown","14c74400":"markdown","a9343156":"markdown","c1e7f9bb":"markdown","9ec6891b":"markdown","aaa223b2":"markdown","14c7261a":"markdown","9ba458bc":"markdown","066fe614":"markdown","ba4cc27a":"markdown","b2533546":"markdown","57d60a2a":"markdown","fabdd281":"markdown","1c720893":"markdown","aa62cc0b":"markdown","10e10298":"markdown","36caa660":"markdown","92cde48e":"markdown","5d941f52":"markdown","a52c9105":"markdown","bae2348a":"markdown","05437386":"markdown","7d00b889":"markdown"},"source":{"a33b5276":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import cross_val_score, cross_val_predict,train_test_split,GridSearchCV,ShuffleSplit\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, roc_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb ;\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nfrom scipy.stats import spearmanr\nfrom sklearn.inspection import permutation_importance\nfrom scipy.cluster.hierarchy import ward, fcluster\nfrom scipy.spatial.distance import pdist\nimport seaborn as sns\nfrom scipy import stats\nfrom pandas.plotting import scatter_matrix\nfrom scipy.cluster import hierarchy\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn import metrics\nfrom IPython.display import Image, display\nfrom sklearn.metrics import precision_recall_curve\n","ee6c88d2":"data=pd.read_csv('data.csv')\nkeep_data=data.copy()","51996489":"data.head()","0bc5e4fa":"data.info()","9710e7b2":"# \"Unnamed:32\" 'yi silelim\ndata=data.drop(columns=['Unnamed: 32','id'], axis=1)\ndata.head(2)","3543f3db":"data.isnull().sum()","0fc8a974":"data.describe().T","a1c4dc82":"data.drop(columns=['diagnosis']).hist(bins=50, figsize=(25,20)); ","620c2118":"\nfig, axes=plt.subplots(ncols=2, nrows=int(len(data.columns)\/2), figsize=(10, 28))\nfig.tight_layout(pad = 3.0)\n\nfor index,i in enumerate(data.drop(columns='diagnosis').columns):\n    data01 = data[data.diagnosis=='M'][str(i)]\n    data02 = data[data.diagnosis=='B'][str(i)]\n    ax1 = sns.distplot(data01, color = 'blue', ax=axes[int(index\/2)][int(index%2)],kde = True)\n    ax2 = sns.distplot(data02, color = 'red', ax=axes[int(index\/2)][int(index%2)], kde = True)","b07adda0":"fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\nsns.countplot(x='diagnosis', data=data, ax=axes[1])\naxes[0].pie(data.diagnosis.value_counts(), colors=[\"r\",\"g\"],autopct='%1.1f%%',labels=['B','M']);","13bc55e4":"rs = ShuffleSplit(n_splits=1, test_size=.25, random_state=42)\nfor train_index, test_index in rs.split(data):\n    train_set = data.loc[train_index]\n    test_set = data.loc[test_index]\ny_train, X_train =train_set[\"diagnosis\"],train_set.drop(columns=[\"diagnosis\"])\ny_test, X_test=test_set[\"diagnosis\"],test_set.drop(columns=[\"diagnosis\"])","62a09ae9":"len(X_train),len(y_train),len(X_test),len(y_test)","65d244b9":"# E\u011fitim setimizdeki oranlar\u0131n hemen hemen ayn\u0131 oldu\u011funu g\u00f6relim:\nfig, axes = plt.subplots(ncols=2, figsize=(12, 6))\nsns.countplot(x='diagnosis', data=train_set, ax=axes[1])\naxes[0].pie(train_set.diagnosis.value_counts(), colors=[\"r\",\"g\"],autopct='%1.1f%%',labels=['B','M']);","d530e747":"\nlabelencoder = LabelEncoder()\n#\u015eu an \"e\u011fitim setini\" i de\u011fi\u015ftirmek istemedi\u011fimden, bir kopyas\u0131n\u0131 kullan\u0131yorum. Bu, verimli bir y\u00f6ntem de\u011fil. Ama bu veri i\u00e7in bir sorun olmayacak.\ndata_copy=train_set.copy()\ndata_copy.diagnosis=labelencoder.fit_transform(train_set['diagnosis'])\ndata_copy.head(2)","68e6e743":"# \u00d6zelliklerin kanserli olma olmama durumu ile ilgili korelasyonlar\u0131: \ncorr_matrix = data_copy.corr()\ncorr_matrix[\"diagnosis\"].sort_values(ascending=False)","cd4cf717":"attributes=[\"concave points_worst\",\"perimeter_worst\",\n\"concave points_mean\",\"radius_worst\",\"perimeter_mean\"]","3ee6fdf5":"#burada sadece\nscatter_matrix(data_copy[attributes], figsize=(20, 20));","080718ae":"plt.figure(figsize=(20,20))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr_matrix, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap=cmap)\nplt.show()","bc4d6501":"labelencoder = LabelEncoder()\ny_train=labelencoder.fit_transform(y_train)\ny_test=labelencoder.fit_transform(y_test)\n","408b9f76":"y_train[:10]","aec6e5a7":"\ntree_clf=DecisionTreeClassifier(random_state=42)\nxgb_clf= xgb.XGBClassifier(random_state=42)\nknn_clf=KNeighborsClassifier(random_state=42)\nlog_clf = LogisticRegression(random_state=42)\nrnd_clf = RandomForestClassifier(random_state=42)\nsvm_clf = SVC(probability=True,random_state=42)\nestimators_=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('xgb', xgb_clf), ('knn', knn_clf),('tree', tree_clf)]\ndef get_scores(X_train_,y_train=y_train, estm=estimators_,voting=True):\n\n    estimators=[]\n    for name, estimator in estm:\n        estimators.append(estimator)\n    \n    if(voting==True):\n        voting_clf = VotingClassifier(\n            estimators=estm,\n            voting='soft'\n        )\n        voting_clf.fit(X_train_, y_train)\n        estimators.append(voting_clf)\n\n\n        \n    for  estimator in estimators:\n        \n        estimator.fit(X_train_, y_train)\n        \n        from sklearn.model_selection import cross_val_score\n        \n        print(estimator.__class__.__name__, \"\\nf1_score:{:.3f}-----recall: {:.3f}------ precision:{:.3f} \".format(\n              cross_val_score( estimator, X_train_, y_train, cv=4, scoring=\"f1\").mean(),\n              cross_val_score( estimator, X_train_, y_train, cv=4, scoring=\"recall\").mean(),\n              cross_val_score( estimator, X_train_, y_train, cv=4, scoring=\"precision\").mean()\n             ), sep=\"   \")","f95cccdd":"get_scores(X_train,estm=estimators_)","c1ccc17c":"labelencoder.fit(y_train)\ny_train=labelencoder.transform(y_train)\ny_test=labelencoder.transform(y_test)\ny_train[:20],y_test[:20]","aa28c6e4":"get_scores(X_train, estm=estimators_)","179531a7":"# \u00d6zelliklerin kanserli olma olmama durumu ile ilgili korelasyonlar\u0131: \ncorr_matrix_abs = train_set.corr()\n#corr_matrix_abs[\"diagnosis\"].sort_values(ascending=False)","b19817f0":"upper_tri = corr_matrix_abs.where(np.triu(np.ones(corr_matrix_abs.shape),k=1).astype(np.bool))\nupper_tri","0f145bd2":"#burada 0.95'ten y\u00fcksek korelasyona sahip de\u011ferleri sildik. Ama bu de\u011fer evrensel kabul g\u00f6ren bir de\u011fer de\u011fildir. De\u011fi\u015febilir. \nto_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\nprint(to_drop)","90325dfd":"train_set[\"diagnosis\"]=y_train\n\ndroped_train_data=train_set.drop(columns=to_drop, axis=1)\ndroped_train_data.head(3)","6a744c38":"# \u00d6zelliklerin kanserli olma olmama durumu ile ilgili korelasyonlar\u0131: \ndroped_train_data[\"diagnosis\"]=y_train # asa\u011f\u0131daki heapmap'i \u00e7izdirmek i\u00e7in \u015funu ekledik.\ncorr_matrix_abs = droped_train_data.corr()\ncorr_matrix_abs[\"diagnosis\"].sort_values(ascending=False)","642dd72f":"plt.figure(figsize=(20,20))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr_matrix_abs, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap=cmap)\nplt.show()","ea13caa8":"X_train.shape, X_test.shape, droped_train_data.drop(\"diagnosis\",axis=1).shape","fe91145f":"get_scores(droped_train_data.drop(\"diagnosis\",axis=1), estm=estimators_)","610fc7ce":"droped_train_data.shape","f38c7945":"from sklearn.inspection import permutation_importance\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)\nresult = permutation_importance(clf, X_train, y_train, n_repeats=10,\n                                random_state=42)\nperm_sorted_idx = result.importances_mean.argsort()\n\ntree_importance_sorted_idx = np.argsort(clf.feature_importances_)\ntree_indices = np.arange(0, len(clf.feature_importances_)) + 0.5\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\nax1.barh(tree_indices,\n         clf.feature_importances_[tree_importance_sorted_idx], height=0.7)\nax1.set_yticks(tree_indices)\nax1.set_yticklabels(X_train.columns[tree_importance_sorted_idx])\nax1.set_ylim((0, len(clf.feature_importances_)))\nax2.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n            labels=X_train.columns)\nfig.tight_layout()\nplt.show()","c3e84d2d":"\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\ncorr = spearmanr(X_train).correlation\ncorr_linkage = hierarchy.ward(corr)\ndendro = hierarchy.dendrogram(\n    corr_linkage, labels=X_train.columns, ax=ax1, leaf_rotation=90\n)\ndendro_idx = np.arange(0, len(dendro['ivl']))\n\nax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\nax2.set_xticks(dendro_idx)\nax2.set_yticks(dendro_idx)\nax2.set_xticklabels(dendro['ivl'], rotation='vertical')\nax2.set_yticklabels(dendro['ivl'])\nfig.tight_layout()\n\nplt.show()","5d62e4ed":"cluster_ids = hierarchy.fcluster(corr_linkage, 0.8, criterion='distance') #e\u015fik: 0.8\ncluster_id_to_feature_ids = defaultdict(list)\nfor idx, cluster_id in enumerate(cluster_ids):\n    cluster_id_to_feature_ids[cluster_id].append(idx)\nselected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n\nX_train_sel = X_train.iloc[:,selected_features]\nX_test_sel = X_test.iloc[:,selected_features]","bccdaed3":"X_train_sel.shape","b44d9f4b":"# kalan \u00f6zellikler\nX_train_sel.columns","c038f1da":"X_train_sel.head(4)","8d2e7f23":"# \u00d6zelliklerin kanserli olma olmama durumu ile ilgili korelasyonlar\u0131: \nX_train_sel[\"diagnosis\"]=y_train # asa\u011f\u0131daki heapmap'i \u00e7izdirmek i\u00e7in \u015funu ekledik.\ncorr_matrix = X_train_sel.corr()\ncorr_matrix[\"diagnosis\"].sort_values(ascending=False)\nplt.figure(figsize=(20,20))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr_matrix, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap=cmap)\nplt.show()","9ae89d0d":"X_train_sel=X_train_sel.drop(columns='diagnosis', axis=1)","981599b3":"X_train_sel.shape","aca12a0b":"#\u00f6zellik d\u00fcs\u00fcrmeden once:\nget_scores(X_train, estm=estimators_)","d71955d2":"#ozellik d\u00fcs\u00fcrd\u00fckten sonra\nget_scores(X_train_sel, estm=estimators_)","af0814b0":"def plotBoxplot(columns, data, ncols=7, nrows=5):\n    fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(20,12))\n    fig.tight_layout(pad=4.0)\n\n    col = 0\n    row = 0\n    colors = ['#bad9e9', '#7ab6d6', '#3c8abd','#7ab6d6','#bad9e9', '#3c8abd','#7ab6d6',]\n\n\n    for i, column in enumerate(columns):\n        sns.boxplot(y=column, data=data, ax=axes[row][col], color=colors[col])\n\n        if (i + 1) % 7 == 0:\n            row += 1\n            col = 0\n        else:\n            col += 1\nplotBoxplot(X_train.columns, X_train)","ff8f7cfe":"sns.boxplot(x= X_train.texture_mean)","64b96d5d":"def outlierLimit(column):\n    q1, q3=np.nanpercentile(column, [25, 75])#column\u0131n  %25 ve %75 lik y\u00fczdeli\u011fine gelen k\u0131s\u0131mlar\u0131 ald\u0131k\n    IQR=q3-q1 #bu de\u011fer standartt\u0131r ->Interquartile range\n    ust_limit=q3+IQR*1.5 # alt ve \u00fcst s\u0131n\u0131rlar\u0131 ald\u0131k. \n    alt_limit=q1-IQR*1.5\n    return alt_limit, ust_limit\nprint(outlierLimit(X_train.texture_mean))","58250c73":"def outliers_to_change(data):\n    for col in data.columns:\n        col_=data[col]#se\u00e7ili s\u00fctunun dizisini ald\u0131k\n        alt, ust=outlierLimit(col_)\n        col_[col_<alt]=alt #dizide \u00fcst s\u0131n\u0131rdan b\u00fcy\u00fck olanlar\u0131 \u00fcst s\u0131n\u0131ra k\u00fc\u00e7\u00fck olanlar\u0131 alt s\u0131n\u0131ra e\u015fitledik\n        col_[col_>ust]=ust\n        #print(\"column \", col, \"alttan dusen= \", sum(col_[col_<alt]),\"  ustten dusen:\", len(col_[col_>alt]))\nX_test_outliers_done=X_test_sel.copy()\nX_train_outliers_done=X_train_sel.copy()\noutliers_to_change(X_train_outliers_done) # traindeki outlierslar d\u00fczenlendi\noutliers_to_change(X_test_outliers_done) # testteki outlierlar d\u00fczenlendi","75fb2bdc":"sns.boxplot(x= X_train_outliers_done.texture_mean)","0c5000a2":"plotBoxplot(X_train_outliers_done.columns, X_train_outliers_done, nrows=3)","65752ca9":"get_scores(X_train_sel)","0bd773ed":"get_scores(X_train_outliers_done)","92430611":"clf=LocalOutlierFactor(n_neighbors=30, contamination=0.2)\nclf.fit_predict(X_train_outliers_done)[:40]","3b16d822":"#\u015eimdi, elimizde her g\u00f6zlem i\u00e7in skorlar var:\ntrain_scores=clf.negative_outlier_factor_\nnp.sort(train_scores)[:50]","6b44a2d3":"fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(14,4))\naxes[0].plot(np.sort(train_scores))\naxes[1].plot(np.sort(train_scores)[:35])","7a8d6b4e":"esik_deger=np.sort(train_scores)[8] #1.9'U E\u015e\u0130K OLARAK SE\u00c7T\u0130K.\nesik_deger\nX_train_outliers_done_done=X_train_sel[train_scores>esik_deger]\ny_train_instances=y_train[train_scores>esik_deger]","e05fcd35":"X_train_outliers_done_done.head()","57af6814":"y_train_instances[:10]","d2728a82":"get_scores(X_train_sel)","54a7b660":"get_scores(X_train_outliers_done_done,y_train=y_train_instances)","1878751a":"sc=StandardScaler().fit(X_train_sel)\nX_train_sel_scaled=sc.transform(X_train_sel)\nX_test__sel_scaled=sc.transform(X_test_sel)\nget_scores(X_train_sel_scaled)","996f9941":"def select_best_params(model, hiperparams):\n    model = model\n    #grid_search = GridSearchCV(model, param_grid, cv=5,\n    #    scoring='f1', n_jobs=-1, refit=True)\n    grid_search = GridSearchCV(model, hiperparams,refit=True, scoring=\"recall\")\n    grid_search.fit(X_train_sel_scaled, y_train)\n    return grid_search.best_params_, grid_search.best_estimator_","78a9957e":"#Round1     --> 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'reg_lambda': 1.0, 'scale_pos_weight': 3\nparam_grid_xgb = {\n    'max_depth': [3, 4, 5],\n    'learning_rate': [0.2,0.1, 0.01, 0.05],\n    'gamma': [0, 0.25, 1.0],  \n    'reg_lambda': [0, 1.0, 10.0],\n    'scale_pos_weight': [1, 3, 5] # NOTE: XGBoost recommends sum(negative instances) \/ sum(positive instances)\n}\n#round2 --> 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'reg_lambda': 1.0, 'scale_pos_weight': 3 || ayn\u0131 hiperparametreler.\n#param_grid_xgb = {\n#    'max_depth': [2, 3],\n#    'learning_rate': [0.01,0.05,0.1],\n#    'gamma': [0],  \n#    'reg_lambda':[ 1.0], \n#    'scale_pos_weight':[3]\n#}\nprint(select_best_params(xgb_clf, param_grid_xgb))","14eb065e":"tuned_xgb_clf= xgb.XGBClassifier(gamma= 0, learning_rate= 0.1, max_depth= 5, reg_lambda= 10.0, scale_pos_weight= 3, random_state=42)","a9f661de":"#round 1 -> {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\nparam_grid_svm = {'C': [0.1,1,10,100,300,1000], 'gamma': [1,0.1,0.01,0.001,0.0001],'kernel': ['rbf', 'poly', 'sigmoid']}\n#    best params-->  {'C': 20, 'gamma': 0.1, 'kernel': 'poly'} \nresult_for_svm=select_best_params(svm_clf,  param_grid_svm)\nprint(\"best params for svm=\", result_for_svm[0])","98cda681":"tuned_svm=SVC(C=100, gamma=0.1, kernel=\"rbf\", probability= True, random_state=42)","881870f2":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000,10000],       #---->> 'C': 1000, 'penalty': 'l2'\n             'penalty':['l1', 'l2']}\nprint(select_best_params(log_clf, param_grid))\n","8b4401c5":"tuned_log= LogisticRegression(C=100, penalty=\"l2\", random_state=42)","81d00fe5":"#Tune edildikten sonra\ntuned_estimators=[('lr', tuned_log),('svc', tuned_svm), ('xgb', tuned_xgb_clf)]\nget_scores(X_train_sel_scaled, estm=tuned_estimators, )","8d53507d":"# tune edilmeden \u00f6nceki skorlar\u0131m\u0131z \u015fuydu:\nestimators_=[('lr', log_clf), ('svc', svm_clf), ('xgb', xgb_clf)]\nget_scores(X_train_sel_scaled, estm=estimators_, )","1a95f663":"#y_scores = cross_val_predict(tuned_svm, X_train_sel_scaled, y_train, cv=3,\n#    method=\"decision_function\")\n#from sklearn.metrics import precision_recall_curve\n#precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n#def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n#    plt.plot(thresholds, precisions[:-1], \"r--\", label=\"Precision\")\n#    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n#    plt.xlabel(\"Threshold\")\n#    plt.legend(loc=\"upper left\")\n#    plt.ylim([0, 1])\n#plt.figure(figsize=(8, 4))\n#plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n#plt.xlim([-3, 14])\n#\n#plt.show()\n\n","3a7e96c6":"y_scores = cross_val_predict(tuned_svm, X_train_sel_scaled, y_train, cv=3,\n    method=\"decision_function\")\nfpr, tpr, thresholds = roc_curve(y_train, y_scores)\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.03, 1.03, -0.03, 1.03])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\nplot_roc_curve(fpr, tpr)\nplt.show()","dd45ea27":"\ndef get_roc_curves(X_train_,y_train=y_train, estm=tuned_estimators,voting=True):\n    estimators=[]\n    for name, estimator in estm:\n        estimators.append(estimator)\n    \n    if(voting==True):\n        voting_clf = VotingClassifier(\n            estimators=estm,\n            voting='soft'\n        )\n        voting_clf.fit(X_train_, y_train)\n        estimators.append(voting_clf)\n\n\n    for  estimator in estimators:\n        plt.rcParams['figure.figsize'] = [15, 10]\n        estimator.fit(X_train_, y_train)\n        \n        from sklearn.model_selection import cross_val_score\n        y_probas_forest = cross_val_predict(estimator, X_train_, y_train, cv=3,\n            method=\"predict_proba\")\n        y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n        fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train,y_scores_forest)\n        plot_roc_curve(fpr_forest, tpr_forest, estimator.__class__.__name__ )\n        plt.legend(loc=\"bottom right\")\n        from sklearn.metrics import roc_auc_score\n        print(estimator.__class__.__name__  ,\"\\nAUC score: \", roc_auc_score(y_train, y_scores_forest))\n    plt.show()","22473074":"get_roc_curves(X_train_sel_scaled)","4ee86ffa":"#Roc Curve\nvoting_clf = VotingClassifier(\n    estimators=tuned_estimators,\n    voting='soft'\n)\nvoting_clf.fit(X_train_sel_scaled, y_train)\ny_probas_voting = cross_val_predict(voting_clf, X_train_sel_scaled, y_train, cv=3,\n            method=\"predict_proba\")\ny_scores_voting = y_probas_voting[:, 1] # score = proba of positive class\nfpr_voting, tpr_voting, thresholds_voting = roc_curve(y_train,y_scores_voting)\nplt.rcParams['figure.figsize'] = [10, 6]\nplot_roc_curve(fpr_voting, tpr_voting, voting_clf.__class__.__name__ )\nplt.legend(loc=\"bottom right\")","37b5cf23":"y_preds_voting = cross_val_predict(voting_clf, X_train_sel_scaled, y_train, cv=3)\n\ndef display_conf_matrix(y_pred, y_actual):\n    cm = metrics.confusion_matrix(y_actual, y_pred)\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\n    for i in range(cm.shape[0]):\n         for j in range(cm.shape[1]):\n            ax.text(x=j, y=i,\n                    s=cm[i, j], \n                    va='center', ha='center')\n    plt.xlabel('Tahmin Edilen De\u011ferler', )\n    plt.ylabel('Ger\u00e7ek De\u011ferler')\n    plt.show()\n    print(classification_report(y_actual, y_pred))\ny_probas_forest = cross_val_predict(voting_clf, X_train_sel_scaled, y_train, cv=3)\ndisplay_conf_matrix(y_preds_voting, y_train)","f5114d35":"y_scores = cross_val_predict(voting_clf, X_train_sel_scaled, y_train, cv=3,\n    method=\"predict_proba\")\ny_scores=y_scores[:, 1]\nprecisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.scatter([0.21,0.25,0.29,0.32],[0.95,0.95,0.95,0.95],s=30,color='k',marker='.')\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"upper left\")\n    plt.ylim([0, 1])\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()\n","ea1aaa89":"y_train_pred_90 = (y_scores > 0.32)","f219f2d7":"precision_score(y_train, y_train_pred_90)","0f20774a":"recall_score(y_train, y_train_pred_90)","c2f088b2":"y_test_probs=voting_clf.predict_proba(X_test__sel_scaled)[:, 1]\ny_test_pred_032 = (y_test_probs > 0.32)\nprecision_score(y_test, y_test_pred_032), recall_score(y_test, y_test_pred_032)","78264997":"# Final Confusion matris:\ndisplay_conf_matrix(y_test_pred_032, y_test)","d8c39d77":"Model, toplam 54 kanserli hastan\u0131n bulundu\u011fu test setinde, 52 kanserli hastay\u0131 tespit edebildi ve 89 kansersiz hastan\u0131n 9'unun kanserli oldu\u011funu tahmin etti. ","bfe8b50c":"Matrisin alt \u00fc\u00e7geni \u00fcst \u00fc\u00e7geni ile ayn\u0131 de\u011ferleri i\u00e7erdi\u011finden ve k\u00f6\u015fegendeki de\u011ferler daima 1 oldu\u011fundan, sadece alt \u00fc\u00e7gen matrisi alal\u0131m:","41e4d71b":"ROC e\u011frisi, Recall\/Precision aras\u0131ndaki dengeyi bulmam\u0131z i\u00e7in bizim i\u00e7in olduk\u00e7a kullan\u0131\u015fll\u0131 olacakt\u0131r. \n\nROC e\u011frisi, True Positive(kanserli tahmin edilen kanserli hasta) oran\u0131n\u0131n False Positive(kanserli tahmin edilen kansersiz hasta) oran\u0131 ile birlikte de\u011fi\u015fimini g\u00f6steren olduk\u00e7a fazla kullan\u0131lan, kullan\u0131\u015fl\u0131 bir grafiktir.\n\nRoc e\u011frisi \u015f\u00f6yle bir e\u011fridir:","b86f00f7":"Yine de\u011ferlerin pek de\u011fi\u015fmedi\u011fini g\u00f6r\u00fcyoruz. Malesef. \u0130ster inan\u0131n ister inanmay\u0131n, bu durumun verinin temiz olu\u015fuyla olduk\u00e7a ilgili olabilece\u011fini s\u00f6yleyebiliriz :D\n\n**X_train_sel** ile devam :)","6b84e5c4":"**Eksik de\u011fer kontrol\u00fc**","cb0cbcd8":"# 7-\u00c7\u00f6z\u00fcm\u00fc Sunmak | Sonu\u00e7","88ccf74a":"Her neyse, hangi modeli se\u00e7ece\u011fimize karar vermeden \u00f6nce son olarak __ROC__ e\u011frisine bakal\u0131m:","2651b719":"G\u00f6r\u00fcld\u00fc\u011f\u00fc gibi g\u00f6rece daha iyi recall de\u011ferleri elde ettik. Ama \u015funu s\u00f6ylemeliyim ki \u00f6nemsenecek kadar b\u00fcy\u00fck de\u011fi\u015fimler elde etmedik, malesef. ","c5ea6c74":"***Bunun i\u00e7in \u00f6ncelikle kanserli olup olmama durumunu 1 ve 0 ile ifade edelim. ( orijinal veriye dokunmadan )***\n>__M: 1 ->__  Kanser\n\n>__B: 0 ->__  Kanser yok","7c3aa76f":"G\u00f6r\u00fcld\u00fc\u011f\u00fc gibi, \u00f6zelliklerin 7'sini d\u00fc\u015f\u00fcrmemize ra\u011fmen olu\u015fan fark pek b\u00fcy\u00fck de\u011fil. \u015eu an i\u00e7in normal train-test setimizi de\u011fi\u015ftirmeden devam edelim... Bir ba\u015fka yakla\u015f\u0131ma daha bakal\u0131m","5dc09466":"\n\u015eimdi, \u00f6zellikleri scale etmeden \u00f6nce bir de;\n### \u00c7ok De\u011fi\u015fkenli Ayk\u0131r\u0131 G\u00f6zlem Analizi\n\n\u015eimdi de \u00e7ok de\u011fi\u015fkenli ayk\u0131r\u0131 g\u00f6zlem analizi ile sonu\u00e7lar\u0131n de\u011fi\u015fimini g\u00f6zlemleyelim. Tek de\u011fi\u015fkenli analizde tek tek \u00f6zelliklere bak\u0131l\u0131rken, burada tespit edilmeye \u00e7al\u0131\u015f\u0131lan b\u00fct\u00fcn\u00fcyle bir g\u00f6zlemin **\"ayk\u0131r\u0131l\u0131\u011f\u0131d\u0131r\"**. \u00d6rne\u011fin \u015funu tespit etmeye \u00e7al\u0131\u015f\u0131r\u0131z: 17 ya\u015f\u0131nda 3 \u00e7ocuk sahibi bir insan. Bu teroide m\u00fcmk\u00fcn olsa da, ayk\u0131r\u0131 bir durumdur ve modeli olumsuz etkiler.","7b200efb":"Ve y\u00fcksek korelasona sahip de\u011ferleri d\u00fc\u015f\u00fcrelim: ","a79e6a90":"Evvet! S\u0131n\u0131rlar\u0131 do\u011fru bulduk. \u00d6yleyse, her column i\u00e7in bu s\u0131n\u0131rlar\u0131 tek tek gezip outlier lar\u0131 bulup, d\u00fczenleyebiliriz.","6f329865":"#### \u0130li\u015fkili \u00f6zellikleri d\u00fc\u015f\u00fcr\u00fclm\u00fc\u015f \u00f6zellikler ile Accuracy_score: ","be98ce4b":"**Veriseti: ile ilgili k\u0131sa bir a\u00e7\u0131klama** \n\n    1.Column:\n    \n        Her bir \u00f6rne\u011fin kendine ait ID'si.\n\n    2.Column:\n\n        M = Malignant | K\u00f6t\u00fc Huylu - Present (M): Kanser\n        B = Benign | \u0130yi Huylu - Absent (B): Kanser de\u011fil\n    \n    3-32 Column:\n    \n        G\u00f6r\u00fcnt\u00fclerin say\u0131salla\u015ft\u0131r\u0131lmas\u0131 ile elde edilen numerik de\u011ferler.","9528dd5a":"# Veriyi algoritmalar i\u00e7in haz\u0131rlama\/ veri manip\u00fclasyonu","fda2a085":"Bu grafiklere bakarak: Ba\u011f\u0131ms\u0131z de\u011fi\u015fken ile y\u00fcksek ili\u015fkisi bulunan \u00f6zelliklerin **kendi aralar\u0131nda da y\u00fcksek ili\u015fkiye sahip oldu\u011funu g\u00f6r\u00fc\u00fcyoruz**. Bu durum, yorumlanabilir bir model aray\u0131\u015f\u0131nda iseniz kabul edilemezdir. Ayn\u0131 \u015fekilde do\u011frusal regresyon modelleri i\u00e7in de berbatt\u0131r. \u00c7\u00fcnk\u00fc... bu de\u011fi\u015fkenlerin birinin olmamas\u0131 durumunda de\u011fi\u015fen pek bir \u015fey olmaz, mesela \"kad\u0131n olmak\" s\u00fctunun oldu\u011fu verisetinde \"erkek olmak\" s\u00fctunun olmas\u0131na gerek yoktur \u00e7\u00fcnk\u00fc \"erkek olmak\" \"kad\u0131n olmak\" ile ifade edilebilir. Bu hem gereksiz fazla \u00f6zelliktir, hem de, daha \u00f6nemlisi, dedi\u011fim gibi \u00f6zelliklerin yorumlanabilirli\u011fi konusunda b\u00fcy\u00fck sorunalr yarat\u0131r. Sa\u011fl\u0131kl\u0131 yorumlar yap\u0131lmas\u0131na engel olur.  \n\nBu grafikte yaln\u0131zca en ili\u015fkili 5 \u00f6zelli\u011fi \u00e7izdirdik. \u00c7\u00fcnk\u00fc t\u00fcm \u00f6zellikleri dahil etseydik 30*30=900 grafik olacakt\u0131, bunu \u015fu an i\u00e7in yapmayal\u0131m :)\nAma bir \u00e7aresi var, a\u015fa\u011f\u0131daki grafik i\u015fimize yarayacakt\u0131r:","efc9687a":"### Nerede Kalm\u0131\u015ft\u0131k?\n\n\u00d6zellikler ve hedef de\u011fi\u015fken aras\u0131ndaki korelasyonlara bir g\u00f6z atacakt\u0131k. ","5f60cbef":"## Feature scaling:","8a9c1ef6":"---\n---\n---\n---","2154e499":"Bir e\u015fik de\u011feri se\u00e7ip(bu e\u015fik de\u011feri bir k\u0131r\u0131l\u0131m\u0131n oldu\u011fu nokta olabilir. \u00d6rne\u011fin skorlar 10,9,8,3,2,1 \u015feklinde gidiyorsa 8 ve yukar\u0131s\u0131 outlier g\u00f6zlemler olarak se\u00e7ilebilir.) Bunu daha iyi g\u00f6rmek i\u00e7in bir grafik \u00e7izlim:","47d5b26d":"XGBClassifier, RandomForestClassifier umut vadediyor. Bu iki algoritmay\u0131 ve votin classifier\u0131n \u00fczeridne drumak mant\u0131kl\u0131 olur. Ama \u015fu an t\u00fcm algoritmalar\u0131 denemeye devam edec\u011fim.","4ba4a19c":"# 5-6 -> Model se\u00e7imi ve hiperparametre ayar\u0131","c6307793":"Art\u0131k 30 yerine 14 \u00f6zelli\u011fimiz var! Yine, yeni \u00f6zelliklerimizin heapMap'ine bakacak olursak:\n","a4329030":"Biraz daha \u00fcst\u00fcne gidelim. \u00d6zel oalrak bir feature se\u00e7elim ve oitliers s\u0131n\u0131rlar\u0131n\u0131 bulmay\u0131 bir deneyelim:","85eabe7e":"Ayk\u0131r\u0131 g\u00f6zlemleri boxplot ile g\u00f6zlemleyelim. S\u0131n\u0131r\u0131n d\u0131\u015f\u0131ndaki g\u00f6zlemler, outlier de\u011ferler olara kde\u011ferlendirilecek.. \n\nBurada **S\u0131n\u0131r** dedi\u011fim Quantileslara g\u00f6re belirlenen noktalard\u0131r. Bilinmiyorsa ara\u015ft\u0131r\u0131lmal\u0131. \u00d6nemli. Ve bu ayk\u0131r\u0131 g\u00f6zlem analizi i\u00e7in, de\u011fi\u015fkenlerin ormal da\u011f\u0131l\u0131ma sahip olmas\u0131 gerekti\u011fini unutmay\u0131n. \u015eu an i\u00e7in, bizim de\u011fi\u015fkenlerimiz normal da\u011f\u0131l\u0131ma yak\u0131n\u0131s\u0131yor gibi g\u00f6r\u00fcnd\u00fc\u011f\u00fc i\u00e7in normal oldu\u011funu kabul ediyor ve devam ediyorum. ","da0cb191":"***\u00f6ncelikle kanserli olup olmama durumunu 1 ve 0 ile ifade edelim. ( orijinal veriye dokunmadan )***\n>__M: 1 ->__  Kanser\n\n>__B: 0 ->__  Kanser yok","eac36685":"Birbiri ile ili\u015fkili de\u011ferlerin oldu\u011funu ve bundan kurtulmam\u0131z\u0131 gerektirecek senaryolar\u0131n oldu\u011funu g\u00f6rm\u00fc\u015ft\u00fck. \u015eimdi bu senaryolardan birinde oldu\u011fumuzu d\u00fc\u015f\u00fcnelim ve birbiri ile ili\u015fkili olan, \"fazlal\u0131k\" olan \u00f6zelliklerden kurtulup ne olaca\u011f\u0131na bakal\u0131m. Ben burada bu i\u015fi elle yapaca\u011f\u0131m. Ama PCA, regularization, forests kullanarak daha farkl\u0131 yakla\u015f\u0131mlar ile \u00e7\u00f6zmenin daha mant\u0131kl\u0131 oldu\u011fu senaryolar da vard\u0131r. \u015eu an hepsine odaklanmayaca\u011f\u0131m. ","32c9d3ff":"Bu grafi\u011fe bakarak, benim projem i\u00e7in optimum TPR\/FPR de\u011fi\u015f toku\u015funun ger\u00e7ekle\u015fti\u011fi noktay\u0131 belirleyebilirim. %20'lik bir yanl\u0131\u015f pozitif oran\u0131n\u0131 kabul ederek %97'nin \u00fcst\u00fcnde ger\u00e7ek pozitif oran\u0131 yakalayabilece\u011fimi g\u00f6r\u00fcyorum. \u015eu grafi\u011fi \u00e7izelim, ve optimum thresholdumuzu belirleyip projemizi sunal\u0131m :)","64b689a1":"G\u00f6r\u00fclece\u011fi gibi burada birka\u00e7 tane \u00f6zelli\u011fin neredeyse \"1\" korelasyon katsay\u0131s\u0131na sahip. Bu soruna \"Multicollinearity\" denir.  Bu sorunu \u00e7\u00f6zmek i\u00e7in farkl\u0131 yakla\u015f\u0131mlar vard\u0131r, Lasso regresyon,  algoritmalar\u0131n\u0131 kullanarak \u00f6zellik se\u00e7ilebilir. Hangisinin en mant\u0131kl\u0131s\u0131 oldu\u011fu probleme g\u00f6re de\u011fi\u015fkenlik g\u00f6sterecektir. Bununla birlikte \u00d6zelliklerin birbiri ile ili\u015fkili olmas\u0131, yorumlanabilirli\u011fi etkilerken, tahmin ba\u015far\u0131s\u0131n\u0131 pek etkilemez. \n\n\u00d6rne\u011fin, \"Erkek olmak\" ve \"Kad\u0131n olmak\" gibi birbiri ile tamamen ili\u015fkili olan 2 \u00f6zelli\u011fin olms\u0131 halinde \"cinsiyetin\" ba\u011f\u0131ml\u0131 d\u011fei\u015fkene etkisi do\u011fru yorumlanamaz ama tahmin ba\u015far\u0131s\u0131 da \u00e7ok etkilenmez. Veri manip\u00fclasyonu k\u0131sm\u0131nda bu durumu irdeleyece\u011fiz. ","570be7ad":">Train-Test \u015feklinde ay\u0131rma i\u015fini klasik **\"train_test_split\"** ile de\u011fil, **ShuffleSplit** ile yapaca\u011f\u0131z. \u00c7\u00fcnk\u00fc elimizdeki \u00f6rnek say\u0131s\u0131 epey az ve bu y\u00fczden test ve train setlerindeki kanserli\/kanserli olmama orna\u0131n\u0131n yak\u0131n olmas\u0131n\u0131 istiyoruz. Aksi halde yanl\u0131l\u0131k olacakt\u0131r. ","9a5682d1":"LogisticRegression, SVC ve XGBClassifier algoritmalar\u0131 \u00fczerinde hiper parametre ayar\u0131 yapaca\u011f\u0131m. En iyi sonucu veren modeli se\u00e7ece\u011fim. En iyi hiper parametreleri se\u00e7tikten sonra bu hiper parametreler ile olu\u015fturulmu\u015f modeller \u00fczerinden, problemimiz i\u00e7in optimum recall\/precision dengesini bulmaya \u00e7al\u0131\u015faca\u011f\u0131z.","8c2f8502":"***From Hands-on-Machine Learning***: \"Bu a\u015famada verilerin bir k\u0131sm\u0131n\u0131 g\u00f6n\u00fcll\u00fc olarak bir kenara b\u0131rakmak garip gelebilir. Sonu\u00e7ta, verilere sadece h\u0131zl\u0131ca bir g\u00f6z att\u0131n\u0131z ve kesinlikle hangi algoritmalar\u0131 kullanaca\u011f\u0131n\u0131za karar vermeden \u00f6nce bu konuda \u00e7ok daha fazlas\u0131n\u0131 \u00f6\u011frenmelisiniz, de\u011fil mi? Bu do\u011fru, ancak beyniniz inan\u0131lmaz bir \u00f6r\u00fcnt\u00fc tespit sistemidir, bu da a\u015f\u0131r\u0131 uyuma e\u011filimli oldu\u011fu anlam\u0131na gelir: test setine bakarsan\u0131z, test verilerinde sizi bir se\u00e7meye y\u00f6nlendiren ilgin\u00e7 g\u00f6r\u00fcnen baz\u0131 modellere rastlayabilirsiniz. belirli t\u00fcrden Makine \u00d6\u011frenimi modeli. Test setini kullanarak genelleme hatas\u0131n\u0131 tahmin etti\u011finizde, tahmininiz \u00e7ok iyimser olacak ve beklendi\u011fi kadar iyi performans g\u00f6stermeyecek bir sistem ba\u015flatacaks\u0131n\u0131z. Buna, **veri g\u00f6zetleme \u00f6nyarg\u0131s\u0131** denir\"","5f3eea94":"**Peki buradan ne \u00e7\u0131karabiliriz?**\n> Genel olarak da\u011f\u0131l\u0131mlar\u0131n gauss(normal) da\u011f\u0131l\u0131m\u0131na sahip oldu\u011funu g\u00f6rsemde, baz\u0131 da\u011f\u0131l\u0131mlar birar\u0131n, __area_se__ gibi, gausstan biraz farkl\u0131 oldu\u011funu g\u00f6r\u00fcyorum. \n\n>__\u25fe__ \"hands-on-machine-learning\" kitab\u0131nda \u015fu s\u00f6ylenir: **\"Histogramlar\u0131n kuyruk a\u011f\u0131rl\u0131kl\u0131 olmalar\u0131, yani sola k\u0131yasla medyan\u0131n sa\u011f\u0131na daha fazla uzanmalar\u0131 baz\u0131 Makine \u00d6\u011frenimi algoritmalar\u0131n\u0131n kal\u0131plar\u0131 alg\u0131lamas\u0131n\u0131 biraz zorla\u015ft\u0131rabilir\"** (Sebebini tam olarak bilmiyorum). O y\u00fczden daha sonra bu nitelikleri daha \u00e7an \u015fekilli da\u011f\u0131l\u0131mlara sahip olacak \u015fekilde d\u00f6n\u00fc\u015ft\u00fcrmek denenebilir. Bunu da **standardizasyon** ile yapar\u0131z. Standardizasyon, Gauss da\u011f\u0131l\u0131m\u0131na ve farkl\u0131 ortalamalara ve standart sapmalara sahip \u00f6znitelikleri, ortalamas\u0131 0 ve standart sapmas\u0131 1 olan standart bir Gauss da\u011f\u0131l\u0131m\u0131na d\u00f6n\u00fc\u015ft\u00fcrmek i\u00e7in kullan\u0131\u015fl\u0131d\u0131r.\n\n>Bunun d\u0131\u015f\u0131nda de\u011ferlerin b\u00fcy\u00fck ihtimalle \u00f6l\u00e7eklendirilmi\u015f oldu\u011funu da farkedebiliriz (b\u00fcy\u00fck ihtimalle de\u011ferler oldu\u011funun birka\u00e7 bin kat\u0131 daha az\u0131 ya da daha fazlas\u0131yd\u0131.)","05d7f8e7":"E\u011fer \u00e7\u0131k\u0131p bu \u00f6zelliklerin da\u011f\u0131l\u0131m\u0131na bakarsan\u0131z, farkl\u0131 da\u011f\u0131l\u0131m g\u00f6sterenlerin, ba\u011f\u0131ms\u0131z de\u011fi\u015fken ile  genellikle y\u00fcksek korelasyona sahip olduklar\u0131n\u0131 g\u00f6rebilirsiniz.","6c88faa8":"## Veri temizleme\nEksik de\u011fer yok dolay\u0131s\u0131yla eksik de\u011ferler ile u\u011fra\u015fmayaca\u011f\u0131z. ","dd0aae79":"ScikitLearn dok\u00fcman\u0131: __\"\u00d6zellikler e\u015fdo\u011frusal oldu\u011funda, bir \u00f6zelli\u011fin perm\u00fctasyonunun modellerin performans\u0131 \u00fczerinde \u00e7ok az etkisi olacakt\u0131r, \u00e7\u00fcnk\u00fc ili\u015fkili bir \u00f6zellikten ayn\u0131 bilgileri alabilir. \u00c7ok Sat\u0131rl\u0131 \u00f6zellikleri i\u015flemenin bir yolu, Spearman s\u0131ra s\u0131ras\u0131 korelasyonlar\u0131 \u00fczerinde hiyerar\u015fik k\u00fcmeleme yapmak, bir e\u015fik se\u00e7mek ve her k\u00fcmeden tek bir \u00f6zellik tutmakt\u0131r. \u0130lk olarak, RandomForrest algoritmas\u0131n\u0131 kullanarak\u00f6zelliklerin \u00f6nem s\u0131ralamas\u0131na bakal\u0131m sonra ili\u015fkili \u00f6zelliklerin bir \u0131s\u0131 haritas\u0131n\u0131 \u00e7izelim:\"__\n","127e3995":"Feature Scaling\/ \u00d6zelik \u00d6l\u00e7eklendirme, veriye uygulanmas\u0131 gereken en \u00f6nemli d\u00f6n\u00fc\u015ft\u00fcrmelerden birisidir. Baz\u0131 istisnalar d\u0131\u015f\u0131nda(mesela random forrest i\u00e7in \u00f6zellik \u00f6l\u00e7eklendirmesi pek \u00f6nemli de\u011fildir) algoritmalar \u00f6l\u00e7eklendirilmi\u015f \u00f6zellikler ile daha iyi performans g\u00f6sterirler. \n\n**Not:** Ba\u011f\u0131ml\u0131 de\u011fi\u015fkeni, yani hedefi \u00f6l\u00e7eklendirmeye gerek yoktur.","4df94e92":"Kanserli olma durumunu 1, olmama durumunu 0 ile ifade edelim.\n>__M: 1 ->__  Kanser\n\n>__B: 0 ->__  Kanser yok","568147f6":"***NOTE*** SVM() i\u00e7in model tuning yaparken, ilk deferde scale edilmi\u015f \u00f6zellikleri kullanmay\u0131 unutmu\u015ftum. Neredeyse 40 dakika boyunca \u00e7al\u0131\u015ft\u0131 :( Yani, baz\u0131 algoritmalar i\u00e7in bu i\u015f hayatidir .d","f9814efa":"baz\u0131 algoritmalar farkl\u0131 tahminler yapm\u0131\u015f olsa da XGBoost'ta neredeyse hi\u00e7 d\u011fei\u015fim olmad\u0131 ve random forrestta olduk\u00e7a k\u00fc\u00e7\u00fck bir de\u011fi\u015fim g\u00f6zlendi.\n\nhiper parametre ayar\u0131 yapaca\u011f\u0131m\u0131z zaman bize zaman az da olsa(normalde gereksiz \u00f6zellikleri d\u00fc\u015f\u00fcrmek \u00e7ok zaman kazand\u0131rsada \u015fu an k\u00fc\u00e7\u00fck bir veri seti ile u\u011fra\u015ft\u0131\u011f\u0131m\u0131z i\u00e7in az zaman kazand\u0131racak.) zaman kazand\u0131raca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcnerek bu 14 \u00f6zellik ile yoluma devam etmek istiyorum :)\n","a0818c1e":"Ba\u015flamadan \u00f6nce: Veriye uygulad\u0131\u011f\u0131m her i\u015flemden sonra skorlardaki de\u011fi\u015fimi g\u00f6rmek istiyorum. Onun i\u00e7in a\u015fa\u011f\u0131daki fonksiyonu dahil edip, verideki de\u011fi\u015fikliklerden sonra uygulayaca\u011f\u0131m.","6b15f4e5":"Daha az ili\u015fkili \u00f6zellikleri elde ettik gibi g\u00f6r\u00fcn\u00fcyor. \u015eimdi accuracy_score undaki de\u011fi\u015fime bakal\u0131m:","9bbc12db":"Ben \u015fu an sadece tahmin ba\u015far\u0131s\u0131 ile ilgilendi\u011fim i\u00e7in bu sorunu \u00e7\u00f6zmeyebilirim (neredeyse t\u00fcm ger\u00e7ek hayat problemlerinde \u00e7\u00f6z\u00fclmesi gerekir. Yorumlanabilirlik ihtiyac\u0131 olmasa da, algoritmalar i\u00e7in g\u00fcnler s\u00fcrecek olan e\u011fitim setlerini k\u00fc\u00e7\u00fck boyutlara indirgemek neredeyse zorunluluktur). Ama yine de veri manip\u00fclasyonu b\u00f6l\u00fcm\u00fcnde bir g\u00f6z ataca\u011f\u0131m. Y\u00fcksek korelasyona sahip de\u011fi\u015fkenleri \u00e7\u0131kart\u0131p, tahmin ba\u015far\u0131s\u0131n\u0131n pek de\u011fi\u015fmedi\u011fini g\u00f6zle g\u00f6rece\u011fim: \n","6da008a0":"---\n---","d9039f72":"Buraya bakarak threshold'u \u015fu siyah noktalar\u0131n oldu\u011fu hizadaki recall'\u0131n de\u011fi\u015fmedi\u011fini ve noktalar\u0131n en sa\u011f\u0131n\u0131n optimum nokta olabilece\u011fini g\u00f6r\u00fcyorum. Hadi threshold'u oraya koyal\u0131m ve bakal\u0131m. Basit\u00e7e \u015f\u00f6yle yapabiliriz:","d5e9eacd":"# 2,3 | Veri setinin y\u00fcklenmesi \/ Ke\u015fif\u00e7i veri analizi","a500f40b":">***Bu y\u00fcksek ili\u015fkili \u00f6zelliklerden kurtulman\u0131n bir ba\u015fka y\u00f6ntemi ise \u015fudur: | ScikitLearn dok\u00fcman\u0131 |***","fa0decfa":"\u00dcstte \u00e7izdi\u011fimiz boxplot grafiklerini birdaha \u00e7izersek art\u0131k ay\u0131k\u0131r\u0131 g\u00f6zlemlerin olmad\u0131\u011f\u0131n\u0131 g\u00f6rece\u011fiz:","f49cd79f":"Biz e\u011fer e\u015fikde\u011ferini 0'a kadar d\u00fc\u015f\u00fcr\u00fcrsek, t\u00fcm de\u011ferlerin 1 oldu\u011funu buluruz ama bu olduk\u00e7a mant\u0131ks\u0131z. Burada yapmam\u0131z gereken, **recall**, **accuracy_score**, **presicion** aras\u0131nda bir denge bulmakt\u0131r ve bu denge bizim ihtiyac\u0131m\u0131za g\u00f6re de\u011fi\u015fecektir. \u00d6rne\u011fin, e\u011fer her 1 pozitif olan tahmin de\u011ferimiz i\u00e7in 10 tl para harcanmas\u0131 gerekiyorsa, ve bizim bu i\u015f i\u00e7in 500 tl b\u00fct\u00e7emiz varsa, 50 ki\u015fiyi tedavi edebiliriz. E\u011fer biz e\u015fik de\u011ferini 0 yapar ve 100 ki\u015finin 100'\u00fcn\u00fcn de pozitif oldu\u011funu tahminlersek, ger\u00e7ekten kanserli olan hastalar\u0131n bir \u00e7o\u011funu yoksaymam\u0131z gerekir. O y\u00fczden, bir denge bulmam\u0131z gerekecektir. Bu dengeyi bulmak i\u00e7in, umut vadeden modelelri se\u00e7tikten sonra u\u011fra\u015faca\u011f\u0131z.\n\n\u015eu an i\u00e7in; kanserli hastalar\u0131 %99 ihtimalle tespit eden ama kansersiz hastalar\u0131n da % 20'sine kanserli diyen bir model, kanserli hastalar\u0131n %90'\u0131n\u0131 tespit eden ve kansersiz hastalar\u0131n %5'ine kanserli diyen bir modelden daha iyi olaca\u011f\u0131n\u0131 s\u00f6yleyebilriiz.\n\n> -> Bu g\u00f6rseller, \"Karma\u015f\u0131kl\u0131k Matrisleri\" dir.","d479a4ad":"![image.png](attachment:image.png)","19fa800c":"Art\u0131k test setine dokunabiliriz! Hadi \u015fimdi test setinin skorlar\u0131na bir g\u00f6z atal\u0131m","d566738d":"#### \u0130li\u015fkili \u00f6zellikleri d\u00fc\u015f\u00fcr\u00fclm\u00fc\u015f (with 16 features) \u00f6zellikler ile Accuracy_score: ","08084cb4":"Grafi\u011fe bakarsak, 2.1, 1.9, 1.4 de\u011ferlerinde bir k\u0131r\u0131l\u0131m oldu\u011funu g\u00f6rebiliriz. Se\u00e7ti\u011fimiz noktan\u0131n \u00fcst\u00fcn\u00fc silip, outlierlardan kurtulmu\u015f, outlierlardan etkilenmeyen bir e\u011fitim seti olu\u015ftural\u0131m.","062c4e0f":"### Olay\n\n<em>Meme kanseri kad\u0131nlarda g\u00f6r\u00fclen kanserlerin 1\/3 gibi b\u00fcy\u00fck bir b\u00f6l\u00fcm\u00fcn\u00fc olu\u015fturan yayh\u0131n g\u00f6r\u00fclen bir kanser t\u00fcr\u00fcd\u00fcr. \u0130yi ya da k\u00f6t\u00fc huylu olabilir. \u00d6zellikler, bir g\u00f6\u011f\u00fcs kitlesinin ince i\u011fne aspirat\u0131n\u0131n (FNA) dijitalle\u015ftirilmi\u015f bir g\u00f6r\u00fcnt\u00fcs\u00fcnden hesaplan\u0131r. G\u00f6r\u00fcnt\u00fcde bulunan h\u00fccre \u00e7ekirdeklerinin \u00f6zelliklerini a\u00e7\u0131klarlar.<\/em>\n\n\n### Hedef\n\n<em>\u00d6rneklerin k\u00f6t\u00fc(1) ve iyi(0) huylu olarak etiketlendi\u011fi veri setini kullanarak yeni \u00f6rneklerin iyi huylu mu k\u00f6t\u00fc huylu mu oldu\u011funu tahminlemek. Bu, bir s\u0131n\u0131fland\u0131rma problemidir. \n\nBurada \u015f\u00f6yle bir soru sorulabilir; kanserli olanlar\u0131n tahmininin kesinli\u011fi mi daha \u00f6nemli yoksa t\u00fcm \u00f6rneklerin tahminlerinin kesinli\u011fi mi? \u00d6rne\u011fin 70 kansersiz 30'u kanserli olan 100 \u00f6rnek varsa, 60 kansersizi, 20 kanserliyi do\u011fru tahmin ederek %80 ba\u015far\u0131l\u0131 olabiliriz. Ama 10 kansersizi daha yanl\u0131\u015f tahmin etmek pahas\u0131na, toplam ba\u015far\u0131dan \u00f6d\u00fcn vererek 50 kanserliyi, 25 kansersizi do\u011fru tahmin edip, toplam ba\u015far\u0131m\u0131z\u0131 %75 e d\u00fc\u015f\u00fcr\u00fcp, kanserlileri do\u011fru tahmin etme oran\u0131m\u0131z\u0131 art\u0131rabiliriz. \n\nBu soruya \u015f\u00f6yle bir cevap ald\u0131\u011f\u0131m\u0131z\u0131 varsay\u0131p devam edelim: \"Bir hastan\u0131n kanserli oldu\u011funu erken tahmin etmenin maliyeti, kanserli hastalar\u0131 sonradan tespit etti\u011fimizde olu\u015fan maliyetten daha az. Bununla birlikte b\u00fct\u00e7emiz s\u0131n\u0131rl\u0131 oldu\u011fu i\u00e7im, t\u00fcm hastalar\u0131 kanser kabul edip erken tedaviye ba\u015flayam\u0131yoruz. B\u00fct\u00e7emiz, kansersiz hastalar\u0131n %20'si yanl\u0131\u015f tahmin edilse bile bunu tolare edebilecek seviyede. Buna kar\u015f\u0131n kanserli hastalar\u0131 do\u011fru tahmin etme oran\u0131n\u0131z\u0131 ne kadar art\u0131rabilirseniz bizim i\u00e7in o kadar iyi olacakt\u0131r.\" \n\nBu a\u00e7\u0131klamaya g\u00f6re devam edece\u011fiz.\n\nYani biz, \u015fu an kanserli olanlar\u0131 do\u011fru tahminlemeye toplam ba\u015far\u0131dan daha fazla \u00f6nem verece\u011fiz. Yani, gerekirse kanser olmayanlar\u0131 kanserli tahmin etme oran\u0131m\u0131z art\u0131raca\u011f\u0131z. Ama kanserli olanlar\u0131 tespit etme ba\u015far\u0131m\u0131z\u0131 art\u0131raca\u011f\u0131z. <\/em> \n\n---","9c87150c":"g\u00f6r\u00fcld\u00fc\u011f\u00fc gibi train setimizdeki kanser-kanser olmama oran\u0131 ayn\u0131. klasik train_test_split kullansayd\u0131k ta ayn\u0131 olabilirdi. Ama olmayada bilirdi. ShuffleSplit e\u015fit da\u011f\u0131lmas\u0131 i\u00e7in olmamas\u0131 i\u00e7in \u00f6zellikle u\u011fra\u015f\u0131r..","61afc3f0":"    \u00d6zelliklerin tamam\u0131 dahil oldu\u011fundaki ba\u015far\u0131 skorumuz:","ee5e1a16":"#### Orijinal \u00f6zellikler  ile tahmin Accuracy_score: ","dcb711a4":"U\u011fra\u015ft\u0131\u011f\u0131n\u0131z veri hakk\u0131nda, verinin da\u011f\u0131l\u0131m\u0131 hakk\u0131nda bir fikir edinmenin ba\u015fka bir h\u0131zl\u0131 yolu, her say\u0131sal \u00f6znitelik i\u00e7in bir histogram \u00e7izmektir.Ayn\u0131 zamanda \u00f6zelliklerin da\u011f\u0131l\u0131mlar\u0131nda bir anormallik var m\u0131 diye da\u011f\u0131l\u0131mlar\u0131na bakmak yararl\u0131d\u0131r. ","ab3cd311":"> ->Al\u0131nt\u0131: **\"Genel olarak, veri k\u00fcmenizde ili\u015fkili \u00f6zelliklere sahip olmaktan ka\u00e7\u0131nman\u0131z \u00f6nerilir. Ger\u00e7ekten de, y\u00fcksek oranda ili\u015fkili \u00f6zelliklerden olu\u015fan bir grup ek bilgi (veya sadece \u00e7ok az) getirmeyecek, ancak algoritman\u0131n karma\u015f\u0131kl\u0131\u011f\u0131n\u0131 art\u0131racak ve b\u00f6ylece hata riskini art\u0131racakt\u0131r.\"**","9b9f710f":"ScikitLearn dok\u00fcman\u0131: __Daha sonra, \u00f6zelliklerimizi k\u00fcmeler halinde gruplamak ve her k\u00fcmeden bir \u00f6zellik se\u00e7mek, veri k\u00fcmemizden bu \u00f6zellikleri se\u00e7mek ve yeni bir rastgele orman yeti\u015ftirmek i\u00e7in dendrogram\u0131n g\u00f6rsel olarak incelenmesiyle manuel olarak bir e\u015fik se\u00e7iyoruz(1).__","7207c851":"Umut vadeden \u00f6zellikleri ele alarak \u00f6zellikler aras\u0131 korelasyonlar\u0131 \u015f\u00f6yyle de inveleyebiliriz: ","779c1883":"Bu tabloya bakarak ba\u011f\u0131ms\u0131z de\u011fi\u015fkenlerin da\u011f\u0131l\u0131m\u0131, standart sapmas\u0131, ortalama de\u011ferine bakarak yay\u0131l\u0131m\u0131 hakk\u0131nda fikir sahibi olabilirsiniz.","c50b7192":"\u015eimdi, e\u011fer biz, bir \u00f6rne\u011fin pozitif olara tahmin edilece\u011fi e\u015fi\u011fi a\u015fa\u011f\u0131 indirirsek; yani normalde 0.5 ihtimalden yukar\u0131dan pozitifse, bu de\u011feri 0.3 e \u00e7ekersek, pozitif tahmin edilende\u011ferlerin say\u0131s\u0131 artacakt\u0131r. Ama bu de\u011ferlerin baz\u0131lar\u0131 \"Ger\u00e7ekte pozitifken, baz\u0131lar\u0131 ger\u00e7ekte \"negatif\" olacakt\u0131r. Yani biz, Yanl\u0131\u015f tahmin edilen yanl\u0131\u015flar\u0131 art\u0131rmak pahas\u0131na pozitif deperleri tahmin edebilme ihtimalimizi art\u0131raca\u011f\u0131z. A\u015fa\u011f\u0131daki g\u00f6rseller bu durumu daha iyi a\u00e7\u0131klayacakt\u0131r\n\n![image.png](attachment:image.png)","abad48ee":"### But! Wait! Veriye daha dair derin bir i\u00e7g\u00f6r\u00fc elde etmeden \u00f6nce, ba\u011f\u0131ml\u0131 de\u011fi\u015fkenlerimizin oran\u0131na bak\u0131p, veriyi Train-Test setlerine ay\u0131ral\u0131m ve test setine hi\u00e7 bakmadan devam edelim.","6a1184ba":" Birbirileri ile ili\u015fkili de\u011fi\u015fkenelrin oldu\u011funu g\u00f6rm\u00fc\u015ft\u00fcr. Bu de\u011ferlere odaklanal\u0131m ve ne yapabiliriz diye bir bakal\u0131m: ","59003ea1":"**\u0130\u015flemleri elle yapmak yerine fonksiyonlar ile yapmak, birka\u00e7 iyi nedenden \u00f6t\u00fcr\u00fc daha sa\u011fl\u0131kl\u0131 ve \u00e7ok daha \"g\u00fczeldir\".**\n\n>Bu, bu d\u00f6n\u00fc\u015f\u00fcmleri herhangi bir veri k\u00fcmesinde kolayca yeniden olu\u015fturman\u0131za olanak tan\u0131r (\u00f6rne\u011fin, bir dahaki sefere yeni bir veri k\u00fcmesi ald\u0131\u011f\u0131n\u0131zda). \n\n>Gelecekteki projelerde yeniden kullanabilece\u011finiz bir d\u00f6n\u00fc\u015f\u00fcm i\u015flevleri kitapl\u0131\u011f\u0131n\u0131z olur.\n\n>Yeni verileri algoritmalar\u0131n\u0131za beslemeden \u00f6nce d\u00f6n\u00fc\u015ft\u00fcrmek i\u00e7in canl\u0131 sisteminizde bu i\u015flevleri kullanabilirsiniz.\n\n>Bu, \u00e7e\u015fitli d\u00f6n\u00fc\u015f\u00fcmleri kolayca denemenizi ve hangi d\u00f6n\u00fc\u015f\u00fcm kombinasyonunun en iyi sonucu verdi\u011fini g\u00f6rmenizi sa\u011flar.","14c74400":"randomForres'ta az\u0131c\u0131k bir art\u0131\u015f, XGB'da azal\u0131\u015f olmas\u0131yla birlikte hemen hemen ayn\u0131 de\u011ferleri elde ettik. Normalde skorun geli\u015fmesi muhtemeldi. Ama verisetinin olduk\u00e7a temiz olmas\u0131 sebebiyle pek bir fark g\u00f6remedik. Bu, denenmesi genelde mantkl\u0131 olan bir harekettir. Hatta genellikle \u015fartt\u0131r. \"G\u00fcr\u00fclt\u00fcl\u00fc\" verisetlerinin temizlenmemesi muhtemel bile de\u011fildir. Ama \u015fu an i\u00e7in ben ellemeden **X_train_sel** ile devam edece\u011fim.","a9343156":"Hi\u00e7bir \u015fey yapmadan \u00f6nce skorumuza bakal\u0131m: \u015eu an 6 farkl\u0131 s\u0131n\u0131fland\u0131rma algoritmas\u0131 ve bu 5 algoritman\u0131n ortalamas\u0131na g\u00f6re tahmin \u00fcreten voting classifier'\u0131 kullanaca\u011f\u0131z:","c1e7f9bb":"Grafiklere bakarak, kanserli olmama oran\u0131n\u0131n kanserli olmaoran\u0131ndan biraz daha y\u00fcksek oldu\u011funu g\u00f6rebiliriz.","9ec6891b":"**Buraya bakarak ne d\u00fc\u015f\u00fcnmeliyiz?:**\n    \n    >T\u00fcm \u00f6zelliklerin(columns) olmas\u0131 gereken tipte oldu\u011funu(bazen kategorik olmas\u0131 gereken \u00f6zellik numerik olabilir ve bunu d\u00fczeltmek gerekir.) g\u00f6r\u00fcr\u00fcz.\n    \n    >'Unnamed: 32' isminde gereksiz bir \u00f6zellik var, bundan kurtulmal\u0131y\u0131z.\n   ","aaa223b2":"***U\u00e7tan uca bir veri projesinde ad\u0131mlar \u015fu \u015fekilde takip edilir:***\n>1-B\u00fcy\u00fck resmi g\u00f6rme, \u00fczerinde \u00e7al\u0131\u015f\u0131lacak projeye hakim olma.\n    Bu ad\u0131m, ba\u015flamadan i\u015fe ba\u015flamadan \u00f6nce dikkatli olunmas\u0131 gerken k\u0131s\u0131md\u0131r. Burada ba\u015far\u0131 parametresinin ne olaca\u011f\u0131na, problemin \u00e7\u00f6z\u00fcm\u00fcn\u00fcn ne olmas\u0131 gerekti\u011fine dair fikirler edinebilirsiniz. \u00d6rne\u011fin, bir komutan\u0131n yan\u0131nda veribilimci iseniz ve sizden, 2 yere farkl\u0131 yerden birine d\u00fc\u015fme ihtimali olan bir bombalar\u0131n nereye d\u00fc\u015fece\u011fini tahminlemenizi isterse (bir s\u0131n\u0131fland\u0131rma problemidir) b\u00f6lgelerin \u00f6nemi aras\u0131nda bir hiyerar\u015fi yoksa accuracy score u  kullanabilirsiniz. Ama A b\u00f6lgesi B b\u00f6lgesinden \u00f6nemli diyorsa, \"A\" b\u00f6lgesini do\u011fru tahminlemek B b\u00f6lgesini do\u011fru tahminlemekten daha \u00f6nemli olacakt\u0131r ve performans  (etik tart\u0131\u015fmalar\u0131 bir kenara b\u0131rak\u0131yorum :d ) \u00f6l\u00e7\u00fcm metri\u011fi de de\u011fi\u015fecektir. Performans metri\u011finin ne olaca\u011f\u0131 konusunda model performans\u0131n\u0131 \u00f6l\u00e7erken daha ayr\u0131nt\u0131l\u0131 konu\u015faca\u011f\u0131z.\n \n>2- Veriyi \u00e7ekmek.\n\n>3- Veriyi ke\u015ffetmek, g\u00f6rselle\u015ftirerek yeni \u00e7\u0131kar\u0131mlar, yorumlar yapmak. Nihayetinde veriyi i\u00e7selle\u015ftirmek gerekir. Haz\u0131r bir veriyi modele sokup, ard\u0131ndan ba\u015far\u0131l\u0131 sonu\u00e7lar almak i\u00e7in birka\u00e7 g\u00fcnl\u00fck bir e\u011fitim hemen hemen yeterli olabilir. Daha de\u011ferlisi, yorum yapabilmek olacakt\u0131r.\n\n>4- Verileri algoritmalar i\u00e7in haz\u0131r hale getirmek. \n    Bu a\u015famada ayk\u0131r\u0131 g\u00f6zlem analizi (\u00f6rne\u011fin 17 ya\u015f\u0131nda 3 \u00e7ocu\u011fu olan bir g\u00f6zlem gibi(teorik olarak m\u00fcmk\u00fcn ama modeli etkilemesi gerekmeyecek kadar istisna de\u011ferler yani), eksik g\u00f6zlem analizi, \u00f6rne\u011fin Support Vector Machine algoritmas\u0131n\u0131 kullanacaksan\u0131z veriyi \u00f6l\u00e7eklendirmek(Bunun i\u00e7in SVM kullanmak \u015fart de\u011fil) gibi, amac\u0131n\u0131za g\u00f6re de\u011fi\u015fecek bir s\u00fcr\u00fc farkl\u0131 senaryoyu uygulay\u0131p veriyi haz\u0131r hale getirirsiniz.\n    \n> 5- farkl\u0131 modeller denemek, umut vad edenleri se\u00e7mek.\n\n> 6- se\u00e7ilen modelere ince hiperparametre ayarlar\u0131 uygulayarak optium hiperparametreleri bulmak.\n\n> 7- \u00c7\u00f6z\u00fcm\u00fc sunmak\n","14c7261a":"# Burada;\n\n\n\n>__Recall__: do\u011fru tahmin edilen pozitif\/kanserli de\u011ferler oran\u0131\n\n>__Precision__: negatif tahmin edilen negatif\/kansersiz de\u011ferler oran\u0131\n\n>__F1_score__: Hassasiyet ve geri \u00e7a\u011f\u0131rman\u0131n harmonik ortalamas\u0131d\u0131r. Normal ortalama t\u00fcm de\u011ferleri e\u015fit olarak ele al\u0131rken, harmonik ortalama d\u00fc\u015f\u00fck de\u011ferlere \u00e7ok daha fazla a\u011f\u0131rl\u0131k verir. Sonu\u00e7 olarak, s\u0131n\u0131fland\u0131r\u0131c\u0131 yaln\u0131zca hem geri \u00e7a\u011f\u0131rma hem de hassasiyet y\u00fcksekse y\u00fcksek bir F1 puan\u0131 alacakt\u0131r. Her zaman istenen \u015fey de\u011fildir, bununla birlikte kullan\u0131\u015fl\u0131d\u0131r.\n\n>__Accuracy_score__: Do\u011fru tahmin edilen hedaf de\u011fi\u015fkenlerin oran\u0131.\n\n\nYani; \n\nnormalde negatif olan de\u011ferleri pozitif bulma say\u0131m\u0131z artarsa precision\/\/hassasl\u0131k\/kesinlik azal\u0131r. \n\nnormalde pozitif olanlar\u0131 negatif bulma say\u0131m\u0131z artarsa, recall\/hassasl\u0131k azal\u0131r.  \n\nDaha iyi bir i\u00e7g\u00f6r\u00fc i\u00e7in \u015fu g\u00f6rsele bakal\u0131m. A\u015fa\u011f\u0131daki g\u00f6rsel, optimum accuracy skorunu ald\u0131\u011f\u0131m\u0131z tablo olsun:\n\n![image.png](attachment:image.png)","9ba458bc":"## Ayk\u0131r\u0131 g\u00f6zlem analizi: \n\nAyk\u0131r\u0131 g\u00f6zlemleri burada unun i\u00e7in farkl\u0131 yollar vard\u0131r, PCA, DBSCAN, arac\u0131l\u0131\u011f\u0131 ile de uygulanabilir. Ben burada LocalOutlierFactor'u kullanaca\u011f\u0131m: ","066fe614":"Kanser-Kanser olmama oran\u0131","ba4cc27a":"hem grafikten hem skorlardan g\u00f6rebilece\u011fimiz gibi en iyi AUC skorunu **\"VotingClassifier\"** dan ald\u0131k. Yolumuza **\"VotingClassifier\"** ile devam edece\u011fiz. Bunun i\u00e7in tekrar bir tan\u0131mlama yapal\u0131m: Yaln\u0131zca voting_clasifier'\u0131n ROC e\u011frisine ve karma\u015f\u0131kl\u0131k matrisine bir g\u00f6z atal\u0131m:","b2533546":"# 1- B\u00fcy\u00fck resmi g\u00f6rmek","57d60a2a":"***Skorlardaki de\u011fi\u015fimi farkettiniz mi?***\n\nLogistic regresyon bizim i\u00e7in pekte umut vadetmiyorken \u015fu an hemen hemen en ba\u015far\u0131l\u0131 skorlar\u0131 \u00fcreten model. SVC'de ayn\u0131 \u015fekilde. Random forrest d\u0131\u015f\u0131nda t\u00fcm modellerin geli\u015fti\u011fini s\u00f6yleyebiliriz.","fabdd281":"Ayk\u0131r\u0131 de\u011ferlerle u\u011fra\u015fman\u0131n bu metoduna **Bask\u0131lama** denir.  ","1c720893":"Biz, birisi bize kanser \u015f\u00fcphesi olan bir ki\u015finin bilgilerini ald\u0131\u011f\u0131m\u0131zda kanserli olan bir ki\u015finin kanserli oldu\u011funu %96'l\u0131k bir ba\u015far\u0131 ile tahmin edebiliriz. Bununla birlikte ger\u00e7ekte negatif olan bireylerin %87'sini negatif tahmin ederken, %13'\u00fcn\u00fc pozitif tahmin eden bir model \u00fcrettik.\n\n","aa62cc0b":"Ah evet, art\u0131k birbiri ile y\u00fcksek oranda ili\u015fkili\u00f6zelliklerimizin say\u0131s\u0131 daha az. \u015eimdi, birbiri ile ili\u015fkili \u00f6zelliklerin d\u00fc\u015f\u00fcr\u00fcld\u00fc\u011f\u00fc bu veri seti ile orjinal verisetimizi RandomForrest'a sokal\u0131m ve ba\u015far\u0131 skorumuzda pek bir fark olamd\u0131\u011f\u0131n\u0131 g\u00f6relim:   ","10e10298":"BoxBlot grafi\u011finin betimlenmes:","36caa660":"Elimizde 2 farkl\u0131 s\u0131n\u0131f (kanser \/ kanser de\u011fil) oldu\u011fu i\u00e7in da\u011f\u0131l\u0131mlar\u0131n baz\u0131lar\u0131, b\u00fcy\u00fck ihtimalle, iki s\u0131n\u0131f i\u00e7in birbirinden farkl\u0131 da\u011f\u0131l\u0131mlar g\u00f6sterecektir. \u00d6zelliklerin da\u011f\u0131l\u0131mlar\u0131n\u0131n s\u0131n\u0131flara g\u00f6re de\u011fi\u015fimine bir bakmak hi\u00e7 fena olmaz. Bunu da \u015f\u00f6yle yapabiliriz: ","92cde48e":"Eksik verimiz yok. E\u011fer olsayd\u0131, problemimize g\u00f6re \u00e7\u00f6z\u00fcm \u00fcretmemiz gerekecekti. ","5d941f52":"__.info()__ metodu, toplam sat\u0131r say\u0131s\u0131na, s\u00fctunlardaki null olmayan de\u011ferlerin say\u0131s\u0131na, \u00f6zelliklerin t\u00fcr\u00fcne h\u0131zl\u0131ca bir bak\u0131\u015f i\u00e7in kullan\u0131\u015fl\u0131d\u0131r:","a52c9105":"\u00d6zelliklerin \u00f6nem s\u0131ras\u0131na bak\u0131l\u0131rsa, az\u0131msanamayacak kadar fazla \u00f6zelli\u011fin neredeyse hi\u00e7 etkisinin olmad\u0131\u011f\u0131n\u0131 g\u00f6r\u00fcr\u00fcz. ","bae2348a":"***Hiperpaametre ayarlar\u0131n\u0131 yapt\u0131k. \u015eimdi sonu\u00e7\u00e7lara tekrar bakal\u0131m:***","05437386":"G\u00f6r\u00fclece\u011fi gibi, baz\u0131 \u00f6zellikler, kanseri ve kanserli omayan h\u00fccreler i\u00e7in farkl\u0131 da\u011f\u0131l\u0131mlar g\u00f6sterirken baz\u0131 \u00f6zellikler hemen hemen ayn\u0131 da\u011f\u0131l\u0131ma sahip. Farkl\u0131 da\u011f\u0131l\u0131m g\u00f6steren \u00f6zellikler kanserli\/kanserli olmayan h\u00fccreleri belirlemede ay\u0131rt edici olabilir. A\u00e7\u0131k\u00e7as\u0131, \u00f6zelliklerin ne ifade etti\u011fine tam anlam\u0131yla hakim de\u011filim. E\u011fer bir hastanede veribilimci oalrak \u00e7al\u0131\u015f\u0131yor olsayd\u0131m, verileri haz\u0131rlayan ekip ve doktorlar ile bir g\u00f6r\u00fc\u015fme yapard\u0131m .)\n\nAz sonra \u00f6zellikler ve hedef de\u011fi\u015fken aras\u0131ndaki korelasyonlara bakt\u0131\u011f\u0131m\u0131zda, bu histogram grafiklerinde farkl\u0131 da\u011f\u0131lan \u00f6zelliklerin y\u00fcksek korelasyona sahip oldu\u011funu g\u00f6rece\u011fiz. Hatta hemen \u015fimdi k\u0131saca bir bakal\u0131m:","7d00b889":"Buradaki kesikli \u00e7izgi, tamamen rastgele tahmin \u00fcreten bir modelin \u00fcstedece\u011fi TPR\/FPR oran\u0131 olacakt\u0131r. \n\nYani ROC e\u011frisi ne kadar sol \u00fcst k\u00f6\u015feye yak\u0131nsa o kadar ba\u015far\u0131l\u0131 bir model \u00fcretildi\u011fi s\u00f6ylenebilir.\n\n\u015eimdi t\u00fcm modellerimiz i\u00e7in bu e\u011friye bakal\u0131m ve son olarak bir modeli se\u00e7ip, bu model \u00fczerinden bir e\u015fik de\u011feri se\u00e7elip projeyi sunal\u0131m."}}