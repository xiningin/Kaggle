{"cell_type":{"76fd9557":"code","eaea6b7a":"code","e5d5dbed":"code","fb36e531":"code","c9b3d3f6":"code","53a4d4ed":"code","342edd50":"code","380b2b6b":"markdown","a94856db":"markdown","93e2c5ae":"markdown","b6ceb9fc":"markdown"},"source":{"76fd9557":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eaea6b7a":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\ntrain_df.info()","e5d5dbed":"train_df.head()","fb36e531":"train_df = train_df.fillna({'Age':train_df['Age'].mean(), 'Cabin':'NA', 'Embarked':'NA'})\ntest_df = test_df.fillna({'Age':test_df['Age'].mean(), 'Cabin':'NA', 'Embarked':'NA'})\n\ntrain_df.info()","c9b3d3f6":"# extract features from columns: Name, Cabin, Ticket\nimport re\n\ndef name_prefix(str):\n    x = re.search('^(?:.*,)?(?:\\s*)?(.*?\\.)', str)\n    if x:\n        return x[1]\n    else:\n        return ''\n\ndef all_number(str):\n    return int(str.isnumeric())\n\ntrain_df['Name_len'] = train_df['Name'].apply(len)\ntrain_df['Name_prefix'] = train_df['Name'].apply(name_prefix)\ntrain_df['Cabin_prefix'] = train_df['Cabin'].str[0]\ntrain_df['Ticket_isnumeric'] = train_df['Ticket'].apply(all_number)\n\ntest_df['Name_len'] = test_df['Name'].apply(len)\ntest_df['Name_prefix'] = test_df['Name'].apply(name_prefix)\ntest_df['Cabin_prefix'] = test_df['Cabin'].str[0]\ntest_df['Ticket_isnumeric'] = test_df['Ticket'].apply(all_number)\n\ntrain_df.head()","53a4d4ed":"!pip install pycaret","342edd50":"# Classification task\nfrom pycaret.classification import *\n\nmodels = setup(data=train_df, target='Survived', train_size=0.8,\n               ignore_features=['PassengerId', 'Name', 'Ticket', 'Cabin'],\n               numeric_features=['SibSp', 'Parch', 'Fare', 'Name_len'],\n               categorical_features=['Sex', 'Embarked', 'Name_prefix', 'Cabin_prefix', 'Ticket_isnumeric'],\n               ordinal_features={'Pclass':['1','2','3']},\n               normalize=True,\n               silent=True)\n\nbest_model = compare_models(exclude=['xgboost'], sort='F1')\n\nout = predict_model(best_model, data=test_df)\n\nout[['PassengerId','Label']].to_csv('submission.csv', index=False, header=['PassengerId','Survived'])","380b2b6b":"## Data Exploration","a94856db":"## Features Engineering","93e2c5ae":"# Data Preparation: Missing values","b6ceb9fc":"## Install PyCaret"}}