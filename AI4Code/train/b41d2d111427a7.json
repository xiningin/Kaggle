{"cell_type":{"e8fa7f84":"code","85323d88":"code","93a1fb91":"code","5bc0fba6":"code","2f02422b":"code","f7cb984b":"code","cb3b482d":"code","07970994":"code","4401c032":"code","5d6986c3":"code","e1bd6942":"code","74b79d60":"code","48b9e923":"code","da226ee6":"code","f4e1c28d":"code","5126d9d7":"code","6c860be2":"code","87965732":"code","edcb42e8":"code","cd4b843a":"code","f7e46d49":"code","f6cd6254":"markdown","cccfd39f":"markdown","74838703":"markdown","42e57b99":"markdown","d8f72a81":"markdown","baca0c94":"markdown","06d2c877":"markdown","751c4aa1":"markdown","136cbab0":"markdown","8352bbc9":"markdown","eba715ef":"markdown"},"source":{"e8fa7f84":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets","85323d88":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","93a1fb91":"IMG_SIZE = 784\nBATCH_SIZE = 8*strategy.num_replicas_in_sync\nnb_classes = 4","5bc0fba6":"path='..\/input\/plant-pathology-2020-fgvc7\/'\n\ntrain = pd.read_csv(path+'train.csv')\ntrain_id = train['image_id']\ntrain.pop('image_id')\n\ny_train = train.to_numpy().astype('float32')\ncategory_names = ['healthy','multiple_diseases','rust','scab']\n\nroot = 'images'\nimages_paths = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in train_id]","2f02422b":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(images_paths,y_train,test_size=0.2,shuffle=True)","f7cb984b":"\nfrom sklearn.utils.class_weight import compute_class_weight\nclass_weights = compute_class_weight('balanced',np.unique(y_train.argmax(axis=1)),y_train.argmax(axis=1))\nprint('class weights: ',class_weights)\n\nplt.bar(range(4),1\/class_weights,color=['springgreen', 'lightcoral', 'mediumpurple', 'gold'],width=0.9)\nplt.xticks(range(4), category_names) \n\nplt.title(\"Categories distribution\");\nplt.ylabel('Probability')\nplt.xlabel('Data')\nplt.show()\n\n#class weights to dict\nc_w = dict(zip(range(4),class_weights))","cb3b482d":"def decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n           \n    if label is None:\n        return image\n    else:\n        return image, label","07970994":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )","4401c032":"val_dataset = (tf.data.Dataset\n               .from_tensor_slices((x_val,y_val))\n               .map(decode_image,num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE)\n               .cache()\n               .prefetch(AUTO)\n              )","5d6986c3":"!pip install efficientnet\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers","e1bd6942":"def get_model():\n    base_model = efn.EfficientNetB7(weights='imagenet',\n                          include_top=False,\n                          input_shape=(IMG_SIZE,IMG_SIZE, 3),\n                          pooling='avg')\n    x = base_model.output\n    predictions = Dense(nb_classes, activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)","74b79d60":"from tensorflow.keras.optimizers import Adam\n\nwith strategy.scope():\n    model = get_model()\n\nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])","48b9e923":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel_name = 'effNetPlants.h5'\n\n#good callbacks\nbest_model = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True,mode='min')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,min_lr=0.000001,patience=6)","da226ee6":"history = model.fit(train_dataset,\n                    steps_per_epoch=y_train.shape[0]\/\/BATCH_SIZE,\n                    epochs=5,\n                    verbose=1,\n                    validation_data=val_dataset,\n                    callbacks=[reduce_lr,best_model]\n                    )","f4e1c28d":"plt.title('model accuracy')\nplt.plot(history.history['val_accuracy'])\nplt.plot(history.history['accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","5126d9d7":"path='..\/input\/plant-pathology-2020-fgvc7\/'\n\ntest = pd.read_csv(path+'test.csv')\ntest_id = test['image_id']\n\nroot = 'images'\nx_test = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in test_id]","6c860be2":"model.load_weights(model_name)","87965732":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","edcb42e8":"y_pred = model.predict(test_dataset,verbose=1)","cd4b843a":"def save_results(y_pred):\n    \n    path='..\/input\/plant-pathology-2020-fgvc7\/'\n    test = pd.read_csv(path + 'test.csv')\n    test_id = test['image_id']\n\n    res = pd.read_csv(path+'train.csv')\n    res['image_id'] = test_id\n  \n    labels = res.keys()\n\n    for i in range(1,5):\n        res[labels[i]] = y_pred[:,i-1]\n\n    res.to_csv('submission.csv',index=False)\n  \n    print(res.head)","f7e46d49":"save_results(y_pred)","f6cd6254":"**callbacks**","cccfd39f":"# Plant pathology 2020\nIn this notebook you will see simple to code model with data preparation and results submission. I used EfficientNetB7, because it is amazing to classify images, but it is slow and heavy. So we need to use TPU to speed up our training proccess and to be able to store data in memory.\nPlay with number of epochs to get 0.980","74838703":"If  it was helpful, please vote. It will motivate me to create more notebooks.","42e57b99":"functions to image preprocessing","d8f72a81":"**Preparing train and validation sets**","baca0c94":"**Class weights**\n\nDataset is not balanced, so we need to use class_weights. ","06d2c877":" **TPU preparation**","751c4aa1":"**Important constants**","136cbab0":"**Model architecture**","8352bbc9":"**Split data into train and validation set**","eba715ef":"**Loading data**"}}