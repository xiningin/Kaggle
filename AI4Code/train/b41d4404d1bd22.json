{"cell_type":{"7628eb10":"code","89f7ad00":"code","fca2d9cf":"code","214451e5":"code","9b1cb780":"code","5f72de6c":"code","7c875827":"code","24247873":"code","6507447c":"code","67318b8d":"code","b8ff470d":"code","b814bba1":"code","d7a162de":"code","9b65d799":"code","f0cb1285":"code","eedf1e42":"code","04edfe6e":"code","ecce5e96":"code","e407c28b":"code","69b2c054":"code","40b14f5c":"code","dddef27e":"code","e3b8ac86":"code","b0a12f0a":"code","ba84d288":"code","eb44362b":"code","ae8122bb":"code","5eb88f9b":"code","d8e66f4f":"code","d02c1cb5":"code","7f4b0cef":"code","920485cd":"code","721927db":"code","d13bc9bf":"code","71f142b7":"code","be1ede16":"code","8f89f018":"code","a9cf6cb1":"code","b808dfcc":"code","8b7440b7":"code","0f1b68a5":"code","aea53de8":"code","f764404b":"code","922e82c2":"code","71ed9bb0":"code","422897ec":"code","67a68289":"code","ea1d2248":"code","9687d4dd":"code","265b014f":"code","3337f252":"code","4c1447d3":"code","89100be7":"code","1d5b9876":"code","098f04b2":"code","1eb08d68":"code","214150ee":"code","ad477fa9":"code","002f8861":"code","fc359552":"code","0e539fd3":"markdown","cea6fe0a":"markdown","72c70d93":"markdown","ae3aa0c5":"markdown","851ac897":"markdown","32487e00":"markdown","cdb4a64a":"markdown","829b0b73":"markdown","df0af871":"markdown","e79cdf68":"markdown","d439ff3f":"markdown","2eb46859":"markdown","0c3bbf2e":"markdown","0956f74c":"markdown","9ccc395c":"markdown"},"source":{"7628eb10":"# Leitura de Pacotes\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom string import ascii_letters\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import Imputer, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nimport xgboost as xgb\nfrom scipy import stats\nimport statsmodels.api as sm \nfrom scipy.stats import uniform, randint\nfrom pandas.plotting import scatter_matrix\nfrom scipy.stats import norm, skew\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","89f7ad00":"# Lendo as bases de dados\ndataset_treino = pd.read_csv(\"..\/input\/dataset_treino.csv\")\ndataset_teste = pd.read_csv(\"..\/input\/dataset_teste.csv\")\ndataset_lojas = pd.read_csv(\"..\/input\/lojas.csv\")","fca2d9cf":"# Visualiza\u00e7\u00e3o dos dados de treino\ndataset_treino.head(5)","214451e5":"# Visualiza\u00e7\u00e3o dos dados das lojas\ndataset_lojas.head(5)","9b1cb780":"# Juntando o conjunto de dados de treino e as lojas\ndataset_treino = pd.merge(dataset_treino, dataset_lojas, on = \"Store\")\n\n# Juntando o conjunto de dados de teste e as lojas\ndataset_teste = pd.merge(dataset_teste, dataset_lojas, on = \"Store\")\n\ndataset_treino.head(5)","5f72de6c":"# Shape do Dado\ndataset_treino.shape","7c875827":"# Tipos de Dados\nprint(dataset_treino.dtypes)","24247873":"# Mudando as variaveis que est\u00e3o em categorias de letras para categorias numericas\n\n# StoreType\nlabel_encoder = LabelEncoder().fit(dataset_treino['StoreType'])\ndataset_treino['StoreType'] = label_encoder.transform(dataset_treino['StoreType'])\n\ndataset_teste['StoreType'] = label_encoder.transform(dataset_teste['StoreType'])\n\n# Assortment\nlabel_encoder = LabelEncoder().fit(dataset_treino['Assortment'])\ndataset_treino['Assortment'] = label_encoder.transform(dataset_treino['Assortment'])\n\ndataset_teste['Assortment'] = label_encoder.transform(dataset_teste['Assortment'])\n\n# StateHoliday\ndataset_treino['StateHoliday'] = np.array(dataset_treino['StateHoliday'], dtype = str)\nlabel_encoder = LabelEncoder().fit(dataset_treino['StateHoliday'])\ndataset_treino['StateHoliday'] = label_encoder.transform(dataset_treino['StateHoliday'])\n\ndataset_teste['StateHoliday'] = label_encoder.transform(dataset_teste['StateHoliday'])","6507447c":"# Pegando informacoes da variavel 'Date'\n\n# Pegando somente o dia da variavel 'Date'\ndataset_treino[\"Dia\"] = dataset_treino[\"Date\"].str.split(\"-\", n = 2, expand = True)[2]\ndataset_treino['Dia'] = dataset_treino['Dia'].astype(int) \n\ndataset_teste[\"Dia\"] = dataset_teste[\"Date\"].str.split(\"-\", n = 2, expand = True)[2]\ndataset_teste['Dia'] = dataset_teste['Dia'].astype(int) \n\n# Pegando somente o mes da variavel 'Date'\ndataset_treino[\"Mes\"] = dataset_treino[\"Date\"].str.split(\"-\", n = 2, expand = True)[1]\ndataset_treino['Mes'] = dataset_treino['Mes'].astype(int) \n\ndataset_teste[\"Mes\"] = dataset_teste[\"Date\"].str.split(\"-\", n = 2, expand = True)[1]\ndataset_teste['Mes'] = dataset_teste['Mes'].astype(int) \n\n# Pegando somente o ano da variavel 'Date'\ndataset_treino[\"Ano\"] = dataset_treino[\"Date\"].str.split(\"-\", n = 1, expand = True)[0]\ndataset_treino['Ano'] = dataset_treino['Ano'].astype(int) \n\ndataset_teste[\"Ano\"] = dataset_teste[\"Date\"].str.split(\"-\", n = 1, expand = True)[0]\ndataset_teste['Ano'] = dataset_teste['Ano'].astype(int) ","67318b8d":"# Separando os meses de Intervalo de Promocao\ndataset_treino[['mes1', 'mes2', 'mes3', 'mes4']] = dataset_treino[\"PromoInterval\"].str.split(\",\", n = 3, expand = True)\n\ndataset_teste[['mes1', 'mes2', 'mes3', 'mes4']] = dataset_teste[\"PromoInterval\"].str.split(\",\", n = 3, expand = True)","b8ff470d":"# Transformando os meses em valores numeros\ntransf_num = {np.nan: '0', 'Jan': 1, 'Feb':2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, \n              'Jul': 7, 'Aug': 8, 'Sept': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\ndataset_treino['mes1'] = dataset_treino['mes1'].map(transf_num)\ndataset_treino['mes2'] = dataset_treino['mes2'].map(transf_num)\ndataset_treino['mes3'] = dataset_treino['mes3'].map(transf_num)\ndataset_treino['mes4'] = dataset_treino['mes4'].map(transf_num)\n\ndataset_teste['mes1'] = dataset_teste['mes1'].map(transf_num)\ndataset_teste['mes2'] = dataset_teste['mes2'].map(transf_num)\ndataset_teste['mes3'] = dataset_teste['mes3'].map(transf_num)\ndataset_teste['mes4'] = dataset_teste['mes4'].map(transf_num)","b814bba1":"# Criando a variavel intervalo de promocao\ndataset_treino['Intervalo_Promo'] = 0\n\ndataset_teste['Intervalo_Promo'] = 0","d7a162de":"# Verificando se a loja est\u00e1 em intervalo de promocao\ndataset_treino.Intervalo_Promo[((dataset_treino['Mes'] == dataset_treino['mes1'])\\\n                                | (dataset_treino['Mes'] == dataset_treino['mes2'])\\\n                                | (dataset_treino['Mes'] == dataset_treino['mes3']) \\\n                                | (dataset_treino['Mes'] == dataset_treino['mes4']))] = 1\n\ndataset_teste.Intervalo_Promo[((dataset_teste['Mes'] == dataset_teste['mes1'])\\\n                                | (dataset_teste['Mes'] == dataset_teste['mes2'])\\\n                                | (dataset_teste['Mes'] == dataset_teste['mes3']) \\\n                                | (dataset_teste['Mes'] == dataset_teste['mes4']))] = 1","9b65d799":"# Pegando as semanas do ano\ndataset_treino['Date'] = pd.to_datetime(dataset_treino['Date'], errors ='coerce')\ndataset_treino['WeekOfYear'] = dataset_treino['Date'].dt.weekofyear\n\ndataset_teste['Date'] = pd.to_datetime(dataset_teste['Date'], errors ='coerce')\ndataset_teste['WeekOfYear'] = dataset_teste['Date'].dt.weekofyear","f0cb1285":"# Quanto tempo o concorrente abriu em anos\ndataset_treino['Concorrente_Open'] = dataset_treino['Ano'] - dataset_treino['CompetitionOpenSinceYear']\n\ndataset_teste['Concorrente_Open'] = dataset_teste['Ano'] - dataset_teste['CompetitionOpenSinceYear']","eedf1e42":"# Quanto tempo a promo2 abriu em anos\ndataset_treino['Promo2_Open'] = dataset_treino['Ano'] - dataset_treino['Promo2SinceYear']\n\ndataset_teste['Promo2_Open'] = dataset_teste['Ano'] - dataset_teste['Promo2SinceYear']","04edfe6e":"# Quanto tempo o concorrente abriu em meses\ndataset_treino['Concorrente_Open_Mes'] = 12*(dataset_treino['Ano'] - dataset_treino['CompetitionOpenSinceYear'])- (dataset_treino['Mes'] - dataset_treino['CompetitionOpenSinceMonth'])\/4.0\n\ndataset_teste['Concorrente_Open_Mes'] = 12*(dataset_teste['Ano'] - dataset_teste['CompetitionOpenSinceYear']) - (dataset_teste['Mes'] - dataset_teste['CompetitionOpenSinceMonth'])\/4.0","ecce5e96":"# Quanto tempo a promo2 abriu em meses\ndataset_treino['Promo2_Open_Mes'] = 12*(dataset_treino['Ano'] - dataset_treino['Promo2SinceYear'])- (dataset_treino['Mes'] - dataset_treino['Promo2SinceWeek'])\/4.0\n\ndataset_teste['Promo2_Open_Mes'] = 12*(dataset_teste['Ano'] - dataset_teste['Promo2SinceYear'])- (dataset_teste['Mes'] - dataset_teste['Promo2SinceWeek'])\/4.0","e407c28b":"# Retirando as lojas que n\u00e3o tiveram vendas (n\u00e3o abriram)\ndataset_treino = dataset_treino.drop(dataset_treino[dataset_treino.Sales == 0].index)","69b2c054":"# Vendo se existem valores vazios na variavel Open nos dados de treino\ndataset_treino['Open'].isnull().sum()","40b14f5c":"# Vendo se existem valores nulos na variavel Open nos dados de teste\ndataset_teste['Open'].isnull().sum()","dddef27e":"# Para os valores NA, colocando valores 1\ndataset_teste.Open[dataset_teste['Open'].isnull()] = 1","e3b8ac86":"# Separando os dados de teste em rela\u00e7\u00e3o a variavel Open\nsep_teste_notopen = dataset_teste[dataset_teste['Open'] == 0]\ndataset_teste = dataset_teste[dataset_teste['Open'] == 1]","b0a12f0a":"# Retirando a vari\u00e1vel Open dos dados de treino e de teste\ndataset_treino = dataset_treino.drop(columns = 'Open')\n\ndataset_teste = dataset_teste.drop(columns = 'Open')","ba84d288":"# Lojas que tiveram promo\u00e7\u00e3o\ndataset_treino.groupby('Promo').size()","eb44362b":"# Distribui\u00e7\u00e3o das lojas\ndataset_treino.groupby('Store').size().head(10)","ae8122bb":"# Fun\u00e7\u00e3o para calcular valores faltantes\ndef missing_values_table(df):\n        # Total de valores faltantes\n        mis_val = df.isnull().sum()\n        \n        # Percentagem de valores faltantes\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Fazendo uma tabela com os resultados\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis = 1)\n        \n        # Renomeando as colunas\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Valores Missing', 1 : '% of Valores Totais'})\n        \n        # Ordenado a tabela pela percentagem de valores faltantes\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Valores Totais', ascending=False).round(1)\n        \n        # Print summary information\n        print (\"Este dataframe tem \" + str(df.shape[1]) + \" colunas.\\n\"      \n            \"Existem \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" colunas que tem valores faltantes.\")\n        \n        # Returnar o dataframe com a informa\u00e7\u00e3o dos valores missing\n        return mis_val_table_ren_columns","5eb88f9b":"# Calculando a % de valores faltantes\nmissing_values_table(dataset_treino)","d8e66f4f":"# Histograma da Variavel 'Sales'\nplt.hist(dataset_treino['Sales'], bins = 50, edgecolor = 'k');\nplt.xlabel('Sales');  \nplt.title('Distribui\u00e7\u00e3o das Vendas');","d02c1cb5":"# Comparacao do Histograma da Variavel 'Sales'\nfig = plt.figure(figsize = (10,5))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\ngraf1 = sns.distplot(dataset_treino['Sales'], hist = True, label='skewness:{:.2f}'.format(dataset_treino['Sales'].skew()),ax = ax1)\ngraf1.legend()\ngraf1.set(xlabel = 'Sales', ylabel = 'Densidade', title = 'Distribuicao Sales')\ngraf2 = sns.distplot(np.log1p(dataset_treino['Sales']), hist = True, label = 'skewness:{:.2f}'.format(np.log1p(dataset_treino['Sales']).skew()),ax=ax2)\ngraf2.legend()\ngraf2.set(xlabel = 'log(Sales+1)',ylabel = 'Densidade', title = 'Distribuicao log(Sales+1)')\nplt.show()","7f4b0cef":"# Boxplot\nvariaveis_num = ['Sales', 'Customers', 'CompetitionDistance']\nsns.boxplot(data = dataset_treino[variaveis_num], orient = \"h\")\nplt.show()","920485cd":"# Gr\u00e1fico de Correla\u00e7\u00e3o\nsns.set(style = \"white\")\n\n# Compute the correlation matrix\ncorr = dataset_treino.corr(method = 'pearson')\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize = (11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap = True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask = mask, cmap = cmap, vmax = .3, center = 0,\n            square = True, linewidths = .5, cbar_kws={\"shrink\": .5})\n\nplt.show()","721927db":"# Grafico dos Customers x Sales\nfig, ax = plt.subplots()\nax.scatter(dataset_treino['Customers'], dataset_treino['Sales'], edgecolors = (0, 0, 0))\nax.set_xlabel('Customers')\nax.set_ylabel('Sales')\nplt.show()","d13bc9bf":"# Vendo como est\u00e3o as vendas da Store1\ndataset_treino.loc[dataset_treino['Store'] == 1, ['Date','Sales']].plot(x = 'Date', y = 'Sales', title ='Store 1',\n                                                                        figsize = (16,4), color = 'purple')\nplt.show()","71f142b7":"# Imputando os Dados Faltantes da variavel CompetitionDistance\nmediana = dataset_treino['CompetitionDistance'].median()\nd = {np.nan: mediana}\ndataset_treino['CompetitionDistance'] = dataset_treino['CompetitionDistance'].replace(d).astype(int)\n\ndataset_teste['CompetitionDistance'] = dataset_teste['CompetitionDistance'].replace(d).astype(int)","be1ede16":"# Mudando os Na para 0\nd = {np.nan: 0}\ndataset_treino['CompetitionOpenSinceMonth'] = dataset_treino['CompetitionOpenSinceMonth'].replace(d).astype(int)\ndataset_treino['CompetitionOpenSinceYear'] = dataset_treino['CompetitionOpenSinceYear'].replace(d).astype(int)\n\ndataset_teste['CompetitionOpenSinceMonth'] = dataset_teste['CompetitionOpenSinceMonth'].replace(d).astype(int)\ndataset_teste['CompetitionOpenSinceYear'] = dataset_teste['CompetitionOpenSinceYear'].replace(d).astype(int)\n\ndataset_treino['Promo2SinceWeek'] = dataset_treino['Promo2SinceWeek'].replace(d).astype(int)\ndataset_treino['Promo2SinceYear'] = dataset_treino['Promo2SinceYear'].replace(d).astype(int)\n\ndataset_teste['Promo2SinceWeek'] = dataset_teste['Promo2SinceWeek'].replace(d).astype(int)\ndataset_teste['Promo2SinceYear'] = dataset_teste['Promo2SinceYear'].replace(d).astype(int)","8f89f018":"# Mudando os Na para 0\nd = {np.nan: 0}\ndataset_treino['Promo2_Open'] = dataset_treino['Promo2_Open'].replace(d).astype(int)\ndataset_treino['Concorrente_Open'] = dataset_treino['Concorrente_Open'].replace(d).astype(int)\n\ndataset_teste['Promo2_Open'] = dataset_teste['Promo2_Open'].replace(d).astype(int)\ndataset_teste['Concorrente_Open'] = dataset_teste['Concorrente_Open'].replace(d).astype(int)\n\ndataset_treino['Promo2_Open_Mes'] = dataset_treino['Promo2_Open_Mes'].replace(d).astype(int)\ndataset_treino['Concorrente_Open_Mes'] = dataset_treino['Concorrente_Open_Mes'].replace(d).astype(int)\n\ndataset_teste['Promo2_Open_Mes'] = dataset_teste['Promo2_Open_Mes'].replace(d).astype(int)\ndataset_teste['Concorrente_Open_Mes'] = dataset_teste['Concorrente_Open_Mes'].replace(d).astype(int)","a9cf6cb1":"# Transformando os resultados em arrays\nvalores_storetype = np.array(dataset_treino['StoreType'])\nvalores_assortment = np.array(dataset_treino['Assortment'])\nvalores_state = np.array(dataset_treino['StateHoliday'])\n\nvalores_storetype_teste = np.array(dataset_teste['StoreType'])\nvalores_assortment_teste = np.array(dataset_teste['Assortment'])\nvalores_state_teste = np.array(dataset_teste['StateHoliday'])","b808dfcc":"# Reshape nos dados\ninteiros_storetype = valores_storetype.reshape(len(valores_storetype),1)\ninteiros_assortment = valores_assortment.reshape(len(valores_assortment),1)\ninteiros_state = valores_state.reshape(len(valores_state),1)\n\ninteiros_storetype_teste = valores_storetype_teste.reshape(len(valores_storetype_teste),1)\ninteiros_assortment_teste = valores_assortment_teste.reshape(len(valores_assortment_teste),1)\ninteiros_state_teste = valores_state_teste.reshape(len(valores_state_teste),1)","8b7440b7":"# Criando um objeto do tipo 'OneHotEnconder'\nonehot_encoder1 = OneHotEncoder(sparse = False).fit(inteiros_storetype)\nonehot_encoder2 = OneHotEncoder(sparse = False).fit(inteiros_assortment)\nonehot_encoder3 = OneHotEncoder(sparse = False).fit(inteiros_state)\n\n# Transforma\u00e7\u00e3o nos dados de treino\nvetores_binarios1 = onehot_encoder1.transform(inteiros_storetype)\nvetores_binarios2 = onehot_encoder2.transform(inteiros_assortment)\nvetores_binarios3 = onehot_encoder3.transform(inteiros_state)\n\n# Transforma\u00e7\u00e3o nos dados de teste\nvetores_binarios1_teste = onehot_encoder1.transform(inteiros_storetype_teste)\nvetores_binarios2_teste = onehot_encoder2.transform(inteiros_assortment_teste)\nvetores_binarios3_teste = onehot_encoder3.transform(inteiros_state_teste)","0f1b68a5":"# Concatenando os resultados\nvetores_binarios = pd.concat([pd.DataFrame(vetores_binarios1, \n                                           columns = ['store0', 'store1', 'store2', 'store3']), \n                              pd.DataFrame(vetores_binarios2, \n                                           columns = ['assort0', 'assort1', 'assort2']), \n                              pd.DataFrame(vetores_binarios3, \n                                           columns = ['state0', 'state1', 'state2', 'state3'])], \n                             axis = 1)\n\nvetores_binarios_teste = pd.concat([pd.DataFrame(vetores_binarios1_teste, \n                                                 columns = ['store0', 'store1', 'store2', 'store3']), \n                                  pd.DataFrame(vetores_binarios2_teste, \n                                               columns = ['assort0', 'assort1', 'assort2']), \n                                  pd.DataFrame(vetores_binarios3_teste, \n                                               columns = ['state0', 'state1', 'state2', 'state3'])], \n                                   axis = 1)\n\nvetores_binarios.head(5)","aea53de8":"# Alinhando os indices\nvetores_binarios.index = dataset_treino.index\n\nvetores_binarios_teste.index = dataset_teste.index","f764404b":"# Import\u00e2ncia do Atributo com o Extra Trees Regressor\n\n# Separando o array em componentes de input e output\ncolunas_choice =   ['Promo', 'Store', 'Mes', 'Ano', 'Dia', 'DayOfWeek', \n                    'CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth',\n                    'SchoolHoliday',  'CompetitionDistance',  'Promo2', \n                    'Promo2SinceWeek', 'Promo2SinceYear', 'Intervalo_Promo',\n                    'WeekOfYear', 'Concorrente_Open', 'Promo2_Open', \n                    'Concorrente_Open_Mes', 'Promo2_Open_Mes', \n                    'Sales']\n\n#StoreTypeAssortmentStateHoliday\ndf = dataset_treino[colunas_choice]\narray = df.values\n\n# Separando o array em componentes de input e output\nX = array[:,0:(len(colunas_choice)-1)]\nY = array[:,(len(colunas_choice)-1)]\n\n# Cria\u00e7\u00e3o do Modelo - Feature Selection\nmodelo_feat = ExtraTreesRegressor()\nmodelo_feat.fit(X, Y)","922e82c2":"# Plotando a importancia das variaveis\nfeat_importances = pd.Series(modelo_feat.feature_importances_, index = colunas_choice[:-1])\nfeat_importances.sort_values(ascending = True).plot(kind = 'barh')\nplt.title('Importancia dos Atributos')\nplt.show()","71ed9bb0":"# Juntando os resultados de transformacao dos dados \ncolunas_importance =  ['CompetitionDistance', 'Store',  'Promo', \n                       'CompetitionOpenSinceMonth',\n                      'DayOfWeek','CompetitionOpenSinceYear', \n                      'Dia', 'Promo2SinceYear','WeekOfYear',\n                      'Concorrente_Open_Mes','Promo2SinceWeek',\n                      'Mes', 'Concorrente_Open', 'Promo2_Open_Mes','Ano']\ndata_modelo = dataset_treino[colunas_importance].copy()\ndata_modelo = data_modelo.join(vetores_binarios)\n\ndata_modelo_teste = dataset_teste[colunas_importance].copy()\ndata_modelo_teste = data_modelo_teste.join(vetores_binarios_teste)","422897ec":"# Separando em X e Y\nX_treino = data_modelo.values\nY_treino = dataset_treino['Sales']","67a68289":"#def rmspe(predictions, targets):\n#    return np.sqrt((((targets - predictions)\/targets) ** 2).mean())","ea1d2248":"# Criando modelo de Machine Learning a partir de cada algoritmo\n\n#modelos = []\n#modelos.append(('LR', LinearRegression()))\n#modelos.append(('LASSO', Lasso()))\n#modelos.append(('EN', ElasticNet()))\n#modelos.append(('Ridge', Ridge()))\n#modelos.append(('KNN', KNeighborsRegressor()))\n#modelos.append(('CART', DecisionTreeRegressor()))\n#modelos.append(('SVR', SVR(gamma = 'auto')))\n#modelos.append(('AB', AdaBoostRegressor(n_estimators = 100)))\n#modelos.append(('GBM', GradientBoostingRegressor(n_estimators = 100)))\n#modelos.append(('RF', RandomForestRegressor(n_estimators = 100)))\n#modelos.append(('ET', ExtraTreesRegressor(n_estimators = 100)))\n#modelos.append(('XG', XGBRegressor()))\n\n#resultados = []\n#nomes = []\n\n# Percorrendo cada um dos modelos\n#for nome, modelo in modelos:\n#    kfold = model_selection.KFold(10, True, random_state = 42)\n#    previsoes = cross_val_predict(modelo, X_treino, np.log1p(Y_treino), cv = kfold)\n#    metrica = rmspe(np.expm1(previsoes), np.expm1(Y_treino))\n#    resultados.append(previsoes)\n#    nomes.append(nome)\n#    texto = \"%s: %f\" % (nome, metrica)\n#    print(texto)\n# 0.18079538227473296\n# 0.17492211856266057","9687d4dd":"# Graficos das previsoes\n#fig, ax = plt.subplots()\n#ax.scatter(np.expm1(Y_treino), np.expm1(previsoes), edgecolors = (0, 0, 0))\n#ax.plot([Y_treino.min(), Y_treino.max()], [Y_treino.min(), Y_treino.max()], 'k--', lw = 4)\n#ax.set_xlabel('Observado')\n#ax.set_ylabel('Previsto')\n#plt.show()","265b014f":"# Funcoes para calculo do RMPSE\n\ndef rmspe(y, yhat):\n    return np.sqrt(np.mean((yhat\/y-1) ** 2))\n\ndef rmspe_xgboost(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y,yhat)","3337f252":"# Melhores parametros\nparams = {\"objective\": \"reg:linear\",\n          \"booster\" : \"gbtree\",\n          \"eta\": 0.1,\n          \"max_depth\": 10,\n          \"subsample\": 0.9,\n          \"colsample_bytree\": 0.5,\n          \"silent\": 1}\n\nnum_boost_round = 10000\n\n# Dividindo em dados de treino e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X_treino, Y_treino, test_size = 0.04)\n\n# Treinando um modelo XGBoost\ndtrain = xgb.DMatrix(X_train, np.log1p(y_train)) # dados de treino\ndvalid = xgb.DMatrix(X_valid, np.log1p(y_valid)) # dados de validacao\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n\nmodelo = xgb.train(params, dtrain, num_boost_round, evals = watchlist, \\\n  early_stopping_rounds = 100, feval = rmspe_xgboost, verbose_eval = True)","4c1447d3":"# Resultado nos dados de validacao\ny_pred = modelo.predict(xgb.DMatrix(X_valid), ntree_limit = modelo.best_ntree_limit)\nerro = rmspe(y_valid.values, np.expm1(y_pred))\nprint('O RMSPE \u00e9 : {:.5f}'.format(erro))","89100be7":"# Importancia das variaveis no modelo\nfig, ax = plt.subplots(figsize = (10, 5))\nxgb.plot_importance(modelo, ax = ax)\nplt.show()","1d5b9876":"# Graficos das previsoes\nfig, ax = plt.subplots()\nax.scatter(y_valid.values, np.expm1(y_pred), edgecolors = (0, 0, 0))\nax.plot([y_valid.values.min(), y_valid.values.max()], [y_valid.values.min(), y_valid.values.max()], 'k--', lw = 4)\nax.set_xlabel('Observado')\nax.set_ylabel('Previsto')\nplt.show()","098f04b2":"# Prevendo para os dados em que a loja foi aberta\ndtest = xgb.DMatrix(data_modelo_teste.values)\nprevisoes_teste = np.expm1(modelo.predict(dtest, ntree_limit = modelo.best_ntree_limit))","1eb08d68":"# Juntando os resultados das previsoes\nSubmissao = pd.DataFrame(dataset_teste['Id'])\nSubmissao['Sales'] = previsoes_teste","214150ee":"# Adicionando a variavel Sales com valores zeros para lojas que n\u00e3o abriram\nsep_teste_notopen['Sales'] = 0\nSubmissao2 = sep_teste_notopen[['Id','Sales']]","ad477fa9":"# Juntando os dataframes\nSubmissao_final = pd.concat([Submissao, Submissao2])\nSubmissao_final.head(10)","002f8861":"# Ordenando os dados de submissao\nSubmissao_final = Submissao_final.sort_values(by = ['Id'])","fc359552":"# Salvando os resultados\nSubmissao_final.to_csv('Submission.csv', header = True, index = False)","0e539fd3":"### An\u00e1lise Explorat\u00f3ria ","cea6fe0a":"### Valores Faltantes","72c70d93":"### Convertendo Dados","ae3aa0c5":"### Feature Selection","851ac897":"### Separa\u00e7\u00e3o dos Dados","32487e00":"### Distribui\u00e7\u00e3o das classes","cdb4a64a":"### Processos Iniciais","829b0b73":"### One Hot Encoding","df0af871":"## Competi\u00e7\u00e3o DSA de Machine Learning\n### Leonara Alves","e79cdf68":"### Previs\u00e3o","d439ff3f":"### Imputa\u00e7\u00e3o de Dados Faltantes","2eb46859":"### Visualiza\u00e7\u00e3o dos Dados","0c3bbf2e":"#### Descri\u00e7\u00e3o dos Campos\n* ID - um ID que representa uma tupla (Store, Date) dentro do conjunto de dados\n* Store - um ID \u00fanico para cada loja\n* Sales - o volume de neg\u00f3cios de um determinado dia (\u00e9 isso que voc\u00ea est\u00e1 prevendo)\n* Customers - o n\u00famero de clientes em um determinado dia\n* Open - um indicador para saber se a loja estava aberta: 0 = fechada, 1 = aberta\n* StateHoliday - indica um feriado estadual. Normalmente, todas as lojas, com poucas exce\u00e7\u00f5es, est\u00e3o fechadas nos feriados estaduais. Note que todas as escolas est\u00e3o fechadas nos feriados e fins de semana. a = feriado p\u00fablico, b = feriado de P\u00e1scoa, c = Natal, 0 = Nenhum\n* SchoolHoliday - indica se a (Store, Date) foi afetada pelo fechamento de escolas p\u00fablicas\n* StoreType - diferencia entre 4 modelos de lojas diferentes: a, b, c, d\n* Assortment - descreve um n\u00edvel: a = b\u00e1sico, b = extra, c = estendido\n* CompetitionDistance - dist\u00e2ncia em metros at\u00e9 a loja concorrente mais pr\u00f3xima\n* CompetitionOpenSince[Month\/Year] - indica o ano e m\u00eas aproximado da hora em que o concorrente mais pr\u00f3ximo foi aberto\n* Promo - indica se uma loja est\u00e1 executando uma promo\u00e7\u00e3o nesse dia\n* Promo2 - promo\u00e7\u00e3o cont\u00ednua e consecutiva para algumas lojas: 0 = loja n\u00e3o est\u00e1 participando, 1 = loja est\u00e1 participando\n* Promo2Since[Year\/Week] - descreve o ano e a semana do calend\u00e1rio em que a loja come\u00e7ou a participar do Promo2\n* PromoInterval - descreve os intervalos consecutivos que o Promo2 \u00e9 iniciado, indicando os meses em que a promo\u00e7\u00e3o \u00e9 iniciada novamente. Por exemplo. \"Feb, May, Aug, Nov\" significa que cada rodada come\u00e7a em fevereiro, maio, agosto, novembro de qualquer ano para aquela loja.","0956f74c":"### Otimiza\u00e7\u00e3o do XGBoost","9ccc395c":"### Cria\u00e7\u00e3o do Modelo"}}