{"cell_type":{"46d8f720":"code","b5f23071":"code","e8e68fd4":"code","20994201":"code","00d8f3d5":"code","8f4210dc":"code","eb9269d5":"code","cc78a1cb":"code","2f72ce64":"code","51615576":"code","9e6e311e":"code","f34adb89":"code","3bfb66e8":"code","773d5174":"code","00fb23c8":"code","d362ba95":"code","4d7c7a5f":"code","66bd5fe9":"code","3232efd5":"code","977cd914":"code","6acf291b":"code","baf9c348":"code","ef44396d":"code","a1134480":"code","6ba4b5fc":"code","ef90ddc5":"code","03600564":"markdown","7bfe596f":"markdown","4e89fbd2":"markdown","535f2a2b":"markdown","69dcd9f2":"markdown","a4ff7aaf":"markdown","55ae3e49":"markdown","a14caa13":"markdown","8731c2df":"markdown","5409131d":"markdown","ff5f9426":"markdown","08a328d0":"markdown","d312c701":"markdown","69bd393f":"markdown","99b795a5":"markdown","0564e516":"markdown"},"source":{"46d8f720":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\n\nimport zipfile ","b5f23071":"working_dir = '..\/input\/histopathologic-cancer-detection'\nos.listdir(working_dir)","e8e68fd4":"print('Number of images in train set',len(os.listdir('..\/input\/histopathologic-cancer-detection\/train')))\nprint('Number of images in test set',len(os.listdir('..\/input\/histopathologic-cancer-detection\/test')))","20994201":"# Load the training data into a DataFrame named 'train'.\ntrain = pd.read_csv(f'..\/input\/histopathologic-cancer-detection\/train_labels.csv',dtype = 'str')\n\n# Print the shape of the resulting DataFrame.\nprint('Training set size', train.shape)","00d8f3d5":"# Display the first few rows of the dataframe.\ntrain.head(10) ","8f4210dc":"#The id in the csv file does not have .tif extension, let's add it.\ntrain['id'] = train['id'].apply(lambda x:f'{x}.tif')\ntrain.head()","eb9269d5":"#Let's check the class distribution\n#train['label'].value_counts()\ntrain.label.value_counts() \n","cc78a1cb":"#Let's check the class distribution in proportion\n#y_train = train.label\nround((train.label.value_counts() \/ len(train)).to_frame()*100,2)","2f72ce64":"#Let's visualize the label distribution\nimport seaborn as sns\nsns.countplot(train.label, edgecolor = 'black',\n              palette = sns.color_palette())\nplt.show()","51615576":"#display 16 images\n\nsample = train.sample(n=16).reset_index()\nplt.figure(figsize=(6,6)) # specifying the overall grid size\n\nfor i, row in sample.iterrows():  \n    img = mpimg.imread(f'..\/input\/histopathologic-cancer-detection\/train\/{row.id}')\n    label = row.label\n    \n    plt.subplot(4,4,i+1)    # the number of images in the grid is 6*6 (16)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","9e6e311e":"from sklearn.utils import shuffle\n\nsample_size = 80000\ntrain_0 = train[train['label'] == '0'].sample(sample_size, random_state=1)\ntrain_1 = train[train['label'] == '1'].sample(sample_size, random_state=1)\n\n#combine the two dataframe\ntrain_set = pd.concat([train_0, train_1], axis=0).reset_index(drop=True)\n\n#Shuffle\ntrain = shuffle(train_set)\n\ntrain['label'].value_counts()","f34adb89":"# Split the dataframe train into two DataFrames named train_df and valid_df. \n\ntrain_df, valid_df = train_test_split(train, test_size=0.20, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","3bfb66e8":"# Create image data generators for both the training set and the validation set. \n# Here we use the data generators to scale the pixel values by a factor of 1\/255. \n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","773d5174":"BATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '..\/input\/histopathologic-cancer-detection\/train\/',\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (64,64)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = '..\/input\/histopathologic-cancer-detection\/train\/',\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (64,64)\n)","00fb23c8":"# Let's determine the number of training and validation batches. \n\nTR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint('Number of batches in the training set:',TR_STEPS)\nprint('Number of batches in the validation set:',VA_STEPS)","d362ba95":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn_model = Sequential([\n    Conv2D(filters=32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(64,64,3)),\n    Conv2D(filters=32, kernel_size=(3,3), padding='valid', activation='relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='relu'),\n    Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.25),\n    Dense(64, activation='relu'),\n    Dropout(0.25),\n    Dense(32, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(2, activation='softmax')\n])\n \n\ncnn_model.summary()","4d7c7a5f":"# Define an optimizer and select a learning rate. \n# And then compile the model. \nimport tensorflow as tf\n\nopt = tf.keras.optimizers.Adam(0.001)\ncnn_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy',tf.keras.metrics.AUC()])","66bd5fe9":"%%time \n\nh1 = cnn_model.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 30,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","3232efd5":"history = h1.history\nprint(history.keys())","977cd914":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","6acf291b":"# we decrease the learning rate\ntf.keras.backend.set_value(cnn_model.optimizer.learning_rate, 0.0001)","baf9c348":"%%time \n\nh2 = cnn_model.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 35,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","ef44396d":"for k in history.keys():\n    history[k] += h2.history[k]","a1134480":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","6ba4b5fc":"# save the model and the combined history dictionary to files.\ncnn_model.save('cancer_model_v08.h5')\npickle.dump(history, open(f'cancer_history_v08.pkl', 'wb'))","ef90ddc5":"cnn_model.save('cancer_model_v08.h2')\npickle.dump(history, open(f'cancer_history_v09.pkl', 'wb'))","03600564":"# Train Network","7bfe596f":"# View Sample of Images","4e89fbd2":"# Data Generator","535f2a2b":"# Import Packages","69dcd9f2":"# Working Directory","a4ff7aaf":"# Number of images in the train and test folder","55ae3e49":"# Load Training DataFrame","a14caa13":"# Save Model and History","8731c2df":"# Now we need to balance the target distribution","5409131d":"# Label as per csv file\n\n#### 0 = no tumor tissue\n#### 1 = has tumor tissue","ff5f9426":"# About the images","08a328d0":"# Display Training Curve","d312c701":"# Histopathologic Cancer Detection\n### Identify metastatic tissue in histopathologic scans of lymph node sections","69bd393f":"#### There are 220,025 training images and 57,456 test images.\n#### The images are 96x96 pixels and are full color.","99b795a5":"# Build Network","0564e516":"# Label Distribution"}}