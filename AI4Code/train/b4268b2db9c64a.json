{"cell_type":{"291f535e":"code","ac5f51ab":"code","7f24e2c6":"code","52a4ce8c":"code","8e2e3d08":"code","a469b643":"code","8ecd4b6c":"code","44c6cfc6":"code","3ac65c6a":"markdown","e25863af":"markdown","b87a4289":"markdown","7c7d57de":"markdown","7eaee669":"markdown","c7334dbd":"markdown","896dfe38":"markdown","9e763a26":"markdown","97b20215":"markdown","be2d50e1":"markdown","7470ed1b":"markdown","ff19fe9e":"markdown","ed6ba76b":"markdown","140bbd98":"markdown","1f6b93c3":"markdown","116384b0":"markdown","4b8970bf":"markdown"},"source":{"291f535e":"# import all the packages\nimport math\nimport statistics\nimport numpy as np\nimport pandas as pd\nimport scipy.stats","ac5f51ab":"b = [9.0, 2, 3.5, 5, 28.0]\nb_with_nan = [9.0, 2, 3.5, math.nan, 5, 28.0]\nprint(b)\nprint(b_with_nan)","7f24e2c6":"mean_ = sum(b) \/ len(b)\nmean_","52a4ce8c":"mean_ = statistics.mean(b)\nprint(mean_)","8e2e3d08":"mean_ = statistics.mean(b_with_nan)\nmean_","a469b643":"0.2 * 2 + 0.5 * 4 + 0.3 * 8","8ecd4b6c":"x = [8.0, 1, 2.5, 4, 28.0]\nw = [0.1, 0.2, 0.3, 0.25, 0.15]\nwmean = sum(w[i] * x[i] for i in range(len(x))) \/ sum(w)\nprint(wmean)\nwmean = sum(x_ * w_ for (x_, w_) in zip(x, w)) \/ sum(w)\nprint(wmean)","44c6cfc6":"y, z, w = np.array(x), pd.Series(x), np.array(w)\nwmean = np.average(y, weights=w)\nprint(wmean)\nwmean = np.average(z, weights=w)\nprint(wmean)","3ac65c6a":"These are all the packages you\u2019ll need for Python statistics calculations. Usually, you won\u2019t use Python\u2019s built-in math package\n\n\nLet\u2019s create some data to work with. You\u2019ll start with Python lists that contain some arbitrary numeric data:","e25863af":"Here, you take the frequencies into account with the weights. With this method, you don\u2019t need to know the total number of items.\n\nYou can implement the weighted mean in pure Python by combining sum() with either range() or zip():","b87a4289":"# Understanding Descriptive Statistics\nDescriptive statistics is about describing and summarizing data. It uses two main approaches:\n\n1. The quantitative approach describes and summarizes data numerically.\n2. The visual approach illustrates data with charts, plots, histograms, and other graphs.\n\nYou can apply descriptive statistics to one or many datasets or variables. When you describe and summarize a single variable, you\u2019re performing univariate analysis. When you search for statistical relationships among a pair of variables, you\u2019re doing a bivariate analysis. Similarly, a multivariate analysis is concerned with multiple variables at once.\n\n![](https:\/\/miro.medium.com\/max\/707\/1*w2hGJO5gUD6se5yQ6Efsdw.png)","7c7d57de":"Again, this is a clean and elegant implementation where you don\u2019t need to import any libraries.\n\nHowever, if you have large datasets, then NumPy is likely to provide a better solution. You can use np.average() to get the weighted mean of NumPy arrays or Pandas Series:","7eaee669":"# Population Vs Samples\n![](https:\/\/s3-eu-west-1.amazonaws.com\/blog.omniconvert.com-media\/blog\/wp-content\/uploads\/2019\/10\/21150245\/sample-size-definition.png)\n\nIn statistics, the **population** is a set of all elements or items that you\u2019re interested in. Populations are often vast, which makes them inappropriate for collecting and analyzing data. That\u2019s why statisticians usually try to make some conclusions about a population by choosing and examining a representative subset of that population.\n\nThis subset of a population is called a **sample**. Ideally, the sample should preserve the essential statistical features of the population to a satisfactory extent. That way, you\u2019ll be able to use the sample to glean conclusions about the population.","c7334dbd":"# Types of Measures\n\n**Following types of measures in descriptive statistics:**\n\n**Central tendency** tells you about the centers of the data. Useful measures include the mean, median, and mode.\n\n**Variability** tells you about the spread of the data. Useful measures include variance and standard deviation.\n\n**Correlation or joint variability** tells you about the relation between a pair of variables in a dataset. Useful measures include covariance and the correlation coefficient.","896dfe38":"## What is Weighted Mean?\nThe weighted mean, also called the **weighted arithmetic mean** or **weighted average**, is a generalization of the arithmetic mean that enables you to define the relative contribution of each data point to the result.\n\nYou define one weight \ud835\udc64\u1d62 for each data point \ud835\udc65\u1d62 of the dataset \ud835\udc65, where \ud835\udc56 = 1, 2, \u2026, \ud835\udc5b and \ud835\udc5b is the number of items in \ud835\udc65. Then, you multiply each data point with the corresponding weight, sum all the products, and divide the obtained sum with the sum of weights: \u03a3\u1d62(\ud835\udc64\u1d62\ud835\udc65\u1d62) \/ \u03a3\u1d62\ud835\udc64\u1d62.\n\n![](http:\/\/www.mathsisfun.com\/data\/images\/weighted-average-seesaw.svg)\n\nThe weighted mean is very handy when you need the mean of a dataset containing items that occur with given relative frequencies. For example, say that you have a set in which 20% of all items are equal to 2, 50% of the items are equal to 4, and the remaining 30% of the items are equal to 8. You can calculate the mean of such a set like this:","9e763a26":"## What is Mean?\nThe **sample mean**, also called the sample arithmetic mean or simply the average, is the arithmetic average of all the items in a dataset. The mean of a dataset \ud835\udc65 is mathematically expressed as \u03a3\u1d62\ud835\udc65\u1d62\/\ud835\udc5b, where \ud835\udc56 = 1, 2, \u2026, \ud835\udc5b. In other words, it\u2019s the sum of all the elements \ud835\udc65\u1d62 divided by the number of items in the dataset \ud835\udc65.\n\nThis figure illustrates the mean of a sample with five data points:\n\n![](http:\/\/files.realpython.com\/media\/py-stats-01.3254dbfe6b9a.png)\n\nThe green dots represent the data points 1, 2.5, 4, 8, and 28. The red dashed line is their mean, or (1 + 2.5 + 4 + 8 + 28) \/ 5 = 8.7.\n\nYou can calculate the mean with pure Python using sum() and len(), without importing libraries:","97b20215":"# Python Statistics Libraries\n\nThere are many Python statistics libraries out there for you to work, but in this notebook i show you some popular one.\n\n1. [NumPy](http:\/\/www.numpy.org\/) is a third-party library for numerical computing, optimized for working with single- and multi-dimensional arrays. Its primary type is the array type called ndarray. This library contains many routines for statistical analysis.\n\n2. [SciPy](http:\/\/www.scipy.org\/) is a third-party library for scientific computing based on NumPy. It offers additional functionality compared to NumPy, including scipy.stats for statistical analysis.\n\n3. [Pandas](http:\/\/www.pandas.pydata.org\/) is a third-party library for numerical computing based on NumPy. It excels in handling labeled one-dimensional (1D) data with Series objects and two-dimensional (2D) data with DataFrame objects.\n\n4. [Matplotlib](https:\/\/matplotlib.org\/) is a third-party library for data visualization. It works well in combination with NumPy, SciPy, and Pandas.","be2d50e1":"**Today's Topics:**\n* **Numerical quantities** you can use to describe and summarize your datasets.\n* **calculate** descriptive statistics in pure Python\n* **descriptive statistics** with available Python libraries\n* How to **visualize** your datasets","7470ed1b":"# Calculating Descriptive Statistics\n","ff19fe9e":"# How to Describe Your Data Statistics Fundamentals with Python","ed6ba76b":"A necessary aspect of working with data is the ability to describe, summarize, and represent data visually. Python statistics libraries are comprehensive, popular, and widely used tools that will assist you in working with data.","140bbd98":"Although this is clean and elegant, you can also apply built-in Python statistics functions:","1f6b93c3":"# Measures of Central Tendency\n\nThe measures of central tendency show the central or middle values of datasets. There are several definitions of what\u2019s considered to be the center of a dataset. but now, you\u2019ll learn how to identify and calculate these measures of central tendency:\n\n* Mean\n* Weighted Mean\n* Geometric Mean\n* Harmonic Mean\n* Mode\n","116384b0":"# Outliers\n\nAn **outlier** is a data point that differs significantly from the majority of the data taken from a sample or population. There are many possible causes of outliers, but here are a few to start you off:\n\n* **Natural variation** in data\n* **Change** in the behavior of the observed system\n* **Errors** in data collection\n\nData collection errors are a particularly prominent cause of outliers. For example, the limitations of measurement instruments or procedures can mean that the correct data is simply not obtainable. Other errors can be caused by miscalculations, data contamination, human error, and more.\n\nThere isn\u2019t a precise mathematical definition of outliers. You have to rely on experience, knowledge about the subject of interest, and common sense to determine if a data point is an outlier and how to handle it.\n\n![](https:\/\/miro.medium.com\/max\/697\/1*O3lOgPwuHP7Vfc1T6NDRrQ.png)","4b8970bf":"if there are nan values among your data, then statistics.mean() and statistics.fmean() will return nan as the output:"}}