{"cell_type":{"fe93f6e1":"code","b6016277":"code","454f74a6":"code","4510ce08":"code","8b1c90aa":"code","4547e1e8":"code","6f760b78":"code","759fce67":"code","b400a390":"code","89746fb5":"code","e6f63327":"code","1709de1b":"code","5950c374":"code","e6d90803":"code","620215f5":"code","24ced186":"code","0a1a6843":"code","aedda5d7":"code","64ea241c":"code","6d429cb8":"code","6d1abf80":"code","23d41269":"code","898cc5d8":"code","ae9e1377":"code","5b406bc6":"code","046f8c05":"code","bda1dad1":"code","b66b5b5d":"code","22868636":"code","5f0e5ea2":"code","20bf9894":"code","3d2b567c":"code","86057b3d":"markdown","53c7d29b":"markdown","c764aa27":"markdown","7b5b7889":"markdown","52875c46":"markdown","a49fa003":"markdown","fd5c4a13":"markdown","3de45376":"markdown"},"source":{"fe93f6e1":"import torch\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n%matplotlib inline\n \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom torch import nn, optim\nimport torch.nn.functional as F\n \nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","b6016277":"df = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ndf.head()","454f74a6":"df.describe()","4510ce08":"if max(df.isnull().sum())==0:\n        print(\"There are no missing values\")\nelse:\n    for i in df.columns:\n        if df[i].isnull().sum()!=0:\n            print(\"The number of missing values in column\",i,\" :\",df[i].isnull().sum())","8b1c90aa":"df.shape","4547e1e8":"data=df.drop([\"id\",\"target\"],axis=1)\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler.fit(data)\nfeatures=scaler.transform(data)\nfeatures","6f760b78":"scaled_features_df = pd.DataFrame(features, index=df.index, columns=data.columns)\n","759fce67":"scaled_features_df.describe()","b400a390":"X=scaled_features_df\n\ny = df[['target']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","89746fb5":"X_train = torch.from_numpy(X_train.to_numpy()).float()\ny_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n\nX_test = torch.from_numpy(X_test.to_numpy()).float()\ny_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","e6f63327":"class Net(nn.Module):\n\n  def __init__(self, n_features):\n    super(Net, self).__init__()\n    self.fc1 = nn.Linear(n_features, 20)\n    self.fc2 = nn.Linear(20, 10)\n    self.fc3 = nn.Linear(10, 3)\n    self.fc4 = nn.Linear(3, 1)\n\n  def forward(self, x):\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = F.relu(self.fc3(x))\n    return torch.sigmoid(self.fc4(x))","1709de1b":"net = Net(X_train.shape[1])\n","5950c374":"criterion = nn.BCELoss()\n\noptimizer = optim.Rprop(net.parameters(), lr=0.001, etas=(0.1, 1.2), step_sizes=(1e-06, 50))\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nX_train = X_train.to(device)\ny_train = y_train.to(device)\nX_test = X_test.to(device)\ny_test = y_test.to(device)\nnet = net.to(device)\ncriterion = criterion.to(device)","e6d90803":"def calculate_accuracy(y_true, y_pred):\n  predicted = y_pred.ge(.5).view(-1)\n  return (y_true == predicted).sum().float() \/ len(y_true)","620215f5":"def round_tensor(t, decimal_places=4):\n  return round(t.item(), decimal_places)\n\nfor epoch in range(1001):\n    \n    y_pred = net(X_train)\n    \n    y_pred = torch.squeeze(y_pred)\n    train_loss = criterion(y_pred, y_train)\n    \n    if epoch % 500 == 0:\n      train_acc = calculate_accuracy(y_train, y_pred)\n\n      y_test_pred = net(X_test)\n      y_test_pred = torch.squeeze(y_test_pred)\n\n      test_loss = criterion(y_test_pred, y_test)\n\n      test_acc = calculate_accuracy(y_test, y_test_pred)\n      print(\nf'''epoch {epoch}\nTrain set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\nTest  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n''')\n    \n    optimizer.zero_grad()\n    \n    train_loss.backward()\n    \n    optimizer.step()","24ced186":"classes = ['0', '1']\n\ny_pred = net(X_test)\n\ny_pred = y_pred.ge(.5).view(-1).cpu()\ny_test = y_test.cpu()\n\nprint(classification_report(y_test, y_pred, target_names=classes))","0a1a6843":"cm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, index=classes, columns=classes)\n\nhmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\nhmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\nhmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=0, ha='right')\nplt.ylabel('True label')\nplt.xlabel('Predicted label');","aedda5d7":"MODEL_PATH = 'model.pth'\n\ntorch.save(net, MODEL_PATH)","64ea241c":"net = torch.load(MODEL_PATH)\n","6d429cb8":"test_data=pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")","6d1abf80":"test_data.head()","23d41269":"data_test=test_data.drop(\"id\",axis=1)","898cc5d8":"test=data_test","ae9e1377":"scaler=StandardScaler()\nscaler.fit(test)\ntest=scaler.transform(test)\ntest\n","5b406bc6":"scaled_features_test = pd.DataFrame(test, index=test_data.index, columns=data_test.columns)\n","046f8c05":"scaled_features_test = torch.from_numpy(scaled_features_test.to_numpy()).float()\nscaled_features_test = scaled_features_test.to(device)\n","bda1dad1":"pred=net(scaled_features_test)","b66b5b5d":"pred=pred.detach().cpu().numpy()","22868636":"test_data[[\"target\"]]=pred","5f0e5ea2":"sub=test_data[[\"id\",\"target\"]]","20bf9894":"sub.head()","3d2b567c":"sub.to_csv(\"submissionw0.7.csv\", index=False)","86057b3d":"# Standardize features","53c7d29b":"# Model evaluation","c764aa27":"# Save and load model","7b5b7889":"# training model","52875c46":"# Build a fully connected layer.","a49fa003":"# Loading data from numpy","fd5c4a13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3de45376":"# Prepare data"}}