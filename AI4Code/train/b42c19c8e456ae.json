{"cell_type":{"cdea6b66":"code","847b6c84":"code","0ee06a6f":"code","38b47d49":"code","dce0556d":"code","57b1e5e3":"code","4d9a5551":"code","c9ff47e4":"markdown"},"source":{"cdea6b66":"import numpy as np\nimport pandas as pd \nimport keras\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport os\n\nimg_rows = 128\nimg_cols = 128\nchannels = 3\nimg_shape = (img_rows, img_cols, channels)\nlatent_dim = 100\n\noptimizer = Adam(0.0002, 0.5)","847b6c84":"baseDir = \"..\/input\/cropped\/\"\n\ntrain_x = []\n\ncharacterNames =[]\ncounter = 0\nfor imgname in  os.listdir(baseDir + '\/'):\n    if \".png\" in imgname:\n        img = Image.open(baseDir +'\/' + imgname)\n        img.thumbnail((img_shape[0],img_shape[1]), Image.ANTIALIAS)\n        \n        x = np.asarray(img)\n        x = x \/ 255\n\n        train_x.append(x)\n        counter += 1\n     \nprint(\"loaded!\")\nX_train = np.array(train_x)\nprint(X_train.shape)","0ee06a6f":"generator = Sequential()\n\niDimX = int(img_rows \/ 4)\niDimY = int(img_cols \/ 4)\n\ngenerator.add(Dense(128 * iDimX * iDimY, activation=\"relu\", input_dim=latent_dim))\ngenerator.add(Reshape((iDimX, iDimY, 128)))\ngenerator.add(UpSampling2D())\nfor i in range(1):\n    generator.add(Conv2D(128, kernel_size=3, padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\nfor i in range(1):\n    generator.add(Conv2D(64, kernel_size=5, padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\nfor i in range(1):\n    generator.add(Conv2D(channels, kernel_size=7, padding=\"same\"))\ngenerator.add(Activation(\"tanh\"))\n\ngenerator.summary()","38b47d49":"discriminator = Sequential()\n\ndiscriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\nfor i in range(1):\n    discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\"))\ndiscriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\nfor i in range(1):\n    discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\nfor i in range(1):\n    discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1, activation='sigmoid'))\n\ndiscriminator.summary()\ndiscriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])","dce0556d":"z = Input(shape=(latent_dim,))\nimg = generator(z)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# The discriminator takes generated images as input and determines validity\nvalid = discriminator(img)\n\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)","57b1e5e3":"# Adversarial ground truths\nbatch_size = 100\nvalid = np.ones((batch_size, 1))\nfake = np.zeros((batch_size, 1))\n\nr, c = 4, 4\nnoise = np.random.normal(0, 1, (r*c, latent_dim))\n\nfor epoch in range(20000):\n\n    # ---------------------\n    #  Train Discriminator\n    # ---------------------\n\n    # Select a random half of images\n    idx = np.random.randint(0, X_train.shape[0], batch_size)\n    imgs = X_train[idx]\n\n    # Sample noise and generate a batch of new images\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    gen_imgs = generator.predict(noise)\n\n    # Train the discriminator (real classified as ones and generated as zeros)\n    d_loss_real = discriminator.train_on_batch(imgs, valid)\n    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n    # ---------------------\n    #  Train Generator\n    # ---------------------\n\n    # Train the generator (wants discriminator to mistake images as real)\n    g_loss = combined.train_on_batch(noise, valid)\n\n    # Plot the progress\n    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n    # If at save interval => save generated image samples\n    if epoch % 2000 == 0:\n        generator.save(\"g{}.h5\".format(epoch))\n        \n        gen_imgs = generator.predict(noise)\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n                axs[i,j].axis('off')\n                cnt += 1\n        plt.show()\n        plt.close()","4d9a5551":"generator.save(\"final.h5\".format(epoch))\nnum_tests = 50\nnoise = np.random.normal(0, 1, (num_tests, latent_dim))\ngen_imgs = generator.predict(noise)\n\nc = 1\nfor img in gen_imgs:\n    i = img * 255\n    Image.fromarray(i.astype('uint8')).save(\"f_{}.png\".format(c))\n    c += 1","c9ff47e4":"* [How to Train a GAN? Tips and tricks to make GANs work](https:\/\/github.com\/soumith\/ganhacks)"}}