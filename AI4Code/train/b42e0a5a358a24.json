{"cell_type":{"8133a718":"code","aeb3d760":"code","18ed53bc":"code","293915cb":"code","93cd672e":"code","f656a468":"code","0bec7160":"code","573a2c47":"code","b4a086aa":"code","ea396b67":"code","dac6c323":"code","2bb387fd":"code","8505c96d":"code","25241d79":"code","d3ba3e29":"code","2aeadfe1":"code","64b77c2a":"code","a53eb59a":"code","e2f81144":"code","44b31c73":"code","616c96ea":"code","783097d1":"markdown","0b0a2eb6":"markdown","045ef777":"markdown","c3cae03e":"markdown","3966c59b":"markdown","10923be1":"markdown","c0a07f19":"markdown","2d1ac78a":"markdown","9816d22f":"markdown","b14d0599":"markdown","1e79b2be":"markdown","16fc60ae":"markdown","1360804f":"markdown","30073d44":"markdown","d3db53eb":"markdown","c094f283":"markdown","b7ae02cd":"markdown","03f0a456":"markdown","f40aa803":"markdown","456d7287":"markdown","92eb7eb4":"markdown"},"source":{"8133a718":"import fastai\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\n\nfrom fastai.tabular.all import *","aeb3d760":"data_dir = \"\/kaggle\/input\/tabular-playground-series-mar-2021\/\"\ntrain_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\ntrain_df.head()","18ed53bc":"train_df['target'].value_counts().plot.bar()\nplt.show()","293915cb":"train_df['target'].value_counts()","93cd672e":"processing_funcs = [Categorify, FillMissing, Normalize]\ncat_cols = [x for x in train_df.columns.values if x.startswith('cat')]\nnum_cols = [x for x in train_df.columns.values if x.startswith('cont')]","f656a468":"nn_df = TabularPandas(train_df, cat_names=cat_cols, cont_names=num_cols, procs=processing_funcs, y_names='target', y_block = CategoryBlock())","0bec7160":"train_dl = nn_df.dataloaders(1024)","573a2c47":"# preview some of our data from the dataloader\ntrain_dl.show_batch()","b4a086aa":"dls = TabularDataLoaders.from_df(train_df, path='.', y_names=\"target\",  \n                                 cat_names = cat_cols, \n                                 cont_names = num_cols, \n                                 procs=processing_funcs, \n                                 y_block = CategoryBlock())","ea396b67":"tab_learn = tabular_learner(dls, layers=[500, 250], metrics=[accuracy, error_rate, Recall(), Precision()])","dac6c323":"tab_learn.model","2bb387fd":"tab_learn.lr_find()","8505c96d":"tab_learn.fit_one_cycle(2, lr_max=5e-3)","25241d79":"tab_learn.recorder.plot_loss()","d3ba3e29":"interpret = ClassificationInterpretation.from_learner(tab_learn)\ninterpret.plot_confusion_matrix()","2aeadfe1":"interpret.print_classification_report()","64b77c2a":"test_dl = tab_learn.dls.test_dl(test_df)\ntest_dl.show_batch()","a53eb59a":"preds, test_labels = tab_learn.get_preds(dl=test_dl)","e2f81144":"preds ","44b31c73":"final_preds = preds.numpy()\nfinal_preds = np.argmax(final_preds, axis=1)","616c96ea":"submission_df = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\nsubmission_df['target'] = final_preds\nsubmission_df.to_csv('submission.csv', index=False)","783097d1":"## 3. Production of our DNN model","0b0a2eb6":"A key thing with tabular classification problems is to pass in y_block = CategoryBlock() above, since this will inform our model to perform classification rather than regression.","045ef777":"We need to take the argmax of these resultant predictions in order to obtain the final hard class output labels. We'll do this, and then make a submission to the competition:","c3cae03e":"FastAI provides a huge number of convenient functions on top of PyTorch for Deep Learning tasks. \n\nWithin this notebook, I'll quickly demonstrate a simple process that can be used to perform binary classification with a Deep Learning Tabular model that uses categorical embeddings and standardised numerical features as inputs.","3966c59b":"## 1. Load our data","10923be1":"## 2. Data preprocessing and creation of dataloader","c0a07f19":"Its so easy you almost feel like you've cheated somehow!\n\nI must admit, this is something that put me off using FastAI initially, however after the pain and effort of doing all of this manually many times with Keras, Tensorflow and PyTorch imeplementations, the ease of this method is highly appreciated for quick experimentation and research.\n\nWe could also have performed exactly the same as above, but straight from TabularDataLoaders, like so:","2d1ac78a":"---","9816d22f":"Its also helpful to find an appropriate learning rate for our model prior to training:","b14d0599":"---","1e79b2be":"Overall, its amazing how easy this process is, especially when compared to doing all of the low-level features yourself.","16fc60ae":"We can get a quick preview of our model before training:","1360804f":"We've got a varied mix of categorical and numerical features.\n\nLets preprocess our data into a suitable form for training. We'll encode categorical variables, standardise numerical features, and fill missing values (if there are any) within the dataset. We can do this extremely easily using the TabulerPandas class, like so:","30073d44":"Our problem is a slightly imbalanced classification problem.","d3db53eb":"Preprocess our test set and make predictions using our trained model:","c094f283":"Lets preprocess our data into a suitable form for training. We'll encode categorical variables, standardise numerical features, and fill missing values (if there are any) within the dataset. We can do this extremely easily using the TabulerPandas class, like so:","b7ae02cd":"We're performing basic binary classification for this challenge, so we only need to inform our model that its output bounds lie between 0 and 1. This will create a sigmoid output layer, from which we can classify our targets as either 0 and 1 depending on the chosen threshold.","03f0a456":"---","f40aa803":"## 4. Test set predictions","456d7287":"---","92eb7eb4":"# Training of a DNN Tabular model with categorical embeddings using FastAI"}}