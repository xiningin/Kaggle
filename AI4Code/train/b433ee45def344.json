{"cell_type":{"ac6ce58a":"code","ee83b70c":"code","0d0288b7":"code","cb115b98":"code","0b9a0bbf":"code","036c33d0":"code","006aaa1d":"code","936974f6":"code","f827a726":"code","3b1304b6":"code","e76d28b1":"code","d8d6a737":"code","d056475a":"code","cabb0d86":"code","acb39bae":"code","3acca65b":"code","f3864a62":"code","18a4d511":"code","8324dc3f":"code","b1f5712f":"code","4e988d9a":"code","08ec8f00":"code","ba494fb1":"code","a9df9c0b":"code","5622bfee":"code","d51273d3":"code","a4783b1e":"code","e710b89c":"code","aa22ffa6":"code","f6b6da40":"code","acd2aa5d":"code","7d22c26a":"code","0001a43d":"code","f597077f":"code","ad9b0ad5":"code","412fc149":"code","5b9494ba":"code","38cd25aa":"markdown","a381336a":"markdown","3dc8ab1d":"markdown","f7a43e99":"markdown","216bdca7":"markdown","5c1fb6b8":"markdown","08cd23b0":"markdown","c2300d17":"markdown","0304c1aa":"markdown","1d3ef413":"markdown","f4afa3a6":"markdown","e9474f39":"markdown","d7e8affe":"markdown","3f07f5aa":"markdown","1308b0bd":"markdown","eeb7876b":"markdown","e2549d9e":"markdown","54e8e344":"markdown","8d0e106f":"markdown","c114941f":"markdown","95005430":"markdown","9953a3c1":"markdown","f8f066eb":"markdown","0764bfff":"markdown","be2e54a7":"markdown"},"source":{"ac6ce58a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math as mt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee83b70c":"# Reading the data\ndata = pd.read_csv('..\/input\/autompg-dataset\/auto-mpg.csv')","0d0288b7":"# Looking at the data provided\n\ndata","cb115b98":"# Looking at the data shape\n\ndata.shape","0b9a0bbf":"# plotting linear regression between mpg(dependent Variable) and acceleration(independent Variable), origin(independent Variable)\n\nsns.lmplot(x='mpg',y='acceleration',hue='origin', data=data)\nplt.show()","036c33d0":"# Finding Correlation Coefficient \ndata['mpg'].corr(data['acceleration'])","006aaa1d":"# plotting linear regression between mpg(dependent Variable) and cylinders(independent Variable), origin(independent Variable)\n\nsns.lmplot(x='mpg',y='cylinders',hue='origin', data=data)\nplt.show()","936974f6":"# Finding Correlation Coefficient \ndata['mpg'].corr(data['cylinders'])","f827a726":"# plotting linear regression between mpg(dependent Variable) and weight(independent Variable), origin(independent Variable)\n\nsns.lmplot(x='mpg',y='weight',hue='origin', data=data)\nplt.show()","3b1304b6":"# Finding Correlation Coefficient \ndata['mpg'].corr(data['weight'])","e76d28b1":"# Statistical Summary of Numerical attributes of the dataset\n\ndata.describe().T","d8d6a737":"# Dropping the car name attribure from the data\ndf = data.drop('car name',axis=1)","d056475a":"# Replacing the categorical variable with actual values\ndf['origin'] = df['origin'].replace({1:'america',2:'europe',3:'asia'})\n\n#verifying the mnewly replaced values\ndf.origin.value_counts()","cabb0d86":"df.head(20)","acb39bae":"# getting dummies for the origin attribute.\n\ndf = pd.get_dummies(df, columns=['origin'])\ndf","3acca65b":"# checking if any NaN values in any attributes\n\ndf.isna().sum()","f3864a62":"df.dtypes","18a4d511":"# perform isdigit() on 'horsepower'\ndigits_in_hp = pd.DataFrame(df.horsepower.str.isdigit()) # returns true if digits else false\ndigits_in_hp","8324dc3f":"#print isDIgit = False!\ndf[digits_in_hp['horsepower'] == False]","b1f5712f":"df = df.replace('?',np.nan)  ","4e988d9a":"sns.distplot(df['horsepower'])","08ec8f00":"df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n\n# --- Alternatively with lambda function ---\n# medianFIlter = lambda x: x.fillnam(x.median())\n# Data = Data.apply(medianFilter,axis=0)","ba494fb1":"# Converting the Hporsepower column from object\/string type to float64\ndf['horsepower'] = df['horsepower'].astype('float64')","a9df9c0b":"df.dtypes","5622bfee":"attr_select = df.iloc[:,0:7]\nsns.pairplot(attr_select, diag_kind='kde') # kde is help plot desity curve instead of histogram on the diagonal","d51273d3":"df.isna().sum()","a4783b1e":"# independent variables\nX = df.drop(['mpg'], axis=1)\n# dependent variable\ny = df['mpg']","e710b89c":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state=1)","aa22ffa6":"regression_model = LinearRegression()\nregression_model.fit(X_train,y_train)","f6b6da40":"regression_model.coef_","acd2aa5d":"for indx,col_name in enumerate(X_train.columns):\n    print(\"Coefficient of  {} is {}\".format(col_name,regression_model.coef_[indx]))","7d22c26a":"intercept = regression_model.intercept_\nprint(\"The intercept for our model is {}\".format(intercept))","0001a43d":"# In sample score\nregression_model.score(X_train,y_train) ","f597077f":"# Out of sample score\nregression_model.score(X_test,y_test)","ad9b0ad5":"X_test","412fc149":"y_pred = regression_model.predict(X_test)","5b9494ba":"mse = mean_squared_error(y_test,y_pred)\n\nrmse = mt.sqrt(mse)\n\nprint(rmse)","38cd25aa":"### **Import Libraries**","a381336a":"# **Dealing with Missing Values**","3dc8ab1d":"# Multivariate Plots","f7a43e99":" From the above pair plot some of the interpretations we can observe like,\n*  horsepower and weight have negetive correlation with mpg\n*  displacement has very less positive or almost no correlation with mpg\n*  acceleration has slightly positive correlation with mpg\n*  displacement is positively correlated with horsepower, weight\n*  horsepower has positive correlation with weight and negetive correlation with acceleration\n*  weight has very little or no correlation with acceleration\n\nSo observation between **mpg** and other attributes indicate the relationship is not really linear. However, the plots also indicate that linearity would still capture quite a bit of useful information\/pattern. Several Assumptions of classical linear regression seem to be violated, including the assumption of no Heteroscedasticity.","216bdca7":"Now we are ready with the data to be fit into the model. So first we will take our model instance and pass the data as we prepared in aboce step.","5c1fb6b8":"# **Building our Linear Regression Model**","08cd23b0":"# Building a Linear Model to express the relationship between a car's milage(mpg) and the rest of its other attributes","c2300d17":"Replacing NaN with median for **horsepower** as the distribution is not **normal**","0304c1aa":"### Handling the Missing Data","1d3ef413":"Checking the mistyped values of horsepower column using above exploration.","f4afa3a6":"# **Converting Categorical Attributes to dummies**","e9474f39":"Gettting the coefficients for all the columns.","d7e8affe":"As we have performed the EDA on the given dataset now we will split the data in two parts.\n*  First part containing independent variables, to be used for input to the model\n*  Seond part containing dependent variable, to be used to compare the result of model","3f07f5aa":"### **Fit the linear Model** (Make our model learn) ","1308b0bd":"Using the isdigit() mmethod to check the non numeric values in the Horsepower column. As horsepower containts numeric values but its datatype is shown objects. This needs to be looked into. So we will check each of values and verify if it contains numeric values or not.","eeb7876b":"Now checking the **score(R^2)** for in-sample and out of sample","e2549d9e":"Replacing the **?** with **NaN**","54e8e344":"# **Individually checking the Correlation among the Attributes**","8d0e106f":"We are selecting the first 7 columns as we have generated further dummy columns. So we are limiting visualization of pairplot to 7 columns.","c114941f":"### Divide the Data into Dependent and Independent variables","95005430":"There are various ways to handle missing values. Drop the rows, replace missing values etc. Droping which might not be a good idea under all circumstances.","9953a3c1":"Calculating the error for out of sample data","f8f066eb":"Getting intercept","0764bfff":"### Now Split X and y into **training and testing set in 70:30 ratio**","be2e54a7":"Testing the model for out of the sample data and making prediction"}}