{"cell_type":{"728227ba":"code","525fa338":"code","6c63e4cd":"code","d6ddb056":"code","62b32f44":"code","9d9c8f82":"code","450c420d":"code","51b6f4a1":"code","231bc3fa":"code","7bb6ffef":"code","4f274793":"markdown"},"source":{"728227ba":"import pandas as pd\nimport numpy as np\nimport os\nfrom matplotlib import pyplot as plt","525fa338":"plt.style.use('ggplot')","6c63e4cd":"data_folder='\/kaggle\/input\/acea-water-prediction\/'","d6ddb056":"for i in os.listdir(data_folder):\n    print(i)","62b32f44":"df_Auser_Aquifer=pd.read_csv(data_folder+\"Aquifer_Auser.csv\")\ndf_Auser_Aquifer['Date'] = pd.to_datetime(df_Auser_Aquifer['Date'], dayfirst=True)\n\ndf_Doganella_Aquifer=pd.read_csv(data_folder+\"Aquifer_Doganella.csv\")\ndf_Luco_Aquifer=pd.read_csv(data_folder+\"Aquifer_Luco.csv\")\ndf_Petrignano_Aquifer=pd.read_csv(data_folder+\"Aquifer_Petrignano.csv\")\ndf_Bilancino_Lake=pd.read_csv(data_folder+\"Lake_Bilancino.csv\")\ndf_Arno_River=pd.read_csv(data_folder+\"River_Arno.csv\")\ndf_Amiata_Water_Spring=pd.read_csv(data_folder+\"Water_Spring_Amiata.csv\")\ndf_Lupa_Water_Spring=pd.read_csv(data_folder+\"Water_Spring_Lupa.csv\")\ndf_Madonna_di_Canneto_Water_Spring=pd.read_csv(data_folder+\"Water_Spring_Madonna_di_Canneto.csv\")","9d9c8f82":"df_Auser_Aquifer_2020 = df_Auser_Aquifer[(df_Auser_Aquifer['Date'] >= '2019-01-01') & (df_Auser_Aquifer['Date'] < '2020-01-01')]","450c420d":"def missing_values(df):\n    fig, ax = plt.subplots(1, 1, figsize=(16,10))\n\n    ax1 = ax.pcolormesh(df.isnull().T, cmap='Blues')\n    ax.set_yticks([x + 0.5 for x in range(0,len(df.columns))])\n    ax.set_yticklabels([x + \" - \" + str(round(sum(df[x].isnull())\/df.shape[0]*100,2)) + \"%\" for x in df.columns])\n\n    ax.set_title(\"Missing Values\",\n                {'fontsize':25})\n    plt.show()","51b6f4a1":"def corr_graph(df):\n    fig, ax1 = plt.subplots(1,1,figsize=(10,8))\n    ax1.set_title(\"Correlation Graph\")\n    corr = df.corr('pearson')\n    pcm = ax1.pcolormesh(corr)\n    ax1.set_xticks(np.arange(0.5,len(corr.columns)))\n    ax1.set_xticklabels(corr.columns, rotation='vertical')\n    ax1.set_yticks(np.arange(0.5,len(corr.columns)))\n    ax1.set_yticklabels(corr.columns)\n    plt.colorbar(pcm, ax=ax1)\n    plt.show()","231bc3fa":"def data_quality_report(df):\n    n_rows = df.shape[0]\n    n_cols = df.shape[1]\n    \n    desc = df.describe().T\n    \n    desc['miss %'] = desc['count'].apply(lambda x : round((n_rows - x)*100\/n_rows,2))\n    desc['card'] = [len(df[x].value_counts()) for x in desc.index]\n    \n    desc = desc[['count', 'miss %', 'card', 'min', '25%', '50%', '75%', 'max', 'mean', 'std']]\n\n    print(\"No. of rows: \" + str(n_rows))\n    print(\"No. of cols: \" + str(n_cols))\n    \n    print(\"Data types:\")\n    \n    display(df.dtypes)\n    display(df.dtypes.value_counts())\n    display(desc)\n    \n    n_num_cols = desc.shape[0]\n    numeric_cols = list(desc.index)\n    \n    if(n_num_cols > 5):     \n        df.hist(figsize=(20,((n_num_cols\/\/5)+1)*4), layout=((n_num_cols\/\/5)+1, 5), bins=100)\n        df[numeric_cols].plot(figsize=(20,n_num_cols*4), layout=(n_num_cols,1), kind='line', subplots=True)\n        plt.show()\n        \n    else:\n        df.hist(figsize=(20,5), layout=(1, n_num_cols), bins=100)\n        df[numeric_cols].plot(figsize=(20,5), layout=(n_num_cols,1), kind='line', subplots=True)\n        plt.show()\n        \n    missing_values(df)\n    corr_graph(df)","7bb6ffef":"pd.set_option('display.max_rows',5000)\ndata_quality_report(df_Auser_Aquifer_2020)","4f274793":"Usually in data exploration, we need some statistical measures to have a quick look into the data. \nIn this notebook, we try to write a function to create a **Data Quality Report** for continuous features, which could be used for any dataframe and can reduce some effort in EDA.\n\nA data quality report includes tabular reports that describe the characteristics of each feature in a dataset using standard statistical measures of central tendency and variation. The tabular reports are accompanied by data visualizations that illustrate the distribution of the values in each feature of the dataset. \n\nFor the data quality report, we use the below measures and plots:<br>\n<b>\n1. No. of rows\n2. No. of columns\n3. Data types for all the rows\n4. Cardinality of the data types for rows\n5. A table with the below statistical measures for each continuous feature:\n    * Count\n    * Missing values percentage\n    * Cardinality\n    * Minimum\n    * 1st quartile - 25%ile\n    * 2nd quartile - 50%ile - Median\n    * 3rd quartile - 75%ile\n    * Maximum\n    * Mean\n    * Mode\n    * Standard deviation\n6. Histogram of the features\n7. Line graphs of the features\n8. Graph showing the occurrence of missing values based on row index\n9. Correlation graph - Pearson's correlation\n<\/b>"}}