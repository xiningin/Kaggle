{"cell_type":{"dc7ea674":"code","18605baf":"code","2a0c047f":"code","f20207db":"code","e23d56a5":"code","d24f389d":"code","be4409d8":"code","01390353":"code","b64e5df9":"code","14b06b79":"code","efe33cfc":"code","3484bb02":"code","a34a3f82":"code","aff91a88":"code","54bff2c5":"code","fc040fcb":"code","66dd2ea4":"code","773c57d0":"code","5fd0bbca":"code","fda38da9":"code","cc2bdf84":"code","f501fe75":"code","00ab0374":"code","171a391e":"code","86819589":"code","849e2c09":"code","74dcaa05":"code","00109ef2":"code","a354c2fe":"code","d1f74edc":"code","f6ea8b4f":"code","ce7f8534":"code","224cb7ac":"code","c6a4ca5d":"code","2809582c":"code","722ff313":"code","bc777aa3":"code","7d6e1956":"code","ca351fe2":"code","8726bd21":"code","59cf1983":"code","8597bdd5":"code","f5199193":"code","80abbdf0":"code","ed43f786":"code","8c12650c":"code","7ff3adb0":"code","092d5cd8":"code","ec2e9d3d":"code","205f5430":"code","04a1fb11":"code","16547217":"code","2c81a874":"code","c4ff671f":"code","767409a0":"code","36b5114e":"code","aa39d05b":"code","d2f93e3a":"code","801c09cb":"code","8a7ebc33":"code","60c25a82":"code","8a22d7f6":"code","bca7dbd6":"code","6e422b93":"code","c938f7f5":"code","a780cb73":"code","580484ff":"code","ec65a420":"code","087f37c1":"code","68732273":"code","c5f944fd":"code","c047c664":"code","1da18466":"code","387bfeeb":"markdown","2b82b193":"markdown","5ec1be98":"markdown","7ce71729":"markdown","e19214d5":"markdown","3aa33bd7":"markdown","8b4dc1d2":"markdown","37deeb6f":"markdown","dc0d21d8":"markdown","4ab72590":"markdown","85ce3768":"markdown","1ca341c0":"markdown","f3218035":"markdown","2d6bbd30":"markdown","214ff8d0":"markdown","f6425343":"markdown","2cbd43da":"markdown","9d34c568":"markdown","c3d29d88":"markdown","b0d32d8f":"markdown","bb3ce929":"markdown"},"source":{"dc7ea674":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns","18605baf":"file_path='train.csv'\ndf=pd.read_csv(file_path)\ndf.head()","2a0c047f":"path='test.csv'\ndf2=pd.read_csv(path)\ndf2.head()\n# df2.isnull().sum()","f20207db":"df.describe(include='all')","e23d56a5":"# group 'Product_Identifier', 'Product_Weight' by 'Product_Identifier' so as to replace nan with the mean\n#of the corresponding 'Product_Identifier'\ndf_gptest = df[['Product_Identifier', 'Product_Weight']]\ngrouped_test1 = df_gptest.groupby(['Product_Identifier'],as_index=False).mean() ","d24f389d":"# df.isnull().sum()\n\n# df2.isnull().sum()\n\n#check the mode of the supermarket size values\n# df['Supermarket _Size'].value_counts().idxmax()\n\n# df2['Supermarket _Size'].value_counts().idxmax()\n\n#replace the missing 'Supermarket_Size' values by the most frequent \ndf[\"Supermarket _Size\"].replace(np.nan, \"Medium\", inplace=True)\ndf2[\"Supermarket _Size\"].replace(np.nan, \"Medium\", inplace=True)\ndf.Product_Weight=df.sort_values(['Product_Identifier','Product_Weight']).Product_Weight.ffill( )\ndf2.Product_Weight=df.sort_values(['Product_Identifier','Product_Weight']).Product_Weight.ffill( )","be4409d8":"df.sort_values(['Product_Identifier','Supermarket_Identifier']).head()","01390353":"df.dtypes","b64e5df9":"# grouped_1=df[['Product_Type','Supermarket_Identifier','Product_Supermarket_Sales']]\n# grpd_1=grouped_1.groupby(['Product_Type','Supermarket_Identifier'],as_index=False).mean()\n# grpd_1=grpd_1.sort_values(['Product_Type','Product_Supermarket_Sales'], ascending=False)\n# grpd_1","14b06b79":"# grouped_11=df[['Product_Type','Product_Supermarket_Sales']]\n# grpd_11=grouped_11.groupby(['Product_Type'],as_index=False).sum()\n# grpd_11=grpd_11.sort_values(['Product_Supermarket_Sales'], ascending=False)\n# grpd_11","efe33cfc":"# grouped_pivot = grpd_1.pivot(index='Product_Type',columns='Supermarket_Identifier')\n# grouped_pivot.head()","3484bb02":"# fig, ax = plt.subplots()\n# im = ax.pcolor(grouped_pivot, cmap='RdBu')\n\n# #label names\n# row_labels = grouped_pivot.columns.levels[1]\n# col_labels = grouped_pivot.index\n\n# #move ticks and labels to the center\n# ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n# ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n\n# #insert labels\n# ax.set_xticklabels(row_labels, minor=False)\n# ax.set_yticklabels(col_labels, minor=False)\n\n# #rotate label if too long\n# plt.xticks(rotation=90)\n\n# fig.colorbar(im)\n# plt.show()","a34a3f82":"grouped_2=df[['Supermarket_Type', 'Product_Supermarket_Sales']]\ngrpd_2=grouped_2.groupby(['Supermarket_Type'],as_index=False).mean()\ngrpd_2.sort_values('Product_Supermarket_Sales',ascending=False)","aff91a88":"df['Supermarket_Type'].replace('Supermarket Type3',4, inplace=True)\ndf['Supermarket_Type'].replace('Supermarket Type1',3, inplace=True)\ndf['Supermarket_Type'].replace('Supermarket Type2',2, inplace=True)\ndf['Supermarket_Type'].replace('Grocery Store',1, inplace=True)\n# df[['Supermarket_Type']]\n\ndf2['Supermarket_Type'].replace('Supermarket Type3',4, inplace=True)\ndf2['Supermarket_Type'].replace('Supermarket Type1',3, inplace=True)\ndf2['Supermarket_Type'].replace('Supermarket Type2',2, inplace=True)\ndf2['Supermarket_Type'].replace('Grocery Store',1, inplace=True)\n# df2[['Supermarket_Type']]","54bff2c5":"# sns.boxplot(x=\"Supermarket_Type\", y=\"Product_Supermarket_Sales\", data=df)","fc040fcb":"# grpd_2=grouped_2.groupby(['Supermarket_Type'],as_index=False)\n# f_val, p_val = stats.f_oneway(grpd_2.get_group('Supermarket Type1')['Product_Supermarket_Sales'], grpd_2.get_group('Supermarket Type2')['Product_Supermarket_Sales'], grpd_2.get_group('Supermarket Type3')['Product_Supermarket_Sales'], grpd_2.get_group('Grocery Store')['Product_Supermarket_Sales'])  \n# print( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","66dd2ea4":"# df['Supermarket_Type'].value_counts()","773c57d0":"grouped_3=df[['Supermarket_Location_Type', 'Product_Supermarket_Sales']]\ngrpd_3=grouped_3.groupby(['Supermarket_Location_Type'],as_index=False).mean()\ngrpd_3","5fd0bbca":"df['Supermarket_Location_Type'].replace('Cluster 2',3, inplace=True)\ndf['Supermarket_Location_Type'].replace('Cluster 3',2, inplace=True)\ndf['Supermarket_Location_Type'].replace('Cluster 1',1, inplace=True)\n# df['Supermarket_Location_Type'].value_counts()\n\ndf2['Supermarket_Location_Type'].replace('Cluster 2',3, inplace=True)\ndf2['Supermarket_Location_Type'].replace('Cluster 3',2, inplace=True)\ndf2['Supermarket_Location_Type'].replace('Cluster 1',1, inplace=True)\n# df2['Supermarket_Location_Type'].value_counts()","fda38da9":"# df['Supermarket_Location_Type'].value_counts()","cc2bdf84":"sns.boxplot(x=\"Supermarket_Location_Type\", y=\"Product_Supermarket_Sales\", data=df)","f501fe75":"# grpd_3=grouped_3.groupby(['Supermarket_Location_Type'],as_index=False)\n# f_val, p_val = stats.f_oneway(grpd_3.get_group('Cluster 1')['Product_Supermarket_Sales'], grpd_3.get_group('Cluster 2')['Product_Supermarket_Sales'], grpd_3.get_group('Cluster 3')['Product_Supermarket_Sales'])  \n# print( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","00ab0374":"df['Product_Fat_Content'].value_counts()","171a391e":"grouped_4=df[['Product_Fat_Content', 'Product_Supermarket_Sales']]\ngrpd_4=grouped_4.groupby(['Product_Fat_Content'],as_index=False).mean()\ngrpd_4","86819589":"df['Product_Fat_Content'].replace('Low Fat',3, inplace=True)\ndf['Product_Fat_Content'].replace('Normal Fat',2, inplace=True)\ndf['Product_Fat_Content'].replace('Ultra Low fat',1, inplace=True)\n# df['Product_Fat_Content'].value_counts()\ndf2['Product_Fat_Content'].replace('Low Fat',3, inplace=True)\ndf2['Product_Fat_Content'].replace('Normal Fat',2, inplace=True)\ndf2['Product_Fat_Content'].replace('Ultra Low fat',1, inplace=True)\n# df2['Product_Fat_Content'].value_counts()","849e2c09":"# sns.boxplot(x='Product_Fat_Content', y='Product_Supermarket_Sales', data=df)","74dcaa05":"# grpd_4=grouped_4.groupby(['Product_Fat_Content'],as_index=False)\n# f_val, p_val = stats.f_oneway(grpd_4.get_group('Low Fat')['Product_Supermarket_Sales'], grpd_4.get_group('Normal Fat')['Product_Supermarket_Sales'], grpd_4.get_group('Ultra Low fat')['Product_Supermarket_Sales'])  \n# print( \"ANOVA results: F=\", f_val, \", P =\", p_val)   ","00109ef2":"df['Supermarket _Size'].value_counts()","a354c2fe":"grouped_5=df[['Supermarket _Size', 'Product_Supermarket_Sales']]\ngrpd_5=grouped_5.groupby(['Supermarket _Size'],as_index=False).mean()\ngrpd_5","d1f74edc":"df['Supermarket _Size'].replace('Medium',3, inplace=True)\ndf['Supermarket _Size'].replace('Small',2, inplace=True)\ndf['Supermarket _Size'].replace('High',1, inplace=True)\n\ndf2['Supermarket _Size'].replace('Medium',3, inplace=True)\ndf2['Supermarket _Size'].replace('Small',2, inplace=True)\ndf2['Supermarket _Size'].replace('High',1, inplace=True)","f6ea8b4f":"sns.boxplot(x='Supermarket _Size', y='Product_Supermarket_Sales', data=df)","ce7f8534":"# grpd_5=grouped_5.groupby(['Supermarket _Size'],as_index=False)\n# f_val, p_val = stats.f_oneway(grpd_5.get_group('Medium')['Product_Supermarket_Sales'], grpd_5.get_group('Small')['Product_Supermarket_Sales'],grpd_5.get_group('High')['Product_Supermarket_Sales'])  \n# print( \"ANOVA results: F=\", f_val, \", P =\", p_val) ","224cb7ac":"df['Product_Type'].value_counts()","c6a4ca5d":"# rdf= [x for x in df.Product_Type.value_counts().sort_values(ascending=False).head(11).index]\n# for label in rdf:\n#     df['Product_Type'+ label]=np.where(df['Product_Type']==label,1,0)\n# for label in rdf:\n#     df2['Product_Type'+ label]=np.where(df2['Product_Type']==label,1,0)","2809582c":"type_count= df['Product_Type'].value_counts().sort_values( ascending=False)\ntype_count\n# grouped_11=df[['Product_Type','Product_Supermarket_Sales']]\n# # grpd_11=grouped_11.groupby(['Product_Type'],as_index=False).sum()\n# # grpd_11=grpd_11.sort_values(['Product_Supermarket_Sales'], ascending=False)\n# # grpd_11","722ff313":"type_count.index","bc777aa3":"ptype_encode = {}\nptype_encode_values = range(16,0,-1)\nfor i,k in zip(type_count.index,ptype_encode_values):\n    ptype_encode[i]=k\nptype_encode","7d6e1956":"df['Product_Type'] = df['Product_Type'].map(ptype_encode)","ca351fe2":"df","8726bd21":"df2['Product_Type'] = df2['Product_Type'].map(ptype_encode)\ndf2","59cf1983":"grouped_7=df[['Supermarket_Opening_Year','Supermarket_Identifier','Product_Supermarket_Sales']]\ngrpd_7=grouped_7.groupby(['Supermarket_Opening_Year','Supermarket_Identifier'],as_index=False).mean()\ngrpd_7.sort_values(['Product_Supermarket_Sales'], ascending=False)","8597bdd5":"# Engine size as potential predictor variable of price\nsns.regplot(x=\"Supermarket_Opening_Year\", y=\"Product_Supermarket_Sales\", data=grpd_7)\nplt.ylim(0,)","f5199193":"grpd_7.corr()","80abbdf0":"df.corr()","ed43f786":"df.columns","8c12650c":"# df.head()","7ff3adb0":"# df2.head()","092d5cd8":"# No need for normalizing for this the Tree based algos though\n\n# df['Product_Price']=df['Product_Price']\/df['Product_Price'].max()\n# df2['Product_Price']=df2['Product_Price']\/df2['Product_Price'].max()\n\n# df['Product_Weight']=df['Product_Weight']\/df['Product_Weight'].max()\n# df2['Product_Weight']=df2['Product_Weight']\/df2['Product_Weight'].max()\n# df.head()","ec2e9d3d":"X=df.drop(['Product_Identifier','Supermarket_Identifier','Product_Supermarket_Identifier','Product_Type','Product_Weight',\n           'Supermarket_Opening_Year','Product_Fat_Content','Product_Supermarket_Sales'], axis=1)","205f5430":"X.head()","04a1fb11":"y=df.Product_Supermarket_Sales\ny.head()","16547217":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","2c81a874":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error","c4ff671f":"params = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}","767409a0":"reg = GradientBoostingRegressor()#**params)\nreg.fit(X_train, y_train)","36b5114e":"mse = mean_squared_error(y_train, reg.predict(X_train))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\nprint(reg.score(X_train,y_train))","aa39d05b":"mse = mean_squared_error(y_test, reg.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\nprint(reg.score(X_test,y_test))","d2f93e3a":"# X2=df2.drop(['Product_Identifier','Supermarket_Identifier','Product_Supermarket_Identifier','Product_Fat_Content','Supermarket_Opening_Year'], axis=1)\n# X2=pd.get_dummies(X2)\n# X2.head()","801c09cb":"# test_pred = reg.predict(X2) #predict on the test set for submission\n# df3= {'Product_Supermarket_Identifier': df2['Product_Supermarket_Identifier'], 'Product_Supermarket_Sales': test_pred}\n# sub = pd.DataFrame(data=df3)\n# sub = sub[['Product_Supermarket_Identifier', 'Product_Supermarket_Sales']]","8a7ebc33":"# sub.shape","60c25a82":"# # sub.to_csv('submission.csv', index = False)","8a22d7f6":"# subxamp=pd.read_csv('sample_submission.csv')\n# subxamp.head()","bca7dbd6":"from xgboost import XGBRegressor\nparame = {\"n_jobs\":-1,'n_estimators':127,'learning_rate':0.08,\n                    'max_depth':3,'subsample':0.9,'random_state':1,\n                    'colsample_bylevel':0.9,'min_child_weight':2,\n                    'reg_alpha':1\n        }\n# n_jobs=-1,n_estimators=127,learning_rate=0.08,\n#                     max_depth=3,subsample=0.9,random_state =1,\n#                     colsample_bylevel=0.9,min_child_weight=2,\n#                     reg_alpha=1\n\n# clf1 = XGBRegressor(n_estimators=64,learning_rate=0.08,max_depth=4,\n#                      subsample=0.7, min_child_weight=2,reg_alpha=1)#**parame)\n\nclf1 = XGBRegressor()\nclf1.fit(X_train, y_train)","6e422b93":"#very latest best\nclf1 = XGBRegressor(n_estimators=62,learning_rate=0.07,max_depth=5,\n                      subsample=0.7, min_child_weight=2,reg_alpha=1)\nclf1.fit(X_train, y_train)","c938f7f5":"clf1 = XGBRegressor(n_estimators=62,learning_rate=0.07,max_depth=5,\n                      subsample=0.7, min_child_weight=2,reg_alpha=0.8)\nclf1.fit(X_train, y_train)","a780cb73":"mse = mean_squared_error(y_train, clf1.predict(X_train))\nprint(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\nprint(clf1.score(X_train,y_train))\n","580484ff":"mse = mean_squared_error(y_test, clf1.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\nprint(clf1.score(X_test,y_test))","ec65a420":"from catboost import CatBoostRegressor","087f37c1":"ctb = CatBoostRegressor(depth=6, learning_rate=0.019, n_estimators=270)\nctb.fit(X_train,y_train)","68732273":"coeff_score = ctb.score(X_test,y_test)\ncoeff_score","c5f944fd":"ctb.score(X_train,y_train)","c047c664":"X2=df2.drop(['Product_Identifier','Supermarket_Identifier','Product_Supermarket_Identifier','Product_Type','Product_Weight',\n           'Supermarket_Opening_Year','Product_Fat_Content'], axis=1)\nX2.head()","1da18466":"test_pred = ctb.predict(X2) #predict on the test set for submission\ndf3= {'Product_Supermarket_Identifier': df2['Product_Supermarket_Identifier'], 'Product_Supermarket_Sales': test_pred}\nsub = pd.DataFrame(data=df3)\nsub = sub[['Product_Supermarket_Identifier', 'Product_Supermarket_Sales']]\n\nsub.to_csv('submission_recent2.csv', index = False)\nsub.head()","387bfeeb":"# Product_Fat_Content analysis","2b82b193":"# Treating Missing Values","5ec1be98":"NOT DONE WITH FEATURE ENGINEERING","7ce71729":"# Encoding","e19214d5":"# Assigning Dependent and Independent Variables","3aa33bd7":"# Encoding","8b4dc1d2":"# Encoding","37deeb6f":"Croos validation","dc0d21d8":"# Normalization","4ab72590":"# Supermarket Type analysis","85ce3768":"# Supermarket_Location_Type analysis","1ca341c0":"# GradientBoostingRegression Algo","f3218035":"# XGBRegressor Algo","2d6bbd30":"# predicting the test data","214ff8d0":"# catBOOST","f6425343":"# One hot encodiing of of top 11 product type","2cbd43da":"# product that gives a better margin at specific stores","9d34c568":"# predicting the test data","c3d29d88":"# Encoding","b0d32d8f":"# supermarket_size analysis","bb3ce929":"# Product_Type analysis"}}