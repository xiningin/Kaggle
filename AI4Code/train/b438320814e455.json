{"cell_type":{"596f3be9":"code","e619afba":"code","a7e93ec8":"code","45f22d18":"code","b55fb479":"code","9d223889":"code","4aad6f36":"code","393ac9ee":"code","4abd1f16":"code","9f33a3c6":"code","d92b6c1f":"code","121bc2b9":"code","30738cf1":"code","ed013045":"code","f94ff12c":"code","7eee1081":"code","d52a6c5f":"code","8c26a7f3":"code","4a04c3f8":"code","3747448c":"code","907d6a6f":"code","c6093342":"code","6c0b00d5":"code","b56de981":"code","84584ca4":"code","7674d0d9":"code","7428e647":"code","1eecab79":"code","d5d2bfde":"code","b6bdf9b3":"code","c6dd9d87":"code","d01455c5":"code","6f4e378e":"code","08e7e9c4":"code","dd4dad93":"code","fc122c64":"code","2c754789":"code","9d598901":"markdown","a874de3c":"markdown","66060325":"markdown","9dd90d5b":"markdown","bfc47377":"markdown","26cdce42":"markdown","38531780":"markdown","673afd44":"markdown","04e8035e":"markdown","03460acb":"markdown","755f37e5":"markdown","48ee2562":"markdown","29990ac4":"markdown"},"source":{"596f3be9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import shapiro","e619afba":"# import sales Data\n\ndf = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')","a7e93ec8":"df.keys()","45f22d18":"df.id","b55fb479":"df.head()","9d223889":"# from the csv file named 'sales_train_evaluation' we create our parameters\n\nCOLS_ITM = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n\n#we only study the first year (from day 1 to day 366)\n\nCOLS_DATE = ['d_' + str(i) for i in range(1, 366)]\n\n# Change id to match with price dataframe (in file 'sell_prices' id is not mentioned as a feature)\n\ndf['id'] = df['store_id'] + '-' + df['item_id']","4aad6f36":"df.keys()","393ac9ee":"# Set our index\n\ndf.set_index(COLS_ITM, inplace = True)\n\n# And the Scope of our study  = Year 1 (366 days)\n\ndf = df[COLS_DATE]","4abd1f16":"df.keys()","9f33a3c6":"# Import Calendar\n\ndf_calendar = pd.read_csv('..\/input\/m5-forecasting-accuracy\/calendar.csv')\n\n# convert days to Weeks to get the sale prices\n\ndict_week = dict(zip(df_calendar.d.values, df_calendar.wm_yr_wk.values))","d92b6c1f":"df_calendar.head()","121bc2b9":"dict_week","30738cf1":"# We'll create a pricing matrix M(n, p) with n = sku_id and p = week\n\n# Import Pricing\n\ndf_price = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sell_prices.csv')\n\n# create a unique SKU Index\n\ndf_price['item_store_id'] = df_price['store_id'] + '-' + df_price['item_id']\n\ndf_price.head()","ed013045":"print(\"{:,} records for sales price\".format(len(df_price)))","f94ff12c":"df_price.keys()","7eee1081":"# Pricing\n\ndf_price = df_price.pivot(index='item_store_id', columns='wm_yr_wk', values='sell_price').fillna(0)\n\ndf_price.head()","d52a6c5f":"# Matrix from pivot \n\nmatrix_price = df_price.to_numpy()","8c26a7f3":"matrix_price","4a04c3f8":"# Dict Matrix Index\n\npr_n = dict(zip(df_price.index, range(len(df_price.index))))\n\npr_p = dict(zip(df_price.columns, range(len(df_price.columns))))","3747448c":"pr_n","907d6a6f":"pr_p","c6093342":"print(\"{:,} records for sales price pivot\".format(len(df_price)))","6c0b00d5":"# we calculate the Sales Mean during the first 366 days\n\ndf['mean'] = df[COLS_DATE].mean(axis = 1)\n\n# Standard Deviation\n\ndf['std'] = df[COLS_DATE].std(axis = 1)\n\n# We remove items not sold during the first year\n\nprint(\"{:,} records for the full scope\".format(len(df)))\n\ndf = df[df['mean']>0]\n\nprint(\"{:,} records for after filter\".format(len(df)))\n\ndf.reset_index(inplace = True)\n\n# We verifie that the line with product with zero sales in year 1 if they are deleted or not yet + Mean and standard dev columns\n\ndf.head()","b56de981":"# let's calculate the Total Units\n\ndf['units'] = df[COLS_DATE].sum(axis = 1)\n\n# Turnover = Units x Price\n\ndf['TO'] = 0 \n\nfor col in COLS_DATE:\n    df['TO'] = df['TO'] + df[col] * df[['id', col]].apply(\n        lambda t: matrix_price[pr_n[t['id']], pr_p[dict_week[col]]], axis = 1)\n    \n# We verify our updated columns\n\ndf.head(10)","84584ca4":"df['CV'] = df['std']\/df['mean']\n\ndf.head()","7674d0d9":"# create a copy of our data frame where we focus only on 1 category (Hobbies)\n\ndf_abc = df[df['cat_id']=='HOBBIES'].drop(['mean', 'std', 'CV'], axis = 1).copy()\n\ndf_abc = df_abc.groupby(['item_id', 'dept_id', 'cat_id']).sum()","7428e647":"df_abc.head()","1eecab79":"# Calculate mean - standard deviation - CV\n\n# Mean\n\ndf_abc['mean'] = df_abc[COLS_DATE].mean(axis = 1)\n\n# Filter out the reference withou sales\n\ndf_abc = df_abc[df_abc['mean']>0]\n\n# Standard\n\ndf_abc['std'] = df_abc[COLS_DATE].std(axis = 1)\n\n# Coefficient of Variation\n\ndf_abc['CV'] = df_abc['std']\/df_abc['mean']\n\ndf_abc.reset_index(inplace = True)","d5d2bfde":"df_abc.head()","b6bdf9b3":"# Normalility Test through Shapiro-wilks test\n\ndf_abc['Normality_p'] = df_abc[COLS_DATE].apply(lambda row : stats.shapiro(row)[1], axis = 1)\nalpha = 0.001\ndf_abc['Not_Normal'] = df_abc['Normality_p'] < alpha","c6dd9d87":"df_abc.head()","d01455c5":"# if you want to find a specific item base on its id : \n\nhobbies_index = df_abc[df_abc[\"item_id\"].str.contains(\"HOBBIES_1_323\",  na=False)]\nhobbies_index","6f4e378e":"# ABC SKU-LEVEL\n\ndf_abc = df_abc.drop(COLS_DATE, axis =1).copy()\ndf_abc['TO%'] = 100*(df_abc['TO']\/(df_abc['TO'].sum()))\n\n# Sort \n\ndf_abc.sort_values(['TO%'], ascending = False, inplace = True, ignore_index=True)\ndf_abc['TO%_CS'] = df_abc['TO%'].cumsum() #cumulated sum\n\n# A, B, C on SKU Number\n\nn_sku = len(df_abc)\nn_a, n_b = int(0.05*n_sku), int(0.5*n_sku)\ndf_abc['SKU_ID'] = pd.Series(range(1, len(df_abc))).astype(int)\ndf_abc['SKU_%'] = (100 * pd.Series(range(1, len(df_abc))) \/ len(df_abc))\ndf_abc['ABC'] = pd.Series(range(len(df_abc))).apply(lambda t: 'A' if t <= n_a-1 else 'B' if t <= n_b-1 else 'C')\n\n# A, B, C on turnover\n\nto_a, to_b = df_abc[df_abc['SKU_ID']==n_a]['TO%'].max(), df_abc[df_abc['SKU_ID']==n_b]['TO%'].max()\n\nprint(\"{:,} unique SKU\".format(len(df_abc)))\n\ndf_abc.head()","08e7e9c4":"# Distribution by Value\n\nax = plt.gca()\ndf_abc.plot(figsize=(12, 8), x='SKU_%', y='TO%_CS', ax =ax, grid = True)\n\n# ABC\n\n# 20%, 50% of SKU Number (2 Vertical lines)\n\nax.axvline(5 , color=\"red\", linestyle=\"-\", linewidth = 1.0)\nax.axvline(20 , color=\"red\", linestyle=\"-\", linewidth = 1.0)\n\n# 20%, 50% of SKU Number (2 Horizental lines)\n\nax.axhline(80 , color=\"blue\", linestyle=\"--\", linewidth = 1.0)\nax.axhline(95 , color=\"blue\", linestyle=\"--\", linewidth = 1.0)\n\nplt.xlabel('Percentage of SKU (%)')\nplt.xticks(rotation=90)\nplt.ylabel('Percentage of the Annual Turnover (%)')\n\nplt.title('ABC Analysis: Distribution by Turnover (Sales Value in $)')\n\nplt.show()","dd4dad93":"# Bar Chart\n\nax = plt.gca()\ncolors = {'A':'red', 'B':'green', 'C':'blue'}\n\n# Remove Outliers\n\ndf_plot = df_abc[df_abc['CV']<4].copy()\ndf_plot.plot.scatter(figsize=(12, 8), x='TO%', y='CV', color=df_plot['ABC'].map(colors), ax =ax, grid = True)\n\n# ABC\n# A, B and C\n\nax.axvline(to_a , color=\"red\", linestyle=\"-\", linewidth = 1.0)\nax.axvline(to_b , color=\"red\", linestyle=\"-\", linewidth = 1.0)\n\n# 20%, 50% of SKU Number\n\nax.axhline(1 , color=\"blue\", linestyle=\"--\", linewidth = 1.0)\n\nplt.xlabel('Percentage of Turnover (%)')\nplt.xticks(rotation=90)\nplt.ylabel('Coefficient of Variation')\n\nplt.title('Distribution by Demand Variability')\n\nplt.show()","fc122c64":"# Bar Chart\n\nax = plt.gca()\ncolors = {False:'green', True:'red'}\n\n# Remove Outliers\n\ndf_plot = df_abc[df_abc['CV']<4].copy()\ndf_plot.plot.scatter(figsize=(12, 8), x='TO%', y='CV', color=df_plot['Not_Normal'].map(colors), ax =ax, grid = True)\n\n# ABC\n# A, B and C\n\nax.axvline(to_a , color=\"red\", linestyle=\"-\", linewidth = 1.0)\nax.axvline(to_b , color=\"red\", linestyle=\"-\", linewidth = 1.0)\n\n# 20%, 50% of SKU Number\n\nax.axhline(1 , color=\"blue\", linestyle=\"--\", linewidth = 1.0)\n\nplt.xlabel('Percentage of Turnover (%)')\nplt.xticks(rotation=90)\n\nplt.ylabel('Coefficient of Variation')\nplt.title('Distribution by Demand Variability')\n\nplt.show()","2c754789":"df_abc['Not_Normal'].value_counts()","9d598901":"## Coefficient of Variation","a874de3c":"## Turnover, Sales Units","66060325":"##### Does the distribution of our sales follows a normal distribution ?","9dd90d5b":"\n#### CV = sigma \/ mu = Standard deviation \/ Mean","bfc47377":"#### Turnover = Price x Volume\n\n#### Product turnover, or inventory turnover, is a measurement of the speed a company sells the products or its inventory that she has on hand","26cdce42":"## Segmentation","38531780":"### Segmentation by Demand Variability (aka Coefficient of variation)","673afd44":"# Product Segmentation for Retail","04e8035e":"### Normality Test","03460acb":"## Import Data & Processing","755f37e5":"## Statistical Analysis","48ee2562":"###### few items follows a Normal distribution. Just 7 items out of 317","29990ac4":"#### ABC Analysis + Demand Variability"}}