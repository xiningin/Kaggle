{"cell_type":{"393b2b43":"code","39e95ace":"code","980340b5":"code","8d399e12":"code","033518dc":"code","503804c9":"code","be50f016":"code","087f56ca":"code","7e460b78":"code","b5dde7f0":"code","0d1cc3f2":"code","f6ad529c":"code","5ac950f2":"code","68895357":"code","2b36a9f0":"markdown","cde530f9":"markdown"},"source":{"393b2b43":"%%capture\n!pip install wandb --upgrade","39e95ace":"import os\nimport re\nimport cv2\nimport glob\nimport imageio\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","980340b5":"import wandb\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\nwandb.login(key=wandb_api)","8d399e12":"WORKING_DIR_PATH = '..\/input\/hpa-single-cell-image-classification\/'\nIMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128","033518dc":"# Ref: https:\/\/www.kaggle.com\/divyanshuusingh\/eda-image-segmentation\nlabel_names= {\n0: \"Nucleoplasm\",\n1: \"Nuclear membrane\",\n2: \"Nucleoli\",\n3: \"Nucleoli fibrillar center\",\n4: \"Nuclear speckles\",\n5: \"Nuclear bodies\",\n6: \"Endoplasmic reticulum\",\n7: \"Golgi apparatus\",\n8: \"Intermediate filaments\",\n9: \"Actin filaments\",\n10: \"Microtubules\",\n11: \"Mitotic spindle\",\n12: \"Centrosome\",\n13: \"Plasma membrane\",\n14: \"Mitochondria\",\n15: \"Aggresome\",\n16: \"Cytosol\",\n17: \"Vesicles and punctate cytosolic patterns\",\n18: \"Negative\"\n}","503804c9":"df = pd.read_csv(WORKING_DIR_PATH+'train.csv')\n# Add a column - num_classes\ndf['num_classes'] = df['Label'].apply(lambda r: len(r.split('|')))\nprint(f'Total number of images: {len(df)}')\ndf.head()","be50f016":"print(df['num_classes'].value_counts())\ndf['num_classes'].value_counts().plot.bar(title='Examples with multiple labels', xlabel='number of labels per example', ylabel='# train examples')\nplt.show()","087f56ca":"df_one_label = df.loc[df['num_classes'] == 1]\nprint(f'Number of images with one image-level labels: {len(df_one_label)}')\ndf_one_label.Label = df_one_label.Label.astype('int64')\ndf_one_label.head()","7e460b78":"# Save as Artifacts\n\ndf_one_label.to_csv('train_single.csv', index=True)\n\nrun = wandb.init(entity='ayush-thakur', project='hpa', job_type='single_label_dataset')\nartifact_raw = run.use_artifact('ayush-thakur\/hpa\/raw:v0', type='dataset')\n\nartifact = wandb.Artifact('single_label', type='dataset')\nartifact.add_file('train_single.csv')\nrun.log_artifact(artifact)\nrun.join()","b5dde7f0":"labels, counts = np.unique(df_one_label.Label.values, return_counts=True)\nprint(f'The unique labels are: {labels} and there values are: {counts}')\n\nplt.figure(figsize=(15,5))\nplt.bar(labels, counts)\n\nfor index, value in enumerate(counts):\n    plt.text(index-0.25, value, str(value), fontdict=dict(fontsize=10))\n\nplt.xticks(np.arange(len(labels)), labels=label_names.values(), rotation=85)\nplt.show()","0d1cc3f2":"df_splits = np.array_split(df_one_label, 4)","f6ad529c":"len(df_one_label), len(df_splits[0]), len(df_splits[1]), len(df_splits[2]), len(df_splits[3])","5ac950f2":"for i, df_split in enumerate(df_splits):\n    df_split.to_csv(f'train_single_{i}.csv')","68895357":"# Save as Artifacts\nrun = wandb.init(entity='ayush-thakur', project='hpa', job_type='single_label_dataset_split')\nartifact_single_label = run.use_artifact('ayush-thakur\/hpa\/single_label:v1', type='dataset')\n\nartifact = wandb.Artifact('single_label_split', type='dataset')\n\nfor i in range(4):\n    artifact.add_file(f'train_single_{i}.csv')\n    \nrun.log_artifact(artifact)\nrun.join()","2b36a9f0":"* Since it's going to take more than 9 hours to create this dataset and the Kernel capacity is 9 hrs currently, I am splitting the `df_one_label.csv` into four `csv` files. Each will have roughly 2500 image ids. ","cde530f9":"* First going to create single label dataset for images which have one image-level labels. "}}