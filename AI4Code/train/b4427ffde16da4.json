{"cell_type":{"9b5f50c9":"code","ff28df5d":"code","685b4c3b":"code","2e2e52a9":"code","acdcee58":"code","cbb41053":"code","cab26a1b":"code","9fb54aad":"code","5c7c35f4":"code","ab2996c1":"code","c8ba7f8d":"code","0746f096":"code","ea8a4c98":"code","3e315b37":"code","f3b3c904":"code","a5cc9cf2":"code","829781ad":"markdown","14ada3f8":"markdown","80508175":"markdown","f202daef":"markdown","ac57232d":"markdown","b82b04e5":"markdown","ed4ed75b":"markdown","52fc1300":"markdown","02539776":"markdown"},"source":{"9b5f50c9":"%%capture\n!pip install \/kaggle\/input\/facenet-pytorch-vggface2\/facenet_pytorch-2.2.7-py3-none-any.whl\n!pip install \/kaggle\/input\/dlibpkg\/dlib-19.19.0\n!pip install \/kaggle\/input\/mtcnn-package\/mtcnn-0.1.0-py3-none-any.whl","ff28df5d":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport torch\nfrom tqdm.notebook import tqdm\nimport time\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'","685b4c3b":"sample = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/aagfhgtpmv.mp4'\n\nreader = cv2.VideoCapture(sample)\nimages_1080_1920 = []\nimages_720_1280 = []\nimages_540_960 = []\nfor i in tqdm(range(int(reader.get(cv2.CAP_PROP_FRAME_COUNT)))):\n    _, image = reader.read()\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    images_1080_1920.append(image)\n    images_720_1280.append(cv2.resize(image, (1280, 720)))\n    images_540_960.append(cv2.resize(image, (960, 540)))\nreader.release()\n\nimages_1080_1920 = np.stack(images_1080_1920)\nimages_720_1280 = np.stack(images_720_1280)\nimages_540_960 = np.stack(images_540_960)\n\nprint('Shapes:')\nprint(images_1080_1920.shape)\nprint(images_720_1280.shape)\nprint(images_540_960.shape)","2e2e52a9":"def plot_faces(images, figsize=(10.8\/2, 19.2\/2)):\n    shape = images[0].shape\n    images = images[np.linspace(0, len(images)-1, 16).astype(int)]\n    im_plot = []\n    for i in range(0, 16, 4):\n        im_plot.append(np.concatenate(images[i:i+4], axis=0))\n    im_plot = np.concatenate(im_plot, axis=1)\n    \n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n    ax.imshow(im_plot)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\n    ax.grid(False)\n    fig.tight_layout()\n\ndef timer(detector, detect_fn, images, *args):\n    start = time.time()\n    faces = detect_fn(detector, images, *args)\n    elapsed = time.time() - start\n    print(f', {elapsed:.3f} seconds')\n    return faces, elapsed","acdcee58":"plot_faces(images_540_960, figsize=(10.8, 19.2))","cbb41053":"from facenet_pytorch import MTCNN\ndetector = MTCNN(device=device, post_process=False)\n\ndef detect_facenet_pytorch(detector, images, batch_size):\n    faces = []\n    for lb in np.arange(0, len(images), batch_size):\n        imgs = [img for img in images[lb:lb+batch_size]]\n        faces.extend(detector(imgs))\n    return faces\n\ntimes_facenet_pytorch = []    # batched\ntimes_facenet_pytorch_nb = [] # non-batched","cab26a1b":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_540_960, 60)\ntimes_facenet_pytorch.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_720_1280, 40)\ntimes_facenet_pytorch.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_facenet_pytorch, images_1080_1920, 20)\ntimes_facenet_pytorch.append(elapsed)\n\nplot_faces(torch.stack(faces).permute(0, 2, 3, 1).int().numpy())","9fb54aad":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_540_960, 1)\ntimes_facenet_pytorch_nb.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_facenet_pytorch, images_720_1280, 1)\ntimes_facenet_pytorch_nb.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_facenet_pytorch, images_1080_1920, 1)\ntimes_facenet_pytorch_nb.append(elapsed)","5c7c35f4":"del detector\ntorch.cuda.empty_cache()","ab2996c1":"from dlib import get_frontal_face_detector\ndetector = get_frontal_face_detector()\n\ndef detect_dlib(detector, images):\n    faces = []\n    for image in images:\n        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        boxes = detector(image_gray)\n        box = boxes[0]\n        face = image[box.top():box.bottom(), box.left():box.right()]\n        faces.append(face)\n    return faces\n\ntimes_dlib = []","c8ba7f8d":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_dlib, images_540_960)\ntimes_dlib.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_dlib, images_720_1280)\ntimes_dlib.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_dlib, images_1080_1920)\ntimes_dlib.append(elapsed)\n\nplot_faces(np.stack([cv2.resize(f, (160, 160)) for f in faces]))","0746f096":"del detector\ntorch.cuda.empty_cache()","ea8a4c98":"from mtcnn import MTCNN\ndetector = MTCNN()\n\ndef detect_mtcnn(detector, images):\n    faces = []\n    for image in images:\n        boxes = detector.detect_faces(image)\n        box = boxes[0]['box']\n        face = image[box[1]:box[3]+box[1], box[0]:box[2]+box[0]]\n        faces.append(face)\n    return faces\n\ntimes_mtcnn = []","3e315b37":"print('Detecting faces in 540x960 frames', end='')\n_, elapsed = timer(detector, detect_mtcnn, images_540_960)\ntimes_mtcnn.append(elapsed)\n\nprint('Detecting faces in 720x1280 frames', end='')\n_, elapsed = timer(detector, detect_mtcnn, images_720_1280)\ntimes_mtcnn.append(elapsed)\n\nprint('Detecting faces in 1080x1920 frames', end='')\nfaces, elapsed = timer(detector, detect_mtcnn, images_1080_1920)\ntimes_mtcnn.append(elapsed)\n\nplot_faces(np.stack([cv2.resize(face, (160, 160)) for face in faces]))","f3b3c904":"del detector\ntorch.cuda.empty_cache()","a5cc9cf2":"fig, ax = plt.subplots(figsize=(10,6))\n\npos = np.arange(3)\nplt.bar(pos, times_facenet_pytorch, 0.2, label='facenet-pytorch')\nplt.bar(pos + 0.2, times_facenet_pytorch_nb, 0.2, label='facenet-pytorch (non-batched)')\nplt.bar(pos + 0.4, times_dlib, 0.2, label='dlib')\nplt.bar(pos + 0.6, times_mtcnn, 0.2, label='mtcnn')\n\nax.set_ylabel('Elapsed time (seconds)')\nax.set_xticks(pos + 0.25)\nax.set_xticklabels(['540x960', '720x1280', '1080x1920'])\nplt.legend();","829781ad":"## The dlib package","14ada3f8":"## The mtcnn package","80508175":"# Comparison of face detection packages","f202daef":"## The facenet-pytorch package (non-batched)","ac57232d":"This notebook demonstrates the use of three face detection packages:\n\n1. facenet-pytorch: https:\/\/pypi.org\/project\/facenet-pytorch\/\n1. mtcnn: https:\/\/pypi.org\/project\/mtcnn\/\n1. dlib: https:\/\/pypi.org\/project\/dlib\/\n\nThanks to Carlos Souza and \"Need to think of a good name\" for creating the datasets used to install the packages offline.\n\nEach package is tested for its speed in detecting the faces in a set of 300 images (all frames from one video), with GPU support enabled. Detection is performed at 3 different resolutions. Any one-off initialization steps, such as model instantiation, are performed prior to performance testing.\n\nPlease let me know if you know of better\/faster ways to use these packages.\n\n*****\n**UPDATE (2020-01-05)**: facenet-pytorch version 2.0.0 has been released, offering some additional performance gains, particularly for batched processing.\n*****\n\n## Summary of results\n\n|Package|FPS (1080x1920)|FPS (720x1280)|FPS (540x960)|\n|-|-|-|\n|***facenet-pytorch***|12.97|20.32|25.50|\n|***facenet-pytorch (non-batched)***|9.75|14.81|19.68|\n|***dlib***|3.80|8.39|14.53|\n|***mtcnn***|3.04|5.70|8.23|\n\n## Other resources\n\nSee the following kernel for a guide to using the MTCNN functionality of facenet-pytorch: https:\/\/www.kaggle.com\/timesler\/guide-to-mtcnn-in-facenet-pytorch","b82b04e5":"## Install packages\n\nNormally, each package can be installed with `pip install <package>`, but this notebook is offline to demonstrate their use in this competition.","ed4ed75b":"Read in the frames of a video using cv2's `VideoCapture`.","52fc1300":"## Performance comparison","02539776":"## The facenet-pytorch package"}}