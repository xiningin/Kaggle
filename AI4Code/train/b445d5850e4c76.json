{"cell_type":{"5f85e0c5":"code","6dce117f":"code","86ac06db":"code","a8ef8bfe":"code","f4b0b5a1":"code","524ab020":"code","9240d1d2":"code","2b0809df":"code","5e436e5d":"code","806740f9":"code","e675cbc8":"code","f8b78760":"code","9d932084":"code","09268a14":"code","3dc7d055":"code","93466d15":"code","d5b0bcda":"code","5070b6f8":"code","4ad67916":"code","837858a2":"code","a3538155":"code","ee7e8c07":"code","cbab6e82":"code","7067f61e":"code","fc884365":"code","356b853b":"code","91db28cd":"code","a701022d":"code","f91ad716":"code","10a7f77a":"code","22738b83":"code","95996814":"code","f9dbdccc":"code","6f28f64e":"code","f043a388":"code","3231b65b":"code","80cefcf4":"code","7e43a524":"code","3dd8394d":"code","86243a23":"code","60a59b36":"code","7d481b30":"code","161f0d7f":"code","8c0820d4":"code","4c57c253":"code","cfaf6884":"code","860ac24c":"code","a27f8205":"code","21cf3051":"code","08cca9de":"code","3d166188":"code","94d8d09f":"code","ee2f19a7":"code","064367fd":"code","37c349fd":"code","ff2ac1bc":"code","f45c01c0":"code","0837122a":"code","8cfc6c9d":"code","dbf0f4c8":"code","54a15588":"code","663ccb0d":"code","c0209152":"code","f5c9c30b":"code","664b2064":"code","652ec6cc":"code","6e284326":"code","e0a8d38a":"code","3bfc838c":"code","0710118f":"code","63fce9c9":"code","0eafadf2":"code","6e2b3ad6":"code","5082933b":"markdown","558e760f":"markdown","f6e5002f":"markdown","b2353bed":"markdown","89a1e8a5":"markdown","8053023a":"markdown","973b8d86":"markdown","6d033926":"markdown","b13344d4":"markdown","03df52d6":"markdown","d63b4f22":"markdown","eccfecdf":"markdown","cc3daeb6":"markdown","b79a7bdf":"markdown","8f8374fd":"markdown","7bdde500":"markdown"},"source":{"5f85e0c5":"# surpress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","6dce117f":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","86ac06db":"# importing day.csv and looking at five columns\nboombike = pd.read_csv(\"..\/input\/daybmb\/day.csv\")\nboombike.head()","a8ef8bfe":"boombike.shape","f4b0b5a1":"boombike.info()","524ab020":"# droping casual resistered as cnt = casual + registered and dteday as all other variables like \n# season weekday are derived from it\nboombike = boombike.drop(['casual','registered','instant','dteday'],axis=1)\nboombike.head()","9240d1d2":"# converting categorical variables datatype feom int to object\nboombike['mnth'] = boombike['mnth'].astype(str)\nboombike['weekday'] = boombike['weekday'].astype(str)\nboombike['weathersit'] = boombike['weathersit'].astype(str)\nboombike['season'] = boombike['season'].astype(str)\nboombike.info()","2b0809df":"# replcaing integers with month in mnth column\nboombike['mnth'] =boombike['mnth'].replace('1','jan').replace('2','feb').replace('3','mar').replace('4','apr').replace('5',\n'may').replace('6','jun').replace('7','july').replace('8','aug').replace('9','sep').replace('10','oct').replace('11',\n 'nov').replace('12','dec')\n\n","5e436e5d":"# replcaing integers with season in season column\nboombike['season'] =boombike['season'].replace('1','spring').replace('2','summer').replace('3','fall').replace('4','winter')\n","806740f9":"# replcaing integers with weekday in weekday column\nboombike['weekday'] =boombike['weekday'].replace('1','mon').replace('2','tue').replace('3','wed').replace('4','thu').replace('5',\n'fri').replace('6','sat').replace('0','sun')","e675cbc8":"# replcaing integers with weathersit in weathersit column\nboombike['weathersit'] =boombike['weathersit'].replace('1','clear').replace('2','mist').replace('3',\n'lightsnow').replace('4','rain')\n","f8b78760":"boombike.head()","9d932084":"# pairplot between the numerical variables\nsns.pairplot(boombike,vars=['temp','atemp','hum','windspeed','cnt'])\nplt.show()","09268a14":"# box plot between the cnt and other categorical variables\nplt.figure(figsize=(20,12))\nplt.subplot(3,3,1)\nsns.boxplot(x='season', y='cnt', data = boombike)\nplt.subplot(3,3,2)\nsns.boxplot(x='yr', y='cnt', data = boombike)\nplt.subplot(3,3,3)\nsns.boxplot(x='holiday', y='cnt', data = boombike)\nplt.subplot(3,3,4)\nsns.boxplot(x='weekday', y='cnt', data = boombike)\nplt.subplot(3,3,5)\nsns.boxplot(x='workingday', y='cnt', data = boombike)\nplt.subplot(3,3,6)\nsns.boxplot(x='mnth', y='cnt', data = boombike)\nplt.subplot(3,3,7)\nsns.boxplot(x='weathersit',y= 'cnt' ,data = boombike)","3dc7d055":"# creating dummy variables for season, weekday, mnth and weathersit \nseason_1 = pd.get_dummies(boombike['season'],drop_first='True')\nweekday_1 = pd.get_dummies(boombike['weekday'],drop_first='True')\nmnth_1 = pd.get_dummies(boombike['mnth'],drop_first='True')\nweathersit_1 = pd.get_dummies(boombike['weathersit'],drop_first='True')","93466d15":"#five columns in weathersit_1\nweathersit_1.head() ","d5b0bcda":"# five columns in mnth\nmnth_1.head() ","5070b6f8":"#five columns in weekday\nweekday_1.head()","4ad67916":"# five columns in season\nseason_1.head()","837858a2":"# adding results to our original data frame boombike\nboombike = pd.concat([boombike,season_1,weekday_1,mnth_1,weathersit_1], axis=1)\nboombike.head()","a3538155":"# dropping season,weekday,mnth,weathersit columns as we have created dummies for it\nboombike = boombike.drop(['season','weekday','mnth','weathersit'],axis=1)\nboombike.head()","ee7e8c07":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(boombike, train_size = 0.7, test_size = 0.3, random_state = 100)","cbab6e82":"# using minmax scaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","7067f61e":"num_vars = ['temp', 'atemp', 'hum', 'windspeed', 'cnt']\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n\ndf_train.head()","fc884365":"# heat map for seeing the corelation between the variables\nplt.figure(figsize = (30, 20))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","356b853b":"y_train = df_train.pop('cnt')\nX_train = df_train","91db28cd":"# importing RFE and linearregression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","a701022d":"#running rfe with outnumber of variables equal to 15\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             \nrfe = rfe.fit(X_train, y_train)","f91ad716":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","10a7f77a":"col = X_train.columns[rfe.support_]\ncol","22738b83":"X_train.columns[~rfe.support_]","95996814":"# creating X_train dataframe with rfe selected variables\nX_train_rfe = X_train[col]","f9dbdccc":"import statsmodels.api as sm\nX_train_rfe = sm.add_constant(X_train_rfe)\nlr = sm.OLS(y_train,X_train_rfe)\nlr_model =lr.fit()\nlr_model.summary()","6f28f64e":"# all p values are significant.lets check VIF","f043a388":"X_train_rfe.columns","3231b65b":"X_train_new = X_train_rfe.drop('const',axis=1)","80cefcf4":"from statsmodels.stats.outliers_influence import variance_inflation_factor","7e43a524":"vif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3dd8394d":"# dropping hum column as as it is having highest vif valu and greater than 5\nX_train_new = X_train_new.drop('hum',axis=1)","86243a23":"X_train_lm = sm.add_constant(X_train_new)\nlr = sm.OLS(y_train,X_train_lm)\nlr_model =lr.fit()\nlr_model.summary()","60a59b36":"# all the p values are significant and lets check for vif","7d481b30":"X_train_new = X_train_lm.drop('const',axis=1)","161f0d7f":"vif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8c0820d4":"# though temp is having high vif, bt dropping it Rsquared value dropping to .66 which is bad lets drop next highest vif working day\nX_train_new = X_train_new.drop('workingday',axis=1)","4c57c253":"X_train_lm = sm.add_constant(X_train_new)\nlr = sm.OLS(y_train,X_train_lm)\nlr_model =lr.fit()\nlr_model.summary()","cfaf6884":"# dropping sat as pvalue > .05\nX_train_new = X_train_new.drop('sat',axis=1)","860ac24c":"X_train_lm = sm.add_constant(X_train_new)\nlr = sm.OLS(y_train,X_train_lm)\nlr_model =lr.fit()\nlr_model.summary()","a27f8205":"# all pvalues are significant lets check vif\nX_train_new = X_train_lm.drop('const',axis=1)","21cf3051":"vif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","08cca9de":"# dropping windspeed as it is having high vif next to temp\nX_train_new = X_train_new.drop('windspeed',axis=1)","3d166188":"X_train_lm = sm.add_constant(X_train_new)\nlr = sm.OLS(y_train,X_train_lm)\nlr_model =lr.fit()\nlr_model.summary()","94d8d09f":"# dropping jan column as p >.05\nX_train_new = X_train_new.drop('jan',axis=1)","ee2f19a7":"X_train_lm = sm.add_constant(X_train_new)\nlr = sm.OLS(y_train,X_train_lm)\nlr_model =lr.fit()\nlr_model.summary()","064367fd":"# all p values are significant lets check vif\nX_train_new = X_train_lm.drop('const',axis=1)","37c349fd":"vif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ff2ac1bc":"# all vif values are below 5 and our Rsquared value is .824 and adjusted R square is .821 which is good","f45c01c0":"# checking whether all the error values are normally distributed ot not. lets plot histogram of error values\n\n","0837122a":"y_train_cnt = lr_model.predict(X_train_lm)","8cfc6c9d":"# Importing the required libraries for plots.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","dbf0f4c8":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_cnt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label","54a15588":"# applying the test scaling on X_test and y_test\nnum_vars =['temp','atemp','hum','windspeed','cnt']\ndf_test[num_vars] = scaler.transform(df_test[num_vars])\ndf_test.head()","663ccb0d":"#creating y_test and X_test\ny_test =df_test.pop('cnt')\nX_test = df_test\nX_test.head()","c0209152":"# creating X_test_now by dropping columns which are dropped in training set\nX_test_new = X_test[X_train_new.columns]\n# adding constant\nX_test_new = sm.add_constant(X_test_new)","f5c9c30b":"# making predictions\ny_test_pred = lr_model.predict(X_test_new)","664b2064":"# checking r2_score to know about our model whether it is good or bad\n# importing libary\nfrom sklearn.metrics import r2_score","652ec6cc":"r2_score(y_true =y_test,y_pred=y_test_pred)","6e284326":"# got r2_score .80 which is close to adjusted Rsuared value.82  tells that our model is good","e0a8d38a":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_test_pred)\nfig.suptitle('y_test vs y_test_pred', fontsize=20)         # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label\n","3bfc838c":"# from abive we can see the spread of y_test vs Y-test_pred is good","0710118f":"# for plotting bar plot vs y_tes vs y_test_predict\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})\n","63fce9c9":"df1 = df.head(50)\ndf1","0eafadf2":"# barplot for Actual vs predicted\ndf1.plot(kind='bar',figsize=(50,40))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","6e2b3ad6":"# from above bar plot we can we actual & precicted values are close which tells us that our model is good","5082933b":"our model\ncnt = 0.1503 + 0.2325year-0.1008holiday+0.5034temp-0.0764spring+0.0355summer+0.0842winter-0.0527july+0.0810sep-0.2999lightsnow-0.0791mist\nyear,temp,summer,winter,sep have positive coefficients\nholiday,spring,july,lightsnow,mist  have negative coefficients\n\n1)no of users will be slightly lower during holidays, in spring season,in july \n2) no of users will be lower during light snow , mist and there will be no users during rain\n3) no of users will be slightly higher during summer, winter,september\n4) temperature variable majorly effects the no of users","558e760f":"# residual analysis of train data","f6e5002f":"# importing and understanding data\n","b2353bed":"# Data visualisation","89a1e8a5":"In above pairplot clearly cnt and temp and a temp have a linear relation","8053023a":"# building model using statsmodel for detailed statistics","973b8d86":"# Spliting the data into training and testing sets","6d033926":"# Dummy variables","b13344d4":"# Dividing into X and Y sets for the model building","03df52d6":"1)from aboeve boxplot we can see that cnt is low in spring and high fall\n2) cnt is high in year 2019\n3)cnt is very low during in light snow and there is no cnt during rain\n4)cnt is very low in jan","d63b4f22":"# making predictions","eccfecdf":"\nProblem Statement\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes. How well those variables describe the bike demands Based on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n","cc3daeb6":"# Data Preparation","b79a7bdf":"# rescalling the features","8f8374fd":"# Building our model using RFE(recursive feature elimination)","7bdde500":"# model evaluation"}}