{"cell_type":{"2f6a2c61":"code","9eddbed0":"code","5f58897c":"code","77aa17bb":"code","2f2c7126":"code","30e18105":"code","28d3b24a":"code","2c4acf94":"code","31f2a64b":"code","6bee775c":"code","1580210b":"code","1f37b7f0":"code","a9f03f1c":"code","ef6354c5":"code","bbfb9695":"code","c62741dc":"code","16772f72":"code","6c6f8418":"code","295b3a71":"code","1aee87c7":"code","9cb4e9d1":"markdown","ff17d91e":"markdown","79c6172d":"markdown","35941a32":"markdown","ea88010b":"markdown","54a32a2b":"markdown","8a76fdf0":"markdown","309d59f6":"markdown","75d49314":"markdown","e6fc106f":"markdown","150d0c5b":"markdown","a5254969":"markdown","489258c4":"markdown","6f876013":"markdown","651b7d00":"markdown","ab3c8735":"markdown","f2b65c9e":"markdown"},"source":{"2f6a2c61":"import pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport os\nimport pydicom as dcm","9eddbed0":"np.random.seed(42)","5f58897c":"data = pd.read_csv('..\/input\/1-tradition-image-processing-feature-extraction\/img_features.csv')\ndata.head()","77aa17bb":"feats = data.features.apply(lambda x: list(eval(x)))  # oops!\ndataset = pd.DataFrame(feats.values.tolist(), \n                        columns=['mean', 'stddev', 'area', 'perimeter', 'irregularity', 'equiv_diam', 'hu1', 'hu2', 'hu4', 'hu5', 'hu6'],\n                       index=data.index)\ndataset['label'] = data['target']\ndataset.head()","2f2c7126":"X_train, X_test, y_train, y_test = train_test_split(dataset.drop('label', axis=1), dataset['label'],\n                                                   test_size=0.4, stratify=dataset['label'])","30e18105":"from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n\ndef print_metrics(y_pred, y_train, yt_pred, y_test):\n    print('Train data metrics:')\n    print('Accuracy: ', accuracy_score(y_train, y_pred))\n    print('Precison: ', precision_score(y_train, y_pred))\n    print('Recall: ', recall_score(y_train, y_pred))\n    print('F1 score: ', f1_score(y_train, y_pred))\n    print('ROC AUC score: ', roc_auc_score(y_train, y_pred))\n    print()\n    print('Test data metrics:')\n    print('Accuracy: ', accuracy_score(y_test, yt_pred))\n    print('Precison: ', precision_score(y_test, yt_pred))\n    print('Recall: ', recall_score(y_test, yt_pred))\n    print('F1 score: ', f1_score(y_test, yt_pred))\n    print('ROC AUC score: ', roc_auc_score(y_test, yt_pred))","28d3b24a":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nprint_metrics(lr.predict(X_train), y_train, lr.predict(X_test), y_test)","2c4acf94":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(500, max_depth=8, min_samples_split=2,\n                            n_jobs=-1)\nrf.fit(X_train, y_train)\n\nprint_metrics(rf.predict(X_train), y_train, rf.predict(X_test), y_test)","31f2a64b":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.01,\n                               max_depth=7, min_samples_split=5)\ngb.fit(X_train, y_train)\n\nprint_metrics(gb.predict(X_train), y_train, gb.predict(X_test), y_test)","6bee775c":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train, y_train)\n\nprint_metrics(svm.predict(X_train), y_train, svm.predict(X_test), y_test)","1580210b":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(20)\nknn.fit(X_train, y_train)\n\nprint_metrics(knn.predict(X_train), y_train, knn.predict(X_test), y_test)","1f37b7f0":"from yellowbrick.classifier import ConfusionMatrix\n\ncm = ConfusionMatrix(gb, classes=[0,1], \n                     encoder={0: 'normal', 1: 'pneumonia'})\ncm.fit(X_train, y_train)\ncm.score(X_test, y_test)\ncm.show()","a9f03f1c":"from yellowbrick.classifier import ROCAUC\n\nvisualizer = ROCAUC(gb, classes=[\"normal\", \"pneumonia\"])\n\nvisualizer.fit(X_train, y_train) \nvisualizer.score(X_test, y_test) \nvisualizer.show()    ","ef6354c5":"importances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\nprint(\"Feature ranking:\")\n\nfor f in range(X_train.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\nplt.figure(figsize=(13,7))\nplt.title(\"Feature importances\")\n\nplt.bar(range(X_train.shape[1]), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X_train.shape[1]), X_train.columns[indices])\nplt.xlim([-1, X_train.shape[1]])","bbfb9695":"import skimage\nfrom skimage import feature, filters","c62741dc":"PATH = '..\/input\/rsna-pneumonia-detection-challenge'\n\ndef load_image(path):    \n    patientImage = path + '.dcm'\n    imagePath = os.path.join(PATH,\"stage_2_train_images\/\", patientImage)\n    img = dcm.read_file(imagePath).pixel_array\n    return img\n\ndef imshow_gray(img):\n    plt.figure(figsize=(12,7))\n    return plt.imshow(img, cmap='gray')\n\ndef area(img):\n    # binarized image as input\n    return np.count_nonzero(img)\n\ndef perimeter(img):\n    # edges of the image as input\n    return np.count_nonzero(img)\n\ndef irregularity(area, perimeter):\n    # area and perimeter of the image as input, also called compactness\n    I = (4 * np.pi * area) \/ (perimeter ** 2)\n    return I\n\ndef equiv_diam(area):\n    # area of image as input\n    ed = np.sqrt((4 * area) \/ np.pi)\n    return ed\n\ndef get_hu_moments(contour):\n    # hu moments except 3rd and 7th (5 values)\n    M = cv2.moments(contour)\n    hu = cv2.HuMoments(M).ravel().tolist()\n    del hu[2]\n    del hu[-1]\n    log_hu = [-np.sign(a)*np.log10(np.abs(a)) for a in hu]\n    return log_hu\n\n\ndef extract_features(img):\n    mean = img.mean()\n    std_dev = img.std()\n    \n    # hist equalization\n    equalized = cv2.equalizeHist(img)\n    \n    # sharpening\n    hpf_kernel = np.full((3, 3), -1)\n    hpf_kernel[1,1] = 9\n    sharpened = cv2.filter2D(equalized, -1, hpf_kernel)\n    \n    # thresholding\n    ret, binarized = cv2.threshold(cv2.GaussianBlur(sharpened,(7,7),0),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    \n    # edge detection\n    edges = skimage.filters.sobel(binarized)\n    \n    # moments from contours\n    contours, hier = cv2.findContours((edges * 255).astype('uint8'),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    select_contour = sorted(contours, key=lambda x: x.shape[0], reverse=True)[0]\n    \n    \n    # feature extraction\n    ar = area(binarized)\n    per = perimeter(edges)\n    irreg = irregularity(ar, per)\n    eq_diam = equiv_diam(ar)\n    hu = get_hu_moments(select_contour)\n    \n    return (mean, std_dev, ar, per, irreg, eq_diam, *hu)","16772f72":"test_img = data[data['target']==1]['patientId'].sample(1)\n\nimg = load_image(test_img.values[0])\nimshow_gray(img)","6c6f8418":"feats = list(extract_features(img))\n\npred = gb.predict([feats])\n\nif pred == 1:\n    print('Patient is infected with pneumonia')\nelse:\n    print('Patient is normal')","295b3a71":"from skimage.util import random_noise\n\nimg = random_noise(img, mode='gaussian')\nimg = (img*255).astype('int')\nimshow_gray(img)","1aee87c7":"feats = list(extract_features(img.astype('uint8')))\n\npred = gb.predict([feats])\n\nif pred == 1:\n    print('Patient is infected with pneumonia')\nelse:\n    print('Patient is normal')","9cb4e9d1":"### Test on a noisy image","ff17d91e":"### ROC","79c6172d":"# Predict with an image","35941a32":"## Train test split","ea88010b":"# Part 2 - Tradition Image processing for classification: model training\n\nContinuation of my [previous notebook](https:\/\/www.kaggle.com\/suryathiru\/1-tradition-image-processing-feature-extraction\/) where features were manually extracted from the dataset","54a32a2b":"### Gradient boosting classifier","8a76fdf0":"### Functions","309d59f6":"### Make prediction","75d49314":"## Train models\n\nWe evaluate on the following metrics\n1. Accuracy\n2. Precision\n3. Recall\n4. ROC AUC","e6fc106f":"## Visualize the best model","150d0c5b":"### Random forest","a5254969":"### Support Vector Machines","489258c4":"### Logistic regression model","6f876013":"### Load images","651b7d00":"# Prepare dataset","ab3c8735":"### Feature importance","f2b65c9e":"### KNN"}}