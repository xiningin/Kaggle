{"cell_type":{"37ede9ce":"code","4984e5ed":"code","8b411f2a":"code","37c4b122":"code","ab952d1a":"code","d04fcefe":"code","4e73e172":"code","b434fecf":"code","8f9e47c0":"code","c0c804d1":"code","2b845805":"markdown","1ecf87d5":"markdown","351bc216":"markdown","b7cf6e4a":"markdown","5453a50d":"markdown","2584c1e7":"markdown","8168ec86":"markdown","aea6a2c7":"markdown","4d748c1e":"markdown"},"source":{"37ede9ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4984e5ed":"#load data\nx_ = np.load(\"..\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/X.npy\")\ny_ = np.load(\"..\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/Y.npy\")\n\nprint(\"x_ shape:\",x_.shape)\nprint(\"y_ shape:\",y_.shape)","8b411f2a":"#visualize\nplt.subplot(2, 2, 1)\nplt.imshow(x_[260])\nplt.axis('off')\nplt.subplot(2, 2, 2)\nplt.imshow(x_[500])\nplt.axis('off')\nplt.subplot(2, 2, 3)\nplt.imshow(x_[1300])\nplt.axis('off')\nplt.subplot(2, 2, 4)\nplt.imshow(x_[2000])\nplt.axis('off')\nplt.show()","37c4b122":"#reshape\nx = x_.reshape(-1,64,64,1)\nprint(\"x shape: \", x.shape)\n\ny = y_\nprint(\"y shape: \", y.shape)","ab952d1a":"#train test split process\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"x_train shape: \",x_train.shape)\nprint(\"x_test shape: \",x_test.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_test shape: \",y_test.shape)","d04fcefe":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (6,6),padding = 'Same', activation ='relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\n#**************************\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(10, activation='softmax'))\n\n#**************************\n","4e73e172":"optimizer = RMSprop(lr = 0.0001)\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","b434fecf":"history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 30, batch_size = 16, verbose = 1 )","8f9e47c0":"plt.plot(history.history[\"loss\"], label = \"Train loss\")\nplt.plot(history.history[\"val_loss\"], label = \"Test Loss\")\nplt.title(\"Loss graph\")\nplt.xlabel(\"Num of epochs\")\nplt.ylabel(\"Loss value\")\nplt.legend()\nplt.show()\n","c0c804d1":"plt.plot(history.history[\"accuracy\"], label = \"Train accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label = \"Test accuracy\")\nplt.title(\"Accuracy graph\")\nplt.xlabel(\"Num of epochs\")\nplt.ylabel(\"Acc value\")\nplt.legend()\nplt.show()","2b845805":"**Creating Model**\n* After splitting data, we can start to create the model now. \n* Outline: (Conv => Max pool => Batch Normalization => Dropout)x3 => Fully connected(with 2 layer and 1 dropout)","1ecf87d5":"* We got good accuracy. You can try to increase the accuracy with changing hyperparameters if you wish.","351bc216":"* Now, let's visualize loss and accuracy graphs of the model.","b7cf6e4a":"# Introduction\nIn this kernel, I will create a CNN( Convolutional Neural Network) model with Keras library and try to teach the sign language digits to my model. Thanks to [Arda Mavi](http:\/\/www.kaggle.com\/ardamavi) for the dataset and his remarkable works.\n","5453a50d":"* Let's look at several images for improving our perception of data.","2584c1e7":"* Optimizer : RMSprop","8168ec86":"* For using CNN algorithms with Keras, we must reshape the x_ as four-dimensional. The extra dimension correspond to channels. Because of these images are grayscaled, I will write just 1 at the end.","aea6a2c7":"# Conclusion\n* To conclude, we created a convolutional neural network model using Keras library. I prepared this kernel for reinforcing my understanding and doing some practice just after learned the CNN. If you are not familiar with this kind of stuff, you can (infact should) examine this great [tutorial](https:\/\/www.kaggle.com\/kanncaa1\/convolutional-neural-network-cnn-tutorial). Also, if you have questions on your mind or want to give some tricks and advices to me, please leave a comment and don't forget to upvote :)","4d748c1e":"* We created our model, now we can fit and implement it. "}}