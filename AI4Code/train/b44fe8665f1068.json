{"cell_type":{"1a18917b":"code","9a9d8538":"code","c83451ca":"code","7dccf41f":"code","85533885":"code","f8a93948":"code","1fd25c42":"code","27156780":"code","536960d1":"code","adadf344":"code","8b0238b5":"code","138c37d7":"code","e8fc0f2e":"code","ec346c5f":"code","901b252d":"code","2f331e69":"code","ecef9e75":"code","7b30b2de":"code","f2e4aed5":"code","6f277a4a":"code","a60de863":"code","814fe028":"code","08d1973e":"code","aad3654d":"code","8ca87b0b":"code","8e80cfdb":"code","cc0914cc":"code","bd6d4b07":"markdown","1715c649":"markdown","cc7be573":"markdown","456d9d9e":"markdown","ea103aeb":"markdown"},"source":{"1a18917b":"import tensorflow as tf\nfrom tensorflow import keras","9a9d8538":"from keras.datasets import cifar10","c83451ca":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","7dccf41f":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","85533885":"D = (X_train[0].shape)\nprint(D)","f8a93948":"X_train, X_test = X_train\/255, X_test\/255  ## Scaling\n\ny_train, y_test = y_train.flatten(), y_test.flatten()","1fd25c42":"print(y_train.shape)\nprint(y_test.shape)","27156780":"K = len(set(y_train))\nK  # Classes","536960d1":"from keras.layers import Input, Dense, Dropout, Flatten, Conv2D\nfrom keras.models import Model\n\ni = Input(shape = (D))\nx = Conv2D(32, (3,3), strides=2, activation='relu')(i)\nx = Conv2D(64, (3,3), strides=2, activation='relu')(x)\nx = Conv2D(128, (3,3), strides=2, activation='relu')(x)\n#x = Conv2D(256, (3,3), strides=2, activation='relu')(x)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\n#x = Dense(2048, activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(K, activation='softmax')(x)","adadf344":"model = Model(i, x)","8b0238b5":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 15)","138c37d7":"    ### Hit Trial.\n# With everything - 67.3 %\n# With both Dropuout, without 256 Conv2D - 71.4 %\n# Without 1st Dropout, without 256 Conv2D - 68.3 %\n# Without 2nd Dropuout, with 256 Conv2D - 67.6 %\n# Using 1024 instead of 512 in Dense - 68.4 %\n# Using 2048 instead of 512 in Dense - 68.6 %","e8fc0f2e":"# We can take a look at loss & accuracy the way we did in last notebook on CNN.\n# Confusion Matrix.\n# Misclassified labels","ec346c5f":"# Using BatchNormalization\nfrom keras.layers import BatchNormalization, MaxPooling2D\n\ni = Input(shape = (D))\n\nx = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(i)\nx = BatchNormalization()(x)\nx = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(x)\nx = MaxPooling2D((2,2))(x)\n\nx = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(x)\nx = MaxPooling2D((2,2))(x)\n\nx = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(x)\nx = MaxPooling2D((2,2))(x)\n\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(1024, activation = 'relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(K, activation = 'softmax')(x)","901b252d":"model = Model(i, x)","2f331e69":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nr = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 50)","ecef9e75":"# With BatchNormalization with 15 epochs - 80.7 %\n# With BatchNormalization with 50 epochs -  %","7b30b2de":"import matplotlib.pyplot as plt\n\nplt.plot(r.history['accuracy'], label = 'acc')\nplt.plot(r.history['val_accuracy'], label = 'val_acc')\nplt.legend()","f2e4aed5":"plt.plot(r.history['loss'], label = 'loss')\nplt.plot(r.history['val_loss'], label = 'val_loss')\nplt.legend()","6f277a4a":"from sklearn.metrics import confusion_matrix\n\np_pred = model.predict(X_test).argmax(axis = 1)\ncm = confusion_matrix(p_pred, y_test)\nprint(cm)","a60de863":"model.evaluate(X_test, y_test)","814fe028":"batch_size = 32\n\ndata_generator = keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1,\n                                                              height_shift_range=0.1, \n                                                              horizontal_flip=True)\ntrain_generator = data_generator.flow(X_train, y_train, batch_size)\nsteps_per_epochs = X_train.shape[0] \/\/ batch_size\nr = model.fit_generator(train_generator, validation_data=(X_test, y_test), steps_per_epoch=steps_per_epochs, epochs = 50)","08d1973e":"model.evaluate(X_test, y_test)","aad3654d":"# As you can see the time has been increased.","8ca87b0b":"plt.plot(r.history['accuracy'], label = 'acc')\nplt.plot(r.history['val_accuracy'], label = 'val_acc')\nplt.legend()","8e80cfdb":"plt.plot(r.history['loss'], label = 'loss')\nplt.plot(r.history['val_loss'], label = 'val_loss')\nplt.legend()","cc0914cc":"model.summary()","bd6d4b07":"#### Here we are focusing on Droupout & BatchNorm difference.","1715c649":"#### \u2022 If we have already called fit & then calling the fit_generator in \"Data Augmentation\" Keras will continue training where it left, helpful in fine tuning.\n#### \u2022 But if we want to see how N.N will perform with Data Augmentation only call 'fit_generator'.","cc7be573":"##### 50000 images, Height & width = 32 & color image","456d9d9e":"#### Instead of Droupout BatchNorm is beter.","ea103aeb":"### Data Augmentation"}}