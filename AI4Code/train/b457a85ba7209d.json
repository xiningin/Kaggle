{"cell_type":{"c8c50cd1":"code","d491ffaf":"code","a61a27ef":"code","1ef2fa02":"code","3c1820ea":"markdown","ba85f7c2":"markdown","824aa755":"markdown","26f15341":"markdown"},"source":{"c8c50cd1":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# split method \nfrom sklearn.model_selection import train_test_split\n\n# model \nfrom xgboost import XGBRegressor\nimport optuna\n\n# data path \nTRAIN_PATH = \"..\/input\/tabular-playground-series-jan-2022\/train.csv\"\nTEST_PATH = \"..\/input\/tabular-playground-series-jan-2022\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"row_id\"\nTARGET = \"num_sold\"\nDATE = \"date\"\n\nSEED = 2022\nTEST_SIZE = 0.2\n\nNTRIALS = 500\nESR = 50 ","d491ffaf":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntrain[DATE] = pd.to_datetime(train[DATE])\ntest[DATE]  = pd.to_datetime(test[DATE])\n\ntrain['year'] = train[DATE].dt.year\ntrain['month'] = train[DATE].dt.month\ntrain['day'] = train[DATE].dt.day\ntrain['day_of_year'] = train[DATE].dt.dayofyear\ntrain['day_of_month'] = train[DATE].dt.days_in_month\ntrain['day_of_week'] = train[DATE].dt.dayofweek\ntrain['weekday'] = train[DATE].dt.weekday\n\ntest['year'] = test[DATE].dt.year\ntest['month'] = test[DATE].dt.month\ntest['day'] = test[DATE].dt.day\ntest['day_of_year'] = test[DATE].dt.dayofyear\ntest['day_of_month'] = test[DATE].dt.days_in_month\ntest['day_of_week'] = test[DATE].dt.dayofweek\ntest['weekday'] = test[DATE].dt.weekday\n\ncat_cols = train.select_dtypes('object').columns.tolist()\ntrain = pd.get_dummies(train, columns=cat_cols)\ntest  = pd.get_dummies(test, columns=cat_cols)","a61a27ef":"y = train[TARGET]\nX = train.drop(columns=[ID, DATE, TARGET])\nX_test = test.drop(columns=[ID, DATE])\n\ndef smape(actual, predicted):\n    numerator = np.abs(predicted - actual)\n    denominator = (np.abs(actual) + np.abs(predicted)) \/ 2\n    \n    return np.mean(numerator \/ denominator)*100\n\ndef objective(trial, data=X, target=y):\n    \n    X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED, shuffle=False)\n    params = {\n        'max_depth': trial.suggest_int('max_depth',1, 20),\n        'eta': trial.suggest_float('eta', 1e-5, 0.1),\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 0.9, 0.1),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.1, 0.9, 0.1),\n        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 1e5),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 1e5),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        'predictor': \"gpu_predictor\",\n        'eval_metric': 'mape'\n    }\n    \n    model = XGBRegressor(**params,\n                         tree_method='gpu_hist', \n                         booster='gbtree',\n                         random_state=SEED)\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=ESR, verbose=False)\n    preds = model.predict(X_test)\n    score = smape(y_test, preds)\n    \n    return score\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=NTRIALS)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial parameter:', study.best_trial.params)","1ef2fa02":"model = XGBRegressor(**study.best_params)\nmodel.fit(X, y,verbose=False)\npreds = model.predict(X_test)\n\nsub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = preds\nsub.to_csv(SUBMISSION_PATH, index=False)\nsub.head()","3c1820ea":"# load & preprocess","ba85f7c2":"# imports & variables","824aa755":"# build model","26f15341":"# predict & submit"}}