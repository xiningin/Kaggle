{"cell_type":{"308f7b8a":"code","bdecaeb8":"code","74d9b53c":"code","ce02b5fe":"code","49c6065d":"code","f36f1d90":"code","0717be4f":"code","eb9417ea":"code","89e98b71":"code","fe79df52":"code","c67a7bf5":"code","3bd61faa":"code","4b135da1":"code","8bc47c10":"code","661bbab4":"code","d83694c3":"code","d2dcc711":"code","c4bd8ec4":"code","53277082":"code","1263d932":"code","be1731a0":"code","aa49a54a":"code","3e59a0ed":"code","1a969c6f":"code","61bc5222":"code","ad6a0159":"code","ce5a223d":"code","ebd17809":"code","dfcd0265":"code","64a80cef":"code","8ee509f3":"code","284c9998":"code","75d2e633":"code","0d120841":"code","2f2f4f14":"code","97edf046":"code","7907a403":"code","d7adac31":"code","6383a941":"code","e008346c":"code","ead34fea":"code","ad6355f9":"code","de1b70b3":"code","70f9028d":"code","77638214":"code","07f63de3":"code","05da60a8":"code","2b7fad63":"code","34514e41":"code","df0d36ba":"code","08cbb5e6":"code","c1377118":"code","5462a37b":"code","2d318956":"code","3a6bbded":"code","2409a328":"code","ade3cf56":"code","dfdea02a":"code","4a752847":"code","f926f9d3":"code","64b2f4aa":"code","4519b620":"code","2c183232":"code","b1add5d6":"code","e74c074a":"code","87f1bf5f":"code","09e5ac4f":"code","e919d616":"code","fcea32b2":"code","eb07b065":"code","893d02ba":"code","896e0054":"code","f8c30c95":"code","b016b17c":"code","b2a28bd3":"code","d9669ad5":"markdown","a7e90796":"markdown","721a651d":"markdown","d8513cb6":"markdown","eedbb092":"markdown","6205cf99":"markdown","b56b755c":"markdown","e86b93ef":"markdown","b7b8927a":"markdown","48603713":"markdown","8b1faf26":"markdown","ca9d2bb4":"markdown","be74debe":"markdown","f429c3c1":"markdown","64375d2f":"markdown","370947e6":"markdown","9d054bd7":"markdown","6e3ecf44":"markdown","d0ccbb6c":"markdown","158057af":"markdown","91c1889c":"markdown","84f88881":"markdown","973bc855":"markdown","df89d161":"markdown","8a76abd5":"markdown","fcca6911":"markdown","a971b70a":"markdown","7ac7d0fc":"markdown","1b52fb8f":"markdown","1fd3da3f":"markdown","88b53b28":"markdown","7e7c33fa":"markdown","af9d727e":"markdown","686b7c9e":"markdown","31c8a10f":"markdown","b6f4f2d7":"markdown","aa515b42":"markdown"},"source":{"308f7b8a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport random\nimport re\nimport string\n\nimport scipy.spatial\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import ngrams\n\n\nfrom tqdm import tqdm\nfrom pprint import pprint\n\nimport sys\nimport os\nimport glob\n# Graphics in retina format are more sharp and legible\n%config InlineBackend.figure_format = 'retina'\n","bdecaeb8":"PATH = '..\/input\/good-reads-quotes'","74d9b53c":"# Here all files \nfor name in glob.glob(PATH + '\/*'):\n    print(name)","ce02b5fe":"love_quotes = ['love' , 'poetry' , 'romance' , 'relationships']\nmotivation_quotes = ['hope', 'life' , 'inspirational' , 'success']\nwisdom_quotes = ['wisdom', 'truth' , 'faith' , 'spirituality']\n","49c6065d":"PATH","f36f1d90":"pd.read_csv(PATH + '\/quotes_of_love.csv')","0717be4f":"# quotes_of_love.csv\nlove_list = []\nfor q in love_quotes:\n    path = PATH + \"\/quotes_of_\" + q + \".csv\"\n    name = \"quotes_of_\" + q\n    df = pd.read_csv(path)\n    li = df['quotes'].values\n    for row in li:\n        love_list.append(row)\n    \n\nlove_list[0]","eb9417ea":"len(love_list)","89e98b71":"# There is no none values\nNone in love_list","fe79df52":"motive_list = []\nfor q in motivation_quotes:\n    path = PATH + \"\/quotes_of_\" + q + \".csv\"\n    name = \"quotes_of_\" + q\n    df = pd.read_csv(path)\n    li = df['quotes'].values\n    for row in li:\n        motive_list.append(row)\n    \n\nmotive_list[0]","c67a7bf5":"len(motive_list)","3bd61faa":"# There is no none values\nNone in motive_list","4b135da1":"wisdom_list = []\nfor q in wisdom_quotes:\n    path = PATH + \"\/quotes_of_\" + q + \".csv\"\n    name = \"quotes_of_\" + q\n    df = pd.read_csv(path)\n    li = df['quotes'].values\n    for row in li:\n        wisdom_list.append(row)\n    \n\nwisdom_list[0]","8bc47c10":"len(wisdom_list)","661bbab4":"# There is no none values\nNone in wisdom_list","d83694c3":"quotes = love_list + motive_list + wisdom_list","d2dcc711":"len(quotes)","c4bd8ec4":"print(len(love_list) , len(motive_list), len(wisdom_list))","53277082":"labels = []\nlove = ['love' for i in range(len(love_list))]                   ## ading love label\nmotivation = ['motivation' for i in range(len(motive_list))]     ## ading motivation label\nwisdom = ['wisdom' for i in range(len(wisdom_list))]             ## ading motivation label\nlabels = love + motivation + wisdom\nlen(labels)","1263d932":"labels[0], labels[len(motive_list)+1], labels[-1]","be1731a0":"# They have the same length\nlen(quotes), len(labels)","aa49a54a":"import random\n\na = ['a', 'b', 'c']\nb = [1, 2, 3]\n\nc = list(zip(a, b))\n\nrandom.shuffle(c)\n\na, b = zip(*c)\n\nprint(a)\nprint(b)\n","3e59a0ed":"shuffled_data = list(zip(quotes, labels))\nrandom.shuffle(shuffled_data)\nquotes, labels = zip(*shuffled_data)\n","1a969c6f":"len(quotes), len(labels)","61bc5222":"print(quotes[0])\nprint(labels[0])","ad6a0159":"data = pd.DataFrame({'quotes': quotes,\n                     'class': labels})\ndata.head()","ce5a223d":"data.shape","ebd17809":"# Missing Values  -> there is no null values\ndata.isnull().sum()","dfcd0265":"data['class'].value_counts()","64a80cef":"data['class'].value_counts(normalize = True)","8ee509f3":"sns.countplot(data= data, x= 'class',\n             order = data['class'].value_counts().index);","284c9998":"# Love class\nprint('--Love class example:--\\n', data[data['class'] == 'love']['quotes'].values[0])\n\n# Motivation class\nprint('--Motivation class example:--\\n', data[data['class'] == 'motivation']['quotes'].values[0])\n\n# Wisdom class\nprint('--Wisdom class example:--\\n', data[data['class'] == 'wisdom']['quotes'].values[0])","75d2e633":"nltk.download('stopwords')","0d120841":"stop_words = stopwords.words('english')\nstemmer    = nltk.SnowballStemmer(\"english\")","2f2f4f14":"def clean_text(text):\n    '''\n        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n        and remove words containing numbers.\n    '''\n    # text = re.findall('\u201c([^\"]*)\u201d', text)[0] # extract text for quotations\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","97edf046":"def preprocess_data(text):\n    # text = remove_quotations(text)                                            # extract text for quotations\n    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n    text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n    return text","7907a403":"def remove_quotations(data):\n    res = []\n    for row in data:\n        if re.findall('\u201c([^\"]*)\u201d', row):\n            res.append(re.findall('\u201c([^\"]*)\u201d', row)[0])\n    return res","d7adac31":"data['clean_text'] = data['quotes'].apply(preprocess_data)\ndata.head()","6383a941":"data['label'] = data['class'].map({'love': 0,\n                                'motivation': 1,\n                                'wisdom': 2})\ndata.head()","e008346c":"data['text_n_chars'] = data.clean_text.apply(len) # count all chars in each sentence\ndata['text_n_words'] = data.clean_text.apply(lambda sent: len(sent.split())) # count number of words in each sentence\ndata.head()","ead34fea":"max(data['text_n_words']), min(data['text_n_words'])","ad6355f9":"data['text_n_words'].value_counts()","de1b70b3":"sns.histplot(data= data, x= 'text_n_words', hue= 'class', multiple= 'stack');","70f9028d":"data['text_n_words'] = data['text_n_words'].apply(lambda x : 100 if x > 100 else x)","77638214":"max(data['text_n_words']), min(data['text_n_words'])","07f63de3":"sns.histplot(data= data, x= 'text_n_words', hue= 'class', multiple= 'stack');","05da60a8":"from collections import Counter","2b7fad63":"def freq_words(text, c, num):\n    '''\n        take the whole data, and return data which is have # of words in each sentiment has been passed\n    '''\n    words = [word for sent in text[text['class'] == c]['clean_text'] for word in sent.split()]\n    freq_words = Counter(words)\n    freq_words_sorted = sorted(freq_words.items(), key=lambda pair: pair[1], reverse=True)\n    freq_words_df = pd.DataFrame(freq_words_sorted[:num], columns=['word', 'counts'])\n    return freq_words_df","34514e41":"def plot_freq(data, st):\n    '''\n        take the data, and st refeere to kind of sentiment\n    '''\n    plt.figure(figsize=(12, 6))\n    sns.barplot(data= data , x= 'counts', y= 'word')\n    plt.title(f'Top 20 words in {st} quotes')\n    plt.show();","df0d36ba":"love_words = freq_words(data, 'love', 20)\nlove_words.T","08cbb5e6":"plot_freq(love_words, 'love')","c1377118":"motivation_words = freq_words(data, 'motivation', 20)\nmotivation_words.T","5462a37b":"plot_freq(motivation_words, 'motivation')","2d318956":"wisdom_words = freq_words(data, 'wisdom', 20)\nwisdom_words.T","3a6bbded":"plot_freq(wisdom_words, 'wisdom')","2409a328":"def get_top_n_gram(corpus, c,  n_gram, top_n=None):\n    \n    # list of splited senteces, which is just list of words\n    text = [word for sent in corpus[corpus['class'] == c]['clean_text'] for word in sent.split()]\n\n    grams = ngrams(text, n_gram)\n    grams = (' '.join(g) for g in grams)\n    num_of_grams = [words for words in grams]\n    freq_words = Counter(num_of_grams)\n    freq_words_sorted = sorted(freq_words.items(), key=lambda pair: pair[1], reverse=True)\n    freq_words_df = pd.DataFrame(freq_words_sorted[:top_n], columns=['word', 'counts'])\n    return freq_words_df[:top_n]","ade3cf56":"love_2_gram = get_top_n_gram(data, 'love', 2, 20)\nlove_2_gram.T","dfdea02a":"plot_freq(love_2_gram, 'love')","4a752847":"motivation_2_gram = get_top_n_gram(data, 'motivation', 2, 20)\nmotivation_2_gram.T","f926f9d3":"plot_freq(love_2_gram, 'motivation')","64b2f4aa":"wisdom_2_gram = get_top_n_gram(data, 'wisdom', 2, 20)\nwisdom_2_gram.T","4519b620":"plot_freq(wisdom_2_gram, 'wisdom')","2c183232":"# getting list of love quotes\nlove_text_clean = data[data['class' ] == 'love']['clean_text']\nlove_clean_words = [word for words in love_text_clean for word in words.split()]","b1add5d6":"# getting list of motivation quotes\nmotivation_text_clean = data[data['class' ] == 'motivation']['clean_text']\nmotivation_clean_words = [word for words in motivation_text_clean for word in words.split()]\n","e74c074a":"# getting list of wisdom quotes\nwisdom_text_clean = data[data['class' ] == 'wisdom']['clean_text']\nwisdom_clean_words = [word for words in wisdom_text_clean for word in words.split()]\n","87f1bf5f":"from wordcloud import WordCloud\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(love_clean_words))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('love quotes',fontsize=40);\n\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(motivation_clean_words))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('motivation quotes',fontsize=40);\n\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(wisdom_clean_words))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('wisdom quotes',fontsize=40);","09e5ac4f":"quotes_multi_label_data = pd.read_csv(PATH + '\/popular_quotes.csv')\nquotes_multi_label_data.head()","e919d616":"print(quotes_multi_label_data['tags'][0])\nprint(type(quotes_multi_label_data['tags'][0]))\nprint(quotes_multi_label_data['tags'][0][0]) # print char instate of str as a tag word","fcea32b2":"# make a preprocessing pipeline \nquotes_multi_label_data['clean_text'] = quotes_multi_label_data['quotes'].apply(preprocess_data)\n\n# remove ' and , from the string and [] and spliting the tags\nquotes_multi_label_data['tags'] = quotes_multi_label_data['tags'].apply(lambda tags: tags.replace(\"'\",\"\").replace(\",\",\"\")[1:-1].split())\n\n# get the len of number of tags in each quote\nquotes_multi_label_data['n_tags'] = quotes_multi_label_data['tags'].apply(lambda tags: len(tags))\nquotes_multi_label_data.head()","eb07b065":"print(quotes_multi_label_data['tags'][0])\nprint(type(quotes_multi_label_data['tags'][0]))\nprint(quotes_multi_label_data['tags'][0][0]) # print char instate of str as a tag word","893d02ba":"sns.histplot(data= quotes_multi_label_data, x= 'n_tags');","896e0054":"tag_list = [word for sent in quotes_multi_label_data['tags'] for word in sent]","f8c30c95":"freq_tags = Counter(tag_list)\nfreq_tags_sorted = sorted(freq_tags.items(), key=lambda pair: pair[1], reverse=True)\nfreq_tags_df = pd.DataFrame(freq_tags_sorted[:20], columns=['word', 'counts'])\nfreq_tags_df.T","b016b17c":"plot_freq(freq_tags_df, 'Most_tags')","b2a28bd3":"wordcloud = WordCloud( background_color='white', max_words= 50).generate(\" \".join(tag_list))\nplt.title('Most tags of quotes',fontsize=30)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show();","d9669ad5":"### Two-grams for love quotes","a7e90796":"# Analyzing Text Statistics","721a651d":"### Collect quotes and labels","d8513cb6":"## Word Cloud","eedbb092":"**The distribution of number of words for each class.**","6205cf99":"## Most frequent words","b56b755c":"Here we converted the list as a string to actual list type","e86b93ef":"### Distribution on number of tags","b7b8927a":"# Working with one quote for muli-label","48603713":"### Make a wisdom class","8b1faf26":"* Class `love` -> love + poetry + romance + relationships\n* Class `motivation` -> life + inspirational + hope + success\n\n* Class `wisdom` -> truth + faith + wisdom + spirituality\n\nAnd make a multi-class classification model for this project","ca9d2bb4":"As we sow we have a lot of csv file, which is contains a quotes for exact label.\n\n\n\nWe want to make just `N-class` like sentiment, and will updata each class with some quotes which is relate to this class.","be74debe":"# Text Data Preprocessing\nWe need to pre-process the data to get it all in a consistent format.We need to clean, tokenize and convert our data into a matrix. Let's create a function which will perform the following tasks on the text columns:\n\n* Tokenizes\n* Make text lowercase\n* Removes hyperlinks\n* Remove punctuation\n* Removes numbers\n* Removes useless words \"stopwords\"\n* Stemming\/Lemmatization\n","f429c3c1":"**Convert sentiment to numerical variable**\n","64375d2f":"# Customize data","370947e6":"We will make each sent > 100 = 100 ","9d054bd7":"### Frequent words for each wisdom class","6e3ecf44":"## Distribution of top n-grams","d0ccbb6c":"### Two-grams for motivation quotes","158057af":"## Working with each quote label, one quote for one label","91c1889c":"**We can easily make tri-grams for sentiment using this function `get_top_n_gram` by passing `n_gram = 3`**","84f88881":"### Make a love class","973bc855":"**Examples of each class**","df89d161":"### Make a dataframe for exact style","8a76abd5":"We can now do some statistical analysis to explore the data like:\n\n* Text length analysis.\n    * length for whole sentence, # of each character in the sentence.\n    * count # of word in each sentence.\n* word frequency analysis","fcca6911":"### Make a motivation class","a971b70a":"# Importing libs","7ac7d0fc":"### Make a list of frequent tags","1b52fb8f":"### Frequent words for each love class","1fd3da3f":"**Make all three classes in one list**","88b53b28":"### Top most tags quotes ","7e7c33fa":"**Shuffel quotes and labes for modeling**","af9d727e":"### Frequent words for each motivation class","686b7c9e":"**What about label?**\n\n\nI can make a lable of each class, by knowing the size of each one and make a list contain all classes.\n\n","31c8a10f":"# EDA","b6f4f2d7":"**Makes a labels for each class and collect them in one list**","aa515b42":"### Two-grams for wisdom quotes"}}