{"cell_type":{"fae4a8ae":"code","d4a6de1b":"code","816bc29c":"code","50e0f816":"code","abc7396a":"code","bc50490e":"code","0fcfc8e1":"code","a7856709":"code","4394707a":"code","11a2611b":"code","c7cdb324":"code","d241a73a":"code","b8bc1162":"code","4bb6579a":"code","f7661a6f":"code","6e5d03c3":"code","f5b562e7":"code","bf8ced5a":"code","622ba335":"code","8dbfc9b3":"code","d22a3492":"code","8e922d73":"code","17ee743d":"code","3a0c8311":"code","723132f8":"code","bbdaecea":"code","18258377":"code","307fffa0":"code","8b592fd8":"code","cfa96362":"code","37e61a9c":"code","224a96ad":"code","16a91c0f":"code","4dcd20f9":"code","3cdd1729":"code","c3e03044":"code","84bb6999":"code","e1970f1e":"code","33f76dc8":"code","8f1c6427":"code","1b932a66":"code","964ecd78":"code","74383251":"code","86399628":"code","1a92f0d3":"code","c63f2e9c":"code","f189e9e2":"code","e8e3d669":"code","49d473f8":"code","65f8fb02":"code","da06d4ae":"code","900828fb":"code","a7462fcc":"code","dabc1432":"code","ab251d9c":"code","08c1f408":"code","7f4f0dd7":"code","044fe733":"code","0c6dd489":"code","2a60b4d2":"code","9a0c8e91":"code","c8cce3ae":"code","3416aadf":"code","adac46da":"code","a12dd029":"markdown"},"source":{"fae4a8ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4a6de1b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression , Ridge , LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder , PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score , mean_squared_error\nfrom scipy import stats\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom graphviz import Source\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix , classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set(style=\"darkgrid\")\n\nplt.style.use('fivethirtyeight')","816bc29c":"train = pd.read_csv(\"\/kaggle\/input\/airline-passenger-satisfaction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/airline-passenger-satisfaction\/test.csv\")","50e0f816":"train.head()","abc7396a":"train.shape\n","bc50490e":"test.shape","0fcfc8e1":"train.info()","a7856709":"train.isnull().sum()","4394707a":"test.isnull().sum()","11a2611b":"train.dropna(inplace=True)","c7cdb324":"test.dropna(inplace=True)","d241a73a":"def dropds(dset):\n    dset.drop([\"Unnamed: 0\",\"id\"],axis=1,inplace=True)\n    dset[\"Gender\"] = dset[\"Gender\"].map({\"Male\":1,\"Female\":0})\n    dset[\"Customer Type\"] = dset[\"Customer Type\"].map({\"Loyal Customer\":1,\"disloyal Customer\":0})\n    #travel_dum = pd.get_dummies(dset[[\"Type of Travel\"]],drop_first=True)\n    #class_dum = pd.get_dummies(dset[[\"Class\"]],drop_first=True)\n","b8bc1162":"dropds(train)\ndropds(test)","4bb6579a":"train.shape","f7661a6f":"test.shape","6e5d03c3":"train.head()","f5b562e7":"train.info()","bf8ced5a":"test.info()","622ba335":"travel_dum = pd.get_dummies(train[[\"Type of Travel\"]],drop_first=True)\nclass_dum = pd.get_dummies(train[[\"Class\"]],drop_first=True)\ntrain = pd.concat([train,travel_dum,class_dum],axis=1)","8dbfc9b3":"train.head()","d22a3492":"travel_dum = pd.get_dummies(test[[\"Type of Travel\"]],drop_first=True)\nclass_dum = pd.get_dummies(test[[\"Class\"]],drop_first=True)\ntest = pd.concat([test,travel_dum,class_dum],axis=1)","8e922d73":"test.head()","17ee743d":"train.drop([\"Type of Travel\",\"Class\"],axis=1,inplace=True)","3a0c8311":"test.drop([\"Type of Travel\",\"Class\"],axis=1,inplace=True)","723132f8":"train.head()","bbdaecea":"test.head()","18258377":"train[\"satisfaction\"] = train[\"satisfaction\"].map({\"satisfied\":1,\"neutral or dissatisfied\":0})\ntest[\"satisfaction\"] = test[\"satisfaction\"].map({\"satisfied\":1,\"neutral or dissatisfied\":0})","307fffa0":"train.head()","8b592fd8":"train.info()","cfa96362":"import seaborn as sns \nimport matplotlib.pyplot as plt \n","37e61a9c":"plt.figure(figsize=(20,20))\n#sns.pairplot(train)","224a96ad":"sns.countplot(x='Online boarding',hue=\"satisfaction\",data=train,color=\"green\")","16a91c0f":"sns.histplot(x='Age',hue=\"satisfaction\",data=train,kde=True,palette=\"flare\")","4dcd20f9":"sns.countplot(x='Customer Type',hue=\"satisfaction\",data=train)","3cdd1729":"sns.histplot(x='Flight Distance',hue=\"satisfaction\",data=train,kde=True,palette=\"dark\")","c3e03044":"sns.countplot(x='Inflight wifi service',hue=\"satisfaction\",data=train,color=\"red\")","84bb6999":"sns.countplot(x='Food and drink',hue=\"satisfaction\",data=train,color=\"orange\")","e1970f1e":"plt.figure(figsize = (18,18))\nsns.heatmap(train.corr(), annot = True, cmap = \"RdYlGn\")","33f76dc8":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n","8f1c6427":"x_train = train.drop([\"satisfaction\"],axis=1)\ny_train = train['satisfaction']","1b932a66":"x_test = test.drop([\"satisfaction\"],axis=1)\ny_test = test[\"satisfaction\"]\n","964ecd78":"x_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","74383251":"from xgboost import XGBClassifier\nxgb = XGBClassifier()","86399628":"xgb.fit(x_train,y_train)","1a92f0d3":"pred = xgb.predict(x_test)","c63f2e9c":"from sklearn.metrics import accuracy_score, confusion_matrix","f189e9e2":"accuracy_score(y_test,pred)","e8e3d669":"confusion_matrix(y_test,pred)","49d473f8":"from sklearn.ensemble import RandomForestClassifier\nreg_rf = RandomForestClassifier()","65f8fb02":"reg_rf.fit(x_train,y_train)\n#reg_rf.score(y_test,x_test)","da06d4ae":"rf_pred = reg_rf.predict(x_test)","900828fb":"accuracy_score(y_test,rf_pred)","a7462fcc":"train.columns","dabc1432":"train['satisfaction'].head()","ab251d9c":"X=train.drop('satisfaction', axis=1)\ny=train['satisfaction']\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","08c1f408":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    d=[acc_train, acc_test,  roc, correct, incorrect,  cm]\n    index=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\n    output=pd.DataFrame(data=d, index=index)\n    \n    d=sns.heatmap(cm, annot=True)\n    dd=plot_roc_curve(clf, X_train, y_train)\n    ddd=plot_precision_recall_curve(clf, X_train, y_train)\n\n    return output,d, dd, ddd","7f4f0dd7":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression(solver='liblinear')\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","044fe733":"# 2 Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier()\nclf_rf.fit(X_train, y_train)\n\nY_pred_rf = clf_rf.predict(X_test)\nprint(clf_scores(clf_rf, Y_pred_rf))","0c6dd489":"# 3 XGboost\nfrom sklearn.ensemble import GradientBoostingClassifier\nclf_xg = GradientBoostingClassifier()\nclf_xg.fit(X_train, y_train)\n\nY_pred_xg = clf_xg.predict(X_test)\nprint(clf_scores(clf_xg, Y_pred_xg))","2a60b4d2":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n{'n_estimators': [10, 25], 'max_features': [5, 10], \n 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n]\n\ngrid_search_forest = GridSearchCV(clf_rf, param_grid, cv=10, scoring='neg_mean_squared_error')\ngrid_search_forest.fit(X_train, y_train)","9a0c8e91":"#now let's how the RMSE changes for each parameter configuration\ncvres = grid_search_forest.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","c8cce3ae":"#find the best model of grid search\ngrid_search_forest.best_estimator_","3416aadf":"# Performance metrics\ngrid_best= grid_search_forest.best_estimator_.predict(X_train)\nerrors = abs(grid_best - y_train)\n# Calculate mean absolute percentage error (MAPE)\nmape = np.mean(100 * (errors \/ y_train))\n# Calculate and display accuracy\naccuracy = 100 - mape    \n#print result\nprint('The best model from grid-search has an accuracy of', round(accuracy, 2),'%')","adac46da":"# Tuned Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier(max_features=10, n_estimators=25)\nclf_rf.fit(X_train, y_train)\n\nY_pred_rf = clf_rf.predict(X_test)\nprint(clf_scores(clf_rf, Y_pred_rf))","a12dd029":"# Fine-tune Random Forest"}}