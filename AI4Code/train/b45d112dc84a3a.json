{"cell_type":{"b208fda7":"code","5cebcf3d":"code","51c47877":"code","71bf9c39":"code","9b63cd8c":"code","991a0852":"code","7f175ec2":"code","651b597a":"code","455ea0ab":"code","0fa343e7":"code","a070e23d":"code","b3ff36d2":"code","c2f46857":"code","831fb4a0":"code","85cb28b6":"code","6df18389":"code","220861e9":"code","87ddc249":"code","f3b9013d":"code","ff68b179":"code","156bec4d":"code","1bc565c6":"code","4aa9f40a":"code","a6737f7a":"code","4896e0d6":"code","50944f2b":"code","4ce1f5e4":"code","d1da74e9":"code","f2de59da":"code","7b408c46":"code","ad557cc2":"markdown","36703b58":"markdown","3103638b":"markdown","76dfd7f5":"markdown","66a1c89f":"markdown","27ca2036":"markdown","77d2ccff":"markdown","f9ab8b76":"markdown","a63d647e":"markdown","0fcddfc0":"markdown","0d8325da":"markdown","bfe3f415":"markdown","d93f7954":"markdown","082ec191":"markdown","2336373b":"markdown","fba8ceeb":"markdown","1ccf4f25":"markdown","eaefe30d":"markdown","1f339d2b":"markdown","4d6d6a1c":"markdown","055ad48c":"markdown","4aa568a1":"markdown"},"source":{"b208fda7":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator # for data augmentation \n\nimport matplotlib.pyplot as plt","5cebcf3d":"keras.__version__","51c47877":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)","71bf9c39":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    Image_Count = 0\n#     print(dirname)\n    \n    for file in filenames:\n        Image_Count += 1\n    \n    if Image_Count > 0:\n        print('Total Files in directory {} is {}'.format(dirname, Image_Count))","9b63cd8c":"train_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train'\nval_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation'","991a0852":"training_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n\n)","7f175ec2":"training_data = training_datagen.flow_from_directory(\n    directory = train_path,\n    target_size = (150, 150),   # Setting the size of output images to have in same size.\n    batch_size = 32,\n    class_mode = 'binary',\n    shuffle=True,\n    seed=42\n)","651b597a":"training_data.class_indices","455ea0ab":"training_data","0fa343e7":"# Doing the same for validation dataset.\n# But here we do not need to generate the images for Validation, so we just use rescale.\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nvalid_data = valid_datagen.flow_from_directory(\n    directory = val_path,\n    target_size = (150, 150),   # Setting the size of output images to have in same size.\n    batch_size = 32,\n    class_mode = 'binary'\n)","a070e23d":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1,5,figsize = (20, 20))\n    axes = axes.flatten()\n    \n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        \n    plt.tight_layout()\n    plt.show()","b3ff36d2":"images_to_show = [training_data[0][0][0] for i in range(5)] # taking 5 images.\nplotImages(images_to_show)","c2f46857":"cnn_model = keras.models.Sequential(\n    [\n        keras.layers.Conv2D(filters = 32, kernel_size = 3, input_shape = [150, 150, 3]),\n        keras.layers.MaxPooling2D(pool_size = (2,2)),\n        keras.layers.Conv2D(filters = 64, kernel_size = 3),\n        keras.layers.MaxPooling2D(pool_size = (2,2)),\n        keras.layers.Conv2D(filters = 128, kernel_size = 3),\n        keras.layers.MaxPooling2D(pool_size = (2,2)),\n        keras.layers.Conv2D(filters = 256, kernel_size = 3),\n        keras.layers.MaxPooling2D(pool_size = (2,2)),\n        \n        keras.layers.Dropout(0.5),\n        \n        # Neural Network Building\n        keras.layers.Flatten(),\n        keras.layers.Dense(units = 128, activation = 'relu'), # Input Layer\n        keras.layers.Dropout(0.1),\n        keras.layers.Dense(units = 256, activation = 'relu'), # Hidden Layer\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(units = 2, activation = 'softmax'), # Output Layer\n    ]\n)","831fb4a0":"from keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint","85cb28b6":"cnn_model.compile(\n    optimizer = Adam(lr=0.0001),\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)","6df18389":"# model_path = '\/kaggle\/input\/output\/horse_human_model.h5'  \nmodel_path = '\/kaggle\/working\/horse_human_model.h5'\n# model_path = '\/kaggle\/input\/horse_human_model.h5'\ncheckpoint = ModelCheckpoint(model_path, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\ncallbacks_list = [checkpoint]","220861e9":"history = cnn_model.fit(\n    training_data,\n    epochs = 100,\n    verbose = 1,\n    validation_data = valid_data,\n    callbacks = callbacks_list\n)","87ddc249":"# Summarize the accuracy.\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch or iteration')\nplt.legend([\"train\", 'valid'], loc = 'upper left')\nplt.show()","f3b9013d":"# Summarize the Loss\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('Model Loss')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch or iteration')\nplt.legend([\"train\", 'valid'], loc = 'upper left')\nplt.show()","ff68b179":"import numpy as np\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image","156bec4d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle'):\n    print(dirname)","1bc565c6":"model_path = '\/kaggle\/working\/horse_human_model.h5'","4aa9f40a":"trained_model = keras.models.load_model(model_path)","a6737f7a":"# Define path for Horse Image\nhorse1 = '\/kaggle\/input\/hh-test-images\/horse1.jpg'\nhorse2 = '\/kaggle\/input\/hh-test-images\/horse2.jpg'\nhorse3 = '\/kaggle\/input\/hh-test-images\/horse3.jpg'\nhorse4 = '\/kaggle\/input\/hh-test-images\/horse4.jpg'\n\n# Define path for Human Images\nhuman1 = '\/kaggle\/input\/hh-test-images\/human.jpg'\nhuman2 = '\/kaggle\/input\/hh-test-images\/human2.jpg'\nhuman3 = '\/kaggle\/input\/hh-test-images\/human3.jpg'\nhuman4 = '\/kaggle\/input\/hh-test-images\/human4.jpg'\nhuman5 = '\/kaggle\/input\/hh-test-images\/human5.jpg'\n","4896e0d6":"def pred_horse_human(model, horse_human):\n    test_image = image.load_img(horse_human, target_size = (150, 150))\n    test_image = image.img_to_array(test_image)\/255\n    test_image = np.expand_dims(test_image, axis = 0)\n    \n    result = model.predict(test_image).round(3)\n    \n    pred = np.argmax(result)\n    print(result, \"-->\", pred)\n    \n    if pred == 0:\n        print(\"Predicted as a HORSE\")\n    else:\n        print(\"Predicted as a HUMAN\")\n        ","50944f2b":"for horse_human in [horse1, horse2, horse3, horse4, human1, human2, human3, human4, human5]:\n    pred_horse_human(trained_model, horse_human)","4ce1f5e4":"import cv2","d1da74e9":"def pred_horse_human_image(model, horse_human):\n    test_image = image.load_img(horse_human, target_size = (150, 150))\n    test_image = image.img_to_array(test_image)\/255\n    test_image = np.expand_dims(test_image, axis = 0)\n    \n    result = model.predict(test_image).round(3)\n    \n    pred = np.argmax(result)\n#     print(result, \"-->\", pred)\n    \n    if pred == 0:\n        prediction = \"HORSE\"\n    else:\n        prediction = \"HUMAN\"\n\n    img_array = cv2.imread(horse_human, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(img_array, cmap = 'gray')\n    \n    plt.axis('off')\n    plt.title(\"PREDICTED AS : \" + prediction)\n    \n    plt.show()","f2de59da":"pred_horse_human_image(trained_model, horse1)","7b408c46":"for horse_human in [horse1, horse2, horse3, horse4, human1, human2, human3, human4, human5]:\n    pred_horse_human_image(trained_model, horse_human)","ad557cc2":"We have captured all details like accuracy of train and validation dataset.\n\nSimilarly we do have Loss for both training and validation dataset.\nSo lets visualize it by plotting it.","36703b58":"# Buidling CNN Model","3103638b":"# Load Data","76dfd7f5":"# Visualization","66a1c89f":"# Test images from outside","27ca2036":"Considering that we are doing this testing out somewhere. \nSo will first load required library.","77d2ccff":"Lets modify the function to include image as well.","f9ab8b76":"Now its time to generate the training images.. so will pass the directory path itself to our function, and in return we will get the images with different angle of single image.\n\nNote : Source images are of diffeent size.. where we we want the result or output to be in same size for that will provide target_size.\n\nflow_from_directory() expects at least one directory under the given directory path.","a63d647e":"Keras Preprocessing is the data preprocessing and data augmentation module of the Keras deep learning library. It provides utilities for working with image data, text data, and sequence data.\n\nImage data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n\nThe Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ImageDataGenerator class.\n\nRefer site for more details : https:\/\/www.pyimagesearch.com\/2019\/07\/08\/keras-imagedatagenerator-and-data-augmentation\/\n\n","0fcddfc0":"Here we see the same image but with different variations in it.","0d8325da":"For Training : Here we have 500 Horse images and 527 Human (Including Mal and Female) images.\n\nFor validation : we have 128 Horse images and 128 Human images.\n\nProblem Statement : Classify given image as Horse or Human.\n\nSolution : To solve this problem we are going to use Deep Learning Algorithm that is CNN.","bfe3f415":"# Predict the Output","d93f7954":"So now the training_data is generated... \nWe can check the count of images found at given path.. as we already defined.. we have 500 images of Horse + 527 images of Human, which is 1027 total images.\n\nThe good thing is Keras itself set the class index for us, and this we can validate using `class_indices`.","082ec191":"# Import Libraries","2336373b":"# Compile Model","fba8ceeb":"# Load or import the Model.","1ccf4f25":"For Validation Dataset...\n* `class_mode`: Set this to None, to return only the images.\n* `shuffle`: Set this to False, because you need to yield the images in \u201corder\u201d, to predict the outputs and match them with their unique ids or filenames.","eaefe30d":"Here we defined our Image Data Generator function with some parameters.\n\n* The `directory` must be set to the path where your \u2018n\u2019 classes of folders are present.\n* The `target_size` is the size of your input images, every image will be resized to this size.\n* `color_mode`: if the image is either black and white or grayscale set \u201cgrayscale\u201d or if the image has three color channels, set \u201crgb\u201d.\n* `batch_size`: No. of images to be yielded from the generator per batch.\n* `class_mode`: Set \u201cbinary\u201d if you have only two classes to predict, if not set to\u201ccategorical\u201d, in case if you\u2019re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to \u201cinput\u201d.\n* `shuffle`: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n* `seed`: Random seed for applying random image augmentation and shuffling the order of the image.","1f339d2b":"# Data Processing","4d6d6a1c":"# Plot the Images","055ad48c":"# Horse or Human Image Classification using Keras and CNN.\nThis is a dataset from https:\/\/www.kaggle.com\/sanikamal\/horses-or-humans-dataset","4aa568a1":"# Load Test images"}}