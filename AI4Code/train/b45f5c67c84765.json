{"cell_type":{"1171329b":"code","6032e3de":"code","006f30e2":"code","aae3b66c":"code","09052236":"code","09d449b4":"code","8c714358":"code","283e681b":"code","000a89c0":"code","18b0d1e8":"code","a73541d1":"code","2ba118d1":"code","d66ce2c0":"code","7c2b005d":"code","f953b806":"code","e653d2ea":"code","23506ae0":"code","f74efde2":"code","62daa99c":"code","2911280f":"code","39f1aa5f":"code","ed50a727":"code","dfe8f5bf":"code","7445e1fe":"code","20954074":"code","de52bb55":"code","745b69ad":"code","3648c6e4":"code","2ae791d1":"code","409a73cb":"code","c550291f":"code","b15f07f9":"code","a46c34fa":"code","95680e41":"code","d874a8c1":"code","906741ad":"code","cdc45376":"code","35070669":"code","06702271":"code","222209d4":"code","dd38f56b":"code","127688be":"code","2f945876":"code","79774770":"code","c866ee31":"code","60d23828":"code","be2175e3":"code","c59deed5":"code","26847df9":"code","40a138c3":"code","57e49c4f":"code","f987af22":"code","de794d50":"code","8051dfb7":"code","762aabcd":"code","653aca53":"code","dfd7172d":"code","81d84eed":"code","5747edbf":"code","336c6c18":"code","4f97159f":"code","62801bb0":"code","d346c0c0":"code","f9bcdfa5":"code","eff84e4e":"code","dac3dd3e":"code","ee878795":"code","2b2a3402":"code","cac2a816":"code","ebe0f343":"code","cb1c2468":"code","1553c8ac":"code","f39c9684":"code","1435f8c2":"code","876dfae5":"code","0265d922":"code","20c7b9cb":"code","64924f59":"code","ff824523":"code","f1acc7da":"code","4911921a":"code","0d10d674":"code","6627eba0":"code","7370a357":"code","87a0fead":"code","ebcc64f9":"code","38a9d5c3":"code","1391cc0a":"code","f998b54f":"code","6c144e5c":"code","85b6c0ae":"code","f95c8c6d":"code","d23384b5":"code","b864a95e":"code","0afdb4f5":"code","04da3244":"code","f89d2941":"code","3f9c8aba":"code","3dd37c38":"code","0586481c":"code","eeb60282":"markdown","e1e066db":"markdown","183cef65":"markdown","9f6f3ea4":"markdown","5f6cbede":"markdown","5a673ce1":"markdown","43963b1f":"markdown","650a748b":"markdown","79ab0fb2":"markdown","fa35c5e3":"markdown","41591ae2":"markdown","5371d05a":"markdown","a84081fd":"markdown","ccfd7cff":"markdown","a0e2a24d":"markdown","8ab0c383":"markdown","3f887b77":"markdown","3334d9d7":"markdown","9de4a5d1":"markdown","ad208c81":"markdown","5c4c8ec0":"markdown","e083d9db":"markdown","43fd2522":"markdown","eafe18dd":"markdown","05de2b9e":"markdown","47296f8b":"markdown","cf5b0cf4":"markdown","48f0c34a":"markdown"},"source":{"1171329b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ncolor = sns.color_palette()\nimport warnings\nwarnings.filterwarnings('ignore')\n# Garbage Collector to free up memory\nimport gc                         \ngc.enable()   \n","6032e3de":"# Load the datasets\norders = pd.read_csv('..\/input\/dataset\/orders.csv' )\norder_products_train = pd.read_csv('..\/input\/dataset\/order_products__train.csv')\norder_products_prior = pd.read_csv('..\/input\/dataset\/order_products__prior.csv')\nproducts = pd.read_csv('..\/input\/dataset\/products.csv')\naisles = pd.read_csv('..\/input\/dataset\/aisles.csv')\ndepartments = pd.read_csv('..\/input\/dataset\/departments.csv')","006f30e2":"# Get heads for the orders dataset\norders.head()","aae3b66c":"# Get shape of orders dataset\norders.shape","09052236":"# Get a brief descriptive info on orders\norders.info()","09d449b4":"# Get missing values in orders dataset\norders.isnull().sum()","8c714358":"# Get heads for the order_products_train dataset\norder_products_train.head()","283e681b":"# Get shape of order_products_train dataset\norder_products_train.shape","000a89c0":"# Get missing values in order_products_train dataset\norder_products_train.isnull().sum()","18b0d1e8":"# Get head for order_products_prior\norder_products_prior.head()","a73541d1":"# Get shape for order_products_prior\norder_products_prior.shape","2ba118d1":"# Get missing value for order_products_prior\norder_products_prior.isnull().sum()","d66ce2c0":"# Get heads for the products dataset\nproducts.head()","7c2b005d":"#  Get shape for products\nproducts.shape","f953b806":"# Get missing value for products\nproducts.isnull().sum()","e653d2ea":"# Get head for aisles\naisles.head()","23506ae0":"# Get shape for aisles\naisles.shape","f74efde2":"# Check missing values in aisle\naisles.isnull().sum()","62daa99c":"# Get head for departments\ndepartments.head()","2911280f":"# Get shape for departments\ndepartments.shape","39f1aa5f":"# Check missing values in departments\ndepartments.isnull().sum()","ed50a727":"# Get the number of orders in each days of a week\nplt.figure(figsize=(6,4))\nsns.countplot(x=\"order_dow\", data=orders, color=color[0])\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Day of week', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Orders by week day\", fontsize=15)\nplt.show()","dfe8f5bf":"# Get the number of orders for each hour in a day\nplt.figure(figsize=(6,4))\nsns.countplot(x=\"order_hour_of_day\", data=orders, color=color[0])\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Hour of day', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Orders by Hour of day\", fontsize=15)\nplt.show()","7445e1fe":"# Analyse how people orders a new one since last order\nplt.figure(figsize=(10,6))\nsns.countplot(orders['days_since_prior_order'])\nplt.xticks(rotation=90)\nplt.show()","20954074":"# Merge products and departments dataframes and then merging with aisles\nproducts_details = pd.merge(left=products,right=departments,how=\"left\")\nproducts_details = pd.merge(left=products_details,right=aisles,how=\"left\")\nproducts_details.head()","de52bb55":"# Get the number of products in each department\nplt.figure(figsize=(10,6))\ng=sns.countplot(x=\"department\",data=products_details)\ng.set_xticklabels(g.get_xticklabels(), rotation=40, ha=\"right\")\nplt.show()","745b69ad":"# Get top 10 aisle with most number of products\nplt.figure(figsize=(10,6))\ntop10_aisle=products_details[\"aisle\"].value_counts()[:10].plot(kind=\"bar\",title='Aisles')","3648c6e4":"# Merge order_products_train and products dataframes\norder_products_name_train = pd.merge(left=order_products_train,right=products.loc[:,[\"product_id\",\"product_name\"]],on=\"product_id\",how=\"left\")","2ae791d1":"# Get the top 10 common products which are most bought by the customers\ncommon_Products=order_products_name_train[order_products_name_train.reordered == 1][\"product_name\"].value_counts().to_frame().reset_index()\nplt.figure(figsize=(12,7))\nplt.xticks(rotation=90)\nsns.barplot(x=\"product_name\", y=\"index\", data=common_Products.head(10))\nplt.ylabel('product_name', fontsize=12)\nplt.xlabel('count', fontsize=12)\nplt.show()","409a73cb":"# Merge order_products_name_train and products_details dataframes\norder_products_name_train = pd.merge(left=order_products_name_train,right=products_details.loc[:,[\"product_id\",\"aisle\",\"department\"]],on=\"product_id\",how=\"left\")","c550291f":"#  Get the aisles which have most number of sales\ncommon_aisle=order_products_name_train[\"aisle\"].value_counts().to_frame().reset_index()\nplt.figure(figsize=(12,7))\nplt.xticks(rotation=90)\nsns.barplot(x=\"aisle\", y=\"index\", data=common_aisle.head(10),palette=\"Blues_d\")\nplt.ylabel('aisle', fontsize=12)\nplt.xlabel('count', fontsize=12)\nplt.show()","b15f07f9":"#  Get the departments which have most number of sales\ncommon_aisle=order_products_name_train[\"department\"].value_counts().to_frame().reset_index()\nplt.figure(figsize=(12,7))\nplt.xticks(rotation=90)\nsns.barplot(x=\"department\", y=\"index\", data=common_aisle,palette=\"Blues_d\")\nplt.ylabel('department', fontsize=12)\nplt.xlabel('count', fontsize=12)\nplt.show()\n","a46c34fa":"# Get the products which were reordered in each order from the train data.\ntrain_data_reordered = order_products_train.groupby([\"order_id\",\"reordered\"])[\"product_id\"].apply(list).reset_index()\ntrain_data_reordered = train_data_reordered[train_data_reordered.reordered == 1].drop(columns=[\"reordered\"]).reset_index(drop=True)\ntrain_data_reordered.head()","95680e41":"# Delete all unnncessary dataframes\ndel products_details\ndel order_products_name_train\ndel common_Products\ndel common_aisle\ndel train_data_reordered\ngc.collect()","d874a8c1":"# Get 15% of users as it is a huge dataset and will take lots of time to train.\norders = orders.loc[orders.user_id.isin(orders.user_id.drop_duplicates().sample(frac=0.15, random_state=101))] ","906741ad":"# Convert character variables into category. \naisles['aisle'] = aisles['aisle'].astype('category')\ndepartments['department'] = departments['department'].astype('category')\norders['eval_set'] = orders['eval_set'].astype('category')\nproducts['product_name'] = products['product_name'].astype('category')","cdc45376":"# Merge orders and order_products_prior datasets to get prior order dataset\nprior_orders = pd.merge(orders, order_products_prior, on='order_id', how='inner')\nprior_orders.head()","35070669":"# Create a feature based on number of orders placed by each user.\nusers = prior_orders.groupby(by='user_id')['order_number'].aggregate('max').to_frame('num_of_orders_for_each_user').reset_index()\nusers.head()","06702271":"# Get average number of products in  each orders placed by each users.\n\n# Get the total number of products in each order.\ntoal_product_per_order = prior_orders.groupby(by=['user_id', 'order_id'])['product_id'].aggregate('count').to_frame('total_products_per_order').reset_index()\n\n# Create a dataframe to get the average number of products purchased in  each orders by each user\navg_number_of_products_per_order = toal_product_per_order.groupby(by=['user_id'])['total_products_per_order'].mean().to_frame('avg_no_prd_per_order').reset_index()\n\n# Delete unnecessay the toal_product_per_order dataframe\ndel [toal_product_per_order]\ngc.collect()\n\n#  Get head of avg_number_of_products_per_order\navg_number_of_products_per_order.head()","222209d4":"# Importing the scipy's stats model\nfrom scipy import stats\n\n# Create a dataframe for the day of the week where users orders most\norder_most_dow = prior_orders.groupby(by=['user_id'])['order_dow'].aggregate(lambda x : stats.mode(x)[0]).to_frame('dow_with_most_orders').reset_index()\n\n# Get head of the dataset\norder_most_dow.head()","dd38f56b":"#Create a dataframe for hour of day where users has ordered most.\norder_most_hod = prior_orders.groupby(by=['user_id'])['order_hour_of_day'].aggregate(lambda x : stats.mode(x)[0]).to_frame('hod_with_most_orders').reset_index()\norder_most_hod.head()","127688be":"#Get a dataframe for reorder ratio of each user and set data type as float\nuser_reorder_ratio = prior_orders.groupby(by='user_id')['reordered'].aggregate('mean').to_frame('reorder_ratio').reset_index()\nuser_reorder_ratio['reorder_ratio'] = user_reorder_ratio['reorder_ratio'].astype(np.float16)\nuser_reorder_ratio.head()","2f945876":"# Merging all the created user based features into the users dataset one by one.\nusers = users.merge(avg_number_of_products_per_order, on='user_id', how='left')\nusers = users.merge(order_most_dow, on='user_id', how='left')\nusers = users.merge(order_most_hod, on='user_id', how='left')\nusers = users.merge(user_reorder_ratio, on='user_id', how='left')\n\nusers.head()","79774770":"# Delete unnecessay dataframes\ndel [avg_number_of_products_per_order,order_most_dow,order_most_hod,user_reorder_ratio]\ngc.collect()","c866ee31":"#Get a dataframe to show the number of times a product has been purchased.\npurchased_num_of_times = prior_orders.groupby(by='product_id')['order_id'].aggregate('count').to_frame('purchased_num_of_times').reset_index()\npurchased_num_of_times.head()\n","60d23828":"#Get a dataframe for the reordered ratio for each product\nproduct_reorder_ratio = prior_orders.groupby(by='product_id')['reordered'].aggregate('mean').to_frame('product_reorder_ratio').reset_index()\nproduct_reorder_ratio.head()","be2175e3":"#Get a dataframe for avearage number of adding to cart for each product.\nadd_to_cart = prior_orders.groupby(by='product_id')['add_to_cart_order'].aggregate('mean').to_frame('product_avg_cart_addition').reset_index()\nadd_to_cart.head()","c59deed5":"# Merge all the created features based on product_id into the purchased_num_of_times dataset.\npurchased_num_of_times = purchased_num_of_times.merge(product_reorder_ratio, on='product_id', how='left')\npurchased_num_of_times = purchased_num_of_times.merge(add_to_cart, on='product_id', how='left')\n\n#Delete unwanted dataframes.\ndel [product_reorder_ratio, add_to_cart]\ngc.collect()","26847df9":"# Get head of purchased_num_of_times\npurchased_num_of_times.head()","40a138c3":"#Create a user_product dataframe which shows the number of times a user have bough a product.\nuser_product_data = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('uxp_times_bought').reset_index()\nuser_product_data.head()","57e49c4f":"#Create a dataframe  to find a product's order number when the user has bought a product for the first time.\nproduct_first_order_num = prior_orders.groupby(by=['user_id', 'product_id'])['order_number'].aggregate('min').to_frame('first_order_number').reset_index()\nproduct_first_order_num.head()","f987af22":"#Get total number of orders by each user\ntotal_orders = prior_orders.groupby('user_id')['order_number'].max().to_frame('total_orders').reset_index()\ntotal_orders.head()","de794d50":"# Merge total_orders and user_product_data dataframes to create a new dataframe user_product_df\nuser_product_df = pd.merge(total_orders, product_first_order_num, on='user_id', how='right')\nuser_product_df.head()","8051dfb7":"# Calculate the order range.\n# The +1 includes in the difference is the first order where the product has been purchased\nuser_product_df['order_range'] = user_product_df['total_orders'] - user_product_df['first_order_number'] + 1\nuser_product_df.head()","762aabcd":"#Create  a dataframe to show the number of times a user have bough a product.\nnumber_of_times = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('times_bought').reset_index()\nnumber_of_times.head()","653aca53":"# Merging number_of_times with user_product_df\nuxp_ratio = pd.merge(number_of_times, user_product_df, on=['user_id', 'product_id'], how='left')\nuxp_ratio.head()","dfd7172d":"# Get a dataframe to calculate the reorder ratio for each product\nuxp_ratio['uxp_reorder_ratio'] = uxp_ratio['times_bought'] \/ uxp_ratio['order_range']\nuxp_ratio.head()","81d84eed":"#Drop all the unnecessary columns from uxp_ratio dataframe .\nuxp_ratio.drop(['times_bought', 'total_orders', 'first_order_number', 'order_range'], axis=1, inplace=True)\nuxp_ratio.head()","5747edbf":"#Merge uxp_ratio with user_product_data.\nuser_product_data = user_product_data.merge(uxp_ratio, on=['user_id', 'product_id'], how='left')\n\n# Delete all unnecessay datasets\ndel [product_first_order_num, number_of_times,user_product_df,total_orders, uxp_ratio]\ngc.collect()","336c6c18":"# Get head for user_product_data\nuser_product_data.head()","4f97159f":"#Create a column order_number_back to reverse the order number for each product in prior_orders dataframe\nprior_orders['order_number_back'] = prior_orders.groupby(by=['user_id'])['order_number'].transform(max) - prior_orders.order_number + 1\nprior_orders.head()","62801bb0":"#Update the dataframe to keep only the first 3 orders from the order_number_back.\ntemp_df = prior_orders.loc[prior_orders.order_number_back <= 3]\ntemp_df.head()","d346c0c0":"#Get the products bought by users in the last 3 orders.\nlast_three_order = temp_df.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('uxp_last_three').reset_index()\nlast_three_order.head()","f9bcdfa5":"#Get the ratio of the products bought in the last 3 orders.\nlast_three_order['uxp_ratio_last_three'] = last_three_order['uxp_last_three'] \/ 3\nlast_three_order.head()","eff84e4e":"#Merge last_three_order with feature with uxp df.\nuser_product_data = user_product_data.merge(last_three_order, on=['user_id', 'product_id'], how='left')\n\n# Delete unwanted dataframes\ndel [last_three_order, temp_df]\ngc.collect()\n","dac3dd3e":"# Get the head of updated dataframe user_product_data.head()\nuser_product_data.head().head()","ee878795":"# Check any missing values in user_product_data columns\nuser_product_data.isnull().sum()","2b2a3402":"#Fill the NAN values with 0 in user_product_data.\nuser_product_data.fillna(0, inplace=True)","cac2a816":"# Confirm filling of missing values in user_product_data columns\nuser_product_data.isnull().sum()","ebe0f343":"#  Merge user_product_data and users, then resulting dataframe with purchased_num_of_times to get featured_engineered_data dataset\nfeatured_engineered_data = user_product_data.merge(users, on='user_id', how='left')\nfeatured_engineered_data = featured_engineered_data.merge(purchased_num_of_times, on='product_id', how='left')\n\n# Delete unncessary dataframes.\ndel [users, user_product_data, purchased_num_of_times]\ngc.collect()\n\n# Get head of featured_engineered_data\nfeatured_engineered_data.head()","cb1c2468":"# Check if any missing values found in featured_engineered_data dataframe columns\nfeatured_engineered_data.isnull().sum()","1553c8ac":"# Keep only the future orders from all customers i.e. train  and test orders\norders_future = orders[((orders.eval_set=='train') | (orders.eval_set=='test'))]\norders_future = orders_future[['user_id', 'eval_set', 'order_id']]","f39c9684":"# merge the orders_future with featured_engineered_data to create a final dataframe.\nfinal_data = featured_engineered_data.merge(orders_future, on='user_id', how='left')\nfinal_data.head()","1435f8c2":"#Create training data set.\ntrain_data = final_data[final_data.eval_set=='train']\ntrain_data.head()","876dfae5":"#Merge order_products__train  with into train_data datframe.\ntrain_data = train_data.merge(order_products_train[['product_id', 'order_id', 'reordered']], on=['product_id', 'order_id'], how='left')\ntrain_data.head()","0265d922":"# Check if any missing values found in train_data dataframe columns\ntrain_data.isnull().sum()","20c7b9cb":"# Fill the missing values in reordered column with 0\ntrain_data['reordered'] = train_data['reordered'].fillna(0)\ntrain_data.head()","64924f59":"# Set user_id and product_id as the index of the train_data\ntrain_data = train_data.set_index(['user_id', 'product_id'])","ff824523":"# Drop unwanted columns from train_data dataframe\ntrain_data = train_data.drop(['eval_set', 'order_id'], axis=1)","f1acc7da":"# Get head of train_data\ntrain_data.head()","4911921a":"#Keep only the future orders labelled as test\ntest_data = final_data[final_data.eval_set=='test']\ntest_data.head()","0d10d674":"# Set user_id and product_id as the index of the train_data\ntest_data = test_data.set_index(['user_id', 'product_id'])\n\n# Drop unwanted columns from train_data dataframe\ntest_data = test_data.drop(['eval_set', 'order_id'], axis=1)\n\n# Get head of test_data \ntest_data.head()","6627eba0":"#Delete unnecessay dataframes\ndel [final_data, orders_future, products, order_products_train]\ngc.collect()","7370a357":"# Import libraries\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n# Define X_train and y_train\nX_train, y_train = train_data.drop('reordered', axis=1), train_data.reordered\n\n# Set boosting parameters\nparameters = {\"max_depth\":[5,8,10],\n            \"colsample_bytree\":[0.3, 0.4]}\n\n#  Fit the model after tuning with GridSearchCV\nxgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', num_boost_round=10)\ngridsearch = GridSearchCV(xgb_classifier, parameters, cv=5, verbose=2, n_jobs=-1)\nxgb_model = gridsearch.fit(X_train, y_train)","87a0fead":"# Get optimal model\nxgb_optimal_model = gridsearch.best_estimator_","ebcc64f9":"# Get best params\nxgb_optimal_model.get_params()","38a9d5c3":"# Get feature importance\nxgb.plot_importance(xgb_optimal_model)","1391cc0a":"# Get model predictions with threshold of 0.21 probability\ntest_prediction = (xgb_optimal_model.predict_proba(test_data)[:, 1] >= 0.21).astype(int)\ntest_prediction[:5]","f998b54f":"# Get model predictions on train set with threshold of 0.21 probability\ntrain_prediction = (xgb_optimal_model.predict_proba(X_train)[:, 1] >= 0.21).astype(int)\ntrain_prediction[:5]","6c144e5c":"# Import evaluation matrices\nfrom sklearn.metrics import f1_score, classification_report","85b6c0ae":"# Get f1 score and classification report\nprint(f'f1 Score: {f1_score(train_prediction, y_train)}')\nprint(classification_report(train_prediction, y_train))\n","f95c8c6d":"#Create the prediction as a new column in test_data\ntest_data['prediction'] = test_prediction\ntest_data.head()","d23384b5":"# Reset the index and create a dataset called final_df\nfinal_df = test_data.reset_index()\n\n# Keeping only the required columns to create  submission file\nfinal_df = final_df[['product_id', 'user_id', 'prediction']]\n\n# Collect garbage and show head of final_df\ngc.collect()\nfinal_df.head()","b864a95e":"#Create  a new dataframe orders_test \norders_test = orders.loc[orders.eval_set == 'test', ['user_id', 'order_id']]\norders_test.head()","0afdb4f5":"#Merge  final_df with orders_test daatframe\nfinal_df = final_df.merge(orders_test, on='user_id', how='left')\nfinal_df.head()","04da3244":"# Remove user_id column and convert product_id as integer\nfinal_df = final_df.drop('user_id', axis=1)\nfinal_df['product_id'] = final_df.product_id.astype(int)\nfinal_df.head()","f89d2941":"# Create a dictionary to store product IDs whose reordered prediction value is 1\nfinal_dict = dict()\nfor row in final_df.itertuples():\n    if row.prediction== 1:\n        try:\n            final_dict[row.order_id] += ' ' + str(row.product_id)\n        except:\n            final_dict[row.order_id] = str(row.product_id)\n\n# Update products whose reorder prediction value is 0 as None          \nfor order in final_df.order_id:\n    if order not in final_dict:\n        final_dict[order] = 'None'\n \n# Collect garbage\ngc.collect()","3f9c8aba":"# Convert the final_dict dictionary into a final submission dataframe called submission_df\nsubmission_df = pd.DataFrame.from_dict(final_dict, orient='index')\n\n# Reset index\nsubmission_df.reset_index(inplace=True)\n\n#Set column names\nsubmission_df.columns = ['order_id', 'products']\n\n# Get head\nsubmission_df.head()","3dd37c38":"# Create the final submission file\nsubmission_df.to_csv('sub.csv', index=False, header=True)","0586481c":"submission_df.shape","eeb60282":"# **Load the datasets**","e1e066db":"produce and dairy eggs are the top 2 departments with the highest number of sales.","183cef65":"### Create final dataframe for engineered features","9f6f3ea4":"missing is the aisle with most products available.","5f6cbede":"### Create features using product_id.","5a673ce1":"**Inspecting order_products_train dataset**","43963b1f":"Banana is the most common type of product bought by people followed by Bag of organic banana. ","650a748b":"### Create training dataset","79ab0fb2":"The number of orders on weekends is more compared to weekdays as people stay at home and might have wanted to enjoy the foods.","fa35c5e3":"**Inspecting orders dataset**","41591ae2":"## Creating submission file","5371d05a":"### XGBoost Model","a84081fd":"Fresh vegetable aisle has the highest number of sales followed by fresh_fruits.","ccfd7cff":"**Inspect products dataset**","a0e2a24d":"# **EDA**","8ab0c383":"### Creating features using user_id and product_id","3f887b77":"**Inspecting departments dataset**","3334d9d7":"**Inspecting order_products_prior dataset**","9de4a5d1":"## Building model using XGBoost and LGB","ad208c81":"# **Feature Engineering**","5c4c8ec0":"### Create testing dataset","e083d9db":"We have observed that there are 206209 missing values in days_since_prior_order column.","43fd2522":"**Inspecting aisles dataset**","eafe18dd":"Maximum number of users order again after 1 month. People also order after a week and this forms the second largest order habit.","05de2b9e":"Peak hours wheremaximum orders are done is between 9 AM- 5PM. Less orders are placed before 7AM and after 11 PM.","47296f8b":"## Creating Train and Test datasets","cf5b0cf4":"Personal care is the most abundant type of department available followed by snacks.","48f0c34a":"### Create Features using user_id"}}