{"cell_type":{"cbd282f4":"code","4c5f80f6":"code","9a3efa31":"code","19eab138":"code","bab83062":"code","d30c4b6d":"code","152e6805":"code","fe63f340":"code","bcb9b091":"code","aa678fbe":"code","527d6d2c":"code","6585bb51":"code","b15e3e69":"code","d3b767f7":"code","cfc0d63f":"markdown","b8000138":"markdown","77fb75a2":"markdown","6367faa7":"markdown","2b0f7f29":"markdown","79679cec":"markdown","37a51bb8":"markdown","5bde512e":"markdown","dda8e2eb":"markdown"},"source":{"cbd282f4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline ","4c5f80f6":"train_data = pd.read_csv('..\/input\/landmark-retrieval-2020\/train.csv')\nprint(\"Size of training data:\", train_data.shape)\ntrain_data.head()","9a3efa31":"print(\"Number of unique landmark ids:\", len(train_data['landmark_id'].unique()))","19eab138":"# Looking for missing data\n\ntrain_data.isnull().sum()","bab83062":"# Mostly recorded landmarks\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id','count']\n\n# Plot the most frequent landmark_ids\nplt.figure(figsize = (9, 8))\nplt.title('Most frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","d30c4b6d":"# Class distribution\nplt.figure(figsize = (10, 8))\nplt.title('Category Distribuition')\nsns.distplot(train_data['landmark_id'])\n\nplt.show()","152e6805":"print(\"Number of classes under 20 occurences\",(train_data['landmark_id'].value_counts() <= 20).sum(),'out of total number of categories',len(train_data['landmark_id'].unique()))","fe63f340":"def visualize_landmark(landmark_id=0):\n\n    # Filtering the dataframe for most repeated landmark\n    plotting_data = train_data[train_data['landmark_id']==train_data.landmark_id.value_counts().head(10).index[landmark_id]].reset_index()\n    number_of_subplots = 3\n    fig, axs = plt.subplots(number_of_subplots,figsize=(20,20))\n    for i in range(number_of_subplots):\n\n        # Creating file path\n        image_name = plotting_data['id'][i] + '.jpg'\n        first_initial, second_initial, third_initial = image_name[0]+'\/', image_name[1]+'\/', image_name[2]+'\/'\n        image_path = \"..\/input\/landmark-retrieval-2020\/train\/\"+ first_initial + second_initial + third_initial + image_name\n\n        # Displaying the image\n        img = plt.imread(image_path)\n        axs[i].imshow(img)","bcb9b091":"visualize_landmark(0)","aa678fbe":"visualize_landmark(7)","527d6d2c":"df = train_data.copy()","6585bb51":"# How many unique landmarks are there?\ngroups=df.groupby('landmark_id')['id'].nunique()\ngroups.sort_values()","b15e3e69":"# # Make a sample of everything under 22 images\n# under22=df.groupby('landmark_id')['id'].nunique()\n# under22=under22.where(under22 < 22)\n# under22=under22.dropna(how='any')\n# under22=under22.index.tolist()\n\n# # Change them into landmark id 99999999\n# changed=df.replace([under22],99999999)\n\n# # save this\n# changed.to_csv(\"under22.csv\", encoding='utf-8',index=False)","d3b767f7":"# Get the top X categories\nlst = df.groupby('landmark_id')['id'].nunique()\n\n# Get the X largest categories\ncategories = 20000\ntop = lst.nlargest(categories)\n\n# Create df subset\nsamplelocations = list(top.index.values)\n\n#Receive files for subset\ndfsubset=df[df['landmark_id'].isin(samplelocations)]\n\n#Make Top 10\n#dfsubset.to_csv(\"\/home\/jd\/data\/google\/256\/t10labels.csv\", encoding='utf-8',index=False)\ndfsubset.to_csv(\"t20000labels.csv\", encoding='utf-8',index=False)","cfc0d63f":"Visualizing the images of the most observed landmarks id in the training data","b8000138":"There are 81313 unique landmark ids and many of them do not have a lot of images. It is better to falsely label these images rather than taking it into account in the assumption that the test set has these images in low numbers.","77fb75a2":"Visualizing another landmark id that is lower on the top 10 list.","6367faa7":"# Image visualization","2b0f7f29":"I will be performing exploratory data analysis on the landmark training data in hopes of finding something useful for training a model later on. I have used this notebook as a starting reference: \n\n- https:\/\/www.kaggle.com\/codename007\/a-very-extensive-landmark-exploratory-analysis\n- https:\/\/github.com\/jamesdietle\/Kaggle2019\/blob\/master\/GoogleLandmarkRecognition\/GoogleLandmarkRecognition.ipynb","79679cec":"These landmarks look like castles.","37a51bb8":"All of these seem to be random landmarks therefore they may be in huge numbers in the dataset.\n","5bde512e":"# Data Pre-processing","dda8e2eb":"### Creating subset of top 20000 categories"}}