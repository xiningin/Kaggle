{"cell_type":{"62317e2d":"code","b72bf47f":"code","64d43b59":"code","1dec28a9":"code","53129484":"code","53d55b35":"code","ddecd48a":"code","4553764c":"code","1c2d1917":"code","52a2cf06":"code","3e41d8bc":"code","03889083":"markdown"},"source":{"62317e2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b72bf47f":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings('ignore')","64d43b59":"'''train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\nsubmission = pd.read_csv('submission.csv')'''\n\ntrain = pd.read_csv('\/kaggle\/input\/mh-work-hour-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/mh-work-hour-prediction\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/mh-work-hour-prediction\/submission.csv')","1dec28a9":"print(train.columns.difference(test.columns), train.columns.intersection(submission.columns))\ntgt_var = submission.columns\nprint(tgt_var)","53129484":"print(\"Train:\",train.isna().sum()[train.isna().sum().values>0], \"\\nTest:\",test.isna().sum()[test.isna().sum().values>0])","53d55b35":"train.duplicated().sum(), test.duplicated().sum()","ddecd48a":"train.columns","4553764c":"train.head(1)","1c2d1917":"X = train.drop(columns=['hours-per-week'])\ny = train[tgt_var]\ntrain_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.3, random_state=22)\n\nnumerical = train.drop(columns=tgt_var).select_dtypes(include = np.number).columns\ncategorical = train.select_dtypes(exclude = np.number).columns\ndisplay(numerical, categorical)","52a2cf06":"cat_pipe = Pipeline([\n            #('Imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n             ('encoder',OneHotEncoder(handle_unknown='ignore',sparse=False))\n            ])\n\nnum_pipe = Pipeline([\n                #('Imputer',SimpleImputer(strategy='median')),\n                 ('scaler',MinMaxScaler())\n                ])\n\npreprocessor_ct = ColumnTransformer([\n                ('cat',cat_pipe,categorical),\n                ('num',num_pipe,numerical)\n                ])\n\npipe = Pipeline([\n    ('preprocessor', preprocessor_ct),\n    ('model', Ridge())\n])\n\npipe.fit(X, y)\ntrain_y_pred = pipe.predict(X)\nprint(\"Full Train RMSE: \",mean_squared_error(y, pipe.predict(X), squared=False))\nprint(\"Train RMSE     : \",mean_squared_error(train_y, pipe.predict(train_X), squared=False))\nprint(\"Test RMSE      : \",mean_squared_error(test_y, pipe.predict(test_X), squared=False))\n","3e41d8bc":"test_y_pred = pipe.predict(test)\nsubmission['hours-per-week'] = test_y_pred\n\n#submission.to_csv('submission_ohe_mmsc_ridge_v1.csv',index=False)","03889083":"# Final LeaderBoard (RMSE#9.78452 Rnk#17)"}}