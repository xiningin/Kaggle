{"cell_type":{"33f64fde":"code","38e643bb":"code","1278b184":"code","6d3ef40c":"code","d54b2825":"code","f3503749":"code","dd0f648e":"code","1670f417":"code","de3d3b3f":"code","c45949e4":"code","cf5169e2":"code","2718910a":"code","b208a329":"code","5c3aabf1":"code","5746664f":"code","d656b061":"code","29666692":"markdown","c21d7db6":"markdown","dbdc3fa1":"markdown","e8a2df1b":"markdown","94f46ce6":"markdown"},"source":{"33f64fde":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport cufflinks as cf\n\nimport plotly.express as px\n%matplotlib inline\n\n\nimport os\nimport random\nimport time\nfrom datetime import datetime\nimport gc\nimport warnings\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.ensemble import RandomTreesEmbedding\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer\n\nimport tensorflow as tf\nfrom keras import Sequential\nfrom keras import backend as K\nfrom keras.layers import Dense,Dropout,BatchNormalization,LeakyReLU,Activation\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nimport tensorflow_addons as tfa\n\nwarnings.filterwarnings(\"ignore\")\n","38e643bb":"train=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")","1278b184":"df=pd.DataFrame(train.groupby(\"loss\").count().f0.reset_index())\npx.pie(df, values='f0', names='loss', \n       title='share of loss values in dataset', \n       color_discrete_sequence=px.colors.sequential.RdBu)","6d3ef40c":"sns.displot(train['loss'],stat = 'density',binwidth = 3,bins = 11,kde = True)","d54b2825":"fig = px.density_heatmap(train, x='loss', y='f0', z='f1', \n                         marginal_x=\"histogram\", marginal_y=\"histogram\")\nfig","f3503749":"import random\ncolors = [ \"red\", \"lightblue\", \"lightgreen\", \"deeppink\", \"purple\", \"orange\", \"black\",\"pink\",\"deepskyblue\" ]\nlist=train.columns\ntrain[list[2]].shape\n\nsns.color_palette()","dd0f648e":"fig, axes = plt.subplots(25, 4, figsize=(20, 90))\n\n\nfor i in range(100):\n sns.scatterplot(ax=axes[i\/\/4,i%4],x=train[list[i]], y=train['loss'],color=random.choice(colors))\n \n","1670f417":"sns.lineplot( x=train['f1'], y=train['loss'],color='darkred')","de3d3b3f":"sns.lineplot( x=train['f86'], y=train['loss'],color='darkorange')","c45949e4":"def scaling(X_train,X_test):\n    \n    df = pd.concat([X_train,X_test],axis=0,copy=False).reset_index(drop=True)    \n    #scaling\n    scaler = StandardScaler()\n    df = scaler.fit_transform(df)\n    \n    #quantile transformation\n    qt = QuantileTransformer(random_state=0, output_distribution='normal')\n    df = qt.fit_transform(df)\n    \n    X_train = df[:len(X_train),:]\n    X_test = df[len(X_train):,:]\n    del df\n    gc.collect()\n    \n    return X_train,X_test","cf5169e2":"\nX=train.drop(['loss','id'],axis=1)\ny=train['loss']\ntest=test.drop('id',axis=1)\n\n","2718910a":"X,test = scaling(X,test)","b208a329":"\nX.shape","5c3aabf1":"import tensorflow.keras.backend as t\nimport tensorflow as tf\nimport math","5746664f":"def nn_model():\n    model = Sequential()\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='linear'))\n       \n    return model\n\n    \nlearning_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min') \nearlystopping = EarlyStopping(monitor='accuracy', patience=4) \n        \nN_FOLDS = 5\nSEED = 42\nEPOCH = 50\nN_round = 1\n\nfor i in range (N_round):\n    \n    oof = np.zeros((X.shape[0],1))\n    pred = np.zeros((test.shape[0],1))\n\n    skf = StratifiedKFold(n_splits=N_FOLDS, \n                          shuffle=True, \n                          random_state=SEED *i)\n\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(X,y)):\n        print(f\"FOLD {fold} of round {i}\")\n\n        X_train,y_train  = X[train_idx],y[train_idx]\n        X_valid,y_valid = X[valid_idx],y[valid_idx]\n        model= nn_model()\n        model.compile(loss='mse',metrics=['accuracy'],optimizer ='sgd')\n        model.fit(X_train, y_train,batch_size = 128,epochs = EPOCH,validation_data=(X_valid, y_valid),\n                  callbacks=[learning_loss, earlystopping],verbose = 1)\n\n        pred_round = model.predict(X_valid) \n        oof[valid_idx] += pred_round\n        score_NN_round = math.sqrt(mean_squared_error(y_valid, pred_round))\n        print('RMSE: {}'.format(np.sqrt(mean_squared_error(y_valid,pred_round ))))\n        pred += model.predict(test) \/ N_FOLDS \n        t.clear_session()\n     \n\n    score_round = math.sqrt(mean_squared_error(y, oof))\n    print(f\"\\n=== FINAL SCORE round {i} REGRESSION MODEL  : {score_round}===\\n\") ","d656b061":"\nsub=pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\nsub['loss'] = pred\nsub.to_csv('sub.csv', index = 0)","29666692":"\n\n# there are some outliers in loss\n\n41 and 42 have extremly low rows in dataset\n\n\n","c21d7db6":"**EDA's are very interesting dont know what new could be found**\n\ngo through the scatterplots \n\ncolumn f21 and f86 are not following pattern as showed by other columns\n\nif you do corelation analysis, you will find out there is no corelation\ni mean its in range of 0.0005 - 0.00010 doesnt makes any sense.\n\nthe columns doesnt explain target variable","dbdc3fa1":"\n\n\n\n**most of the values for loss lies from 0 to 12**\n\nlets compare loss with f1 \n\n\n\n\n","e8a2df1b":"**pie chart for target value**\n\n1. target loss is dominated by value 0\n2. the classes are unbalanced\n\nif anyone has idea how to balance the data set please comment \n\nnote - i have tried to reduce number of values in loss but score increases.\n","94f46ce6":"**+++training+++**"}}