{"cell_type":{"32a0ffa5":"code","40eb8d6d":"code","c4e6c348":"code","be5c87ba":"code","d5a4f421":"code","d774f637":"code","2fe2d7e9":"code","39abb3c7":"code","c5ae799a":"code","f002b8ab":"code","8ac58fc4":"code","0cf8854c":"code","91b17274":"code","295d5cfd":"code","ffa99be5":"code","820236ea":"code","a9cf9ec9":"code","a1d62664":"code","0b988949":"code","124d99d4":"code","e794b0b0":"code","0c6c23d4":"code","8e11c646":"code","c9285618":"code","e931fb4a":"code","68fb6360":"code","87cecd8a":"code","cf0ed9fa":"code","c90e4455":"code","393d49bc":"code","3d39aede":"code","cf63d777":"code","daf36a38":"code","de7828db":"code","bd2d1529":"code","30e1641f":"code","5dbd7ed1":"code","b52fbe94":"code","2eb7cd77":"code","647ab1a2":"code","fcf23bd8":"code","ff695f35":"code","a5636a4d":"code","97e163b9":"markdown","1f8e3fa0":"markdown","55dc5f3b":"markdown","ba566e98":"markdown","322dedea":"markdown","800dcd73":"markdown","70f143ab":"markdown","58dc2f33":"markdown","7a6780d4":"markdown","e6a55aec":"markdown","1a98ad34":"markdown","1b0188ff":"markdown","5894aefd":"markdown","ae01b780":"markdown","af39aca0":"markdown","d7cd4f5a":"markdown","6a6145fb":"markdown","d15edf38":"markdown","07e80ae4":"markdown","00738f47":"markdown","c2fcd93d":"markdown","56ce0bef":"markdown"},"source":{"32a0ffa5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","40eb8d6d":"# Check\u3000assined GPU detail\n!nvidia-smi","c4e6c348":"# File I\/O\nimport csv\nimport subprocess\nimport shutil\nimport os\nfrom glob import glob\nfrom datetime import datetime\nfrom PIL import Image\n\n# Data processing\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n\n# Image processing\nimport cv2\nfrom scipy.ndimage import rotate\nimport scipy.misc\n\n# Graph\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras import Model\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten, Dropout\nfrom keras.layers.core import Dense\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import np_utils\nfrom keras.optimizers import Adam\nfrom keras.optimizers import Adagrad\nfrom keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n# EfficientNet\nfrom tensorflow.keras.applications import EfficientNetB0\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom IPython.display import display\nimport ipywidgets as widgets","be5c87ba":"!unzip -q '..\/input\/dogs-vs-cats\/train.zip' -d '\/kaggle\/working\/' # ->'\/kaggle\/working\/train'\n!unzip -q '..\/input\/dogs-vs-cats\/test1.zip' -d '\/kaggle\/working\/test\/' # ->'\/kaggle\/working\/test\/test1'","d5a4f421":"shutil.move('\/kaggle\/working\/train\/', '\/kaggle\/working\/train_raw\/all_pics')","d774f637":"root_path = '\/kaggle\/working'\n\n# Path of Unzipping data stored (root)\ntrain_raw_root_path = '\/kaggle\/working\/train_raw\/'\n\n\n# Path of Unzipping data stored \ntrain_raw_path = '\/kaggle\/working\/train_raw\/all_pics'\n\n# Path for training\ntrain_root_path = '\/kaggle\/working\/train_root'\ntest_path = '\/kaggle\/working\/test'\nsubmit_file = 'submission.csv'\n\n# Path for Imagegenerator\ntrain_dir = os.path.join(train_root_path, 'train')\nvalid_dir = os.path.join(train_root_path, 'valid')\n\nprint(train_dir)\nprint(valid_dir)","2fe2d7e9":"# picture file name list\ndata_img_list = [os.path.basename(f) for f in glob(f'{train_raw_path}\/*.jpg')]\ntest_img_list = [os.path.basename(f) for f in glob(f'{test_path}\/test1\/*.jpg')]","39abb3c7":"# target labels list\ntarget_labels = ['cat', 'dog']\n\n# directories in the train_root path\ndirs = ['train', 'valid']\n\n# make dirctories for data store\nfor d in dirs:\n    for label in target_labels:\n        os.makedirs(os.path.join(train_root_path, d, label), exist_ok=True)","c5ae799a":"# Initializing instance\nimg_cat_list = []\nimg_dog_list = []\n\n# make dog and cat file name list\nfor f in data_img_list:\n    label = f.split('.')[0]\n    if label == target_labels[0]:\n        img_cat_list.append(f)\n    elif label == target_labels[1]:\n        img_dog_list.append(f)\n    else:\n        print('abnormal file name is found', f)\n\n# Split data to for train and for valid\ntrain_list_cat, val_list_cat, train_list_dog, val_list_dog = train_test_split(img_cat_list, img_dog_list, \n                                                                  test_size=0.3,\n                                                                 random_state=46)\n# directories list to join to train_root path\ncopy_to_dirs = ['train\/cat', 'valid\/cat', 'train\/dog', 'valid\/dog']\nimg_lists = [train_list_cat, val_list_cat, train_list_dog, val_list_dog] \n\n# Copy to each directories\nfor to_dir in copy_to_dirs:\n    for f in img_lists[copy_to_dirs.index(to_dir)]:\n        shutil.copyfile(os.path.join(train_raw_path,f), os.path.join(train_root_path, to_dir,f))","f002b8ab":"# Check file quantity \nprint('train image quantity:', len(data_img_list))\nprint('cat:', len(img_cat_list))\nprint('dog:', len(img_dog_list))\nprint()\nprint('prediction target test image quantity:', len(test_img_list))","8ac58fc4":"# Check file number\nfor d in dirs:\n    for label in target_labels:\n        print(os.path.join(train_root_path, d, label))\n        print(len([file for file in os.listdir(os.path.join(train_root_path, d, label))]))","0cf8854c":"# Check data directry tree structure\n!tree -d '\/kaggle\/working\/'","91b17274":"learning_rate = 1e-4\nbatch_size = 20\ninput_height , input_width = 300, 300\nrandom_split = 1\nepochs = 200\n\n# model name setting\nmodel_name_list = ['efficient_net', 'mymodel', ]","295d5cfd":"# \u753b\u50cf\u306e\u8868\u793a\nim = Image.open(os.path.join(train_raw_path, img_dog_list[0]))\nprint(os.path.join(train_raw_path, img_dog_list[0]))\nplt.imshow(im)\nplt.title(img_dog_list[0])\nplt.axis(\"off\")\nplt.show()","ffa99be5":"labels = ['cat', 'dog']\nlabel_description = {\n    '0': 'cat',\n    '1': 'dog',\n}\n\nfor label in labels:\n    f, ax = plt.subplots(figsize=(12,10))\n    if label == 'cat':\n        img_list = img_cat_list\n        \n    elif label == 'dog':\n        img_list = img_dog_list\n        \n    # show pictures 3 x 3 \n    for x in range(9):\n        plt.subplot(3, 3, x+1)\n        im = Image.open(os.path.join(train_raw_path, img_list[x]))\n        plt.axis('off')\n        plt.title(img_list[x])\n        plt.imshow(im)\n        \n    print(f'\\t\\t\\t\\t# {label}')\n    plt.show()\n    print()","820236ea":"# All images will be rescaled by 1.\/255\n# train_datagen = ImageDataGenerator(rescale=1.\/255)\n# Added data augumentation to avoid over fitting (version 8)\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 360,\n    # zca_whitening = True,\n    # zca_epsilon = 1e-06,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.1,\n    zoom_range = [0.5,1.0],\n    channel_shift_range = 0.2,\n    horizontal_flip = True,\n    vertical_flip = True,\n    rescale = 1.\/255,\n    preprocessing_function = None\n)\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(input_height, input_width),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalid_generator = valid_datagen.flow_from_directory(\n        valid_dir,\n        target_size=(input_height, input_width),\n        batch_size=20,\n        class_mode='binary')","a9cf9ec9":"def efficientnet_model(input_height, input_width):\n    model = Sequential()\n    model.add( tf.keras.applications.EfficientNetB3(\n    include_top=False,\n    weights=\"imagenet\", input_shape=(input_height, input_width, 3)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    return model","a1d62664":"def mymodel(input_height, input_width):\n    # \u30e2\u30c7\u30eb\u306e\u4f5c\u6210\n    mymodel = Sequential()\n    mymodel.add(Conv2D(32, kernel_size=3, padding=\"same\", activation='relu', input_shape=(input_height, input_width, 3)))\n    mymodel.add(MaxPooling2D(pool_size=(3, 3)))\n    mymodel.add(Conv2D(64, kernel_size=3, padding=\"same\", activation='relu'))\n    mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n    mymodel.add(Conv2D(128, kernel_size=3, padding=\"same\", activation='relu'))\n    mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n    mymodel.add(Flatten())    #Flatten()\u306b\u3088\u308a\u7279\u5fb4\u30de\u30c3\u30d7\u3092\u30d9\u30af\u30c8\u30eb\u306b\u5909\u63db\u3057\u3001\u5f8c\u7d9a\u306e\u5168\u7d50\u5408\u5c64\u3068\u7e4b\u3052\u3089\u308c\u308b\u3088\u3046\u306b\u3059\u308b\n    mymodel.add(Dense(384, activation='relu'))\n    mymodel.add(Dense(128, activation='relu'))\n    mymodel.add(Dense(1, activation='sigmoid'))    #Softmax\u95a2\u6570\u306b\u3066\u3001\u30af\u30e9\u30b9\u6bce\u306e\u78ba\u7387\u3068\u3057\u3066\u51fa\u529b\n\n    return mymodel","0b988949":"'''\ndef mymodel2 (input_height, input_width, num_classes):\n  # network layer\n  # write code and define network\n\n  return model\n'''","124d99d4":"def get_answer(x):\n    return x","e794b0b0":"model_selected = get_answer(widgets.RadioButtons(options=model_name_list))\ndisplay(model_selected)","0c6c23d4":"model_name = model_selected.value\nprint(model_name)","8e11c646":"def select_model(model_name, input_height, input_width):\n    if model_name == 'mymodel':\n        model = mymodel(input_height, input_width)\n    elif model_name == 'efficient_net':\n        model = efficientnet_model(input_height, input_width)\n\n    return model\n\nmodel = select_model(model_name, input_height, input_width)\n\n# display model summary \nmodel.summary()","c9285618":"# compile model with some setting item\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=learning_rate),\n              metrics=['accuracy'])","e931fb4a":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                           patiene = 3,\n                                           verbose = 1,\n                                           factor = 0.5,\n                                           min_lr = 0.00001)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=10)","68fb6360":"# train\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\n      epochs=200,\n      validation_data=valid_generator,\n      validation_steps=50,  # 1000 images = batch_size * steps\n      verbose=2,\n      callbacks = [learning_rate_reduction, early_stopping],\n)","87cecd8a":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","cf0ed9fa":"# Save Model\nmodel.save(root_path + '\/model.h5' )    # model\nmodel.save_weights(root_path + '\/model_weights.h5')    # model parameter","c90e4455":"# load model\n# from keras.models import load_model\n# model = load_model(root_path + '\/model.h5')","393d49bc":"eval_datagen = ImageDataGenerator(rescale=1.\/255)\neval_generator = eval_datagen.flow_from_directory(\n    train_raw_root_path,\n    target_size=(input_height, input_width),\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)\n\nprint('evaluation(all pictures(raw train dataset) \uff1a', len(data_img_list))","3d39aede":"eval_pred_proba = model.predict(\n    eval_generator,\n    steps=len(data_img_list),\n    verbose=0)\n\n# probability value is predicted\nprint(eval_pred_proba.shape)\neval_pred_class = np.where(eval_pred_proba < 0.5, 0, 1)","cf63d777":"true_class = []\ntrue_class_name = []\nfor f in os.listdir(train_raw_path):\n    class_name = f.split('.')[0]\n    true_class_name.append(class_name)\n    if class_name == 'cat':\n        true_class.append(0)\n    elif class_name == 'dog':\n        true_class.append(1)\n    else:\n        continue\n        \nprint(true_class[0:10])\nprint(true_class_name[0:10])","daf36a38":"from sklearn.metrics import confusion_matrix\n\neval_cmx = confusion_matrix(true_class, eval_pred_class)\n\n# DataFrame\neval_cmx_df = pd.DataFrame(eval_cmx, columns=target_labels, index=target_labels)\n\nprint('Confution matrix with train all pics data')\n\n# \u7d50\u679c\u306e\u8868\u793a\neval_cmx_df","de7828db":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nprint('accuracy:', accuracy_score(true_class, eval_pred_class))\nprint('precision:', precision_score(true_class, eval_pred_class, average='macro'))\nprint('recall:', recall_score(true_class, eval_pred_class, average='macro'))\nprint('f1:', f1_score(true_class, eval_pred_class, average='macro'))","bd2d1529":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.heatmap(eval_cmx, annot=True, cmap='Blues')\nplt.savefig(root_path + '\/' + 'sklearn_confusion_matrix.png')","30e1641f":"# Again, test path folder shall have one more folder at least and test data shall be stored in the folder\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(input_height, input_width),\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)\n\nprint('test data quantity\uff1a', len(test_img_list))","5dbd7ed1":"test_pred_proba = model.predict(\n    test_generator,\n    steps=len(test_img_list),\n    verbose=0)\n\nprint(test_pred_proba.shape)\ntest_pred_class = np.where(test_pred_proba < 0.5, 0, 1)","b52fbe94":"test_filename_list=[]\nfor f in test_img_list:\n    test_filename_list.append(f.split('.')[0])","2eb7cd77":"result_id = pd.DataFrame(test_filename_list, columns=['id'])\nresult_label = pd.DataFrame(test_pred_class, columns=['label'])\nresult_for_submit = pd.concat([result_id, result_label], axis=1)\nresult_for_submit.head()","647ab1a2":"result_for_submit.to_csv(submit_file, sep=\",\", header=True, index=False)","fcf23bd8":"'''\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306b\u4ed8\u3051\u308b\u65e5\u6642\u30c7\u30fc\u30bf\u306e\u6587\u5b57\u5217\u4f5c\u6210\nimport datetime\n\ndt_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\nd_today = datetime.date.today()\n\nfiletime = str(d_today)+'_'+str(dt_now.hour)+str(dt_now.minute)\n'''","ff695f35":"'''\nhist  = model.fit(\n    train_generator,\n    validation_data = valid_generator,\n    steps_per_epoch = len(df_train)*0.9\/\/batch_size,\n    validation_steps = len(df_train)*0.1\/\/batch_size, \n    epochs = epochs,\n    # callbacks = [model_checkpoint, early_stopping])\n    callbacks = [model_checkpoint, learning_rate_reduction, early_stopping])\n'''","a5636a4d":"'''\n# cp_cb = ModelCheckpoint(model_path + '\/checkpoint\/' + \"{epoch}\"+\"checkpoint.h5\", verbose=1, save_best_only=True)\nmodel_checkpoint = ModelCheckpoint(\n        filepath = f'{root_path}\/checkpoint.h5',\n        save_weights_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True)\n'''","97e163b9":"## 2-2. Path and file name setting  \nAgain, test path folder shall have one more folder at least.  ","1f8e3fa0":"------------------------unimplimented-------------------------------","55dc5f3b":"# 5. Model evaluation","ba566e98":"test: pictures for test  \ntrain_raw: train data provided from kaggle  \ntrain_root: train pictures copied to place for ImageDataGenerator","322dedea":"Adding some model network definition","800dcd73":"## 6. Prediction with Test data","70f143ab":"# 4. Save Model","58dc2f33":"# 3. Training","7a6780d4":"## 5-1. Confusion matrix","e6a55aec":"## 2-4. Copy picture data to tree for ImageDataGenerator","1a98ad34":"## 3-1. setting for training","1b0188ff":"Making each file name list of classificaion target categories","5894aefd":"## 1. Import libraries","ae01b780":"# 2.Data preparation  \n## 2-1. Unzip data  \nI will use ImageGenerator to load data for training.  \nTest data poctures shall not be stored in Test data path folder directory.Test data path shall have one folder.  \nIf prediction target pictures are stored in the test data path folder directory, error occurrs.   ","af39aca0":"## 3-2. dataset confirmation","d7cd4f5a":"## 3-4. Network definition","6a6145fb":"## 3-3. ImageDataGenerator","d15edf38":"## 7. Create Submission file","07e80ae4":"## 3-5. train","00738f47":"# Starter notebook \u201dDogs vs. Cats\u201d with EfficientNet vs My own model\nThis notebook shows a flow of \"Dogs and Cats\" distinguish model development.  \nhttps:\/\/www.kaggle.com\/c\/dogs-vs-cats\/  \n\n[Agenda]\n1. Import libraries  \n2.\u3000Data preparation  \n    2-1. Unzip data  \n    2-2. Path and file name setting  \n    2-3. making directory tree for ImageDataGenerator  \n    2-4. Copy picture data to tree for ImageDataGenerator  \n3. Training  \n    3-1. setting for training  \n    3-2. dataset confirmation  \n    3-3. ImageDataGenerator  \n    3-4. Network definition  \n    3-5. train  \n4. Save Model  \n5. Model evaluation  \n    5-1. Confusion matrix  \n6. Prediction with Test data  \n7. Create submission file  ","c2fcd93d":"Check file quantity in each directory.Above quantity shows correct copy picture process.","56ce0bef":"## 2-3. making directory tree for ImageDataGenerator"}}