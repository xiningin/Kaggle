{"cell_type":{"e9938dbe":"code","2f5ecf34":"code","3ab45461":"code","450e322e":"code","ad7ee238":"code","9e729482":"code","c604eda7":"code","35663f1a":"code","8b9ca542":"code","f64b58aa":"code","e07052b6":"code","3c9d4d44":"code","58825cd0":"code","094df531":"code","ec994603":"code","d16eba1d":"code","c999e93a":"code","6cb207db":"code","20f8bc18":"code","2a4c5bf9":"code","d8dac735":"code","83fcef8d":"code","7d8c6b5f":"code","26fe482d":"code","04ee4f2f":"code","e19453a7":"code","d79d0edd":"code","6e2357b3":"code","750ce057":"code","18c6ab33":"code","2805972d":"code","427d75b3":"code","059aa046":"code","55c6fb48":"code","b60db0a8":"code","1ad1b1dc":"code","81363ab5":"code","0df5db6f":"code","992e27d4":"code","11ad0ac8":"code","da1d2f6e":"markdown","9955f47f":"markdown","72aacf4b":"markdown","b1f70254":"markdown","68620ff1":"markdown","2a95b443":"markdown","1919866e":"markdown","cea0e05c":"markdown","cc6b8851":"markdown","f8c12f77":"markdown","c10b5151":"markdown"},"source":{"e9938dbe":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_curve, auc","2f5ecf34":"df_original = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf_original.head()","3ab45461":"df = df_original.iloc[:, :-2]\ndf.drop(['CLIENTNUM'], axis=1, inplace=True)\ndf.head(4)","450e322e":"df.isna().sum().sum()","ad7ee238":"col_names = df.columns.tolist()\nprint(col_names)","9e729482":"df['Attrition_Flag'].value_counts()","c604eda7":"df['Customer_Age'].describe()","35663f1a":"df['Gender'].value_counts()","8b9ca542":"df['Dependent_count'].value_counts()","f64b58aa":"df['Education_Level'].value_counts()","e07052b6":"df['Marital_Status'].value_counts()","3c9d4d44":"df['Income_Category'].value_counts()","58825cd0":"df['Card_Category'].value_counts()","094df531":"df['Months_on_book'].describe()","ec994603":"df['Total_Relationship_Count'].value_counts()","d16eba1d":"df['Months_Inactive_12_mon'].value_counts()","c999e93a":"df['Contacts_Count_12_mon'].value_counts()","6cb207db":"df['Credit_Limit'].describe()","20f8bc18":"df['Total_Revolving_Bal'].describe()","2a4c5bf9":"df['Avg_Open_To_Buy'].describe()","d8dac735":"df['Total_Amt_Chng_Q4_Q1'].describe()","83fcef8d":"df['Total_Trans_Amt'].describe()","7d8c6b5f":"df['Total_Trans_Ct'].describe()","26fe482d":"df['Total_Ct_Chng_Q4_Q1'].describe()","04ee4f2f":"df['Avg_Utilization_Ratio'].describe()","e19453a7":"cat_col_names = df.columns[df.dtypes==object].tolist()\ncat_col_names","d79d0edd":"label_enc = LabelEncoder()\ndf[cat_col_names] = df[cat_col_names].apply(\n    lambda col: label_enc.fit_transform(col))","6e2357b3":"x = df.drop(['Attrition_Flag'], axis=1)\ny = df['Attrition_Flag']","750ce057":"x_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=0)","18c6ab33":"model_DecTreeClass = DecisionTreeClassifier(random_state=0)\nmodel_DecTreeClass.fit(x_train, y_train)\ny_pred_DecTreeClass = model_DecTreeClass.predict(x_test)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_DecTreeClass)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint('AUC: %.2f' % (roc_auc*100), \"%\")","2805972d":"feat_imp_dic = dict(zip(x.columns, model_DecTreeClass.feature_importances_))\nfeat_imp_sorted = sorted(feat_imp_dic.items(), key=lambda x: x[1], reverse=True)\npd.DataFrame(feat_imp_sorted, columns=['Feature', 'Feature importance'])","427d75b3":"def train_test_scores(x_train, x_test, y_train, y_test, model):    \n    model.fit(x_train, y_train)      \n    fp_train, tp_train, _ = roc_curve(y_train, model.predict(x_train))\n    fp_pred, tp_pred, _ = roc_curve(y_test, model.predict(x_test))    \n    return auc(fp_train, tp_train), auc(fp_pred, tp_pred)","059aa046":"max_depths = range(1,31) # max_depth: 1,2,...,30\n\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n    model = DecisionTreeClassifier(max_depth=max_depth, random_state=0)\n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')\nline2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('Tree depth')\nplt.ylabel('AUC score')\nplt.title('Impurity measure - Gini')\nplt.show()","55c6fb48":"max_depths = range(1,31) # max_depth: 1,2,...,30\n\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n    model = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=0)\n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')\nline2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('Tree depth')\nplt.ylabel('AUC score')\nplt.title('Impurity measure - Entropy')\nplt.show()","b60db0a8":"max_features_list = range(1,20)\n\ntrain_results = []\ntest_results = []\nfor max_features in max_features_list:\n    model = DecisionTreeClassifier(max_features=max_features, random_state=0)\n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(max_features_list, train_results, 'b', label='Train AUC')\nline2, = plt.plot(max_features_list, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('Number of used features')\nplt.xticks(max_features_list)\nplt.ylabel('AUC score')\nplt.show()\n","1ad1b1dc":"min_samples_splits = np.linspace(0.05, 1.0, num=100, endpoint=True)\n\ntrain_results = []\ntest_results = []\nfor min_samples_split in min_samples_splits:\n    model = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=0)    \n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('min samples splits')\nplt.ylabel('AUC score')\nplt.show()","81363ab5":"min_samples_leafs = np.linspace(0.05, 0.5, num=100, endpoint=True)\n\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n    model = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=0)    \n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('min samples leaf')\nplt.ylabel('AUC score')\nplt.show()","0df5db6f":"min_impurity_decrease_list = np.linspace(0.0, 0.5, num=100, endpoint=True)\n\ntrain_results = []\ntest_results = []\nfor min_impurity_decrease in min_impurity_decrease_list:\n    model = DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease, random_state=0)    \n    auc_train, auc_pred = train_test_scores(x_train, x_test, y_train, y_test, model)\n    train_results.append(auc_train)\n    test_results.append(auc_pred)\n\nline1, = plt.plot(min_impurity_decrease_list, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_impurity_decrease_list, test_results, 'r', label='Test AUC')\nplt.legend()\nplt.xlabel('min impurity decrease')\nplt.ylabel('AUC score')\nplt.show()","992e27d4":"parameters = {'criterion': ('gini', 'entropy'), \n              'max_depth': range(1,17),\n              'min_samples_split': np.linspace(0.05, 0.4, num=10, endpoint=True),\n              'min_samples_leaf': np.linspace(0.05, 0.2, num=10, endpoint=True),\n              }\nmodel_DecTreeClass = DecisionTreeClassifier(random_state=0)\nmodel_param = GridSearchCV(model_DecTreeClass, parameters, cv=5)\n\nmodel_param.fit(x_train, y_train)\ny_pred_param = model_param.predict(x_test)\n\nprint('Model parameters: ', model_param.best_params_)\nprint('-----------------------')\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_param)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint('AUC with parameter tuning: %.2f' % (roc_auc*100), \"%\")","11ad0ac8":"parameters = {'criterion': ('gini', 'entropy'), \n              'max_depth': range(1,17)\n              }\nmodel_DecTreeClass = DecisionTreeClassifier(random_state=0)\nmodel_param = GridSearchCV(model_DecTreeClass, parameters, cv=5)\n\nmodel_param.fit(x_train, y_train)\ny_pred_param = model_param.predict(x_test)\n\nprint('Model parameters: ', model_param.best_params_)\nprint('-----------------------')\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_param)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint('AUC with parameter tuning: %.2f' % (roc_auc*100), \"%\")","da1d2f6e":"Inspecting each column.","9955f47f":"There are no empty data:","72aacf4b":"The last two columns are dropped, because they have been added by the author of this dataset.\n\nColumn 'CLIENTNUM' referring to the client number is also dropped.","b1f70254":"Decision tree classifier with default parameters.","68620ff1":"## Decision Tree Classifier","2a95b443":"## Read data","1919866e":"List of features sorted by its importance.","cea0e05c":"## Import packages","cc6b8851":"## Hyperparameter Tuning","f8c12f77":"Encoding categorical data","c10b5151":"Columns that contain categorical data."}}