{"cell_type":{"c0ca9789":"code","40a069c1":"code","320248a1":"code","bbc18c1a":"code","f2263b79":"code","db5eb26a":"code","88974dc1":"code","fd74111b":"code","5313c7fb":"code","265c95e2":"code","dc3f1b95":"code","e48c7cff":"code","68989f67":"code","0e255f20":"code","76f8e873":"code","cd60c71a":"code","d8514a92":"code","fa26c4ef":"code","11dae99f":"code","4da04ecb":"code","4371c15c":"code","daff3adc":"code","7d3092a3":"code","3f7694f0":"code","7c794bc1":"code","b24b1b4f":"code","9b5f63f0":"code","e779836c":"code","59d4665a":"code","17ae56c5":"code","110ddb47":"code","3d532508":"markdown","653adeb5":"markdown","24c89fcd":"markdown","f6c40cb7":"markdown","e25c4d9f":"markdown","3dd71e6e":"markdown","97790d0e":"markdown","7aa0ee2e":"markdown","0d3135e9":"markdown","18f11537":"markdown","80ba7007":"markdown","70c04abd":"markdown"},"source":{"c0ca9789":"import os\nGPU_id = 0\nos.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)","40a069c1":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport time\nimport os\n\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *","320248a1":"!pwd","bbc18c1a":"path = Path('..\/input\/pennfudanped')\npath.ls()","f2263b79":"path_lbl = path\/'PedMasks'\npath_img = path\/'PNGImages'","db5eb26a":"fnames = get_image_files(path_img)\nfnames[:3]","88974dc1":"lbl_names = get_image_files(path_lbl)\nlbl_names[:3]","fd74111b":"img_f = fnames[0]\nimg = open_image(img_f)\nimg.show(figsize=(5, 5))","5313c7fb":"print(img_f.stem,img_f.suffix)\nget_y_fn = lambda x: path_lbl\/f'{x.stem}_mask{x.suffix}'\nget_y_fn(img_f)","265c95e2":"mask = open_mask(get_y_fn(img_f))\nmask.show(figsize=(5, 5), alpha=1)\nsrc_size = np.array(mask.shape[1:])","dc3f1b95":"df = pd.read_csv(path\/'added-object-list.txt',skiprows=1,sep='\\t')\ndf.columns = ['image','objects']\ndf.head()","e48c7cff":"df['objects'].max()","68989f67":"mask = df['objects']==8\ndf.loc[mask]","0e255f20":"img_f = Path(path\/'PNGImages\/FudanPed00058.png')\nimg = open_image(img_f)\nimg.show(figsize=(5, 5))","76f8e873":"mask = open_mask(get_y_fn(img_f))\nmask.show(figsize=(5, 5), alpha=1)","cd60c71a":"codes = np.array(['background','person'])","d8514a92":"size = src_size\/\/2\nbs = 32","fa26c4ef":"class MySegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): \n        res = open_mask(fn)\n        res.px = (res.px>0).float()\n        return res\n\nclass MySegmentationItemList(ImageList):\n    \"`ItemList` suitable for segmentation tasks.\"\n    _label_cls,_square_show_res = MySegmentationLabelList,False","11dae99f":"src = (MySegmentationItemList.from_folder(path_img) # SegmentationItemList\n       .split_by_rand_pct(0.2) # SegmentationItemList\n       .label_from_func(get_y_fn, classes=codes)) # LabelLists","4da04ecb":"data = (src.transform(get_transforms(), size=size, tfm_y=True)\n        .databunch(bs=bs)\n        .normalize(imagenet_stats))","4371c15c":"data.show_batch(2, figsize=(5, 5))","daff3adc":"name2id = {v:k for k,v in enumerate(codes)}\nvoid_code = -1\n\ndef acc_camvid(input, target):\n    target = target.squeeze(1)\n    mask = target != void_code\n    #print(input.size())\n    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()","7d3092a3":"wd = 1e-2\nmetrics = acc_camvid\nlearn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)\nlearn.model_dir = '\/kaggle\/working\/models'","3f7694f0":"learn.lr_find()","7c794bc1":"learn.recorder.plot()","b24b1b4f":"lr = 1e-4\nlearn.fit_one_cycle(10, slice(lr))","9b5f63f0":"%%time\npred,truths = learn.get_preds()","e779836c":"class MyImageList(ImageList):\n    def __init__(self, *args, imgs=None, **kwargs):\n        self.imgs = imgs\n        \n    def get(self, i):\n        res = self.imgs[i]\n        return Image(res)","59d4665a":"pred_masks = MyImageList(imgs = pred.argmax(dim=1,keepdim=True))\ntrue_masks = MyImageList(imgs = truths)","17ae56c5":"def _plot(i,j,ax): true_masks[i*3+j].show(ax)\nplot_multi(_plot, 3, 3, figsize=(8,8))","110ddb47":"def _plot(i,j,ax): pred_masks[i*3+j].show(ax)\nplot_multi(_plot, 3, 3, figsize=(8,8))","3d532508":"### show true masks","653adeb5":"### Create databunch for segmentation","24c89fcd":"Although there is only one class, person, objects are labeled with increasing integers. For example, values of object 1 in the mask are 1. values of object 2 in the mask are 2. so on so forth.","f6c40cb7":"### Let's visually check the predictions","e25c4d9f":"### show predicted masks","3dd71e6e":"### Training","97790d0e":"### show an image and its mask","7aa0ee2e":"It seems there could be up to 8 objects in one image. Let's verify it.","0d3135e9":"### Create a Path object and view folders","18f11537":"### so how many objects could there be in one image?","80ba7007":"yeah, it seems correct. However, some objects could be very small.","70c04abd":"The mask can have unique values from 0 to 8, which means up to 8 objects in the image. However, they belong to the same class, person. Hence, we binarize the masks. "}}