{"cell_type":{"aca51a67":"code","5770349f":"code","01f58cb4":"code","c8daf213":"code","01a0202e":"code","fc92881f":"code","36b5bd5f":"code","72e5f0e8":"code","aa4aecc8":"code","61de3dfd":"code","0bb939d3":"code","2200b5ad":"code","85268038":"code","d313f114":"code","11569d9b":"code","b4b47e4b":"code","82600284":"code","bc0aeb85":"code","4f89c872":"code","3bdcc6bb":"code","26831e33":"code","f96b1734":"code","337cd67f":"code","3b853f8d":"code","3df9313f":"code","0a03ee37":"markdown","2a02b610":"markdown","cc0ea0fe":"markdown","f5328f3d":"markdown","0076fc97":"markdown","6836e926":"markdown","e88764c9":"markdown","48906860":"markdown","8d6be18c":"markdown","da7af2f7":"markdown","3508778d":"markdown","9f05ecbb":"markdown","e5793a07":"markdown","1cead31b":"markdown","b2a881df":"markdown","de35e67f":"markdown","77606a88":"markdown"},"source":{"aca51a67":"import pandas as pd\nimport numpy as np","5770349f":"df=pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","01f58cb4":"df.head()","c8daf213":"df.isna().any()","01a0202e":"df.info()\n","fc92881f":"df.describe()","36b5bd5f":"X=df.drop(\"output\",axis=1)\ny=df[\"output\"]","72e5f0e8":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2, shuffle =True,random_state=42)","aa4aecc8":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\n","61de3dfd":"rfc.score(X_test,y_test)","0bb939d3":"import seaborn as sns\nsns.pairplot(df)\n","2200b5ad":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(16,10))\nsns.heatmap(df.corr(method='pearson'), annot=True)","85268038":"from scipy.stats import skew\n\nfor column in df.columns:\n    print(skew(df[column]))","d313f114":"df['age'] = df['age']\/max(df['age'])\ndf['cp'] = df['cp']\/max(df['cp'])\ndf['trtbps'] = df['trtbps']\/max(df['trtbps'])\ndf['chol'] = df['chol']\/max(df['chol'])\ndf['thalachh'] = df['thalachh']\/max(df['thalachh'])","11569d9b":"X=df.drop(\"output\",axis=1)\ny=df[\"output\"]","b4b47e4b":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2, shuffle =True,random_state=42)","82600284":"from sklearn.ensemble import RandomForestClassifier\nrfc1 = RandomForestClassifier()\nrfc1.fit(X_train,y_train)\n","bc0aeb85":"rfc1.score(X_test,y_test)","4f89c872":"from sklearn.model_selection import RandomizedSearchCV\ngrid={'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt',\"log2\"],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n","3bdcc6bb":"rfc2=RandomForestClassifier()\nrfc3 = RandomizedSearchCV(estimator = rfc2, param_distributions = grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrfc3.fit(X_train,y_train)","26831e33":"rfc3.score(X_test,y_test)","f96b1734":"rdc3pred=","337cd67f":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\nada1=AdaBoostClassifier(learning_rate=0.15, n_estimators=25)\nada1.fit(X_train,y_train)","3b853f8d":"print(ada1.score(X_test,y_test))\nadapred=ada1.predict(X_test)","3df9313f":"from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix\nprint(accuracy_score(y_test,adapred))","0a03ee37":"## Importing dataset using read_csv of pandas","2a02b610":"## checking for skewness in the independent feature","cc0ea0fe":"## Prediction after preprocessing","f5328f3d":"## Pairplot for better understanding of data","0076fc97":"## Accesing the first five coloums by head() method","6836e926":"# Now I am going to show how feature engineering and hyperparametre tuning going to show the difference in predictions","e88764c9":"# Overall highest accuracy achieved was ~86 percent","48906860":"## I coudnot see any correations between independent features but have to find it througly with a correlation map","8d6be18c":"# Hyperparaametre tuning","da7af2f7":"## predicting with randomforest classifier with default parametres","3508778d":"## So hyperparametre tuning incresed out acuracy by ~1 percent ","9f05ecbb":"## I cound not see any skewed data here hence these are all normally distributed features","e5793a07":"## scaling data","1cead31b":"## Trying ada boost","b2a881df":"## checking for null values","de35e67f":"## So the accuracy increased by ~2 percent ","77606a88":"## Acheived a score of ~83 percent without any preprocessing and tuning "}}