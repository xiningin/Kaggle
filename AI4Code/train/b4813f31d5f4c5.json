{"cell_type":{"361b063b":"code","f3ed1f7c":"code","744ef8a8":"code","cb180589":"code","70816532":"code","3e77ebe1":"code","3da20338":"code","292fe101":"code","0d2af3c8":"code","efe144bd":"code","c0e17f22":"code","a3970c83":"code","06174f74":"code","bc02f43e":"code","3f18f381":"code","7b47b071":"code","6b6040c5":"code","788dc4fe":"code","42c89cb0":"code","74304095":"code","dcbc012c":"code","ddcd3be3":"code","dd394fab":"code","8427945a":"code","d9677383":"code","5ea6e889":"code","3f767d4b":"code","7337d227":"code","94c90436":"code","013771d0":"code","a0cdf27c":"code","17727645":"code","ce83c476":"code","517cffd6":"code","259486c3":"code","19df7ed1":"code","a75b8216":"code","246968c6":"code","9e032cf3":"code","00da9251":"code","cdeebe66":"code","d5d31b49":"code","eb339098":"code","135e78fa":"code","c47de3e9":"markdown","8bcf3f8c":"markdown","a6db19be":"markdown","e3410773":"markdown"},"source":{"361b063b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport time\nimport datetime\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom scipy import stats\nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook\n#timeseries libraries\nfrom statsmodels import tsa\nfrom statsmodels.graphics import tsaplots\nfrom statsmodels.stats.diagnostic import acorr_ljungbox\nfrom statsmodels.api import qqplot\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\n\nfrom statsmodels.tsa.arima_model import ARMA \nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error","f3ed1f7c":"%%time\ntrain = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","744ef8a8":"#test = pd.read_csv('..\/input\/test\/.csv')\n#test.shape","cb180589":"train_acoustic_data_small = train['acoustic_data'].values[::50]\ntrain_time_to_failure_small = train['time_to_failure'].values[::50]\n\nfig, ax1 = plt.subplots(figsize=(16, 8))\nplt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\nplt.plot(train_acoustic_data_small, color='b')\nax1.set_ylabel('acoustic_data', color='b')\nplt.legend(['acoustic_data'])\nax2 = ax1.twinx()\nplt.plot(train_time_to_failure_small, color='g')\nax2.set_ylabel('time_to_failure', color='g')\nplt.legend(['time_to_failure'], loc=(0.875, 0.9))\nplt.grid(False)\n\ndel train_acoustic_data_small\ndel train_time_to_failure_small","70816532":"train_time_to_failure_small = train['time_to_failure'].values[::50]\n\nfig, ax1 = plt.subplots(figsize=(16, 8))\nax2 = ax1.twinx()\nplt.plot(train_time_to_failure_small, color='g')\nax2.set_ylabel('time_to_failure', color='g')\nplt.legend(['time_to_failure'], loc=(0.875, 0.9))\nplt.grid(False)\ndel train_time_to_failure_small","3e77ebe1":"#let's prepare our data\nseg_length = 60000\ntotal_samples = int(np.floor((train.shape[0]) \/ seg_length))\n\n#we will be using a total of nine different features as given below for making our predictions\ncols = ['average', 'std'] #our features used for the prediction\nx_train = pd.DataFrame(index = range(total_samples), columns = cols, dtype = np.float64) #an empty dataframe holding our feature values\ny_train = pd.DataFrame(index = range(total_samples), columns = ['time_to_failure'], dtype = np.float64) #an empty dataframe holding our target labels","3da20338":"for value in tqdm(range(total_samples)):\n    sample = train.iloc[value*seg_length : value*seg_length + seg_length]\n    x = sample['acoustic_data'].values\n    y = sample['time_to_failure'].values[-1]\n    \n    y_train.loc[value, 'time_to_failure'] = y\n    \n    x_train.loc[value, 'average'] = x.mean()\n    x_train.loc[value, 'std'] = x.std()","292fe101":"train_acoustic_data_small = x_train['average']\ntrain_time_to_failure_small = y_train['time_to_failure']\n\nfig, ax1 = plt.subplots(figsize=(16, 8))\nplt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\nplt.plot(train_acoustic_data_small, color='b')\nax1.set_ylabel('acoustic_data', color='b')\nplt.legend(['acoustic_data'])\nax2 = ax1.twinx()\nplt.plot(train_time_to_failure_small, color='g')\nax2.set_ylabel('time_to_failure', color='g')\nplt.legend(['time_to_failure'], loc=(0.875, 0.9))\nplt.grid(False)\n\ndel train_acoustic_data_small\ndel train_time_to_failure_small","0d2af3c8":"x_train['seismic'] = x_train.average.diff()\ntrain_seismic = x_train['seismic']","efe144bd":"nlags=13  #define number of lags to plot on ACF\/PACF plots\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = tsaplots.plot_acf(train_seismic.dropna(), lags=nlags, ax=ax1,title='Autocorrelation of Seismic Data')\nplt.xticks(list(range(0,nlags)))\n\nax2 = fig.add_subplot(212)\nfig = tsaplots.plot_pacf(train_seismic.dropna(), lags=nlags, ax=ax2,title='Partial Autocorrelation of Seismic Data')\nplt.xticks(list(range(0,nlags)))\nplt.xlabel('Lag-k')\nplt.show()","c0e17f22":"train_seismic.dropna(inplace=True)","a3970c83":"fig=plt.figure(figsize=(16,6))\n\nax1=plt.subplot(121)\nfig=sns.distplot(train_seismic,bins=200,ax=ax1)\nplt.title('Distribution of Seismic Data')\n\nax2=plt.subplot(122)\nfig=  qqplot(train_seismic,fit=True,line='45',ax=ax2)\nplt.title('Initial Q-Q plot for Seismic Data')\n\nplt.show()","06174f74":"#Jarque-Bera test for normality\nval,p=stats.jarque_bera(train_seismic)\n\nprint('Jarque-Bera Test Results:\\nStatistics = {}\\np-value = {}'.format(val,p))","bc02f43e":"# Ljung-box test for auto-correlation\n_,p=acorr_ljungbox(train_seismic,lags=10)\nprint('Ljung-Box test p-values for 10-lags:\\n',p)","3f18f381":"test_stat,pval,usedlag,_,CI=adfuller(train_seismic,regression='c',autolag='BIC')[:5]\nprint('Augmented Dickey Fuller test results:')\nprint('Test Statistics:',test_stat)\nprint('p-value:',pval)\nprint('Used Lags:',usedlag)\nprint('Critical Values:')\nfor key, value in CI.items():\n    print('\\t%s: %.3f' % (key, value))","7b47b071":"x_train.to_csv(\"x_train_105.csv\")\ny_train.to_csv(\"y_train_105.csv\")","6b6040c5":"#let's prepare our data\nseg_length = 50000\ntotal_samples = int(np.floor((train.shape[0]) \/ seg_length))\n\n#we will be using a total of nine different features as given below for making our predictions\ncols = ['average', 'std'] #our features used for the prediction\nx_train = pd.DataFrame(index = range(total_samples), columns = cols, dtype = np.float64) #an empty dataframe holding our feature values\ny_train = pd.DataFrame(index = range(total_samples), columns = ['time_to_failure'], dtype = np.float64) #an empty dataframe holding our target labels","788dc4fe":"for value in tqdm(range(total_samples)):\n    sample = train.iloc[value*seg_length : value*seg_length + seg_length]\n    x = sample['acoustic_data'].values\n    y = sample['time_to_failure'].values[-1]\n    \n    y_train.loc[value, 'time_to_failure'] = y\n    \n    x_train.loc[value, 'average'] = x.mean()\n    x_train.loc[value, 'std'] = x.std()","42c89cb0":"train_acoustic_data_small = x_train['average']\n\nfig, ax1 = plt.subplots(figsize=(16, 8))\nplt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\nplt.plot(train_acoustic_data_small, color='b')\nax1.set_ylabel('acoustic_data', color='b')\nplt.legend(['acoustic_data'])\nplt.grid(False)\n\ndel train_acoustic_data_small","74304095":"y_train.shape","dcbc012c":"nlags=60  #define number of lags to plot on ACF\/PACF plots\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = tsaplots.plot_acf(y_train, lags=nlags, ax=ax1,title='Autocorrelation of Seismic Data')\nplt.xticks(list(range(0,nlags)))\n\nax2 = fig.add_subplot(212)\nfig = tsaplots.plot_pacf(y_train, lags=nlags, ax=ax2,title='Partial Autocorrelation of Seismic Data')\nplt.xticks(list(range(0,nlags)))\nplt.xlabel('Lag-k')\nplt.show()","ddcd3be3":"train_main = train.values[::6000]","dd394fab":"train_main = pd.DataFrame(train_main, columns=['seismic','ttf'])\ntrain_main.head()","8427945a":"train_acoustic_data_small = train_main['seismic']\ntrain_time_to_failure_small = train_main['ttf']\n\nfig, ax1 = plt.subplots(figsize=(16, 8))\nplt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\nplt.plot(train_acoustic_data_small, color='b')\nax1.set_ylabel('acoustic_data', color='b')\nplt.legend(['acoustic_data'])\nax2 = ax1.twinx()\nplt.plot(train_time_to_failure_small, color='g')\nax2.set_ylabel('time_to_failure', color='g')\nplt.legend(['time_to_failure'], loc=(0.875, 0.9))\nplt.grid(False)\n\ndel train_acoustic_data_small\ndel train_time_to_failure_small","d9677383":"train_lr = train_main[['seismic']]\ntarget_lr = train_main[['ttf']]\nprint(train_lr.shape)\nprint(target_lr.shape)","5ea6e889":"plt.plot(train_main.ttf.diff())","3f767d4b":"lr = LinearRegression()\nmodel = lr.fit(train_lr,target_lr)\npredict = model.predict(train_lr)\nresiduals = model.predict(train_lr) - target_lr","7337d227":"mean_absolute_error(target_lr, predict)","94c90436":"'''fig = plt.figure(figsize=(16,10))\nnlags = 15\nax1 = plt.subplot(2, 2, 1)\nfig = tsaplots.plot_acf(residuals, lags=nlags, ax=ax1,title='ACF for residuals')\nplt.xticks(list(range(0,nlags)))\n\nax2 = plt.subplot(2, 2, 2)\nfig = tsaplots.plot_pacf(residuals, lags=nlags, ax=ax2,title='PACF for residuals')\nplt.xticks(list(range(0,nlags)))\nplt.xlabel('Lag-k')\nplt.show() '''","013771d0":"model = SARIMAX(train_main.ttf, order=(1,0,0), exog=train_main[['seismic']])\nresult = model.fit()\nresult.summary()","a0cdf27c":"sample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")\nsample_submission.shape","17727645":"submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id')\nX_test = pd.DataFrame(columns=train_main.columns, dtype=np.float64, index=submission.index)","ce83c476":"test_result = []","517cffd6":"for seg_id in tqdm(X_test.index):\n    test = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    pred_uc = result.get_forecast(steps = len(test), exog=test[['acoustic_data']])\n    test_result.append(max(pred_uc.predicted_mean))","259486c3":"test_result_submission = pd.DataFrame(test_result).T","19df7ed1":"test_result_submission = test_result_submission.T","a75b8216":"test_result_submission.to_csv(\"submission\")","246968c6":"print(test_result_submission[:50])","9e032cf3":"print(test_result_submission[50:100])","00da9251":"print(test_result_submission[100:150])","cdeebe66":"print(test_result_submission[150:200])","d5d31b49":"print(test_result_submission[200:250])","eb339098":"print(test_result_submission[250:300])","135e78fa":"print(test_result_submission[300:350])","c47de3e9":"# Building a Time Series Regression Model","8bcf3f8c":"Null Hypothesis (H0): If accepted, it suggests the time series has a unit root, meaning it is non-stationary. It has some time dependent structure.   \nAlternate Hypothesis (H1): The null hypothesis is rejected; it suggests the time series does not have a unit root, meaning it is stationary. It does not have time-dependent structure. We interpret this result using the p-value from the test.    \nA p-value below a threshold (such as 5% or 1%) suggests we reject the null hypothesis (stationary), otherwise a p-value above the threshold suggests we accept the null hypothesis (non-stationary).  \np-value > 0.05: Accept the null hypothesis (H0), the data has a unit root and is non-stationary.     \np-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.    \n\n\nRunning the test statistic value of -26.753. As per ADF statistic we can see that our statistic value of -26.753 is less than the value of -3.432 at 1%.\nThe p-value is < 0.05.\nComparing the p-value and test statistic to the critical values, it looks like we would have to Reject the null hypothesis (H0),  the data does not have a unit root and is stationary.","a6db19be":"# Taking difference of the dataset and the preparing the data.","e3410773":"# Preparing and exploring data using average and std devation."}}