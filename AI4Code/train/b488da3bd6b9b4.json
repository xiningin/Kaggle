{"cell_type":{"e93dabc7":"code","e848813f":"code","a9162816":"code","f472791a":"code","85002c26":"code","ee1eff4c":"code","2e354d28":"code","6459b563":"code","5fbdf1c4":"code","7422dc4b":"code","0ff1ee18":"code","b7962a25":"code","450987cc":"code","2b10d68f":"code","b8e2b51a":"code","d3b1ea2c":"code","9285c296":"markdown","3748c7d8":"markdown","883b2b30":"markdown","d40293db":"markdown","aa79afb7":"markdown","f5a7317c":"markdown","b4927154":"markdown","ddf53f49":"markdown","76e77f91":"markdown","6806c283":"markdown","7a26413b":"markdown","57e32e2b":"markdown","ba84cfe2":"markdown","bd9cda5b":"markdown","5a0ee0ea":"markdown","291bf6bc":"markdown","b9a3e89f":"markdown"},"source":{"e93dabc7":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\nfrom tensorflow.keras import optimizers\nfrom keras.utils.np_utils import to_categorical\n\nimport os","e848813f":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","a9162816":"print(train.shape)\ntrain.head()","f472791a":"# The 'label' column is separated from the rest in the training set\n\nlabel = train['label'].to_numpy()\ntrain['label'].value_counts().plot(kind='bar')\ntrain = train.drop(columns=['label']).to_numpy()\ntest = test.to_numpy()\n\n# The reshaping is important as need to put it in form of an image of dimension 28x28.\n# The extra 1 denotes it is an gray scale image. For an RGB image it would be 3\ntrain=np.reshape(train,(42000,28,28,1))\ntest=np.reshape(test,(28000,28,28,1))","85002c26":"#Visualizing few random digits from the training set\n\nfig=plt.figure(figsize=(10, 4))\ncolumns = 6\nrows = 1\nfor i in range(columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    plt.axis('off')\n    img1 = train[i+1000]\n    plt.imshow(np.squeeze(img1,axis=2), cmap=\"gray\")","ee1eff4c":"#Here I have used the second method, the first method is equally applicable:\n\nmeu = train.mean()\nsig = train.std()\ntrain = (train - meu)\/sig\n\nmeu = test.mean()\nsig = test.std()\ntest = (test - meu)\/sig","2e354d28":"print(\"Labels before one-hot encoding:\")\nprint(label[5:8])\nprint(\"Labels after one-hot encoding:\")\nprint(to_categorical(label)[5:8])\n\nlabel = to_categorical(label)","6459b563":"# Spilitting the training set to get validation results\n\nX_train, X_val, Y_train, Y_val = train_test_split(train, label, test_size=0.1, random_state=0)","5fbdf1c4":"model = Sequential()\n\nmodel.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2))\nmodel.add(Conv2D(64,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dense(10,activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel.summary()","7422dc4b":"model.fit(X_train,Y_train, epochs=10, validation_data=(X_val,Y_val))","0ff1ee18":"result = model.evaluate(X_val, Y_val, batch_size = 32)\nprint(\"Loss on validation: %f \\nAccuracy on validation: %f \" %(result[0] ,result[1]*100))","b7962a25":"ylabel = model.predict_classes(X_val)\nytest = [np.argmax(y, axis=None, out=None) for y in Y_val]\nconf_matrix = confusion_matrix(ytest, ylabel)\nsns.heatmap(conf_matrix, cmap=\"YlGnBu\",annot=True, fmt='g')\nplt.xlabel('predicted value')\nplt.ylabel('actual value')","450987cc":"#Displaying the picture along with the predictions\n\nfig=plt.figure(figsize=(15, 6))\ncolumns = 6\nrows = 3\nfor i in range(columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    plt.axis('off')\n    img1 = X_val[i]\n    value ='%1.0f'%(ylabel[i])\n    plt.text(5, 25,value,color='black',fontsize=12,bbox=dict(facecolor='yellow'))\n    plt.imshow(np.squeeze(img1,axis=2), cmap=\"gray\")","2b10d68f":"# Let me print both the prediction and the actual values on \n# the images which will help in better visualisation\n\ny_mis = [i for i in range(len(ytest)) if ytest[i]!=ylabel[i]]\nprint(y_mis) #indices of the mis-classifications\n\nfig=plt.figure(figsize=(15, 6))\ncolumns = 6\nrows = 3\nx=0\nfor i in range(columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    plt.axis('off')\n    img1 = X_val[y_mis[x]]\n    predicted_value ='%1.0f'%(ylabel[y_mis[x]])\n    plt.text(5, 25,predicted_value,color='black',fontsize=12,bbox=dict(facecolor='yellow'))\n    actual_value ='%1.0f'%(ytest[y_mis[x]])\n    plt.text(20, 25,actual_value,color='white',fontsize=12,bbox=dict(facecolor='green'))\n    plt.imshow(np.squeeze(img1,axis=2), cmap=\"gray\")\n    x=x+1","b8e2b51a":"img=X_val[8]\nfig=plt.figure(figsize=(2,2))\nplt.imshow(np.squeeze(img,axis=2), cmap=\"gray\")\nplt.show()\n\nimg = np.expand_dims(img, axis=0)\nconv1_output = Model(inputs=model.input, outputs=model.get_layer('conv2d').output)\nconv2_output = Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\nconv1_features = conv1_output.predict(img)\nconv2_features = conv2_output.predict(img)\n\nimport matplotlib.image as mpimg\n\nfig=plt.figure(figsize=(14,7))\ncolumns = 8\nrows = 4\n\nprint(\"Output for each filter of first Convolution Layer\")\nfor i in range(columns*rows):\n    #img = mpimg.imread()\n    fig.add_subplot(rows, columns, i+1)\n    plt.axis('off')\n    plt.title('filter'+str(i))\n    plt.imshow(conv1_features[0, :, :, i], cmap='gray')\nplt.show()\n\nfig=plt.figure(figsize=(14,7))\nprint(\"Output for each filter of second Convolution Layer\")\nfor i in range(columns*rows):\n    #img = mpimg.imread()\n    fig.add_subplot(rows, columns, i+1)\n    plt.axis('off')\n    plt.title('filter'+str(i))\n    plt.imshow(conv2_features[0, :, :, i], cmap='gray')\nplt.show()","d3b1ea2c":"answers = model.predict_classes(test, verbose=0)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(answers)+1)),\"Label\": answers})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","9285c296":"The plot above shows the occurence of each of the digits in the training set. \n\nThere is not much of a difference between frequency of each of the digit. So, the dataset can be assumed to be not skewed and therefore good.","3748c7d8":"#### Inference from above output:\n\nIt can be seen that the first layer of convolution observes edge features or backgroud or sudden changes that can be obtained by certain well known image-processing convolution kernels such as sobel or laplacian. \n\nHowever, the second convolution layer observes edges and corners which cannot be explained very well. And this is true if we go even further the convolution output cannot be explained but they capture relevant feature which makes CNN very useful for image classification","883b2b30":"### Checking some mis-classifications:\n\nAs most of the results are correct let us check some incorrect predictions that were being made and we might be able to figure out the reason.\n","d40293db":"### Data Visualization:","aa79afb7":"##### Displaying some of the predictions:","f5a7317c":"### Visualising the output:\n\nLet us check the Confusion Matrix which will give us the idea of the predictions.","b4927154":"Thankyou for reading till the end. If it has helped you understand Convolution please concider upvoting. Thankyou.","ddf53f49":"##### One-Hot encoding:\n\nIt is popular way to categorising data and is widely used whenever we do classification for more than 2 classes but is equally appliable for binary(2 class) classification as well.\n\nA one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the n-th digit will be represented as a vector which is 1 in the n-th dimension.\n\nIn this problem, since we classify 10 digits(0 to 9) we have 10:\n\nFor example, 3 would be represented as [0,0,0,1,0,0,0,0,0,0] ","76e77f91":"### Submitting Predictions to Kaggle:","6806c283":"### Visualising Convolution Layers:\n\nLet us see how the Convolution layers work to produce a classification","7a26413b":"### Reading the data from Input folder:","57e32e2b":"## Comprehensive beginners guide to CNN:\n\nCNN(Convolution Neural Networks) are very popular and well used specially when it comes to pattern or shape recognitions in images. \n\nSince, this problem asks for a hand-written digit recognition or in other words pattern recognition I have used CNN. There are several advantages of using CNN which are described later and are easy to use. I have used a Keras model. \n\nI hope this will give a good idea of how Convolution Neural Nets work.","ba84cfe2":"### Data Preprocessing:\n\n##### Normalizing:\nThis is a very important step in any image or feature based classification. \nWithout normalisation of data some features get much more importance to others leading to lower accuracy compared to when normalized.\n\nThere are generally 2 very popular ways of normalizing:\n\ni) Dividing the values with the maximum value that can occur (for gray scale it is 255) --\n\n      This will lead values from 0 to 1\n      \nii) Subtracting the mean of the values and then dividing it with the standard deviation --\n\n      This will lead values from -1 to 1","bd9cda5b":"As we can see above that the mis-classifications are very debatable as they could have been predicted either ways even with human eyes.","5a0ee0ea":"### Analyzing the data:","291bf6bc":"## Modelling the CNN:\n\n##### Design idea:\n\nDesigning a CNN is a very important step towards classification result.\n\nA common practice in CNN is \"Increase the Dimension - Reduce the size\"\n\nHere, dimension is the number of channels. Initially it was 1(gray-scale), after first Convolution I am making it 32 and then I am making it 64\n\n##### Placing Layers:\n\nA CNN architecture always looks like a repeatation of Convolution-Activation-Pooling Combination followed by Dense and Dropout(optional) layers for the final classification.\n\n##### Choosing values:\n\nThe choice of loss function is very important. In this question, since I am performing categorisation I will be choosing \"categorical_cross entropy\". There are many more options which have there special uses.\n\nThe activation of the final layer is chosen as \"Softmax\" since we break it into 10 categories(with each having its own prediction). If the output layer had only 1 neuron then \"Softmax\" is irrelavant. (You can try training and see the results)","b9a3e89f":"### Importing libraires and packages:"}}