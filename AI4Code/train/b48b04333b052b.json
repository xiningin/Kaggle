{"cell_type":{"db037fef":"code","a2169886":"code","da4110a6":"code","841b0d91":"code","96d9228f":"code","61cf01fc":"code","695a5679":"code","859b9318":"code","94b3aaaf":"code","b5060d74":"code","71ab5fd5":"code","5678ca6a":"code","1820cb08":"code","d48b0eac":"code","4ee1a269":"markdown","8ae61309":"markdown","6decc13a":"markdown","d361850f":"markdown","0bb56db9":"markdown","7ab85f4f":"markdown","0cf53dd3":"markdown","179aa027":"markdown"},"source":{"db037fef":"import numpy as np # linear algebra\nimport pandas as pd","a2169886":"import os\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nimport torch\nfrom torch import device\nimport torch.nn as nn\nimport cv2\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","da4110a6":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","841b0d91":"direc= '..\/input\/cats-faces-64x64-for-generative-models\/'","96d9228f":"print(os.listdir(direc+ '\/cats')[:5])\n","61cf01fc":"image_size = 64\nbatch_size = 128\nlatent_size= 128\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n\ntrain = ImageFolder(direc, transform=tt.Compose([ tt.Resize(image_size),\n                                                        tt.CenterCrop(image_size),\n                                                        tt.ToTensor(),\n                                                        tt.Normalize(*stats)]))\n \ntrain_dl = DataLoader(train, batch_size, shuffle=True, num_workers=3, pin_memory=True) #For loading data into batches","695a5679":"generator = nn.Sequential(\n    # in: latent_size x 1 x 1\n\n    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # out: 512 x 4 x 4\n\n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # out: 256 x 8 x 8\n\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # out: 128 x 16 x 16\n\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # out: 64 x 32 x 32\n\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh())\n    # out: 3 x 64 x 64\n","859b9318":"discriminator = nn.Sequential(\n    # in: 3 x 64 x 64\n\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 64 x 32 x 32\n\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 128 x 16 x 16\n\n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 256 x 8 x 8\n\n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 512 x 4 x 4\n\n    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    # out: 1 x 1 x 1\n\n    nn.Flatten(),\n    nn.Sigmoid())","94b3aaaf":"def denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]","b5060d74":"#To save the samples produced during epochs\n\nsample_dir = 'generated'\nos.makedirs(sample_dir, exist_ok=True)\n\ndef save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors).to(device)\n    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","71ab5fd5":"def train_discriminator(real_images, opt_d):\n    \n    # Clear discriminator gradients\n    opt_d.zero_grad()\n\n    # Pass real images through discriminator\n    real_preds = discriminator(real_images).to(device) #real images\n    real_targets = torch.ones(real_images.size(0), 1).to(device) #setting targets as 1\n    real_loss = F.binary_cross_entropy(real_preds, real_targets) #getting the loss\n    real_score = torch.mean(real_preds).item()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1).to(device) #generating the random noices for input image\n    fake_images = generator(latent).to(device)  #getting the fake images\n\n    # Pass fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1).to(device) #setting 0 as target for fake images\n    fake_preds = discriminator(fake_images).to(device)  #getting the predictions for fake images\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)  #Comparing the two scores through loss\n    fake_score = torch.mean(fake_preds).item()\n\n    # Update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    return loss.item(), real_score, fake_score","5678ca6a":"def train_generator(opt_g):\n    \n    # Clear generator gradients\n    opt_g.zero_grad()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1,1).to(device) #random noice\n    fake_images = generator(latent).to(device) #fake images generated\n    \n    # Try to fool the discriminator\n    preds = discriminator(fake_images).to(device) #getting the predictions of discriminator for fake images\n    targets = torch.ones(batch_size, 1).to(device) #setting 1 as targets so the discriminator can be fooled\n    loss = F.binary_cross_entropy(preds, targets) #comparing\n    \n    # Update generator weights\n    loss.backward()\n    opt_g.step()\n    \n    return loss.item(),latent","1820cb08":"def fit(epochs, lr, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # Create optimizers\n    opt_d = torch.optim.Adam(discriminator.to(device).parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.to(device).parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            \n            # Train discriminator\n            real_images= real_images.to(device)\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            \n            # Train generator\n            loss_g, latent = train_generator(opt_g)\n            \n        # Record losses & scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # Log losses & scores (last batch)\n        print(\"Epoch [{}\/{}], loss_g: {}, loss_d: {}, real_score: {}, fake_score: {}\".format(\n            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n    \n        # Save generated images\n        save_samples(epoch+start_idx, latent, show=False)\n    \n    return losses_g, losses_d, latent, fake_scores","d48b0eac":"model = fit(epochs=10, lr=0.0002).to(device) #set epochs to 40 or more for better results","4ee1a269":"### In this notebook, Ive tried to implement a Deep Convolutional GAN or DCGAN from scratch by defining a Generator, a Discriminator and training them for maintaining the balance of universe :)\n\n### [This](https:\/\/arxiv.org\/pdf\/1511.06434.pdf) paper is followed in the notebook for hyperparameter tuning and loss function maintainance.\n\n### I've used cat images dataset to train the model. Hope you'll find it insightful","8ae61309":"Generator intakes a s tensor of size N*(128x1x1) and outputs a (3x64x64) Tensor which inturn is an image. Since the GAN training are unstable as they start off with random noices, we require batchnormalization so the outputs remain normalized and under control.","6decc13a":"### Function for training the generator...Notice it doesnt require any input as it works with random noices.","d361850f":"The data is normalized to mean=0 and SD= 0.5 so as to fit the data in (-1,1) range. This is useful for generator as it uses tanh function in the last layer. Apart from that, image size is reduced to 64x64 considering the computational cost. ","0bb56db9":"Discriminator intakes the image outputs a tensor of size (1x1x1) providing a score between 0-1 according to the probability of real and fake.","7ab85f4f":"### Function for training the discriminator","0cf53dd3":"A denorm function to denormalize the images produced by generator to make it understandable to human eyes.","179aa027":"![image.png](attachment:image.png)\n\nA dummy model for generator is shown here. Our model somewhat looks like this but is different in number of channels at some layers. The generator model is the most important part in the GAN as it originally generates the images. Sometimes, when GAN gets fully trained, the discriminator is frozen.\n\n### Equation to be followed\n\nmin\nG\nmax\nD\nV (D, G) = Ex\u223cpdata(x)\n[log D(x)] + Ez\u223cpz(z)\n[log(1 \u2212 D(G(z)))]\n\nFrom Discriminator's perspective, we need to maximize the upper equation and from Generator's view, we train to minimized the second log term.\nMore literature and better understanding can be achieved by following [this](https:\/\/arxiv.org\/pdf\/1406.2661.pdf), the original GAN paper."}}