{"cell_type":{"aff24eea":"code","8333bdb4":"code","f85f9316":"code","a1539811":"code","6b1215e1":"code","cb325356":"code","122e0e6b":"code","d8aa2883":"code","1cc068c1":"markdown","2b5e69f8":"markdown"},"source":{"aff24eea":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport gc\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\n\nfrom keras.models import Model\n","8333bdb4":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission = submission.set_index('id')\n","f85f9316":"targets = pd.get_dummies(train['target'])","a1539811":"def custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss\n\ncce = tf.keras.losses.CategoricalCrossentropy()\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_custom_metric', min_delta=1e-05, patience=5, verbose=1,\n    mode='min', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_custom_metric', factor=0.7, patience=2, verbose=1,\n    mode='min')","6b1215e1":"def attention_model():\n    attention_inputs = layers.Input(shape = (75,))\n    embed = layers.Embedding(360, 8)(attention_inputs)\n    embed = layers.Flatten()(embed)\n    hidden = layers.Dropout(0.3)(embed)\n    hidden = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='selu', kernel_initializer=\"lecun_normal\"))(hidden)\n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='relu'))(output) \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden, output]))\n        \n    attention_outputs = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(output) \n    \n    return attention_inputs,attention_outputs","cb325356":"def model_NN_by_column():\n    model_NN_by_column_inputs = layers.Input(shape = (75,))\n    b = layers.Reshape((-1,1))( model_NN_by_column_inputs)\n    b = layers.Embedding(360, 8,input_length = 75)(b)\n    embed = layers.Flatten()(b)\n    hidden = layers.Dropout(0.3)(embed)\n    hidden = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='selu', kernel_initializer=\"lecun_normal\"))(hidden)\n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='relu'))(output) \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden, output]))\n    \n    model_NN_by_column_outputs = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(output) \n    \n    return model_NN_by_column_inputs,model_NN_by_column_outputs","122e0e6b":"oof = np.zeros((train.shape[0],9))\npred = np.zeros((test.shape[0],9))\n\nN_FOLDS = 10\nSEED = 2021\nEPOCH = 50\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train,train.iloc[:,-1])):\n    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n\n    X_train = train.iloc[:,1:-1].iloc[tr_idx]\n    y_train = targets.iloc[tr_idx]\n    X_test = train.iloc[:,1:-1].iloc[ts_idx]\n    y_test = targets.iloc[ts_idx]\n\n    K.clear_session()\n    \n    #---------- Base API collection ---------------------\n    \n    attention_inputs, attention_ouputs = attention_model()\n    model_NN_by_column_inputs,model_NN_by_column_outputs = model_NN_by_column()\n\n    #---------- Concatenation Layer --------------------  \n        \n    z = layers.Concatenate(axis=1)(\n                    [attention_ouputs,\n                    model_NN_by_column_outputs,\n                    ])\n    out = layers.Dense(9, activation = 'softmax', name = 'out')(z)\n    \n     #----------Model creation---------------------\n    \n    model_merged = Model(\n                    inputs=[\n                    attention_inputs,\n                    model_NN_by_column_inputs,\n                    ], \n                    outputs=out, \n                    name=\"model_merged\")\n     #----------Model compile---------------------- \n    \n    model_merged.compile(\n                    tf.keras.optimizers.Adam(learning_rate=2e-4),\n                    loss='categorical_crossentropy',  \n                    metrics=custom_metric)\n\n    #----------Model fit--------------------------- \n    \n    model_merged.fit([X_train,\n                    X_train],\n                    y_train,\n                    validation_data = ([\n                    X_test,\n                    X_test,\n                    ],y_test),\n                    batch_size = 256,\n                    epochs = EPOCH,\n                    verbose = 1,\n                    callbacks = [es,plateau])\n    \n    #----------Model prediction----------------------\n    \n    oof[ts_idx] = model_merged.predict([X_test,\n                                        X_test])\n    score = log_loss(y_test, oof[ts_idx])\n    print(f\"\\nFOLD {fold} Score {score}\\n\")\n    pred += model_merged.predict([test.iloc[:,1:],\n                                  test.iloc[:,1:]]) \/ N_FOLDS\n\nscore = log_loss(targets, oof)\nprint(f\"Score total {score}\\n\")   ","d8aa2883":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\npred_embedding = pred\nsubmission['Class_1']=pred_embedding[:,0]\nsubmission['Class_2']=pred_embedding[:,1]\nsubmission['Class_3']=pred_embedding[:,2]\nsubmission['Class_4']=pred_embedding[:,3]\nsubmission['Class_5']=pred_embedding[:,4]\nsubmission['Class_6']=pred_embedding[:,5]\nsubmission['Class_7']=pred_embedding[:,6]\nsubmission['Class_8']=pred_embedding[:,7]\nsubmission['Class_9']=pred_embedding[:,8]\nsubmission.to_csv(\"concatenated4.csv\", index=False)","1cc068c1":"![image.png](attachment:d674a941-62dc-47f0-85f1-76c817d9e972.png)","2b5e69f8":"<h3> Adapted from Alexander Ryzhkov python translation of Oscar Villarreal Escamilla Notebook"}}