{"cell_type":{"b2743fef":"code","0fbb5546":"code","da6a7a85":"code","6b247e94":"code","263aadc0":"code","550b9652":"code","8672bbe5":"code","28ce2743":"code","ddddf178":"code","8627b3d4":"code","40209758":"code","618e1895":"code","ad5e42f4":"code","4ebb31c9":"code","5340f0f8":"code","d28a39cf":"code","32a60d22":"code","581c2af6":"code","acf6884a":"code","8f53950c":"code","5c4f7c83":"code","22afbffc":"code","222eeb18":"code","f2bb95f5":"code","08b2f587":"code","ca443147":"code","58c7d0ee":"code","f19ce3b6":"code","5538f935":"code","339bec04":"code","68ccd2f3":"code","6a26129a":"code","7d67d0c5":"code","32fce469":"code","f12829e7":"code","abb30bb9":"code","cde2f0e8":"code","620984cb":"code","eebe3f3c":"code","5423b471":"code","bf64b53e":"code","d1311f3e":"code","07809dc0":"markdown","651ffca9":"markdown","d30e39a1":"markdown","21bd1c7d":"markdown","f7a511a5":"markdown","a5106a41":"markdown","a6dc9754":"markdown","e9b53801":"markdown","6313b6a9":"markdown","97fafd03":"markdown","4437cf87":"markdown","cca448a0":"markdown","975b7ca0":"markdown","4ae23d0a":"markdown","8dfdd935":"markdown","9bdbb978":"markdown"},"source":{"b2743fef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fbb5546":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder","da6a7a85":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_df.head()\n","6b247e94":"null_values = pd.isnull(train_df).sum()\nnull_values","263aadc0":"train_df.boxplot(column=[\"Age\"], grid=True)\nplt.show()","550b9652":"not_null_index = pd.notnull(train_df[\"Age\"])\ntrain_df = train_df[not_null_index]\nage_median = train_df[\"Age\"].median()\nnull_index = pd.isnull(train_df[\"Age\"])\ntrain_df.loc[null_index, \"Age\"] = age_median","8672bbe5":"null_values = pd.isnull(train_df).sum()\nnull_values","28ce2743":"train_df = train_df.drop(columns=\"Cabin\")\n","ddddf178":"print(train_df[\"Embarked\"].value_counts())  # S is the mode\n\n","8627b3d4":"null_index = pd.isnull(train_df[\"Embarked\"])\ntrain_df.loc[null_index, \"Embarked\"] = \"S\"","40209758":"null_values = pd.isnull(train_df).sum()\nnull_values","618e1895":"train_df = train_df.drop(columns=\"PassengerId\")\ntrain_df = train_df.drop(columns=\"Name\")\ntrain_df = train_df.drop(columns=\"Ticket\")","ad5e42f4":"train_df.head()","4ebb31c9":"train_encoded = pd.get_dummies(train_df, prefix= [\"SibSp\", \"Parch\", \"Embarked\"], columns= [\"SibSp\", \"Parch\", \"Embarked\"])\ntrain_encoded[\"Sex\"] = LabelEncoder().fit_transform(train_encoded.Sex)\ntrain_encoded.head()","5340f0f8":"train_df = train_encoded\ntraining_X = train_df.iloc[:, 1:]\ntraining_y = train_df.iloc[:, 0]\nfrom sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(training_X, training_y, test_size=0.3, random_state=40)\n","d28a39cf":"def normalize(x, col_max, col_min):\n    if x == -1:\n        return np.nan\n    else:\n        return ((x - col_min) \/ (col_max - col_min))","32a60d22":"train_X = train_X.loc[:]\ntrain_X[\"Age\"] = train_X[\"Age\"].apply(lambda x: normalize(x, train_X[('Age')].max(), train_X[('Age')].min()))\ntrain_X[\"Fare\"] = train_X[\"Fare\"].apply(lambda x: normalize(x, train_X[('Fare')].max(), train_X[('Fare')].min()))\n\ntest_X = test_X.loc[:]\ntest_X[\"Age\"] = test_X[\"Age\"].apply(lambda x: normalize(x, test_X[('Age')].max(), test_X[('Age')].min()))\ntest_X[\"Fare\"] = test_X[\"Fare\"].apply(lambda x: normalize(x, test_X[('Fare')].max(), test_X[('Fare')].min()))","581c2af6":"test_X.head()","acf6884a":"train_X.head()","8f53950c":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=9, metric= \"euclidean\")\nknn.fit(train_X, train_y)\nknn_pred = knn.predict(test_X)","5c4f7c83":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\ncm = confusion_matrix(test_y, knn_pred)\naccuracy = accuracy_score(test_y, knn_pred)\ncm","22afbffc":"accuracy","222eeb18":"testing_file = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntesting_df = testing_file\ntesting_df.head()\n","f2bb95f5":"null_values = pd.isnull(testing_df).sum()\nnull_values","08b2f587":"testing_df.boxplot(column=[\"Age\"], grid=True)\nplt.show()","ca443147":"not_null_index = pd.notnull(testing_df[\"Age\"])\ntesting_nn = testing_df[not_null_index]\nage_median = testing_df[\"Age\"].median()\nnull_index = pd.isnull(testing_df[\"Age\"])\ntesting_df.loc[null_index, \"Age\"] = age_median","58c7d0ee":"null_values = pd.isnull(testing_df).sum()\nnull_values","f19ce3b6":"testing_df = testing_df.drop(columns=\"Cabin\")","5538f935":"testing_df.boxplot(column=[\"Fare\"], grid=True)\nplt.show()","339bec04":"not_null_index = pd.notnull(testing_df[\"Fare\"])\ntesting_nn = testing_df[not_null_index]\nfare_median = testing_nn[\"Fare\"].median()\nnull_index = pd.isnull(testing_df[\"Fare\"])\ntesting_df.loc[null_index, \"Fare\"] = fare_median","68ccd2f3":"null_values = pd.isnull(testing_df).sum()\nnull_values","6a26129a":"testing_df = testing_df.drop(columns=\"PassengerId\")\ntesting_df = testing_df.drop(columns=\"Name\")\ntesting_df = testing_df.drop(columns=\"Ticket\")","7d67d0c5":"testing_df.head()","32fce469":"testing_encoded = pd.get_dummies(testing_df, prefix= [\"SibSp\", \"Parch\", \"Embarked\"], columns= [\"SibSp\", \"Parch\", \"Embarked\"])\ntesting_encoded[\"Sex\"] = LabelEncoder().fit_transform(testing_encoded.Sex)\ntesting_encoded.head()","f12829e7":"testing_df = testing_encoded\ntesting_df = testing_df.loc[:]\ntesting_df[\"Age\"] = testing_df[\"Age\"].apply(lambda x: normalize(x, testing_df[('Age')].max(), testing_df[('Age')].min()))\ntesting_df[\"Fare\"] = testing_df[\"Fare\"].apply(lambda x: normalize(x, testing_df[('Fare')].max(), testing_df[('Fare')].min()))","abb30bb9":"testing_df.head()","cde2f0e8":"new_list = [train_X.columns, testing_df.columns]\nnew_list","620984cb":"testing_df = testing_df.drop(columns='SibSp_8')\ntesting_df = testing_df.drop(columns='Parch_9')","eebe3f3c":"knn_predictions = knn.predict(testing_df)","5423b471":"testing_file[\"Survived\"] = pd.Series(knn_predictions, index = testing_file.index)\ntesting_file","bf64b53e":"final_df = testing_file.filter(['PassengerId', 'Survived'], axis = 1)\nfinal_df.set_index('PassengerId')","d1311f3e":"final_df.to_csv(\"survival_predictions2.csv\", encoding='utf-8', index = False, header = True)","07809dc0":"# Importing The Dataset\nImport the Dataset and get a basic understanding of the data","651ffca9":"# Splitting into Training and Testing","d30e39a1":"Remove Cabin feature as has more then 30% of it's observations as missing values:","21bd1c7d":"Evident that whilst \"SibSp_8\" appears in the testing set, it does not appear in the training set.\nTheoretically by dropping this column, the algorithm should still have the ability to make an accurate prediction.","f7a511a5":"# Fitting the Nearest Neighbor Model","a5106a41":"# Applying to Test Data File","a6dc9754":"# Encoding Categoric\nAll nominal features encoded using One-Hot-Encoding and Ordinal Features encoded to preserve ordered relationship","e9b53801":"Impute Mode for Embarked Feature","6313b6a9":"# Define a normalisation function to be used on numerical features","97fafd03":"No missing values remain.","4437cf87":"# Missing Values\nDespite the fact that the k-NN algorithm can handle missing values, all missing values will be imputed for optimal performance.\nImputation rules followed will be:\n* Features with more then 30% missing values removed\n* Categoric Features: Mode Imputed\n* Numeric Features with Outliers: Median\n* Numeric Features without Outliers: Mean","cca448a0":"# Importing All Relevant and Used Packages","975b7ca0":"Boxplot indicates outliers, therefore impute median:","4ae23d0a":"# Using the same model as previously trained","8dfdd935":"**Age Missing Values**\nAs this is numeric, visualise the boxplot to see if outliers","9bdbb978":"# Irrelevant Features\nDrop all irrelevant Features"}}