{"cell_type":{"fd74899a":"code","6631ce85":"code","dab3b933":"code","3d156799":"code","df2102d8":"code","31c5cd4e":"code","cd612cb4":"code","0e276f97":"code","e86699d0":"code","23dcc24a":"code","87b156da":"code","3cb056bc":"markdown","95628a00":"markdown"},"source":{"fd74899a":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport random\nimport cv2\nimport tensorflow as tf\n\n#print(os.listdir('\/kaggle\/input\/landmark-recognition-2021'))","6631ce85":"path = '\/kaggle\/input\/landmark-recognition-2021'\nos.listdir(path)\n\ntrain_images = f'{path}\/train'\ndf_train = pd.read_csv(f'{path}\/train.csv')\ndf_train['path'] = df_train['id'].apply(lambda f: os.path.join('\/kaggle\/input\/landmark-recognition-2021\/train',f[0], f[1], f[2], f + '.jpg'))\n\ntest_images = f'{path}\/test'\ndf_test = pd.read_csv(f'{path}\/sample_submission.csv')\ndf_test['path'] = df_test['id'].apply(lambda f: os.path.join('\/kaggle\/input\/landmark-recognition-2021\/test',f[0], f[1], f[2], f + '.jpg'))\n\n# Defining the amount of classes and images in the training dataset.\nnr_classes = len(df_train[\"landmark_id\"].unique())\nnr_images = len(df_train)\n\n#print(\"Number of classes in training dataset: \", nr_classes)\n#print(\"Number of images in training dataset: \", nr_images)","dab3b933":"# Histogram of data distribution, to show the amount of images in each class.\n# One class goes higher than the histogram top, which is due to the class containing 6272 images.\n#hist = plt.figure(figsize = (10, 10))\n#ax = plt.hist(df_train[\"landmark_id\"], bins = df_train[\"landmark_id\"].unique())\n#plt.ylim([0, 100])\n#plt.show()","3d156799":"# Showing the number of classes containing 5 or less images in a class.\n# I am doing the same for classes contatining between 5 to 10 images.\n#classes = ax[0]\n#from0To5 = len(classes[classes <= 5])\n#from5To10 = len(classes[classes <= 10] - from0To5)\n#print(\"Number of classes with 0 to 5 images: \", from0To5)\n#print(\"Number of classes with 5 to 10 images: \", from5To10)","df2102d8":"# Here can a overall representation of the data distribution be seen\nValueCounts = df_train['landmark_id'].value_counts()\nValueCounts.describe()","31c5cd4e":"#Visualize 4 sample images from 4 random classes.\ndisplayImages = []\nfor i in range(0,4):\n    randomClass = df_train[df_train['landmark_id'] == ValueCounts.iloc[[np.random.randint(0, nr_classes)]].index[0]]\n    for j in range(0,4):\n        randomImages = randomClass.iloc[np.random.randint(0, len(randomClass))]\n        displayImages.append(randomImages)\n        \nplt.subplots(4, 4, figsize = (15, 10))\nfor i in range(len(displayImages)):\n    plt.subplot(4, 4, i + 1)\n    plt.axis('Off')\n    img = cv2.imread(displayImages[i][2])\n    plt.imshow(img)\n    plt.title(f'landmark id: {displayImages[i][1]} ', fontsize=8)","cd612cb4":"# Setting up hyperparameters and splitting training data into train and val\ndef imagePath(imgPath):\n    images = []\n    for imgFile in imgPath:\n        imgPic = cv2.imread(imgFile, 1)\n        images.append(cv2.resize(imgPic, (img_size, img_size)))\n    \n    return images\n\n# Hyperparameters\nepochs = 50\nbatch_size = 32\nimg_size = 128\ntrain_split = 0.7\nval_split = 0.2\nnrClasses = 120\n\n# Setting up dataset for training\nimgList = []\nlabels = []\ntemp_labels = []\n\ni = 0\nfor lbl in df_train['landmark_id'].unique():\n    if i == nrClasses:\n        break\n    if(len(df_train['path'][df_train['landmark_id'] == lbl].value_counts()) > 50 and # Try to change it to 25 to see if higher accuracy is achieved\n       len(df_train['path'][df_train['landmark_id'] == lbl].value_counts()) < 500): \n        for path in df_train['path'][df_train['landmark_id'] == lbl]: \n            imgList.append(path) \n            labels.append(lbl)\n            temp_labels.append(i)\n        i = i + 1\n\n# Random shuffle dataset, so it is no longer set up in classes\nshuff = list(zip(imgList, temp_labels))\nrandom.shuffle(shuff)\n\nimgList, lbls = zip(*shuff)\n\n# Preparing data to be split into train and val\nimgNr = round(len(imgList) * train_split)\n\ntrainImages = imgList[:imgNr]\nprint(\"Images being resized: \", len(trainImages))\ntrainData = imagePath(trainImages)\ntrainLabels = lbls[:imgNr]\n\nprint(\"Number of training images: \", len(trainData))\nprint(\"Number of training labels: \", len(trainLabels))\n\n# Setting images and labels to be split into x_train, y_tran, x_val and y_val\nxData = np.array(trainData) \/ 255\nyData = tf.keras.utils.to_categorical(trainLabels, num_classes = nrClasses)\n\nx_train, x_val, y_train, y_val = train_test_split(xData, yData, test_size = val_split, random_state = 101)\n\n# Setting up data generator\ndataGenerator = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip = False, \n                                                                vertical_flip = False, \n                                                                rotation_range = 0, \n                                                                zoom_range = 0.2, \n                                                                width_shift_range = 0, \n                                                                height_shift_range = 0, \n                                                                shear_range = 0, \n                                                                fill_mode = \"nearest\")\n\nopt = tf.optimizers.Adam(learning_rate = 0.001)\nopt2 = tf.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, \nepsilon = 1e-08, decay = 0.0001)","0e276f97":"# This a implementation of ResNet50. It also allows for experimentation with more layers by changing to RenNet101.\nResNet101 = tf.keras.applications.resnet.ResNet101(input_shape = (img_size, img_size, 3),\n                                                      include_top = False,\n                                                      weights = 'imagenet',\n                                                      pooling = 'avg')\n\n\ninputs = ResNet101.input\nflatten = tf.keras.layers.Flatten()(ResNet101.output)\ndropout1 = tf.keras.layers.Dropout(0.2)(flatten)\ndense1 = tf.keras.layers.Dense(units = 4096, activation = \"relu\")(dropout1)\ndropout2 = tf.keras.layers.Dropout(0.2)(dense1)\ndense2 = tf.keras.layers.Dense(units = 4096, activation = \"relu\")(dropout2)\ndropout3 = tf.keras.layers.Dropout(0.2)(dense2)\noutput = tf.keras.layers.Dense(units = nrClasses, activation = \"softmax\")(dropout3)\nmodel = tf.keras.Model(inputs = inputs, outputs = output)\n\nprint(model.summary())","e86699d0":"# Compile the network\nmodel.compile(optimizer = opt2, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n\n#es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model.fit(dataGenerator.flow(x_train, y_train, batch_size = batch_size), validation_data = (x_val, y_val), epochs = epochs)","23dcc24a":"# Plotting the performance of the model\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('ResNet50 Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()\n\n# Plot of loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('ResNet50 Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()","87b156da":"# Predictions of the model -> running model on test data\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn import metrics\n\ntestImages = imgList[len(trainImages):]\ntestImages = imagePath(testImages)\ntestLabels = lbls [len(trainLabels):]\n\ntestData = np.array(testImages) \/ 255\ntestPrediction = model.predict(dataGenerator.flow(testData, batch_size = batch_size))\n\ngoodAcc = []\nbadAcc = []\nconfidence = []\nfor i in testPrediction:\n    confidence.append(max(i))\n    goodAcc.append(np.argmax(i))\n    badAcc.append(np.argmax(i))\n\nprecision, recall, fscore, support = score(testLabels, goodAcc, labels = np.unique(goodAcc))\n\nprint(metrics.confusion_matrix(testLabels, goodAcc))\nprint(metrics.classification_report(testLabels, goodAcc, digits = 3))\n\nfor i in range(len(goodAcc)):\n    plt.axis('Off')\n    if (testLabels[i] == goodAcc[i]):\n        print(\"Perfect Label Match\")\n        title = ('True label: ' + str(testLabels[i]) + '_' + 'Predicted label: ' + str(goodAcc[i]) + '_' + 'confidence: ' + str(confidence[i]))\n        plt.title(title, fontsize = 10)\n        plt.imshow(testImages[i])\n        plt.show()\n        \n    elif(confidence[i] > 0.98):\n        print(\"High Confidence\")\n        title = ('True label: ' + str(testLabels[i]) + '_' + 'Predicted label: ' + str(goodAcc[i]) + '_' + 'confidence: ' + str(confidence[i]))\n        plt.title(title, fontsize = 10)\n        plt.imshow(testImages[i])\n        plt.show()\n    \n    elif(confidence[i] < 0.05):\n        print(\"Poor Confidence\")\n        title = ('True label: ' + str(testLabels[i]) + '_' + 'Predicted label: ' + str(goodAcc[i]) + '_' + 'confidence: ' + str(confidence[i]))\n        plt.title(title, fontsize = 10)\n        plt.imshow(testImages[i])\n        plt.show()","3cb056bc":"**Creating the CNN**","95628a00":"**Google Landmark Recognition 2021 VGIS Mini Project**\nThis notebook contains the material of the third exercise for the Research in VGIS course.\nThe notebook will go through the tasks of the exercise."}}