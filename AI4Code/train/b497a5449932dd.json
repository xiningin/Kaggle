{"cell_type":{"ccd38703":"code","4100ce4f":"code","2698fafe":"code","49d8e663":"code","ae3b7cd7":"code","c78ec38a":"code","adc954a4":"code","379fe2e3":"code","623657c4":"code","7f642277":"code","b4ba21d9":"code","536fbdff":"code","a029e85a":"code","fd34fb4e":"code","90e5d137":"code","7b373abe":"code","19396182":"code","4fb4c52f":"code","f820c018":"code","32013dea":"code","346ff65b":"code","831dd432":"code","ddac9055":"code","b6608cf4":"code","14913848":"code","31ba4719":"code","9de3762c":"code","26b85d70":"code","eb83d521":"code","70a73406":"code","6a8ad8f5":"code","f6dca3fc":"code","05a73b11":"code","e86b2709":"code","16f3e357":"code","7612c364":"markdown","1c24c228":"markdown","af79914b":"markdown","f4378dec":"markdown","a65fad4e":"markdown","3aa02ab2":"markdown","8835d63e":"markdown","6f8663b0":"markdown","689a4f27":"markdown","7eabe9c1":"markdown","aa7ab19d":"markdown","d8240cc5":"markdown","7b9016bd":"markdown","dd038483":"markdown","6c73f0a6":"markdown","f1df1713":"markdown","33bc0057":"markdown","3d45f1f7":"markdown","2f03e82d":"markdown","6b30a114":"markdown","3583b515":"markdown","e1511587":"markdown","4bbaad18":"markdown"},"source":{"ccd38703":"import time\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport seaborn as sns \nimport plotly.express as px\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\nimport os\nfrom geopy.distance import distance, geodesic\nimport plotly.express as px","4100ce4f":"os.listdir()","2698fafe":"train = pd.read_csv('..\/input\/atividade-regressao-PMR3508\/train.csv',index_col = ['Id'])\ntest = pd.read_csv('..\/input\/atividade-regressao-PMR3508\/test.csv',index_col = ['Id'])","49d8e663":"train.head()","ae3b7cd7":"train.shape","c78ec38a":"test.head()","adc954a4":"test.shape","379fe2e3":"#Aqui j\u00e1 conseguimos verificar que n\u00e3o existem dados nulos\ntrain.info()","623657c4":"test.info()","7f642277":"plt.figure(figsize=(12,10))\nsns.heatmap(train.corr(),annot = True)\nplt.show()","b4ba21d9":"fig = px.scatter_mapbox(train, lat=\"latitude\", lon=\"longitude\", color=\"median_house_value\", size=\"population\",\n                  color_continuous_scale=px.colors.sequential.Brwnyl, size_max=15, zoom=4,\n                  mapbox_style=\"carto-positron\")\nfig.show()","536fbdff":"SF = (37.779026, -122.419906)\nLA = (34.053691, -118.242766)\nSD = (32.717421, -117.162771)","a029e85a":"def dist(df):\n    casa = (df['latitude'],df['longitude'])\n    df['dist'] = min(geodesic(casa, SF).km, geodesic(casa, LA).km, geodesic(casa, SD).km)\n    \n    return df\ntrain = train.apply(dist, axis = 1)","fd34fb4e":"train.head()","90e5d137":"plt.figure(figsize=(12,10))\nsns.heatmap(train.corr(),annot = True)\nplt.show()","7b373abe":"train.drop(['longitude','latitude'],axis = 1,inplace = True)","19396182":"train['rooms\/house'] = train['total_rooms']\/train['households']\ntrain['bedrooms\/house'] = train['total_bedrooms']\/train['households']\ntrain['people\/house'] = train['population']\/train['households']\ntrain['people\/room'] = train['population']\/train['total_rooms']\ntrain['people\/bedroom'] = train['population']\/train['total_bedrooms']","4fb4c52f":"plt.figure(figsize=(12,10))\nsns.heatmap(train.corr(),annot = True)\nplt.show()","f820c018":"train.drop(['bedrooms\/house','people\/house','people\/room','people\/bedroom','total_rooms','total_bedrooms'],axis = 1, inplace = True)","32013dea":"train.head()","346ff65b":"test = test.apply(dist, axis = 1)\ntest['rooms\/house'] = test['total_rooms']\/test['households']\ntest.drop(['latitude', 'longitude','total_rooms','total_bedrooms'], axis = 1, inplace=True)","831dd432":"#verificando se esta tudo  certo\ntest.head()","ddac9055":"train.drop_duplicates(inplace = True, keep = 'first')\nfeatures = ['median_age', 'population', 'households', 'median_income', 'dist', 'rooms\/house']\nY = train['median_house_value']\nX = train[features]","b6608cf4":"#normalizando a base\npreprocessor = StandardScaler()\nX = preprocessor.fit_transform(X)","14913848":"model_KNN = KNeighborsRegressor(n_neighbors=20)","31ba4719":"cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)","9de3762c":"start = time.time()\nscore_KNN = cross_val_score(model_KNN, X, Y, cv = cv, scoring=\"neg_mean_squared_log_error\")\nstop = time.time()\ntime_KNN = stop - start\nRMSLE_KNN = ((-score_KNN)**0.5).mean()\nprint(\"RMSLE:\", RMSLE_KNN)\nprint(f\"Training time: {time_KNN}s\")","26b85d70":"model_RF = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)","eb83d521":"start = time.time()\nscore_RF = cross_val_score(model_RF, X, Y, cv = cv, scoring=\"neg_mean_squared_log_error\")\nstop = time.time()\ntime_RF = stop - start\nRMSLE_RF = ((-score_RF)**0.5).mean()\nprint(\"RMSLE:\", RMSLE_RF)\nprint(f\"Training time: {time_RF}s\")","70a73406":"model_RF.fit(X, Y)","6a8ad8f5":"X_test = test[features]\nX_test = preprocessor.transform(X_test)","f6dca3fc":"predictions = model_RF.predict(X_test)\npredictions","05a73b11":"df_sub = pd.DataFrame(test.index)\ndf_sub['median_house_value'] = predictions\ndf_sub.head()","e86b2709":"df_sub","16f3e357":"df_sub.to_csv(\"submission.csv\", index = False,index_label = 'Id')","7612c364":"# Predi\u00e7\u00e3o","1c24c228":"Primeiro iremos criar uma matriz de correla\u00e7\u00e3o","af79914b":"Agora vou preparar os dados para que possamos aplicar algumas regress\u00f5es diferentes e identificar a que performa melhor.","f4378dec":"Com essas novas an\u00e1lises, podemos criar outro mapa de correla\u00e7\u00e3o","a65fad4e":"# Data Prep","3aa02ab2":"#  Analise dos dados","8835d63e":"# Importando bibliotecas","6f8663b0":"# Aplicando algumas regress\u00f5es","689a4f27":"Aqui j\u00e1 conseguimos ver que as bases est\u00e3o com o shape correto, com a coluna objetivo n\u00e3o estando presente na base teste. Agora iremos verificar se existem linhas nulas e depois analisar a correla\u00e7\u00e3o entre os dados.","7eabe9c1":"Como nosso target \u00e9 o median_house_value , podemos ver que o median income \u00e9 o dado mais relevante para nossa an\u00e1lise.\nTodavia, existem dados que podemos gerar para criar mais correla\u00e7\u00f5es. Como pode ser visto pela ideia de outros alunos, existe a possibilidade de se criar uma correla\u00e7\u00e3o geografica a partir da latitude e longitude e verificar a distancia dos imov\u00e9is de pontos valorizados, como grandes cidades e o litoral.\n\nPara verificar visualmente essa distribui\u00e7\u00e3o, vamos utilizar um mapa de calor tendo como parametro de analise o median_house_value","aa7ab19d":" A partir do mapa j\u00e1 podemos verificar essa premissa de proximidade a grandes centros e do literal. Agora devemos criar a fun\u00e7\u00e3o para trasnformar a long e lat em uma unica coluna de dist\u00e2ncia. Para isso devemos primeiro setar as cidades de referencia, sendo elas SF (San Francisco), LA (Los Angeles) e SD (San Diego).","d8240cc5":"Com as analises prontas, iremos formatar o teste para ser compativel com o treino.","7b9016bd":"Ap\u00f3s essa an\u00e1lise, iremos partir para a correla\u00e7\u00e3o e a exclus\u00e3o de colunas n\u00e3o relevantes","dd038483":"Como pudemos observar, o RF performou melhor que o KNN, portanto iremos utiliza-lo para a previs\u00e3o","6c73f0a6":"# Lendo dados","f1df1713":"## KNN","33bc0057":"## Random Forest","3d45f1f7":"Agora iremos an\u00e1lisar a base de dados a procura de incongru\u00eancias na base, como linhas nulas e outliers ","2f03e82d":"Vendo agora que deu certo, podemos dropar as colunas de longitude e latitude. Depois disso j\u00e1 podemos criar mais uma correla\u00e7\u00e3o de dados e dropar as colunas que julgar desnecess\u00e1rias","6b30a114":"# Prepara\u00e7\u00e3o para as regress\u00f5es","3583b515":"Podemos dropar de cara algumaas colunas, como ID, Longitude e Latitude. Por\u00e9m ainda nao temos dados suficientes, para isso iremos criar novas analises. Essas analises iram atuar nas colunas total, que ira transformalas em metricas por casa, ou seja rooms\/ house etc...","e1511587":"Agora vamos criar a fun\u00e7\u00e3o de dist\u00e2ncia","4bbaad18":"Dessas novas an\u00e1lises, pdoemos ver que a unica que fez grande relevancia foi a de rooms\/house. Portanto irei deixar apenas essa."}}