{"cell_type":{"14256633":"code","fb1d3d26":"code","df8d5340":"code","da2284bc":"code","0a07d32d":"code","1d622627":"code","6de75058":"code","28f31875":"code","638c9d75":"code","5b6f4f01":"code","09cf4008":"code","4c0e6a46":"code","331e6e60":"code","2722fb68":"code","ead0e2e4":"code","55c056b3":"code","0f06c83a":"code","2f1f7332":"code","0aab51a9":"code","70b275f6":"code","05449033":"code","7d9edec1":"code","911874af":"code","6f313042":"code","b14c7e04":"code","87926aa1":"code","231de5c1":"code","9eb87c27":"code","b01ed2ff":"code","56b5fb76":"code","6c2398a8":"code","bdd9dbca":"code","e788bd03":"code","124bea4a":"code","4863e3b8":"code","b505ca81":"code","4a9c75d5":"code","fc3e13c0":"code","eac7f93f":"code","2e7ba380":"code","92b6a420":"code","3277a71b":"code","830cc735":"code","1b34a8d9":"code","5c1fbca4":"code","a7782a11":"code","3c8e1be4":"code","64da41e1":"code","6847a0f0":"code","c6571ddc":"code","8f86672f":"code","ec090682":"code","cb9c2695":"code","7ffed9c4":"code","13912baf":"code","176238cc":"code","d0f3cfbe":"code","1a9af67a":"code","0429396f":"code","3bf1706c":"code","a53af093":"code","f6974fbb":"code","1f125d09":"code","be8e6756":"code","284c531f":"code","799035c2":"code","fe1efc70":"code","914e94ed":"code","15d863ae":"code","641a3a76":"code","0b1f6ca3":"code","d9c294ba":"code","35949e34":"code","d43d0b3c":"code","9516b695":"markdown","373dc29e":"markdown","d1c7b250":"markdown","6babc875":"markdown","ac4ef300":"markdown","6cfdde79":"markdown","785b5fdf":"markdown","fecea48e":"markdown","ee33b865":"markdown","e1d64896":"markdown","a6c5d403":"markdown","c08cd40a":"markdown","ab72782a":"markdown","807b6d6a":"markdown","1554cff1":"markdown","86e1a06a":"markdown","79f660ee":"markdown","f93229ea":"markdown","174bd793":"markdown","e7314d43":"markdown","5954fef2":"markdown","1f9271d0":"markdown","8d1df521":"markdown","44a6109c":"markdown","d73431bb":"markdown","21dea030":"markdown","e7ece995":"markdown","39b4e05a":"markdown","8e8ac529":"markdown","4a31511d":"markdown","80b84364":"markdown","33718fb9":"markdown","1be3d5e6":"markdown","b9676453":"markdown","1c41b306":"markdown","e5b65f22":"markdown","66acbc96":"markdown","448041fe":"markdown","107c5102":"markdown","a46b58b3":"markdown","e6928a40":"markdown","7911fc1b":"markdown","2a1e750c":"markdown","41bed76d":"markdown","fb0a103f":"markdown","53c03d4c":"markdown","53a73c57":"markdown"},"source":{"14256633":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\n\n%matplotlib inline\nSEED = 42","fb1d3d26":"INPUT_DIR='..\/input'\nfor dirname, _, filenames in os.walk(INPUT_DIR):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","df8d5340":"train = pd.read_csv(INPUT_DIR+'\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv(INPUT_DIR+'\/house-prices-advanced-regression-techniques\/test.csv')","da2284bc":"train.head()","0a07d32d":"Y_train = train['SalePrice'].reset_index(drop=True)\ntrain=train.drop(['Id'], axis=1)\ntest_ids = test['Id'].reset_index(drop=True)\ntest=test.drop(['Id'], axis=1)\nprint(len(train),len(test))","1d622627":"df = pd.concat([train, test],sort=False)\ndf = df.reset_index(drop=True)","6de75058":"df.info()","28f31875":"fig = plt.figure(figsize=(20,20))\n\n# Columns with low correlation with other variables, will be dropped to get matrix\ncolumns = ['PoolArea', 'MiscVal', 'BsmtHalfBath', 'MoSold', 'YrSold']\ntrain_corr = train.drop(columns=columns).corr().round(2)\n\nsns.heatmap(train_corr, \n            annot=True, \n            center = 0,\n            cmap=sns.diverging_palette(20, 220, n=200));","638c9d75":"fig, ax = plt.subplots(ncols=2,figsize=(16,6))\nax = ax.ravel()\nsns.scatterplot(x='OverallQual',y='SalePrice', data=train, ax=ax[0]);\nsns.boxplot(x='OverallQual',y='SalePrice', data=train,ax=ax[1]);","5b6f4f01":"fig, ax = plt.subplots(ncols=1,figsize=(16,6))\nax = ax.ravel()\nsns.distplot(train.GrLivArea, ax=ax[0]);","09cf4008":"fig, ax = plt.subplots(ncols=2,figsize=(12,6))\nax = ax.ravel()\nsns.distplot(train['1stFlrSF'],hist=False, label='1stFlrSF', ax=ax[0]);\nsns.distplot(train['2ndFlrSF'],hist=False, label='2ndFlrSF', ax=ax[1]);","4c0e6a46":"firstandsecondSF = train['1stFlrSF'] + train['2ndFlrSF']\ntrain.GrLivArea.corr(firstandsecondSF)","331e6e60":"sns.distplot(train['GrLivArea'],hist=False,label='GrLivArea');\nsns.distplot(firstandsecondSF,hist=False, label='1stFlrSF + 2ndFlrSF');","2722fb68":"totalSF = train['1stFlrSF'] + train['2ndFlrSF'] + train['LowQualFinSF']\ntrain.GrLivArea.corr(totalSF)","ead0e2e4":"sns.distplot(train['GrLivArea'], hist=False, label='GrLivArea');\nsns.distplot(totalSF, hist=False, label='1stFlrSF + 2ndFlrSF + LowQualFinSF');","55c056b3":"def print_missing(df):\n    for col in df.columns.tolist():\n        if df[col].isnull().sum():\n             print('{}: {}'.format(col, df[col].isnull().sum()))","0f06c83a":"print_missing(df)","2f1f7332":"df.loc[df['Alley'].isnull(),'Alley'] = 'None'\ndf.loc[df['Fence'].isnull(),'Fence'] = 'None'\ndf.loc[df['MiscFeature'].isnull(),'MiscFeature'] = 'None'","0aab51a9":"df.loc[np.logical_and(df['PoolArea'] != 0, df['PoolQC'].isnull()), \n        ['PoolArea', 'PoolQC', 'OverallQual']]","70b275f6":"df.loc[2420,['PoolQC']] = 2\ndf.loc[2599,['PoolQC']] = 2\ndf.loc[2503,['PoolQC']] = 3\n\ndf['PoolQC'].fillna('None', inplace=True)","05449033":"df['MasVnrType'].value_counts()","7d9edec1":"df.loc[df['MasVnrArea'].isnull() | df['MasVnrType'].isnull()][['MasVnrArea','MasVnrType']]","911874af":"df.loc[df['MasVnrArea'].isnull(),['MasVnrArea','MasVnrType']] = [0, 'None']\ndf.loc[df['MasVnrType'].isnull(),['MasVnrType']] = 'None'","6f313042":"print(len(df.loc[df['BsmtQual'].isnull() & df['BsmtCond'].isnull() & df['BsmtExposure'].isnull() &\n             df['BsmtFinType1'].isnull() & df['BsmtFinType2'].isnull()]))","b14c7e04":"df.loc[(df['BsmtFinType1'].notnull()) & (df['BsmtQual'].isnull() | df['BsmtCond'].isnull() | df['BsmtExposure'].isnull() | df['BsmtFinType2'].isnull())][['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2',\\\n        'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']]","87926aa1":"df.BsmtQual.loc[[2217, 2218]] = df.BsmtQual.mode()[0]\ndf.BsmtCond.loc[[2040, 2185, 2524]]= df.BsmtCond.mode()[0]\ndf.BsmtFinType2.loc[[332]] = df.BsmtFinType2.mode()[0]\ndf.BsmtExposure.loc[[948, 1487, 2348]] = df.BsmtExposure.mode()[0]\n\ndf.BsmtQual.fillna('None', inplace=True) \ndf.BsmtCond.fillna('None', inplace=True)\ndf.BsmtExposure.fillna('None', inplace=True)\ndf.BsmtFinType1.fillna('None', inplace=True)\ndf.BsmtFinType2.fillna('None', inplace=True)\ndf.BsmtFinSF1.fillna(0, inplace=True)\ndf.BsmtFinSF2.fillna(0, inplace=True)\ndf.BsmtUnfSF.fillna(0, inplace=True)\ndf.TotalBsmtSF.fillna(0, inplace=True)\ndf.BsmtFullBath.fillna(0, inplace=True)\ndf.BsmtHalfBath.fillna(0, inplace=True)","231de5c1":"len(df.loc[df.GarageType.isnull() & df.GarageFinish.isnull() & df.GarageQual.isnull() & df.GarageCond.isnull(),\n       ['GarageType','GarageYrBlt','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond']])","9eb87c27":"df.loc[df.GarageType.notnull() & (df.GarageFinish.isnull() | df.GarageQual.isnull() | df.GarageCond.isnull()),\n       ['GarageType','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond']]","b01ed2ff":"df.loc[[2127, 2576], ['GarageCond', 'GarageQual', 'GarageFinish', 'GarageCars', 'GarageArea']] = [df['GarageCond'].mode()[0], df['GarageQual'].mode()[0], df['GarageFinish'].mode()[0], df['GarageCars'].mode()[0], df['GarageArea'].mean()]","56b5fb76":"indexes = df.loc[df.GarageYrBlt.notnull()].index\ndf.GarageYrBlt.iloc[indexes].corr(df.YearBuilt.iloc[indexes])","6c2398a8":"print(np.sort(df.GarageYrBlt.unique())[::-1])\nprint(np.sort(df.YearBuilt.unique())[::-1])","bdd9dbca":"df.GarageYrBlt.replace(2207, 2007, inplace=True)\nemp_garageYr = df.loc[df.GarageYrBlt.isnull()].index\ndf.GarageYrBlt.iloc[emp_garageYr] = df.YearBuilt.iloc[emp_garageYr]","e788bd03":"indexes = df.loc[df.GarageYrBlt.notnull()].index\ndf.GarageYrBlt.iloc[indexes].corr(df.YearBuilt.iloc[indexes])","124bea4a":"df.loc[df['GarageType'].isnull(), ['GarageYrBlt']] = 0\ndf['GarageType'].fillna('None', inplace=True)\ndf['GarageFinish'].fillna('None',inplace=True)\ndf['GarageCars'].fillna(0,inplace=True)\ndf['GarageArea'].fillna(0,inplace=True)\ndf['GarageQual'].fillna('None',inplace=True)\ndf['GarageCond'].fillna('None',inplace=True)","4863e3b8":"df['FireplaceQu'].fillna('None', inplace=True)","b505ca81":"for feature in ['Exterior1st', 'Exterior2nd', 'Electrical', 'KitchenQual', 'MSZoning', 'Functional', 'SaleType', 'Utilities']:\n    df[feature] = df.groupby(['Neighborhood', 'MSSubClass'])[feature].apply(lambda x: x.fillna(x.mode()[0]))\n\ndf['LotFrontage'] = df.groupby(['Neighborhood'])['LotFrontage'].apply(lambda x : x.fillna(x.median()))","4a9c75d5":"print_missing(df)","fc3e13c0":"print('Training Set SalePrice Skew: {}'.format(train['SalePrice'].skew()))\nprint('Training Set SalePrice Kurtosis: {}'.format(train['SalePrice'].kurt()))\nprint('Training Set SalePrice Mean: {}'.format(train['SalePrice'].mean()))\nprint('Training Set SalePrice Median: {}'.format(train['SalePrice'].median()))\nprint('Training Set SalePrice Max: {}'.format(train['SalePrice'].max()))\n","eac7f93f":"fig, axs = plt.subplots(figsize=(8, 5))\ng = sns.distplot(train.SalePrice, hist=True)\ng=g.legend([\"Skewness: {:.4}\".format(Y_train.skew())])","2e7ba380":"train_corr = df[:len(train)].corr().abs().unstack().reset_index().sort_values(by=[0], ascending=False)\ntrain_corr.rename(columns={\"level_0\": \"Feature_1\", \"level_1\": \"Feature_2\", 0: 'Correlation'}, inplace=True)\ntrain_corr.drop(train_corr[train_corr['Correlation'] == 1.0].index, inplace=True)","92b6a420":"train_corr[train_corr['Feature_1'] == 'SalePrice']","3277a71b":"train_corr[1::2].head(15)","830cc735":"df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\ndf['TotalBath'] = df['FullBath']+df['BsmtFullBath']+(df['BsmtHalfBath']+df['HalfBath'])*0.5\ndf['TotalPorchSF'] = df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch']","1b34a8d9":"df['YearBuiltRemod'] = df['YearBuilt'] + df['YearRemodAdd']\nprint(f'Correaltion with Target variable: {df.SalePrice.corr(df.YearBuiltRemod).round(3)}')","5c1fbca4":"sns.jointplot(x=\"YearBuiltRemod\", y=\"SalePrice\", data=df, kind=\"reg\");","a7782a11":"df['HasPool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndf['HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ndf['isNewer'] = 0\ndf.loc[df['YrSold'] == df['YearBuilt'], 'isNewer'] = 1","3c8e1be4":"fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16,12))\nax=ax.ravel()\nfor i,f in enumerate(['HasPool', 'HasFireplace', 'isNewer']):\n    sns.barplot(x=f, y='SalePrice', data=df, ax=ax[i])","64da41e1":"df_ = df.copy()\nfor f in ['MSSubClass', 'MoSold', 'YrSold', 'OverallQual', 'OverallCond']:\n    df_[f] = df_[f].astype('category')\nnum_features = df_.drop(columns=['SalePrice']).select_dtypes(include=np.number).columns.tolist()\ncat_features = df_.select_dtypes(exclude=np.number).columns.tolist()","6847a0f0":"print(len(num_features), len(cat_features))\ndf_num = df_[num_features]\ndf_cat = df_[cat_features]","c6571ddc":"fig = plt.figure(figsize=(18,24))\nax = fig.gca()\ndf_num.hist(ax=ax);","8f86672f":"skew_df = df_num.skew().abs().sort_values(ascending=False).reset_index()\nskew_df.rename(columns={\"level_0\": \"Feature_1\",0: 'Skewness'}, inplace=True)\nskew_df[skew_df.Skewness >= 0.5]","ec090682":"from scipy.stats import boxcox_normmax\nfrom scipy.special import boxcox1p\n\nskew_features = [\n    'LotFrontage', 'MasVnrArea', 'BsmtFinSF1',\n    'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '2ndFlrSF', \n    'LowQualFinSF', 'GrLivArea', 'WoodDeckSF', 'OpenPorchSF',\n    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal', \n    'TotalSF', 'TotalPorchSF',\n]\n\nfor feature in skew_features:\n    df[feature] = boxcox1p(df[feature], boxcox_normmax(df[feature] + 1))","cb9c2695":"exterQual = {'Fa': 1, 'TA': 2, 'Gd': 3,'Ex': 4}\nexterCond = {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\nbsmtQual = {'None': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\nbsmtCond = {'None': 0, 'Po': 1, 'Fa': 2,'TA': 3, 'Gd': 4}\nbsmtExposure = {'None': 0, 'No': 1, 'Mn': 2,'Av': 3, 'Gd': 4}\nbsmtFinType1 = {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\nbsmtFinType2 = {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\nheatingQC = {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\nkitchenQual = {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}\nfirePlaceQu = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ngarageQual = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ngarageCond = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\nfunctional = {'Typ': 0, 'Min1': 1, 'Min2': 1, 'Mod': 2, 'Maj1': 3, 'Maj2': 3, 'Sev': 4}\nlandSlope = { 'Sev': 1, 'Mod': 2, 'Gtl': 3 }\n\ndf['ExterQual'] = df['ExterQual'].map(exterQual)\ndf['ExterCond'] = df['ExterCond'].map(exterCond)\ndf['BsmtQual'] = df['BsmtQual'].map(bsmtQual)\ndf['BsmtCond'] = df['BsmtCond'].map(bsmtCond)\ndf['BsmtExposure'] = df['BsmtExposure'].map(bsmtExposure)\ndf['BsmtFinType1'] = df['BsmtFinType1'].map(bsmtFinType1)\ndf['BsmtFinType2'] = df['BsmtFinType2'].map(bsmtFinType2)\ndf['HeatingQC'] = df['HeatingQC'].map(heatingQC)\ndf['KitchenQual'] = df['KitchenQual'].map(kitchenQual)\ndf['FireplaceQu'] = df['FireplaceQu'].map(firePlaceQu)\ndf['GarageQual'] = df['GarageQual'].map(garageQual)\ndf['GarageCond'] = df['GarageCond'].map(garageCond)\ndf['Functional'] = df['Functional'].map(functional)\ndf['LandSlope'] = df['LandSlope'].map(landSlope)","7ffed9c4":"df.drop(columns=['Street', 'Utilities', 'Fireplaces', \n                'PoolArea', 'PoolQC', 'GarageYrBlt',\n                'GarageArea', 'TotalBsmtSF', '1stFlrSF',\n                'FullBath', 'YearBuilt', 'YearRemodAdd',\n                ], inplace=True)","13912baf":"df = pd.get_dummies(df,columns=df.select_dtypes(exclude=np.number).columns.tolist())\ndf.shape","176238cc":"fig = plt.figure(figsize=(12, 6))\n\nsns.scatterplot(x='GrLivArea', y='SalePrice', hue='OverallQual', data=df)\n\nplt.xlabel('GrLivArea', size=15)\nplt.ylabel('SalePrice', size=15)\nplt.tick_params(axis='x', labelsize=12)\nplt.tick_params(axis='y', labelsize=12) \n    \nplt.title('GrLivArea & OverallQual vs SalePrice', size=15, y=1.05)\n\nplt.show()","d0f3cfbe":"fig = plt.figure(figsize=(12, 6))\n\nsns.scatterplot(x='OverallQual', y='SalePrice', data=df);","1a9af67a":"print(train[np.logical_and(train['OverallQual'] < 5, train['SalePrice'] > 200000)].index)\nprint(train[np.logical_and(train['GrLivArea'] > 4000, train['SalePrice'] < 300000)].index)\nprint(df[np.logical_and(df['OverallQual']==4,  df['SalePrice'] > 200000)].index)\n# train[train['BsmtFinSF1'] > 4000]\noutliers=[457, 523, 1298]","0429396f":"X_train = df[:len(train)].drop(columns=['SalePrice'])\nX_test = df[len(train):].drop(columns=['SalePrice'])\nprint(X_train.shape, Y_train.shape, X_test.shape)","3bf1706c":"sparse=[]\nfor feature in X_test.columns:\n    counts = X_test[feature].value_counts()\n    zeros = counts.iloc[0]\n    if zeros\/len(X_test) > 99.94:\n        sparse.append(feature)\n        print(feature)\n\nX_test.drop(columns=sparse, inplace=True)\nX_train.drop(columns=sparse, inplace=True)","a53af093":"X_train = X_train.drop(X_train.index[outliers])\nY_train = Y_train.drop(Y_train.index[outliers])\ny_train = Y_train.apply(np.log1p)","f6974fbb":"scaler = RobustScaler()\n\nx_train = pd.DataFrame(scaler.fit_transform(X_train),\n                      index=X_train.index,\n                      columns=X_train.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test),\n                      index=X_test.index,\n                      columns=X_test.columns)","1f125d09":"kfolds = KFold(n_splits=8, shuffle=True, random_state=42)\n\ndef cv_rmse(model, X=x_train, y=y_train):\n    rmse = np.sqrt(-cross_val_score(model, X, y,scoring=\"neg_mean_squared_error\",cv=kfolds))\n    return (rmse)\n\n# rmsle scoring function\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef fit_model(model, X=x_train, y=y_train):\n    return model.fit(X, y)","be8e6756":"def grid_search(model, param_grid, cv=5, \n                scoring='neg_mean_squared_error'):\n    \n    grid_model = GridSearchCV(model, \n                          param_grid, \n                          cv=cv, \n                          scoring=scoring, \n                          return_train_score=True \n                         )\n    fit_model(grid_model)\n    cvres = grid_model.cv_results_\n    for mean_score, std_score, params in zip(cvres[\"mean_test_score\"], cvres[\"std_test_score\"], cvres[\"params\"]):\n        print(np.sqrt(-mean_score), std_score, params)\n    return grid_model","284c531f":"param_grid=[{'alpha': np.arange(13,14,0.1)}]\nridge = Ridge(random_state=SEED)\ngrid_ridge = grid_search(ridge, param_grid, cv=kfolds)","799035c2":"param_grid=[{'alpha': [0.0005, 0.0007]}]\nlasso = Lasso(max_iter=1e7, random_state=SEED)\ngrid_lasso = grid_search(lasso, param_grid, cv=kfolds)","fe1efc70":"param_grid=[\n    {\n        'alpha': [ 0.008],\n        'l1_ratio': [0.0056, 0.009, 0.01, 0.05],\n    }\n]\nelastic = ElasticNet(max_iter=1e7, random_state=SEED)\ngrid_elastic = grid_search(elastic, param_grid, cv=kfolds)","914e94ed":"param_grid=[\n    {\n        'C': np.logspace(1.5,2,4),\n        'epsilon': [0.05, 0.06],\n        'gamma':[0.0001]\n    }\n]\nsvr= SVR()\ngrid_svr = grid_search(svr, param_grid, cv=kfolds)","15d863ae":"param_grid=[\n    {\n        'learning_rate': [0.01],\n        'max_depth':[ 4 ],\n    }\n]\ngbr = GradientBoostingRegressor(\n    n_estimators=3000, max_features='sqrt', \n    min_samples_leaf=15, min_samples_split=10,\n    loss='huber', random_state=SEED)\ngrid_gbr = grid_search(gbr, param_grid, cv=kfolds)","641a3a76":"param_grid=[\n    {\n        'learning_rate': [0.005, 0.009, 0.01],\n        'n_estimators': [5000]\n    }\n]\nlightgbm = LGBMRegressor(objective='regression',\n                        num_leaves=4,max_bin=200,\n                        bagging_fraction=0.75,\n                        bagging_freq=5,bagging_seed=7,\n                        feature_fraction=0.2,\n                        feature_fraction_seed=7,\n                        random_state=SEED,verbose=-1\n                        )\ngrid_lgb = grid_search(lightgbm, param_grid, cv=kfolds)","0b1f6ca3":"param_grid=[\n    {\n        'learning_rate': [0.1],\n        'n_estimators': [3460],\n        'max_depth':[ 3 ],\n        'gamma':[0.001],\n        'subsample':[0.7]\n    }\n]\nxgb = XGBRegressor(n_jobs=3)\ngrid_xgb = grid_search(xgb, param_grid, cv=kfolds)","d9c294ba":"stacking = StackingRegressor(estimators=[\n    ('ridge', grid_ridge.best_estimator_), \n    ('lasso', grid_lasso.best_estimator_),\n    ('elastic',grid_elastic.best_estimator_),\n    ('xgb', grid_xgb.best_estimator_),\n    ('lgb', grid_lgb.best_estimator_)\n                                        ],\n                             final_estimator=grid_xgb.best_estimator_,\n                            passthrough=True)\n\nstacking_model=fit_model(stacking)\nloss=rmsle(y_train, stacking_model.predict(x_train))\nprint(\"Stacking:\\n Loss: %.4f\"%(loss))","35949e34":"def blend(x):\n    return (\n            0.1*grid_elastic.best_estimator_.predict(x)+\n            0.05*grid_lasso.best_estimator_.predict(x)+\n            0.1*grid_ridge.best_estimator_.predict(x)+ \n            0.1*grid_svr.best_estimator_.predict(x)+\n            0.15*grid_gbr.best_estimator_.predict(x)+ \n            0.1*grid_lgb.best_estimator_.predict(x)+\n            0.1*grid_xgb.best_estimator_.predict(x)+\n            0.3*stacking.predict(x)\n           )\ny_pred = blend(x_train)\nscores=rmsle(y_train, y_pred)\nprint(\"Loss:\\n %.4f\"%(scores))\n\nY_test = blend(X_test)","d43d0b3c":"Y_test = np.expm1(Y_test)\ndef save_csv(y):\n    submission = pd.DataFrame()\n    submission['Id'] = test_ids\n    submission['SalePrice'] = y\n    submission.to_csv('submission.csv',index=False)\n\nsave_csv(Y_test)","9516b695":"#### Blending and Evaluation\nAll of the models individually achieved scores between **0.11** and **0.12**, but when the predictions of those models are blended, they get much lower loss value.    \nOne reason can be that models are actually overfitting to certain degree and are performing better on subset of data. When their predictions are blended, they complement each other. ","373dc29e":"New feature `YearBuiltRemod` is combination of `YearBuilt` and `YearRemodAdd`. The new feature has good correlation compared to other two varibles. (**0.57** compared to **0.50** and **0.52**)","d1c7b250":"### Outliar Detection","6babc875":"`BsmtCond`, `BsmtQual`, `BsmtExposure`, `BsmtFinType1` and `BsmtFinType2` has 79 and more missing values.  \nAmong all empty Basement rows, 79 has no basement.","ac4ef300":"`MasVnrArea` and `MasVnrType` are misssing for most of the rows which shows that those houses don't have Masonary Veneer.    \nExcept for Row 2610 where MasVnrArea is 198 and MasVnrType is null.  For now I will impute that with `None`.  \nBut that perticular row can be imputed with most frequent non-null value 'BrkFace'.","6cfdde79":"From above plots, outliars with `GrLivArea` > 4000 has much lower `SalePrice` and one outliar with `OverallQual` = 4 has higher `SalePrice` compared to others within same category.","785b5fdf":"Correlation shows that GarageYrBlt and YearBuilt are highly correlated. But let's see if there is any error in this feature.  \nAfter Getting Unique values in GarageYrBlt it shows 2207, which clearly is error. So I would replace it with most likely 2007.","fecea48e":"Heatmap shows that two features have correlation with `SalePrice`. Let's Explore them.","ee33b865":"#### Masonry Veneer Features","e1d64896":"Overview  \n1. Training set has 1460 samples and test set has 1459 samples  \n2. Training and Testing set has 81 and 80 features respectively. (Test set has no Target Feature `SalePrice`)","a6c5d403":"#### Stacking\nStacked generalization is a method for combining estimators to reduce their biases. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.\n\nThe StackingClassifier and StackingRegressor provide such strategies which can be applied to classification and regression problems.\n\nThe estimators parameter corresponds to the list of the estimators which are stacked together in parallel on the input data. It should be given as a list of names and estimators.  \n\nThe `final_estimator` will use the predictions of the estimators as input.   \n\nWhen `passthrough` is False, only the predictions of estimators will be used as training data for final_estimator. When True, the `final_estimator` is trained on the predictions as well as the original training data.\n\n[StackingRegressor in Scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor)\n\n![alt](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/regressor\/StackingRegressor_files\/stackingregression_overview.png)","c08cd40a":"#### Correlation","ab72782a":"#### Feature Scaling \n\nMachine Learning models perform better compared o scaled data compared to unscaled data. (Here Linear Models especially).  \nWe have many outliars in the data which are yet be identified but among all Scaling options available, RobustScaler is best as it deals with outliars.  \n(https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html#scaling-data-with-outliers)","807b6d6a":"New correlation is improved after imputing values, it can also cause problem for linear models becuse of co-linearity. ","1554cff1":"Training set `SalePrice` skew is 1.88 which clearly shows that the target distribution is not normally distributed and has positive skew.  \nTail extremity is also present, as kurtosis is 6.53.  \nMean SalePrice is 180921.2, however, median is 163000.  \nAll these indicate that there extreme outliars in the data.  ","86e1a06a":"## Exploratory Data Analysis","79f660ee":"GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, and GarageCond have 157+ missing values.  \nOne reason can be that 157 houses have no garage. and rest of the rows have missing value which may be due to error.","f93229ea":"Plotting histogram of each feature shows that many features are very skew. we will use box_cox for reducing skewness.  \nCaution: box cox only works with positive values (0 is neither positive nor negative). [power_transform](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.power_transform.html)  \nSolution:   \n    1. Add 1 to each value (make sure there are no negative values).  \n    2. Use `yeo-johnson` (works with positive and negative values).","174bd793":"#### Encoding Nominal Features","e7314d43":"GarageYrBlt is replaced with -1 for houses that have no garage. Rest of the parameters have been replaced with 0 and `None`.","5954fef2":"### Models","1f9271d0":"Rows with missing `BsmtFinType1` have no basement. Rest of the the rows have only one missing value among basement features.","8d1df521":"Whola! the correlation is approx to 1.Let's plot distribution of both.","44a6109c":"#### Cross Validation and Loss Function\n\nKfold with 8 folds is used with `rmse` (root mean squared error) to evaluate model. All model hyperparameters have been selected with best results from `GridSearchCV`.  \n(https:\/\/scikit-learn.org\/stable\/modules\/grid_search.html#grid-search)","d73431bb":"The plot is completely overlapped. Which also says that these variables are perfectly correlated.","21dea030":"### Imputing Missing Values","e7ece995":"#### Garage variables.","39b4e05a":"The below correlation shows that `GrLivArea` is addition of both. But it is still not exactly 1. Let's add another variable `LowQualFinSF`.","8e8ac529":"#### Encoding Ordinal Features","4a31511d":"#### Features Related to Pool.","80b84364":"All of the features are imputed, except `SalePrice` which are of Test dataset. ","33718fb9":"According to data description `GrLivArea` is area of living above groud in square feet.\nwhich can be related to other square feet features such as `1stFlrSF` and `2ndFlrSF`. ","1be3d5e6":"Below categorical features shows clear difference of SalePrice.","b9676453":"## Introduction","1c41b306":"#### Basement Variables","e5b65f22":"### Target Variable and Correlation","66acbc96":"#### New Features\n11 new features have been created from existing features.","448041fe":"These 9 rows will be imputed with mode of the feature, and rest of the houses have no basement, those can be replaced wit `None`.\n","107c5102":"#### Features with more than 50% missing values.","a46b58b3":"These feauters have high skew, which will create problem for regression models. Though some categorical variables have high skew, I will leave them from transformation and only use continuous features.","e6928a40":"Combined Data has many features with missing values. Majority of the features have value `NA` which says that this feature is not availabe for that house. I will replace those values with `None`. ","7911fc1b":"#### Rest of the variables.","2a1e750c":"Some features are not useful or causing colinearity can be removed.","41bed76d":"## Feature Engineering","fb0a103f":"Three rows have PoolArea > 0 and PoolQC is missing.\nTo Impute those values I will use OverallQual","53c03d4c":"### Target Distribution","53a73c57":"Intuitively, GarageYrBlt should be same as in most cases as YearBuilt if house is not modified. Let's plot the relation between them."}}