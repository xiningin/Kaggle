{"cell_type":{"77367313":"code","03e889a8":"code","b5138dec":"code","84d7c32b":"code","4ef7f3f2":"code","44f65100":"code","0d212b20":"code","56ec0256":"code","e27c4989":"code","ac844c76":"code","870664b3":"code","d2290a35":"code","6599055a":"code","189fd0ab":"code","ca1c8c70":"code","e71d659e":"code","f92bfa5c":"code","3e027112":"code","2c270e4e":"code","63e679af":"code","4cfad901":"code","29f12a97":"code","b6839f47":"code","7307499e":"code","66efe20d":"code","7ee362e3":"code","1296f03d":"code","205a1bde":"code","032697e3":"code","3d47c415":"code","e9e85441":"code","1002c479":"code","a33d15ab":"code","d4b83566":"code","54705e7d":"code","7ddfcda9":"code","872bd501":"code","3ab8cd36":"code","d2d179db":"code","44224b9c":"code","9ced9441":"code","529a54f0":"code","368d40ae":"code","9a9430e2":"code","fb33fcce":"code","a83246e5":"code","81cf6d24":"code","0a34dbe3":"code","778c56ae":"code","df4baf3e":"code","146e0a16":"code","77ff9028":"code","aa4feefb":"code","89ad6b28":"code","c4ac9107":"code","7055b3a0":"code","047d0097":"code","5ca4e7a6":"code","f4bb6305":"code","024b1c20":"code","33fb4aa7":"code","b93728c2":"code","3879a969":"code","f4e2083b":"code","55594bf3":"code","761c0509":"code","e78fa446":"code","cd1b99c9":"code","ab647347":"code","8ab5f055":"code","8ab16e27":"code","c06ae8c9":"code","dc11fdf0":"markdown","af2febaa":"markdown","a80fd1c9":"markdown","757d5f1a":"markdown","e5c3f0da":"markdown","c395c494":"markdown","7fb76b20":"markdown","b0b29202":"markdown","91ebc4da":"markdown","c250dc63":"markdown"},"source":{"77367313":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas import Series\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, mean_absolute_error, mean_squared_error, precision_score\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport datetime\nfrom datetime import datetime, timedelta\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03e889a8":"DATA_DIR = '\/kaggle\/input\/sf-dst-scoring\/'\ntrain = pd.read_csv(DATA_DIR+'\/train.csv')\ntest = pd.read_csv(DATA_DIR+'\/test.csv')\nsample_submission = pd.read_csv(DATA_DIR+'\/sample_submission.csv')","b5138dec":"sample_submission.info()","84d7c32b":"train.info()","4ef7f3f2":"test.info()\n","44f65100":"train.head()","0d212b20":"#\u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c train \u0438 test \u0432 \u043e\u0434\u0438\u043d \u0434\u0430\u0442\u0430\u0441\u0435\u0442\ntrain['train'] = 1 # \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\ntest['train'] = 0  # \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\ndf = pd.concat([train, test], ignore_index=True)\ndf.info","56ec0256":"df.head()","e27c4989":"#\u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432\ndf.isna().sum()","ac844c76":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c \u0432 %, \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u043d\u0435 \u043c\u043d\u043e\u0433\u043e.\nfor col in df.columns:\n    pct_missing = df[col].isna().mean()\n    print(f'{col} - {pct_missing :.1%}')","870664b3":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 education\ndf['education'].value_counts().plot.barh()\ndf.education.value_counts","d2290a35":"# \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u043c\u043e\u0434\u043e\u0439\ndf.education.fillna(df.education.mode()[0], inplace = True)","6599055a":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c\ndf.info()","189fd0ab":"# \u041f\u0435\u0440\u0435\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f education \u0432 \u0447\u0438\u0441\u043b\u0430\nlabel_encoder = LabelEncoder()\n\ndf['education'] = label_encoder.fit_transform(df['education'])\nprint(dict(enumerate(label_encoder.classes_)))\ndf.head()","ca1c8c70":"#\u041f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0434\u0430\u0442\u0443 \u0432 \u0443\u0434\u043e\u0431\u043d\u044b\u0439 \u0432\u0438\u0434\ndf['ap_date'] = df['app_date'].apply(pd.Timestamp)","e71d659e":"#\u0423\u0434\u0430\u043b\u0438\u043c \u0441\u0442\u0430\u0440\u0443\u044e \u0434\u0430\u0442\u0443\ndf.drop(['app_date'], inplace = True, axis = 1)","f92bfa5c":"#\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0433\u043e\u0434\u0430, \u043c\u0435\u0441\u044f\u0446\u0430, \u0434\u043d\u044f.\ndf['year'] = df.ap_date.dt.year\ndf['month'] = df.ap_date.dt.month\ndf['day'] = df.ap_date.dt.day","3e027112":"# \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u043d\u0435\u0439 \u0441 \u043d\u0430\u0447\u0430\u043b\u0430 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0439\u0416\ndf['count_days'] = (df.ap_date - df.ap_date.min()).dt.days","2c270e4e":"df.head()","63e679af":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0433\u043e\u0434\ndf.year.value_counts()","4cfad901":"# \u0413\u043e\u0434 \u0432\u0435\u0437\u0434\u0435 \u043e\u0434\u0438\u043d, \u0443\u0434\u0430\u043b\u0438\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0443\ndf.drop(['year'], inplace = True, axis = 1)","29f12a97":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0447\u0442\u043e \u0441 \u043c\u0435\u0441\u044f\u0446\u0430\u043c\u0438\ndf.month.value_counts()","b6839f47":"#\u0414\u0430\u0442\u0430 \u0442\u043e\u0436\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 \u043d\u0435 \u043d\u0443\u0436\u043d\u0430\ndf.drop(['ap_date'], inplace = True, axis = 1)","7307499e":"df.head()","66efe20d":"df.info()","7ee362e3":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044e \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 client_id\ndif_cols = ['client_id', 'day', 'count_days', 'month']\nplt.figure(figsize=(8,4))\nsns.heatmap(df[dif_cols].corr(), annot = True)","1296f03d":"# \u0438\u0441\u043a\u043b\u044e\u0447\u0438\u043c \u043c\u0435\u0441\u044f\u0446\u044b \u0438 count_days\ndf.drop(['month'], inplace = True, axis = 1)\ndf.drop(['count_days'], inplace = True, axis = 1)","205a1bde":"df.info()","032697e3":"# \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435. \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u0438 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435\nnum_cols = ['age', 'day', 'decline_app_cnt', 'income', 'bki_request_cnt', 'score_bki']\nbin_cols = ['sex', 'car', 'car_type', 'foreign_passport', 'good_work']\ncat_cols = ['education', 'home_address', 'work_address', 'sna', 'first_time', 'region_rating']","3d47c415":"#\u041f\u0440\u0438\u043c\u0435\u043d\u0438\u043c LabelEncoder \u043a \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c\nlabel_encoder = LabelEncoder()\nfor column in bin_cols:\n    df[column] = label_encoder.fit_transform(df[column])","e9e85441":"df.head()","1002c479":"# \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442\ntrain_n = df.query('train == 1').drop(['train'], axis = 1)\ntest_n = df.query('train ==0').drop(['train'], axis = 1)\n","a33d15ab":"#\u043d\u0430\u0438\u0432\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c\nX = train_n.drop(['default'], axis = 1).values\nY = train_n['default'].values\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n","d4b83566":"model_n = LogisticRegression(max_iter = 100)\nmodel_n.fit(X_train, y_train)\ny_pred = model_n.predict(X_test)","54705e7d":"probs = model_n.predict_proba(X_test)\nprobs = probs[:,1]\n\nfpr, tpr, threshold = roc_curve(y_test, probs)\nroc_auc = roc_auc_score(y_test, probs)\n\nplt.figure()\nplt.plot([0, 1], label = 'Baseline', linestyle = '--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()\n","7ddfcda9":"# \u041e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\nprint('accuracy_score: {}'.format(np.round(accuracy_score(y_test, y_pred), 3)))\nprint('f1_score: {}'.format(np.round(f1_score(y_test, y_pred), 3)))\nprint('recall_score: {}'.format(np.round(recall_score(y_test, y_pred), 3)))\nprint('MSE: {}'.format(np.round(mean_squared_error(y_test, y_pred), 3)))","872bd501":"# \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f confusion matrix\nsns.set_context(context='paper', font_scale=2, rc=None)\ngroup_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\ngroup_counts = ['{0:0.0f}'.format(value) for value in confusion_matrix(y_test, y_pred).flatten()]\nlabels = [f'{v1}\\n{2}' for v1, v2 in zip(group_names, group_counts)]\nlabels = np.asarray(labels).reshape(2, 2)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=labels, fmt='', cmap='summer')","3ab8cd36":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\ndf['default'].value_counts().plot.barh()\ndf.default.value_counts()","d2d179db":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0438 \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0431\u043e\u043a\u0441\u043f\u043b\u043e\u0442\u044b\ndata = df.copy()\nfor i in num_cols:\n    plt.figure()\n    sns.boxplot(x='default', y = i, data = data)\n    plt.title(i)\n","44224b9c":"# \u0414\u0435\u043d\u044c \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0438\u0437 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\ndf.drop(['day'], axis=1, inplace=True)\nnum_cols.remove('day')","9ced9441":"df.info()","529a54f0":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432\u043b\u0438\u044f\u044e\u0442 \u043d\u0430 \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e\nnum_df = df[df['train'] == 1]\nimp_num = Series(f_classif(num_df[num_cols], num_df['default'])[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","368d40ae":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nfor i in num_cols:\n    plt.figure()\n    \n    sns.distplot(df[i], kde=False, rug=False)\n    plt.title(i)\n    plt.show()","9a9430e2":"num_cols","fb33fcce":"#score_bki \u0438\u043c\u0435\u0435\u0442 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435","a83246e5":"# \u043f\u0440\u043e\u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u0443\u0435\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nnum_cols1 = ['age', 'decline_app_cnt', 'income', 'bki_request_cnt']\nfor i in num_cols1:\n    plt.figure()\n    \n    df[i] = df[i].apply(lambda w: np.log(w + 1))\n    plt.hist(df[i], bins=50);\n    plt.title(i)\n    plt.show()\n        ","81cf6d24":"#\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0435\u0441\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 income\n","0a34dbe3":"# \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0447\u0442\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c\n\nfor i in num_cols:\n    plt.figure()\n    sns.distplot(df[i], kde=False, rug=False)\n    plt.title(i)\n    plt.show()","778c56ae":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439 \u0434\u043b\u044f \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\nplt.figure(figsize=(8, 10))\nsns.heatmap(df[num_cols+['default']].corr(), cmap='winter', annot=True)","df4baf3e":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043f\u043e \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\nfor col in bin_cols:\n    plt.figure(figsize=(8, 4))\n    prob_df = df[col].groupby(df['default']).value_counts(normalize=True).rename('percent').reset_index()\n    prob_df['percent'] *= 100\n    sns.barplot(x=col, y='percent', hue='default', data = prob_df)\n    plt.title(f'\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 {col}')\n    \n    ","146e0a16":"# \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\ntemp_df = df[df['train'] == 1]\nimp_cat = Series(mutual_info_classif(temp_df[bin_cols], temp_df['default'], discrete_features=True), index=bin_cols)\nimp_cat.sort_values(inplace=True)\nimp_cat.plot(kind='barh')","77ff9028":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439 \u0434\u043b\u044f \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nplt.figure(figsize=(10,5))\nsns.heatmap(df[bin_cols+['default']].corr(), annot=True)","aa4feefb":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u043e \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u044e \u043a \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\nfor col in cat_cols:\n    plt.figure(figsize=(8,8))\n    prop_df = df[col].groupby(df['default']).value_counts(normalize=True).rename('percent').reset_index()\n    prop_df['percent'] *= 100\n    sns.barplot(x=col, y='percent', hue='default', data=prop_df)\n    plt.title(f'\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430{col}')","89ad6b28":"# \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\ntemp_df = df[df['train'] == 1]\nimp_cat = Series(mutual_info_classif(temp_df[cat_cols], temp_df['default'], discrete_features=True), index=cat_cols)\nimp_cat.sort_values(inplace=True)\nimp_cat.plot(kind='barh')","c4ac9107":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0439 \u0434\u043b\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nplt.figure(figsize=(16,6))\nsns.heatmap(df[cat_cols+['default']].corr(), cmap='winter', annot= True)","7055b3a0":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u043a \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u0438 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0442 \u043c\u0435\u0436\u0434\u0443 \u0441\u043e\u0431\u043e\u0439 \u0438 \u0441 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\nsns.heatmap(df[bin_cols + cat_cols + ['default']].corr(method='spearman'), vmin=0, vmax=1)","047d0097":"#\u0414\u0435\u043b\u0438\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043e\u0431\u0440\u0430\u0442\u043d\u043e \u043d\u0430 \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442\ntrain = df.query('train == 1').drop(['train'], axis=1)\ntest = df.query('train == 0').drop(['train'], axis=1)","5ca4e7a6":"#\u0414\u0435\u043b\u0438\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u043d\u0430 0 \u0438 1\nX_cat = OneHotEncoder(sparse = False).fit_transform(train[cat_cols].values)\n","f4bb6305":"X_cat.shape","024b1c20":"# \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0430\u0446\u0438\u044f \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nX_num = StandardScaler().fit_transform(train[num_cols].values)\n","33fb4aa7":"#\u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c\n\nX = np.hstack([X_num, train[bin_cols].values, X_cat])\nY = train['default'].values","b93728c2":"#\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0430. \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f:","3879a969":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42 )","f4e2083b":"model_1 = LogisticRegression(max_iter=1000, random_state=42)\nmodel_1.fit(X_train, y_train)\npreds = model_1.predict(X_test)","55594bf3":"probs = model_1.predict_proba(X_test)\nprobs = probs[:,1]\n\nfpr, tpr, threshold = roc_curve(y_test, probs)\nroc_auc = roc_auc_score(y_test, probs)\n\nplt.figure()\nplt.plot([0, 1], label='Baseline', linestyle='--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = \"lower right\")\nplt.show()\n\nplot_confusion_matrix(model_1, X_test, y_test)\nplt.show()\n","761c0509":"\nprint('Accuracy: %.3f' % accuracy_score(y_test, preds))\nprint('Precision: %.3f' % precision_score(y_test, preds))\nprint('Recall: %.3f' % recall_score(y_test, preds))\nprint('F1: %.3f' % f1_score(y_test, preds))\nprint('MSE: {}' .format(np.round(mean_squared_error(y_test, preds), 3)))\n","e78fa446":"from sklearn.model_selection import GridSearchCV\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0442\u0438\u043f\u044b \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\npenalty = ['l1', 'l2']\n\n# \u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\nC = np.logspace(0, 4, 10)\n\n# \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nhyperparameters = dict(C=C, penalty=penalty)\n\nmodel = LogisticRegression(solver = 'liblinear', max_iter = 100)\nmodel.fit(X_train, y_train)\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0442\u043a\u0443 \u043f\u043e\u0438\u0441\u043a\u0430 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c 5-\u043a\u0440\u0430\u0442\u043d\u043e\u0439 \u043f\u0435\u0440\u0435\u043a\u0440\u0435\u0441\u0442\u043d\u043e\u0439 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\nclf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n\nbest_model = clf.fit(X_train, y_train)\n\n# View best hyperparameters\nprint('\u041b\u0443\u0447\u0448\u0435\u0435 Penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('\u041b\u0443\u0447\u0448\u0435\u0435 \u0421:', best_model.best_estimator_.get_params()['C'])","cd1b99c9":"# \u041f\u043e\u0434\u0431\u0438\u0440\u0430\u0435\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0432\u0440\u0443\u0447\u043d\u0443\u044e\nmodel = LogisticRegression(max_iter=1000, C=100,\n                          class_weight='balanced',\n                          multi_class='auto',\n                          penalty='l2',\n                          random_state=42,\n                          solver='liblinear',\n                          tol=0.0001,\n                          verbose=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprobs = model.predict_proba(X_test)\nprobs = probs[:,1]\n\nfpr, tpr, threshold = roc_curve(y_test, probs)\nroc_auc = roc_auc_score(y_test, probs)\n\nplt.figure()\nplt.plot([0, 1], label='Baseline', linestyle='--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = \"lower right\")\nplt.show()\n\nplot_confusion_matrix(model, X_test, y_test)\nplt.show()\n","ab647347":"X_cat_test = OneHotEncoder(sparse = False).fit_transform(test[cat_cols].values)\nX_num_test = StandardScaler().fit_transform(test[num_cols].values)\n\nX_test_test = np.hstack([X_num_test, test[bin_cols].values, X_cat_test])\ny_probs = model.predict_proba(X_test_test)[:,1]","8ab5f055":"test['default'] = y_probs","8ab16e27":"submission = test[['client_id', 'default']]\ndisplay(submission.sample(10))\ndisplay(submission.shape)","c06ae8c9":"submission.to_csv('submission.csv', index=False)","dc11fdf0":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u043f\u0435\u0440\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0445 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430\u0445 \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","af2febaa":"\u041d\u0430\u0439\u0434\u0435\u043c \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0434\u043b\u044f \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438\u044e \u041f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u043c \u043f\u043e\u0438\u0441\u043a \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 GridSearchCV \u043f\u0440\u0438 \u043f\u043e\u043c\u043e\u0449\u0438 \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043f\u043e \u0441\u0435\u0442\u043a\u0435 \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0435\u0439","a80fd1c9":"\u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c","757d5f1a":"\u0411\u043e\u043b\u044c\u0448\u0435 \u0434\u0440\u0443\u0433\u0438\u0445 \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0442 car \u0438 car_type \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u043e\u0431\u0430","e5c3f0da":"# GridSearchCV - \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043f\u043e\u0438\u0441\u043a\u043e\u043c \u043f\u043e \u0441\u0435\u0442\u043a\u0435\nfrom sklearn.linear_model import LogisticRegressionCV\nmodel = LogisticRegression(random_state=42)\n\nparam_grid = [\n    {'penalty': ['l1'],\n     'solver': ['liblinear', 'lbfgs'],\n    'class_weight': ['none', 'balanced'],\n    'multi_class': ['auto', 'ovr'],\n    'max_iter': [100]},\n    {'penalty': ['l2'],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n     'class_weight': ['none', 'balanced'],\n     'multi_class': ['auto', 'ovr'],\n    'max_iter': [100]},\n    {'penalty': ['none'],\n    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n    'class_weight': ['none', 'balanced'],\n    'multi_class': ['auto', 'ovr'],\n    'max_iter': [100]}\n]\n\ngridsearch = GridSearchCV(model, param_grid, scoring='f1', n_jobs=-1)\ngridsearch.fit(X_train, y_train)\nmodel = gridsearch.best_estimator_\n# \u043f\u0435\u0447\u0430\u0442\u0430\u0435\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0438\nbest_parameters = model.get_params()\n","c395c494":"# ","7fb76b20":"\u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u043c \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435, \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u0438 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0432 \u043e\u0434\u043d\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\u043e\u0435 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e, \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0432 \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e.","b0b29202":"client_id                 \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u043a\u043b\u0438\u0435\u043d\u0442\u0430\n\napp_date                  \u0434\u0430\u0442\u0430 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f\n\neducation                 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f\n\nsex                       \u043f\u043e\u043b \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430\n\nage                       \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430\n\ncar                       \u0444\u043b\u0430\u0433 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f\n\ncar_type                  \u0444\u043b\u0430\u0433 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f_\u0438\u043d\u043e\u043c\u0430\u0440\u043a\u0438\n\ndecline_app_cnt           \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u043e\u0448\u043b\u044b\u0445 \u0437\u0430\u044f\u0432\u043e\u043a\n\ngood_work                 \u0444\u043b\u0430\u0433 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0445\u043e\u0440\u043e\u0448\u0435\u0439 \u0440\u0430\u0431\u043e\u0442\u044b\n\nscore_bki                 \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0440\u0435\u0434\u0438\u0442\u043d\u043e\u0439 \u0438\u0441\u0442\u043e\u0440\u0438\u0438\n\nbki_reguest_cnt           \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 \u0411\u041a\u0418\n\nregion_rating             \u0440\u0435\u0433\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0435\u0439\u0442\u0438\u043d\u0433\n\nhome_address              \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0437\u0430\u0442\u043e\u0440 \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u0430\u0434\u0440\u0435\u0441\u0430\n\nwork_address              \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0437\u0430\u0442\u043e\u0440 \u0440\u0430\u0431\u043e\u0447\u0435\u0433\u043e \u0430\u0434\u0440\u0435\u0441\u0430\n\nincome                    \u0434\u043e\u0445\u043e\u0434 \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430\n\nsna                       \u0441\u0432\u044f\u0437\u044c \u0437\u0430\u0435\u043c\u0449\u0438\u043a\u0430 \u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430\u043c\u0438 \u0431\u0430\u043d\u043a\u0430\n\nfirst_time                \u0441\u0442\u0435\u043f\u0435\u043d\u044c \u0434\u0430\u0432\u043d\u043e\u0441\u0442\u0438 \u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f\n\nforeign_pasport           \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0437\u0430\u0433\u0440\u0430\u043d\u043f\u0430\u0441\u043f\u043e\u0440\u0442\u0430\n\ndefault                   \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0434\u0435\u0444\u043e\u043b\u0442\u0430","91ebc4da":"for param_name in sorted(best_parameters.keys()):\n    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n    # \u043c\u0435\u0442\u0440\u0438\u043a\u0438\npreds = model.predict(X_test)\nprint('Accuracy: %.3f' % accuracy_score(y_test, preds))\nprint('Precision: %.3f' % precision_score(y_test, preds))\nprint('Recall: %.3f' % recall_score(y_test, preds))\nprint('F1: %.3f' % f1_score(y_test, preds))\nprint('MSE: {}' .format(np.round(mean_squared_error(y_test, preds), 3)))\n","c250dc63":"\u041e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443, \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432 \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u0433\u043e\u0442\u043e\u0432\u0438\u043c submission"}}