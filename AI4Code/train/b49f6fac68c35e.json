{"cell_type":{"f013d601":"code","0ce26162":"code","3c1d9fd2":"code","c17a15db":"code","a0facac6":"code","deb75d2b":"code","d1ce3494":"code","31e4e359":"code","7f05007d":"code","e6f2c10a":"code","cde10683":"code","d9d3de11":"code","f5da9ffd":"code","2db8cc1d":"code","20d61dc5":"code","59ef8f6b":"code","6dd7a849":"code","6738dfa5":"code","2d1492e1":"code","1f22a6e0":"markdown","fdf64798":"markdown","2239e63d":"markdown","1583c818":"markdown","4428c4dc":"markdown","d5627506":"markdown","3e0db68d":"markdown","0723ecbc":"markdown"},"source":{"f013d601":"# importing necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport keras\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ce26162":"# reading csv file\nds = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv')\nds","3c1d9fd2":"len(ds)   # length of train dataset","c17a15db":"# reading test dataset\ntds = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv')\ntds.head()","a0facac6":"len(tds)     # length of test dataset","deb75d2b":"ds = ds.append(tds, ignore_index=True)\nds.shape","d1ce3494":"ds = ds['meantemp']\nds = np.array(ds)\nds = ds.reshape(-1,1)\nds","31e4e359":"plt.plot(ds)","7f05007d":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nds = scaler.fit_transform(ds)\nds","e6f2c10a":"scaler.scale_","cde10683":"train = ds[0:1462]\ntest = ds[1462:]\ntrain.shape , test.shape","d9d3de11":"def get_data(dataset, look_back):\n  datax = []\n  datay = []\n  for i in range(len(dataset)-look_back-1):\n    a = dataset[i:(i+look_back), 0]\n    datax.append(a)\n    datay.append(dataset[i+look_back, 0])\n  return np.array(datax), np.array(datay)","f5da9ffd":"look_back = 1\nx_train, y_train = get_data(train, look_back)\nx_test, y_test = get_data(test, look_back)","2db8cc1d":"x_train , y_train","20d61dc5":"x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n\nx_train.shape , x_test.shape","59ef8f6b":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(16, activation='tanh', input_shape = (1,1)))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss = 'mean_squared_error') \nmodel.fit(x_train, y_train, epochs = 20, batch_size=1)","6dd7a849":"y_pred = model.predict(x_test)\ny_pred = scaler.inverse_transform(y_pred)\ny_pred","6738dfa5":"y_test = np.array(y_test)\ny_test = y_test.reshape(-1,1)\ny_test = scaler.inverse_transform(y_test)","2d1492e1":"plt.plot(y_test, color='blue', label = 'Actual Values')\nplt.plot(y_pred, color='brown', label = 'Predicted Values')\nplt.ylabel('Passengers')\nplt.legend()","1f22a6e0":"# Predicting test data","fdf64798":"# spliting training & testing data","2239e63d":"# Visualizing the dataset","1583c818":"# Appending train and test for scaling","4428c4dc":"# Standardization","d5627506":"# plotting predicted & test labels","3e0db68d":"# **LSTM**","0723ecbc":"# Reshaping"}}