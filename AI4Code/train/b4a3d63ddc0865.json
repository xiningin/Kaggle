{"cell_type":{"ece2d082":"code","e110441f":"code","fc350c85":"code","40c88405":"code","d3108cdb":"code","c931aaa3":"code","d73210c4":"code","3c614552":"code","9c4dccfb":"code","4e342ebf":"code","b2799636":"code","7a05d332":"code","6d383b49":"code","96bdfd9b":"code","827de747":"code","0f3f923c":"code","608b75cb":"code","f970cb10":"code","affa3812":"markdown","f0130d50":"markdown","f3bb9432":"markdown","b53fd74a":"markdown","af86b8e8":"markdown","8ffaa115":"markdown","b6b3f9a9":"markdown"},"source":{"ece2d082":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e110441f":"# Resources: https:\/\/www.kaggle.com\/supratimhaldar\/deepartist-identify-artist-from-art\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","fc350c85":"#seeds:\nnp.random.seed(123)\ntf.random.set_seed(123)","40c88405":"images_dir = '..\/input\/best-artworks-of-all-time\/resized\/resized'\nartists_dirs = list(set([\" \".join(filename.split(\"_\")[:-1]) for filename in os.listdir(images_dir)])) #get all names from \/resized\/resized\nn_classes = len(artists_dirs)\nprint(artists_dirs)","d3108cdb":"fig, axes = plt.subplots(1, 5, figsize=(20,10))\n\nfor i in range(5):\n    random_image = random.choice(os.listdir(os.path.join(images_dir)))\n    random_image_file = os.path.join(images_dir, random_image)\n    image = plt.imread(random_image_file)\n    axes[i].imshow(image)\n    axes[i].set_title(\"Image: \" + random_image)\n    axes[i].axis('off')\n\nplt.show()","c931aaa3":"# using the \/images\/ folder because the folder structure is aligned with the requirements of keras\nartists_dirs = list(os.listdir('..\/input\/best-artworks-of-all-time\/images\/images'))\nimages_dir = '..\/input\/best-artworks-of-all-time\/images\/images'","d73210c4":"batch_size = 16\ntrain_input_shape = (224, 224, 3)","3c614552":"train_datagen = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1.\/255.,\n                                   shear_range=5,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    shuffle=True,\n                                                    classes=artists_dirs\n                                                   )\n\nvalid_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"validation\",\n                                                    shuffle=True,\n                                                    classes=artists_dirs\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nprint(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)\n\n#Error because folder structure doesn't match the one required by tf (in case of \/resized\/resized)\n#Check this out: https:\/\/datascience.stackexchange.com\/questions\/65979\/what-is-the-correct-way-to-call-keras-flow-from-directory-method","9c4dccfb":"train_input_shape = (224, 224, 3)","4e342ebf":"# Pre-trained model (requires activated internet-access in kaggle)\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n\nfor layer in base_model.layers:\n    layer.trainable = True","b2799636":"X = base_model.output\nX = Flatten()(X)\n\nX = Dense(512, kernel_initializer='he_uniform')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\nX = Dense(16, kernel_initializer='he_uniform')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\noutput = Dense(n_classes, activation='softmax')(X)\n\nmodel = Model(inputs=base_model.input, outputs=output)","7a05d332":"optimizer = Adam(lr=0.0001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])","6d383b49":"n_epoch = 5 #takes way too long for anything > 1\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              verbose=1, mode='auto')","96bdfd9b":"history1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr],\n                              use_multiprocessing=True,\n                              workers=16\n                             )","827de747":"for layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[:50]:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])\n\nn_epoch = 8\nhistory2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr, early_stop],\n                              use_multiprocessing=True,\n                              workers=16\n                             )","0f3f923c":"# Prediction accuracy on train data\nscore = model.evaluate_generator(train_generator, verbose=1)\nprint(\"Prediction accuracy on train data =\", score[1])","608b75cb":"# Acccuracy\nscore = model.evaluate_generator(valid_generator, verbose=1)\nprint(\"Prediction accuracy on CV data =\", score[1])","f970cb10":"# Prediction\nfrom keras.preprocessing import *\n\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(25,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_dirs)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n\n    # Original image\n\n    test_image = image.load_img(random_image_file, target_size=(train_input_shape[0:2]))\n\n    # Predict artist\n    test_image = image.img_to_array(test_image)\n    test_image \/= 255.\n    test_image = np.expand_dims(test_image, axis=0)\n\n    prediction = model.predict(test_image)\n    prediction_probability = np.amax(prediction)\n    prediction_idx = np.argmax(prediction)\n\n    labels = train_generator.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n\n\n    title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n                .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n                        prediction_probability*100)\n\n    # Print image\n    axes[i].imshow(plt.imread(random_image_file))\n    axes[i].set_title(title)\n    axes[i].axis('off')\n\nplt.show()","affa3812":"# Image Exploration","f0130d50":"# Build Model","f3bb9432":"# Build NN","b53fd74a":"# Artist Recognition","af86b8e8":"# Intuition\n- Model should classify the artist and not objects in painting\n    - this requires understanding of paint style -> shallow layers > deep layers","8ffaa115":"# Prerequisites","b6b3f9a9":"# Prediction"}}