{"cell_type":{"123d78c5":"code","467da40b":"code","e6d29400":"code","6807fea0":"code","979a3878":"code","6d3ad4b1":"code","d11f3ee9":"code","0acf9a7c":"code","453cf0cd":"code","e4f8acb7":"code","31ec6377":"code","facd92ba":"code","5269806a":"code","1499028d":"code","9a64aa60":"code","26154bf2":"code","f48650df":"code","ddf1975b":"code","d7139661":"code","b0315e20":"code","413e554d":"code","57d155bd":"code","1d56df1f":"code","c6786d77":"code","6912e894":"code","88d0342e":"code","18150b69":"code","00e88a3e":"code","14e435fa":"code","b0afceee":"code","82efce98":"code","b6dda856":"code","b9a27876":"code","299d786e":"code","0d236e2c":"code","24aa9eec":"code","63806b16":"code","e19d8cf7":"code","bbe7dd5d":"code","e3e0a850":"code","8f449f78":"code","cc095f60":"code","e57e3f6a":"code","301e6a11":"code","5d1f8380":"code","30d40af0":"code","8f220a5d":"code","e083d802":"code","a0f9b439":"code","98b960eb":"code","ed797ae2":"code","314f8bd1":"code","83237e42":"code","2c5f8343":"code","8f6a113b":"code","b9972ffa":"code","71ab5448":"code","0a9fc95d":"code","99fb9448":"code","ebb3a4c2":"code","77edd641":"markdown","b670c3b1":"markdown","d8ef4153":"markdown","c2d3b591":"markdown","c2b5d2b0":"markdown","b632d75d":"markdown","485925bd":"markdown","13d9cde4":"markdown","7c402136":"markdown","82326635":"markdown","a0f87327":"markdown","f73c4050":"markdown","f7b88585":"markdown","e2ea2327":"markdown","6fc32c6c":"markdown","1e222ea6":"markdown","d7f18782":"markdown","de91483c":"markdown","26cd6fb6":"markdown","7fa9af51":"markdown","90604fed":"markdown","49a74b84":"markdown","23849699":"markdown","41c1d038":"markdown","657e64f8":"markdown","e3082e16":"markdown","596779b3":"markdown","91c36120":"markdown","d2625b4b":"markdown","b1799c0b":"markdown","8d71ef2b":"markdown","efc31397":"markdown","a899e081":"markdown","264db287":"markdown","1c26dda4":"markdown","501bfabb":"markdown","d3bca17c":"markdown","831de06a":"markdown","fd1b3d6d":"markdown","02616a75":"markdown","2f3221fe":"markdown","3d10adfd":"markdown","4ee003a8":"markdown","ee4e12de":"markdown","a8d104b4":"markdown","4b52a94d":"markdown","b025d533":"markdown","4e6e32b8":"markdown","ab263d75":"markdown"},"source":{"123d78c5":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport re\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set(style='white', context='notebook', palette='deep')\n\nfrom collections import Counter\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Decision_Tree\nfrom sklearn import tree","467da40b":"# Acquire filenames\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e6d29400":"# Load Train and Test data\n# Combine Train and Test data\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ncombine = [train_df, test_df]\ndataset =  pd.concat(objs=[train_df, test_df], axis=0).reset_index(drop=True)","6807fea0":"train_df.shape, test_df.shape, dataset.shape","979a3878":"print(train_df.columns.values)","6d3ad4b1":"# preview the data\ntrain_df.head()","d11f3ee9":"print(train_df.info())","0acf9a7c":"# Check for Null values\nprint(train_df.isnull().sum().sort_values(ascending=False).head())\ntest_df.isnull().sum().sort_values(ascending=False).head()","453cf0cd":"train_df.describe(include=['object'])","e4f8acb7":"# Summarie and statistics\ntrain_df.describe()\n\n# Review survived rate using percentiles\n#train_df['Survived'].quantile([.61,.62])\n#train_df['Pclass'].quantile([.4, .45])\n#train_df['SibSp'].quantile([.65, .7])\n#train_df[['Age', 'Fare']].quantile([.05,.1,.2,.4,.6,.8,.9,.99])","31ec6377":"# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   ","facd92ba":"# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train_df,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","5269806a":"# Show the outliers rows\ntrain_df.loc[Outliers_to_drop]","1499028d":"test_df.describe()","9a64aa60":"# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \ng = sns.heatmap(train_df[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True,fmt = \".2f\",cmap = \"coolwarm\",alpha=.8,vmin=-1, vmax=1)","26154bf2":"# Explore SibSp feature vs Survived\ng = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train_df,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","f48650df":"# Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=train_df,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","ddf1975b":"# Explore Age vs Survived\ng = sns.FacetGrid(train_df, col='Survived')\ng = g.map(sns.distplot, \"Age\")","d7139661":"# Explore Age distibution \ng = sns.kdeplot(train_df[\"Age\"][(train_df[\"Survived\"] == 0) & (train_df[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train_df[\"Age\"][(train_df[\"Survived\"] == 1) & (train_df[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xticks(range(0,100,10))\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","b0315e20":"dataset[\"Fare\"].isnull().sum()","413e554d":"#Fill Fare missing values with the median value\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","57d155bd":"# Explore Fare distribution \ng = sns.distplot(dataset[\"Fare\"], color=\"r\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","1d56df1f":"# Apply log to Fare to reduce skewness distribution\ndataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i+1))","c6786d77":"g = sns.distplot(dataset[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","6912e894":"g = sns.barplot(x=\"Sex\",y=\"Survived\",data=train_df)\ng = g.set_ylabel(\"Survival Probability\")","88d0342e":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","18150b69":"# Explore Pclass vs Survived\ng = sns.factorplot(x=\"Pclass\",y=\"Survived\",data=train_df,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","00e88a3e":"# Explore Pclass vs Survived by Sex\ng = sns.factorplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_df,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","14e435fa":"dataset[\"Embarked\"].isnull().sum()","b0afceee":"#Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","82efce98":"# Explore Embarked vs Survived \ng = sns.factorplot(x=\"Embarked\", y=\"Survived\",  data=train_df,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b6dda856":"# Explore Pclass vs Embarked \ng = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=train_df,\n                   size=6, kind=\"count\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","b9a27876":"# convert Sex into categorical value 0 for male and 1 for female\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})","299d786e":"g = sns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),fmt = \".2f\",cmap=\"BrBG\",annot=True,alpha=.8,vmin=-1, vmax=1)","0d236e2c":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\ng = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ng.map(plt.hist, 'Age', bins=20, alpha=.7)\ng.add_legend()","24aa9eec":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med","63806b16":"dataset['Age'].isnull().sum()","e19d8cf7":"g = sns.factorplot(x=\"Survived\", y = \"Age\",data = train_df, kind=\"box\")\ng = sns.factorplot(x=\"Survived\", y = \"Age\",data = train_df, kind=\"violin\")","bbe7dd5d":"print(\"Before\", dataset.shape)\n\ndataset.drop(['Cabin', 'Ticket', 'PassengerId'], axis=True, inplace=True)\n\nprint('After', dataset.shape)","e3e0a850":"dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)","8f449f78":"pd.crosstab(dataset['Title'], dataset['Sex'])","cc095f60":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45)","e57e3f6a":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona',\"Ms\" ,\"Mme\",\"Mlle\"],'Rare')","301e6a11":"g = sns.countplot(dataset[\"Title\"])","5d1f8380":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"survival probability\")","30d40af0":"# Drop Name variable\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","8f220a5d":"# Create a family size descriptor from SibSp and Parch\ndataset['Familysize'] = dataset['Parch'] + dataset['SibSp'] + 1","e083d802":"g = sns.factorplot(x=\"Familysize\",y=\"Survived\",data = dataset)\ng = g.set_ylabels(\"Survival Probability\")","a0f9b439":"# Create new feature of family size\nbins = [0,1,2,4,8]\nlabels = ['Single','SmallF','MedF','LargeF']\ndataset[\"Familysize\"] = pd.cut(dataset[\"Familysize\"], bins, labels=labels)","98b960eb":"g = sns.factorplot(x=\"Familysize\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"survival probability\")","ed797ae2":"# Drop Fsize\/SibSp\/Parch variable\ndataset.drop(labels = ['SibSp','Parch'], axis = 1, inplace = True)","314f8bd1":"# Create categorical values for Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset[\"Sex\"] = dataset[\"Sex\"].astype(\"category\")","83237e42":"dataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"],prefix=\"Em\")\ndataset = pd.get_dummies(dataset, columns = [\"Familysize\"],prefix=\"Fs\")","2c5f8343":"dataset = pd.get_dummies(dataset)","8f6a113b":"dataset.head()","b9972ffa":"train_df.shape[0]","71ab5448":"## Separate train dataset and test dataset\n\ntrain = dataset[:train_df.shape[0]]\nX_test = dataset[train_df.shape[0]:]\nX_test.drop(labels=[\"Survived\"],axis = 1,inplace=True)","0a9fc95d":"## Separate train features and label \nX_train = train.drop(labels = [\"Survived\"],axis = 1)\nY_train = train[\"Survived\"].astype(int)","99fb9448":"# Decision Tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nacc_decision_tree = round(clf.score(X_train, Y_train)*100, 2)\nacc_decision_tree","ebb3a4c2":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n#submission.to_csv('.\/input\/submission.csv', index=False)","77edd641":"#### Parch","b670c3b1":"# Titanic Analyst Report","d8ef4153":"### 3.4. Correlating Features analysis\n\n#### 3.4.1 Numerical features","c2d3b591":"Only Fare feature seems to have a significative correlation with the survival probability.\n\nIt doesn't mean that the other features are not usefull. Subpopulations in these features can be correlated with the survival. To determine this, we need to explore in detail these features","c2b5d2b0":"#### 3.6.2 Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.","b632d75d":"Age distribution seems to be a tailed distribution, maybe a gaussian distribution.\n\nWe notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived.\n\nSo, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n\nIt seems that very young passengers have more chance to survive.","485925bd":"#### Fare","13d9cde4":"#### SibSP","7c402136":"### 3.6 Feature engineering","82326635":"Indeed, the third class is the most frequent for passenger coming from Southampton (S) and Queenstown (Q), whereas Cherbourg passengers are mostly in first class which have the highest survival rate.","a0f87327":"No difference between median value of age in survived and not survived subpopulation.\n\nBut in the violin plot of survived passengers, we still notice that very young passengers have higher survival rate.","f73c4050":"### 2.2 Acquire data","f7b88585":"#### Embarked","e2ea2327":"**3.1.6 Which features contain blank, null or empty values?**\n\n- Cabin > Age > Embarked features contain a number of null values in that order for the training dataset.\n- Cabin > Age are incomplete in case of test dataset.\n\n**3.1.7 What are the data types for various features?**\n\n- Seven features are integer or floats.\n- Five features are strings (object).","6fc32c6c":"**3.1.2 Which features are categorical?**  \n*Within categorical features are the values nominal, ordinal, ratio, or interval based?*\n\n- Categorical: Survived, Sex and Embarked. \n- Ordinal: Pclass.\n\n**3.1.3 Which features are numerical?**  \n*Within numerical features are the values discrete, continuous, or timeseries based? *\n\n- Continous: Age and Fare. \n- Discrete: SibSp and Parch.","1e222ea6":"**3.1.8 What is the distribution of categorical features?**\n\n- Names are unique across the dataset (count=unique=891)\n- Sex variable as two possible values with 65% male (top=male, freq=577\/count=891).\n- Ticket feature has high ratio (24%) of duplicate values (unique=681).\n- Cabin values have several dupicates across samples. Alternatively several passengers shared a cabin.\n- Embarked takes three possible values. S port used by most passengers (top=S)","d7f18782":"Since we have two missing values , i decided to fill them with the most fequent value of \"Embarked\" (S).","de91483c":"It seems that passengers having a lot of siblings\/spouses have less chance to survive\n\nSingle passengers (0 SibSP) or with two other persons (SibSP 1 or 2) have more chance to survive\n\nThis observation is quite interesting, we can consider a new feature describing these categories (See feature engineering)","26cd6fb6":"**3.1.4 Which features are mixed data types?**  \n\n- Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.\n\n**3.1.5 Which features may contain errors or typos?**\n\n- Name feature may contain errors or typos as there are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names.","7fa9af51":"#### 3.6.1 Correcting by dropping features\n\nBased on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.","90604fed":"## Step 4: Model, predict and solve","49a74b84":"It is interesting to note that passengers with rare title have more chance to survive.","23849699":"As we can see, Fare distribution is very skewed. This can lead to overweigth very high values in the model, even if it is scaled.\n\nIn this case, it is better to transform it with the log function to reduce this skew.","41c1d038":"Since outliers can have a dramatic effect on the prediction (espacially for regression problems), i choosed to manage them.\n\nI decided to detect outliers from the numerical values features (Age, SibSp, Sarch and Fare). Then, i considered outliers as rows that have at least two outlied numerical values.","657e64f8":"When we superimpose the two densities , we cleary see a peak correponsing (between 0 and 5) to babies and very young childrens.","e3082e16":"We detect 10 outliers. The 28, 89 and 342 passenger have an high Ticket Fare\n\nThe 7 others have very high values of SibSP.\n\nbecause test data have high ticket Fare and high values of SibSp, so we don't drop the outliers.","596779b3":"## Step 1: Question or problem definition\n\n**Project Summary.**  \nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n**Goal.**   \nIt is your job to predict if a passenger survived the sinking of the Titanic or not. \nFor each in the test set, you must predict a 0 or 1 value for the variable.","91c36120":"#### 3.4.2 Categorical features","d2625b4b":"## Step3: Wrangle, prepare, cleanse the data\n\n### 3.1 Analyze by describing data\n\n**3.1.1 Which features are available in the dataset?**","b1799c0b":"Infant passengers in Pclass=2 and Pclass=3 mostly survived. \n\na few of young passengers in Pclass=3 survived.\n\nPclass varies in terms of Age distribution of passengers.  ","8d71ef2b":"#### Sex","efc31397":"Small families have more chance to survive, more than single (Parch 0), medium (Parch 3,4) and large families (Parch 5,6 ).\n\nBe carefull there is an important standard deviation in the survival of passengers with 3 parents\/children ","a899e081":"Since we have one missing value , i decided to fill it with the median value which will not have an important effect on the prediction.","264db287":"The family size seems to play an important role, survival probability is worst for large families.\n\nAdditionally, i decided to created 4 categories of family size.","1c26dda4":"Skewness is clearly reduced after the log transformation","501bfabb":"It seems that passenger coming from Cherbourg (C) have more chance to survive.\n\nMy hypothesis is that the proportion of first class passengers is higher for those who came from Cherbourg than Queenstown (Q), Southampton (S).\n\nLet's see the Pclass distribution vs Embarked","d3bca17c":"The correlation map confirms the factorplots observations except for Parch. Age is not correlated with Sex, but is negatively correlated with Pclass, Parch and SibSp.\n\nIn the plot of Age in function of Parch, Age is growing with the number of parents \/ children. But the general correlation is negative.\n\nSo, i decided to use SibSP, Parch and Pclass in order to impute the missing ages.\n\nThe strategy is to fill Age with the median age of similar rows according to Pclass, Parch and SibSp.","831de06a":"**3.1.9 What is the distribution of numerical feature values across the samples?**\n\n- Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n- Survived is a categorical feature with 0 or 1 values.\n- Around 38% samples survived representative of the actual survival rate at 32%.\n- Nearly 45% of the passengers had in No.3 pclass.\n- Few elderly passengers (<1%) within age range 65-80.\n- Nearly 30% of the passengers had siblings and\/or spouse aboard.\n- Most passengers (> 75%) did not travel with parents or children.\n- Fares varied significantly with few passengers (<1%) paying as high as $512.","fd1b3d6d":"### 3.3 Assumtions based on data analysis\n\n**Correlating.**\n\n1. We want to know how well does each feature correlate with Survival. We want to do this early in our project and match these quick correlations with modelled correlations later in the project.\n\n**Completing.**\n\n1. We may want to complete Age feature as it is definitely correlated to survival.\n2. We may want to complete the Embarked feature as it may also correlate with survival or another important feature.\n\n**Correcting.**\n\n1. Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation between Ticket and survival.\n2. Cabin feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\n3. PassengerId may be dropped from training dataset as it does not contribute to survival.\n4. Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped.\n\n**Creating.**\n\n1. We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n2. We may want to engineer the Name feature to extract Title as a new feature.\n3. We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n4. We may also want to create a Fare range feature if it helps our analysis.\n\n**Classifying.**\n\nWe may also add to our assumptions based on the problem description noted earlier.\n\n1. Women (Sex=female) were more likely to have survived.\n2. Children (Age<?) were more likely to have survived. \n3. The upper-class passengers (Pclass=1) were more likely to have survived.","02616a75":"#### Age","2f3221fe":"### 3.2 Outlier detection","3d10adfd":"There is 17 titles in the dataset, most of them are very rare and we can group them in 4 categories.","4ee003a8":"#### Family size\n\nWe can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets.","ee4e12de":"## Step 2: Acquire training and testing data\n\n### 2.1 Load Data Modelling Libraries","a8d104b4":"Sex We confirm the observation during problem definition that Sex=female had very high survival rate at 74%.","4b52a94d":"The passenger survival is not the same in the 3 classes. First class passengers have more chance to survive than second class and third class passengers.\n\nThis trend is conserved when we look at both male and female passengers.","b025d533":"### 3.5 Completing Features\n\n#### 3.5.1 Age\n\nAs we see, Age column contains 256 missing values in the whole dataset.\n\nSince there is subpopulations that have more chance to survive (children for example), it is preferable to keep the age feature and to impute the missing values. \n\nTo adress this problem, i looked at the most correlated features with Age (Sex, Parch , Pclass and SibSP).","4e6e32b8":"#### Pclass","ab263d75":"## Step 5: Model evaluation"}}