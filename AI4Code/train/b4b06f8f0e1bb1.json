{"cell_type":{"7409a221":"code","6678cd19":"code","b556dce4":"code","60bd70a8":"code","a976b321":"code","2c1708ef":"code","9a9bca26":"code","0bddc947":"code","ba979482":"code","a1eff9f5":"code","36c3a86d":"code","49e45be8":"code","501ebcf7":"code","4da06803":"code","ea1e7d29":"code","bd2f8648":"code","8df3f9f9":"code","29546f12":"code","ae57254b":"code","f4ec2753":"code","cc292d93":"code","c7873506":"code","0e1d5752":"code","03c8d092":"code","bda6d1e9":"markdown","fa675275":"markdown"},"source":{"7409a221":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import text\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, LSTM, Dropout, Bidirectional, Conv1D, MaxPooling1D\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","6678cd19":"random.seed(42)","b556dce4":"df = pd.read_csv(\"\/kaggle\/input\/amazon-music-reviews\/Musical_instruments_reviews.csv\")","60bd70a8":"df.head()","a976b321":"df[\"text\"] = df.apply(lambda x: str(x[\"summary\"]) + \" \" + str(x[\"reviewText\"]), axis=1)","2c1708ef":"df[\"split\"] = df.apply(lambda x: \"train\" if random.randrange(0,100) > 10 else \"valid\", axis=1)","9a9bca26":"df[\"split\"].value_counts()","0bddc947":"df_train = df[df[\"split\"] == \"train\"]\ndf_val = df[df[\"split\"] == \"valid\"]","ba979482":"tokenizer=Tokenizer(oov_token=\"'oov'\")\ntokenizer.fit_on_texts(df_train['text'])","a1eff9f5":"maxlen = 200\ntrain_X = pad_sequences(tokenizer.texts_to_sequences(df_train['text']), maxlen=maxlen)\nval_X = pad_sequences(tokenizer.texts_to_sequences(df_val['text']), maxlen=maxlen)","36c3a86d":"train_Y = df_train[\"overall\"]\nval_Y = df_val[\"overall\"]\ntrain_Y_cat = to_categorical(df_train[\"overall\"]-1, num_classes=5)\nval_Y_cat = to_categorical(df_val[\"overall\"]-1, num_classes=5)","49e45be8":"glove_dir=\"\/kaggle\/input\/glove-global-vectors-for-word-representation\/\"\n\nembedding_index = {}\nf = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='utf8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embedding_index[word] = coefs\nf.close()\nprint('Found %s word vectors ' % len(embedding_index))","501ebcf7":"max_words = len(tokenizer.word_index) + 1\nembedding_dim = 100\nembedding_matrix = np.zeros((max_words,embedding_dim))\n\nfor word, idx in tokenizer.word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[idx]=embedding_vector","4da06803":"model=Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"linear\"))\nmodel.compile(optimizer=\"Adam\", loss='mean_squared_error', metrics=['mse'])\nprint(model.summary())","ea1e7d29":"model.fit(train_X, train_Y, epochs=30, batch_size=256, validation_data=(val_X, val_Y))","bd2f8648":"pred = model.predict(val_X)","8df3f9f9":"pred_hard = np.array([round(p[0]) for p in pred])","29546f12":"pred_hard[pred_hard < 1] = 1\npred_hard[pred_hard > 5] = 5","ae57254b":"np.unique(pred_hard)","f4ec2753":"accuracy_score(val_Y, pred_hard)","cc292d93":"model=Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(5, activation=\"softmax\"))\nmodel.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","c7873506":"model.fit(train_X, train_Y_cat, epochs=30, batch_size=256, validation_data=(val_X, val_Y_cat))","0e1d5752":"pred = model.predict(val_X)","03c8d092":"accuracy_score(val_Y, [np.argmax(p)+1 for p in pred])","bda6d1e9":"## Regression","fa675275":"## Classification"}}