{"cell_type":{"7f1be1a8":"code","2be0c9b3":"code","a49267dc":"code","a0ce5d98":"code","f96c3388":"code","80b08241":"code","e522a68e":"code","2a461bf6":"code","a9720bc1":"code","2594a7e4":"code","82c748db":"code","08bf14d0":"code","30e87a68":"markdown"},"source":{"7f1be1a8":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","2be0c9b3":"learning_rate = 1e-4\ntraining_epoches = 100\nbatch_size = 50\nScaler = preprocessing.StandardScaler()\n#drop_prob=0.3","a49267dc":"train = pd.read_csv('2020AI_soil_train.csv', header=None, skiprows=1,usecols=range(1,9))\ntest = pd.read_csv('2020_soil_test.csv', header = None, skiprows=1, usecols=range(1,8))","a0ce5d98":"x_train = train.loc[:,1:7]\ny_train = train.loc[:,8:8]\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nx_train = torch.FloatTensor(x_train)\ny_train = torch.FloatTensor(y_train)","f96c3388":"train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n\ndata_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True,\n                                          drop_last=True)","80b08241":"linear1 = torch.nn.Linear(7,64, bias = True) # feature\nlinear2 = torch.nn.Linear(64,64, bias = True)\nlinear3 = torch.nn.Linear(64,32, bias = True)\nlinear4 = torch.nn.Linear(32,32, bias = True)\nlinear5 = torch.nn.Linear(32,32, bias = True)\nlinear6 = torch.nn.Linear(32,32, bias = True)\nlinear7 = torch.nn.Linear(32,16, bias = True)\nlinear8 = torch.nn.Linear(16,16, bias = True)\nlinear9 = torch.nn.Linear(16,8, bias = True)\nlinear10 = torch.nn.Linear(8,8, bias = True)\nlinear11 = torch.nn.Linear(8,4, bias = True)\nlinear12 = torch.nn.Linear(4,1, bias = True)\n","e522a68e":"torch.nn.init.kaiming_uniform_(linear1.weight)\ntorch.nn.init.kaiming_uniform_(linear2.weight)\ntorch.nn.init.kaiming_uniform_(linear3.weight)\ntorch.nn.init.kaiming_uniform_(linear4.weight)\ntorch.nn.init.kaiming_uniform_(linear5.weight)\ntorch.nn.init.kaiming_uniform_(linear6.weight)\ntorch.nn.init.kaiming_uniform_(linear7.weight)\ntorch.nn.init.kaiming_uniform_(linear8.weight)\ntorch.nn.init.kaiming_uniform_(linear9.weight)\ntorch.nn.init.kaiming_uniform_(linear10.weight)\ntorch.nn.init.kaiming_uniform_(linear11.weight)\ntorch.nn.init.kaiming_uniform_(linear12.weight)","2a461bf6":"model = torch.nn.Sequential(linear1,\n                            linear2,\n                            linear3,\n                            linear4,\n                            linear5,\n                            linear6,\n                            linear7,\n                            linear8,\n                            linear9,\n                            linear10,\n                            linear11,\n                            linear12\n                            ).to(device)","a9720bc1":"loss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","2594a7e4":"total_batch = len(data_loader)\n#model.train()\nfor epoch in range(training_epoches):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n    avg_cost += cost \/ total_batch\n  \n  print('Epoch:','%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\nprint('Learning finshed')","82c748db":"with torch.no_grad():\n  #model.eval()\n  x_test = test.loc[:,1:7]\n  x_test = np.array(x_test)\n\n  x_test = torch.from_numpy(x_test).float().to(device)\n\n  prediction = model(x_test)","08bf14d0":"correct_prediction = prediction.cpu().numpy().reshape(-1,1)","30e87a68":"\ucd08\uae30\ud654 \ubc29\ubc95 \ubcc0\uacbd : xavier_uniform -> kaiming_uniform"}}