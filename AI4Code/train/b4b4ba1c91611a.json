{"cell_type":{"1d73187a":"code","d7119121":"code","3f1d97a5":"code","2211dbdf":"code","d0c47136":"code","56b4619d":"code","37a6ab38":"code","270131b9":"code","14368d9f":"code","1d30d474":"code","c0dce108":"code","34ccea0c":"code","743bc5d9":"code","6baa5888":"code","b2c236b1":"code","f9c94041":"code","af9e04a8":"code","31376fac":"code","c3411bc4":"code","59f6d16e":"markdown","86ace650":"markdown","7e4914f2":"markdown","63306acb":"markdown","48a93cc7":"markdown","df2178b1":"markdown","65cc6775":"markdown","89b3936b":"markdown","be375ad1":"markdown","413e5c36":"markdown"},"source":{"1d73187a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d7119121":"All_Sources = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')","3f1d97a5":"All_Sources.columns\n##Begin with understanding our dataset columns and list them out","2211dbdf":"All_Sources.head(10)\n#Sample the data, are there any columns that we would like to focus on first?","d0c47136":"##After the sample I would like to get an good idea of the size of this dataset therefore count the rows\ncount_row = All_Sources.shape[0]  \ncount_row","56b4619d":"print(All_Sources['journal'].describe())","37a6ab38":" print(All_Sources['journal'].value_counts())","270131b9":"import csv\nf= open(\"\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv\")\ncsvreader = csv.reader(f)\nAll_Data = list(csvreader)","14368d9f":"Journals = [row[10] for row in All_Data]\n\nJournals_Counts = {}\nfor Journals in Journals:\n    if Journals not in Journals_Counts:\n        Journals_Counts[Journals] = 1\n    else:\n        Journals_Counts[Journals] += 1\n        \nJournals_Counts\npd.DataFrame.from_dict(Journals_Counts, orient='index')","1d30d474":"Journal_Counts_CSV = pd.DataFrame.from_dict(Journals_Counts, orient='index')\nJournal_Counts_CSV.to_csv('Jounal_Counts.csv')","c0dce108":"import matplotlib as plt\nAll_Sources['journal'].value_counts().iloc[[0,1,2,3,4]].plot.barh(\n    title = 'Top Five Active Journals')","34ccea0c":"All_Sources['journal'].value_counts().iloc[[0,1,2,3,4,5,6,7,8,9]].plot.pie(figsize = (10,10), autopct = '%.2f%%',\n                                                                           title = 'Top Ten Active Journals')","743bc5d9":"##Lets focus on the abstract column as a starting point for our sentiment-analysis, and convert it to string. \nAll_Sources['abstract'] = All_Sources['abstract'].astype(str)\n##Lowercase the abstract column\nAll_Sources['abstract'] = All_Sources['abstract'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n##Remove punctuation\nAll_Sources['abstract'] = All_Sources['abstract'].str.replace('[^\\w\\s]','')\n##Remove stop words\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nAll_Sources['abstract'] = All_Sources['abstract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\nAll_Sources = All_Sources.drop_duplicates()","6baa5888":"##Removing empty abstract values \nAll_Sources['abstract'] = All_Sources['abstract'].fillna('nan')\nMy_List = ['nan']\nAll_Sources=All_Sources[All_Sources[\"abstract\"].isin(My_List) == False]","b2c236b1":"##Now let's run our sentiment \nfrom textblob import TextBlob\ndef senti(x):\n    return TextBlob(x).sentiment  \n \nAll_Sources['senti_score'] = All_Sources['abstract'].apply(senti)\n \nAll_Sources.senti_score.head()","f9c94041":"##In order to prepare visuals we will need to clean our sentiment scores and sort them into two new columns\nAll_Sources['senti_score'] = All_Sources['senti_score'].astype(str)\nAll_Sources['senti_pos_neg'], All_Sources['senti_subjectivity'] = All_Sources['senti_score'].str.split(',', 1).str\nAll_Sources['senti_pos_neg'] = All_Sources.senti_pos_neg.str.replace('Sentiment\\(polarity=,?' , '')\nAll_Sources['senti_subjectivity'] = All_Sources.senti_subjectivity.str.replace('subjectivity=,?' , '')\nAll_Sources['senti_subjectivity'] = All_Sources.senti_subjectivity.str.replace('\\)' , '')\nAll_Sources[['senti_subjectivity', 'senti_pos_neg']] = All_Sources[['senti_subjectivity', 'senti_pos_neg']].apply(pd.to_numeric)","af9e04a8":"All_Sources['senti_pos_neg'].plot.hist()","31376fac":"All_Sources['senti_pos_neg'].value_counts().iloc[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]].plot.pie(figsize = (12,12), autopct = '%.2f%%',\n                                    title = 'Top Percentages of Sentiment Reflected in the Data')","c3411bc4":"Senti_Counts = All_Sources['senti_pos_neg'].value_counts()\nSenti_Counts","59f6d16e":"**Here we have now an visual representation of the frequency of the sentiment associated with all abstracts in our dataset. \nPositive words in sentiment obtain an + score, and - for a negative word. Let's continue in our understanding of the sentiment associated with the abstracts associated with the Journals. **","86ace650":"**Upon file import it is of utmost importance to completely understand the data in the context of healthcare. \nPython is helpful in data exploration, similar to an open world video game simulation. **","7e4914f2":"**The first score is sentiment polarity which tells if the sentiment is positive or negative and the second score is subjectivity score to tell how subjective is the text included in the abstract.** ","63306acb":"**This is for the most part, a small dataset therefore let us find any trends to focus our analysis. \nAs we would expect most of the columns have varied data let's see who the most active journals are on COVID-19.\nWe may afterwards find the most active authors. **","48a93cc7":"**From our analysis we can quickly sort in on the most active journals, and even focus in on those that have full text.  \nFor now lets continue understanding the most active journals. **","df2178b1":"**Afterwards we may then switch over and begin NLP as an subsequent method of analysis in an seperate project.**","65cc6775":"**PLoS One is by far the most active journal. Let us see if we can identify any trends that might provide greater insight. **","89b3936b":"Goal\n\nGiven the large amount of literature and rapidly spreading COVID-19, it is difficult to differ an understanding between the research presented by the academic community and the information being presented for mass consumption, as COVID-19 is approached with aggressive timelines. The pretext is to gain a basic level understanding of the sentiment regarding COVID-19 presented by reputable sources.\n\nApproach:\n\n    Exploratory data analysis","be375ad1":"** The top percentages of sentiment reflected in the data show us the data predominantly supports neutral to positive sentiment in our journal abstracts. **","413e5c36":"**Here we get an great basic visual of where the next most active journals are in relation to the number one most active. **"}}