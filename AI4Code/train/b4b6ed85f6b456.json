{"cell_type":{"ada854a0":"code","d9dc033a":"markdown","12496b61":"markdown"},"source":{"ada854a0":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n\n\n# Load data \ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ncombine = [train_df, test_df]\n\n# Preprocess the data\n## Print a basic data description and Print descriptive statistics\nprint(\"Checking basic data description:\")\nprint(train_df.info())\nprint(\"Checking descriptive statistics:\")\nprint(train_df.describe())\n\n## Age Histogram\nprint(\"Histogram of surivals across different ages\")\ng = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\nplt.show()\n\n## Correlation between features\nprint(\"Correlation map between features: higher means more correlation\")\nsns.heatmap(train_df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()\n\n\n## Drop Field\ntrain_df = train_df.drop(['Ticket', 'Cabin', 'Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin', 'Name'], axis=1)\n## Fill Fare in test data with median\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ncombine = [train_df, test_df]\n\n## Convert Sex to 0\/1\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n## Convert Embarked to 0\/1\/2, fill NA with mode\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n## fill missing values in Age with mean in train dataset\nage_mean = train_df['Age'].dropna().mean()\nprint(\"mean age in train dataset is \" + str(age_mean))\ntrain_df['Age'].fillna(age_mean, inplace=True)\ntest_df['Age'].fillna(age_mean, inplace=True)\n\nX_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n\n# split the train data into train and valid set\nX_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.10, random_state=111)\nprint(\"Checking X_train and X_valid shape:\" + str(X_train.shape) + str(X_valid.shape))\n\n# Logistic Regression\nprint(\"Try Logistic Regression Model...\")\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n#Y_pred = logreg.predict(X_test)\nY_valid_pred = logreg.predict(X_valid)\nprint(\"Validation accuracy is \"+ str(accuracy_score(Y_valid, Y_valid_pred)))\nprint(\"Validation f1 score is \" + str(f1_score(Y_valid, Y_valid_pred)))\nprint(\"Validation AUC is \" + str(roc_auc_score(Y_valid, Y_valid_pred)))\n\n# Random Forest\nprint(\"Try Random Forest Model...\")\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_valid_pred = random_forest.predict(X_valid)\nprint(\"Validation accuracy is \"+ str(accuracy_score(Y_valid, Y_valid_pred)))\nprint(\"Validation f1 score is \" + str(f1_score(Y_valid, Y_valid_pred)))\nprint(\"Validation AUC is \" + str(roc_auc_score(Y_valid, Y_valid_pred)))\n\n# SVM\nprint(\"Try SVM Model...\")\nmodel_svc=SVC(C=100,kernel='rbf')\nmodel_svc.fit(X_train, Y_train)\nY_valid_pred = model_svc.predict(X_valid)\nprint(\"Validation accuracy is \"+ str(accuracy_score(Y_valid, Y_valid_pred)))\nprint(\"Validation f1 score is \" + str(f1_score(Y_valid, Y_valid_pred)))\nprint(\"Validation AUC is \" + str(roc_auc_score(Y_valid, Y_valid_pred)))\n\n# Use random forest model because it performs best on validation set\nY_pred = random_forest.predict(X_test)\n\n# Output\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)\ndata=pd.read_csv(\"submission.csv\")\nprint(\"Checking submission format:\")\nprint(data.head(10))","d9dc033a":"## References\n\nThis notebook has been created based on great work done solving the Titanic competition and other sources.\n\n- [A journey through Titanic](https:\/\/www.kaggle.com\/omarelgabry\/titanic\/a-journey-through-titanic)\n- [Getting Started with Pandas: Kaggle's Titanic Competition](https:\/\/www.kaggle.com\/c\/titanic\/details\/getting-started-with-random-forests)\n- [Titanic Best Working Classifier](https:\/\/www.kaggle.com\/sinakhorami\/titanic\/titanic-best-working-classifier)","12496b61":"# Code"}}