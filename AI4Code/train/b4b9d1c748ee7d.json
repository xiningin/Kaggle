{"cell_type":{"7d2e7db0":"code","0d12f60f":"code","e994352c":"code","b1c08944":"code","26553649":"code","ebd11854":"code","9d5de90e":"code","f4b72ef8":"code","d6ae97be":"code","74787f64":"code","c6f541cb":"code","dbd4113d":"code","06b8f875":"code","19275030":"code","2092d2ea":"code","d5241cc8":"code","55a7a95b":"code","52bb02fc":"code","9244a0ba":"code","6e0e7ca7":"code","c10ee469":"code","ba22402c":"code","0c55a2f3":"code","187ff7a4":"code","c37e9a12":"code","1113458c":"code","dbf6107e":"code","559f80d5":"code","e8583e3f":"code","f09f7e31":"code","3dfe272d":"code","30c408e2":"code","9f312471":"code","9fd2a2ff":"code","9029283d":"code","64169e72":"code","632873ba":"code","68e50cd6":"code","0399d899":"code","3bd44c99":"code","8bb1999a":"code","8776d8cc":"code","d3797c20":"code","aab5cb23":"code","42fa45e5":"markdown","3fea913a":"markdown"},"source":{"7d2e7db0":"pip install yfinance","0d12f60f":"import yfinance as yf","e994352c":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline","b1c08944":"data = yf.download('ESCORTS.NS',period='5y',interval='1d')","26553649":"data.head(3)","ebd11854":"data_target = data.iloc[:1182,4]\ndata_test = data.iloc[1132:,4]\ndata = data.loc[:,[\"Adj Close\"]].values","9d5de90e":"plot = data_target.plot()","f4b72ef8":"#Check Length \nprint(\"Length of Data:{}\".format(len(data)))\nprint(\"Length of Data_Target:{}\".format(len(data_target)))","d6ae97be":"#Scaling Dataset\ndef scaledata(data_target):\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0,1))\n    data_target_scaled = scaler.fit_transform(np.array(data_target).reshape(-1,1))\n    #plot_scaled = pd.DataFrame(data_target_scaled).plot()\n    print(data_target.shape)\n    return data_target_scaled, scaler","74787f64":"data_target_scaled = scaledata(data_target)[0]\nscaler = scaledata(data_target)[1]\ndata_target_scaled","c6f541cb":"data_test_scaled = scaledata(data_test)[0]","dbd4113d":"#Create pattern and end price set\ndef createPatternSet(data_target_scaled,steps=7):   \n    x_patern = []\n    y_price = []\n\n    for day in range(steps,data_target_scaled.shape[0]):\n        row = data_target_scaled[day-steps:day,0]\n        #print(len(row))\n        x_patern.append(row)\n        y = data_target_scaled[day,0]\n        #print(y)\n        y_price.append(y)\n    \n    x_patern,y_price = np.array(x_patern),np.array(y_price)\n    x_patern = x_patern.reshape(x_patern.shape[0],x_patern.shape[1],1)\n    \n    return x_patern,y_price","06b8f875":"train_pattern = createPatternSet(data_target_scaled,steps=50)","19275030":"x_train = train_pattern[0]\ny_train = train_pattern[1]","2092d2ea":"x_train.shape","d5241cc8":"y_train.shape","55a7a95b":"x_train","52bb02fc":"class StocksPriceRNN():\n\n    loss='mean_squared_error'\n    batch_size=32\n    neurons = 50\n    model = tf.keras.Sequential()\n    def __init__(self,x_train,y_train,epoch):\n        self.x_train = x_train\n        self.y_train = y_train\n        self.epoch = epoch\n    \n    def buildArchitecture(self,rnn=2,dense=1):\n        StocksPriceRNN.model = tf.keras.Sequential()\n        StocksPriceRNN.model.add(tf.keras.layers.SimpleRNN(StocksPriceRNN.neurons,\n                                            activation='tanh',\n                                            return_sequences = True,\n                                            input_shape = (self.x_train.shape[1],1)))\n        StocksPriceRNN.model.add(tf.keras.layers.Dropout(0.2))\n        for i in range(rnn):\n            StocksPriceRNN.model.add(tf.keras.layers.SimpleRNN(StocksPriceRNN.neurons,\n                                                activation='tanh',\n                                                return_sequences = True))\n            StocksPriceRNN.model.add(tf.keras.layers.Dropout(0.2))\n        \n        #return sequense changed to false\n        StocksPriceRNN.model.add(tf.keras.layers.SimpleRNN(StocksPriceRNN.neurons,\n                                                activation='tanh',\n                                                return_sequences = False))\n        StocksPriceRNN.model.add(tf.keras.layers.Dropout(0.2))\n        \n        for i in range(dense):\n            StocksPriceRNN.model.add(tf.keras.layers.Dense(units=StocksPriceRNN.neurons,\n                                            activation='tanh'))\n        \n        #Output\n        StocksPriceRNN.model.add(tf.keras.layers.Dense(units=1))\n        return StocksPriceRNN.model.summary()\n    \n    def compiler(self):\n        opt= tf.keras.optimizers.Adam()\n        StocksPriceRNN.model.compile(optimizer = opt,\n                                    loss = StocksPriceRNN.loss)\n        return StocksPriceRNN.model.summary()\n        \n    def modelfit(self):\n        history = StocksPriceRNN.model.fit(self.x_train,self.y_train,\n                                        epochs=self.epoch,batch_size=StocksPriceRNN.batch_size,validation_split=0.2,\n                                       )\n        return history\n    \n    def changeBatchSize(self,size):\n        StocksPriceRNN.batch_size = size\n        print(\"Changed!\")\n    def changeNeurons(self,size):\n        StocksPriceRNN.neurons = size\n        print(\"Changed!\")\n    def changeEpoch(self,size):\n        self.epoch = size\n        print(\"Changed!\")","9244a0ba":"RNN1 = StocksPriceRNN(x_train,y_train,50)","6e0e7ca7":"RNN1.buildArchitecture(2,0)","c10ee469":"RNN1.compiler()","ba22402c":"history = RNN1.modelfit()","0c55a2f3":"#Prepare Test Data\ntest = data[len(data) - len(data_test) - 50:]\ntest = scaler.transform(test)","187ff7a4":"test_pattern = createPatternSet(test,steps=50)\nx_test = test_pattern[0]\ny_test = test_pattern[1]","c37e9a12":"#Predict the value for test set\ny_test","1113458c":"x_test","dbf6107e":"pred = RNN1.model.predict(x=x_test)\npred.shape","559f80d5":"#Transform back the inverse value\n\noutput = scaler.inverse_transform(pred)\norg_vals = scaler.inverse_transform(y_test.reshape(-1,1))","e8583e3f":"output","f09f7e31":"def plotting(org_vals,output):\n    plt.figure(figsize=(10,5), dpi=80, facecolor='w', edgecolor='k')\n    plt.plot(org_vals,color=\"Green\",label=\"Org value\")\n    plt.plot(output,color=\"Yellow\",label=\"Predicted\")\n    plt.legend()\n    plt.xlabel(\"Days\")\n    plt.ylabel(\"Price\")\n    plt.grid(True)\n    plt.show()","3dfe272d":"plotting(org_vals,output)","30c408e2":"#Build a for loop with some iterations\nfor steps in [7,30,90]:\n    for epoch in [20,30,50]:\n        #prepare train data\n        train_pattern = createPatternSet(data_target_scaled,steps=steps)\n        #prepare test data\n        test = data[len(data) - len(data_test) - steps:]\n        test = scaler.transform(test)\n\n        test_pattern = createPatternSet(test,steps=steps)\n        x_test = test_pattern[0]\n        y_test = test_pattern[1]\n        #Build Model\n        RNN1 = StocksPriceRNN(x_train,y_train,epoch)\n        RNN1.buildArchitecture(2,0)\n        RNN1.compiler()\n        #fit model\n        history = RNN1.modelfit()\n        #Predict Values\n        pred = RNN1.model.predict(x=x_test)\n        output = scaler.inverse_transform(pred)\n        \n        #visualise\n        print(\"Plotting for Steps {} and Epoch {}\".format(steps,epoch))\n        plotting(org_vals,output)","9f312471":"#Long Short Term Memory\nclass LstmModel(StocksPriceRNN):\n    StocksPriceRNN.model = tf.keras.Sequential()\n    def __init__(self,x_train,y_train,epoch):\n        super().__init__(x_train,y_train,epoch)\n    \n    def buildArchitecture(self,dense=1):\n        StocksPriceRNN.model = tf.keras.Sequential()\n        StocksPriceRNN.model.add(tf.keras.layers.LSTM(StocksPriceRNN.neurons,input_shape=(None,1)))\n        #Output\n        StocksPriceRNN.model.add(tf.keras.layers.Dense(units=1))\n        return StocksPriceRNN.model.summary()","9fd2a2ff":"LSTM = LstmModel(x_train,y_train,epoch=50)","9029283d":"LSTM.changeBatchSize(1)","64169e72":"LSTM.changeNeurons(10)","632873ba":"LSTM.buildArchitecture()","68e50cd6":"LSTM.compiler()","0399d899":"history = LSTM.modelfit()","3bd44c99":"pred = LSTM.model.predict(x_test)\noutput = scaler.inverse_transform(pred)\n\nplotting(org_vals,output)","8bb1999a":"#27 Iterations!!!!!!!!!!!!!!!!!!!\nfor epch in [60,100,200]:\n    for batch in [2,4,6]:\n        for neurons in [8,10,12]:\n            LSTM2 = LstmModel(x_train,y_train,epoch=epch)\n            LSTM2.changeBatchSize(batch)\n            LSTM2.changeNeurons(neurons)\n\n            LSTM2.buildArchitecture()\n            LSTM2.compiler()\n            history = LSTM2.modelfit()\n\n            pred = LSTM2.model.predict(x_test)\n            output = scaler.inverse_transform(pred)\n            \n\n            print(\"For epch {} and batch {}\".format(epch,batch))\n            plotting(org_vals,output)","8776d8cc":"import warnings\nwarnings.filterwarnings('ignore')\n\n#Final Model Output\n#prepare train data\ntrain_pattern = createPatternSet(data_target_scaled,steps=90)\ntest = data[len(data) - len(data_test) - 90:]\ntest = scaler.transform(test)\ntest_pattern = createPatternSet(test,steps=90)\nx_test = test_pattern[0]\ny_test = test_pattern[1]\nLSTM2 = LstmModel(x_train,y_train,epoch=200)\nLSTM2.changeBatchSize(2)\nLSTM2.changeNeurons(10)\n\nLSTM2.buildArchitecture()\nLSTM2.compiler()\nhistory = LSTM2.modelfit()\npred = LSTM2.model.predict(x_test)\npred = scaler.inverse_transform(pred)\norg_vals = scaler.inverse_transform(y_test.reshape(-1,1))\nprint(\"For epch {}, neurons {} and batch {}\".format(200,10,2))\nplotting(org_vals,pred)","d3797c20":"curr_data = yf.download('ESCORTS.NS',start=\"2021-02-1\",end=\"2021-06-22\",interval='1d')\nprint(\"Length of Data: \",len(curr_data))\ncurr_data = curr_data[\"Adj Close\"]\n\ndef futurePrediciton1D(curr_data,start=\"2021-02-1\",end=\"2021-06-19\"):\n    '''\n    '''\n    curr_scaled = scaledata(curr_data)[0]\n    scaler = scaledata(curr_data)[1]\n    \n    #flatten into list\n    x_data = list(curr_scaled.flatten())\n    #convert into 3D\n    x_data = np.array(x_data)\n    x_data = x_data.reshape(1,len(x_data),1)\n    \n    #Predict\n    nextDay = LSTM2.model.predict(x=x_data)\n    nextDay = scaler.inverse_transform(nextDay.reshape(-1,1))\n\n    nextDay = nextDay[-1][0]\n    print(\"Prediction: {}\".format(nextDay))\n    \n    #convert into dataframe again\n    curr_data = pd.DataFrame(curr_data)\n    curr_data.reset_index(inplace=True)\n    adj_cl = curr_data[['Adj Close']]\n    \n    #concatenate new value\n    adj_cl.loc[len(adj_cl.index)] = [nextDay]\n    \n    return adj_cl","aab5cb23":"data = futurePrediciton1D(curr_data)\nplot = data.plot()","42fa45e5":"### Conclusion:\n- Lstm with batch 2 and units 10 works best with epoch 200. Model was able to capture the actual path with minimum deviations in it.","3fea913a":"# Future Predictions"}}