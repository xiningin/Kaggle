{"cell_type":{"4ef1bf5e":"code","7ac9897f":"code","0f89b26e":"code","1e0c5798":"code","62ea4892":"code","6bfd933c":"code","0ee546ec":"code","b5caf9b6":"code","6761eb3f":"code","ed4bcbab":"code","e53f3955":"code","870d8510":"code","f8c279b2":"code","be89be80":"code","ff67c56f":"code","5b6996eb":"markdown","5570c669":"markdown","eb0af599":"markdown"},"source":{"4ef1bf5e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","7ac9897f":"path = '\/kaggle\/input\/deepfake-detection-challenge'\n# reading file names\ntrain_files = os.listdir(os.path.join(path, 'train_sample_videos'))\ntrain_files.remove('metadata.json')\ntest_files = os.listdir(os.path.join(path, 'test_videos'))\n\nprint(f'Number of Train files: {len(train_files)}\\nNumber of Test files: {len(test_files)}')","0f89b26e":"# reading the labels json file\nlabels_df = pd.read_json(os.path.join(path, 'train_sample_videos\/metadata.json'))\nlabels_df = labels_df.T\nprint(labels_df.shape)\nlabels_df.head()","1e0c5798":"# number of real and fake samples\nlabels_df['label'].value_counts(normalize=True)*100","62ea4892":"# gets the frame size for a video\ndef get_frame_size(file):\n    cap = cv2.VideoCapture(file)\n    ret, frame = cap.read()\n    #plt.imshow(frame)\n    shape = frame.shape\n    cap.release()\n    return shape\n\n# gets the fps and duration of video\ndef get_video_length(file):\n    cap = cv2.VideoCapture(file)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    duration = frame_count\/fps\n    cap.release()\n    return round(fps), round(duration)\n\n# extract metadata of all files and return in a dataframe\ndef extract_metadata(files, path):\n    frame_size_list = []\n    fps_list = []\n    duration_list = []\n    for i in tqdm(files):\n        shape = get_frame_size(os.path.join(path,f'{i}'))\n        fps, duration = get_video_length(os.path.join(path,f'{i}'))\n        frame_size_list.append(shape)\n        fps_list.append(fps)\n        duration_list.append(duration)\n\n    meta_df = pd.DataFrame(data={'frame_shape':frame_size_list, 'fps':fps_list, 'duration':duration_list}, index=files)\n    return meta_df\n\nprint(get_frame_size(os.path.join(path, 'train_sample_videos\/aagfhgtpmv.mp4')))\nprint(get_video_length(os.path.join(path, 'train_sample_videos\/aagfhgtpmv.mp4')))","6bfd933c":"# getting metadata for train files\ntrain_meta = extract_metadata(train_files, os.path.join(path, 'train_sample_videos'))\ntrain_meta.head()","0ee546ec":"train_meta.frame_shape.value_counts()","b5caf9b6":"train_meta.fps.value_counts()","6761eb3f":"print('Duration in seconds')\nprint(train_meta.duration.value_counts())","ed4bcbab":"# getting metadata for test files\ntest_meta = extract_metadata(test_files, os.path.join(path, 'test_videos'))\ntest_meta.head()","e53f3955":"test_meta.frame_shape.value_counts()","870d8510":"test_meta.fps.value_counts()","f8c279b2":"test_meta.duration.value_counts()","be89be80":"submission = pd.read_csv(f\"{path}\/sample_submission.csv\")\nsubmission.head()","ff67c56f":"submission['label'] = 0.7\nsubmission.to_csv('submission.csv', index=False)","5b6996eb":"## The training data is skewed","5570c669":"## Equal number of train and test samples","eb0af599":"* All videos are of 10 seconds and in 30 fps\n* Videos are in 2 frame sizes:\n  * 1080 X 1920\n  * 1920 X 1080"}}