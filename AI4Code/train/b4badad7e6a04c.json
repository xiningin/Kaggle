{"cell_type":{"7266ca51":"code","d5356f13":"code","af62c652":"code","66a0d6ef":"code","c6c9c565":"code","1fac480a":"code","172d4c98":"code","7c9d0733":"code","1f069668":"code","74fe64a9":"code","94f189df":"markdown","3fe71ed7":"markdown","2a1cfed2":"markdown"},"source":{"7266ca51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\"))\n\n# Any results you write to the current directory are saved as output.","d5356f13":"from __future__ import print_function, division\nfrom builtins import range, input\n\n\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob","af62c652":"# Explore Data\ntrain_path = '..\/input\/fruits-360_dataset\/fruits-360\/Training'\nvalid_path = '..\/input\/fruits-360_dataset\/fruits-360\/Test'\n\n# useful for getting number of files\nimage_files = glob(train_path + '\/*\/*.jp*g')\nvalid_image_files = glob(valid_path + '\/*\/*.jp*g')\nprint(\"Number of Images for Training: \",len(image_files))\nprint(\"Number of Images for validating: \",len(glob(valid_path + '\/*\/*.jp*g')))\n# useful for getting number of classes\nfolders = glob(train_path + '\/*')\nprint(\"Number of classes: \",len(folders))\n\n\n# look at an image for fun\nplt.imshow(image.load_img(np.random.choice(image_files)))\n\nplt.show()","66a0d6ef":"# re-size all the images to 100x100\nIMAGE_SIZE = [100, 100] \n\n# add preprocessing layer to the front of VGG\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False\n\n# our layers\nx = Flatten()(vgg.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(len(folders), activation='softmax')(x)\n\n\n# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()","c6c9c565":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='rmsprop',\n  metrics=['accuracy']\n)\n\n# create an instance of ImageDataGenerator\ngen = ImageDataGenerator(\n  rotation_range=20,\n  width_shift_range=0.1,\n  height_shift_range=0.1,\n  shear_range=0.1,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  vertical_flip=True,\n  preprocessing_function=preprocess_input\n)","1fac480a":"# test generator to see how it works and some other useful things\n\n# get label mapping for confusion matrix plot later\ntest_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\nprint(test_gen.class_indices)\nlabels = [None] * len(test_gen.class_indices)\nfor k, v in test_gen.class_indices.items():\n    labels[v] = k\n\n# should be a strangely colored image (due to VGG weights being BGR)\nfor x, y in test_gen:\n    print(\"min:\", x[0].min(), \"max:\", x[0].max())\n    plt.title(labels[np.argmax(y[0])])\n    plt.imshow(x[0])\n    plt.show()\n    break","172d4c98":"# training config:\nepochs = 5\nbatch_size = 32\n\n# create generators\ntrain_generator = gen.flow_from_directory(\n  train_path,\n  target_size=IMAGE_SIZE,\n  shuffle=True,\n  batch_size=batch_size,\n)\nvalid_generator = gen.flow_from_directory(\n  valid_path,\n  target_size=IMAGE_SIZE,\n  shuffle=True,\n  batch_size=batch_size,\n)\n\n# fit the model\nr = model.fit_generator(\n  train_generator,\n  validation_data=valid_generator,\n  epochs=epochs,\n  steps_per_epoch=len(image_files) \/\/ batch_size,\n  validation_steps=len(valid_image_files) \/\/ batch_size,\n)","7c9d0733":"def get_confusion_matrix(data_path, N):\n  # we need to see the data in the same order\n  # for both predictions and targets\n    print(\"Generating confusion matrix\", N)\n    predictions = []\n    targets = []\n    i = 0\n    for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n        i += 1\n        if i % 50 == 0:\n            print(i)\n        p = model.predict(x)\n        p = np.argmax(p, axis=1)\n        y = np.argmax(y, axis=1)\n        predictions = np.concatenate((predictions, p))\n        targets = np.concatenate((targets, y))\n        if len(targets) >= N:\n            break\n    cm = confusion_matrix(targets, predictions)\n    return cm\n\n\ncm = get_confusion_matrix(train_path, len(image_files))\nprint(cm)\nvalid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\nprint(valid_cm)\n\n\n","1f069668":"# plot Loss and Accuracies\n\n# loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(r.history['acc'], label='train acc')\nplt.plot(r.history['val_acc'], label='val acc')\nplt.legend()\nplt.show()\n","74fe64a9":"# Plot Confusion Matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\nplot_confusion_matrix(cm, labels, title='Train confusion matrix')\nplot_confusion_matrix(valid_cm, labels, title='Validation confusion matrix')","94f189df":"### Explore Data","3fe71ed7":"### Import Libraries","2a1cfed2":"### Loss and Optimization functions"}}