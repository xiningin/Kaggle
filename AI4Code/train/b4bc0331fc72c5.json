{"cell_type":{"df1bf699":"code","fb439d97":"code","1a47856b":"code","a6a079b8":"code","0533a2eb":"code","a6375abf":"code","260a48f9":"code","50b2c819":"code","5d7472e1":"code","81ed1af7":"code","d9e11088":"code","3f4a3903":"code","cb3a8563":"code","4968751d":"code","29fdb61c":"code","4eef0768":"code","db07354b":"code","679115b1":"code","ed52f04c":"code","c2da0960":"code","a6e795ea":"code","64ca0c57":"code","8d18bf29":"code","e28bd3ae":"code","1b1e1fd1":"code","39eeb89f":"code","02c7c082":"code","746f093a":"code","62e154b5":"code","59f7624f":"code","ea94c85f":"code","57c27d60":"code","b4887cd5":"code","765a1d27":"code","87540b03":"code","d5d45595":"code","a7fc4fcc":"code","bee659b9":"code","ed89eff1":"code","d3e4bd21":"code","744d18d3":"code","0b3ecdfe":"code","e6ce76f0":"code","3f5f985e":"code","235c826c":"markdown","7bcbb93b":"markdown","e1957be3":"markdown","86f09f26":"markdown","6b4a1d58":"markdown","fcf771e1":"markdown","d2113ec5":"markdown","1781b557":"markdown","544033b4":"markdown","7e85b0f5":"markdown","af969536":"markdown","fb5da6ed":"markdown","499db3f0":"markdown","c50aef14":"markdown","2b45d154":"markdown","bcb2bdd0":"markdown","27792e55":"markdown","5ce789db":"markdown","3cfd7f0e":"markdown","d90051f4":"markdown","b0665c16":"markdown","42aff6fd":"markdown","67496ec3":"markdown","758a201c":"markdown","05769dde":"markdown","68846e2e":"markdown","862fa622":"markdown","39f803ec":"markdown","cc6b1e10":"markdown","0e4f8e2a":"markdown","fb582c32":"markdown","3efa6f00":"markdown","b551e018":"markdown","a4811b84":"markdown","fe13d6a2":"markdown","30b99d2c":"markdown","496a0966":"markdown","08810621":"markdown"},"source":{"df1bf699":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb439d97":"!pip install --upgrade kneed","1a47856b":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom kneed import KneeLocator, DataGenerator\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import DBSCAN","a6a079b8":"path=\"\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\"\ndata = pd.read_csv(path)\ndata.head()","0533a2eb":"# Check columns and its data types\ndata.info()","a6375abf":"# Describe the columns\ndata.describe()","260a48f9":"data.isna().sum()","50b2c819":"sns.countplot(x='Gender', data=data)\nplt.title(\"Gender distribution\")","5d7472e1":"data['Age'].describe()","81ed1af7":"sns.distplot(data['Age'])\nplt.title(\"Age distribution\")","d9e11088":"sns.boxplot('Age', data=data)\nplt.title(\"Customer Age distribution\")","3f4a3903":"data['Annual Income (k$)'].describe()","cb3a8563":"sns.distplot(data['Annual Income (k$)'])\nplt.title(\"Income distribution\")","4968751d":"sns.boxplot(x='Annual Income (k$)', data=data)\nplt.title(\"Annual income distribution\")","29fdb61c":"data['Spending Score (1-100)'].describe()","4eef0768":"sns.distplot(data['Spending Score (1-100)'])\nplt.title(\"Spending Score distribution\")","db07354b":"sns.boxplot('Spending Score (1-100)', data=data)\nplt.title('Spending Dist')","679115b1":"data.drop('CustomerID', axis=1, inplace=True)","ed52f04c":"#Encode Gender\ndata['isMale'] = pd.get_dummies(data['Gender'], drop_first=True)","c2da0960":"sns.heatmap(data.corr())","a6e795ea":"sns.pairplot(data)","64ca0c57":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Spending Score (1-100)', y='Annual Income (k$)', hue='Gender', data=data)\nplt.title(\"Income vs Spending\")","8d18bf29":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Spending Score (1-100)', y='Gender', data=data)\nplt.title(\"Gender wise spending score\")","e28bd3ae":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Spending Score (1-100)', y='Age', hue=\"Gender\", data=data)\nplt.title(\"Age vs Spending score\")","1b1e1fd1":"# Transform the data to get the better result, as we are using the distance based calculations\ncolumns_to_transform = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\ndata_to_transform = data[columns_to_transform]\nfor i in columns_to_transform:\n    # fit on training data column\n    scale = StandardScaler().fit(data_to_transform[[i]])\n    \n    # transform the training data column\n    data_to_transform[i] = scale.transform(data_to_transform[[i]])\n    \ndata_to_transform.head()","39eeb89f":"income_spending_data = data_to_transform[['Annual Income (k$)', 'Spending Score (1-100)']]\nincome_spending_data","02c7c082":"# Elbow method\nsse = []\nfor n in range(1,10):\n    kmean = KMeans(n_clusters=n)\n    kmean.fit(income_spending_data)\n    sse.append(kmean.inertia_)","746f093a":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, 10), sse)\nplt.xticks(range(1, 10))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()","62e154b5":"# Get elbow parameter with KneeLocator\nkl = KneeLocator(range(1, 10), sse, curve=\"convex\", direction='decreasing')\nkl.elbow","59f7624f":"income_spending_data","ea94c85f":"silhouette_coefficients = []\n\n# Notice you start at 2 clusters for silhouette coefficient\nfor k in range(2, 11):\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(income_spending_data)\n    score = silhouette_score(income_spending_data, kmeans.labels_)\n    silhouette_coefficients.append(score)","57c27d60":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(2, 11), silhouette_coefficients)\nplt.xticks(range(2, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()","b4887cd5":"# Lets do clustering with KMean having 5 clusters\nkmeans = KMeans(n_clusters=5)\nidentified_clusters = kmeans.fit_predict(income_spending_data)\ndata_with_clusters = income_spending_data.copy()\ndata_with_clusters['Clusters'] = identified_clusters \nplt.scatter(data['Spending Score (1-100)'], data['Annual Income (k$)'],c=data_with_clusters['Clusters'],cmap='rainbow')\nplt.xlabel(\"Spending Score\")\nplt.ylabel(\"Annual Income\")\nplt.title(\"Spending Score vs Annual Income\")","765a1d27":"# Epsilon distance best paramaters\ndbscan_silhouette = []\ndistances=[0.1,0.2,0.3,0.4,0.5,0.6]\nfor index in range(len(distances)):\n    dbscan = DBSCAN(eps=distances[index])\n    dbscan.fit(income_spending_data)\n    score = silhouette_score(income_spending_data, dbscan.labels_).round(2)\n    dbscan_silhouette.append(score)\ndbscan_silhouette","87540b03":"plt.style.use(\"fivethirtyeight\")\nplt.plot([0.1,0.2,0.3,0.4,0.5,0.6], dbscan_silhouette)\nplt.xticks([0.1,0.2,0.3,0.4,0.5,0.6])\nplt.xlabel(\"Epsilon\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()","d5d45595":"# Lets do clustering with DBScan having epsilon as 0.4\ndbscan = DBSCAN(eps=0.4)\nidentified_clusters = dbscan.fit_predict(income_spending_data)\n\ndata_with_clusters = income_spending_data.copy()\ndata_with_clusters['Clusters'] = identified_clusters \nplt.scatter(data['Spending Score (1-100)'], data['Annual Income (k$)'],c=data_with_clusters['Clusters'],cmap='rainbow')\nplt.xlabel(\"Spending Score\")\nplt.ylabel(\"Annual Income\")\nplt.title(\"Spending Score vs Annual Income\")","a7fc4fcc":"# Transform the data to get the better result, as we are using the distance based calculations\ncolumns_to_transform = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\ndata_to_transform = data[columns_to_transform]\nfor i in columns_to_transform:\n    # fit on training data column\n    scale = StandardScaler().fit(data_to_transform[[i]])\n    \n    # transform the training data column\n    data_to_transform[i] = scale.transform(data_to_transform[[i]])\n    \ndata_to_transform.head()","bee659b9":"age_spending_data = data_to_transform[['Age', 'Spending Score (1-100)']]\nage_spending_data","ed89eff1":"# Elbow method\nsse = []\nfor n in range(1,10):\n    kmean = KMeans(n_clusters=n)\n    kmean.fit(age_spending_data)\n    sse.append(kmean.inertia_)","d3e4bd21":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, 10), sse)\nplt.xticks(range(1, 10))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()","744d18d3":"# Get elbow parameter with KneeLocator\nkl = KneeLocator(range(1, 10), sse, curve=\"convex\", direction='decreasing')\nkl.elbow","0b3ecdfe":"# Lets do clustering with KMean having 3 clusters\nkmeans = KMeans(n_clusters=3)\nidentified_clusters = kmeans.fit_predict(age_spending_data)\ndata_with_clusters = age_spending_data.copy()\ndata_with_clusters['Clusters'] = identified_clusters \nplt.scatter(data['Age'], data['Spending Score (1-100)'],c=data_with_clusters['Clusters'],cmap='rainbow')\nplt.ylabel(\"Spending Score\")\nplt.xlabel(\"Age\")\nplt.title(\"Spending Score vs Age\")","e6ce76f0":"# Epsilon distance best paramaters\ndbscan_silhouette = []\ndistances=[0.1,0.2,0.3,0.4,0.5]\nfor index in range(len(distances)):\n    dbscan = DBSCAN(eps=distances[index])\n    dbscan.fit(age_spending_data)\n    score = silhouette_score(age_spending_data, dbscan.labels_).round(2)\n    dbscan_silhouette.append(score)\n\nplt.style.use(\"fivethirtyeight\")\nplt.plot([0.1,0.2,0.3,0.4,0.5], dbscan_silhouette)\nplt.xticks([0.1,0.2,0.3,0.4,0.5])\nplt.xlabel(\"Epsilon\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()\n","3f5f985e":"# Lets do clustering with DBScan having epsilon as 0.3\ndbscan = DBSCAN(eps=0.3)\nidentified_clusters = dbscan.fit_predict(age_spending_data)\n\ndata_with_clusters = age_spending_data.copy()\ndata_with_clusters['Clusters'] = identified_clusters \nplt.scatter(data['Age'], data['Spending Score (1-100)'],c=data_with_clusters['Clusters'],cmap='rainbow')\nplt.ylabel(\"Spending Score\")\nplt.xlabel(\"Age\")\nplt.title(\"Spending Score vs Age\")","235c826c":"**Observation:** The data is right skewed in which we can see that 75% of our customer lies in the range of 18-50 years. The youngest customer is of 18 year and oldest is having 70 year of age.","7bcbb93b":"**Observation:** There are no null values","e1957be3":"## Choose appropriate number of clusters","86f09f26":"**Tasks:**\n1. Check missing values, if there then fix that\n2. Gender distribution\n3. Age distribution\n4. Annual income distribution\n5. Spending score distributions\n6. Check the correlation with spending score\n7. Annual income vs spending score, also consideration with Gender\n8. Gender vs spending score\n9. Age vs spending score considering gender\n10. Segmentation of Annual income vs spending score K-Means - Also Include Clusters choosing using Elbow method(Manual and KneeLocator) and Silhoutee Score \n11. Segmentation of Annual income vs spending score DBScan - silhouette_score\n12. Segmentation of Age vs spending score K-Means - Also Include Clusters choosing using Elbow method(Manual and KneeLocator) and Silhoutee Score \n13. Segmentation of Age vs spending score DBScan - silhouette_score","6b4a1d58":"**Observation:** The score seems to be right skewed","fcf771e1":"**Observation:** By looking here we cannot say Spending score is linked to Age, income or gender","d2113ec5":"**Observation** We can see the eps=0.4 gives a good result","1781b557":"**Observation:** The data seems to be a bit left skewed where minimum salary earned by the person is 15000 dollars, and the maximum income is of 137000 dollars. Here approximately 75% of the customer are having annual income less than 78000 dollars","544033b4":"**1. Check missing values**","7e85b0f5":"**11. Age vs Spending Score K-means clustering**","af969536":"**Knee Locator** It is showing the perfect number of cluster is 4.\\\n\nAs our analysis and Knew locator, is different by 1 cluster so lets go by 5 then","fb5da6ed":"**Observation:** DBScan doesnot seperate the clusters well, as density is less","499db3f0":"## Choose appropriate number of clusters","c50aef14":"**Observation:** There is clear indication that there are only customers in age group 18-40 independent of Gender having spending score above 60. So We should target on the customers in age group 18- 40","2b45d154":"**7. Annual Income vs Spending Score with Gender**","bcb2bdd0":"**Observation:** There are more female customers as comparison to male. So seems female used to do more shopping but can't conclude from this whether they spend more or not","27792e55":"**5. Spending score distributions**","5ce789db":"**9. Income vs Spending Score K-means clustering**","3cfd7f0e":"**2. Gender distribution**","d90051f4":"**Import necessary libraries**","b0665c16":"**8. Gender vs Spending score**","42aff6fd":"**9. Age vs spending score considering Gender**","67496ec3":"**Observtion:** We can see when the number of cluster is 3, then the Sum of squared error almost converges. So we can take number of cluster as 3. In order to cross validate lets use knee locator ","758a201c":"1. Elbow method - Simple observation, or with Kneelocater\n2. Silhoutte coefficient","05769dde":"**Onservation:** As we know that when the Silhoutte coefficient is near to 1 then its best, so here the coefficient value is max at cluster 5, so we will take the number of clusters as 5.","68846e2e":"**Observation:** Only for Spending score range from 1-20, there are more Male customer, above 20 score Female customers are in majority.","862fa622":"**3. Age distribution**","39f803ec":"**4. Annual income distribution**","cc6b1e10":"**Final Conclusion:**\\\nWe should focus on the customers having Age from 20-40, as they used to spend more, if want be more specific then the Age should having annual income in between 40-65k","0e4f8e2a":"**10. Age vs Spending Score using DBScan**","fb582c32":"**Observation:** Here we can see epsilon value = 0.3, then it needs to be perfect.","3efa6f00":"2. Silhoutte Coefficient","b551e018":"**Observation:** There seems to be 5 differnt categories of the customers.\\\nSpending score           |        Income(k in dollars)      |  Majority of Genders\\\n1-40                     |     15-40                        |   Female\\\n1-40                     |     70-138                       |   Male\\\n40-60                    |     40-65                        |   Female\\\n60-100                   |     10-40                        |   Female\\\n60-100                   |     70-138                       |   Female\n              \nMost of the spending score is between 40-60 with the customers who is having annual income between 40-65k dollars. This range is having more female customers as compared to male. We can target the female customers having income in the range of 40-65k dollars. or if in generic way all genders in the range of 40-65k income","a4811b84":"**6. Check the correlation with spending score**","fe13d6a2":"**10. Income vs Spending Score using DBScan**","30b99d2c":"**Observation:** From elbow method we can choose cluster as 5, as after that error is almost constant. But in order to choose the best from elbow method, we can use kneelocator","496a0966":"**Observation:** We can see that the cluster distribution is not good for DBScan over here, the reason is because the dataset is not very densely seperated.","08810621":"1. Elbow method - Simple observation, or with Kneelocater\n2. Silhoutte coefficient"}}