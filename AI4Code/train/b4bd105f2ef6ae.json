{"cell_type":{"58aa7f10":"code","095a49d1":"code","9dfb0e50":"code","43a36161":"code","b77abdc4":"code","3b243676":"code","763d1b98":"code","9d0b0780":"code","6490bd62":"code","f0edeb4c":"code","349a3fb8":"code","ba3d8d75":"code","295345a5":"code","cda8b7a1":"code","8f311761":"code","a1ba0d11":"code","ddaa4e76":"code","794f0d60":"code","008eed06":"code","23a70f57":"code","407d925f":"code","63ee584f":"code","bdeffeb5":"code","eaf99a74":"code","359281d1":"code","ea6133cb":"code","b7ebdf5f":"code","5ac7df60":"code","68ab535f":"code","0fb122b2":"code","10b52d1c":"code","9d77b959":"code","e5d4d78a":"code","8d908929":"code","fe6fa886":"code","c8de54f0":"code","105c4b71":"code","22d3c65d":"code","7ac8c7d9":"code","e3c7a188":"code","56f9b73c":"code","d5408e35":"code","1c080fc1":"code","1dbebc90":"code","92a149f3":"code","9bae02d7":"code","d5eca464":"code","772b7e3f":"code","753ea5fb":"code","2e3c73a2":"markdown","7edfdfc4":"markdown","b15d3b8f":"markdown","fe429f6f":"markdown","7b457dad":"markdown","a11ab153":"markdown","d7deb4a7":"markdown","8ec86915":"markdown","433ba1a2":"markdown"},"source":{"58aa7f10":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error\n#XGBoost\nfrom xgboost import XGBRegressor\n#warnings\nimport warnings\nwarnings.filterwarnings('ignore')","095a49d1":"df=pd.read_csv('\/kaggle\/input\/autompg-dataset\/auto-mpg.csv', na_values=['?'])","9dfb0e50":"data=df.copy()","43a36161":"df.head()","b77abdc4":"df.drop('car name', axis=1, inplace=True)","3b243676":"df.shape","763d1b98":"df.info()","9d0b0780":"df['origin'] = df['origin'].replace([1, 2, 3], ['USA', 'Europe', 'Japan'])","6490bd62":"df.head()","f0edeb4c":"df['origin'].value_counts()","349a3fb8":"df['origin'].value_counts(normalize=True)","ba3d8d75":"df.nunique()","295345a5":"df.describe().T","cda8b7a1":"#The dataset contains a few unknown values.\ndf.isnull().sum()","8f311761":"df.isnull().sum().sum()\/df.shape[0]","a1ba0d11":"df.isnull().sum()\/df.shape[0]","ddaa4e76":"df.dropna(axis=0, inplace=True)","794f0d60":"df.isnull().sum()","008eed06":"#Correlation\nf, ax = plt.subplots(figsize= [14, 8])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()","23a70f57":"sns.pairplot(df, diag_kind='kde', markers='+')","407d925f":"df['origin'].value_counts().plot.bar()","63ee584f":"plt.figure(figsize=[14, 6])\nplt.pie(x=df['origin'].value_counts(), autopct=\"%.2f\", labels=['USA', 'Europe', 'Japan'])\nplt.title(\"Origin Distribution\", fontsize=14)","bdeffeb5":"sns.barplot(x='origin', y='mpg', data=df)","eaf99a74":"plt.figure(figsize=[14, 6])\nsns.barplot(x=df['model year']+1900, y=df['mpg'])\nplt.title('Consumption Gallon by Years')","359281d1":"#Boxplot\nfor col in df._get_numeric_data().columns:       \n    plt.figure()\n    sns.boxplot(df[col])","ea6133cb":"for i in df._get_numeric_data().columns:\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n    sns.histplot(df[i], bins=10, ax=axes[0])\n    axes[0].set_title(i)\n    \n    sns.boxplot(df[i], ax=axes[1])\n    axes[1].set_title(i)\n   \n    sns.kdeplot(df[i], ax=axes[2])\n    axes[2].set_title(i)\n    plt.show()","b7ebdf5f":"#Outliers\ndef outlier(df, column):\n    Q1=df[column].quantile(0.00)\n    Q3=df[column].quantile(0.95)\n    IQR_hp=Q3-Q1\n    top_limit=Q3+ 1.5*IQR_hp\n    bottom_limit=Q1- 1.5*IQR_hp\n    return df[ (df[column]>=bottom_limit) & (df[column]<=top_limit) ]","5ac7df60":"df=outlier(df, 'horsepower')\ndf=outlier(df, 'acceleration')","68ab535f":"#Skewness\n#feature- dependent variable\nsns.distplot(df['mpg'])","0fb122b2":"sns.distplot(df['mpg'], fit=norm)","10b52d1c":"(mu, sigma)=norm.fit(df['mpg'])\nprint(mu, sigma)","9d77b959":"#qq plot\nfig=plt.figure()\nstats.probplot(df['mpg'], plot=plt)\nplt.show()","e5d4d78a":"df['mpg']=np.log1p(df['mpg'])","8d908929":"sns.distplot(df['mpg'], fit=norm)","fe6fa886":"(mu, sigma)=norm.fit(df['mpg'])\nprint(mu, sigma)","c8de54f0":"fig=plt.figure()\nstats.probplot(df['mpg'], plot=plt)\nplt.show()","105c4b71":"#feature- independent variable\nskewed_feats=df.drop('origin', axis=1).apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness=pd.DataFrame(skewed_feats, columns=['skewned'])\n#Box Cox Transformation lazim olsa skew ucun","22d3c65d":"skewness","7ac8c7d9":"df['cylinders']=df['cylinders'].astype(str)","e3c7a188":"df=pd.get_dummies(df)","56f9b73c":"df.head()","d5408e35":"#Split and stand\nX=df.drop(['mpg'], axis=1)\nY=df['mpg']\nscaler=StandardScaler() #RobustScaler\n#RobustScaler()-outlier-lari veriden uzaklasdirir\n#mean=0, std=1\nX=scaler.fit_transform(X)","1c080fc1":"def train_show_results(X, Y, model, split_share=0.3):\n    print(f\"Training using {model}\")\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=split_share)\n    m=model.fit(X_train, Y_train)\n    preds=m.predict(X_test)\n    mse=mean_squared_error(Y_test, preds)\n    print(f\"MSE: {mse}\")\n    print(\"###########################\")","1dbebc90":"models=[LinearRegression(), Ridge(), Lasso(), ElasticNet(), XGBRegressor(), \n        XGBRegressor(objective='reg:linear', max_depth=5, min_child_weight=4, subsample=0.7, n_estimators=100, learning_rate=0.7)]\nfor model in models:\n    train_show_results(X, Y, model)","92a149f3":"def model_tuning(X, Y, model, tuned_params, split_share=0.3, n_folds=5, slogx=True):\n    print(f\"Training using {model} with {tuned_params}\")\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=split_share)\n    clf=GridSearchCV(model, tuned_params, cv=n_folds,\n                 scoring='neg_mean_squared_error', n_jobs=5)\n    clf.fit(X_train, Y_train)\n    scores=clf.cv_results_['mean_test_score']\n    best_model=clf.best_estimator_\n    best_model.fit(X_train, Y_train)\n    Y_pred=best_model.predict(X_test)\n    mse=mean_squared_error(Y_test, Y_pred)\n    print(f\"MSE: {mse}\")\n    if slogx:  \n        plt.semilogx(tuned_params['alpha'], scores)","9bae02d7":"alphas=np.logspace(-4, -0.5, 30)\ntuned_params={'alpha':alphas}\nmodel_tuning(X, Y, Ridge(random_state=42, max_iter=10000), tuned_params)","d5eca464":"alphas=np.logspace(-4, -0.5, 30)\ntuned_params={'alpha':alphas}\nmodel_tuning(X, Y, Lasso(random_state=42, max_iter=10000), tuned_params)","772b7e3f":"alphas=np.logspace(-4, -0.5, 30)\neNet=ElasticNet(random_state=42, max_iter=10000)\ntuned_params={'alpha':alphas, 'l1_ratio':np.arange(0.0, 1.0, 0.05)}\nmodel_tuning(X, Y, ElasticNet(random_state=42, max_iter=10000), tuned_params, slogx=False)","753ea5fb":"parameters = {'nthread':[4],\n              'objective':['reg:linear'],\n              'learning_rate': [.03, 0.05, .07],\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [500]}\n\nmodel_xgb=XGBRegressor()\n\nmodel_tuning(X, Y, model_xgb, parameters, slogx=False)","2e3c73a2":"# Missing Values","7edfdfc4":"# Import libraries","b15d3b8f":"# Get the data","fe429f6f":"# Model","7b457dad":"# Exploratory Data Analysis","a11ab153":"# Model tuning","d7deb4a7":"# One Hot encoding","8ec86915":"**I could say our model did ok with the small data we have!\nThank you for checking out my work!**","433ba1a2":"# Feature Engineering"}}