{"cell_type":{"69020b76":"code","2870d7a0":"code","f46baa2c":"code","f0e08d60":"code","d6f3dac1":"code","e73b27f6":"code","d5c66bf2":"code","3fd86ff2":"code","8eaf222d":"code","a6761a5b":"code","1d82234a":"code","3229a2cc":"code","5538a926":"code","aa91595e":"markdown","9cbe71bf":"markdown","b1ed2648":"markdown","5ff976ec":"markdown","944a7bf1":"markdown","c5471de9":"markdown","f08d696f":"markdown","63d69238":"markdown","4b607f79":"markdown","b4cda358":"markdown","37767cfe":"markdown","105c5cb4":"markdown"},"source":{"69020b76":"!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null # no output\npackage_path = '..\/input\/unetmodelscript' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script","2870d7a0":"import os\nimport cv2\nimport pdb\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\nfrom albumentations import (HorizontalFlip, VerticalFlip, RandomBrightness,  ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise, ElasticTransform)\nfrom albumentations.imgaug.transforms import IAASharpen\nfrom albumentations.torch import ToTensor\nwarnings.filterwarnings(\"ignore\")\nseed = 69\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","f46baa2c":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_mask(row_id, df):\n    '''Given a row index, return image_id and mask (256, 1600, 4)'''\n    fname = df.iloc[row_id].name\n    labels = df.iloc[row_id][:4]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n    # 4:class 1\uff5e4 (ch:0\uff5e3)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            mask = np.zeros(256 * 1600, dtype=np.uint8)\n            for pos, le in zip(positions, length):\n                mask[pos:(pos + le)] = 1\n            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n    return fname, masks","f0e08d60":"class SteelDataset(Dataset):\n    def __init__(self, df, data_folder, mean, std, phase):\n        self.df = df\n        self.root = data_folder\n        self.mean = mean\n        self.std = std\n        self.phase = phase\n        self.transforms = get_transforms(phase, mean, std)\n        self.fnames = self.df.index.tolist()\n\n    def __getitem__(self, idx):\n        image_id, mask = make_mask(idx, self.df)\n        image_path = os.path.join(self.root, \"train_images\",  image_id)\n        img = cv2.imread(image_path)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask'] # 1x256x1600x4\n        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n        return img, mask\n\n    def __len__(self):\n        return len(self.fnames)\n\n\ndef get_transforms(phase, mean, std):\n    list_transforms = []\n    if phase == \"train\":\n        list_transforms.extend(\n            [\n                HorizontalFlip(), ElasticTransform(alpha=50, sigma=5), #IAASharpen(alpha=(0, 1), lightness = (0.5, 2))\n            ]\n        )\n    list_transforms.extend(\n        [\n            Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    )\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\ndef provider(\n    data_folder,\n    df_path,\n    phase,\n    mean=None,\n    std=None,\n    batch_size=16,\n    num_workers=16,\n):\n    '''Returns dataloader for the model training'''\n    df = pd.read_csv(df_path)\n    # some preprocessing\n    # https:\/\/www.kaggle.com\/amanooo\/defect-detection-starter-u-net\n    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n    df['ClassId'] = df['ClassId'].astype(int)\n    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    \n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"])\n    df = train_df if phase == \"train\" else val_df\n    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n    dataloader = DataLoader(\n        image_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=True,\n        shuffle=True,   \n    )\n\n    return dataloader\n","d6f3dac1":"def predict(X, threshold):\n    '''X is sigmoid output of the model'''\n    X_p = np.copy(X)\n    preds = (X_p > threshold).astype('uint8')\n    return preds\n\ndef metric(probability, truth, threshold=0.5, reduction='none'):\n    '''Calculates dice of positive and negative images seperately'''\n    '''probability and truth must be torch tensors'''\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert(probability.shape == truth.shape)\n\n        p = (probability > threshold).float()\n        t = (truth > 0.5).float()\n\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0)\n        pos_index = torch.nonzero(t_sum >= 1)\n\n        dice_neg = (p_sum == 0).float()\n        dice_pos = 2 * (p*t).sum(-1)\/((p+t).sum(-1))\n\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = torch.cat([dice_pos, dice_neg])\n\n        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n        dice = dice.mean().item()\n\n        num_neg = len(neg_index)\n        num_pos = len(pos_index)\n\n    return dice, dice_neg, dice_pos, num_neg, num_pos\n\nclass Meter:\n    '''A meter to keep track of iou and dice scores throughout an epoch'''\n    def __init__(self, phase, epoch):\n        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n        self.base_dice_scores = []\n        self.dice_neg_scores = []\n        self.dice_pos_scores = []\n        self.iou_scores = []\n\n    def update(self, targets, outputs):\n        probs = torch.sigmoid(outputs)\n        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n        self.base_dice_scores.append(dice)\n        self.dice_pos_scores.append(dice_pos)\n        self.dice_neg_scores.append(dice_neg)\n        preds = predict(probs, self.base_threshold)\n        iou = compute_iou_batch(preds, targets, classes=[1])\n        self.iou_scores.append(iou)\n\n    def get_metrics(self):\n        dice = np.mean(self.base_dice_scores)\n        dice_neg = np.mean(self.dice_neg_scores)\n        dice_pos = np.mean(self.dice_pos_scores)\n        dices = [dice, dice_neg, dice_pos]\n        iou = np.nanmean(self.iou_scores)\n        return dices, iou\n\ndef epoch_log(phase, epoch, epoch_loss, meter, start):\n    '''logging the metrics at the end of an epoch'''\n    dices, iou = meter.get_metrics()\n    dice, dice_neg, dice_pos = dices\n    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n    return dice, iou\n\ndef compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n    '''computes iou for one ground truth mask and predicted mask'''\n    pred[label == ignore_index] = 0\n    ious = []\n    for c in classes:\n        label_c = label == c\n        if only_present and np.sum(label_c) == 0:\n            ious.append(np.nan)\n            continue\n        pred_c = pred == c\n        intersection = np.logical_and(pred_c, label_c).sum()\n        union = np.logical_or(pred_c, label_c).sum()\n        if union != 0:\n            ious.append(intersection \/ union)\n    return ious if ious else [1]\n\ndef compute_iou_batch(outputs, labels, classes=None):\n    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n    ious = []\n    preds = np.copy(outputs) # copy is imp\n    labels = np.array(labels) # tensor to np\n    for pred, label in zip(preds, labels):\n        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n    iou = np.nanmean(ious)\n    return iou\n","e73b27f6":"!mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n!cp ..\/input\/resnet18\/resnet18.pth \/tmp\/.cache\/torch\/checkpoints\/resnet18-5c106cde.pth","d5c66bf2":"model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)","3fd86ff2":"model # a *deeper* look","8eaf222d":"import math\nimport torch\nfrom torch.optim.optimizer import Optimizer, required\n\nclass RAdam(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        self.buffer = [[None, None, None] for ind in range(10)]\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('RAdam does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state['step'] += 1\n                buffered = self.buffer[int(state['step'] % 10)]\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 \/ (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t \/ (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) \/ (N_sma_max - 4) * (N_sma - 2) \/ N_sma * N_sma_max \/ (N_sma_max - 2)) \/ (1 - beta1 ** state['step'])\n                    else:\n                        step_size = group['lr'] \/ (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                if group['weight_decay'] != 0:\n                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n                # more conservative since it's an approximated value\n                if N_sma >= 5:            \n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-step_size, exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss","a6761a5b":"class Trainer(object):\n    '''This class takes care of training and validation of our model'''\n    def __init__(self, model):\n        self.num_workers = 6\n        self.batch_size = {\"train\": 10, \"val\": 8}\n        self.accumulation_steps = 32 \/\/ self.batch_size['train']\n        self.lr = 5e-3\n        self.num_epochs = 20\n        self.best_loss = float(\"inf\")\n        self.phases = [\"train\", \"val\"]\n        self.device = torch.device(\"cuda:0\")\n        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n        self.net = model\n        self.criterion = torch.nn.BCEWithLogitsLoss()\n        self.optimizer = RAdam(self.net.parameters(), lr=self.lr)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n        self.net = self.net.to(self.device)\n        cudnn.benchmark = True\n        self.dataloaders = {\n            phase: provider(\n                data_folder=data_folder,\n                df_path=train_df_path,\n                phase=phase,\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size[phase],\n                num_workers=self.num_workers,\n            )\n            for phase in self.phases\n        }\n        self.losses = {phase: [] for phase in self.phases}\n        self.iou_scores = {phase: [] for phase in self.phases}\n        self.dice_scores = {phase: [] for phase in self.phases}\n        \n    def forward(self, images, targets):\n        images = images.to(self.device)\n        masks = targets.to(self.device)\n        outputs = self.net(images)\n        loss = self.criterion(outputs, masks)\n        return loss, outputs\n\n    def iterate(self, epoch, phase):\n        meter = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | \u23f0: {start}\")\n        batch_size = self.batch_size[phase]\n        self.net.train(phase == \"train\")\n        dataloader = self.dataloaders[phase]\n        running_loss = 0.0\n        total_batches = len(dataloader)\n#         tk0 = tqdm(dataloader, total=total_batches)\n        self.optimizer.zero_grad()\n        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n            images, targets = batch\n            loss, outputs = self.forward(images, targets)\n            loss = loss \/ self.accumulation_steps\n            if phase == \"train\":\n                loss.backward()\n                if (itr + 1 ) % self.accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            running_loss += loss.item()\n            outputs = outputs.detach().cpu()\n            meter.update(targets, outputs)\n#             tk0.set_postfix(loss=(running_loss \/ ((itr + 1))))\n        epoch_loss = (running_loss * self.accumulation_steps) \/ total_batches\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(dice)\n        self.iou_scores[phase].append(iou)\n        torch.cuda.empty_cache()\n        return epoch_loss\n\n    def start(self):\n        for epoch in range(self.num_epochs):\n            self.iterate(epoch, \"train\")\n            state = {\n                \"epoch\": epoch,\n                \"best_loss\": self.best_loss,\n                \"state_dict\": self.net.state_dict(),\n                \"optimizer\": self.optimizer.state_dict(),\n            }\n            val_loss = self.iterate(epoch, \"val\")\n            self.scheduler.step(val_loss)\n            if val_loss < self.best_loss:\n                print(\"******** New optimal found, saving state ********\")\n                state[\"best_loss\"] = self.best_loss = val_loss\n                torch.save(state, \".\/model.pth\")\n            print()\n","1d82234a":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntrain_df_path = '..\/input\/severstal-steel-defect-detection\/train.csv'\ndata_folder = \"..\/input\/severstal-steel-defect-detection\/\"\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","3229a2cc":"model_trainer = Trainer(model)\nmodel_trainer.start()","5538a926":"# PLOT TRAINING\nlosses = model_trainer.losses\ndice_scores = model_trainer.dice_scores # overall dice\niou_scores = model_trainer.iou_scores\n\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\nplot(losses, \"BCE loss\")\nplot(dice_scores, \"Dice score\")\nplot(iou_scores, \"IoU score\")","aa91595e":"## Imports","9cbe71bf":"This training and validation takes about ~400 minutes which exceeds Kaggle's GPU usage limit of 60 minutes, we won't be able to submit the `submission.csv` file generated from this kernel. So, for test prediction and submission I've written a separate [UNet inference kernel](https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-pytorch-inference-kernel), make sure you add the `model.pth` file generated from this kernel as dataset to test inference kernel.","b1ed2648":"## Dataloader","5ff976ec":"### Training and Validation","944a7bf1":"## UNet starter for Steel defect detection challenge\n\n> > This kernel is minimal improvement of @rishabhiitbhu kernel (https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-pytorch-inference-kernel).\n1. It presents new SOTA RAdam optimizer (https:\/\/arxiv.org\/pdf\/1908.03265.pdf) to Kaggle comunity. Thanks LiyuanLucasLiu (https:\/\/github.com\/LiyuanLucasLiu\/RAdam) for original RAam code.\n2. I added VerticalFlip for better perfomance. \n\nThis kernel uses a UNet model with pretrained resnet18 encoder for this challenge, with simple augmentations using albumentations library, uses BCE loss, metrics like Dice and IoU. I've used [segmentation_models.pytorch](https:\/\/github.com\/qubvel\/segmentation_models.pytorch) which comes with a lot pre-implemented segmentation architectures. This is a modified version of my previous [kernel](https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-with-resnet34-encoder-pytorch) for [siim-acr-pneumothorax-segmentation](https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/) competition.","c5471de9":"**As internet is not allowed for this competition, I tried installing `segmentation_models.pytorch` by source using pip but due to some reasons it didn't work. So, as a [Jugaad](https:\/\/en.wikipedia.org\/wiki\/Jugaad) I took all of `segmentation_models.pytorch`'s UNet code and wrote it in a single file and added it as a dataset so as to use it for this kernel, its dependency [pretrained-models.pytorch](https:\/\/github.com\/Cadene\/pretrained-models.pytorch) is also added as a dataset.","f08d696f":"## Refrences:\n\nFew kernels from which I've borrowed some cod[](http:\/\/)e:\n\n* https:\/\/www.kaggle.com\/amanooo\/defect-detection-starter-u-net\n* https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda\n\nA big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https:\/\/www.kaggle.com\/abhishek), [@Yury](https:\/\/www.kaggle.com\/deyury), [@Heng](https:\/\/www.kaggle.com\/hengck23), [@Ekhtiar](https:\/\/www.kaggle.com\/ekhtiar), [@lafoss](https:\/\/www.kaggle.com\/iafoss), [@Siddhartha](https:\/\/www.kaggle.com\/meaninglesslives), [@xhulu](https:\/\/www.kaggle.com\/xhlulu), and the list goes on..","63d69238":"I've used resnet-18 architecture in this kernel. It scores ~0.89 on LB. Try to play around with other architectures of `segmenation_models.pytorch` and see what works best for you, let me know in the comments :) and do upvote if you liked this kernel, I need some medals too. \ud83d\ude2c","4b607f79":"## Some more utility functions\n\nDice and IoU metric implementations, metric logger for training and validation.","b4cda358":"* ## RLE-Mask utility functions","37767cfe":"## Model Initialization","105c5cb4":"## Test prediction and submission"}}