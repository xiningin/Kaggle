{"cell_type":{"0af6934f":"code","cf0b825b":"code","3faca070":"code","e83344e2":"code","82222328":"code","a0f356e6":"code","b2d0a949":"code","0c69abd5":"code","3920ad01":"code","99981436":"code","803fec7e":"code","b4c75024":"code","a18b9a18":"code","8745c175":"code","ab257559":"code","29ac3310":"code","65e9e45d":"code","d127fa73":"code","71554c5d":"code","1397aee1":"code","58ff54d4":"code","de7832c4":"code","378e540e":"code","456de311":"code","3b99f24d":"markdown","9ad2762c":"markdown","f1192fb2":"markdown","028712ca":"markdown","2c843974":"markdown","b6000680":"markdown"},"source":{"0af6934f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf0b825b":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n# Plotting libraries\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline","3faca070":"true_df = pd.read_csv('\/kaggle\/input\/fake-and-real-news-dataset\/True.csv')\nfake_df = pd.read_csv('\/kaggle\/input\/fake-and-real-news-dataset\/Fake.csv')\nprint(f'Shape True New articles: {true_df.shape}')\nprint(f'Shape Fake New articles: {fake_df.shape}')","e83344e2":"true_df['Label'] = 'True'\nfake_df['Label'] = 'Fake'\ntrue_df.head()","82222328":"df_final = pd.concat([true_df,fake_df])\nprint(f'Shape of Combined DATA SET: {df_final.shape}')","a0f356e6":"df_final['Label'].shape","b2d0a949":"TRAIN_SET,TEST_SET, TRAIN_label,TEST_label = train_test_split(df_final['text'], df_final['Label'],random_state = 10,\n                                                               test_size = 0.20)\nprint(f'TRAIN FEATURE SET: {TRAIN_SET.shape}')\nprint(f'TRAIN LABEL SET: {TRAIN_label.shape}')\nprint(f'TEST FEATURE SET: {TEST_SET.shape}')","0c69abd5":"# Building Pipeline for raw text transformation\nclf = Pipeline([\n    ('vect', TfidfVectorizer(stop_words= \"english\")),\n    ('classifier', MultinomialNB()),\n    ])","3920ad01":"model_NB = clf.fit(TRAIN_SET, TRAIN_label)","99981436":"score = model_NB.score(TEST_SET, TEST_label)\nprint(f'Accuracy of Model is: {score}')","803fec7e":"#Confusion Matrix\n# Compute confusion matrix\ny_predicted_labels = model_NB.predict(TEST_SET)\ncnf_matrix = confusion_matrix(TEST_label, y_predicted_labels)\nnp.set_printoptions(precision=2)\ncnf_matrix","b4c75024":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","a18b9a18":"#With Normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= ['True', 'Fake'],\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= ['True', 'Fake'], normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","8745c175":"from sklearn.linear_model import LogisticRegression","ab257559":"# Building Pipeline for raw text transformation\nclf = Pipeline([\n    ('vect', TfidfVectorizer(stop_words= \"english\")),\n    ('classifier', LogisticRegression()),\n    ])","29ac3310":"model_LogReg = clf.fit(TRAIN_SET, TRAIN_label)","65e9e45d":"score = model_LogReg.score(TEST_SET, TEST_label)\nprint(f'Accuracy of Model is: {score}')","d127fa73":"#Confusion Matrix\n# Compute confusion matrix\ny_predicted_labels = model_LogReg.predict(TEST_SET)\ncnf_matrix = confusion_matrix(TEST_label, y_predicted_labels)\nnp.set_printoptions(precision=2)\ncnf_matrix","71554c5d":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","1397aee1":"#With Normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= ['True', 'Fake'],\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= ['True', 'Fake'], normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","58ff54d4":"joblib.dump(model_LogReg,'Log_Reg.joblib')","de7832c4":"sample_example = ['two hundred people flew to Mars from my Country',\n                  'India won the test series against Australia',\n                  'World war started in 2020 and thanks to COVID it was stopped',\n                 'World conference held in Winter']","378e540e":"model_loaded= joblib.load('Log_Reg.joblib')","456de311":"for text in sample_example:\n    print(f'Predicted label for new:{model_loaded.predict([text])[0]}')","3b99f24d":"### Import Libraries","9ad2762c":"### Save the trained model to file system","f1192fb2":"### Preprocess and split DATA SET into training and test using pipeline method\n- Also add ML model to classify the fake vs True articles","028712ca":"### Predicting fake news using Logistic Regression","2c843974":"### Load DATA\n### Clean and Preprocess the 2 datasets and combine them","b6000680":"### Validate the scores\n- Confusion Matrix"}}