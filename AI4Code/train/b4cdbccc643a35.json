{"cell_type":{"44425275":"code","2083c565":"code","de912d7e":"code","bf3ae7a0":"code","e24711b9":"code","4cff4538":"code","eb8b1432":"code","4f600b9f":"code","904088e1":"code","3a938df6":"code","4736812f":"code","ba92912a":"code","0a00d61a":"code","7fcd5fa8":"code","cd47a734":"markdown"},"source":{"44425275":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report # Importing metrics for evaluation\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.simplefilter(action='ignore')","2083c565":"# importing the dataset\ndataset = pd.read_csv(\"..\/input\/Iris.csv\")","de912d7e":"dataset.head()","bf3ae7a0":"dataset.shape","e24711b9":"# visualize data for correlation and correlation matrix\nsns.pairplot(dataset, hue='Species')","4cff4538":"dataset.Species.value_counts()","eb8b1432":"# correlation between the variables\nplt.figure(figsize=(20,10)) \nsns.heatmap(dataset.corr(),annot=True)","4f600b9f":"dataset['Species'].replace(\"Iris-setosa\",1,inplace= True)\ndataset['Species'].replace(\"Iris-virginica\",2,inplace = True)\ndataset['Species'].replace(\"Iris-versicolor\",3,inplace=True)","904088e1":"# Data wrangling\nX = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values","3a938df6":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","4736812f":"# Spliting data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","ba92912a":"# Test options and evaluation metric\nnum_folds = 10\nseed = 0\nscoring = 'accuracy'","0a00d61a":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import KFold, cross_val_score\n\n# Spot-Check Algorithms (Classification)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Spot-Check Ensemble Models (Classification)\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom xgboost.sklearn import XGBClassifier\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('SVM', SVC()))\n\nmodels.append(('AB', AdaBoostClassifier()))\nmodels.append(('GBM', GradientBoostingClassifier()))\nmodels.append(('ET', ExtraTreesClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('XGB',XGBClassifier()))\n\n# evaluate each model in turn\nresults = {}\naccuracy = {}\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results[name] = (cv_results.mean(), cv_results.std())\n    model.fit(X_train, y_train)\n    _ = model.predict(X_test)\n    accuracy[name] = accuracy_score(y_test, _)","7fcd5fa8":"accuracy","cd47a734":"> Naive Bayes, Linear Discriminant Analysis, K-Nearest Neighbors, Support Vector Machine, ExtraTrees, Random Forests and XGBoost provides accuracy 1.0"}}