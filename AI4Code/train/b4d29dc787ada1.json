{"cell_type":{"def3f0dd":"code","2982db00":"code","d65c2f6a":"code","e2e45d1b":"code","97068882":"code","72654890":"code","186f16e5":"code","c46ae962":"code","f16d825f":"code","36ef847c":"code","246a5ce1":"code","854ae65b":"code","254d1eff":"markdown","2c5b392e":"markdown","70c3032b":"markdown","bfb8d2a9":"markdown","c0379f05":"markdown","79733eed":"markdown","1302af7d":"markdown"},"source":{"def3f0dd":"import numpy as np \nimport pandas as pd\nimport math","2982db00":"def coefficient_correlation(col_x, col_y):\n    n = len(col_x)\n    # find mean x and y (\u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432 \u043e\u0431\u043e\u0438\u0445 \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u0445)\n    x = 1\/n * sum(col_x)\n    y = 1\/n * sum(col_y)\n    # find mean xy (\u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u043d\u0438\u044f xy)\n    xy = 1\/n * sum([col_x[i]*col_y[i] for i in range(n)])\n    # find variance (\u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044e)\n    D_x = 1\/n * sum([(col_x[i]- x)**2 for i in range(n)])\n    D_y = 1\/n * sum([(col_y[i]- y)**2 for i in range(n)])\n    # find sigma (\u043d\u0430\u0445\u043e\u0434\u0438\u043c sigma)\n    sigma_x = math.sqrt(D_x)\n    sigma_y = math.sqrt(D_y)\n    return (xy - x * y)\/(sigma_x * sigma_y)","d65c2f6a":"# Example r_xy = 0.9859\ncol_x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\ncol_y = [107, 109, 110, 113, 120, 122, 123, 128, 136, 140, 145,150]\ncoefficient_correlation(col_x, col_y) ","e2e45d1b":"columns = [\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\",\n           \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\", \"genre\"]\ndata = pd.read_csv(\"..\/input\/dataset-of-songs-in-spotify\/genres_v2.csv\", \n                   usecols=columns)\ndata.head()","97068882":"data.isnull().count() # \u043d\u0435\u0442 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 ","72654890":"# \u0414\u043b\u044f \u0443\u0434\u043e\u0431\u0441\u0442\u0432\u0430, \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0443 \"genre\" \u043a \u043a\u043e\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u043e\u043c\u0443 \u0442\u0438\u043f\u0443 \u0434\u0430\u043d\u043d\u044b\u0445\ngenre_unique = list(data.genre.unique())\ngenre = {} # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c\ni = 0\nfor name in genre_unique:\n    genre[name] = i\n    i = i + 1\n\nnew_genre = [] # \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0440\u0430\u043d\u0435\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0439 \u0441\u043b\u043e\u0432\u0430\u0440\u044c, \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\nfor row in data.genre:\n    new_genre.append(genre[row])\n\ndata[\"new_genre\"] = new_genre # \u0434\u043e\u0431\u043e\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u0441\u0442\u043e\u043b\u0431\u0435\u0446, \u0441\u043e\u0441\u0442\u043e\u044f\u0449\u0438\u0439 \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\ndata = data.drop(\"genre\", axis=1) # \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \"genre\"\n\nprint(genre)","186f16e5":"data.head()","c46ae962":"df_genre = pd.DataFrame({\"genre\": list(data.groupby(\"new_genre\").new_genre.count())}, index=genre_unique)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,5))\ndf_plot = sns.barplot(x=df_genre.index, y=df_genre[\"genre\"])","f16d825f":"def col_coefficient_correlation(col_x, data):\n    coefficient = []\n    for col in list(data.columns):\n        coefficient.append(coefficient_correlation(data[col_x], data[col]))\n    return coefficient","36ef847c":"index = list(data.columns)\ncolumns = {}\nfor col in index:\n    columns[col] = col_coefficient_correlation(col, data)\n    print(col, \" - finish\")","246a5ce1":"df = pd.DataFrame(columns, index=index)\ndf","854ae65b":"plt.figure(figsize=(14,10))\ntab = sns.heatmap(data=df, vmin=-1, vmax=1, annot=True)","254d1eff":"# Correlation (\u041a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c)\n\n","2c5b392e":"$ \\overline{x} $ - arithmetic mean (\u0430\u0440\u0435\u0444\u043c\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0441\u0440\u0435\u0434\u043d\u0435\u0435)\n\n$r_{xy} = \\dfrac{\\overline{xy} - \\overline{x} \\cdot \\overline{y}}{\\sigma_{x} \\cdot \\sigma_{y}}$ - coefficient correlation (\u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438), \u0433\u0434\u0435 $\\sigma_{x}, \\sigma_{y}$ - standard deviation (\u0441\u0440\u0435\u0434\u043d\u0435\u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u044f)\n\n$\\sigma_{x} = \\sqrt{D[x]}$ , \u0433\u0434\u0435 $D[x]$ - variance (\u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0439 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b)\n\n$D[x] = \\dfrac{1}{n} \\cdot \\sum^{n}_{i=1} (x_{i} - \\overline{x})^{2} $","70c3032b":"\u0412\u044b\u0432\u043e\u0434: \u043d\u0430\u0439\u0434\u0435\u043d\u044b \u0441\u043b\u0430\u0431\u044b\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438: \n1. \u041f\u0440\u044f\u043c\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c: loudness - energy (0.6); instrumentalness - duration_ms (0.6); energy - new_genre (0.54)\n2. \u041e\u0431\u0440\u0430\u0442\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c: energy - acousticness (-0.5)","bfb8d2a9":"Let's choose the columns we need (\u0412\u044b\u0431\u0435\u0440\u0435\u043c \u043d\u0443\u0436\u043d\u044b\u0435 \u043d\u0430\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0438) ","c0379f05":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c DataFrame \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0439 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u044b \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438","79733eed":"I am learning to find correlations.  This work may contain errors, if you find them, please write in the comments.\n\n( \u0423\u0447\u0443\u0441\u044c \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c \u043a\u043e\u0440\u0435\u043b\u044f\u0446\u0438\u0438.\n\n\u042d\u0442\u0430 \u0440\u0430\u0431\u043e\u0442\u0430 \u043c\u043e\u0436\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043e\u0448\u0438\u0431\u043a\u0438, \u0435\u0441\u043b\u0438 \u0432\u044b \u0438\u0445 \u043d\u0430\u0439\u0434\u0435\u0442\u0435, \u0442\u043e \u043d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430 \u0432 \u043a\u043e\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438.)","1302af7d":"Check for null data (\u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430 \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u0443\u0445)"}}