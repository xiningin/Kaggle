{"cell_type":{"64b4281e":"code","1faa9a0a":"code","36982a26":"code","298a553e":"code","b38e7226":"code","3a8d4f93":"code","f227af4d":"code","8961aaa2":"code","1ed79753":"code","5711102f":"code","7736aadd":"code","06355815":"code","ea19bbb6":"code","442fe10b":"code","5552db6c":"code","545e77e7":"code","2993ec72":"code","7da44cad":"code","084dae54":"code","6f6df5e0":"code","b5485fac":"code","09ad02e4":"code","6b336214":"code","23c952be":"code","334b17b0":"code","c3cc635f":"code","49bba7bf":"code","5ec94b4a":"code","4eb609c8":"code","ffb73fbf":"code","d46c69dd":"code","4b099341":"code","89b9162f":"code","f950b316":"code","9a0b35e0":"code","97f8c754":"code","a61e99a5":"code","127ccf3c":"code","447af76a":"code","f501592a":"markdown","cd9d319a":"markdown","17c31131":"markdown","7618db55":"markdown","d0ee262f":"markdown","54196b5a":"markdown","eb08dc14":"markdown","ac3f89df":"markdown","751ed832":"markdown","a22a488d":"markdown","096d05af":"markdown","3cff4a4a":"markdown","3f811a26":"markdown","c0d09d24":"markdown","e5a02248":"markdown","f7a4877b":"markdown","9bad0b6f":"markdown","97c9e7ed":"markdown","03982861":"markdown"},"source":{"64b4281e":"DoTrain = False\nDoTrain3D = False\nDoCV = False","1faa9a0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36982a26":"import matplotlib.pyplot as plt\nimport sklearn\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.manifold import TSNE\nimport sys\nsys.path.append('..\/input\/iterative-stratification\/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","298a553e":"train_features_df = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_labels_df = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nsubmission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\ntrain_df = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')","b38e7226":"catnames = train_features_df.columns[1:4]\ncatnames = [str(c) for c in catnames]\n\ncontnames = train_features_df.columns[4:]\ncontnames = [str(c) for c in contnames]\n\nynames = train_labels_df.columns[1:]\nynames = [y for y in ynames]\n\njoined = pd.concat([train_features_df, train_labels_df], axis=1, join='inner')\njoined = joined.drop(columns = 'sig_id')\njoined = joined[joined['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)","3a8d4f93":"cov = np.cov(train_features_df[train_features_df.columns[4:]].to_numpy().transpose())\nplt.imshow(cov)","f227af4d":"cov = 1 \/ cov","8961aaa2":"dim = 2\ntsne_em = TSNE(n_components=dim, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\nif dim == 1:\n    plt.hist(*[tsne_em[:,i] for i in range(dim)])\nelse:\n    plt.scatter(*[tsne_em[:,i] for i in range(dim)])","1ed79753":"def GetIndexMap1D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) \/ n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):        \n            pos = mini + np.array([i*d[0]])\n            ds = []\n            for s in range(tsne_em.shape[0]):\n                ds.append(np.linalg.norm(tsnecopy[s] - pos))\n            ds = np.array(ds)\n            mindindex = indexhelper[ds == np.min(ds)]\n            tsnecopy[mindindex] = np.array([np.inf])\n            if count <  len(train_df.columns) - 4:\n                dic[i] = mindindex[0]\n            count += 1\n    return dic\n\n\ndef GetIndexMap2D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) \/ n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            pos = mini + np.array([i*d[0],j*d[1]])\n            ds = []\n            for s in range(tsne_em.shape[0]):\n                ds.append(np.linalg.norm(tsnecopy[s] - pos))\n            ds = np.array(ds)\n            mindindex = indexhelper[ds == np.min(ds)]\n            tsnecopy[mindindex] = np.array([np.inf,np.inf])\n            if count <  len(train_df.columns) - 4:\n                dic[(i,j)] = mindindex[0]\n            count += 1\n    return dic\n\n\ndef GetIndexMap3D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) \/ n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                pos = mini + np.array([i*d[0],j*d[1],k*d[2]])\n                ds = []\n                for s in range(tsne_em.shape[0]):\n                    ds.append(np.linalg.norm(tsnecopy[s] - pos))\n                ds = np.array(ds)\n                mindindex = indexhelper[ds == np.min(ds)]\n                tsnecopy[mindindex] = np.array([np.inf,np.inf,np.inf])\n                if count <  len(train_df.columns) - 4:\n                    dic[(i,j,k)] = mindindex[0]\n                count += 1\n    return dic","5711102f":"def GetUnityMap1D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        dic[i] = i\n    return dic\n\ndef GetUnityMap2D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            dic[(i,j)] = i * n_sqrt + j\n    return dic\n\ndef GetUnityMap3D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                dic[(i,j,k)] = i * n_sqrt * n_sqrt + j * n_sqrt + k            \n    return dic","7736aadd":"def getBatchNormalized(inds,dic,mini,maxi,dim):    \n    if dim == 1:          \n        return getBatchNormalized1D(inds,dic,mini,maxi,872).astype(np.single)\n    if dim == 2:\n        return getBatchNormalized2D(inds,dic,mini,maxi,30).astype(np.single)\n    if dim == 3:\n        return getBatchNormalized3D(inds,dic,mini,maxi,10).astype(np.single)\n    \ndef getStats(dic,dim):    \n    if dim == 1:          \n        return getStats1D(dic,872)\n    if dim == 2:\n        return getStats2D(dic,30)\n    if dim == 3:\n        return getStats3D(dic,10)\n\ndef getBatchNormalized1D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()   \n    \n    for i in range(n_sqrt):        \n        try:\n            image[:,0,i] = rows[:,dic[i]]\n        except:                \n            continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) \/ ampl\n    \n    return result   \n\ndef getBatchNormalized2D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()  \n    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            try:\n                image[:,0,i,j] = rows[:,dic[(i,j)]]\n            except:                \n                continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) \/ ampl\n    \n    return result   \n\ndef getBatchNormalized3D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt,n_sqrt,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()  \n    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for j in range(n_sqrt):            \n                try:\n                    image[:,0,i,j,k] = rows[:,dic[(i,j,k)]]\n                except:                \n                    continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) \/ ampl\n    \n    return result   \n\ndef getStats1D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):        \n        try:\n            image[:,0,i] = row[:,dic[i]]\n        except:                \n            continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\n\ndef getStats2D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            try:\n                image[:,0,i,j] = row[:,dic[(i,j)]]\n            except:                \n                continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\ndef getStats3D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt,n_sqrt,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                try:\n                    image[:,0,i,j,k] = row[:,dic[(i,j,k)]]\n                except:                \n                    continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\ndef getLabelBatch(inds):\n    entry = joined.iloc[inds]\n    return entry[ynames].to_numpy().astype(np.single)","06355815":"class BatchLoader:\n    def __init__(self,trainInds,valInds,dim,dic,bs):\n        self.trainIndices = trainInds\n        self.valInds = valInds\n        self.dim = dim\n        self.dic = dic\n        self.min,self.max = getStats(dic,dim)\n        self.its = trainIndices.shape[0] \/\/ bs\n        self.bs = bs\n        if self.trainIndices.shape[0] - self.its * bs > 0:\n            self.its += 1\n        \n    def randomize(self):\n        self.pmt = np.random.permutation(range(self.trainIndices.shape[0]))\n        \n    def __len__(self):\n        return self.its      \n    \n    def getValidationSet(self):        \n        inpBatch = getBatchNormalized(self.valInds,self.dic,self.min,self.max,self.dim) \n        tgtBatch = getLabelBatch(self.valInds)    \n        \n        return torch.from_numpy(inpBatch), torch.from_numpy(tgtBatch)      \n        \n    def __getitem__(self, index):\n        start = index * self.bs\n        end = min((index+1)*self.bs,self.trainIndices.shape[0])\n        inds = self.trainIndices[self.pmt][start:end]\n        inpBatch = getBatchNormalized(inds,self.dic,self.min,self.max,self.dim) \n        tgtBatch = getLabelBatch(inds)    \n        \n        return torch.from_numpy(inpBatch), torch.from_numpy(tgtBatch)      ","ea19bbb6":"class QuickModelBase(nn.Module):\n    def __init__(self):\n        super(QuickModelBase, self).__init__()  \n        \n        \n    def forward(self, x, dbg = False, dropout = True):        \n        x = self.bn1(x)\n        x = self.conv1(x)\n        x = self.act1(x)\n        if dropout: x = self.do1(x)\n        \n        x = self.bn2(x)\n        x = self.conv2(x)\n        x = self.act2(x)\n        if dropout: x = self.do2(x)\n        \n        x = self.bn3(x)\n        x = self.conv3(x)\n        x = self.act3(x)\n        if dropout: x = self.do3(x)\n        \n        x = self.bn4(x)                \n        x = torch.flatten(x,start_dim = 1)        \n        x = self.full1(x)\n        x = self.act4(x)       \n                \n        return x\n    \n    \nclass QuickModel1DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size,n_sqrt):\n        super(QuickModel1DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm1d(1)\n        self.conv1 = nn.Conv1d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()\n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm1d(feat_num[0])\n        self.conv2 = nn.Conv1d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm1d(feat_num[1])\n        self.conv3 = nn.Conv1d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU()\n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm1d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()\n        \n\nclass QuickModel2DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size,n_sqrt):\n        super(QuickModel2DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm2d(1)\n        self.conv1 = nn.Conv2d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()  \n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm2d(feat_num[0])\n        self.conv2 = nn.Conv2d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm2d(feat_num[1])\n        self.conv3 = nn.Conv2d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU()\n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm2d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()    \n        \n        \nclass QuickModel3DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size, n_sqrt):\n        super(QuickModel3DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm3d(1)\n        self.conv1 = nn.Conv3d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()        \n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm3d(feat_num[0])\n        self.conv2 = nn.Conv3d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm3d(feat_num[1])\n        self.conv3 = nn.Conv3d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU() \n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm3d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()","442fe10b":"def TrainEpoch(valloss,model,opt,sch,dim,dl,valInds,loss,istest,fold=None):\n    count = 0\n    modelname = f\"BestModel{dim}D\" if not istest else f\"BestRefModel{dim}D\"\n    if fold != None: modelname = modelname + f\"Fold{fold}\"\n    modelname = modelname + \".pth\"\n    \n    for i in range(len(dl)): \n        (inp,tgt) = dl[i]\n        opt.zero_grad()       \n        fwd = model(inp.cuda())\n        ys = tgt.cuda()\n        output = loss(fwd, ys)        \n        output.backward()\n        opt.step()   \n        \n        if count % 1 == 0:           \n            batchVal,ysVal = dl.getValidationSet()\n            fwdVal = model(batchVal.cuda())            \n            currentvalloss = loss(fwdVal, ysVal.cuda()).detach().cpu().numpy()   \n            \n            if currentvalloss < valloss:\n                valloss = currentvalloss\n                torch.save(model.state_dict(), modelname)\n                \n        count += 1\n                \n    return currentvalloss","5552db6c":"def Train(dim, dic, bs, trainInds, valInds, model,istest,fold = None):    \n    dl = BatchLoader(trainInds,valInds, dim, dic,bs)\n\n    loss = nn.BCEWithLogitsLoss().cuda()    \n\n    lrstart = 0.1\n    optimizer = optim.Adam(model.parameters(), lr=lrstart)\n    scheduler = ReduceLROnPlateau(optimizer, 'min')\n\n    valloss = np.inf\n    for e in range(70):\n        if e % 3 == 0: print('Epoch: ' + str(e)) \n        dl.randomize()\n        currentvalloss = TrainEpoch(valloss,model,optimizer,scheduler,dim,dl,valIndices,loss,istest,fold)\n        scheduler.step(currentvalloss)\n        if abs(currentvalloss - valloss) < 0.0000001: break\n        if currentvalloss < valloss: \n            valloss = currentvalloss\n            print('BestLoss: ' + str(currentvalloss))\n    \n        ","545e77e7":"folds = joined.copy()\nFold = MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n\nindices = {}\nfor n, (trainidx, validx) in enumerate(Fold.split(joined, joined[ynames])):    \n    indices[n] = (trainidx, validx)","2993ec72":"valIndices = indices[0][1]\ntestIndices = indices[4][1]\ntrainIndices =  indices[0][0]\ntrainIndices = trainIndices[np.isin(trainIndices,testIndices,invert=True)]\nvalIndices = valIndices[np.isin(valIndices,testIndices,invert=True)]","7da44cad":"if DoTrain or DoCV:\n    tsne1D = TSNE(n_components=1, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne1D',tsne1D)\nelse: \n    tsne1D = np.load('..\/input\/t-sne-for-applying-nd-cnns\/tsne1D.npy')    ","084dae54":"dicRef1D = GetUnityMap1D(872)\ndic1D = GetIndexMap1D(tsne1D,872)","6f6df5e0":"bs = 512\nmodelRef1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\nif DoTrain: Train(1, dicRef1D, bs, trainIndices, valIndices, modelRef1D,True)","b5485fac":"model1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\nif DoTrain: Train(1, dic1D, bs, trainIndices, valIndices, model1D,False)","09ad02e4":"if DoCV:\n    fold = 0\n    for i in indices:\n        print(f\"Fold: {i}\")\n        model1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\n        valInds = indices[i][1]\n        trainInds = indices[i][0]\n        Train(1, dicRef1D, bs, trainInds, valInds, model1D,True,fold)\n        fold += 1","6b336214":"if DoTrain or DoCV:\n    tsne2D = TSNE(n_components=2, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne2D',tsne2D)\nelse: tsne2D = np.load('..\/input\/t-sne-for-applying-nd-cnns\/tsne2D.npy')    ","23c952be":"dicRef2D = GetUnityMap2D(30)\ndic2D = GetIndexMap2D(tsne2D,30)","334b17b0":"bs = 512\nmodelRef2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\nif DoTrain: Train(2, dicRef2D, bs, trainIndices, valIndices, modelRef2D,True)","c3cc635f":"model2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\nif DoTrain: Train(2, dic2D, bs, trainIndices, valIndices, model2D,False)","49bba7bf":"if DoCV:\n    fold = 0\n    for i in indices:\n        print(f\"Fold: {i}\")\n        model2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\n        valInds = indices[i][1]\n        trainInds = indices[i][0]\n        Train(2, dic2D, 512, trainInds, valInds, model2D,False,fold)\n        fold += 1","5ec94b4a":"if DoTrain3D:\n    tsne3D = TSNE(n_components=3, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne3D',tsne3D)\nelse: tsne3D = np.load('..\/input\/t-sne-for-applying-nd-cnns\/tsne3D.npy')    ","4eb609c8":"dicTest3D = GetUnityMap3D(10)\ndic3D = GetIndexMap3D(tsne3D,10)","ffb73fbf":"bs = 64\nmodelRef3D = QuickModel3DGen([20,40,80],[3,5],10).cuda()\nif DoTrain3D: Train(3, dicTest3D, bs, trainIndices, valIndices, modelRef3D,True)","d46c69dd":"model3D = QuickModel3DGen([10,20,40],[3,5],10).cuda()\nif DoTrain3D: Train(3, dic3D, 256, trainIndices, valIndices, model3D,False)","4b099341":"mini, maxi = getStats(dic1D,1)\nbatch1D = getBatchNormalized(testIndices,dic1D,mini,maxi,1) \nmini, maxi = getStats(dicRef1D,1)\nbatchRef1D = getBatchNormalized(testIndices,dicRef1D,mini,maxi,1) ","89b9162f":"if DoTrain: \n    model1D.load_state_dict(torch.load(\".\/BestModel1D.pth\"))\n    modelRef1D.load_state_dict(torch.load(\".\/BestRefModel1D.pth\"))\nelse: \n    model1D.load_state_dict(torch.load(\"..\/input\/t-sne-for-applying-nd-cnns\/BestModel1D.pth\"))\n    modelRef1D.load_state_dict(torch.load(\"..\/input\/t-sne-for-applying-nd-cnns\/BestRefModel1D.pth\"))\n    \nloss = nn.BCEWithLogitsLoss().cuda()    ","f950b316":"batch1DTorch = torch.from_numpy(batch1D.astype(np.single)).cuda()\nbatchRef1DTorch = torch.from_numpy(batchRef1D.astype(np.single)).cuda()\nfwdVal = model1D.forward(batch1DTorch,False,False)\nfwdRefVal = modelRef1D.forward(batchRef1DTorch,False,False)\nysVal = torch.from_numpy(getLabelBatch(testIndices)).cuda()\ntestloss1D = loss(fwdVal, ysVal).detach().cpu().numpy()\ntestlossRef1D = loss(fwdRefVal, ysVal).detach().cpu().numpy()","9a0b35e0":"print('1D: ')\nprint('Test loss: ')\nprint(testloss1D)\nprint('Test loss unaranged reference model: ')\nprint(testlossRef1D)","97f8c754":"mini, maxi = getStats(dic2D,2)\nbatch2D = getBatchNormalized(testIndices,dic2D,mini,maxi,2) \nmini, maxi = getStats(dicRef2D,2)\nbatchRef2D = getBatchNormalized(testIndices,dicRef2D,mini,maxi,2) ","a61e99a5":"if DoTrain:\n    model2D.load_state_dict(torch.load(\".\/BestModel2D.pth\"))\n    modelRef2D.load_state_dict(torch.load(\".\/BestRefModel2D.pth\"))\nelse:\n    model2D.load_state_dict(torch.load(\"..\/input\/t-sne-for-applying-nd-cnns\/BestModel2D.pth\"))\n    modelRef2D.load_state_dict(torch.load(\"..\/input\/t-sne-for-applying-nd-cnns\/BestRefModel2D.pth\"))\n    \nloss = nn.BCEWithLogitsLoss().cuda()    ","127ccf3c":"batch2DTorch = torch.from_numpy(batch2D.astype(np.single)).cuda()\nbatchRef2DTorch = torch.from_numpy(batchRef2D.astype(np.single)).cuda()\nfwdVal = model2D.forward(batch2DTorch,False,False)\nfwdRefVal = modelRef2D.forward(batchRef2DTorch,False,False)\nysVal = torch.from_numpy(getLabelBatch(testIndices)).cuda()\ntestloss2D = loss(fwdVal, ysVal).detach().cpu().numpy()\ntestlossRef2D = loss(fwdRefVal, ysVal).detach().cpu().numpy()","447af76a":"print('2D: ')\nprint('Test loss: ')\nprint(testloss2D)\nprint('Test loss unaranged reference model: ')\nprint(testlossRef2D)","f501592a":"# 2D","cd9d319a":"# 1D","17c31131":"<a id=\"section-six\"><\/a>\n# 6.) Evaluating arrangement and models","7618db55":"<a id=\"section-two\"><\/a>\n# 2.) Arranging the data into arrays\n","d0ee262f":"<a id=\"section-five\"><\/a>\n# 5.) Training","54196b5a":"<a id=\"subsection-three\"><\/a>\n# 6.3) Testing and comparing arangement models","eb08dc14":"# 3D","ac3f89df":"* The arangement of the data columns into 2D arrays has a large impact on the performance of 1D and 2D CNNs\n* The method of aranging the data into multidimensional arrays investigated here seems promising\n* Overall the 1D CNN tried out here seems to perform slightly better then the 2D CNN\n* It should be investigated if this holds for deeper models and other train-\/testset combinations\n* 3D CNN perform poorly","751ed832":"* In the following sections the g- and c-data is aranged into a 1-,2- or 3-dimensional cubic grid of length n_sqrt\n* For this the absolute of the entries of the covariance matrix (here named cov) are interpreted as the pairwise distances between the data columns\n* When applying t-sne to the absolute covariance matrix the data columns with higher absolute covariance will be closer to each other in the lower diomensional projected space\n* The lower diomensional projected space is then divided into equidistantly spaced 'pixels' \n* Then, while iterating over the 'pixels', the data column with the closest distance to the 'pixel' in the projected space is assigned to the respective 'pixel' \n* This assignment to pixels is stored into a dictionary by the GetIndexMapND functions in the Map section\n* To these 'images' a CNN is then applied\n* As a reference, another 'image' is generated by assigning data columns to each pixel according to the order they appear in the data frame \n* This random arangement of the data columns is supposed determine if the arangement according to covariance is of any use \n* The random arangement is stored into a dictionary by the GetUnityMapND functions in the Map section","a22a488d":"<a id=\"section-one\"><\/a>\n# 1.) Dimensionality reduction by t-sne","096d05af":"<a id=\"section-three\"><\/a>\n# 3.) Dataloading","3cff4a4a":"<a id=\"subsection-one\"><\/a>\n# 6.1) Train-, validation and testsets ","3f811a26":"<a id=\"section-seven\"><\/a>\n# 7.) Conclusion & Outlook","c0d09d24":"# Table of contents\n1. [Dimensionality reduction by t-sne](#section-one)\n2. [Arranging the data into arrays](#section-two)\n3. [Dataloading](#section-three)\n4. [Models](#section-four)\n5. [Training](#section-five)\n6. [Evaluating arrangement and models](#section-six)\n    - [Train-, validation and testsets](#subsection-one)\n    - [Training models](#subsection-two)\n    - [Testing and comparing arangement models](#subsection-three)\n7. [Conclusion](#section-seven)","e5a02248":"# 2D","f7a4877b":"# Description:\n* In this notebook effectivity of ***1D,2D and 3D CNNs*** is evaluated\n* In order to apply CNNs efficiently to the data, it is aranged into arrays in a way that genes with a high covariance are close to each other\n* This is done by projecting the data into a 1-,2- or 3 dimensional space using ***t-sne***\n* It turns out that this way of aranging the data yields significantly better results for the 1D and 2D CNN\n* The 3D CNN generally yields bad results ","9bad0b6f":"<a id=\"section-four\"><\/a>\n# 4.) Models\n* Here the 1-,2- and 3-dimensional CNN models are defined\n* These models are very simple and consist of two convolutional layers, with number of channels and filter size can be set varied","97c9e7ed":"<a id=\"subsection-two\"><\/a>\n# 6.2) Training models","03982861":"# 1D"}}