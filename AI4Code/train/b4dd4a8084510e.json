{"cell_type":{"f2941cf7":"code","7945497d":"code","d8493dae":"code","db076b9f":"code","9c366454":"code","4f3f90ac":"code","68776dcc":"code","08cc23a0":"code","475a726b":"code","c5f33695":"code","676e53a0":"code","5e89f626":"code","06ec1712":"code","bcac5961":"code","f3d88e5e":"code","2e8fe62e":"code","239e7d9b":"code","4e06dc3f":"code","0cf20f43":"code","66bd9729":"code","1faa6971":"code","a422420b":"markdown","cebd8ae7":"markdown","fcd013cc":"markdown","a4881985":"markdown","5331b44b":"markdown","25ac99f4":"markdown"},"source":{"f2941cf7":"import keras\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.applications import MobileNetV2\nfrom sklearn.metrics import classification_report\nimport cv2\nfrom tqdm import tqdm","7945497d":"import os\nimage_ids = os.listdir('..\/input\/train\/train\/')","d8493dae":"x_train = []\ny_train = []\nfor i in tqdm(image_ids):\n    category = i.split(\".\")[0]\n    if category == \"dog\":\n        y_train.append(1)\n    else:\n        y_train.append(0)\n        \n    img_arr = cv2.imread(\"..\/input\/train\/train\/\"+i, cv2.IMREAD_GRAYSCALE)\n    #img_arr = cv2.imread(\"..\/input\/train\/train\/\"+i)\n    img_arr = cv2.resize(img_arr, dsize=(128, 128))\n    x_train.append(img_arr)","db076b9f":"x_train = np.array(x_train)\nx_train.shape","9c366454":"x_train = x_train\/255\n#x_train = x_train.reshape(-1, 128, 128, 3)\nx_train = x_train.reshape(-1, 128, 128, 1)","4f3f90ac":"x_train.shape","68776dcc":"import pickle\nf = open(\"x_train.pickle\", \"wb\")\npickle.dump(x_train, f)\nf.close()\nf = open(\"y_train.pickle\", \"wb\")\npickle.dump(y_train,f)\nf.close()","08cc23a0":"model = Sequential()\nmodel.add(Conv2D(4,(3,3),strides=1, padding='valid', activation = 'relu', input_shape = x_train.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = (2,2), strides=2))\n\nmodel.add(Conv2D(16,(3,3), activation = 'relu', strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size = (2,2), strides=2))\n\nmodel.add(Conv2D(32, (3,3), activation=\"relu\", strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\", strides=1, padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='sigmoid'))\n\nmodel.add(Dense(1, activation='sigmoid'))","475a726b":"#base_model = MobileNetV2(input_shape=(128,128,3),\n #                        include_top=False, \n  #                       weights='imagenet')","c5f33695":"#model = Sequential([base_model,\n #                   MaxPooling2D(),\n  #                  Flatten(),\n   #                 Dense(1, activation='sigmoid')])","676e53a0":"model.compile(optimizer=\"adam\",\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","5e89f626":"model.summary()","06ec1712":"model.fit(x_train, y_train, epochs=1, batch_size=32, validation_split=0.2)","bcac5961":"f = open(\"model.pickle\", \"wb\")\npickle.dump(model, f)\nf.close()","f3d88e5e":"x_test = []\ntest_files = os.listdir(\"..\/input\/test1\/test1\/\")\nfor i in tqdm(test_files):    \n    img_arr = cv2.imread(\"..\/input\/test1\/test1\/\"+i, cv2.IMREAD_GRAYSCALE)\n    img_arr = cv2.resize(img_arr, dsize=(128, 128))\n    x_test.append(img_arr)","2e8fe62e":"x_test = np.array(x_test)\/255\nx_test = x_test.reshape(-1, 128, 128, 1)","239e7d9b":"x_test.shape","4e06dc3f":"predictions = model.predict(x_test)","0cf20f43":"results = []\nfor i in predictions:\n    if(i>0.5):\n        results.append(1)\n    else:\n        results.append(0)","66bd9729":"df = pd.DataFrame({\"id\":[i+1 for i in range(12500)], \n                   \"lable\" : [p for p in results]})","1faa6971":"df.to_csv(\"submission.csv\",index=False)","a422420b":"# Dogs v\/s Cats Classification","cebd8ae7":"As the data consists of images named as \"dog.1.jpg\", so we will store the image information in the x_train list and the category into y_train list.","fcd013cc":"We will be using keras framework for implementing our model","a4881985":"## Defining our model","5331b44b":"This is a classification problem which consists of 25000 images of dogs and cats in jpeg format. Our task is to correctly classify them as dogs and cats using convolutional neural networks.","25ac99f4":"## Importing Libraries"}}