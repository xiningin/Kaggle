{"cell_type":{"68db7ca9":"code","22d395b6":"code","799511be":"code","f54a1168":"code","81509d72":"code","cdc08819":"code","5ae91d50":"code","561981b1":"code","377f83c4":"code","73358681":"code","a2bb5379":"code","26307aaf":"code","457e15ff":"code","08559f79":"code","50891e17":"code","2b1066ae":"code","ae7dbc63":"markdown","1dcaca9c":"markdown","536ef47e":"markdown","e9be9a48":"markdown","3ade036d":"markdown"},"source":{"68db7ca9":"#\u5fc5\u8981\u306a\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom lightgbm import LGBMRegressor\nimport joblib\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\n\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","22d395b6":"#\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n\nsales = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')\nsales.name = 'sales'\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\ncalendar.name = 'calendar'\nprices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nprices.name = 'prices'","799511be":"for d in range(1942,1970):\n    col = 'd_' + str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","f54a1168":"#\u30c7\u30fc\u30bf\u306e\u30e1\u30e2\u30ea\u524a\u6e1b\n#https:\/\/www.kaggle.com\/fabiendaniel\/elo-world\n\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  \n\nsales = downcast(sales)\nprices = downcast(prices)\ncalendar = downcast(calendar)","81509d72":"#\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306e\u7d71\u5408\n\ndf = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\ndf = pd.merge(df, calendar, on='d', how='left')\ndf = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left')","cdc08819":"#\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u683c\u7d0d\n\nd_id = dict(zip(df.id.cat.codes, df.id))\nd_item_id = dict(zip(df.item_id.cat.codes, df.item_id))\nd_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))\nd_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))\nd_store_id = dict(zip(df.store_id.cat.codes, df.store_id))\nd_state_id = dict(zip(df.state_id.cat.codes, df.state_id))","5ae91d50":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306e\u30a8\u30f3\u30b3\u30fc\u30c9\nlist1=['event_name_1','event_type_1','event_name_2','event_type_2']\nfor i in list1:\n    df[i] = df[i].cat.add_categories(\"nan\").fillna(\"nan\")\n    df[i]=LabelEncoder().fit_transform(df[i]).astype(np.int8)\n    df[i]=df[i].astype('category')\n    \n#\u65e5\u6570\u306e\u578b\u5909\u63db\ndf.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n\n#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306e\u578b\u5909\u63db\ncols = df.dtypes.index.tolist()\ntypes = df.dtypes.values.tolist()\nfor i,type in enumerate(types):\n    if type.name == 'category':\n        df[cols[i]] = df[cols[i]].cat.codes\n\n#\u65e5\u4ed8\u578b\u306b\u5909\u63db\ndf['date'] = df['date'].apply(lambda x: x.strftime('%d')).astype(np.int8)","561981b1":"#\u30e9\u30b0\u7279\u5fb4\u91cf\u306e\u4f5c\u6210\n\nlags = [28,35,42,49]\nfor lag in lags:\n    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n\nlags2 = [1,2]\nfor lag in lags2:\n    df['event1_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['event_name_1'].shift(lag).astype(np.float16)\n    df['event1_lag_'+str(lag)].fillna(100, inplace=True)\n    df['event1_lag_'+str(lag)]=df['event1_lag_'+str(lag)].astype(np.int8)\n    df['event1_lag_'+str(lag)]=df['event1_lag_'+str(lag)].astype('category')","377f83c4":"#\u305d\u306e\u4ed6\u7279\u5fb4\u91cf\u306e\u4f5c\u6210\n\ndf['item_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)    \n#df['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n#df['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\ndf['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n#df['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n#df['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n\ndf['wm_yr_wk_linear']=LabelEncoder().fit_transform(df['wm_yr_wk'].values).astype(np.int16)\ndf.drop(['wm_yr_wk'], axis=1, inplace=True)\n\ndf['price_lag'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sell_price'].shift(7).astype(np.float16)\ndf['price-diff']=df['price_lag']-df['sell_price']\ndf.drop(['price_lag'], axis=1, inplace=True)\n\ndf['sell_price'].fillna(-1,inplace=True)\ndf['decimal']=df['sell_price'].apply(lambda x: 100*(x-int(x))).astype(np.int16)\ndf['sell_price'].replace(-1,np.nan,inplace=True)\n\ndf['expanding_price_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sell_price'].transform(lambda x: x.expanding(2).mean()).astype(np.float16)\ndf['diff_moving_mean']=df['expanding_price_mean']-df['sell_price']\ndf.drop(['expanding_price_mean'], axis=1, inplace=True)\n\ndf['price-diff']=df['price-diff'].astype(np.float16)\ndf.drop(['wday'], axis=1, inplace=True)\ndf['decimal']=df['decimal'].astype(np.int8)\ndf['year']=LabelEncoder().fit_transform(df['year']).astype(np.int8)\n\ndf['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sell_price'].transform('mean').astype(np.float16)\ndf['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sell_price'].transform('mean').astype(np.float16)\ndf['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\ndf.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)\n\n\ndf['price_max'] = df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n#df['price_min'] = df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n#df['price_std'] = df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n#df['price_mean'] = df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\ndf['price_norm'] = df['sell_price']\/df['price_max']\n#df['price_momentum'] = df['sell_price']\/df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\ndf['price_momentum_m'] = df['sell_price']\/df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\ndf['price_momentum_y'] = df['sell_price']\/df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n\n#df['rolling_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)\n#df['expanding_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.expanding(2).mean()).astype(np.float16)\n#df['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sold'].transform('mean').astype(np.float16)\n#df['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform('mean').astype(np.float16)\n#df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\n#df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)","73358681":"#\u4e0d\u8981\u306a\u30ab\u30e9\u30e0\u306e\u524a\u9664\n\nlist3=['cat_id','state_id']\nfor i in list3:\n    df.drop([i], axis=1, inplace=True)","a2bb5379":"#\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092pkl\u3067\u4fdd\u5b58\n\ndf = df[df['d']>=49]\ndf.to_pickle('data.pkl')\ndel df, sales, prices, calendar\ngc.collect()","26307aaf":"#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5207\u308a\u51fa\u3057\n\ndata = pd.read_pickle('data.pkl')\nvalid_csv=data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\ntest = data[data['d']>=1942][['id','d','sold']]\neval_preds = test['sold']\nvalid_preds_csv=valid_csv['sold']","457e15ff":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306e\u683c\u7d0d\n\ncat_column=[]\nfor i in data.columns:\n    if(str(data.dtypes[i])=='category'):\n        cat_column.append(i)","08559f79":"#store_id\u3054\u3068\u306b\u30e2\u30c7\u30ea\u30f3\u30b0\n\nfor store in d_store_id:\n    df = data[data['store_id']==store]\n    \n    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n    X_valid_csv, y_valid_csv = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n    X_test = df[df['d']>=1942].drop('sold',axis=1)\n    \n    model = LGBMRegressor(\n        learning_rate= 0.05,\n        subsample=0.6,\n        feature_fraction=0.6,\n        num_iterations = 1200,\n        max_bin=350,\n        num_leaves= 100,\n        lambda_l2=0.003,\n        max_depth=200,\n        min_data_in_leaf= 80,\n        force_row_wise= True,\n    )\n    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid_csv,y_valid_csv)],\n             eval_metric='rmse',  verbose=100, early_stopping_rounds=20,categorical_feature=cat_column)\n    valid_preds_csv[X_valid_csv.index] = model.predict(X_valid_csv)\n    eval_preds[X_test.index] = model.predict(X_test)\n    filename = 'model'+str(d_store_id[store])+'.pkl'\n\n    #\u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\n    joblib.dump(model, filename)\n    del model, X_train, y_train, X_valid_csv, y_valid_csv\n    gc.collect()","50891e17":"#feature importance\u306e\u7b97\u51fa\u3068\u53ef\u8996\u5316\n\nfeature_importance_df = pd.DataFrame()\nfeatures = [f for f in data.columns if f != 'sold']\nfor filename in os.listdir('\/kaggle\/working\/'):\n    if 'model' in filename:\n        model = joblib.load(filename)\n        store_importance_df = pd.DataFrame()\n        store_importance_df[\"feature\"] = features\n        store_importance_df[\"importance\"] = model.feature_importances_\n        store_importance_df[\"store\"] = filename[5:9]\n        feature_importance_df = pd.concat([feature_importance_df, store_importance_df], axis=0)\n    \ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (averaged over store predictions)')\n    plt.tight_layout()\n    \ndisplay_importances(feature_importance_df)","2b1066ae":"valid_csv['sold'] = valid_preds_csv\nvalidation = valid_csv[['id','d','sold']]\nvalidation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\nvalidation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nvalidation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n\ntest['sold'] = eval_preds\nevaluation = test[['id','d','sold']]\nevaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\nevaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nevaluation.id = evaluation.id.map(d_id)\n\n#\u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\nsubmit = pd.concat([validation,evaluation]).reset_index(drop=True)\n\n#dark magic\n#https:\/\/www.kaggle.com\/kyakovlev\/m5-dark-magic\nfor i in range(1,29):\n    submit['F'+str(i)] *= 1.04\n\nsubmit.to_csv('submission.csv',index=False)","ae7dbc63":"### \u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u3068\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","1dcaca9c":"### \u30e2\u30c7\u30eb\u69cb\u7bc9","536ef47e":"references:\n\n* https:\/\/www.kaggle.com\/kyakovlev\/m5-simple-fe\n* https:\/\/speakerdeck.com\/syaorn_13\/kaggle-m5-forecasting-accuracy-42nd-place-solution\n* https:\/\/www.kaggle.com\/anshuls235\/time-series-forecasting-eda-fe-modelling#5.-Feature-Engineering","e9be9a48":"### submission\u306e\u4f5c\u6210","3ade036d":"### \u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0"}}