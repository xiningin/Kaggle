{"cell_type":{"4bf9a557":"code","79df9efa":"code","7fb21f79":"code","e82cc209":"code","e94a4230":"code","185fbc2e":"code","5fbd87c6":"code","32db9338":"code","7cca51e5":"code","9140b5b1":"code","c4aac038":"code","cf5b4d19":"code","78cf2182":"code","cb4d754e":"code","f90539cb":"code","6d7c83c7":"code","3b0d9302":"code","58511045":"code","e667014c":"code","8493b2cd":"code","f2221386":"code","ce7bbadd":"code","0e2bfb41":"code","8b78774f":"code","5f930e1f":"code","94f2df1d":"code","e1d587c8":"code","172c79fc":"code","c95b27a9":"code","c0e9b20a":"code","20cddad3":"code","1b846faa":"code","2fe6edfc":"code","b8e5bda1":"code","50bd6bf3":"code","1c940f50":"code","a4552fc8":"code","92bf8889":"code","b3019014":"code","a02b74d3":"code","14de728b":"code","bded8675":"code","ce477f12":"code","03805d0e":"code","2996dd00":"code","5a389734":"code","b9bd842e":"code","6e7425ba":"code","b9da7695":"code","63d4ed65":"code","ea3a9ce9":"code","4ffa567e":"code","5e9919ed":"code","8a25e5d3":"code","519d6aa6":"code","190d6cdf":"code","55e12977":"code","1833c985":"code","742e689e":"code","1bb98444":"code","6daa086a":"code","e11aa13d":"code","3f35e9d8":"code","b2ce5016":"code","1c4c7dd0":"code","bed86f77":"markdown","c63d0ccc":"markdown","761114b0":"markdown","82caca2c":"markdown","634656d2":"markdown"},"source":{"4bf9a557":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","79df9efa":"import seaborn as sns\nimport matplotlib.pyplot as plt","7fb21f79":"store = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/store.csv')\ndata =  pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv')","e82cc209":"print(data.shape,store.shape)","e94a4230":"store.head()","185fbc2e":"data.head(20)","5fbd87c6":"test = pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/test.csv')","32db9338":"test.shape","7cca51e5":"test.head()","9140b5b1":"data.dtypes","c4aac038":"data.describe(include='object')","cf5b4d19":"data.describe()[['Sales','Customers']].loc['mean']","78cf2182":"data.describe()[['Sales','Customers']].loc['max']","cb4d754e":"data.describe()[['Sales','Customers']].loc['min']","f90539cb":"data.head()","6d7c83c7":"data.Store.nunique()","3b0d9302":"data.Store.value_counts()","58511045":"data.Store.value_counts().tail(50).plot.bar()","e667014c":"data.Store.value_counts().head(50).plot.bar()","8493b2cd":"data.DayOfWeek.value_counts()","f2221386":"data.Open.value_counts()","ce7bbadd":"data[data['Customers']==data['Customers'].max()]","0e2bfb41":"data[data['Sales']==data['Sales'].max()]","8b78774f":"data.isnull().sum()","5f930e1f":"store.isnull().sum()","94f2df1d":"data['Date'] = pd.to_datetime(data['Date'],format = '%Y-%m-%d')\n\n#for a single store\n\nstore_id = data.Store.unique()[0]\nstore_rows = data[data['Store']==store_id]\nstore_rows.resample('1d',on='Date')['Sales'].sum().plot.line(figsize=(10,8))","e1d587c8":"store_rows[store_rows.Sales==0]","172c79fc":"test['Date'] = pd.to_datetime(test['Date'],format = '%Y-%m-%d')\nstore_test_rows = test[test['Store']==store_id]\nstore_test_rows['Date'].min(), store_test_rows['Date'].max()","c95b27a9":"store_rows['Sales'].plot.hist()","c0e9b20a":"data['Sales'].plot.hist()","20cddad3":"store[store['Store']==store_id].T","1b846faa":"store[~store['Promo2SinceYear'].isna()].iloc[0]","2fe6edfc":"store.isna().sum()","b8e5bda1":"#Method1\n\nstore['Promo2SinceWeek'] = store['Promo2SinceWeek'].fillna(0)\nstore['Promo2SinceYear'] = store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\nstore['PromoInterval'] = store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\n\nstore['CompetitionDistance'] = store['CompetitionDistance'].fillna(store['CompetitionDistance'].max())\nstore['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])","50bd6bf3":"store.isna().sum()","1c940f50":"data_merged = data.merge(store, on ='Store', how='left')","a4552fc8":"data_merged","92bf8889":"data.shape, data_merged.shape","b3019014":"data_merged.isna().sum()\n","a02b74d3":"data_merged.dtypes","14de728b":"data_merged['day'] = data_merged['Date'].dt.day\ndata_merged['year'] = data_merged['Date'].dt.year\ndata_merged['month'] = data_merged['Date'].dt.month\n#data_merged['Date'].dt.strftime('%a')","bded8675":"data_merged['StateHoliday'].unique()\ndata_merged['StateHoliday'] = data_merged['StateHoliday'].map({'0':0, 0:0,'a':1,'b':2,'c':3}).astype(int)\ndata_merged['StoreType'] = data_merged['StoreType'].map({'c':0, 'a':1,'d':2,'b':3}).astype(int)\ndata_merged['Assortment'] = data_merged['Assortment'].map({'a':0, 'c':1,'b':2}).astype(int)\ndata_merged['PromoInterval'] = data_merged['PromoInterval'].map({'Jan,Apr,Jul,Oct':0, 'Feb,May,Aug,Nov':1,'Mar,Jun,Sept,Dec':2}).astype(int)\ndata_merged['StateHoliday']","ce477f12":"data_merged.dtypes","03805d0e":"data_merged.shape","2996dd00":"from sklearn.model_selection import train_test_split\nimport numpy as np\nX = data_merged.drop(['Sales','Date','Customers'],axis=1)\ny = data_merged['Sales']\nX_train, X_test, y_train, y_test = train_test_split(X, np.log(y+1), test_size=0.3, random_state=1)","5a389734":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nmodel = DecisionTreeRegressor(max_depth=11)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nr2_score(y_pred,y_test)\n\n# def ToWeight(y):\n#     w = np.zeros(y.shape, dtype=float)\n#     ind = y != 0\n#     w[ind] = 1.\/(y[ind]**2)\n#     return w\n\n# def rmspe(y, yhat):\n#     w = ToWeight(y)\n#     rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n#     return rmspe\n\n# rmse_val = np.sqrt(mean_squared_error(y_test_inv,y_pred_inv))\n# rmspe_val = rmspe(y_test_inv,y_pred_inv)\n# print(rmse_val,rmspe_val)","b9bd842e":"\n# def draw_tree(model, columns):\n#     import pydotplus\n#     from sklearn.externals.six import StringIO\n#     from IPython.display import Image\n#     import os\n#     from sklearn import tree\n    \n#     graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38\/bin\/'\n#     os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n#     dot_data = StringIO()\n#     tree.export_graphviz(model,\n#                          out_file=dot_data,\n#                          feature_names=columns)\n#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n#     return Image(graph.create_png())","6e7425ba":"#draw_tree(model,X)","b9da7695":"y_test_inv = np.exp(y_test) - 1\ny_pred_inv = np.exp(y_pred) - 1\nnp.sqrt(mean_squared_error(y_test_inv,y_pred_inv))","63d4ed65":"r2_score(y_test_inv,y_pred_inv)","ea3a9ce9":"test.head()","4ffa567e":"pd.Series(model.feature_importances_,index=X.columns)\n","5e9919ed":"data_merged.corr()['Sales'].sort_values(ascending=False)","8a25e5d3":"stores_avg_cuts = data.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest1 = test.merge(stores_avg_cuts,\n                  on = 'Store',\n                  how = 'left')\n\ntest_merged = test1.merge(store,\n                          on='Store',\n                          how='inner')\ntest_merged['Open'] = test_merged['Open'].fillna(1) \ntest_merged['Date'] = pd.to_datetime(test_merged['Date'], format = '%Y-%m-%d')\ntest_merged['day'] = test_merged['Date'].dt.day\ntest_merged['month'] = test_merged['Date'].dt.month\ntest_merged['year'] = test_merged['Date'].dt.year","519d6aa6":"test_merged.dtypes","190d6cdf":"\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].map({'0':0,'a':1}).astype(int)\ntest_merged['StoreType'] = test_merged['StoreType'].map({'c':0, 'a':1,'d':2,'b':3}).astype(int)\ntest_merged['Assortment'] = test_merged['Assortment'].map({'a':0, 'c':1,'b':2}).astype(int)\ntest_merged['PromoInterval'] = test_merged['PromoInterval'].map({'Jan,Apr,Jul,Oct':0, 'Feb,May,Aug,Nov':1,'Mar,Jun,Sept,Dec':2}).astype(int)","55e12977":"test_merged.shape","1833c985":"test_pred = model.predict(test_merged[X.columns])\ntest_pred_inv = np.exp(test_pred) -1\nsubmission_predicted = pd.DataFrame({'Id': test['Id'], 'Sales': test_pred_inv })\nsubmission_predicted.to_csv('submission.csv',index=False)\n","742e689e":"from sklearn.model_selection import GridSearchCV","1bb98444":"# parameters = {'max_depth' : list(range(5,20))}\n# base_model = DecisionTreeRegressor()\n# cv_model = GridSearchCV(base_model, param_grid=parameters, cv=5, return_train_score=True).fit(X_train,y_train)","6daa086a":"# cv_model.best_params_","e11aa13d":"# dv_cv_results = pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score', ascending=False)\n# dv_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\n# dv_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\n# plt.legend(['Test Scores', 'Train Scores'])","3f35e9d8":"# dv_cv_results\n","b2ce5016":"# X_1 = X.drop('Customers',axis=1)","1c4c7dd0":"# test_pred = model.predict(test_merged[X_1.columns])\n# test_pred_inv = np.exp(test_pred) -1\n# submission_predicted = pd.DataFrame({'Id': test['Id'], 'Sales': test_pred_inv })\n# submission_predicted.to_csv('submission.csv',index=False)\n","bed86f77":"## Missing value","c63d0ccc":"## Encoding\n","761114b0":"### customers is an important column so we cant drop it as the column in not present in test csv[](http:\/\/)","82caca2c":"# Optimisation-1\n\n## Hyperparameter Tuning","634656d2":"## Train & Validate Split"}}