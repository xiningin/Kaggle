{"cell_type":{"dee6a272":"code","60ebf6d2":"code","2cfad867":"code","07dac82f":"code","38b46f8c":"code","422f7072":"code","7f48ba8e":"code","944d85f0":"code","42ab72a0":"code","b9e43f05":"code","7bfe26b8":"code","ee940d0b":"code","7c2cbb5a":"code","a9f35333":"code","4fbbb45b":"code","51a0d401":"code","afbcebf1":"code","5bc66a5f":"code","152e0496":"code","53b57a88":"code","efc8d033":"code","bfaaa40d":"code","353484ee":"code","e8cb8a2a":"code","2aa9887b":"markdown","31b5ef34":"markdown","1651b4a4":"markdown","541cf5b5":"markdown","da6687d0":"markdown","b0e3e768":"markdown","332bb6db":"markdown","075514fd":"markdown","90a83491":"markdown","3a17c200":"markdown","918d2eb5":"markdown","6fe50ecf":"markdown","1fe67c3e":"markdown","9ff4f33c":"markdown","3b68b4e7":"markdown","e1e6e74d":"markdown","42db0675":"markdown","1977dc49":"markdown","0e4c4adc":"markdown","170af707":"markdown","710df3ab":"markdown","37e4191c":"markdown","c797f03c":"markdown","3aa8a18c":"markdown","26cbdf24":"markdown","a2650f80":"markdown","fb8999de":"markdown","dff8b19b":"markdown","f20fd327":"markdown","fa5ad088":"markdown"},"source":{"dee6a272":"import numpy as np \nimport pandas as pd \n\n!pip install geocoder\nimport geocoder\n\nimport requests\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"white\")\n\nimport folium\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","60ebf6d2":"demographics = pd.read_csv('\/kaggle\/input\/sf-demographics-data\/SF Demographics Dataset.csv')","2cfad867":"demographics.head()","07dac82f":"demographics.info() ","38b46f8c":"demographics = demographics.fillna(0)","422f7072":"demographics['White'] = demographics['White'].astype('float64')\ndemographics['Other\/Two or More Races'] = demographics['Other\/Two or More Races'].astype('float64')\ndemographics['% Latino (of Any Race)'] = demographics['% Latino (of Any Race)'].astype('float64')","7f48ba8e":"demographics.describe()","944d85f0":"neighborhoods = demographics['Neighborhood'].to_list()\n\nlongitude = []\nlatitude = []\n\nfor neighborhood in neighborhoods:\n    \n    # initialize the variable to None\n    lat_lng_coords = None\n\n    # loop until getting the coordinates\n    while(lat_lng_coords is None):\n        g = geocoder.arcgis('{}, San Francisco, California'.format(neighborhood))\n        lat_lng_coords = g.latlng\n\n    \n    # Append the data to the lists\n    latitude.append(lat_lng_coords[0])\n    longitude.append(lat_lng_coords[1])","42ab72a0":"location = pd.DataFrame({'Neighborhood': neighborhoods, 'Latitude': latitude, 'Longitude': longitude})","b9e43f05":"location.head()","7bfe26b8":"# Setting Foursquare credentials\nCLIENT_ID = 'DASAS2TJ5QYKKAI2QZEPBF0XACCR5JAX0JL4OKNFPI1SYN0K' # your Foursquare ID\nCLIENT_SECRET = 'OXNV1ECFX2G4ZYPKP5BDAYI1OZPA1SYVZDIMCKLDSB05OEPE' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version","ee940d0b":"\"\"\"\ndef getNearbyVenues(names, latitudes, longitudes, radius=1600, LIMIT=300, categoryId='4d4b7105d754a06374d81259'):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&categoryId={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT,\n            categoryId)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)\n\nvenues = getNearbyVenues(names=location['Neighborhood'],\n                                   latitudes=location['Latitude'],\n                                   longitudes=location['Longitude']\n                                  )\"\"\"","7c2cbb5a":"venues = pd.read_csv('\/kaggle\/input\/sf-venues\/SF venues.csv')","a9f35333":"venues.groupby('Neighborhood').count()","4fbbb45b":"venue_count = venues.groupby(['Neighborhood', 'Venue Category'])['Venue'].count()\nvenue_count = venue_count.unstack()\nvenue_count = venue_count.fillna(0)","51a0d401":"venue_count.head()","afbcebf1":"plt.figure(figsize=(20,10))\nax = sns.barplot(demographics['Neighborhood'], demographics['Total Population'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.show()","5bc66a5f":"plt.figure(figsize=(10,10))\nsns.boxplot(demographics['Total Population'])\nplt.show()","152e0496":"plt.figure(figsize=(20,10))\nax = sns.barplot(demographics['Neighborhood'], demographics['Median Household Income'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.show()","53b57a88":"plt.figure(figsize=(10,10))\nsns.boxplot(demographics['Median Household Income'])\nplt.show()","efc8d033":"dem_corr = demographics.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(dem_corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(dem_corr, mask=mask, cmap=cmap, vmax=1, vmin=-1,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)","bfaaa40d":"import math\ndef get_info(venue_count, demographics):\n    neighs = []\n    infos = []\n    dem_keys = demographics.iloc[0][['Asian', 'Black\/African American', 'White', 'Native American Indian', 'Native Hawaiian\/Pacific Islander', 'Other\/Two or More Races', '% Latino (of Any Race)']].keys()\n    for i in range(len(venue_count)):\n        neigh = \"<b>\" + venue_count.iloc[i].name + \"<\/b>\"\n        message = \"\"\n        message += neigh\n        message = message + '<br>Population: ' + str(demographics['Total Population'][i])\n        message += '<br><br>Race (%):<ul> '\n        for key in dem_keys:\n            message = message + '<li>' + key + ': ' + str(demographics.iloc[i][key]) + '<\/li>' \n        message += '<\/ul>'\n        message += '<p style=\"width:200px\"><i>Most common restaurant:<\/i><\/p><ol>'\n        top_keys = venue_count.iloc[i].sort_values(ascending=False).keys()[:5]\n        top_values = venue_count.iloc[i].sort_values(ascending=False).values[:5]\n        for j in range(5):\n            message = message + '<li>' + top_keys[j] + ': ' + str(math.trunc(top_values[j])) + '<\/li>'\n        message += '<\/ol>'\n        neighs.append(neigh)\n        infos.append(message)\n    return neighs, infos","353484ee":"m = folium.Map(\n    location=[37.7749, -122.4194],\n    zoom_start=12  \n)\n\nrestaurants = folium.map.FeatureGroup()\n\nfor neighborhood, lat, lng in zip(location['Neighborhood'], location['Latitude'], location['Longitude']):\n    restaurants.add_child(\n        folium.vector_layers.CircleMarker(\n            [lat, lng],\n            radius=5, \n            color='yellow',\n            fill=True,\n            fill_color='blue',\n            fill_opacity=0.6\n        )\n    )\n\nlatitudes = list(location['Latitude'])\nlongitudes = list(location['Longitude'])\nneighs, infos = get_info(venue_count, demographics)\n\n\n\nfor lat, lng, neigh, info in zip(latitudes, longitudes, neighs, infos):\n    folium.map.Marker([lat, lng], popup=folium.map.Popup(html=info, parse_html=False, max_width='300px'), tooltip=neigh).add_to(m)    \n    \nm.add_child(restaurants)","e8cb8a2a":"m.save('map.html') ","2aa9887b":"## Mapping the Results\nWe will create the interactive map visualizing the relevant information here.\n","31b5ef34":"Let's take a quick look at the demographics dataset.","1651b4a4":"Here we use a box plot to see the distribution of median household income and whether there's any outliers.","541cf5b5":"There are total 41 neighborhoods of San Francisco in the dataset. Upon examination, we will convert all ethnicity data to floats, and fill n\/a values with 0s.\n","da6687d0":"Here we use a bar plot to visualize each neighborhood's median household income.","b0e3e768":"# Finding the Best Area to Start a Restaurant Business in San Francisco\n","332bb6db":"The line of our concern is Median Household Income vs the races. We can see that higher percentage of White household corresponds with higher median household income, while the high percentage of any other race household corresponses negatively with median household income. ","075514fd":"Let's take a quick look at the location dataframe.","90a83491":"Here we use a box plot to see the distribution of population and whether there's any outliers.","3a17c200":"Let's read the venues CSV file into Pandas dataframe.","918d2eb5":"Here we use a heatmap to visualize the correlation between features.","6fe50ecf":"Let's see what the datatype of each columns is.","1fe67c3e":"This project offers an infographic view of the demographics and restaurant competitions in each neighborhood of San Francisco. Anyone who wants to start a new restaurant in San Francisco can use the report or the interactive tool on the Jupyter Notebook as a guide to find the optimal place to start a restaurant based on the two elements. ","9ff4f33c":"Creating a Pandas dataframe containing the location information for each neighborhood.","3b68b4e7":"## Import Libraries\nHere we import the necessary libraries.\n* numpy, Pandas -- Standard Data Analytics Libraries  \n* geocoder -- Finding Location Data for Neighborhoods\n* request -- HTML Request\n* matplotlib, seaborn -- Data Visualization\n* Folium -- Creating Map\n\n","e1e6e74d":"We will perform more exploratory data analysis after compiling the restaurant data from Foursquare.","42db0675":"Each row of the CSV file is information of one restaurant. For this project's purpose, we need to group the restaurants by the Neighborhood they are in. So let's take a look at how many restaurants data we have in each neighborhood first.","1977dc49":"This is the function to get all venues near a neighborhood.","0e4c4adc":"## Exploratory Data Analysis\nAs the project is focused on creating a visualization for demographics and restaurant competition information for each neighborhood, there is less need to draw insights from the datasets by its own. But it is still quite interesting to examine them especially the demographics dataset. \n<br>\nCouple things of interest are the distribution of population, distribution of median household income, and whether there\u2019s a correlation between median household income and percentage of each race.\n","170af707":"This is a function to create the messages used in the map.","710df3ab":"In order to use the Foursquare API to find restaurant data, we need to first find the longitude and latitude for each neighborhood.","37e4191c":"Now let's convert the **venue** dataframe into **venue_count** dataframe with the columns being the amount of each type of restaurant.","c797f03c":"Let's take a look at the dataset after cleaning.","3aa8a18c":"Most of the neighborhoods have 100 data points, as the max limit set by Foursquare API is 100. ","26cbdf24":"Here we use a bar plot to visualize each neighborhood's population.","a2650f80":"## Data Acquisition and Cleaning\nThere are two datasets used in the project.\n1. The demographics by neighborhood data are from San Francisco Planning Department (https:\/\/default.sfplanning.org\/publications_reports\/SF_NGBD_SocioEconomic_Profiles\/2012-2016_ACS_Profile_Neighborhoods_Final.pdf). Relevant data have been picked out and put in a CSV file.\n2. The restaurant competition data are to be compiled from Foursquare API.\n","fb8999de":"Here we create the map with Folium.","dff8b19b":"### Demographics Dataset\nThe demographics data is available in CSV format. We will read the data into Pandas dataframe, and clean it.","f20fd327":"Now let's get restaurant data within 1 mile radius of each neighborhood's latitude and longitude. We have implemented a function **getNearbyVenues** to find the data via Foursquare API and save it to a CSV file. To avoid sending API request everytime running the notebook, we have commented out the function, and will read the information from the CSV file.","fa5ad088":"### Restaurant Competition Dataset"}}