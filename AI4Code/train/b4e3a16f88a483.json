{"cell_type":{"be64b06e":"code","9e279506":"code","b534d36d":"code","0eb1652f":"code","c9e702f2":"code","1ba4aa24":"code","aae4b233":"code","c9bee3df":"code","5efe1fc0":"code","cdc78886":"code","e9241c2c":"code","94bd0234":"code","c1e393b9":"code","04be83da":"markdown","f3d6ee13":"markdown","3724ae9c":"markdown","77a7f103":"markdown","ae02dd93":"markdown","a4789821":"markdown","124f412a":"markdown","0885435c":"markdown","9220c85b":"markdown","0c242b25":"markdown","886e7877":"markdown"},"source":{"be64b06e":"import tensorflow as tf\nimport numpy as np\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow.random import set_seed\nset_seed(2)\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport time\nimport glob\nimport random\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport cv2\nimport shutil","9e279506":"base_path = '..\/input\/alpaca-dataset-small\/dataset'\nclasses = os.listdir(base_path)\nfilepaths = []\nlabels = []\nfor c in classes:\n    flist = os.listdir(base_path + '\/' + c)\n    for f in flist:\n        fpath = os.path.join(base_path, c, f)\n        filepaths.append(fpath)\n        labels.append(c)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","b534d36d":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\ndf=pd.concat([Fseries,Lseries], axis=1)\ndf=pd.DataFrame(np.array(df).reshape(327,2), columns = ['file_paths', 'labels'])\nprint(df['labels'].value_counts())","0eb1652f":"plt.figure(figsize=(14,10))\nfor i in range(20):\n    random = np.random.randint(1,len(df))\n    plt.subplot(4,5,i+1)\n    img = df.loc[random,\"file_paths\"]\n    plt.imshow(plt.imread(img))\n    plt.title(df.loc[random, \"labels\"], size = 10, color = \"black\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","c9e702f2":"train_df, test_df = train_test_split(df, train_size=0.96, random_state=1)\ntrain_df, valid_df = train_test_split(train_df, train_size=0.96, random_state=1)\nprint(train_df.labels.value_counts())\nprint(valid_df.labels.value_counts())\nprint(test_df.labels.value_counts())","1ba4aa24":"target_size=(300,300)\nbatch_size=32","aae4b233":"train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input, zoom_range=0.2, width_shift_range=0.1, height_shift_range=0.1)\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntrain_gen = train_datagen.flow_from_dataframe(train_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\nvalid_gen = test_datagen.flow_from_dataframe(valid_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\ntest_gen = test_datagen.flow_from_dataframe(test_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')","c9bee3df":"base_model = tf.keras.applications.EfficientNetB3(include_top=False, input_shape=(300,300,3))\nmodel = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","5efe1fc0":"lr=0.001\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])","cdc78886":"patience = 2\nstop_patience = 5\nfactor = 0.5\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n]","e9241c2c":"epochs = 30\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks, verbose=1)","94bd0234":"plt.plot(history.history['loss'], label='Loss (training data)')\nplt.plot(history.history['val_loss'], label='Loss (validation data)')\nplt.title('Loss for Training')\nplt.ylabel('Loss')\nplt.xlabel('No. epoch')\nplt.legend(['train', 'validation'], loc=\"upper left\")\nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","c1e393b9":"best_model = model\nbest_model.load_weights('.\/classify_model.h5')\nbest_model.evaluate(test_gen)","04be83da":"# **Split Datatframe into Train, Validation, and Test**","f3d6ee13":"# **Predictions on Test Set**","3724ae9c":"# **Create Dataframe from Images**","77a7f103":"# **ImageDataGenerator**","ae02dd93":"# **Training**","a4789821":"# **Visualize Images**","124f412a":"Looks like we can perform zooming and  height and width shearing with ImageDataGenerator.","0885435c":"# **Callbacks**","9220c85b":"# **Import Libraries**","0c242b25":"The dataset is a little unbalanced, but not enough to where it makes sense to remove or augment images. ","886e7877":"# **EfficientNetB3-based Model**"}}