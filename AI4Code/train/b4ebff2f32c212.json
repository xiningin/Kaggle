{"cell_type":{"3a3117e0":"code","f4c2936e":"code","5d45f7fd":"code","5f42484b":"code","4c39d28c":"code","8377d835":"code","b13a92e1":"code","c6b40402":"code","a94bb7f8":"code","5867e304":"code","28f4b005":"code","831e75ec":"code","c047e878":"code","463ac050":"code","c816a296":"code","6f3317de":"code","141a2096":"code","1a360c1d":"code","f556f746":"markdown","49ac5444":"markdown","b1959628":"markdown","648ec12a":"markdown","f57d02cc":"markdown","9532e821":"markdown","4c85c93f":"markdown","b68c6281":"markdown","8766be62":"markdown"},"source":{"3a3117e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4c2936e":"#imports\nfrom sklearn.metrics import classification_report\n","5d45f7fd":"#Lets read the dataset\ndf = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","5f42484b":"df.head()\n#print(df.shape)","4c39d28c":"#Lets see all the data types\ndf.info()","8377d835":"df.isnull().sum()","b13a92e1":"#Lets tackle all the null values and impute them using mean and mode\nfor column in df:\n    if(df[column].isnull().sum()!=0):\n            if(df[column].dtype !='object'):\n                df[column].fillna(df[column].mean(),inplace=True)\n            else:\n                df[column].fillna(df[column].mode()[0],inplace=True)\n\ndf.isnull().sum()\n            ","c6b40402":"#Lets create 3 columns from date as year month and day of month\ndf['Year'] = df['Date'].apply(lambda x:int(x.split('-')[0]))\ndf['Month'] = df['Date'].apply(lambda x:int(x.split('-')[1]))\ndf['Day'] = df['Date'].apply(lambda x:int(x.split('-')[2]))\ndf = df.drop(['Date'],axis=1)","a94bb7f8":"#Lets see the categories present in all the categorical variables.\nfor column in df:\n    if(df[column].dtype == 'object'):\n        print(df[column].value_counts())","5867e304":"columns_binary =['WindDir3pm','RainToday','RainTomorrow']\nfor i in columns_binary:\n    df[i]=df[i].apply(lambda x:1 if x == 'Yes' else 0)","28f4b005":"#Lets do target encoding for 'Location','WindGustDir','WindDir9am','WindDir3pm':\ncolumns_target_encoding = ['Location','WindGustDir','WindDir9am','WindDir3pm']\nfor i in columns_target_encoding:\n    encoding = df.groupby(i)['RainTomorrow'].mean().reset_index()\n    newname = i + \"new\"\n    encoding.rename(columns={\"RainTomorrow\":newname},inplace=True)\n    df = df.merge(encoding, how='left', on=i)\ndf.drop(columns_target_encoding,axis=1,inplace=True)","831e75ec":"#Lets see the final dataframe\ndf.head()","c047e878":"#Creating target variable and explanatory features\nX_res = df.drop(['RainTomorrow'],axis=1)\nY_res = df['RainTomorrow']","463ac050":"#Lets see the class distribution\ndf['RainTomorrow'].value_counts()[0]\/df['RainTomorrow'].value_counts()[1]\n#Since the distribution is non uniform we need to do sampling","c816a296":"from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\nX, Y = rus.fit_resample(X_res, Y_res)","6f3317de":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n","141a2096":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\n","1a360c1d":"from sklearn.metrics import accuracy_score\ny_predict = rf.predict(X_test)\nprint(classification_report(y_test, y_predict, target_names=[\"Yes\",\"No\"]))\n","f556f746":"# DATA MODELLING","49ac5444":"To handle non binary categorical variables , we can apply target encoding.","b1959628":"***DATE***","648ec12a":"***Location***","f57d02cc":"All the binary variables can be converted to numerical using binary encoding","9532e821":"***HANDLING NULL VALUES***","4c85c93f":"Lets take a glimpse of how the dataset looks like.","b68c6281":"# DATA CLEANING","8766be62":"# DATA ENCODING"}}