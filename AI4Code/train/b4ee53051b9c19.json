{"cell_type":{"31ef581d":"code","7568bc21":"code","4ae9769a":"code","1b8d1936":"code","9b9c4271":"code","0d24e453":"code","d0ab3788":"code","8a57fa68":"code","c40b8fa2":"code","ba656191":"code","2f9ce427":"code","210ec639":"code","258bad3d":"markdown","eeebcba2":"markdown","0d7476e7":"markdown","267c5aac":"markdown","2e2e5963":"markdown","a0704ee1":"markdown","7bac1939":"markdown","b34930e7":"markdown"},"source":{"31ef581d":"import torch\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport shutil\nfrom itertools import chain\n\nfrom PIL import Image\nimport glob\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport copy\nimport wandb\nimport re\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torchvision\n\nfrom torch.utils.data import DataLoader, Dataset","7568bc21":"class CIFAR100dataset(Dataset):\n    def __init__(self, path, transforms=None):\n        self.paths = glob.glob(os.path.join(path, '*'))\n        self.transforms = transforms\n        self.n_class = 100\n        \n    def __getitem__(self, index):\n        image_path = self.paths[index]\n        target = int(re.findall(r'_\\d{2}', image_path)[0][1:])\n        \n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        else:\n            image = torch.tensor(image, dtype=torch.float32)\n        target = torch.as_tensor(target, dtype=torch.int64)\n        return image, target\n        \n    def __len__(self):\n        return len(self.paths)","4ae9769a":"# folder = []\n# for i in os.walk('..\/input\/imagenetmini-1000\/imagenet-mini\/train'): # ..\/input\/imagenetmini-1000\/imagenet-mini\/train\n#     folder.append(i)\n#     break\n# \n# _, train, _ = folder[0]\n# folder = []\n# for i in os.walk('..\/input\/imagenetmini-1000\/imagenet-mini\/val'): # ..\/input\/imagenetmini-1000\/imagenet-mini\/train\n#     folder.append(i)\n#     break\n# _, val, _ = folder[0]\n# train = sorted(train)\n# val = sorted(val)","1b8d1936":"\ndataset = CIFAR100dataset('..\/input\/cifar100-256x256\/cifar100-preprocessed\/train')\nval = CIFAR100dataset('..\/input\/cifar100-256x256\/cifar100-preprocessed\/test')\ndef visualize(dataset):\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(20,10))\n    axes = ax.ravel()\n    for i, (X, y) in enumerate(dataset):\n        if i < len(axes):\n            axes[i].imshow(X)\n            axes[i].set_title(y)\n            axes[i].axis('off')\n        else:\n            break\n\nvisualize(dataset)","9b9c4271":"visualize(val)","0d24e453":"def arc_loss(m=0.5, s=50.0):\n    def criterion(X, y):\n        original_target_logit = torch.gather(X, dim=1, index=y.view(-1,1))\n        theta = torch.acos(original_target_logit.clip(-1+1e-7, 1-1e-7))\n        marginal_target_logit = torch.cos(theta + m)\n        one_hot = F.one_hot(y, num_classes = output_classes)\n        X = X + torch.mul(one_hot, marginal_target_logit - original_target_logit)\n        logits = X * s\n        out = F.cross_entropy(logits, y)\n        return out\n    return criterion\n\nclass ArcFaceClassifier(torch.nn.Module):\n    def __init__(self, emb_size, output_classes):\n        super().__init__()\n        self.W = nn.Parameter(torch.Tensor(output_classes, emb_size))\n        torch.nn.init.kaiming_uniform_(self.W)\n        \n    def forward(self, X, y):\n        # x.shape = (batch, emb_size) - features from backbone\n        # y.shape = (batch, )\n        X_norm = F.normalize(X)\n        W_norm = F.normalize(self.W)\n        fc = F.linear(X_norm, W_norm, bias=None)\n        # fc.shape = (batch, output_classes)\n        return fc\n\nclass ModResNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = torchvision.models.resnet34(pretrained=True)\n        self.flat = torch.nn.Sequential(\n            *list(backbone.children())[:-1],\n            torch.nn.Flatten()\n        )\n        for p in self.flat.parameters():\n            p.requires_grad_(False)\n        # self.emb = nn.Linear(512, 512)\n    def forward(self, x):\n        x = self.flat(x)\n        x = self.emb(x)\n        return x\n        ","d0ab3788":"train_transforms = A.Compose(\n    [\n        # A.Resize(256, 256),\n        # A.RandomCrop(224, 224),\n        A.Resize(224, 224),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\n\nval_transforms = A.Compose(\n    [\n        # A.Resize(256, 256),\n        # A.RandomCrop(224, 224),\n        A.Resize(224, 224),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\n# train_dataset = LFWdataset('.\/lfw_funneled', transforms=train_transforms)\ntrain_dataset = CIFAR100dataset('..\/input\/cifar100-256x256\/cifar100-preprocessed\/train', transforms=train_transforms)\nval_dataset = CIFAR100dataset('..\/input\/cifar100-256x256\/cifar100-preprocessed\/test', transforms=val_transforms)","8a57fa68":"train_loader = DataLoader(\n        train_dataset,\n        batch_size=16,\n        shuffle=True,\n        pin_memory=True,\n    )\n\nval_loader = DataLoader(\n        val_dataset,\n        batch_size=16,\n        shuffle=False,\n        pin_memory=True,\n    )","c40b8fa2":"emb_size = 512\n#emb_size = 2048\noutput_classes = train_dataset.n_class\nm=0.5\ns=50.0\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = ModResNet()\nmodel.to(device)\narcface = ArcFaceClassifier(emb_size, output_classes)\narcface.to(device)\n\nepochs = 50 + 1\nlr = 1e-2  # initial learning rate\nlr_steps = [2, 10, 20, 30, 40, 50]\n# lr_step = 10\n#lr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\nweight_decay = 5e-4\n\n# optimizer = torch.optim.SGD([{'params': model.parameters()}, {'params': arcface.parameters()}],\n#                                      lr=lr, weight_decay=weight_decay)\noptimizer = torch.optim.SGD(chain(model.parameters(), arcface.parameters()),\n                                     lr=lr, weight_decay=weight_decay)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=0.1, verbose=True)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_steps, gamma=0.1, verbose=True)\n# criterion = torch.nn.CrossEntropyLoss()\ncriterion = arc_loss(m=m, s=s)","ba656191":"# print('Freeze backbone')\n# for p in model.parameters():\n#     p.requires_grad_(False)\nfor epoch in range(1, epochs):\n    model.train()\n    arcface.train()\n    for batch_n, (X, y) in enumerate(train_loader):\n        X, y = X.to(device), y.to(device)\n        feature = model(X)\n        output = arcface(feature, y)\n        loss = criterion(output, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n    if epoch == 2:\n        print('Unfreeze all')\n        for p in model.parameters():\n            p.requires_grad_(True)\n    print('train epoch {} iter {} loss {} '.format(epoch, batch_n,  loss.item()))\n    model.eval()\n    arcface.eval()\n    out = []\n    lbl = []\n    for X, y in val_loader:\n        X, y = X.to(device), y.to(device)\n        feature = model(X)\n        output = arcface(feature, y)\n        output = output.data.cpu().numpy()\n        output = np.argmax(output, axis=1)\n        label = y.data.cpu().numpy()\n        out.append(output)\n        lbl.append(label)\n    out = np.concatenate(out)\n    lbl = np.concatenate(lbl)\n    print(\"out\", out)\n    print(\"lbl\", lbl)\n    acc = np.mean((out == lbl).astype(int))\n    print('mean_acc {}'.format(acc))","2f9ce427":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = torchvision.models.resnet34(pretrained=True)\nfor p in model.parameters():\n    p.requires_grad_(False)\nmodel.fc = nn.Linear(512, 100)\nmodel.to(device)\n\nepochs = 50 + 1\nlr = 1e-2  # initial learning rate\nlr_step = 10\n#lr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\nweight_decay = 5e-4\n\noptimizer = torch.optim.SGD([{'params': model.parameters()}],\n                                     lr=lr, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=0.1, verbose=False)\ncriterion = torch.nn.CrossEntropyLoss()","210ec639":"for epoch in range(1, epochs):\n    model.train()\n    for batch_n, (X, y) in enumerate(train_loader):\n        X, y = X.to(device), y.to(device)\n        output = model(X)\n        #output = arcface(feature, y)\n        loss = criterion(output, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n    if epoch == 2:\n        print('Unfreeze all')\n        for p in model.parameters():\n            p.requires_grad_(True)\n    print('train epoch {} iter {} loss {} '.format(epoch, batch_n,  loss.item()))\n    model.eval()\n    out = []\n    lbl = []\n    for X, y in val_loader:\n        X, y = X.to(device), y.to(device)\n        output = model(X)\n        #output = arcface(feature, y)\n\n        output = output.data.cpu().numpy()\n        output = np.argmax(output, axis=1)\n        label = y.data.cpu().numpy()\n        out.append(output)\n        lbl.append(label)\n    out = np.concatenate(out)\n    lbl = np.concatenate(lbl)\n    print(\"out\", out)\n    print(\"lbl\", lbl)\n    acc = np.mean((out == lbl).astype(int))\n    print('mean_acc {}'.format(acc))","258bad3d":"# Make dataset","eeebcba2":"![arcface](https:\/\/i.ibb.co\/mDFvbFt\/arc.jpg)","0d7476e7":"# Make model and classifier","267c5aac":"# Just Resnet34","2e2e5963":"### \u0415\u0441\u043b\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u043e\u0441\u0442\u043e Resnet34 \u0441 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u043c \u0441\u043b\u043e\u0435\u043c \u0438 \u043a\u0440\u043e\u0441\u044d\u043d\u0442\u0440\u043e\u043f\u0438\u0435\u0439, \u0442\u043e \u0442\u0430\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c 0.8","a0704ee1":"# Visualize","7bac1939":"## \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u0448\u0435 0.01 \u043d\u0435 \u0440\u0430\u0441\u0442\u0435\u0442, \u043f\u043e\u0447\u0435\u043c\u0443?","b34930e7":"### \u041d\u0438\u0436\u0435 \u044f \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u044e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0438\u0437 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u0441\u0442\u0430\u0442\u044c\u0438"}}