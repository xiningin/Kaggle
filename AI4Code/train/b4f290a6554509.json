{"cell_type":{"2a35727b":"code","33a19e9e":"code","ea02620c":"code","81390470":"code","152d8fe8":"code","974ff3ee":"code","22da3a36":"code","c657fe8d":"code","0dfdef9b":"code","4b01e34f":"code","95ebc69a":"code","6f31083d":"code","2290b588":"code","31dfc5a2":"code","56673d82":"code","29bc7b35":"code","adf9da4d":"code","4749c0f7":"code","b064e6a0":"code","1380bf72":"code","3196bb20":"code","68dcefc2":"code","43a79dbc":"code","4e127c31":"code","2228fe08":"code","d568520c":"code","ddefc69a":"code","b374985f":"markdown","908b2d2a":"markdown","d06d53e6":"markdown","3848b38d":"markdown","121ccf1a":"markdown","4712ea29":"markdown","86673559":"markdown","207aa4b0":"markdown","dc4b44a6":"markdown","d2ced3fe":"markdown","aa5c608f":"markdown","1b2e612f":"markdown","6132a7d2":"markdown","389be38f":"markdown","30edef18":"markdown","9956e1d7":"markdown","d11783d5":"markdown"},"source":{"2a35727b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#Library for Mathemtical Computation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Library for Modelling \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error \n\n#Libraries for Deep Learning\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten\n\n#Library for Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33a19e9e":"#Loading data into training and testing sets\ntrain_data=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","ea02620c":"#Displaying Training Data\ntrain_data.head()","81390470":"#Displaying Test Data\ntest_data.head()","152d8fe8":"#Displaying Metadata\/Information about Training Data\ntrain_data.info()","974ff3ee":"#Displaying Stats on Training Data\ntrain_data.describe()","22da3a36":"#Changing Negative numbers into Positive\ntrain_data['item_price']=train_data['item_price'].abs()\ntrain_data['item_cnt_day']=train_data['item_cnt_day'].abs()","c657fe8d":"#Checking if the training data has any Null values or not\nnull_percent=100*(train_data.isnull().sum()\/len(train_data))\nprint(null_percent)","0dfdef9b":"#Grouping item price and item count per month\ntrain_data=train_data.groupby(['date_block_num','shop_id','item_id']).agg({'item_price':'last','item_cnt_day':'sum'}).reset_index()\n#Changing the name of the item_cnt_day to item_cnt_month\ntrain_data=train_data.rename(columns={'item_cnt_day':'item_cnt_month'})\nprint(train_data)","4b01e34f":"#Calculating Correlation\ncorrelation=train_data.corr()\n\n#Plotting correlation\nplt.figure(figsize=(12,12))\ncorr_heatmap=sns.heatmap(correlation,annot=True,cmap=\"GnBu\")","95ebc69a":"#Adding date_block_num to the Test data\ntest_data['date_block_num']=34\ntest_data=test_data[['date_block_num','shop_id','item_id']]\nprint(test_data)","6f31083d":"#Adding the latest item price from the training data into test data into their respective item id\nitem_price=dict(train_data.groupby('item_id')['item_price'].last().reset_index().values)\ntest_data['item_price']=test_data.item_id.map(item_price)\nprint(test_data)","2290b588":"#Replacing Missing Value with median price\nprint(test_data['item_price'].unique())\ntest_data['item_price']=test_data['item_price'].fillna(test_data['item_price'].median())\ntest_data['item_price']","31dfc5a2":"#allocating training data into X and y training sets\nx_train=train_data.drop('item_cnt_month',axis=1)\ny_train=train_data[\"item_cnt_month\"]\nx_test=test_data\nx_train.shape,y_train.shape","56673d82":"#Training the model\nlinear_model=LinearRegression()\nlinear_model.fit(x_train,y_train)","29bc7b35":"#Testing the model\nlinear_prediction=linear_model.predict(x_test)","adf9da4d":"#output is the predicted cnt_per_month\nprint(linear_prediction)","4749c0f7":"#Buliding Model in Random Forest Regressor\nrr_model=RandomForestRegressor(n_estimators=50)\nrr_model.fit(x_train,y_train)","b064e6a0":"#Testing the model\nrr_predict=rr_model.predict(x_test)\nprint(rr_predict)","1380bf72":"#Building the Model in Lasso Regression Model\nlasso_model=Lasso(alpha=1.0)\nlasso_model.fit(x_train,y_train)\n\n#Testing the Model\nlasso_predict=lasso_model.predict(x_test)\nprint(lasso_predict)","3196bb20":"#Building the model in Ridge Regression Model\nr_model=Ridge(alpha=1.0)\nr_model.fit(x_train,y_train)\n\n#Testing the model\nr_predict=r_model.predict(x_test)\nprint(r_predict)","68dcefc2":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    NN_model = Sequential()\n    # The Input Layer :\n    NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x_train.shape[1], activation='relu'))\n\n# The Hidden Layers :\n    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n\n# The Output Layer :\n    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n# Compile the network :\n    NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])","43a79dbc":"checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]","4e127c31":"NN_model.fit(x_train, y_train, epochs=500, batch_size=268435456 * tpu_strategy.num_replicas_in_sync, validation_split = 0.2, callbacks=callbacks_list)","2228fe08":"DNN_predict=NN_model.predict(x_test)\n\nprint(DNN_predict)","d568520c":"#Creating Dataframe to Display the output, The Id is the item id from the test data and output is the predicted cnt_per_month\nsample_submission= pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nsample_submission.item_cnt_month=DNN_predict[:,0]\nDNN_result=sample_submission\nprint(DNN_result)","ddefc69a":"DNN_result.to_csv(\"Sales_Prediction.csv\",index=False)\nprint(\"Completed\")","b374985f":"# Saving the Output in CSV file","908b2d2a":"**Define a checkpoint callback**","d06d53e6":"**Ridge Regression**","3848b38d":"**Correlation is a good way to find whether the data columns have linear relationship with item_cnt_day or not. If the correlation value is closer to one, then the data columns are positively related.**","121ccf1a":"**Training Model**","4712ea29":"**Lasso Regression**","86673559":"**Building Model**","207aa4b0":"Here, it could be noticed that item_price and item_cnt_day consist of Negative Numbers. These values should be changed into positive because as the value is in negative it does not make any sense, item price being in negative.","dc4b44a6":"**Random Forest Regression**","d2ced3fe":"# Data Manipulation","aa5c608f":"**Preparing Training Data**","1b2e612f":"# Deep Learning","6132a7d2":"As the item count per month is to be predicted, item_cnt_day will be converted to item_cnt_mnt","389be38f":"# Preparing for Modelling","30edef18":"# Training the Model","9956e1d7":"**Linear Regression**","d11783d5":"# Preparing Test Data\n\nAs Test data only consists of two data columns shop_id and item_id, other data columns like date_block_num and item price should be added."}}