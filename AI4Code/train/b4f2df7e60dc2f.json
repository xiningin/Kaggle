{"cell_type":{"6e1e0d51":"code","d6475eaa":"code","feda38ba":"code","f332360a":"code","7fd01e6c":"code","4acc68c9":"code","15501e6e":"code","c2975801":"code","07b7c3ee":"code","0e16376a":"code","5d698061":"code","2e81ef2b":"code","c33bc807":"code","6a2ecaf3":"code","e916eea6":"code","6131aa48":"code","bd3e25d3":"code","1a2fa73c":"code","b6ad7457":"markdown","0643f725":"markdown"},"source":{"6e1e0d51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6475eaa":"df = pd.read_csv('\/kaggle\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv' )\ndf.dropna(inplace  = True)\nprint(df)","feda38ba":"from datetime import datetime\ndf.drop(columns = ['Weighted_Price'] , inplace = True)\n\ndf['Timestamp'] = df['Timestamp'].apply(datetime.fromtimestamp)\ndf.set_index('Timestamp' , inplace = True)\ndf.sort_index(inplace = True)\n","f332360a":"df = df.iloc[3500000: , :]","7fd01e6c":"def data_treat(df , shift_days  , window ):\n    #####the labels are from minutes later\n    df['target'] = df['Close'].shift(-shift_days)\n    df.dropna(inplace = True)\n    df\n    ###\n    x = df.iloc[:,:-1]\n    y = df.iloc[: ,-1]\n    from sklearn.preprocessing import MinMaxScaler\n\n    ###standardlize\n    scaler = MinMaxScaler()\n    x = scaler.fit_transform(x)\n    from collections import deque\n    deq = deque(maxlen = window)\n\n    ###transform x into input of LSTM\n    train_x = []\n    for i in list(x):\n        deq.append(list(i))\n\n        if len(deq)==window:\n            train_x.append(list(deq))\n\n    train_x_last = train_x[-shift_days:]\n    train_x = train_x[:-shift_days]\n    train_y = y.values[window-1:-shift_days]\n    X = np.array(train_x)\n    Y = np.array(train_y)\n\n    from sklearn.model_selection import train_test_split\n    X_train , X_test , y_train , y_test = train_test_split(X , Y , test_size = 0.1 ,shuffle = False )\n\n\n    return X_train , X_test , y_train , y_test","4acc68c9":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM ,Dense ,GRU, Dropout , BatchNormalization\nfrom tensorflow.keras import regularizers\n","15501e6e":"X_train , X_test , y_train , y_test = data_treat(df , 2 , 7)","c2975801":"def get_model(wd):\n    model = Sequential(\n    [\n        LSTM(64 , kernel_regularizer = regularizers.l2(wd),input_shape =X_train.shape[1:] , activation = 'relu' , return_sequences = True ),\n        \n        Dropout(0.3),\n        LSTM(64 ,kernel_regularizer = regularizers.l2(wd) , activation = 'relu' , return_sequences = True ),\n        \n        Dropout(0.3),\n        GRU(64 ,kernel_regularizer = regularizers.l2(wd) , activation = 'relu' , return_sequences = True ),\n        \n        Dropout(0.2),\n        GRU(64 ,kernel_regularizer = regularizers.l2(wd) , activation = 'relu' , return_sequences = True ),\n        \n        Dropout(0.2),\n        \n        \n        \n        LSTM(32,kernel_regularizer = regularizers.l2(wd)  , activation = 'relu' , return_sequences = False ),\n        \n       \n        Dropout(0.3),\n        \n        \n        \n        \n        Dense(1)\n    ]\n)\n    model.compile(optimizer ='adam' ,loss = 'mse' , metrics = ['mape'])\n    return model \n","07b7c3ee":"model = get_model(1e-5)","0e16376a":"model.summary()","5d698061":"\nX_train.shape[1:]\n","2e81ef2b":"def get_callbacks():\n\n    callbacks1 = tf.keras.callbacks.EarlyStopping(patience = 30 , monitor = 'val_mape' , mode = 'min')\n    callbacks2 = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.2 , patience =30)\n    callback  = [callbacks1 , callbacks2]\n    return callback","c33bc807":"early_stopping, learning_rate_reduction = get_callbacks()","6a2ecaf3":"history = model.fit(X_train , y_train ,batch_size =256 ,epochs = 50 , validation_split = 0.15 , verbose = 1   , callbacks = [early_stopping , learning_rate_reduction])","e916eea6":"pred_y = model.predict(X_test)","6131aa48":"model.evaluate(X_train , y_train)","bd3e25d3":"import matplotlib.pyplot as plt\ny_index = list(range(len(pred_y)))\nplt.plot( y_index ,  pred_y  , color = 'red')\n\nplt.plot(y_index , y_test)\nplt.show()","1a2fa73c":"pred_y = model.predict(X_train)\ny_index = list(range(len(pred_y)))\nplt.plot( y_index ,  pred_y  , color = 'red')\n\nplt.plot(y_index , y_train)\nplt.show()","b6ad7457":"I only use 100k rows for the first trial to save running time.\n","0643f725":"For this notebook , I tend to use 'Open' , 'High' , 'Low' , 'Volume_(BTC)' ,'Volume_(Currency)' to predict the price of three  minutes later "}}