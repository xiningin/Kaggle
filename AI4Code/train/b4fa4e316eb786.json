{"cell_type":{"33886250":"code","e6893563":"code","898fb983":"code","ab651f47":"code","cfdf8958":"code","6880d8d9":"code","aab8193a":"code","747cdc58":"code","acccd9c6":"code","cfea6f2f":"code","6103df7a":"code","2cc1a6b7":"code","6856b27b":"code","9889ab89":"code","10e0d580":"code","07b704e1":"code","2e5f4d9f":"code","a4814b73":"code","5860629f":"code","db594249":"code","cd8696aa":"code","fad2b76d":"code","c483f416":"code","12b0f78d":"code","c9620fb4":"code","c6cf8956":"code","b5e53a2d":"code","84feb427":"code","8766492b":"markdown","4eeb3f48":"markdown","09809320":"markdown","7d123f38":"markdown","1deb453f":"markdown","6512f66c":"markdown","18c53383":"markdown","cb0ec615":"markdown","7441b224":"markdown","c52fb609":"markdown","d089a7aa":"markdown","04485661":"markdown","c4e88e54":"markdown","91aee4b8":"markdown","051f4ab9":"markdown","6bc0ee12":"markdown","e8ca1b4a":"markdown"},"source":{"33886250":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualisation\nimport matplotlib.pyplot as plt #data visualisation\nimport warnings  #Filter warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Reference for dataset files\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n","e6893563":"#Reading the dataset, creating a DataFrame from Admission_Predict.csv\ndf = pd.read_csv('..\/input\/Admission_Predict.csv')\ndf.head()","898fb983":"#Removing Serial No. column from our DataFrame\ndf.drop(columns=['Serial No.'],inplace=True)\ndf.head()","ab651f47":"df.info(),\nprint(\"Shape\",df.shape) #shape of dataset => (400,8)","cfdf8958":"df.describe() #statistical inferences","6880d8d9":"df.isnull().sum() #To check missing values without using describe()\n#columns depict no missing count","aab8193a":"#Data Visualisation\n#Comparing every feature with the target variable\nplt.figure(figsize=(17,7))\nsns.scatterplot(df['CGPA'],df['Chance of Admit '],hue=df['Chance of Admit '])","747cdc58":"plt.figure(figsize=(17,7))\nsns.scatterplot(df['GRE Score'],df['Chance of Admit '],hue=df['Chance of Admit '])","acccd9c6":"plt.figure(figsize=(17,7))\nsns.scatterplot(df['TOEFL Score'],df['Chance of Admit '],hue=df['Chance of Admit '])","cfea6f2f":"plt.figure(figsize=(17,7))\nsns.barplot(df['University Rating'],df['Chance of Admit '])","6103df7a":"plt.figure(figsize=(17,7))\nsns.barplot(df['SOP'],df['Chance of Admit '])","2cc1a6b7":"plt.figure(figsize=(17,7))\nsns.barplot(df['LOR '],df['Chance of Admit '])","6856b27b":"#Finding out how features are correlated to each other in our data\ncorr = df.corr()\nsns.heatmap(corr,annot=True,cmap='Blues') #creates a heatmap that tells the correlation among all the features","9889ab89":"#Comparing these potential features among each others\nplt.figure(figsize=(17,7))\nsns.scatterplot(df['GRE Score'],df['TOEFL Score'],hue=df['University Rating'],palette=['red','blue','green','yellow','purple'])","10e0d580":"plt.figure(figsize=(17,7))\nsns.scatterplot(df['GRE Score'],df['CGPA'],hue=df['University Rating'],palette=['red','blue','green','yellow','purple'])","07b704e1":"plt.figure(figsize=(17,7))\nsns.scatterplot(df['CGPA'],df['TOEFL Score'],hue=df['University Rating'],palette=['red','blue','green','yellow','purple'])","2e5f4d9f":"#Reading Test dataset\ntestdf = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv',skiprows=400) #skipping first 400 rows\ntest_org = testdf.copy() #reserve original test DataFrame\ntestdf.columns=['Serial No.','GRE Score','TOEFL Score','University Rating','SOP','LOR','CGPA','Research','Chance of Admit']\ntestdf.drop(testdf[['Serial No.','Chance of Admit']],axis=1,inplace=True) #drop Serial No., and Chance of Admit\ntestdf.head()","a4814b73":"#Preparing data for our model\nx = df.iloc[:,:-1].values\ny = df.iloc[:,7].values\ntestX = testdf.iloc[:,:].values\ntestY = test_org.iloc[:,8].values","5860629f":"#Importing libraries\nfrom sklearn.preprocessing import StandardScaler #Feature Scaling\nscaler = StandardScaler()\nx = scaler.fit_transform(x)\ntestX = scaler.fit_transform(testX)","db594249":"#Importing Linear Regression model from sklearn\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(x,y)  #Fitting training data","cd8696aa":"#Prediction on test data\npredict = regressor.predict(testX)\nregressor.score(x,y)","fad2b76d":"#Checking mean squared error\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\nmse = mean_squared_error(predict,testY)\nmae = mean_absolute_error(predict,testY)\nmsle = mean_squared_log_error(predict,testY)\nprint(\"mean_squared_error : %f\\nmean_absolute_error : %f\\nmean_squared_log_error : %f\"%(mse,mae,msle))","c483f416":"from sklearn.tree import DecisionTreeRegressor\ntreeRegressor = DecisionTreeRegressor(criterion='mse',random_state=0,max_depth=6)\ntreeRegressor.fit(x,y)","12b0f78d":"predict = treeRegressor.predict(testX)\ntreeRegressor.score(x,y)","c9620fb4":"mse = mean_squared_error(predict,testY)\nmae = mean_absolute_error(predict,testY)\nmsle = mean_squared_log_error(predict,testY)\nprint(\"mean_squared_error : %f\\nmean_absolute_error : %f\\nmean_squared_log_error : %f\"%(mse,mae,msle))","c6cf8956":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=110,criterion='mse',max_depth=6,random_state=0)\nrf.fit(x,y)","b5e53a2d":"predict = rf.predict(testX)\nrf.score(x,y)","84feb427":"mse = mean_squared_error(predict,testY)\nmae = mean_absolute_error(predict,testY)\nmsle = mean_squared_log_error(predict,testY)\nprint(\"mean_squared_error : %f\\nmean_absolute_error : %f\\nmean_squared_log_error : %f\"%(mse,mae,msle))","8766492b":"So we have two file in the input repository which are <strong>Admission_Predict.csv<\/strong> and <strong>Admission_Predict_Vert1.1.csv<\/strong>\n\n<ul><li><strong>Admission_Predict.csv<\/strong> is the main dataset that we are going to clean, explore and perform some visualisation on, so to prepare it for training our Machine Learning model.<\/li>\n    <li><strong>Admission_Predict_Vert1.1.csv<\/strong> is the testing data that we are going to use for testing the model's performance, how good our model generalize.<\/li><\/ul>","4eeb3f48":"Now we are good to go, let's see the variety of datatypes in our data","09809320":"It can be seen in the above visualisation, the more you have the GRE Score the chances are higher of a student of getting into Grad School.","7d123f38":"<h1>Graduate Admissions<\/h1>\n<b>  We will be doing predictive modelling for Graduate Admissions dataset. Predicting what are the chances of a student of getting   admission into a Graduate school based on the given features in the dataset.<\/b><br>\n<b>The skills covering are as follows:<b>\n           1. Data Cleaning\n           2. Exploratory Data Analysis\n           3. Data Visualisation\n           4. Machine Learning","1deb453f":"From above information, we can understand that we have no missing values in our data.<br>\n<b>describe()<\/b> provides statistical information about our data such as mean, standard deviation and more.","6512f66c":"The Decision Regression model shows an accuracy of about 88.9% with maximum depth of tree as 6 on training data which is quite good. After testing we got cost values:\n<ul><li>mean_squared_error : 0.004924<\/li>\n    <li>mean_absolute_error : 0.051753<\/li>\n    <li>mean_squared_log_error : 0.001858<\/li><\/ul>","18c53383":"<h2>Decision Tree<\/h2>","cb0ec615":"<h2>Random Forest<\/h2>","7441b224":"Features like CGPA, GRE Score, and TOEFL Score plays a very dominant role in determining chance of  admit.","c52fb609":"The Linear Regression model shows an accuracy of about 80.35% on training data which is quite good. After testing we got cost values:\n<ul><li>mean_squared_error : 0.002002<\/li>\n    <li>mean_absolute_error : 0.034729<\/li>\n    <li>mean_squared_log_error : 0.000758<\/li><\/ul>","d089a7aa":"<h3>Importing necessary Python libraries<\/h3>","04485661":"CGPA plays a very important role, there higher chances if the your CGPA is high, the chance of admission is pretty solid.","c4e88e54":"I am going to prepare data for testing, as I told you that we are going to use <b>Admission_Predict_Ver1.1.csv<\/b>. But if you will look at the data, it contains the first 400 rows same as we have in our training data, so we will retrieve the last 100 rows from this data.","91aee4b8":"As you can see the Random Forest Regressor outperform the Linear Regression and Decision Tree with better score :\nAfter testing we got cost values:\n<ul><li>mean_squared_error : 0.002548<\/li>\n    <li>mean_absolute_error : 0.035929<\/li>\n    <li>mean_squared_log_error : 0.000975<\/li><\/ul>","051f4ab9":"As we can we have various features in our dataset like Serial No., GRE Score, TOEFL Score, University Rating, and more. The last column is our target, and the rest are the features we are going to use for our prediction.<br>\n<b>But do you think a Serial No. can have any effect on our target value ?<\/b><br>\nThere is no significance of this column in our data, so we will clean our data, removing Serial No. column.","6bc0ee12":"<h1>Building Machine Learning Model<\/h1>","e8ca1b4a":"<h2>Linear Regression<\/h2>"}}