{"cell_type":{"5940868f":"code","086fdc13":"code","84762626":"code","c8b117c1":"code","04e107c5":"code","14db8403":"code","af879167":"code","fb18e678":"code","08bf398d":"code","36efe90f":"code","6bb469eb":"code","2825d17a":"code","4b5e4fda":"code","baa1ba2f":"code","c7856153":"code","67c133a0":"code","2193c8ea":"code","e2fc004d":"code","a7f01659":"code","22d9c14e":"code","41c71a8a":"code","1bd45166":"code","e1fd992f":"code","bbc83f6f":"code","442d9e1b":"code","ba3e8007":"markdown","c256d9ed":"markdown","ea288b42":"markdown","ed09ab35":"markdown","3db253cd":"markdown","5ed113a7":"markdown","e1b4daa5":"markdown","51397169":"markdown"},"source":{"5940868f":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\nfrom pprint import pprint\n\nfrom sklearn.metrics import auc, roc_curve, plot_roc_curve\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import ComplementNB\n\nimport gc\nimport string\nimport re","086fdc13":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","84762626":"print('train shape:', train.shape)\nprint('test shape:', test.shape)","c8b117c1":"train.head()","04e107c5":"test.head()","14db8403":"train['keyword'].fillna('', inplace=True)\ntrain['location'].fillna('', inplace=True)\n\n\ntest['keyword'].fillna('', inplace=True)\ntest['location'].fillna('', inplace=True)","af879167":"train['final_text'] = train['keyword'] + ' ' + train['text'] + ' ' + train['location']\ntest['final_text'] = test['keyword'] + ' ' + test['text'] + ' ' + test['location']","fb18e678":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\n\ndef remove_html(text):\n    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n    return re.sub(html, '', text)\n\n\ndef remove_punct(text):\n    table = str.maketrans('', '', string.punctuation)\n    return text.translate(table)","08bf398d":"train['final_text'] = train['final_text'].apply(lambda x: remove_URL(x))\ntrain['final_text'] = train['final_text'].apply(lambda x: remove_html(x))\ntrain['final_text'] = train['final_text'].apply(lambda x: remove_punct(x))\n\ntest['final_text'] = test['final_text'].apply(lambda x: remove_URL(x))\ntest['final_text'] = test['final_text'].apply(lambda x: remove_html(x))\ntest['final_text'] = test['final_text'].apply(lambda x: remove_punct(x))","36efe90f":"count_vectorizer = CountVectorizer()","6bb469eb":"train_vectors = count_vectorizer.fit_transform(train[\"final_text\"])","2825d17a":"test_vectors = count_vectorizer.transform(test[\"final_text\"])","4b5e4fda":"y = train['target']","baa1ba2f":"del train, test\ngc.collect()","c7856153":"X_train, X_test, y_train, y_test = train_test_split(\n    train_vectors.toarray(), y, test_size=0.33, random_state=42)","67c133a0":"del train_vectors\ngc.collect()","2193c8ea":"clf = ComplementNB()","e2fc004d":"clf.fit(X_train, y_train)","a7f01659":"del X_train, y_train\ngc.collect()","22d9c14e":"pred = clf.predict(X_test)","41c71a8a":"fpr, tpr, thresholds = roc_curve(y_test, pred)\nprint(auc(fpr, tpr))\n\nplot_roc_curve(clf, X_test, y_test)\nplt.show()","1bd45166":"del X_test, y_test\ngc.collect()","e1fd992f":"y_pred = clf.predict(test_vectors.toarray())","bbc83f6f":"data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\ndata['target'] = y_pred\ndf = pd.DataFrame(data=data)\ndf.head()","442d9e1b":"df.to_csv('submission.csv', index=False)","ba3e8007":"Dealing with missing data","c256d9ed":"# Exporting predictions to appropriate submission format","ea288b42":"# Using Complement Naive Bayes Classifier","ed09ab35":"# Measuring performance","3db253cd":"# Applying vectorization to our data","5ed113a7":"Cleaning the text ","e1b4daa5":"# Data preprocessing","51397169":"# Reading the dataset"}}