{"cell_type":{"734a8e57":"code","81be06aa":"code","766bfa7b":"code","8fa933f3":"code","6d9425f4":"code","50ea58fe":"code","8b63cbea":"code","fc361e97":"markdown","071b899d":"markdown","3c33ccbf":"markdown","95adde46":"markdown","5aecc723":"markdown","22089000":"markdown"},"source":{"734a8e57":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","81be06aa":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries were imported.\")","766bfa7b":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint(\"Data were loaded.\")\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","8fa933f3":"# parameter to be optimized\nparams = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n\n# 512 models\nreg_params = np.zeros(512)\nfor i in range(512):\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = VarianceThreshold(threshold=2).fit_transform(data[cols])\n\n    train3 = data2[:train2.shape[0]]; \n    \n    qda = QuadraticDiscriminantAnalysis()\n    clf = GridSearchCV(qda, params, cv=4)\n    clf.fit(train3, train2['target'])\n    \n    reg_params[i] = clf.best_params_['reg_param']\n    print(\"Best reg_param for model \" + str(i) + \" is \" + str(reg_params[i]))","6d9425f4":"sns.distplot(reg_params)\nplt.title(\"reg_param in QDA\")\nplt.figure()","50ea58fe":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nfor i in range(512):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = VarianceThreshold(threshold=2).fit_transform(data[cols])\n\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=5, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        clf = QuadraticDiscriminantAnalysis(reg_params[i])\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n\nauc = roc_auc_score(train['target'], oof)\nprint(f'AUC: {auc:.5}')","8b63cbea":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['target'] = preds\nsub.to_csv('submission.csv', index=False)","fc361e97":"Interesting, actually optimal parameters differ across models.\n\nLet's use optimal parameters for each model and submit.","071b899d":"### Parameter tuning on QDA via GridSearchCV","3c33ccbf":"### load data","95adde46":"Thanks to great public kernels (e.g. [Synthetic data for (next?) Instant Gratification](https:\/\/www.kaggle.com\/mhviraf\/synthetic-data-for-next-instant-gratification) and [Quadratic Discriminant Analysis](https:\/\/www.kaggle.com\/speedwagon\/quadratic-discriminant-analysis)), we all know that applying quadratic discriminant analysis to data with the same values of 'wheezy-copper-turtle-magic' is a very promissing way to go in this competition.\n\nQDA has essentially only one hyperparameter, which is 'reg_param', for regularization. What I would like to try here is to see whether using the same 'reg_param', say 0.1 or 0.5, for 512 models is OK. \n\nTo this end, I simply use GridSearchCV in each model.","5aecc723":"### libraries","22089000":"### submission"}}