{"cell_type":{"c16e503c":"code","1f005411":"code","76f3a3cb":"code","328ba77e":"code","f060341a":"code","6461f585":"code","fa33a916":"code","6c47cd24":"code","7f4913cb":"code","e6a1101f":"code","e5330bc3":"code","652b4b84":"code","f097da8c":"code","cc8c09ca":"code","32d3b7b3":"code","3034de1a":"code","5a38d237":"code","778d50f5":"code","8ced0404":"code","b274c763":"code","a2cdd132":"code","3886319e":"code","899435e8":"code","bdbddfa0":"code","1655e31c":"code","5981543e":"code","776f26bb":"code","8fa38cf0":"code","b40e97a0":"code","4a5e3b8f":"code","061997dd":"code","d55483de":"code","edaeace3":"code","baf983a0":"code","f215a870":"code","f0ca6945":"code","d02843e8":"code","a081f363":"code","c59b0b2b":"code","578f2a09":"markdown","5d9f4fc1":"markdown","61c40620":"markdown","fdd8606b":"markdown","96e97b66":"markdown","c9c85f82":"markdown","fc1b80fc":"markdown","7ccb23f9":"markdown","9891939b":"markdown","c217d117":"markdown","dd1afe9a":"markdown","2c91441f":"markdown","41c44f46":"markdown","73ac31a1":"markdown","f1795f6c":"markdown","44c17ad1":"markdown"},"source":{"c16e503c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1f005411":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import PorterStemmer,WordNetLemmatizer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom string import punctuation\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf","76f3a3cb":"true = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\nfalse = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")","328ba77e":"true.head()","f060341a":"false.head()","6461f585":"true['category'] = 1\nfalse['category'] = 0","fa33a916":"true.head()","6c47cd24":"df = pd.concat([true,false]) ","7f4913cb":"df.isna().sum()","e6a1101f":"df.title.count()","e5330bc3":"df.subject.value_counts()","652b4b84":"df['text'] = df['text'] + \" \" + df['title'] + \" \" + df['subject']\ndel df['title']\ndel df['subject']\ndel df['date']","f097da8c":"df.head()","cc8c09ca":"stop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","32d3b7b3":"stop","3034de1a":"stemmer = PorterStemmer()\ndef stem_text(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            word = stemmer.stem(i.strip())\n            final_text.append(word)\n    return \" \".join(final_text)    ","5a38d237":"df.text = df.text.apply(stem_text)","778d50f5":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 3000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df.text))\nplt.imshow(wc , interpolation = 'bilinear')","8ced0404":"x_train,x_test,y_train,y_test = train_test_split(df.text,df.category)","b274c763":"cv=CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))\n#transformed train reviews\ncv_train_reviews=cv.fit_transform(x_train)\n#transformed test reviews\ncv_test_reviews=cv.transform(x_test)\n\nprint('BOW_cv_train:',cv_train_reviews.shape)\nprint('BOW_cv_test:',cv_test_reviews.shape)","a2cdd132":"model = Sequential()\nmodel.add(Dense(units = 100 , activation = 'relu' , input_dim = cv_train_reviews.shape[1]))\nmodel.add(Dense(units = 50 , activation = 'relu'))\nmodel.add(Dense(units = 25 , activation = 'relu'))\nmodel.add(Dense(units = 10 , activation = 'relu'))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))","3886319e":"model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])","899435e8":"model.fit(cv_train_reviews,y_train , epochs = 5)","bdbddfa0":"from joblib import dump, load\ndump(model, 'CNN.model') \n","1655e31c":"pred = (model.predict(cv_test_reviews) > 0.9999)","5981543e":"#for i in range(len(pred)):\n #   if(pred[i] ==1):\n  #      pred[i] = 1\n   # else:\n    #    pred[i] = 0","776f26bb":"#0.7\naccuracy_score(pred,y_test)","8fa38cf0":"#0.8\naccuracy_score(pred,y_test)","b40e97a0":"#0.9999\naccuracy_score(pred,y_test)","4a5e3b8f":"#cv_report = classification_report(y_test,pred,target_names = ['0','1'])\n#print(cv_report)","061997dd":"#0.7\ncm_cv = confusion_matrix(pred,y_test)\ncm_cv","d55483de":"#0.8\ncm_cv = confusion_matrix(pred,y_test)\ncm_cv","edaeace3":"#0.9999\ncm_cv1 = confusion_matrix(pred,y_test)\ncm_cv1","baf983a0":"cm_cv2 = confusion_matrix(y_test,pred)\ncm_cv2","f215a870":"#cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])\n#cm_cv.index.name = 'Actual'\n#cm_cv.columns.name = 'Predicted'","f0ca6945":"#0.7\nplt.figure(figsize = (10,10))\nsns.heatmap(cm_cv,cmap= \"Blues\",annot = True, fmt='')","d02843e8":"# confusion_matrix(pred,y_test)\n\n\n                     #Actual Negative    #Actual Positive                          #y_test(second variable)\n#Predicted Negative   True Negative       False Negative\n#Predicted Positive   False Positive      True Positive\n    \n    \n    \n#pred(first variable)","a081f363":"#0.8\nplt.figure(figsize = (10,10))\nsns.heatmap(cm_cv,cmap= \"Blues\",annot = True, fmt='')","c59b0b2b":"#0.9999\nplt.figure(figsize = (10,10))\nsns.heatmap(cm_cv1,cmap= \"Blues\",annot = True, fmt='')","578f2a09":"# Generating Word Cloud","5d9f4fc1":"# Loading Dataset","61c40620":"# Define the model","fdd8606b":"# Prediction and Accuracy","96e97b66":"# Text-2-Vector conversion ","c9c85f82":"# Stemming and lemmatization","fc1b80fc":"# Confusion Matrix","7ccb23f9":"# Evaluation","9891939b":"# Check for missing values","c217d117":"# Compile the model","dd1afe9a":"# First 5 records","2c91441f":"# Merging the 2 datasets","41c44f46":"# Importing Libraries","73ac31a1":"# Fit the model","f1795f6c":"# Spliting training and testing data","44c17ad1":"# Remove noisy words from a text"}}