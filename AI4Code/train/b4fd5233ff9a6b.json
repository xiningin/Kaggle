{"cell_type":{"eaeb025b":"code","831a750a":"code","de10b989":"code","5c492561":"code","34d63f39":"code","799374fc":"code","7fd615f2":"code","332c3904":"code","68fc4568":"code","892d1d09":"code","13e278f9":"code","4966688b":"code","4e18eea6":"code","1576f067":"code","d33ce20c":"code","11b89e36":"code","9a021dca":"code","f2bbadc0":"code","0fde607a":"code","7a87808e":"code","1bc979e0":"code","0508d427":"code","2fdfc7ff":"code","9beaadee":"code","855c4b1e":"code","67c0b820":"code","b68139ce":"code","c091a57f":"code","545256a2":"code","43f0213a":"code","84fe0b14":"code","a4974fe1":"code","79469656":"code","dfe36180":"code","9acf945c":"code","a8a7c6a5":"code","cb75e644":"code","eb871d24":"code","76e00e88":"code","682bb273":"code","b023381b":"code","36a2eccf":"code","7650eeb6":"code","619a1b37":"code","5c040a73":"code","2f730dfa":"code","66fd8794":"code","30a8e810":"code","08144d12":"code","93cce37a":"code","83579181":"code","a2b2dd69":"code","afad741a":"code","83210320":"code","0fba3b20":"code","67229df7":"code","634179d0":"code","16724a19":"code","fbfe95e9":"code","865d9ff0":"code","b3b3b984":"code","eb79bf00":"code","2e9a6209":"code","1d4b5760":"code","c5e9d238":"code","d69af2c5":"code","7ccb66a1":"code","7204f068":"markdown","4f6c041c":"markdown","ae61dc40":"markdown","d45aee22":"markdown","65c594c1":"markdown","ca8cf9ca":"markdown","61853cdd":"markdown","b222c6f6":"markdown","39e63100":"markdown","fdfbaa01":"markdown","9b25045f":"markdown","03a12c83":"markdown","c746bc1b":"markdown","d4420b4e":"markdown"},"source":{"eaeb025b":"import pandas as pd\nimport os\nimport numpy as np","831a750a":"meta = pd.read_csv(\"..\/input\/meta_open.csv\", index_col='uid', parse_dates=[\"datastart\",\"dataend\"], dayfirst=True)","de10b989":"meta.head(30)","5c492561":" meta.info()","34d63f39":"meta.datastart.value_counts()","799374fc":"meta[(meta.datastart == '2012-01-01') & (meta.primaryspaceusage == \"Office\")]","7fd615f2":"temporal = pd.read_csv(\"..\/input\/temp_open_utc_complete.csv\", index_col='timestamp', parse_dates=True).tz_localize('utc')","332c3904":"temporal.info()","68fc4568":"temporal.iloc[:,:10].info()","892d1d09":"singlebuilding = \"Office_Bobbi\"\nsingle_timezone = meta.T[singlebuilding].timezone\nsingle_start = meta.T[singlebuilding].datastart\nsingle_end = meta.T[singlebuilding].dataend\nsingle_building_data = pd.DataFrame(temporal[singlebuilding].tz_convert(single_timezone).truncate(before=single_start,after=single_end))","13e278f9":"single_building_data.plot(figsize=(15,3))","4966688b":"single_building_data.info()","4e18eea6":"single_building_data.resample(\"D\").sum().plot(figsize=(15,3))","1576f067":"single_building_data.truncate(after='2015-02').plot(figsize=(15,3))","d33ce20c":"single_building_data.dropna().index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])","11b89e36":"trainingdata = single_building_data[single_building_data.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])]","9a021dca":"trainingdata.plot(figsize=(15,3))","f2bbadc0":"trainingdata.info()","0fde607a":"testdata = single_building_data[single_building_data.index.month.isin([\"4\",\"8\",\"12\"])]","7a87808e":"testdata.info()","1bc979e0":"weatherfilename = meta.T[singlebuilding].newweatherfilename","0508d427":"weatherfilename","2fdfc7ff":"weather = pd.read_csv(os.path.join(\"..\/input\/\",weatherfilename),index_col='timestamp', parse_dates=True, na_values='-9999')\nweather = weather.tz_localize(single_timezone, ambiguous = 'infer')","9beaadee":"weather.info()","855c4b1e":"outdoor_temp = pd.DataFrame(weather[[col for col in weather.columns if 'Temperature' in col]]).resample(\"H\").mean()","67c0b820":"outdoor_temp.info()","b68139ce":"outdoor_temp = outdoor_temp.reindex(pd.DatetimeIndex(start=outdoor_temp.index[0], periods=len(single_building_data), freq=\"H\")).fillna(method='ffill').fillna(method='bfill')","c091a57f":"outdoor_temp.info()","545256a2":"outdoor_temp[outdoor_temp.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])].TemperatureC.values","43f0213a":"pd.get_dummies(trainingdata.index.dayofweek).head()","84fe0b14":"train_features = np.array(pd.concat([pd.get_dummies(trainingdata.index.hour),\n                                     pd.get_dummies(trainingdata.index.dayofweek),\n           pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])].TemperatureC.values)], axis=1))","a4974fe1":"train_features.shape","79469656":"train_labels = np.array(trainingdata[singlebuilding].values)","dfe36180":"train_labels","9acf945c":"train_labels.shape","a8a7c6a5":"test_features = np.array(pd.concat([pd.get_dummies(testdata.index.hour),\n                                     pd.get_dummies(testdata.index.dayofweek),\n           pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"4\",\"8\",\"12\"])].TemperatureC.values)], axis=1))","cb75e644":"test_labels = testdata[singlebuilding].values\n","eb871d24":"test_labels.shape","76e00e88":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n# Train the model on training data\nrf.fit(train_features, train_labels);","682bb273":"# Use the forest's predict method on the test data\npredictions = rf.predict(test_features)\n# Calculate the absolute errors\nerrors = abs(predictions - test_labels)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2))\n","b023381b":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors \/ test_labels)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","36a2eccf":"NMBE = 100 * (sum(test_labels - predictions) \/ (pd.Series(test_labels).count() * np.mean(test_labels)))\nCVRSME = 100 * ((sum((test_labels - predictions)**2) \/ (pd.Series(test_labels).count()-1))**(0.5)) \/ np.mean(test_labels)","7650eeb6":"CVRSME","619a1b37":"NMBE","5c040a73":"from sklearn.metrics import r2_score","2f730dfa":"r2_score(test_labels, predictions)","66fd8794":"testdata[\"Prediction\"]= predictions","30a8e810":"testdata.head()","08144d12":"testdata.columns = ['Actual','Prediction']","93cce37a":"testdata.plot(figsize=(15,3))","83579181":"testdata.truncate(after='2015-05-01').plot(figsize=(15,3))","a2b2dd69":"testdata.resample(\"D\").sum().plot(figsize=(15,3))","afad741a":"buildingnames = temporal.columns[temporal.columns.str.contains(\"Office\")]","83210320":"buildingnames","0fba3b20":"def get_model(buildingnames, meta, temporal):\n        MAPE_data = {}\n        RSQUARED_data = {}\n        NMBE_data = {}\n        CVRSME_data = {}\n\n        for singlebuilding in buildingnames:\n            print(\"Modelling: \"+singlebuilding)\n            try:\n                # Get Data\n                single_timezone = meta.T[singlebuilding].timezone\n                single_start = meta.T[singlebuilding].datastart\n                single_end = meta.T[singlebuilding].dataend\n                single_building_data = pd.DataFrame(temporal[singlebuilding].tz_convert(single_timezone).truncate(before=single_start,after=single_end))\n\n                # Split into Training and Testing\n                trainingdata = single_building_data[single_building_data.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])]\n                testdata = single_building_data[single_building_data.index.month.isin([\"4\",\"8\",\"12\"])]\n\n                # Get weather file\n                weatherfilename = meta.T[singlebuilding].newweatherfilename\n                print(\"Weatherfile: \"+weatherfilename)\n                weather = pd.read_csv(os.path.join(\"..\/input\/\",weatherfilename),index_col='timestamp', parse_dates=True, na_values='-9999')\n                weather = weather.tz_localize(single_timezone, ambiguous = 'infer')\n                outdoor_temp = pd.DataFrame(weather[[col for col in weather.columns if 'Temperature' in col]]).resample(\"H\").mean()\n                outdoor_temp = outdoor_temp.reindex(pd.DatetimeIndex(start=outdoor_temp.index[0], periods=len(single_building_data), freq=\"H\")).fillna(method='ffill').fillna(method='bfill')\n\n                # Create training data array\n                train_features = np.array(pd.concat([pd.get_dummies(trainingdata.index.hour),\n                                                     pd.get_dummies(trainingdata.index.dayofweek),\n                           pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])].TemperatureC.values)], axis=1))\n                train_labels = np.array(trainingdata[singlebuilding].values)\n\n                # Create test data array\n                test_features = np.array(pd.concat([pd.get_dummies(testdata.index.hour),\n                                                     pd.get_dummies(testdata.index.dayofweek),\n                           pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"4\",\"8\",\"12\"])].TemperatureC.values)], axis=1))\n                test_labels = np.array(testdata[singlebuilding].values)\n\n                # Make model\n                rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n                # Train the model on training data\n                rf.fit(train_features, train_labels);\n\n                # Use the forest's predict method on the test data\n                predictions = rf.predict(test_features)\n                # Calculate the absolute errors\n                errors = abs(predictions - test_labels)\n\n                # Calculate mean absolute percentage error (MAPE) and add to list\n                MAPE = 100 * np.mean((errors \/ test_labels))\n                NMBE = 100 * (sum(test_labels - predictions) \/ (pd.Series(test_labels).count() * np.mean(test_labels)))\n                CVRSME = 100 * ((sum((test_labels - predictions)**2) \/ (pd.Series(test_labels).count()-1))**(0.5)) \/ np.mean(test_labels)\n                RSQUARED = r2_score(test_labels, predictions)\n\n                print(\"MAPE: \"+str(MAPE))\n                print(\"NMBE: \"+str(NMBE))\n                print(\"CVRSME: \"+str(CVRSME))\n                print(\"R SQUARED: \"+str(RSQUARED))\n\n                MAPE_data[singlebuilding] = MAPE\n                NMBE_data[singlebuilding] = NMBE\n                CVRSME_data[singlebuilding] = CVRSME\n                RSQUARED_data[singlebuilding] = RSQUARED\n\n            except:\n                print(\"There was a problem\")\n            \n        return MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data","67229df7":"MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data = get_model(buildingnames, meta, temporal)","634179d0":"metrics_office = pd.DataFrame([MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data]).T\nmetrics_office.columns = [\"MAPE\", \"NMBE\", \"CVRSME\", \"RSQUARED\"]","16724a19":"metrics_office","fbfe95e9":"metrics_office.to_csv(\"RF_metrics_office.csv\")","865d9ff0":"metrics_office[metrics_office<100].hist(bins=30, figsize=(10,10))","b3b3b984":"buildingnames_dorm = temporal.columns[temporal.columns.str.contains(\"UnivDorm\")]","eb79bf00":"buildingnames_dorm","2e9a6209":"MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data = get_model(buildingnames_dorm, meta, temporal)","1d4b5760":"metrics_dorm = pd.DataFrame([MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data]).T\nmetrics_dorm.columns = [\"MAPE\", \"NMBE\", \"CVRSME\", \"RSQUARED\"]","c5e9d238":"metrics_dorm","d69af2c5":"metrics_dorm.to_csv(\"RF_metrics_dorm.csv\")","7ccb66a1":"metrics_dorm[metrics_dorm<100].hist(bins=30, figsize=(10,10))","7204f068":"## Use a random forest model to predict the test set and calculate the results\n\n### Train Model\nAfter all the work of data preparation, creating and training the model is pretty simple using Scikit-learn. We import the random forest regression model from skicit-learn, instantiate the model, and fit (scikit-learn\u2019s name for training) the model on the training data. (Again setting the random state for reproducible results). This entire process is only 3 lines in scikit-learn!","4f6c041c":"Let's get only the code","ae61dc40":"One can notice that there are 507 buildings and various attributes are available.\n\nIn this analysis, let's only focus on the Office Buildings with one full year of data in 2015","d45aee22":"## Create the training data","65c594c1":"# Go through and create and test a model for all the buildings in the data set\n\nLet's only look at Office Buildings","ca8cf9ca":"# Office Building Energy Prediction Demonstration - Random Forest\n\nThis notebook is a demonstration of the use of the Building Data Genome Project Data to illustrate how a prediction competition using whole building electrical meter data could be set up. \n\nThe open data set we're using for this demonstration is the Building Data Genome Project (https:\/\/github.com\/buds-lab\/the-building-data-genome-project)\n\nFirst we'll load the *meta* data and take a look around - these data show the diversity of building types in this machine learning exercise\n","61853cdd":"The temporal data from these devices is 8760 hourly points. Each building has its own `start` and `stop` times and its own weather files\n\n# Single building energy prediction example\n\nWe will take one of the buildings to demonstrate a type of forecasting example. \n\n**We will take 12 months of hourly data and remove one our of every four months and attempt to predict those gaps. This means that 25% of the data set is testing and 75% is training. **\n\nFirst, we need to extract a singpe building and adapt its time zone.","b222c6f6":"# Visualize the model","39e63100":"Calculate R squared","fdfbaa01":"# Building a simple open-source model to fill in the gaps\n\nUsing this link as a guide: https:\/\/towardsdatascience.com\/random-forest-in-python-24d0893d51c0\n\nIn order to fill in the gaps, we will use a very basic implementation of the random forest model implemented in `sci-kit learn` toa fill in the gaps. \n\nWe will use the following features at each timestamp:\n- Day of Week\n- Hour of Day\n- Outdoor Air Temperature\n\nRemember, this is a very simple example.\n\nFirst, let's grab the weather data","9b25045f":"# Let's look at all the other building types also\n\n## Let's do dormitories now","03a12c83":"## Create the test labels data","c746bc1b":"We can resample to smooth out the data to see the macro-level trends ","d4420b4e":"### Make Predictions on the Test Set\nOur model has now been trained to learn the relationships between the features and the targets. The next step is figuring out how good the model is! To do this we make predictions on the test features (the model is never allowed to see the test answers). We then compare the predictions to the known answers. When performing regression, we need to make sure to use the absolute error because we expect some of our answers to be low and some to be high. We are interested in how far away our average prediction is from the actual value so we take the absolute value (as we also did when establishing the baseline).\n\n"}}