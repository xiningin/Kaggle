{"cell_type":{"7c5cf6e0":"code","d25bfffd":"code","38bbd47e":"code","1bc85318":"code","460495ba":"code","d2719333":"code","016ef271":"code","20fb0bd5":"code","2b809aa7":"code","22f7d369":"code","a7af83ba":"code","eac4ed84":"markdown","9d6fa6cf":"markdown","de0e71b3":"markdown","fc6fd691":"markdown","c7d918a7":"markdown","789cb309":"markdown","46100b34":"markdown","ea20455b":"markdown","12679056":"markdown","e09e52d4":"markdown","64c7a1a5":"markdown"},"source":{"7c5cf6e0":"import matplotlib.pyplot as plt # for plotting \nimport numpy as np\nimport os  # accessing directory\nimport pandas as pd #for data processing\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler","d25bfffd":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        #print filepath for csv","38bbd47e":"df = pd.read_csv('\/kaggle\/input\/trumprelated-tweets-us-election-day-2020\/247500_totaloutput_9parts.csv')\ndf.dataframeName = '247500_totaloutput_9parts.csv'\n","1bc85318":"print(f\"data shape: {df.shape}\")\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","460495ba":"df.info()","d2719333":"#check duplicate\n\n# Select duplicate rows except first occurrence based on all columns\nduplicateRowsDF = df[df.duplicated()]\nprint(\"Duplicate Rows except first occurrence based on all columns are :\")\nprint(duplicateRowsDF)","016ef271":"df.duplicated().unique()\ndf.duplicated(keep = 'last').sum()\n\n#By using \u2018last\u2019, the last occurrence of each set of duplicated values is set on False and all others on True.\n# dropping ALL duplicte values \ndata_1= df.drop_duplicates(keep = 'last') \n  \n# displaying data \ndata_1.count() \n\n#consist of no duplicate tweet text\ndata_1.duplicated().unique()\n\ndf=data_1\n\ndf.info()","20fb0bd5":"df.describe()","2b809aa7":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))\n\nmissing_data(df)","22f7d369":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))\n\nunique_values(df)","a7af83ba":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))\n\nmost_frequent_values(df)","eac4ed84":"### read csv","9d6fa6cf":"## data describe","de0e71b3":"## Most frequent data","fc6fd691":"## remove duplication","c7d918a7":"## Data Info","789cb309":"## Unique Values","46100b34":"## Missing Data","ea20455b":"## Data Shape","12679056":"### import libraries and print working directory","e09e52d4":"# Preliminary EDA","64c7a1a5":"## check duplicate"}}