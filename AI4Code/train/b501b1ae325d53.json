{"cell_type":{"cbbb151a":"code","e2107581":"code","ee72c9a9":"code","15942675":"code","75dd0e79":"code","c7c3933b":"code","79a47335":"code","d7cb9488":"code","70046a3c":"code","8a362b8d":"code","f67b8c5b":"code","662be5a5":"code","016ab807":"code","ba6807b5":"code","bf6176e7":"code","b1002dff":"code","c3d31da6":"code","407b6e70":"code","32e9827e":"code","be35ff69":"code","3aa2b92d":"code","727ccdd3":"code","31770569":"code","f13af7ed":"code","05c2d8c2":"code","9d2b086f":"code","0ca48fb8":"code","a585f00e":"code","dc2c7a0f":"code","ab751be0":"code","1209e04e":"code","7979cf12":"code","241360c7":"code","60407822":"code","43294447":"code","9c597306":"code","f7c87c25":"code","31d099c3":"code","c800be1a":"code","6bbb2a2d":"code","30d28625":"code","29c0f3dd":"markdown","adcd5524":"markdown","8da675e9":"markdown","2c461293":"markdown","1e04c536":"markdown","a3bc3975":"markdown","4c02bd6a":"markdown","cd8ec07b":"markdown","ae3e99c4":"markdown","39d2928b":"markdown","6447b7c0":"markdown","6aec12fc":"markdown","8953c37e":"markdown","2ed129ad":"markdown","ce173e2b":"markdown","62203fc3":"markdown","8b56d704":"markdown","6e0f01c5":"markdown","18cd24fd":"markdown","df784e3d":"markdown","5e2cd078":"markdown","0ff0f8f2":"markdown"},"source":{"cbbb151a":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","e2107581":"df_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')","ee72c9a9":"sns.countplot(x='Survived',hue='Sex',data=df_train)","15942675":"sns.countplot(x='Survived',hue='Pclass',data=df_train)","75dd0e79":"sns.distplot(df_train['Age'].dropna(),bins=30,kde=False)","c7c3933b":"df_train.info()","79a47335":"df_train['Fare'].hist(bins=100,figsize=(10,10))","d7cb9488":"df_train[df_train['Fare']>500]","70046a3c":"#adjusting for inflation, one dollar back then is equal to $25.89\/\n#lets ajust for inflation","8a362b8d":"df_train[df_train['Fare']>500]['Fare']*25.89","f67b8c5b":"age_means = pd.pivot_table(df_train,values = 'Age',index= 'Pclass',aggfunc='mean')\nage_means","662be5a5":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass ==1:\n            return 38\n        elif Pclass ==2:\n            return 30\n        else:\n            return 25\n    else:\n        return Age","016ab807":"df_train['Age'] = df_train[['Age','Pclass']].apply(impute_age,axis=1)","ba6807b5":"df_train.drop('Cabin',axis=1,inplace=True)","bf6176e7":"sex = pd.get_dummies(df_train['Sex'],drop_first=True)","b1002dff":"embark = pd.get_dummies(df_train['Embarked'],drop_first=True)","c3d31da6":"embark.head()","407b6e70":"\ntrain = pd.concat([df_train,sex,embark],axis=1)","32e9827e":"train.head()","be35ff69":"train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","3aa2b92d":"train.drop(['PassengerId'],axis=1,inplace=True)","727ccdd3":"X = train.drop('Survived',axis=1)\ny = train['Survived']","31770569":"from sklearn.model_selection import train_test_split","f13af7ed":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=50)","05c2d8c2":"from sklearn.linear_model import LogisticRegression","9d2b086f":"logmodel = LogisticRegression()","0ca48fb8":"logmodel.fit(X_train,y_train)","a585f00e":"predictions = logmodel.predict(X_test)","dc2c7a0f":"predictions","ab751be0":"from sklearn.metrics import classification_report","1209e04e":"print(classification_report(y_test,predictions))","7979cf12":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score","241360c7":"confusion_matrix(y_test,predictions)","60407822":"precision_score(y_test,predictions)","43294447":"pd.DataFrame(index= list(logmodel.coef_),data = list(X_train.columns))","9c597306":"logmodel.intercept_","f7c87c25":"gma  = pd.read_csv(\"..\/input\/grandmas-attributes\/grandma.csv\")","31d099c3":"gma.head()","c800be1a":"gma_surv = logmodel.predict(gma.drop('Adj. Fare',axis=1))","6bbb2a2d":"print(gma_surv)","30d28625":"logmodel.predict_proba(gma.drop('Adj. Fare',axis=1))","29c0f3dd":"But the probabilites are 59-60%. I don't know about you, but with a 40% chance of rain, I bring an umbrella. \n\nI'm not sure if the data are realistic, but this was cool first experiment to see just how likely my ancestor would be around had she been on that big boat. \n\n","adcd5524":"Indeed. ","8da675e9":"Here are the predictions for the test sample of our model. ","2c461293":"From the graph, we can see that the majority of females surived and disporportionally to their gender. ","1e04c536":"**My Grandmother Was 2 Hours Late to the Titanic**\n\n\nIn 1912, my grandmother traveled from a small town in Hungary to South Hampton, England, in hopes of beginning a new life in America. With her mother and sister in toe, they made the trek to be united with their father in The States. \n\nUpon arrival, they were dissapointed learn that their vessel of freedom had left without them, a mere two hours before. \nI can only image their relief when they learned of their good fortune to nearly miss the most famous ship distaster in history.\n\nI had always heard this story by family members, but much to my suprise, elements of this story actually exist in her obitutary. [Check it out!](https:\/\/www.findagrave.com\/memorial\/64694097\/mary-barilich)\n\n\n\n**Introduction:**\n\nAfter learning a bit about python, I've decided to tip my toes in machine learning. I beginning with a very simple dataset to grasp the fundamentals of Data Science and attempt to answer a very interesting and person question...\n\n**Had my grandmother sailed on the Titanic, would she have survived? Would I have ever existed!??**\n\nLet see what we can do. \n\n*(Guidance on this mini-project comes from Data Science and Machine Learning with Python by Jose Portilla)*\n\n","a3bc3975":"So, we noticed from .info() that we were missing a good chunk of our age data. The course that I followed suggested taking the average of age by class and imputing (filling in) those values to remove the nulls. And, there's a good portion of the cabin info missing, so we'll drop that column all together. ","4c02bd6a":"And some paid over 500 dollars for a ticket! Did they survive?! ","cd8ec07b":"Does she survive!?","ae3e99c4":"**Nice!**","39d2928b":"**Logistic Regression:**\n\nIn this section, we'll take all of our explanatory variables and our predicted values and fit them to the logistic model. ","6447b7c0":"And here is the acrruacy of the logistic model to the actual variable. ","6aec12fc":"You better be a wealthy, classy lady though...","8953c37e":"**Exploratory Data Analysis and Cleaning:**","2ed129ad":"**Would my grandmother have survived?**\n\nLets see based on the predictions of the model. ","ce173e2b":"Recall, that the SibSP field denotes siblings. ","62203fc3":"**First, lets load our data set and necessary package for analysis**","8b56d704":"Let's round and call it 80%!\n\nI was interested to find what the coefficents were for each of the X variables and the intercept. ","6e0f01c5":"To run logistic regression, we'll need to turn Male and Female into 1s and 0s, along with the departure location, because there are three categories. 2 columns are used to fix this! ","18cd24fd":"From what I know from her obituary and other information from my data family, I make the following inputs:\n\n* **Class = 3** (They were quite poor)\n* **Age = 13**\n* **Siblings = One sister**\n* **Parents or Children = Her mother**\n* **Fare = 3**  This is an estimate from information obtained online. \n* **Male = 0**\n* **Departure = South Hampton**","df784e3d":"80% isn't bad. ","5e2cd078":"BALLIN!","0ff0f8f2":".info() gives us some a great overview of the data types we have in our columns and shows were data may be missing. "}}