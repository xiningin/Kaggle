{"cell_type":{"9455ef1f":"code","45301d8c":"code","c0246694":"code","bdeb888b":"code","acb11d2f":"code","0bbccfce":"code","be03b3cd":"code","93aae011":"code","d118c8b8":"code","a782b9da":"code","37a02a53":"code","58cb80fa":"code","a1229595":"code","fb99ac5a":"code","49d314f5":"code","5973d06c":"code","6be4e44a":"code","da8af091":"code","e7305a71":"code","3dffbd9b":"code","fdc84285":"code","52c41e20":"code","a4c5e398":"code","ea385b04":"code","574a764b":"code","5148c0ec":"code","048f00ac":"code","1ee23854":"code","341f8ea9":"code","e1737cda":"code","f0cc3a59":"code","85f9ff31":"code","f42eeab2":"code","ce1207d8":"code","e5899c6f":"code","91f61295":"code","c6f700e8":"code","527c71a7":"code","d096a716":"code","e28a8167":"code","0abe051b":"code","f4b32dc7":"code","cae53f0a":"code","ce576ea6":"code","cb7818a0":"code","8700e404":"code","91ec1393":"code","6646442d":"code","c022df5a":"code","2e222f72":"code","a6f71069":"code","8c1745ec":"code","05311715":"code","083d8ce1":"code","3cc0e5cb":"code","6cdc127b":"code","dfa40961":"code","3b422ece":"code","82e6d8c0":"code","6241a9b0":"code","820f329a":"code","ed60cb6c":"code","e24c087b":"code","ac53d389":"code","d4536991":"code","d47168c6":"code","13d8b128":"code","63aaa5db":"code","17f8887c":"code","61515565":"code","76643412":"code","c58e3b8a":"code","7a22c722":"code","82f6eab9":"code","d59956b2":"code","5a47528e":"code","e6454593":"code","c5bb6344":"code","243fa16f":"markdown","83d0e9ea":"markdown","2aa6944e":"markdown","02bbcf1f":"markdown","5f5d954e":"markdown","26b4c3c8":"markdown","fc8f9c93":"markdown","3ab96686":"markdown","134a4d26":"markdown","8908999c":"markdown","8d704700":"markdown","b4ddd98d":"markdown","83b3103a":"markdown","5a042d76":"markdown","a53e6dc2":"markdown","c3e2e6e7":"markdown","35fa090b":"markdown","1fa97bfe":"markdown","a8b79075":"markdown","e30bc57a":"markdown","d93d345e":"markdown","35757434":"markdown","3470a6ca":"markdown","fbd1b142":"markdown","93ed4a73":"markdown","98f27b62":"markdown","fceaf149":"markdown","acbad973":"markdown","e5553e4c":"markdown","5d3f0ca6":"markdown","a03b322d":"markdown","3019461d":"markdown","8510b827":"markdown","84257d2f":"markdown","32655d0f":"markdown","93aa3d45":"markdown","31e314d8":"markdown","396f7174":"markdown","0c86a490":"markdown","245a169f":"markdown"},"source":{"9455ef1f":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_id = test['PassengerId']\ntest.drop(['PassengerId'], axis=1, inplace=True)\ntrain.drop(['PassengerId'], axis=1, inplace=True)","45301d8c":"train.head()","c0246694":"train.describe()","bdeb888b":"train.info()","acb11d2f":"test.info()","0bbccfce":"def loss_rate(x):  # x is DataFrmae type\n    table = ((x.isnull().sum())\/x.shape[0]).sort_values(ascending=False).map(lambda i:\"{:.2%}\".format(i))\n    return table","be03b3cd":"loss_rate(train)","93aae011":"loss_rate(test)","d118c8b8":"train.Cabin.value_counts()\n# there are many multiple rooms info","a782b9da":"ls = []\nfor i in train.Cabin:\n    if i is np.nan:  # remain nan\n        ls.append(np.nan)\n    elif len(i.split()) > 1:  # remain mutiple rooms info, waiting further process\n        ls.append(i)\n    else:\n        ls.append(i[:1])","37a02a53":"train.Cabin = ls","58cb80fa":"train.Cabin.value_counts()","a1229595":"ls = []\nfor i in train.Cabin:\n    if i is np.nan:  # remain nan\n        ls.append('U')\n    elif i[:3] in [\"F E\", \"F G\"]:\n        ls.append(i[:3].replace(' ',''))  # remove blank\n    else:\n        ls.append(i[:1])","fb99ac5a":"train.Cabin = ls\ntrain.drop(train[train.Cabin == 'T'].index, inplace=True)  # delete \"T\"\ntrain.Cabin.value_counts()","49d314f5":"train.head()","5973d06c":"train.corr()","6be4e44a":"train.reset_index(inplace=True, drop=True)","da8af091":"train","e7305a71":"train.drop(['Ticket'], axis=1, inplace=True)","3dffbd9b":"train.drop(['Name'], axis=1, inplace=True)","fdc84285":"train.head()","52c41e20":"train.info()","a4c5e398":"train.Age.hist()","ea385b04":"train.Age.describe()","574a764b":"train.Age.fillna(train.Age.mean(), inplace=True)","5148c0ec":"train.Age.describe()","048f00ac":"train.Embarked.value_counts()","1ee23854":"train.info()","341f8ea9":"attrs_cat = ['Survived', 'Sex', 'Cabin', 'Embarked']\nx_cat = train[attrs_cat]","e1737cda":"from sklearn.preprocessing import StandardScaler\nattrs_num = ['Pclass', 'Age', 'SibSp' ,'Parch', 'Fare']\nscl = StandardScaler()\nx_num = pd.DataFrame(scl.fit_transform(train[attrs_num]), columns=attrs_num)","f0cc3a59":"x = pd.concat([x_cat, x_num], axis=1)","85f9ff31":"x.info()","f42eeab2":"pd.get_dummies(x).info()","ce1207d8":"x","e5899c6f":"x = pd.get_dummies(x)","91f61295":"x.head()","c6f700e8":"from sklearn.base import BaseEstimator, TransformerMixin\nclass pocess(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        ls = []\n        for i in X.Cabin:\n            if i is np.nan:  # remain nan\n                ls.append('U')\n            elif i[:3] in [\"F E\", \"F G\"]:\n                ls.append(i[:3].replace(' ',''))  # remove blank\n            else:\n                ls.append(i[:1])\n        X.Cabin = ls\n        X.drop(['Ticket'], axis=1, inplace=True)\n        X.drop(['Name'], axis=1, inplace=True)\n        X.Age.fillna(train.Age.mean(), inplace=True)\n        \n        attrs_cat = ['Sex', 'Cabin', 'Embarked']\n        X_cat = X[attrs_cat]\n        attrs_num = ['Pclass', 'Age', 'SibSp' ,'Parch', 'Fare']\n        scl = StandardScaler()\n        X_num = pd.DataFrame(scl.fit_transform(X[attrs_num]), columns=attrs_num)\n        X = pd.concat([X_cat, X_num], axis=1)\n\n        X = pd.get_dummies(X)\n        return X","527c71a7":"test","d096a716":"processor = pocess()","e28a8167":"y_copy = test.copy()","0abe051b":"y_pre = processor.fit_transform(y_copy)","f4b32dc7":"x.info()","cae53f0a":"from sklearn.model_selection import train_test_split\nx_train, x_test = train_test_split(x, test_size = 0.2, random_state=42)","ce576ea6":"x_pre = x_train.drop(['Survived'], axis=1)\nx_labels = x_train['Survived']","cb7818a0":"from sklearn.linear_model import LogisticRegression\nlogic_reg = LogisticRegression(solver='lbfgs', max_iter=10000)\nlogic_reg.fit(x_pre, x_labels)","8700e404":"x_predict = logic_reg.predict(x_pre)","91ec1393":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(x_labels, x_predict)","6646442d":"from sklearn.model_selection import cross_val_score\ncross_val_score(logic_reg, x_pre, x_labels, cv=10, scoring='accuracy')  # 10\u6298\u4ea4\u53c9\u9a8c\u8bc1","c022df5a":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_predict\ny_logic_scores = cross_val_predict(logic_reg, x_pre, x_labels, cv=5, method='decision_function')  \nfrom sklearn.metrics import precision_recall_curve\nprecisions_logic, recalls_logic, thresholds_logic = precision_recall_curve(x_labels, y_logic_scores)\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label='precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label='recall')\n    plt.xlabel('threshold')\n    plt.legend()\n    plt.grid()\n    plt.title('PR curve')\n    plt.show()\nplot_precision_recall_vs_threshold(precisions_logic, recalls_logic, thresholds_logic)","2e222f72":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1],[0, 1], 'k--')  \n    plt.xlabel('FPR')\n    plt.ylabel('TPR')\n    plt.title('ROC')\n    plt.legend()\n    plt.grid()\n    plt.show()","a6f71069":"x_scores = logic_reg.decision_function(x_pre)","8c1745ec":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(x_labels, x_scores)","05311715":"plot_roc_curve(fpr, tpr, 'Logic')","083d8ce1":"from sklearn.metrics import roc_auc_score\nroc_auc_score(x_labels, x_scores)","3cc0e5cb":"from sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(random_state=42)\nforest_clf.fit(x_pre, x_labels)\nx_probas_forest = cross_val_predict(forest_clf, x_pre, x_labels, cv=5, method='predict_proba')","6cdc127b":"x_probas_forest","dfa40961":"x_scores_forest = x_probas_forest[:, 1]\nfpr_forest, tpr_forest, threshold = roc_curve(x_labels, x_scores_forest)","3b422ece":"plt.plot(fpr, tpr, 'r:', label='Logic')\nplot_roc_curve(fpr_forest, tpr_forest,'Randomforest')","82e6d8c0":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state = 42)  \nsgd_clf.fit(x_pre, x_labels)","6241a9b0":"x_SDG_predict = sgd_clf.predict(x_pre)","820f329a":"confusion_matrix(x_labels, x_SDG_predict)","ed60cb6c":"cross_val_score(sgd_clf, x_pre, x_SDG_predict, cv=10) ","e24c087b":"x_sgd_scores = sgd_clf.decision_function(x_pre)\nfpr_sgd, tpr_sgd, thresholds_sgd = roc_curve(x_labels, x_sgd_scores)","ac53d389":"plt.plot(fpr, tpr, 'r:', label='Logic')\nplt.plot(fpr_forest, tpr_forest, 'g-', label='RandomForest')\nplot_roc_curve(fpr_sgd, tpr_sgd, 'SGD')","d4536991":"y_SGD_score = cross_val_predict(sgd_clf, x_pre, x_labels, cv=5, method='decision_function')  \nprecisions_SGD, recalls_SGD, thresholds_SGD = precision_recall_curve(x_labels, y_SGD_score)\nplot_precision_recall_vs_threshold(precisions_SGD, recalls_SGD, thresholds_SGD)","d47168c6":"from sklearn.svm import SVC\nsvc = SVC(C=1)\nsvc.fit(x_pre, x_labels)","13d8b128":"x_svc_predict = svc.predict(x_pre)","63aaa5db":"confusion_matrix(x_labels, x_svc_predict)","17f8887c":"cross_val_score(svc, x_pre, x_labels, cv=10, scoring='accuracy')  # 10\u6298\u4ea4\u53c9\u9a8c\u8bc1","61515565":"y_svc_scores = cross_val_predict(svc, x_pre, x_labels, cv=5, method='decision_function')\nprecisions_svc, recalls_svc, thresholds_svc = precision_recall_curve(x_labels, y_svc_scores)\nplot_precision_recall_vs_threshold(precisions_svc, recalls_svc, thresholds_svc)","76643412":"x_svc_scores = svc.decision_function(x_pre)\nfpr_svc, tpr_svc, thresholds_svc = roc_curve(x_labels, x_svc_scores)","c58e3b8a":"plt.plot(fpr, tpr, 'r:', label='Logic')\nplt.plot(fpr_forest, tpr_forest, 'g-', label='RandomForest')\nplt.plot(fpr_sgd, tpr_sgd, label='SGD')\nplot_roc_curve(fpr_svc, tpr_svc, 'SVC')","7a22c722":"loss_rate(y_pre)","82f6eab9":"y_pre['Fare'] = y_pre['Fare'].fillna(y_pre['Fare'].mean())","d59956b2":"loss_rate(y_pre)","5a47528e":"y_predict = forest_clf.predict(y_pre)","e6454593":"submission = pd.DataFrame(np.c_[test_id, y_predict], columns=['PassengerId', 'Survived'])","c5bb6344":"submission.to_csv('.\/submission.csv', index = False)","243fa16f":"## Age","83d0e9ea":"### ROC curve","2aa6944e":"## Name","02bbcf1f":"I think the missing values should be filled with the average.","5f5d954e":"## LogisticRegression","26b4c3c8":"I don't think that name related to survival.","fc8f9c93":"## Standardization","3ab96686":"## One-hot encoding","134a4d26":"# Test_set converter","8908999c":"SVC looks good.","8d704700":"# Predict test set","b4ddd98d":"## Ticket","83b3103a":"Multiple rooms are in same type cabin, so I will merge them, \"C23 C25 C27\" to \"C\".  \n\nThere are some special info such as \"F G73\" and \"T\", I think that is special cabin for crews or captain or some kinds of people. In test.csv, Cabin categories contain \"ABCDEFG\" and \"F E\", \"F G\", without \"T\", so we need to merge all data but \"T\"(delete).  \n\nAs for NaN data, turn it to U('Unknow').","5a042d76":"### Confusion matrix","a53e6dc2":"I don't think that ticket related to thier survival, so I just delete this atrribute.","c3e2e6e7":"It has no special value. I will not process this attribute, cause one-hot encoder will group them together.","35fa090b":"I think it's ok.","1fa97bfe":"## Embarked","a8b79075":"## Cabin","e30bc57a":"# Machine Learning","d93d345e":"## SGDClassifier","35757434":"### K-fold cross validation","3470a6ca":"### ROC curve","fbd1b142":"### Confusion matrix","93ed4a73":"### PR curve","98f27b62":"### Confusion matrix","fceaf149":"Need to fill \"Fare\", with the use of average.","acbad973":"Little difference.","e5553e4c":"## SVM","5d3f0ca6":"Train set finished.","a03b322d":"I choose random forest this time.","3019461d":"### PR curve","8510b827":"# Process data","84257d2f":"### ROC curve","32655d0f":"## RandomForest","93aa3d45":"### K-fold cross validation","31e314d8":"All right!","396f7174":"Process Cabin first. The Cabin data is far more less then other data, but I think that Cabin is still related to thier survival. Cause the Cabin types may related to thier economy condition and so on.\n\nI decide to drop the specific room number, only remain the cabin type.","0c86a490":"## Prepare data","245a169f":"# Check data"}}