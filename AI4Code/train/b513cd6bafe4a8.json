{"cell_type":{"82b3b805":"code","ed11fa69":"code","44b50ce4":"code","df492fb6":"code","683a4057":"code","c0ccd4b5":"code","a983aa66":"code","c76fe749":"code","27c3a7e2":"code","8293bd34":"code","64f65ec0":"code","9d0dd0fa":"code","e8115df7":"code","e888016f":"code","3b6e38a5":"code","20fc3bff":"code","30e1e12e":"code","597cd6d2":"code","0532f44b":"code","2fe647e4":"code","fa5cff45":"code","b0ec5f22":"code","f7d0f318":"code","2da7cc9c":"code","037e5499":"code","6bbad1ad":"code","a267fc28":"code","d5efbb2c":"markdown","04d7bfc1":"markdown","63d1a966":"markdown","69da05d4":"markdown","00f1e497":"markdown","1ac9e538":"markdown","503e2f07":"markdown","4fbb358d":"markdown","bfcf7c73":"markdown","1baec33e":"markdown","44b0ad8b":"markdown","715960c6":"markdown","3b9e2332":"markdown","3120187a":"markdown","bd72d90e":"markdown","c08a3e42":"markdown","6c5ac4a5":"markdown","fadac527":"markdown","562f6bbb":"markdown","37e2a901":"markdown","549965bc":"markdown","6cc93155":"markdown","994d9816":"markdown"},"source":{"82b3b805":"import tensorflow as tf","ed11fa69":"import numpy as np\n\nX_train = np.load('..\/input\/street-view-house-numbers-svhn-dataset-numpy\/X_train.npy')\ny_train = np.load('..\/input\/street-view-house-numbers-svhn-dataset-numpy\/y_train.npy')\nX_test = np.load('..\/input\/street-view-house-numbers-svhn-dataset-numpy\/X_test.npy')\ny_test = np.load('..\/input\/street-view-house-numbers-svhn-dataset-numpy\/y_test.npy')","44b50ce4":"y_train = np.where(y_train==10, 0, y_train)\ny_test = np.where(y_test==10, 0, y_test)","df492fb6":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(13, 5))\ncolumns = 5\nrows = 2\n\n# ax enables access to manipulate each of subplots\nax = []\n\nfor i in range(rows*columns):\n    j = np.random.randint(X_train.shape[3], size=1)[0]\n    img = X_train[:,:,:,j]\n    # create subplot and append to ax    \n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(str(y_train[j][0]))  # set title\n    plt.tick_params(length=0)\n    plt.axis('off')\n    plt.imshow(img)","683a4057":"X_train_gray = X_train.mean(axis=2, keepdims=True)\nX_test_gray = X_test.mean(axis=2, keepdims=True)","c0ccd4b5":"fig = plt.figure(figsize=(13, 5))\ncolumns = 5\nrows = 2\n\n# ax enables access to manipulate each of subplots\nax = []\n\nfor i in range(rows*columns):\n    j = np.random.randint(X_train_gray.shape[3], size=1)[0]\n    img = X_train_gray[:,:,0,j]\n    # create subplot and append to ax    \n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(str(y_train[j][0]))  # set title\n    plt.tick_params(length=0)\n    plt.axis('off')\n    plt.imshow(img)","a983aa66":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ndef get_new_model(input_shape):\n    model = Sequential([\n        Dense(64, activation='relu', input_shape=input_shape, name='dense_1'),\n        Flatten(name='flatten_2'),\n        Dense(128, activation='relu', name='dense_3'),\n        Flatten(name='flatten_4'),\n        Dense(128, activation='relu', name='dense_5'),\n        Flatten(name='flatten_6'),\n        Dense(64, activation='relu', name='dense_7'),\n        Flatten(name='flatten_8'),\n        Dense(10, activation='softmax', name='dense_9')\n    ])\n    \n    model.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy',\n                         ])\n    \n    return model\n\nmodel = get_new_model(X_train_gray[:,:,:,0].shape)","c76fe749":"model.summary()","27c3a7e2":"def get_checkpoint_best_only():\n    checkpoint_path='checkpoints_best_only\/checkpoint'\n    checkpoint= ModelCheckpoint(filepath=checkpoint_path,\n                               frequency='epoch',\n                               save_weights_only=True,\n                               monitor='val_accuracy',\n                                save_best_only=True,\n                               verbose=1)\n    return checkpoint","8293bd34":"def get_early_stopping():\n    callback = tf.keras.callbacks.EarlyStopping(\n                    monitor=\"val_loss\",\n                    patience=8,\n                    verbose=0,\n                    )\n    return callback","64f65ec0":"checkpoint_best_only = get_checkpoint_best_only()\nearly_stopping = get_early_stopping()","9d0dd0fa":"# import os\n# import sys\n# import shutil\n# shutil.rmtree('.\/checkpoints_best_only')","e8115df7":"callbacks = [checkpoint_best_only, early_stopping]\n\ndef train_model(model, X_train_gray, y_train, epochs1=30, callbacks=callbacks):\n    history = model.fit(np.moveaxis(X_train_gray, -1, 0), y_train, epochs=epochs1, \n                  validation_split=0.1 , callbacks=callbacks)\n    return history \n\nhistory = train_model(model, X_train_gray[:,:,:,0:30000], y_train[0:30000])","e888016f":"try:\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\nexcept KeyError:\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\nplt.title('Accuracy vs. epochs MLP model')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='lower right')\nplt.show() ","3b6e38a5":"def get_CNN_model(input_shape=X_train_gray[:,:,:,0].shape, dropout_rate=0.3):\n    model = Sequential([\n        Conv2D(filters=32, input_shape=input_shape, kernel_size=(3,3), activation=\"relu\", \n               padding='SAME', name='conv_1'),\n        Dropout(dropout_rate),\n        Conv2D(32, kernel_size=(3,3), activation=\"relu\", name='conv_2', padding='SAME'),\n        MaxPooling2D(pool_size=(8,8), name='pool_1'),\n        Flatten(name='flatten'),\n        Dropout(dropout_rate),\n        Dense(64, activation='relu', name='dense_1'),\n        Dense(64, activation='relu', name='dense_2'),\n        BatchNormalization(),\n        Dense(10, activation='softmax', name='dense_3')\n    ])\n    \n    model.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy'])\n    \n    return model","20fc3bff":"def get_checkpoint_best_only_CNN():\n    checkpoint_path='checkpoints_best_only_CNN\/checkpoint'\n    checkpoint= ModelCheckpoint(filepath=checkpoint_path,\n                               frequency='epoch',\n                               save_weights_only=True,\n                               monitor='val_accuracy',\n                               save_best_only=True,\n                               verbose=1)\n    return checkpoint","30e1e12e":"from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n\nCNN_model = get_CNN_model()\nCNN_model.summary()","597cd6d2":"checkpoint_best_only_CNN = get_checkpoint_best_only_CNN()\nearly_stopping_CNN = get_early_stopping()","0532f44b":"CNN_callbacks = [checkpoint_best_only_CNN, early_stopping_CNN]\n\ndef train_CNN_model(CNN_model=CNN_model, X_train=X_train_gray[:,:,:,0:30000], y_train=y_train[0:30000],\n                    epochs1=30, callbacks=CNN_callbacks):\n\n    history = CNN_model.fit(np.moveaxis(X_train, -1, 0), y_train, epochs=epochs1, \n                  validation_split=0.1 , callbacks=CNN_callbacks)\n    return history\n\nCNN_history = train_CNN_model()","2fe647e4":"try:\n    plt.plot(CNN_history.history['accuracy'])\n    plt.plot(CNN_history.history['val_accuracy'])\nexcept KeyError:\n    plt.plot(CNN_history.history['acc'])\n    plt.plot(CNN_history.history['val_acc'])\nplt.title('Accuracy vs. epochs CNN_model')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc='lower right')\nplt.show() ","fa5cff45":"model = get_new_model(X_train_gray[:,:,:,0].shape)\nCNN_model = get_CNN_model()","b0ec5f22":"def get_model_best_epoch(model=model, folder=\"checkpoints_best_only\"):\n    path = tf.train.latest_checkpoint(folder)\n    model.load_weights(path) \n    return model\n\nloaded_model = get_model_best_epoch()\nloaded_CNN_model = get_model_best_epoch(CNN_model, \"checkpoints_best_only_CNN\")","f7d0f318":"def get_test_accuracy(model=loaded_model, X_test=X_test_gray, y_test=y_test):\n    test_loss, test_acc = model.evaluate(x=np.moveaxis(X_test, -1, 0), y=y_test, verbose=0)\n    return test_acc\n    \ndef get_test_accuracy_CNN(model=loaded_CNN_model, X_test=X_test_gray, y_test=y_test):\n    test_loss, test_acc = model.evaluate(x=np.moveaxis(X_test, -1, 0), y=y_test, verbose=0)\n    return test_acc","2da7cc9c":"MLP_acc = get_test_accuracy() \nCNN_acc = get_test_accuracy_CNN()\nprint(\"MLP_acc:\" + str(MLP_acc) + \", CNN_acc:\" + str(CNN_acc))","037e5499":"import matplotlib.pyplot as plt\nimport numpy as np\n\nlabels = ['MLP acc', 'CNN acc']\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.20  # the width of the bars\n\nfig, ax = plt.subplots()\nplt.figure(figsize=(5, 5\n                   ))\nrects1 = ax.bar(x - width\/2, [MLP_acc, CNN_acc] , width, label=['MLP acc','CNN acc'], color=['black', 'blue'])\n#rects2 = ax.bar(x + width\/2, CNN_acc, width, label='CNN acc')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Accuracy')\nax.set_title('Accuracy of two models')\nax.set_xticks(x)\nax.yaxis.set_ticks(np.arange(0, 1.1, .2))\nax.set_xticklabels(labels)\n\nfig.tight_layout()\nplt.show()","6bbad1ad":"import pandas as pd\n\nl0 = loaded_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 0,:,:,:])[0]\ndf0 = pd.DataFrame(l0, columns=[\n    'probability'])\ndf0['pred']=df0.index\ndf0 = df0.sort_values(by=['probability'], axis=0, ascending=False)\n\nl00 = loaded_CNN_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 0,:,:,:])[0]\ndf00 = pd.DataFrame(l00, columns=[\n    'probability'])\ndf00['pred']=df00.index\ndf00 = df00.sort_values(by=['probability'], axis=0, ascending=False)\n\nl1 = loaded_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 1,:,:,:])[0]\ndf1 = pd.DataFrame(l1, columns=[\n    'probability'])\ndf1['pred']=df1.index\ndf1 = df1.sort_values(by=['probability'], axis=0, ascending=False)\n\nl11 = loaded_CNN_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 1,:,:,:])[0]\ndf11 = pd.DataFrame(l11, columns=[\n    'probability'])\ndf11['pred']=df11.index\ndf11 = df11.sort_values(by=['probability'], axis=0, ascending=False)\n\nl2 = loaded_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 2,:,:,:])[0]\ndf2 = pd.DataFrame(l2, columns=[\n    'probability'])\ndf2['pred']=df2.index\ndf2 = df2.sort_values(by=['probability'], axis=0, ascending=False)\n\nl22 = loaded_CNN_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 2,:,:,:])[0]\ndf22 = pd.DataFrame(l22, columns=[\n    'probability'])\ndf22['pred']=df22.index\ndf22 = df22.sort_values(by=['probability'], axis=0, ascending=False)\n\nl3 = loaded_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 3,:,:,:])[0]\ndf3 = pd.DataFrame(l3, columns=[\n    'probability'])\ndf3['pred']=df3.index\ndf3 = df3.sort_values(by=['probability'], axis=0, ascending=False)\n\nl33 = loaded_CNN_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 3,:,:,:])[0]\ndf33 = pd.DataFrame(l33, columns=[\n    'probability'])\ndf33['pred']=df33.index\ndf33 = df33.sort_values(by=['probability'], axis=0, ascending=False)\n\nl4 = loaded_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 4,:,:,:])[0]\ndf4 = pd.DataFrame(l4, columns=[\n    'probability'])\ndf4['pred']=df4.index\ndf4 = df4.sort_values(by=['probability'], axis=0, ascending=False)\n\nl44 = loaded_CNN_model.predict(np.moveaxis(X_test_gray, -1, 0)[np.newaxis, 4,:,:,:])[0]\ndf44 = pd.DataFrame(l44, columns=[\n    'probability'])\ndf44['pred']=df44.index\ndf44 = df44.sort_values(by=['probability'], axis=0, ascending=False)","a267fc28":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axs = plt.subplots(2, 5)\n# plt.figure(figsize=(24,.5))\n\naxs[0, 0].imshow(X_test_gray[:,:,0,0],cmap='gray')\naxs[0, 0].set_title(y_test[0][0])\naxs[0, 0].axis('off')\n\n#ax.bar(x - width\/2, [MLP_acc, CNN_acc] , width, label=['MLP acc','CNN acc'], color=['black', 'blue'])\nwidth = 0.20\nlabels1 = list(df0.pred[0:5])\ntitles = \"probability by model\"\nx1 = np.arange(len(labels1))\naxs[1, 0].bar(x1 - width\/2, list(df0.probability[0:5]), width, label=['MLP prob'], color=['black'])\naxs[1, 0].bar(x1 + width\/2, list(df00.probability[0:5]), width, label=['CNN prob'], color=['blue'])\naxs[1, 0].set_xticks(x1)\naxs[1, 0].set_xticklabels(labels1)\naxs[1, 0].yaxis.set_ticks(np.arange(0, 1.1, .5))\naxs[1, 0].legend(['MLP acc','CNN acc'], loc =\"upper right\")\naxs[1, 0].set_title(titles)\n\naxs[0, 1].imshow(X_test_gray[:,:,0,1],cmap='gray')\naxs[0, 1].set_title(y_test[1][0])\naxs[0, 1].axis('off')\n\nlabels2 = list(df1.pred[0:5])\nx2 = np.arange(len(labels2))\naxs[1, 1].bar(x2 - width\/2, list(df1.probability[0:5]), width, label=['MLP prob'], color=['black'])\naxs[1, 1].bar(x2 + width\/2, list(df11.probability[0:5]), width, label=['CNN prob'], color=['blue'])\naxs[1, 1].set_xticks(x2)\naxs[1, 1].set_xticklabels(labels2)\naxs[1, 1].yaxis.set_ticks(np.arange(0, 1.1, .5))\naxs[1, 1].legend(['MLP acc','CNN acc'], loc =\"upper right\")\naxs[1, 1].set_title(titles)\n\naxs[0, 2].imshow(X_test_gray[:,:,0,2],cmap='gray')\naxs[0, 2].set_title(y_test[2][0])\naxs[0, 2].axis('off')\n\nlabels3 = list(df2.pred[0:5])\nx3 = np.arange(len(labels3))\naxs[1, 2].bar(x3 - width\/2, list(df2.probability[0:5]), width, label=['MLP prob'], color=['black'])\naxs[1, 2].bar(x3 + width\/2, list(df22.probability[0:5]), width, label=['CNN prob'], color=['blue'])\naxs[1, 2].set_xticks(x3)\naxs[1, 2].set_xticklabels(labels3)\naxs[1, 2].yaxis.set_ticks(np.arange(0, 1.1, .5))\naxs[1, 2].legend(['MLP acc','CNN acc'], loc =\"upper right\")\naxs[1, 2].set_title(titles)\n\naxs[0, 3].imshow(X_test_gray[:,:,0,3],cmap='gray')\naxs[0, 3].set_title(y_test[3][0])\naxs[0, 3].axis('off')\n\nlabels4 = list(df3.pred[0:5])\nx4 = np.arange(len(labels4))\naxs[1, 3].bar(x4 - width\/2, list(df3.probability[0:5]), width, label=['MLP prob'], color=['black'])\naxs[1, 3].bar(x4 + width\/2, list(df33.probability[0:5]), width, label=['CNN prob'], color=['blue'])\naxs[1, 3].set_xticks(x4)\naxs[1, 3].set_xticklabels(labels4)\naxs[1, 3].legend(['MLP acc','CNN acc'], loc =\"upper right\")\naxs[1, 3].set_title(titles)\n\n\naxs[0, 4].imshow(X_test_gray[:,:,0,4], cmap='gray')\naxs[0, 4].set_title(y_test[4][0])\naxs[0, 4].axis('off')\n\nlabels5 = list(df4.pred[0:5])\nx5 = np.arange(len(labels5))\naxs[1, 4].bar(x5 - width\/2, list(df4.probability[0:5]), width, label=['MLP prob'], color=['black'])\naxs[1, 4].bar(x5 + width\/2, list(df44.probability[0:5]), width, label=['CNN prob'], color=['blue'])\naxs[1, 4].set_xticks(x5)\naxs[1, 4].set_xticklabels(labels5)\naxs[1, 4].legend(['MLP acc','CNN acc'], loc =\"upper right\")\naxs[1, 4].set_title(titles)\n\nplt.subplots_adjust(left=None, bottom=None, right=2, top=1.5, wspace=None, hspace=None)\nplt.figure(figsize=(13,5))","d5efbb2c":"The EarlyStopping module stop the training process if the validation accuracy doesn't improve after the patience argument value","04d7bfc1":"Let's start the training process","63d1a966":"Now we reduce the images' channels to make the processing faster. To do this, we take the mean value between channels","69da05d4":"We can see that the CNN model certainty is higher than the MLP in all of this predictions, and the models just fails in the fourth image!","00f1e497":"Now we can see that even that the CNN model has by far less parameters, it ouperformed the MLP model","1ac9e538":"Now, we build an Miltilayer Perceptron (MLP) classifier","503e2f07":"The label '0' is as '10' in the original dataset, so we are gonna replace this value","4fbb358d":"# Transform the dataset: reducing channels","bfcf7c73":"*Thanks to the London Imperial College to bring me the knowledge to make this notebook*","1baec33e":"This function loads the weights of the models","44b0ad8b":"The data of the dataset was downloaded from http:\/\/ufldl.stanford.edu\/housenumbers\/\nand tranformed into numpy","715960c6":"# Building a CNN model","3b9e2332":"Let's build a Convolutional Neural Network model to see the accuracy","3120187a":"# loading the data","bd72d90e":"We can see that the best accuracy we got was 0.745, let's try the CNN model","c08a3e42":"The keras ModelCheckpoint module saves the weights of the model layers that get the best validation accuracy during the training process","6c5ac4a5":"With the functions above we get the test accuracy of the two models","fadac527":"And let's see our model","562f6bbb":"# Test accuracy","37e2a901":"# Building an MLP classifier","549965bc":"# Predictions' probability distribution","6cc93155":"We can see than the test accuracy achieved by the CNN model it's higher","994d9816":"And then display 10 random images and its labels"}}