{"cell_type":{"63586ce8":"code","f5a675b1":"code","abb24135":"code","88612f1c":"code","87b71556":"code","39a3717f":"code","ea641929":"code","d0f28a2a":"code","b3919bee":"code","1aa70af8":"code","6e231c4c":"code","3098ceac":"code","30c07c5a":"code","9f40edf5":"code","4848ceb5":"code","666bdc4d":"code","1b219111":"code","64bb1361":"code","901f7312":"code","c688bcff":"code","4a84f6ee":"code","b672a7fb":"code","776071e3":"code","26c1ff7e":"code","2c7ce1b5":"code","6c99323f":"markdown","b1e41f5c":"markdown","b4ff3b64":"markdown","bca6f6cf":"markdown","0364a4ff":"markdown","7e4eafa1":"markdown"},"source":{"63586ce8":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport os\nprint(os.listdir(\"..\/input\"))","f5a675b1":"# Thanks to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n#        else:\n#            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","abb24135":"df_train = pd.read_csv('..\/input\/train_V2.csv', index_col='Id')\ndf_train.shape","88612f1c":"df_train = reduce_mem_usage(df_train)","87b71556":"df_train.head().T","39a3717f":"df_test = pd.read_csv('..\/input\/test_V2.csv', index_col = 'Id')\ndf_test.shape","ea641929":"df_test = reduce_mem_usage(df_test)","d0f28a2a":"df_test_id = pd.DataFrame(index=df_test.index)","b3919bee":"part_train = 0.05\npart_valid = 0.05","1aa70af8":"match_ids = df_train['matchId'].unique()\nmatch_ids_train = np.random.choice(match_ids, int(part_train * len(match_ids)))\nlen(match_ids_train)","6e231c4c":"df_train_train = df_train[df_train['matchId'].isin(match_ids_train)]\ndf_train_train.shape[0]","3098ceac":"match_ids_valid = np.random.choice(np.setdiff1d(match_ids, match_ids_train), int(part_valid * len(match_ids)))\nlen(match_ids_valid)","30c07c5a":"del df_train\ndel match_ids\ndel match_ids_train","9f40edf5":"# Thanks to many kernels in the competition\n\ndef feature_engineering(df, is_train=True):\n    \n    # fix rank points\n    df['rankPoints'] = np.where(df['rankPoints'] <= 0, 0, df['rankPoints'])\n    \n    features = list(df.columns)\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchDuration\")\n    features.remove(\"matchType\")\n    if 'winPlacePerc' in features:\n        features.remove('winPlacePerc')\n    \n    y = None\n    \n    # average y for training dataset\n    if is_train:\n        y = df.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean')\n    elif 'winPlacePerc' in df.columns:\n        y = df['winPlacePerc']\n    \n    # mean by match and group\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train:\n        df_out = agg.reset_index()[['matchId','groupId']]\n    else:\n        df_out = df[['matchId','groupId']]\n    \n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # max by match and group\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # max by match and group\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # number of players in group\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    \n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    # mean by match\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    \n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    # number of groups in match\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    \n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    # drop match id and group id\n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n    \n    del agg, agg_rank\n    \n    return df_out, y","4848ceb5":"%%time\nfe_x_train, fe_y_train = feature_engineering(df_train_train, is_train=True)","666bdc4d":"fe_x_train.shape","1b219111":"del df_train_train","64bb1361":"%%time\nfe_x_test, t = feature_engineering(df_test, is_train=False)","901f7312":"fe_x_test.shape","c688bcff":"del df_test","4a84f6ee":"%%time\nrf = RandomForestRegressor(n_estimators=30, criterion='mae', n_jobs=-1)\nrf.fit(fe_x_train, fe_y_train)\nrf_y_pred = rf.predict(fe_x_test)","b672a7fb":"# Thanks to https:\/\/www.kaggle.com\/anycode\/simple-nn-baseline-4\n\ndef fix_pred(x, pred):\n    \n    updated_pred = []\n    for i in range(len(x)):\n        winPlacePerc = pred[i]\n        \n        maxPlace = int(x.iloc[i]['maxPlace'])\n        if maxPlace == 0:\n            winPlacePerc = 0.0\n        elif maxPlace == 1:\n            winPlacePerc = 1.0\n        else:\n            gap = 1.0 \/ (maxPlace - 1)\n            winPlacePerc = round(winPlacePerc \/ gap) * gap\n        \n        if winPlacePerc < 0: winPlacePerc = 0.0\n        if winPlacePerc > 1: winPlacePerc = 1.0\n        \n        updated_pred.append(winPlacePerc)\n    \n    return updated_pred","776071e3":"%%time\nfixed_rf_y_pred = fix_pred(fe_x_test, rf_y_pred)","26c1ff7e":"def make_submission(x, y, filename):\n    submission = pd.DataFrame(index=x.index)\n    submission['winPlacePerc'] = np.clip(y, a_min=0, a_max=1)\n    submission.to_csv(filename, index_label='Id')","2c7ce1b5":"make_submission(df_test_id, fixed_rf_y_pred, 'random_forest_baseline.csv')","6c99323f":"## Feature engineering","b1e41f5c":"## Load data\n\n* Load\n* Reduce memory usage","b4ff3b64":"## Preprocessing\n\n* Get prtion of data preserving matches","bca6f6cf":"## Random forest baseline\n\nParameters retrieved by multiple executions of the kernel (because of time limit).","0364a4ff":"# Random forest baseline","7e4eafa1":"## Submission"}}