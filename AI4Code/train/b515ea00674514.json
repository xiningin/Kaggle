{"cell_type":{"12531353":"code","379a7bc2":"code","70b74459":"code","5176690d":"code","f608a279":"code","88db06c1":"code","ad50e3e0":"code","160dca37":"code","51386ef7":"code","dd950a05":"code","8c768442":"code","6ac6a151":"code","f464be81":"code","59ae720c":"code","140f6a62":"code","b9d1c413":"code","78e9982e":"code","8b67da70":"code","ac37703f":"code","8b51f670":"code","e07b7ae4":"code","f505fe3f":"code","7a3be112":"code","f7c9cfff":"code","84db9005":"code","314a0b9f":"code","8ad9ff57":"code","bc56b097":"code","eeb6b879":"code","cf2db1ef":"code","48420792":"code","8ebcf27f":"code","0a0522a1":"code","bf5c3de7":"code","b24c92bc":"code","8c9f8e1c":"code","38138325":"code","613126b8":"code","cabd2892":"code","7c82032a":"code","1e0e8939":"code","08e4ea5b":"code","ca82dc22":"markdown","7c1c9be6":"markdown","28ea07b5":"markdown","9222215d":"markdown","17a24f94":"markdown","183c6a09":"markdown","54a39477":"markdown","a5032ef1":"markdown","8c9d646a":"markdown","628cdb85":"markdown","c79e1245":"markdown","96cc18a4":"markdown","70b47a06":"markdown","d428c4f2":"markdown","8f57a853":"markdown","598f58eb":"markdown"},"source":{"12531353":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","379a7bc2":"import pandas as pd \nimport cv2                 \nimport numpy as np         \nimport os                  \nfrom random import shuffle\nfrom tqdm import tqdm  \nimport scipy\nimport skimage\nfrom skimage.transform import resize\nfrom PIL import Image\nimport sklearn","70b74459":"print(os.listdir(\"\/kaggle\/input\/papsmeardatasets\/\"))\nHerlev = \"\/kaggle\/input\/papsmeardatasets\/herlev_pap_smear\/\"\nSipak = \"\/kaggle\/input\/papsmeardatasets\/sipakmed_fci_pap_smear\/\"","5176690d":"Lista_H = os.listdir(Herlev)","f608a279":"def get_label(Dir):\n    for nextDir in os.listdir(Dir):\n            if nextDir.startswith('normal') or nextDir.startswith('benign'):\n                label = 0\n            elif nextDir.startswith('abnormal'):\n                label = 1\n            \n    return nextDir, label","88db06c1":"def get_data(Dir):\n    X = []\n    y = []\n    \n    for dir_name in Dir:\n        for nextDir in os.listdir(dir_name):\n            if not nextDir.startswith('.'):\n                if nextDir.startswith('normal'):\n                    label = 0\n                elif nextDir.startswith('abnormal') or nextDir.startswith('benign'):\n                    label = 1\n                \n\n\n                temp = dir_name + nextDir\n\n                for file in tqdm(os.listdir(temp)):\n                    if not file.endswith('d.bmp') and not file.endswith('dat'):\n                        img = cv2.imread(temp + '\/' + file)\n                        if img is not None:\n                            img = skimage.transform.resize(img, (64,64,3))\n                            #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n                            img = np.asarray(img)\n                            X.append(img)\n                            y.append(label)\n                    \n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y","ad50e3e0":"Lista = [Herlev, Sipak]","160dca37":"X_train, y_train = get_data(Lista)","51386ef7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt","dd950a05":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15)","8c768442":"classifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Conv2D(64, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a third convolutional layer\nclassifier.add(Conv2D(128, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a fourth convolutional layer\nclassifier.add(Conv2D(128, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dropout(0.4))\nclassifier.add(Dense(units = 64, activation = 'relu'))\nclassifier.add(Dense(units = 1, activation = 'sigmoid'))\n\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =[\"accuracy\",tf.keras.metrics.Recall(\n    thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n)])\n#metrics =[ tf.keras.metrics.Recall()]\nplot_model(classifier, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)\ndisplay(Image.open('cnn_model.png'))\n","6ac6a151":"\n\nclassifier.fit(X_train, y_train,validation_split = 0.1,  epochs=20)","f464be81":"\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt","59ae720c":"print(classifier.history.history.keys())","140f6a62":"plt.plot(classifier.history.history['accuracy'])\nplt.plot(classifier.history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n#history1.history['val_loss']\n# Plot training & validation loss values\nplt.plot(classifier.history.history['loss'])\nplt.plot(classifier.history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","b9d1c413":"classifier.save('Cell_predict')","78e9982e":"new_model = tf.keras.models.load_model('Cell_predict')","8b67da70":"predictions = new_model.predict([X_test])","ac37703f":"niz = np.arange(0.0, 1.01, 0.01)","8b51f670":"def zaok(a, x):\n    if a >= x:\n        return 1\n    else:\n        return 0","e07b7ae4":"y_test[0] == np.rint(predictions[0])","f505fe3f":"TP = 0\nFP = 0\nTN = 0\nFN = 0\nfor (i, j) in zip (y_test, predictions):\n    if i == 0:\n        if i == np.rint(j):\n            TN += 1\n        else:\n            FP += 1\n    elif i == 1:\n        if i == np.rint(j):\n            TP += 1\n        else:\n            FN += 1\n     \n            ","7a3be112":"print(TP, FP, TN, FN)","f7c9cfff":"def prec(TP,FP):\n    return TP\/(TP+FP)\ndef rec(TP, FN):\n    return TP\/(TP+FN)","84db9005":"precision = []\nrecall = []\npom_pred = []\n\nfor k in niz:\n    TP_1 = 0\n    FP_1 = 0\n    TN_1 = 0\n    FN_1 = 0\n    for (i, j) in zip (y_test, predictions):\n        if i == 0:\n            if i == zaok(j, k):\n                TN_1 += 1\n            else:\n                FP_1 += 1\n        elif i == 1:\n            if i == zaok(j, k):\n                TP_1 += 1\n            else:\n                FN_1 += 1\n    precision.append(prec(TP_1,FP_1))\n    recall.append(rec(TP_1,FN_1))\n    \n    \n    ","314a0b9f":"brojac = 0\n\nfor (i, j) in zip (y_test, predictions):\n    if i != np.rint(j):\n        brojac += 1\n    ","8ad9ff57":"accu = 1 - brojac\/len(y_test)","bc56b097":"print('Accuracy je:', accu)","eeb6b879":"Rec_ = TP\/(FN+TP)","cf2db1ef":"print(Rec_)","48420792":"Pre_ = TP\/(FP+TP)","8ebcf27f":"print(Pre_)","0a0522a1":"plt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.annotate('Najbolji Recall i precision', xy=(Rec_, Pre_), xytext=(1, 1.1),\n            arrowprops=dict(facecolor='black', shrink=0.002),\n            )","bf5c3de7":"y_pred = []\nfor i in predictions:\n    y_pred.append(np.rint(i))\n","b24c92bc":"arr = np.rint(predictions)","8c9f8e1c":"y_pred2 = []\nfor i in y_pred:\n    y_pred2.append(i[0])","38138325":"cm = sklearn.metrics.confusion_matrix(y_test,arr)","613126b8":"from sklearn.metrics import plot_confusion_matrix","cabd2892":"cm","7c82032a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncn = sns.light_palette(\"blue\", as_cmap=True)\nx=pd.DataFrame(cm)\nx=x.style.background_gradient(cmap=cn)\ndisplay(x)","1e0e8939":"%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n","08e4ea5b":"plt.imshow(cm, interpolation='nearest', cmap=cn)\nplt.title(\"Matrica konfuzije\")\nplt.colorbar()\ntick_marks = np.arange(2)\nplt.xticks(tick_marks, ['Negative', 'Positive'], rotation=45)\nplt.yticks(tick_marks, ['P', 'N'])\n\n#if normalize:\n#    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n#    print(\"Normalized confusion matrix\")\n#else:\n#    print('Confusion matrix, without normalization')\n\n#print(cm)\n\nthresh = cm.max() \/ 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n        horizontalalignment=\"center\",\n        color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","ca82dc22":"## Matrica konfuzije","7c1c9be6":"## Accuracy\n","28ea07b5":"# Pristup datasetu","9222215d":"Dijelimo dataset na trening i test.","17a24f94":"Na trening setu od 3798 slika i validacijskom setu od 423 uvje\u017eban je CNN. ","183c6a09":"# Prou\u010davanje predikcije za test set od 745 slika","54a39477":"Resizeanje slika na 64 x 64 za CNN.\nDavanje labela ( abnormalna = 1, normalna = 0).\nVra\u0107a listu slika i labela.","a5032ef1":"Graf: Precision i recall, u ovisnosti o decision funkciji","8c9d646a":"## Broj pogre\u0161nih predikcija","628cdb85":"Recall","c79e1245":"## Prebrojavanje TP, TN, FP, FN","96cc18a4":"Precision","70b47a06":"## Matrica konfuzije ve\u0107a\n","d428c4f2":"pomo\u0107na funkcija","8f57a853":"Ispod je CNN za binarnu klasifikaciju","598f58eb":"## Graf "}}