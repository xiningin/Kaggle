{"cell_type":{"87ac4ab0":"code","3211aa9f":"code","1a4d7a3c":"code","eec871b3":"code","107c28a4":"code","46e63814":"code","d19c44aa":"code","76035400":"code","46767c4b":"code","8c231278":"code","ba591cf6":"code","185edf15":"code","715fc4c5":"code","e651461b":"code","e2e3c643":"code","a8bf262d":"code","3b07873a":"code","29af0696":"code","faa86824":"code","5e82bb96":"code","d49eefb7":"code","93143137":"code","c5d0b1c8":"markdown","2b505f6b":"markdown","a6d356ed":"markdown","7e8e6b02":"markdown","eca46db6":"markdown","954678b7":"markdown","850f8944":"markdown","52c1c9ec":"markdown"},"source":{"87ac4ab0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3211aa9f":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport itertools\n","1a4d7a3c":"#Reading data as pandas dataframe\nframe = pd.read_csv('..\/input\/textdb3\/fake_or_real_news.csv')\n\n#Inspecing Shape\nprint(frame.shape)\n\n#Inspecting top 5 rows\nframe.head()","eec871b3":"#Setting the DataFrame index (row labels) using one or more existing columns\nframe = frame.set_index(\"Unnamed: 0\")\nframe.head()","107c28a4":"y = frame.label\ny.head()","46e63814":"frame.drop(\"label\", axis=1)\nframe.head()","d19c44aa":"X_train, X_test, y_train, y_test = train_test_split(frame['text'], y, test_size=0.33, random_state=53)\nX_train.head()","76035400":"y_train.head()","46767c4b":"# Initialize the `count_vectorizer` \ncount_vectorizer = CountVectorizer(stop_words='english')\n\n# Fit and transform the training data.\ncount_train = count_vectorizer.fit_transform(X_train)\n\n# Transform the test set \ncount_test = count_vectorizer.transform(X_test)","8c231278":"# Initialize the `tfidf_vectorizer` \ntfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n\n# Fit and transform the training data \ntfidf_train = tfidf_vectorizer.fit_transform(X_train) \n\n# Transform the test set \ntfidf_test = tfidf_vectorizer.transform(X_test)","ba591cf6":"\nprint(tfidf_test)","185edf15":"# Get the feature names of `tfidf_vectorizer` \nprint(tfidf_vectorizer.get_feature_names()[-10:])","715fc4c5":"# Get the feature names of `count_vectorizer` \nprint(count_vectorizer.get_feature_names()[0:10])","e651461b":"count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\ntfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\ndifference = set(count_df.columns) - set(tfidf_df.columns)\ndifference\nset()\nprint(count_df.equals(tfidf_df))\ncount_df.head()","e2e3c643":"import matplotlib.pyplot as plt\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    See full source and example: \n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n    \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","a8bf262d":"clf = MultinomialNB() \nclf.fit(tfidf_train, y_train)\npred = clf.predict(tfidf_test)\nscore = accuracy_score(y_test, pred)\nprint(\"accuracy:   %0.3f\" % score)\ncm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","3b07873a":"clf = MultinomialNB() \nclf.fit(count_train, y_train)\npred = clf.predict(count_test)\nscore = accuracy_score(y_test, pred)\nprint(\"accuracy:   %0.3f\" % score)\ncm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","29af0696":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_clf = PassiveAggressiveClassifier(n_iter_no_change=50)\nlinear_clf.fit(tfidf_train, y_train)\npred = linear_clf.predict(tfidf_test)\nscore = accuracy_score(y_test, pred)\nprint(\"accuracy:   %0.3f\" % score)\ncm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","faa86824":"def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n    \"\"\"\n    See: https:\/\/stackoverflow.com\/a\/26980472\n    \n    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n    of weighted features you would like to show. (Note: current implementation merely prints and does not \n    return top classes.)\n    \"\"\"\n\n    class_labels = classifier.classes_\n    feature_names = vectorizer.get_feature_names()\n    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n\n    for coef, feat in topn_class1:\n        print(class_labels[0], coef, feat)\n\n    print()\n\n    for coef, feat in reversed(topn_class2):\n        print(class_labels[1], coef, feat)\n\n\nmost_informative_feature_for_binary_classification(tfidf_vectorizer, linear_clf, n=30)","5e82bb96":"feature_names = tfidf_vectorizer.get_feature_names()\nsorted(zip(clf.coef_[0], feature_names), reverse=True)[:20]","d49eefb7":"### Most fake\nsorted(zip(clf.coef_[0], feature_names))[:20]","93143137":"tokens_with_weights = sorted(list(zip(feature_names, clf.coef_[0])))\nfor i in tokens_with_weights:\n    print(i)\n    break","c5d0b1c8":"**Building Vectorizer Classifiers**","2b505f6b":"Drawing Confusion Matrix With TfIdf Vectorizer","a6d356ed":"Drawing Confusion Matrix With Passive Agressive Classifier","7e8e6b02":"Values of Token Generated by Both The Vectorizers Are Same","eca46db6":"1. By Using Count Vectorizer","954678b7":"Drawing Confusion Matrix With Bag Of Words (Count Vectorizer)","850f8944":"Confusion Matrix","52c1c9ec":"2. By Using Tf-IDF Vectorizer"}}