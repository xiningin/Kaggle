{"cell_type":{"a7827796":"code","27d1b19d":"code","9d42eebf":"code","f6334ba0":"code","89440d6f":"code","f8b238f2":"code","d8d42c0a":"code","0c4df77d":"code","96136820":"code","c9f30cf3":"code","7f043f2f":"code","2fe8b820":"code","60e9d7c7":"code","e61c076c":"code","0421bd77":"code","25b58aa8":"code","f0ccd4c3":"code","45924cd6":"code","62930465":"code","b1d34504":"code","d6afdf81":"code","bfbd4761":"code","96ce0145":"code","7ff7f9a2":"code","efe4732d":"code","92bb838a":"code","4ac44c34":"code","3bf24e2b":"code","3f25dd66":"code","06f785a2":"code","6a824372":"code","6b739676":"code","9a7e06a1":"code","c1afb429":"code","75611826":"code","44b7dc75":"code","b2d4f7e3":"code","a28aaec3":"code","1fb15674":"code","5626de3f":"code","0b04a390":"code","13eae502":"code","1e8206db":"code","6dce1362":"markdown","6db89824":"markdown","be646bd1":"markdown","c85960ce":"markdown","aa98c70c":"markdown","212d5013":"markdown","128a9781":"markdown","71eae449":"markdown","d4280e9a":"markdown","860eb959":"markdown","0787a641":"markdown","2b593feb":"markdown","2fe07b18":"markdown","9b40bfc3":"markdown"},"source":{"a7827796":"raw_data=\"..\/input\/brazilian-ecommerce\"","27d1b19d":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","9d42eebf":"# read them all\n\ncustomers=pd.read_csv(raw_data + \"\/olist_customers_dataset.csv\")           \ngeolocation=pd.read_csv(raw_data + \"\/olist_geolocation_dataset.csv\")         \norder_items=pd.read_csv(raw_data + \"\/olist_order_items_dataset.csv\")         \norder_payments=pd.read_csv(raw_data + \"\/olist_order_payments_dataset.csv\")      \norder_reviews=pd.read_csv(raw_data + \"\/olist_order_reviews_dataset.csv\")\norders=pd.read_csv(raw_data + \"\/olist_orders_dataset.csv\")\nproducts=pd.read_csv(raw_data + \"\/olist_products_dataset.csv\")\nsellers=pd.read_csv(raw_data + \"\/olist_sellers_dataset.csv\")\nproduct_category= pd.read_csv(raw_data + \"\/product_category_name_translation.csv\")","f6334ba0":"customers.head()","89440d6f":"# are there some duplicated data\nlen(np.unique(customers.customer_id)),len(np.unique(customers.customer_unique_id)), customers.shape[0]","f8b238f2":"# check for duplicates in a dataframe for given column\n\ndef duplicateRowsDataFrame(df, var):\n    '''df: dataframe\n       var: a column between quotes'''\n    # you could think of adding verbose parameter\n    return df[df.duplicated(subset=[var], keep=False)].sort_values(var, ascending=False) ","d8d42c0a":"duplicateRowsDataFrame(customers, 'customer_id')\n# customer_id have no duplicate","0c4df77d":"# customer_unique_id have some duplicates\ncustomers[customers.duplicated(subset=['customer_unique_id'], keep=False)].sort_values('customer_unique_id')[:5]","96136820":"order_items.head(3)","c9f30cf3":"duplicateRowsDataFrame(order_items,'order_id').head(5)","7f043f2f":"order_items_df=pd.DataFrame(order_items.groupby('order_id')['order_item_id'].sum()).merge(order_items.groupby('order_id')['price','freight_value'].first(),\n                                  on='order_id')\n","2fe8b820":"order_items_df.columns=['nb_order_items','price', 'freight_value']","60e9d7c7":"order_items_df.head()","e61c076c":"order_payments.head(3)","0421bd77":"order_payments.payment_type.value_counts()","25b58aa8":"# we just drop 3 rows\norder_payments.loc[order_payments.payment_type!='not_defined'].shape, order_payments.shape","f0ccd4c3":"order_payments=order_payments.loc[order_payments.payment_type!='not_defined']","45924cd6":"# we create some dummy features for credit card payment type \norder_payments['credit_card_type']=np.where(order_payments.payment_type=='credit_card', 1, 0)\norder_payments['boleto_type']= np.where(order_payments.payment_type=='boleto', 1, 0)\norder_payments['voucher_type']=np.where(order_payments.payment_type=='voucher', 1, 0)\norder_payments['debit_card_type']=np.where(order_payments.payment_type=='debit_card', 1, 0)","62930465":"#payment_type number per order\n\norder_payments['payment_type_number']=( order_payments['credit_card_type']+order_payments['boleto_type']+\n                                     order_payments['voucher_type']+order_payments['debit_card_type'])","b1d34504":"order_payments_df=order_payments.groupby('order_id')['payment_sequential',\n                                                     'payment_installments', 'payment_value',\n                                                    'credit_card_type', 'boleto_type', 'voucher_type', \n                                                     'debit_card_type', 'payment_type_number'].sum()","d6afdf81":"# rename columns\norder_payments_df.columns=['payment_sequential_nb', 'payment_instlmt_order_nb', 'total_payment_value',\n       'credit_card_type_nb', 'boleto_type_nb', 'voucher_type_nb', 'debit_card_type_nb', 'payment_type_nb']","bfbd4761":"# Interesting isn't?\norder_payments_df.loc[order_payments_df.payment_type_nb >1].sort_values('payment_type_nb', ascending=False)[:5]","96ce0145":"order_payments_df.shape","7ff7f9a2":"order_reviews.head(3)","efe4732d":"duplicateRowsDataFrame(order_reviews,'order_id').head(5)","92bb838a":"order_reviews.groupby('order_id')['review_id'].count().sort_values(ascending=False)","4ac44c34":"order_reviews_df=pd.DataFrame(order_reviews.groupby('order_id')['review_score'].mean()) \\\n                             .merge(order_reviews.groupby('order_id')['review_id'].count(), on='order_id')","3bf24e2b":"order_reviews_df.columns=['review_score_mean', 'review_nb']","3f25dd66":"order_reviews_df.sort_values('review_nb', ascending=False)[:5]","06f785a2":"orders.shape[0], len(orders.groupby('order_id')), len(orders.groupby('customer_id'))","6a824372":"orders.order_status.value_counts()","6b739676":"orders2=orders.loc[orders.order_status=='delivered']","9a7e06a1":"orders2.head(3)","c1afb429":"orders_df=orders2[['order_id', 'customer_id']]","75611826":"orders_df.head()","44b7dc75":"# drop customer_zip_code_prefix\ncustomers_df=customers.drop('customer_zip_code_prefix', axis=1)","b2d4f7e3":"# merge\ncustomers_orders_df=orders_df.merge(order_items_df, on='order_id').merge(order_reviews_df,\n                 on='order_id').merge(order_payments_df, on='order_id').merge(customers_df, on='customer_id')","a28aaec3":"customers_orders_df.head()","1fb15674":"# drop 'customer_id', 'order_id \ncustomers_orders_df.drop(columns=['customer_id', 'order_id'], inplace=True)","5626de3f":"# take customer_unique_id as the new key identifier for our customer dataset\ncustomers_orders_df.drop_duplicates(subset=['customer_unique_id'], keep='first', inplace=True)","0b04a390":"# put customer_unique_id as the index\ncustomers_orders_df.set_index('customer_unique_id', inplace=True)","13eae502":"customers_orders_df.head()","1e8206db":"customers_orders_df.shape","6dce1362":"The next step is going to be the segmentation process.  ","6db89824":"**payment_type** is an interesting column.\n\nI think credit card type can say a lot about a customer characteristics.\nwe are going to discard the not_defined category and build indicators for the 5 categories.\n\nMay be the number of payment type per order is usefull.\n\nAnd then collapse our quantitative data to the order_id as unique key entry for the table set.\n","be646bd1":"Three reviews max per order, but still..","c85960ce":"We can see below that all columns in this dataset are duplicated. It is quite normal. It is an inventory table.\nMany orders are made for the same product, with differents item qantities, for a given price, and so on.\n\nWe are going to collapse the dataset by making the order_id as unique key and grouping it by :\n- the number of order_item by order\n- the first  value of the price\n- the first value of the freight value","aa98c70c":"**customer_id** is unique key for the orders dataset. Each order has a unique customer_id.\n**customers_unique_id** is the unique identifier of a customer in the customers dataset. This is the one that we are going to use in our final dataset.\n","212d5013":"#### ORDER PAYMENT DATASET\n\nThis dataset includes data about orders payments options.\n\n- **payment_sequential** : a customer may pay an order with more than one payment method. If he does so, a sequence will be created to\n\n- **payment_installments**: number of installement (versement in french)\n\n- **order_id**: unique identifier of an order.\n- **payment_value**\n\n- **payment_type**: method of payment chosen by the customer.","128a9781":"We can see many review_id per order_id.  Let's use that inforamtion to create our features","71eae449":"# MERGE ","d4280e9a":"The main dataset for merging orders is the order dataset. Here the order_id column is unique and the customer_id column is unique too.\n\nWe are going to use this dataset to merge order_items_df, order_payments_df, order_reviews_df and then see what we can do with the customers dataset.\n\nFor more consistency let's only work on data, where the customers have a status_order equal to delivered.\n","860eb959":"## Customers Segmentation\n\nOur **objective** is to do customers segmentation, therefore we are going to be interested in only features that could matter in that case. \n\nHow could we know that ?\n\nI guess, we are going to be the guest of guess...(you are joking, right?). No, we are  going to use our common sens, if we have one, sometimes we think we have it, but do we? I guess so. Exploration data analysis would be of good help (now you are talking real).\n\nMainly we are going to be interested in the orders and customer dataset.\n\nThroughout the process of merging datasets, we are going to use a bottom up approach, in the sens that we are going to start with orders payments, items collections, products up to customers identity and informations.\n","0787a641":"#### ORDER DATASET","2b593feb":"#### ORDER REVIEWS DATASET\n\norder_reviews dataset is interesting for customers satisfaction, but is it for customers segmentation?\n\nAfter a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product (or at the estimated delivery date due), the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments.\n\nTherefore since a customer can have many orders, he can make many reviews.\nthe review_id row is duplicated, but by taking order_id as entry key, we can take the mean of the revew_score, and create a number of reviews per order feature(that could highlight something...The more we talk about it, the more we are unsatified, is that true?) \n","2fe07b18":"This is a Brazilian ecommerce public dataset of orders made at Olist Store. The dataset has information of 100k **orders** from 2016 to 2018 made at multiple marketplaces in Brazil. \n\nIts features allows viewing an order from multiple dimensions: from **order status**, price, payment and freight performance to customer location, product attributes and finally reviews written by customers. We also released a geolocation dataset that relates Brazilian zip codes to lat\/lng coordinates.\n\nThis is real commercial data, it has been anonymised, and references to the companies and partners in the review text have been replaced with the names of Game of Thrones great houses.\n\n\n![image.png](attachment:image.png)","9b40bfc3":"#### ORDER ITEMS DATASET\n\nIt is composed of those columns : *order_id , order_item_id , product_id, seller_id, shipping_limit_date, price,\tfreight_value*.\nAre they all matter for our job?\n\n"}}