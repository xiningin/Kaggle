{"cell_type":{"cf3877d5":"code","0be514e7":"code","8781b2c0":"code","a5f6ea18":"code","833a528c":"code","00e66b77":"code","fd376abd":"code","6e1c7551":"code","167ac001":"code","419d0f73":"code","284a5fd9":"code","e09b6ddc":"code","094dba3c":"code","5f7bfccd":"code","1ffb2d5c":"code","afa98e6b":"code","fa8baa39":"code","8d1d9e7b":"code","cfdd1aa8":"code","fba897cd":"code","9a3f1bf5":"code","a90dc382":"code","c8b3033b":"code","0d867f51":"code","4d05e00a":"code","e290cc1f":"code","2892d800":"code","96c8b9c0":"code","581ed359":"code","c5075f98":"code","0c52bd0f":"code","fb5b9651":"code","a398dbdd":"code","cade5916":"code","c74e5b85":"code","d208a1fc":"code","2505bcef":"code","952adda4":"code","49777288":"code","89f8ae46":"code","ff36a96d":"code","4251b9b7":"code","01e23763":"code","66eea6c2":"code","de1fc745":"code","5681bc88":"code","cda7840f":"code","d3af14db":"code","0ea0f467":"code","bac97408":"code","b3518e53":"code","1dc5c747":"code","58c6af02":"code","f6c81859":"code","cbe3b702":"code","53b1058a":"code","4b2c8fec":"code","d4b1fbaf":"code","7bed4fb0":"code","7d5da45e":"code","70fd88dc":"code","de24f154":"code","140f8144":"code","32efcfb4":"code","516c5988":"code","b81db37a":"code","97e3b052":"code","77149e93":"code","bfc826ce":"code","b3fd7be0":"code","3e2909dc":"code","4300c3dd":"code","b803c305":"code","aa2a61da":"code","44e2357e":"code","3ddf8a73":"code","71aa8b0b":"code","37a8efdb":"code","15640916":"code","5fa65558":"code","4154c263":"code","f1a7fd62":"code","0f7aa7b8":"code","7cf703e4":"code","b5a5a744":"code","40b31268":"code","6f220d6b":"code","8cb06d98":"markdown","61ec3880":"markdown","6581727e":"markdown","42de2746":"markdown","426a5263":"markdown","0e7635db":"markdown","83ae85a3":"markdown","41eb59d7":"markdown","64de8848":"markdown","8607d29a":"markdown","36865e0e":"markdown","7c9e8982":"markdown","0d095aaa":"markdown","d7ded060":"markdown","e35c1f28":"markdown","5d5eed6f":"markdown","5caf21a9":"markdown","7a458b86":"markdown","185a5acd":"markdown","dec81d0f":"markdown","6ec97a83":"markdown","deb3b02d":"markdown","cd66f893":"markdown","159798f3":"markdown","6e17d11c":"markdown","61f13e1a":"markdown","4877e6e4":"markdown","e1b56f5e":"markdown","d86ab857":"markdown","8664d887":"markdown","59ac351d":"markdown","97ad2e44":"markdown","fbafd43f":"markdown","8c9f89f4":"markdown","8f938cbb":"markdown","7ed6c927":"markdown","2537b69a":"markdown","bb77cc71":"markdown","f434d8ae":"markdown","90ee9dd1":"markdown","6f64d7fc":"markdown","bafea676":"markdown","3732d374":"markdown","7ae3ae59":"markdown","e51c10d7":"markdown","ca6666af":"markdown","bc738716":"markdown","3eff55ff":"markdown"},"source":{"cf3877d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.figure_factory as ff\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport plotly.offline as py\nimport plotly.express as px\nimport seaborn as sns\nimport random\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0be514e7":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","8781b2c0":"train_df.columns","a5f6ea18":"train_df.head()","833a528c":"train_df.describe()","00e66b77":"train_df.info()","fd376abd":"def pie_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: pie plot & value count\n    \"\"\"\n    #get feature\n    var = train_df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    #visualize\n    fig = px.pie(values=varValue,names=varValue.index,template=\"plotly_white\",title=\"Titanic Pie Plot in {} column\".format(variable))\n    fig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\n    fig.show()\n    print(\"{}:\\n{}\".format(variable,varValue))","6e1c7551":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: pie plot & value count\n    \"\"\"\n    #get feature\n    var = train_df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    #visualize\n    fig = px.bar(y=varValue,x=varValue.index,template=\"plotly_white\",title=\"Titanic Bar Plot in {} column\".format(variable),color=varValue.index)\n    fig.update_layout(showlegend=True)\n    fig.show()\n    print(\"{}:\\n{}\".format(variable,varValue))","167ac001":"categoricals = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in categoricals:\n    pie_plot(c) if random.getrandbits(1) else bar_plot(c)\n    ","419d0f73":"dirtyCategoricals = [\"Cabin\",\"Name\",\"Ticket\"]\nfor c in dirtyCategoricals:\n    print(\"{} \\n\".format(train_df[c].value_counts()))\n    print(\"*\"*35)","284a5fd9":"def plot_hist(x_name,color):\n    \"\"\"\n        input: x_name: must be numeric, color: must be categorical\n        output: hist plot & value count \n    \"\"\"\n    fig = px.histogram(train_df,x= x_name,\n                       title=\"Histogram of {} Column with distribution of {}\".format(x_name,color),\n                       template=\"plotly_white\",\n                       marginal=\"violin\",\n                       histnorm='probability density',\n                       color=color)\n                      \n    fig.update_layout(showlegend=True)\n    fig.show()","e09b6ddc":"numericals = [\"Fare\",\"Age\",\"PassengerId\"]\ncategoricals = [\"Sex\",\"Pclass\",\"Survived\"]\nfor n in numericals:\n    for c in categoricals:\n        plot_hist(n,c)","094dba3c":"#Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index= False).mean().sort_values(by=\"Survived\",ascending= False)","5f7bfccd":"#SibSp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index= False).mean().sort_values(by=\"Survived\",ascending= False)","1ffb2d5c":"#Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index= False).mean().sort_values(by=\"Survived\",ascending= False)","afa98e6b":"#Pclass vs Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index= False).mean().sort_values(by=\"Survived\",ascending= False)","fa8baa39":"#Embarked vs Survived\ntrain_df[[\"Embarked\",\"Survived\"]].groupby([\"Embarked\"], as_index= False).mean().sort_values(by=\"Survived\",ascending= False)","8d1d9e7b":"def detect_outliers(df,features):\n    outlier_indices = []\n    for c in features:\n        #1st Quartile\n        Q1 = np.percentile(df[c],25)\n        #3rd Quartile\n        Q3 = np.percentile(df[c],75)\n        #IQR\n        IQR = Q3-Q1\n        #Outlier Step\n        outlier_step = IQR*1.5\n        #Detect Outlier and their Indeces\n        outlier_list_col = df[(df[c]< Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # Store indeces\n        outlier_indices.extend(outlier_list_col),\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i,v in outlier_indices.items() if v>2)\n    return multiple_outliers","cfdd1aa8":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","fba897cd":"train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]), axis=0).reset_index(drop = True)","9a3f1bf5":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df], axis= 0).reset_index(drop= True)","a90dc382":"train_df.columns[train_df.isnull().any()]","c8b3033b":"train_df.isnull().sum()","0d867f51":"train_df[train_df[\"Embarked\"].isnull()]","4d05e00a":"train_df.boxplot(column=\"Fare\", by=\"Embarked\")","e290cc1f":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")","2892d800":"train_df[train_df[\"Fare\"].isnull()]","96c8b9c0":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"]==3][\"Fare\"]))","581ed359":"corr_list=[\"Age\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\",\"Survived\"]\npx.imshow(train_df[corr_list].corr())","c5075f98":"cat_list=[\"SibSp\",\"Parch\",\"Pclass\",\"Survived\"]\nfig = px.parallel_categories(train_df[cat_list], color=\"Survived\")\nfig.show()","0c52bd0f":"g = sns.factorplot( x = \"SibSp\",y=\"Survived\",data=train_df, kind= \"point\", size = 7)\ng.set_ylabels(\"Survived Probability\")","fb5b9651":"g = sns.factorplot( x = \"Parch\",y=\"Survived\",data=train_df, kind= \"point\", size = 7)\ng.set_ylabels(\"Survived Probability\")","a398dbdd":"g = sns.factorplot( x = \"Pclass\",y=\"Survived\",data=train_df, kind= \"point\", size = 7)\ng.set_ylabels(\"Survived Probability\")","cade5916":"fig = px.histogram(train_df[:train_df_len],\n                   x=\"Age\",\n                   opacity=0.7,\n                   facet_col=\"Survived\",\n                   marginal=\"rug\",\n                   color=\"Survived\",\n                   template=\"plotly_white\",\n                   hover_data=train_df.columns,\n                   nbins=20,\n                   histnorm='probability density')\nfig.show()","c74e5b85":"fig = px.histogram(train_df[:train_df_len],\n                   x=\"Age\",\n                   opacity=0.7,\n                   facet_col=\"Pclass\",\n                   facet_row=\"Survived\",\n                   color=\"Pclass\",\n                   template=\"plotly_white\",\n                   nbins=20,\n                   width=600,\n                    )\nfig.show()","d208a1fc":"g = sns.FacetGrid(train_df, col= \"Embarked\",size= 5)\ng.map(sns.pointplot,\"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()","2505bcef":"fig = px.bar(train_df[:train_df_len],\n                   x=\"Sex\",\n                   y=\"Fare\",\n                   opacity=0.7,\n                   facet_col=\"Embarked\",\n                   facet_row=\"Survived\",\n                   color = \"Sex\",\n                   template=\"plotly_white\",\n                   width=1200,\n                    )\nfig.show()","952adda4":"train_df[train_df[\"Age\"].isnull()]","49777288":"fig = px.box(train_df, x=\"Sex\", y=\"Age\", notched=True)\nfig.show()","89f8ae46":"fig = px.box(train_df, x=\"Pclass\", y=\"Age\", color=\"Sex\", notched=True)\nfig.show()","ff36a96d":"fig = px.box(train_df, x=\"Parch\", y=\"Age\", notched=True)\nfig.show()\nfig = px.box(train_df, x=\"SibSp\", y=\"Age\", notched=True)\nfig.show()","4251b9b7":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","01e23763":"corr_list=[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]\nsns.heatmap(train_df[corr_list].corr(),annot=True)","66eea6c2":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nage_med = train_df[\"Age\"].median()\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","de1fc745":"train_df[\"Name\"].head(10)","5681bc88":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip()   for i in name]","cda7840f":"train_df[\"Name\"].head(10),train_df[\"Title\"].head(10)","d3af14db":"fig = px.bar(x=train_df[\"Title\"].unique(),y=train_df[\"Title\"].value_counts())\nfig.show()","0ea0f467":"#convert to categorical\nrareList = [\"Rev\",\"Dr\",\"Major\",\"Lady\",\"Sir\",\"Col\",\"Capt\",\"Jonkheer\"]\ntrain_df[\"Title\"] = train_df[\"Title\"].replace(rareList,\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i ==\"Ms\" or i ==\"Mlle\" or i == \"the Countess\" or i == \"Mrs\" or i == \"Dona\" else 2 if i ==\"Mr\" or i == \"Don\" else 3 for i in train_df[\"Title\"]]","bac97408":"g = sns.factorplot( x = \"Title\",y=\"Survived\",data=train_df, kind= \"bar\", size = 7)\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survived Probability\")","b3518e53":"train_df.drop(labels = [\"Name\"],axis = 1,inplace=True)","1dc5c747":"    train_df.head()","58c6af02":"  train_df = pd.get_dummies(train_df,columns=[\"Title\"]) ","f6c81859":"train_df.head()","cbe3b702":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","53b1058a":"g = sns.factorplot( x = \"Fsize\",y=\"Survived\",data=train_df, kind= \"bar\", size = 7)\ng.set_ylabels(\"Survived Probability\")","4b2c8fec":"train_df[\"FamilySize\"] = [1 if i <5 else 0 for i in train_df[\"Fsize\"]]","d4b1fbaf":"fig = px.bar(x=train_df[\"FamilySize\"].unique(),y=train_df[\"FamilySize\"].value_counts())\nfig.show()","7bed4fb0":"g = sns.factorplot( x = \"FamilySize\",y=\"Survived\",data=train_df, kind= \"point\", size = 7)\ng.set_ylabels(\"Survived Probability\")","7d5da45e":"train_df = pd.get_dummies(train_df,columns=[\"FamilySize\"])","70fd88dc":"train_df.drop(labels = [\"Fsize\",\"SibSp\",\"Parch\"],axis = 1,inplace=True)","de24f154":"train_df.head()","140f8144":"fig = px.bar(x=train_df[\"Embarked\"].unique(),y=train_df[\"Embarked\"].value_counts(),color=[\"Southampton\",\"Cherbourg\",\"QuuenStown\"])\nfig.show()","32efcfb4":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])","516c5988":"train_df[\"Ticket\"].head(20)","b81db37a":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split()[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","97e3b052":"train_df.head()","77149e93":"fig = px.bar(x=train_df[\"Ticket\"].unique(),y=train_df[\"Ticket\"].value_counts())\nfig.show()","bfc826ce":"rarelist = [\"SP\",\"SOC\",\"C\",\n             \"SOP\",\"Fa\",\"LINE\",\"SWPP\",\"SCOW\",\n             \"PPP\",\"SC\",\"SCAH\",\"AS\",\"SOPP\",\"SOTONO2\",\"CASOTON\",\n             \"SCA3\",\"AQ4\",\"A\",\"LP\",\"AQ3\",\"PP\",\"CA\",\"SCParis\",\"SCA4\",\"STONO2\",\"WEP\",\"FC\"]","b3fd7be0":"train_df[\"Ticket\"]=train_df[\"Ticket\"].replace(rarelist,\"x\")","3e2909dc":"train_df.Ticket.value_counts()","4300c3dd":"train_df = pd.get_dummies(train_df,columns= [\"Ticket\"], prefix= \"T\")","b803c305":"train_df.head(15)","aa2a61da":"fig = px.bar(x=train_df[\"Pclass\"].unique(),y=train_df[\"Pclass\"].value_counts(),color=[\"Third Class\",\"First Class\",\"Second Class\"])\nfig.show()","44e2357e":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","3ddf8a73":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df,columns = [\"Sex\"])\ntrain_df.head()","71aa8b0b":"train_df.drop(labels = [\"PassengerId\",\"Cabin\"],axis=1,inplace=True)","37a8efdb":"train_df.columns","15640916":"from sklearn.model_selection import train_test_split, StratifiedKFold , GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","5fa65558":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis=1,inplace=True)","4154c263":"train = train_df[:train_df_len]\nX_train = train.drop(labels=[\"Survived\"],axis=1)\ny_train = train[\"Survived\"]\nX_train, X_validation, y_train,y_validation = train_test_split(X_train,y_train,test_size=0.33, random_state=42)","f1a7fd62":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\nacc_log_train = logreg.score(X_train,y_train)\nacc_log_test = logreg.score(X_validation,y_validation)\nprint(\"*\"*40)\nprint(\"Training Acc is % {} \\n Testing Acc is % {}\".format(round(acc_log_train*100,5),round(acc_log_test*100,5)))","0f7aa7b8":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","7cf703e4":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","b5a5a744":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\nfig = px.bar(cv_results,x=\"Cross Validation Means\",y=\"ML Models\", orientation='h',color=[\"DecisionTreeClassifier\",\"SVM\",\n                                                                                         \"RandomForestClassifier\",\n                                                                                         \"LogisticRegression\",\"KNeighborsClassifier\"])\nfig.show()","40b31268":"votingC = VotingClassifier(estimators= [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])], voting = \"soft\", n_jobs= -1)\nvotingC = votingC.fit(X_train,y_train)\nprint(accuracy_score(votingC.predict(X_validation),y_validation))","6f220d6b":"test_survived = pd.Series(votingC.predict(test),name=\"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived], axis =1)\nresults.to_csv(\"titanic.csv\",index=False)\nresults","8cb06d98":"<a id=\"33\"><\/a>\n### Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* Svm\n* Random Forest\n* KNN\n* Logistic Regression","61ec3880":"<a id=\"4\"><\/a>\n### Categorical Variable","6581727e":"# Introduction\nThe sinking of Titanic is one of the most notorious shipwredcks in the history. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passngers and crew.\n____\n<font color =\"Purple\">\n Content:\n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n    * [Univeriate Variable Analysis](#3)\n        - [Categorical Variable](#4)\n        - [Numerical Variable](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Pclass -- Age -- Fare -- Survived](#12)\n    * [Categories Between Sibsp -- Parch -- Pclass -- Survived](#13)\n    * [SibSp -- Survived](#14)\n    * [Parch -- Survived](#15)\n    * [Pclass -- Survived](#16)\n    * [Age -- Survived](#17)\n    * [Pclass -- Age -- Survived](#18)\n    * [Embarked -- Sex -- Pclass -- Survived](#19)\n    * [Embarked -- Sex -- Fare -- Survived](#20)\n    * [Fill Missing: Age Feature](#21)\n7. [Feature Engineering](#22)\n    * [Name --> Title](#23)\n    * [Family Size](#24)\n    * [Embarked](#25)\n    * [Ticket](#26)\n    * [Pclass](#27)\n    * [Sex](#28)\n    * [Drop PassengerID and Cabin](#29)\n8. [Modelling](#30)\n    * [Train Test Split](#31)\n    * [Simple Logistic Regression](#32)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#33)\n    * [Ensemble Modeling](#34)\n    * [Prediction and Submission](#35)","42de2746":"<a id=\"34\"><\/a>\n### Ensemble Modeling","426a5263":"> <a id=\"10\"><\/a>\n### Fill Missing Value\n* Embarked has 2 missing value\n* Fare has only 1","0e7635db":"<a id=\"27\"><\/a>\n### Pclass","83ae85a3":"<a id=\"24\"><\/a>\n### Family Size","41eb59d7":"<a id=\"28\"><\/a>\n### Sex","64de8848":"<a id=\"23\"><\/a>\n### Name --> Title","8607d29a":"<a id=17><\/a>\n### Age -- Survived\n","36865e0e":"<a id=20><\/a>\n### Embarked -- Sex -- Fare -- Survived","7c9e8982":"> <a id=\"9\"><\/a>\n### Find Missing Value","0d095aaa":"<a id=\"30\"><\/a>\n## Modelling","d7ded060":"<a id=\"35\"><\/a>\n### Prediction and Submission","e35c1f28":"<a id=21><\/a>\n### Fill Missing: Age Feature","5d5eed6f":"<a id=\"12\"><\/a>\n### Correlation Between Sibsp -- Pclass -- Parch -- Age -- Fare -- Survived","5caf21a9":"Fare features seems to have correlation with survived feature(0.26).","7a458b86":"<a id = \"1\"><\/a>\n___\n## Load and Check Data\n","185a5acd":"<a id=\"6\"><\/a>\n## Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived\n* Embarked - Survied","dec81d0f":"<a id=\"29\"><\/a>\n### Drop PassengerID and Cabin","6ec97a83":"* Passengers who pay higher fare have better survival.\n* Fare can be used as categorical for training. ","deb3b02d":"<a id=\"3\"><\/a>\n## Univeriate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, SibSp and Parch\n* Numerical Variable: Fare, age and passengerId","cd66f893":"<a id=\"26\"><\/a>\n### Ticket","159798f3":"* Female Passengers have much better survival rate than males.\n* Males have better Survival rate in pclass 3 in C.\n* Embarked and Sex will be used in training.","6e17d11c":"<a id=18><\/a>\n### Pclass -- Age -- Survived","61f13e1a":"<a id=16><\/a>\n### Pclass -- Survived","4877e6e4":"* float64(2): Fare and Age\n* int64(5): Pclass, Sibsp, Parch, PassengerId and Survived\n* object(5): Cabin, Embarked, Name, Sex and Ticket","e1b56f5e":"* 1st class passengers are older than 2nd class, 2nd is older than 3rd","d86ab857":"<a id=19><\/a>\n### Embarked -- Sex -- Pclass -- Survived","8664d887":"<a id=\"25\"><\/a>\n### Embarked","59ac351d":"<a id = \"2\"><\/a>\n___\n## Variable Description\n1. PassengerId: unique id number to each passenger\n1. Survived: Passenger survived(1) or died(0)\n1. Pclass: Passenger Class categories(1,2,3)\n1. Name: Name of Passenger\n1. Sex: gender of Passenger\n1. Age: age of Passenger\n1. SibSp: # siblings\/spouses    \n1. Parch: # parents\/children\n1. Ticket: ticket number\n1. Fare: amount of money spent on ticket\n1. Cabin: Cabin numbers\n1. Embarked: Port where passenger embarked ( C = Cherbourg , Q = QuuenStown, S= Southampton)\n","97ad2e44":"<a id=\"31\"><\/a>\n### Train Test Split","fbafd43f":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass","8c9f89f4":"<a id=\"7\"><\/a>\n## Outlier Detection","8f938cbb":"* Pclass is important feature for model training.","7ed6c927":"* Age <= 10 has a high survival rate\n* Oldest passengers (80) survived.\n* Large number of betweeen 17.5 - 32.4 years old did not survive.\n* Most passenger are in 15-35 age range.\n* Use Age feature in training\n* Use Age distribution for missing value of Age","2537b69a":"<a id=\"13\"><\/a>\n### Categories Between Sibsp -- Parch -- Pclass -- Survived","bb77cc71":"<a id=\"22\"><\/a>\n## Feature Engineering","f434d8ae":"* Small Families have more chance to survive than large families.\n","90ee9dd1":"<a id=\"5\"><\/a>\n### Numerical Variable","6f64d7fc":"* Sex is not informative for age prediction because Age distribution seems to be same.","bafea676":"<a id=\"32\"><\/a>\n### Simple Logistic Regression","3732d374":"<a id=15><\/a>\n### Parch -- Survived\n","7ae3ae59":"* Having a lot of SibSp has less chance to survive\n* If SibSp == 0 or 1 or 2, passenger has more chance to survive\n* We can consider a new feature describing these categories.","e51c10d7":"* SibSp and Parch can be used for new feature extraction with th = 3\n* Small families have more chance to survive.\n* there is a std in survival of passenger with parch=3","ca6666af":"<a id=14><\/a>\n### SibSp -- Survived\n","bc738716":"<a id=\"8\"><\/a>\n## Missing Value\n","3eff55ff":"<a id=\"11\"><\/a>\n## Visualization"}}