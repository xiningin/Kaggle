{"cell_type":{"3091b107":"code","3459c7a2":"code","81fc109d":"code","115a5660":"code","d816f37d":"code","400c7d9c":"code","a4fdcd4c":"code","967b874c":"code","6df9a7e9":"code","fa858841":"code","f443c489":"code","4df5b036":"code","6164694b":"code","78a16ed8":"code","7b760185":"code","472b11ad":"code","7aca6c5e":"code","edc81037":"code","5acf66f4":"code","682e601d":"code","3048ac3f":"code","ec79dedb":"code","412c521e":"code","fa6e546f":"code","272cd58e":"markdown","f0045975":"markdown","dbd5514b":"markdown","73832bb4":"markdown","40fe866b":"markdown","4724bb2c":"markdown","bc5913fe":"markdown","44404ef8":"markdown","e0618c5d":"markdown","4c4b57cb":"markdown","bf6e8b53":"markdown","b31ccea9":"markdown","22128b3d":"markdown","feb52252":"markdown","bb567997":"markdown","dc9dc5c4":"markdown","b4c304f7":"markdown","d569f0a1":"markdown","1a0db520":"markdown","d5cc415d":"markdown"},"source":{"3091b107":"#import libraries\n#!pip install bs4\n#!pip install requests\n#!pip install sqlalchemy\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport sqlalchemy","3459c7a2":"website = 'https:\/\/www.justia.com\/lawyers\/new-york\/new-york-city'","81fc109d":"response = requests.get(website)","115a5660":"response","d816f37d":"soup = BeautifulSoup(response.content, 'html.parser')\n#soup","400c7d9c":"results = soup.find_all('div',{'data-vars-action':'OrganicListing'})\n#results","a4fdcd4c":"len(results)","967b874c":"#Name\n#Short Bio\n#Specialization\n#University\n#Address\n#Phone\n#email\n#Site Link","6df9a7e9":"results[0].find('strong', {'class':'lawyer-name'}).get_text().strip()","fa858841":"results[0].find('div', {'class':'lawyer-expl'}).get_text().strip()","f443c489":"results[0].find('span', {'class':'-practices'}).get_text().strip()","4df5b036":"results[0].find('span', {'class':'-law-schools'}).get_text().strip()","6164694b":"results[0].find('span', {'class':'-address'}).get_text().strip().replace(\"\\t\",'').replace('\\n',', ')","78a16ed8":"results[0].find('strong', {'class':'-phone'}).get_text().strip()","7b760185":"results[0].find('a', {'class':'-email'}).get('href')","472b11ad":"results[0].find('a', {'class':'-website'}).get('href')","7aca6c5e":"name = []\nshort_bio = []\nspecialization = []\nuniversity = []\naddress = []\nphone = []\nemail_link = []\nsite_link = []\n\n#aside from just entering result information, in the case that some data has not been entered on the site for any variable, we will use try\/except method\n\nfor result in results:\n  #Name\n  try:\n    name.append(result.find('strong', {'class':'lawyer-name'}).get_text().strip())\n  except:\n    name.append('')\n  #Short Bio\n  try:\n    short_bio.append(result.find('div', {'class':'lawyer-expl'}).get_text().strip())\n  except:\n    short_bio.append('')  \n  #Specialization\n  try:\n    specialization.append(result.find('span', {'class':'-practices'}).get_text().strip())\n  except:\n    specialization.append('')  \n  #University\n  try:\n    university.append(result.find('span', {'class':'-law-schools'}).get_text().strip())\n  except:\n    university.append('')  \n  #Address\n  try:\n    address.append(result.find('span', {'class':'-address'}).get_text().strip().replace(\"\\t\",'').replace('\\n',', '))\n  except:\n    address.append('')  \n  #Phone\n  try:\n    phone.append(result.find('strong', {'class':'-phone'}).get_text().strip())\n  except:\n    phone.append('')  \n  #Email Link\n  try:\n    email_link.append(result.find('a', {'class':'-email'}).get('href'))\n  except:\n    email_link.append('')  \n  #Site Link\n  try:\n    site_link.append(result.find('a', {'class':'-website'}).get('href'))\n  except:\n    site_link.append('')","edc81037":"#Test\nprint(university)\nprint(len(university))","5acf66f4":"df_lawyers = pd.DataFrame({'lawyer_name':name, 'short_bio':short_bio, 'specialization':specialization, 'university':university, \n                           'address':address, 'phone':phone, 'email_link':email_link, 'site_link':site_link})\ndf_lawyers","682e601d":"#df_lawyers.to_excel('lawyers_single.xlsx', index=False)\n#df_lawyers.to_csv('lawyers_singledb.csv', index=False)","3048ac3f":"#Scraping data from multiple pages\n#seeing the url address structure allows us to manipulate the number of webpages we collect from through the url variable\n\nnames = []\nshort_bios = []\nspecializations = []\nuniversities = []\naddresses = []\nphones = []\nemail_links = []\nsite_links = []\n\nfor s in range(1,21):\n\n  websites = 'https:\/\/www.justia.com\/lawyers\/new-york\/new-york-city?page='+str(s)\n  responses = requests.get(websites)\n  soups = BeautifulSoup(responses.content, 'html.parser')\n  resultss = soups.find_all('div',{'data-vars-action':'OrganicListing'})\n\n  for r in resultss:\n    #Names\n    try:\n      names.append(r.find('strong', {'class':'lawyer-name'}).get_text().strip())\n    except:\n      names.append('')\n    #Short Bios\n    try:\n      short_bios.append(r.find('div', {'class':'lawyer-expl'}).get_text().strip())\n    except:\n      short_bios.append('')  \n    #Specializations\n    try:\n      specializations.append(r.find('span', {'class':'-practices'}).get_text().strip())\n    except:\n      specializations.append('')  \n    #Universities\n    try:\n      universities.append(r.find('span', {'class':'-law-schools'}).get_text().strip())\n    except:\n      universities.append('')  \n    #Addresses\n    try:\n      addresses.append(r.find('span', {'class':'-address'}).get_text().strip().replace(\"\\t\",'').replace('\\n',', '))\n    except:\n      addresses.append('')  \n    #Phones\n    try:\n      phones.append(r.find('strong', {'class':'-phone'}).get_text().strip())\n    except:\n      phones.append('')  \n    #Email Links\n    try:\n      email_links.append(r.find('a', {'class':'-email'}).get('href'))\n    except:\n      email_links.append('')  \n    #Site Links\n    try:\n      site_links.append(r.find('a', {'class':'-website'}).get('href'))\n    except:\n      site_links.append('')\n\ndf_lawyers_multiple = pd.DataFrame({'lawyer_names':names, 'short_bios':short_bios, 'specializations':specializations, 'universities':universities, \n                           'addresses':addresses, 'phones':phones, 'email_links':email_links, 'site_links':site_links})","ec79dedb":"df_lawyers_multiple","412c521e":"#df_lawyers_multiple.to_excel('lawyers_multiple.xlsx', index=False)\n#df_lawyers_multiple.to_csv('lawyers_multipledb.csv', index=False)","fa6e546f":"# Create sqlalchemy engine - as we now have an 800 row x 8 column database we can now import it to MySQL\n# Due to the size of the database it may be easier to clean, manipulate, and analyze uning SQL as opposed to a spreadsheet\n#engine = sqlalchemy.create_engine('mysql:\/\/root@localhost\/3306')\n#df_lawyers_multiple.to_sql('lawyers', engine, index=False)","272cd58e":"Name","f0045975":"University\n","dbd5514b":"## Put everything together inside a For-Loop","73832bb4":"## Output in excel","40fe866b":"Response code","4724bb2c":"Email Link","bc5913fe":"Site Link","44404ef8":"## Create Padas Dataframe","e0618c5d":"Results","4c4b57cb":"### Output to Excel","bf6e8b53":"## Soup Object","b31ccea9":"Short Bio","22128b3d":"Address","feb52252":"# Pagination (Part 2) \n#### Scrape 20 pages","bb567997":"Get Request","dc9dc5c4":"Phone","b4c304f7":"### Output to MySQL","d569f0a1":"Specialization","1a0db520":"### Target Necessary Data","d5cc415d":"# HTTP Request\n\nStore website in variable"}}