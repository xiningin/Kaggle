{"cell_type":{"54a206e9":"code","f174aa17":"code","fde6900f":"code","694ea13b":"code","2d38c162":"code","79569604":"code","46e6c6f0":"code","5a8fae42":"code","b8b975d3":"code","3e43e4b9":"markdown","6e8cc8ba":"markdown","22ae7e72":"markdown","ad7aeabf":"markdown","d876bd6f":"markdown"},"source":{"54a206e9":"import numpy as np \nimport pandas as pd\nimport datatable as dt\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier","f174aa17":"%%time\ntrain = dt.fread('..\/input\/tabular-playground-series-oct-2021\/train.csv').to_pandas()\ntest  = dt.fread('..\/input\/tabular-playground-series-oct-2021\/test.csv').to_pandas()\nsub   = dt.fread('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv').to_pandas()","fde6900f":"train.drop('id',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)","694ea13b":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64','float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                else:\n                    df[col] = df[col].astype(np.float32)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","2d38c162":"train = reduce_mem_usage(train)\ntest  = reduce_mem_usage(test)","79569604":"y = train['target']\ntrain.drop('target',axis=1,inplace=True)","46e6c6f0":"# lgbm params\nlgbm_params = {\n  \"objective\": \"binary\",\n  \"metric\": \"auc\",\n  \"learning_rate\": 0.08,\n  \"device\": \"gpu\",\n  \"verbose\": 0, \n  \"feature_pre_filter\": False, \n  \"lambda_l1\": 9.314037635261775, \n  \"lambda_l2\": 0.10613573572440353,\n  \"num_leaves\": 7,\n  \"feature_fraction\": 0.4, \n  \"bagging_fraction\": 0.8391963650875751, \n  \"bagging_freq\": 5, \n  \"min_child_samples\": 100,\n  \"num_iterations\": 10000,\n  \"n_estimators\": 20000,\n  \"random_state\": 42\n}","5a8fae42":"folds = KFold(n_splits = 5, random_state = 102021, shuffle = True)\n\npredictions = np.zeros(len(test))\nlgbm_oof = np.zeros(train.shape[0])\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n\n    X_train, X_test = train.iloc[trn_idx], train.iloc[val_idx]\n    y_train, y_test = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = LGBMClassifier(**lgbm_params)\n    print(f\"model fit started for Fold: {fold}\")\n    model.fit(X_train, \n              y_train,\n              eval_set=[(X_test, y_test)],\n              early_stopping_rounds=400,\n              verbose=False)\n    pred = model.predict_proba(X_test)[:,1]\n    lgbm_oof[val_idx] = pred\n    roc = roc_auc_score(y_test, pred)\n    print(f\" roc_auc_score: {roc}\")\n    print(\"-\"*50)\n    \n    predictions += model.predict_proba(test)[:,1] \/ folds.n_splits ","b8b975d3":"sub['target'] = predictions\nsub.to_csv(f'submission_lgbm_1.csv',index = False)\nnp.savez_compressed('oof_lgbm.npz', lgbm_oof)","3e43e4b9":"# Load dataset","6e8cc8ba":"# Model hyperparameters","22ae7e72":"# 5-fold model training and prediction","ad7aeabf":"# Imports","d876bd6f":"# Store submission and oof "}}