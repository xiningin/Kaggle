{"cell_type":{"145d89c5":"code","d80dbc46":"code","95e95980":"code","b3fcccd7":"code","0424f770":"code","7ac48d33":"code","efa1363e":"code","776822f8":"code","81c597b6":"code","a8265a18":"code","12cacecc":"code","e0dda30b":"code","1d41ebed":"code","be960e34":"code","2cba5359":"code","71a0c290":"code","0a9737e4":"code","f1fc0275":"code","f8e1480b":"code","306ee547":"code","5d873c71":"code","2698e0eb":"code","ee74e113":"code","6e64a36a":"code","a2c7e189":"code","2878e803":"code","6ba81711":"code","3f0855d6":"code","1e7fb38d":"code","fdf166ad":"code","36b3b6cc":"markdown","c991b2b4":"markdown","18577679":"markdown","581e8a2e":"markdown","a268cb61":"markdown","0f4dda53":"markdown","84d7d490":"markdown","b22d53e1":"markdown","692c9f4b":"markdown","28e15211":"markdown","0247b955":"markdown","d68d89ff":"markdown","bd5de47e":"markdown","582c2986":"markdown","d65efbbf":"markdown","7c7c6c47":"markdown"},"source":{"145d89c5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","d80dbc46":"Cr_card=pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","95e95980":"Cr_card.head(10)","b3fcccd7":"Cr_card.shape","0424f770":"Cr_card.describe()","7ac48d33":"fraud = Cr_card[Cr_card['Class'] == 1] \nvalid = Cr_card[Cr_card['Class'] == 0] \noutlierFraction = len(fraud)\/float(len(valid)) \nprint(outlierFraction) \nprint('Fraud Cases: {}'.format(len(Cr_card[Cr_card['Class'] == 1]))) \nprint('Valid Transactions: {}'.format(len(Cr_card[Cr_card['Class'] == 0])))","efa1363e":"total = Cr_card.isnull().sum().sort_values(ascending = False)\npercent = (Cr_card.isnull().sum()\/Cr_card.isnull().count()*100).sort_values(ascending = False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()","776822f8":"Cr_card.Amount= preprocessing.scale(Cr_card.Amount)","81c597b6":"Cr_card.head()","a8265a18":"# dividing the X and the Y from the dataset \nx = Cr_card.drop(['Class'], axis = 1) \ny= Cr_card[\"Class\"] ","12cacecc":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 42)","e0dda30b":"print(x_train.shape, x_test.shape)\nprint(y_train.shape, y_test.shape)","1d41ebed":"#1. Find the number of the minority class\nnumber_fraud = len(Cr_card[Cr_card['Class']==1])","be960e34":"number_non_fraud = len(Cr_card[Cr_card['Class']==0])","2cba5359":"#2. Find the indices of the majority class\nindex_non_fraud = Cr_card[Cr_card['Class']==0].index","71a0c290":"#.3 Find the indices of the minority class\nindex_fraud = Cr_card[Cr_card['Class']==1].index","0a9737e4":"#4. Randomly sample the majority indices with respect to the number of minority classes\nrandom_indices = np.random.choice(index_non_fraud, number_fraud,replace='False')","f1fc0275":"\nlen(random_indices)","f8e1480b":"#5. Concat the minority indices with the indices from step 4\nunder_sample_indices = np.concatenate([index_fraud,random_indices])","306ee547":"\n#Get the balanced dataframe - This is the final undersampled data\nunder_sample_df = Cr_card.iloc[under_sample_indices]","5d873c71":"under_sample_df.shape","2698e0eb":"under_sample_class_counts = pd.value_counts(under_sample_df['Class'])\nunder_sample_class_counts.plot(kind='bar')","ee74e113":"# dividing the X and the Y from the dataset \nX = under_sample_df .drop(['Class'], axis = 1) \nY= under_sample_df [\"Class\"] ","6e64a36a":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state = 42)","a2c7e189":"print(X_train.shape, X_test.shape)","2878e803":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier \n# random forest model creation \nrfc = RandomForestClassifier() \nscores = cross_val_score(rfc, X_train, Y_train, cv=5)","6ba81711":"print(scores)","3f0855d6":"rfc.fit(X_train, Y_train)\n# predictions \nyPred = rfc.predict(X_test) ","1e7fb38d":"rfc_accuracy = accuracy_score(yPred, Y_test)\nrfc_recall = recall_score(yPred, Y_test)\nprint(rfc_accuracy)\nprint(rfc_recall)","fdf166ad":"cm = confusion_matrix(Y_test, yPred)\nprint (\"Confusion matrix:\\n\", cm)\nprint (\"\\n\")\n\nfig, ax = plt.subplots(1, 2, figsize=(24,5))\n\n# annot: If True, write the data value in each cell\nsns.heatmap(cm, ax=ax[0], annot=True, cmap=plt.cm.copper)\nax[0].set_title(\"Confusion Matrix\")\nax[0].set_xlabel(\"Prediction\")\nax[0].set_ylabel(\"Actual\")\n\nprecision, recall, _ = precision_recall_curve(Y_test, yPred)\nax[1].plot(recall, precision)\nax[1].set_title(\"Precision-recall Curve\")\nax[1].set_xlabel(\"Recall\")\nax[1].set_ylabel(\"Precision\")\nplt.show()","36b3b6cc":"we will scale our data using the scale() function. We will apply this to the amount component of our creditcard_data amount.","c991b2b4":"we will split our dataset into training set as well as test set with a split ratio of 0.80. This means that 80% of our data will be attributed to the train_data whereas 20% will be attributed to the test data.","18577679":"# 4. Data Modeling","581e8a2e":"### Handle Imbalanced Data","a268cb61":"We can see that the recall is 98%, which is a great number. We can say that our model is correctly classifying data as 'fraudulent' with 98% accuracy. However, we see that accuracy is lesser than recall. This is normal, as we have undersampled our data.","0f4dda53":"### Description","84d7d490":"## Import libs","b22d53e1":"# 2. Data Exploration","692c9f4b":"Now we have balanced data, so we can go further with our analysis and data preprocessing.","28e15211":"### Check missing data","0247b955":"There is no messing data","d68d89ff":"## Import data","bd5de47e":"So we have highly Unbalanced data, Only 0.17% fraudulent transaction out all the transactions.","582c2986":"# 3. Data preprocessing","d65efbbf":"### Imbalance in the data","7c7c6c47":"we will implement \"Undersampling\" which basically consists of removing data in order to have a more balanced dataset"}}