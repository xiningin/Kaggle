{"cell_type":{"a55d2578":"code","225e51ef":"code","b81d69f7":"code","41f0593c":"code","3b54d923":"code","88e9e27c":"code","5fb370fc":"code","8602758b":"code","033ecda8":"code","05c92f84":"code","25cbc718":"code","3ebe88de":"code","4b04c8fd":"code","34876061":"code","c620e810":"code","0568697e":"code","e3c64152":"code","2cc5f201":"code","03b5fb45":"code","bedd54ee":"code","cd477ba2":"code","1223a694":"code","b03c0543":"code","706aa0cc":"code","b599816a":"code","5ee7f18b":"code","8ebb1a31":"code","bea6eae8":"code","a1f2c269":"code","2516689b":"code","bcb2bd6b":"code","fe5064ba":"code","5323f8e4":"code","63747018":"code","d6acf609":"code","d3a11091":"code","7c968b36":"code","34206818":"code","5c1f8fa2":"code","3e2328d5":"code","8ed89bac":"code","f36004ba":"code","ef53d778":"code","80481b7a":"code","a985f066":"code","6035b513":"code","1bafff43":"code","1a59f115":"code","cb333ab0":"code","72a90c15":"code","7209c04c":"code","497e2b76":"code","76de2a9a":"code","09fd2bdf":"code","05a769d9":"code","852149b9":"code","76237d5e":"code","1d2eea3a":"code","e7e615cf":"code","b5e91903":"code","7626b5bf":"code","a467a481":"code","11d26f7e":"code","ae4c9be9":"code","7f2fb029":"code","3aa38888":"code","ffc22c79":"code","6c1af84d":"code","d650fb45":"code","807ce0a5":"code","6458c3ab":"code","89cc3497":"code","098daff3":"code","69e2cf1c":"code","e3c1197c":"markdown","7fa7d97e":"markdown","7ad4e747":"markdown","adebcbd2":"markdown","e8ba9150":"markdown","0e62741d":"markdown","2ad5fd30":"markdown","b517ea05":"markdown","1dc0e01d":"markdown","1fa28a63":"markdown","b38cd2de":"markdown","d17d563b":"markdown","29f7b5bc":"markdown","2ecf0691":"markdown","23637797":"markdown","2c073498":"markdown","c19e29a6":"markdown","ea70517f":"markdown","df630526":"markdown","9ee74700":"markdown","0d7df550":"markdown","fbd7b855":"markdown","6ad9db04":"markdown","14c8510f":"markdown","b6ade28b":"markdown","0bb057a0":"markdown","ba22cbca":"markdown","297f0f01":"markdown","4e7a7539":"markdown","7a9352dd":"markdown","6fa85e76":"markdown","45d27b97":"markdown","360fa987":"markdown","2ccea2b4":"markdown","ff150d7e":"markdown","a84bc486":"markdown","c4e53020":"markdown","b981f18d":"markdown","90c96a59":"markdown","192a5a16":"markdown","a94e95f8":"markdown","acdb8518":"markdown","b5ec5989":"markdown","e60d29a3":"markdown","3f05ca51":"markdown","81e6f830":"markdown","ab2299fa":"markdown","a8bc9639":"markdown","b5db8bb5":"markdown","127474e3":"markdown","1584f9f5":"markdown","6352e830":"markdown","7231aeeb":"markdown","c1daf61b":"markdown","c2f1b56d":"markdown","9102ed93":"markdown","70ae4c01":"markdown","a8f484b8":"markdown","28e2ec69":"markdown"},"source":{"a55d2578":"import numpy as np\nimport os\nimport cv2","225e51ef":"dirname = \"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise\\ Files\/Ch02\/02_01\\ Begin\"","b81d69f7":"fname = \"opencv-logo.png\"\nf_path = os.path.join(dirname,fname)\nprint(f_path)","41f0593c":"img = cv2.imread(\"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch02\/02_01 Begin\/opencv-logo.png\")","3b54d923":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.imshow(img)\nplt.show()","88e9e27c":"cv2.imwrite(\"\/kaggle\/working\/output.jpg\",img)","5fb370fc":"dirname = \"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch02\/02_02 Begin\/\"","8602758b":"img = cv2.imread(os.path.join(dirname,\"opencv-logo.png\"),1)\nplt.imshow(img)\nplt.show()","033ecda8":"len(img)","05c92f84":"len(img[0])","25cbc718":"len(img[0][0])","3ebe88de":"img.shape","4b04c8fd":"img.dtype","34876061":"img[10,5]","c620e810":"plt.imshow(img[:,:,1])\nplt.show()","0568697e":"img.size","e3c64152":"black = np.zeros([150,200,3],'uint8')\nplt.imshow(black)\nplt.show()","2cc5f201":"#almost black\nones = np.ones([150,200,3],'uint8')\nplt.imshow(ones)\nplt.show()","03b5fb45":"white = np.ones([150,200,3],'uint8')\nwhite *= (2**8-1)\nplt.imshow(white)\nplt.show()","bedd54ee":"color = ones.copy()\ncolor[:,:] = (0,0,255)\nplt.imshow(color)\nplt.show()","cd477ba2":"color_BGR = cv2.imread(\"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch02\/02_04 Begin\/butterfly.jpg\", 1)","1223a694":"plt.imshow(color)\nplt.show()","b03c0543":"color_RGB = color_BGR[:,:,[2,1,0]].copy()\nplt.imshow(color_RGB)\nplt.show()","706aa0cc":"print(color_BGR.shape)","b599816a":"height, width, channels = color_BGR.shape","5ee7f18b":"b,g,r = cv2.split(color_BGR)","8ebb1a31":"rgb_split = np.empty([height, width*3,3],'uint8')","bea6eae8":"rgb_split[:,0:width] = cv2.merge([b,b,b])\nrgb_split[:,width:2*width] = cv2.merge([g,g,g])\nrgb_split[:,width*2:width*3] = cv2.merge([r,r,r])","a1f2c269":"plt.imshow(rgb_split)\nplt.show()","2516689b":"cv2.imwrite('\/kaggle\/working\/butterfly_rgb.jpg',rgb_split)","bcb2bd6b":"hsv = cv2.cvtColor(color_BGR, cv2.COLOR_BGR2HSV)\nh,s,v=cv2.split(hsv)\nhsv_split = np.concatenate((h,s,v),axis=1)\nplt.imshow(hsv_split)\nplt.show()","fe5064ba":"maindir = \"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch02\/\"","5323f8e4":"color = cv2.imread(maindir+\"02_05 Begin\/butterfly.jpg\", 1)","63747018":"gray = cv2.cvtColor(color, cv2.COLOR_RGB2GRAY)","d6acf609":"b = color[:,:,0]\ng = color[:,:,1]\nr = color[:,:,2]","d3a11091":"rgba = cv2.merge((r,g,b,g))\nplt.imshow(rgba)\nplt.show()","7c968b36":"image_BGR = cv2.imread(os.path.join(maindir,\"02_06 Begin\/thresh.jpg\"))","34206818":"image_RGB = cv2.cvtColor(image_BGR,cv2.COLOR_BGR2RGB)","5c1f8fa2":"plt.imshow(image_RGB)\nplt.show()","3e2328d5":"blur_RGB = cv2.GaussianBlur(image_RGB, (5,55),0)\nplt.imshow(blur_RGB)\nplt.show()","8ed89bac":"kernel = np.ones((5,5),'uint8')\ndilate = cv2.dilate(image_RGB, kernel, iterations=1)\nerode = cv2.erode(image_RGB,kernel, iterations=1)\n\nf,ax = plt.subplots(1,2)\nax[0].imshow(dilate)\nax[0].set_title(\"dilate\")\nax[1].imshow(erode)\nax[1].set_title(\"erode\")\nplt.show()","f36004ba":"img = cv2.imread(os.path.join(maindir,\"02_07 Begin\/players.jpg\"))","ef53d778":"#scale\nimg_half = cv2.resize(img,(0,0),fx=0.5,fy=0.5)\nimg_stretch = cv2.resize(img,(600,600))\nimg_stretch_near = cv2.resize(img,(600,600),interpolation=cv2.INTER_NEAREST)","80481b7a":"f,ax=plt.subplots(1,2,figsize=(10,5))\nax[0].imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\nax[1].imshow(cv2.cvtColor(img_half,cv2.COLOR_BGR2RGB))\nplt.show()","a985f066":"f,ax=plt.subplots(1,2,figsize=(10,5))\nax[0].imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\nax[1].imshow(cv2.cvtColor(img_stretch,cv2.COLOR_BGR2RGB))\nplt.show()","6035b513":"f,ax=plt.subplots(1,2,figsize=(10,5))\nax[0].imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\nax[1].imshow(cv2.cvtColor(img_stretch_near,cv2.COLOR_BGR2RGB))\nplt.show()","1bafff43":"#rotation\n#(0,0) to rotate about top-left-hand corner\nM = cv2.getRotationMatrix2D((0,0), -30, 1)\nrotated = cv2.warpAffine(img,M,(img.shape[1],img.shape[0]))\nplt.imshow(cv2.cvtColor(rotated,cv2.COLOR_BGR2RGB))\nplt.show()","1a59f115":"maindir = \"\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch03\/\"","cb333ab0":"bw = cv2.imread(os.path.join(maindir,\"03_02 Begin\/detect_blob.png\"),0)","72a90c15":"height, width = bw.shape[0:2]","7209c04c":"#plt.imshow(cv2.cvtColor(bw,cv2.COLOR_BGR2RGB))\nplt.imshow(bw)\nplt.show()","497e2b76":"threshold = 85\nidxs = bw>threshold","76de2a9a":"binary = np.zeros([height,width,1],'uint8')\nbinary[idxs] = 255","09fd2bdf":"plt.imshow(binary[:,:,0])\nplt.show()","05a769d9":"ret, thresh = cv2.threshold(bw,threshold,255,cv2.THRESH_BINARY)\nplt.imshow(thresh)\nplt.show()","852149b9":"file_dir = '\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch03\/03_03 Begin\/'","76237d5e":"img = cv2.imread(file_dir+'sudoku.png',0)\nplt.imshow(img)\nplt.show()","1d2eea3a":"ret, thresh_basic = cv2.threshold(img,70,255,cv2.THRESH_BINARY)\nplt.imshow(thresh_basic)\nplt.show()","e7e615cf":"thresh_adapt = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115, 1)\nplt.imshow(thresh_adapt)\nplt.show()","b5e91903":"file_dir = '\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch03\/03_04 Begin\/'","7626b5bf":"img = cv2.imread(file_dir + 'faces.jpeg',1)\nimg_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img_RGB)\nplt.show()","a467a481":"hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\nh = hsv[:,:,0]\ns = hsv[:,:,1]\nv = hsv[:,:,2]","11d26f7e":"hsv_split = np.concatenate([h,s,v],axis=1)\nplt.imshow(hsv_split)\nplt.show()","ae4c9be9":"ret, min_sat = cv2.threshold(s,40,255,cv2.THRESH_BINARY)\nret, max_hue = cv2.threshold(h,15,255,cv2.THRESH_BINARY_INV)\nfinal = cv2.bitwise_and(min_sat,max_hue)","7f2fb029":"f, ax = plt.subplots(1,3,figsize=(30,10))\nax[0].imshow(min_sat)\nax[1].imshow(max_hue)\nax[2].imshow(final)\nplt.show()","3aa38888":"file_dir = '\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch03\/03_06 Begin\/'","ffc22c79":"img = cv2.imread(file_dir+'detect_blob.png',1)#color image\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nthresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,115,1)\nplt.imshow(thresh)\nplt.show()","6c1af84d":"contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)","d650fb45":"img2 = img.copy()\nindex = -1 #draw all the contours\nthickness = 4 #thickness of contours\ncolor = (255,0,255)\n\ncv2.drawContours(img2, contours, index, color, thickness)\nplt.imshow(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))\nplt.show()","807ce0a5":"objects = np.zeros([img.shape[0],img.shape[1],3],'uint8')\nfor c in contours:\n    cv2.drawContours(objects,[c],-1, color, -1)# first -1 shows all contours in the list, here 1 contour. second -1 says we want to completely fill the contours\n    \n    area = cv2.contourArea(c)#pixle squared\n    perimeter = cv2.arcLength(c,True)\n    \n    M = cv2.moments(c)#image moment\n    cx = int( M['m10']\/M['m00'])\n    cy = int ( M['m01']\/M['m00'])\n    cv2.circle(objects, (cx,cy),4, (0,0,255), -1)\n    plt.imshow(objects)\nplt.show()","6458c3ab":"file_dir = '\/kaggle\/input\/Ex_Files_OpenCV_Python_Dev\/Exercise Files\/Ch03\/03_08 Begin\/'","89cc3497":"img = cv2.imread(file_dir+'tomatoes.jpg',1)\nplt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\nplt.show()","098daff3":"hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\nres,thresh = cv2.threshold(hsv[:,:,0], 25, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(thresh)\nplt.show()","69e2cf1c":"edges = cv2.Canny(img,100, 70)\nplt.imshow(edges)\nplt.show()","e3c1197c":"which means that this pixle is perfectly white!","7fa7d97e":"I gonna add the 4th channel namely __transparency__ or $\\alpha$-channel. Note that `jpg` doesn't support transparency and instead I should use `png`:","7ad4e747":"## Image types and color channels","adebcbd2":"Note: I have used image only with `1` channel and got error. The `plt.imshow()` only accepsts images with `3` channels!","e8ba9150":"We see that the picture is blured vertically far more than horizontally!","0e62741d":"We can do many things. For instance we can write the image stored in `img` into a file with a desired extension using `cv2.imwrite`:","2ad5fd30":"the top row, number of vertical columns","b517ea05":"First we start with importing the required libraries:","1dc0e01d":"the type of each element:","1fa28a63":"- Note: The `near` image is a bit more pixelated because no interpolation has been done during the scaling process. It simply uses the closest pixels compared to the source image","b38cd2de":"## Skin Detection","d17d563b":"## Scale and rotate images","29f7b5bc":"## Data types and structures","2ecf0691":"Let's see what is inside the image:","23637797":"## Adaptive Thresholding","2c073498":"The goal is to segment each individual tomatoes. Lets first try a simple thresholding. Note that the hue values are around red between 0 and 25","c19e29a6":"Splitting the image into its channels by `cv2.split`","ea70517f":"first we load an image and explicitly specify black and white by choosing `0`","df630526":"One channel image:","9ee74700":"Transformation of the images: BW to Color, etc.","0d7df550":"__Hue Saturation Value space__[](http:\/\/)","fbd7b855":"The total number of pixles:","6ad9db04":"## Pixel manipulation and filtering","14c8510f":"- The left pic filters small saturation out\n- The mid pic filters high hue out\n- the right pic multiplies both images.\n\nApparently, using this strategy we can have a focus on the skins in the final image.As an example look at the individual in the right most and then down one row. his right shulder appears white in the left, it is black in the mid and in the right it disappears!","b6ade28b":"## Use video inputs","0bb057a0":"Apparently it has combined the three tomatos into a single object! which is not what we want. Canny edges helps us to break it up!","ba22cbca":"- Adaptive thresholding is increases the versitality of thresholding\n- looks at the local neighboring.","297f0f01":"## Contour object detection","4e7a7539":"Next we want to display our image. We first initialize a named window using `cv2.namedWindow`:","7a9352dd":"which means unsigned integers. `8` means that the range of the values vary from `0` to `2**8=256`. (256 numbers which means 0, ..., 255!)\n\nNow we can access each individual pixle:","6fa85e76":"Built-in method:","45d27b97":"## Read-Write commands:","360fa987":"Lets make a deep copy of `ones` in `color`. \n\nWe want to assign a color to all pixles in the picture:","2ccea2b4":"converting the number of channels down to 1 using `cv2.cvtColor(color,cv2.COLOR_RGB2GRAY)`","ff150d7e":"`findContours` is a useful tool for __shape analysis__ and __object detection__","a84bc486":"NOTE: This part will be done on the local computer. Because it involves image capturing which probabely is not supported by kaggle.","c4e53020":"## Blur, dilation and erosion","b981f18d":"- `countor`: actual list of individual contours. Countor is a list of points which describes the perimeter of an object\n- `hierarchy`: is a parent and child relationship of all the contours","90c96a59":"Here a simple hand-made segmentation by setting a `threshold`","192a5a16":"## Simple thresholding","a94e95f8":"A simple basic thresholding","acdb8518":"- Segmentin skin tones from the image. \n- composite of thresholdings","b5ec5989":"Its problematic!","e60d29a3":"## Access and understand pixel data","3f05ca51":"much more better result.","81e6f830":"We use `cv2.GaussianBlur` to Gaussian blur the picture. The second argument says how much bluring along each axis. It should be an `odd` number","ab2299fa":"* 2- Dilation and Erosion Filter\n\n- Dilation: turns black pixels into white\n- Erosion : turns white pixels into black","a8bc9639":"the number of channels:","b5db8bb5":"Let us generate a black image:","127474e3":"Now we are going to look at the area, perimeter and centroids of the detected objects","1584f9f5":"1- Gaussian Blur: Smoothens the picture by averaging the pixles with its neighbors. ","6352e830":"Here we have a lot more details about the edges than the simple thresholding","7231aeeb":"Note that the `plt.imshow` supposes an image of `RGB`, while `cv2` makes an image of `BGR`. We first transform to `BGR`","c1daf61b":"We start out by reading in the image. We do this task by function `cv2.imread`'","c2f1b56d":"We want to merge images using `cv2.merge`:","9102ed93":"number of rows, vertical pixles and channels:","70ae4c01":"Note that we are in the `RGB` format, if we use `plt.imshow()`, From the tutorial, it seems that `cv2.imshow()` uses a `BGR` format instead!","a8f484b8":"## Canny edge detection","28e2ec69":"# OpenCV, Linkedin Course"}}