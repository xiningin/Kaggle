{"cell_type":{"54fa004c":"code","2b89830f":"code","2317b881":"code","5cceb773":"code","18bb8c7b":"code","e9e4446b":"code","cc0717a4":"code","370bb8b9":"code","fa89912d":"code","b99443be":"code","c8eafc9f":"code","c593b90a":"code","86f4604a":"code","d39163d5":"code","6a5b206a":"code","92305b15":"code","f46eb053":"code","e8c516e7":"code","b971e13a":"code","e9682e5b":"code","bce302cf":"code","03507c73":"code","d29a6e4e":"code","25ebf017":"code","2e273d34":"code","037324f3":"code","28632995":"code","9170fac8":"markdown","364e6cbc":"markdown","e70c9060":"markdown","2bbdd61c":"markdown","b24d110c":"markdown","ee8cd34c":"markdown","6599a39e":"markdown","804b757d":"markdown","c4b581e0":"markdown","abae331c":"markdown","3a92d6e7":"markdown"},"source":{"54fa004c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2b89830f":"pubg = pd.read_csv('..\/input\/train_V2.csv')\npubg.head()","2317b881":"pubg.info()","5cceb773":"# let's see the nOfNull values in each columns\npubg.isnull().sum()","18bb8c7b":"pubg[pubg['winPlacePerc'].isnull()]","e9e4446b":"pubg.matchId.nunique()","cc0717a4":"pubg.matchType.value_counts()","370bb8b9":"pubg.describe()","fa89912d":"def plot_heatmap(corrmat, title):\n    sns.set(style = \"white\")\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    \n    mask = np.zeros_like(corrmat, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    plt.figure(figsize=(20, 20))\n    hm = sns.heatmap(corrmat, mask=mask, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, cmap=cmap)\n    hm.set_title(title)\n    plt.yticks(rotation=0)\n    plt.show()","b99443be":"cols_to_drop = ['Id', 'groupId', 'matchId', 'matchType']\ncols_to_fit = [col for col in pubg.columns if col not in cols_to_drop]\ncorr = pubg[cols_to_fit].corr()","c8eafc9f":"plot_heatmap(corr, \"Correlation Table\")","c593b90a":"from pandas.plotting import scatter_matrix\n\nscatter_matrix(pubg[[\"killPlace\", \"killPoints\", \"winPoints\", \"winPlacePerc\"]], figsize=(16, 10));","86f4604a":"pubg_copy = pubg.copy()","d39163d5":"pubg_copy['winPlacePerc'].fillna(0, inplace=True)","6a5b206a":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(pubg_copy, pubg_copy['matchType']):\n    strat_train_set = pubg_copy.loc[train_index]\n    strat_test_set = pubg_copy.loc[test_index]","92305b15":"X_train = strat_train_set[cols_to_fit[:-1]].copy()\n\ny_train = strat_train_set.winPlacePerc.copy()","f46eb053":"X_test = strat_test_set[cols_to_fit[:-1]].copy()\n\ny_test = strat_test_set.winPlacePerc.copy()","e8c516e7":"X_train_dummy = pd.get_dummies(strat_train_set.matchType)","b971e13a":"X_test_dummy = pd.get_dummies(strat_test_set.matchType)","e9682e5b":"X_train = pd.concat([X_train, X_train_dummy], axis='columns').copy()","bce302cf":"X_test = pd.concat([X_test, X_test_dummy], axis='columns').copy()","03507c73":"# DecisionTree\nfrom sklearn.tree import DecisionTreeRegressor\n\ndt = DecisionTreeRegressor()\n\ndt.fit(X_train, y_train)\n\ndt.score(X_train, y_train)","d29a6e4e":"dt.score(X_test, y_test)","25ebf017":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(DecisionTreeRegressor(), X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\nprint(\"Scores:\", tree_rmse_scores)\nprint(\"Mean:\", tree_rmse_scores.mean())\nprint(\"Standard deviation:\", tree_rmse_scores.std())","2e273d34":"# RandomForest\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators=20)\n\nrf.fit(X_train, y_train)\n\nrf.score(X_train, y_train)","037324f3":"rf.score(X_test, y_test)","28632995":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(RandomForestRegressor(n_estimators=20), X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-scores)\n\nprint(\"Scores:\", forest_rmse_scores)\nprint(\"Mean:\", forest_rmse_scores.mean())\nprint(\"Standard deviation:\", forest_rmse_scores.std())","9170fac8":"we only one mising value so can fill the missin value with zero since the  `walkDistance` is zero","364e6cbc":"We only have one missing value in the `winPlacePerc` column.","e70c9060":"### One-Hot-Encoding\n\nwe encode the `matchType` feature using one-hot encoding.","2bbdd61c":"We don't need to scale the data before training a model by using DesicionTree and RandomForest algorithms. In other words, they don't require scaling of the data.","b24d110c":"## Explore the Data","ee8cd34c":"# Introduction to DecisionTree and RandomForest\n\nIn this kernel, we train the PUBG dataset using two broadly used tree-based supervised algorithms namely `DecisionTree` and `RandomForest`.   These algorithms for regression and classification are currently among the most widely used machine learning methods.\n\nWe use the regression models of the mentioned learning algorithms. \n\nNote that this kernel has just an introductory purpose and is for giving you some ideas about how the models could work.","6599a39e":"## Train RandomForestRegressor[](http:\/\/) Model","804b757d":"## Train DecisionTreeRegressor Model","c4b581e0":"## Prepare the Data","abae331c":"## Split the Data","3a92d6e7":"## Get the Data\n"}}