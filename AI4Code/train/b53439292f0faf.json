{"cell_type":{"b3dc4b5e":"code","46589db0":"code","b05154ab":"code","e5274455":"code","091bacb1":"code","4a10353c":"code","a33e18a2":"code","e59ae962":"markdown","a4bbd7bd":"markdown","5f7d57ef":"markdown","51ef71d7":"markdown","c9f7065f":"markdown","8ce2ff95":"markdown","b60fc67e":"markdown","5d3ccbb7":"markdown","789235c6":"markdown","684e0566":"markdown","782aa8a6":"markdown"},"source":{"b3dc4b5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46589db0":"import tensorflow as tf\nimport tflearn\nfrom tflearn.layers.conv import conv_2d,max_pool_2d\nfrom tflearn.layers.core import input_data,dropout,fully_connected\nfrom tflearn.layers.estimator import regression\nimport numpy as np\nimport cv2\nfrom sklearn.utils import shuffle","b05154ab":"# Please change the directory path according to your path.\n#Load Images from Swing\nloadedImages = []\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/SwingImages\/swing_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images From Palm\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/PalmImages\/palm_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n    \n#Load Images From Fist\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/FistImages\/fist_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n#Load Images From One\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/One\/one_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images From Two\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/Two\/two_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images From Three\nfor i in range(0, 1000):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/Three\/three_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n    \n","e5274455":"# Create OutputVector\n\noutputVectors = []\nfor i in range(0, 1000):\n    outputVectors.append([1, 0, 0, 0, 0, 0])\n\nfor i in range(0, 1000):\n    outputVectors.append([0, 1, 0, 0, 0, 0])\n\nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 1, 0, 0, 0])\n\nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 0, 1, 0, 0])    \n\nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 0, 0, 1, 0])    \n    \nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 0, 0, 0, 1])    \n","091bacb1":"testImages = []\n\n#Load Images for swing\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/SwingTest\/swing_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images for Palm\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/PalmTest\/palm_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n    \n#Load Images for Fist\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/FistTest\/fist_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n#Load Images for One\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/OneTest\/one_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n#Load Images for Two\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/TwoTest\/two_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n#Load Images for Three\nfor i in range(0, 100):\n    image = cv2.imread('\/kaggle\/input\/hand-gesture-recognition\/Dataset\/ThreeTest\/three_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))    \n\n#One-hot encoding of test images    \ntestLabels = []\n\nfor i in range(0, 100):\n    testLabels.append([1, 0, 0,0,0,0])\n    \nfor i in range(0, 100):\n    testLabels.append([0, 1, 0,0,0,0])\n\nfor i in range(0, 100):\n    testLabels.append([0, 0, 1,0,0,0])\nfor i in range(0, 100):\n    testLabels.append([0, 0, 0,1,0,0]) \nfor i in range(0, 100):\n    testLabels.append([0, 0, 0,0,1,0])\nfor i in range(0, 100):\n    testLabels.append([0, 0, 0,0,0,1])    ","4a10353c":"# Define the CNN Model\ntf.reset_default_graph()\nconvnet=input_data(shape=[None,89,100,1],name='input')\nconvnet=conv_2d(convnet,32,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\nconvnet=conv_2d(convnet,64,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,128,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,256,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,256,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,128,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,64,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=fully_connected(convnet,1000,activation='relu')\nconvnet=dropout(convnet,0.75)\n\nconvnet=fully_connected(convnet,6,activation='softmax')\n\nconvnet=regression(convnet,optimizer='adam',learning_rate=0.001,loss='categorical_crossentropy',name='regression')\n\nmodel=tflearn.DNN(convnet,tensorboard_verbose=0)\n","a33e18a2":"# Shuffle Training Data\nloadedImages, outputVectors = shuffle(loadedImages, outputVectors, random_state=0)\n\n# Train model\nmodel.fit(loadedImages, outputVectors, n_epoch=50,\n           validation_set = (testImages, testLabels),\n           snapshot_step=100, show_metric=True, run_id='Beast')\n\nmodel.save(\"TrainedModel\/GestureRecogModel.tfl\")","e59ae962":"### Note:\n* **Ignore the first cell if you doing the project in your local system or google colab notebook.**","a4bbd7bd":"* **Generally the beginners have this question about how to set the architecture of the model and how to zero down on having how many layers in the network. I'm planning to make a kernel or blog on the basics of what is CNN and How to go about choosing the architechtures. I'm gonna update the version of this kernel once I'm done with that.** ","5f7d57ef":"* **Loading test images from their respective directories and following the similar approach of training images.**","51ef71d7":"**Importing Required libraries**\n\nNote that we are using tensorflow 1.13.1 version","c9f7065f":"#### **Requirements**\n* Python3\n* Tensorflow version=1.13.1\n* TfLearn\n* Opencv headless (cv2) for python3\n* Numpy\n* Pillow (PIL)\n* Imutils\n\n**Note:**\nrequirements file is available in the data. I recommend to create a new python virtual environment and install the requirements file.\n\n**To install requirements file**\n* Move to the directory( cd filename),command is same in both windows & linux\n\n> pip install -r requirements.txt","8ce2ff95":"#### Training Images\n* **Loading images from their respective directories and converting them to grayscale**\n* **All the images now become an array of pixels of size(89,100,1), 1 channel as we converted the image to grayscale** \n* **We are using opencv to read and convert the image to grayscale**","b60fc67e":"Training Step: 3175  | total loss: 0.00001 | time: 1.771s\n| Adam | epoch: 034 | loss: 0.00001 - acc: 1.0000 -- iter: 4672\/6000","5d3ccbb7":"### Conclusion\n* **We have successfully completed the hand gesture recognition project** \n* **We can save this model in any way. If you plan to deploy the model, I recommend you to follow https:\/\/www.tensorflow.org\/js\/tutorials\/conversion\/import_saved_model**\n* If you have suggestions or queries, please feel free to write it down under comments section.","789235c6":"### If you like the work please upvote my kernel.If you have any suggestions, please do post them in the comments.\n### Thanks in advance. All the best for your future endeavours.","684e0566":"#### One-hot Encoding of training images\n* Now its time for one-hot encoding. Check out the below link to know what is one-hot encoding and why do we need to do it.\n* **https:\/\/machinelearningmastery.com\/how-to-one-hot-encode-sequence-data-in-python\/**\n* Youtube Tutorial : **https:\/\/youtu.be\/v_4KWmkwmsU**","782aa8a6":"* **Now that we are all set with the data loading and preparing it for feeding it for our model, it's high time that we need to start modelling.**\n* **Since we are using tensorflow, we have to perform everything after initializing the tensorflow graph.**\n* **If you don't have an idea of how tensorflow works I've made another notebook about it. Please do check the below link to get proper idea.**"}}