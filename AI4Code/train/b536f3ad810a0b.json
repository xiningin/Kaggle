{"cell_type":{"42c3b9c9":"code","9612b888":"code","747a052b":"code","bf4f6a87":"code","745aa56a":"code","80414668":"code","b8163b3b":"code","d9657b08":"code","43385dd9":"code","ebf0a0d7":"code","10b201c5":"code","8da7ed4a":"code","a1631de6":"code","491b4c7a":"code","2f22d6fd":"code","c820a4af":"code","bf9fe06c":"code","82c10f26":"code","932ccdbd":"code","84cd3dd3":"code","daa7415c":"code","814a0d1e":"code","a7e7d128":"code","b5e12371":"code","c0de7879":"code","812992b5":"code","6a4991da":"code","f1ac935f":"code","2c181738":"code","338d9a50":"code","689e2644":"code","662c016d":"code","e21ed2f5":"code","ca067cc2":"code","637dde64":"code","b5b8f063":"code","fbe0017c":"code","6bbb4650":"code","b5e114d6":"code","7b6b9ed8":"markdown","ece92373":"markdown","c623e221":"markdown","4bcff0a5":"markdown","b9838fe8":"markdown","69deb2bb":"markdown","02ac8693":"markdown","8feb3dd8":"markdown","ea3040ec":"markdown","4255cf85":"markdown","b4b0d301":"markdown","7cb0b6d1":"markdown","eee9b392":"markdown","3fb80457":"markdown","93a4e595":"markdown","828b2ffd":"markdown","bf972dd4":"markdown","7909373b":"markdown","2270fd9b":"markdown","2bee1604":"markdown","a31bd8a8":"markdown","bcfa5a3e":"markdown","c1be8b48":"markdown","001886fe":"markdown","f4238ddc":"markdown","16184289":"markdown","e87d1bb9":"markdown","afb7fd8b":"markdown","b156c05a":"markdown"},"source":{"42c3b9c9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport dateutil\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nimport cartopy.crs as ccrs\nimport os\n\n%matplotlib inline\nsns.set()","9612b888":"orders = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv')\ncustomers = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv')\nsellers = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv')\norders_items = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\nproducts = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_products_dataset.csv')\ngeolocation = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv', engine='python')\n\ndatasets_names = ['orders', 'customers', 'sellers', 'orders_items', 'products', 'geolocation']\nfor dataset in datasets_names:\n    print(\"Dataset {} has shape {}\".format(dataset, eval(dataset).shape))","747a052b":"def dtypes_pie(dset, axis):\n    x = dset.dtypes.value_counts()\n    labels = [y.name for y in x.index.values]\n    wedges, text, autotexts = axis.pie(x=x.values,labels=labels, autopct='%1.1f%%', explode=[0.05]*len(x), pctdistance=0.5)\n    axis.set_title('DF {}'.format(get_df_name(dset)))\n    axis.legend(wedges, labels,\n          title=get_df_name(dset),\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\ndef get_df_name(df):\n    name =[x for x in globals() if globals()[x] is df][0]\n    return name","bf4f6a87":"fig, axs = plt.subplots(1, 3, figsize=(20, 20))\ndtypes_pie(orders, axs[0])\ndtypes_pie(customers, axs[1])\ndtypes_pie(sellers, axs[2])\nfig, axs = plt.subplots(1, 3, figsize=(20, 20))\ndtypes_pie(orders_items, axs[0])\ndtypes_pie(products, axs[1])\ndtypes_pie(geolocation, axs[2])","745aa56a":"print(\" The following columns should be of dtype datetime: \", orders.columns[3:].values)","80414668":"for column in orders.columns[3:].values:\n    if orders[column].dtype != np.dtype('<M8[ns]'):\n        orders[column] = pd.to_datetime(orders[column], cache=True)\n    else:\n        continue\nfig, ax = plt.subplots()\ndtypes_pie(orders, ax)","b8163b3b":"orders_items['shipping_limit_date'] = pd.to_datetime(orders_items['shipping_limit_date'], cache=True);","d9657b08":"for dataset in datasets_names:\n    print(\"In dataframe {} there are approximately {} null values\".format(dataset, eval(dataset).isna().sum().sum()))","43385dd9":"orders.isna().sum()","ebf0a0d7":"orders[orders.order_approved_at.isna()].head()","10b201c5":"orders[orders.order_delivered_carrier_date.isna()].head()","8da7ed4a":"null_del_car = orders[orders.order_delivered_carrier_date.isna()]\nfig, axs = plt.subplots(1, 2, figsize=(10,5))\naxs[0].bar(x=null_del_car.order_status.value_counts().index, height=null_del_car.order_status.value_counts().values)\naxs[0].set_title('Different Status with Delivered Carrier NaT')\nwedges, text, autotexts = axs[1].pie(x=null_del_car.order_delivered_customer_date.value_counts(dropna=False),labels=null_del_car.order_delivered_customer_date.value_counts(dropna=False).index, autopct='%1.1f%%', explode=[0.05]*2, pctdistance=0.5)\naxs[1].set_title('Data in Delivered Customer Date')\naxs[1].legend(wedges, null_del_car.order_delivered_customer_date.value_counts().index,\n      title='Label',\n      loc=\"center left\",\n      bbox_to_anchor=(1, 0.2, 0.5, 1))\nfor tick in axs[0].get_xticklabels():\n    tick.set_rotation(-45)","a1631de6":"orders = orders[~orders.order_delivered_carrier_date.isna()]\norders.isna().sum()","491b4c7a":"orders[orders.order_delivered_customer_date.isna()].head()","2f22d6fd":"orders[orders.order_delivered_customer_date.isna()].isna().sum()","c820a4af":"orders = orders[~orders.order_delivered_customer_date.isna()]","bf9fe06c":"orders.shape","82c10f26":"products.isna().sum()","932ccdbd":"products[products['product_category_name'].isna()].info()","84cd3dd3":"print(orders.order_approved_at.max() - orders.order_approved_at.min(), ' from ', \n      orders.order_approved_at.min(), ' to ', orders.order_approved_at.max())","daa7415c":"monthcount = orders.order_approved_at.dropna().sort_values().apply(lambda x: x.strftime(\"%b-%y\"))\ng = sns.countplot(x=monthcount)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_xlabel('Month-Year')\ng.set_ylabel('Orders Count');","814a0d1e":"print(\"Number of unique categories: \", len(products.product_category_name.unique()))","a7e7d128":"prod_categories = products.groupby('product_category_name')['product_id'].count().sort_values(ascending=False)\ng = sns.barplot(x=prod_categories.head(10).index, y=prod_categories.head(10).values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_xlabel('Product Category')\ng.set_title('10 Most Common Categories');","b5e12371":"translated_categories = pd.read_csv('..\/input\/brazilian-ecommerce\/product_category_name_translation.csv')\ntop10_cat = translated_categories[translated_categories['product_category_name'].isin(prod_categories.head(10).index)]\nprint(top10_cat)","c0de7879":"top10_perc = prod_categories.head(10).values.sum() \/ prod_categories.values.sum() * 100\nprint(\"Number of Products in Top 10 Categories: \", prod_categories.head(10).values.sum())\nprint(\"Share of Top 10 Categories in Products Dataframe: {0:.2f}\".format(top10_perc))","812992b5":"cats = ['cama_mesa_banho', 'esporte_lazer', 'moveis_decoracao']\nitems = pd.merge(left=orders_items, right=products, left_on='product_id', right_on='product_id')\ntop3_cats = items[items['product_category_name'].isin(cats)].count()\nprint(\"{} of {} items purchased belong to the top three categories: {}.\".format(top3_cats.values[0], items.shape[0], cats))\nprint(\"Or about {0:.2f}%.\".format(top3_cats.values[0]\/items.shape[0]*100))","6a4991da":"bestseller = items['product_id'].value_counts()\nprint(\"Frequency of Top Seller: {}\".format(bestseller[0]))\nproducts[products.product_id == bestseller.index[0]]","f1ac935f":"g = sns.countplot(x='customer_state', data=customers)\ng.set_xticklabels(g.get_xticklabels(), rotation=-45);\ng.set_title('Customers by State');","2c181738":"print(customers.shape)","338d9a50":"g = sns.countplot(x='seller_state', data=sellers)\ng.set_xticklabels(g.get_xticklabels(), rotation=-45);\ng.set_title('Sellers by State');","689e2644":"print(sellers.shape)","662c016d":"ten_cities = customers[customers['customer_state'] == 'SP'].groupby('customer_city').count().sort_values(by='customer_state', ascending=False).head(10)\n\nsellers_and_orders = pd.merge(pd.merge(orders, orders_items, on=['order_id'])\n              .groupby(['order_id', 'seller_id'], as_index=False)\n              .agg({'price': 'sum'}, as_index=False),\n              sellers, on='seller_id')\ndf = sellers_and_orders[(sellers_and_orders['seller_state'] == 'SP') & \n        (sellers_and_orders['seller_city'].isin(ten_cities.index))].groupby('seller_city')['price'].sum().reindex(ten_cities.index)\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\n\ng = sns.barplot(x=ten_cities.index, y=ten_cities.customer_state, ax=axs[0])\ng.set_title('Orders by City in SP')\ng.set_xlabel('City in SP')\ng.set_ylabel('Customer per City')\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\n\ng = sns.barplot(x=df.sort_values(ascending=False).index, y=df.sort_values(ascending=False).values, ax=axs[1])\ng.set_title('Money Received by City in SP')\ng.set_xlabel('City in SP')\ng.set_ylabel('Money per City')\ng.set_xticklabels(g.get_xticklabels(), rotation=90);","e21ed2f5":"total_revenue = sellers_and_orders['price'].sum()\nsp_revenue = sellers_and_orders[(sellers_and_orders['seller_state'] == 'SP')].price.sum() \/ total_revenue * 100\nsp_cap_revenue = sellers_and_orders[(sellers_and_orders['seller_state'] == 'SP') & (sellers_and_orders['seller_city'] == 'sao paulo')].price.sum() \/ total_revenue * 100\nprint(\"Share of the state of S\u00e3o Paulo in national e-commerce revenue: {0:.2f}%\".format(sp_revenue))\nprint(\"Share of the city capital S\u00e3o Paulo in national e-commerce revenue: {0:.2f}%\".format(sp_cap_revenue))","ca067cc2":"orders.columns, orders_items.columns","637dde64":"customers_orders = pd.merge(pd.merge(orders, orders_items, on=['order_id'])\n              .groupby(['order_id', 'customer_id', 'order_approved_at', 'order_delivered_customer_date'], as_index=False)\n                .agg({'price': 'sum'})\n              ,customers, on='customer_id')","b5b8f063":"fy_orders = customers_orders[(customers_orders.order_approved_at >= pd.Timestamp(\"2017-01-01\"))\n                            & (customers_orders.order_approved_at < pd.Timestamp(\"2018-01-01\"))]\nmedian_one = fy_orders.price.median()\nmean_one = fy_orders.price.mean()\n\nsy_orders = customers_orders[(customers_orders.order_approved_at >= pd.Timestamp(\"2017-09-01\"))\n                            & (customers_orders.order_approved_at <= pd.Timestamp(\"2018-08-31\"))]\nmedian_two = sy_orders.price.median()\nmean_two = sy_orders.price.mean()","fbe0017c":"print(\"The mean customer spending from January 1st, 2017 to December 31st,  2017 was {0:.2f} \".format(mean_one),\n      \"and the median customer spending in the same period was {0:.2f}.\".format(median_one))\nprint(\"The mean customer spending from September 1st, 2017 to August 31st,  2018 was {0:.2f} \".format(mean_two),\n      \"and the median customer spending in the same period was {0:.2f}.\".format(median_two))","6bbb4650":"monthly_avgs = []\n#First Period Averages\nfor i in range(1, 13):\n    ords = fy_orders[fy_orders.order_approved_at.dt.month == i].price\n    mean = ords.mean()\n    median = ords.median()\n    month = i\n    year = 2017 \n    monthly_avgs.append([month, year, mean, median])\n    \n    if i in range(1, 9):\n        ords = sy_orders[(sy_orders.order_approved_at.dt.month == i) & (sy_orders.order_approved_at.dt.year == 2018)].price\n        mean = ords.mean()\n        median = ords.median()\n        month = i\n        year = 2018\n        monthly_avgs.append([month, year, mean, median])\n        \nmonthly_avgs = pd.DataFrame(monthly_avgs, columns=['month', 'year', 'mean', 'median'])","b5e114d6":"fig, axs = plt.subplots(1, 2, figsize=(10, 5))\ng = sns.lineplot(data=monthly_avgs, x='month', y='mean', hue='year', ax=axs[0], palette='colorblind')\ng.set_title('Mean per Month')\nh = sns.lineplot(data=monthly_avgs, x='month', y='median', hue='year', ax=axs[1], palette='colorblind')\nh.set_title('Median per Month');","7b6b9ed8":"There are 610 missing values in category name, length of product's name, length of description and quantitiy of pictures, and 2 in all other columns except product id. That is, there are 610 products *nameless* products. \n\nDespite this, I don't think it would be a good idea to just drop them. Products that have no description or name could be 'adult' products, or errors in the gathering of data. There's plenty of reasons it could be, and messing this up could potentially damage our ability to understand the relation between orders and products. For instance, most products have non-null values in the columns for size and weight, which we could use to understand the relation between these variables and freight value. This is just an example, but there's plenty of others. Let's leave them as they are.\n\nLastly, let's see the range of time the orders dataset contains and the span of orders throughout the months in the range.","ece92373":"We can cleary see a rise in e-commerce purchases since January 2017, with some sparks in November-17, January-18. These sharp ascents may be due to the Black Friday, a commercial event that usually takes place in November 26th, as well as the traditional clearance sales of January. From this, I think it's safe to assume that e-commerce purchases *were* experiencing a rise in Brazil. Since I'm writing this in early 2021, it's not possible to say if this rise still is the case.","c623e221":"From the above plot we see that a very large share of our customers are based in the federal state of S\u00e3o Paulo (about 40000 of our 99441 clients). It's a huge share considering there's 26 states and 1 federal district. About 60% of consumers are left to be spread accross 26 regions. However, I wonder what's the distribution of sellers like.","4bcff0a5":"While the mean customer spending decreased from the first to the second period, the median customer spending rose. Why is that? There's plenty of reasons, but one safe guess is that simply 2017 had more high priced orders than 2018; another safe guess would be to consider the number of high priced orders more or less the same and a higher number of low priced orders (which would then \"push the mean down\").\n\nLet's verify the assumptions above. First, we'll look at the distribution of monthly spending averages throughout both periods and compare them. Then, if needed, we'll look into other aspects of the data.","b9838fe8":"Notice how the means differ from each other in the first few months, and how the 2018 mean seems to follow the same trend as the 2017 mean. However the medians are very close to each others, and the 2018 median seems to perform above the 2017 median. These findings may imply that there were a higher number of high-priced orders at the beginning of 2017, which would explain the almost R\\\\$20,00 difference in January.","69deb2bb":"It seems the best selling product belongs to the *Furniture & Decoration* category. It appears in our dataset 527 times and weighs 2.6 kilograms. It has 6 uploaded photos and a description of almost a thousand characters. This is just an example of analysis we can perform with this dataset. Further down this notebook we'll look for patterns in best selling items and successfull orders.\n\n\n## E-Commerce Concentration <a class='anchor' id='concentration'><\/a>\n\nNow, it's time to look at the customers dataset. Since our dataset contains information about orders throughout Brazilian territory, we can learn a lot about the behaviors of consumers online and the distribution of \"online wealth\".","02ac8693":"Nearly a fourth of all ordered items belong to one of these three categories! This is surprising, since we've just shown that there are 74 *unique categories*. However, let's not get carried away with such a finding. Perhaps the quantity of unique categories may be due to different sellers categorizing their products differently, that is, labelling the same products in different ways. For instance, if you're selling a shower, you could place it in *Bed, Bath & Table* as well as in *Houseware*. Same with perfumes, you could label them as *Health & Beauty* as well as *Watches & 'Gifts'*.\n\nOver a a *hundred thousand* items were purchased in the range of our data and this is a quite limited dataset (in the sense that there are many unlisted sellers acting in the market). Despite this, its potential is huge for learning many things about the state of e-commerce in Brazil.","8feb3dd8":"It stands out that some orders are labeled *canceled* and it seems all dates besides the purchase and estimated delivery dates are missing too. Let's look at a column that has more missing values, the delivered carrier date (the date the orders reached the shipping company's headquarters).","ea3040ec":"Expand the output below if you'd like to translate the categories to English, but I do that myself in the lines below.","4255cf85":"## Basic Statistics <a class='anchor' id='basic_stats'><\/a>\n\nNow, let's look at some basic statistics of our data. One of the most interesting, given our purpose, is the average customer spending in the e-commerce sector. Firstly, it's interesting to limit the average customer spending to a year, since that's the usual period of analysis for most sellers. Secondly, it's important to distinguish between the various \"averages\", that is, the measures of central tendency.\n\nIf we choose the 'mean' as a central tendency measure, we may suffer from extremely high priced orders as well as low priced orders; this is due to the 'mean' being calculated by the arithmetic sum, that may push the value upwards.\n\nChoosing the 'median' may eliminate that problem, but creates others, such as leading to a false impression. Suppose the age span of patients with a specific disease ranges from 40 to 60. If the doctor says the average age at which people develop this specific disease is 50 (the median), he\/she may be leading to a false impression that people below this age are safe.\n\nAnyway, below I present these two values and discuss them in further detail. Keep in mind that our analysis will consider two periods, from jan-17 to dec-17 and sep-17 to aug-18. I did this so we may compare how these values evolved.","b4b0d301":"## Products <a class='anchor' id='dist'><\/a>\n\nFirst, let's look at the distribution of products categories.","7cb0b6d1":"# The Fastest Growing Commerce in Brazil\n\n<i> This is a project in development, divided into many notebooks for simplicity's sake. Please, if you find anything that is wrong and\/or could be realized in another more efficient way, don't hesitate to get in touch! <\/i>\n\nThis dataset comprises many different information concerning sales made by e-commerce retailers from 2016 to 2018. Besides orders, it contains data regarding sellers, customers, products, payments, reviews, geolocation (of both sellers and customers). We'll deal with this data in many notebooks, each with a specific purpose. These notebooks will be listed directly below. If you don't find a specific analysis, it probably doesn't exist yet.\n\nThe intention behind these analysis is to provide a profile for understanding the average brazilian customer and the future of e-commerce sales in the country.\n\n### Notebooks\n<ul>\n    \n<\/ul>\n\n\n## Contents\n\n1. [Initializing](#init)\n2. [Loading The Data](#loading)\n    * [Presenting the files](#presenting)\n    * [Objective](#objective)\n3. [Exploratory Data Analysis](#eda)\n    * [Checking for Null Values](#nan)\n    * [Products](#prods)\n    * [Bestseller](#bestseller)\n    * [E-Commerce Concentration](#concentration)\n    * [Customers Statistics](#cust_stats)","eee9b392":"### Checking for null values <a class='anchor' id='nan'><\/a>\n\nNow that we've seen some of the types of data we'll be handling, let's check for null values in the datasets.","3fb80457":"## Exploratory Data Analysis <a class='anchor' id='eda'><\/a>\n\nFirst and foremost, let's understand what are we messing with.","93a4e595":"## Loading the Data <a class='anchor' id='load'><\/a>\nLet's import all the files into a few Pandas Dataframes and print basic information about them (number of rows, cols).","828b2ffd":"600 of the orders that are missing values for delivered_carrier_date column are labeled as *unavailable*, another *550 or so are labeled canceled*. About 300 are labeled as invoiced and another 300 as processing. It stands out that most of these orders are not of interest, since we can't know what to make of it. About six hundreds (invoiced and processing) could be used to analyze what customers *are* buying, but I doubt due to few data points. Let's drop these and look again at the nan values.","bf972dd4":"Hm... About 56% of our sellers are also based in S\u00e3o Paulo. This makes sense since the state of SP is home to the biggest city in South America and one of the most important cities in the commercial world. Despite the significance of this finding, it casts a shadow over other potential benefits of our data. In future analysis we shall look to the distribution of customers and sellers and how they relate to each other (which buyers purchase more at home state and which don't, etc).","7909373b":"If we look at the other datasets, we'll see that there is one column of orders_items that should also be of datetime dtype. Let's also change that.","2270fd9b":"The plots above represent the concetration of wealth within the state of S\u00e3o Paulo. As expected, most orders are made and **received** in capital S\u00e3o Paulo. Notice that the first plot shows us the concentration of customers (or at least orders) in the capital, whereas the second shows that for all the sellers in the state of S\u00e3o Paulo, most of the money goes to sellers based in the capital regardless of consumers location. \n\nAlmost R$ 2.5 million was received by S\u00e3o Paulo-based sellers in the span of our data. Let's take a look at the share of national revenue that this figure represents.","2bee1604":"### Presenting the files <a class='anchor' id='presenting'><\/a>\n\nThe **orders** dataframe contains information about orders, including customer_id and order_id, which are unique identifiers of orders. We'll use both these fields in the future to reference the **customers** and **orders_items** dataframes, which contain, respectively, information about customers (city, state, zip code and unique identifier) and products bought (their id in the order, id of seller, shipping limit date, price and freight value).\n\n\n\n### Objective <a class='anchor' id='objective'><\/a>\nIn this notebook we'll aim for exploring and understanding the relationship between the data in different files and aspects of the information inside those. At the end of the notebook, we expect to have learnt important relations that could be then used in another file to gain insights on the behavior of brazilian consumers and the value of this information to sellers.\n","a31bd8a8":"Of the rows with missing delivered to customer date, none are missing 'order_approved_at', which makes sense, since an order would be first approved and then delivered to the customer. These rows, that miss delivered to customer date, may refer to orders that were collected too early, that is, before the orders could be delivered to the clients. Let's drop them.","bcfa5a3e":"As we may see from the pie charts above, most of our data is of object dtype. Some of it comes as floats and few as integers. Some of the data in the orders dataset, for instance, refers to datetime, but it's stored as object dtype. Let's change that for future use.","c1be8b48":"The proportion of S\u00e3o Paulo (state) revenue in relation to national revenue is about 9% higher than the proportion of sellers based in the state, and ~14% higher than the proportion of customers based in S\u00e3o Paulo. This *suggests* an unequal concentration of wealth, which we'll explore later. For now, the findings above will suffice.","001886fe":"There are still 1183 nan values in the order_delivered_customer_date column. Let's look at some of these rows.","f4238ddc":"About 20745 products belong to the 10 most common categories of products, about 64% of all products. It's a large share considering we have *74 unique categories*. The three most frequent product categories are *Bed, Bath & Table, Sports\/Leisure and Furniture & Decoration*. Let's explore the share of these three categories in all orders!","16184289":"We're left with a dataset that contains 96475 rows. That's a lot of data. Now that we've explored the missing values of the orders dataset, let's take a look at the products data. As we've printed earlier, there are 2448 missing values in the **products** dataframe. Let's see from which columns are these values missing.","e87d1bb9":"Most missing data from the **orders** dataframe is present in the datetime-related dates (most of these missing values refer to the actual delivery date). In fact, it seems there are no orders with empty ids, status, customer_ids, and estimated delivery date, which is a significant aspect of the Olist dataset. Let's understand if there is any reasoning behind these missing values.","afb7fd8b":"## Initializing <a class='anchor' id='init'><\/a>","b156c05a":"### Best-selling item characteristics <a class='anchor' id='bestseller'><\/a>\n\nBelow, we select the best selling item from the database (the one with most purchases) and explore some of its characteristics, physical as well as \"digital\", that is, information regarding its page in the website."}}