{"cell_type":{"3d1e0183":"code","01035e2d":"code","b2cc1360":"code","597d1588":"code","346d7327":"code","dbf9a954":"code","22ec5dbe":"code","40218b10":"code","bdab43d1":"code","307a110a":"code","0f7c9f5c":"code","2543cb77":"code","19106115":"code","c49fd3d5":"code","0ed82449":"code","b0f6c099":"code","d95ce84e":"code","f93a9bd7":"code","515d6f62":"code","e191f83b":"markdown","0893c0eb":"markdown","cded3ff1":"markdown","fc786275":"markdown","b393dbc6":"markdown","e4234345":"markdown","8d07cb5f":"markdown","4dde424f":"markdown","63b614dc":"markdown","57692f39":"markdown","ec030f7b":"markdown","9370cd91":"markdown","365b76cb":"markdown","bbb40d09":"markdown","9f2a325f":"markdown","69af1998":"markdown"},"source":{"3d1e0183":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncol_names=['BI_RADS', 'age', 'shape', 'margin', 'density','severity']\nfile=pd.read_csv(\"..\/input\/mammographic_masses.data.txt\")\nfile.head(5)","01035e2d":"file=pd.read_csv(\"..\/input\/mammographic_masses.data.txt\", na_values='?', names=col_names, usecols=range(1,6))\nfile.describe(include=(\"all\"))","b2cc1360":"print(\"Number of NULL values per feature:\")\nfile.isnull().sum()","597d1588":"file.dropna(inplace=True)\nfile.shape\nfile. describe(include=(\"all\"))","346d7327":"fig, axes = plt.subplots(1,4, sharey=False, figsize=(18,4))\nax1, ax2, ax3, ax4 = axes.flatten()\n\nax1.hist(file['age'], bins=10, color=\"lightslategray\")\nax2.hist(file['shape'], bins=4, color=\"steelblue\")\nax3.hist(file['margin'], bins=5, color=\"mediumslateblue\")\nax4.hist(file['density'], bins=4, color=\"darkslategray\")\nax1.set_xlabel('AGE', fontsize=\"large\")\nax2.set_xlabel('SHAPE', fontsize=\"large\")\nax3.set_xlabel('MARGIN', fontsize=\"large\")\nax4.set_xlabel('DENSITY', fontsize=\"large\")\nax1.set_ylabel(\"AMOUNT\", fontsize=\"large\")\n\nplt.suptitle('COMPARISON of DISTRIBUTIONS', ha='center', fontsize='x-large')\nplt.show()","dbf9a954":"feature_names=['age', 'shape', 'margin', 'density']\nfeatures=file[['age', 'shape', 'margin', 'density']].values\nclasses=file['severity'].values","22ec5dbe":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nfeatures_scaled=scaler.fit_transform(features)\nprint(\"Scaled features:\")\nfeatures_scaled","40218b10":"from sklearn.model_selection import train_test_split\ntrain_f, test_f, train_c, test_c=train_test_split(features_scaled, classes, test_size=0.2, random_state=0)","bdab43d1":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ndicti={SVC(kernel=\"rbf\", C=1, gamma=1000, probability=True):\"svc\",\n    LogisticRegression(solver=\"liblinear\", random_state=0):\"lr\",\n    KNeighborsClassifier(n_neighbors=10):'knn',\n    RandomForestClassifier(max_depth=3, n_estimators=100, random_state=0):'rfc',\n    DecisionTreeClassifier(random_state=0):'dtc'}\nfor model in dicti:\n    model.fit(train_f, train_c)\n    pred_c=model.predict(test_f)\n    accc=accuracy_score(test_c, pred_c)\n    print(\"Accuracy score for \", dicti[model], \" is \", accc.round(2))","307a110a":"from sklearn.model_selection import cross_val_score\nfor model in dicti:\n    score=cross_val_score(model,features_scaled,classes, cv=10)\n    print(\"Accuracy score for \", dicti[model], \"with cros. val. is \",'{:3.2f}'.format(score.mean()))","0f7c9f5c":"from sklearn.neighbors import KNeighborsClassifier\nfor n in range(1,11):\n    model=KNeighborsClassifier(n_neighbors=n)\n    model.fit(train_f, train_c)\n    pred_c=model.predict(test_f)\n    acc=accuracy_score(test_c, pred_c)\n    print(n,\"neighbor(s):\")\n    print(\"Accuracy score for KNN is :\", acc.round(2))\n    score=cross_val_score(model,train_f,train_c, cv=10)\n    print(\"Accuracy score for KNN with cros. val. is \",'{:3.2f}'.format(score.mean()),\"\\n\")","2543cb77":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nMNB=MultinomialNB()\nfeatures_minmax=scaler.fit_transform(features)\ncv_scores=cross_val_score(MNB,features_minmax, classes, cv=10)\nprint(\"Accuracy score for Multinomial Naive Bayes with cross. val. is \",'{:3.2f}'.format(score.mean()))","19106115":"from sklearn.metrics import roc_curve, auc\ndicti={SVC(kernel=\"rbf\", C=1, gamma=1000, probability=True):\"svc\",\n    LogisticRegression(solver=\"liblinear\", random_state=0):\"lr\",\n    KNeighborsClassifier(n_neighbors=10):'knc',\n    RandomForestClassifier(max_depth=3, n_estimators=100):'rfc',\n    DecisionTreeClassifier():'dtc'}\nfor model in dicti:\n    model.fit(train_f,train_c)\n    prob=model.predict_proba(test_f)\n    fpr, tpr, thresholds=roc_curve(test_c, prob[:,1])\n    roc_auc=auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=3, label=dicti[model]+' AUC = %0.2f' % roc_auc)\n    plt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('Receiver Operating Characteristic', fontsize=15)\n\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.rcParams[\"figure.figsize\"] = (10,5)\nplt.show()","c49fd3d5":"from sklearn.decomposition import PCA\npca=PCA()\ntrain_f_pca=pca.fit_transform(train_f)\ntest_f_pca=pca.transform(test_f)\n\ndf = pd.DataFrame({'Variance Explained':pca.explained_variance_ratio_,\n             'Principal Components':['PC1','PC2', 'PC3', 'PC4']})\nsns.barplot(x='Principal Components',y=\"Variance Explained\", data=df, color=\"b\")\nplt.title(\"Variance Explained by Principal Components\\n\", fontsize=20, color=\"b\")\nplt.show()","0ed82449":"print(\"Explained variance per component:\")\npca.explained_variance_ratio_.tolist()","b0f6c099":"from matplotlib.colors import ListedColormap\npca2 = PCA(2)  # project from 4 to 2 dimensions\ntrain_f_pca2=pca2.fit_transform(train_f)\ntest_f_pca2=pca2.transform(test_f)\nplt.scatter(train_f_pca2[:, 0], train_f_pca2[:, 1], c=train_c, edgecolor='k',s=50, alpha=0.7, cmap=ListedColormap(('g','r')))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.title(\"Visualization of Train Data\\n with two components\\n\", color=\"r\", fontsize=15)\nplt.colorbar(label='benign'+\" \"*15+'malignant')\nplt.show()","d95ce84e":"plt.scatter(test_f_pca2[:, 0], test_f_pca2[:, 1], c=test_c, edgecolor='black',s=50, alpha=0.7, cmap=ListedColormap(('g','r')))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.title('Visualization of Test Data\\n with two components')\nplt.colorbar(label='beign'+\" \"*15+'malign')\nplt.title(\"Visualization of Test Data\\n with two components\\n\", color=\"r\", fontsize=15)\nplt.show()","f93a9bd7":"from sklearn.model_selection import train_test_split\ntrain_f, test_f, train_c, test_c=train_test_split(features_scaled, classes, test_size=0.2, random_state=0)\n\nclassifier =LogisticRegression(solver=\"liblinear\", random_state=0)\nclassifier.fit(train_f_pca2, train_c)\npred_c = classifier.predict(test_f_pca2)\nplt.subplot(2,1,1)\n\n#Train set boundary\nX_set, y_set = train_f_pca2, train_c\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\\\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('green', 'red')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],s=10,\n                c = ListedColormap(('green', 'red'))(i), label = j)\nplt.title('Logistic Rgression\\nBoundary Line with PCA (Train Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.legend()\n       \nplt.subplot(2,1,2)\n#Test set boundary\nX_set, y_set = test_f_pca2, test_c\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\\\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('green', 'red')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],s=10, c = ListedColormap(('green', 'red'))(i), label = j)\nplt.title('Boundary Line with PCA (Test Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.legend()\nplt.tight_layout()\nplt.show()","515d6f62":"from sklearn.model_selection import train_test_split\ntrain_f, test_f, train_c, test_c=train_test_split(features_scaled, classes, test_size=0.2, random_state=0)\n\nclassifier = RandomForestClassifier(max_depth=3, n_estimators=100)\nclassifier.fit(train_f_pca2, train_c)\npred_c = classifier.predict(test_f_pca2)\n   \nplt.subplot(2,1,1)\n#Train set boundary\nX_set, y_set = train_f_pca2, train_c\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\\\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('green', 'red')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],s=10,\n                c = ListedColormap(('green', 'red'))(i), label = j)\nplt.title('Randon Forest Classifier\\nBoundary Line with PCA (Train Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.legend()\n       \nplt.subplot(2,1,2)\n#Test set boundary\nX_set, y_set = test_f_pca2, test_c\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\\\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('green', 'red')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],s=10, c = ListedColormap(('green', 'red'))(i), label = j)\nplt.title('Boundary Line with PCA (Test Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.legend()\nplt.tight_layout()\nplt.show()   ","e191f83b":"The top 5 rows of our data show that we need to add column names as well as to deal with \"?\". After doing this, it's the time to go over main statistics of the data.","0893c0eb":"A curve pulled close to the upper left corner indicates a better performing test. And one can notice that we have higest performance for Logistic Regression again.","cded3ff1":"We have different scales for the features. As some of the algorithms require a prior normalization of input data, let's normalize our data.","fc786275":"Seems there are no outliers. Let's see how each of the features is distributed.","b393dbc6":"The last model to check is Naive Bayes. For this model let's apply MinMaxScaler to have all the features' values between 0 and 1. The result of this shows that Naive Bayes does not perform better than Logistic regression.","e4234345":" I also suggest to visualize classifiers' boundaries for two best performing algorithms. Below we have it for Train and Test data separately.","8d07cb5f":"The purpose of this project is to predict whether a mammogram mass is benign or malignant.\nAfter preparing data, several algorithms will be applied for classification purposes, and their parformance accuracies will follow.\nIn addition, I will show the appliaction of PCA to visualize our data, as well as ROC-AUC will be presented for a list of algorithms.\n\nWe'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Mammographic+Mass)\nThis data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n\n1. BI-RADS assessment: 1 to 5 (ordinal)\n2. Age: patient's age in years (integer)\n3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n6. Severity: benign=0 or malignant=1 (binominal)\n\nBI-RADS is an assesment of how confident the severity classification is. As this is not a \"predictive\" attribute we will discard it.\nThe age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\nNote that \"shape\" and \"margin\" are nominal data types. Since they are close enough to ordinal we will not discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n\nWe will use the following algorithms, and assess their performance on test data with and without K-Fold validation:\n1. Decision tree\n2. Random forest\n3. KNN\n4. Naive Bayes\n5. SVM\n6. Logistic Regression\n","4dde424f":"The result is not bad with just two components.\n>As always, your comments are appreciated.\n\n>I hope you found this kernel useful and informative. If so, please **<font size=\"4\">upvote  :)<\/font>**  ","63b614dc":"Here is the top 5 rows of our data.","57692f39":"**<font size=\"4\">PCA (Principal Component Analysis)<\/font>**\n\nAs we have 4 features, we can not visualize our data in 2D. Let's use PCA to reduce dimensionality.","ec030f7b":"After applying cross validation, Logistic Regression succeeds more.\nNow let's try K-Nearest-Neighbors and see if the values of K plays a significant role in the accuracy of prediction.","9370cd91":"Here the winner was Logistic regression. However, the results may change after applying K-Fold cross validation, because, the latter  generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train\/test split. The mean of these K scores is consider as the ultimate accuracy score for the model.","365b76cb":"As more than 3\/4 of the data variance is explained with two components, let's consider those components in order to visualize data sets in 2D.\n\nThe following two plots show the distribution of Training and Test data.","bbb40d09":"**<font size=\"4\">ROC and AUC for different models<\/font>**\n    \nROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: \n1. True Positive Rate \n2. False Positive Rate \n\nTrue Positive Rate = True Positive \/ (True Positive + False Negative)\nFalse Positive Rate = False Positive \/ (False Positive + True Negative)\n\nAUC measures the entire two-dimensional area underneath the entire ROC curve from (0,0) to (1,1). One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example. So, the higher the area under the curve the better the model is.","9f2a325f":"Let's see if there are null values and drop them.","69af1998":"In order to train and test our data, let's split it into two parts: 80%-20%.\nThen we'll apply the above mentioned models to see which of them performs better with selected parameters."}}