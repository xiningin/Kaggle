{"cell_type":{"06d85d07":"code","8dcd74c2":"code","519bffef":"code","60ce8034":"code","817bebde":"code","6eed85a3":"code","cab95689":"code","212fa1e9":"code","ad20a87a":"code","1ee38ac5":"code","4bb199da":"code","8bfca6c8":"code","335fc20d":"code","31dd56a9":"code","cddbdb48":"code","803b86c2":"code","933ff2bd":"code","a086f83a":"code","4da4f493":"code","20d41f71":"code","15f90b90":"code","27762578":"markdown","321c86e8":"markdown","47681ca9":"markdown","ddc41d49":"markdown","b32d12fd":"markdown","79dba615":"markdown","0e64432c":"markdown","1cba4b2c":"markdown","ba29df21":"markdown","a2ec9c3a":"markdown","ed3b827a":"markdown"},"source":{"06d85d07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8dcd74c2":"# change default plot config\nplt.rc('figure', figsize=(14.4, 8.1), dpi=72)\nplt.rc('font', size=13)","519bffef":"train_df = pd.read_csv(\"..\/input\/train.csv\", parse_dates=['created_date'])","60ce8034":"train_df.info()\ndisplay(train_df.head())\ndisplay(train_df.describe())","817bebde":"# Subgroups\ntoxicity_subtypes = [\n    'severe_toxicity', 'obscene', 'identity_attack',\n    'insult', 'threat', 'sexual_explicit'\n]\n\nidentities = [\n    'asian', 'atheist', 'bisexual',\n    'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n    'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n    'jewish', 'latino', 'male', 'muslim', 'other_disability',\n    'other_gender', 'other_race_or_ethnicity', 'other_religion',\n    'other_sexual_orientation', 'physical_disability',\n    'psychiatric_or_mental_illness', 'transgender', 'white'\n]\n\nmetadata = [\n    'created_date', 'publication_id', 'parent_id', 'article_id',\n    'rating', 'funny', 'wow', 'sad', 'likes', 'disagree'\n]\n\nannotation = ['identity_annotator_count', 'toxicity_annotator_count']","6eed85a3":"# Feture Engineering for visualization\ntrain_df['rating'] = train_df['rating'].map({\"approved\": 1, \"rejected\": 0})\ntrain_df[\"is_toxic\"] = np.where(train_df[\"target\"].values >= 0.5, 1, 0).astype(\"int32\")","cab95689":"for col in train_df.columns:\n    if col in [\"rating\", \"is_toxic\"]:\n        sns.countplot(train_df[col])\n    elif train_df[col].dtype.name in [\"float64\", \"int64\"] and col not in [\"id\", \"comment_text\", \"article_id\", \"parent_id\", \"publication_id\"]:\n        sns.distplot(train_df.loc[train_df[col].notna() & train_df[\"is_toxic\"].eq(0), col], label=\"is_toxic=0\")\n        sns.distplot(train_df.loc[train_df[col].notna() & train_df[\"is_toxic\"].eq(1), col], label=\"is_toxic=1\")\n        plt.legend()\n    else:\n        continue\n    plt.title(f\"Distribution of `{col}` in train\")\n    plt.show()","212fa1e9":"import unicodedata\nimport sys\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n\npuncts_trans = {i: ' ' for i in range(sys.maxunicode)\n                if unicodedata.category(chr(i)).startswith('P')}\n\ndel puncts_trans[ord(\"'\")]\n\npuncts = [chr(i) for i in puncts_trans.keys()]\n# print(\"Puncts:\", puncts)\n\nstop_words = stopwords.words('english')\nother_frequent_words = [\"people\", \"don\", \"doesn\", \"didn\", \"can\",\n                        \"could\", \"like\", \"would\", \"one\", \"get\",\n                        't', 's', 'i', 'you']\n\n\ndef freqs_plot_incond(df, cond=''):\n    new_comment_text = df[\"comment_text\"].str.translate(puncts_trans).str.lower()\n    tokenized = ' '.join(new_comment_text.values.tolist()).split()\n    tokenized = [word for word in tokenized if word not in stop_words + other_frequent_words]\n    s = pd.Series(tokenized)\n    del tokenized\n    gc.collect()\n    freq = s.value_counts().to_dict()\n    del s\n    gc.collect()\n    if len(freq) == 0:\n        print(f\"The {cond} has no words\")\n        return\n    wc = WordCloud(width=800, height=450)\n    pic_mat = wc.fit_words(freq).to_array()\n    plt.imshow(pic_mat)\n    plt.title(f\"Frequent words in condition of {cond}\")\n    plt.show()\n    del pic_mat, wc\n    gc.collect()","ad20a87a":"for col in identities:\n    freqs_plot_incond(train_df.loc[train_df[col].gt(0.2)], f\"mentioned identity `{col}` > 0.2\")","1ee38ac5":"for col in toxicity_subtypes:\n    freqs_plot_incond(train_df.loc[train_df[col].gt(0.2)], f\"subtype `{col}` > 0.2\")","4bb199da":"del train_df\ngc.collect()","8bfca6c8":"train_df = pd.read_csv(\"..\/input\/train.csv\", usecols=identities+toxicity_subtypes+[\"id\", \"target\", \"comment_text\"])\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\ntrain_df.info()\ntest_df.info()","335fc20d":"train_df[\"is_toxic\"] = np.where(train_df[\"target\"].values >= 0.5, 1, 0).astype(\"int32\")","31dd56a9":"%%time\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nSIZEOF_VOCAB = 49999  # size of vocabulary\nINPUT_LENGTH = 192  # max length for each sequence\n\n# fit on text in all the datasets\n# text_to_fit = pd.concat([train_df[\"comment_text\"], test_df[\"comment_text\"]])\n\n# fit on text in condition of:\ntext_to_fit = train_df.loc[((train_df[\"target\"]>0.3)\n                             &(train_df[toxicity_subtypes].gt(0.2).any(axis=1)))\n                           |((train_df[\"target\"]>0.3)\n                             &(train_df[identities].gt(0.2).any(axis=1))), \"comment_text\"]\n\ntokenizer = Tokenizer(num_words=SIZEOF_VOCAB,\n                      filters=''.join(puncts) + '\\n\\t\\r',\n                     )\ntokenizer.fit_on_texts(text_to_fit)\nprint(len(tokenizer.word_index))\n\nword_counts = pd.Series(dict(tokenizer.word_counts.items())).sort_values(ascending=False)\nfig, ax = plt.subplots(figsize=(14.4, 10.8))\nsns.barplot(x=word_counts[:50], y=word_counts[:50].index, ax=ax)\nax.set_title(\"Top frequent words in tokenizer\")\nplt.show()\n\ntrain_text_seq = tokenizer.texts_to_sequences(train_df[\"comment_text\"])\ntest_text_seq = tokenizer.texts_to_sequences(test_df[\"comment_text\"])\n\n# Find out the lengths of words in each sequence\nfor seq, title in zip([train_text_seq, test_text_seq], [\"Train\", \"Test\"]):\n    s = pd.Series([len(x) for x in seq])\n    sns.boxplot(s)\n    plt.title(f\"Distribution of number of words in each comment in {title}\")\n    plt.show()\n\ntrain_features = pad_sequences(train_text_seq, maxlen=INPUT_LENGTH).astype(\"int32\")\ntest_features = pad_sequences(test_text_seq, maxlen=INPUT_LENGTH).astype(\"int32\")\n\ntrn_istoxic = train_df[\"is_toxic\"].values\ntrn_aux_target = train_df[\"target\"].values\ntrn_subtypes = train_df[toxicity_subtypes].values\n\ngc.collect()","cddbdb48":"from tensorflow.keras import Model\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.regularizers import l1_l2\n\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\n\nEMBEDDING_SIZE = 512\nBATCH_SIZE = 512\nRECURRENT_UNITS = 128\nLR = 0.005\nreg_l1 = 0.3\nreg_l2 = 0.5\n\n\ndef model_fn():\n    \n    inp = L.Input(shape=(INPUT_LENGTH,))\n    emb = L.Embedding(input_dim=SIZEOF_VOCAB+1, output_dim=EMBEDDING_SIZE,\n                      input_length=INPUT_LENGTH,\n                      trainable=True)(inp)\n    \n    drop_0 = L.SpatialDropout1D(rate=0.15)(emb)\n    bi_lstm_0 = L.Bidirectional(L.CuDNNLSTM(RECURRENT_UNITS,\n                                            recurrent_regularizer=l1_l2(l1=reg_l1, l2=reg_l2),\n                                            return_sequences=True))(drop_0)\n    bi_lstm_1 = L.Bidirectional(L.CuDNNLSTM(RECURRENT_UNITS,\n                                            recurrent_regularizer=l1_l2(l1=reg_l1, l2=reg_l2),\n                                            return_sequences=False))(bi_lstm_0)\n\n    out_main = L.Dense(1, activation='sigmoid', name=\"main_proba\")(bi_lstm_1)\n    out_aux = L.Dense(1, activation='sigmoid', name=\"aux_proba\")(bi_lstm_1)\n    out_subtypes_probas = L.Dense(6, activation='sigmoid', name=\"subtypes_proba\")(bi_lstm_1)\n    \n    model = Model(inputs=inp, outputs=[out_main, out_aux, out_subtypes_probas])\n    model.compile(Adam(lr=LR), loss=binary_crossentropy, metrics=['acc'])\n\n    return model","803b86c2":"%%time\n\nmodel = model_fn()\nmodel.summary()\n\nhist = model.fit(\n    train_features,\n    [trn_istoxic, trn_aux_target, trn_subtypes],\n    batch_size=BATCH_SIZE,\n    epochs=3,\n    callbacks=[\n     LearningRateScheduler(lambda epoch: max([LR-0.3*LR*epoch, 0.001]), verbose=1),\n    ],\n    validation_split=0.1, shuffle=True,\n)\n\ntrn_pred, trn_aux, _ = model.predict(train_features)\n\ntest_pred, test_aux, sub_pred = model.predict(test_features)","933ff2bd":"gc.collect()\n\n# AUC\nprint(\"Train's istoxic,main AUC: {}\".format(roc_auc_score(trn_istoxic, trn_pred)))\nprint(\"Train's istoxic,aux AUC: {}\".format(roc_auc_score(trn_istoxic, trn_aux)))\n\n# Plot Confusion Matrices\nmain_cm = confusion_matrix(trn_istoxic, np.where(trn_pred>=0.5, 1, 0))\nsns.heatmap(main_cm, annot=True)\nplt.xlabel(\"Actual classes\")\nplt.ylabel(\"Predicted classes\")\nplt.title(\"Confusion Matrix in Train\")\nplt.show()","a086f83a":"submission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"prediction\": test_pred.flatten(),\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","4da4f493":"subtypes = pd.DataFrame(data=sub_pred, columns=toxicity_subtypes)\nsubmission[toxicity_subtypes] = subtypes[toxicity_subtypes]\nsubmission[\"target\"] = test_aux.flatten()\nsubmission[\"comment_text\"] = test_df[\"comment_text\"]","20d41f71":"# Find out the distribution of subtypes\nfor col in toxicity_subtypes+[\"target\"]:\n    sns.distplot(submission[col])\n    plt.title(f\"Distribution of `{col}` in test\")\n    plt.show()","15f90b90":"for col in toxicity_subtypes+[\"target\"]:\n    freqs_plot_incond(submission.loc[submission[col].gt(0.2)], f\"`{col}` > 0.2\")","27762578":"### Frequent words in identities mentioned","321c86e8":"## Submission","47681ca9":"## Build and train models","ddc41d49":"## Distributions","b32d12fd":"*Disclaimer: The Visualizations and dataframes in this kernel may be considered profane, vulgar, or offensive.*","79dba615":"### Frequent words in toxicity subtypes","0e64432c":"## Prepare datasets for training","1cba4b2c":"## Next step:\n\n* Explore on extra datasets containing preset embedding weights.","ba29df21":"## Explore frequent words","a2ec9c3a":"## Exploration on predicted testset","ed3b827a":"## Validation on trainset"}}