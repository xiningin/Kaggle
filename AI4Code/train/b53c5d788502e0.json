{"cell_type":{"033c534f":"code","aae1075d":"code","f0e999fc":"code","89d7417e":"code","7da80dcb":"code","16055fea":"code","f28b849d":"code","a2df916c":"code","4c713d90":"code","f11159d8":"code","0637fe7e":"code","0636fd7c":"code","bbb33fed":"code","9360cdfe":"code","9dc1260a":"code","dfb0e7d4":"code","9f003999":"code","73b39d29":"code","b60c4dde":"code","52235ec5":"code","4092b20c":"code","8e8b4933":"code","3d31f366":"code","065cd684":"code","4446b99c":"code","39fe7a1c":"code","aa6b5010":"code","e45434b0":"code","813a1cbc":"code","59ecef66":"code","311a4406":"code","1ba8c43b":"code","79486ff0":"code","19670f9b":"code","481f1b97":"code","52909f9c":"code","6afcab15":"code","1e61a125":"markdown","a78c1de0":"markdown","aee3bf5b":"markdown","ab0078be":"markdown","5b0b859c":"markdown","b927a0ed":"markdown","d1be7cf2":"markdown","26977916":"markdown","8691fa8a":"markdown","7b3642bb":"markdown","d130440b":"markdown","43d85168":"markdown","f2127627":"markdown","c843ce62":"markdown","2881fb47":"markdown","14b50464":"markdown","bc75c220":"markdown","da7d3a90":"markdown","dc5a7620":"markdown","ecc54b28":"markdown","f0d49d54":"markdown","ae8f0fa8":"markdown","759c8f47":"markdown","d04605cc":"markdown","6a2085a5":"markdown","0e7c04b4":"markdown","d3fd2789":"markdown","ed94e946":"markdown","bafaacc9":"markdown","700e18f5":"markdown"},"source":{"033c534f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import DBSCAN \nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# setting the style of the notebook to be monokai theme  \n# this line of code is important to ensure that we are able to see the x and y axes clearly\n# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them. \n","aae1075d":"# You have to include the full link to the csv file containing your dataset\ncreditcard_df = pd.read_csv('\/kaggle\/input\/ccdata\/CC GENERAL.csv')","f0e999fc":"creditcard_df.head()","89d7417e":"# Let's apply info and get additional insights on our dataframe\ncreditcard_df.info()\n# 18 features with 8950 points  ","7da80dcb":"creditcard_df.describe()\n# Let's apply describe() and get more statistical insights on our dataframe\n","16055fea":"# Let's see if we have any missing data, luckily we don't have many!\nsns.heatmap(creditcard_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n","f28b849d":"creditcard_df.isnull().sum()","a2df916c":"# Let's see if we have duplicated entries in the data\ncreditcard_df.duplicated().sum()","4c713d90":"creditcard_df.drop('CUST_ID',axis=1,inplace=True)","f11159d8":"\nplt.figure(figsize=(10,50))\nfor i in range(len(creditcard_df.columns)):\n    plt.subplot(17, 1, i+1)\n    sns.distplot(creditcard_df[creditcard_df.columns[i]], kde_kws={\"color\": \"b\", \"lw\": 3, \"label\": \"KDE\",\"bw\":0.1}, hist_kws={\"color\": \"g\"})\n    plt.title(creditcard_df.columns[i])\n\nplt.tight_layout()","0637fe7e":"corr = creditcard_df.corr()\nf,ax=plt.subplots(figsize=(20,20))\nsns.heatmap(corr,annot=True)","0636fd7c":"# Fill up the missing elements with mean of the 'MINIMUM_PAYMENT' \ncreditcard_df.loc[(creditcard_df['MINIMUM_PAYMENTS'].isnull() == True), 'MINIMUM_PAYMENTS'] = creditcard_df['MINIMUM_PAYMENTS'].mean()\n","bbb33fed":"creditcard_df.loc[(creditcard_df['CREDIT_LIMIT'].isnull()==True),'CREDIT_LIMIT'] = creditcard_df['CREDIT_LIMIT'].mean()","9360cdfe":"creditcard_df.isnull().sum()","9dc1260a":"scaler = StandardScaler()\ncreditcard_df_scaled = scaler.fit_transform(creditcard_df)","dfb0e7d4":"creditcard_df_scaled.shape","9f003999":"creditcard_df_scaled","73b39d29":"inertia = []\nsil=[]\nlist_num_clusters = list(range(2,11))\nfor num_clusters in list_num_clusters:\n    km = KMeans(n_clusters=num_clusters)\n    km.fit(creditcard_df_scaled)\n    inertia.append(km.inertia_)\n    sil.append(silhouette_score(creditcard_df_scaled,km.labels_))\n    \nplt.plot(list_num_clusters,inertia)\nplt.scatter(list_num_clusters,inertia)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')","b60c4dde":"plt.plot(list_num_clusters,sil)\nplt.scatter(list_num_clusters,sil)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Silhouette Coefficient')","52235ec5":"kmeans = KMeans(7)\nkmeans.fit(creditcard_df_scaled)\nlabels = kmeans.labels_","4092b20c":"kmeans.cluster_centers_.shape","8e8b4933":"cluster_centers = pd.DataFrame(data = kmeans.cluster_centers_, columns = [creditcard_df.columns])\ncluster_centers","3d31f366":"# In order to understand what these numbers mean, let's perform inverse transformation\ncluster_centers = scaler.inverse_transform(cluster_centers)\ncluster_centers = pd.DataFrame(data = cluster_centers, columns = [creditcard_df.columns])\ncluster_centers\n\n\n","065cd684":"labels.shape # Labels associated to each data point","4446b99c":"labels.max()","39fe7a1c":"labels.min()","aa6b5010":"y_kmeans = kmeans.fit_predict(creditcard_df_scaled)\ny_kmeans\n","e45434b0":"# concatenate the clusters labels to our original dataframe\ncreditcard_df_cluster = pd.concat([creditcard_df, pd.DataFrame({'cluster':labels})], axis = 1)\ncreditcard_df_cluster.head()","813a1cbc":"# Plot the histogram of various clusters\nfor i in creditcard_df.columns:\n  plt.figure(figsize = (35, 5))\n  for j in range(7):\n    plt.subplot(1,7,j+1)\n    cluster = creditcard_df_cluster[creditcard_df_cluster['cluster'] == j]\n    cluster[i].hist(bins = 20)\n    plt.title('{}    \\nCluster {} '.format(i,j))\n  \n  plt.show()\n\n","59ecef66":"# Obtain the principal components \npca=PCA(n_components=2)\nprincipal_comp=pca.fit_transform(creditcard_df_scaled)","311a4406":"# Create a dataframe with the two components\npca_df = pd.DataFrame(data = principal_comp, columns =['pca1','pca2'])\npca_df.head()","1ba8c43b":"# Concatenate the clusters labels to the dataframe\npca_df = pd.concat([pca_df,pd.DataFrame({'cluster':labels})], axis = 1)\npca_df.head()","79486ff0":"plt.figure(figsize=(10,10))\nax = sns.scatterplot(x=\"pca1\", y=\"pca2\", hue = \"cluster\", data = pca_df, palette =['red','green','blue','purple','yellow','orange','pink'])\nplt.show()","19670f9b":"list_num_clusters = list(range(2,11))\nlinkage=['complete','ward','single','average']\nmetrics=list()\nfor link in linkage:\n    for num_clusters in list_num_clusters:\n        ag = AgglomerativeClustering(n_clusters=num_clusters, linkage=link, compute_full_tree=True)\n        labels=ag.fit_predict(creditcard_df_scaled)\n        metrics.append(pd.Series({'n':num_clusters, \n                              'score':silhouette_score(creditcard_df_scaled,labels)}, \n                             name=link))\n\nmetrics = pd.concat(metrics, axis=1)","481f1b97":"metrics.T.reset_index()","52909f9c":"ag=AgglomerativeClustering(n_clusters=5, linkage='single')\nlabels=ag.fit_predict(creditcard_df_scaled)","6afcab15":"pca_df = pd.DataFrame(data = principal_comp, columns =['pca1','pca2'])\npca_df = pd.concat([pca_df,pd.DataFrame({'cluster':labels})], axis = 1)\nplt.figure(figsize=(10,10))\nax = sns.scatterplot(x=\"pca1\", y=\"pca2\", hue = \"cluster\", data = pca_df, palette =['red','green','blue','purple','yellow'])\nplt.show()\n","1e61a125":"Data Source: https:\/\/www.kaggle.com\/arjunbhasin2013\/ccdata","a78c1de0":"**Let's Try the Single Linkage Clusters as they are giving the best scores**","aee3bf5b":"1) First Customers cluster (Non-Users) - These are the type of customers who make the least use of their card in any purchase. They have the lowest purchase ratio in any category.\n\n2) Second Customers cluster (Transactors): Those are customers who pay least amount of intrerest charges and careful with their money, Cluster with lowest balance ($104) and cash advance ($303), Percentage of full payment = 23%\n\n3) Third Customer cluster (revolvers) who use credit card as a loan (most lucrative sector): highest balance ($5000) and cash advance (~$5000), low purchase frequency, high cash advance frequency (0.5), high cash advance transactions (16) and low percentage of full payment (3%)\n\n4) Fourth customer cluster (VIP\/Prime): high credit limit $16K and highest percentage of full payment, target for increase credit limit and increase spending habits\n\n5) Fifth customer cluster (low tenure): these are customers with low tenure (7 years), low balance.\n","ab0078be":"## Insights","5b0b859c":"# Summary of Dataset ","b927a0ed":"**From The above plot we can't get a clear indication of our elbow point , so we'll use the silhouette_score method to find the optimal number of clusters**","d1be7cf2":"# K Means ","26977916":"# Hierarchial Clustering","8691fa8a":"Try using a different clustering algorithm too like DBSCAN. Try removing the outliers of the data and then fitting the model.\nWe can also try to perform PCA before fitting the model . It might give a different and better result.","7b3642bb":"#  APPLY K-MEANS METHOD WITH K = 7","d130440b":"#  IMPORT LIBRARIES AND DATASETS","43d85168":"1) CUSTID: Identification of Credit Card holder\n\n2) BALANCE: Balance amount left in customer's account to make purchases\n\n3) BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n\n4) PURCHASES: Amount of purchases made from account\n\n5) ONEOFFPURCHASES: Maximum purchase amount done in one-go\n\n6) INSTALLMENTS_PURCHASES: Amount of purchase done in installment\n\n7) CASH_ADVANCE: Cash in advance given by the user\n\n8) PURCHASES_FREQUENCY: How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n\n9) ONEOFF_PURCHASES_FREQUENCY: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n\n10) PURCHASES_INSTALLMENTS_FREQUENCY: How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n11) CASH_ADVANCE_FREQUENCY: How frequently the cash in advance being paid\n\n12) CASH_ADVANCE_TRX: Number of Transactions made with \"Cash in Advance\"\n\n13) PURCHASES_TRX: Number of purchase transactions made\n\n14) CREDIT_LIMIT: Limit of Credit Card for user\n\n15) PAYMENTS: Amount of Payment done by user\n\n16) MINIMUM_PAYMENTS: Minimum amount of payments made by user  \n\n17) PRC_FULL_PAYMENT: Percent of full payment paid by user\n\n18) TENURE: Tenure of credit card service for user","f2127627":"# Feature engineering","c843ce62":"- Obtain the correlation matrix between features","2881fb47":"# APPLY PCA AND VISUALIZE THE RESULTS","14b50464":"#  UNDERSTAND THE PROBLEM STATEMENT AND BUSINESS CASE","bc75c220":"1) Mean of balance is $1500\n\n2) 'Balance_Frequency' for most customers is updated frequently ~1\n\n3) For 'PURCHASES_FREQUENCY', there are two distinct group of customers\n\n4) For 'ONEOFF_PURCHASES_FREQUENCY' and 'PURCHASES_INSTALLMENT_FREQUENCY' most users don't do one off puchases or installment purchases frequently      \n\n5) Very small number of customers pay their balance in full 'PRC_FULL_PAYMENT'~0\n\n6) Credit limit average is around $4500\n\n7)  Most customers are ~11 years tenure\n\n8) Most of the Data is **Skewed** and we will have to perform some kind of log transformation on the dataset.","da7d3a90":"\n- Drop Customer ID column 'CUST_ID' and make sure that the column has been removed from the dataframe","dc5a7620":"#  Exploratory Data Analysis","ecc54b28":"## Insights","f0d49d54":"## Insights","ae8f0fa8":"![image.png](attachment:image.png)","759c8f47":"# Inference","d04605cc":"### Looking at the Seven clusters created by Kmeans I can infer that -\n","6a2085a5":"**Although the ward linkages will provide clear segmentations of the data , we will overlook those segmentations because of lower silhouette scores as compared to KMeans clustering algorithm**","0e7c04b4":"**There are no clear clusters and this is not at all a good segmentation of the credit card data. Therefore, we will not use this clustering algorithm for this problem**","d3fd2789":"# Suggestions","ed94e946":"1) Mean balance is $1564 \n\n2) Balance frequency is frequently updated on average ~0.9\n\n3) Purchases average is $1000\n\n4) one off purchase average is ~$600\n\n5) Average purchases frequency is around 0.5\n\n6) average ONEOFF_PURCHASES_FREQUENCY, PURCHASES_INSTALLMENTS_FREQUENCY, and CASH_ADVANCE_FREQUENCY are generally low\n\n7) Average credit limit ~ 4500\n\n8) Percent of full payment is 15%\n\n9) Average tenure is 11 years\n\n- All the Features are on different scale , so **scaling** of this dataset is important before fitting the model.","bafaacc9":"**We can use 7 clusters with KMeans and get a decent Silhouette Coefficient of 0.21**","700e18f5":"1) Purchases is strongly correlated with oneoff and installments purchases.\n\n2) Purchase frequency and purchace installments frequency are highly correlated .\n\n3) Cash advance , cash advance frequency and cash advance trx are also highly correlated.\n\n- Since there are many highly correlated and hence **redundant** features , performing **PCA** would be reccomended."}}