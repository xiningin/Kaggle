{"cell_type":{"0c2c203b":"code","dff4ed05":"code","1da07764":"code","0c3848b5":"code","93ba1515":"code","08d82052":"code","a4a08198":"code","49b2141b":"code","8b052dbf":"code","589dc6fb":"code","bb128848":"code","99e6eac5":"code","3f044107":"code","600537eb":"code","3363a571":"code","fefb5bcd":"code","0392c41e":"code","90b33b9d":"code","1d2cd208":"code","d2a86863":"code","b62bfa81":"code","b6920b12":"code","bd766997":"code","5eb2097b":"code","ed698a54":"code","35d3b1c7":"code","24c4a97b":"code","cdcc2500":"code","186456a0":"code","a88cfc70":"code","b0a082e2":"code","1bdd069e":"code","c3f605f5":"code","61e0d545":"code","b9a6effb":"markdown","45309bdc":"markdown","d4109bfc":"markdown","6469a0d8":"markdown","7aa9ed62":"markdown","55ab4002":"markdown","fc7104be":"markdown","113b4e68":"markdown","a905effd":"markdown","c57fd351":"markdown","3a6198e3":"markdown","25aeeecc":"markdown","ae93552b":"markdown","98122796":"markdown","d78dc0f7":"markdown","a7d91e2a":"markdown","54d4756c":"markdown","58e4d655":"markdown","cd5e7b95":"markdown","1477ebca":"markdown"},"source":{"0c2c203b":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MyNet(nn.Module):\n\n    def __init__(self):\n        super(MyNet, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square, you can specify with a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension (i.e. start_dim = 1).\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","dff4ed05":"net = MyNet()\nprint(net)","1da07764":"params = list(net.parameters())\nprint(len(params))\n\nprint(params[0].size())  # conv1's .weight","0c3848b5":"for i in range(len(params)):\n    print(params[i].size())","93ba1515":"# Try a random 32x32 input\n\ninput = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out)","08d82052":"# Zero the gradient buffers of all parameters and backprops with random gradients.\n\nnet.zero_grad()\nbk = out.backward(torch.randn(1, 10))","a4a08198":"print(bk)","49b2141b":"output = net(input)\ntarget = torch.randn(10)  # a dummy target, for example\ntarget","8b052dbf":"target = target.view(1, -1)  # make it the same shape as output\ntarget","589dc6fb":"criterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss)","bb128848":"print(loss.grad_fn)  # MSELoss\nprint(loss.grad_fn.next_functions[0][0])  # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU","99e6eac5":"net.zero_grad()     # zeroes the gradient buffers of all parameters\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)","3f044107":"# We can implement this using simple Python code:\n\nlearning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)","600537eb":"import torch.optim as optim\n\n# create your optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# in your training loop:\noptimizer.zero_grad()            # zero the gradient buffers\noutput = net(input)\nloss = criterion(output, target) # criterion = nn.MSELoss()\nloss.backward()\noptimizer.step()                 # Does the update","3363a571":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","fefb5bcd":"transform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                               ])\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","0392c41e":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# Show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))","90b33b9d":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass MyNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch (i.e. start_dim = 1).\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","1d2cd208":"net = MyNet()\nnet","d2a86863":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","b62bfa81":"for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","b6920b12":"# Let\u2019s quickly save our trained model:\n\nPATH = '.\/cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","bd766997":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","5eb2097b":"# Let\u2019s load back in our saved model\n\nnet = MyNet()\nnet.load_state_dict(torch.load(PATH))","ed698a54":"# Let us see what the neural network thinks these examples above are\n\noutputs = net(images)\noutputs","35d3b1c7":"outputs.shape","24c4a97b":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","cdcc2500":"# Let us look at how the network performs on the whole dataset.\n\ncorrect = 0\ntotal = 0\n\n# Since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # Calculate outputs by running images through the network\n        outputs = net(images)\n        # The class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","186456a0":"# Prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# Again no gradients needed\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predictions = torch.max(outputs, 1)\n        # Collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n# Print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) \/ total_pred[classname]\n    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n                                                   accuracy))","a88cfc70":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","b0a082e2":"net.to(device)","1bdd069e":"# Remember that you will have to send the inputs and targets at every step to the GPU too:\n\ninputs, labels = data[0].to(device), data[1].to(device)","c3f605f5":"if device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0)\/1024**3,1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_reserved(0)\/1024**3,1), 'GB')    ","61e0d545":"torch.cuda.empty_cache()","b9a6effb":"## Define the Network\n\nLet's define the following network as below.\n\nWe have a `forward` function, and the `backward` function (where gradients are computed) is automatically defined for us using `autograd`. We can use any of the Tensor operations in the `forward` function.\n\nThe learnable parameters of a model are returned by `net.parameters()`.","45309bdc":"**Note:** `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n\nFor example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n\nIf you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension.","d4109bfc":"The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let\u2019s get the index of the highest energy:","6469a0d8":"Now, if you follow loss in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations that looks like this:\n\n> input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n>\n>         -> flatten -> linear -> relu -> linear -> relu -> linear\n>\n>         -> MSELoss\n>\n>         -> loss\n\nSo, when we call `loss.backward()`, the whole graph is differentiated w.r.t. the neural net parameters, and all Tensors in the graph that have `requires_grad=True` will have their `.grad` Tensor accumulated with the gradient.\n\nFor illustration, let us follow a few steps backward:","7aa9ed62":"## Backprop\n\nTo backpropagate the error all we have to do is to `loss.backward()`. You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n\nNow we shall call `loss.backward()`, and have a look at conv1\u2019s bias gradients before and after the backward.","55ab4002":"As we're using neural networks, we want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we have a small package: `torch.optim` that implements all these methods.\n\nObserve how gradient buffers had to be manually set to zero using `optimizer.zero_grad()`. This is because gradients are accumulated as explained in the Backprop section.","fc7104be":"## Update the weights\n\nThe simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n\n`weight = weight - learning_rate * gradient`","113b4e68":"### 3. Define a [Loss Function](https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions) and [Optimizer](https:\/\/pytorch.org\/docs\/stable\/optim.html)","a905effd":"### 4. Train the network\n\nWe simply have to loop over our data iterator, and feed the inputs to the network and optimize.","c57fd351":"**Neural networks** can be constructed using the [`torch.nn` package](https:\/\/pytorch.org\/docs\/stable\/nn.html#torch-nn).\n\n`nn` depends on `autograd` to define models and differentiate them. An `nn.Module` contains layers, and a method `forward(input)` that returns the `output`.\n\n**Convolutional Neural Network (convnet)** is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.\n\nA typical training procedure for a neural network is as follows:\n\n- Define the neural network that has some learnable parameters (or weights)\n- Iterate over a dataset of inputs\n- Process input through the network\n- Compute the loss (how far is the output from being correct)\n- Propagate gradients back into the network\u2019s parameters\n- Update the weights of the network, typically using a simple update rule: `weight = weight - learning_rate * gradient`","3a6198e3":"## Loss Function\n\nA loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n\nThere are several different [loss functions under the nn package](https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions) . A simple loss is: `nn.MSELoss` which computes the mean-squared error between the input and the target.","25aeeecc":"### 2. Define a Convolutional Neural Network","ae93552b":"# Example: Training an image classifier\n\nHere, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.","98122796":"See [here](https:\/\/pytorch.org\/docs\/stable\/notes\/serialization.html) for more details on saving PyTorch models.","d78dc0f7":"### 5. Test the network on the test data\n\nWe will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n","a7d91e2a":"## Training on GPU\n\nJust like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU.\n\nLet\u2019s first define our device as the first visible cuda device if we have CUDA available:","54d4756c":"### 1. Load and normalize CIFAR10\n\nThe output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n\n**Note:** `ToTensor()` converts a PIL image or NumPy `ndarray` into a `FloatTensor`, and scales the image\u2019s pixel intensity values in the range [0., 1.]","58e4d655":"# Learning PyTorch\n\nLearning PyTorch is a series of notebooks I created to learn PyTorch.\n\nSource: https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/neural_networks_tutorial.html","cd5e7b95":"That looks way better than chance, which is 10% accuracy (i.e. randomly picking a class out of 10 classes). Seems like the network learnt something.\n\nHmmm, what are the classes that performed well, and the classes that did not perform well:","1477ebca":"`nn.Parameter` is a kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a `Module`."}}