{"cell_type":{"381847cb":"code","1010bcaa":"code","f177bfe8":"code","54a92701":"code","1bcd4c9d":"code","0cda6eea":"code","bb4f9253":"code","defd3dd0":"code","ce588829":"code","320ce8b4":"code","fcfa6392":"code","8f68de33":"markdown","4d746e86":"markdown","c7ccab0e":"markdown","1ef8a8ae":"markdown","cd87f77e":"markdown"},"source":{"381847cb":"import sys\n!cp ..\/input\/rapids\/rapids.0.14.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","1010bcaa":"!git clone https:\/\/github.com\/aerdem4\/rapids-kaggle-utils.git\n%cd rapids-kaggle-utils\/","f177bfe8":"!pip install -U xgboost","54a92701":"from  datetime import datetime, timedelta\nimport gc\nimport numpy as np, pandas as pd\nimport lightgbm as lgb\n\nimport cudf\nimport cu_utils.transform as cutran","1bcd4c9d":"h = 28 \nmax_lags = 57\ntr_last = 1913\nfday = datetime(2016,4, 25) \nFIRST_DAY = 1000\nfday","0cda6eea":"%%time\n\ndef create_df(start_day):\n    prices = cudf.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\n            \n    cal = cudf.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\n    cal[\"date\"] = cal[\"date\"].astype(\"datetime64[ms]\")\n    \n    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    dt = cudf.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\", usecols = catcols + numcols)\n    \n    dt = cudf.melt(dt,\n                  id_vars = catcols,\n                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n                  var_name = \"d\",\n                  value_name = \"sales\")\n    \n    dt = dt.merge(cal, on= \"d\")\n    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"])\n    \n    return dt\n\n\ndf = create_df(FIRST_DAY)","bb4f9253":"%%time\n\ndef transform(data):\n    \n    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n    for feature in nan_features:\n        data[feature].fillna('unknown', inplace = True)\n    \n    data['id_encode'], _ = data[\"id\"].factorize()\n    \n    cat = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n    for feature in cat:\n        data[feature], _ = data[feature].factorize()\n    \n    return data\n        \n        \ndf = transform(df)","defd3dd0":"%%time\n\ndef create_fea(data):\n\n    for lag in [7, 28]:\n        out_col = \"lag_{}\".format(str(lag))\n        data[out_col] = data[[\"id\", \"sales\"]].groupby(\"id\", method='cudf').apply_grouped(cutran.get_cu_shift_transform(shift_by=lag),\n                                                                      incols={\"sales\": 'x'},\n                                                                      outcols=dict(y_out=np.float32),\n                                                                      tpb=32)[\"y_out\"]\n    \n        for window in [7, 28]:\n            out_col = \"rmean_{lag}_{window}\".format(lag=lag, window=window)\n            data[out_col] = data[[\"id\", \"lag_{}\".format(lag)]].groupby(\"id\", method='cudf').apply_grouped(cutran.get_cu_rolling_mean_transform(window),\n                                                                          incols={\"lag_{}\".format(lag): 'x'},\n                                                                          outcols=dict(y_out=np.float32),\n                                                                          tpb=32)[\"y_out\"]\n\n    # time features\n    data['date'] = data['date'].astype(\"datetime64[ms]\")\n    data['year'] = data['date'].dt.year\n    data['month'] = data['date'].dt.month\n    data['day'] = data['date'].dt.day\n    data['dayofweek'] = data['date'].dt.weekday\n    \n    \n    return data\n\n\n    \n\n# define list of features\nfeatures = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n            'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', \n            'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', \n            'year', 'month', 'day', 'dayofweek',\n            'lag_7', 'lag_28', 'rmean_7_7', 'rmean_7_28', 'rmean_28_7', 'rmean_28_28'\n           ]\n\n\ndf = create_fea(df)\ndf.tail()","ce588829":"!pip install lofo-importance","320ce8b4":"from lofo import LOFOImportance, Dataset, plot_importance\nfrom sklearn.model_selection import KFold\nimport xgboost\n\nsample_df = df.to_pandas().sample(frac=0.2, random_state=0)\nsample_df.sort_values(\"date\", inplace=True)\n\ncv = KFold(n_splits=7, shuffle=False, random_state=0)\n\ndataset = Dataset(df=sample_df, target=\"sales\", features=features)\n\n# define the validation scheme and scorer\nparams = {\"objective\": \"count:poisson\",\n          \"learning_rate\" : 0.075,\n          \"max_depth\": 8,\n          'n_estimators': 200,\n          'min_child_weight': 50,\n          \"tree_method\": 'gpu_hist', \"gpu_id\": 0}\nxgb_reg = xgboost.XGBRegressor(**params)\nlofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"neg_mean_squared_error\", model=xgb_reg)\n\n# get the mean and standard deviation of the importances in pandas format\nimportance_df = lofo_imp.get_importance()","fcfa6392":"plot_importance(importance_df, figsize=(12, 12))","8f68de33":"## Install LOFO and get the feature importances","4d746e86":"## Install RAPIDS for faster feature engineering on GPU\nhttps:\/\/www.kaggle.com\/cdeotte\/rapids","c7ccab0e":"## Get rapids-kaggle-utils","1ef8a8ae":"## Get the latest Xgboost with GPU support","cd87f77e":"## Get the current best public kernel features and parameters\nAdapted from https:\/\/www.kaggle.com\/kneroma\/m5-first-public-notebook-under-0-50\n\nSwitched from pandas to **cudf** for the speed boost."}}