{"cell_type":{"3c191cc3":"code","65728350":"code","48947ace":"code","8a1fc44e":"code","0d61aba6":"code","8f7261f0":"code","cb02a415":"code","39f8e67b":"code","ee9e6f83":"code","52bb06e8":"code","9c9a82cd":"code","41fe4399":"code","f7a73575":"code","2b599ddb":"code","e42c2c66":"code","bc35dfa3":"code","f3231f92":"code","97207c85":"code","c6bbdb61":"code","90d1b99a":"code","badfa671":"code","d351615f":"code","1ed00418":"code","7297b62e":"code","6747c9ab":"code","e1e24f3a":"code","a63026b4":"code","29c50fb6":"code","fde70571":"code","51b8b442":"code","432afc17":"code","7765d7ef":"code","079289a0":"code","676655f8":"code","788fb75d":"code","a1084784":"code","e75c1482":"code","17345c12":"code","f7dc4215":"markdown","24ae2f7f":"markdown","e80e3f8f":"markdown","8c1a2d7b":"markdown","8a4a1d02":"markdown","1cd629c7":"markdown","acbdd919":"markdown","dc9c8652":"markdown","13c250e3":"markdown","f133e0a4":"markdown","5cdd67ea":"markdown","ebf5b0ee":"markdown","3d43f6b6":"markdown","73b4ef7c":"markdown","901db6c9":"markdown","c687904c":"markdown","01c26ba4":"markdown","b390bb1c":"markdown","50393261":"markdown","486c5475":"markdown","44b119eb":"markdown","4b011655":"markdown","3d6af99b":"markdown","3ec81593":"markdown","5619c709":"markdown","b9e2cef4":"markdown","1d4a3cd3":"markdown","962bd5aa":"markdown","a7ec321a":"markdown"},"source":{"3c191cc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65728350":"import matplotlib.pyplot as plt","48947ace":"data = {'year': [2010, 2011, 2012,\n2010, 2011, 2012,\n2010, 2011, 2012],\n'team': ['FCBarcelona', 'FCBarcelona', 'FCBarcelona',\n'RMadrid', 'RMadrid', 'RMadrid',\n'ValenciaCF', 'ValenciaCF', 'ValenciaCF'],\n'wins': [30, 28, 32, 29, 32, 26, 21, 17, 19],\n'draws': [6, 7, 4, 5, 4, 7, 8, 10, 8],\n'losses': [2, 3, 2, 4, 2, 5, 9, 11, 11]\n}\n\nfootball = pd.DataFrame(data, columns = ['year', 'team', 'wins', 'draws', 'losses'])","8a1fc44e":"football","0d61aba6":"edu = pd.read_csv('\/kaggle\/input\/ense32020\/files\/ch02\/educ_figdp_1_Data.csv',\n                  na_values=':', usecols=['TIME', 'GEO', 'Value'])\nedu","8f7261f0":"edu.head()","cb02a415":"edu.head(10)","39f8e67b":"edu.tail()","ee9e6f83":"edu.tail(7)","52bb06e8":"edu[10:15]","9c9a82cd":"edu.describe()","41fe4399":"edu['Value']","f7a73575":"edu['GEO']","2b599ddb":"edu.iloc[90:94][['TIME','GEO']]","e42c2c66":"edu['Value'] > 6.5","bc35dfa3":"edu[edu['Value'] > 6.5]","f3231f92":"edu[edu['Value'] > 6.5].tail()","97207c85":"edu.max(axis = 0)","c6bbdb61":"s = edu[\"Value\"]\/100\ns.head()","90d1b99a":"s = edu[\"Value\"].apply(lambda d: d**2)\ns.head()","badfa671":"s = edu[\"Value\"].apply(np.sqrt)\ns.head()","d351615f":"s = edu[\"Value\"].apply(lambda d: -d)\ns.head()","1ed00418":"edu['ValueNorm'] = edu['Value']\/edu['Value'].max()\nedu.head()","7297b62e":"edu.drop('ValueNorm', axis = 1, inplace = True)\nedu.head()","6747c9ab":"edu = edu.append({\"TIME\": 2000, \"Value\": 5.00, \"GEO\": 'a'},\n                  ignore_index = True)\nedu.tail()","e1e24f3a":"edu.drop(max(edu.index), axis = 0, inplace = True)\nedu.tail()","a63026b4":"eduDrop = edu[~edu[\"Value\"].isnull()].copy()\neduDrop.head()","29c50fb6":"eduDrop = edu.dropna(how = 'any', subset = [\"Value\"])\neduDrop.head()","fde70571":"edu.sort_values(by = 'Value', ascending = False,\n                inplace = True)\nedu.head()","51b8b442":"edu.sort_index(axis = 0, ascending = True, inplace = True)\nedu.head()","432afc17":"eduFilled = edu.fillna(value = {\"Value\": 0})\neduFilled.head()","7765d7ef":"group = edu[[\"GEO\", \"Value\"]].groupby('GEO').mean()\ngroup","079289a0":"filtered_data = edu[edu[\"TIME\"] > 2005]\npivedu = pd.pivot_table(filtered_data, values = 'Value',\n                        index = ['GEO'], columns = ['TIME'])\npivedu.head()","676655f8":"pivedu.loc[['Spain','Portugal'], [2006,2011]]","788fb75d":"pivedu = pivedu.drop(['Euro area (13 countries)',\n                      'Euro area (15 countries)',\n                      'Euro area (17 countries)',\n                      'Euro area (18 countries)',\n                      'European Union (25 countries)',\n                      'European Union (27 countries)',\n                      'European Union (28 countries)'\n                      ], axis=0)\npivedu = pivedu.rename(\n    index={'Germany (until 1990 former territory of the FRG)': 'Germany'})\npivedu = pivedu.dropna()\npivedu.rank(ascending=False, method='first').head()","a1084784":"totalSum = pivedu.sum(axis = 1)\n\ntotalSum.rank(ascending = False, method = 'dense').sort_values().head()","e75c1482":"totalSum = pivedu.sum(axis = 1).sort_values(ascending = False)\ntotalSum.plot(kind = 'bar', style = 'b', alpha = 0.4,\n              title = \"Total Values for Country\")","17345c12":"my_colors = ['b', 'r', 'g', 'y', 'm', 'c']\nax = pivedu.plot(kind='barh', stacked=True, color=my_colors, figsize=(12, 6))\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.savefig('Value_Time_Country.png', dpi=300, bbox_inches='tight')","f7dc4215":"1- Which is the size of the edu DataFrame (rows x columns)?\n\n     383 rows and 3 columns","24ae2f7f":"lambda function name d\n","e80e3f8f":"Joanne Assaf Bou Saba ","8c1a2d7b":"fill the null values by zero","8a4a1d02":"Here we can visualize the missing values NaN, it indicated the null values contained in my data collection ","1cd629c7":" we have created a dataframe with country names as the index, while the columns will be the years starting from 2006 and the values will be the previous Value column","acbdd919":"Get the maximum value of each column and pivoting dataframe (pivoting rows and colums), in this case we don't  have dataframe as a result of the operation but instead it is of type object","dc9c8652":"If we want to return to the original order, we can sort by an index using the function sort_index and specifying axis=0:","13c250e3":"Now our new index is the country name ","f133e0a4":"the first five rows of data sorted in descending order","5cdd67ea":"2- What happens if we give a number as argument to the method head()?\n\n    the method head will return the first number of rows depending on the number given in the argument, in our case, the first 10 elements \n    \n","ebf5b0ee":"Removing any row that contains a null value using the function dropna()","3d43f6b6":"iloc is transforming my result to the type Dataframe, in case it is of another type in order to continue performing operations provided by pandas on our data ","73b4ef7c":"5- What does this index return? What does the first index represent? And the second one?\n\n    [i:j] represents the index of the row i included until the row j-1\n    \n    ","901db6c9":"we added a new row using append ","c687904c":"4 - Which measures does the result show? It seems that it shows some default values, can you guess which ones?\n\n    The result shows a quantitive description of the dataframe and a statistical view of the content of the data collection\n    \n    the count\/it will count the number of rows  in the column time  and the number of non null rows in the column value\n    the mean\/ the mean value of all the values contained in the columns \n    the minimun\n    the Lowest 25% value\n    the lowest 50% value\n    the lowest 75% value\n    The maximum\/ the maxium if all the values in the column Time ( which is 2011)","01c26ba4":"The function drop was used to delete the column name \"ValueNorm\". Since it is a column, we set axis=1. Inplace = true is to remove the old values, dy default it is set to false ( in order to provide a copy and keep the old values) ","b390bb1c":"Observe the rows between the index 10 and the index 15 (excluding 15) since the index starts from 0","50393261":"iloc is transforming the data into dataframe ","486c5475":"we deleted back the row we added previously ","44b119eb":"indexedu[edu[\u2019Value\u2019] ","4b011655":"group by country and get the average value for each. The result would be a DataFrame with countries as indexes and the mean values as the column:","3d6af99b":"6- An if we apply the edu[edu[\u2019Value\u2019] > 6.5]?\n\n     wet get the dataframe based on the boolean vector that returns true","3ec81593":"Adding a new column named ValueNorm","5619c709":"we have created a dataframe using the content of a csv file and we name the 3 columns, in our case TIMW, GEO, VALUE","b9e2cef4":"7- What do you observe regarding the parameter ascending=False?\n\n    if it is false, it doesn't sort the values from the lowest to the higher ","1d4a3cd3":"We are visualizing our data and determining the issues in it, in order to take decisions regarding ( missing content, garbage and unuseful content )","962bd5aa":"3- What does the method tail()return?\n\n     the last 5 rows\n     ","a7ec321a":"6- What does the operation edu[\u2019Value\u2019] > 6.5 produce? \n\n   \n  \n     returns a Series of type boolean (not a dataframe with indexed rows)  of all the rows of a specific column based on the condition specified\n    However, is we apply edu[edu['Value'] > 6.5] we obtain a dataframe where we can perform pandas operations and we can access the different indexed rows and project the columns "}}