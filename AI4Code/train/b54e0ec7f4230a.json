{"cell_type":{"1d2a2adf":"code","6b5a8e10":"code","a90741bd":"code","bcc45fde":"code","f3c218a7":"code","e919ecca":"code","0e2a6797":"code","683dc95c":"code","dceddf7a":"markdown","5f0eb2c9":"markdown","817856ae":"markdown","a28f0558":"markdown"},"source":{"1d2a2adf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b5a8e10":"# Read data\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","a90741bd":"# Preprocess data\nused_features_dtype = {\n#     'PassengerId' : 'int64',\n    'Survived': 'int64',\n    'Pclass': 'int64',\n    #'Name': 'object',\n    'Sex': 'object',\n    'Age': 'float64',\n    'SibSp': 'int64',\n    'Parch': 'int64',\n    #'Ticket': 'object\n    'Fare': 'float64',\n    #'Cabin': 'object',\n    'Embarked': 'object'\n    \n}\n\ncategorical_to_int = {'Sex' : {'male': 0, 'female': 1}, \n                     'Embarked': {'C': 0, 'Q': 1, 'S': 2}}\n\npp_train_data = train_data[used_features_dtype.keys()].replace(categorical_to_int)\npp_train_data = pp_train_data.fillna(0)\npp_train_data[\"Embarked\"] = pp_train_data[\"Embarked\"].astype('int64')\n\ny = pp_train_data[['Survived']]\nX = pp_train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]","bcc45fde":"# Split data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n","f3c218a7":"# Learning rate decay\ndef lr_decay(init_lr, current_iter):\n    lr = init_lr  * np.power(.99, current_iter)\n    return lr if lr > 1e-4 else 1e-4\n\n# Define Model\nimport lightgbm as lgb\nclf = lgb.LGBMClassifier(boosting_type='dart', learning_rate=1e-2, n_estimators=1000, objective='binary',random_state=2021)\nfit_params = {\n    'early_stopping_rounds': 30,\n    'eval_set': [(X_val, y_val)],\n    'eval_names': ['valid'],\n    'verbose': 5,\n    'categorical_feature': 'auto',\n#     'callbacks': [lr_decay]\n    \n}\n\n# Dataframe to lgb Dataset obj\ntrain_data_obj = lgb.Dataset(X_train, y_train, categorical_feature=list(categorical_to_int.keys()))\nvalid_data_obj = lgb.Dataset(X_val, y_val, categorical_feature=list(categorical_to_int.keys()))","e919ecca":"# Set hyperparmeter space\nfrom scipy.stats import randint\nfrom scipy.stats import uniform\nhp_space = {'num_leaves': randint(5, 50), 'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100], 'reg_lambda':[0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_search = RandomizedSearchCV(estimator=clf, param_distributions=hp_space, n_iter=30, refit=True, random_state=2021, verbose=True)\nrandom_search.fit(X_train, y_train, **fit_params)","0e2a6797":"# Training\nprint('Best scroe: ',random_search.best_score_)\nprint('Best hyper-prameter: ', random_search.best_params_)","683dc95c":"# Test\nbst = random_search.best_estimator_\n\n## Preprocess\nused_features_dtype = {\n#     'PassengerId' : 'int64',\n#     'Survived': 'int64',\n    'Pclass': 'int64',\n    #'Name': 'object',\n    'Sex': 'object',\n    'Age': 'float64',\n    'SibSp': 'int64',\n    'Parch': 'int64',\n    \n    #'Ticket': 'object\n    'Fare': 'float64',\n    #'Cabin': 'object',\n    'Embarked': 'object'\n    \n}\npp_test_data = test_data[used_features_dtype.keys()].replace(categorical_to_int)\npp_test_data = pp_test_data.fillna(0)\npp_test_data[\"Embarked\"] = pp_test_data[\"Embarked\"].astype('int64')\n\n## Prediction\nypred = bst.predict(pp_test_data)\nypred = np.array(ypred) > 0.5\nypred = ypred.astype(int)\n\n\n## Prediction to CSV\nd = {'PassengerId': test_data['PassengerId'], 'Survived': ypred}\ndf = pd.DataFrame(d)\ndf.to_csv('submission.csv', index=False)","dceddf7a":"# Define model\nLight Gradient Boosting Machine(LGBM) for classify survival.","5f0eb2c9":"# Hyperparameter tuning via RandomsearchCV\nRandomsearchCV for searching optimal hyperparameter of LGBMClassifier.","817856ae":"# Prepare dataset\nLoading dataset and preprocess it.","a28f0558":"# Titanic: Survival prediction"}}