{"cell_type":{"085bc7e5":"code","2da0e4c8":"code","466b0d1b":"code","b90316ad":"code","a2e456c8":"code","cd4d25a4":"code","3ef2710a":"code","a097e79c":"code","92f5c0c9":"code","49d9a699":"code","dc102c3d":"code","b72a461d":"code","cb1207f2":"code","3b95a51a":"markdown"},"source":{"085bc7e5":"import pandas as pd\ndata1 = pd.read_csv((\"\/media\/gargi\/Data\/DataSets\/SalaryData_Train(naive).csv\"),encoding = \"ISO-8859-1\")\ndata2 = pd.read_csv((\"\/media\/gargi\/Data\/DataSets\/SalaryData_Test(naive).csv\"),encoding = \"ISO-8859-1\")","2da0e4c8":"data1.head()","466b0d1b":"data2","b90316ad":"data1.isnull().sum()","a2e456c8":"data2.isnull().sum()","cd4d25a4":"from sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np","3ef2710a":"emails_bow = CountVectorizer(analyzer=split_into_words).fit(data.text)\n# For training messages\ntrain_emails_matrix = emails_bow.transform(data1)\ntrain_emails_matrix.shape # (3891,8175)\n\n# For testing messages\ntest_emails_matrix = emails_bow.transform(data2)\ntest_emails_matrix.shape # (1668,8175)","a097e79c":"from sklearn.feature_extraction.text import TfidfTransformer\n\n# Learning Term weighting and normalizing on entire emails\ntfidf_transformer = TfidfTransformer().fit(all_emails_matrix)\n\n# Preparing TFIDF for train emails\ntrain_tfidf = tfidf_transformer.transform(train_emails_matrix)\n\ntrain_tfidf.shape # (3891, 6661)\n\n# Preparing TFIDF for test emails\ntest_tfidf = tfidf_transformer.transform(test_emails_matrix)\n\ntest_tfidf.shape #  (1668, 6661)","92f5c0c9":"import re #regular expression\nimport string\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub(\"[0-9\" \"]+\",\" \",text)\n    text = re.sub('[\u2018\u2019\u201c\u201d\u2026]', '', text)\n    return text\n\nclean = lambda x: clean_text(x)\n","49d9a699":"data1['text'] = data1.text.apply(clean)\ndata.text","dc102c3d":"data['text'] = data.text.apply(clean)\ndata.text","b72a461d":"def split_into_words(i):\n    return (i.split(\" \"))","cb1207f2":"emails_bow = CountVectorizer(analyzer=split_into_words).fit(data.text)\n","3b95a51a":"# Data cleaning"}}