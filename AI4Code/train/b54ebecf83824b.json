{"cell_type":{"2d90bd57":"code","443e1e20":"code","781674e5":"code","1ba2fbeb":"code","05f7cd31":"code","67cadc56":"code","dcf5f4d1":"code","263b0e28":"code","f40f4852":"code","92f0854d":"code","43531892":"code","0cacaa0b":"code","9a4dfc34":"code","69e4e5f2":"code","b3ac6775":"code","75da0fa1":"code","cb09491b":"code","c4657954":"code","5b62efe4":"code","6b0bb585":"code","8668afa7":"code","3fc9271d":"code","7f84bb5a":"code","1998faf3":"code","81270555":"code","8c2f01e1":"code","bcc5d798":"code","5aaa815c":"code","c7de95a6":"code","523939a8":"code","7a2f6f97":"code","e0a556aa":"code","7b6f927d":"code","1fda35a4":"code","20ca482c":"code","28d593ce":"code","74ddc268":"code","92cba5f7":"code","bcdc178d":"markdown","dae94c2c":"markdown","a6026ffa":"markdown","79e00505":"markdown"},"source":{"2d90bd57":"from fastai.vision.all import *\nimport numpy as np\nfrom ipywidgets import widgets\nfrom pandas.api.types import CategoricalDtype\nimport pandas as pd\nfrom ipywidgets import widgets\nfrom pandas.api.types import CategoricalDtype\nimport os\nimport matplotlib as mpl","443e1e20":"df=pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\nprint(len(df))\nprint(df.columns)\nprint(df['label'].value_counts().plot.bar())","781674e5":"df.head()","1ba2fbeb":"path = Path('..\/input\/cassava-leaf-disease-classification')\nPath.BASE_PATH=path\npath.ls()\n\n","05f7cd31":"get_items=get_image_files(path\/'train_images')","67cadc56":"Image.open(get_items[1])","dcf5f4d1":"\n#Check the images file, if there are a few that are corrupt\nfailed = verify_images(get_items)\nfailed","263b0e28":"count_dict = df.label.value_counts()\ncount_dict","f40f4852":"df.info","92f0854d":"def get_x(r): return path\/'train_images'\/r['image_id']\ndef get_y(r): return r['label']\n\n","43531892":"get_y(df)","0cacaa0b":"dblock = DataBlock(blocks=(ImageBlock,CategoryBlock),\n                get_x=get_x, \n                get_y=get_y,\n                batch_tfms=[*aug_transforms(min_scale=0.5, size=128),\n                Normalize.from_stats(*imagenet_stats)],\n                item_tfms = RandomResizedCrop(224, min_scale=0.35))\n                   \n","9a4dfc34":"dls = dblock.dataloaders(df,bs=128)\ndls.show_batch()","69e4e5f2":"list(dls)","b3ac6775":"dls.valid.show_batch()","75da0fa1":"\n#Dataset\ndsets = dblock.datasets(df)\ndsets.train[0]\nx,y = dsets.train[0]\nx,y","cb09491b":"dblock.summary(df)\n","c4657954":"dl_train=dls.train\ndl_valid=dls.valid\nlen(dl_train),len(dl_valid)","5b62efe4":"xb,yb = first(dls[0])\nxb.shape,yb.shape\n#Batch_size contains 128 images\n#Images Pixels are 128*128\n#3 channel","6b0bb585":"xb,yb = first(dls.valid)\nprint(\"Print the Input and Output Shape: \\n\", xb.shape,yb.shape)","8668afa7":"#Categories number \n#output Categories\ndls.c","3fc9271d":"# I try to grabb a mini batch from our DataLoader and then passing it to the model:\n#we have a batch side of 64 and 5 categories \nx,y = to_cpu(dls.train.one_batch())\nsubset_model = learn.model(x)\nprint(\"shape of the Submodel: \\n\"subset_model.shape\nsubset_model[0]","7f84bb5a":"learn = cnn_learner(dls, resnet18,\n                    loss_func=F.cross_entropy, metrics=accuracy)\nlearn.fine_tune(4, base_lr=1e-3, freeze_epochs=4)","1998faf3":"learn = cnn_learner(dls, resnet34, metrics=accuracy)\nlearn.fine_tune(4, base_lr=1e-3, freeze_epochs=4)","81270555":"#79%\nlearn = cnn_learner(dls, resnet50,\n                    loss_func=F.cross_entropy, metrics=accuracy)\nlearn.fine_tune(5, base_lr=1e-3, freeze_epochs=4)","8c2f01e1":"learn = cnn_learner(dls, resnet101,\n                    loss_func=F.cross_entropy, metrics=accuracy)\nlearn.fine_tune(4, base_lr=1e-3, freeze_epochs=4)","bcc5d798":"learn.lr_find()","5aaa815c":"def conv(ni, nf, ks=3, act=True):\n    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks\/\/2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res","c7de95a6":"simple_cnn = sequential(\n    conv(3 ,4),            #14x14\n    conv(4 ,8),            #7x7\n    conv(8 ,16),           #4x4\n    conv(16,32),           #2x2\n    conv(32,5, act=False), #1x1\n    Flatten(),\n)","523939a8":"learn = Learner(dls, simple_cnn, loss_func=F.cross_entropy, metrics=accuracy)","7a2f6f97":"learn.summary()","e0a556aa":"learn.fit_one_cycle(2, 0.01)\n","7b6f927d":"m = learn.model[0]\nm","1fda35a4":"m[0].weight.shape","20ca482c":"m[0].bias.shape","28d593ce":"def fit(epochs=1):\n    learn = Learner(dls, simple_cnn, loss_func=F.cross_entropy,\n                    metrics=accuracy, cbs=ActivationStats(with_hist=True))\n    learn.fit(epochs, 0.06)\n    return learn","74ddc268":"learn = fit()","92cba5f7":"learn.activation_stats.plot_layer_stats(0)","bcdc178d":"## Check the torch size","dae94c2c":"## show the Categoories ","a6026ffa":"#Input has a 128 Pixel","79e00505":"#  I defined a new Model"}}