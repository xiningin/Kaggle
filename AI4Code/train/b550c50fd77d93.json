{"cell_type":{"ee890b3d":"code","0eb49d9d":"code","95d0b5ef":"code","6655bc1d":"code","da74774b":"code","f6e41b35":"code","01170d47":"code","036b58f4":"code","f4166dec":"code","e6611813":"code","ed4f8143":"code","7d9ba1f6":"code","5b7fb700":"markdown","d4cdd0ab":"markdown","af4c7901":"markdown","d18e658d":"markdown","f08ace05":"markdown","46e6160e":"markdown","a2cbe117":"markdown","a7be1187":"markdown","d0f3e5b1":"markdown","9ac0066a":"markdown","c451b28b":"markdown","e0f99902":"markdown"},"source":{"ee890b3d":"import os\nimport time\nimport gc\nimport random\n\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pylab as plt\nimport cv2\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.models import Model\nfrom osgeo import gdal\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.colors import LinearSegmentedColormap\n\nprint(tf.__version__)","0eb49d9d":"image_size = 512\nimage_channels = 3\nlabel_values = [0, 1]","95d0b5ef":"def load_dataset(X, y):\n    img1=gdal.Open(X).ReadAsArray().transpose(1, 2, 0)\n    img1  = np.array((img1 \/ 255.0) - 1)\n\n    img2=gdal.Open(y).ReadAsArray()\n    img2 = img2.reshape((img2.shape[0], img2.shape[1], 1))\n    \n    img2 = img2 >= 1 # to binary classification\n      \n    img1=np.array(img1).astype('float16')\n    img2=np.array(img2).astype('int8')\n    \n    return img1, img2","6655bc1d":"X_train, y_train = sorted(glob('..\/input\/california-crop-mapping\/train_images\/*')), sorted(glob('..\/input\/california-crop-mapping\/train_label\/*'))\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=1)\n\nX_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=1)\n\nprint(\"Train: {}, Validation: {}, Test: {}\".format(len(X_train),len(X_val), len(X_test))) ","da74774b":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, \\\n    Conv2DTranspose, concatenate, BatchNormalization, Activation\n\n\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred = K.cast(K.greater(y_pred, t), dtype='float32')\n        inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)\n        union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter\n        acc = K.mean((inter + K.epsilon()) \/ (union + K.epsilon()))\n        prec.append(acc)\n    return  K.mean(tf.convert_to_tensor(prec))\n\ndef model_fn(input_shape, n_filters=64, labels=[]):\n    inputs = keras.Input(input_shape)\n\n    c1 = Conv2D(n_filters * 1, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(n_filters * 1, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(n_filters * 2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(n_filters * 2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(n_filters * 4, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(n_filters * 4, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(n_filters * 8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(n_filters * 8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(n_filters * 16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(n_filters * 16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(n_filters * 8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(n_filters * 8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(n_filters * 4, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(n_filters * 4, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(n_filters * 2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(n_filters * 2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(n_filters * 1, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(n_filters * 1, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    \n    model = keras.Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n\n    return model\n\n\nmodel = model_fn((image_size, image_size, image_channels), labels=label_values)\nmodel.summary()","f6e41b35":"model_dir = '\/kaggle\/working\/logs'\n\ncheckpoint_path = model_dir + '\/model.ckpt'\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n            patience=5, verbose=1)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=checkpoint_path,\n            save_weights_only=True,\n            save_best_only=True)\n\ncallbacks = [es_callback, cp_callback]","01170d47":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, x_data, y_data=None, batch_size=32, labels=None, shuffle=True):\n        self.batch_size = batch_size\n        self.indices = range(len(x_data))\n        self.shuffle = shuffle\n        self.x_data = x_data\n        self.y_data = y_data\n        self.labels = labels\n        self.on_epoch_end()\n\n    def __len__(self):\n        return len(self.indices) \/\/ self.batch_size\n\n    def __getitem__(self, index):\n        X, y = self.__get_data(start=index, end=index + self.batch_size)\n        return X, y\n\n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n\n    def __get_data(self, start, end):\n        \n        X = self.x_data[start:end]\n        y = self.y_data[start:end]\n        \n        X_values = []\n        y_values = []\n        for image_path, labels_path in zip(X, y):\n            image, labels = load_dataset(image_path, labels_path)\n            X_values.append(image)\n            y_values.append(labels)\n        \n        X_values = np.array(X_values)\n        y_values = np.array(y_values)\n        \n        return X_values, y_values","036b58f4":"batch_size = 5\n\nhistory = model.fit_generator(DataGenerator(X_train, y_train, batch_size, label_values),\n                              validation_data=DataGenerator(X_val, y_val, batch_size, label_values),\n                              validation_steps=len(X_val)\/\/batch_size,\n                              steps_per_epoch=len(X_train)\/\/batch_size, \n                              epochs=100, \n                              verbose=1, \n                              callbacks=callbacks)","f4166dec":"plt.figure(figsize=(20,8))\nplt.plot(history.history['loss'], label='Train loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.legend()\nplt.ylabel('Model loss')\nplt.xlabel('Epochs')\nplt.show()\nplt.savefig('\/kaggle\/working\/model_loss.png', dpi=300, bbox_inches='tight')","e6611813":"latest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    print(\"Loading best model....\")\n    model.load_weights(latest)","ed4f8143":"model.save('\/kaggle\/working\/model.h5')","7d9ba1f6":"rows = len(X_test)\n\nrandom.seed(42)\n\ncolors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(label_values))]\n\ncmap = LinearSegmentedColormap.from_list('Colors', colors, N=len(label_values))\n\ncount = 1\n\nfor x, y in zip(X_test, y_test):\n    image, labels = load_dataset(x, y)\n    \n    labels = labels >= 1\n    \n    predicted = model.predict(np.array([image]))[0]\n\n    if len(label_values) > 2:\n        predicted = np.array(tf.math.argmax(predicted, axis=2))\n        labels = tf.math.argmax(labels, axis=2)\n    else:\n        predicted[predicted > 0.5] = 1\n        predicted[predicted <= 0.5] = 0\n    \n    labels = labels.reshape((labels.shape[0], labels.shape[1]))\n    predicted = predicted.reshape((predicted.shape[0], predicted.shape[1]))\n    \n\n    rgb_image = np.array((image + 1) * 255).astype(int)\n    \n    fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n    \n    axs[0].imshow(rgb_image)\n    axs[0].set_title('Image')\n    axs[0].axis('off')\n\n    axs[1].imshow(labels, vmin=0, vmax=len(label_values) - 1, cmap=cmap)\n    axs[1].set_title('Labels')\n    axs[1].axis('off')\n\n    axs[2].imshow(predicted, vmin=0, vmax=len(label_values) - 1, cmap=cmap)\n    axs[2].set_title('Predicted')\n    axs[2].axis('off')\n    \n    plt.show()\n    \n    if count  == 20:\n        break\n    else:\n        count += 1","5b7fb700":"# Settings","d4cdd0ab":"# Save model","af4c7901":"# Train model","d18e658d":"# Imports","f08ace05":"# Load dataset","46e6160e":"# Split data in train, validation and test sets","a2cbe117":"# Create callbacks","a7be1187":"# Plot history","d0f3e5b1":"# U-Net model","9ac0066a":"# Load best model","c451b28b":"# Build DataGenerator","e0f99902":"# Predict test images"}}