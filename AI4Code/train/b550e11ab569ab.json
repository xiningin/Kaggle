{"cell_type":{"e38eb0dd":"code","bd2f9113":"code","211f2cc6":"code","049a2b4f":"code","02d15bd6":"code","1f00c9da":"code","f1c3767b":"code","6a837f97":"code","df48b2fe":"code","b1b1e58d":"code","f9381b9d":"code","f0fdcb53":"code","897f937b":"code","3deebf8a":"code","57e5e895":"code","5fdb841f":"code","b74129e6":"code","b02a81a8":"code","0a668280":"code","8ab84e72":"code","65f67395":"code","9fceb981":"code","d593a278":"code","85bda315":"code","c083feaa":"code","61a70cb7":"code","c1ae3843":"code","2eae3b40":"code","63f38fea":"code","5753528f":"code","79079be8":"code","2f5acdf2":"code","1d4e502e":"code","8cdf356e":"code","bea57f8a":"markdown","fb2d3991":"markdown","1a53a97f":"markdown","85857e64":"markdown","4614d916":"markdown","97764114":"markdown","189a9e69":"markdown","563d85d8":"markdown","e37c959d":"markdown","8a112082":"markdown","19be1023":"markdown","5b20af51":"markdown","cc08953a":"markdown","229d6b2d":"markdown","5d6b4400":"markdown","e3080da3":"markdown","72fb533d":"markdown","56b24e41":"markdown","1810ed58":"markdown","04f18ced":"markdown","766db73c":"markdown","a87dffc0":"markdown","7b9a2a98":"markdown","5d8bfb09":"markdown","0523dfd2":"markdown","074765b8":"markdown","7896fbb3":"markdown"},"source":{"e38eb0dd":"import numpy as np\nimport pandas as pd\nimport gc\nimport json\n\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns","bd2f9113":"DIR = '..\/input\/tensorflow2-question-answering\/'\nPATH_TRAIN = DIR + 'simplified-nq-train.jsonl'\nPATH_TEST = DIR + 'simplified-nq-test.jsonl'","211f2cc6":"!wc -l '..\/input\/tensorflow2-question-answering\/simplified-nq-train.jsonl'\n!wc -l '..\/input\/tensorflow2-question-answering\/simplified-nq-test.jsonl'","049a2b4f":"df_test = pd.read_json(PATH_TEST, orient='records', lines=True)","02d15bd6":"df_test","1f00c9da":"json_train_head = []\nN_HEAD = 10\n\nwith open(PATH_TRAIN, 'rt') as f:\n    for i in range(N_HEAD):\n        json_train_head.append(json.loads(f.readline()))","f1c3767b":"df_train_head = pd.DataFrame(json_train_head)","6a837f97":"df_train_head","df48b2fe":"df_train_head.iloc[0,:].loc['long_answer_candidates']","b1b1e58d":"df_train_head.iloc[0,:].loc['annotations']","f9381b9d":"del df_train_head, df_test\ngc.collect()","f0fdcb53":"N_TRAIN = 307373\nn_long_candidates_train = np.zeros(N_TRAIN)\nt_long_train = np.zeros((N_TRAIN,2))\nt_yesno_train = []","897f937b":"with open(PATH_TRAIN, 'rt') as f:\n    for i in tqdm(range(N_TRAIN)):\n        dic = json.loads(f.readline())\n        n_long_candidates_train[i] = len(dic['long_answer_candidates'])\n        t_long_train[i,0] = dic['annotations'][0]['long_answer']['start_token']\n        t_long_train[i,1] = dic['annotations'][0]['long_answer']['end_token']\n        t_yesno_train.append(dic['annotations'][0]['yes_no_answer'])","3deebf8a":"N_TEST = 345\nn_long_candidates_test = np.zeros(N_TEST)","57e5e895":"with open(PATH_TEST, 'rt') as f:\n    for i in tqdm(range(N_TEST)):\n        dic = json.loads(f.readline())\n        n_long_candidates_test[i] = len(dic['long_answer_candidates'])","5fdb841f":"pd.Series(n_long_candidates_train).describe()","b74129e6":"pd.Series(n_long_candidates_test).describe()","b02a81a8":"plt.hist(n_long_candidates_train, bins=64, alpha=0.5, color='c')","0a668280":"plt.hist(n_long_candidates_train[n_long_candidates_train < np.max(n_long_candidates_test)], density=True, bins=64, alpha=0.5, color='c')\nplt.hist(n_long_candidates_test, density=True, bins=64, alpha=0.5, color='orange')","8ab84e72":"plt.hist(t_yesno_train, bins=[0,1,2,3], align='left', density=True, rwidth=0.6, color='lightseagreen')","65f67395":"pd.Series(t_long_train[:,0]).describe()","9fceb981":"pd.Series(t_long_train[:,1]).describe()","d593a278":"print('{0:.1f}% of start tokens are -1.'.format(np.sum(t_long_train[:,0] < 0) \/ N_TRAIN * 100))\nprint('{0:.1f}% of end tokens are -1.'.format(np.sum(t_long_train[:,1] < 0) \/ N_TRAIN * 100))","85bda315":"np.sum(t_long_train[:,0] * t_long_train[:,1] < 0)","c083feaa":"# no_answer_state[1,:] is the number of train data whose start token and end token are -1\n# no_answer_state[:,1] is the number of train data whose yes-no answer is 'NONE'\n\nno_answer_state = np.zeros((2,2))\nno_answer_state[1,1] = np.sum((t_long_train[:,0]==-1) * (np.array([ 1 if t=='NONE' else 0 for t in t_yesno_train ])))\nno_answer_state[1,0] = np.sum((t_long_train[:,0]==-1) * (np.array([ 0 if t=='NONE' else 1 for t in t_yesno_train ])))\nno_answer_state[0,1] = np.sum((t_long_train[:,0]>=0) * (np.array([ 1 if t=='NONE' else 0 for t in t_yesno_train ])))\nno_answer_state[0,0] = np.sum((t_long_train[:,0]>=0) * (np.array([ 0 if t=='NONE' else 1 for t in t_yesno_train ])))                             ","61a70cb7":"no_answer_state","c1ae3843":"sns.heatmap(no_answer_state \/ N_TRAIN, annot=True, fmt='.3f', vmin=0, vmax=1, cmap='Blues_r')","2eae3b40":"del n_long_candidates_train, n_long_candidates_test, t_long_train, t_yesno_train, no_answer_state\ngc.collect()","63f38fea":"q_lens_train = np.zeros(N_TRAIN)\nd_lens_train = np.zeros(N_TRAIN)","5753528f":"with open(PATH_TRAIN, 'rt') as f:\n    for i in tqdm(range(N_TRAIN)):\n        dic = json.loads(f.readline())\n        q_lens_train[i] = len(dic['question_text'].split())\n        d_lens_train[i] = len(dic['document_text'].split())","79079be8":"q_lens_test = np.zeros(N_TEST)\nd_lens_test = np.zeros(N_TEST)","2f5acdf2":"with open(PATH_TEST, 'rt') as f:\n    for i in tqdm(range(N_TEST)):\n        dic = json.loads(f.readline())\n        q_lens_test[i] = len(dic['question_text'].split())\n        d_lens_test[i] = len(dic['document_text'].split())","1d4e502e":"plt.hist(q_lens_train, density=True, bins=8, alpha=0.5, color='c')\nplt.hist(q_lens_test, density=True, bins=8, alpha=0.5, color='orange')","8cdf356e":"plt.hist(d_lens_train, density=True, bins=64, alpha=0.5, color='c')\nplt.hist(d_lens_test, density=True, bins=64, alpha=0.5, color='orange')","bea57f8a":"We can see below that nearly half of the long answers have start\/end token -1.  \nIn other words, there are a considerable number of '**NO ANSWERS**' in long answer labels, not only in yes-no labels:","fb2d3991":"Let us have fun!  \nComments and recommendations will be welcomed ;)","1a53a97f":"## 3. Text Word Counts","85857e64":"### 3-2. Visualization","4614d916":"#### 3-2-2. Word counts of document text","97764114":"Description of start token labels:","189a9e69":"# 1. Load .jsonl file iteratively","563d85d8":"We can see significant class imbalance in yes-no answer labels.","e37c959d":"## 2-1. Obtain data","8a112082":"## 2-2. Visualization","19be1023":"#### 3-2-1. Word counts of question text","5b20af51":"### 2-2-1. Number of long answer candidates","cc08953a":"Some of data for long answers are swamped with a lot of candidates (**7946 in maximum!**):","229d6b2d":"### 3-1. Obtain data","5d6b4400":"Desciption of end token labels:","e3080da3":"We must be cautious that **\"short answer\" for this competition corresponds to \"yes-no answer\" in the original dataset**.  ","72fb533d":"The heatmap below tells us that:\n- when the start token and\/or the end token are -1, yes-no answer is 'NONE'\n- yes-no answer 'NONE' does not always mean that the start token and\/or the end token are -1","56b24e41":"# 0. Preparation","1810ed58":"### 2-2-2. Yes-no answer labels","04f18ced":"### 0-1. Number of samples in train & test dataset","766db73c":"# 2. Data Visualization","a87dffc0":"However, since we have a **HUGE train dataset** for this competition, Kaggle Notebook RAM cannot afford this method.\nInstead, we probablly have to load the train dataset iteratively:","7b9a2a98":"Let us look into word counts of question texts & document texts.","5d8bfb09":"As we know, one of the most common way to convert .jsonl file into pd.DataFrame is  `pd.read_json(FILENAME, orient='records', lines=True)`:","0523dfd2":"### 2-2-3. Long answer labels","074765b8":"# TL;DR\nThe dataset is **TOO LARGE** for the Kaggle Notebook RAM to load at once.","7896fbb3":"If the start token is -1, the corresponding end token is also -1:"}}