{"cell_type":{"f7146022":"code","5eda4ddc":"code","6c55a3f0":"code","be66b94a":"code","16786a6b":"code","942afb44":"code","0d560915":"code","cc78cfc7":"code","a09e8975":"code","468fcb02":"code","aa428528":"code","1b4041e2":"code","311ab944":"code","290aa1a8":"code","c5c3cf64":"code","643da835":"code","3ff03572":"code","1ce044a7":"code","f2e2da5d":"code","f4db72c8":"code","0865517c":"code","fd9bf7d4":"code","232e2922":"code","63aa620c":"code","73488a3a":"code","2a80ced5":"code","9fe94736":"code","62997179":"code","1199c0a2":"code","28155611":"code","08b1e658":"code","24275e4c":"code","42d4c025":"code","fc1abd75":"code","a43ae6b0":"code","12e916c3":"code","7de86e9f":"code","3689a7b9":"code","dc146210":"code","0f4169fe":"code","26790fc8":"code","a5f81a9f":"code","07753527":"code","94059e95":"code","b1137f24":"code","90338075":"code","2d10de02":"code","ca35f250":"code","508da440":"code","6742af89":"code","6b4f3330":"code","03e0a1a2":"code","d61cdd68":"code","60c646a3":"code","7c277f7d":"code","a639e429":"code","5dd80d54":"code","cb9dcf36":"code","7d841518":"code","335ae58c":"code","2eb90d6f":"code","a69d88d4":"code","9dcfc9a8":"code","9e3e96c9":"code","3947010e":"code","1419b4b9":"code","c65dbb49":"code","98324d1d":"code","31908f83":"code","4e6f88db":"code","dd5e3a7a":"code","fdadc8b1":"markdown","9180e38e":"markdown","cb11825f":"markdown","1db8b531":"markdown","0652b669":"markdown","f2bc93ee":"markdown","3b60969a":"markdown"},"source":{"f7146022":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nimport pickle","5eda4ddc":"data = pd.read_csv('..\/input\/complete.csv')","6c55a3f0":"data.isnull().values.any()","be66b94a":"# Select the columns to be dropped (based on domain knowledge)\ndrop_features = [\"ID\", \"name\", \"full_name\", \"club_logo\", \"birth_date\", \"flag\", \"photo\", \"preferred_foot\", \"eur_release_clause\", \"gk_diving\", \"gk_handling\", \"gk_kicking\", \"gk_positioning\", \"gk_reflexes\", \"1_on_1_rush_trait\", \"argues_with_officials_trait\", \"backs_into_player_trait\",\t\"diver_trait\", \"fan's_favourite_trait\",\t\"gk_flat_kick_trait\", \"gk_long_throw_trait\", \"gk_up_for_corners_trait\", \"leadership_trait\",\t\"one_club_player_trait\", \"puncher_trait\", \"rushes_out_of_goal_trait\", \"saves_with_feet_trait\", \"second_wind_trait\", \"selfish_trait\", \"tactician_speciality\", \"prefers_gk\"]","16786a6b":"# `data_1` is the dataframe that contains the relevant attributes (after performing the drop)\ndata_1 = data[[item for item in list(data.columns) if item not in drop_features]]","942afb44":"data_1.head()","0d560915":"# Columns which contain `null` values\nfor i in list(data_1.columns):\n    if data_1[i].isnull().values.any():\n        print(i, end=\" \")","cc78cfc7":"# club and league NaN values are asigned as \"Unknown\"\ndata_1.club.fillna(\"Unknown\", inplace=True)\ndata_1.league.fillna(\"Unknown\", inplace=True)","a09e8975":"data_1.club.isnull().values.any()","468fcb02":"# Identify the indices of rows which have a goal-keeper\nindex = data_1[~data_1.gk.isnull()].index","aa428528":"# Drop the goal-keeper rows and the associated `gk` column\ndata_2 = data_1.drop(index=index, columns=[\"gk\"])","1b4041e2":"data_2.shape","311ab944":"# Columns which have a bool value (True\/False)\ntf_col = [\"real_face\", \"acrobatic_clearance_trait\", \"avoids_using_weaker_foot_trait\", \"bicycle_kicks_trait\", \"cautious_with_crosses_trait\", \"chip_shot_trait\", \"chipped_penalty_trait\", \"comes_for_crosses_trait\", \"corner_specialist_trait\", \"dives_into_tackles_trait\", \"diving_header_trait\", \"driven_pass_trait\", \"early_crosser_trait\", \"fancy_flicks_trait\", \"finesse_shot_trait\", \"flair_trait\", \"flair_passes_trait\", \"giant_throw_in_trait\", \"inflexible_trait\", \"injury_free_trait\", \"injury_prone_trait\", \"long_passer_trait\", \"long_shot_taker_trait\", \"long_throw_in_trait\", \"outside_foot_shot_trait\", \"playmaker_trait\", \"power_free_kick_trait\", \"power_header_trait\", \"skilled_dribbling_trait\", \"stutter_penalty_trait\", \"swerve_pass_trait\", \"takes_finesse_free_kicks_trait\", \"target_forward_trait\", \"team_player_trait\", \"technical_dribbler_trait\", \"tries_to_beat_defensive_line_trait\", \"poacher_speciality\", \"speedster_speciality\", \"aerial_threat_speciality\", \"dribbler_speciality\", \"playmaker_speciality\", \"engine_speciality\", \"distance_shooter_speciality\", \"crosser_speciality\", \"free_kick_specialist_speciality\", \"tackling_speciality\", \"acrobat_speciality\", \"strength_speciality\", \"clinical_finisher_speciality\", \"prefers_rs\", \"prefers_rw\", \"prefers_rf\", \"prefers_ram\", \"prefers_rcm\", \"prefers_rm\", \"prefers_rdm\", \"prefers_rcb\", \"prefers_rb\", \"prefers_rwb\", \"prefers_st\", \"prefers_lw\", \"prefers_cf\", \"prefers_cam\", \"prefers_cm\", \"prefers_lm\", \"prefers_cdm\", \"prefers_cb\", \"prefers_lb\", \"prefers_lwb\", \"prefers_ls\", \"prefers_lf\", \"prefers_lam\", \"prefers_lcm\", \"prefers_ldm\", \"prefers_lcb\"]","290aa1a8":"# Represent the bool values as numeric data\n# True === 1, False === 0\nfor i in tf_col:\n    data_2[i] = data_2[i].apply(lambda x: 1 if x else 0)","c5c3cf64":"labelEncoder = LabelEncoder()","643da835":"# Encode the string attributes using the LabelEncoder\ndata_2['club_le'] = labelEncoder.fit_transform(data_2.club)\ndata_2['league_le'] = labelEncoder.fit_transform(data_2.league)\ndata_2['body_type_le'] = labelEncoder.fit_transform(data_2.body_type)\ndata_2['nationality_le'] = labelEncoder.fit_transform(data_2.nationality)\ndata_2['work_rate_att_le'] = labelEncoder.fit_transform(data_2.work_rate_att)\ndata_2['work_rate_def_le'] = labelEncoder.fit_transform(data_2.work_rate_def)","3ff03572":"# Feature Engineering\n# Represents the sum of number of prefered positions of a player\ndata_2['prefers_pos_sum'] = data_2.prefers_rs + data_2.prefers_rw + data_2.prefers_rf + data_2.prefers_ram + data_2.prefers_rcm + data_2.prefers_rm + data_2.prefers_rdm + data_2.prefers_rcb + data_2.prefers_rb + data_2.prefers_rwb + data_2.prefers_st + data_2.prefers_lw + data_2.prefers_cf + data_2.prefers_cam + data_2.prefers_cm + data_2.prefers_lm + data_2.prefers_cdm + data_2.prefers_cb + data_2.prefers_lb + data_2.prefers_lwb + data_2.prefers_ls + data_2.prefers_lf + data_2.prefers_lam + data_2.prefers_lcm + data_2.prefers_ldm + data_2.prefers_lcb","1ce044a7":"# Feature Engineering\n# Represents the sum of number of traits\/speciality of a player\ndata_2['traits_sum'] = data_2.acrobatic_clearance_trait + data_2.avoids_using_weaker_foot_trait + data_2.bicycle_kicks_trait + data_2.cautious_with_crosses_trait + data_2.chip_shot_trait + data_2.chipped_penalty_trait + data_2.comes_for_crosses_trait + data_2.corner_specialist_trait + data_2.dives_into_tackles_trait + data_2.diving_header_trait + data_2.driven_pass_trait + data_2.early_crosser_trait + data_2.fancy_flicks_trait + data_2.finesse_shot_trait + data_2.flair_trait + data_2.flair_passes_trait + data_2.giant_throw_in_trait + data_2.inflexible_trait + data_2.injury_free_trait + data_2.injury_prone_trait + data_2.long_passer_trait + data_2.long_shot_taker_trait + data_2.long_throw_in_trait + data_2.outside_foot_shot_trait + data_2.playmaker_trait + data_2.power_free_kick_trait + data_2.power_header_trait + data_2.skilled_dribbling_trait + data_2.stutter_penalty_trait + data_2.swerve_pass_trait + data_2.takes_finesse_free_kicks_trait + data_2.target_forward_trait + data_2.team_player_trait + data_2.technical_dribbler_trait + data_2.tries_to_beat_defensive_line_trait + data_2.poacher_speciality + data_2.speedster_speciality + data_2.aerial_threat_speciality + data_2.dribbler_speciality + data_2.playmaker_speciality + data_2.engine_speciality + data_2.distance_shooter_speciality + data_2.crosser_speciality + data_2.free_kick_specialist_speciality + data_2.tackling_speciality + data_2.acrobat_speciality + data_2.strength_speciality + data_2.clinical_finisher_speciality","f2e2da5d":"data_2.head()","f4db72c8":"# Correlation matrix\ncorr = data_2.corr()\ncor_dict = corr['overall'].sort_values(ascending=False).to_dict()\ncorr['overall'].sort_values(ascending=False)","0865517c":"# Feature Engineering\n# Compute BMI from height and weight\ndata_2['bmi'] = data_2.weight_kg \/ (data_2.height_cm\/100.0)**2","fd9bf7d4":"data_2.body_type.value_counts()","232e2922":"# Dataset has outliers, clean them up by setting them to appropriate values\n# Values have been set based on the domain knowledge\ndata_2.loc[data_2.body_type == 'Neymar', 'body_type'] = 'Lean'\ndata_2.loc[data_2.body_type == 'Messi', 'body_type'] = 'Lean'\ndata_2.loc[data_2.body_type == 'Shaqiri', 'body_type'] = 'Normal'\ndata_2.loc[data_2.body_type == 'Akinfenwa', 'body_type'] = 'Stocky'\ndata_2.loc[data_2.body_type == 'C. Ronaldo', 'body_type'] = 'Normal'","63aa620c":"minmax = MinMaxScaler()","73488a3a":"# Columns to be normalized\ncol = [\"age\", \"height_cm\", \"weight_kg\", \"real_face\", \"eur_value\", \"eur_wage\", \"potential\", \"pac\", \"sho\", \"pas\", \"dri\", \"def\", \"phy\", \"international_reputation\", \"skill_moves\"]","2a80ced5":"# Normalize the data using the `MinMaxScalar`\narr =  minmax.fit_transform(data_2[col])","9fe94736":"# Build the appropriate data frame (note that goal-keepers have been removed) - Set appropriate index\ndata_norm = pd.DataFrame(arr,columns=col,index=data_2.index)","62997179":"data_norm.shape","1199c0a2":"# Aggregate feature set\nfeatures = [\"club_le\", \"real_face\", \"age\", \"league_le\", \"height_cm\", \"weight_kg\", \"body_type_le\", \"nationality_le\", \"eur_value\", \"eur_wage\", \"potential\", \"pac\", \"sho\", \"pas\", \"dri\", \"def\", \"phy\", \"international_reputation\", \"skill_moves\"]","28155611":"data_2[features].hist(bins=50, figsize=(20,15))\nplt.savefig('hist.png')\nplt.show()","08b1e658":"attributes = [\"age\", \"height_cm\", \"weight_kg\", \"real_face\", \"eur_value\", \"eur_wage\", \"potential\", \"pac\", \n              \"sho\", \"pas\", \"dri\", \"def\", \"phy\", \"international_reputation\", \"skill_moves\"]\n\npositions = ['rs', 'rw', 'rf', 'ram', 'rcm', 'rm', 'rdm', 'rcb', 'rb', 'rwb', 'st', 'lw',\n             'cf', 'cam', 'cm', 'lm', 'cdm', 'cb', 'lb', 'lwb', 'ls', 'lf', 'lam', 'lcm',\n             'ldm', 'lcb']\n\ncols_pref = [x for x in data_2.columns if 'prefers' in x]\n\ndata_norm_prefs = data_2.loc[:, cols_pref]\n\ny = data_norm_prefs.sum().sort_values(ascending=False)\nx = np.arange(1, len(y) + 1)\n\ncols_inc = [x for x in data_2.columns]\n\ncols_incl = [x for x in y.index if y[x]>0]\n\ndata_norm_prefs = data_2.loc[:, cols_incl]\n\ndata_norm_att = data_norm.loc[:, attributes].applymap(lambda x: x)\n#data_norm_att = data_norm_att.loc[data_norm_att.sum(axis=1) > 0, cols_inc]\ndata_norm_att = data_norm_att.apply(lambda x: (x-x.mean()))\n\ndata_norm_prefs = data_norm_prefs.drop(columns = ['prefers_pos_sum'])","24275e4c":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\nmclf = OneVsRestClassifier(clf)\nmclf.fit(data_norm_att, data_norm_prefs)\n\nfeat_imp = pd.DataFrame()\n#feat_imp_sum = np.zeros(len(data_norm_prefs.columns))\n\nfig, ax = plt.subplots(1,1, figsize=(20, 15))\n\nx = 1\nfor l, e in zip(data_norm_prefs.columns, mclf.estimators_):\n    feat_imp.loc[:, l] = e.feature_importances_\n\ncolors = np.concatenate((plt.cm.tab20(np.linspace(0, 1, 20)), plt.cm.Set3(np.linspace(0, 1, 20))))\nx = np.arange(1, len(feat_imp.columns) + 1)\ny = np.zeros(len(feat_imp.columns))\n\npositions=feat_imp.columns\nfor n in range(0, len(feat_imp.index)):\n    ax.bar(x, feat_imp.loc[n, :], bottom=y, label=data_norm_att.columns[n], color=colors[n])\n    y += feat_imp.loc[n, :]\nax.set_xticks(x)\nax.set_xticklabels(positions,rotation = 45, ha=\"right\")\nax.legend(bbox_to_anchor=(0.98,1), loc=\"upper left\")\nplt.savefig('bar.png')","42d4c025":"dataset40 = data_1.loc[data_1['age'] <= 40]\nage = dataset40.sort_values(\"age\")['age'].unique()\noverall = dataset40.groupby(\"age\")[\"overall\"].mean().values\npotential = dataset40.groupby(\"age\")[\"potential\"].mean().values\npace = dataset40.groupby(\"age\")[\"pac\"].mean().values\nPass = dataset40.groupby(\"age\")[\"pas\"].mean().values\n\nplt.figure()\nplt.figure(figsize=(16,8))\nplt.title('Age vs Mean Overall\/Potential\/Pace\/Shot Rating', fontsize=20, fontweight='bold')\nplt.xlabel('Player Age', fontsize=15)\nplt.ylabel('Player Overall', fontsize=15)\nsns.set_style(\"whitegrid\")\nplt.plot(age, overall, label=\"Overall\")\nplt.plot(age, potential, label=\"Potential\")\nplt.plot(age, pace, label=\"Pace\")\nplt.plot(age, Pass, label=\"Pass\")\nplt.legend(loc=4, prop={'size': 15}, frameon=True,shadow=True, facecolor=\"white\", edgecolor=\"black\")\nplt.savefig('chart.png')","fc1abd75":"attr = ['name', 'pac', 'sho', 'pas', 'dri', 'def', 'phy']\ndf = pd.DataFrame(data.loc[:10,attr])\n\nfrom math import pi\ncategories = ['pace', 'shot', 'pass', 'dribble','defence', 'physique']\nN = len(categories)\n \n# What will be the angle of each axis in the plot? (we divide the plot \/ number of variable)\nangles = [n \/ float(N) * 2 * pi for n in range(N)]\nangles += angles[:1]\n\nfor i in range(df.shape[0]):\n    # Initialise the spider plot\n    ax = plt.subplot(111, polar=True)\n    # If you want the first axis to be on top:\n    ax.set_theta_offset(pi \/ 2)\n    ax.set_theta_direction(-1)\n    # Draw one axe per variable + add labels labels yet\n    plt.xticks(angles[:-1], categories)\n    # Draw ylabels\n    ax.set_rlabel_position(0)\n    plt.yticks([0,50,100], [\"0\",\"50\",\"100\"], color=\"grey\", size=7)\n    plt.ylim(0,100)\n\n    values=df.loc[i].drop('name').values.flatten().tolist()\n    values += values[:1]\n    ax.plot(angles, values, linewidth=1, linestyle='solid', label=df.name[i])\n    ax.fill(angles, values, 'b', alpha=0.1)\n    fig_size = plt.rcParams[\"figure.figsize\"]\n    fig_size[0] = 20\n    fig_size[1] = 16\n    plt.rcParams[\"figure.figsize\"] = fig_size\n    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n    plt.savefig('radar.png')","a43ae6b0":"# train, test = train_test_split(data_3, test_size=0.3, random_state=3, shuffle=True)\n# ytrain_ = train['overall']\n# Xtrain_ = train[features]\n# ytest_ = test['overall']\n# Xtest_ = test[features]\n# # Experiment - Linear Regression model\n# from sklearn.linear_model import LinearRegression\n# clf = LinearRegression()\n\n# # Validation score\n# # Evaluation criteria - Mean squared error\n# score = -1 * cross_val_score(clf, Xtrain_, ytrain_, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n# score.mean()\n\n# # Train the model\n# clf.fit(Xtrain_, ytrain_)\n# # Evaluate the model based on the defined evaluation criteria\n# mean_squared_error(ytest_, clf.predict(Xtest_))\n# # Compute the R2 score of the model\n# clf.score(Xtest_, ytest_)\n# pickle.dump(clf, open('Linear_Regression.p', 'wb'))","12e916c3":"train_, test_ = train_test_split(data_2, test_size=0.3, random_state=3, shuffle=True)","7de86e9f":"# Define the target feature set for the problem\ny_features = [\"overall\", \"rs\", \"rw\", \"rf\", \"ram\", \"rcm\", \"rm\", \"rdm\", \"rcb\", \"rb\", \"rwb\", \"st\", \"lw\", \"cf\", \"cam\", \"cm\", \"lm\", \"cdm\", \"cb\", \"lb\", \"lwb\", \"ls\", \"lf\", \"lam\", \"lcm\", \"ldm\", \"lcb\"]","3689a7b9":"print(features)","dc146210":"Ytrain_ = train_[y_features]\nXtrain_ = train_[features]\nYtest_ = test_[y_features]\nXtest_ = test_[features]","0f4169fe":"# Multi-target regression is a stratergy of fitting one regressor per target. This is a simple stratergy for extending regressors that do not natively support multi-target regression\nfrom sklearn.multioutput import MultiOutputRegressor\n# Gradient Boosting for regression - In each stage a regression tree is fit on the negative gradient of the given loss function\n# Default loss function = Least square regression\nfrom sklearn.ensemble import GradientBoostingRegressor\nclf =  MultiOutputRegressor(GradientBoostingRegressor(), n_jobs=-1)","26790fc8":"# Validation score\n# Evaluation criteria - Mean squared error\nscore = -1 * cross_val_score(clf, Xtrain_, Ytrain_, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\nscore.mean()","a5f81a9f":"# Train the model\nclf.fit(Xtrain_, Ytrain_)","07753527":"# Evaluate the model based on the defined evaluation criteria\nmean_squared_error(Ytest_, clf.predict(Xtest_))","94059e95":"# Compute the R2 score of the model\nclf.score(Xtest_, Ytest_)","b1137f24":"pickle.dump(clf, open('MultiOutputRegressor_GradientBoostingRegressor1.p', 'wb'))","90338075":"# A decision tree regressor\nfrom sklearn.tree import DecisionTreeRegressor\nclf =  DecisionTreeRegressor()","2d10de02":"# Validation score\n# Evaluation criteria - Mean squared error\nscore = -1 * cross_val_score(clf, Xtrain_, Ytrain_, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\nscore.mean()","ca35f250":"# Train the model\nclf.fit(Xtrain_, Ytrain_)","508da440":"# Evaluate the model based on the defined evaluation criteria\nmean_squared_error(Ytest_, clf.predict(Xtest_))","6742af89":"# Compute the R2 score of the model\nclf.score(Xtest_, Ytest_)","6b4f3330":"pickle.dump(clf, open('DecisionTreeRegressor1.p', 'wb'))","03e0a1a2":"# A random forest is a meta estimator that fits a number of decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and controls over-fitting\nfrom sklearn.ensemble import RandomForestRegressor\nclf = RandomForestRegressor(n_jobs=-1, n_estimators=500, max_depth=15)","d61cdd68":"# Validation score\n# Evaluation criteria - Mean squared error\nscore = -1 * cross_val_score(clf, Xtrain_, Ytrain_, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\nscore.mean()","60c646a3":"# Train the model\nclf.fit(Xtrain_, Ytrain_)","7c277f7d":"pickle.dump(clf, open('RandomForestRegressor1.p', 'wb'))","a639e429":"# Evaluate the model based on the defined evaluation criteria\nmean_squared_error(Ytest_, clf.predict(Xtest_))","5dd80d54":"# Compute the R2 score of the model\nclf.score(Xtest_, Ytest_)","cb9dcf36":"string_features = ['club', 'league', 'body_type', 'nationality', 'work_rate_att', 'work_rate_def']","7d841518":"train_, test_ = train_test_split(data_2, test_size=0.3, random_state=3, shuffle=True)","335ae58c":"Xtrain2_ = train_[[item for item in list(data_2.columns) if item not in ['overall']+string_features]]\nXtest2_ = test_[[item for item in list(data_2.columns) if item not in ['overall']+string_features]]","2eb90d6f":"# PCA for dimension reduction(from 177 to 50)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=50)\npca.fit(Xtrain2_, Ytrain_)","a69d88d4":"# Transforming the X labels into PCA X labels with reduced dimensionality\nXtrain_pca = pca.transform(Xtrain2_)\nXtest_pca = pca.transform(Xtest2_)","9dcfc9a8":"Xtrain_pca.shape, Xtrain_.shape","9e3e96c9":"# Create the multi regressor model\nclf =  MultiOutputRegressor(GradientBoostingRegressor(), n_jobs=-1)","3947010e":"# Validation score\n# Evaluation criteria - Mean squared error\nscore = -1 * cross_val_score(clf, Xtrain_, Ytrain_, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\nscore.mean()","1419b4b9":"# Train the model with PCA components\nclf.fit(Xtrain_pca, Ytrain_)","c65dbb49":"# Evaluate the model based on the defined evaluation criteria\nmean_squared_error(Ytest_, clf.predict(Xtest_pca))","98324d1d":"# Compute the R2 score of the model\nclf.score(Xtest_pca, Ytest_)","31908f83":"pickle.dump(clf, open('MultiOutputRegressor_GradientBoostingRegressor_PCA1.p', 'wb'))","4e6f88db":"test_.to_csv(path_or_buf='test.csv')","dd5e3a7a":"test_","fdadc8b1":"Visualization","9180e38e":"PCA","cb11825f":"Multi Output RandomForest","1db8b531":"Data Preprocessing","0652b669":"Decision Tree regressor","f2bc93ee":"Linear Regression","3b60969a":"Multi Regression "}}