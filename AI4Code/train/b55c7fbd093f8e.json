{"cell_type":{"80c8ed42":"code","b09c9813":"code","102d29c8":"code","0c177cc0":"code","f4bea8b3":"code","795ec4c6":"code","8bcd8a13":"code","f6b6ed6a":"code","6594d951":"code","83c07204":"code","8e804541":"code","d091eaaf":"code","d15bbc2d":"code","e1662a96":"code","e51c75d1":"code","f8bfe989":"code","97c0741a":"code","9bb5cd52":"code","f9ddfcaa":"code","913d765d":"code","42ead62f":"code","74adc75a":"code","76a06b2d":"markdown","45682882":"markdown","32c82994":"markdown","2305060d":"markdown","127f8268":"markdown","559a89b5":"markdown","b105f325":"markdown","357e3c5f":"markdown","8fd4d60b":"markdown","120838eb":"markdown","9dc9cd4a":"markdown","9b950e83":"markdown","bb717c97":"markdown","b084fa12":"markdown","24eebd18":"markdown","8662724d":"markdown","de2905df":"markdown"},"source":{"80c8ed42":"import pandas as pd\nimport numpy as np\nfrom pandas import Series, DataFrame","b09c9813":"import matplotlib as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","102d29c8":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf.head()","0c177cc0":"df.describe()","f4bea8b3":"sns.histplot(df[df.DEATH_EVENT == 1].age, kde=True, color=\"red\")","795ec4c6":"sns.histplot(df[df.DEATH_EVENT == 0].age, kde=True)","8bcd8a13":"df.isnull().any()","f6b6ed6a":"df.dtypes","6594d951":"df.corr()[\"DEATH_EVENT\"].sort_values()","83c07204":"df.columns","8e804541":"X = df.drop(['DEATH_EVENT'], axis=1)\ny = df.DEATH_EVENT","d091eaaf":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)","d15bbc2d":"from sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Function to evaluate models\ndef evaluating_model(model, X_train, y_train, X_valid, y_valid):\n    model.fit(X_train, y_train)\n    pred = model.predict(X_valid)\n    print(f'Accuracy Score: {round(accuracy_score(y_valid, pred) * 100, 3)}')\n    print(f'Precision Score: {round(precision_score(y_valid,pred) * 100, 3)}')\n    print(f'Recall Score: {round(recall_score(y_valid,pred) * 100, 3)}')","e1662a96":"from sklearn.tree import DecisionTreeClassifier\n\ntree_model_1 = DecisionTreeClassifier(random_state=1)\n\nevaluating_model(tree_model_1, X_train, y_train, X_valid, y_valid)","e51c75d1":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_model_1 = RandomForestClassifier(random_state=1)\n\nevaluating_model(random_model_1, X_train, y_train, X_valid, y_valid)","f8bfe989":"from xgboost import XGBClassifier\n\nxgb_model_1 = XGBClassifier(eval_metric='logloss')\n\nevaluating_model(xgb_model_1, X_train, y_train, X_valid, y_valid)","97c0741a":"for max_leaf_nodes in [5, 50, 500, 5000, 50000]:\n    model = DecisionTreeClassifier(random_state=1, max_leaf_nodes=max_leaf_nodes)\n    print(f'Max leaf nodes = {max_leaf_nodes}')\n    evaluating_model(model, X_train, y_train, X_valid, y_valid)\n    print('-----------------')","9bb5cd52":"tree_model_2 = DecisionTreeClassifier(random_state=1, max_leaf_nodes=5000)\n\nevaluating_model(tree_model_2, X_train, y_train, X_valid, y_valid)","f9ddfcaa":"for n_estimators in [500, 550, 600, 650, 700, 750, 800]:\n    model = RandomForestClassifier(random_state=1, n_estimators=n_estimators)\n    print(f'N_estimators = {n_estimators}')\n    evaluating_model(model, X_train, y_train, X_valid, y_valid)\n    print('-----------------')","913d765d":"random_model_2 = RandomForestClassifier(random_state=1, n_estimators=800)\n\nevaluating_model(random_model_2, X_train, y_train, X_valid, y_valid)","42ead62f":"for n_estimators in [500, 550, 600, 650, 700, 750, 800]:\n    model = XGBClassifier(n_estimators=n_estimators, learning_rate=0.05, eval_metric = \"logloss\")\n    print(f'N_estimators = {n_estimators}')\n    evaluating_model(model, X_train, y_train, X_valid, y_valid)\n    print('-----------------')","74adc75a":"xgb_model_2 = XGBClassifier(n_estimators=800, learning_rate=0.05, eval_metric = \"logloss\")\n\nevaluating_model(xgb_model_2, X_train, y_train, X_valid, y_valid)","76a06b2d":"### After tuning the parameters:\n<ul>\n<li>Decision Tree: 81.333<\/li>\n<li>Random Forest: 89.333<\/li>\n<li>XGBoost: 92.0<\/li>\n<\/ul>","45682882":"### Decision Tree","32c82994":"### XGBoost","2305060d":"### Check the correlation of the variables","127f8268":"## Expore the data","559a89b5":"Hence there are no missing values","b105f325":"### Checking the distribution of age for Death and Alive cases","357e3c5f":"## Defining X and y","8fd4d60b":"### Random Forest","120838eb":"### Default parameters:\n<ul>\n<li>Decision Tree: 78.667<\/li>\n<li>Random Forest: 89.333<\/li>\n<li>XGBoost: 92.0<\/li>\n<\/ul>","9dc9cd4a":"## Comparing models with default parameters","9b950e83":"### Random Forest","bb717c97":"### Checking for null values","b084fa12":"<ul>\n<li>Decision Tree<\/li>\n<li>Random Forest<\/li>\n<li>XGBoost<\/li>\n<\/ul>","24eebd18":"### XGBoost","8662724d":"## Fine-tuning the parameters","de2905df":"### Decision Tree"}}