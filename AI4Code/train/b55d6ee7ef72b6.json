{"cell_type":{"956292a7":"code","9c1bc378":"code","a24dd1cc":"code","697dd371":"code","567ab52c":"code","838fcbae":"code","13a46eae":"code","b120cf79":"code","c9b655df":"code","91c387c0":"code","9d8a15f7":"code","28adc562":"code","ee514219":"code","72b87caa":"code","df959f2b":"code","9a053235":"code","c479115f":"code","277663f0":"code","0ab4467a":"code","b543337d":"code","f4be9551":"code","e3e7957a":"code","3c43a8c5":"code","2d1bacf0":"code","8d926694":"code","bd4a1e0f":"code","7da08ba2":"code","4e20adae":"code","114ab78c":"code","a82f9305":"code","9d3bff67":"code","34752156":"code","c7f80137":"code","b690ac2b":"code","f698d995":"code","49d20a33":"code","2789fbcc":"code","7df34054":"code","75487042":"code","bfcca7ec":"code","4abbeb30":"code","004e7ecd":"code","ca99b141":"code","953ec6f0":"code","a291c27c":"code","fda1a3c5":"code","3d6ef71e":"code","7cf24cab":"code","38e8cdb5":"code","86fc0730":"code","34d8d427":"code","afb57866":"code","117526bb":"code","b9e66c69":"code","643639e0":"code","f5bfe507":"code","8b69bbd3":"code","3f06b022":"code","bdd7f312":"code","459b1eca":"code","be4fb978":"code","74636778":"code","1d429b9a":"code","91558582":"code","c4922fbc":"code","2d1053d8":"code","4622c187":"code","4241b4a9":"code","065a71be":"code","b45c2b09":"code","13f96842":"code","604a943f":"code","2879c1e0":"code","5b313d57":"code","9fc79a91":"code","74512670":"code","a6a304c4":"code","fa89fc7f":"code","c1e43964":"code","339647f4":"code","1b953439":"code","6120773b":"code","fb3d5ce5":"code","ffd49528":"code","8008ba3d":"code","c6d99f2c":"code","d396d048":"code","6d3d9884":"code","9a147b2c":"code","5a4d4a49":"code","8c7ef2d3":"code","3b60e5dc":"code","aa197c22":"code","50b84bab":"markdown","4e21e23e":"markdown","6f4151ed":"markdown","df67a238":"markdown","052bd6c4":"markdown","5b0565c6":"markdown","ac8e79fe":"markdown","75b0563e":"markdown","ad39cc49":"markdown","8f18f449":"markdown","f87a73a5":"markdown","95fed199":"markdown","edc7baa1":"markdown","4442209b":"markdown","07f9251d":"markdown","2fb3a226":"markdown","7d66bce2":"markdown","31701b7a":"markdown","a96640c5":"markdown"},"source":{"956292a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9c1bc378":"import seaborn as sns\nsns.set(style=\"darkgrid\")\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot figures\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12","a24dd1cc":"def load_housing_data(filename, house_path):\n    csv_path = os.path.join(house_path, filename)\n    return pd.read_csv(csv_path)","697dd371":"train_data = load_housing_data('train.csv',\"..\/input\")\ntest_data = load_housing_data('test.csv','..\/input')","567ab52c":"housing = train_data.copy()","838fcbae":"housing.info()","13a46eae":"housing.head()","b120cf79":"housing.describe()","c9b655df":"#box plot overallqual\/saleprice\nvar = 'MSZoning'\ndata = pd.concat([housing['SalePrice'], housing[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","91c387c0":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([housing['SalePrice'], housing[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","9d8a15f7":"housing['SalePrice'].describe()","28adc562":"sns.distplot(housing[['SalePrice']].dropna())\nplt.show()","ee514219":"#skewness and kurtosis\nprint(\"Skewness: %f\" % housing['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % housing['SalePrice'].kurt())","72b87caa":"housing[housing.isnull().any(axis=1)].head()","df959f2b":"sns.pairplot(data=housing[['SalePrice','MasVnrArea','LotFrontage','BsmtFinSF1','BsmtFinSF2']].dropna())\nplt.show()","9a053235":"corrmat = housing.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","c479115f":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(housing[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","277663f0":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nclass ReduceVIF(BaseEstimator, TransformerMixin):\n    def __init__(self, thresh=5.0, impute=True, impute_strategy='median'):\n        # From looking at documentation, values between 5 and 15 are \"okay\".\n        # Above 15 is too high and so should be removed.\n        self.thresh = thresh\n        \n        # The statsmodel function will fail with NaN values, as such we have to impute them.\n        # By default we impute using the median value.\n        if impute:\n            self.imputer = SimpleImputer(strategy=impute_strategy)\n\n    def fit(self, X, y=None):\n        print('ReduceVIF fit')\n        print(self.imputer)\n        if hasattr(self, 'imputer'):\n            self.imputer.fit(X)\n        return self\n\n    def transform(self, X, y=None):\n        print('ReduceVIF transform')\n        columns = X.columns.tolist()\n        if hasattr(self, 'imputer'):\n            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n        return ReduceVIF.calculate_vif(X, self.thresh)\n\n    @staticmethod\n    def calculate_vif(X, thresh=5.0):\n        dropped=True\n        while dropped:\n            variables = X.columns\n            dropped = False\n            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n            \n            max_vif = max(vif)\n            if max_vif > thresh:\n                maxloc = vif.index(max_vif)\n                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n                dropped=True\n        print(X.columns)\n        return X","0ab4467a":"transformer = ReduceVIF(thresh=15)\nnum_attributes = list(transformer.fit_transform(housing.select_dtypes(include=['int64','float64'])).columns.values)","b543337d":"corrmat = housing[num_attributes].corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","f4be9551":"#missing data\ntotal = housing.isnull().sum().sort_values(ascending=False)\npercent = (housing.isnull().sum()\/housing.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","e3e7957a":"missing_data[missing_data.Percent>=0.15]","3c43a8c5":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# A class to select numerical, categorical or datetime columns \nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attribute_names]","2d1bacf0":"housing = train_data.copy()","8d926694":"housing.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1, inplace=True)","bd4a1e0f":"cat_attributes = housing.select_dtypes(include='object').columns\ncat_attributes","7da08ba2":"from sklearn.pipeline import Pipeline\n\ncat_pipeline = Pipeline([\n    (\"selector\", DataFrameSelector(attribute_names=cat_attributes))\n])","4e20adae":"cat_pipeline.fit_transform(housing).info()","114ab78c":"plt.figure(figsize=(15,3))\n\nax1=plt.subplot(131)\nsns.countplot(x='BsmtQual', data=housing, ax=ax1)\nplt.xlabel('BsmtQual')\n\nax2=plt.subplot(132)\nsns.countplot(x='BsmtCond', data=housing, ax=ax2)\nplt.xlabel('BsmtCond')\n\nax3=plt.subplot(133)\nsns.countplot(x='BsmtFinType2', data=housing, ax=ax3)\nplt.xlabel('BsmtFinType2')\n\nplt.show()","a82f9305":"class CategoricalImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[attr].value_counts().index[0] for attr in X], index=X.columns)\n        return self\n    \n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","9d3bff67":"from sklearn.pipeline import Pipeline\n\ncat_pipeline = Pipeline([\n    (\"selector\", DataFrameSelector(attribute_names=cat_attributes)),\n    ('imputer', CategoricalImputer())\n])","34752156":"some_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nsome_incomplete_rows[cat_attributes]","c7f80137":"cat_pipeline.fit_transform(housing).loc[some_incomplete_rows.index]","b690ac2b":"cat_pipeline.fit_transform(housing).info()","f698d995":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\n\ncat_pipeline = Pipeline([\n    (\"selector\", DataFrameSelector(attribute_names=cat_attributes)),\n    ('imputer', CategoricalImputer()),\n    (\"encoder\", OneHotEncoder(sparse=False))\n])","49d20a33":"cat_pipeline.fit_transform(housing)","2789fbcc":"cat_pipeline.fit_transform(housing).shape","7df34054":"housing = train_data.copy()","75487042":"housing.select_dtypes(include=['int64','float64']).columns","bfcca7ec":"housing.drop(['Id','SalePrice', 'LotFrontage'],axis=1, inplace=True)","4abbeb30":"transformer = ReduceVIF(thresh=15)\nnum_attributes = list(transformer.fit_transform(housing.select_dtypes(include=['int64','float64'])).columns.values)","004e7ecd":"num_attributes = housing.select_dtypes(include=['int64','float64']).columns.values\nnum_attributes","ca99b141":"housing[num_attributes].info()","953ec6f0":"housing[num_attributes].hist(figsize=(20,12))\nplt.show()","a291c27c":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')","fda1a3c5":"housing_transform = pd.DataFrame(imputer.fit_transform(housing[num_attributes]), columns=num_attributes)","3d6ef71e":"housing_transform = housing_transform.apply(lambda x: np.sign(x) * np.log(1 + np.abs(x)))","7cf24cab":"housing_transform.hist(figsize=(20,12))\nplt.show()","38e8cdb5":"class LogModulusTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        return np.apply_along_axis(lambda x: np.sign(x) * np.log(1 + np.abs(x)), 1, X)\n        # return X.apply(lambda x: np.sign(x) * np.log(1 + np.abs(x)))","86fc0730":"BsmtFullBath_ix = list(num_attributes).index('BsmtFullBath')\nBsmtHalfBath_ix = list(num_attributes).index('BsmtHalfBath')\nHalfBath_ix = list(num_attributes).index('HalfBath')\n\nextra_attributes = ['TotalBath']\n\nclass CombinedNumAttributesAdder(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        total_bath = X[:, BsmtFullBath_ix] + X[:, BsmtHalfBath_ix] + X[:, HalfBath_ix]\n        return np.c_[X, total_bath]","34d8d427":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attributes)),\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('attr_adder', CombinedNumAttributesAdder()),\n    ('transformer', LogModulusTransformer()),\n    ('scaler', StandardScaler()),\n])","afb57866":"num_pipeline.fit_transform(housing)","117526bb":"num_pipeline.fit_transform(housing).shape","b9e66c69":"from sklearn.pipeline import FeatureUnion\n\npreprocess_pipeline = FeatureUnion(transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline)\n    ])","643639e0":"X_train = train_data.copy()","f5bfe507":"X_train['SalePrice'].hist()\nplt.show()","8b69bbd3":"X_train['SalePrice'].apply(lambda x: np.sign(x) * np.log(1 + np.abs(x))).hist()\nplt.show()","3f06b022":"X_train_prepared = preprocess_pipeline.fit_transform(X_train)\ny_train = X_train['SalePrice'].apply(lambda x: np.log(x))","bdd7f312":"print(X_train_prepared.shape)\nprint(y_train.shape)","459b1eca":"cat_encoder = cat_pipeline.named_steps['encoder']\ncat_encoder.categories_[:10]","be4fb978":"cat_one_hot_attribs =[] \nfor cat in range(len(cat_encoder.categories_)):\n    cat_one_hot_attribs = cat_one_hot_attribs + list(cat_encoder.categories_[cat])","74636778":"attributes = list(num_attributes) + extra_attributes + cat_one_hot_attribs\nattributes","1d429b9a":"from sklearn.metrics import mean_squared_error","91558582":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_prepared, y_train)\ny_pred = lin_reg.predict(X_train_prepared)\nlin_mse = mean_squared_error(y_train, y_pred)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","c4922fbc":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(penalty=None, random_state=42, max_iter=1000, tol=1e-6)\nsgd_reg.fit(X_train_prepared, y_train)\ny_pred = sgd_reg.predict(X_train_prepared)\nsgd_mse = mean_squared_error(y_train, y_pred)\nsgd_rmse = np.sqrt(sgd_mse)\nsgd_rmse","2d1053d8":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(X_train_prepared, y_train)\ny_pred = tree_reg.predict(X_train_prepared)\ntree_mse = mean_squared_error(y_train, y_pred)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","4622c187":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(random_state=42, n_estimators=100)\nforest_reg.fit(X_train_prepared, y_train)\ny_pred = forest_reg.predict(X_train_prepared)\nforest_mse = mean_squared_error(y_train, y_pred)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","4241b4a9":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(X_train_prepared, y_train)\ny_pred = svm_reg.predict(X_train_prepared)\nsvm_mse = mean_squared_error(y_train, y_pred)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse","065a71be":"from sklearn.model_selection import cross_val_score\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","b45c2b09":"sgd_scores = cross_val_score(sgd_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=5)\nsgd_rmse_scores = np.sqrt(-sgd_scores)\ndisplay_scores(sgd_rmse_scores)","13f96842":"tree_scores = cross_val_score(tree_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=5)\ntree_rmse_scores = np.sqrt(-tree_scores)\ndisplay_scores(tree_rmse_scores)","604a943f":"forest_scores = cross_val_score(forest_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=5)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","2879c1e0":"svm_scores = cross_val_score(svm_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=5)\nsvm_rmse_scores = np.sqrt(-svm_scores)\ndisplay_scores(svm_rmse_scores)","5b313d57":"plt.figure(figsize=(8, 4))\nplt.plot([1]*5, np.sqrt(-tree_scores), \".\")\nplt.plot([2]*5, np.sqrt(-svm_scores), \".\")\nplt.plot([3]*5, np.sqrt(-forest_scores), \".\")\nplt.plot([4]*5, np.sqrt(-sgd_scores), \".\")\nplt.boxplot([np.sqrt(-tree_scores), np.sqrt(-svm_scores), np.sqrt(-forest_scores), np.sqrt(-sgd_scores)], labels=(\"Tree\",\"SVM\", 'Forest', 'SGD'))\nplt.ylabel(\"Mean Squared Error\", fontsize=14)\nplt.show()","9fc79a91":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [30, 50, 100],\n     'max_features': [30, 50, 100]},\n    {'bootstrap': [False],\n     'n_estimators': [30, 50, 100],\n     'max_features': [30, 50, 100]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\ngrid_search_forest = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search_forest.fit(X_train_prepared, y_train)","74512670":"grid_search_forest.best_params_","a6a304c4":"grid_search_forest.best_estimator_","fa89fc7f":"cvres = grid_search_forest.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","c1e43964":"param_grid = [\n        {'kernel': ['linear'], 'C': [0.1, 1.0, 10.]},\n        {'kernel': ['rbf'], 'C': [0.1, 1.0, 10.],\n         'gamma': [0.001, 0.01, 0.1]},\n    ]\n\nsvm_reg = SVR()\ngrid_search_svm = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=4)\ngrid_search_svm.fit(X_train_prepared, y_train)","339647f4":"grid_search_svm.best_params_","1b953439":"cvres = grid_search_svm.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","6120773b":"grid_search_svm.best_estimator_","fb3d5ce5":"feature_importances = grid_search_forest.best_estimator_.feature_importances_","ffd49528":"sorted(zip(feature_importances, attributes), reverse=True)","8008ba3d":"indices = np.argsort(feature_importances)[::-1]\n\nranking = pd.DataFrame({'features':[attributes[indices[f]] for f in range(len(attributes[:10]))],\n                        'values': [feature_importances[indices[f]] for f in range(len(attributes[:10]))]})\n\nranking","c6d99f2c":"plt.figure(figsize=(6, 6))\nsns.barplot(x='values', y='features', data=ranking, orient='h', color='mediumseagreen')\nplt.title('feature importances')\nplt.show()","d396d048":"final_model = grid_search_svm.best_estimator_\nfinal_model","6d3d9884":"X_test=test_data.copy()","9a147b2c":"X_test.info()","5a4d4a49":"X_test_prepared = preprocess_pipeline.transform(X_test)","8c7ef2d3":"y_pred = final_model.predict(X_test_prepared)\nprint(y_pred.shape)\ny_pred.ravel()","3b60e5dc":"test_data['SalePrice'] = np.exp(y_pred.ravel())\ntest_data[['Id','SalePrice']].head()","aa197c22":"test_data[['Id','SalePrice']].to_csv('submission.csv', index=False)","50b84bab":"# Table of Contents\n* [Setup](#setup)\n* [Get the Data](#get_data)\n* [Take a Quick Look at the Data Structure](#data_structure)\n* [Prepare Data for Machine Learning](#preparation)\n* [Select and Train a Model](#selection)\n* [Fine-tune the model](#tuning)\n* [Make Predictions](#predictions)","4e21e23e":"### Handling Numerical Attributes","6f4151ed":"### Missing Data","df67a238":"<a id=\"tuning\"><\/a>\n# Fine-tune the model","052bd6c4":"### Grid Search","5b0565c6":"<a id=\"predictions\"><\/a>\n# Make Predictions","ac8e79fe":"### Transformation Pipelines","75b0563e":"<a id=\"selection\"><\/a>\n# Select and Train a Model","ad39cc49":"<a id=\"setup\"><\/a>\n# Setup","8f18f449":"<a id=\"data_structure\"><\/a>\n# Take a Quick Look at the Data Structure","f87a73a5":"### Feature Importances","95fed199":"### Handling Categorical Attributes","edc7baa1":"<h1 align=center><font size = 4>Housing Sales Prediction<\/font><\/h1>\n<h1 align=center><font size = 5>Regression Modelling<\/font><\/h1>","4442209b":"<a id=\"get_data\"><\/a>\n# Get the Data","07f9251d":"The attributes with more than 15% missing data will be removed","2fb3a226":"### Categorical Attributes","7d66bce2":"<a id=\"preparation\"><\/a>\n# Prepare Data for Machine Learning","31701b7a":"### Correlation Matrix","a96640c5":"### Numerical Attributes"}}