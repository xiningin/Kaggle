{"cell_type":{"43b75359":"code","e0d0c80b":"code","5a6812f7":"code","d0987a04":"code","c9159af4":"code","b84ae623":"code","186451ca":"code","5ae47dc7":"code","b035e24f":"code","9cf18a39":"code","23083759":"code","0af750d3":"code","59a4a0e0":"code","76a59c71":"code","9bd2b6d4":"code","7fee44f1":"markdown","d61b8d00":"markdown","e591bb80":"markdown","e2a295d6":"markdown","aae636a6":"markdown","60557696":"markdown","981ee506":"markdown","eb1e0cac":"markdown","81cd42c8":"markdown","13ebe591":"markdown","32a3b701":"markdown","b73403ca":"markdown","da11edbb":"markdown","e36a76e4":"markdown"},"source":{"43b75359":"import os, cv2, random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm    #Helps in visualization\nfrom random import shuffle #to shuffle the images \n\n%matplotlib inline \n\nTRAIN_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/'\nTEST_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test\/'\nIMG_SIZE = 224\n\nSHORT_LIST_TRAIN = os.listdir(TRAIN_DIR)[0:10000] #using a subset of data as resouces as limited. \nSHORT_LIST_TEST = os.listdir(TEST_DIR)","e0d0c80b":"def label_img(img): \n    word_label = img.split('.')[-3]\n    # conversion to one-hot array [cat,dog]\n    #                            [much cat, no dog]\n    if word_label == 'cat': return [1,0]\n    #                             [no cat, very doggo]\n    elif word_label == 'dog': return [0,1]","5a6812f7":"#returns an numpy array of train and test data\ndef create_train_data():\n    training_data = []\n    for img in tqdm(SHORT_LIST_TRAIN):\n        label = label_img(img)\n        path = os.path.join(TRAIN_DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),np.array(label)])\n    shuffle(training_data)\n    return training_data\n\ndef process_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(TEST_DIR)):\n        path = os.path.join(TEST_DIR,img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img), img_num])\n    shuffle(testing_data)\n    return testing_data","d0987a04":"\nlabels = []\nfor i in SHORT_LIST_TRAIN:\n    if 'dog' in i:\n        labels.append(1)\n    else:\n        labels.append(0)\n\nsns.countplot(labels)\nplt.title('Cats and Dogs')","c9159af4":"train = create_train_data()","b84ae623":"X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY = np.array([i[1] for i in train])","186451ca":"from tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nNUM_CLASSES = 2\nRESNET_WEIGHTS_PATH = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5' #importing a pretrained model\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='max', weights=RESNET_WEIGHTS_PATH))\nmy_new_model.add(Dense(NUM_CLASSES, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = True","5ae47dc7":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","b035e24f":"my_new_model.summary()","9cf18a39":"history = my_new_model.fit(X, Y, validation_split=0.20, epochs=4, batch_size=64)","23083759":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","0af750d3":"\nSHORT_LIST_TRAIN = os.listdir(TRAIN_DIR)[-5000:]\ntrain = create_train_data()\nX = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY = np.array([i[1] for i in train])\nhistory = my_new_model.fit(X, Y, validation_split=0.5, epochs=20, batch_size=64)\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","59a4a0e0":"import matplotlib.pyplot as plt\n\n# if you need to create the data:\ntest_data = process_test_data()\n# if you already have some saved:\n#test_data = np.load('test_data.npy')\n\nfig=plt.figure()\n\nfor num,data in enumerate(test_data[:12]):\n    # cat: [1,0]\n    # dog: [0,1]\n    \n    img_num = data[1]\n    img_data = data[0]\n    \n    y = fig.add_subplot(3,4,num+1)\n    orig = img_data\n    data = img_data.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n    #model_out = model.predict([data])[0]\n    model_out = my_new_model.predict([data])[0]\n    \n    if np.argmax(model_out) == 1: str_label='Dog'\n    else: str_label='Cat'\n        \n    y.imshow(orig)\n    plt.title(str_label)\n    y.axes.get_xaxis().set_visible(False)\n    y.axes.get_yaxis().set_visible(False)\nplt.show()","76a59c71":"prob = []\nimg_list = []\nfor data in tqdm(test_data):\n        img_num = data[1]\n        img_data = data[0]\n        orig = img_data\n        data = img_data.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n        model_out = my_new_model.predict([data])[0]\n        img_list.append(img_num)\n        prob.append(model_out[1])","9bd2b6d4":"submission = pd.DataFrame({'id':img_list , 'label':prob})\nprint(submission.head())\nsubmission.to_csv(\"..\/working\/submit.csv\", index=False)","7fee44f1":"## Model Sumary##","d61b8d00":"## Sources\n1. https:\/\/machinelearningmastery.com\/transfer-learning-for-deep-learning\/ <br\/>\n2. http:\/\/cs231n.github.io\/transfer-learning\/ <br\/>\n3. https:\/\/arxiv.org\/abs\/1411.1792 <br\/>\nIf you are Interested in Research.\n\n\n","e591bb80":"## From Train Dividing X and Y##","e2a295d6":"## Transfer learning\nIt is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task. \n\n<img src=\"https:\/\/elearningindustry.com\/wp-content\/uploads\/2016\/09\/5-tips-improve-knowledge-transfer-elearning-e1475138920743.jpeg\" width=\"400px\"\/>\n\nThe above image exactly represets what the model does for you.\nIt remembers the learning from a fairly related problem and applies it to the problem having new data.\n\n\nPre-trained Model Approach :-\n\n   1.  Select Source Model. A pre-trained source model is chosen from available models. Many research institutions release models on large and challenging datasets that may be included in the pool of candidate models from which to choose from.\n   <br\/><br\/>\n   2.  Reuse Model. The model pre-trained model can then be used as the starting point for a model on the second task of interest. This may involve using all or parts of the model, depending on the modeling technique used.  \n   <br\/>\n   3.  Tune Model. Optionally, the model may need to be adapted or refined on the input-output pair data available for the task of interest.\n   <br\/>\n![](http:\/\/https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2017\/09\/Three-ways-in-which-transfer-might-improve-learning.png)    \n\nPre-trained Models <br\/>\n<a href=\"https:\/\/github.com\/KaimingHe\/deep-residual-networks\">Microsoft ResNet Model<\/a> <br\/>\n<a href=\"https:\/\/github.com\/tensorflow\/models\/tree\/master\/inception\">Google Inception Model<\/a> <br\/>\n<a href=\"https:\/\/github.com\/BVLC\/caffe\/wiki\/Model-Zoo\">Caffe Model Zoo<\/a>\n\n","aae636a6":"## Fit Model##","60557696":"## Creating a Training Set Data##","981ee506":"Please upvote this kernel so that it reaches the top of the chart and is easily locatable by new users. Your comments on how we can improve this kernel is welcome. Thanks You For your Support.","eb1e0cac":"## Visualizing Classes ##\nVisulization is important to compare differnet classes and their number of occurances.","81cd42c8":"## Plotting loss and accuracy for the model##","13ebe591":"## Compile Model##","32a3b701":"## Specify Model##","b73403ca":"## This Notebook Introduces How to apply 'Transfer Learning' in Kaggle\n\nThank you for opening this Notebook!\n\nPress \"Fork\" at the top-right of this screen to run this notebook yourself and build each of the examples.\n\nI have made all efforts to document each and every step involved so that this notebook acts as a good starting point for new Kagglers who hope to apply **Transfer Learning** to their problem.","da11edbb":"## Libraries and settings ##\nImporting the Required libraries and assignment of few constants(such as Directories)","e36a76e4":"## Testing Model on the Test Data##"}}