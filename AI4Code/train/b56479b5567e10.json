{"cell_type":{"4dda8840":"code","cb902e72":"code","3b41cd67":"code","ce686345":"code","f701143c":"code","a72c8406":"code","4fdb45dd":"code","e438cb6b":"code","7ce65a46":"code","df1c92f9":"code","a5ef8bd2":"code","5208c7a2":"code","a52f84be":"code","50e009e7":"code","a37653ac":"code","594eb1d9":"code","c401f450":"code","0767ab62":"code","1f8ea645":"code","b68c6497":"code","3d43f034":"code","f01c2e3f":"code","60b928ca":"code","2e722791":"code","e4eef6c0":"code","174b9f55":"code","00dc2a88":"code","6654c4fb":"code","7a2b96d5":"code","28186ee3":"code","d603a981":"code","bacadbb2":"code","7c29fd71":"code","f62218e7":"code","b7a16831":"code","c6c6b96a":"code","a2ef9d3b":"code","70528a53":"code","884e7dbb":"code","c01ad051":"code","84c58260":"code","403204cf":"code","79eda7cb":"code","02bc204e":"code","53d3928f":"code","78235090":"code","9a652c32":"markdown","cd28ca3f":"markdown","01f9fcb9":"markdown","bada37c4":"markdown","156c2b35":"markdown","9482a659":"markdown","995e51d1":"markdown"},"source":{"4dda8840":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb902e72":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree,svm\nfrom sklearn.metrics import accuracy_score","3b41cd67":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')","ce686345":"print(train_data)","f701143c":"train_data.head()","a72c8406":"train_data.info()","4fdb45dd":"print(train_data.shape)","e438cb6b":"train_data.isna().sum()","7ce65a46":"heatmap = sns.heatmap(train_data[[\"Survived\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]].corr(), annot=True)  # corr stands for correlation\nsns.set(rc={'figure.figsize':(8,6)})              # & annot labelized the cell","df1c92f9":"train_data['SibSp'].unique()","a5ef8bd2":"bargraph_sibsp = sns.catplot(x=\"SibSp\", y=\"Survived\", data=train_data, kind=\"bar\", height=8)","5208c7a2":"ageplot = sns.FacetGrid(train_data, col=\"Survived\", height=7)\nageplot = ageplot.map(sns.distplot, \"Age\")\nageplot = ageplot.set_ylabels(\"Survival Probability\")","a52f84be":"sexplot = sns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","50e009e7":"pclassplot = sns.catplot(x=\"Pclass\", y=\"Survived\", data = train_data, kind=\"bar\", height=6)","a37653ac":"a = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data, height=7, kind=\"bar\")","594eb1d9":"train_data[\"Embarked\"].isna().sum()","c401f450":"train_data[\"Embarked\"].value_counts()","0767ab62":"# Filling 2 missing value with most frequent value\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')","1f8ea645":"sns.catplot(x=\"Embarked\", y=\"Survived\", data=train_data, height=5, kind=\"bar\")","b68c6497":"sns.catplot(x=\"Pclass\", col=\"Embarked\", data=train_data, kind=\"count\", height=7)","3d43f034":"train_data.isna().sum()","f01c2e3f":"print(train_data[\"Age\"].mean())\nprint(train_data[\"Age\"].median())","60b928ca":"x = train_data.iloc[:,:]","2e722791":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\nx[[\"Age\"]] = imputer.fit_transform(x[[\"Age\"]])","e4eef6c0":"train_data.isna().sum()","174b9f55":"col_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\ndrop_col = train_data.drop(col_to_drop, axis=1)\ndrop_col.head(10)","00dc2a88":"genders = {\"male\":0, \"female\":1}\ndrop_col[\"Sex\"] = drop_col[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ndrop_col[\"Embarked\"] = drop_col[\"Embarked\"].map(ports)\n\ndrop_col.head()","6654c4fb":"df_train_x = drop_col[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n\n# Target variable column\ndf_train_y = drop_col[['Survived']]\n\nx_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.2, random_state=43)","7a2b96d5":"regressor = LogisticRegression()\nregressor.fit(x_train, y_train)\ny_pred = regressor.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred) * 100\nprint(\"accuracy=\",accuracy)","28186ee3":"classifier = RandomForestClassifier()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\naccuracy1 = accuracy_score(y_test, y_pred) * 100\nprint(\"accuracy=\",accuracy1)","d603a981":"classifier1 = KNeighborsClassifier()\nclassifier1.fit(x_train, y_train)\ny_pred = classifier1.predict(x_test)\naccuracy2 = accuracy_score(y_test, y_pred) * 100\nprint(\"accuracy=\",accuracy2)","bacadbb2":"classifier2 = tree.DecisionTreeClassifier()\nclassifier2.fit(x_train, y_train)\ny_pred = classifier2.predict(x_test)\naccuracy3 = accuracy_score(y_test, y_pred) * 100\nprint(\"accuracy=\",accuracy3)","7c29fd71":"classifier3 = svm.SVC()\nclassifier3.fit(x_train, y_train)\ny_pred = classifier3.predict(x_test)\naccuracy4 = accuracy_score(y_test, y_pred) * 100\nprint(\"accuracy=\",accuracy4)","f62218e7":"print(\"Accuracy of Logistic Regressor =\", accuracy)\nprint(\"Accuracy of Random Forest Classifier =\", accuracy1)\nprint(\"Accuracy of K-Neighbor Classifier =\", accuracy2)\nprint(\"Accuracy of Decision Tree Classifier = \", accuracy3)\nprint(\"Accuracy of Support Vector Machine Classifier = \", accuracy4)","b7a16831":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')","c6c6b96a":"test_data.head()","a2ef9d3b":"test_data.info()","70528a53":"test_data.isnull().sum()","884e7dbb":"print(test_data[\"Age\"].mean())\nprint(test_data[\"Age\"].median())","c01ad051":"X = test_data.iloc[:,:]","84c58260":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\nX[[\"Age\", \"Fare\"]] = imputer.fit_transform(X[[\"Age\", \"Fare\"]])","403204cf":"test_data.isnull().sum()","79eda7cb":"col_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\ndrop_col_test = test_data.drop(col_to_drop, axis=1)\ndrop_col_test.head()","02bc204e":"genders = {\"male\":0, \"female\":1}\ndrop_col_test[\"Sex\"] = drop_col_test[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ndrop_col_test[\"Embarked\"] = drop_col_test[\"Embarked\"].map(ports)\n\ndrop_col_test.head()","53d3928f":"x_test = drop_col_test\ny_pred = classifier.predict(x_test)\noriginaltest_data = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n    \"PassengerId\": originaltest_data[\"PassengerId\"],\n    \"Survived\": y_pred\n})\nsubmission.head(15)","78235090":"submission.to_csv('.\/FianalSubmission.csv', index=False)","9a652c32":"# Support Vector Machine","cd28ca3f":"# K-Neighbor Classifier","01f9fcb9":"# Random Forest Classifier ","bada37c4":"# Logistic Regression","156c2b35":"# Final Submission","9482a659":"# **Making Prediction for Test.csv**","995e51d1":"# Decision Tree Classifier"}}