{"cell_type":{"0044dd14":"code","b7d52081":"code","a80be1a1":"code","87d21835":"code","4250a76c":"code","54feb21d":"code","aa9cfb6d":"code","441189b6":"code","ffb5616d":"code","0d54518a":"code","cb3c0607":"code","f7fafe1e":"code","9f332527":"code","a4ac4a95":"code","45d4bb83":"code","e23b3b06":"code","fb359956":"code","4cf3fa22":"code","5dfd6045":"code","17a6e6b2":"code","45dfe98b":"code","d1c7c0c5":"code","70d2b180":"code","6fb33e2d":"code","17084c90":"code","39019f6a":"code","a2545880":"code","2686a313":"code","ec6bae27":"code","c19c4a15":"code","38c43182":"code","ff1fabfc":"code","753bb6bb":"code","2e37c84b":"markdown","40d38a1c":"markdown","9d17f890":"markdown","1f3c3d43":"markdown","28f9e479":"markdown","30bfa36f":"markdown","8dcaa4bf":"markdown","0a03b583":"markdown","7d359240":"markdown","9bc93c25":"markdown","305cf6ae":"markdown"},"source":{"0044dd14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b7d52081":"import csv\ntrain_data = []\nwith open(\"\/kaggle\/input\/digit-recognizer\/train.csv\",\"r\") as f:\n    csvreader = csv.reader(f)\n    for line in csvreader:\n        train_data.append(line)","a80be1a1":"print(len(train))","87d21835":"print(train[0])","4250a76c":"print(train[0][:10])","54feb21d":"print(train[0][-1])","aa9cfb6d":"import numpy as np\nimg = np.array(train[1][1:], dtype=np.uint8)","441189b6":"img = img.reshape(28,28)","ffb5616d":"import matplotlib.pyplot as plt\nplt.imshow(img)","0d54518a":"#import pytorch\nimport torch\nimport torch.nn as nn","cb3c0607":"# This is the class (i.e. the blueprint) for our neural network\n# ANN stands for Artifical Neural Network\n\nclass ANNModel(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ANNModel, self).__init__()\n        # Linear function 1: 784 --> 100\n        self.fc1 = nn.Linear(input_dim, hidden_dim) \n        # Non-linearity 1\n        self.sig1 = nn.Sigmoid()\n        \n        # Linear function 2 (readout): 100 --> 10\n        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n    \n    def forward(self, x):\n        # Linear function 1\n        out = self.fc1(x)\n        # Non-linearity 1\n        out = self.sig1(out)\n        \n        # Linear function 2 (readout)\n        out = self.fc2(out)\n        return out","f7fafe1e":"# instantiate ANN\ninput_dim = 28*28\nhidden_dim = 150 #hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason.\noutput_dim = 10\n\n# Create ANN object from our class\nmodel = ANNModel(input_dim, hidden_dim, output_dim)\n\n# Cross Entropy Loss -> this is how we calculate the error in our ANN's predictions\nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","9f332527":"train_features = [line[1:] for line in train[1:]]\ntrain_features = np.array(train_features, dtype=np.float64)\/255.0","a4ac4a95":"train_target = [line[0]  for line in train[1:]]\ntrain_target = np.array(train_target, dtype=np.int16)","45d4bb83":"train_features_tensor = torch.from_numpy(train_features).float()\ntrain_target_tensor = torch.from_numpy(train_target).long()","e23b3b06":"train_dataset = torch.utils.data.TensorDataset(\n    train_features_tensor, \n    train_target_tensor\n)\nbatch_size = 64\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, \n    batch_size = batch_size, \n    shuffle = True\n)","fb359956":"from torch.autograd import Variable\n\n# How many times to go through the entire dataset\nnum_epochs = 2\n\n# ANN model training\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n\n        train = Variable(images.view(-1, 28*28))\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and cross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n","4cf3fa22":"for images, labels in train_loader:\n    test = Variable(images.view(-1, 28*28))\n    \n    # Forward propagation\n    outputs = model(test)\n\n    # Get predictions from the maximum value\n    predicted = torch.max(outputs.data, 1)[1]\n\n    # Total number of labels\n    total = len(labels)\n\n    # Total correct predictions\n    correct = (predicted == labels).sum()\n    break\n\naccuracy = 100 * correct \/ float(total)\nprint(accuracy)","5dfd6045":"test = []\nwith open(\"\/kaggle\/input\/digit-recognizer\/test.csv\",\"r\") as f:\n    csvreader = csv.reader(f)\n    for line in csvreader:\n        test.append(line)","17a6e6b2":"test[0][:10]","45dfe98b":"test_features = test[1:]\ntest_features = np.array(test_features, dtype=np.float64)\/255.0\n\ntest_features_tensor = torch.from_numpy(test_features).float()\nfake_labels = torch.from_numpy(np.random.randint(0,1, (test_features_tensor.shape[0], ) ))\n\n\ntest_dataset = torch.utils.data.TensorDataset(\n    test_features_tensor,\n    fake_labels\n)\n\nbatch_size = 64\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, \n    batch_size = batch_size, \n    shuffle = False\n)","d1c7c0c5":"# TO DO: generate predictions\nall_predictions = []\nfor images, fake_labels in test_loader:\n    test_imgs = Variable(images.view(-1, 28*28))\n    \n    # Forward propagation\n    outputs = model(test_imgs)\n\n    # Get predictions from the maximum value\n    predicted = torch.max(outputs.data, 1)[1]\n#     print(predicted)\n    all_predictions += predicted\nprint(len(all_predictions))","70d2b180":"# TO DO: save predictions to CSV file\nwith open(\"submission.csv\", \"w\") as f:\n    f.write(\"ImageId,Label\\n\")\n    for i, prediction in enumerate(all_predictions):\n        line = f\"{i+1},{prediction}\\n\"\n        f.write(line)","6fb33e2d":"import torch.nn.functional as F\n\nclass cnn(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        # 28x28x1 -> 28x28x4\n        self.cl1 = nn.Conv2d(1, 4, (3,3), padding=1)\n        # 28x28x4 -> 14x14x4\n        self.mp1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n        # 14x14x4 -> 14x14x8\n        self.cl2 = nn.Conv2d(4, 8, (3,3), padding=1)\n        # 14x14x8 -> 7x7x8\n        self.mp2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n        self.lin = nn.Linear(7*7*8, num_classes)\n    \n    def forward(self, x):\n        out = F.relu(self.cl1(x))\n        out = self.mp1(out)\n        out = F.relu(self.cl2(out))\n        out = self.mp2(out)\n        out = self.lin(out.view(-1, 7*7*8))\n        return out","17084c90":"model = cnn(num_classes = 10)","39019f6a":"import csv\ntrain_data = []\nwith open(\"\/kaggle\/input\/digit-recognizer\/train.csv\",\"r\") as f:\n    csvreader = csv.reader(f)\n    for line in csvreader:\n        train_data.append(line)","a2545880":"\n\ntrain_features = [line[1:] for line in train_data[1:]]\ntrain_features = np.array(train_features, dtype=np.float64)\/255.0\n\ntrain_features = train_features.reshape(42000, 1, 28,28)\n\ntrain_target = [line[0]  for line in train_data[1:]]\ntrain_target = np.array(train_target, dtype=np.int16)\n\ntrain_features_tensor = torch.from_numpy(train_features).float()\ntrain_target_tensor = torch.from_numpy(train_target).long()\n\ntrain_dataset = torch.utils.data.TensorDataset(\n    train_features_tensor, \n    train_target_tensor\n)\nbatch_size = 64\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, \n    batch_size = batch_size, \n    shuffle = True\n)","2686a313":"for img, labs in train_loader:\n    print(img.shape)\n    break","ec6bae27":"error = nn.CrossEntropyLoss()\n\n# SGD Optimizer\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","c19c4a15":"from torch.autograd import Variable\n\n# How many times to go through the entire dataset\nnum_epochs = 2\n\n# ANN model training\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n\n        train = Variable(images)\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and cross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n","38c43182":"test = []\nwith open(\"\/kaggle\/input\/digit-recognizer\/test.csv\",\"r\") as f:\n    csvreader = csv.reader(f)\n    for line in csvreader:\n        test.append(line)\n\ntest_features = test[1:]\ntest_features = np.array(test_features, dtype=np.float64)\/255.0\n\ntest_features = test_features.reshape(len(test)-1, 1, 28,28)\n\ntest_features_tensor = torch.from_numpy(test_features).float()\nfake_labels = torch.from_numpy(np.random.randint(0,1, (test_features_tensor.shape[0], ) ))\n\n\ntest_dataset = torch.utils.data.TensorDataset(\n    test_features_tensor,\n    fake_labels\n)\n\nbatch_size = 64\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, \n    batch_size = batch_size, \n    shuffle = False\n)","ff1fabfc":"# TO DO: generate predictions\nall_predictions = []\nfor images, fake_labels in test_loader:\n    test_imgs = Variable(images)\n    \n    # Forward propagation\n    outputs = model(test_imgs)\n\n    # Get predictions from the maximum value\n    predicted = torch.max(outputs.data, 1)[1]\n#     print(predicted)\n    all_predictions += predicted\nprint(len(all_predictions))","753bb6bb":"with open(\"submission.csv\", \"w\") as f:\n    f.write(\"ImageId,Label\\n\")\n    for i, prediction in enumerate(all_predictions):\n        line = f\"{i+1},{prediction}\\n\"\n        f.write(line)","2e37c84b":"# Train the network","40d38a1c":"# Test the network\nAlthough we are measuring the network on the training data set, we really want to measure its accuracy on the test set (to do so, we need to create a test set DataLoader, make predictions, and upload them to Kaggle - see below!).","9d17f890":"# CNN Code","1f3c3d43":"# Create a blueprint for a Neural Network using the PyTorch library\n\nIn Python, these \"blueprints\" are called classes. Later we will create an actual instance of the class: this is called an object.","28f9e479":"# Read in the Training Data\n\nEach image in the MNIST dataset is stored as a row in a CSV file. We can use Python's `csvreader` module to easily ready these files.","30bfa36f":"# Create an instance of our network","8dcaa4bf":"# Examine one of the images\nEvery pixel in an image is a number.","0a03b583":"# Create \"DataLoaders\"\nThese are needed by PyTorch - they are how the network loads a batch of images to train on.","7d359240":"Note that there is no label column is the test.csv file (unlike the train.csv file):","9bc93c25":"# Taking it further\n* In this code, we have only trained the neural network for 2 epochs (i.e. we have only gone through the dataset 2 times). What happens if you increase the number of epochs?\n* Try altering the ANNModel class. Can you add in another layer? Remember, you will have to include it in both the __init__() method and the forward() method.","305cf6ae":"# Make predictions\nHere we create a Dataloader for the test data (where we don't know the actual number for each image), and create a submission.csv file."}}