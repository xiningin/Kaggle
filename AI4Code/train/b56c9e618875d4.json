{"cell_type":{"acd5a42c":"code","dc1e2fb1":"code","0fdc7c88":"code","288ac51a":"code","7fef7095":"code","6ec7e867":"code","ddcbd3cf":"code","6878d486":"code","b08d35e2":"code","c7b29065":"code","61865ee1":"code","2b664fef":"code","9d9e7617":"code","f684b2ed":"code","e472ae02":"code","d0d247de":"code","a704876d":"code","7df1626c":"code","b538687a":"code","17c69f79":"code","80dc02cf":"code","d6ec37a1":"code","f93f9f50":"code","80a24e54":"code","644c1388":"code","b5735ffe":"code","176acaaa":"code","3dd4eaa9":"code","a3ecb16e":"code","a9a31e1d":"code","963eac78":"code","bfd40fe7":"code","0cd70f8a":"code","eb7bb1d3":"code","5370f5ef":"code","507f1ba4":"code","d3087682":"code","57d7213d":"code","529f013a":"code","3fcbf59a":"code","118d0d66":"code","33be5a94":"code","e91ad2dc":"code","d1ef62f8":"code","af8b5ec9":"code","cbd95c5d":"code","e0cf7370":"code","a96363dc":"code","a94d352d":"code","386dd333":"code","8e6b42ee":"code","4d7302a5":"code","097d81c1":"code","5fdf6311":"code","cced299c":"code","e9787786":"code","c1f6efb4":"code","238a4b6d":"code","c07a783b":"code","97ec4f7d":"code","342e07c6":"code","7aec3d07":"code","a54ddc95":"code","d3e0714f":"code","9cec600f":"code","41c7aa50":"code","557dccf6":"code","682ac1b9":"code","51760dac":"code","1ef4d68a":"code","48572f85":"code","386a49e4":"code","62998862":"code","9856fd00":"code","64d82eb1":"code","b5edf0b1":"code","b52ca5bb":"code","062c1ec5":"code","72ebec16":"code","1d376762":"code","b608b8e3":"code","2ac09c57":"code","dcd21c5c":"code","40ace4f4":"code","bd768cf2":"code","45cc3734":"code","39b415b5":"code","1da3c38b":"code","847fa2ff":"code","8b3b97e4":"code","80db17a6":"code","b6a9f1ab":"code","484e191d":"code","c2e256a4":"code","12e0bf2c":"code","50c46c14":"code","9ea07c1b":"code","5512f30d":"code","37b4173f":"code","b36ae689":"code","17b7ae30":"code","95b8ff0c":"code","e05f1137":"code","eb3988cc":"code","b9a6c03d":"code","d8074a4a":"code","04b7f492":"code","10844c97":"code","79dbd4d4":"code","bb82ca6d":"code","aea799ec":"code","615b9f36":"code","c8ba9aa8":"code","77c0fcfd":"code","7d4e65ea":"code","6d07fe67":"code","dbde6162":"code","06a46295":"code","3fc0c8f9":"code","8d468399":"code","b3428652":"code","34408fd9":"code","39021a9f":"code","e037d4ef":"code","66239f03":"markdown","893ffc93":"markdown","99db2388":"markdown","241f5cc9":"markdown","b583e17a":"markdown","8645d8e6":"markdown","ecc2a462":"markdown","0b06f8d8":"markdown","a4c88a9b":"markdown","32e10af8":"markdown","2a3637a6":"markdown","8b32293a":"markdown","bae2792e":"markdown","987548ff":"markdown","62534105":"markdown","5198a1d2":"markdown","b6993ce8":"markdown","5c88cfff":"markdown","93adc667":"markdown","e5d5c299":"markdown","a71f8952":"markdown","5f19657f":"markdown","3a9654e1":"markdown","ec5d5a0d":"markdown","b09c9754":"markdown","128ad672":"markdown","0896ff00":"markdown","b6642257":"markdown","1c6e2e2d":"markdown","10a65059":"markdown","2961e60d":"markdown","ebf365b6":"markdown","f3493796":"markdown","5dcc422f":"markdown","7516de2d":"markdown","6053bc93":"markdown","687ccd94":"markdown","22df4720":"markdown","c01dcfff":"markdown","79c314cb":"markdown","9a9ab4f5":"markdown","b644504d":"markdown","531764e2":"markdown","2fab0487":"markdown","1b6df365":"markdown","5de64857":"markdown","d97f118f":"markdown","a8e52e71":"markdown","493cdd63":"markdown","8d1f541d":"markdown","387d4daa":"markdown","ad3a0e9e":"markdown","09bf4cc5":"markdown","bb675a8b":"markdown","373ecdcb":"markdown","b285cc43":"markdown","cbbe1e52":"markdown","deac5ae2":"markdown","ea6b337e":"markdown","cbf8fe8d":"markdown","967c3298":"markdown","07d8fa5c":"markdown","cfb7743a":"markdown","f878bb49":"markdown","a8d05a5c":"markdown","a31f4f85":"markdown","2f2be9ed":"markdown","27cc6a31":"markdown","84970dff":"markdown","362b650a":"markdown","f0ce4192":"markdown","d7700059":"markdown","63d3e390":"markdown","13caf6f6":"markdown","92d54274":"markdown","dba12d3a":"markdown","f650934f":"markdown","57d5d8bd":"markdown","df407718":"markdown","c5cffd65":"markdown"},"source":{"acd5a42c":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datetime import date\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nplt.style.use('seaborn')\n\nfrom collections import Counter\nimport datetime\nimport wordcloud\nimport json","dc1e2fb1":"df = pd.read_csv('..\/input\/startup-success-prediction\/startup data.csv')","0fdc7c88":"df.head(10)","288ac51a":"df.info()","7fef7095":"df.columns","6ec7e867":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df.select_dtypes(include=numeric)\ndf_num.head(3)","ddcbd3cf":"df_cat=df.select_dtypes(include='object')\ndf_cat.head(3)","6878d486":"df['status'] = df.status.map({'acquired':1, 'closed':0})","b08d35e2":"#Tipe data status diganti dari object ke int\ndf['status'].astype(int)","c7b29065":"#labels dan status check similarity\nfor index, row in df.iterrows():\n    if row['labels']!=row['status']:\n        print(index, row['labels'], row['status'])","61865ee1":"#drop feature\ndf.drop([\"labels\"], axis=1, inplace=True)","2b664fef":"describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","9d9e7617":"describeNumCat = df.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","f684b2ed":"cats = ['state_code','zip_code','id','city','Unnamed: 6','name','founded_at','closed_at','first_funding_at','last_funding_at','state_code.1','category_code','object_id','status'] \nfor col in cats:\n    print(f'''Value count kolom {col}:''')\n    print(df[col].value_counts())\n    print()","e472ae02":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()\/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","d0d247de":"# Checking Missing Values Column \ndf[[\"Unnamed: 6\", \"closed_at\", \"age_first_milestone_year\", \"age_last_milestone_year\", \"state_code.1\", \"status\"]].head(4)","a704876d":"df['Unnamed: 6'] = df.apply(lambda row: (row.city) + \" \" + (row.state_code) + \" \" +(row.zip_code)  , axis = 1)\ndf.head()","7df1626c":"# Total Missing Values kolom \"Unnamed: 6\"\ntotalNull = df['Unnamed: 6'].isnull().sum()\n\nprint('Total Missing Values Kolom \"Unnamed: 6\": ', totalNull)","b538687a":"df['closed_at'] = df['closed_at'].fillna(value=\"31\/12\/2013\")","17c69f79":"totalNull = df['closed_at'].isnull().sum()\n\nprint('Total Missing Values Kolom \"closed_at\": ', totalNull)","80dc02cf":"df[['age_first_milestone_year','age_last_milestone_year','milestones']].head()","d6ec37a1":"df['age_first_milestone_year'] = df['age_first_milestone_year'].fillna(value=\"0\")\ndf['age_last_milestone_year'] = df['age_last_milestone_year'].fillna(value=\"0\")","f93f9f50":"for index, row in df.iterrows():\n    if row['state_code']!=row['state_code.1']:\n        print(index, row['state_code'], row['state_code.1'])","80a24e54":"df.drop([\"state_code.1\"], axis=1, inplace=True)","644c1388":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()\/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","b5735ffe":"df.corr()","176acaaa":"df['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","3dd4eaa9":"features = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','is_CA','is_NY','is_MA','is_TX','is_otherstate','is_software','is_web','is_mobile','is_enterprise','is_advertising','is_gamesvideo','is_ecommerce','is_biotech','is_consulting','is_othercategory','has_VC','has_angel','has_roundA','has_roundB','has_roundC','has_roundD','avg_participants','is_top500','status']\n\nplt.figure(figsize=(30,20))\nax = sns.heatmap(data = df[features].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","a3ecb16e":"#number of variables for heatmap\ncols = df[features].corr().nlargest(10,'status')['status'].index\ncm = np.corrcoef(df[cols].values.T) \nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, cmap='YlGnBu', fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","a9a31e1d":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_funding_year'], y=df['age_last_funding_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"age_first_funding_year\", ylabel=\"age_last_funding_year\")","963eac78":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_milestone_year'], y=df['age_last_milestone_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"status\", ylabel=\"milestones\")","bfd40fe7":"featuresNum = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','avg_participants']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNum)):\n    plt.subplot(1, len(featuresNum), i+1)\n    sns.boxplot(y=df[featuresNum[i]], color='green', orient='v')\n    plt.tight_layout()","0cd70f8a":"cdf = df[\"founded_at\"].apply(lambda x: '' + x[:2]).value_counts() \\\n            .to_frame().reset_index() \\\n            .rename(columns={\"index\": \"year\", \"founded_at\": \"No_of_startup\"})\n\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"year\", y=\"No_of_startup\", data=cdf, \n                palette=sns.color_palette(['#003f5c', '#ffa600'], n_colors=7), ax=ax)\n_ = ax.set(xlabel=\"Year\", ylabel=\"No. of startup\")","eb7bb1d3":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=False)","5370f5ef":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","507f1ba4":"df[\"closed_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","d3087682":"df_acquired = df[(df[\"status\"] == True)]\ndf_acquired.shape","57d7213d":"df_closed = df[(df[\"status\"] == False)]\ndf_closed.shape","529f013a":"value_counts = df[\"status\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie(x=[value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Startup Acquired')","3fcbf59a":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"category_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.category_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","118d0d66":"data1 = df[df['status']==1].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata1.columns=['category_code','total_success']\n\ndata2 = df[df['status']==0].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata2.columns=['category_code','total_closed']\n\ndata3=df.groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata3.columns=['category_code','total_startup']\n\ndata1= data1.merge(data2, on='category_code')\ndata1= data1.merge(data3, on='category_code')\n\ndata1['success_rate']= round((data1['total_success'] \/ data1['total_startup']) * 100,2)\n\nmost_succes_rate = data1.sort_values('success_rate', ascending=False)\nmost_succes_rate","33be5a94":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"category_code\", y=\"success_rate\", data=most_succes_rate,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Success Rate of Start Up\")","e91ad2dc":"funding_sorted_category = pd.pivot_table(df,\n              index=['category_code'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_category.columns = ['category_code', 'funding_total_usd']\nfunding_sorted_category = funding_sorted_category.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_category.head(10)","d1ef62f8":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category_code\", y=\"funding_total_usd\", data=funding_sorted_category,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Funding USD\")","af8b5ec9":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"state_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.state_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"state_code\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","cbd95c5d":"trending_statea = df.groupby(['state_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea","e0cf7370":"trending_statea = df_acquired.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea.head(10)","a96363dc":"trending_statec = df_closed.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statec = trending_statec[trending_statec.groupby('state_code')['num_startup'].transform(max) == trending_statec['num_startup']]\nmost_trending_statec = most_trending_statec.sort_values('num_startup', ascending=False)\nmost_trending_statec","a94d352d":"trending_categorya = df_acquired.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categorya = trending_categorya[trending_categorya.groupby('city')['num_startup'].transform(max) == trending_categorya['num_startup']]\nmost_trending_categorya = most_trending_categorya.sort_values('num_startup', ascending=False)\nmost_trending_categorya","386dd333":"trending_categoryc = df_closed.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categoryc = trending_categoryc[trending_categoryc.groupby('city')['num_startup'].transform(max) == trending_categoryc['num_startup']].reset_index()\nmost_trending_categoryc = most_trending_categoryc.sort_values('num_startup', ascending=False)\nmost_trending_categoryc","8e6b42ee":"funding_sorted_city = pd.pivot_table(df,\n              index=['city'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_city.columns = ['city', 'funding_total_usd']\nfunding_sorted_city = funding_sorted_city.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_city = funding_sorted_city.head(10)\nfunding_sorted_city","4d7302a5":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"city\", y=\"funding_total_usd\", data=funding_sorted_city,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"No of State\", ylabel=\"Number of Start Up\")","097d81c1":"df_what_in_kirkland = df[(df[\"city\"] == 'Kirkland')]\ndf_what_in_kirkland.shape","5fdf6311":"df_what_in_kirkland.head()","cced299c":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"has_VC\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.has_VC.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Has_VC\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","e9787786":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"is_top500\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.is_top500.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"is_top500\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","c1f6efb4":"#How many Startup have both 'acquired' status and is_top500?\nlen(df[(df[\"status\"] == True) & (df[\"is_top500\"] == True)].index)","238a4b6d":"#How many Startup have both 'closed' status and is_top500?\nlen(df[(df[\"status\"] == False) & (df[\"is_top500\"] == False)].index)","c07a783b":"df_acquired[\"is_top500\"].value_counts(normalize=True)","97ec4f7d":"df_closed.founded_at=pd.to_datetime(df_closed.founded_at)\ndf_closed.closed_at=pd.to_datetime(df_closed.closed_at)","342e07c6":"df_closed['age_closed_startup'] = df_closed.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","7aec3d07":"#df_closed['age_closed_startup'] = pd.to_numeric(df['age_closed_startup'].dt.days, downcast='int64')","a54ddc95":"df_closed['age_closed_startup'].head()","d3e0714f":"df_closed['year'] = df_closed['age_closed_startup'].dt.days \/365","9cec600f":"df_closed.head(3)","41c7aa50":"(df_closed['age_closed_startup'].mean()) ","557dccf6":"ratarata = round(2184 \/ 365) \nprint(\"Rata-Rata Startup Closed :\", ratarata ,\"tahun\")","682ac1b9":"fig, ax = plt.subplots(figsize=(17,10))\n\nsns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\nplt.legend(bbox_to_anchor=(0.945, 0.90))","51760dac":"fig, ax = plt.subplots(figsize=(12,8))\n\nsns.countplot(x=\"funding_rounds\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.funding_rounds.value_counts().index)\n# plt.legend(bbox_to_anchor=(0.945, 0.90))","1ef4d68a":"coba = df[(df[\"status\"] == 1)]\n\nfeatures = coba[[\"has_VC\",\"has_angel\",\"has_roundA\",\"has_roundB\",\"has_roundC\",\"has_roundD\"]]\n\nfig, ax = plt.subplots(figsize=(12,8))\n\na= np.random.choice([\"{}\".format(i) for i in [1,2,3,4,5,6]], size=(12,8))\ncoba = pd.DataFrame(a, columns=[\"has_{}\".format(i) for i in list(\"features\")])\n\nsns.countplot(x=\"variable\", hue=\"value\",palette=\"nipy_spectral\", data=pd.melt(features))\n\nplt.show()","48572f85":"import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapefile as shp","386a49e4":"import sys","62998862":"'geopandas' in sys.modules","9856fd00":"gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))","64d82eb1":"print(gdf.head())","b5edf0b1":"street_map = gpd.read_file('..\/input\/json-map-file\/USA_States.shp')\n\nfig,ax = plt.subplots(figsize = (15,15))\nstreet_map.plot(ax = ax)","b52ca5bb":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = street_map.plot(figsize = (50,50))\n\n# We can now plot our ``GeoDataFrame``.\ngdf.plot(ax=ax, color='red')\n\nplt.show()","062c1ec5":"#check\nduplicate = df[df.duplicated()] \n  \nprint(\"Duplicate Rows :\")","72ebec16":"age=[\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\"]\n\nfor a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","1d376762":"df=df.drop(df[df.age_first_funding_year<0].index)\ndf=df.drop(df[df.age_last_funding_year<0].index)\ndf=df.drop(df[df.age_first_milestone_year<0].index)\ndf=df.drop(df[df.age_last_milestone_year<0].index)","b608b8e3":"for a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","2ac09c57":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","dcd21c5c":"df[\"age_first_funding_year\"] = np.log1p(df[\"age_first_funding_year\"])\ndf[\"age_last_funding_year\"] = np.log1p(df[\"age_last_funding_year\"])\ndf[\"age_first_milestone_year\"] = np.log1p(df[\"age_first_milestone_year\"])\ndf[\"age_last_milestone_year\"] = np.log1p(df[\"age_last_milestone_year\"])\ndf[\"funding_total_usd\"] = np.log1p(df[\"funding_total_usd\"])","40ace4f4":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","bd768cf2":"df['has_RoundABCD'] = np.where((df['has_roundA'] == 1) | (df['has_roundB'] == 1) | (df['has_roundC'] == 1) | (df['has_roundD'] == 1), 1, 0)\ndf.head()","45cc3734":"df['has_Investor'] = np.where((df['has_VC'] == 1) | (df['has_angel'] == 1), 1, 0)\ndf.head()","39b415b5":"len(df[(df[\"has_RoundABCD\"] == 1)].index)","1da3c38b":"len(df[ (df['has_RoundABCD']  == 1) & (df['status']  == 1) ].index)","847fa2ff":"len(df)","8b3b97e4":"923-490","80db17a6":"df['has_Seed'] = np.where((df['has_RoundABCD'] == 0) & (df['has_Investor'] == 1), 1, 0)\ndf.head()","b6a9f1ab":"df['has_Seed'] == 1","484e191d":"len(df[(df[\"has_Seed\"] == 1)].index)","c2e256a4":"df['invalid_startup'] = np.where((df['has_RoundABCD'] == 0) & (df['has_VC'] == 0) & (df['has_angel'] == 0), 1, 0)\ndf.head()","12e0bf2c":"len(df[(df[\"invalid_startup\"] == 1)].index)","50c46c14":"df.founded_at=pd.to_datetime(df.founded_at)\ndf.closed_at=pd.to_datetime(df.closed_at)","9ea07c1b":"df['age_closed_startup'] = df.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","5512f30d":"df['age_closed_startup'].head()","37b4173f":"df['age_startup_year'] = df['age_closed_startup'].dt.days \/365","b36ae689":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","17b7ae30":"# create a list of our conditions\nconditions = [\n    (df['relationships'] <= 5),\n    (df['relationships'] > 5) & (df['relationships'] <= 10),\n    (df['relationships'] > 10) & (df['relationships'] <= 16),\n    (df['relationships'] > 16)\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['4', '3', '2', '1']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndf['tier_relationships'] = np.select(conditions, values)\n\n# display updated DataFrame\ndf.head()","95b8ff0c":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"tier_relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.tier_relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"tier_relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","e05f1137":"df['tier_relationships'] = df.tier_relationships.astype(int)","eb3988cc":"df = df.drop(['state_code'],axis=1)\ndf = df.drop(['id'],axis=1)\ndf = df.drop(['Unnamed: 6'],axis=1)\ndf = df.drop(['category_code'],axis=1)\ndf = df.drop(['object_id'],axis=1)\ndf = df.drop(['zip_code'],axis=1)\ndf = df.drop(['founded_at'],axis=1)\ndf = df.drop(['closed_at'],axis=1)\ndf = df.drop(['first_funding_at'],axis=1)\ndf = df.drop(['last_funding_at'],axis=1)\ndf = df.drop(['city'],axis=1)\ndf = df.drop(['name'],axis=1)\ndf = df.drop(['Unnamed: 0'],axis=1)\ndf = df.drop(['latitude','longitude'],axis=1)\ndf = df.drop(['geometry'],axis=1)\ndf = df.drop(['age_closed_startup'],axis=1)\ndf = df.drop(['relationships'],axis=1)","b9a6c03d":"#Cek categorical\ncat_feature = df.select_dtypes(include='object')\ncat_feature.head()","d8074a4a":"from sklearn.model_selection import train_test_split\n# Split the data\n# Input\/independent variables\nX = df.drop('status', axis = 1) # her we are droping the output feature as this is the target and 'X' is input features, the changes are not \n                                # made inplace as we have not used 'inplace = True'\n\ny = df['status'] # Output\/Dependent variable","04b7f492":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","10844c97":"# lets print the shapes again \nprint(\"Shape of the X Train :\", X_train.shape)\nprint(\"Shape of the y Train :\", y_train.shape)\nprint(\"Shape of the X test :\", X_test.shape)\nprint(\"Shape of the y test :\", y_test.shape)","79dbd4d4":"# Model Build\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","bb82ca6d":"import lightgbm as lgb\n#lightGBM model fit\ngbm = lgb.LGBMRegressor()\ngbm.fit(X_train,y_train)\ngbm.booster_.feature_importance()\n\n\n# importance of each attribute\nfea_imp_ = pd.DataFrame({'cols':X.columns, 'fea_imp':gbm.feature_importances_})\nfea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)","aea799ec":"from sklearn.feature_selection import RFE\n# create the Recursive Feature Elimination model and select 10 attributes\nrfe = RFE(gbm, 10)\nrfe = rfe.fit(X_train,y_train)\n\n# summarize the selection of the attributes\nprint(rfe.support_)\n\n# summarize the ranking of the attributes\nfea_rank_ = pd.DataFrame({'cols':X.columns, 'fea_rank':rfe.ranking_})\nfea_rank_.loc[fea_rank_.fea_rank > 0].sort_values(by=['fea_rank'], ascending = True)","615b9f36":"from lightgbm import LGBMClassifier\nclf = LGBMClassifier()\n\nclf.fit(X_train,y_train)\n\ny_pred_lgb = clf.predict(X_test)\n\nprint(\"Training Accuracy :\", clf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", clf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_lgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_lgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_lgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_lgb)\nf1 = f1_score(y_test, y_pred_lgb)\nPrecision_Recall_lgbm = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_lgbm)","c8ba9aa8":"from xgboost import XGBClassifier\n\n#train\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\n\n#predict\ny_predicted_xgb = xgb.predict(X_test)\n\nprint(\"Training Accuracy :\", xgb.score(X_train, y_train))\nprint(\"Testing Accuracy :\", xgb.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_xgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_xgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_xgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_xgb)\nf1 = f1_score(y_test, y_predicted_xgb)\nPrecision_Recall_xgb = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_xgb)","77c0fcfd":"from sklearn.ensemble import GradientBoostingClassifier\n#train\ngbc = GradientBoostingClassifier(learning_rate=0.02,\n                    max_depth=4,\n                    random_state=100, n_estimators=1000)\n\n\ngbc.fit(X_train,y_train)\n\n#predict\ny_predicted_gb = gbc.predict(X_test)\n\nprint(\"Training Accuracy :\", gbc.score(X_train, y_train))\nprint(\"Testing Accuracy :\", gbc.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_gb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_gb)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_gb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_gb)\nf1 = f1_score(y_test, y_predicted_gb)\nPrecision_Recall_gbs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_gbs)","7d4e65ea":"from sklearn.ensemble import AdaBoostClassifier\n#train\nada = AdaBoostClassifier()\n\n\nada.fit(X_train,y_train)\n\n#predict\ny_predicted_ab = ada.predict(X_test)\n\nprint(\"Training Accuracy :\", ada.score(X_train, y_train))\nprint(\"Testing Accuracy :\", ada.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_ab)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_ab)\nprint(cr)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"roc_auc\",roc_auc)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_ab)\nf1 = f1_score(y_test, y_predicted_ab)\nPrecision_Recall_abs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_abs)","6d07fe67":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)\n\n\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Training Accuracy :\", rf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", rf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)\nf1 = f1_score(y_test, y_pred_rf)\nPrecision_Recall_rfs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_rfs)","dbde6162":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nscores = {'LGBM':  { \n                             'precision_score': precision_score(y_test, y_pred_lgb),\n                             'recall_score': recall_score(y_test, y_pred_lgb)\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_gb),\n                             'recall_score': recall_score(y_test, y_predicted_gb)\n                         },\n                 'Adaboost Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_ab),\n                             'recall_score': recall_score(y_test, y_predicted_ab)\n                         },\n                 'XGBoost':  { \n                             'precision_score': precision_score(y_test, y_predicted_xgb),\n                             'recall_score': recall_score(y_test, y_predicted_xgb)\n                         },\n                 'Random Forest':  { \n                             'precision_score': precision_score(y_test, y_pred_rf),\n                            'recall_score': recall_score(y_test, y_pred_rf)\n                         }\n            }","06a46295":"from sklearn.metrics import precision_score\n\n\nPrecision_Recall = {'LGBM':  { \n                             'Precision_Recall': Precision_Recall_lgbm\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'Precision_Recall': Precision_Recall_gbs\n                         },\n                 'Adaboost Classifier':  { \n                             'Precision_Recall': Precision_Recall_abs\n                         },\n                 'XGBoost':  { \n                             'Precision_Recall': Precision_Recall_xgb\n                         },\n                 'Random Forest':  { \n                             'Precision_Recall': Precision_Recall_rfs\n                         }\n            }","3fc0c8f9":"scores = pd.DataFrame(scores)\n\n\nscores.plot(kind=\"barh\",figsize=(12, 12)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","8d468399":"Precision_Recall = pd.DataFrame(Precision_Recall)\n\n\nPrecision_Recall.plot(kind=\"barh\",figsize=(15, 8)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","b3428652":"# import pickle","34408fd9":"# # Saving model to disk\n# pickle.dump(gbm, open('model.pkl','wb'))","39021a9f":"# # Loading model to compare the results\n# model = pickle.load(open('model.pkl','rb'))\n# print(model.predict([[2, 3, 4, 6, 3, 3, 375000, 3, 1, 6,]]))","e037d4ef":"# df2 = df[[\"status\",\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\",\"relationships\",\"funding_rounds\",\"funding_total_usd\",\"milestones\",\"avg_participants\"]]\n# df2.head(10)","66239f03":"## New Column \"invalid_startup\"","893ffc93":"## AdaBoost Classifier","99db2388":"### Mapping area startup ","241f5cc9":"## Duplicate Values","b583e17a":"# Data Preprocessing","8645d8e6":"## Drop unused column for modelling","ecc2a462":"### How many years on average the company closes","0b06f8d8":"## LGBM Classifier","a4c88a9b":"## Graphic Approach","32e10af8":"css and js file for css js elements to work on webpage.Get it from here : https:\/\/materializecss.com\/getting-started.html","2a3637a6":"##  New Column \"tier_relationships\"","8b32293a":"- Does the value listed on each column make sense?\n- age_first_funding_year and age_last_funding_year have the same min,max data, need to be checked again \n- Is the maximum\/minimum value still within the reasonable limit? \n- Min\/max that is too far from the mean\/median may be an indication of data input error \n- Is there a column with a significant difference between the mean and the median?\n- Differences between mean\/median indicate outlier or skewed distribution","bae2792e":"### Correlation heatmap","987548ff":"###  Handling Missing Value Unnamed: 6","62534105":"### Which city having most number of acquired Startup per category","5198a1d2":"from the total data available as many as 63% of startups are still standing while the remaining 37% have been closed and most closed in 2001.","b6993ce8":"## New Column \"has_RoundABCD\"","5c88cfff":"Based on the results of the analysis obtained that the column **Unnamed: 6** is a combination of several other columns including columns **city, state_code, and zip_code**, then we decided that remove the contents of the column **Unnamed: 6** first and then fill in the data based on a combination of several related columns.","93adc667":"- the **\"state_code\"** column and the **\"state_code.1\"** column must be the same, so the **\"state_code.1\"** column must be dropped. \n- column **\"state_code.1\"** has missing value in line 515.","e5d5c299":"Based on the results of the analysis obtained that the columns 'age_first_milestone_year' and 'age_last_milestone_year' have null values because the startup does not have milestones. this can be confirmed by looking at the 'milestones' column containing the data 0 must be accompanied by the null 'age_first_milestone_year' and 'age_last_milestone_year' columns. so we decided to fill that null column with a value of 0.","a71f8952":"## New Column \"has_Investor\"","5f19657f":"### Which category has the largest number of startup","3a9654e1":"## Outliers","ec5d5a0d":"### Which category having most number of total funding","b09c9754":"### which funding_rounds related to acquired or closed startup?","128ad672":"total 563 startups or 60% of startups established in 2001","0896ff00":"## Problem Statement\n\n**Startup** is a business that has just been established and grown supported by digital services and has also become an important element of innovation systems and economies around the world. The **Startup** ecosystem is growing very rapidly and still needs a lot of funding to operate with a minimalist working group. So it is very important for VC to monitor the performance and performance of **Startup**, so that it can be used as a consideration to decide whether to fund a Startup to drive its growth or refuse to take part in funding. To monitor startup performance, it is important to analyze what makes a Startup successful and how to determine its success.\n\n## Goals\nThe goal to be achieved is to determine whether a StartUp will be successful or not.\n\n## Objective\nThe objective is to analyze startup behavior based on several variables, determine what variables affect startup success the most, then build a model that can predict the success of a StartUp.","b6642257":"based on the correlation table above which says that **'views'** and **'likes'** are very positively correlated. then we then verify that by plotting a scatter plot between **'views'** and **'likes'** to visualize the relationship between those variables.","1c6e2e2d":"### Handling Missing Value state_code.1","10a65059":"### Which State having most number of Startup","2961e60d":"## New Column \"has_Seed\"","ebf365b6":"### Which State having most number of acquired Startup per category","f3493796":"##### Build Model","5dcc422f":"# Data Exploration","7516de2d":"### Which category has the largest number Success Rate","6053bc93":"## Import Libraries","687ccd94":"### Which State having most number of closed Startup per category","22df4720":"## Data numeric","c01dcfff":"## XGBoost Classifier","79c314cb":"### How many Startup have has_VC?","9a9ab4f5":"### Handling Missing Value age_first_milestone_year and age_last_milestone_year","b644504d":"### Investing Feature on Acquired","531764e2":"- **Analysis results in the dataset used there are Missing Values among them are**\n    - **Total Missing Values i.e. 1386**\n    - **Columns that have more than 50% of missing values**\n        - Variable 'closed_at' with a total percentage of 63.70% or a total of 588 columns.\n        - Variable 'Unnamed: 6' with a total percentage of 53.41% or a total of 493 columns.\n    - **Columns that have less than 50% of missing values** \n        - Variable 'age_first_milestone_year' with a total percentage of 16.46% or a total of 152 columns.\n        - Variable 'age_last_milestone_year' with a total percentage of 16.46% or a total of 152 columns.","2fab0487":"##### Recursive Feature Elimination(RFE)","1b6df365":"We see that **'age_first_milestones_year'** and **'age_last_milestones_year'** are really positively correlated whereas when one increases, the other also increases\u2014mostly.","5de64857":"### Dataset collection founded years","d97f118f":"## Data type identification","a8e52e71":"# Startup Success Prediction Model","493cdd63":"### Scatter plot","8d1f541d":"# Exploratory Data Analysis","387d4daa":"## Description","ad3a0e9e":"##  New Column \"age_startup_year\"","09bf4cc5":"# Deploy Model","bb675a8b":"### Changing 'status' data value","373ecdcb":"## Load Dataset","b285cc43":"## Missing Value ","cbbe1e52":"### Box plots","deac5ae2":"### Statistical Summary","ea6b337e":"## Data categorical","cbf8fe8d":"### Drop column labels","967c3298":"Now how to correlate between data variables. \n\nCorrelation is represented as a value between -1 and +1 where +1 indicates the highest positive correlation, -1 indicates the highest negative correlation, and 0 indicates no correlation.","07d8fa5c":"# Feature Engineering","cfb7743a":"### Handling 'status' data type to int ","f878bb49":"# Modeling","a8d05a5c":"## GradientBoosting Classifier","a31f4f85":"### Handling Missing Value closed_at","2f2be9ed":"# Summary","27cc6a31":"### How many Startup are acquired or closed have?","84970dff":"Round A, Round B,Round C, Round D, VC, Angel = 0 earlier startup status acquired ????????? there is something strange about this data, the possibility of invalid data","362b650a":"### which relationship related to acquired or closed startup?","f0ce4192":"### Categorical Value Counting","d7700059":"## Log-transformation of the funding and milestone year variable","63d3e390":"### Which city having most number of closed Startup per category","13caf6f6":"##### Feature importance by LGBM","92d54274":"### Which city having most number of total funding","dba12d3a":"## Numerical Approach","f650934f":"- **Analysis results in the column contained Missing Values among them are** \n    - **Column \"Unnamed: 6\"** is a column of information from a combination of several tables including \n        - Column \"city\", \"state_code\", and \"zip_code\" \n    - **Column \"closed_at\"** is a column where StartUp **\"Closed\"** so that the empty data should be a StarUp whose status is still **\"Acquired\"** \n    - **Column age_first_milestone_year** is information on when milestones were first performed in units of the year \n        - This column has a total of 771 rows of data with a Mean of 3.055353 and a median of 2.520500 showing abnormal data distribution \n    - **Column age_Last_milestone_year** is information when the last milestone was done in units of years \n        - This column has a total of 771 rows of data with a Mean of 4.754423 and a median of 4.476700 that shows the distribution of data is abnormal","57d5d8bd":"## Negative value","df407718":"### How many Startup have is_top500?","c5cffd65":"## Random Forest"}}