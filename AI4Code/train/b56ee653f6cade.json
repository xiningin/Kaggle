{"cell_type":{"1ed5717d":"code","557c708f":"code","10a5253b":"code","90053bed":"code","a232a475":"code","873c8d94":"code","76dac1e3":"code","a62eda00":"code","e02726b8":"code","c160151d":"code","fba1ccd7":"code","65531da3":"code","1c6f8a40":"code","cde0bf85":"code","88806d46":"code","1a97ebf2":"code","2749909d":"code","64d0fadf":"code","69971f5f":"code","8ecdc457":"code","0e835092":"code","479ddeeb":"code","b6745549":"code","ba3010ce":"code","ca959a97":"code","2a5fc3d6":"code","f3ed85d6":"code","72cbcd10":"code","ab97ad88":"code","9ffaa571":"code","3546fb04":"code","5eff46b9":"code","a9b94372":"code","dc3a8611":"code","5bb91f60":"code","06bff3d5":"code","88ea729c":"code","813c83a2":"code","e8847331":"code","e6bdf2bc":"code","0216d908":"code","375730cf":"code","103e9f8d":"code","b683c805":"code","18216c0a":"code","23775167":"code","f35d4107":"code","27fbeac4":"code","e5388a60":"code","46a51135":"code","34bffdd9":"code","1cba2e01":"code","5dfdd3aa":"code","bf3a62fe":"code","2c4c7498":"code","e038134e":"code","a3181698":"code","09152b00":"code","aa187252":"code","ca7dede8":"code","5a9afe11":"code","a82f28d8":"code","ba7dc2eb":"code","f3bfd8d8":"code","f202213f":"code","8bc04982":"code","f47e7faa":"code","87a3153e":"code","e3751015":"code","270a2356":"code","74f93051":"code","64c37ef9":"code","18d23e2a":"code","5a52f27b":"code","86113f4b":"code","9a80c682":"code","b841bb1b":"code","fcf6fa5d":"code","3b636158":"code","24696538":"code","9328dcbe":"code","c0b921db":"code","d78c6d44":"code","cfd5eb0d":"code","70eb78ae":"code","dbf206bf":"code","5f49c6f7":"code","d5890161":"code","98764300":"code","2449aeb3":"code","60b12367":"code","8b535e58":"code","0f3fc4bd":"code","7b123989":"code","8086513b":"code","e981f5e9":"code","6f66585b":"code","b417ce32":"code","86a78ab2":"code","5d5b894d":"code","dc568108":"code","fff5bc93":"code","892af2ac":"code","36f1f82d":"code","4402dba3":"code","9c1f2d57":"code","37a7d321":"code","be943851":"code","ca6b8bb8":"code","5b47f5b9":"code","8d9c7cae":"code","3a20089c":"code","f5bf7f8d":"code","1f999971":"code","65070bca":"code","7688d821":"code","6fecf5bc":"markdown","dc610597":"markdown","d7f98cd3":"markdown","e27ef319":"markdown","60c674f1":"markdown","6a8864b6":"markdown","b3cb1c99":"markdown","74409f74":"markdown","1d348c0d":"markdown","07af8cec":"markdown","016b9105":"markdown","4ed97f6b":"markdown","36f9ae1c":"markdown","488ca8d8":"markdown","38e98bb3":"markdown","b6e49876":"markdown","c301c31e":"markdown","59c334c1":"markdown","38beee59":"markdown","2fed388d":"markdown","46c16795":"markdown","729cd2d6":"markdown","253f0333":"markdown","3aae00f9":"markdown","54ac675a":"markdown","11b3a6b5":"markdown","1e6bb92b":"markdown","ad01828d":"markdown","48aaf003":"markdown","a34ae19e":"markdown","35a9a731":"markdown","99eff1e9":"markdown","ea4a4608":"markdown","3a77c33c":"markdown","41fd00f1":"markdown","99c31dca":"markdown","dfe871c5":"markdown","31cd9b87":"markdown","dab555e4":"markdown","4a2160de":"markdown","4f2a28b1":"markdown","4d705a82":"markdown","ea0e9c3f":"markdown","9061b74c":"markdown","69c0d26e":"markdown","9a9eac0e":"markdown","576e7f9f":"markdown","461f89a5":"markdown","5ebd466e":"markdown","ff2465f5":"markdown","de21c3a7":"markdown","008888cc":"markdown","c1bc1bc1":"markdown","1326c398":"markdown","f9a76b61":"markdown","4d3aea7e":"markdown","c64e47b3":"markdown","ca778ea6":"markdown","c6791a9a":"markdown","a97cd2ac":"markdown","7db66433":"markdown","783801be":"markdown","c1a003fb":"markdown","243f9e41":"markdown","9e2da00a":"markdown","ef1de037":"markdown","37db5ef9":"markdown","db119d7d":"markdown","365f8744":"markdown","c98e6b54":"markdown"},"source":{"1ed5717d":"import numpy as np \nimport pandas as pd \n\nimport random as rn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\n# plotly library\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold \nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import uniform\n\nimport itertools\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import np_utils\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n#from keras.layers import AvgPool2D, BatchNormalization, Reshape\nfrom keras.optimizers import Adadelta, RMSprop, Adam\nfrom keras.losses import categorical_crossentropy\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nimport tensorflow as tf\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","557c708f":"img_rows, img_cols = 28, 28\n\nnp.random.seed(5)\n#rn.seed(5)\n#tf.set_random_seed(5)","10a5253b":"def get_best_score(model):\n    \n    print(model.best_score_)    \n    print(model.best_params_)\n    print(model.best_estimator_)\n    \n    return model.best_score_","90053bed":"def print_validation_report(y_true, y_pred):\n    print(\"Classification Report\")\n    print(classification_report(y_true, y_pred))\n    acc_sc = accuracy_score(y_true, y_pred)\n    print(\"Accuracy : \"+ str(acc_sc))\n    \n    return acc_sc","a232a475":"def plot_confusion_matrix(y_true, y_pred):\n    mtx = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(8,8))\n    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n    #  square=True,\n    plt.ylabel('true label')\n    plt.xlabel('predicted label')","873c8d94":"def plot_history_loss_and_acc(history_keras_nn):\n\n    fig, axs = plt.subplots(1,2, figsize=(12,4))\n\n    axs[0].plot(history_keras_nn.history['loss'])\n    axs[0].plot(history_keras_nn.history['val_loss'])\n    axs[0].set_title('model loss')\n    axs[0].set_ylabel('loss')\n    axs[0].set_xlabel('epoch')\n    axs[0].legend(['train', 'validation'], loc='upper left')\n\n    axs[1].plot(history_keras_nn.history['acc'])\n    axs[1].plot(history_keras_nn.history['val_acc'])\n    axs[1].set_title('model accuracy')\n    axs[1].set_ylabel('accuracy')\n    axs[1].set_xlabel('epoch')\n    axs[1].legend(['train', 'validation'], loc='upper left')\n\n    plt.show()","76dac1e3":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","a62eda00":"y = train[\"label\"]\nX = train.drop([\"label\"],axis = 1)\nX_test = test","e02726b8":"X = X\/255.0\nX_test = X_test\/255.0","c160151d":"# for best performance, especially of the NN classfiers,\n# set mode = \"commit\"\nmode = \"edit\"\nmode = \"commit\"\n#\n\nif mode == \"edit\" :\n    nr_samples = 1200\n\nif mode == \"commit\" :    \n    nr_samples = 30000\n\ny_train=y[:nr_samples]\nX_train=X[:nr_samples]\nstart_ix_val = nr_samples \nend_ix_val = nr_samples + int(nr_samples\/3)\ny_val=y[start_ix_val:end_ix_val]\nX_val=X[start_ix_val:end_ix_val]\n    \nprint(\"nr_samples train data:\", nr_samples)\nprint(\"start_ix_val:\", start_ix_val)\nprint(\"end_ix_val:\", end_ix_val)","fba1ccd7":"print(\"X:\")\nprint(X.info())\nprint(\"*\"*50)\nprint(\"X_test:\")\nprint(X_test.info())\nprint(\"*\"*50)\nprint(\"y:\")\nprint(y.shape)","65531da3":"X.iloc[0:5,:]","1c6f8a40":"y.iloc[0:5]","cde0bf85":"fig, axs = plt.subplots(1, 5, sharex=True, sharey=True, figsize=(10,6))\naxs = axs.flatten()\nfor i in range(0,5):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[i].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[i].set_title(y[i])\nplt.tight_layout()    ","88806d46":"y.value_counts()","1a97ebf2":"fig, ax = plt.subplots(figsize=(8,5))\ng = sns.countplot(y)","2749909d":"li_idxs = []\nfor i in range(10):\n    for nr in range(10):\n        ix = y[y==nr].index[i]\n        li_idxs.append(ix) ","64d0fadf":"fig, axs = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(10,12))\naxs = axs.flatten()\nfor n, i in enumerate(li_idxs):\n    im = X.iloc[i]\n    im = im.values.reshape(-1,28,28,1)\n    axs[n].imshow(im[0,:,:,0], cmap=plt.get_cmap('gray'))\n    axs[n].set_title(y[i])\nplt.tight_layout()    ","69971f5f":"from sklearn.linear_model import Perceptron\nclf_Perceptron = Perceptron(random_state=0)\nparam_grid = { 'penalty': ['l1','l2'], 'tol': [0.05, 0.1] }\nGridCV_Perceptron = GridSearchCV(clf_Perceptron, param_grid, verbose=1, cv=5)\nGridCV_Perceptron.fit(X_train,y_train)\nscore_grid_Perceptron = get_best_score(GridCV_Perceptron)","8ecdc457":"pred_val_perc = GridCV_Perceptron.predict(X_val)","0e835092":"acc_perc = print_validation_report(y_val, pred_val_perc)","479ddeeb":"plot_confusion_matrix(y_val, pred_val_perc)","b6745549":"from sklearn.linear_model import LogisticRegression\nclf_LR = LogisticRegression(random_state=0)\nparam_grid = {'C': [0.014,0.012], 'multi_class': ['multinomial'],  \n              'penalty': ['l1'],'solver': ['saga'], 'tol': [0.1] }\nGridCV_LR = GridSearchCV(clf_LR, param_grid, verbose=1, cv=5)\nGridCV_LR.fit(X_train,y_train)\nscore_grid_LR = get_best_score(GridCV_LR)","ba3010ce":"pred_val_lr = GridCV_LR.predict(X_val)\nacc_lr = print_validation_report(y_val, pred_val_lr)","ca959a97":"plot_confusion_matrix(y_val, pred_val_lr)","2a5fc3d6":"from sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=10)\nclf_knn.fit(X_train,y_train)","f3ed85d6":"pred_val_knn = clf_knn.predict(X_val)\nacc_knn = print_validation_report(y_val, pred_val_knn)","72cbcd10":"plot_confusion_matrix(y_val, pred_val_knn)","ab97ad88":"from sklearn.ensemble import RandomForestClassifier\nclf_RF = RandomForestClassifier(random_state=0)\nparam_grid = {'max_depth': [15], 'max_features': [100],  \n              'min_samples_split': [5],'n_estimators' : [50] }\nGridCV_RF = GridSearchCV(clf_RF, param_grid, verbose=1, cv=5)\nGridCV_RF.fit(X_train,y_train)\nscore_grid_RF = get_best_score(GridCV_RF)","9ffaa571":"pred_val_rf = GridCV_RF.predict(X_val)","3546fb04":"acc_rf = print_validation_report(y_val, pred_val_rf)","5eff46b9":"plot_confusion_matrix(y_val, pred_val_rf)","a9b94372":"from sklearn.svm import SVC\nclf_svm = SVC(C=5, gamma=0.05, kernel='rbf', random_state=0)\nclf_svm.fit(X_train,y_train)","dc3a8611":"pred_val_svm = clf_svm.predict(X_val)\nacc_svm = print_validation_report(y_val, pred_val_svm)","5bb91f60":"plot_confusion_matrix(y_val, pred_val_svm)","06bff3d5":"batchsize = int(nr_samples\/15) ","88ea729c":"from sklearn.neural_network import MLPClassifier\n\nclf_mlp = MLPClassifier(activation = \"logistic\", hidden_layer_sizes=(200,), random_state=0)\nparam_grid = { 'batch_size' : [batchsize] , 'max_iter': [600], 'alpha': [1e-4], \n               'solver': ['sgd'], 'learning_rate_init': [0.05,0.06],'tol': [1e-4] }\n    \nGridCV_MLP = GridSearchCV(clf_mlp, param_grid, verbose=1, cv=3)\nGridCV_MLP.fit(X_train,y_train)\nscore_grid_MLP = get_best_score(GridCV_MLP)   ","813c83a2":"fig, ax = plt.subplots(figsize=(6,3))\nax.plot(GridCV_MLP.best_estimator_.loss_curve_)\n\nplt.xlabel(\"number of steps\") \nplt.ylabel(\"Loss During GD\")\nplt.title(\"loss function\")\nplt.show()","e8847331":"pred_val_mlp = GridCV_MLP.predict(X_val)","e6bdf2bc":"acc_mlp = print_validation_report(y_val, pred_val_mlp)","0216d908":"plot_confusion_matrix(y_val, pred_val_mlp)","375730cf":"y_train = to_categorical(y_train, 10)\ny_val_10 = to_categorical(y_val, 10)","103e9f8d":"def dense_model_0():\n    model = Sequential()\n    model.add(Dense(10, input_dim=784, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","b683c805":"model_dense_0 = dense_model_0()\nmodel_dense_0.summary()","18216c0a":"model_dense_0.fit(X_train, y_train, epochs=50, batch_size=batchsize)","23775167":"pred_val_dense0 = model_dense_0.predict_classes(X_val)","f35d4107":"acc_fc0 = print_validation_report(y_val, pred_val_dense0)","27fbeac4":"plot_confusion_matrix(y_val, pred_val_dense0)","e5388a60":"def dense_model_1():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","46a51135":"model_dense_1 = dense_model_1()\nmodel_dense_1.summary()","34bffdd9":"history_dense_1 = model_dense_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","1cba2e01":"plot_history_loss_and_acc(history_dense_1)","5dfdd3aa":"pred_val_dense1 = model_dense_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense1)\nprint(classification_report(y_val, pred_val_dense1))\nacc_fc1 = accuracy_score(y_val, pred_val_dense1)\nprint(acc_fc1)","bf3a62fe":"def dense_model_2():\n    model = Sequential()\n    model.add(Dense(100, input_dim=784, activation='relu'))\n    model.add(Dense(200, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","2c4c7498":"model_dense_2 = dense_model_2()\nmodel_dense_2.summary()","e038134e":"history_dense_2 = model_dense_2.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","a3181698":"plot_history_loss_and_acc(history_dense_2)","09152b00":"pred_val_dense2 = model_dense_2.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense2)\nprint(classification_report(y_val, pred_val_dense2))\nacc_fc2 = accuracy_score(y_val, pred_val_dense2)\nprint(acc_fc2)","aa187252":"def dense_model_3():\n    \n    model = Sequential()  \n    model.add(Dense(100, activation='relu', input_dim=784))\n    model.add(Dense(200, activation='relu')) \n    model.add(Dense(100, activation='relu')) \n    model.add(Dense(10, activation='softmax'))\n         \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #model.compile(optimizer=RMSprop(lr=0.001),\n    #         loss='categorical_crossentropy',\n    #         metrics=['accuracy'])\n    \n    return model","ca7dede8":"model_dense_3 = dense_model_3()\nmodel_dense_3.summary()","5a9afe11":"history_dense_3 = model_dense_3.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                    epochs=50, batch_size=batchsize)","a82f28d8":"plot_history_loss_and_acc(history_dense_3)","ba7dc2eb":"pred_val_dense3 = model_dense_3.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_dense3)\nprint(classification_report(y_val, pred_val_dense3))\nacc_fc3 = accuracy_score(y_val, pred_val_dense3)\nprint(acc_fc3)","f3bfd8d8":"X_train.shape","f202213f":"X_train = X_train.values.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_val = X_val.values.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\ninput_shape = (img_rows, img_cols, 1)","8bc04982":"X_train.shape","f47e7faa":"y_train.shape","87a3153e":"batchsize = 128\nepochs = 12","e3751015":"activation = 'relu'\nadadelta = Adadelta()\nloss = categorical_crossentropy","270a2356":"def cnn_model_1(activation):\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n    \n    model.add(Conv2D(64, (3, 3), activation=activation))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Flatten())\n\n    model.add(Dense(128, activation=activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss=loss, optimizer=adadelta, metrics=['accuracy'])\n\n    return model","74f93051":"model_cnn_1 = cnn_model_1(activation)\nmodel_cnn_1.summary()","64c37ef9":"#model_cnn_1.fit(X_train, y_train, batch_size=batchsize, epochs=epochs, verbose=1)\nhistory_cnn_1 = model_cnn_1.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                   epochs=epochs, batch_size=batchsize, verbose=1)","18d23e2a":"plot_history_loss_and_acc(history_cnn_1)","5a52f27b":"pred_val_cnn1 = model_cnn_1.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_cnn1)\nprint(classification_report(y_val, pred_val_cnn1))\nacc_cnn1 = accuracy_score(y_val, pred_val_cnn1)\nprint(acc_cnn1)\n","86113f4b":"batch_size=90\nepochs=30\n","9a80c682":"def cnn_model_2(optimizer,loss):\n\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding = 'Same', activation=\"relu\", input_shape=input_shape ))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation=activation))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy']) \n\n    return model","b841bb1b":"model_cnn_2 = cnn_model_2(adadelta, categorical_crossentropy)\nmodel_cnn_2.summary()","fcf6fa5d":"#model_cnn_2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\nhistory_cnn_2 = model_cnn_2.fit(X_train, y_train, validation_data=(X_val,y_val_10), \n                                epochs=epochs, batch_size=batchsize, verbose=1)","3b636158":"plot_history_loss_and_acc(history_cnn_2)","24696538":"pred_val_cnn2 = model_cnn_2.predict_classes(X_val)\nplot_confusion_matrix(y_val, pred_val_cnn2)\nprint(classification_report(y_val, pred_val_cnn2))\nacc_cnn2 = accuracy_score(y_val, pred_val_cnn2)\nprint(acc_cnn2)","9328dcbe":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nif mode == \"edit\" :\n    X = X[:nr_samples\/\/2]\n    y = y[:nr_samples\/\/2]\n    X_test = X_test[:nr_samples\/\/2]\n    sample_submission = sample_submission[:nr_samples\/\/2]","c0b921db":"print(X.shape)\nprint(y.shape)\nprint(X_test.shape)","d78c6d44":"print(GridCV_Perceptron.best_params_)\nGridCV_Perceptron.best_estimator_.fit(X,y)","cfd5eb0d":"pred_test_perc = GridCV_Perceptron.best_estimator_.predict(X_test)\nresult_perc = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_perc})\nresult_perc.to_csv(\"subm_perc.csv\",index=False)","70eb78ae":"print(GridCV_LR.best_params_)\nGridCV_LR.best_estimator_.fit(X,y)","dbf206bf":"pred_test_lr = GridCV_LR.best_estimator_.predict(X_test)\nresult_lr = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_lr})\nresult_lr.to_csv(\"subm_lr.csv\",index=False)","5f49c6f7":"clf_knn.fit(X,y)","d5890161":"pred_test_knn = clf_knn.predict(X_test)\nresult_knn = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_knn})\nresult_knn.to_csv(\"subm_knn.csv\",index=False)","98764300":"print(GridCV_RF.best_params_)\nGridCV_RF.best_estimator_.fit(X,y)","2449aeb3":"pred_test_rf = GridCV_RF.best_estimator_.predict(X_test)\nresult_rf = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_rf})\nresult_rf.to_csv(\"subm_rf.csv\",index=False)","60b12367":"clf_svm.fit(X,y)","8b535e58":"pred_test_svm = clf_svm.predict(X_test)\nresult_svm = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_svm})\nresult_svm.to_csv(\"subm_svm.csv\",index=False)","0f3fc4bd":"print(GridCV_MLP.best_params_)\nGridCV_MLP.best_estimator_.fit(X,y)","7b123989":"pred_test_mlp = GridCV_MLP.best_estimator_.predict(X_test)\nresult_mlp = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_mlp})\nresult_mlp.to_csv(\"subm_mlp.csv\",index=False)","8086513b":"y = to_categorical(y, 10)","e981f5e9":"model_dense_1.fit(X,y)\npred_test_fc1 = model_dense_1.predict_classes(X_test)\nresult_fc1 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc1})\nresult_fc1.to_csv(\"dense_1.csv\",index=False)","6f66585b":"model_dense_2.fit(X,y)\npred_test_fc2 = model_dense_2.predict_classes(X_test)\nresult_fc2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc2})\nresult_fc2.to_csv(\"dense_2.csv\",index=False)","b417ce32":"model_dense_3.fit(X,y)\npred_test_fc3 = model_dense_3.predict_classes(X_test)\nresult_fc3 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_fc3})\nresult_fc3.to_csv(\"dense_3.csv\",index=False)","86a78ab2":"X = X.values.reshape(X.shape[0], img_rows, img_cols, 1)\nX_test = X_test.values.reshape(X_test.shape[0], img_rows, img_cols, 1)\n#y = to_categorical(y, 10)","5d5b894d":"batchsize = 128\nepochs = 12\nmodel_cnn_1 = cnn_model_1('relu')\nmodel_cnn_1.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)","dc568108":"pred_test_cnn_1 = model_cnn_1.predict(X_test)\npred_test_cnn_1 = np.argmax(pred_test_cnn_1,axis=1)\nresult_cnn_1 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_1})\nresult_cnn_1.to_csv(\"subm_cnn_1.csv\",index=False)","fff5bc93":"batch_size=90\nepochs=30\nmodel_cnn_2 = cnn_model_2(adadelta, categorical_crossentropy)\nmodel_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)","892af2ac":"pred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_adadelta.csv\",index=False)","36f1f82d":"predictions = {'PERC': pred_test_perc, 'LR': pred_test_lr, 'KNN': pred_test_knn, \n               'RF': pred_test_rf, 'SVM': pred_test_svm, 'MLP': pred_test_mlp, \n               'DENSE1': pred_test_fc1, 'DENSE2': pred_test_fc2, 'DENSE3': pred_test_fc3, \n               'CNN1': pred_test_cnn_1, 'CNN2': pred_test_cnn_2}\ndf_predictions = pd.DataFrame(data=predictions) \ndf_predictions.corr()","4402dba3":"list_classifiers = ['PERC','LR','KNN','RF','SVM',\n                    'MLP','DENSE1','DENSE2','DENSE3',\n                    'CNN1','CNN2']","9c1f2d57":"val_scores = [acc_perc, acc_lr, acc_knn, acc_rf, \n               acc_svm, acc_mlp, acc_fc1, acc_fc2, \n               acc_fc3, acc_cnn1, acc_cnn2]","37a7d321":"score_perc  = 0.88057\nscore_lr    = 0.88700\nscore_knn   = 0.96557\nscore_rf    = 0.96028\nscore_svm   = 0.98100\nscore_mlp   = 0.96985\n\nscore_dns_1  = 0.95971 \nscore_dns_2  = 0.96228      \nscore_dns_3  = 0.96128\nscore_cnn_1  = 0.98928\nscore_cnn_2  = 0.99028","be943851":"test_scores = [score_perc, score_lr, score_knn, score_rf, score_svm, score_mlp,\n               score_dns_1, score_dns_2, score_dns_3, score_cnn_1, score_cnn_2]","ca6b8bb8":"trace1 = go.Scatter(x = list_classifiers, y = val_scores,\n                   name=\"Validation\", text = list_classifiers)\ntrace2 = go.Scatter(x = list_classifiers, y = test_scores,\n                   name=\"Submission\", text = list_classifiers)\n\ndata = [trace1, trace2]\n\nlayout = dict(title = \"Validation and Submission Scores\", \n              xaxis=dict(ticklen=10, zeroline= False),\n              yaxis=dict(title = \"Accuracy\", side='left', ticklen=10,),                                  \n              legend=dict(orientation=\"v\", x=1.05, y=1.0),\n              autosize=False, width=750, height=500,\n              )\n\nfig = dict(data = data, layout = layout)\niplot(fig)","5b47f5b9":"model_cnn_2.optimizer","8d9c7cae":"model_cnn_2_rmsprop = cnn_model_2(RMSprop(), categorical_crossentropy)\nmodel_cnn_2_rmsprop.optimizer","3a20089c":"model_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)\npred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_rmsprop.csv\",index=False)","f5bf7f8d":"model_cnn_2_adam = cnn_model_2(Adam(), categorical_crossentropy)\nmodel_cnn_2_adam.optimizer","1f999971":"model_cnn_2.fit(X, y, epochs=epochs, batch_size=batchsize, verbose=0)\npred_test_cnn_2 = model_cnn_2.predict(X_test)\npred_test_cnn_2 = np.argmax(pred_test_cnn_2,axis=1)\nresult_cnn_2 = pd.DataFrame({'ImageId':sample_submission.ImageId, 'Label':pred_test_cnn_2})\nresult_cnn_2.to_csv(\"subm_cnn_2_adam.csv\",index=False)","65070bca":"arr_y_val = y_val.values\nfalse_cnn2 = pred_val_cnn2 != arr_y_val","7688d821":"fig, axs = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(10,12))\naxs = axs.flatten()\nfor i, n  in enumerate(false_cnn2[:25]):\n    im = X_val[false_cnn2][i,:,:,0]\n    axs[i].imshow(im, cmap=plt.get_cmap('gray'))\n    title = (\"predicted: \" + str(pred_val_cnn2[false_cnn2][i]) + \n            \"\\n\" + \"true: \" + str(arr_y_val[false_cnn2][i]) )\n    axs[i].set_title(title)\nplt.tight_layout()    ","6fecf5bc":"Using GridSearchCV with KNN takes very long for this dataset.  \nTherefore I fit the data with one parameter: neighbors = 10  \nThe resulting accuracy is already quite good.","dc610597":"**get indexes of first 10 occurences for each number**","d7f98cd3":"Convnets:  \n[Udacity](https:\/\/www.youtube.com\/watch?v=jajksuQW4mc) ","e27ef319":"**reshape for CNN**","60c674f1":"### Perceptron","6a8864b6":"Adam","b3cb1c99":"### get_best_score for GridSearchCV","74409f74":"### plot_confusion_matrix","1d348c0d":"### Multi Layer Perceptron","07af8cec":"### setting train and validation data","016b9105":"**CNN 1**","4ed97f6b":"from submission ","36f9ae1c":"Like for KNN, GridSearchCV for SVM takes very long, so I only fit one good set of parameters here.","488ca8d8":"**MLP**","38e98bb3":"'RandomForestClassifier' object has no attribute 'loss_curve_'","b6e49876":"* Best accuracy around 99% is obtained with CNN1 and CNN2.  \n* SVC also has very good accuracy with 98%  \n* Except for Perceptron and Logistic regression, all classifiers get accuarcy similar to humans (above 95%)  \n* Fully connected NNs (dense 1,2,3) show most overfitting (validation score much larger than test score)","c301c31e":"**For the GridSearchCV studies on finding the best model parameters we fit the classifiers using cross validation.**  \n**This reduces the number of training examples because a portion of the data is used for validation.**  \n**We now fit the classifiers on the complete training set (42000 samples).**  \n**Then we use this new fit to make predictions for the test dataset (28000 samples).**","59c334c1":"# Part 4: Predictions for test data","38beee59":"## Fitting on all training data","2fed388d":"**Logistic Regression**","46c16795":"1. **We can see that there is a lot of variety in the look of the numbers**  \n2. **The digits are obviously written by many different people**\n3. **And it seems that there might be difficulties identifying some of the digits correctly also for humans:**\n\n\n","729cd2d6":"# Part 3: NN Classifiers with Keras","253f0333":"### **Reading the data**","3aae00f9":"**SVM**","54ac675a":"# **MNIST: Sklearn and Keras** \n**Comparing the performance of ML and DL classification models on**  \n**the Digit Recognizer (MNIST) competition**  \n\n\n*from Kaggle:*   \nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision.  \nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","11b3a6b5":"## 3.2 Keras : Convolutional Neural Networks, CNN","1e6bb92b":"### Normalization","ad01828d":"### 3.1.1 Keras: only input and output layer","48aaf003":"## Test scores","a34ae19e":"### plot_history_loss_and_acc","35a9a731":"from validation data","99eff1e9":"**some global variables**","ea4a4608":"### Logistic Regression","3a77c33c":"RMSprop","41fd00f1":"### Random Forest Classifier","99c31dca":"## Validation scores","dfe871c5":"### Keras: 1 hidden layer","31cd9b87":"### KNN","dab555e4":"## Keras: CNN model 1\nConv2D (32, (3, 3))  \nConv2D (64, (3, 3))  \nPooling2D (2,2)  \nDropout (0.25)\nFlatten  \nDense(128, relu)  \nDropout (0.5)  \nDense(10, softmax)","4a2160de":"**dense_3**","4f2a28b1":"**KNN**","4d705a82":"# Part 6: Different Optimizers","ea0e9c3f":"### Distribution of labels \n**(in train set)**","9061b74c":"### **Conclusions on EDA**","69c0d26e":"### Check some images","9a9eac0e":"### first 10 image samples for each digit","576e7f9f":"**Outline of the kernel:**\n\n**Part 0: Imports, functions**\n\n[some useful functions](#some-useful-functions)\n\n\n**Part 1: Exploring the Data**\n\n[Distribution of labels](#Distribution-of-labels)  \n[first 10 samples for each digit](#first-10-image-samples-for-each-digit)  \n[Conclusions on EDA](#Conclusions-on-EDA) \n\n\n**Part 2: Sklearn Classifiers** \n\n[Perceptron](#Perceptron)  \n[Logistic Regression](#Logistic-Regression)  \n[KNN](#KNN)  \n[Random Forest Classifier](#Random-Forest-Classifier)  \n[Support Vector Machine Classifier](#Support-Vector-Machine-Classifier)  \n[Multi Layer Perceptron](#Multi-Layer-Perceptron)\n\n\n**Part 3: NN and CNN Classifiers with Keras**\n\n3.1 Fully-Connected Neural Networks  \n[Keras: dense, 1 hidden layer](#Keras:-1-hidden-layer)  \n[Keras: dense, 2 hidden layers](#Keras:-2-hidden-layers)  \n[Keras: dense, 3 hidden layers](#Keras:-3-hidden-layers)  \n3.2 Convolutional Neural Networks, CNN  \n[features : reshaping 1d vector to 2d images](#features-:-reshaping-1d-vector-to-2d-images)  \n[Keras: CNN, model 1](#Keras:-CNN-model-1)  \n[Keras: CNN, model 2](#Keras:-CNN-model-2)\n\n**Part 4: Predictions for test data**  \n[Fitting on all training data](#Fitting-on-all-training-data)  \n\n**Part 5: Comparing classifier performance**  \n[Validation scores](#Validation-scores)  \n[Test scores](#Test-scores)  \n\n\n**Part 6: Different optimizers**  \nadadelta  \nrmsprop  \nadam  \n\n**Part 7: Investigating false predictions**\n","461f89a5":"### Support Vector Machine Classifier","5ebd466e":"## Conclusions on classifier performance","ff2465f5":"**Random Forest**","de21c3a7":"# Part 5: Comparing classifier performance","008888cc":"# Part 2 : Sklearn Classifiers","c1bc1bc1":"# Part 0: Imports, Functions","1326c398":"**My first kernel for the MNIST Digit Recognizer Competition**  \n\nThe kernel includes an **EDA part** on the distribution of labels and some sample images for each digit.  \nWe explore how the images of handwritten digits are stored as 784 values (pixels).  \nWe transform these 784 pixels back to images of 28 x 28 (width x heigth) and have a look at possible difficulties in identifying and distinguishing certain digits.  \nThe part on **prediction modelling** starts with **classifiers from sklearn**:  \nPerceptron, Logistic Regression, Random Forest, SVM, Multi Layer Perceptron  \nand then continues to **Neural Networks with Keras**:   \nDense (1,2 and 3 layers) and CNN (Conv2D, MaxPooling, Dropout)","f9a76b61":"Adadelta","4d3aea7e":"**dense_1**","c64e47b3":"### print Classification Report and Accuracy","ca778ea6":"### Keras: 2 hidden layers","c6791a9a":"**Perceptron**","a97cd2ac":"**CNN 2**","7db66433":"Correlation of prediction results","783801be":"# Part 1 : Exploring the Data","c1a003fb":"* The 6s in row 0 1 and 6 look close to a 4  \n* The 5 in row 1 looks close to a 6 and the 5 in row 8 looks close to a 8  \n* The 4 in row 4 is wriiten differently as the other 4s and the 4 in row 7 almost looks like a 7  \n* The 8 in row 8 is wriiten differently as the other 8s  ","243f9e41":"# Part 7: Investigating false predictions","9e2da00a":"### **some useful functions**","ef1de037":"## 3.1 Fully-Connected Neural Networks  \ndense layers : every node is connected to every other node in the next layer","37db5ef9":"**dense_2**","db119d7d":"### **features : reshaping 1d vector to 2d images**\n\n(784) --> (28,28,1)","365f8744":"### Keras: CNN model 2  \nConv2D (32, (3, 3))  \nPooling2D (2,2)  \nConv2D (32, (3, 3))  \nPooling2D (2,2)  \nFlatten  \nDense(256, relu)  \nDense(10, softmax)  ","c98e6b54":"### Keras: 3 hidden layers"}}