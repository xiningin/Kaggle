{"cell_type":{"7af231ea":"code","19c15349":"code","321f8ef0":"code","b0343357":"code","037655a6":"code","bb320aa7":"code","d0730fd7":"code","89f869db":"code","1f372a46":"code","f0680cc5":"code","9778428b":"code","9141bd42":"code","c6956890":"code","b1e17974":"code","3b958e6a":"code","389cd59a":"code","ccaab149":"code","5febfb62":"code","37b52936":"code","039f6614":"code","2d37c047":"code","05ec897d":"code","1bbd8871":"code","317a7253":"code","de749d64":"code","933618bd":"code","2838350f":"code","70c5e5fc":"code","fed8fee1":"code","27f5baab":"markdown"},"source":{"7af231ea":"## References:\n\n#https:\/\/www.kaggle.com\/artgor\/pytorch-whale-identifier\n#https:\/\/www.kaggle.com\/josephvm\/kannada-pytorch-visualizations\n#https:\/\/www.kaggle.com\/bonhart\/pytorch-cnn-from-scratch\n#https:\/\/www.kaggle.com\/ateplyuk\/aptos-pytorch-starter-rnet50","19c15349":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","321f8ef0":"#!pip install albumentations > \/dev\/null 2>&1","b0343357":"###Import pytorch libraries utlis:\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision.transforms import transforms\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom PIL import Image\nimport tqdm\ntrain_on_gpu=True\n\nimport cv2\nimport albumentations\nfrom albumentations import pytorch as AT","037655a6":"## read the dataset:\ntrain=pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')\nsample_submission=pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv')\ndigits=pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/Dig-MNIST.csv')","bb320aa7":"train.head()","d0730fd7":"digits.head()","89f869db":"print(f'There are {train.shape[0]} training examples')\nprint(f'There are {digits.shape[0]} validation examples')\nprint(f'There are {test.shape[0]} test examples')","1f372a46":"train['label'].value_counts()","f0680cc5":"digits['label'].value_counts()","9778428b":"### distribution of class lables in train:\n\nplt.figure(figsize=(8,8))\nsns.countplot(train['label'])\nplt.title(\"Distribution of label in train\")\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","9141bd42":"plt.figure(figsize=(8,8))\nsns.countplot(digits['label'])\nplt.title(\"Distribution of label in validation\")\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","c6956890":"## Transforms:\n\ntrain_transform=transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(0.3),\n    transforms.ToTensor()\n])\ntest_transform=transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(0.3),\n    transforms.ToTensor()\n])","b1e17974":"class KannadaMNIST(Dataset):\n    def __init__(self,images,data=None,transform=transforms.Compose([transforms.ToTensor()])):\n        self.data=data\n        self.images=images\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self,i):\n        item=self.images.iloc[i]\n        image=item[1:].values.astype(np.uint8).reshape(28,28,1)\n        image=self.transform(image)\n        if self.data is not None:\n            label=item[0]\n            return image,label\n        else:\n            return image","3b958e6a":"train_dataset=KannadaMNIST(train,'Train',transform=train_transform)\nvalid_dataset=KannadaMNIST(digits,'Valid',transform=test_transform)\ntest_dataset=KannadaMNIST(test,transform=test_transform)","389cd59a":"train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\nvalid_loader=DataLoader(valid_dataset,batch_size=32,shuffle=True)","ccaab149":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nprint(f'Batch Image shape {images.shape}')\n\nprint(images[1].numpy().transpose((1,2,0)).shape)\nprint(labels[1].item())","5febfb62":"## Creating a simple nnet model:\n##https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0)) ## changing the shape of the image.\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n    \n    \ninputs,classes=next(iter(train_loader))\nout=torchvision.utils.make_grid(inputs)\n\nimshow(out)","37b52936":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","039f6614":"### Building the model:\n\nclass nnet(nn.Module):\n    def __init__(self):\n        super(nnet,self).__init__()\n        self.conv1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=5,padding=2) # (28,28,32)\n        self.conv1_bn=nn.BatchNorm2d(num_features=32) #\n        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2) #(14,14,32)\n        \n        self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,padding=2) # (14,14,64)\n        self.conv2_bn=nn.BatchNorm2d(num_features=64)\n        self.conv3=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2) #(14,14,128)\n        self.pool2=nn.AvgPool2d(kernel_size=2,stride=2) # (7,7,128)\n        \n        self.fc1=nn.Linear(in_features=7*7*128,out_features=1024)\n        self.fc1_batchnorm=nn.BatchNorm1d(num_features=1024)\n        self.dropout=nn.Dropout(0.5)\n        self.out=nn.Linear(in_features=1024,out_features=10)\n        \n    def forward(self,x):\n        x=self.pool1(F.relu(self.conv1_bn(self.conv1(x))))\n        x=self.pool2(F.relu(self.conv3(self.conv2_bn(self.conv2(x)))))\n        #print(x.shape)\n        x=x.view(-1,7*7*128)\n        x=F.relu(self.fc1_batchnorm(self.fc1(x)))\n        x=self.dropout(x)\n        x=self.out(x)\n        return(x)\n        ","2d37c047":"model=nnet().to(device)","05ec897d":"\noptimizer=optim.Adam(model.parameters(),lr=0.001)\n","1bbd8871":"n_epochs = 15\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n\n    for batch_i, (data, target) in enumerate(train_loader):\n        #print(batch_i)\n        data, target = data.cuda(), target.cuda()\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        train_loss.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')","317a7253":"#https:\/\/www.kaggle.com\/bonhart\/pytorch-cnn-from-scratch\nmodel.eval()  # eval mode (batchnorm uses moving mean\/variance instead of mini-batch mean\/variance)\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in valid_loader:\n        images = images.cuda()\n        labels = labels.cuda()\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy of the model on the 10240 validation images: {} %'.format(100 * correct \/ total))\n\n# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","de749d64":"test_loader=DataLoader(test_dataset,shuffle=False)","933618bd":"predict = []\nmodel.eval() ## weighted mean and variance will be used in batch norm for test\nfor i, (data) in enumerate(test_loader):\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy()    \n    predict.append(output[0])","2838350f":"sample_submission.head()","70c5e5fc":"sample_submission['label']=np.argmax(predict,axis=1)","fed8fee1":"sample_submission.to_csv('submission.csv',index=False)","27f5baab":"As per the dataset description , there is a additional dataset provided to us which we can use to validate our model before making the submission.We will use the `digits` dataset as the validation set."}}