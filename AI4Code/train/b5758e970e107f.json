{"cell_type":{"65cc6157":"code","c16cd7e0":"code","dc3d5407":"code","db36baeb":"code","d1402ddf":"code","f5573188":"code","005ce717":"code","771dd3e4":"code","dc50c1c0":"code","6f3cfccc":"code","1ef46c27":"code","c537f644":"code","6e5274cc":"code","9cb39b83":"code","27d0d67d":"code","8879d26b":"code","16fc1199":"code","b17787d9":"code","915947af":"code","feabbe19":"code","dcc72aa5":"code","4a8ebeef":"code","4e554531":"code","5099b42e":"code","93edf183":"code","675b497d":"code","b297cb70":"code","f54547c1":"code","ae9b785d":"code","9292f9ed":"code","73e8ea24":"code","58485e41":"code","6635f556":"code","e5a1b7b8":"code","e4a9570a":"code","002303c3":"code","020989ef":"code","9e5f9767":"code","e32f0cd1":"code","c44e7998":"code","545481ab":"code","152702ef":"code","9f2a21d8":"code","43e9df81":"code","08c0fe02":"code","51896b67":"code","6fc30682":"code","884c59f1":"code","b48db07f":"code","3018b861":"code","cddbaf68":"code","925e14eb":"code","76ebafb7":"code","59768c91":"markdown","db579461":"markdown","226bcb2c":"markdown","adbbb249":"markdown","acd4ce97":"markdown","3af0956c":"markdown","982aa4fa":"markdown","eb5815e1":"markdown","0ba61537":"markdown","cac3348b":"markdown","aa34ed84":"markdown","77eb38f7":"markdown"},"source":{"65cc6157":"# linear algebra\nimport numpy as np \n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd   \n\n# Input data \nimport os\nprint(os.listdir(\"..\/input\"))\n\n#Medir tiempo de ejecuci\u00f3n\nimport time\n\n#Gr\u00e1ficos de barra\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\n#Modelo\nfrom keras.layers import Input, Dense, BatchNormalization, Add, GaussianNoise, Dropout\nfrom keras.models import Model\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.layers import Wrapper\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers, initializers, optimizers\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler","c16cd7e0":"train = pd.read_csv(\"..\/input\/train.csv\")     # leyendo data de entrenamiento \ntest = pd.read_csv(\"..\/input\/test.csv\")       # leyendo data de prueba \nprint(\"Train shape: \",train.shape)            # Tama\u00f1o del data set (filas,columnas)\nprint(\"Test shape: \",test.shape)              # La columna que falta en el set test, es lo que tenemos que predecir (Survived)","dc3d5407":"#Formato de los datos del train set, podemos ver Name, sex, Parch, SibSp, Ticket Embarked y Cabin no son n\u00famericos \ntrain.info()  ","db36baeb":"#Formato de los datos del test set, podemos ver Name, sex, Parch, SibSp, Ticket Embarked y Cabin no son n\u00famericos \ntest.info()","d1402ddf":"train.head(80)","f5573188":"#Muestra la cantidad de datos que faltan por columna en el train set, especialmente en la columna Cabin \ntrain.isnull().sum() ","005ce717":"#Muestra la cantidad de datos que faltan por columna en el test set, especialmente en la columna Cabin y Age\ntest.isnull().sum()","771dd3e4":"#Funci\u00f3n auxiliar para imprimir gr\u00e1ficos de barra\ndef bar_chart(feature):\n    sobreviviente = train[train['Survived']==1][feature].value_counts()\n    muerto = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([sobreviviente,muerto])\n    df.index = ['Sobreviviente','Muerto']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","dc50c1c0":"bar_chart('Sex')","6f3cfccc":"bar_chart('Embarked')","1ef46c27":"bar_chart('Parch')","c537f644":"bar_chart('Pclass')","6e5274cc":"bar_chart('SibSp')","9cb39b83":"train.head()","27d0d67d":"#Uniendo los datos de train y test pero pre-procesarlos m\u00e1s f\u00e1cil y r\u00e1pido.\ndatostotales = [train, test]     ","8879d26b":"#Creando columna Title extrayendo el t\u00edtulo de la persona por su nombre.\nfor datatotal in datostotales:\n    datatotal['Title'] = datatotal['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","16fc1199":"#Ya que son demasiados t\u00edtulos se agrupan del 0 al 3, para ayudar a generalizar.\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor datatotal in datostotales:\n    datatotal['Title'] = datatotal['Title'].map(title_mapping)","b17787d9":"train.head() #Se puede ver como se agrego la columna \"Title\" y se mapeo a valores n\u00famericos.","915947af":"#Eliminando columna Name\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","feabbe19":"#Mapeando el sexo a valores n\u00famericos siendo male: 0 y female: 1\nsex_mapping = {\"male\": 0, \"female\": 1}\nfor datatotal in datostotales:\n    datatotal['Sex'] = datatotal['Sex'].map(sex_mapping)","dcc72aa5":"#Cambiando los valores nulos de la columna Age con la media de dicho campo agrupandolos por su edad y t\u00edtulo\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","4a8ebeef":"#train.head(30)\n#Cambiando los valores de la columna Age con la media de dicho campo agrupandolos por su edad y t\u00edtulo\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","4e554531":"#Creando intervalos para la la columna edad, para ayudar a generalizar mejor\nfor datatotal in datostotales:\n    datatotal.loc[ datatotal['Age'] <= 15, 'Age'] = 0,                           # Funcionan como un condicional\n    datatotal.loc[(datatotal['Age'] > 15) & (datatotal['Age'] <= 35), 'Age'] = 1,\n    datatotal.loc[(datatotal['Age'] > 35) & (datatotal['Age'] <= 55), 'Age'] = 2,\n    datatotal.loc[(datatotal['Age'] > 55) & (datatotal['Age'] <= 69), 'Age'] = 3,\n    datatotal.loc[ datatotal['Age'] > 69, 'Age'] = 4","5099b42e":"bar_chart('Age')","93edf183":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","675b497d":"#Reemplazando por valores nulos con S, este de utiliza como valor por defecto\nfor datatotal in datostotales:\n    datatotal['Embarked'] = datatotal['Embarked'].fillna('Q')","b297cb70":"#Mapeando en que puerto embarc\u00f3 el pasajero\nembarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor datatotal in datostotales:\n    datatotal['Embarked'] = datatotal['Embarked'].map(embarked_mapping)","f54547c1":"#Cambiando los valores nulos de la columna Fare con la media de dicho campo agrupandolos por su Pclass y Fare\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)","ae9b785d":"#Estableciendo intervalos para la tarifa del pasaje  para ayudar a generalizar mejor\nfor datatotal in datostotales:\n    datatotal.loc[ (datatotal['Fare'] <= 30), 'Fare'] = 0,\n    datatotal.loc[ (datatotal['Fare'] > 30) & (datatotal['Fare'] <= 100), 'Fare'] = 1,\n    datatotal.loc[ (datatotal['Fare'] > 30) & (datatotal['Fare'] <= 100), 'Fare'] = 2,\n    datatotal.loc[ (datatotal['Fare'] > 100), 'Fare'] = 3","9292f9ed":"train.Cabin.value_counts()","73e8ea24":"#Extrayendo la primera letra de la columna Cabin \nfor datatotal in datostotales:\n    datatotal['Cabin'] = datatotal['Cabin'].str[:1]","58485e41":"#Mapeando los datos de la columna cabina\ncabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor datatotal in datostotales:\n    datatotal['Cabin'] = datatotal['Cabin'].map(cabin_mapping)","6635f556":"#Remplazando los valores nulos de Cabin con la media de dicha columna, agrupondolos por Pclass y Cabin\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","e5a1b7b8":"#Creando una columna FamilySize que mide el n\u00famero total de parientes abordo que tenian los pasajeros\ntrain[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","e4a9570a":"#Mapeando de datos de tama\u00f1o de la familia\nfamily_size = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor datatotal in datostotales:\n    datatotal['FamilySize'] = datatotal['FamilySize'].map(family_size)","002303c3":"#Eliminando columnas Ticket, SibSp, Parch \nfeatures_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\n#Eliminando PassengerId \ntrain = train.drop(['PassengerId'], axis=1)","020989ef":"train.head()","9e5f9767":"train_dfX = train.drop('Survived', axis=1)\ntrain_dfY = train['Survived']\nsubmission = test[['PassengerId']].copy()\ntest_df = test.drop(['PassengerId'], axis=1)","e32f0cd1":"#Haciendo One Hot Enconding \ncategorical = ['Embarked', 'Title', 'Pclass', 'Fare']\nfor var in categorical:\n    train_dfX = pd.concat([train_dfX, pd.get_dummies(train_dfX[var], prefix=var)], axis=1)\n    del train_dfX[var]","c44e7998":"#Haciendo One Hot Enconding \ncategorical = ['Embarked', 'Title', 'Pclass', 'Fare'] \nfor var in categorical:\n    test_df = pd.concat([test_df, pd.get_dummies(test_df[var], prefix=var)], axis=1)\n    del test_df[var]","545481ab":"#Tama\u00f1os vectores de entrenamiento y prueba\ntest_df.shape, train_dfX.shape","152702ef":"train_dfX.head()","9f2a21d8":"test_df.head()","43e9df81":"precisiones_globales=[]\nepochs = 30 \ndef graf_model(train_history):\n    f = plt.figure(figsize=(15,10))\n    ax = f.add_subplot(121)\n    ax2 = f.add_subplot(122)\n    # summarize history for accuracy\n    ax.plot(train_history.history['binary_accuracy'])\n    ax.plot(train_history.history['val_binary_accuracy'])\n    ax.set_title('Model Accuracy')\n    ax.set_ylabel('Accuracy')\n    ax.set_xlabel('Epoch')\n    ax.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(train_history.history['loss'])\n    ax2.plot(train_history.history['val_loss'])\n    ax2.set_title('Model Loss')\n    ax2.set_ylabel('loss')\n    ax2.set_xlabel('epoch')\n    ax2.legend(['train', 'test'], loc='upper left')\n    plt.show()\ndef precision(model, registrar=False):\n    y_pred = model.predict(train_dfX)\n    train_auc = roc_auc_score(train_dfY, y_pred)\n    y_pred = model.predict(val_dfX)\n    val_auc = roc_auc_score(val_dfY, y_pred)\n    print('Train AUC: ', train_auc)\n    print('Test AUC: ', val_auc)\n    if registrar:\n        precisiones_globales.append([train_auc,val_auc])","08c0fe02":"sc = StandardScaler()\ntrain_dfX = sc.fit_transform(train_dfX)\ntest_df = sc.transform(test_df)\nprint(\"Test shape : \",test_df.shape)","51896b67":"train_dfX,val_dfX,train_dfY, val_dfY = train_test_split(train_dfX,train_dfY , test_size=0.10, stratify=train_dfY)\nprint(\"Tama\u00f1o set de Entrenamiento: \",train_dfX.shape)\nprint(\"Tama\u00f1o set de Validacion : \",val_dfX.shape)","6fc30682":"def func_model():\n    inp = Input(shape=(17,)) \n    x=Dropout(0.1)(inp)\n    x=Dense(350, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(inp)\n    x=Dropout(0.50)(x)\n    x=Dense(350, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n    x=Dropout(0.50)(x)\n    x=Dense(350, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n    x=Dropout(0.30)(x)\n    x=Dense(350, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n    x=Dropout(0.30)(x)\n    x=Dense(350, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n    x=Dropout(0)(x)\n    x=Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n    return model","884c59f1":"start_time = time.time()\nmodel = func_model()\nprint(model.summary())","b48db07f":"train_history = model.fit(train_dfX, train_dfY, batch_size=64, epochs=epochs, validation_data=(val_dfX, val_dfY))","3018b861":"graf_model(train_history)","cddbaf68":"precision(model, True)","925e14eb":"#Tiempo de ejecuci\u00f3n\nprint(\"Tiempo de ejecuci\u00f3n %s segundos\" % (time.time() - start_time))","76ebafb7":"y_test = model.predict(test_df)\nsubmission['Survived'] = np.rint(y_test).astype(int)\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)\n","59768c91":"**Se puede observar la proporci\u00f3n de los hombres que sobrevivieron es mayor que el de las mujeres.**","db579461":"Formato de los datos finales","226bcb2c":"**CREACI\u00d3N DEL MODELO**","adbbb249":"**Se puede observar que un % elevado de los pasajeros que no sobrevivieron estaban en tercera clase.**","acd4ce97":"**PRE-PROCESAMIENTO DE LOS DATOS**","3af0956c":"**Se puede observar que la mayor\u00eda de los pasajeros embarcaron en el puerto S: Southampton**","982aa4fa":"**Se puede observar que la mayor\u00eda de los pasajeros que embarcaron no tenian familiares abordo**","eb5815e1":"**Se observa que la mayor\u00eda de los pasajeros de tercera clase abordaron en el puerto Q: Queenstown.**","0ba61537":"**Se puede observar que la mayor\u00eda de los pasajeros no ten\u00edan hermanos(as) ni esposas(os) abordo, seguido por los que solo ten\u00edan 1. El n\u00famero de familiares parece estar relacionado con su supervivencia.**","cac3348b":"**AN\u00c1LISIS DE LOS DATOS**","aa34ed84":"**Podemos ver que un alto porcentaje de las persona que no sobrevivieron tiene un edad en el rango de los 27-45 a\u00f1os.**","77eb38f7":"**Datos en su formato inicial**"}}