{"cell_type":{"5af7ed78":"code","34fcf931":"code","2d2a793e":"code","20979d3e":"code","65ab0ce1":"code","566c21ff":"code","2114b968":"code","b1e5597c":"code","5ff67918":"code","8b615b32":"code","ce3eb555":"code","69c8b3f7":"code","ed87dce4":"code","adf59198":"code","253313ae":"code","b0df06d2":"code","6f23c1cc":"code","ca5801a3":"code","d0d095bd":"code","9ae0a2a7":"code","d906e458":"code","0439638a":"code","69797f50":"code","8679ed04":"code","7c340eeb":"code","e8ce8dc2":"code","59bcf729":"markdown","0f5b19a3":"markdown","c0f7ccfa":"markdown","ea55408d":"markdown","892f97e4":"markdown","2707ee22":"markdown","b29302d4":"markdown","70a9d21b":"markdown","b34f7954":"markdown","22b3dae6":"markdown","bacdb0af":"markdown","411b27e5":"markdown","9c68e741":"markdown","a4fae8ff":"markdown","d11e4079":"markdown","d2c4b885":"markdown","6d5dd233":"markdown","059bf4ff":"markdown","524a1f84":"markdown","ff26ee52":"markdown","a53770fe":"markdown","fd846992":"markdown","28bc5899":"markdown","e37c8cb1":"markdown","e4ead909":"markdown"},"source":{"5af7ed78":"import numpy as np\nimport pandas as pd\nfrom functools import reduce\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math, nltk, warnings\nfrom nltk.corpus import wordnet\nfrom sklearn import linear_model\nfrom sklearn.neighbors import NearestNeighbors","34fcf931":"import json\n\n#___________________________\ndef load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries',\n                    'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#___________________________\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#___________________\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews']\n#____________________________________\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'gross',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',\n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users'}\n#_____________________________________________________\nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n#_____________________________________________________\ndef safe_access(container, index_values):\n    # return missing value rather than an error upon indexing\/key failure\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n#_____________________________________________________\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n#_____________________________________________________\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n#_____________________________________________________\ndef convert_to_original_format(movies, credits):\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies","2d2a793e":"plt.rcParams[\"patch.force_edgecolor\"] = True\nplt.style.use('fivethirtyeight')\nmpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"last_expr\"\npd.options.display.max_columns = 50\n%matplotlib inline\nwarnings.filterwarnings('ignore')\nPS = nltk.stem.PorterStemmer()","20979d3e":"from subprocess import check_output\nprint(check_output([\"ls\",\"..\/input\/\"]))","65ab0ce1":"# load the dataset\n#credits = load_tmdb_credits(\"\/Users\/machen\/Documents\/000 MSBA\/452 Machine Learning\/HW3 TMDB MOVIE\/tmdb\/tmdb_5000_credits.csv\")\n#movies = load_tmdb_movies(\"\/Users\/machen\/Documents\/000 MSBA\/452 Machine Learning\/HW3 TMDB MOVIE\/tmdb\/tmdb_5000_movies.csv\")\ncredits = load_tmdb_credits(\"..\/input\/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"..\/input\/tmdb_5000_movies.csv\")\ndf_initial = convert_to_original_format(movies, credits)\ndf_initial = convert_to_original_format(movies, credits)\nprint('Shape:',df_initial.shape)","566c21ff":"# info on variable types and filling factor\ntab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\ntab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values'}))\ntab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()\/df_initial.shape[0]*100).T.\n                         rename(index={0:'null values (%)'}))\ntab_info","2114b968":"C = df_initial['vote_average'].mean()\nC","b1e5597c":"m = df_initial['num_voted_users'].quantile(q=0.9)\nm","5ff67918":"movies = df_initial.copy().loc[df_initial['num_voted_users']>= m]\nmovies.shape","8b615b32":"def weighted_rating(x, m=m, C=C):\n    v = x['num_voted_users']\n    R = x['vote_average']\n    # Calculation based on the IMDB formula\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","ce3eb555":"# Define a new feature 'score' and calculate its value with `weighted_rating()`\nmovies['weighted_score'] = movies.apply(weighted_rating, axis=1)","69c8b3f7":"#Sort movies based on score calculated above\nmovies = movies.sort_values(by = 'weighted_score', ascending=False, axis = 0)\n\n#Print the top 10 movies\nmovies[['movie_title','weighted_score','title_year','director_name']].head(10)","ed87dce4":"df_initial['genres'] = df_initial['genres'].str.split('|')\ndf_initial['plot_keywords'] = df_initial['plot_keywords'].str.split('|')","adf59198":"features = ['genres', 'plot_keywords', 'director_name', 'actor_1_name','actor_2_name','actor_3_name']\ndf_initial[features].head()","253313ae":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    #for genres and plot_keywords\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #for director, actors\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","b0df06d2":"# Apply clean_data function to your features.\nfor feature in features:\n    df_initial[feature] = df_initial[feature].apply(clean_data)","6f23c1cc":"df_initial[features].head()","ca5801a3":"# Function to join all attributes\ndef create_soup(x):\n    return ' '.join(x['plot_keywords']) + ' ' + ' '.join(x['actor_1_name']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['genres'])+ ' ' + ' '.join(x['actor_2_name'])+ ' ' + ' '.join(x['actor_3_name'])","d0d095bd":"# Apply create_soup function to your df\ndf_initial['soup'] = df_initial.apply(create_soup, axis =1)\ndf_initial['soup'].head()","9ae0a2a7":"# Import CountVectorizer and create the count matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(df_initial['soup'])","d906e458":"# Compute the Cosine Similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim1 = cosine_similarity(count_matrix, count_matrix)","0439638a":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english')\n\n#Replace NaN with an empty string\ndf_initial['overview'] = df_initial['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(df_initial['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape\n\n# Import linear_kernel\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","69797f50":"# Reset index of our main DataFrame and construct reverse mapping as before\ndf_initial = df_initial.reset_index()\nindices = pd.Series(df_initial.index, index=df_initial['movie_title'])\nindices.head()","8679ed04":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return df_initial['movie_title'].iloc[movie_indices]","7c340eeb":"get_recommendations('The Shawshank Redemption')","e8ce8dc2":"get_recommendations('The Shawshank Redemption',cosine_sim1)","59bcf729":"### 3.2.2 Use Overview (Plot)","0f5b19a3":"## 1. Objective\nIn this notebook, we aim to analyze moving rating data provided by TMDB and build up a movie recommendation engine.\n\nGenerally speaking, three methods are widely adopted in building up recommendation system, and they are often combined due to the attributes of each method.For TMDB dataset, we will mainly use Popularity-based and Content-based methods. We will do Collaboratie-filtering with another dataset.\n1. Popularity-based recommendation\n2. Content-based recommendation\n3. Collaboratie-filtering recommendation","c0f7ccfa":"The next step is to determine an appropriate value for m, the minimum votes required to be listed in the chart. We will use 90th percentile as our cutoff. In other words, for a movie to feature in the charts, it must have more votes than at least 90% of the movies in the list.","ea55408d":"#### Disadvantages\n\n**1. Hard to extract attributes** Extract attributes to represent items is challenging, for example we can use director, actors, genres to represent a movie, but these are only part of information.\n\n\n**2. Can not find potential user interest** CB will only recommend movies similar to the ones user has already watched. It can not uncover user's potential interest.\n\n\n**3. Can deal with new user \"cold-start\" issue** New user do not have preference data, hence no recommendations can be made with CB.","892f97e4":"**Advantages**\n1. Can be used to solve \"cold-start\" issue, meaning recommending movies for new users, where user-level preference information is missing.\n\n**Disadvantages**\n1. Can not make personalized recommendation, though combinded with cookie information, it can make recommendations like \"what's popular around\".\n2. Can not make minority recommendation. Moives with high rating but small number of ratings do not stand out in this algorithum.\n\n**Improvements**\n1. The formula does not take **recent pupularity trend** into consideration. Some movies which have been on shelf for a long time such as The Shawshank Redemption(1994), have accumulate large amounts of votes, compared with newly released movies. If we want to recommend more popular movies to viewers, the more recent a rating is, the higher weight is has.","2707ee22":"## 2. Data Preprocessing","b29302d4":"### 2.2 Missing Values","70a9d21b":"#### Recommendation for movie \"The Shawshank Redemption\" based on plot similarity:","b34f7954":"## 3. Recommendation Systems","22b3dae6":"#### Convert the collection of text documents, to a matrix of token counts","bacdb0af":"# TMDB movie rating","411b27e5":"### 2.1 Data Loading\nThe codes used for data loading belongs entirely to https:\/\/www.kaggle.com\/fabiendaniel\/film-recommendation-engine\/data","9c68e741":"TF-IDF is widely used as the last pre-processing step in NLP. It identifies word frequency, reduces the impact of the words that are more common in the corpus, and transforms text data into matrix for modelling.\n\nBroadly speaking, if a word occurs many times in a document it is likely to be important. However, if it also appears frequently across multiple documents then it may just be a common word and not in fact very meaningful.\u00a0","a4fae8ff":"Filter the movies qualified for number of votes(votes > 1838)","d11e4079":"#### Recommendation for movie \"The Shawshank Redemption\" based on genre\/keyword\/director\/actors similarity:","d2c4b885":"#### Advantages\n\n**1. User independence** CB is based entirely on one user's preference and the attributes of all items. It's independent of other users' preference. Hence no matter how other people cheat on item preference(like brushing tickets), the recommendation stays unchanged. While Collaborative-filtering relies entirely on other users' preference.\n\n**2. Interpretability** Easy to interpret and explain to non-tech people.\n\n**3. Can deal with new item \"cold-start' issue** If a new item is added to the database, it has the same chance as existing items to be recommended to user. Hence it can deal with new item cold-start issue. While Collaborative-filtering will not recommend a new item until it has been rated by some user.  \n","6d5dd233":"Now, we need to calculate our metric for each qualified movie. To do this, we will define a function, weighted_rating() and define a new feature score, of which we'll calculate the value by applying this function to our DataFrame of qualified movies:","059bf4ff":"We already have v(vote_count) and R (vote_average) and C can be calculated as\uff1a","524a1f84":"### 3.2 Content-Based Filtering Recommendation","ff26ee52":"### 3.2.3 Recommendation based on cosine similarity","a53770fe":"#### Data preprocessing: \n- remove \"|\" for genres and plot keywords;\n- strip space between first name and last name, because we want the model to treat first name and last name as whole.","fd846992":"### 3.2.1 Use keywords, Genres, Director, Actors","28bc5899":"### 3.1 Demographic Filtering Recommendation\nIn order to demonstate how a movie is liked by users, vote average and number of voted users are combined to formulate a new metric. The formula is used by IMDB (https:\/\/www.kaggle.com\/ibtesama\/getting-started-with-a-movie-recommendation-system)\n![image.png](attachment:image.png)","e37c8cb1":"Finally, let's sort the DataFrame based on the score feature and output the title, vote count, vote average and weighted rating or score of the top 10 movies.","e4ead909":"Content-based filtering is to recommend new items similar to previous item that has already been liked by user.\n\n#### Generally, the construction of a content-based filtering consists of the following three steps: \n\n**1. Establish item profile**\n\nCollect attributes that can be used to describe items and distinguish between items. Use 0-1 matrix to represent whether a item has the attribute. For example, for movie director, we can collect all directors as attributes. For a spcific movie like \"Matrix\", denote 1 for \"Lana Wachowski\" and \"Lilly Wachowski\", 0 for other directors.\n\n**2. Establish user profile**\n\nThis process is similar to establishing item profile, except for user preference for a attribute is calculated by the average rating of items with the attribute. For example, user's preference for director \"Lana Wachowski\" is the average of all movies directed by \"Lana Wachowski\", which have been watched by the user.\n\n**3. Calculate similarity between item and user**\n\nCalculate similarity based on distance definition like cosine, L2. And recommend items which have the smallest distance from user.\n\n\nFor TMDB data, we're going to establish content-based recommendation with genres, directors, actors, and movie keywords."}}