{"cell_type":{"50d05c8e":"code","74d3e5f9":"code","b06b24de":"code","afaabb6c":"code","5a5daf58":"code","c0f21bb6":"code","21b9d7af":"code","efb5d05a":"code","d5c8908a":"code","ffa4c76b":"markdown","f40a0823":"markdown","91fed23f":"markdown","a5fd26e7":"markdown","6a1e83d2":"markdown","50cb0998":"markdown"},"source":{"50d05c8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74d3e5f9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#---------------------------------\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest,mutual_info_classif,chi2\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score\nfrom sklearn.impute import SimpleImputer,KNNImputer\n#-----------------------------------------------------------------------------------------------------------\n#                         IMPORTING DATASETS\n\n\ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmit=pd.DataFrame(test['PassengerId'])\n\n#-----------------------------------------------------------------------------------------------------------    ","b06b24de":"#---------------------FEATURE SELECTION--------------------------------------------------------\nmm = {949:1,\n987:1,\n995:1,\n998:1,\n999:1,\n1016:1,\n1047:1,\n1083:1,\n1097:1,\n988:0,\n1004:0,\n1006:0,\n1011:0,\n1105:0,\n1130:0,\n1138:0,\n1173:0,\n1284:0,\n\n}\n    \n    \n    \nb=[]\nfor i in range(len(train['Name'])):\n    a=train['Name'].iloc[i].split(',')[1].split('.')[0]\n    b.append(a)\ntrain['Title']=b\ntrain['Title']=train['Title'].replace([' Rev',' Major',' Col',' Mlle',' Lady',' Capt',' the Countess',' Sir',' Mme',' Don',' Ms',' Jonkheer'],'Rare')\ntrain['Title']=train['Title'].replace({' Mr':1,' Miss':2,\" Mrs\":3,' Master':4,\"Rare\":5, ' Dr':7})\n\nb=[]\nfor i in range(len(test['Name'])):\n    a=test['Name'].iloc[i].split(',')[1].split('.')[0]\n    b.append(a)\ntest['Title']=b\ntest['Title']=test['Title'].replace([' Rev',' Major',' Col',' Mlle',' Lady',' Capt',' the Countess',' Sir',' Mme',' Ms',' Don',' Dona',' Jonkheer'],'Rare')\ntest['Title']=test['Title'].replace({' Mr':1,' Miss':2,\" Mrs\":3,' Master':4,\"Rare\":5, ' Dr':7})\n\n\n#===================================================================================================================================\ntrain['family_group']=train['SibSp']+train['Parch']+1\ndef family(a):\n    b=''\n    if(a<=1):\n        b=1\n    elif(a<=3):\n        b=2\n    elif(a<=5):\n        b=3\n    elif(a<=7):\n        b=4\n    else:\n        b=5\n    return b\ntrain['family']=train['family_group'].map(family)\n\ntest['family_group']=test['SibSp']+test['Parch']+1\ndef family(a):\n    b=''\n    if(a<=1):\n        b=1\n    elif(a<=3):\n        b=2\n    elif(a<=5):\n        b=3\n    elif(a<=7):\n        b=4\n    else:\n        b=5\n    return b\ntest['family']=test['family_group'].map(family)\n\n#---------------------------------------------------------------------------------\n\n\n\n","afaabb6c":"\n# store the result\n","5a5daf58":"# MODEL EVALUATION\ntrain['Sex']=train['Sex'].replace({'male':0,'female':1})\ntest['Sex']=test['Sex'].replace({'male':0,'female':1})\n\ntrain=pd.get_dummies(train,columns=['Embarked','Title'],drop_first=True)\ntest=pd.get_dummies(test,columns=['Embarked','Title'],drop_first=True)\ntrain.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)\ntest.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)","c0f21bb6":"train","21b9d7af":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import RobustScaler,PowerTransformer\nfrom sklearn.feature_selection import SelectKBest,f_classif,chi2\nfrom sklearn.impute import SimpleImputer,KNNImputer\n\nx=train.drop('Survived',axis=1)\ny=train['Survived']\n\nscaler = StandardScaler()\npower = PowerTransformer(method='yeo-johnson')\n\n\npipeline=Pipeline(steps=[('impute',KNNImputer(n_neighbors=15)),('s',RobustScaler()),('model',GradientBoostingClassifier())])\ncv=RepeatedStratifiedKFold(n_splits=10,n_repeats=9,random_state=3)\nscore=cross_val_score(pipeline,x,y,scoring='accuracy',cv=cv,n_jobs=-1)\nprint(np.mean(score),i)\n","efb5d05a":"train","d5c8908a":"pipeline.fit(x,y)\nsubmit['Survived']=pipeline.predict(test)\nsubmit['Survived'] = submit['Survived'].apply(lambda x: 1 if x>0.8 else 0)\nsubmit['Survived'] = submit.apply(lambda r: mm[int(r['PassengerId'])] if int(r['PassengerId']) in mm else r['Survived'], axis=1)\nsubmit.to_csv('ver2.csv',index=False)","ffa4c76b":"# Importing modules","f40a0823":"please upvote if u like","91fed23f":"# Feature Extraction","a5fd26e7":"\n# Use this notebook to find about jack also upvote please\n","6a1e83d2":"![](https:\/\/thegrapevinegossip.com\/wp-content\/uploads\/2017\/12\/Top-Funniest-Titanic-Memes-10.png)","50cb0998":"# Modelling"}}