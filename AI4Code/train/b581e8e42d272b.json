{"cell_type":{"c0168743":"code","218989c9":"code","a4d08138":"code","5d421a1e":"code","ae6d4345":"code","c7f5c3d8":"code","9dcf080c":"code","3f319200":"code","66febcfe":"code","69a632dd":"code","2c40edc3":"code","a7807f1b":"code","22e14b19":"code","d91de5de":"code","14b68b21":"code","e150354d":"code","37f0b877":"code","a6408075":"code","3b4195f0":"markdown","c28f580d":"markdown","0037d0d0":"markdown","c208d7a9":"markdown","de5ae2ff":"markdown","64b09208":"markdown","3127ea39":"markdown","66b5c5ab":"markdown","55c68214":"markdown"},"source":{"c0168743":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","218989c9":"# Importing the datasets\ntraining_set = pd.read_csv(\"..\/input\/train.csv\")\ntest_set = pd.read_csv(\"..\/input\/test.csv\")\ntraining_set.head(20)","a4d08138":"test_set.head(20)","5d421a1e":"# Display the number of missing values for each feature(column)\ntraining_set.isnull().sum()","ae6d4345":"test_set.isnull().sum()","c7f5c3d8":"# Create Matrix of Features(Training set)\nX_train = training_set.iloc[:, [2,4,5,6,7]].values # Pclass, Sex, Age, SibSp, Parch\n\n# Create Dependent Variable Vector(Training set)\ny_train = training_set.iloc[:, 1].values # Survived\n\n# Create Matrix of Features(Test set)\nX_test = test_set.iloc[:, [1,3,4,5,6]].values # Pclass, Sex, Age, SibSp, Parch\n\n# No y_test as I'm not given the \"survived\" feature in the test set as this is a competition\n\n# Take care of missing values in Age for both Training Set and Test Set\nfrom sklearn.impute import SimpleImputer\nimputer_train = SimpleImputer(strategy = 'mean')\nimputer_test = SimpleImputer(strategy = 'mean')\n\n# Training Set\nimputer_train = imputer_train.fit(X_train[:, 2:3]) # Fit Age column to imputer\nX_train[:, 2:3] = imputer_train.transform(X_train[:, 2:3]) # Convert NaN's to mean of whole column\n\n# Test Set\nimputer_test = imputer_test.fit(X_test[:, 2:3]) # Fit Age column to imputer\nX_test[:, 2:3] = imputer_test.transform(X_test[:, 2:3]) # Convert NaN's to mean of whole column\n\n# Couldn't easily find a built in numpy way to compute this so I just made my own function to count how many NaN's are in the imputed X_train ndarray\ndef numMissing(X_train):\n    num_nans = 0\n    for y in X_train:\n        if y[2] == np.nan:\n            count = count + 1\n    return num_nans\n\nprint(\"Training Set: Number of missing values in age: {}\".format(numMissing(X_train)))\nprint(\"Test Set: Number of missing values in age: {}\".format(numMissing(X_test)))\n","9dcf080c":"X_train","3f319200":"X_test","66febcfe":"# Encoding categorical data for X_train\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# Label Encode Sex feature in X_train and X_test\nlabelencoder_train_sex = LabelEncoder()\nX_train[:, 1] = labelencoder_train_sex.fit_transform(X_train[:, 1])\nlabelencoder_test_sex = LabelEncoder()\nX_test[:, 1] = labelencoder_test_sex.fit_transform(X_test[:, 1])\n\n# OneHotEncode X_train\nonehotencoder_train = OneHotEncoder(n_values = 'auto', categories = 'auto')\nX_train = onehotencoder_train.fit_transform(X_train[:, [0,1,3,4]]).toarray()\n\n# OneHotEncode X_test\nonehotencoder_test = OneHotEncoder(n_values = 'auto', categories = 'auto')\nX_test = onehotencoder_test.fit_transform(X_test[:, [0,1,3,4]]).toarray()\n\n# Print shape\nprint(\"X_train shape: {}\".format(X_train.shape))\nprint(\"X_test shape: {}\".format(X_test.shape))","69a632dd":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","2c40edc3":"X_train","a7807f1b":"X_test","22e14b19":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)","d91de5de":"y_pred = classifier.predict(X_test)","14b68b21":"submission = pd.DataFrame({\n    \"PassengerId\": test_set[\"PassengerId\"],\n    \"Survived\": y_pred\n})","e150354d":"submission.shape","37f0b877":"submission","a6408075":"submission.to_csv('survive_or_not.csv')\nprint(os.listdir(\"..\/working\"))","3b4195f0":"**Exploratory Analysis**\n\nLet's take a look at the dataset.  Here are notes on the dataset as provided by Kaggle:\n\nVariable: Definition Key\nsurvival: Survival\t0 = No, 1 = Yes\n\npclass:\tTicket class:\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex: Sex\t\nAge: Age in years\t\nsibsp:\t# of siblings \/ spouses aboard the Titanic\t\nparch:\t# of parents \/ children aboard the Titanic\t\nticket:\tTicket number\t\nfare: Passenger fare\t\ncabin: Cabin number\t\nembarked: Port of Embarkation:\tC = Cherbourg, Q = Queenstown, S = Southampton\n\nVariable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","c28f580d":"I am attempting to predict the survival of each passenger based on the independent variables in the dataset of which there are 11.  Some of these 11 have no relationship or correllation to the dependent variable \"Survived\".  At first glance these apear to be: PassengerId, Name, Ticket, Fare, and Embarked.  This leaves us with Pclass, Sex, Age, SibSp, Parch, and Cabin as usable IV's.   ","0037d0d0":"**Predict Test Set**","c208d7a9":"Age has now been dealt with","de5ae2ff":"**Split the data into the Training Set and the Test Set**","64b09208":"**Encoding Categorical Data**\n\nMissing data has been dealt with, now the categorical data must be encoded.  The Matrix of Features X_train contains 5 features: Pclass, Sex, Age, SibSp, and Parch.  \n* Pclass is already in a numerical format, but one is not necessarily better than the other for survival, so it must be One Hot Encoded\n* Sex is either Male or Female, so it must be Label Encoded first and then One Hot Encoded\n* Age is already in a numerical format, and fine the way it is\n* SibSp and Parch are in a numerical format, but one or the other value  is not necessarily better for survival, so it must be One Hot Encoded.\n\ny_train does not need any adjusting as it is only if they survived or not which is either 0 or 1.\n\nThe same encoding will be done for X_test as well","3127ea39":"**Fitting Logistic Regression to the Training Set**","66b5c5ab":"**Feature Scaling**","55c68214":"I am not using Embarked so 2 missing values does not matter.  Therefore, Age and Cabin are the only variables to be considered.  For age I will fill the missing values with the mean age.  I do not know the format for the cabin identifier and cannot fill in the missing values, so I will leave the variable out of the model.\n1. First I will split the dataset into the matrix of features and the dependent variable vector.\n2. Secondly, I will take care of the missing data in Age with the mean of the column"}}