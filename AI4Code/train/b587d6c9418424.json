{"cell_type":{"b89508eb":"code","f402b1e0":"code","0032d1f7":"code","3e7ab40a":"code","50da41ab":"code","a0b66c9a":"code","db251c0d":"code","2731f0b3":"code","7726b96d":"code","6e2a05d3":"code","9c5c744a":"code","0204fc71":"code","bf6f013b":"code","042255be":"code","1f137675":"code","df6fbce3":"code","e87a6d5c":"code","f8680260":"code","2116565e":"code","6651039e":"code","bca33eb0":"code","f7b9c910":"code","f11bf25c":"code","ef4dc5e7":"code","5d4bfad4":"code","9d37edf5":"code","7cb74bd3":"code","2d0a6561":"code","dc0eec25":"code","c8546219":"code","ebeac5f9":"code","169efe28":"code","696c362b":"code","45e8d980":"code","d9584c2c":"markdown","dcaf0a6c":"markdown","c95db95f":"markdown","1312af09":"markdown","c273584c":"markdown","b9f84438":"markdown","51ce8df2":"markdown","5b5f1ef1":"markdown","8673588e":"markdown","803fa796":"markdown"},"source":{"b89508eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f402b1e0":"filepath='..\/input\/for-simple-exercises-time-series-forecasting\/Alcohol_Sales.csv'\ndata=pd.read_csv(filepath, index_col='DATE', parse_dates=True)\ndata['sales']=data['S4248SM144NCEN']\ndata.head()","0032d1f7":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style='darkgrid')\n%matplotlib inline\n","3e7ab40a":"data.tail()","50da41ab":"data['sales'].plot(figsize=(16,8))","a0b66c9a":"data['date']=data.index\ndata['month']=data['date'].dt.month\ndata['year']=data['date'].dt.year\ndata.drop('date', axis=1, inplace=True)\ndata.head()","db251c0d":"plt.figure(figsize=(16,8))\ndata.groupby('year')['sales'].mean().plot.bar()\nplt.show()","2731f0b3":"plt.figure(figsize=(16,8))\ndata.groupby('month')['sales'].mean().plot.bar()\nplt.show()","7726b96d":"\ndata.groupby(['year','month'])['sales'].mean().plot(figsize=(16,8))\nplt.show()","6e2a05d3":"monthly=data.resample('m').mean()\nyearly=data.resample('y').mean()","9c5c744a":"fig, axs= plt.subplots(2,1)\nmonthly['sales'].plot(figsize=(16,8), title='Monthly',fontsize=12, ax=axs[0])\nyearly['sales'].plot(figsize=(16,8), title='Yearly', fontsize=12,  ax=axs[1])\nfig.tight_layout()\nplt.show()","0204fc71":"data.shape","bf6f013b":"train=data.loc[:'2011-12-01']\nvalid=data.loc['2011-12-01':]","042255be":"train.shape, valid.shape","1f137675":"train.head()","df6fbce3":"plt.figure(figsize=(16,8))\ntrain['sales'].plot(kind='line',color='blue',label='train')\nvalid['sales'].plot(kind='line', color='orange',label='valid')\nplt.legend(loc='best')\nplt.show()","e87a6d5c":"y_pred = valid.copy()\ny_pred['movig_avg']=valid['sales'].rolling(6).mean().iloc[-1]\ntrain['sales'].plot(figsize=(16,8), color='blue', label='Train')\nvalid['sales'].plot(figsize=(16,8), color='orange', label='Valid')\ny_pred['movig_avg'].plot(figsize=(16,8), color='green', label='Moving Averages')\nplt.legend(loc='best')\nplt.show()","f8680260":"from sklearn.metrics import mean_squared_error \nfrom math import sqrt \nrms = sqrt(mean_squared_error(valid.sales, y_pred['movig_avg'])) \nprint(rms)","2116565e":"import statsmodels.api as sm\nsm.tsa.seasonal_decompose(train['sales']).plot() \nresult = sm.tsa.stattools.adfuller(train.sales)\nfig.tight_layout()\nplt.show()","6651039e":"print(result)","bca33eb0":"from statsmodels.tsa.api import Holt\npred_y=valid.copy()\nfit1= Holt(np.asarray(train['sales'])).fit(smoothing_level= 0.3, smoothing_slope= 0.01)\npred_y['holt']=fit1.forecast(len(valid))","f7b9c910":"plt.figure(figsize=(16,8))\ntrain['sales'].plot(color='blue', label='Train')\nvalid['sales'].plot(color='orange', label='valid')\npred_y['holt'].plot(color='green', label='Holt')\nplt.legend(loc='best')\nplt.show()","f11bf25c":"np.sqrt(mean_squared_error(valid.sales, pred_y['holt']))","ef4dc5e7":"from statsmodels.tsa.stattools import adfuller","5d4bfad4":"def test_stationarity(data):\n    rolmean=data.rolling(window=12).mean()\n    rolstd=data.rolling(window=12).std()\n    plt.plot(data, color='blue', label='original')\n    plt.plot(rolmean, color='red', label='Rolling Mean')\n    plt.plot(rolstd, color='black', label='Rolling std')\n    plt.legend(loc='best')\n    plt.show()\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(data, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    \n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","9d37edf5":"from matplotlib.pylab import rcParams \nrcParams['figure.figsize'] = 20,10\ntest_stationarity(train['sales'])","7cb74bd3":"train_log=np.log(train['sales'])\nplt.figure(figsize=(16,8))\nmov_avg=train_log.rolling(12).mean()\nplt.plot(train_log,label='log')\nplt.plot(mov_avg,label='mov_avg')\nplt.legend(loc='best')\nplt.show()","2d0a6561":"train_log_mov_avg_diff=train_log-mov_avg\ntrain_log_mov_avg_diff.dropna(inplace=True)\ntest_stationarity(train_log_mov_avg_diff)","dc0eec25":"#Train Log diffrence\ntrain_log_diff= train_log - train_log.shift(1)\ntrain_log_diff.fillna(0,inplace=True)\ntest_stationarity(train_log_diff)","c8546219":"from statsmodels.tsa.stattools import acf, pacf \nlag_acf = acf(train_log_diff.dropna(), nlags=25) \nlag_pacf = pacf(train_log_diff.dropna(), nlags=25, method='ols')","ebeac5f9":"plt.plot(lag_acf) \nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96\/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96\/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Autocorrelation Function') \nplt.show() \nplt.plot(lag_pacf) \nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96\/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray') \nplt.axhline(y=1.96\/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray') \nplt.title('Partial Autocorrelation Function') \nplt.show()","169efe28":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(train_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(train_log_diff.dropna(),  label='original') \nplt.plot(results_ARIMA.fittedvalues, color='red', label='predicted') \nplt.legend(loc='best') \nplt.show()","696c362b":"def check_prediction_diff(predict_diff, given_set):\n    predict_diff= predict_diff.cumsum().shift().fillna(0)\n    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['sales'])[0], index = given_set.index)\n    predict_log = predict_base.add(predict_diff,fill_value=0)\n    predict = np.exp(predict_log)\n\n    plt.plot(given_set['sales'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['sales']))\/given_set.shape[0]))\n    plt.show()","45e8d980":"ARIMA_predict_diff=results_ARIMA.predict(start=\"2011-12-01\", end=\"2019-01-01\")\ncheck_prediction_diff(ARIMA_predict_diff, valid)","d9584c2c":"Here we observe an increasing trend in data, this can validate our hypothesis that as year increases sales increases","dcaf0a6c":"Since Test statistics < critical values so we can assume that series is stationary, but the constant moving average confirms our assumptions that series is stationary","c95db95f":"## ARIMA Model","1312af09":"For good forcasting we have to remove trend from time-series data\n1. Using log to penalise increasing trend\n2. using shift diffrence to reduce trend\n3. making mean and covariance constant","c273584c":"1. This plot confirms hypothesis that sales increase as year increases.\n2. In year 2019 sales is less because we have only first month (january) data.\n\n","b9f84438":"As we can see that month of may - june have high sales and also december have high sales may be of christmas and newyear","51ce8df2":"Hypothesis:\n1. Months with festivals may have more sales \n2. Weekends may have more no. of sales\n3. As year increases sales may increase","5b5f1ef1":"## Holt's linear model for trend","8673588e":"### Moving Average of last 12 observations","803fa796":"As we seen that time series becomes more stable as we aggregate from monthly to yearly"}}