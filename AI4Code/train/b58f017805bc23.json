{"cell_type":{"77892564":"code","26b4ce14":"code","ccc68997":"code","62df2869":"code","00d53722":"code","54d6d507":"code","d3da3201":"code","c7e12244":"code","a8b86c47":"code","e748a947":"code","186c81ea":"code","e0e63a56":"code","71362bab":"code","8eb00044":"markdown","eecce350":"markdown","191b533b":"markdown","cf51334c":"markdown","9e239334":"markdown","a9dffbee":"markdown","c77da203":"markdown","1a734fb8":"markdown","7b3e81a8":"markdown"},"source":{"77892564":"#Importing Basic ML Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Now we load our training and test datasets in order to visualise and know our features better.\n#train = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\titanic problem\\New folder\\train.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n","26b4ce14":"#We visualise our data.\ntrain","ccc68997":"test\n","62df2869":"#clubbing the test and training data\ndf = pd.concat((train, test), axis = 0)","00d53722":"#NAN Values\ndf.info()\n","54d6d507":"sns.heatmap(df.isnull(), yticklabels = False, cbar = False)","d3da3201":"# Replacing NAN values with either mean values or mode values. \n# Also Feature 'Cabin' has only 295 non null values out of 1309, so we basically drop the whole column for now.\ndf = df.drop(['Cabin'], axis = 1)\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\ndf[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].mean())\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\n","c7e12244":"sns.heatmap(df.isnull(), yticklabels = False, cbar = False)","a8b86c47":"#Nominal Categorical Data\ncol = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\ndef one_hot_encod(col, df):\n    j = 0\n    df_final = df\n    for i in col:\n        df1 = pd.get_dummies(df[i], drop_first = True)\n        df.drop([i], axis = 1, inplace= True)\n        \n        if j == 0:\n            df_final = df1\n        else:\n            df_final = pd.concat((df_final, df1), axis = 1)\n        j += 1\n    df_final = pd.concat((df_final, df), axis = 1)\n    return df_final\nfinal_df = one_hot_encod(col, df)    \n    ","e748a947":"final_df\n","186c81ea":"df[\"Ticket\"].value_counts()\n","e0e63a56":"final_df = final_df.drop([\"Name\"], axis = 1)\nfinal_df = final_df.drop([\"Ticket\"], axis = 1)\nfinal_df","71362bab":"# Now we split our training and test datasets as we have done basic Data Cleaning to be used in our model.\n\nclean_train = final_df.iloc[:len(train)]\nclean_test = final_df.iloc[len(train):]\nclean_train.to_csv(r\"C:\\Users\\hp\\Desktop\\titanic problem\\New folder\\Notebook\\clean_train.csv\", index = False)\nclean_test.to_csv(r\"C:\\Users\\hp\\Desktop\\titanic problem\\New folder\\Notebook\\clean_test.csv\", index = False)\n","8eb00044":"## This Notebook will focus on Data Cleaning and Preprocessing.","eecce350":"### So There is no NAN values left.\n\n### Now we need to take care of the categorical data.\n### col = (Pclass, Sex, SibSp, Parch, Embarked) are the features which contain categorical data.\n### Note that there are two kind of Categorical Data: Nominal and Ordinal data. All these column are Nominal Categorical Data.\n### We deal with Nominal Data By creating Dummmy variables which are binary columns basically.","191b533b":"### Note that while creating dummy variables and using get_dummies method, we use a parameter drop_first = True. What it does is that it creates k-1 dummies for K categories. For eg: for Sex, we had two categories male and female. so it removed female dummy column and wherever it is 0 for male, it is automatically assumed it is female.","cf51334c":"### So 4 features contain NAN values with them.\n### lis = ('Age', 'Fare, 'Cabin', 'Embarked')\n### Now we visualise with a heat map too.","9e239334":"### In our data we have 11 different features and we have to classify whether a person survived or not based on these.\n\n### Now first of all we have to do Data Cleaning and Data Preprocessing. It considers the following:\n### i) Dealing with missing values or NAN values.\n### ii) converting textual data into a format that can be deployed in our model.\n### iii) Handling Categorical data.\n\n### Before we do that we need to combine the Test and Training Datasets so that we can apply all the changes to them simultanously and won't have to do it twice","a9dffbee":"#                                         TITANIC PROBLEM KAGGLE\n\n### This is a Classifier Supervised Machine Learning Project in which we have to successfully identify whether a person survived the Titanic Ship tragedy or not, given features about them such as their name, age, sex, ticket fare, cabin, etc.","c77da203":"### This is a code only for Data Cleaning and basic data Preprocessing. If you like the code please upvote it.","1a734fb8":"### So we see that there is no specific order within the Ticket column. So we discard it for now for our initial iteration. Also Name column should also be droped for our initial iteration. ","7b3e81a8":"### Now we deal with textual and mix data.\n### In this problem only Name and Ticket columns are of textual type left. Rest all columns are dealt with."}}