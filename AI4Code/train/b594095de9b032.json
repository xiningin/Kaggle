{"cell_type":{"f2671615":"code","ef418899":"code","5c4f5499":"code","d832a4e3":"code","ec191f12":"code","5dd0d335":"code","a0fae9f7":"code","ddef2e5c":"code","49b2923e":"code","c1e062b6":"code","e53911ae":"code","1e0c74f1":"markdown","945aeda7":"markdown","fe29ac3f":"markdown"},"source":{"f2671615":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef418899":"import pandas as pd","5c4f5499":"df = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.dropna()\ndf.describe()","d832a4e3":"df.corr()","ec191f12":"df.columns","5dd0d335":"features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']\nX = df[features]\ny = df['quality']","a0fae9f7":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)","ddef2e5c":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression","49b2923e":"k3 = KNeighborsRegressor(n_neighbors=3)\nk5 = KNeighborsRegressor(n_neighbors=5)\nk10 = KNeighborsRegressor(n_neighbors=10)\nk30 = KNeighborsRegressor(n_neighbors=10)\nk50 = KNeighborsRegressor(n_neighbors=50)\n\nk3.fit(X_train, y_train)\nk5.fit(X_train, y_train)\nk10.fit(X_train, y_train)\nk30.fit(X_train, y_train)\nk50.fit(X_train, y_train)","c1e062b6":"print(f'K = 3 train_score {k3.score(X_train,y_train)} & test_score {k3.score(X_test, y_test)}')\nprint(f'K = 5 train_score {k5.score(X_train,y_train)} & test_score {k5.score(X_test, y_test)}')\nprint(f'K = 10 train_score {k10.score(X_train,y_train)} & test_score {k10.score(X_test, y_test)}')\nprint(f'K = 30 train_score {k30.score(X_train,y_train)} & test_score {k30.score(X_test, y_test)}')\nprint(f'K = 50 train_score {k50.score(X_train,y_train)} & test_score {k50.score(X_test, y_test)}')","e53911ae":"linear_model = LinearRegression()\n\nlinear_model.fit(X_train, y_train)\n\nprint(f'intercept found is {linear_model.intercept_} and coef found in {linear_model.coef_}')\nprint(f'train_score {linear_model.score(X_train, y_train)} and test_score {linear_model.score(X_test, y_test)}')","1e0c74f1":"test score of linear_model is better that KNNRegression","945aeda7":"KNNRegression vs LinearRegression\n\n1. KNeighborsRegressor. Testing with k=3, k=5, k=10","fe29ac3f":"When k = 10 it gives best score of 0.1615997382172184 and for k>50 it decreases. So best value for k is 10"}}