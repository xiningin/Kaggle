{"cell_type":{"bc54ad4f":"code","f161aa90":"code","3748e86b":"code","95b3b4fe":"code","15e6c4fd":"code","899039a1":"code","2496d217":"code","ebc480e3":"code","b9e2e978":"code","1184692e":"code","63eb1fb5":"code","c5956070":"code","409e28cb":"code","c35e84ae":"code","b0f87975":"code","309da5eb":"code","bdeefef2":"code","d1725a05":"code","388b992c":"code","30fa9f07":"markdown","66895018":"markdown","f521afea":"markdown","8ff626ba":"markdown","52dcf80e":"markdown","ba79824e":"markdown","065b4d5f":"markdown","7c54143d":"markdown","0ce8e4c4":"markdown","4d238920":"markdown","17d38698":"markdown","1f4e8bcf":"markdown","2df65d9d":"markdown","5c47fa9b":"markdown","2a7c2a4d":"markdown","ec92181a":"markdown"},"source":{"bc54ad4f":"# Importing Modules\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nprint(os.listdir(\"..\/input\"))","f161aa90":"# Reading the data frames\n#Training Data\ntrain = pd.read_csv(\"..\/input\/train.csv\") \n#Testing Data\ntest = pd.read_csv(\"..\/input\/test.csv\")\n","3748e86b":"#Converting the Pandas frame to numpy \nlabel = np.array(train.iloc[:,0],np.str)\ndata = np.array(train.iloc[:,1:],np.float32)\n\n#Test data\nlabel_test = np.array([])\ndata_test = np.array(test.iloc[:,:],np.float32)\n\n","95b3b4fe":"def visualize_input(img, ax):\n    ax.imshow(img, cmap='gray')\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        color='white' if img[x][y]<thresh else 'black')\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nvisualize_input(data[4].reshape(28,28), ax)","15e6c4fd":"#Drawing Train Data\nfig = plt.figure(figsize=(20,20))\nfor i in range(10):\n    ax = fig.add_subplot(1,10,i+1)\n    ax.imshow(np.reshape(data[i],(28,28)),cmap='gray')\n    ax.set_title(str(label[i]))","899039a1":"#Drawing Test Data \nfig = plt.figure(figsize=(20,20))\nfor i in range(10):\n    ax = fig.add_subplot(1,10,i+1)\n    ax.imshow(np.reshape(data_test[i],(28,28)),cmap='gray')","2496d217":"# Reshape and Normalizing the data\n#(height = 28px, width = 28px , canal = 1)\ndata = data.reshape(data.shape[0],28,28,1)\ndata_test = data_test.reshape(data_test.shape[0],28,28,1)\ndata = data\/255\ndata_test = data_test\/255","ebc480e3":"data.shape","b9e2e978":"from keras.utils import np_utils\nprint(\"Before conding\")\nprint(label[:10])\nlabels = np_utils.to_categorical(label,10)\nprint(\"Encoded Data\")\nprint(labels[:10])","1184692e":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout\n\ndef model_generator(dropout=[0.25],denses=[512,10],activation=\"relu\"):\n    model = Sequential()\n    model.add(Conv2D(filters=32,kernel_size=3,padding='same', activation='relu', input_shape=(28, 28,1)))\n    model.add(Conv2D(filters=32, kernel_size=3,  border_mode='same', activation='relu'))\n    model.add(MaxPool2D(pool_size=3))\n    model.add(Dropout(0.20))\n    \n    model.add(Conv2D(filters=64,kernel_size=3,padding='same', activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=3,  border_mode='same', activation='relu'))\n    model.add(MaxPool2D(pool_size=2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters=128, kernel_size=3,  border_mode='same', activation='relu'))\n    model.add(MaxPool2D(pool_size=2))\n    model.add(Dropout(0.20))\n    \n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))  \n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    #Model Summary\n    model.summary()\n    return model","63eb1fb5":"def model_generator2(dropout=[0.25],denses=[512,10],activation=\"relu\"):\n    model = Sequential()\n    model.add(Conv2D(filters=16,kernel_size=2,padding='same', activation='relu', input_shape=(28, 28,1)))\n    model.add(MaxPool2D(pool_size=2))\n    model.add(Dropout(0.20))\n    model.add(Conv2D(filters=32, kernel_size=2,  border_mode='same', activation='relu'))\n    model.add(MaxPool2D(pool_size=2))\n    model.add(Dropout(0.20))\n    model.add(Conv2D(filters=64,kernel_size=2,padding='same', activation='relu'))\n    model.add(MaxPool2D(pool_size=2))\n    model.add(Dropout(0.15))\n    #model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    model.add(Dense(512, name='aux_output'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(10, name='aux_output2'))\n    model.add(Activation('softmax'))\n    #Model Summary\n    model.summary()\n    return model","c5956070":"from keras.optimizers import RMSprop, Adam\ndef model_fit(model,batch_size=64,epochs=10):\n#     optimizer = RMSprop(lr=0.0002, rho=0.9, epsilon=1e-08, decay=0.0)\n    optimizer = Adam(lr=0.0001)\n    model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\n    from keras.callbacks import ModelCheckpoint\n    checkpointer = ModelCheckpoint(filepath='mnist.model.best', verbose=1, monitor='val_loss', save_best_only=True)\n    training = model.fit(data, labels,batch_size=batch_size, epochs=epochs,validation_split=0.25, callbacks=[checkpointer],verbose=1, shuffle=True)\n    return training","409e28cb":"model1 = model_generator(dropout=[0.25],denses=[128,10],activation=\"relu\")\ntraining = model_fit(model1,batch_size=128,epochs=100)","c35e84ae":"def draw_model(training):\n    plt.plot(training.history['loss'])\n    plt.plot(training.history['val_loss'],'r')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss\")\n    plt.legend([\"Training\",\"Validation\"])\n    plt.show()\n    plt.plot(training.history['acc'])\n    plt.plot(training.history['val_acc'])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Accuracy\")\n    plt.legend([\"Training\",\"Validation\"],loc=4)\n    plt.show()\n    \ndraw_model(training)","b0f87975":"# evaluate test accuracy\ndef scoring(model):\n    model.load_weights('mnist.model.best')\n    score = model.evaluate(data[:2000], labels[:2000], verbose=0)\n    accuracy = 100*score[1]\n    # print test accuracy\n    print('Test accuracy: %.4f%%' % accuracy)\n    label_test = model.predict_classes(data_test)\n    print(\"Sample of the prdiction\",label_test[:10])\n    return label_test","309da5eb":"label_test = scoring(model1)","bdeefef2":"#Drawing Test Dta \nfig = plt.figure(figsize=(20,20))\nfor i in range(10):\n    ax = fig.add_subplot(1,10,i+1)\n    ax.imshow(np.reshape(data_test[i],(28,28)),cmap='gray')\n    ax.set_title(label_test[i])","d1725a05":"#Drawing Test Dta \nfig = plt.figure(figsize=(20,20))\nfor i in range(10):\n    rn = np.random.randint(1,100)\n    ax = fig.add_subplot(1,10,i+1)\n    ax.imshow(np.reshape(data_test[rn],(28,28)),cmap='gray')\n    ax.set_title(label_test[rn])","388b992c":"np.savetxt(\"submission.csv\", np.dstack((np.arange(1, label_test.size+1),label_test))[0],\"%d,%d\",header=\"ImageId,Label\",comments=\"\")","30fa9f07":"## Content \n---\n- ### Loading the Dataset\n        - Splitting labels from images\n        - Visulaizing an image on pixel level\n        - Visulaizing sample of the Training data \n        - Visualizing sample of the Testing Data \n \n- ### Data Preparation\n        - Reshape images in matrix form\n        - Normalization\n        - Applying One-hot-encoding on labels\n\n- ### Network structure\n        - Model generator to dynamically change hyperparameters\n\n- ### Training\n        - Training generator and fitting\n        - Visualize Model behaviour on loss drawing\n\n- ### Evaluation\n        - Predict classes for testing data\n        - Visulaize predictions on images\n        - Saving results\n      \n\n## History\n---\nUsing Dense Nodes best results was **0.97571**\n\n---\n","66895018":"# Drawing predicited data ","f521afea":"\n# Getting started with Keras | CNN implementation for Digit Recognizer ","8ff626ba":"# Start Training","52dcf80e":"# Visualize model behaviour","ba79824e":"---\n# Data Preparation\n\n- The dataset is clean no need for cleaning\n- Reshap the data to  (height = 28px, width = 28px , canal = 1) for 1D Vector\n- Normalizing the data as each pixel is from 0 : 255 => Black => white in gray scale\n- the data will be from 0 to 1","065b4d5f":"### One-hot-encoding | Convering the label to one hot encoded 10 categories each for one number ","7c54143d":"# Visulaizing an Image on the pixel level","0ce8e4c4":"# Splitting Labels from the images","4d238920":"# Visualizing sample of the training dataset","17d38698":"---\n# Loading Dataset","1f4e8bcf":"# Saving the scores to the submission CSV","2df65d9d":"# Visualizing sample of the testing dataset","5c47fa9b":"---\n# Model Scoring on Test set","2a7c2a4d":"---\n# Creating Training Generator \nUsing keras callback to save the best model based on **validation accuracy** through the training to prevent overfitting with the validation dataset","ec92181a":"--- \n## Network Structure\nCreating Model generators to dynamically change and select the best hyperparameters for the model  using the same structure.\n\n- Dropout parameter\n- Denses \n- Activation layer"}}