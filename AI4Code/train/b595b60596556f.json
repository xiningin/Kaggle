{"cell_type":{"3d70d2c5":"code","ed6ee40a":"code","29532319":"code","f7d026a5":"code","660ac413":"code","3be8a719":"code","3531d9a0":"code","121af83a":"code","1e178a20":"code","adee4036":"code","3e7e6f67":"code","8a787549":"code","64075791":"code","56c7a3ce":"code","e59a09d4":"code","b0b5d5cb":"code","90b0ea3a":"code","0eb6513d":"code","37a91bb9":"code","8b2229af":"code","dbe15363":"code","85d76c30":"code","2327715b":"code","f5535378":"code","2d4520d3":"code","6a87561d":"code","1496d2d7":"code","55ca274b":"code","eb357404":"code","bb543f65":"code","92241d36":"code","ad936474":"code","145bb232":"code","74a57b63":"code","50210189":"code","c4a300f8":"code","68ba6c91":"code","a20ad46b":"code","5311fd82":"code","2a6324af":"code","32fca424":"markdown","7df6c2ce":"markdown","d05a3c42":"markdown","faaf936d":"markdown","17fcf195":"markdown","30c916b7":"markdown","49f6f048":"markdown","1e2a9731":"markdown","4fd117c7":"markdown","5fc1c266":"markdown"},"source":{"3d70d2c5":"!pip install imageai --upgrade","ed6ee40a":"!pip install split-folders","29532319":"import numpy as np\nimport pandas as pd\nimport math\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\n\nfrom fastai.vision.all import *\nfrom fastai.vision.all import *\n\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,MaxPool2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import SGD\nfrom keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Lambda\nfrom keras.layers.embeddings import Embedding\nfrom keras.models import load_model\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n\nfrom imageai.Detection import ObjectDetection\nfrom imageai.Detection import VideoObjectDetection\nimport matplotlib.pyplot as plt\n","f7d026a5":"dice_roll_classes = '1','2','3','4','5','6'\npath = \".\/\"\nfns = get_image_files(path)","660ac413":"img = load_img(\"..\/input\/dice-roll\/Test\/1\/20210123_160932.jpg\")\nim1 = img.save(\".\/File_View.jpg\") ","3be8a719":"from imageai.Detection.Custom import CustomObjectDetection\n\ndetector = CustomObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"..\/input\/dicev2\/detection_model-ex-011--loss-0019.695.h5\")\ndetector.setJsonPath(\"..\/input\/dicev2\/detection_config.json\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(\n    input_image=\"..\/input\/dice-roll\/Test\/1\/20210123_160932.jpg\",\n    output_image_path=\".\/File_View.jpg\", minimum_percentage_probability=30)","3531d9a0":"img = load_img(\".\/File_View.jpg\")\nimg","121af83a":"dice = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=2021),\n    get_y=parent_label,\n    item_tfms=Resize(224))","1e178a20":"path = \"..\/input\/dice-roll\/Train\/\"\ndls = dice.dataloaders(path,bs = 2)\nlen(dls.train_ds)","adee4036":"dls.train.show_batch()","3e7e6f67":"learn = cnn_learner(dls, resnet18, metrics=[accuracy, error_rate])","8a787549":"learn.fine_tune(4)","64075791":"learn.fine_tune(4)","56c7a3ce":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","e59a09d4":"interp.plot_top_losses(5, nrows=1)","b0b5d5cb":"learn.export()","90b0ea3a":"model_inf = load_learner('.\/export.pkl')","0eb6513d":"pred = model_inf.predict('..\/input\/dice-roll\/Test\/1\/20210123_160932.jpg')\npred[0]","37a91bb9":"# DIR = '.\/train\/2'\n# print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))","8b2229af":"import splitfolders\npath = \"..\/input\/dice-roll\/Train\"\nsplitfolders.ratio(path, output=\".\/\", seed=2021, ratio=(.8, 0.1,0.1)) ","dbe15363":"dice_roll_classes = '1','2','3','4','5','6'\npath = \".\/\"","85d76c30":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntrain_generator = train_datagen.flow_from_directory(\n        path + 'train\/',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='categorical')\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = valid_datagen.flow_from_directory(\n        path + 'val\/',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='categorical')","2327715b":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory( path + 'test\/',\n                                                    target_size=(224, 224),\n                                                    batch_size=32,\n                                                    class_mode='categorical', shuffle=False)","f5535378":"input_shape = (224, 224, 3,)\nnum_classes = 6\nmodel = Sequential()\n\nmodel.add(Conv2D(kernel_size=(3,3), filters=16, activation='tanh', input_shape=input_shape))\nmodel.add(Conv2D(filters=8,kernel_size = (2,2),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=4,kernel_size = (2,2),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(filters=2,kernel_size = (2,2),activation='relu'))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(24,activation='relu'))\nmodel.add(Dense(12,activation='relu'))\nmodel.add(Dense(6,activation = 'softmax'))\n    \nmodel.compile(\n              loss='categorical_crossentropy', \n              metrics=['acc'],\n              optimizer='adam'\n             )","2d4520d3":"model.summary()","6a87561d":"history = model.fit(\n        train_generator,\n        #steps_per_epoch=200,\n        epochs=20,\n        validation_data=validation_generator)\n        #,\n        #validation_steps=80)","1496d2d7":"# summarize history for accuracy\nplt.subplot(211)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","55ca274b":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","eb357404":"#Get the accuracy score\ntest_score = model.evaluate_generator(test_generator, 32)\n\nprint(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100))\nprint(\"[INFO] Loss: \",test_score[0])","bb543f65":"def plots(ims, figsize=(12,12), rows=1, interp=False, titles=None):\n\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)\/\/rows if len(ims) % 2 == 0 else len(ims)\/\/rows + 1\n\n    for i in range(len(ims)):\n        sp = f.add_subplot(cols, rows, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=12)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')","92241d36":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n        print(\"Normalized confusion matrix\")\n\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","ad936474":"\n#Print the Target names\ntarget_names = []\nfor key in train_generator.class_indices:\n    target_names.append(key)\n\n# print(target_names)\n\n#Confusion Matrix \nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n\n\n#Print Classification Report\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","145bb232":"#Save the model\nmodel.save(\"Keras_Model.hdf5\")","74a57b63":"# Try Predictions with one image sample\n\nlabels = ['1','2','3','4','5','6']\n#..\/input\/dicev4\/Train\/1\/aug0_20210123_160932.jpg\n\n#Test the model\nimg_rows = 224\nimg_cols = 224\nmodel = load_model('Keras_Model.hdf5')\n\nfile = path + 'train\/' + '1\/aug0_20210123_160932.jpg'\n# img = cv.cvtColor(cv.imread(file),cv.COLOR_BGR2RGB)\n# img = cv.resize(img, (img_rows,img_cols))\n\nimg = tf.keras.preprocessing.image.load_img(\n     path + 'train\/' + '1\/aug0_20210123_160932.jpg',\n     grayscale=False, color_mode=\"rgb\", target_size=(img_rows,img_cols),\n     interpolation=\"nearest\"\n )\n\ntest_image = img_to_array(img)\ntest_image = np.expand_dims(test_image, axis=0)\npred = model.predict(test_image)\n\nprint(pred, labels[np.argmax(pred)])","50210189":"from imageai.Detection.Custom import CustomObjectDetection\n\ndetector = CustomObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"..\/input\/dicev2\/detection_model-ex-011--loss-0019.695.h5\")\ndetector.setJsonPath(\"..\/input\/dicev2\/detection_config.json\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(\n    input_image=\"..\/input\/dice-roll\/Test\/1\/20210123_160932.jpg\",\n    output_image_path=\".\/File_View.jpg\", minimum_percentage_probability=30)\n\nprint(len(detections))\nfor eachObject in detections:\n    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"], \" : \",\n          eachObject[\"box_points\"] )\n    plt.figure(figsize=(12,12))\n    plt.imshow(plt.imread(\".\/File_View.jpg\"))\n    plt.show()","c4a300f8":"from numpy import asarray \nfor icnt in range(4,6):\n    print(str(icnt))\n    path = '..\/input\/dice-roll\/Test\/' + str(icnt) + '\/'\n    dirs = os.listdir( path )\n    i=0\n    for file in dirs:         \n        print(file)\n        \n        detections = detector.detectObjectsFromImage(input_image=path + file, \n                                                     output_image_path=\".\/File_View.png\", \n                                                     minimum_percentage_probability = 40)   \n        img = load_img(\".\/File_View.png\")\n        \n        for eachObject in detections:\n            print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n            \n            roi = img.crop(eachObject[\"box_points\"])\n            plt.imshow(roi)\n            plt.show()\n            \n            img = img.resize((224,224)) \n            test_image = img_to_array(img)\n            test_image = np.expand_dims(test_image, axis=0)\n            pred = model.predict(test_image)\n            print(\"Prediction : \", labels[np.argmax(pred)])","68ba6c91":"detector_video = VideoObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"..\/input\/dicev2\/detection_model-ex-011--loss-0019.695.h5\")\ndetector.setJsonPath(\"..\/input\/dicev2\/detection_config.json\")\ndetector.loadModel()\n\nvideo_path = detector_video.detectObjectsFromVideo(input_file_path='..\/input\/dice-roll\/Videos\/20210123_161601.mp4',\n                                            output_file_path=\".\/File_View1.png\",\n                                            minimum_percentage_probability=60,\n                                            frames_per_second=1, log_progress=True)\nprint(video_path)","a20ad46b":"from IPython.display import Video\n\n# read video\ncap = cv2.VideoCapture(\"..\/input\/dice-roll\/Videos\/20210123_161601.mp4\")\n\nif (cap.isOpened()== False): \n    print(\"Error opening video stream or file\")\n\ncount = 0\nwhile count < 3:\n    cap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))   \n    ret,frame = cap.read()\n    if count == 0:\n        image0 = frame\n    elif count == 1:\n        image1 = frame\n    elif count == 2:\n        image2 = frame\n    count =count + 1\n    ","5311fd82":"from PIL import Image as im \nimage2.shape\ndata = im.fromarray(image2)\ndetections = detector.detectObjectsFromImage(input_type=\"array\",input_image=image2, \n                                                     output_image_path=\".\/File_View1.png\", \n                                                     minimum_percentage_probability = 40) ","2a6324af":"img = load_img(\".\/File_View1.png\")\n    \nfor eachObject in detections:\n    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n\n    roi = img.crop(eachObject[\"box_points\"])\n    plt.imshow(roi)\n    plt.show()\n\n    img = img.resize((224,224)) \n    test_image = img_to_array(img)\n    test_image = np.expand_dims(test_image, axis=0)\n    pred = model.predict(test_image)\n    print(\"Prediction : \", labels[np.argmax(pred)])","32fca424":"#### Did Transfer lerning using a Yolo Model on Google Colab and exported the .h5 file for Object recognition.\n\n#### Augmented Images to train other models are available under the DatasetObjectDetectionTraining folder.\n","7df6c2ce":"### Object Detection on Test Images","d05a3c42":"## Object Detection","faaf936d":"### Dice Project\n\nI created this project to build a model to recogize the score of a dice by looking at a video. If we are able to get the correct score of a dice we could build a augmented reality game where players could join remotely.","17fcf195":"## Keras","30c916b7":"##### References\n##### https:\/\/www.kaggle.com\/prateek0x\/multiclass-image-classification-using-keras","49f6f048":"#### Tried out a simple classification Model using Tranfer Learning on a Resnet 18 model","1e2a9731":"### Object Detection and Image Classification on Videos","4fd117c7":"#### Below is a custom build Keras Model for Classification","5fc1c266":"### Fast AI with Resnet18"}}