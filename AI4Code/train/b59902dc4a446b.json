{"cell_type":{"5bd9a12c":"code","2dd996e6":"code","352ae74e":"code","6fe2b8e9":"code","693a0cf1":"code","ab034377":"code","693a233f":"code","b155e42d":"markdown","184c4782":"markdown","7ce7d4ee":"markdown","129302e6":"markdown","f79030fb":"markdown","eeea89dc":"markdown","8b0904c2":"markdown","60c6f460":"markdown","68966cbb":"markdown","aedda444":"markdown","404f59e9":"markdown"},"source":{"5bd9a12c":"import pandas as pd\n\n# Load dataset\ndata_path = '..\/input\/insurance.csv'\ndata = pd.read_csv(data_path)\n\n# See general information about the dataset & 5 sample data points\nprint(data.info())\ndata.head(5)","2dd996e6":"from sklearn.preprocessing import LabelEncoder\n\n# Label encoder initialization\nle_sex = LabelEncoder()\nle_smoker = LabelEncoder()\nle_region = LabelEncoder()\n\n# Label encoding\ndata['sex_encoded'] = le_sex.fit_transform(data.sex)\ndata['smoker_encoded'] = le_smoker.fit_transform(data.smoker)\ndata['region_encoded'] = le_region.fit_transform(data.region)\n\n# See the encoding mapping \n# (categorical value encoded by the index)\nprint('sex column encoding mapping : %s' % list(le_sex.classes_))\nprint('smoker column encoding mapping : %s' % list(le_smoker.classes_))\nprint('region column encoding mapping : %s' % list(le_region.classes_))\n\n# See label encoding result\ndata.head(5)","352ae74e":"from sklearn.preprocessing import OneHotEncoder\n\n# One hot encoder initialization\nohe_region = OneHotEncoder()\n\n# One hot encoding (OHE) to array\narr_ohe_region = ohe_region.fit_transform(data.region_encoded.values.reshape(-1,1)).toarray()\n\n# Convert array OHE to dataframe and append to existing dataframe\ndfOneHot = pd.DataFrame(arr_ohe_region, columns=['region_'+str(i) for i in range(arr_ohe_region.shape[1])])\ndata = pd.concat([data, dfOneHot], axis=1)\n\n# See the preprocessing result\ndata.head(5)","6fe2b8e9":"# Drop categorical features\npreprocessed_data = data.drop(['sex','smoker','region',\n                               'region_encoded'], axis=1)\n\n# See the preprocessing final result\npreprocessed_data.head(5)","693a0cf1":"from sklearn.model_selection import train_test_split\n\n# Split the dataset to training and testing\ntrain, test = train_test_split(preprocessed_data, test_size=0.2)\n\n# Split the feature and the target\ntrain_y = train.charges.values\ntrain_x = train.drop(columns=['charges']).values\ntest_y = test.charges.values\ntest_x = test.drop(columns=['charges']).values\n\n# See the size of training and testing\nprint('Training features : ', train_x.shape)\nprint('Training target : ', train_y.shape)\nprint('Testing features : ', test_x.shape)\nprint('Testing target : ', test_y.shape)","ab034377":"from sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Building linear regression model\nlr_model = linear_model.LinearRegression()\nlr_model.fit(train_x, train_y)\n\n# Building Random Forest model\nrf_model = RandomForestRegressor()\nrf_model.fit(train_x, train_y)\n\n# Make prediction\nlr_predict = lr_model.predict(test_x)\nrf_predict = rf_model.predict(test_x)\n\n# Sample the prediction\nsample_id = 7\nprint('Actual Charges : %.2f' % test_y[sample_id])\nprint('Linear Regression Prediction : %.2f' % lr_predict[sample_id])\nprint('Random Forest Prediction : %.2f' % rf_predict[sample_id])","693a233f":"from sklearn.metrics import mean_squared_error, r2_score\nimport math\n\n# Evaluate prediction model using MSE\nlr_mse = mean_squared_error(test_y, lr_predict)\nprint('MSE-Linear Regression : %.2f (square-rooted)' % math.sqrt(lr_mse))\nrf_mse = mean_squared_error(test_y, rf_predict)\nprint('MSE-Random Forest : %.2f (square-rooted)' % math.sqrt(rf_mse))\n\n# Evaluate prediction model using R2-Score\nlr_r2 = r2_score(test_y, lr_predict)\nprint('R2-Linear Regression : %.2f' % lr_r2)\nrf_r2 = r2_score(test_y, rf_predict)\nprint('R2-Random Forest : %.2f' % rf_r2)","b155e42d":"So far, we added the transformed categorical column to the end of the dataset column, but not all the column will be used for building the prediction model. So unnecessary column will be dropped, such as the categorical column and non-binary encoded column.","184c4782":"**<h1>3. Data Pre-processing<\/h1>**\n\n**<h2>Label Encoding<\/h2>**\n\nLabel encoding is a process to transform categorical value to numerical value. *LabelEncoder* from scikit-learn library is used in this transformation process. Decimal number is assigned to each categorical value within the column. New columns containing encoded categorical values then added at the end of medical dataset column.\n","7ce7d4ee":"**<h2>One Hot Encoding<\/h2>**\n\nOne Hot Encoding (OHE) utilized in this kernel is using module from scikit-learn. The OHE module takes decimal number assigned to categorical value as input. The OHE result then added to the end of the dataset column.","129302e6":"As seen above, numerical value assigned for *region* column is not binary (it has 4 categorical values).  It doesn't seem like a problem at first, but it does. Unless the categorical value has some order (i.e. cold, warm, hot) \"binarization\" of categorical value is necessary. Therefore One Hot Encoding is applied to transform decimal number assigned to *region* column to binary values. ","f79030fb":"**<h1>4. Building Prediction Model (Training)<\/h1>**\n\nIn this kernel, 2 method are employed to building the prediction model : Linear Regression (MLR) & Random Forest (RFR). The two method then evaluated and compared in term of performance.","eeea89dc":"**<h1>2. Dataset Overview<\/h1>**\n\nLet's take a glimpse at the dataset before we processed it furthermore. Then we can start pre-processing (LINEAR REGRESSOR AND RANDOM FOREST REGRESSOR) method suitable for making medical cost prediction.","8b0904c2":"**<h1>1. Introduction<\/h1>**\n\nThis kernel aims to exercising simple data pre-processing and regression model building for predicting medical cost based on medical dataset.","60c6f460":"**<h1>6. Conclusion<\/h1>**\nThe result show that random forest model yield better prediction than linear regression indicated both by MSE and R2-Score. ","68966cbb":"As seen above, the medical cost dataset consists of 1338 data, which each data has 7 columns, 3 of them are categorical (stated by object data type). Categorical value can be found in *sex*, *smoker*, and *region* column. Those categorical values need to be converted to numerical values in prior to building the prediction model. In addition, there is no missing values in the dataset, showed by number 1338 (the number of total data) on each column information.","aedda444":"**<h1>5. Model Evaluation (Testing)<\/h1>**\n\nThe prediction made using testing data evaluated using *Mean Squared Error (MSE)* and R2-Score.  MSE is the average squared difference between predicted values and actual values. R2-Score (coefficient of determination) is regression score function. The result show that random forest model yield better prediction than linear regression indicated both by MSE and R2-Score.","404f59e9":"**<h1>3. Data Preparation<\/h1>**\n\nThe pre-processed dataset then divided to training data and testing data. Training data is used for building the prediction model, while testing data is used for evaluating the prediction model."}}