{"cell_type":{"4b88d635":"code","7501f02d":"code","eaaa363f":"code","e85135ad":"code","4d50baae":"code","b5cc2de0":"code","8a4ac027":"code","8549c847":"code","4aa0f4b8":"code","cd2a7694":"code","94e83f6d":"code","df14e4b0":"code","fdefa69a":"code","184ac545":"code","6effe27b":"code","b7b84367":"code","6d772a07":"code","540fa735":"markdown","bf00e884":"markdown"},"source":{"4b88d635":"from __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport json\nimport pprint\nimport warnings\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.nn.utils.prune as prune\nfrom torch.optim import lr_scheduler\nimport torchvision.transforms as transforms\n\nimport sklearn.metrics\nfrom collections import OrderedDict\n\nfrom torch.autograd import Variable\nfrom PIL import Image","7501f02d":"#from sklearn.metrics import roc_auc_score","eaaa363f":"# d = pd.read_csv(\"..\/input\/latestdata\/train.csv\", index_col = False)\n# d['Path'] = d['Image Index']\n# img_paths = d[\"Path\"].tolist()\n# pathologies = [col for col in d.columns.values if (col != \"Path\" and col != \"No Finding\" and col != 'Image Index')]\n# labels = d[pathologies].to_numpy().astype(int)\n# d\n# n_classes = labels.shape[1]\n# n_classes","e85135ad":"sumary = []","4d50baae":"class Parser():\n    def __init__(self, model = \"densenet\", optimizer = \"adam\", lr = 0.0001, weight_decay = 0.0, drop_rate = 0.0, epochs = 20,\\\n               batch_size = 16, workers = 2, seed = 42, tag = \"\", toy = False, save_path =\".\/\", scale = 224, horizontal_flip = True,\\\n               verbose = True, scratch = False, train_weighted = False, valid_weighted = True, size = None):\n        self.model = model; self.optimizer = optimizer; self.lr = lr; self.weight_decay = weight_decay; self.drop_rate = drop_rate\n        self.epochs = epochs; self.batch_size = batch_size; self.workers = workers; self.seed = seed; self.tag = tag; self.toy = toy\n        self.save_path = save_path; self.scale = scale; self.horizontal_flip = horizontal_flip; self.verbose = verbose; self.scratch = scratch\n        self.train_weighted = train_weighted; self.valid_weighted = valid_weighted; self.size = size\n\nclass Dataset(data.Dataset):\n    def __init__(self, args, data_split):\n        super(Dataset, self).__init__()\n        tag = \"\"\n        if args.tag:\n          tag = \"_\" + args.tag\n        df = pd.read_csv(os.path.join(\"..\/input\/latestdata\/%s%s.csv\" % (data_split, tag)))\n        df['Path'] = df['Image Index']\n        \n        # C\u00f3 th\u1eed nghi\u1ec7m hay kh\u00f4ng? frac = t\u1ec9 l\u1ec7 data l\u1ea5y ra t\u1eeb dataset\n        if args.toy:\n            df = df.sample(frac=0.001)\n            \n        self.df = df\n        self.img_paths = df[\"Path\"].tolist()\n        self.pathologies = [col for col in df.columns.values if (col != \"Path\" and col != \"No Finding\" and col != 'Image Index')]\n        self.labels = df[self.pathologies].to_numpy().astype(int)\n        \n        self.n_classes = self.labels.shape[1]\n\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n        if data_split == \"train\":\n            transforms_lst = [\n                transforms.Resize((args.scale, args.scale)),\n                transforms.RandomHorizontalFlip() if args.horizontal_flip else None,\n                transforms.ToTensor(),\n                normalize,\n            ]\n            self.transform = transforms.Compose([t for t in transforms_lst if t])\n        else:\n            self.transform = transforms.Compose([\n                transforms.Resize((args.scale, args.scale)),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        self.df = df\n                \n        if (data_split == \"train\" and args.train_weighted) or (data_split == \"valid\" and args.valid_weighted):\n            self.get_weights(args, data_split)\n\n\n    def get_weights(self, args, data_split):\n\n        self.use_gpu = torch.cuda.is_available()\n        p_count = (self.labels == 1).sum(axis = 0)\n        self.p_count = p_count\n        n_count = (self.labels == 0).sum(axis = 0)\n        total = p_count + n_count\n\n        # invert *opposite* weights to obtain weighted loss\n        # (positives weighted higher, all weights same across batches, and p_weight + n_weight == 1)\n        p_weight = n_count \/ total\n        n_weight = p_count \/ total\n\n        self.p_weight_loss = Variable(torch.FloatTensor(p_weight), requires_grad=False)\n        self.n_weight_loss = Variable(torch.FloatTensor(n_weight), requires_grad=False)\n        \n        print (\"Positive %s Loss weight:\" % data_split, self.p_weight_loss.data.numpy())\n        print (\"Negative %s Loss weight:\" % data_split, self.n_weight_loss.data.numpy())\n        random_loss = sum((p_weight[i] * p_count[i] + n_weight[i] * n_count[i]) *\\\n                                               -np.log(0.5) \/ total[i] for i in range(self.n_classes)) \/ self.n_classes\n        print (\"Random %s Loss:\" % data_split, random_loss)\n\n\n    def __getitem__(self, index):\n        img = Image.open(self.img_paths[index]).convert(\"RGB\")\n        label = self.labels[index]\n\n        return self.transform(img), torch.LongTensor(label)\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def weighted_loss(self, preds, target, epoch=1):\n\n        weights = target.type(torch.FloatTensor) * (self.p_weight_loss.expand_as(target)) + \\\n                  (target == 0).type(torch.FloatTensor) * (self.n_weight_loss.expand_as(target))\n        if self.use_gpu:\n            weights = weights.cuda()\n        loss = 0.0\n        for i in range(self.n_classes):\n            #loss += nn.functional.binary_cross_entropy_with_logits(preds[:,i], target[:,i], weight=weights[:,i])\n            loss += nn.functional.binary_cross_entropy(preds[:,i], target[:,i], weight=weights[:,i])\n        return loss \/ self.n_classes\n\n# evaluate(gts, outs, loader.dataset.pathologies) + (avg_loss,)\ndef evaluate(gts, probabilities, pathologies, use_only_index = None):\n    gts = np.array(gts)\n    probabilities = np.array(probabilities)\n    #assert(np.all(probabilities >= 0) == True)\n    #assert(np.all(probabilities <= 1) == True)\n\n    def compute_metrics_for_class(i):\n        #p, r, t = sklearn.metrics.precision_recall_curve(gts[:, i], probabilities[:, i])\n         #PR_AUC = sklearn.metrics.auc(r, p)\n        ROC_AUC = sklearn.metrics.roc_auc_score(gts[:, i], probabilities[:, i])\n         #F1 = sklearn.metrics.f1_score(gts[:, i], preds[:, i])\n        acc = sklearn.metrics.accuracy_score(gts[:, i], preds[:, i])\n        count = np.sum(gts[:, i])\n        #return PR_AUC, ROC_AUC, F1, acc, count\n        return ROC_AUC, acc, count\n    \n    #PR_AUCs = []\n    ROC_AUCs = []\n    #F1s = []\n    accs = []\n    counts = []\n    preds = probabilities >= 0.5\n\n    classes = [use_only_index] if use_only_index is not None else range(len(gts[0]))\n\n    for i in classes:\n        try:\n            #PR_AUC, ROC_AUC, F1, acc, count = compute_metrics_for_class(i)\n            ROC_AUC, acc, count = compute_metrics_for_class(i)\n        except ValueError:\n            continue\n        #PR_AUCs.append(PR_AUC)\n        ROC_AUCs.append(ROC_AUC)\n        #F1s.append(F1)\n        accs.append(acc)\n        counts.append(count)\n        #print('Class: {!s} Count: {:d} PR AUC: {:.4f} ROC AUC: {:.4f} F1: {:.3f} Acc: {:.3f}'.format(pathologies[i], count, PR_AUC, ROC_AUC, F1, acc))\n        print('Class: {!s} Count: {:d} ROC AUC: {:.4f} ACC: {:.3f}'.format(pathologies[i], count, ROC_AUC, acc))\n        sumary.append('Class: {!s} Count: {:d} ROC AUC: {:.4f} ACC: {:.3f}'.format(pathologies[i], count, ROC_AUC, acc))\n    #avg_PR_AUC = np.average(PR_AUCs)\n    avg_ROC_AUC = np.average(ROC_AUCs, weights=counts)\n    #avg_F1 = np.average(F1s, weights=counts)\n\n    #print('Avg PR AUC: {:.3f}'.format(avg_PR_AUC))\n    print('Avg ROC AUC: {:.3f}'.format(avg_ROC_AUC))\n    #print('Avg F1: {:.3f}'.format(avg_F1))\n    return (avg_ROC_AUC, )\n\n# def loader_to_gts(data_loader):\n#     gts = []\n#     for (inputs, labels) in data_loader:\n#         for label in labels.cpu().numpy().tolist():\n#             gts.append(label)\n#     gts = np.array(gts)\n#     return gts\n\n\ndef load_data(args):\n    \n    train_dataset = Dataset(args, \"train\")\n    valid_dataset = Dataset(args, \"valid\")\n    \n    train_loader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=args.batch_size, shuffle=True,\n            num_workers=2, pin_memory=True, sampler=None)\n        \n    valid_loader = torch.utils.data.DataLoader(\n            valid_dataset, batch_size=args.batch_size, shuffle=False,\n            num_workers = 2, pin_memory=True, sampler=None)\n\n    return train_loader, valid_loader","b5cc2de0":"import torchvision\nN_CLASSES = 14\nmodel_path = {\n    'densenet121': '..\/input\/10-epochs\/10epoch.056068_epoch10'\n}\n\n# T\u00f9y ch\u1ec9nh Densenet\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module('norm-1', nn.BatchNorm2d(num_input_features)),\n        self.add_module('relu-1', nn.ReLU(inplace=True)),\n        self.add_module('conv-1', nn.Conv2d(num_input_features, bn_size *\n                        growth_rate, kernel_size=1, stride=1, bias=False)),\n        self.add_module('norm-2', nn.BatchNorm2d(bn_size * growth_rate)),\n        self.add_module('relu-2', nn.ReLU(inplace=True)),\n        self.add_module('conv-2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n        return torch.cat([x, new_features], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n            self.add_module('denselayer%d' % (i + 1), layer)\n\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(_Transition, self).__init__()\n        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n\n        \nclass densenet121(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = torchvision.models.densenet121(pretrained=True)\n        \n        # Cat bo cai block va cai transition\n        self.net.features.denseblock4 = nn.Sequential(\n            nn.Identity()\n        )\n        self.net.features.transition3 = nn.Sequential(\n            nn.Identity()\n        )\n\n        num_ftrs = self.net.classifier.in_features\n        \n        self.net.classifier = nn.Sequential(\n            nn.Linear(num_ftrs,N_CLASSES),\n            #nn.Sigmoid()\n        )\n#         self.pool = nn.AvgPool2d(2,2)\n        \n    def forward(self, x):\n        out = self.net(x)\n        return out\n","8a4ac027":"# output = torch.tensor([[0.4333, 0.6059, 0.6042, 0.3994, 0.5265, 0.6359, 0.4557, 0.5028, 0.6069,\n#          0.4067, 0.5673, 0.3736, 0.6243, 0.6617],\n#         [0.4421, 0.5773, 0.5658, 0.4237, 0.5294, 0.5985, 0.4737, 0.5387, 0.6341,\n#          0.4080, 0.5900, 0.4268, 0.6564, 0.6518],\n#         [0.4254, 0.5761, 0.5755, 0.4304, 0.5498, 0.6475, 0.4522, 0.4998, 0.6399,\n#          0.3935, 0.5574, 0.4198, 0.6261, 0.6224],\n#         [0.4452, 0.6000, 0.5508, 0.4113, 0.5645, 0.6091, 0.4467, 0.5304, 0.6047,\n#          0.4320, 0.5314, 0.3819, 0.6437, 0.6300],\n#         [0.4265, 0.5757, 0.5460, 0.4407, 0.5575, 0.6340, 0.4572, 0.4917, 0.6255,\n#          0.3786, 0.5298, 0.3988, 0.6233, 0.6599],\n#         [0.4249, 0.5686, 0.5589, 0.4354, 0.5726, 0.6202, 0.4341, 0.4836, 0.6283,\n#          0.4179, 0.5417, 0.3856, 0.6442, 0.6206],\n#         [0.4386, 0.5755, 0.5408, 0.4163, 0.5642, 0.6165, 0.4540, 0.5271, 0.6348,\n#          0.3581, 0.5484, 0.3889, 0.6397, 0.6541],\n#         [0.4467, 0.5769, 0.5698, 0.3997, 0.5502, 0.6337, 0.4737, 0.5093, 0.6370,\n#          0.4039, 0.5631, 0.4570, 0.6112, 0.6144],\n#         [0.4260, 0.5858, 0.5683, 0.3868, 0.5657, 0.6233, 0.4581, 0.5153, 0.6252,\n#          0.3732, 0.5860, 0.3587, 0.6264, 0.6366],\n#         [0.3926, 0.5576, 0.5303, 0.4345, 0.5740, 0.6097, 0.4494, 0.5414, 0.5881,\n#          0.4073, 0.5262, 0.3775, 0.6116, 0.6322],\n#         [0.4275, 0.5612, 0.5509, 0.3628, 0.5207, 0.6179, 0.4438, 0.5409, 0.6400,\n#          0.4113, 0.5267, 0.3953, 0.6298, 0.6274],\n#         [0.3992, 0.6026, 0.5832, 0.4016, 0.5266, 0.6432, 0.4783, 0.5126, 0.6612,\n#          0.4128, 0.5698, 0.4176, 0.6178, 0.6224],\n#         [0.4600, 0.5679, 0.5645, 0.4300, 0.5497, 0.6114, 0.4111, 0.5181, 0.5931,\n#          0.3928, 0.5588, 0.3870, 0.6553, 0.6680],\n#         [0.4540, 0.5546, 0.5094, 0.4384, 0.5847, 0.6442, 0.4005, 0.5456, 0.6342,\n#          0.4088, 0.5332, 0.3824, 0.6759, 0.6325],\n#         [0.4216, 0.5747, 0.5720, 0.4274, 0.5548, 0.6218, 0.4503, 0.5083, 0.6100,\n#          0.4214, 0.5053, 0.4023, 0.6279, 0.6363],\n#         [0.4527, 0.5849, 0.5658, 0.4286, 0.5713, 0.6163, 0.4496, 0.4840, 0.6460,\n#          0.3948, 0.5448, 0.4177, 0.6689, 0.6208]])","8549c847":"# labels = torch.tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n#                         [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n#                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n#                         [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]])","4aa0f4b8":"\"\"\"\nTrain script for CheXNet\n\"\"\"\n\ndef transform_data(data, use_gpu, train=False):\n    inputs, labels = data\n    labels = labels.type(torch.LongTensor)\n    inputs = inputs.cuda()\n    labels = labels.cuda()\n    inputs = Variable(inputs, requires_grad = False, volatile=not train)\n    labels = Variable(labels, requires_grad = False, volatile=not train)\n    return inputs, labels\n\ndef train_epoch(epoch, args, model, loader, criterion, optimizer):\n    model.train()\n    batch_losses = []\n    for batch_idx, data in enumerate(loader):\n        inputs, labels = transform_data(data, True, train=True)\n        \n        optimizer.zero_grad()\n        output = model(inputs)\n        \n        loss = criterion(output, torch.max(labels, 1)[1])\n\n        loss.backward()\n        optimizer.step()\n        if(batch_idx % 1000 == 0 or batch_idx>5555):\n            print(\"Epoch: {:d} Batch: {:d} ({:d}) Train Loss: {:.6f}\".format(epoch, batch_idx, args.batch_size, loss.data))\n        sys.stdout.flush()\n        batch_losses.append(loss.data)\n    train_loss = torch.stack(batch_losses).mean().item()\n    print(\"Training Loss: {:.6f}\".format(train_loss))\n    return train_loss\n\n# def loader_to_gts(data_loader):\n#     gts = []\n#     for (inputs, labels) in data_loader:\n#         for label in labels.cpu().numpy().tolist():\n#             gts.append(label)\n#     gts = np.array(gts)\n#     return gts\n\ndef test_epoch(model, loader, criterion, epoch=1):\n    \"\"\"\n    Returns: (ROC AUC, validation loss)\n    \"\"\"\n    model.eval()\n    test_losses = []\n    outs = []\n    gts = []\n    for _, data in enumerate(loader):\n        inputs, labels = transform_data(data, True, train = False)\n        for gt in data[1].numpy().tolist():\n            gts.append(gt)\n        with torch.no_grad():\n            \n            out = model(inputs)\n            #print('outputs shape: ', outputs.shape)\n            loss = criterion(out, torch.max(labels, 1)[1])\n            test_losses.append(loss.data)\n            outs.extend(out.cpu())\n            \n    avg_loss = torch.stack(test_losses).mean().item()\n    print(\"Validation Loss: {:.6f}\".format(avg_loss))\n\n    gts = torch.tensor(gts)\n\n    tmp = torch.tensor((len(outs), outs[0].shape[0])).float()\n    torch.cat(outs, out = tmp)\n    outs = tmp\n    outs = torch.reshape(outs, gts.shape)\n        \n    return evaluate(gts, outs, loader.dataset.pathologies) + (avg_loss,)\n\ndef get_loss(dataset, weighted):\n\n    criterion = nn.CrossEntropyLoss()\n\n    def loss(preds, target, epoch):\n        if weighted:\n            return dataset.weighted_loss(preds, target, epoch=epoch)\n        else:\n            return criterion(preds, target)\n    return loss\n\ndef run(args):\n\n    use_gpu = torch.cuda.is_available()\n    \n    train, val = load_data(args)\n    print(\"train.shape = {}\",len(train))\n    print(\"val.shape = {}\", len(val))\n    nclasses = train.dataset.n_classes\n    print(\"Number of classes:\", nclasses)\n    \n    \n    criterion = nn.CrossEntropyLoss()\n    if args.model == \"densenet\":\n        model = densenet121()\n        #model.load_state_dict(torch.load(model_path['densenet121']), strict=True)\n    else:\n        print(\"{} is not a valid model.\".format(args.model))\n    if use_gpu:\n        model = model.to(\"cuda\")\n\n    train_criterion = criterion #get_loss(train.dataset, args.train_weighted)\n    #train_criterion = F.binary_cross_entropy\n    val_criterion = criterion # get_loss(val.dataset, args.valid_weighted)\n    optimizer = optim.Adam(\n                   filter(lambda p: p.requires_grad, model.parameters()),\n                   lr=args.lr,\n                   betas = (0.9, 0.999),\n                   weight_decay=args.weight_decay)\n\n    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, threshold=0.001, factor=0.1)\n    best_model_wts, best_loss = model.state_dict(), float(\"inf\")\n\n    counter = 0\n    for epoch in range(1, args.epochs + 1):\n        print(\"Epoch {}\/{}\".format(epoch, args.epochs))\n        print(\"-\" * 10)\n        train_loss = train_epoch(epoch, args, model, train,train_criterion, optimizer)\n        epoch_auc, valid_loss = test_epoch(model, val, val_criterion, epoch)\n        scheduler.step(valid_loss)\n\n        if (valid_loss < best_loss):\n            best_loss = valid_loss\n            best_model_wts = model.state_dict()\n            counter = 0\n        else:\n            counter += 1\n\n        if counter > 3:\n            print(\"ran out of patience....\")\n            break\n\n        torch.save(best_model_wts, os.path.join(args.save_path, \"val%f_train%f_epoch%d\" % (valid_loss, train_loss, epoch)))\n\n    print(\"Best Validation Loss:\", best_loss)\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Usage\n        Download the images data at https:\/\/nihcc.app.box.com\/v\/ChestXray-NIHCC\n        To train on the original labels:\n            python train.py --save_path run_dir --model densenet --batch_size 8 --horizontal_flip --epochs 10 --lr 0.0001 --train_weighted --valid_weighted --scale 512\n        To train on the relabels:\n            python train.py --save_path run_dir --model densenet --batch_size 8 --horizontal_flip --epochs 10 --lr 0.0001 --train_weighted --valid_weighted --scale 512 --tag relabeled\n    \"\"\"\n    p = Parser()\n    run(p)","cd2a7694":"# Cach tinh loss, thay the?","94e83f6d":"# k = [torch.rand(3), torch.rand(3), torch.rand(3)]\n# k","df14e4b0":"# x = torch.tensor((3,3))\n# x = x.float()\n# torch.cat(k, out = x)\n# x","fdefa69a":"# x = torch.reshape(x, (3,3))\n# x","184ac545":"# assert(np.all(np.array(x) >= 0) == True)","6effe27b":"# np.array(x)","b7b84367":"# x = torch.tensor((len(k),k[0].shape[0]))\n# torch.cat(k, out = x)\n# x","6d772a07":"# a = []\n# for i in range(15):\n#     a.append(torch.rand(1, 100, 100))\n# print(a)\n# b = torch.Tensor(15, 100, 100)\n# torch.cat(a, out = b)","540fa735":"# Data Retriver","bf00e884":"# Densenet configuration"}}