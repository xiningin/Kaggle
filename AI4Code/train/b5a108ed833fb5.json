{"cell_type":{"6b351497":"code","f57f37fb":"code","db2f59dd":"code","00e26437":"code","99cad73d":"code","3c857bde":"code","9d0ce122":"markdown","b0c53beb":"markdown","1213c0ce":"markdown","55f3f878":"markdown","05a14b99":"markdown","c6c8f354":"markdown"},"source":{"6b351497":"import numpy as np\nimport pandas as pd\nimport random \nimport os \nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n\nfrom xgboost import XGBClassifier\nimport optuna\nfrom sklearn.metrics import roc_auc_score\n\nTRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\n\nTEST_SIZE = 0.2\n\nOPTUNA_TRIALS = 100\nOPTUNA_ESR = 50\nOPTUNA_DIRECTION = \"maximize\"\n\nNFOLD = 100\nTREE_METHOD = 'gpu_hist'\nBOOSTER = \"gbtree\"\n\nSEED = 2002\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything()","f57f37fb":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\n#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","db2f59dd":"# split data \ny = train[TARGET]\nX = train.drop(columns=[TARGET])\nX_test = test\n\n# search best param\n\ndef objective(trial, data=X, target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777, stratify=y) \n    params = {\n        'objective': 'binary:logistic',\n        'max_depth': trial.suggest_int('max_depth',1, 20),\n        'eta': trial.suggest_float('eta', 1e-5, 0.1),\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 0.9, 0.1),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.1, 0.9, 0.1),\n        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 1e5),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 1e5),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        'predictor': \"gpu_predictor\",\n        'eval_metric': 'auc'\n    }\n    \n    model = XGBClassifier(**params,\n                         tree_method=TREE_METHOD, \n                         booster=BOOSTER,\n                         random_state=SEED)\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=OPTUNA_ESR, verbose=False)\n    preds = model.predict(X_test)\n    score = roc_auc_score(y_test, preds)\n    \n    return score\n\nstudy = optuna.create_study(direction=OPTUNA_DIRECTION)\nstudy.optimize(objective, n_trials=OPTUNA_TRIALS)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n\nparams=study.best_params\nprint(params)","00e26437":"def stratifiedShuffleSplitOOF(NFOLD,X,y,X_test,model,eval_function):\n    # OOF \n    stratifiedShuffleSplit = StratifiedShuffleSplit(NFOLD)\n\n    preds = np.zeros(len(X_test))\n    scores = []\n\n    for fold, (train_idx, valid_idx) in enumerate(stratifiedShuffleSplit.split(X,y)):\n\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n        \n        model.fit(X_train, y_train,verbose=False)\n\n        preds_valid = model.predict(X_valid)\n        score = eval_function(y_valid, preds_valid)\n        scores.append(score)\n\n        print(f\"Fold: {fold + 1} Score: {score}\")\n  \n        preds += model.predict(X_test) \/ stratifiedShuffleSplit.n_splits\n        \n    print(f\"\\nOverall Validation Score: {np.mean(scores)}\")\n    return preds","99cad73d":"model = XGBClassifier(**params,tree_method=TREE_METHOD,booster=BOOSTER,)\npreds = stratifiedShuffleSplitOOF(5,X,y,X_test,model,roc_auc_score)","3c857bde":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = preds.astype(int)\nsub.to_csv(SUBMISSION_PATH, index=False)\nsub.head()","9d0ce122":"# define OOF","b0c53beb":"# imports & variables","1213c0ce":"# use OOF  = > predict ","55f3f878":"# load & preprocess","05a14b99":"# build model ","c6c8f354":"# submit"}}