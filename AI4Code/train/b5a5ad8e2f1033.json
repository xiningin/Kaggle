{"cell_type":{"56df7235":"code","e38eb3fe":"code","4365a71a":"code","8bf3d19c":"code","0520c976":"code","9e19e789":"code","3b14d925":"code","1461bdd0":"code","a2526f4d":"code","c3970fa1":"code","f95c4106":"code","50218c21":"code","f4d35e81":"code","c98ca589":"code","8caeb32a":"code","b6e3f88d":"code","8ebf2e9f":"code","094b5c19":"code","d085e338":"code","ac57b4cf":"code","e4e01c26":"code","86432327":"code","a28e832f":"code","8f082574":"code","fb936aa7":"code","22f5543f":"code","7a12773b":"code","01650cf1":"markdown","7a6efbe3":"markdown"},"source":{"56df7235":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e38eb3fe":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","4365a71a":"test_data=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data=pd.read_csv('..\/input\/digit-recognizer\/train.csv')","8bf3d19c":"train_data.head()","0520c976":"train_data.shape","9e19e789":"test_data.shape","3b14d925":"test_data.head()","1461bdd0":"training=np.array(train_data,dtype='float32')\ntesting=np.array(test_data,dtype='float32')","a2526f4d":"plt.imshow(training[11,1:].reshape(28,28))","c3970fa1":"plt.imshow(testing[11,0:].reshape(28,28))","f95c4106":"W_grid=15\nL_grid=15\n\nfig,axes=plt.subplots(L_grid,W_grid,figsize=(17,17))\n\naxes=axes.ravel()\n\nn_training=len(training)\n\nfor i in np.arange(0,W_grid*L_grid):\n    #Select the random no\n    index=np.random.randint(0,n_training)\n    axes[i].imshow(training[index,1:].reshape(28,28))\n    axes[i].set_title(training[index,0],fontsize=8)\n    axes[i].axis('off')\nplt.subplots_adjust(hspace=0.4)   ","50218c21":"x_train=training[:,1:]\/255\ny_train=training[:,0]","f4d35e81":"x_test=testing[:,0:]\/255","c98ca589":"X_train=x_train.reshape(x_train.shape[0],*(28,28,1))\nX_test=x_test.reshape(x_test.shape[0],*(28,28,1))","8caeb32a":"X_train.shape","b6e3f88d":"X_test.shape","8ebf2e9f":"from keras.utils.np_utils import to_categorical\ny_train_cat=to_categorical(y_train)","094b5c19":"import keras\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Model\nfrom keras import datasets, layers, models\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\nmodel =Sequential()\nmodel.add(Conv2D(64,kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1)))  # Convolution Layer -1 \nmodel.add(Conv2D(64,kernel_size=(3, 3),activation='relu'))                          # Convolution Layer -2 \nmodel.add(MaxPooling2D(pool_size=(2, 2)))                                               # Pooling Layer -1\nmodel.add(BatchNormalization())                                                      # Normalization \nmodel.add(Dropout(0.25))                                                             # Set 25% to 0 to prevent overfitting \n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),activation ='relu'))             # Convolution Layer -3 \nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),activation ='relu'))             # Convolution Layer -4 \nmodel.add(MaxPooling2D(pool_size=(2,2)))                                                # Pooling Layer -2 \nmodel.add(BatchNormalization())                                                      # Normalization\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),activation ='relu'))             # Convolution Layer -5 \nmodel.add(MaxPooling2D(pool_size=(2,2)))                                                # Pooling Layer -3 \nmodel.add(Dropout(0.25))                                                             # Set 25% to 0 to prevent overfitting\n\nmodel.add(Flatten())                                                                 # Flattens input\nmodel.add(BatchNormalization())                                                      # Normalization\nmodel.add(Dense(512, activation = \"relu\"))                                           # Connection Layer -1 \nmodel.add(Dropout(0.5))                                                              #  Set 50% to 0 to prevent overfitting\nmodel.add(Dense(10, activation = \"softmax\"))     ","d085e338":"model.summary()","ac57b4cf":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\n# Define Callback function for reducting learning rate when no more improvement of accuracy\nlearning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.3, \n                                            min_lr=0.0001)","e4e01c26":"# Fit train&test data\nepochs_range = 60\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#history = model.fit(X_train_tensor,y_train,batch_size=256,epochs=epochs_range,validation_data=(X_test_tensor,y_test_cat),callbacks=learning_rate_reduction )\nmodel.fit(X_train,y_train_cat,batch_size=256,epochs=epochs_range)","86432327":"y_pred=model.predict_classes(X_test)","a28e832f":"fig,axes=plt.subplots(8,8,figsize=(15,15))\n\naxes=axes.ravel()\n\nfor i in range(0,8*8):\n    axes[i].imshow(X_test[i,0:].reshape(28,28))\n    axes[i].set_title(\"Prediction Class = {:0.1f}\".format(y_pred[i]))\n    axes[i].axis('off')\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.5)","8f082574":"sample=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","fb936aa7":"temp=pd.DataFrame({'ImageId':sample['ImageId'],'Label':y_pred})","22f5543f":"temp.head()","7a12773b":"csv_data=temp.to_csv('pred.csv',index=False)","01650cf1":"Training Model","7a6efbe3":"**Model Building**"}}