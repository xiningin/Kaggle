{"cell_type":{"56e25803":"code","9d7374d8":"code","b15e4755":"code","4ff97170":"code","16a07a37":"code","ef2c635e":"code","3271bece":"code","db67305e":"code","7613502d":"code","586acb65":"code","1c5707b2":"markdown","0654d95e":"markdown","31b7a9da":"markdown"},"source":{"56e25803":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d7374d8":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","b15e4755":"train.info()\ntest.info()","4ff97170":"def cleandata(data):\n    \n    data.drop(['Name','Cabin','Ticket'],axis=1,inplace=True) \n    \n    #\n    data['Age'] = data.groupby(['Pclass','Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n    data['Fare'] = data.groupby(['Pclass','Sex'])['Fare'].transform(lambda x: x.fillna(x.median()))\n    \n    data.dropna(axis=0, subset=['Embarked'], inplace=True)\n    \n    #\n    data['Sex'].replace({'male':0, 'female':1}, inplace=True)\n    data['Embarked'].replace({'S':0, 'C':1, 'Q':2}, inplace=True)\n    \n    return data","16a07a37":"train2=pd.DataFrame(train)\ntest2=pd.DataFrame(test)\n\ncleandata(train2)\ncleandata(test2)\n\n#Check cleaning\ntrain2.info()\ntest2.info()","ef2c635e":"train2_x=train2.drop(['Survived'],axis=1)\ntrain2_y=train2[['Survived']]\n\nx_train=train2_x.values\ny_train=train2_y.values","3271bece":"#some useful function\n\n\ndef _sigmoid(z):\n    return np.clip(1\/(1.0+np.exp(-z)),1e-8,1-(1e-8))\n\ndef _f(x,w,b):\n    return _sigmoid(np.matmul(x,w)+b)\n\ndef _predict(x,w,b):\n    return pd.DataFrame(np.round(_f(x,w,b)).astype(np.int))\n\ndef _accuracy(y_pred,y_label):\n    acc=1-np.mean(np.abs(y_pred-y_label))\n    return acc\n","db67305e":"x_train_0=np.array([x for x,y in zip(x_train,y_train) if y==0])\nx_train_1=np.array([x for x,y in zip(x_train,y_train) if y==1])\n\n#Compute in-class mean\nmean_0=np.mean(x_train_0,axis=0)\nmean_1=np.mean(x_train_1,axis=0)\n\n#Compute in-class covariance\ncov_0=np.zeros((x_train.shape[1],x_train.shape[1]))\ncov_1=np.zeros((x_train.shape[1],x_train.shape[1]))\n\nfor x in x_train_0:\n    cov_0 += np.dot(np.transpose([x-mean_0]),[x-mean_0])\/x_train_0.shape[0]\nfor x in x_train_1:\n    cov_1 += np.dot(np.transpose([x-mean_1]),[x-mean_1])\/x_train_1.shape[0]\n\n#\ncov = (cov_0*x_train_0.shape[0]+cov_1*x_train_1.shape[0])\/(x_train_0.shape[0]+x_train_1.shape[0])","7613502d":"#\nu,s,v= np.linalg.svd(cov,full_matrices=False)\ninv= np.matmul(v.T*1\/s,u.T)\n\n#Compute weights and bias\nw=np.dot(inv , mean_0-mean_1)\nb=(-0.5)*np.dot(mean_0,np.dot(inv,mean_0))+0.5*np.dot(mean_1,np.dot(inv,mean_1)) \\\n  + np.log(float(x_train_0.shape[0])\/x_train_1.shape[0])\n\n#Cumpute accuracyd on training set\ny_train_pred=1-_predict(train2_x,w,b)\ntrain_accracy=_accuracy(y_train_pred.values,train2_y.values)\ntrain_accracy","586acb65":"y_test_pred=1-_predict(test2,w,b)\ny_test_pred=pd.DataFrame({'PassengerId':test2['PassengerId'],'Survived':y_test_pred.values.reshape(-1,)})\ny_test_pred.to_csv('Titanic output',index=False)","1c5707b2":"# Data","0654d95e":"# Data cleaning","31b7a9da":"# Modeling"}}