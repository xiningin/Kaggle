{"cell_type":{"44c7e4ef":"code","9a39c373":"code","e9948a77":"code","9317395e":"code","f0596c75":"code","902546e5":"code","690a8ece":"code","afedb93b":"code","1794c2fb":"code","311d7bb8":"code","6decb5d6":"code","e447d650":"code","fcdcf2c5":"code","883d0be4":"code","94cf2f25":"code","44cba610":"code","2ea60cd3":"code","e3dc088d":"code","dfdf3761":"code","da69b217":"code","5e1795b9":"code","0c37f862":"code","d9b41179":"code","3a2cfd84":"code","b89f3ad8":"code","df00aeb6":"code","b939f8bb":"code","db438513":"code","3f20d9d6":"code","305e02ec":"code","f87866ef":"code","99c44128":"code","8a816378":"code","aae8dfce":"code","a453a258":"code","377222b3":"code","b5806c5e":"code","78b9e068":"code","2702c8fc":"code","fd566976":"markdown","d7d4cc4a":"markdown","b4ef0326":"markdown","4353aaec":"markdown","0495a1ab":"markdown","c8f0dd15":"markdown","7acbde17":"markdown","3c2d42a8":"markdown"},"source":{"44c7e4ef":"# import required libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing import image\nfrom pathlib import Path\nimport os\nimport glob  # used for loading multiple files","9a39c373":"# get the list of subdirectories to find out where the data files are \nprint(os.listdir(\"..\/input\"))","e9948a77":"# load the trian labels and sample submission files into dataframes\nraw_train = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\nsample_submission = pd.read_csv('..\/input\/severstal-steel-defect-detection\/sample_submission.csv')","9317395e":"# create a copy of the train dataframe into the labels dataframe\nlabels = raw_train.copy()\nlabels.tail(4)","f0596c75":"# split the ImageId_ClassId column into image_id and class_id\nimport re\n\nlabels['class_id'] = labels['ImageId_ClassId'].str.extract(r'.jpg_(\\d)')  # extract the last digit right after underscore(_)\nlabels['class_id'] = labels['class_id'].astype(int)                       # change the class_id data type to numeric\nlabels['image_id'] = labels['ImageId_ClassId'].str.extract(r'(\\w*\\d*.jpg)_\\d')  # extract the first set of characters before underscore\n\nlabels = labels[['image_id','EncodedPixels','class_id']]                 # exclude the unnecessary columns from labels at this stage\nlabels.tail(4)","902546e5":"# create a flag for the faulty images - defect is present where EncodedPixels is not NaN \nlabels['has_defects'] = labels.EncodedPixels.apply(lambda x: 1 if not pd.isnull(x) else 0)\nlabels.tail(4)","690a8ece":"# determine the number of defect per image by adding the has_defect values for each image_id\n\ndefects = pd.DataFrame(labels.groupby(by=\"image_id\")['has_defects'].sum())\ndefects.reset_index(inplace=True)  # convert the image_id which is an index to a column so that the dataframes can be joined on that\ndefects.rename(columns={\"has_defects\": \"no_of_defects\"},inplace=True) # rename the aggregated column ready for the join \n\n# left join the no_of_defects to the labels dataframe\nlabels = labels.merge(defects, left_on='image_id', right_on='image_id', how='left')\nlabels.tail(4)","afedb93b":"# plot the number of images per class\nsns.countplot(labels.class_id[labels.EncodedPixels.notnull()])","1794c2fb":"labels.class_id[labels.EncodedPixels.notnull()].value_counts().sort_values() # 7,095","311d7bb8":"# create a dataframe of unique image_id and the number of defects per image\ndedup_labels = labels[['image_id','no_of_defects']].drop_duplicates()\ndedup_labels.no_of_defects.value_counts().sort_values() # 6,666","6decb5d6":"# plot the number of images per number of defects \nsns.countplot(dedup_labels.no_of_defects)","e447d650":"# get a list of items in the \/input\/severstal-steel-defect-detection directory\nprint(os.listdir(\"..\/input\/severstal-steel-defect-detection\"))","fcdcf2c5":"# get a list of images in the \/input\/severstal-steel-defect-detection\/train_images directory\n# print(os.listdir(\"..\/input\/severstal-steel-defect-detection\/train_images\"))","883d0be4":"# set the variables for the paths of train and test image directories\ntrain_img_path = '..\/input\/severstal-steel-defect-detection\/train_images\/'\ntest_img_path = '..\/input\/severstal-steel-defect-detection\/test_images\/'","94cf2f25":" # number of image files in the train_img_path directory\nprint (len([name for name in os.listdir(train_img_path) if os.path.isfile(os.path.join(train_img_path, name))]))","44cba610":"import cv2\n\nimg = cv2.imread(train_img_path+'6dcbc2c43.jpg')\nplt.imshow(img)\nplt.show()","2ea60cd3":"img.shape","e3dc088d":"# function to plot n image of class of class_id\n# adopted from https:\/\/www.kaggle.com\/bonhart\/simple-cnn-on-pytorch-for-beginers\ndef metal_plot(class_id,n):\n    fig,ax = plt.subplots(1,n,figsize=(15,30))\n\n    for i, idx in enumerate(labels[(labels['class_id'] == class_id) & (labels['has_defects'] == 1)]['image_id'][-n:]):\n      path = os.path.join(train_img_path,idx)\n      ax[i].imshow(cv2.imread(path)) ","dfdf3761":"# class 1 sample images\nmetal_plot(1,3)","da69b217":"# class 2 sample images\nmetal_plot(2,3)","5e1795b9":"# class 3 sample images\nmetal_plot(3,3)","0c37f862":"# class 4 sample images\nmetal_plot(4,3)","d9b41179":"# plot metals with different number of defects\ndef def_vs_no_def(no_of_defects,n):\n    fig,ax = plt.subplots(1,n,figsize=(15,30))\n\n    for i, idx in enumerate(labels[labels['no_of_defects'] == no_of_defects]['image_id'][-n:]):\n      path = os.path.join(train_img_path,idx)\n      ax[i].imshow(cv2.imread(path)) ","3a2cfd84":"# no defects\ndef_vs_no_def(0,3)","b89f3ad8":"# with 1 defect\ndef_vs_no_def(1,3)","df00aeb6":"# with 2 defects\ndef_vs_no_def(2,3)","b939f8bb":"# with 3 defects\ndef_vs_no_def(3,3)","db438513":"# os.listdir(\"..\/input\/severstal-steel-defect-detection\/train_images\")","3f20d9d6":"import glob\n\nfolders = glob.glob(train_img_path)\n\nimagenames_list = []\nfor folder in folders:\n#     for f in os.listdir(\"..\/input\/severstal-steel-defect-detection\/train_images\"):\n    for f in glob.glob(folder+'*.jpg'):\n        imagenames_list.append(f)\n\nread_images = [] \nfor image in imagenames_list:\n    read_images.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE))\n","305e02ec":"# imagenames_list","f87866ef":"plt.imshow(read_images[160])","99c44128":"read_images[160].shape","8a816378":"read_images[160]","aae8dfce":"from tensorflow.python.keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input","a453a258":"image_size = 256\ndef read_and_prep_images(img_paths,img_height=image_size,img_width=image_size):\n    imgs = [load_img(img_path,target_size=(img_height,img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    return(output)","377222b3":"from os.path import join\nimage_dir = train_img_path\nimg_paths = [join(image_dir, filename) for filename in \n                           ['7bb25cc94.jpg', '2eb516639.jpg', '390e9ea29.jpg', 'fc20db1e0.jpg', '5238bc100.jpg', 'cff9230ae.jpg'\n                            , '8088f6b20.jpg', '5b3685c8c.jpg', 'd7939330f.jpg', 'cd4a71d17.jpg', '180478e66.jpg', '20b5096a5.jpg'\n                            , 'f3a5aa94c.jpg', 'ea56440ac.jpg', 'c487b1ce1.jpg', 'a6f761c3f.jpg', '3f400c81f.jpg', 'ed1c6be8d.jpg'\n                            , '7025a90c1.jpg', '58a9d89c8.jpg', '74bbe241c.jpg', '8ad6b411a.jpg', '0181695f9.jpg', 'a2a8ba02d.jpg'\n                            , 'f4296a45d.jpg', '89eec1aae.jpg', 'cc7920c72.jpg', '519e11f0b.jpg', 'f81b617ec.jpg', 'e90bfe49b.jpg'\n                            , 'df917bee3.jpg', '2acd6db1e.jpg', '5172a46ee.jpg', '0ddbc9fb5.jpg', 'ac1a64a23.jpg', 'dc59b5377.jpg'\n                            , 'bc67d17de.jpg', '22ee0a368.jpg', 'ead245f1f.jpg', 'fdc83849e.jpg', '0ba2d403f.jpg', '49a4b51fa.jpg'\n                            , '165a55d5c.jpg', '661c42b97.jpg', '6dbd47d4f.jpg', '1f45f2491.jpg', '4bb7b1660.jpg', 'b3ae9675d.jpg'\n                            , '56ba7c882.jpg', 'df4d01acb.jpg', '2e12e1c6a.jpg', 'd3ef4bac1.jpg', '83bd40de8.jpg', '19fd40586.jpg'\n                            , 'dae3c563a.jpg', '5663a9e34.jpg', '04c3aade7.jpg', '9a8475c90.jpg', '1ecfcc78b.jpg', '28a1ea8c2.jpg'\n                            , 'babdf889d.jpg', '74211b046.jpg', '1065b4d64.jpg', 'cc3a294d4.jpg', 'ae41ecb3f.jpg', 'f375d814f.jpg'\n                            , '4d9973900.jpg', '47f5c8e07.jpg', 'cdf44eab9.jpg', '2d18eccdd.jpg', '00c6060db.jpg', 'd91c205e6.jpg'\n                            , '3a0e5cad8.jpg', 'b3cea5fb4.jpg', '541707319.jpg', 'ea17260aa.jpg', 'd808c5310.jpg', '3e1ed281b.jpg'\n                            , '195e36565.jpg', 'a88757126.jpg', '0e15479f7.jpg', '1f5af3611.jpg', 'f32454873.jpg', '974171041.jpg'\n                            , '5432fd9e1.jpg', 'df79cce6c.jpg', '9c2dc4bfc.jpg', 'ce7b7ac0b.jpg', 'f71f9c14b.jpg', '938a15be6.jpg'\n                            , '05c05ea43.jpg', '554cbd6bf.jpg', '8fb078599.jpg', 'cd38fd93a.jpg', 'e63ad114c.jpg', 'bae58dc36.jpg'\n                           ]]","b5806c5e":"train_images_df = read_and_prep_images(img_paths,img_height=image_size,img_width=image_size)\ntrain_images_df[1]","78b9e068":"raw_train.head(4)","2702c8fc":"# from keras.preprocessing.image import ImageDataGenerator\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1.\/255,\n#     validation_split=0.15,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True\n# )\n\n# train_generator = train_datagen.flow_from_dataframe(\n#     raw_train,\n#     directory=train_img_path,\n#     subset='training',\n#     x_clo='image_id',\n#     y_col='class_id',\n#     target_size=(256, 1600),\n#     class_mode='sparse'\n#     )","fd566976":"## 2.4. Mapping the image files to the image_ids in the training set","d7d4cc4a":"# Severstal: Steel Defect detection - Competition Background\nCompetitors are asked to use machine\/deep learning algorithms to detect areas of fault on a set of steel images. There are 4 classes of defects present in the images and each metal may or may not have defects on its surface. Also, each faulty metal may contain one or multiple defects. \n\nThe labels(classes) are given in _train.csv_. Note that there are 4 rows per image each relates to a defect class i.e. classes 1 to 4. If the defect is present in a class, the corresponding **EncodedPixels** column has a non-null value. The actual image files are also provided.  ","b4ef0326":"# 1. Import and explore data","4353aaec":"## 2.3. Alternative approach for loading images","0495a1ab":"## 2.1. Import and display sample image from the train set","c8f0dd15":"**Caution:**\n\nDo not sum the no_of_defects column to calculate the total number of defects per image_id as this is should be a single scalar per image_id but due to duplicate records per image_id it has been repeated too.","7acbde17":"## 2.2. Load the training images","3c2d42a8":"# 2. Load the images files from the zip directory"}}