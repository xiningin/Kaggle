{"cell_type":{"a03e6f58":"code","fce440bc":"code","429c0ed5":"code","73c81349":"code","9b35ea5a":"code","b2e0f92c":"code","58ab3f7d":"code","6b054b4a":"code","95f610fc":"code","5e83fe97":"code","ec052f37":"code","f2f3e648":"code","ce261735":"code","2a2348a6":"code","de23e4e2":"code","76fbb671":"code","52af106b":"code","11190159":"code","2dfd6930":"code","4f95f83a":"code","3c5364a9":"code","53e6009d":"code","4725783e":"code","bc96d74c":"code","74216854":"code","3a0289d9":"code","7ca94b92":"code","b697941d":"code","67438bbe":"code","6f823560":"code","89a7e85a":"code","fefba7a6":"code","fdc7f4c9":"code","95e87659":"code","a86c68b6":"code","af5eb032":"code","1b45a76f":"code","1fb8eeec":"code","88db61c4":"markdown","794c6f0a":"markdown","f8534d19":"markdown","6e041fb9":"markdown","51a4590e":"markdown","eeb42ec6":"markdown","eb866bb5":"markdown","7dc54bcb":"markdown","7bd48e72":"markdown","f9d548a3":"markdown","6563c999":"markdown","ef2d70e9":"markdown","5804efec":"markdown","20f07451":"markdown","ca7c9288":"markdown","bf929a00":"markdown","8d90df40":"markdown","31c1a900":"markdown","0a5da460":"markdown","ce11f00c":"markdown","571c79fe":"markdown","9f2e81d9":"markdown","0ef9706e":"markdown","9ed8fe23":"markdown","e907d120":"markdown","06206dbe":"markdown","ad871667":"markdown","d8210daf":"markdown"},"source":{"a03e6f58":"import pandas\nimport os\nimport glob\nimport tensorflow as tf\nfrom keras.applications import ResNet50V2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras\nimport os\nimport seaborn as sns\nimport cv2\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import classification_report\n\nimport seaborn as sns\nimport glob","fce440bc":"main_path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\n","429c0ed5":"train_path = os.path.join(main_path,\"train\")\ntest_path=os.path.join(main_path,\"test\")\nval_path=os.path.join(main_path,\"val\")\n\npneumonia_train_images = glob.glob(train_path+\"\/PNEUMONIA\/*.jpeg\")\nnormal_train_images = glob.glob(train_path+\"\/NORMAL\/*.jpeg\")\n\npneumonia_val_images = glob.glob(val_path+\"\/PNEUMONIA\/*.jpeg\")\nnormal_val_images = glob.glob(val_path+\"\/NORMAL\/*.jpeg\")\n\npneumonia_test_images = glob.glob(test_path+\"\/PNEUMONIA\/*.jpeg\")\nnormal_test_images = glob.glob(test_path+\"\/NORMAL\/*.jpeg\")","73c81349":"data = pd.DataFrame(np.concatenate([[0]*len(normal_train_images) , [1] *  len(pneumonia_train_images)]),columns=[\"class\"])","9b35ea5a":"plt.figure(figsize=(10,8))\n\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\n\nplt.title('Number of cases', fontsize=14)\nsns.countplot(data['class'],data=data)","b2e0f92c":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\n\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512,512))\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()    \nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()    \nplt.show()","58ab3f7d":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.Canny(img, 80, 100)\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.Canny(img, 80, 100)\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()    \nplt.show()","6b054b4a":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), 512\/10), -4, 128)\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()\nplt.show()\n\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), 512\/10), -4, 128)\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()","95f610fc":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512,512))\n    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    image = cv2.GaussianBlur(image, (11, 11), 0)\n    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n    sobel_x = np.uint8(np.absolute(sobel_x))\n    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1)\n    sobel_y = np.uint8(np.absolute(sobel_y))\n    edged = cv2.bitwise_or(sobel_x, sobel_y)\n    ax.imshow(edged)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512,512))\n    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    image = cv2.GaussianBlur(image, (11, 11), 0)\n    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n    sobel_x = np.uint8(np.absolute(sobel_x))\n    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1)\n    sobel_y = np.uint8(np.absolute(sobel_y))\n    edged = cv2.bitwise_or(sobel_x, sobel_y)\n    ax.imshow(edged)\n    ax.set_title(\"normal\")\nfig.tight_layout()\nplt.show()","5e83fe97":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=3)\n    ax.imshow(img_erosion)\n    ax.set_title(\"normal\")\nfig.tight_layout()\nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=3)\n    ax.imshow(img_erosion)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()","ec052f37":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal_train_images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.dilate(img, kernel, iterations=3)\n    ax.imshow(img_erosion)\n    ax.set_title(\"Normal\")\nfig.tight_layout()\nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia_train_images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.dilate(img, kernel, iterations=3)\n    ax.imshow(img_erosion)\n    ax.set_title(\"Pneumonia\")\nfig.tight_layout()\nplt.show()","f2f3e648":"val_Pneumonia = len(os.listdir(val_path+'\/PNEUMONIA'))\nval_Normal =len(os.listdir(val_path+'\/NORMAL'))\nprint(f'len(val_Normal) = {val_Normal},len(val_Pneumonia)={val_Pneumonia}')","ce261735":"from distutils.dir_util import copy_tree\n# This will let us transfer our file from input dir to kaggles working\/temp\ncopy_tree(main_path,'temp')","2a2348a6":"path = '.\/temp\/chest_xray'","de23e4e2":"train_path = os.path.join(path,\"train\")\ntest_path=os.path.join(path,\"test\")\nval_path=os.path.join(path,\"val\")","76fbb671":"val_Pneumonia = len(os.listdir(val_path+'\/PNEUMONIA'))\nval_Normal =len(os.listdir(val_path+'\/NORMAL'))\nprint(f'len(val_Normal) = {val_Normal},len(val_Pneumonia)={val_Pneumonia}')","52af106b":"for i in ['\/NORMAL\/','\/PNEUMONIA\/']:\n    for img in os.listdir(train_path+i)[:191]:\n        os.replace(train_path+i+img, val_path+i+img)","11190159":"val_Pneumonia = len(os.listdir(val_path+'\/PNEUMONIA'))\nval_Normal =len(os.listdir(val_path+'\/NORMAL'))\nprint(f'len(val_Normal) = {val_Normal},len(val_Pneumonia)={val_Pneumonia}')","2dfd6930":"COUNT_NORMAL = data['class'].value_counts()[0]\nCOUNT_PNEUMONIA = data['class'].value_counts()[1]\nTOTAL_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\n\ninitial_bias = np.log([COUNT_PNEUMONIA\/COUNT_NORMAL])\ninitial_bias","4f95f83a":"weight_class_0 = (1 \/ COUNT_NORMAL)*(TOTAL_COUNT)\/2.0 \nweight_class_1 = (1 \/ COUNT_PNEUMONIA)*(TOTAL_COUNT)\/2.0\n\nclass_weight = {0: weight_class_0, 1: weight_class_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_class_0))\nprint('Weight for class 1: {:.2f}'.format(weight_class_1))\n# We can use this metric but it actually hit to recall for class 1 pretty bad, so we'll not use it here.","3c5364a9":"# define the tvalue_countse of augmentation techniques we will apply.\ntrain_Datagen = ImageDataGenerator(\n    rescale =1\/255,\n#     shear_range=10,\n    zoom_range = 0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n#     rotation_range=20,\n    fill_mode = 'nearest',\n)\nval_datagen = ImageDataGenerator(\n    rescale =1\/255,\n#     shear_range=10,\n#     zoom_range = 0.2,\n#     horizontal_flip = True,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     rotation_range=20,\n#     fill_mode = 'nearest',\n)","53e6009d":"train_generator=train_Datagen.flow_from_directory(\n    train_path,\n    target_size=(512,512),\n    batch_size= 32,\n    class_mode='binary'\n)\nvalidation_generator = val_datagen.flow_from_directory(\n        test_path,\n        target_size=(512,512),\n        batch_size=32,\n        class_mode='binary'\n)\ntest_generator = val_datagen.flow_from_directory(\n    val_path,\n    target_size=(512,512),\n    batch_size=32,\n    class_mode='binary'\n)","4725783e":"base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(128, activation = 'relu',kernel_regularizer= keras.regularizers.l2(l2=0.1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","bc96d74c":"from keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\n\n# Creating LR Scheduler\ninitial_learning_rate = 1e-3\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=755,\n    decay_rate=0.9,\n    staircase=True)\n\nMETRICS = ['accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n\nmodel.compile(optimizer= Adam(lr_schedule), loss='binary_crossentropy', metrics=METRICS)\n\n#callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)\n\nhistory = model.fit(train_generator,\n                    epochs=10,\n                    steps_per_epoch = 4834 \/\/ 32,\n                    validation_data = validation_generator,\n                    validation_steps = 624 \/\/ 32,\n                    class_weight=None\n                   )","74216854":"model.evaluate(test_generator)[1]","3a0289d9":"model.evaluate(validation_generator)[1]","7ca94b92":"for layer in base_model.layers[:165]:\n    layer.trainable = False\nfor layer in base_model.layers[165:]:\n    layer.trainable = True","b697941d":"# Learning Rate\ninitial_learning_rate = 1e-5\n\n# Learning Rate Scheduler\nlr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=755,\n    decay_rate=0.9,\n    staircase=True)\n\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),  # Very slow learning rate\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=METRICS)","67438bbe":"history_new = model.fit(train_generator,\n                        epochs=20,\n                        steps_per_epoch = 4834 \/\/ 32,\n                        validation_data = validation_generator,\n                        validation_steps = 624 \/\/ 32,\n                        )","6f823560":"accuracy = history_new.history['accuracy']\nval_accuracy  = history_new.history['val_accuracy']\n\nloss = history_new.history['loss']\nval_loss = history_new.history['val_loss']","89a7e85a":"fig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])\n","fefba7a6":"model.evaluate(validation_generator)[1]","fdc7f4c9":"model.evaluate(test_generator)[1]","95e87659":"y_true=test_generator.classes[test_generator.index_array]  ","a86c68b6":"y_pred = np.squeeze(model.predict_classes(test_generator))","af5eb032":"print(classification_report(y_true,y_pred))","1b45a76f":"from sklearn.metrics import confusion_matrix\n\nsns.heatmap(confusion_matrix(y_true,y_pred),annot=True)","1fb8eeec":"cm = confusion_matrix(y_true,y_pred)\n\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\n","88db61c4":"# 3. EDA","794c6f0a":"We saw the same results with the Sobel Filter. There is definitely a pattern.","f8534d19":"# 2. Importing Libraries","6e041fb9":"We can see the Pneumonia X-ray images are quite blurry.","51a4590e":"## Image Erosion","eeb42ec6":"## Ben Graham's Method\nThis method involves 2 steps:\n1. GrayScaling the images\n2. Applying Gaussian Blur","eb866bb5":"## Image Dialation","7dc54bcb":"# 1. Understanding the Data\nPneumonia is a very common disease. It can be either: \n- Bacterial pneumonia \n- Viral Pneumonia \n- Mycoplasma pneumonia and \n- Fungal pneumonia. \n\nThis dataset consists pneumonia samples belonging to the first two classes. The dataset consists of only very few samples and that too unbalanced. The aim of this notebook is to develop a robust deep learning model on this limited amount of data. We all know that deep learning models are data hungry but if you know how things work, you can build good models even with a limited amount of data.\n","7bd48e72":"## 4.2 Correct for data imbalance\nWe saw earlier in this notebook that the data was imbalanced, with more images classified as pneumonia than normal. We will correct for that in this following section.","f9d548a3":"## Sobel Filter\n\nThe image is first read in as a grayscale image and converted to a matrix, then vertical and horizontal Sobel filters are applied to extract edges. Finally, we find the edge farthest from the center (approximated by the vertical center of the image) and crop vertically along this.","6563c999":"\n> Keeping in mind the risk of changing the distribution of validation data, keeping that in mind I'll  be using our **Test data** as **Validation data**","ef2d70e9":"# 6. Finetuning the Model: \nFinetuning is an art when it comes to Machine Learning, and there are many ways to adjust the model in efforts to improve it. Finetuning is beyond the scope of this notebook, but check out this [article](https:\/\/www.pyimagesearch.com\/2020\/04\/27\/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning\/) for more information.\n\nFor our purposes, we'll use Keras callbacks to further finetune our model. The checkpoint callback saves the best weights of the model, so next time we want to use the model, we do not have to spend time training it. The early stopping callback stops the training process when the model starts becoming stagnant, or even worse, when the model starts overfitting. Since we set restore_best_weights to True, the returned model at the end of the training process will be the model with the best weights (i.e. low loss and high accuracy).","5804efec":"## Images with Canny Edges","20f07451":"## Basic X-Ray images","ca7c9288":"## Understanding the Stake\n\nMachine Learning & Deep Learning has proven to be really effective in the field of heathcare. \nWhen it comes to healthcare, its not just a classification problem, **the stake is very high** and as a Data Scientist it is our responsiblity to make use of what minimal data we have in a best possible way.","bf929a00":"# 98% Accuracy\n\nI hope you enjoyed the notebook. Happy Kaggling!!\n<br>\nIf you liked it leave an upvote and if not leave your suggestions in the comments.  ","8d90df40":"# 7. Visualizing Model Performance","31c1a900":"## Shifting some training data to Validation data\n","0a5da460":"If you look carefully, then there are some cases where you won't be able to differentiate between a normal case and a pneumonia case with the naked eye. There is one case in the above plot, at least for me ,which is too much confusing. If we can build a robust classifier, it would be a great assist to the doctor too.\n\nLet's try some other pre-processing techniques.","ce11f00c":"**The data is imbalanced, we can see that for almost every Normal-xray images there are 3 Pneumonia-xray images**","571c79fe":"## 4.1 Dealing with Lack of data in Validation Dir","9f2e81d9":"# 4. Dealing with Data Imbalance\n*imbalance in both classes as well as the lack of enough data in validation dir*\n\n\n#### Validation data is quite small so we need to add more information to Validation data, so as the reduce the variance in the **Validation Accuracy**","0ef9706e":"# 8. Predicting and Evaluating Results","9ed8fe23":"## 5.1 Data Generators with Image Augmentation","e907d120":"# 5.2 Creating Model (Using pre-trained resnet50 on 'image-net')","06206dbe":"We duplicated the same results with the Ben-Grahams model.","ad871667":"Can we see a differnce, yes we do. I think we might be able to find a good pattern among the images in the earlier layers of the model itself.","d8210daf":"# 5. Model:\nThis is the best part and I suggest you to write the whole model from scratch(the basic **Convnet** worked pretty good, also the **Depthwise Separable Convnet** also worked really well). In this kernel I used transfer learning after trying out those ideas and got the best result. But also we are kaggling to learn not to implement the best model. One could also try partial transfer learning. I'll make a seprate notebook on that."}}