{"cell_type":{"c501b8da":"code","e65d65d3":"code","49601154":"code","b44ca36a":"code","6e6d3bfe":"code","cf8b652e":"code","96d8b126":"code","4060536b":"code","e5304eff":"code","b5cda966":"code","05027606":"code","069a17ed":"code","e078d07f":"code","6650bad0":"code","01b26dd8":"code","3d750267":"code","5448986c":"code","c3df4977":"code","909ea33e":"code","31b304c9":"code","3fadc8c5":"code","4f0f170b":"code","eb72679e":"code","d6439535":"code","bb845d18":"code","ba77e117":"code","f98ae1ff":"code","cace6028":"code","1d3c88db":"code","ee3d14c1":"code","8d253e93":"code","8395ba89":"code","8edb25c7":"code","6a1e2a3b":"code","f47a0190":"code","f49eda90":"code","daedbf05":"code","57a55916":"code","06172fd3":"code","829604c6":"code","03fa423f":"code","021a5ace":"code","f359d7e3":"code","52f86aad":"markdown","ec42e8e0":"markdown","230e3c19":"markdown","3514ac5d":"markdown","cbf5ffb6":"markdown","1e8e1773":"markdown","9b1fa646":"markdown","9c21e88c":"markdown","55d4cb9e":"markdown","8b554458":"markdown","10770b2f":"markdown","c7ace118":"markdown","a26ba768":"markdown","0b7e2a57":"markdown","69e32289":"markdown","1da95926":"markdown","d5b0c574":"markdown","b1d58261":"markdown","635d9a93":"markdown","bd5e2cea":"markdown","4a36051e":"markdown","adaa5fcb":"markdown","a9b0e706":"markdown","57c8a1ff":"markdown","8706de4e":"markdown","5511c7c8":"markdown","e36a05c9":"markdown","deeb9555":"markdown","2a956858":"markdown","6fd5059e":"markdown","3f6a3f9e":"markdown","3b381ef7":"markdown","44ecf1fb":"markdown","ee3d5952":"markdown","82bb9a86":"markdown","0bea7d1c":"markdown","58840fb7":"markdown"},"source":{"c501b8da":"import pandas as pd\nimport seaborn as sns\nimport numpy as np","e65d65d3":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nx_train = pd.concat([train, test], sort = False).reset_index(drop = True)","49601154":"pd.set_option('display.max_columns',None)\nx_train.head(10)","b44ca36a":"x_train.info()","6e6d3bfe":"x_train.describe(include='all')","cf8b652e":"x_train.isna().sum()","96d8b126":"data_na = (x_train.isnull().sum() \/ len(x_train)) * 100\ndata_na = data_na.drop(data_na[data_na==0].index).sort_values(ascending=False)\nmissing_data=pd.concat([data_na], axis=1, keys=['Percent of NA'])\nmissing_data.drop(index='SalePrice', inplace=True)\nmissing_data","4060536b":"x_train.drop(columns=[\"Id\",\"Street\",\"Alley\",\"Utilities\",\"PavedDrive\",\"PoolQC\",\"MiscFeature\"], inplace=True)","e5304eff":"dic={}\ncolumname = [['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2'],\n             ['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond']]\n\nfor i in range(0,len(columname)):\n    for col in columname[i]:\n        num = x_train[col].isna().sum()\n        loc = x_train[col][x_train[col].isnull().values==True].index.tolist()\n        print('\u5217\u540d\uff1a\"{}\", \u6709\"{}\"\u500b\u7f3a\u5931\u503c'.format(col,num))\n        print('\u7f3a\u5931\u503c\u4f4d\u7f6e:\"{}\"'.format(loc))\n\n    for j in range(0,len(columname[i])):\n        listname = 'list' + str(j)\n        setname = 's'+ str(j)\n        dic.setdefault(listname,[])\n        dic.setdefault(setname,[])\n        dic[listname] = x_train[columname[i][j]][x_train[columname[i][j]].isnull().values==True].index.tolist()\n        dic[setname] = set(dic[listname])\n\n    s = dic['s0'] & dic['s1'] & dic['s2'] & dic['s3'] & dic['s4']\n    print('\u4ea4\u96c6:')\n    print(sorted(list(s)))\n\n    for j in range(0,len(columname[i])):\n        rmname = 'r' + str(j)\n        setname = 's'+ str(j)\n        dic.setdefault(rmname,[])\n        dic[rmname] = list(dic[setname].difference(s))\n        print('\u5217\u540d\uff1a\"{}\", \u5269\u9918\u7f3a\u5931\u503c\u4f4d\u7f6e\uff1a\"{}\"'.format(columname[i][j],dic[rmname]))\n    print('=======================================================')    ","b5cda966":"# \u8f49\u578b\u614b\nx_train.MSSubClass = x_train.MSSubClass.astype('str')\nx_train.YrSold = x_train.YrSold.astype('str')\n# \u7f3a\u5931\u503c\nx_train.MSZoning.fillna(*x_train.MSZoning.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.LotFrontage.fillna(x_train.LotFrontage.mean(), inplace=True) #\u88dc\u5e73\u5747\u503c\nx_train.Exterior1st.fillna(*x_train.Exterior1st.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.Exterior2nd.fillna(*x_train.Exterior2nd.mode(), inplace=True) #\u88dc\u773e\u6578\n\n# 'MasVnrType','MasVnrArea' \u6709\u95dc\u9023\u6027\u9700\u7279\u5225\u8655\u7406\nx_train.loc[2610,'MasVnrType'] = 'BrkFace' #\u500b\u6848\u512a\u5148\u586b\u5165\nx_train.MasVnrType.fillna(*x_train.MasVnrType.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.MasVnrArea.fillna(*x_train.MasVnrArea.mode(), inplace=True) #\u88dc\u773e\u6578\n\n# 'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2' \u6709\u95dc\u9023\u6027\n# \u500b\u6848\u512a\u5148\u586b\u5165\nx_train.loc[2217,'BsmtQual'] = 'TA'\nx_train.loc[2218,'BsmtQual'] = 'TA'\nx_train.loc[2040,'BsmtCond'] = 'TA'\nx_train.loc[2185,'BsmtCond'] = 'TA'\nx_train.loc[2524,'BsmtCond'] = 'TA'\nx_train.loc[948,'BsmtExposure'] = 'No'\nx_train.loc[2348,'BsmtExposure'] = 'No'\nx_train.loc[1487,'BsmtExposure'] = 'No'\nx_train.loc[332,'BsmtFinType2'] = 'Unf'\nx_train.BsmtQual.fillna(*x_train.BsmtQual.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtCond.fillna(*x_train.BsmtCond.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtExposure.fillna(*x_train.BsmtExposure.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtFinType1.fillna(*x_train.BsmtFinType1.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtFinType2.fillna(*x_train.BsmtFinType2.mode(), inplace=True) #\u88dc\u773e\u6578\n\nx_train.BsmtFinSF1.fillna(*x_train.BsmtFinSF1.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtFinSF2.fillna(*x_train.BsmtFinSF2.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtUnfSF.fillna(*x_train.BsmtUnfSF.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.TotalBsmtSF.fillna(*x_train.TotalBsmtSF.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.Electrical.fillna(*x_train.Electrical.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtFullBath.fillna(*x_train.BsmtFullBath.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.BsmtHalfBath.fillna(*x_train.BsmtHalfBath.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.KitchenQual.fillna(*x_train.KitchenQual.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.Functional.fillna(*x_train.Functional.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.FireplaceQu.fillna('None', inplace=True) #\u7528 None\u53d6\u4ee3\n\n# 'GarageType','GarageYrBlt','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond'  \u6709\u95dc\u9023\u6027\n#\u500b\u6848\u512a\u5148\u586b\u5165\nx_train.loc[2576,'GarageYrBlt'] = x_train.GarageYrBlt.median() \nx_train.loc[2126,'GarageYrBlt'] = x_train.GarageYrBlt.median() \nx_train.loc[2576,'GarageFinish'] = str(*x_train.GarageFinish.mode())\nx_train.loc[2126,'GarageFinish'] = str(*x_train.GarageFinish.mode())\nx_train.loc[2576,'GarageQual'] = str(*x_train.GarageQual.mode())\nx_train.loc[2126,'GarageQual'] = str(*x_train.GarageQual.mode())\nx_train.loc[2576,'GarageCond'] = str(*x_train.GarageCond.mode())\nx_train.loc[2126,'GarageCond'] = str(*x_train.GarageCond.mode())\nx_train.GarageCars.fillna(x_train.GarageCars.median(), inplace=True) #\u88dc\u4e2d\u4f4d\u6578\nx_train.GarageArea.fillna(x_train.GarageArea.median(), inplace=True) #\u88dc\u4e2d\u4f4d\u6578\nx_train.GarageType.fillna(*x_train.GarageType.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.GarageYrBlt.fillna(*x_train.GarageYrBlt.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.GarageFinish.fillna(*x_train.GarageFinish.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.GarageQual.fillna(*x_train.GarageQual.mode(), inplace=True) #\u88dc\u773e\u6578\nx_train.GarageCond.fillna(*x_train.GarageCond.mode(), inplace=True) #\u88dc\u773e\u6578\n\nx_train.Fence.fillna('None', inplace=True) #\u7528 None\u53d6\u4ee3\nx_train.SaleType.fillna(*x_train.SaleType.mode(), inplace=True) #\u88dc\u773e\u6578","05027606":"x_train.isna().sum()","069a17ed":"# \u67e5\u770b\u504f\u79fb\u60c5\u6cc1\nprint (\"The skewness of SalePrice is {}\".format(x_train['SalePrice'].skew()))\nsns.distplot(x_train.SalePrice[:1460])","e078d07f":"from scipy.stats import norm, skew\n\nnumeric_feats = x_train.dtypes[x_train.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = x_train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","6650bad0":"skewness.index","01b26dd8":"class SeabornFig2Grid():\n\n    def __init__(self, seaborngrid, fig,  subplot_spec):\n        self.fig = fig\n        self.sg = seaborngrid\n        self.subplot = subplot_spec\n        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n            isinstance(self.sg, sns.axisgrid.PairGrid):\n            self._movegrid()\n        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n            self._movejointgrid()\n        self._finalize()\n\n    def _movegrid(self):\n        \"\"\" Move PairGrid or Facetgrid \"\"\"\n        self._resize()\n        n = self.sg.axes.shape[0]\n        m = self.sg.axes.shape[1]\n        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n        for i in range(n):\n            for j in range(m):\n                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n\n    def _movejointgrid(self):\n        \"\"\" Move Jointgrid \"\"\"\n        h= self.sg.ax_joint.get_position().height\n        h2= self.sg.ax_marg_x.get_position().height\n        r = int(np.round(h\/h2))\n        self._resize()\n        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n\n        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n\n    def _moveaxes(self, ax, gs):\n        #https:\/\/stackoverflow.com\/a\/46906599\/4124317\n        ax.remove()\n        ax.figure=self.fig\n        self.fig.axes.append(ax)\n        self.fig.add_axes(ax)\n        ax._subplotspec = gs\n        ax.set_position(gs.get_position(self.fig))\n        ax.set_subplotspec(gs)\n\n    def _finalize(self):\n        plt.close(self.sg.fig)\n        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n        self.fig.canvas.draw()\n\n    def _resize(self, evt=None):\n        self.sg.fig.set_size_inches(self.fig.get_size_inches())","3d750267":"import matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsfg = SeabornFig2Grid\n\nexample =  x_train.copy() #\u526f\u672c\u4e00\u4efd\u7576EDA\u4f7f\u7528\nexample['SalePrice_log'] = np.log1p(example['SalePrice'])\nexample['GrLivArea_log'] = np.log1p(example['GrLivArea'])\n\nsns.set()\n\npp = sns.jointplot(x='GrLivArea',y='SalePrice',data=example,kind='reg').annotate(stats.pearsonr)\npp2 = sns.jointplot(x='GrLivArea_log',y='SalePrice_log',data=example,kind='reg').annotate(stats.pearsonr)\n\nfig = plt.figure(figsize=(12,6))\ngs = gridspec.GridSpec(1,2)\n\nsfg(pp, fig, gs[0])\nsfg(pp2, fig, gs[1])\nplt.tight_layout()\nplt.show()\n","5448986c":"train['SalePrice'] = np.log1p(x_train.SalePrice[:1460])\nprint ('Skewness is', train['SalePrice'].skew())\nsns.distplot(train.SalePrice)","c3df4977":"# \u6240\u6709 categorical \u6b04\u4f4d\u540d\u7a31\ncategorical = [var for var in x_train.columns if x_train[var].dtype=='O']\nprint('There are {} categorical variables'.format(len(categorical)))\n\n# \u6240\u6709 numerical \u6b04\u4f4d\u540d\u7a31\nnumerical = [var for var in x_train.columns if x_train[var].dtype!='O']\nprint('There are {} numerical variables'.format(len(numerical)))","909ea33e":"threshold = 20\ndiscrete = []\n\nfor var in numerical:\n    if len(x_train[var].unique()) < threshold:\n        discrete.append(var)\n\nprint('There are {} discrete variables'.format(len(discrete)))\n#print(discrete)\ncontinuous = [var for var in numerical if var not in discrete and var not in ['Id', 'SalePrice']]\n#print(continuous)\nprint('There are {} continuous variables'.format(len(continuous)))","31b304c9":"# \u6b63\u898f\u5316\u5176\u5b83\u7684\u9023\u7e8c\u6027\u8cc7\u6599\u6b04\u4f4d\ndef Normalized():\n    global x_train\n    for col in continuous:\n        # min-max\n        Min, Max = np.log1p(x_train[col]).min(), np.log1p(x_train[col]).max()\n        x_train[col] = (np.log1p(x_train[col]) - Min)\/(Max - Min)\nNormalized()        ","3fadc8c5":"from sklearn.preprocessing import LabelEncoder\n\n# process columns, apply LabelEncoder to categorical features\nfor col in categorical:\n    lbl = LabelEncoder()\n    lbl.fit(list(x_train[col].values)) \n    x_train[col] = lbl.transform(list(x_train[col].values))","4f0f170b":"x_train.head(10)","eb72679e":"x_test = x_train.iloc[1460:]\nx_train = x_train.head(1460)\nprint(x_train.shape, x_test.shape)","d6439535":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(40,40),dpi=80)  #\u8a2d\u7f6e\u756b\u5e03\u5927\u5c0f\u548c\u8fa8\u8b58\u7387\nhighcorr=[]\n\ncorr = x_train.corr()\n\n# \u6839\u64da\u71b1\u529b\u5716\u518d\u6b21\u6392\u9664 |\u76f8\u95dc\u4fc2\u6578|< ??\nprint('=============== Drop Corr ===================')\nfor i in range(0,len(corr)):\n    if abs(corr.SalePrice[i]) < 0.02:\n        print(corr.SalePrice.index[i], ':', corr.SalePrice[i])\n        colname = corr.SalePrice.index[i]\n        x_train.drop(columns=[colname], inplace=True)\n        x_test.drop(columns=[colname], inplace=True)\nprint('=============== High Corr ===================')        \nfor i in range(0,len(corr)):        \n    if abs(corr.SalePrice[i]) >= 0.5:\n        highcorr.append(corr.SalePrice.index[i])\n        print(corr.SalePrice.index[i], ':', corr.SalePrice[i])\nprint('=============== Shape ===================')         \nprint(x_train.shape, x_test.shape)","bb845d18":"for j in range(len(highcorr)-1):\n    colname = highcorr[j]\n    sns.pairplot(x_train,x_vars=colname, y_vars=['SalePrice'], height=5, kind=\"reg\")  #type your code here   ","ba77e117":"for i in range(x_train.index.max()):\n    if any([\n        x_train.loc[i,'YearBuilt'] < 0.2,\n        x_train.loc[i,'1stFlrSF'] < 0.2 or x_train.loc[i,'1stFlrSF'] > 0.7,\n        x_train.loc[i,'GrLivArea'] < 0.2 or x_train.loc[i,'GrLivArea'] > 0.8,\n        ]):\n        \n        x_train.drop([i],inplace=True)\n        train.drop([i],inplace=True)        \n","f98ae1ff":"for j in range(len(highcorr)-1):\n    colname = highcorr[j]\n    sns.pairplot(x_train,x_vars=colname, y_vars=['SalePrice'], height=5, kind=\"reg\")  #type your code here  ","cace6028":"Y_label = train.SalePrice\nx_train.drop(columns=['SalePrice'], inplace=True)\nx_test.drop(columns=['SalePrice'], inplace=True)","1d3c88db":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import ExtraTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\n\nX_train,X_vali,Y_train,Y_vali = train_test_split(x_train.values,Y_label.values,test_size = 0.3,random_state= 17)\nX_train.shape,X_vali.shape,Y_train.shape,Y_vali.shape","ee3d14c1":"from sklearn.model_selection import GridSearchCV\n\n# Set the parameters by cross-validation\ncv_params = {'n_estimators': [300, 400, 500, 600, 700]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,\n                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nn_est = optimized_GBM.best_params_['n_estimators']","8d253e93":"# Set the parameters by cross-validation\ncv_params = {'n_estimators': [n_est-50, n_est-25, n_est, n_est+25, n_est+50]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': 3, 'min_child_weight': 3, 'seed': 0,\n                'subsample': 0.7, 'colsample_bytree': 0.6, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nn_est = optimized_GBM.best_params_['n_estimators']","8395ba89":"# Set the parameters by cross-validation\ncv_params = {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'min_child_weight': [1, 2, 3, 4, 5, 6]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': 3, 'min_child_weight': 3, 'seed': 0,\n                'subsample': 0.7, 'colsample_bytree': 0.6, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\ndepth = optimized_GBM.best_params_['max_depth']\nweight = optimized_GBM.best_params_['min_child_weight']","8edb25c7":"# Set the parameters by cross-validation\ncv_params = {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': 0,\n                'subsample': 0.7, 'colsample_bytree': 0.6, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\ngamma = optimized_GBM.best_params_['gamma']","6a1e2a3b":"# Set the parameters by cross-validation\ncv_params = {'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': 0,\n                'subsample': 0.7, 'colsample_bytree': 0.6, 'gamma': gamma, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nsubs = optimized_GBM.best_params_['subsample']\nbytree = optimized_GBM.best_params_['colsample_bytree']","f47a0190":"# Set the parameters by cross-validation\ncv_params = {'reg_alpha': [0.05, 0.1, 1, 2, 3], 'reg_lambda': [0.05, 0.1, 1, 2, 3]}\n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': 0,\n                'subsample': subs, 'colsample_bytree': bytree, 'gamma': gamma, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nalpha = optimized_GBM.best_params_['reg_alpha']\nlamb = optimized_GBM.best_params_['reg_lambda']","f49eda90":"# Set the parameters by cross-validation\ncv_params = {'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]} \n\nother_params = {'learning_rate': 0.1, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': 0,\n                'subsample': subs, 'colsample_bytree': bytree, 'gamma': gamma, 'reg_alpha': alpha, 'reg_lambda': lamb,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nlearning = optimized_GBM.best_params_['learning_rate']","daedbf05":"# Set the parameters by cross-validation\ncv_params = {'seed': [0, 25, 50, 75, 100, 125, 150]}\n\nother_params = {'learning_rate': learning, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': 0,\n                'subsample': subs, 'colsample_bytree': bytree, 'gamma': gamma, 'reg_alpha': alpha, 'reg_lambda': lamb,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}\n\nmodel = XGBRegressor(**other_params)\noptimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\noptimized_GBM.fit(X_train, Y_train)\nprint('\u53c3\u6578\u6700\u4f73\u53d6\u503c\uff1a {0}'.format(optimized_GBM.best_params_))\nprint('\u6700\u4f73\u6a21\u578b\u5f97\u5206: {0}'.format(optimized_GBM.best_score_))\n\nseed = optimized_GBM.best_params_['seed']","57a55916":"other_params = {'learning_rate': learning, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': seed,\n                'subsample': subs, 'colsample_bytree': bytree, 'gamma': gamma, 'reg_alpha': alpha, 'reg_lambda': lamb,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}","06172fd3":"lm = LinearRegression()\nlm.fit(X_train,Y_train)\n\nrdgCV = RidgeCV(alphas=[0.01,0.1,1,10,100,1000], cv=5)\nrdgCV.fit(X_train,Y_train)\n\nrdg = Ridge(alpha=10)\nrdg.fit(X_train, Y_train)\n\nrfr = RandomForestRegressor(n_jobs=-1, n_estimators=100)\nrfr.fit(X_train,Y_train)\n\nabr = AdaBoostRegressor(n_estimators=100,learning_rate=1.,loss='linear')\nabr.fit(X_train,Y_train)\n\ngbr = GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=100,\n                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n                 max_depth=3, min_impurity_decrease=0.,\n                 min_impurity_split=None, init=None, random_state=None,\n                 max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None,\n                 warm_start=False, presort='auto')\ngbr.fit(X_train,Y_train)\n\nbr = BaggingRegressor(n_jobs=-1, n_estimators=100)\nbr.fit(X_train,Y_train)\n\netr = ExtraTreeRegressor()\netr.fit(X_train,Y_train)\n\n# xgboost\nxgb = XGBRegressor(**other_params)\nxgb.fit(X_train,Y_train)","829604c6":"from mlxtend.regressor import StackingCVRegressor\n\nstack = StackingCVRegressor(regressors=(lm , br, gbr), meta_regressor=xgb)\nstack.fit(X_train,Y_train)","03fa423f":"print('-- training score --')\nprint('LinearRegression:', lm.score(X_train, Y_train))\nprint('LinearRegression rdg:', rdg.score(X_train, Y_train))\nprint('LinearRegression rdgCV:', rdgCV.score(X_train, Y_train))\nprint('RandomForestRegressor rfr:', rfr.score(X_train, Y_train))\nprint('AdaBoostRegressor abr:', abr.score(X_train, Y_train))\nprint('GradientBoostingRegressor gbr:', gbr.score(X_train, Y_train))\nprint('BaggingRegressor br:', br.score(X_train, Y_train))\nprint('ExtraTreeRegressor etr:', etr.score(X_train, Y_train))\nprint('XGBRegressor xgb:', xgb.score(X_train, Y_train))\nprint('StackingCVRegressor stack:', stack.score(X_train, Y_train))\n\n\nprint()\n\nprint('-- Validation score --')\nprint('LinearRegression:', lm.score(X_vali, Y_vali))\nprint('LinearRegression rdg:', rdg.score(X_vali, Y_vali))\nprint('LinearRegression rdgCV:', rdgCV.score(X_vali, Y_vali))\nprint('RandomForestRegressor rfr:', rfr.score(X_vali, Y_vali))\nprint('AdaBoostRegressor abr:', abr.score(X_vali, Y_vali))\nprint('GradientBoostingRegressor gbr:', gbr.score(X_vali, Y_vali))\nprint('BaggingRegressor br:', br.score(X_vali, Y_vali))\nprint('ExtraTreeRegressor etr:', etr.score(X_vali, Y_vali))\nprint('XGBRegressor xgb:', xgb.score(X_vali, Y_vali))\nprint('StackingCVRegressor stack:', stack.score(X_vali, Y_vali))","021a5ace":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Model 1\ny_pred = xgb.predict(X_vali)\nplt.figure(figsize=(10, 5))\nplt.scatter(Y_vali, y_pred, s=20)\nplt.title('Predicted vs. Actual')\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.plot([min(Y_vali), max(Y_vali)], [min(Y_vali), max(Y_vali)], color='green',label='XGBRegressor')\nplt.legend(loc='upper left')\nplt.tight_layout()\n\n# Model 2\ny_pred = stack.predict(X_vali)\nplt.figure(figsize=(10, 5))\nplt.scatter(Y_vali, y_pred, s=20)\nplt.title('Predicted vs. Actual')\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.plot([min(Y_vali), max(Y_vali)], [min(Y_vali), max(Y_vali)], color='red',label='StackingCVRegressor')\nplt.legend(loc='upper left')\nplt.tight_layout()\n","f359d7e3":"label1 = np.expm1(xgb.predict(x_test.values))\nlabel2 = np.expm1(stack.predict(x_test.values))\n\nFinal_labels = label1*0.7 + label2*0.3\npd.DataFrame({'Id': test.Id, 'SalePrice': Final_labels}).to_csv('2019-2-22.csv', index=False)","52f86aad":">\u521d\u6b65\u4e1f\u68c4\u4e0d\u91cd\u8981\u7684\u6b04\u4f4d\n1. \u4e1f\u68c4\u7f3a\u5931\u503c>90%\u4e4b\u6b04\u4f4d (**Alley**,**MiscFeature**,**PoolQC**)\n2. \u4e1f\u68c4\u8207\u50f9\u683c\u4e0d\u91cd\u8981\u7684\u6b04\u4f4d\n  ","ec42e8e0":"# 6. \u504f\u614b\u8207\u5c0d\u6578\u8f49\u63db\n\u5c0d\u6578\u8f49\u63db\u7684\u76ee\u7684\u662f\u70ba\u4e86\u6e1b\u5c11\u6578\u503c\u5dee\u8ddd\u904e\u5927\u53ca\u96e2\u7fa4\u503c\u800c\u5e36\u4f86\u7684\u5f71\u97ff\uff0c\u5f9e\u7d55\u5c0d\u5dee\u7570\u8f49\u8b8a\u70ba\u76f8\u5c0d\u5dee\u7570\uff0c\u7279\u5fb5\u7684\u96e2\u6563\u7a0b\u5ea6\u7a69\u5b9a\u3002\n\n  - \u793e\u6703\u7d71\u8a08\u6578\u64da\u4f8b\u5982\u5bb6\u5ead\u5e73\u5747\u5e74\u6536,\u570b\u6c11\u4eba\u5747\u6240\u5f97\u7b49\u7b49\uff0c\u901a\u5e38\u90fd\u662f\u5c6c\u65bc\u53f3\u504f\u5206\u4f48\u7684\u8cc7\u6599\uff0c\u56e0\u70ba\u6709\u9322\u4eba\u5c6c\u65bc\u5c11\u6578\uff0c\u80af\u5b9a\u6703\u628a\u6574\u9ad4\u7684\u5e73\u5747\u62c9\u9ad8\uff0c\u800c\u4e14\u52d5\u8f12\u5e7e\u5104\u7684\u8eab\u50f9\u6703\u5c07x\u8ef8\u62c9\u5f97\u975e\u5e38\u975e\u5e38\u7684\u9577\uff0c\u53d6\u5c0d\u6578\u4e4b\u5f8c\uff0c\u5c31\u6703\u8b8a\u6210\u7d1a\u8ddd\u7684\u76f8\u5c0d\u5dee\u7570\uff0c\u4f8b\u5982\u5c07 $10^9$\u53d6$log10$\u5c31\u662f$9$\uff0c\u5dee\u8ddd\u77ac\u9593\u5c31\u6e1b\u5c11\uff0c\u4f46\u662f\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53d6\u5c0d\u6578\u5f8c\u7684\u8cc7\u6599\u55ae\u4f4d\u5c31\u4e0d\u5177\u610f\u7fa9\u4e86\u3002\n  \n\n  - \u4e0b\u5716\u662fGrLiveArea\u8207SalePrice\u6563\u4f48\u5716\u8207\u5bc6\u5ea6\u5716\uff0c\u5f9e\u5de6\u5716\u770b\u4f86\u5169\u8005\u6709\u5448\u73fe\u4e00\u9ede\u6307\u6578\u905e\u589e\u7684\u95dc\u4fc2\uff0c\u76f8\u95dc\u4fc2\u6578\u70ba0.73\uff0c\u5169\u8005\u7684\u8cc7\u6599\u5206\u4f48\u7686\u5448\u73fe\u53f3\u504f\u5206\u4f48\uff0c\u800c\u8ff4\u6b78\u6a21\u578b\u7684\u57fa\u672c\u5047\u8a2d\u662f\u8cc7\u6599\u70ba\u7dda\u6027\u95dc\u4fc2\uff0c\u986f\u7136\u9019\u7a2e\u5206\u4f48\u4e0d\u9069\u5408\u8ff4\u6b78\u6a21\u578b\uff0c\u6240\u4ee5\u9019\u88cf\u5c31\u9700\u8981\u7528\u5230\u5c0d\u6578\u8f49\u63db\uff0c\u53f3\u5716\u662f\u7d93\u904e\u5c0d\u6578\u8f49\u63db\u7684\u7d50\u679c\uff0c\u6211\u5011\u767c\u73fe\u7d93\u904e\u5c0d\u6578\u8f49\u63db\u5f8c\uff0c\u76f8\u95dc\u4fc2\u6578\u6709\u63d0\u5347\uff0c\u800c\u4e14\u5f9e\u975e\u7dda\u6027\u8f49\u70ba\u7dda\u6027\u3002","230e3c19":"# 2. \u8cc7\u6599\u63a2\u52d8\n>`pd.set_option('display.max_columns',None)`: \u5c55\u958b\u6240\u6709\u6b04\u4f4d","3514ac5d":"## Summary\n\u6211\u5011\u7e3d\u7d50\u4e00\u4e0b\u76ee\u524d\u70ba\u6b62\u7684\u6b65\u9a5f\n> **\u7f3a\u5931\u503c**\n  - \u5728\u4e00\u958b\u59cb\u8cc7\u6599\u63a2\u7d22\uff0c\u6211\u5011\u6aa2\u67e5\u4e86\u6240\u6709\u8cc7\u6599\u7684\u7f3a\u5931\u503c NaN\u3002\n  \n  \n  - \u6aa2\u67e5\u6240\u6709\u6b04\u4f4d\u8a55\u7d1a\uff0c\u5728\u8a55\u50f9\u4e0a\u6709\u512a\u52a3\u95dc\u4fc2\u7684\u6b04\u4f4d\uff0c\u4f7f\u7528LabelEncoder\u8f49\u6210\u6578\u503c\u578b\u614b\u3002\n  - \u91dd\u5c0d\u9023\u7e8c\u578b\u614b\u53ca\u96e2\u6563\u578b\u614b\u7684\u6b04\u4f4d\u756b\u5716\uff0c\u53bb\u9664\u96e2\u7fa4\u503c\u3002\n  \n  - \u70ba\u4e86\u7b26\u5408\u8ff4\u6b78\u57fa\u672c\u7dda\u6027\u95dc\u4fc2\u5047\u8a2d\uff0c\u6211\u5011\u91dd\u5c0d\u504f\u614b\u4fc2\u6578\u9023\u7e8c\u8b8a\u6578\u7684\u6b04\u4f4d\u4ee5\u53caSalePrice\u9032\u884c\u5c0d\u6578\u8f49\u63db\u3002\n  - \u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u4f7f\u7528\u5c0d\u6578\u8f49\u63db\u904e\u7684\u9810\u6e2c\u503cSalePrice\u8a13\u7df4\u5f97\u5230\u6a21\u578b\u4e4b\u5f8c\uff0c\u6700\u5f8c\u5728testing data\u4e0a\u5f97\u5230\u7684\u6700\u7d42\u9810\u6e2c\u503c\u9700\u8981\u4f7f\u7528\u81ea\u7136\u6307\u6578 e \u8f49\u63db\u56de\u53bb","cbf5ffb6":">\u63cf\u8ff0DataFrame\u7684\u6240\u6709\u5217\uff0c\u4e0d\u7ba1\u5b57\u4e32\u578b\u6b04\u4f4d(Categorical)\u6216\u6578\u503c\u578b\u6b04\u4f4d(Numerical)","1e8e1773":">Step2: **n_estimators**\u7e2e\u5c0f\u7bc4\u570d\u3002\n>`cv_params = {'n_estimators': [n_est-50, n_est-25, n_est, n_est+25, n_est+50]}`","9b1fa646":"# 7. \u9023\u7e8c\u578b\u8b8a\u6578\u6b63\u898f\u5316\n- \u5148\u505a**log**\u8655\u7406\u504f\u614b\uff0c\u518d\u505a**min-max**\u6b63\u898f\u5316","9c21e88c":">Step6: **reg_alpha**(L1\u6b63\u5247\u5316\u7684\u61f2\u7f70\u4fc2\u6578\uff0c\u7dad\u5ea6\u6975\u9ad8\u53ef\u4ee5\u63d0\u5347\u904b\u7b97\u901f\u5ea6), **reg_lambda**(L2\u6b63\u5247\u5316\u7684\u61f2\u7f70\u4fc2\u6578\uff0c\u964d\u4f4e\u904e\u64ec\u5408)\n>>`cv_params = {'reg_alpha': [0.05, 0.1, 1, 2, 3], 'reg_lambda': [0.05, 0.1, 1, 2, 3]}`","55d4cb9e":">\u5254\u9664\u96e2\u7fa4\u503c\u5f8c\uff0c\u518d\u6b21\u6bd4\u5c0d\u6563\u4f48\u5716","8b554458":">Step9: \u5b58\u53d6**XGBRegressor**\u6700\u4f73\u5316\u53c3\u6578\n>`other_params = {'learning_rate': learning, 'n_estimators': n_est, 'max_depth': depth, 'min_child_weight': weight, 'seed': seed,\n                'subsample': subs, 'colsample_bytree': bytree, 'gamma': gamma, 'reg_alpha': alpha, 'reg_lambda': lamb,\n                'eval_metric': 'rmse', 'tree_method': 'exact'}`","10770b2f":"# 9. EDA\n- \u6839\u64da\u71b1\u529b\u5716\u5254\u9664\u76f8\u95dc\u4fc2\u6578\u4f4e\u7684\u6b04\u4f4d\n- \u5c07\u76f8\u95dc\u4fc2\u6578\u9ad8\u7684\u5b58\u6210list","c7ace118":">Step7: **learning_rate**\n>`cv_params = {'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]}`","a26ba768":"# 1. \u8f09\u5165\u8cc7\u6599\n>\u4e00\u4f75\u8655\u7406\u7279\u5fb5\u5de5\u7a0b\uff0c\u5c07dataset: **test** \u9644\u52a0\u65bc **train** \u5f8c\u65b9\uff0c\u6210\u70ba\u53e6\u4e00\u500bdataset: **x_train**\u3002","0b7e2a57":">\u4f7f\u7528`np.log1p()`\u4f86\u6b63\u898f\u5316\u9023\u7e8c\u6027\u6578\u503c","69e32289":">\u6a19\u6e96\u5316\u5f8c\u7684**SalePrice**\u79fb\u51fa\u4f86\u6210\u70ba**Y_label**","1da95926":">\u5c07Test dataset\u79fb\u51fa","d5b0c574":"# 8. \u5b57\u4e32\u578b\u6b04\u4f4d\u505a\u6a19\u7c64\u7de8\u78bc(LabelEncoder)","b1d58261":">Step3: **max_depth**(\u63a7\u5236\u904e\u64ec\u5408), **min_child_weight**(\u8abf\u5927\u53c3\u6578\u53ef\u4ee5\u63a7\u5236\u904e\u64ec\u5408)\n>>`cv_params = {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'min_child_weight': [1, 2, 3, 4, 5, 6]}`","635d9a93":"# 4. \u586b\u88dc\u7f3a\u5931\u503c\n- \u6578\u503c\u8f49\u5b57\u4e32\u578b\u614b\n    1. **MSSubClass**\n    2. **YrSold**\n- \u6578\u503c\u578b\u6b04\u4f4d\u88dc**\u5e73\u5747\u6578**    \n- \u95dc\u806f\u6027\u7f3a\u5931\u6b04\u4f4d\n    1. **\u975e\u4ea4\u96c6**\u7684\u7279\u5b9a\u7f3a\u5931\u503c\u512a\u5148\u8655\u7406\n    2. \u4e00\u4f75\u88dc**\u773e\u6578\u6216\u4e2d\u4f4d\u6578**\n- **FireplaceQu**, **Fence**\u7684\u7f3a\u5931\u503c\n    * Nan\u53ef\u80fd\u4ee3\u8868\u5bb6\u88e1\u7121\u6b64\u9805\u76ee\uff0c\u6545\u7528**\"None\"**\u53d6\u4ee3","bd5e2cea":">Step1: **n_estimators**(\u6700\u4f73\u8fed\u4ee3\u6b21\u6578)\u5927\u7bc4\u570d\u3002\n>`cv_params = {'n_estimators': [300, 400, 500, 600, 700]}`","4a36051e":">\u984d\u5916\u4f7f\u7528**StackingCVRegressor**\u7ec4\u5408\u591a\u4e2a\u8ff4\u6b78\u6a21\u578b","adaa5fcb":"# 3. \u8cc7\u6599\u7f3a\u5931\u503c\u89c0\u5bdf\n>\u8a08\u7b97\u6b04\u4f4d\u7f3a\u5931\u503c\u7e3d\u6578","a9b0e706":"# 5. \u504f\u614b\u8655\u7406\u8207\u89c0\u5bdf\n>\u6211\u5011\u5148\u770b\u770b\u6240\u6709\u7279\u5fb5\u4e2d\u504f\u614b\u4fc2\u6578\u7684\u60c5\u5f62\n  - \u504f\u614b\u4fc2\u6578\u6c92\u6709\u4e00\u500b\u7d55\u5c0d\u7bc4\u570d\uff0c\u5927\u65bc*0.5*\u6642\u6211\u5011\u5c31\u53ef\u4ee5\u7a31\u5206\u4f48\u904e\u65bc\u53f3\u504f\uff0c\u53cd\u4e4b\uff0c\u5c0f\u65bc*-0.5*\u5c31\u662f\u5de6\u504f\u3002\n  - \u6211\u5011\u91dd\u5c0d\u504f\u614b\u4fc2\u6578\u5927\u65bc*0.75*\u7684\u6b04\u4f4d\u4ee5\u53caSalePrice\u9032\u884c\u5c0d\u6578\u8f49\u63db\u3002 (\u6216\u662f\u4f7f\u7528Box Cox\u4e5f\u53ef\u4ee5)","57c8a1ff":">\u5c0b\u627e\u7f3a\u5931\u503c\u767e\u5206\u6bd4\u76f8\u8fd1\u7684\uff0c\u4ee3\u8868\u6709\u9ad8\u5ea6\u95dc\u806f\u6027\n1. \u5370\u51fa\u6709\u95dc\u806f\u6027\u7684\u7f3a\u5931\u503c\u4f4d\u7f6e\n2. \u53d6\u4ea4\u96c6\uff0c\u53ef\u4e00\u4f75\u8655\u7406\n3. \u627e\u51fa\u975e\u4ea4\u96c6\u7684\u7279\u5b9a\u4f4d\u7f6e\uff0c\u512a\u5148\u8655\u7406","8706de4e":"# 11. \u53c3\u6578\u6700\u4f73\u5316: **GridSearchCV**\n- \u76f4\u63a5\u4ee5XGBRegressor\u7576\u4f5c\u6700\u7d42\u6a21\u578b\u4f7f\u7528\n    1. estimator: \u9078\u5b9a\u7684\u8a13\u7df4\u6a21\u578b\u3002\n>`model = XGBRegressor(**other_params)`\n    2. param_grid: \u6700\u4f73\u5316\u7684\u53ef\u8abf\u53c3\u6578\u3002\n>`cv_params = {}`\n    3. scoring: \u6e96\u78ba\u5ea6\u7684\u8a55\u50f9\u6a19\u6e96\u3002\n>`scoring='neg_mean_squared_error'`","5511c7c8":">\u77ad\u89e3\u4e00\u4e0bdataset\u4e2d\u6709\u591a\u5c11\u70baNumerical\u53caCategorical\u985e\u578b\u7684\u6b04\u4f4d","e36a05c9":">Numerical\u985e\u578b\u7684\u8cc7\u6599\uff0c\u9084\u53ef\u518d\u5340\u5206\u70ba\u9023\u7e8c\u8207\u96e2\u6563\u5169\u7a2e\u8b8a\u6578\uff0c\u9019\u662f\u7531\u8cc7\u6599\u662f\u5426\u5448\u73fe\u9023\u7e8c\u8b8a\u5316\u4f86\u4f5c\u5224\u65b7\u7684\u3002\n    >- \u96e2\u6563\u8b8a\u6578\uff1a\n        1. \u5176\u6578\u503c\u53ea\u80fd\u7528\u81ea\u7136\u6578\u6216\u6574\u6578\u55ae\u4f4d\u8a08\u7b97\u3002\n        2. \u6216\u7a31\u70ba\u8a08\u91cf\u55ae\u4f4d\u6578\uff0c\u56e0\u70ba\u90fd\u662f\u7531\u8a08\u6578\u65b9\u6cd5\u53d6\u5f97\u3002\n        3. \u4f8b\u5982\uff1a\u4f01\u696d\u500b\u6578\u3001\u8077\u5de5\u4eba\u6578\u3001\u8a2d\u5099\u53f0\u6578\u7b49\u3002\n    >- \u9023\u7e8c\u8b8a\u6578\uff1a        \n        1. \u5728\u4e00\u5b9a\u5340\u9593\u5167\u53ef\u4ee5\u4efb\u610f\u53d6\u503c\u3002\n        2. \u5176\u6578\u503c\u662f\u9023\u7e8c\u4e0d\u65b7\u7684\uff0c\u76f8\u9130\u5169\u500b\u6578\u503c\u53ef\u4f5c\u7121\u9650\u5206\u5272\u3002\n        3. \u4f8b\u5982\uff1a\u751f\u7522\u96f6\u4ef6\u7684\u898f\u683c\u5c3a\u5bf8\u3001\u4eba\u9ad4\u6e2c\u91cf\u7684\u8eab\u9ad8\u3001\u9ad4\u91cd\u3001\u80f8\u570d\u7b49\u3002\n\n>\u4ee5\u6578\u503c\u7a2e\u985e\u7684\u6578\u76ee\u4f5c\u70ba\u8a55\u65b7\u6a19\u6e96\uff0c\u82e5\u5c11\u65bc20\u500b\uff0c\u5247\u70ba\u96e2\u6563\u8b8a\u6578\uff0c\u53cd\u4e4b\u5247\u70ba\u9023\u7e8c\u8b8a\u6578\u3002       ","deeb9555":">\u7e6a\u51fa\u76f8\u95dc\u4fc2\u6578\u9ad8\u7684\u6563\u4f48\u5716\uff0c\u4e26\u5254\u9664\u96e2\u7fa4\u503c","2a956858":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/5407\/media\/housesbanner.png)\n# AIA\u4f5c\u696d\u4e00 : House Prices: Advanced Regression Techniques\n- \u65e5\u671f: 2019\/2\/22\n- \u6280\u5de7:\n    1. \u7f3a\u5931\u503c\u89c0\u5bdf\u53ca\u8655\u7406\n    2. \u504f\u614b\u89c0\u5bdf\u53ca\u8655\u7406\n    3. \u6b63\u898f\u5316\u8655\u7406\u53ca\u6a19\u7c64\u7de8\u78bc\n    4. EDA\n- \u6a21\u578b:\n    1. [XGBRegressor](https:\/\/xgboost.readthedocs.io\/en\/latest\/)\n    2. [StackingCVRegressor](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/regressor\/StackingCVRegressor\/#stackingcvregressor)\n- \u53c3\u6578\u6700\u4f73\u5316: [GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html)\n- \u53c3\u8003\u7bc4\u4f8b:\n    - [Kaggle \u2013 House Price](https:\/\/chtseng.wordpress.com\/2017\/12\/26\/kaggle-house-price\/), \u4f5c\u8005: **CH.Tseng**\n    - [XGboost\u6570\u636e\u6bd4\u8d5b\u5b9e\u6218\u4e4b\u8c03\u53c2\u7bc7(\u5b8c\u6574\u6d41\u7a0b)](https:\/\/segmentfault.com\/a\/1190000014040317), \u4f5c\u8005: **\u6709\u6545\u4e8b**","6fd5059e":"# 12. \u9078\u5b9a\u6a21\u578b\u53ca\u9810\u6e2c","3f6a3f9e":">Step8: **seed**(\u96a8\u6a5f\u7522\u751f\u91cd\u8907\u7d50\u679c)\n>`cv_params = {'seed': [0, 25, 50, 75, 100, 125, 150]}`","3b381ef7":">Step4: **gamma**(Loss Function > gamma\uff0c\u9032\u884c\u7bc0\u9ede\u5283\u5206)\n>>`cv_params = {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]}`","44ecf1fb":">\u8a08\u7b97\u7f3a\u5931\u503c\u767e\u5206\u6bd4: $\\frac{\u7f3a\u5931\u503c\u7b46\u6578}{\u8cc7\u6599\u7e3d\u7b46\u6578}\\times 100\\%$","ee3d5952":"# \u8f09\u5165\u5957\u4ef6","82bb9a86":">Step5: **subsample**(\u96a8\u6a5f\u62bd\u53d6\u7684\u6a23\u672c\u6578\u5360\u7e3d\u6a23\u672c\u7684\u6bd4\u4f8b\uff0c\u9632\u6b62\u904e\u64ec\u5408), **colsample_bytree**(\u5c0d\u7279\u5fb5\u96a8\u6a5f\u63a1\u6a23\u7684\u6bd4\u4f8b)\n>>`cv_params = {'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]}`","0bea7d1c":"# 10. \u6a21\u578b\u8a13\u7df4\n- \u532f\u5165\u591a\u7a2e\u8ff4\u6b78\u6a21\u578b\u52a0\u4ee5\u6bd4\u5c0d","58840fb7":">\u8a13\u7df4\u591a\u500b\u6a21\u578b"}}