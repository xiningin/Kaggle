{"cell_type":{"763a8e1c":"code","5822ff64":"code","c1512882":"code","bbbf27ec":"code","173822d9":"code","f49a6adb":"code","196b8c5c":"code","c9542f4e":"code","a0a14cef":"code","7dc2b0ed":"code","46337657":"code","1253a6ca":"code","48ab9c3c":"code","04e49b7b":"code","597bebed":"code","e60464db":"code","6db45e50":"code","069b90e8":"code","9406cc5c":"code","48c078c0":"code","1d626a19":"code","4a7bbc7c":"code","eaad91c6":"code","faf5ae31":"code","4a9f715b":"code","a29f925a":"code","fa103d9d":"code","07434bd9":"code","8ccedc46":"code","cac72360":"code","32642281":"code","c899bc40":"code","8594ca2d":"code","6a0693fe":"code","13adf9a6":"code","7e66c9e9":"code","76357075":"code","33f51eea":"markdown","a1e5e278":"markdown","6280f5b8":"markdown","0b42514a":"markdown","2aea509c":"markdown","3bbb116f":"markdown","437be69a":"markdown"},"source":{"763a8e1c":"#IMPORTING REQUIRED LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom lightgbm.sklearn import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport gc\ngc.enable()\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n","5822ff64":"#DATASET VIEW\npath1=\"..\/input\/\"\ndata_files=list(os.listdir(path1))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path1+x).st_size\/(1024*1024),2))\ndf_files","c1512882":"#All functions\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))\n\n#FUNCTION FOR READING DICTIONARY ITEMS AND HANDLING KEYERROR\ndef get_val(x,col):\n    try:\n        y=x[col]\n    except:\n        y=np.nan\n    return(y)\n\n#FUNCTION FOR CALCULATING RSME\ndef rsme(y,pred):\n    return(mean_squared_error(y,pred)**0.5)","bbbf27ec":"%%time\n#READING TRAINING AND TEST DATASET\nprint('reading train dataset...')\ndf_train=pd.read_csv(path1+'train.csv',dtype={'fullVisitorId':str,'date':str,'sessionId':str,'visitId':str,'visitStartTime':str})\nprint('reading test dataset...')\ndf_test=pd.read_csv(path1+'test.csv',dtype={'fullVisitorId':str,'date':str,'sessionId':str,'visitId':str,'visitStartTime':str})\nprint('data reading complete')","173822d9":"#CHECKING TOP FIVE TRAIN OBSERVATIONS OR ROWS\ndf_train.head()","f49a6adb":"#FEATURE SUMMARY FOR TRAIN DATASET\nfeature_summary(df_train)","196b8c5c":"#CHECKING TOP 5 TEST OBSERVATIONS OR ROWS\ndf_test.head()","c9542f4e":"#FEATURE SUMMARY FOR TEST DATASET\nfeature_summary(df_test)","a0a14cef":"#COMBINING TRAIN AND TEST DATASET\ndf_combi=pd.concat([df_train,df_test],ignore_index=True)","7dc2b0ed":"#STORING NUMBER OF ROWS IN TRAIN DATASET\n#AND DELETING BOTH TRAIN & TEST DATAFRAMES\n#NUMBER OF ROWS IN TRAIN DATASET WILL HELP IN SPLITING COMBINED DATASET INTO TRAIN & TEST \ntrain_len=len(df_train)\ndel df_train,df_test\ngc.collect()","46337657":"#FEATURE SUMMARY FOR COMBINED DATASET\ndf_combi_fs=feature_summary(df_combi)\ndf_combi_fs","1253a6ca":"%%time\n#REPLACING false WITH False AND true WITH True\n#AS false AND true HAVE NO MEANING IN PYTHON\n#ALSO REPLACING 'not available in demo dataset' WITH 'NaN'\nj_fields=['device','geoNetwork','totals','trafficSource']\n\nfor col in j_fields:\n    df_combi[col].replace('false','False',inplace=True,regex=True)\n    df_combi[col].replace('true','True',inplace=True,regex=True)\n    df_combi[col].replace('not available in demo dataset','NaN',inplace=True,regex=True)\n    df_combi[col].replace('(not set)','NaN',inplace=True,regex=True)\n    df_combi[col]=df_combi[col].apply(lambda x: eval(x))","48ab9c3c":"%%time\n#EXTRACTING FEATURE NAMES UNDER EACH JSON FEATURES\ndevice_cols=list(df_combi['device'][0].keys())\ngeoNetwork_cols=list(df_combi['geoNetwork'][0].keys())\ntotals_cols=list(df_combi['totals'][0].keys())\ntrafficSource_cols=list(df_combi['trafficSource'][0].keys())\n\nfor i in range(1,len(df_combi)):\n    device_cols=list(set(device_cols) | set(list(df_combi['device'][i].keys())))\n    geoNetwork_cols=list(set(geoNetwork_cols) | set(list(df_combi['geoNetwork'][i].keys())))\n    totals_cols=list(set(totals_cols) | set(list(df_combi['totals'][i].keys())))\n    trafficSource_cols=list(set(trafficSource_cols) | set(list(df_combi['trafficSource'][i].keys())))","04e49b7b":"device_cols","597bebed":"geoNetwork_cols","e60464db":"totals_cols","6db45e50":"trafficSource_cols","069b90e8":"%%time\n#CONVERTING DEVICE JSON FEATURE INTO INDIVIDUAL SUB FEATURES UNDER IT\nfor jlist in device_cols:\n    col_name='device_'+jlist\n    df_combi[col_name]=df_combi['device'].apply(lambda x: get_val(x,jlist))\n\n#DROPPING device JSON FEATURE\ndf_combi.drop('device',axis=1,inplace=True)\ndisplay(df_combi.head())    ","9406cc5c":"%%time\n#CONVERTING geoNetwork JSON FEATURE INTO INDIVIDUAL SUB FEATURES UNDER IT\nfor jlist in geoNetwork_cols:\n    col_name='geoNetwork_'+jlist\n    df_combi[col_name]=df_combi['geoNetwork'].apply(lambda x: get_val(x,jlist))\n    \n#DROPPING geoNetwork JSON FEATURE\ndf_combi.drop('geoNetwork',axis=1,inplace=True)\ndisplay(df_combi.head())","48c078c0":"%%time\n#CONVERTING trafficSource JSON FEATURE INTO INDIVIDUAL SUB FEATURES UNDER IT\nfor jlist in trafficSource_cols:\n    col_name='trafficSource_'+jlist\n    df_combi[col_name]=df_combi['trafficSource'].apply(lambda x: get_val(x,jlist)) \n\n\n#DROPPING trafficSource JSON FEATURE\ndf_combi.drop('trafficSource',axis=1,inplace=True)\ndisplay(df_combi.head())","1d626a19":"%%time\n#CONVERTING totals JSON FEATURE INTO INDIVIDUAL SUB FEATURES UNDER IT\nfor jlist in totals_cols:\n    col_name='totals_'+jlist\n    df_combi[col_name]=df_combi['totals'].apply(lambda x: get_val(x,jlist)) \n    \n#DROPPING totals JSON FEATURE\ndf_combi.drop('totals',axis=1,inplace=True)\ndisplay(df_combi.head())","4a7bbc7c":"#DELETING COMBINED FEATURE SUMMARY DATAFRAME\ndel df_combi_fs\ngc.collect()","eaad91c6":"#CONVERTING ALL STRING 'NaN' VALUES TO np.nan\ndf_combi.replace('NaN',np.nan,inplace=True)\n\n#CONVERTING VALUES IN FEATURE trafficSource_adwordsClickInfo AS THEY ARE AGAIN Json FEATURES\n#WE HAVE TO HANDLE trafficSource_adwordsClickInfo AS OTHER Json FEATURES\ndf_combi['trafficSource_adwordsClickInfo']=df_combi.trafficSource_adwordsClickInfo.apply(lambda x: str(x))","faf5ae31":"#FEATURE SUMMARY FOR COMBINED DATASET\ndf_combi_fs=feature_summary(df_combi)\ndf_combi_fs","4a9f715b":"#IDENFIYING ALL FEATURES WITH SAME VALUES IN ALL OBSERVATIONS\ncol_drop=list(df_combi_fs.index[df_combi_fs.Unique_Count==1])\nprint('No of Columns to be removed:',len(col_drop))\nprint(col_drop)\n\n#DROPPING ALL FEATURES WITH SAME VALUES IN ALL OBSERVATIONS\ndf_combi.drop(col_drop,axis=1,inplace=True)\ngc.collect()","a29f925a":"#FEATURE SUMMARY FOR COMBINED DATASET\ndf_combi_fs=feature_summary(df_combi)\ndf_combi_fs","fa103d9d":"#DROPPING trafficSource_campaignCode, AS IT HAS ONLY 2 OBSERVATIONS WITH SOME VALUES\ndf_combi.drop('trafficSource_campaignCode',axis=1,inplace=True)\n\n#GARBAGE COLLECTION\ngc.collect()","07434bd9":"%%time\n#EXTRACTING FEATURES NAMES FROM Json FEATURE trafficSource_adwordsClickInfo\ndf_combi['trafficSource_adwordsClickInfo']=df_combi.trafficSource_adwordsClickInfo.apply(lambda x: eval(x))\ntsadclick_cols=list(df_combi['trafficSource_adwordsClickInfo'][0].keys())\n\nfor i in range(1,len(df_combi)):\n    tsadclick_cols=list(set(tsadclick_cols) | set(list(df_combi['trafficSource_adwordsClickInfo'][i].keys())))\n\nprint('FEATURES UNDER trafficSource_adwordsClickInfo Json FEATURE\\n',tsadclick_cols)\n\n#EXTRACTING FEATURES FROM Json FEATURE trafficSource_adwordsClickInfo\nfor jlist in tsadclick_cols:\n    col_name='tsadclick_'+jlist\n    df_combi[col_name]=df_combi['trafficSource_adwordsClickInfo'].apply(lambda x: get_val(x,jlist))\n    df_combi[col_name]=df_combi[col_name].apply(lambda x: str(x))\n    \n#DROPPING Json FEATURE trafficSource_adwordsClickInfo\ndf_combi.drop('trafficSource_adwordsClickInfo',axis=1,inplace=True)","8ccedc46":"#DROPPING IRRELEVANT FEATURES tsadclick_targetingCriteria AND tsadclick_criteriaParameters\ndf_combi.drop(['tsadclick_targetingCriteria','tsadclick_criteriaParameters'],axis=1,inplace=True)\n\n#GARBAGE COLLECTION\ngc.collect()","cac72360":"# %%time\n# #HANDLING SURROGATES IN TRAIN DATASET\n# #THERE ARE NO SUCH ENTRIES IN TEST SET\n# #SURROGATES: VALUES CAN'T BE ENCODED\/DECODED USING utf-8\n# for col in df_combi.columns:\n#     if ((df_combi[col].dtype==object) & (col!='fullVisitorId')):\n#         df_combi[col]=df_combi[col].apply(lambda x: np.nan if x==np.nan else str(x).encode('utf-8', 'replace').decode('utf-8'))","32642281":"%%time\n#REPLACING 'nan' and '(not provided)' WITH np.nan\ndf_combi.replace(\"nan\",np.nan,inplace=True)\ndf_combi.replace(\"(not provided)\",np.nan,inplace=True)\ndf_combi.replace(\"(NaN)\",np.nan,inplace=True)\ndf_combi['totals_transactionRevenue'].replace(np.nan,0,inplace=True)\n\n#CONVERTING FEATURES TO CORRECT DATATYPE\ndf_combi['totals_pageviews']=df_combi['totals_pageviews'].astype('float')\ndf_combi['totals_transactionRevenue']=df_combi['totals_transactionRevenue'].astype('float')\ndf_combi['totals_hits']=df_combi['totals_hits'].astype('float')\ndf_combi['tsadclick_page']=df_combi['tsadclick_page'].astype('float')","c899bc40":"#FEATURE SUMMARY FOR COMBINED DATASET\ndf_combi_fs=feature_summary(df_combi)\ndf_combi_fs","8594ca2d":"#SPLITING COMBINED DATASET BACK TO TRAIN AND TEST SETS\ntrain=df_combi[:train_len]\ntest=df_combi[train_len:]","6a0693fe":"#FEATURE SUMMARY TRAIN SET\nfeature_summary(train)","13adf9a6":"#FEATURE SUMMARY TEST SET\nfeature_summary(test)","7e66c9e9":"for col in train.columns:\n    if ((train[col].dtype==object) & (col!='fullVisitorId')):\n        train[col]=train[col].apply(lambda x: np.nan if x==np.nan else str(x).encode('utf-8', 'replace').decode('utf-8'))","76357075":"#WRITING BACK PREPARED TRAIN AND TEST DATASET\ntrain.to_csv('prepared_train.gz', compression='gzip',index=False)\ntest.to_csv('prepared_test.gz', compression='gzip',index=False)","33f51eea":"<font color=\"blue\"><I>Please upvote if you find notebook useful<\/I><\/font><br><br><br>\n\n<h2>Problem Statement<\/h2>\nIn this competition, you\u2019re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to <b>predict revenue per customer.<\/b> \n\n<br><br>\nSubmissions are scored on the <b>root mean squared error<\/b>. RMSE or RMSD is defined as:\n\n![RSME or RSMD](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/eeb88fa0f90448e9d1a67cd7a70164f674aeb300)\n\n<br><br>\n Final submission deadline: <b>November 15, 2018<\/b>\n<h2>GStore Data Preparation<\/h2>\n<ol>\n    <li>Data Preparation steps\n        <ul>\n            <li>Data Correction\n            <li>Extracting Json Features\n            <li>Dropping irrelevant features\n            <li>Exporting Prepared data to csv files\n         <\/ul>\n     <li>For detailed EDA and Baseline model, check notebook [GStore EDA](https:\/\/www.kaggle.com\/rahullalu\/gstore-eda-lgbm-baseline-1-4281)\n      <li> Prepared public [Dataset](https:\/\/www.kaggle.com\/rahullalu\/gstore-prepared-dataset) can directly be consumed in a kernel\n<\/ol>\n","a1e5e278":"<h2>Handling Json Features<\/h2>\n<ol>\n<li>Json features <b>device, geoNetwork,totals and trafficSource<\/b>\n    <li>Will be using <b>eval()<\/b> function to convert string to Dictionary\n<li>Extracting underlying fields under each Json field\n<li>Converting each Json field into its underlying fields\n<\/ol>\n","6280f5b8":"Features under <b>trafficSource<\/b> Json feature","0b42514a":"Features under <b>totals<\/b> Json feature","2aea509c":"Features under <b>geoNetwork<\/b> Json feature","3bbb116f":"<h2>Dropping irrelevant features<\/h2>\nDropping all the features having same value in all observations","437be69a":"Features under <b>device<\/b> Json feature"}}