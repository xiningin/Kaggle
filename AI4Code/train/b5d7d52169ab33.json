{"cell_type":{"3289ab0a":"code","bc6cea55":"code","0096356b":"code","8b594117":"code","89fa2a51":"code","f98d64ee":"code","f62191f4":"code","d9f9e244":"code","303d8b87":"code","842e0a78":"code","34da6160":"code","49e8dfd1":"code","cd87a448":"code","99f16127":"code","d6591799":"code","99434519":"markdown","2d7eac17":"markdown","063fa1ac":"markdown","c7afbf29":"markdown","94b849c8":"markdown","b20db15c":"markdown","846be1bb":"markdown","a6a02303":"markdown","d4fcd0ee":"markdown","40e05738":"markdown","41ae12b8":"markdown","0bbb0e64":"markdown","eeb79525":"markdown","362f66de":"markdown","ed11fb15":"markdown","72c13c95":"markdown","61a37fe1":"markdown","237398db":"markdown","58d720c7":"markdown","c476add7":"markdown","4fcfc12e":"markdown","9e1d50c9":"markdown","61117d5e":"markdown","f26bd465":"markdown"},"source":{"3289ab0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# visualization libraries\nimport seaborn as sns\nsns.set(style='darkgrid')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Machine learning Classification Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb\n\n# Machine Learning performance metrics \nfrom sklearn.metrics import classification_report \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bc6cea55":"# Importing the train data\ntrain = pd.read_csv('..\/input\/train.csv')\n\n# Importing the test data\ntest = pd.read_csv('..\/input\/test.csv')\n\n# save PassengerId for final submission\npassengerId = test['PassengerId']\n\n# merge the train and test data\ndf = train.append(test, ignore_index=True)\n\n# create indexes to separate data later on\ntrain_idx = len(train)\ntest_idx = len(df) - len(test)","0096356b":"print('First 5 samples of the full Data')\ndf.head()","8b594117":"print('Full Data stats: ')\nprint('Number of records: {}\\nNumber of features: {}'.format(df.shape[0],df.shape[1] ))\nprint('Are there missing values: {}, How many: {}'.format(df.isnull().any().any(),df.isnull().sum().sum()))\nprint('\\n')\nprint(('*')*40)\nprint('\\n')\nprint('Full Data info:')\nprint(df.info())","89fa2a51":"print('Ratio of Passengers onboard the Titanic:')\nprint(df.Sex.value_counts())\nprint('\\n')\nprint(('*')*40)\nprint('\\n')\nprint('Number of Passengers onboard the Titanic that survived:')\nprint(len(df[df.Survived == 1]))\nprint('\\n')\nprint(('*')*40)\nprint('\\n')\nprint('Ratio of the sex of passengers onboard the Titanic that Survived:' )\nprint(df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().round(2))\nplt.figure(figsize=(10,6))\ng= sns.countplot(data = df, x = 'Survived', hue= 'Sex')\ng.set_xticklabels([\"No\", \"Yes\"]);\nplt.ylabel('No of Passengers');","f98d64ee":"g = sns.catplot(x=\"Pclass\", hue=\"Sex\", col=\"Survived\", \n                data=df, kind=\"count\",height=6, aspect=.7);\ng.set_ylabels('No. of Passengers');\nprint('Percentage of Passengers survival by class: ')\nprint('\\n')\nprint(pd.crosstab(index=[df.Pclass, df.Sex], \n            columns = df.Survived, normalize = True).round(3))","f62191f4":"g = sns.FacetGrid(df, col='Survived', height=5, aspect=.6)\ng = g.map(plt.hist, 'Age', bins=10, color = 'm')\nprint('Average Age of the Passengers on board the Titanic by passenger class:')\nprint('\\n')\nprint(pd.crosstab(index= df['Pclass'], \n            columns = df['Sex'],\n            values = df['Age'], \n            aggfunc=np.mean).round())","d9f9e244":"print('Survival percentage of Passengers based off where they embarked')\nprint('\\n')\nprint(pd.crosstab(index = df.Embarked, \n            columns = df.Survived, \n            margins = True, margins_name = 'Total', normalize = 'index').round(2))","303d8b87":"missing = pd.DataFrame(df.isnull().sum()).rename(columns = {0:'missing'})\nmissing","842e0a78":"# For the Age column, we use the average age per persenger class \nfirst_class = round(df[df['Pclass'] == 1]['Age'].mean())\nsecond_class = round(df[df['Pclass'] == 2]['Age'].mean())\nthird_class = round(df[df['Pclass'] == 3]['Age'].mean())\n\n# to vreate a function \ndef impute_age(col):\n    '''\n    Creating a function that replaces the missing \n    age values in each class by the average age\n    value of the class\n    \n    '''\n    Age = col[0]\n    Pclass = col[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return first_class\n        elif Pclass == 2:\n            return second_class\n        else:\n            return third_class\n    else:\n        return Age\n    \n# and impute the average age with the function created to fill the missing values\ndf['Age'] = df[['Age', 'Pclass']].apply(impute_age, axis = 1)\n\n# For the  Cabin column, we simply drop the entire column because of the large number of missing values\ndf.drop('Cabin', axis= 1, inplace= True)\n\n# for the Embarked feature, we find most frequent Embarked value\nmost_embarked = df.Embarked.value_counts().index[0]\n\n# and fill the missing values with most_embarked value\ndf.Embarked = df.Embarked.fillna(most_embarked)\n\n# for the fare column, we fill the missing value with median fare\ndf.Fare = df.Fare.fillna(df.Fare.median())\n\n","34da6160":"# Visualizing if any missing values still persists besides the survived column\nsns.heatmap(df.isnull(), cbar= False, yticklabels= False);","49e8dfd1":"# Convert the male and female categories to integers\ndf.Sex = df.Sex.map({\"male\": 0, \"female\":1})\n\n# Create dummy variables for  the categorical features\npclass_dummies = pd.get_dummies(df.Pclass, prefix=\"Pclass\")\nembarked_dummies = pd.get_dummies(df.Embarked, prefix=\"Embarked\")\n\n# concatenate dummy columns with the data\ndf_dummies = pd.concat([df, pclass_dummies, embarked_dummies], axis=1)\n\n# drop categorical features\ndf_dummies.drop(['Pclass', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n\nprint('After encoding our data:')\ndf_dummies.head()","cd87a448":"# create train and test data\ntrain = df_dummies[ :train_idx]\ntest = df_dummies[test_idx: ]\n\n# convert Survived back to int\ntrain.Survived = train.Survived.astype(int)\n\n# create X and y for data and target values \nX = train.drop('Survived', axis=1).values \ny = train.Survived.values\n\n# create array for test set\nX_test = test.drop('Survived', axis=1).values","99f16127":"# create param grid object \nrf_params = dict(     \n    max_depth = [n for n in range(9, 14)],     \n    min_samples_split = [n for n in range(4, 11)], \n    min_samples_leaf = [n for n in range(2, 5)],     \n    n_estimators = [n for n in range(10, 60, 10)],\n)\n\n# instantiate a Random Forest classifier\nclf = RandomForestClassifier()\n\n# fit the model \nclf_cv = GridSearchCV(estimator=clf, param_grid=rf_params, cv=5, iid= False) \nclf_cv.fit(X, y)\n\nprint(\"Best score: {}\".format(clf_cv.best_score_))","d6591799":"predictions = clf_cv.predict(X_test)\nsubmission = pd.DataFrame({\"PassengerId\": passengerId, \"Survived\": predictions})\nsubmission.to_csv('gender_submission.csv', index=False)","99434519":"### *Cleaning the  Missing Train Data*","2d7eac17":"## **3. Exploratory Data Analysis**","063fa1ac":"#### ***Insights***:\n* 263 records of the Age feature is missing. \n* The Cabin feature is missing 1014 records\n* Survived feature is missing 418 records\n* The Embarked and fare features are small enough to be negligible.\n\n#### ***Conclusion***:\n* The  Age data  missing is small enough for reasonable replacement with some form of imputation\n* We would use the mean age\/class to impute this missing data\n* The Cabin feature is missing too many records. It will be dropped\n* The missing data in the Embarked and fare feature will be dropped\n* Since the survived feature is out target value, we will analyze this during the model selection stage\n","c7afbf29":"### *Sex vs Survived*","94b849c8":"### *Age vs Survived*","b20db15c":"## **2. Descriptive Statistics**","846be1bb":"### *Feature Selection*","a6a02303":"Great! We can now go on to feature engineering","d4fcd0ee":"#### ***Insights***:\n* Passengers who paid higher ticket fares(Embarking at gate C) had a better survival rate, 55%\n* Q and S had the highest mortality rate, 61% & 66%\n   \n#### ***Conclusion***:\n* There's a correlation between the Embarked feature and the Target, Survived ","40e05738":"### *Hyperparameters*","41ae12b8":"## **5. Modeling Using Random Forrests**","0bbb0e64":"### *Checking if there are still  Missing Train Data*","eeb79525":"#### ***Insights***:\n* Most of the passengers onboard were between 15 - 35\n* Adults were in the 1st class while young people occupied the 3rd class\n* A large number of young people  (15-25) didnt survive\n* A lot of Infants survived (again, emphasis were put on women and children)\n* Older passengers (80 years and above) survived\n   \n#### ***Conclusion***:\n* There's a correlation between the Age feature and the Target, Survived ","362f66de":"#### ***Insights***:\n* Of the 1309 passengers onboard the titanic. 843 were men while 466 were women\n* 342 of these passengeres survived with 74% of them being women while 19%  men\n* This may be because an importance was put on rescuing women (and chiledren) first\n   \n#### ***Conclusion***:\n* There's a correlation between the Sex feature and the Target column, Survived ","ed11fb15":"> ### *Missing Data*\n* From the descriptive statistics carried out, we know that the data contains missing values\n* This can be dealth with by either dropping the features containing the missing values or for numerical features, imputing an average value for the missing values or for categorical features using the most frequent value\n* Lets investigate more","72c13c95":"\nFrom the EDA carried out, the features we would be focusing on are:\n* **Age**\n* **Pclass**\n* **Embarked**\n* **Sex**\n* **Fare**\n* **Parch**\n* **SibSp**\n\nAnd our target variable will be the **Survived** feature","61a37fe1":"#### ***Insights***:\n* Passengers, women mostly in 1st class survived more than the other passenger classes\n* Passengers, men especially, in 3rd class recorded the most deaths\n* This could be also related to fare price as the most expensive class had the best chance of surviving\n   \n#### ***Conclusion***:\n* There's a correlation between the Pclass feature and the Target, Survived ","237398db":"From the descriptive statistics, we see that there are 1309 entries and 12 columns(features). Also, we notice that the Age, Cabin, Embarked, Fare, and Survived  columns have less than the total entries.\nThis dataset will need to be cleaned! ","58d720c7":"## **4. Feature Engineering**","c476add7":"## **6. Submission**","4fcfc12e":"### *Embarked vs Survived*","9e1d50c9":"### *Pclass vs Survived*","61117d5e":"## **1. The Data**","f26bd465":"### *Model Selection*"}}