{"cell_type":{"8d73c882":"code","68066b03":"code","4fa47225":"code","67d93dc5":"code","230c4267":"code","1d7b7e8d":"code","ef31a263":"code","ed382ac2":"code","b091124d":"code","cb2e6c30":"code","0f3a31a5":"code","4fdac155":"code","1662dbf2":"code","d65ebf97":"code","08a923de":"code","aae4ea16":"code","6da67f69":"code","8794255a":"code","9a8f4a0f":"code","5effa19c":"code","b1968916":"code","02f203a7":"code","9a498c90":"code","8e349de8":"code","83a7f0b0":"code","d4fd5cbd":"markdown","3d4ffab1":"markdown","672cd19a":"markdown","e71b52bc":"markdown","0057122c":"markdown","63b529de":"markdown","9e0823f8":"markdown","53cb71a5":"markdown","013346c4":"markdown","17332078":"markdown","bd4fe41f":"markdown","da57a557":"markdown","00f529a0":"markdown","91dc3c13":"markdown","2031d110":"markdown","088d24eb":"markdown","a947bc94":"markdown","b4bd9fc4":"markdown","a3be03c9":"markdown","63548d8d":"markdown","c9943655":"markdown","3bbf6377":"markdown","12be8652":"markdown","4d05b711":"markdown"},"source":{"8d73c882":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nfrom scipy.stats import norm\n\nimport keras\nfrom keras import backend as k\nk.clear_session()","68066b03":"# set parameter\nimage_shape = (28,28,1)\nbatch_size = 64\nlatent_dim = 10\nepoch = 30","4fa47225":"# import minist dataset\n(x_train, y_train), (x_test,y_test) = keras.datasets.mnist.load_data()","67d93dc5":"# change datatype and reshape data\nx_train = x_train.astype('float32') \/ 255.\nx_train = x_train.reshape((x_train.shape[0],) + image_shape)\nx_test = x_test.astype('float32') \/ 255.\nx_test = x_test.reshape((x_test.shape[0],) + image_shape)","230c4267":"# function to fatch 10 images of labeld 0 to 9\ndef get_images_1_to_10(x_train,y_train):\n    selected_x,selected_y = [],[]\n    for i in range(10):\n        number_index = np.where(y_train == i)[0]\n        random_index = np.random.choice(len(number_index),1,replace=False)\n        select_index = number_index[random_index]\n        selected_x.append(x_train[select_index[0]])\n        selected_y.append(y_train[select_index][0])\n    return np.array(selected_x,dtype=\"float32\").reshape((len(selected_x),)+image_shape),np.array(selected_y,dtype=\"float32\")","1d7b7e8d":"# select random 10 image of labeled 0 to 9\nselected_x,selected_y =  get_images_1_to_10(x_train,y_train)","ef31a263":"# function for plot images\ndef plot_image(selected_x,selected_y,title=None,save=None):\n    ncols = selected_x.shape[0]\n    fig,ax  = plt.subplots(nrows=1, ncols=ncols,figsize=(20,3))\n    for x,y,ax_i in zip(selected_x,selected_y,ax):\n        ax_i.imshow(x.reshape((28,28)))\n        ax_i.axis(\"off\")\n        ax_i.set_title(int(y))\n    if title:\n        fig.suptitle(title)\n    if save:\n        fig.savefig(str(save)+\".png\")\n    plt.show()","ed382ac2":"# plot selected images\nplot_image(selected_x,selected_y,title=\"original images\",save=\"original_images\")","b091124d":"# Input layer\n# input shape = (None,28,28,1)\nencoder_input = keras.Input(shape=image_shape)\n\n# convolutional layer 1\n# input shape = (None,28,28,1)\n# output shape = (None,28,28,32)\nconv_1 = keras.layers.Conv2D(filters=32,\n                             kernel_size=3,\n                             padding=\"same\",\n                             activation=\"relu\",\n                            )(encoder_input)\n\n# convolutional layer 2\n# input shape = (None,28,28,32)\n# output shape = (None,28,28,64)\nconv_2 = keras.layers.Conv2D(filters=64,\n                             kernel_size=3,\n                             padding=\"same\",\n                             activation=\"relu\",\n                            )(conv_1)\n\n# convolutional layer 3\n# input shape = (None,28,28,64)\n# output shape = (None,28,28,64)\nconv_3 = keras.layers.Conv2D(filters=64,\n                             kernel_size=3,\n                             padding=\"same\",\n                             activation=\"relu\",\n                            )(conv_2)\n\n# Flatten layer\n# input shape = (None,28,28,64)\n# output shape = (None,50176)\nflatten = keras.layers.Flatten()(conv_3)\n\n# Dense layer 1\n# input shape = (None,50176)\n# output shape = (None,128)\nencoder_output = keras.layers.Dense(128,activation=\"relu\")(flatten)","cb2e6c30":"# latent mean and (log)variance\n\n# Dense layer 2\n# input shape = (None,128)\n# output shape = (None,latent_dim)\nz_mu = keras.layers.Dense(latent_dim)(encoder_output)\n\n# Dense layer 3\n# input shape = (None,128)\n# output shape = (None,latent_dim)\nz_log_sigma = keras.layers.Dense(latent_dim)(encoder_output)","0f3a31a5":"# sampling function for latent layer\ndef sampling(args):\n    z_mu, z_log_sigma = args\n\n    # epsilon is simple normal distribution\n    epsilon = k.random_normal(shape=(k.shape(z_mu)[0], latent_dim),mean=0., stddev=1.)\n    return z_mu + k.exp(z_log_sigma) * epsilon\n\nz = keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mu, z_log_sigma])","4fdac155":"# Dense layer 4\n# input shape = (None,latent_dim)\n# output shape = (None,128)\ndense_2 = keras.layers.Dense(128,activation=\"relu\")\n\n# Dense layer 4\n# input shape = (None,128)\n# output shape = (None,50176)\ndense_3 = keras.layers.Dense(np.prod(k.int_shape(conv_3)[1:]),\n                             activation=\"relu\"\n                            )\n\n# Reshape layer \n# input shape = (None,128)\n# output shape = (None,28,28,64)\nreshape = keras.layers.Reshape(k.int_shape(conv_3)[1:])\n\n# Deconvolutional layer 1\n# input shape = (None,28,28,64)\n# output shape = (None,28,28,64)\nconv_4 = keras.layers.Conv2DTranspose(filters=64,\n                                      kernel_size=3,\n                                      padding=\"same\",\n                                      activation=\"relu\"\n                                     )\n# Deconvolutional layer 2\n# input shape = (None,28,28,64)\n# output shape = (None,28,28,64)\nconv_5 = keras.layers.Conv2DTranspose(filters=64,\n                                      kernel_size=3,\n                                      padding=\"same\",\n                                      activation=\"relu\"\n                                     )\n\n# Deconvolutional layer 3\n# input shape = (None,28,28,64)\n# output shape = (None,28,28,32)\nconv_6 = keras.layers.Conv2DTranspose(filters=32,\n                                      kernel_size=3,\n                                      padding=\"same\",\n                                      activation=\"relu\"\n                                     )\n\n# convolutional layer 4\n# input shape = (None,28,28,32)\n# output shape = (None,28,28,1)\ndecoder_output = keras.layers.Conv2D(filters=1,\n                                     kernel_size=3,\n                                     padding=\"same\",\n                                     activation=\"sigmoid\"\n                                    )\n\n_dense_2 = dense_2(z)\n_dense_3 = dense_3(_dense_2)\n_reshape = reshape(_dense_3)\n_conv_4 = conv_4(_reshape)\n_conv_5 = conv_5(_conv_4)\n_conv_6 = conv_6(_conv_5)\n_decoder_output = decoder_output(_conv_6)","1662dbf2":"def vae_loss(x, z_decoded):\n        x = k.flatten(x)\n        z_decoded = k.flatten(z_decoded)\n        # Reconstruction loss\n        Reconstruction_loss = 786*keras.metrics.binary_crossentropy(x, z_decoded)\n        # KL divergence\n        kl_loss = -0.5 * k.mean(1 + z_log_sigma - k.square(z_mu) - k.exp(z_log_sigma), axis=-1)\n        return Reconstruction_loss + kl_loss","d65ebf97":"variational_encoder = keras.Model(encoder_input,_decoder_output)\nvariational_encoder.compile(optimizer='rmsprop',loss=vae_loss)\nvariational_encoder.summary()","08a923de":"keras.utils.plot_model(variational_encoder,to_file=\"variational_encoder_L{}_E_{}.png\".format(latent_dim,epoch),show_shapes=True)","aae4ea16":"variational_encoder.fit(x=x_train,y=x_train,\n                        shuffle=True,\n                        epochs=epoch,\n                        batch_size=batch_size,\n                        validation_data=(x_test,x_test))","6da67f69":"# Model weights save\nvariational_encoder.save_weights('vae_L2_E10.h5')","8794255a":"pred = variational_encoder.predict(selected_x)","9a8f4a0f":"plot_image(selected_x,selected_y)\nplot_image(pred,selected_y,title=\"prediction_from_original_images\",save=\"prediction_from_original_images\")","5effa19c":"encoder = keras.Model(encoder_input,z_mu)\nx_test_encoded = encoder.predict(x_test, batch_size=batch_size)\nplt.figure(figsize=(6, 6))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\nplt.colorbar()\nplt.title(\"Encoded_dimension_visualization_L{}_E{}\".format(latent_dim,epoch))\nplt.savefig(\"Encoded_dimension_visualization_L{}_E{}.png\".format(latent_dim,epoch))\nplt.show()","b1968916":"# Generator Model\ndecoder_input = keras.layers.Input(shape=(latent_dim,))\n_dense_2 = dense_2(decoder_input)\n_dense_3 = dense_3(_dense_2)\n_reshape = reshape(_dense_3)\n_conv_4 = conv_4(_reshape)\n_conv_5 = conv_5(_conv_4)\n_conv_6 = conv_6(_conv_5)\n_decoder_output = decoder_output(_conv_6)\n\ndecoder = keras.Model(decoder_input,_decoder_output)","02f203a7":"digit_size = 28\nn = 10  # figure with 10x10 digits\nfigure = np.zeros((digit_size * n, digit_size * n))\n\nfor i in range(n):\n    for j in range(n):\n        z_sample = np.random.normal(size=latent_dim).reshape(1, latent_dim)\n        x_decoded = decoder.predict(z_sample, batch_size=1)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        \n        x = i * digit_size\n        y = j * digit_size\n        figure[x:x + digit_size, y:y + digit_size] = digit\n\nplt.figure(figsize=(14, 14))\nplt.axis(\"off\")\nplt.imshow(figure, cmap='Greys_r')\nplt.title(\"generated_images_L{}_E_{}\".format(latent_dim,epoch))\nplt.savefig(\"generated_images_L{}_E_{}.png\".format(latent_dim,epoch))\nplt.show()","9a498c90":"def add_noise(x, noise_factor=0.1):\n    x = x + np.random.randn(*x.shape) * noise_factor\n    x = x.clip(0., 1.)\n    return x","8e349de8":"selected_x_noisy = add_noise(selected_x)\npred_noise_remove = variational_encoder.predict(selected_x_noisy)","83a7f0b0":"# selected original images\nplot_image(selected_x,selected_y,title=\"selected original images\")\n# add noise to  original images\nplot_image(selected_x_noisy,selected_y,title=\"Noisy_images\",save=\"Noisy_images\")\n# predicted images from noisy image\nplot_image(pred_noise_remove,selected_y,title=\"prediction_from_noisy_image\",save=\"prediction_from_noisy_image\")","d4fd5cbd":"## Model prediction<a id='13'><\/a>","3d4ffab1":"## Model training<a id='12'><\/a>","672cd19a":"<a id='1'><\/a>\n# Autoencoder\n* neural network with unsupervised machine-learning algorithm apply back-prop to set target value to the input\n* auto-encoder prefers over PCA because it can learn non-linear transformations with non-linear activation functions. more efficient to learn several layer with auto-encoder then one huge transformation with PCA.","e71b52bc":"# <font color='red'>Please!!! Upvote this kernel if you find it useful.<\/font>","0057122c":"<a id='4'><\/a>\n# Properties of Autoencoder\n1. **Data-specific**: Autoencoders are only able to meaningfully compress data similar to what they have been trained on.\n2. **Lossy**: de-compressed output will be degrad compared to the original input\n3. **Unsupervised**: Autoencoders are considered an unsupervised learning technique since they don\u2019t need explicit labels to train on. But to be more precise they are **self-supervised** because they generate their own labels from the training data.","63b529de":"# Variational Autoencoder (convolutional)<a id=\"vae\"><\/a>\n","9e0823f8":"## Model plot<a id='11'><\/a>","53cb71a5":"<a id='2'><\/a>\n# Autoencoder Applications\n* Image coloring (Black-white images -> colored)\n* Feature variation (Extract required feature)\n* Dimensionality Reduction\n* Denosing image (Remove Noise)\n* Remove watermark","013346c4":"<a id='9'><\/a>\n## Decoder implementation","17332078":"![VAE.png](attachment:VAE.png)","bd4fe41f":"<a id='5'><\/a>\n# Types of Autoencoder\n1.  **Denoising** autoencoder.\n2.  **Sparse** Autoencoder.\n3.  **Deep** Autoencoder.\n4.  **Contractive** Autoencoder.\n5.  **Undercomplete** Autoencoder.\n6.  **Convolutional** Autoencoder.\n7.  **Variational** Autoencoder.","da57a557":"<a id='3'><\/a>\n# Autoencoder Architecture\n* **Encoder** : part of NN compress the input into latent space representation\n* **code** : part of NN represents compressed input \n* **Decoder** : Decode the encoded data to original dimension","00f529a0":"<a id='8'><\/a>\n## Latent space implementation","91dc3c13":"# <font color='red'>Please!!! Upvote this kernel if you find it useful.<\/font>","2031d110":"# Remove Noise<a id=\"17\"><\/a>","088d24eb":"## Model compile and summary","a947bc94":"<a id='7'><\/a>\n## Encoder implementation","b4bd9fc4":"<a id='6'><\/a>\n![Conv_vae.png](attachment:Conv_vae.png)","a3be03c9":"## Loss Function<a id='10'><\/a>","63548d8d":"![encoder_decoder.png](attachment:encoder_decoder.png)","c9943655":"## Decoder\/Generator Model<a id='16'><\/a>","3bbf6377":"1.  [Introduction](#1)\n2.  [Applications](#2)\n3.  [Architecture](#3)\n4.  [Properties of Autoencoder](#4)\n5.  [Types of Autoencoder](#5)\n6.  [Variational Autoencoder (convolutional)](#vae)\n    * [Encoder implementation](#7)\n    * [Latent space implementation](#8)\n    * [Decoder implementation](#9)\n    * [Loss Function](#10)\n    * [Model layers plot](#11)\n    * [Model training](#12)\n    * [Model prediction](#13)\n    * [Visualize  prediction](#14)\n    * [Encoded dimension visualization ](#15)\n    * [Decoder\/Generator Model](#16)\n    * [Remove Noise](#17)","12be8652":"## Visualize prediction<a id='14'><\/a>","4d05b711":"## Encoded dimension visualization <a id='15'><\/a>"}}