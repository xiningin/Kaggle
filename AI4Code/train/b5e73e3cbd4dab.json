{"cell_type":{"aa7e84a0":"code","9afa6848":"code","69f4fae9":"code","2929ad9a":"code","030cf0e0":"code","bac29246":"code","e91086f4":"code","e1a51826":"code","fb32a2f9":"code","00db5fa4":"code","d2178ef9":"code","c9fce8bd":"code","6da87593":"code","f1bd5f1a":"code","61ea3c8c":"code","0786e644":"code","f2ac847c":"code","0b0b0684":"code","7df5567b":"code","e5e44320":"code","c0ca2a30":"code","605f4c5a":"code","025d0863":"code","a1c53e43":"code","afacd1fe":"code","fcea9fc5":"code","95d2e527":"code","f0ebdf4d":"code","d8776530":"code","0000b3ab":"code","0cabeed2":"code","bf14b73b":"code","6495e83b":"markdown","f791971f":"markdown","1a51102a":"markdown","805b08c5":"markdown","777bc66c":"markdown","6e282230":"markdown","9da8b787":"markdown","9385eae3":"markdown","9d2c7ba0":"markdown","bb9cc6fa":"markdown","f253b8eb":"markdown","b6710597":"markdown","772d5106":"markdown","c8c64389":"markdown","b2aa24a0":"markdown","b7d39cab":"markdown","04cb7f7b":"markdown","06957323":"markdown","f7f2e05a":"markdown","8587fac9":"markdown","773a35b3":"markdown","53a43dc3":"markdown","5163a644":"markdown","652e5cb0":"markdown","55981947":"markdown","a8f9ceee":"markdown","d401457a":"markdown","8442d683":"markdown","7f6081d4":"markdown","ff746e74":"markdown","ec9626ae":"markdown","127bf373":"markdown","5bfb42c2":"markdown"},"source":{"aa7e84a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9afa6848":"import spacy\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport timeit\nimport tensorflow as tf\nimport tensorflow_hub as hub\n# Cleaning Data\nfrom keras.preprocessing.text import Tokenizer\nfrom nltk import corpus, SnowballStemmer, word_tokenize\n# !pip install pyspellchecker\n# from spellchecker import SpellChecker\nfrom tqdm import tqdm\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Preprocessing and Modelling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, GRU, LSTM, SpatialDropout1D\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM\nfrom keras.models import Sequential\n","69f4fae9":"train_full = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_full = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ndf = pd.concat([train_full, test_full])\n\ntrain_len = train_full.shape[0]\n\nprint('Training Set Shape = {}'.format(train_full.shape))\nprint('Training Set Memory Usage = {:.2f}MB'.format(train_full.memory_usage().sum()\/2**20))\n\nprint('Test Set Shape = {}'.format(test_full.shape))\nprint('Test Set Memory Usage = {:.2f}MB'.format(test_full.memory_usage().sum()\/2**20))","2929ad9a":"# Check Unbalancing Data\ntrain_full.groupby('target').describe()","030cf0e0":"# Using to plot model that be trained\ndef plot_model(history):\n    acc = history['acc'] if 'acc' in history.keys() else history['accuracy']\n    val_acc = history['val_acc'] if 'val_acc' in history.keys() else history['val_accuracy']\n    loss = history['loss'] \n    val_loss = history['val_loss'] \n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()","bac29246":"# Counting the number of meaning tweet (1 is real disaster, 0 is no disaster)\nx = train_full.target.value_counts()\n# Display it\nsns.barplot(x.index, x)\nplt.gca().set_ylabel('Number of tweets')","e91086f4":"# Define the default histogram chart\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25,10))\nfig.suptitle(\"Characters in Tweets\", color=\"Blue\", size=30)\n# Disaster Chart\ndisaster_len = train_full[train_full.target==1].text.str.len()\nax1.hist(disaster_len, color='red')\nax1.set_title(\"Disaster Tweets\")\nax1.set_xlabel(\"Tweet Character Length\")\nax1.set_ylabel(\"Quantity\")\n# No Disaster Chart\nnodisaster_len = train_full[train_full.target==0].text.str.len()\nax2.hist(nodisaster_len, color='blue')\nax2.set_title(\"No Disaster Tweets\")\nax2.set_xlabel(\"Tweet Character Length\")\nax2.set_ylabel(\"Quantity\")\n# Display charts\nplt.show()","e1a51826":"# Define the defaults histogram\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(25,10))\nfig.suptitle(\"Words in Tweet\", size=30, color=\"Blue\")\n# Disaster chart\nDisasterWord_len=train_full[train_full.target==1].text.str.split().map(lambda x: len(x))\nax1.hist(DisasterWord_len, color='Red')\nax1.set_title(\"Disaster Tweets\")\nax1.set_xlabel(\"Tweet Word Length\")\nax1.set_ylabel(\"Quantity\")\n# No Disaster chart\nNoDisasterWord_len = train_full[train_full.target==0].text.str.split().map(lambda x: len(x))\nax2.hist(NoDisasterWord_len, color='Green')\nax2.set_title(\"No Disaster Tweets\")\nax2.set_xlabel(\"Tweet Word Length\")\nax2.set_ylabel(\"Quantity\")\n# Display Histogram\nplt.show()","fb32a2f9":"# Define the default plots\nfig, (ax1, ax2) = plt.subplots(1,2,figsize=(25,10))\nfig.suptitle(\"Average Word Length in a Tweet\", color=\"blue\", size=30)\n# Disaster Plot\nDisasterAvgWord_len = train_full[train_full.target==1].text.str.split().apply(lambda x: [len(i) for i in x])\nsns.distplot(DisasterAvgWord_len.map(lambda x: np.mean(x)), ax=ax1, color='red')\nax1.set_title(\"Disaster Tweets\")\n# Distribution Plots\nNoDisasterAvgWord_len= train_full[train_full.target==0].text.str.split().apply(lambda x: [len(i) for i in x])\nsns.distplot(NoDisasterAvgWord_len.map(lambda x: np.mean(x)), ax=ax2, color=\"green\")\nax2.set_title(\"No Disaster Tweets\")\n# Display Plots\nplt.show()","00db5fa4":"emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n# Collect all clean-corpus technics into a function\ndef clean_text(tweet):\n    \n    tweet = str(tweet).lower() # Make text lowercase\n    tweet = re.sub('\\[.*?\\]', '', tweet)\n    tweet = re.sub('https?:\/\/\\S+|www\\.\\S+', '', tweet)\n    tweet = re.sub('<.*?>+', '', tweet)\n    tweet = re.sub('[%s]' % re.escape(string.punctuation), '', tweet) # Remove Punctuation\n    tweet = re.sub('\\n', '', tweet)\n    tweet = re.sub('\\w*\\d\\w*', '', tweet)\n    \n    # Remove Emoji\n    tweet = emoji_pattern.sub(r'', tweet)\n    # Special characters\n    tweet = re.sub(r\"\\x89\u00db_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00d2\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00d3\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00cfWhen\", \"When\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00cf\", \"\", tweet)\n    tweet = re.sub(r\"China\\x89\u00db\u00aas\", \"China's\", tweet)\n    tweet = re.sub(r\"let\\x89\u00db\u00aas\", \"let's\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00f7\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00aa\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\\x9d\", \"\", tweet)\n    tweet = re.sub(r\"\u00e5_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00a2\", \"\", tweet)\n    tweet = re.sub(r\"\\x89\u00db\u00a2\u00e5\u00ca\", \"\", tweet)\n    tweet = re.sub(r\"from\u00e5\u00cawounds\", \"from wounds\", tweet)\n    tweet = re.sub(r\"\u00e5\u00ca\", \"\", tweet)\n    tweet = re.sub(r\"\u00e5\u00c8\", \"\", tweet)\n    tweet = re.sub(r\"Jap\u00cc_n\", \"Japan\", tweet)    \n    tweet = re.sub(r\"\u00cc\u00a9\", \"e\", tweet)\n    tweet = re.sub(r\"\u00e5\u00a8\", \"\", tweet)\n    tweet = re.sub(r\"Suru\u00cc\u00a4\", \"Suruc\", tweet)\n    tweet = re.sub(r\"\u00e5\u00c7\", \"\", tweet)\n    tweet = re.sub(r\"\u00e5\u00a33million\", \"3 million\", tweet)\n    tweet = re.sub(r\"\u00e5\u00c0\", \"\", tweet)\n    \n    # Contractions\n    tweet = re.sub(r\"he's\", \"he is\", tweet)\n    tweet = re.sub(r\"there's\", \"there is\", tweet)\n    tweet = re.sub(r\"We're\", \"We are\", tweet)\n    tweet = re.sub(r\"That's\", \"That is\", tweet)\n    tweet = re.sub(r\"won't\", \"will not\", tweet)\n    tweet = re.sub(r\"they're\", \"they are\", tweet)\n    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n    tweet = re.sub(r\"don\\x89\u00db\u00aat\", \"do not\", tweet)\n    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"What's\", \"What is\", tweet)\n    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n    tweet = re.sub(r\"There's\", \"There is\", tweet)\n    tweet = re.sub(r\"He's\", \"He is\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"You're\", \"You are\", tweet)\n    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n    tweet = re.sub(r\"I\\x89\u00db\u00aam\", \"I am\", tweet)\n    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n    tweet = re.sub(r\"you've\", \"you have\", tweet)\n    tweet = re.sub(r\"you\\x89\u00db\u00aave\", \"you have\", tweet)\n    tweet = re.sub(r\"we're\", \"we are\", tweet)\n    tweet = re.sub(r\"what's\", \"what is\", tweet)\n    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n    tweet = re.sub(r\"we've\", \"we have\", tweet)\n    tweet = re.sub(r\"it\\x89\u00db\u00aas\", \"it is\", tweet)\n    tweet = re.sub(r\"doesn\\x89\u00db\u00aat\", \"does not\", tweet)\n    tweet = re.sub(r\"It\\x89\u00db\u00aas\", \"It is\", tweet)\n    tweet = re.sub(r\"Here\\x89\u00db\u00aas\", \"Here is\", tweet)\n    tweet = re.sub(r\"who's\", \"who is\", tweet)\n    tweet = re.sub(r\"I\\x89\u00db\u00aave\", \"I have\", tweet)\n    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n    tweet = re.sub(r\"can\\x89\u00db\u00aat\", \"cannot\", tweet)\n    tweet = re.sub(r\"would've\", \"would have\", tweet)\n    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n    tweet = re.sub(r\"wouldn\\x89\u00db\u00aat\", \"would not\", tweet)\n    tweet = re.sub(r\"We've\", \"We have\", tweet)\n    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n    tweet = re.sub(r\"That\\x89\u00db\u00aas\", \"That is\", tweet)\n    tweet = re.sub(r\"they've\", \"they have\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"should've\", \"should have\", tweet)\n    tweet = re.sub(r\"You\\x89\u00db\u00aare\", \"You are\", tweet)\n    tweet = re.sub(r\"where's\", \"where is\", tweet)\n    tweet = re.sub(r\"Don\\x89\u00db\u00aat\", \"Do not\", tweet)\n    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n    tweet = re.sub(r\"They're\", \"They are\", tweet)\n    tweet = re.sub(r\"Can\\x89\u00db\u00aat\", \"Cannot\", tweet)\n    tweet = re.sub(r\"you\\x89\u00db\u00aall\", \"you will\", tweet)\n    tweet = re.sub(r\"I\\x89\u00db\u00aad\", \"I would\", tweet)\n    tweet = re.sub(r\"let's\", \"let us\", tweet)\n    tweet = re.sub(r\"it's\", \"it is\", tweet)\n    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n    tweet = re.sub(r\"don't\", \"do not\", tweet)\n    tweet = re.sub(r\"you're\", \"you are\", tweet)\n    tweet = re.sub(r\"i've\", \"I have\", tweet)\n    tweet = re.sub(r\"that's\", \"that is\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n    tweet = re.sub(r\"I've\", \"I have\", tweet)\n    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n    tweet = re.sub(r\"don\u00e5\u00abt\", \"do not\", tweet)   \n    \n    # Character entity references\n    tweet = re.sub(r\"&gt;\", \">\", tweet)\n    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n    \n    # Typos, slang and informal abbreviations\n    tweet = re.sub(r\"w\/e\", \"whatever\", tweet)\n    tweet = re.sub(r\"w\/\", \"with\", tweet)\n    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n    tweet = re.sub(r\"<3\", \"love\", tweet)\n    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n    tweet = re.sub(r\"8\/5\/2015\", \"2015-08-05\", tweet)\n    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n    tweet = re.sub(r\"8\/6\/2015\", \"2015-08-06\", tweet)\n    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n    \n    # Hashtags and usernames\n    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n    tweet = re.sub(r\"Listen\/Buy\", \"Listen \/ Buy\", tweet)\n    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n    tweet = re.sub(r\"Newss\", \"News\", tweet)\n    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n    tweet = re.sub(r\"andword\", \"and word\", tweet)\n    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n    tweet = re.sub(r\"evng\", \"evening\", tweet)\n    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n    \n    # Urls\n    tweet = re.sub(r\"https?:\\\/\\\/t.co\\\/[A-Za-z0-9]+\", \"\", tweet)\n    \n    # Words with punctuations and special characters\n    punctuations = '@#!?+&*[]-%.:\/();$=><|{}^' + \"'`\"\n    for p in punctuations:\n        tweet = tweet.replace(p, f' {p} ')\n        \n    # ... and ..\n    tweet = tweet.replace('...', ' ... ')\n    if '...' not in tweet:\n        tweet = tweet.replace('..', ' ... ')      \n        \n    # Acronyms\n    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n    tweet = re.sub(r\"m\u00cc\u00bcsica\", \"music\", tweet)\n    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n    \n    # Grouping same words without embeddings\n    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n    \n    return tweet\ndf.text = df.text.apply(lambda x: clean_text(x))","d2178ef9":"stop_words = corpus.stopwords.words('english')\ndef remove_stopwords(text):\n    return ' '.join(w for w in text.split(' ') if w not in stop_words)\ndf.text = df.text.apply(remove_stopwords)","c9fce8bd":"stemmer = SnowballStemmer(\"english\")\n\ndef stemming_text(text):\n    return ' '.join(stemmer.stem(w) for w in text.split(' '))\n\ndf.text = df.text.apply(stemming_text)","6da87593":"# spell = SpellChecker()\n# def correct_spelling(text):    \n#     misspelled_words = spell.unknown(text.split())\n#     corrected_text = [spell.correction(w) if w in misspelled_words else w for w in text.split()] \n#     return \" \".join(corrected_text)\n# t1 = timeit.timeit()\n# # df.text = df.text.apply(correct_spelling)\n# t2 = timeit.timeit()\n# print(t2-t1)","f1bd5f1a":"# Instantiate the Vectorizer\nvect = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0, max_df=0.9, max_features=100)\ndf_dtm = vect.fit_transform(df)\ndf_dtm.toarray()[0]","61ea3c8c":"tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=0, max_df=0.98, max_features=100)\ndf_ifidf= tfidf_vect.fit_transform(df)\ndf_ifidf.toarray()[0]","0786e644":"# Create Corpus from Text DataFrame\ncorpus=[]\nfor tweet in tqdm(df['text']):\n    words = [word.lower() for word in word_tokenize(tweet) if (word.isalpha()==1 & (word not in stop_words))]\n    corpus.append(words)","f2ac847c":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(corpus)\nword_index =  tokenizer.word_index\nvocal_length = len(word_index) + 1\nvocal_length","0b0b0684":"# Create Embedding Dictionary from GloVe Data\nembedding_dict = {}\nwith open('\/kaggle\/input\/glove-global-vectors-for-word-representation\/glove.6B.100d.txt', 'r') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vectors = np.asarray(values[1:], 'float32')\n        embedding_dict[word] = vectors\nf.close()\nlen(embedding_dict)","7df5567b":"# Preparing the GloVe word-embeddings matrix\nEMBEDDING_DIM = 100\n\nembedding_matrix = np.zeros((vocal_length, EMBEDDING_DIM))\n\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embedding_dict.get(word)\n    if embedding_vector is not None:\n        # word not found will be all-zeros.\n        embedding_matrix[i] = embedding_vector","e5e44320":"MAX_SEQUENCE_LENGTH = 40\n\npadded_sentences = pad_sequences(tokenizer.texts_to_sequences(corpus), maxlen=MAX_SEQUENCE_LENGTH, truncating='post', padding=\"post\")\n\ntrain = padded_sentences[:train_len]\ntarget = train_full['target'].values\ntest = padded_sentences[train_len:]","c0ca2a30":"def modelRNN(embed_dim):\n    model = Sequential()\n    model.add(Embedding(vocal_length, \n                        EMBEDDING_DIM,\n                        weights=[embedding_matrix],\n                        input_length=MAX_SEQUENCE_LENGTH,\n                        trainable=False))\n    model.add(SimpleRNN(embed_dim))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='rmsprop', \n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    history = model.fit(train, target,\n                         epochs=10,\n                         batch_size=128,\n                         validation_split=0.2)\n    return model, history","605f4c5a":"# mod_RNN, his_RNN = modelRNN(64)\n# plot_model(his_RNN.history)","025d0863":"def modelLSTM(embed_dim):\n    model = Sequential()\n    model.add(Embedding(vocal_length, \n                        EMBEDDING_DIM, \n                        weights=[embedding_matrix], \n                        input_length=MAX_SEQUENCE_LENGTH, \n                        trainable=False))\n    model.add(Bidirectional(LSTM(embed_dim,\n                                dropout=0.2,\n                                recurrent_dropout=0.2)))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='rmsprop', \n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    history = model.fit(train, target,\n                         epochs=8,\n                         batch_size=128,\n                         validation_split=0.2)\n    return model, history","a1c53e43":"# mod_LSTM, his_LSTM = modelLSTM(64)\n# plot_model(his_LSTM.history)","afacd1fe":"def modelGRU(embed_dim):\n    model = Sequential()\n    model.add(Embedding(vocal_length,\n                       EMBEDDING_DIM,\n                       weights=[embedding_matrix],\n                       input_length=MAX_SEQUENCE_LENGTH,\n                       trainable=False))\n    model.add(Bidirectional(GRU(embed_dim,\n                               dropout=0.3,\n                               recurrent_dropout=0.4)))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='rmsprop', \n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    history = model.fit(train, target,\n                         epochs=18,\n                         batch_size=128,\n                         validation_split=0.2)\n    return model, history","fcea9fc5":"model_GRU, history_GRU = modelGRU(64)\nplot_model(history_GRU.history)","95d2e527":"def modelLSTM_dropout(embed_dim):\n    model = Sequential()\n    model.add(Embedding(vocal_length,\n                       EMBEDDING_DIM,\n                       weights=[embedding_matrix],\n                       input_length=MAX_SEQUENCE_LENGTH,\n                       trainable=False))\n    model.add(SpatialDropout1D(0.2))\n    model.add(Bidirectional(LSTM(embed_dim,\n                               dropout=0.2,\n                               recurrent_dropout=0.2)))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='rmsprop', \n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    history = model.fit(train, target,\n                         epochs=10,\n                         batch_size=128,\n                         validation_split=0.2)\n    return model, history","f0ebdf4d":"# model_LSTM_dropout, history_LSTM_dropout = modelLSTM_dropout(64)\n# plot_model(history_LSTM_dropout.history)","d8776530":"def model_doubleLSTM(embed_dim):\n    model = Sequential()\n    model.add(Embedding(vocal_length,\n                       EMBEDDING_DIM,\n                       weights=[embedding_matrix],\n                       input_length=MAX_SEQUENCE_LENGTH,\n                       trainable=False))\n    \n    model.add(Bidirectional(GRU(embed_dim,\n                            dropout=0.2,\n                            recurrent_dropout=0.2,\n                               return_sequences=True)))\n    model.add(Bidirectional(GRU(embed_dim,\n                           dropout=0.2,\n                           recurrent_dropout=0.2)))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='rmsprop', \n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    history = model.fit(train, target,\n                         epochs=10,\n                         batch_size=128,\n                         validation_split=0.2)\n    return model, history","0000b3ab":"# model_doubleLSTM, history_doubleLSTM = model_doubleLSTM(64)\n# plot_model(history_doubleLSTM.history)","0cabeed2":"def submission_glove(model, test):\n    \"\"\"For GloVe\"\"\"\n    sample_sub = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\n    y_preds = model.predict(test).round().astype(int).reshape(3263) \n    sub=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':y_preds})\n    sub.to_csv('submission.csv',index=False)\n","bf14b73b":"submission_glove(model_GRU, test)","6495e83b":"In general, the Validation accuracy climbed slowly. Model is needed improvement.  ","f791971f":"<a id=10 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">Make a Submission<\/p>\n\n[Content](#0)","1a51102a":"<a id='1'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">1. Loading Data \ud83d\udc8e<\/p>\n\nJust load the dataset and global variables for colors and so on.\n\n[Content](#0)","805b08c5":"<a id='3'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">3. Data Pre-processing <\/p>\n\nNow we are going to engineering the data to make it easier for the model to clasiffy.\n\nThis section is very important to reduce the dimensions of the problem.\n\n\n[Content](#0)","777bc66c":"# Number of Words in a tweet","6e282230":"# Class Distribution\n","9da8b787":"<a id=5.1.4 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.4 'Bidirectional' and GRU layer<\/p>\n\n[Content](#0)","9385eae3":"<a id='2'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">2. EDA \ud83d\udcca<\/p>\n\nNow we are going to take a look about the target distribution and the messages length.\n\n[Content](#0)","9d2c7ba0":"<a id=3.1 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 15px 50px;\">3.1 Cleaning the corpus<\/p>\n\n\n[Content](#0)","bb9cc6fa":"<a id=5.1.5 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.5 SpatialDropout1D + Bidirectional + LSTM layer<\/p>\n\n[Content](#0)","f253b8eb":"<a id=3.2 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 15px 50px;\">3.2 Stemming<\/p>\n\n\n[Content](#0)","b6710597":"<a id=5.1.1 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.1 Preparing the data<\/p>\n\n[Content](#0)","772d5106":"Spend so much time to apply Spelling Checker, I will not use it in this data.","c8c64389":"Result: Model is better with increasing dropout hyperparameter. I am make confused with maximum dropout that can be chosen. \nIn practical, dropout = 0.3 is best.","b2aa24a0":"<a id=4.2 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4.2 TF-IDF<\/p>\nReference: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n\n[Content](#0)","b7d39cab":"<img src=\"https:\/\/i.ibb.co\/RT7wV2V\/double-LSTM.png\" alt=\"double-LSTM\" border=\"0\">","04cb7f7b":"<a id=5.1.6 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.6 Bidirectional + double LSTM layer<\/p>\n\n[Content](#0)","06957323":"<img src=\"https:\/\/i.ibb.co\/0rCjB7T\/LSTMDropout.png\" alt=\"LSTMDropout\" border=\"0\">","f7f2e05a":"# Remove Stopwords","8587fac9":"# Number of characters in tweets","773a35b3":"Result : Adding Dropout working with Bidirectorial LSTM make worse result. Model is easier to overfit and sensitive ","53a43dc3":"<img src=\"https:\/\/i.ibb.co\/Cv80Nbj\/LSTM.png\" alt=\"LSTM\" border=\"0\">","5163a644":"Result: It is a bad idea","652e5cb0":"<a id=4 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4. Vectorization<\/p>\n\nThree steps using the Bag-of-words (BOW) model:\n1. Term frequency : count occurrences of word in sentence\n2. Inverse document frequency: \n3. L2 Norm\nReference : https:\/\/scikit-learn.org\/stable\/modules\/feature_extraction.html#text-feature-extraction\n\n[Content](#0)","55981947":"<a id=5 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">5. Model<\/p>\n\n[Content](#0)","a8f9ceee":"<a id=3.3 ><\/a>\n   ## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">3.3 Spelling Checker<\/p>\n   \n\n[Content](#0)","d401457a":"<a id=4.1 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">4.1 Common Vectorizer Usage<\/p>\nReference: https:\/\/scikit-learn.org\/stable\/modules\/feature_extraction.html#common-vectorizer-usage\n\n[Content](#0)","8442d683":"<a id=5.1 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:140%; text-align:left; border-radius: 20px 50px;\">5.1. GloVe for Vectorization<\/p>\n\nGloVe (*Global Vectors for Word Representation*) is:\n\n    * An unsupervised learning algorithm for obtaining vector representations for words.\n\n    * Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n    \n    * Non-contextual Word Embedding\n    \n    * Un-directional Model\n\n[Content](#0)","7f6081d4":"<a id=5.1.2 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.2 The First recurrent Baseline with 'SimpleRNN' layer<\/p>\n\n[Content](#0)","ff746e74":"<img src=\"https:\/\/i.ibb.co\/6wdWCPm\/RNN.png\" alt=\"RNN\" border=\"0\">","ec9626ae":"<a id=0><\/a>\n## <p style=\"background-color:lightblue; font-family:newtimeroman; font-size:120%; text-align:left; border-radius: 15px 50px;\">Table of Content<\/p>\n\n* [1. Loading Data \ud83d\udc8e](#1)\n* [2. EDA \ud83d\udcca](#2)\n* [3. Data Preprocessing](#3)\n    * [3.1 Remove corpus](#3.1)\n    * [3.2 Remove Stemming](#3.2)\n* [4. Vectorization](#4)\n    * [4.1 Common Vectorizer Usage](#4.1)\n    * [4.2 If-Idf Term Weightings](#4.2)\n* [5. Model](#5)\n    * [5.1. GloVe for Vectorization](#5.1)\n        * [5.1.1 Preparing the data](#5.1.1)\n        * [5.1.2 The First recurrent Baseline with 'SimpleRNN' layer](#5.1.2)\n        * [5.1.3 'Bidirectional' and 'LSTM' layer](#5.1.3)\n        * [5.1.4 'Bidirectional' and GRU layer](#5.1.4)\n        * [5.1.5 SpatialDropout1D + Bidirectional + LSTM layer](#5.1.5) \n        * [5.1.6 Bidirectional + double LSTM layer](#5.1.6)\n* [Make a Submission](#10)","127bf373":"Range from 120 to 140 characters is the most common in tweet.","5bfb42c2":"<a id=5.1.3 ><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:left; border-radius: 20px 50px;\">5.1.3 'Bidirectional' and 'LSTM' layer<\/p>\n\n[Content](#0)"}}