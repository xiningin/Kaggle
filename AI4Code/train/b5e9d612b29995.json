{"cell_type":{"931e675a":"code","2c3ac247":"code","08f0e3d5":"code","474fe7d2":"code","a65b286e":"code","7b434776":"code","9d952b3d":"code","44e004a7":"code","7b0e0e0f":"code","fac35ac0":"code","33776e93":"code","5e7fca0d":"code","c6cde414":"code","31be751b":"code","e72b69d8":"code","1d601133":"code","b4b87fc2":"code","3382da3e":"code","fbe633ac":"code","66a4b85d":"code","06e43651":"code","8a092798":"code","22d74787":"markdown","05e53088":"markdown","01a7c845":"markdown","00142a2b":"markdown","80c44958":"markdown","37600f02":"markdown","fa2b44fe":"markdown","6328ab6c":"markdown","8f505c91":"markdown","8d80d298":"markdown","0b0aab44":"markdown","a987eba4":"markdown","cc9781d0":"markdown"},"source":{"931e675a":"!pip install bnlearn","2c3ac247":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport bnlearn as bn\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","08f0e3d5":"train = pd.read_csv('..\/input\/titanic\/train.csv').set_index('PassengerId')\ntest = pd.read_csv('..\/input\/titanic\/test.csv').set_index('PassengerId')","474fe7d2":"train.head(3)","a65b286e":"train.describe()","7b434776":"# Dropping columns with many unique values\ndrop_list = ['Name', 'Age', 'Cabin', 'Ticket', 'Fare']\ntrain = train.drop(columns=drop_list)\ntest = test.drop(columns=drop_list)","9d952b3d":"train.info()","44e004a7":"test.info()","7b0e0e0f":"# Data preparing\ndfhot_train, dfnum_train = bn.df2onehot(train)\ndfhot_test, dfnum_test = bn.df2onehot(test)","fac35ac0":"dfnum_train","33776e93":"dfnum_target = dfnum_train.pop('Survived')","5e7fca0d":"Xtrain, Xval, Ztrain, Zval = train_test_split(dfnum_train, dfnum_target, test_size=0.2, random_state=0)\nvalid = pd.concat([Xval, Zval], axis='columns')\ndfnum = pd.concat([Xtrain, Ztrain], axis='columns')\ndfnum","c6cde414":"# Get score\ndef get_acc(model, df, col):\n    # Get accuracy score by the model for the validation dataset df with target col\n    pred = bn.predict(model, df, variables=[col])\n    print(pred)\n    acc = accuracy_score(df[col], pred[col])\n    print('Accuracy -', acc)\n    return acc","31be751b":"%%time\n# Structure learning\nDAG = bn.structure_learning.fit(dfnum, methodtype='hc', root_node='Survived', bw_list_method='nodes', verbose=3)\n\n# Plot\nG = bn.plot(DAG)\n\n# Parameter learning\nmodel = bn.parameter_learning.fit(DAG, dfnum, verbose=3);","e72b69d8":"# About the model\nmodel","1d601133":"# Get score of the model1\nacc1 = get_acc(model, valid, 'Survived')","b4b87fc2":"%%time\n# Structure learning\nDAG2 = bn.structure_learning.fit(dfnum, methodtype='hc', black_list=['SibSp'], root_node='Survived', bw_list_method='nodes', verbose=4)\n\n# Plot\nG2 = bn.plot(DAG2)\n\n# Parameter learning\nmodel2 = bn.parameter_learning.fit(DAG2, dfnum, verbose=4);","3382da3e":"# Score of the model2\nacc2 = get_acc(model, valid.drop(columns=['SibSp']), 'Survived')","fbe633ac":"# Models comparing\nres = bn.bnlearn.compare_networks(model, model2, figsize=(15, 8), verbose=3)\nprint('Coincidence -', (res[0][0, 0] + res[0][1, 1])\/res[0].sum())","66a4b85d":"%%time\n# Make inference\nquery = bn.inference.fit(model, variables=['Survived'], evidence={'Sex':True, 'Pclass':True})\nprint(query)\nprint(query.df)\n\n# Another inference using only sex for evidence\nq1 = bn.inference.fit(model, variables=['Survived'], evidence={'Sex':0})\nprint(query)\nprint(query.df)\n\n# Print model\nbn.print_CPD(model)","06e43651":"# Prediction using the Bayesian network\nPout = bn.predict(model, df=dfnum_test, variables=['Survived'])\nPout","8a092798":"# Submission\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = Pout['Survived']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","22d74787":"Your comments and feedback are most welcome.","05e53088":"<a class=\"anchor\" id=\"0.1\"><\/a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [Creation the Bayesian network](#3)\n1. [Inference from the Bayesian network](#4)\n1. [Prediction](#5)","01a7c845":"## 4. Inference from the Bayesian network <a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","00142a2b":"<a class=\"anchor\" id=\"0\"><\/a>\n# Bayesian network for the competition \"Titanic: Machine Learning from Disaster\"","80c44958":"## 5. Prediction <a class=\"anchor\" id=\"5\"><\/a>\n\n[Back to Table of Contents](#0.1)","37600f02":"## 3. Creation the Bayesian network <a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","fa2b44fe":"I hope you find this kernel useful and enjoyable.","6328ab6c":"## 1. Import libraries <a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","8f505c91":"### Model 2","8d80d298":"### Model 1","0b0aab44":"## 2. Download datasets <a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","a987eba4":"[Go to Top](#0)","cc9781d0":"## Thanks to:\n* library [bnlearn](https:\/\/erdogant.github.io\/bnlearn\/pages\/html\/Inference.html)\n* notebook [Merging FE & Prediction - xgb, lgb, logr, linr](https:\/\/www.kaggle.com\/vbmokin\/merging-fe-prediction-xgb-lgb-logr-linr)"}}