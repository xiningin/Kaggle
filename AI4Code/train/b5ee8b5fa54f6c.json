{"cell_type":{"6fa5d931":"code","9f3e8835":"code","d47f2094":"code","a5905f81":"code","e9e6b95f":"code","69920aba":"code","5975bac1":"code","161ea156":"code","b25faf8f":"code","2904c126":"code","b7932999":"code","497fe619":"code","8d7272f8":"code","8cb02f1c":"code","939e1dcc":"code","d00e4e59":"code","937d8d9a":"code","95e7028c":"code","665553fa":"code","aa3b12f8":"code","8ac835e3":"code","3bbf9645":"code","b0d2c479":"code","a1e0d56f":"code","ef58c11e":"code","f7210b48":"code","47e08bb1":"code","27cae5eb":"code","4bbc2ec3":"code","23ff5a34":"code","1608bad0":"code","3e2b79d7":"code","d26e8661":"code","51716ef4":"code","4cd9cdfe":"code","ad62a92f":"markdown","b1dab984":"markdown","ef86071b":"markdown","fdfde336":"markdown","81fb7c5f":"markdown","1ebabb9d":"markdown","d4905e41":"markdown","53b8e613":"markdown"},"source":{"6fa5d931":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f3e8835":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import linear_model\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","d47f2094":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","a5905f81":"data.head()","e9e6b95f":"print(data.shape)","69920aba":"data.describe()","5975bac1":"data['Class'].value_counts()","161ea156":"sns.countplot('Class', data=data)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=12)","b25faf8f":"data.info()  # explore teh type and value of the data","2904c126":"data[data.duplicated()] # discover the duplicated row","b7932999":"data = data.drop_duplicates(keep='first') # remove the duplication and keep the first rows ","497fe619":"data.duplicated().sum() # Cheking any other duplication","8d7272f8":"data.describe()","8cb02f1c":"data.groupby('Class').hist(figsize=(9,9))","939e1dcc":"#shuffles the data before undersampling \ndata=data.sample(frac=1)\n\n# Taking 492 of non-fraud rows\nfraud_df = data.loc[data['Class']==1]\nnon_fraud_df = data.loc[data['Class']==0][:492]\n\n# Creating a new dataframe with 50:50 ratio of fraud:non-fraud\nequal_dis_df = pd.concat([fraud_df, non_fraud_df])\n\n# Shufffle the new dataframe\nnew_df = equal_dis_df.sample(frac=1, random_state=42)\n","d00e4e59":"# test the new values\n\ncolors = [\"#000000\", \"#FF0000\"]\n\nsns.countplot('Class', data=new_df, palette=colors)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n","937d8d9a":"X = new_df.drop('Class', axis=1)\ny = new_df['Class']\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n# Turn values into array to feed into classification algo\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\n","95e7028c":"# LogisticRegression\n\nclassifier = LogisticRegression(solver='liblinear',random_state = 0)\nclassifier.fit(X_train,y_train)","665553fa":"# predict the Result\nlog_y_pred = classifier.predict(X_test)\nprint(log_y_pred)","aa3b12f8":"#Confusion Matrix\ncm = confusion_matrix(y_test, log_y_pred)\nprint(cm)","8ac835e3":"acc_score_LR = accuracy_score(y_test, log_y_pred)\nprint(classifier , \"Has a training score of\", round(acc_score_LR.mean(), 2) * 100, \"% accuracy score\")\n","3bbf9645":"classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n","b0d2c479":"# predict the Result\nKN_y_pred = classifier.predict(X_test)\nprint(KN_y_pred)","a1e0d56f":"#Confusion Matrix\ncm_KN = confusion_matrix(y_test, KN_y_pred)\nprint(cm_KN)","ef58c11e":"acc_score_KNN = accuracy_score(y_test, KN_y_pred)\nprint(\"KNN Has a training score of\", round(acc_score_KNN.mean(), 2) * 100, \"% accuracy score\")\n","f7210b48":"classifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)","47e08bb1":"# predict the Result\nSVM_y_pred = classifier.predict(X_test)\nprint(SVM_y_pred)","27cae5eb":"#Confusion Matrix\ncm_svm = confusion_matrix(y_test, SVM_y_pred)\nprint(cm_svm)","4bbc2ec3":"acc_score_svm = accuracy_score(y_test, SVM_y_pred)\nprint(\"SVM Has a training score of\", round(acc_score_svm.mean(), 2) * 100, \"% accuracy score\")\n","23ff5a34":"dtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(X_train, y_train)","1608bad0":"# predict the Result\ndtc_y_pred = dtc.predict(X_test)\nprint(dtc_y_pred)","3e2b79d7":"#Confusion Matrix\ncm_dtc = confusion_matrix(y_test, dtc_y_pred)\nprint(cm_dtc)","d26e8661":"acc_score_dtc = accuracy_score(y_test, dtc_y_pred)\nprint(\"DecisionTreeClassifier Has a training score of\", round(acc_score_dtc.mean(), 2) * 100, \"% accuracy score\")","51716ef4":"mylist=[]\nmylist2=[]\nmylist.append(acc_score_LR)\nmylist2.append(\"Logistic Regression\")\nmylist.append(acc_score_KNN)\nmylist2.append(\"k-nearest neighbors\")\nmylist.append(acc_score_svm)\nmylist2.append(\"Support vector machine\")\nmylist.append(acc_score_dtc)\nmylist2.append(\"DecisionTreeClassifier\")","4cd9cdfe":"plt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Regressor Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","ad62a92f":"## DecisionTreeClassifier","b1dab984":"## Traning our Model","ef86071b":"# Exploratory data analysis ","fdfde336":"## Random Undersampling Technique","81fb7c5f":"## KNeighborsClassifier","1ebabb9d":"# Discover the duplication# ","d4905e41":"## SVM model ","53b8e613":"# Define Dataset"}}