{"cell_type":{"8a069385":"code","9222f515":"code","e552ed97":"code","a874cff8":"code","062af83f":"code","b48b542d":"code","b2f9c55a":"code","b6c5cf81":"code","a2e0e77e":"code","d81ce159":"code","d7ef433d":"code","1fb6147d":"code","454d25ad":"markdown","84727ea2":"markdown","f85157ee":"markdown","32e9684b":"markdown","56dacd47":"markdown","dc8256ae":"markdown","2d5ccec0":"markdown","51d74311":"markdown","60fd7149":"markdown","d2ec3e81":"markdown","a3d675ab":"markdown","5213aa6f":"markdown","2ee58475":"markdown","d2bed3bd":"markdown","509bd542":"markdown"},"source":{"8a069385":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n\n# This is a bit of magic to make matplotlib figures appear inline in the notebook\n# rather than in a new window.\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n","9222f515":"from tensorflow.python.keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Import Data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Train size:{}\\nTest size:{}\".format(train.shape, test.shape))\n\n# Transform Train and Test into images\\labels.\nx_train = train.drop(['label'], axis=1).values.astype('float32') # all pixel values\ny_train = train['label'].values.astype('int32') # only labels i.e targets digits\nx_test = test.values.astype('float32')\nx_train = x_train.reshape(x_train.shape[0], 28, 28) \/ 255.0\nx_test = x_test.reshape(x_test.shape[0], 28, 28) \/ 255.0\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.05, random_state=42)\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(x_test.shape)","e552ed97":"# classes for title\n# num classes for amount of examples\nclasses = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\nprint(x_train.shape)\nnum_classes = len(classes)\nsamples_per_class = 7\nplt.figure(0)\nfor y, cls in enumerate(classes):\n    idxs = np.flatnonzero(y_train == y)\n    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n    for i, idx in enumerate(idxs):\n        plt_idx = i * num_classes + y + 1\n        plt.subplot(samples_per_class, num_classes, plt_idx)\n        # plt.imshow(x_train[idx].astype('uint8'))\n        plt.imshow(x_train[idx])\n        plt.axis('off')\n        if i == 0:\n            plt.title(cls)\nplt.show()","a874cff8":"x_train = x_train.reshape(x_train.shape[0], 28, 28,1)  \nx_val = x_val.reshape(x_val.shape[0], 28, 28,1)  \nx_test = x_test.reshape(x_test.shape[0], 28, 28,1) \nprint(\"Train size:{}\\nvalidation size:{}\\nTest size:{}\".format(x_train.shape,x_val.shape, x_test.shape))\n\nmean_px = x_train.mean().astype(np.float32)\nstd_px = x_train.std().astype(np.float32)\n","062af83f":"from tensorflow.python.keras.layers import Input , Dense , Conv2D , Activation , Add,ReLU,MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom tensorflow.python.keras.models import Model\n\n\ninput = Input(shape=[28, 28, 1])\nx = Conv2D(32, (5, 5), strides=1, padding='same', name='conv1')(input)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch1')(x)\nx = Activation('relu', name='relu1')(x)\n# x = Dropout (0.5)(x)\nx = Conv2D(32, (5, 5), strides=1, padding='same', name='conv2')(x)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch2')(x)\nx = Activation('relu', name='relu2')(x)\n# x = Dropout (0.5)(x)\nx = Conv2D(32, (5, 5), strides=1, padding='same', name='conv2add')(x)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch2add')(x)\nx = Activation('relu', name='relu2add')(x)\nx = Dropout (0.15)(x)\nx = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\nx = Conv2D(64, (3, 3), strides=1, padding='same', name='conv3')(x)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch3')(x)\nx = Activation('relu', name='relu3')(x)\nx = Conv2D(64, (3, 3), strides=1, padding='same', name='conv4')(x)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch4')(x)\nx = Activation('relu', name='relu4')(x)\nx = Conv2D(32, (3, 3), strides=1, padding='same', name='conv5')(x)\nx = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform',name='batch5')(x)\nx = Activation('relu', name='relu5')(x)\nx = Dropout (0.15)(x)\nx = MaxPool2D(pool_size=2, strides=2)(x)\nx = Flatten()(x)\nx = Dense(100, name='Dense30')(x)\nx = Activation('relu', name='relu6')(x)\nx = Dropout (0.05)(x)\nx = Dense(10, name='Dense10')(x)\nx = Activation('softmax')(x)\nmodel = Model(inputs = input, outputs =x)\n\nprint(model.summary())","b48b542d":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\nfrom tensorflow.python.keras.optimizers import Adam ,RMSprop\n\ncheckpoint = ModelCheckpoint(\"best_weights.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\n# # CREATE MORE IMAGES VIA DATA AUGMENTATION\ndatagen = ImageDataGenerator(\n        rotation_range= 8,  \n        zoom_range = 0.13,  \n        width_shift_range=0.13, \n        height_shift_range=0.13)\n\nepochs = 60\nlr_initial = 0.0011\n# optimizer = RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0)\noptimizer = Adam(lr=lr_initial, decay= lr_initial \/ (epochs*1.3))\n\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\ndatagen.fit(x_train)\nbatch_size = 64\n\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size, callbacks=[checkpoint])\nmodel.load_weights(\"best_weights.hdf5\") \n","b2f9c55a":"plt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()\n\n","b6c5cf81":"# predicted class\nnum_rows = 6\nnum_cols = 15\nsample_size = num_rows * num_cols\nindices = np.arange(sample_size)\nx_pred = x_test[indices,:,:]\npredictions = model.predict(x_pred)\nx_pred = np.squeeze(x_test[indices,:,:])\ny_pred = np.argmax(predictions,axis=1)\n\nnum_images = num_rows*num_cols\nplt.figure(figsize=(num_cols*2, num_rows*2))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.6)\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plt.imshow(x_pred[i])\n  plt.title(classes[y_pred[i]])\n  # plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  # plot_value_array(i, predictions, test_labels)\nplt.show()","a2e0e77e":"from sklearn.metrics import confusion_matrix\n\ny_vecs = model.predict(x_val)\ny_pred = np.argmax(y_vecs, axis=1)\ny_true = y_val\ncm = confusion_matrix(y_true, y_pred)\n# print(cm)\n\n# plt.imshow(cm, cmap = 'ocean')\n# plt.colorbar\n\nmin_val, max_val = 0, 15\n\n# intersection_matrix = np.random.randint(0, 10, size=(max_val, max_val))\nplt.figure(11)\nfig, ax = plt.subplots()\nax.matshow(cm, cmap=plt.cm.Blues)\n# ax.matshow(cm, cmap=plt.cm.magma_r)\n\nfor i in range(10):\n    for j in range(10):\n        c = cm[j,i]\n        ax.text(i, j, str(c), va='center', ha='center')\n\n\nplt.xticks(range(10))\nplt.yticks(range(10))\nplt.title('Confusion matrix',size = 28)\nplt.xlabel('True labeling',size = 20)\nplt.ylabel('Predicted labeling',size = 20)\nplt.rcParams.update({'font.size': 22})\n\n","d81ce159":"# Display some error results \n# y_vecs = model.predict(x_test)\n# y_pred = np.argmax(y_vecs, axis=1)\nY_true = y_val\nY_pred_classes =  y_pred\nY_pred = y_vecs\nX_val = x_val\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 2\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=1)\n    plt.figure(figsize=(num_cols, num_rows))\n\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted  :{}\\nTrue  :{}\".format(pred_errors[error],obs_errors[error]), fontsize=14)\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-25:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","d7ef433d":"# predict results\nresults = model.predict(x_test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"MNIST-CNN-ENSEMBLE.csv\",index=False)","1fb6147d":"# model.save('gdrive\/My Drive\/DL-ML\/mnist\/2203 995 percent.h5')","454d25ad":"### Adding dimensions for keras","84727ea2":"## 3. Defining the architecture\n\n### Option 1:\nLight architecture with approximately 50K parameters. \n<br>Dropout for avoiding overfitting\n<br>BatchNormalization for faster convergence time","f85157ee":"## 1. Starting with Kaggle - importing data \n\nImportant: Switch settings to GPU","32e9684b":"## 2. Visualize some examples from the dataset.\nShowing some example per class","56dacd47":"## Save model","dc8256ae":"### 5.3 Confusion matrix\n","2d5ccec0":"### 5.4 Miss-labeled data visualization","51d74311":"## 4. Train the model using data augmentation","60fd7149":"### 5.2 Prediction images visualization\nStright forward taking some images and plotting predictions","d2ec3e81":"## 6. Submission","a3d675ab":"### 5.1 Loss graph visualizations","5213aa6f":"### 5. After train visualizations","2ee58475":"### Importing libraries","d2bed3bd":"# Introduction to Computer Vision: MNIST Challenge\nHi!\n\n3 Upvotes for silver, any upvote will be helpeful!\n__________________________\n\nThis is my first project on Kaggle and is done mainly for myself, I am sharing it as it might be useful for others. If you have any suggestions or remarks i would be glad to hear. \nSome sections were taken from cs231n homework, and various tutorials\/kernels on-line.\n<br> Based on this kernel I built an heavier model to maximize my score, I managed to score 99.971, top 9% - https:\/\/www.kaggle.com\/shaygu\/mnist-using-keras-improving-accuracy-13-99-96\nTo achieve said score I made a net with more parameters and optimized other parameters around it. I've also tried to implement model ensambling but it didnt improve the result. I suspect the reason is that that there isnt enough variance between my models. \n<brr> I've checked my model on the more challenging fashion mnist (further explained at https:\/\/github.com\/zalandoresearch\/fashion-mnist ), you can check my kernel: https:\/\/www.kaggle.com\/shaygu\/fashion-mnist-keras-cnn-94-99-71-on-mnist\n\n\n### Table of interest:\n> ### 1. Starting with Kaggle - importing data \n> ### 2. Visualize some examples from the dataset.\n> ### 3. Defining the architecture\n> ### 4. Train the model using data augmentation\n> ### 5. After train visualizations\n> > #### 5.1 Loss graph visualizations\n> > #### 5.2 Prediction images visualization\n> > #### 5.3 Confusion matrix\n> > #### 5.4 Miss-labeled data visualization\n> ### 6. Submission\n\n#### Author: Shay Guterman, Hebrew University of Jerusalem: shaygu62@gmail.com\n","509bd542":"### Importing the data the data"}}