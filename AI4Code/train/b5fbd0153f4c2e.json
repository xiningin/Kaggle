{"cell_type":{"a5fa16eb":"code","9048a17f":"code","7a8d765a":"code","57a26abc":"code","820321f8":"code","4cb42a71":"code","696167cd":"code","722b4b58":"code","a19d6199":"code","8031710f":"code","1c20520b":"code","04aafaca":"code","d9a73231":"code","b088671c":"code","6f6c89b7":"code","190bd858":"code","d6de3c32":"code","ba27edec":"code","ea1a185e":"code","56722ffe":"code","5d176ced":"code","7768b3ec":"code","bf455bbd":"code","7e151886":"code","9516ef4d":"code","2a1ec04b":"code","e1239279":"code","6ab1ea4c":"code","2f640fcf":"code","5ef194cf":"code","71304357":"code","6b2e09ff":"code","692caf51":"code","1e025310":"code","69ef8e2f":"code","086a6ef3":"code","f245ffcc":"code","4f187229":"markdown","58f49f36":"markdown"},"source":{"a5fa16eb":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","9048a17f":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7a8d765a":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","57a26abc":"df1 = pd.read_csv('\/kaggle\/input\/X_data.csv', delimiter=',')","820321f8":"def analiseData(dfAnalisado, describe=False, desc='EDA', variables=[0]):\n    print(desc)\n    if describe:\n        if variables[0]:\n            dfAnalisado = dfAnalisado[variables]\n        print(f'\\nShape:\\n{dfAnalisado.shape}')\n        print(f'\\nHead:\\n{dfAnalisado.head()}')\n        print(f'\\nSample:\\n{dfAnalisado.sample(5)}')\n        print(f'\\nTail:\\n{dfAnalisado.tail()}')\n        print(f'\\nDescribe:\\n{dfAnalisado.describe()}')\n        print(f'\\nIs Null:\\n{dfAnalisado.isnull().sum()}')\n        print(dfAnalisado.info())\n         \n    else:\n        print(f'\\nSamples: \\n',dfAnalisado.sample(10))\n    print(len(dfAnalisado), ' rows')","4cb42a71":"analiseData(df1, desc='EDA only 10 samples')","696167cd":"analiseData(df1, describe=True, desc='Retinopath EDA complete')","722b4b58":"analiseData(df1, describe=True, desc='Retinopath EDA only variables', \n            variables=['Systolic_BP','Diastolic_BP'])","a19d6199":"idealbp = df1[(df1.Systolic_BP.between(89.5,120.5)) & (df1.Diastolic_BP.between(59.5, 80.5))]\nhbp = df1[(df1.Systolic_BP > 139.5) & (df1.Diastolic_BP > 89.5)]\nlbp = df1[(df1.Systolic_BP < 89.5) & (df1.Diastolic_BP < 59.6)]","8031710f":"print('BP ideal: ', len(idealbp), 'registers')\nprint('BP high: ', len(hbp), 'registers')\nprint('BP low: ', len(lbp))","1c20520b":"df1.sample(5)","04aafaca":"analiseData(df1, describe=True, desc='Retinopath EDA only variables', \n            variables=['Cholesterol'])","d9a73231":"plotScatterMatrix(df1, 12, 10)","b088671c":"plotScatterMatrix(idealbp, 12, 10)","6f6c89b7":"df2 = pd.read_csv('\/kaggle\/input\/y_data.csv', delimiter=',')","190bd858":"analiseData(df2, describe=True)","d6de3c32":"from tabulate import tabulate\nimport seaborn as sns, matplotlib.pyplot as plt\nimport warnings\n# ML Algoritmos\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.dummy import DummyRegressor\n\n# ML selecao de dados de treino e teste\nfrom sklearn.model_selection import train_test_split\n# calcular o menor erro medio absoluto entre 2 dados apresentados\nfrom sklearn.metrics import mean_absolute_error\nwarnings.filterwarnings('ignore')","ba27edec":"# choosing best model\ndef melhorModelo(mlData, mlAlgoritmo, varFeatures, varTarget, exibe=False, exibeGrafico=False):\n\n    print(f'\\n\\nAnalizing Regressors ML')\n\n    X = mlData[varFeatures]\n    y = mlData[varTarget]\n\n    Xtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.3, random_state=123)\n\n    # applying regressors\n    reg = []\n    mae = []\n    sco = []\n\n    for regressor in mlAlgoritmo:\n        modelo = regressor\n\n        # training model\n        try:\n            modelo.fit(Xtreino, ytreino)\n            sco.append(modelo.score(Xtreino, ytreino))\n            previsao = modelo.predict(Xteste)\n            mae.append(round(mean_absolute_error(yteste, previsao), 2))\n            reg.append(regressor)\n        except:\n            pass\n\n    meuMae = pd.DataFrame(columns=['Regressor', 'mae', 'score'])\n    meuMae['Regressor'] = reg\n    meuMae['mae'] = mae\n    meuMae['score'] = sco\n    meuMae = meuMae.sort_values(by='mae', ascending=True)\n    if exibe:\n        print(tabulate(meuMae, headers='keys', tablefmt='psql'))\n\n    if exibeGrafico:\n        try:\n            resultado = meuMae.values[0][0].predict(Xteste)\n            ax1 = plt.subplot(322)\n            ax1.set_title('Distribution Prices')\n            sns.distplot(resultado)\n            ax2 = plt.subplot(321)\n            ax2.set_title('Results - Prices')\n            sns.boxplot(resultado)\n        \n\n            ax3 = plt.subplot(312)\n            ax3.set_title('Performance - Regressors ML')\n            g = sns.barplot(x=meuMae['Regressor'], y=meuMae['mae'])\n            g.set_xticklabels(ax3.get_xticklabels(), rotation=30)\n\n            ax4 = plt.subplot(312)\n            ax4.set_title('Performance - Score - Regressors')\n            g = sns.barplot(x=meuMae['Regressor'], y=meuMae['score'])\n            g.set_xticklabels(ax4.get_xticklabels(), rotation=30)\n            plt.show()\n        except:\n            pass\n\n    return meuMae\n","ea1a185e":"# regressor used\ndef mlAlgoritmos():\n    regressores = [\n        DecisionTreeRegressor(),\n        RandomForestRegressor(),\n        SVR(),\n        LinearRegression(),\n        GradientBoostingRegressor(),\n        PoissonRegressor(),\n        DummyRegressor(),\n        LogisticRegression(),\n        GaussianNB()\n    ]\n    return regressores","56722ffe":"df = df1.copy()\ndf['y'] = df2.y\ndf.sample(5)","5d176ced":"def viewGraph(dataset):\n    g = sns.FacetGrid(dataset, col=\"y\")\n    g.map(plt.scatter, \"Age\", \"Cholesterol\", alpha=.7)\n    g.add_legend();\n    g = sns.FacetGrid(dataset, hue=\"y\", palette='Set1', height=5)\n    g.map(plt.scatter, \"Age\", \"Cholesterol\", s=50, alpha=.7, linewidth=.5, edgecolor=\"white\")\n    g.add_legend();","7768b3ec":"viewGraph(df)","bf455bbd":"def correlacao(df, varT, xpoint=-0.5, showGraph=True):\n    corr = df.corr()\n    print(f'\\nFeatures correlation:\\n'\n          f'Target: {varT}\\n'\n          f'Reference.: {xpoint}\\n'\n          f'\\nMain features:')\n    if showGraph:\n        sns.heatmap(corr,\n                    annot=True, fmt='.2f', vmin=-1, vmax=1, linewidth=0.01,\n                    linecolor='black', cmap='RdBu_r'\n                    )\n        plt.title('Correlations between features w\/ target')\n        plt.show()\n\n    corrs = corr[varT]\n    features = []\n    for i in range(0, len(corrs)):\n        if corrs[i] > xpoint and corrs.index[i] != varT:\n            print(corrs.index[i], f'{corrs[i]:.2f}')\n            features.append(corrs.index[i])\n    return features","7e151886":"varT = 'y'\nvarF = correlacao(df, varT, xpoint=0.3, showGraph=True)","9516ef4d":"def removeOutliers(out, varTarget):\n    print('\\nRemovendo Outliers')\n    cidgrp = out[varTarget]\n\n    # criando quantis\n    qtl1 = cidgrp.quantile(.25)  # exiba o valor da variavel\n    qtl3 = cidgrp.quantile(.75)\n\n    # calculando a diferenca entre os dois quantis, conhecido como interquartile range\n    iqr = qtl3 - qtl1\n    # print(qtl1, qtl3, iqr)\n\n    # gerando os limites\n    baixo = qtl1 - 1.5 * iqr\n    alto = qtl3 + 1.5 * iqr\n\n    # remover os outliers\n    novodf = pd.DataFrame()\n\n    limites = out[varTarget].between(left=baixo, right=alto, inclusive=True)\n    novodf = pd.concat([novodf, out[limites]])\n\n    print('Done')\n\n    return novodf.copy()","2a1ec04b":"df = removeOutliers(df, varT)","e1239279":"viewGraph(df)","6ab1ea4c":"bestML = melhorModelo(mlData=df, mlAlgoritmo=mlAlgoritmos(),\n                               varTarget=varT, varFeatures=varF,\n                               exibe=True, exibeGrafico=False)","2f640fcf":"bestML['Regressor'][0]","5ef194cf":"def previsao(dfEscolhida, mlAlgoritmo, varFeatures, valueFeatures, varTarget, desc=''):\n\n    x = dfEscolhida[varFeatures]\n    y = dfEscolhida[varTarget]\n\n    modelo = mlAlgoritmo\n    modelo.fit(x, y)\n\n    previsao = float(modelo.predict([valueFeatures]))\n    cond = ''\n\n    print(f'Summary:\\n'\n          f'Regs analyzed: {len(dfEscolhida)}\\n'\n          f'ML applied: {mlAlgoritmo}\\n'\n          f'Features analyzed:')\n    for i in range(0, len(varFeatures)):\n        print(f' - {varFeatures[i]}: {valueFeatures[i]}')\n        cond += f\" and `{varFeatures[i]}` == {valueFeatures[i]}\"\n        \n    if previsao:\n        descPrev = 'Positive'\n    else:\n        descPrev = 'Negative'\n    \n    print(f\"Predicted value: {previsao} [{descPrev}] \\n\")\n\n   ","71304357":"df.sample(1)\nidealbp","6b2e09ff":"# example creating condition\n# features name\nvarFeaturesFilters = ['Age', 'Systolic_BP', 'Diastolic_BP', 'Cholesterol']\n# features values \nvalueFeaturesFilters = [49.93829, 109.893662, 90.019716, 106.02519]","692caf51":"previsao(dfEscolhida=df, mlAlgoritmo=bestML['Regressor'][0],\n         varFeatures=varFeaturesFilters,\n         valueFeatures=valueFeaturesFilters, varTarget=varT,\n         desc='\\nPredicting price')","1e025310":"varFeaturesFilters = ['Age', 'Systolic_BP', 'Diastolic_BP', 'Cholesterol']\n# features values \nvalueFeaturesFilters = [54, 90, 75, 108]","69ef8e2f":"previsao(dfEscolhida=df, mlAlgoritmo=bestML['Regressor'][0],\n         varFeatures=varFeaturesFilters,\n         valueFeatures=valueFeaturesFilters, varTarget=varT,\n         desc='\\nPredicting price')","086a6ef3":"varFeaturesFilters = ['Age', 'Cholesterol']\n# features values \nvalueFeaturesFilters = [35, 108]","f245ffcc":"previsao(dfEscolhida=df, mlAlgoritmo=bestML['Regressor'][0],\n         varFeatures=varFeaturesFilters,\n         valueFeatures=valueFeaturesFilters, varTarget=varT,\n         desc='\\nPredicting price')","4f187229":"**SKLearn to predict values**","58f49f36":"**Notice**\n\nhttps:\/\/www.nhs.uk\/common-health-questions\/lifestyle\/what-is-blood-pressure\/#:~:text=For%20example%2C%20if%20your%20blood,be%20140%2F90mmHg%20or%20higher\n\n**As a general guide:**\n* ideal blood pressure is considered to be between 90\/60mmHg and 120\/80mmHg\n* high blood pressure is considered to be 140\/90mmHg or higher\n* low blood pressure is considered to be 90\/60mmHg or lower"}}