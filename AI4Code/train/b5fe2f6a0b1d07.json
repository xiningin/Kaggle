{"cell_type":{"ab5d1ef4":"code","e22fc68c":"code","b099d475":"code","e17fe8db":"code","7ce19fc9":"code","134090d9":"code","d59c961c":"code","9b35fb19":"code","5caf0cdf":"code","a7dcfe88":"code","4ee4b3dc":"code","9cad68f3":"code","d02f37be":"code","b7b564cd":"code","b1b00e74":"code","0539c040":"code","63321b27":"code","3286a20d":"code","f6f3bf93":"code","9c642e14":"code","7b51e0b9":"code","aaccffd5":"code","809e7f5c":"code","f8c25842":"code","ed091772":"code","61554aaa":"code","99d62cfc":"markdown","908a905a":"markdown","362d017e":"markdown","55a06274":"markdown","e59fb66f":"markdown","d5363351":"markdown","2012c712":"markdown","7894af2b":"markdown","b15cac80":"markdown","04e3c714":"markdown","2dde11d9":"markdown","9ee6e1fd":"markdown","0dcb9ad3":"markdown","9c1bc524":"markdown","3848b01e":"markdown","b5cc16fa":"markdown","608373b7":"markdown","ae299b90":"markdown","f5843dea":"markdown","157016e4":"markdown"},"source":{"ab5d1ef4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e22fc68c":"# Importing basic dependencies\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ncolor = sns.color_palette()","b099d475":"import zipfile\n\ndataset_orders = \"orders.csv\"\ndataset_products = 'products.csv'\ndataset_departments = 'departments.csv'\ndataset_aisles = 'aisles.csv'\ndataset_orders_train = \"order_products__train.csv\"\ndataset_orders_prior = \"order_products__prior.csv\"\n\ndirectory = \"..\/input\/instacart-market-basket-analysis\/\"\narchive_orders = zipfile.ZipFile(directory+dataset_orders+\".zip\",\"r\")\narchive_products = zipfile.ZipFile(directory+dataset_products+\".zip\",\"r\")\narchive_departments = zipfile.ZipFile(directory+dataset_departments+\".zip\",\"r\")\narchive_aisles = zipfile.ZipFile(directory+dataset_aisles+\".zip\",\"r\")\narchive_orders_train = zipfile.ZipFile(directory+dataset_orders_train+\".zip\",\"r\")\narchive_orders_prior = zipfile.ZipFile(directory+dataset_orders_prior+\".zip\",\"r\")","e17fe8db":"# Reading files\n\norders_df = pd.read_csv(archive_orders.open('orders.csv'))\nproducts_df = pd.read_csv(archive_products.open('products.csv'))\ndepartments_df = pd.read_csv(archive_departments.open('departments.csv'))\naisles_df = pd.read_csv(archive_aisles.open('aisles.csv'))\norders_train_df = pd.read_csv(archive_orders_train.open('order_products__train.csv'))\norders_prior_df = pd.read_csv(archive_orders_prior.open('order_products__prior.csv'))","7ce19fc9":"# Checking orders df\n\norders_df.head()","134090d9":"orders_df.info()","d59c961c":"orders_df.isnull().sum()","9b35fb19":"# products_df\n\nproducts_df.head()","5caf0cdf":"departments_df.head()","a7dcfe88":"aisles_df.head()","4ee4b3dc":"orders_train_df.head()","9cad68f3":"orders_prior_df.head()","d02f37be":"cnt_srs = orders_df.eval_set.value_counts()\n\nplt.figure(figsize=(12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Eval set type', fontsize=12)\nplt.title('Count of rows in each dataset', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","b7b564cd":"# Let's get unique count of each type\n\ndef get_unique_count(x):\n    return len(np.unique(x))\n\ncnt_srs = orders_df.groupby(\"eval_set\")[\"user_id\"].aggregate(get_unique_count)\ncnt_srs","b1b00e74":"cnt_srs = orders_df.groupby(\"user_id\")[\"order_number\"].aggregate(np.max).reset_index()\ncnt_srs = cnt_srs.order_number.value_counts()\n\nplt.figure(figsize=(12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Maximum order number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","0539c040":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"order_dow\", data=orders_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Day of week', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of order by week day\", fontsize=15)\nplt.show()","63321b27":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"order_hour_of_day\", data=orders_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Hour of day', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of order by hour of day\", fontsize=15)\nplt.show()","3286a20d":"grouped_df = orders_df.groupby([\"order_dow\", \"order_hour_of_day\"])[\"order_number\"].aggregate(\"count\").reset_index()\ngrouped_df = grouped_df.pivot('order_dow', 'order_hour_of_day', 'order_number')\n\nplt.figure(figsize=(12,6))\nsns.heatmap(grouped_df)\nplt.title(\"Frequency of Day of week Vs Hour of day\")\nplt.show()","f6f3bf93":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"days_since_prior_order\", data=orders_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Days since prior order', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency distribution by days since prior order\", fontsize=15)\nplt.show()","9c642e14":"# percentage of re-orders in prior set\norders_prior_df.reordered.sum() \/ orders_prior_df.shape[0]","7b51e0b9":"# percentage of re-orders in train set\n\norders_train_df.reordered.sum() \/ orders_train_df.shape[0]","aaccffd5":"productsCount = orders_train_df[\"product_id\"].value_counts().to_frame()\nproductsCount[\"count\"] = productsCount.product_id\nproductsCount[\"product_id\"] = productsCount.index\nmergedData = pd.merge(productsCount,products_df,how=\"left\",on=\"product_id\").sort_values(by=\"count\",ascending=False)\n\nfig,ax = plt.subplots()\nfig.set_size_inches(25,10)\nsns.barplot(data=mergedData.head(30),x=\"product_name\",y=\"count\",ax=ax,orient=\"v\")\nax.set(xlabel='Product Names',ylabel=\"Count\",title=\"Best Selling Products\")\nplt.xticks(rotation=90)\n\nmergedData.head(10)","809e7f5c":"# Top reordered products\n\nproductsCountReordered = orders_train_df[orders_train_df[\"reordered\"]==1][\"product_id\"].value_counts().to_frame()\nproductsCountReordered[\"reordered_count\"] = productsCountReordered.product_id\nproductsCountReordered[\"product_id\"] = productsCountReordered.index\nproductCountReorderedMerged = pd.merge(productsCount,productsCountReordered,how=\"left\",on=\"product_id\").sort_values(by=\"count\",ascending=False)\nproductCountReorderedMerged[\"reordered_ratio\"] = productCountReorderedMerged[\"reordered_count\"]\/productCountReorderedMerged[\"count\"]\nproductCountReorderedMerged.sort_values(by=\"reordered_ratio\",ascending=False,inplace=True)\nproductMerged = pd.merge(productCountReorderedMerged,products_df,how=\"left\",on=\"product_id\")\n\nfig,ax = plt.subplots()\nfig.set_size_inches(25,10)\nsns.barplot(data=productMerged[productMerged[\"count\"]>40].head(30),x=\"product_name\",y=\"reordered_ratio\",ax=ax,orient=\"v\")\nax.set(xlabel='Product Names',ylabel=\"Count\",title=\"Top Reordered Products\")\nax.set_ylim(0.85,.95)\nplt.xticks(rotation=90)\n\nproductMerged.head(10)","f8c25842":"order_products_prior_df = pd.merge(orders_prior_df, products_df, on='product_id', how='left')\norder_products_prior_df = pd.merge(order_products_prior_df, aisles_df, on='aisle_id', how='left')\norder_products_prior_df = pd.merge(order_products_prior_df, departments_df, on='department_id', how='left')\norder_products_prior_df.head()","ed091772":"grouped_df = order_products_prior_df.groupby([\"department\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n\nplt.figure(figsize=(12,8))\nsns.pointplot(grouped_df['department'].values, grouped_df['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder ratio', fontsize=12)\nplt.xlabel('Department', fontsize=12)\nplt.title(\"Department wise reorder ratio\", fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","61554aaa":"order_products_prior_df[\"add_to_cart_order_mod\"] = order_products_prior_df[\"add_to_cart_order\"].copy()\norder_products_prior_df[\"add_to_cart_order_mod\"].loc[order_products_prior_df[\"add_to_cart_order_mod\"]>70] = 70\ngrouped_df = order_products_prior_df.groupby([\"add_to_cart_order_mod\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n\nplt.figure(figsize=(12,8))\nsns.pointplot(grouped_df['add_to_cart_order_mod'].values, grouped_df['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder ratio', fontsize=12)\nplt.xlabel('Add to cart order', fontsize=12)\nplt.title(\"Add to cart order - Reorder ratio\", fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","99d62cfc":"So there are no orders less than 4 and is max capped at 100 as given in the data page.\n\nNow let us see how the ordering habit changes with day of week.","908a905a":"So majority of the orders are made during day time. Now let us combine the day of week and hour of day to see the distribution.","362d017e":"Dairy eggs has highest reorder ratio while personal care has lowest","55a06274":"That is, 206209 are total customers given out of which 131209 customers are given as train set and we need to predict on 75k customers.","e59fb66f":"Let's merge products, department & aisles together","d5363351":"# Department wise reorder ratio","2012c712":"**Most Ordered Product**","7894af2b":"orders: This table includes all orders, namely prior, train, and test. It has single primary key (order_id).\n\norder_products_train: This table includes training orders. It has a composite primary key (order_id and product_id) and indicates whether a product in an order is a reorder or not (through the reordered variable).\n\norder_products_prior : This table includes prior orders. It has a composite primary key (order_id and product_id) and indicates whether a product in an order is a reorder or not (through the reordered variable).\n\nproducts: This table includes all products. It has a single primary key (product_id)\n\naisles: This table includes all aisles. It has a single primary key (aisle_id)\n\ndepartments: This table includes all departments. It has a single primary key (department_id)","b15cac80":"As we could see, orders.csv has all the information about the given order id like the user who has purchased the order, when was it purchased, days since prior order and so on.\n\nThe columns present in order_products_train and order_products_prior are same. Then what is the difference between these files.?\n\nAs mentioned earlier, in this dataset, 4 to 100 orders of a customer are given (we will look at this later) and we need to predict the products that will be re-ordered. So the last order of the user has been taken out and divided into train and test sets. All the prior order informations of the customer are present in order_products_prior file. We can also note that there is a column in orders.csv file called eval_set which tells us as to which of the three datasets (prior, train or test) the given row goes to.\n","04e3c714":"### Add to cart - Reorder ratio","2dde11d9":"Each user has purchased various products during their prior orders. Moreover, for each user we know the order_id of their future order. The goal is to predict which of these products will be in a user's future order. This is a classification problem because we need to predict whether each pair of user and product is a reorder or not. This is indicated by the value of the reordered variable, i.e. reordered=1 or reordered=0 (see figure below).\n\n![image.png](attachment:6a72b582-5c34-42a7-8b81-dd5725980b7b.png)","9ee6e1fd":"As a result we need to come up and calculate various predictor variables (X) that will describe the characteristics of a product and the behaviour of a user regarding one or multiple products. We will do so by analysing the prior orders of the dataset. We will then use the train users to create a predictive model and the test users to make our actual prediction. As a result we create a table as the following one and we train an algorithm based on predictor variables (X) and response variable (Y).\n\n![image.png](attachment:4ead94c2-9338-4515-b3c7-f670fcfd3a6a.png)","0dcb9ad3":"Seems Satuday evenings and Sunday mornings are the prime time for orders.\n\nNow let us check the time interval between the orders.","9c1bc524":"Looks like customers order once in every week (check the peak at 7 days) or once in a month (peak at 30 days). We could also see smaller peaks at 14, 21 and 28 days (weekly intervals).\n\nSince our objective is to figure out the re-orders, let us check out the re-order percentage in prior set and train set","3848b01e":"Seems like 0 and 1 is Saturday and Sunday when the orders are high and low during Wednesday.\n\nNow we shall see how the distribution is with respect to time of the day.","b5cc16fa":"## Introduction\n\nInstacart is an American company that operates as a same-day grocery delivery service. Customers select groceries through a web application from various retailers and delivered by a personal shopper. Instacart's service is mainly provided through a smartphone app, available on iOS and Android platforms, apart from its website.\n\nIn 2017 Instacart organised a Kaggle competition and provided to the community a sample of over 3 million grocery orders from more than 200,000 Instacart users. The orders include 32 million basket items and 50,000 unique products. The objective of the competition was to predict which previously purchased products will be in a user\u2019s next order.","608373b7":"On an average, about 59% of the products in an order are re-ordered products.","ae299b90":"## Problem Definition\n\nThe data that Instacart opened up include orders of 200,000 Instacart users with each user having between 4 and 100 orders. Instacart indicates each order in the data as prior, train or test. Prior orders describe the past behaviour of a user while train and test orders regard the future behaviour that we need to predict. As a result, we want to predict which previously purchased products (prior orders) will be in a user\u2019s next order (train and test orders). For the train orders Instacart reveals the results (i.e. the ordered products) while for the test orders we do not have this piece of information. Moreover, the future order of each user can be either train or test meaning that each user will be either a train or a test user. The setting of the Instacart problem is described in the figure below.\n\n\n![image.png](attachment:96e83184-aa2e-4c98-87a3-3f0e7c82ec79.png)","f5843dea":"**Looks like the products that are added to the cart initially are more likely to be reordered again compared to the ones added later and this is quite reasonable as well**","157016e4":"Now let us validate the claim that 4 to 100 orders of a customer are given."}}