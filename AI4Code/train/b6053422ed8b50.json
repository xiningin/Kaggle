{"cell_type":{"ef45fc6b":"code","c1adac75":"code","6e45fe25":"code","b63571d3":"code","aa64a9d0":"code","a6fbd14a":"code","2515911d":"code","28b226df":"code","dc8d1c4b":"code","e81d1670":"code","4b3b6030":"code","d9a87b13":"code","85fc3c18":"code","1a770a42":"code","5d95b644":"code","e7e23186":"code","96047a57":"code","59703d71":"code","17d70919":"code","3350a253":"code","05d77ab7":"code","85d677d0":"markdown","dcbb7bbe":"markdown","e8aedc73":"markdown","f6221a94":"markdown","3bde715c":"markdown","0c1d94e1":"markdown","6970cee3":"markdown","b86a25fd":"markdown","6915faf6":"markdown","84d66cb8":"markdown","78c511c8":"markdown","a89ba095":"markdown"},"source":{"ef45fc6b":"import numpy as np\nimport pandas as pd","c1adac75":"train=pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest=pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","6e45fe25":"y_train=train['label']\ny_test=test['label']\ndel train['label']\ndel test['label']","b63571d3":"x_train=train.values\nx_test=test.values","aa64a9d0":"x_train.shape","a6fbd14a":"x_test.shape","2515911d":"x_train=x_train.reshape(-1,28,28,1)\nx_test=x_test.reshape(-1,28,28,1)","28b226df":"import matplotlib.pyplot as plt\nplt.imshow(x_train[0][:,:,0])\nplt.title(y_train[0])\nplt.show()","dc8d1c4b":"import seaborn as sns","e81d1670":"g = sns.countplot(y_train)\n\ny_train.value_counts()","4b3b6030":"y_train.shape","d9a87b13":"from tensorflow.keras.utils import to_categorical\ny_train=to_categorical(y_train, num_classes=10)\ny_test=to_categorical(y_test, num_classes=10)\nprint(y_train[0])","85fc3c18":"x_train=x_train\/255\nx_test=x_test\/255","1a770a42":"import tensorflow as tf\nimport keras\nfrom keras import backend as K","5d95b644":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","e7e23186":"model=Sequential()\nmodel.add(Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)))\n#model.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3), activation='relu'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(128,(3,3), activation='relu'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n","96047a57":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","59703d71":"import keras.utils\ntf.keras.utils.plot_model(model, show_shapes=True)","17d70919":"epochs=50\nbatch_size=600\nhistory = model.fit(x_train, y_train,\n                              epochs = epochs, verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size, validation_split=0.2)","3350a253":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()","05d77ab7":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Loss on test data\",score[0])\nprint(\"Accuracy on test data\", score[1]*100)","85d677d0":"# Training the model","dcbb7bbe":"Splitting dataset into x_train, y_train, x_test and y_test","e8aedc73":"# Creating model.","f6221a94":"# Converting y(labels) into one hot vectors\nUsing tensorflow.keras.utils.to_categorical() to convert y_train and y_test to onehot vectors.","3bde715c":"Importing numpy and pandas.","0c1d94e1":"Normalisation of the inputs. Dividing by 255 makes values of all pixels between 0 and 1.","6970cee3":"# Loading the datasets.","b86a25fd":"# Reshaping the images.\n28x28 pixel images from 784 columns","6915faf6":"Checking whether datast is balanced or not, we have 60000 images in train set from 10 classes and each class has 6000 images.","84d66cb8":"# Hello and welcome\n\nIn this notebook you will get an example on how to create a CNN model using keras and tensorflow in backend. Dataset used is fashion mnist.","78c511c8":"Ploting the model for better understanding.","a89ba095":"# Results\nModel gives an accuracy of 93.93% when used on the given test set."}}