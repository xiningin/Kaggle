{"cell_type":{"8d92c8d0":"code","5a69aa51":"code","16d0d30a":"code","9f9224f9":"code","89c819c5":"code","cfa3920f":"code","a8e02ce3":"code","9e55d9bd":"code","1c44d3dd":"code","72ba447b":"code","f1b7e763":"code","75e095f5":"code","621f5c1d":"code","98b1755e":"code","86c8bfda":"code","280e8dc7":"code","75260658":"code","2ded64a7":"code","ca4b90bb":"code","51a89b85":"code","1d935dea":"code","a9bdd775":"code","3c950ef5":"code","7e01ea8c":"code","1e54ed7d":"code","1fa8babb":"code","1fe21193":"code","fc8be1d0":"code","a254aaed":"code","f0aca5c3":"code","4b42ffad":"code","1930131d":"code","2df4480e":"code","950dd3e1":"code","8383f3b9":"code","8d0786b5":"code","dfc689a3":"code","e961ecd9":"code","2fe83cf0":"code","3f7d68f9":"code","2e4df4c0":"code","db6c26b0":"code","1fa26772":"code","a87678ae":"code","a5f8a726":"code","223b6c23":"code","19fdeaee":"code","743eeb0f":"code","9aa05550":"code","b287dc42":"code","f76ffbfe":"code","b7934f52":"code","d46a0c92":"code","0f2547e2":"code","9ff57101":"code","40482a06":"code","0f2eade5":"code","553b7f90":"code","637c0b07":"code","032ffef6":"code","fcfdfeb6":"code","ad4d1421":"code","70adfcad":"code","ae6cf975":"code","d283d5c4":"code","319b0114":"code","e5ecf428":"code","33000590":"code","bcd9f63a":"code","14f3232b":"code","c723f855":"code","461997d4":"code","d5506b85":"markdown","f257c5ea":"markdown","c5a1ae45":"markdown","03283602":"markdown","ba1566f2":"markdown","b83b7d6d":"markdown","1dcb3c52":"markdown","5df1c8d5":"markdown","92c6c344":"markdown","7a1ced3d":"markdown","4669b7e5":"markdown","f486bf51":"markdown","442d904a":"markdown","b46fcd77":"markdown","6e67be99":"markdown","dd700902":"markdown","57d07541":"markdown","f101fd15":"markdown","ae02c24e":"markdown","63c34d9f":"markdown","24724948":"markdown","64e7a081":"markdown","1cb64f57":"markdown","65ac3663":"markdown","7c146192":"markdown","011442f7":"markdown","0b0d2988":"markdown","8bb9e0f1":"markdown","2ec2061b":"markdown","f36a3c3d":"markdown","ca04bfc0":"markdown","1ceb737b":"markdown","8713d1d5":"markdown","badd4007":"markdown"},"source":{"8d92c8d0":"import warnings # Ignoreing all the warning\nwarnings.filterwarnings(\"ignore\")","5a69aa51":"# Loading all the library\nimport os\nimport numpy\nimport pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import NearestNeighbors\nimport matplotlib.pyplot as pyplot\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, confusion_matrix,precision_score,recall_score\n%matplotlib inline","16d0d30a":"file_list = os.listdir('..\/input')\nfile_list[0]\nData = pd.read_csv(r'..\/input\/'+file_list[0])\nData.columns # # column Name of Data","9f9224f9":"Data.head(10)","89c819c5":"Data['target'].value_counts() # Get the value_counts for Heart Diseases class and not Heart Diseases ","cfa3920f":"class_dist_df = pd.DataFrame(Data['target'].value_counts()).reset_index(drop=True)# Reseting the index and get the counts for each class \nclass_dist_df['class']= ['HD','WHD'] # HD Means Heart diseases and WHD means NO diseases\nsns.barplot(y = 'target', x = class_dist_df['class'], data=class_dist_df) # Plotting Class frequency vs Class\npyplot.title('Class Frequency Vs Class Name')\npyplot.show()","a8e02ce3":"DF_HD = Data[Data['target']==1] # Dataframe of Heart diseases\nDF_WHD = Data[Data['target']==0] # Dataframe of Without Heart diseases","9e55d9bd":"DF_HD.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']\nDF_WHD.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']","1c44d3dd":"DF_WHD['age'].describe() #This will output the basic statsitics of age in population","72ba447b":"# Hist of Age\nDF =DF_HD.append(DF_WHD) \npd.crosstab(DF['age'],DF['target']).plot(kind=\"bar\",figsize=(20,6))\npyplot.title('Heart Disease Frequency for Ages')\npyplot.xlabel('Age')\npyplot.ylabel('Frequency')\npyplot.savefig('heartDiseaseAndAges.png')\npyplot.show()","f1b7e763":"print ('male count with the heart dieases ='), DF_HD[DF_HD['sex']==1]['sex'].value_counts() # 1 means Male in Sex Column","75e095f5":"print ('male count without the heart dieases ='), DF_WHD[DF_WHD['sex']==1]['sex'].count() # 0 means Female in Sex column","621f5c1d":"print ('Female count with the heart dieases ='), len(DF_HD[DF_HD['sex']==0]['sex'])","98b1755e":"print ('Female count without the heart dieases ='), len(DF_WHD[DF_WHD['sex']==0]['sex'])","86c8bfda":"Gender_HD = pd.DataFrame(DF_HD['sex'].value_counts()).reset_index() # Value counts for sex with Heart diseases\nGender_WHD = pd.DataFrame(DF_WHD['sex'].value_counts()).reset_index() # Value counts for sex with withot Heart diseases\nGender_HD['class'] = \"HD\"\nGender_WHD['class'] = \"WHD\"\nGender_HD['index'] =['Male','Female']\nGender_WHD['index'] =['Male','Female']\nGender_DF = Gender_HD.append(Gender_WHD)\nGender_DF.columns = ['Category','Gender_count','class']\nsns.barplot(y='Gender_count', x='Category', data=Gender_DF, hue='class')\npyplot.title('Gender Frequency vs Gender_Name')\npyplot.show()","280e8dc7":"print ('male age with heart dieases ='), DF_HD[DF_HD['sex']==1]['age'].describe()\nprint ('male age without heart dieases ='), DF_WHD[DF_WHD['sex']==1]['age'].describe()\nprint ('Female age without heart dieases ='), DF_WHD[DF_WHD['sex']==0]['age'].describe()\nprint ('Female age without heart dieases ='), DF_HD[DF_HD['sex']==0]['age'].describe()","75260658":"DF_HD['cp'].value_counts() # Get value counts for each class ","2ded64a7":"DF_WHD['cp'].value_counts() # Get value counts for each class ","ca4b90bb":"cp_dist_df = pd.DataFrame(DF_HD['cp'].value_counts()).reset_index() # Value counts for CP with Heart diseases\ncp_dist_Wdf = pd.DataFrame(DF_WHD['cp'].value_counts()).reset_index()# Value counts for CP without Heart diseases\ncp_dist_df['class'] = \"HD\"\ncp_dist_Wdf['class'] = \"WHD\"\ncp_dist_df_copy = cp_dist_df.copy()\ncp_dist_df_copy = cp_dist_df_copy.append(cp_dist_Wdf)\ncp_dist_df_copy.columns = [u'index', u'cp_frequency', u'class']\nsns.barplot(y='cp_frequency', x='index', data=cp_dist_df_copy, hue='class')\npyplot.show()","51a89b85":"DF_HD['trestbps'].describe() # Basic statsitics for trestbps for Heart Diseases cases","1d935dea":"DF_WHD['trestbps'].describe() # Basic statsitics for trestbps for without Heart Diseases cases","a9bdd775":"pyplot.plot(DF[DF['target']==0]['trestbps'].values,'ro',label='WHD') # Heart Diseases cases vs trestbps\npyplot.plot(DF[DF['target']!=0]['trestbps'].values,'bo',label='HD') # Without Heart Diseases cases vs trestbps\npyplot.xlabel('Index')\npyplot.ylabel('trestbps')\npyplot.title('Heart_disease VS trestbps')\npyplot.legend()\npyplot.show()","3c950ef5":"# Plot between age vs trestbps\npyplot.plot(DF_WHD['age'],DF_WHD['trestbps'],'bo')\npyplot.plot(DF_HD['age'],DF_HD['trestbps'],'ro')\npyplot.title('age VS trestbps')\npyplot.ylabel('age')\npyplot.xlabel('trestbps')\npyplot.show()","7e01ea8c":"DF_HD['chol'].describe()# Basic statsitics for chol for Heart Diseases cases","1e54ed7d":"DF_WHD['chol'].describe() # Basic statsitics for chol for without Heart Diseases cases","1fa8babb":"# Plot of target variable with chol level\npyplot.plot(DF[DF['target']==0]['chol'].values,'ro',label='WHD')\npyplot.plot(DF[DF['target']!=0]['chol'].values,'bo',label='HD')\npyplot.xlabel('Dummy_Index')\npyplot.ylabel('Chol_values')\npyplot.title('Heart_dieases VS Chol')\npyplot.legend()\npyplot.show()","1fe21193":"# Plot of age value with chol level\npyplot.plot(DF_WHD['age'],DF_WHD['chol'],'bo',label='WHD')\npyplot.plot(DF_HD['age'],DF_HD['chol'],'ro',label='HD')\npyplot.title('age VS chol')\npyplot.ylabel('age')\npyplot.xlabel('chol')\npyplot.legend()\npyplot.show()","fc8be1d0":"DF_HD['fbs'].value_counts() # Value counts for categorical data (FBS) for heart disease","a254aaed":"DF_WHD['fbs'].value_counts() # Value counts for categorical data (FBS) for without heart disease","f0aca5c3":"fbs_dist_df = pd.DataFrame(DF_HD['fbs'].value_counts()).reset_index()\nfbs_dist_Wdf = pd.DataFrame(DF_WHD['fbs'].value_counts()).reset_index()\nfbs_dist_df['class'] = \"HD\"\nfbs_dist_Wdf['class'] = \"WHD\"\nfbs_dist_df_copy = fbs_dist_df.copy()\nfbs_dist_df_copy = fbs_dist_df_copy.append(fbs_dist_Wdf)\nfbs_dist_df_copy.columns = [u'index', u'fbs_frequency', u'class']\nsns.barplot(y='fbs_frequency', x='index', data=fbs_dist_df_copy, hue='class')\npyplot.title('fbs_frequency vs class ')\npyplot.show()","4b42ffad":"DF_HD['restecg'].value_counts()  # Value counts for categorical data (restecg) for heart disease","1930131d":"DF_WHD['restecg'].value_counts() # Value counts for categorical data (restecg) for without heart disease","2df4480e":"restecg_dist_df = pd.DataFrame(DF_HD['restecg'].value_counts()).reset_index() # value counts for restecg for Heart diseases Cases\nrestecg_dist_Wdf = pd.DataFrame(DF_WHD['restecg'].value_counts()).reset_index()# value counts for restecg for without Heart diseases Cases\nrestecg_dist_df['class'] = \"HD\"\nrestecg_dist_Wdf['class'] = \"WHD\"\nrestecg_dist_df_copy = restecg_dist_df.copy()\nrestecg_dist_df_copy = restecg_dist_df_copy.append(restecg_dist_Wdf)\nrestecg_dist_df_copy.columns = [u'index', u'restecg_frequency', u'class']\nsns.barplot(y='restecg_frequency', x='index', data=restecg_dist_df_copy, hue='class')\npyplot.title('restecg_frequency vs index')\npyplot.show()","950dd3e1":"DF_HD['thalach'].describe() # Basic statstics for thalach for Heart diseases ","8383f3b9":"DF_WHD['thalach'].describe() # Basic statstics for thalach for without Heart diseases ","8d0786b5":"# Plot between target vs thalach\npyplot.plot(DF[DF['target']==0]['thalach'].values,'ro',label='WHD')\npyplot.plot(DF[DF['target']!=0]['thalach'].values,'bo',label='HD')\npyplot.xlabel('Dummy_Index')\npyplot.ylabel('thalach')\npyplot.title('thalach vs Heart_dieases')\npyplot.legend()\npyplot.show()","dfc689a3":"DF_HD['exang'].value_counts()  # Value counts for categorical data (exang) for heart disease","e961ecd9":"DF_WHD['exang'].value_counts() # Value counts for categorical data (exang) for without heart disease","2fe83cf0":"exang_dist_df = pd.DataFrame(DF_HD['exang'].value_counts()).reset_index()\nexang_dist_Wdf = pd.DataFrame(DF_WHD['exang'].value_counts()).reset_index()\nexang_dist_df['class'] = \"HD\"\nexang_dist_Wdf['class'] = \"WHD\"\nexang_dist_df_copy = exang_dist_df.copy()\nexang_dist_df_copy = exang_dist_df_copy.append(exang_dist_Wdf)\nexang_dist_df_copy.columns = ['index','exang_frequency','class']\nsns.barplot(y='exang_frequency', x='index', data=exang_dist_df_copy, hue='class')\npyplot.title('exang_frequency vs index')\npyplot.show()","3f7d68f9":"DF_HD[u'oldpeak'].describe() # Basic statstics for oldpeak for Heart diseases ","2e4df4c0":"DF_WHD[u'oldpeak'].describe() # Basic statstics for oldpeak for without Heart diseases ","db6c26b0":"pyplot.plot(DF[DF['target']==0]['oldpeak'].values,'ro',label='WHD')\npyplot.plot(DF[DF['target']!=0]['oldpeak'].values,'bo',label='HD')\npyplot.xlabel('Dummy_Index')\npyplot.ylabel('oldpeak')\npyplot.title('oldpeak vs Heart_dieases')\npyplot.legend()\npyplot.show()","1fa26772":"DF_WHD[u'slope'].value_counts() # Value counts for categorical data (slope) for heart disease","a87678ae":"DF_HD[u'slope'].value_counts()  # Value counts for categorical data (slope) for without heart disease","a5f8a726":"slope_dist_df = pd.DataFrame(DF_HD['slope'].value_counts()).reset_index()\nslope_dist_Wdf = pd.DataFrame(DF_WHD['slope'].value_counts()).reset_index()\nslope_dist_df['class'] = \"HD\"\nslope_dist_Wdf['class'] = \"WHD\"\nslope_dist_df_copy = slope_dist_df.copy()\nslope_dist_df_copy = slope_dist_df_copy.append(slope_dist_Wdf)\nslope_dist_df_copy.columns = ['index','slope_frequency','class']\nsns.barplot(y='slope_frequency', x='index', data=slope_dist_df_copy, hue='class')\npyplot.show()","223b6c23":"DF_HD['ca'].value_counts() # Value counts for categorical data (ca) for heart disease","19fdeaee":"DF_WHD['ca'].value_counts() # Value counts for categorical data (ca) for without heart disease","743eeb0f":"ca_dist_df = pd.DataFrame(DF_HD['ca'].value_counts()).reset_index()\nca_dist_Wdf = pd.DataFrame(DF_WHD['ca'].value_counts()).reset_index()\nca_dist_df['class'] = \"HD\"\nca_dist_Wdf['class'] = \"WHD\"\nca_dist_df_copy = ca_dist_df.copy()\nca_dist_df_copy = ca_dist_df_copy.append(ca_dist_Wdf)\nca_dist_df_copy.columns =['index','ca_frequency','class']\nsns.barplot(y='ca_frequency', x='index', data=ca_dist_df_copy, hue='class')\npyplot.title('ca_frequency vs index')\npyplot.show()","9aa05550":"DF_HD['thal'].value_counts()# Value counts for categorical data (thal) for heart disease","b287dc42":"DF_WHD['thal'].value_counts()# Value counts for categorical data (thal) for without heart disease","f76ffbfe":"thal_dist_df = pd.DataFrame(DF_HD['thal'].value_counts()).reset_index()\nthal_dist_Wdf = pd.DataFrame(DF_WHD['thal'].value_counts()).reset_index()\nthal_dist_df['class'] = \"HD\"\nthal_dist_Wdf['class'] = \"WHD\"\nthal_dist_df_copy = thal_dist_df.copy()\nthal_dist_df_copy = thal_dist_df_copy.append(thal_dist_Wdf)\nthal_dist_df_copy.columns = ['index','thal_frequency','class']\nsns.barplot(y='thal_frequency', x='index', data=thal_dist_df_copy, hue='class')\npyplot.show()","b7934f52":"Features = ['thal','ca','slope','exang','restecg','trestbps','cp','sex'] # we will choose only these based on above analysis","d46a0c92":"Data[Features].head(5) # Print the prepared Data","0f2547e2":"# This Function will convert categorical data to numerical data and put the data of different category into different column\ndef one_hot_coding(Data,column_name):\n    thal_value = Data[column_name].tolist()\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(thal_value)\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n    new_df = pd.DataFrame(onehot_encoded)\n    new_df = rename_column(new_df,column_name)\n    return new_df","9ff57101":"# This function rename the columns created by above column \ndef rename_column(new_df,column_name):\n    col_list = []\n    for i in range(0,len(new_df.columns)):\n        col_list.append(column_name+'_'+str(i))\n    new_df.columns = col_list\n    return new_df\n        \n","40482a06":"# converting the categorical data to numerical data\nnew_df_thal = one_hot_coding(Data,'thal')\nnew_df_ca = one_hot_coding(Data,'ca')\nnew_df_slope = one_hot_coding(Data,'slope')\nnew_df_exang = one_hot_coding(Data,'exang')\nnew_df_restecg = one_hot_coding(Data,'restecg')\nnew_df_cp = one_hot_coding(Data,'cp')\nnew_df_sex = one_hot_coding(Data,'sex')\nnew_df_thalach = Data['thalach']\nnew_df_oldpeak = Data['oldpeak']","0f2eade5":"# Merging all the feature Dataframe into single Dataframe\nMerged_df = pd.concat([new_df_thal, new_df_ca,new_df_slope,new_df_exang,new_df_restecg,new_df_cp,new_df_sex,new_df_thalach,new_df_oldpeak], axis=1)","553b7f90":"# Normalizing the numerical data and bring them in range 0 to 1\nMerged_df['thalach'] = (Merged_df['thalach'] - np.min(Merged_df['thalach'])) \/ (np.max(Merged_df['thalach']) - np.min(Merged_df['thalach']))\nMerged_df['oldpeak'] = (Merged_df['oldpeak'] - np.min(Merged_df['oldpeak'])) \/ (np.max(Merged_df['oldpeak']) - np.min(Merged_df['oldpeak']))","637c0b07":"(Merged_df.columns)","032ffef6":"# Divide the data into input and Output data \nMerged_df['Output_variable'] = Data['target']\nInput_DF = Merged_df.drop(['Output_variable'],axis =1)","fcfdfeb6":"# Divide the data into train and test data sets \nX_train, X_test, y_train, y_test = train_test_split(Input_DF, Merged_df['Output_variable'], test_size=0.20, random_state=42)","ad4d1421":"len(X_train)","70adfcad":"len(X_test)","ae6cf975":"# Intialization of classifier \nclassifiers =[]\nmodel1 = LogisticRegression()\nclassifiers.append(model1)\nmodel2 = SVC()\nclassifiers.append(model2)\nmodel3 = DecisionTreeClassifier()\nclassifiers.append(model3)\nmodel4 = RandomForestClassifier()\nclassifiers.append(model4)\nmodel5 = AdaBoostClassifier()\nclassifiers.append(model5)","d283d5c4":"# List of models \nmodel_name = ['LogisticRegression','Support Vector Machine','DecisionTreeClassifier','RandomForestClassifier','AdaBoostClassifier']\nTraining_score ,Testing_score,TP,FP,FN,Precision,Recall,classifiers_list = [],[],[],[],[],[],[],[]","319b0114":"# Running for differnent classifier and Save scores for different classfiers into model\nfor i in range(0,len(classifiers)):\n    clf = classifiers[i]\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    classifiers_list.append(model_name[i])\n    Training_score.append(clf.score(X_train,y_train))\n    Testing_score.append(clf.score(X_test,y_test))\n    TP.append(cm[1][1])\n    FP.append(cm[0][1])\n    FN.append(cm[1][0])\n    Precision.append( precision_score(y_test,y_pred))\n    Recall.append(recall_score(y_test,y_pred))\n    \nScore_DF = pd.DataFrame()\nScore_DF['classifiers'] = classifiers_list\nScore_DF['Training_score'] = Training_score\nScore_DF['Testing_score'] = Testing_score\nScore_DF['True_positive'] = TP\nScore_DF['False_positive'] = FP\nScore_DF['False_negative'] = FN\nScore_DF['Precision'] = Precision\nScore_DF['Recall'] = Recall\nScore_DF","e5ecf428":"# Since from above LogisticRegression was performing best between among the model and we will try with logistic model with different value of C ()\nc =[0.0001,0.001,0.01,0.1,1,10,20,30,40,50] # c is inverse of Regularization Coefficient\nTraining_score ,Testing_score,TP,FP,FN,Precision,Recall,classifiers_list = [],[],[],[],[],[],[],[]\nfor i in range(0,len(c)):\n    clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=c[i], fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    Training_score.append(clf.score(X_train,y_train))\n    Testing_score.append(clf.score(X_test,y_test))\n    TP.append(cm[1][1])\n    FP.append(cm[0][1])\n    FN.append(cm[1][0])\n    Precision.append( precision_score(y_test,y_pred))\n    Recall.append(recall_score(y_test,y_pred))\n\nScore_DF = pd.DataFrame()\nScore_DF['C value'] = c\nScore_DF['Training_score'] = Training_score\nScore_DF['Testing_score'] = Testing_score\nScore_DF['True_positive'] = TP\nScore_DF['False_positive'] = FP\nScore_DF['False_negative'] = FN\nScore_DF['Precision'] = Precision\nScore_DF['Recall'] = Recall\nScore_DF","33000590":"# plot accuracy vs Regularization Coefficient\npyplot.plot(c,Score_DF['Testing_score'],'r-',label='Testing_Accuracy')\npyplot.plot(c,Score_DF['Training_score'],'b-',label='Trainig_Accuracy')\npyplot.xlabel('Regularization Coefficient')\npyplot.ylabel('Accuracy')\npyplot.legend()\naxes = pyplot.gca()\naxes.set_ylim([0.70,1])\npyplot.legend()\npyplot.show()","bcd9f63a":"# plot scores(Precision,Recall) vs Regularization Coefficient\npyplot.plot(c,Score_DF['Precision'],'g-',label='Precision')\npyplot.plot(c,Score_DF['Recall'],'y-',label='Recall')\npyplot.xlabel('Regularization Coefficient')\npyplot.ylabel('scores')\npyplot.legend()\npyplot.show()","14f3232b":"# we will try with L1 Penalty and different value of Regularization Coefficient\nc =[0.1,1,10,20,30,40,50]\nTraining_score ,Testing_score,TP,FP,FN,Precision,Recall,classifiers_list = [],[],[],[],[],[],[],[]\nfor i in range(0,len(c)):\n    clf = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=c[i], fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    Training_score.append(clf.score(X_train,y_train))\n    Testing_score.append(clf.score(X_test,y_test))\n    TP.append(cm[1][1])\n    FP.append(cm[0][1])\n    FN.append(cm[1][0])\n    Precision.append( precision_score(y_test,y_pred))\n    Recall.append(recall_score(y_test,y_pred))\n\nScore_DF = pd.DataFrame()\nScore_DF['C value'] = c\nScore_DF['Training_score'] = Training_score\nScore_DF['Testing_score'] = Testing_score\nScore_DF['True_positive'] = TP\nScore_DF['False_positive'] = FP\nScore_DF['False_negative'] = FN\nScore_DF['Precision'] = Precision\nScore_DF['Recall'] = Recall\nScore_DF","c723f855":"# plot accuracy vs Regularization Coefficient\npyplot.plot(c,Score_DF['Testing_score'],'r-',label='Testing_Accuracy')\npyplot.plot(c,Score_DF['Training_score'],'b-',label='Trainig_Accuracy')\npyplot.xlabel('Regularization Coefficient')\npyplot.ylabel('Accuracy')\npyplot.legend()\naxes = pyplot.gca()\naxes.set_ylim([0.70,1])\npyplot.legend()\npyplot.show()","461997d4":"# plot scores(Precision,Recall) vs Regularization Coefficient\npyplot.plot(c,Score_DF['Precision'],'g-',label='Precision')\npyplot.plot(c,Score_DF['Recall'],'y-',label='Recall')\npyplot.xlabel('Regularization Coefficient')\npyplot.ylabel('scores')\npyplot.legend()\npyplot.show()","d5506b85":"#### thal with value 2 have more probabilty of Heart disease\n#### thal with value 3 have less probabilty of Heart disease\n#### thal with value 1 very less difference in positive and Negative class\n#### thal with value 0 no difference positive and Negative class","f257c5ea":"#### slope(the slope of the peak exercise ST segment)","c5a1ae45":"#### No descision Boundary to classify between of heart disease and Not a heart disease with help of  chol","03283602":"#### AGE ANALYSIS","ba1566f2":"#### The resting blood Pressure ","b83b7d6d":"#### After analysis histrogram with age we are not able say anything about Heart diseases","1dcb3c52":"#### FBS Analysis(fasting blood sugar)","5df1c8d5":"# Loading the data ","92c6c344":"#### Not providing much information about classification of Heart disease and Non Heart disease","7a1ced3d":"# model selection","4669b7e5":"#### combine 2 Features gender and male","f486bf51":"#### Female population are more tend to Heart dieases in the population \n","442d904a":" ##### There is no imbalance in Data set so no need of downsampling","b46fcd77":"#### Chest Pain Type Analysis","6e67be99":"####  thalach(maximum heart rate achieved)","dd700902":"#### Ca(number of major vessels (0-3) colored by flourosopy)","57d07541":"# For Different Value of C and L1 Penalty","f101fd15":"# For Different Value of C and L2 Penalty","ae02c24e":"#### 0 means less possibilty of heart attack\n#### 1 means more possibity of heart attack\n#### 2 means more possibity of heart attack\n#### 3 means more or less possibity of heart attack confused..","63c34d9f":"#### exang(exercise induced angina)","24724948":"#### More probablity of heart disease for Type 0 exang\n#### More probablity of heart disease for Type 1 exang\n","64e7a081":"#### No descision Boundary to classify between of heart disease and Not a heart disease with help of  trestbps\n","1cb64f57":"# Hyperparameterzation","65ac3663":"#### Thal(reversable defect)","7c146192":"#### Gender analysis \n","011442f7":"# Count of Target variable","0b0d2988":"# Forming Feature Dataframe","8bb9e0f1":"#### Ca with value 0 means high probability of Heart disease\n#### Ca with value 1 means low probability of Heart disease\n#### Ca with value 2 means low probability of Heart disease\n#### Ca with value 3 means low probability of Heart disease\n#### Ca with value 4 means very less difference in  positive and Negative class","2ec2061b":"#### oldpeak(ST depression induced by exercise relative to rest)","f36a3c3d":"#### Slope 0 means Very less difference\n#### Slope 1 Means less probability  for Heart Disease\n#### Slope 2 Means high probability  for Heart Disease","ca04bfc0":"#### Restecg analysis(resting electrocardiographic results)","1ceb737b":"#### 1.Restecg with type 1 have more probablity of Heart dieases \n#### 2.Restecg with type 0 have less probablity of Heart dieases \n#### 3.Restecg with type 2 have less probablity of Heart dieases ","8713d1d5":"# Data anlaysis and Feature Selection\n\n","badd4007":"#### chol analysis(serum cholestoral in mg\/dl)"}}