{"cell_type":{"5132ee9e":"code","e0a8cbf5":"code","c23ccbb2":"code","b872fbf7":"code","83633878":"code","8a1e9890":"code","27b54f57":"code","f8ca3493":"code","3d18a34f":"code","a9c102d3":"code","613333c1":"code","b1bb2f85":"code","aa6b3459":"code","0ec3b8dd":"code","970c6190":"code","aa0e2c20":"code","3c282a5f":"code","095b71d5":"code","99763bcb":"code","4f3bcb19":"code","0f299f94":"code","621a91b8":"code","f5dcca17":"code","de59e76c":"code","9f623be3":"code","12655626":"code","ed1679dd":"code","a0d2bd2b":"code","f25a0724":"markdown","f3e37118":"markdown","608ba849":"markdown","203a6674":"markdown","b9db6c48":"markdown","4f86aa84":"markdown","011032fe":"markdown","233f4bdf":"markdown"},"source":{"5132ee9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0a8cbf5":"# \u52a0\u8f7d\u6570\u636e\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nfeatures = train_data.append(test_data, ignore_index=True)\ny_train = features['Survived']\nX_train = features.drop('Survived', axis=1)\n\n# \u9884\u89c8\u524d5\u6761\u6570\u636e\nX_train.head()","c23ccbb2":"print(\"X_train.shape={}, y_train.shape={}\".format(X_train.shape, y_train.shape))","b872fbf7":"X_train.info()","83633878":"# \u7f3a\u5931\u503c\u5408\u8ba1\nX_train.isnull().sum()\n\n# \u5f85\u5904\u7406\u7684\u7f3a\u5931\u503c\n# X_train.Age\n# X_train.Cabin\n# X_train.Embarked\n# X_train.Fare","8a1e9890":"import seaborn as sns\n\n# \u5148\u770b\u4e0b\u6570\u636e\u96c6\u7684 Age \u5206\u5e03\u72b6\u6001\nsns.histplot(X_train['Age'].dropna(), kde=True)","27b54f57":"# \u5c06\u6570\u636e\u96c6\u4e2d\u7684NaN\u6570\u636e\u4f7f\u7528\u4e2d\u503c\u586b\u5145\u3002\nX_train['Age'].replace(np.nan, np.nanmedian(X_train['Age']), inplace=True)\n\nsns.histplot(X_train['Age'], kde=True)","f8ca3493":"# Cabin \u7684\u7f3a\u5931\u503c\u592a\u591a\uff0c\u4ece Dataframe \u4e2d\u79fb\u9664\u540e\uff0c\u4e5f\u4e0d\u4f1a\u5f71\u54cd\u9884\u6d4b\u7684\nX_train.drop(\"Cabin\", axis=1, inplace=True)","3d18a34f":"# \u6211\u4eec\u6765\u770b\u4e0b\u4e58\u5ba2\u90fd\u5728\u54ea\u4e9b\u7ad9\u767b\u8239\u7684\n# S \u8868\u793a\uff1aSouthampton\uff0c\u82f1\u56fd\u5357\u5b89\u666e\u6566\n# C \u8868\u793a\uff1aCherbourg-Octeville\uff0c\u6cd5\u56fd\u745f\u5821-\u5965\u514b\u7279\u7ef4\u5c14\n# Q \u8868\u793a\uff1aQueenstown\uff0c\u7231\u5c14\u5170\u6606\u58eb\u6566\nX_train.Embarked.value_counts()","a9c102d3":"# \u767b\u8239\u60c5\u51b5\nsns.countplot(x='Embarked', data=X_train)","613333c1":"X_train['Embarked'].replace(np.nan, 'S', inplace=True)","b1bb2f85":"# \u6570\u636e\u96c6\u6709\u4e00\u4e2a\u7f3a\u5931\u6570\u636e\uff0c\u6211\u4eec\u628a\u5b83\u627e\u51fa\u6765\uff0c\u7136\u540e\u9644\u4e0a\u4e2d\u503c\nX_train[np.isnan(X_train[\"Fare\"])]","aa6b3459":"# \u67e5\u8be2\u4ece \u82f1\u56fd\u5357\u5b89\u666e\u6566 \u4e0a\u4f20\uff0c\u7ea7\u522b\u662f3\u7684\u8239\u7968\u4ef7\u683c\npclass3_fares = X_train.query('Pclass == 3 & Embarked == \"S\"')['Fare']\n# \u5148\u5c06\u7a7a\u503c\u586b\u5145\u4e3a0\npclass3_fares = pclass3_fares.replace(np.nan, 0)\n# \u7136\u540e\u53d6\u4e2d\u503c\nmedian_fare = np.median(pclass3_fares)\n\n# \u6700\u540e\u66f4\u65b0\u4e2d\u503c\u5230\u7f3a\u5931\u503c\u7684\u90a3\u5904\nX_train.loc[X_train['PassengerId'] == 1044, 'Fare'] = median_fare\n# \u67e5\u770b\u8fd9\u4e2a\u4e3a\u4e58\u5ba2\nX_train.loc[X_train['PassengerId'] == 1044]","0ec3b8dd":"X_train['Sex'].replace(['male', 'female'], [1,0], inplace=True)","970c6190":"X_train.isnull().sum()","aa0e2c20":"print(\"X_train.shape={}, y_train.shape={}\".format(X_train.shape, y_train.shape))","3c282a5f":"X_train = pd.get_dummies(X_train)\n\n# \u9884\u89c8 one-hot encoding \u524d5\u6761\u6570\u636e\nX_train.head()","095b71d5":"print(\"X_train.shape={}, y_train.shape={}\".format(X_train.shape, y_train.shape))","99763bcb":"train_X = X_train.iloc[:891, :]\ntest_X = X_train.iloc[891:, :]\ntrain_y = y_train.iloc[:891]\ntest_y = y_train.iloc[891:]","4f3bcb19":"print(\"train_X.shape={}, train_y.shape={}\".format(train_X.shape, train_y.shape))\nprint(\"test_X.shape={}, test_y.shape={}\".format(test_X.shape, test_y.shape))","0f299f94":"# \u4f7f\u7528\u51b3\u7b56\u6811\u9884\u6d4b\u6a21\u578b\nfrom sklearn.tree import DecisionTreeClassifier\n\n# \u521b\u5efa\u51b3\u7b56\u6811\u6a21\u578b\ndef createDecisionTreeClassifier():\n    model = DecisionTreeClassifier()\n\n    # \u8bad\u7ec3\u6a21\u578b\n    model.fit(train_X, train_y)\n\n    # \u9884\u6d4b\n    test_pred = model.predict(test_X)\n    test_pred = test_pred.astype(int)\n    return test_pred","621a91b8":"from sklearn.linear_model import LogisticRegression\n\n# \u521b\u5efa\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6a21\u578b\ndef createLogisticRegressionModel():\n    # LogisticRegression \u62a5\u9519 AttributeError: \u2018str\u2019 object has no attribute \u2018decode\u2019\n    # \u89e3\u51b3\u529e\u6cd5\u5c06\u6c42\u89e3\u5668\u6307\u5b9a\u4e3aliblinear\n    model = LogisticRegression(solver='liblinear')\n    model.fit(train_X, train_y)\n    \n    # \u9884\u6d4b\n    test_pred = model.predict(test_X)\n    test_pred = test_pred.astype(int)\n    return test_pred","f5dcca17":"from sklearn.ensemble import GradientBoostingClassifier\n\ndef createGradientBoostingClassifierModel():\n    model = GradientBoostingClassifier(n_estimators = 500)\n    model.fit(train_X, train_y)\n    \n    # \u9884\u6d4b\n    test_pred = model.predict(test_X)\n    test_pred = test_pred.astype(int)    \n    return test_pred","de59e76c":"from sklearn.neural_network import MLPClassifier\n\n# \u521b\u5efa\u591a\u5c42\u611f\u77e5\u5668\u7684\u9884\u6d4b\u6a21\u578b\ndef createMLPClassifierModel():\n    model = MLPClassifier(hidden_layer_sizes=128, batch_size=64, max_iter=1000, solver=\"adam\")\n    model.fit(train_X, train_y)\n     \n    # \u9884\u6d4b\n    test_pred = model.predict(test_X)\n    test_pred = test_pred.astype(int)    \n    return test_pred","9f623be3":"# Keras\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u9884\u6d4b\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras import utils as np_utils\n\ndef createKerasModel(X, y):\n    \n    # \u521b\u5efa\u6a21\u578b\n    model = Sequential()\n\n    # \u5185\u6838\u521d\u59cb\u5316\u5668\u5c31\u4f7f\u7528\u622a\u65ad\u6b63\u6001\u5206\u5e03\n    initializers = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n    \n    # \u8f93\u5165\u5c42\u7ef4\u5ea6\u662f X.shape[1]\n    model.add(Dense(input_dim=X.shape[1], units=128, kernel_initializer=initializers, bias_initializer='zeros'))\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(32))\n    model.add(Activation(\"relu\"))\n\n    model.add(Dense(2))\n    \n    # \u8f93\u51fa\u7684\u7ed3\u679c\u662f\u8981\u4e481\uff0c\u8981\u4e480\uff0c\u6240\u4ee5\u4f7f\u7528 sigmoid\u6fc0\u6d3b\u51fd\u6570\n    model.add(Activation(\"sigmoid\"))\n\n    # \u7f16\u8bd1\u4f7f\u7528\u4e8c\u8fdb\u5236\u4ea4\u53c9\u71b5\uff0cadam\u4f18\u5316\u5668\u81ea\u884c\u8c03\u6574\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    # \u5c06\u8bad\u7ec3\u6570\u636e\u7684y\u8fdb\u884c\u72ec\u70ed\u7f16\u7801\uff08one-hot encoding\uff09\n    y_train_categorical = np_utils.to_categorical(y)\n    \n    # \u8bad\u7ec3\u6a21\u578b\uff0cepochs\u8868\u793a\u8981\u8bad\u7ec3150\u6b21\uff0cverbose\u8868\u793a\u8bad\u7ec3\u6bcf\u6279\u6b21\u65f6\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\n    model.fit(X.values, y_train_categorical, epochs=150, verbose=1)\n\n    return model\n   \nkeras_model = createKerasModel(train_X, train_y)\n","12655626":"predictions_classes = np.argmax(keras_model.predict(test_X), axis=-1)","ed1679dd":"def output(predictions):\n    output = pd.DataFrame({'PassengerId': test_X.PassengerId, 'Survived': predictions})\n    output.to_csv('my_submission.csv', index=False)\n    print(\"Your submission was successfully saved!\")","a0d2bd2b":"# Decision Tree for testing data\n# output(createDecisionTreeClassifier())\n\n# Logistic Regression for testing data\n# output(createLogisticRegressionModel())\n\n# Gradient Boosting for testing data\noutput(createGradientBoostingClassifierModel())\n\n# Neural Network classifier for testing data\n# output(createMLPClassifierModel())\n\n# Keras Model for testing data\n# output(predictions_classes)","f25a0724":"# \u57fa\u4e8e\u51b3\u7b56\u6811\u6a21\u578b\u9884\u6d4b","f3e37118":"# \u9884\u5904\u7406\u6570\u636e","608ba849":"# \u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4b","203a6674":"# \u57fa\u4e8e\u68af\u5ea6\u63d0\u5347\u5206\u7c7b\u5668\u6a21\u578b\u9884\u6d4b","b9db6c48":"# \u57fa\u4e8eKeras\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4b","4f86aa84":"# \u57fa\u4e8e\u903b\u8f91\u56de\u5f52\u6a21\u578b\u9884\u6d4b","011032fe":"# \u9884\u6d4b\u4e58\u5ba2\u751f\u8fd8\u60c5\u51b5","233f4bdf":"# \u6570\u636e\u6e05\u6d17\u4e0e\u5206\u5272"}}