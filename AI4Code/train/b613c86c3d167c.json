{"cell_type":{"1ee5c19f":"code","1ad59201":"code","c9fdab58":"code","5ad2ef14":"code","c5d8dc42":"code","8e0afa5d":"code","4ccb10a5":"code","d8006007":"code","07bc8bdf":"code","fdddaaf9":"code","860cf2c9":"code","867440df":"code","7dc9a49d":"code","d7d6d325":"code","aa8342a4":"code","93d50197":"code","8d127f92":"code","6947aceb":"code","2afa2b4a":"code","9b510b9c":"code","b0d984ce":"code","db5f6ebd":"markdown","6eb723ec":"markdown","59b5e938":"markdown","77f5bedc":"markdown","df1c4bd3":"markdown","c0cb0cbb":"markdown","9bde0064":"markdown"},"source":{"1ee5c19f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1ad59201":"trainSet = pd.read_csv('..\/input\/train.csv')\ndisplay(trainSet.head())","c9fdab58":"testSet = pd.read_csv('..\/input\/test.csv')\ndisplay(testSet.head())","5ad2ef14":"structures = pd.read_csv('..\/input\/structures.csv')\ndisplay(structures.head())","c5d8dc42":"# Map the atom structure data into train and test files\n\ndef map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrainSet = map_atom_info(trainSet, 0)\ntrainSet = map_atom_info(trainSet, 1)\n\ntestSet = map_atom_info(testSet, 0)\ntestSet = map_atom_info(testSet, 1)\n","8e0afa5d":"display(trainSet.head())\ndisplay(testSet.head())","4ccb10a5":"# https:\/\/www.kaggle.com\/jazivxt\/all-this-over-a-dog\n# https:\/\/www.kaggle.com\/artgor\/molecular-properties-eda-and-models\ntrain_p0 = trainSet[['x_0', 'y_0', 'z_0']].values\ntrain_p1 = trainSet[['x_1', 'y_1', 'z_1']].values\ntest_p0 = testSet[['x_0', 'y_0', 'z_0']].values\ntest_p1 = testSet[['x_1', 'y_1', 'z_1']].values\n\ntrainSet['dist'] = np.linalg.norm(train_p0 - train_p1, axis=1)\ntestSet['dist'] = np.linalg.norm(test_p0 - test_p1, axis=1)\n\ntrainSet['dist_to_type_mean'] = trainSet['dist'] \/ trainSet.groupby('type')['dist'].transform('mean')\ntestSet['dist_to_type_mean'] = testSet['dist'] \/ testSet.groupby('type')['dist'].transform('mean')","d8006007":"# All atom_0 are hydrogens\nassert all(trainSet[\"atom_0\"].astype('category').cat.categories == ['H'])\nassert all(testSet[\"atom_0\"].astype('category').cat.categories == ['H'])","07bc8bdf":"# atom_1 are carbon, hydrogen or nitrogen\nprint(trainSet[\"atom_1\"].astype('category').cat.categories)\nprint(testSet[\"atom_1\"].astype('category').cat.categories)","fdddaaf9":"# We use the interaction types, that already include the type of atoms involved\nprint(testSet[\"type\"].astype('category').cat.categories)\nprint(trainSet[\"type\"].astype('category').cat.categories)","860cf2c9":"for i in trainSet[\"type\"].astype('category').cat.categories.values:\n    trainSet['type_'+str(i)] = (trainSet['type'] == i)\n    testSet['type_'+str(i)] = (testSet['type'] == i)","867440df":"model = LinearRegression(n_jobs = -1)","7dc9a49d":"from sklearn.linear_model import LinearRegression\n","d7d6d325":"# NB: no need to include type_3JHN as this is redundant: this is always true when all other types are false\nfitDist = model.fit(np.array(trainSet[['type_1JHC', 'type_1JHN', 'type_2JHC', 'type_2JHH', 'type_2JHN', \n                                       'type_3JHC', 'type_3JHH', 'dist', 'dist_to_type_mean']]), \n                    trainSet['scalar_coupling_constant'])","aa8342a4":"# Display factors to learn what is important for the prediction\nfitDist.coef_","93d50197":"# See https:\/\/www.kaggle.com\/uberkinder\/efficient-metric\ndef group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n    maes = (y_true-y_pred).abs().groupby(types).mean()\n    return np.log(maes.map(lambda x: max(x, floor))).mean()","8d127f92":"group_mean_log_mae(trainSet['scalar_coupling_constant'], \n                   model.predict(np.array(trainSet[['type_1JHC', 'type_1JHN', 'type_2JHC', 'type_2JHH', 'type_2JHN', \n                                       'type_3JHC', 'type_3JHH', 'dist', 'dist_to_type_mean']])), trainSet['type'])","6947aceb":"# Control: this should perform better than outputing the same overfitted value for all interactions\nprint(group_mean_log_mae(trainSet['scalar_coupling_constant'], trainSet['scalar_coupling_constant'].median(), trainSet['type']))\nprint(group_mean_log_mae(trainSet['scalar_coupling_constant'], 0.85, trainSet['type']))","2afa2b4a":"resultSet = pd.DataFrame( { \"id\" : testSet['id'],\n                            \"scalar_coupling_constant\" : model.predict(np.array(testSet[['type_1JHC', 'type_1JHN', \n                                                                                         'type_2JHC', 'type_2JHH', \n                                                                                         'type_2JHN', 'type_3JHC', \n                                                                                         'type_3JHH', 'dist', \n                                                                                         'dist_to_type_mean']]))} )","9b510b9c":"resultSet.to_csv(\"results.csv\", index = False, header = True)","b0d984ce":"# Check content of the output file\nwith open(\"results.csv\", \"r\") as f:\n    for i, line in enumerate(f):\n        print(line)\n        if i > 5:\n            break","db5f6ebd":"## Export results","6eb723ec":"### Atom types","59b5e938":"## Simple linear regression","77f5bedc":"### Evaluate performance\n","df1c4bd3":"## Load data sets","c0cb0cbb":"### Atomic distance\nhttps:\/\/www.kaggle.com\/inversion\/atomic-distance-benchmark\/","9bde0064":"# Naive Kernel for Magnetic Interaction Prediction\nThis is a work-in-progress kernel."}}