{"cell_type":{"156eeced":"code","9891ce2d":"code","f6a270d1":"code","744ceb18":"code","f2e9e978":"code","b7175ef8":"code","42bf98ff":"code","104a8b8e":"code","388a9643":"code","a6c4669a":"code","711c9ef4":"code","8b73871f":"code","cd9d1860":"code","d9a0498d":"code","d3a40c2a":"code","00e4d7a7":"code","8131377f":"code","bd7ce64e":"code","23d5ba96":"code","593b2e14":"code","e56e6564":"code","82ac1ce4":"markdown","309335b0":"markdown","f044695e":"markdown","a2dcad00":"markdown"},"source":{"156eeced":"import pandas as pd\nimport numpy as np \n\n\nimport matplotlib.pyplot as plt\n\n# Image manipulation\nfrom skimage.io import imshow, imsave\n\n# 1.2 Image compression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\n\n# 1.3 Libraries for modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n# 1.4 ML - we will classify using lightgbm\n#          with stratified cross validation\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1.5 OS related\nimport os, sys, time\n\n# 1.6 Bayes Optimization\n#  Install as: pip install bayesian-optimization   \nfrom bayes_opt import BayesianOptimization\n\n\n# Disable scientific notation\n\n#options(scipen = 999)","9891ce2d":"\nCostatrain = pd.read_csv(\"..\/input\/train.csv\")\nCostatest = pd.read_csv(\"..\/input\/test.csv\")\n\nprint (\"Train Dataset: Rows, Columns: \", Costatrain.shape)\nprint (\"Test Dataset: Rows, Columns: \", Costatest.shape)","f6a270d1":"Costatrain.head()\n","744ceb18":"Costatest.head()","f2e9e978":"# Get the examindata\n\ndef ExamineData(x):\n    \"\"\"Prints various data charteristics, given x\n    \"\"\"\n    print(\"Data shape:\", x.shape)\n    print(\"\\nColumn:\", x.columns)\n    print(\"\\nData types\", x.dtypes)\n    print(\"\\nDescribe data\", x.describe())\n    print(\"\\nData \", x.head(2))\n    print (\"\\nSize of data\", sys.getsizeof(x)\/1000000, \"MB\" )    # Get size of dataframes\n    print(\"\\nAre there any NULLS\", np.sum(x.isnull()))\n#Costatrain.index.values\n#Costatrain.info()\nExamineData(Costatrain)\n","b7175ef8":"#To take  target column from test data\nTrain_target = Costatrain['Target']\nTrain_target.value_counts(normalize=True)","42bf98ff":"#Missing value\nnaData = Costatrain.isnull().sum().values \/ Costatrain.shape[0] *100\ndf_na = pd.DataFrame(naData, index=Costatrain.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_count} rows which have missing value in train set ')\ndf_na.head(10)\n\n#ax=sns.barplot(\"df_na\", \"missing_count\",data=df_na.head(10))\n#_ = plt.title('Fraction of NaN values, %')","104a8b8e":"Costatrain_null = Costatrain.isnull().sum()\nCostatrain_null_non_zero = Costatrain_null[Costatrain_null>0] \/ Costatrain.shape[0]\n\nsns.barplot(x=Costatrain_null_non_zero, y=Costatrain_null_non_zero.index)\n_ = plt.title('Fraction of NaN values in Train data, %')","388a9643":"#Costatest\n\n#Missing value\nnaData = Costatest.isnull().sum().values \/ Costatest.shape[0] *100\ndf_na = pd.DataFrame(naData, index=Costatest.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_count} rows which have missing value in test set ')\ndf_na.head(10)\n","a6c4669a":"Costatest_null = Costatest.isnull().sum()\nCostatest_null_non_zero = Costatest_null[Costatest_null>0] \/ Costatest.shape[0]\n\nsns.barplot(x=Costatest_null_non_zero, y=Costatest_null_non_zero.index)\n_ = plt.title('Fraction of NaN values in Test data, %')","711c9ef4":"# Impute missing values for v2a1, v18q1 for test and train data\nCostatrain['v2a1'] = Costatrain['v2a1'].fillna(value=Costatrain['tipovivi3'])\nCostatest['v2a1'] = Costatest['v2a1'].fillna(value=Costatest['tipovivi3'])\n\nCostatrain['v18q1'] = Costatrain['v18q1'].fillna(value=Costatrain['v18q'])\nCostatest['v18q1'] = Costatest['v18q1'].fillna(value=Costatest['v18q'])\nCostatrain.info()\nCostatest.info()\nCostatrain.head(5)\nCostatest.head(5)","8b73871f":"#feature engineering for convert 0,1 to false and true respectively.\ncols = ['edjefe', 'edjefa']\nCostatrain[cols] = Costatrain[cols].replace({'no': 0, 'yes':1}).astype(float)\nCostatest[cols] = Costatest[cols].replace({'no': 0, 'yes':1}).astype(float)\n\n#Costatrain[cols] =Costatrain[cols].applymap(lambda x: 1 if x == True else x)\n#Costatest[cols] =Costatest[cols].applymap(lambda x: 0 if x == 'no' else x)\n#Costatrain[cols].replace({'no': 0, 'yes':1}).astype(float)\n#Costatrain[cols]\n#Costatest[cols]\n","cd9d1860":"#Added new feature for roof and electricity\ncols=['techozinc','techoentrepiso','techocane','techootro']\n\n\nCostatrain['roof_waste_material'] = np.nan\nCostatest['roof_waste_material'] = np.nan\nCostatrain['electricity_other'] = np.nan\nCostatest['electricity_other'] = np.nan\n\ndef fill_roof_exception(x):\n    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n        return 1\n    else:\n        return 0\n    \ndef fill_no_electricity(x):\n    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n        return 1\n    else:\n        return 0\n\nCostatrain['roof_waste_material'] = Costatrain.apply(lambda x : fill_roof_exception(x),axis=1)\nCostatest['roof_waste_material'] = Costatest.apply(lambda x : fill_roof_exception(x),axis=1)\nCostatrain['electricity_other'] = Costatrain.apply(lambda x : fill_no_electricity(x),axis=1)\nCostatest['electricity_other'] = Costatest.apply(lambda x : fill_no_electricity(x),axis=1)\n#Costatrain['roof_waste_material']","d9a0498d":"Costatrain.head()","d3a40c2a":"Costatrain['adult'] = Costatrain['hogar_adul'] - Costatrain['hogar_mayor']\nCostatrain['dependency_count'] = Costatrain['hogar_nin'] + Costatrain['hogar_mayor']\nCostatrain['dependency'] = Costatrain['dependency_count'] \/ Costatrain['adult']\nCostatrain['child_percent'] = Costatrain['hogar_nin']\/Costatrain['hogar_total']\nCostatrain['elder_percent'] = Costatrain['hogar_mayor']\/Costatrain['hogar_total']\nCostatrain['adult_percent'] = Costatrain['hogar_adul']\/Costatrain['hogar_total']\n\n","00e4d7a7":"Costatest['adult'] = Costatest['hogar_adul'] - Costatest['hogar_mayor']\n\nCostatest['dependency_count'] = Costatest['hogar_nin'] + Costatest['hogar_mayor']\nCostatest['dependency'] = Costatest['dependency_count'] \/ Costatest['adult']\nCostatest['child_percent'] = Costatest['hogar_nin']\/Costatest['hogar_total']\nCostatest['elder_percent'] = Costatest['hogar_mayor']\/Costatest['hogar_total']\nCostatest['adult_percent'] = Costatest['hogar_adul']\/Costatest['hogar_total']\n############more feature engineer ","8131377f":"#drop column in train and test data ,which will no use.\nsubmission = Costatest[['Id']]\nCostatrain.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\nCostatest.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n\ncorrelation = Costatrain.corr()\ncorrelation = correlation['Target'].sort_values(ascending=False)\nprint(f'The most 20 positive feature: \\n{correlation.head(20)}')\nprint('*'*50)\n\nprint(f'The most 20 negative feature: \\n{correlation.tail(20)}')","bd7ce64e":"#Costatrain.dtypes\n# get the labels\ny = Costatrain['Target']\n\n#y\nCostatrain.drop(['Target'], inplace=True, axis=1)\n#x = Costatrain.values\n#x\n#\n# Create training and validation sets\n#\n#x, x_test, y, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n\n","23d5ba96":"# Create the LightGBM data containers\n#\n#categorical_features = [c for c, col in enumerate(Costatrain.columns) if 'cat' in col]\n#train_data = lgb.Dataset(x, label=y)\n#test_data = lgb.Dataset(x_test, label=y_test)\n\n#\n# Train the model\n#\n#parameter value is copied from \nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n                             colsample_bytree =  0.89, min_child_samples = 90, num_leaves = 14, subsample = 0.96)\n\nkfold = 5\nskf = StratifiedKFold(n_splits=kfold, shuffle=True)\nX=Costatrain\nfolds = skf.split(X,y)    # Our data is in X and y\ntype(folds)    # generator\n#kf.get_n_splits((Costatrain,  y)\npredicts = []\nfor train_index, test_index in folds:\n    print(\"train_test_index\")\n    X_train, X_val = Costatrain.iloc[train_index], Costatrain.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n            early_stopping_rounds=400, verbose=100)\n    predicts.append(clf.predict(Costatest))\n\n","593b2e14":"indices = np.argsort(clf.feature_importances_)[::-1]\nindices = indices[:75]\n\n# Visualise these with a barplot\nplt.subplots(figsize=(20, 15))\ng = sns.barplot(y=Costatrain.columns[indices], x = clf.feature_importances_[indices], orient='h')\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=26)\ng.tick_params(labelsize=12)\ng.set_title(\"LightGBM feature importance\");","e56e6564":"#submission = Costatest[['Id']]\n#ExamineData(Costatrain);\n#Costatest.dtypes;\n#Costatrain.head()\n#submission['Target']=np.array(predicts_result).mean(axis=0).round().astype(int)\n#predicts_result\ny_pred =np.array(predicts).mean(axis=0).round().astype(int)# np.mean(predicts_result,axis=1) \n#len(y_pred)\n#submission\n#submission.dtypes\nsub = pd.DataFrame()\nsub['Id'] = submission['Id']\nsub['Target'] = y_pred\nsub.to_csv('submission.csv', index=False)\nsub.head()\n#sub = pd.read_csv(\"sample_submission.csv\", header =0)\n#submission['Target'] = y_pred\n#sub\n#sub.to_csv(\"sub.csv\",index = False)\n#y_pred.dtypes\n#submission['Target']=y_pred\n#X=Costatest[predicts_result]\n#submission['Target'] =predicts_result#xg_cl.predict(X)# np.array(predicts_result).mean(axis=0).round().astype(int)\n#np.array(predicts_result).mean(axis=0).round().astype(int)\n#submission.to_csv('submission.csv', index = False)","82ac1ce4":"Training and testing Dataset","309335b0":"To use LightGBM Model","f044695e":"Note-Missing data is the same in train and test data, it means there is less trouble","a2dcad00":"More feature engineering"}}