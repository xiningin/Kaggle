{"cell_type":{"d9bd61ae":"code","ac0b490f":"code","a26462b7":"code","13d33f53":"code","a131f1e4":"code","bc6aed03":"code","da6429fb":"code","d6e085ef":"code","a8ce1aaf":"code","a79289f6":"code","67c33815":"code","1d1cd486":"code","9bc11885":"code","cceef59a":"code","d51fbc69":"code","4ead6cf0":"code","95366ae1":"code","0dadabfe":"code","16f0e22a":"code","0c0c7771":"code","a7b15bc8":"code","6c904e90":"markdown","9cca36b9":"markdown","7431ba70":"markdown","fff9f3a5":"markdown","cda05d56":"markdown","cac5b568":"markdown","dab3d858":"markdown","17dd0daf":"markdown","45c42b33":"markdown","ecccb364":"markdown","69366ec1":"markdown"},"source":{"d9bd61ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac0b490f":"import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pandas.api.types import CategoricalDtype\n\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport optuna\n\nwarnings.filterwarnings('ignore')","a26462b7":"train_data = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Concatenate train_data and test_data so we can process them together\ndata = pd.concat([train_data, test_data], axis=0)","13d33f53":"col_names = list(data.select_dtypes('object').columns)","a131f1e4":"# Run this function to view one-by-one features and compare with data description to find typos\n\ndef view_feature(data):\n    print(col_names[0])\n    print(data[col_names[0]].unique())\n    col_names.remove(col_names[0])\n    print(f'Features remaining: {len(col_names)}')","bc6aed03":"# Fill NaN with 'None' because following data description, NaN is value 0, not missing value\n# With truly missing values, we will fill with a better strategy\n\ndef clean(data):\n    data['MSZoning'] = data['MSZoning'].replace({'C (all)': 'C'})\n    data['Alley'] = data['Alley'].fillna('None')\n    data['Neighborhood'] = data['Neighborhood'].replace({'NAmes': 'Names'})\n    data['BldgType'] = data['BldgType'].replace({'Duplex': 'Duplx', 'Twnhs': 'TwnhsI'})\n    data['Exterior2nd'] = data['Exterior2nd'].replace({'Brk Cmn': 'BrkComm'})\n    data['BsmtQual'] = data['BsmtQual'].fillna('None')\n    data['BsmtCond'] = data['BsmtCond'].fillna('None')\n    data['BsmtExposure'] = data['BsmtExposure'].fillna('None')\n    data['BsmtFinType1'] = data['BsmtFinType1'].fillna('None')\n    data['BsmtFinType2'] = data['BsmtFinType2'].fillna('None')\n    data['FireplaceQu'] = data['FireplaceQu'].fillna('None')\n    data['GarageType'] = data['GarageType'].fillna('None')\n    data['GarageFinish'] = data['GarageFinish'].fillna('None')\n    data['GarageQual'] = data['GarageQual'].fillna('None')\n    data['GarageCond'] = data['GarageCond'].fillna('None')\n    data['PoolQC'] = data['PoolQC'].fillna('None')\n    data['Fence'] = data['Fence'].fillna('None')\n    data['MiscFeature'] = data['MiscFeature'].fillna('None')\n    return data","da6429fb":"def impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(df[name].median())\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(df[name].describe().top)\n    return df","d6e085ef":"features_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\",\n                \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\",\n                \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\",\n                \"SaleType\", \"SaleCondition\"]\n\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nsix_levels = ['None', \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": six_levels,\n    \"BsmtCond\": six_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": six_levels,\n    \"GarageQual\": six_levels,\n    \"GarageCond\": six_levels,\n    \"PoolQC\": ['None', \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": ['None', \"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": ['None', \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": ['None', \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": ['None', \"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df","a8ce1aaf":"data = clean(data)\ndata = encode(data)","a79289f6":"# Split data to train, test data with their own original 'Id'\n\ntrain_data = data.loc[train_data.index, :]\n\ntest_data = data.loc[test_data.index, :]\n\n#Test data have 'SalePrice' columns because of data merging before, so we must drop it.\ntest_data.drop(['SalePrice'], axis=1, inplace=True)","67c33815":"X = train_data.copy()\ny = X.pop('SalePrice')\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)","1d1cd486":"X_train = impute(X_train)\nX_valid = impute(X_valid)\n\ntest_data = impute(test_data)","9bc11885":"<h2>Label Encode for categorical features<\/h2>","cceef59a":"def label_encode(df):\n    for colname in df.select_dtypes([\"category\"]):\n        df[colname] = df[colname].cat.codes\n    return df","d51fbc69":"X_train = label_encode(X_train)\nX_valid = label_encode(X_valid)\n\ntest_data = label_encode(test_data)","4ead6cf0":"xgb = XGBRegressor()","95366ae1":"def score_dataset(X_train, y_train, X_valid, y_valid, xgb):\n    model = xgb\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, preds)\n    return score","0dadabfe":"score = score_dataset(X_train, y_train, X_valid, y_valid, xgb)\nprint(f'Baseline model score: {score} MAE')","16f0e22a":"def objective(trial):\n    xgb_params = dict(\n        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n        n_estimators=trial.suggest_int(\"n_estimators\", 10, 2000),\n        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n    )\n    xgb = XGBRegressor(**xgb_params)\n    return score_dataset(X_train, y_train, X_valid, y_valid, xgb)\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\nxgb_params = study.best_params","0c0c7771":"model = XGBRegressor(**xgb_params)\n\nmodel.fit(X_train, y_train)\npredictions = model.predict(test_data)","a7b15bc8":"output = pd.DataFrame({'Id': test_data.index, 'SalePrice': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","6c904e90":"<h2>Split train data to validate model<\/h2>","9cca36b9":"<h2>Order ordinal categoricals features<\/h2>","7431ba70":"<h1>1. Import Packages and Configuration<\/h1>","fff9f3a5":"<h2>To avoid target leakage, we must impute train, and valid data independently","cda05d56":"<h1>2. Preprocessing Data<\/h1>","cac5b568":"<h1>5. Train Model and Create Submissions<\/h2>","dab3d858":"<h1>4. Hyperparameter Tuning<\/h1>","17dd0daf":"***In this notebook, we will do some simple data preprocessing and use optuna package to improve our model.***","45c42b33":"<h2>Dealing with missing values<\/h2>\nWe will fill 'nan' numerical values with median values, and categorical values with most frequency values.","ecccb364":"<h2>Clean data<\/h2>\n\nReplace typos for categorical features.\nI will use XGB, so don't need to rescale features.","69366ec1":"<h1>3. Baseline Model<\/h1>"}}