{"cell_type":{"9c827a6d":"code","45f9eec2":"code","a80034b6":"code","9706bc5e":"code","ee6af538":"code","2f01860a":"code","e0cd506d":"code","42399d03":"code","d725193f":"code","80d5659f":"code","d945b344":"code","1583d001":"code","dd3dc4a7":"code","4d69d268":"code","2381559b":"code","7739103c":"code","79c2a92c":"markdown","17ff409b":"markdown","825ac578":"markdown","63f58d2b":"markdown","b708f22c":"markdown","cc3f7c73":"markdown","0b02e04f":"markdown","d2285dfc":"markdown","59d2e6f6":"markdown","d7eb3de8":"markdown","a526c8c1":"markdown","18681d14":"markdown"},"source":{"9c827a6d":"import numpy as np\nimport os # Working with files and folders\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image, ImageEnhance, ImageFilter, ImageOps # Image processing\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential","45f9eec2":"image_dir = os.path.abspath(\"\/kaggle\/input\/photographs-of-28-different-domino-tiles\/data\")","a80034b6":"# Crops image from size 100,100 to size sq_size, sq_size\ndef crop_image(im, sq_size):\n  new_width = sq_size\n  new_height = sq_size\n  width, height = im.size   # Get dimensions \n  left = (width - new_width)\/2\n  top = (height - new_height)\/2\n  right = (width + new_width)\/2\n  bottom = (height + new_height)\/2\n  imc = im.crop((left, top, right, bottom))\n  return imc \n\n# Image augmentation by rotating images\ndef rotated_images(im):\n    im_list = [im]\n    im_list.append(im.rotate(45))\n    im_list.append(im.rotate(90))\n    im_list.append(im.rotate(135))    \n    im_list.append(im.rotate(180))\n    im_list.append(im.rotate(225))    \n    im_list.append(im.rotate(270))\n    im_list.append(im.rotate(315))    \n    return im_list\n\n# Image augmentation by inverting image\ndef invert_images(im_list):\n    inverted_im_list = []\n    for im in im_list:\n        inverted_im_list.append(im)\n        inverted_im_list.append(ImageOps.invert(im))\n    return inverted_im_list\n\n# Image enhancement in order to remove noise and extract features\ndef enhance_image(im):\n    im = im.convert('L') # Turns black\/white\n    im = im.filter(ImageFilter.CONTOUR) # Enhances contours\n    c_enhancer = ImageEnhance.Contrast(im)\n    im = c_enhancer.enhance(5) # Enhances contrast\n    b_enhancer = ImageEnhance.Brightness(im)\n    im = b_enhancer.enhance(1.2) # Enhances brightness\n    return im","9706bc5e":"example_folder = '\/3x3\/'\nexample_image = '20180505_181945.jpg'\nim = Image.open(os.path.join(image_dir + example_folder, example_image))\nprint(\"Image size:\", im.size)\n#im = im.rotate(45)\n#im = Image.open(os.path.join(image_dir + \"\/3x3\/\", example_image))\n#plt.imshow(im)\n#rotated_image_list = rotated_images(im)\n#rotandinv_list = invert_images(rotated_image_list)\n#print(\"Augmented images: \", len(rotandinv_list))\n#for r_im in rotandinv_list:\n#    plt.imshow(r_im)\n#    plt.show()\nim = enhance_image(im)\nplt.imshow(im, cmap='gray', vmin=0, vmax=255)","ee6af538":"X = []\ny = []\nim_squared_size = 80 # Cropped image size\n\nfor subdir, dirs, files in os.walk(image_dir):\n    dir_name = subdir.split(\"\/\")[-1] # Retrieve directory name, i.e. the target feature\n    if dir_name and len(dir_name) == 3 and \"x\" in dir_name: # Double check that it is a valid target feature name\n        #print(\"Dir name:\", dir_name)\n        for filename in files:            \n            im = Image.open(os.path.join(image_dir + \"\/\" + dir_name + \"\/\", filename))\n            if im.size == (100,100): # Some photos have not been resized properly, ignore those.\n                im = crop_image(im, im_squared_size) # Crops image\n                im = enhance_image(im) # Enhances image\n                \n                # Create extra data with rotated images of every image\n                rotated_images_list = rotated_images(im) \n                \n                # Inverts every image in image_list (and thus doubles data size)\n                rotated_inverted_list = invert_images(rotated_images_list) \n                \n                for aug_image in rotated_inverted_list:\n                    y.append(dir_name)\n                    im_arr = np.array(aug_image)\n                    X.append(im_arr)                \n\n# Turns to numpy arrays            \nX = np.array(X)\ny_string_keys = np.array(y)                ","2f01860a":"X = X.astype(\"float32\") \/ 255 # Pixel value needs to be between 0 and 1\nX = np.expand_dims(X, -1) \nprint(\"Data size: \", X.shape[0])","e0cd506d":"num_classes = len(np.unique(y_string_keys))\nprint(\"Num classes: \", num_classes)","42399d03":"# Transfer target key from string (e.g. '2x1') to number (index in labels_list)\ny_number_keys = []\nlabels = dict(enumerate(np.unique(y_string_keys).flatten(), 0))\nprint(\"Labels\", labels)\nval_list = list(labels.values())\nfor i,val in enumerate(y_string_keys):\n    y_number_keys.append(int(val_list.index(val)))","d725193f":"# Transfer target key from number to one hot encoded array\ny = to_categorical(y_number_keys, num_classes)","80d5659f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nprint(\"Train images: \", X_train.shape)\nprint(\"Test images: \", X_test.shape[0])","d945b344":"# Look at test samples\nsamples = np.random.choice(len(X_test), 5)\nfor i, prediction in enumerate(samples):    \n    #print(np.argmax(prediction), labels[np.argmax(prediction)])\n    X_test[samples[i]]\n    plt.imshow(X_test[samples[i]], cmap='gray')\n    plt.xlabel(labels[np.argmax(y_test[samples[i]])])\n    plt.show()","1583d001":"input_shape = (im_squared_size,im_squared_size,1)\n\nmodel = Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel.summary()","dd3dc4a7":"es = EarlyStopping(monitor='val_loss', patience=5)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\nmodel.fit(X_train, y_train, validation_split=0.1, epochs=20, callbacks=[es])\n","4d69d268":"scores = model.evaluate(X_test, y_test)\nprint(\"Model accuracy: {:.2%}\".format(scores[1]))\nprint(\"Baseline guess accuracy: {:.2%}\".format(1\/num_classes))\nprint(\"Better than guessing: {}x\".format((scores[1] \/(1\/num_classes))))","2381559b":"from sklearn.metrics import confusion_matrix\ny_pred = model.predict(X_test)\ny_pred_classes = []\ny_test_classes = []\nfor y in y_pred:\n    y_pred_classes.append(labels[np.argmax(y)])\nfor y in y_test:\n    y_test_classes.append(labels[np.argmax(y)])\ncf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n\nfig = plt.figure(figsize=(16,16))\ncfmap = sns.heatmap(cf_matrix, yticklabels=list(labels.values()), xticklabels=list(labels.values()), annot=True, cmap='Blues', )\ncfmap.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Confusion matrix\")\nplt.show()","7739103c":"\nsamples = np.random.choice(len(y_test), 5)\nsamples_to_predict = []\nfor sample in samples:\n    samples_to_predict.append(X_test[sample])\n    #print(y_test[sample])\n\npredictions = model.predict(np.array(samples_to_predict))\n\nfor i, prediction in enumerate(predictions):    \n    #print(np.argmax(prediction), labels[np.argmax(prediction)])\n    plt.imshow(X_test[samples[i]], cmap='gray')\n    plt.xlabel(\"Prediction: \" + labels[np.argmax(prediction)])\n    plt.show()","79c2a92c":"### Credits\nThanks to https:\/\/www.kaggle.com\/christoffer\/ for providing a NN-setup.","17ff409b":"In order to test different image enhancements and filters I have used the following code to review a sample photo with different types of code.","825ac578":"### Test samples from augmented data","63f58d2b":"## Data augmentation (image processing) - and target feature extraction\nAs there is only 100 images per class, there is a strong need for data augmentation by image processing. The images are:\n\n- **Enhanced** (contrast, brightness, contour enhancement etc) in order to remove unnecessary background information and enhance informative features more likely to improve classification\n- **Cropped** (from 100 to <im_squared_size> px): Most photos are taken from a bit afar. By cropping the image we remove unnecessary background information, while also reducing data amount. Cropping to much, removes too much information and decreases accuracy (some photos are taken at closer range).\n- **Rotated**: Photos of the domino tiles are taken with different rotations so rotating images are an easy way of augmenting more data. Rotations of 45 degrees adds an unfortunate 'frame-like' anomaly but doing so still improves classification.\n- **Inverted**: Inverted images turn black to white and vice versa. In order for the model to learn necessary features and not the 'color information'.\n\nThe target feature is taken from the directory name which holds the key to all the photos inside (e.g. folder '3x3' all have photos of 3x3-tiles).","b708f22c":"# Model","cc3f7c73":"## Conclusions on work and results","0b02e04f":"### Sampled test predictions","d2285dfc":"The accuracy of the model is nearly 100%. The confusions are between tiles of similar amount of dots, which makes sense. \n\nDuring the development I have made the following conclusions:\n\n- When I started off with the model I did not use a large enough neural network with only one Convolutional layer which made the accuracy barely better than a random guess. After reviewing https:\/\/www.kaggle.com\/christoffer\/domino-recognition I added more convolutional layers (as well as Maxpooling layers) which made a great positive diffence. I have not been able to improve on Christoffer's NN-setup. \n\n- Adding\/removing inversion of images changed accuracy approximately 4%-units (96 to ~100%).\n\n- Adding 45-degree rotations of the images did improve accuracy but not by much (99.0 with 45 degree rotations, 98.0 without 45 degree and 4 times less data)\n\n- Cropping has a rather large impact on accuracy. Not cropping adds to much unnecessary data, cropping to much removes important data. 80px was shown to be a sweet spot.\n\n- Removing data augmentation completely reduced accuracy from ~100% to about 65%\n\n","59d2e6f6":"# Domino classification with a CNN\nThis project is about classifying domino tiles. I have taken 100 photos of all different versions of dominos from 0 to 6 - and resized the photos to 100x100px using an image editor (outside of this code and already in the data). The idea was to classify each of the 28 versions of domino tiles. \n ","d7eb3de8":"## Image processing functions","a526c8c1":"# Result visualization","18681d14":"\n### Sample image for image processing"}}