{"cell_type":{"3a03a2cb":"code","04ac9b3c":"code","52074eba":"code","df654b72":"code","d0e7b51a":"code","47cffcd6":"code","1bbd88f3":"code","7c6f9d10":"code","e527692e":"code","0dd0cfd9":"code","bda0faa2":"code","7a48e267":"code","0132688e":"code","a41681da":"code","a7cb515f":"code","fddabef2":"code","1587380b":"code","dd7d5a06":"code","2959db32":"code","300bd3fa":"code","05586d54":"markdown","ef0f5192":"markdown","68e888d2":"markdown"},"source":{"3a03a2cb":"!nvidia-smi","04ac9b3c":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models\nimport os\nimport argparse\nimport copy\n","52074eba":"!pip install wandb -q","df654b72":"import wandb\nwandb.login()","d0e7b51a":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0.0  # best test accuracy\nbest_model = None","47cffcd6":"# Data\nprint('Data transformation')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='.\/data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=128, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='.\/data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=100, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\n\n","1bbd88f3":"# Dataset sizes\ndata_size = {'train': len(trainset), \n             'test' : len(testset)}","7c6f9d10":"# create the list of targets in the test dataset\nall_test_targets = torch.tensor([]).to(device)\nfor data, target in testloader:\n  target = target.to(device)\n  all_test_targets = torch.cat(\n      (all_test_targets, target),\n      dim = 0\n  )","e527692e":"data_size","0dd0cfd9":"# Training\ndef train(epoch, net, criterion, optimizer):\n    \n    net.train()\n    current_loss = 0.0    # Current loss \n    current_tp = 0        # current count of true positives\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        # zero the optimzier gradients \n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(True):\n          outputs =  net(inputs)\n          _, preds = torch.max(outputs, 1)\n          loss = criterion(outputs, targets)\n          current_loss += loss.item()*inputs.size(0)\n          current_tp += torch.sum(preds == targets.data)\n          # since training so update params\n          loss.backward()\n          optimizer.step()\n\n    epoch_loss = current_loss \/ data_size['train']\n    epoch_acc = current_tp.double() \/ data_size['train']\n    print(f'\\tTraining : Loss {epoch_loss} and Accuracy {epoch_acc}')\n    wandb.log({\n        \"Training Accuracy\": 100. * epoch_acc,\n        \"Training Loss\": epoch_loss})\n","bda0faa2":"def test(epoch, net, criterion, optimizer):\n    global best_acc\n    global best_model\n    global all_preds\n    net.eval()\n    current_loss = 0.0    # Current loss \n    current_tp = 0        # current count of true positives\n    example_images = []\n    # for storing all the targets \n    \n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, targets)\n            # add to all_preds\n            x = np.array(preds.cpu())\n            all_preds = np.concatenate((all_preds,x), axis=0)\n            # calculate statistics\n            current_loss += loss.item()*inputs.size(0)\n            current_tp += torch.sum(preds == targets.data)\n            # take one image from each batch and store it\n            example_images.append(wandb.Image(\n                inputs[0], caption=\"Pred: {} Truth: {}\".format(preds[0].item(), targets[0])))\n    \n    epoch_loss = current_loss \/ data_size['test']\n    epoch_acc = current_tp.double() \/ data_size['test']\n    print(f'\\tTest : Loss {epoch_loss} and Accuracy {epoch_acc}')\n    wandb.log({\n        \"Examples\": example_images,\n        \"Test Accuracy\": 100. * epoch_acc,\n        \"Test Loss\": epoch_loss})\n    return epoch_acc\n    ","7a48e267":"# List for storing the best accuracies\nbest_accuracies = []\n# List for storing the best models\nbest_models = []","0132688e":"# Check over the last 5 iterations whether the best_accuracy is one among them\ndef check_convergence(epoch, accuracies, best_acc):\n  if epoch < 5:\n    return False\n  last_5_acc = np.max(accuracies[-5:])\n  if last_5_acc < best_acc:\n    return True\n  return False","a41681da":"# imports for plotting confusion matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    # print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    wandb.log({\"Confusion Matrix\": plt})","a7cb515f":"# loop over all the configs \nmodel_configs = ['all_layers', 'last_layer']\ntraining_configs = ['sdm', 'adam']\nfor model_config in model_configs[:]:\n  for optim_config in training_configs[:]:  \n    \n    # Load the pretrained model\n    net = models.resnet18(pretrained=True)\n    # If only last layer then switch off grad for rest of the layers\n    if model_config == 'last_layer':\n      for param in net.parameters():\n        param.requires_grad = False\n\n    # reset the last layer of the neural network\n    num_ftrs =  net.fc.in_features\n    net.fc = nn.Linear(num_ftrs, len(classes))\n    \n    net = net.to(device)\n    # Loss function is always cross entropy loss\n    criterion  = nn.CrossEntropyLoss()\n    \n    # set the appropriate optimizer\n    if model_config=='last_layer':\n      param = net.fc.parameters()\n    else :\n      param = net.parameters()\n\n    if optim_config=='sdm' : \n      optimizer = optim.SGD(param, lr=0.001, momentum=0.9)\n    else:\n      optimizer = optim.Adam(param, lr=0.01)\n    max_acc = 0.0\n    max_acc_model = copy.deepcopy(net.state_dict())\n\n    # Run the epochs\n    print('-'*20)\n    print(f'Configuration: {model_config} and {optim_config}')\n    \n    ## stores the predictions for all the \n    best_preds = []\n    iterations  = None\n    accuracies  = []\n#     wandb.init(project=\"pytorch-resnet18-transfer-learning\")\n    run = wandb.init(project=\"pytorch-resnet18-transfer-learning\", reinit=True)\n    wandb.watch(net, log=\"all\")\n    for epoch in range(0,200):\n        # all the predictions made in this epoch\n        all_preds = []\n        print(f'At Epoch {epoch} ...')\n        print(\"Training\")\n        train(epoch, net, criterion, optimizer)\n        print(\"Testing\")\n        acc = test(epoch, net, criterion, optimizer)\n        \n        # save this epoch_acc to memory\n        accuracies.append(acc)\n        if acc>=max_acc:\n          max_acc = acc\n          run.summary[\"best_accuracy\"] = max_acc\n          max_acc_model = copy.deepcopy(net.state_dict())\n          \n          best_preds = all_preds\n\n        if check_convergence(epoch, accuracies, max_acc):\n          iterations = epoch\n          break\n    \n    # Generate the confusion matrix \n    conf_matrix = confusion_matrix(all_test_targets.cpu(), best_preds)\n    plt.figure(figsize = (20,20))\n    plot_confusion_matrix(conf_matrix,classes)\n    print(f'\\tTraining Converged with {iterations} iterations and best accuracy {max_acc}')\n    wandb.summary[\"iterations\"] = iterations\n    run.finish()\n    # finally with this config done, add to list the best accuracie obtained \n    # and the best model\n    accuracies.append(max_acc)\n    best_models.append(max_acc_model)\n    ","fddabef2":"x = np.array(all_preds[0].cpu())","1587380b":"y = []","dd7d5a06":"best_pred_new = []\nfor pred in best_preds:\n    x = np.array(pred.cpu())\n    best_pred_new = np.concatenate((best_pred_new,x), axis=0)","2959db32":"all_test_targets","300bd3fa":"conf_matrix = confusion_matrix(all_test_targets.cpu(), best_pred_new)\nplt.figure(figsize = (20,20))\nplot_confusion_matrix(conf_matrix,classes)","05586d54":"## Final Piece of Code ","ef0f5192":"## Write the training methods here ","68e888d2":"## Write the test methods here "}}