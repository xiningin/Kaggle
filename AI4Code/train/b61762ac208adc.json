{"cell_type":{"15f713d0":"code","97b0d8e6":"code","e6e447f4":"code","6246e6d5":"code","8c7bc731":"code","51564a83":"code","8afffad4":"code","3f6fd087":"code","d19ce923":"code","e930ad45":"code","4de484ad":"code","528b11e4":"code","723a7a64":"code","81962b17":"code","4315f240":"code","ef21683e":"code","f9c65565":"code","439edcb1":"code","06c28bad":"code","c0eaf7ae":"code","6680565c":"code","1f93ce3d":"code","68191e88":"code","d5373879":"code","0e448b23":"code","305df75c":"code","7d03f75d":"code","88142e06":"code","92541b10":"code","e840eca8":"code","ebb38bdb":"code","ab33a9af":"code","79e72379":"code","fcab346b":"code","b437739d":"code","3606de60":"code","685f59bd":"markdown","e5051e9d":"markdown","6056af35":"markdown","73f96d42":"markdown","55bb69f9":"markdown","59510656":"markdown","3b2d0c55":"markdown","1177dce6":"markdown","1c92790c":"markdown","2dd80760":"markdown","ff0290b0":"markdown","faa7e8ce":"markdown"},"source":{"15f713d0":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport warnings\nwarnings.filterwarnings('ignore')\nfrom pandas_profiling import ProfileReport\nfrom matplotlib import pyplot as plt","97b0d8e6":"train_data=pd.read_csv(\"..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv\")\ntest_data=pd.read_csv(\"..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv\")","e6e447f4":"print(train_data.shape)\nprint(test_data.shape)","6246e6d5":"print(\"columns of train data :\\n\" ,train_data.columns)\nprint(\"-------------------------------------------------------\")\nprint(\"columns of test data :\\n\",test_data.columns )","8c7bc731":"print('Missing values in train dataset:\\n\\n', train_data.isnull().sum())\nprint(\"------------------------------------------\")\nprint('\\n\\nMissing values in test dataset:\\n\\n', test_data.isnull().sum())","51564a83":"profile_train_data=ProfileReport(train_data , title=\"Job Change of Data Scientists training_data profiling report \")\nprofile_test_data=ProfileReport(train_data , title=\"Job Change of Data Scientists testing_data profiling report \")","8afffad4":"profile_train_data","3f6fd087":"profile_test_data","d19ce923":"train_data.head(10)","e930ad45":"test_data.head(10)","4de484ad":"train_data.info()","528b11e4":"test_data.info()","723a7a64":"\n# Top 15 features with missing data for train data \n\nsns.set_style(\"whitegrid\")\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(15,4))\ndf=pd.Series(1 - train_data.count() \/ len(train_data)).sort_values(ascending=False).head(20)\nsns.barplot(x=df.index, y=df,palette=\"Blues_d\")\nplt.xticks(rotation=90)\n","81962b17":"sns.heatmap(train_data.isnull(),cbar=False, cmap='viridis')","4315f240":"# Top 5 features with missing data for test data \n\nsns.set_style(\"whitegrid\")\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(15,4))\ndf=pd.Series(1 - test_data.count() \/ len(test_data)).sort_values(ascending=False).head(20)\nsns.barplot(x=df.index, y=df,palette=\"Blues_d\")\nplt.xticks(rotation=90)\n","ef21683e":"sns.heatmap(test_data.isnull(),cbar=False, cmap='viridis')","f9c65565":"#missing data for train data \ntotal = train_data.isnull().sum().sort_values(ascending=False)\npercent = (train_data.isnull().sum()\/train_data.shape[0]).sort_values(ascending=False)\n\nmissin_train = pd.concat([total, percent], axis=1, keys=['Total', 'Perc_missing'])\nmissin_train.head(10)\n\n","439edcb1":"#missing data for train data \ntotal = test_data.isnull().sum().sort_values(ascending=False)\npercent = (test_data.isnull().sum()\/test_data.shape[0]).sort_values(ascending=False)\n\nmissing_test = pd.concat([total, percent], axis=1, keys=['Total', 'Perc_missing'])\nmissing_test.head(10)\n","06c28bad":"train_data[\"gender\"].dropna(inplace=True)\ntrain_data[\"company_type\"].dropna(inplace=True)\ntrain_data[\"company_size\"].dropna(inplace=True)\ntrain_data.drop(['enrollee_id'], axis = 1, inplace = True)\ntrain_data.dropna(inplace=True)\n#aug_test.dropna(inplace=True)","c0eaf7ae":"train_data.isnull().sum()","6680565c":"print(list(train_data.columns))\nprint(\"------------------------------------------------------\")\nprint(train_data.shape)","1f93ce3d":"test_data.dropna(inplace=True)\ntest_data.drop(['enrollee_id'], axis = 1, inplace = True)","68191e88":"test_data.isnull().sum()","d5373879":"print(list(test_data.columns))\nprint(\"--------------------------------------------------\")\nprint(test_data.shape)","0e448b23":"train_data['experience'].value_counts()","305df75c":"def replacment(experience):\n    if experience == '>20':\n        return 21\n    elif experience == '<1':\n        return 0\n\n    else:\n        return experience","7d03f75d":"train_data.experience = train_data.experience.map(replacment)","88142e06":"train_data['experience'].value_counts()","92541b10":"train_data['last_new_job'].unique()","e840eca8":"train_data['last_new_job'].value_counts()","ebb38bdb":"# We will use the same function.\ndef replacement_2(last_new_job):\n    if last_new_job == '>4':\n        return 5\n    elif last_new_job == 'never':\n        return 0\n\n    else:\n        return last_new_job\n\ntrain_data.last_new_job = train_data.last_new_job.map(replacement_2)","ab33a9af":"train_data['last_new_job'].unique()","79e72379":"value = train_data['target'].value_counts().values.tolist()\nlabels = train_data['target'].value_counts().index\nplt.figure(figsize= (5,5))\nplt.title('The ratio of each component to the target column.')\nplt.pie(x = value, labels = labels, autopct='%1.f%%', pctdistance= .5)\nplt.show()","fcab346b":"train_data.corr()","b437739d":"# Now we will draw a heat map.\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train_data.corr(), annot=True, linewidths=.5, ax=ax)\nplt.show()","3606de60":"\ntable = pd.pivot_table(train_data,index=['education_level','target','gender'])\nprint(table)\ntable.plot(kind='hist',\n           figsize = (15,10),\n           colormap =\"Dark2\")","685f59bd":"# Now we will review one of the most important columns, which is the target column.","e5051e9d":"Now let's look at the types of data and their details.\n# Let's go deeper into the data.","6056af35":"# reading the data ","73f96d42":"I will do machine learning algorithms for that data later.","55bb69f9":"In order to get a detailed report on the data we have, we called the amazing tool **pandas_profiling** to do this task.\nAnd through the report that we obtained, we were able to obtain high-quality results about the data, **so it is better to see them.**","59510656":"It seems that the data we have here needs a lot of work, and there is a problem that we are working on two separate files so the work will be difficult.","3b2d0c55":"> ****Here we will get the percentages of loss in the data that we have previously obtained in the report.****","1177dce6":"****Now I will modify the values inside the columns.****","1c92790c":"# Let's make it look better","2dd80760":"We notice some unwanted values such as \"<1\" and \">20\"\nWe will convert these values.","ff0290b0":"# Thank you very much","faa7e8ce":"**We will work to change or delete those unwanted values.**"}}