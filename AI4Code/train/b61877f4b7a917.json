{"cell_type":{"f360fc5d":"code","7ac24f6e":"code","b61e573a":"code","3e55aeef":"code","585113c8":"code","4d5c54af":"code","054546a3":"code","c077d24b":"code","f9e0d3b2":"code","2bc015c9":"code","2bb387ad":"code","a9e6571a":"code","4f3b978c":"code","50b2ae83":"code","3c5d1c29":"code","8105c901":"code","4d74fd22":"code","1df85f3b":"code","561cef9a":"code","6a912f77":"code","a0115207":"code","fee00a55":"markdown","30730a20":"markdown","a02635fc":"markdown","e1fd04f1":"markdown","58f38cb7":"markdown","60076fcc":"markdown","7915cb06":"markdown","8c08a2b3":"markdown"},"source":{"f360fc5d":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation\nfrom keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline  ","7ac24f6e":"dataset_train=pd.read_csv('..\/input\/PM_train.txt',sep=' ',header=None).drop([26,27],axis=1)\ncol_names = ['id','cycle','setting1','setting2','setting3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\ndataset_train.columns=col_names\nprint('Shape of Train dataset: ',dataset_train.shape)\ndataset_train.head()","b61e573a":"dataset_test=pd.read_csv('..\/input\/PM_test.txt',sep=' ',header=None).drop([26,27],axis=1)\ndataset_test.columns=col_names\n#dataset_test.head()\nprint('Shape of Test dataset: ',dataset_train.shape)\ndataset_train.head()","3e55aeef":"pm_truth=pd.read_csv('..\/input\/PM_truth.txt',sep=' ',header=None).drop([1],axis=1)\npm_truth.columns=['more']\npm_truth['id']=pm_truth.index+1\npm_truth.head()","585113c8":"# generate column max for test data\nrul = pd.DataFrame(dataset_test.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\nrul.head()","4d5c54af":"# run to failure\npm_truth['rtf']=pm_truth['more']+rul['max']\npm_truth.head()","054546a3":"pm_truth.drop('more', axis=1, inplace=True)\ndataset_test=dataset_test.merge(pm_truth,on=['id'],how='left')\ndataset_test['ttf']=dataset_test['rtf'] - dataset_test['cycle']\ndataset_test.drop('rtf', axis=1, inplace=True)\ndataset_test.head()","c077d24b":"dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max)-dataset_train['cycle']\ndataset_train.head()","f9e0d3b2":"df_train=dataset_train.copy()\ndf_test=dataset_test.copy()\nperiod=30\ndf_train['label_bc'] = df_train['ttf'].apply(lambda x: 1 if x <= period else 0)\ndf_test['label_bc'] = df_test['ttf'].apply(lambda x: 1 if x <= period else 0)\ndf_train.head()","2bc015c9":"features_col_name=['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n                   's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\ntarget_col_name='label_bc'","2bb387ad":"sc=MinMaxScaler()\ndf_train[features_col_name]=sc.fit_transform(df_train[features_col_name])\ndf_test[features_col_name]=sc.transform(df_test[features_col_name])","a9e6571a":"def gen_sequence(id_df, seq_length, seq_cols):\n    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n    id_df=df_zeros.append(id_df,ignore_index=True)\n    data_array = id_df[seq_cols].values\n    num_elements = data_array.shape[0]\n    lstm_array=[]\n    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n        lstm_array.append(data_array[start:stop, :])\n    return np.array(lstm_array)\n\n# function to generate labels\ndef gen_label(id_df, seq_length, seq_cols,label):\n    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n    id_df=df_zeros.append(id_df,ignore_index=True)\n    data_array = id_df[seq_cols].values\n    num_elements = data_array.shape[0]\n    y_label=[]\n    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n        y_label.append(id_df[label][stop])\n    return np.array(y_label)","4f3b978c":"# timestamp or window size\nseq_length=50\nseq_cols=features_col_name","50b2ae83":"# generate X_train\nX_train=np.concatenate(list(list(gen_sequence(df_train[df_train['id']==id], seq_length, seq_cols)) for id in df_train['id'].unique()))\nprint(X_train.shape)\n# generate y_train\ny_train=np.concatenate(list(list(gen_label(df_train[df_train['id']==id], 50, seq_cols,'label_bc')) for id in df_train['id'].unique()))\nprint(y_train.shape)","3c5d1c29":"# generate X_test\nX_test=np.concatenate(list(list(gen_sequence(df_test[df_test['id']==id], seq_length, seq_cols)) for id in df_test['id'].unique()))\nprint(X_test.shape)\n# generate y_test\ny_test=np.concatenate(list(list(gen_label(df_test[df_test['id']==id], 50, seq_cols,'label_bc')) for id in df_test['id'].unique()))\nprint(y_test.shape)","8105c901":"nb_features =X_train.shape[2]\ntimestamp=seq_length\n\nmodel = Sequential()\n\nmodel.add(LSTM(\n         input_shape=(timestamp, nb_features),\n         units=100,\n         return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(\n          units=50,\n          return_sequences=False))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","4d74fd22":"# fit the network\nmodel.fit(X_train, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n          callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])","1df85f3b":"# training metrics\nscores = model.evaluate(X_train, y_train, verbose=1, batch_size=200)\nprint('Accurracy: {}'.format(scores[1]))","561cef9a":"y_pred=model.predict_classes(X_test)\nprint('Accuracy of model on test data: ',accuracy_score(y_test,y_pred))\nprint('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))","6a912f77":"def prob_failure(machine_id):\n    machine_df=df_test[df_test.id==machine_id]\n    machine_test=gen_sequence(machine_df,seq_length,seq_cols)\n    m_pred=model.predict(machine_test)\n    failure_prob=list(m_pred[-1]*100)[0]\n    return failure_prob","a0115207":"machine_id=16\nprint('Probability that machine will fail within 30 days: ',prob_failure(machine_id))","fee00a55":"# LSTM For Predictive Maintenance","30730a20":"#### Loadind Truth table","a02635fc":"### Probability of Machine failure","e1fd04f1":"## Feature Scaling","58f38cb7":"## Function to reshape dataset as required by LSTM","60076fcc":"### Loading Libraries","7915cb06":"## LSTM Network","8c08a2b3":"### Loading Dataset"}}