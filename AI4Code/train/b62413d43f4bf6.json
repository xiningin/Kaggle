{"cell_type":{"e0a1d68d":"code","be87b7ba":"code","a599ec4a":"code","c715fc8a":"code","30883263":"code","e4b6ba6e":"code","20b3fdce":"code","0c5b6bfb":"code","cd71ed1f":"code","6bdec4c7":"code","a9214f57":"code","1ecb4277":"code","b9ae700c":"code","e46dcf1b":"code","e17bd402":"code","08511b79":"markdown","54f8b826":"markdown","bdef040a":"markdown","9bd551f2":"markdown","1e79dd4d":"markdown","39f0d021":"markdown","5afee88f":"markdown","c3f8423d":"markdown","d6dcba40":"markdown"},"source":{"e0a1d68d":"import tensorflow as tf\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.optimizers import *\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import *\n\nimport numpy as np\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n\n\n!echo \"All packages Successfully imported\"","be87b7ba":"(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n\nX_train = X_train.astype('float32')\/255.\nX_test = X_test.astype('float32') \/255.\n\nprint()\nprint(f\"Shape of Train Data: {X_train.shape}\")\nprint(f\"Shape of Test Data: {X_test.shape}\")","a599ec4a":"fashionMNIST_classes = {0:\"T-shirt\/top\", 1:\"Trouser\",\n                        2:\"Pullover\", 3:\"Dress\",\n                        4:\"Coat\", 5:\"Sandal\",\n                        6:\"Shirt\", 7:\"Sneaker\", \n                        8:\"Bag\", 9:\"Ankle boot\"}","c715fc8a":"n = 10\nplt.figure(figsize = (20, 4))\nfor i in range(n):\n    plt.subplot(1, n, i+1)\n    idx = np.random.randint(i, len(X_train))\n    plt.imshow(X_train[idx], cmap = 'binary')\n    plt.title(fashionMNIST_classes[y_train[idx]])\n    plt.gray()\n    plt.xticks([]); plt.yticks([])\nplt.show()","30883263":"img_shape = (28, 28, 1)\nlatent_dim = 10\nbatch_size = 16\nepsilon_std = 1.0\n\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape = (batch_size, latent_dim),\n                            mean = 0.0,\n                            stddev = epsilon_std\n                            )\n    return z_mean + K.exp(z_log_var\/2)*epsilon","e4b6ba6e":"def build_encoder():\n    ip = Input(shape = img_shape)\n    hl = Flatten()(ip)\n    hl = Dense(512, kernel_initializer='he_uniform')(hl)\n    hl = LeakyReLU(alpha = 0.2)(hl)\n    hl = Dense(512, kernel_initializer='he_uniform')(hl)\n    hl = LeakyReLU(alpha = 0.2)(hl)\n    mu = Dense(latent_dim)(hl)\n    log_var = Dense(latent_dim)(hl)\n    z = Lambda(sampling, output_shape = (latent_dim), name = \"latent_rep\")([mu, log_var])\n    return Model(ip, z, name = \"Encoder\")\n","20b3fdce":"def build_decoder():\n    model = Sequential()\n    model.add(Dense(512, input_dim = latent_dim))\n    model.add(LeakyReLU(alpha = 0.2))\n    model.add(Dense(512, kernel_initializer='he_uniform'))\n    model.add(LeakyReLU(alpha = 0.2))\n    model.add(Dense(np.prod(img_shape), activation = 'tanh'))\n    model.add(Reshape(img_shape))\n    print(model.summary())\n    \n    z = Input(shape = latent_dim)\n    img = model(z)\n\n    return Model(inputs = z, outputs = img, name = \"Decoder\")","0c5b6bfb":"def build_discriminator():\n    model = Sequential()\n    model.add(Dense(1024, input_dim = latent_dim))\n    model.add(LeakyReLU(alpha = 0.2))\n    model.add(Dense(512, kernel_initializer='he_uniform'))\n    model.add(LeakyReLU(alpha = 0.2))\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    print(model.summary())\n\n    enc_rep = Input(shape = (latent_dim))\n    validity = model(enc_rep)\n\n    return Model(enc_rep, validity, name = \"Discriminator\")","cd71ed1f":"optimizer = Adam(0.0002, 0.5)\n\n# Discriminator\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss = 'binary_crossentropy',\n                      optimizer = optimizer,\n                      metrics = ['accuracy'])\n\n# Encoder & Decoder\nencoder = build_encoder()\ndecoder = build_decoder()\n\nimg = Input(shape = img_shape)\n\nenc_rep = encoder(img)\nreconst_img = decoder(enc_rep)\n\n\ndiscriminator.trainable = False\nvalidity = discriminator(enc_rep)\n\naae = Model(img, [reconst_img, validity])\naae.compile(loss = ['mse', 'binary_crossentropy'],\n            loss_weights = [0.999, 0.001],\n            optimizer = optimizer)\n\naae.trainable = True","6bdec4c7":"def train(epochs, batch_size = 128, sample_interval = 50):\n    valid = np.ones((batch_size, 1))\n    fake = np.ones((batch_size, 1))\n    for epoch in range(epochs):\n\n        # Training Discriminator and Generator\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs = X_train[idx]\n\n        latent_fake = encoder.predict(imgs)\n        latent_real = np.random.normal(size = (batch_size, latent_dim))\n\n        d_loss_real = discriminator.train_on_batch(latent_real, valid)\n        d_loss_fake = discriminator.train_on_batch(latent_fake, fake)\n        d_loss = 1*np.add(d_loss_real, d_loss_fake)\n        \n        g_loss = aae.train_on_batch(imgs, [imgs, valid])\n\n        # Plotting the progress\n        if (epoch%sample_interval == 0):\n            print()\n            print(\"===============================\")\n            print(f\"EPOCH: {epoch}\")\n            print(\"===============================\")\n            print(f\"Discriminator Loss: {d_loss[0]}\")\n            print(f\"Accuracy: {round(100*d_loss[1])}\")\n            print(f\"Generator Loss: {g_loss[0]}\")\n            print(f\"MSE: {g_loss[1]}\")\n            sample_images(epoch)\n        \n        if (discriminator.trainable_variables == False):\n            discriminator.trainable = True\n            aae.trainable = False\n        elif (discriminator.trainable == True):\n            discriminator.trainable = False\n            aae.trainable = True\n\n","a9214f57":"def sample_images(epoch):\n    r, c = 5, 5\n    z = np.random.normal(size = (r*c, latent_dim))\n    gen_imgs = decoder.predict(z)\n    gen_imgs = 0.5*gen_imgs + 0.5\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap = plt.cm.binary)\n            axs[i, j].axis('off')\n            cnt += 1\n    plt.show();\n    fig.savefig(f\"fashionMnist_{epoch}.png\")\n    plt.close()\n","1ecb4277":"epochs = 6000\nsample_interval = 50\nsample_count = epochs\/sample_interval\n\n# Let the training Begins\ntrain(epochs = epochs, \n      batch_size = batch_size,\n      sample_interval=sample_interval)","b9ae700c":"if not os.path.exists(\".\/Images\"):\n    os.mkdir(\".\/Images\")\n\nimgs = []\nfor item in os.listdir(\".\/\"):\n    if item.endswith(\".png\"):\n        imgs.append(item)\n","e46dcf1b":"import shutil\n\nfor img in imgs:\n    shutil.move(f\".\/{img}\", f\".\/Images\/{img}\")","e17bd402":"import glob\nfrom PIL import Image\n\n# filepaths\nfp_in = \".\/Images\/fashionMnist_*.png\"\nfp_out = \".\/Images\/fashionMnist_AAE.gif\"\n\nimg, *imgs = [Image.open(f) for f in sorted(glob.glob(fp_in))]\nimg.save(fp=fp_out, format='GIF', append_images=imgs,\n         save_all=True, duration=1000, loop=0)","08511b79":"# Let the Training Begins\n## *You can see how the AAE is generating images from a random normal distribution*","54f8b826":"# Downloading Fashion MNIST Dataset","bdef040a":"# Importing Modules","9bd551f2":"\n# Creating a Sampling Function ","1e79dd4d":"# Building my first Adverserial Variational AutoEncoder\n<div align=\"center\"><img src=\"https:\/\/user-images.githubusercontent.com\/56304060\/110815395-67aa4880-82b0-11eb-9b6d-e62b6f4a8115.gif\" width=\"800px\" height=\"400px\"\/><\/div>\n","39f0d021":"# Function For Displaying training Results","5afee88f":"# Building Encoder, Decoder, Discriminator","c3f8423d":"# Building a Customized training Function","d6dcba40":"# Creating a GIF over the training results"}}