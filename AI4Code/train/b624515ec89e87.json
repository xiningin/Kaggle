{"cell_type":{"0238e52e":"code","93b5e483":"code","6ede077d":"code","d857abfd":"code","867d1cce":"code","b65c4b89":"code","61fc349f":"code","1607551d":"code","40c96aa4":"code","889173a5":"code","7825ffee":"code","9c7890f6":"code","d36f4f25":"markdown"},"source":{"0238e52e":"%config Completer.use_jedi = False","93b5e483":"import os\nimport datetime\nimport glob\nimport time\nimport cv2\nimport itertools\nfrom tqdm.notebook import tqdm\nimport shutil\n\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","6ede077d":"img_path = '..\/input\/gan-getting-started\/'\nmonet_path = glob.glob(img_path + 'monet_jpg\/*')\nphoto_path = glob.glob(img_path + 'photo_jpg\/*')\n\nprint('Dataset')\nprint(f'- monet data : {len(monet_path)}\\n- photo data : {len(photo_path)}')","d857abfd":"class Custom_dataset(Dataset):\n    def __init__(self, img_path : list , transforms = None, mode = 'train'):\n        super().__init__()\n\n        self.path_monet = img_path[0]\n        self.path_photo = img_path[1]\n        self.transforms = transforms\n        self.mode = mode\n        \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            monet_img = self.path_monet[idx]\n            monet_img = Image.open(monet_img).convert('RGB')\n            monet_img = self.transforms(monet_img)\n            \n            photo_idx = np.random.randint(0, len(self.path_photo))\n            photo_img = self.path_photo[photo_idx]\n            photo_img = Image.open(photo_img).convert('RGB')\n            photo_img = self.transforms(photo_img)\n            \n            return monet_img, photo_img\n\n        elif self.mode == 'test':\n            photo_img = self.path_photo[idx]\n            photo_img = Image.open(photo_img).convert('RGB')\n            photo_img = self.transforms(photo_img)\n            return photo_img    \n        \n    def __len__(self):\n        if self.mode == 'train':\n            return len(self.path_monet)\n        elif self.mode == 'test':\n            return len(self.path_photo)","867d1cce":"# Data loader\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], \n                                [0.5, 0.5, 0.5])\n])\n\ntest_dataset = Custom_dataset([monet_path, photo_path], transforms = transform, mode = 'test')\ntest_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)","b65c4b89":"# Define Conv Block\n'''\n1. Conv_up\n2. Conv_down\n3. Residual_block\n'''\n\n# 1.Conv_up\nclass Conv_up(nn.Module):\n    '''\n    convTranspose - instanceNorm - ReLU - (dropout)\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 4, stride = 2, \n                 padding = 1, output_padding = 1, drop_out = True):\n        super().__init__()\n        \n        self.convT = nn.ConvTranspose2d(in_ch, out_ch,\n                                       kernel_size = kernel_size,\n                                       stride = stride,\n                                       padding = padding,\n                                       output_padding = output_padding,\n                                       bias = False)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.drop_out = drop_out\n        \n    def forward(self, x):\n        x = self.convT(x)\n        x = self.instance_norm(x)\n        x = self.relu(x)\n        if self.drop_out:\n            x = nn.Dropout2d(0.5)(x)\n\n        return x\n\n# 2. Conv_down\nclass Conv_down(nn.Module):\n    '''\n    Conv2d - instanceNorm - LeakyReLU\n    '''\n    def __init__(self, in_ch, out_ch,\n                 kernel_size = 4,\n                 stride = 2,\n                 padding = 1,\n                 batch_Norm = True):\n        super().__init__()\n        \n        self.conv = nn.Conv2d(in_ch, out_ch,\n                             kernel_size = kernel_size,\n                             stride = stride,\n                             padding = padding,\n                             bias = True)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.batch = batch_Norm\n        \n    def forward(self, x):\n        x = self.conv(x)\n        if self.batch:\n            x = self.instance_norm(x)\n        x = self.relu(x)\n        \n        return x\n    \n# 3. Residual_block\nclass Residual_block(nn.Module):\n    '''\n    Conv2d - InstanceNorm - Relu - Conv2d - InstanceNorm\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 3, stride = 1, padding = 1):\n        super().__init__()\n        \n        self.res = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch),\n            nn.ReLU(),\n            nn.Conv2d(out_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch)\n        )\n    \n    def forward(self, x):\n        return x + self.res(x)\n","61fc349f":"class Generator(nn.Module):\n    '''\n    kernel   D64 - D128 - D256 - R256 * n - U128 - U64 - U3\n    filter   7x7 - 3x3  - 3x3  -          -  3x3 - 3x3 - 7x7\n    stride    1     2      2       1          2     2     1\n    '''\n    def __init__(self, n_features = 64, n_res = 9):\n        super().__init__()\n        \n        self.main = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            Conv_down(3, n_features, 7, 1, 0, False),\n            Conv_down(n_features * 1, n_features * 2, 3, 2),\n            Conv_down(n_features * 2, n_features * 4, 3, 2),\n            *[\n                Residual_block(n_features * 4, n_features * 4) for _ in range(n_res)\n            ],\n            Conv_up(n_features * 4, n_features * 2, 3, 2, 1),\n            Conv_up(n_features * 2, n_features * 1, 3, 2, 1),\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(n_features, 3, 7, 1, 0, bias = False),\n            nn.Tanh()   \n        )\n        \n    def forward(self, x):\n        x = self.main(x)\n        \n        return x","1607551d":"# load netG_B\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = torch.load('..\/input\/cyclegan-baseline\/model_G\/netG(uNet)_B100.pt').to(device)","40c96aa4":"def unNormalize(img, mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5]):\n    img = img[0].cpu().detach()\n    np_img = np.transpose(img.numpy(), (1, 2, 0))\n    np_img = np_img * std + mean\n    np_img = (np_img * 255).astype('uint8')\n    return np_img","889173a5":"!mkdir images","7825ffee":"for i, photo in tqdm(enumerate(test_loader), total = len(test_loader)):\n    with torch.no_grad():\n        photo = photo.to(device)\n        out = model(photo)\n        img = unNormalize(out)\n        img = Image.fromarray(img)\n        img.save('..\/working\/images\/' + str(i + 1) + '.jpg')","9c7890f6":"shutil.make_archive('..\/working\/images', 'zip', '..\/working\/images')","d36f4f25":"## Inference\n- photo -> monet"}}