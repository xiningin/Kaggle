{"cell_type":{"ddcf8b4b":"code","d2bf7925":"code","0310b859":"code","09bd3b00":"code","d8007a45":"code","998f123f":"code","18555a41":"code","83bb61fa":"code","55ac3f24":"code","f8bf12e2":"code","4b8cf5f7":"code","9b5c811b":"code","b6e429a0":"code","bb2d8fbf":"code","a6c76b67":"code","8d798797":"code","0f845e85":"code","5f6ebf28":"code","6d50a4ce":"code","4ec6f673":"code","0ded3fd5":"code","63350c44":"markdown","e738c8ff":"markdown","54cfb5dc":"markdown","88bb8b67":"markdown","1c9b91f5":"markdown","45e87416":"markdown","eb0517e4":"markdown","dffde25b":"markdown","d800e299":"markdown","33c435f7":"markdown","62d39d13":"markdown"},"source":{"ddcf8b4b":"debug=True   # use 10% sampling data for debug mode","d2bf7925":"import os\n!pip install ..\/input\/nfllibs\/bounded_pool_executor-0.0.3-py3-none-any.whl\n!pip install ..\/input\/nfllibs\/pqdm-0.1.0-py2.py3-none-any.whl\n!pip install ..\/input\/nfllibs\/progress-1.6\/progress-1.6\n!pip install ..\/input\/nfllibs\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar\n!pip install ..\/input\/nfllibs\/filterpy-1.4.5\/filterpy-1.4.5","0310b859":"from PIL import Image\nfrom matplotlib import pyplot as plt\nfrom multiprocessing import Pool, cpu_count\nfrom pqdm.processes import pqdm\nfrom scipy.spatial import distance\nfrom tqdm.auto import tqdm\nimport cv2\nimport glob\nimport itertools\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport torch\ntqdm.pandas()","09bd3b00":"# based on https:\/\/www.kaggle.com\/go5kuramubon\/merge-label-and-tracking-data\nSAVE_DIR = '..\/train_images'\nBASE_DIR = '..\/input\/nfl-health-and-safety-helmet-assignment'\ndef add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) \/ 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\n\ndef add_cols(df):\n    df['frame'] = df['video_frame'].str.split('_').str[-1].astype(int)\n    df['playID'] = df['video_frame'].str.split('_').str[1].astype(int)\n    df['view'] = df['video_frame'].str.split('_').str[2]\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\ndef merge_label_and_tracking(tracking_df, label_df):\n    tracking_with_game_index = tracking_df.set_index([\"gameKey\", \"playID\", \"player\"])\n    df_list = []\n    for key, _label_df in tqdm(label_df.groupby([\"gameKey\", \"playID\", \"view\", \"label\"])):\n        # skip because there are sideline player\n        if key[3] == \"H00\" or key[3] == \"V00\":\n            continue\n        tracking_data = tracking_with_game_index.loc[(key[0], key[1], key[3])]\n        _label_df = _label_df.sort_values(\"frame\")\n        # merge with frame and est_frame\n        merged_df = pd.merge_asof(\n            _label_df,\n            tracking_data,\n            left_on=\"frame\",\n            right_on=\"est_frame\",\n            direction='nearest',\n        )\n        df_list.append(merged_df)\n    all_merged_df = pd.concat(df_list)\n    all_merged_df = all_merged_df.sort_values([\"video_frame\", \"label\"], ignore_index=True)\n    \n    return all_merged_df\n\ndef compute_overlap(boxes, query_box):\n    #'XMin', 'YMin', 'XMax', 'YMax'\n    N = boxes.shape[0]\n    overlaps = np.zeros((N), dtype=np.float64)\n    box_area = (\n        (query_box[2] - query_box[0]) *\n        (query_box[3] - query_box[1])\n    )\n    for n in range(N):\n        iw = (\n            min(boxes[n, 2], query_box[2]) -\n            max(boxes[n, 0], query_box[0])\n        )\n        if iw > 0:\n            ih = (\n                min(boxes[n, 3], query_box[3]) -\n                max(boxes[n, 1], query_box[1])\n            )\n            if ih > 0:\n                ua = np.float64(\n                    (boxes[n, 2] - boxes[n, 0]) *\n                    (boxes[n, 3] - boxes[n, 1]) +\n                    box_area - iw * ih\n                )\n                overlaps[n] = iw * ih \/ ua\n    return overlaps\n\ndef add_xy(df):\n    \"\"\"\n    Adds `x1`, `x2`, `y1`, and `y2` columns necessary for computing IoU.\n\n    Note - for pixel math, 0,0 is the top-left corner so box orientation\n    defined as right and down (height)\n    \"\"\"\n    df[\"x1\"] = df[\"left\"]\n    df[\"x2\"] = df[\"left\"] + df[\"width\"]\n    df[\"y1\"] = df[\"top\"]\n    df[\"y2\"] = df[\"top\"] + df[\"height\"]\n    return df\n\ndef set_counts_columns(df, tgt, dummy):\n    mapping_df = df[[tgt,dummy]].groupby(tgt).count().reset_index().rename(columns={dummy:f'{tgt}_counts'})\n    mapping_dict = mapping_df.set_index(tgt).to_dict()[f'{tgt}_counts']\n    df[f'{tgt}_counts'] = df[tgt].map(mapping_dict)\n    return df, mapping_df\n\n\nlabels = pd.read_csv(f'{BASE_DIR}\/train_labels.csv')\ntracking = pd.read_csv(f'{BASE_DIR}\/train_player_tracking.csv')\ntracking = add_track_features(tracking)\nlabels = add_cols(labels)\nlabels = merge_label_and_tracking(tracking, labels)\nlabels['team'] = labels['label'].str[0].map({'H':0, 'V':1})\nlabels = add_xy(labels)\nlabels = labels[~(labels.frame == 0)]\nlabels, mapping_df = set_counts_columns(labels, 'video_frame', 'left')\nlabels = labels.reset_index()\ntracking = tracking.reset_index()","d8007a45":"# 4-fold CV\ncv_video = [\n{'57584_000336_Endzone.mp4', '57584_000336_Sideline.mp4', '57584_002674_Endzone.mp4', '57584_002674_Sideline.mp4', '57594_000923_Endzone.mp4', '57594_000923_Sideline.mp4', '57682_002630_Endzone.mp4', '57682_002630_Sideline.mp4', '57684_001985_Endzone.mp4', '57684_001985_Sideline.mp4', '57787_003413_Endzone.mp4', '57787_003413_Sideline.mp4', '57905_002404_Endzone.mp4', '57905_002404_Sideline.mp4', '57906_000718_Endzone.mp4', '57906_000718_Sideline.mp4', '57907_003615_Endzone.mp4', '57907_003615_Sideline.mp4', '57910_001164_Endzone.mp4', '57910_001164_Sideline.mp4', '57913_000218_Endzone.mp4', '57913_000218_Sideline.mp4', '57915_003093_Endzone.mp4', '57915_003093_Sideline.mp4', '58048_000086_Endzone.mp4', '58048_000086_Sideline.mp4', '58098_001193_Endzone.mp4', '58098_001193_Sideline.mp4'},\n{'57676_003572_Endzone.mp4', '57676_003572_Sideline.mp4', '57775_000933_Endzone.mp4', '57775_000933_Sideline.mp4', '57778_004244_Endzone.mp4', '57778_004244_Sideline.mp4', '57781_000252_Endzone.mp4', '57781_000252_Sideline.mp4', '57783_003374_Endzone.mp4', '57783_003374_Sideline.mp4', '57911_000147_Endzone.mp4', '57911_000147_Sideline.mp4', '57911_002492_Endzone.mp4', '57911_002492_Sideline.mp4', '57912_001325_Endzone.mp4', '57912_001325_Sideline.mp4', '57992_000301_Endzone.mp4', '57992_000301_Sideline.mp4', '57992_000350_Endzone.mp4', '57992_000350_Sideline.mp4', '57993_000475_Endzone.mp4', '57993_000475_Sideline.mp4', '58093_001923_Endzone.mp4', '58093_001923_Sideline.mp4', '58094_000423_Endzone.mp4', '58094_000423_Sideline.mp4', '58094_002819_Endzone.mp4', '58094_002819_Sideline.mp4', '58102_002798_Endzone.mp4', '58102_002798_Sideline.mp4', '58104_000352_Endzone.mp4', '58104_000352_Sideline.mp4'},\n{'57596_002686_Endzone.mp4', '57596_002686_Sideline.mp4', '57679_003316_Endzone.mp4', '57679_003316_Sideline.mp4', '57686_002546_Endzone.mp4', '57686_002546_Sideline.mp4', '57700_001264_Endzone.mp4', '57700_001264_Sideline.mp4', '57782_000600_Endzone.mp4', '57782_000600_Sideline.mp4', '57785_002026_Endzone.mp4', '57785_002026_Sideline.mp4', '57790_002792_Endzone.mp4', '57790_002792_Sideline.mp4', '57790_002839_Endzone.mp4', '57790_002839_Sideline.mp4', '57904_001367_Endzone.mp4', '57904_001367_Sideline.mp4', '57997_003691_Endzone.mp4', '57997_003691_Sideline.mp4', '57998_002181_Endzone.mp4', '57998_002181_Sideline.mp4', '58005_001254_Endzone.mp4', '58005_001254_Sideline.mp4', '58005_001612_Endzone.mp4', '58005_001612_Sideline.mp4', '58107_004362_Endzone.mp4', '58107_004362_Sideline.mp4'},\n{'57583_000082_Endzone.mp4', '57583_000082_Sideline.mp4', '57586_000540_Endzone.mp4', '57586_000540_Sideline.mp4', '57586_001934_Endzone.mp4', '57586_001934_Sideline.mp4', '57586_004152_Endzone.mp4', '57586_004152_Sideline.mp4', '57597_000658_Endzone.mp4', '57597_000658_Sideline.mp4', '57597_001242_Endzone.mp4', '57597_001242_Sideline.mp4', '57680_002206_Endzone.mp4', '57680_002206_Sideline.mp4', '57680_003470_Endzone.mp4', '57680_003470_Sideline.mp4', '57784_001741_Endzone.mp4', '57784_001741_Sideline.mp4', '57786_003085_Endzone.mp4', '57786_003085_Sideline.mp4', '57788_000781_Endzone.mp4', '57788_000781_Sideline.mp4', '57995_000109_Endzone.mp4', '57995_000109_Sideline.mp4', '58000_001306_Endzone.mp4', '58000_001306_Sideline.mp4', '58095_004022_Endzone.mp4', '58095_004022_Sideline.mp4', '58103_003494_Endzone.mp4', '58103_003494_Sideline.mp4', '58106_002918_Endzone.mp4', '58106_002918_Sideline.mp4'}\n]\nfor f in range(4):\n    labels.loc[labels['video'].isin(cv_video[f]), 'fold'] = f\nlabels['fold'] = labels['fold'].astype(int)","998f123f":"if debug:\n    labels =labels[labels.frame%10==1]\nlabels.shape","18555a41":"# based on https:\/\/www.kaggle.com\/its7171\/nfl-baseline-simple-helmet-mapping\ndef norm_arr_1dim(a):   \n    a = a-a.min()\n    max_a = a.max()\n    if max_a == 0:\n        print('max_a is 0')\n    else:\n        a = a\/max_a\n    return a, max_a\n\ndef norm_arr(a):\n    a[:,0], scale0 = norm_arr_1dim(a[:,0])\n    a[:,1], scale1 = norm_arr_1dim(a[:,1])\n    return a, scale0, scale1\n\ndef dist(a1, a2):\n    #print(a1)\n    #print(a2)\n    distx = np.sum(np.abs(a1[:,0]-a2[:,0]))\n    disty = np.sum(np.abs(a1[:,1]-a2[:,1]))\n    return distx + disty\n\ndef rotate_arr(u, t, pt, w, h, aspect_ratio=(1,1), debug=False):\n    xscale, yscale = aspect_ratio[0], aspect_ratio[1]\n    if xscale > yscale:\n        yscale \/= xscale\n        xscale = 1\n    else:\n        xscale \/= yscale\n        yscale = 1\n    aspect_ratio = (xscale, yscale)\n\n    rot_center_x = w*xscale\/2\n    rot_center_y = w*yscale\/2\n    R_rot = cv2.getRotationMatrix2D((rot_center_x, rot_center_y), t, 1)\n    \n    if pt > 1:\n        pt = 1 \/ pt\n        src_pts = np.array([[0, 0], [0+int(w*(1-pt)\/2), h], [w-int(w*(1-pt)\/2), h], [w, 0]], dtype=np.float32)\n        dst_pts = np.array([[0, 0], [0, h], [w, h], [w, 0]], dtype=np.float32);\n    else:\n        src_pts = np.array([[0, 0], [0, h], [w, h], [w, 0]], dtype=np.float32)\n        dst_pts = np.array([[0, 0], [0+int(w*(1-pt)\/2), h], [w-int(w*(1-pt)\/2), h], [w, 0]], dtype=np.float32)\n    R_pt = cv2.getPerspectiveTransform(src_pts, dst_pts)\n\n    if debug:\n        print('R_rot', R_rot, t)\n        print('R_pt', R_pt, pt, w, h, [0+w*pt, 0], [w-w*pt, 0])\n        print('src_pts',src_pts)\n        print('dst_pts',dst_pts)\n    \n    u = u.T\n    # Trapezoidal correction\n    u = np.vstack([u,np.ones(u.shape[1])])\n    u = np.dot(R_pt, u)\n    u = u[:2,:]\/u[2,:]\n    # aspect ratio\n    u = u*np.expand_dims(aspect_ratio, axis=1)\n    #\u3000rotate\n    u = np.vstack([u,np.ones(u.shape[1])])\n    u = np.dot(R_rot, u)\n    return  u.T\n\ndef dist_rot(helmets):\n    a2_org = helmets[['center_x','center_y']].values.astype(float)#predicted BB\n    a2_min = np.min(a2_org, axis=0)\n    a2_max = np.max(a2_org, axis=0)\n    a2_len = a2_max - a2_min\n    a2,a2scl0,a2scl1 = norm_arr(a2_org)\n    a1 = helmets[['gt_x','gt_y']].values.astype(float)\n    min_dist = 1000000\n    mean_x = a1[0].mean()\n    if helmets['Endzone'].values[0]:\n        w = 53.3\n        h = 120\n    else:\n        w = 120\n        h = 53.3\n    for dig in range(-DIG_MAX,DIG_MAX+1,DIG_STEP):\n        for x_pt in np.arange(1.0, 1.8, 0.1):\n            a1_rot = rotate_arr(a1, dig, 1, 1280, 720).copy()\n            a1_min = np.min(a1_rot, axis=0)\n            a1_max = np.max(a1_rot, axis=0)\n            a1_len = a1_max - a1_min\n            a1_rot_rescale = (a1_rot-a1_min)*a2_len\/a1_len + a2_min \n            a1_rot2 = rotate_arr(a1_rot_rescale, 0, x_pt, 1280, 720).copy()\n            a1_rot,a1scl0,a1scl1 = norm_arr(a1_rot2)\n            this_dist = dist(a1_rot, a2.copy())\n            if min_dist > this_dist:\n                min_dist = this_dist\n                min_rot = dig\n                min_pt = x_pt\n                min_scl0 = a1scl0\n                min_scl1 = a1scl1\n                min_a1_rot = a1_rot.copy()\n    helmets['dist0'] = min_dist\n    helmets['rot0'] = min_rot\n    helmets['pt0'] = min_pt\n    helmets['a1scl0'] = min_scl0\n    helmets['a1scl1'] = min_scl1\n    helmets['x_rot0'] = min_a1_rot[:,0]\n    helmets['y_rot0'] = min_a1_rot[:,1]\n    helmets['x_org0'] = a1[:,0]\n    helmets['y_org0'] = a1[:,1]\n    return min_dist, helmets\n\ndef mapping_df(args):\n    video_frame, df = args\n    gameKey,playID,view,frame = video_frame.split('_')\n    gameKey = int(gameKey)\n    playID = int(playID)\n    frame = int(frame)\n    this_tracking = df\n    len_this_tracking = len(this_tracking)\n    df['center_x'] = (df['left']+df['width']\/2).astype(int)\n    df['center_y'] = (df['top']+df['height']\/2).astype(int)\n    df_a = df.copy()\n    df_h = df.copy()\n    \n    if view == 'Endzone':\n        # Endzone Home\n        df_h['Endzone'] = True\n        df_h['Home'] = True\n        df_h['gt_x'] = 53.3 - df_h['y'].copy()\n        df_h['gt_y'] = 120  - df_h['x'].copy()\n        # Endzone Visitor\n        df_a['Endzone'] = True\n        df_a['Home'] = False\n        df_a['gt_x'] = df_a['y'].copy()\n        df_a['gt_y'] = df_a['x'].copy()\n    else:\n        # Sideline Home\n        df_h['Endzone'] = False\n        df_h['Home'] = True\n        df_h['gt_x'] = df_h['x'].copy()\n        df_h['gt_y'] = 53.3 - df_h['y'].copy()\n        # Sideline Visitor\n        df_a['Endzone'] = False\n        df_a['Home'] = False\n        df_a['gt_x'] = 120  - df_a['x'].copy()\n        df_a['gt_y'] = df_a['y'].copy()\n\n    min_dist_a, df_a = dist_rot(df_a)\n    min_dist_h, df_h = dist_rot(df_h)\n    if min_dist_a < min_dist_h:\n        tgt_df = df_a\n    else:\n        tgt_df = df_h\n    return tgt_df","83bb61fa":"multi_thread_type = 'pqdm'\n#multi_thread_type = 'none'\n#multi_thread_type = 'pool'\nDIG_STEP = 1 \nDIG_MAX = 80\nlabels = labels[labels.frame != 0]\n\nif multi_thread_type == 'pqdm':\n    df_list = list(labels.groupby('video_frame'))\n    submission_df_list = pqdm(df_list, mapping_df, n_jobs=cpu_count())\nelif multi_thread_type == 'pool':\n    p = Pool(processes=cpu_count())\n    submission_df_list = []\n    df_list = list(labels.groupby('video_frame'))\n    with tqdm(total=len(df_list)) as pbar:\n        for this_df in p.imap(mapping_df, df_list):\n            submission_df_list.append(this_df)\n            pbar.update(1)\n    p.close()\nelse:\n    submission_df_list = []\n    df_list = list(labels.groupby('video_frame'))\n    with tqdm(total=len(df_list)) as pbar:\n        for args in df_list:\n            #print(args[0])\n            this_df = mapping_df(args)\n            submission_df_list.append(this_df)\n            pbar.update(1)\n\nlabels =  pd.concat(submission_df_list)","55ac3f24":"labels.dist0.hist(bins=100)","f8bf12e2":"labels.rot0.hist(bins=100)","4b8cf5f7":"# Some players are oriented the other way, so we'll fix that.\n# Adjust the angle according to (Endzone or Sideline) and (Home or Visitor)\n\ndef fix_bad_data(labels, tgt_col = 'o'):\n    labels['HorV'] = labels['label'].str[0]\n    labels['gamePlay_label'] = labels['video'].str.rsplit('_').str[0] + '_' + labels['label']\n    labels[\"team_o_mean\"] = labels.groupby([\"video_frame\",\"HorV\"])[tgt_col].transform(\"mean\")\n    labels[\"diff_o_vs_team\"] = np.abs(labels[tgt_col] - labels[\"team_o_mean\"])\n    labels.loc[labels[\"diff_o_vs_team\"]>180, \"diff_o_vs_team\"] = np.abs(labels.loc[labels[\"diff_o_vs_team\"]>180, \"diff_o_vs_team\"] - 360)\n    labels[\"same_direction_vs_team\"] = labels[\"diff_o_vs_team\"] < 100\n    bad_data = labels[(labels['frame']==1)&(labels.same_direction_vs_team==False)]['gamePlay_label'].unique()\n    new_tgt_col = tgt_col + '_fixed'\n    labels[new_tgt_col] = labels[tgt_col]\n    labels.loc[labels[\"gamePlay_label\"].isin(bad_data), new_tgt_col] -= 180\n    labels.loc[labels[new_tgt_col] < 0, new_tgt_col] += 360\n    \n    labels.loc[(labels['Endzone']==True)&(labels['Home']==True), new_tgt_col] = labels.loc[(labels['Endzone']==True)&(labels['Home']==True), new_tgt_col]-180\n    labels.loc[(labels['Endzone']==True)&(labels['Home']==False), new_tgt_col] = labels.loc[(labels['Endzone']==True)&(labels['Home']==False), new_tgt_col]\n    labels.loc[(labels['Endzone']==False)&(labels['Home']==True), new_tgt_col] = labels.loc[(labels['Endzone']==False)&(labels['Home']==True), new_tgt_col]-90\n    labels.loc[(labels['Endzone']==False)&(labels['Home']==False), new_tgt_col] = labels.loc[(labels['Endzone']==False)&(labels['Home']==False), new_tgt_col]-270\n    labels.loc[labels[new_tgt_col]<-180, new_tgt_col] += 360\n    labels.loc[labels[new_tgt_col]>180, new_tgt_col] -= 360\n\n    return labels\nlabels = fix_bad_data(labels, tgt_col = 'o')","9b5c811b":"# calculate the difference between the helmet and the sensor\n# how many times the helmet size is off after rotation\ndef calc_xy_diff(df):\n    dig = df.rot0.values[0]\n    x_pt = df.pt0.values[0]\n    \n    a2 = df[['center_x','center_y']].values.astype(float)\n    a2_min = np.min(a2, axis=0)\n    a2_max = np.max(a2, axis=0)\n    a2_len = a2_max - a2_min\n\n    a1 = df[['gt_x','gt_y']].values.astype(float)\n    a1_rot = rotate_arr(a1, dig, 1, 1280, 720).copy()\n    a1_min = np.min(a1_rot, axis=0)\n    a1_max = np.max(a1_rot, axis=0)\n    a1_len = a1_max - a1_min\n    a1_rot_rescale = (a1_rot-a1_min)*a2_len\/a1_len + a2_min \n    a1_rot2 = rotate_arr(a1_rot_rescale, 0, x_pt, 1280, 720).copy()\n\n    a1_min = np.min(a1_rot2, axis=0)\n    a1_max = np.max(a1_rot2, axis=0)\n    a1_len = a1_max - a1_min\n    a1_rot2_rescale = (a1_rot2-a1_min)*a2_len\/a1_len + a2_min \n    \n    xy_diff = a1_rot2_rescale - a2\n    # normalize using mean helmet size\n    xy_diff[:,0] = xy_diff[:,0] \/  df['width'].mean()\n    xy_diff[:,1] = xy_diff[:,1] \/  df['height'].mean()\n        \n    return xy_diff\n\n\nresult = []\nfor video_frame, df in tqdm(labels.groupby('video_frame')):\n    xy_diff = calc_xy_diff(df)\n    df['xdiff'] = xy_diff[:,0]\n    df['ydiff'] = xy_diff[:,1]\n    result.append(df)\nlabels = pd.concat(result)","b6e429a0":"labels['alpha'] = labels['o_fixed'] - labels['rot0']\nlabels.loc[labels['alpha']<-180, 'alpha'] += 360\nlabels.loc[labels['alpha']>180, 'alpha'] -= 360\nlabels['beta'] = labels['dir'] - labels['rot0']\nlabels.loc[labels['beta']<-180, 'beta'] += 360\nlabels.loc[labels['beta']>180, 'beta'] -= 360","bb2d8fbf":"norm_dict = {'xdiff': {'mean': 0, 'var': 1.0, 'max': 5.0, 'min': -5.0},\n             'ydiff': {'mean': 0, 'var': 1.0, 'max': 5.0, 'min': -5.0},\n             's': {'mean': 1.0, 'var': 2.0, 'max': 10.0, 'min': -1.0},\n             'a': {'mean': 1.0, 'var': 2.0, 'max': 10.0, 'min': -1.0},\n             'dis': {'mean': 0.1, 'var': 0.2, 'max': 1.0, 'min': -1.0},\n            }\nfor lbl in ['xdiff', 'ydiff','s','a','dis','alpha','beta']:\n    print(lbl)\n    labels[lbl].hist(bins=100)\n    plt.show()\n    if lbl in norm_dict:\n        labels.loc[labels[lbl]>norm_dict[lbl]['max'], lbl] = norm_dict[lbl]['max']\n        labels.loc[labels[lbl]<norm_dict[lbl]['min'], lbl] = norm_dict[lbl]['min']\n        labels[lbl] -= norm_dict[lbl]['mean']\n        labels[lbl] \/= norm_dict[lbl]['var']\n    labels[lbl].hist(bins=100)\n    plt.show()","a6c76b67":"# based on https:\/\/www.kaggle.com\/bamps53\/create-coco-format-annotations-train-val\n\nclass NumpyEncoder(json.JSONEncoder):\n    \"\"\" \n    https:\/\/stackoverflow.com\/questions\/26646362\/numpy-array-is-not-json-serializable\n    Special json encoder for numpy types\n    \"\"\"\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n\nclass COCOConverter:\n    \"\"\"Class to convert competition csv to coco format.\"\"\"\n    def __init__(\n        self,\n        df: pd.DataFrame, \n        image_height: int = 720, \n        image_width: int = 1280, \n        type_agnostic: bool = True):\n        \n        self.image_height = image_height\n        self.image_width = image_width\n        self.type_agnostic = type_agnostic\n        if self.type_agnostic:\n            self.categories = [{\"id\": 1, \"name\": \"Helmet\"}]\n        else:\n            self.categories = [\n                {\"id\": 1, \"name\": \"impact_None\",},\n                {\"id\": 2, \"name\": \"impact_Helmet\"},\n                {\"id\": 3, \"name\": \"impact_Shoulder\",},\n                {\"id\": 4, \"name\": \"impact_Body\"},\n                {\"id\": 5, \"name\": \"impact_Ground\",},\n                {\"id\": 6, \"name\": \"impact_Hand\"},\n            ]         \n        self.df = self._initialize(df)\n\n    def _get_file_name(self, row: pd.Series):\n        base_name = row.video[:-4]\n        file_name = f'{base_name}_frame{row.frame:04}.jpg'\n        return file_name\n\n    def _get_bbox(self, row: pd.Series):\n        return [row.left, row.top, row.width, row.height]\n\n    def _initialize(self, df: pd.DataFrame):\n        # set category id\n        if self.type_agnostic:\n            df['impactType'] = 'Helmet'\n            df['category_id'] = 1\n        else:\n            df['category_id'] = df['impactType'].map(\n                {\n                    'None': 1,\n                    'Helmet': 2,\n                    'Shoulder': 3,\n                    'Body': 4,\n                    'Ground': 5,\n                    'Hand': 6\n                }\n            )\n        # some preprocesses\n        df['file_name'] = df[['video', 'frame']].progress_apply(self._get_file_name, axis=1)\n        df['area'] = df['width'] * df['height']\n        df['bbox'] = df[['left', 'top', 'width', 'height']].progress_apply(self._get_bbox, axis=1)\n        df['iscrowd'] = 0\n        return df\n        \n\n    def save(self, save_path):\n        \"\"\"\n        Save as coco json format.\n        But also has many supplemental items like gameKey or view.\n        \"\"\"\n        df = self.df.copy()\n        image_df = df[['gameKey', 'playID', 'view', 'video', 'frame', 'file_name']].drop_duplicates()\n        image_df['height'] = self.image_height\n        image_df['width'] = self.image_width\n        \n        # add image id to images. Note that it's called just \"id\".\n        image_df['id'] = range(1, len(image_df) + 1)\n    \n        # add image id to annotations.\n        df['image_id'] = df[['file_name']].merge(image_df[['file_name', 'id']])['id'].values\n        df['id'] = range(1, len(df) + 1)\n\n        print('start dumping...')\n        coco_annotations = dict()\n        coco_annotations['categories'] = self.categories\n        coco_annotations['images'] = [dict(row) for _, row in image_df.iterrows()]\n        coco_annotations['annotations'] = [dict(row) for _, row in df.iterrows()]\n        json.dump(coco_annotations, open(save_path, 'w'), indent=4, cls=NumpyEncoder)","8d798797":"!mkdir -p ..\/work\ndf = labels[['video_frame','gameKey','playID','view','video','frame','label','left','width','top','height','impactType','isDefinitiveImpact','isSidelinePlayer','alpha','beta','xdiff','ydiff','x', 'y', 's', 'a', 'dis', 'o', 'dir', 'fold']]\nPH='ph5'\ntrain_coco = COCOConverter(df.copy(), type_agnostic=True)\ntrain_coco.save(f'..\/work\/coco_train_full_{PH}.json')\n\nfor fold in range(4):\n    train_df = df[df['fold']!=fold].reset_index(drop=True).copy()\n    valid_df = df[df['fold']==fold].reset_index(drop=True).copy()\n    print('number of train annotations:', len(train_df))\n    print('number of valid annotations:', len(valid_df))\n    train_coco = COCOConverter(train_df, type_agnostic=True)\n    train_coco.save(f'..\/work\/coco_train_fold{fold}_{PH}.json')\n    valid_coco = COCOConverter(valid_df, type_agnostic=True)\n    valid_coco.save(f'..\/work\/coco_valid_fold{fold}_{PH}.json')","0f845e85":"# https:\/\/www.kaggle.com\/bamps53\/create-image-dataset\ndef split_to_images(video_path):\n    video_name = os.path.basename(video_path).split('.')[0]\n    cam = cv2.VideoCapture(video_path)\n    frame_count = 1 # To make it consistant with train_labels.csv\n    while True:\n        successed, img = cam.read()\n        if not successed:\n            break\n        if debug == False or (frame_count % 10 == 1):\n            save_name = f'{SAVE_DIR}\/{video_name}_frame{frame_count:04}.jpg'\n            cv2.imwrite(save_name, img)\n        frame_count += 1\n\nos.makedirs(SAVE_DIR, exist_ok=True)\nvideo_paths = sorted(glob.glob('..\/input\/nfl-health-and-safety-helmet-assignment\/train\/*'))\nnum_cpu = cpu_count()\npool = Pool(num_cpu)\nwith tqdm(total=len(video_paths)) as t:\n    for _ in pool.imap_unordered(split_to_images, video_paths):\n        t.update(1)\npool.close()\npool.terminate()","5f6ebf28":"!mkdir -p \/kaggle\/centernet\n%cd \/kaggle\/centernet\n\n!tar xfz ..\/input\/nfllibs\/centernet.tgz\n%cd src\/lib\/models\/networks\/DCNv2\n!python3 setup.py build develop > \/dev\/null 2>&1\n%cd \/kaggle\/centernet\/src\/lib\/external\n!make > \/dev\/null 2>&1\n%cd \/kaggle\/working","6d50a4ce":"%cd \/kaggle\/centernet\/src\n\nn_fold = 4\nif debug:\n    n_fold = 1\n\nfor fold in range(n_fold):\n    !python main.py ctdet --exp_id nfl_ph5_fold{fold} --batch_size 4 --lr 0.156e-4  --gpus 0 --split_train ..\/..\/work\/coco_train_fold{fold}_ph5.json --split_val ..\/..\/work\/coco_valid_fold{fold}_ph5.json --save_all --num_epochs 5 --val_intervals 1\n# using full data, so validation can not be trusted for full model.\n!python main.py ctdet --exp_id nfl_ph5_full        --batch_size 4 --lr 0.156e-4  --gpus 0 --split_train ..\/..\/work\/coco_train_full_ph5.json --split_val        ..\/..\/work\/coco_valid_fold0_ph5.json       --save_all --num_epochs 5 --val_intervals 1\n\nfor fold in range(n_fold):\n    !python test.py ctdet --exp_id nfl_ph5_fold{fold} --keep_res --load_model ..\/exp\/ctdet\/nfl_ph5_fold{fold}\/model_5.pth --flip_test --split_test ..\/..\/work\/coco_valid_fold{fold}_ph5.json --K 50\n!python test.py ctdet --exp_id nfl_ph5_full        --keep_res --load_model ..\/exp\/ctdet\/nfl_ph5_full\/model_5.pth        --flip_test --split_test ..\/..\/work\/coco_train_full_ph5.json --K 50\n%cd \/kaggle\/working","4ec6f673":"# result weight file for full model\n!ls -Rl \/kaggle\/centernet\/exp\/ctdet\/nfl_ph5_full\/model_5.pth","0ded3fd5":"def add_bb_to_image(image, boxes, txt=None, color=(0, 255, 0)):\n    for idx, box in enumerate(boxes.astype(int)):\n        #print(len(box.shape))\n        if len(box) == 2:\n            box = box.copy()\n            box -= 5\n            w = 10\n            h = 10\n        else:\n            w = box[2]\n            h = box[3]\n        cv2.rectangle(image, (box[0], box[1]), (box[0]+w,  box[1]+h), color, 2)\n        if txt is not None:\n            cv2.putText(\n                image,\n                f\"{txt[idx]}\",\n                (box[0], box[1]),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.7,\n                color,\n                thickness=1,\n            )\n        \ndef add_arrow_dgree(image, boxes, alpha, len_arrow = 30, color=(0, 255, 0)):\n    ooffset = [np.cos(np.deg2rad(alpha)), np.sin(np.deg2rad(alpha))]\n    o_point = boxes[:,:2]+len_arrow*np.array(ooffset).T\n    for box, o in zip(boxes[:,:2].astype(int), o_point.astype(int)):\n        cv2.arrowedLine(image, (box[0], box[1]), (o[0],  o[1]), color, 2)\n\nprint('GT label:')\nvideo_frame = '57584_000336_Endzone_101'\nvideo = video_frame.rsplit('_',1)[0].replace('.mp4','')\nframe = int(video_frame.rsplit('_',1)[1])\nimg = cv2.imread(f\"..\/train_images\/{video}_frame{frame:04}.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ndf = labels[labels.video_frame==video_frame].copy().reset_index(drop=True)\nboxes = df[['left','top','width','height']].values\narrow_arr = df['alpha']\nadd_bb_to_image(img, boxes, color=(0, 255, 0))\nadd_arrow_dgree(img, boxes, arrow_arr, color=(255, 64, 64))\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(img)\nplt.show()\n\nprint('predicted:')\nimg = cv2.imread(f\"..\/train_images\/{video}_frame{frame:04}.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nhelmets = pd.read_csv('\/kaggle\/centernet\/exp\/ctdet\/nfl_ph5_fold0\/coco_valid_fold0_ph5.json.csv')\ndf = helmets[helmets.video_frame==video_frame].copy().reset_index(drop=True)\ndf = df[df.conf>0.3]\nboxes = df[['left','top','width','height']].values\narrow_arr = df['alpha']*180\/np.pi\nadd_bb_to_image(img, boxes, color=(0, 255, 0))\nadd_arrow_dgree(img, boxes, arrow_arr, color=(255, 64, 64))\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(img)\nplt.show()","63350c44":"# visualization","e738c8ff":"# find best params\nSearch for the values of Rotation Angle, Trapezoidal Correction, and Home\/Visotor that will result in the smallest gap between the players' coordinates.","54cfb5dc":"# fix data","88bb8b67":"# prepair data","1c9b91f5":"This notebook uses CenterNet to detect the helmet as well as the player's orientation and the gap between the helmet and the sensor.\n\nFollowing notetebooks are used here:\n- https:\/\/www.kaggle.com\/go5kuramubon\/merge-label-and-tracking-data\n- https:\/\/www.kaggle.com\/bamps53\/create-coco-format-annotations-train-val\n- https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\n- https:\/\/www.kaggle.com\/its7171\/nfl-baseline-simple-helmet-mapping","45e87416":"# normalization","eb0517e4":"# make coco format files","dffde25b":"# calculate the gap","d800e299":"# CenterNet","33c435f7":"# make image files","62d39d13":"# prepair CenterNet"}}