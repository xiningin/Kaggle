{"cell_type":{"861d27f3":"code","a066a6b2":"code","c00e8bbc":"code","eac745b5":"code","9f800773":"code","025c63b1":"code","a1462f2d":"code","bb0744f6":"code","47c14794":"code","e03da06d":"code","0129efa0":"code","5a3df3e5":"code","599ec230":"code","3132f304":"code","8f3675d6":"code","3ed58705":"code","59b3ad69":"code","054a3d3a":"code","88c0a116":"code","db09d68c":"code","b522fe15":"code","f3f8abec":"code","0ad7ed21":"code","dee0e63c":"code","6c062f63":"code","c70c749e":"code","9573c9ee":"code","df1513d4":"code","b39bbcc0":"code","128c88df":"code","bd630f59":"code","3315b415":"code","958ba913":"code","048aef22":"code","435742b3":"code","a6a2f343":"code","b9c85d06":"code","422a73de":"code","4040f497":"code","43c07007":"code","7d4b6acd":"code","34b9a719":"code","f5407c1f":"code","67d81763":"code","e8904c5e":"code","2ebb66e3":"code","e7d0d0aa":"code","17e9d1dd":"code","e10ebe1f":"code","3e298afc":"code","869f03d3":"code","d58659a0":"code","43a96831":"markdown","3d197806":"markdown","154ff305":"markdown","bf7397ef":"markdown","4a60c008":"markdown","6871099f":"markdown","4b7142aa":"markdown","13261dde":"markdown"},"source":{"861d27f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a066a6b2":"# importando o dataset\ndf = pd.read_csv('\/kaggle\/input\/hmeq-data\/hmeq.csv')\ndf.head()","c00e8bbc":"# Verificando as informa\u00e7\u00f5es do dataset\ndf.shape, df.info()","eac745b5":"# realizando an\u00e1lise explorat\u00f3ria\n\ndf.describe(include='all')","9f800773":"# Verificando o percentual de empr\u00e9stimos n\u00e3o pagos (BAD = 1)\n\nprint(df['BAD'].value_counts())\nprint(df['BAD'].value_counts(normalize=True))","025c63b1":"# Verificando estat\u00edsticas b\u00e1sicas dos valores de empr\u00e9stimos. A m\u00e9dia est\u00e1 em 18.607.\n\ndf['LOAN'].describe()","a1462f2d":"# Fazer tratamento dos Dados verificando a exist\u00eancia de missing values ou valores null\n\nMissingValues =df.isnull().sum().rename_axis('Colunas').reset_index(name='Missing Values')\nMissingValues","bb0744f6":"# utilizando a biblioteca Pandas Profiling para gerar um report com an\u00e1lise de todas os campos e suas principais estat\u00edsticas.\n\nimport pandas_profiling as pp\n\npp.ProfileReport(df)","47c14794":"# avalia\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas por meio de histogramas\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndf.hist(figsize=(20,10))","e03da06d":"# Criando um dataframe para empr\u00e9stimos que n\u00e3o foram pagos\n\ndf_bad = df[df['BAD'] == 1]","0129efa0":"# Verificando o Total dos empr\u00e9stimos n\u00e3o pagos (20.120.400). Este total \u00e9 relevante para estudar os potenciais maus pagadores.\n\ndf_bad['LOAN'].sum()","5a3df3e5":"# Explorando as informa\u00e7\u00f5es\ndf['DELINQ'].value_counts()","599ec230":"print(df['LOAN'].sum())\nprint(df[df['DELINQ'] != 0.0]['LOAN'].sum())\nprint(df[df['DELINQ'] == 0.0]['LOAN'].sum())","3132f304":"# Distribui\u00e7\u00e3o por profiss\u00e3o\n%matplotlib inline\n\ndf['JOB'].value_counts().plot.bar()","8f3675d6":"# Distribui\u00e7\u00e3o por motivo do empr\u00e9stimo\n%matplotlib inline\n\ndf['REASON'].value_counts().plot.bar()","3ed58705":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plotando a correla\u00e7\u00e3o\n\n# Aumentando a area do grafico\nf, ax = plt.subplots(figsize=(15,6))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', linecolor='red', ax=ax, lw=1)","59b3ad69":"# Identificando valores de hipoteta devido nulo.\n\ndf[df['MORTDUE'].isna()]","054a3d3a":"# Substituindo Nan por 0\n\ndf.fillna(0, inplace = True)","88c0a116":"# criando uma nova base para proteger a base original\n\ndf_n = df","db09d68c":"# Criando uma nova coluna onde 0 n\u00e3o \u00e9 maior e 1 \u00e9 maior que, para o campo da hipot\u00e9ca ser maior que o valor da propriedade\n\ndf_n['HIP_M_PROP'] = df_n['VALUE'] - df_n['MORTDUE']\n\nHIP_M_PROP = []","b522fe15":"# determinar as categorias\nfor valor in df_n['HIP_M_PROP']:\n    if valor <  0.0:\n        HIP_M_PROP.append(1)\n    elif valor >= 0.0:\n        HIP_M_PROP.append(0)\n        \ndf_n['HIP_M_PROP'] = HIP_M_PROP","f3f8abec":"# Criando nova coluna com valores 1 (sim) e 0 (n\u00e3o) para definir se o valor do empr\u00e9stimo \u00e9 maior que o valor da hipoteca\n\ndf_n['LOAN_M_HIP'] = df_n['LOAN'] - df_n['MORTDUE']\n\nLOAN_M_HIP = []\n\n# determinar as categorias\nfor valor in df_n['LOAN_M_HIP']:\n    if valor <  0.0:\n        LOAN_M_HIP.append(1)\n    elif valor >= 0.0:\n        LOAN_M_HIP.append(0)\n        \ndf_n['LOAN_M_HIP'] = LOAN_M_HIP","0ad7ed21":"features = df_n.columns.difference(['BAD','REASON','JOB'])\n\nX = df_n[features].values\ny = df_n['BAD'].values","dee0e63c":"# dividir a base em treino e teste\n\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(df_n.drop('BAD',\n                                                    axis=1),\n                                                    df_n['BAD'],\n                                                    test_size=0.3,\n                                                    random_state=42)","6c062f63":"# cria\u00e7\u00e3o das bases e seus tamanhos\nx_train.shape","c70c749e":"x_test.shape","9573c9ee":"y_train.shape","df1513d4":"y_test.shape","b39bbcc0":"# base de treino\nx_train.head()","128c88df":"# Importando o m\u00e9todo do scikitlearn para divis\u00e3o do dataframe de treino em treino e valida\u00e7\u00e3o\n\nfrom sklearn.model_selection import train_test_split","bd630f59":"# Dividindo a base de treino para teste\n\ntrain, valid = train_test_split(x_train, random_state=42)","3315b415":"# base de valida\u00e7\u00e3o\nvalid.head()","958ba913":"valid.shape","048aef22":"train.shape","435742b3":"# \u00e1rvore de decis\u00e3o\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier_dt = DecisionTreeClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=3)\nclassifier_dt.fit(X, y)","a6a2f343":"# validar modelo\nfrom sklearn.model_selection import cross_val_score\n\nscores_dt = cross_val_score(classifier_dt, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_dt.mean())","b9c85d06":"# predi\u00e7\u00e3o com Ensemble\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier_rf = RandomForestClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=10,\n                           n_estimators=30,\n                           n_jobs=-1)\nscores_rf = cross_val_score(classifier_rf, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_rf.mean())","422a73de":"# tentando uma nova modelagem e medindo a import\u00e2ncia da features\n\nclassifier_rf.fit(X, y) \n\nfeatures_importance = zip(classifier_rf.feature_importances_, features)\nfor importance, feature in sorted(features_importance, reverse=True):\n    print(\"%s: %f%%\" % (feature, importance*100))","4040f497":"# nova modelagem com Vari\u00e1vel resposta: BAD e Vari\u00e1vel explicativa: DEBTINC","43c07007":"# Identificando a frequ\u00eancia da vari\u00e1vel DEBTINC\n\ndf['DEBTINC'].value_counts()","7d4b6acd":"# Separando os dataframes onde o count \u00e9 nulo\n\nteste = df[df['DEBTINC'] == 0.0]\n\ntreino = df[df['DEBTINC'] != 0.0]","34b9a719":"treino.shape","f5407c1f":"teste.shape","67d81763":"# Modelo RandomForest\n\n# m\u00e9todo do scikitlearn para divis\u00e3o e instanciando o modelo\n\nfrom sklearn.model_selection import train_test_split\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","e8904c5e":"# Removendo as colunas de resposta\n\nremoved_cols = ['BAD','DEBTINC','JOB','REASON']","2ebb66e3":"# Criar a lista da colunas de entrada\n\nfeats = [c for c in train.columns if c not in removed_cols]","e7d0d0aa":"# Treinamento do modelo com as vari\u00e1veis de entrada e as de resposta\nrf.fit(treino[feats], treino['BAD'])","17e9d1dd":"# Previs\u00e3o da vari\u00e1vel de teste usando o modelo treinado\nteste['BAD'] = rf.predict(teste[feats]).astype(int)","e10ebe1f":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier_rf = RandomForestClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=10,\n                           n_estimators=30,\n                           n_jobs=-1)\nscores_rf = cross_val_score(classifier_rf, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_rf.mean())","3e298afc":"# Este modelo apresentou um desempenho melhor no percentual de predi\u00e7\u00e3o.\n# H\u00e1 uma margem de diferen\u00e7a entre a base prim\u00e1ria e a base testada de 10%","869f03d3":"# Verifica\u00e7\u00e3o das previs\u00f5es\nteste['BAD'].value_counts(normalize=True)","d58659a0":"df['BAD'].value_counts(normalize=True)","43a96831":"Observa-se que a base est\u00e1 desbalanceada e que possu\u00edmos uma quantidade pequena de maus pagadores (1)","3d197806":"Como o resultado sobre DEBTINC ficou melhor, vamos focar nesta vari\u00e1vel como explicativa","154ff305":"Observamos agora que as correla\u00e7\u00f5es de vari\u00e1veis com a vari\u00e1vel resposta BAD n\u00e3o s\u00e3o significativas\nTemos ent\u00e3o dois cen\u00e1rios poss\u00edveis para predi\u00e7\u00e3o:\n> pegar todas as vari\u00e1veis, exceto  'BAD','REASON', 'JOB' e preparar um treinamento para encontrar um padr\u00e3o que melhor gere um modelo capaz de prever a sa\u00edda para novos dados. Ser\u00e1 adotado X para os valores das entradas (features) e y para os valores das sa\u00eddas.\n> outra possibilidade \u00e9 pegar DEBTINC, e analisar a apresentada correla\u00e7\u00e3o m\u00e9dia com a vari\u00e1vel resposta BAD.","bf7397ef":"**Centro Universit\u00e1rio IESB\n\nP\u00f3s Gradua\u00e7\u00e3o em Ci\u00eancia de Dados\n\nData Mining e Machine Learning II\n\nProfessor Marcos Vinicius Guimar\u00e3es\n\nFernanda Fernandes Minist\u00e9rio**\n\nObjetivo deste trabalho\nIdentificar as pessoas que possam ter problemas de inadimpl\u00eancia junto aos bancos na modalidade de habita\u00e7\u00e3o (Home Equity).\n\nDefinir um modelo que fa\u00e7a predi\u00e7\u00e3o dos maus pagadores por meio de uma base de dados do Home Equity com aproximadamente 6.000 empr\u00e9stimos anteriormente concedidos. Podemos usar estas informa\u00e7\u00f5es identificando clientes que tenham deixado de pagar alguma parcela de empr\u00e9stimo no passado para treinar modelos de aprendizado de m\u00e1quina para prever probabilidades de pessoas que poderiam deixar de pagar a modalidade habita\u00e7\u00e3o (Home Equity) no futuro baseado em situa\u00e7\u00f5es anteriores.\n\nAssim vou propor um problema de classifica\u00e7\u00e3o bin\u00e1ria onde o modelo dever\u00e1 prever se uma pessoa seria um pagador ruim.\n\n\nMetodologia\nA base de dados \"Home Equity\" possui  pessoas e dados de empr\u00e9stimo de 5.960 empr\u00e9stimos recentes. Para cada empr\u00e9stimo existem 12 vari\u00e1veis. A vari\u00e1vel alvo (BAD) indica quando o cliente n\u00e3o pagou o empr\u00e9stimo (1), e quando ele pagou (0).\n\nSer\u00e3o utilizados os modelos Random Forest Classifier, XGBosst e XGBoost com aux\u00edlio do GridSearchCV para otimiza\u00e7\u00e3o do modelo\n\nDicion\u00e1rio de Dados (em ordem alfab\u00e9tica)\n\nBAD: 1 = client defaulted on loan 0 = loan repaid\n\nCLAGE: Age of oldest trade line in months\n\nCLNO: Number of credit lines\n\nDEBTINC: Debt-to-income ratio\n\nDELINQ: Number of delinquent credit lines\n\nDEROG: Number of major derogatory reports\n\nJOB: Six occupational categories\n\nLOAN: Amount of the loan request\n\nMORTDUE: Amount due on existing mortgage\n\nNINQ: Number of recent credit lines\n\nREASON: DebtCon = debt consolidation ; HomeImp = home improvement\n\nVALUE: Value of current property\n\nYOJ: Years at present job","4a60c008":"Observa-se que a maior parte das colunas s\u00e3o valores num\u00e9ricos","6871099f":"Ficou parecido o resultado com a aplica\u00e7\u00e3o do m\u00e9todo CrossValidation, o que significa que o modelo continua sem boa acur\u00e1cia.","4b7142aa":"Observa-se que no gr\u00e1fico de correla\u00e7\u00e3o abaixo as vari\u00e1veis n\u00e3o apresentam correla\u00e7\u00e3o fortes entre si. A melhor correla\u00e7\u00e3o apresentada foi entre as vari\u00e1veis MORTDUE e VALUE (valor da hipot\u00e9ca devido e o valor da propriedade).","13261dde":"Observa-se neste caso que a acur\u00e1cia \u00e9 ruim"}}