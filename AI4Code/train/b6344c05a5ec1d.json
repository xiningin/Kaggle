{"cell_type":{"7393a875":"code","0faac81f":"code","b21316c6":"code","d6099cc0":"code","90e20a76":"code","93fca80f":"code","c3b9d11a":"code","4739287c":"code","c112f6e3":"code","4d02c8eb":"code","8cc3813f":"code","f7e49dff":"code","892ce41f":"code","beeba43a":"code","08d38302":"code","33f9f539":"code","eafa3401":"code","b9bc4509":"code","c0b8f85e":"code","b1cf28fe":"code","14cb996c":"code","39e37d2b":"code","79434dd5":"code","8df5fe0b":"code","134c41a2":"code","0b7e3fc0":"code","86f8f45e":"code","13e4e558":"code","a3023c71":"code","81bead31":"code","b3c0f364":"code","abdd4f46":"code","b1d50505":"code","f0e7ea80":"code","84c4518e":"code","f19bb6cf":"code","d3c88917":"code","4e8201e5":"code","1bbeacf5":"code","57756bc4":"code","6282a784":"code","a4d74b84":"code","55db50db":"code","a36944db":"code","a909272d":"code","ee72984f":"code","92434589":"code","1121127e":"markdown","5a2364dc":"markdown","cf383c8d":"markdown","39ade725":"markdown","883f2445":"markdown","a5d624bf":"markdown","0ff78d18":"markdown","9e43d9ab":"markdown","88029256":"markdown","b356745e":"markdown","775df797":"markdown","db768655":"markdown","fd7cc0b4":"markdown","0fe6b505":"markdown","3624865b":"markdown","ca836f14":"markdown","d0654d82":"markdown","8c775cf1":"markdown","122fabe1":"markdown","c2f4b1a3":"markdown","8e9d9203":"markdown","4c492d9a":"markdown","883e5be9":"markdown","7aee53a4":"markdown","1c4ec6a8":"markdown"},"source":{"7393a875":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0faac81f":"# Import helpful libraries\nimport pandas as pd\n\n# Load the data, and separate the target\niowa_file_path = '\/kaggle\/input\/home-data-for-ml-course\/train.csv'\ndata_train = pd.read_csv(iowa_file_path)\n\n#create y will predictions\ny = data_train.SalePrice\ny.head()\n","b21316c6":"# statistical overview for SalePrice Variable\ndata_train['SalePrice'].describe()","d6099cc0":"#import library\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Pricesale Histogram Plot\nsns.distplot(data_train['SalePrice']);\n\n#kurtosis and Skewness\nprint(\"Skewness: %f\" % data_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % data_train['SalePrice'].kurt())","90e20a76":"#look all variable\ndata_train.columns","93fca80f":"#Correlation in percentage between pricesale and all independent variables\ndata_train.corr()['SalePrice'].sort_values()","c3b9d11a":"#import library\nimport matplotlib.pyplot as plt\n\n#correlation by matrix\ndata_train_kor = data_train.corr()\nplt.figure(figsize=(18,18))\nsns.heatmap(data_train_kor, vmin=-1, vmax=1, cmap=\"viridis\", annot=True, linewidth=0.1)","4739287c":"#saleprice correlation matrix\nk = 11 #number of variables for heatmap\ncols = data_train_kor.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(data_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2g', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","c112f6e3":"#scatterplot variable correlation above 50%\n\nsns.set()\ncols = ['YearRemodAdd', 'YearBuilt', 'TotRmsAbvGrd', 'FullBath', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual', 'SalePrice']\nsns.pairplot(data_train[cols], size = 3)\nplt.show();","4d02c8eb":"#scatterplot variable correlation above 50% after check sam e character\n\nsns.set()\ncols = ['YearBuilt', 'TotRmsAbvGrd', 'FullBath','TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual', 'SalePrice']\nsns.pairplot(data_train[cols], size = 3)\nplt.show();","8cc3813f":"# Create X features\nfeatures = ['YearBuilt', 'TotRmsAbvGrd', 'FullBath','TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual']\n\n# Select columns corresponding to features, and preview the data\nX = data_train[features]\nX.head()","f7e49dff":"#missing data\ntotal = data_train.isnull().sum().sort_values(ascending=False)\npercent = (data_train.isnull().sum()\/data_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","892ce41f":"data_train = data_train.drop((missing_data[missing_data['Total'] >= 1]).index,1)\ndata_train.isnull().sum().max()","beeba43a":"#import library\nfrom sklearn.preprocessing import StandardScaler\n\n#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(data_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","08d38302":"#bivariate analysis\nsns.scatterplot(data=data_train, x='YearBuilt', y='SalePrice')\nplt.axvline(x=1900,color='purple')\nplt.axhline(y=200000,color='purple')\n","33f9f539":"sns.scatterplot(data=data_train, x='YearBuilt', y='SalePrice')\nplt.axvline(x=1980,color='purple')\nplt.axhline(y=620000,color='purple')","eafa3401":"data_train[(data_train['SalePrice']>200000) &(data_train['YearBuilt']<1900) ][['SalePrice', 'YearBuilt']]","b9bc4509":"data_train[(data_train['SalePrice']>620000) &(data_train['YearBuilt']>1980)][['SalePrice', 'YearBuilt']]","c0b8f85e":"#Remove the outliers:\nindex_drop_1 = data_train[(data_train['SalePrice']>200000) &(data_train['YearBuilt']<1900) ].index\nindex_drop_2 = data_train[(data_train['SalePrice']>620000) &(data_train['YearBuilt']>1980)].index\ndata_train_del = data_train.drop(index_drop_1, axis=0)\ndata_train = data_train_del.drop(index_drop_2, axis=0)","b1cf28fe":"#bivariate analysis\nsns.scatterplot(data=data_train, x='TotRmsAbvGrd', y='SalePrice')\nplt.axvline(x=13,color='purple')\nplt.axhline(y=220000,color='purple')","14cb996c":"data_train[(data_train['SalePrice']<220000) &(data_train['TotRmsAbvGrd']>13)][['SalePrice', 'TotRmsAbvGrd']]","39e37d2b":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']<220000) &(data_train['TotRmsAbvGrd']>13)].index\ndata_train = data_train.drop(index_drop, axis=0)","79434dd5":"#bivariate analysis\nsns.scatterplot(data=data_train, x='FullBath', y='SalePrice')\nplt.axhline(y=600000,color='purple')\nplt.axvline(x=1.9,color='purple')","8df5fe0b":"data_train[(data_train['SalePrice']>600000)&(data_train['FullBath']>1.9)][['SalePrice', 'FullBath']]","134c41a2":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']>600000)&(data_train['FullBath']>1.9)].index\ndata_train = data_train.drop(index_drop, axis=0)","0b7e3fc0":"#bivariate analysis\nsns.scatterplot(data=data_train, x='TotalBsmtSF', y='SalePrice')\nplt.axhline(y=200000,color='purple')\nplt.axvline(x=6000,color='purple')","86f8f45e":"data_train[(data_train['SalePrice']<200000)&(data_train['TotalBsmtSF']>6000)][['SalePrice', 'TotalBsmtSF']]","13e4e558":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']<200000)&(data_train['TotalBsmtSF']>6000)].index\ndata_train = data_train.drop(index_drop, axis=0)","a3023c71":"#bivariate analysis\nsns.scatterplot(data=data_train, x='GarageArea', y='SalePrice')\nplt.axhline(y=300000,color='purple')\nplt.axvline(x=1200,color='purple')","81bead31":"data_train[(data_train['SalePrice']<300000)&(data_train['GarageArea']>1200)][['SalePrice', 'GarageArea']]","b3c0f364":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']<300000)&(data_train['GarageArea']>1200)].index\ndata_train = data_train.drop(index_drop, axis=0)","abdd4f46":"#bivariate analysis\nsns.scatterplot(data=data_train, x='GarageCars', y='SalePrice')\nplt.axhline(y=250000,color='purple')\nplt.axvline(x=3.5,color='purple')","b1d50505":"data_train[(data_train['SalePrice']<250000)&(data_train['GarageCars']>3.5)][['SalePrice', 'GarageCars']]","f0e7ea80":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']<250000)&(data_train['GarageCars']>3.5)].index\ndata_train = data_train.drop(index_drop, axis=0)","84c4518e":"#bivariate analysis\nsns.scatterplot(data=data_train, x='GrLivArea', y='SalePrice')\nplt.axhline(y=250000,color='purple')\nplt.axvline(x=4000,color='purple')","f19bb6cf":"data_train[(data_train['SalePrice']<250000)&(data_train['GrLivArea']>4000)][['SalePrice', 'GrLivArea']]","d3c88917":"#Remove the outliers:\nindex_drop = data_train[(data_train['SalePrice']<250000)&(data_train['GrLivArea']>4000)].index\ndata_train = data_train.drop(index_drop, axis=0)","4e8201e5":"#bivariate analysis\nsns.scatterplot(data=data_train, x='OverallQual', y='SalePrice')","1bbeacf5":"#import library\nfrom sklearn.model_selection import train_test_split\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","57756bc4":"#import library\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Define a random forest model\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","6282a784":"# path to file you will use for predictions\niowa_file_path_test = '\/kaggle\/input\/home-data-for-ml-course\/test.csv'\ndata_test = pd.read_csv(iowa_file_path_test)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = data_test[features]\ntest_X.head()","a4d74b84":"#missing data\ntotal_test = data_test.isnull().sum().sort_values(ascending=False)\npercent_test = (data_test.isnull().sum()\/data_test.isnull().count()).sort_values(ascending=False)\nmissing_data_test = pd.concat([total_test, percent_test], axis=1, keys=['total_test', 'percent_test'])\nmissing_data_test.head(20)","55db50db":"#convert float data to integer\npd.options.display.float_format = '{:,.0f}'.format","a36944db":"test_X.mean()","a909272d":"test_X=test_X.fillna(test_X.mean())\ntest_X","ee72984f":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor()\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model_on_full_data.fit(X, y)\n\n# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(test_X)","92434589":"# Run the code to save predictions in the format used for competition scoring\n\noutput = pd.DataFrame({'Id': data_test.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)\noutput","1121127e":"# correlation of independent variable to pricesale","5a2364dc":"only overview variable is above 50%","cf383c8d":"# predict PriceSale from data test with random forest","39ade725":"# correlation in matrix","883f2445":"scatterplot variable correlation above 50%, can look variable have sama character always have same distribution :\n1. 'YearRemodAdd' and 'YearBuilt'\nsame character about year\n\n2. '1stFlrSF' and 'TotalBsmtSF'\nsame character about first floor\n\nso we can only use 1 varibale wiht more bigger correlation percentage","a5d624bf":"# missing data check","0ff78d18":"# split train and test data","9e43d9ab":"# Input data train","88029256":"# PriceSale Statistical overview","b356745e":"# outliers","775df797":"this analysis only focus on house price predicitons, so start with dependent variable \"SalePrice\"","db768655":"# convert float data to integer","fd7cc0b4":"# input data test","0fe6b505":"# deleted missing data","3624865b":"# correlation above 50% reviewed","ca836f14":"# overview of independent variables","d0654d82":"# missing data","8c775cf1":"# measure average every features","122fabe1":"# error value evaluation for random forest","c2f4b1a3":"# explore outliers with bivariate analysis","8e9d9203":"# replace 0 values, nan, Na, null with average","4c492d9a":"OverallQual no outlier","883e5be9":"# choose the features used in the model","7aee53a4":"# PriceSale Distribution Overview","1c4ec6a8":"# output with keep id and saleprice"}}