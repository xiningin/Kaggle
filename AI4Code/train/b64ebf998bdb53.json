{"cell_type":{"5c5a7824":"code","0dff1f1c":"code","b48a28c4":"code","e429f3d0":"code","7976dae3":"code","0f9d894b":"code","9c0e4d4f":"code","1edaf138":"code","afe92a6e":"code","a2e04c14":"code","8dcd5bcc":"code","9ff2cc9e":"code","287a6771":"code","f54ebd9b":"code","99127aeb":"code","ae165b2c":"code","35a57475":"code","309e034f":"code","0cb2ffae":"code","289d38d5":"code","3ec7a015":"code","7bc5cbd0":"code","e2558f5d":"code","3966e781":"code","c69d8f37":"code","7ef98d7b":"code","56e7ec58":"code","dfa95d81":"code","a0cf058f":"code","7d30a4f4":"code","c405bc70":"code","0039d4a2":"code","88de4a1c":"code","f60255d6":"code","28ae2145":"code","ec81cc23":"code","2887d510":"code","06753324":"code","54a1e951":"code","12a81a17":"code","7552c289":"code","12dd430f":"code","084d140f":"code","4407cdf5":"code","b665230e":"code","cd97f0dd":"code","e18bfaf6":"code","dfcd0602":"code","536f1fdc":"code","8b5f107a":"code","6a074903":"code","4e1ad8bb":"code","f066ca00":"code","3bee1fa9":"code","40e203ae":"code","bd08f3ac":"code","10b3ea26":"code","3428970e":"markdown","70473ee6":"markdown","201b520d":"markdown","4fbffd20":"markdown","fef25a12":"markdown","0fd99a71":"markdown","ba941d5a":"markdown","4b12e8c3":"markdown","27fe1f49":"markdown","20fc8685":"markdown","5d6ca6e6":"markdown","65da7282":"markdown","df9c2f5f":"markdown"},"source":{"5c5a7824":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0dff1f1c":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')","b48a28c4":"df.head()","e429f3d0":"df.columns","7976dae3":"df = df.drop('id',axis=1)","0f9d894b":"df = df.drop('Unnamed: 32',axis=1)","9c0e4d4f":"df.head()","1edaf138":"import matplotlib.pyplot as plt \n\nimport seaborn as sns","afe92a6e":"plt.figure(figsize=(16,8))\n\nsns.kdeplot(df['texture_mean'])","a2e04c14":"plt.figure(figsize=(16,8))\n\nsns.kdeplot(df['area_mean'])","8dcd5bcc":"plt.figure(figsize=(10,10))\nplt.xlabel('mean_radius')\nplt.ylabel('mean_area')\nsns.scatterplot(x = df['radius_mean'], y = df['area_mean'], hue = df['diagnosis'])","9ff2cc9e":"plt.figure(figsize=(10,10))\nplt.xlabel('mean concavity')\nplt.ylabel('mean compactness')\nsns.scatterplot(x = df['concavity_mean'], y = df['compactness_mean'], hue = df['diagnosis'])","287a6771":"plt.figure(figsize=(10,10))\nplt.xlabel('mean_texture')\nplt.ylabel('mean_dimension')\nsns.scatterplot(x = df['texture_mean'], y = df['fractal_dimension_mean'], hue = df['diagnosis'])","f54ebd9b":"plt.figure(figsize=(12,12))\nsns.heatmap(df.corr(),cmap='magma')","99127aeb":"def func(x):\n    if x == 'M':\n        return 1\n    else:\n        return 0\ndf['diagnosis'] = df['diagnosis'].apply(func)","ae165b2c":"df.head()","35a57475":"X = df[df.columns[1:]]\ny = df[df.columns[0]]","309e034f":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler","0cb2ffae":"x_train, x_test, y_train, y_test = train_test_split(X,y,random_state=101,test_size=0.33)","289d38d5":"scaler = StandardScaler()\n\nscaled_train = scaler.fit_transform(x_train)\n\nscaled_test = scaler.transform(x_test)","3ec7a015":"scaled_train.shape","7bc5cbd0":"scaled_test.shape","e2558f5d":"from sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression()\n\nlr_model.fit(scaled_train,y_train)\n\npreds = lr_model.predict(scaled_test)","3966e781":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score","c69d8f37":"print(confusion_matrix(y_test,preds))","7ef98d7b":"print(classification_report(y_test,preds))","56e7ec58":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 3)","dfa95d81":"reduced_train = pca.fit_transform(scaled_train)\n\nreduced_test = pca.transform(scaled_test)","a0cf058f":"reduced_train.shape","7d30a4f4":"sns.scatterplot(x=reduced_train[:,0],\n            y=reduced_train[:,1],hue=y_train)","c405bc70":"sns.scatterplot(x=reduced_train[:,0],\n            y=reduced_train[:,2],hue=y_train)","0039d4a2":"sns.scatterplot(x=reduced_train[:,1],\n            y=reduced_train[:,2],hue=y_train)","88de4a1c":"from sklearn.svm import SVC","f60255d6":"svc = SVC() ","28ae2145":"svc.fit(reduced_train,y_train)","ec81cc23":"preds = svc.predict(reduced_test)","2887d510":"print(classification_report(y_test,preds))","06753324":"print(confusion_matrix(y_test,preds))","54a1e951":"from sklearn.ensemble import RandomForestClassifier","12a81a17":"accuracy = []\ni_vals = [] \nfor i in range(1,100):\n    \n    forest = RandomForestClassifier(n_estimators=i)\n    \n    forest.fit(scaled_train,y_train)\n    \n    preds = forest.predict(scaled_test)\n    \n    accuracy.append(accuracy_score(y_test,preds))\n    i_vals.append(i)","7552c289":"plt.figure(figsize=(14,3))\nplt.plot(i_vals, accuracy)","12dd430f":"forest = RandomForestClassifier(n_estimators=40)\n    \nforest.fit(scaled_train,y_train)\n    \npreds = forest.predict(scaled_test)\n\nprint(classification_report(y_test,preds))","084d140f":"accuracy = []\ni_vals = [] \nfor i in range(1,100):\n    \n    forest = RandomForestClassifier(n_estimators=i)\n    \n    forest.fit(reduced_train,y_train)\n    \n    preds = forest.predict(reduced_test)\n    \n    accuracy.append(accuracy_score(y_test,preds))\n    i_vals.append(i)","4407cdf5":"plt.figure(figsize=(14,3))\nplt.plot(i_vals, accuracy)","b665230e":"forest = RandomForestClassifier(n_estimators=35)\n    \nforest.fit(reduced_train,y_train)\n    \npreds = forest.predict(reduced_test)\n\nprint(classification_report(y_test,preds))","cd97f0dd":"from tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Dropout","e18bfaf6":"from tensorflow.keras.callbacks import EarlyStopping","dfcd0602":"scaled_test.shape","536f1fdc":"model = Sequential()\n\nmodel.add(Dense(30, activation='relu'))\n\nmodel.add(Dense(15, activation='relu'))\n\nmodel.add(Dense(7, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","8b5f107a":"stop = [EarlyStopping(patience=100, monitor = 'val_acc')]\n\nmodel.fit(scaled_train,\n          y_train,\n          epochs = 600,\n          callbacks=stop,\n          validation_data=(scaled_test,y_test))","6a074903":"plt.figure(figsize=(15,8))\npd.DataFrame(model.history.history).plot()","4e1ad8bb":"preds = model.predict_classes(scaled_test)","f066ca00":"print(classification_report(y_test,preds))","3bee1fa9":"model = Sequential()\n\nmodel.add(Dense(3, activation='relu'))\n\nmodel.add(Dense(8, activation='relu'))\n\nmodel.add(Dense(2, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","40e203ae":"stop = [EarlyStopping(patience=100, monitor = 'val_acc')]\n\nmodel.fit(reduced_train,\n          y_train,\n          epochs = 600,\n          callbacks=stop,\n          validation_data=(reduced_test,y_test))","bd08f3ac":"preds = model.predict_classes(reduced_test)","10b3ea26":"print(classification_report(y_test,preds))","3428970e":"*we just isolated the labels and the input data for our models from each other !*","70473ee6":"# using PCA for dimensionality reduction :","201b520d":"# coverting categorical variables into binary classes :","4fbffd20":"*the data shows that, smaller the radius more likely is the tumor to be non-cancerous*","fef25a12":"*problem statement : \"given the features of the tumor, predict the diagnosis i.e. malignant(m) or begnin(b)\"*","0fd99a71":"# scaling and splitting the data into training and test examples :","ba941d5a":"*most of the dimensions and measurement is of medical relevance, as i have no background in medical science i can't study the data that well so as to plot out curves that are of importance*","4b12e8c3":"# using support vector classifier :","27fe1f49":"# using random forest classifier :","20fc8685":"# constructing neural network for classification purpose :","5d6ca6e6":"# getting the data, initial processing :","65da7282":"# using logistic regression :","df9c2f5f":"# exploratory data analysis :"}}