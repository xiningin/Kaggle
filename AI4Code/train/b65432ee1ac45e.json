{"cell_type":{"e4445df8":"code","da7623d5":"code","2a952f27":"code","e3a9d52b":"code","8fa93df4":"code","d61d6395":"markdown"},"source":{"e4445df8":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV","da7623d5":"X_full = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny_train = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\ncategorical_cols = [cname for cname in X_full.columns if X_full[cname].nunique() < 10 and X_full[cname].dtype == \"object\"]\nnumerical_cols = [cname for cname in X_full.columns if X_full[cname].dtype in ['int64', 'float64']]\n\n#Set aside columns with more than 25% missing values\ncat_highNA_cols = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"]\ncategorical_cols = [item for item in categorical_cols if item not in cat_highNA_cols]\n\n#Set aside discrete numerical columns\nnumcat_cols = [\"MSSubClass\", \"OverallQual\", \"OverallCond\", \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \n                \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\", \"GarageCars\", \"MoSold\"]\nnumerical_cols = [item for item in numerical_cols if item not in numcat_cols]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols + numcat_cols + cat_highNA_cols\nX_train = X_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","2a952f27":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy=\"mean\")\nnumcat_transformer = SimpleImputer(strategy=\"most_frequent\")\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\ncat_highNA_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value = \"Missing\")),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols),\n        ('numcat', numcat_transformer, numcat_cols)\n#        ('highcat', cat_highNA_transformer, cat_highNA_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor()","e3a9d52b":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\nparam_grid = {\n    'model__n_estimators': [120, 180, 240],\n    'model__max_depth': [80, 120, 160],\n    'model__min_samples_leaf': [3, 4, 5],\n    'model__min_samples_split': [6, 8, 10]\n}\n\nsearch = GridSearchCV(my_pipeline, param_grid, n_jobs=-1, verbose=10, cv=3)\nsearch.fit(X_train, y_train)\nprint(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_params_)","8fa93df4":"# Preprocessing of test data, fit model\npreds = search.predict(X_test)\n\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds})\noutput.to_csv('submission.csv', index=False)","d61d6395":"EDA visualizations created during the development of this model can be found here: https:\/\/www.kaggle.com\/db102291\/housing-prices-exploratory-data-analysis"}}