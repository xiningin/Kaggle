{"cell_type":{"3cdd33e9":"code","a4b5ba70":"code","e6da68ee":"code","a06fef73":"code","b0d85380":"code","73626b2b":"code","559feffa":"code","5782a8cb":"code","fcb9fb21":"code","e02ec750":"code","edb09088":"code","b302612a":"code","d6b31f87":"code","c5e8c7f0":"code","3f2f80f1":"code","941c5152":"code","4d4e11f4":"code","a0a86ee8":"code","1ff3bb9f":"code","5bb58567":"code","91106938":"code","794eeb73":"code","4e918e76":"code","0d4c748b":"code","15fb42e9":"code","f115df70":"code","f50624fe":"code","85b8f456":"code","c36d4b6b":"code","5822105c":"code","df8ab7d7":"code","feb89143":"code","cc9fe843":"code","681f52ab":"code","1950eea1":"code","ef33b77a":"code","161eed3e":"code","df623a0a":"code","fae86b5d":"code","e595903b":"code","a3e1d9ec":"code","e9a3a74d":"code","201c77dc":"code","ecd02466":"code","84e5224b":"code","9bb6227a":"code","04cfe624":"code","fbeb5e01":"code","d337a2f0":"code","52482212":"code","b56d2a76":"code","20807946":"code","38774ac3":"code","a5adbaac":"code","fe96f88e":"code","88c67c02":"code","56c36e97":"code","fd15dd75":"code","cbd04397":"code","c00e805e":"code","ea21ddd4":"code","6b0cb11c":"code","e287ae97":"code","7cca0baf":"code","47222e51":"code","8c597c94":"code","4dceb974":"code","0fbe835d":"code","a7f2a410":"code","6f6714a6":"code","33ee78da":"code","648cd90f":"code","f9449ebd":"code","7423e496":"code","6bafb1e1":"code","9f062d2b":"code","debc50b6":"code","2bbdc661":"code","71a1c5b5":"code","8c15b715":"code","1db7ffe5":"code","10c78408":"code","260d1f23":"code","e3cb128c":"code","6f637020":"code","5846d964":"code","bc0e6f01":"code","1fb1be52":"code","6cebd234":"code","3774c51d":"code","6503cdf7":"code","d788684c":"code","4d77e3db":"code","0938848f":"code","3cbb1183":"code","8727146a":"markdown","0546a171":"markdown","c092e969":"markdown","d1ec039a":"markdown","a735c91c":"markdown","16a6b515":"markdown","3006bfa3":"markdown","bd8148f5":"markdown","c5141cb5":"markdown","dfad0b6d":"markdown","ee9f726e":"markdown","e43d773a":"markdown","b2212f68":"markdown","16cfbe1f":"markdown","03cba23d":"markdown","e2c90530":"markdown","546dd0e0":"markdown","fb7be5f5":"markdown","0698bcdd":"markdown","01cbce7e":"markdown","54736ef1":"markdown","b3b361ca":"markdown","70313305":"markdown"},"source":{"3cdd33e9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix","a4b5ba70":"df = pd.read_csv('..\/input\/latest-covid19-india-statewise-data\/Latest Covid-19 India Status.csv')\ndf","e6da68ee":"\n# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    df=pd.read_csv('..\/input\/latest-covid19-india-statewise-data\/Latest Covid-19 India Status.csv')\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","a06fef73":"df.head()","b0d85380":"df.tail()","73626b2b":"df.dtypes","559feffa":"df.columns","5782a8cb":"df.info()","fcb9fb21":"df.describe()","e02ec750":"df.corr()","edb09088":"df.skew()","b302612a":"df.isnull().sum()","d6b31f87":"df.duplicated().sum()","c5e8c7f0":"df.shape","3f2f80f1":"df.size","941c5152":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","4d4e11f4":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'State\/UTs'}}\nmulti_table([df_nunique['State\/UTs']])","a0a86ee8":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True,cmap = 'viridis')\nplt.show()","1ff3bb9f":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df.drop(['State\/UTs'],axis = 1))","5bb58567":"'''Plot Correlation to Target Variable only'''\ndef corrMat2(df,target='Discharge Ratio',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr\ncorrMat2(df.drop(['State\/UTs'],axis = 1))","91106938":"df['State\/UTs'].value_counts()","794eeb73":"fig = px.histogram(df, 'Total Cases',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Total Cases'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","4e918e76":"df[df['Total Cases'] < 1000000]['State\/UTs']\n# States with total cases less than 1M","0d4c748b":"df[df['Total Cases'] < 1000000]['State\/UTs'].count()\n#count of them","15fb42e9":"x = df[df['Total Cases'] < 1000000]['State\/UTs']\ny = df[df['Total Cases'] < 1000000]['Total Cases']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","f115df70":"df[df['Total Cases'] > 1000000]['State\/UTs']\n# States with total cases morethan 1M","f50624fe":"df[df['Total Cases'] > 1000000]['State\/UTs'].count()\n#count of them","85b8f456":"x = df[df['Total Cases'] > 1000000]['State\/UTs']\ny = df[df['Total Cases'] > 1000000]['Total Cases']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","c36d4b6b":"df1 = df[['State\/UTs','Total Cases']].sort_values('Total Cases')\ndf1\n# This dataframe is arranged in ascending order of total cases now we can clearly see with state has less total cases","5822105c":"x = df1['State\/UTs']\ny = df1['Total Cases']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","df8ab7d7":"fig = px.histogram(df, 'Active',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Active'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","feb89143":"df[df['Active'] < 10000]['State\/UTs']\n# States with active cases less than 10k","cc9fe843":"df[df['Active'] < 10000]['State\/UTs'].count()\n# count of them","681f52ab":"x = df[df['Active'] < 10000]['State\/UTs']\ny = df[df['Active'] < 10000]['Active']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()\n","1950eea1":"df[df['Active'] > 10000]['State\/UTs']\n# States with active cases more than 10k","ef33b77a":"df[df['Active'] > 10000]['State\/UTs'].count()\n# count of them","161eed3e":"x = df[df['Active'] > 10000]['State\/UTs']\ny = df[df['Active'] > 10000]['Active']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","df623a0a":"df2 = df[['State\/UTs','Active']].sort_values('Active')\ndf2\n# This dataframe is arranged in ascending order of active cases now we can clearly see with state has less total cases","fae86b5d":"x = df2['State\/UTs']\ny = df2['Active']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","e595903b":"fig = px.histogram(df, 'Discharged',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Discharged'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","a3e1d9ec":"df[df['Discharged'] < 1000000]['State\/UTs']\n# States with discharged cases less than 1M","e9a3a74d":"df[df['Discharged'] < 1000000]['State\/UTs'].count()\n# count of them","201c77dc":"x = df[df['Discharged'] < 1000000]['State\/UTs']\ny = df[df['Discharged'] < 1000000]['Discharged']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","ecd02466":"df[df['Discharged'] > 1000000]['State\/UTs']\n# States with discharged cases greather than 1M","84e5224b":"df[df['Discharged'] > 1000000]['State\/UTs'].count()","9bb6227a":"x = df[df['Discharged'] > 1000000]['State\/UTs']\ny = df[df['Discharged'] > 1000000]['Discharged']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","04cfe624":"df3 = df[['State\/UTs','Discharged']].sort_values('Discharged')\ndf3\n# This dataframe is arranged in ascending order of discharged cases now we can clearly see with state has less total cases","fbeb5e01":"x = df3['State\/UTs']\ny = df3['Discharged']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","d337a2f0":"fig = px.histogram(df, 'Deaths',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Deaths'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","52482212":"df[df['Deaths'] < 20000]['State\/UTs']\n# States with deaths less than 20k","b56d2a76":"df[df['Deaths'] < 20000]['State\/UTs'].count()\n#count of them","20807946":"x = df[df['Deaths'] < 20000]['State\/UTs']\ny =df[df['Deaths'] < 20000]['Deaths']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","38774ac3":"df[df['Deaths'] > 20000]['State\/UTs']\n# States with deaths morethan 20k","a5adbaac":"df[df['Deaths'] > 20000]['State\/UTs'].count()\n#count of them","fe96f88e":"x = df[df['Deaths'] > 20000]['State\/UTs']\ny =df[df['Deaths'] > 20000]['Deaths']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","88c67c02":"df4 = df[['State\/UTs','Deaths']].sort_values('Deaths')\ndf4\n# This dataframe is arranged in ascending order of deaths now we can clearly see with state has less total cases","56c36e97":"x = df4['State\/UTs']\ny = df4['Deaths']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","fd15dd75":"fig = px.histogram(df, 'Active Ratio',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Active Ratio'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","cbd04397":"df5 = df[['State\/UTs','Active Ratio']].sort_values('Active Ratio')\ndf5","c00e805e":"x = df5['State\/UTs']\ny = df5['Active Ratio']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","ea21ddd4":"fig = px.histogram(df, 'Discharge Ratio',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Discharge Ratio'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","6b0cb11c":"df6 = df[['State\/UTs','Discharge Ratio']].sort_values('Discharge Ratio')\ndf6","e287ae97":"x = df6['State\/UTs']\ny = df6['Discharge Ratio']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","7cca0baf":"fig = px.histogram(df, 'Death Ratio',             \n                   color=\"State\/UTs\",\n                   title=\"<b>Average cases per state<\/b>\")\n\nfig.add_vline(x=df['Death Ratio'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()","47222e51":"df7 = df[['State\/UTs','Death Ratio']].sort_values('Death Ratio')\ndf7","8c597c94":"x = df7['State\/UTs']\ny = df7['Death Ratio']\ndata = go.Bar(x= x,y= y)\nlayout = go.Layout(title = 'Simple Bar Chart')\nfig = go.Figure(data=data,layout=layout)\nfig.show()","4dceb974":"a = []\nfor i in df1['State\/UTs'].tail(5):\n    a.append(i)\ndf1.tail()","0fbe835d":"for i in df2['State\/UTs'].tail(5):\n    a.append(i)\ndf2.tail()","a7f2a410":"for i in df3['State\/UTs'].tail(5):\n    a.append(i)\ndf3.tail()","6f6714a6":"for i in df4['State\/UTs'].tail(5):\n    a.append(i)\ndf4.tail()","33ee78da":"for i in df5['State\/UTs'].tail(5):\n    a.append(i)\ndf5.tail()","648cd90f":"for i in df6['State\/UTs'].tail(5):\n    a.append(i)\ndf6.tail()","f9449ebd":"for i in df7['State\/UTs'].tail(5):\n    a.append(i)\ndf7.tail()","7423e496":"a\nlen(a)","6bafb1e1":"c = []\nfor i in a:\n    if i not in c:\n        c.append(i)\nc\n# removing repeated states","9f062d2b":"v = df['State\/UTs'].index.values\nv","debc50b6":"m = []\nfor i in range(len(v)):\n    if df['State\/UTs'][i] in c:\n        m.append(v[i])\nm","2bbdc661":"df8 = df.loc[m]\ndf8","71a1c5b5":"x = df8['State\/UTs']\ny1 = df8['Total Cases']\ny2 = df8['Active']\ny3 = df8['Discharged']\ny4 = df8['Deaths']\ntrace1 = go.Bar(x= x,y= y1,marker={'color' : '#FFB300'},name = 'Total Cases')    \ntrace2 = go.Bar(x= x,y= y2,marker={'color' : '#F7DC6F'},name = 'Active') \ntrace3 = go.Bar(x= x,y= y3,marker={'color' : '#FF9800'},name = 'Discharged')\ntrace4 = go.Bar(x= x,y= y4,marker={'color' : '#7CB342'},name = 'Deaths')\nlayout = go.Layout(title= 'Grouped Bar Chart' , width=980,height=800)\ndata = [trace1,trace2,trace3,trace4]\nfig = go.Figure(data=data, layout=layout)\nfig.show()\n\n# over all visualisation of states","8c15b715":"# pairplot of dataframe contating only top 5 or bottom 5 in a column\nsns.pairplot(df8)","1db7ffe5":"# pairplot of original dataframe\nsns.pairplot(df)","10c78408":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","260d1f23":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df8.corr(),annot = True, cmap = 'viridis')\nplt.show()","e3cb128c":"plt.figure(figsize=(6,8))\nx = df.drop(['State\/UTs'],axis = 1)\nfor i in x.columns:\n    sns.histplot(x[i],kde = True)\n    plt.show()","6f637020":"plt.figure(figsize=(6,8))\nx = df.drop(['State\/UTs'],axis = 1)\nfor i in x.columns:\n    sns.scatterplot(x= 'Active',y=x[i],data=df)\n    plt.show()","5846d964":"x = df.drop('State\/UTs',axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","bc0e6f01":"x = df.drop('State\/UTs',axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","1fb1be52":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(df,i)","6cebd234":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\nc1 = 'State\/UTs'\ndf[c1]= label_encoder.fit_transform(df[c1]) \ndf[c1].unique()\ndf","3774c51d":"X = df.drop('Discharge Ratio',axis = 1)\nY = df['Discharge Ratio']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state=44)","6503cdf7":"reg = linear_model.LinearRegression()\nreg.fit(X_train, Y_train)","d788684c":"reg.coef_","4d77e3db":"pred = reg.predict(X_test)\npred","0938848f":"plt.scatter(Y_test,pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","3cbb1183":"metrics.explained_variance_score(Y_test,pred)","8727146a":"#### overall india maharastra has highest discharged cases 6.3M followed by kerala 4.3M","0546a171":"# Exploratory Data Analysis Uing User Defined Function","c092e969":"#### consists of states which are top 5 or bottom of respective column","d1ec039a":"#### Maharasatra has highest cases 6.5M followed by kerala 4.5M\n#### 10 states have total cases morethan 1M","a735c91c":"#### andaman, dadra,lakshadweep has no active cases","16a6b515":"# prediction of discharge ratio using linear regression","3006bfa3":"#### except mizoram all states had discahrge rate morethan 95%","bd8148f5":"#### laksha dweep and darda has no deaths","c5141cb5":"# Exploratory Data Analysis","dfad0b6d":"#### Discharge ratio is highly negatively corerlated with Active Ratio","ee9f726e":"# Loading DataSet","e43d773a":"#### maharastra has more number of deaths 138.546k followed by karnataka 37.627k","b2212f68":"#### Kerala has highest active cases 167.578k followed by maharastra has 45.22k","16cfbe1f":"# Feature Selection","03cba23d":"# Count of outliers","e2c90530":"## Getting unique values of each category","546dd0e0":"#### Kerala has more number of active cases","fb7be5f5":"#### All are unique values","0698bcdd":"# Data Preprocessing","01cbce7e":"#### 9 states have discharge people more than 1M","54736ef1":"# Data Visualisation","b3b361ca":"# Importing Libraries","70313305":"#### under 1M chhattisgarh has more number of discharged cases 0.99M"}}