{"cell_type":{"6344cbc1":"code","2c067f4e":"code","1cd4b87f":"code","b32bfd54":"code","07fab174":"code","664e5d13":"code","90dbb063":"code","ba88b035":"code","a6dd0c6b":"code","ffbe442c":"code","c193a59d":"code","17c36610":"code","4c477193":"code","cea48731":"code","81455550":"code","8cb6284d":"code","54527626":"code","f4a0299c":"code","ce014090":"code","df8c90a6":"code","2fd56478":"code","45f07435":"code","5da8b45c":"code","48298b81":"code","dc2cecca":"code","ec2b9482":"code","37bf2ea9":"code","602b88e6":"code","b60aa6a0":"code","e606270a":"code","5d53e3c8":"code","1eca3375":"code","a70fda70":"code","40f6ae73":"code","98b9ad37":"code","01615a1d":"code","2ae952eb":"code","c977b1dd":"code","f931b3be":"code","2ff42df8":"code","512b3164":"code","56f0cab8":"code","8ffed0dd":"code","37e3dd03":"code","acb90e99":"code","05d8fb99":"markdown","a42a708c":"markdown","6838e595":"markdown","8929bca1":"markdown","2587af81":"markdown","67597c97":"markdown","8f1ded48":"markdown","2b88e30f":"markdown","a4b1f0a0":"markdown","3b389549":"markdown","e32510c3":"markdown"},"source":{"6344cbc1":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nfrom tensorflow import keras\nfrom random import shuffle\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout,ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras.applications import VGG19\nfrom keras.utils.vis_utils import plot_model\n\nsns.set()","2c067f4e":"data=[]\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file_path=os.path.join(dirname, filename)\n        class_name=file_path.split('\/')[-2]\n        data.append([file_path,class_name])\n        \n# shuffling the files so that all the images of same class are randomly distributed \nshuffle(data)\ndf=pd.DataFrame(data,columns=['path','class'])","1cd4b87f":"df.head()","b32bfd54":"sns.countplot('class',data=df)\nplt.title('Class Wise Frequency')\nplt.show()","07fab174":"# mapping the sample labels to integer values\nmapping={'sunflower':0,'tulip':1,'dandelion':2,'rose':3,'daisy':4}","664e5d13":"df['class'].value_counts()\nclasses=df['class'].value_counts().index","90dbb063":"df.shape","ba88b035":"## visualising some of the samples in the set\n\nrows=4\ncols=4\n\nfig=plt.figure(figsize=(10,10))\n\nfor index in range(1,rows*cols+1):\n    path=df['path'][index-1]\n    flower_class=df['class'][index-1]\n    flower_img=cv2.imread(path)\n    axis=fig.add_subplot(rows,cols,index)\n    axis.set_xticks([]) \n    axis.set_yticks([])\n    plt.xlabel(flower_class)\n    plt.imshow(flower_img)\nplt.show()","a6dd0c6b":"min_width=float('inf')\nmin_height=float('inf')\n\nfor index,row in df.iterrows():\n    img=cv2.imread(row['path'])\n    \n    try:\n        min_width=min(min_width,img.shape[0])\n        min_height=min(min_height,img.shape[1])\n    except:\n        print('Not an image file at index:',index)\n        df.drop(index=index,inplace=True)\n    \nprint('minimum image width:',min_width,'minimum image height:',min_height)","ffbe442c":"IMG_SIZE=80 # chossing the image size as the minimum image width and height value available\nCHANNELS=3\n\ndef get_data(df,width,height): # function resizes all the images to same dimensions i.e width*height*number_of_channels\n    \n    data=[]\n    \n    for index,row in df.iterrows():\n        img=cv2.imread(row['path'])\n        label=row['class']\n        img=cv2.resize(img,(width,height))\n        data.append([np.array(img),label])\n    return data\n\n# resizig the images to IMG_SIZE*IMG_SIZE*CHANNELS\ndata=get_data(df,width=IMG_SIZE,height=IMG_SIZE)","c193a59d":"data[0][0].shape","17c36610":"## visualizing the samples after resizing the images\n\nrows=4\ncols=4\n\nfig=plt.figure(figsize=(8,8))\n\nfor index in range(1,rows*cols+1):\n    flower_img=data[index-1][0]\n    flower_class=data[index-1][1]\n    \n    axis=fig.add_subplot(rows,cols,index)\n    axis.set_xticks([]) \n    axis.set_yticks([])\n    plt.xlabel(flower_class)\n    plt.imshow(flower_img)\nplt.show()","4c477193":"X=[]\nY=[]\n\nfor elem in data:\n    X.append(elem[0])\n    Y.append(mapping.get(elem[1]))\n    \nX=np.array(X)\nY=np.array(Y)","cea48731":"## standardising the rgb channel values between 0 and 1\n\nX=X\/255.0","81455550":"# converting the labels into categorical values which keras expects\nY = to_categorical(Y,num_classes = 5)","8cb6284d":"x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=0)\nx_train,x_validate,y_train,y_validate=train_test_split(x_train,y_train,random_state=0)","54527626":"def cnn_model_1(img_size,channels):\n    \n    model = Sequential()\n\n    # 1st Convolutional Layer\n    model.add(Conv2D(filters=64, kernel_size=(3,3),padding=\"Same\",activation=\"relu\" , input_shape = (img_size,img_size,channels)))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    # 2nd Convolutional Layer\n    model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    # 3rd Convolutional Layer\n    model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    # 4th Convolutional Layer\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Dropout(0.5))\n    \n    # 4th Convolutional Layer\n    model.add(Conv2D(filters=1024, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Flatten())\n    # 1st Fully Connected Layer\n    model.add(Dense(1024,activation=\"relu\"))\n    model.add(Dropout(0.5))\n    # Add output layer\n    model.add(Dense(5,activation=\"softmax\"))\n    \n    model.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=0.001),\n              metrics=['accuracy'])\n    \n    return model\n\nmodel=cnn_model_1(img_size=IMG_SIZE,channels=CHANNELS)\nmodel.summary() # print summary my model","f4a0299c":"x_train.shape,x_validate.shape,y_train.shape,y_validate.shape","ce014090":"history = model.fit(x_train,y_train,epochs=20,validation_data=(x_validate,y_validate))","df8c90a6":"print(\"Test Accuracy: {0:.2f}%\".format(model.evaluate(x_test,y_test)[1]*100))","2fd56478":"fig,axis=plt.subplots(1,2)\nfig.set_size_inches(20,10)\n\nepochs=[i for i in range(20)]\n\ntrain_loss=history.history['loss']\nvalidation_loss=history.history['val_loss']\n\ntrain_accuracy=history.history['accuracy']\nvalidation_accuracy=history.history['val_accuracy']\n\n\naxis[0].plot(epochs,train_loss,color='b',label='Train Loss')\naxis[0].plot(epochs,train_accuracy,color='r',label='Train Accuracy')\naxis[0].set_title('Training Accuracy And Loss')\naxis[0].set_xlabel('Epochs')\naxis[0].legend()\n\naxis[1].plot(epochs,validation_loss,color='b',label='Validation Loss')\naxis[1].plot(epochs,validation_accuracy,color='r',label='Validation Accuracy')\naxis[1].set_title('Validation Accuracy And Loss')\naxis[1].set_xlabel('Epochs')\naxis[1].legend()\n\nplt.show()","45f07435":"def get_prediction_labels(model,x_validate,y_validate):\n    \n    y_validate_prediction_categorical=model.predict(x_validate)\n    y_validate_labels=[]\n    y_validate_prediction_labels=[]\n\n    for prediction in y_validate_prediction_categorical:\n        y_validate_prediction_labels.append(prediction.argmax())\n\n    for prediction in y_validate:\n        y_validate_labels.append(prediction.argmax())\n\n    y_validation_labels=np.array(y_validate_labels)\n    y_validate_prediction_labels=np.array(y_validate_prediction_labels)\n    \n    return y_validate_labels,y_validate_prediction_labels","5da8b45c":"y_validate_labels,y_validate_prediction_labels=get_prediction_labels(model,x_validate,y_validate)","48298b81":"y_validate_prediction_labels.shape","dc2cecca":"conf_matrix=confusion_matrix(y_validate_labels,y_validate_prediction_labels)\nsns.heatmap(conf_matrix,annot=True,fmt='g')\nplt.show()","ec2b9482":"print(classification_report(y_validate_labels,y_validate_prediction_labels))","37bf2ea9":"datagen = ImageDataGenerator(\n    rotation_range=60,  # randomly rotate images in the range (0 to 60 degrees)\n    zoom_range = 0.1, # Randomly zooms image between [1-value,1+value] i.e [0.9,1.1] which means zoom btw 90% (zoom in) and (110%) zoom out \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.5, # shifts the images vertically (fraction of total height)\n    fill_mode = \"reflect\"\n    ) \ndatagen.fit(x_train)","602b88e6":"model=cnn_model_1(img_size=IMG_SIZE,channels=CHANNELS)\nhistory = model.fit(datagen.flow(x_train,y_train),epochs=20,validation_data=(x_validate,y_validate))","b60aa6a0":"## Plotting the new results\n\nfig,axis=plt.subplots(1,2)\nfig.set_size_inches(20,10)\n\nepochs=[i for i in range(20)]\n\ntrain_loss=history.history['loss']\nvalidation_loss=history.history['val_loss']\n\ntrain_accuracy=history.history['accuracy']\nvalidation_accuracy=history.history['val_accuracy']\n\n\naxis[0].plot(epochs,train_loss,color='b',label='Train Loss')\naxis[0].plot(epochs,train_accuracy,color='r',label='Train Accuracy')\naxis[0].set_title('Training Accuracy And Loss')\naxis[0].set_xlabel('Epochs')\naxis[0].legend()\n\naxis[1].plot(epochs,validation_loss,color='b',label='Validation Loss')\naxis[1].plot(epochs,validation_accuracy,color='r',label='Validation Accuracy')\naxis[1].set_title('Validation Accuracy And Loss')\naxis[1].set_xlabel('Epochs')\naxis[1].legend()\n\nplt.show()","e606270a":"y_validate_labels,y_validate_prediction_labels=get_prediction_labels(model,x_validate,y_validate)","5d53e3c8":"conf_matrix=confusion_matrix(y_validate_labels,y_validate_prediction_labels)\nsns.heatmap(conf_matrix,annot=True,fmt='g')\nplt.show()","1eca3375":"print(classification_report(y_validate_labels,y_validate_prediction_labels))","a70fda70":"print('Test Score:',model.evaluate(x_test,y_test)[1]*100,'%')","40f6ae73":"pretrained_model = VGG19(input_shape = (IMG_SIZE, IMG_SIZE, CHANNELS), include_top = False, weights = 'imagenet')","98b9ad37":"pretrained_model.summary()","01615a1d":"# freezing the weights of the vgg19 layers so that they don't get updated during back propagation\n\nfor layer in pretrained_model.layers[:19]:\n    layer.trainable = False\n\nmodel = Sequential(\n    [\n        pretrained_model,\n        Dense(1024,activation='relu'),\n        Flatten(),\n        Dense(5, activation = 'softmax')\n    ]\n)","2ae952eb":"model.summary()","c977b1dd":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","f931b3be":"x_train.shape,y_train.shape,x_validate.shape,y_validate.shape,x_test.shape,y_test.shape","2ff42df8":"history = model.fit(datagen.flow(x_train,y_train), epochs = 20, validation_data =(x_validate,y_validate))","512b3164":"## Plotting the new results\n\nfig,axis=plt.subplots(1,2)\nfig.set_size_inches(20,10)\n\nepochs=[i for i in range(20)]\n\ntrain_loss=history.history['loss']\nvalidation_loss=history.history['val_loss']\n\ntrain_accuracy=history.history['accuracy']\nvalidation_accuracy=history.history['val_accuracy']\n\n\naxis[0].plot(epochs,train_loss,color='b',label='Train Loss')\naxis[0].plot(epochs,train_accuracy,color='r',label='Train Accuracy')\naxis[0].set_title('Training Loss And Accuracy')\naxis[0].set_xlabel('Epochs')\naxis[0].legend()\n\naxis[1].plot(epochs,validation_loss,color='b',label='Validation Loss')\naxis[1].plot(epochs,validation_accuracy,color='r',label='Validation Accuracy')\naxis[1].set_title('Validation Loss And Accuracy')\naxis[1].set_xlabel('Epochs')\naxis[1].legend()\n\nplt.show()","56f0cab8":"print('Test Accuracy:',model.evaluate(x_test,y_test)[1]*100,'%')","8ffed0dd":"y_validate_labels,y_validate_prediction_labels=get_prediction_labels(model,x_validate,y_validate)","37e3dd03":"conf_matrix=confusion_matrix(y_validate_labels,y_validate_prediction_labels)\nsns.heatmap(conf_matrix,annot=True,fmt='g')\nplt.show()","acb90e99":"print(classification_report(y_validate_labels,y_validate_prediction_labels))","05d8fb99":"### The training examples are not uniformly distributed across each classes.","a42a708c":"## Observations\n\n### 1) The model gives good results with VGG19 model used along With Data Augmentation\n### 2) The Recall Value for class 4 i.e Daisy is very low","6838e595":"### To Reduce Overfitting Using Data Augmentation","8929bca1":"## Thanks For Your Time!! Any Suggestions Would Be Appreciated.","2587af81":"## Self Created CNN Model With Data Augmentation ","67597c97":"### The model is overfitting the train set.","8f1ded48":"### The model is performing better on the validation set than the train set and there is no overfitting.","2b88e30f":"## Using Self Created CNN Model","a4b1f0a0":"## Plotting the Results","3b389549":"## Using Pretrained VGG19 model with data augmentation","e32510c3":"### After Augumentation Fitting the model"}}