{"cell_type":{"87ec3b4a":"code","255723f2":"code","f736cca1":"code","c4212125":"code","677da479":"code","7a83a90b":"code","96699152":"code","ba69e25b":"code","c2af3e3b":"code","db27d8ab":"code","55ee65de":"code","227ffc5f":"code","47e241d0":"code","5d385dbb":"code","1e104bbb":"code","2fd87c7f":"code","3bf03ac8":"code","cc9b1c58":"code","548f855e":"code","74d19a13":"code","43a91d1e":"code","21ff6f2a":"markdown"},"source":{"87ec3b4a":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=Monoton&effect=3d';      \n    <\/style><h1 class='font-effect-3d' \n    style='font-family:Monoton; color:#ff1155; font-size:35px;'>\n    %s<\/h1>\"\"\"%str))","255723f2":"dhtml('Code Modules & Functions')","f736cca1":"import numpy as np,pandas as pd,pylab as pl\nimport os,torch\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom torchvision import transforms,utils\nfrom PIL import Image\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")\ntrain_csv='train.csv'; test_csv='test.csv'\nimg_path='AFAD-Lite'","c4212125":"@register_line_magic\ndef display_examples(data):\n    for images,labels in dataloaders[data]:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow(np.transpose(images[i],(1,2,0)))\n        break","677da479":"def conv31(in_planes,out_planes,stride=1):\n    return tnn.Conv2d(in_planes,out_planes,\n                      kernel_size=3,stride=stride,\n                      padding=1,bias=False)\ndef cost_fit(targets,predictions):\n    return torch.mean((targets.float()-predictions)**2)\ndef mae_mse(model,data_loader):\n    mae,mse,num_examples=\\\n    torch.tensor([0.]),torch.tensor([0.]),0\n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.float().to(dev)\n        logits,probs,predictions=model(features)\n        assert len(targets.size())==1\n        assert len(predictions.size())==1\n        predicted_labels=torch.round(predictions).float()\n        num_examples+=targets.size(0)\n        mae+=torch.abs(predicted_labels-targets).sum()\n        mse+=torch.sum((predicted_labels-targets)**2)\n    return mae\/num_examples,mse\/num_examples","7a83a90b":"dhtml('Data')","96699152":"!git clone https:\/\/github.com\/afad-dataset\/tarball-lite.git","ba69e25b":"!cat tarball-lite\/AFAD-Lite.tar.xz*>tarball-lite\/AFAD-Lite.tar.xz","c2af3e3b":"!tar xf tarball-lite\/AFAD-Lite.tar.xz","db27d8ab":"files=[os.path.relpath(os.path.join(dirpath,fn),img_path) \\\nfor (dirpath,dirnames,filenames) in os.walk(img_path) \\\nfor fn in filenames if fn.endswith('.jpg')]\nd={'age':[],'gender':[],\n   'file':[],'path':[]}\nfor f in files:\n    age,gender,fn=f.split('\/')\n    if gender=='111': gender='male'\n    else: gender='female'        \n    d['age'].append(age)\n    d['gender'].append(gender)\n    d['file'].append(fn)\n    d['path'].append(f)\ndf=pd.DataFrame.from_dict(d)\ndf['age']=df['age'].values.astype(int)-18\nnp.random.seed(123)\nids=np.random.rand(len(df))<.8\ndf_train=df[ids]; df_test=df[~ids]\ndf_train.set_index('file',inplace=True)\ndf_train.to_csv(train_csv)\ndf_test.set_index('file',inplace=True)\ndf_test.to_csv(test_csv)\nnum_classes=np.unique(df['age'].values).shape[0]\nprint([num_classes,len(files)]); df.head()","55ee65de":"class AFADAgeData(tds):\n    def __init__(self,csv_path,img_dir,transform=None):\n        df=pd.read_csv(csv_path,index_col=0)\n        self.img_dir=img_dir\n        self.csv_path=csv_path\n        self.img_paths=df['path']\n        self.y=df['age'].values\n        self.transform=transform\n    def __getitem__(self,index):\n        img=Image.open(os.path\\\n        .join(self.img_dir,self.img_paths[index]))\n        if self.transform is not None:\n            img=self.transform(img)\n        lbl=self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","227ffc5f":"batch_size=256; num_workers=4\ngrayscale=False; img_size=120\ntrans=transforms\\\n.Compose([transforms.Resize((128,128)),\n          transforms.RandomCrop((img_size,img_size)),\n          transforms.ToTensor()])\ntrans2=transforms\\\n.Compose([transforms.Resize((128,128)),\n          transforms.CenterCrop((img_size,img_size)),\n          transforms.ToTensor()])\ntrain=AFADAgeData(csv_path=train_csv,\n                  img_dir=img_path,\n                  transform=trans)\ntest=AFADAgeData(csv_path=test_csv,\n                 img_dir=img_path,\n                 transform=trans2)\ndataloaders={'train':tdl(dataset=train,batch_size=batch_size,\n                         shuffle=True,num_workers=num_workers),\n             'test':tdl(dataset=test,batch_size=batch_size,\n                        shuffle=True,num_workers=num_workers)}","47e241d0":"%display_examples test","5d385dbb":"dhtml('Ordinal Regression CNN')","1e104bbb":"class BasicBlock(tnn.Module):\n    expansion=1\n    def __init__(self,inplanes,planes,stride=1,downsample=None):\n        super(BasicBlock,self).__init__()\n        self.conv1=conv31(inplanes,planes,stride)\n        self.bn1=tnn.BatchNorm2d(planes)\n        self.relu=tnn.ReLU(inplace=True)\n        self.conv2=conv31(planes,planes)\n        self.bn2=tnn.BatchNorm2d(planes)\n        self.downsample=downsample\n        self.stride=stride\n    def forward(self,x):\n        residual=x\n        out=self.conv1(x)\n        out=self.bn1(out)\n        out=self.relu(out)\n        out=self.conv2(out)\n        out=self.bn2(out)\n        if self.downsample is not None:\n            residual=self.downsample(x)\n        out+=residual\n        out=self.relu(out)\n        return out","2fd87c7f":"class ResNN(tnn.Module):\n    def __init__(self, block,layers,num_classes,grayscale):\n        self.num_classes=num_classes\n        self.inplanes=64\n        base_num=64\n        if grayscale: in_dim=1\n        else: in_dim=3\n        super(ResNN,self).__init__()\n        self.conv1=tnn\\\n        .Conv2d(in_dim,base_num,kernel_size=7,\n                stride=2,padding=3,bias=False)\n        self.bn1=tnn.BatchNorm2d(base_num)\n        self.relu=tnn.ReLU(inplace=True)\n        self.maxpool=tnn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n        self.layer1=self._make_layer(block,base_num,layers[0])\n        self.layer2=self._make_layer(block,2*base_num,layers[1],stride=2)\n        self.layer3=self._make_layer(block,4*base_num,layers[2],stride=2)\n        self.layer4=self._make_layer(block,8*base_num,layers[3],stride=2)\n        self.avgpool=tnn.AvgPool2d(7,stride=1,padding=2)\n        self.fc=tnn.Linear(2048*block.expansion,num_classes)\n        self.a=tnn.Parameter(torch.zeros(\n            self.num_classes).float().normal_(0.,.1).view(-1,1))\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n                m.weight.data.normal_(0,(2.\/n)**.5)\n            elif isinstance(m,tnn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n    def _make_layer(self,block,planes,blocks,stride=1):\n        downsample=None\n        if stride!=1 or self.inplanes!=planes*block.expansion:\n            downsample=tnn.Sequential(\n                tnn.Conv2d(self.inplanes,planes*block.expansion,\n                           kernel_size=1,stride=stride,bias=False),\n                tnn.BatchNorm2d(planes*block.expansion),)\n\n        layers=[]\n        layers.append(block(self.inplanes,planes,stride,downsample))\n        self.inplanes=planes*block.expansion\n        for i in range(1,blocks):\n            layers.append(block(self.inplanes,planes))\n        return tnn.Sequential(*layers)\n    def forward(self, x):\n        x=self.conv1(x); x=self.bn1(x)\n        x=self.relu(x); x=self.maxpool(x)\n        x=self.layer1(x); x=self.layer2(x)\n        x=self.layer3(x); x=self.layer4(x)\n        x=self.avgpool(x)\n        x=x.view(x.size(0),-1)\n        logits=self.fc(x)\n        probs=torch.softmax(logits,dim=1)\n        predictions=((self.num_classes-1)*torch\\\n                     .sigmoid(probs.mm(self.a).view(-1)))\n        return logits,probs,predictions\ndef ResNN34(num_classes,grayscale):\n    return ResNN(block=BasicBlock,\n                 layers=[3,4,6,3],\n                 num_classes=num_classes,\n                 grayscale=grayscale)","3bf03ac8":"dhtml('Training')","cc9b1c58":"random_seed=12; learning_rate=.0005\ntorch.manual_seed(random_seed)\ntorch.cuda.manual_seed(random_seed)\nmodel=ResNN34(num_classes,grayscale)\nmodel.to(dev)\noptimizer=torch.optim\\\n.Adam(model.parameters(),lr=learning_rate)","548f855e":"epochs=130\nfor epoch in range(epochs):\n    model.train()\n    for batch_ids,(features,targets) \\\n    in enumerate(dataloaders['train']):\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs,predictions=model(features)\n        assert len(targets.size())==1\n        assert len(predictions.size())==1\n        cost=cost_fit(targets,predictions)\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n        if not batch_ids%100:\n            st='Epoch: %03d\/%03d | Batch: %04d\/%04d | Cost: %.4f'\n            print(st%(epoch+1,epochs,batch_ids,\n                     len(dataloaders['train']),cost))","74d19a13":"dhtml('Evaluation')","43a91d1e":"model.eval()\nwith torch.set_grad_enabled(False):\n    train_mae,train_mse=\\\n    mae_mse(model,dataloaders['train'])\n    test_mae,test_mse=\\\n    mae_mse(model,dataloaders['test'])\n    st='MAE\/RMSE => Train: %.2f\/%.2f | Test: %.2f\/%.2f'\n    print(st%(train_mae,torch.sqrt(train_mse),\n              test_mae,torch.sqrt(test_mse)))","21ff6f2a":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/ordinal\/ordinal-cnn-beckham2016-afadlite.ipynb)\n\n[Google Colaboratory Version](https:\/\/colab.research.google.com\/drive\/1Nkr8BybYG-iIy7nha-A6S2d2QIa3rTx2)"}}