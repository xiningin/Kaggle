{"cell_type":{"5f31e72b":"code","ee94e0af":"code","9de47444":"code","c5c596aa":"code","1dbccf26":"code","ef788a4c":"code","2c5dd232":"code","f7af5e52":"code","42e95fde":"code","a9aa3878":"code","b8d2d24f":"code","bebe1004":"code","82184adb":"code","44830bbd":"code","508551ce":"code","8b45e764":"code","73ce7c05":"code","accea881":"code","f2bb240b":"code","f021a620":"code","0bb15bae":"code","7af7293b":"code","0c5f785d":"code","8810fea0":"code","337c768f":"code","e7905ff2":"markdown","057d56dd":"markdown","671c796e":"markdown","cb8a06fe":"markdown","366ac20a":"markdown","525368bd":"markdown","e5115059":"markdown","838b96ae":"markdown","5ab6bcde":"markdown","0e21c643":"markdown","802fb595":"markdown","c68ffd56":"markdown","4002a550":"markdown","211b92ea":"markdown","0f4ccb65":"markdown","29583d3c":"markdown","c3645fee":"markdown","c61694c9":"markdown","9912d69f":"markdown","0bbcb749":"markdown"},"source":{"5f31e72b":"!pip install -q efficientnet_pytorch > \/dev\/null","ee94e0af":"from glob import glob\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nimport sklearn\n\nSEED = 512\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","9de47444":"%%time\n\ndataset = []\n\nfor label, kind in enumerate(['Cover', 'JMiPOD', 'JUNIWARD', 'UERD']):\n    for path in glob('..\/input\/alaska2-image-steganalysis\/Cover\/*.jpg'):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.split('\/')[-1],\n            'label': label\n        })\n\nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\n\ngkf = GroupKFold(n_splits=32)\n\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number","c5c596aa":"# dataset = pd.read_csv('..\/input\/alaska2-public-baseline\/groupkfold_by_shonenkov.csv')","1dbccf26":"def get_train_transforms():\n    return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","ef788a4c":"DATA_ROOT_PATH = '..\/input\/alaska2-image-steganalysis'\n\ndef onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, kinds, image_names, labels, transforms=None):\n        super().__init__()\n        self.kinds = kinds\n        self.image_names = image_names\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        kind, image_name, label = self.kinds[index], self.image_names[index], self.labels[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}\/{kind}\/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n        target = onehot(4, label)\n        return image, target\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)","2c5dd232":"fold_number = 0\n\ntrain_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] != fold_number].kind.values,\n    image_names=dataset[dataset['fold'] != fold_number].image_name.values,\n    labels=dataset[dataset['fold'] != fold_number].label.values,\n    transforms=get_train_transforms(),\n)\n\nvalidation_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] == fold_number].kind.values,\n    image_names=dataset[dataset['fold'] == fold_number].image_name.values,\n    labels=dataset[dataset['fold'] == fold_number].label.values,\n    transforms=get_valid_transforms(),\n)","f7af5e52":"image, target = train_dataset[0]\nnumpy_image = image.permute(1,2,0).cpu().numpy()\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    \nax.set_axis_off()\nax.imshow(numpy_image);","42e95fde":"from sklearn import metrics\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n        \n        \ndef alaska_weighted_auc(y_true, y_valid):\n    \"\"\"\n    https:\/\/www.kaggle.com\/anokas\/weighted-auc-metric-updated\n    \"\"\"\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights = [2, 1]\n\n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n\n    # size of subsets\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n\n    # The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1.\n    normalization = np.dot(areas, weights)\n\n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (tpr < y_max)\n        # pdb.set_trace()\n\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min  # normalize such that curve starts at y=0\n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n\n    return competition_metric \/ normalization\n        \nclass RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = alaska_weighted_auc(self.y_true, self.y_pred)\n    \n    @property\n    def avg(self):\n        return self.score","a9aa3878":"class LabelSmoothing(nn.Module):\n    def __init__(self, smoothing = 0.05):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n\n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n    \n            smooth_loss = -logprobs.mean(dim=-1)\n\n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n\n            return loss.mean()\n        else:\n            return torch.nn.functional.cross_entropy(x, target)","b8d2d24f":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nclass Fitter:\n    \n    def __init__(self, model, device, config):\n        self.config = config\n        self.epoch = 0\n        \n        self.base_dir = '.\/'\n        self.log_path = f'{self.base_dir}\/log.txt'\n        self.best_summary_loss = 10**5\n\n        self.model = model\n        self.device = device\n\n        param_optimizer = list(self.model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ] \n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n        self.criterion = LabelSmoothing().to(self.device)\n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, validation_loader):\n        for e in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr = self.optimizer.param_groups[0]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR: {lr}')\n\n            t = time.time()\n            summary_loss, final_scores = self.train_one_epoch(train_loader)\n\n            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n            self.save(f'{self.base_dir}\/last-checkpoint.bin')\n\n            t = time.time()\n            summary_loss, final_scores = self.validation(validation_loader)\n\n            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                self.model.eval()\n                self.save(f'{self.base_dir}\/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}\/best-checkpoint-*epoch.bin'))[:-3]:\n                    os.remove(path)\n\n            if self.config.validation_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = AverageMeter()\n        final_scores = RocAucMeter()\n        t = time.time()\n        for step, (images, targets) in enumerate(val_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Val Step {step}\/{len(val_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            with torch.no_grad():\n                targets = targets.to(self.device).float()\n                batch_size = images.shape[0]\n                images = images.to(self.device).float()\n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n                final_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, final_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = AverageMeter()\n        final_scores = RocAucMeter()\n        t = time.time()\n        for step, (images, targets) in enumerate(train_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Train Step {step}\/{len(train_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            \n            targets = targets.to(self.device).float()\n            images = images.to(self.device).float()\n            batch_size = images.shape[0]\n\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            \n            final_scores.update(targets, outputs)\n            summary_loss.update(loss.detach().item(), batch_size)\n\n            self.optimizer.step()\n\n            if self.config.step_scheduler:\n                self.scheduler.step()\n\n        return summary_loss, final_scores\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        if self.config.verbose:\n            print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","bebe1004":"from efficientnet_pytorch import EfficientNet\n\ndef get_net():\n    net = EfficientNet.from_pretrained('efficientnet-b2')\n    net._fc = nn.Linear(in_features=1408, out_features=4, bias=True)\n    return net\n\nnet = get_net().cuda()","82184adb":"class TrainGlobalConfig:\n    num_workers = 4\n    batch_size = 22\n    n_epochs = 3\n    lr = 0.001\n\n    # -------------------\n    verbose = True\n    verbose_step = 1\n    # -------------------\n\n    # --------------------\n    step_scheduler = False  # do scheduler.step after optimizer.step\n    validation_scheduler = True  # do scheduler.step after validation stage loss\n\n#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n#     scheduler_params = dict(\n#         max_lr=0.001,\n#         epochs=n_epochs,\n#         steps_per_epoch=int(len(train_dataset) \/ batch_size),\n#         pct_start=0.1,\n#         anneal_strategy='cos', \n#         final_div_factor=10**5\n#     )\n    \n    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.6,\n        patience=1,\n        verbose=False, \n        threshold=0.001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-9,\n        eps=1e-09\n    )\n    # --------------------","44830bbd":"from catalyst.data.sampler import BalanceClassSampler\n\ndef run_training():\n    device = torch.device('cuda:0')\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        batch_size=TrainGlobalConfig.batch_size,\n        pin_memory=False,\n        drop_last=True,\n        num_workers=TrainGlobalConfig.num_workers,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        validation_dataset, \n        batch_size=TrainGlobalConfig.batch_size,\n        num_workers=TrainGlobalConfig.num_workers,\n        shuffle=False,\n        sampler=SequentialSampler(validation_dataset),\n        pin_memory=False,\n    )\n\n    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n    fitter.load(\"..\/input\/alaska2-checkpoint\/last-checkpoint.bin\")\n    fitter.fit(train_loader, val_loader)","508551ce":"!nvidia-smi","8b45e764":"run_training()","73ce7c05":"file = open('..\/input\/alaska2-checkpoint\/log.txt', 'r')\nfor line in file.readlines():\n    print(line[:-1])\nfile.close()","accea881":"checkpoint = torch.load('..\/input\/alaska2-checkpoint\/last-checkpoint.bin')\nnet.load_state_dict(checkpoint['model_state_dict']);\nnet.eval();","f2bb240b":"checkpoint.keys()","f021a620":"def get_test_transforms(mode):\n    if mode == 0:\n        return A.Compose([\n                A.Resize(height=512, width=512, p=1.0),\n                ToTensorV2(p=1.0),\n            ], p=1.0)\n    elif mode == 1:\n        return A.Compose([\n                A.HorizontalFlip(p=1),\n                A.Resize(height=512, width=512, p=1.0),\n                ToTensorV2(p=1.0),\n            ], p=1.0)    \n    elif mode == 2:\n        return A.Compose([\n                A.VerticalFlip(p=1),\n                A.Resize(height=512, width=512, p=1.0),\n                ToTensorV2(p=1.0),\n            ], p=1.0)\n    else:\n        return A.Compose([\n                A.HorizontalFlip(p=1),\n                A.VerticalFlip(p=1),\n                A.Resize(height=512, width=512, p=1.0),\n                ToTensorV2(p=1.0),\n            ], p=1.0)","0bb15bae":"class DatasetSubmissionRetriever(Dataset):\n\n    def __init__(self, image_names, transforms=None):\n        super().__init__()\n        self.image_names = image_names\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_name = self.image_names[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}\/Test\/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image_name, image\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]","7af7293b":"results = []\nfor mode in range(0, 4):\n    dataset = DatasetSubmissionRetriever(\n        image_names=np.array([path.split('\/')[-1] for path in glob('..\/input\/alaska2-image-steganalysis\/Test\/*.jpg')]),\n        transforms=get_test_transforms(mode),\n    )\n\n\n    data_loader = DataLoader(\n        dataset,\n        batch_size=8,\n        shuffle=False,\n        num_workers=2,\n        drop_last=False,\n    )\n    \n    result = {'Id': [], 'Label': []}\n    for step, (image_names, images) in enumerate(data_loader):\n        print(step, end='\\r')\n\n        y_pred = net(images.cuda())\n        y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n\n        result['Id'].extend(image_names)\n        result['Label'].extend(y_pred)\n        \n    results.append(result)","0c5f785d":"submissions = []\nfor mode in range(0,4):\n    submission = pd.DataFrame(results[mode])\n    submissions.append(submission)","8810fea0":"for mode in range(0,4):\n    submissions[mode].to_csv(f'submission_{mode}.csv', index=False)","337c768f":"submissions[0]['Label'] = (submissions[0]['Label']*3 + submissions[1]['Label'] + submissions[2]['Label'] + submissions[3]['Label']) \/ 6\nsubmissions[0].to_csv(f'submission.csv', index=False)","e7905ff2":"# EfficientNet","057d56dd":"# Label Smoothing","671c796e":"# Config","cb8a06fe":"%%time\n\nresult = {'Id': [], 'Label': []}\nfor step, (image_names, images) in enumerate(data_loader):\n    print(step, end='\\r')\n    \n    y_pred = net(images.cuda())\n    y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n    \n    result['Id'].extend(image_names)\n    result['Label'].extend(y_pred)","366ac20a":"# Dataset","525368bd":"In any case original dataframe with splitting:","e5115059":"# Main Ideas\n\n- 4 Classes\n- GroupKFold splitting\n- Class Balance\n- Flips\n- Label Smoothing\n- EfficientNetB2\n- ReduceLROnPlateau","838b96ae":"# Class Balance \"on fly\" from [@CatalystTeam](https:\/\/github.com\/catalyst-team\/catalyst)","5ab6bcde":"# Training\n\nI have used 1xV100 for training model, in kaggle kernel it works also. You can make fork and check it, but I would like to share with you my logs","0e21c643":"# Inference","802fb595":"In checkpoint you can find states for optimizer and scheduler if you need","c68ffd56":"# Alaska2 Baseline PyTorch\n\nHi everyone!\n\nMy name is Alex Shonenkov, I am DL\/NLP\/CV\/TS research engineer. Especially I am in Love with NLP & DL.\n\nI would like to share with you my starter pipeline for solving this competition :)","4002a550":"# Dependencies","211b92ea":"\n# This is a fork of Alex Shonenkov kernel with TTA added\n[[Train + Inference] GPU Baseline](https:\/\/www.kaggle.com\/shonenkov\/train-inference-gpu-baseline)","0f4ccb65":"# Metrics","29583d3c":"# Thank you for reading my kernel!","c3645fee":"# Fitter","c61694c9":"# Testing Time Augmentation","9912d69f":"# Simple Augs: Flips","0bbcb749":"# GroupKFold splitting\n\nI think group splitting by image_name is really important for correct validation in this competition ;) "}}