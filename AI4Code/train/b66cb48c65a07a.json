{"cell_type":{"e50d00c8":"code","2569c57c":"code","0eb8c601":"code","50551a10":"code","7be22887":"code","c794524c":"code","92bfac77":"code","539aa300":"code","80f98ab4":"code","a2c9dd70":"markdown"},"source":{"e50d00c8":"#importing libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPool2D\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix\nimport itertools","2569c57c":"#reading data\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","0eb8c601":"#train data x and y\nx_train = train.drop(labels = [\"label\"], axis = 1)\ny_train = train[\"label\"]","50551a10":"#normalizing and reshaping data\nx_train = x_train \/ 255.0 #pixel values vary between 0 and 255\ntest = test \/ 255.0\nx_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","7be22887":"#one hot encoding for y\ny_train = to_categorical(y_train)\n#train test split\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)","c794524c":"#defining the model\nmodel = Sequential()\n# 2 conv2d layers\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten()) #flattening the data into a 1D vector, before the fully connected layers\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(10, activation = 'softmax'))\n\n\n#optimizing the model: using Adam omptimizer\noptim=Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n#compiling the model\nmodel.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n#training the model\nmodel.fit(X_train, Y_train, epochs=10, batch_size=128)","92bfac77":"# Predicting the values from the validation dataset\nY_pred = model.predict(X_val)\n# converting one hot vectors to actual values \nY_pred = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \n# computing the confusion matrix\ncm = confusion_matrix(Y_true, Y_pred) \n\n#plotting the confusion matrix\nplt.imshow(cm)\nplt.title('confusion matrix')\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, range(10), rotation=45)\nplt.yticks(tick_marks, range(10))\n\nthresh = cm.max() \/ 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","539aa300":"#evaluating the model: 0.9926 accuracy\nloss_and_metrics = model.evaluate(X_val, Y_val, batch_size=128)\nloss_and_metrics","80f98ab4":"#predicting on the test set\ny_pred = model.predict(test, batch_size = 128)\npred = np.argmax(y_pred,axis = 1)\n\npred = pd.Series(pred,name=\"Label\")\n#preparing submission\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","a2c9dd70":"**Hi there!**\n\nHere you'll find a super simple implementation of the MNIST digit recognition using CNN.\nOf course, [Yassine's kernel](http:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6) was of a great help for me, as a beginner.\n\nFeel free to fork this notebook, or upvote it if you find it helpful :)"}}