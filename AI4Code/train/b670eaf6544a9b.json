{"cell_type":{"b62bb5b7":"code","d5f96513":"code","e189898a":"code","5aeb4c06":"code","9d074ff9":"code","48389f49":"code","010a7621":"code","4a040ad2":"code","08746392":"code","fc581190":"code","a2417cc6":"code","e29a8861":"code","56106503":"code","6c5f898f":"code","d498a125":"code","f119e846":"code","5d37c949":"code","3411e23c":"code","b6107c20":"code","eee6a552":"code","d85360ee":"code","c1bac7b6":"code","3cce2ee7":"code","ba5a1ea9":"code","6122b064":"code","e524f2a7":"code","c316c045":"code","7dda22db":"code","a2fbca52":"code","2a6d44c5":"markdown","96364877":"markdown","3030ed68":"markdown","9ef04045":"markdown","9ff847ca":"markdown","2d7312e9":"markdown","b51bc11f":"markdown","7f50972d":"markdown","1054260b":"markdown","9416615e":"markdown","b8971f20":"markdown","371e4f44":"markdown","cc3d3ba2":"markdown","111a5958":"markdown","3942e876":"markdown","481818b1":"markdown","9792b8ce":"markdown","432320d2":"markdown","31195a03":"markdown"},"source":{"b62bb5b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5f96513":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport xgboost as xgb\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold \nfrom sklearn.metrics import accuracy_score, make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import decomposition\n\n\n\n","e189898a":"train = pd.read_csv('..\/input\/cap-4611-assignment-2\/train.csv')\ntest = pd.read_csv('..\/input\/cap-4611-assignment-2\/eval.csv')\nsample = pd.read_csv(\"..\/input\/cap-4611-assignment-2\/train.csv\")","5aeb4c06":"#Examining the training data\ntrain","9d074ff9":"#Examining the training data further\nprint(\"Training data shape:\",train.shape, end=\"\\n\\n\")\ntrain.info()","48389f49":"train.describe()","010a7621":"#Examining the test data\ntest","4a040ad2":"test.describe()","08746392":"test.info()","fc581190":"#Checking the frequency of each rating\nprint(train[\"esrb_rating\"].value_counts())\n\n#Plotting the frequency of ESRB rating\nax = plt.subplots(figsize=(10,10))\ntrain[\"esrb_rating\"].value_counts().plot.bar();","a2417cc6":"#Spliting the console column to analyze it\nd = train[['console']]\nps, both = [], []\nfor val in d.console:\n    if val == 0:\n        ps.append(1)\n        both.append(0)\n    else:\n        both.append(1)\n        ps.append(0)\n\n#Checking the frequency of each category\ndf = train.drop(columns = ['title','id','esrb_rating', 'console'], axis=1)\ndf.insert(0,'Only_PS4',ps)\ndf.insert(1,'PS4andXbox',both)\ndf = df.sum()\ndf = df.reset_index() \ndf.rename(columns={\"index\" : \"Categories\", 0 : \"Count\"}, inplace=True)\n\nprint(df)","e29a8861":"#Plotting the frequency of each category\nsns.catplot(x=\"Categories\", y=\"Count\", data=df,kind=\"bar\", ci=None, height=6, aspect = 2)\nplt.xticks(rotation=90)\nplt.show()\n","56106503":"#Checking the frequency of each rating in every cattegory\ndf = train.drop(columns = ['id', 'title', 'esrb_rating', 'console'], axis=1)\ndf.insert(0,'Only_PS4',ps)\ndf.insert(1,'PS4andXbox',both)\nratings = train[['esrb_rating']]\ncolumns = df.columns.values.tolist()\nsave = {}\n\nfor col in columns:\n    save[col]=[]\n    for i in range(len(df)):\n        if df.loc[i, col] == 1:\n            save[col].insert(i,ratings.loc[i,'esrb_rating'])\n\nratings = ratings.esrb_rating.unique()\ndf = pd.DataFrame(index=columns, columns=ratings)\nfor col in columns:\n    for r in ratings:\n        df.loc[col, r] = save[col].count(r)\nprint(df)","6c5f898f":"#Plotting the frequency of each rating in every cattegory\nfig,ax = plt.subplots(figsize=(20,10))\nax.bar(df.index, df[\"E\"], label=\"E\")\nax.bar(df.index, df[\"ET\"], bottom=df[\"E\"],\n       label=\"ET\")\nax.bar(df.index, df[\"T\"],\n       bottom=df[\"E\"] + df[\"ET\"],\n       label=\"T\")\nax.bar(df.index, df[\"M\"],\n       bottom=df[\"E\"] + df[\"ET\"]+ df['T'],\n       label=\"M\")\nax.set_xticklabels(df.index, rotation=90)\nax.set_ylabel('Number of Occurences')\nax.legend(prop={'size': 20})\nplt.show()","d498a125":"# Plotting distribution of games Platformwise\n\nps = len(train[train['console'] == 0 ])\nboth = len(train[train['console'] == 1 ])\nnameList = ['Play Station Exclusives','Available on both']\nnameValues = [ps,both]\n\nplt.figure(figsize=(17, 5))\nplt.subplot(1,2,1)\nplt.bar(nameList, nameValues, color = 'green')\nplt.title('Game Distribution by Platform')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.pie(nameValues, labels = nameList,autopct='%1.2f%%')\nplt.title('Game Distribution by Platform')\nplt.show()\n","f119e846":"def DistributionPlotter(dataFrame, featureName, setName):\n    uniqueVals = set(dataFrame[featureName])\n    countArr =  []\n    \n    for mem in uniqueVals:\n        countArr.append(len(dataFrame[dataFrame[featureName] == mem]))\n    \n    plt.figure(figsize=(17, 5))\n    plt.subplot(1,2,1)\n    plt.bar(list(uniqueVals), countArr, color = 'orange')\n    plt.title(str(setName))\n    plt.grid(True)\n\n    plt.subplot(1, 2, 2)\n    plt.pie(countArr, labels = list(uniqueVals),autopct='%1.2f%%')\n    plt.title(str(setName))\n    plt.show()\n    ","5d37c949":"DistributionPlotter(train, 'esrb_rating', 'Rating distribution')","3411e23c":"#Getting the distribution of ratings by category type\nfor col in train.columns[2:34]:\n    if col =='console':\n        df = train[train[col] == 1]\n        DistributionPlotter(df, 'esrb_rating', 'PS Exclusives Rating distribution')\n        df2 = train[train[col] == 0]\n        DistributionPlotter(df, 'esrb_rating', 'Both Consoles Rating distribution')\n    else:\n        df = train[train[col] == 1]\n        DistributionPlotter(df, 'esrb_rating', f'Rating distribution by {col}')","b6107c20":"df = train\n\n#Spliting and encoding the console column\nd = train[['console']]\nps, both = [], []\n\nfor val in d.console:\n    if val == 0:\n        ps.append(1)\n        both.append(0)\n    else:\n        both.append(1)\n        ps.append(0)\n        \ndf = train.drop(columns = ['title', 'esrb_rating'])\ndf.insert(1,'Only_PS4',ps)\ndf.insert(2,'PS4andXbox',both)\n\n#Encoding the esrb ratings\ncols=[]\nd = train[['esrb_rating']]\nfor rating in d.esrb_rating.unique():\n    f = d.copy()\n    f[f != rating] = 0\n    f[f == rating] = 1\n    f = f.rename(columns={'esrb_rating': rating})\n    p = f.copy()\n    df[rating] = p\n    df[rating]= df[rating].astype('int64')\n    \n#producing a heatmap\nplt.figure(figsize = (20, 15))\nsns.heatmap(df.corr(), linewidths = 1, cmap=\"nipy_spectral\")\nplt.show()\n","eee6a552":"\"\"\"#Creating a pipeline for the data sets\ndef preprocessTrain(df, scaler):\n    df = df.copy()\n    \n    #Shuffling the data\n    df = df.sample(frac=1.0, random_state=1).reset_index(drop=True)\n    \n    #Splitting the rating column\n    y = df['esrb_rating']\n    \n    #Dropping unnecessary columns\n    X = df.drop(columns = ['id', 'title', 'console','esrb_rating'], axis=1)\n\n    #Scaling X\n    scaler.fit(X)\n    X = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)\n    return X, y\n\ndef preprocessTest(df, scaler):\n    df = df.copy()\n    \n    #Saving the id column\n    sid = df[\"id\"]\n    \n    #Dropping unnecessary columns\n    X = df.drop(columns = ['id', 'console'], axis=1)\n    \n    #Shuffling the data\n    df = df.sample(frac=1.0, random_state=1).reset_index(drop=True)\n\n    #Scaling the data\n    scaler.fit(X)\n    X = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)\n    return X\"\"\"","d85360ee":"\"\"\"#Transforming the data using scaling\nscaler = StandardScaler()\nX, y = preprocessTrain(train, scaler=scaler)\n\n #Converting the ESRB ratings to numerical values\ny = y.map({'E': 0, 'ET': 1, 'T': 2, 'M': 3})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n\ntest2 = preprocessTest(test, scaler=scaler)\"\"\"\n","c1bac7b6":"#Splitting the rating column\ny = train['esrb_rating']\n\n#Converting the ESRB ratings to numerical values\ny = y.map({'E': 0, 'ET': 1, 'T': 2, 'M': 3})\n\n#Saving the id for my submission\nsid = test[\"id\"]\n\n#Dropping unnecessary columns\nX = train.drop(columns = ['id', 'title', 'console','esrb_rating','animated_blood', 'mature_humor', 'nudity','partial_nudity'], axis=1)\ntest2 = test.drop(columns = ['id', 'console', 'animated_blood', 'mature_humor', 'nudity','partial_nudity'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)","3cce2ee7":"#List to hold best scores and models\ns_best, m_best = [], []\n\n#Pipline to train the models\ndef modelTraining(m_type, t_model, t_params, t_best, t_result, t_score, t_cv, t_df):\n    for i in range(2, 21): \n    \n        #Building the models\n        t_result = GridSearchCV(m_type, t_params, scoring='accuracy', cv=5, verbose=0)\n        t_result.fit(X_train, y_train)\n\n        # Comparing and Replacing Data\n        t_score = t_result.score(X_train, y_train)\n    \n        #Printing Scores\n        print(\"Model \"+str(i)+\" Score: \", t_score)\n        if t_score > t_best:\n            print(\"Current Best Score: {}\".format(t_score))\n        else:\n            print(\"Current Best Score: {}\".format(t_best))\n        if i == 50:\n            print(\"Best Score: {}\".format(t_best), end=\"\\n\\n\")\n            \n        #Saving the best score\n        if t_score > t_best:\n            t_best = t_score\n            t_model = t_result\n\n    #Saving the best score and model\n    s_best.append(t_best)\n    m_best.append(t_model)\n        \n    #The best score and paramerter configuration\n    print(\"Best Score: {}\".format(t_best))\n    print(\"Best Parameters:\")\n    for key, value in list(t_model.best_params_.items()): \n        print(f\"{key}: {value}\")\n\n    t_cv = cross_val_score(t_model, X, y, cv=50, n_jobs=-1)\n    t_df = pd.DataFrame(t_cv)\n    print('')\n    print(\"Cross Validation\\nSummary Statistics:\")\n    print(f\"{t_df.describe().to_string()}\\n\")\n\n    sns.displot(t_cv, bins=25, color = 'r')\n    plt.xticks(rotation=90)\n    plt.title(\"CV Score Distribution\")\n    plt.show()","ba5a1ea9":"lr = LogisticRegression(max_iter=4000)\n#Setting the parameters for GridSearch\npenalty = ['l1', 'l2']\nsolver = ['liblinear', 'saga']\nC = [150, 175, 200, 225, 250]\nlr_params = {\"penalty\": penalty,\"solver\": solver,\"C\": C}\n\n#Creating the first model\nlr_model = GridSearchCV(lr, lr_params, scoring='accuracy', cv=5, verbose=0)\nlr_model.fit(X_train, y_train)\ny_pred = lr_model.predict(X_test)\nlr_best = lr_model.score(X_test, y_test)\nprint(\"First Model Score: {}\".format(lr_best))\n\n#Initializing variables\nlr_result = 0\nlr_score = 0\nlr_cv = 0\nlr_df = 0\n\n#Training multiple models\nmodelTraining(lr, lr_model, lr_params, lr_best, lr_result, lr_score, lr_cv, lr_df)","6122b064":"svm = SVC()\n#Setting the parameters for GridSearch\nC = [.25, .5, 1, 1.5, 2, 2.5, 3]\nkernel = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\ngamma = [\"scale\", \"auto\"]\nsvm_params = {\"C\": C,\"kernel\": kernel,\"gamma\": gamma}\n\n#Creating the first model\nsvm_model = GridSearchCV(svm, svm_params, scoring='accuracy', cv=5, verbose=0)\nsvm_model.fit(X_train, y_train)\ny_pred = svm_model.predict(X_test)\nsvm_best = svm_model.score(X_test, y_test)\nprint(\"First Model Score: {}\".format(svm_best))\n\n#Initializing variables\nsvm_result = 0\nsvm_score = 0\nsvm_cv = 0\nsvm_df = 0\n\n#Training multiple models\nmodelTraining(svm, svm_model, svm_params, svm_best, svm_result, svm_score, svm_cv, svm_df)","e524f2a7":"dt = DecisionTreeClassifier()\n#Setting the parameters for GridSearch\ncriterion = [\"gini\", \"entropy\"]\nsplitter = [\"best\",\"random\"]\ndt_params = {\"criterion\": criterion,\"splitter\": splitter}\n\n#Creating the first model\ndt_model = GridSearchCV(dt, dt_params, scoring='accuracy', cv=5, verbose=0)\ndt_model.fit(X_train, y_train)\ny_pred = dt_model.predict(X_test)\ndt_best = dt_model.score(X_test, y_test)\nprint(\"First Model Score: {}\".format(dt_best))\n\n#Initializing variables\ndt_result = 0\ndt_score = 0\ndt_cv = 0\ndt_df = 0\n\n#Training multiple models\nmodelTraining(dt, dt_model, dt_params, dt_best, dt_result, dt_score, dt_cv, dt_df)","c316c045":"rf = RandomForestClassifier(n_jobs=-1)\n#Setting the parameters for GridSearch\nn_estimators = [81, 83, 85, 87, 90, 93, 96]\ncriterion = ['gini','entropy']\nmax_depth = [12, 13, 14, 15]\nmax_features = ['log2','sqrt','auto']\nrandom_state = [random.randint(0, 781967287)]\nrf_params = {\"n_estimators\": n_estimators,\"criterion\": criterion,\"max_depth\": max_depth,\n                 \"max_features\": max_features,\"random_state\": random_state}\n\n#Creating the first model\nrf_model = GridSearchCV(rf, rf_params, scoring='accuracy', cv=5, verbose=0)\nrf_model.fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\nrf_best = rf_model.score(X_test, y_test)\nprint(\"First Model Score: {}\".format(rf_best))\n\n#Initializing variables\nrf_result = 0\nrf_score = 0\nrf_cv = 0\nrf_df = 0\n\n#Training multiple models\nmodelTraining(rf, rf_model, rf_params, rf_best, rf_result, rf_score, rf_cv, rf_df)","7dda22db":"knn = KNeighborsClassifier(n_jobs=-1)\n#Setting the parameters for GridSearch\nn_neighbors = [5, 6, 7, 8, 9, 10]\nweights = ['distance', 'uniform']\nalgorithm = ['ball_tree','kd_tree','auto', 'brute']\nleaf_size = [1,2,3]\np = [1,2]\nmetric = [\"minkowski\"]\nknn_params = {\"n_neighbors\": n_neighbors,\"weights\": weights,\"algorithm\": algorithm,\n                  \"leaf_size\": leaf_size,\"p\": p,\"metric\": metric}\n\n#Creating the first model\nknn_model = GridSearchCV(knn, knn_params, scoring='accuracy', cv=5, verbose=0)\nknn_model.fit(X_train, y_train)\ny_pred = knn_model.predict(X_test)\nknn_best = knn_model.score(X_test, y_test)\nprint(\"First Model Score: {}\".format(knn_best))\n\n#Initializing variables\nknn_result = 0\nknn_score = 0\nknn_cv = 0\nknn_df = 0\n\n#Training multiple models\nmodelTraining(knn, knn_model, knn_params, knn_best, knn_result, knn_score, knn_cv, knn_df)","a2fbca52":"allModels = {0: \"Logistic Regression\",1: \"Support Vector Machine\",\n               2: \"Decision Tree\",3: \"Random Forest\",4: \"Nearest Neighbor\", 5: \"XGBoost\"}\n\n#Printing all scores for the models\nprint(\"Model Scores:\")\nfor i, s in zip(range(0, 5), s_best):\n    print(allModels[i] + \": {}\".format(s_best), end=\"\\n\\n\")\n\n#Creating the submission file\nX_test = test2\n\nsid = test['id']\n\n#Storing the models\nfor i, mod in zip(range(0, 6), m_best):\n    #Test Predictions\n    y_pred = mod.predict(X_test)\n\n    #Saving all models to a csv\n    submission = pd.DataFrame({\"id\": sid, \"esrb_rating\": y_pred})\n    #Re-mapping the ESRB ratings\n    submission[\"esrb_rating\"] = submission[\"esrb_rating\"].map({0: 'E', 1: 'ET', 2: 'T', 3: 'M'})\n    submission.to_csv(allModels[i] + \" Submission.csv\", index=False)\n\n#Selecting the best model\ns = max(s_best)\nx = s_best.index(s)\nbest = m_best[x]\nprint(\"The best model is: \" + allModels[x])\nprint(\"With a score of:{}\".format(s_best[x]))\n\n#Getiting the best prediction\ny_best = best.predict(X_test)\n\n#Preparing and saving my submission file\nsubmission = pd.DataFrame({\"id\": sid, \"esrb_rating\": y_best})\n#Re-mapping the ESRB ratings\nsubmission[\"esrb_rating\"] = submission[\"esrb_rating\"].map({0: 'E', 1: 'ET', 2: 'T', 3: 'M'})\nsubmission.to_csv(\"submission.csv\", index=False)\n","2a6d44c5":"The 'T' rating is the most prevalent while the other ratings occur with similar frequency.","96364877":"# Data Transformation","3030ed68":"**<font size=8>Estimateing ESRB Ratings<\/font>**","9ef04045":"<font size= 6>**Support Vector Machine (SVM)**<\/font>","9ff847ca":"<font size= 6>**K-Nearest Neighbor**<\/font>","2d7312e9":"<font size= 6>**Logistic Regression**<\/font>","b51bc11f":"The console\/PS4 category is so much larger than the others that it may be considered an outlier.","7f50972d":"# Generating the Submission","1054260b":"# Data Observations","9416615e":"Again, there are no null values.","b8971f20":"Thankfully there are no null values.<br>","371e4f44":"After examining the data I decided to drop the 'title' and 'id' columns as they hold not valuable information.<br>\nI also decided to drop columns that had so few occurences (animated_blood, mature_humor, nudity, partial_nudity).<br>\nI decided on dropping the \"console\" column because it had too many occurences. \nI encoded the ESRB ratings into integers and used a scaler on the dataset to increase the accuracy.","cc3d3ba2":"Here we can see the correlation between certain categories and esrb ratings.<br>\nI was going to drop the 'no_descriptor' categories but decided against it after seeing the strong cprrelation with the 'E' rating.<br>\nThere doesn't seem to be any real correlection between PS4 exclusives and PS4&Xbox game, so splitting the console column is pointless.","111a5958":"<font size= 6>**Random Forest**<\/font>","3942e876":"<font size= 6>**Decision Tree**<\/font>","481818b1":"Some categories have so few occurences that they can be considered outliers.","9792b8ce":"<font size=6>CAP4611 Assignment 2 by Chelsea Oshodi<\/font>","432320d2":"# Building The Models","31195a03":"# Data Analysis"}}