{"cell_type":{"e1f1b0ec":"code","70ed9e27":"code","ee804468":"code","ebb28371":"code","9301b421":"code","d414936f":"code","c5aa2a4a":"code","ffcb87d1":"code","d8c6e30a":"code","ceb1d1ba":"code","b99a2cae":"code","1ecd8b24":"code","c246beb7":"code","dd2e1110":"code","224adefd":"code","72a83800":"code","fcdd590b":"code","0d66d5e8":"code","46e296cf":"code","38511008":"code","3dba0eb0":"code","83836f26":"code","4d8107f1":"code","903ef481":"code","45b59c5d":"code","94ffb7ce":"code","af8a7331":"code","be733334":"code","9d3acb85":"code","7543172d":"code","9e53fc62":"code","6c0004d2":"code","fe54bb49":"code","d4fbc479":"code","fab727a8":"code","79a45b78":"code","0d231733":"code","bda9e294":"code","a454bf04":"code","617f8089":"code","d1c29f03":"code","4e4ea5cc":"code","65b3bdb0":"code","442cb0a4":"code","4c0afe38":"code","62ff07f0":"code","c7830fb4":"code","560197c5":"code","a8214fde":"code","7d307230":"code","72c0f8b3":"code","889af019":"code","e61a2035":"code","bacb05d0":"code","ce3a5c03":"code","b11700e5":"code","b8228b94":"code","63b332d5":"code","2dd98cc0":"code","9307f5c4":"code","559ce3b4":"code","2254de96":"code","168303ca":"code","a52d5a09":"markdown","0907a793":"markdown","c2676e0a":"markdown","dcf5ab3a":"markdown","cc2ab090":"markdown","b0332ca0":"markdown","8d9a2d97":"markdown","ab66bf16":"markdown","e91fd391":"markdown","a8e7ec3e":"markdown","9538f8b3":"markdown","40ba9256":"markdown","3982c157":"markdown","369fb6bc":"markdown"},"source":{"e1f1b0ec":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.impute import KNNImputer\nfrom sklearn import preprocessing\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.svm import SVC\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import classification_report,f1_score,recall_score ,precision_score,roc_curve,confusion_matrix","70ed9e27":"df_train=pd.read_csv('..\/input\/predicting-pulsar-starintermediate\/pulsar_data_train.csv', sep=\",\", encoding='utf-8')\ndf_train.head()","ee804468":"df_test=pd.read_csv('..\/input\/predicting-pulsar-starintermediate\/pulsar_data_test.csv', sep=\",\", encoding='utf-8')\ndf_test.head()","ebb28371":"df_train.shape # data have 12528 raws and 9 columns(features)","9301b421":"df_test.shape","d414936f":"df_train.info() # all features are numerical","c5aa2a4a":"df_test.info()","ffcb87d1":"df_train.duplicated().sum()\n#ther is no duplicated","d8c6e30a":"df_test.duplicated().sum()","ceb1d1ba":"df_train.describe()","b99a2cae":"df_test.describe()","1ecd8b24":"df_train.isnull().sum() #nulls","c246beb7":"df_test.isnull().sum() ## Dropping the target_class","dd2e1110":"sns.heatmap(df_train.isnull())","224adefd":"sns.heatmap(df_test.isnull())","72a83800":"# copying the data to use \ndf1=df_train.copy()","fcdd590b":"df_train.isnull().sum() #nulls","0d66d5e8":"df_test.isnull().sum()","46e296cf":"imputer = KNNImputer(n_neighbors=2)\ndf_train = pd.DataFrame(imputer.fit_transform(df_train))","38511008":"imputer = KNNImputer(n_neighbors=2)\ndf_test = pd.DataFrame(imputer.fit_transform(df_test))","3dba0eb0":"df_train.isnull().sum()","83836f26":"df_test.isnull().sum()\n# we see that KNN deleted the target columns so we will add it again after prediction","4d8107f1":"df_train.describe()\n#we notice there is hardly change in the values before treating with missing values","903ef481":"df1.columns # used to know the name of columns","45b59c5d":"# rename the data_train\ndf_train.rename(columns = {0:'Mean of the integrated profile',\n                           1:'Sd of the integrated profile',\n                           2:'Excess kurtosis of the integrated profile',\n                           3:'Skewness of the integrated profile',\n                           4:'Mean of the DM-SNR C',\n                           5:'Sd of the DM-SNR C',\n                           6:'Excess kurtosis of the DM-SNR C',\n                           7:'Skewness of the DM-SNR C',\n                           8:'Target'}, inplace = True)\ndf_train.head()","94ffb7ce":"# rename the data_test\ndf_test.rename(columns = {0:'Mean of the integrated profile',\n                          1:'Sd of the integrated profile',\n                          2:'Excess kurtosis of the integrated profile',\n                          3:'Skewness of the integrated profile',\n                          4:'Mean of the DM-SNR C',\n                          5:'Sd of the DM-SNR C',\n                          6:'Excess kurtosis of the DM-SNR C',\n                          7:'Skewness of the DM-SNR C'\n                          }, inplace = True)\ndf_test.head()","af8a7331":"df_test.describe()\n#we notice there is hardly change in the values before treating with missing values","be733334":"sns.heatmap(df_train.isnull())","9d3acb85":"sns.heatmap(df_test.isnull())","7543172d":"df_train.plot(kind = \"box\" , subplots = True , figsize = (26,22) ,  layout = (3,3))\nplt.show()","9e53fc62":"df_test.plot(kind = \"box\" , subplots = True , figsize = (26,22) ,  layout = (3,3))\nplt.show()","6c0004d2":"df_train.columns","fe54bb49":"def remove_the_outlier(col):\n    sorted(col)\n    Q1,Q3=np.percentile(col,[25,75])\n    IQR=Q3-Q1\n    lower= Q1-(1.5 * IQR)\n    upper= Q3+(1.5 * IQR)\n    return lower, upper\n# here i don't need to apply this function on the target\nfor column in df_train.iloc[:,:8].columns: \n    if df_train[column].dtype != 'object':\n        lower,upper=remove_the_outlier(df_train[column])\n        df_train[column]=np.where(df_train[column]>upper,upper,df_train[column])\n        df_train[column]=np.where(df_train[column]<lower,lower,df_train[column])","d4fbc479":"df_train.plot(kind = \"box\" , subplots = True , figsize = (28,22) ,  layout = (3,3))\nplt.show()","fab727a8":"df_train.shape","79a45b78":"def remove_the_outlier_test(col):\n    Q1,Q3=np.percentile(col,[25,75])\n    IQR=Q3-Q1\n    lower= Q1-(1.5 * IQR)\n    upper= Q3+(1.5 * IQR)\n    return lower, upper\n# here i don't need to apply this function on the target\nfor column in df_test.iloc[:,:8].columns: \n    if df_test[column].dtype != 'object':\n        lower,upper=remove_the_outlier(df_test[column])\n        df_test[column]=np.where(df_test[column]>upper,upper,df_test[column])\n        df_test[column]=np.where(df_test[column]<lower,lower,df_test[column])","0d231733":"df_test.plot(kind = \"box\" , subplots = True , figsize = (28,22) ,  layout = (3,3))\nplt.show()","bda9e294":"df_test.shape","a454bf04":"fg,ax=plt.subplots(figsize=(12,8))\nax=sns.heatmap(df_train.corr(),annot=True)","617f8089":"scaler = preprocessing.StandardScaler()","d1c29f03":"X =pd.DataFrame(scaler.fit_transform(df_train.drop([\"Target\"],axis = 1)))","4e4ea5cc":"y= df_train['Target'].values","65b3bdb0":"fg,ax=plt.subplots(figsize=(14,10))\nexplode=[0.0,0.5]\nax=(df_train['Target'].value_counts(normalize=True)*100).plot.pie(autopct='%1.1f%%', explode=explode)","442cb0a4":"sm = SMOTE(random_state=42)\nX,y=sm.fit_resample(X, y)","4c0afe38":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)","62ff07f0":"parameters = {'C':[0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01, 0.001],\n              'kernel': ['rbf']}\ngridCV = GridSearchCV(SVC(), parameters, n_jobs=-1)             \ngridCV.fit(X_train, y_train)\nbest_C = gridCV.best_params_['C']\nbest_gamma = gridCV.best_params_['gamma']\nprint(best_C)\nprint(best_gamma)","c7830fb4":"SVM_best = SVC(kernel='rbf', C=100,gamma=1)\nSVM_best.fit(X_train, y_train);\ny_pred = SVM_best.predict(X_test)","560197c5":"print(\"F1-score\",f1_score(y_test,y_pred))\nprint(\"Recall: \",recall_score(y_test,y_pred))\nprint(\"percision: \",precision_score(y_test,y_pred))\nprint(\"accuracy:\", metrics.accuracy_score(y_test,y_pred))\nprint(classification_report(y_test, y_pred))","a8214fde":"FPR, TPR, cutoffs = metrics.roc_curve(y_test,y_pred,pos_label=1)\nplt.plot(FPR,TPR,c='red',linewidth=1.0)\nplt.xlabel('False Positive')\nplt.ylabel('True Positive')\nplt.title('ROC Curve')\nplt.show()","7d307230":"conf_matrix=confusion_matrix(y_test,y_pred)\nprint(conf_matrix)\nplot_confusion_matrix(conf_matrix,class_names=[\"not pulsar(0 or negative)\",\"pulsar(1 or positive)\"],figsize=(12,5))","72c0f8b3":"parameters = {'C':[0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01, 0.001],\n              'kernel': ['linear']}\ngridCV = GridSearchCV(SVC(), parameters, n_jobs=-1)             \ngridCV.fit(X_train, y_train)\nbest_C = gridCV.best_params_['C']\nbest_gamma = gridCV.best_params_['gamma']\nprint(best_C)\nprint(best_gamma)","889af019":"SVM_best2 = SVC(kernel='linear', C=best_C,gamma=best_gamma)\nSVM_best2.fit(X_train, y_train)\ny_pred2 = SVM_best2.predict(X_test)","e61a2035":"print(\"F1-score\",f1_score(y_test,y_pred2))\nprint(\"Recall: \",recall_score(y_test,y_pred2))\nprint(\"percision: \",precision_score(y_test,y_pred2))\nprint(\"accuracy:\", metrics.accuracy_score(y_test,y_pred2))\nprint(classification_report(y_test, y_pred2))","bacb05d0":"FPR, TPR, cutoffs = metrics.roc_curve(y_test,y_pred2,pos_label=1)\nplt.plot(FPR,TPR,c='red',linewidth=1.0)\nplt.xlabel('False Positive')\nplt.ylabel('True Positive')\nplt.title('ROC Curve')\nplt.show()","ce3a5c03":"conf_matrix=confusion_matrix(y_test,y_pred2)\nprint(conf_matrix)\nplot_confusion_matrix(conf_matrix,class_names=[\"not pulsar(0 or negative)\",\"pulsar(1 or positive)\"],figsize=(12,5))","b11700e5":"X =pd.DataFrame(scaler.fit_transform(df_test))\n## here there is no y because we need to get it by prediction by SVM by X data test","b8228b94":"Target_test = SVM_best.predict(X) # by rbf SVM\nprint(Target_test)","63b332d5":"Target_test2=SVM_best2.predict(X) # by linear SVM\nprint(Target_test2)","2dd98cc0":"df_test[\"Target_test\"]=Target_test","9307f5c4":"df_test['Target_test'].unique()","559ce3b4":"sns.displot(df_test['Target_test'])","2254de96":"df_test.describe()","168303ca":"df_test.head()","a52d5a09":"##### from this heat map there are four features which are highly related with the target \n1-Excess kurtosis of the integrated profile \n\n2-Skewness of the integrated profile\n\n3-Mean of the DM-SNR C\n\n4-Sd of the DM-SNR C ","0907a793":"### Scaling","c2676e0a":"### Preprocesssing","dcf5ab3a":"### Dealing with missing values using  KNNImputer","cc2ab090":"### Outliers","b0332ca0":"### Linear SVM","8d9a2d97":"### now, predicting the target_test in test data\n#### i will make scaling as train data","ab66bf16":"### please notice, i make one code for Train data and the same code for Test data","e91fd391":"### Droping the outliers","a8e7ec3e":"#### After predicting Target test we can add new column(Target_test) and i will use rbf SVM results because the haighly acc","9538f8b3":"### Dublicated ","40ba9256":"## Modeling\n## Rbf SVM","3982c157":"## EDA","369fb6bc":"#### the data is imbalanced so i will use smote method to treat it"}}