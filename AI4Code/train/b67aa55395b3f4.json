{"cell_type":{"d12ab4a5":"code","a019f578":"code","37157c94":"code","9491a47c":"markdown","d195d9ce":"markdown"},"source":{"d12ab4a5":"#Select station\n\nstation = \"Cortegada\" # stations [\"Cortegada\", \"Coron\"]\n\n\n# Select output format\n \nquantile =  5 # select quintiles, deciles ... (integer input)\n\nbeaufort = True # True Beaufort False quintiles\n\nknots = True # True knots False m\/s\n\nH_resolution = False # True 1.3 Km False 4 Km\n\n\n#Select date and time\n \ndate_input = \"2020-08-13\" # date forecast format \"yyyy-mm-dd\"\n \nhour = 15 # UTC from 0 to 23 \n\n\n\n","a019f578":"import warnings\nwarnings.filterwarnings(\"ignore\")\n!pip install simplekml\nimport simplekml\nimport pickle\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix ,classification_report \nfrom sklearn.model_selection import cross_val_score,cross_validate\nimport seaborn as sns\nfrom sklearn import preprocessing\n\n \n\n\n \n \ndelete_ten_minutes = False \nX_var = ['mod_NE', 'mod_SE','mod_SW', 'mod_NW',\"wind_gust_NE\",\"wind_gust_SE\" ,\"wind_gust_SW\",\"wind_gust_NW\"]\n \nif station==\"Coron\":\n  join=pd.read_csv(\"..\/input\/wind-coron\/coronD1res4K.csv\")\nelse:\n  join=pd.read_csv(\"..\/input\/wind-coron\/cortegadaD1res4K.csv\")\n \ntable_columns=[]\ntable=[]\ntable_index=[]\n \nfor var_pred0 in X_var:\n  var_obs=\"spd_o\"\n  if beaufort:\n \n    #first cut observed variable in Beaufort intervals\n    bins_b = pd.IntervalIndex.from_tuples([(-1, 0.5), (.5, 1.5), (1.5, 3.3),(3.3,5.5),\n                                     (5.5,8),(8,10.7),(10.7,13.8),(13.8,17.1),\n                                     (17.1,20.7),(20.7,24.4),(24.4,28.4),(28.4,32.6),(32.6,60)])\n    join[var_obs+\"_l\"]=pd.cut(join[var_obs], bins=bins_b).astype(str)\n    join[var_pred0+\"_l\"]=pd.cut(join[var_pred0],bins = bins_b).astype(str)\n \n    #transform to Beaufort scale\n    bins_b=bins_b.astype(str)\n    labels=[\"F0\",\"F1\",\"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\",\"F11\",\"F12\"]\n    join[var_obs+\"_l\"]=join[var_obs+\"_l\"].map({a:b for a,b in zip(bins_b,labels)})\n    join[var_pred0+\"_l\"]=join[var_pred0+\"_l\"].map({a:b for a,b in zip(bins_b,labels)})\n \n  else:\n    #first q cut observed variable then cut predicted with the bins obtained at qcut\n    join[var_obs+\"_l\"]=pd.qcut(join[var_obs], quantile, retbins = False,precision=1).astype(str)\n    interval=pd.qcut(join[var_obs], quantile,retbins = True,precision=1)[0].cat.categories\n    join[var_pred0+\"_l\"]=pd.cut(join[var_pred0],bins = interval).astype(str)\n        \n \n \n  #results tables\n  res_df=pd.DataFrame({\"pred_var\":join[var_pred0+\"_l\"],\"obs_var\":join[var_obs+\"_l\"]})\n  table.append(pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,))\n  table_columns.append(pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,normalize=\"columns\"))\n  table_index.append(pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,normalize=\"index\")  )\n \n \n \n \n \n \nfrom urllib.request import urlretrieve\nfrom datetime import datetime, timedelta, date\nfrom urllib.request import urlretrieve\nimport xarray as xr\n \n#X_var 8 variables\n \nif station==\"Coron\":\n  if beaufort:\n    filename_in = \"..\/input\/wind-coron\/algorithm\/coron\/coronD1res4K_treeb.h5\"\n  else:\n    filename_in = \"..\/input\/wind-coron\/algorithm\/coron\/coronD1res4K_treeq.h5\"\nelse:\n  if beaufort:\n    filename_in = \"..\/input\/wind-coron\/algorithm\/cortegada\/cortegadaD1res4K_treeb.h5\"\n  else:\n    filename_in = \"..\/input\/wind-coron\/algorithm\/cortegada\/cortegadaD1res4K_treeq.h5\"\n \n \n \ndate_input=datetime.strptime(date_input,  '%Y-%m-%d')\nnp.set_printoptions(formatter={'float_kind':\"{'.0%'}\".format})\n \n#getting model variables\n \n#creating the string_url\n#analysis day= Yesterday. Time 00:00Z. \ndatetime_str = (date_input-timedelta(days = 1)).strftime('%Y%m%d')\n \n#day to forecast 1= D+1 , 2 =D+2 and so on \nforecast=1\ndataframes=[]\ndate_anal = datetime.strptime(datetime_str,'%Y%m%d')\ndate_fore=(date_anal+timedelta(days=forecast)).strftime('%Y-%m-%d')\n \n# points NE,SE,SW,Nw\nif station==\"Coron\":\n  coordenates=[\"latitude=42.6088&longitude=-8.7588&\",\"latitude=42.5729&longitude=-8.7619&\"\n,\"latitude=42.5752&longitude=-8.8107&\",\"latitude=42.6110&longitude=-8.8076&\"]\nelse:\n  coordenates=[\"latitude=42.6446&longitude=-8.7557&\",\"latitude=42.6088&longitude=-8.7588&\"\n,\"latitude=42.6110&longitude=-8.8076&\",\"latitude=42.6469&longitude=-8.8045&\"]\n \n \n \n#variables string type to perform url. The same variables as model (AI)\n \ndataframes=[]\nfor coordenate in coordenates:\n  head=\"http:\/\/mandeo.meteogalicia.es\/thredds\/ncss\/wrf_2d_04km\/fmrc\/files\/\"\n  text1=\"\/wrf_arw_det_history_d03_\"+datetime_str+\"_0000.nc4?\"\n  met_var=\"var=dir&var=mod&var=wind_gust&\"\n  scope1=\"time_start=\"+date_fore+\"T00%3A00%3A00Z&\"\n  scope2=\"time_end=\"+date_fore+\"T23%3A00%3A00Z&accept=netcdf\"\n  #add all the string variables\n  url=head+datetime_str+text1+met_var+coordenate+scope1+scope2\n  #load the actual model from Meteogalicia database and transform as pandas dataframe\n  urlretrieve(url,\"model\")\n  dataframes.append(xr.open_dataset(\"model\").to_dataframe().set_index(\"time\").loc[:, 'dir':])\nE = dataframes[0].join(dataframes[1], lsuffix='_NE', rsuffix='_SE')\nW = dataframes[2].join(dataframes[3], lsuffix='_SW', rsuffix='_NW')\nmodel=E.join(W)\nif beaufort:\n  #model forecast bins and Machine learning forecast\n  bins_b = pd.IntervalIndex.from_tuples([(-1, 0.5), (.5, 1.5), (1.5, 3.3),(3.3,5.5),\n                                     (5.5,8),(8,10.7),(10.7,13.8),(13.8,17.1),\n                                     (17.1,20.7),(20.7,24.4),(24.4,28.4),(28.4,32.6),(32.6,60)])\n  labels=[\"F0\",\"F1\",\"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\",\"F11\",\"F12\"]\n  model[\"mod_NE_l\"]=pd.cut(model[\"mod_NE\"],bins = bins_b).map({a:b for a,b in zip(bins_b,labels)})\n  model[\"mod_SE_l\"]=pd.cut(model[\"mod_SE\"],bins = bins_b).map({a:b for a,b in zip(bins_b,labels)})\n  model[\"mod_SW_l\"]=pd.cut(model[\"mod_SW\"],bins = bins_b).map({a:b for a,b in zip(bins_b,labels)})\n  model[\"mod_NW_l\"]=pd.cut(model[\"mod_NW\"],bins = bins_b).map({a:b for a,b in zip(bins_b,labels)})\nelse:\n  interval=pd.qcut(join[var_obs], quantile,retbins = True,precision=1)[0].cat.categories\n  model[\"mod_NE_l\"]=pd.cut(model[\"mod_NE\"],bins = interval).astype(str)\n  model[\"mod_SE_l\"]=pd.cut(model[\"mod_SE\"],bins = interval).astype(str)\n  model[\"mod_SW_l\"]=pd.cut(model[\"mod_SW\"],bins = interval).astype(str)\n  model[\"mod_NW_l\"]=pd.cut(model[\"mod_NW\"],bins = interval).astype(str)\n \n#load \n \nclf1 = pickle.load(open(filename_in, 'rb'))\n#get Y\n \nif beaufort:\n  Y=join[var_obs+\"_l\"]\nelse:\n  Y=pd.qcut(join[var_obs], quantile, retbins = False,precision=1).astype(str)\n  labels=pd.qcut(join[var_obs], quantile,retbins = True,precision=1)[0].cat.categories.astype(str)\n \n \n \n \n#independent variables. \nX=join[X_var]\n \n \n#we  scale and split\n \n \nx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2,random_state=42)\n \ny_pred=clf1.predict(x_test)\n \n \n \n \n \n \n#plot results\nres_df=pd.DataFrame({\"pred_var\":y_pred,\"obs_var\":y_test})\ntable=pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,)\ntable_columnsml=pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,normalize=\"columns\")\ntable_index=pd.crosstab(res_df.obs_var,res_df.pred_var, margins=True,normalize=\"index\")\n \n \n \n#from array to labels\nlb = preprocessing.LabelBinarizer()\nif beaufort:\n  labels=[\"F0\",\"F1\",\"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\",\"F11\",\"F12\"]\nelse:\n  labels=interval.astype(str)\n \n \n \n \n#scale X_var. Same scale NN trained\n \n \nmodel[var_obs+\"_ML\"]=clf1.predict(model[X_var])\n \n \n \n \n#station results\ntry:\n  station_r=True\n  variables_station=[\"spd_o_corte\",\"std_spd_o_corte\",\"gust_spd_o_corte\"]\n  param=[\"param=81\",\"param=10009\",\"param=10003\"]\n \n  head=\"http:\/\/www2.meteogalicia.gal\/galego\/observacion\/plataformas\/historicosAtxt\/DatosHistoricosTaboas_dezminutalAFicheiro.asp?\"\n \n  \"\"\"Cortegada platform:15001, Ribeira buoy:15005 warnings: wind intensity negatives!!\"\"\"\n  station_n=\"est=15001&\"\n \n \n  dateday=\"&data1=\"+date_input.strftime(\"%d\/%m\/%Y\")+\"&data2=\"+(date_input+timedelta(days = 1)).strftime(\"%d\/%m\/%Y\")\n \n  \"\"\"param=83 (air temperature C) ,10018 (dew temperature C),86 (humidity%)\n  ,81(wind speed m\/s),10003 (wind gust m\/s),10009 (std wind speed m\/s)\n  ,82 (wind direction degrees),10010 (std wind direction degrees),\n  10015 (gust direcction degree),20003 (temperature sea surface C),20005 (salinity),\n  20004 (conductivity mS\/cm),20017 (density anomaly surface kg\/m^3),20019 (deep sea temperature degrees)\n  ,20018 (deep sea salinity),20022 (deep sea conductivity mS\/cm),20021 (density anomaly deep sea kg\/m^3),\n  20020 (Presure water column db),20804 (East current compound cm\/s) ,20803 (North current compound cm\/s)\"\"\"\n \n  df_station=pd.DataFrame()\n  for parameters, var in zip(param,variables_station):\n    url3=head+station_n+parameters+dateday\n \n    #decimal are comma ,!!\n    df=pd.read_fwf(url3,skiprows=24,sep=\" \",encoding='latin-1',decimal=',').dropna()\n    df_station[\"datetime\"]=df[\"DATA\"]+\" \"+df['Unnamed: 2']\n    df_station['datetime'] = pd.to_datetime(df_station['datetime'])\n    df_station[var]=df['Valor'].astype(float)\n  df_station=df_station.set_index(\"datetime\") \n \n  if beaufort:\n    df_station[\"spd_o_corte_l\"]=pd.cut(df_station[\"spd_o_corte\"],bins = bins_b).map({a:b for a,b in zip(bins_b,labels)})\n  else:\n    df_station[\"spd_o_corte_l\"]=pd.cut(df_station[\"spd_o_corte\"],bins=interval).astype(str)  \n  df_station[\"observed_resample_hourly\"]=df_station.spd_o_corte.resample(\"H\").mean()\nexcept:\n  station_r=False\n  df_station=pd.DataFrame(index=model.index,columns=['spd_o_corte', \n                                                     'std_spd_o_corte', \n                                                     'gust_spd_o_corte',\n                                                     'spd_o_corte_l',\n                                                     \"observed_resample_hourly\"])\n \n \n \n#merge station with meteorological model and plot\n \nfinal=pd.merge(model, df_station, left_index=True, right_index=True, how='outer')\nif station_r:\n  g1=(final[['mod_NE',\"mod_SE\",\"mod_SW\",\"mod_NW\",\"spd_o_corte\"]]*1.9438).dropna().plot(title=\"wind velocity KT\",figsize=(9,5)).grid(True,which='both')\n  \n \n#reample observed data hourly and show all data about spd\npd.options.display.max_rows = 999\n \nif delete_ten_minutes:\n  final_s=final[[\"mod_NE\",\"mod_NE_l\",\"mod_SE\",\"mod_SE_l\",\"mod_SW\",\"mod_SW_l\",\n                 \"mod_NW\",\"mod_NW_l\",\"spd_o_ML\",\"spd_o_corte\",\n                 \"spd_o_corte_l\",\"gust_spd_o_corte\",\"observed_resample_hourly\"]].dropna()\nelse:\n  final_s=final[[\"mod_NE\",\"mod_NE_l\",\"mod_SE\",\"mod_SE_l\",\"mod_SW\",\"mod_SW_l\",\n                 \"mod_NW\",\"mod_NW_l\",\"spd_o_ML\",\"spd_o_corte\",\"spd_o_corte_l\",\n                 \"gust_spd_o_corte\",\"observed_resample_hourly\"]]\n \n \n \n\"\"\"***********************************\"\"\"\n \n \nq_df=final[[\"mod_NE_l\",\"mod_SE_l\",\"mod_SW_l\",\"mod_NW_l\",var_obs+\"_ML\"]].dropna()\npd.set_option('max_colwidth', 2000)\nquantum_metmod_NE=[]\nquantum_metmod_SE=[]\nquantum_metmod_SW=[]\nquantum_metmod_NW=[]\nquantum_ML=[]\ntable=[]\nfor i in range (0,4):\n  table.append(table_columns[i].rename(mapper=str,axis=1))\nfor i in range(0, len(q_df.index)):\n  quantum_metmod_NE.append(table[0][q_df[\"mod_NE_l\"][i]].map(\"{:.0%}\".format))\n  quantum_metmod_SE.append(table[1][q_df[\"mod_SE_l\"][i]].map(\"{:.0%}\".format))\n  quantum_metmod_SW.append(table[2][q_df[\"mod_SW_l\"][i]].map(\"{:.0%}\".format))\n  quantum_metmod_NW.append(table[3][q_df[\"mod_NW_l\"][i]].map(\"{:.0%}\".format))\n \n  quantum_ML.append(table_columnsml[q_df[var_obs+\"_ML\"][i]].map(\"{:.0%}\".format))\n  \nquantum_fi=pd.DataFrame({\"NE\":quantum_metmod_NE,\"SE\":quantum_metmod_SE,\n                         \"SW\":quantum_metmod_SW,\"NW\":quantum_metmod_NW,\n                         \"ML\":quantum_ML}, index=q_df.index)\n \n \n \n \n \nvariable_met = \"mod\"\n \n \ntoday=date_input\nyesterday=today+timedelta(days=-1)\ntoday=today.strftime(\"%Y-%m-%d\")\nyesterday=yesterday.strftime(\"%Y%m%d\")\n \n \nurl1=\"http:\/\/mandeo.meteogalicia.es\/thredds\/ncss\/wrf_2d_04km\/fmrc\/files\/\"+yesterday+\"\/wrf_arw_det_history_d03_\"+yesterday+\"_0000.nc4?var=lat&var=lon&var=\"+variable_met+\"&north=42.68&west=-9.00&east=-8.75&south=42.450&disableProjSubset=on&horizStride=1&time_start=\"+today+\"T\"+str(hour)+\"%3A00%3A00Z&time_end=\"+today+\"T\"+str(hour)+\"%3A00%3A00Z&timeStride=1&accept=netcdf\"\nurl2=\"http:\/\/mandeo.meteogalicia.es\/thredds\/ncss\/wrf_1km_baixas\/fmrc\/files\/\"+yesterday+\"\/wrf_arw_det1km_history_d05_\"+yesterday+\"_0000.nc4?var=lat&var=lon&var=\"+variable_met+\"&north=42.68&west=-9.00&east=-8.75&south=42.450&disableLLSubset=on&disableProjSubset=on&horizStride=1&time_start=\"+today+\"T\"+str(hour)+\"%3A00%3A00Z&time_end=\"+today+\"T\"+str(hour)+\"%3A00%3A00Z&timeStride=1&accept=netcdf\"\nif H_resolution:\n  url=url2\n  r=\"HI_\"\nelse:\n  url=url1\n  r=\"LO_\"\n \n \nurlretrieve(url,\"model\")\ndf=xr.open_dataset(\"model\").to_dataframe()\ndf_n=pd.DataFrame(df[[\"lat\",\"lon\",variable_met]].values,columns=df[[\"lat\",\"lon\",variable_met]].columns)\n \nif knots:\n  df_n[variable_met]=round(df_n[variable_met]*1.94384,2).astype(int)\n  \n \ndf_n[variable_met]=df_n[variable_met].astype(str)\nkml = simplekml.Kml()\ndf_n.apply(lambda X: kml.newpoint(name=X[variable_met], coords=[( X[\"lon\"],X[\"lat\"])]) ,axis=1)\n \n#add description tag\nif beaufort:\n  tag= \"Beaufort Scale\\n\"\nelse:\n  tag=\"quintile\\n\"  \n#add Cortegada velocity and ML prediction\ndescription=tag+quantum_fi.columns[4]+\" \"+str(quantum_fi.iloc[hour,4])[:-15]\nstring=final.index.strftime(\"%Y-%m-%d\")[0]+\" \"+str(hour)+\":00:00\"\n \nif station==\"Cortegada\":\n  kml.newpoint(name=str(final['spd_o_corte_l'].loc[string]), description=description,coords=[(-8.7836,42.6255)]) \nelse:\n  kml.newpoint(name=\"Coron\", description=description,coords=[(-8.8046,42.5801)]) \n \n#Add model stadistical results four corners\nif station==\"Cortegada\":\n  descriptionNE=tag+quantum_fi.columns[0]+\" \"+str(quantum_fi.iloc[hour,0])[:-15]\n  kml.newpoint(name=str(final['mod_NE_l'].loc[string]),description=descriptionNE,coords=[(-8.7557,42.6446)])\n  descriptionSE=tag+quantum_fi.columns[1]+\" \"+str(quantum_fi.iloc[hour,1])[:-15]\n  kml.newpoint(name=str(final['mod_SE_l'].loc[string]),description=descriptionSE,coords=[(-8.7588,42.6090)])\n  descriptionSW=tag+quantum_fi.columns[2]+\" \"+str(quantum_fi.iloc[hour,2])[:-15]\n  kml.newpoint(name=str(final['mod_SW_l'].loc[string]),description=descriptionSW,coords=[(-8.8076,42.6115)])\n  descriptionNW=tag+quantum_fi.columns[3]+\" \"+str(quantum_fi.iloc[hour,3])[:-15]\n  kml.newpoint(name=str(final['mod_NW_l'].loc[string]),description=descriptionNW,coords=[(-8.8045,42.6469)])  \nelse:\n  descriptionNE=tag+quantum_fi.columns[0]+\" \"+str(quantum_fi.iloc[hour,0])[:-15]\n  kml.newpoint(name=str(final['mod_NE_l'].loc[string]),description=descriptionNE,coords=[(-8.7588,42.6080)])\n  descriptionSE=tag+quantum_fi.columns[1]+\" \"+str(quantum_fi.iloc[hour,1])[:-15]\n  kml.newpoint(name=str(final['mod_SE_l'].loc[string]),description=descriptionSE,coords=[(-8.7619,42.5729)])\n  descriptionSW=tag+quantum_fi.columns[2]+\" \"+str(quantum_fi.iloc[hour,2])[:-15]\n  kml.newpoint(name=str(final['mod_SW_l'].loc[string]),description=descriptionSW,coords=[(-8.8107,42.5752)])\n  descriptionNW=tag+quantum_fi.columns[3]+\" \"+str(quantum_fi.iloc[hour,3])[:-15]\n  kml.newpoint(name=str(final['mod_NW_l'].loc[string]),description=descriptionNW,coords=[(-8.8076,42.6108)])  \n \n#save results  \n  \n#save results\nif beaufort:\n  kml.save(\"beaufort_\"+today+\"H\"+str(hour)+r+variable_met+\"_ML\"+\".kml\")\nelse:\n  kml.save(\"quintile_\"+today+\"H\"+str(hour)+r+variable_met+\"_ML\"+\".kml\")\n \n \n \nfinal_s","37157c94":"quantum_fi","9491a47c":"**The notebook provides a way to obtain wind intensity at the station selected. There are two meteorological stations: Cortegada and Coron. The machine learning algorithm gets two kinds of output labels: quintiles or the Beaufort scale. We get a KML file and two-screen outputs.**\n1. KML file displays all the model points and the station selected. There are two possible models to show: WRF with resolutions 1.3 Km and 4 Km. All the calculations are made at the 4 Km resolution model.\nThe right picture shows the location of Cortegada station surrounded by the nearest meteorological points from the WRF model (from the Meteogalicia database). Points are labeled as NE, SE, SW, NW. If you click at these points, you will get the probability of every possible outcome at the meteorological station. We obtained this probability function comparing historical data at the station and the meteorological model at the point chosen. The file that contains all the information about has the format: stationnameD1res4K. D1 means the model forecast of the day+1 (from 24 to 48 hours). res4K is the model spatial resolution. It means that points separation is 4 Km.\nClicking at the station, we get all the possibles wind intensity outcomes from the machine learning algorithm. Files in format PowerPoint at the data set Wind Ria Arousa contains the performance results of machine learning algorithms and meteorological models\n2. The first table shows the following columns:\nwind intensity in m\/s at every cardinal point near the station from the meteorological model, wind intensity labeled (Beaufort or quintiles) from the meteorological model also, wind intensity forecasted by the machine learning algorithm, at Cortegada actual wind intensity station in m\/s, real wind gust in m\/s and the average wind intensity every hour.\nRows are the time. Meteorological models and machine learning algorithms report every hour. The actual data indicates every ten minutes. Finally\na plot with wind intensity at every point near the station and the real wind intensity at the station, all in knots.\n3. The second table, \"quantum_fi,\" shows from every point near the station and the machine learning algorithm all the possibles outputs of wind intensity and their probability.\n","d195d9ce":"![image.png](attachment:image.png)"}}