{"cell_type":{"bb45b02f":"code","340378b3":"code","811b9128":"code","4abb862c":"code","cced16fc":"code","ae8f3001":"code","5a89e165":"code","9af04343":"code","0bbf8c77":"code","5637c7d7":"code","f6fe2a27":"code","3d593b8c":"code","84147e96":"code","8166df53":"code","d0a73504":"code","7c390726":"code","202491ef":"code","28a79f57":"code","5a179014":"code","53b72262":"code","a52521a7":"code","5dc9d317":"code","31c0dd62":"code","ad8dd464":"code","d4cba3d2":"code","ea6d5a56":"code","ac87704a":"code","0ba12596":"code","81bb4345":"code","c78e9e46":"code","af87af26":"code","39740ef9":"markdown","2b1b95c5":"markdown","37459444":"markdown"},"source":{"bb45b02f":"from mlxtend.plotting import plot_decision_regions\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","340378b3":"dp_data = pd.read_csv('..\/input\/dataset-dental-panoramic\/dataset_dental_panoramic_new.csv')\n\ndp_data.head()","811b9128":"dp_data.info(verbose=True)","4abb862c":"dp_data.describe()\n\n","cced16fc":"dp_data.describe().T","ae8f3001":"dp_data_copy = dp_data.copy(deep = True)\ndp_data_copy[['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135']] = dp_data_copy[['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(dp_data_copy.isnull().sum())","5a89e165":"p = dp_data.hist(figsize = (20,20))","9af04343":"dp_data_copy['dissimilarity_0'].fillna(dp_data_copy['dissimilarity_0'].mean(), inplace = True)\ndp_data_copy['dissimilarity_45'].fillna(dp_data_copy['dissimilarity_45'].mean(), inplace = True)\ndp_data_copy['dissimilarity_90'].fillna(dp_data_copy['dissimilarity_90'].median(), inplace = True)\ndp_data_copy['dissimilarity_135'].fillna(dp_data_copy['dissimilarity_135'].median(), inplace = True)\ndp_data_copy['correlation_0'].fillna(dp_data_copy['correlation_0'].mean(), inplace = True)\ndp_data_copy['correlation_45'].fillna(dp_data_copy['correlation_45'].mean(), inplace = True)\ndp_data_copy['correlation_90'].fillna(dp_data_copy['correlation_90'].median(), inplace = True)\ndp_data_copy['correlation_135'].fillna(dp_data_copy['correlation_135'].median(), inplace = True)\ndp_data_copy['homogeneity_0'].fillna(dp_data_copy['homogeneity_0'].mean(), inplace = True)\ndp_data_copy['homogeneity_45'].fillna(dp_data_copy['homogeneity_45'].mean(), inplace = True)\ndp_data_copy['homogeneity_90'].fillna(dp_data_copy['homogeneity_90'].median(), inplace = True)\ndp_data_copy['homogeneity_135'].fillna(dp_data_copy['homogeneity_135'].median(), inplace = True)\ndp_data_copy['contrast_0'].fillna(dp_data_copy['contrast_0'].mean(), inplace = True)\ndp_data_copy['contrast_45'].fillna(dp_data_copy['contrast_45'].mean(), inplace = True)\ndp_data_copy['contrast_90'].fillna(dp_data_copy['contrast_90'].median(), inplace = True)\ndp_data_copy['contrast_135'].fillna(dp_data_copy['contrast_135'].median(), inplace = True)\ndp_data_copy['energy_0'].fillna(dp_data_copy['energy_0'].mean(), inplace = True)\ndp_data_copy['energy_45'].fillna(dp_data_copy['energy_45'].mean(), inplace = True)\ndp_data_copy['energy_90'].fillna(dp_data_copy['energy_90'].median(), inplace = True)\ndp_data_copy['energy_135'].fillna(dp_data_copy['energy_135'].median(), inplace = True)\n","0bbf8c77":"p = dp_data_copy.hist(figsize = (20,20))","5637c7d7":"dp_data.shape","f6fe2a27":"sns.countplot(y=dp_data.dtypes ,data=dp_data)\nplt.xlabel(\"count of each data type\")\nplt.ylabel(\"data types\")\nplt.show()","3d593b8c":"import missingno as msno\np=msno.bar(dp_data)\n","84147e96":"color_wheel = {1: \"#0392cf\", \n               2: \"#7bc043\"}\ncolors = dp_data[\"outcome\"].map(lambda x: color_wheel.get(x + 1))\nprint(dp_data.outcome.value_counts())\np=dp_data.outcome.value_counts().plot(kind=\"bar\")\n","8166df53":"from pandas.tools.plotting import scatter_matrix\np=scatter_matrix(dp_data,figsize=(25, 25))","d0a73504":"p=sns.pairplot(dp_data_copy, hue = 'outcome')","7c390726":"plt.figure(figsize=(12,10))\np=sns.heatmap(dp_data.corr(), annot=True,cmap ='RdYlGn')","202491ef":"plt.figure(figsize=(12,10))\np=sns.heatmap(dp_data_copy.corr(), annot=True,cmap ='RdYlGn') ","28a79f57":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(dp_data_copy.drop([\"outcome\", \"label\"],axis = 1),),\n        columns=['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135'])","5a179014":"X.head()","53b72262":"y = dp_data_copy.outcome","a52521a7":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1\/3,random_state=42, stratify=y)","5dc9d317":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,6):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","31c0dd62":"max_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","ad8dd464":"max_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","d4cba3d2":"plt.figure(figsize=(12,5))\np = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\np = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')","ea6d5a56":"knn = KNeighborsClassifier(11)\nkfold=KFold(n_splits=5, shuffle=True, random_state=0)\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)\n\naccuracy = cross_val_score(knn,X,y, cv=kfold, scoring='accuracy')\nprecision = cross_val_score(knn,X,y, cv=kfold, scoring='precision_weighted')\nrecall = cross_val_score(knn,X,y, cv=kfold, scoring='recall_weighted')\nf1 = cross_val_score(knn,X,y, cv=kfold, scoring='f1_weighted')\nprint('accuray',  accuracy.mean())\nprint('precision' , precision.mean())\nprint('recall' ,recall.mean())\nprint('F1-Score' , f1.mean())","ac87704a":"from sklearn.metrics import confusion_matrix\n#let us get the predictions using the classifier we had fit above\ny_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","0ba12596":"y_pred = knn.predict(X_test)\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","81bb4345":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","c78e9e46":"\nfig1, ax1 = plt.subplots(figsize=(10,5))\n\nred_square = dict(markerfacecolor='r', marker='s')\n\n\nall_data = [accuracy,precision,recall,f1]\nax1.set_title('performance - boxplot')\n\nax1.boxplot(all_data,notch=False,flierprops=red_square)\n\n\n\n\nax1.yaxis.grid(True)\nax1.set_xticks([y +1 for y in range(len(all_data))])\nax1.set_xlabel('performa')\nax1.set_ylabel('score')\n\nplt.setp(ax1, xticks=[y+1 for y in range(len(all_data))],\n         xticklabels=[ 'accuracy','precision','recall','f1_score'])\nplt.show()\n","af87af26":"plt.figure(figsize=(10,7))\nxx = [\"cv1\", \"cv2\", \"cv3\", \"cv4\", \"cv5\"] #, \"cv6\", \"cv7\", \"cv8\", \"cv9\", \"cv10\"\nplt.plot(xx, accuracy, '--')\nplt.plot(xx, precision, '--')\nplt.plot(xx, recall, '--')\nplt.plot(xx, f1, '--')\nplt.title(\"comparison of each crossvalidation - KNN\")\nplt.xlabel(\"Crossvaldiation\")\nplt.ylabel(\"score\")\nplt.legend([\"accuracy\",\"precision\", \"recall\", \"f1-score\"])\nplt.grid()\nplt.show()","39740ef9":"#### To fill these Nan values the data distribution needs to be understood","2b1b95c5":"#### The best result is captured at k = 11 hence 11 is used for the final model","37459444":"## Result Visualisation"}}