{"cell_type":{"b175a7e0":"code","f1f27b74":"code","7b5054e1":"code","3f66a20a":"code","fd38d366":"code","ceb3e26b":"code","70532164":"code","5e556d10":"code","a6e2c988":"code","300a0858":"code","b4bf3b29":"code","373e5b73":"code","54d3b1be":"code","193cddb8":"code","269e323b":"code","7f8175e6":"code","f7627299":"markdown"},"source":{"b175a7e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1f27b74":"from sklearn.cluster import KMeans\ndf  = pd.read_csv('\/kaggle\/input\/world-happiness-report-2021\/world-happiness-report-2021.csv',index_col=0)\ncols = list(df.columns)[5:11]\ndf = df[cols]\ndf.tail()\n\n# df.drop(columns=['Regional indicator','Ladder score','Standard error of ladder score','upperwhisker'])","7b5054e1":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(df)\n","3f66a20a":"df_ = df[df.index == 'Uzbekistan']\ndf_","fd38d366":"from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nimport matplotlib.pyplot as plt\nmerging = linkage(X, method='ward')\nplt.figure(figsize=(20,20))\n# \u0421\u0442\u0440\u043e\u0438\u043c \u0434\u0435\u043d\u0434\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443\ndendrogram(merging, labels=df.index, leaf_font_size=10)\nplt.show()","ceb3e26b":"clusters = fcluster(merging, 15, criterion='distance')\nprint(clusters)","70532164":"# \u041a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u043c k-\u0441\u0440\u0435\u0434\u043d\u0438\u0445 \u043d\u0430 3 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\nlabels = kmeans.predict(X)\n\n# \u0412\u044b\u0432\u043e\u0434 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u0432 \u0432\u0438\u0434\u0435 \u0441\u043b\u043e\u0432\u0430\u0440\u044f\nprint(dict(zip(df.index, labels)))","5e556d10":"# \u041f\u043e\u0434\u0431\u0435\u0440\u0451\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u043e\u0432 (\"\u043f\u0440\u0430\u0432\u0438\u043b\u043e \u043b\u043e\u043a\u0442\u044f\")\n\n# crit = []\n# for k in range(2, 7):\n#     kmeans = KMeans(n_clusters=k, random_state=15)\n#     kmeans.fit(X)\n#     crit.append(kmeans.inertia_)\n    \n# plt.plot(range(2,7), crit)\n# plt.show()","a6e2c988":"df['cluster'] = kmeans.labels_\nprint(set(kmeans.labels_))\ndf.tail()","300a0858":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 2)\npca.fit(X)\nZ = pca.transform(X)","b4bf3b29":"print(Z)","373e5b73":"print(pca.explained_variance_)\nprint(pca.explained_variance_ratio_)#\u0437\u0434\u0435\u0441\u044c \u0432\u0438\u0434\u0438\u043c, \u043a\u0430\u043a\u043e\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u0430\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0435","54d3b1be":"plt.plot(Z[labels == 0,0], Z[labels == 0,1], 'bo', label='Clauster 1') \nplt.plot(Z[labels == 1,0], Z[labels == 1,1], 'go', label='Clauster 2') \nplt.plot(Z[labels == 2,0], Z[labels == 2,1], 'ro', label='Clauster 3') \nplt.plot(Z[labels == 3,0], Z[labels == 3,1], 'yo', label='Clauster 4') \nplt.legend(loc=4)","193cddb8":"loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n\nloading_matrix = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=df.columns[:-1])\nloading_matrix.sort_values(by=['PC1'],inplace=True)\nprint(loading_matrix)\nloading_matrix.sort_values(by=['PC2'],inplace=True)\nprint(loading_matrix)","269e323b":"#\u0421\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0433\u0440\u0430\u0444\u0438\u043a \u0432\u044b\u0448\u0435\n#\u0438\u0441\u0445\u043e\u0434\u0438\u043c \u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0448\u0435, \u043e\u0441\u044c X - \u0440\u0430\u0437\u0432\u0438\u0442\u043e\u0441\u0442\u044c \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u043a\u0438, \u043e\u0441\u044c Y - \u0449\u0435\u0434\u0440\u043e\u0441\u0442\u044c\/\u0434\u043e\u0431\u0440\u043e\u0442\u0430 \u043b\u044e\u0434\u0435\u0439\nprint(df.index[np.argmin(Z[:,1])])#\u0441\u0430\u043c\u044b\u0435 \u0437\u043b\u044b\u0435 \u043b\u044e\u0434\u0438\nprint(df.index[np.argmax(Z[:,0])]) #\u0441\u0430\u043c\u0430\u044f \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u0438 \u043d\u0435\u0440\u0430\u0437\u0432\u0438\u0442\u0430\u044f \u0441\u0442\u0440\u0430\u043d\u0430","7f8175e6":"print(df.index[np.argmin(Z[:,0])]) # \u0441\u0430\u043c\u0430\u044f \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u0438 \u0440\u0430\u0437\u0432\u0438\u0442\u0430\u044f \u0441\u0442\u0440\u0430\u043d\u0430 ","f7627299":"# \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0444\u0438\u0447\u0443, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u0442 \u0432 \u043a\u0430\u043a\u043e\u0439 \u043a\u043b\u0430\u0441\u0441 \u0432\u0445\u043e\u0434\u0438\u0442 \u0444\u0438\u0447\u0430"}}