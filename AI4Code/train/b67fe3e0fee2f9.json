{"cell_type":{"c752a7c4":"code","e79a4547":"code","4201623f":"code","8c68c459":"code","0e9410fe":"code","8c8acd8a":"code","8e621519":"code","f50e8d1a":"code","809d5beb":"code","fa8353cb":"code","b6aefb1e":"code","de64cd3d":"code","6acd2e22":"code","16781107":"code","1cdfee26":"code","00e8108c":"code","440bacec":"code","d46401a4":"code","455a1642":"code","d63b51b2":"code","66786831":"markdown","c9fc4382":"markdown","17c5821b":"markdown","dcb7d435":"markdown","a798d200":"markdown","502b35bb":"markdown","f2e344b0":"markdown","ce70f5f2":"markdown","260e2d12":"markdown","648ef408":"markdown"},"source":{"c752a7c4":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","e79a4547":"df = pd.read_csv('..\/input\/concrete-compressive-strength\/Concrete Compressive Strength.csv')","4201623f":"df.head()","8c68c459":"df.info()","0e9410fe":"df.describe()","8c8acd8a":"for column in df.columns:\n    plt.figure()\n    sns.distplot(df[column])","8e621519":"for column in df.columns:\n    plt.figure()\n    sns.boxplot(df[column])","f50e8d1a":"import plotly.graph_objects as go\ncorr = df.corr()\ngraph = go.Figure()\ngraph.add_trace(go.Heatmap(z=corr.values, x=corr.index.values, y=corr.columns.values))\ngraph.show()","809d5beb":"!pip install smogn","fa8353cb":"import smogn\nconcrete_smogn = smogn.smoter(\n    data = df,       \n    y = 'Concrete compressive strength(MPa, megapascals) '  \n)","b6aefb1e":"sns.kdeplot(df['Concrete compressive strength(MPa, megapascals) '], label = \"Original\")\nsns.kdeplot(concrete_smogn['Concrete compressive strength(MPa, megapascals) '], label = \"Modified\")","de64cd3d":"#splitting the data\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","6acd2e22":"from sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)\ndtr.score(X_test, y_test)","16781107":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test) ","1cdfee26":"dtr1 = DecisionTreeRegressor()\ndtr1.fit(X_train, y_train)\ndtr1.score(X_test, y_test)","00e8108c":"from sklearn.model_selection import GridSearchCV\n\ngrid_params = {\n    'criterion' : [ 'mae' ,'mse', 'friedman_mse','poisson'],\n    'splitter' : ['best', 'random'],\n    'max_depth' : [3, 5, 7, 9, 10,12,],\n    'min_samples_split' : [ 2, 3, 4, 5,7],\n    'min_samples_leaf' : [ 2, 3, 4, 5,7]\n}\n\ngrid_search = GridSearchCV(dtr1, grid_params, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search.fit(X_train, y_train)","440bacec":"print(grid_search.best_params_)\nprint(grid_search.best_score_)","d46401a4":"!pip install lazypredict","455a1642":"from lazypredict.Supervised import LazyRegressor\nreg = LazyRegressor(ignore_warnings=False, custom_metric=None)\nmodels, predictions = reg.fit(X_train, X_test, y_train, y_test)\nmodels","d63b51b2":"from xgboost import XGBRegressor\nxgbr = XGBRegressor(verbosity=0) \nxgbr.fit(X_train,y_train)\n#bellow is the Adjusted R-Squared for the model\n1 - (1-xgbr.score(X_test, y_test))*(len(y_test)-1)\/(len(y_test)-X_test.shape[1]-1)","66786831":"As we can see there's no major improvement in the performance of the model, now to go for hyperparameter optimisation","c9fc4382":"An alternative approach to select a base model is to use the lazyregressor from lazypredict \n1. https:\/\/pypi.org\/project\/lazypredict\/","17c5821b":"Now to check for imbalence in the dataset\n1. https:\/\/pypi.org\/project\/smogn\/","dcb7d435":"Here is a basic approach to regression problems","a798d200":"Above step is not compulsory for regression , however the accuracy of classification problems increases by using SMOTE","502b35bb":"After installing lazypredict you need to restart your kernel otherwise it will not work","f2e344b0":"As the XGB regressor has the highest Adjusted R-Squared and R - Squared metric","ce70f5f2":"Since we are using a decision tree model , we don't need to use StandardScaler","260e2d12":"Looks like theres n null values present in the dataset , now to check for outliers","648ef408":"There looks like theres a few outliers in the dataset ,however there's no need to worry about them as DecisionTreeRegressor is not influenced by outliers."}}