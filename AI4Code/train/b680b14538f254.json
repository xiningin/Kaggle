{"cell_type":{"1f1697d9":"code","a0ae9c75":"code","0bef7fde":"code","e0e0ed14":"code","fa130005":"code","47414f7a":"code","bf545bea":"code","9dd01257":"code","aa6fa3a0":"code","071819dd":"code","a92701e9":"code","fad2d7bb":"code","a5f1dca3":"code","afc22a64":"code","7b456bec":"code","fa391795":"code","adae5603":"code","764444c0":"code","2bc53947":"code","58396a75":"code","12855500":"code","87ea0786":"code","9b9812fb":"code","fc30b3be":"code","178eeed5":"code","b743c192":"code","188e8f0a":"code","8076f45e":"code","1a35bb7c":"code","1d0f9450":"code","e8b4992c":"code","cfc1aea8":"code","72ef69ae":"code","b8024374":"code","cc1e52e5":"code","06833fb7":"code","12ff1e1a":"code","abaeb4d5":"code","a6a1c5b7":"code","2236ec12":"code","88d1aaf4":"code","b308e2d0":"code","7b5a1c9d":"code","2ff77e6c":"code","ed4a64c2":"code","45e164e2":"code","7b711c1b":"code","7ffe429c":"code","49908e0b":"code","adae7aba":"code","e89cd6f5":"code","cfc9d6f8":"code","ec4e8444":"code","49150c18":"code","30e6b961":"code","bb6c4019":"code","bc282bc4":"code","fa8ac81a":"code","02d9a672":"code","0ad95eb9":"code","710802f4":"code","8e522839":"code","ba1ea322":"code","7e5531ee":"code","642de48a":"code","336697fe":"code","08607cff":"code","5fbf26d9":"code","5b541c9b":"code","08943041":"code","aed87042":"code","4f11e387":"code","bb4bd5d5":"code","b8e2cf2e":"code","8cb36c43":"code","d0529ce0":"code","d7cf7522":"code","32452e68":"markdown","e5f1fa28":"markdown","d9be201e":"markdown","0e73fc55":"markdown","e1ef28ae":"markdown","d94a842e":"markdown","4fc640fc":"markdown","32052945":"markdown","a7a6e42f":"markdown","5c62e79a":"markdown","cea849cb":"markdown","b2e4e4ce":"markdown","c37f9532":"markdown","5a8289c7":"markdown","4f4fd895":"markdown","07dfc815":"markdown","b75ddb00":"markdown","b4f7b312":"markdown","09ac8fea":"markdown","9c0ea98b":"markdown","822910bb":"markdown","27d3a360":"markdown","0169dd72":"markdown","fbf9df5e":"markdown","3827e2c9":"markdown","85cd17ad":"markdown","759ddebb":"markdown","9c1214e6":"markdown","5cb45466":"markdown"},"source":{"1f1697d9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npd.set_option('display.max_columns',None)","a0ae9c75":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","0bef7fde":"df","e0e0ed14":"df.isnull().sum()","fa130005":"df.quality.value_counts()","47414f7a":"df['quality'] = np.where(df['quality']<=4,0,df['quality'])","bf545bea":"df['quality'] = np.where((df['quality']<=6) & (df['quality']!=0 ),1,df['quality'])","9dd01257":"df['quality'] = np.where( df['quality']>=7,2,df['quality'])","aa6fa3a0":"df.quality.value_counts()","071819dd":"from imblearn.combine import SMOTETomek","a92701e9":"smk = SMOTETomek(random_state=0)","fad2d7bb":"X,y=smk.fit_sample(df.drop('quality',axis=1),df['quality'])","a5f1dca3":"df = pd.concat([X,y],axis=1)","afc22a64":"df.quality.value_counts()","7b456bec":"df.head()","fa391795":"features = [feature for feature in df.columns if feature!='quality']","adae5603":"for feature in features:\n    sns.boxplot(x=feature,data=df)\n    plt.xlabel(feature)\n    plt.show()","764444c0":"dic = {}\nfor feature in features:\n    IQR = df[feature].quantile(0.75) - df[feature].quantile(0.25)\n    upper_bond = df[feature].quantile(0.75) + (IQR * 1.5)\n    lower_bond = df[feature].quantile(0.25) - (IQR * 1.5)\n    \n    df[feature] = np.where(df[feature]>upper_bond,upper_bond,df[feature])\n    df[feature] = np.where(df[feature]<lower_bond,lower_bond,df[feature])","2bc53947":"for feature in features:\n    sns.boxplot(x=feature,data=df)\n    plt.xlabel(feature)\n    plt.show()","58396a75":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","12855500":"selectk = SelectKBest(score_func=chi2,k=7)","87ea0786":"Best = selectk.fit(df.drop('quality',axis=1),df['quality'])","9b9812fb":"Best.scores_","fc30b3be":"features","178eeed5":"dfscores = pd.DataFrame(Best.scores_)\ndffeatures = pd.DataFrame(features)","b743c192":"features_scores = pd.concat([dffeatures,dfscores],axis=1)","188e8f0a":"features_scores.columns = ['feature','scores']","8076f45e":"features_scores.sort_values(by='scores',ascending=False)","1a35bb7c":"Best_features = features_scores[features_scores['scores']>30]['feature']","1d0f9450":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","e8b4992c":"from sklearn.model_selection import train_test_split","cfc1aea8":"X_train,X_test,y_train,y_test = train_test_split(df[Best_features],df['quality'],test_size=0.2,random_state=0)","72ef69ae":"from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,classification_report","b8024374":"from sklearn.tree import DecisionTreeClassifier","cc1e52e5":"model = DecisionTreeClassifier()","06833fb7":"model.fit(X_train,y_train)","12ff1e1a":"y_predict = model.predict(X_test)","abaeb4d5":"y_predict_proba_train = model.predict_proba(X_train)","a6a1c5b7":"y_predict_proba_test = model.predict_proba(X_test)","2236ec12":"roc_auc_score(y_train,y_predict_proba_train,multi_class='ovo')","88d1aaf4":"roc_auc_score(y_test,y_predict_proba_test,multi_class='ovo')","b308e2d0":"confusion_matrix(y_test,y_predict)","7b5a1c9d":"accuracy_score(y_test,y_predict)","2ff77e6c":"print(classification_report(y_test,y_predict))","ed4a64c2":"from sklearn.model_selection import cross_val_score","45e164e2":"cross_val_score(model,df[Best_features],df['quality'],scoring='accuracy',n_jobs=-1).mean()","7b711c1b":"from sklearn.ensemble import RandomForestClassifier","7ffe429c":"model = RandomForestClassifier()","49908e0b":"model.fit(X_train,y_train)","adae7aba":"y_predict = model.predict(X_test)","e89cd6f5":"y_predict_proba_train = model.predict_proba(X_train)","cfc9d6f8":"y_predict_proba_test = model.predict_proba(X_test)","ec4e8444":"roc_auc_score(y_train,y_predict_proba_train,multi_class='ovo')","49150c18":"roc_auc_score(y_test,y_predict_proba_test,multi_class='ovo')","30e6b961":"confusion_matrix(y_test,y_predict)","bb6c4019":"accuracy_score(y_test,y_predict)","bc282bc4":"print(classification_report(y_test,y_predict))","fa8ac81a":"cross_val_score(model,df[Best_features],df['quality'],scoring='accuracy',n_jobs=-1).mean()","02d9a672":"from xgboost import XGBClassifier","0ad95eb9":"model = XGBClassifier()","710802f4":"model.fit(X_train,y_train)","8e522839":"y_predict = model.predict(X_test)","ba1ea322":"y_predict_proba_train = model.predict_proba(X_train)","7e5531ee":"y_predict_proba_test = model.predict_proba(X_test)","642de48a":"roc_auc_score(y_train,y_predict_proba_train,multi_class='ovo')","336697fe":"roc_auc_score(y_test,y_predict_proba_test,multi_class='ovo')","08607cff":"confusion_matrix(y_test,y_predict)","5fbf26d9":"accuracy_score(y_test,y_predict)","5b541c9b":"print(classification_report(y_test,y_predict))","08943041":"cross_val_score(model,df[Best_features],df['quality'],scoring='accuracy',n_jobs=-1).mean()","aed87042":"params = {\n    'n_estimators' : list(np.arange(5,101,1)) ,\n    'max_depth' : list(np.arange(3,16,1)) ,\n    'min_child_weight' : [1,3,4,5,6,7,8] ,\n    'learning_rate' : list(np.arange(0.05,0.35,0.05)) ,\n    'colsample_bytree' : [0.4,0.5,0.6,0.7],\n    'gamma' : [0.0,0.1,0.2,0.3,0.4]    \n}","4f11e387":"from sklearn.model_selection import RandomizedSearchCV","bb4bd5d5":"random_search = RandomizedSearchCV(model,param_distributions=params,n_jobs=-1,scoring='accuracy',verbose=3,cv=5)","b8e2cf2e":"random_search.fit(df[Best_features],df['quality'])","8cb36c43":"random_search.best_estimator_","d0529ce0":"model = XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.4, gamma=0.4, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.3, max_delta_step=0, max_depth=10,\n              min_child_weight=1, monotone_constraints=None,\n              n_estimators=37, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1,\n              tree_method=None, validate_parameters=False, verbosity=None)","d7cf7522":"cross_val_score(model,df[Best_features],df['quality'],scoring='accuracy',n_jobs=-1).mean()","32452e68":"As we can see with the help of Hyperparameter Optimization we have improved 1% accuracy","e5f1fa28":"we can see Random  Forest Classifier is giving 88% with cross_val_score\n\nNow we will check with XGBClassifier.","d9be201e":"From above we can see that for class 1 precision and recall is falling behind","0e73fc55":"There are no Nan values present in Dataset.","e1ef28ae":"will analyse it one by one. ","d94a842e":"Now, it is perfectly balanced dataset","4fc640fc":"As we can see here,Dataset is completely imbalanced.\n\nso,we need to fix it. Otherwise your model will baised to single label.","32052945":"As we can see RandomForest fixed the problem of low bias high variance to low bias low variance.","a7a6e42f":"we will take top 7 features","5c62e79a":"As we know Decision tree follows low bias and high variance. Which means for training dataset it gives high accuracy but for testing dataset it gives less accuracy.\n\nThis problem can be easily solved with the help of ensemble techniques. \n\ne.g - RandomForest,XGBoost.","cea849cb":"we have converted quality variable into three labels as 0-poor,1-good,2-best.","b2e4e4ce":"XGBClassifier is giving 90% accuracy with cross_val_score","c37f9532":"Now we will move to feature selection part.","5a8289c7":"we are mapping each score with respect to each feature recpectively.","4f4fd895":"#### Thank You","07dfc815":"Now we split our dataset into train and test dataset.","b75ddb00":"First and foremost will check is there any Nan values present in the Dataset.","b4f7b312":"we will improve model accuracy by using Hyperparameter Optimization.\n\nHere we are using RandomizedSearchCV.","09ac8fea":"These are the scores related to each feature with respect to output variable(quality).","9c0ea98b":"As we can see there are number of Outliers present in each feature.\nso,here will use top encoding and bottom encoding technique to fix this.","822910bb":"with cross_val_score, Decisison Tree is giving 82% accuracy. ","27d3a360":"Feature Selection with the help of correlation","0169dd72":"Precision and Recall is further improved with XGBoost","fbf9df5e":"#### I hope you enjoyed a lot.","3827e2c9":"Here,All the variables(features) are of Numerical type.","85cd17ad":"As there are many labels, we will divide it into 3 labels. ","759ddebb":"From above we can notice that volatile acidity,citric acid,alcohol and sulphates are correlated more than fifty percent to target variable (quality).","9c1214e6":"But Outliers do not impact much on tree based models.","5cb45466":"Precision and Recall is improved with Random Forest"}}