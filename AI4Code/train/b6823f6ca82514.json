{"cell_type":{"f743fa43":"code","bba68748":"code","c424fa9f":"code","893f8e4b":"code","47011c2b":"code","eedb5322":"code","e51e3d1b":"code","30fed13d":"code","c948a58a":"code","d931a07e":"code","9429d7fd":"code","1abfa02d":"code","28365be1":"code","df9eac6d":"code","f644382e":"code","320a6bc7":"code","586bcd50":"code","e0fac235":"markdown","102ecf38":"markdown","551e25a8":"markdown","cd7e0691":"markdown","19150305":"markdown","9eec0328":"markdown","9fce1480":"markdown","06b633aa":"markdown","5cf38cc8":"markdown","3d5d3db5":"markdown","5c0de889":"markdown","a26973a2":"markdown","e58a259f":"markdown"},"source":{"f743fa43":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\nimport datetime\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model","bba68748":"train_dir = '..\/input\/fer2013\/train\/'\ntest_dir = '..\/input\/fer2013\/test\/'\n\nrow, col = 48, 48\nclasses = 7\n\ndef count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","c424fa9f":"train_count.transpose().plot(kind='bar')","893f8e4b":"test_count.transpose().plot(kind='bar')","47011c2b":"plt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[5]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","eedb5322":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   zoom_range=0.3,\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=64,\n                                                target_size=(48,48),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                                batch_size=64,\n                                                target_size=(48,48),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')","e51e3d1b":"training_set.class_indices","30fed13d":"def get_model(input_size, classes=7):\n     #Initialising the CNN\n    model = tf.keras.models.Sequential()   \n\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(2, 2))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(classes, activation='softmax'))\n\n    #Compliling the model\n    model.compile(optimizer=Adam(lr=0.0001, decay=1e-6), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model","c948a58a":"fernet = get_model((row,col,1), classes)\nfernet.summary()","d931a07e":"plot_model(fernet, to_file='fernet.png', show_shapes=True, show_layer_names=True)","9429d7fd":"chk_path = 'ferNet.h5'\nlog_dir = \"checkpoint\/logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncheckpoint = ModelCheckpoint(filepath=chk_path,\n                             save_best_only=True,\n                             verbose=1,\n                             mode='min',\n                             moniter='val_loss')\n\nearlystop = EarlyStopping(monitor='val_loss', \n                          min_delta=0, \n                          patience=3, \n                          verbose=1, \n                          restore_best_weights=True)\n                        \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=6, \n                              verbose=1, \n                              min_delta=0.0001)\n\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\ncsv_logger = CSVLogger('training.log')\n\ncallbacks = [checkpoint, reduce_lr, csv_logger]","1abfa02d":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\nhist = fernet.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=60,\n                 callbacks=callbacks,\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","28365be1":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","df9eac6d":"train_loss, train_accu = fernet.evaluate(training_set)\ntest_loss, test_accu = fernet.evaluate(test_set)\nprint(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))","f644382e":"fernet.save_weights('fernet_bestweight.h5')","320a6bc7":"y_pred = fernet.predict(training_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm_train = confusion_matrix(training_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_train)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(training_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_train, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","586bcd50":"y_pred = fernet.predict(test_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\n#from sklearn.metrics import classification_report, confusion_matrix\ncm_test = confusion_matrix(test_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_test)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(test_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_test, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","e0fac235":"### Confusion Matrix and Classification on training set","102ecf38":"## Creating Training and test sets","551e25a8":"### PLot of number of images in test set","cd7e0691":"### PLot of number of images in training set","19150305":"## Importing Dataset","9eec0328":"## Loss and Accuracy plot","9fce1480":"### Model evaluation","06b633aa":"### Callbacks Function","5cf38cc8":"# Facial Emotion Recogination","3d5d3db5":"## Training Model","5c0de889":"### Confusion Matrix and Classification on test set","a26973a2":"## importing libraries","e58a259f":"## Defining Model"}}