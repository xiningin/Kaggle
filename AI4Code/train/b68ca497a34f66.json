{"cell_type":{"f5932c51":"code","52203e27":"code","9333bdf6":"code","79e2ac05":"code","6f832e72":"code","cdb4fceb":"code","cd458a4c":"code","359e44ed":"code","0da26958":"code","96a747bc":"code","0869fc80":"code","e8ad792d":"code","254e34f0":"code","ec906cf6":"code","beea6955":"code","08824c74":"code","03bdfe10":"code","41ba8385":"code","517c614a":"code","e8753ddf":"code","c2be377d":"code","77912a97":"code","fa4ca6e7":"code","e2b1e1e9":"code","1eaa9054":"code","a9452dec":"code","dbd07c27":"code","d3e85396":"code","214f1289":"code","de56b169":"code","9cb7d781":"code","ed303711":"markdown","2e4e99c5":"markdown","b5ed9342":"markdown","4fcee829":"markdown","f2a7216a":"markdown","b2009684":"markdown","25f75b3c":"markdown","e5c69016":"markdown","a1e65f59":"markdown","2f3a5c46":"markdown","dc03e804":"markdown","15472689":"markdown","dc17b472":"markdown","43895cd1":"markdown","cf4c8b8d":"markdown","8ab164e1":"markdown","88408c07":"markdown","382c9fe6":"markdown","9a3e3645":"markdown","475446e7":"markdown","9a180509":"markdown","56bce71d":"markdown","0ac699db":"markdown"},"source":{"f5932c51":"import os\nimport cv2\nimport glob\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n!pip install git+https:\/\/github.com\/miykael\/gif_your_nifti # nifti to gif \nimport gif_your_nifti.core as gif2nif\n\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nfrom keras.utils.np_utils import to_categorical   \nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","52203e27":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',\n    1 : 'NECROTIC\/CORE', \n    2 : 'EDEMA',\n    3 : 'ENHANCING' # original 4 -> converted into 3 later\n}\n\n# days start interval\nSURVIVAL_CATEGORIES= {\n    'SHORT' : 0 , # 0-300\n    'MEDIUM' : 300,  # 300-450\n    'LONG' : 450, # 450 and more\n}\n\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include\nIMG_SIZE=128\nTRAIN_DATASET_PATH='..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData\/'","9333bdf6":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('\/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); ","79e2ac05":"my_loc_slice=73\nimage_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001\/BraTS20_Training_001_t1.nii').get_fdata()\nmy_img=image_volume[:,:,my_loc_slice]\nmy_converted_img = my_img.copy()\nmy_converted_img[my_converted_img == 0] = 666\n\n\nf, axarr = plt.subplots(1,2, figsize = (10, 5))\naxarr[0].imshow(my_img)\naxarr[1].imshow(my_converted_img)","6f832e72":"def maskSizeForSlice(path,i_slice):\n    totals = dict([(1, 0), (2, 0), (3, 0)])\n    image_volume=nib.load(path).get_fdata()\n    # flatten 3D image into 1D array and convert mask 4 to 2\n    arr=image_volume[:,:,i_slice].flatten()\n    arr[arr == 4] = 3\n\n    unique, counts = np.unique(arr, return_counts=True)\n    unique = unique.astype(int)\n    values_dict=dict(zip(unique, counts))\n    for k in range(1,4):\n        totals[k] += values_dict.get(k,0)\n    return totals","cdb4fceb":"my_loc_slice=73\nmy_loc_class=1\nseg_sum=maskSizeForSlice(TRAIN_DATASET_PATH+'BraTS20_Training_001\/BraTS20_Training_001_seg.nii',my_loc_slice)\n\n\nimage_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001\/BraTS20_Training_001_seg.nii').get_fdata()\nimage_loc=image_volume[:,:,my_loc_slice]\nimage_loc[image_loc != my_loc_class] = 0\n\n# plot segment only for class 'my_loc_class'\nplt.imshow(image_loc)\n\nimage_loc=image_loc.flatten()\ncount = np.count_nonzero(image_loc == my_loc_class)\nprint(f'count class {my_loc_class}: {count}')\nprint(seg_sum)","cd458a4c":"import csv\n\ncsv_path = '..\/input\/brats20-dataset-training-validation\/BraTS2020_TrainingData\/MICCAI_BraTS2020_TrainingData\/survival_info.csv'\n\nage_dict = {}\ndays_dict = {}\n\n\nwith open(csv_path, mode='r') as csv_file:\n    csv_reader = csv.reader(csv_file,delimiter = ',')\n  #  row_count = sum(1 for row in csv_reader)\n #   print(f'total rows: {row_count} .')\n    at_line = 0\n    category_short = 0\n    category_medium = 0\n    category_long = 0\n    max_days = 0\n    for row in csv_reader:\n        if at_line == 0:\n            print(f'Column names are {\", \".join(row)}')\n            at_line += 1\n        else:\n            if (row[3] != \"GTR\"):\n                continue\n            print(row)\n            key = row[0]\n            age = row[1]\n            days = row[2]\n            if (not days.isnumeric()):\n                continue\n            age_dict[key] = float(age)\n            days_dict[key] = int(days)\n            max_days = max(max_days,int(days))\n            if int(days) < 250:\n                category_short += 1\n            elif (int(days) >= 250 and int(days) <= 450):\n                category_medium += 1\n            else:\n                category_long += 1\n            at_line+=1\n\n    print(f'Processed {at_line} lines.')\n    print(category_short,category_medium,category_long)\n    print(max_days)","359e44ed":"from collections import Counter\nfrom itertools import cycle\n#age_dict, days_dict \n\n# round values in dictionary\nage_dict_rounded = {key : round(age_dict[key], 0) for key in age_dict}\n# survival days are very distinct values => move the values in ranges per 20\ndays_dict_rounded = {key : round(days_dict[key]\/20)*20 for key in days_dict}\n\n# count same numbers => create statistics how many times is there person with same age\nage_dict_rounded_counted = Counter(age_dict_rounded.values())\ndays_dict_rounded_counted = Counter(days_dict_rounded.values())\n\ncycol = cycle('bgrcmk')\ncolors = list()\nfor i in range(len(age_dict_rounded_counted)):\n    colors.append(next(cycol))\n    \ncycol = cycle('bgrcmk')    \ncolorsDays = list()\nfor i in range(len(days_dict_rounded_counted)):\n    colorsDays.append(next(cycol))\n\nplt.figure(figsize=(16, 6), dpi=80)\nplt.xlabel('Number of people with (rounded) age')\nplt.ylabel('Age (rounded)')\nplt.title(\"(Rounded) age distrubution in dataset\")\nplt.bar(list(age_dict_rounded_counted.keys()), age_dict_rounded_counted.values(), color=colors)\nplt.show()\n\nplt.figure(figsize=(14, 6), dpi=80)\nplt.xlabel('Days survived')\nplt.ylabel('Number of people (rounded to 20)')\nplt.title(\"Survival days distribution\")\nplt.bar(list(days_dict_rounded_counted.keys()), days_dict_rounded_counted.values(),width=15, color=colorsDays)\nplt.show()","0da26958":"# get number of pixels for each segment as dictionary\n# original images contain segment values (0,1,2,4) => 4 is our 3 ... :)\ndef getMaskSizesForVolume(image_volume):\n    totals = dict([(1, 0), (2, 0), (3, 0)])\n    for i in range(VOLUME_SLICES):\n        # flatten 2D image into 1D array and convert mask 4 to 2\n        arr=image_volume[:,:,i+VOLUME_START_AT].flatten()\n        arr[arr == 4] = 3\n        \n        unique, counts = np.unique(arr, return_counts=True)\n        unique = unique.astype(int)\n        values_dict=dict(zip(unique, counts))\n        for k in range(1,4):\n            totals[k] += values_dict.get(k,0)\n    return totals","96a747bc":"# returns count of non zero elements in whole 3D volume\ndef getBrainSizeForVolume(image_volume):\n    total = 0\n    for i in range(VOLUME_SLICES):\n        arr=image_volume[:,:,i+VOLUME_START_AT].flatten()\n        image_count=np.count_nonzero(arr)\n        total=total+image_count\n    return total\n\nexample_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001\/BraTS20_Training_001_t1.nii').get_fdata()\n\nf, axarr = plt.subplots(1,2, figsize = (8, 4))\naxarr[0].imshow(example_volume[:,:,VOLUME_START_AT])\naxarr[1].imshow(example_volume[:,:,VOLUME_START_AT+30])\n\nprint(f'total count: {getBrainSizeForVolume(example_volume)}')","0869fc80":"# create only age: category data\n\n# id: age, categories\ndef getListAgeDays(id_list):\n    x_val = []\n    y_val = []\n    for i in id_list:\n        if (i not in age_dict):\n            continue\n        masks = getMaskSizesForVolume(nib.load(TRAIN_DATASET_PATH + f'BraTS20_Training_{i[-3:]}\/BraTS20_Training_{i[-3:]}_seg.nii').get_fdata())\n        brain_vol = getBrainSizeForVolume(nib.load(TRAIN_DATASET_PATH + f'BraTS20_Training_{i[-3:]}\/BraTS20_Training_{i[-3:]}_t1.nii').get_fdata())\n        masks[1] = masks[1]\/brain_vol\n        masks[2] = masks[2]\/brain_vol\n        masks[3] = masks[3]\/brain_vol\n        merged=[age_dict[i],masks[1],masks[2],masks[3]] ## add segments\n        x_val.append(merged) \n        if (days_dict[i] < 250):\n            y_val.append([1,0,0])\n        elif (days_dict[i] >= 250 and days_dict[i] < 450):\n            y_val.append([0,1,0])\n        else:\n            y_val.append([0,0,1])\n            \n    return np.array(x_val), np.array(y_val)\n\nX_all, y_all = getListAgeDays(train_and_test_ids)\n\nprint(f'X_test: {X_all.shape}')\ndf = pd.DataFrame(np.concatenate((X_all, y_all), axis=1) , columns = [\"age\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\",\"short\",\"medium\",\"long\"])\ndf.head()","e8ad792d":"scaler = MinMaxScaler()\nv = X_all\nv_scaled = scaler.fit_transform(v)\nX_all = v_scaled\n\ndf = pd.DataFrame(X_all, columns = [\"age normalised\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\"])\ndisplay(df)","254e34f0":"sns.set()\n\ndf = pd.DataFrame(X_all, columns = [\"age\", SEGMENT_CLASSES[1],SEGMENT_CLASSES[2],SEGMENT_CLASSES[3]])\nsns.pairplot(df, diag_kind='kde')","ec906cf6":"X_train, X_test, y_train, y_test = train_test_split(X_all,y_all,test_size = 0.2, random_state = 42, shuffle = True)\n\n\nprint(\"x_train shape:\",X_train.shape)\nprint(\"x_test shape:\", X_train.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","beea6955":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\nrfc = RandomForestClassifier(n_estimators=3, random_state=0)\n\n# fit the model to the training set\nrfc.fit(X_train, y_train)\ny_pred = rfc.predict(X_test)\n\nprint('Model accuracy score with 3 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n\n\n\naccuracies = cross_val_score(rfc, X_train, y_train, cv=3)\n# rfc.fit(X_train,y_train)\n\nprint(\"Cross validation: Train Score:\",np.mean(accuracies))\nprint(\"Cross validation: Test Score:\",rfc.score(X_test,y_test))","08824c74":"df = pd.DataFrame(X_train, columns = [\"age\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\"])\n\nfeature_scores = pd.Series(rfc.feature_importances_, index=df.columns).sort_values(ascending=False)\nfeature_scores","03bdfe10":"sns.barplot(x=feature_scores, y=feature_scores.index)\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.show()","41ba8385":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n\nsns.set(font_scale=1.2) \nsns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n\nplt.show()","517c614a":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))","e8753ddf":"grid = {\n    'n_estimators':np.arange(1,100,1),\n    'criterion':['gini','entropy']\n    }\n\nrfc_ = RandomForestClassifier(random_state = 42)\nrf_grid = GridSearchCV(rfc_, grid, cv=5)\nrf_grid.fit(X_train,y_train)\n\nprint(\"Hyperparameters:\",rf_grid.best_params_)\nprint(\"Train Score:\", rf_grid.best_score_)\nprint(\"Test Score:\",rf_grid.score(X_test,y_test))","c2be377d":"from sklearn.svm import SVC\n\n#convert one hot into multilabel\ny_train_multi=np.argmax(y_train, axis=1)\ny_test_multi =np.argmax(y_test, axis=1)\n\nsvc = SVC(random_state = 42, C=10, degree=3, gamma=1, kernel='poly')\nsvc.fit(X_train,y_train_multi)\naccuracies = cross_val_score(svc, X_train, y_train_multi)\n\n\ny_pred = svc.predict(X_test)\n\nprint('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n\n\nprint(\"Cross validation: Train Score:\",np.mean(accuracies))\nprint(\"Cross validation: Test Score:\",svc.score(X_test,y_test_multi))","77912a97":"# convert to one hot\ny_pred=y_pred.astype(int)\nn_values = np.max(y_pred) + 1\ny_pred_hot=np.eye(n_values)[y_pred]\n\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n\nsns.set(font_scale=1.2) \nsns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n\nplt.show()","fa4ca6e7":"print(classification_report(y_test_multi, y_pred))","e2b1e1e9":"grid = {\n    'C':[0.01,0.1,1,10,15,20],\n    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n    'degree' : [1,3,5,7],\n    'gamma' : [0.01,1]\n}\n\nsvm  = SVC();\nsvm_grid = GridSearchCV(svm, grid, cv = 5)\nsvm_grid.fit(X_train,y_train_multi)\nprint(\"Best Parameters:\",svm_grid.best_params_)\nprint(\"Train Score:\",svm_grid.best_score_)\nprint(\"Test Score:\",svm_grid.score(X_test,y_test_multi))","1eaa9054":"from sklearn.neighbors import KNeighborsClassifier\n\nknn  = KNeighborsClassifier(n_neighbors=38, p=2, weights='distance')\nknn.fit(X_train,y_train_multi)\naccuracies = cross_val_score(knn, X_train, y_train_multi)\n\ny_pred = knn.predict(X_test)\n\nprint('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n\n\nprint(\"Cross validation: Train Score:\",np.mean(accuracies))\nprint(\"Cross validation: Test Score:\",knn.score(X_test,y_test_multi))","a9452dec":"# convert to one hot\ny_pred=y_pred.astype(int)\nn_values = np.max(y_pred) + 1\ny_pred_hot=np.eye(n_values)[y_pred]\n\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n\nsns.set(font_scale=1.2) \nsns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n\nplt.show()","dbd07c27":"print(classification_report(y_test_multi, y_pred))","d3e85396":"grid = {\n    'n_neighbors':np.arange(1,75),\n    'p':np.arange(1,5),\n    'weights':['uniform','distance']\n    }\n\nknn = KNeighborsClassifier()\nknn_grid = GridSearchCV(knn,grid,cv=5)\nknn_grid.fit(X_train,y_train_multi)\n\nprint(\"Hyperparameters:\",knn_grid.best_params_)\nprint(\"Train Score:\",knn_grid.best_score_)\nprint(\"Test Score:\",knn_grid.score(X_test,y_test_multi))","214f1289":"from sklearn.neural_network import MLPClassifier\n\n\nclf = MLPClassifier(\n    hidden_layer_sizes=11,\n    max_iter=150,\n    alpha=1e-05,\n    solver='lbfgs',\n    verbose=10,\n    random_state=6,\n    tol=0.000000001\n)\n\nclf.fit(X_train, y_train_multi)\naccuracies = cross_val_score(clf, X_train, y_train_multi)\ny_pred = clf.predict(X_test)\n\nprint('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n\n\nprint(\"Cross validation: Train Score:\",np.mean(accuracies))\nprint(\"Cross validation: Test Score:\",knn.score(X_test,y_test_multi))","de56b169":"# convert to one hot\ny_pred=y_pred.astype(int)\nn_values = np.max(y_pred) + 1\ny_pred_hot=np.eye(n_values)[y_pred]\n\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n\nsns.set(font_scale=1.2) \nsns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n\nplt.show()","9cb7d781":"grid = {\n    'solver': ['lbfgs'],\n    'max_iter': [25,50,100,150,200,300,500,1000 ],\n    'alpha': 10.0 ** -np.arange(1, 10),\n    'hidden_layer_sizes':np.arange(10, 15),\n    'random_state':[0,1,2,3,4,5,6,7,8,9]\n}\nclf_grid = GridSearchCV(MLPClassifier(), grid, n_jobs=-1)\n\nclf_grid.fit(X_train, y_train_multi)\n\nprint(\"Hyperparameters:\",clf_grid.best_params_)\nprint(\"Train Score:\",clf_grid.best_score_)\nprint(\"Test Score:\",clf_grid.score(X_test, y_test_multi))","ed303711":"**Lets see what is the age distrubution in our dataset and their survival days**<br>\nskip not GTR values..","2e4e99c5":"# SVM classifier","b5ed9342":"**Normalize the data**\nperforming min-max scaling into range [0, 1]","4fcee829":"# MLP Classifier","f2a7216a":"**Compute brain volume size** => ignore background","b2009684":"# Survival prediction","25f75b3c":"**GridSearch**<br>\nTo find best score, I will try different value of:\n1. solver -> \u2018lbfgs\u2019 is an optimizer in the family of quasi-Newton methods. (we will use 'lbfgs', because we have very small dataset)\n2. max_iter -> Maximum number of iterations.\n3. alpha -> L2 penalty (regularization term) parameter.\n4. hidden_layer_sizes -> The ith element represents the number of neurons in the ith hidden layer\n5. random state -> Determines random number generation for weights and bias initialization, \n                  -> train-test split if early stopping is used, and batch sampling when solver=\u2019sgd\u2019 or \u2018adam","e5c69016":"**Gridsearch**<br>\nTo find best score, I will try different value of:\n1. n_estimators -> in range (1,100) with step 1\n2. criterion parameters -> gini and entropy","a1e65f59":"**Train test split**","2f3a5c46":"**GridSearch**<br>\nTo find best score, I will try different value of:\n1. n_neighbors -> Number of neighbors to use by default for kneighbors queries\n2. p -> Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance\n3. weights -> weight function used in prediction\n","dc03e804":"**Define constants**","15472689":"# KNN Classifier","dc17b472":"**Check if the background of images contains only zero values**<br>\nVisualize zero values in image (black values ==> background) , converted into another color so its easier to see ","43895cd1":"# Setup env","cf4c8b8d":"**View data distributions**","8ab164e1":"# Conclusion<br>\n\nTODO :)\n","88408c07":"**Confusion matrix**","382c9fe6":"**GridSearch**<br>\nTo find best score, I will try different value of:\n1. C -> Regularization parameter\n2. kernel -> Specifies the kernel type to be used in the algorithm\n3. degree -> Degree of the polynomial kernel function\n4. gamma -> Kernel coefficient for \u2018rbf\u2019, \u2018poly\u2019 and \u2018sigmoid\u2019.","9a3e3645":"**Split Dataset into train\/test\/validation**<br>\n0.65\/0.20\/0.15<br>","475446e7":"Count number of pixels for each segment for each slice in volume","9a180509":"**Visualize the most important features**<br>\nWe can see that the most important feature is age","56bce71d":"# Computing segment sizes\nFind number of pixels for each class in volume, no need to compute as ration to image size, since all images are of same size 240x240","0ac699db":"# Random forest "}}