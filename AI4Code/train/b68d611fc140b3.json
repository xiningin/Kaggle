{"cell_type":{"23d5adff":"code","9c11aa7e":"code","1876e083":"code","b1a64e34":"code","cd1a6d6a":"code","620f0e3b":"code","6f548bb2":"code","7ac8ac43":"code","de3efcee":"code","2270d103":"code","8817bcdc":"code","90ffdf22":"code","541324a9":"code","0dac5068":"code","bf171bac":"code","1546a923":"code","534642a1":"code","c2b02d9e":"markdown","7ed67c34":"markdown","18735204":"markdown","5fc85f0d":"markdown","4650f817":"markdown","2de665c1":"markdown","523c0d6f":"markdown","73814a89":"markdown","58efafb0":"markdown","7dfca1b1":"markdown"},"source":{"23d5adff":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout, BatchNormalization\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import RidgeClassifier\nfrom catboost import Pool, CatBoostClassifier, cv\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import precision_score,make_scorer,roc_auc_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n\nfrom sklearn.model_selection import StratifiedShuffleSplit \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/creditcardfraud\/creditcard.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9c11aa7e":"df=pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","1876e083":"pd.set_option('display.float','{:.2f}'.format)\ndf.describe()","b1a64e34":"miss = df.isnull().sum()\nmiss_percnt = (miss\/len(df))*100\npd.concat([miss,miss_percnt], axis=1, keys=['Valores Ausentes','Percentual de Ausentes '])","cd1a6d6a":"df['Class'].value_counts()","620f0e3b":"fraud = df[(df['Class'] != 0)]\nnormal = df[(df['Class'] == 0)]\n\ntrace = go.Pie(labels = ['Genu\u00edna', 'Fraude'], values = df['Class'].value_counts(), \n               textfont=dict(size=15), opacity = 0.9,\n               marker=dict(colors=['white','black'], \n                           line=dict(color='#000000', width=1)))\n\n\nlayout = dict(title =  'Distribui\u00e7\u00e3o de transa\u00e7\u00f5es genu\u00ednas e fraudulentas')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","6f548bb2":"height=df.groupby('Class')['Class'].count().values\nbars=df.groupby('Class')['Class'].count().index\ny_pos=np.arange(len(bars))\n\nplt.bar(y_pos,height)\n\nfor i in range(0,len(y_pos)):\n    plt.text(x=1-0.05,y=height[i],s=height[i],size=10)\n    \n    plt.xticks(y_pos, bars, fontweight='bold',fontsize='10')\n    \nplt.show()","7ac8ac43":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr().round(3));","de3efcee":"X = df.drop('Class', axis=1)\ny = df['Class']","2270d103":"sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(X, y):\n  X_train_full, X_test = X.iloc[train_index], X.iloc[test_index]\n  y_train_full, y_test = y.iloc[train_index], y.iloc[test_index]\n\nsss2 = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\nfor train_idx, test_idx in sss2.split(X_train_full, y_train_full):\n  X_train, X_valid = X_train_full.iloc[train_idx], X_train_full.iloc[test_idx]\n  y_train, y_valid = y_train_full.iloc[train_idx], y_train_full.iloc[test_idx]","8817bcdc":"print('X_train shape: ', X_train.shape)\nprint('y_train shape: ', y_train.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y_test shape: ', y_test.shape)","90ffdf22":"clf = RandomForestClassifier(max_depth=5, min_samples_split=5,min_samples_leaf=4, random_state=42)\n                            \nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n# Accuracy score\n\nprint('accuracy is',accuracy_score(y_pred,y_test))","541324a9":"from imblearn.over_sampling import ADASYN\n\nads = ADASYN( random_state=42)\n\nX_ads, y_ads = ads.fit_resample(X_train_full[feat_cols].values, y_train_full)","0dac5068":"sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(X_ads, y_ads):\n  X_train_ads, X_valid_ads = X_ads[train_index], X_ads[test_index]\n  y_train_ads, y_valid_ads = y_ads[train_index], y_ads[test_index]","bf171bac":"from imblearn.over_sampling import ADASYN\n\nads = ADASYN( random_state=42)\n\nX_ads, y_ads = ads.fit_resample(X_train_full[feat_cols].values, y_train_full)","1546a923":"sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(X_ads, y_ads):\n  X_train_ads, X_valid_ads = X_ads[train_index], X_ads[test_index]\n  y_train_ads, y_valid_ads = y_ads[train_index], y_ads[test_index]","534642a1":"clf = RandomForestClassifier(max_depth=3, min_samples_split=4,min_samples_leaf=4, random_state=42)\nclf.fit(X_train_ads, y_train_ads)\n\ny_pred = clf.predict(X_test)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n# Accuracy score\n\nprint('accuracy is',accuracy_score(y_pred,y_test))","c2b02d9e":"Importando as bibliotecas necess\u00e1rias","7ed67c34":"Separando o dataset em treino e teste","18735204":"Balanceando os dados","5fc85f0d":"**RESUMO**","4650f817":"Rodando os dados com RandomForest","2de665c1":"Explorando os dados","523c0d6f":"**INTRODU\u00c7\u00c3O**\n","73814a89":"Checando valores faltantes","58efafb0":"Distrubui\u00e7\u00e3o das classes","7dfca1b1":"Carregando os dados"}}