{"cell_type":{"2afaafa2":"code","ac1c947e":"code","261f8e5f":"code","213003da":"code","9cb7b13e":"code","e3692a7e":"code","713ad028":"code","063a40eb":"code","efe2961f":"code","0379e409":"code","f03a208f":"code","d8c5a663":"code","30b5d27d":"code","207b5680":"code","5451c8ce":"code","4504e5a0":"code","ef13bf08":"code","5ee0277a":"code","c24c5afb":"code","63d16783":"code","32b88356":"code","87d3e001":"code","7a725a3e":"code","6ad1945d":"code","268c7b53":"code","ea64584f":"code","b631f143":"code","3b741c4a":"code","a12b4eec":"code","4091f23f":"code","9b2a7d99":"code","aa2657e4":"code","3f7b6b58":"code","f8b2f958":"code","0438a0ea":"code","d3c38850":"code","5679ec2c":"code","c5aadf19":"code","d62024d8":"code","e2b01c73":"code","865d24a5":"code","e42e032e":"code","e2be1c3d":"code","39cd79d5":"code","7b1acce0":"code","9268e002":"code","7fef83dd":"code","b4de9035":"code","05b6c2a1":"code","ff1b514c":"code","cf635abd":"code","a7cedb57":"code","a6327c0d":"code","ece489e1":"code","2a9d2404":"code","9ef49409":"code","206409ed":"code","8b1840c0":"code","685947d1":"code","f23393c4":"code","3fd8b63e":"code","1e4b1faf":"code","210e78cd":"code","ffac77fd":"code","a6710e71":"code","5480983f":"code","1e986dea":"code","7a4c5e88":"code","ad17e3c8":"code","e9229a9e":"code","a63ad58e":"code","94ed75c0":"code","ebcf2563":"code","a85eea62":"code","a6a90907":"code","0b9a779e":"code","17c9644c":"code","01badcdc":"code","3475e170":"code","cb888bfd":"code","70d55e5d":"code","4725ed41":"code","6e6d2b07":"code","f93ed96e":"code","5384c235":"code","48da08da":"code","2a6b366d":"code","06a57f10":"code","3b8a1493":"code","81ffd46e":"code","99a829d3":"code","71dcb418":"code","6d239e10":"code","a57d0259":"code","23c0abd5":"code","a5738e51":"code","6696b2b7":"code","dbc45caa":"code","63e246c0":"code","ba2b20e1":"code","ef3dce94":"code","8f919e33":"code","ccfd8fcc":"code","905382c3":"code","a876e8a7":"code","24e95734":"code","fb2d659e":"code","8f7de0a9":"code","ce3a7dc3":"code","5adfd5f9":"code","cfb67236":"code","6e28abc8":"code","10004d5a":"code","5e785566":"code","0042320d":"code","40a184e4":"code","c876d69d":"code","bdd3106b":"code","bd32c18b":"code","fe837e50":"code","9ff6f8e0":"code","f82fc5aa":"code","fb7c4ba4":"code","1463fa8c":"code","24a25b05":"code","8f818429":"code","e2f2a0cf":"code","56ad95fd":"code","6ae8dfad":"code","fbae7210":"code","326abaa2":"code","ef9e290c":"code","6cbbace2":"code","1111d88a":"code","3ae0d5c1":"code","235d13ce":"code","3031aecf":"code","29bdebdc":"code","927f907d":"code","4e523d8c":"code","0092f15b":"code","5e715470":"code","0ed328bd":"code","b8e17e27":"code","09386c26":"code","3123cac9":"code","3f13a038":"code","c5101de2":"code","c201bc83":"code","154670b8":"code","1885c167":"code","22e4e651":"code","2a90859d":"code","3b298ef7":"code","892c5412":"code","a8f9bd2a":"code","cb11bff1":"code","0dfc7360":"code","e4c8ed6d":"code","0676bb3f":"code","0f25ef1d":"code","0a748fe3":"code","10fc8ff1":"code","ff5a802c":"code","8114b208":"code","471a54b7":"code","7cce98e7":"code","1a9f7f11":"code","74f6a8c5":"code","d20cba15":"code","cb413bbb":"code","95f6bb1e":"code","ebc73a75":"code","77ffe1e5":"code","60169cda":"code","f58aecee":"code","6a73c5f5":"code","b747e486":"code","cd58ab6f":"code","ed4009c9":"code","f9231e95":"code","74d1ad84":"code","827a6c7d":"code","048459f3":"markdown","60322851":"markdown","7a5a908a":"markdown","a8801b09":"markdown","8455c364":"markdown","a6b6c271":"markdown","d1b2ada4":"markdown","3599bf1d":"markdown","4b4440b4":"markdown","5512b0ff":"markdown","3fa748be":"markdown","9e716a43":"markdown","87ce3a36":"markdown","ef784979":"markdown","4d6a9385":"markdown","b0f99333":"markdown","edda745a":"markdown","d772d926":"markdown","ef284bb6":"markdown","b75a9de4":"markdown","5e22a4e2":"markdown","f71fe04c":"markdown","a7918e49":"markdown","09957800":"markdown","8c07fee1":"markdown","5a610c8f":"markdown","05ac9eb8":"markdown","be7b38ba":"markdown","a8a4089f":"markdown"},"source":{"2afaafa2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ac1c947e":"data1=pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/train.csv\")","261f8e5f":"data1.head()","213003da":"data1.info()","9cb7b13e":"data1.isnull().sum()","e3692a7e":"data1.isnull().mean()","713ad028":"data1.describe()","063a40eb":"data1.describe(include='O')","efe2961f":"data1.shape","0379e409":"data1['Response'].value_counts()","f03a208f":"sns.countplot('Gender',data=data1,hue='Response')\nplt.plot()","d8c5a663":"data1.groupby(['Gender'])['Response'].value_counts(normalize=True)*100","30b5d27d":"sns.distplot(data1['Age'])\nplt.plot()","207b5680":"data1['Age'].describe()","5451c8ce":"def brac(x):\n    if (x>=20) & (x<31):\n        return '20-30'\n    if(x>=31) & (x<41):\n        return '31-40'\n    if(x>=41) & (x<51):\n        return '41-50'\n    if(x>=51) & (x<61):\n        return '51-60'\n    if(x>=61) & (x<71):\n        return '61-70'\n    if(x>=71) & (x<81):\n        return '71-80'\n    if(x>=81) & (x<91):\n        return '81-90'\n        ","4504e5a0":"data1['AgeBracket']=data1['Age'].apply(brac)","ef13bf08":"data1[['Age','AgeBracket']]","5ee0277a":"sns.countplot('AgeBracket',data=data1,hue='Response')\nplt.plot()","c24c5afb":"t1=pd.DataFrame(data1.groupby(['AgeBracket'])['Response'].value_counts(normalize=True)*100)","63d16783":"t1","32b88356":"pd.DataFrame(data1.groupby(['Driving_License'])['Response'].value_counts(normalize=True))","87d3e001":"pd.DataFrame(data1.groupby(['Previously_Insured'])['Response'].value_counts(normalize=True))","7a725a3e":"data1['Vehicle_Age'].unique()","6ad1945d":"pd.DataFrame(data1.groupby(['Vehicle_Age'])['Response'].value_counts(normalize=True))","268c7b53":"data1['Vehicle_Damage'].unique()","ea64584f":"pd.DataFrame(data1.groupby(['Vehicle_Damage'])['Response'].value_counts(normalize=True))","b631f143":"data1['Annual_Premium'].unique()","3b741c4a":"t3=pd.DataFrame(data1.groupby(['Annual_Premium'])['Response'].value_counts(normalize=True))","a12b4eec":"t3","4091f23f":"data1['Annual_Premium'].describe()","9b2a7d99":"data3=data1.copy()","aa2657e4":"sns.distplot(data1['Annual_Premium'])\nsns.relplot('Response','Annual_Premium',data=data1)","3f7b6b58":"data1['quantile_5']=pd.qcut(data1['Annual_Premium'], q=5)","f8b2f958":"pd.DataFrame(data1.groupby(['quantile_5'])['Response'].value_counts(normalize=True)*100)","0438a0ea":"pp=pd.DataFrame(data1.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100)","d3c38850":"pp","5679ec2c":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","c5aadf19":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(data3, variable, tolerance)\n\n    # re-group rare labels\n    data3[variable] = np.where(data3[variable].isin(\n        frequent_cat), data3[variable], 'Rare')\n\n    return data3","d62024d8":"for variable in ['Policy_Sales_Channel']:\n    \n     data3= rare_encoding(data3, variable, 0.01)","e2b01c73":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","865d24a5":"pd.DataFrame(data3.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100)","e42e032e":"data1['Vintage'].plot(kind='hist')","e2be1c3d":"data1['Vin_q']=pd.cut(data1['Vintage'], bins=10)","39cd79d5":"pd.DataFrame(data1.groupby(['Vin_q'])['Response'].value_counts(normalize=True)*100)","7b1acce0":"sns.distplot(data1['Vintage'])\nsns.relplot('Response','Vintage',data=data1)","9268e002":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.05, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","7fef83dd":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","b4de9035":"find_non_rare_labels(data3, 'Region_Code', 0.02)","05b6c2a1":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(data3, variable, tolerance)\n\n    # re-group rare labels\n    data3[variable] = np.where(data3[variable].isin(\n        frequent_cat), data3[variable], 'Rare')\n\n    return data3","ff1b514c":"for variable in ['Region_Code']:\n    \n     data3= rare_encoding(data3, variable, 0.01)","cf635abd":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","a7cedb57":"pd.DataFrame(data3.groupby(['Region_Code'])['Response'].value_counts(normalize=True)*100)","a6327c0d":"data_contact=data3[(data3['Driving_License']==1) & \n      (data3['Previously_Insured']==0) &\n     (data3['Vehicle_Age']=='> 2 Years') & (data3['Vehicle_Damage']=='Yes') & \n      ((data3['AgeBracket']=='31-40') | (data3['AgeBracket']=='41-50') | (data3['AgeBracket']=='51-60')) & \n                  ((data3['Region_Code']=='11.0') | (data3['Region_Code']=='18.0') |\n                  (data3['Region_Code']=='20.0') | (data3['Region_Code']=='29.0') |\n                  (data3['Region_Code']=='3.0') | (data3['Region_Code']=='25.0') |\n                  (data3['Region_Code']=='39.0') | (data3['Region_Code']=='41.0')) & \n                  ((data3['Policy_Sales_Channel']=='154.0') | (data3['Policy_Sales_Channel']=='156.0') |\n                  (data3['Policy_Sales_Channel']=='157.0'))]","ece489e1":"data_contact.head()","2a9d2404":"data_contact.shape","9ef49409":"cor1=data1.corr()","206409ed":"plt.figure(figsize = (16,10))\nsns.heatmap(cor1,linewidths=1,annot=True)\nplt.plot()","8b1840c0":"data2=data1.copy()","685947d1":"data2.drop(['AgeBracket','quantile_5','Vin_q'],axis=1,inplace=True)","f23393c4":"data2.shape","3fd8b63e":"data_test=pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv\")","1e4b1faf":"data_test.shape","210e78cd":"#data_test.drop(['Annual_Premium','Vintage'],axis=1,inplace=True)","ffac77fd":"new=pd.concat([data2,data_test],axis=0)","a6710e71":"new['Vintage']=new['Vintage']\/365","5480983f":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(new[col].value_counts() \/ len(new) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.05, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","1e986dea":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","7a4c5e88":"find_non_rare_labels(new, 'Region_Code', 0.02)","ad17e3c8":"[x for x in new['Region_Code'].unique(\n) if x not in find_non_rare_labels(new, 'Region_Code', 0.02)]","e9229a9e":"new1=new.copy()","a63ad58e":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(new1, variable, tolerance)\n\n    # re-group rare labels\n    new1[variable] = np.where(new1[variable].isin(\n        frequent_cat), new1[variable], 'Rare')\n\n    return new1","94ed75c0":"for variable in ['Region_Code']:\n    \n     new1= rare_encoding(new1, variable, 0.01)","ebcf2563":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(new1[col].value_counts() \/ len(new1) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","a85eea62":"g1=pd.DataFrame((new1.groupby(['Region_Code'])['Response'].value_counts(normalize=True)*100).sort_values(ascending=False))","a6a90907":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(new[col].value_counts() \/ len(new) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","0b9a779e":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","17c9644c":"find_non_rare_labels(new1, 'Policy_Sales_Channel', 0.01)","01badcdc":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(new1, variable, tolerance)\n\n    # re-group rare labels\n    new1[variable] = np.where(new1[variable].isin(\n        frequent_cat), new1[variable], 'Rare')\n\n    return new1","3475e170":"for variable in ['Policy_Sales_Channel']:\n    \n     new1= rare_encoding(new1, variable, 0.01)","cb888bfd":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(new1[col].value_counts() \/ len(new1) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","70d55e5d":"pc=pd.DataFrame((new1.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100).sort_values(ascending=False))","4725ed41":"pc","6e6d2b07":"new1.dtypes","f93ed96e":"#from feature_engine.categorical_encoders import CountFrequencyCategoricalEncoder","5384c235":"#dl=dict(new['Driving_License'].value_counts())","48da08da":"#new['Driving_License']=new['Driving_License'].replace(dl)","2a6b366d":"#a=dict(new['Region_Code'].value_counts())","06a57f10":"#new['Region_Code']=new['Region_Code'].replace(a)","3b8a1493":"new1['Vehicle_Age']=new1['Vehicle_Age'].replace({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})","81ffd46e":"new1['Vehicle_Damage']=new1['Vehicle_Damage'].replace({'Yes':1,'No':0})","99a829d3":"new1['Gender']=new1['Gender'].replace({'Male':1,'Female':0})","71dcb418":"new1.head()","6d239e10":"!pip install feature-engine\nfrom feature_engine.categorical_encoders import OneHotCategoricalEncoder","a57d0259":"#new.columns","23c0abd5":"new1.dtypes","a5738e51":"new1['Region_Code'].unique()","6696b2b7":"#new1['Region_Code']=new1['Region_Code'].replace({'Rare':0})","dbc45caa":"\n#new1=new1.astype({'Region_Code':float})","63e246c0":"new1.describe()","ba2b20e1":"import scipy.stats as stats","ef3dce94":"# function to create histogram, Q-Q plot and\n# boxplot. We learned this in section 3 of the course\n\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n\n    # define figure size\n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.distplot(df[variable], bins=30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('Variable quantiles')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n\n    plt.show()","8f919e33":"diagnostic_plots(new, 'Age')","ccfd8fcc":"diagnostic_plots(new, 'Annual_Premium')","905382c3":"diagnostic_plots(new, 'Vintage')","a876e8a7":"def find_skewed_boundaries(df, variable, distance):\n\n    # Let's calculate the boundaries outside which sit the outliers\n    # for skewed distributions\n\n    # distance passed as an argument, gives us the option to\n    # estimate 1.5 times or 3 times the IQR to calculate\n    # the boundaries.\n\n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n    return upper_boundary, lower_boundary","24e95734":"ap_upper_limit, ap_lower_limit = find_skewed_boundaries(new, 'Annual_Premium', 1.5)\nap_upper_limit, ap_lower_limit","fb2d659e":"# Now let's replace the outliers by the maximum and minimum limit\n\nnew['Annual_Premium']= np.where(new['Annual_Premium'] > ap_upper_limit, ap_upper_limit,\n                       np.where(new['Annual_Premium'] < ap_lower_limit, ap_lower_limit, new['Annual_Premium']))","8f7de0a9":"diagnostic_plots(new, 'Annual_Premium')","ce3a7dc3":"new['Annual_Premium'].describe()","5adfd5f9":"ohe_enc = OneHotCategoricalEncoder(\n    top_categories=None, # we can select which variables to encode\n    drop_last=True) # to return k-1, false to return k\n\n\nohe_enc.fit(new1)","cfb67236":"tmp = ohe_enc.transform(new1)\n\ntmp.head()","6e28abc8":"#tmp.drop('Driving_License',axis=1,inplace=True)","10004d5a":"tmp.drop('id',axis=1,inplace=True)","5e785566":"Train=tmp.iloc[0:381109]","0042320d":"Test=tmp.iloc[381109:]","40a184e4":"X=Train.drop('Response',axis=1)","c876d69d":"Y=Train['Response']","bdd3106b":"from imblearn.over_sampling import RandomOverSampler","bd32c18b":"os =  RandomOverSampler(0.70)","fe837e50":"X_train_res, y_train_res = os.fit_sample(X, Y)","9ff6f8e0":"X_train_res.shape,y_train_res.shape","f82fc5aa":"from collections import Counter\nprint('Original dataset shape {}'.format(Counter(Y)))\nprint('Resampled dataset shape {}'.format(Counter(y_train_res)))","fb7c4ba4":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","1463fa8c":"ordered_rank_features=SelectKBest(score_func=chi2,k=5)\nordered_feature=ordered_rank_features.fit(X_train_res,y_train_res)","24a25b05":"\ndfscores=pd.DataFrame(ordered_feature.scores_,columns=[\"Score\"])\ndfcolumns=pd.DataFrame(X.columns)\n\n","8f818429":"features_rank=pd.concat([dfcolumns,dfscores],axis=1)","e2f2a0cf":"features_rank.columns=['Features','Score']\n","56ad95fd":"X_train_res.shape","6ae8dfad":"features_rank.nlargest(15,'Score')","fbae7210":"from sklearn.model_selection import train_test_split","326abaa2":"X_train, X_test, Y_train, Y_test = train_test_split(X_train_res,\n                                                    y_train_res,\n                                                    test_size=0.3,\n                                                    random_state=0)\n\nX_train.shape, X_test.shape","ef9e290c":"Test.drop('Response',axis=1,inplace=True)","6cbbace2":"from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, roc_auc_score","1111d88a":"test1=pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv\")","3ae0d5c1":"id1=test1['id']","235d13ce":"from lightgbm import LGBMClassifier\nlgbcl = LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=10,learning_rate=0.04,objective='binary',metric='auc',\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)\nlgbcl= lgbcl.fit(X_train, Y_train,eval_metric='auc',verbose=2)\ny_lgb = lgbcl.predict(X_test)\nprobs_tr = lgbcl.predict_proba(X_train)[:, 1]\nprobs_te = lgbcl.predict_proba(X_test)[:, 1]\nprint(roc_auc_score(Y_train, probs_tr))\nprint(roc_auc_score(Y_test, probs_te))","3031aecf":"lgbcl1=lgbcl.fit(X_train_res,y_train_res)","29bdebdc":"lgbcl1","927f907d":"lgb_pred= lgbcl1.predict_proba(Test)[:, 1]","4e523d8c":"lgb_pred","0092f15b":"lgb=pd.concat([pd.DataFrame(id1),pd.DataFrame(lgb_pred)],axis=1)","5e715470":"lgb2=lgb.copy()","0ed328bd":"lgb2.rename(columns={0:'Response'},inplace=True)","b8e17e27":"lgb2.to_csv('lgb_onehot+label.csv',index=False)","09386c26":"te=lgbcl.predict(X_test)","3123cac9":"tr=lgbcl.predict(X_train)","3f13a038":"from sklearn.metrics import confusion_matrix\ntrc=confusion_matrix(Y_train,tr)","c5101de2":"\ntec=confusion_matrix(Y_test,te)","c201bc83":"recall_train=((trc[0][0])\/(trc[0][0]+trc[1][0]))*100","154670b8":"recall_train","1885c167":"recall_test=((tec[0][0])\/(tec[0][0]+tec[1][0]))*100","22e4e651":"recall_test","2a90859d":"precision_train=((trc[0][0])\/(trc[0][0]+trc[0][1]))*100","3b298ef7":"precision_train","892c5412":"precision_test=((tec[0][0])\/(tec[0][0]+trc[0][1]))*100","a8f9bd2a":"precision_test","cb11bff1":"from sklearn.ensemble import RandomForestClassifier","0dfc7360":"rf1=RandomForestClassifier()","e4c8ed6d":"cross_val_score(rf1,X_train_res,y_train_res,cv=5,scoring='accuracy')","0676bb3f":"rf1.fit(X_train,Y_train)","0f25ef1d":"probs_tr_rf = rf1.predict_proba(X_train)[:, 1]\nprobs_te_rf = rf1.predict_proba(X_test)[:, 1]\nprint(roc_auc_score(Y_train, probs_tr_rf))\nprint(roc_auc_score(Y_test, probs_te_rf))","0a748fe3":"te=rf1.predict(X_test)","10fc8ff1":"tr=rf1.predict(X_train)\n","ff5a802c":"from sklearn.metrics import confusion_matrix\ntrc=confusion_matrix(Y_train,tr)","8114b208":"\ntec=confusion_matrix(Y_test,te)","471a54b7":"recall_train=((trc[0][0])\/(trc[0][0]+trc[1][0]))*100","7cce98e7":"recall_train","1a9f7f11":"recall_test=((tec[0][0])\/(tec[0][0]+tec[1][0]))*100","74f6a8c5":"recall_test","d20cba15":"precision_train=((trc[0][0])\/(trc[0][0]+trc[0][1]))*100","cb413bbb":"precision_train","95f6bb1e":"precision_test=((tec[0][0])\/(tec[0][0]+trc[0][1]))*100","ebc73a75":"precision_test","77ffe1e5":"F1_train = 2 * (precision_train * recall_train) \/ (precision_train + recall_train)","60169cda":"F1_train","f58aecee":"F1_test = 2 * (precision_test * recall_test) \/ (precision_test + recall_test)","6a73c5f5":"F1_test","b747e486":"rf_t=rf1.predict_proba(Test)","cd58ab6f":"rf_t","ed4009c9":"rf123=pd.concat([pd.DataFrame(id1),pd.DataFrame(rf_t)],axis=1)","f9231e95":"rf_done=rf123.drop(0,axis=1)","74d1ad84":"rf_done.rename(columns={1:'Response'},inplace=True)","827a6c7d":"rf_done.to_csv('AR_check.csv',index=False)","048459f3":"**PTRVIOUSLY INSURED**","60322851":"**GENDER**","7a5a908a":"**REGION CODE**","a8801b09":"UNIVIRATE ANALYSIS","8455c364":"**Customer list that has to be contatced first**","a6b6c271":"***People who have damaged the vehicle should be contacted first***","d1b2ada4":"**VINTAGE**","3599bf1d":"***SO age bracket of 31-40 and 41-50 and even 51-60 are the ones of who should be contacted first\nfor vehicle insurance premium***","4b4440b4":"***CLEAR CASE OF IMBALANCE PROBLEM***","5512b0ff":"**PleaseLeave a like asit motivates me, thank you :)**","3fa748be":"*** >2 years and 1-2 years should be contacted first***","9e716a43":"***SO from 381109 customers we have boiled down the list to 106,\nthe sales department can use this list and contact them first***","87ce3a36":"**Here we have to take care of Recall more than Precision\nBy taking care of Recall, We say that we want to increase Our True positives and reduce False neagtive\nWe dont want to miss out customers who have actually responed 1**\n\n**We also want to take care of type 1 error\nthat is we dont want to classify who has response as 0 to response of 1\nit may increase our cost on business side, as calling may increase**\n\n**but recall has higher importance here**","ef784979":"***Annual premium is health premium taken by the customer\nlets find out in what range of annual premium does customer go for vehicle insurance***","4d6a9385":"***We can contact all customers in case of annual premium***","b0f99333":"**VEHICLE AGE**","edda745a":"***People who are not previously insured should be contacted first***","d772d926":"***people with drivig liscence should be contacted first to pitch the insurance***","ef284bb6":"**POLICY SALES CAHNNEL**","b75a9de4":"EDA:\n    1) VISUALIZE","5e22a4e2":"***In vintage also we can include all***","f71fe04c":"***For policy sales channel BY TAKING greater than 20% chance we should contact customers which are contacted through\n154,156,157 sales channel***","a7918e49":"**AGE**","09957800":"**ANNUAL PREMIUM**","8c07fee1":"**DRIVING LICENSE**","5a610c8f":"**VEHICLE DAMAGE**","05ac9eb8":"***for region code we can use greater than 10% chance\nregion 11,18,20,29,3,25,39,41***","be7b38ba":"**OUTLIER Treatment**","a8a4089f":"**ENCODING RARE LABELS IN POLICY SALES CHANNEL**"}}