{"cell_type":{"2550a6b7":"code","5dd16f77":"code","5ae4222e":"code","590c37c3":"code","b842a544":"code","83cd5e9b":"code","9a84346f":"code","5e70184f":"code","b1e2dc52":"code","76f75a93":"code","c640ccf2":"code","b583e1fb":"code","3fd0f863":"code","2f380aeb":"code","fb812833":"code","dd74ae79":"code","2e5acb17":"code","0cb15014":"code","1b1e8bcd":"code","3ef3089d":"code","b76a0004":"code","cdc33227":"code","818c2ebb":"code","a3055fc3":"code","15ce6507":"code","9514e88e":"code","aeacb3bd":"code","dda128f4":"code","1d0bbecc":"code","5dfac851":"code","7f5fad43":"code","ef0ee13f":"code","523ac35e":"code","9ffebc01":"code","e39a0602":"code","afad6377":"code","74da2459":"code","f72bf4aa":"code","c6e2a8ca":"code","d01f576f":"code","42f51e50":"code","0ba8d901":"code","b529a990":"code","e84fa744":"code","09cd2bf3":"code","8ac4460a":"code","fef750ec":"code","0bbf0bef":"code","16dd1b15":"code","293734db":"code","e5a03fe7":"markdown","8f411daa":"markdown","f58e1a8d":"markdown","cd40e33c":"markdown","f71fb38f":"markdown","83d1d42e":"markdown","3d96a283":"markdown","99cfc3e7":"markdown","bd632f8a":"markdown","12a8a9e8":"markdown","ea46f61c":"markdown","928bf497":"markdown","436b7617":"markdown","e07a500e":"markdown","e92ea268":"markdown","85ca993a":"markdown","b9b92008":"markdown","18749ca6":"markdown","b9aa490f":"markdown","ba24fe8f":"markdown","d66e0a0a":"markdown","f03599bc":"markdown","24e1f41e":"markdown","f1c7bc17":"markdown","78e5c125":"markdown","d66c8428":"markdown","964a8bb8":"markdown","c8189131":"markdown","abfc9aef":"markdown","7aab7f37":"markdown","e4d53168":"markdown","db60806a":"markdown","d3d2f293":"markdown","5bfdb600":"markdown","5164de8c":"markdown","f58aa921":"markdown","6f708bff":"markdown","b196ba37":"markdown","ca164e48":"markdown","a7da7f28":"markdown","18ea6999":"markdown","6ba1f7b6":"markdown","fdbfab10":"markdown","e9ac3370":"markdown","a9ed8b44":"markdown","262d5972":"markdown","6b66d091":"markdown","040f9efc":"markdown","47188d87":"markdown"},"source":{"2550a6b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5dd16f77":"data=pd.read_csv(\"\/kaggle\/input\/income-dataset-itu-project\/income_dataset_ITU_project.csv\")","5ae4222e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.model_selection import cross_val_score,KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n","590c37c3":"data.shape","b842a544":"data.columns","83cd5e9b":"data.columns=['age', 'workclass', 'education', 'education_num', 'marital_status',\n       'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n       'capital_loss', 'hours_per_week', 'native_country', 'income']\ndata.columns","9a84346f":"data=pd.DataFrame(data)\ndata.head(20)","5e70184f":"data.describe()","b1e2dc52":"data.isnull().sum().sum()","76f75a93":"data.isnull().sum()","c640ccf2":"data[\"native_country\"]=data[\"native_country\"].fillna(\"Unknown\")","b583e1fb":"data[\"workclass\"]=data[\"workclass\"].fillna(\"Unknown\")","3fd0f863":"data[\"occupation\"]=data[\"occupation\"].fillna(\"Unknown\")","2f380aeb":"data.corr()","fb812833":"f,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(data.corr(),annot=True,linewidth=.5,fmt='.2f',ax=ax)\ndata.corr()\nplt.show()","dd74ae79":"f,ax=plt.subplots(figsize=(20,20))\nsns.countplot(data['occupation'],label=\"Toplam\")\nplt.show()","2e5acb17":"f,ax=plt.subplots(figsize=(20,20))\nsns.countplot(data['education'],label=\"Toplam\")\nplt.show()","0cb15014":"f,ax=plt.subplots(figsize=(20,20))\ng = sns.barplot(x=\"education\",y=\"income\",data=data)\ng = g.set_ylabel(\"50K$\")\nplt.show()","1b1e8bcd":"sns.countplot(data['income'],label=\"Count\")\nplt.show()","3ef3089d":"g = sns.barplot(x=\"sex\",y=\"income\",data=data)\ng = g.set_ylabel(\"50K$\")\nplt.show()","b76a0004":"data_edu=data[\"education\"]\ndata_edu.unique()","cdc33227":"data_country=data[\"native_country\"]\ndata_country.unique()","818c2ebb":"data_marital=data[\"marital_status\"]\ndata_marital.unique()","a3055fc3":"data_sex=data[\"sex\"]\ndata_sex.unique()","15ce6507":"data_work=data[\"workclass\"]\ndata_work.unique()","9514e88e":"data_occupation=data[\"occupation\"]\ndata_occupation.unique()","aeacb3bd":"data_race=data[\"race\"]\ndata_race.unique()","dda128f4":"data[\"sex\"] = data[\"sex\"].map({\"Male\": 0, \"Female\":1})","1d0bbecc":"data[\"marital_status\"] = data[\"marital_status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\ndata[\"marital_status\"] = data[\"marital_status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\ndata[\"marital_status\"] = data[\"marital_status\"].map({\"Married\":1, \"Single\":0})\ndata[\"marital_status\"] = data[\"marital_status\"].astype(int)","5dfac851":"data[\"education\"] = data[\"education\"].replace([\"Bachelors\",\"Masters\",\"Doctorate\",\"Prof-school\"],\"HighEdu\")\ndata[\"education\"] = data[\"education\"].replace([\"Preschool\",\"1st-4th\",\"5th-6th\",\"7th-8th\",\"9th\",\"10th\",\"11th\",\"12th\",\"HS-grad\", \n                    \"Assoc-acdm\",\"Assoc-voc\",\"Some-college\"],\"LowEdu\")\ndata[\"education\"] = data[\"education\"].map({\"HighEdu\":1, \"LowEdu\":0})\ndata[\"education\"] = data[\"education\"].astype(int)\n","7f5fad43":"data[\"race\"] = data[\"race\"].replace(['White'],\"WhiteRace\")\ndata[\"race\"] = data[\"race\"].replace(['Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo','Other'],\"OtherRace\")\ndata[\"race\"] = data[\"race\"].map({\"WhiteRace\":1, \"OtherRace\":0})\ndata[\"race\"] = data[\"race\"].astype(int)","ef0ee13f":"data[\"native_country\"] = data[\"native_country\"].replace(['United-States','England','Canada','Germany', 'France', 'Italy',\n                        'China', 'Japan', 'Scotland', 'Ireland','Holand-Netherlands'],\"HighPriceCountry\")\n\ndata[\"native_country\"] = data[\"native_country\"].replace(['Cuba', 'Jamaica', 'India', 'Unknown', 'Mexico',\n                        'South', 'Puerto-Rico', 'Honduras','Iran', 'Philippines', 'Poland','Columbia', 'Cambodia',\n                        'Thailand', 'Ecuador', 'Laos', 'Taiwan', 'Haiti', 'Portugal','Yugoslavia', 'Peru',\n                        'Outlying-US(Guam-USVI-etc)', 'Trinadad&Tobago','Greece', 'Nicaragua', 'Vietnam', 'Hong',\n                        'Hungary','Dominican-Republic', 'El-Salvador', 'Guatemala' ],\"LowPriceCountry\")\ndata[\"native_country\"] = data[\"native_country\"].map({\"HighPriceCountry\":1, \"LowPriceCountry\":0})\ndata[\"native_country\"] = data[\"native_country\"].astype(int)","523ac35e":"data.head(20)","9ffebc01":"data.drop(labels=[\"workclass\",\"occupation\",\"relationship\"], axis = 1, inplace = True)\ndata.head(20)","e39a0602":"f,ax=plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot=True,linewidth=.5,fmt='.2f',ax=ax)\ndata.corr()\nplt.show()","afad6377":"data","74da2459":"X= data.iloc[:,:10]\ny=data.iloc[:,10]\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,shuffle=True)","f72bf4aa":"param_grid = {'n_neighbors':[4,5,6,7],'leaf_size':[1,3,5],'algorithm':['auto', 'kd_tree'],'n_jobs':[-1]}\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5)\ngrid.fit(X, y)\ngrid.best_params_","c6e2a8ca":"knn = KNeighborsClassifier(algorithm=\"auto\",leaf_size=1,n_jobs=-1,n_neighbors=6)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nknn.score(X_test,y_test)","d01f576f":"\nclf =KNeighborsClassifier(algorithm=\"auto\",leaf_size=1,n_jobs=-1,n_neighbors=6)\nprint(cross_val_score(clf, X, y, cv=10, n_jobs=1))","42f51e50":"param_grid = {'penalty':['l1', 'l2', 'elasticnet'], 'C':[0.001, 0.01, 0.1, 1, 10, 100],\n             'solver':['lbfgs', 'liblinear'], 'l1_ratio':[0.001, 0.01, 0.1]}\n\ngrid = GridSearchCV(LogisticRegression(), param_grid=param_grid, verbose=3)\n\ngrid.fit(X, y)\ngrid.best_params_","0ba8d901":"logmodel = LogisticRegression(C= 0.01, l1_ratio= 0.1, penalty= 'l1', solver= 'liblinear',max_iter=1000)\nlogmodel.fit(X_train,y_train)\ny_pred = logmodel.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nlogmodel.score(X_test,y_test)","b529a990":"clf =LogisticRegression(C= 0.01, l1_ratio= 0.1, penalty= 'l1', solver= 'liblinear',max_iter=1000)\nprint(cross_val_score(clf, X, y, cv=10, n_jobs=1))","e84fa744":"param_grid = {'criterion':['gini', 'entropy'], 'max_depth':[5,10,15,20], 'n_estimators':[500,600,700,800,900,1000]}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, verbose=3)\n\ngrid.fit(X, y)\ngrid.best_params_","09cd2bf3":"randomforest = RandomForestClassifier(max_depth=15,random_state=42,criterion=\"entropy\",n_estimators=900)\nrandomforest.fit(X_train, y_train)\ny_pred = randomforest.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nrandomforest.score(X_test,y_test)","8ac4460a":"clf =RandomForestClassifier(max_depth=15,random_state=42,criterion=\"entropy\",n_estimators=900)\nprint(cross_val_score(clf, X, y, cv=10, n_jobs=1))","fef750ec":"\nparam_grid = {'max_depth':[2, 4, 5, 7, 9, 10], 'learning_rate':[0.001, 0.01, 0.1, 0.2, 0.3], 'min_child_weight':[2, 4, 5, 6, 7]}\n\ngrid = GridSearchCV(XGBClassifier(), param_grid=param_grid, verbose=3)\n\ngrid.fit(X, y)\ngrid.best_params_","0bbf0bef":"xgb = XGBClassifier(learning_rate=0.3, max_depth=5, min_child_weight=2)\nxgb.fit(X_train,y_train)\ny_pred=xgb.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nxgb.score(X_test,y_test)","16dd1b15":"clf = XGBClassifier(learning_rate=0.3, max_depth=5, min_child_weight=2)\nprint(cross_val_score(clf, X, y, cv=10, n_jobs=1))","293734db":"print(\"KNN Model Score                  = \",knn.score(X_test,y_test))\nprint(\"Logistic Regression Score        = \",logmodel.score(X_test,y_test))\nprint(\"Random Forest Classifier Score   = \",randomforest.score(X_test,y_test))\nprint(\"XGBoost Forest Classifier Score  = \",xgb.score(X_test,y_test))","e5a03fe7":"a)KNN Classification","8f411daa":"Logistic Regression modeli i\u00e7in Cross Validation Score Hesaland\u0131 ve Accuracy ile kar\u015f\u0131la\u015f\u0131r\u0131ld\u0131.","f58e1a8d":"Ayn\u0131 mant\u0131kla datam\u0131zda bulunan e\u011fitim seviyeleri g\u00f6rsellenmi\u015ftir.En fazla 'HS-grad' e\u011fitim seviyesinde ki\u015fi buunmaktad\u0131r.","cd40e33c":"\"education\" kolonu HighEdu ve LowEdu olarak n\u00fcmerik formata d\u00f6nd\u00fcr\u00fclm\u00fc\u015ft\u00fcr.","f71fb38f":"\"martial_status\" kolonu Single ve Married olarak n\u00fcmerik formata d\u00f6nd\u00fcr\u00fclm\u00fc\u015ft\u00fcr.","83d1d42e":"Hangi kolonda ka\u00e7 tane bo\u015f datam\u0131z\u0131n oldu\u011fu \u00e7\u0131kart\u0131ld\u0131.","3d96a283":"Datada bulunan meslek gruplar\u0131ndan ki da\u011f\u0131l\u0131m\u0131 seaborn k\u00fct\u00fcphanesi ile g\u00f6rselle\u015ftirme.En fazla meslek grubu 'Prof-Specialty' grubunda oldu\u011fu g\u00f6zlemlenmi\u015ftir.","99cfc3e7":"\u00d6ncellikle kullan\u0131lan data da bo\u015f (null) olan kolonlardaki say\u0131lar\u0131n toplam\u0131 \u00e7\u0131kart\u0131ld\u0131","bd632f8a":"Datam\u0131zdaki kolonlar\u0131m\u0131z\u0131n birbirleri ile olan ili\u015fkilerini g\u00f6zlemek i\u00e7in korelasyonlar\u0131 \u00e7\u0131kart\u0131ld\u0131.","12a8a9e8":"Random Forest Classifier modellinde kullana\u0131lacak parametreleri belirlemek i\u00e7in GridSearchCV ile en iyi score'u \u00fcretecek parametreler bulunur.","ea46f61c":"'workclass','native_country','occupation' kolonlar\u0131nda bo\u015f data oldu\u011fu g\u00f6r\u00fcld\u00fc.Burada bulunan null datalar drop edilmesi model uygulamada hatal\u0131 sonu\u00e7lar verece\u011fi de\u011ferlendi\u011finden, 'Unknown' olarak dolduruldu. ","928bf497":"GridsearchCV ile bulunan en iyi parametreler KNN modeline parametre olarak uygulanr.S\u0131n\u0131fland\u0131rma raporlan\u0131r ve accuracy hesaplan\u0131r.","436b7617":"Datam\u0131zda bulunan n\u00fcmerik datalar\u0131n istatiski olarak g\u00f6sterimi (maksimum,minumum,ortalama,medyan vb.)","e07a500e":"\"native_country\" kolonu HighPriceCounty ve LowPriceCountry olarak n\u00fcmerik formata d\u00f6nd\u00fcr\u00fclm\u00fc\u015ft\u00fcr.","e92ea268":"b)Logistic Regression","85ca993a":"\"sex\" kolonu Male ve Female olarak n\u00fcmerik formata d\u00f6nd\u00fcr\u00fclm\u00fc\u015ft\u00fcr. ","b9b92008":"Datan\u0131n Kolonlar\u0131","18749ca6":"XGBoost Classifier modeli i\u00e7in Cross Validation Score Hesaland\u0131 ve Accuracy ile kar\u015f\u0131la\u015f\u0131r\u0131ld\u0131.","b9aa490f":"\"race\" kolonu WhiteRace ve OtherRace olarak n\u00fcmerik formata d\u00f6nd\u00fcr\u00fclm\u00fc\u015ft\u00fcr.","ba24fe8f":"KNN modellinde kullana\u0131lacak parametreleri belirlemek i\u00e7in GridSearchCV ile en iyi score'u \u00fcretecek parametreler bulunur.","d66e0a0a":"Projede kullan\u0131lan dataset UCI Machine Learning Repository (https:\/\/archive.ics.uci.edu\/ml\/datasets\/Adult)'den elde edilmi\u015ftir. Data Set 14 attributes halinde insanlar\u0131n demografik bilgilerinden olu\u015fmaktad\u0131r.\n\n-age : Ya\u015f\n\n-workclass : \u00c7al\u0131\u015fma \u015fekli.Attributes: Federal-gov, Local-gov, Never-worked, Private, Self-emp-inc, Self-emp-not-inc, State-gov, and Without-pay.\n\n-education : E\u011fitim seviyesi.S\u0131ralanm\u0131\u015f e\u011ftim seviyeri attibutes: Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate.\n\n-education_num : E\u011fitim seviyelerinin n\u00fcmerik formu\n\n-marital_status : Evlilik durumu. Evlilik durumu attributes: Divorced, Married-AF-spouse, Married-civ-spouse, Married-spouse-absent, Never-married, Separated, and Widowed.\n\n-occupation : \u0130\u015fi.\u0130\u015f attributes: Adm-clerical, Armed-Forces, Craft-repair, Exec-managerial, Farming-fishing, Handlers-cleaners, Machine-op-inspct, Other-service, Priv-house-serv, Prof-specialty, Protective-serv, Sales, Tech-support, and Transport-moving.\n\n-relationship : Aile durumu.Aile durumu attributes: Husband, Not-in-family, Other-relative, Own-child, Unmarried, and Wife.\n\n-race : Irk\u0131.Irk attributes: Amer-Indian-Eskimo, Asian-Pac-Islander, Black, Other, and White.\n\n-sex : Cinsiyeti.Cinsiyet attribute. The levels of the attributes: Female and Male.\n\n-capital_gain : De\u011fer art\u0131\u015f\u0131.\n\n-capital_loss : De\u011fer aza\u0131\u015f\u0131.\n\n-hours_per_week : Haftal\u0131k \u00e7al\u0131\u015fma saati.\n\n-native_country \u2013 Men\u015fei.Men\u015fei attributes: Cambodia, Canada, China, Columbia, Cuba, Dominican-Republic, Ecuador, El-Salvador, England, France, Germany, Greece, Guatemala, Haiti, Holand-Netherlands, Honduras, Hong, Hungary, India, Iran, Ireland, Italy, Jamaica, Japan, Laos, Mexico, Nicaragua, Outlying-US(Guam-USVI-etc), Peru, Philippines, Poland, Portugal, Puerto-Rico, Scotland, South, Taiwan, Thailand, Trinadad&Tobago, United-States, Vietnam,Yugoslavia.\n\n-income \u2013Y\u0131ldaki $50000 kazan\u0131m durum.Attributes: <=50K-0 ve >50K-1.\n","f03599bc":"Modellemede kullan\u0131lmayacak n\u00fcmerik formatta olmayan datalar\u0131n setten at\u0131lmas\u0131","24e1f41e":"Cinsiyetlere g\u00f6re y\u0131ll\u0131k 50K kazanma g\u00f6rselle\u015ftirmesi. ","f1c7bc17":"Bu a\u015famada data girdier ve \u00e7\u0131kt\u0131lar olarak ikiye b\u00f6l\u00fcnecek girdi olarak kullan\u0131lan verilerle \u00e7\u0131kt\u0131y\u0131 modeller kullan\u0131larak tahminlemeye \u00e7al\u0131\u015f\u0131lacakt\u0131r.\n","78e5c125":"Datan\u0131n Boyutu (32561 sat\u0131r ve 14 kolondan olu\u015fmaktad\u0131r)","d66c8428":"SONU\u00c7","964a8bb8":"GridsearchCV ile bulunan en iyi parametreler XGBoost Classifier modeline parametre olarak uygulanr.S\u0131n\u0131fland\u0131rma raporlan\u0131r ve accuracy hesaplan\u0131r.","c8189131":"Toplamda ki\u015filerin kazan\u00e7lar\u0131n\u0131n g\u00f6rselle\u015ftirilmesi.","abfc9aef":"MODELLEME","7aab7f37":"GridsearchCV ile bulunan en iyi parametreler Random Forest Classifier modeline parametre olarak uygulanr.S\u0131n\u0131fland\u0131rma raporlan\u0131r ve accuracy hesaplan\u0131r.","e4d53168":"Cross-validation ile makine \u00f6\u011frenmesi modelinin g\u00f6rmedi\u011fi veriler \u00fczerindeki performans\u0131n\u0131 \u00f6l\u00e7mek ama\u00e7l\u0131 kullan\u0131l\u0131r.Knn modeli i\u00e7in Cross Validation Score Hesaland\u0131 ve Accuracy ile kar\u015f\u0131la\u015f\u0131r\u0131ld\u0131.","db60806a":"Lojistic Regression modellinde kullana\u0131lacak parametreleri belirlemek i\u00e7in GridSearchCV ile en iyi score'u \u00fcretecek parametreler bulunur.","d3d2f293":"RandomForestClassifier modeli i\u00e7in Cross Validation Score Hesaland\u0131 ve Accuracy ile kar\u015f\u0131la\u015f\u0131r\u0131ld\u0131.","5bfdb600":"N\u00fcmerik olamayan \"education\",\"native_country\",\"marital_status\",\"sex\",\"workclass\",\"occupation\",\"race\" kolonlar\u0131nda kullan\u0131lan veriler g\u00f6zlenmi\u015ftir.","5164de8c":"Data girdiler ve \u00e7\u0131kt\u0131 olarak ayr\u0131l\u0131r.Girdiler ve \u00e7\u0131kt\u0131 olarak ayr\u0131lan datalar e\u011fitim ve test olarak belirlenir.Burada test edilecek datalar %20 olarak ayr\u0131lm\u0131\u015ft\u0131r.Modellemeden \u00f6nce yap\u0131lacak i\u015flem train ve test datas\u0131 boyutlar\u0131n\u0131 ayr\u0131\u015ft\u0131rmakt\u0131r.\n","f58aa921":"GridsearchCV ile bulunan en iyi parametreler Logistic Regression modeline parametre olarak uygulanr.S\u0131n\u0131fland\u0131rma raporlan\u0131r ve accuracy hesaplan\u0131r.","6f708bff":"c)Random Forest Classifier","b196ba37":"FEATURE ENG\u0130NEER\u0130NG","ca164e48":"Kullan\u0131lacak olan ve n\u00fcmerik formata d\u00f6n\u00fc\u015ft\u00fcr\u00fclen datan\u0131n korelasyon matrisi.","a7da7f28":"Pandas k\u00fct\u00fcphanesi ile DataFrame format\u0131na d\u00f6n\u00fc\u015ft\u00fcrme ve ilk 20 datay\u0131 okuma","18ea6999":"DATA SET","6ba1f7b6":"XGBoost Classifier modellinde kullan\u0131lacak parametreleri belirlemek i\u00e7in GridSearchCV ile en iyi score'u \u00fcretecek parametreler bulunur.","fdbfab10":"N\u00fcmerik Formata d\u00f6nd\u00fcr\u00fclen data.","e9ac3370":"DATA G\u00d6RSELLE\u015eT\u0130RME","a9ed8b44":"d)XGBoost Classifier","262d5972":"\n\nProje kapsam\u0131nda ilk olarak 'income' data seti incelendi data hakk\u0131nda bilgi edinildi.Setteki verilerle g\u00f6rselle\u015ftirmeler yap\u0131ld\u0131 n\u00fcmerik olmayan veriler n\u00fcmerik formata d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc.Dataya KNN,Logistic Regression,Random Forest ve XGBoost makine \u00f6\u011frenmesi modelleri uyguland\u0131.Modeller uygulanmadan \u00f6nce en iyi performans sa\u011flayaca\u011f\u0131 parametreler GridSearch algoritmas\u0131 ile \u00e7\u0131kart\u0131ld\u0131 ve bu parametrelerle \u00e7al\u0131\u015ft\u0131r\u0131ld\u0131 sonu\u00e7lar raporlandI akabinde Cross Validation Score'lar\u0131 ilede incelendi. Bu incelemeler sonucunda income kolonunda en fazla veri '0' yani <50K da oldu\u011fundan dolay\u0131 '0' lar\u0131 \u00f6\u011frenme ve dolay\u0131s\u0131yla tahminde '1' yani >50K'lardan daha iyi bir performans g\u00f6stermi\u015ftir. Uygulanan modellerde en y\u00fcskek ba\u015far\u0131m XGBoost modelinde g\u00f6zlemlenmi\u015ftir.\n","6b66d091":"Datan\u0131n Kolonlar\u0131nda i\u015flem kolayl\u0131\u011f\u0131 olmas\u0131 a\u00e7\u0131s\u0131ndan kolon isimleri de\u011fi\u015ftirilmesi","040f9efc":"E\u011fitim seviyesine g\u00f6re 50K y\u0131ll\u0131k kazan\u00e7 durumu g\u00f6rsellenmi\u015ftir. En fazla ki\u015fi 'HS-grad' olmas\u0131na ra\u011fmen dataya bak\u0131ld\u0131\u011f\u0131 zaman en fazla kazan\u00e7 'Doctorate' e\u011fitim seviyesindeki ki\u015filerde g\u00f6zlenmektedir.","47188d87":"Korelasyonu daha net g\u00f6rebilmek ad\u0131na seaborn k\u00fct\u00fcphanesi ile g\u00f6rselli\u011fi art\u0131r\u0131ld\u0131.Korelasyon incelendi\u011fnde 'education_num' ile 'income' aras\u0131nda en fazla pozitif bir korelasyon oldu\u011fu g\u00f6zlemlendi."}}