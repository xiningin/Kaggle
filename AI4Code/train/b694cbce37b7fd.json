{"cell_type":{"d60aa229":"code","cbdd0a6d":"code","c71f065a":"code","3e6e5f19":"code","d1dc0360":"code","9a576ddf":"code","18557a3e":"code","3751167b":"code","2ae37515":"code","86733983":"code","653048b7":"code","a4fe3eb2":"code","c458e180":"code","c8c0af51":"code","78ff7f1b":"code","a88db979":"code","14501ffc":"code","64aa8b1c":"code","0c026f7a":"code","f6cad99f":"markdown","6258c0b3":"markdown","bdf9e4f6":"markdown","c8a8002f":"markdown"},"source":{"d60aa229":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport datetime\n\nfrom bq_helper import BigQueryHelper\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import dates as md\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cbdd0a6d":"path_rawdata = '\/kaggle\/input\/cubems-smart-building-energy-and-iaq-data\/'","c71f065a":"list_csv = []\n\nfor file in os.listdir(path_rawdata):\n    if file.endswith(\".csv\"):\n        list_csv.append(os.path.join(path_rawdata, file))\n        \nlist_csv","3e6e5f19":"df_merged = pd.DataFrame({'Date': pd.date_range('2018-07-01', '2020-01-01', freq='min', closed='left')}).set_index('Date')\n\nfor path_csv in list_csv:\n    csv_file_name = path_csv.split('\/')[-1]\n    print(csv_file_name)\n    df_temp = pd.read_csv(path_csv)\n    df_temp = df_temp.set_index('Date')\n    df_temp = df_temp.dropna(how='all')\n    df_temp.index = pd.to_datetime(df_temp.index)\n\n\n    str_floor = pd.Series(csv_file_name).str.split('2018|2019|.csv',expand=True).replace('', np.nan).dropna(axis=1).iloc[0,0]\n    df_temp.columns = str_floor + '_' + df_temp.columns\n    \n    df_merged.loc[df_temp.index, df_temp.columns] = df_temp","d1dc0360":"df_merged.iloc[:, :5].resample('H').mean().iplot()","9a576ddf":"df_merged.sort_index(axis=0).sort_index(axis=1).to_pickle('df_merged.pickle.gz', compression='gzip')","18557a3e":"# Input parameters\nstation_name = 'BANGKOK METROPOLIS'\nyears = range(2018, 2020)","3751167b":"helper = BigQueryHelper('bigquery-public-data', 'noaa_gsod')\n\nsql = '''\nSELECT\n  year, mo, da, temp, min, max, prcp\nFROM\n    `bigquery-public-data.noaa_gsod.gsod{}` a\n    INNER JOIN `bigquery-public-data.noaa_gsod.stations` b ON a.stn = b.usaf\nWHERE\n  country = 'TH' AND name = '{}'\n'''\n\n# Query weather data for each year\ndatasets = [ helper.query_to_pandas(sql.format(i, station_name)) for i in years ]\n\n# print out each year's data shape\nprint('\\n'.join([ '{}: {}'.format(x[0],x[1].shape) for x in zip(years, datasets)]))","2ae37515":"# Concatenate datasets\nweather = pd.concat(datasets)\n\n# Handling missing values based on Table Schema description\nweather['temp'] = weather['temp'].replace({ 9999.9 : np.nan })\nweather['min'] = weather['min'].replace({ 9999.9 : np.nan })\nweather['max'] = weather['max'].replace({ 9999.9 : np.nan })\nweather['prcp'] = weather['prcp'].replace( { 99.99 : 0 })\n\nweather","86733983":"# Data processing\n\n# Setting date index\nweather['date'] = weather.apply(lambda x: \n                                datetime.datetime(int(x.year), int(x.mo), int(x.da)), \n                                axis=1)\nweather = weather.set_index('date')\n\n# Convert temperature values from farenheit to celcius\ndef f_to_c(temp_f):\n    temp_c = (temp_f - 32) * 5\/9\n    return round(temp_c, 2)\n\nfor col in ['temp','min','max']:\n    weather[col] = weather[col].apply(f_to_c)\n\n# Convert precipitation from inches to milimeters\ndef inch_to_mm(x):\n    return round(x * 25.4)\n\nweather['prcp'] = weather['prcp'].apply(inch_to_mm)","653048b7":"start_date = '{}0101'.format(years[0])\nend_date = weather.index.max().strftime('%Y%m%d')\n\n# Re-index to see if there are any days with missing data\nweather = weather.reindex(pd.date_range(start_date, end_date))\n\n# check if there is missing values occured from re-indexing\nmissing = weather[weather.isnull().any(axis=1)].index\n# printing missing index\nmissing","a4fe3eb2":"# Interpolate numerical variables for the missing days\nweather = weather.interpolate()\n\n# Re-setting year, month, day fields\nweather['year'] = weather.index.year\nweather['mo'] = weather.index.month\nweather['da'] = weather.index.day\n\n# Verify interpolated data\nweather.loc[missing].head(10)","c458e180":"data = weather[['temp','min','max','prcp']]\ndata.columns = ['Avg Temp', 'Min Temp', 'Max Temp', 'Precip']","c8c0af51":"data.iplot()","78ff7f1b":"data.to_pickle('df_weather.pickle.gz', compression='gzip')","a88db979":"df_holiday_2018 = pd.read_html('https:\/\/www.timeanddate.com\/holidays\/thailand\/2018')[0]\ndf_holiday_2018.columns = df_holiday_2018.columns.get_level_values(0)\ndf_holiday_2018 = df_holiday_2018.dropna(how='all')\ndf_holiday_2018 = df_holiday_2018[['Date', 'Name', 'Type']]\ndf_holiday_2018['Date'] = '2018 ' + df_holiday_2018['Date']\ndf_holiday_2018['Date'] = pd.to_datetime(df_holiday_2018['Date'])\n\ndf_holiday_2019 = pd.read_html('https:\/\/www.timeanddate.com\/holidays\/thailand\/2019')[0]\ndf_holiday_2019.columns = df_holiday_2019.columns.get_level_values(0)\ndf_holiday_2019 = df_holiday_2019.dropna(how='all')\ndf_holiday_2019 = df_holiday_2019[['Date', 'Name', 'Type']]\ndf_holiday_2019['Date'] = '2019 ' + df_holiday_2019['Date']\ndf_holiday_2019['Date'] = pd.to_datetime(df_holiday_2019['Date'])\n\ndf_holiday = pd.concat([df_holiday_2018, df_holiday_2019], axis=0, ignore_index=True)\ndf_holiday = df_holiday.drop_duplicates(subset=['Date'])\ndf_holiday = df_holiday.set_index('Date').asfreq('D')\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Name'] = 'weekend'\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Type'] = 'weekend'\ndf_holiday.columns = 'holiday_' + df_holiday.columns\n\ndf_holiday = df_holiday.reset_index()\ndf_holiday = df_holiday.rename(columns={'Date':'date'}) \n\ndf_holiday","14501ffc":"df_holiday_encode = df_holiday.copy()\ndf_holiday_encode[['holiday_Name', 'holiday_Type']] = df_holiday_encode[['holiday_Name', 'holiday_Type']].astype('str').apply(LabelEncoder().fit_transform)\ndf_holiday_encode","64aa8b1c":"df_holiday_encode.set_index('date')['holiday_Type'].iplot()","0c026f7a":"data.to_pickle('df_holiday.pickle.gz', compression='gzip')\ndata.to_pickle('df_holiday_encode.pickle.gz', compression='gzip')","f6cad99f":"# 2. Get daily weather data from NOAA","6258c0b3":"# 1. Merge and Compress raw data of CU-BEMS","bdf9e4f6":"# 3. Get holiday information","c8a8002f":"In this notebook, the main goal is to organize raw data and collect useful information from other sources:\n1. Raw data of CU-BEM is merged as one and compressed to save memory use.\n2. Obtain weather data from NOAA dataset on Kaggle (ref: https:\/\/www.kaggle.com\/tanatiem\/eda-bangkok-weather)\n3. Get holiday information from the website (https:\/\/www.timeanddate.com\/holidays\/)"}}