{"cell_type":{"85ce79b9":"code","35a87d82":"code","1d988b7f":"code","8aaff22c":"code","abd20bf5":"code","87aa1959":"code","d71825f1":"code","3ef9a84d":"code","c26af53a":"code","9858cc4e":"code","0ef234ef":"code","a5ed53df":"code","35edfb84":"code","c4260146":"code","a0a65155":"code","458dbe55":"code","2fabb3cd":"code","31dd5256":"code","685470dd":"code","0ef8f1b1":"code","0d078171":"code","19a19037":"code","43517a15":"markdown","5731f8cf":"markdown","34a41964":"markdown","d22e17df":"markdown","3256c135":"markdown","acea4970":"markdown","abf420b1":"markdown","160f7bd0":"markdown","e369bb5b":"markdown","242480a6":"markdown","19ddada6":"markdown","290f65ee":"markdown","d817853c":"markdown","4c5408bb":"markdown","81a35245":"markdown","637a1ce2":"markdown","8afa8c33":"markdown","068795f3":"markdown","722ad864":"markdown","2a13e05a":"markdown","439c8bd6":"markdown","ccea1247":"markdown","87854b2f":"markdown","8930ba9a":"markdown","f8b837ed":"markdown","f487413c":"markdown","c7708324":"markdown","81212f4f":"markdown"},"source":{"85ce79b9":"# pip command for the bs4 library (used for web scraping)\n!pip install bs4==0.0.1\n\nimport pandas as pd\nimport numpy as np\nimport requests\nfrom sklearn.preprocessing import StandardScaler\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport seaborn as sns","35a87d82":"#The website loads 20 deals per page to obtain a larger data set one can set a higher value of pages. Higher the page value longer the data fetching process.\nnumbers_of_pages =  20\n\n#The Url consists of specific cityId parameter for fetching the data, following a few example of popular cities of India.\n#To add more city one must get the relevant city code and add it as key-value pair in the following directory.\nmap_of_city_codes = {\n    'Mumbai': '2378',\n    'New Delhi': '02',\n    'Bengaluru': '4709',\n    'Hyderabad': '3686',\n    'Chennai': '5732',\n    'Ahmedabad': '1692',\n    'Kolkata': '777'\n}\n\n#The Data is fetched an stored in pandas DataFrame format with the following as the column headers\ncars24_data = pd.DataFrame(columns= ['model_year', 'maker', 'model_name', 'city','distance_covered (km)', 'fuel_type','pre_owner', 'price (\u20b9)'])\n\n#The nested loop consits of an outer loop for collection of data by the above specified cities, by thier respective cityId.\nfor city, code in map_of_city_codes.items():\n\n  #While the inner loop is for collection of data for the specified number of pages per city. (each page contains 20 enteries)\n  for page_number in range(1, numbers_of_pages + 1):\n    response = requests.get('https:\/\/www.cars24.com\/buy-used-car?sort=P&storeCityId={}&page={}'.format(code ,page_number))\n    soup = BeautifulSoup(response.content)\n    for div in soup.findAll('div', attrs={'itemprop':'itemOffered'}):\n      model = div.find('a', attrs={'class': '_20d39'})\n\n      model_year = model.get('title', 'NaN').split(' ')[0]                              # manufacturing year\n      maker = model.get('title', 'NaN').split(' ')[1]                                   # manufacturing brand\n      model_name = ' '.join(model.get('title', 'NaN').split(' ')[2:])                   # model name\n\n      distance_covered = div.find('div', attrs={'class': '_Ecri'}).find('span').text    # distance covered by the vehicle\n      fuel_type = div.find('span', attrs={'itemprop': 'name'}).text                     # fuel type\n      pre_owner = div.find('div', attrs={'class': '_Ecri'}).findAll('span')[-1].text    # previous number of owner\n      price = div.find('h3', attrs={'class': '_6KkG6'}).text                            # price pitched\n        \n      #Adding a new entry to the DataFrame per itteration.\n      cars24_data.loc[len(cars24_data.index)] = [model_year, maker, model_name, city, distance_covered, fuel_type, pre_owner, price]","1d988b7f":"cars24_data","8aaff22c":"cars24_data.dtypes","abd20bf5":"cars24_data['distance_covered (km)'] = cars24_data['distance_covered (km)'].str.replace(',', '').str.replace('km', '').astype(int)\ncars24_data['price (\u20b9)'] = cars24_data['price (\u20b9)'].str.replace(',', '').str.replace('\u20b9', '').astype(int)\ncars24_data.dtypes","87aa1959":"cars24_data.describe(include='all')","d71825f1":"cars24_data.isnull().values.any()","3ef9a84d":"print( StandardScaler().fit_transform(cars24_data[['distance_covered (km)']])[:10] )\n\n#Obtained standardised data can be concatinated to the DataFrame with the following line of code\n\n# cars24_data['std-distance_covered'] = StandardScaler().fit_transform(cars24_data[['distance_covered (km)']])\n# cars24_data.head()","c26af53a":"# Introducting indicator variable for the 'fuel_type'\ndummy_var = pd.get_dummies(cars24_data['fuel_type'])\ndummy_var\n\n#Obtained indicators variable can be concatinated to the DataFrame with the following line of code\n\n#cars24_data = pd.concat([cars24_data, dummy_var], axis=1)\n#cars24_data","9858cc4e":"#The unique sub-categories of the categorical data type.\nprint(str(cars24_data['model_year'].value_counts().to_frame()) + '\\n')\nprint(str(cars24_data['maker'].value_counts().to_frame()) + '\\n')\nprint(str(cars24_data['fuel_type'].value_counts().to_frame()) + '\\n')\nprint(str(cars24_data['pre_owner'].value_counts().to_frame()) + '\\n')","0ef234ef":"# Visualising the data for year of car made vs count\nsns.countplot(x=cars24_data['model_year'].sort_values())\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.5, Size[1] * 1.5, forward=True)\n\n# Add title and axis names\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.show()","a5ed53df":"# Visualising the data for maker brand vs count\nmaker_name = cars24_data['maker'].value_counts().sort_values(ascending=False).keys() \nmaker_count = cars24_data['maker'].value_counts().sort_values(ascending=False)\n\nsns.barplot(y=maker_name, x=maker_count)\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.2, Size[1] * 1.2, forward=True)\nfor index, value in enumerate(maker_count):\n  plt.text(value, index, str(value))\n\n# Add title and axis names\nplt.xlabel('Count')\nplt.ylabel('Maker Name')\nplt.show()","35edfb84":"# Visualising the data for top '15' models of car vs count\ntop_model_names = cars24_data['model_name'].value_counts().sort_values(ascending=False)[:16].keys()\ntop_model_count = cars24_data['model_name'].value_counts().sort_values(ascending=False)[:16]\n\nsns.barplot(y=top_model_names, x=top_model_count)\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.2, Size[1] * 1.2, forward=True)\n\n# Add title and axis names\nplt.xlabel('Count')\nplt.ylabel('Model Name')\nplt.show()","c4260146":"# Visualising the data for distance covered vs count\nsns.histplot(cars24_data['distance_covered (km)'])\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.5, Size[1] * 1.5, forward=True)\nplt.xlim(0)\n\n# Add title and axis names\nplt.xlabel('Distance Covered (Km)')\nplt.ylabel('Count')\nplt.show()","a0a65155":"# Visualising the data for fuel types vs count\nsns.countplot(x=cars24_data['fuel_type'], hue=cars24_data['fuel_type'])\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.2, Size[1] * 1.2, forward=True)\n\n# Add title and axis names\nplt.xlabel('Fuel Types')\nplt.ylabel('Count')\nplt.show()","458dbe55":"# Visualising the data for pervious owners vs count\nsns.countplot(x=cars24_data['pre_owner'], hue=cars24_data['pre_owner'])\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0], Size[1], forward=True)\n\n# Add title and axis names\nplt.xlabel('Previous Owners')\nplt.ylabel('Count')\nplt.show()","2fabb3cd":"# Visualising the data for price vs count\nsns.histplot(cars24_data['price (\u20b9)'])\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.5, Size[1] * 1.5, forward=True)\nplt.xlim(0)\n\n# Add title and axis names\nplt.xlabel('Price (\u20b9)')\nplt.ylabel('Count')\nplt.show()","31dd5256":"#Confirming Outliers for Price\nsns.boxplot(x=cars24_data['price (\u20b9)'])\n\nF = plt.gcf()\nSize = F.get_size_inches()\nF.set_size_inches(Size[0] * 1.5, Size[1] * 1.5, forward=True)\nplt.xlim(0)\n\n# Add title and axis names\nplt.xlabel('Price (\u20b9)')\nplt.ylabel('Count')\nplt.show()","685470dd":"# Analysis of Average price of model for different years\ncars24_grp_test1 = cars24_data[['model_name','model_year','price (\u20b9)']].groupby(['model_name','model_year'],as_index=False).mean().pivot(index='model_year',columns='model_name')\ncars24_grp_test1","0ef8f1b1":"# Analysis of Average price of model for different cities\ncars24_grp_test2 = cars24_data[['model_name','city','price (\u20b9)']].groupby(['model_name','city'],as_index=False).mean().pivot(index='city',columns='model_name')\ncars24_grp_test2","0d078171":"# Analysis of Average price of model for different cities\ncars24_grp_test3 = cars24_data[['model_name','pre_owner','price (\u20b9)']].groupby(['model_name','pre_owner'],as_index=False).mean().pivot(index='pre_owner',columns='model_name')\ncars24_grp_test3","19a19037":"cars24_data.corr()","43517a15":"The URL can be altered with various parameter and filter such as cityId, page, budget, brand, models, etc. For the current session the cityId and the page parameter are used for data filteration.","5731f8cf":"The plot can shows a significant **dominance of specific fuel_type** over the other.","34a41964":"# **4.Data Scaling (Standardization\/Normalization)**\n\nAs observed in the data set, the numeric data has a difference in scale values and hence we need scaling features for dealing with classifiers in data modelling.\n\nDifferent scaling model (Standardization\/Normalization) can be used. The numeric data is the current session is scaled by Standardization.","d22e17df":"The plot can shows a significant **dominance of specific maker brand** over the other, such data sets can lead to false results due to competitve advantages of one category over the other.\n\n* Important Data Insight to be understood and handled before futher data processing.","3256c135":"# **1.Basic Data Exploration**","acea4970":"# **DATA SCRAPING**\nThe web\/data scraping is process of extraction of content and data from a website.\n\nThe 'requests' library is used for API call, while the 'BeautifulSoup' library is used for extraction of the data from the content of API request's response.\n[https:\/\/www.cars24.com\/buy-used-car?](https:\/\/www.cars24.com\/buy-used-car?)\n\n![Screenshot (13).png](attachment:356a472c-e63b-4af1-ad1c-91ef134a5fb0.png)","abf420b1":"**If you notice any error, mistake, or typo, please feel free to let me know. I will do my best to correct it.**\n\n**Open for suggestion, Thank you.**","160f7bd0":"# **2.Descriptive Statistics & Grouping**","e369bb5b":"# **ENVIRONMENT SET-UP**\n\nImporting python libraries necessary for data cleaning, pre-processing and visualisation.","242480a6":"The plot can indicates uneven concentrated distribution for re-sale in a specific range and consists a few outliers.","19ddada6":"# **5.Introduction of Indicator variable (dummies)**\n\nIndicator variables are used to convert categorical variable into numeric variable (also called as dummies) for Regression analysis.\n\nAll the categorical variable in the data set can be converted into dummies.","290f65ee":"The above funtion has a return type of bool.\nIf the return value is\n* **True** - It implies that the data set contains a Null value (np.nan\/Null\/None), the function can be further called on specific columns and can be used to determine the number of Null values.\nDecision such as, column elimination (Due to high number of Null values),row elimination of Null values, Replacement of Null values with any measure of central tendency (such as mean\/median\/mode) are made for a data set with no Null values.\n\n* **False** - It implies that the data set does not contains any Null value.\n\nIn the current sample we can see a return value of False implying that the data set does not contains any Null value.","d817853c":"The above code converts the data types of distance_covered and price to numeric values by elimination of character elements such as (km) or (\u20b9). The column model_year can also be converted to DateTime, if viewed as a numerical parameter. For the the current session it is treated as categorical one. ","4c5408bb":"The above function provides co-relations between the numeric features of data set.\n\nThe obtained correlation can be determined by the following condition:\n\nCorrelation coefficient values less than +0.8 or greater than -0.8 are not considered significant.","81a35245":"# **DATA WRANGLING**\n\nData wrangling is the process of cleaning complex data sets for easy access and analysis.","637a1ce2":"The outliers can be clearily seen in the box-plot if any.","8afa8c33":"# **1.Analyzing Individual Feature**","068795f3":"# **3.Correlation**","722ad864":"# **DATA EXPLORATION**\n\nData exploration uses visual exploration to understand what is in a dataset and the characteristics of the data also known as determining **data quality**.","2a13e05a":"# **Exploratory Data Analysis_Car Re-Sale in India**\nBy [Darshan Dhanke](https:\/\/www.kaggle.com\/darshandhanke)\n\n# **INTRODUCTION**\n\nThe notebook consists of an **exploratory data analysis of car re-sale from some of the popular cities of India**.\nThe data set used is been collected by web scraping from one of the leading e-commerce platform ([www.cars24.com](http:\/\/www.cars24.com\/)) for pre-owned automobiles re-sale in India.\n\nThe study of the notebook focus on the Data Visualisation of different features such as car manufacturer, car model, car usage, city, number of previous owners, etc.\n\nThe notebook consists of the following sections:\n* **ENVIRONMENT SET-UP**\n* **DATA SCRAPING**\n* **DATA WRANGLING**\n    1. *Basic Data Exploration*\n    2. *Data Type Conversion*\n    3. *Indentification of missing Data and outliers*\n    4. *Data Standarization \/ Normalization*\n    5. *Introduction of Indicator variable (dummies)*\n* **DATA EXPLORATION**\n    1. *Analyzing Individual Feature*\n    2. *Descriptive Statistics & Grouping*\n    3. *Correlation*\n* **CONCLUSION**","439c8bd6":"# **2.Data Type Conversion**","ccea1247":"The plot can signifies that a **higher number of cars** are observed into the data set **for the past decade** as compared to the previous years, This effect could be cross verified by ulter the static variable (such as numbers_of_pages, map_of_city_codes) or by adding aditional filter to the web scrapping process.","87854b2f":"It can be observer into the previous section **(Data Wrangling)**, due to higher sub-catergories **(100+)** of car model_name,\n\nThe above plot visualize only the count of top '15' model with high frequency.","8930ba9a":"The data set appears to be segregated into tabular format.The above function has returned the data set obtain from the previous section.","f8b837ed":"As the data set is obtained from data scrapping of websites all the data obtain is in the form of object\/string data type.\n\nSince the data set contains parameter such as model_year, distance_covered and price which are numeric in nature conversion of data type is to be carried out prior to the analysis.","f487413c":"The above function has a brief analyzes both numeric and categorical data types.\n* The key elements to be observed for numeric data are the\nmean, standard dev., maximum-minimum value and quartile values\n* The key elements to be observed for categorical data are \nunique sub-categories, most frequent sub-category and frequency of the most frequent sub-category","c7708324":"# **CONCLUSION**\n\n\n  The brief Data exploration can provides many insights of the data set observed which are considered which modelling the data set.\n\n  In the session the data gather and pre-processed provides a basic understanding of the use case of the data set. Different filters could be applied at the intial stages for obtaining specific data set for a target problem statement.\n\nFollowing are a few examples for Data Modelling problem statements which can be implied for the given data set:\n\n  1. Determination of the price of a specific car model for different parameters (city, fuel type, maker brand, etc).\n  2. Determination of a specific car model life span for different parameters (distance covered, previous number of owners, etc).","81212f4f":"# **3.Identification of missing Data**"}}