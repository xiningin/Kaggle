{"cell_type":{"2c3ed650":"code","f404827b":"code","a12e0efd":"code","864fee0b":"code","d35a7ff7":"code","89c7a086":"code","20416ffa":"code","52e2848e":"code","06840a13":"code","b86fa384":"code","079e6599":"code","7114e04c":"code","9ce6cbb6":"code","0a45c737":"code","e7698182":"code","c365bd4e":"markdown","b1831b0d":"markdown","3effedf8":"markdown","c31496fa":"markdown","fdd69b03":"markdown","a157b58b":"markdown","28144cd0":"markdown","8252bac1":"markdown","ddf771a6":"markdown","89c385d7":"markdown","3947058c":"markdown","5e6f2ede":"markdown"},"source":{"2c3ed650":"from keras.layers import Dense, Input\nfrom keras.layers import Conv2D, Flatten, Lambda\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.datasets import mnist\nfrom keras.losses import mse, binary_crossentropy\nfrom keras import backend as K\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\nimport os","f404827b":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nimage_size = x_train.shape[1]\n# Only get some data to train and test\ntrain_len = 10000\ntest_len = 1000\nx_train = np.reshape(x_train[:train_len], [-1, image_size, image_size, 1])\nx_test = np.reshape(x_test[:test_len], [-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\ny_test = y_test[:test_len]","a12e0efd":"x_train.shape","864fee0b":"x_test.shape","d35a7ff7":"x_train_show = x_train.reshape(-1,28,28)\nplt.figure(1)\nplt.subplot(221)\nplt.imshow(x_train_show[20])\nprint('y_train[20] = ', y_train[20])\n\nplt.subplot(222)\nplt.imshow(x_train_show[500])\nprint('y_train[500] = ', y_train[500])\n\nplt.subplot(223)\nplt.imshow(x_train_show[3000])\nprint('y_train[3000] = ', y_train[3000])\n\nplt.subplot(224)\nplt.imshow(x_train_show[9000])\nprint('y_train[9000] = ', y_train[9000])\nplt.show()","89c7a086":"# reparameterization trick: instead of sampling from Q(z|X), sample epsilon = N(0,1)\n# then z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon","20416ffa":"def plot_results(encoder, decoder, x_test, y_test, batch_size=128):\n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.show()\n\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size \/\/ 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.imshow(figure, cmap='Greys_r')\n    plt.show()","52e2848e":"input_shape = (image_size, image_size, 1)\nbatch_size = 32\nkernel_size = 3\nfilters = 16\nlatent_dim = 2\nepochs = 30\nuse_mse = True\nload_weights = False","06840a13":"inputs = Input(shape=input_shape, name='encoder_input')\nx = inputs\nfor i in range(2):\n    filters *= 2\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               activation='relu',\n               strides=2,\n               padding='same')(x)\n\n# shape info needed to build decoder model\nshape = K.int_shape(x)\n\n# generate latent vector Q(z|X)\nx = Flatten()(x)\nx = Dense(16, activation='relu')(x)\nz_mean = Dense(latent_dim, name='z_mean')(x)\nz_log_var = Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\nz = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()","b86fa384":"latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\nx = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\n\n# use Conv2DTranspose to reverse the conv layers from the encoder\nfor i in range(2):\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        activation='relu',\n                        strides=2,\n                        padding='same')(x)\n    filters \/\/= 2\n\noutputs = Conv2DTranspose(filters=1,\n                          kernel_size=kernel_size,\n                          activation='sigmoid',\n                          padding='same',\n                          name='decoder_output')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()","079e6599":"outputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name='vae')","7114e04c":"if use_mse:\n    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\nelse:\n    reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n                                              K.flatten(outputs))\n\nreconstruction_loss *= image_size * image_size\nkl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\nkl_loss = K.sum(kl_loss, axis=-1)\nkl_loss *= -0.5\nvae_loss = K.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)","9ce6cbb6":"vae.compile(optimizer='rmsprop')\nvae.summary()","0a45c737":"if load_weights:\n    vae = vae.load_weights(args.weights)\nelse:\n    # train the autoencoder\n    vae.fit(x_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            validation_data=(x_test, None))\n    vae.save_weights('vae_cnn_mnist.h5')","e7698182":"plot_results(encoder, decoder, x_test, y_test, batch_size=batch_size)","c365bd4e":"##  Set up network parameters","b1831b0d":"## Show MNIST images","3effedf8":"## Fit model","c31496fa":" ## Loss = reconstruction loss + KL loss","fdd69b03":"## Plot new MNIST images","a157b58b":"## Reference\n> https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/variational_autoencoder_deconv.py","28144cd0":"## Load MNIST","8252bac1":"## Compile model","ddf771a6":"## Build encoder model","89c385d7":"## Build VAE model = encoder + decoder","3947058c":"This kernel present how to use VAE(Variational Auto-Encoder) to generate different MNIST images. VAE use convolution layers in encoder and decoder.","5e6f2ede":"## Build decoder model"}}