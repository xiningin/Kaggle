{"cell_type":{"f66005f8":"code","9b2b02ba":"code","cb99249a":"code","254e5034":"code","0ffb13a3":"code","bbe765c4":"code","22e5c492":"code","15394daf":"code","b3c74ef5":"code","3bb8a258":"code","d24951fa":"code","f0832a00":"code","8f948ad3":"code","458f971c":"code","048ae1fb":"code","49161b74":"code","fb4f1737":"markdown","437177b3":"markdown","16060fb0":"markdown","7f75cd3f":"markdown","d5eaf80d":"markdown","21eedcb5":"markdown","cf214742":"markdown","b97eb0f7":"markdown","6bf3fad0":"markdown","c6e00ba0":"markdown"},"source":{"f66005f8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9b2b02ba":"# Get launch date\n\nprices = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\nprices['id'] = prices['store_id'] + \"_\" + prices['item_id']\ncal = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\ncal = cal[['wm_yr_wk', 'date', 'd']]\ncal['d'] = cal['d'].str.replace(\"d_\", \"\").astype(int)\nprices = prices.merge(cal[['wm_yr_wk', 'd']].groupby(['wm_yr_wk'])[['d']].min().reset_index(), on = 'wm_yr_wk')\nprices = prices.sort_values(['id', 'd'])\nlaunch_date = prices.groupby(['id'])[['d']].min().reset_index()\nlaunch_date.head()\n\nlaunch_date.to_csv(\"m5_launch_date.csv\", index = False)","cb99249a":"import gc\ngc.collect()","254e5034":"# Get prices\n\nprices = prices.drop(['d', 'store_id', 'item_id'], axis= 1)\ncal = cal.drop('date', axis = 1)\nprices = prices.merge(cal, on = 'wm_yr_wk')\nprices = prices.drop(['wm_yr_wk'], axis = 1)\nprices = prices.pivot(index = 'id', columns = 'd', values = 'sell_price')\n\n# Remove this line for eventual test set\nprices = prices.iloc[:,:-28]\n\nprices.reset_index().to_csv(\"m5_prices_wide.csv\", index = False)","0ffb13a3":"cal = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\n\n# Weekends\n\ncal = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\nweekends = cal[['wday']]\nweekends[(weekends['wday'] == 1) | (weekends['wday'] == 2) | (weekends['wday'] == 7)] = 1\nweekends[(weekends['wday'] != 1) & (weekends['wday'] != 2) & (weekends['wday'] != 7)] = 0\n\nweekends.columns = ['weekend']\n\n# Remove for eventual set\nweekends = weekends.iloc[:-28]\n\nweekends.to_csv(\"m5_weekends.csv\", index = False)","bbe765c4":"# Snap\nsales = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\", usecols = [0,1,2,3,4,5])\nsnap_CA = cal['snap_CA'].values\nsnap_WI = cal['snap_WI'].values\nsnap_TX = cal['snap_TX'].values\nsnap_CA_m = np.repeat(snap_CA.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"CA\"), axis = 1).transpose()\nsnap_TX_m = np.repeat(snap_TX.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"TX\"), axis = 1).transpose()\nsnap_WI_m = np.repeat(snap_WI.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"WI\"), axis = 1).transpose()\nsnap = np.concatenate([snap_CA_m, snap_TX_m, snap_WI_m], axis = 0)\n\nsnap = pd.DataFrame(snap)\n\n# remove for final set\nsnap.iloc[:, :-28].to_csv(\"snap.csv\", index = False)","22e5c492":"# holidays\nlist_of_hols = list(set(np.append(cal['event_name_1'].unique(), cal['event_name_2'].unique())))[1:]\n\nholidays = cal.loc[(cal['event_name_1'] == list_of_hols[0]) | (cal['event_name_2'] == list_of_hols[0]), ['date', 'event_name_1', 'date','event_name_2']]\n\nfor i in list_of_hols[1:]:\n    holidays = holidays.append(cal.loc[(cal['event_name_1'] == i) | (cal['event_name_2'] == i), ['date', 'event_name_1', 'date','event_name_2']])\n    \nholidays_m = holidays.iloc[:,:2].rename(columns = {'event_name_1':'holiday'}).append(holidays.iloc[:,2:].rename(columns = {'event_name_2':'holiday'}))\n\nholidays_m = holidays_m.dropna()\n\nholidays_m = holidays_m[['holiday', 'date']]\nholidays_m.columns = ['holiday', 'ds']\nholidays_m['lower_window'] = 0\nholidays_m['upper_window'] = 0\n\nholidays_m.loc[holidays_m['holiday'] == \"Thanksgiving\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Thanksgiving\",'upper_window'] = 1\n\nholidays_m.loc[holidays_m['holiday'] == \"Christmas\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Christmas\",'upper_window'] = 1\n\nholidays_m.loc[holidays_m['holiday'] == \"Easter\",'lower_window'] = -2\n\nholidays_m.loc[holidays_m['holiday'] == \"Eid al-Fitr\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Eid al-Fitr\",'upper_window'] = 1\n\n\nholidays_m['ds'] = pd.to_datetime(holidays_m['ds'])\n\nholidays_m.to_csv(\"m5_holidays.csv\", index = False)","15394daf":"sales = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")\nsale_hist = sales.iloc[:,6:]\ncumulative_max = sale_hist.transpose().cummax().transpose()\nextra = pd.DataFrame(np.repeat(cumulative_max.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncumulative_max = pd.concat([cumulative_max, extra], axis = 1)\ncumulative_max.to_csv(\"cumulative_max.csv\", index = False)","b3c74ef5":"sale_hist = sales.iloc[:,6:]\nsale_hist[sale_hist != 0] = 2","3bb8a258":"sale_hist[sale_hist == 0] = 1\nsale_hist[sale_hist == 2] = 0","d24951fa":"cum_7_freq_zero = sale_hist.transpose().rolling(7).mean().transpose()\ncum_14_freq_zero = sale_hist.transpose().rolling(14).mean().transpose()\ncum_28_freq_zero = sale_hist.transpose().rolling(28).mean().transpose()\ncum_56_freq_zero = sale_hist.transpose().rolling(56).mean().transpose()","f0832a00":"extra = pd.DataFrame(np.repeat(cum_7_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_7_freq_zero = pd.concat([cum_7_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_14_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_14_freq_zero = pd.concat([cum_14_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_28_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_28_freq_zero = pd.concat([cum_28_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_56_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_56_freq_zero = pd.concat([cum_56_freq_zero, extra], axis = 1)","8f948ad3":"cum_7_freq_zero.fillna(0).to_csv(\"cum_7_freq_zero.csv\", index = False)\ncum_14_freq_zero.fillna(0).to_csv(\"cum_14_freq_zero.csv\", index = False)\ncum_28_freq_zero.fillna(0).to_csv(\"cum_28_freq_zero.csv\", index = False)\ncum_56_freq_zero.fillna(0).to_csv(\"cum_56_freq_zero.csv\", index = False)","458f971c":"cum_zero = sale_hist.transpose().cumsum().transpose()","048ae1fb":"history_zeros = (cum_zero.values - np.repeat(launch_date['d'].values.reshape(-1,1) - 1, repeats = 1913, axis = 1)) - 1\nhistory_zeros[history_zeros < 0] = 0\ncumulative_zero = pd.DataFrame(np.concatenate([history_zeros, np.repeat(history_zeros[:,-1].reshape(-1,1), 28, axis = 1)], axis = 1))\ncumulative_zero.to_csv(\"cumulative_zero.csv\", index = False)","49161b74":"df = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv\")\ndf2 = pd.DataFrame(np.zeros([30490, 1913])).astype(int)\n\ndf3 = df.drop(['id'], axis = 1)\ndf3.columns = list(np.arange(1914, 1914+28))\ndf2.columns = df2.columns + 1\ndf_sample = pd.concat([df[['id']].head(30490), df2.astype(int), df3.head(30490)], axis = 1)\ndf_sample.to_csv(\"holder.csv\", index = False)","fb4f1737":"### Cumulative Zeros","437177b3":"### Freq of Zero Sales in the last t days","16060fb0":"# Get Holidays","7f75cd3f":"# Get SNAP Dates","d5eaf80d":"### Cumulative Max","21eedcb5":"# DF to store results when training","cf214742":"# Get Weekends","b97eb0f7":"# Launch Date of Each Item","6bf3fad0":"# Some Optional Feature: (A) Cumulative Max, (B) Cumulative Number of Zero Sales, (C) Percenatge of Zero Sales in the last (7\/14\/28\/56) days ","c6e00ba0":"# Get Prices"}}