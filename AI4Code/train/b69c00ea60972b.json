{"cell_type":{"57f4683c":"code","0051c189":"code","513cc017":"code","1949c53f":"code","684057b4":"code","61b305c5":"code","9ab4eed0":"code","3a3137ec":"code","850443ee":"code","10b7153b":"code","90552a16":"code","0b1d808d":"code","4278dcf3":"markdown","db9ed291":"markdown","d6fddf44":"markdown","6883a479":"markdown","35cec4be":"markdown","e973764f":"markdown","94d13167":"markdown"},"source":{"57f4683c":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\n\nimport time\nimport copy","0051c189":"torch.cuda.is_available()","513cc017":"# Another way to copy the pretrained models to the cache directory (~\/.torch\/models) where PyTorch is looking for them.\n# From https:\/\/www.kaggle.com\/pvlima\/use-pretrained-pytorch-models#Transfer-learning-in-kernels-with-PyTorch\nimport os\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.torch'))\n\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n    \n!cp ..\/input\/pretrained-pytorch-models\/* ~\/.torch\/models\/\n!ls ~\/.torch\/models","1949c53f":"import torchvision\nfrom torchvision import datasets, transforms\n\ndata_transforms = {\n    'train': transforms.Compose([   # Here we do not make data augmentations\n        transforms.Resize(325),\n        transforms.CenterCrop(299), # Note that we want to use Inception v3, it requires this size of images\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # We can simply use this parameter\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(325),\n        transforms.CenterCrop(299),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = \"..\/input\/dogs-vs-cats\/dataset\/dataset\"\n\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, name),\n                                          data_transforms[x])\n                  for x, name in [['train', \"training_set\"], ['val', \"test_set\"]]}\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\n# See some statistics\nprint(dataloaders)\nlen(dataloaders['train'])","684057b4":"import numpy as np\nimport matplotlib.pyplot as plt\nplt.ion()   # interactive mode\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)\n\n# imshow(out, title=[class_names[x] for x in classes])","61b305c5":"def train_model(model, criterion, optimizer, scheduler, num_epochs=2, is_inception=False):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    # mode we calculate the loss by summing the final output and the auxiliary output\n                    # but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https:\/\/discuss.pytorch.org\/t\/how-to-optimize-inception-model-with-auxiliary-classifiers\/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                    \n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","9ab4eed0":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","3a3137ec":"import torchvision.models as models\nimport torch.optim as optim\n\nmodel_ft = models.inception_v3(pretrained=True)\nfor param in model_ft.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\n# Handle the auxilary net\nnum_ftrs = model_ft.AuxLogits.fc.in_features\nmodel_ft.AuxLogits.fc = nn.Linear(num_ftrs, 2)\n# Handle the primary net\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\n# print(model_ft)","850443ee":"from torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft = model_ft.to(device)\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\nparams_to_update = []\nfor name,param in model_ft.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\noptimizer_conv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n\ncriterion = nn.CrossEntropyLoss()\n# Decay LR by a factor of 0.1 every epoch\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=1, gamma=0.1)","10b7153b":"model_ft = train_model(model_ft, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=2, is_inception=True) # As an example, only show the results of 2 epoch","90552a16":"visualize_model(model_ft)\n\nplt.ioff()\nplt.show()","0b1d808d":"# Note that this way of copying files will generate outputs.\n\"\"\"\n%mkdir -p data\/train\n%mkdir -p data\/val\n%mkdir -p \/tmp\/.torch\/models\n\n%cp -r ..\/input\/dogs-vs-cats\/dataset\/dataset\/training_set\/* data\/train\n%cp -r ..\/input\/dogs-vs-cats\/dataset\/dataset\/test_set\/* data\/val\n%cp -r ..\/input\/pretrained-pytorch-models\/* \/tmp\/.torch\/models\n\nimport os\nprint(os.listdir(\"data\"))\nprint(os.listdir(\"\/tmp\/.torch\/models\"))\n\"\"\"","4278dcf3":"# Dogs v.s. Cats: Transfer learning\n\nMainly based on [*Transfer learnig tutorial*](https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html#transfer-learning-tutorial), of which code is fine-tuned for this task.\n\nIn this kernel we use **feature extraction**, which means we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n\nWe use **Inception v3** as a fixed feature extractor.\n\nResult: ~97.7% accuracy within 9 epochs.\n\n## Contents\n\n* Load data\n* General functions to train and visualize\n* Transfer learning: feature extractor (Inception v3)\n* Train and evaluate","db9ed291":"## 2. General functions to train and visualize\n\nHere we use a general function to train a model. It includes:\n\n* Scheduling the learning rate\n* Saving the best model\n\nWe use [*torch.optim.lr_scheduler*](https:\/\/pytorch.org\/docs\/stable\/optim.html#how-to-adjust-learning-rate). It provides several methods to adjust the learning rate based on the number of epochs. Our function parameter `scheduler` is an object from it.","d6fddf44":"### Visualize a few images","6883a479":"## 1. Load data\n\nHere we use [**torchvision.datasets.ImageFolder**](https:\/\/pytorch.org\/docs\/stable\/torchvision\/datasets.html#torchvision.datasets.ImageFolder) to load our data.\n\nIt is A generic data loader where the images are arranged in this way:**\n\n>root\/dog\/xxx.png\n>\n>root\/cat\/123.png\n\n","35cec4be":"## 4. Train and evaluate\n\nWe use [torch.optim.lr_scheduler.StepLR](https:\/\/pytorch.org\/docs\/stable\/optim.html#torch.optim.lr_scheduler.StepLR) to schedule the learning rate.","e973764f":"### Visualizing the model predictions\n\nA generic function to display predictions for a few images.","94d13167":"## 3. Transfer learning: feature extractor\n\nHere we use **Inception v3** as a fixed feature extractor.\n\nHere, we need to freeze all the network except the final layer. We need to set `requires_grad == False` to freeze the parameters so that the gradients are not computed in `backward()`.\n\n### Inception v3\n\nInception v3 was first described in [Rethinking the Inception Architecture for Computer Vision](https:\/\/arxiv.org\/pdf\/1512.00567v1.pdf). This network is unique because it has two output layers when training. \n\nThe second output is known as an auxiliary output and is contained in the AuxLogits part of the network. The primary output is a linear layer at the end of the network. \n\nNote, when testing we only consider the primary output. "}}