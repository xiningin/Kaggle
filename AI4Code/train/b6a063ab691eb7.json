{"cell_type":{"13319c3c":"code","b9d21579":"code","d40610c2":"code","9685dd4a":"code","ae9620e8":"code","bc40b47e":"code","1045f061":"code","3984d449":"code","fe03785b":"code","250dcc13":"code","d7179342":"code","1e224503":"code","9057a0e9":"code","305494f6":"code","92a8fabe":"code","74fea306":"code","f7894729":"code","35f0443c":"code","7d34f1d9":"code","636c27c9":"code","e23dd292":"code","4d688fab":"code","bb27db71":"code","9bc47daa":"code","41d0c0ed":"code","12e0db7e":"code","fc34fbfc":"code","b70b6891":"code","2925e234":"code","e69c6b09":"code","01a1e653":"markdown","447fbdeb":"markdown","4901031a":"markdown","27273102":"markdown","c3d784d2":"markdown","0ef72adf":"markdown","b9fb8424":"markdown","caad3660":"markdown","d6a06960":"markdown","c1bef435":"markdown","21cb9265":"markdown"},"source":{"13319c3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b9d21579":"data = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata.head()","d40610c2":"data.drop('customerID', axis =1, inplace = True)","9685dd4a":"data.info()","ae9620e8":"data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors = 'coerce')","bc40b47e":"data.info()","1045f061":"X = data.iloc[:,:-2].values\ny = data.loc[:,'Churn'].values","3984d449":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder","fe03785b":"cols = [0,2,3,5,6,7,8,9,10,11,12,13,14,15,16]\nfor col in cols:\n    label_encoder = LabelEncoder()\n    X[:,col] = label_encoder.fit_transform(X[:,col])\n\nX","250dcc13":"X_1 = X[:,[4,-2,-1]]\nX = X[:,[0,1,2,3,5,6,7,8,9,10,11,12,13,14,15,16]]","d7179342":"onehotencoders = OneHotEncoder(categories='auto', drop = 'first')\nX = onehotencoders.fit_transform(X).toarray()\nX","1e224503":"X = np.concatenate((X,X_1),axis = 1)\nX = np.asarray(X)","9057a0e9":"y","305494f6":"labelencoder = LabelEncoder()\ny = labelencoder.fit_transform(y)\ny","92a8fabe":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)","74fea306":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f7894729":"len(X_test)","35f0443c":"from sklearn.linear_model import LogisticRegression","7d34f1d9":"logclf = LogisticRegression(penalty = 'l1')\nlogclf.fit(X_train,y_train)","636c27c9":"logclf.predict(X_test)\nlog_acc= logclf.score(X_test, y_test)\nprint(log_acc)","e23dd292":"from sklearn.ensemble import AdaBoostClassifier","4d688fab":"ada_clf = AdaBoostClassifier(random_state = 14)\nada_clf.fit(X_train,y_train)\nada_acc= ada_clf.score(X_test,y_test)\nada_acc","bb27db71":"from sklearn import tree","9bc47daa":"dec_clf = tree.DecisionTreeClassifier(criterion ='entropy', splitter='random', random_state= 53, max_features=8, max_leaf_nodes=20)\ndec_clf.fit(X_train,y_train)\ndec_acc = dec_clf.score(X_test,y_test)\ndec_acc","41d0c0ed":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential()\nclassifier.add(Dense(output_dim = 30, init='uniform', activation='relu', input_dim = 30))\nclassifier.add(Dense(output_dim = 50, init='uniform', activation='relu'))\nclassifier.add(Dense(output_dim = 30, init='uniform', activation='relu'))\nclassifier.add(Dense(output_dim = 1, init='uniform', activation='sigmoid'))","12e0db7e":"classifier.compile(optimizer = 'adam', loss='binary_crossentropy',metrics = ['accuracy'])\nclassifier.fit(X_train,y_train, batch_size = 10, nb_epoch=100)","fc34fbfc":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred>0.5)\ny_pred","b70b6891":"cm = confusion_matrix(y_test,y_pred)\ncm","2925e234":"ann_acc = classifier.evaluate(X_test, y_test)[1]","e69c6b09":"print(\"Logistic Accuracy Score: {}\\nAdaBOOST Accuracy Score: {}\\nDecision Tree Accuracy Score: {}\\nANN Classifier Accuracy Score: {}\".format(log_acc,ada_acc,dec_acc,ann_acc))","01a1e653":"# Data","447fbdeb":"# Model testing","4901031a":"## The simple logistic regression model produces a higher accuracy score as compared to ANN classifier","27273102":"# Data Preprocessing","c3d784d2":"## ANN model","0ef72adf":"# Model Comparison","b9fb8424":"## AdaBoost","caad3660":"# Data Preparation","d6a06960":"## Logistic Regression","c1bef435":"### This notebook tries to establish predictions using a simple algorithm Logistic with ANN classifier.","21cb9265":"### Decision Tree"}}