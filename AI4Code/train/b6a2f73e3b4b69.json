{"cell_type":{"71c97531":"code","daece4a2":"code","13953cfb":"code","c749e5a3":"code","f066994e":"code","3ee8d1d2":"code","47b6ded4":"code","de9e5e62":"code","c776b3db":"code","faa07530":"code","b1af15e7":"code","f32aec77":"code","e830f623":"code","f519ab32":"code","7e64917a":"code","37a57224":"code","ad78c2f5":"markdown","1be13492":"markdown"},"source":{"71c97531":"# Do imports\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt","daece4a2":"# Setup some config variables\nepochs = 15\nbatch_size = 50\nimage_size = (256,256)\nbase_path = '..\/input\/eyes-rtte'\nimages_f = '..\/input\/eyes-rtte\/femaleeyes'\nimages_m = '..\/input\/eyes-rtte\/maleeyes'\nseed = 82","13953cfb":"# Split the images into train\/validation sets\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    base_path,\n    validation_split = 0.2,\n    subset = \"training\",\n    seed = seed,\n    image_size = image_size,\n    batch_size = batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    base_path,\n    validation_split = 0.2,\n    subset = \"validation\",\n    seed = seed,\n    image_size= image_size,\n    batch_size = batch_size,\n)","c749e5a3":"# Display a few images, label 0 is female, label 1 is male\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","f066994e":"# Setup augmentations, add horizontal flip and a little bit of rotation\ndata_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n    ]\n)","3ee8d1d2":"# Display examples of an augmented image\nplt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","47b6ded4":"# Setup buffered prefetching to save on memory\ntrain_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","de9e5e62":"# Setup the model. This is a stock model definition from the keras website. keras.io\n#\ndef make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n        \n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)","c776b3db":"# Create the model\ncallbacks = [ keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")]\nmodel.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds)","faa07530":"# Prediction function, call with \/path\/to\/image.jpg\ndef predict_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=image_size)\n    img_array = keras.preprocessing.image.img_to_array(img)\n\n    # Image needs to be in the form of a batch\n    img_array = tf.expand_dims(img_array, 0)\n\n    # Predict & score\n    predictions = model.predict(img_array)\n    score = predictions[0]\n    print(\"This image is %.2f percent female and %.2f percent male.\" % (100 * (1 - score), 100 * score))\n    plt.imshow(img);","b1af15e7":"# Predect on the external test images\npredict_image(\"..\/input\/eyes-test-images\/female_1.jpg\")","f32aec77":"predict_image(\"..\/input\/eyes-test-images\/female_2.jpg\")","e830f623":"predict_image(\"..\/input\/eyes-test-images\/female_3.jpg\")","f519ab32":"predict_image(\"..\/input\/eyes-test-images\/male_1.jpg\")","7e64917a":"predict_image(\"..\/input\/eyes-test-images\/male_2.jpg\")","37a57224":"predict_image(\"..\/input\/eyes-test-images\/male_3.jpg\")","ad78c2f5":"<div class='alert alert-info' style='text-align: center'><h1>Male or Female Eyes? - A Simple Keras Classifier<\/h1><\/div>\n\n#### I loaded this cool 'male\/female eyes' dataset -> https:\/\/www.kaggle.com\/pavelbiz\/eyes-rtte \n\n##### - It contains ~11K images of human eye photographs separated into two directories, by sex.\n\n#### This notebook demonstrates training and testing a simple keras binary classification CNN.\n##### - I created and loaded six images into my own dataset (..\/input\/eyes-test-images) for testing. These are not part of the original dataset .. this way, we can be sure there is no leakage.\n\n- Thanks https:\/\/www.kaggle.com\/pavelbiz for the dataset","1be13492":"#### As we can see, this model is pretty accurate with just some basic hyperparameters, a few epochs and no tuning."}}