{"cell_type":{"e1781e98":"code","183a65a4":"code","828c4332":"code","58a10738":"code","f4cb042a":"code","dddc8ba8":"code","0b7ab3b9":"code","a9e04161":"code","8191e289":"code","33b22b0c":"code","ace0868e":"code","db7cfb4e":"code","aea6b570":"code","6cacfdc6":"code","d41d547f":"code","c97372cf":"code","9e91bc46":"code","ee06b399":"code","35cafb30":"code","9ca045f5":"code","803009b0":"code","2f744356":"code","1623264e":"code","d510f6ca":"code","757e0859":"code","56339a3e":"code","fa08cccd":"code","a7798852":"code","29e816cd":"code","2e5d70cb":"code","a45e3861":"code","161aded8":"code","c414fa9b":"code","6a8beb0a":"code","3e1f5f43":"code","33c4a0d6":"code","bf96535e":"code","096bdbc2":"code","c4bb6995":"code","3c44239c":"code","ceb195d1":"code","71b707b5":"code","74c79a08":"code","19aea337":"code","940f5fad":"code","c126f2d6":"code","b28b7f44":"code","4a2b7e41":"code","bbee50ed":"code","38351968":"code","43a52fb2":"code","72416db3":"code","44b4a5a0":"code","aaf95531":"code","84a2fd99":"code","7bbffc67":"code","9f5a6b8e":"code","63c45835":"code","7b95d202":"code","007feda2":"code","548a2039":"code","ef6af75a":"code","64634f5d":"code","81373252":"code","771c7473":"code","7c996a56":"code","f2fa4641":"code","e07f0696":"code","515cd742":"code","77b36cf1":"markdown","dde0d5aa":"markdown","8f8e7a0f":"markdown","73208d2d":"markdown","16f4e0af":"markdown","32b25172":"markdown","9270f75f":"markdown","82e3e7ab":"markdown","6e2398e1":"markdown","59ba8b37":"markdown","bf726013":"markdown","9fb270b0":"markdown","5b562aa4":"markdown","41a1c635":"markdown","b1cf701c":"markdown"},"source":{"e1781e98":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain =pd.read_csv(os.path.join(dirname,'train.csv'))\ntest =pd.read_csv(os.path.join(dirname,'test.csv'))\n\ntest_ID = test['Id']\ntrain=train.drop(\"Id\",axis=1)\ntest=test.drop(\"Id\",axis=1)\n\n# print(np.shape(train),np.shape(test))\n\n","183a65a4":"plt.scatter(train['OpenPorchSF'],train['SalePrice'])\nplt.xlabel('OpenPorchSF',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","828c4332":"plt.scatter(train['BsmtFinSF1'],train['SalePrice'])\nplt.xlabel('BsmtFinSF1',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","58a10738":"plt.scatter(train['YearBuilt'],train['SalePrice'])\nplt.xlabel('YearBuilt',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","f4cb042a":"plt.scatter(train['OverallCond'],train['SalePrice'])\nplt.xlabel('OverallCond',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","dddc8ba8":"plt.scatter(train['TotalBsmtSF'],train['SalePrice'])\nplt.xlabel('TotalBsmtSF',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","0b7ab3b9":"plt.scatter(train['GrLivArea'],train['SalePrice'])\nplt.xlabel('GrLivArea',fontsize=13)\nplt.ylabel('SalePrice',fontsize=13)","a9e04161":"\ntrain=train.drop(train[(train['OpenPorchSF']>500) & (train['SalePrice']<100000)].index)\n\ntrain=train.drop(train[(train['BsmtFinSF1']>5000) & (train['SalePrice']<300000)].index)\n\ntrain=train.drop(train[(train['YearBuilt']<1900) & (train['SalePrice']>400000)].index)\n\ntrain=train.drop(train[(train['OverallCond']==2) & (train['SalePrice']>300000)].index)\n\ntrain=train.drop(train[(train['TotalBsmtSF']>3000) & (train['SalePrice']<300000)].index)\n\ntrain=train.drop(train[(train['GrLivArea']>3000) & (train['SalePrice']<300000)].index)","8191e289":"from scipy.stats import norm\nsns.distplot(train[\"SalePrice\"],fit=norm)\nmu,sigma= norm.fit(train['SalePrice'])\nprint(\"mu {}, sigma {}\".format(mu,sigma))","33b22b0c":"########## REMOVING SKEWEENESS ###########\ntrain['SalePrice']=np.log1p(train['SalePrice'])\nsns.distplot(train[\"SalePrice\"],fit=norm)\nmu,sigma= norm.fit(train['SalePrice'])\nprint(\"mu {}, sigma {}\".format(mu,sigma))","ace0868e":"ytrain=train.SalePrice.values","db7cfb4e":"# Concatenating train + test= all_data\nall_data=pd.concat((train,test)).reset_index(drop=True)","aea6b570":"all_data=all_data.drop('SalePrice',axis=1)\n","6cacfdc6":"print(np.shape(all_data))","d41d547f":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","c97372cf":"all_data['PoolQC']=all_data['PoolQC'].fillna(\"None\")\nall_data['MiscFeature']=all_data['MiscFeature'].fillna(\"None\")\nall_data['Alley']=all_data['Alley'].fillna(\"None\")\nall_data['Fence']=all_data['Fence'].fillna(\"None\")\nall_data['FireplaceQu']=all_data['FireplaceQu'].fillna(\"None\")\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\nfor col in ('GarageQual','GarageCond','GarageFinish','GarageType'):\n    all_data[col]=all_data[col].fillna(\"None\")\n# Garageyrbuilt !!!!!!!!!    \nfor col in ('GarageYrBlt','GarageArea','GarageCars'):\n    all_data[col]=all_data[col].fillna(0)\n    \n","9e91bc46":"for col in ('BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2'):\n    all_data[col]=all_data[col].fillna(\"None\")\nfor col in ('BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath'):\n    all_data[col]=all_data[col].fillna(0)\n  ","ee06b399":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","35cafb30":"all_data['MasVnrType']=all_data['MasVnrType'].fillna(\"None\")\nall_data['MasVnrArea']=all_data['MasVnrArea'].fillna(0)\nall_data['MSZoning']=all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data=all_data.drop(['Utilities'],axis=1)\nall_data['Functional']=all_data['Functional'].fillna(\"Typ\")\nall_data['SaleType']=all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['KitchenQual']=all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior2nd']=all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['Exterior1st']=all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Electrical']=all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n","9ca045f5":"miss=all_data.isnull().sum()\nmiss=miss[miss>0]\nmiss=miss.sort_values(ascending=False)\nprint(miss)","803009b0":"all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","2f744356":"########################### MISSING VALUES HANDLED ########################","1623264e":"print(np.shape(all_data))","d510f6ca":"#CHANGED\nall_data=all_data.drop(['Street'],axis=1)","757e0859":"#CHANGED\nall_data=all_data.drop(['PoolQC'],axis=1)","56339a3e":"############# Numerically represented categorical values .    NEED TO CONVERT THESE TO CATEGORICAL      ########################\n# MSSubClass OverallQual  OverallCond   YearBuilt   YearRemodAdd    BsmtFullBath   BsmtHalfBath   FullBath   HalfBath   BedroomAbvGr  KitchenAbvGr   TotRmsAbvGrd   Fireplaces   GarageYrBlt   GarageCars   MoSold   YrSold   ","fa08cccd":"#CHANGED\nfor col in ('MSSubClass' ,   'OverallCond'  ,'OverallQual', 'BedroomAbvGr',  'KitchenAbvGr', 'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,    'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold'):\n    all_data[col]=all_data[col].astype(str)","a7798852":"# CATEGORICAL\n\n# ('MSSubClass', 'OverallQual',  'OverallCond' ,   'YearRemodAdd',    'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,  'BedroomAbvGr',  'KitchenAbvGr',   'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold','MSZoning','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','Fence','MiscFeature','SaleType','SaleCondition', 'YearBuilt')","29e816cd":"# CATEGORICAL Features\nc=('MSSubClass', 'OverallQual',  'OverallCond' ,   'YearRemodAdd',    'BsmtFullBath',   'BsmtHalfBath',   'FullBath',   'HalfBath' ,  'BedroomAbvGr',  'KitchenAbvGr',   'TotRmsAbvGrd' ,  'Fireplaces',   'GarageYrBlt',   'GarageCars'  , 'MoSold' ,  'YrSold','MSZoning','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','Fence','MiscFeature','SaleType','SaleCondition', 'YearBuilt')\n","2e5d70cb":"\ncat_list=list(c)\n","a45e3861":"######## LABEL ENCODING OF ALL CATEGORICAL FEATURES ###########\nfrom sklearn.preprocessing import LabelEncoder\nfor i in cat_list:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[i].values)) \n    all_data[i] = lbl.transform(list(all_data[i].values))","161aded8":"# Numerical_cols= all_data.columns-CategoricalColumns\nnumeric_col=[]\nfor col in all_data.columns:\n    if(col not in cat_list):\n        numeric_col.append(col)","c414fa9b":"skew=all_data[numeric_col].skew()","6a8beb0a":"print(skew)","3e1f5f43":"skew=skew[abs(skew) > 0.75]\nprint(len(skew))","33c4a0d6":"from scipy.special import boxcox1p\nlam=0.15\nfor i in skew.index:\n    all_data[i]=np.log1p(all_data[i])","bf96535e":"########### NORMALIZING NUMERIC FEATURES ####################\nfor col in numeric_col:\n    m=np.mean(all_data[col])\n    ma=np.max(all_data[col])\n    mi=np.min(all_data[col])\n    all_data[col]=(all_data[col]-m)\/(ma-mi)\n    ","096bdbc2":"all_data=pd.get_dummies(all_data)\nprint(np.shape(all_data))","c4bb6995":"######### test + train = all_data ######\nq=np.shape(ytrain)[0]\ntrain=all_data[:q]\ntest=all_data[q:]","3c44239c":"print(np.shape(train),np.shape(test))","ceb195d1":"print(len(test.columns),len(train.columns))","71b707b5":"######## train = xtrain , val ###########\nfrom sklearn.model_selection import train_test_split\nxtrain, xval, ytrain, yval = train_test_split(train, ytrain, test_size=0.33,\n                                                      random_state=0)\n####################################### CHANGED TEST SIZE ##############################################","74c79a08":"print('''XTRAIN {}   \nXVAL{}   \nXTEST{}'''.format(np.shape(xtrain),np.shape(xval),np.shape(test)))","19aea337":"from sklearn.model_selection import cross_val_score","940f5fad":"# ########## lasso ######### {update :- it didn't help}\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n# lasso = make_pipeline(RobustScaler(), Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.00001, warm_start=False, positive=False, random_state=None, selection='cyclic'))","c126f2d6":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import ElasticNet,BayesianRidge\nfrom sklearn.preprocessing import RobustScaler\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))","b28b7f44":"import lightgbm as lgb\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.03, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","4a2b7e41":"from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)","bbee50ed":"from sklearn.kernel_ridge import KernelRidge\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)","38351968":"from xgboost import XGBRegressor,XGBRFRegressor\nfrom lightgbm import LGBMRegressor","43a52fb2":"######### CV #########\n\n#previous 1000\nscores=-1 * cross_val_score(XGBRegressor(n_estimators=2200,learning_rate=0.05),xtrain,ytrain,cv=5,scoring=\"neg_mean_absolute_error\")","72416db3":"val_score=scores.mean()","44b4a5a0":"print(val_score)","aaf95531":"#LASSO\n# model1=lasso\n# model1.fit(xtrain,ytrain)","84a2fd99":"#LGB\nmodel_lgb.fit(xtrain,ytrain)","7bbffc67":"#GrBOOST\nGBoost.fit(xtrain,ytrain)","9f5a6b8e":"#KKR\nKRR.fit(xtrain,ytrain)","63c45835":"#ENET\nENet.fit(xtrain,ytrain)\n","7b95d202":"#XGBOOST\nmodel=XGBRegressor(n_estimators=2200,learning_rate=0.05)\nmodel.fit(xtrain,ytrain)#,early_stopping_rounds=5,eval_set=[(xval,yval)],verbose=False)","007feda2":"x=model.predict(test)","548a2039":"# y=model1.predict(test)\n# y=np.expm1(y)","ef6af75a":"x=np.expm1(x)","64634f5d":"z=model_lgb.predict(test)\nz=np.expm1(z)","81373252":"q=GBoost.predict(test)\nq=np.expm1(q)","771c7473":"w=KRR.predict(test)\nw=np.expm1(w)","7c996a56":"e=ENet.predict(test)\ne=np.expm1(e)","f2fa4641":"x=(0.15*x+0.15*z)+0.7*(q+e+w)\/3\n","e07f0696":"output = pd.DataFrame({'Id': test_ID,\n                       'SalePrice': x})\noutput.to_csv('submission.csv', index=False)","515cd742":"print(\"That's all Folks !\")","77b36cf1":"## *LABEL ENCODING OF CATEGORICAL FEATURES*:-\n\n### Label encoding categorical features as 'SalePrice'  depend on the individual order in which these categorical features are given","dde0d5aa":"### *Missing values*:-\n### We have a lot of features to handel (81 in total), so there is a potential chance for missing values","8f8e7a0f":" Predict sales prices and practice feature engineering, RFs, and gradient boosting\n![image.png](attachment:image.png)\n \n ","73208d2d":"## *USING Multiple Models for final prediction* :-\n\n### Now I'll be using variour regression models and then will take their weighted average for final prediction on *test*","16f4e0af":"### Now lets analyse our target i.e **SalePrice**, and see how it is distributed","32b25172":"## Visualizing Scatter plots of various features with *target* SalePrice","9270f75f":"# Multi-model Advanced Regression:  House Prices","82e3e7ab":"### **Normalizing NUMERICAL_COLUMNS to be between [0,1]**","6e2398e1":" ## Importing libraries","59ba8b37":"### Now let's handel skew in all numerical features","bf726013":"## *Numerically represented categorical values*:-\n\n### Some of the features are represented in numbers<int64>, when they should be in 'string' representing categorical features","9fb270b0":"### Again using log transformation to remove skewness {as all of the numerical features have positive skew}","5b562aa4":"### Removing potential Outlier data points { After careful analysis of the above scatter plots }","41a1c635":"### As we can see that *target* is right skewed, we will perform log transform ","b1cf701c":" ### *Observation*:-   All of them have positive skew"}}