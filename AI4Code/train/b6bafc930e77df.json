{"cell_type":{"2b91fc0f":"code","a67535d4":"code","213a5aaf":"code","9fd7f976":"code","7cf8a453":"code","2a02b773":"code","a5781e5d":"code","974077fd":"code","d7d47ac9":"code","70fb0549":"code","1d44065c":"code","e7294e2f":"code","e0798806":"markdown"},"source":{"2b91fc0f":"#!pip install -q pydicom\n#!pip3 install -q tqdm \n#!pip3 install -q imgaug\n#!pip3 install -q kaggle\n#!pip3 install -q pypng\n#!pip3 install -q pillow\n#!pip3 install PyDrive","a67535d4":"import os \nimport sys\nimport shutil\nimport glob\nimport png\nimport itertools\nimport pydicom # for reading dicom files\nimport os # for doing directory operations \nimport pandas as pd # for some simple data analysis (right now, just to load in the labels data and quickly reference it)\n\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport numpy as np\nimport cv2\n","213a5aaf":"# enter your Kaggle credentionals here ,  you can create tokens from you profile page\nos.environ['KAGGLE_USERNAME']=\"username\"\nos.environ['KAGGLE_KEY']=\"key\"","9fd7f976":"# run from 'content' directory\n# Root directory of the project\nos.mkdir('..\/content\/RSNAdata')\nROOT_DIR = os.path.abspath('..\/content\/RSNAdata')\nos.chdir(ROOT_DIR)","7cf8a453":"#!kaggle competitions download -c rsna-pneumonia-detection-challenge","2a02b773":"# unzipping takes a few minutes\n#!unzip -q -o stage_1_test_images.zip -d stage_1_test_images\n#!unzip -q -o stage_1_train_images.zip -d stage_1_train_images\n#!unzip -q -o stage_1_train_labels.csv.zip","a5781e5d":"os.chdir('..\/')\ndata_dir = '..\/content\/RSNAdata\/stage_1_train_images\/'\npatients = os.listdir(data_dir)\nlabels_df = pd.read_csv('..\/content\/RSNAdata\/stage_1_train_labels.csv')\n\nlabels_df.head()","974077fd":"#merges the train labels and detailed class\n\nclass_info_df = pd.read_csv('..\/content\/RSNAdata\/stage_1_detailed_class_info.csv.zip')\ntrain_labels_df = pd.read_csv('..\/content\/RSNAdata\/stage_1_train_labels.csv')\n\ntrain_class_df = train_labels_df.merge(class_info_df, left_on='patientId', right_on='patientId', how='inner')\n\ntrain_class_df.head()","d7d47ac9":"os.mkdir('..\/content\/Target_0NN_PNGs')    #create folder to store png files, here 0NN = No Lung Opacity \/ Not Normal","70fb0549":"#batch conversion using PyPNG\n\ndef convertDCMtoPNG():\n\n    img_data = list(train_class_df.T.to_dict().values())\n     \n    for i ,data_row in enumerate(itertools.islice(img_data, 0, None)):\n      try:\n        if data_row['class']=='No Lung Opacity \/ Not Normal':\n            patientImage = data_row['patientId']+'.dcm'\n            imagePath = os.path.join(\"..\/content\/RSNAdata\/stage_1_train_images\/\", patientImage)\n            data_row_img_data = pydicom.read_file(imagePath)\n            data_row_img = pydicom.dcmread(imagePath)\n            shape = data_row_img.pixel_array.shape\n        \n   # Convert to float to avoid overflow or underflow losses.\n            image_2d = data_row_img.pixel_array.astype(float)\n    \n       # Rescaling grey scale between 0-255\n            image_2d_scaled = (np.maximum(image_2d,0) \/ image_2d.max()) * 255.0\n\n    # Convert to uint\n            image_2d_scaled = np.uint8(image_2d_scaled)\n\n    # Write the PNG file\n            download_location = os.path.join('..content\/Target_0NN_PNGs', data_row['patientId'] + '.png')\n            with  open(data_row['patientId'] + '.png','wb') as png_file:\n                  w = png.Writer(shape[1], shape[0], greyscale=True)\n                  w.write(png_file, image_2d_scaled)\n            shutil.move(data_row['patientId'] + '.png', '..\/content\/Target_0NN_PNGs\/')\n        else:\n            continue\n      except:\n        \n        if os.path.exists(download_location):\n            copy = False\n            continue","1d44065c":"#convertDCMtoPNG()","e7294e2f":"#adds a zip with all the pngs to your drive\n\nfilename = \"target_0_NN\" #@param {type:\"string\"}\nfolders_or_files_to_save = \"Target_0NN_PNGs\" #@param {type:\"string\"}\nfrom google.colab import files\nfrom google.colab import auth\nfrom googleapiclient.http import MediaFileUpload\nfrom googleapiclient.discovery import build\n\ndef save_file_to_drive(name, path):\n    file_metadata = {\n    'name': name,\n    'mimeType': 'application\/octet-stream'\n    }\n\n    media = MediaFileUpload(path, \n                  mimetype='application\/octet-stream',\n                  resumable=True)\n\n    created = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n\n    print('File ID: {}'.format(created.get('id')))\n\n    return created\n\nextension_zip = \".zip\"\nzip_file = filename + extension_zip\n\n!zip -r $zip_file {folders_or_files_to_save} # FOLDERS TO SAVE INTO ZIP FILE\n\nauth.authenticate_user()\ndrive_service = build('drive', 'v3')\n\ndestination_name = zip_file\npath_to_file = zip_file\nsave_file_to_drive(destination_name, path_to_file)","e0798806":"The original code is on colaboratory so the below will not run on Kaggle.\n\nI combined a few functions and some code from the earlier EDA kernels so if you see your code, just let me know and I'll source you.\n\nThis is my first public kernel so sorry for any obscurity.\n\nhttps:\/\/colab.research.google.com\/drive\/1reOc-bBi2CNBZ94rHsy86dMJbm9KwJGU"}}