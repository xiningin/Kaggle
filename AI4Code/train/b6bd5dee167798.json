{"cell_type":{"d53ec2a7":"code","080005c6":"code","8ad7d752":"code","66a2f7ac":"code","7c03924c":"code","ff7e9b0d":"code","78404acb":"code","cf6619ca":"code","1dce4b7e":"code","60dcd24b":"code","c6d59c13":"code","8d14a970":"code","ba14b380":"code","1916f4ea":"code","79c5dffa":"code","517be0d5":"code","b25376e8":"code","a9bd05c2":"code","cc5230ef":"code","d0817667":"code","74adf7c5":"code","e700caf3":"code","38ece832":"code","b1ed285e":"code","a0b1d222":"code","431d5e41":"code","63291a3d":"code","bc043b95":"code","2d83ecae":"code","0256fb07":"code","16f03c49":"code","7139cd44":"code","6636d588":"code","d66bb4a5":"code","65bd7974":"code","c16e088f":"code","94868c63":"code","ab6fbcfa":"code","0e994473":"code","cad78f9a":"code","2d57ca77":"code","7b5bb9ef":"code","54b2b40f":"code","cb7c6a8a":"code","496e78ef":"code","cf15c6af":"code","f9e94cf8":"code","d826c649":"code","1ddfebc3":"code","4877093e":"code","0fa117d6":"code","cb9d8959":"code","29e443a2":"code","f6618df6":"code","92a9a23c":"code","cad37b15":"code","0cb3dbbd":"code","39e8174a":"code","d788a747":"code","5d824e7a":"code","a45f19d7":"code","3ad7daad":"code","d76487a7":"code","6df287de":"code","6e110f94":"code","9d35e8d4":"markdown","112ed2d3":"markdown","cac5e5db":"markdown","44ae5dbd":"markdown","96eb6a5e":"markdown","7fff290b":"markdown","b1d9eb0c":"markdown","02db8c5e":"markdown","d344dd1f":"markdown","ac255110":"markdown","d0cf720f":"markdown","807cac66":"markdown","1057cfb6":"markdown","507ce146":"markdown","90ab34bc":"markdown","95d3b120":"markdown","a656bd65":"markdown","eed50df6":"markdown","85a8a693":"markdown","d6b0cecd":"markdown","1ef77dbe":"markdown","1afa135b":"markdown","efc48161":"markdown","fd50bf0c":"markdown","c5a8da95":"markdown"},"source":{"d53ec2a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict","080005c6":"df = pd.read_csv('..\/input\/data-scientist-jobs\/DataScientist.csv')\ndf.shape","8ad7d752":"df.head()","66a2f7ac":"states_df = pd.read_csv('..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv')","7c03924c":"states_df.head()","ff7e9b0d":"print(df.isnull().any()) # To check whether any column in dataset has null values\ndf = df.drop(columns = [\"Unnamed: 0\",\"Easy Apply\",\"Competitors\",\"index\"]) # dropping the columns which I will not use for analysis\ndf.shape # Check the shape of the dataset -> Rows and Columns","78404acb":"df = df[~df[\"Salary Estimate\"].str.contains(\"Per Hour\")] # Removing the salary estimates given as per hour basis\ndf.shape # only 4 rows were deleted","cf6619ca":"df[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"(Glassdoor est.)\", \"\",regex=True) # Remove the \"Glassdoor est.\" keyword\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"(Employer est.)\", \"\",regex=True)  # Remove the \"Employer est.\" Keyword\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"K\", \"\",regex=True) # Remove the Letter K\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.strip('()')) # Remove the \"()\" from the end\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"$\", \"\",regex=True) # Remove the dollar '$' sign\ndf[\"Salary Estimate\"] = df[\"Salary Estimate\"].replace(\"-\", \" \",regex=True) # Remove the '-' sign","1dce4b7e":"df[\"Salary Estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.strip(' ')) # Remove the whitespaces\ndf[['Salary Estimate Lower Bound','Salary Estimate Upper Bound']] = df[\"Salary Estimate\"].str.split(\" \",expand=True) # split the Salary Estimate into upper and lower bound\ndf = df.drop(columns = \"Salary Estimate\") # drop the salary estimate column","60dcd24b":"df[\"Salary Estimate Lower Bound\"] = df[\"Salary Estimate Lower Bound\"].replace({'\\$':\"\"},regex=True) # Remove the dollar '$' sign from lower bound\ndf[\"Salary Estimate Upper Bound\"] = df[\"Salary Estimate Upper Bound\"].replace({'\\$':\"\"},regex=True) # Remove the dollar '$' sign from upper bound","c6d59c13":"df[\"Salary Estimate Lower Bound\"] = df[\"Salary Estimate Lower Bound\"].astype(str).astype(int) # Convert the column from string to integer\ndf[\"Salary Estimate Upper Bound\"] = df[\"Salary Estimate Upper Bound\"].astype(str).astype(int) # Convert the column from string to integer","8d14a970":"df[\"Size\"] = df[\"Size\"].replace(\"employees\", \"\",regex=True)  # Remove the \"employees\" keyword\ndf[\"Size\"] = df[\"Size\"].replace(\"to\", \" \",regex=True) # Remove the \"to\" keyword\ndf[\"Size\"] = df[\"Size\"].replace({'\\+':\" 0\"},regex=True) # Remove the \"+\" sign\n","ba14b380":"df[\"Size\"] = df[\"Size\"].apply(lambda x: x.strip(' ')) # Remove the whitespaces\ndf[\"Size\"] = df[\"Size\"].replace(\"   \", \" \",regex=True) # Replace double space with single space so that we can split the column\ndf[['Size Lower Bound','Size Upper Bound']] = df[\"Size\"].str.split(\" \",expand=True) # Split the Size column in upper and lower bound\ndf = df.drop(columns = \"Size\") # drop the Size column","1916f4ea":"df[\"Size Upper Bound\"] = df[\"Size Upper Bound\"].replace(\"0\", \"10001\") \ndf[\"Size Lower Bound\"] = df[\"Size Lower Bound\"].replace(\"10000\", \"0\")","79c5dffa":"df['Company Name'] = df[\"Company Name\"].str.partition(\"\\n\")","517be0d5":"df[\"Size Lower Bound\"] = df[\"Size Lower Bound\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Type of ownership\"] = df[\"Type of ownership\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Industry\"] = df[\"Industry\"].replace(\"-1\", \"Unknown\",regex=True)\ndf[\"Sector\"] = df[\"Sector\"].replace(\"-1\", \"Unknown\",regex=True)","b25376e8":"def filter_revenue(x):\n    revenue=0\n    if(x== 'Unknown \/ Non-Applicable' or type(x)==float):\n        revenue=0                                                                                   # Max Revenue will be 0 if the range is Unknown or non-applicable \n    elif(('million' in x) and ('billion' not in x)):\n        maxRev = x.replace('(USD)','').replace(\"million\",'').replace('$','').strip().split('to')    # Remove the words such as: USD, million, $, to\n        if('Less than' in maxRev[0]):\n            revenue = float(maxRev[0].replace('Less than','').strip())                              # Remove the \"less than\" keyword and also remove the whitespaces\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])\n            elif(len(maxRev)<2): \n                revenue = float(maxRev[0])\n    elif(('billion'in x)):\n        maxRev = x.replace('(USD)','').replace(\"billion\",'').replace('$','').strip().split('to')    # Remove the words such as: USD, billion, $, to\n        if('+' in maxRev[0]):\n            revenue = float(maxRev[0].replace('+','').strip())*1000                                 #  Remove the \"+\" sign and also remove the whitespaces\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])*1000\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])*1000\n    return revenue","a9bd05c2":"df['Max_revenue']=df['Revenue'].apply(lambda x: filter_revenue(x))","cc5230ef":"states_df = states_df.drop(columns = [\"country_code\",\"usa_state\",\"country\",\"latitude\",\"longitude\"])","d0817667":"states_df = states_df.dropna() # drop the null values","74adf7c5":"df[['City','State']] = df[\"Location\"].str.split(\",\",expand=True) \ndf = df[~df[\"State\"].str.contains(\"United Kingdom\")] # Removing United Kingdom from state!","e700caf3":"df['State'] = df['State'].str.lstrip() # Remove the whitespaces from front\nlatitude = states_df['usa_state_latitude'].to_list() # Make a list of all the states \nlongitude = states_df['usa_state_longitude'].to_list() # Make a list of all the latitudes of a state\nstates = states_df['usa_state_code'].to_list() # Make a list of all the longitudes of a state","38ece832":"def find_latitude(x,states,latitude):\n    index = states.index(x)\n    return latitude[index]","b1ed285e":"def find_longitude(x,states,longitude):\n    index = states.index(x)\n    return longitude[index]","a0b1d222":"df['latitude']= df['State'].apply(lambda x: find_latitude(x,states,latitude))\ndf['longitude']= df['State'].apply(lambda x: find_longitude(x,states,longitude))","431d5e41":"df","63291a3d":"df1 = df[df[\"Rating\"]>1]\nsns.distplot(df1[\"Rating\"],)\nplt.title('Distribution of Ratings Column')\nplt.show()","bc043b95":"plt.hist(df1['Rating'], density=True, cumulative=True, label='CDF',histtype='step');","2d83ecae":"sns.distplot(df[\"Salary Estimate Lower Bound\"])\nplt.title('Distribution of Salary Estimate Lower Bound Column')\nplt.show()","0256fb07":"sns.distplot(df[\"Salary Estimate Upper Bound\"])\nplt.title('Distribution of Salary Estimate Lower Bound Column')\nplt.show()","16f03c49":"plt.figure(figsize = (15,5))\n\ndf[\"Company Name\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color = \"orange\",fontsize=12, edgecolor='Red', linewidth = 2)\nplt.title(\"Top 20 Company with Highest number of Jobs in Data Science\")\nplt.xlabel(\"Company Name\",fontsize=15)\nplt.ylabel(\"Count\")\n\nplt.show()","7139cd44":"plt.figure(figsize = (15,5))\ndf[\"Job Title\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color= \"Red\", fontsize=12, edgecolor='green',linewidth = 2)\nplt.title(\"Top 20 Data Science Job\")\nplt.xlabel(\"Job Title\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","6636d588":"plt.figure(figsize = (10,5))\ndf[\"Location\"].value_counts().sort_values(ascending=False).head(20).plot.bar(color= \"Blue\", fontsize=12)\nplt.title(\"Top 20 locations for Data Science Job\")\nplt.xlabel(\"Locations\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","d66bb4a5":"plt.figure(figsize = (50,8))\ndf[\"Headquarters\"].value_counts().sort_values(ascending=False).head(15).plot.pie(y=\"Headquarters\",autopct=\"%0.1f%%\")\nplt.title(\"Head Quarters according to Locations\")\nplt.axis(\"off\")\nplt.show()","65bd7974":"plt.figure(figsize = (10,5))\ndf[\"Type of ownership\"].value_counts().sort_values(ascending=False).plot.bar(color= \"Orange\",fontsize=12)\nplt.title(\"Types of Ownership\")\nplt.xlabel(\"Ownership\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","c16e088f":"plt.figure(figsize = (10,5))\ndf[\"Sector\"].value_counts().sort_values(ascending=False).plot.bar(color= \"red\",fontsize=12)\nplt.title(\"Different types of Sectors in DataScience\")\nplt.xlabel(\"Sectors\",fontsize=15)\nplt.ylabel(\"Count\")\nplt.show()","94868c63":"plt.figure(figsize = (10,5))\ndf[\"Founded\"].value_counts().sort_values(ascending=False)[1:21].plot.bar(color= \"Green\",fontsize=12)\nplt.title(\"Number of Company, Founded in a Year\",fontsize=20)\nplt.xlabel(\"Foundation Year\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.show()","ab6fbcfa":"ax = sns.boxplot(x=df[\"Rating\"])","0e994473":"df2 = df.groupby('Sector')[['Max_revenue']].mean().sort_values(['Max_revenue'],ascending=False).head(20)","cad78f9a":"df2.head(20)","2d57ca77":"df2.reset_index(inplace=True)\nplt.figure(figsize=(10,5))\nchart = sns.barplot(\n    data=df2,\n    x='Sector',\n    y='Max_revenue'\n)\nchart.set_xticklabels(\n    chart.get_xticklabels(), \n    rotation=65, \n    horizontalalignment='right',\n    fontweight='light',\n \n)\nchart.axes.yaxis.label.set_text(\"Revenue(Million dollars)\")","7b5bb9ef":"df3 = df.groupby('Industry')[['Max_revenue']].mean().sort_values(['Max_revenue'],ascending=False).head(20)","54b2b40f":"df3.reset_index(inplace=True)\nplt.figure(figsize=(10,5))\nchart = sns.barplot(\n    data=df3,\n    x='Industry',\n    y='Max_revenue',\n    palette='Set1'\n)\nchart.set_xticklabels(\n    chart.get_xticklabels(), \n    rotation=65, \n    horizontalalignment='right',\n    fontweight='light',\n \n)\nchart.axes.yaxis.label.set_text(\"Revenue(Million dollars)\")\n","cb7c6a8a":"from wordcloud import WordCloud\njob_title=df['Job Title'][~pd.isnull(df['Job Title'])]\nwordCloud = WordCloud(background_color = 'lightpink',width=2000,height= 2000).generate(' '.join(job_title))\nplt.figure(figsize=(19,9))\nplt.axis('off')\nplt.title(df['Job Title'].name,fontsize=20)\nplt.imshow(wordCloud)\nplt.show()","496e78ef":"pg_lan = [\"python\",\"c++\",\"java\",\"matlab\",\".net\",\"c#\",\"javascript\",\"html\",\"bash\"]\nbig_data = [\"big data\",\"hadoop\",\"spark\",\"impala\",\"cassandra\",\"kafka\",\"hdfs\",\"hbase\",\"hive\"]\nexp_edu = [\"experience\",\"bs\",\"ms\",\"phd\",\"full-time\",\"intern\",\"remote\",\"master\",\"doctorate\",\"computer science\",\"bachelor\"]\ncloud = [\"aws\",\"gcp\",\"azure\",\"s3\",\"redshift\",\"ec2\",\"lambda\",\"route s3\",\"dynamo db\"]\nds_ml = [\"time series\",\"machine learning\",\"regression\",\"stat\",\"numpy\",\"pandas\",\"data visualization\",\"data analysis\",\"time series\",\"data cleaning\",\"deep learning\"]\nother_skills = [\"sql\",\"mongo db\",\"excel\",\"sas\",\"nosql\",\"communication\"]\njob = df[\"Job Description\"].tolist()","cf15c6af":"job = [x.lower() for x in job]","f9e94cf8":"pg_lan_required = defaultdict()\nfor item in pg_lan:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    pg_lan_required[item] = counter\n\npg_lan_df = pd.DataFrame(list(pg_lan_required.items()),columns = ['Programming Langauge','count']) \npg_lan_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","d826c649":"plt.figure(figsize = (15,5))\nx = pg_lan_df[\"Programming Langauge\"]\ny = pg_lan_df[\"count\"]\nplt.bar(x,y,color= \"blue\")\nplt.title(\"Top programming languages requrired by the companies\",fontsize=15)\nplt.xlabel(\"Programming Languages\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in pg_lan_required.items():\n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","1ddfebc3":"counter = 0\nbig_data_required = defaultdict()\nfor item in big_data:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    big_data_required[item] = counter\n\nbig_data_df = pd.DataFrame(list(big_data_required.items()),columns = ['Big Data Technologies','count']) \nbig_data_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","4877093e":"plt.figure(figsize = (15,5))\nx = big_data_df[\"Big Data Technologies\"]\ny = big_data_df[\"count\"]\nplt.bar(x,y,color= \"orange\")\nplt.title(\"Top Big Data Technologies requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in big_data_required.items():\n    plt.text(k,v+5, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","0fa117d6":"exp_edu_required = defaultdict()\nfor item in exp_edu:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    exp_edu_required[item] = counter\n    \nexp_edu_df = pd.DataFrame(list(exp_edu_required.items()),columns = ['Experience\/Education','count']) \nexp_edu_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","cb9d8959":"plt.figure(figsize = (15,5))\nx = exp_edu_df[\"Experience\/Education\"]\ny = exp_edu_df[\"count\"]\nplt.bar(x,y,color= \"blue\")\nplt.title(\"Experience\/Education requrired by the companies\",fontsize=15)\nplt.xlabel(\"Experience\/Education\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in exp_edu_required.items():\n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","29e443a2":"counter = 0\ncloud_required = defaultdict()\nfor item in cloud:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    cloud_required[item] = counter\n\n\n\ncloud_df = pd.DataFrame(list(cloud_required.items()),columns = ['cloud ','count']) \ncloud_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","f6618df6":"plt.figure(figsize = (15,5))\nx = cloud_df[\"cloud \"]\ny = cloud_df[\"count\"]\nplt.bar(x,y,color= \"red\")\nplt.title(\"Top cloud computing skills requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in cloud_required.items():\n    plt.text(k,v+5, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","92a9a23c":"counter = 0\nds_ml_required = defaultdict()\nfor item in ds_ml:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    ds_ml_required[item] = counter\n\nds_ml_df = pd.DataFrame(list(ds_ml_required.items()),columns = ['Data Science\/Machine Learning Skills ','count']) \nds_ml_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","cad37b15":"plt.figure(figsize = (15,5))\nx = ds_ml_df[\"Data Science\/Machine Learning Skills \"]\ny = ds_ml_df[\"count\"]\nplt.bar(x,y,color= \"orange\")\nplt.title(\"Top data science or machine learning skills requrired by the companies\",fontsize=15)\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in ds_ml_required.items(): \n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","0cb3dbbd":"counter = 0\nother_skills_required = defaultdict()\nfor item in other_skills:\n    counter = 0\n    for it in job:\n        if item in it:\n            counter = counter + 1\n    other_skills_required[item] = counter\n\n\nother_skills_df = pd.DataFrame(list(other_skills_required.items()),columns = ['Other Skills ','count']) \nother_skills_df.sort_values([\"count\"], axis=0, ascending=False, inplace=True)","39e8174a":"plt.figure(figsize = (15,5))\nplt.title(\"other top skills required by companies\", fontsize=18)\nplt.bar(other_skills_df[\"Other Skills \"], other_skills_df[\"count\"],color= \"Green\")\nplt.xlabel(\"Skills\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\nfor k,v in other_skills_required.items(): \n    plt.text(k,v+25, str(v), fontsize=12, fontweight='bold',color='k', horizontalalignment='center');","d788a747":"import plotly.express as px\nfig = px.scatter(df, x='Rating', y='Salary Estimate Upper Bound',color=\"Rating\",hover_data=['Headquarters','Location', 'Type of ownership', 'Industry', 'Sector','Company Name'], title = \"Data Scientist jobs\")\nfig.show()","5d824e7a":"df_sal = df.groupby('Location')[['Salary Estimate Upper Bound','Salary Estimate Lower Bound']].mean().sort_values(['Salary Estimate Upper Bound','Salary Estimate Lower Bound'],ascending=False)[0:30]\ndf_sal.plot(kind=\"barh\", figsize=(16,17), width=0.8)\nplt.ylabel(\"Location\")\nplt.xlabel(\"Salary\")\nplt.title(\"Min and Max Salary From Different Location\", fontweight=\"bold\")\n\nfor index, value in enumerate(df_sal[\"Salary Estimate Upper Bound\"]):\n    plt.text(value + 0.5, index - 0.4, str(value))\n    \n    \nfor index, value in enumerate(df_sal[\"Salary Estimate Lower Bound\"]):\n    plt.text(value + 0.2, index + 0.1, str(value))","a45f19d7":"df_sal = df.groupby('Job Title')[['Salary Estimate Upper Bound','Salary Estimate Lower Bound']].mean().sort_values(['Salary Estimate Upper Bound','Salary Estimate Lower Bound'],ascending=False)[:30]\ndf_sal.plot(kind=\"barh\", figsize=(16,17), width=0.8)\nplt.ylabel(\"Job Title\")\nplt.xlabel(\"Salary\")\nplt.title(\"Min and Max Salary of different Job Title\", fontweight=\"bold\")\n\nfor index, value in enumerate(df_sal[\"Salary Estimate Upper Bound\"]):\n    plt.text(value + 0.5, index - 0.4, str(value))\n    \n    \nfor index, value in enumerate(df_sal[\"Salary Estimate Lower Bound\"]):\n    plt.text(value + 0.2, index + 0.1, str(value))","3ad7daad":"df[\"State\"].value_counts().sort_values(ascending=False).head(20)","d76487a7":"import folium\nimport folium.plugins as plugins","6df287de":"data_heat = df[['latitude','longitude','Rating']].values.tolist()","6e110f94":"import folium.plugins as plugins\n\nm = folium.Map(location=[41, -102],zoom_start=4)\n\nplugins.HeatMap(data_heat).add_to(m)\n\nm","9d35e8d4":"**Replace \"-1\" with \"Unknown\"**","112ed2d3":"**If you liked my work! Kindly Upvote!**","cac5e5db":"**This is how the dataset looks**","44ae5dbd":"<center><h1><b>Data Scientist Job Analysis<\/b><\/h1><\/center>\n\n1. Data Cleaning\n\n2. Data visualization\n\n**You can also check the same analysis on Data Analyst Jobs and Data Engineer Jobs**\n\n1. [Data Analyst Job Analysis](https:\/\/www.kaggle.com\/rohitsahoo\/data-analyst-job-analysis)\n2. [Data Engineer Job Analysis](https:\/\/www.kaggle.com\/rohitsahoo\/data-engineer-job-analysis)","96eb6a5e":"**The 10000+ range was split with a lower bound of 10000 and upper bound as null**\n\n**The lower bound is updated to 0 and the upper bound is updated to 10001.**","7fff290b":"**So most of the Head Quarters are in New York, & \"-1\" is the no. of undeclared Head Quarters in the Dataset**","b1d9eb0c":"# Data Visualization","02db8c5e":"**Split Salary Estimate into lower & upper bound**","d344dd1f":"**Let's Look at the Cummulative Distributive Function for Ratings!**","ac255110":"**There are some unnecessary columns,First drop these Columns**\n1. Index\n2. Unnamed\n3. Easy Apply\n4. Competitors\n\n***Check whether any column has Null Values***","d0cf720f":"# Data Cleaning","807cac66":"**Read the Data Scientist job dataset**","1057cfb6":"**Split the Location into City and State**","507ce146":"![image.png](attachment:image.png)","90ab34bc":"**Similary, Let's split Size of a company into lower & upper bound!**","95d3b120":"**Let's check how the dataset looks after cleaning**","a656bd65":"**To map the latitudes and longitudes to the states in the dataset we have to write a funtion!**\n\n**Here the find_function finds the latitude of a given state. It takes the input as the Abbreviation of State (Given in Dataset), list of states and latitude.**","eed50df6":"**Let's split Salary Estimate into lower & upper bound**\n\nAnd let's remove the rows having Salary on an hourly basis. We can change it and guess an estimate, but we don't know the no. of working hours","85a8a693":"**Now let's remove the \"\\n & rating\" from company Name**","d6b0cecd":"**The filter_revenue function takes the input as the range of revenue and finds the max. revenue**","1ef77dbe":"**Let's do analysis on Job Description!**\n\n**We will check how many jobs require skills such as Hadoop, Python, Machine Learning etc.?**","1afa135b":"**Let's Make a new column of max revenue of a company**","efc48161":"**For Better analysis, I have taken another dataset which consists of the latitudes and longitudes of the all the Stats in America!**","fd50bf0c":"**Clean up the Salary Estimate!**","c5a8da95":"**We don't require the codes of all the countries, since our dataset mostly deals with states in America.**"}}