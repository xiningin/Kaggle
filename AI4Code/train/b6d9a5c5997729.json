{"cell_type":{"2f4af962":"code","0787cf3a":"code","6a0b4e8c":"code","ebaca6d1":"code","6927f954":"code","0df6ce8d":"code","758f828a":"code","aa3dc900":"code","1c19f196":"code","2363d2fd":"code","9e742a43":"code","c9832842":"code","750decbb":"code","77ef193f":"markdown"},"source":{"2f4af962":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0787cf3a":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom math import sqrt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport re\nfrom sklearn.preprocessing import LabelEncoder","6a0b4e8c":"def plot_all(data):\n    data['Survived'].value_counts().plot(\n        kind='pie',\n        labels=['No','Yes'],\n        autopct='%.0f%%',\n        colors=['orange','green'])\n    plt.title(\"Survival percentage\")\n    plt.show()\n    sns.boxplot(x = train['Age'],data = data)\n    plt.title(\"Titans survival age period\")\n    plt.show()\n    data['Age'].hist(bins=40,grid=True)\n    plt.title(\"Titans age histogram\")\n    plt.show()\n    sns.barplot(x='Sex',y='Survived',data=data)\n    plt.title(\"Female vs Male\")\n    plt.show()\n    fig = plt.figure()\n    plt.figure(figsize = (12,4))\n    plt.subplot(1,2,1)\n    plt.title(\"Titans with siblings\")\n    data['SibSp'].value_counts().plot(kind='bar')\n    plt.subplot(1,2,2)\n    plt.title(\"Titans belongs to parent and childrens\")\n    data['Parch'].value_counts().plot(kind='bar',color='orange')\n    plt.show()\n    \ndef get_missing_hist(data):\n    return data.isnull().sum().sort_values(ascending=False)\n\ndef missing_data(train_data,test_data):\n    train_missing = get_missing_hist(train_data)\n    test_missing = get_missing_hist(test_data)\n    missing = pd.DataFrame(train_missing,columns=['Training'])\n    missing['Testing'] = test_missing\n    return missing","ebaca6d1":"# Using functions may helps to reduce errors\ndef get_title(name):\n    return re.search('\\w*\\.', name).group()[0:-1]\n    \ndef preprocess_data(data):\n    #  I am using functions for both test and train data such that,coding errors can be reduced\n    data['Age'].fillna(data['Age'].mean(),inplace=True)\n    data['Fare'].fillna(data['Fare'].mean(),inplace=True)\n    title = data['Name'].apply(get_title)\n    data['Title'] = title\n    data['Embarked'].fillna('S',inplace=True)\n    data.drop(['PassengerId','Ticket','Cabin','Name'],axis=1,inplace=True)\n    data[\"Fare\"] = data['Fare'].astype(int)\n    return data\n\ndef encode_category(data):\n    le = LabelEncoder()\n    encoded_title = le.fit_transform(data['Title'])\n    data['Title'] = encoded_title\n    classes = {}\n    classes['title'] = le.classes_\n    encoded_embarked = le.fit_transform(data['Embarked'])\n    data['Embarked'] = encoded_embarked\n    classes['Embarked'] = le.classes_\n    return data,classes\n\ndef print_score(y,y_pred,y_test,y_test_pred):\n    print(round(accuracy_score(y,y_pred,normalize=True)*100),'%',sep='')\n    print(round(accuracy_score(y_test['Survived'],y_test_pred,normalize=True)*100),'%',sep='')","6927f954":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ny_test = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n# missing_data(train,test)","0df6ce8d":"train = preprocess_data(train)\ntest = preprocess_data(test)\n# missing_data(train,test)","758f828a":"plot_all(train)","aa3dc900":"train,classes = encode_category(train)\ntest,_ = encode_category(test)","1c19f196":"train.head()","2363d2fd":"y = train['Survived']\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\nX['Title'] = train['Title']\n# X['Embarked'] = train['Embarked']\n# X['Fare'] = train['Fare']\nX_test = pd.get_dummies(test[features])\nX_test['Title'] = test['Title']\n# X_test['Embarked'] = test['Embarked']\n# X_test['Fare'] = test['Fare']","9e742a43":"lr = LogisticRegression()\nlr.fit(X,y)\nY_pred = lr.predict(X)\nY_test_pred = lr.predict(X_test)\nprint_score(y,Y_pred,y_test,Y_test_pred)","c9832842":"model = RandomForestClassifier(n_estimators = 100, max_depth = 5, random_state = 1)\nmodel.fit(X, y)\nY_test_pred = model.predict(X_test)\nY_pred = model.predict(X)\nprint_score(y,Y_pred,y_test,Y_test_pred)","750decbb":"output = pd.DataFrame({'PassengerId': y_test.PassengerId, 'Survived': Y_test_pred})\noutput.to_csv('my_submission.csv', index = False)\nprint('Your submission was successfully saved!')","77ef193f":"**Notes**\n* Without title(Mr.|Ms. etc.) column accurancy of test getting 97% which seems to be something wrong in my view, Please correct me if i am wrong\n* Including Fare in model gives accuracy of train 84% and testing 92%\n* pd.get_dummies gives me more features, so i use Labelencoder for Title column, Suggest me if i am wrong"}}