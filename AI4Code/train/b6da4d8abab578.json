{"cell_type":{"48546cdf":"code","630c91f6":"code","c0c6f805":"code","b44060e2":"code","e8eae1c2":"code","972f3599":"code","a4a52bd0":"code","49a75e8c":"code","caeedb7d":"code","aeb26ed5":"code","0baf3a25":"code","9c1f63e1":"code","5cc19bbc":"code","b03a7913":"code","95437a81":"code","087413ec":"code","531d660b":"code","5312ff1c":"markdown","252c6849":"markdown","4f976992":"markdown","8a5fc895":"markdown","49a629e6":"markdown","8ba61661":"markdown","44039e74":"markdown","d5933731":"markdown","056f959f":"markdown","18cd8369":"markdown","035d878e":"markdown","3848a26f":"markdown","67d394f1":"markdown","c56f549c":"markdown"},"source":{"48546cdf":"!wget https:\/\/bit.ly\/fruits_300_data -O fruits_300.npy","630c91f6":"import numpy as np\nfrom sklearn.decomposition import PCA\n\nimport matplotlib.pyplot as plt","c0c6f805":"NPY_FILE_NAME = 'fruits_300.npy'\nIMAGE_SIZE = 100\nTOTAL_ONE_IMAGE_SIZE = IMAGE_SIZE * IMAGE_SIZE\nSEED = 2021\n\nN_COMPONENTS = 50","b44060e2":"fruits = np.load(NPY_FILE_NAME)\nfruits[:5]","e8eae1c2":"fruits_2d = fruits.reshape(-1, TOTAL_ONE_IMAGE_SIZE)\nfruits_2d[:5]","972f3599":"pca = PCA(n_components=N_COMPONENTS)\npca.fit(fruits_2d)","a4a52bd0":"pca.components_.shape","49a75e8c":"DISPLAY_COL_SIZE = 10\nCMAP = 'gray_r'","caeedb7d":"def draw_images(arr, ratio=1):\n    n = len(arr)  \n   \n    rows = int(np.ceil(n\/DISPLAY_COL_SIZE))\n  \n    cols = n if rows < 2 else DISPLAY_COL_SIZE\n    fig, axs = plt.subplots(rows, cols, \n                            figsize=(cols*ratio, rows*ratio), squeeze=False)\n    for i in range(rows):\n        for j in range(cols):\n            if i*DISPLAY_COL_SIZE + j < n:   \n                axs[i, j].imshow(arr[i*DISPLAY_COL_SIZE + j], cmap=CMAP)\n            axs[i, j].axis('off')\n    plt.show()","aeb26ed5":"print(fruits_2d.shape)","0baf3a25":"fruits_pca = pca.transform(fruits_2d)","9c1f63e1":"print(fruits_pca.shape)","5cc19bbc":"fruits_inverse = pca.inverse_transform(fruits_pca)\nprint(fruits_inverse.shape)","b03a7913":"fruits_reconstruct = fruits_inverse.reshape(-1, IMAGE_SIZE, IMAGE_SIZE)","95437a81":"for start in [0, IMAGE_SIZE, IMAGE_SIZE*2]:\n    draw_images(fruits_reconstruct[start:start+IMAGE_SIZE])\n    print(\"\\n\")","087413ec":"print(np.sum(pca.explained_variance_ratio_))","531d660b":"plt.plot(pca.explained_variance_ratio_)","5312ff1c":"# preprocess data (3d data => 2d data)","252c6849":"# make pca model for dimension reduction","4f976992":"# load data (3d data)","8a5fc895":"# 2d data = > 3d data ","49a629e6":"# plot data ","8ba61661":"# apply inverse => original dimension ","44039e74":"# apply pca model => dimension reduction","d5933731":"92% explained image","056f959f":"# plot image","18cd8369":"# fetch data ","035d878e":"# global variables","3848a26f":"Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. \n\nThe input data is centered but not scaled for each feature before applying the SVD.\n\nIt uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.\n\nIt can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD","67d394f1":"# get explained_variance_ratio_","c56f549c":"# Principal component analysis (PCA)"}}