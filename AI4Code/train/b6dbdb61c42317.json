{"cell_type":{"28e07029":"code","500bb7f8":"code","064d6a05":"code","2d8d34f4":"code","186115dd":"code","8b682eb3":"code","1970c510":"code","f156eff2":"code","996328dd":"code","ba176e94":"code","41dfb4d9":"code","d584d3a0":"code","f40f9aea":"code","4339c7e1":"code","71bc6b16":"code","d072f266":"code","46d2c293":"code","b3aa5563":"code","4de81339":"code","ac50f99b":"code","8336f2e9":"code","a694b4b5":"code","2c4cb024":"code","a4319cb1":"code","c2d343fa":"code","0bd9ca42":"code","81fd43af":"code","5cb14622":"code","4af6d928":"code","d4f86cd0":"code","2dc388bc":"code","e5400480":"code","8b59f3aa":"code","58078f23":"code","88d999b4":"code","30dfeed2":"code","e47f4810":"code","ecaa11c3":"code","2808def2":"code","6fcee692":"code","81804a36":"code","eadd55fb":"code","c278cd18":"code","ee392393":"code","4e0f8070":"code","e2da97d3":"code","d9692ac7":"code","8b1d0a07":"code","3d33106c":"code","7478fff3":"code","74fbf28f":"code","d57b44b0":"code","286120ed":"code","df1a3a8a":"code","8d75b854":"code","4231d50d":"code","b2459441":"code","329b7b98":"code","12cf77ea":"code","7dc304b5":"code","1a83e29c":"code","cb8f6e48":"code","bc0c83bb":"markdown","7b19f4b0":"markdown","a805d8e2":"markdown","be407c62":"markdown","78dc5884":"markdown","e5c47a6a":"markdown","27bfc6a1":"markdown","35ae87df":"markdown","ead1e0e3":"markdown","1ac090f4":"markdown","7dfe573a":"markdown","e53a8d2a":"markdown","4cd587ff":"markdown","db172a9d":"markdown","2920357d":"markdown","769873e8":"markdown","38b0bbba":"markdown","325fd0fd":"markdown","cbaa21e1":"markdown","7374dd73":"markdown","8f77bb97":"markdown","2dbee286":"markdown","0c521af8":"markdown","2bc71097":"markdown"},"source":{"28e07029":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","500bb7f8":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder","064d6a05":"df = pd.read_csv(\"\/kaggle\/input\/bluebook-for-bulldozers\/trainandvalid\/TrainAndValid.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/bluebook-for-bulldozers\/Test.csv\")","2d8d34f4":"df.head()","186115dd":"df.describe()","8b682eb3":"df.info()","1970c510":"total = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\nmissing_data.head()","f156eff2":"df['YearMade'].unique()","996328dd":"df['datasource'].unique()","ba176e94":"df['SalePrice'] = np.log(df['SalePrice'])","41dfb4d9":"from sklearn.linear_model import LinearRegression\n\nlinear_regressor = LinearRegression()","d584d3a0":"from xgboost import XGBRegressor\n\nxgb_regressor = XGBRegressor()","f40f9aea":"from sklearn.ensemble import RandomForestRegressor\n\nrandom_forest_regressor = RandomForestRegressor()","4339c7e1":"from sklearn.neighbors import KNeighborsRegressor\n\nk_neighbors_regressor = KNeighborsRegressor()","71bc6b16":"features1 = ['YearMade', 'datasource'] \ny = ['SalePrice']\n\nX1 = df[features1]\ny = df[y]","d072f266":"from sklearn.preprocessing import LabelEncoder","46d2c293":"encoder = LabelEncoder()\n\ndf['state'] = encoder.fit_transform(df.state)\ndf['fiBaseModel'] = encoder.fit_transform(df.fiBaseModel)\ndf['fiProductClassDesc'] = encoder.fit_transform(df.state)\ndf['fiModelDesc'] = encoder.fit_transform(df.fiBaseModel)","b3aa5563":"features2 = ['YearMade', 'datasource', 'state', 'fiBaseModel']\n\nX2 = df[features2]","4de81339":"features3 = ['YearMade', 'datasource', 'state', 'fiBaseModel', 'fiProductClassDesc' , 'fiModelDesc']\n\nX3 = df[features3]","ac50f99b":"X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y, test_size=0.3)","8336f2e9":"X_train2, X_val2, y_train2, y_val2 = train_test_split(X2, y, test_size=0.3)","a694b4b5":"X_train3, X_val3, y_train3, y_val3 = train_test_split(X3, y, test_size=0.3)","2c4cb024":"linear_regressor.fit(X_train1, y_train1)\n\npred_y_val1 = linear_regressor.predict(X_val1)","a4319cb1":"score_lr_1 = np.sqrt(mean_squared_error(pred_y_val1, y_val1))\nscore_lr_1","c2d343fa":"xgb_regressor.fit(X_train1, y_train1)\n\npred_y_val1 = xgb_regressor.predict(X_val1)","0bd9ca42":"score_xgb_1 = np.sqrt(mean_squared_error(pred_y_val1, y_val1))\nscore_xgb_1","81fd43af":"random_forest_regressor.fit(X_train1, y_train1)\n\npred_y_val1 = random_forest_regressor.predict(X_val1)","5cb14622":"score_rf_1 = np.sqrt(mean_squared_error(pred_y_val1, y_val1))\nscore_rf_1","4af6d928":"k_neighbors_regressor.fit(X_train1, y_train1)\n\npred_y_val1 = k_neighbors_regressor.predict(X_val1)","d4f86cd0":"score_kn_1 = np.sqrt(mean_squared_error(pred_y_val1, y_val1))\nscore_kn_1","2dc388bc":"models = pd.DataFrame({\n    'Model': ['Linear Regression', 'XGB Regressor', 'Random Forest Regressior', 'KNeighbors Regressor'],\n    'Score': [score_lr_1, score_xgb_1, score_rf_1, score_kn_1 ]})\nmodels.sort_values(by='Score', ascending=False)","e5400480":"linear_regressor.fit(X_train2, y_train2)\n\npred_y_val2 = linear_regressor.predict(X_val2)","8b59f3aa":"score_lr_2 = np.sqrt(mean_squared_error(pred_y_val2, y_val2))\nscore_lr_2","58078f23":"xgb_regressor.fit(X_train2, y_train2)\n\npred_y_val2 = xgb_regressor.predict(X_val2)","88d999b4":"score_xgb_2 = np.sqrt(mean_squared_error(pred_y_val2, y_val2))\nscore_xgb_2","30dfeed2":"random_forest_regressor.fit(X_train2, y_train2)\n\npred_y_val2 = random_forest_regressor.predict(X_val2)","e47f4810":"score_rf_2 = np.sqrt(mean_squared_error(pred_y_val2, y_val2))\nscore_rf_2","ecaa11c3":"k_neighbors_regressor2 = KNeighborsRegressor()\n\nk_neighbors_regressor2.fit(X_train2, y_train2)\n\npred_y_val2 = k_neighbors_regressor2.predict(X_val2)","2808def2":"score_kn_2 = np.sqrt(mean_squared_error(pred_y_val2, y_val2))\nscore_kn_2","6fcee692":"models = pd.DataFrame({\n    'Model': ['Linear Regression', 'XGB Regressor', 'Random Forest Regressior', 'KNeighbors Regressor'],\n    'Score': [score_lr_2, score_xgb_2, score_rf_2, score_kn_2 ]})\nmodels.sort_values(by='Score', ascending=False)","81804a36":"linear_regressor.fit(X_train3, y_train3)\n\npred_y_val3 = linear_regressor.predict(X_val3)","eadd55fb":"score_lr_3 = np.sqrt(mean_squared_error(pred_y_val3, y_val3))\nscore_lr_3","c278cd18":"xgb_regressor.fit(X_train3, y_train3)\n\npred_y_val3 = xgb_regressor.predict(X_val3)","ee392393":"score_xgb_3 = np.sqrt(mean_squared_error(pred_y_val3, y_val3))\nscore_xgb_3","4e0f8070":"random_forest_regressor.fit(X_train3, y_train3)\n\npred_y_val3 = random_forest_regressor.predict(X_val3)","e2da97d3":"score_rf_3 = np.sqrt(mean_squared_error(pred_y_val3, y_val3))\nscore_rf_3","d9692ac7":"k_neighbors_regressor3 = KNeighborsRegressor()\n\nk_neighbors_regressor3.fit(X_train3, y_train3)\n\npred_y_val3 = k_neighbors_regressor3.predict(X_val3)","8b1d0a07":"score_kn_3 = np.sqrt(mean_squared_error(pred_y_val3, y_val3))\nscore_kn_3","3d33106c":"models = pd.DataFrame({\n    'Model': ['Linear Regression', 'XGB Regressor', 'Random Forest Regressior', 'KNeighbors Regressor'],\n    'Score': [score_lr_3, score_xgb_3, score_rf_3, score_kn_3 ]})\nmodels.sort_values(by='Score', ascending=False)","7478fff3":"test.head()","74fbf28f":"test['fiModelDesc'].unique()","d57b44b0":"test['fiProductClassDesc'].unique()","286120ed":"test['fiBaseModel'].unique()","df1a3a8a":"test['state'].unique()","8d75b854":"test['fiModelDesc'] = encoder.fit_transform(test.fiModelDesc)\ntest['fiProductClassDesc'] = encoder.fit_transform(test.fiProductClassDesc)\ntest['fiBaseModel'] = encoder.fit_transform(test.fiBaseModel)\ntest['state'] = encoder.fit_transform(test.state)","4231d50d":"features = ['datasource', 'YearMade', 'state' ,'fiBaseModel', 'fiProductClassDesc', 'fiModelDesc']\n\nX = test[features]","b2459441":"pred = k_neighbors_regressor3.predict(X)\n#pred = np.exp(pred)","329b7b98":"pred.shape","12cf77ea":"pred1 = np.reshape(pred, (12457,))","7dc304b5":"pred1.shape","1a83e29c":"submission = pd.DataFrame({\n        \"Id\": test[\"SalesID\"],\n        \"SalePrice\": np.exp(pred1)\n    })\n\nsubmission.to_csv('submission.csv', index=False)","cb8f6e48":"submission = pd.read_csv('submission.csv')\nsubmission.head()","bc0c83bb":"> 4. KNeighbors Regressor ","7b19f4b0":"# Missing features in the Training Dataset #","a805d8e2":"> 2. XGB Regressor","be407c62":"****Summary of the trained models","78dc5884":"Let's define features and the target ","e5c47a6a":"## Let's split the data into training and cross-validation set","27bfc6a1":"#### Let's move to the test dataset","35ae87df":"> 1. Linear Regressor","ead1e0e3":"> 1. Linear Regressor","1ac090f4":"> 3. Random Forest Regressor","7dfe573a":"# Define the Regressors ","e53a8d2a":"****Summary of the trained models","4cd587ff":"> 3. Random Forest Regressor","db172a9d":"> 4. KNeighbors Regressor","2920357d":"2. Train the model with features YearMade, datasource, state and fiBaseModel","769873e8":"> 3. Random Forest Regressor","38b0bbba":"1. Train the model with features YearMade and datasource ","325fd0fd":"1. Train the model with features YearMade, datasource, state ,fiBaseModel, fiProductClassDesc and fiModelDesc ","cbaa21e1":"> 2. XGB Regressor ","7374dd73":"> 2. XBG Regressor","8f77bb97":"**Summary of the Trained Models**","2dbee286":"4. KNeighbors Regressor","0c521af8":"## Train the model","2bc71097":"> 1. Linear Regressor "}}