{"cell_type":{"cdf6e7cf":"code","3cd2a9d5":"code","178515e5":"code","5809372f":"code","0d6aa0f5":"code","b60ae25f":"code","08c28b5c":"code","1eec2e9d":"code","7abfb83e":"code","cfdd9f47":"code","5521f12f":"code","a038dbbf":"code","8af54b01":"code","03a30831":"code","f74f4d5b":"code","2e057a10":"code","40898a0f":"code","f2dc57a9":"code","bc9c0960":"code","793ca492":"code","e70a7176":"code","2f9be7b6":"code","ce6ceaea":"code","8c334a94":"code","fc7fd429":"code","29f36c2f":"code","f7088d47":"code","6a312340":"code","e92b82dc":"code","e8cf5cff":"code","383c01ae":"code","2a784b26":"code","084762ec":"code","7da69734":"code","9e3eb845":"code","432b986b":"code","0c7f974a":"code","c9666fda":"code","0636119b":"code","28836690":"code","d80abaec":"code","3b1dd9a9":"code","add203b0":"code","2d284ac0":"code","c3659103":"code","e08f4c67":"code","f2b59b2e":"code","c25fa751":"code","5fd1b874":"code","133ec8ff":"markdown","9bc78548":"markdown","7aa71fef":"markdown","e57b8a1f":"markdown","71cee85e":"markdown","8a479d6b":"markdown","52516fc4":"markdown","d8c09d30":"markdown","7b8e1955":"markdown","471ec016":"markdown","a2b72fc0":"markdown","765a8a95":"markdown","99706d55":"markdown","aa1b541c":"markdown","4053e0e3":"markdown","7f3ef233":"markdown","6e39ae91":"markdown","0f147fd1":"markdown","7608da78":"markdown","4ed724cf":"markdown","2d5a8430":"markdown","3067308d":"markdown","d60aa780":"markdown","66f931a6":"markdown","8b291c09":"markdown","5d0dfe0a":"markdown","44f87af9":"markdown","14e1090f":"markdown","626aea87":"markdown","225d5c0b":"markdown","19366807":"markdown","ad6b5c6d":"markdown","3663dcc2":"markdown","98948247":"markdown","07ef0d5f":"markdown","50ef758b":"markdown","d02aba74":"markdown","c770f1c7":"markdown","5954e674":"markdown","a04021e1":"markdown","990b5970":"markdown","be4d9854":"markdown","507c1fa8":"markdown","94a850c9":"markdown"},"source":{"cdf6e7cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3cd2a9d5":"#Importing all the necessary libs\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np   \nimport pandas as pd    \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier,RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nimport datetime\n\n# To build sklearn model\nfrom sklearn.linear_model import LogisticRegression\n\n# To get diferent metric scores\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,accuracy_score, recall_score, precision_score, roc_auc_score, roc_curve, confusion_matrix, precision_recall_curve\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.utils      import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint","178515e5":"data_raw = pd.read_csv(\"\/kaggle\/input\/churn-for-bank-customers\/churn.csv\") ## load the given dataset\ndata = data_raw.copy() # copy the data to new dataframe for the eda purpose\ndata.shape # find the shape of the dataset","5809372f":"data.describe().T # get the stats of teh data","0d6aa0f5":"data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True) \ndata['IsActiveMember'] = data['IsActiveMember'].astype('category')\ndata['HasCrCard'] = data['HasCrCard'].astype('category')\n#data['Exited'] = data['Exited'].astype('category')\ncat_columns=data.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\nnum_column=data.select_dtypes(include=np.number).columns.tolist()","b60ae25f":"for objCols in cat_columns:\n    tot_count = data[objCols].count().sum()\n    print(\"******\",objCols,\"******\")\n    for i,v in data[objCols].value_counts().items():\n         print(i,\"has \",v,\" rows, that makes\",round((v\/tot_count)*100,2) ,\"% of total dataset\")\n    print('*'*100)","08c28b5c":"# function to plot a boxplot and a histogram along the same scale.\n\n\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n    \"\"\"\n    Boxplot and histogram combined\n\n    data: dataframe\n    feature: dataframe column\n    figsize: size of figure (default (12,7))\n    kde: whether to the show density curve (default False)\n    bins: number of bins for histogram (default None)\n    \"\"\"\n    f2, (ax_box2, ax_hist2) = plt.subplots(\n        nrows=2,  # Number of rows of the subplot grid= 2\n        sharex=True,  # x-axis will be shared among all subplots\n        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n        figsize=figsize,\n    )  # creating the 2 subplots\n    sns.boxplot(\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n    )  # boxplot will be created and a star will indicate the mean value of the column\n    sns.histplot(\n        data=data, x=feature, kde=True, ax=ax_hist2, bins=bins, palette=\"winter\"\n    ) if bins else sns.histplot(\n        data=data, x=feature, kde=True, ax=ax_hist2\n    )  # For histogram\n    ax_hist2.axvline(\n        data[feature].mean(), color=\"green\", linestyle=\"--\"\n    )  # Add mean to the histogram\n    ax_hist2.axvline(\n        data[feature].median(), color=\"black\", linestyle=\"-\"\n    )  # Add median to the histogram","1eec2e9d":"histogram_boxplot(data, 'CreditScore')","7abfb83e":"histogram_boxplot(data, 'Age')","cfdd9f47":"histogram_boxplot(data, 'Tenure')","5521f12f":"histogram_boxplot(data, 'Balance')","a038dbbf":"histogram_boxplot(data, 'EstimatedSalary')","8af54b01":"title=['NumOfProducts','IsActiveMember',\n       'HasCrCard','Geography',\n       'Gender','Exited']\n\ncols = data[\n    [\n        \"NumOfProducts\",\n        \"IsActiveMember\",\n        \"HasCrCard\",\n        \"Geography\",\n        \"Gender\",\"Exited\"\n    ]\n].columns.tolist()\nplt.figure(figsize=(14, 20))\n\nfor i, variable in enumerate(cols):\n    plt.subplot(5, 2, i + 1)\n    order = data[variable].value_counts(ascending=False).index   \n    ax=sns.countplot(data[variable],palette='Accent')\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/len(data[variable]))\n        x = p.get_x() + p.get_width() \/ 2 - 0.05\n        y = p.get_y() + p.get_height()\n        plt.annotate(percentage, (x, y),ha='center')\n    plt.tight_layout()\n    plt.title(title[i].upper())\nplt.show()","03a30831":"sns.pairplot(data[data.select_dtypes('number').columns])\nplt.show()","f74f4d5b":"plt.figure(figsize=(15, 7))\nsns.heatmap(data.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\nplt.show()","2e057a10":"plt.figure(figsize=(15, 20))\n\nfor i, variable in enumerate(num_column):\n    plt.subplot(7, 3, i + 1)\n    sns.boxplot(data[\"Exited\"], data[variable], palette=\"spring\")\n    plt.tight_layout()\n    plt.title(variable)\nplt.show()","40898a0f":"title=['Exited vs Geography','Exited vs Gender','Exited vs Has Credit Card',\n       'Exited vs ActiveMember']\ncols = data.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\nplt.figure(figsize=(14, 20))\n\nfor i, variable in enumerate(cols):\n    plt.subplot(6, 2, i + 1)\n    ax=sns.countplot(data[variable],hue=data[\"Exited\"],palette='Pastel1')\n    ax.set_ylabel('')\n    bars = ax.patches\n    half = int(len(bars)\/2)\n    left_bars = bars[:half]\n    right_bars = bars[half:]\n\n    for left, right in zip(left_bars, right_bars):\n        height_l = left.get_height()\n        height_r = right.get_height()\n        total = height_l + height_r\n\n        ax.text(left.get_x() + left.get_width()\/2., height_l + 40, '{0:.0%}'.format(height_l\/total), ha=\"center\")\n        ax.text(right.get_x() + right.get_width()\/2., height_r + 40, '{0:.0%}'.format(height_r\/total), ha=\"center\")\n    plt.tight_layout()\n    plt.title(title[i])\nplt.show()","f2dc57a9":"plt.figure(figsize=(10,4))\nsns.distplot(data[data[\"Exited\"] == 0]['Age'], color = 'g',label='Existing Customer')\nsns.distplot(data[data[\"Exited\"] == 1]['Age'], color = 'm',label='Attrited Customer')\nplt.legend()\nplt.title(\"Income Distribution\")","bc9c0960":"sns.catplot(x='NumOfProducts', y='CreditScore', hue='Exited', data = data, kind='swarm')","793ca492":"plt.figure(figsize=(15,7))\nsns.boxplot(data[\"NumOfProducts\"],data[\"Age\"],hue=data[\"Exited\"],palette=\"viridis\")\nplt.legend(bbox_to_anchor=(1.00, 1))\nplt.show()","e70a7176":"plt.figure(figsize=(15,7))\nsns.boxplot(data[\"HasCrCard\"],data[\"Age\"],hue=data[\"Exited\"],palette=\"viridis\")\nplt.legend(bbox_to_anchor=(1.00, 1))\nplt.show()","2f9be7b6":"sns.catplot(x='NumOfProducts', y='Age', hue='Exited', data = data, kind='swarm')","ce6ceaea":"sns.catplot(x='NumOfProducts', y='CreditScore', hue='Exited', data = data, kind='swarm')","8c334a94":"sns.catplot(x='NumOfProducts', y='EstimatedSalary', hue='Exited', data = data, kind='swarm')","fc7fd429":"sns.catplot(x='Geography', y='Age', hue='Exited', data = data, kind='swarm')","29f36c2f":"sns.catplot(x='Geography', y='CreditScore', hue='Exited', data = data, kind='swarm')","f7088d47":"fig=plt.figure(figsize=(7,5))\n# Then, for each country we will find all the men\nMen = [data.loc[(data['Geography']=='France') & (data['Gender']=='Male'), 'Balance'].sum()\/10**6, \n       data.loc[(data['Geography']=='Germany') & (data['Gender']=='Male'), 'Balance'].sum()\/10**6,\n       data.loc[(data['Geography']=='Spain') & (data['Gender']=='Male'), 'Balance'].sum()\/10**6]\n\n# To find the women, we subtract men from total amount of customers\nWomen = [data.loc[(data['Geography']=='France') & (data['Gender']=='Female'), 'Balance'].sum()\/10**6, \n       data.loc[(data['Geography']=='Germany') & (data['Gender']=='Female'), 'Balance'].sum()\/10**6,\n       data.loc[(data['Geography']=='Spain') & (data['Gender']=='Female'), 'Balance'].sum()\/10**6]\n# Contribution Ratio\n\nCRatio = [Women[k]\/Men[k] for k in range(len(Men))]\n\n# Let's define the width of each bar\nbarWidth = 0.3\n\n# The x position of bars\nr1 = np.arange(len(Men))\nr2 = [x + barWidth for x in r1]\n \n# Plot men per country\nplt.bar(r1, Men, width = barWidth, color = '#5539cc', edgecolor = 'black', label='Men')\n# Plot women per country\nplt.bar(r2, Women, width = barWidth, color = '#cb416b', edgecolor = 'black', label='Women')\n \n# General layout\nplt.xticks([r + barWidth for r in range(len(Men))], ['France\\nCRatio: ' + str(round(CRatio[0],2)), 'Germany\\nCRatio: ' + str(round(CRatio[1],2)), 'Spain\\nCRatio: ' + str(round(CRatio[2],2))],fontsize=12)\nplt.ylabel('Million \u20ac',fontsize=12)\nplt.title('Total Balance by Nation and Gender', fontsize=18)\nplt.legend()\n\n\n# Show graphic\nplt.show()","6a312340":"df_exited= data[data['Exited']==1]","e92b82dc":"fig = plt.figure(figsize=[15,6]);\nax=sns.countplot(data=data, x='Geography', hue='HasCrCard',palette='gray')\nsns.countplot(data=df_exited, x='Geography', hue='HasCrCard', palette=\"autumn\")\nplt.xticks(fontsize=14);\nplt.xlabel('Geography', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12, bbox_to_anchor=(0.5,1));\nplt.title('Non Churn(Grey) vs Churn(Red) vs Geography vs HasCrCard', fontsize=16, fontweight='bold');","e8cf5cff":"fig = plt.figure(figsize=[15,6]);\nax=sns.countplot(data=data, x='HasCrCard', hue='IsActiveMember',palette='gray')\nsns.countplot(data=df_exited, x='HasCrCard', hue='IsActiveMember', palette=\"autumn\")\nplt.xticks(fontsize=14);\nplt.xlabel('HasCrCard', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12, bbox_to_anchor=(0.5,1));\nplt.title('Non Churn(Grey) vs Churn(Red) vs IsActiveMember vs HasCrCard', fontsize=16, fontweight='bold');","383c01ae":"fig = plt.figure(figsize=[15,6]);\nax=sns.countplot(data=data, x='Geography', hue='NumOfProducts',palette='gray')\nsns.countplot(data=df_exited, x='Geography', hue='NumOfProducts', palette=\"autumn\")\nplt.xticks(fontsize=14);\nplt.xlabel('Geography', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12, bbox_to_anchor=(0.5,1));\nplt.title('Non Churn(Grey) vs Churn(Red) vs Geography vs NumOfProducts', fontsize=16, fontweight='bold');","2a784b26":"data.isnull().sum().sort_values(ascending=False).head()","084762ec":"threshold = 3\noutlier = {}\nfor col in data.select_dtypes('number'):\n    i = data[col]\n    mean = np.mean(data[col])\n    std = np.std(data[col])\n    list1 = []\n    for v in i:\n        z = (v - mean) \/ std\n        if z > threshold:\n            list1.append(v)\n    list1.sort()\n    outlier[i.name] = list1\n\nprint(\"The following are the outliers in the data:\")\nfor key, value in outlier.items():\n    print(\"\\n\", key, \":\", value)","7da69734":"def get_metrics_score(model,train,test,train_y,test_y,threshold=0.5,flag=True,roc=False):\n    '''\n    Function to calculate different metric scores of the model - Accuracy, Recall, Precision, and F1 score\n    model: classifier to predict values of X\n    train, test: Independent features\n    train_y,test_y: Dependent variable\n    threshold: thresold for classifiying the observation as 1\n    flag: If the flag is set to True then only the print statements showing different will be displayed. The default value is set to True.\n    roc: If the roc is set to True then only roc score will be displayed. The default value is set to False.\n    '''\n    # defining an empty list to store train and test results\n    \n    score_list=[] \n    \n    pred_train = (model.predict_proba(train)[:,1]>threshold)\n    pred_test = (model.predict_proba(test)[:,1]>threshold)\n\n    pred_train = np.round(pred_train)\n    pred_test = np.round(pred_test)\n    \n    train_acc = accuracy_score(pred_train,train_y)\n    test_acc = accuracy_score(pred_test,test_y)\n    \n    train_recall = recall_score(train_y,pred_train)\n    test_recall = recall_score(test_y,pred_test)\n    \n    train_precision = precision_score(train_y,pred_train)\n    test_precision = precision_score(test_y,pred_test)\n    \n    train_f1 = f1_score(train_y,pred_train)\n    test_f1 = f1_score(test_y,pred_test)\n    \n    \n    score_list.extend((train_acc,test_acc,train_recall,test_recall,train_precision,test_precision,train_f1,test_f1))\n        \n    \n    if flag == True: \n        print(\"Accuracy on training set : \",accuracy_score(pred_train,train_y))\n        print(\"Accuracy on test set : \",accuracy_score(pred_test,test_y))\n        print(\"Recall on training set : \",recall_score(train_y,pred_train))\n        print(\"Recall on test set : \",recall_score(test_y,pred_test))\n        print(\"Precision on training set : \",precision_score(train_y,pred_train))\n        print(\"Precision on test set : \",precision_score(test_y,pred_test))\n        print(\"F1 on training set : \",f1_score(train_y,pred_train))\n        print(\"F1 on test set : \",f1_score(test_y,pred_test))\n   \n    if roc == True:\n        pred_train_prob = model.predict_proba(train)[:,1]\n        pred_test_prob = model.predict_proba(test)[:,1]\n        print(\"ROC-AUC Score on training set : \",roc_auc_score(train_y,pred_train))\n        print(\"ROC-AUC Score on test set : \",roc_auc_score(test_y,pred_test))\n    \n    return score_list # returning the list with train and test scores","9e3eb845":"def make_confusion_matrix(model,test_X,y_actual,labels=[1, 0]):\n    '''\n    model : classifier to predict values of X\n    test_X: test set\n    y_actual : ground truth  \n    \n    '''\n    y_predict = model.predict(test_X)\n    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[1,0])\n    df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual - <=50K\",\"Actual - >50K\"]],\n                  columns = [i for i in ['Predicted - <=50K','Predicted - >50k']])\n    group_counts = [\"{0:0.0f}\".format(value) for value in\n                cm.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                         cm.flatten()\/np.sum(cm)]\n    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n              zip(group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    plt.figure(figsize = (10,7))\n    sns.heatmap(df_cm, annot=labels,fmt='')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","432b986b":"# Copy the raw data\ndata_model_1 = data_raw.copy()  \n\n# Eliminating unnecesary attributes\ndata_model_1.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)  # inplace=True to perform it over the dataset itself\n\ndata_model_1.rename(columns = {'Gender':'IsMale'}, inplace=True)\ndata_model_1.IsMale.loc[data_model_1.IsMale == 'Female'] = 0        # Alternative doesn't work: bank_data.IsMale.replace([0, 1], ['Female', 'Male'], inplace=True)\ndata_model_1.IsMale.loc[data_model_1.IsMale == 'Male'] = 1\ndata_model_1['IsMale'] = data_model_1['IsMale'].astype('int')\n# Separating numerical (to normalize) and categorical variables (one-hot encoding)\nnum_subset = data_model_1.select_dtypes('number')\ncat_subset = data_model_1.select_dtypes('object')\n\n# Obtain one-hote enconded features using pd.get_dummies\ncat_subset = pd.get_dummies(cat_subset)\n\n# We save a denormalized but organized version of the dataset. This will be useful for some figures.\ndenorm_bank_data = pd.concat([cat_subset, num_subset], axis=1)\n\n# Normalizing numerical variables\nmaxvals = num_subset.astype(float).max()                      # Finds maximum value\nnumericalColumns = {'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary'}\nfor col in numericalColumns:\n  num_subset[str(col)] = num_subset[str(col)]\/maxvals[col]    # Divide each column (variable) by its maximum\ndata_model_1 = pd.concat([cat_subset, num_subset], axis=1)       # Concatenate both subsets\n\n# Printing dataset types\n# uint8: unsigned integer 0-255 (natural), int64: Integer (-9223372036854775808 to 9223372036854775807) float64: Double precision float\nprint(data_model_1.dtypes)  \n\n# Displaying a dataset head\ndisplay(data_model_1.head())\n\n# Defining X and Y\nbankX = data_model_1.iloc[:,:12]\nbankY = data_model_1.iloc[:,12:13]","0c7f974a":"acc_train = []\nacc_test = []\nrecall_train = []\nrecall_test = []\nprecision_train = []\nprecision_test = []\nf1_score_train=[]\nf1_score_test=[]\n\ndef make_confusion_matrix1(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()\/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n    \n    acc_test.append(accuracy)\n    recall_test.append(recall)\n    precision_test.append(precision)\n    f1_score_test.append(f1_score)\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","c9666fda":"X = data_model_1.drop(['Exited'], axis=1)\ny = data_model_1['Exited']","0636119b":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1, stratify=y\n)","28836690":"models = []  # list that will contain the models i will be using in this project","d80abaec":"# There are different solvers available in Sklearn logistic regression\n# The newton-cg solver is faster for high-dimensional data\nlg = LogisticRegression(solver='newton-cg',random_state=1)\nlgmodel  = lg.fit(X_train,y_train)\ny_pred = lg.predict(X_test)\nlg.score(X_test,y_test)\ncm1=confusion_matrix(y_test, y_pred)\nlabels = ['True Negative','False Positive','False Negative','True Positive']\ncategories = [ 'Non Churn','Churn']\n# checking model performances for this model\nscores_LR = get_metrics_score(lgmodel,X_train,X_test,y_train,y_test)\n\n# creating confusion matrix\n#make_confusion_matrix(lg,X_test,y_test)\nmake_confusion_matrix1(cm1, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues', title='Confusion Matrix of Logistic Regression')\nmodels.append(lgmodel)","3b1dd9a9":"random_forest = RandomForestClassifier(n_estimators=100)\nrf_model = random_forest.fit(X_train,y_train.values.ravel())    # np.ravel() Return a contiguous flattened array\ny_pred = random_forest.predict(X_test)\nrandom_forest.score(X_test,y_test)\ncm1=confusion_matrix(y_test, y_pred)\nscores_RF = get_metrics_score(rf_model,X_train,X_test,y_train,y_test)\nlabels = ['True Negative','False Positive','False Negative','True Positive']\ncategories = [ 'Not_Churn','Churn']\nmake_confusion_matrix1(cm1, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues', title='Confusion Matrix of Random Forest')\nmodels.append(rf_model)","add203b0":"\norigDataModel = []  # will contain the #iterations models trained with the original (imbalanced) data\n# Splitting data into training, validation and test set:\n# first we split data into 2 parts, say temporary and test\n#X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.2)\n  # Common X_val and Y_val for validating the classifiers\nX_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size=0.2)\n  \nmodel = tf.keras.Sequential()\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128,  activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(8,  activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(Adam(lr=0.001),\n            loss='binary_crossentropy',\n            metrics=['acc'])\nmodels.append(model)\nmodel_logs = model.fit(X_train,\n      y_train,\n      batch_size=32,\n      epochs=150,\n      verbose=0,  # silent mode\n      validation_data=(X_test, y_test))  # Only to check that the model is not \"overfitting\" the training data\n\norigDataModel.append(model)\n\n# Pseudo-validate with common validation data\n\nscore = model.evaluate(X_test, y_test, verbose=0)  # tensorflow default threshold = 0.5\nprint(\"Accuracy training with imbalanced data (default threshold=0.5): {:-5f} %\".format(score[1] * 100))\n\ny_pred = model.predict(X_test) > 0.5  # manual threshold\nmatConf = confusion_matrix(y_test, y_pred)\nvalsize = y_test.shape[0]\n\n# Capturing learning history per epoch\nhist  = pd.DataFrame(model_logs.history)\nhist['epoch'] = model_logs.epoch\n\n# Plotting accuracy at different epochs\nplt.plot(hist['loss'])\nplt.plot(hist['val_loss'])\nplt.legend((\"train\" , \"valid\") , loc =0)\n#cm2=confusion_matrix(y_val, y_pred1)\nlabels = ['True Negative','False Positive','False Negative','True Positive']\ncategories = [ 'Not_Churn','Churn']\n#scores_ann = get_metrics_score(model,X_train,X_test,y_train,y_test)\nmake_confusion_matrix1(matConf, \n                  group_names=labels,\n                  categories=categories, \n                  cmap='Blues',title='Confusion Matrix of ANN Base Model')","2d284ac0":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1, stratify=y\n)\n\n  \nes= keras.callbacks.EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=15,\n\n                         verbose=0, mode='min', restore_best_weights= True)\nmodel = Sequential()\n\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128,  activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(8,  activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer='he_normal'))\n\nmodel.compile(Adam(lr=0.001),\n            loss='binary_crossentropy',\n            metrics=['acc'])\nmodels.append(model)\nmodel_logs = model.fit(X_train,\n      y_train,\n      batch_size=32, callbacks=[es],\n      epochs=120,\n      verbose=0,  # silent mode\n      validation_data=(X_test, y_test))  # Only to check that the model is not \"overfitting\" the training data\n\norigDataModel.append(model)\n\n# Pseudo-validate with common validation data\n\nscore = model.evaluate(X_test, y_test, verbose=0)  # tensorflow default threshold = 0.5\nprint(\"Accuracy training with imbalanced data (default threshold=0.5): {:-5f} %\".format(score[1] * 100))\n\ny_pred = model.predict(X_test) > 0.5  # manual threshold\nmatConf = confusion_matrix(y_test, y_pred)\nvalsize = y_test.shape[0]\n\n# Capturing learning history per epoch\nhist  = pd.DataFrame(model_logs.history)\nhist['epoch'] = model_logs.epoch\n\n# Plotting accuracy at different epochs\nplt.plot(hist['loss'])\nplt.plot(hist['val_loss'])\nplt.legend((\"train\" , \"valid\") , loc =0)\n#cm2=confusion_matrix(y_val, y_pred1)\nlabels = ['True Negative','False Positive','False Negative','True Positive']\ncategories = [ 'Not_Churn','Churn']\nmake_confusion_matrix1(matConf, \n                  group_names=labels,\n                  categories=categories, \n                  cmap='Blues', title=\"Confusion Matrix of Early Stopping\")","c3659103":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), np.array([y_train.iloc[i] for i in range(len(y_train))]))\nclass_weights = dict(enumerate(class_weights))\nclass_weights","e08f4c67":"#X_train, X_test, y_train, y_test = train_test_split(X, Y.ravel(), test_size=0.3)\n  \nes= keras.callbacks.EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=15,\n\n                         verbose=0, mode='min', restore_best_weights= True)\nmodel = Sequential()\n\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128,  activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(8,  activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer='he_normal'))\n\nmodel.compile(Adam(lr=0.001),\n            loss='binary_crossentropy',\n            metrics=['acc'])\nmodels.append(model)\nmodel_logs = model.fit(X_train,\n      y_train,\n      batch_size=32, class_weight=class_weights,\n      epochs=120,\n      verbose=0,  # silent mode\n      validation_data=(X_test, y_test))  # Only to check that the model is not \"overfitting\" the training data\n\norigDataModel.append(model)\n\n# Pseudo-validate with common validation data\n\nscore = model.evaluate(X_test, y_test, verbose=0)  # tensorflow default threshold = 0.5\nprint(\"Accuracy training with imbalanced data (default threshold=0.5): {:-5f} %\".format(score[1] * 100))\n\ny_pred = model.predict(X_test) > 0.5  # manual threshold\nmatConf = confusion_matrix(y_test, y_pred)\nvalsize = y_test.shape[0]\n\n# Capturing learning history per epoch\nhist  = pd.DataFrame(model_logs.history)\nhist['epoch'] = model_logs.epoch\n\n# Plotting accuracy at different epochs\nplt.plot(hist['loss'])\nplt.plot(hist['val_loss'])\nplt.legend((\"train\" , \"valid\") , loc =0)\n#cm2=confusion_matrix(y_val, y_pred1)\nlabels = ['True Negative','False Positive','False Negative','True Positive']\ncategories = [ 'Not_Churn','Churn']\nmake_confusion_matrix1(matConf, \n                  group_names=labels,\n                  categories=categories, \n                  cmap='Blues')","f2b59b2e":"from imblearn.under_sampling import ClusterCentroids\nfrom imblearn.over_sampling import SMOTENC, ADASYN\nfrom imblearn.combine import SMOTEENN\n\nli = [ClusterCentroids, SMOTENC, ADASYN, SMOTEENN]  # List of resampling techniques\nli_names = [\"ClusterCentroids\", \"SMOTENC\", \"ADASYN\", \"SMOTEENN\"]  # List of their names (with visualization purposes)\n\n\ncat_index = [0, 1, 2, 4, 9, 10]  # List of categorical features indexes (only used in SMOTENC)\n\n\nfor n, method in enumerate(li):\n\n    if(method==SMOTENC):  # An instance of the resampling technique\n      resampler = method(cat_index) \n    else: resampler = method()\n\n    X_resampled, Y_resampled = resampler.fit_resample(X, y.ravel())  # Resampled sets\n    Y_resampled = Y_resampled[:, np.newaxis]\n\n    print(\"After\", li_names[n], \": \\nX.shape: {}, Y.shape: {}\".format(X_resampled.shape, Y_resampled.shape))\n    print(\"{} '0' labels, {} '1' labels\".format(sum(Y_resampled==0), sum(Y_resampled==1)))\n\n    # After resampling, we shuffle to avoid data pools with the same label\n    # In this way, even more large fluctuations in accuracy value could be avoided\n\n    data_resampled = np.hstack((X_resampled, Y_resampled))\n    np.random.shuffle(data_resampled)\n    X_resampled = data_resampled[:,:12]\n    Y_resampled = data_resampled[:,12:13]\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled.ravel(), test_size=0.2)\n\n    # Neural network model\n\n    modelresampled = tf.keras.Sequential()\n\n    modelresampled.add(Dense(256, activation='relu'))\n    modelresampled.add(BatchNormalization())\n    modelresampled.add(Dropout(0.3))\n\n    modelresampled.add(Dense(128,  activation='relu'))\n    modelresampled.add(BatchNormalization())\n    modelresampled.add(Dropout(0.3))\n\n    modelresampled.add(Dense(64, activation='relu'))\n    modelresampled.add(BatchNormalization())\n    modelresampled.add(Dropout(0.3))\n\n    modelresampled.add(Dense(32, activation='relu'))\n    modelresampled.add(BatchNormalization())\n    modelresampled.add(Dropout(0.3))\n\n    modelresampled.add(Dense(8,  activation='relu'))\n    modelresampled.add(BatchNormalization())\n    modelresampled.add(Dropout(0.3))\n\n    modelresampled.add(Dense(1, activation='sigmoid'))\n\n    modelresampled.compile(Adam(lr=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    modelresampled_logs = modelresampled.fit(X_train,\n            Y_train,\n            batch_size=32,\n            epochs=150,\n            verbose=0,  # silent mode\n            validation_data=(X_test, Y_test))  # Only to check that the model is not \"overfitting\" the training data\n\n    models.append(modelresampled)\n\n    # Pseudo-validate with common validation data\n\n    score = modelresampled.evaluate(X_test, Y_test, verbose=0)  # tensorflow default threshold = 0.5\n    print(score)\n    print(\"Accuracy training with resampled data (default threshold=0.5): {:-5f} %\\n\".format(score[1] * 100))\n    Y_pred = modelresampled.predict(X_test) > 0.5\n    matConf = confusion_matrix(Y_test, Y_pred)\n    valsize = Y_test.shape[0]\n    #plt.figure(figsize=(12, 10))  # Establishing the heatmap size before plotting\n    \n    # Capturing learning history per epoch\n    hist  = pd.DataFrame(modelresampled_logs.history)\n    hist['epoch'] = modelresampled_logs.epoch\n\n    # Plotting accuracy at different epochs\n    plt.plot(hist['loss'])\n    plt.plot(hist['val_loss'])\n    plt.legend((\"train\" , \"valid\") , loc =0)\n    \n    #plt.title(\"Confusion Matrix of \", fontsize=20)\n    title = \"Confusion Martix of \"+li_names[n]\n    labels = ['True Negative','False Positive','False Negative','True Positive']\n    categories = [ 'Not_Churn','Churn']\n\n    make_confusion_matrix1(matConf, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues', title=title)\n    plt.show()\n  ","c25fa751":"comparison_frame = pd.DataFrame({'Model':['Logistic Regression','Random Forrest','ANN-Base', 'ANN-Early Stopping',\n                                          'ANN-Weighted Loss', 'ANN-ClusterCentroids','ANN-SMOTENC','ANN-ADASYN','ANN-SMOTEENN'], \n                                          'Accuracy': acc_test,\n                                          'Recall':recall_test,\n                                          'Precision':precision_test,\n                                          'f1_score':f1_score_test}) \ncomparison_frame","5fd1b874":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nli_names = ['Logistic','RandomForest','ANN','Early Stopping','Weighted-ANN',\"ClusterCentroids\", \"SMOTENC\", \"ADASYN\", \"SMOTEENN\"]\niterations=1\nfor i in range(iterations):\n\n  plt.figure(i+1, figsize=(11, 11))\n  plt.title('ROC Curve for all the models ', fontsize=20)\n  plt.xlabel('False positive rate', fontsize=15)\n  plt.ylabel('True positive rate', fontsize=15)\n  plt.plot([0, 1], [0, 1], '--', color='black')\n\n  for j in range(len(li_names)):  # For each model, calculate false positive rate, true positive rate and area under curve\n    pred = models[len(li_names)*i+j].predict(X_test).ravel()  # Predictions for each model\n    fpr, tpr, thresholds = roc_curve(Y_test, pred)  # False positive rate, true positive rate, threshold\n    auc_ = auc(fpr, tpr)\n\n    opt_index = np.argmax(np.abs(tpr-fpr))  # Optimal threshold: point where tpr is high and fpr is low\n    opt_threshold = thresholds[opt_index]\n    \n    plt.plot(fpr, tpr, label=li_names[j]+' (AUC = {:.5f}, optimal threshold = {:.5f})'.format(auc_, opt_threshold))\n    \n  plt.legend(loc='lower right', prop={'size': 14})  # Display the legend\n  plt.show()","133ec8ff":"## 2.4.2 Multivariate Analysis - Geography vs Numerical Data vs Churn\n","9bc78548":"### 4.4: Model 4: Early Stopping\n","7aa71fef":"**Observations**\n* Age has the highest relation with the target variable. Since the relationship is positive we can say that as the age of the customer increases, the rate of losing the customer also increases. \n* Exited and Number of Products has highest negative correlation. \n* Exited and Balance has positive relation. ","e57b8a1f":"# 2. Exploratory Data Analysis","71cee85e":"## 2.3.3 Bivariate Analysis - Churn Vs Categorical Columns","8a479d6b":"# 1. Reading Dataset and Feature Elimination","52516fc4":"### 4.2: Model 2: Random Forrest\n","d8c09d30":"### 3.1 Missing Value Treatment","7b8e1955":"# 7. Final - Recommendations :\n\n* The older customers are churning at more than the younger ones alluding to a difference in service preference in the age categories. The bank may need to review their target market or review the strategy for retention between the different age groups\n* With regard to the tenure, the clients on either extreme end (spent little time with the bank or a lot of time with the bank) are more likely to churn compared to those that are of average tenure.\n* The bank is losing customers with significant bank balances which is likely to hit their available capital for lending.\n* Bank should focus on the Germany market to understand why the customers from the germany churn more than its neighbouring countries\n* Female tend to churn more ,even though the pay gap is not that much between male and female. \n* Customers holding more than 2 products churn at higher rate, Bank should identify the products those customer holding and strategies accordingly. Since there is not much of product details, with the given data set this couldnt be find out. \n","471ec016":"**Observations**\n* Germany has more bank customer left the bank compared to France and Spain\n* Female customers are more likely to leave the bank compared to male. \n* Inactive customers leave the bank faster than active one\n* Customer having a credit card has left the bank a lot to the one doesnt have","a2b72fc0":"#  2.5 <a id='link1'>Summary of EDA<\/a>  \n**Data Description:**\n\n- There are no duplicates observed in the dataset.\n- There are no missing values but outliers in the data, which will be handled in the feature engineering section\n- Dataset contains 10000 rows and 14 columns\n- Columns are in mixed datatype int, float and category.\n- Customer ID, RowNum and SurName columns is not needed for futher analysis and hence dropped at the earlier stage\n- Age, CreditScore, Balance, EstimatedSalary are continuous variables.\n\n\n\n**Observations from EDA:**\n\n* Most of the customers are from France. However the customers from Germany are the one tend to leave the bank more than other countries. \n* In total, female customers left the bank compared to the male customer. \n* Customer who hold the credit card has some impact to leaving the bank\n* Inactive customers seem to leave the bank.  \n* Credit score doesnt give much insight.\n* Younger customers are retained with the bank, while the older customer leave the bank.\n* The clients on the both ends of the tenure leave the bank. Means those who spent little time with bank or more time with the bank. \n* Balance data shows that bank looses the customers across the balance range. There are customers who left the bank with zero balance and there are few left having more balance amount.\n* Customers having 3 or 4 products with the bank has seen leaving the bank.\n* There is no salary gap between Male and female in all the country. \n\nIn general, \n\n* Gernams are more likely to leave the bank than any other nationality\n* Female customer generally leave the bank at the higher rate\n* Older customers holding credit card and more product with the bank leave the bank. \n","765a8a95":"The number of samples belonging to the class 'Exited = 1' (2037) is significantly lower than those belonging to the class 'Exited = 0' (7963). In this situation, model training with these data could lead to inaccurate predictions. In order to obtain the same number of instances for both classes, several techniques present in [imbalanced-learn API](https:\/\/imbalanced-learn.org\/stable\/references\/index.html#api) have been used, in such a way that we finally choose the best one. These strategies are divided in **oversampling** techniques (create more instances of the minority class), **undersampling** techniques (reduce the number of instances of the majority class), and the combination between **undersampling + oversampling**.\n\n**Undersampling**: *ClusterCentroids*: Equals to **2037** the number of instances of both classes.\n\n**Oversampling**: *SMOTENC*: Equals to **7963** the number of instances of both classes, *ADASYN*: Increases to **8600** the number of instances of the minority class 'Exited = 1'.\n\n**Undersampling** + **Oversampling**: *SMOTEENN*: Decreases to **5047** the number of instances of the majority class 'Exited = 0' and increases to **6701** the number of instances of the minority class 'Exited = 1'.","99706d55":"### 4.1 Model 1: Logistic Regression","aa1b541c":"## 4. Model Building\n","4053e0e3":"## Model evaluation criterion\n\n### Model can make wrong predictions as:\n* Predicting a customer will exit a bank and the customer remains with the bank\n* Predicting a customer will not exit the bank but the customer exits\n\n### Which case is more important? \n* Predicting that a customer will not exit the bank but exit the bank. It might enable heavy loss to the bank \n\n### How to reduce this loss i.e need to reduce False Negative?\n* Company  would want `Recall` to be maximized, greater the Recall higher the chances of minimizing false Negative. Hence, the focus should be on increasing Recall or minimizing the false Negative or in other words identifying the True Positive(i.e. Class 1) so that the Company can identify the fraud transaction.","7f3ef233":"**Conclusion:**\n\nAs you can see here the Recall of the model is not improved and it is worse than the Previous ANN model as well as the RandomForest but the precision is changed.\n\nLet's try weighted loss for imbalance dataset","6e39ae91":"### 2.3.1 Correaltion Matrix","0f147fd1":"**Observations**\n* Data is evenly distributed and not much can be inferred here. ","7608da78":"## 2.4.1 Multivariate Analysis - NumOfProducts vs Numerical Data vs Churn","4ed724cf":"### 4.5: Model 5:  Weighted loss to account for large class imbalance in train dataset\n- we will adjust the class imbalance by giving additional weight to the loss associated to errors made on fraudulent transaction detection.\n\nWe will use our first ANN model and apply weighted loss\n\n\n Let's review the process:","2d5a8430":"No missing value or null observed in the dataset. Hence no treatment is needed","3067308d":"Detection of fraudulent transactions did not improve compared to the previous machine learning model ( Randomforest).\n\n- There are 211 customers predicted to exit the bank in the test data and yet 210 Churn customers are not identified (false negative) which remains an issue. Our objective must be to detect as many customer churn as possible since these can have a huge negative impact.\n\n- 210 regular transactions are detected as potentially churn customer by the model. These are false positive. This number is negligible.\n\n**Conclusion:**\n\nWe must find ways to further reduce the number of false negative.\n##Let's try another architecture to get the better Recall \n\n\nThere are some basic Hyperparameters which can help to get the better model performance.\n\n**Early stopping:** \n\nDuring training, the model is evaluated on a holdout validation dataset after each epoch. If the performance of the model on the validation dataset starts to degrade or no improvement (e.g. loss begins to increase or accuracy begins to decrease), then the training process is stopped after the certian interations.The model at the time that training is stopped is then used and is known to have good generalization performance.\n\nThis procedure is called \u201cearly stopping\u201d and is perhaps one of the oldest and most widely used forms of neural network regularization.\n\n**Weight Initialization**\n\nWeight initialization is an important consideration in the design of a neural network model.\n\nThe nodes in neural networks are composed of parameters referred to as weights used to calculate a weighted sum of the inputs.\n\nNeural network models are fit using an optimization algorithm called stochastic gradient descent that incrementally changes the network weights to minimize a loss function, hopefully resulting in a set of weights for the mode that is capable of making useful predictions.\n\nThis optimization algorithm requires a starting point in the space of possible weight values from which to begin the optimization process. Weight initialization is a procedure to set the weights of a neural network to small random values that define the starting point for the optimization (learning or training) of the neural network model.\n\nThere are many WI techniques as follows:\n\n1) Random normal initialization\n\n2) Random Uniform initialization\n\n3) Xaviour Initialization\n\n4) He Initialization ","d60aa780":"**Observations**\n\n- There are outliers in the columns *Age* and *NumOfProducts*.\n- We will not treat the outliers as most of those outliers are not disjoint from the curve (continues curve).\n- These outliers might also form their own cluster.","66f931a6":"## 2.2 Univariate Analysis - Categorical Variable","8b291c09":"## 2.4 Multivariate Analysis ","5d0dfe0a":"**Observations**:\n\n* Dataset has 10000 rows and 14 columns, and the data is non null dataset. \n* Balance & Estimated Salary seems to be right skewed, with max value is extreme right\n* There are 2932 unique Surnames and Smith Surname is max with 32 occrence. Surname is not an important in this modeling. so will remove the surname\n* Dataset consists of the customer from 3 countries, with France holding 50% of total customers, followed by Germany and Spain roughly 25% of population each\n* Bank has more male customers compared to female. ","44f87af9":"## 2.1 Univariate Analysis - Continuous Variable","14e1090f":"## 2.3 Bivariate Analysis","626aea87":"## 2.3.2 Bivariate Analysis - Churn Vs Numerical Columns\n","225d5c0b":"#  3. Data Pre-Processing\n","19366807":"* For the given business case, the model should have better accuracy and recall values. from the above table it is clear that ANN-SMOTE with Edited Nearest Neighbours(SMOTEENN) model gives better accuracy, recall, precision and F1-score. The model looks more generalised one having all the meterics in the same range. \n* The same can be verified in the ROC charts of each models. ","ad6b5c6d":"**Observation**\n* Slight left skwed with more customers having having higher credit scores.","3663dcc2":"## Let's now explore Neural Network models\n\n## Deep neural network\n\n### 4.3 Model-3 - DNN Base Model\n\n- We will use a simple NN made of 5 fully-connected layers with ReLu activation. The NN takes a vector of length 29 as input. This represents the information related to each transactions, ie each line with 29 columns from the dataset. For each transaction, the final layer will output a probability distribution (sigmoid activation function) and classify either as not fraudulent (0) or fraudulent (1).\n- a dropout step is included to prevent overfitting.\n\n\n\n**Dropout**\n\nDropout is a regularization technique for neural network models proposed by Srivastava, et al. in their 2014 paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Dropout is a technique where randomly selected neurons are ignored during training. They are \u201cdropped-out\u201d randomly.\n\n### Creating a model\n\nKeras model object can be created with Sequential class\n\nAt the outset, the model is empty per se. It is completed by adding additional layers and compilation\n\n### Adding layers [layers and activations]\n\nKeras layers can be added to the model\n\nAdding layers are like stacking lego blocks one by one\n\nIt should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added","98948247":"## 3.3 Feature Engineering and Scaling\n","07ef0d5f":"## 6. ROC of all the models","50ef758b":"**Observations**\n* The Tenure data is evenly distributed. \n* There is no direct correlation inferred here. ","d02aba74":"### 4.6 : Model Performance Improvement - Resampling Technique","c770f1c7":"### 3.2 Outlier Detection\n\n- Let's find outliers in the data using z-score with a threshold of 3.","5954e674":"## 3.4 Data Preparation for Modelling","a04021e1":"**Observations**\n* Balance may be give some insight. \n* Around 35% of the customers have balance 0 or less than 1000. Checking these customers may give some relations. ","990b5970":"## 5. Model Comparison\n","be4d9854":"**Observations**\n\n**Number of Products**: Most of the customers host atleast one or two products. Very few customers hold 3 or 4 products. \n\n**IsActive**: Almost only half of the customers are Active with the bank making the transaction. \n\n**HasCrCard**: Two third of the customers have credit cards. \n\n**Geography**: Half of the customers are from France and remaining half is from Spain and Germany. \n\n**Gender**: More customers are male customers with 55 pct compared to female customers. \n\n**Exited**: 20 pct of the customers has left the bank. and 80pct are still in active member with the bank.","507c1fa8":"**Observations**\n* Most of the customers are in the age group of 30-40 \n* The boxplot is right skewed, with the outliers at the extreme end. \n* We shall check on these outliers later section","94a850c9":"The above ROC curve hints that the most suitable model is the resampled SMOTEENN(Combine over- and under-sampling using SMOTE and Edited Nearest Neighbours) technique, which stands out from the other model results. Due to high accuracy and area under curve(98%) this model outperformed the models trained with original, imbalance data. ROC curve also helped to find the optimal threshold(.54) value of each model. \n\nTo sum up, the results have indicated taht for the give dataset, it is suitable to perform Combine over- and under-sampling using SMOTE and Edited Nearest Neighbours to balance the classes and train the model. "}}