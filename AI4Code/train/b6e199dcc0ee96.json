{"cell_type":{"cc05a588":"code","3c8c976a":"code","30f886e2":"code","f3a28929":"code","a56b1585":"code","b7103951":"code","160ec805":"code","db2714f2":"code","5678d3ff":"code","34ebc83c":"code","29fbad1d":"code","46e61d8a":"code","56eaf25f":"code","55b7e75a":"code","849c06b8":"code","a80b82f6":"code","928c0624":"code","80fb8a93":"code","507fc074":"code","77fd6feb":"code","248e02e2":"code","68053480":"code","6df90719":"code","23177ec8":"code","13ba1cc5":"code","fe61eee9":"code","3ba23644":"code","b4e6e74d":"code","6865fa6d":"code","453d6816":"code","4bb376f8":"code","6ad7f26d":"code","9d825c25":"code","d2505faf":"markdown","a9362834":"markdown","f834f36a":"markdown","fbc42019":"markdown"},"source":{"cc05a588":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c8c976a":"import matplotlib.pyplot as plt\nfrom sklearn import metrics\n\ndata = pd.read_csv('\/kaggle\/input\/weatherww2\/Summary of Weather.csv')\n\ndata.head()","30f886e2":"X = data.iloc[:, 5].values\nY = data.iloc[:, 6].values","f3a28929":"print(data['MinTemp'].isnull().any())\nprint(data['MaxTemp'].isnull().any())","a56b1585":"plt.scatter(X, Y)\nplt.xlabel('Min Temp')\nplt.ylabel('Max Temp')\nplt.show()","b7103951":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)","160ec805":"X_train= X_train.reshape(-1, 1)\ny_train= y_train.reshape(-1, 1)\nX_test = X_test.reshape(-1, 1)","db2714f2":"from sklearn.linear_model import LinearRegression\nref = LinearRegression()\nref.fit(X_train, y_train)\ny_pred4 = ref.predict(X_test)","5678d3ff":"plt.scatter(y_test, y_pred4)\nplt.xlabel('y_test')\nplt.ylabel('y_pred')\nplt.show()","34ebc83c":"plt.scatter(X_test, y_test, color='green')\nplt.plot(X_test, y_pred4, color='blue')\nplt.xlabel('X_test')\nplt.ylabel('y_test')\nplt.grid()\nplt.show()\n\n# blue line is predicted value","29fbad1d":"print('m :', ref.coef_)\nprint('c :', ref.intercept_)","46e61d8a":"r2 = ref.score(X_test, y_test)\nprint('R2 :',r2)","56eaf25f":"print(\"mean_squared_error :\",metrics.mean_squared_error(y_test, y_pred4))","55b7e75a":"data.shape","849c06b8":"data.columns","a80b82f6":"X_train = data.iloc[:83329, 5]\nX_test = data.iloc[83329:, 5]\nY_train = data.iloc[:83329, 4]\nY_test = data.iloc[83329:, 4]\n\nprint(X_test[:10])\nprint(len(X_train))","928c0624":"plt.scatter(X_train, Y_train)\nplt.xlabel('X_train')\nplt.ylabel('Y_train')\nplt.show()","80fb8a93":"# we have to find out the mean\nx_ = np.mean(X_train)\ny_ = np.mean(Y_train)\nprint(x_, y_)","507fc074":"def find_sploe(X, Y, x_, y_):\n    dem = 0\n    newm = 0\n    for i in range(len(X)):\n        dem += (X[i] - x_) * (Y[i] - y_)\n        newm += (X[i] - x_) ** 2\n    return dem \/ newm","77fd6feb":"M = find_sploe(X_train, Y_train, x_, y_)\nprint('M : ', M)\n\n# y = mx + c is the equation of line\n# and now we have to find out the y_intercept\n# we have one point (x_, y_) on line and sploe of line(M)\nc = y_ - M * x_ \nprint(\"c : \",c)","248e02e2":"# y = M x + c\n# y_pred is predicted value for X_train\ny_pred = []\nfor i in X_train:\n    y_pred.append(0.9564942836256293 * i + 10.003872467572915)\n    # print(i)","68053480":"df = pd.DataFrame({'Actual': Y_train, 'Predicted': y_pred})\ndf.head()","6df90719":"mse = (1\/len(X_train)) * np.sum(val ** 2 for val in (Y_train - (M*X_train + c)))\nprint('mean_squared_error :',mse)\nprint('mean_squared_error :',metrics.mean_squared_error(Y_train, y_pred))","23177ec8":"# we will find the R2 = ?\ndef find_score_r2(Y, y_pred, y_):\n    d = n = 0\n    i = 0\n    for j in Y:\n        d += (y_pred[i] - y_) ** 2\n        n += (j - y_) ** 2\n        i += 1\n    # d = np.sum(val ** 2 for val in (y_pred - y_))\n    # n = np.sum(val ** 2 for val in (Y - y_))\n    R2 = 1 - (d \/ n)\n\n    return R2","13ba1cc5":"print(\"R2 : \", find_score_r2(Y_train, y_pred, y_))","fe61eee9":"plt.scatter(X_train, Y_train, color='green')\nplt.plot(X_train, y_pred, color='blue')\nplt.xlabel('X_train')\nplt.ylabel('Y_train')\nplt.grid()\nplt.show()\n\n# blue line is predicted point","3ba23644":"# we will find out the best fit line \n\ndef gradient_descent(X, Y):\n    m_cur = c_cur = 0\n    iteration = 15000\n    n = len(X)\n    learning_rate = 0.002\n    \n    for i in range(iteration):\n        y_pred2 = m_cur * X + c_cur\n        mse = (1\/n) * sum(val ** 2 for val in (Y - y_pred2))\n        md = - (2\/n) * sum(X*(Y - y_pred2))\n        cd = -(2\/n) * sum(Y - y_pred2)\n        \n        m_cur = m_cur - learning_rate * md\n        c_cur = c_cur - learning_rate * cd\n        \n        print(\"m {}, c {}, cost {}, iteration {}\".format(m_cur, c_cur, mse, i))","b4e6e74d":"# gradient_descent(X_train, Y_train)","6865fa6d":"y_pred3 = []\nfor i in X_test:\n    y_pred3.append( (0.9564942836256293 * i) + 10.003872467572915)","453d6816":"df2 = pd.DataFrame({'Actual': Y_test, 'Predicted': y_pred3})\ndf2.head()","4bb376f8":"mse = (1\/len(X_test)) * np.sum(val ** 2 for val in (Y_test - (0.9564942836256293*X_test + 10.003872467572915)))\nprint('mean_squared_error :',mse)\nprint('mean_squared_error :',metrics.mean_squared_error(Y_test, y_pred3))","6ad7f26d":"print('R2 :',find_score_r2(Y_test, y_pred3, y_))","9d825c25":"plt.scatter(X_test, Y_test, color='green')\nplt.plot(X_test, y_pred3, color='blue')\nplt.xlabel('X_test')\nplt.ylabel('y_test')\nplt.show()\n\n# blue line is predicted point (y_pred3)","d2505faf":"### gradient_descent(X, Y)\n## Now i just predict values for X_test\n### By using Y = (0.9564942836256293 * X) + 10.003872467572915","a9362834":"# First we will use inbuild Regression function for prediction","f834f36a":"# Now we will use user define function for prediction","fbc42019":"# Gradient descent"}}