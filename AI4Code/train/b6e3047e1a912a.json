{"cell_type":{"8f6a3bf7":"code","d7a01561":"code","44b63e05":"code","153f3973":"code","290474c2":"code","bb1b948b":"code","6f109652":"code","d93819db":"code","dd2beb21":"code","4be80440":"code","63480b7d":"code","265ac665":"code","bd011694":"code","2d0032d5":"code","5048ff9e":"code","3d82b746":"code","ee01cfa9":"code","fbf3ce4c":"code","037abe3a":"code","203e3a0e":"code","56963873":"code","8b7ac7ca":"code","dd4b05c9":"code","d799fa2e":"code","26d791e1":"code","b34fdc10":"code","2812cda3":"code","b1801be9":"code","e5c84516":"code","2037f3e1":"code","f0fd5878":"code","a351f485":"code","459bc7bf":"markdown","e53b8787":"markdown"},"source":{"8f6a3bf7":"\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n#         pass\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7a01561":"!tar -xzvf ..\/input\/conversation-tagging\/tagging_test.tgz ","44b63e05":"!python -m spacy download en_core_web_sm","153f3973":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob\n\nimport spacy\nfrom spacy.vocab import Vocab\nfrom spacy.tokenizer import Tokenizer\nnlp = spacy.load('en_core_web_sm')\n\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nmax_review_length = 4000\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","290474c2":"import matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport random as python_random\n\ndef reset_seeds(seed):\n    np.random.seed(seed) \n    python_random.seed(seed)\n    tf.random.set_seed(seed)\n\nreset_seeds(seed=1291)","bb1b948b":"from sklearn.model_selection import StratifiedShuffleSplit","6f109652":"labels_df = pd.read_csv(\"..\/input\/conversation-tagging\/mapping_conv_topic.train.txt\",header=None,sep=\" \")\nlabels_df.columns = [\"file_id\",\"tag\"]\nlabels_df[:3]","d93819db":"files = glob(\".\/tagging_test\/*.txt\")\n\ndata_df = pd.DataFrame()\ndata_df[\"file_path\"] = pd.Series(files)\ndata_df[:3]","dd2beb21":"def read_file(path):\n    with open(path,\"r\") as f:\n        doc = f.read()\n    return doc","4be80440":"data_df[\"text\"] = data_df[\"file_path\"].apply(read_file)\ndata_df[\"file_id\"] = data_df[\"file_path\"].str[-8:-4].astype(int)\n\ndata_df[:3]","63480b7d":"labeled_data_df = data_df.merge(labels_df,on=\"file_id\")\nlabeled_data_df[:3]","265ac665":"labeled_data_df.shape","bd011694":"labeled_data_df['tag'].value_counts()","2d0032d5":"lencoder = LabelEncoder()\ny_cat = lencoder.fit_transform(labeled_data_df['tag'])\ny_cat = keras.utils.to_categorical(y_cat)\ny_cat","5048ff9e":"X_train, X_test, Y_train, Y_test = train_test_split(labeled_data_df['text'],y_cat, test_size=0.2)\n[i.shape for i in [X_train, X_test, Y_train, Y_test]]","3d82b746":"sss = StratifiedShuffleSplit(1,test_size=0.2)\nsss.get_n_splits(labeled_data_df['text'],y_cat)\nfor train_index, test_index in sss.split(labeled_data_df['text'],y_cat):\n    pass\nX_train, X_test, Y_train, Y_test = labeled_data_df['text'].iloc[train_index], labeled_data_df['text'].iloc[test_index],y_cat[train_index,:],y_cat[test_index,:]","ee01cfa9":"pd.concat([pd.Series(y_cat[train_index,:].argmax(1)).value_counts().sort_index().rename(\"train\"), \n           pd.Series(y_cat[test_index,:].argmax(1)).value_counts().sort_index().rename(\"test\")],1)","fbf3ce4c":"t= Tokenizer()\nt.fit_on_texts(X_train.tolist())\nprint(\"The document count\",t.document_count)\n# print(\"The count of words\",t.word_counts)","037abe3a":"nvocab = t.texts_to_matrix(X_train.tolist(), mode='binary').shape[1]","203e3a0e":"seq_tr = t.texts_to_sequences(X_train.tolist())\nseq_ts = t.texts_to_sequences(X_test.tolist())\n\nX_tr = sequence.pad_sequences(seq_tr, maxlen=max_review_length)\nX_ts = sequence.pad_sequences(seq_ts, maxlen=max_review_length)\n[i.shape for i in [X_tr, X_ts]]","56963873":"4000\/4","8b7ac7ca":"X_tr = X_tr.reshape(-1,1000)\nX_ts = X_ts.reshape(-1,1000)\n\nY_tr = np.repeat(Y_train,4,0) \nY_ts = np.repeat(Y_test,4,0) \n\n[i.shape for i in [X_tr, X_ts, Y_tr, Y_ts]]","dd4b05c9":"keras.layers.Embedding","d799fa2e":"def define_model(inshape,outshape):\n    keras.backend.clear_session()\n    model = keras.models.Sequential([\n        keras.layers.Input(inshape[0]),\n#         keras.layers.Reshape((inshape[0],inshape[1])),\n#         Embedding(vocab coverage, n kernels, seq len)\n        keras.layers.Embedding(nvocab+10, 32*4, input_length=inshape[0]),\n        keras.layers.Dropout(0.7),\n        \n        keras.layers.Conv1D(32*4,3,2),\n        keras.layers.Conv1D(32*2,3,2),\n        keras.layers.MaxPool1D(2),        \n        keras.layers.Dropout(0.6),\n        keras.layers.BatchNormalization(),\n        \n        keras.layers.Conv1D(16*4,3,2),\n        keras.layers.Conv1D(16*2,3,2),\n        keras.layers.MaxPool1D(2),        \n        keras.layers.Dropout(0.6),\n        keras.layers.BatchNormalization(),\n        \n        keras.layers.LSTM(64*4),\n        keras.layers.Flatten(),\n        keras.layers.Dropout(0.6),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(32*8),\n        keras.layers.Dropout(0.6),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(32),\n        keras.layers.Dropout(0.4),\n        keras.layers.BatchNormalization(),\n        \n        keras.layers.Dense(outshape,activation=\"sigmoid\"),\n        \n    ])\n    \n    return model\n    \nmodel = define_model(inshape=(4000,1), outshape=6)\nmodel.summary()","26d791e1":"reset_seeds(seed=1291)\n\nmodel = define_model(inshape=(1000,1), outshape=6)\nmodel.compile(loss=keras.losses.BinaryCrossentropy(),\n              optimizer=keras.optimizers.Adam(0.001),\n              metrics=keras.metrics.AUC())\n\nes = keras.callbacks.EarlyStopping(patience=13, verbose=1,restore_best_weights=True)\n\nmodel.fit(X_tr,Y_tr, epochs=500, validation_split=0.2, batch_size=128, callbacks=[es])","b34fdc10":"f,axs = plt.subplots(1,2,figsize=(12,4))\n\naxs[0].set_title(\"Loss\")\naxs[0].plot(model.history.history[\"loss\"],\".:\",label=\"loss\")\naxs[0].plot(model.history.history[\"val_loss\"],\":.\",label=\"val_loss\")\naxs[0].set_yscale(\"log\")\n\naxs[1].set_title(\"AUC\")\naxs[1].plot(model.history.history[\"auc\"],\".:\",label=\"auc\")\naxs[1].plot(model.history.history[\"val_auc\"],\":.\",label=\"val_auc\")\n\naxs[0].legend()\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()","2812cda3":"from sklearn.metrics import classification_report, confusion_matrix","b1801be9":"Y_tr_true = Y_tr.argmax(1)\nY_tr_pred = model.predict(X_tr).argmax(1)","e5c84516":"Y_ts_true = Y_ts.argmax(1)\nY_ts_pred_cat = model.predict(X_ts)\nY_ts_pred = Y_ts_pred_cat.argmax(1)","2037f3e1":"cr = classification_report(Y_tr_true,Y_tr_pred)\ncm = confusion_matrix(Y_tr_true,Y_tr_pred)\nprint(cr)\npd.DataFrame(cm,index=lencoder.classes_,columns=lencoder.classes_).style.background_gradient()","f0fd5878":"cr = classification_report(Y_ts_true,Y_ts_pred)\ncm = confusion_matrix(Y_ts_true,Y_ts_pred)\nprint(cr)\npd.DataFrame(cm,index=lencoder.classes_,columns=lencoder.classes_).style.background_gradient()","a351f485":"from sklearn.metrics import roc_curve, auc\nplt.rcParams[\"figure.figsize\"] = (8,6)\n\nn_classes = 6\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_ts[:, i], Y_ts_pred_cat[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_ts.ravel(), Y_ts_pred_cat.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# Plot ROC curve\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                   ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","459bc7bf":"# Split","e53b8787":"# Evaluation"}}