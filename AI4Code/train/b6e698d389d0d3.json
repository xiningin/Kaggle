{"cell_type":{"0868498a":"code","6471f819":"code","702597a9":"code","75a9336b":"code","5a3ea233":"code","19dafb1a":"code","5234b514":"code","7ea847ad":"code","9715cc6f":"code","08b43adc":"code","8d385d33":"code","8e037921":"markdown","8d318eef":"markdown","7745f6e6":"markdown","03c9c4ae":"markdown","f7f6db78":"markdown","552bf7c4":"markdown","5e153dae":"markdown","5f913018":"markdown","26f084c4":"markdown","8e9c798d":"markdown"},"source":{"0868498a":"import numpy as np\nimport pandas as pd\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport itertools\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nSEED = 2021\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","6471f819":"TRAIN_PATH = \"..\/input\/digit-recognizer\/train.csv\"\nTEST_PATH = \"..\/input\/digit-recognizer\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/digit-recognizer\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nTARGET = \"label\"\nSUBMIT_TARGET = \"Label\"\nTEST_SIZE = 0.2\nLABEL_NUM = 10\n\nIMAGE_SIZE_X = 28\nIMAGE_SIZE_Y =28\nSCALE_SIZE = 255","702597a9":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","75a9336b":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test ","5a3ea233":"X = X\/SCALE_SIZE\nX_test = X_test\/SCALE_SIZE\n\nX = X.values.reshape(-1,IMAGE_SIZE_X,IMAGE_SIZE_Y,1)\nX_test = X_test.values.reshape(-1,IMAGE_SIZE_X,IMAGE_SIZE_Y,1)\n\ny = to_categorical(y, num_classes=LABEL_NUM)","19dafb1a":"X_train, X_val, y_train, y_val = train_test_split(X, y,test_size=TEST_SIZE,random_state=SEED )","5234b514":"BATCH_SIZE = 64 \nEPOCH = 5\nLEARNING_RATE = 0.001\n\nKERNEL_INITIALIIZERS = tf.keras.initializers.GlorotNormal(seed=SEED)\nPADDING = \"Same\"\nMID_ACTIVATION = \"relu\"\nLAST_ACTIVATION = \"softmax\"\n\nCOMPILE_LOSS = \"categorical_crossentropy\"\nCOMPILE_METRICS = ['accuracy']\nRHO = 0.9\nEPSILON = 1e-08\nDROPOUT = 0.25\nVERBOSE = 1","7ea847ad":"def define_model():\n    model = Sequential()\n\n    model.add(Input(shape=(IMAGE_SIZE_X,IMAGE_SIZE_Y,1)))\n    model.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=KERNEL_INITIALIIZERS, \n                     padding=PADDING, activation=MID_ACTIVATION))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(DROPOUT, seed=SEED))\n\n    model.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=KERNEL_INITIALIIZERS, \n                     padding=PADDING, activation=MID_ACTIVATION))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(DROPOUT, seed=SEED))\n\n    model.add(Flatten())\n    model.add(Dense(256, kernel_initializer=KERNEL_INITIALIIZERS, activation=MID_ACTIVATION))\n    model.add(Dropout(DROPOUT, seed=SEED))\n    model.add(BatchNormalization())\n    model.add(Dense(LABEL_NUM, kernel_initializer=KERNEL_INITIALIIZERS, activation=LAST_ACTIVATION))\n    \n    decay= 5 * LEARNING_RATE \/ EPOCH\n    optimizer = RMSprop(learning_rate=LEARNING_RATE, rho=RHO, epsilon=EPSILON, decay=decay)\n    \n    model.compile(optimizer=optimizer,loss=COMPILE_LOSS,metrics=COMPILE_METRICS)\n    return model\n\nmodel = define_model()\nmodel.summary()","9715cc6f":"train_datagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=10,\n                             zoom_range=0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             horizontal_flip=False,\n                             vertical_flip=False\n                            )\ntrain_generator = train_datagen.flow(X_train, y_train,\n                                     batch_size=BATCH_SIZE,\n                                     shuffle=True)\n\nval_datagen = ImageDataGenerator()\nval_generator = val_datagen.flow(X_val, y_val,\n                                 batch_size=BATCH_SIZE,\n                                 shuffle=True)\n\nreduceLROnPlateau = ReduceLROnPlateau(monitor='val_acc', \n                                patience=3,\n                                verbose=VERBOSE, \n                                factor=0.5,\n                                min_lr=0.00001)\n\nhistory = model.fit(train_generator,\n                    epochs= EPOCH,\n                    validation_data=val_generator,\n                    verbose=VERBOSE,\n                    callbacks=[reduceLROnPlateau]\n                   )","08b43adc":"results = model.predict(X_test)\nresults = np.argmax(results,axis = 1)\nresults[:5]","8d385d33":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[SUBMIT_TARGET] = results\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","8e037921":"# submission","8d318eef":"# global variables","7745f6e6":"# predict test data target using model","03c9c4ae":"# split data (input data and target data)","f7f6db78":"# split data (train set and validation set)","552bf7c4":"# define model","5e153dae":"# train model","5f913018":"# load data","26f084c4":"# model variables","8e9c798d":"# scaling and transformation"}}