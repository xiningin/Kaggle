{"cell_type":{"ab46ada5":"code","107edd55":"code","d45f008b":"code","a7e9cdab":"code","16c094b0":"code","9e93fe39":"code","5a09d4e5":"code","1ac7817a":"code","fcd74acf":"code","9e9d22ae":"code","44364981":"code","833d651c":"code","dec81f73":"code","d8ed6dcc":"code","ec0bf448":"code","dcd5fa4a":"code","5eebd81b":"code","91528849":"code","23493da5":"code","277eebe8":"code","f6d83f17":"code","5c88a9fa":"code","10531dd8":"code","f0c7a31b":"code","98997424":"code","4de73306":"code","ab05e03d":"code","f276eab0":"code","93b20dba":"code","3fa8c34c":"code","088c2dd2":"code","6a220544":"code","98ce55d1":"code","47e01d9b":"code","0e99b130":"code","935edb3a":"code","5928477c":"code","502f17f1":"code","d770d72f":"code","c90fbe89":"code","43126294":"code","a0a979ce":"code","c6ea46f2":"code","16cca460":"code","c7ac0c06":"markdown","945cc144":"markdown","b2a8d517":"markdown","6a1caae6":"markdown","cef6556b":"markdown","2fd24e1e":"markdown","e21a23ae":"markdown","501501ab":"markdown","f7ae0cb1":"markdown","6d70ea09":"markdown","dc7a396e":"markdown","f40c4122":"markdown","c4914535":"markdown","b21ed213":"markdown","39f6a058":"markdown","0d4ea429":"markdown","b1447af1":"markdown","83ce8986":"markdown","a9cdaca5":"markdown","271afe95":"markdown","744f7d6b":"markdown","1e2d0baa":"markdown"},"source":{"ab46ada5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","107edd55":"import torch\nimport numpy as np\nfrom torch import Tensor, nn, tensor\nimport math\nimport pandas as pd\nimport csv\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom pathlib import Path\nfrom fastai.vision.all import *\nfrom fastai.text.all import *","d45f008b":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads, masked):\n        super().__init__()\n        assert d_model % num_heads == 0, \"num_heads must evenly chunk d_model\"\n        self.num_heads = num_heads\n        self.wq = nn.Linear(d_model, d_model, bias=False)  # QQ what if bias=True?\n        self.wk = nn.Linear(d_model, d_model, bias=False)\n        self.wv = nn.Linear(d_model, d_model, bias=False)\n        self.masked = masked\n        self.softmax = nn.Softmax(dim=2)\n\n    def forward(self, q, k, v):\n        qs = self.wq(q).chunk(self.num_heads, dim=2)\n        ks = self.wk(k).chunk(self.num_heads, dim=2)\n        vs = self.wv(v).chunk(self.num_heads, dim=2)\n        outs = []\n        # TODO Use einsum instead of for loop\n        for qi, ki, vi in zip(qs, ks, vs):\n            attns = qi.bmm(ki.transpose(1, 2)) \/ (ki.shape[2] ** 0.5)\n            if self.masked:\n                attns = attns.tril()  # Zero out upper triangle so it can't look ahead\n            attns = self.softmax(attns)\n            outs.append(attns.bmm(vi))\n        return torch.cat(outs, dim=2)","a7e9cdab":"class AddNorm(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.ln = nn.LayerNorm(d_model)\n\n    def forward(self, x1, x2):\n        return self.ln(x1+x2)\n","16c094b0":"class FeedForward(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.l1 = nn.Linear(d_model, d_model)\n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(d_model, d_model)\n    def forward(self, x):\n        return self.l2(self.relu(self.l1(x)))","9e93fe39":"class AttentionAggregation(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.query = nn.Linear(d_model, 1, bias=False)\n\n    def forward(self, x):  # (b, s, m)\n        attns = self.query(x).softmax(dim=1)  # (b, s, 1)\n        enc = torch.bmm(attns.transpose(1, 2), x)  # (b, 1, m)\n        return enc.squeeze(1)","5a09d4e5":"class ReadNetBlock(nn.Module):\n    def __init__(self, d_model, n_heads, n_blocks, n_feats, n_out):\n        super().__init__()\n        self.blocks = nn.Sequential(*[EncoderBlock(d_model=d_model, num_heads=n_heads) for _ in range(n_blocks)])\n        self.lin_tanh = LinTanh(d_model=d_model)\n        self.attn_agg = AttentionAggregation(d_model=d_model)\n        self.lin_feat_concat = LinFeatConcat(d_model=d_model, n_feats=n_feats, n_out=n_out)\n\n    def forward(self, x, feats):  # (b, s, m), (b, f)\n        x = pos_encode(x)\n        x = self.blocks(x)\n        x = self.lin_tanh(x)\n        x = self.attn_agg(x)\n        return self.lin_feat_concat(x, feats)\n    \n    \nclass ReadNet(nn.Module):\n    def __init__(self, embed, d_model, n_heads, n_blocks, n_feats_sent, n_feats_doc):\n        super().__init__()\n        self.embed = embed\n        self.sent_block = ReadNetBlock(\n            d_model=d_model, n_heads=n_heads, n_blocks=n_blocks, n_feats=n_feats_sent, n_out=d_model\n        )\n        self.doc_block = ReadNetBlock(\n            d_model=d_model, n_heads=n_heads, n_blocks=n_blocks, n_feats=n_feats_doc, n_out=d_model + n_feats_doc\n        )\n        self.head = nn.Sequential(\n            nn.Linear(d_model + n_feats_doc, 1),\n        )\n\n    def forward(self, x, feats_sent=None, feats_doc=None):  # (b, d, s) tokens, (b, d, n_f_s), (b, n_f_d)\n        if feats_sent is None: feats_sent = Tensor([])\n        if feats_doc is None: feats_doc = Tensor([])\n        if x.is_cuda:\n            feats_sent = feats_sent.cuda()\n            feats_doc = feats_doc.cuda()\n        #print(len(x))\n        #print(x.shape)\n        #print(x)\n        \n        x = self.embed(x)\n        b, d, s, m = x.shape\n        x = x.reshape(b * d, s, m)\n        sents_enc = self.sent_block(x, feats_sent.reshape(b * d, -1))  # (b*d, m)\n        docs = sents_enc.reshape(b, d, m)\n        docs_enc = self.doc_block(docs, feats_doc)\n        out = self.head(docs_enc)\n        return out.squeeze(1)\n","1ac7817a":"\n\n\n# Make sure to have your glove embeddings stored here\nroot_dir = '..\/input\/glove-embeddings'\n\n\n## MODEL CODE ##\n\n\n\n\n\n\n\n\n\n\ndef pos_encode(x):\n    pos, dim = torch.meshgrid(torch.arange(x.shape[1]), torch.arange(x.shape[2]))\n    dim = 2 * (dim \/\/ 2)\n    enc_base = pos\/(10_000**(dim \/ x.shape[2]))\n    addition = torch.zeros_like(x)\n    for d in range(x.shape[2]):\n        enc_func = torch.sin if d % 2 == 0 else torch.cos\n        addition[:,:,d] = enc_func(enc_base[:,d])\n    if x.is_cuda:\n        addition = addition.cuda()\n    #print(x+addition)\n    return x + addition\n\n\nclass EncoderBlock(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        self.mha = MultiHeadAttention(d_model=d_model, num_heads=num_heads, masked=False)\n        self.an1 = AddNorm(d_model)\n        self.ff = FeedForward(d_model)\n        self.an2 = AddNorm(d_model)\n\n    def forward(self, x):\n        x = self.an1(x, self.mha(q=x, k=x, v=x))\n        return self.an2(x, self.ff(x))\n\n\n\n\n\nclass LinTanh(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.lin = nn.Linear(d_model, d_model)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        return self.tanh(self.lin(x))\n\n\nclass LinFeatConcat(nn.Module):\n    def __init__(self, d_model, n_feats, n_out):\n        super().__init__()\n        self.lin = nn.Linear(d_model + n_feats, n_out, bias=False)  # TODO what if True?\n\n    def forward(self, x, feats):\n        return self.lin(torch.cat([x, feats], dim=1))\n\n\n\n\n\nclass GloveEmbedding(nn.Module):\n    def __init__(self, num):\n        super().__init__()\n        # Make embedding\n        self.embed = nn.Embedding(400_000 + 1, num)\n        emb_w = pd.read_csv(\n            root_dir +'\/'+ f'glove.6B.{num}d.txt', header=None, sep=\" \", quoting=csv.QUOTE_NONE\n        ).values[:, 1:].astype('float64')\n        emb_w = Tensor(emb_w)\n        emb_w = torch.cat([emb_w, torch.zeros(1, num)], dim=0)\n        self.embed.weight = nn.Parameter(emb_w)\n\n    def forward(self, x):\n        return self.embed(x.to(torch.long))\n\n\n\n\n## DATA PREPARATION ##\n\nclass GloveTokenizer:\n    def __init__(self, num):\n        words = pd.read_csv(\n            root_dir + '\/'+ f'glove.6B.{num}d.txt', header=None, sep=\" \", quoting=csv.QUOTE_NONE, usecols=[0]\n        ).values\n        words = [word[0] for word in words]\n        self.word2idx = {w: i for i, w in enumerate(words)}\n\n    def __call__(self, sent):\n        toks = [self.word2idx.get(w.lower()) for w in word_tokenize(sent)]\n        return [self.unk_token if t is None else t for t in toks]\n\n    @property\n    def unk_token(self):\n        return 400_000  # We appended this to the end of the embedding to return all zeros\n\n    @property\n    def pad_token(self):\n        return self.unk_token  # Seems that this is the best option for GLOVE\n\n\ndef prepare_txts(txts, tokenizer):\n    # Input: (bs,) str, Output: (bs, max_doc_len, max_sent_len)\n    # We choose to elongate all docs and sentences to the max rather than truncate some of them\n    # TODO: Do this better later:\n    # (1) Truncate smartly (if there is one very long outlier sentence or doc)\n    # (2) Group together docs of similar lengths (in terms of num_sents)\n    docs = [[tokenizer(sent) for sent in sent_tokenize(txt)] for txt in txts]\n    # pkl_save(root_dir\/\"doc_lens\", pd.Series([len(doc) for doc in docs]))\n    max_doc_len = max([len(doc) for doc in docs])\n    docs = [doc + [[]] * (max_doc_len - len(doc)) for doc in docs]\n    # pkl_save(root_dir\/\"sent_lens\", pd.Series([len(sent) for doc in docs for sent in doc]))\n    max_sent_len = max([len(sent) for doc in docs for sent in doc])\n    docs = [[s + [tokenizer.pad_token] * (max_sent_len - len(s)) for s in doc] for doc in docs]\n    return Tensor(docs)\n\n\ndef prepare_txts_cut(txts, tokenizer, max_doc_len=18, max_sent_len=49):\n    docs = [[tokenizer(sent)[:max_sent_len] for sent in sent_tokenize(txt)[:max_doc_len]] for txt in txts]\n    docs = [doc + [[]] * (max_doc_len - len(doc)) for doc in docs]\n    docs = [[s + [tokenizer.pad_token] * (max_sent_len - len(s)) for s in doc] for doc in docs]\n    return Tensor(docs)\n\n\n\n\n","fcd74acf":"## TRAIN ## (using fastai)\n\ntokenizer = GloveTokenizer(200)\nembed = GloveEmbedding(200)\n\ndef get_splits(data):\n  num = len(data)\n  idx = list(range(num))\n  random.seed(42)\n  random.shuffle(idx)\n  split = int(num*0.75)\n  return idx[:split], idx[split:]\n\n\ndef get_dls(bs,path):\n  data = pd.read_csv(path)\n  txts = data.excerpt.tolist()\n  x = prepare_txts_cut(txts, tokenizer)\n  y = data.target.tolist()\n\n  ds = TfmdLists(\n      zip(x, y),\n      tfms=[],\n      splits=get_splits(data),\n  )\n  #print(ds)\n  dls = ds.dataloaders(batch_size=bs)\n  print(dls)\n  return dls\n","9e9d22ae":"def get_model():\n    readnet = ReadNet(\n        embed=embed,\n        d_model=200,\n        n_heads=4,\n        n_blocks=6,\n        n_feats_sent=0,\n        n_feats_doc=0,\n    )\n    readnet = readnet.cuda()\n\n    # Automatically freeze the embedding. We should not be learning this\n    for p in readnet.embed.parameters():\n        p.requires_grad = False\n\n    return readnet","44364981":"\nlearn = Learner(dls=get_dls(32,path=\"..\/input\/commonlitreadabilityprize\/train.csv\"), model=get_model(), loss_func=MSELossFlat())\nlearn.summary()\nlearn.lr_find()\nlearn.fit_one_cycle(20, 3e-5,cbs=SaveModelCallback())","833d651c":"import gc","dec81f73":"#del learn\ngc.collect()","d8ed6dcc":"test_df= pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')","ec0bf448":"test_df","dcd5fa4a":"def prepare_txts_pred(txts, tokenizer, max_doc_len=18, max_sent_len=49):\n    docs = [[tokenizer(sent)[:max_sent_len] for sent in sent_tokenize(txt)[:max_doc_len]] for txt in txts]\n    docs = [doc + [[]] * (max_doc_len - len(doc)) for doc in docs]\n    docs = [[s + [tokenizer.pad_token] * (max_sent_len - len(s)) for s in doc] for doc in docs]\n    return Tensor(docs)","5eebd81b":"txts = test_df.excerpt.tolist()\nx = prepare_txts_pred(txts, tokenizer)\n","91528849":"model = get_model()","23493da5":"del learn\ngc.collect()","277eebe8":"model.load_state_dict(torch.load('.\/models\/model.pth'))","f6d83f17":"device = \"cuda:0\"\nmodel = model.to(device)","5c88a9fa":"len(x)","10531dd8":"pred_batch_List=[]","f0c7a31b":"last = 0","98997424":"for i in range(0,len(x)-4,4):\n    pred_batch_List.append((x[i:i+4]))\n    last = i + 4\n    torch.cuda.empty_cache()\npred_batch_List.append(x[last:len(x)])","4de73306":"predictions = []","ab05e03d":"for x in pred_batch_List:\n    with torch.no_grad():\n        a= x.to(device)\n        y_temp = model(a)\n        y_temp = y_temp.cpu()\n        predictions.append(y_temp)\n    del y_temp\n    del a\n    gc.collect()\n    ","f276eab0":"import operator as op","93b20dba":" torch.cuda.memory_summary(device=None, abbreviated=False)","3fa8c34c":"len(pred_batch_List)","088c2dd2":"y=torch.cat(predictions)","6a220544":"len(y)","98ce55d1":"y = y.cpu()","47e01d9b":"preds = y.detach().numpy()","0e99b130":"preds","935edb3a":"list(preds)","5928477c":"test_df","502f17f1":"sub = test_df","d770d72f":"samp= pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")","c90fbe89":"samp","43126294":"sub[\"target\"] = preds","a0a979ce":"sub.drop([\"url_legal\",\"license\",\"excerpt\"],axis=1,inplace=True)","c6ea46f2":"sub","16cca460":"sub.to_csv(\"submission.csv\",index=False)","c7ac0c06":"* This notebook uses the readnet implementation from https:\/\/github.com\/vdefont\/readnet.\n* Readnet Paper : https:\/\/arxiv.org\/abs\/2103.04083\n","945cc144":"In this notebook we'll try to use ReadNet for calculating the readability value of given samples. Since readnet has achived a far better acuuracy than BERT on the Text Classification on WeeBit (Readability Assessment) , we'll see whether the same improved performance is reflected in CommonLit Readability Competition.\n","b2a8d517":"## submission\nsave the predictions to sub and save it to submission.csv for prediction","6a1caae6":"## Model\nThe model is loaded into cuda using the get model function and we define the parameters here.\nNote: d_model must be a multiple of n_heads.","cef6556b":"## Results \nAlthough the validation score was 0.47 , The submission score was not 0.674 .The model has not generalized well, I have observed this with other models too, do share your thoughts on this in the comments.","2fd24e1e":"![Readnet ](https:\/\/media.springernature.com\/original\/springer-static\/image\/chp%3A10.1007%2F978-3-030-45439-5_3\/MediaObjects\/492459_1_En_3_Fig1_HTML.png)","e21a23ae":"### Multi-Head Attention","501501ab":"## Batching\nBatch the inputs during prediction as well since the test set during submission run is a much larger dataset.","f7ae0cb1":"## Defining the layers \nThe layers from the representation of readnet is implemented below.","6d70ea09":"### Add & Norm","dc7a396e":"### Atention ","f40c4122":"## Credits","c4914535":"### Importing Required libraries","b21ed213":"### Positional Encoding and Tokenizing Layers","39f6a058":"## Tokenization and embedding\n\nThe golve tokenizer is used to tokenize and then glove embeddings of corresponding words are givenas input to the model , we'll be using glove 200 d vector since it gave the best results for us.","0d4ea429":"## Load Model\n\nLoad the trained model for prediction on test dataset","b1447af1":"## Training\nTrain the model with the given ","83ce8986":"# ReadNet: A Hierarchical Transformer Framework for Web Article Readability Analysis","a9cdaca5":"## Predicting","271afe95":"### Readnet ","744f7d6b":"### Feed Forward","1e2d0baa":"The   [ReadNet](https:\/\/arxiv.org\/abs\/2103.04083) was published in 2021 march, it  proposed a new and comprehensive framework which uses a hierarchical self-attention model to analyze document readability.It has been evaluated over three widely-used benchmark datasets against several strong baseline approaches. Experimental results showed that the  proposed method achieves the state-of-the-art performance on estimating the readability for various web articles and literature."}}