{"cell_type":{"05d7c49a":"code","af8d2403":"code","6d670a22":"code","fd333b16":"code","84912cc8":"code","b1260163":"code","20afc3e0":"code","67dc7beb":"code","66fce9c2":"code","9099a1ae":"code","6fe5d3c0":"code","0db355d6":"code","8688a9f8":"code","01b5fd3a":"code","e7e4c1ad":"code","dc94b466":"code","30bd4f4d":"code","232142eb":"code","b175fee4":"code","0dce246e":"code","231a9f9e":"code","ce4022b4":"code","d8fe968e":"code","70c29c3f":"code","778802ed":"code","48d41ee7":"code","648c6a33":"code","fe7f1d96":"code","6516b7a7":"code","e4c7aa4f":"code","c22073b4":"markdown","abff9d1d":"markdown","03aa8d38":"markdown","132daa16":"markdown"},"source":{"05d7c49a":"# import the necessary package\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport zipfile\nimport os\n\n#digunakan untuk membuat model dan data preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding, Bidirectional\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n#untuk menampilkan gambar\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline","af8d2403":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6d670a22":"dataset = pd.read_csv ('\/kaggle\/input\/seoul-bike-sharing-demand-prediction\/SeoulBikeData.csv')","fd333b16":"dataset.head()","84912cc8":"print ('Shape dataset')\nprint (dataset.shape)\nprint ('\\n')\nprint ('Info Dataset')\nprint (dataset.info())\nprint ('\\n')\nprint ('See if any missing value of Dataset')\nprint (dataset.isna().sum())","b1260163":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nfrom pylab import rcParams\nsns.set_style(\"darkgrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","20afc3e0":"sns.countplot(x=\"Seasons\",data=dataset)","67dc7beb":"sns.countplot(x=\"Holiday\", data=dataset)","66fce9c2":"dataset['Date'] = pd.to_datetime(dataset['Date'])","9099a1ae":"dataset['Year'] = dataset['Date'].dt.year\ndataset['Month'] = dataset['Date'].dt.month\ndataset['Day'] = dataset['Date'].dt.day\ndataset.tail()","6fe5d3c0":"sns.countplot(x=\"Year\", data=dataset)","0db355d6":"sns.countplot(x=\"Month\", data=dataset)","8688a9f8":"Years = dataset.groupby(\"Year\").sum().reset_index()\nplt.figure(figsize=(16,4), dpi=150)\nsns.barplot(x=\"Year\", y=\"Rented Bike Count\", data=Years)\nplt.xticks(rotation=90);","01b5fd3a":"Month = dataset.groupby(\"Month\").sum().reset_index()\nplt.figure(figsize=(16,4), dpi=150)\nsns.barplot(x=\"Month\", y=\"Rented Bike Count\", data=Month)\nplt.xticks(rotation=90);","e7e4c1ad":"Day = dataset.groupby(\"Day\").sum().reset_index()\nplt.figure(figsize=(16,4), dpi=150)\nsns.barplot(x=\"Day\", y=\"Rented Bike Count\", data=Day)\nplt.xticks(rotation=90);","dc94b466":"Season = dataset.groupby(\"Seasons\").sum().reset_index()\nplt.figure(figsize=(16,4), dpi=150)\nsns.barplot(x=\"Seasons\", y=\"Rented Bike Count\", data=Season)\nplt.xticks(rotation=90);","30bd4f4d":"plt.figure(figsize=(12,4), dpi=100)\nsns.lineplot(data=dataset, x=\"Hour\", y=\"Rented Bike Count\", hue=\"Seasons\")","232142eb":"plt.figure(figsize=(12,8), dpi=150)\nsns.heatmap(dataset.corr(),annot=True)","b175fee4":"plt.figure(figsize=(2,4), dpi=150)\nsns.heatmap(dataset.corr()[[\"Rented Bike Count\"]].sort_values\n            (by=\"Rented Bike Count\", ascending=False)[1:],annot=True)","0dce246e":"fig, axs = plt.subplots(nrows=4,ncols=1,figsize=(12,10), dpi=100)\nsns.pointplot(data=dataset, x=\"Hour\", y=\"Rented Bike Count\", ax=axs[0])\nsns.pointplot(data=dataset, x=\"Hour\", y=\"Rented Bike Count\", ax=axs[1], \n              hue=\"Holiday\")\nsns.pointplot(data=dataset, x=\"Hour\", y=\"Rented Bike Count\", ax=axs[2], \n              hue=\"Functioning Day\")\nsns.pointplot(data=dataset, x=\"Hour\", y=\"Rented Bike Count\", ax=axs[3], \n              hue=\"Seasons\")\nplt.tight_layout()","231a9f9e":"#change the index\ndataset.index = pd.to_datetime(dataset.index)","ce4022b4":"MinMax_scaler = MinMaxScaler(feature_range=(0, 1))\ndataset['Rented Bike Count'] = MinMax_scaler.fit_transform(dataset['Rented Bike Count'].values.reshape(-1, 1))","d8fe968e":"Rented = dataset['Rented Bike Count'].to_numpy()\ndates = dataset.index\n\ndate_train, date_test, rented_train, rented_test = train_test_split (dates, Rented,test_size = 0.2, random_state=25)","70c29c3f":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.map(lambda w: (w[:-1], w[-1:]))\n    return ds.batch(batch_size).prefetch(1)","778802ed":"train_set = windowed_dataset(rented_train, window_size=60, batch_size=100, shuffle_buffer=1000)\nval_set = windowed_dataset(rented_test, window_size=60, batch_size=100, shuffle_buffer=1000)","48d41ee7":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('mae')<0.01 \n       and \n       logs.get('val_mae')<0.01):\n      print(\"\\n Mean Absolute Error <10%!\")\n      self.model.stop_training = True\ncallbacks = myCallback()","648c6a33":"model = tf.keras.models.Sequential([\n  tf.keras.layers.LSTM(10, return_sequences=True),\n  tf.keras.layers.Dropout(rate=0.1),\n  tf.keras.layers.LSTM(10,return_sequences=False),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dropout(rate=0.1),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n])","fe7f1d96":"optimizer = tf.keras.optimizers.SGD(learning_rate=1.00e-05, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])","6516b7a7":"Training = model.fit(train_set, epochs=25, steps_per_epoch= 10,\n                    batch_size= 62, validation_data=val_set, \n                    verbose=2, callbacks=[callbacks])","e4c7aa4f":"plt.figure()\nplt.subplot(211)\nplt.plot(Training.history['mae'])\nplt.plot(Training.history['val_mae'])\nplt.title('Model Mean Absolute Error (MAE)')\nplt.ylabel('MAE')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\nplt.subplot(212)\nplt.plot(Training.history['loss'])\nplt.plot(Training.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","c22073b4":"Normalization dataset using Minmax Scalar","abff9d1d":"**Let's extract new columns (day of the week, day of the month, hour, month, season, year etc.) by using new index.**","03aa8d38":"Plot bike shares by months and year_of_month to understand the correlation between bike shares and months","132daa16":"**Predicting the data using LSTM**"}}