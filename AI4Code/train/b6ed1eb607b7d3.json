{"cell_type":{"dc412179":"code","2143af68":"code","748487f0":"code","87503927":"code","ec929b25":"code","9c1cd5e8":"code","52b5d486":"code","7f93b7be":"code","3f70465a":"code","750e952f":"code","4ff5a365":"code","b9c07632":"code","e4dc1407":"code","d3e29989":"code","40906513":"code","44d0f7ca":"code","51a5a092":"code","4029d07a":"code","315aabc6":"code","a40e76b9":"code","f0713f40":"code","8e0de081":"code","187acf5d":"code","53f88a2a":"code","a29b71ff":"code","7d60cd75":"code","af0a48f0":"code","d90ba35b":"code","86bae3da":"code","6c959cab":"code","5a32b88b":"code","38328305":"code","5555f8fc":"code","5651a641":"code","157d2e4f":"code","41b1b9cf":"code","a92fcc0f":"code","1210b6fb":"code","bbf47925":"markdown","33c3b0b3":"markdown","5dd00462":"markdown","8122241b":"markdown","3e2dd7d1":"markdown","4d6ec3fa":"markdown","cf1e7ffc":"markdown","53682a2c":"markdown","77075acf":"markdown","5b368e0f":"markdown","5e68e895":"markdown","fc97b414":"markdown","4b3e9023":"markdown","84524d72":"markdown","4ebc72c5":"markdown","17845edf":"markdown","b4a4c161":"markdown","b1608c96":"markdown","505f4420":"markdown","188cc3a0":"markdown","ef1fde18":"markdown","cf59aa1e":"markdown","b128ba91":"markdown","2f401cfb":"markdown","20e0746d":"markdown","79e9d689":"markdown","82f7eadd":"markdown","42bb41c2":"markdown","0ba8b7e2":"markdown","261d292a":"markdown","97460286":"markdown","760af62c":"markdown","58c5606b":"markdown","2020cb96":"markdown","d501c6de":"markdown","f16e15c5":"markdown","50cce42e":"markdown","0d7d86c5":"markdown","4e4a5295":"markdown","c26558e9":"markdown","64a5b416":"markdown","eadf0d8c":"markdown","6421ec4d":"markdown","4aeb3145":"markdown","1414f886":"markdown","5ca41916":"markdown","7eb33573":"markdown"},"source":{"dc412179":"#import linear algebra and data manipulation libraries\nimport numpy as np\nimport pandas as pd\n\n#import standard visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import machine learning\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nimport xgboost\n\nfrom sklearn.model_selection import train_test_split #split\nfrom sklearn.metrics import accuracy_score #metrics\n\n#tools for hyperparameters search\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2143af68":"#import dataset\n\ndf = pd.read_csv('..\/input\/bank.csv')","748487f0":"df.head()","87503927":"# number of rows in dataset\n\nprint(\"Bank marketing dataset consists of {rows} rows.\".format(rows = len(df)))","ec929b25":"#find percentage of missing values for each column\nmissing_values = df.isnull().mean()*100\n\nmissing_values.sum()","9c1cd5e8":"cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','poutcome']\n\nfig, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(20, 15))\n\ncounter = 0\nfor cat_column in cat_columns:\n    value_counts = df[cat_column].value_counts()\n    \n    trace_x = counter \/\/ 3\n    trace_y = counter % 3\n    x_pos = np.arange(0, len(value_counts))\n    \n    axs[trace_x, trace_y].bar(x_pos, value_counts.values, tick_label = value_counts.index)\n    \n    axs[trace_x, trace_y].set_title(cat_column)\n    \n    for tick in axs[trace_x, trace_y].get_xticklabels():\n        tick.set_rotation(90)\n    \n    counter += 1\n\nplt.show()","52b5d486":"num_columns = ['balance', 'day','duration', 'campaign', 'pdays', 'previous']\n\nfig, axs = plt.subplots(2, 3, sharex=False, sharey=False, figsize=(20, 15))\n\ncounter = 0\nfor num_column in num_columns:\n    \n    trace_x = counter \/\/ 3\n    trace_y = counter % 3\n    \n    axs[trace_x, trace_y].hist(df[num_column])\n    \n    axs[trace_x, trace_y].set_title(num_column)\n    \n    counter += 1\n\nplt.show()","7f93b7be":"df[['pdays', 'campaign', 'previous']].describe()","3f70465a":"len (df[df['pdays'] > 400] ) \/ len(df) * 100","750e952f":"len (df[df['campaign'] > 34] ) \/ len(df) * 100","4ff5a365":"len (df[df['previous'] > 34] ) \/ len(df) * 100","b9c07632":"value_counts = df['deposit'].value_counts()\n\nvalue_counts.plot.bar(title = 'Deposit value counts')","e4dc1407":"#job and deposit\nj_df = pd.DataFrame()\n\nj_df['yes'] = df[df['deposit'] == 'yes']['job'].value_counts()\nj_df['no'] = df[df['deposit'] == 'no']['job'].value_counts()\n\nj_df.plot.bar(title = 'Job and deposit')","d3e29989":"#marital status and deposit\nj_df = pd.DataFrame()\n\nj_df['yes'] = df[df['deposit'] == 'yes']['marital'].value_counts()\nj_df['no'] = df[df['deposit'] == 'no']['marital'].value_counts()\n\nj_df.plot.bar(title = 'Marital status and deposit')","40906513":"#education and deposit\nj_df = pd.DataFrame()\n\nj_df['yes'] = df[df['deposit'] == 'yes']['education'].value_counts()\nj_df['no'] = df[df['deposit'] == 'no']['education'].value_counts()\n\nj_df.plot.bar(title = 'Education and deposit')","44d0f7ca":"#type of contact and deposit\nj_df = pd.DataFrame()\n\nj_df['yes'] = df[df['deposit'] == 'yes']['contact'].value_counts()\nj_df['no'] = df[df['deposit'] == 'no']['contact'].value_counts()\n\nj_df.plot.bar(title = 'Type of contact and deposit')","51a5a092":"#balance and deposit\n\nb_df = pd.DataFrame()\nb_df['balance_yes'] = (df[df['deposit'] == 'yes'][['deposit','balance']].describe())['balance']\nb_df['balance_no'] = (df[df['deposit'] == 'no'][['deposit','balance']].describe())['balance']\n\nb_df","4029d07a":"b_df.drop(['count', '25%', '50%', '75%']).plot.bar(title = 'Balance and deposit statistics')","315aabc6":"#age and deposit\n\na_df = pd.DataFrame()\na_df['age_yes'] = (df[df['deposit'] == 'yes'][['deposit','age']].describe())['age']\na_df['age_no'] = (df[df['deposit'] == 'no'][['deposit','age']].describe())['age']\n\na_df","a40e76b9":"a_df.drop(['count', '25%', '50%', '75%']).plot.bar(title = 'Age and deposit statistics')","f0713f40":"#number of contacts performed during this campaign ('campaign') and deposit\nc_df = pd.DataFrame()\nc_df['campaign_yes'] = (df[df['deposit'] == 'yes'][['deposit','campaign']].describe())['campaign']\nc_df['campaign_no'] = (df[df['deposit'] == 'no'][['deposit','campaign']].describe())['campaign']\n\nc_df","8e0de081":"c_df.drop(['count', '25%', '50%', '75%']).plot.bar(title = 'Number of contacts performed during this campaign and deposit statistics')","187acf5d":"#number of contacts performed during previous campaign ('previous') and deposit\np_df = pd.DataFrame()\np_df['previous_yes'] = (df[df['deposit'] == 'yes'][['deposit','previous']].describe())['previous']\np_df['previous_no'] = (df[df['deposit'] == 'no'][['deposit','previous']].describe())['previous']\n\np_df","53f88a2a":"p_df.drop(['count', '25%', '50%', '75%']).plot.bar(title = 'Number of contacts performed during previous campaign and deposit statistics')","a29b71ff":"def get_dummy_from_bool(row, column_name):\n    ''' Returns 0 if value in column_name is no, returns 1 if value in column_name is yes'''\n    return 1 if row[column_name] == 'yes' else 0\n\ndef get_correct_values(row, column_name, threshold, df):\n    ''' Returns mean value if value in column_name is above threshold'''\n    if row[column_name] <= threshold:\n        return row[column_name]\n    else:\n        mean = df[df[column_name] <= threshold][column_name].mean()\n        return mean\n\ndef clean_data(df):\n    '''\n    INPUT\n    df - pandas dataframe containing bank marketing campaign dataset\n    \n    OUTPUT\n    df - cleaned dataset:\n    1. columns with 'yes' and 'no' values are converted into boolean variables;\n    2. categorical columns are converted into dummy variables;\n    3. drop irrelevant columns.\n    4. impute incorrect values\n    '''\n    \n    cleaned_df = df.copy()\n    \n    #convert columns containing 'yes' and 'no' values to boolean variables and drop original columns\n    bool_columns = ['default', 'housing', 'loan', 'deposit']\n    for bool_col in bool_columns:\n        cleaned_df[bool_col + '_bool'] = df.apply(lambda row: get_dummy_from_bool(row, bool_col),axis=1)\n    \n    cleaned_df = cleaned_df.drop(columns = bool_columns)\n    \n    #convert categorical columns to dummies\n    cat_columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n    \n    for col in  cat_columns:\n        cleaned_df = pd.concat([cleaned_df.drop(col, axis=1),\n                                pd.get_dummies(cleaned_df[col], prefix=col, prefix_sep='_',\n                                               drop_first=True, dummy_na=False)], axis=1)\n    \n    #drop irrelevant columns\n    cleaned_df = cleaned_df.drop(columns = ['pdays'])\n    \n    #impute incorrect values and drop original columns\n    cleaned_df['campaign_cleaned'] = df.apply(lambda row: get_correct_values(row, 'campaign', 34, cleaned_df),axis=1)\n    cleaned_df['previous_cleaned'] = df.apply(lambda row: get_correct_values(row, 'previous', 34, cleaned_df),axis=1)\n    \n    cleaned_df = cleaned_df.drop(columns = ['campaign', 'previous'])\n    \n    return cleaned_df","7d60cd75":"#clean the dataset\ncleaned_df = clean_data(df)\ncleaned_df.head()","af0a48f0":"X = cleaned_df.drop(columns = 'deposit_bool')\ny = cleaned_df[['deposit_bool']]","d90ba35b":"TEST_SIZE = 0.3\nRAND_STATE = 42","86bae3da":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state=RAND_STATE)","6c959cab":"#train XGBoost model\nxgb = xgboost.XGBClassifier(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)\nxgb.fit(X_train,y_train.squeeze().values)\n\n#calculate and print scores for the model for top 15 features\ny_train_preds = xgb.predict(X_train)\ny_test_preds = xgb.predict(X_test)\n\nprint('XGB accuracy score for train: %.3f: test: %.3f' % (\n        accuracy_score(y_train, y_train_preds),\n        accuracy_score(y_test, y_test_preds)))","5a32b88b":"#get feature importances from the model\nheaders = [\"name\", \"score\"]\nvalues = sorted(zip(X_train.columns, xgb.feature_importances_), key=lambda x: x[1] * -1)\nxgb_feature_importances = pd.DataFrame(values, columns = headers)\n\n#plot feature importances\nx_pos = np.arange(0, len(xgb_feature_importances))\nplt.bar(x_pos, xgb_feature_importances['score'])\nplt.xticks(x_pos, xgb_feature_importances['name'])\nplt.xticks(rotation=90)\nplt.title('Feature importances (XGB)')\n\nplt.show()","38328305":"df_new = cleaned_df.copy()\n\n#introduce new column 'balance_buckets' to  ''\ndf_new['balance_buckets'] = pd.qcut(df_new['balance'], 50, labels=False, duplicates = 'drop')\n\n#group by 'balance_buckets' and find average campaign outcome per balance bucket\nmean_deposit = df_new.groupby(['balance_buckets'])['deposit_bool'].mean()\n\n#plot\nplt.plot(mean_deposit.index, mean_deposit.values)\nplt.title('Mean % subscription depending on account balance')\nplt.xlabel('balance bucket')\nplt.ylabel('% subscription')\nplt.show()","5555f8fc":"df_new[df_new['balance_buckets'] == 34]['balance'].min()","5651a641":"#introduce new column 'age_buckets' to  ''\ndf_new['age_buckets'] = pd.qcut(df_new['age'], 20, labels=False, duplicates = 'drop')\n\n#group by 'balance_buckets' and find average campaign outcome per balance bucket\nmean_age = df_new.groupby(['age_buckets'])['deposit_bool'].mean()\n\n#plot\nplt.plot(mean_age.index, mean_age.values)\nplt.title('Mean % subscription depending on age')\nplt.xlabel('age bucket')\nplt.ylabel('% subscription')\nplt.show()","157d2e4f":"df_new[df_new['age_buckets'] == 3]['age'].max()","41b1b9cf":"df_new[df_new['age_buckets'] == 17]['age'].min()","a92fcc0f":"#introduce new column 'age_buckets' to  ''\ndf_new['campaign_buckets'] = pd.qcut(df_new['campaign_cleaned'], 20, labels=False, duplicates = 'drop')\n\n#group by 'balance_buckets' and find average campaign outcome per balance bucket\nmean_campaign = df_new.groupby(['campaign_buckets'])['deposit_bool'].mean()\n\n#plot average campaign outcome per bucket \nplt.plot(mean_campaign.index, mean_campaign.values)\nplt.title('Mean % subscription depending on number of contacts')\nplt.xlabel('number of contacts bucket')\nplt.ylabel('% subscription')\nplt.show()","1210b6fb":"df_new[df_new['campaign_buckets'] == 2]['campaign_cleaned'].min()","bbf47925":"After we imported the dataset, we have to look at the total number of rows in the dataset and analyze the number of missing values.","33c3b0b3":"'campaign' holds the number of contacts performed during this campaign and for this client (numeric, includes last contact)\nNumbers for 'campaign' above 34 are clearly noise, so I suggest to impute them with average campaign values while data cleaning.","5dd00462":"## Machine Learning for prediction of campaign outcome","8122241b":"From the diagram above we can conclude, that marketing campaigns should concentrate on customers with account balance greater than 1490$.","3e2dd7d1":"'previous' holds the number of contacts performed before this campaign and for this client (numeric)\nNumbers for 'previous' above 34 are also really strange, so I suggest to impute them with average campaign values while data cleaning.","4d6ec3fa":"3. Find out appropriate number of contacts with the customer during campaign:","cf1e7ffc":"### Analysis of the response column","53682a2c":"## Data Exploration","77075acf":"Now let's use cleaned datasets for prediction of campaign outcome with help of machine learning classification models. I will use __[XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/)__, which is one of the most common machine learning libraries for modelling.\n<br> Resulting model will also help me to understand, which features have the greatest importance for the prediction of the results of the campaing.","5b368e0f":"Regarding the diagrams we can tell that according to our dataset:\n1. Customers with 'blue-collar' and 'services' jobs are less likely to subscribe for term deposit.\n2. Married customers are less likely to subscribe for term deposit.\n3. Customers with 'cellular' type of contact are less likely to subscribe for term deposit.","5e68e895":"So we see that average subscrition rate tends to be higher for customers below 31 years old or above 56 years old.","fc97b414":"In order to optimize marketing campaigns with the help of the dataset, we will have to take the following steps:\n1. Import data from dataset and perform initial high-level analysis: look at the number of rows, look at the missing values, look at dataset columns and their values respective to the campaign outcome.\n2. Clean the data: remove irrelevant columns, deal with missing and incorrect values, turn categorical columns into dummy variables.\n3. Use machine learning techniques to predict the marketing campaign outcome and to find out factors, which affect the success of the campaign.","4b3e9023":"Let's see how 'deposit' column value varies depending on other categorical columns' values:","84524d72":"In general, datasets which contain marketing data can be used for 2 different business goals:\n1. Prediction of the results of the marketing campaign for each customer and clarification of factors which affect the campaign results. This helps to find out the ways how to make marketing campaigns more efficient.\n2. Finding out customer segments, using data for customers, who subscribed to term deposit. This helps to identify the profile of a customer, who is more likely to acquire the product and develop more targeted marketing campaigns.","4ebc72c5":"1. Find out account balance, which marketing campaign should focus on: ","17845edf":"Get the feature importances from the trained model:","b4a4c161":"'pdays' holds the number of days that passed by after the client was last contacted from a previous campaign\nLooking closer into 'pdays' data we can see that:\n* only 1.2% of values above 400. They are possibly outliers, so we should consider imputing something (possibly mean value) instead of these values.\n* -1 possibly means that the client wasn't contacted before or stands for missing data.\n\nSince we are not sure exactly what -1 means I suggest to drop this column, because -1 makes more than 50% of the values of the column.","b1608c96":"### Numerical columns exploration","505f4420":"On the diagram we see that counts for 'yes' and 'no' values for 'deposit' are close, so we can use accuracy as a metric for a model, which predicts the campaign outcome.","188cc3a0":"Percentage of 'pdays' values above 400:","ef1fde18":"Before we will be able to apply machine learning techniques, we should prepare the dataset for processing:\n1. Convert columns with 'yes' and 'no' values to boolean columns;\n2. Convert categorical columns into dummy variables.","cf59aa1e":"Key outcomes of the analysis are the recommendations for future marketing campaigns:\n* The customer's account balance has a huge influence on the campaign's outcome. People with account balance above 1490$ are more likely to subscribe for term deposit, so future address those customers.\n* The customer's age affects campaign outcome as well. Future campains should concentrate on customers from age categories below 30 years old and above 50 years old.\n* Number of contacts with the customer during the campaign is also very important. The number of contacts with the customer shouldn't exceed 4.","b128ba91":"We can see that numerical columns have outliers (especially 'pdays', 'campaign' and 'previous' columns). Possibly there are incorrect values (noisy data), so we should look closer at the data and decide how do we manage the noise.\n<br> Let's look closer at the values of 'campaign', 'pdays' and 'previous' columns:","2f401cfb":"Today organizations, which hire data scientists are especially interested in job candidate's portfolio. Analysis of organization's marketing data is one of the most typical applications of data science and machine learning. Such analysis will definetely be a nice contribution to the protfolio.","20e0746d":"As we can see from the diagram showing feature importances, the most important features are:\n* Customer's account balance,\n* Customer's age,\n* Number of contacts performed during this campaign and contact duration,\n* Number of contacts performed before this campaign.","79e9d689":"In the dataset we have both categorical and numerical columns. Let's look at the values of categorical columns first.","82f7eadd":"## Introduction","42bb41c2":"Create X and y datasets for training the model and split into train and test datasets.","0ba8b7e2":"## Import Data","261d292a":"Percentage of 'previous' values above 20:","97460286":"Percentage of 'campaign' values above 20:","760af62c":"It is very important to look at the response column, which holds the information, which we are going to predict. In our case we should look at 'deposit' column and compare its values to other columns. \n<br> First of all we should look at the number of 'yes' and 'no' values in the response column 'deposit'.","58c5606b":"Let's try to make more specific recommendations:","2020cb96":"From the plot above we see that average subscription rate is below 50% if the number of contacts during the campaign exceeds 4.","d501c6de":"So the main outcomes of the modelling are:\n* Customers of greater age are more likely to subscribe for the term deposit.\n* Customers with greater account balance are more likely to subscribe for the term deposit.\n* Number of contacts with the customers really matters. Too many contacts with the customer could make him decline the offer.","f16e15c5":"## Data Cleaning","50cce42e":"Train XGBoost classifier model:","0d7d86c5":"So we see that there are no missing values.","4e4a5295":"Now let's look at the numerical columns' values. The most convenient way to look at the numerical values is plotting histograms.","c26558e9":"### Categorical columns exploration","64a5b416":"## Conclusion","eadf0d8c":"### Classification model for the campaign outcome prediction","6421ec4d":"Looking at the diagrams above we can conclude that:\n1. People who subscribed for term deposit tend to have greater balance and age values.\n2. People who subscribed for term deposit tend to have fewer number of contacts during this campaign.","4aeb3145":"Now let's look how numerical columns affect term deposit subscription.","1414f886":"This dataset contains banking marketing campaign data and we can use it to optimize marketing campaigns to attract more customers to term deposit subscription.\nDetailed description of the dataset's content is describe in this  [kaggle kernel](https:\/\/www.kaggle.com\/janiobachmann\/marketing-in-banking-opening-term-deposits).","5ca41916":"## Approach","7eb33573":"First of all to perform the analysis, we have to import the data:"}}