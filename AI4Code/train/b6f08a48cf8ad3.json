{"cell_type":{"dabbfd4a":"code","7b300dab":"code","2dbc0c52":"code","08deb0c3":"code","5f01689a":"code","7425d53a":"code","ce4277dc":"code","e7b21eef":"code","fa82914d":"code","d2ecf72c":"code","2b5806fa":"code","eac02f4a":"code","87d26c7e":"code","ffe033ab":"code","cd2fdc7f":"code","e010bb54":"code","0e5a0ef9":"markdown","e04b8618":"markdown","0be368b3":"markdown","fb952549":"markdown","f1b71940":"markdown","b3eeac18":"markdown","2540ceb5":"markdown","043ce846":"markdown"},"source":{"dabbfd4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b300dab":"! conda install -c rapidsai cudf","2dbc0c52":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as s\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nimport joblib\nfrom dask.distributed import Client\nimport pickle\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","08deb0c3":"%%time\ntrain  = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\nfeatures = pd.read_csv('..\/input\/jane-street-market-prediction\/features.csv')\nexample_test = pd.read_csv('..\/input\/jane-street-market-prediction\/example_test.csv')\nsample_prediction_df = pd.read_csv('..\/input\/jane-street-market-prediction\/example_sample_submission.csv')\nprint (\"Data is loaded!\")","5f01689a":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","7425d53a":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing\/total_cells) * 100)","ce4277dc":"%%time\ntrain = train.fillna(train.mean())","e7b21eef":"%%time\ntrain['action'] = ((train['resp'] > 0) & (train['weight'] > 0)).astype('int')","fa82914d":"%%time\ntrain = train.drop(labels='date',axis=1)\ntrain = train.drop(labels='weight',axis=1)\ntrain = train.drop(labels='resp_1',axis=1)\ntrain = train.drop(labels='resp_2',axis=1)\ntrain = train.drop(labels='resp_4',axis=1)\ntrain = train.drop(labels='resp',axis=1)","d2ecf72c":"X = train.drop(labels='action',axis=1)\ny = train['action']","2b5806fa":"%%time\nX = StandardScaler().fit_transform(X)","eac02f4a":"%%time\n# Correlation matrix\ncorrmat = train.corr()\nfig = plt.figure(figsize = (16, 16))\n\ns.heatmap(corrmat, vmax = 1, square = True,annot=True,vmin=-1)\nplt.show()","87d26c7e":"%%time\nnp.random.seed(10)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True, random_state = 0)","ffe033ab":"del X, y, train, features, example_test, sample_prediction_df","cd2fdc7f":"%%time     \ndef fitXgboostModel(X_train, X_test, y_train, y_test,algo_name,cv):\n    classifier = XGBClassifier(\n    n_estimators=500,\n    max_depth=11,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist')\n    xgboost_model = classifier.fit(X_train,y_train)\n    pred = xgboost_model.predict(X_test)\n    cm = confusion_matrix(y_test, pred)\n    print(pred)\n    pickle.dump(xgboost_model,open(algo_name,'wb'))\n\n    print('Classification Report :',classification_report(y_test,pred))\n    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n    print('Confusion Matrix : \\n', cm)\n\n\n    #def featureImportance():\n    #%%Feature importances\n\n    plt.figure(figsize=(12,12))\n    plt.barh(range(len(xgboost_model.feature_importances_)), \n             xgboost_model.feature_importances_)\n    plt.show()","e010bb54":"%%time\nfitXgboostModel(X_train, X_test, y_train, y_test,'xgboost_norm_3',cv=5)","0e5a0ef9":"### Fill Missing Values","e04b8618":"### Create Target Column","0be368b3":"### Drop unwanted Columns","fb952549":"### Missing Values Count","f1b71940":"### Identify Correlation between features","b3eeac18":"## Training","2540ceb5":"### Carry out Feature Scaling","043ce846":"### Carry out Data Spliting"}}