{"cell_type":{"201bc557":"code","46964d73":"code","70a8e20e":"code","677c2183":"code","120816d5":"code","1ff8d691":"code","6b4f8128":"code","34b015cb":"code","8c266248":"code","485b6d12":"code","b3d8c404":"markdown","d141f01b":"markdown","62b517b4":"markdown","23e7df17":"markdown","933d40a9":"markdown","6a7b0278":"markdown","8364defe":"markdown","83f92255":"markdown"},"source":{"201bc557":"# importing libraries  \nimport numpy as np \nimport matplotlib.pyplot as mtp  \nimport pandas as pd  \n  ","46964d73":"#importing datasets\ndata_set= pd.read_csv(\"..\/input\/suv-data\/suv_data.csv\")","70a8e20e":"#Extracting Independent and dependent Variable  \nx= data_set.iloc[:, [2,3]].values  \ny= data_set.iloc[:, 4].values  ","677c2183":"# Splitting the dataset into training and test set.  \nfrom sklearn.model_selection import train_test_split  \nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  ","120816d5":"#feature Scaling  \nfrom sklearn.preprocessing import StandardScaler    \nst_x= StandardScaler()    \nx_train= st_x.fit_transform(x_train)    \nx_test= st_x.transform(x_test)  ","1ff8d691":"#Fitting Logistic Regression to the training set  \nfrom sklearn.linear_model import LogisticRegression  \nclassifier= LogisticRegression(random_state=0)  \nclassifier.fit(x_train, y_train)  ","6b4f8128":"#Predicting the test set result  \ny_pred= classifier.predict(x_test)  \nprint(y_pred)","34b015cb":"#Creating the Confusion matrix  \nfrom sklearn.metrics import confusion_matrix  \ncm= confusion_matrix(y_test,y_pred)  \nprint(cm)","8c266248":"#Visualizing the training set result  \nfrom matplotlib.colors import ListedColormap  \nx_set, y_set = x_train, y_train  \nx1, x2 = np.meshgrid(np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step  =0.01),  \nnp.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))  \nmtp.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),  \nalpha = 0.75, cmap = ListedColormap(('purple','green' )))  \nmtp.xlim(x1.min(), x1.max())  \nmtp.ylim(x2.min(), x2.max())  \nfor i, j in enumerate(np.unique(y_set)):  \n    mtp.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],  \n        c = ListedColormap(('purple', 'green'))(i), label = j)  \nmtp.title('Logistic Regression (Training set)')  \nmtp.xlabel('Age')  \nmtp.ylabel('Estimated Salary')  \nmtp.legend()  \nmtp.show()  ","485b6d12":"#Visulaizing the test set result  \nfrom matplotlib.colors import ListedColormap  \nx_set, y_set = x_test, y_test  \nx1, x2 = np.meshgrid(np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step  =0.01),  \nnp.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))  \nmtp.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),  \nalpha = 0.75, cmap = ListedColormap(('purple','green' )))  \nmtp.xlim(x1.min(), x1.max())  \nmtp.ylim(x2.min(), x2.max())  \nfor i, j in enumerate(np.unique(y_set)):  \n    mtp.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],  \n        c = ListedColormap(('purple', 'green'))(i), label = j)  \nmtp.title('Logistic Regression (Test set)')  \nmtp.xlabel('Age')  \nmtp.ylabel('Estimated Salary')  \nmtp.legend()  \nmtp.show()  ","b3d8c404":"### **Data Pre-procesing Step**  ","d141f01b":"## **4. Test Accuracy of the result**","62b517b4":"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass\/fail, win\/lose, alive\/dead or healthy\/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1, with a sum of one.\n\nLogistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression[1] (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass\/fail which is represented by an indicator variable, where the two values are labeled \"0\" and \"1\". In the logistic model, the log-odds (the logarithm of the odds) for the value labeled \"1\" is a linear combination of one or more independent variables (\"predictors\"); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled \"1\" can vary between 0 (certainly the value \"0\") and 1 (certainly the value \"1\"), hence the labeling; the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio.","23e7df17":"## **5. Visualizing the training set result**","933d40a9":"## **3. Predicting the Test Result**","6a7b0278":"## **Logistic Regression in Machine Learning || By:- Ayush Namdeo**","8364defe":"**The above graph shows the test set result. As we can see, the graph is divided into two regions (Purple and Green). And Green observations are in the green region, and Purple observations are in the purple region. So we can say it is a good prediction and model. Some of the green and purple data points are in different regions, which can be ignored as we have already calculated this error using the confusion matrix**\n\n**Hence our model is pretty good and ready to make new predictions for this classification problem.**","83f92255":"## **2. Fitting Logistic Regression to the Training set:**"}}