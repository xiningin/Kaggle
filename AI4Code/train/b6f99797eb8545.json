{"cell_type":{"e640b3df":"code","11177a0a":"code","012aa085":"code","27b5eda8":"code","8515db17":"code","af99889b":"code","b10614de":"code","9dbed157":"code","00757d34":"code","b77a9de4":"code","6b669cd8":"code","dac9bdee":"code","713bde49":"code","6e80252d":"code","6a39f398":"markdown","d3aeb9b0":"markdown","761fe338":"markdown","998870bb":"markdown","d96fc7c0":"markdown","fb55bbdd":"markdown","9e97885d":"markdown","11ffca67":"markdown","ff91919e":"markdown","ddcea674":"markdown","739bf1a6":"markdown","a78b15ef":"markdown"},"source":{"e640b3df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11177a0a":"pip install scrapy","012aa085":"from scrapy import Selector\nimport requests\nimport pandas as pd","27b5eda8":"sel = Selector( text = requests.get('https:\/\/www.fundacionmapfre.org\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/').content )\nlettersSelector = sel.xpath('\/\/ul[@id=\"lista-abc\"]\/li\/\/a\/@href') # Contiene la URL para acceder a cada letra del diccionario","8515db17":"def getWords(words):\n    dictionary2 = pd.DataFrame()\n    for j in words:\n        htmlWord = requests.get(j.extract()).content\n        selWord = Selector( text = htmlWord)\n        try:\n            word = selWord.xpath('\/\/div[@class=\"heading-holder\"]\/h1\/text()').extract_first().strip()\n            definition = selWord.xpath('\/\/div[@class=\"content-box\"]\/p[1]').extract_first().strip()\n            if((definition == '<p><\/p>') or ('          <\/p>' in definition) ):\n                definition = selWord.xpath('\/\/div[@class=\"content-box\"]\/p[2]').extract_first().strip()\n            row = pd.DataFrame([[word,definition]])\n        except IndexError:\n            row = pd.DataFrame([[word,'***','IndexError']])\n        except AttributeError:\n            row = pd.DataFrame([[word,'***','AttributeError']])\n        # print(word) # quita el comentario si quieres ir viendo cada palabra y su definici\u00f3n mientras lo extrae\n        dictionary2 = dictionary2.append(row)\n    return dictionary2","af99889b":"dictionary = pd.DataFrame()\n\nfor i in lettersSelector:\n    j = 1\n    htmlLetter = requests.get('https:\/\/www.fundacionmapfre.org'+i.extract()).content\n    selLetter = Selector( text = htmlLetter )\n    words = selLetter.xpath('\/\/section[@class=\"dictionary-content\"]\/\/ul\/\/li\/a\/@href')\n    dictionary = dictionary.append(getWords(words))\n    numberOfWords = len(words)\n    while numberOfWords==24: # Si la p\u00e1gina tiene 24 palabras lo m\u00e1s probable es que haya una siguiente p\u00e1gina\n        j = j+1\n        currentLetter = i.extract()[-1]\n        htmlLetter = requests.get('https:\/\/www.fundacionmapfre.org\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/?page='+str(j)+'&charx='+currentLetter+'&start='+str(j*12)).content\n        selLetter = Selector( text = htmlLetter )\n        words = selLetter.xpath('\/\/section[@class=\"dictionary-content\"]\/\/ul\/\/li\/a\/@href')\n        dictionary = dictionary.append(getWords(words))\n        numberOfWords = len(words)\n\ndictionary.columns = ['word','definition']","b10614de":"Unavez obtenido el DataFrame dictionary, se lleva a cabo una limpieza b\u00e1sica, ya que como se mencion\u00f3 antes, la definici\u00f3n contiene diversos elementos HTML que se reemplazan por ' '. Por \u00faltimo, se aplica strip() para limpiar los multiples espacios vac\u00edos que se generan.","9dbed157":"dictionary['definition_clean'] = dictionary.definition.apply(lambda x: x.replace('<p>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/p>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<span>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/span>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<em>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/em>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<a href=\"\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/a>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('.jsp\"',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('title=\"',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('\">',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<br>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('xlink:',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<i>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/i>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<li>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<\/li>',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('.jsp%20\"',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<ol type= a',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<ol type=',' ')\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.replace('<a href=\"https:\/\/www.fundacionmapfre.org\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/',' '))\ndictionary['definition_clean'] = dictionary.definition_clean.apply(lambda x: x.strip())\n","00757d34":"mapfre_insurance_dictionary = dictionary.drop(columns=['definition'])\nmapfre_insurance_dictionary.columns = ['word','definition']\nmapfre_insurance_dictionary.set_index('word', inplace=True)\nmapfre_insurance_dictionary.to_csv('mapfre_insurance_dictionary.csv')","b77a9de4":"Para usar la informaci\u00f3n para entrenar un diccionario de palabras de seguros en vectores, se pasa todo a un string que contiene toda la base:\n","6b669cd8":"string = ''\nfor key, info in dictionary.iterrows():\n    string = string + ' ' + key + ' ' + info.definition ","dac9bdee":"import scrapy\nfrom scrapy.crawler import CrawlerProcess","713bde49":"#%%\nclass MapfreSpider(scrapy.Spider):\n    name = \"MAPFRE_dictionary_spider\"\n  \n    def start_requests(self):\n        yield scrapy.Request(url = 'https:\/\/www.fundacionmapfre.org\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/',\n                         callback = self.parse_front)\n    def parse_front(self, response):\n        links_to_letters = response.xpath('\/\/ul[@id=\"lista-abc\"]\/\/li\/a\/@href').extract()\n        for url in links_to_letters:\n          yield response.follow(url = url,\n                                callback = self.parse_letters)\n    def parse_letters(self, response):\n        links_to_words = response.xpath('\/\/section[@class=\"dictionary-content\"]\/\/ul\/\/li\/a\/@href').extract()\n        for url in links_to_words:\n          yield response.follow(url = url,\n                                callback = self.parse_words)\n    def parse_words(self, response):\n        word = response.xpath('\/\/div[@class=\"heading-holder\"]\/h1\/text()').extract_first().strip()\n        meaning = response.xpath('\/\/div[@class=\"content-box\"]\/p').extract_first().strip()\n        if meaning=='<p><\/p>':\n            meaning = response.xpath('\/\/div[@class=\"content-box\"]\/p[2]').extract_first().strip()\n        dictionary[word] = meaning","6e80252d":"dictionary = dict()\n\nprocess = CrawlerProcess()\nprocess.crawl(MapfreSpider)\nprocess.start()\n\nprint(dictionary)","6a39f398":"# Uso ","d3aeb9b0":"Otro enfoque hubiera sido el usar un Crawler de Scrapy. No lo usamos debido a que la paginaci\u00f3n de la informaci\u00f3n lo complica un poco, pero sin duda se puede. A cpntinuaci\u00f3n el c\u00f3digo para obtener las primeras 24 palabras de cada letra.","761fe338":"# Otras consideraciones","998870bb":"# Referencia","d96fc7c0":"Definimos la funci\u00f3n que obtendr\u00e1 todas las definiciones (m\u00e1ximo 24) que aparecen en una p\u00e1gina determinada correspondiente a una letra del abecedario.\n\nPara ello, a la funci\u00f3n se le pasa el selector con las palabras contenidas en dicha p\u00e1gina (ver m\u00e1s adelante).\n\nLa funci\u00f3n se dirige a cada p\u00e1gina que contiene la definici\u00f3n de la palabra. Al analizar la estructura HTML, de la p\u00e1gina con la definici\u00f3n, se vi\u00f3 lo siguiente:\n* La pablabra a ser definida se encuentra en el atributo 'text' del \u00fanico elemento 'h1' contenido en el elemento 'div' con class=\"heading-holder\". Esto facilita la extracci\u00f3n del nombre de la definici\u00f3n.\n* La definici\u00f3n se encuentra en un elemento 'p' dentro de un elemento 'div' con class=\"content-box\".\n* Sin embrago en algunas p\u00e1ginas la definici\u00f3n se encuentra en el primer elemento 'p' y en otras en el segundo, por lo que tuvo que programarse para buscar en uno u otro elemento 'p'. \n* Sin embargo no se puede extraer directamente el atributo 'text' de dicho elemento 'p', ya que en ocasiones contiene otros elementos HTML, como 'em', 'span', 'a', etc.","fb55bbdd":"# Limpieza de la base","9e97885d":"El esfuerzo llevado a cabo por MAPFRE para la elaboraci\u00f3n del diccionario es un esfuerzo colosal el cual agradecemos. La liga en donde puede encontrarse la informaci\u00f3n original es:\n\nhttps:\/\/www.fundacionmapfre.org\/fundacion\/es_es\/publicaciones\/diccionario-mapfre-seguros\/","11ffca67":"Antes de llevar a cabo el scraping, se debe conocer la estructura del HTML de la p\u00e1gina web. En este caso se analiz\u00f3 y se descubri\u00f3 la siguiente estructura:\n* Hay un \u00edndice para cada letra del alfabeto. Este \u00edndice se encuentra con la etiqueta de lista (HTML tag: ul) con id='lista-abc'. Esto facilita la b\u00fasqueda, ya que cada letra corresponde al \u00fanico elemento 'a' de cada elemento 'li' de la lista. El elemento 'a' contiene la url de las palabras del diccionario que comienzan con esa letra\n* Cada p\u00e1gina correspondiente a una letra, tiene a lo m\u00e1s 24 palabras, por lo que el total de palabras se encuentra paginado. Esto dificulta un poco el craping.\nA continuaci\u00f3n identificamos el selector para la lista de letras que conforman el diccionario:","ff91919e":"Por \u00faltimo se crea el DataFrame final y se exporta a csv.","ddcea674":"# Web Scrpaing","739bf1a6":"**NOTA: El c\u00f3digo puede tardar varias horas.**","a78b15ef":"A continuaci\u00f3n se crea el DataFrame en donde se almacenar\u00e1 la informaci\u00f3n y se corre el c\u00f3digo para ir en b\u00fasqueda de las palabras de cada letra del abecedario.\n\nDebido a que cada p\u00e1gina muestra un m\u00e1ximo de 24 palabras por p\u00e1gina, se program\u00f3 un ciclo while para detectar si hay que buscar m\u00e1s palabras. Es decir, si una p\u00e1gina tiene 24 palabras es muy probable que haya una siguiente p\u00e1gina. Por ello, mientras haya 24 palabras el c\u00f3digo ir\u00e1 en b\u00fasqueda de la siguiente p\u00e1gina."}}