{"cell_type":{"1021dc8d":"code","87e6be26":"code","f3c72a57":"code","d472958f":"code","f9306fd8":"markdown"},"source":{"1021dc8d":"#show files\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","87e6be26":"# https:\/\/jessicastringham.net\/2018\/05\/03\/smallnorb\/\nimport numpy as np\nimport struct\n\nDATA_FOLDER = \"\/kaggle\/input\/the-small-norb-dataset-v10\/\"\n\nPREFIXES = {\n    'train': 'smallnorb-5x46789x9x18x6x2x96x96-training-',\n    'test': 'smallnorb-5x01235x9x18x6x2x96x96-testing-',\n}\n\nFILE_TYPES = ['info', 'cat', 'dat']\n\n# helper function to read int from file\ndef read_int(f):\n    num, = struct.unpack('i', f.read(4))\n    return num\n\n\n# From https:\/\/cs.nyu.edu\/~ylclab\/data\/norb-v1.0-small\/ \n# \"The magic number encodes the element type of the matrix\"\n# Note: I only copied over the ones I needed for these files.\nmap_magic_number_to_data_type = {\n    '1e3d4c55': np.uint8,\n    '1e3d4c54': np.int32,\n}\n\nloaded_data = {}\n\nfor dataset, prefix in PREFIXES.items():\n    for filetype in FILE_TYPES:\n        filename = prefix + filetype + \".mat\"\n        print('Reading {}'.format(filename))\n        \n        file_loc = os.path.join(DATA_FOLDER, filename)\n        with open( file_loc, 'rb') as f:\n            # Read the magic_num, convert it to hexadecimal, and look up the data_type\n            raw_magic_num = read_int(f)\n            magic_num = format(raw_magic_num, '02x')\n            data_type = map_magic_number_to_data_type[magic_num]\n            print('dtype', data_type)\n\n            # Read how many dimensions to expect\n            ndim = read_int(f)\n            \n            # Read at least 3 ints, or however many ndim there are\n            shape = [\n                read_int(f)\n                for i in range(max(ndim, 3))\n            ]   \n            # But in case ndims < 3, take at most n_dim elements\n            shape = shape[:ndim]\n            print('shape', shape)\n    \n            # Now load the actual data!\n            loaded_data[(dataset, filetype)] = np.fromfile(\n                f, \n                dtype=data_type, \n                count=np.prod(shape)\n            ).reshape(shape)","f3c72a57":"import matplotlib.pyplot as plt","d472958f":"# taking a look in some samples\n\nx= np.random.randint( loaded_data[('train', 'cat')].shape[0], size=3)\nprint(x)\nfor i in x:\n    image  = loaded_data[('train', 'dat')][i]\n    plt.subplot(1,2, 1)\n    plt.imshow( image[0], cmap=\"gray_r\")   # pic from first camera\n    image3 = np. moveaxis ( np.concatenate( (image, image[0:1]) ), 0, -1 ) # adding third channel for RGB\n    plt.subplot(1,2, 2)\n    plt.imshow( image3, cmap=\"gray_r\")     # 'stereo'\n    plt.show()\n    # print metadata: category and properties\n    print( loaded_data[('train', 'cat')][i], loaded_data[('train', 'info')][i]  )","f9306fd8":"This code demonstrates how to load small NORB database into numpy array, it appeared to be non trivial task, because \".mat\" files is not a plain text as MNIST \".mat\".\nCode originated from\nhttps:\/\/jessicastringham.net\/2018\/05\/03\/smallnorb\/\nin its turn, it based on\nhttps:\/\/github.com\/ndrplz\/small_norb\nI just adopted it for Kaggle."}}