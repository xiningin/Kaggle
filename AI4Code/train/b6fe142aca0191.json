{"cell_type":{"f1bb65e1":"code","6cfc83b0":"code","abb89ffe":"code","aecd5b41":"code","01ca6b16":"code","4cf4b850":"code","e54c2d02":"code","c69e8e5f":"code","1bc4d9e4":"code","154f1074":"code","c5e99200":"code","d64ddafb":"code","9c5beb27":"code","f7f0c565":"code","de95946b":"markdown","df2de8ea":"markdown","da193be3":"markdown","c5a5acc5":"markdown","35e228db":"markdown","80f779f1":"markdown","38352664":"markdown","d9868046":"markdown","4ad5a69e":"markdown","ebd7b636":"markdown","656d1405":"markdown","85627354":"markdown","1ff76a13":"markdown"},"source":{"f1bb65e1":"from pprint import pprint\n\nimport spacy\nimport pandas as pd\n\nimport gensim\nfrom gensim import corpora\nfrom gensim.models.ldamodel import LdaModel\nfrom gensim.models import CoherenceModel\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nNUM_TOPICS = 5","6cfc83b0":"# load the spacy model\nnlp = spacy.load(\"en_core_web_lg\")\n# unzip and load the mallet lda folder\nmallet_path = 'mallet-2.0.8\/bin\/mallet' ","abb89ffe":"data = pd.read_csv('data.csv').set_index('Id')","aecd5b41":"print (get_text_attributes(data['text'].values[0]))","01ca6b16":"# Common patterns\nglassdoor_ids = data.loc[data.text.str.startswith('pros:')].index.tolist()\nautomobile_ids = data.loc[data.text.str.startswith('from ') | data.text.str.startswith('subject ')].index.tolist()\n\ndata.drop(glassdoor_ids+automobile_ids, inplace=True)","4cf4b850":"def get_text_attributes(text):\n    doc = nlp(text)\n#   lemmatising tokens, converting working, worked, etc to work\n    tokens = [token.lemma_ for token in doc] #if not ((token.is_punct)|(token.is_stop))\n    \n#   Get the entities (named entities) for each of the words\n    entities = [ent.label_ for ent in doc.ents]\n#     pos = [token.pos_ for token in doc]\n    print(entities)\n    pos = []\n    attributes = tokens + entities + pos\n    \n    return attributes\n\n# texts = data['text'].apply(get_text_attributes).tolist()","e54c2d02":"# out put of the function above\nprint (texts[0])","c69e8e5f":"dictionary = corpora.Dictionary(texts)\ncorpus = [dictionary.doc2bow(text) for text in texts]","1bc4d9e4":"%%time \nmodel = gensim.models.wrappers.LdaMallet(mallet_path,\n                                         corpus=corpus,\n                                         num_topics=TOPICS,\n                                         id2word=dictionary,\n                                         iterations=50000,\n                                         workers=6)\n\ncoherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\nprint(f\"Coherence: {coherence_model.get_coherence()}\")","154f1074":"data['lda_topics'] = [sorted(doc_topics, key=lambda k: k[1], reverse=True)[0][0] for doc_topics in model[corpus]]\ndata['lda_topics'].value_counts()","c5e99200":"tech_ids = data[data['lda_topics'] == 4].index.tolist()\nroomrental_ids = data[(data['lda_topics'] == 1) | (data['lda_topics'] == 2) | ((data['lda_topics'] == 5)| ((data['lda_topics'] == 0)))].index.tolist()\nsportsnews_ids = data[data['lda_topics'] == 3].index.tolist()","d64ddafb":"data[data['lda_topics'] == 1]","9c5beb27":"topic = [\"glassdoor_reviews\"]*len(glassdoor_ids) +\\\n[\"tech_news\"]*len(tech_ids) +\\\n[\"room_rentals\"]*len(roomrental_ids) +\\\n[\"sports_news\"]*len(sportsnews_ids) +\\\n[\"Automobiles\"]*len(automobile_ids) \n\nid = glassdoor_ids + tech_ids + roomrental_ids + sportsnews_ids + automobile_ids","f7f0c565":"pd.DataFrame({'topic': topic, 'Id': id}).set_index('Id').to_csv('submission_lda_reduced.csv', sep=',')","de95946b":"The below function does the following:\n- Lemmatizing the tokens in text\n- Extracting the Named Entities of tokens\n\nIn order to retain the sentence structure, stopwords are not removed as we are using NER. ","df2de8ea":"#### Create submission file","da193be3":"#### Topic Model","c5a5acc5":"#### Get topics","35e228db":"#### Load Packages","80f779f1":"#### Read data","38352664":"Based on multiple iterations of Topic Models, I noticed that there was one topic in particular which **was not appearing** very prominently in any of the five topics: \"Tech News\". So I removed those texts from the data which contained specific patterns and for which topics are not needed to be predicted based on empirical analysis of the text data. Removing cases for which we already know topics, **reduces noise from the data** and increases the chance for lesser prominent topics to show up.\n\nFor eg. the text containing the \"pros\" and \"cons\" are glassdoor reviews. Text containing \"from\" and \"subject\" are emails which contain conversations between a prospect and salesperson enquiring about cars. So that belongs to automobiles. We can leverage such patterns in the data to improve ","d9868046":"#### Extract text features","4ad5a69e":"The *lemmatised tokens* as well as the *Named Entities* of the tokens are returned in a list and that it is used as ahead to prepare the corpus and the dictionary (as shown below)","ebd7b636":"Since Topic Models are bag of words models, it can benefitted by the extra information of enitites present in the text. For example: if ORG is occurring in a text (once or multiple times) there is a higher chance that it is a \"tech news\" or \"glassdoor review\". Hence information of entities is also passed in LDAMallet.","656d1405":"#### Common token patterns","85627354":"#### Map the topics to topic names","1ff76a13":"Having already tried simple LDA with various parameter combinations, I was unable to achieve a performance beyond 93. So I started exploring other algorithms for LDA. There is a *Mallet LDA* which is known to provide better quality of topics."}}