{"cell_type":{"5fc2da75":"code","32e73c3a":"code","d1a3884e":"code","913f5af7":"code","cec1daf1":"code","0d0fad61":"code","ae7c2abb":"code","4be91233":"code","979df3aa":"code","757cc7cc":"markdown"},"source":{"5fc2da75":"import bs4\nimport requests\nimport os\nimport pandas as pd\nimport re\nfrom datetime import timedelta, datetime","32e73c3a":"def getNewsFromCategoryAndDate(category, date):\n  url = f\"https:\/\/www.bd-pratidin.com\/{category}\/{date}\"\n  page = requests.get(url)\n  soup = bs4.BeautifulSoup(page.content,\"html.parser\").find(\"div\",{\"class\": \"container-left-area col-md-9\"})\n  newsLinks = []\n\n  for a in soup.findAll(\"a\", {\"href\": re.compile(r\"^[a-z-]+\\\/\\d+\\\/\\d+\\\/\\d+\\\/\\d+$\")}):\n    newsLinks.append(a[\"href\"])\n\n  return newsLinks","d1a3884e":"def getNewsFromLink(link):\n  url = f\"https:\/\/www.bd-pratidin.com\/{link}\"\n  page = requests.get(url)\n  soup = bs4.BeautifulSoup(page.content, \"html.parser\")\n\n  title = soup.find(\"h1\", {\"class\":\"post-title\"}).text.strip()\n  description = soup.find(\"meta\",{\"property\":\"og:description\"})[\"content\"].strip()\n  category = link.split(\"\/\")[0]\n  id = int(link.split(\"\/\")[4])\n  date = \"\/\".join(link.split(\"\/\")[1:4])\n\n  articleSoup = soup.find(\"article\")\n  article = \"\"\n  for p in articleSoup.findAll(\"p\"):\n    article += p.text\n\n  return {\"id\": id,\n          \"title\": title, \n          \"description\": description, \n          \"category\": category,\n          \"date\": date,\n          \"article\": article}","913f5af7":"def getNewsFromDate(date, save=0, verbose=1):\n  url = f\"https:\/\/www.bd-pratidin.com\/archive\/{date}\"\n  page = requests.get(url)\n  soup = bs4.BeautifulSoup(page.content, \"html.parser\").find(\"div\", {\"class\": \"container-left-area printversion col-md-9\"})\n  categories = set()\n\n  for a in soup.findAll(\"a\", {\"href\": re.compile(r\"^[a-z-]+\\\/\\d+\\\/\\d+\\\/\\d+\")}):\n    categories.add(a[\"href\"].split(\"\/\")[0])\n  categories = list(categories)\n\n  if verbose==1:\n    print(f\"There are {len(categories)} categories.\")\n\n  news = []\n  for category in categories:\n    newsLink = getNewsFromCategoryAndDate(category, date)\n\n    if verbose==1:\n      print(f\"Downloading {len(newsLink)} news from '{category}' category...\")\n\n    for link in newsLink:\n      news.append(getNewsFromLink(link))\n\n    if verbose==1:\n      print(f\"Done!\")\n\n  news_df = pd.DataFrame(news)\n\n  if save != 0:\n    news_df.to_csv(save, index=False)\n\n  return news_df","cec1daf1":"def saveNewsFromMultipleDate(days=0, startDate=datetime.today(), path=\"\/\", verbose=1):\n  for day in range(days+1):\n    date = (startDate - timedelta(days=day)).strftime(\"%Y\/%m\/%d\")\n    filename = \"-\".join(date.split(\"\/\")) + \".csv\"\n    filepath = path + filename\n\n    if verbose==1:\n      print(f\"Saving news from {date} in {filepath}...\")\n\n    getNewsFromDate(date, filepath, verbose)\n\n    if verbose==1:\n      print(f\"Saving news from {date} in {filepath} is complete.\\n\")","0d0fad61":"os.mkdir(\"data\")\n# len(os.listdir(\"data\/\"))","ae7c2abb":"filepath = \"\/kaggle\/working\/data\/\"\nstartDate = datetime.today() - timedelta(0)\ndays = 0\n\nsaveNewsFromMultipleDate(days, startDate, filepath)","4be91233":"!zip -r data_4.zip \/kaggle\/working\/data\/","979df3aa":"# !rm data\/*","757cc7cc":"Go to the last cell to scrape news from any date or date interval."}}