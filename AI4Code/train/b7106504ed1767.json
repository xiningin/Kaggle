{"cell_type":{"73f37f0b":"code","27652054":"code","39192c26":"code","140c44da":"code","18dcd2c6":"code","376f5dac":"code","ad604871":"code","a2d7c1fb":"code","a402ee44":"code","fd403e42":"code","78f2fd5b":"code","84ab77e6":"code","84203e34":"code","c92908a9":"code","f3fcd58c":"code","10112ab4":"code","83499f66":"code","fd511ad7":"code","2d8767cf":"code","b26d1fee":"code","6ff67d1b":"code","b9847d9e":"code","d123b668":"code","e4435cc4":"code","4c2113ab":"code","1651daaa":"code","2d73d055":"code","9520f1a3":"markdown"},"source":{"73f37f0b":"import torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random","27652054":"import numpy as np\nimport torch\nimport torch.optim as optim\nimport pandas as pd\n\nxy=pd.read_csv('..\/input\/city-commercialchange-analysis\/train.csv')\nxy","39192c26":"corr=xy.corr(method='pearson')\ncorr","140c44da":"x_data=xy.iloc[:,0:7]    #0~7 col\ny_data=xy.iloc[:,7]\n\nx_data","18dcd2c6":"y_data","376f5dac":"x_train=np.array(x_data)\ny_train=np.array(y_data)\n\nx_train=torch.FloatTensor(x_train)\ny_train=torch.LongTensor(y_train)\n\nx_train[:5]","ad604871":"x_train.shape","a2d7c1fb":"y_train.shape","a402ee44":"y_train","fd403e42":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","78f2fd5b":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 0.001\ntraining_epochs = 1000\nbatch_size = 100\n\nfrom sklearn import preprocessing\nScaler = preprocessing.StandardScaler()  ","84ab77e6":"x_train","84203e34":"x_train_scaler=Scaler.fit_transform(x_train)\nx_train_scaler","c92908a9":"x_train_scaler=torch.FloatTensor(x_train_scaler)","f3fcd58c":"\ntrain = torch.utils.data.TensorDataset(x_train_scaler, y_train)","10112ab4":"data_loader = torch.utils.data.DataLoader(dataset=train,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n#xy=train","83499f66":"# 3-Layer\n\nlinear1 = torch.nn.Linear(7,32,bias=True)\nlinear2 = torch.nn.Linear(32,32,bias=True)\nlinear3 = torch.nn.Linear(32,4,bias=True)\nrelu = torch.nn.ELU()\ndropout = torch.nn.Dropout(p=0.5)","fd511ad7":"# Random Init => Xavier Init\ntorch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)","2d8767cf":"model = torch.nn.Sequential(linear1,relu,dropout,linear2,relu,dropout,linear3).to(device)","b26d1fee":"# \uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\nloss = torch.nn.CrossEntropyLoss().to(device) # softmax \ub0b4\ubd80\uc801\uc73c\ub85c \uacc4\uc0b0\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","6ff67d1b":"\ntotal_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        # one-hot encoding\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc74c\n        X = X.to(device)\n        Y = Y.to(device)\n        #%debug\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\n    if 0.05<avg_cost < 0.054:\n      break\nprint('Learning finished')","b9847d9e":"test=pd.read_csv('..\/input\/city-commercialchange-analysis\/test.csv')\n\nwith torch.no_grad():\n  x_test=test.loc[:,:]\n  x_test=np.array(x_test)\n  x_test_scaler=Scaler.transform(x_test)\n  x_test_scaler=torch.from_numpy(x_test_scaler).float().to(device)\n\n  prediction=model(x_test_scaler)\n  prediction = torch.argmax(prediction, 1)\n\nprediction","d123b668":"ans = [3, 0, 0, 0, 3, 0, 0, 1, 3, 0, \n       0, 3, 3, 0, 3, 0, 3, 0, 0, 3, \n       0, 0, 0, 3, 0, 0, 3, 3, 0, 0, \n       0, 3, 0, 3, 3, 3, 1, 0, 3, 3, \n       1, 1, 3, 3, 0, 3, 3, 3, 3, 3, \n       0, 0, 3, 3, 2, 3, 3, 3, 3, 1, \n       3, 0]\nans = np.array(ans)\nans = torch.torch.from_numpy(ans).float().to(device)\nans","e4435cc4":"correct_prediction = prediction.float() == ans\nprint(correct_prediction > 0.5)\naccuracy = correct_prediction.sum().item() \/ len(correct_prediction)\nprint('The model has an accuracy of {:2.3f}% for the training set.'.format(accuracy * 100))","4c2113ab":"submit = pd.read_csv('..\/input\/city-commercialchange-analysis\/submit.csv')\nsubmit","1651daaa":"for i in range(len(prediction)):\n  submit['Label'][i]=prediction[i].item()\n\nsubmit","2d73d055":"submit.to_csv('submission.csv',index=False,header=True)","9520f1a3":"### baseline defense \ucf54\ub4dc\n- 3layer\n- xavier init\n- Adam\n- \ucd08\uae30\ud654 \ubc29\uc2dd : ReLU\n- training_epochs = 55\n- hidden layer node \uac1c\uc218: 256\n- scaler\ub97c \uc0ac\uc6a9\n- lr = 0.001\n\n-> Accuracy: 0.96774\n\n### \uc704\uc758 \ucf54\ub4dc\uc640 \ubcc0\uacbd\ub41c \uc810\n- hidden layer node \uac1c\uc218: 32\n- - lr = 0.0001\n- training_epochs \ubcc0\uacbd : \uae30\ubcf8 1000, if\ubb38\uc73c\ub85c \uc6d0\ud558\ub294 cost\uac12 \ub098\uc62c\ub54c break\n```\nif 0.05<avg_cost < 0.054:\n      break\n```\n- dropout \ucd94\uac00 : 0.5<br>\n`dropout = torch.nn.Dropout(p=0.5)`\n- \ucd08\uae30\ud654 \ubc29\uc2dd ELU\ub85c \ubcc0\uacbd<br>\n`relu = torch.nn.ELU()`\n\n"}}