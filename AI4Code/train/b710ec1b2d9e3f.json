{"cell_type":{"cffdd481":"code","a4131f4c":"code","836e2243":"code","3b1259e0":"code","6fa88f98":"code","7d7c83da":"code","8dd1c586":"code","5edd91e4":"code","0125a3f9":"code","aee95bbb":"code","0f00d59c":"code","349afb39":"code","01bb2003":"code","2ab1a556":"code","30f042f6":"code","729a3679":"code","332884e6":"code","0254e06d":"code","f5562589":"code","24148d49":"code","4283a328":"code","73cbd665":"code","91776685":"code","428a5a7a":"code","74fbffa1":"code","f9bef1cd":"code","44aeaaf5":"code","8e590fb0":"code","db67d910":"code","c6704359":"code","d7e3921c":"code","2158bd53":"code","e955e6d4":"code","3783e490":"code","a5f23c69":"code","f32df189":"code","bf17028a":"code","6546b297":"code","10cf5437":"markdown","5d56f833":"markdown","8a2b8926":"markdown","2b3b7e20":"markdown"},"source":{"cffdd481":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a4131f4c":"df_bcell=pd.read_csv(\"..\/input\/epitope-prediction\/input_bcell.csv\")\ndf_covid=pd.read_csv(\"..\/input\/epitope-prediction\/input_covid.csv\")\ndf_sars=pd.read_csv(\"..\/input\/epitope-prediction\/input_sars.csv\")","836e2243":"df_bcell.head()","3b1259e0":"df_bcell.tail()","6fa88f98":"df_bcell.isna().sum()","7d7c83da":"df_bcell.dtypes","8dd1c586":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_bcell.iloc[:,0]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,0].values)\ndf_bcell.iloc[:,1]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,1].values)\ndf_bcell.iloc[:,4]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,4].values)","5edd91e4":"df_bcell.head()","0125a3f9":"df_bcell.dtypes","aee95bbb":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_bcell.corr(), annot=True,fmt=\".0%\")\nplt.show()","0f00d59c":"df_covid.head()","349afb39":"df_covid.tail()","01bb2003":"df_covid.isna().sum()","2ab1a556":"df_covid.dtypes","30f042f6":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_covid.iloc[:,0]=labelEncoder_Y.fit_transform(df_covid.iloc[:,0].values)\ndf_covid.iloc[:,1]=labelEncoder_Y.fit_transform(df_covid.iloc[:,1].values)\ndf_covid.iloc[:,4]=labelEncoder_Y.fit_transform(df_covid.iloc[:,4].values)","729a3679":"df_covid.head()","332884e6":"df_covid.dtypes","0254e06d":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_covid.corr(), annot=True,fmt=\".0%\")\nplt.show()","f5562589":"df_sars.head()","24148d49":"df_sars.tail()","4283a328":"df_sars.isna().sum()","73cbd665":"df_sars.dtypes","91776685":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_sars.iloc[:,0]=labelEncoder_Y.fit_transform(df_sars.iloc[:,0].values)\ndf_sars.iloc[:,1]=labelEncoder_Y.fit_transform(df_sars.iloc[:,1].values)\ndf_sars.iloc[:,4]=labelEncoder_Y.fit_transform(df_sars.iloc[:,4].values)","428a5a7a":"df_sars.head()","74fbffa1":"df_sars.dtypes","f9bef1cd":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sars.corr(), annot=True,fmt=\".0%\")\nplt.show()","44aeaaf5":"#Split the data set into independent(x) and dependent (y) data sets\nx=df_bcell.iloc[:,1:14].values\ny=df_bcell.iloc[:,0].values.reshape(-1,1)\nx_test  = df_covid.drop(\"parent_protein_id\",axis=1).copy()","8e590fb0":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.469,random_state=42)","db67d910":"#scale the data(feature scaling)\nfrom sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","c6704359":"x_train.shape","d7e3921c":"x_test.shape","2158bd53":"y_train.shape","e955e6d4":"y_test.shape","3783e490":"def models(x_train,y_train):\n  #Logistic Regression Model\n  from sklearn.linear_model import LogisticRegression\n  log=LogisticRegression(random_state=42)\n  log.fit(x_train,y_train)\n  \n  #Decision Tree\n  from sklearn.tree import DecisionTreeClassifier\n  tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n  tree.fit(x_train,y_train)\n  \n  #Random Forest Classifier\n  from sklearn.ensemble import RandomForestClassifier\n  forest = RandomForestClassifier(n_estimators=15,criterion=\"entropy\",random_state=0)\n  forest.fit(x_train,y_train)\n\n  #Print the models accuracy on the training data\n  print(\"[0]Logistic Regression Training Accuracy:\",log.score(x_train,y_train))\n  print(\"[1]Decision Tree Classifier Training Accuracy:\",tree.score(x_train,y_train))\n  print(\"[2]Random Forest Classifier Training Accuracy:\",forest.score(x_train,y_train))\n  \n  return log,tree,forest","a5f23c69":"#Getting all of the models\nmodel = models(x_train,y_train)","f32df189":"#test model accuracy on confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n\nfor i in range(len(model)):\n  print(\"Model \", i)\n  cm =confusion_matrix(y_test,model[i].predict(x_test))\n\n  TP=cm[0][0]\n  TN=cm[1][1]\n  FN=cm[1][0]\n  FP=cm[0][1]\n\n  print(cm)\n  print(\"Testing Accuracy = \", (TP+TN) \/ (TP+TN+FN+FP))\n  print()","bf17028a":"#show another way to get metrics of the models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nfor i in range(len(model) ):\n  print(\"Model \",i)\n  print( classification_report(y_test,model[i].predict(x_test)))\n  print( accuracy_score(y_test,model[i].predict(x_test)))\n  print()","6546b297":"pred=model[2].predict(x_test)\nprint(pred)","10cf5437":"# BCELL VS COVID","5d56f833":"# BCELL","8a2b8926":"# COVID","2b3b7e20":"# SARS"}}