{"cell_type":{"abe631e7":"code","c93e9bfd":"code","a9d131d0":"code","cb3c4de0":"code","b7b129a3":"code","81d7131a":"code","61972027":"code","4fe29f36":"code","e073c47d":"code","7fb2f80a":"code","934424af":"code","f8d2f59d":"code","b0e79710":"code","cf5c0a1b":"code","1337898d":"code","21f47c05":"code","c2a1fe7e":"code","357d4da1":"code","70ac197b":"code","3f336887":"code","e0985a5f":"code","f3311f92":"code","1bfc364f":"code","1943b042":"code","d05ee445":"code","04269710":"code","23c0cd9b":"code","5cbcefbb":"code","7f8831e6":"code","656da030":"code","bf4e21d4":"code","177dbc8f":"code","de3045b4":"code","4ae0e704":"code","294360d5":"code","8ea01ac4":"code","c446678f":"code","362803f0":"code","4f31c7a5":"code","0a2f8ff3":"code","a7ea7a57":"code","00322a1c":"code","024d6a03":"code","1b931cec":"code","e69be630":"code","30816715":"code","64a37eb0":"code","31d54a8c":"code","a3f4fbe1":"code","8c9026bd":"code","8ddfd6a7":"code","151d7785":"code","5a37d263":"code","70275b64":"code","dc3547c4":"code","ca710219":"code","caaa32bc":"code","37d54c59":"code","8b925b73":"code","5335ac1f":"code","bb7590a8":"markdown","9de9c255":"markdown","0f55c88a":"markdown","2fc6e87e":"markdown","0c03c79a":"markdown","ddd199bc":"markdown","713407d8":"markdown","4a01f77b":"markdown","726b2e5e":"markdown","181dc0fa":"markdown","ec1277a6":"markdown","1346ba3f":"markdown","cdae310f":"markdown","d53ce132":"markdown","97a61c92":"markdown","103d5114":"markdown","bcc815d5":"markdown","e8f79214":"markdown","a207331d":"markdown","6eb2348f":"markdown","979aaefc":"markdown","95448ca9":"markdown","68ed857b":"markdown","f200a2c4":"markdown","4cdc2505":"markdown","15619ead":"markdown","22c6024e":"markdown","fef8fd65":"markdown","f6a6bda1":"markdown","ef12bed0":"markdown","dea70ee4":"markdown","f9bc323b":"markdown","4155db19":"markdown"},"source":{"abe631e7":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport matplotlib.pylab as plt\nimport calendar\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold\nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product\nimport copy\nimport time\n\nimport random\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)","c93e9bfd":"%%time\npath_data = '\/kaggle\/input\/data-science-bowl-2019\/'\ntrain = pd.read_csv(path_data+'train.csv')\ntrain_labels = pd.read_csv(path_data+'train_labels.csv')\ntest = pd.read_csv(path_data+'test.csv')\nspecs = pd.read_csv(path_data+'specs.csv')\nsample_submission = pd.read_csv(path_data+'sample_submission.csv')","a9d131d0":"len(train[\"event_id\"].unique())\n#train[\"event_id\"].unique()","cb3c4de0":"keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\ntrain = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")","b7b129a3":"train.shape","81d7131a":"keep_id.shape","61972027":"train.type.value_counts()","4fe29f36":"train.world.value_counts()","e073c47d":"plt.rcParams.update({'font.size': 16})\n\nfig = plt.figure(figsize=(12,10))\nax1 = fig.add_subplot(211)\nax1 = sns.countplot(y=\"type\", data=train, color=\"blue\", order = train.type.value_counts().index)\nplt.title(\"number of events by type\")\n\nax2 = fig.add_subplot(212)\nax2 = sns.countplot(y=\"world\", data=train, color=\"blue\", order = train.world.value_counts().index)\nplt.title(\"number of events by world\")\n\nplt.tight_layout(pad=0)\nplt.show()","7fb2f80a":"#train.title.value_counts()","934424af":"plt.rcParams.update({'font.size': 12})\n\nfig = plt.figure(figsize=(12,10))\nse = train.title.value_counts().sort_values(ascending=True)\nse.plot.barh()\nplt.title(\"Event counts by title\")\nplt.xticks(rotation=0)\nplt.show()","f8d2f59d":"def get_time(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['date'] = df['timestamp'].dt.date\n    df['month'] = df['timestamp'].dt.month\n    df['hour'] = df['timestamp'].dt.hour\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    return df\n    \ntrain = get_time(train)","b0e79710":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('date')['date'].count()\nse.plot()\nplt.title(\"Event counts by date\")\nplt.xticks(rotation=90)\nplt.show()","cf5c0a1b":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('dayofweek')['dayofweek'].count()\nse.index = list(calendar.day_abbr)\nse.plot.bar()\nplt.title(\"Event counts by day of week\")\nplt.xticks(rotation=0)\nplt.show()","1337898d":"fig = plt.figure(figsize=(12,10))\nse = train.groupby('hour')['hour'].count()\nse.plot.bar()\nplt.title(\"Event counts by hour of day\")\nplt.xticks(rotation=0)\nplt.show()","21f47c05":"test.head()","c2a1fe7e":"test.shape","357d4da1":"test.installation_id.nunique()","70ac197b":"sample_submission.shape[0]","3f336887":"set(list(train.installation_id.unique())).intersection(set(list(test.installation_id.unique())))","e0985a5f":"test['timestamp'] = pd.to_datetime(test['timestamp'])\nprint(f'The date range in train is: {train.timestamp.dt.date.min()} to {train.timestamp.dt.date.max()}')\nprint(f'The date range in test is: {test.timestamp.dt.date.min()} to {test.timestamp.dt.date.max()}')","f3311f92":"plt.rcParams.update({'font.size': 22})\n\nplt.figure(figsize=(12,6))\nsns.countplot(y=\"title\", data=train_labels, color=\"blue\", order = train_labels.title.value_counts().index)\nplt.title(\"Counts of titles\")\nplt.show()","1bfc364f":"plt.rcParams.update({'font.size': 16})\n\nse = train_labels.groupby(['title', 'accuracy_group'])['accuracy_group'].count().unstack('title')\nse.plot.bar(stacked=True, rot=0, figsize=(12,10))\nplt.title(\"Counts of accuracy group\")\nplt.show()","1943b042":"train_labels[train_labels.installation_id == \"0006a69f\"]","d05ee445":"train[(train.event_code == 4100) & (train.installation_id == \"0006a69f\") & (train.title == \"Bird Measurer (Assessment)\")]","04269710":"train[(train.installation_id == \"0006a69f\") & ((train.type == \"Assessment\") & (train.title == 'Bird Measurer (Assessment)') & (train.event_code == 4110) |\n                                               (train.type == \"Assessment\") & (train.title != 'Bird Measurer (Assessment)') & (train.event_code == 4100))]","23c0cd9b":"train[~train.installation_id.isin(train_labels.installation_id.unique())].installation_id.nunique()","5cbcefbb":"train = train[train.installation_id.isin(train_labels.installation_id.unique())]\ntrain.shape","7f8831e6":"print(f'Number of rows in train_labels: {train_labels.shape[0]}')\nprint(f'Number of unique game_sessions in train_labels: {train_labels.game_session.nunique()}')","656da030":"len(train_labels.installation_id.unique())","bf4e21d4":"train = train.drop(['date', 'month', 'hour', 'dayofweek'], axis=1)","177dbc8f":"train.columns","de3045b4":"test.columns","4ae0e704":"#Credits go to Andrew Lukyanenko\n\ndef encode_title(train, test, train_labels):\n    # encode title\n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    \n    \n    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n\n# get usefull dict with maping encode\ntrain, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n\ncategoricals = ['session_title']","294360d5":"#Credits go to Massoud Hosseinali\n\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # news features: time spent in each activity\n    time_spent_each_act = {actv: 0 for actv in list_of_user_activities}\n    event_code_count = {eve: 0 for eve in list_of_event_code}\n    last_session_time_sec = 0\n    \n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title] #from Andrew\n        \n        # get current session time in seconds\n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] \/ 1000)\n            time_spent_each_act[activities_labels[session_title]] += time_spent\n        \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(time_spent_each_act.copy())\n            features.update(event_code_count.copy())\n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1] #from Andrew\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0] \n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            # the accurace is the all time wins divided by the all time attempts\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        # this piece counts how many actions was made in each event_code so far\n        n_of_event_codes = Counter(session['event_code'])\n        \n        for key in n_of_event_codes.keys():\n            event_code_count[key] += n_of_event_codes[key]\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n    # if test_set=True, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in train_set, all assessments are kept\n    return all_assessments","8ea01ac4":"sample_id = train[train.installation_id == \"0006a69f\"]\nsample_id_data = get_data(sample_id) #returns a list\nsample_df = pd.DataFrame(sample_id_data)\nsample_df.iloc[:,-10:]","c446678f":"train_labels[train_labels.installation_id == \"0006a69f\"].iloc[:, [0, 1, -3, -1]]","362803f0":"#Credits go to Massoud Hosseinali\n\n#The get_data function is applied to each installation_id and added to the compile_data list\ncompiled_data = []\n# tqdm is the library that draws the status bar below\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n    # user_sample is a DataFrame that contains only one installation_id\n    compiled_data += get_data(user_sample)","4f31c7a5":"#Credits go to Massoud Hosseinali\n\n#Compiled_data is converted into a DataFrame and deleted to save memmory\nreduce_train = pd.DataFrame(compiled_data)\ndel compiled_data\nreduce_train.shape","0a2f8ff3":"#reduce_train.head()\nreduce_train.shape","a7ea7a57":"new_test = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n    a = get_data(user_sample, test_set=True)\n    new_test.append(a)\n    \nreduce_test = pd.DataFrame(new_test)","00322a1c":"reduce_test.shape","024d6a03":"reduce_test.head()","1b931cec":"import pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n","e69be630":"def preprocess(reduce_train, reduce_test):\n    for df in [reduce_train, reduce_test]:\n        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n        \n        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n        \n        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n        \n    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n    #features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n    features = [x for x in features if x not in ['accuracy_group', 'installation_id']]\n    return reduce_train, reduce_test, features\n# call feature engineering function\nreduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)","30816715":"y = reduce_train['accuracy_group']","64a37eb0":"reduce_train.shape\n#print(features)\nlen(features)","31d54a8c":"#cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate']\ncols_to_drop = [ 'installation_id', 'accuracy_group']\n#X =reduce_train.drop(cols_to_drop, axis=1)\nX =reduce_train[features]\nX.shape","a3f4fbe1":"#print(features)","8c9026bd":"dummy_y = np_utils.to_categorical(y)","8ddfd6a7":"pd.DataFrame(dummy_y).head()\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.callbacks import ReduceLROnPlateau\npd.DataFrame(dummy_y).head()","151d7785":"input_dim= X.shape[1]\nprint('input_dim is:', input_dim)\npd.DataFrame(X).head(5)\nfeatures = X.columns\nX.head(5)","5a37d263":"from sklearn.base import BaseEstimator, TransformerMixin\n@jit\ndef qwk(a1, a2):\n    \"\"\"\n    Source: https:\/\/www.kaggle.com\/c\/data-science-bowl-2019\/discussion\/114133#latest-660168\n\n    :param a1:\n    :param a2:\n    :param max_rat:\n    :return:\n    \"\"\"\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e \/ a1.shape[0]\n\n    return 1 - o \/ e\n\n\ndef eval_qwk_lgb(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n\n    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n    return 'cappa', qwk(y_true, y_pred), True\n\n\ndef eval_qwk_lgb_regr(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n    y_pred[y_pred <= 1.12232214] = 0\n    y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n    y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n    y_pred[y_pred > 2.22506454] = 3\n\n    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n\n    return 'cappa', qwk(y_true, y_pred), True","70275b64":"\n##############################################################################################\n\nfrom keras.callbacks import Callback\nclass roc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = qwk(self.y, y_pred)\n        #roc = eval_qwk_lgb(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = qwk(self.y_val, y_pred_val)\n        #roc_val = eval_qwk_lgb(self.y_val, y_pred_val)\n        #print('\\rqwk: %s - qwk_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        print('\\rqwk: %s - qwk_val: %s' % (str(roc),str(roc_val)),end=100*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n\n\n","dc3547c4":"from keras.callbacks import ModelCheckpoint\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\n#pd.DataFrame(X).head(5)\n\nmodel = Sequential()\nmodel.add(Dense(221, input_dim=input_dim,kernel_initializer='random_normal', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(111,activation='tanh'))\n#model.add(Dense(163, input_dim=input_dim, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4, activation='softmax'))\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#model.fit(X,dummy_y, batch_size = 32, epochs = 50,validation_split=0.2)\n\ntrain_x, valid_x , train_y, valid_y = train_test_split(X, dummy_y, test_size=0.2, random_state=2020)\nfrom keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.008)\n\n# checkpoint\nfilepath='\/kaggle\/working\/best_weights.hdf5'\n#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\"\"\"\nmodel.fit(train_x, train_y, batch_size = 32, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[reduce_lr,roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)\n\nmodel.fit(train_x, train_y, batch_size = 32, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[checkpoint,roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)\n\"\"\"\nmodel.fit(train_x, train_y, batch_size = 8, epochs = 100,validation_data=(valid_x, valid_y),\n               callbacks=[roc_callback(training_data=(train_x, train_y),validation_data=(valid_x, valid_y)),early_stopping],verbose=1)","ca710219":"#model.load_weights(filepath)\npreds = model.predict(sc.transform(reduce_test[features]))\n\n","caaa32bc":"pd.DataFrame(preds).head(200)","37d54c59":"pd.DataFrame(preds).head(100).idxmax(axis=1)","8b925b73":"sample_submission['accuracy_group'] = pd.DataFrame(preds).idxmax(axis=1).astype(int)\nsample_submission.to_csv('submission.csv', index=False)","5335ac1f":"sample_submission.head(50)","bb7590a8":"Now, we need to do the same thing for the test set. Parameter test_set=True leads to accuracy_group=0 and only the last assessment is kept (so only one row per installation_id).","9de9c255":"So we have 1.1 million rows on a thousand unique installation_ids in the test set. Below, you can see that we have this same amount of rows in the sample submission. This means that there are no installation_ids without assessment in the test set indeed.","0f55c88a":"As you can see, we have now lost about 3 million rows.","2fc6e87e":"The outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n\n3: the assessment was solved on the first attempt\n\n2: the assessment was solved on the second attempt\n\n1: the assessment was solved after 3 or more attempts\n\n0: the assessment was never solved\n\n\nI started by visualizing some of these columns","0c03c79a":"Below your see the counts by date. By the way, I have wasted a lot of time on trying to fix the weird ticks on the x-axis, but this seems a bug: https:\/\/github.com\/matplotlib\/matplotlib\/issues\/13183","ddd199bc":"GroupKFold is chosen for cross validation as we want all sessions of an installation_id to end up in either train or valid. See also the RegressorModel class.","713407d8":"Below, you can see that a lot of Chest Sorter assessments were never solved. Bird Measurer also seems hard with a relatively small amount solved on the first attempt.","4a01f77b":"The date range is more or less the same, so we are talking about a dataset that seems (randomly) split on installation_id. Well actually \"sort of\" as Kaggle seems to have done this on installation_id's with assessments first, and added the \"left-overs\" with no assessments taken to the train set.","726b2e5e":"What about the date ranges?","181dc0fa":"Ok, now that we have that confirmed, I my first step was initially to start by looking for values that are always the same for a game_session in the train dataframe. It turns out that the only one is world. I also checked if some of the datetime variables were unique, but this is not always the case (events within a session may cross midnight).\n\nOf course, on Kaggle it is not always necessary to reinvent the wheel. I knew that I would have to iterate over all the rows and add features that only look at what happened up to the moment at which the an installation_id starts a particluar assessment. I found out that Massoud Hosseinali already posted fantastic code on how to do that in this kernel: https:\/\/www.kaggle.com\/mhviraf\/a-new-baseline-for-dsb-2019-catboost-model. Thanks Massoud, and all credit go to you! As Bruno Aquino reused this code and already added some comments, I am actually using his code.\n\nAs I figured out that datetime variables cannot be matched uniquely to the train_labels, I am starting again with a train dataframe as it originally was (except for keeping timestamp as datetime). The huge code chunck below contains the function to generate features for each row in train_labels.","ec1277a6":"##Attribution##\nMost of preprocessing and feature engineering taken from:\nhttps:\/\/www.kaggle.com\/erikbruin\/data-science-bowl-2019-eda-and-baseline\n##### What has changed##\nTrying an approach with NeuralNet using Softmax - multiclass classification\n###What to expect####\n0.455","1346ba3f":"The number of unique installations in our \"smaller\" train set is now 4242.","cdae310f":"When we compare this to the train_labels, you can see that the accuracy_group values are the same so features have been added for all game_session id's. However more importantly, by comparing the accumulated_uncorrect_attempts with num_incorrect, you will see that **only activities before the start of that particular session have been accumulated**.","d53ce132":"I will first visualize some of the existing columns.","97a61c92":"# 2. Understanding the test set\n\nFrom Kaggle: For each installation_id represented in the test set, you must predict the accuracy_group of the last assessment for that installation_id.","103d5114":"Another thing that I would like to check is if there is any overlap with regards to installation_id's in the train and test set. As you can see, there are no installation_id's that appear in both train and test.","bcc815d5":"# Table of contents\n\n* [1. Understanding the train data](#1.-Understanding-the-train-data)\n* [2. Understanding the test set](#2.-Understanding-the-test-set)\n* [3. Understanding and visualizing the train labels](#3.-Understanding-and-visualizing-the train-labels)\n* [4. Feature engineering](#4.-Feature-engineering)","e8f79214":"Basically what we need to do is to compose aggregated features for each session of which we know the train label. Before I get started, I am quickly checking if game_session alone is the unique identifier in train_labels indeed.","a207331d":"# 3. Understanding and visualizing the train labels","6eb2348f":"# 5. Baseline Model\n\nIn this competition,regression with rounding of coefficients is clearly the way to go as explained by Andrew Lukyanenko in his excellent kernel: https:\/\/www.kaggle.com\/artgor\/quick-and-dirty-regression\n\nStep 1: Just get it working....\n\nCredits for this section go to Andrew. I have only made small changes, and are basically just using other (less actually) features. As I was just focused on getting it to work, I changed the test and train set into the names that Andrew uses (reduce_train and reduce_test).","979aaefc":"From Kaggle: The file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains \"correct\":true.\n\nHowever, in the first version I already noticed that I had one attempt too many for this installation_id when mapping the rows with the train_labels for. It turns out that there are in fact also assessment attemps for Bird Measurer with event_code 4100, which should not count (see below). In this case that also makes sense as this installation_id already had a pass on the first attempt","95448ca9":"When looking at the numbers by hour of the day, I find the distribution a little bit strange. Kids seem up late at night and don't do much early in the morning. Has this something to do with time zones perhaps?","68ed857b":"I will now add some new columns based on the timestamp, and visualize these.","f200a2c4":"To make this a little bit easier to understand, I am first using the function on one installation_id as an example (same one as used as an example before). Below, I have only displayed the last bunch of columns of the resulting dataframe. As you can see, five rows have been created for this installation_id.","4cdc2505":"# 4. Feature engineering","15619ead":"When looking at the day of the week, we see no major difference. Of course, we are talking about kids who don't have to go to work ;-)","22c6024e":"So we have 11 million rows and just 11 columns. However, Kaggle provided the following note: Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment.\n\nAs there is no point in keeping training data that cannot be used for training anyway, I am getting rid of the installation_ids that never took an assessment\n    ","fef8fd65":"When we exclude the Bird Measurer\/4100 rows we get the correct match with the numbers in train_labels for this installation_id (4 correct, 12 incorrect)","f6a6bda1":"As the match between the train dataframe and the train_labels dataframe is not straightforward, it tried to figure out how these dataframes are to be matched by focussing on just one particular installation_id.","ef12bed0":"# 1. Understanding the train data","dea70ee4":"As we can not train on those installation_id's anyway, I am taking them out of the train set. This reduces our train set further from 8.3 million rows to 7.7 million.","f9bc323b":"Now the question arises: Could there be installation_id's who did assessments (we have already taken out the ones who never took one), but without results in the train_labels? As you can see below, yes there are 628 of those.","4155db19":"In the code below the function is applied to each installation_id in the train dataset.\n\nCompared to the original code I changed the total. In the original code this was set at 17,000. However, since I reduced the train dataframe, I only have 3614 of those left (train.installation_id.nunique()=3614). In addition, I had issues with incorrect rendering of the tdqm bar, and solved this by adding position=0. I also turns out that possible to add a description, which is nice to have."}}