{"cell_type":{"8e3bc143":"code","059caa46":"code","743ed630":"code","f03ea04a":"code","2fc65bba":"code","57170172":"code","f1d0b33c":"code","b976f41c":"code","37049431":"code","efbb43c9":"code","a2a683b7":"code","4d239564":"code","a8feb48b":"code","6c70d7a8":"code","02fb6b0a":"code","d9332d17":"code","04c55345":"code","5c33cd6a":"code","d9c14462":"code","dab615d7":"code","539ede58":"code","f36815d2":"code","07b3e3cb":"code","82a49e2b":"code","a0c00076":"code","362ffd76":"code","f90a8579":"code","bb809473":"code","f037304f":"code","ea107b1a":"code","4348531e":"code","693282ef":"code","01490ed9":"code","31acdf0b":"code","6033ccdd":"code","67cecad1":"code","ec728e2d":"code","c03229b6":"code","383a7135":"code","7b997c90":"code","166fa9d8":"code","ebdb1d13":"code","5fcdfb07":"code","a3212d74":"code","4d98fc38":"code","660d5f5e":"code","1cea12f0":"code","82c0eba0":"code","d5bf84ff":"code","1713d219":"code","21d59fab":"code","063297ae":"code","563cea9a":"code","168fb649":"code","9ec27b76":"code","1d5d34c3":"code","08d71bc6":"code","ef95fddb":"code","cedf5126":"code","7619a117":"code","e7d5dae3":"code","e6387f12":"code","fbd0129b":"code","ddbf8b98":"code","10c2f284":"code","1b1f94a4":"code","28e81cc2":"code","e1358465":"code","1f0a3a27":"code","8de36cbe":"code","944dc066":"code","c0d723e6":"code","77f0dda1":"code","9f3cf7b8":"code","3c236e11":"code","1220cc00":"code","bd47dcde":"code","a23e8617":"code","8ade80f5":"code","bfeb0d15":"code","bc43b726":"code","a1413221":"code","12f5929f":"code","f602dd92":"code","5df9d2a9":"code","9f32b935":"code","72a419ab":"code","00e10420":"code","fdb14622":"code","11ea946b":"code","dd7149b8":"code","f3a5b8c5":"code","24fb2a79":"code","2dca16a7":"code","18b73dda":"code","ccb2dc57":"code","a824f85d":"code","26c0269f":"code","23b515a7":"code","fb74d76d":"code","eb64cd49":"code","696a3c39":"code","eb62c215":"code","e80e1633":"code","108374b6":"code","10421d7f":"code","4cf4eef5":"code","cbb9a3a4":"code","4373043c":"code","c569fff6":"code","6c9b8598":"code","f77b909d":"code","8bef1ce9":"code","c03e2058":"code","fd06b34c":"code","da3fbc85":"code","9481211a":"code","1e266f4b":"code","0fd5ef3e":"code","fd5eaa2f":"code","6a2e2e37":"code","494200a4":"code","d710f861":"code","bf470172":"code","4f1d5995":"code","b164f53c":"code","b8661c3b":"code","009f3aed":"code","25e51372":"code","f8f332c4":"code","3559b70c":"code","51ef72e5":"code","fe02bcfa":"code","55d3aa1a":"code","b4a6fdd7":"code","ce22d1ab":"code","98564ecd":"code","4c6e2841":"code","9e9f42da":"code","ab8374be":"code","d7820613":"code","54b6e5a0":"code","290bc67a":"code","2acc7b24":"code","74e0b728":"code","10dec5ea":"code","4b97b46c":"code","cc5b9938":"code","3b5aea70":"code","5279abae":"code","33c7057e":"code","030849cf":"code","059a9596":"code","9f074a96":"code","dcddaf48":"code","a9cff11c":"code","040fbcd7":"code","85268737":"code","f49514ad":"code","391e1bf5":"code","f9b7b5c5":"code","8f12c680":"code","2235ef3e":"code","48835af6":"code","a2451b41":"code","032a2531":"code","3ee278e6":"code","cabc2a3f":"code","489d9bf5":"code","7d05a9f7":"code","79f6bdcc":"code","5ad09262":"code","a0ef6761":"code","9858ccbd":"code","641f954c":"code","56208f21":"code","a3dcd33e":"code","b86c0359":"code","053f22a3":"code","a7615fa1":"code","e5a8e789":"code","8b948039":"code","f2864b59":"code","27771946":"code","4e312c63":"code","57163878":"code","8a92deef":"code","437f2cb2":"code","5bfa398b":"code","f9a7264d":"code","8d8e662b":"code","d6ff5cc7":"code","7b1c4547":"code","ee070e6c":"code","562ad3dd":"code","a7e2eb87":"code","4b507acd":"code","2d2824fa":"code","1a9b50f1":"code","8d8d5483":"code","d7ff7698":"code","6ff53178":"code","b999d141":"code","319a9712":"code","804e7477":"code","c2a15569":"code","c83e2180":"code","5181916b":"code","5b2fc327":"code","bdbf8360":"code","6f47292d":"code","92c3d91a":"code","cb208e07":"code","0fe29461":"markdown","5e60ff72":"markdown","665ef35a":"markdown","c36f7430":"markdown","fd5fe3ee":"markdown","3e40b77e":"markdown","f7b0ff9c":"markdown","ebdf607c":"markdown","52120974":"markdown","6efd75b5":"markdown","3f6e36eb":"markdown","0a007304":"markdown","2386e98a":"markdown","430c5832":"markdown","41c6119c":"markdown","5ee3d5d9":"markdown","b0428b99":"markdown","b89a1d37":"markdown","b4ae92cf":"markdown","e8dc7e8e":"markdown","190de1a8":"markdown","19e3ea5e":"markdown","4d526efe":"markdown","00192628":"markdown","88842a4b":"markdown","b1a3df31":"markdown","7c83019b":"markdown","7d1cb58f":"markdown","94344e2e":"markdown","64fa3a0f":"markdown","b4bf9561":"markdown"},"source":{"8e3bc143":"import pandas as pd\nimport numpy as np\n\nsummary = pd.DataFrame({'Model': ['RF', 'RF', 'RF', 'Ensemble', 'Ensemble', 'Ensemble', 'RF', 'RF', 'RF', 'RF', 'Ensemble',\n                                 'Ensemble', 'Ensemble'],\n                        'Resolution Status': ['Open', 'Open', 'Open', 'Open', 'Open', 'Open', 'All', 'All', 'All', 'All',\n                                             'All', 'All', 'All'],\n                        'Recovered from Insurer': ['=0', '!=0', '!=0 & nooutliers', '=0 & !=0', '=0 & (!=0 & nooutliers)',\n                                                  'all RFs', 'all data', '=0', '!=0', '!=0 & nooutliers','=0 & !=0', \n                                                   '=0 & (!=0 & nooutliers)','all RFs' ],\n          'Train_Accuracy': [.8399, 0.98217, 0.98057, 0.86248, 0.85091, 0.86116, 0.8681, 0.84334, 0.60847, 0.9843, 0.86581,\n                            0.86709, 0.87985],\n          'Validation_Accuracy': [.54051, 0.63936, 0.64259, 0.55766, 0.85076, 0.85957, 0.56724, 0.54831, 0.61998, 0.63736,\n                                 0.56124, 0.55739, 0.56574],\n          \"Train f1-score ['poor', 'average', 'outstanding']\": [\"[0.7771  0.78983 0.88811]\", \"[0.97278 0.96527 0.98927]\",\n                                                               \"[0.96941 0.96739 0.98753]\", \"[0.8166  0.80315 0.9061 ]\",\n                                                               \"[0.79915 0.78934 0.89836]\",\"[0.80431 0.80663 0.90558]\",\n                                                               \"[0.81022 0.81777 0.91077]\",\"[0.78409 0.78979 0.89073]\",\n                                                               \"[0.27404 0.28235 0.77278]\",\"[0.97572 0.97207 0.99008]\",\n                                                               \"[0.8164  0.81175 0.90917]\",\"[0.81563 0.81283 0.91121]\",\n                                                               \"[0.82805 0.83383 0.91856]\"],\n          \"Validation f1-score ['poor', 'average', 'outstanding']\": [\"0.34549 0.38779 0.68984]\", \"[0.33129 0.38009 0.78421]\",\n                                                                    \"[0.40571 0.29557 0.78446]\", \"[0.39659 0.39121 0.69972]\",\n                                                                    \"[0.79849 0.79979 0.89567]\", \"[0.79421 0.81972 0.90309]\",\n                                                                    \"[0.35744 0.39622 0.71745]\",\"[0.37799 0.39467 0.68947]\",\n                                                                    \"[0.29582 0.25926 0.78027]\",\"[0.39548 0.26804 0.78165]\",\n                                                                    \"[0.39371 0.3921  0.71122]\",\"[0.39647 0.39162 0.70271]\",\n                                                                    \"[0.35685 0.39475 0.71554]\"]}\n                      )\nsummary.index = np.arange(1, len(summary)+1)\nsummary.style.set_properties(subset = ['Recovered from Insurer'], **{'width': '130px'})","059caa46":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","743ed630":"df_cd = pd.read_csv(\"..\/input\/Train_Complaints-1564659763354.csv\")\ndf_ind = pd.read_csv(\"..\/input\/Train-1564659747836.csv\")","f03ea04a":"# Combining the dataframes to include the target variable 'DRC' based on key column - 'InsurerID'\ndf = pd.merge(df_cd, df_ind, how='inner', on = 'InsurerID')","2fc65bba":"df.head()","57170172":"# Converting DateOfRegistration & DateOfResolution to Date\ndf['DateOfRegistration'] =pd.to_datetime(df.DateOfRegistration, format = '%d-%m-%Y')\ndf['DateOfResolution'] = pd.to_datetime(df.DateOfResolution, format = '%d-%m-%Y')\ndf.dtypes","f1d0b33c":"# Checking column wise NAs\n\nNA_col = pd.DataFrame(df.isna().sum(), columns = ['NA_Count'])\nNA_col['%_of_NA'] = (NA_col.NA_Count\/len(df))*100\nNA_col.sort_values(by = ['%_of_NA'], ascending = False, na_position = 'first').head(7)\n\n# Considering threshold of 20% for columnwise NAs, SubCoverage column will be dropped in further analysis","b976f41c":"# Checking row wise NAs\n\nNA_row = pd.DataFrame(df.isna().sum(axis=1), columns = ['NA_rw_count'])\nNA_row['%_of_rw_NA'] = (NA_row.NA_rw_count\/len(df))*100\nNA_row.sort_values(by = ['%_of_rw_NA'], ascending = False, na_position = 'first').head(7)\n\n# We are good in terms of rowwise NAs w.r.t. no need of row removals","37049431":"for col in (df):\n    print(col)\n    print(len(df[col].unique()))\n    \n# Column State will be dropped as it just has 1 unique value\n# ComplaintID column will also be dropped\n# FileNo column will also be dropped\n# Bawsed on the Dataset we can drop Company and use InsurerID ","efbb43c9":"df = df.drop(['SubCoverage', 'Company','FileNo', 'ComplaintID', 'State'], axis = 1)\ndf.columns","a2a683b7":"df['SubReason'].unique()","4d239564":"df['SubReason'] = df['SubReason'].replace({'Other [Enter Sub-Reason]':'Other_Enter_Sub_Reason'})","a8feb48b":"claims = ['Actual Cash Value Dispute', 'Cancellation', 'CPT Code Issue', \n          'CT Continuation 38a-512a', 'Denial of Claim', 'Failed to Remit Premium', 'No Coverage\/Premium Paid']\ndf['New_SubReason'] = ['Claims' if x in claims else x for x in df['SubReason']] ","6c70d7a8":"df['New_SubReason'].unique()","02fb6b0a":"delay = [\"Carrier Never Rec'd Appl\", \"Carrier Never Rec'd Claim\", 'Claim Delays', 'Claim Procedure', \n         'Policy Issue Delay', 'Policy Service', 'Policy Service Delay', \n         'Premium Refund Delay', 'Time Delay', 'Underwriting Delays']\ndf['New_SubReason'] = ['Delay' if x in delay else x for x in df['New_SubReason']] ","d9332d17":"nosubreason = ['No Subreason', 'Other_Enter_Sub_Reason']\ndf['New_SubReason'] = ['No_SubReason' if x in nosubreason else x for x in df['New_SubReason']] ","04c55345":"service = ['Audit','Benefit Extension','Case Management','Classification','Comparative Negligence','Contract Provision',\n'Coordination of Benefit','Discontinuation & Replmnt','Duplicate Coverage','Loss of Use','Misleading Advertising',\n'Mis-Quote','Misrepresentation','Network Adequacy','No Response','Non-Renewal','Provider Contract Issue','Refusal to Insure',\n'Steering','Surprise Billing','Unfair Discrimination','Unprofessional Conduct','Unsatisfactory Offer',\n           'Unsatisfactory Settlement']\ndf['New_SubReason'] = ['Service' if x in service else x for x in df['New_SubReason']] ","5c33cd6a":"undr_sales = ['After Mrkt Prts\/Unsat Set','Diminished Value','Eligibility of Provider','Excessive Charges','Labor Rate',\n'Mandated Benefit','Medical Necessity','Other Fees','Pre-Existing Condition','Premium\/Notice','Premium\/Rate Increase',\n'Producer Handling','Rebate','Replacement','Rescission','Service Fees','Storage Fees','Subrogation','Unapproved Form',\n'Underwrtng\/Credit History','Underwrtng\/Waivers\/Rated','UR Procedure','Usual and Customary Fees']\n\ndf['New_SubReason'] = ['Underwriting\/Sales' if x in undr_sales else x for x in df['New_SubReason']]","d9c14462":"df.head()","dab615d7":"import copy\ndf_bu = df.copy()","539ede58":"df = df.drop(df[df.ResolutionStatus.isin([\"Re-Opened\", \"Open\"])].index)","f36815d2":"# Creating column that gives the days taken to resolve complaints\n# Going forward DateOfResolution and DateOfRegistration can be dropped\ndf['DaysTakenforResn'] = (df['DateOfResolution'] - df['DateOfRegistration']).dt.days ","07b3e3cb":"train = df.copy()\ntrain.sort_values(by ='RecoveredFromInsurer', ascending = False).head()","82a49e2b":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ntrain = train.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\ntrain.columns","a0c00076":"# Reading Test dataset given\ntest = pd.read_csv(\"..\/input\/Test_Complaints-1565162197608.csv\")","362ffd76":"test.head()","f90a8579":"# Converting DateOfRegistration & DateOfResolution to Date\ntest['DateOfRegistration'] =pd.to_datetime(test.DateOfRegistration, format = '%Y-%m-%d')\ntest['DateOfResolution'] = pd.to_datetime(test.DateOfResolution, format = '%Y-%m-%d')","bb809473":"test = test.drop(['SubCoverage', 'Company','FileNo', 'ComplaintID', 'State'], axis = 1)\ntest.columns","f037304f":"test['SubReason'] = test['SubReason'].replace({'Other [Enter Sub-Reason]':'Other_Enter_Sub_Reason'})","ea107b1a":"claims = ['Actual Cash Value Dispute', 'Cancellation', 'CPT Code Issue', \n          'CT Continuation 38a-512a', 'Denial of Claim', 'Failed to Remit Premium', 'No Coverage\/Premium Paid']\ntest['New_SubReason'] = ['Claims' if x in claims else x for x in test['SubReason']] ","4348531e":"delay = [\"Carrier Never Rec'd Appl\", \"Carrier Never Rec'd Claim\", 'Claim Delays', 'Claim Procedure', \n         'Policy Issue Delay', 'Policy Service', 'Policy Service Delay', \n         'Premium Refund Delay', 'Time Delay', 'Underwriting Delays']\ntest['New_SubReason'] = ['Delay' if x in delay else x for x in test['New_SubReason']] ","693282ef":"nosubreason = ['No Subreason', 'Other_Enter_Sub_Reason']\ntest['New_SubReason'] = ['No_SubReason' if x in nosubreason else x for x in test['New_SubReason']] ","01490ed9":"service = ['Audit','Benefit Extension','Case Management','Classification','Comparative Negligence','Contract Provision',\n'Coordination of Benefit','Discontinuation & Replmnt','Duplicate Coverage','Loss of Use','Misleading Advertising',\n'Mis-Quote','Misrepresentation','Network Adequacy','No Response','Non-Renewal','Provider Contract Issue','Refusal to Insure',\n'Steering','Surprise Billing','Unfair Discrimination','Unprofessional Conduct','Unsatisfactory Offer',\n           'Unsatisfactory Settlement']\ntest['New_SubReason'] = ['Service' if x in service else x for x in test['New_SubReason']] ","31acdf0b":"undr_sales = ['After Mrkt Prts\/Unsat Set','Diminished Value','Eligibility of Provider','Excessive Charges','Labor Rate',\n'Mandated Benefit','Medical Necessity','Other Fees','Pre-Existing Condition','Premium\/Notice','Premium\/Rate Increase',\n'Producer Handling','Rebate','Replacement','Rescission','Service Fees','Storage Fees','Subrogation','Unapproved Form',\n'Underwrtng\/Credit History','Underwrtng\/Waivers\/Rated','UR Procedure','Usual and Customary Fees']\n\ntest['New_SubReason'] = ['Underwriting\/Sales' if x in undr_sales else x for x in test['New_SubReason']] ","6033ccdd":"test_bu = test.copy()","67cecad1":"test = test.drop(test[test.ResolutionStatus.isin([\"Re-Opened\", \"Open\"])].index)","ec728e2d":"test['DaysTakenforResn'] = (test['DateOfResolution'] - test['DateOfRegistration']).dt.days ","c03229b6":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ntest = test.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\ntest.columns","383a7135":"# Separating the target variable\nX_train = train.copy().drop('DRC', axis = 1)\ny_train = train['DRC']\nprint(X_train.shape)\nprint(y_train.shape)","7b997c90":"test.shape","166fa9d8":"# Checking Train NAs\nX_train.isna().sum()","ebdb1d13":"# Checking Test NAs\ntest.isna().sum()","5fcdfb07":"cat_cols = ['Coverage', 'Reason', 'EnforcementAction', 'Conclusion', 'ResolutionStatus', 'New_SubReason']\nnum_cols = ['RecoveredFromInsurer', 'DaysTakenforResn']","a3212d74":"X_train_num = len(X_train)\ncombined_dataset = pd.concat(objs=[X_train, test], axis=0)","4d98fc38":"combined_dataset.head()","660d5f5e":"def impute_with_mode(x):\n    max_x = x.value_counts()\n    mode = max_x[max_x == max_x.max()].index[0]\n    x[x.isna()] = mode\n    return x\n\ncombined_dataset[cat_cols] = combined_dataset[cat_cols].apply(lambda x: impute_with_mode(x))","1cea12f0":"combined_dataset.isna().sum()","82c0eba0":"combined_dataset = pd.get_dummies(combined_dataset, columns=cat_cols, drop_first=True)","d5bf84ff":"combined_dataset.head()","1713d219":"X_train = copy.copy(combined_dataset[:X_train_num])\ntest = copy.copy(combined_dataset[X_train_num:])","21d59fab":"print(X_train.shape)\nprint(test.shape)","063297ae":"train = pd.concat([X_train, y_train], axis =1)\nprint(train.shape)","563cea9a":"df0 = train[train['RecoveredFromInsurer'] == 0]\nprint(df0.shape)","168fb649":"test0 = test[test['RecoveredFromInsurer'] == 0]\nprint(test0.shape)","9ec27b76":"# Splitting df0 into train0 and val0\nfrom sklearn.model_selection import train_test_split\n\ntrain0 , val0 = train_test_split(df0, test_size = 0.3, shuffle = True ,random_state = 800)","1d5d34c3":"X_Train0 = train0.copy().drop('DRC', axis = 1)\ny_Train0 = train0[['InsurerID','DRC']]\nX_val0 = val0.copy().drop('DRC', axis = 1)\ny_val0 = val0[['InsurerID','DRC']]","08d71bc6":"# Setting InsurerID as the Index\nX_Train0.set_index('InsurerID', inplace = True)\ny_Train0.set_index('InsurerID', inplace = True)\nX_val0.set_index('InsurerID', inplace = True)\ny_val0.set_index('InsurerID', inplace = True)","ef95fddb":"# Applying Random Forest \nfrom sklearn.ensemble import RandomForestClassifier\nrfc0 = RandomForestClassifier()\nrfc0.fit(X = X_Train0,y = y_Train0)","cedf5126":"train_pred_rfc0 = rfc0.predict(X_Train0)\ntest_pred_rfc0 = rfc0.predict(X_val0)","7619a117":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_Train accuracy\", metrics.accuracy_score(y_Train0, train_pred_rfc0).round(5))\nprint(\"\\nRF_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train0, train_pred_rfc0, average = None).round(5))\nprint(\"\\nRF_Validation accuracy\", metrics.accuracy_score(y_val0, test_pred_rfc0).round(5))\nprint(\"\\nRF_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val0, test_pred_rfc0, average = None).round(5))","e7d5dae3":"# Applying on Test data\ntest0_new = test0.copy()","e6387f12":"test0_new.set_index('InsurerID', inplace = True)","fbd0129b":"y_pred_rfc0 = rfc0.predict(test0_new)","ddbf8b98":"y_pred_rfc0 = pd.DataFrame(y_pred_rfc0, columns = ['DRC'])","10c2f284":"y_pred_rfc0['InsurerID'] = test0['InsurerID']","1b1f94a4":"y_pred_rfc0.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","28e81cc2":"group_RF0_pred = pd.DataFrame(y_pred_rfc0.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF0_pred = group_RF0_pred.round().astype(int)\ngroup_RF0_pred.head(10)","e1358465":"dfnot0 = train[train['RecoveredFromInsurer'] != 0]\nprint(dfnot0.shape)","1f0a3a27":"dfnot0.sort_values(by = 'RecoveredFromInsurer', ascending = False).head()","8de36cbe":"testnot0 = test[test['RecoveredFromInsurer'] != 0]\nprint(testnot0.shape)","944dc066":"Xno0 = dfnot0.copy().drop('DRC', axis = 1)\nyno0 = dfnot0[['DRC']]","c0d723e6":"Xno0_num = len(Xno0)\ncombined_dataset_no0 = pd.concat(objs=[Xno0, testnot0], axis=0)\nprint(combined_dataset_no0.shape)","77f0dda1":"# Standardization of Numerical Columns\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(combined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","9f3cf7b8":"Xno0 = copy.copy(combined_dataset_no0[:Xno0_num])\ntestnot0 = copy.copy(combined_dataset_no0[Xno0_num:])","3c236e11":"dfnot0 = pd.concat([Xno0, yno0], axis =1)","1220cc00":"print(dfnot0.shape)\nprint(testnot0.shape)","bd47dcde":"# Splitting dfnot0 into trainnot0 and valnot0\nfrom sklearn.model_selection import train_test_split\n\ntrainnot0 , valnot0 = train_test_split(dfnot0, test_size = 0.3, shuffle = True ,random_state = 800)","a23e8617":"X_Trainnot0 = trainnot0.copy().drop('DRC', axis = 1)\ny_Trainnot0 = trainnot0[['InsurerID','DRC']]\nX_valnot0 = valnot0.copy().drop('DRC', axis = 1)\ny_valnot0 = valnot0[['InsurerID','DRC']]","8ade80f5":"# Setting InsurerID as the Index\nX_Trainnot0.set_index('InsurerID', inplace = True)\ny_Trainnot0.set_index('InsurerID', inplace = True)\nX_valnot0.set_index('InsurerID', inplace = True)\ny_valnot0.set_index('InsurerID', inplace = True)","bfeb0d15":"# Applying Random Forest\nrfcnot0 = RandomForestClassifier()\nrfcnot0.fit(X = X_Trainnot0,y = y_Trainnot0)","bc43b726":"train_pred_rfcnot0 = rfcnot0.predict(X_Trainnot0)\ntest_pred_rfcnot0 = rfcnot0.predict(X_valnot0)","a1413221":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_not0_Train accuracy\", metrics.accuracy_score(y_Trainnot0, train_pred_rfcnot0).round(5))\nprint(\"\\nRF_not0_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Trainnot0, train_pred_rfcnot0, average = None).round(5))\nprint(\"\\nRF_not0_Validation accuracy\", metrics.accuracy_score(y_valnot0, test_pred_rfcnot0).round(5))\nprint(\"\\nRF_not0_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_valnot0, test_pred_rfcnot0, average = None).round(5))","12f5929f":"# Applying on Test data\ntestnot0_new = testnot0.copy()","f602dd92":"testnot0_new.set_index('InsurerID', inplace = True)","5df9d2a9":"y_pred_not0 = rfcnot0.predict(testnot0_new)","9f32b935":"y_pred_not0 = pd.DataFrame(y_pred_not0, columns = ['DRC'])","72a419ab":"y_pred_not0['InsurerID'] = testnot0['InsurerID']","00e10420":"y_pred_not0.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","fdb14622":"group_RF_not0_pred = pd.DataFrame(y_pred_not0.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF_not0_pred = group_RF_not0_pred.round().astype(int)\ngroup_RF_not0_pred.head(10)","11ea946b":"dfnot0_noout = train[(train['RecoveredFromInsurer'] != 0) & (train['RecoveredFromInsurer'] < 400000)]\nprint(dfnot0_noout.shape)","dd7149b8":"testnot0_noout = test[(test['RecoveredFromInsurer'] != 0) & (test['RecoveredFromInsurer'] < 400000)]\nprint(testnot0_noout.shape)","f3a5b8c5":"Xno0_noout = dfnot0_noout.copy().drop('DRC', axis = 1)\nyno0_noout = dfnot0_noout[['DRC']]","24fb2a79":"Xno0_noout_num = len(Xno0_noout)\ncombined_dataset_no0_noout = pd.concat(objs=[Xno0_noout, testnot0_noout], axis=0)\nprint(combined_dataset_no0_noout.shape)","2dca16a7":"# Standardization of Numerical Columns\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(combined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","18b73dda":"Xno0_noout = copy.copy(combined_dataset_no0_noout[:Xno0_noout_num])\ntestnot0_noout = copy.copy(combined_dataset_no0_noout[Xno0_noout_num:])","ccb2dc57":"dfnot0_noout = pd.concat([Xno0_noout, yno0_noout], axis =1)\nprint(dfnot0_noout.shape)\nprint(testnot0_noout.shape)","a824f85d":"# Splitting dfnot0 into trainnot0 and valnot0\nfrom sklearn.model_selection import train_test_split\n\ntrainnot0_noout , valnot0_noout = train_test_split(dfnot0_noout, test_size = 0.3, shuffle = True ,random_state = 800)","26c0269f":"X_Trainnot0_noout = trainnot0_noout.copy().drop('DRC', axis = 1)\ny_Trainnot0_noout = trainnot0_noout[['InsurerID','DRC']]\nX_valnot0_noout = valnot0_noout.copy().drop('DRC', axis = 1)\ny_valnot0_noout = valnot0_noout[['InsurerID','DRC']]","23b515a7":"# Setting InsurerID as the Index\nX_Trainnot0_noout.set_index('InsurerID', inplace = True)\ny_Trainnot0_noout.set_index('InsurerID', inplace = True)\nX_valnot0_noout.set_index('InsurerID', inplace = True)\ny_valnot0_noout.set_index('InsurerID', inplace = True)","fb74d76d":"# Applying Random Forest\nrfcnot0_noout = RandomForestClassifier()\nrfcnot0_noout.fit(X = X_Trainnot0_noout,y = y_Trainnot0_noout)","eb64cd49":"train_pred_rfcnot0_noout = rfcnot0_noout.predict(X_Trainnot0_noout)\ntest_pred_rfcnot0_noout = rfcnot0_noout.predict(X_valnot0_noout)","696a3c39":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_not0_noout_Train accuracy\", metrics.accuracy_score(y_Trainnot0_noout, train_pred_rfcnot0_noout).round(5))\nprint(\"\\nRF_not0_noout_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Trainnot0_noout, train_pred_rfcnot0_noout, average = None).round(5))\nprint(\"\\nRF_not0_noout_Validation accuracy\", metrics.accuracy_score(y_valnot0_noout, test_pred_rfcnot0_noout).round(5))\nprint(\"\\nRF_not0_noout_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_valnot0_noout, test_pred_rfcnot0_noout, average = None).round(5))","eb62c215":"# Applying on Test data\ntestnot0_noout_new = testnot0_noout.copy()","e80e1633":"testnot0_noout_new.set_index('InsurerID', inplace = True)","108374b6":"y_pred_not0_noout = rfcnot0_noout.predict(testnot0_noout_new)","10421d7f":"y_pred_not0_noout = pd.DataFrame(y_pred_not0_noout, columns = ['DRC'])","4cf4eef5":"y_pred_not0_noout['InsurerID'] = testnot0_noout['InsurerID']","cbb9a3a4":"y_pred_not0_noout.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","4373043c":"group_RF_not0_noout_pred = pd.DataFrame(y_pred_not0_noout.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF_not0_noout_pred = group_RF_not0_noout_pred.round().astype(int)\ngroup_RF_not0_noout_pred.head(10)","c569fff6":"from sklearn.ensemble import VotingClassifier","6c9b8598":"model = VotingClassifier(estimators = [('rf1', rfc0), ('rf2', rfcnot0)], voting = 'hard')","f77b909d":"Train , val = train_test_split(train, test_size = 0.3, shuffle = True ,random_state = 800)","8bef1ce9":"X_Train = Train.copy().drop('DRC', axis = 1)\ny_Train = Train[['InsurerID','DRC']]\nX_val = val.copy().drop('DRC', axis = 1)\ny_val = val[['InsurerID','DRC']]","c03e2058":"X_Train.set_index('InsurerID', inplace = True)\ny_Train.set_index('InsurerID', inplace = True)\nX_val.set_index('InsurerID', inplace = True)\ny_val.set_index('InsurerID', inplace = True)","fd06b34c":"model.fit(X_Train, y_Train)","da3fbc85":"train_model_pred = model.predict(X_Train)\ntest_model_pred = model.predict(X_val)","9481211a":"print(\"\\nEn_Train accuracy\", metrics.accuracy_score(y_Train, train_model_pred).round(5))\nprint(\"\\nEn_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model_pred, average = None).round(5))\nprint(\"\\nEn_Validation accuracy\", metrics.accuracy_score(y_val, test_model_pred).round(5))\nprint(\"\\nEn_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model_pred, average = None).round(5))","1e266f4b":"test_en1 = test.copy()","0fd5ef3e":"test_en1.set_index('InsurerID', inplace = True)","fd5eaa2f":"y_pred_en_model1 = model.predict(test_en1)","6a2e2e37":"y_pred_en_model1 = pd.DataFrame(y_pred_en_model1, columns = ['DRC'])","494200a4":"y_pred_en_model1['InsurerID'] = test['InsurerID']","d710f861":"y_pred_en_model1.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","bf470172":"group_ensemble1_pred = pd.DataFrame(y_pred_en_model1.groupby(['InsurerID'])['DRC'].mean())\ngroup_ensemble1_pred = group_ensemble1_pred.round().astype(int)\ngroup_ensemble1_pred.head(10)","4f1d5995":"pd.DataFrame(group_ensemble1_pred, columns=['DRC']).to_csv('Prediction_DRC_ensemble1.csv')","b164f53c":"model_0_noout = VotingClassifier(estimators = [('rf1', rfc0), ('rf3', rfcnot0_noout)], voting = 'hard')","b8661c3b":"model_0_noout.fit(X_Train, y_Train)","009f3aed":"train_modelnoout_pred = model_0_noout.predict(X_Train)\ntest_modelnoout_pred = model_0_noout.predict(X_val)","25e51372":"print(\"\\nEn2_Train accuracy\", metrics.accuracy_score(y_Train, train_modelnoout_pred).round(5))\nprint(\"\\nEn2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_modelnoout_pred, average = None).round(5))\nprint(\"\\nEn2_Validation accuracy\", metrics.accuracy_score(y_val, test_modelnoout_pred).round(5))\nprint(\"\\nEn2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_modelnoout_pred, average = None).round(5))","f8f332c4":"model_all = VotingClassifier(estimators = [('rf1', rfc0), ('rf2', rfcnot0),('rf3', rfcnot0_noout)], voting = 'hard')","3559b70c":"model_all.fit(X_Train, y_Train)","51ef72e5":"train_model_all = model_all.predict(X_Train)\ntest_model_all = model_all.predict(X_val)","fe02bcfa":"print(\"\\nEn_all_Train accuracy\", metrics.accuracy_score(y_Train, train_model_all).round(5))\nprint(\"\\nEn_all_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model_all, average = None).round(5))\nprint(\"\\nEn_all_Validation accuracy\", metrics.accuracy_score(y_val, test_model_all).round(5))\nprint(\"\\nEn_all_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model_all, average = None).round(5))","55d3aa1a":"y_pred_en_model_all = model_all.predict(test_en1)","b4a6fdd7":"y_pred_en_model_all = pd.DataFrame(y_pred_en_model_all, columns = ['DRC'])","ce22d1ab":"y_pred_en_model_all['InsurerID'] = test['InsurerID']","98564ecd":"y_pred_en_model_all.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","4c6e2841":"group_ensemble_predall = pd.DataFrame(y_pred_en_model_all.groupby(['InsurerID'])['DRC'].mean())\ngroup_ensemble_predall = group_ensemble_predall.round().astype(int)\ngroup_ensemble_predall.head(10)","9e9f42da":"# Writing prediction for upload","ab8374be":"y_pred_all_new = y_pred_en_model_all.groupby('InsurerID')['DRC'].value_counts()\n# Grouping to count the occurrences for different DRCs","d7820613":"arf_df = y_pred_all_new.unstack()\n# Reshaping data to stack the columns row-wise","54b6e5a0":"arf_df_pred = arf_df.idxmax(axis=1, skipna = True)\n# Taking the max value based on index","290bc67a":"arf_df_pred = pd.DataFrame(arf_df_pred, columns = ['DRC'])","2acc7b24":"pd.DataFrame(arf_df_pred).to_csv('Ensemble_AllRFs.csv')\narf_df_pred.head()","74e0b728":"df_bu.ResolutionStatus.unique()","10dec5ea":"test_bu.ResolutionStatus.unique()","4b97b46c":"df_bu.isna().sum()","cc5b9938":"test_bu.isna().sum()","3b5aea70":"import datetime\ndf_bu.loc[df_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()\ntest_bu.loc[test_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()","5279abae":"df_bu.loc[df_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()","33c7057e":"df_bu.isna().sum()","030849cf":"test_bu.isna().sum()","059a9596":"df_bu['DaysTakenforResn'] = (df_bu['DateOfResolution'] - df_bu['DateOfRegistration']).dt.days\ndf_bu.head()","9f074a96":"test_bu['DaysTakenforResn'] = (test_bu['DateOfResolution'] - test_bu['DateOfRegistration']).dt.days\ntest_bu.head()","dcddaf48":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ndf_bu = df_bu.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\nprint(df_bu.columns)\ntest_bu = test_bu.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\nprint(test_bu.columns)","a9cff11c":"# Separating the target variable\nX_train_new = df_bu.copy().drop('DRC', axis = 1)\ny_train_new = df_bu['DRC']\nprint(X_train_new.shape)\nprint(y_train_new.shape)","040fbcd7":"X_train_new_num = len(X_train_new)\ncombined_dataset_new = pd.concat(objs=[X_train_new, test_bu], axis=0)","85268737":"combined_dataset_new[cat_cols] = combined_dataset_new[cat_cols].apply(lambda x: impute_with_mode(x))","f49514ad":"combined_dataset_new = pd.get_dummies(combined_dataset_new, columns=cat_cols, drop_first=True)","391e1bf5":"X_train_new = copy.copy(combined_dataset_new[:X_train_new_num])\ntest_bu = copy.copy(combined_dataset_new[X_train_new_num:])","f9b7b5c5":"train_new = pd.concat([X_train_new, y_train_new], axis =1)\nprint(train_new.shape)\nprint(test_bu.shape)","8f12c680":"train_brf , val_brf = train_test_split(train_new, test_size = 0.3, shuffle = True ,random_state = 800)","2235ef3e":"X_Train_brf = train_brf.copy().drop('DRC', axis = 1)\ny_Train_brf = train_brf[['InsurerID','DRC']]\nX_val_brf = val_brf.copy().drop('DRC', axis = 1)\ny_val_brf = val_brf[['InsurerID','DRC']]","48835af6":"X_Train_brf.set_index('InsurerID', inplace = True)\ny_Train_brf.set_index('InsurerID', inplace = True)\nX_val_brf.set_index('InsurerID', inplace = True)\ny_val_brf.set_index('InsurerID', inplace = True)","a2451b41":"# Applying Random Forest\nrf_brf = RandomForestClassifier()\nrf_brf.fit(X = X_Train_brf,y = y_Train_brf)","032a2531":"train_pred_brf = rf_brf.predict(X_Train_brf)\ntest_pred_brf = rf_brf.predict(X_val_brf)","3ee278e6":"print(\"\\nRF_new_Train accuracy\", metrics.accuracy_score(y_Train_brf, train_pred_brf).round(5))\nprint(\"\\nRF_new_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_brf, train_pred_brf, average = None).round(5))\nprint(\"\\nRF_new_Validation accuracy\", metrics.accuracy_score(y_val_brf, test_pred_brf).round(5))\nprint(\"\\nRF_new_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_brf, test_pred_brf, average = None).round(5))","cabc2a3f":"dfnew0 = train_new[train_new['RecoveredFromInsurer'] == 0]\ntestnew0 = test_bu[test_bu['RecoveredFromInsurer'] == 0]\nprint(dfnew0.shape)\nprint(testnew0.shape)","489d9bf5":"train_new0, val_new0 = train_test_split(dfnew0, test_size = 0.3, shuffle = True, random_state = 800)","7d05a9f7":"X_Train_new0 = train_new0.copy().drop('DRC', axis = 1)\ny_Train_new0 = train_new0[['InsurerID', 'DRC']]\nX_val_new0 = val_new0.copy().drop('DRC', axis = 1)\ny_val_new0 = val_new0[['InsurerID', 'DRC']]","79f6bdcc":"X_Train_new0.set_index('InsurerID', inplace = True)\ny_Train_new0.set_index('InsurerID', inplace = True)\nX_val_new0.set_index('InsurerID', inplace = True)\ny_val_new0.set_index('InsurerID', inplace = True)","5ad09262":"rf_0_new = RandomForestClassifier()\nrf_0_new.fit(X_Train_new0, y_Train_new0)","a0ef6761":"train_pred_rf_0_new = rf_0_new.predict(X_Train_new0)\ntest_pred_rf_0_new = rf_0_new.predict(X_val_new0)","9858ccbd":"print(\"\\nRF_0_new_Train accuracy\", metrics.accuracy_score(y_Train_new0, train_pred_rf_0_new).round(5))\nprint(\"\\nRF_0_new_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_new0, train_pred_rf_0_new, average = None).round(5))\nprint(\"\\nRF_0_new_Validation accuracy\", metrics.accuracy_score(y_val_new0, test_pred_rf_0_new).round(5))\nprint(\"\\nRF_0_new_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_new0, test_pred_rf_0_new, average = None).round(5))","641f954c":"dfnewnot0 = train_new[train_new['RecoveredFromInsurer'] != 0]\ntestnewnot0 = test_bu[test_bu['RecoveredFromInsurer'] != 0]\nprint(dfnewnot0.shape)\nprint(testnewnot0.shape)","56208f21":"X = dfnewnot0.copy().drop('DRC', axis = 1)\ny = dfnewnot0[['DRC']]","a3dcd33e":"X_num = len(X)\ncombined_df = pd.concat(objs = [X, testnewnot0], axis = 0)\nprint(combined_df.shape)","b86c0359":"scaler = StandardScaler()\nscaler.fit(combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\ncombined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","053f22a3":"X = copy.copy(combined_df[:X_num])\ntestnewnot0 = copy.copy(combined_df[X_num:])","a7615fa1":"dfnewnot0 = pd.concat([X, y], axis=1)\nprint(dfnewnot0.shape)\nprint(testnewnot0.shape)","e5a8e789":"train_newnot0, val_newnot0 = train_test_split(dfnewnot0, test_size = 0.3, shuffle = True, random_state = 800)","8b948039":"X_Train_newnot0 = train_newnot0.copy().drop('DRC', axis = 1)\ny_Train_newnot0 = train_newnot0[['InsurerID', 'DRC']]\nX_val_newnot0 = val_newnot0.copy().drop('DRC', axis = 1)\ny_val_newnot0 = val_newnot0[['InsurerID', 'DRC']]","f2864b59":"X_Train_newnot0.set_index('InsurerID', inplace = True)\ny_Train_newnot0.set_index('InsurerID', inplace = True)\nX_val_newnot0.set_index('InsurerID', inplace = True)\ny_val_newnot0.set_index('InsurerID', inplace = True)","27771946":"rf_newnot0 = RandomForestClassifier()\nrf_newnot0.fit(X_Train_newnot0, y_Train_newnot0)","4e312c63":"train_pred_rf_newnot0 = rf_0_new.predict(X_Train_newnot0)\ntest_pred_rf_newnot0 = rf_0_new.predict(X_val_newnot0)","57163878":"print(\"\\nRF_new_not0_Train accuracy\", metrics.accuracy_score(y_Train_newnot0, train_pred_rf_newnot0).round(5))\nprint(\"\\nRF_new_not0_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_newnot0, train_pred_rf_newnot0, average = None).round(5))\nprint(\"\\nRF_new_not0_Validation accuracy\", metrics.accuracy_score(y_val_newnot0, test_pred_rf_newnot0).round(5))\nprint(\"\\nRF_new_not0_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_newnot0, test_pred_rf_newnot0, average = None).round(5))","8a92deef":"dfnew_no0_noout = train_new[(train_new['RecoveredFromInsurer'] != 0) & (train_new['RecoveredFromInsurer'] < 400000)]\ntestnew_no0_noout = test_bu[(test_bu['RecoveredFromInsurer'] != 0) &(test_bu['RecoveredFromInsurer'] < 400000)]\nprint(dfnew_no0_noout.shape)\nprint(testnew_no0_noout.shape)","437f2cb2":"X = dfnew_no0_noout.copy().drop('DRC', axis =1)\ny = dfnew_no0_noout[['DRC']]","5bfa398b":"X_num = len(X)\ncombined_df = pd.concat(objs = [X, testnew_no0_noout], axis=0)\nprint(combined_df.shape)","f9a7264d":"scaler = StandardScaler()\nscaler.fit(combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","8d8e662b":"X = copy.copy(combined_df[:X_num])\ntestnew_no0_noout = copy.copy(combined_df[X_num:])","d6ff5cc7":"dfnew_no0_noout = pd.concat([X,y],axis =1)\nprint(dfnew_no0_noout.shape)\nprint(testnew_no0_noout.shape)","7b1c4547":"t, v = train_test_split(dfnew_no0_noout, test_size = 0.3, shuffle = True, random_state = 800)","ee070e6c":"Xt = t.copy().drop('DRC', axis = 1)\nyt = t[['InsurerID', 'DRC']]\nXv = v.copy().drop('DRC', axis = 1)\nyv = v[['InsurerID', 'DRC']]","562ad3dd":"Xt.set_index('InsurerID', inplace = True)\nyt.set_index('InsurerID', inplace = True)\nXv.set_index('InsurerID', inplace = True)\nyv.set_index('InsurerID', inplace = True)","a7e2eb87":"RF = RandomForestClassifier()\nRF.fit(X=Xt, y= yt)","4b507acd":"tp = RF.predict(Xt)\nvp = RF.predict(Xv)","2d2824fa":"print(\"\\nRF_not0_noout_Train accuracy\", metrics.accuracy_score(yt, tp).round(5))\nprint(\"\\nRF_not0_noout_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(yt, tp, average = None).round(5))\nprint(\"\\nRF_not0_noout_Validation accuracy\", metrics.accuracy_score(yv, vp).round(5))\nprint(\"\\nRF_not0_noout_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(yv, vp, average = None).round(5))","1a9b50f1":"model1 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', rf_newnot0)], voting = 'hard')","8d8d5483":"Train , val = train_test_split(train_new, test_size = 0.3, shuffle = True ,random_state = 800)","d7ff7698":"X_Train = Train.copy().drop('DRC', axis = 1)\ny_Train = Train[['InsurerID','DRC']]\nX_val = val.copy().drop('DRC', axis = 1)\ny_val = val[['InsurerID','DRC']]","6ff53178":"X_Train.set_index('InsurerID', inplace = True)\ny_Train.set_index('InsurerID', inplace = True)\nX_val.set_index('InsurerID', inplace = True)\ny_val.set_index('InsurerID', inplace = True)","b999d141":"model1.fit(X_Train, y_Train)","319a9712":"train_model1_pred = model1.predict(X_Train)\ntest_model1_pred = model1.predict(X_val)","804e7477":"print(\"\\nEnnew1_Train accuracy\", metrics.accuracy_score(y_Train, train_model1_pred).round(5))\nprint(\"\\nEnnew1_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model1_pred, average = None).round(5))\nprint(\"\\nEnnew1_Validation accuracy\", metrics.accuracy_score(y_val, test_model1_pred).round(5))\nprint(\"\\nEnnew1_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model1_pred, average = None).round(5))","c2a15569":"model2 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', RF)], voting = 'hard')","c83e2180":"model2.fit(X_Train, y_Train)","5181916b":"train_model2_pred = model2.predict(X_Train)\ntest_model2_pred = model2.predict(X_val)","5b2fc327":"print(\"\\nEnnew2_Train accuracy\", metrics.accuracy_score(y_Train, train_model2_pred).round(5))\nprint(\"\\nEnnew2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model2_pred, average = None).round(5))\nprint(\"\\nEnnew2_Validation accuracy\", metrics.accuracy_score(y_val, test_model2_pred).round(5))\nprint(\"\\nEnnew2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model2_pred, average = None).round(5))","bdbf8360":"model3 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', rf_newnot0), ('rf3', RF)], voting = 'hard')","6f47292d":"model3.fit(X_Train, y_Train)","92c3d91a":"train_model3_pred = model3.predict(X_Train)\ntest_model3_pred = model3.predict(X_val)","cb208e07":"print(\"\\nEnnew2_Train accuracy\", metrics.accuracy_score(y_Train, train_model3_pred).round(5))\nprint(\"\\nEnnew2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model3_pred, average = None).round(5))\nprint(\"\\nEnnew2_Validation accuracy\", metrics.accuracy_score(y_val, test_model3_pred).round(5))\nprint(\"\\nEnnew2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model3_pred, average = None).round(5))","0fe29461":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer (!= 0 & <400000)","5e60ff72":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer != 0","665ef35a":"## Processing on Train set by dropping 'Re-Opened' & 'Open' ResolutionStatus","c36f7430":"#### Checking unique values in columns","fd5fe3ee":"## Creating 3 subsets of the data based on RecoveredFromInsurer for all type of Resolution Status\n- 1. Subset with RecoveredFromInsurer == 0\n- 2. Subset with RecoveredFromInsurer != 0\n- 3. Subset with RecoveredFromInsurer !=0 & < 400000","3e40b77e":"### 3. For RecoveredFromInsurer != 0 removing outliers (RecoveredFromInsurer >= 400000)","f7b0ff9c":"# Analysis with all types of Resolution Status","ebdf607c":"#### Segragating 66 Sub Reasons into 5 Sections - Claims, Delay, No SubReason, Service, and Underwriting\/Sales","52120974":"### Basic RF - applying on all the data","6efd75b5":"#### Checking for NAs","3f6e36eb":"## Ensemble with all RFs","0a007304":"### 3. For RecoveredFromInsurer != 0 removing outliers (RecoveredFromInsurer >= 400000)","2386e98a":"## Dropping 'Re-Opened' & 'Open' for ResolutionStatus from test for analysis continuation","430c5832":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer (!= 0 & <400000)","41c6119c":"### 1. For RecoveredFromInsurer == 0","5ee3d5d9":"## Creating 3 subsets of the data based on RecoveredFromInsurer\n- 1. Subset with RecoveredFromInsurer == 0\n- 2. Subset with RecoveredFromInsurer != 0\n- 3. Subset with RecoveredFromInsurer !=0 & < 400000","b0428b99":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer != 0","b89a1d37":"## Analysis continuation for only 'Closed' ResolutionStatus","b4ae92cf":"#### Dropping of columns","e8dc7e8e":"## Model Summary","190de1a8":"## Ensemble for all RFs","19e3ea5e":"#### RFs are working relatively better on train part of segragated data sets\n#### On an overall perspective the Ensemble model combining 3 RFs on data for Resolution Status = Open is giving the best generalization (Train acc = 0.86116 & Val acc = 0.85957)","4d526efe":"### Test set with all ResolutionStatus","00192628":"### 1. For RecoveredFromInsurer == 0","88842a4b":"# Ensemble of RFs - further analysis","b1a3df31":"#### Reading and Preview of the data","7c83019b":"### Reading and applying changes to the Test dataset","7d1cb58f":"## Dummies for Categorical Variables","94344e2e":"### Train set with all ResolutionStatus","64fa3a0f":"### 2. For RecoveredFromInsurer != 0","b4bf9561":"### 2. For RecoveredFromInsurer != 0"}}