{"cell_type":{"a575e5ad":"code","2050c193":"code","75651ad9":"code","2db0f0e3":"code","20acfb87":"code","1090c35c":"code","5759c448":"code","e45c5efa":"code","ccbe981f":"code","d1beea56":"code","08b7a6d2":"code","a0234b08":"code","adcbdea6":"code","35aa75fb":"markdown","cf4f0846":"markdown","768ea80a":"markdown","99e43942":"markdown","2f4be112":"markdown"},"source":{"a575e5ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport datatable as dt\nfrom sklearn.metrics import silhouette_score\n\n\nimport gc\npd.set_option('display.max_rows', 500)","2050c193":"!pip install ..\/input\/faiss-163\/faiss_cpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl","75651ad9":"import faiss","2db0f0e3":"train_data_datatable = dt.fread('..\/input\/jane-street-market-prediction\/train.csv')\ndf = train_data_datatable.to_pandas()\n\n# Thanks to this notebook to gain memory usage : https:\/\/www.kaggle.com\/jorijnsmit\/one-liner-to-halve-your-memory-usage\nfloat64_cols = df.select_dtypes(include='float64').columns\nmapper = {col_name: np.float32 for col_name in float64_cols}\ndf = df.astype(mapper)\n\ndel train_data_datatable    \n","20acfb87":"class FaissKMeans:\n    def __init__(self, n_clusters=8, n_init=10, max_iter=300):\n        self.n_clusters = n_clusters\n        self.n_init = n_init\n        self.max_iter = max_iter\n        self.kmeans = None\n        self.cluster_centers_ = None\n        self.inertia_ = None\n\n    def fit(self, X):\n        self.kmeans = faiss.Kmeans(d=X.shape[1],\n                                   k=self.n_clusters,\n                                   niter=self.max_iter,\n                                   nredo=self.n_init)\n        self.kmeans.train(X.astype(np.float32))\n        self.cluster_centers_ = self.kmeans.centroids\n        self.inertia_ = self.kmeans.obj[-1]\n\n    def predict(self, X):\n        return self.kmeans.index.search(X.astype(np.float32), 1)[1]","1090c35c":"cols_with_missing = [col for col in df.columns if df[col].isnull().any()]\nfor col in cols_with_missing:\n    df[col].fillna(-999, inplace=True) ","5759c448":"NB_CLUSTERS = 5\nFEATURES_LIST = ['feature_'+str(i) for i in range(130)] + ['weight']\n\nclusterer = FaissKMeans(n_clusters=NB_CLUSTERS, n_init=10, max_iter=3000)\n\ndf = df.astype({'feature_0': np.float32})\ndf_feats = np.copy(df[FEATURES_LIST].to_numpy(), order='C')\nclusterer.fit(df_feats)\ny_clusters = clusterer.predict(df_feats)\n#silhouette_score(df_feats, y_clusters.ravel()) # Too slow","e45c5efa":"df_full = pd.concat([df[FEATURES_LIST+['date', 'resp']], pd.DataFrame(y_clusters, columns=['cluster'], index=df.index)], axis=1)","ccbe981f":"#fig = plt.figure(figsize = (15, 10))\nfig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Date', fontsize=18)\nax.set_ylabel('Number of instances in cluster', fontsize=18)\nax.set_title('Repartition of clusters along time', fontsize=18)\n\ncolors = ['red', 'blue', 'orange', 'brown', 'black']\n\nfor cluster_indice in range(NB_CLUSTERS):\n    df_cluster = df_full[df_full.cluster == cluster_indice].groupby(by='date')['date'].count()\n    df_cluster.rename(f'Cluster {cluster_indice}', inplace=True)\n    #ax = fig.add_subplot(111)\n\n    df_cluster.groupby(pd.cut(df_cluster.index, np.arange(-1,500,100))).sum().plot(kind='bar', position=cluster_indice, label=f'{cluster_indice}', color=colors[cluster_indice], width=0.1)\n    \nplt.legend(loc=\"upper right\");","d1beea56":"#df_full['resp_bins'] = pd.cut(df_full['resp'], bins=[-0.25, -0.2, -0.15, -0.1, -0.0505, -0.000569, 0.0493, 0.0992, 0.149])\ndf_full['resp_bins'] = pd.cut(df_full['resp'], bins=50)","08b7a6d2":"#fig = plt.figure(figsize = (15, 10))\nfig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Date', fontsize=18)\nax.set_ylabel('Number of instances in cluster', fontsize=18)\nax.set_title('Repartition of clusters along resp interval', fontsize=18)\n\ncolors = ['red', 'blue', 'orange', 'brown', 'black']\n\nfor cluster_indice in range(NB_CLUSTERS):\n    df_cluster = df_full[df_full.cluster == cluster_indice].groupby(by='resp_bins')['resp_bins'].count()\n    df_cluster.rename(f'Cluster {cluster_indice}', inplace=True)\n    #ax = fig.add_subplot(111)\n\n    df_cluster.plot(kind='bar', position=cluster_indice, label=f'{cluster_indice}', color=colors[cluster_indice], width=0.1)\n    \nplt.legend(loc=\"upper right\");","a0234b08":"fig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Cluster', fontsize=18)\nax.set_ylabel('Number of values in cluster', fontsize=18)\nax.set_title('Number of values by cluster', fontsize=18)\n\ndf_full.groupby(by='cluster')['resp'].count().plot.bar(figsize=(15,5), ax=ax, color=colors);","adcbdea6":"fig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Cluster', fontsize=18)\nax.set_ylabel('Mean value of resp in cluster', fontsize=18)\nax.set_title('resp mean by cluster', fontsize=18)\n\ndf_full.groupby(by='cluster')['resp'].mean().plot.bar(figsize=(15,5), ax=ax, color=colors);","35aa75fb":"# Clustering of feature values","cf4f0846":"# Install and import FAISS","768ea80a":"# Train a clustering with k=5 clusters","99e43942":"# Some visualizations ","2f4be112":"# Load data"}}