{"cell_type":{"9c5d448b":"code","cd0a4335":"code","34840f2d":"code","476f3cb4":"code","5eafc101":"code","ce59c1b1":"code","fe326296":"code","010e4659":"code","59cab2fe":"code","72f0cefd":"code","d7211b86":"code","836ba143":"code","2440bf75":"code","2f14c7fd":"code","1c7f672f":"code","b476516b":"code","bd5cbe3e":"code","60bb2a10":"code","fc6648f4":"code","f77f8cb5":"code","f053b9a5":"code","3b175771":"code","273c94fe":"code","1c937137":"code","b02cb475":"code","f5fbc3b6":"code","84b42ac4":"code","a6dfa761":"code","a16f1dfc":"code","b2edb955":"code","dc68d859":"code","2ee45162":"markdown","8d04c2e2":"markdown","80980cdd":"markdown","e6280567":"markdown","1ab4f091":"markdown","ea8a81e9":"markdown"},"source":{"9c5d448b":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd0a4335":"# import tensorflow as tf\nimport tensorflow.compat.v1 as tf\nimport tensorflow_datasets as tfds\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tempfile\nimport pprint\n\nfrom PIL import Image, ImageOps\n\nimport glob\nimport io\nimport os\nimport yaml\n\nimport IPython.display as display\n\n%matplotlib inline","34840f2d":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set.\n    # On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\n# AUTO = tf.data.experimental.AUTOTUNE\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","476f3cb4":"from kaggle_datasets import KaggleDatasets\n\n# upload your datasets and make public\n# you get your pulic dataset's gcs path in below way\n# https:\/\/www.kaggle.com\/c\/flower-classification-with-tpus\/discussion\/130326\n# https:\/\/www.kaggle.com\/paultimothymooney\/how-to-retrieve-gcs-paths-from-kaggle-datasets\/data\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('mnist-tfrecord-dataset2')\nGCS_DS_PATH","5eafc101":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\n\nprint(train.shape)\ntrain.head()","ce59c1b1":"files_train = np.sort(np.array(tf.io.gfile.glob(GCS_DS_PATH + '\/mnist_train.tfrecord')))\nprint(files_train)\n\nfiles_test = np.sort(np.array(tf.io.gfile.glob(GCS_DS_PATH + '\/mnist_test.tfrecord')))\nprint(files_test)","fe326296":"filenames = [files_train[0]]\nraw_dataset = tf.data.TFRecordDataset(filenames)\nraw_dataset","010e4659":"# Create a description of the features.\nfeature_description = {\n    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n}\n\ndef _parse_function(example_proto):\n  # Parse the input `tf.train.Example` proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, feature_description)\n\ndef _decode_image_function(example):\n    image = example['image']\n    label = example['label']\n    \n    image = tf.image.decode_jpeg(image, channels=1)\n    image = tf.reshape(image, [28,28,1])\n    return image, label","59cab2fe":"parsed_dataset = raw_dataset.map(_parse_function)\nparsed_dataset = parsed_dataset.map(_decode_image_function)\nparsed_dataset","72f0cefd":"def get_selected_dataset(ds, X_indices_np):\n    # Make a tensor of type tf.int64 to match the one by Dataset.enumerate(). \n    X_indices_ts = tf.constant(X_indices_np, dtype=tf.int64)\n    \n    def is_index_in(index, rest):\n        # Returns True if the specified index value is included in X_indices_ts.\n        #\n        # '==' compares the specified index value with each values in X_indices_ts.\n        # The result is a boolean tensor, looks like [ False, True, ..., False ].\n        # reduce_any() returns Ture if True is included in the specified tensor.\n        return tf.math.reduce_any(index == X_indices_ts)\n    \n    def drop_index(index, rest):\n        return rest\n\n    # Dataset.enumerate() is similter to Python's enumerate().\n    # The method adds indices to each elements. Then, the elements are filtered\n    # by using the specified indices. Finally unnecessary indices are dropped.\n    selected_ds = ds \\\n        .enumerate() \\\n        .filter(is_index_in) \\\n        .map(drop_index)\n    return selected_ds","d7211b86":"from sklearn.model_selection import train_test_split\n\n\n# y_targets = np.array([parsed_record['label'] for parsed_record in iter(parsed_dataset)])\ny_targets = train['label'].values\nX_indices = np.arange(len(y_targets))\n\n# Split the generated indices and target values by train_test_split().\n# The ratio of target values should be kept in the splitted datasets.\nX_train_indices, X_val_indices, y_train_targets, y_val_targets = train_test_split(\n    X_indices, y_targets, test_size=0.1, stratify=y_targets, random_state=42)","836ba143":"y_targets","2440bf75":"X_train_indices, X_val_indices","2f14c7fd":"train_ds = get_selected_dataset(parsed_dataset, X_train_indices)\nvalid_ds = get_selected_dataset(parsed_dataset, X_val_indices)\n\n\nTPUDatasetsDict = {\n    'train' : train_ds,\n    'valid' : valid_ds\n}","1c7f672f":"print(TPUDatasetsDict['train'])\nprint(TPUDatasetsDict['valid'])","b476516b":"TPUDatasetsDict['train'].batch(200)","bd5cbe3e":"for train_record in TPUDatasetsDict['train'].take(3):\n    images = train_record[0].numpy()\n    labels = train_record[1]\n    \n    images = images.reshape(28,28)\n    images = Image.fromarray(images)\n    display.display(images)","60bb2a10":"for val_record in TPUDatasetsDict['valid'].take(3):\n    images = val_record[0].numpy()\n    labels = val_record[1]\n    \n    images = images.reshape(28,28)\n    images = Image.fromarray(images)\n    display.display(images)","fc6648f4":"def create_model():\n  return tf.keras.Sequential(\n      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n       tf.keras.layers.Flatten(),\n       tf.keras.layers.Dense(256, activation='relu'),\n       tf.keras.layers.Dense(128, activation='relu'),\n       tf.keras.layers.Dense(10)])","f77f8cb5":"def scale2(image, label):\n    image = tf.cast(image, tf.float32)\n    image \/= 255.0\n    return image, label","f053b9a5":"TPUDatasetsDict['train'].map(scale2).shuffle(10000).batch(200)","3b175771":"def get_dataset(ds_dict, batch_size, is_training=True):\n    split = 'train' if is_training else 'valid' # 'test'\n\n    dataset = ds_dict[split]\n\n    def scale(image, label):\n        image = tf.cast(image, tf.float32)\n        image \/= 255.0\n        return image, label\n\n    dataset = dataset.map(scale)\n\n    # Only shuffle and repeat the dataset in training. The advantage to have a\n    # infinite dataset for training is to avoid the potential last partial batch\n    # in each epoch, so users don't need to think about scaling the gradients\n    # based on the actual batch size.\n    if is_training:\n      dataset = dataset.shuffle(10000)\n      dataset = dataset.repeat()\n\n    dataset = dataset.batch(batch_size)\n\n    return dataset","273c94fe":"len(X_train_indices), len(X_val_indices)","1c937137":"with strategy.scope():\n  model = create_model()\n  model.compile(optimizer='adam',\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['sparse_categorical_accuracy'])\n\nbatch_size = 200\nsteps_per_epoch = len(X_train_indices) \/\/ batch_size\nvalidation_steps = len(X_val_indices) \/\/ batch_size\n\n\ntrain_dataset = get_dataset(TPUDatasetsDict, batch_size, is_training=True)\nvalid_dataset = get_dataset(TPUDatasetsDict, batch_size, is_training=False)\n\nmodel.fit(train_dataset,\n          epochs=5,\n          steps_per_epoch=steps_per_epoch,\n          validation_data=valid_dataset, \n          validation_steps=validation_steps)","b02cb475":"def prepare_test_dataset(dataset, batch_size):\n    def scale(image, label):\n        image = tf.cast(image, tf.float32)\n        image \/= 255.0\n        return image, label\n\n    dataset = dataset.map(scale)\n    dataset = dataset.batch(batch_size)\n    return dataset","f5fbc3b6":"test_dataset = tf.data.TFRecordDataset([files_test[0]])\ntest_dataset = test_dataset.map(_parse_function).map(_decode_image_function)\ntest_dataset = prepare_test_dataset(test_dataset, batch_size)\ntest_dataset","84b42ac4":"test_preds = model.predict(test_dataset)\n\ntest_preds.shape","a6dfa761":"np.argmax(test_preds, 1).shape","a16f1dfc":"sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsub['Label'] = np.argmax(test_preds, 1)\n\nprint(sub.shape)\nsub.head()","b2edb955":"sub.to_csv('submission.csv', index=False)","dc68d859":"for testrecord in tf.data.TFRecordDataset([files_test[0]]).map(_parse_function).map(_decode_image_function).take(5):\n    images = testrecord[0].numpy()\n    labels = testrecord[1]\n    \n    images = images.reshape(28,28)\n    images = Image.fromarray(images)\n    display.display(images)","2ee45162":"### Visualize Valid Data","8d04c2e2":"### Visualize Train Data","80980cdd":"#### Generate TFRecord dataset with below notebook\n\nhttps:\/\/www.kaggle.com\/kaerunantoka\/tpu-starter2-createtfrecorddatasetclassv2","e6280567":"### TPU Settings","1ab4f091":"### Reading a TFRecord file","ea8a81e9":"### \u53c2\u8003\n\n- Kaggle datasets \u304b\u3089 gcs path \u3092\u767a\u884c\u3059\u308b\n\n    - https:\/\/www.kaggle.com\/c\/flower-classification-with-tpus\/discussion\/130326\n\n    - https:\/\/www.kaggle.com\/paultimothymooney\/how-to-retrieve-gcs-paths-from-kaggle-datasets\/data\n    \n\n- TPU session \u306e\u6642\u306f tfrecord \u306f gcs \u306b\u5b58\u5728\u3057\u3066\u308b\u3082\u306e\u3057\u304b\u8aad\u307f\u8fbc\u3081\u306a\u3044\u3089\u3057\u3044\n\n    - https:\/\/cloud.google.com\/tpu\/docs\/troubleshooting#cannot_use_local_filesystem\n    \n    - https:\/\/qiita.com\/mgmk2\/items\/556ca3f4471ada9c69f0"}}