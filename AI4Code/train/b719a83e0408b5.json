{"cell_type":{"b2a81d65":"code","ca1bcd5c":"code","8e931de2":"code","bc6dd05f":"code","e0feb440":"code","1ef35fa3":"code","9ea00fd0":"code","ecba2788":"code","aaae2279":"code","e675a45d":"code","c332ca94":"code","1d4a7314":"code","65ea765a":"code","50f2798c":"code","981cacfa":"code","7005bf49":"code","6e23d297":"code","498659bb":"code","18d8ea22":"code","67ba42b4":"code","cb858235":"markdown","684c1a11":"markdown","536b325a":"markdown","05c36460":"markdown","9ca76eaa":"markdown"},"source":{"b2a81d65":"import numpy as np # linear algebra\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport os\nimport shutil\nimport multiprocessing as mp\nimport tensorflow as tf\n\nfrom random import randint\nimport cv2\nimport numpy as np\nimport sklearn.metrics as metrics\nfrom keras.models import load_model\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom sklearn.utils import class_weight\nfrom keras import layers\nfrom keras.layers import Dense, Dropout, Activation, GlobalAveragePooling2D, MaxPooling2D, Conv2D, Input, Flatten\n#from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.models import Model\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import SGD\n\n\n\nfrom keras.applications.imagenet_utils import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\n#from keras.applications.resnet50 import ResNet50\n\n%matplotlib inline\n\ntrain_dir = '\/kaggle\/input\/food11\/training'\ntest_dir = '\/kaggle\/input\/food11\/validation'\n\ntrain_files = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\ntest_files = [f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]","ca1bcd5c":"from scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\n# label extraction\ntrain = []\ny_train = []\ntest = []\ny_test = []\n\nfor file in train_files:\n    train.append(file)\n    label= file.find(\"_\")\n    y_train.append(int(file[0:label]))\nfor file in test_files:\n    test.append(file)\n    label= file.find(\"_\")\n    y_test.append(int(file[0:label]))","8e931de2":"\ndef Random_sample_images(n_class=0):\n    nrows = 4\n    ncols = 8\n    fig, axes = plt.subplots(nrows=nrows,ncols = ncols)\n    fig.set_size_inches(16,12)\n    img = np.random.choice((np.array(y_train) == n_class).nonzero()[0],nrows*ncols)\n    for i,ax in enumerate(axes.flat):\n        image = cv2.imread(train_dir + \"\/\" + train[img[i]]) \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, dsize=(192, 192), interpolation=cv2.INTER_CUBIC)\n        im = ax.imshow(image)\n        ax.set_axis_off() #to remove the axis\n    plt.subplots_adjust(left = 0,wspace = 0,hspace = 0)\n    plt.show()\n    \n    \nRandom_sample_images(2)","bc6dd05f":"cnnInput = np.ndarray(shape=(len(train), 192,192, 3), dtype=np.float32)\nprint('[INFO] Loading training images')\ni=0\nfor file in train:\n    image = cv2.imread(train_dir + \"\/\" + file)  \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # do not normalize for this model, keep 0-255\n    image = image.astype(\"float\")\n    image = cv2.resize(image, dsize=(192, 192), interpolation=cv2.INTER_CUBIC)\n    # no normalization for this model, keep 0-255\n    x = img_to_array(image)\n    x = x.reshape((1, x.shape[0], x.shape[1],\n                                   x.shape[2]))\n\n    cnnInput[i]=x\n    i+=1\nprint('[INFO] Done')","e0feb440":"cnnTest = np.ndarray(shape=(len(test), 192,192, 3), dtype=np.float32)\nprint('[INFO] Loading test images')\ni=0\nfor file in test:\n    image = cv2.imread(test_dir + \"\/\" + file)  \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # do not normalize for this model, keep 0-255\n    image = image.astype(\"float\")\n    image = cv2.resize(image, dsize=(192, 192))\n    # no normalization for this model, keep 0-255\n    x = img_to_array(image)\n    x = x.reshape((1, x.shape[0], x.shape[1],\n                                   x.shape[2]))\n\n    cnnTest[i]=x\n    i+=1\nprint('[INFO] Done')","1ef35fa3":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport warnings\nfrom keras import backend as K\nfrom keras import layers as L\nfrom keras import models as M\nfrom keras import utils as U\nWEIGHTS_PATH = ('https:\/\/github.com\/fchollet\/deep-learning-models\/'\n                'releases\/download\/v0.2\/'\n                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\nWEIGHTS_PATH_NO_TOP = ('https:\/\/github.com\/fchollet\/deep-learning-models\/'\n                       'releases\/download\/v0.2\/'\n                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nbackend = None\nlayers = None\nmodels = None\nkeras_utils = None\n_KERAS_BACKEND = None\n_KERAS_LAYERS = None\n_KERAS_MODELS = None\n_KERAS_UTILS = None\n\n\ndef get_submodules_from_kwargs(kwargs):\n    backend = kwargs.get('backend', _KERAS_BACKEND)\n    layers = kwargs.get('layers', _KERAS_LAYERS)\n    models = kwargs.get('models', _KERAS_MODELS)\n    utils = kwargs.get('utils', _KERAS_UTILS)\n    for key in kwargs.keys():\n        if key not in ['backend', 'layers', 'models', 'utils']:\n            raise TypeError('Invalid keyword argument: %s', key)\n    return backend, layers, models, utils\nCLASS_INDEX = None\nCLASS_INDEX_PATH = ('https:\/\/storage.googleapis.com\/download.tensorflow.org\/'\n                    'data\/imagenet_class_index.json')\n\ndef preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n    backend, _, _, _ = get_submodules_from_kwargs(kwargs)\n\n    if data_format is None:\n        data_format = backend.image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    if isinstance(x, np.ndarray):\n        return _preprocess_numpy_input(x, data_format=data_format,\n                                       mode=mode, **kwargs)\n    else:\n        return _preprocess_symbolic_input(x, data_format=data_format,\n                                          mode=mode, **kwargs)\ndef decode_predictions(preds, top=5, **kwargs):\n    global CLASS_INDEX\n\n    backend, _, _, keras_utils = get_submodules_from_kwargs(kwargs)\n\n    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 1000)). '\n                         'Found array with shape: ' + str(preds.shape))\n    if CLASS_INDEX is None:\n        fpath = keras_utils.get_file(\n            'imagenet_class_index.json',\n            CLASS_INDEX_PATH,\n            cache_subdir='models',\n            file_hash='c2c37ea517e94d9795004a39431a14cb')\n        with open(fpath) as f:\n            CLASS_INDEX = json.load(f)\n    results = []\n    for pred in preds:\n        top_indices = pred.argsort()[-top:][::-1]\n        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n        result.sort(key=lambda x: x[2], reverse=True)\n        results.append(result)\n    return results\n\n\ndef _obtain_input_shape(input_shape,default_size,min_size,data_format,require_flatten,weights=None):\n    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n        if data_format == 'channels_first':\n            if input_shape[0] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[0]) + ' input channels.')\n            default_shape = (input_shape[0], default_size, default_size)\n        else:\n            if input_shape[-1] not in {1, 3}:\n                warnings.warn(\n                    'This model usually expects 1 or 3 input channels. '\n                    'However, it was passed an input_shape with ' +\n                    str(input_shape[-1]) + ' input channels.')\n            default_shape = (default_size, default_size, input_shape[-1])\n    else:\n        if data_format == 'channels_first':\n            default_shape = (3, default_size, default_size)\n        else:\n            default_shape = (default_size, default_size, 3)\n    if weights == 'imagenet' and require_flatten:\n        if input_shape is not None:\n            if input_shape != default_shape:\n                raise ValueError('When setting `include_top=True` '\n                                 'and loading `imagenet` weights, '\n                                 '`input_shape` should be ' +\n                                 str(default_shape) + '.')\n        return default_shape\n    if input_shape:\n        if data_format == 'channels_first':\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[0] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n                   (input_shape[2] is not None and input_shape[2] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) +\n                                     '; got `input_shape=' +\n                                     str(input_shape) + '`')\n        else:\n            if input_shape is not None:\n                if len(input_shape) != 3:\n                    raise ValueError(\n                        '`input_shape` must be a tuple of three integers.')\n                if input_shape[-1] != 3 and weights == 'imagenet':\n                    raise ValueError('The input must have 3 channels; got '\n                                     '`input_shape=' + str(input_shape) + '`')\n                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n                   (input_shape[1] is not None and input_shape[1] < min_size)):\n                    raise ValueError('Input size must be at least ' +\n                                     str(min_size) + 'x' + str(min_size) +\n                                     '; got `input_shape=' +\n                                     str(input_shape) + '`')\n    else:\n        if require_flatten:\n            input_shape = default_shape\n        else:\n            if data_format == 'channels_first':\n                input_shape = (3, None, None)\n            else:\n                input_shape = (None, None, 3)\n    if require_flatten:\n        if None in input_shape:\n            raise ValueError('If `include_top` is True, '\n                             'you should specify a static `input_shape`. '\n                             'Got `input_shape=' + str(input_shape) + '`')\n    return input_shape\ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = L.Conv2D(filters1, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2a')(input_tensor)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = L.Activation('relu')(x)\n\n    x = L.Conv2D(filters2, kernel_size,\n                      padding='same',\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2b')(x)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = L.Activation('relu')(x)\n\n    x = L.Conv2D(filters3, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2c')(x)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = L.add([x, input_tensor])\n    x = L.Activation('relu')(x)\n    return x\n\n\ndef conv_block(input_tensor,kernel_size,filters,stage,block,strides=(2, 2)):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = L.Conv2D(filters1, (1, 1), strides=strides,\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2a')(input_tensor)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = L.Activation('relu')(x)\n\n    x = L.Conv2D(filters2, kernel_size, padding='same',\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2b')(x)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = L.Activation('relu')(x)\n\n    x = L.Conv2D(filters3, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2c')(x)\n    x = L.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = L.Conv2D(filters3, (1, 1), strides=strides,\n                             kernel_initializer='he_normal',\n                             name=conv_name_base + '1')(input_tensor)\n    shortcut = L.BatchNormalization(\n        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = L.add([x, shortcut])\n    x = L.Activation('relu')(x)\n    return x\n\n\ndef ResNet50(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs):\n    global backend, layers, models, keras_utils\n    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = L.Input(shape=input_shape)\n    else:\n        if not backend.is_keras_tensor(input_tensor):\n            img_input = L.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = L.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n    x = L.Conv2D(64, (7, 7),\n                      strides=(2, 2),\n                      padding='valid',\n                      kernel_initializer='he_normal',\n                      name='conv1')(x)\n    x = L.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = L.Activation('relu')(x)\n    x = L.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n    x = L.MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    if include_top:\n        x = L.GlobalAveragePooling2D(name='avg_pool')(x)\n        x = L.Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = L.GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = L.GlobalMaxPooling2D()(x)\n        else:\n            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n                          'has been changed since Keras 2.2.0.')\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = keras_utils.get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = M.Model(inputs, x, name='resnet50')\n\n    # Load weights.\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = U.get_file(\n                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                WEIGHTS_PATH,\n                cache_subdir='models',\n                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n        else:\n            weights_path = U.get_file(\n                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                WEIGHTS_PATH_NO_TOP,\n                cache_subdir='models',\n                md5_hash='a268eb855778b3df3c7506639542a6af')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            U.convert_all_kernels_in_model(model)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model","9ea00fd0":"model = ResNet50(weights='imagenet',include_top=False,input_shape=(192,192,3),classes=11)","ecba2788":"# make explained variable hot-encoded\ny_train_hot_encoded = to_categorical(y_train)\ny_test_hot_encoded = to_categorical(y_test)","aaae2279":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)","e675a45d":"# get layers and add average pooling layer\nx = model.output\nx = GlobalAveragePooling2D()(x)\n\n# add fully-connected layer\nx = Dense(2048, activation='relu')(x)\nx = Dropout(0.3)(x)\n\n# add output layer\npredictions = Dense(11, activation='softmax')(x)\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\n# training\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory= model.fit(cnnInput,y_train_hot_encoded, batch_size=64, shuffle=True,\n                    validation_data=(cnnTest, y_test_hot_encoded),\n                  class_weight=class_weights, epochs=60)\n#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)","c332ca94":"#to save the model\n#model.save('Food11_60Epoch.h5')","1d4a7314":"#to load the model\n#history = load_model(\"Food11_60Epoch.h5\")","65ea765a":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","50f2798c":"# training\n#history = model.fit(cnnInput, y_train_hot_encoded, batch_size=256, epochs=50, shuffle=True,  validation_split=0.1)\ndata_dict = {0:\"Bread is a staple food prepared from a dough of flour and water,#usually by baking.Throughout recorded history it has been a prominent #food in large parts of the world;#it is one of the oldest man-made foods,#having been of significant importance since the dawn of agriculture; and #plays an essential role in religious rituals and secular culture.Bread may be leavened by #naturally occurring microbes, chemicals, industrially produced yeast, or high-pressure aeration.#In many countries, commercial bread often contains additives to improve flavor, texture, color, shelf life, nutrition, and ease of production for one slice(32gms)#Calories 82#Fat 1.1g#Sodium 144mg#Carbohydrates 13.8g#Fiber 1.9g#Sugars 1.4g#Protein 4g\",\n1 : \"Dairy products or milk products are a type of food produced from or containing the milk of mammals.#They are primarily produced from mammals such as cattle, water buffaloes, goats, sheep, camels and humans. Dairy products include food items such as yogurt, cheese and butter.A facility that produces dairy products is known as a dairy, or dairy factory.Dairy products are consumed worldwide, with the exception of most of East and Southeast Asia and parts of central Africa. #Amount Per 100 grams#Calories 46#Total Fat 2 g#Sodium 55 mg#Potassium 150 mg#Total Carbohydrate 5 g#fiber 0 g#Sugar 5g#Protein 1.6 g\",\n2 : \"Desert is usually a sweet course or dish (as of pastry or ice cream) usually served at the end of a meal. 2 British : a fresh fruit served after a sweet course.Amount Per 100 grams#Calories 20#Total Fat 11 g#Sodium 80 mg#Potassium 199 mg#Total Carbohydrate 24 g#fiber 0.7 g#Sugar 21 g#Protein 3.5 g\",\n3 : \"Egg yolks and whole eggs store significant amounts of protein and choline,and are widely used in cookery. Due to their protein content, the United States Department of Agriculture formerly categorized eggs as Meats within the Food Guide Pyramid (now MyPlate). Despite the nutritional value of eggs, there are some potential health issues arising from cholesterol content, salmonella contamination, and allergy to egg proteins.Amount Per 100 grams#Calories 155#Total Fat 11 g#Sodium 124 mg#Potassium 126 mg#Total Carbohydrate 1.1 g#fiber 0g#Sugar 1.1 g#Protein 13 g\",\n4 : \"Deep frying is a common cooking method used across the globe. It\u2019s often used by restaurants and fast food chains as a quick and inexpensive way to prepare foods. Popular fried foods include fish, french fries, chicken strips and cheese sticks, although you can deep fry just about anything. Many people like the taste of fried foods. Yet these foods tend to be high in calories and trans fat, so eating a lot of them can have negative effects on your health.#Amount Per 100 grams#Calories 200#Total Fat 1 g#Potassium 0 mg#Total Carbohydrate 39 g#fiber 4 g#Sugar 4g#Protein 7 g\",\n5 : \"Meat is animal flesh that is eaten as food.Humans have hunted and killed animals for meat since prehistoric times. The advent of civilization allowed the domestication of animals such as chickens, sheep, rabbits, pigs and cattle. This eventually led to their use in meat production on an industrial scale with the aid of slaughterhouses. Meat is mainly composed of water, protein, and fat. It is edible raw, but is normally eaten after it has been cooked and seasoned or processed in a variety of ways. Unprocessed meat will spoil or rot within hours or days as a result of infection with and decomposition by bacteria and fungi.Meat is important in economy and culture, even though its mass production and consumption has been determined to pose risks for human health and the environment. Many religions have rules about which meat may or may not be eaten. Vegetarians and vegans may abstain from eating meat because of concerns about the ethics of eating meat, environmental effects of meat production or nutritional effects of consumption.#Amount Per 100 grams#Calories 143#Total Fat 3.5 g#Sodium 57 mg#Potassium 421 mg#Total Carbohydrate 0 g#fiber 0g#Sugar 0 g#Protein 26 g\",\n6 : \"Noodles and pasta differ primarily because of their ingredients and the type of processing involved, Kaminska says. Noodles are usually made with flour milled from common wheat. Pasta is processed from durum semolina, which is coarser than typical flour. However, that difference is not always so cut and dried. In some markets, processors will use common wheat for pasta because durum is so expensive. But in a higher-end market such as Italy, there are regulations that require pasta to be made of 100 per cent durum.Also, certain markets such as Japan are starting to use durum in fresh alkaline noodles because they like the yellow colour that the flour provides.There are many formulas for making a variety of Asian noodles, but salt is always a requirement in the production phase. Noodles undergo a \u201csheeting\u201d process where dough is passed through a series of rollers to produce a flat sheet that is sent through a cutter to produce individual noodle strands. Pasta, on the other hand, involves mixing durum semolina with water to form a stiff dough which is then extruded through a mould or die to create various shapes such as spaghetti, lasagna or macaroni.#Amount Per 100grams#Calories 131#Total Fat 1.1 g#Sodium 6 mg#Potassium 24 mg#Total Carbohydrate 25 g#fiber 0g#sugar 0g#Protein 5 g\",\n7 : \"Rice, a monocot, is normally grown as an annual plant, although in tropical areas it can survive as a perennial and can produce a ratoon crop for up to 30 years.Rice cultivation is well-suited to countries and regions with low labor costs and high rainfall, as it is labor-intensive to cultivate and requires sample water. However, rice can be grown practically anywhere, even on a steep hill or mountain area with the use of water-controlling terrace systems. Although its parent species are native to Asia and certain parts of Africa, centuries of trade and exportation have made it commonplace in many cultures worldwide.Amount Per 100 grams#Calories 111#Total Fat 0.9 g#Sodium 5 mg#Potassium 43 mg#Total Carbohydrate 23 g#fiber 1.8 g#Sugar 0.4 g#Protein 2.6 g\",\n8 : \"The harvesting of wild seafood is usually known as fishing or hunting, while the cultivation and farming of seafood is known as aquaculture or fish farming(in the case of fish). Seafood is often colloquially distinguished from meat, although it is still animal in nature and is excluded from a vegetarian diet, as decided by groups like the Vegetarian Society after confusion surrounding pescetarianism. Seafood is an important source of (animal) protein in many diets around the world, especially in coastal areas.#Amount Per 100 grams#Calories 204#Total Fat 8 g#Sodium 117 mg#Potassium 283 mg#Total Carbohydrate 1.9 g#fiber 0 g#Protein 29 g\",\n9 : \"Soup(food) is low in Saturated Fat, and very low in Cholesterol. It is also a good source of Dietary Fiber, Vitamin E (Alpha Tocopherol), Thiamin, Niacin, Vitamin B6, Potassium, Copper and Manganese, and a very good source of Vitamin A.#amount 100gms#Calories 65#Total Fat 0.9g#Sodium 385mg#Potassium 433mg#Carbohydrates 12.1g#Sugar 4.3g#Fiber 2.1g#Protein 2.2g\",\n10: \"Vegetables are parts of plants that are consumed by humans or other animals as food. The original meaning is still commonly used and is applied to plants collectively to refer to all edible plant matter, including the flowers, fruits, stems, leaves, roots, and seeds. The alternate definition of the term is applied somewhat arbitrarily, often by culinary and cultural tradition. It may exclude foods derived from some plants that are fruits, flowers, nuts, and cereal grains, but include savoury fruits such as tomatoes and courgettes, flowers such as broccoli, and seeds such as pulses.#Amount Per 100 grams#Calories 52#Total Fat 0.2 g#Sodium 1 mg#Potassium 107 mg#Total Carbohydrate 14 g#fiber 2.4 g#Sugar 10 g#Protein 0.3 g\"}\n ","981cacfa":"#Predicting a image\nrand_num = randint(0,3430)\ntest_image = cv2.imread(train_dir + \"\/\" + test[rand_num]) \ntest_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\ntest_image = cv2.resize(test_image, dsize=(192, 192), interpolation=cv2.INTER_CUBIC)\nim = imshow(test_image)\npredict_image = np.expand_dims(test_image, axis = 0)\n#predict_image = preprocess_input(predict_image)\nprint(\"The test image is: \" + str(rand_num) + ' in test images')\nprint(\"\\nShape of the image is: \" + str(test_image.shape))\n\nprobability_list = model.predict(predict_image)\n#print(probability_list)\nmax_value = max(probability_list[0])\nduplicate_list = list(probability_list[0])\nindex = duplicate_list.index(max_value)\nprint('\\nOriginal class is: ' + str(y_test[rand_num]))\nprint('\\nPredicted class is: '+ str(index))\nnutrients = data_dict[index]\nnutrients_list = nutrients.split('#')\nfor each in nutrients_list:\n    print(each)","7005bf49":"model.summary()","6e23d297":"#Extra Other Technique","498659bb":"# Data augmentation\n#from keras.preprocessing.image import ImageDataGenerator\n# this is the augmentation configuration we will use for training\n#train_datagen = ImageDataGenerator(\n#    width_shift_range=0.2,\n#    height_shift_range=0.2,\n#    zoom_range=[.6, 1],\n#    vertical_flip=True,\n#    horizontal_flip=True)\n#train_generator = train_datagen.flow(cnnInput, y_train, batch_size=64, seed=11)\n#test_datagen = ImageDataGenerator()\n#test_generator = valid_datagen.flow(cnnValidation, y_valid, batch_size=64, seed=11)","18d8ea22":"#train_datagen.fit(cnnInput)\n#test_datagen.fit(cnnTest)","67ba42b4":"#model.fit_generator(train_datagen.flow(cnnInput, y_train_hot_encoded, batch_size=64), shuffle=True,validation_data=valid_datagen.flow(cnnValidation, y_test_hot_encoded, batch_size=64),class_weight=class_weights, epochs=20)","cb858235":"We start by loading the libraries and the Data :\nWe are going to use CNN ResNet50, which explain the use of the library keras.  ","684c1a11":"* We create containers where we store the arrays of the images in the shape (192,192,3)for both training and validation data.\n* We loaded images with PIL library.\n* We chose 192 because of lack of RAM and kernel crashing","536b325a":"In this part, we did data augmentation. Data augmentation is a way of creating new data with modifications:\n\n* different orientations (horizontal_flip and vertical_flip)\n* With shift (randomly shift images horizontally or randomly shift images vertically)\n* Zoom We used this image generator for training and validation, but for validation image generator, we use the original images from validation dataset.","05c36460":"We used one hot encoding instead of number of the class for labels. To get an ouput of probabilities for belonging to each class.","9ca76eaa":"Here we are going to extract the labels and the names of the file names from training and validation set."}}