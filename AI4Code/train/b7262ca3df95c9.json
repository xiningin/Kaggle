{"cell_type":{"d87f9784":"code","ca6d13c6":"code","35e48eaa":"code","08b158f8":"code","23b2f461":"code","a4d1e7d4":"code","a78a5fdb":"code","24723faf":"code","225d373e":"code","58605ec2":"code","bd800ecf":"code","b0693912":"code","9f07488e":"code","5b61d7de":"code","457ccd77":"code","b3b10f7e":"code","f59ae977":"code","88b4d6eb":"code","df4d3e7e":"code","7a4efe16":"code","52ac1de5":"code","526d0c72":"code","df17731f":"code","df3f78cc":"code","986dc4e2":"code","55d48b72":"markdown","1a0df1c3":"markdown","cc7e585a":"markdown","f053a219":"markdown","9b7272c7":"markdown","c24f15b2":"markdown","0e8e5ba8":"markdown","1091e941":"markdown","0ac91957":"markdown","9b7a798a":"markdown","e1b5b7a0":"markdown","bc48c1c8":"markdown","5ef00555":"markdown","f012547f":"markdown","ee7b3375":"markdown","4895b98c":"markdown","b376b51b":"markdown","9f7ccfb4":"markdown","0c5935e5":"markdown","2516dfb4":"markdown","da727332":"markdown","43755982":"markdown","c5096db3":"markdown"},"source":{"d87f9784":"import warnings\nwarnings.simplefilter('ignore')","ca6d13c6":"import numpy as np\nimport pandas as pd\nimport pylab as plt\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import cohen_kappa_score\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pickle\n\nfrom imblearn.over_sampling import SMOTE\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nimport io\nimport requests\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')","35e48eaa":"%%time\nurl = 'https:\/\/raw.githubusercontent.com\/harshildarji\/ML-Practise\/master\/IMDB%20Sentiment%20Classification%20using%20TF-IDF\/datasets\/data.csv'\n_data = requests.get(url).content\ndata = pd.read_csv(io.StringIO(_data.decode('utf-8')))","08b158f8":"data.head()","23b2f461":"data.isnull().sum()","a4d1e7d4":"data = data.dropna().reset_index(drop=True)","a78a5fdb":"data.isnull().sum()","24723faf":"X_train, X_test, y_train, y_test = train_test_split(data['review'], data['label'], test_size = .4, shuffle = False)","225d373e":"len(X_train), len(y_train), len(X_test), len(y_test)","58605ec2":"sentiments = data['label'].value_counts()\nprint('Sentiments in entire dataset:\\n Positive: {}\\n Negative: {}'.format(sentiments[1], sentiments[0]))","bd800ecf":"def get_sentiments(d, _d):\n    positive = (d==1).sum()\n    negative = (d==0).sum()\n    print('Sentiments in {}:\\n Positive: {}\\n Negative: {}'.format(_d, positive, negative))","b0693912":"get_sentiments(y_train, 'Train data')\nget_sentiments(y_test, 'Test data')","9f07488e":"def tokenize(text):\n    return [word for word in word_tokenize(text.lower()) if word not in stopwords.words('english')]","5b61d7de":"def choose_vectorizer(option):\n    if option == 'generate':\n        vectorizer = TfidfVectorizer(tokenizer = tokenize)\n    elif option == 'load':\n        vectorizer = TfidfVectorizer(vocabulary = pickle.load(open('vocabulary.pkl', 'rb')))\n    \n    return vectorizer","457ccd77":"%%time\noptions = ['generate', 'load']\n\n# 0 to generate, 1 to load (choose wisely, your life depends on it!)\noption = options[0] \n\nvectorizer = choose_vectorizer(option)\nvectorized_train_data = vectorizer.fit_transform(X_train)\nvectorized_test_data = vectorizer.transform(X_test)\n    \nif option == 'generate':\n    pickle.dump(vectorizer.vocabulary_, open('vocabulary.pkl', 'wb'))","b3b10f7e":"%%time\nsm = SMOTE(random_state=42, ratio=1.0)\nX_train, y_train = sm.fit_sample(vectorized_train_data, y_train)","f59ae977":"clf = LogisticRegression()","88b4d6eb":"%%time\nclf.fit(X_train, y_train)","df4d3e7e":"%%time\nkf = KFold(n_splits=10, random_state = 42, shuffle = True)\nscores = cross_val_score(clf, X_train, y_train, cv = kf)","7a4efe16":"print('Cross-validation scores:', scores)\nprint('Cross-validation accuracy: {:.4f} (+\/- {:.4f})'.format(scores.mean(), scores.std() * 2))","52ac1de5":"predictions = clf.predict(vectorized_test_data)\n\nvalidation = dict()\n\nvalidation['accuracy'] = accuracy_score(y_test, predictions)\nvalidation['precision'] = precision_score(y_test, predictions, average='macro')\nvalidation['recall'] = recall_score(y_test, predictions, average='macro')\nvalidation['f1'] = f1_score(y_test, predictions, average='macro')","526d0c72":"print('Validation results:\\n', '-' * 12)\nfor v in validation:\n    print('{}: {:.5f}'.format(v.title(), validation[v]))","df17731f":"p = predictions.tolist()\nck = cohen_kappa_score(y_test, p)\nprint('C-K Score: {:.5f}'.format(ck))","df3f78cc":"example_reviews = [\n    'An honest, engaging, and surprisingly funny look back at one of modern television\\'s greatest achievements.',\n    'Excellent movie! Inspiring and very entertaining for all especially youth and anyone inspired by today\\'s modern age of tech entrepreneurship!',\n    'Honestly even the trailer made me uncomfortable.',\n    'I never write movie reviews, but this one was such a stinker, I feel I owe it to everyone to at least provide a warning.',\n    'This movie was a good movie by standard and a lil beyond standard. It was written very well, The acting was great, each characters performance was clever and the comedic timing was spot on. The story line is very real and relatable. Enjoyable for adults and completely appropriate for pre-teens up to 20. Go support, my family loved it.'\n]","986dc4e2":"example_preds = clf.predict(vectorizer.transform(example_reviews))\nprint(' '.join(str(int(p)) for p in example_preds))","55d48b72":"As one can tell, **first**, **second** and **fifth** reviews in **example_reviews** are **positive** while **third** and **fourth** reviews are **negative**.\n\n*Let's see what classifier predicts!*","1a0df1c3":"In following code cell, choose the option **generate** if you want to generate vectors of train-test data again (*this will also store the vocabulary in the same directory as this project*) otherwise go with the option **load** if you already have the vocabulary (*saved in the same directory as this project*).","cc7e585a":"# TF-IDF","f053a219":"# Training and Validation","9b7272c7":"In the training dataset, there are more negative reviews than positive ones. Therefore, we will first make both the sides equal using **SMOTE** (**S**ynthetic **M**inority **O**ver-sampling **TE**chnique).","c24f15b2":"After split,\n- Number of **positive sentiments** in **train data + test data** should be equal to the **total number positive sentiments** in entire dataset,\n- Likewise, Number of **neagetive sentiments** in **train data + test data** should be equal to the **total number negative sentiments** in entire dataset.","0e8e5ba8":"We will use **Logistic Regression** classifier here. So, let's train this guy!","1091e941":"Now, as we all know, we cannot feed the data to a classifier as it is. We should first convert these data into a numerical form known as vectors.\n\nHere, we will use **TF-IDF** (**T**erm **F**requency\u2013**I**nverse **D**ocument **F**requency), a numerical statistic that reflects how important a word is to a document in a collection or corpus by assigning some weight to it.","0ac91957":"Let's see what's inside the *data*!","9b7a798a":"**Perfect**, Classifier also says the same!","e1b5b7a0":"Here, Label $0.0$ means **negative** sentiment, while $1.0$ means **positive** sentiment.\n\nNow, let's check if our dataset contains any null values, if yes, drop those rows!","bc48c1c8":"# Import and prepare dataset","5ef00555":"# Cohen-Kappa score","f012547f":"# Import necessary modules","ee7b3375":"Now it looks good!\n\nNext step, **split** the dataset in **train-test**!","4895b98c":"**Cohen\u2019s kappa** statistic measures **interrater reliability** which is more robust than a simple percent agreement calculation.\n\nIn simple words, it will show us a level of agreement between the labels predicted by the classifier and the actual labels.","b376b51b":"Of course, we will also do some **cross-validation**!","9f7ccfb4":"Everything seems right! Let's proceed further!","0c5935e5":"Since our dataset contains in total $49078$ reviews, generating vectors will take a lot of time. Doing so every time will be a time-consuming task.\n\nTherefore, once we generate vectors in the first run, we can\u00a0_store_\u00a0the **vocabulary** in a separate file. We can then use this saved vocabulary to **fit** our **train** and **test data** in future runs (*of this program, of course!*).\n\nThe following method will **initialize vectorizer** based on the chosen option.","2516dfb4":"# A little about number of sentiments!","da727332":"# It's time for a tiny test!","43755982":"**Note:** The dataset used here is obtained from initial preprocessing on the [original dataset](http:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/).","c5096db3":"The classifier is trained, so let's check its performance on the **validation set**."}}