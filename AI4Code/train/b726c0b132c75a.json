{"cell_type":{"dd656173":"code","613407cd":"code","138a515c":"code","ecb46711":"code","180436a0":"code","85d23445":"code","7d102585":"code","759c0c7b":"code","25d6d9a6":"code","9ad7a3da":"code","6690d679":"code","754627e3":"code","9ac99541":"code","5b7b730e":"code","bfb7ec97":"code","b1bdc29f":"code","2cde3932":"code","9e7f7c35":"code","0517baa0":"code","c5a979e5":"code","231c2814":"code","866c842e":"code","1281db12":"code","9b4ecfd9":"code","9b25463b":"markdown","272bf369":"markdown","3644beed":"markdown","551d8389":"markdown","1595e1ea":"markdown","46a89ef7":"markdown","0eb7a4e5":"markdown"},"source":{"dd656173":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport lightgbm as lgb\nimport os\nimport re\nimport gc\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm.notebook import tqdm\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# DataFrame \u8868\u793a\u5217\u6570\u306e\u4e0a\u9650\u5909\u66f4\npd.set_option('display.max_columns', 100)\n\n# Kaggle \u74b0\u5883\u304b\u5426\u304b\u3092\u53d6\u5f97\nis_local_env = 'KAGGLE_URL_BASE' not in os.environ.keys()\n\n# \u30b3\u30a2\u6570\u53d6\u5f97\nif is_local_env:\n    CORE_NUM = os.environ['NUMBER_OF_PROCESSORS']\nelse:\n    CORE_NUM = 1","613407cd":"df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, parse_dates=['issue_d', 'earliest_cr_line']) # skiprows=lambda x: x%20!=0\ndf_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, parse_dates=['issue_d', 'earliest_cr_line'])","138a515c":"# issue_d \u304b\u3089\u5e74\u6708\u60c5\u5831\u3092\u8ffd\u52a0\ndf_train['year'] = df_train.issue_d.dt.year\ndf_train['month'] = df_train.issue_d.dt.month\ndf_test['year'] = df_test.issue_d.dt.year\ndf_test['month'] = df_test.issue_d.dt.month","ecb46711":"# earliest_cr_line \u304b\u3089\u5e74\u60c5\u5831\u3092\u8ffd\u52a0\ndf_train['ecl_year'] = df_train.earliest_cr_line.dt.year\ndf_test['ecl_year'] = df_test.earliest_cr_line.dt.year","180436a0":"# \u30b5\u30d6\u30c6\u30fc\u30d6\u30eb\u306e\u30de\u30fc\u30b8 - spi.csv\ndf_spi = pd.read_csv('..\/input\/homework-for-students2\/spi.csv', parse_dates=['date'])\ndf_spi['year'] = df_spi.date.dt.year\ndf_spi['month'] = df_spi.date.dt.month\n\ndf_temp = df_spi.groupby(['year', 'month'], as_index=False)['close'].mean() # \u5e74\u6708\u3067 GroupBy \u5e73\u5747\ndf_train = df_train.merge(df_temp, on=['year', 'month'], how='left')\ndf_test = df_test.merge(df_temp, on=['year', 'month'], how='left')","85d23445":"fillna_param = {\n#    'annual_inc' : 0,\n#    'collections_12_mths_ex_med' : 0,\n#    'acc_now_delinq' : 0,\n#    'tot_coll_amt' : 0,\n#    'tot_cur_bal' : 0,\n#    'delinq_2yrs' : 0,\n#    'open_acc' : 0,\n#    'revol_bal' : 0,\n#    'revol_util' : 0,\n#    'pub_rec' : 0,\n#    'inq_last_6mths' : 0,\n    'mths_since_last_delinq' : 9999,\n    'mths_since_last_record' : 9999,\n    'mths_since_last_major_derog' : 9999,\n    'emp_title': '#',\n    'title': '#',\n}","7d102585":"# \u4e0a\u8a18\u5b9a\u7fa9\u306b\u6cbf\u3063\u305f NaN \u57cb\u3081\ndf_train = df_train.fillna(fillna_param)\ndf_test = df_test.fillna(fillna_param)\n\n# \u6b20\u640d\u5024\u306e\u88dc\u5b8c - \u7a7a\u767d\u3092\u4e2d\u592e\u5024\u3067\u57cb\u3081\u308b\n# mean_cols = ['dti', 'revol_util', 'total_acc', 'ecl_year']\n\n# for col in mean_cols:\n#     median = df_train[col].median()\n#     df_train[col] = [median if str(x) == 'nan' else x for x in df_train[col]]\n#     df_test[col] = [median if str(x) == 'nan' else x for x in df_test[col]]\n\n# \u5b9a\u7fa9\u306b\u306a\u3044\u3082\u306e\u306f\u9069\u5f53\u306b\u57cb\u3081\u308b\ndf_train = df_train.fillna(-9999)\ndf_test = df_test.fillna(-9999)","759c0c7b":"ratio_cols = ['grade', 'sub_grade', 'purpose', 'addr_state']\n\n# \u7b97\u51fa\u306f\u5b66\u7fd2\u30c7\u30fc\u30bf\u3067\u884c\u3044\u3001\u540c\u3058\u5024\u3092\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u3082\u9069\u5fdc\u3055\u305b\u308b\nfor col in ratio_cols:\n    all_cnt = df_train[col].value_counts()\n    true_cnt = df_train.query('loan_condition == 1')[col].value_counts()\n    ratio_values = true_cnt \/ all_cnt\n    ratio_values = ratio_values.fillna(0)\n    df_train['ratio_' + col] = df_train[col].map(ratio_values)\n    df_test['ratio_' + col] = df_test[col].map(ratio_values)","25d6d9a6":"# \u7279\u5fb4\u91cf\u8ffd\u52a0 : xxx \/ yyy --> \u5404\u5024\u306e\u6bd4\u7387\u306e\u7279\u5fb4\u91cf\nvalue_cols = [\n    'loan_amnt',\n    'dti',\n    'annual_inc',\n    'revol_bal',\n    'revol_util',\n    'open_acc',\n    'close',\n    'tot_cur_bal',\n    'installment'\n]\n\nfor x_col in value_cols:\n    for y_col in value_cols:\n        if x_col == y_col:\n            continue\n        df_train[x_col + '*' + y_col] = df_train[x_col] * df_train[y_col]\n        df_train[x_col + '\/' + y_col] = df_train[x_col] \/ df_train[y_col]\n        df_test[x_col + '*' + y_col] = df_test[x_col] * df_test[y_col]\n        df_test[x_col + '\/' + y_col] = df_test[x_col] \/ df_test[y_col]","9ad7a3da":"X_train = df_train.drop(['loan_condition'], axis=1)\ny_train = df_train['loan_condition']\nX_test = df_test","6690d679":"# grade, sub_grade \u306f\u9806\u5e8f\u306b\u610f\u5473\u3092\u6301\u305f\u305b\u308b\u305f\u3081\u30bb\u30eb\u30d5\u30a8\u30f3\u30b3\u30fc\u30c9\n# grade_cols = ['grade', 'sub_grade']\ngrade_cols = ['sub_grade']\n\ndef set_grade_value(grade):\n    if grade == 'A':\n        return 1\n    if grade == 'B':\n        return 2\n    if grade == 'C':\n        return 3\n    if grade == 'D':\n        return 4\n    if grade == 'E':\n        return 5\n    if grade == 'F':\n        return 6\n    if grade == 'G':\n        return 7\n    \nfor col in grade_cols:\n    unique = pd.unique(X_train[col])\n    unique.sort()\n    \n    items = []\n    indicies = []\n    for i, item in enumerate(unique):\n        items.append(item)\n        grade_val = set_grade_value(item[0])\n        rank_val = float(item[1]) \/ 10\n        indicies.append(grade_val + rank_val)\n\n    grade_vals = pd.Series(indicies, index=items)\n    X_train[col] = X_train[col].map(grade_vals)\n    X_test[col] = X_test[col].map(grade_vals)","754627e3":"# sub_grade \u3067\u91cd\u307f\u3065\u3051\u3055\u308c\u305f or \u7279\u5fb4\u91cf\u3092\u8ffd\u52a0\u3059\u308b\ng_weight_cols = [\n    'loan_amnt',\n    'dti',\n    'annual_inc',\n    'revol_bal',\n    'revol_util',\n    'open_acc',\n    'close',\n    'tot_cur_bal',\n    'installment'\n]\n\n# for col in g_weight_cols:\n#     X_train[col + '*sub_grade'] = X_train[col] * X_train['sub_grade']\n#     X_test[col + '*sub_grade'] = X_test[col] * X_test['sub_grade']","9ac99541":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n\n# \u3042\u3068\u3067\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u3059\u308b\u306e\u3067\u9664\u5916\ncats.remove('emp_title')\ncats.remove('title')\n\noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","5b7b730e":"X_train","bfb7ec97":"# \u3053\u306e\u3042\u305f\u308a\u304b\u3089\u30e1\u30e2\u30ea\u3092\u903c\u8feb\u3057\u3066\u304f\u308b\u306e\u3067 GC\ndel df_train, df_test\ngc.collect()","b1bdc29f":"%%time\ntxt_cols = ['emp_title', 'title']\n\nfor txt in txt_cols:\n    tfidf = TfidfVectorizer(max_features=128, analyzer='word', ngram_range=(1, 2))\n    txt_train = tfidf.fit_transform(X_train[txt])\n    txt_test = tfidf.transform(X_test[txt])\n\n    txt_train.todense()\n    txt_test.todense()\n    df_TXT_train = pd.DataFrame(txt_train.toarray(), columns=['txt_' + txt + '_' + name for name in tfidf.get_feature_names()])\n    df_TXT_test = pd.DataFrame(txt_test.toarray(), columns=['txt_' + txt + '_' + name for name in tfidf.get_feature_names()])\n\n    X_train = pd.concat([X_train, df_TXT_train], axis=1)\n    X_test = pd.concat([X_test, df_TXT_test], axis=1)    ","2cde3932":"# del_cols = ['issue_d', 'title', 'earliest_cr_line', 'emp_title', 'year', 'month', 'City']\ndel_cols = ['grade','issue_d', 'title', 'earliest_cr_line', 'emp_title', 'year']\n\nfor col in del_cols:\n    X_train.drop([col], axis=1, inplace=True)\n    X_test.drop([col], axis=1, inplace=True)","9e7f7c35":"display(X_train)\ndisplay(X_test)","0517baa0":"del txt_train, txt_test, df_TXT_train, df_TXT_test\ngc.collect()","c5a979e5":"# \u4ea4\u5dee\u691c\u5b9a\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\u3002\u5c64\u5316\u62bd\u51fa\u3067\u826f\u3044\u304b\u306f\u5225\u9014\u3088\u304f\u691c\u8a0e\u3002\nif is_local_env:\n    scores = []\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n    for i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n        # clf = GradientBoostingClassifier()\n        clf = lgb.LGBMClassifier(n_jobs=CORE_NUM)\n        \n        clf.fit(X_train_, y_train_)\n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n\n        print('CV Score of Fold_%d is %f' % (i, score))\n\n    print('Mean : ', np.mean(scores))","231c2814":"# CV Averaging \u5b9f\u884c\nSPLIT_NUM = 5\ndf_cv_avg = pd.DataFrame() # Average \u8a08\u7b97\u7528 DataFrame\n\nskf = StratifiedKFold(n_splits=SPLIT_NUM, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n    # clf = GradientBoostingClassifier()\n    clf = lgb.LGBMClassifier(n_jobs=CORE_NUM)\n        \n    clf.fit(X_train_, y_train_)\n    # y_pred = clf.predict_proba(X_val)[:,1]\n    y_pred = clf.predict_proba(X_test)[:,1]\n    series = pd.Series(y_pred, name='rslt_' + str(i))\n    df_cv_avg = pd.concat([df_cv_avg, series], axis=1)\n    print('CV Score of Fold_%d is completed.' % (i))\n \n    del X_train_, y_train_, X_val, y_val\n    gc.collect()\n\ndf_cv_avg['rslt_avg'] = df_cv_avg.mean(axis=1)\ndisplay(df_cv_avg)","866c842e":"# \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3001test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\n# clf = lgb.LGBMClassifier(n_jobs=CORE_NUM)\n# clf.fit(X_train, y_train)\n# y_pred = clf.predict_proba(X_test)[:,1]","1281db12":"imp = pd.DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance'])\nsorted = imp.sort_values('importance', ascending=False)\ndisplay(sorted)\n\nsorted.to_csv('feature_importance.csv')","9b4ecfd9":"submission = pd.read_csv('..\/input\/homework-for-students2\/sample_submission.csv', index_col=0)\n\ndf_cv_avg.set_index(submission.index, inplace=True)\nsubmission.loan_condition = df_cv_avg['rslt_avg']\nsubmission.to_csv('submission.csv')\nsubmission","9b25463b":"### \u4e0d\u8981\u306a\u7279\u5fb4\u91cf\u306e\u524a\u9664","272bf369":"### \u30ab\u30c6\u30b4\u30ea \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","3644beed":"### \u30c6\u30ad\u30b9\u30c8\u51e6\u7406","551d8389":"### \u7279\u5fb4\u91cf\u30bb\u30c3\u30c8\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u5206\u5272\u3059\u308b\uff08\u4ee5\u964d\u3001\u5909\u66f4\u5bfe\u8c61\u306f X_train)","1595e1ea":"### \u7279\u5fb4\u91cf\u306e\u8ffd\u52a0","46a89ef7":"### \u6b20\u640d\u5024\u306e\u88dc\u5b8c","0eb7a4e5":"### \u5b66\u7fd2\u30fb\u691c\u5b9a"}}