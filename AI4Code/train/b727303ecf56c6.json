{"cell_type":{"306a0f8a":"code","8bceeee1":"code","ecc5ccb5":"code","ebbb01fa":"code","b7205261":"code","2d861824":"code","06853849":"code","9c028d25":"code","a69ceed9":"code","c4280534":"code","74a1aadf":"code","7b4d5b99":"code","9792ea01":"code","18a51b00":"code","f8fdbcae":"code","1d25f783":"code","aad8bc98":"code","6b07bbf5":"code","60fbaa4f":"code","d3fe2c88":"code","37b5403c":"code","2e227b61":"code","7ae41af4":"code","cab6cc80":"code","f71c3ea2":"code","b858bca4":"code","d465118c":"markdown","a16464a7":"markdown","8c96e710":"markdown","c7a15074":"markdown","9d0eb123":"markdown","68953fe0":"markdown","1407bb62":"markdown","27435c55":"markdown","d87df603":"markdown","d393ca42":"markdown","36ed859d":"markdown","7f8a37e4":"markdown","3bc62516":"markdown","2efe9171":"markdown"},"source":{"306a0f8a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","8bceeee1":"spams=pd.read_table(\"..\/input\/SMSSpamCollection.txt\")\nspams.head(5)","ecc5ccb5":"print(type(spams))","ebbb01fa":"spams.shape","b7205261":"print(\"list of columns: \",spams.columns,\"\\n\")\nprint(\"Type of columns:\\n \",spams.dtypes,\"\\n\")\nprint(\"Description : \\n\" ,spams.describe())","2d861824":"pd.crosstab(index=spams[\"classe\"],columns=\"count\")","06853849":"from sklearn.model_selection import train_test_split\nspamsTrain,spamsTest=train_test_split(spams,train_size=3572,random_state=1,stratify=spams['classe'])","9c028d25":"#Import the countVectorizer tool\nfrom sklearn.feature_extraction.text import CountVectorizer \n#instantiation of the object - binary weighting\nparseur=CountVectorizer(binary=True)\n#Create the document term matrix\nXTrain=parseur.fit_transform(spamsTrain['message'])\nprint(\"number of tokens : \" ,len(parseur.get_feature_names()))\nprint(\"list of tokens : \" ,parseur.get_feature_names())","a69ceed9":"#Transform the spam matrix into numpy matrix\nmdtTrain=XTrain.toarray()\nprint(type(mdtTrain))\nprint(\"size of matrix : \",mdtTrain.shape)","c4280534":"#Frequency of terms\nfreq_mots=np.sum(mdtTrain,axis=0)\nprint(freq_mots)","74a1aadf":"index = np.argsort(freq_mots)\nprint(index)\n","7b4d5b99":"#print the terms and their frequency\nimp={'terme':np.asarray(parseur.get_feature_names())[index],'freq':freq_mots[index]}\nprint(pd.DataFrame(imp))","9792ea01":"#import the class LogistiRegression\nfrom sklearn.linear_model import LogisticRegression\n#instatiate the object\nlr=LogisticRegression()\n#perform the training process\nlr.fit(mdtTrain,spamsTrain[\"classe\"])","18a51b00":"#size of coefficients matrix \nprint(lr.coef_.shape)\n#intercept of the model \nprint(lr.intercept_)","f8fdbcae":"#create the document term matrix \nmdtTest = parseur.transform(spamsTest['message'])\n#size of the matrix \nprint(mdtTest.shape)","1d25f783":"predTest = lr.predict(mdtTest) \npredTest","aad8bc98":"#recall\nprint(metrics.recall_score(spamsTest['classe'],predTest,pos_label='spam'))","6b07bbf5":"#precision\nprint(metrics.precision_score(spamsTest['classe'],predTest,pos_label='spam'))\n","60fbaa4f":"#F1-Score\nprint(metrics.f1_score(spamsTest['classe'],predTest,pos_label='spam'))","d3fe2c88":"#accuracy rate\nprint(metrics.accuracy_score(spamsTest['classe'],predTest))","37b5403c":"#rebuild the parser with new options : stop_words='english' and min_df = 10\nparseurBis=CountVectorizer(stop_words='english',binary=True,min_df=10)\nXTrainBis=parseurBis.fit_transform(spamsTrain['message'])\n#number of tokens\nprint('number of tokens : ',len(parseurBis.get_feature_names()))\n#document term matrix\nmdtTrainBis = XTrainBis.toarray()\n","2e227b61":"#instatiate the object\nmodelBis= LogisticRegression()\n#perform the training process\nmodelBis.fit(mdtTrainBis,spamsTrain['classe'])\n#create the document term matrix for the test set\nmdtTestBis=parseurBis.transform(spamsTest['message'])\n#predection fot the test set\npredTestBis=modelBis.predict(mdtTestBis)","7ae41af4":"#recall \nprint(metrics.recall_score(spamsTest['classe'],predTestBis,pos_label='spam')) ","cab6cc80":"#precision \nprint(metrics.precision_score(spamsTest['classe'],predTestBis,pos_label='spam'))","f71c3ea2":"#F1-Score \nprint(metrics.f1_score(spamsTest['classe'],predTestBis,pos_label='spam'))","b858bca4":"#accuracy rate \nprint(metrics.accuracy_score(spamsTest['classe'],predTestBis)) ","d465118c":"**Decription of Data**","a16464a7":"**Size of the dataset**","8c96e710":"**Subdivision into train and test sets**","c7a15074":"**Construction of document-term matrix**","9d0eb123":"\nThe term '' to '' appears in 1091 documents, '' you '' in 1042, and so on.","68953fe0":"**CONCLUSION**","1407bb62":"**Dimensionality reduction**","27435c55":"**EVALUATION**","d87df603":"With more than 12 times less terms (541 terms against 6789 to be precise), we obtain equivalent performances\n\nWe have a simpler model while preserving the quality of the prediction","d393ca42":"**MODELING WITH LOGISTIC REGRESSION**","36ed859d":"**Frequency distrubition of the class attribute**","7f8a37e4":"**EVALUATION**","3bc62516":"**Type of the object**","2efe9171":"**Imortation of the Corpus**"}}