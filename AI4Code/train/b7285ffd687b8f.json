{"cell_type":{"bccb02ac":"code","58397084":"code","117c12cc":"code","6d1fc9bd":"code","0ac7d07a":"code","94a0076c":"code","b062401d":"code","77e0ae4c":"code","9cb26132":"code","a8314322":"code","625a0628":"code","342f423a":"code","e7f691a2":"code","5369d373":"code","2e8c0af4":"code","19d283a2":"code","0436d40b":"markdown","1d4d7a39":"markdown","ab19348d":"markdown","3f313b37":"markdown","d4fdb276":"markdown","8ff4c4da":"markdown","98b8b836":"markdown","f0d5e196":"markdown","35a0cf4e":"markdown","a6217113":"markdown","5640cb95":"markdown","365fa5bb":"markdown","d0c73cd0":"markdown","0229d935":"markdown"},"source":{"bccb02ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58397084":"!pip3 install pycaret","117c12cc":"import pandas as pd\nfrom pycaret import classification","6d1fc9bd":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","0ac7d07a":"classification_setup = classification.setup(data=train,target='Survived')","94a0076c":"classification.compare_models()","b062401d":"# Create Xgboost model\nclassification_xgb = classification.create_model('xgboost')","77e0ae4c":"# Tune the model\ntune_xgb = classification.tune_model('xgboost')","9cb26132":"# build the lightgbm model\nclassification_lightgbm = classification.create_model('lightgbm')","a8314322":"# Tune lightgbm model\ntune_lightgbm = classification.tune_model('lightgbm')","625a0628":"# Residual Plot\nclassification.plot_model(tune_lightgbm)","342f423a":"# Error Plot\nclassification.plot_model(tune_lightgbm, plot = 'error')","e7f691a2":"# Feature Important plot\nclassification.plot_model(tune_lightgbm, plot='feature')","5369d373":"# Evaluate model\nclassification.evaluate_model(tune_lightgbm)","2e8c0af4":"# read the test data\ntest_data_classification = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n# make predictions\npredictions = classification.predict_model(tune_xgb, data=test_data_classification)\n# view the predictions\npredictions","19d283a2":"# read the test data\ntest_data_classification = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n# make predictions\npredictions = classification.predict_model(tune_lightgbm, data=test_data_classification)\n# view the predictions\npredictions","0436d40b":"# Getting the Data","1d4d7a39":"# 2 .Make Predictions - lightgbm","ab19348d":"# Plot Model","3f313b37":"*The output prints a score grid that shows average Accuracy, AUC, Recall, Precision, F1, Kappa accross the folds (10 by default) of all the available models in the model library.*","d4fdb276":"Special Thanks to : **Moez Ali** - Data Scientist, Founder & Author of PyCaret & **Analytics Vidhya**\n\n[https:\/\/towardsdatascience.com\/announcing-pycaret-an-open-source-low-code-machine-learning-library-in-python-4a1f1aad8d46](http:\/\/)\n\n[https:\/\/www.analyticsvidhya.com\/blog\/2020\/05\/pycaret-machine-learning-model-seconds\/?utm_source=feed&utm_medium=feed-articles&utm_campaign=feed](http:\/\/)","8ff4c4da":"*Obeserve the difference when the model is run with default parameters and after fine tuning them*","98b8b836":"*Once the setup has been succesfully executed it prints the information grid which contains several important pieces of information. Most of the information is related to the pre-processing pipeline which is constructed when setup() is executed.*","f0d5e196":"# Pip install PyCaret","35a0cf4e":"# Compare Model","a6217113":"# 1. Make Predictions - Xgboost","5640cb95":"# Setting up Environment","365fa5bb":"**Note** : *Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using kfold cross validation for metric evaluation.* ","d0c73cd0":"# Thanks for reading.If you like it Kindly Upvote","0229d935":"# Loading the Required Packages"}}