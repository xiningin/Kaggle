{"cell_type":{"be05b6ad":"code","9ee93eb1":"code","9d86cbc8":"code","a61188c4":"code","ef2faacb":"code","4453b146":"code","a4663484":"code","55a0bc99":"code","9be004f9":"code","2c46b5c8":"code","09ef7994":"code","e52606a2":"code","9cde7381":"code","faa3e2f9":"code","d00338fa":"code","f0e9187b":"code","c261e9ed":"code","903c4fa0":"code","70668235":"markdown"},"source":{"be05b6ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ee93eb1":"\n\n# Import required librarues\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import RobustScaler\n\n# Import svm, multilinear regression, decision tree and xgboost\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.metrics import accuracy_score\n\n","9d86cbc8":"train = pd.read_csv(\"\/kaggle\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/learn-together\/test.csv\")","a61188c4":"# get target\ny = train['Cover_Type']\n\n# get features (TODO feature extraction)\nX = train.drop(['Cover_Type'],axis=1)\ntest_X = test\n\n\n\n# split data into training and validation data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.0001, random_state=42)\n\ntrain_X = train_X.drop(['Id'], axis = 1)\nval_X = val_X.drop(['Id'], axis = 1)\ntest_X = test_X.drop(['Id'], axis = 1)","ef2faacb":"train_X.describe()","4453b146":"val_X.describe()","a4663484":"test_X.describe()","55a0bc99":"scaler_train = RobustScaler(quantile_range = (25, 75))\ntrain_X = pd.DataFrame(scaler_train.fit_transform(train_X), index = train_X.index, columns = train_X.columns)\ntrain_X.describe()","9be004f9":"scaler_val = RobustScaler(quantile_range = (25, 75))\nval_X = pd.DataFrame(scaler_train.fit_transform(val_X), index = val_X.index, columns = val_X.columns)\nval_X.describe()","2c46b5c8":"scaler_test = RobustScaler(quantile_range = (25, 75))\ntest_X = pd.DataFrame(scaler_train.fit_transform(test_X), index = test_X.index, columns = test_X.columns)\ntest_X.describe()","09ef7994":"len(train_X.columns), len(val_X.columns), len(val_X.columns)","e52606a2":"len(train_X.index), len(val_X.index), len(test_X.index)","9cde7381":"### define the classifiers\n\n\nclassifier_rf = RandomForestClassifier(n_estimators = 400, min_samples_split = 2,\n                                           min_samples_leaf = 1, max_features = 'sqrt',\n                                           bootstrap = False, random_state=42)\nclassifier_xgb = OneVsRestClassifier(XGBClassifier(n_estimators=50, random_state=42))\n\n\n\n\neclf = EnsembleVoteClassifier(clfs=[classifier_rf,\n                                    classifier_xgb],\n                              weights=[1, 1])","faa3e2f9":"\nclassifier_sbs_en = eclf\nseqbacksel_rf = SFS(classifier_rf, k_features = (25, 30),\n                    forward = False, floating = False,\n                    scoring = 'accuracy', cv = 5, \n                    n_jobs = -1)\nseqbacksel_rf = seqbacksel_rf.fit(train_X, train_y.values.ravel())\n\n\nprint('best combination (ACC: %.3f): %s\\n' % (seqbacksel_rf.k_score_, seqbacksel_rf.k_feature_idx_))\nprint('all subsets:\\n', seqbacksel_rf.subsets_)\nplot_sfs(seqbacksel_rf.get_metric_dict(), kind='std_err');","d00338fa":"train_X_sbs = seqbacksel_rf.transform(train_X)\ntest_X_sbs = seqbacksel_rf.transform(test_X)","f0e9187b":"classifier_rf.fit(train_X_sbs, train_y.values.ravel())","c261e9ed":"test_ids = test[\"Id\"]\ntest_pred = classifier_rf.predict(test_X_sbs)\ntest_pred","903c4fa0":"# Save test predictions to file\noutput = pd.DataFrame({'Id': test_ids,\n                       'Cover_Type': test_pred})\noutput.to_csv('submission.csv', index=False)","70668235":"### Feature Selection using Sequential Backward Selection"}}