{"cell_type":{"e0737933":"code","8d40723e":"code","ba6dbcaa":"code","a71bb32c":"code","7069bca4":"code","1edceddd":"code","0f712c51":"code","4252245a":"code","932b477f":"code","3c80e7ac":"code","dc5324a7":"code","b0e86528":"code","ddec5e58":"code","e71572f3":"code","0f138d2e":"code","97066fc9":"code","10ada266":"code","3c631b45":"code","fecf17df":"code","8b4bcbe4":"code","6640b489":"code","5dc0af5e":"code","953bf1bd":"code","7d133145":"code","eb01d270":"code","e27fc158":"code","f0843c6d":"code","0c662a1e":"code","b6456385":"code","e12153a1":"code","5df789ca":"code","86d97cf0":"code","113a4c32":"code","e630a1c9":"code","19f97c82":"code","2f62db77":"code","1ad37fcc":"code","24447726":"code","f0886fdf":"code","ca53205e":"code","62d7b4ac":"code","f7369335":"code","0c56a75c":"code","2eac91de":"code","2d0beaf2":"code","9c5edd6f":"code","9cc843ae":"code","8841cb64":"code","891bc10b":"code","f654edbd":"code","1098a757":"code","d44cece7":"code","bb83a25a":"code","09725b87":"markdown","d4551153":"markdown","5028994b":"markdown","cd475a9b":"markdown","5fdbb7a4":"markdown","5d28e720":"markdown","7ec00811":"markdown","ded86c31":"markdown","2fcd2c6f":"markdown","afc89163":"markdown","997418d6":"markdown","b9c3187d":"markdown","06970273":"markdown","392918d3":"markdown","1fa5db2d":"markdown","90c91135":"markdown","abaf631f":"markdown","ca3c9553":"markdown","33a75205":"markdown","68d611a4":"markdown","5740261c":"markdown","e1649f19":"markdown","269e1e30":"markdown","de2ab186":"markdown","8c101032":"markdown","35026e06":"markdown","f8e7d452":"markdown","a0324d8b":"markdown","cd145c11":"markdown","6874beb6":"markdown","251695bd":"markdown","f6467c0a":"markdown","add954ec":"markdown","145115f7":"markdown","5cac7d8e":"markdown","94a20c0f":"markdown","81037501":"markdown","288fda05":"markdown","3c8ce4fd":"markdown","d73a3989":"markdown","d9f7a3a9":"markdown","dd8a39d2":"markdown","4e034e46":"markdown","00ec80f9":"markdown","d81ac195":"markdown","dc2f99e3":"markdown","3bab8463":"markdown","f746cdad":"markdown","f8681c4f":"markdown","f4bb6bee":"markdown","67b51f9a":"markdown","8e849145":"markdown","00000ca3":"markdown","4ad0fb5c":"markdown","7b0bda0d":"markdown","d894267e":"markdown","f02d0ef5":"markdown","eeee3fae":"markdown","6aedba2a":"markdown","9bebf092":"markdown","8c9078c3":"markdown"},"source":{"e0737933":"!pip install chart_studio --quiet","8d40723e":"import pandas as pd\nimport os\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport chart_studio.plotly as py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport cufflinks as cf\nfrom sklearn.cluster import KMeans\nimport tensorflow_hub as hub\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\nfrom plotly.offline import iplot\npd.options.plotting.backend = \"plotly\"","ba6dbcaa":"HARDCODE_LAST_SPEAK_DURATION = 40\nBASE_PATH = \"..\/input\/chai-time-data-science\/\"\nBASE_CSV_PATH = \"..\/input\/generating-cleaner-sublititles-file\/\"\ndf_episodes = pd.read_csv(BASE_PATH+\"Episodes.csv\")","a71bb32c":"def merge_consecutive_data(df):\n    \"\"\"If same speaker content is in succession, merge it into a single row to make further analysis simpler\"\"\"\n    new_idx = 0\n    rows = []\n    for idx,row in df.iterrows():\n        if new_idx == 0:\n            prev_row = row\n            new_idx += 1\n            continue\n        if prev_row[\"Speaker\"] == row[\"Speaker\"]:\n            prev_row[\"Text\"] += row[\"Text\"]\n        else:\n            rows.append(prev_row)\n            prev_row = row\n            prev_row[\"relative_index\"] = new_idx\n            new_idx += 1\n        if idx == df.shape[0] - 1:\n            rows.append(prev_row)\n    df = pd.DataFrame(rows)\n    return df\n\ndef get_time(t):\n    \"\"\"hh:mm:ss to seconds. Since time isn't formatted nicely in cleaned data, using hacks\"\"\"\n    ts = t.split(\":\")\n    total = 0\n    for idx, data in enumerate(ts[::-1]):\n        total += int(data) * 60**idx\n    return total        \n\ndef calculate_speak_duration(df, df_episodes, episode_id):\n    \"\"\"Calculate speaker duration in seconds and also in time elapsed since 0\"\"\"\n    df = df.reset_index()\n    df[\"duration\"] = None\n    df[\"timestamp_relative\"] = None\n    prev_time = None\n    for idx, row in df.iterrows():\n        if idx == 0:\n            prev_time = get_time(row[\"Time\"])\n            df.loc[idx, \"timestamp_relative\"] = prev_time\n            continue\n        curr_time = get_time(row[\"Time\"])\n        df.loc[idx-1, \"duration\"] = curr_time - prev_time\n        prev_time = curr_time\n        df.loc[idx, \"timestamp_relative\"] = curr_time\n    # Hardcoding because for some of the cases subtracting from episode duration is producing too large numbers than practically expected\n#     df.loc[idx, \"duration\"] = df_episodes[df_episodes[\"episode_id\"] == episode_id][\"episode_duration\"].values[0] - prev_time\n    df.loc[idx, \"duration\"] = HARDCODE_LAST_SPEAK_DURATION\n    return df","7069bca4":"df = pd.DataFrame()\nfor f in os.listdir(BASE_PATH+\"Cleaned Subtitles\"):\n    if f == \"E69.csv\":\n        continue\n    df_e = pd.read_csv(BASE_PATH+'Cleaned Subtitles\/'+f)\n    \n    df_e[\"relative_index\"] = df_e.index\n    df_e[\"episode_id\"] = f.split(\".csv\")[0]\n    df_e = merge_consecutive_data(df_e)\n    df_e = calculate_speak_duration(df_e, df_episodes, f.split(\".csv\")[0])\n    df = df.append(df_e)\ndel df[\"index\"]","1edceddd":"\nprint(\"Shape of all data:\", df.shape)","0f712c51":"df.head(2)","4252245a":"def get_words_list(x):\n    \"\"\"For an input text, returns list of words used\"\"\"\n    x_list = x.replace(\".\", \" \").replace(\",\", \" \").lower().split()\n    return x_list\n\ndef get_num_words(x):\n    \"\"\"For an input text, returns number of words used\"\"\"\n    x_list = x.replace(\".\", \" \").replace(\",\", \" \").lower().split()\n    return len(x_list)\n\ndef get_num_sentences(x):\n    \"\"\"For an input text, gets number of sentences\"\"\"\n    num_sentences = len(x.split(\".\"))\n    return num_sentences\n\ndef get_avg_sentence_len(x):\n    \"\"\"For an input text containing multiple sentences, returns the average length of sentences used\"\"\"\n    sentences = x.split(\".\")\n    sentences_splitted = [len(s.split(\" \")) for s in sentences]\n    return sum(sentences_splitted) \/ len(sentences_splitted)\n","932b477f":"def plot_single_episode_timeline(episode_id, df, df_episodes, max_tick=4000):\n    \"\"\"Plots a timeline for an individual episode\"\"\"\n    df_e = df[df[\"episode_id\"] == episode_id]\n    data = []\n    colors = []\n    for idx, row in df_e.iterrows():\n        color = \"tab:blue\"\n        if row[\"Speaker\"] == \"Sanyam Bhutani\":\n            color = \"tab:orange\"\n        data_tuple = (row[\"timestamp_relative\"], row[\"duration\"])\n        data.append(data_tuple)\n        colors.append(color)\n    fig, ax = plt.subplots(figsize=(20,3))\n    ax.broken_barh(data, (10, 9),\n                   facecolors=colors)\n    # ax.set_ylim(0, 1)\n#     ax.set_xlim(0, 200)\n    ax.set_xlabel('seconds since start')\n    ax.set_yticks([15])\n    ax.set_xticks(range(0, max_tick, 200))\n    ax.set_yticklabels(['Speaker'])\n    blue_patch = mpatches.Patch(color='tab:blue', label=df_episodes[df_episodes[\"episode_id\"] == episode_id][\"heroes\"].values[0])\n    orange_patch = mpatches.Patch(color='tab:orange', label=\"Sanyam Bhutani\")\n    ax.legend(handles=[orange_patch, blue_patch])\n    fig.suptitle(df_episodes[df_episodes[\"episode_id\"] == episode_id][\"episode_name\"].values[0], fontsize=14)\n    plt.show()","3c80e7ac":"df[\"words_used\"] = df[\"Text\"].apply(get_words_list)\ndf[\"num_words\"] = df[\"Text\"].apply(get_num_words)\ndf[\"num_sentences\"] = df[\"Text\"].apply(get_num_sentences)\ndf[\"avg_sentence_len\"] = df[\"Text\"].apply(get_avg_sentence_len)","dc5324a7":"df.to_csv(\"subtitles_aggregated.csv\", index=False)\ndf.head(2)\n","b0e86528":"df_temp = df.groupby([\"Speaker\", \"episode_id\"])[\"num_words\"].sum().reset_index().sort_values(by=\"num_words\", ascending=False)\ndf_temp[\"derived\"] = df_temp[\"Speaker\"] + \" - \"+ df_temp[\"episode_id\"]","ddec5e58":"\ndf_temp[\"num_words\"].hist()","e71572f3":"\npx.bar(x=\"derived\",y=\"num_words\",data_frame=df_temp[:10],title=\"10 speakers with highest Number of words spoken\", labels={\"derived\": \"Speaker\", \"num_words\": \"Number of words\"})","0f138d2e":"px.bar(x=\"derived\",y=\"num_words\",data_frame=df_temp[(df_temp[\"Speaker\"] != \"Unknown Speaker\") & (df_temp[\"Speaker\"] != \"Sanyam Bhutani\")][-10:],title=\"10 speakers with lowest Number of words spoken\", labels={\"derived\": \"Speaker\", \"num_words\": \"Number of words\"})","97066fc9":"df_temp2 = df.groupby([\"Speaker\", \"episode_id\"])[\"duration\"].sum().reset_index().sort_values(by=\"duration\", ascending=False)\ndf_temp2[\"duration\"] \/= 60\ndf_temp2[\"derived\"] = df_temp2[\"Speaker\"] + \" - \"+ df_temp2[\"episode_id\"]","10ada266":"df_temp2[\"duration\"].hist()","3c631b45":"px.bar(x=\"derived\",y=\"duration\",data_frame=df_temp2[:10],title=\"10 Speakers with highest speak duration\", labels={\"derived\": \"Speaker\", \"duration\": \"Speaker Duration(minutes)\"})","fecf17df":"plot_single_episode_timeline(\"E23\", df, df_episodes, max_tick=3600*2+1200)","8b4bcbe4":"df_temp3 = df_temp.merge(df_temp2, on=\"derived\")\ndf_temp3[\"wpm\"] = df_temp3[\"num_words\"] \/ df_temp3[\"duration\"]\ndf_temp3 = df_temp3.sort_values(\"wpm\", ascending=False)","6640b489":"df_temp3[\"wpm\"].hist()","5dc0af5e":"px.bar(x=\"derived\",y=\"wpm\",data_frame=df_temp3[(df_temp3[\"Speaker_x\"] != \"Sanyam Bhutani\") & (df_temp3[\"Speaker_x\"] != \"Unknown Speaker\")][:20],title=\"20 speakers with highest words per minute\", labels={\"derived\": \"Speaker\", \"wpm\": \"WPM(Words per minute)\"})","953bf1bd":"px.bar(x=\"derived\",y=\"wpm\",data_frame=df_temp3[(df_temp3[\"Speaker_x\"] != \"Sanyam Bhutani\") & (df_temp3[\"Speaker_x\"] != \"Unknown Speaker\")][-20:],title=\"20 speakers with lowest words per minute\", labels={\"derived\": \"Speaker\", \"wpm\": \"WPM(Words per minute)\"})","7d133145":"df_temp3.rename(columns={\"episode_id_x\": \"episode_id\"}, inplace=True)\ndf_temp4 = df_temp3.merge(df_episodes, on=\"episode_id\").sort_values(\"wpm\", ascending=False)\ndf_temp4[\"derived\"] = df_temp4[\"heroes\"] + \" - \"  + df_temp4[\"episode_id\"]","eb01d270":"fig = px.bar(x=\"derived\",y=\"wpm\",data_frame=df_temp4[df_temp4[\"Speaker_x\"] == \"Sanyam Bhutani\"][:10],title=\"10 highest wpm episodes of Host(Sanyam)\", labels={\"derived\": \"Episode\", \"wpm\": \"Sanyam's WPM(Words per minute)\"})\nfig.update_traces(marker_color='#ff7f0e')\nfig.show()","e27fc158":"fig = px.bar(x=\"derived\",y=\"wpm\",data_frame=df_temp4[df_temp4[\"Speaker_x\"] == \"Sanyam Bhutani\"][-10:],title=\"10 lowest wpm episodes of Host(Sanyam)\", labels={\"derived\": \"Episode\", \"wpm\": \"Sanyam's WPM(Words per minute)\"})\nfig.update_traces(marker_color='#ff7f0e')\nfig.show()","f0843c6d":"plot_single_episode_timeline(\"E49\", df, df_episodes, max_tick=3400)","0c662a1e":"plot_single_episode_timeline(\"E63\", df, df_episodes, max_tick=4200)","b6456385":"plot_single_episode_timeline(\"E36\", df, df_episodes, max_tick=4200)","e12153a1":"plot_single_episode_timeline(\"E35\", df, df_episodes, max_tick=4200)","5df789ca":"plot_single_episode_timeline(\"E1\", df, df_episodes, max_tick=4200)","86d97cf0":"plot_single_episode_timeline(\"E74\", df, df_episodes, max_tick=4200)","113a4c32":"df_temp5 = df.groupby([\"Speaker\", \"episode_id\"])[\"num_words\"].max().reset_index().sort_values(by=\"num_words\", ascending=False)\ndf_temp5[\"derived\"] = df_temp5[\"Speaker\"] + \" - \"+ df_temp5[\"episode_id\"]","e630a1c9":"px.bar(x=\"derived\",y=\"num_words\",data_frame=df_temp5[df_temp5[\"Speaker\"] != \"Sanyam Bhutani\"][:10],title=\"10 episodes containing longest monologue by guest speaker\", labels={\"derived\": \"Episode\", \"num_words\": \"Count of consecutive words spoken\"})","19f97c82":"plot_single_episode_timeline(\"E57\", df, df_episodes, max_tick=4200)","2f62db77":"rindex = df[(df[\"episode_id\"] == \"E57\")&(df[\"num_words\"] == 1682)][\"relative_index\"].values[0]\nprevious_text = df[(df[\"episode_id\"] == \"E57\")&(df[\"relative_index\"] == rindex-1)][\"Text\"].values[0]\ncurrent_text = df[(df[\"episode_id\"] == \"E57\")&(df[\"relative_index\"] == rindex)][\"Text\"].values[0]","1ad37fcc":"print(\"Sanyam's Question:\", previous_text)","24447726":"fig = px.bar(x=\"derived\",y=\"num_words\",data_frame=df_temp5[df_temp5[\"Speaker\"] == \"Sanyam Bhutani\"][:10],title=\"10 episodes containing longest monologue by host\", labels={\"derived\": \"Episode\", \"num_words\": \"Count of consecutive words spoken by host\"})\nfig.update_traces(marker_color='#ff7f0e')\nfig.show()","f0886fdf":"df[\"text_stripped\"] = df[\"Text\"].apply(lambda x: x.strip().replace(\".\", \"\").replace(\",\",\" \"))\ndf[(df[\"Speaker\"] == \"Sanyam Bhutani\") &(df[\"num_words\"] < 3)].groupby([\"text_stripped\"]).count().reset_index().sort_values(\"Text\", ascending=False)[[\"text_stripped\", \"Text\"]].rename(columns={\"text_stripped\": \"text\", \"Text\": \"Times used\"})[:15]","ca53205e":"embedder = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4\")","62d7b4ac":"df_episode_content = df.groupby(\"episode_id\")['Text'].apply(lambda x: ','.join(x)).reset_index()\ndf_episode_content[\"embedding\"] = None\nfor idx, row in df_episode_content.iterrows():\n    df_episode_content.loc[idx, \"embedding\"] = list(np.array(embedder([row[\"Text\"]])[0])) # Get embeddings per episode\n    \nkmeans = KMeans(n_clusters=8, random_state=0).fit(list(df_episode_content[\"embedding\"].values))\n\ndf_episode_content[\"cluster_id\"] = kmeans.labels_\n\ndf_temp7 = df_episode_content.merge(df_episodes, on=\"episode_id\")\ndf_temp7 = df_temp7[[\"episode_id\", \"episode_name\", \"cluster_id\"]]","f7369335":"df_temp7[df_temp7[\"cluster_id\"] == 7]","0c56a75c":"df_temp7[df_temp7[\"cluster_id\"] == 4]","2eac91de":"df_temp7[df_temp7[\"cluster_id\"] == 3]","2d0beaf2":"df_temp7[df_temp7[\"cluster_id\"] == 1]","9c5edd6f":"df2 = pd.read_csv(\"subtitles_aggregated.csv\")\ndf2[\"embedding\"] = None\nfor idx, row in df2.iterrows():\n    df2.at[idx, \"embedding\"] = list(np.array(embedder([row[\"Text\"]])[0]))\n    \ndf2[\"is_question\"] = df2[\"Text\"].apply(lambda x: \"?\" in x)\n\n# df_questions = df2[(df2[\"is_question\"] == True) & (df2[\"Speaker\"] == \"Sanyam Bhutani\")]\n# kmeans = KMeans(n_clusters=25, random_state=0).fit(list(df_questions[\"embedding\"].values))\n# df_questions[\"cluster_id\"] = kmeans.labels_\n# df_questions = df_questions.merge(df_episodes, on=\"episode_id\")\n# df_temp8 = df_questions[[\"episode_id\", \"episode_name\", \"cluster_id\", \"Text\", \"timestamp_relative\", \"relative_index\"]]\ndf_temp8 = pd.read_csv(\"..\/input\/ctds-kmeans-clustered\/ctds_kmeans_clustered_df.csv\") # Kmeans output cache","9cc843ae":"df_temp8[\"answer\"] = None\nfor idx, row in df_temp8.iterrows():\n    try:\n        df_temp8.at[idx, \"answer\"] = df2[(df2[\"episode_id\"] == row[\"episode_id\"]) & (df2[\"relative_index\"] == row[\"relative_index\"] + 1)][\"Text\"].values[0]    \n    except:\n        pass","8841cb64":"df_temp8[df_temp8[\"cluster_id\"] == 1][[\"episode_name\", \"Text\", \"answer\"]].sample(frac=1)[:3].style.set_properties(subset=['Text', \"episode_name\"], **{'width': '200px'})","891bc10b":"df_temp8[df_temp8[\"cluster_id\"] == 17][[\"episode_name\", \"Text\", \"answer\"]].sample(frac=1)[:3].style.set_properties(subset=['Text', \"episode_name\"], **{'width': '200px'})","f654edbd":"df_temp8[df_temp8[\"cluster_id\"] == 23][[\"episode_name\", \"Text\", \"answer\"]].sample(frac=1)[:3].style.set_properties(subset=['Text', \"episode_name\"], **{'width': '200px'})","1098a757":"from transformers import pipeline\nsummarizer = pipeline(\"summarization\")","d44cece7":"df_temp9 = df_temp8[df_temp8[\"cluster_id\"] == 17].copy()\nall_answers = \" \".join(df_temp9[df_temp9[\"cluster_id\"] == 17][\"answer\"].values)","bb83a25a":"df_temp9[\"summarized_answer\"] = None\nctr = 0\nquestions, answers, summaries = [], [], []\n\nfor idx, row in df_temp9.sample(frac=1).iterrows():\n    if len(row[\"answer\"]) < 200:\n        continue\n    print(\"*\"*10)\n    print(row[\"episode_name\"])\n    print(\"*\"*10)\n    print(\"Question:\")\n    print(row[\"Text\"])\n    questions.append(row[\"Text\"])\n    print(\"-\"*10)\n    print(\"Answer:\")\n    print(row[\"answer\"])\n    answers.append(row[\"answer\"])\n    print(\"-\"*10)\n    print(\"Summarized Answer:\")\n    summary = summarizer(row[\"answer\"], max_length=100, min_length=10, do_sample=False)[0][\"summary_text\"]\n    print(summary)\n    summaries.append(summary)\n    print(\"~\"*20)\n    if ctr == 0:\n        break\n    ctr+=1","09725b87":"### Who spoke for the longest duration (overall)?","d4551153":"### Anayzing speaker's WPM(words per minute)","5028994b":"That's it for now. Please let me know in comments if you spot any errors and have suggestions. The output from this kernel can directly be used in further analysis. \n\nPS: I couldn't find a good library for timeline chart. The closest was plotly's gantt chart, but I couldn't make it work on just the time data(without datetime). So if you have any recommendations to build a similar but interactive timeline chart quickly, please share. ","cd475a9b":"Since this is unsupervised clustering algorithm, there's no fixed rule on numbers of cluster and what the clusters actually mean, but I found `n_clusters=8` setting to generate a pretty decent grouping. Let's see a couple of them.\n\n**AutoCluster1: Huggingface, sklearn, spacy, albumentations, DALI augmentations..**","5fdbb7a4":"Let's see the timeline and inspect data for highest wpm episode E49 - Parul Pandey","5d28e720":"**AutoCluster3: Musenet, Audio, Remix, Deoldify..**","7ec00811":"Just a clarification here, GM Abhishek appeared on E1 of the podcast, and E36 occurence is most probably a typo rather than him putting out a cameo to just say `Okay`.\n![image.png](attachment:image.png)\nAnd some of the heroes appeared in podcasts where multiple speakers were present, which is the reason we see significant drop in number of words spoken.","ded86c31":"That's it. Just like a simple API with Universal Sentence Encoder, we can use `summarizer(data_to_summarize, max_length=X)` to generate abstractive summaries.\n\nLet's use the same cluster from above (where advice for beginners is asked). ","2fcd2c6f":"**ChristOf Henkel - Read.Read.Read. Try not to copy.**\n![image.png](attachment:image.png)","afc89163":"We've already established above(by plotting the timeline) that Dmitry data seems to be incorrect. Let's explore E57 a bit","997418d6":"#### Analyzing WPM for host(Sanyam)","b9c3187d":"###### Let's find what was Saynam talking about which invoked a long response from Mark.","06970273":"## 9. Abstractive Summarization by HuggingFace pipelines","392918d3":"Upon manual inspection, comparing subtitles with youtube videos, **host wasn't speaking for the duration of 1900-2400s, and the data isn't labelled correctly**. Some of the WPM boost seen here could be coming from Parul's section being mislabelled as Sanyam's section. (Just a guess, didn't verify it, too lazy to manually annotate!)","1fa5db2d":"Data doesn't look right for Dmitry Larko E74 as well. Sometimes visualizing through a simple timeline helps to indentify outliers, which then could be followed by deeper look at the data.","90c91135":"**Anokas - Keep doing it**\n![image.png](attachment:image.png)","abaf631f":"### Who spoke the most number of words in an epsiode? \n","ca3c9553":"## 4. Analyzing WPM(Words per minute)","33a75205":"##### Distribution of num_words","68d611a4":"### **Okay**.**Yeah**.**Hehehe**.**Makes sense**. :)","5740261c":"Following the same pattern, I've skipped our host from the monologue analysis.","e1649f19":"Let's visualize a few of the interesting clusters and have the Questions and Answers formatted in a single row. To avoid kernel load on UI, I am sampling just 5 rows per cluster.","269e1e30":"Columns are as follows:\n - `words_used`: Splitting `Text` column for easier analysis\n - `num_words`: Number of words in that particular row item\n - `num_sentences`: Number of sentences in a particular row item.(Using split and not using any model to get cleaner data)\n - `avg_sentence_len`: Average number of words in a sentence for that row item.\n \n","de2ab186":"**AutoCluster4: Kaggle..**","8c101032":"**AutoCluster3: Passions, Interests and how it all started..**","35026e06":"Let's now attempt to summarize all the good advice given by a lot of people and try to view summarizations and see if we can distill the info in a short paragraph.\n\nThere are two types of summaries which could be generated:\n    - Extractive: Most important sentences\/paragraphs\/phrases picked from a large content, thus shortening it\n    - Abstractive: The cooler one, where we use a pretrained model to generate the `gist` of the content.\n    \n","f8e7d452":"<div class=h3> Summary<\/div>\nIn this kernel,\n\n- I've attempted to generate some features out of the subtitle data available in csv format\n- aggregated the csvs together for an easier more database-like analysis\n- a bit of speaker related metrics exploration\n- attempted to identify bad data\n\nNLP analysis done is very primitive and not using any particular model or toolkit.\n\nLet's begin by importing the necessary data and helper functions. Some of the libaries imported are unused(WIP). ","a0324d8b":"## 7. Grouping similar episodes together","cd145c11":"## 3. Analyzing the duration a speaker spoke","6874beb6":"List of kernels I like and took inspiration from(and copied from):\n- [Analysing CTDS show- Views and Reach](https:\/\/www.kaggle.com\/kurianbenoy\/analysing-ctds-show-views-and-reach)\n- [Generating Data from the Chai](https:\/\/www.kaggle.com\/muellerzr\/generating-data-from-the-chai)\n\nThanks for hosting this dataset!","251695bd":"As we can see, even with embeddings generated for the entire transcript together, we are able to form pretty good clusters from it.","f6467c0a":"**AutoCluster1: Platforms to follow heroes**","add954ec":"Next steps: \n- Huggingface summarization","145115f7":"Now, we load all the csv from [this kernel's output](https:\/\/www.kaggle.com\/tomtillo\/generating-cleaner-sublititles-file). Original datasource can also be used for analysis. \nFor simplicity in defining visualizations and analysis, I am explicitly skipping E69 which is a host-only special episode.","5cac7d8e":"## 5. Longest monologue","94a20c0f":"## 1. Importing Libraries  and loading data","81037501":"## 6. Shortest response by host","288fda05":"## 2. Analyzing number of words spoken","3c8ce4fd":"There can be multiple approaches of grouping the episodes. I here would like to display a slightly unconventional approach, which is using sentence embeddings.\nLet's start by loading a pretrained [Universal Sentence Encoder](https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4) which is present in tensorflow_hub","d73a3989":"Using the same sentence encoder and powerful unsupervised Kmeans clustering over it's embeddings, let's now try to group similar questions view a couple of clusters. Another approach (and a more precise approach) would be to use the embeddings and calculate similarities and find closest ones. [Faiss](https:\/\/github.com\/facebookresearch\/faiss) is an excellent library by Facebook research which can take inputs as embeddings(taken from Google's sentence encoder here), and indexes it so that similarity searches can be performed neatly and efficiently.\n\nHowever for the current task at hand, we will stick to KMeans, as I'd like to demonstrate that this simple clustering algorithm is also able to come up with some gems. ","d9f7a3a9":"**AutoCluster2: Best advice from heroes**","dd8a39d2":"Let's get the count of 2-3 length sentences spoken by host as a response and print a few. Note that we're still operating at row level and viewing speaker exchange. This isn't the count of times host speaks a word, but a count of times a short response is given (or as a filler), to another speaker.","4e034e46":"This histogram is a graph shape(distribution) we're used to seeing. Phew!\n\n##### What is average words per minute rate of speaking English?\nFrom google, we can see that the average rate is:\n![image.png](attachment:image.png)\n\nSo apart from some outliers, the distribution of wpm correlates with universal known rate. This also indicates that there are less chances of bugs in calculation of words & duration :D \n\nLet's now see a few episodes where speakers had the highest WPM.\n\nSince the data is grouped by epsidoes, I am also going to filter and consider only non-host speakers and also remove data marked as `Unknown Speaker` in the dataset.","00ec80f9":"In order to get embeddings we simply need to call `embedder([para_or_sentence_to_embed])`. Let's merge all the episode's data in a single row per episode and perform `KMeans` clustering on the embeddings to group data into clusters.","d81ac195":"As we can see duration distribution is also long tailed, with most episodes where speakers spoke between 500-1000s. Note that this includes host as a speaker too.","dc2f99e3":"Also,since we note that the top-10 isn't the same when looking at words or duration, let's try to now visualize top10 at another angle - WPM(words per minute)","3bab8463":"I know for a fact that the host is biased towards fast.ai & kaggle. But could this be a reason for such a lively exchange with Robert Bracco as compared to others? Shouldn't comment without a deeper analysis of text and interactions.\n\nHowever, in a totally unrelated context, let's see another timeline.","f746cdad":"**AutoCluster2: Freelancing, ML Interview, SharpestMind..**","f8681c4f":"Columns are as follows:\n - `relative_index`: Preserving the index of individual dataframe(0-max) per episode\n - `timestamp_relative`: It's a conversion of `Time` column in seconds\n - `duration`: Duration for which a speaker spoke\n \n Let's add word and sentence level data to the dataframe.","f4bb6bee":"It looks like there's some labelling\/formatting issue in the data, causing such high numbers. Rest all max values in 500 range points to the introduction part.","67b51f9a":"From Episodes data, we know that **E23 (Andres Torrubia) lasted 2h10mins**. Let's visualize the timeline for the episode. ","8e849145":"##### Distribution of Speaker WPM","00000ca3":"**Robert Bracco - Consistency matters**\n![image.png](attachment:image.png)","4ad0fb5c":"Here are a couple of summaries generated, which I found to be very crisp and precise. Hope you enjoy reading them! ","7b0bda0d":"##### Distribution of duration","d894267e":"## 8. Grouping similar questions together","f02d0ef5":"Randomly print summary for a single question in the cluster.","eeee3fae":"We can see that the distribution is long-tailed, but most of the speakers are around 2000 words range. This is just distribution of total words spoken by speaker per episode and large numbers could also mean longer episodes. We will need to dig further before inferring anything from just a histogram.\n","6aedba2a":"Overall, it's apretty consistent WPM by host which is usually an indicator of a good podcast host. :) \nHowever I would still like to hear a possible explanation of WPM difference from **177** to **127** by the host in different episodes.\n\nLet's sidetrack a bit and visualize a couple more of timelines to get an intuitive sense of interviews and conversations. I am printing out couple which I found interesting.","9bebf092":"**And finally,advice from Co-founder@HuggingFace, the library which made the summarization pipeline so easy to use**\n![image.png](attachment:image.png)","8c9078c3":"#### Analyzing WPM for other speakers"}}