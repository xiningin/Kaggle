{"cell_type":{"207e70a6":"code","eeb23e18":"code","0c05d244":"code","dfdb3b17":"code","4c11bd53":"code","d7e10453":"code","929646c0":"code","e0eb93ec":"code","be61a66d":"code","33b83868":"code","2b8f28c6":"code","13b7fcbb":"code","eec5d905":"code","57888b08":"code","38e9069a":"code","4ae9eb0a":"code","6c46dda9":"code","0490b6d4":"code","f67aa5e5":"code","e8f8428b":"code","773e8f6b":"code","5ffc2717":"code","7813f485":"code","7710288e":"code","901e2c0b":"code","bb42b809":"code","506b0244":"code","63f9bf11":"code","ee2d4f3e":"code","7d0399c8":"code","4f90ed24":"code","ba38f12d":"code","7eefed43":"code","760f3478":"code","ba700a3a":"code","ce663139":"code","fbab73b6":"code","cca5e201":"code","205d1dc1":"code","55e5feef":"code","320e7aa8":"code","8d80fc32":"code","35f5083d":"code","2c927372":"code","e43d2149":"code","c88e1a36":"code","2b68804c":"code","1dc151d6":"code","386220d0":"code","81193b2f":"code","8fe0ecfb":"code","463b91be":"code","5981e95c":"code","5a4ed8af":"code","3c63969e":"code","3da1a367":"code","137a1860":"code","7da36a1f":"code","1ef0c495":"code","7392f970":"code","dddeb6c7":"code","4c1e16f6":"code","c3d2bd52":"code","507dcd75":"code","dfbdcbe2":"code","d65fa29b":"code","da7453bf":"code","2e9e7087":"markdown","0fc3e3f4":"markdown","98d47d9b":"markdown","04deaac6":"markdown","aafcaf27":"markdown","fd5c04d5":"markdown","152bf983":"markdown","2df63db2":"markdown","1dc21da3":"markdown","768b148f":"markdown","4980f586":"markdown"},"source":{"207e70a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","eeb23e18":"# import package\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport statsmodels as sm \nfrom pathlib import Path\nfrom sklearn.impute import SimpleImputer\nimport warnings","0c05d244":"%matplotlib inline\npd.options.plotting.backend\npd.plotting.register_matplotlib_converters()\nsns.set()\nwarnings.filterwarnings('ignore')","dfdb3b17":"file = '\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx'","4c11bd53":"data_icu = pd.read_excel(file)","d7e10453":"data_icu.head()","929646c0":"data_icu.info()","e0eb93ec":"data_icu.columns","be61a66d":"data = data_icu.drop(columns='ICU') # data for modelling\ntarget = data_icu['ICU'] # target","33b83868":"definitions = []\nfor i in data.columns:\n    if type(data[i].iloc[0]) == str:\n        factor = pd.factorize(data[i])\n        data[i] = factor[0]\n        definitions.append([np.unique(factor[0]), factor[1]])","2b8f28c6":"definitions","13b7fcbb":"data.head()","eec5d905":"target.value_counts()","57888b08":"data.isnull().sum()[data.isnull().sum()>0]","38e9069a":"my_imputer = SimpleImputer(strategy='mean')","4ae9eb0a":"imputed_data = pd.DataFrame(my_imputer.fit_transform(data.drop(columns='PATIENT_VISIT_IDENTIFIER')))","6c46dda9":"imputed_data.columns = data.drop(columns='PATIENT_VISIT_IDENTIFIER').columns","0490b6d4":"imputed_data.shape","f67aa5e5":"imputed_data.head()","e8f8428b":"#we find the feature that is most correlated or collinear\ncor = pd.DataFrame(np.triu(imputed_data.corr().values), index = imputed_data.corr().index,\n                   columns=imputed_data.corr().columns).round(3)\nx = cor.unstack()\nxo = x.sort_values()","773e8f6b":"most_correlated = xo[xo>0.95][xo[xo>0.90] !=1] # feature more collinear","5ffc2717":"pd.DataFrame(most_correlated, columns=['correlation'])","7813f485":"n = len(most_correlated)\nprint('Number of feature most correlated are: {}'.format(n))","7710288e":"# I plot only 20 features most correlated\nfig = plt.figure(dpi=200, figsize=(20,20))\nfig.subplots_adjust(hspace=0.5, wspace=0.4)\nfor i in range(1, 21):\n    ax = fig.add_subplot(5,4,i)\n    col1 = most_correlated.index[i-1][0]\n    col2 = most_correlated.index[i-1][1] \n    sns.regplot(col1, col2, imputed_data)","901e2c0b":"# we take a columns that we remove\ncol_selected = []\nfor row in most_correlated.index:\n    col_selected.append(row[0])","bb42b809":"np.unique(col_selected) # we see that feature","506b0244":"# we take column for standardscaler and pca\nnew_data = imputed_data.drop(columns=np.unique(col_selected))","63f9bf11":"new_data.info()","ee2d4f3e":"#we divide data to train set and test set following a WINDOW feature\ntrain = new_data[new_data.WINDOW != 4]\ntest = new_data[new_data.WINDOW == 4]","7d0399c8":"train.shape","4f90ed24":"test.shape","ba38f12d":"# we take target_train and target_test\ntarget_train = target.iloc[:train.shape[0]]\ntarget_test = target.iloc[train.shape[0]:]","7eefed43":"target_train.shape","760f3478":"target_test.shape","ba700a3a":"# define xtrain, xvalid, ytrain, yvalid\nfrom sklearn.model_selection import train_test_split","ce663139":"xtrain, xvalid, ytrain, yvalid = train_test_split(train, target_train, stratify=target_train, random_state=0,\\\n                                                  train_size=0.8)","fbab73b6":"print('xtrain shape: {}'.format(xtrain.shape))\nprint('xvalid shape: {}'.format(xvalid.shape))","cca5e201":"print('ytrain shape: {}'.format(ytrain.shape))\nprint('yvalid shape: {}'.format(yvalid.shape))","205d1dc1":"from sklearn.preprocessing import StandardScaler","55e5feef":"scaler = StandardScaler()","320e7aa8":"xtrain_scaled = scaler.fit_transform(xtrain)\nxvalid_scaled = scaler.transform(xvalid)","8d80fc32":"from sklearn.decomposition import PCA","35f5083d":"plt.figure(dpi=250, figsize=(10,5))\npca_curve = PCA().fit(xtrain_scaled)\nplt.plot(np.cumsum(pca_curve.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cummulative explained variance')\nplt.title('PCA curve')","2c927372":"pca = PCA(n_components=50)","e43d2149":"xtrain_pca = pca.fit_transform(xtrain_scaled)\nxvalid_pca = pca.transform(xvalid_scaled)","c88e1a36":"xtrain_pca.shape","2b68804c":"m = pca.components_.shape\nm # eigenvectors","1dc151d6":"comp =pd.DataFrame(pca.components_, columns=train.columns, index=['PC'+str(i) for i in range(1,m[0]+1)])","386220d0":"plt.figure(figsize=(20, 20))\nsns.heatmap(comp.T)\nplt.title('Principal component and primitive feature')\nplt.show()","81193b2f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom xgboost  import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold,cross_val_predict\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, classification_report\n# Set random seed\nnp.random.seed(0)","8fe0ecfb":"skf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 0)","463b91be":"def model_selection(listof_model, cv=skf, x=xtrain_pca, y=ytrain):\n    \n    \" listof_model is dictionary type containing different model algorithm \"\n    \n    result = {}\n    \n    for cm in list(listof_model.items()):\n        \n        name = cm[0]\n        model = cm[1]\n        \n        cvs = cross_val_score(model, x, y, cv=cv).mean()\n        ypred = cross_val_predict(model, x, y, cv=cv)\n        auc = roc_auc_score(y, ypred)\n        precision = precision_score(y, ypred)\n        recall = recall_score(y, ypred)\n        acc = accuracy_score(y, ypred)\n        fscore = f1_score(y, ypred)\n        \n        result[name] = {'cross_val_score': cvs, 'auc':auc, 'precision':precision, 'recall':recall,\n                        'accuracy': acc, 'f1_score': fscore}\n        \n        print('{} model done !!!'.format(name))\n        \n        \n    return result","5981e95c":"listof_model = {'LogisticRegression': LogisticRegression(), 'LinearSVC': LinearSVC(),\n                'KNeighbors':KNeighborsClassifier(), 'RandomForest': RandomForestClassifier(),\n               'GradientBoosting': GradientBoostingClassifier(), 'ExtraTree':ExtraTreesClassifier(),\n               'XGBoost': XGBClassifier()}","5a4ed8af":"all_model = model_selection(listof_model)","3c63969e":"pd.DataFrame(all_model) # we see a model that is match well with our data.","3da1a367":"# we choose random forest \nsearch_space = {'n_estimators': [100, 200, 500],\n               'criterion': ['gini', 'entropy'], 'min_samples_split': [1,2,3], \n               'max_samples':[0.5363991145732665, 0.1, 1],\n               'max_depth': [2,3,4]}","137a1860":"# Create grid search\ngridsearch = GridSearchCV(RandomForestClassifier(), search_space, cv=skf, verbose=1)","7da36a1f":"# Fit grid search\nbest_model = gridsearch.fit(xtrain_pca, ytrain)","1ef0c495":"print(\"Validation set score: {:.2f}\".format(gridsearch.score(xvalid_pca, yvalid)))","7392f970":"print(\"Best parameters: {}\".format(gridsearch.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(gridsearch.best_score_))","dddeb6c7":"opt_model = RandomForestClassifier(min_samples_split=2, n_estimators=100, max_depth=2, max_samples=0.5363991145732665).fit(xtrain_pca, ytrain)","4c1e16f6":"ypred = opt_model.predict(xvalid_pca)","c3d2bd52":"print('Validation accuracy score: {}'.format(accuracy_score(yvalid, ypred)))","507dcd75":"print(classification_report(yvalid, ypred, target_names=['NO', 'YES']))","dfbdcbe2":"xtest_scaled = scaler.transform(test)\nxtest_pca = pca.transform(xtest_scaled)","d65fa29b":"pred = opt_model.predict(xtest_pca)","da7453bf":"print('Test accuracy score: {}'.format(accuracy_score(target_test, pred)))","2e9e7087":"# Cleaning and preprocessing data","0fc3e3f4":"# Model Selection","98d47d9b":"My model is not too bad, it give me **77.4% accuracy score**. May be size of data is small for this model to improve performance.","04deaac6":"# UPNEXT\n\n**You can download, share, improve this model and comment. Be free.**","aafcaf27":"## Select feature if possible","fd5c04d5":"# Task Details\n\nBased on the data available, is it feasible to predict which patients will need intensive care unit support?\n\nFrom this task I am trying to give my model. Let's start. ","152bf983":"NO class give good result but not Yes class","2df63db2":"## Find train set and test set data following WINDOW  feature (ABOVE_12)","1dc21da3":"# Extraction feature using PCA","768b148f":"## Training and validation  model","4980f586":"## Standardize data"}}