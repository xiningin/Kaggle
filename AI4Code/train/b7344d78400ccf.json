{"cell_type":{"db3b453f":"code","3d767db1":"code","2bd1dfb7":"code","d482f18e":"code","29294552":"code","eb535072":"code","39b830fd":"code","94868b8c":"code","6e841ec3":"code","3d26ab8a":"code","a3ba9a44":"code","27c923e1":"code","adccaee7":"code","7ea27c6d":"code","16c723cd":"code","64de4b73":"code","cd481ffb":"code","d2c0b79f":"code","d03b7a08":"code","0a4a91bb":"code","68f28d21":"code","a57e4a42":"code","c8970752":"code","f331b139":"code","af921648":"code","64c581c2":"code","673a7084":"code","9c2c8ed5":"code","cbab4acf":"code","11354b72":"code","5dd1dac2":"code","2be3d7fd":"code","c212d6d5":"code","18193354":"code","48d8f1e0":"code","6f3e8d3b":"code","67242b54":"code","7a4ad965":"code","9102bd65":"code","f615eb76":"code","0ec8a0b9":"code","9040a27d":"code","279acf40":"code","ebd031aa":"code","8fa14349":"code","b6cec22c":"code","d5c0b4d7":"code","356c75e6":"code","05f10e4e":"code","b410aaf4":"code","6229dcc2":"code","2202fcec":"code","3e7c1a72":"code","81514394":"markdown"},"source":{"db3b453f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3d767db1":"housing = pd.read_csv(\"\/kaggle\/input\/california-housing-prices\/housing.csv\")","2bd1dfb7":"housing.head()","d482f18e":"housing.info()","29294552":"housing.describe()","eb535072":"%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20,15))\nplt.show()","39b830fd":"import numpy as np\ndef split_train_test(data, test_ratio):\n    shuffled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled_indices[:test_set_size]\n    train_indices = shuffled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]","94868b8c":"train_set, test_set = split_train_test(housing, .2)","6e841ec3":"len(train_set)","3d26ab8a":"len(test_set)","a3ba9a44":"from zlib import crc32\n\ndef test_set_check(identifier, test_ratio):\n    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n\ndef split_train_test_by_id(data, test_ratio, id_column):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n    return data.loc[~in_test_set], data.loc[in_test_set]","27c923e1":"housing_with_id = housing.reset_index()","adccaee7":"train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")","7ea27c6d":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size=.2, random_state=42)","16c723cd":"housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], bins=[0.,1.5,3.0,4.5,6.,np.inf], labels=[1,2,3,4,5])","64de4b73":"housing[\"income_cat\"].hist()","cd481ffb":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","d2c0b79f":"strat_test_set[\"income_cat\"].value_counts() \/ len(strat_test_set)","d03b7a08":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)\n    ","0a4a91bb":"housing = strat_train_set.copy()","68f28d21":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)","a57e4a42":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, s=housing[\"population\"]\/100, label=\"population\", figsize=(10,7), c=\"median_house_value\",cmap=plt.get_cmap(\"jet\"), colorbar=True)","c8970752":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","f331b139":"from pandas.plotting import scatter_matrix\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_matrix(housing[attributes], figsize=(12,8))","af921648":"housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1)","64c581c2":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"]\/housing[\"households\"]\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]\/housing[\"total_rooms\"]\nhousing[\"population_per_household\"]=housing[\"population\"]\/housing[\"households\"]","673a7084":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","9c2c8ed5":"housing = strat_train_set.drop(\"median_house_value\", axis=1)\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","cbab4acf":"housing.dropna(subset=[\"total_bedrooms\"])","11354b72":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\")","5dd1dac2":"housing_num = housing.drop(\"ocean_proximity\", axis=1)\nimputer.fit(housing_num)","2be3d7fd":"imputer.statistics_","c212d6d5":"housing_num.median().values","18193354":"X = imputer.transform(housing_num)","48d8f1e0":"housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)","6f3e8d3b":"housing_cat = housing[[\"ocean_proximity\"]]\nhousing_cat.head()","67242b54":"from sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]","7a4ad965":"ordinal_encoder.categories_","9102bd65":"from sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder()\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot.toarray()","f615eb76":"cat_encoder.categories_","0ec8a0b9":"from sklearn.base import BaseEstimator, TransformerMixin\n\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","9040a27d":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")), ('attribs_adder', CombinedAttributesAdder()), ('std_scaler', StandardScaler()),])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","279acf40":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing)","ebd031aa":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","8fa14349":"some_data = housing.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", lin_reg.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","b6cec22c":"from sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","d5c0b4d7":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)\n\nhousing_predictions = tree_reg.predict(housing_prepared)\n\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","356c75e6":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","05f10e4e":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","b410aaf4":"display_scores(tree_rmse_scores)","6229dcc2":"lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","2202fcec":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nforest_reg.fit(housing_prepared, housing_labels)","3e7c1a72":"forest_predictions = forest_reg.predict(housing_prepared)\n\nforest_mse = mean_squared_error(housing_labels, forest_predictions)\nforest_rmse = np.sqrt(forest_mse)\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","81514394":"This follows Aurelien Geron's book Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow, 2nd Edition"}}