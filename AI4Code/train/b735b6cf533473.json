{"cell_type":{"7423e68f":"code","e5043c56":"code","54022e9a":"code","6b40fbc7":"code","4634dd01":"code","3f07678b":"code","f6dabdbd":"code","d6630313":"code","b5c19a8c":"code","457331ac":"code","dea6b459":"code","b1955375":"code","e6b5786c":"code","b71c58b2":"code","78a1b600":"code","2672df95":"code","5512b050":"code","51bcae7b":"code","70f2cde8":"code","aa78d3e3":"code","10d44871":"code","f55a2ed5":"code","8e98c89d":"code","be913fc1":"code","562302bf":"code","6691450b":"code","f32535e5":"code","313f8217":"code","40727878":"code","eef640cd":"code","43b793c2":"code","cc0b8208":"code","18a32a41":"code","ce716bf9":"code","83646bb3":"code","e169a8f6":"code","385b95f6":"code","1954d5bc":"code","f75ac5a2":"code","4f2fd5f6":"code","30f7e828":"code","a50e40b6":"code","9e846774":"code","19d83333":"code","88015f24":"code","7d219870":"code","bc06363c":"code","dceebc42":"code","aff67f42":"code","60f56ad4":"code","eb035317":"code","af45c7a8":"code","522f7905":"code","60aa1a72":"code","016301f3":"code","cb9e528b":"code","41269635":"markdown","251eb121":"markdown","55ce3e66":"markdown","170e531b":"markdown","021f3830":"markdown","e861ef13":"markdown","514538f8":"markdown","559aaddf":"markdown","e749db60":"markdown","85707304":"markdown","7784bfa9":"markdown","cff778f1":"markdown","51505290":"markdown","57330f1f":"markdown","2e725fa2":"markdown","4af5b769":"markdown","bc98cd8b":"markdown","82d49d4a":"markdown","4daa4d2a":"markdown","31372768":"markdown","28d8e308":"markdown"},"source":{"7423e68f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n% matplotlib inline","e5043c56":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n#first focusing on what the train dataset tells us","54022e9a":"#1. The first five observations\ntrain.head(5)","6b40fbc7":"#2. What is the size of the dataframe?\ntrain.shape","4634dd01":"#3. What are the data types?\ntrain.info()","3f07678b":"#4. How many missing values?\n# Looks like we can't fully rely on Age and Cabin. We need to figure out a way on how to predict the values of these fields especially Age.\n# Since Embarked only has 2 missing values we fill them in using mean, median, or mode\ntrain.isnull().sum()","f6dabdbd":"#5. Basic Statistics\n# 39% of the data survived\n# average fare is $32\n# the younges passenger is around five months old and the oldest is 80 years old\ntrain.describe()","d6630313":"#6. Number of unique Values\ntrain.nunique()\n#Tickets have dupes\n#Cabin have dupes","b5c19a8c":"train['Survived_C'] = np.where(train['Survived']==0,'No','Yes')\ntrain.head()","457331ac":"#Breakdown of the passengers by gender\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\ntrain['Sex'].value_counts().plot.pie(autopct='%1.f%%', shadow=True, explode=(.1,0), startangle=90, ax=ax[0]).axis('equal')\nax[0].set_title('Passenger Breakdown Based on Sex')\n\nax1 = sns.countplot(x='Survived_C', hue='Sex', data=train, ax=ax[1])\ntotal = float(len(train))\nfor p in ax1.patches:\n    height = p.get_height()+1\n    ax1.text(p.get_x()+p.get_width()\/2.,\n            height+3,\n            '{:1.0f}%'.format((height\/total)*100),\n            ha=\"center\")\nax1.set_title('Survival Count and Rate Breakdown')\n\nplt.show()","dea6b459":"sns.barplot(x='Sex', y='Survived', data=train).set_title('Survival Rate based on Sex')\nplt.show()","b1955375":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","e6b5786c":"#Filling in missing Embarked values\ntrain[train.Embarked.isnull()]\n#both are female Pclass1 survivors, paid $80, and travelled alone (although PassengerID 830 looks like have 2 Names registered?)","b71c58b2":"# Determining how many passengers per observation \/ per ticket\ntrain['No_of_Passengers_on_Ticket']= train['SibSp'] + train['Parch'] + 1 #+1 for those travelling alone\n\n# Adding a column called 'Group Size' to better segment the observation\n# Solo - 1 traveller\n# Couple - 2 travellers \n# Mid - 3 to 5 travellers\n# Large - 6+ travellers \ntrain['Group_Size'] = np.where(train.No_of_Passengers_on_Ticket==1, 'Solo',\n                                    np.where(train.No_of_Passengers_on_Ticket==2, 'Couple', \n                                             np.where(np.logical_and(train.No_of_Passengers_on_Ticket>2, train.No_of_Passengers_on_Ticket<6),'Mid',\n                                                      'Large')))\ntrain[train.Embarked.isnull()]","78a1b600":"#We know that the missing values are Female passengers, Pclass 1, fare=$80, both travelling alone\nPclass1 = train[(train['Sex']=='female') & (train['Pclass']==1) & (train['Group_Size']=='Solo')]\n#Pclass1[['Embarked', 'Fare']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Fare', ascending=False)\nPclass1[['Embarked', 'Fare']].groupby(['Embarked'], as_index=False).describe()","2672df95":"#The mean closest to $80 is Southampton. It also has the smaller standard deviation \nPclass1[['Embarked', 'Fare']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Fare', ascending=False)","5512b050":"train.Embarked.fillna('S', inplace=True) #filling in missing Embarked with S","51bcae7b":"f, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\ntrain['Embarked'].value_counts().plot.pie(autopct='%1.f%%', shadow=True, explode=(.1,0.1,0), startangle=90, ax=ax[0]).axis('equal')\nax[0].set_title('Passenger Breakdown Based on Port of Embarkation')\n\nsns.countplot(x='Survived_C', hue='Embarked', data=train, ax=ax[1]).set_title('Survival Count based on Port of Embarkation')\n\nplt.show()","70f2cde8":"train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()","aa78d3e3":"f, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\ncolors=['forestgreen','steelblue', 'darkorange']\n\ntrain['Pclass'].value_counts().plot.pie(autopct='%1.1f%%', shadow=True, explode = (0.1,0,0), startangle=90, colors=colors, ax=ax[0]).axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\nax[0].set_title('Proportion of Passengers Per Pclass')\n\nsns.barplot(x='Pclass', y='Survived', ax=ax[1], data=train).set_title('Survival Rate based on Pclass')\n\nplt.show()","10d44871":"sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train).set_title('Survival Rate Per Gender and Pclass')\nplt.show()","f55a2ed5":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","8e98c89d":"sns.countplot(x='Embarked', hue='Pclass', data=train).set_title('Survival Count based on Port of Embarkation and Pclass')\nplt.show()","be913fc1":"data = train.sort_values(['No_of_Passengers_on_Ticket'], ascending=True)\n\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\nsns.countplot(x='Group_Size', hue='Survived_C', ax=ax[0], data=data).set_title('Survival Count based on Group Size')\nsns.countplot(x='No_of_Passengers_on_Ticket', hue='Survived_C', ax=ax[1], data=data).set_title('Survival Count based on Group Size')\nplt.show()","562302bf":"train['Age'].fillna(train.Age.mean(), inplace=True)\ntrain.describe()","6691450b":"f, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\nGender = ['male', 'female']\nSurvive = ['Yes', 'No']\n\nfor g in Gender:\n    survivors = train[(train['Sex']==g) & (train['Survived_C']=='Yes')].Age\n    sns.distplot(survivors, hist=False, label=g, ax=ax[0]).set_title('Age Distribution of Survivors')\n    deaths = train[(train['Sex']==g) & (train['Survived_C']=='No')].Age        \n    sns.distplot(deaths, hist=False, label=g, ax=ax[1]).set_title('Age Distribution of those Who Died')  \n\nplt.show()","f32535e5":"f, ax = plt.subplots(nrows=1,ncols=2,figsize=(15,4))\n\nsns.pointplot(y='Age', x='No_of_Passengers_on_Ticket', hue='Survived_C', linestyles=['--','-'], markers=['x','o'], \\\n              dodge=True, data=train, ax=ax[0]).set_title('Distribution by Age and Passenger Count')\nsns.pointplot(y='Age', x='Group_Size', hue='Survived_C', linestyles=['--','-'], markers=['x','o'], \\\n              dodge=True, data=train, ax=ax[1]).set_title('Distribution by Age and Group Size')\n\nplt.show()","313f8217":"sns.boxplot(y='Age',x='Pclass', data=train).set_title('Age and Pclass')","40727878":"#Dropping \ntrain.drop(['Survived_C','Cabin'], axis=1, inplace=True)\ntrain.head()","eef640cd":"Sex = pd.get_dummies(train['Sex'], drop_first=True)\nEmbarked_New = pd.get_dummies(train['Embarked'], drop_first=True)\nPclass_New = pd.get_dummies(train['Pclass'], drop_first=True)\ntrain_n = pd.concat([train,Sex,Embarked_New,Pclass_New],axis=1)\ntrain_n.drop(columns=['Sex','Pclass','Embarked','Name','PassengerId','Ticket','Group_Size'],axis=1, inplace=True)","43b793c2":"train_n.rename(columns={'male':'Sex', 'Q':'Queenstown', 'S':'Southampton',2:'Pclass2',3:'Pclass3'}, inplace=True)\ntrain_n.head()","cc0b8208":"# Preparing the data\nX = train_n.drop(['Survived'], axis=1)\ny = train_n.Survived","18a32a41":"#building the logistic regression model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1)\nlogmodel = LogisticRegression()\n#fitting the model\nlogmodel.fit(X_train, y_train)","ce716bf9":"#make predictions\nprediction = logmodel.predict(X_test)","83646bb3":"# Examining the Prediction\n#calculate precision and recall\nfrom sklearn.metrics import classification_report\nclassification_report(y_test,prediction)","e169a8f6":"#look at the confusion matrix to justify Precision and Recall\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,prediction)","385b95f6":"#calculate the accuracy score - from the confusion matrix\n#Number of correct predictions\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,prediction)\n#we have 77% accuracy, which is still pretty good","1954d5bc":"#Preparing the data\nSex = pd.get_dummies(test['Sex'], drop_first=True)\nEmb = pd.get_dummies(test['Embarked'], drop_first=True)\nPcl = pd.get_dummies(test['Pclass'], drop_first=True)\ntest_n = pd.concat([test, Sex, Emb, Pcl], axis=1)\n\n#Matching the train data's column labels\ntest_n.drop(columns=['PassengerId', 'Ticket', 'Pclass', 'Name', 'Sex', 'Cabin', 'Embarked'], axis=1, inplace=True)\ntest_n['No_of_Passengers_on_Ticket'] = test_n.SibSp + test_n.Parch + 1","f75ac5a2":"test_n.rename(columns={'male':'Sex', 'Q':'Queenstown', 'S':'Southampton',2:'Pclass2',3:'Pclass3'}, inplace=True)\ntest_n.head()\n\n#checking if the test data has null values\n#test_n.isnull().sum()\n\n#Dropping the null values of the test data\nX_n_test = test_n.dropna(how='any')","4f2fd5f6":"test_n.shape","30f7e828":"X_n_test.shape","a50e40b6":"#X_n_test is still a decent sample size, we still have 79% of the actual test data\n331\/418","9e846774":"# Preparing the data\nX_train1 = train_n.drop(['Survived'], axis=1)\ny_train1 = train_n.Survived\n\n#building the logistic regression model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#Train data has a 891 observations, while Testa data has 331 observations\n#Using 331\/891 = 37% of the Train data as the test size, so that I can compare and plug the Test data later on\nX_train, X_test, y_train, y_test = train_test_split(X_train1, y_train1, test_size=.3714, random_state=1)\nlogmodel = LogisticRegression()\n\n#fitting the model\nlogmodel.fit(X_train, y_train)","19d83333":"#predict from the train set\nprediction = logmodel.predict(X_test)","88015f24":"#Examining the Prediction\n#calculate precision and recall\nfrom sklearn.metrics import classification_report\nclassification_report(y_test,prediction)","7d219870":"#calculate the accuracy score - from the confusion matrix\n#Number of correct predictions\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,prediction)\n#we have 77% accuracy, which is still pretty decent","bc06363c":"#predict from the test set\nprediction2 = logmodel.predict(X_n_test)","dceebc42":"# Examining the Prediction\n#calculate precision and recall\nfrom sklearn.metrics import classification_report\nclassification_report(y_test,prediction2)","aff67f42":"#look at the confusion matrix to justify Precision and Recall\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,prediction2)","60f56ad4":"#calculate the accuracy score - from the confusion matrix\n#Number of correct predictions\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,prediction2)\n#we have 50% accuracy, it's not good... need to improve the prediction model","eb035317":"X_train2 = train_n.drop(['Survived'], axis=1)\ny_train2 = train_n.Survived\n\nX_train, X_test, y_train, y_test = train_test_split(X_train2, y_train2, test_size=.3714, random_state=2)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\n#check classification accuracy of KNN with K=16 \n#the bigger the K, the less likely an error will occur, 10 is a good start to fine tuning K\nknn = KNeighborsClassifier(n_neighbors=17)\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\nmetrics.accuracy_score(y_test,y_pred)\n#from 10 to 33, K=17 has the highest accuracy\n#70% classification of accuracy of KNN = 17 using the Train set","af45c7a8":"from sklearn.cross_validation import cross_val_score\nscores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\nscores","522f7905":"#average accuracy as an estimate of out-of-sample accuracy - using the Train set\n#71% accuracy\nscores.mean()","60aa1a72":"#using the Test set \ny_pred2 = knn.predict(X_n_test)\nmetrics.accuracy_score(y_test,y_pred2)\n#56% classification accuracy of KNN = 17, using the Test set","016301f3":"scores2 = cross_val_score(knn, X_n_test, y_test, cv=10, scoring='accuracy')\nscores2","cb9e528b":"#average accuracy as an estimate of out-of-sample accuracy - using the Train set\n#51% accuracy\nscores2.mean()\n#Looks similar to Logistic Regression ","41269635":"**Point of Embarkation**\n\nC = Cherbourg; Q = Queenstown; S = Southampton <br \/>\n*Southampton* embarked 72% of passengers.  <br \/>\nVisually we can see that Cherbourg is the only port that embarked more survivors than those who died. <br \/>\nMajority of the passengers embarked from Southampton and Queenstown mostly died.","251eb121":"**Pclass and Embarked**","55ce3e66":"**Passenger Class**\n\n*Pclass* is a proxy for socio-economic status (SES)\n1st ~ Upper;  2nd ~ Middle;  3rd ~ Lower\n\n55% of the passengers were considered Pclass 3 (more poor people than rich people) but it also has the lowest survival rate at 24% <br \/>\nFor both genders, Pclass 1 passengers have the highest survival rate at 63% <br \/>","170e531b":"*2. KNN cross validation*","021f3830":"**Observation:**\nWe got 78% Precision and Recall -- which is pretty good. Although I think this can still be improved.\n<br \/>\n*Precision* is the number of True Positives divided by the number of True Positives and False Positives <br \/>\n*Recal*l is the number of True Positives divided by the number of True Positives and the number of False Negatives. <br \/>\n\n134 - True Positive <br \/>\n75 - True Negative <br \/>\n19 - False Positive (Type 1 Error) <br \/>\n40 - False Negative (Type 2 Error) <br \/>\n<br \/>\n*For any system to be able to achieve maximum Precision (no false positive) and maximum Recall (no false negative) there needs to be an absence of type I and II errors.","e861ef13":"**Age **\n\nSince Age has 177 NaN values, we are going to fill in the missing values using Mean Imputation. ","514538f8":"**Loading Datasets**","559aaddf":"# 3. Data Wrangling\n* Converting Strings into Categorical Values\n* Cleaning \/ Removing Categorical Values","e749db60":"\n**Group Size of the Survivors**\n\nRecap of the added Group Size Column:  <br \/>\nSolo - 1 traveller <br \/>\nCouple - 2 travellers <br \/>\nMid - 3 to 5 travellers <br \/>\nLarge - 6+ travellers <br \/>\n\nPeople who mostly survived are ethe ones travelling alone <br \/>\nPeople who travelled in 2 - 4 are the ones who mostly didn't survive<br \/>","85707304":"**Age and Group Size** <br \/>\nMost 30 year olds travelled alone or in two.","7784bfa9":"# 1. Data Exploration\n<br \/>\n**Goals:** <br \/>\n* Load dataframes <br \/>\n* Know the size of the dataframes <br \/>\n* Familiarize with the fields <br \/>\n* Identify the type of variables <br \/>\n* Perform basic statistic <br \/>","cff778f1":"**Pclass and Gender**","51505290":"Most survivors are in their 30s but it's interesting to see that there's a spike around 1 to 2 years of age. There are also infants and survivors over 80 years old.\n\nFor those who died, it follows pretty much the same curve as the Survivors distribution, wherein lots of thirty year old passengers died.","57330f1f":"**Using the Test Data**","2e725fa2":"**From Visualizing the data, we have observed:** <br \/>\n1. There are twice as much male (65%) than female (35%) passengers <br \/>\n2. More female survivors than their male counterparts (almost doubled). <br \/>\n3. More male deaths than femle (4x more). <br \/>\n4. Southampton embarked the most passengers but is also the port with lowest survival rate <br \/>\n5. Cherbourg embarked the second largest number of passengers but also have passengers with the highest survival rate.  <br \/>\n6. Most survivors travelled alone and in two's and most of them are 30 years olds. <br \/>\n7. Socio-economic status played part in survival, having Pclass 1 passengers with the highest surival rate at 63%","4af5b769":"# 4. Predictions","bc98cd8b":"**How does the data look like?**<br \/>\nI'd like to know how huge is the dataset, the fields, data types and missing values. This allows me to come up with a game plan and gives me an idea of where to start my analysis.","82d49d4a":"# 5. Conclusion\n\nIt's a fun exercise to visualize the data. I'm getting familiar with Kaggle. Although I wish to have better prediction, I'll keep looking for ways to improve my prediction and update this kernel from time to time.","4daa4d2a":"**Age and Pclass** <br \/>\nMost 30 year olds travelled alone or in two.","31372768":"*1. Logistic Regression*\n\nIn logistic regression, the outcome (dependent variable) has only a limited number of possible values. It is used when the response variable is categorical in nature -- which is what exactly what we are trying to predict, whether a passenger will survive or not.\n","28d8e308":"# 2.  Data Visualization\n <br \/>\n\n**More Male passengers survived than Females passengers**  <br \/>\n 60% of the passengers died, 53% Male and 9% Female  <br \/>\n 48% of the passengers survived, 12% Male and 26% Female\n\n74% Female survival rate  <br \/>\n19% Male survival rate"}}