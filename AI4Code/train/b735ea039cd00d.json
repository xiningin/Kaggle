{"cell_type":{"27b0a544":"code","47927b9e":"code","e02631b1":"code","c4be0db3":"markdown","64c4ce1d":"markdown","c6bcd2b2":"markdown"},"source":{"27b0a544":"# imports\nimport numpy as np\nimport pandas as pd \nimport os \nimport random\nimport warnings \nwarnings.filterwarnings(action='ignore')\n\nfrom sklearn.preprocessing import LabelEncoder \n\nfrom sklearn.model_selection import train_test_split\nimport optuna.integration.lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# data path\nTRAIN_PATH = \"..\/input\/tabular-playground-series-may-2021\/train.csv\"\nTEST_PATH = \"..\/input\/tabular-playground-series-may-2021\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/tabular-playground-series-may-2021\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\n# main column\nID = \"id\"\nTARGET = 'target'\n\nCLASS1 = \"Class_1\"\nCLASS2 = \"Class_2\"\nCLASS3 = \"Class_3\"\nCLASS4 = \"Class_4\"\nCLASS = [CLASS1,CLASS2,CLASS3,CLASS4]\nTARGET_NUM = len(CLASS)\n\n# seed\nSEED = 2022\ndef seedAll(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\nseedAll()\n\n# model\nTEST_SIZE = 0.2\nVERBOSE_EVAL = 100\nESR = 100\n\n# load\ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","47927b9e":"# split (input & target)\ny = train[TARGET]\nX = train.drop([TARGET,ID],axis=1)\n\n# label encoding\nlabelEncoder = LabelEncoder()\ny = labelEncoder.fit_transform(y)\nprint(y)\nprint(labelEncoder.classes_)\n\n#split data (train & validation)\nX_train, X_val, y_train, y_val = train_test_split(X, y,test_size=TEST_SIZE,\n                                                  shuffle=True,random_state=SEED)\n# search best param\nD_train = lgb.Dataset(X_train, label = y_train)\nD_val = lgb.Dataset(X_val, label = y_val)\nparams = {'objective' : 'multiclass', \n          'num_class' : TARGET_NUM,  \n          'metric' : 'multi_logloss', \n          'verbosity' : -1, \n          'boosting_type' : 'gbdt'}\n\nmodel = lgb.train(params,\n                  D_train,\n                  valid_sets =[D_val],\n                  verbose_eval=VERBOSE_EVAL,\n                  early_stopping_rounds=ESR)\n\n# build model using best params\nmodel = LGBMClassifier(**model.params)\nmodel.fit(X_train, y_train, \n          eval_set = ((X_val, y_val)), \n          early_stopping_rounds = ESR, verbose = 0)","e02631b1":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n\nX_test = test.drop([ID],axis=1)\npreds = model.predict_proba(X_test)\nsub[CLASS1]=preds[:,0]\nsub[CLASS2]=preds[:,1]\nsub[CLASS3]=preds[:,2]\nsub[CLASS4]=preds[:,3]\n\nsub.to_csv(SUBMISSION_PATH,index = False)\nsub.head()","c4be0db3":"# build model","64c4ce1d":"# predict & submit","c6bcd2b2":"# imports & variables & load"}}