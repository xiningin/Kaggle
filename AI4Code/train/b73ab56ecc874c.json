{"cell_type":{"4b0de7bf":"code","23a876cd":"code","39bdeaed":"code","f6539c9b":"code","e1c04871":"code","01979722":"code","5dd0fb8b":"code","347bfc7b":"code","372eb302":"code","47368df0":"code","c6a74d1b":"code","2c02ba15":"code","9eb4ad5e":"code","d029abeb":"code","bd489afa":"code","94c093fb":"code","510f12e7":"code","e1df9183":"code","41d6f8c8":"code","bf2d73e2":"code","8827eb71":"code","551223bb":"markdown"},"source":{"4b0de7bf":"import os, warnings\nwarnings.filterwarnings('ignore')","23a876cd":"print(os.listdir(\"..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\"))","39bdeaed":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom itertools import groupby\nfrom imageio import imread\nfrom random import randint\nfrom tqdm import tqdm_notebook\nfrom glob import glob\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, Conv2DTranspose\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\nfrom keras.utils.vis_utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom IPython.display import SVG","f6539c9b":"TRAIN_SEED = randint(1, 1000)\nVALIDATION_SEED = randint(1, 1000)","e1c04871":"train_image_data_generator = ImageDataGenerator(\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    rotation_range = 5,\n    zoom_range = 0.1,\n    rescale = 1.0 \/ 255.0\n).flow_from_directory(\n    \"..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\/train_imges\",\n    target_size = (128, 128),\n    color_mode = 'grayscale',\n    batch_size = 16,\n    seed = TRAIN_SEED\n)\n\ntrain_mask_data_generator = ImageDataGenerator(\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    rotation_range = 5,\n    zoom_range = 0.1,\n    rescale = 1.0 \/ 255.0\n).flow_from_directory(\n    \"..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\/train_masks\",\n    target_size = (128, 128),\n    color_mode = 'grayscale',\n    batch_size = 16,\n    seed = TRAIN_SEED\n)\n\nvalidation_image_data_generator = ImageDataGenerator(rescale = 1.0 \/ 255.0).flow_from_directory(\n    \"..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\/train_imges\",\n    target_size = (128, 128),\n    color_mode = 'grayscale',\n    batch_size = 16,\n    seed = VALIDATION_SEED,\n)\n\nvalidation_mask_data_generator = ImageDataGenerator(rescale = 1.0 \/ 255.0).flow_from_directory(\n    \"..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\/train_masks\",\n    target_size = (128, 128),\n    color_mode = 'grayscale',\n    batch_size = 16,\n    seed = VALIDATION_SEED,\n)","01979722":"# Code Credits: https:\/\/www.kaggle.com\/abhishek\/inference-for-mask-rcnn\n\ndef mask_to_rle(img, width, height):\n    rle = []\n    lastColor = 0\n    currentPixel = 0\n    runStart = -1\n    runLength = 0\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 1:\n                    runStart = currentPixel\n                    runLength = 1\n                else:\n                    rle.append(str(runStart))\n                    rle.append(str(runLength))\n                    runStart = -1\n                    runLength = 0\n                    currentPixel = 0\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor\n            currentPixel+=1\n    return \" \" + \" \".join(rle)","5dd0fb8b":"x_batch, _ = train_image_data_generator.next()\ny_batch, _ = train_mask_data_generator.next()\nfig, axes = plt.subplots(nrows = 4, ncols = 2, figsize = (16, 16))\nplt.setp(axes.flat, xticks = [], yticks = [])\nc = 1\nfor i, ax in enumerate(axes.flat):\n    if i % 2 == 0:\n        ax.imshow(x_batch[c].reshape(128, 128))\n        ax.set_xlabel('Image_' + str(c))\n    else:\n        ax.imshow(y_batch[c].reshape(128, 128))\n        ax.set_xlabel('Mask_' + str(c))\n        c += 1\nplt.show()","347bfc7b":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","372eb302":"def build_unet(shape):\n    input_layer = Input(shape = shape)\n    \n    conv1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(input_layer)\n    conv1 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(conv1)\n    pool1 = MaxPooling2D(pool_size = (2, 2))(conv1)\n    \n    conv2 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(conv2)\n    pool2 = MaxPooling2D(pool_size = (2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(conv3)\n    pool3 = MaxPooling2D(pool_size = (2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(conv4)\n    pool4 = MaxPooling2D(pool_size = (2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(conv5)\n    \n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides = (2, 2), padding = 'same')(conv5), conv4], axis = 3)\n    conv6 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same')(conv6), conv3], axis = 3)\n    conv7 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv7), conv2], axis = 3)\n    conv8 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv8), conv1], axis = 3)\n    conv9 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation = 'sigmoid')(conv9)\n    \n    return Model(input_layer, conv10)","47368df0":"model = build_unet((128, 128, 1))\nmodel.summary()\nmodel.compile(optimizer = Adam(lr = 1e-5), loss = dice_coef_loss, metrics = [dice_coef, 'binary_accuracy'])","c6a74d1b":"SVG(model_to_dot(model, show_shapes = True, show_layer_names = True).create(prog = 'dot', format = 'svg'))","2c02ba15":"weight_saver = ModelCheckpoint(\n    'model.h5',\n    monitor = 'val_dice_coeff',\n    save_best_only = True,\n    mode = 'min',\n    save_weights_only = True\n)\n\nreduce_lr_on_plateau = ReduceLROnPlateau(\n    monitor = 'val_loss', factor = 0.5,\n    patience = 3, verbose = 1,\n    mode = 'min', min_delta = 0.0001,\n    cooldown = 2, min_lr = 1e-6\n)\n\nearly = EarlyStopping(\n    monitor = \"val_loss\",\n    mode = \"min\",\n    patience = 15\n)","9eb4ad5e":"def train_data_generator(image_generator, mask_generator):\n    while True:\n        x_batch, _ = train_image_data_generator.next()\n        y_batch, _ = train_mask_data_generator.next()\n        yield x_batch, y_batch\n\ndef validation_data_generator(image_generator, mask_generator):\n    while True:\n        x_batch, _ = validation_image_data_generator.next()\n        y_batch, _ = validation_mask_data_generator.next()\n        yield x_batch, y_batch","d029abeb":"history = model.fit_generator(\n    train_data_generator(\n        train_image_data_generator,\n        train_mask_data_generator\n    ),\n    epochs = 100,\n    steps_per_epoch = 670,\n    validation_steps = 670,\n    validation_data = validation_data_generator(\n        validation_image_data_generator,\n        validation_mask_data_generator\n    ),\n    verbose = 1,\n    callbacks = [\n        weight_saver,\n        early,\n        reduce_lr_on_plateau\n    ]\n)","bd489afa":"plt.plot(history.history['loss'], color = 'b', label = 'Loss')\nplt.plot(history.history['val_loss'], color = 'r', label = 'Validation Loss')\nplt.legend()\nplt.show()","94c093fb":"plt.plot(history.history['dice_coef'], color = 'b', label = 'Dice Coefficient')\nplt.plot(history.history['val_dice_coef'], color = 'r', label = 'Validation Dice Coefficient')\nplt.legend()\nplt.show()","510f12e7":"mask_to_rle(model.predict(x_batch[0].reshape(1, 128, 128, 1)).reshape(128, 128), 128, 128)","e1df9183":"rle, image_id = [], []\nfor file in tqdm_notebook(glob('..\/input\/pneumothoraxdata128\/pneumothoraxdata128\/PneumothoraxData128\/test_images\/test\/*')):\n    image = imread(file).reshape(1, 128, 128, 1)\n    pred = model.predict(image).reshape(128, 128)\n    image_id.append(file.split('\/')[-1][:-4])\n    encoding = mask_to_rle(pred, 128, 128)\n    if encoding == ' ':\n        rle.append('-1')\n    else:\n        rle.append(encoding)","41d6f8c8":"submission = pd.DataFrame(data = {\n    'ImageId' : image_id,\n    'EncodedPixels' : rle\n})\nsubmission.head()","bf2d73e2":"submission.to_csv('submission.csv', index = False)","8827eb71":"model.save('unet_starter.h5')","551223bb":"### Note on Dataset:\nI am using a modified version of the [pneumotorax128](https:\/\/www.kaggle.com\/mnpinto\/pneumotorax128) dataset by [Miguel Pinto](https:\/\/www.kaggle.com\/mnpinto) for this kernel. The directory structure of the dataset was modified for the use of the `Keras ImageDataGenerator`."}}