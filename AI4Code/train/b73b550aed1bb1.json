{"cell_type":{"711cbeae":"code","d3ba5f33":"code","8578b407":"code","e11a5df2":"code","1e6f382d":"code","99da26b6":"code","1f8b0f84":"code","a50d97f3":"code","93b67da1":"code","f1428231":"code","015cd48f":"code","57ba98f5":"code","9c835bbf":"code","1aa7f9d8":"code","12a51afe":"code","d9a5b9b9":"code","c9a67c16":"code","1d73eebf":"code","2c035fd8":"code","a1764131":"code","cb1a5e5f":"code","4e92ce12":"code","d7b7ee7f":"code","c5829c7c":"code","88c843cc":"code","f80c58f0":"code","ed28897e":"code","fe69eb54":"code","fcfc5f06":"code","51052764":"markdown","77e473f4":"markdown","4714f598":"markdown","58ba2675":"markdown","5719c00c":"markdown","26d4e59d":"markdown","d981b0aa":"markdown","afacb33c":"markdown","bcc966b3":"markdown","c34edd6d":"markdown","60ae93c1":"markdown","213de026":"markdown","33051bb9":"markdown","f0586065":"markdown","92e8e7b1":"markdown","19a94051":"markdown","ad672104":"markdown","9668ccd6":"markdown","3cf22630":"markdown","62da006f":"markdown","6db49d63":"markdown","88e8ac7a":"markdown","05bd598e":"markdown","5a8c9f5b":"markdown","4a27912c":"markdown","06027d59":"markdown","9422405c":"markdown","aca9d76a":"markdown","6a0ebe1e":"markdown","d6d97b26":"markdown","e4bc7604":"markdown","67fe04e4":"markdown","85475c41":"markdown","41c588b9":"markdown","bea6cdba":"markdown","20fb64f6":"markdown","9435cda4":"markdown","18443ad0":"markdown","ddcc083e":"markdown","bce38e56":"markdown","fcd2daca":"markdown"},"source":{"711cbeae":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set()\nfrom plotly.offline import init_notebook_mode, iplot \nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport pycountry\npy.init_notebook_mode(connected=True)\nimport folium \nfrom folium import plugins\nfrom plotly.subplots import make_subplots\nfrom wordcloud import WordCloud, STOPWORDS\nimport plotly.express as px\nimport operator","d3ba5f33":"df_20=pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\ndf_20.drop(df_20.index[0],inplace=True)\ndf_20.head(2)\ndf_19=pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\",encoding='latin-1')\ndf_19.drop(df_19.index[0],inplace=True)","8578b407":"df_20.head()","e11a5df2":"df_19.head()","1e6f382d":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(20.0,10.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n     \nplot_wordcloud(df_20[\"Q5\"].dropna(), title=\"Current Role of Participating people in 2020\")","99da26b6":"Age_19 = df_19['Q1'].value_counts().reset_index()\nAge_20 = df_20['Q1'].value_counts().reset_index()\n\nspecs =[[{'type':'domain'},{'type':'domain'}]]\nfig = make_subplots(rows=1, cols=2, specs=specs)\nfig.add_trace(go.Pie(labels=Age_19['index'],values=Age_19['Q1'],name=\"2019\",hole=0.4,domain={'x': [0,0.46]}), 1, 1)\nfig.add_trace(go.Pie(labels=Age_20['index'],values=Age_20['Q1'],name=\"2020\",hole=0.4,domain={'x': [0,0.46]}),1,2)\n#fig.add_trace(go.Pie(labels=Age_20['index'],values=Age_20['Q1'],name=\"2020\",hole=0.4,domain={'x': [0,0.46]}),1,3)\n\n\nfig.update_traces(hole=.6, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Age Gropu across the years\",\n   annotations=[dict(text='2019', x=0.18, y=.550, font_size=20, showarrow=False),\n                dict(text='2020', x=0.80, y=0.55, font_size=20, showarrow=False),\n                #dict(text='2020', x=0.89, y=0.55, font_size=20, showarrow=False)\n               ])\n\nfig.show()","1f8b0f84":"Age=Age_19.merge(Age_20,on='index')\nAge.rename(columns={'Q1_x': '2019'})\nAge","a50d97f3":"fig = go.Figure()\nfig.add_trace(go.Bar(x=Age['index'].values,\n                y=Age['Q1_x'].values,\n                name='2019',\n                marker_color='#009688'\n                ))\nfig.add_trace(go.Bar(x=Age['index'].values,\n                y=Age['Q1_y'].values,\n                name='2020',\n                marker_color='#83d0c9'\n                ))\nfig.update_layout(\n    title='Age_Distribution',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Age_Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15,\n    bargroupgap=0.1 \n)\nfig.show()","93b67da1":"Gender_19 = df_19['Q2'].value_counts().reset_index()\nGender_20 = df_20['Q2'].value_counts().reset_index()\n\nspecs =[[{'type':'domain'},{'type':'domain'}]]\nfig = make_subplots(rows=1, cols=2, specs=specs)\n\nfig.add_trace(go.Pie(labels=Gender_19['index'],values=Gender_19['Q2'],name=\"2019\",hole=0.4,domain={'x': [0,0.46]}),1,1)\nfig.add_trace(go.Pie(labels=Gender_20['index'],values=Gender_20['Q2'],name=\"2020\",hole=0.4,domain={'x': [0,0.46]}),1,2)\n\n\nfig.update_traces(hole=.6, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Gender across the years\",\n   annotations=[\n                dict(text='2019', x=0.19, y=0.55, font_size=20, showarrow=False),\n                dict(text='2020', x=0.80, y=0.55, font_size=20, showarrow=False)])\n\nfig.show()","f1428231":"df_20['Q2'].replace({'Man':'Male','Woman':'Female'},inplace=True)\ndf_gender_count_20 = pd.DataFrame({'Gender':df_20[\"Q2\"].value_counts().index, \n                               'Count':df_20[\"Q2\"].value_counts().values}).sort_values(\"Gender\",ascending=False)\n\ndf_gender_count_19 = pd.DataFrame({'Gender':df_19[\"Q2\"].value_counts().index, \n                               'Count':df_19[\"Q2\"].value_counts().values}).sort_values(\"Gender\",ascending=False)\nfig = make_subplots(rows=2, cols=1, specs=[[{'type':'xy'}],\n                                          [{'type':'xy'}]], subplot_titles=('Gender_based_Participation_20','Gender_based_Participation_19'))\n        \nfig.add_trace(\n    go.Bar(x=df_gender_count_20[\"Count\"],\n                     y=df_gender_count_20['Gender'],\n                     marker_color='LightSkyBlue',\n                     marker_line_color='#536872',\n                     marker_line_width=1.5, \n                     opacity=0.6,\n                     orientation='h'),row=1, col=1)\nfig.add_trace(\n    go.Bar(x=df_gender_count_19[\"Count\"],y=df_gender_count_19[\"Gender\"],\n            marker_color='red',\n            marker_line_color='#536878',\n            marker_line_width=1.5, \n            opacity=0.6,\n            orientation='h'),row=2, col=1)\nfig.update_layout(\n    title_text=\"Gender\",\n    height=600, width=600, showlegend=False)\n\nfig.update_traces(marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\n\nfig.show()","015cd48f":"country_wise_distribution_19=df_19['Q3'].value_counts()\nfig = px.choropleth(country_wise_distribution_19.values, locations=country_wise_distribution_19.index,\n                    locationmode='country names',\n                    color=country_wise_distribution_19.values,\n                    color_continuous_scale=px.colors.sequential.Jet)\nfig.update_layout(title=\"Country_wise Distribution of Data Scientists-2019\")\nfig.show()\n\ncountry_wise_distribution_20=df_20['Q3'].value_counts()\nfig = px.choropleth(country_wise_distribution_20.values, locations=country_wise_distribution_20.index,\n                    locationmode='country names',\n                    color=country_wise_distribution_20.values,\n                    color_continuous_scale=px.colors.sequential.dense)\nfig.update_layout(title=\"Country_wise Distribution of Data Scientists-2020\")\nfig.show()","57ba98f5":"count_20 = df_20['Q3'].value_counts().head(25).reset_index().rename(columns={'index': 'Country','Q3':'2020'})\ncount_19 = df_19['Q3'].value_counts().head(25).reset_index().rename(columns={'index': 'Country','Q3':'2019'})\nTop_25_Countries=count_19.merge(count_20,on='Country')\nTop_25_Countries","9c835bbf":"fig = go.Figure()\nfig.add_trace(go.Bar(x=Top_25_Countries['Country'].values,\n                y=Top_25_Countries['2019'].values,\n                name='2019',\n                marker_color='#854442'\n                ))\nfig.add_trace(go.Bar(x=Top_25_Countries['Country'].values,\n                y=Top_25_Countries['2020'].values,\n                name='2020',\n                marker_color='#be9b7b'\n                ))\nfig.update_layout(height=900,\n    title='Country_Yearly_Contribution',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Participation_Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=.5,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, \n    bargroupgap=0.2 \n)\nfig.show()","1aa7f9d8":"gkk = df_20.groupby(['Q3', 'Q5'])\nkkg = df_19.groupby(['Q3', 'Q5'])\ngkk.get_group(('India','Data Scientist'))\ngkk_20_india=gkk.get_group(('India','Data Scientist'))\ngkk_20_usa=gkk.get_group(('United States of America','Data Scientist'))\n\nkkg.get_group(('India','Data Scientist'))\nkkg_19_india=kkg.get_group(('India','Data Scientist'))\nkkg_19_usa=kkg.get_group(('United States of America','Data Scientist'))\n\nfig = make_subplots(rows=2, cols=2, specs=[[{'type':'xy'}, {'type':'xy'}],\n                                          [{'type':'xy'}, {'type':'xy'}]], subplot_titles=('India_2020', 'India_2019','USA_2020','USA_2019'))\n\nfig.add_trace(\n    go.Bar(x=gkk_20_india['Q1'].dropna().value_counts().index, y=gkk_20_india['Q1'].dropna().value_counts().values, name=\"INDIA_2020\"),\n    row=1, col=1)\n\nfig.add_trace(\n    go.Bar(x=kkg_19_india[\"Q1\"].dropna().value_counts().index, y=kkg_19_india[\"Q1\"].dropna().value_counts().values, name=\"India_2019\"),\n    row=1, col=2)\n\nfig.add_trace(\n    go.Bar(x=gkk_20_usa['Q1'].dropna().value_counts().index, y=gkk_20_usa['Q1'].dropna().value_counts().values, name=\"USA_2020\"),\n    row=2, col=1)\n\nfig.add_trace(\n    go.Bar(x=kkg_19_usa[\"Q1\"].dropna().value_counts().index, y=kkg_19_usa[\"Q1\"].dropna().value_counts().values, name=\"USA_2019\"),\n    row=2, col=2)\nfig.update_layout(\n    title_text=\"Data Scientist Age\",\n    height=600, width=990, showlegend=False)\n\nfig.update_traces(marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6) \n                 \nfig.show()","12a51afe":"degree_19=df_19['Q4'].value_counts().dropna().index\ndegree_20=df_20['Q4'].value_counts().dropna().index\n\nwordcloud2 = plot_wordcloud(degree_20, title=\"Education Qualification in 2020\")\nwordcloud3 =plot_wordcloud(degree_19, title=\"Education Qualification in 2019\")","d9a5b9b9":"\ndf_19['Q4'].replace({'Master\u00e2\u0080\u0099s degree':'Master\u2019s degree','Bachelor\u00e2\u0080\u0099s degree':'Bachelor\u2019s degree'},inplace=True)\ndegree_20 = df_20['Q4'].value_counts().reset_index().rename(columns={'index': 'Education','Q4':'2020'})\ndegree_19 = df_19['Q4'].value_counts().reset_index().rename(columns={'index': 'Education','Q4':'2019'})\nEducation=degree_19.merge(degree_20,on='Education')\nEducation","c9a67c16":"fig = go.Figure()\nfig.add_trace(go.Bar(x=Education['Education'].values,\n                y=Education['2019'].values,\n                name='2019',\n                marker_color='#3385c6'\n                ))\nfig.add_trace(go.Bar(x=Education['Education'].values,\n                y=Education['2020'].values,\n                name='2020',\n                marker_color='#7f8e9e'\n                ))\nfig.update_layout(\n    title='Education_Yearly_Contribution',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Degree_Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=.5,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, \n    bargroupgap=0.2\n)\nfig.show()","1d73eebf":"media_20={} # dictionary is seems to be very helpful for analyzing where we have more than one choice for selection.\nfor i in range(10):\n    value=df_20['Q39_Part_'+str(i+1)].value_counts().values[0]\n    text=df_20['Q39_Part_'+str(i+1)].value_counts().index[0]\n    media_20[text]=value\nmedia_20=dict(sorted(media_20.items(), key=operator.itemgetter(1)))\nmedia_19={}\nfor i in range(10):\n    value=df_19['Q12_Part_'+str(i+1)].value_counts().values[0]\n    text=df_19['Q12_Part_'+str(i+1)].value_counts().index[0]\n    media_19[text]=value\nmedia_19=dict(sorted(media_19.items(),key=operator.itemgetter(1)))\n\nx_2020=list(media_20.keys())\ny_2020=list(media_20.values())\nx_2019=list(media_19.keys())\ny_2019=list(media_19.values())\n\nfig = make_subplots(\n    rows=1, cols=2,\n    specs=[[{\"type\": \"xy\"},{\"type\": \"domain\"}]],\n)\n\nfig.add_trace(go.Bar(x=x_2020, y=y_2020),\n              row=1, col=1)\nfig.add_trace(go.Pie(labels=x_2020,values=y_2020),\n              row=1, col=2)\n\nfig.update_layout(height=800, showlegend=False,title=\"Media sources in 2020\")\nfig.show()","2c035fd8":"fig = make_subplots(\n    rows=1, cols=2,\n    specs=[[{\"type\": \"xy\"},{\"type\": \"domain\"}]],\n)\n\nfig.add_trace(go.Bar(x=x_2019, y=y_2019),\n              row=1, col=1)\nfig.add_trace(go.Pie(labels=x_2019,values=y_2019),\n              row=1, col=2)\n\nfig.update_layout(height=800, showlegend=False,title=\"Media sources in 2019\")\nfig.show()","a1764131":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[16, 8])\nwordcloud1 = WordCloud( background_color='White',\n                        width=600,\n                        height=500).generate_from_frequencies(media_20)\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Media_Sources-2020',fontsize=20);\n\nwordcloud2 = WordCloud( background_color='White',\n                        width=600,\n                        height=500).generate_from_frequencies(media_19)\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Media_Sources-2019',fontsize=20);\n\n","cb1a5e5f":"fig = make_subplots(\n    rows=1, cols=2,\n    specs=[[{\"type\": \"domain\"},{\"type\": \"domain\"}]],subplot_titles=('Media_2020', 'Media_2019')\n\n)\nfig.add_trace(go.Pie(labels=x_2020,values=y_2020),\n              row=1, col=1)\nfig.add_trace(go.Pie(labels=x_2019,values=y_2019),\n              row=1, col=2)\n\n\nfig.update_layout(height=800,showlegend=False)\nfig.show()","4e92ce12":"df_20['Q37_Part_3'].replace({'Kaggle Learn Courses':'Kaggle'},inplace=True)\ndf_20['Q37_Part_10'].replace({'University Courses (resulting in a university degree)':'University Courses'},inplace=True)\ndf_20['Q37_Part_9'].replace({'Cloud-certification programs (direct from AWS, Azure, GCP, or similar)':'Cloud-certification'},inplace=True)\ndf_19['Q13_Part_6'].replace({'Kaggle Courses (i.e. Kaggle Learn)':'Kaggle'},inplace=True)\ndf_19['Q13_Part_10'].replace({'University Courses (resulting in a university degree)':'University Courses'},inplace=True)\n\n\nmooc_20={} \nfor i in range(10):\n    value=df_20['Q37_Part_'+str(i+1)].value_counts().values[0]\n    text=df_20['Q37_Part_'+str(i+1)].value_counts().index[0]\n    mooc_20[text]=value\nmooc_20=dict(sorted(mooc_20.items(), key=operator.itemgetter(1)))\n\nmooc_19={} \nfor i in range(10):\n    value=df_19['Q13_Part_'+str(i+1)].value_counts().values[0]\n    text=df_19['Q13_Part_'+str(i+1)].value_counts().index[0]\n    mooc_19[text]=value\nmooc_19=dict(sorted(mooc_19.items(), key=operator.itemgetter(1)))\n\n\n\nx_2020=list(mooc_20.keys())\ny_2020=list(mooc_20.values())\nx_2019=list(mooc_19.keys())\ny_2019=list(mooc_19.values())\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=x_2020,\n                y=y_2020,\n                name='2020',\n                marker_color='#3d2352'\n                ))\nfig.add_trace(go.Bar(x=x_2019,\n                y=y_2019,\n                name='2019',\n                marker_color='#8874a3'\n                ))\n\nfig.update_layout(height=500, \n    title='MOOC Courses ',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Course_Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, \n    bargroupgap=0.1 \n)\n#fig.update_layout(height=900, showlegend=False)\nfig.show()\n","d7b7ee7f":"fig = go.Figure()\nfig.add_trace(go.Bar(x=df_20['Q6'].value_counts().index,\n                y=df_20['Q6'].value_counts().values,\n                name='2020',\n                marker_color='#8d5524'\n                ))\nfig.add_trace(go.Bar(x=df_19['Q15'].value_counts().index,\n                y=df_19['Q15'].value_counts().values,\n                name='2019',\n                marker_color='#f1c27d'\n                ))\nfig.update_layout(\n    title='Coding_Experience_Distribution',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Coding_Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, \n    bargroupgap=0.1 \n)\nfig.show()","c5829c7c":"lan_19,lan_20={},{}\nfor i in range(10):\n    value_19=df_19['Q18_Part_'+str(i+1)].value_counts().values[0]\n    text_19=df_19['Q18_Part_'+str(i+1)].value_counts().index[0]\n    lan_19[text_19]=value_19\n    value_20=df_20['Q7_Part_'+str(i+1)].value_counts().values[0]\n    text_20=df_20['Q7_Part_'+str(i+1)].value_counts().index[0]\n    lan_20[text_20]=value_20\nlan_19=dict(sorted(lan_19.items(), key=operator.itemgetter(1)))\nlan_20=dict(sorted(lan_20.items(), key=operator.itemgetter(1)))\n\nx_lan_2020=list(lan_20.keys())\ny_lan_2020=list(lan_20.values())\nx_lan_2019=list(lan_19.keys())\ny_lan_2019=list(lan_19.values())\n\nfig = make_subplots(\n    rows=3, cols=2,\n    specs=[[{\"type\": \"xy\"},{\"type\": \"xy\"}],[ {\"type\": \"scatter\",\"colspan\":2},None],\n          [{\"type\": \"domain\"},{\"type\": \"domain\"}]],\n    subplot_titles=('Programming_Languages-2020','Programming_Languages-2019','Recommendation of Programming_Languages'))\n\nfig.add_trace(go.Bar(y=x_lan_2020, x=y_lan_2020,orientation='h'),\n              row=1, col=1)\nfig.add_trace(go.Bar(y=x_lan_2019, x=y_lan_2019,orientation='h'),\n              row=1, col=2)\nfig.add_trace(go.Scatter(x=df_20['Q8'].dropna().value_counts().index,y=df_20['Q8'].value_counts().values),row=2,col=1)\nfig.add_trace(go.Scatter(x=df_19['Q19'].dropna().value_counts().index,y=df_19['Q19'].value_counts().values),row=2,col=1)\n\nfig.add_trace(go.Pie(labels=df_20['Q8'].dropna().value_counts().index,values=df_20['Q8'].dropna().value_counts().values),\n              row=3, col=1)\nfig.add_trace(go.Pie(labels=df_19['Q19'].dropna().value_counts().index,values=df_19['Q19'].dropna().value_counts().values),\n              row=3, col=2)\n\nfig.update_layout(height=900, showlegend=False)\nfig.show()","88c843cc":"ide_20,ide_19=[],[]\nide_val_20,ide_val_19=[],[]\nfor i in range(10):\n    value_20=df_20['Q9_Part_'+str(i+1)].value_counts().values[0]\n    text_20=df_20['Q9_Part_'+str(i+1)].value_counts().index[0]\n    value_19=df_19['Q16_Part_'+str(i+1)].value_counts().values[0]\n    text_19=df_19['Q16_Part_'+str(i+1)].value_counts().index[0]\n    ide_20.append(text_20)\n    ide_val_20.append(value_20)\n    ide_19.append(text_19)\n    ide_val_19.append(value_19)\ndata_ide_tuples_20 = list(zip(ide_20,ide_val_20))\ndata_ide_tuples_19 = list(zip(ide_19,ide_val_19))\n\n\ndf19=pd.DataFrame(data_ide_tuples_19, columns=['IDE','Count_2019'])\ndf20=pd.DataFrame(data_ide_tuples_20, columns=['IDE','Count_2020'])\ndf_ide=df19.merge(df20,on='IDE')\ndf_ide","f80c58f0":"vis_20,vis_19=[],[]\nvis_val_20,vis_val_19=[],[]\nfor i in range(10):\n    value_20=df_20['Q14_Part_'+str(i+1)].value_counts().values[0]\n    text_20=df_20['Q14_Part_'+str(i+1)].value_counts().index[0]\n    value_19=df_19['Q20_Part_'+str(i+1)].value_counts().values[0]\n    text_19=df_19['Q20_Part_'+str(i+1)].value_counts().index[0]\n    vis_20.append(text_20)\n    vis_val_20.append(value_20)\n    vis_19.append(text_19)\n    vis_val_19.append(value_19)\ndata_vis_tuples_20 = list(zip(vis_20,vis_val_20))\ndata_vis_tuples_19 = list(zip(vis_19,vis_val_19))\ndata_vis_tuples_20,data_vis_tuples_20\n\ndf19=pd.DataFrame(data_vis_tuples_19, columns=['VIS','Count_2019'])\ndf20=pd.DataFrame(data_vis_tuples_20, columns=['VIS','Count_2020'])\ndf_vis=df19.merge(df20,on='VIS')\ndf_vis","ed28897e":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"scatter\"},{\"type\": \"scatter\"}]],subplot_titles=('Integrated Development Environments','Visualization Library'))\nfig.add_trace(go.Scatter(\n    x=df_vis['VIS'].values,\n    y=df_vis['Count_2019'].values,\n    name = 'Vis_2019'\n),row=1,col=2)\nfig.add_trace(go.Scatter(\n    x=df_vis['VIS'].values,\n    y=df_vis['Count_2020'].values,\n    name='Vis_2020',\n),row=1,col=2)\n\n\nfig.add_trace(go.Scatter(\n    x=df_ide['IDE'].values,\n    y=df_ide['Count_2019'].values,\n    name = 'Ide_2019'\n),row=1,col=1)\nfig.add_trace(go.Scatter(\n    x=df_ide['IDE'].values,\n    y=df_ide['Count_2020'].values,\n    name='Ide_2020',\n),row=1,col=1)\n\nfig['layout'].update( height=500,width=1000)\npy.offline.iplot(fig)\n","fe69eb54":"df_19['Q21_Part_4'].replace({'None \/ I do not know':'None'},inplace=True)\nhrd_20,hrd_19=[],[]\nhrd_val_20,hrd_val_19=[],[]\nfor i in range(3):\n    value_20=df_20['Q12_Part_'+str(i+1)].value_counts().values[0]\n    text_20=df_20['Q12_Part_'+str(i+1)].value_counts().index[0]\n    hrd_20.append(text_20)\n    hrd_val_20.append(value_20)\nfor i in range(5):\n    value_19=df_19['Q21_Part_'+str(i+1)].value_counts().values[0]\n    text_19=df_19['Q21_Part_'+str(i+1)].value_counts().index[0]\n    hrd_19.append(text_19)\n    hrd_val_19.append(value_19)\n    \ndata_hrd_tuples_20 = list(zip(hrd_20,hrd_val_20))\ndata_hrd_tuples_19 = list(zip(hrd_19,hrd_val_19))\ndata_hrd_tuples_20,data_hrd_tuples_19\n\ndf19=pd.DataFrame(data_hrd_tuples_19, columns=['HRD','Count_2019'])\ndf20=pd.DataFrame(data_hrd_tuples_20, columns=['HRD','Count_2020'])\ndf_hrd=df19.merge(df20,on='HRD')\ndf_hrd","fcfc5f06":"df_20['Q15'].replace({'Under 1 year':'< 1 years'},inplace=True)\nTpu_index_20=df_20['Q13'].value_counts().index\nTpu_values_20=df_20['Q13'].value_counts().values\n\nTpu_index_19=df_19['Q22'].value_counts().index\nTpu_values_19=df_19['Q22'].value_counts().values\n\nfig = make_subplots(\n    rows=2, cols=2,\n    specs=[[{\"type\": \"xy\"},{\"type\": \"xy\"}],\n         \n          [ {\"type\": \"scatter\",\"colspan\":2},None]],subplot_titles=(\"TPU_USUAGE\",\"ML_METHODS_EXPEROENCE\",\"Specialized Hardware\")\n)\n\nfig.add_trace(go.Bar(x=Tpu_index_20,\n                y=Tpu_values_20,\n                name='2020',\n                marker_color='rgb(55, 83, 109)'\n                ),row=1, col=1)\nfig.add_trace(go.Bar(x=Tpu_index_19,\n                y=Tpu_values_20,\n                name='2019',\n                marker_color='rgb(26, 118, 255)'\n                ),row=1, col=1)\n\n\nfig.add_trace(go.Bar(x=df_20['Q15'].value_counts().index,\n                y=df_20['Q15'].value_counts().values,\n                name='2020',\n                marker_color='#4f5b66'\n                ),row=1, col=2)\nfig.add_trace(go.Bar(x=df_19['Q23'].value_counts().index,\n                y=df_19['Q23'].value_counts().values,\n                name='2019',\n                marker_color='#65737e'\n                ),row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    x=df_hrd['HRD'].values,\n    y=df_hrd['Count_2019'].values,\n    name = 'HRD_2019'\n),row=2,col=1)\nfig.add_trace(go.Scatter(\n    x=df_hrd['HRD'].values,\n    y=df_hrd['Count_2020'].values,\n    name='HRD_2020',\n),row=2,col=1)\n\n\n\nfig.update_layout(height=800, showlegend=False,\n    title='Experience_Distribution',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Count',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, \n    bargroupgap=0.1 \n)\n#fig.update_layout(height=900, showlegend=False)\nfig.show()","51052764":"1. Coursera is one of best plateform for learning data science in deep way but in 2020 peoples focus on cloud-certification which was missing in 2019\n2. Udemy attracts people due to sales and looks like maintained its position almost same in both of the years and same for kaggle\n3. Datacamp,Udacity,edx were quite famous in 2019 compared to 2020 whereas Linkedin is growing in 2019.","77e473f4":"<a id=\"media\"><\/a>\n# 7.1 Favourite media Sources:","4714f598":"<a id=\"section-one-three\"><\/a>\n# 3.Dataset:\nTo check my assumption that data sciemce is growing in last two years, I am using 2019 and 2020 years dataset in this notebook. We know it's fourth time Kaggle is conducting this survey,I try to focus on the latest information, things which were in trend and the changes happened in the last two years in the data science.In this coming story of these two  years,I will compare and come up with some interesting insights and facts.\n\nThe both dataset yu can found here.\n\n2020 Kaggle ML & DS Survey: https:\/\/www.kaggle.com\/c\/kaggle-survey-2020\/data\n\n2019 Kaggle ML & DS Survey: https:\/\/www.kaggle.com\/c\/kaggle-survey-2019\/data\n","58ba2675":"> It's true that female contribution is incresing as Data science field is growing and i hope we can see more contribution in coming years.\nIt's our responsibility also to make this data balanced by doing some campaign where we are totally focus to female group, we have to motivated our women to come up \n! Common girls","5719c00c":"<a id=\"ide\"><\/a>\n# 8.3 Popular IDE and visualization library:","26d4e59d":"<a id=\"code\"><\/a>\n# 8.1.Coding experience:","d981b0aa":"<a id=\"(section-six)\"><\/a>\n# 9.Data scientist on there Regualr basis:\nIn this section we tries to see usage of machine learning methods with Hardwares in both of years\n","afacb33c":"1. In 2019 also we can see Kaggle attracts a lot of people due to its amazing kernels and resources.\n2. Youtube is not much popular in last year where Blogs play an important role previously also.\n3. Hacker news was also a favourite media source in 2019.","bcc966b3":"1. In Both of the years Python won the race as well as it is highly recommended from data scientist to learn before start journey of data science.\n2. Data science is all about data so we should know how to handle data and for that knowing about database is necessary and sql is second winner in this race but not that much recommended compare to R. We know beauty of R so python and R are highly recommended followed by sql to start Data sciecnce\n3. Still fights are going between R and Python but in 2020 peoples are more using python.\n4. Yes it is true that C++ is low latency language and fast compared to python but knowing python is almost good for data scientist.\n5. Julia is new entry in field of data science and hope it will come in competition soon with python because peoples are telling julia is fast in statistical calculation compared to python","c34edd6d":"# **WORK IN PROGRESS**","60ae93c1":"1. Master's people contibution was maximum in both the years but 2020 not good for master's people as this number is decreased compared to 2019.\n2. Bachelor's people were mostly young people and their contribution is really appreciated in 2020 as compared to 2019.\n3. We can easily observe professional degree people were increasing in data sciene and the mostly doctroal degree loosing their interest in 2020 as compared to 2019.","213de026":"1.  Young talent is coming from India in both of years compared to USA as mostly data scientist age in USA is 25-34 whereas from India we can see the peoples from 18-30 years are participating. ","33051bb9":"1. Kaggle is a great source of learning which we can see from 2020 years of data, From the all over world there are great data scientist who share their work in this plateform and from where we can easily learn.\n2. Ohh It's interesting to see youtube gaining popularity in Data science (covid may be one reason) as people never stops learning and through youtube we easily can share and spread knowledge across the world.\n3. Blogs play an important role to understand many aspects of DATA SCIENCE.\n4. Podcasts is pretty new entry and we use to enjoy chai time episods quite well and also we come to across how someone won the compitition and what kind of approached they followed.","f0586065":"<a id=\"section-one-four\"><\/a>\n# 4.Approach:\n\n1. I try to keep myself on one library known as \"PLOTLY\" for visualization and this is famous for it's intersting and amazing plots \n2. In this notebook,I try to divide whole survey analysis in different subsets like Basic analysis contains Age group, country, degree,etc.h\n3. Once we know all the information regarding characterstics of Data scientist we try to analyze what their preferences on regular basis in two years.\n4. We will get to know \"Is really Data science growing\" at the end of this notebook \n5. I will update this notbook as we will move ahead in this competition so please stay tuned!.\n\n","92e8e7b1":"<a id=\"load\"><\/a>\n# 5.1 Load library:","19a94051":"1. Kaggle maintained to attract people for learning Data science from its kernels in both years.\n2. People are more interesting to watch videos from youtube and learn compare to read some good blogs in 2020.\n3. Podcasts are pretty new and amazing resource to know about how others are walking in this journey\n4. Slack communities are growing in 2020 and we hope we will have great Courses Forums in future. ","ad672104":"<a id=\"section-five\"><\/a>\n# 8.Common Practices of Data Scientist:\n![image.png](attachment:image.png)\nIn this section we going to see what are the common practices Data scientist followed in last two years .Which programming language,visualization libraries, IDE peoples followed on the regular basis of their work.","9668ccd6":"<a id=\"section-four\"><\/a>\n# 7. Preferencies of Data Scientist:\n\nIn this section of notebook I try to analyze what common preferences data scientist have in last two years which can be very helpful for those peoples who are going to start amazing journey in this field.There are lot of media resources we know which are quite popular so let's  compare data and observe which media resource play a major role in field of Data science.when we talk about media resources we have another thing in our mind from where we can learn data science and for this what are MOOC courses avilabLe and which mooc courses are in trend, also we are going to see which plateform data scientist are choosing to show their work.\nso Let's begin!","3cf22630":"<a id=\"degree\"><\/a>\n# Education:\n![image.png](attachment:image.png)\n","62da006f":"Many peoples who are the beginners like me have a question to become data scientist what we need to study.So in this section we tries to see what the education background of data scientist in 2019 and 2020","6db49d63":"<a id=\"country\"><\/a>\n# Top 25 Countries:\n\nlet's examine which part of world is most active to producing Data scientist or let's say from which part of people making there contribution in this field.\n","88e8ac7a":"> By looking this above visualization it's become clear that Data science field based on gender equality is highly imbalanced in nature.Yes it is true that contribution of female side increases in 2020 compared to 2019 but not upto the mark.\nWe have to encourage the female group to take participiation in the data science and share their knowledge.","05bd598e":"1. Numbers of peoples were increased of having 3-5 years of experience in 2020 and peoples who have less than one year of experience are decreased that is interesting because having knowledge about Data is not sufficeint for us to become data scientist , we also should know how to code also.\n2. Maximum number of peoples have 2-5 years of experience whereas seniority level is increasing in 2020 compared to 2019","5a8c9f5b":"<a id=\"gender\"><\/a>\n# Participation based on Gender:\n\n![image.png](attachment:image.png)","4a27912c":"1. As Data science is growing peoples start using TPU but in very less numbers in both of years, still peoples are using CPU for there work \n2. When we are talking about TPU, another term GPU also comes in our mind which are uses by people more compared to TPU.\n3. Looks like very young peoples are entering in Machine learning work and having experience of 1-3 years, still we have to progress in this field.\n4. There is less number of seniors who used ml methods in 20+ years upto 2020.\n \nSo yes we have to put more efforts to raise data science in coming time","06027d59":"Yes we can see Software and Research people are in trend till now but in parallel we can observe Machine learning in our word cloud is also in trend.We will analyze further what Data scientist common practices and how much our title of notebook hold in this compitition.","9422405c":"<a id=\"read\"><\/a>\n# 5.2 Load and Read Dataset:","aca9d76a":"<a id=\"section-one-two\"><\/a>\n# 2.Objective:\nObjective of this challange is need to tell a tell a data story data science community represented in this survey, through a combination of both narrative and visulaization techniques.This is basically a Analytics type of challange and we have to focus on more about a  \u201cstory\u201d which could be defined any number of ways. In this challenge we going to analyze some best practices and preference of data scientist whloe over the world also we encounter them based on characterstics in deep and some good combination of plots .In this notebook we  tries to see the title of notebook is valid or noth. At the end of this notebook we comes up some good recommendation from this survey which is really helpful to beginners like me.\n","6a0ebe1e":"<a id=\"section-one-one\"><\/a>\n# 1.Introduction:\n**DO YOU FEEL DATA SCIENCE IS GROWING NOWDAYS**\n\n> In the past few years we can feel there is too much focus on data in every industry. Everything what we do ,what we talk in our surrounding is becoming Data.Data is integral part of every decision making process and it helps to resolve complex problems. When it comes to analyze and use historical data and  when some community makes effort to understand how to deal with data, this field  becomes more interesting.\n> Kaggle makes this task easy to understand how data can be used to tell story.\n\nThis is fourth year when Kaggle conducting same experiment which is truely comprenhensive of the state of Data science and Machine learning.\n\nIn this notebook we are going to see what Data scientist are doing in this field all over the world.","d6d97b26":"> Young people participation is increasing as the field of Data Science is growing day by day that is pretty amazing things for us,but the participation of senior class is matter in almost all the works.\n1. Now if we see the trand in both years there are maximum number of peoples coming from age group 25-29,but trend in 2020 contains more participation from young age group of class 18-21(Countries like india have college going students of this age group) while keeping in mind of seniority level, there was less participation in 2020 compared to 2019.\n2. In 2020 we can see as the participation of 25-29 years age group decreased but 22-24 and 18-21 was increased compare to year 2019.\n\nAs the time will change ,I think there will be more young people participation.\nOverall 20-35 peoples are more active in participation.","e4bc7604":"1.  [INRODUCTION](#section-one-one)\n2. [OBJECTIVE](#section-one-two)\n3. [DATASET](#section-one-three)\n4. [APPROACH](#section-one-four)\n5. [Basic exploratory data analysis](#section-two)\n    - [5.1 Load library](#load)\n    - [5.2 Read Dataset](#read-dataset)\n6. [Characterstics of People](#section-three)\n     -  [Age Distribution](#age)\n     - [Participation based on Gender](#gender)\n     - [Top 25 countries](#country)\n     - [Education](#education)\n7. [Preferences of Data Scientist](#section-four)\n     - [7.1 Favourite Media Sources](#media)\n     - [7.2 MOOC Courses](#mooc)\n     - [7.3 Plateform types for Projects](#plt)\n8. [Common Practices of Data Scientist](#section-five)\n     - [8.1 Coding Experience](#code)\n     - [8.2 Programming Languages](#lan)\n     - [8.3 Popular IDE and Visualization](#ide)\n     - [8.4 Hosted Notebooks](#hosted)\n9. [Data scientist on there Regualr basis](#section-six)\n     - [Hardware usuage and Ml experience](#ml-ex)\n     \n* [Conclusion](#section-three)","67fe04e4":"1. Most of the peoples are coming from INDIA and USA but compared to 2019 USA somehow loosing it's grab to produce data scientist where india is one of the famous county which producing more and more data scientist.\n2. There was very less participation from African Sub-continent and some other countries which has very low participation are grouped others in both years.\n3. Let's see top 25 countries which were mostly active and tried to capture their trend in two years.","85475c41":"<a id=\"mooc\"><\/a>\n# 7.2 MOOC COURSES:\nwhen we are beginner in data science, we always used to search some good sources of materials from which we can learn fasts.So in this subsection of this notebook we going to see which mooc courses are trending in data science.","41c588b9":"1. As most of peoples are using Python so it's obvious that jupyter won the race in popular ide whereas pycharm is using more in 2020 compared to 2019 and Rstudio loosed its grab in 2020.\n2. There are amazing library for visualization known as Plotly(I am using this) but there is less awareness in peoples as in 2020 again Matplotlib won the race\n3. There is slight increase in number of peoples who are using matplotlib as well as seaborn in 2020 as compared to 2019.","bea6cdba":"<a id=\"plateform\"><\/a>\n# 7.3 Plateforms types for Data science Projects:\nonce we learn something we are intersting to share with others people and for this purpose which comes to be famous plateform for data science projects ,we going to see in this section","20fb64f6":"<a id =\"section-two\" ><\/a>\n# Basic exploratory data analysis:\nIn this section of notebook we are loading some imporatant libraries to handle data and visualization. ","9435cda4":"1. \n2. Where as in 2020 the number of countries increased which have very low contribution means Other participation increased in 2020\n3. Countries like Japan, Russia tried to maintain there contribution\n4. Nigeria, Indonesia are the countries from  where contribution is increasing.","18443ad0":"<a id=\"age\"><\/a>\n# Age Distribution:\n![image.png](attachment:image.png)\n\nIt's become imporatnt to know from which age group of people are participating in both of years and how there disribution changes.","ddcc083e":"<a id=\"age-country\"><\/a>\n# Data Scientist Age in INDIA AND USA:","bce38e56":"![image.png](attachment:image.png)","fcd2daca":"<a id=\"Programming language\"><\/a>\n# 8.2 Programming languages:"}}