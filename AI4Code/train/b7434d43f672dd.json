{"cell_type":{"a66adb4c":"code","b26d5cd6":"code","de1238af":"code","410ea273":"code","83f5bec7":"code","2690af5b":"code","86505f44":"code","6e295628":"code","b1819c50":"code","ffca4b5e":"code","95dc88a5":"code","f7cfe127":"code","c226bec8":"code","dfdff165":"code","89e9daba":"code","f86de898":"code","584d74e5":"code","b3d704d0":"code","dfe3199a":"code","b967c0bb":"code","1c01f694":"code","8e1819bd":"code","8574f9e9":"code","cf5f31f6":"code","0ee0b8b9":"code","3ad9df81":"code","33aec24a":"code","59d793fb":"code","cd314144":"code","20d6283b":"code","1648a17d":"code","dad5deff":"code","30f4b94e":"code","2ecf2548":"code","0b16af3f":"code","dd50645b":"code","c813b052":"code","ab4a4129":"code","a5af4dcb":"markdown","d193feec":"markdown","5988fbf3":"markdown","e422aa11":"markdown","c546428d":"markdown","695fbdd1":"markdown","788e4300":"markdown","ab418463":"markdown","72bc3ad1":"markdown","a5355917":"markdown","c38b40e6":"markdown","5e4fa415":"markdown","421304b2":"markdown","8be1e5cc":"markdown","c6151362":"markdown","9e00a3ad":"markdown","a1791813":"markdown","3b169a6a":"markdown","fb242bd4":"markdown","f6f12175":"markdown","e9537ed8":"markdown","54e5e6c4":"markdown","ce04f827":"markdown","779986e0":"markdown","538f0c71":"markdown","a2eb66ba":"markdown","98f2ab76":"markdown","c832ab57":"markdown","673fa1fd":"markdown","8d001fad":"markdown","1b9a58b8":"markdown","4cafae4b":"markdown","88392f96":"markdown","515c96c3":"markdown","dd5a9bc6":"markdown","77e3da26":"markdown","f7bcf311":"markdown","6bfc6bbf":"markdown"},"source":{"a66adb4c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore')\nfrom IPython.display import display, HTML\n#preprocess\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom imblearn.over_sampling import SMOTE\n\n#model selection\nfrom sklearn.model_selection import train_test_split , GridSearchCV, cross_val_score, cross_val_predict\n\n#models.\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n#validation \nfrom sklearn.metrics import classification_report , precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve","b26d5cd6":"#at kaggels \ndf = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\n#on my PC \n# df = pd.read_csv('diabetes.csv')\nprint(df.shape)\ndf.head(1)","de1238af":"from IPython.display import display_html\nfrom itertools import chain,cycle\ndef display_side_by_side(*args,titles=cycle([''])):\n    html_str=''\n    for df,title in zip(args, chain(titles,cycle(['<\/br>'])) ):\n        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n        html_str+=f'<h2>{title}<\/h2>'\n        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n        html_str+='<\/td><\/th>'\n    display_html(html_str,raw=True)","410ea273":"df.info()","83f5bec7":"df[df.duplicated()]","2690af5b":" df.nunique(axis=0).sort_values().to_frame()","86505f44":"df.describe()","6e295628":"df.columns","b1819c50":" #this rename for much easiar read \ndf.rename(columns={'DiabetesPedigreeFunction': 'pedi'},inplace=True)","ffca4b5e":"Cant_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'Age' ,'pedi']\ndf[Cant_zeros] = df[Cant_zeros].replace(0, np.nan)","95dc88a5":"df[Cant_zeros].describe()","f7cfe127":"df.describe().T","c226bec8":" df.hist(figsize = (20,20));","dfdff165":"na = df.isna().sum().sort_values(ascending =False)\nNA = na[na>0].to_frame()\nNA.columns = ['Nulls']","89e9daba":"explorenulls ='display_side_by_side(NA,df[NA.index.to_list()].nunique(axis=0).to_frame().set_axis([\"uniqu\"], axis=1))'","f86de898":"exec(explorenulls)\ndf.Insulin.hist(figsize = (2,2));\ndisplay(df[~df.Insulin.isna()])\ndisplay(df[['Insulin']].describe())\nsns.pairplot(df, y_vars=\"Insulin\", x_vars=df.columns.values);","584d74e5":"exec(explorenulls)\ndf.SkinThickness.hist(figsize = (2,2));\ndisplay(df[df.SkinThickness.isna()])\nsns.pairplot(df, y_vars=\"SkinThickness\", x_vars=df.columns.values);\ndisplay(df[['SkinThickness']].describe())","b3d704d0":"exec(explorenulls)\ndf.BloodPressure.hist(figsize = (2,2));\ndisplay(df[df.BloodPressure.isna()])\nsns.pairplot(df, y_vars=\"BloodPressure\", x_vars=df.columns.values);\ndisplay(df[['BloodPressure']].describe())","dfe3199a":"exec(explorenulls)\ndf.BMI.hist(figsize = (2,2));\ndisplay(df[df.BMI.isna()])\nsns.pairplot(df, y_vars=\"BMI\", x_vars=df.columns.values);\ndisplay(df[['BMI']].describe())","b967c0bb":"exec(explorenulls)\ndf.Glucose.hist(figsize = (2,2));\ndisplay(df[df.Glucose.isna()])\nsns.pairplot(df, y_vars=\"Glucose\", x_vars=df.columns.values);\ndisplay(df[['Glucose']].describe())","1c01f694":"TrainDF, TestDF = train_test_split(df, test_size=0.2, random_state=9110)","8e1819bd":"col = 'Insulin' \nTrainDF[col].fillna(TrainDF[col].median(), inplace = True)\nTestDF[col].fillna(TrainDF[col].median(), inplace = True)","8574f9e9":"col = 'SkinThickness' \nTrainDF[col].fillna(TrainDF[col].median(), inplace = True)\nTestDF[col].fillna(TrainDF[col].median(), inplace = True)","cf5f31f6":"col = 'BloodPressure' \nTrainDF[col].fillna(TrainDF[col].mean(), inplace = True)\nTestDF[col].fillna(TrainDF[col].mean(), inplace = True)","0ee0b8b9":"from sklearn.linear_model import LinearRegression\ndata = TrainDF[['SkinThickness','BMI']][TrainDF.BMI.notna()] # load data set\nX = data.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\nY = data.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\nlinear_regressor = LinearRegression()  # create object for the class\nlinear_regressor.fit(X, Y)  # perform linear regression\nTrainDF.loc[TrainDF.BMI.isna(),'BMI']= linear_regressor.predict(TrainDF['SkinThickness'][TrainDF.BMI.isna()].values.reshape(-1, 1) )\nTestDF.loc[TestDF.BMI.isna(),'BMI']= linear_regressor.predict(TestDF['SkinThickness'][TestDF.BMI.isna()].values.reshape(-1, 1) ) ","3ad9df81":"col = 'Glucose' \nTrainDF[col].fillna(TrainDF[col].mean(), inplace = True)\nTestDF[col].fillna(TrainDF[col].mean(), inplace = True)","33aec24a":"TrainDF.isna().sum()","59d793fb":"TestDF.isna().sum()","cd314144":"features = df.columns.to_list()\nfeatures.pop(-1)\nfeatures","20d6283b":"scaler = StandardScaler()\nTrainDF[features] = scaler.fit_transform(TrainDF[features])\nTestDF[features] = scaler.transform(TestDF[features])","1648a17d":"X_train,y_train = TrainDF.drop(['Outcome'],axis = 1),TrainDF[['Outcome']]\nX_test,y_test = TestDF.drop(['Outcome'],axis = 1),TestDF[['Outcome']]","dad5deff":"# transform the dataset\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_train_S,y_train_S = oversample.fit_resample(X_train,y_train)","30f4b94e":"knn = KNeighborsClassifier()\nparam_grid = {\n    'n_neighbors': [*range(1,20)],\n}\nGrid_search = GridSearchCV(knn, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train , y_train)\nGrid_search.best_estimator_\nfinalknn  = Grid_search.best_estimator_\nfinalknn.fit(X_train,y_train )\ny_model = finalknn.predict(X_test)\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinalknn","2ecf2548":"knn = KNeighborsClassifier()\nparam_grid = {\n    'n_neighbors': [*range(1,20)],\n}\nGrid_search = GridSearchCV(knn, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train_S,y_train_S)\nGrid_search.best_estimator_\nfinalknn  = Grid_search.best_estimator_\nfinalknn.fit(X_train_S,y_train_S )\ny_model = finalknn.predict(X_test)\nprint(\"With Smote\")\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinalknn","0b16af3f":"lr = LogisticRegression(random_state=9110,n_jobs=-1,max_iter=100)\nparam_grid = {\n    'C': [0.0001, 0.001, 0.01,0.1,1,5],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n}\n\nGrid_search = GridSearchCV(lr, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train , y_train)\nGrid_search.best_estimator_\nfinallr = Grid_search.best_estimator_\nfinallr.fit(X_train,y_train )\ny_model = finallr.predict(X_test)\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinallr","dd50645b":"lr = LogisticRegression(random_state=9110,n_jobs=-1,max_iter=100)\nparam_grid = {\n    'C': [0.0001, 0.001, 0.01,0.1,1,5],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n}\n\nGrid_search = GridSearchCV(lr, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train_S,y_train_S)\nGrid_search.best_estimator_\nfinallr = Grid_search.best_estimator_\nfinallr.fit(X_train_S,y_train_S )\ny_model = finallr.predict(X_test)\nprint(\"With Smote\")\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinallr","c813b052":"svm = SVC(random_state = 9110)\nparam_grid = {\n    'C': [0.0001, 0.001, 0.01,0.1,1,5],\n    'kernel': ['linear', 'poly', 'rbf','sigmoid'],\n    'degree': [2,3,4,5],\n    'shrinking': [True,False]\n}\n\nGrid_search = GridSearchCV(svm, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train , y_train)\nGrid_search.best_estimator_\nfinalsvm = Grid_search.best_estimator_\nfinalsvm.fit(X_train,y_train )\ny_model = finalsvm.predict(X_test)\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinalsvm","ab4a4129":"svm = SVC(random_state = 9110)\nparam_grid = {\n    'C': [0.0001, 0.001, 0.01,0.1,1,5],\n    'kernel': ['linear', 'poly', 'rbf','sigmoid'],\n    'degree': [2,3,4,5],\n    'shrinking': [True,False]\n}\n\nGrid_search = GridSearchCV(svm, param_grid=param_grid, cv=5, scoring='roc_auc',n_jobs=-1)\n\nGrid_search.fit(X_train_S,y_train_S)\nGrid_search.best_estimator_\nfinalsvm = Grid_search.best_estimator_\nfinalsvm.fit(X_train_S,y_train_S )\ny_model = finalsvm.predict(X_test)\nprint(\"With Smote\")\nprint('roc_auc_score : ', roc_auc_score(y_test, y_model))\nprint('accuracy_score : ', accuracy_score(y_test, y_model))\nprint('recall_score : ', recall_score(y_test, y_model))\nprint('precision : ', precision_score(y_test, y_model))\nprint('f1_score : ', f1_score(y_test, y_model))\nprint(classification_report(y_test, y_model))\nfinalsvm","a5af4dcb":"\n##  3.[DataPreprocess](#preprocess)\n<a id='preprocess'><\/a>\n##### [Contnet](#Jump)","d193feec":"i can fill it with mean as the distrpution wont go bad \n<a id='deal_with_BloodPressure'><\/a>","5988fbf3":"TestDF[TestDF.duplicated()]","e422aa11":"i can use skinthickness to help me fill the data here create small regressing model \n<a id='deal_with_BMI'><\/a>","c546428d":"### 3.3.[Clean Duplication](#Duplication)\n<a id='Duplication'><\/a>\n##### [Contnet](#Jump)","695fbdd1":"columns cant be zeros ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'Age' , 'DiabetesPedigreeFunction']","788e4300":"Same as The insulin fill it with median \n<a id='deal_with_SkinThickness'><\/a>","ab418463":"#### 3.2.[Data Scaling ](#scaling) \n<a id='scaling'><\/a>\n##### [Contnet](#Jump)","72bc3ad1":"### 3.1.[Clean NA values](#NA)\n<a id='NA'><\/a>\n##### [Contnet](#Jump)","a5355917":"### 4.1.[KNN](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html)\n<a id='KNN'><\/a>\n##### [Contnet](#Jump)","c38b40e6":"# Contnet <a id='Jump'><\/a>\n\n##   1.[Import and reading the Data Section](#imports)\n---\n##   2.[Exploration](#EDA)<br>\n---\n##   3.[DataPreprocess](#preprocess)\n###  <br>3.1.[Clean NA values](#NA)\n\n###  <br>3.2.[Scalling](#scaling)\n###  <br>3.3.[Clean Duplication](#Duplication)<br>\n---\n## 4.[Modeling](#Models)<br>\n### 4.1.[KNN](#KNN)\n### 4.2.[Logistic  Regression](#lr)\n### 4.3.[SVM](#svm)","5e4fa415":"## imports\n<a id='imports'><\/a>\n##### [Contnet](#Jump)","421304b2":"### Helps","8be1e5cc":"### 4.3[SVM](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html)\n<a id='svm'><\/a>\n##### [Contnet](#Jump)","c6151362":"Cfloat, default=1.0\nInverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.","9e00a3ad":"[deal with Glucose](#deal_with_Glucose)","a1791813":"from jupyterthemes import jtplot\njtplot.style(theme='grade3' , context='talk', fscale=1.4, spines=False, gridlines='--' , ticks=True,figsize=(6, 4.5) )","3b169a6a":"# Practice KNN,LR,SVM","fb242bd4":"i will fill inslun with median as there is no realy connetction betweet it and other var to help me fill it and the var of the data is really big i cant just fill it with the mean that might ruin the data and this column need some expert to help me fill it \n<a id='deal_with_Insulin'><\/a>","f6f12175":"### 4.2.Logistic Regression\n<a id='lr'><\/a>\n##### [Contnet](#Jump)","e9537ed8":"(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)","54e5e6c4":"## 4.[Modeling](#Models)\n### 4.1.[KNN](#KNN)\n### 4.2.[Logistic  Regression](#lr)\n### 4.3.[SVM](#svm)\n<a id='Models'><\/a>\n##### [Contnet](#Jump)\n","ce04f827":"[deal with BMI](#deal_with_BMI)","779986e0":"[source](https:\/\/machinelearningmastery.com\/case-study-predicting-the-onset-of-diabetes-within-five-years-part-1-of-3\/)\nA particularly interesting attribute used in the study was the **Diabetes Pedigree Function**, pedi. It provided some data on diabetes mellitus history in relatives and the genetic relationship of those relatives to the patient. This measure of genetic influence gave us an idea of the hereditary risk one might have with the onset of diabetes mellitus. Based on observations in the proceeding section, it is unclear how well this function predicts the onset of diabetes.\n\n[anothersource](https:\/\/rpubs.com\/ikodesh\/53189)\nAccording to http:\/\/www.personal.kent.edu\/~mshanker\/personal\/Zip_files\/sar_2000.pdf, the diabetes pedigree function provides \u201ca synthesis of the diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject.\u201d It utilizes information from a person\u2019s family history to predict how diabetes will affect that individual. According to http:\/\/www.rci.rutgers.edu\/~cabrera\/587\/pima.pdf, \u201cmany Pima Indians have diabetes\u201d. I was intrigued at why this might be and what variables may influence this. To test the relationship between BMI and the number of times the women were pregnant, I will compare the two variables visually.","538f0c71":"the columns info \n\n    Pregnancies:\t\"Number of times pregnant\"\n    Glucose:\tPlasma glucose concentration a 2 hours in an oral glucose tolerance test\n    BloodPressure:\t\"Diastolic blood pressure (mm Hg)\"\n    SkinThickness:\tTriceps skin fold thickness (mm)\n    Insulin:\t2-Hour serum insulin (mu U\/ml)\n    BMI:\tBody mass index (weight in kg\/(height in m)^2)\n    DiabetesPedigreeFunction:\tDiabetes pedigree function\n    Age:\tAge (years)\n    Outcome:\tClass variable (0 or 1) 268 of 768 are 1, the others are 0","a2eb66ba":"[deal with BloodPressure](#deal_with_BloodPressure)","98f2ab76":"kernel{\u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmoid\u2019, \u2018precomputed\u2019}, default=\u2019rbf","c832ab57":"[Insulin](#deal_with_Insulin)","673fa1fd":"#### split the data set before continue ","8d001fad":"[deal with SkinThickness](#deal_with_SkinThickness)","1b9a58b8":"Wont do that i want to fix imlance data ","4cafae4b":"i will fill it with mean \n<a id='deal_with_Glucose'><\/a>","88392f96":"## Exploration\n<a id='EDA'><\/a>\n##### [Contnet](#Jump)","515c96c3":"TrainDF[TrainDF.duplicated()]","dd5a9bc6":"C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)[source]\u00b6","77e3da26":"### 3.4.Imb\n","f7bcf311":"- all int or float that makes things simpler \n- also there is no na here","6bfc6bbf":"- no duplicates in the data"}}