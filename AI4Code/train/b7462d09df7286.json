{"cell_type":{"35a6da3a":"code","3693a92d":"code","2cca9221":"code","7f7873fd":"code","cdbc5921":"code","ba3fbc5f":"code","a55e41d5":"code","f85cf904":"code","02c15b4d":"code","84955636":"code","0a93c7e8":"code","f7697c25":"code","66f7b954":"code","16696190":"code","0feab2fc":"code","34daf4f3":"code","4b2e06b3":"code","f048d552":"code","ec18da87":"code","0dc6f464":"code","bf0611fe":"code","0aba7afc":"code","84e00c2a":"code","133d8c7a":"code","e7bd55d2":"code","48d21f7d":"code","bc30e990":"code","c1638743":"code","8a61c751":"markdown","653cf5f6":"markdown","0cffd108":"markdown","a679cc46":"markdown","52247edb":"markdown","df181d3f":"markdown","88828f68":"markdown","c4c0ef25":"markdown","d3fca9ab":"markdown","e5a15722":"markdown","4d1b7458":"markdown","4efcfd15":"markdown"},"source":{"35a6da3a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","3693a92d":"# constants\nIMG_SIZE = 28\nN_CHANNELS = 1 # because gray scale images","2cca9221":"train_df = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/Dig-MNIST.csv')\npred_df = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')","7f7873fd":"train_df = train_df.append(test_df)","cdbc5921":"train_df.head()","ba3fbc5f":"print (f'Training set: {train_df.shape}')\nprint (f'To be Predicted: {pred_df.shape}')","a55e41d5":"X_train = train_df.drop(['label'], axis = 1)\nY_train = train_df['label']\nX_pred = pred_df.drop(['id'], axis = 1)","f85cf904":"X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.05)","02c15b4d":"X_train, X_test, X_pred = X_train.apply(lambda x: x\/255), X_test.apply(lambda x: x\/255), X_pred.apply(lambda x: x\/255)","84955636":"Y_train, Y_test = pd.get_dummies(Y_train), pd.get_dummies(Y_test)","0a93c7e8":"X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\nX_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)","f7697c25":"print (f'Training images: {X_train.shape}')\nprint (f'Testing images: {X_test.shape}')","66f7b954":"Y_train = Y_train.to_numpy()","16696190":"fig, ax = plt.subplots(nrows=3, ncols=4)\ncount=0\nfor row in ax:\n    for col in row:\n        col.set_title(np.argmax(Y_train[count, :]))\n        col.imshow(X_train[count, :, :, 0])\n        count += 1\nplt.show()","0feab2fc":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.15, # Randomly zoom image \n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\n# This will just calculate parameters required to augment the given data. This won't perform any augmentations\ndatagen.fit(X_train)","34daf4f3":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.15))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu'))\nmodel.add(Dropout(rate=0.3))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu'))\nmodel.add(BatchNormalization(momentum=0.15))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu'))\nmodel.add(Dropout(rate=0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(Dropout(0.40))\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.40))\nmodel.add(Dense(10, activation = \"softmax\"))","4b2e06b3":"model.summary()","f048d552":"model.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])","ec18da87":"# Set a learning rate annealer. Learning rate will be half after 3 epochs if accuracy is not increased\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)","0dc6f464":"batch_size=32\nepochs = 25","bf0611fe":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,Y_test),\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size, \n                              callbacks=[learning_rate_reduction])\n","0aba7afc":"%matplotlib inline\ndef PlotLoss(his, epoch):\n    plt.style.use(\"ggplot\")\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history[\"loss\"], label=\"train_loss\")\n    plt.plot(np.arange(0, epoch), his.history[\"val_loss\"], label=\"val_loss\")\n    plt.title(\"Training Loss\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss\")\n    plt.legend(loc=\"upper right\")\n    plt.show()\n\ndef PlotAcc(his, epoch):\n    plt.style.use(\"ggplot\")\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history[\"accuracy\"], label=\"train_acc\")\n    plt.plot(np.arange(0, epoch), his.history[\"val_accuracy\"], label=\"val_accuracy\")\n    plt.title(\"Training Accuracy\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend(loc=\"upper right\")\n    plt.show()","84e00c2a":"PlotLoss(history, epochs)\nPlotAcc(history, epochs)","133d8c7a":"cfm = confusion_matrix(np.argmax(Y_test.to_numpy(), axis=1), np.argmax(model.predict(X_test), axis=1))\ncfm = pd.DataFrame(cfm,index=range(0,10),columns=range(0,10))\ncfm","e7bd55d2":"preds = model.predict(X_pred.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS))","48d21f7d":"pred_df['label'] = np.argmax(preds, axis=1)","bc30e990":"preds = pred_df[['id', 'label']]","c1638743":"preds.to_csv('sub.csv', index=False)","8a61c751":"### CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images","653cf5f6":"### Normalize the images ","0cffd108":"### Confusion matrix ","a679cc46":"#### Predictions will be in one hot encoding, take `argmax` to make the predictions submission ready","52247edb":"### Ploting loss and accuracy","df181d3f":"### Apply data augmentation:\nTo get more training data, to avoid overfitting, data augmentation is used. Data augmentation is the creation of altered copies of each training instance (image) within a training dataset. \nI've used following data augmentation for this problem:\n* Ramdomly rotate the images by 8 degrees\n* Randomly zoom the images by 15%\n* Randomly shift its height and width by 15%","88828f68":"#### Finally create submission file","c4c0ef25":"### Define required constants\nImage size is `28*28` as per the MNIST standards and images are grayscale, so number of channels is `1`.","d3fca9ab":"### Make predictions using trained model","e5a15722":"### Create CNN model using Keras","4d1b7458":"### Split the given dataset into training and testing dataset","4efcfd15":"### Convert training and testing labels (Ys) to one hot encoding"}}