{"cell_type":{"c7cd0dcc":"code","038e63ba":"code","ee5a7715":"code","707a8416":"code","99eb1b19":"code","f3364606":"code","68c19428":"code","23b86432":"code","2ce0816c":"code","bfd2e0c6":"code","73630c51":"code","1b7ecbdf":"code","dc66e760":"code","c23cdf4a":"code","bff1dc67":"code","162918f1":"code","1e487fca":"code","73000f56":"code","dc797566":"code","accb9781":"code","a2779ea1":"code","77708943":"code","8266509c":"code","3d0db269":"code","1d59aa93":"code","99bd43b0":"code","5d888cbf":"code","cb84ed75":"code","e95347cb":"code","06fae758":"code","9680766e":"code","5b37f8f2":"code","4f2e2a6c":"code","ebd4d602":"code","4963d5da":"code","23a3a422":"code","c6d40109":"code","5c7541fa":"code","738f7e24":"code","556c2238":"code","1b615e60":"code","8effd41d":"code","5549911e":"code","e6950a12":"code","d658ffb0":"code","2d24069d":"code","c12c8f96":"code","b237d7ba":"code","aecc9b38":"code","a9b1c546":"code","9985d4dd":"code","f5b23968":"code","f71ca672":"code","547f22ad":"code","ecfff81f":"code","224f142c":"markdown","77f5c05a":"markdown","7210e524":"markdown","f6cf9b2e":"markdown","df0cd4f4":"markdown","873f2da3":"markdown","2c0f2810":"markdown","9c3fbe31":"markdown","189ddcc5":"markdown"},"source":{"c7cd0dcc":"pip install spotipy","038e63ba":"pip install kneed","ee5a7715":"import sys\nimport spotipy\nimport yaml\nimport spotipy.util as util\nfrom pprint import pprint\nimport json\nimport argparse\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom kneed import KneeLocator\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nsns.set()","707a8416":"import sklearn.metrics as metrics\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster.elbow import kelbow_visualizer\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom yellowbrick.cluster import silhouette_visualizer","99eb1b19":"from spotipy.oauth2 import SpotifyClientCredentials \nclient_id = \nclient_secret = \nclient_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager) ","f3364606":"name = [\"Pitbull\",\"Enrique Iglesias\",\"Akon\",\"Ed Sheeran\",\"Justin Bieber\",\"Lady Gaga\",\"Taylor Swift\",\"Katy Perry\",\"Rihana\",\"Christina Aguilera\"]\nresult = sp.search(name) \nresult['tracks']['items'][1]['artists']","68c19428":"artists_uris = result['tracks']['items'][0]['artists'][0]['uri']\n#Pull all of the artist's albums\nartist_albums = sp.artist_albums(artists_uris, album_type='album')\n#Store artist's albums' names' and uris in separate lists\nartist_album_names = []\nartist_album_uris = []\nfor i in range(len(artist_albums['items'])):\n    artist_album_names.append(artist_albums['items'][i]['name'])\n    artist_album_uris.append(artist_albums['items'][i]['uri'])\nartist_album_names\nartist_album_uris","23b86432":"def album_songs(uri):\n    album = uri \n    spotify_albums[album] = {}\n    #Create keys-values of empty lists inside nested dictionary for album\n    spotify_albums[album]['album'] = [] \n    spotify_albums[album]['track_number'] = []\n    spotify_albums[album]['id'] = []\n    spotify_albums[album]['name'] = []\n    spotify_albums[album]['artist'] = []\n    spotify_albums[album]['uri'] = []\n    #pull data on album tracks\n    tracks = sp.album_tracks(album) \n    for n in range(len(tracks['items'])): \n        spotify_albums[album]['album'].append(artist_album_names[album_count]) \n        spotify_albums[album]['track_number'].append(tracks['items'][n]['track_number'])\n        spotify_albums[album]['id'].append(tracks['items'][n]['id'])\n        spotify_albums[album]['name'].append(tracks['items'][n]['name'])\n        spotify_albums[album]['artist'].append(tracks['items'][n]['artists'])\n        spotify_albums[album]['uri'].append(tracks['items'][n]['uri'])","2ce0816c":"spotify_albums = {}\nalbum_count = 0\nfor i in artist_album_uris: #each album\n    album_songs(i)\n    print(str(artist_album_names[album_count]) + \" album songs has been added to spotify_albums dictionary\")\n    album_count+=1 #Updates album count once all tracks have been added","bfd2e0c6":"def audio_features(album):\n    #Add new key-values to store audio features\n    spotify_albums[album]['acousticness'] = []\n    spotify_albums[album]['danceability'] = []\n    spotify_albums[album]['energy'] = []\n    spotify_albums[album]['instrumentalness'] = []\n    spotify_albums[album]['liveness'] = []\n    spotify_albums[album]['loudness'] = []\n    spotify_albums[album]['speechiness'] = []\n    spotify_albums[album]['tempo'] = []\n    spotify_albums[album]['valence'] = []\n    spotify_albums[album]['popularity'] = []\n\n    \n    track_count = 0\n    for track in spotify_albums[album]['uri']:\n        #pull audio features per track\n        features = sp.audio_features(track)\n        \n        #Append to relevant key-value\n        spotify_albums[album]['acousticness'].append(features[0]['acousticness'])\n        spotify_albums[album]['danceability'].append(features[0]['danceability'])\n        spotify_albums[album]['energy'].append(features[0]['energy'])\n        spotify_albums[album]['instrumentalness'].append(features[0]['instrumentalness'])\n        spotify_albums[album]['liveness'].append(features[0]['liveness'])\n        spotify_albums[album]['loudness'].append(features[0]['loudness'])\n        spotify_albums[album]['speechiness'].append(features[0]['speechiness'])\n        spotify_albums[album]['tempo'].append(features[0]['tempo'])\n        spotify_albums[album]['valence'].append(features[0]['valence'])\n        #popularity is stored elsewhere\n        pop = sp.track(track)\n        spotify_albums[album]['popularity'].append(pop['popularity'])\n        track_count+=1","73630c51":"import time\nimport numpy as np\nsleep_min = 2\nsleep_max = 5\nstart_time = time.time()\nrequest_count = 0\nfor i in spotify_albums:\n    audio_features(i)\n    request_count+=1\n    if request_count % 5 == 0:\n        print(str(request_count) + \" playlists completed\")\n        time.sleep(np.random.uniform(sleep_min, sleep_max))\n        print('Loop #: {}'.format(request_count))\n        print('Elapsed Time: {} seconds'.format(time.time() - start_time))","1b7ecbdf":"dic_df = {}\ndic_df['album'] = []\ndic_df['track_number'] = []\ndic_df['name'] = []\ndic_df['artist']=[]\ndic_df['id']=[]\ndic_df['uri'] = []\ndic_df['acousticness'] = []\ndic_df['danceability'] = []\ndic_df['energy'] = []\ndic_df['instrumentalness'] = []\ndic_df['liveness'] = []\ndic_df['loudness'] = []\ndic_df['speechiness'] = []\ndic_df['tempo'] = []\ndic_df['valence'] = []\ndic_df['popularity'] = []\nfor album in spotify_albums: \n    for feature in spotify_albums[album]:\n        dic_df[feature].extend(spotify_albums[album][feature])\nlen(dic_df['album'])","dc66e760":"import pandas as pd\ndf = pd.DataFrame.from_dict(dic_df)","c23cdf4a":"df=df.drop(['album','track_number','name','artist','id','uri','popularity'],axis=1,inplace=False)","bff1dc67":"df.head()","162918f1":"scaler = StandardScaler()\nX = scaler.fit_transform(df)","1e487fca":"pd.DataFrame(X).head()","73000f56":"pca = PCA()","dc797566":"X_r = pca.fit(X).transform(X)\nprint('\\nEigenvalues \\n%s' %pd.DataFrame(pca.explained_variance_).T)\nprint('Eigenvectors \\n%s' %pd.DataFrame(pca.components_).T.head())","accb9781":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\")","a2779ea1":"import matplotlib.pyplot as plt\nimport mplcyberpunk\nplt.figure(figsize=(15,10))\nplt.style.use(\"cyberpunk\")\nplt.scatter(x=[i+1 for i in range(len(pca.explained_variance_ratio_))],y=pca.explained_variance_ratio_,s=50, alpha=0.75,c='pink',edgecolor='blue')\nplt.grid(True)\nplt.title(\"Explained variance ratio of the fitted principal component vector\\n\",fontsize=12)\nplt.xlabel(\"Principal components\",fontsize=10)\nplt.xticks([i+1 for i in range(len(pca.explained_variance_ratio_))],fontsize=10)\nplt.yticks(fontsize=15)\nplt.ylabel(\"Explained variance ratio\",fontsize=10)\nplt.show()","77708943":"exp_var_ratio=pca.explained_variance_ratio_\nexp_var_ratio","8266509c":"cum_explaiend_var = exp_var_ratio.cumsum()\ncum_explaiend_var","3d0db269":"plt.figure(figsize=(15,7))\nplt.bar(x=['PrComp'+str(i) for i in range(1,10)],height=cum_explaiend_var,width=0.6)\nplt.xticks(fontsize=14)\nplt.hlines(y=0.9,xmin='PrComp1',xmax='PrComp8',linestyles='dashed',lw=3)\nplt.text(x='PrComp1',y=0.82,s=\"80% variance explained\",fontsize=15)\nplt.show()","1d59aa93":"principal_df = pd.DataFrame(data = X, \\\n                            columns = ['PC_1', 'PC_2','PC_3','PC_4','PC_5','PC_6','PC_7','PC_8','PC_9'])\nprincipal_df.head() ","99bd43b0":"plt.figure(figsize=(15,7))\nplt.style.use(\"cyberpunk\")\nplt.plot(range(1,10), np.cumsum(pca.explained_variance_ratio_), linestyle=\":\", marker='o', label='Cumulative')\nplt.plot(range(1,10), pca.explained_variance_ratio_, marker='o', label='Proportion')\nplt.xlabel(\"Number of Principal Components\")\nplt.ylabel(\"Explained Variance\")\nplt.title(\"Scree Plot\",fontsize=15)\nplt.plot([6]*10, np.linspace(0,1,10), \":\")\nplt.text(6.1, 0.90, \"optimal number of components = 6\")\nplt.legend(loc='best')\nplt.show()","5d888cbf":"for i, exp_var in enumerate(exp_var_ratio.cumsum()):\n    if exp_var >= 0.9:\n        n_comps = i + 1\n        break\nprint(\"Number of components:\", n_comps)\npca = PCA(n_components=n_comps)\npca.fit(principal_df)\nscores_pca = pca.transform(principal_df)","cb84ed75":"plt.figure(figsize=(15,8))\nvisualizer = KElbowVisualizer(KMeans(init='k-means++', random_state=42),k=(1,20), timings=True)\nvisualizer.fit(scores_pca)\nvisualizer.show()\nn_clusters = visualizer.elbow_value_\nprint(\"Optimal number of clusters:\", n_clusters)","e95347cb":"wcss = []\nmax_clusters = 20\nfor i in range(1, max_clusters):\n    kmeans_pca = KMeans(i, init='k-means++', random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)\nn_clusters = KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee\nprint(\"Optimal number of clusters\", n_clusters)","06fae758":"fig = plt.figure(figsize=(15,8))\nplt.plot(range(1, 20), wcss, marker='o', linestyle='--')\nplt.vlines(KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee, ymin=min(wcss), ymax=max(wcss), linestyles='dashed')\nplt.xlabel('Number of Clusters', fontsize=18)\nplt.ylabel('Within Cluster Sum of Squares (WCSS)', fontsize=10)\nplt.title(\"Scree Plot\",fontsize=18)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","9680766e":"#silhouette_visualizer(KMeans(5, random_state=42), principal_df, colors='yellowbrick')\nplt.figure(figsize=(15,8))\nmodel = KMeans(5, random_state=42)\nvisualizer = SilhouetteVisualizer(model, colors='yellowbrick')\nvisualizer.fit(principal_df)        # Fit the data to the visualizer\nvisualizer.show()   ","5b37f8f2":"km = KMeans(n_clusters=5, random_state=123)\ny_kmeans=km.fit(principal_df)","4f2e2a6c":"predicted_cluster = km.predict(principal_df)","ebd4d602":"predicted_cluster","4963d5da":"principal_df['Cluster'] = pd.Series(predicted_cluster, index=df.index)\ndf.index.name = \"Index\"","23a3a422":"principal_df.head()","c6d40109":"# Scatter plot on Principal components to visualize the spread of the data\n\nfig, axes = plt.subplots(1,2, figsize=(15,8))\n\nsns.scatterplot(x='PC_1',y='PC_2',hue='Cluster',legend='full',palette=\"Set1\",data=principal_df,ax=axes[0])\nsns.scatterplot(x='PC_1',y='PC_3',hue='Cluster',legend='full',palette=\"Set1\",data=principal_df,ax=axes[1])","5c7541fa":"import plotly.express as px\nimport plotly.graph_objects as go\n\npx.scatter_3d(data_frame=principal_df,x='PC_3',y='PC_4',z='PC_5',color='Cluster',template='plotly_dark',\n             title='3D Scatter plot for KMeans Clusters')","738f7e24":"px.scatter(data_frame=principal_df,x='PC_6',y='PC_7',color='Cluster',template='plotly_dark',\n          title='PC_6 vs PC_7')","556c2238":"df=pd.concat([df, principal_df], axis=1)","1b615e60":"df=df.drop(df.columns[[9,10,11,12,13,14,15,16,17]], axis = 1)\ndf.head()","8effd41d":"spotify  = df.groupby(\"Cluster\").mean()\nscaler = MinMaxScaler()\nspotify=scaler.fit_transform(spotify)\ndf1=pd.DataFrame(spotify)","5549911e":"df1=df1.rename(columns = {0:'acousticness',1:'danceability',2:'energy',3:'instrumentalness',4:'liveness',5:'loudness',6:'speechiness',\n                         7:'tempo',8:'valence'}, inplace = False) \ndf1=df1.T","e6950a12":"df1=df1.reset_index()","d658ffb0":"df1=df1.rename(columns = {'index':'Properties',0:'Cluster1',1:'Cluster2',2:'Cluster3',3:'Cluster4',4:'Cluster5'}, inplace = False) \ndf1.head(10)","2d24069d":"import plotly.express as px\nimport pandas as pd\ndf = pd.DataFrame(dict(\n    r=[2.20128725e-02, 9.63607902e-01, 9.13387718e-01, 4.18629097e-04,1.51705093e-01, 9.64854429e-01, 1.38304403e-01, 6.10507030e-01,7.49139534e-01],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']))\nfig = px.line_polar(df, r='r', theta='theta', line_close=True,template=\"plotly_dark\")\nfig.update_traces(fill='toself')\nfig.update_layout(\n    autosize=False,title_text=\"Radar Chart showing song Property in Cluster 1\", title_x=0.5)\nfig.show()\n","c12c8f96":"df = pd.DataFrame(dict(\n    r=[0.00000000e+00, 1.00000000e+00, 9.58869206e-01, 6.83411957e-05,1.00000000e+00, 9.82744319e-01, 2.55884153e-01, 7.98203467e-01,\n       7.78862259e-01],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']))\nfig = px.line_polar(df, r='r', theta='theta', line_close=True,template=\"plotly_dark\")\nfig.update_traces(fill='toself')\nfig.update_layout(\n    autosize=False,title_text=\"Radar Chart showing song Property in Cluster 2\", title_x=0.5)\nfig.show()","b237d7ba":"import plotly.express as px\nimport pandas as pd\ndf = pd.DataFrame(dict(\n    r=[1.        , 0.        , 0.        , 1.        , 0.09433248,0.        , 0.        , 0.25134906, 0.        ],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']))\nfig = px.line_polar(df, r='r', theta='theta', line_close=True,template=\"plotly_dark\")\nfig.update_traces(fill='toself')\nfig.update_layout(\n    autosize=False,title_text=\"Radar Chart showing song Property in Cluster 3\", title_x=0.5,)\nfig.show()\n","aecc9b38":"import plotly.express as px\nimport pandas as pd\ndf = pd.DataFrame(dict(\n    r=[0.19483184, 0.9289785 , 1.        , 0.        , 0.22480534,1.        , 1.        , 1.        , 0.54614131],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']))\nfig = px.line_polar(df, r='r', theta='theta', line_close=True,template=\"plotly_dark\")\nfig.update_traces(fill='toself')\nfig.update_layout(\n    autosize=False,title_text=\"Radar Chart showing song Property in Cluster 4\", title_x=0.5)\nfig.show()\n","a9b1c546":"import plotly.express as px\nimport pandas as pd\ndf = pd.DataFrame(dict(\n    r=[8.13590101e-02, 9.47020399e-01, 7.58931551e-01, 9.15442657e-06,0.00000000e+00, 8.71401752e-01, 8.43363946e-01, 0.00000000e+00,1.00000000e+00],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']))\nfig = px.line_polar(df, r='r', theta='theta', line_close=True,template=\"plotly_dark\")\nfig.update_traces(fill='toself')\nfig.update_layout(\n    autosize=False,title_text=\"Radar Chart showing song Property in Cluster 5\", title_x=0.5)\nfig.show()\n","9985d4dd":"import plotly.graph_objects as go\ncategories = ['processing cost','mechanical properties','chemical stability','thermal stability', 'device integration']\nfig = go.Figure()\nfig.add_trace(go.Scatterpolar(\n      r=[2.20128725e-02, 9.63607902e-01, 9.13387718e-01, 4.18629097e-04,1.51705093e-01, 9.64854429e-01, 1.38304403e-01, 6.10507030e-01,7.49139534e-01],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence'], fill='toself',name='Cluster 1'))\nfig.add_trace(go.Scatterpolar(\n      r=[0.00000000e+00, 1.00000000e+00, 9.58869206e-01, 6.83411957e-05,1.00000000e+00, 9.82744319e-01, 2.55884153e-01, 7.98203467e-01,\n       7.78862259e-01],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence'],fill='toself',name='Cluster 2'))\nfig.add_trace(go.Scatterpolar(\n      r=[1.        , 0.        , 0.        , 1.        , 0.09433248,0.        , 0.        , 0.25134906, 0.        ],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence'],fill='toself',name='Cluster 3'))\nfig.add_trace(go.Scatterpolar(\n      r=[0.19483184, 0.9289785 , 1.        , 0.        , 0.22480534,1.        , 1.        , 1.        , 0.54614131],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence'],fill='toself',name='Cluster 4'))\nfig.add_trace(go.Scatterpolar(\n      r=[8.13590101e-02, 9.47020399e-01, 7.58931551e-01, 9.15442657e-06,0.00000000e+00, 8.71401752e-01, 8.43363946e-01, 0.00000000e+00,1.00000000e+00],\n    theta=['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence'],fill='toself',name='Cluster 5'))\nfig.update_layout(polar=dict(radialaxis=dict(visible=True,range=[0, 1])),showlegend=False,template=\"plotly_dark\")\nfig.show()","f5b23968":"from sklearn.mixture import GaussianMixture","f71ca672":"gm_bic= []\ngm_score=[]\nfor i in range(4,20):\n    gm = GaussianMixture(n_components=i,n_init=10,tol=1e-3,max_iter=1000).fit(principal_df)\n    print(\"BIC for number of cluster(s) {}: {}\".format(i,gm.bic(principal_df)))\n    print(\"Log-likelihood score for number of cluster(s) {}: {}\".format(i,gm.score(principal_df)))\n    print(\"-\"*100)\n    gm_bic.append(-gm.bic(principal_df))\n    gm_score.append(gm.score(principal_df))","547f22ad":"plt.figure(figsize=(15,7))\nplt.title(\"The Gaussian Mixture model BIC \\nfor determining number of clusters\\n\",fontsize=16)\nplt.scatter(x=[i for i in range(4,20)],y=np.log(gm_bic),s=150,edgecolor='k')\nplt.grid(True)\nplt.xlabel(\"Number of clusters\",fontsize=14)\nplt.ylabel(\"Log of Gaussian mixture BIC score\",fontsize=15)\nplt.xticks([i for i in range(4,20)],fontsize=14)\nplt.yticks(fontsize=15)\nplt.show()","ecfff81f":"plt.figure(figsize=(15,7))\nplt.scatter(x=[i for i in range(4,20)],y=gm_score,s=150,edgecolor='k')\nplt.show()","224f142c":"The V-measure is the harmonic mean between homogeneity and completeness. This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won\u2019t change the score value in any way.\nOne of the primary disadvantages of any clustering technique is that it is difficult to evaluate its performance. To tackle this problem, the metric of V-Measure was developed.\n\nThe calculation of the V-Measure first requires the calculation of two terms:-<br>\n1. Homogenity: A perfectly homogeneous clustering is one where each cluster has data-points belonging to the same class label. Homogeneity describes the closeness of the clustering algorithm to this perfection.\n2. Completeness: A perfectly complete clustering is one where all data-points belonging to the same class are clustered into the same cluster. Completeness describes the closeness of the clustering algorithm to this perfection.","77f5c05a":"### K-Means Clustering","7210e524":"A Gaussian mixture model (GMM) attempts to find a mixture of multi-dimensional Gaussian probability distributions that best model any input dataset. In the simplest case, GMMs can be used for finding clusters in the same manner as k-means.\n\nHowever, because GMM contains a probabilistic model under the hood, it is also possible to find probabilistic cluster assignments\u2014in Scikit-Learn this is done using the predict_proba method. This returns a matrix of size [n_samples, n_clusters] which measures the probability that any point belongs to the given cluster.","f6cf9b2e":"## K-Means Clustering and PCA to categorize music by similar audio features","df0cd4f4":"## Expectation-maximization (Gaussian Mixture Model)","873f2da3":"### Explained Variance Ratio","2c0f2810":"https:\/\/developer.spotify.com\/  ----> Dashboard ----> Create An App ---> get client id & client Secret id --- Follow the below codes","9c3fbe31":"Variable Dictionary\nThese are the descriptions of the features provided by Spotify on their Spotify for Develepors documentation:\n\n1. artist_name - Name of the artist\n2. track_name - Name of the track\n3. track_id - Id of the track\n4. popularity - Popularity of the track (The higher, the more popular it is)\n5. danceability - Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. \n6. energy - Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. \n7. key - The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on. If no key was detected, the value is -1.\n8. loudness - The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. \n9. mode - Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n10. speechiness - Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. \n11. acousticness - A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:\n12. instrumentalness - Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n13. liveness - Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n14. valence - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n15. tempo - The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n16. duration_ms - The duration of the track in milliseconds.\n17. time_signature - An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).","189ddcc5":"### Scree Plot\nFor the k-means clustering method, the most common approach for answering this question is the so-called elbow method. It involves running the algorithm multiple times over a loop, with an increasing number of cluster choice and then plotting a clustering score as a function of the number of clusters."}}