{"cell_type":{"ef9e1e4d":"code","536a7ea8":"code","28593465":"code","930adf04":"code","39968191":"code","70d8ace3":"code","f8d16a7f":"code","f1feb7b7":"markdown","316baabf":"markdown","0d71db0f":"markdown","b0b90606":"markdown","aa0e888e":"markdown","1551754d":"markdown"},"source":{"ef9e1e4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","536a7ea8":"train_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\n\nfeatures_list = [\"OverallQual\", \"GrLivArea\",\"FullBath\",\"1stFlrSF\",\"TotalBsmtSF\",\"GarageArea\",\"GarageCars\",\"TotRmsAbvGrd\",\"YearBuilt\",\"Fireplaces\"]\n","28593465":"from sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\n","930adf04":"data = train_data\n\nfor col in data.columns:\n    if (data.dtypes[col] != np.int64 and data.dtypes[col] != np.float64):\n        data[col] = LabelEncoder().fit_transform(data[col])\n    else:\n        continue\n    ","39968191":"y = data[\"SalePrice\"]\n\nX = data[features_list]\n\ntest_data = test[features_list]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\nn_features = X_train.shape[1]\n#660 1116\n\n\n","70d8ace3":"model = Sequential()\n\nmodel.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\nmodel.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.fit(X_train, y_train, epochs=1000, batch_size=128, verbose=0)\n\nerror = model.evaluate(X_test, y_test, verbose=0)\n\nprint('MSE: %.3f, RMSE: %.3f' % (error, np.sqrt(error)))\n    \n","f8d16a7f":"output = pd.DataFrame()\noutput[\"Id\"] = test[\"Id\"]\noutput[\"SalePrice\"] = model.predict(test_data)\n\noutput.to_csv(\"my_submission.csv\", index=False)\n\nimport csv\n\nfile = csv.reader(open(\".\/my_submission.csv\"))\n\n#file.set_value(659,\"SalePrice\",file[\"SalePrice\"].mean())\n\n#file.to_csv(\"my_submission.csv\", index=False)\n\nlines = list(file)\nmen = output[\"SalePrice\"].mean()\n\nlines[661][1] = str(men)\n\nlines[1117][1] = str(men)\n\nprint(lines[661])\n\nlst = csv.writer(open(\".\/my_submission.csv\",\"w\"))\n\nlst.writerows(lines)\n                      \n                      ","f1feb7b7":"* Data initialization","316baabf":"* Data Encoding and cleaning","0d71db0f":"* Model Building","b0b90606":"* Importing required Libraries","aa0e888e":"* Model Prediction","1551754d":"* Features selection and Data split into training and testing sets."}}