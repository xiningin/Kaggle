{"cell_type":{"b0c34ace":"code","513e5ac7":"code","ccda8123":"code","17113090":"code","0010efe0":"code","ae661ab8":"code","1d5f552d":"code","6157e94f":"code","16dfef0f":"code","f5dcf6e0":"code","805b9870":"code","fccebb64":"code","242a271b":"code","b50b5909":"code","27cdf300":"code","6c7b08f5":"code","867b4613":"code","2761f631":"code","6115141c":"code","f8eb779c":"code","82935ddf":"code","149d0cc2":"code","3033c567":"code","513c78c4":"markdown"},"source":{"b0c34ace":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ndata = os.listdir(\"..\/input\")\ndata[0]\n# Any results you write to the current directory are saved as output.","513e5ac7":"import re\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm\nimport bz2\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","ccda8123":"# Adding Performance measure metrics\nfrom sklearn.metrics import precision_recall_fscore_support,accuracy_score","17113090":"def splitReviewsLabels(lines):\n    reviews = []\n    labels = []\n    for review in tqdm(lines):\n        rev = reviewToX(review)\n        label = reviewToY(review)\n        reviews.append(rev[:512])\n        labels.append(label)\n    return reviews, labels","0010efe0":"# Constants\nAMAZON_REVIEW_DIR = '..\/input'","ae661ab8":"def reviewToY(review):\n    return [1,0] if review.split(' ')[0] == '__label__1' else [0,1]","1d5f552d":"def reviewToX(review):\n    review = review.split(' ', 1)[1][:-1].lower()\n    review = re.sub('\\d','0',review)\n    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in review:\n        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\n    return review","6157e94f":"train_file = bz2.BZ2File(os.path.join(AMAZON_REVIEW_DIR, 'train.ft.txt.bz2'))\ntest_file = bz2.BZ2File(os.path.join(AMAZON_REVIEW_DIR,'test.ft.txt.bz2'))","16dfef0f":"train_lines = train_file.readlines()\ntest_lines = test_file.readlines()","f5dcf6e0":"train_lines = [x.decode('utf-8') for x in train_lines]\ntest_lines = [x.decode('utf-8') for x in test_lines]","805b9870":"# Load from the file\nreviews_train, y_train = splitReviewsLabels(train_lines)\nreviews_test, y_test = splitReviewsLabels(test_lines)","fccebb64":"reviews_train, y_train = shuffle(reviews_train, y_train)\nreviews_test, y_test = shuffle(reviews_test, y_test)","242a271b":"y_train = np.array(y_train)\ny_test = np.array(y_test)","b50b5909":"max_features = 8192\nmaxlen = 128\nembed_size = 64","27cdf300":"tokenizer = Tokenizer(num_words=max_features)","6c7b08f5":"tokenizer.fit_on_texts(reviews_train)","867b4613":"import pickle\nwith open('tokenizer_convo_sentiment.pickle','wb') as handle:\n    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)","2761f631":"token_train = tokenizer.texts_to_sequences(reviews_train)\ntoken_test = tokenizer.texts_to_sequences(reviews_test)","6115141c":"x_train = pad_sequences(token_train, maxlen=maxlen, padding='post')\nx_test = pad_sequences(token_test, maxlen=maxlen, padding='post')","f8eb779c":"input = Input(shape=(maxlen,))\nnet = Embedding(max_features, embed_size)(input)\nnet = Dropout(0.2)(net)\nnet = BatchNormalization()(net)\n\nnet = Conv1D(32, 7, padding='same', activation='relu')(net)\nnet = BatchNormalization()(net)\nnet = Conv1D(32, 3, padding='same', activation='relu')(net)\nnet = BatchNormalization()(net)\nnet = Conv1D(32, 3, padding='same', activation='relu')(net)\nnet = BatchNormalization()(net)\nnet = Conv1D(32, 3, padding='same', activation='relu')(net)\nnet1 = BatchNormalization()(net)\n\nnet = Conv1D(2, 1)(net)\nnet = GlobalAveragePooling1D()(net)\noutput = Activation('softmax')(net)\nmodel = Model(inputs = input, outputs = output)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","82935ddf":"model.summary()","149d0cc2":"model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)","3033c567":"model.evaluate (x_test, y_test)","513c78c4":"IF you put epochs=5 then you will get 94.4 accuracy."}}