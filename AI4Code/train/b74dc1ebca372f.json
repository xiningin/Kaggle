{"cell_type":{"0909c5f4":"code","e77f8c23":"code","23d1664f":"code","cffbb4f1":"code","d60c436b":"code","b902f4bf":"code","f83972c1":"code","1d59599f":"code","2564fd91":"code","35843a82":"code","4789c8c7":"code","504861cd":"code","a54e252f":"code","f09b5e3d":"code","da9b816c":"code","1b2564c6":"code","be56121c":"code","f3625855":"code","b99b3269":"code","999c5f1b":"code","9963b0c3":"code","cb065cc0":"code","10099308":"markdown","136ef391":"markdown","d50375e8":"markdown","21862cb0":"markdown","43747235":"markdown","0abdbf42":"markdown","9afca74a":"markdown","45d10fce":"markdown","98365112":"markdown","286471fb":"markdown","9cddf363":"markdown","b0764b2f":"markdown","430b69a8":"markdown","5117dfcf":"markdown","a09405c9":"markdown"},"source":{"0909c5f4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e77f8c23":"!git clone https:\/\/github.com\/CSSEGISandData\/COVID-19.git","23d1664f":"!ls","cffbb4f1":"datasets = [\"time_series_covid19_confirmed_global.csv\",\n         \"time_series_covid19_deaths_global.csv\",\n         \"time_series_covid19_recovered_global.csv\"]\nk=0\ndata = []\nfor i in datasets:\n    data.append(pd.read_csv('.\/COVID-19\/csse_covid_19_data\/csse_covid_19_time_series\/'+i))\n#     data.append(pd.read_csv('.\/' + i))\n    ","d60c436b":"# Grouping the data according to the Country\/Region \ndef transform_pipeline(dataset): # implement arbitrary arugument list in this function\n    ds = dataset.drop(columns=['Lat', 'Long', 'Province\/State'])\n    sum_data = (ds.groupby('Country\/Region').sum().reset_index()).T\n    cleaned_data = sum_data.rename(columns=sum_data.iloc[0]).drop(sum_data.index[0])\n    return cleaned_data.apply(pd.to_numeric)\n\nclean_data = []\nfor dataset_item in data:\n    clean_data.append(transform_pipeline(dataset_item))\n","b902f4bf":"clean_data[0].head()","f83972c1":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n                               AutoMinorLocator)\n","1d59599f":"countries = list(clean_data[0].columns) \ncountries_bar_china = countries.copy()\ncountries_bar_china.remove('China')","2564fd91":"\n# plt.figure()\n\nfig, ax = plt.subplots(figsize=(30,15))\nx_labels = clean_data[0].index.sort_values()\nfor country in countries_bar_china:\n    if (clean_data[0][country][-1]>1000):\n        ax.plot(x_labels, clean_data[0][country])\n#         handler.append(l)\n    else:\n        ax.plot(x_labels, clean_data[0][country], 'k')\nplt.grid(axis='both')  \n# plt.xticks(rotation=90, ha='right')\nplt.xlabel('Week Count').set_fontsize(30)\nax.xaxis.set_major_locator(MultipleLocator(7))\nax.xaxis.set_major_formatter(FormatStrFormatter(\"Week - %d\"))        #--------------------> get week number\nax.xaxis.set_minor_locator(MultipleLocator(1))\nplt.ylabel('Confirmed cases').set_fontsize(30)\nplt.title('Confirmed Cases in the world outside China').set_fontsize(30)\nax.tick_params(axis='both', which='major', labelsize=20)\n\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[:20], labels[:20], loc='upper left', borderaxespad=0.8)\n\n","35843a82":"cd_bar_china = clean_data[0].drop(columns='China')","4789c8c7":"def get_portion(array, total, pct):\n    adder=total\n    for idx, x in enumerate(array):\n        if adder>((pct)*total):\n            adder = adder - x\n        else:\n            return idx\n    return None\n\ntotal_cases_ech = cd_bar_china.sum().sort_values(ascending=False)\nportion = get_portion(total_cases_ech, total_cases_ech.sum(), 0.11)\n\nprint(portion)\n\n","504861cd":"fig = plt.figure(figsize=(10,10))\naxl = fig.add_axes([0, 0, 1, 1])\naxl.axis('equal')\n\naxl.set_title(\"Portion affected outside China\")\n# total_cases_ech[portion:].sort_values(ascending=False)\nwedges, texts, autotexts = axl.pie(total_cases_ech[:portion], labels=total_cases_ech[:portion].index, autopct=\"%1.2f%%\")\n\naxl.legend(wedges, total_cases_ech[:portion].sort_values(ascending=False).index,\n          title=\"Countries\",\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\nplt.show()","a54e252f":"new_cases = pd.DataFrame({\"Confirmed\": clean_data[0].iloc[-1]  - clean_data[0].iloc[-2],\n               \"Deaths\": clean_data[1].iloc[-1]  - clean_data[1].iloc[-2],\n              \"Recovered\": clean_data[2].iloc[-1]  - clean_data[2].iloc[-2]})\n\nprint(new_cases.sort_values(by=\"Confirmed\", ascending=False).head(10))\nprint(new_cases.loc['India'])","f09b5e3d":" total_cases = pd.DataFrame({\"Confirmed\": clean_data[0].sum(),\n               \"Deaths\": clean_data[1].sum(),\n              \"Recovered\": clean_data[2].sum()})","da9b816c":"recovery_rate = [round((total_cases.loc[x]['Recovered']\/total_cases.loc[x]['Confirmed'])*100, 2)\n                 if total_cases.loc[x]['Confirmed'] != 0 else 0 for x in countries]\n\nmortality = [round((total_cases.loc[x]['Deaths']\/total_cases.loc[x]['Confirmed'])*100, 2)\n                 if total_cases.loc[x]['Confirmed'] != 0 else 0 for x in countries]\n\n\ntotal_cases['Recovery_rate'] = recovery_rate\ntotal_cases['Mortality'] = mortality\n\n","1b2564c6":"Recov_gr = total_cases.sort_values(by='Recovery_rate', ascending=False)\nRecov_gr.head(10)","be56121c":"\nfig2, ax2 = plt.subplots(figsize=(30, 15))\nax2.bar(Recov_gr.head(10).index, Recov_gr['Recovery_rate'].head(10))\nplt.xticks(rotation=90, ha='right')\nplt.show()","f3625855":"Mortality_gr = total_cases.sort_values(by='Mortality', ascending=False)\nMortality_gr.head(10)\n","b99b3269":"portion_mortal = get_portion(Mortality_gr['Mortality'], Mortality_gr['Mortality'].sum(), 0.20)\n","999c5f1b":"fig3, ax3 = plt.subplots(figsize=(30, 15))\nax3.bar(Mortality_gr[:portion_mortal].index, Mortality_gr[:portion_mortal]['Mortality'])\nplt.xticks(rotation=90, ha='right')\nplt.show()","9963b0c3":"confirmed_delta = clean_data[0].diff()\nconfirmed_delta.iloc[0] = 0\n# confirmed_delta.head()\n# figi, axi = plt.subplots(figsize=(30, 15))\n# axi.plot(confirmed_delta.index, confirmed_delta['Italy'])\n# plt.show()","cb065cc0":"\n# print(confirmed_delta['Italy'])\nfig, ax = plt.subplots(figsize=(30,15))\nx_labels = clean_data[0].index.sort_values()\n\nfor country in countries_bar_china:\n#     if (confirmed.sum>1000):\n    ax.plot(confirmed_delta.index, confirmed_delta[country] )\n#         handler.append(l)\n#     else:\n#         ax.plot(confirmed_delta.index, confirmed_delta )\nplt.grid(axis='both')  \n# plt.xticks(rotation=90, ha='right')\nplt.xlabel('Week Count').set_fontsize(30)\nax.xaxis.set_major_locator(MultipleLocator(7))\nax.xaxis.set_major_formatter(FormatStrFormatter(\"Week - %d\"))        #--------------------> get week number\nax.xaxis.set_minor_locator(MultipleLocator(1))\nplt.ylabel('Confirmed INCREMENT').set_fontsize(30)\nplt.title('Increment Rate for country till recent').set_fontsize(30)\nax.tick_params(axis='both', which='major', labelsize=20)\n\nhandles, labels = ax.get_legend_handles_labels()\n\nax.legend(handles[:20], labels[:20], loc='upper left', borderaxespad=0.8)\nplt.show()","10099308":"# DOWNLOADING THE DATA\nWe clone the github repository from the given link and access the time series data from the csse_covid_19_time_series directory. \nIt has three files in it, namely:\n\n1. time_series_covid19_confirmed_global.csv\n2. time_series_covid19_deaths_global.csv\n3. time_series_covid19_trending_global.csv\n","136ef391":"# Distribution of Confirmed cases worldwide","d50375e8":"# Recovery Rate","21862cb0":"# Mortality Rate","43747235":"# New Cases per day","0abdbf42":"\n### With this notebook I hope to answer the following 10 questions:\n~1. Deaths\/ Confirmed\/ Recovered till the current date~\n\n2. Graphically represent this information through graphs\n\n3. Deaths\/ Confirmed\/ Recovered per day and per month\n\n~4. The Highest rate till now; grouped by country; and displayed by the week~\n\n5. Compare with the deaths by car accidents\/ smoking(tobacco) deaths\n\n~6. Sort by the growth rate of confirmed~\n\n~7. Sort by the inc rate of recovered~\n\n8. Interactive Map showing Deaths\/ Confirmed\/ Recovered\n\n~9. Mortality rate\/ recovery chance for each country~\n\n10. What kind of distribution does the confirmed cases follow (look for patterns)\n","9afca74a":"This notebook is a project which visualises data gathered daily. After completion of the notebbok, I'll develop a dashboard that updates regularly as the github repo is updated. ","45d10fce":"# Mortality Graph","98365112":"# VISUALISING THE DATA","286471fb":"# Novel Coronavirus (COVID-19) Cases\nNovel Corona Virus (COVID-19) epidemiological data since 22 January 2020. The data is compiled by the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) from various sources including the World Health Organization (WHO), DXY.cn. Pneumonia. 2020, BNO News, National Health Commission of the People\u2019s Republic of China (NHC), China CDC (CCDC), Hong Kong Department of Health, Macau Government, Taiwan CDC, US CDC, Government of Canada, Australia Government Department of Health, European Centre for Disease Prevention and Control (ECDC), Ministry of Health Singapore (MOH). JSU CCSE maintains the data on the 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository on github.\nFields available in the data include \n* Province\/State\n* Country\/Region\n* Last Update\n* Confirmed\n* Suspected\n* Recovered\n* Deaths\n","9cddf363":"We drop the columns that are not necessary to make graphs and visualisations","b0764b2f":"The data for the covid-19 is updated daily on the github link --> [COVID-19](https:\/\/github.com\/CSSEGISandData\/COVID-19)","430b69a8":"# Rate of Increase in Confirmed Cases by the Country","5117dfcf":"# Catch the notebook in action \n   \n   ## Get to see the notebook in action at this dashboard I created using Dash-Plotly and hosted on Heroku \n   \ud83d\udc49\n   [covid-19-visual](http:\/\/covid-19-visual.herokuapp.com\/)","a09405c9":"Of course, this notebook is still under work and will see many revisions. Each of the 10 questions will be answered each day for 10 days; thus completing the project."}}