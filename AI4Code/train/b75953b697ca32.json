{"cell_type":{"7368b431":"code","c4c36236":"code","41557a2d":"code","7f94930b":"code","b031f607":"code","aaf1a852":"code","e58cf70b":"code","13fd87d6":"code","50416f14":"code","185724ab":"code","3dd4d6b7":"code","01bb2ce2":"code","35329909":"code","ba16898b":"code","0b10f392":"code","754be26c":"code","87f565ed":"code","32de3e2d":"code","93dfee21":"code","7b27a3a0":"code","4b7c194b":"code","b422a52f":"code","e4516196":"code","7d4686c5":"code","55885830":"code","48479c55":"code","3c9caab3":"code","222894f6":"code","9d074766":"markdown","9209e167":"markdown","01c3a252":"markdown","0de636b7":"markdown","be23f461":"markdown"},"source":{"7368b431":"import sys\nimport pandas as pd\nimport os\nfrom glob import glob\nsys.path.append(\"..\/input\/timmmaster\/\")\nsys.path.append(\"..\/input\/pythonbox\")","c4c36236":"test_df=pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest_df[\"Jpg\"] = test_df[\"Id\"].apply(lambda x: os.path.join('..\/input\/petfinder-pawpularity-score\/test', x + \".jpg\"))","41557a2d":"#store predictions of each model\nmodel_predictions=[]","7f94930b":"from timm import create_model\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nimport gc\nfrom fastai.vision.all import *\n\nMODEL_WEIGHT='..\/input\/exp044-044-beit-large-chaug-mixup-chbs'\nPRETRAINED='beit_large_patch16_224'\nIMG_SIZE = 224\nN_FOLDS = 10\nBATCH_SIZE = 32\nSEED = 2021\n\nset_seed(SEED, reproducible=True)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","b031f607":"dataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","aaf1a852":"df = pd.read_csv(f'{dataset_path}\/train.csv')\ndf[\"Jpg\"] = df[\"Id\"].apply(lambda x: os.path.join(f'{dataset_path}\/train', x + \".jpg\"))\ndf['norm_score'] = df['Pawpularity']\/100","e58cf70b":"all_preds = []\n\nfor i in range(N_FOLDS):   \n\n    print(f'Fold {i} results')\n    \n    dls = ImageDataLoaders.from_df(df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               path='.',\n                            #    folder='train',\n                               seed=SEED, #seed\n                               fn_col='Jpg', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(IMG_SIZE), #pass in item_tfms\u2192\u30d0\u30c3\u30c1\u5316\u524d\u306e\u5404\u30a2\u30a4\u30c6\u30e0\u306b\u9069\u7528\n                               batch_tfms=setup_aug_tfms([Flip(),])) #\u5404\u30d0\u30c3\u30c1\u306b\u9069\u7528\n    \n    #batch_size\u306f\u3001\u4f5c\u6210\u5143\u306e\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u5024\u3092\u5f15\u304d\u7d99\u3050\n    test_dl=dls.test_dl(test_df)\n#     break\n    \n    model = create_model(PRETRAINED, pretrained=False, num_classes=dls.c)\n    learn = Learner(\n        dls, \n        model, \n        model_dir= MODEL_WEIGHT,\n        loss_func= BCEWithLogitsLossFlat()\n    ).to_fp16()\n    \n    # learner\u306e{self.path}\/{self.model_dir}\/{file}.pth\u304b\u3089\u8aad\u307f\u8fbc\u307f\n    learn.load(f'{i+1}fold_best')\n    \n    \n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.5)\n    \n    all_preds.append(preds)\n    \n    del learn\n\n    torch.cuda.empty_cache()\n\n    gc.collect()\n","13fd87d6":"preds = (np.mean(np.hstack(all_preds), axis=1))*100\nmodel_predictions.append(preds)","50416f14":"from timm import create_model\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nimport gc\nfrom fastai.vision.all import *\n\nMODEL_WEIGHT='..\/input\/exp056-056-swin-large-224-new'\nPRETRAINED = 'swin_large_patch4_window7_224'\nIMG_SIZE = 224\nN_FOLDS = 10\nBATCH_SIZE = 32\n\nSEED=1\nset_seed(SEED, reproducible=True)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\n\ndef petfinder_rmse(input,target):\n    return torch.sqrt(F.mse_loss(100*F.sigmoid(input.flatten()), 100*target))","185724ab":"dataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","3dd4d6b7":"df = pd.read_csv(f'{dataset_path}\/train.csv')\ndf[\"Jpg\"] = df[\"Id\"].apply(lambda x: os.path.join(f'{dataset_path}\/train', x + \".jpg\"))\ndf['norm_score'] = df['Pawpularity']\/100","01bb2ce2":"all_preds = []\n\nfor i in range(N_FOLDS):   \n\n    print(f'Fold {i} results')\n    \n    dls = ImageDataLoaders.from_df(df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               path='.',\n                            #    folder='train',\n                               seed=SEED, #seed\n                               fn_col='Jpg', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(IMG_SIZE), #pass in item_tfms\u2192\u30d0\u30c3\u30c1\u5316\u524d\u306e\u5404\u30a2\u30a4\u30c6\u30e0\u306b\u9069\u7528\n                               batch_tfms=setup_aug_tfms([Flip(),])) #\u5404\u30d0\u30c3\u30c1\u306b\u9069\u7528\n    \n    #batch_size\u306f\u3001\u4f5c\u6210\u5143\u306e\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u5024\u3092\u5f15\u304d\u7d99\u3050\n    test_dl=dls.test_dl(test_df)\n#     break\n    \n    model = create_model(PRETRAINED, pretrained=False, num_classes=dls.c)\n    learn = Learner(\n        dls, \n        model, \n        model_dir= MODEL_WEIGHT,\n        loss_func= BCEWithLogitsLossFlat()\n    ).to_fp16()\n    \n    # learner\u306e{self.path}\/{self.model_dir}\/{file}.pth\u304b\u3089\u8aad\u307f\u8fbc\u307f\n    learn.load(f'{i+1}fold_best')\n    \n    \n    preds, _ = learn.tta(dl=test_dl, n=4, beta=0.5)\n    \n    all_preds.append(preds)\n    \n    del learn\n\n    torch.cuda.empty_cache()\n\n    gc.collect()\n","35329909":"preds = (np.mean(np.hstack(all_preds), axis=1))*100\nmodel_predictions.append(preds)","ba16898b":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\nimport random\nimport  time\nimport gc\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\n\n#RAPIDS\nimport cupy as cp\nimport cuml, pickle\nfrom cuml.svm import SVR\n\nwarnings.filterwarnings(\"ignore\")\n","0b10f392":"def sigmoid(a):\n    return 1 \/ (1 + np.exp(-a))","754be26c":"def set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(2021)","87f565ed":"dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n\nclass PetfinderDataset(Dataset):\n    #image_size\u306fresize\u3067\u7528\u3044\u308bsize\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Jpg\"].values\n        self._features=df[dense_features].values\n        self._y = None\n        #\u30ab\u30e9\u30e0\u306e\u4e00\u89a7\u3092\u53d6\u5f97\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        fearure = self._features[idx]\n        #rgb\u306e\uff13\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u542b\u3093\u3060tensor\u306b\u5909\u63db\n        image = read_image(image_path)\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]\n            return image, fearure, label\n        return image, fearure","32de3e2d":"class Model(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self.transforms = get_default_transforms()\n        \n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=False, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features+12, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x1, x2, svr_path, tta=True, svr_weight=0.45):\n        svr_head = pickle.load(open(svr_path, \"rb\"))\n        \n        if tta == True:\n            nn_preds=[]\n            svr_preds=[]\n            for k,transform in self.transforms.items():\n                x=transform(x1)\n                x = self.backbone(x)\n                x = torch.cat([x, x2], dim=1)\n                #tensor\n                nn_pred = self.fc(x)\n                #rapid\u306endarray\n                svr_pred = svr_head.predict(x)\n                \n                nn_preds.append(nn_pred)\n                svr_preds.append(svr_pred)\n            \n            nn_pred=torch.mean(torch.stack(nn_preds, dim=0), dim=0)\n            nn_pred=nn_pred.to('cpu').detach().numpy()\n            nn_pred=np.array([sigmoid(p)*100 for p in nn_pred]).ravel()\n            \n            #ndarray\u306b\u5909\u63db\u3057\u3066\u304b\u3089mean\n            svr_pred = np.mean(cp.array(svr_preds).get(), axis=0)\n            \n            pred=(1-svr_weight)*nn_pred+svr_weight*svr_pred\n\n        return pred\n","93dfee21":"#weight_path\u3068image_size\u3068\u3001model_name\u306f\u5909\u66f4\nconfig = {'seed': 2021,\n          'root': '\/kaggle\/input\/petfinder-pawpularity-score\/', \n          'weight_path':'..\/input\/exp006-tta1',\n          'svr_path': '..\/input\/svrhead-for-exp006',\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 384\n          },\n          'test_loader': {\n              'batch_size': 32,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n              'name': 'swin_large_patch4_window12_384',\n              'output_dim': 1\n          },\n          'device':'cuda' if torch.cuda.is_available() else 'cpu',\n          'amp':True,\n          'tta':True\n}\n\nconfig = Box(config)","7b27a3a0":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\n#for TTA\ndef get_default_transforms(image_size: int = config.transform.image_size):\n\n    transforms_dict = {\n        \"default\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n    ),\n        \"tta_flip\": T.Compose(\n            [   \n                T.RandomHorizontalFlip(p=1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n    ),\n        \"tta_rotate\": T.Compose(\n            [   \n                T.RandomRotation(degrees=45),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n    )\n    }\n\n    return transforms_dict","4b7c194b":"test_dataset=PetfinderDataset(test_df, config.transform.image_size)\ntest_dataloader=DataLoader(test_dataset,**config.test_loader)","b422a52f":"model = Model(config) \nmodel.to(config.device)\nmodel_paths=glob(f'{config.weight_path}\/*')","e4516196":"fold_predictions=[]\nfor fold in range(10):\n    \n    model_weight = f'..\/input\/exp006-tta1\/{fold+1}fold_best_loss.ckpt'\n    svr_path=f'{config.svr_path}\/SVR_fold_{fold}.pkl'\n    \n    print(model_weight)\n    print(svr_path)\n    model.load_state_dict(torch.load(model_weight)['state_dict'])\n    model.eval()\n    \n    predictions=[]\n    with torch.no_grad():\n        #\u534a\u7cbe\u5ea6\n        if config.amp==True:\n            with torch.cuda.amp.autocast(enabled=True):\n                for img, features in test_dataloader:\n                    img=img.to(config.device)\n                    features=features.to(config.device)\n                    out=model(img, features, svr_path, tta=config.tta, svr_weight=0.45)\n                    predictions.append(out)\n        \n        else:\n            for img, features in test_dataloader:\n                img=img.to(config.device)\n                features=features.to(config.device)\n                out=model(img, features, svr_path, tta=config.tta, svr_weight=0.45)\n                predictions.append(out)\n                \n    predictions=np.hstack(predictions)\n    \n    fold_predictions.append(predictions)","7d4686c5":"final_predictions=np.mean(fold_predictions,axis=0)\nmodel_predictions.append(final_predictions)","55885830":"del test_dataset,test_dataloader,model\ngc.collect()\ntorch.cuda.empty_cache()","48479c55":"w1=0.36826336\nw2=0.35625861\nw3=0.27547803\nens_pred=w1*model_predictions[0]+w2*model_predictions[1]+w3*model_predictions[2]","3c9caab3":"test_df[\"Pawpularity\"] = ens_pred\ntest_df = test_df[[\"Id\", \"Pawpularity\"]]\ntest_df.to_csv(\"submission.csv\", index=False)","222894f6":"test_df.head()","9d074766":"# Swin-L-224","9209e167":"# commom setting","01c3a252":"# Swin-L-384","0de636b7":"# weight_ensemble","be23f461":"# Beit-L-224"}}